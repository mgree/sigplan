{"article_publication_date": "09-25-2013", "fulltext": "\n The Bedrock Structured Programming System Combining Generative Metaprogramming and Hoare Logic in an \nExtensible Program Veri.er Adam Chlipala MIT CSAIL adamc@csail.mit.edu Abstract We report on the design \nand implementation of an extensible pro\u00adgramming language and its intrinsic support for formal veri.ca\u00adtion. \nOur language is targeted at low-level programming of infras\u00adtructure like operating systems and runtime \nsystems. It is based on a cross-platform core combining characteristics of assembly lan\u00adguages and compiler \nintermediate languages. From this founda\u00adtion, we take literally the saying that C is a macro assembly \nlan\u00adguage : we introduce an expressive notion of certi.ed low-level macros, suf.cient to build up the \nusual features of C and beyond as macros with no special support in the core. Furthermore, our macros \nhave integrated support for strongest postcondition calcu\u00adlation and veri.cation condition generation, \nso that we can provide a high-productivity formal veri.cation environment within Coq for programs composed \nfrom any combination of macros. Our macro interface is expressive enough to support features that low-level \nprograms usually only access through external tools with no formal guarantees, such as declarative parsing \nor SQL-inspired querying. The abstraction level of these macros only imposes a compile-time cost, via \nthe execution of functional Coq programs that compute programs in our intermediate language; but the \nrun-time cost is not substantially greater than for more conventional C code. We describe our experiences \nconstructing a full C-like language stack using macros, with some experiments on the veri.ability and \nper\u00adformance of individual programs running on that stack. Categories and Subject Descriptors F.3.1 [Logics \nand meanings of programs]: Mechanical veri.cation; D.3.4 [Programming Lan\u00adguages]: Compilers Keywords \ngenerative metaprogramming; interactive proof assis\u00adtants; low-level programming languages; functional \nprogramming 1. Introduction A fundamental tension in programming language design is between performance \nand abstraction. Closer to the high-performance end of the spectrum, we have languages like C, which \nare often used to implement low-level infrastructure that many applications de- Permission to make digital \nor hard copies of part or all of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. Copyrights for third-party components of this work must be honored. \nFor all other uses, contact the owner/author(s). Copyright is held by the owner/author(s). ICFP 13, \nSeptember 25 27, 2013, Boston, MA, USA. ACM 978-1-4503-2326-0/13/09. http://dx.doi.org/10.1145/2500365.2500592 \npend on. Examples include operating systems and runtime systems, which today are almost exclusively written \nin C and its close rela\u00adtives. Need we always choose between performance and abstraction? One approach \nto retaining both is metaprogramming, from basic cases of textual macro substitution as in the C preprocessor, \nto so\u00adphisticated code generators like Yacc. Here we employ abstractions that in a sense are compile-time \nonly, running programs that gen\u00aderate programs in C or other low-level languages. As a result, we incur \nno run-time cost to abstraction. Unfortunately, code generation is hard to get right. The C pre\u00adprocessor \ns textual substitution mechanism allows for all sorts of scoping errors in macro de.nitions. There exist \nwidely used alter\u00adnatives, like the macro systems of Lisp/Scheme, OCaml (Camlp4), and Haskell (Template \nHaskell), which can enforce hygiene re\u00adquirements on lexical scoping in macro de.nitions. The functional \nprogramming community knows well the advan\u00adtages of code generation with languages like Haskell and ML \nas metalanguages for embedded domain-speci.c languages (DSLs). That is, one represents the programs of \nsome object language, like C or CUDA, as data within the metalanguage, making it possible to compute \nprograms of the object language at compile time using all of the abstraction features of the metalanguage. \nThere is a tower of static assurance levels for this kind of gener\u00adative metaprogramming. Tools like \nYacc receive little static assur\u00adance from their implementation languages, as they output source code \nas strings that the implementation language does not analyze. Conventional macro systems, from primitive \ntoken substitution in C to hygienic Scheme macros, can provide stronger lexical guar\u00adantees. Next in \nthe tower are languages that allow for static typing of macros, guaranteeing that any of their applications \nproduce both scope-safe and type-safe object-language code. Languages in this category include MetaML \n[30] and MacroML [13], for homoge\u00adneous metaprogramming where the meta and object languages are the same; \nand MetaHaskell [22], for heterogeneous metaprogram\u00adming where meta and object languages are different \n(e.g., Haskell and CUDA). Our contribution in this paper is to continue higher up this tower of static \nguarantees: we support separate static check\u00ading of macros to guarantee that they always produce functionally \ncorrect object-language code. The programming language and associated veri.cation tools will need to \nprovide a proof rule for each macro. A naive proof rule just expands macro applications using their de.nitions, \npro\u00adviding no abstraction bene.t. We could ask instead that macro de.\u00adnitions include proof rules, and \nthat the veri.cation system requires programmers to prove that their macro de.nitions respect the as\u00adsociated \nproof rules. In effect, we have a macro system support\u00ading modularity in the style of well-designed functions, \nclasses, or libraries, with clear separation between implementation and inter\u00adface.  In this paper, \nwe report on our experiences building such a macro system for a low-level language, intended as a replacement \nfor C in the systems programming domain. This macro system is part of the Bedrock library for the Coq \nproof assistant, which provides an integrated environment for program implementation, speci.cation, and \nveri.cation. A prior publication [8] introduced Bedrock s support for proof automation, implementing \nexample programs using an earlier version of our macro system but not de\u00adscribing it in detail. Since \nthat paper was written, the macro system has evolved, and we have used it to implement more interesting \nexamples. We now present its design and implementation in detail, along with the higher-level language \ndesign principle that motivates it. Our metalanguage is Gallina, the functional programming lan\u00adguage \nin Coq s logic. Our object language is a tiny compiler inter\u00admediate language. We build up the usual \nfeatures of C via unpriv\u00adileged macros, and then we go further and implement features like declarative \nparsing and declarative querying of data structures as macros rather than ad-hoc external tools like \nYacc and MySQL. To support productive formal veri.cation, we tag each macro with a proof rule. To be \nmore precise, each macro contains a pred\u00adicate transformer, which evolves a logical assertion to re.ect \nthe effects of a program statement; and a veri.cation condition gener\u00adator, which outputs proof obligations \nassociated with a use of the macro. These are some of the standard tools of highly automated program \nveri.cation, and requiring them of all macros lets us build a generic veri.cation environment that supports \nautomated proofs about programs built with macros drawn from diverse sources. We call the central abstraction \ncerti.ed low-level macros. Our implementations and proofs have much in common with compiler veri.cation. \nFor instance, CompCert [21] is a C com\u00ad piler implemented in Coq with a proof that it preserves program \nsemantics. Each of our macro implementations looks like one case of the CompCert compiler, dealing with \na speci.c source language syntax construct, paired with the corresponding correctness proof cases. A \nspeci.c program may draw upon several macros imple\u00admented by different programmers, who never considered \nhow their macros might interact. The proof approach from CompCert does not extend straightforwardly to \nthis setting, since each CompCert subproof refers to one or more simulation relations between the programs \nof different .xed languages. It is not apparent how such an approach could be extended to verify compilation \nrules for ex\u00adtensible languages. For instance, in that conventional setting, func\u00adtion pointers may be \nspeci.ed informally as points to the code our compiler would generate from the corresponding source-level \nfunc\u00adtion body, an explanation that does not adapt naturally to the case of an extensible compiler. We \nwould rather not verify handling of function pointers relative to a particular set of available macros. \nThe key selling point of compile-time metaprogramming is per\u00adformance. Programmers will come up with \ndifferent code con\u00adstructs that mimic those available in higher-level programming lan\u00adguages, but implemented \nin a way that facilitates case-speci.c op\u00adtimization and in general promotes performance. We are able \nto attach speci.cations to such macros in a way that makes reasoning about use of a macro more like reasoning \nabout a function call than reasoning directly about low-level code after macro expansion. At a high level, \nthen, our contribution can be viewed alter\u00adnatively as an extensible programming language or an extensible \nHoare-logic program veri.er. We present the .rst low-level lan\u00adguage with a notion of macros that cleanly \nseparates interface and implementation, to such an extent as to enable mostly au\u00adtomated correctness \nveri.cation without macro expansion. We Constants c ::= [width-32 bitvectors] Code labels e ::= ... Registers \nAddresses Lvalues Rvalues Binops Tests Instructions Jumps Specs Blocks Modules r a L R o t i j S B M \n::= ::= ::= ::= ::= ::= ::= ::= ::= ::= ::= Sp | Rp | Rv r | c | r + c r | [a]8 | [a]32 L | c | e + | \n- | \u00d7 =| = | < | = L . R | L . R o R goto R | if (R t R) then e else e ... e : {S} i * ; j B * Figure \n1. Syntax of the Bedrock IL prove correctness theorems within a framework for modular ver\u00adi.cation, where \nwe can verify libraries separately and then link together their correctness theorems into whole-program \ncorrect\u00adness theorems, without revisiting details of code implementation or proof. This modularity holds \neven in the presence of a mutable heap that may hold callable code pointers, thanks to the XCAP [26] \nprogram logic that sits at the base of our framework. The remaining sections of this paper will walk \nthrough the steps of building our stack of macros. We begin with a tiny assembly-like language and proceed \nto introduce our notion of certi.ed low-level macros for it, build macros for basic C-like constructs, \nadd support for local variables and function calls, and culminate in the high\u00adlevel macros for declarative \nparsing and querying. Next we evaluate the effectiveness of our platform in terms of program veri.ability \nand run-time performance, and we .nish with a comparison to related work. Source code to both the Bedrock \nlibrary and our example pro\u00adgrams is available in the latest Bedrock source distribution at: http://plv.csail.mit.edu/bedrock/ \n 2. The Bedrock IL The lowest layer of Bedrock is a simple intermediate language in\u00adspired by common \nassembly languages. This Bedrock IL is easy to compile to those real languages, using only localized \nreplace\u00adment of IL concepts with assembly language constructs. A single veri.cation result applies to \nall target architectures. So far, we have built a compiler to AMD64 assembly (currently unveri.ed), and \nwe expect it will be easy to implement sound translations to other popular architectures like ARM and \n32-bit x86. Figure 1 gives the full syntax of the Bedrock IL. There are small .nite sets of registers, \naddressing modes (for both 8-bit and 32-bit memory accesses), and forms of lvalues and rvalues (borrowing \nC terminology). Straightline instructions do assignment or arithmetic, and jump instructions do unconditional \nbranching or branching based on the result of an arithmetic comparison. A standalone code module is a \nset of basic blocks, each with a code label and a speci.cation. Bedrock is based on the XCAP program \nlogic [26] of Ni and Shao, and block speci.cations use the XCAP assertion language, which supports a \nlimited form of higher-order logic tailored to reasoning about .rst-class code pointers. A module is \ncorrect when every one of its blocks satis.es two conditions: Progress: When control enters the block \nin a machine state satisfying the spec, control continues safely at least until the end of the block. \n Preservation: When control enters the block in a machine state satisfying the spec and exits the block \nby jumping to some other block, the spec of the new block is satis.ed. In this way, we can construct \nan inductive proof of in.nite safe execution, giving us memory safety. Further, we may also treat each \nblock spec as an assertion, so that we verify absence of assertion failures, giving us functional correctness. \nXCAP supports separate veri.cation and linking of modules, via mechanisms that we will not go into here, \nbut we do want to emphasize that XCAP supports modular veri.cation, where libraries can be veri.ed separately \nin a way that permits composition of their correctness theorems to conclude whole-program theorems. It \nis not trivial to design a framework that permits such modular proof rules in the presence of a mutable \nhigher-order heap, where code from one module might .nd in the heap a pointer to code from another module \nwritten and veri.ed independently. Building on XCAP enables us to realize this level of modularity without \ndoing much explicit extra work. What does it mean for a Bedrock IL program to be safe? There are two \nsorts of bad instruction executions that violate safety. First, a jump to a nonexistent code label is \nillegal. Second, a Bedrock IL program is restricted to read or write only memory addresses allowed by \na con.gurable memory policy. These informal notions are codi.ed in a conventional Coq op\u00aderational semantics. \nWe support sound compilation to a variety of assembly languages by considering machine states to contain \na read-only component describing the byte ordering of words in memory, with enough expressiveness to \ndescribe little-endian, big\u00adendian, and other orders. As a result, we can work with a trivial ar\u00adray \nof bytes memory model, rather than the more complex mem\u00adory model used in, e.g., the informal ANSI C \nsemantics and the closely related formal semantics of CompCert [21]. The simplistic memory model we adopt \nmakes it dif.cult to reason about many standard program transformations and optimizations, but we still \nachieve reasonable performance with an optimizer-free implemen\u00adtation (see Section 6). There is a great \nbene.t to starting from a language with such a simple semantics. Our .nal platform is foundational, in \nthe sense that we produce formal proofs that can be checked and audited with relatively small trusted \ncode bases. We need to trust the Coq proof checker and its dependencies, which can be made small compared \nto program veri.ers in general. Beyond that, we must make sure that the statement of the theorem we prove \nmatches our informal notion of program safety or correctness. The theorems that come out of our system \nare stated only in terms of the Bedrock IL operational semantics, which is quite small and easy to audit. \nMost importantly in the context of this paper, the .nal theorem statements are independent of any details \nof our macro system. A .nal foundational theorem will be of the form if execution begins at code address \ne1 in a state satisfying the spec of e1, then if execution ever reaches code address e2, the spec of \ne2 will be satis\u00ad.ed. In the sections that follow, we will introduce convenient nota\u00adtions not just for \nprograms, but also for speci.cations; for instance, see the notation for specifying functions with local \nvariables in Sec\u00adtion 4. If such a notation appears in a .nal correctness theorem, then its de.nition \nmust be considered part of the trusted base. However, we are able to prove .nal theorems that reduce \nour notations to sim\u00adpler concepts. For instance, while we may verify the main() func\u00adtion of a program \nagainst a precondition-postcondition-style spec\u00adi.cation inspired by separation logic [28], the .nal \ntheorem state\u00ad ment need only say that main() requires all memory addresses between 0 and N are allowed \nby the memory access policy. We prove that the latter implies the former, and so a .nal audit of a veri.ed \nprogram need only ensure that the latter is accurate. Definition appendS : spec := SPEC(\"x\", \"y\") reserving \n2 Al ls1, Al ls2, PRE[V] sll ls1 (V \"x\") * sll ls2 (V \"y\") POST[R] sll (ls1 ++ ls2) R. bfunction \"append\"(\"x\", \n\"y\", \"r\", \"tmp\") [appendS] If ( \"x\" = 0) {Return \"y\" } else { \"r\" . \"x\";; \"tmp\" . * \"x\" + 4;; [ Al p1, \nAl x, Al ls1, Al ls2, PRE[V] I V \"x\" = p1 l * V \"x\" . x = $0 l * I V \"tmp\" * ( V \"x\" + $4) . p1 * sll \nls1 p1 * sll ls2 (V \"y\") POST[R] I R = V \"r\" l * sll (x :: ls1 ++ ls2) ( V \"x\") ] While (\"tmp\" = 0) { \n\"x\" . \"tmp\";; \"tmp\" . * \"x\" + 4 };; \"x\" + 4 *. \"y\";; Return \"r\" } end Figure 2. Bedrock implementation \nof destructive list append 3. Certi.ed Low-Level Macros Bedrock s structured programming system uses \nmacros to present a C-like view of the Bedrock IL. Figure 2 shows an example, a destructive linked-list \nappend function, beginning with its formal speci.cation, whose explanation we put off until later. The \nbody of the implementation uses standard control .ow constructs like if and while to group together sequences \nof operations on local variables, which are named with string literals to appease Coq s lexer. (In this \npaper, we never use a string literal for its more conventional purpose in C-like code, so it is safe \nto assume that literals indicate object-language identi.ers.) A token . * indicates a memory read operation, \nwhile *. indicates a write. A loop invariant appears within square brackets. We will have a bit more \nto say later about the language of speci.cations and invariants, though it is not our focus in this paper, \nas our architecture applies to other speci.cation languages, too. For now, the take-away message from \nFigure 2 is that it denotes a Coq program for computing an assembly program, in the style of heterogeneous \ngenerative metaprogramming. None of the con\u00adtrol .ow constructs are built into the language, but rather \nthey use macros that any Bedrock programmer can de.ne without modify\u00ading the library. We also want to \nprove that the computed assembly program is correct. Programming, compilation, and proving are all done \ncompletely within the normal Coq environment. We will introduce our central concept of macro in two stages. \nFirst we introduce the aspects needed to support compilation of programs, and then we add the features \nto support veri.cation. 3.1 The Code Generation Part of a Macro In our setting, a macro stands for a \nstatement in the sense of C-like languages. To make sense of this concept, we must impose a notion of \nstructured programs on top of the freeform control .ow of the Bedrock IL. Figure 3 summarizes such an \ninterface. The fundamental task of a macro is to mutate a program by appending new basic blocks to it. \nSuccessive blocks are assigned successive numeric labels. To run a macro, it must be passed one input: \nthe exit label of the block its statement should jump to when .nished. This label will have Figure 3. \nThe interface of a low-level macro   Figure 4. Sketch of macro for single straightline instructions \n Figure 5. Sketch of macro for if..then..else been allocated previously by other macros. A macro runs \nby not only creating new basic blocks, but also returning one more value: an entry label within the freshly \ngenerated code blocks. A macro s statement is run by jumping to the entry label. Consider the very basic \nexample of a macro for converting a straightline IL instruction into a statement. Figure 4 sketches a \nsimple implementation. Macros are implemented as functional pro\u00adgrams in Coq s logic, so it is natural \nto think of them as statement combinators. The straightline code combinator takes an instruction i as \nits parameter. When run, the macro allocates a single block, consisting of i followed by a direct jump \nto the exit label. The out\u00adput entry label points to the new block. A more involved example is the if..then..else \nmacro, as sketched in Figure 5. While Bedrock IL includes a standard conditional jump Figure 6. The \ninterface of a certi.ed low-level macro instruction, we would rather program in terms of a higher-level \nstatement combinator that hides details of code block label allo\u00adcation. The if..then..else combinator \ntakes three arguments: a test expression, suitable as an argument to Bedrock IL s low-level con\u00additional \njump; a then statement, to run when the test passes; and an else statement, to run when the test fails. \nThe two statement param\u00adeters will generally be constructed with further macro applications, and the \nif..then..else combinator should work correctly regardless of the details of the two statements. An instance \nof the if..then..else combinator works as follows: The macro is passed an exit label as input. The same \nlabel is passed along unchanged as the exit label inputs to the then and else statements. That is, regardless \nof which way the test expression evaluates, the statement we jump to should exit the if..then..else upon \ncompletion.  Each of the then and else macros generates some code blocks to represent itself, outputting \nan entry label for each. The if..then..else macro adds one more code block, a conditional jump using \nthe test expression, jumping to the entry label of ei\u00adther the then or else case, depending on how the \ntest evaluates.  Finally, the overall macro outputs the address of the conditional test as its own entry \nlabel.  The working of the macro is broadly similar to standard com\u00adpilation strategies. To support \nan expressive macro system, it is crucial to choose a macro interface compatible with a wide range of \ncompilation rules. Many other such architectures are possible. For instance, Benton et al. [2] use an \nintermediate language with explicitly scoped local labels. The veri.cation support of our ap\u00adproach ought \nto adapt straightforwardly to many such compilation schemes, since in a sense veri.cation considers only \na macro s in\u00adterface and not its implementation. It is worth mentioning one mundane aspect of macro implemen\u00adtation, \nwhich is registering concrete parsing notations for macros. We rely on Coq s extensible parser for this \npurpose. For instance, here is the notation we introduce for calls to the if..then..else com\u00adbinator \nIf_: Notation \" If c { b1 } else { b2 }\" := (If_ c b1 b2) (no associativity, at level 95, c at level \n0) : SP_scope. All of the standard control-.ow constructs of C-like languages are straightforward to \nencode in our macro system, but, before we consider more examples, we back up to extend the macro interface \nfor veri.cation support.  3.2 Veri.cation Support Figure 6 gives the expanded interface of certi.ed \nlow-level macros, where we add the ingredients needed to build a formal veri.ca\u00adtion environment that \nsupports automated proofs about programs that use macros drawn from diverse sources. At a high level, \nthe addition is this: We previously de.ned a macro as a compila\u00adtion rule. Veri.cation support involves \nalso including a predicate transformer (closely related to the idea of a strongest postcondi\u00adtion calculator) \nand a veri.cation condition generator.  The predicate transformer of a macro maps a precondition to \na postcondition. Both sorts of conditions are logical predicates over Bedrock IL machine states; that \nis, they can be represented as functions typed like state . Prop, returning logical propo\u00adsitions given \nmachine states as input. The precondition describes the machine state on entry to a statement, and the \npostcondition describes the machine state when control exits the statement. The postcondition is computed \nas a function, or transformation, of the precondition, leading to the name predicate transformer. At \na high level, the predicate transformer of a macro answers the question what does this macro do? A macro \nalso includes a veri.cation condition generator, which given a precondition outputs a logical formula \n(a veri.ca\u00adtion condition) that the programmer must prove. If the veri.cation condition is false, the \nstatement may not work as expected. At a high level, the veri.cation condition generator answers the \nques\u00adtion which uses of this macro are safe and functionally correct? More formally, we de.ne the veri.cation \npart of a macro with: Predicates P = state . Prop Predicate transformers T = P . P Veri.cation condition \ngenerators C = P . Prop Veri.cation parts of macros V = T\u00d7 C At a high level, the intent of these de.nitions \nis as follows: Consider a macro de.nition M(x1, . . . , xn) = E, expanding an M invocation into some \nmore primitive statement E. Let the associated predicate transformer be T . T and the veri.cation condition \ngenerator be C . C. Client code sees the following Hoare-logic proof rule for a macro invocation with \na particular precondition P . P: {P . C(P )}M(e1, . . . , en){T (P )} The formal version of this notation \nis complicated by the need to deal with sets of IL basic blocks, rather than the usual structured statements. \nTo give an intuition for those details, we return to extended versions of our previous example macros. \nFirst, consider the straightline code macro with instruction parameter i. When called with precondition \nP , the macro produces: i ' ' Veri.cation condition: .s. P (s) . .s. s -. s i ' '' Postcondition: .s. \n.s. P (s) . s-. s Preconditions and postconditions are predicates, or functions from machine states to \nlogical propositions, so we often notate i them as anonymous . functions. The judgment s -. s' asserts \nthat running instruction i transforms state s into state s'. Instruction executions that would violate \nBedrock IL safety do not belong to this relation. Thus, the veri.cation condition expresses the idea \nthat the pre\u00adcondition implies safety of executing the instruction i. The post\u00adcondition is actually \nthe strongest postcondition for this particular macro, denoting exactly the set of states that could \nbe reached by running i in a state satisfying P . In general, macros need to ex\u00adpose sound postconditions, \nwhich include all possible states upon statement exit, but macros need not always return strongest post\u00adconditions. \nIndeed, the chance to return weaker postconditions is essential for supporting separation of interface \nand implementation in macros, where some details of macro implementation are hid\u00adden in speci.cations \nthat are easier to reason about than strongest postconditions. Consider now the if..then..else macro, \nwhere the parameters are a conditional test e, a then statement with predicate transformer T1 and veri.cation \ncondition generator C1, and an else statement with predicate transformer T0 and veri.cation condition \ngenerator C0. If the overall precondition is P , the macro produces: e Veri.cation condition:Cb(.s. \nP (s) . s -. b) b.{0,1} e . (.s. P (s) . .b. s -. b) e ' Postcondition: .s'.Tb(.s. P (s) . s -. b)(s) \nb.{0,1} e We write s -. b to indicate that conditional test e evaluates to Boolean value b . {0, 1} in \nstate s. The overall veri.cation condition is the conjunction of the two sub-statements veri.cation conditions, \nplus the requirement that the precondition imply safety of evaluating the conditional test. The overall \npostcondition is a disjunction of the sub-statements postconditions. In each case, we pass off extended \npreconditions that combine the original precon\u00addition P with information on the outcome of the test e. \nWe have decided that a macro constitutes a parsing rule, a com\u00adpilation rule, a predicate transformer, \nand a veri.cation condition generator. The last crucial ingredient is a proof that all of the above agree \nwith each other in an appropriately sound way. That is, we package macros with dependently typed records \nthat contain not just functions but also machine-checked proofs about those func\u00adtions. Such a thing \nis easy to do in Coq, as shown by our de.nition of macros below. (These de.nitions actually occur in \na Coq sec\u00adtion that introduces parameters describing the code s assumptions about its own module and \nothers, but we omit such details here to simplify the presentation.) Note that this code incorporates \na few optimizations, including representing veri.cation conditions as lists of propositions instead of \nsingle propositions, to allow conjunction of veri.cation condi\u00adtions without creating arbitrarily bushy \nconjunction trees; and stag\u00ading of macros in a manner similar to currying, so that programs may be veri.ed \nwithout the need to generate code for them. We write Prop for the type of logical propositions, or standalone \nfacts; and assert for the type of predicates over machine states, or func\u00adtions from states to Prop. \n(* Delayed code generation part of macro output *) Record codeGen (Precondition : assert) (Base Exit \n: N) ( Postcondition : assert) (VerifCond : list Prop) := { Entry : N; Blocks : list (assert * block); \n PreconditionOk : . bl, nth_error Blocks (nat_of_N Entry) = Some (Precondition, bl); BlocksOk : vcs \nVerifCond . Exit < Base . List.Forall (fun p . blockOk  ( imps Blocks Base Exit Postcondition) (fst \np) (snd p)) Blocks }. (* Immediate verification part of macro output *) Record codeOut (Precondition \n: assert) := {Postcondition : assert; VerifCond : list Prop; Generate : . Base Exit : N, codeGen Precondition \nBase Exit Postcondition VerifCond }. (* Overall type of a macro, a dependent function type *) Definition \ncmd := . cin : assert, codeOut cin.  We will explain these de.nitions in reverse. A macro, of type cmd, \nhas a dependent function type, where the return type of the function is allowed to mention the value \nof the actual parameter. In this case, the formal parameter cin is the input precondition, and we return \na value of a type codeOut cin specialized to the pre\u00adcondition. Where our earlier less formal de.nitions \ntreated predi\u00adcate transformers and veri.cation condition generators as indepen\u00addent functions over preconditions, \nhere we instead make the whole macro a function on preconditions. A codeOut record contains the computed \npostcondition and veri.cation condition, as well as Generate, a function that we call if we wish to do \ncode generation, too. A codeGen record contains the output of code generation. While our earlier sketches \nrefer to generation of new code blocks as an imperative process, we implement generation in Coq via re\u00adturning \nlists of new blocks only. Furthermore, a Generate function is passed not only the Exit label for a statement, \nbut also Base, the address that will be given to the .rst new code block returned by this macro. In general, \nthe nth block in the output will have label Base + n. It is important to .x the labeling convention to \nallow the macro to create internal jumps in its code blocks. Speci.cally, the codeGen record includes \nthe Entry label of the statement and the list of its new Blocks. Additionally, proofs of two theorems \nmust be packaged in the same dependent record. The PreconditionOk theorem asserts that the requested \nprecon\u00addition really has been assigned as the spec of the statement s entry block. The BlocksOk theorem \nasserts that every block in Blocks is correct according to the rules of XCAP. This latter statement uses \na predicate blockOk that can be thought of as a judgment G f B, asserting the correctness of basic block \nB under the assumptions in G, a .nite map from code labels to assumed preconditions for their associated \nblocks. Here we build G with a function imps, which constructs a .nite map containing (a) the Exit label \nwith spec Postcondition, (b) the macro s Blocks themselves with their associated specs, and (c) any label\u00adspec \npairs for other modules that are listed explicitly as imports. We also note that BlocksOk takes as premises \n(a) the truth of the veri.cation condition and (b) an assertion that the Exit label is less than the \nBase label, so that the macro knows it will not accidentally generate a block with the same address as \nthe exit block it should jump to. The new components of certi.ed macros are very similar to con\u00adventional \nlogical manipulations in program veri.cation tools and veri.ed compilers. The power of the idea comes \nfrom formalizing the requirements on statements with a precise, open interface. We have proved a Coq \ntheorem that any statement satisfying the cmd in\u00adterface is compiled into a valid XCAP module, when its \nveri.cation condition holds and it is started in a state satisfying the claimed pre\u00adcondition. This notion \nof module validity follows XCAP s modular veri.cation approach, so that it is possible to link such theorems \nto\u00adgether to produce theorems about larger composite modules, with\u00adout revisiting module internals. We \nclose out this section with more examples of combinators for conventional C-like control constructs, \nbefore turning in the fol\u00adlowing sections to local variables, calling conventions, and higher\u00adlevel notations \nnot commonly supported in C-like languages.  3.3 More Examples Certi.ed low-level macros are compatible \nwith classic Hoare-logic proof rules that require the programmer to provide invariants. For instance, \nconsider a macro for a while loop, with conditional test e, loop invariant I, and a body statement that \nhas predicate trans\u00adformer T and veri.cation condition generator C. The macro s log\u00adical outputs then \nmirror standard proof rules, where P again stands for the precondition passed into the macro. e Veri.cation \ncondition: C(.s. I (s) . s -. 1) . (.s. P (s) . I(s)) e . (.s. I (s) . .b. s -. b) e . (.s. T (.s ' \n. I (s ' ) . s ' -. 1)(s) . I(s)) e Postcondition: .s. I (s) . s -. 0 The respective veri.cation conditions \nare the conditions of the loop body, an implication from loop precondition to loop invariant, an implication \nfrom loop invariant to safety of conditional test, and an implication from loop body postcondition to \nloop invariant. The overall loop postcondition is the conjunction of the loop invariant with the failure \nof the conditional test. It is also possible to write macros for function calls, where the crucial challenge \nis to reason about the passing of a return pointer as .rst-class data. The macro must allocate a new \nblock whose address will be passed as return pointer. We follow the convention that a function receives \nits return pointer in Bedrock IL register Rp. The compilation part of a function-call macro may simply \nuse its own exit label as the return pointer. i Since there is no succinct logical counterpart to -. \nfor express\u00ading the effect of a whole function call, we ask the programmer to provide an invariant I, \ncharacterizing the machine state after the function call returns. To state the logical outputs of the \nfunction\u00adcall macro, we use the XCAP notation {P }p to indicate that ma\u00adchine word p is the address of \na basic block whose spec is implied by condition P . As is usual at the assembly level, our programs \nare effectively in continuation-passing style, so it is natural to reason about .rst-class return pointers \nwith Hoare doubles (preconditions only) rather than the more common Hoare triples (preconditions and \npostconditions). As usual, below let P stand for the precondition passed into the function-call macro. \nAdditionally, let Q be the spec of the function being called, which is in precondition-only form just \nas for return pointers. Veri.cation condition: Rp.p .s, p, s ' . P (s) . s -. s ' . {I}p . Q(s ' ) Postcondition: \nI The veri.cation condition is stated in terms of the assignment of an arbitrary code pointer p to the \nreturn pointer register Rp, subject to the constraint that invariant I is a valid spec for p s basic \nblock. The invariant I itself is used as the call s postcondition. A complete calling convention also \ndeals with function argu\u00adments and local variables. Further, the reader may be worried about the readability \nof complex specs in continuation-passing style with Hoare doubles. The next section addresses both concerns, \ndescrib\u00ading how we use more macros and other notational conventions to present a more normal perspective \non C-like functions. 4. Local Variables and Calling Conventions Figure 2 contained a speci.cation in \na conventional precondition\u00ad and-postcondition style, hiding the complexities of continuation\u00adpassing-style \nreasoning. As another example, here is Coq code for a spec we might write for an in-place linked list \nreversal function. The predicate sll stands for singly linked list, and its parameters are a functional \nlist and a pointer to the root of a matching linked list in memory. SPEC(\"l\") reserving 5 Al L, PRE[V] \nsll L ( V \"l\") POST[R] sll (rev L) R In order, the four lines of such a spec may be thought of as:  \n1. A header giving the function s formal arguments, plus how many free additional stack slots it requires \n(reserving clause)  2. Universal quanti.ers for speci.cation variables (similar to ghost variables) \nthat may be mentioned in both precondition and postcondition  3. A precondition, introducing a local \nname V for a function as\u00adsigning values to actual arguments  4. A postcondition, introducing a local \nname R for the function return value  A more compact notation, closer to usual Hoare logic conven\u00adtions \nbut with explicit use of functions to handle binding of V and R, might be: .L. {.V. sll(L, V (l))}f(l, \n5){.V, R. sll(rev(L), R)} A mechanical translation produces a continuation-passing style version of this \nspec, where we only need to assign a precondition. As is usual with this sort of translation, universal \nquanti.ers scoped over both precondition and postcondition turn into existential quan\u00adti.ers appearing \nwithin the precondition; and calling-convention registers appear explicitly, where Rp holds the return \npointer and Rv the function return value. {.L, V. sll(L, V (l)) . {sll(rev(L), Rv)}Rp}f(l, 5) In this \nspeci.cation, the call stack is still treated implicitly. We must eventually be explicit about call stack \nas data structure to bridge the semantic gap to the Bedrock IL. Here is the .nal version of the speci.cation, \nusing a predicate locals to represent a call stack frame. Register Sp holds the stack pointer. {.L, V. \nlocals({l}, V, 5, Sp) * sll(L, V (l)) . {.V ' . locals({l}, V ' , 5, Sp) * sll(rev(L), Rv)}Rp}f Here \nlocals is just another abstract predicate [27] like sll. A fact locals(D, V, n, v) says that a stack \nframe with domain D and variable values V is located at address v, and it has at least n more free stack \nslots remaining. The overall list-reverse spec above indicates that the stack frame must be present with \nsome variable values V at call time, and the separating conjunction * expresses that the call stack and \nthe input linked list must occupy disjoint memory. A nested Hoare double ascribes a precondition to the \nreturn pointer Rp. This postcondition is the same as the function precondition except that (1) local \nvariable values are allowed to change to some arbitrary V ' and (2) the linked list has been reversed. \n In general, a traditional function spec looks like .yx. {P }f(y , n){Q}, where P is a function over \nV , and Q is a function over V and R. The desugaring of this spec into a low-level XCAP precondition \nis: {.yx, V. locals(yy, V, n, Sp) * P (V ) . {.V ' . locals(yy, V ' , n, Sp) * Q(V, Rv)}Rp}f To do code \ngeneration and computation of veri.cation condi\u00adtions and postconditions, a macro now needs to know the \nlocal variable set yy and the reserved stack slot count n. Therefore, we add these two values as additional \nparameters to each macro. We do not update any of the logical components of macros; local variables are \ninstead handled in a more traditional macro expansion style, without any new hiding of implementation \nfrom interface. For in\u00adstance, a statement that reads a local variable will be compiled to refer directly \nto the concrete offset of that variable from the stack pointer, with veri.cation conditions that reveal \nthe compilation de\u00adtails directly. We have extended Bedrock s separation logic proof automation to reason \nproperly about the interaction of such stack pointer indirection and the locals predicate. 5. Higher-Level \nNotations Certi.ed low-level macros do not merely encode strongest post\u00adcondition calculators, to declare \nthe effects of statements. Instead, macro authors have the freedom to expose weaker postconditions, just \nas the author of a conventional function may choose a weaker postcondition to enforce data abstraction \nor another form of in\u00adformation hiding. Conventional Hoare logics have a rule of con\u00adsequence facilitating \nthis sort of hiding in a straightforward way, where one may conclude {P }c{Q} from {P ' }c{Q ' }, given \nP . P ' and Q ' . Q. We have implemented a simple wrapper combinator for macros, embodying the rule of \nconsequence. A programmer uses pre\u00adexisting macros to implement a chunk of code, taking advantage of \nthe associated proof automation to simplify veri.cation of that chunk. Then the chunk may be wrapped \nwith a new predicate trans\u00adformer and veri.cation condition generator, if appropriate condi\u00adtions are \nproved. In particular, say that the original statement has transformer T ' and generator C ' , and the \nwrapper is introducing new transformer T and generator C. The conditions that make the wrapping sound \nare: .P. C(P ) . C ' (P )  .P, s. C(P ) . T ' (P )(s) . T (P )(s)  These conditions are a direct reinterpretation \nof the rule of con\u00adsequence, and they are feasible to prove for a variety of higher\u00adlevel notations that \nconstruct the underlying statements program\u00admatically, via recursive functions over macro parameters. \nIn the rest of this section, we give a motivating example for two higher-level macros and then describe \ntheir implementations. 5.1 A Motivating Example Figure 7 shows an example program that uses higher-level \nmacros. The program is a simple idealization of a network server process\u00ading queries over a database. \nWe deal not with network IO, but rather just with decoding and processing requests and encoding the results \nin memory. We say that the database is an array of machine inte\u00adgers, as is the packet of encoded query \nrequests. The output of the server is stored in a linked list. The lefthand column of the .gure gives \nthe program implemen\u00adtation. Our program declares a module m, which imports function malloc from module \nmalloc, with speci.cation mallocS. Next, we de.ne function main, beginning with its list of local variables, \nincluding formal arguments. The main body of the function is a loop over all requests con\u00adtained in the \nrequest array cmd. We take advantage of two high-level macros to make our implementation more declarative. \nFirst, we use a parsing syntax similar to ML-style pattern matching, via the Match macro. Its arguments \nname an array, its length (Size clause), and a local variable storing our current index within the array \n(Position clause). A Match has a sequence of cases consisting of patterns and bodies. A pattern is a \nsequence of items that are either constants, to indicate that a speci.c machine word value must be found \nin the corresponding array position; or a variable name (string literal), to indicate that any machine \nword may appear in the position. All variables are assigned the appropri\u00adate values from the array before \nexecuting the body of a matching pattern. The other high-level macro is for declarative querying of arrays, \nchosen as a simple example illustrating many of the same chal\u00adlenges applicable to more expressive SQL-style \nquerying. The For macro takes as arguments a loop variable to store an array index, another variable \nto store the value found at that index (Holding clause), the array to query (in clause), the length of \nthat array (Size clause), and a .lter condition choosing which array cells to  Figure 7. Implementation, \nspeci.cation, and veri.cation of our main case study program (* Requests that the server may receive. \n(* Program implementation *) * (W is the type of machine words.) *) Definition m := bimport [[ \"malloc\"!\"malloc\" \n@ [mallocS] ]] Inductive req := bmodule \"m\" {{| ValueIsGe (index valueLowerBound : W) bfunction \"main\"(\"cmd\", \n\"cmdLen\", \"data\", \"dataLen\", (* Test if the value stored at this array index is \"output\", \"position\", \n\"posn\", \"lower\", \"upper\", * at least as large as this value. *) \"index\", \"value\", \"res\", \"node\") [mainS] \n\"output\" . 0;; | MaxInRange (lowerBound upperBound : W) \"position\" . 0;; (* Find the maximum value within \nthe given [ (* ... invariant omitted ... *)] * range of values. *) While (\"position\" < \"cmdLen\") { Match \n\"cmd\" Size \"cmdLen\" Position \"position\" { | CollectBelow (indexLowerBound valueUpperBound : W) (* ValueIsGe \n*) (* Collect a list of all values satisfying Case (0 ++ \"posn\" ++ \"lower\") * the given bounds on index \nand value. *). \"res\" . 0;; [(* ... invariant omitted ... *)] (* Representation of requests as lists of \nwords. *) For \"index\" Holding \"value\" in \"data\" Definition encode (r : req) : list W := Size \"dataLen\" \nmatch r with Where ((Index = \"posn\") &#38;&#38; (Value = \"lower\")) { | ValueIsGe a b . $0 :: a :: b :: \nnil \"res\" . 1 | MaxInRange a b . $1 :: a :: b :: nil };; | CollectBelow a b . $2 :: a :: b :: nil \"node\" \n. Call \"malloc\"!\"malloc\"(0) end. [(* ... invariant omitted ... *)];; \"node\" *. \"res\";; (* Representation \nof sequences of requests *) \"node\" + 4 *. \"output\";; Fixpoint encodeAll (rs : list req) : list W := \"output\" \n. \"node\" match rs with end;; | nil . nil | r :: rs . encode r ++ encodeAll rs (* MaxInRange *) end. \nCase (1 ++ \"lower\" ++ \"upper\") \"res\" . 0;; (* Omitted here: some helper functions *) [(* ... invariant \nomitted ... *)] For \"index\" Holding \"value\" in \"data\" (* Compute the proper response to a request, Size \n\"dataLen\" * as transformation on a list of output values. *) Where ((\"lower\" = Value) &#38;&#38; (Value \n= \"upper\") Definition response (data acc : list W) (r : req) : list W := &#38;&#38; (Value = \"res\")) \n{ match r with \"res\" . \"value\" | ValueIsGe index lower . };; valueIsGe data index lower :: acc \"node\" \n. Call \"malloc\"!\"malloc\"(0) | MaxInRange lower upper . [(* ... invariant omitted ... *)];; maxInRange \nlower upper data :: acc \"node\" *. \"res\";; | CollectBelow lower upper . \"node\" + 4 *. \"output\";; collectBelow \nupper (skipn (wordToNat lower) data) acc \"output\" . \"node\" end. end;; (* Proper response to a request \nsequence *) (* CollectBelow *) Definition responseAll (data : list W) (rs : list req) Case (2 ++ \"lower\" \n++ \"upper\") ( acc : list W) : list W := [(* ... invariant omitted ... *)] fold_left (response data) rs \nacc. For \"index\" Holding \"value\" in \"data\" Size \"dataLen\" (* Specification of the server main() function \n*) Where ((Index = \"lower\") Definition mainS := SPEC(\"cmd\", \"cmdLen\", \"data\", \"dataLen\") &#38;&#38; (Value \n= \"upper\")) { reserving 15 Al r, Al d, \"node\" . Call \"malloc\"!\"malloc\"(0) PRE[V] array (encodeAll r) \n(V \"cmd\") * array d (V \"data\") [ (* ... invariant omitted ... *)];; * mallocHeap \"node\" *. \"value\";; \n* I V \"cmdLen\" = length (encodeAll r) l \"node\" + 4 *. \"output\";; * I V \"dataLen\" = length d l \"output\" \n. \"node\" * I goodSize (length (encodeAll r) + 3) l }POST[R] array (encodeAll r) (V \"cmd\") * array d (V \n\"data\") end * mallocHeap * sll (responseAll d r nil) R. } Default {Fail (* Impossible: the match was \nexhaustive. *) (* Omitted: lemmas and tactics about lists *) } };; (* Correctness theorem *) Theorem \nok : moduleOk m. Return \"output\" Proof. end vcgen; abstract (parse0; for0; post; evaluate hints; }}. \nrepeat (parse1 finish; use_match); multi_ex; sep hints; finish). Qed.  visit in the loop (Where clause). \nThe key property of For is that it performs compile-time analysis of the Where condition to op\u00adtimize \nquery execution. If the Where condition implies a known value for the array index, the loop only visits \nthat cell. If the con\u00addition implies a lower bound on array indices, the loop skips the earlier indices. \nThe proof rule of the For macro hides the details of which optimizations are used, allowing veri.cation \nto proceed only in terms of high-level logical concepts. The righthand column of Figure 7 excerpts the \nspeci.cation and correctness proof for the program. The speci.cation follows the Bedrock style of using \npure functional programs as speci\u00ad.cations for low-level programs. In particular, we de.ne func\u00adtional \ndatatypes to represent requests to the server, and we write functional programs to map requests to their \nnetwork encod\u00adings and their appropriate responses. The three different kinds of queries are represented \nwith capitalized datatype constructors (e.g., ValueIsGe) and speci.ed with pure mathematical functions \nin lowercase (e.g., valueIsGe). The speci.cation mainS applies to our main function, giving its list \nof formal arguments, the arrays cmd and data plus their lengths. Two universal quanti.ers ( Al ) bind \nnames to the purely functional versions of cmd and data, respectively. The precondition (PRE) clause \nbinds a local function V that may be used to access the actual parameter values (e.g., V \"cmd\" as the \nvalue of cmd). The .rst three *-separated formulas here say, respec\u00adtively, that there are regions with \nan array pointed to by parameter cmd and storing an encoding of the queries, an array pointed to by parameter \ndata and storing an encoding of the database, and .nally the internal data structures of the malloc library. \nFurther subfor\u00admulas use the lifting operator I l, for lifting normal Coq proposi\u00adtions into separation \nlogic formulas. We require that cmdLen and dataLen store the lengths of the proper arrays, and we require \nthat adding 3 to the query array length does not over.ow a 32-bit word (which the goodSize predicate \nformalizes). A postcondition (POST) binds the local variable R to stand for the return value. Here we \nassert that the same two arrays remain in memory unchanged, the malloc library state is intact, and the \nreturn value is the root of a linked list. Finally, the program is proved to meet its spec with a short \nsequences of Coq tactics. Some of them, like vcgen and sep, come from the Bedrock library. Others, like \nparse0 and for0, come from the libraries providing the Match and For macros. In this way, macro authors \ncan also provide reusable procedures for discharging the sorts of veri.cation conditions that their macros \ngenerate, while leaving the programmer full .exibility to apply other proof techniques instead. Some \ndetails are omitted in the .gure. The main implemen\u00adtation includes 7 invariants, predicates over intermediate \nprogram states that guide veri.cation condition generation. Together these invariants take up 72 lines \nof code. We also omit 350 lines of lemma statements and proof script, setting up the key arguments behind \nthe program s correctness. Crucially, these lemmas are only about properties of lists, our functional \nmodels of arrays and imperative linked lists; we need do no manual proving work speci.c to pro\u00adgram syntax, \nprogram states, or memories. This program uses at least 7 different macros, at varying lev\u00adels of abstraction \nfrom statement sequencing to declarative query\u00ading, but the veri.cation is independent of macro implementation \ndetails. The level of proof automation used here also means that small changes to the program often require \nlittle manual adaptation of proofs. Nonetheless, in the end we get a foundational theorem, stated in \nterms of a simple assembly-level operational semantics and with a proof checked by the normal Coq proof \nchecker. Fur\u00adthermore, the example program runs only about 25% more slowly than a conventional C program \nfor the same task, as compared to an OCaml implementation we built at a similar level of abstraction, \nwhich runs in about 400% of the time of the C program. We return to performance details in Section 6. \n 5.2 Parsing Arrays of Machine Words Consider now the general interface of the parsing macro from Figure \n7. Its simplest form is as follows: Match array Size size Position pos { Case pattern bodyStmt end } \nDefault { defaultStmt } Here the challenge is giving the macro a strong enough interface without revealing \nits internal workings. We intentionally set out to hide the details of array access, but programmers \nshould still be able to prove reasonable correctness theorems about programs that use this macro. One \nconcrete challenge is which precondition we choose as the input to bodyStmt, a sub-statement that is \nrun when pattern-matching succeeds. We do not want to mention the exact sequence of instructions executed \nbetween the start of the Match and that point. If we did, the programmer would need to reason about memory \nsafety and semantics of a sequence of array accesses, on every invocation of the macro. The alternate \napproach that we take here is to construct a bodyStmt precondition in terms of a simpler instruction \nsequence, different from the one actually executed, but with the same effect. The instruction sequence \nis written in terms of the functional model of the array, a Coq list. For instance, the pattern 0 ++ \n\"posn\" ++ \"lower\" from Figure 7 matches an array span starting with constant 0 and followed by any two \nother values, such that those two values are bound to names posn and lower before running bodyStmt. Let \nL be a mathematical list asserted to describe the contents of the array. The semantics of the example \nmatch may now be expressed with, .rst, an assertion that L = a, b, c, . . . for fresh variables a, b, \nand c; and second, this instruction sequence: assume(a = 0); posn . b; lower . c We express exactly the \nintent of the pattern, without exposing any details of array access. Instruction sequences like the above \nare handled trivially by Bedrock s proof automation, without imposing memory safety proof obligations \non the programmer. It is easy to code a recursive Coq function to translate a pattern into such a sequence \nof instructions. The postcondition of the Match macro is just the disjunction of the postconditions for \nbodyStmt and defaultStmt, when they are passed preconditions constructed using the encoding technique \nabove. The veri.cation conditions include some administrative facts about variables: all program variables \nmentioned are declared as local variables, and the variables array and pos are not also used within patterns. \nThe veri.cation conditions of bodyStmt and defaultStmt are also inherited. Finally, one new veri.cation \ncondi\u00adtion asserts that the overall precondition for the Match implies that there exists an array at \nthe address speci.ed by array, where pos is a valid index into that array, and adding the length of the \npattern to pos does not over.ow a 32-bit word.  5.3 Declarative Querying of Arrays Figure 7 demonstrated \nthe For macro, which loops over exactly those cells of an array that satisfy a .lter condition. The macro \nimplementation analyzes the syntax of the condition to perform optimizations. Such a process is a simpli.ed \nversion of what goes on in an SQL query planner. The interface of the For macro should hide the details \nof the optimizations that are performed. Our complete implementation uses a form of loop invariant that \nis similar to the one introduced by Tuerk [31], where an invariant includes both a precondition and a \npostcondition to simplify appli\u00adcation of the separation logic frame rule. However, we will present here \na simpli.ed version with only a conventional loop invariant. There the general form of a For invocation \nis:  [ After pre.x PRE[V] invariant] For index Holding value in array Size len Where condition { bodyStmt \n} The condition may refer both to local variables and to the special variables Index and Value for the \ncurrent array index and cell value, respectively. Our current implementation performs two opti\u00admizations: \nWhen condition is a conjunction where one conjunct is Index = i, then the loop need only visit cell i. \nWhen condition is a conjunction where one conjunct is Index = i, then the loop may begin at i rather \nthan 0. The optimizer correctly handles cases where i is a local variable. As in the previous subsection, \nhere we have the challenge of assigning For a speci.cation that does not reveal too much about its inner \nworkings. Ideally, programmers who use For will only be faced with proof obligations about mathematical \nlists, not arrays or the details of compiling complex Boolean tests. This time, we use the conventional \nidea of a loop invariant, but modi.ed to expose a list-level view of the action. The schematic For invocation \nabove includes a loop invariant, where an After clause introduces a local name pre.x for the list of \narray cell values that have already been visited. In the course of a naive complete loop through the \narray, pre.x progresses from the empty list to the full value list. However, optimizations may lead to \nsome loop iterations being skipped, though such details should be hidden in the interface of For. We \nare now ready to sketch what that interface is. The postcon\u00addition is simply that there exists an array \nin memory pointed to by array, such that the loop invariant holds for the full array contents. Veri.cation \nconditions include both administrative requirements on variable names and the inherited veri.cation condition \nof bodyStmt. The more interesting conditions are: 1. The loop invariant is independent of the values \nof index and value, which will often be changed without calling the loop body to fast forward past indices \nthat the optimizer determines cannot match the .lter condition. (Note that the invariant may still depend \non the functional list of array cells already visited, just not on the values of local variables used \nincidentally to track progress in visiting cells.) 2. The precondition implies the loop invariant. \n3. When the loop invariant holds for an array value pre.x L, and when the .lter condition will reject \nthe next value if it equals v, then the loop invariant also holds for pre.x L, v. This condition is crucial \nto justify the soundness of fast forwarding. 4. The postcondition of bodyStmt implies the loop invariant, \nwhere bodyStmt is passed a suitably high-level precondition expressed in terms of mathematical lists \nand the loop invariant.  6. Evaluation Together, the core macro system de.nitions and all of the macros \nwe have built on top of them take up about 4000 lines of Coq code within the Bedrock library. We have \nbuilt a few tactics to lower the cost of macro imple\u00admentation, but our primary interest has been in \nthe effort required to implement and verify individual programs, like the example of Figure 7. An important \npart of evaluation is the run-time perfor\u00ad mance of programs, since we motivated certi.ed low-level macros \nwith the possibility to combine the high performance of low-level languages with the abstractions of \nhigh-level languages. To gather Figure 8. Running time (in seconds) of the four different imple\u00admentations \nof the server example, running the same randomly gen\u00aderated workload of 200 queries on an array of 100,000 \nelements some rough evidence that our implementation succeeds in this re\u00adspect, we ran an experiment \nwith four different implementations of the same server example1: 1. A conventional C program (50 lines) \nnot taking advantage of metaprogramming. This is our baseline of high performance. 2. A .rst-order (later \nabbreviated 1O) OCaml program (36 lines), with no variant types (beyond linked lists) or .rst-class func\u00adtions. \nThis is our baseline of the cost of switching to a popular high-level language. 3. A higher-order (later \nabbreviated HO) OCaml program (106 lines, including reusable library code), taking advantage of id\u00adioms \nlike parser combinators and embedded interpreters for ASTs. This version illustrates the cost of employing \nnice ab\u00adstractions that can be type checked in isolation, which is not the case for abstractions embodied \nas Camlp4 macros. 4. The Bedrock implementation from Figure 7 (50 lines, compiled to 561 lines of assembly \nwith the Bedrock malloc library linked in), which is the only one of the implementations that we veri.ed \nas correct.  Figure 8 shows the results of running all four compiled pro\u00ad grams on a particular random \nworkload chosen to be large enough for performance differences to show. These experiments were run on \na 2.4 GHz Intel Xeon processor with 12 GB of RAM, using GCC 4.4.5 and OCaml 3.12.1. They show the .rst-order \nOCaml program running in roughly 300% of the time of the C program, with the higher-order OCaml program \nrunning in roughly 500% of the C program s time. In contrast, the Bedrock program runs in about 125% \nof the time of the C program. We replicated the experi\u00adment on a 4.2 GHz AMD FX processor with 16 GB \nof RAM, where the performance difference between C and Bedrock was within the granularity of measurement, \nand the .rst-and higher-order OCaml programs ran respectively in about 300% and 350% of the time for \nthe C and Bedrock programs. It is worth pointing out that Bedrock is the only language implementation \nused here that does not yet have an optimizer, whereas we used the default optimization op\u00adtions of each \nother compiler, gcc and the ocamlopt native-code OCaml compiler. We experimented with verifying programs \nfor several months before generating any executable assembly code. The .rst program we actually executed \nwas iterative factorial, and the second was the server program in Figure 7. Both worked correctly on \nthe .rst try, providing at least some small testament to the debugging power of our veri.cation environment. \nWe have veri.ed a few other substantial case studies, as detailed in Figure 9, breaking down their lines \nof code into relevant cate\u00ad gories. The case studies include some classic functions over imper\u00ad 1 In \ndirectory examples/comparison of the Bedrock distribution  File Program Invar. Tactics Other Overh. \nServer 50 79 167 239 9.7 LinkedList 42 26 27 31 2.0 Malloc 43 16 112 94 5.2 ListSet 50 31 23 46 2.0 TreeSet \n108 40 25 45 1.0 Queue 53 22 80 93 3.7 Memoize 26 13 56 50 4.6 Figure 9. Case study veri.cations, with \ndata on annotation burden, in lines of code ative linked lists, the malloc library, implementations of \na single .nite set abstract data type interface with both unsorted lists and binary search trees, an \nimplementation of the bag abstract data type using a queue, and an implementation of an abstract data \ntype of memoized functions, where a closure stored in memory contains both a function pointer and an \nassociated 1-element memo table. All case studies are built up from certi.ed low-level macros, where \nour running example Server uses the most advanced macros. In Figure 9, the program column counts lines \nof executable code; invar. refers to function specs, loop invariants, and post\u00adfunction call invariants; \ntactics refers to literal proofs of theorems as well as reusable tactic functions and hints; and other \ncollects the remaining lines, which are mostly helper function de.nitions and lemma statements. We omit \nlines of code that are duplicated between Coq modules and their interfaces. The .nal column of Figure \n9 gives the veri.cation overhead, or ratio of veri.cation code to executable code. The more basic examples \nrange from overheads of 1.0 to 5.2, which compare rea\u00adsonably well to common ratios in Coq developments, \nsuch as the overhead of about 7 in the original CompCert paper [21]. The over\u00ad head is slightly below \n10 for our server example, which involves a fair amount of program-speci.c correctness reasoning. We \nshould also point out that the code size statistics from the original Bedrock paper [8] can also be taken \nas evidence for the effectiveness of the macro system presented in this paper, which is a moderate evolution \nof the macro system used previously and never presented in detail before. The main weakness of our present \nimplementation is the run\u00adning time of automated proof search and proof checking. On the machines used \nin the experiments, the server example runs for about an hour .nding and checking proofs. The other case \nstud\u00adies take less time, but still have running times measured in min\u00adutes, at best. We do not view this \nas a huge obstacle from a scien\u00adti.c perspective, as much opportunity remains to take advantage of parallelism. \nThe Server example generates about 100 independent veri.cation conditions, each of which could be discharged \non a dif\u00adferent processor core, dropping the total veri.cation time for the example to a few minutes. \nWe need only wait for Coq to support forking processes to handle disjoint subgoals of a single proof. \n7. Related Work The original Bedrock paper [8] used a simpler macro system but did not report on its \ndetails. Compared to that macro system, our new one from this paper is distinguished by including a calling \nconvention supporting named local variables, as well as the im\u00adplementation and veri.cation of high-level \nmacros like our parsing and querying examples. Benton et al. [2] report on a system for formal veri.cation \nof assembly programs in Coq using higher-order separation logic. Based on an intermediate language with \nscoped local labels, they de.ne a few macros of moderate complexity, like while loop and function call \n(the latter handling only storing the return pointer to a register, not stack frame management). Proofs \nare largely manual with interspersed use of automation tactics, leading to about 10 lines of proof per \nline of assembly code, as opposed to an about even ratio between the two in our most complicated macro-based \nexample. Their work explores an interesting alternate separation logic featuring a novel higher-order \nframe rule. We expect that an approach like ours in this paper could be adapted to the formalism of Benton \net al. and many others, as our respective projects deal mostly with orthogonal concerns. Work by Myreen \net al. [24, 25] has demonstrated another mech\u00ad anized separation logic suitable for reasoning about realistic \nas\u00adsembly languages. The FLINT project has produced XCAP [26], the assembly-level program logic we adopt \nin this work, as well as several other logics targeting interesting aspects of assembly pro\u00adgram behavior \n[5, 10 12, 23]. Other related work with mechanized separation logic has gone on at the level of C programs, \nas in Ap\u00adpel et al. s Veri.ed Software Toolchain [1]. Mechanized proofs in these logics have been long \nand manual, and previously no macro system had been demonstrated for them at the level of this paper \ns most sophisticated examples. The L4.veri.ed kernel veri.cation project [20] employs a tool [15] for \nveri.ed translation of C code into functional pro\u00ad grams in higher-order logic, applying optimizations \nthat choose simpler types for functions that use fewer varieties of side effect. In a sense, their tool \nreverses the action of the Bedrock macro system, providing similar foundational guarantees for the .xed \nC language. In contrast, our work makes it possible for programmers to add their own new language constructs, \nincluding higher-level macros like our declarative array querying that are unlikely to be reconstructible \nautomatically from C code. Macros have been most studied in the context of Lisp and Scheme. Notable in \nthat area is work by Herman and Wand [17], which shows how to assign macros interfaces suf.cient to guar\u00adantee \nhygiene, or lack of undesirable variable capture, without the need to expand macro de.nitions to check \nprogram validity. Our work also assigns interfaces to macros, for low-level rather than high-level code, \nand facilitating formal veri.cation of functional correctness rather than just proper use of binding \nconstructs. In the functional programming world, the use of embedded domain-speci.c languages is already \nquite popular, for supporting safe code generation to low-level languages via high-level func\u00adtional \nprograms. For instance, the Harpy Haskell library [14] sup\u00ad ports generation of x86 assembly code. Recent \ntools like Meta-Haskell [22] allow generation of programs in low-level languages like C, CUDA, and assembly, \nwhere Haskell-level type checking guarantees that code generators will never output type-incorrect programs. \nOur work in this paper can be viewed as starting from the same foundation of type-safe metaprogramming \nand expanding it to support veri.cation of functional correctness. Extensible C variants like xtc [16] \nand xoc [9] allow the pro\u00ad grammer to specify new statement forms and static checking dis\u00adciplines. These \nsystems can provide much nicer syntax than what we have available within Coq, and there is room for such \nfeatures to migrate to proof assistants. The key disadvantage of existing ex\u00adtensible compilers is that \nthey provide no foundational guarantees; custom static analysis disciplines do not have clear semantics, \nso these languages are not compatible with foundational veri.cation of functional correctness. Safe systems \nlanguages include low-level languages like Cy\u00adclone [19] and various higher-level languages with features \ntargeted at systems programming. Some are known for their use in particu\u00adlar operating systems projects, \nsuch as Modula-3 in SPIN [4] and Sing# in Singularity [18]. None of these languages are extensible, and \nnone give foundational safety or functional correctness guar\u00adantees.  Tools like Smallfoot [3] and Space \nInvader [6, 32] apply sep\u00ad aration logic to check memory safety of low-level programs auto\u00admatically. \nOther systems, including TVLA [29] and XISA [7], can verify memory safety or even functional correctness \nusing other formalisms for data structure invariants. These tools apply to .xed programming languages \nwith no modular macro systems. 8. Conclusion We have presented certi.ed low-level macros, a technique \nsup\u00adporting metaprogramming for low-level software, where programs may be veri.ed formally without looking \ninside the de.nitions of macros. Rather, macros export formal interfaces that include pred\u00adicate transformers \nand veri.cation condition generators. We have demonstrated how to build up a C-like language stack, starting \nfrom a simple intermediate language and culminating in high-level no\u00adtation for tasks like parsing and \ndeclarative querying that are usu\u00adally supported via ad-hoc external tools. Concrete programs have mostly \nautomated Coq proofs, generating foundational results with statements independent of our macro system; \nand the performance of our compiled programs is competitive with C programs. One direction for future \nresearch is optimization of the pro\u00adgrams that result from macro expansion. As these programs are in \na form more like conventional assembly language than conventional compiler intermediate languages, it \nis not obvious how to do sound optimization. We plan to investigate how we might take advantage of the \nveri.ed preconditions associated with all basic blocks, to re\u00adcover semantic information and perhaps \nallow optimizations that are too dif.cult to implement with traditional data.ow analysis. Acknowledgments \nThe author would like to thank Gregory Malecha and Thomas Braibant, for work on Bedrock proof automation \nthat is used in the case studies from this paper; as well as Thomas Braibant, Ryan Kavanagh, Antonis \nStampoulis, and Peng Wang, for their feedback on drafts of this paper. This material is based on research \nsponsored by DARPA un\u00adder agreement number FA8750-12-2-0293. The U.S. Government is authorized to reproduce \nand distribute reprints for Governmen\u00adtal purposes notwithstanding any copyright notation thereon. The \nviews and conclusions contained herein are those of the authors and should not be interpreted as necessarily \nrepresenting the of.cial policies or endorsements, either expressed or implied, of DARPA or the U.S. \nGovernment. References [1] A. W. Appel. Veri.ed software toolchain. In Proc. ESOP, volume 6602 of LNCS, \npages 1 17. Springer-Verlag, 2011. [2] N. Benton, J. B. Jensen, and A. Kennedy. High-level separation \nlogic for low-level code. In Proc. POPL, pages 301 314. ACM, 2013. [3] J. Berdine, C. Calcagno, and P. \nW. O Hearn. Smallfoot: Modular automatic assertion checking with separation logic. In Proc. FMCO, volume \n4111 of LNCS, pages 115 137. Springer-Verlag, 2005. [4] B. N. Bershad, S. Savage, P. Pardyak, E. G. Sirer, \nM. E. Fiuczynski, D. Becker, C. Chambers, and S. Eggers. Extensibility, safety and performance in the \nSPIN operating system. In Proc. SOSP, pages 267 283. ACM, 1995. [5] H. Cai, Z. Shao, and A. Vaynberg. \nCerti.ed self-modifying code. In Proc. PLDI, pages 66 77. ACM, 2007. [6] C. Calcagno, D. Distefano, P. \nO Hearn, and H. Yang. Compositional shape analysis by means of bi-abduction. In Proc. POPL, pages 289 \n300. ACM, 2009. [7] B.-Y. E. Chang and X. Rival. Relational inductive shape analysis. In Proc. POPL, \npages 247 260. ACM, 2008. [8] A. Chlipala. Mostly-automated veri.cation of low-level programs in computational \nseparation logic. In Proc. PLDI, pages 234 245. ACM, 2011. [9] R. Cox, T. Bergan, A. T. Clements, F. \nKaashoek, and E. Kohler. Xoc, an extension-oriented compiler for systems programming. In Proc. ASPLOS, \npages 244 254. ACM, 2008. [10] X. Feng and Z. Shao. Modular veri.cation of concurrent assembly code with \ndynamic thread creation and termination. In Proc. ICFP, pages 254 267. ACM, 2005. [11] X. Feng, Z. Shao, \nA. Vaynberg, S. Xiang, and Z. Ni. Modular veri.ca\u00adtion of assembly code with stack-based control abstractions. \nIn Proc. PLDI, pages 401 414. ACM, 2006. [12] X. Feng, Z. Shao, Y. Dong, and Y. Guo. Certifying low-level \nprograms with hardware interrupts and preemptive threads. In Proc. PLDI, pages 170 182. ACM, 2008. [13] \nS. E. Ganz, A. Sabry, and W. Taha. Macros as multi-stage compu\u00adtations: type-safe, generative, binding \nmacros in MacroML. In Proc. ICFP, pages 74 85. ACM, 2001. [14] M. Grabm \u00a8uller and D. Kleeblatt. Harpy: \nRun-time code generation in Haskell. In Proc. Haskell Workshop, page 94. ACM, 2007. [15] D. Greenaway, \nJ. Andronick, and G. Klein. Bridging the gap: Auto\u00admatic veri.ed abstraction of C. In Proc. ITP, volume \n7406 of LNCS, pages 99 115. Springer-Verlag, 2012. [16] R. Grimm. Better extensibility through modular \nsyntax. In Proc. PLDI, pages 38 51. ACM, 2006. [17] D. Herman and M. Wand. A theory of hygienic macros. \nIn Proc. ESOP, volume 4960 of LNCS, pages 48 62. Springer-Verlag, 2008. [18] G. C. Hunt and J. R. Larus. \nSingularity: Rethinking the software stack. ACM SIGOPS Operating Systems Review, 41(2):37 49, 2007. [19] \nT. Jim, J. G. Morrisett, D. Grossman, M. W. Hicks, J. Cheney, and Y. Wang. Cyclone: A safe dialect of \nC. In Proc. USENIX ATC, pages 275 288. USENIX Association, 2002. [20] G. Klein, K. Elphinstone, G. Heiser, \nJ. Andronick, D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt, R. Kolanski, M. Norrish, T. Sewell, H. \nTuch, and S. Winwood. seL4: Formal veri.cation of an OS kernel. In Proc. SOSP, pages 207 220. ACM, 2009. \n[21] X. Leroy. Formal certi.cation of a compiler back-end or: program\u00adming a compiler with a proof assistant. \nIn Proc. POPL, pages 42 54. ACM, 2006. [22] G. Mainland. Explicitly heterogeneous metaprogramming with \nMeta-Haskell. In Proc. ICFP, pages 311 322. ACM, 2012. [23] A. McCreight, Z. Shao, C. Lin, and L. Li. \nA general framework for certifying garbage collectors and their mutators. In Proc. PLDI, pages 468 479. \nACM, 2007. [24] M. O. Myreen. Veri.ed just-in-time compiler on x86. In Proc. POPL, pages 107 118. ACM, \n2010. [25] M. O. Myreen and M. J. C. Gordon. Hoare logic for realistically modelled machine code. In \nProc. TACAS, volume 4424 of LNCS, pages 568 582. Springer-Verlag, 2007. [26] Z. Ni and Z. Shao. Certi.ed \nassembly programming with embedded code pointers. In Proc. POPL, pages 320 333. ACM, 2006. [27] M. Parkinson \nand G. Bierman. Separation logic and abstraction. In Proc. POPL, pages 247 258. ACM, 2005. [28] J. C. \nReynolds. Separation logic: A logic for shared mutable data structures. In Proc. LICS, pages 55 74. IEEE \nComputer Society, 2002. [29] M. Sagiv, T. Reps, and R. Wilhelm. Parametric shape analysis via 3-valued \nlogic. TOPLAS, 24(3):217 298, May 2002. [30] W. Taha and T. Sheard. Multi-stage programming with explicit \nanno\u00adtations. In Proc. PEPM, pages 203 217. ACM, 1997. [31] T. Tuerk. Local reasoning about while-loops. \nIn Proc. VSTTE Theory Workshop, 2010. [32] H. Yang, O. Lee, J. Berdine, C. Calcagno, B. Cook, D. Distefano, \nand P. O Hearn. Scalable shape analysis for systems code. In Proc. CAV, volume 5123 of LNCS, pages 385 \n398. Springer-Verlag, 2008.   \n\t\t\t", "proc_id": "2500365", "abstract": "<p>We report on the design and implementation of an extensible programming language and its intrinsic support for formal verification. Our language is targeted at low-level programming of infrastructure like operating systems and runtime systems. It is based on a cross-platform core combining characteristics of assembly languages and compiler intermediate languages. From this foundation, we take literally the saying that C is a \"macro assembly language\": we introduce an expressive notion of certified low-level macros, sufficient to build up the usual features of C and beyond as macros with no special support in the core. Furthermore, our macros have integrated support for strongest postcondition calculation and verification condition generation, so that we can provide a high-productivity formal verification environment within Coq for programs composed from any combination of macros. Our macro interface is expressive enough to support features that low-level programs usually only access through external tools with no formal guarantees, such as declarative parsing or SQL-inspired querying. The abstraction level of these macros only imposes a compile-time cost, via the execution of functional Coq programs that compute programs in our intermediate language; but the run-time cost is not substantially greater than for more conventional C code. We describe our experiences constructing a full C-like language stack using macros, with some experiments on the verifiability and performance of individual programs running on that stack.</p>", "authors": [{"name": "Adam Chlipala", "author_profile_id": "81100341086", "affiliation": "MIT CSAIL, Cambridge, MA, USA", "person_id": "P4261288", "email_address": "adamc@csail.mit.edu", "orcid_id": ""}], "doi_number": "10.1145/2500365.2500592", "year": "2013", "article_id": "2500592", "conference": "ICFP", "title": "The bedrock structured programming system: combining generative metaprogramming and hoare logic in an extensible program verifier", "url": "http://dl.acm.org/citation.cfm?id=2500592"}