{"article_publication_date": "09-25-2013", "fulltext": "\n Complete and Easy Bidirectional Typechecking for Higher-Rank Polymorphism Joshua Dun.eld Neelakantan \nR. Krishnaswami Max Planck Institute for Software Systems Kaiserslautern and Saarbr\u00fccken, Germany {jos \nu h a,neelk}@mpi-sws.org Abstract Bidirectional typechecking, in which terms either synthesize a type \nor are checked against a known type, has become popular for its scalability (unlike Damas-Milner type \ninference, bidirectional typ\u00ading remains decidable even for very expressive type systems), its error \nreporting, and its relative ease of implementation. Following design principles from proof theory, bidirectional \ntyping can be ap\u00adplied to many type constructs. The principles underlying a bidirec\u00adtional approach to \npolymorphism, however, are less obvious. We give a declarative, bidirectional account of higher-rank \npolymor\u00adphism, grounded in proof theory; this calculus enjoys many proper\u00adties such as .-reduction and \npredictability of annotations. We give an algorithm for implementing the declarative system; our algo\u00adrithm \nis remarkably simple and well-behaved, despite being both sound and complete. Categories and Subject \nDescriptors D.3.3 [Programming Languages]: Language Constructs and Features polymorphism Keywords bidirectional \ntypechecking, higher-rank polymorphism 1. Introduction Bidirectional typechecking (Pierce and Turner \n2000) has become one of the most popular techniques for implementing typecheck\u00aders in new languages. \nThis technique has been used for depen\u00addent types (Coquand 1996; Abel et al. 2008; L\u00f6h et al. 2008; As\u00adperti \net al. 2012); subtyping (Pierce and Turner 2000); intersec\u00adtion, union, indexed and re.nement types (Xi \n1998; Davies and Pfenning 2000; Dun.eld and Pfenning 2004); termination check\u00ading (Abel 2004); higher-rank \npolymorphism (Peyton Jones et al. 2007; Dun.eld 2009); re.nement types for LF (Lovas 2010); con\u00adtextual \nmodal types (Pientka 2008); compiler intermediate repre\u00adsentations (Chlipala et al. 2005); and object-oriented \nlanguages in\u00adcluding C. (Bierman et al. 2007) and Scala (Odersky et al. 2001). As can be seen, it scales \nwell to advanced type systems; moreover, it is easy to implement, and yields relatively high-quality \nerror mes\u00adsages (Peyton Jones et al. 2007). Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. Copyrights for components of this work owned by others than the author(s) must be honored. \nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. Request permissions from permissions@acm.org. \nICFP 13, September 25 27, 2013, Boston, MA, USA. Copyright is held by the owner/author(s). Publication \nrights licensed to ACM. ACM 978-1-4503-2326-0/13/09. . . $15.00. http://dx.doi.org/10.1145/2500365.2500582 \n However, the theoretical foundation of bidirectional typecheck\u00ading has lagged behind its application. \nAs shown by Watkins et al. (2004), bidirectional typechecking can be understood in terms of the normalization \nof intuitionistic type theory, in which normal forms correspond to the checking mode of bidirectional \ntypecheck\u00ading, and neutral (or atomic) terms correspond to the synthesis mode. This enables a proof of \nthe elegant property that type anno\u00adtations are only necessary at reducible expressions, and that normal \nforms need no annotations at all. The bene.t of the proof-theoretic view is that it gives a simple and \neasy-to-understand declarative ac\u00adcount of where type annotations are necessary, without reference to \nthe details of the typechecking algorithm. While the proof-theoretic account of bidirectional typecheck\u00ading \nhas been scaled up as far as type re.nements and intersection and union types (Pfenning 2008), as yet \nthere has been no com\u00adpletely satisfactory account of how to extend the proof-theoretic approach to handle \npolymorphism. This is especially vexing, since the ability of bidirectional algorithms to gracefully \naccommodate polymorphism (even higher-rank polymorphism) has been one of their chief attractions. In \nthis paper, we extend the proof-theoretic account of bidirec\u00adtional typechecking to full higher-rank \npolymorphism (i.e., pred\u00adicative System F), and consequently show that bidirectional type\u00adchecking is \nnot merely sound with respect to the declarative seman\u00adtics, butalso thatitis complete. Better still, \nthe algorithm we give for doing so is extraordinarily simple. First, as a speci.cation of type checking, \nwe give a declara\u00adtive bidirectional type system which guesses all quanti.er instanti\u00adations. This calculus \nis a small but signi.cant contribution of this paper, since it possesses desirable properties, such as \nthe preserva\u00adtion of typability under .-reduction, that are missing from the type assignment version \nof System F. Furthermore, we can use the bidi\u00adrectional character of our declarative calculus to show \na number of refactoring theorems, enabling us to precisely characterize what sorts of substitutions (and \nreverse substitutions) preserve typability, where type annotations are needed, and when programmers may \nsafely delete type annotations. Then, we give a bidirectional algorithm that always .nds corre\u00adsponding \ninstantiations. As a consequence of completeness, we can show that our algorithm never needs explicit \ntype applications, and that type annotations are only required for polymorphic, reducible expressions \nwhich, in practice, means that only let-bindings of functions at polymorphic type need type annotations; \nno other ex\u00adpressions need annotations. Our algorithm is both simple to understand and simple to im\u00adplement. \nThe key data structure is an ordered context containing all bindings, including type variables, term \nvariables, and existential variables denoting partial type information. By maintaining order, we are \nable to easily manage scope information, which is particu\u00ad  Terms e ::= x | () | .x. e | ee | (e : A) \nFigure 1. Source expressions Types A, B, C ::= 1 | a | .a. A | A . B Monotypes t, s ::= 1 | a | t . s \nContexts . ::= \u00b7 | ., a | ., x : A Figure 2. Syntax of declarative types and contexts larly important \nin higher-rank systems, where different quanti.ers may be instantiated with different sets of free variables. \nFurther\u00admore, ordered contexts admit a notion of extension or informa\u00adtion increase, which organizes \nand simpli.es the soundness and completeness proofs of the algorithmic system with respect to the declarative \none. Contributions. We make the following contributions: We give a declarative, bidirectional account \nof higher-rank polymorphism, grounded strongly in proof theory. This cal\u00adculus has important properties \n(such as .-reduction) that the type assignment variant of System F lacks, yet is sound and complete (up \nto \u00df.-equivalence) with respect to System F. As a result, we can explain where type annotations are \nneeded, where they may be deleted, and why important code transfor\u00admations are sound, all without reference \nto the implementation.  We give a very simple algorithm for implementing the declar\u00adative system. Our \nalgorithm does not need any data structure more sophisticated than a list, but can still solve all of \nthe prob\u00adlems which arise in typechecking higher-rank polymorphism without any need for search or backtracking. \n We prove that our algorithm is both sound and complete with respect to our declarative speci.cation \nof typing. This proof is cleanly structured around context extension, a relational notion of information \nincrease, corresponding to the intuition that our algorithm progressively resolves type constraints. \n As a result of completeness, programmers may safely pay no attention to the implementor behind the \ncurtain , and ignore all the algorithmic details of uni.cation and type inference: the algorithm does \nexactly what the declarative speci.cation says, no more and no less. Lemmas and proofs. Proofs of the \nmain results, as well as state\u00adments of all lemmas (and their proofs), can be found in the ap\u00adpendix, \navailable from www.cs.cmu.edu/~joshuad/bidir/.  2. Declarative Type System In order to show that our \nalgorithm is sound and complete, we need to give a declarative type system to serve as the speci.cation \nfor our algorithm. Surprisingly, it turns out that .nding the correct declarative system to use as a \nspeci.cation is itself an interesting problem! Much work on type inference for higher-rank polymorphism \ntakes the type assignment variant of System F as a speci.cation of type inference. Unfortunately, under \nthese rules typing is not stable under .-reductions. For example, suppose f is a variable of type 1 . \n.a. a. Then the term .x. f x can be ascribed the type 1 . 1, since the polymorphic quanti.er can be instantiated \nto 1 between the f and the x.But the .-reduct f cannot be ascribed the type 1 . 1, because the quanti.er \ncannot be instantiated until after f has been applied. This is especially unfortunate in pure languages \nlike Haskell, where the . law is a valid program equality. Therefore, we do not use the type assignment \nversion of System F as our declarative speci.cation of type checking and inference. . f A Under context \n., type A is well-formed a . . . f a DeclUvarWF . f 1 DeclUnitWF . f A . f B ., a f A . f A . B DeclArrowWF \n. f.a. A DeclForallWF . f A = B Under context ., type A is a subtype of B a . . =Var =Unit . f a = a \n. f 1 = 1 . f B1 = A1 . f A2 = B2 =. . f A1 . A2 = B1 . B2 . f t . f [t/a]A = B ., \u00df f A = B =.L =.R \n. f.a. A = B . f A =.\u00df. B Figure 3. Well-formedness of types and subtyping in the declara\u00adtive system \nInstead, we give a declarative, bidirectional system as the speci.\u00adcation. Traditionally, bidirectional \nsystems are given in terms of a checking judgment . f e . A, which takes a type A as input and ensures \nthat the term e checks against that type, and a synthesis judgment . f e . A, which takes a term e and \nproduces a type A. This two-judgment formulation is satisfactory for simple types, but breaks down in \nthe presence of polymorphism. The essential problem is as follows: the standard bidirectional rule for \nchecking applications e1 e2 in non-polymorphic systems is to synthesize type A . B for e1, and then check \ne2 against A, returning B as the type. With polymorphism, however, we may have an application e1 e2 in \nwhich e1 synthesizes a term of polymorphic type (e.g., .a. a . a). Furthermore, we do not know apriori \nhow many quanti.ers we need to instantiate. To solve this problem, we turn to focalization (Andreoli \n1992), the proof-theoretic foundation of bidirectional typechecking. In fo\u00adcused sequent calculi, it \nis natural to give terms in spine form (Cervesato and Pfenning 2003; Simmons 2012), sequences of ap\u00adplications \nto a head. So we view every application as really being a spine consisting of a series of type applications \nfollowed by a term application, and introduce an application judgment . f A e . C, which says that if \na term of type A is applied to argument e,the result has type C. Consequently, quanti.ers will be instantiated \nex\u00adactly when needed to reveal a function type. The application judgment lets us suppress explicit type \napplica\u00adtions, but to get the . law, we need more. Recall the example with f : 1 . .a. a.In .-reducing \n.x. f x to f, we reduce the number of applications in the term. That is, we no longer have a syntac\u00adtic \nposition at which we can (implicitly) instantiate polymorphic quanti.ers. To handle this, we follow Odersky \nand L\u00e4ufer (1996) in modeling type instantiation using subtyping, where subtyping is de.ned as a more-polymorphic-than \nrelation that guesses type in\u00adstantiations arbitrarily deeply within types. As a result, 1 . .a. a is \na subtype of 1 . 1, and the . law holds. Happily, subtyping does .t naturally into bidirectional sys\u00adtems \n(Davies and Pfenning 2000; Dun.eld 2007; Lovas 2010), so we can give a declarative, bidirectional type \nsystem that guesses type instantiations, but is otherwise entirely syntax-directed. In particular, subsumption \nis con.ned to a single rule (which switches from checking to synthesis), and our use of an application \njudgment determines when to instantiate quanti.ers. The resulting system is very well-behaved, and ensures \nthat the expected typability results (such as typability being preserved by .-reductions) continue to \nhold. Furthermore, our declarative formulation makes it clear that  . f e . A . f e . A . f A e . C \n Under context ., e checks against input type A Under context ., e synthesizes output type A Under context \n., applying a function of type A to e synthesizes type C (x : A). . . f e . A . f A = B . f A . f e . \nA DeclVar DeclSub DeclAnno . f x . A . f e . B . f (e : A). A ., a f e . A . f t . f [t/a]A e . C Decl1I \nDecl1I. Decl.I Decl.App . f () . 1 . f () . 1 . f e . .a. A . f.a. A e . C ., x : A f e . B . f s . \nt ., x : s f e . t . f e1 . A . f A e2 . C Decl.I Decl.I. Decl.E . f .x. e . A . B . f .x. e . s . \nt . f e1 e2 . C . f e . A Decl.App . f A . C e . C Figure 4. Declarative typing the fundamental algorithmic \nproblem in extending bidirectional typechecking to polymorphism is precisely the problem of .guring out \nwhat the missing type applications are. Preserving the .-rule for functions comes at a cost. The sub\u00adtyping \nrelation induced by instantiation is undecidable for im\u00ad predicative polymorphism (Tiuryn and Urzyczyn \n1996; Chrz .aszcz 1998). Since we want a complete typechecking algorithm, we con\u00adsequently restrict our \nsystem to predicative polymorphism, where polymorphic quanti.ers can be instantiated only with monomor\u00adphic \ntypes. We discuss alternatives in Section 9. 2.1 Typing in Detail Language overview. In Figure 1, we \ngive the grammar for our language. We have a unit term (), variables x, lambda-abstraction .x. e, application \ne1 e2, and type annotation (e : A). We write A, B, C for types (Figure 2): types are the unit type 1, \ntype variables a, universal quanti.cation .a. A, and functions A . B. Monotypes t and s are the same, \nless the universal quanti.er. Contexts . are lists of type variable declarations, and term variables \nx : A, with the expected well-formedness condition. (We give a single\u00adcontext formulation mixing type \nand term hypotheses to simplify the presentation.) Checking, synthesis, and application. Our type system \nhas three main judgments, given in Figure 4. The checking judgment . f e . A asserts that e checks against \nthe type A in the context .. The synthesis judgment . f e . A says that we can synthesize the type A \nfor e in the context .. Finally, an application judgment . f A e . C says that if a (possibly polymorphic) \nfunction of type A is applied to argument e, then the whole application synthesizes C for the whole application. \nAs is standard in the proof-theoretic presentations of bidirec\u00adtional typechecking, each of the introduction \nforms in our calculus has a corresponding checking rule. The Decl1I rule says that () checks against \nthe unit type 1. The Decl.I rule says that .x. e checks against the function type A . B if e checks against \nB with the additional hypothesis that x has type A.The Decl.I rule says that e has type .a. A if e has \ntype A in a context extended with a fresh a. 1 Sums, products and recursive types can be added similarly \n(we leave them out for simplicity). Rule DeclSub mediates between 1 Note that we do not require an explicit \ntype abstraction operation. As a result, an implementation needs to use some technique like scoped type \nvariables (Peyton Jones and Shields 2004) to mention bound type variables in annotations. This point \ndoes not matter to the abstract syntax, though. synthesis and checking: it says that e can be checked \nagainst B,if e synthesizes A and A is a subtype of B (that is, A is at least as polymorphic as B). As \nexpected, we can infer a type for a variable (the DeclVar rule) just by looking it up in the context. \nLikewise, the DeclAnno rule says that we can synthesize a type A for a term with a type annotation (e \n: A)just by returning that type (after checking that the term does actually check against A). Application \nis a little more complex: we have to eliminate universals until we reach an arrow type. To do this, we \nuse an application judgment . f A e . C, which says that if we apply a term of type A to an argument \ne, we get something of type C. This judgment works by guessing instantiations of polymorphic quanti.ers \nin rule Decl.App. Once we have instantiated enough quanti.ers to expose an arrow A . C, we check e against \nA and return C in rule Decl.App. In the following example, where we are applying some function polymorphic \nin a, Decl.App instantiates the outer quanti.er (to the unit type 1; we elide the premise . f 1), but \nleaves the inner quanti.er over \u00df alone. . f x . (.\u00df. \u00df.\u00df) Decl.App . f (.\u00df. \u00df.\u00df). 1 . 1 x . 1 . 1 -, \nDecl.App . f .a. (.\u00df. \u00df.\u00df). a . a x . 1 . 1 In the minimal proof-theoretic formulation of bidirectional\u00adity \n(Davies and Pfenning 2000; Dun.eld and Pfenning 2004), in\u00adtroduction forms are checked and elimination \nforms synthesize, full stop. Even () cannot synthesize its type! Actual bidirectional typecheckers tend \nto take a more liberal view, adding synthesis rules for at least some introduction forms. To show that \nour system can accommodate these kinds of extensions, we add the Decl1I. and Decl.I. rules, which synthesize \na unit type for () and a monomorphic function type for lambda expressions .x. e.We ex\u00adamine other variations, \nincluding a purist bidirectional no-inference alternative, and a liberal Damas-Milner alternative, in \nSection 8. Instantiating types. We express the fact that one type is a poly\u00admorphic generalization of \nanother by means of the subtyping judg\u00adment given in Figure 3. One important aspect of the judgment is \nthat types are compared relative to a context of free variables. This simpli.es our rules, by letting \nus eliminate the awkward side con\u00additions on sets of free variables that plague many presentations. Most \nof the subtyping judgment is typical: it proceeds structurally on types, with a contravariant twist for \nthe arrow; all the real ac\u00adtion is contained within the two subtyping rules for the universal quanti.er. \n The left rule, =.L, says that a type .a. A is a subtype of B,if some instance [t/a]A is a subtype of \nB. This is what makes these rules only a declarative speci.cation: =.L guesses the instantia\u00adtion t out \nof thin air , and so the rules do not directly yield an algorithm. The right rule =.R is a little more \nsubtle. It says that A is a subtype of .\u00df. B if we can show that A is a subtype of B in a context extended \nwith \u00df. There are two intuitions for this rule, one semantic, the other proof-theoretic. The semantic \nintuition is that since .\u00df. B is a subtype of [t/\u00df]B for any t, we need A to be a subtype of [t/\u00df]B for \nany t. Then, if we can show that A is a subtype of B, with a free variable \u00df, we can appeal to a substitution \nprinciple for subtyping to conclude that for all t, type A is a subtype of [t/\u00df]B. The proof-theoretic \nintuition is simpler. The rules =.L and =.R are just the left and right rules for universal quanti.cation \nin the sequent calculus. Type inference is a form of theorem prov\u00ading, and our subtype relation gives \nsome of the inference rules a theorem prover may use. Following good proof-theoretic hygiene enables \nus to leave the re.exivity and transitivity rules out of the subtype relation, since they are admissible \nproperties (in sequent calculus terms, they are the identity and cut-admissibility proper\u00adties). The \nabsence of these rules (particularly, the absence of tran\u00adsitivity), in turn, simpli.es a number of proofs. \nIn fact, the rules are practically syntax-directed: the only exception is when both types are quanti.ers, \nand either =.L or =.R could be tried. Since =.R is invertible, however, in practice one can apply it \neagerly. Let-generalization. In many accounts of type inference, let\u00adbindings are treated specially. \nFor example, traditional Damas-Milner type inference only does polymorphic generalization at let\u00adbindings. \nInstead, we have sought to avoid a special treatment of let-bindings. In logical terms, let-bindings \ninternalize the cut rule, and so special treatment puts the cut-elimination property of the calculus \nat risk that is, typability may not be preserved when a let-binding is substituted away. To make let-generalization \nsafe, additional properties like the principal types property are needed, a property endangered by rich \ntype system features like higher-rank polymorphism, re.nement types (Dun.eld 2007) and GADTs (Vy\u00adtiniotis \net al. 2010). To emphasize this point, we have omitted let-binding from our formal development. But \nsince cut is admissible i.e., the substitu\u00adtion theorem holds restoring let-bindings is easy, as long \nas they get no special treatment incompatible with substitution. For exam\u00adple, the standard bidirectional \nrule for let-bindings is suitable: . f e . A ., x : A f e' . C . f let x = e in e' . C Note the absence \nof generalization in this rule.  2.2 Bidirectional Typing and Type Assignment System F Since our declarative \nspeci.cation is (quite consciously) not the usual type-assignment presentation of System F, a natural \nquestion is to ask what the relationship is. Luckily, the two systems are quite closely related: we can \nshow that if a term is well-typed in our type assignment system, it is always possible to add type annotations \nto make the term well-typed in the bidirectional system; conversely, if the bidirectional system types \na term, then some \u00df.-equal term is well-typed under the type assignment system. We formalize these properties \nwith the following theorems, taking |e| to be the erasure of all type annotations from a term. We give \nthe rules for our type assignment System F in Figure 5. . f e : A Under context ., e has type A (x : \nA). . AVar AUnit . f x : A . f () : 1 ., x : A f e : B . f e1 : A . B . f e2 : A A.I A.E . f .x. e : \nA . B . f e1 e2 : B ., a f e : A . f e : .a. A . f t A.I A.E . f e : .a. A . f e :[t/a]A Figure 5. Type \nassignment rules for predicative System F Theorem 1 (Completeness of Bidirectional Typing). If . f e \n: A thenthereexists e' such that . f e' . A and |e'| = e. Theorem 2 (Soundness of Bidirectional Typing). \nIf . f e . A ' ' thenthereexists e' such that . f e : A ande = \u00df. |e|. Note that in the soundness theorem, \nthe equality is up to \u00df and .. We may need to .-expand bidirectionally-typed terms to make them typecheck \nunder the type assignment system, and within the proof of soundness, we \u00df-reduce identity coercions. \n 2.3 Robustness of Typing Type annotations are an essential part of the bidirectional approach: they \nmediate between type checking and type synthesis. However, we want to relieve programmers from having \nto write redundant type annotations, and even more importantly, enable programmers to easily predict \nwhere type annotations are needed. Since our declarative system is bidirectional, the basic prop\u00aderty \nis that type annotations are required only at redexes. Addi\u00adtionally, these typing rules can infer (actually, \nguess) all monomor\u00adphic types, so the answer to the question of where annotations are needed is: only \non bindings of polymorphic type.2 Where bidirec\u00adtional typing really stands out is in its robustness \nunder substitution. We can freely substitute and unsubstitute terms: Theorem 3 (Substitution). Assume. \nf e . A. ' ' If., x : A f e . C then . f [e/x]e . C. ' ' If., x : A f e . C then . f [e/x]e . C. Theorem \n4 (Inverse Substitution). Assume. f e . A. ' ' If . f [(e : A)/x]e . C then ., x : A f e . C. ' ' If \n. f [(e : A)/x]e . C then ., x : A f e . C. Substitution is stated in terms of synthesizing expressions, \nsince any checking term can be turned into a synthesizing term by adding an annotation. Dually, inverse \nsubstitution allows extracting any checking term into a let-binding with a type annotation.3 However, \ndoing so indiscriminately can lead to a term with many redundant annotations, and so we also characterize \nwhen annotations can safely be removed: Theorem 5 (Annotation Removal). Wehave that: -, If . f (.x. e): \nA. C then . f .x. e . C. If . f (() : A). C then . f () . C. If . f e1 (e2 : A). C then . f e1 e2 . C. \nIf . f (x : A). A then . f x . B and. f B = A. 2 The number of annotations can be reduced still further; \nsee Section 8 for how to infer the types of all terms typable under Damas-Milner. 3 The generalization \nof Theorem 4 to any synthesizing term not just (e : ' A) does not hold. For example, given e = .y. y \nand e = x and . f .y. y . 1 . 1and . f .y. y . C1 . C2, we cannot derive ., x : 1 . 1 f x . C1 . C2 unless \nC1 and C2 happen to be 1.  Types A, B, C ::= 1 | a | ^a | .a. A | A . B Monotypes t, s ::= 1 | a | ^a \n| t . s Contexts G, ., T ::= \u00b7 | G, a | G, x : A G f A Under context G, type A is well-formed UvarWF \nUnitWF G[a]f a G f 1 a G f A G f B G, a f A Complete Contexts O ::= \u00b7 | O, a | O, x : A ArrowWF ForallWF \nG f A . B G f.a. A a ^^ | G, a^| G, a^= t | G, . | O, a^= t | O, . Figure 6. Syntax of types, monotypes, \nand contexts in the algo\u00adrithmic system -, If . f (e1 e2): A. A then . f e1 e2 . B and . f B = A. -, \n If . f (e : B): A. A then . f (e : B). B and. f B = A.  If. f ((.x. e): s . t). s . t then . f .x. \ne . s . t.  We can also show that the expected .-laws hold: Theorem 6 (Soundness of Eta). If . f .x. \ne x . A andx . FV(e),then . f e . A.   3. Algorithmic Type System Our declarative bidirectional system \nis a .ne speci.cation of how G, . EvarWF SolvedEvarWF G[^a]f a^G[^a = t]f a^ G ctx Algorithmic context \nG is well-formed G ctx a/. dom(G) EmptyCtx UvarCtx . domctx ^()G G .ctx G^a \u00b7 ctx G, a ctx G ctx x/. \ndom(G) G f A VarCtx G, x : A ctx a/ EvarCtx G, a^ctx G ctx ^. dom(G) a/G f t SolvedEvarCtx G, a^= t \nctx ^ ./G a/ ^. dom(G) a ctx MarkerCtx typing should behave, but it enjoys guessing entirely too much: \nthe typing rules Decl.App and Decl.I. could only be implemented with the help of an oracle. The declarative \nsubtyping rule =.L has thesameproblem. The .rst step in building our algorithmic bidirectional system \nwill be to modify the three oracular rules so that, instead of guess\u00ading a type, they defer the choice \nby creating an existential type variable, to be solved later. However, our existential variables are \nnot exactly uni.cation variables; they are organized into ordered al\u00adgorithmic contexts (Section 3.1), \nwhich de.ne the variables scope and controls the free variables of their solutions. The algorithmic type \nsystem consists of subtyping rules (Fig\u00adure 9, discussed in Section 3.2), instantiation rules (Figure \n10, dis\u00adcussed in Section 3.3), and typing rules (Figure 11, discussed in Section 3.4). All of the rules \nmanipulate the contexts in a way con\u00adsistent with context extension, a metatheoretic notion described \nin Section 4; context extension is key in stating and proving decidabil\u00adity, soundness and completeness. \n 3.1 Algorithmic Contexts A notion of (ordered) algorithmic context is central to our ap\u00adproach. Like \ndeclarative contexts ., algorithmic contexts G (see Figure 6; we also use the letters . and T) contain \ndeclarations of universal type variables a and term variable typings x : A. Unlike declarative contexts, \nalgorithmic contexts also contain declarations of existential type variables a^, which are either unsolved \n(and we simply write a^) or solved to some monotype ( a^= t). Finally, for scoping reasons that will \nbecome clear when we examine the rules, Figure 7. Well-formedness of types and contexts in the algorith\u00admic \nsystem [G]a = a [G]1 = 1 [][] G[^a = t]a^= G[^a = t]t [] G[^a]a^=^a [G](A . B)= ([G]A). ([G]B) [G](.a. \nA) = .a. [G]A Figure 8. Applying a context, as a substitution, to a type Contexts as substitutions on \ntypes. An algorithmic context can be viewed as a substitution for its solved existential variables. For \nexample, a^= 1, \u00df =^a . 1 can be applied as if it were the sub\u00ad ^stitution 1/a,^(^a.1)/\u00df^(applied right \nto left), or the simultaneous substitution 1/^\u00df. We write [G]A for G applied as a sub\u00ad a, (1.1)/^stitution \nto type A; this operation is de.ned in Figure 8. Complete contexts. Complete contexts O (Figure 6) have \nno un\u00adsolved variables. Therefore, applying such a context to a type A (provided it is well-formed: O \nf A) yields a type [O]A with no existentials. Complete contexts are essential for stating and proving \nsoundness and completeness, but are not explicitly distinguished in algorithmic contexts also include \na marker . ^ a. Complete contexts O are the same as contexts, except that they cannot have unsolved \nvariables. The well-formedness rules for contexts (Figure 7, bottom) do not only prohibit duplicate declarations, \nbut also enforce order: if G =(GL,x : A, GR), the type A must be well-formed under GL; it cannot refer \nto variables a or a^in GR. Similarly, if G = (GL, a^= t, GR), the solution type t must be well-formed \nunder GL. Consequently, circularity is ruled out: (^a = \u00df, \u00df^=^a)is not ^ well-formed. any of our rules. \nHole notation. Since we will manipulate contexts not only by ap\u00ad pending declarations (as in the declarative \nsystem) but by inserting and replacing declarations in the middle, a notation for contexts with a hole \nis useful: G = G0[T] means G has the form (GL,T, GR) For example, if G = \u00df]= (^\u00df, x : \u00df^),then G0[\u00df^a]= \nG0[^a, ^=^(^a, \u00df^=^a, x : \u00df^). Since this notation is concise, we use it even  in rules that do not \nreplace declarations, such as the rules for type well-formedness in Figure 7. Occasionally, we also \nneed contexts with two ordered holes: G = G0[T1][T2] means G has the form (GL,T1,GM,T2,GR) Input and \noutput contexts. Our declarative system used a sub\u00adtyping judgment and three typing judgments: checking, \nsynthesis, and application. Our algorithmic system includes similar judgment forms, except that we replace \nthe declarative context . with an al\u00adgorithmic context G (the input context), and add an output context \n. written after a backwards turnstile: G f A <: B . for subtyp\u00ading, G f e . A . for checking, and so \non. Unsolved existential variables get solved when they are compared against a type. For ex\u00adample, a^<: \n\u00df would lead to replacing the unsolved declaration a^with a^= \u00df in the context (provided \u00df is declared \nto the left of a^). Input contexts thus evolve into output contexts that are more solved . The differences \nbetween the declarative and algorithmic sys\u00adtems, particularly manipulations of existential variables, \nare most prominent in the subtyping rules, so we discuss those .rst.  3.2 Algorithmic Subtyping The \n.rst four subtyping rules in Figure 9 do not directly manipulate the context, but do illustrate how contexts \nare propagated. Rules <:Var and <:Unit are re.exive rules; neither involves existential variables, so \nthe output context in the conclusion is the same as the input context G.Rule <:Exvar concludes that any \nunsolved existential variable is a subtype of itself, but this gives no clue as to how to solve that \nexistential, so the output context is similarly unchanged. Rule <:. is a bit more interesting: it has \ntwo premises, where the .rst premise has an output context T, which is used as the input context to the \nsecond (subtyping) premise; the second premise has output context ., which is the output of the conclusion.4 \nNote that in <:. s second premise, we do not simply check that A2 <: B2, Rule <:.R is fairly close to \nthe declarative version, but for scoping reasons similar to <:.L, it also drops T, the part of the context \nto the right of the universal type variable a. (Articulation makes no sense for universal variables, \nso a can act as its own marker.) The last two rules are essential: they derive subtypings with an unsolved \nexistential on one side, and an arbitrary type on the other. Rule <:InstantiateL derives a^<: A,and <:InstantiateR \nderives A <: a^. These rules do not directly change the output context; they just do an occurs check \n^. FV(A)to avoid circularity, and a/ leave all the real work to the instantiation judgment.  3.3 Instantiation \nTwo almost-symmetric judgments instantiate unsolved existential < variables: G f a^:=< A . and G f A \n=<: a^ .. The symbol :=suggests assignment of the variable to its left, but also subtyping: the subtyping \nrule <:InstantiateL moves from instantiation a^:=< A, read instantiate a^to a subtype of A , to subtyping \na^<: A. The symmetric judgment A =<: a^can be read instantiate a^to a supertype of A . The .rst instantiation \nrule in Figure 10, InstLSolve,sets a^to t in the output context: its conclusion is G, ^f a :=< t a, G \n' ^G, a^= t, G ' . The premise G f t checks that the monotype t is well-formed under the pre.x context \nG. To check the soundness of this rule, we can take the conclusion a^:=< t, substitute our new solution \nfor a^, and check that the resulting subtyping makes sense. Since [G, a^= t, G ' ]^a = t,we ask whether \nt <: t makes sense, and of course it does through re.exivity. Rule InstLArr can be applied when the type \nA in a^:=< A has the form A1 . A2. It follows that a^ s solution must have the form \u00b7\u00b7\u00b7 . \u00b7\u00b7\u00b7 , so we \narticulate a^, giving it the solution a^1 . a^2 where the a^k are fresh existentials. We insert their \ndeclarations just before a^ they must be to the left of a^so they can be mentioned in its solution, but \nthey must be close enough to a^that they appear to but apply the .rst premise s output T to those types: \nthe right of the markerpremise A1 =<: ^ a introduced by <:.L. Note that the .rst switches to the other \ninstantiation judgment. a^1T f [T]A2 <: [T]B2 . Also, the second premise T f a^2 :=< [T]A2 . applies \nT to A2, This maintains a general invariant: whenever we try to derive G f to apply any solutions found \nin the .rst premise. A <: B ., the types A and B are already fully applied under G. The other rules \nare somewhat subtle. Rule InstLReach derives That is, they contain no existential variables already solved \nin G.On balance, this invariant simpli.es the system: the extra applications of T in <:. avoid the need \nfor extra rules for replacing solved variables with their solutions. All the rules discussed so far have \nbeen natural extensions of the declarative rules, with <:Exvar being a logical way to extend re.exivity \nto types containing existentials. Rule <:.L diverges sig\u00adni.cantly from the corresponding declarative \nrule =.L. Instead of replacing the type variable a with a guessed t,rule <:.L replaces a with a new existential \nvariable a^, which it adds to the premise s G[^a][\u00df^]f a^:=< \u00df^ G[^a][\u00df^=^a] where, as explained in Section \n3.1, G[^a][\u00df^]denotes a context where some unsolved existential variable a^is declared to the left of \n\u00df^.In this situation, we cannot use InstLSolve to set a^to \u00df^because \u00df ^is not well-formed under the \npart of the context to the left of a^. Instead, we set \u00df^to a^. Rule InstLAllR is the instantiation version \nof <:.R. Since our polymorphism is predicative, we can t assign .\u00df. B to a^,but we ^ ^^ a,T. The peculiar\u00ad \n delineate existentials created by articulation (the step of solving a^InstRReach and InstRArr are direct \nanalogues of the .rst three to a^1 . a^2, discussed in the next subsection). The output context a^:=< \nA rules, and InstRAllL is the instantiation version of <:.L. can decompose the quanti.er in the same \nway that subtyping does. input context: G, a, a^f [^a/a]A <: B ., The rules for the second judgment \nA =<: a^are similar: InstRSolve, looking a is a scope marker, pronounced marker a^ , which will ^ ^ \na,T)allows for some additional (existential) variables to ap\u00ada, in a trailing context T. These existential \nvariables a and a^) could be (., ^ pear afterExample. The interplay between instantiation and quanti.ers \nis delicate. For example, consider the problem of instantiating \u00df^to a could mention a^, or (if they \nappear between mentioned by a^;since a^goes out of scope in the conclusion, we drop such trailing existentials \nfrom the concluding output con\u00adtext, which is simply .. 5 4 Rule <:. enforces that the function domains \nB1, A1 are compared .rst: T is an input to the second premise. But this is an arbitrary choice; the system \nwould behave the same if we chose to check the codomains .rst. 5 In our setting, it is safe to drop trailing \nexistentials that are unsolved: such variables are unconstrained, and we can treat them as having been \nsupertype of .a. a. In this case, the type .a. a is so polymorphic that it places no constraints at all \non \u00df^. Therefore, it seems we are at risk of being forced to make a necessarily incomplete choice but \nthe instantiation judgment s ability to change its mind about which variable to instantiate saves the \nday: instantiated to any well-formed type, such as 1. In a dependently typed setting, we would need to \ncheck that at least one solution exists.  G f A <: B -. Under input context G, type A is a subtype of \nB, with output context . <:Var <:Unit <:Exvar G[a]f a <: a G[a] G f 1 <: 1 G G[^a]f a^<: a^ G[^a] G f \nB1 <: A1 T T f [T]A2 <: [T]B2 . <:. G f A1 . A2 <: B1 . B2 . a, ^a,T ^ ^ a f [^a/a]A <: B .,G, a f A \n<: B ., a, TG, <:.L <:.R G f.a. A <: B . G f A <: .a. B . a/G[^a :=< A . a/a]f A =<: ^ ^. FV(A) a]f \n^^. FV(A) G[^a . <:InstantiateL <:InstantiateR G[^a]f a^<: A . G[^a]f A <: a^ . <<< ' f f f[^^^=^^] ^^[^]^G \naaa aaAaT T a[]. G a,\u00df a B., \u00df, .: :TA:. ===2, 1, 1 2 1 12 2^ ^ Figure 9. Algorithmic subtyping G f \na^:=< A -. Under input context G, instantiate a^such that a^<: A, with output context . G f t InstLSolve \nInstLReach ' ' < ^ G, ^f a :=a = t, G G[^\u00df]f a :=a][\u00df^=^a]a, G ^< t G, ^a][^^\u00df G[^ InstLArr InstLAllR \n G[^a]f a^:=< A1 . A2 . G[^a]f a^:=< .\u00df. B . G f A =<: a^-. Under input context G, instantiate a^such \nthat A <: a^, with output context . G f t InstRSolve InstRReach ^ G, ^' f t =a G, ^t, G ' a][^\u00df =<: \n^a][\u00df^=^a] a, G <: ^a = G[^\u00df]f a G[^ \u00df, \u00df <: a^ ., ' a1 :=< A1 T T f [T]A2 =<: a^2 \u00df^f [^ \u00df/\u00df]B = G[^a],,.a1 \n. a^2]f . G[^a2, a^1, a^=^ ^ InstRArr InstRAllL G[^a]f A1 . A2 =<: a^ . G[^a]f.\u00df. B =<: a^ . Figure \n10. Instantiation G f e . A -. Under input context G, e checks against input type A, with output context \n. G f e . A -. Under input context G, e synthesizes output type A, with output context . G f A e . C \n-. Under input context G, applying a function of type A to e synthesizes type C, with output context \n. (x : A). G G f e . A T T f [T]A <: [T]B . G f A G f e . A . G f x . A G Var G f e . B . Sub G f (e \n: A) . A . Anno G, a f e . A ., a, T G, ^a f [^a/a]A e . C . G f () . 1 G 1I G f () . 1 G 1I. G f e \n. .a. A . .I G f.a. A e . C . .App a, ^\u00df ., x :^ G, x : A f e . B ., x : A, T G, ^\u00df, x :^a f e . ^a, \nT G f e1 . A T T f [T]A e2 . C . .I .I. .E G f .x. e . A . B . G f .x. e . a^. \u00df^ . G f e1 e2 . C . \nG[^a2, a^1, a^=^a1 . a^2]f e . a^1 . G[^a]f a^ e . a^2 . G f e . A . a^App .App G f A . C e . C . \nFigure 11. Algorithmic typing InstRReach G[\u00df^], a^, a^f a^=<: \u00df^G[\u00df^], a^, a^= \u00df^ InstRAllL G[\u00df^]f.a. \na =<: \u00df^G[\u00df^] Here, we introduce a new variable a^to go under the universal quanti.er; then, instantiation \napplies InstRReach to set a^, not \u00df. ^ Hence, \u00df^is, correctly, not constrained by this subtyping problem. \nThus, instantiation does not necessarily solve any existential variable. However, instantiation to any \nmonotype t will solve an existential variable that is, for input context G and output ., we have unsolved(.) \n< unsolved(G). This will be critical for decidability of subtyping (Section 5.2). Another example. In \nFigure 12 we show a derivation that uses quanti.er instantiation (InstRAllL), articulation (InstRArr)and \nreaching (InstLReach), as well as InstRSolve. In the output context . = G[\u00df^2, \u00df^1 =\u00df^2, a^=\u00df^1.\u00df^2]note \nthat a^is solved to ^^ \u00df1 . \u00df^2,and \u00df^2 is solved to \u00df^1. Thus, [.]^a = \u00df1.\u00df^1,which is a monomorphic \napproximation of .\u00df.\u00df.\u00df.  3.4 Algorithmic Typing We now turn to the typing rules in Figure 11. Many \nof these rules follow the declarative rules, with extra context machinery. Rule Var uses an assumption \nx : A without generating any new information, so the output context in its conclusion G f x . A G is \njust the input context. Rule Sub s .rst premise has an output context T, used as the input context to \nthe second (subtyping) premise, which has output context ., the output of the conclusion. Rule Anno does \nnot directly change the context, but the derivation of its premise might include the use of some rule \nthat does, so we propagate the premise s output context . to the conclusion. Unit and .. In the second \nrow of typing rules, 1I and 1I. gener\u00adate no new information and simply propagate the input context. \n.I is more interesting: Like the declarative rule Decl.I, it adds a universal type variable a to the \n(input) context. The output context of the premise G, a f e . A ., a, T allows for some additional (existential) \nvariables to appear after a, in a trailing context T. These existential variables could depend on a;since \na goes out of scope in the conclusion, we must drop them from the concluding output context, which is \njust .: the part of the premise s output context that cannot depend on a. The application-judgment rule \n.App serves a similar purpose to the subtyping rule <:.L, but does not place a marker before a^:the variable \na^may appear in the output type C,so a^must survive in the output context .. Functions. In the third \nrow of typing rules, rule .I follows the same scheme: the declarations T following x : A are dropped \nin the conclusion s output context. Rule .I. corresponds to Decl.I., one of the guessing rules, so we \ncreate new existential variables a^(for the function domain) and \u00df^(for the codomain) and check the function \nbody against \u00df^. As in .App, we do not place a marker before a^, because a^and \u00df^appear in the output \ntype (.x. e . a^. \u00df^). Rule .E is the expected analogue of Decl.E; like other rules with two premises, \nit applies the intermediate context T. On the last row of typing rules, a^App derives a^ e . a^2 where \na^is unsolved in the input context. Here we have an application judgment, which is supposed to synthesize \na type for an application e1 e where e1 has type a^. We know that e1 should have function type; similarly \nto InstLArr/InstRArr, we introduce a^1 and a^2 and add a^=^a1.a^2 to the context. (Rule a^App is the \nonly algorithmic typing rule that does not correspond to a declarative rule.) Finally, rule .App is analogous \nto Decl.App.  4. Context Extension We motivated the algorithmic rules by saying that they evolved input \ncontexts to output contexts that were more solved . To state and prove the metatheoretic results of decidability, \nsoundness and completeness (Sections 5 7), we introduce a context extension judgment G -. .. This judgment \ncaptures a notion of information increase from an input context G to an output context ., and relates \nalgorithmic contexts G and . to completely solved extensions O, which correspond via the context application \ndescribed in Section 4.1 to declarative contexts .. The judgment G -. . is read G is extended by . (or \n. extends G). Another reading is that . carries at least as much information as G. A third reading is \nthat G -. . means that G is entailed by .: all positive information derivable from G (say, that existential \nvariable a^is in scope) can also be derived from . (which may have more information, say, that a^is equal \nto a particular type). This reading is realized by several key lemmas; for instance, extension preserves \nwell-formedness: if G f A and G -. .,then . f A. The rules deriving the context extension judgment (Figure \n13) say that the empty context extends the empty context (-.ID); a term variable typing x : A ' extends \nx : A if applying the extending context . to A and A ' yields the same type (-.Var); universal type variables \nmust match (-.Uvar); scope markers must match (-.Marker); and, existential variables may: appear unsolved \nin both contexts (-.Unsolved),  appear solved in both contexts, if applying the extending con\u00adtext . \nmakes the solutions t and t ' equal (-.Solved),  get solved by the extending context (-.Solve),  be \nadded by the extending context, either without a solution (-.Add) or with a solution (-.AddSolved); \n Extension does not allow solutions to disappear: information must increase. It does allow solutions \nto change, but only if the change preserves or increases information. The extension -,-, ^ a,^\u00df^=^a-. \na^= 1, \u00df =^a directly increases information about a^, and indirectly increases information about \u00df^. \nPerhaps more interestingly, the extension -,-, ^^ a^= 1, \u00df =^a-. a^= 1, \u00df = 1 ' -v ' ' -v ' . O also \nholds: while the solution of \u00df^in O is different, in the sense that O contains \u00df^= 1 while . contains \n\u00df^=^a, applying O to the two solutions gives the same thing: applying O to . s solution of ^ \u00df gives \n[O]^a =[O]1 = 1, while applying O to O s own solution for \u00df^also gives 1, because [O]1 = 1. Extension \nis quite rigid, however, in two senses. First, if a declaration appears in G, it appears in all extensions \nof G. Second, extension preserves order. For example, if \u00df^is declared after a^in G,then \u00df^will also \nbe declared after a^in every extension of G.This holds for every variety of declaration. This rigidity \naids in enforcing type variable scoping and dependencies, which are nontrivial in a setting with higher-rank \npolymorphism. This combination of rigidity (in demanding that the order of declarations be preserved) \nwith .exibility (in how existential type variable solutions are expressed) manages to satisfy scoping \nand dependency relations and give enough room to maneuver in the algorithm and metatheory. 4.1 Context \nApplication A complete context O (Figure 6) has no unsolved variables, so ap\u00adplying it to a (well-formed) \ntype yields a type [O]A with no existen\u00ad  \u00df1 v '' -v '' \u00ad \u00df^1 \u00df^2 f ^ \u00df \u00df2 ^^ context to the left \nof context to the left of  G[\u00df^2, \u00df^1 =\u00df^2, a^=\u00df^1.\u00df^2]= f , .. ., InstLReach InstRSolve , ^^< ^ \u00df \nf \u00df2 :=\u00df , \u00df^= ^ \u00df1  , \u00df^=\u00df^1 f \u00df^2 <: ^ =\u00df1 \u00df^= ^ \u00df1 \u00df, \u00df, \u00df, \u00df, \u00df, G ' = G[\u00df^2, \u00df^1, a^=\u00df^1.\u00df^2] \n G[^a]f (.\u00df. \u00df.\u00df)=<: a^ . ^ ^^ ^ ^ InstRArr ^^ \u00df f \u00df.\u00df^=<: a^ \u00df^= ^ \u00df1 G[^a], InstRAllL Figure 12. \nExample of instantiation G -. . G is extended by . G -. . [.]A =[.]A ' G -. . -.ID -.Var -.Uvar \u00b7 -. \n\u00b7 G, x : A -. ., x : A ' G, a -. ., a G -. . G -. . [.]t =[.]t ' G -. . G -. . -.Unsolved -.Solved -.Solve \n-.Add G, a^-. ., a^G, a^= t -. ., a^= t ' G, a^-. ., a^= t G -. ., a^G -. . G -. . -.AddSolved -.Marker \nG -. ., a^= [\u00b7]\u00b7 = \u00b7 [O, x : A](G, x : AG ) = [O]G, x :[O]A [O, a](G, a) =[O]G, a [O, a^= t](G, a^) = \n[O]G [O, a^= t](G, a^= tG )=[O]G [O, a^= t]G =[O]G a](G,a) ^ ^ [O, [O]G= t G, ^ ^ a -. .,a Figure 13. \nContext extension and G f B and ^. FV([G]B),then |[G]B| = |[.]B|,where |C| is a/theplainsizeof C. if \n[O]A =[O]AG Using this lemma, we can show that the type A in the instan\u00adtiation judgment always get smaller, \neven in rule InstLArr:the if [O]t =[O]tG second premise applies the intermediate context T to A2,but \nthe if ^. dom(G) a/ lemma tells us that this application cannot make A2 larger, and A2 is smaller than \nthe conclusion s type (A1 . A2). Now we can prove decidability of instantiation, assuming that a^is unsolved \nin the input context G,that A is well-formed under Figure 14. Applying a complete context O to a context \ntials. Such a type is well-formed under a declarative context with just a and x : A declarations obtained \nby dropping all the exis\u00adtential declarations and applying O to declarations x : A (to yield x :[O]A). \nWe can think of this context as the result of applying O to itself: [O]O. More generally, we can apply \nO to any context G that it extends. This operation of context application [O]G is given in Figure 14. \nThe application [O]G is de.ned if and only if G -. O,and applying O to any such G yields the same declarative \ncontext [O]O: Lemma (Stability of Complete Contexts). If G -. O then [O]G =[O]O.  5. Decidability Our \nalgorithmic type system is decidable. Since the typing rules (Figure 11) depend on the subtyping rules \n(Figure 9), which in turn depend on the instantiation rules (Figure 10), showing that the typ\u00ading judgments \n(checking, synthesis and application) are decidable requires that we show that the instantiation and \nsubtyping judg\u00adments are decidable. 5.1 Decidability of Instantiation As discussed in Section 3.3, deriving \nG f a^:=< A . does not necessarily instantiate any existential variable (unless A is a monotype). However, \nthe instantiation rules do preserve the size of (substituted) types: Lemma (Instantiation Size Preservation). \nIfG =(G0, ^^< A <: ^., a, G1)andG f a :=. orG f A =a G,that A is fully applied ([G]A = A), and that \na^does not occur in A. These conditions are guaranteed when instantiation is invoked, because the typing \nrule Sub applies the input substitution, and the subtyping rules apply the substitution where needed \nin exactly one place: the second premise of <:.. The proof is based on the (substituted) types in the \npremises being smaller than the (substi\u00adtuted) type in the conclusion. Theorem 7 (Decidability of Instantiation). \nIfG = G0[^a]andG f A such that [G]A = A anda/^. FV(A),then: (1) Eitherthere exists . such that G0[^a]f \na^:=< A .,or not. (2) Eitherthere exists . such that G0[^a]f A =<: a^.,or not.   5.2 Decidability \nof Algorithmic Subtyping To prove decidability of the subtyping system in Figure 9, measure judgments \nG f A <: B . lexicographically by (S1) the number of . quanti.ers in A and B; (S2) |unsolved(G)|, the \nnumber of unsolved existentials in G; (S3) |G f A| + |G f B|. Part (S3) uses contextual size, which penalizes \nsolved variables (*): De.nition (Contextual Size). |G f a| = 1 |G[^a]f a^| = 1 |G[^a = t]f a^| = 1 + \n|G[^a = t]f t| (*) |G f.a. A| = 1 + |G, a f A| |G f A . B| = 1 + |G f A| + |G f B| For example, if G \n=(\u00df, a^= \u00df)then |G f a^| = 1 + |G f \u00df| = 1 + 1 = 2, whereas the plain size of a^is simply 1.  The connection \nbetween (S1) and (S2) may be clari.ed by examining rule <:., whose conclusion says that A1 . A2 is a \nsubtype of B1 . B2.If A2 or B2 is polymorphic, then the .rst premise on A1 . A2 is smaller by (S1). Otherwise, \nthe .rst premise has the same input context as the conclusion, so it has the same (S2), but is smaller \nby (S3). If B1 or A1 is polymorphic, then the second premise is smaller by (S1). Otherwise, we use the \nproperty that instantiating a monotype always solves an existential: Lemma (Monotypes Solve Variables). \nIf G f a^:=< t . or G f t =<: a^.,then if [G]t = t and ^. FV([G]t),we have a/ |unsolved(G)| = |unsolved(.)| \n+ 1. A couple of other lemmas are worth mentioning: subtyping on two monotypes cannot increase the number \nof unsolved existen\u00adtials, and applying a substitution G to a type does not increase the type s size \nwith respect to G. Lemma (Monotype Monotonicity). IfG f t1 <: t2 . then|unsolved(.)| = |unsolved(G)|. \n Lemma (Substitution Decreases Size). IfG f A then|G f [G]A| = |G f A|. Theorem 8 (Decidability of Subtyping). \nGivenacontext G andtypes A, B suchthat G f A and G f B and [G]A = A and[G]B = B,itisdecidablewhetherthereexists. \nsuch thatG f A <: B ..  5.3 Decidability of Algorithmic Typing Theorem 9 (Decidability of Typing). \n(i) Synthesis: Given a context G and a term e, it is decidable whetherthereexistatypeA andacontext. suchthat \nG f e . A .. (ii) Checking: GivenacontextG,aterme,andatypeB suchthat G f B,itisdecidablewhetherthereisacontext \n. suchthat G f e . B ..  (iii) Application: Given a context G,aterm e, and a type A such thatG f A,itisdecidablewhetherthereexistatype \nC anda context. suchthat G f A e . C .. The following induction measure suf.ces to prove decidability: \n. e, ., |G f B| . , |G f A| where (.. . ) denotes lexicographic order, and where (when com\u00adparing two \njudgments typing the same term e) the synthesis judg\u00adment (top line) is considered smaller than the checking \njudgment (second line), which in turn is considered smaller than the applica\u00adtion judgment (bottom line). \nThat is, . .. .. .In Sub,this makes the synthesis premise smaller than the checking conclusion; in .App \nand a^App, this makes the checking premise smaller than the application conclusion. Since we have no \nexplicit introduction form for polymorphism, the rule .I has the same term e in its premise and conclusion, \nand both the premise and conclusion are the same kind of judgment (checking). The rule .App is similar \n(with application judgments in premise and conclusion). Therefore, given two judgments on the same term, \nand that are both checking judgments or both appli\u00adcation judgments, we use the size of the input type \nexpression which does get smaller in .I and .App.  6. Soundness We want the algorithmic speci.cations \nof subtyping and typing to be sound with respect to the declarative speci.cations. Roughly, given a derivation \nof an algorithmic judgment with input context G and output context ., and some complete context O that \nextends . (which therefore extends G), applying O throughout the given al\u00adgorithmic judgment should yield \na derivable declarative judgment. Let s make that rough outline concrete for instantiation, showing that \nthe action of the instantiation rules is consistent with declara\u00adtive subtyping: Theorem 10 (Instantiation \nSoundness). Given. -. O and[G]B = B and ^. FV(B): a/ (1) IfG f a^:=< B . then[O]. f [O]^a = [O]B. (2) \nIfG f B =<: a^. then[O]. f [O]B = [O]^a.  Note that the declarative derivation is under [O].,which is \nO applied to the algorithmic output context .. With instantiation soundness, we can prove the expected \nsound\u00ad ness property for subtyping: Theorem 11 (Soundness of Algorithmic Subtyping). IfG f A <: B . where \n[G]A = A and [G]B = B and . -. O then[O]. f [O]A = [O]B. Finally, knowing that subtyping is sound, we \ncan prove that typing is sound: Theorem 12 (Soundness of Algorithmic Typing). Given. -. O: (i) IfG f \ne . A . then[O]. f e . [O]A. (ii) IfG f e . A . then[O]. f e . [O]A.  (iii) IfG f A e . C . then[O]. \nf [O]A e . [O]C. The proofs need several lemmas, including this one: Lemma (Typing Extension). IfG f \ne . A . orG f e . A . orG f A e . C . thenG -. ..  7. Completeness Completeness of the algorithmic \nsystem is something like sound\u00adness in reverse: given a declarative derivation of [O]G f [O]\u00b7\u00b7\u00b7 , we \nwant to get an algorithmic derivation of G f \u00b7\u00b7\u00b7 .. For soundness, the output context . such that . -. \nO was given; G -. O followed from Typing Extension (the above lemma) and transitivity of extension. For \ncompleteness, only G is given, so we have G -. O in the antecedent. Then we might expect to show, along \nwith G f \u00b7\u00b7\u00b7 .,that . -. O. But this is not general enough: the algorithmic rules generate fresh existential \nvariables, so . may have existentials that are not found in G, nor in O. In completeness, we are given \na declarative derivation, which contains no existentials; the completeness proof must build up the completing \ncontext O along with the algorithmic derivation. Thus, completeness will produce an O ' which extends \nboth the given O and the output context of the algorithmic derivation: O -. O ' and . -. O ' . (By transitivity, \nwe also get G -. O ' .) As with soundness, we have three main completeness results, for instantiation, \nsubtyping and typing. Theorem 13 (Instantiation Completeness). Given G -. O and A =[G]A anda^. unsolved(G)and \n^. FV(A): a/ (1) If[O]G f [O]^a = [O]A thenthereare.,O ' suchthat O -. O ' and . -. O ' andG f a^:=< \nA .. (2) If[O]G f [O]A = [O]^a thenthereare.,O ' suchthat O -. O ' and . -. O ' andG f A =<: a^..  \nTheorem 14 (Generalized Completeness of Subtyping). If G -. O and G f A and G f B and [O]G f [O]A = [O]B \nthenthereexist. and O ' suchthat. -. O ' and O -. O ' and G f [G]A <: [G]B ..  Theorem 15 (Completeness \nof Algorithmic Typing). GivenG -. O andG f A: (i) If[O]G f e . [O]A thenthereexist. andO ' suchthat. \n-. O ' and O -. O ' andG f e . [G]A .. (ii) If[O]G f e . A thenthereexist.,O ' ,andA '  '' ' such \nthat . -. O and O -. O and G f e . A . andA =[O ' ]A ' . (iii) If[O]G f [O]A e . C thenthereexist.,O \n' ,andC ' suchthat. -. O ' and O -. O ' ' '' andG f [G]A e . C . andC =[O ]C .  8. Design Variations \nThe rules we give infer monomorphic types, but require annotations for all polymorphic bindings. In this \nsection, we consider alterna\u00adtives to this choice. Eliminating type inference. To eliminate type inference \nfrom the declarative system, it suf.ces to drop the Decl.I. and Decl1I. rules. The corresponding alterations \nto the algorithmic system are a little more delicate: simply deleting the .I. and 1I. rules breaks completeness. \nTo see why, suppose that we have a variable f of type .a. a . a, and consider the application f (). Our \nalgorithm will introduce a new existential variable a^for a, and then check () against a^. Without the \n1I. rule, typechecking will fail. To restore completeness, we need to modify these two rules. Instead \nof being synthesis rules, we will change them to checking rules that check values against an unknown \nexistential variable. 1Ia^ G[^a]f () . a^G[^a = 1] G[^a2, a^1, a^=^a1 . a^2],x :^a1 f e . a^2 ., x :^a1,. \n' .Ia^ G[^a]f .x. e . a^. With these two rules replacing 1I. and .I., wehavea complete algorithm for \nthe no-inference bidirectional system. Full Damas-Milner type inference. Another alternative is to in\u00adcrease \nthe amount of type inference done. For instance, a natural question is whether we can extend the bidirectional \napproach to subsume the inference done by the algorithm of Damas and Milner (1982). This appears feasible: \nwe can alter the .I. rule to support ML-style type inference. inherently involves navigating a variety \nof design tradeoffs. As a re\u00adsult, there have been a wide variety of proposals for extending type systems \nbeyond the Damas-Milner sweet spot . The main trade\u00adoff appears to be a two-out-of-three choice: language \ndesigners can keep any two of: (1) the .-law for functions, (2) impredicative instantiation, and (3) \nthe standard type language of System F. As discussed in Section 2, for typability under .-reductions, \nit is necessary for subtyping to instantiate deeply: that is, we must allow instantiation of quanti.ers \nto the right of an arrow. However, Tiuryn and Urzyczyn (1996) and Chrz .aszcz (1998) showed that the \nsubtyping relation for impredicative System F is undecidable. As a result, if we want . and a complete \nalgorithm, then either the polymorphic instantiations must be predicative, or a different language of \ntypes must be used. Figure 15 summarizes the different choices made by the design\u00aders of this and related \nsystems. Impredicativity and the .-law. The designers of MLF (Le Bot\u00adlan and R\u00e9my 2003; R\u00e9my and Yakobowski \n2008; Le Botlan and R\u00e9my 2009) chose to use a different language of types, one with a form of bounded \nquanti.cation. This increases the expressivity of types enough to ensure principal types, which means \nthat (1) required annotations are few and predictable, and (2) their system is very robust in the face \nof program transformations, including .. However, the richness of the MLF type structure requires a so\u00adphisticated \nmetatheory and correspondingly intricate implementa\u00adtion techniques. Impredicativity and System F types. \nMuch of the other work on higher-rank polymorphism avoids changing the language of types. The HML system \nof Leijen (2009) and the FPH system of Vy\u00adtiniotis et al. (2008) both retain the type language of (impredicative) \nSystem F. Each of these systems gives as a speci.cation a slightly different extension to the declarative \nDamas-Milner type system, and handle the issue of inference in slightly different ways. HML is essentially \na restriction of MLF , in which the external language of types is limited to System F, but which uses \nthe technology of MLF internally, as part of type inference. FPH, on the other hand, extends and generalizes \nwork on boxy types (Vytiniotis et al. 2006) to control type inference. The differences in expressive \npower be\u00adtween these two systems are subtle roughly speaking, FPH re\u00adquires slightly more annotations, \nbut has a less complicated speci\u00ad.cation. However, in both systems, the same heuristic guidance to the \nprogrammer applies: place explicit annotations on binders with fancy types. The .-law and System F types. \nPeyton Jones et al. (2007) devel\u00ad ' oped an approach for typechecking higher-rank predicative poly\u00ad \na, ^\u00df, x :^a f e . ^ a, ^\u00df ^ ^ a,. t =[. ' ](^a . \u00df^) .a^= unsolved(. ' ) G, ., morphism that is closely \nrelated to ours. They de.ne a bidirec\u00ad .I. ' tional declarative system similar to our own, but which \nlacks an ^ G f .x. e . ..a. [a/..a^]t . application judgment. This complicates the presentation of their \nsystem, forcing them to introduce an additional grammatical cate\u00ad a into the context, and then In this \nrule, we introduce a markergory of types beyond monotypes and polytypes, and requires manycheck the function \nbody against the type \u00df^. Then, our output type rules to carry an additional subtyping premise. Next, \nthey enrich substitutes away all the solved existential variables to the right of the subtyping rules \nof Odersky and L\u00e4ufer (1996) with the distribu\u00ad tivity axiom of Mitchell (1988), which we rejected on \nideological ^ a, and generalizes over all of the unsolved variables to the right of the marker. Using \nan ordered context gives precise the marker grounds: it is a valid coercion, but is not orthogonal (it \nis a sin\u00ad gle rule mixing two different type connectives) and does not cor\u00adcontrol over the scope of \nthe existential variables, making it easy to express polymorphic generalization. The above is only a \nsketch; we have not de.ned the correspond\u00adrespond to a rule in the sequent calculus. They do not prove \nthe soundness and completeness of their Haskell reference implemen\u00ading declarative system, nor proved \ncompleteness. tation, but it appears to implement behavior close to our application judgment.  9. Related \nWork and Discussion History of our approach. Several of the ideas used in the present 9.1 Type Inference \nfor System F paper descend from Dun.eld (2009), an approach to .rst-class Because type inference for \nSystem F is undecidable (Wells 1999), polymorphism (including impredicativity) also based on ordered \ndesigning type inference algorithms for .rst-class polymorphism contexts with existential variables instantiated \nvia subtyping. In System .-laws? Impredicative? System F type language? MLF yes yes no FPH no yes yes \nHML no yes yes Peyton Jones et al. (2007) yes no yes This paper yes no yes Figure 15. Comparison of \ntype inference algorithms fact, the present work began as an attempt to extend Dun.eld (2009) with type-level \ncomputation. During that attempt, we found several shortcomings and problems. The most serious is that \nthe de\u00adcidability and completeness arguments were not valid. These prob\u00adlems may be .xable, but instead \nwe started over, reusing several of the high-level ideas in different technical forms.  9.2 Other Type \nSystems Pierce and Turner (2000) developed bidirectional typechecking for rich subtyping, with speci.c \ntechniques for instantiating polymor\u00adphism within function application (hence, local type inference). \nTheir declarative speci.cation is more complex than ours, and their algorithm depends on computing approximations \nof upper and lower bounds on types. Colored local type inference (Odersky et al. 2001) allows different \nparts of type expressions to be propagated in different directions. Our approach gets a similar effect \nby manipu\u00adlating type expressions with existential variables. 9.3 Our Algorithm One of our main contributions \nis our new algorithm for type infer\u00adence, which is remarkable in its simplicity. Three key ideas under\u00adpin \nour algorithm. Ordered contexts. We move away from the traditional bag of constraints model of type inference, \nand instead embed existential variables and their values directly into an ordered context. Thus, straightforward \nscoping rules control the free variables of the types each existential variable may be instantiated with, \nwithout any need for model-theoretic techniques like skolemization, which .tawk\u00adwardly into a type-theoretic \ndiscipline. Using an ordered context permits handling quanti.ers in a manner resembling the level-based \ngeneralization mechanism of R\u00e9my (1992), used also in MLF (Le Botlan and R\u00e9my 2009). The instantiation \njudgment. The original inspiration for instanti\u00adation comes from the greedy algorithm of Cardelli (1993), \nwhich eagerly uses type information to solve existential constraints. In that setting a language with \nrather ambitious subtyping the greedy algorithm was incomplete: consider a function of type .a. a . a \n. a applied to a Cat and an Animal; the cat will be checked against an existential a^, which instantiates \na^to Cat,but checking the second argument, Animal <: Cat, fails. (Reversing the order of arguments makes \ntyping succeed!) In our setting, where subtyping represents the specialization order induced by quanti.er \ninstantiation, it is possible to get a complete algorithm, by slightly relaxing the pure greedy strategy. \nRather than eagerly setting constraints, we .rst look under quanti\u00ad.ers (in the InstLAllR and InstRAllL \nrules) to see if there is a fea\u00adsible monotype instantiation, and we also use the the InstLReach and \nInstRReach to set the wrong existential variable in case we need to equate an existential variable with \none to its right in the context. Looking under quanti.ers seems forced by our restriction to predicative \npolymorphism, and reaching seems forced by our use of an ordered context, but the combination of these \nmechanisms fortuitously enables our algorithm to .nd good upper and lower monomorphic approximations \nof polymorphic types. This is surprising, since it is quite contrary to the implemen\u00adtation strategy \nof MLF (also used by HML and FPH). There, the language of type constraints supports bounds on fully quanti.ed \ntypes, and the algorithm incrementally re.nes these constraints. In contrast, we only ever create equational \nconstraints on existentials (bounds are not needed), and once we have a solution for an exis\u00adtential, \nour algorithm never needs to revisit its decision. Distinguishing instantiation as a separate judgment \nis new in this paper, and bene.cial: Dun.eld (2009) baked instantiation into the subtyping rules, resulting \nin a system whose direct implementa\u00adtion required substantial backtracking over a set of rules includ\u00ading \narbitrary application of substitutions. We, instead, maintain an invariant in subtyping and instantiation \nthat the types are always fully applied with respect to an input context, obviating the need for explicit \nrules to apply substitutions. Context extension. Finally, we introduce a context-extension judgment as \nthe central invariant in our correctness proofs. This permits us to state many properties important to \nour algorithm ab\u00adstractly, without reference to the details of our algorithm. We are not the only ones \nto study context-based approaches to type inference. Recently, Gundry et al. (2010) recast the classic \nDamas-Milner algorithm, which manipulates unstructured sets of equality constraints, as structured constraint \nsolving under ordered contexts. A (semantic) notion of information increase is central to their development, \nas (syntactic) context extension is to ours. While their formulation supports only ML-style prenex polymorphism, \nthe ultimate goal is a foundation for type inference for dependent types. To some extent, both our algorithm \nand theirs can be under\u00adstood in terms of the proof system of Miller (1992) for mixed-pre.x uni.cation. \nWe each restrict the uni.cation problem, and then give a proof search algorithm to solve the type inference \nproblem.   Acknowledgments Thanks to the anonymous ICFP reviewers for their comments, which have (we \nhope) led to a more correct paper.  References Andreas Abel. Termination checking with types. RAIRO \nTheoretical Informatics and Applications, 38(4):277 319, 2004. Special Issue: Fixed Points in Computer \nScience (FICS 03). Andreas Abel, Thierry Coquand, and Peter Dybjer. Verifying a semantic \u00df.-conversion \ntest for Martin-L\u00f6f type theory. In Mathematics of Program Construction (MPC 08), volume 5133 of LNCS, \npages 29 56, 2008. Jean-Marc Andreoli. Logic programming with focusing proofs in linear logic. J. Logic \nand Computation, 2(3):297 347, 1992. Andrea Asperti, Wilmer Ricciotti, Claudio Sacerdoti Coen, and Enrico \nTassi. A bi-directional re.nement algorithm for the calculus of (co)inductive constructions. Logical \nMethods in Computer Science, 8(1), 2012.  Gavin M. Bierman, Erik Meijer, and Mads Torgersen. Lost in \ntranslation: formalizing proposed extensions to C .In OOPSLA, 2007. Luca Cardelli. An implementation \nof F<:. Research report 97, DEC/Compaq Systems Research Center, February 1993. Iliano Cervesato and Frank \nPfenning. A linear spine calculus. J. Logic and Computation, 13(5):639 688, 2003. Adam Chlipala, Leaf \nPetersen, and Robert Harper. Strict bidirec\u00adtional type checking. In Workshop on Types in Language Design \nand Impl. (TLDI 05), pages 71 78, 2005. Jacek Chrz . aszcz. Polymorphic subtyping without distributivity. \nIn Mathematical Foundations of Computer Science, volume 1450 of LNCS, pages 346 355. Springer, 1998. \nThierry Coquand. An algorithm for type-checking dependent types. Science of Computer Programming, 26(1 \n3):167 177, 1996. Luis Damas and Robin Milner. Principal type-schemes for func\u00adtional programs. In POPL, \npages 207 212. ACM, 1982. Rowan Davies and Frank Pfenning. Intersection types and compu\u00adtational effects. \nIn ICFP, pages 198 208, 2000. Joshua Dun.eld. AUni.ed System of Type Re.nements. PhD thesis, Carnegie \nMellon University, 2007. CMU-CS-07-129. Joshua Dun.eld. Greedy bidirectional polymorphism. In ML Workshop, \npages 15 26, 2009. http://www.cs.cmu.edu/ ~joshuad/papers/poly/. Joshua Dun.eld and Frank Pfenning. \nTridirectional typechecking. In POPL, pages 281 292, January 2004. Adam Gundry, Conor McBride, and James \nMcKinna. Type infer\u00adence in context. In Mathematically Structured Functional Pro\u00adgramming (MSFP), 2010. \nDidier Le Botlan and Didier R\u00e9my. MLF: raising ML to the power of System F. In ICFP, pages 27 38, 2003. \nDidier Le Botlan and Didier R\u00e9my. Recasting MLF . Information and Computation, 207:726 785, 2009. Daan \nLeijen. Flexible types: robust type inference for .rst-class polymorphism. In POPL, pages 66 77, 2009. \nAndres L\u00f6h, Conor McBride, and Wouter Swierstra. A tu\u00adtorial implementation of a dependently typed lambda \ncal\u00adculus. Unpublished draft, http://people.cs.uu.nl/andres/ LambdaPi/index.html, 2008. William Lovas. \nRe.nement Types for Logical Frameworks.PhD thesis, Carnegie Mellon University, 2010. CMU-CS-10-138. Dale \nMiller. Uni.cation under a mixed pre.x. J. Symbolic Compu\u00adtation, 14:321 358, 1992. John C. Mitchell. \nPolymorphic type inference and containment. Information and Computation, 76:211 249, 1988. Martin Odersky \nand Konstantin L\u00e4ufer. Putting type annotations to work. In POPL, 1996. Martin Odersky, Matthias Zenger, \nand Christoph Zenger. Colored local type inference. In POPL, pages 41 53, 2001. Simon Peyton Jones and \nMark Shields. Lexically scoped type variables. Technical report, Microsoft Research, 2004. Simon Peyton \nJones, Dimitrios Vytiniotis, Stephanie Weirich, and Mark Shields. Practical type inference for arbitrary-rank \ntypes. J. Functional Programming, 17(1):1 82, 2007. Frank Pfenning. Church and Curry: Combining intrinsic \nand ex\u00adtrinsic typing. In Reasoning in Simple Type Theory: Festschrift in Honor of Peter B. Andrews on \nHis 70th Birthday. College Publications, 2008. Brigitte Pientka. A type-theoretic foundation for programming \nwith higher-order abstract syntax and .rst-class substitutions. In POPL, pages 371 382, 2008. Benjamin \nC. Pierce and David N. Turner. Local type inference. ACM Trans. Prog. Lang. Sys., 22:1 44, 2000. Didier \nR\u00e9my. Extension of ML type system with a sorted equa\u00adtional theory on types. Research Report 1766, INRIA, \n1992. Didier R\u00e9my and Boris Yakobowski. From ML to MLF: graphic type constraints with ef.cient type inference. \nIn ICFP, pages 63 74, 2008. Robert J. Simmons. Structural focalization. arXiv:1109.6273v4 [cs.LO], 2012. \nJerzy Tiuryn and Pawel Urzyczyn. The subtyping problem for second-order types is undecidable. In LICS, \n1996. Dimitrios Vytiniotis, Stephanie Weirich, and Simon L. Peyton Jones. Boxy types: inference for higher-rank \ntypes and impred\u00adicativity. In ICFP, pages 251 262, 2006. Dimitrios Vytiniotis, Stephanie Weirich, and \nSimon L. Peyton Jones. FPH: First-class polymorphism for Haskell. In ICFP, pages 295 306, 2008. Dimitrios \nVytiniotis, Simon Peyton Jones, and Tom Schrijvers. Let should not be generalised. In Workshop on Types \nin Language Design and Impl. (TLDI 10), pages 39 50, 2010. Kevin Watkins, Iliano Cervesato, Frank Pfenning, \nand David Walker. A concurrent logical framework: The propositional fragment. In Types for Proofs and \nPrograms, pages 355 377. Springer-Verlag LNCS 3085, 2004. J. B. Wells. Typability and type checking in \nSystem F are equiv\u00adalent and undecidable. Annals of Pure and Applied Logic, 98: 111 156, 1999. Hongwei \nXi. Dependent Types in Practical Programming.PhD thesis, Carnegie Mellon University, 1998.  \n\t\t\t", "proc_id": "2500365", "abstract": "<p>Bidirectional typechecking, in which terms either synthesize a type or are checked against a known type, has become popular for its scalability (unlike Damas-Milner type inference, bidirectional typing remains decidable even for very expressive type systems), its error reporting, and its relative ease of implementation. Following design principles from proof theory, bidirectional typing can be applied to many type constructs. The principles underlying a bidirectional approach to polymorphism, however, are less obvious. We give a declarative, bidirectional account of higher-rank polymorphism, grounded in proof theory; this calculus enjoys many properties such as eta-reduction and predictability of annotations. We give an algorithm for implementing the declarative system; our algorithm is remarkably simple and well-behaved, despite being both sound and complete.</p>", "authors": [{"name": "Joshua Dunfield", "author_profile_id": "81100605091", "affiliation": "Max Planck Institute for Software Systems, Kaiserslautern and Saarbr&#252;cken, Germany", "person_id": "P4261293", "email_address": "joshua@mpi-sws.org", "orcid_id": ""}, {"name": "Neelakantan R. Krishnaswami", "author_profile_id": "81320491252", "affiliation": "Max Planck Institute for Software Systems, Kaiserslautern and Saarbr&#252;cken, Germany", "person_id": "P4261294", "email_address": "neelk@mpi-sws.org", "orcid_id": ""}], "doi_number": "10.1145/2500365.2500582", "year": "2013", "article_id": "2500582", "conference": "ICFP", "title": "Complete and easy bidirectional typechecking for higher-rank polymorphism", "url": "http://dl.acm.org/citation.cfm?id=2500582"}