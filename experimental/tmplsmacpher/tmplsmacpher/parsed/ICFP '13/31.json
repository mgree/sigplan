{"article_publication_date": "09-25-2013", "fulltext": "\n A Nanopass Framework for Commercial Compiler Development Andrew W. Keep R. Kent Dybvig University of \nUtah Cisco Systems Inc. akeep@cs.utah.edu dyb@cisco.com Abstract Contemporary compilers must typically \nhandle sophisticated high\u00adlevel source languages, generate ef.cient code for multiple hard\u00adware architectures \nand operating systems, and support source-level debugging, pro.ling, and other program development tools. \nAs a result, compilers tend to be among the most complex of software systems. Nanopass frameworks are \ndesigned to help manage this complexity. A nanopass compiler is comprised of many single\u00adtask passes \nwith formally de.ned intermediate languages. The per\u00adceived downside of a nanopass compiler is that the \nextra passes will lead to substantially longer compilation times. To determine whether this is the case, \nwe have created a plug replacement for the commercial Chez Scheme compiler, implemented using an updated \nnanopass framework, and we have compared the speed of the new compiler and the code it generates against \nthe original compiler for a large set of benchmark programs. This paper describes the up\u00addated nanopass \nframework, the new compiler, and the results of our experiments. The compiler produces faster code than \nthe origi\u00adnal, averaging 15 27% depending on architecture and optimization level, due to a more sophisticated \nbut slower register allocator and improvements to several optimizations. Compilation times average well \nwithin a factor of two of the original compiler, despite the slower register allocator and the replacement \nof .ve passes of the original 10 with over 50 nanopasses. Categories and Subject Descriptors D.3.4 [Programming \nLan\u00adguages]: Processors Translator writing systems and compiler generators General Terms Languages Keywords \nCompiler; Nanopass; Scheme 1. Introduction A compiler is typically structured as a series of passes, \neach ana\u00adlyzing source or intermediate code for an input program and possi\u00adbly producing new intermediate \ncode, with the .nal pass producing Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting \nwith credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, \nrequires prior speci.c permission and/or a fee. Request permissions from permissions@acm.org. ICFP 13, \nSeptember 25 27, 2013, Boston, MA, USA. Copyright is held by the owner/author(s). Publication rights \nlicensed to ACM. ACM 978-1-4503-2326-0/13/09. . . $15.00. http://dx.doi.org/10.1145/2500365.2500618 \n assembly or machine code for a target architecture. Historically, compilers employed no more than a \nfew passes, because each pass involved reading source or intermediate code from cards, tape, or disk. \nContemporary compilers, on the other hand, take advantage of large physical memories and virtual address \nspaces to keep intermediate representations in memory. At the same time, contemporary com\u00adpilers are \nsubstantially more complex, having been called upon to handle larger, higher-level source languages, \nto generate ef.cient code for multiple hardware architectures and operating systems, to support automatic \nstorage management, threading, and other run\u00adtime activities, and to support debugging, pro.ling, and \nother de\u00advelopment tools. While it might be possible to support the addi\u00adtional complexity with the same \nsmall number of passes, it is no longer important or desirable to do so. An attractive alternative is \nto separate a compiler into many, per\u00adhaps dozens, of single-task passes. This improves modularity, po\u00adtentially \nmaking the compiler easier to maintain and extend. Con\u00adstructing a compiler with many single-task passes, \nhowever, can require excessive boilerplate code to recur through unchanging forms, increasing compiler \nsize and thus failing to decrease main\u00adtenance and extension overhead. If intermediate languages are \nnot well speci.ed, having many passes also increases the risk of errors due to inconsistencies among \npasses. Ananopass framework is designed to address these challenges with a domain-speci.c language (DSL) \nthat supports formally de.ned intermediate languages, a convenient pattern matching syntax im\u00adplemented \nvia inexpensive record dispatch, and automatic genera\u00adtion of boilerplate code. When a paper on the .rst \nnanopass frame\u00adwork was accepted for ICFP 2004 [20], however, the program com\u00ad mittee required the authors \nto refocus the paper on education be\u00adcause they did not believe the nanopass methodology was suitable \nfor commercial compilers. They were principally concerned with the compile-time overhead of repeated \ntraversals. This concern was impossible to refute at the time because the prototype infrastructure and \nimplementation were not mature enough to put to the test. This paper describes a nanopass infrastructure \nthat is suitable for developing commercial compilers. To establish the infrastructure s suitability for \ncommercial compiler development, we set out to de\u00advelop a compiler that is 100% compatible with the existing \ncom\u00admercial Chez Scheme [5] compiler, produces code that is at least on par with the original compiler, \nand does so with compile times that are within a factor of two of the original compiler, despite our \nseparate ambition to incorporate a new, slower register allocator. An extensive test suite, used to test \nthe original compiler, is used to demonstrate the new compiler is compatible with the original, while \na large set of benchmarks is used to establish its performance. On the benchmarks, the new compiler produces \ncode that is 15 (define-language Lsrc (terminals (uvar (x)) (primitive (pr)) (datum (d))) (Expr \n(e body) (quote d) (if e0 e1 e2) (begin e* . . . e) (lambda (x* . . . ) body) (let ([x* e*] . . . ) \nbody) (letrec ([x* e*] . . . ) body) (set! x e) (pr e* . . . ) (call e e* . . . ) => (e e* . . . ))) \n Figure 1. The Lsrc language 27% faster than the original compiler, depending on architecture and optimization \nlevel, with compile times that are well within the factor of two budget. This paper is organized as follows. \nSection 2 describes the new nanopass framework and compares it with the original framework. Section 3 \ndescribes the differences between the new and origi\u00ad nal Chez Scheme compiler. Section 4 evaluates the \nrun-time and compile-time performance of the new compiler against the original compiler. Section 5 presents \nrelated work, and Section 6 concludes. 2. The nanopass framework A nanopass framework is a domain-speci.c \nlanguage (DSL) for writing compilers. It provides two main syntactic forms: define-language for formally \nde.ning the intermediate-language grammars and define-pass for specifying passes that operate over these \nintermediate languages. Formally de.ning the interme\u00addiate languages allows the framework to .ll in boilerplate \ncode in passes, permits passes to check that output-language terms are well formed, and allows the framework \nto represent language terms as records internally while maintaining an S-expression pattern\u00admatching \nand template-construction syntax. The new nanopass framework builds on the prototype described by Sarkar \net al. [20]. This section brie.y describes the new framework and differences between this framework and \nthe prototype. More information can be found in the .rst author s dissertation [14]. Examples are extracted \nfrom a student compiler used in a course on compiler implementation, since the Chez Scheme compiler is \nnot open-source. 2.1 De.ning languages Languages de.nitions are similar to context-free grammars, in \nthat they are composed of a set of terminals, a set of nonterminal symbols, a set of productions for \neach nonterminal, and a start symbol. An intermediate language de.nition for a simple variant of the \nScheme programming language, post macro expansion, might look like Lsrc in Figure 1. The Lsrc language \nconsists of three terminals (listed in the terminals form) and a single nonterminal. For each terminal, \nthe compiler writer must supply a correspond\u00ading predicate. The framework adds a ? to the terminal name \nto de\u00adtermine the predicate name. In this case, the nanopass framework expects uvar?, primitive?, and \ndatum? to be lexically visible (define-language L1 (extends Lsrc) (terminals (-(datum (d))) (+ (constant \n(c)))) (Expr (e body) (-(quote d)) (+ (quote c)))) Figure 2. The L1 language where Lsrc is de.ned. \nEach terminal clause lists one or more meta\u00advariables, used to refer to the terminal in nonterminal productions. \nFor instance, x refers to a uvar. The Lsrc language declares the nonterminal Expr. Nonterminals specify \na name, a set of meta-variables, and a set of grammar productions. The Expr nonterminal has two meta-variables, \ne and body. These meta-variables, like the terminal meta-variables, are used to represent the nonterminal \nin a production. Productions follow one of three forms: a single meta-variable, an S\u00adexpression that \nstarts with a keyword, or an S-expression that does not start with a keyword (referred to as an implicit \nproduction). Productions cannot include keywords past the initial keyword. The x production is the only \nsingle-meta-variable production and indicates that a uvar is an Expr. The only implicit S-expression \nproduction is (pr e* . . . ), which speci.es a primitive call with zero or more arguments. (The . . . \nfollowing e* indicates that e* contains a list of Expr, the * suf.x is used by convention to indicate \nplurality.) The (call e e* . . . ) production indicates a procedure call, and the call keyword differentiates \nit from a primitive call production. The => (e e* . . . ) syntax indicates a pretty form for the production. \nThe define-language form de.nes an unparser, and the unparser uses the pretty form when unparsing this \nproduction. The remaining productions correspond to the Scheme syntax that they represent. 2.2 Extending \nlanguages The .rst pass of our student compiler is a simple expander that produces Lsrc language forms \nfrom S-expressions. The next pass expands complex quoted datum constants into code to construct these \nconstants at load time. The compiler writer could fully specify the output language, as we did with Lsrc. \nFully specifying each language, however, results in verbose source code, particularly in a compiler with \nmany inter\u00admediate languages. To avoid this, the framework supports a lan\u00adguage extension form that succinctly \ndescribes only changes from one language to another. Figure 2 shows the output language. The L1 language \nremoves the datum terminal and replaces it with the constant terminal. It also replaces the (quote d) \nproduction with a (quote c) production to indicate that only constants are allowed in the quote form.1 \nThe extends clause indicates a lan\u00adguage extension form. Terminals are removed using the -clause and \nadded using the + clause. Productions in a nonterminal are also removed using the -clause and added using \nthe + clause. 2.3 De.ning passes The pass in Figure 3 converts an input program from the Lsrc intermediate \nlanguage to the L1 intermediate language. This pass 1If we failed to replace the (quote d) form, it would \nresult in an error, since the d meta-variable is not bound in the new language. (define-pass convert-complex-datum \n: Lsrc (x) -> L1 () (definitions (define const-x* ()) (define const-e* ()) (define datum->expr (with-output-language \n(L1 Expr) (lambda (d) (cond [(pair? d) (cons ,(datum->expr (car d)) ,(datum->expr (cdr d)))] [(vector? \nd) (let ([n (vector-length d)]) (if (fxzero? n) (make-vector (quote 0)) (let ([t (unique-name t)]) \n(let ([,t (make-vector (quote ,n))]) (begin ,(map (lambda (i v) (vector-set! ,t (quote ,i) ,(datum->expr \nv))) (iota n) (vector->list d)) . . . ,t)))))] [else (quote ,d)]))))) (Expr : Expr (ir) -> Expr () [(quote \n,d) (guard (not (constant? d))) (let ([t (unique-name t)]) (set! const-x* (cons t const-x*)) (set! const-e* \n(cons (datum->expr d) const-e*)) t)]) (let ([x (Expr x)]) (if (null? const-x*) x (let ([,const-x* ,const-e*] \n. . . ) ,x)))) Figure 3. The convert-complex-datum pass removes the structured quoted datum by making \nthe construction of the data explicit. To avoid constructing these constants more than once at run time, \nthe pass also lifts datum creation to the start of the program. A pass de.nition starts with a name and \na signature. The signature speci.es the input language (in this case, Lsrc)and list of formals (x)followed \nby the output language (L1)and a list of extra return expressions (()). Following the name and signature, \nthis pass speci.es de.nitions for const-x*, const-e*, and datum->expr in the definitions clause. These \nde.nitions are scoped at the same level as the trans\u00adformers in the pass. The const-x* and const-e* variables \nare initialized to null. The const-x* is extended with a new uvar and const-e* is extended with a new \nExpr each time a structured quoted datum is encountered. The datum->expr procedure recur\u00adsively processes \na structured quoted datum and produces the L1 Expr needed to construct it. Recursion terminates when \na quoted constant is found. Next, a transformer from the input nonterminal Expr to the output nonterminal \nExpr is de.ned. The transformer is named Expr and has a signature similar to that of the pass, with an \ninput-language nonterminal and list of formals followed by the output-language nonterminal and list of \nextra-return-value expressions. The transformer has a single clause that matches a quoted datum and uses \na guard to ensure it is a pair or a vector. The define-pass macro autogenerates clauses matching the \nother input-language forms and producing equivalent output-language forms. Each user-supplied clause \nconsists of an input pattern, an optional guard clause, and one or more expressions that specify zero \nor more return values. The input pattern is derived from the pro\u00adductions speci.ed in the input language. \nPattern variables are un\u00adquoted, i.e., preceded by ,. For instance, the clause for the quote production \nmatches the pattern (quote ,d) and binds d to the datum speci.ed by the quote form. The output-language \nexpression is constructed using a quasiquoted template. In the example, the quoted output-language expression \nis in the datum->expr procedure. Here, quasiquote, ( ), is re\u00adbound to a form that constructs language \nforms based on the tem\u00adplate, and unquote (,), is used to escape back into Scheme. The ,(datum->expr \n(car d)) thus puts the result of the recursive call to datum->expr into the output-language (cons ,e0, \ne1) form. Following the Expr transformer is the body of the pass, which calls Expr to transform the Lsrc \nExpr term into an L1 Expr term and wraps the result in a let expression if any structured quoted datums \nare found in the program that is being compiled. 2.4 Comparison with the prototype nanopass framework \nThe prototype nanopass framework demonstrated that a nanopass framework is a viable approach to writing \ncompilers, but only the .rst half of the student compiler was ever implemented using the framework. As \nsuch, the prototype framework has some rough edges that needed to be smoothed out in order to implement \na replacement for the Chez Scheme compiler. The new nanopass framework focused on improvements in two \nareas, usability and performance. On the usability side, the new nanopass framework introduces new features \nand improves error reporting. In the new framework, language de.nitions are no longer restricted to the \ntop-level and can appear anywhere a Scheme de.nition can appear. Passes can be de.ned without an input \nlanguage or output language, allow\u00ading a pass to take a non-language term as input or generate a non-language \nterm as output. This allows passes to create gen\u00aderal parsers, predicates, and code generators. Passes \ncan also take additional arguments and return additional values, allowing infor\u00admation to .ow through \na pass without being encoded in the lan\u00adguage term. Language terms can be constructed outside of a pass \nusing the with-output-language form, as shown in Figure 3 and matched outside a pass using the nanopass-case \nform. The cata\u00admorphisms [17] syntax, used to recur on a sub-form of a language term in a pattern, supports \npassing extra arguments to transformers expecting more than one argument. Error reporting has been improved, \nboth to make messages eas\u00adier to understand and to include source information for where the error occurred. \nLanguage de.nitions perform better checking, e.g., ensuring meta-variables are not repeated, removed \nproduc\u00adtions existed in the base language, and the .elds of a production are uniquely named. On the performance \nside, the new nanopass framework uses an integer tag to perform pattern matching, which is slightly faster \nthan the record dispatch previously used. In transformers, the order of clauses is respected, so that \nprogrammers can place clauses that are more likely to match .rst. The new framework also generates less \ncode, so compiling a compiler generated with the nanopass framework is faster. 3. The new Chez Scheme \ncompiler Chez Scheme is a commercial Scheme compiler for R6RS Scheme with extensions, .rst released in \n1985 [5] and under continuous development and improvement since. The compiler is written in Scheme and \nis comprised of 10 large, multipurpose passes. The compiler is almost absurdly fast, able to compile \nits own source code in roughly three seconds on contemporary hardware. The compiler is also designed \nto generate ef.cient code. 3.1 Workings of the existing Chez Scheme compiler The compiler begins with \na syntax-case expander, extended with a module system and R6RS libraries [6, 8, 12, 23]. The expander \nproduces a simpli.ed core language with letrec, letrec*, and case-lambda as binding forms, quoted constants, \nprimitive refer\u00adences, procedure calls, variable references, and a handful of other forms. The .rst pass \nrecords source information used for debug\u00adging and pro.ling. The next pass places validity checks for \nvari\u00adable references bound by letrec and letrec* [13, 24]. The next pass is the source optimizer [22] \nand can be run one or more times or not at all, depending on the options set in the compiler. A pass \nfor handling letrec and letrec* [13, 24] is run at least once and is run after each run of the source \noptimizer. After this, either the interpreter is invoked to interpret the program or the back-end compiler \nis invoked to .nish compilation and either execute the re\u00adsulting code or write the machine code to the \n.le system. When the back-end compiler is invoked, the code is still in roughly the same form as the \ninput language, although letrec* has been eliminated and letrec bindings bind only unassigned variables \nto case-lambda expressions. The compiler performs assignment conversion, closure conversion, various \noptimizations, and further code simpli.cations and replaces primitives in the source language with an \ninternal set of simpler, although still higher level than as\u00adsembly language, primitives. It also performs \nregister allocation us\u00ading a linear-scan style register allocator with a lazy register save and restore \nstrategy [3], and generates code using destination-driven code generation [7]. The back end consists \nof .ve passes. The .rst pass, cp1, begins the process of closure conversion, recognizes loops, recognizes \ndirect application of .-expressions, begins handling multiple return value calls, sets up the foreign \nand foreign callable expressions, and con\u00adverts primitive calls into a set of slightly lower-level inline \ncalls. The next pass, cpr0, begins the register allocation process, deter\u00admines the actual free variables \nof closures after performing closure optimization, performs assignment conversion, makes explicit all \narguments to inlined primitives, and .ags tail calls and loops. The register allocator reserves the architectural \nstack register, a Scheme frame pointer register, a thread context register pointer, and at least two \ntemporary registers, depending on the target machine architec\u00adture, for use by the assembler. After this, \nthe pass cpr1 assigns variables to their initial register homes. The cpr2 pass .nishes reg\u00adister allocation, \ngenerating register saves and restores across non\u00adtail calls and removing redundant register bindings. \nFinally, the cp2 pass .nishes compilation, converting the higher-level inlined prim\u00aditives into a set \nof high-level instruction inlines that the assembler can convert into machine instructions for the target \nplatform. Each of these back-end passes performs several optimizations in addition to those mentioned \nabove, and some optimizations span multiple passes.  3.2 Workings of the new compiler The new compiler \nstarts with the same set of front-end passes, updated to use the nanopass framework. The back end of \nthe new compiler diverges signi.cantly from that of the original compiler. Where the original compiler \nis structured as a set of multipurpose passes that each performs several tasks, the new compiler is organized \nas approximately 50 passes, with each pass completing primarily one task, using approximately 35 nanopass \nlanguages. These passes implement most of the optimizations from the orig\u00adinal compiler and improve on \nsome, including support for im\u00adplicit cross-library optimization, improvements to closure opti\u00admization \n[15], and improved handling of procedures that return multiple values. The other big difference between \nthe original compiler and the new compiler is the use of a graph-coloring register allocator. This change \nnecessitated several other changes in the compiler, including the expansion of code into a near-assembly \nlanguage form much earlier in the compiler, so that all of the temporaries that might be needed for the \n.nal code to conform to the operand requirements of the machine can be met. It also means that a full \nlive analysis must be performed to compute the con.ict graph needed by the register allocator. In the \noriginal compiler, the cost of the live analysis is largely avoided by tracking the liveness of registers, \nrather than the liveness of variables. Additionally, in the original compiler, primitive expansion is \ndelayed until code generation at the cost of reserving two or more registers, depending on the target \narchitecture. The bene.t of using a graph-coloring register allocator is that it packs spilled variables \ntighter on the frame, makes better use of registers, and generally produces more compact code. The new \nregister allocator also uses move biasing to avoid frame-to-frame moves. This contributes to the generated \ncode s faster run time, at the cost of substantially more compile-time overhead. Both the original and \nnew compilers try to make good use of variable saves and restores around non-tail calls, allowing call-live \nvariables to be accessed from a register, rather than from the frame. The original compiler follows a \nlazy-save strategy [3], while the new compiler attempts to get similar results by using a heuristic that \nestimates the cost of saving and restoring versus the cost of spilling to a frame location permanently. \nThis is one place where the new compiler sometimes underperforms the original compiler. Not all of the \noptimizations provided by the original compiler are provided by the new compiler. The most signi.cant \nmissing optimization is block allocation of closures. When several closures are created at the same time, \na single allocation is performed to allocate the space for the entire group of closures. A more general \nblock allocation optimization is planned for the new compiler but has not yet been implemented. 3.3 \nEnsuring compatibility Over the course of Chez Scheme s development, an extensive suite of unit, functional, \nand regression tests has been developed to ensure that the compiler conforms to the relevant Scheme standards \nand documentation for Chez Scheme extensions. Chez Scheme is also bootstrapped, and the .rst test of \nthe compiler is to compile itself and verify that code generated for the compiler is consistent with \neach run of the compiler. The new compiler passes all of these tests. 4. Evaluation of the new Chez Scheme \ncompiler 4.1 Comparing the speed of generated code We compare the performance of the original and new \ncompilers on a set of benchmarks that includes the R6RS benchmarks [4]; a set of benchmarks, including \nsome larger benchmarks, used to test the source optimizer; and a set of additional benchmarks used for \nperformance regression testing. The benchmark data was generated on an Intel Core i7-3960X with two \nCPUs, six cores per CPU, and 64 GB of RAM. The tests were conducted at both optimize level 2 (run-time \ntype-checking enabled) and optimize level 3 (run-time type-checking disabled), using both the 32-bit \nand 64-bit instruction sets. Table 1 shows the average improvement in run time for benchmarks compiled \nwith the new compiler over the original compiler. In the worst case, optimize level 3 with the 64-bit \ninstruction set, the benchmarks still run 15.0% faster on average. x86 machine x86 64 machine Optimize \nLevel 2 26.6% 22.0% Optimize Level 3 22.3% 15.0% Table 1. Average improvement in benchmark run times \nTwo of the benchmarks, similix, a self-applicable partial eval\u00aduator, and softscheme, a benchmark that \nperforms soft typing, make use of the compiler during the run of the benchmark. This negatively affects \nthe run time of these benchmarks and the overall average. Table 2 shows the normalized run time of these \nbench\u00ad marks on both the 32-bit and 64-bit versions of the compiler and at both optimization levels. \nOpt. level Machine type Similix Soft Scheme 2 x86 1.54 1.27 2 x86 64 1.41 1.32 marks, is the graph-coloring \nregister allocator. The graph-coloring register allocator makes more ef.cient use of available registers, \nwhich is particularly helpful on the 32-bit Intel target, where only eight registers are available. \n 4.2 Comparing compilation speed We set out with the goal of implementing a new compiler that ran within \na factor of two of the original compiler. The extra compile-time budget was intended to allow the more \nexpensive graph-coloring register allocator to be incorporated into the new compiler. Ideally, we would \nhave created a nanopass compiler as near in function to old compiler as possible for apples-to-apples \ncompile-time comparisons, but we did not have the resources to create two new compilers. The two compilers \nwere tested by compiling each benchmark .ve times and averaging compile times. The compile times are \nnormal\u00adized, using the original compiler as a base. Table 3 presents the normalized numbers by machine \ntype and optimization level. In the worst case (the 64-bit version at optimize level 2) the average compile \ntime is a factor of 1.75 longer on the new compiler than on the original compiler. This time is well \nwithin our factor of two goal. Nevertheless, further tuning is still possible and will make the compile \ntimes for the new compiler even closer to those of the original compiler. x86 machine x86 64 machine \nOptimize Level 2 1.71 1.75 Optimize Level 3 1.64 1.71 Table 3. Normalized compile times of benchmarks \n The compile time varies from one benchmark to another. On the 32-bit version, the normalized time ranges \nfrom a factor of 1.00 to 4.44 at optimize level 2 and 0.968 to 3.13 at optimize level 3. On the 64-bit \nversion, normalized time ranges from a factor of 1.00 to  4.73 at optimize level 2 and 1.00 to 3.80 \nat optimize level 3. It is natural to assume that the variance in compile times is related to the increased \ncomputational complexity of the graph-coloring register allocator; however, this does not seem to be \nthe case. Figure 4 shows the normalized times versus the lines of expanded source code. The number of \nlines of expanded source code is determined by pretty printing the results of the expander run on each \nbenchmark and then counting the number of line breaks. Overall, there does not seem to be a direct relationship \nbetween the number of lines of expanded code and the normalized compile time. An understanding of why \nthis occurs might lead to overall improvements in compile time. Figure 4. Normalized compile time vs. \nexpanded source code size 5. Related work Stratego/XT [2] is a DSL for writing source-to-source transforma\u00adtions. \nIt provides a set of combinators for matching and rebuilding abstract syntax tree (AST) forms as well \nas strategies for perform\u00ading different traversals of the AST. Pattern matching and AST con\u00adstruction \nin Stratego is different from that in the nanopass frame\u00adwork, because if construction of an AST fails, \nthe next pattern will be tried, whereas the nanopass framework makes a committed (deterministic) choice \nwith explicit guards for extra-grammatical checks, which simpli.es debugging and improves compiler speed. \nThe JastAdd [9] system allows for the construction of modular and extensible compilers using Java s object-oriented \nclass hierarchy, along with an external DSL to specify the AST and analysis and transformations on the \nAST. Each type of node in the AST has an associated class that encapsulates the transformations on the \nnode type. Method dispatch and aspects are used with the visitor pattern to implement passes instead \nof pattern matching. SableCC [11] is a system for building compilers and interpreters in Java. It provides \na set of tools for writing the lexer and parser for the language and a method for de.ning multiple passes. \nSimilar to JastAdd, it works on an AST represented by Java classes. Also similar to JastAdd, it uses \nthe visitor pattern to implement the language transformations. POET combines a transformation language \nand an empirical testing system to allow transformation to be tuned [26]. Although POET allows for some \ngeneric manipulation of an AST, it is largely focused on targeting speci.c regions of source code to \nbe tuned. It can parse fragments of source code and operate on the AST fragment, preserving unparsed \ncode across the transformation. The ROSE [18] compiler infrastructure provides a C++ library for source-to-source \ntransformation, along with front-ends and back\u00adends for both C/C++ and Fortran. Internally, ROSE represents \nsource code using the ROSE Object-Oriented IR, with transforma\u00adtions written in C++. Although there is \nnothing speci.c that ties the ROSE transformation framework to C/C++ or Fortran, there are no tools to \neasily add new front-ends and back-ends, limiting the use\u00adfulness of ROSE for other languages. The Rhodium \nframework takes a different approach from the other tools described here. Instead of using term rewriting, \nRhodium bases transformations on data-.ow equations and provides a frame\u00adwork for proving the soundness \nof transformations [16, 21]. The framework has also been extended to support inferring optimiza\u00adtions \nfrom the data-.ow semantics de.ned by the compiler writer. The data-.ow facts are de.ned over a C-like \nintermediate represen\u00adtation. This might be a good complement to the nanopass frame\u00adwork. CodeBoost [1] \nis a more targeted tool. Although it was originally developed to support the Sophus numerical library, \nCodeBoost provides a simple way to write compiler transformations within C++ code. It is implemented \nusing Stratego but provides an array of tools to make writing C++ code transformations easier. The template-based \nmetacompiler (Tm) [19] provides a macro lan\u00ad guage, similar to M4, for generating data structures and \ntransforma\u00adtions that can be expanded in a language agnostic way. Tm provides tree-walker and analyzer \ntemplates and an existing C back-end for easier use. Pavilion [25] is a DSL for writing analysis and \noptimization passes to improve the ef.ciency of generic programming in C++. The declarative language \nextends regular expressions with intersection and complement operators, variable quanti.cation, path \nquanti.ca\u00adtion, function de.nition, and native language access to Scheme to provide powerful matching \nduring analysis and transformation. Yoko [10] is a Haskell module for writing functions that transform \nan input type to a similar output type that requires only the inter\u00adesting cases be speci.ed, similar \nto how the nanopass framework operates over languages. The module builds on generic program\u00adming techniques \nto provide the hcompos function. The hcompos function takes the user-speci.ed cases and autogenerates \nthe nec\u00adessary clauses to handle constructors from the input type not spec\u00adi.ed by the programmer, matching \nthem with constructors of the output type with the same name. 6. Conclusion The new Chez Scheme compiler \ndemonstrates that a nanopass com\u00adpiler can perform on par with a more traditionally structured com\u00adpiler. \nDespite a more expensive register allocator and the replace\u00adment of the .ve back-end passes of the original \n10 passes in the compiler with around 50 nanopasses, the new compiler still av\u00aderages compile times that \nare within a factor of two of the origi\u00adnal compiler. The new compiler also generates more ef.cient code, \nshowing between a 15% and 26.6% improvement on a set of bench\u00admarks, depending on the optimize level \nand the target architecture. The new nanopass framework made it easier to implement the new compiler \nand will make it easier to maintain and extend in the fu\u00adture. Acknowledgments Different parts of Keep \ns effort on this work were partially sup\u00adported by the DARPA programs APAC and CRASH. Comments from Dan \nFriedman, Ryan Newton, and the anonymous reviewers led to several improvements in this papers presentation. \nReferences [1] O. S. Bagge, K. T. Kalleberg, M. Haveraaen, and E. Visser. Design of the CodeBoost transformation \nsystem for domain\u00adspeci.c optimisation of C++ programs. In D. Binkley and P. Tonella, editors, Proc. \n3rd International Workshop on Source Code Analysis and Manipulation, SCAM 03, pages 65 75, Amsterdam, \nSept. 2003. IEEE Computer Society Press. URL http://www.codeboost.org/papers/codeboost-scam03.pdf . [2] \nM. Bravenboer, K. T. Kalleberg, R. Vermaas, and E. Visser. Strat\u00adego/XT 0.17. A language and toolset \nfor program transformation. Sci\u00adence of Computer Programming, 72(1 2):52 70, June 2008. URL http://dx.doi.org/10.1016/j.scico.2007.11.003 \n. [3] R. G. Burger, O. Waddell, and R. K. Dybvig. Register allocation using lazy saves, eager restores, \nand greedy shuf.ing. In Proc. ACM SIGPLAN 1995 Conference on Programming Language Design and Implementation, \nPLDI 95, pages 130 138, New York, 1995. ACM. URL http://doi.acm.org/10.1145/207110.207125 . [4] W. D. \nClinger. Description of benchmarks, 2008. URL http://www.larcenists.org/benchmarksAboutR6.html . [5] \nR. K. Dybvig. Chez Scheme Version 8 User s Guide. Cadence Research Systems, 2009. [6] R. K. Dybvig. The \nScheme Programming Language. MIT Press, fourth edition, 2009. [7] R. K. Dybvig, R. Hieb, and T. Butler. \nDestination-driven code gener\u00adation. Technical Report TR302, Indiana University, February 1990. [8] R. \nK. Dybvig, R. Hieb, and C. Bruggeman. Syntactic abstraction in Scheme. LISP and Symbolic Computation, \n5(4):295 326, Dec. 1992. URL http://dx.doi.org/10.1007/BF01806308 . [9] T. Ekman and G. Hedin. The JastAdd \nsystem modular extensible compiler construction. Science of Computer Programming, 69(1-3): 14 26, Dec. \n2007. . [10] N. Frisby, A. Gill, and P. Alexander. A pattern for almost homomor\u00adphic functions. In ACM \nSIGPLAN Workshop on Generic Program\u00adming, 09/2012 2012. [11] E. Gagnon and L. Hendren. SableCC, an object-oriented \ncompiler framework. In Proc. 26th Conference on Technology of Object-Oriented Languages, TOOLS 98, pages \n140 154, 1998. . [12] A. Ghuloum and R. K. Dybvig. Implicit phasing for R6RS libraries. In Proc. 12th \nACM SIGPLAN International Conference on Functional Programming, pages 303 314, New York, 2007. ACM. [13] \nA. Ghuloum and R. K. Dybvig. Fixing letrec (reloaded). In Proc. 2009 Workshop on Scheme and Functional \nProgramming, Scheme 09, pages 57 65, 2009. [14] A. W. Keep. A Nanopass Framework for Commercial Compiler \nDevelopment. PhD thesis, Indiana University, Feb. 2013. [15] A. W. Keep, A. Hearn, and R. K. Dybvig. \nOptimizing closures in O(0) time. In Proc. 2012 Workshop on Scheme and Functional Programming, Scheme \n12, 2012. [16] S. Lerner, T. Millstein, E. Rice, and C. Chambers. Au\u00adtomated soundness proofs for data.ow \nanalyses and transfor\u00admations via local rules. In Proc. 32nd ACM SIGACT-SIGPLAN Symposium on Principles \nof Programming Languages, POPL 05, pages 364 377, New York, 2005. ACM. URL http://doi.acm.org/10.1145/1040305.1040335 \n. [17] E. Meijer, M. M. Fokkinga, and R. Paterson. Functional pro\u00adgramming with bananas, lenses, envelopes \nand barbed wire. In Proc. 5th ACM Conference on Functional Programming Lan\u00adguages and Computer Architecture, \npages 124 144, London, UK, 1991. Springer-Verlag. ISBN 3-540-54396-1. URL http://dl.acm.org/citation.cfm?id=645420.652535 \n. [18] D. Quinlan, M. Schordan, Q. Yi, and B. R. de Supinski. Semantic\u00addriven parallelization of loops \noperating on user-de.ned containers. In Lecture Notes in Computer Science, volume 2958/2004 of Lecture \nNotes in Computer Science, pages 524 538. Springer Berlin / Heidel\u00adberg, 2004. [19] C. V. Reeuwijk. Tm: \nA code generator for recursive data structures. Software: Practice and Experience, 22(10):899 908, Oct. \n1992. URL http://dx.doi.org/10.1002/spe.4380221008 . [20] D. Sarkar, O. Waddell, and R. K. Dybvig. A \nnanopass in\u00adfrastructure for compiler education. In Proc. 9th ACM SIG-PLAN International Conference on \nFunctional Programming, ICFP 04, pages 201 212, New York, 2004. ACM. URL http://doi.acm.org/10.1145/1016850.1016878 \n. [21] E. R. Scherpelz, S. Lerner, and C. Chambers. Automatic inference of optimizer .ow functions from \nsemantic meanings. In Proc. 2007 ACM SIGPLAN Conference on Programming Language Design and Implementation, \nPLDI 07, pages 135 145, New York, 2007. ACM. URL http://doi.acm.org/10.1145/1250734.1250750 . [22] O. \nWaddell and R. K. Dybig. Fast and effective procedure inlining. In Proc. 4th International Symposium \non Static Analysis, SAS 97, pages 35 52, London, 1997. Springer-Verlag. [23] O. Waddell and R. K. Dybvig. \nExtending the scope of syn\u00adtactic abstraction. In Proc. 26th ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Languages, POPL 99, pages 203 215, New York, 1999. ACM. URL http://doi.acm.org/10.1145/292540.292559 \n. [24] O. Waddell, D. Sarkar, and R. K. Dybvig. Fixing letrec: A faithful yet ef.cient implementation \nof Scheme s recursive binding construct. Higher-order and Symbolic Computation, 18(3/4):299 326, Decem\u00adber \n2005. [25] J. J. Willcock. A Language for Specifying Compiler Optimizations for Generic Software. Doctoral \ndissertation, Indiana University, Bloom\u00adington, Indiana, USA, Dec. 2008. [26] Q. Yi, K. Seymour, H. You, \nR. Vuduc, and D. Quinlan. POET: Parameterized optimizations for empirical tuning. Technical Report CS-TR-2006-006, \nUniversity of Texas -San Antonio, 2006. URL http://www.cs.utsa.edu/{~ }qingyi/papers/poet-lang.pdf . \n \n\t\t\t", "proc_id": "2500365", "abstract": "<p>Contemporary compilers must typically handle sophisticated high-level source languages, generate efficient code for multiple hardware architectures and operating systems, and support source-level debugging, profiling, and other program development tools. As a result, compilers tend to be among the most complex of software systems. Nanopass frameworks are designed to help manage this complexity. A nanopass compiler is comprised of many single-task passes with formally defined intermediate languages. The perceived downside of a nanopass compiler is that the extra passes will lead to substantially longer compilation times. To determine whether this is the case, we have created a plug replacement for the commercial Chez Scheme compiler, implemented using an updated nanopass framework, and we have compared the speed of the new compiler and the code it generates against the original compiler for a large set of benchmark programs. This paper describes the updated nanopass framework, the new compiler, and the results of our experiments. The compiler produces faster code than the original, averaging 15-27% depending on architecture and optimization level, due to a more sophisticated but slower register allocator and improvements to several optimizations. Compilation times average well within a factor of two of the original compiler, despite the slower register allocator and the replacement of five passes of the original 10 with over 50 nanopasses.</p>", "authors": [{"name": "Andrew W. Keep", "author_profile_id": "81392616901", "affiliation": "University of Utah, Salt Lake City, UT, USA", "person_id": "P4261274", "email_address": "akeep@cs.utah.edu", "orcid_id": ""}, {"name": "R. Kent Dybvig", "author_profile_id": "81100181541", "affiliation": "Cisco Systems Inc., Research Triangle Park, NC, USA", "person_id": "P4261275", "email_address": "dyb@cisco.com", "orcid_id": ""}], "doi_number": "10.1145/2500365.2500618", "year": "2013", "article_id": "2500618", "conference": "ICFP", "title": "A nanopass framework for commercial compiler development", "url": "http://dl.acm.org/citation.cfm?id=2500618"}