{"article_publication_date": "09-25-2013", "fulltext": "\n Handlers in Action Ohad Kammar Sam Lindley Nicolas Oury University of Cambridge University of Strathclyde \nnicolas.oury@gmail.com ohad.kammar@cl.cam.ac.uk Sam.Lindley@ed.ac.uk Abstract Plotkin and Pretnar s \nhandlers for algebraic effects occupy a sweet spot in the design space of abstractions for effectful \ncomputation. By separating effect signatures from their implementation, alge\u00adbraic effects provide a \nhigh degree of modularity, allowing pro\u00adgrammers to express effectful programs independently of the con\u00adcrete \ninterpretation of their effects. A handler is an interpretation of the effects of an algebraic computation. \nThe handler abstraction adapts well to multiple settings: pure or impure, strict or lazy, static types \nor dynamic types. This is a position paper whose main aim is to popularise the handler abstraction. We \ngive a gentle introduction to its use, a col\u00adlection of illustrative examples, and a straightforward \noperational semantics. We describe our Haskell implementation of handlers in detail, outline the ideas \nbehind our OCaml, SML, and Racket implementations, and present experimental results comparing han\u00addlers \nwith existing code. Categories and Subject Descriptors D.1.1 [Applicative (Func\u00adtional) Programming]; \nD.3.1 [Formal De.nitions and Theory]; D.3.2 [Language Classi.cations]: Applicative (functional) lan\u00adguages; \nD.3.3 [Language Constructs and Features]; F.3.2 [Se\u00admantics of Programming Languages]: Operational semantics \nKeywords algebraic effects; effect handlers; effect typing; mon\u00adads; continuations; Haskell; modularity \n1. Introduction Monads have proven remarkably successful as a tool for abstrac\u00adtion over effectful computations \n[4, 30, 46]. However, monads as a programming language primitive violate the fundamental encapsu\u00adlation \nprinciple: program to an interface, not to an implementation. Modular programs are constructed using \nabstract interfaces as building blocks. This is modular abstraction. To give meaning to an abstract interface, \nwe instantiate it with a concrete implemen\u00adtation. Given a composite interface, each sub-interface can \nbe in\u00addependently instantiated with different concrete implementations. This is modular instantiation. \nThe monadic approach to functional programming takes a con\u00adcrete implementation rather than an abstract \ninterface as primitive. For instance, in Haskell we might de.ne a state monad: Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. Copyrights for components of this work owned by others than the \nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to \npost on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. Request \npermissions from permissions@acm.org. ICFP 13, September 25 27, 2013, Boston, MA, USA. Copyright is held \nby the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-2326-0/13/09. . . $15.00. \nhttp://dx.doi.org/10.1145/2500365.2500590 newtype State s a = State {runState :: s . (a, s)} instance \nMonad (State s) where return x = State (.s . (x, s)) m > = f = State (.s . let (x, s') = runState m s \nin runState (f x) s') This de.nition says nothing about the intended use of State s a as the type of \ncomputations that read and write state. Worse, it breaks abstraction as consumers of state are exposed \nto its concrete implementation as a function of type s . (a, s). We can of course de.ne the natural get \nand put operations on state, but their implementations are .xed. Jones [18] advocates modular abstraction \nfor monads in Haskell using type classes. For instance, we can de.ne the following inter\u00adface to abstract \nstate computation1: class Monad m . MonadState s m | m . s where get :: m s put :: s . m () The MonadState \ninterface can be smoothly combined with other interfaces, taking advantage of Haskell s type class mechanism \nto represent type-level sets of effects. Monad transformers [25] provide a form of modular instantia\u00adtion \nfor abstract monadic computations. For instance, state can be handled in the presence of other effects \nby incorporating a state monad transformer within a monad transformer stack. A fundamental problem with \nmonad transformer stacks is that once a particular abstract effect is instantiated, the order of effects \nin the stack becomes concrete, and it becomes necessary to explic\u00aditly lift operations through the stack. \nTaming the monad transformer stack is an active research area [16, 17, 38, 42]. Instead of the top-down \nmonad transformer approach, we take a bottom-up approach, simply adding the required features as lan\u00adguage \nprimitives. We want modular abstraction, so we add abstract effect interfaces, in fact abstract operations, \nas a language prim\u00aditive. Abstract operations compose, yielding modular abstraction. We also want modular \ninstantiation, so we add effect handlers as a language primitive for instantiating an abstract operation \nwith a concrete implementation. A handler operates on a speci.ed subset of the abstract operations performed \nby an abstract computation, leaving the remainder abstract, and yielding modular instantiation. By directly \nadding the features we require, we obtain modular abstraction and modular instantiation while avoiding \nmany of the pitfalls of monad transformers. Our .rst inspiration is the algebraic theory of computational \neffects. Introduced by Plotkin and Power [33 35], it complements Moggi s monadic account of effects by \nincorporating abstract effect interfaces as primitive. Our second inspiration is the elimination construct \nfor algebraic effects, effect handlers [36]. In Plotkin and Power s setting, one de.nes algebraic effects \nwith respect to an equational theory. As with other handler implementations [2, 6, 29], 1 From the Monad \nTransformer Library [12].  in this paper we always take the equational theory to be the free theory, \nin which there are no equations. We argue that algebraic effects and effect handlers provide a compelling \nalternative to monads as a basis for effectful program\u00adming across a variety of functional programming \nlanguages (pure or impure, strict or lazy, statically typed or dynamically typed). Our position is supported \nby a range of handler libraries we have im\u00adplemented for Haskell, OCaml, SML, and Racket, backed up by \na core calculus of effect handlers with a straightforward operational semantics. This paper focuses on \nthe Haskell library. Our key contributions are the following: A collection of novel features for practical \nprogramming with handlers in the presence of effect typing, illustrated through a series of examples. \n A small-step operational semantics for effect handlers.  A type and effect system for effect handlers. \n Effect handler libraries for Haskell, OCaml, SML, and Racket.  A performance comparison between our \nHaskell library and equivalent non-handler code.  The rest of the paper is structured as follows. Section \n2 presents handlers in action through a series of small examples. Section 3 introduces our core calculus \nof effect handlers, .e. , its effect type system, and small-step operational semantics. Section 4 presents \nin detail the Haskell effect handlers library, and sketches the design of our libraries for OCaml, SML, \nand Racket. Section 5 reports on the baseline performance of handlers in comparison with existing (less \nabstract) code. Section 6 discusses related work, and Section 7 concludes. 2. Handlers in Action We present \nour examples in a monadic style, using an extension to Haskell syntax implemented using the Template \nHaskell [40] and quasiquote [28] features of GHC. Haskell s features allow for a relatively simple, user-friendly \nand ef.cient implementation of effects handlers with effect typing in an existing language. (None of \nour other libraries support effect typing.) However, all of the examples could in fact be implemented \nwith the same level of expressivity and .exibility in a direct-style, with\u00adout any monadic boilerplate. \nIndeed, handlers can be direct-style with or without effect typing, and provide a natural abstraction \nfor adding more controlled effectful computations to the ML family of languages or even to the Lisp family \nof languages as witnessed by the libraries we have implemented in OCaml, SML, and Racket. In Section \n4.3 we outline a practical method to prototype an imple\u00ad mentation of handlers for a large set of such \nlanguages. A key reason for focusing on our Haskell library in this paper is that it is the only one \nthat supports effect typing. Effect typing is crucial to the termination of our core calculus (Section \n3). More im\u00ad portantly, it it is crucial for our notion of soundness, as it statically ensures that operations \ndo not accidentally go unhandled. Anecdo\u00adtally, we have observed that such static guarantees are important \nin practice: when we added effect typing to an early version of our Haskell library, it revealed a number \nof bugs in our test examples. The code for our effect handler libraries, examples, and bench\u00admarks is \navailable in the GitHub repository at: http://github.com/slindley/effect-handlers/ This repository also \nincludes many other other examples. For in\u00adstance, we have reimplemented Kiselyov and Shan s HANSEI DSL \nfor probabilistic computation [22], Kiselyov s iteratees [21], and Gonzalez s Pipes library [14], all \nusing handlers. Template Haskell and Quasiquotes Template Haskell [40] is a facility for compile-time \nmeta programming in Haskell. It provides a data type for manipulating Haskell code as an abstract syntax \ntree. It also provides constructs for splicing chunks of Haskell together. Quasiquotes [28] extend Template \nHaskell splicing functional\u00ad ity with user-de.ned syntax. Each syntax extension (also known as quasiquoter) \nis associated with a name. To de.ne syntax exten\u00adsion, ext, a library writer supplies a parser for ext \nexpressions as a function that takes a string and returns a Haskell abstract syn\u00adtax tree. To invoke \nthe syntax extension, a programmer writes an expression e in quasiquote brackets [ext | e |], a quasiquote. \nAt compile-time, GHC runs the parser on e and splices in the resulting abstract syntax tree in place \nof the quasiquote brackets. 2.1 State and Handlers We introduce the primitives for abstract operations \nand handlers in our Haskell library through the example of global state. We de.ne abstract operations \nfor state with the following operation quasiquotes [operation | Get s :: s |] [operation | Put s :: s \n. () |] which declare a Get s operation that takes no parameters and returns values of type s, and a \nPut s operation that takes a single parameter of type s and returns values of type (). In general an \nabstract operation declaration has the form [operation | .u1 ... ul.Op e1 ... em :: A1 . ... . An . A \n|] where Op is the name of the operation, u1, ..., ul are universal type variables, e1, ..., em are existential \ntype variables, A1, ..., An are parameter types, and A is the return type. (We will discuss the role \nof universal and existential type variables in Section 2.2.) The declarations above automatically derive \nwrappers get and put for actually invoking the operations. Ideally, we would like their types to be get \n:: Comp ' {Get s } s put :: s . Comp ' {Put s } () where Comp ' e a is the type of abstract computations \nthat can perform abstract operations in the set e and return a value of type a. But GHC does not have \na built-in effect type-system, so we simulate one, encoding sets of operations as type class constraints. \nThus, get and put actually have slightly more complicated types: get :: [ handles | h {Get s } | ] . \nComp h s put :: [ handles | h {Put s } | ] . s . Comp h () We can think of the type variable h as standing \nfor a set of op\u00aderations, an effect set e. Membership of operation Op in e is de\u00adnoted by the quasiquotation \n[| handles | h {Op } | ] (which is desugared into a corresponding type class constraint). The reason \nwe write handles instead of contains, and h instead of e, is that h is more than just an effect set; \nit actually ranges over han\u00addlers for e. Thus Comp h represents computations interpreted by handlers \nof type h, and the constraint [| handles | h {Op } | ] really means: handler h handles operation Op. \n(We will introduce the syntax for handlers shortly.) We de.ne the type of abstract state computations \nas follows2: type SComp s a = .h.([handles | h {Get s } | ], [handles | h {Put s } | ]) . Comp h a For \nexample: 2 We would ideally like to write [handles | h {Get s, Put s } | ] as a single constraint, but \nTemplate Haskell currently only allows us to generate one type class constraint per quasiquote.  comp \n:: SComp Int Int comp = do {x . get; put (x + 1); y . get; put (y + y); get } Because Haskell is lazy \nwe still require notation for explicitly sequencing computations. We take advantage of the existing do \nnotation, and Comp h is implemented as a certain kind of universal monad (see Section 4). We can provide \nmany concrete interpretations of stateful com\u00adputation, which is where handlers come in. First, we interpret \nstate in the standard monadic way: 1 [handler | 2 RunState s a :: s . (a, s) 3 4 handles {Get s , Put \ns } where Return x s . (x, s) 5 Get k s . k s s 6 Put s k . k () s |] We describe the syntax line by \nline. Line 1 begins a handler quasiquote. Line 2 speci.es the name, type parameters, and type signature \nof the handler. Notice that the type signature s . (a, s) is that of the state monad. The type signature \nindicates that this handler takes one parameter of type s, which is threaded through the handler, and \nreturns a result of type (a, s). Line 3 speci.es the set of operations handled by the handler. Line 4 \nis a return clause. It expresses how to return a .nal value from a computation. In general, a return \nclause takes the form Return x y1 ... yn . e, where x binds the value returned by the computation and \ny1, . . . , yn bind the handler parameters. Here, the .nal value is paired up with the single state parameter. \nLines 5 and 6 are operation clauses. They express how to handle each operation. In general, an operation \nclause takes the form Op x1 ... xm k y1 ... yn . e, where x1, . . . , xm bind the operation parameters, \nk binds the continuation of the computation, and y1, . . . , yn bind the handler parameters, here the \nsingle state parameter. The continuation k is a curried function which takes a return value followed \nby a sequence of handler parameters, and yields the interpretation of the rest of the computation. For \nGet, the return value is the current state, which is threaded through the rest of the computation. For \nPut s , the existing state is ignored, the return value is (), and the state parameter is updated to \ns. Analogously to abstract operation declarations, a handler decla\u00adration generates a convenient wrapper, \nwhose name is derived from that of the handler by replacing the .rst letter with its lower case counterpart. \nrunState :: s . SComp s a . (a, s) *Main> runState 1 comp (4, 4) If we do not need to read the .nal \ncontents of the state, then we can give a simpler interpretation to state [36], using the type that a \nHaskell programmer might normally associate with a read-only state monad: [handler | EvalState s a :: \ns . a handles {Get s , Put s } where Return x s . x Get k s . k s s Put s k . k () s |] *Main> evalState \n1 comp More interestingly, we can give other interpretations: [handler | LogState s a :: s . (a, [s ]) \nhandles {Get s , Put s } where Return x s . (x, [ ]) Get k s . k s s Put s k . let (x, ss) = k () s in \n(x, s : ss) |] This handler logs the history of all writes to the state. For instance, *Main> logState \n1 comp (4, [ 2, 4 ])  2.2 State and Open Handlers The three handlers of Section 2.1 are closed. They \neach handle Get and Put, but cannot interpret computations that might perform other operations. Thus \nthey do not support modular instantiation. Open handlers extend closed handlers by automatically for\u00adwarding \nall operations that are not explicitly handled. For instance, the following de.nes a handler that forwards \nall operations other than Get and Put: [handler | forward h. OpenState s a :: s . a handles {Get s , \nPut s } where Return x s . return x Get k s . k s s Put s k . k () s |] The type variable h is an artefact \nof the Haskell implementation. It represents an abstract parent handler that will ultimately handle operations \nforwarded by OpenState . It is implicitly added as the .rst type argument to OpenState (yielding OpenState \nh s a) and Comp h is implicitly applied to the return type (yielding Comp h a). Any operations other \nthan Get or Put will be automatically forwarded to h. To illustrate the composability of open handlers, \nwe return to the logging example. In Section 2.1, we demonstrated how to log Put operations using a special \nhandler. We now factor the logging in such a way that we can re.ne any abstract stateful computation \ninto an equivalent abstract computation that also performs logging, such that both logging and state \ncan be subsequently interpreted in arbitrary ways using suitable handlers. First we de.ne a new operation \nfor logging each Put: [operation | LogPut s :: s . () |] Now we can de.ne an open handler that inserts \na LogPut oper\u00adation before every Put operation in the original computation, but otherwise leaves it unchanged: \n[handler | forward h handles {Put s , LogPut s }. PutLogger s a :: a handles {Put s } where Return x \n. return x Put s k . do {logPut s ; put s ; k ()} | ] For instance, the computation putLogger comp is \nequivalent to: do { x . get; logPut (x + 1); put (x + 1); y . get; logPut (y + y); put (y + y); get } \n The constraint (h handles {Put s, LogPut s }) asserts that the parent handler h must also handle the \nPut s and LogPut s operations3 . To obtain the original behaviour of LogState , we can de.ne the following \nopen handler: [handler | forward h. LogPutReturner s a :: (a, [s ]) handles {LogPut s } where Return \nx . return (x, [ ]) LogPut s k . do (x, ss) . k (); return (x, s : ss) |] 3 Under the hood this aids \nGHC type inference.  and compose several handlers together: stateWithLog :: s . SComp s a . (a, [s ]) \nstateWithLog s comp = (handlePure . logPutReturner . openState s . putLogger) comp where HandlePure is \na canonical top-level closed handler: [handler |HandlePure a :: a handles { } where Return x . x |] which \ninterprets a pure computation as a value of type a. An alternative interpretation of logging is to output \nlogging messages as they arrive: [handler | forward h handles {Io }.(Show s) . LogPutPrinter s a :: \na handles {LogPut s } where Return x . return x LogPut s k . do io (putStrLn (\"Put: \" + show s)); k () \n|] Now we can plug everything together: statePrintLog :: Show s . s . SComp s a . IO a statePrintLog \ns comp = (handleIO . logPutPrinter . openState s . putLogger) comp where HandleIO is another top-level \nclosed handler for perform\u00ading arbitrary operations in the IO monad with the Io operation: [operation \n| .a.Io :: IO a . a |] [handler | HandleIO a :: IO a handles {Io } where Return x . return x Io m k \n. do {x . m; k x } |] The universal quanti.er in the Io operation declaration indicates that it must \nbe handled polymorphically in a. This is in contrast to the declaration of Get, for instance: [operation \n| Get s :: s |] where the type parameter s is existential, in the sense that for any handler that handles \nGet, there must exist a .xed type for s. Correspondingly, in any given abstract computation, Io can be \nused at arbitrary types a whereas Get must be used at a .xed type s. Comparing the outputs on our sample \ncomputation we obtain: *Main> stateWithLog 1 comp (4, [2, 4]) *Main> statePrintLog 1 comp Put: 2 Put: \n4 4 The pattern of precomposing one closed top-level handler with a sequence of open handlers is common \nwhen using our library. The order in which open handlers are composed may or may not change the semantics. \nFor instance, if we were to swap the order of openState s and putLogger in statePrintLog then all of \nthe Put operations would be handled before any PutLog operations could be generated, so no logging information \nwould ever be output. On the other hand, if we were to swap the order of logPutPrinter and openState \ns then the semantics would be unchanged as their actions are orthogonal. Open handlers allow us to handle \na subset of the effects in an abstract computation, thus supporting modular instantiation. The next three \nsubsections present more involved examples, demonstrating the interaction of user-de.ned effects with \nvarious Haskell features.  2.3 Choice and Failure Consider abstract operations Choose and Failure: [operation \n| .a.Choose :: a . a . a |] [operation | .a.Failure :: a |] The idea is that Choose should select one \nof its two arguments of type a, and Failure just aborts. Abstract choice computations are interesting \nbecause they admit a range of useful interpreta\u00adtions. Archetypal handlers which we consider include \nthose that enumerate all choices (AllResults below) and random sampling (RandomResult below). The former \nis notable as it takes full ad\u00advantage of the ability for an operation clause to invoke the continu\u00adation \nmore than once. The type of abstract computations over Choose and Failure is: type CF a = .h.([handles \n| h {Choose } |], [handles | h {Failure } |]) . Comp h a As a simple example, consider the following \nprogram: data Toss = Heads | Tails deriving Show drunkToss :: CF Toss drunkToss = do {caught . choose \nTrue False; if caught then choose Heads Tails else failure } drunkTosses :: Int . CF [Toss ] drunkTosses \nn = replicateM n drunkToss The abstract computation drunkToss simulates a drunk perform\u00ading one coin \ntoss. If the drunk catches the coin then the result of tossing the coin (Heads or Tails) is returned. \nIf the coin falls into the gutter then no result is returned. The drunkTosses function repeats the process \nthe speci.ed number of times. We can write a handler that returns all possible results of a CF computation \nas a list, providing a model of non-determinism. [handler | AllResults a :: [a ] handles {Choose, Failure \n} where Return x . [x ] Choose x y k . k x + k y Failure k . [ ] |] This is the .rst handler we have \nseen that uses the continuation non-linearly. The Choose operation is handled by concatenating the results \nof invoking the continuation with each alternative. The Failure operation is handled by returning the \nempty list and ignor\u00ading the continuation. For example: *Main> allResults (drunkCoins 2) [[Heads, Heads \n], [Heads, Tails ], [Tails, Heads ], [Tails, Tails ]] Rather than returning all of the results of a \nCF computation, we might wish to sample a single result at random. In order to keep the implementation \nof randomness abstract, let us declare a new operation for generating random numbers. [operation | Rand \n:: Double |] We .rst give a handler for Choose alone. [handler | forward h handles {Rand }. RandomResult \na :: a handles {Choose } where Return x . return x Choose x y k . do {r . rand; k (if r < 0.5 then x \nelse y)} |] Unlike in the AllResults handler, the Choose operation is handled by supplying one of the \narguments to the continuation at random. We can implement randomness using the IO monad. [handler | HandleRandom \na :: IO a handles {Rand } where Return x . return x Rand k . do {r . getStdRandom random; k r } |] Let \nus now de.ne another open handler for handling Failure, interpreting the result of a possibly failing \ncomputation with a Maybe type.  [handler | forward h. MaybeResult a :: Maybe a handles {Failure } where \nReturn x . return (Just x ) Failure k . return Nothing |] As the body of the handler is pure, there is \nno need to constrain h with a handles clause. We now compose the above three handlers: sampleMaybe :: \nCF a . IO (Maybe a ) sampleMaybe comp = (handleRandom . maybeResult . randomResult ) comp The sampleMaybe \nfunction4 .rst uses randomResult to handle Choose using Rand , forwarding Failure . Then it uses maybeResult \nto handle Failure , forwarding Rand . Finally, at the top-level, it uses handleRandom to handle Rand \nin the IO monad. Here are some example runs: *Main> sampleMaybe (drunkTosses 2) Nothing *Main> sampleMaybe \n(drunkTosses 2) Just [Heads , Heads ] We might decide that rather than stopping on failure, we would \nlike to persevere by trying again: [handler | forward h. Persevere a :: Comp (Persevere h a ) a . a handles \n{Failure } where Return x . return x Failure k c . persevere c c |] The parameter to the Persevere handler \nis a computation that must be handled recursively by the handler itself. The Failure operation is handled \nby reinvoking the handler. We can now persevere until we obtain a sample. sample :: CF a . IO a ' sample \ncomp = handleRandom (persevere comp comp ' ) ' where comp = randomResult comp For instance: *Main> sample \n(drunkTosses 5) [Heads , Tails , Heads , Tails , Heads ] In practice, one might use a more sophisticated \nsampling approach to improve performance by avoiding failures [22].  2.4 Word Count The wc program counts \nthe number of lines, words and characters in an input stream. We .rst present the abstract operations \nrequired to implement this functionality: [operation | ReadChar :: Maybe Char |] [operation | Finished \n:: Bool |] The ReadChar operation reads a character if available. The Finished operation checks whether \nthe input is .nished. Given these operations, we can implement a function that reads a line: readLine \n:: [ handles | h {ReadChar } | ] . Comp h String readLine = do mc . readChar case mc of Nothing . return \n[ ] Just \\n . return [ ] Just c . do cs . readLine ; return (c : cs) Of course, this implementation does \nnot specify where the input is to be read from. We de.ne a handler that reads from a string: 4 We cannot \n.-reduce sampleMaybe as doing so upsets the GHC type checker. [handler | forward h. StringReader a :: \nString . a handles {ReadChar , Finished } where Return x . return x ReadChar k [ ] . k Nothing [ ] ReadChar \nk (c : cs) . k (Just c) cs Finished k [ ] . k True [ ] Finished k cs . k False cs |] and another that \nreads from standard input: [handler | forward h handles {Io }. StdinReader a :: a handles {ReadChar \n, Finished } where Return x . return x ReadChar k . do b . io (hIsEOF stdin ) if b then k Nothing else \ndo c . io getChar ; k (Just c) Finished k . do b . io (hIsEOF stdin ); k b |] With the readLine function, \nwe can count the number of lines in an input stream, but wc additionally provides facilities to count \ncharacters and words. For doing so, we give two handlers, each of which instruments the readChar operation \nin a different way. The .rst handler counts the number of characters read by enumerating each call to \nreadChar : [handler | forward h handles {ReadChar }. CountChar0 a :: Int . (a, Int) handles {ReadChar \n} where Return x i . return (x, i) ReadChar k i . do mc . readChar case mc of Nothing . k mc i Just . \nk mc $! i + 1 |] countChar = countChar0 0 The second handler counts the number of words read by tracking \nspace characters: [handler | forward h handles {ReadChar }. CountWord0 a :: Int . Bool . (a, Int) handles \n{ReadChar } where Return x i . return (x , i) ReadChar k i b . do mc . readChar case mc of Nothing . \n(k mc $! (if b then i + 1 else i)) $ False Just c . if ( c =  . c = \\t . c = \\n . c = \\r ) then (k mc \n$! (if b then i + 1 else i)) $ False else k mc i True |] countWord = countWord0 0 False Combining these \ntwo handlers, we write a general wc function: wc :: ([handles | h {ReadChar } | ], [handles | h {Finished \n} | ]) . Comp h (Int, Int, Int) wc = do ((l, w), c) . countChar (countWord (loop 0)) return (c, w, l) \n where loop i = do b . .nished if b then return i else do . readLine ; loop $! (i + 1) Here is a version \nof wc that takes a string as input:  wcString :: String . IO () wcString s = let (c, w, l) = handlePure \n(stringReader s wc) in putStrLn $ (show l) + \" \" + (show w) + \" \" + (show c) Here is a version of wc \nthat uses standard input: wcStdin :: IO () wcStdin = do (c, w, l) . handleIO (stdinReader wc) putStrLn \n$ (show l) + \" \" + (show w) + \" \" + (show c) In practice, one might de.ne other handlers in order to \nsupport .le input, network input, or different forms of buffering.  2.5 Tail The tail program takes \nan argument n and prints the last n lines of a text .le. In order to implement the functionality of tail, \nwe make use of readLine as well as two additional abstract operations: the .rst to record a line, and \nthe second to print all recorded lines. [operation | SaveLine :: String . () |] [operation | PrintAll \n:: () |] With these two operations, implementing an abstract tail computa\u00adtion tailComp is straightforward. \ntailComp :: ([handles | h {ReadChar } |], [handles | h {Finished } |], [handles | h {SaveLine } |], [handles \n| h {PrintAll } |]) . Comp h () tailComp = do s . readLine; saveLine s b . .nished; if b then printAll \nelse tailComp We now just need to handle the SaveLine and ReadLine opera\u00adtions. A naive handler might \nstore all saved lines in memory, and print the last n as required. In practice, a more ef.cient implemen\u00adtation \nmight store only the last n lines, using a circular array, say. 2.6 Pipes and Shallow Handlers The behaviour \nof handlers we have described thus far is such that the continuation of an operation is handled with \nthe current handler (though the parameters passed to the continuation may differ from the current parameters). \nAnother possible behaviour is for the continuation to return an unhandled computation, which must then \nbe handled explicitly. We call such handlers shallow handlers because each handler only han\u00addles one \nstep of a computation, in contrast to Plotkin and Pretnar s deep handlers. Shallow handlers are to deep \nhandlers as case anal\u00adysis is to a fold on an algebraic data type. Shallow handlers sometimes lead to \nslightly longer code. For example, the EvalState handler from Section 2.1 becomes: [shallowHandler | \nEvalStateShallow s a :: s . a handles {Get s, Put s } where Return x s . x Get k s . evalStateShallow \n(k s) s Put s k . evalStateShallow (k ()) s |] The need to call the handler recursively in most clauses \nis charac\u00adteristic of the style of program one writes with shallow handlers. In some situations, it is \nhelpful to have access to the unhandled result of the continuation. Consider pipes as exempli.ed by Gon\u00adzalez \ns pipes library [14]. A pipe is a data structure used to rep\u00adresent composable producers and consumers \nof data. A consumer can await data and a producer can yield data. A pipe is both a consumer and a producer. \nIt is straightforward to provide such an abstraction with the following operations5: 5 These operations \nhave exactly the same signatures as Get and Put, but their intended interpretation is different. For \ninstance, yield x; yield y is in no way equivalent to yield y. [operation | Await s :: s |] [operation \n| Yield s :: s . () |] To de.ne a plumbing operator that combines a compatible con\u00adsumer and producer \nwe write two handlers: one handles the down\u00adstream consumer and keeps a suspended producer to resume \nwhen needed, the other handles the upstream producer and keeps a sus\u00adpended consumer. These two handlers \nare straightforward to write using shallow handlers: [shallowHandler | forward h.Down s a :: Comp (Up \nh a) a . a handles {Await s } where Return x . return x Await k prod . up k prod |] [shallowHandler \n| forward h.Up s a :: (s . Comp (Down h a) a) . a handles {Yield s } where Return x . return x Yield \ns k cons . down (k ()) (cons s) |] However, transforming these handlers into deep handlers re\u00adquires \nsome ingenuity. Indeed, we need to work with continuations that are fully handled and we cannot keep \nthe simple mutually re\u00adcursive structure of the two handlers. Instead, we introduce two mutually recursive \ntype de.nitions data Prod s r = Prod (() . Cons s r . r) data Cons s r = Cons (s . Prod s r . r) which \nwe use to encode the suspended partner of each computation [handler | forward h.Down s a :: Prod s (Comp \nh a) . a handles {Await s } where Return x . return x Await k (Prod prod) . prod () (Cons k) |] [handler \n| forward h.Up s a :: Cons s (Comp h a) . a handles {Yield s } where Return x . return x Yield s k (Cons \ncons) . cons s (Prod k) |] resulting in a more complex program. We believe both deep and shallow handlers \nare useful. For clarity of presentation, we focus on deep handlers in the rest of this paper. In Section \n3.4 and Section 4.2 we outline how shallow handlers differ from the main presentation.  2.7 Other Perspectives \nIn this paper we primarily treat handlers as a .exible tool for interpreting abstract effectful computations. \nBefore we proceed with the rest of the paper we highlight some alternative perspectives on what handlers \nare. Generalised exception handlers. Benton and Kennedy [3] intro\u00adduced the idea of adding a return continuation \nto exception han\u00addlers. Their return continuation corresponds exactly to the return clause of an effect \nhandler. Effect handler operation clauses gener\u00adalise exception handler clauses by adding a continuation \nargument, providing support for arbitrary effects. An operation clause that ig\u00adnores its continuation \nargument behaves like a standard exception handler clause. Taming delimited continuations. A handler \ninvocation delimits the start of a continuation. Each operation clause captures the con\u00adtinuation of \nthe computation currently being handled, that is, the continuation up to the invocation point of the \nhandler. Effect han\u00addlers modularise delimited continuations by capturing particular patterns of use. \nAs Andrej Bauer, the co-creator of the Eff [2] lan\u00ad  (values) A, B ::= 1 | A1 \u00d7 A2 | 0 | A1 + A2 | UE \nC (computations) C ::= F A A . C C1 &#38; C2 (effect signatures) E (handlers) (environments) G ::= x1 \n: A1, . . . , xn : An Figure 1. Types and Effects of .e. (values) V , W ::= x | () | (V1, V2) | inji \nV | {M}(computations) M, N ::= split(V , x1.x2.M) | case0(V ) | case(V, x1.M1, x2.M2) | V ! | return \nV | let x . M in N | .x.M | M V (M1, M2 prji M (handlers) H Figure 2. Syntax of .e. Terms guage puts \nit (personal communication, 2012): effects + handlers : delimited continuations = while : goto Folds \nover free monads. As we shall see in Section 4, we can de.ne an algebraic data type for a collection \nof operations, and a handler is exactly a fold (otherwise known as catamorphism) over that data type. \n3. The .e. -calculus In this section, we present a small-step operational semantics and a sound type \nand effect system for .e. , a higher-order calculus of ef\u00adfect handlers. Following related work on effect \noperations [19], ef\u00ad fect handlers [36], and monadic re.ection [11], which takes Levy s call-by-push-value \n[24] as the underlying paradigm, we extend Levy s calculus with effect operations and effect handlers. \nFor our purposes, the important features of call-by-push-value are that it makes an explicit distinction \nbetween values and computations, and that thunks are .rst-class objects distinct from functions. 3.1 \nSyntax and Static Semantics The types and effects of .e. are given in Figure 1, the terms are given in \nFigure 2, and the typing rules are given in Figure 3. In all .gures, the interesting parts are highlighted \nin grey. The unhighlighted parts are standard. Call-by-push-value makes a syntactic distinction between \nval\u00adues and computations. Only value terms may be passed to func\u00adtions, and only computation terms may \ncompute. Value types (Figure 1) comprise the value unit type (1), value products (A1 \u00d7 A2), the empty \ntype (0), sums (A1 + A2), and thunks (UE C). The latter is the type of suspended computations. The effect \nsignature E describes the effects that such computations are allowed to cause. Computation types comprise \nvalue-returning computations (F A), functions (A . C), the computation unit type (T), and computation \nproduct types (C1 &#38; C2). Call-by-push-value includes two kinds of products: computation products, \nwhich are eliminated by projection, and value products, which are eliminated by binding. An effect signature \nis a mapping from operations to pairs of value types, written as a set of type assignments. Each type \nassign\u00adment op : A . B, speci.es the parameter type A and return type B of operation op. A handler type \nA E .E1 C has a input value type A, output computation type C, input effect signature E, and output effect \nsignature E '. A handler of this type handles value-returning com\u00adputations of type F A that can only \nperform operations in E. The body of the handler itself may only perform operations in E ', and its computation \ntype is C. Type environments are standard. Value terms (Figure 2) include variables and value introduc\u00ad \ntion forms. We write {M} for the thunk that represents the sus\u00adpended computation M as a value. All elimination \noccurs in com\u00adputation terms, as is standard for call-by-push-value. We write split(V, x1.x2.M) for the \nelimination form for value products, which binds the components of the product value V to the vari\u00adables \nx1 and x2 in the computation M. We write (M1, M2) for a computation pair and prji M for the i-th projection \nof M. We write V ! for the computation that forces the thunk V , that is, runs the computation suspended \nin V . A lambda-abstraction .x.M is not a value, so must be suspended to be passed as an argument. Function \napplication, products, and projections are standard. In .e. operation applications are in continuation-passing-style. \nAn operation application op V (.x.M) takes a parameter V and a continuation .x.M. The intuition is that \nthe operation op is applied to the parameter V , returning a value that is bound to x in the continuation \ncomputation M. We restrict the continuation to be a lambda abstraction in order to simplify the operational \nsemantics. While programming with effects, it is more convenient to work with direct-style operation \napplication. Direct-style application can be de.ned in terms of continuation-passing-style application: \no= = op V op V (.x.return x), and vice versa: op V (.x.M) let x . oop x op V in M. Plotkin and Power \ncall the function .x.ounderlying a direct-style application the generic effect of op [35]. A handled \ncomputation handle M with H runs the compu\u00adtation M with the handler H. A handler H consists of a return \nclause return x . M, and a set of operation clauses of the form op p k . N. The return clause return \nx . M speci.es how to handle a return value. The returned value is bound to x in M . Each operation clause \nop p k . N speci.es how to handle applications of the distinct operation name op. The parameter is bound \nto p and the continuation is bound to k in N. The body of the continuation continues to be handled by \nthe same handler. The typing rules are given in Figure 3. The computation typing judgement G fE M : C \nstates that in type environment G the com\u00adputation M has type C and effect signature E. Only operations \nin the current effect signature can be applied. Handling a computation changes the current effect signature \nto the output effect signature of the handler. The effect signature and type of the handled computa\u00adtion \nmust match up exactly with the input type and effect signature of the handler. In the handler typing \njudgement G f H : R, all clauses must have the same output type and effect signature. The input type \nis determined by the return clause. The effect annotation on the thunked continuation parameter k in \nan operation clause op p k . N is annotated with the output effect rather than the input effect. The \nreason for this is that when handling an operation, the handler is automatically wrapped around the continuation. \nSyntactic Sugar For convenience, we de.ne syntactic sugar for projecting out the return clause and operation \nclauses of a handler. For any handler {return x . M} l {opi p k . Ni}i we write Hreturn = .x.M Hopi = \n.pi ki.Ni  Value typing G f V : A (x : A) . G G f V1 : A1 G f V2 : A2 G f x : A G f () : 1 G f (V1, \nV2) : A1 \u00d7 A2 G f V : Ai G fE M : C G f inji V : A1 + A2 G f {M} : UE C Computation typing G fE M : \nC G f V : A1 \u00d7 A2 G, x1 : A1, x2 : A2 fE M : C G fE split(V , x1.x2.M) : C G f V : 0 G fE case0(V ) : \nC G f V : A1 + A2 G, x1 : A1 fE M1 : C G, x2 : A2 fE M2 : C G fE case(V, x1.M1, x2.M2) : C G f V : \nUE C G f V : A G fE V ! : C G fE return V : F A G fE M : F A G, x : A fE N : C G fE let x . M in N : \nC G, x : A fE M : C G fE M : A . C G f V : A G fE .x.M : A . C G fE M V : C G fE M1 : C1 G fE M2 : C2 \nG fE () : T G fE (M1, M2) : C1 &#38; C2 G fE M : C1 &#38; C2 G fE prji M : Ci (op : A . B) . E G f V \n: A G, x : B fE M : C G fE op V (.x.M) : C E .E1 G fE M : F A G f H : A C G fE1 handle M with H : C \nE .E1 Handler typing G f H : A C E = {opi : Ai . Bi}i H = {return x . M} l {opi p k . Ni}i [G, p : Ai, \nk : UE1 (Bi . C) fE1 Ni : C]i G, x : A fE1 M : C E .E1 G f H : A C Figure 3. Typing Rules for .e.  3.2 \nOperational Semantics The reduction relation (-.) for .e. is de.ned in Figure 4. We use reduction frames \nas an auxiliary notion to simplify our presenta\u00adtion. The \u00df-rules are standard: each \u00df-redex arises as \nan introduc\u00adtion followed by an elimination. The .rst three \u00df-rules eliminate value terms; the last three \neliminate computation terms. The hoist.op-rule hoists operation applications through hoist\u00ading frames. \nIts purpose is to forward operation applications up to the nearest enclosing handler, so that they can \nbe handled by the handle .op-rule. The handle .F -rule returns a value from a handled computation. It \nsubstitutes the returned value into the return clause of a handler Reduction frames (hoisting frames) \nH ::= let x . [ ] in N | [ ] V | prji [ ] (computation frames) C ::= H | handle [ ] with H Reduction \nM -. M ' (\u00df.\u00d7) split((V1, V2), x1.x2.M1) -. M [V1/x1, V2/x2] (\u00df.+) case(inji V , x1.M1, x2.M2) -. Mi[V \n/xi] (\u00df.U ) {M}! -. M (\u00df.F ) let x . return V in M -. M [V /x] (\u00df..) (\u00df.&#38;) (.x.M) V -. M [V /x] prji \n(M1, M2) -. Mi (hoist.op) x /. FV (H) H[op V (.x.M)] -. op V (.x.H[M]) (handle .F ) Hreturn = .x.M handle \n(return V ) with H -. M[V /x] (frame ) M -. M ' C[M] -. C[M ' ] Figure 4. Operational Semantics for \n.e. in exactly the same way that \u00df.F -reduction substitutes a returned value into the body of a let binding. \nThe handle .op-rule is the most involved of the reduction rules. A handled operation application handle \nop V (.x.M) with H reduces to the body of the operation clause Hop = .p k .N with the parameter V substituted \nfor p and the continuation .x.M substituted for k. Any further operation applications should be handled \nby the same handler H. Thus, we wrap H around M. The frame -rule allows reduction to take place within \nany stack of computation frames, that is, inside any evaluation context. The semantics is deterministic, \nas any term has at most one redex. Furthermore, reduction on well-typed terms always termi\u00adnates. Theorem \n1 (Termination). If G fE M : C then reduction on M terminates. Proof sketch: The proof is by a relatively \nstraightforward adapta\u00adtion of Lindley s proof of strong normalisation for sums [26]. The interesting \nrule is handle .op, which reinvokes the handler, pos\u00adsibly many times, but always on a subterm of the \noriginal com\u00adputation. As with Ariola et al. s normalisation result for delimited continuations [1], \ntermination depends crucially on the effect type system. Theorem 2 (Type soundness). If f{} M : F A then \nM reduces to a returned value return V of type A. Proof sketch: De.ne a canonical term to be any computation \nterm of the form: return V , .x.N, (), (V , W ), or op V (.x.M). Induction on typing derivations shows \nprogress: if fE M : C then, either there exists M ' such that M -. M ' , or M is canonical. By appeal \nto a substitution lemma, induction on typing derivations shows preservation: if G fE M : C and M -. M \n' then G fE M ' : C.  3.3 Open Handlers Our presentation of .e. gives an operational account of closed \nhandlers. We can adapt .e. to support open handlers by making two small changes. The typing rule for \nhandlers becomes: E = E ' . {opi : Ai . Bi}i H = {return x . M } l {opi p k . Ni}i [G, p : Ai, k : UE1 \n(Bi . C) fE1 Ni : C]i G, x : A fE1 M : C E .E1 G f H : A C The only change to the original rule is that \nthe input effects are now E ' . E instead of just E, where E ' . E is the extension of E ' by E (where \nany clashes are resolved in favour of E). The handle.op-rule is re.ned by extending the meaning of Hop, \nsuch that it is de.ned as before for operations that are ex\u00adplicitly handled by H, but is also de.ned \nas .p k.op p(.x.k x) for any other operation op. This means that any operation that is not explicitly \nhandled gets forwarded. In our simply-typed formalism, it is straightforward to translate any program \nthat uses open handlers into an equivalent program that uses closed handlers. As any open handler handles \na bounded number of operations, we can simply write down all of the implicit forwarding clauses explicitly. \nIn practice, it seems desirable to offer both open and closed handlers, as in our Haskell library. To \ntake full advantage of open handlers in a typed language, one inevitably wants to add some kind of effect \npolymorphism. Indeed, our Haskell implementation provides effect polymorphism, encoded using type classes. \nWe believe that effect polymorphism can be supported more smoothly using row polymorphism. We brie.y \noutline one path to supporting row polymorphism. The open handler rule from above can be rewritten as \nfollows: E = {opi : Ai . Bi}i l Ef E ' = E '' l Ef H = {return x . M} l {opi p k . Ni}i [G, p : Ai, k \n: UE1 (Bi . C) fE1 Ni : C]i G, x : A fE1 M : C .E1 G f H : A E C The key difference is that this version \nof the rule uses disjoint union l in place of extension ., explicitly naming the collection of forwarded \neffects. One can now instantiate the meta variable Ef with a row variable. We would likely also wish \nto support polymorphism over E '' . This is not dif.cult to achieve using a Remy-style [37] account of \nrow typing if we insist that E '' only include operations in {opi}i. We leave a full investigation of \neffect polymorphism for handlers to future work.  3.4 Shallow Handlers Our presentation of .e. gives \nan operational account of deep han\u00addlers. In order to model shallow handlers we can make two small changes. \nThe typing rule for handlers becomes: E = {opi : Ai . Bi}i H = {return x . M } l {opi p k . Ni}i [G, \np : Ai, k : UE(Bi . F A) fE1 Ni : C]i G, x : A fE1 M : C .E1 G f H : A E C The only changes with respect \nto the original rule are to the types of the continuations, which now yield F A computations under the \ninput effect signature E, rather than C computations under the output effect signature E ' . The handle.op-rule \nis replaced by the shallow-handle.op-rule: 4. Implementation Any signature of operations can be viewed \nas a free algebra and represented as a functor. Every such functor gives rise to a free monad (Swierstra \n[43] gives a clear account of free monads for functional programmers). This yields a systematic way of \nbuilding a monad to represent computations over a signature of operations. We use our standard state \nexample to illustrate. Concretely we can de.ne the free monad over state as follows: data FreeState s \na = Ret a | Get () (s . FreeState s a) | Put s (() . FreeState s a) instance Monad (FreeState s) where \nreturn = Ret Ret v > = f = f v Get () k > = f = Get () (.x . k x > = f ) Put s k > = f = Put s (.x . \nk x > = f ) The type FreeState s a is a particular instance of a free monad. It can be viewed as a computation \ntree. The leaves are labelled with Ret v and the nodes are labelled with Get () and Put s. There is one \nedge for each possible return value supplied to the continuation of Get and Put a possibly in.nite number \nfor Get depending on the type of the state, and just one for Put. The bind operation performs a kind \nof substitution. To compute c > = f , the tree f v is grafted onto each leaf Ret v of c. The generic \nfree monad construction can be de.ned as follows: data Free f a = Ret a | Do (f (Free f a)) instance \nFunctor f . Monad (Free f ) where return = Ret Ret v > = f = f v Do op > = f = Do (fmap (> =f ) op) and \nwe can instantiate it with state as follows: data StateFunctor s a = GetF () (s . a) | PutF s (() . a) \nderiving Functor where FreeState s is isomorphic to Free (StateFunctor s). A handler for state is now \nsimply a unary function whose argu\u00adment has type Free (StateFunctor s). For instance: stateH :: Free \n(StateFunctor s) a . (s . a) stateH (Ret x) = .s . x stateH (Do (GetF () k)) = .s . stateH (k s) s stateH \n(Do (PutF s k)) = . . stateH (k ()) s interprets a stateful computation as a function of type s . a. \nA limitation of the above free monad construction is that it is closed in that it can only handle operations \nin the signature. A key feature of our library is support for open handlers that handle a .xed set of \noperations in a speci.ed way, and forward any other operations to be handled by an outer handler. To \nencode openness in GHC we take advantage of type classes and type families. The code for open free monads \nis given in Figure 5. We split the type of each operation into two parts: a type declaration that de.nes \nthe parameters to the operation, and a type family instance that de.nes the return type of the operation. \nFor instance: [operation | Put s :: s . () |] generates:  data Put (e :: *) (u :: *) where Put :: s \n. Put s () type instance Return (Put s ()) = () The .rst type argument e encodes the existential type \narguments of an operation, while the second type argument u encodes the uni\u00adversal type arguments of \nan operation. In the case of Put there is a single existential type argument s and no universal arguments. \nUs\u00ading GADTs we can encode multiple arguments as tuples. Handler types are generated similarly. Lines \n1 2 of Figure 5 declare type families for operation return types and handler result types. Lines 3 6 \nde.ne a ternary type class (h Handles op) e. Each instance of this class de.nes the clause of handler \nh that handles operation op with existential type arguments bound to e. Of course, we do not supply the \nuniversal arguments, as the clause should be polymorphic in them. The functional dependency h op . a \nasserts that type a must be uniquely determined by types h and op. This is crucial for correctly implementing \nopen handlers as we discuss further in Section 4.1. The handles quasiquoter generates type class constraints \non the Handles type class. Lines 7 14 de.ne the monad Comp h, which is simply a free monad over the functor \nde.ned by those operations op that are handled by h (i.e. such that (h Handles op) e is de.ned for some \ntype e). Lines 15 17 de.ne the auxiliary doOp function, which realises an operation as an abstract computation \nof the appropriate type. The operation quasiquoter uses doOp to automatically generate a function for \neach operation. For instance, the above declarations for Get and Put generate the following functions: \nget :: (h Handles Get) s . Comp h s get = doOp Get put :: (h Handles Put) s . s . Comp h () put s = doOp \n(Put s) Finally, Lines 18 21 de.ne the one remaining ingredient for the core library, the handle function, \nwhich takes a computation, a return clause, and a handler, and returns the result of handling the computation. \nWe supply the return clause independently from the type class mechanism in order to simplify the implementation. \nThe handler is automatically applied to the result of the continuation as speci.ed in the operational \nsemantics. This behaviour contrasts with the closed free monad code presented at the beginning of this \nsubsection, which instead uses explicit recursion as with the shallow handlers for state and pipes. We \nare making essential use of the type class mechanism. It is instructive to read the type of handle as \ntaking a return clause, a list of operation clauses, one for each op such that (h Handles op) e for some \ne, and returning a result. Thus the second argument of type h, as well as providing parameters to the \nhandler, also, albeit indirectly, encodes the list of operation clauses. The handler quasiquoter automatically \ngenerates a convenient wrapper meaning that programmers need never directly manipulate the constructor \nfor a handler type just as automatically generated operation wrappers mean that they need never directly \nmanipulate the constructor for an operation type. Limitations Our Haskell implementation of handlers \nhas several limitations. First, because handlers are encoded as type classes and type classes are not \n.rst-class, neither are handlers. Second, be\u00adcause we abstract over handlers in order to simulate effect \ntyping the types of the operation wrappers are more complex than neces\u00adsary. Third, because we explicitly \nmention a parent handler in the type of open handlers, the order in which open handlers are com\u00adposed \ncan leak into types (this is not as bad as with monad trans\u00adformers, as lifting is never required, but \nit is still undesirable). All of these limitations arise from attempting to encode handlers in Haskell. \nNone is inherent to handlers. We believe that a row\u00ad 1 type family Return (opApp :: *) :: * 2 type family \nResult (h :: *) :: * 3 class ((h :: *) Handles (op :: j . k . *)) (e :: j ) | h op . e 4 where 5 clause \n:: op e u . 6 (Return (op e u) . h . Result h) . h . Result h 7 data Comp h a where 8 Ret :: a . Comp \nh a 9 Do :: (h Handles op) e . 10 op e u . (Return (op e u) . Comp h a) . Comp h a 11 instance Monad \n(Comp h) where 12 return = Ret 13 Ret v > = f = f v 14 Do op k > = f = Do op (.x . k x > = f ) 15 doOp \n:: (h Handles op) e . 16 op e u . Comp h (Return (op e u)) 17 doOp op = Do op return 18 handle :: Comp \nh a . (a . h . Result h) . h . Result h 19 handle (Ret v) r h = r v h 20 handle (Do op k) r h = ' 21 \nclause op (.v h . handle (k v) r h ' ) h Figure 5. Free Monad Implementation 1 type family Return (opApp \n:: *) :: * 2 type family Result (h :: *) :: * 3 class ((h :: *) Handles (op :: j . k . *)) (e :: j ) \n| h op . e 4 where 5 clause :: op e u . (Return (op e u) . h . Result h) . 6 h . Result h 7 newtype \nComp h a = 8 Comp {handle :: (a . h . Result h) . h . Result h } 9 instance Monad (Comp h) where 10 \nreturn v = Comp (.k . k v) 11 Comp c > = f = Comp (.k . c (.x . handle (f x) k)) 12 doOp :: (h Handles \nop) e . 13 op e u . Comp h (Return (op e u)) 14 doOp op = Comp (.k h . clause op k h) Figure 6. Continuation \nMonad Implementation based effect type system along the lines of Leroy and Pesaux [23], Blume et al [5], \nor Lindley and Cheney [27] would provide a cleaner design. The Codensity Monad It is well known that \nfree monad compu\u00adtations can be optimised by composing with the codensity monad, which is essentially \nthe continuation monad over a polymorphic return type [45]. The Continuation Monad We can in fact do \neven better by using the continuation monad directly, meaning that the Ret and Do constructors disappear \ncompletely. The continuation monad code is given in Figure 6. The difference from the free monad code \nbegins on Line 7. The type constructor Comp h is exactly that of the continuation monad with return type \nh . Result h. We choose not to factor through the continuation monad de.ned in the standard library as \ndoing so hurts performance. The handle function is now exactly the deconstructor for Comp, while the \ndoOp function is just Comp . clause. We explicitly .-expand doOp because GHC is unable to optimise the \npointless version. 4.1 Open Handlers and Forwarding The key trick for implementing forwarding is to \nparameterise a handler H by its parent handler h. Without this parameter we would have no way of describing \nthe operations that are handled by both H and h. Now we can de.ne the following type class instance: \n instance (h Handles op) e . (H h Handles op) e where clause op k h = doOp op > = (.x . k x h) The handler \nquasiquoter generates this boilerplate automatically for open handlers. The functional dependency (H \nh) op . e is crucial here. Without it GHC would be unable to resolve the clause function. For instance, \nconsider the OpenState handler. This must select from the following instances for Get: instance (OpenState \nh s a Handles Get) s where clause Get k (OpenState s) = k s (OpenState s) instance (h Handles op) t \n. (OpenState h s a Handles op) t where clause op k h = doOp op > = (.x . k x h) Without the functional \ndependency the latter is chosen. This is because GHC tries to ensure that the same version of clause \nis used for Get t for any t, and the former is only valid if s is equal to t. The functional dependency \nasserts that t must be equal to s. Because the type variable t does not appear in either of the types \nOpenState h s a or op, and there is a functional depen\u00addency which states that OpenState h s a and op \nuniquely de\u00adtermine e, GHC s default type inference gives up. Enabling the UndecidableInstances language \noption .xes this. We believe that our basic use of UndecidableInstances is well-founded (and decidable!), \nbecause of the type class constraint (h Handles op) t which implies that h and op already uniquely determine \nt.  4.2 Shallow Handlers It is relatively straightforward to adapt our free monad implementa\u00adtion to \nimplement shallow handlers. The key change is to the type of the continuation argument of the clause \nfunction which must return a computation. It seems less clear how to adapt the continu\u00adation monad implementation. \n 4.3 Delimited Continuations We now sketch an implementation of (open) effect handlers in terms of delimited \ncontinuations [8, 9]. These ideas underlie our OCaml, SML, and Racket implementations. A variety of different \ndelimited continuation operators are cov\u00adered in the literature. Shan has recently shown that the four \nbasic choices are straightforwardly inter-de.nable [39]6 . We choose to describe our implementation in \nterms of a minor variant of Danvy and Filinski s shift and reset operators [8] called shift0 and reset0. \nThe behaviour of shift0 and reset0 can be concisely summarised through the following reduction rule: \nreset0 (E[shift0 (.k.M)]) -. M[(.x.reset0 (E[x]))/k] where E ranges over call-by-value evaluation contexts. \nThe reset0 operator delimits the start of a continuation, and the shift0 operator captures the continuation \nup to the nearest enclosing reset0. Crucially, the captured continuation is wrapped in a further reset0. \nIt is instructive to compare the above rule with the handle.op-rule, where handle - with H plays a similar \nrole to reset0. The implementations rely on the following key ingredients: A global (or thread-local) \nvariable keeps a stack of handlers in the current dynamic scope.  Each handler includes a map from the \nhandled operations to the corresponding operation clause.  6 These encodings do not preserve memory \nbehaviour, so can sometimes introduce memory leaks. To handle an effectful computation handle M with \nH: The handler H is added to the top of the stack.  We invoke reset0 (Hreturn M).  To apply an operation \n(in direct style) o op p: 1. We invoke shift0 to capture the continuation k up to (but excluding) the \nnext operation handler. 2. The top-most handler H is popped from the stack. 3. We let k ' = .x.push \nH; reset0 (k x), where push H pushes H back onto the stack. 4. The clause corresponding to the operation, \nthat is Hop, is ap\u00adplied to the parameter p and the continuation k ' . 5. If there is no clause corresponding \nto this operation, it will be forwarded by the handler. If no other handlers enclose the operation, an \nexception is raised.  To support shallow handlers, one replaces shift0 and reset0 with control0 and \nprompt0, which behave like shift0 and reset0, except no prompt0 is wrapped around the continuation: prompt0 \n(E[control0 (.k.M)]) -. M[(.x.E[x])/k]  4.4 Dynamic and Static Operations Our Haskell implementation \nuses one static type per operation. A program execution cannot dynamically create a new operation. Be\u00adcause \nthey do not provide effect typing, our other implementations do support dynamic operations, which can \nbe created, closed upon and garbage collected. This makes some programs easier to write. For example, \nreferences can be represented as pairs of dynamically generated Put and Get operations. With only static \noperations, one has to parameterise Put and Get by some representation of a ref\u00aderence, and explicitly \nmanage all of the state in a single handler. Static effect typing for dynamic operations presents challenges: \n Writing an effect type system for dynamic operations involves some form of dependent types, as operations \nare now .rst-class objects of the language.  Dynamic operations are dif.cult to implement as ef.ciently \nas static operations. In particular, it is not clear how to use the type system to pass only the relevant \neffects to each scope.  5. Performance Evaluation To evaluate the performance of our Haskell library, \nwe imple\u00admented a number of micro-benchmarks, comparing handler code against monadic code that makes \nuse of existing libraries. The code for the micro-benchmarks can be found in the GitHub repository at: \nhttp://github.com/slindley/effect-handlers/Benchmarks Detailed performance results can be found in Appendix \nA. Our primary goal was to check that the handler abstraction does not cripple performance. We rely on \nGHC to optimise away many of the abstractions we introduce. In the future we envisage building handlers \ninto the core of a programming language. We might reasonably hope to do signi.cantly better than in the \nlibrary\u00adbased approach by tailoring optimisations to be aware of handlers. The results con.rm that the \nHaskell library performs ade\u00adquately. The performance of the continuation monad implemen\u00adtation of handlers \nis typically no worse than around two thirds that of baseline code. In some cases the continuation monad \nim\u00adplementation actually outperforms existing implementations. The continuation monad implementation \nalways outperforms the co\u00addensity monad implementation (sometimes by more than an order of magnitude), \nwhich always outperforms the free monad imple\u00admentation. Usually standard handlers outperform shallow \nhandlers, pipes being an exception, where for large numbers of nested sub\u00adpipes shallow handlers outperform \neven the continuation monad implementation of standard handlers.  6. Related Work Algebraic Effects \nand Effect Handlers Effect operations were pioneered by Plotkin and Power [35], leading to an algebraic \nac\u00ad count of computational effects [34] and their combination [15]. Effect handlers were added to the \ntheory in order to support ex\u00adception handling [36]. Recent work incorporates additional com\u00ad putational \neffects within the algebraic framework, for example, lo\u00adcal state [41], and applies the algebraic theory \nof effects to new problem domains, such as effect-dependent program transforma\u00adtions [19], and logical-relations \narguments [20]. While mostly denotational in nature, operational accounts of al\u00adgebraic effects (without \nhandlers) do exist. Plotkin and Power [33] gave operational semantics to algebraic effects in a call-by-value \nsetting, and Johann et al. [32] gave operational semantics to alge\u00ad braic effects in a call-by-name setting. \nEffect Handler Implementations Bauer and Pretnar s effectful strict statically-typed language Eff [2] \nhas built-in support for al\u00ad gebraic effects and effect handlers. Like our ML implementations, it lacks \nan effect type system. Eff implements dynamic generation of new operations and effects, which we only \nconsider statically. Visscher has implemented the effects library [44] for Haskell inspired by Eff. The \ncore idea is to layer continuation monads in the style of Filinski [10], using Haskell type classes to \nautomati\u00ad cally infer lifting between layers. McBride s language Frank [29] is similar to Eff, but with \nan effect system along the lines of ours. It supports only shallow handlers and employs a novel form \nof effect polymorphism which elides effect variables entirely. Brady [6] has implemented an effect handlers \nlibrary for the dependently-typed language Idris. It takes advantage of dependent types for resource \ntracking. The current design has some limitations compared with the other handler implementations. In \nparticular, the composition of other effects with non-determinism is not well-behaved. Monadic Re.ection \nand Layered Monads Filinski s work on monadic re.ection and layered monads is closely related to ef\u00adfect \nhandlers [11]. Monadic re.ection supports a similar style of composing effects. The key difference is \nthat monadic re.ection interprets monadic computations in terms of other monadic com\u00adputations, rather \nthan abstracting over and interpreting operations. Filinski s system is nominal (an effect is the name \nof a monad), whereas ours is structural (an effect is a collections of operations). Monad Transformers \nand Inferred Lifting Jaskelioff and Moggi [17] develop the theory of monad transformers and lifting of \neffect operations. Jaskelioff s Monatron [16] is a monad transformer li\u00ad brary based on this development. \nSchrijvers and Oliveira [38] infer lifting in Haskell using a zipper structure at the level of type classes \nto traverse the monad transformer stack. Swamy et al. [42] add support for monads in ML, inferring not \nonly where and how to lift operations, but also where to insert return and bind statements. In both approaches, \nonce the required monad transformers have been de.ned, the desired lifting is inferred automatically. \n7. Conclusion Algebraic effects and handlers provide a promising approach for supporting effectful computations \nin functional languages. By of\u00adfering a new form of modularity, they create possibilities for library \ndesign and reusability that are just beginning to emerge. This pa\u00adper shows that implementing these constructs \nis within the reach of current compiler technology. Acknowledgments The .e. calculus stemmed from discussions \nof the .rst author with Andrej Bauer and Matija Pretnar in Ljubljana and Swansea. The authors would like \nto thank Stevan Andjelkovic, Danel Ahman, Bob Atkey, Andrej Bauer, Brian Campbell, James Ch\u00adeney, Derek \nDreyer, Andrzej Filinski, Ben Kavanagh, Neel Kr\u00adishnaswami, Conor McBride, James McKinna, Gordon Plotkin, \nMatija Pretnar, Alex Simpson, Sam Staton, Phil Wadler, and the POPL 2013, PLDI 2013, and ICFP 2013 referees, \nfor useful con\u00adversations, comments and suggestions. We are grateful to Gabriel Gonzalez for pointing \nout a .aw in the pipes benchmarks in an ear\u00adlier draft of this paper. The type system originated from \na visit by the .rst author to Andrej Bauer and Matija Pretnar in Ljubljana, supported by the Laboratory \nfor Foundations of Computer Science. This work was supported by a Google Research Award, EPSRC grants \nEP/J014591/1 and EP/H005633/1, a SICSA studentship, an Edinburgh University Informatics School studentship, \nand an Isaac Newton Trust starter grant. References [1] Z. M. Ariola, H. Herbelin, and A. Sabry. A type-theoretic \nfoundation of delimited continuations. Higher-Order and Symbolic Computation, 22(3):233 273, 2009. [2] \nA. Bauer and M. Pretnar. Programming with algebraic effects and handlers. CoRR, abs/1203.1539, 2012. \n[3] N. Benton and A. Kennedy. Exceptional syntax. J. Funct. Program., 11(4):395 410, 2001. [4] N. Benton, \nJ. Hughes, and E. Moggi. Monads and effects. In APPSEM 2000. Springer-Verlag, 2002. [5] M. Blume, U. \nA. Acar, and W. Chae. Exception handlers as extensible cases. In APLAS. Springer-Verlag, 2008. [6] E. \nBrady. Programming and reasoning with algebraic effects and dependent types. In ICFP. ACM, 2013. [7] \nB. C. d. S. Oliveira, T. Schrijvers, and W. R. Cook. MRI: Modular reasoning about interference in incremental \nprogramming. J. Funct. Program., 22(6):797 852, 2012. [8] O. Danvy and A. Filinski. Abstracting control. \nIn LFP. ACM, 1990. [9] M. Felleisen. The theory and practice of .rst-class prompts. In POPL. ACM, 1988. \n[10] A. Filinski. Representing layered monads. In POPL. ACM, 1999. [11] A. Filinski. Monads in action. \nIn POPL. ACM, 2010. [12] A. Gill. The mtl package (2.1.2), 2012. http://hackage.haskell.org/package/mtl. \n[13] G. Gonzalez. pipes-2.5: Faster and slimmer, 2012. http://www.haskellforall.com/2012/10/ pipes-25-faster-and-slimmer.html. \n [14] G. Gonzalez. The pipes package (3.2.0), 2013. http://hackage.haskell.org/package/pipes. [15] M. \nHyland, G. D. Plotkin, and J. Power. Combining effects: Sum and tensor. Theoret. Comput. Sci., pages \n70 99, 2006. [16] M. Jaskelioff. Monatron: An extensible monad transformer library. In IFL. Springer-Verlag, \n2008. [17] M. Jaskelioff and E. Moggi. Monad transformers as monoid trans\u00adformers. Theoret. Comput. Sci., \n411(51 52), 2010. [18] M. P. Jones. Functional programming with overloading and higher\u00adorder polymorphism. \nIn Advanced Functional Programming, 1995. [19] O. Kammar and G. D. Plotkin. Algebraic foundations for \neffect\u00addependent optimisations. In POPL. ACM, 2012. [20] S. Katsumata. Relating computational effects \nby TT-lifting. Inf. Comput., 222, 2013. [21] O. Kiselyov. Iteratees. In FLOPS. Springer-Verlag, 2012. \n[22] O. Kiselyov and C.-c. Shan. Embedded probabilistic programming. In DSL. Springer-Verlag, 2009. \n [23] X. Leroy and F. Pessaux. Type-based analysis of uncaught exceptions. ACM Trans. Program. Lang. \nSyst., pages 340 377, 2000. [24] P. B. Levy. Call-By-Push-Value: A Functional/Imperative Synthesis, volume \n2 of Semantics Structures in Computation. Springer, 2004. [25] S. Liang, P. Hudak, and M. P. Jones. Monad \ntransformers and modular interpreters. In POPL. ACM, 1995. [26] S. Lindley. Extensional rewriting with \nsums. In TLCA. Springer-Verlag, 2007. [27] S. Lindley and J. Cheney. Row-based effect types for database \ninte\u00adgration. In TLDI. ACM, 2012. [28] G. Mainland. Why it s nice to be quoted: quasiquoting for Haskell. \nIn Haskell. ACM, 2007. [29] C. McBride. Frank (0.3), 2012. http://hackage.haskell.org/package/Frank. \n[30] E. Moggi. Computational lambda-calculus and monads. In LICS. IEEE Computer Society, 1989. [31] B. \nO Sullivan. The criterion package (0.8.0.0), 2013. http://hackage.haskell.org/package/criterion. [32] \nA. S. Patricia Johann and J. Voigtl \u00a8ander. A generic operational metatheory for algebraic effects. In \nLICS. IEEE Computer Society, 2010. [33] G. D. Plotkin and J. Power. Adequacy for algebraic effects. In \nFoSSaCS. Springer-Verlag, 2001. [34] G. D. Plotkin and J. Power. Notions of computation determine mon\u00adads. \nIn FoSSaCS. Springer-Verlag, 2002. [35] G. D. Plotkin and J. Power. Algebraic operations and generic \neffects. Appl. Categ. Structures, 11(1):69 94, 2003. [36] G. D. Plotkin and M. Pretnar. Handlers of algebraic \neffects. In ESOP. Springer-Verlag, 2009. [37] D. R\u00b4Type inference for records in a natural extension \nof ML. emy. In C. A. Gunter and J. C. Mitchell, editors, Theoretical Aspects Of Object-Oriented Programming. \nTypes, Semantics and Language De\u00adsign. MIT Press, 1993. [38] T. Schrijvers and B. C. d. S. Oliveira. \nMonads, zippers and views: virtualizing the monad stack. In ICFP. ACM, 2011. [39] C.-c. Shan. A static \nsimulation of dynamic delimited control. Higher-Order and Symbolic Computation, 20(4):371 401, 2007. \n[40] T. Sheard and S. L. P. Jones. Template meta-programming for Haskell. SIGPLAN Notices, 37(12):60 \n75, 2002. [41] S. Staton. Two cotensors in one: Presentations of algebraic theories for local state and \nfresh names. Electr. Notes Theor. Comput. Sci., 249:471 490, 2009. [42] N. Swamy, N. Guts, D. Leijen, \nand M. Hicks. Lightweight monadic programming in ML. In ICFP. ACM, 2011. [43] W. Swierstra. Data types \n`a la carte. J. Funct. Program., 18(4):423 436, 2008. [44] S. Visscher. The effects package (0.2.2), \n2012. http://hackage.haskell.org/package/effects. [45] J. Voigtl\u00a8ander. Asymptotic improvement of computations \nover free monads. In MPC. Springer-Verlag, 2008. [46] P. Wadler. Monads for functional programming. In \nAdvanced Func\u00adtional Programming. Springer-Verlag, 1995. A. Performance Results All performance testing \nwas conducted with the -O2 compiler .ag enabled using a PC with a quad-core Intel i7-3770K CPU run\u00adning \nat 3.50GHz CPU and 32GB of RAM, running GHC 7.6.1 on Ubuntu Linux 12.10. We used O Sullivan s criterion \nlibrary [31] to sample each micro-benchmark ten times. The code for the micro-benchmarks can be found \nin the GitHub repository at: http://github.com/slindley/effect-handlers/Benchmarks   A.1 State As \na basic sanity check we tested the following function on state: count :: SComp Int Int count = do i \n. get; if i = 0 then return i else do put (i - 1); count We used 108 as the initial value for the state. \nWe tested implemen\u00adtations using: the state monad, three different versions of standard deep handlers, \nand one implementation of shallow handlers. As a control, we also tested a pure version of count . In \neach case we used open handlers for interpreting state. Implementation Time (ms) Relative Speed pure \n51 1.00 state monad 51 1.00 handlers (continuations) 77 0.67 handlers (free monad) 5083 0.01 handlers \n(codensity) 2550 0.02 shallow handlers 5530 0.01 Table 1. State The results are shown in Table 1. GHC \nis optimised for monadic programming, so there is no cost to using a state monad over a pure program. \nThe continuation monad implementation runs at two thirds of the speed of the baseline. The free monad \nimplementa\u00adtion is a hundred times slower than the baseline. Using a codensity monad gives a two times \nspeed-up to the free monad implementa\u00adtion. Shallow handlers are implemented using a free monad and are \nslowest of all. A.2 Flat Pipes We tested our pipes implementation using a .at pipeline previ\u00adously used \nby the author of the pipes library for comparing per\u00adformance between the pipes library and other libraries \n[13]. The pipeline consists of a producer that yields in turn the integers in the sequence [ 1 . . n \n], for some n, connected to a consumer that ignores all inputs and loops forever. The pipes library optionally \ntakes advantage of GHC rewrite rules to de.ne special code opti\u00admisations for pipes code. We tested against \npipes with and with\u00adout the rewrite rules enabled. The results are shown in Table 2 for n = 108. The \ncontinuation monad implementation is nearly twice as fast as the pipes library without rewrite rules \nenabled. Enabling the rewrite rules makes a signi.cant difference. In this case the pipes library is \nfaster than the continuation monad implementa\u00adtion. The free monad and codensity implementations are \nslower than the pipes library, but the differential is much smaller than in the case of the count micro-benchmark. \nInterestingly, shallow handlers outperform the free monad implementation of standard handlers. Implementation \nTime (ms) Relative Speed pipes library 3398 1.00 pipes library + rewrites 1304 2.61 handlers (continuations) \n1820 1.87 handlers (free monad) 6736 0.50 handlers (codensity) 3918 0.87 shallow handlers 5239 0.65 \nTable 2. Flat Pipes  A.3 Nested Pipes To test the scalability of handlers we implemented a deeply-nested \npipes computation constructed from 2n sub-pipes, for a range of values of n. The results are shown in \nTable 5. They are intrigu\u00ad ing as the relative performance varies according to the number of sub-pipes. \nThe relative performance is shown graphically in Fig\u00adure 7. The pipes library always out-performs all \nof our libraries, even with GHC rewrite rules disabled. The continuation monad im\u00adplementation is relatively \nconstant at around two thirds the speed of the pipes library. What is particularly notable is that as \nthe level of nesting increases, the performance of shallow handlers eventually overtakes that of the \ncontinuation monad implementation.  One possible reason for the pipes library outperforming our continuation \nmonad implementation on nested pipes is that it is in fact based on a free monad, and the implementation \ntakes advantage of the rei.ed representation of computations to optimise the case where an input is forwarded \nthrough several pipes. We are not sure why shallow pipes perform so well on deeply\u00adnested pipes, but \nsuspect it may be due to the simpler de.nition of pipes for shallow handlers, as compared with that for \nstandard handlers, opening up optimisation opportunities along the lines of those explicitly encoded \nin the pipes library. We conjecture that the anomalous dip at 211 sub-pipes for the bottom three lines \nin Figure 7 is due to cache effects. Figure 7. Relative Performance of Nested Pipes  A.4 The n-Queens \nProblem To test the performance of handlers that invoke the continuation zero or many times, we implemented \nthe classic n-queens problem in terms of an n-ary Choose operation: [operation | .a.Choose :: [ a ] . \na |] We wrote a handler that returns the .rst correct solution for the n\u00adqueens problem, and tested against \na hand-coded n-queens solver. We tested both algorithms with n = 20. Implementation Time (ms) Relative \nSpeed hand-coded 160 1.00 handlers 237 0.67 Table 3. n-Queens The results are shown in Table 3. The \nhandler version is about two thirds the speed of the hand-coded version.  A.5 Aspect-Oriented Programming \nEffect handlers can be used to implement a form of aspect\u00adoriented programming. We tested an expression \nevaluator taken from Oliveira et al. s work on monadic mixins [7]. The expression evaluator is extended \nto output logging information whenever en\u00adtering or exiting a recursive call, and to output the environment \nwhenever entering a recursive call. We compared a hand-coded evaluator with Oliveira et al. s mixin-based \nevaluator and an evalu\u00adator implemented using our continuation monad implementation of standard handlers. \nWe tested each evaluator on the same randomly generated expression containing 212 leaf nodes. Implementation \nTime (ms) hand-coded 6516 mixins 6465 handlers (continuations) 6526 Table 4. Aspect-Oriented Programming \nThe results are shown in Table 4. The performance is almost identical for each of the three implementations, \nindicating no ab\u00adstraction overhead. 29 sub-pipes Implementation Time (ms) Relative Speed pipes library \n41 1.00 pipes library + rewrites 23 1.80 handlers (continuations) 57 0.72 handlers (free monad) 103 0.40 \nhandlers (codensity) 81 0.51 shallow handlers 88 0.47 210 sub-pipes Implementation Time (ms) Relative \nSpeed pipes library 90 1.00 pipes library + rewrites 49 1.84 handlers (continuations) 131 0.69 handlers \n(free monad) 275 0.33 handlers (codensity) 206 0.44 shallow handlers 198 0.45 211 sub-pipes Implementation \nTime (ms) Relative Speed pipes library 209 1.00 pipes library + rewrites 111 1.89 handlers (continuations) \n336 0.62 handlers (free monad) 990 0.21 handlers (codensity) 716 0.29 shallow handlers 595 0.35 212 \nsub-pipes Implementation Time (ms) Relative Speed pipes library 721 1.00 pipes library + rewrites 274 \n2.63 handlers (continuations) 1181 0.61 handlers (free monad) 2701 0.27 handlers (codensity) 2178 0.33 \nshallow handlers 1216 0.59 213 sub-pipes Table 5. Nested Pipes Implementation Time (ms) Relative Speed \npipes library 1931 1.00 pipes library + rewrites 877 2.20 handlers (continuations) 3147 0.61 handlers \n(free monad) 6172 0.31 handlers (codensity) 5188 0.37 shallow handlers 2470 0.78   \n\t\t\t", "proc_id": "2500365", "abstract": "<p>Plotkin and Pretnar's handlers for algebraic effects occupy a sweet spot in the design space of abstractions for effectful computation. By separating effect signatures from their implementation, algebraic effects provide a high degree of modularity, allowing programmers to express effectful programs independently of the concrete interpretation of their effects. A handler is an interpretation of the effects of an algebraic computation. The handler abstraction adapts well to multiple settings: pure or impure, strict or lazy, static types or dynamic types. This is a position paper whose main aim is to popularise the handler abstraction. We give a gentle introduction to its use, a collection of illustrative examples, and a straightforward operational semantics. We describe our Haskell implementation of handlers in detail, outline the ideas behind our OCaml, SML, and Racket implementations, and present experimental results comparing handlers with existing code.</p>", "authors": [{"name": "Ohad Kammar", "author_profile_id": "81488671208", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P4261233", "email_address": "ohad.kammar@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Sam Lindley", "author_profile_id": "81330494526", "affiliation": "University of Strathclyde, Glasgow, United Kingdom", "person_id": "P4261234", "email_address": "Sam.Lindley@ed.ac.uk", "orcid_id": ""}, {"name": "Nicolas Oury", "author_profile_id": "81337492278", "affiliation": "n/a, n/a, United Kingdom", "person_id": "P4261235", "email_address": "nicolas.oury@gmail.com", "orcid_id": ""}], "doi_number": "10.1145/2500365.2500590", "year": "2013", "article_id": "2500590", "conference": "ICFP", "title": "Handlers in action", "url": "http://dl.acm.org/citation.cfm?id=2500590"}