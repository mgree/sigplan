{"article_publication_date": "11-04-2002", "fulltext": "\n Making RUP Agile Michael Hirsch Z\u00fchlke Engineering AG Wiesentrasse 10a CH-8952 Schlieren, Switzerland \nHirsch.Michael@acm.org Abstract The Unified Development Process (USDP) and especially its implementation \nby Rational Software Corporation, the Rational Unified Process (RUP), is a comprehensive process covering \nalmost all aspects of software development projects. However, due to the great level of detail provided \nby RUP, many professionals do not consider RUP practical for small, fast paced projects. This paper reports \nthe experiences with RUP on two small projects with teams of 3 to 5 developers. RUP proved to be adaptable \nto the needs of small projects and was very effective in both projects. One key to the successful application \nof RUP in small projects is the careful selection of a proper subset of artifacts and keeping these artifacts \nvery concise and free from unnecessary formalism. This paper goes into the details of what it takes to \nmake RUP agile, how it was applied in the two projects, and how it was configured. Also covered is what \nelements of RUP contributed to the success of one project, and why RUP could not prevent that the outcome \nof the other project was less than optimal. 1. Introduction This paper reports on experiences with applying \nRUP in small projects. A small project in this context is one with 3 to 5 developers and 6 to 9 months \nduration. The focus of this paper is on how we adapted RUP at Z\u00fchlke Engineering AG for this sort of \nproject, i.e. what artifacts we used and why, the typical number and length of iterations, and the approach \nwhich we used for project planning and control. Z\u00fchlke Engineering AG, founded in 1968, is an independant \nsystems development services company with headquarters in Zurich and offices in Frankfurt and London. \nToday, we employ over 200 engineers. Our main business is custom development of software-, electronics-, \nmechanical-and micromechanical systems for our customers in various industries. One fundamental assumption \nof our business model is that the customer provides domain knowledge and we provide project mangement \nand technical know-how, with the consequence that systematic and unambiguous requirements engineering \nis of utmost importance. Typical project teams consist of 7 to 20 engineers on Copyright is held by the \nauthor/owner(s). integrated systems1 projects, and 3 to 10 engineers on software only projects. Software \ndevelopment makes up over 50% of our business volume. For software development we used structured analysis, \ndesign, and programming up to 1991. By that time it became clear to us that structured techniques did \nnot scale up well for complex systems and that we could not achieve the level of productivity with them \nwe needed to stay competitive in a market with ever increasing customer expectations. In 1992 we started \na transition to object oriented analysis, design and programming, which was completed by 1995. Like many \nother companies, we initially defined our own development process, which was rooted in the waterfall \nmodel. This turned out to be not really satisfying and by 1998 we seriously began to look for alternatives. \nAfter a brief survey of what iterative processes were publicly available we decided to try RUP. The main \nreasons for this decision were that (a) RUP was the only well documented and comprehensive iterative \nprocess we could find2 , (b) RUP was very complete, thus saving us work for creating templates, guidelines \nand so on, (c) we got the impression that RUP was created by practitioners as opposed to methodologists \nassuming that we all live in a perfect world, and finally (d) documentation of RUP was available in electronic \nform, an important prerequisite for its applicability in real world projects by real world software engineers. \nThe fact that we were already using the UML for object modeling routinely made it even easier to adopt \nRUP. 2. Adapting RUP for Small Projects 2.1 A Brief Overview of RUP RUP covers virtually all aspects \nof typical software development projects. Figure 1 below shows the two most important dimensions of RUP, \nwhich are (1) the organization of a project on the time axis (shown on the horizontal axis) and (2) the \nareas of work in a software development project (shown on the vertical axis). 1 An integrated systems \nproject is one that requires skills from different engineering disciplines such as sotware-, electronics- \nand mechanical engineering. 2 Extreme Programming and other Agile Methods were not widely published and \neasily accessible in 1998. Figure 1: Overview of RUP An area of work is called a discipline in RUP. \nThese are the 9 disciplines defined by RUP: Business Modeling: Describing business processes and the \ninternal structure of a business in order to (a ) better understand the business and (b) to be able to \ncome up with proper requirements for software systems to be built for the business at hand.  Requirements \nManagement: Eliciting, organi\u00adzing, and documenting requirements.  Analysis and Design: Creating the \narchitecture and the design of the software system.  Implementation: Writing and debugging source code, \nunit testing, and build management.  Test: Integration-, system- and acceptance testing.  Deplyoment: \nPackaging the software, creating in\u00adstallation scripts, writing end user documentation and other tasks \nneeded to make the software available to its end users.  Project Management: Project planning and moni\u00adtoring. \n Configuration and Change Management:  Covers all tasks concerned with (a) version and release management \nand (b) with change request management. Environment: Adapting the process to the needs of a project (or \nan organization), and selecting, introducing and supporting development tools. The height of the bar \nassociated with each discipline in figure 1 is an indication of how much work is spent for this discipline \nat a given point in time. Naturally, business modeling and requirements management need more work at \nearly stages, whereas deplyoment needs more work towards the end of a project. For each discipline, RUP \ndefines a set of artifacts, activities, and roles. An artifact is a work product, such as a document, \nsource code, or an object model expressed in UML. An activity is a detailed description of a small unit \nof work which creates, modifies, adds to, or reviews an artifact. A role is a responsibility which one \nor more people in a project take on, such as project manager, software architect, or test designer. On \nthe time axis, RUP divides a project into the following four phases: Inception: Defining the objectives \nof the project, including the business case.  Elaboration: Creating and validating the architec\u00adture \nof the software system, capturing the most important and critical requirements, and planning and estimating \nthe rest of the project.  Construction: Implementing the system based on the executable architecture \ncreated in the elaboraton phase.  Transition: Beta-testing the system and preparing release candidates. \n  Each phase is further divided into one or more iterations. Each iteration builds on the results of \nthe previous iteration and delivers an executable (development-) release of the system. The duration \nand goals of an iteration are planned before an iteration starts. When an iteration is completed, a full \nassessment of the iteration is done in order to allow for corrective action if needed. 2.2 Considerations \nfor Adapting RUP In its most recent incarnation (Version 2002 of November 2001), RUP defines about 80 \nmajor artifacts, 150 activities, and 40 roles. When we first looked at RUP in 1998 there were fewer artifacts, \nactivities and roles, but even then it was clear to us that there were too many of them for the size \nof projects we had in mind. So we set out to create what we called RUP Light, a scaled down version of \nRUP with as little process overhead as possible. Today, we would call this activity probably Making RUP \nagile3 to be fully buzzword compliant, but in 1998 the term agile methods had not been coined yet, or \nat least we weren t aware of it. We decided to adapt RUP in the following areas: Artifacts: We wanted \nto maintain only artifacts that were really needed and that added value, so we radically scaled down \non the number of artifacts. We kept the proposed structure (i.e. the table of contents of documents) \nof the remaining artifacts, but made changes where we thought a template was not exactly what we wanted. \nThis is, by the way, exactly what RUP recommends. We do not consider RUP to be at fault because we needed \nto customize the extent of documentation we wanted to maintain. Since RUP is a framework for all types \nand sizes of projects, some amount of customization is normal and to be expected. There is a list of \nall artifacts we kept in the next section.  Activities: We didn t change any activities, and we decided \nnot to use them for detailed iteration planning, contrary to what RUP suggests. The reason for this is \nsimple: all developers on the projects were experienced in use case modeling, object modeling, the UML, \nand most other techniques employed by RUP. Activities and their aggregation into so-called workflow details \nare quite finely grained, such as describe a use case or write a unit test for a class . It simply makes \nno sense to plan the work of experienced developers at this level of detail. Rather, we treated activities \nlike a textbook: if a developer needed guidance on how to complete an assigned task, he would consult \nappropriate activity descriptions to find answers, but otherwise activity descriptions were not used. \n Roles: We did no formal assignments of roles to developers. We used roles only as a checklist to verify \nthat we had all required skills in the team.  Project Planning: We decided to maintain two levels of \nplans, as RUP suggests. The first level is a coarsely grained project plan, which basically lists start \nand end dates of all phases and iterations, as well as major goals for each iteration. The second level \nis a detailed plan for each iteration, which is prepared a few days before an iteration starts, and modified \nduring an iteration if needed. Rather than constructing iteration plans based on a list of tasks to be \ndone, we decided to base them on a list of results we wanted to achieve in an iteration. Typical results \nare the specification and implementation of a product feature, the implemen\u00ad  3 See the Agile Manifesto \nat www.agilemanifesto.org tation of a change request or bug fix, or the preparation of a major non-code \nrelated artifact, such as a software architecture document. Each planning item is assigned to an owner \nwho is responsible for achieving the associated result. A typical iteration plan would call for about \na dozen features to be implemented, and up to 10 change requests and bug fixes. In addition to features, \nchange requests and bug fixes, we used a fourth category of planning items, which we called additional \nwork items for a lack of a better term. Additional work items are all kinds of results which are not \ndirectly related to a single feature, such as software infrastructure components (e.g. OO/RDBMS mappings, \nerror logging mechanisms, etc.), preparation and execution of major tests, or installation and configuration \nof development tools and libraries. However, the main focus of planning is on product features, because \nthis is what the customer sees and wants (and ultimately pays for). Phases: We adopted the four phases \nof RUP and the associated milestones without any modificatons.  Iterations: We decided to have iterations \nof about 4 weeks. Each iteration results in a tested software release, complete with release notes and \ninstallation scripts, which is given to the customer. To some people, 4 weeks may seem very long. However, \nfor us an iteration is first and foremost a planning period, with a detailed list of goals we want to \nachieve in that period. The length of an iteration has nothing to do with how frequently we build and \nintegrate the system. Daily builds are the rule on all our RUP projects. Customers are encouraged to \nfrequently look at the current state of the system. We are incorporating minor change requests from customers \ninto a running iteration. Major change requests, however, are postponed to later iterations, because \nthey typically require replanning the overall project.  Project Control: Weekly status meetings with \nthe entire project team are our main tool for tracking progress. Since every result to be achieved is \nthe responsibility of a single person, there are no ambiguities as to who is responsible and for what. \nEvery week, each developer estimates the remaining amount of work to achieve his iteration goals. Thus \ndeviations from the plan become obvious very quickly. We set up the rule that we do not prolong an iteration \nto achieve all results originally planned for if we run out of time. Rather, we end an iteration at the \nscheduled date with fewer results if we can not follow the original iteration plan. We think it is better \nto deliver a release with fewer features than planned on time rather than a release with all features \nbut too late. This view is shared by most of our customers.  We summarized our thoughts and rules on \nhow to apply RUP in an internal memo with a few pages. Other than that, no customization work was done. \nWe deliberately did not modify the RUP online documentation to reflect our changes, because we did not \nwant to repeat the work involved with every new release of RUP. To date (August 2002), the internal memo \nhas evolved into a company specific RUP User Guide, which describes how to apply RUP and which is published \non the SEPG (software engineering process group) homepage in our intranet. 3. Project One: Turbine Layout \nTool Armed with the guidelines and considerations outlined in section 2, we started the inception phase \nof our first official RUP project on October 1st, 1999. The current RUP Version then was RUP 5.1.1. The \nmission of the project was to create a software tool for designing blades of steam turbines. The customer \nwas Alstom Power Inc., one of the leading manufacturers of power generation equipment and power plants. \nThe tool was to be used by about 20 to 30 mechanical engineers at several Alstom design centers around \nthe globe. 3.1 Challenges The main challenges of this project were: A very short development time of \nat most 9 months from the first idea to deployment in a production environment.  A sophisticated user \ninterface with 2D and 3D graphics.  We had to integrate existing software, written by the customer in \nMathlab, for some critical algorithms.  Requirements were initially very vague, because no previous \nor at least similar tool existed.  We decided to meet these challenges with the following approach: \n A small team of highly experienced developers consisting of two full time developers from our company \nand one full time developer for Mathlab work and testing from the customer. The team was led by a part \ntime project manager (myself).  Application of RUP Light, as outlined in the previous section. We settled \nfor iterations of exactly one month, starting on the first and ending on the last day of each month. \nIn hindsight this proved to be very helpful, because it eased planning and created a steady rhythm in \nthe project. We all knew that we were in trouble if the specifications of the features to be implemented \nwere not clear around the 10th, or that we should be feature complete around the 25th of each iteration. \n Early and very intense involvement by the customer. In addition to the developer from the customer, \nwho worked on our premises most of the time, the person responsible for the project from the customer \nattended all iteration planning and iteration assessment meetings.  Systematic requirements management \nbased on product features. All of the customers wishes were expressed in terms of product features. Specifications \nof features were kept to the minimum required and were typically  from a few sentences to a few paragraphs \nper feature. Feature specifications were written by two engineers of the development team, one from us \nand one from the customer. Daily builds. We started with coding activities in the very first iteraration \nand maintained a daily build throughout the entire project.  Implementation in Java-2. We chose Java \nversion 1.2 standard edition as our development and target platform for the following reasons: support \nof 2D and 3D graphics, availability of a comprehensive GUI toolkit (Swing), higher productivity compared \nto development in C++, and finally the tools (Java SDK) were free.  This approach turned out to be \nvery successful. The project was completed 2 months ahead of the initial schedule, with all required \nfeatures , and most important, the customer was very satisfied. 3.2. Some Project Statistics Table 1 \nbelow summarizes some statistics of the completed project. Team size (headcount) 4 Team size (full time \nequivalents): 3.5 Number of use cases: 6 Number of features: 40 Number of change requests implemented: \n53 Number of bugs found an fixed: 14 Number of iterations: 6 + 2 Project duration: 7 months Total effort \nin person days: 260 Number of Java classes implemented: approx. 180 Total LOC, including commment lines: \napprox. 30,000 Table 1: Project Statistics  3.3 Project Timeline Table 2 summarizes phases, iterations \nand releases of the completed project. The project started on October 1, 1999 and delivered the first \nproduction release on April 30, 2000. We spent more time and effort in the inception and elaboration \nphases than in construction and transition. This is typical for projects where requirements are very \nunclear at the beginning and need to be evolved during the project. After having productively used the \nsoftware for a couple of months, the customer came back with some change requests and a few new features. \nWe implemented these in two additional iterations. For the sake of simplicity we added these two iterations \nto the transition phase of the original project rather than defining a new project. Iteration Start Date \nEnd Date Milestone Release Inception Phase 1 1-Oct-1999 30-Oct-1999 -\u00ad R-1.1.1 (GUI layout demonstration) \n2 1-Nov-1999 7-Dec-1999 LCO R-1.2.1 (Proof of concept) Elaboration Phase 3 8-Dec-1999 31-Jan-2000 -\u00ad \nR-1.3.1 4 1-Feb-2000 29-Feb-2000 LCA R-1.4.1 Construction Phase 5 1-Mar-2000 31-Mar-2000 IOC R-1.5.2 \n(Beta test release) Transition Phase 6 1-Apr-2000 30-Apr-2000 PR R-1.6.2 (First production release) 7 \n6-Nov-2000 30-Nov-2000 IOC R-1.7.1 (Added some new features) 8 1-Dec-2000 22-Dec-2000 PR R-1.8.1 (Second \nproduction release) Table 2: Phases, Iterations and Releases The milestones in table 2 are according \nto RUP terminology, which in turn is derived from Barry Boehm s work4. 3.4 Project Artifacts We decided \non the artifacts we wanted to maintain at the beginning of the project and documented our decision in \nthe so called Development Case document. During the project, very few artifacts were added and no artifacts \nwere dropped. Table 3 summarizes the artifacts used by the project. Our main criteria for the inclusion \nor exclusion of an artifact were the questions what value does this artifact add for the customer? and \nwhat are the likely conse\u00adquences if we don t have this artifact? . If we couldn t identify a convincing \nadded value of an artifact we did not use it. As always, selecting the right artifacts involved many \ntradeoffs. For example, a test plan and test case descriptions would have been desirable, but we renounced \nthem in favor of informal and ad-hoc testing. The time saved by this was invested in building more features \nfor the customer. Fortunately we did not run into any significant quality problems despite the lack of \nformal testing. We attribute this mostly to the systematic software design approach used and the fact \nthat we received frequent feedback from the customer. 3.5 Lessons Learned Overall, this project was \na big success both for our customer and for us. We think the following factors contributed strongly to \nthe positive outcome of the project: Iterative and incremental development. It would have been impossible \nto complete this project within the same timeframe and budget with a conventional 4 LCO = Lifecylce \nObjectives Milestone, LCA = Lifecycle Architecture Mileston, IOC = Initial Operational Capabilities Milestone,PR \n= Product Release Milestone. waterfall process. All fundamental assumptions of waterfall processes, i.e. \nthat requirements can be defined upfront or that a systems software architecture can be defined before \nany coding work starts, did not apply to this project. Strong involvement of the customer in project \nplanning and monitoring. A person from the customer was present in all iteration planning and iteration \nassessment meetings. The decision of what goes into an iteration in terms of features, change requests, \nand bug fixes was always made together with the customer.  Fast and useful feedback from the customer. \nUsually we received feedback from the customer for a new release within one working week after delivering \nthe release. In addition to the official releases, which were produced at the end of every iteration, \nwe frequently showed the current state of our work to the customer in an informal manner. Feedback received \nfrom this was usually incorporated into the next official release.  A small team of experienced and \nhighly motivated developers.  Low overhead for project planning, requirements and change management. \nThe effort spent for project management activities was about 7% of the total effort for the project. \n A pragmatic but nevertheless effective approach to change management.  Finally, the framework for \norganizing projects and the many templates and examples which come with RUP saved us a lot of time in \nsetting up the project. Without RUP, we would have had to come up with our own definitions for project \nphases, work areas, artifacts and many other things.  What would we do differently today if we could \nstart again? First of all, we would spend more time on organizing and executing the testing effort. At \na minimum, we would use the JUnit framework (see www.junit.org) for unit testing system. Also, if the \nbudget had a little more margin, we and a small set of documented test cases for system would collect \nsome straightforward design metrics in order testing. Although we had no quality problems in this to \nhave a quantitative view of the design quality of our project we never felt secure about the quality \nof the system. RUP Artifact Comments Format / Tools Requirements Vision Document Describes project objectives, \nimportant classes of users, andall product features. Features are uniquely identified forreference from \nother artifacts. Text document, 15 pages Use Case Model Describes all use cases of the system in one \ndocument. Usecases were used to better understand the system, but not forproject planning. Initial versions \nof the document included sketches of the GUI, in later versions the sketches werereplaced with screen \nshots of the actual GUI. Text document, 20 pages Analysis and Design Software Architecture Document Describes \nthe high level software design of the system.Contains some UML diagrams plus brief descriptions ofimportant \nmechanisms. Text document, 12 pages Design Model Detailed software design of the system in terms of classes \nandobjects and their grouping into packages. We used the CASEtool Together / J for object modeling. This \ntool keeps designinformation as special comments in source code. Together / J Implementation Implementation \nModel In RUP terminology the implementation model is simply thecollection of all artifacts required to \nbuild the system, i.e. all source files, makefiles, configuration files, etc. Java source code files,Makefiles, \nJBuilder Test Defect List A list of all open and closed defects, including a briefdescription of each \ndefect. Text document, 3 pages Deployment Release Notes Were written for each release given to the customer. \nText document, 2 pages Installation Artifacts These are all executable files, configuration files, installationprocedures, \ndocumentation etc. needed to install the system.For each release a set of installation artifacts was \ncreated and given to customer. ZIP file Configuration and Change Management ConfigurationManagement Plan \nDescribes the policies for version control, releasemanagement, and change request management. We used \nCVSfor version and release management. All artifacts of the projectwere placed under version control. \nText document, 8 pages Change Request List A list with all open and closed change requests, including \na verybrief description of each change request. Text document, 4 pages Project Management Software Development \nPlan A coarse grained plan with a list of all planned iterations. For each iteration, the major objectives, \nstart and end dates werespecified. This plan was updated after each iteration. Text document, 8 pages \nIteration Plan A detailed plan for each iteration, outlining which features,change requests, bug fixes \nand additional work items will bedone by whom. Text document, 4-6 pages(one for each iteration) Iteration \nAssessment A summary of the results of an iteration, i.e. what objectiveswere reached, what features, \nchange requests and bug fixeswere actually implemented, and reasons for any deviationsfrom the plan. \nText document, 2-5 pages(one for each iteration) Environment Development Case Describes how RUP is adapted \nfor a project. Mostly a list ofwhich artifacts are used and which aren t. Text document, 6 pages Programming \nGuidelines We reused company internal Java programming guidelines. Text document, 10 pages Table 3: \nProject Artifacts 4. Project Two: Pay TV Planning System When the turbine layout tool project was completed \nin April 2000, another challenging project was about to start. This time the customer was a company developing \nand manufacturing equipment for Pay TV operators. This company had a project under way whose goal was \nto develop a TV program planning system. The system should support creating program schedules for multiple \nPay TV channels and controlling the equipment to actually broadcast the content according to a schedule. \nTechnically, the system was built as a client / server application, where the server was developed by \nthe customer and the client was contracted to us. The challenges of this project were very similar to \nthe previous one, i.e. unclear and changing requirements (the server part was in development, with little \ndocumentation available), a tight schedule, and the need to integrate software provided by the client. \nHaving been very successful with our RUP Light approach in the turbine layout tool project, we decided \nto try the same approach on this project. We assigned the same team plus one additional developer to \nthe new project. Configuration of RUP was also the same, with a few small improvements. For example, \nwe added unit testing with JUnit, a test plan, and use case storyboards. The implementation technology \nwas the same as before, i.e. Java 2 standard edition. Given the same team, the same process, and the \nsame technology, we expected to repeat the success of the previous project. Unfortunately we were wrong, \nthe difference was the customer. 4.1 Project Timeline Here is a chronological list of how events unfolded \nin this project. 1-May-2000 The project starts with a scheduled completion date of 30-Oct-2000. The team \nis highly motivated and confident that we can meet the goals of the project. 31-May-2000 Release 1.1.1 \nis delivered to the customer. June 2000 The customer provides no feedback to this release. In fact, the \ncustomer did not even install the software on their infrastruc\u00adture. Many requirements are still unclear. \nThe customer has no time to work with us on clarifying requirements. Key people from the customer are \nnot available, because they are assigned to other urgent projects and are most of the time occupied with \nfirefighting at their customer s sites all over the globe. We receive contra\u00addicting information from \ndifferent people in the customer s organization. Neverthe\u00adless, we carry on developing and work with \nassumptions of our own where we are missing information from the customer. 30-Jun-2000 Release 1.2.1 \nis delivered to the customer. July 2000 Like in June, the customer doesn t install the release delivered \nand provides no feedback at all. Our client is not yet integrated with the server, because a middleware \nlayer developed by the customer which is needed to access the server is late by 2 months and will probably \nnot be available before September 2000. We agree with the customer that we will develop a simple simulation \nof the middleware and the server in order to be able to test our client. 31-Jul-2000 Release 1.3.1 is \ndelivered to the customer, including a simulation of the middleware and the server. August 2000 Like \nJune and July.... 30-Aug-2000 Release 1.4.1 is delivered to the customer, still with a simulated middleware \nand simulated server. September For the very first time, the customer briefly looks at the software we \ncreated. As to be expected, the customer has many change request but no time to define the changes they \nwant in a sufficient level of detail. The middleware under development by the customer s organization \nis cancelled. We are asked to change direction and build the project s middleware based on the simulation \nwe developed in previous releases. The original task, i.e. developing the client, becomes second priority. \n30-Sep-2000 Release 1.5.1 is develivered to the customer, with a prototype of the middleware. October \n2000 The customer hires a usability expert to create a new GUI for the client. First results from the \nusability expert are available by mid of October. Also, the customer changes the database system from \nSQL Server to Oracle and changes the database schema a couple of times. This affects the client and the \nmiddleware. Also in October, one of our developers gets seriously sick and is not available for the entire \nmonth. 31-Oct-2000 Release 1.6.1 is delivered to the customer. This is the final release for us, as the \ncontract was time-bound and expired by end of October. The development team is completely frustrated \nand declines to continue to work on this project. In our last release we could implement about 70% of \nthe changes to the GUI requested by the usability expert, the middleware worked but could not be completely \nadapted to the changed database system and database schema, many change requests from the customer were \nnot implemented because there were no specifications for them, and some minor bugs remained in the software. \nWe learned later that the customer acquired a competitor and handed development of the entire system, \ni.e. server, client and middleware, to the acquired company. 4.2 Lessons Learned This project was clearly \nno success. The customer did not get what he wanted, we were not able to complete the project as planned, \nand the development team was utterly demoralized. The project was not a complete failure either, at least \nthe customer got a working piece of software, although not as complete as initially planned. The main \nreasons for the unfortunate outcome of the project were the complete lack of feedback from the customer \nduring the first 4 months of the project, and key people from the customer not being involved enough \nin the project. The relationship with the customer was positive and friendly during the entire project. \nKey people from the customer saw the necessity for user feedback and would have liked to provide more \nof it, but were in no position to do so because of other urgent tasks. We parted on good terms, even \nthough the project was not a success. The key lesson to be learned here is that no software process, \nregardless how sophisticated, can compensate for customer feedback. We are convinced that a different \nsetup of RUP would not have improved results, since the root cause of the problem was not a process issue \nbut a committment issue. In hindsight, we should have terminated the project after the second iteration \nwhen it became clear that there was no hope to receive feedback and sufficient support from the customer. \nOther than that, there is not much we could have done differently in order to get better results. 5. \nConclusions Since the two projects reported in this paper we have completed about a dozen more projects \nwith RUP, all in the range of 1 to 4 person years of effort and with teams of 3 to 8 developers. The \ninitial set of artifacts identified in the first project still forms the core of project documentation. \nSince then, we added unit testing with one of the xxUnit frameworks, a test plan, documented test cases \nfor system testing, and a risk list to the set of mandatory artifacts for every project. Even so, the \nnumber of artifacts is still low and not an unneccessary burden on a project. So far we had no complaints \nfrom developers that they have to write too much documentation, which we interpret as a good sign. Here \nare some suggestions to make RUP agile: Carefully select a small subset of artifacts and keep the level \nof detail of these artifacts down to a reasonable limit. Of the 80+ artifacts of RUP, only 10 to 12 are \nreally needed on small projects. The list of must have artifacts includes a software development plan, \nan iteration plan and iteration assessment for each iteration, a software architecture document, a vision \ndocument with a list of required features, a change request list, a defect list, and a few others. See \ntable 3 for further ideas.  Iteration planning should focus on the desired results of an iteration rather \nthan on the list of activities to be performed within an iteration. In this sense, the description of \nactivities and workflow details in the RUP online documentation can be viewed as a textbook which is \nconsulted when needed, rather than a template for detailed iteration planning.  The average amount \nof project management overhead was between 5 and 10% of the overall effort in the roughly 15 RUP projects \nwe completed so far. This disproves claims that RUP is a management-heavy process which creates prohibitively \nhigh management costs for small projects. Apart from the second project covered in this paper, all RUP \nprojects we did have been successful so far. The following conclusions are applicable regardless of what \nconcrete process is used: Iterative and incremental project planning are a key to success in projects \nwith many uncertainties such as vague and frequently changing requirements, unproven technology, or an \nunknown customer.  No amount of planning and project management can substitute for user and customer \nfeedback. Iterative and incremental development can not compensate for lack of feedback.  Even on small \nprojects, a person from the customer's organization who can spend at least 50% of his or her time for \nuser feedback and iteraton planning is essential.  We believe that our configuration of RUP is in the \ntrue spirit of agile methods. Ultimately, being agile is a mindset, which can be practiced with many \ndifferent processes, including lightweight versions of RUP. 6. References 1. Rational Software Corporation \nInc., RUP Online Documentation, Version 2002.05.00 (a commercial product of Rational Corp.) 2. Kruchten, \nPhilippe. The Rational Unified Process / An Introduction. Addison Wesley, 2000 3. Beck, Kent. Extreme \nProgramming Explained. Addison Wesley, 2000 4. The Agile Manifesto, www.agilemanifesto.org (as of August \n2002)    Making RUP Agile OOPSLA 2002 Practitioner Report Michal Hirsch Hirsch.Michael@acm.org Z\u00fchlke \nEngineering AG Wiesenstrasse 10a CH-8952 Schlieren Switzerland www.zuehlke.com Contents 1. Introduction \n 2. Adapting RUP for Small Projects 3. Project One: Steam Turbine Design Tool 4. Project Two: Pay TV \nPlanning System 5. Conclusions and Recommendations   Company Background  . Independent engineering \nand consulting company . Founded 1968 . Offices in Switzerland, Germany and England . Approx. 220 employees \n. Custom development of -Software systems -Electronics and mechanical components -Devices and systems \nrequiring skills in software, electronics, mechanical engineering and optics . Typical project size: \n1-10 person-years, 3 to 10 developers . Additional information on our website at www.zuehlke.com  \nHistory of Software Development at Z\u00fchlke Engineering 1975: First software projects for embedded systems \n1980s: Software development for minicomputers, with SA/SD/SP 1992: Decided to switch to OOT 1995: Transition \nto OOT completed Technology worked, but home-grown waterfall process was cumbersom 1998: Started looking \nfor iterative / incremental processes 1999: First RUP project started 2002: 15+ RUP projects successfully \ncompleted RUP is well established and naturally used in all software projects  RUP Overview  Some \nRUP numbers: . Current Version: RUP 2002 .  80 major artifacts . 150 activities . 40 roles   How \nWe Adapted RUP for Small Projects . Target project size: 3 to 8 developers, 6 to 12 months duration \n. Artifacts: focus on 10 to 15 core artifacts, skip the rest . Activities: used like a textbook, not \nused for planning . Roles: used as a checklist of skills . Project planning: -Coarse grained project \nplan, detailed iteration plans -Focus on results rather than tasks -Most important planning items: features \n-One iteration = one month -Well defined ownership of all artifacts . Project control: -Weekly status \nmeetings with estimation of remaining effort -Schedule has higher priority than functional completeness \n. Policies documented in RUP User Guide  Project One: Steam Turbine Design Tool Mission: Build a tool \nto design blades of steam turbines Customer: Alstom Power  Project Challenges . Very short development \ntime of < 9 months from first idea to first production release . Sophisticated user interface with 2D \nand 3D graphics . Integration of software developed by the customer (in Mathlab) for geometrical and \nthermodynamical calculations . Initially very vague requirements, because no previous tool existed \n Our Approach to meet the Challenges . Small team of experienced developers: Two Z\u00fchlke engineers \nplus one engineer from the customer . RUP Light, with monthly iterations . Early and intense involvement \nof the customer . Systematic requirements management based on features . Daily builds . Implementation \nin Java 2 / Standard Edition The result: finished project two months ahead of time, with all features \nrequired and with very few defects. Big party !  Some Project Statistics Team size (headcount): Team \nsize (full time equivalents): Number of use cases: Number of features: Number of change requests implemented: \nNumber of bugs found and fixed: Number of iterations: Project duration: Total effort in person days: \nNumber of Java classes implemented: Total LOC, including comment lines: 4 3.5 6 40 53 14 6 + 2 7 months \n260 about 180 about 30,000   Project Timeline Iter. Start End MS Release Inception Phase 1 2 1-0ct-1999 \n1-Nov-1999 30-Oct-1999 7-Dec-1999 --LCO R-1-1-1 (GUI layout) R-1-2-1 (Proof of concept) Elaboration Phase \n3 4 8-Dec-1999 1-Feb-2000 31-Jan-2000 29-Feb-2000 --LCA R-1-3-1 R-1-4-1 Construction Phase 5 1-Mar-2000 \n31-Mar-2000 IOC R-1-5-2 (Beta test release) Transition Phase 6 7 8 1-Apr-2000 6-Nov-2000 1-Dec-2000 30-Apr-2000 \n30-Nov-2000 22-Dec-2000 PR IOC PR R-1-6-2 (Production release 1) R-1-7-1 (Some new features) R-1-8-1 \n(Production release 2)   Project Artifacts Requirements Vision Document (15 pages) . Use Case Model \n(20 pages) Analyis and Design Software Architecture Doc. (12 pages) . Design Model (Together/J) Implementation \n Implementation Model (Java Source Files, Makefiles, Jbuilder)  Test Defect List (3 pages) Deployment \n Release notes (2 pages per release) . Installation Artifacts (ZIP file) Configuration and Change Management \n Configuration Mgmt Plan (8 pages) . Change Request List (4 pages) Project Management  Software Development \nPlan (8 pages) . Iteration Plans (4 to 6 pages) . Iteration Assessments (2 to 5 pages) Environment \nDevelopment Case (6 pages) . Java Programming Guidelines (10 pages)   Lessons Learned Factors that \ncontributed to the success of the project: . Iterative and incremental development (no hiding of the \ntruth) . Strong involvment of customer in project planning and monitoring . Fast and useful feedback \nfrom customer . Low overhead for project management (approx 7% of total effort) . Pragmatic but effective \nchange management . RUP framework saved a lot of time at project setup Areas to improve: . Systematic \ntesting effort . As a minimum, add unit testing with xxUnit tools . Collect some design metrics  \nProject Two: Pay TV Planning System Mission: . Build the client of a Pay-TV scheduling and control system \nChallenges: . Unclear and unstable requirements . Server software simultaneously developed by customer \n . Tight schedule . No documentation of server interface Our Approach: . Same team as before, plus \none additional developer . Same process configuration as before . Same technology as before (i.e. Java \n2)  Project Timeline 1-May-2000: 31-May-2000: June 2000: 30-Jun-2000: July 2000: 31-Jul-2000: August \n2000: Start of project, team is highly motivated and confident that we can repeat the previous success. \nRelease 1.1.1 delivered to customer. No feedback from customer, customer is too busy. Release 1.2.1 \ndelivered to customer. Still no feedback from customer. Middleware developed by customer is 2 months \nlate. Customer asks us to develop a simulation of the middleware. Release 1.3.1 delivered to customer, \nincluding simulated middleware and server. Like June and July...   Project Timeline (continued) 30-Aug-2000: \nRelease 1.4.1 delivered, still with simulated middleware and server. September: Customer looks at the \nsoftware for the first time. Many change requests concerning look and feel. Middleware developed by customer \nis cancelled. We are asked to change direction and extend our simulation into a real middleware. Client \nbecomes second priority. 30-Sep-2000: Release 1.5.1 delivered, with prototype of middleware. October: \nCustomer hires usability expert to design a new GUI. Customer changes DBMS from SQL Server to Oracle. \n31-Oct-2000: Release 1.6.1 delivered (last release, as contract was time bound). Not all change requests \nimplemented, a few bugs not fixed. Development team completely frustrated and declines to continue. \n Lessons Learned . Key lesson: No process, regardless how sophisticated, can compensate for missing \nfeedback from customer . Problem was not a process issue, but a commitment issue . Being agile doesn't \nsave you if the customer has no time for you Things we could have done to improve results: . Terminate \nproject when it became clear that the customer could not provide feedback . Maybe offload customer from \nother tasks to free up some time for providing feedback  Making RUP Agile: Conclusions . 15+ projects \nsuccessfully completed since the two projects in this presentation . Making RUP Agile is entirely practical \nand leads to an effective process if done right . Expect 5-10% of management overhead for RUP Light \n . RUP templates, guidelines, and process structure save a lot of time . Projects become comparable, \nwhich is a big advantage in supervising project portfolios  Conclusions (continued) Things to consider \nto make RUP agile: . Carefully select a small subset of artifacts . Iteration planning should primarily \nfocus on results (as opposed to focus on tasks to be done) . An iteration is a planning period, not a \nsingle build . Iterations of one month work very well . Even on small projects, insist on a person \nfrom the customer with at least 50% percent of his / her time available for the project Ultimately, being \nagile is a mindset, which can be practiced with many different processes, including lightweight versions \nof RUP  Questions &#38; Answers   \n\t\t\t", "proc_id": "604251", "abstract": "The Unified Development Process (USDP) and especially its implementation by Rational Software Corporation, the Rational Unified Process (RUP), is a comprehensive process covering almost all aspects of software development projects. However, due to the great level of detail provided by RUP, many professionals do not consider RUP practical for small, fast paced projects. This paper reports the experiences with RUP on two small projects with teams of 3 to 5 developers. RUP proved to be adaptable to the needs of small projects and was very effective in both projects. One key to the successful application of RUP in small projects is the careful selection of a proper subset of artifacts and keeping these artifacts very concise and free from unnecessary formalism. This paper goes into the details of what it takes to make RUP agile, how it was applied in the two projects, and how it was configured. Also covered is what elements of RUP contributed to the success of one project, and why RUP could not prevent that the outcome of the other project was less than optimal.", "authors": [{"name": "Michael Hirsch", "author_profile_id": "81342497489", "affiliation": "Z&#252;hlke Engineering AG, Schlieren, Switzerland", "person_id": "PP31040099", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/604251.604254", "year": "2002", "article_id": "604254", "conference": "OOPSLA", "title": "Making RUP agile", "url": "http://dl.acm.org/citation.cfm?id=604254"}