{"article_publication_date": "06-16-2013", "fulltext": "\n Finding Optimum Abstractions in Parametric Data.ow Analysis Xin Zhang Mayur Naik Hongseok Yang Georgia \nInstitute of Technology, USA Georgia Institute of Technology, USA University of Oxford, UK xin.zhang@gatech.edu \nnaik@cc.gatech.edu hongseok.yang@cs.ox.ac.uk Abstract We propose a technique to ef.ciently search a \nlarge family of ab\u00adstractions in order to prove a query using a parametric data.ow analysis. Our technique \neither .nds the cheapest such abstraction or shows that none exists. It is based on counterexample-guided \nabstraction re.nement but applies a novel meta-analysis on abstract counterexample traces to ef.ciently \n.nd abstractions that are inca\u00adpable of proving the query. We formalize the technique in a generic framework \nand apply it to two analyses: a type-state analysis and a thread-escape analysis. We demonstrate the \neffectiveness of the technique on a suite of Java benchmark programs. Categories and Subject Descriptors \nD.2.4 [SOFTWARE EN-GINEERING]: Software/Program Veri.cation; F.3.2 [LOGICS AND MEANINGS OF PROGRAMS]: \nSemantics of Programming Languages Program analysis General Terms Languages, Veri.cation Keywords Data.ow \nanalysis, CEGAR, abstraction re.nement, optimum abstraction, impossibility, under-approximation 1. Introduction \nA central problem in static analysis concerns how to balance its precision and cost. A query-driven analysis \nseeks to address this problem by searching for an abstraction that discards program details that are \nunnecessary for proving an individual query. We consider query-driven data.ow analyses that are parametric \nin the abstraction. The abstraction is chosen from a large family that allow abstracting different parts \nof a program with varying precision. A large number of .ne-grained abstractions enables an analysis to \nspecialize to a query but poses a hard search problem in practice. First, the number of abstractions \nis in.nite or intractably large to search na\u00a8ively, with most abstractions in the family being too imprecise \nor too costly to prove a particular query. Second, proving queries in different parts of the same program \nrequires different abstractions. Finally, a query might be unprovable by all abstractions in the family, \neither because the query is not true or due to limitations of the analysis at hand. We propose an ef.cient \ntechnique to solve the above search problem. It either .nds the cheapest abstraction in the family that \nproves a query or shows that no abstraction in the family can prove the query. We call this the optimum \nabstraction problem. Our tech\u00adnique is based on counterexample-guided abstraction re.nement Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 13, June 16 \n19, 2013, Seattle, WA, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . $10.00 (CEGAR) \nbut differs radically in how it analyzes an abstract coun\u00adterexample trace: it computes a suf.cient condition \nfor the failure of the analysis to prove the query along the trace. The condition represents a set of \nabstractions such that the analysis instantiated using any abstraction in this set is guaranteed to fail \nto prove the query. Our technique .nds such unviable abstractions by doing a backward analysis on the \ntrace. This backward analysis is a meta\u00adanalysis that must be proven sound with respect to the abstract \nse\u00admantics of the forward analysis. Scalability of backward analyses is typically hindered by exploring \nprogram states that are unreachable from the initial state. Our backward analysis avoids this problem \nas it is guided by the trace from the forward analysis. This trace also enables our backward analysis \nto do under-approximation while guaranteeing to .nd a non-empty set of unviable abstractions. Like the \nforward analysis, the backward meta-analysis is a static analysis, and the performance of our technique \ndepends on how this meta-analysis balances its own precision and cost. If it does under-approximation \naggressively, it analyzes the trace ef.ciently but .nds only the current abstraction unviable and needs \nmore itera\u00adtions to converge. On the other hand, if it does under-approximation passively, it analyzes \nthe trace inef.ciently but .nds many abstrac\u00adtions unviable and needs fewer iterations. We present a \ngeneric framework to develop an ef.cient meta-analysis, which involves choosing an abstract domain, devising \n(backward) transfer func\u00adtions, and proving these functions sound with respect to the forward analysis. \nOur framework uses a generic DNF representation of for\u00admulas in the domain and provides generic optimizations \nto scale the meta-analysis. We show the applicability of the framework to two analyses: a type-state \nanalysis and a thread-escape analysis. We evaluate our technique using these two client analyses on seven \nJava benchmark programs of 400K 600K bytecodes each. Both analyses are fully .ow-and context-sensitive \nwith 2N pos\u00adsible abstractions, where N is the number of pointer variables for type-state analysis, and \nthe number of object allocation sites for thread-escape analysis. The technique .nds the cheapest abstrac\u00adtion \nor shows that none exists for 92.5% of queries posed on aver\u00adage per client analysis per benchmark program. \nWe summarize the main contributions of this paper: We formulate the optimum abstraction problem for \nparametric data.ow analysis. The formulation seeks a cheapest abstraction that proves the query or an \nimpossibility result that none exists.  We present a new re.nement-based technique to solve the prob\u00adlem. \nThe key idea is a meta-analysis that analyzes counterexam\u00adples to .nd abstractions that are incapable \nof proving the query.  We present a generic framework to design the meta-analysis along with an ef.cient \nrepresentation and optimizations to scale it. We apply the framework to two analyses in the literature. \n We demonstrate the ef.cacy of our technique in practice on the two analyses, a type-state analysis \nand a thread-escape analysis, for several real-world Java benchmark programs.   The rest of the paper \nis organized as follows. Section 2 illus\u00adtrates our technique on an example. Section 3 formalizes paramet\u00adric \ndata.ow analysis and the optimum abstraction problem. We .rst de.ne a generic framework and then apply \nit to our two example analyses. Section 4 presents our meta-analysis, .rst in a generic set\u00adting and \nthen for a domain that suf.ces for our two analyses. Sec\u00adtion 5 gives our overall algorithm and Section \n6 presents empirical results. Section 7 discusses related work and Section 8 concludes. 2. Example We \nillustrate our technique using the program in Figure 1(a). The program operates on a File object which \ncan be in either state opened or closed at any instant. It begins in state closed upon creation, transitions \nto state opened after the call to open(), and back to state closed after the call to close(). Suppose \nthat it is an error to call open() in the opened state, or to call close() in the closed state. Statements \ncheck 1 and check 2 at the end of the program are queries which ask whether the state of the File object \nis closed or opened, respectively, at the end of every program run. A static type-state analysis can \nbe used to conservatively answer such queries. Such an analysis must track aliasing relationships between \npointer variables in order to track the state of objects correctly and precisely. For instance, in our \nexample program, the analysis must infer that variables x and y point to the same File object in order \nto prove query check 1. Analyses that track more program facts are typically more precise but also more \ncostly. A query-based analysis enables striking a balance between precision and cost by not tracking \nprogram facts that are unnecessary for proving an individual query. Making our type-state analysis query-based \nenables it to track only variables that matter for answering a particular query (such as check 1). We \ntherefore parameterize this analysis by an abstraction p which speci.es the set of variables that the \nanalysis must track. An abstraction p1 is cheaper than an abstraction p2 if p1 tracks fewer variables \nthan p2 (i.e., |p1| < |p2|). For a program with N variables there are 2N possible abstractions. Figure \n1(b) shows which abstractions in this family are suitable for each of our two queries. Any abstraction \ncontaining variables x and y is precise enough to let our analysis prove query check 1. The cheapest \nof these abstractions is {x, y}. On the other hand, our analysis cannot prove query check 2 using any \nabstraction in the family. This is because query check 2 is not true concretely, but the analysis may \nfail to prove even true queries due to its conservative nature. We propose an ef.cient technique for \n.nding the cheapest ab\u00adstraction in the family that proves a query or showing that no ab\u00adstraction in \nthe family can prove the query. We illustrate our tech\u00adnique on our parametric type-state analysis. This \nanalysis is fully .ow-and context-sensitive, and tracks for each allocation site in the program a pair \n(ts, vs) or T, where ts over-approximates the set of possible type-states of an object created at that \nsite, and vs is a must-alias set a set of variables that de.nitely point to that object. Only variables \nin the abstraction p used to instantiate the analysis are allowed to appear in any must-alias set. T \ndenotes that the analysis has detected a type-state error. Our technique starts by running the analysis \nwith the cheapest abstraction. For our type-state analysis this corresponds to not tracking any variable \nat all. The resulting analysis fails to prove query check 1. Our technique is CEGAR-based and requires \nthe analysis to produce an abstract counterexample trace as a failure witness. Such a trace showing the \nfailure to prove query check 1 under the cheapest abstraction is shown in Figure 1(c). The trace is annotated \nwith abstract states computed by the analysis, denoted ., that track information about the lone allocation \nsite in the program. Note that state ({closed}, {}) incoming into call x.open() results in outgoing state \n({opened, closed}, {}) even though the File object cannot be in the closed state after the call. This \nis because the analysis does a weak update as x is not in the must-alias set of the incoming abstract \nstate. At this point our technique has eliminated abstraction p = {}as incapable of proving query check \n1 and must determine which abstraction to try next. Since the number of abstractions is large, however, \nit .rst analyzes the trace to eliminate abstractions that are guaranteed to suffer a failure similar \nto the current one. It does so by performing a backward meta-analysis that inspects the trace backwards \nand analyzes the result of the (forward) type\u00adstate analysis. This meta-analysis is itself a static analysis \nand the abstract states it computes are denoted by . in Figure 1(c). Each abstract state of the meta-analysis \nrepresents a set of pairs (d, p) consisting of an abstract state d of the forward analysis and an abstraction \np. An abstract state of the meta-analysis is a boolean formula over primitives of the form: (1) err representing \nthe set of pairs where the d component is T; (2) closed . ts representing the set of pairs where the \nd component is (ts, vs) and ts contains closed; (3) x . vs which is analogous to (2) except that vs contains \nx; and (4) x . p meaning the p component contains x. The meta-analysis starts with the weakest formula \nunder which check 1 fails, which is err . (opened . ts), and propagates its weakest precondition at each \nstep of the trace to obtain formula (closed . ts) . (opened ./ts) . (x /. p) at the start of the trace. \nThis formula implies that any abstraction not containing variable x cannot prove query check 1. Our meta-analysis \nhas two notable as\u00adpects. First, it does not require the family of abstractions to be .nite: it can show \nthat all abstractions in even an in.nite family cannot prove a query. Second, it avoids the blowup inherent \nin backward analyses by performing under-approximation. It achieves this for the above domain of boolean \nformulae by dropping disjuncts in the DNF representation of the formulae. A crucial condition ensured \nby our meta-analysis during under-approximation is that the abstract state computed by the forward analysis \nis contained in the resulting simpler formula. Otherwise, it is not possible to guarantee that the eliminated \nabstractions cannot prove the query. Section 4 explains how our technique picks the best k disjuncts \nfor a k = 1 speci\u00ad.ed by the analysis designer. Smaller k enables the meta-analysis to run ef.ciently \non each trace but can require more iterations by eliminating only the current abstraction in each iteration \nin the ex\u00adtreme case. We use k = 1 for this example and highlight in bold the chosen (retained) disjunct \nin each formula with multiple disjuncts in Figure 1. For instance, we drop the second disjunct in formula \nerr.(opened . ts) at the end point of the trace in Figure 1(c), since abstract state T computed by the \nforward analysis at that point is not in the set of states represented by (opened . ts). The weak\u00adest \nprecondition of the chosen disjunct err with respect to the call y.close() is err.(closed . ts), but \nthis time we drop disjunct err as the abstract state ({closed, opened}, {}) computed by the forward analysis \nis not in the set of states represented by err. Having eliminated all abstractions that do not contain \nvariable x, our technique next runs the type-state analysis with abstraction p = {x}, but again fails \nto prove query check 1, and produces the trace showed in Figure 1(d). Our meta-analysis performed on \nthis trace infers that any abstraction containing variable x but not containing variable y cannot prove \nthe query. Hence, our technique next runs the type-state analysis with abstraction p = {x, y}, and this \ntime succeeds in proving the query. Our technique is effective at slicing away program details that are \nirrelevant to proving a query. For instance, even if either of the traces in Figure 1 (c) or (d) contained \nthe statement if (*) z = x , variable z would not be included in any abstraction that our technique tries; \nindeed, tracking variable z is not necessary for proving query check 1. Finally, consider the query check \n2. Our technique starts with the cheapest abstraction p = {}, and obtains a trace identical  x = new \nFile; y = x; if (*) z = x; x.open(); y.close(); if (*) check 1(x, closed); else check 2(x, opened); \n(a) Example program. query abstraction check 1 any p . {x, y} check 2 none (b) Feasible solutions. . \nclosed . ts . opened ./ts . x /. p x = new File; . ({closed}, {}) . closed . ts . opened ./ts . x /. \nvs y = x; . ({closed}, {}) . closed . ts . opened ./ts . x /. vs x.open(); . ({closed, opened}, {}) . \nerr . closed . ts y.close(); . T . err . opened . ts check 1(x, closed);  (c) Iteration 1 for query \ncheck 1 using p = {}. . closed . ts . opened ./ts . y /. p . x . p x = new File; . ({closed}, {x}) \n. closed . ts . opened ./ts . y /. p . x . vs y = x; . ({closed}, {x}) . closed . ts . opened ./ts . \ny /. vs . x . vs x.open(); . ({opened}, {x}) . opened . ts . closed ./ts . y /. vs y.close(); . ({closed, \nopened}, {x}) . err . opened . ts check 1(x, closed);  (d) Iteration 2 for query check 1 using p = \n{x}. . closed . ts . opened ./ts . x . p x = new File; . ({closed}, {x}) . closed . ts . opened ./ts \n. x . vs y = x; . ({closed}, {x}) . closed . ts . opened ./ts . x . vs x.open(); . ({opened}, {x}). opened \n. ts . closed ./ts y.close(); . ({closed, opened}, {x}) . err . closed . ts check 2(x, opened);  (e) \nIteration 2 for query check 2 using p = {x}.  Figure 1. Example illustrating our technique for a parametric \ntype-state analysis. to that in Figure 1(b) for query check 1, except that the meta\u00adanalysis starts by \npropagating formula err . (closed . ts) instead of err . (opened . ts). The same disjunct err in this \nformula is retained and the rest of the meta-analysis result is identical. Thus, in the next iteration, \nour technique runs the type-state analysis with abstraction p = {x}, and obtains the trace shown in Figure \n1(e). This time, the meta-analysis retains disjunct (closed . ts), and concludes any abstraction containing \nvariable x cannot prove the query. Since in the .rst iteration all abstractions without variable x were \neliminated, our technique concludes that the analysis cannot prove query check 2 using any abstraction. \n3. Formalism This section describes a formal setting used throughout the paper. 3.1 Programming Language \nWe present our results using a simple imperative language: (atomic command) a ::= ... (program) s ::= \na | s ; s' | s + s' | s * The language includes a (unspeci.ed) set of atomic commands. Examples are assignments \nv = w.f and statements assume(e) which .lter out executions where e evaluates to false. The language \nalso has the standard compound constructs: sequential composi\u00adtion, non-deterministic choice, and iteration. \nA trace t is a .nite se\u00adquence of atomic commands a1a2 . . . an. It records the steps taken during one \nexecution of a program. Function trace(s) in Figure 2 shows a standard way to generate all traces of \na program s.  3.2 Parametric Data.ow Analysis We consider data.ow analyses whose transfer functions \nfor atomic commands are parametric in the abstraction. We specify such a parametric analysis by the following \ndata: 1. A set (P, :) with a preorder : (i.e., : is re.exive and tran\u00adsitive). Elements p . P are parameter \nvalues. We call them abstractions as they determine the degree of approximation per\u00adformed by the analysis. \nThe preorder : on p s dictates the cost of the analysis: using a smaller p yields a cheaper analysis. \nWe require that every nonempty subset P . Phas a minimum ele\u00adment p . P (i.e., p : p' for every p' . \nP ). trace(a' ) = {a} 'trace(s + s) = trace(s) . trace(s) trace(s ; s') = {t t ' | t . trace(s) . t ' \n. trace(s')}trace(s * ) = leastFix .T . {E} . {t; t ' | t . T . t ' . trace(s)} Figure 2. Traces of a \nprogram s. Symbol E denotes an empty trace. 2. A .nite set D of abstract states. Our analysis uses a \nset of abstract states to approximate reachable concrete states at each program point. Formally, this \nmeans the analysis is disjunctive. 3. A transfer function [a]p : D . Dfor each atomic command a. The \nfunction is parameterized by p . P.  A parametric analysis analyzes a program in a standard way ex\u00adcept \nthat it requires an abstraction to be provided before the anal\u00adysis starts. The abstract semantics in \nFigure 3 describes the behav\u00adior of the analysis formally. In the .gure, a program s denotes a transformer \nFp[s] on sets of abstract states, which is parameterized by p . P. Note that the abstraction p is used \nwhen atomic com\u00admands are interpreted. Hence, p controls the analysis by changing the transfer functions \nfor atomic commands. Besides this parame\u00adterization all the de.ning clauses are standard. Our parametric \nanalyses satisfy a fact of disjunctive analyses: LEM M A 1. For all programs s, abstractions p, and abstract \nstates d, we have Fp[s]({d}) = {Fp[t](d) | t . trace(s)}, where Fp[t ] is the result of analyzing trace \nt as shown in Figure 3. The lemma ensures that for all .nal abstract states d' . Fp[s]({d}), we can construct \na trace t transforming d to d'. This trace does not have loops and is much simpler than the original \nprogram s. We show later how our technique exploits this simplicity (Section 4). We now formalize two \nexample parametric analyses. Type-State Analysis. Our .rst example is a variant of the type\u00adstate analysis \nfrom [7]. The original analysis maintains various kinds of aliasing facts in order to track the type-state \nof objects correctly and precisely. Our variant only tracks must-alias facts. We assume we are given \na set T of type-states containing init, which represents the initial type-state of objects, and a function \n[m] : T . T. {T} for every method m, which describes how a call x.m() changes the type-state of object \nx and when it leads to  Fp[s] : 2D . 2D Fp[a](D) = {[a]p(d) | d . D} Fp[s ; s ' ](D) = (Fp[s ' ] . Fp[s])(D) \nFp[s + s ' ](D) = Fp[s](D) . Fp[s ' ](D) Fp[s * ](D) = leastFix .D0. D . Fp[s](D0) Fp[t ] : D . D Fp[E](d) \n= d Fp[a](d) = [a]p(d) Fp[t ; t ' ](d) = Fp[t ' ](Fp[t](d)) Figure 3. Abstract semantics. In the case \nof loop, we take the least .xpoint with respect to the subset order in the powerset domain 2D . (type-states) \ns . T (we assume init . T) (variables) x, y . V (analysis parameter) p . P = 2V (abstract state) d . \nD = (2T \u00d7 2V) . {T} (order on parameters) p : p ' . |p| = |p ' | (transfer function) : D . D [a]p [a]p(T) \n= T (ts, vs . {x}) if y . vs . x . p [x = y]p(ts, vs) = (ts, vs \\ {x}) otherwise = null]p(ts, vs) = \n(ts, vs \\ {x}) [x . .T if .s . ts. [m](s) = T [x.m()]p(ts, vs) = ({[m](s) | s . ts}, vs) else if x . \nvs . (ts . {[m](s) | s . ts}, vs) otherwise Figure 4. Data for the type-state analysis. an error, denoted \nT. Using these data, we specify the domains and transfer functions of the analysis in Figure 4. The abstraction \np for the analysis is a set of variables that determines what can appear in the must-alias set of an \nabstract state during the analysis. An abstract state d has form (ts, vs) or T, where vs should be a \nsubset of p, and it tracks information about a single object. In the former case, ts represents all the \npossible type\u00adstates of the tracked object and vs, the must-alias set of this object. The latter means \nthat the object can be in any type-state including the error state T. For brevity, we show transfer functions \nonly for simple assignments and method calls. Those for assignments x = y and x = null update the must-alias \nset according to their concrete semantics and abstraction p. The transfer function for a method call \nx.m() updates the ts component of the input abstract state using [m]. In the case where the must-alias \nset is imprecise, this update includes both the old and new type-states. According to our order :, an \nabstraction p is smaller than p ' when its cardinality is smaller than p ' . Hence, running this analysis \nwith a smaller p implies that the analysis would be less precise about must-alias sets, which normally \ncorrelates the faster convergence of the .xpoint iteration of the analysis. Thread-Escape Analysis. Our \nsecond example is a variant of the thread-escape analysis from [17]. A heap object in a multithreaded \nshared-memory program is thread-local when it is reachable only from at most a single thread. A thread-escape \nanalysis conserva\u00adtively answers queries about thread locality. Let Hbe the set of allocation sites, \nLthat of local variables, and F that of object .elds in a program. Using these data, we specify the domains \nand transfer functions of the analysis in Figure 5. There N means the null value, and L and E are abstract \nlocations, representing disjoint sets of heap objects, except that both L and E include the null value. \nAbstract location E summaries null, all the thread-escaping objects, and possibly some thread-local ones. \nOn the other hand, L denotes all the other heap objects and null; hence it means only thread-local objects, \nalthough it might miss some such objects. The analysis maintains an invariant that E\u00adsummarized objects \nare closed under pointer reachability: if a heap object is summarized by E, following any of its .elds \nalways gives null or E-summarized objects, but not L-summarized ones. An abstraction p determines for \neach site h . H whether L or E should be used to summarize objects allocated at h. An abstract element \nd is a function from local variables or .elds of L\u00adsummarized objects to abstract locations or N. It \nrecords the values of local variables and those of the .elds of L-summarized heap objects. For instance, \nabstract state [v . L, f1 . E, f2 . E] means that local variable v points to some heap object summarized \nby L, and .elds f1, f2 of every L object point to those summarized by E. Since all thread-escaping objects \nare summarized by E, this abstract state implies that v points to a thread-local heap object. We order \nabstractions p : p ' based on how many sites are mapped to L by p and p ' . This is because the number \nof L-mapped sites usually correlates the performance of the analysis. The thread-escape analysis includes \ntransfer functions of the following heap-manipulating commands: a ::= v = new h | g = v | v = g | v = \nnull | v = v ' |v = v ' .f | v.f = v ' Here g and v are global and local variables, respectively, and \nh . H is an allocation site. Transfer functions of these commands simulate their usual meanings but on \nabstract instead of concrete states. Function [v = new h]p(d) makes variable v point to abstract location \np(h), simulating the allocation of a p(h)-summarized ob\u00adject and the binding of this object with v. The \ntransfer function for g = v models that if v points to a thread-local object, this assign\u00adment makes \nthe object escape, because it exposes the object to other threads via the global variable g. When v points \nto L, the transfer function calls esc(d), which sets all local variables to E (unless they have value \nN) and resets all .elds to N. This means that after calling esc(d), the analysis loses most of the information \nabout thread lo\u00adcality, and concludes that all variables point to potentially escaping objects. This \ndramatic information loss is inevitable because if v points to L beforehand, the assignment g = v can \ncause any object summarized by L to escape. The transfer functions of the remaining commands in the .gure \ncan be understood similarly by referring to the concrete semantics and approximating it over abstract \nstates. Figure 6 shows the abstract state (denoted by .) computed by our thread-escape analysis at each \npoint of an example program. The results of the analysis in parts (a) and (b1) of the .gure are obtained \nusing the same abstraction [h1 . E, h2 . E] and are thus identical; the results in part (b2) are obtained \nusing a different abstraction [h1 . L, h2 . E].  3.3 Optimum Abstraction Problem Parametric data.ow \nanalyses are used in the context of query\u00addriven veri.cation where we are given not just a program to \nanalyze but also a query to prove. In this usage scenario, the most important matter to resolve before \nrunning the analysis is to choose a right abstraction p. Ideally, we would like to pick p that causes \nthe analysis to keep enough information to prove a given query for a given program, but to discard information \nunnecessary for this proof, so that the analysis achieves high ef.ciency. The optimum abstraction problem \nprovides a guideline on re\u00adsolving the issue of abstraction selection. It sets a speci.c target on abstractions \nto aim at. Assume that we are interested in queries expressed as subsets of D. The problem is de.ned \nas follows:  . [u . N, v . N] . [u . N, v . N] . [u . N, v . N] . h1.E . (h2.E . h1.L) . h1.E . h1.L \n. h2.E u = new h1; u = new h1; u = new h1; . [u . E, v . N] . [u . E, v . N] . [u . L, v . N] . u.E . \n(h2.E . u.L) . (h2.L . f.E . u.L) . u.E . u.L . h2.E v = new h2; v = new h2; v = new h2; . [u . E, v \n. E] . [u . E, v . E] . [u . L, v . E] . u.E . (v.E . u.L) . (v.L . f.E . u.L) . u.E . u.L . v.E v.f \n= u; v.f = u; v.f = u; . [u . E, v . E] . [u . E, v . E] . [u . E, v . E] . u.E . u.E . u.E pc: local(u)? \npc: local(u)? pc: local(u)? (a) p = [h1 . E, h2 . E] (b1) p = [h1 . E, h2 . E] (b2) p = [h1 . L, h2 . \nE] Figure 6. Example showing our technique for thread-escape analysis with under-approximation (parts \n(b1) and (b2)) and without (part (a)). proving a query often does not exist or it is expensive to compute,(allocation \nsites) h . H so they ask for a minimal abstraction instead. (local variables) v . V Our approach to solve \nthe problem is based on using a form(object .elds) f . F of a backward meta-analysis that reasons about \nthe behavior of a(analysis parameter) p . P = H . {L, E} parametric data.ow analysis under different \nabstractions simulta\u00ad(abstract state) d . D = (L. F) . {L, E, N} neously. We explain this backward meta-analysis \nnext. (order on parameters) p : p ' . |{h . H | p(h) = L}| = |{h . H | p ' (h) = L}| esc : D . D 4. \nBackward Meta-Analysis esc(d) = .u. if (d(u) = N . u . F) then N else E In this section, we .x a parametric \ndata.ow analysis (P, :, D, [-]) (transfer function) : D . D and describe corresponding backward meta-analyses. \nTo avoid the [a]p confusion between these two analyses, we often call the parametric [v = analysis as \nforward analysis. new h p(d) = d[v . p(h)] g = v p(d) = if (d(v) = L) then esc(d) else d A backward meta-analysis \nis a core component of our algorithm[ v = g p(d) = d[v . E] for the optimum abstraction problem. It is \ninvoked when the for\u00ad= null [v = d[v . d(v T p(d) = d[v . N] ward analysis fails to prove a query. The \nmeta-analysis attempts [v [v ' ' ] p(d) )] to determine why a run of the forward analysis with a speci.c \nab\u00ad ' v = d[v . d(f)] if (d(v ) = L) straction p fails to prove a query, and to generalize this reason. \n' = v = d[v . E] otherwise Concretely, the inputs to the meta-analysis are a trace t , an ab\u00ad ' straction \np, and an initial abstract state dI , such that the p instance .f]p(d) v ]p(d) = if d(v) = E . d(v ' \nif (d(v) = E . d(v of the forward analysis fails to prove that a given query holds at [v.f = esc(d) . \n. . .. ) = L ' the end of t . Given such inputs, the meta-analysis analyzes t back\u00ad = L) . d(v) = N \nd ) ' )} = {L, E} ward, and collects abstractions that lead to a similar veri.cation ' esc(d) failure \nof the forward analysis. The collected abstractions are used if d(v) = L . {d(f), d(v d[f . L] if d(v) \n= L . {d(f), d(v d[f . E] if d(v) = L . {d(f), d(v if d(v) = L . d(f) = d(v )} = {N, L} ' )} = {N, E} \nsubsequently when our top-level algorithm computes a necessary ' ) . . . condition on abstractions for \nproving the given query and chooses d Figure 5. Data for the thread-escape analysis. DEFINITION 2 (Optimal \nAbstraction Problem). Given a program s, an initial abstract state dI , and a query q . D, .nd a minimum \nabstraction1 p such that Fp[s]{dI } . q, (1) or show that Fp[s]{dI } . q does not hold for any p. The \nproblem asks for not a minimal p but a minimum hence cheap\u00adest one. This requirement encourages any solution \nto exploit cheap abstractions (determined by :) as much as possible. Note that the requirement is aligned \nwith the intended meaning of :, which com\u00adpares abstractions in terms of the analysis cost. A different \nway of comparing abstractions in terms of precision rather than cost is taken in Liang et al. [15]. In \ntheir case, a minimum abstraction for 1 The condition that p be minimum means: if Fp1 [s]dI . q, then \np : p ' . In contrast, the minimality of p means the absence of p ' that satis.es (1) and is strictly \nsmaller than p according to :. a next abstraction to try based on this condition. Formally, the meta-analysis \nis speci.ed by the following data: A set Mand a function P\u00d7D . : M . 2. Elements in M are the main data \nstructures used by the meta\u00adanalysis, and . determines their meanings. We suggest to read elements in \nMas predicates over P\u00d7D. The meta-analysis uses such a predicate f . M to express a suf.cient condition \nfor veri.cation failure: for every (p, d) . .(f), if we instantiate the forward analysis with p and run \nthis instance from the abstract state d (over the part of a trace analyzed so far), we will fail to prove \na given query. A function b : M . M [a]for each atomic command a. The input f1 . M represents a postcondition \non P\u00d7 D. Given such f1, the function computes the weakest precondition f such that running [a] from any \nabstract state in .(f) has an outcome in .(f1). This intuition  B[t] : P\u00d7 D\u00d7 M . M B[E](p, d, f) = f \nB[a](p, d, f) = approx(p, d, [a]b(f)) B[t ; t ' ](p, d, f) = B[t](p, d, B[t ' ](p, Fp[t ](d), f)) Figure \n7. Backward meta-analysis. toDNF(f) transforms f to the DNF form and sorts disjuncts by size V simplify(V{fi \n| i . {1, . . . , n}}) = {fi | i . {1, . . . , n} . \u00ac(.j < i.fj . fi)} V dropk(p, d, {fi | i . {1, . \n. . , n}}) = V ( {fi | i . {1, . . . , min(k - 1, n)}}) . fj (where (p, d) . .(fj ) and j is the smallest \nsuch index) Figure 8. Functions for manipulating f s. is formalized by the following requirement on [a]b: \n.f1 . M. .([a] b(f1)) = {(p, d) | (p, [a]p(d)) . .(f1)}. (2) A function approx : P\u00d7 D\u00d7 M . M. The function \nis required to meet the following two conditions: 1. .p, d, f. . (approx(p, d, f)) . .(f); and 2. .p, \nd, f. (p, d) . .(f) . (p, d) . .(approx(p, d, f)).  The .rst ensures that approx(p, d, f) under-approximates \nthe input f, and the second says that this under-approximation should keep at least (p, d), if it is \nalready in .(f). The main purpose of approx is to simplify f. For instance, when f is a logical formula, \napprox converts f to a syntactically simpler one. The operator is invoked frequently by our meta-analysis \nto keep the complexity of the M value (the analysis s main data structure) under control. Using the given \ndata, our backward meta-analysis analyzes a trace t backward as described in Figure 7. For each atomic \ncommand a in t, it transforms an input f using [a]b .rst. Then, it simpli.es the resulting f ' using \nthe approx operator. Our meta-analysis correctly tracks a suf.cient condition that the forward analysis \nfails to prove a query. This condition is not trivial (i.e., it is a satis.able formula), and includes \nenough information about the current failed veri.cation attempt on t by the forward analysis. Our theorem \nbelow formalizes these guarantees. Proofs of all theorems are provided in the supplementary material. \nTH EO R E M 3 (Soundness). For all t , p, d and f . M, 1. (p, Fp[t](d)) . .(f) . (p, d) . .(B[t](p, d, \nf)); and 2. .(p0, d0) . .(B[t ](p, d, f)). (p0, Fp0 [t ](d0)) . .(f).  4.1 Disjunctive Meta-Analysis \nand Underapproximation Designing a good under-approximation operator approx is impor\u00adtant for the performance \nof a backward meta-analysis, and it often requires new insights. In this subsection, we identify a special \nsub\u00adclass of meta-analyses, called disjunctive meta-analyses, and de.ne a generic under-approximation \noperator for these meta-analyses. Both our example analyses have disjunctive meta-analyses and use the \ngeneric under-approximation operator. A meta-analysis is disjunctive if the following conditions hold: \nThe set Mconsists of formulas f: f ::= p | true | false | \u00acf | f.f ' | f.f ' (p . PForm) (primitive formula) \np . PForm p ::= err | param(x) | var(x) | type(s) .(err) = {(p, T)}.(param(x)) = {(p, d) | x . p}.(var(x)) \n= {(p, (ts, vs)) | x . vs}.(type(s)) = {(p, (ts, vs)) | s . ts} p . p ' . p = p ' f . f ' . f = f ', \nor both f and f ' are conjunction of primitive formulas and for every conjunct p ' of f ', there exists \na conjunct p of f such that p . p ' Figure 9. Data for backward meta-analysis for type-state analysis. \nwhere PForm is a set of primitive formulas, and the boolean operators have the standard meanings: .(true) \n= P\u00d7 D .(false) = \u00d8 .(\u00acf) = (P\u00d7 D) \\ .(f) .(f.f ' ) = .(f) n .(f ' ) .(f.f ' ) = .(f) . .(f ' ) The set \nMcomes with a binary relation . such that '' ' .f, f . M. f . f . .(f) . .(f ). The domain M of a disjunctive \nmeta-analysis in a sense contains all boolean formulas which are constructed from primitive ones in PForm. \nWe de.ne a generic under-approximation operator for disjunctive meta-analyses as follows: approx : P\u00d7 \nD\u00d7 M . M approx(p, d, f) = let f ' = (simplify . toDNF)(f) in if (number of disjuncts in f ' = k) then \nf ' else dropk(p, d, f ' ) Subroutines toDNF, simplify, and drop are de.ned in Figure 8. The approx operator \n.rst transforms f to disjunctive normal form and removes redundant disjuncts in the DNF formula that \nare subsumed by other shorter disjuncts in the same formula. If the resulting formula f ' is simple enough \nin that it has no more than k disjuncts (where k is pre-determined by an analysis designer), then f ' \nis returned as the result. Otherwise, some disjuncts of f ' are pruned: the .rst k - 1 disjuncts according \nto their syntactic size survive, together with the shortest disjunct fj that includes the input (p, d) \n(i.e., (p, d) . .(fj )). Our pruning is an instance of beam search in Arti.cial Intelligence which keeps \nonly the most promising k options during exploration of a search space. Meta-Analysis for Type-State. \nWe de.ne a disjunctive meta\u00adanalysis for our type-state analysis using the above recipe. Doing so means \nde.ning three entities shown in Figures 9 and 10: the set of primitive formulas, the order . on formulas, \nand a function [-]b . The meta-analysis uses three primitive formulas. The .rst is err which says the \nd component of a pair (p, d) is T. The remaining three formulas describe elements that should be included \nin some component of (p, d). For instance, var(x) says that the d compo\u00adnent is a non-T value (ts, vs) \nsuch that the vs part contains x. We order formulas f . f ' in M when f and f ' are the same, or both \nf and f ' are conjunction of primitive formulas and every primitive formula p ' in f ' corresponds to \nsome primitive formula p in f that implies p ' . Finally, for each atomic command a, the meta-analysis \nuses transfer function [a]b, which we show in [23] satis.es requirement (2) of our framework. This requirement \nmeans that [a]b collects all the abstractions p and abstract pre-states d such that the run of the p-instantiated \nanalysis with d generates a result satisfying f. That is, [a]b(f) computes the weakest precondition of \n[a]p with respect to the postcondition f.  false if d = v . o = L v.L . v.E if d = v . o = E v.N if \nd = v . o = N . . . . . .. . . . . . (v.E . v.N) . d.L if d . (L\\ {v}) . o = L if d . (L\\ {v}) . o = \nE b (d.o)= (v.L . d.L) . d.E [g = v] d.N if d . (L\\ {v}) . o = N (v.E . v.N) . d.o if d . F. o . {L, \nE}v.L . ((v.E . v.N) . d.N) if d . F. o = N d.o otherwise b(d.o) = if (d = v . o = E) then (true) else \n(if (d = v . o = E) then (false) else (d.o)) [v = new h b(d.o) = if (d = v) then (h.o) else (d.o) [v \n= null] b(d.o) = if (d = v . o = N) then (true) else (if (d = v . o = N) then (false) else (d.o)) [v \n= v ' [v = g ] b(d.o) = if (d = v) then (v ' .o) else (d.o) . . . . .. . . . . . . . . . . . . . . . \n.. . . . . . . . . . . . . . . . (v ' .L . f.E) . v ' .E . v ' .N if d = v . o = E ' b(d.o) = v ' .L \n. f.o if d = v . o = E[v = v .f] d.o if d = v d.o d.E . (d.L . v.E . v ' .L) . (d.L . v.L . f.L . v \n' .E) . (d.L . v.L . f.E . v ' .L) d.o d.o . (v.N . (v.E . (v ' .E . v ' .N)) . (v.L . (v ' .N . f.N \n. (v ' .L . f.L) . (v ' .E . f.E)))) d.N . (v.E . v ' .L) . (v.L . f .L . v ' .E) if d . (L. F) if d \n. L. o = E if d . L. o = N if (d . L. o = L) . (d . F. o = E . d = f) . (d . F. o = L . d = f) if d . \nF. o = N . d = f ' b . (v.L . f .E . v ' .L) (d.N . (v.E . v.N . (v.L . v ' .N))) if d . F. o = N . \nd = f . (v.E . v ' .L) . (d.L . v.L . v ' .E) . (d.E . v.L . v ' .L) (d.N . v.L . v ' .L) if d . F. o \n= L . d = f . (d.L . v.N) . (d.L . v.E . (v ' .E . v ' .N)) . (d.L . v.L . (v ' .N . v ' .L)) (d.N . \nv.L . v ' .E) if d . F. o = E . d = f . (d.E . v.N) . (d.E . (v.E . v.L) . (v ' .E . v ' .N)) [v.f = \nv ] (d.o) = Figure 11. Backward transfer function for thread-escape analysis. We use d to range over \nh, v, f, and we use o to range over L, E, N. Meta-Analysis for Thread-Escape. The backward meta-analysis \nfor the thread-escape analysis is also disjunctive. Its domain M is constructed from the following primitive \nformulas p: p ::= h.o | v.o | f .o where o is an abstract value in {L, E, N}, and h, v, f are an alloca\u00adtion \nsite, a local variable, and a .eld, respectively. These formulas describe properties about pairs (p, \nd) of abstraction and abstract state. Formula h.o says that an abstraction p should map h to o. Formula \nv.o means that an abstract state d should bind v to o; formula f.o expresses a similar fact on the .eld \nf. We formalize these meanings via function . : M . 2P\u00d7D below: .(h.o) = {(p, d) | p(h) = o} .(v.o) = \n{(p, d) | d(v) = o}.(f.o) = {(p, d) | d(f) = o} We order formulas f f ' in M when our simple entailment \nchecker concludes that f ' subsumes f. This conclusion is reached when f and f ' are the same, or both \nf and f ' are conjunction of primitive formulas and all the primitive formulas in f ' appear in f. This \nproof strategy is fast yet highly incomplete. However, we found it suf.cient in practice for our application, \nwhere the order is used to detect redundant disjuncts in formulas in the DNF form. Figure 11 shows transfer \nfunction [a]b of the meta-analysis for each atomic command a. We show in [23] that it satis.es requirement \n(2) of our framework which determines the semantics of the function using weakest preconditions. Figure \n6 shows the backward meta-analysis for thread-escape analysis without and with under-approximation on \nan example pro\u00adgram. The trace in part (a) is generated by the forward analysis using initial abstraction \n[h1 . E, h2 . E]. The abstract states computed by the meta-analysis at each point of this trace without \nunder-approximation are denoted by .. It correctly computes the suf.cient condition for failure at the \nstart of the trace as h1.E . (h2.E .h1.L), thus yielding the cheapest abstraction that proves the query \nas [h1 . L, h2 . L]. Despite taking a single iteration, however, the lack of under-approximation causes \na blow-up in the size of the formula tracked by the meta-analysis.  [x = y b (err) = err [x = null b(err) \n= err V [x.m()] b(err) = err . {type(s) | [m](s) = T}[x = y b(param(z)) = param(z) [x = null b(param(z)) \n= param(z) [x.m()] b(param(z)) = param(z) T b param(x) . var(y) if x = z (var(z)) = [x = y] Tvar(z) otherwise \nb false if x = z [x = null](var(z)) = var(z) otherwise [x.m()]b(var(z)) = var(z) .{\u00actype(s) | [m](s) \n= T}[x = y b(type(s)) = type(s) [x = null] b(type(s)) = type(s) [x.m()]b(type(s)) = \u00acerr  . ({\u00actype(s \n' ) | [m](s ' ) = T}) . ((\u00acvar(x) . type(s)) V . {type(s ' ) | [m](s ' ) = s}) Figure 10. Backward transfer \nfunction for type-state analysis. Part (b) shows the result with under-approximation, using k = 1 in \nthe beam search via function dropk. This time, the .rst iteration, shown in part (b1), yields a stronger \nsuf.cient condition for failure, h1.E, causing our technique to next run the forward analysis using abstraction \n[h1 . L, h2 . E]. But the analysis again fails to prove the query, and the second iteration, shown in \npart (b2), computes the suf.cient condition for failure as (h1.L . h2.E). By com\u00adbining these conditions \nfrom the two iterations, our technique .nds the same cheapest abstraction as that without under-approximation \nin part (a). Despite needing an extra iteration, the formulas tracked in part (b) are much more compact \nthan those in part (a). 5. Iterative Forward-Backward Analysis This section presents our top-level algorithm, \ncalled TRACER, which brings a parametric analysis and a corresponding backward meta-analysis together, \nand solves the parametric static analysis problem. Throughout the section, we .x a parametric analysis \nand a backward meta-analysis, and denote them by (P, :, D, [-]) and (M, ., [-]b , approx), respectively. \nOur TRACER algorithm assumes that queries are expressed by elements f in Msatisfying the following condition: \n.D0 . D. .(f) = P\u00d7 D0 . (.f ' . M. .(f ' ) = P\u00d7 (D\\ D0)). The .rst conjunct means that f is independent \nof abstractions, and the second, that the negation of f is expressible in M. A f satisfying these two \nconditions is called a query and is denoted by symbol q. The negation of a query q is also a query and \nis denoted not(q). TRACER takes as inputs initial abstract state dI , a program s, and a query q . M. \nGiven such inputs, TRACER repeatedly invokes the forward analysis with different abstractions, until \nit proves the query or .nds that the forward analysis cannot prove the query no matter what abstraction \nis used. The key part of TRACER is to choose a new abstraction p ' to try after the forward analysis \nfails to prove the query using some p. TRACER does this abstraction selection using the backward meta-analysis \nwhich goes over an abstract counterexample trace of the forward analysis and computes a condition on \nabstractions that are necessary for proving the query. TRACER chooses a minimum-cost abstraction p ' \namong such abstractions. The TRACER algorithm is shown in Algorithm 1. It uses vari\u00adable .viable to track \nabstractions that can potentially prove the query. Whenever TRACER calls the forward analysis, it picks \na min\u00adimum p from .viable, and instantiates the forward analysis with p before running the analysis (lines \n8-9). Also, whenever TRACER learns a necessary condition from the backward meta-analysis for proving \na query (i.e., P \\ . in line 14), it conjoins the condition with .viable (line 15). In the description \nof the algorithm, we do not specify how to choose an abstract counterexample trace t from a failed run \nof the forward analysis. Such traces can be chosen by well-known techniques from software model checking \n[1, 20]. We show the correctness of our algorithm in [23]. Algorithm 1 TRACER(dI , s, q): iterative forward-backward \nanalysis 1: INPUTS: Initial abstract state dI , program s, and query q 2: OUTPUTS: Minimum p according \nto : such that Fp[s]({dI }) . {d | (p, d) . .(q)}. Or impossibility meaning that .p : Fp[s]({dI }) . \n{d | (p, d) . .(q)}. 3: var .viable := P 4: while true do 5: if .viable = \u00d8 then 6: return impossible \n7: end if 8: choose a minimum p . .viable according to : 9: let D = (Fp[s]({dI }) n {d | (p, d) . .(not(q))}) \nin 10: if D = \u00d8 then 11: return p 12: end if 13: choose any t . trace(s) : Fp[t ](dI ) . D 14: let . \n= {p ' | (p ' , dI ) . .(B[t ](p, dI , not(q)))} in 15: .viable := .viable n (P\\ .) 16: end let 17: end \nlet 18: end while 6. Experiments We implemented our parametric data.ow analysis technique in Chord [16], \nan extensible program analysis framework for Java bytecode. The forward analysis is expressed as an instance \nof the RHS tabulation framework [19] while the backward meta-analysis is expressed as an instance of \na trace analysis framework that implements our proposed optimizations. We implemented our type-state \nand thread-escape analyses in our framework, and we evaluated our technique on both of them using a suite \nof seven real-world concurrent Java benchmark pro\u00adgrams. Table 1 shows characteristics of these programs. \nAll exper\u00adiments were done using JDK 1.6 on Linux machines with 3.0 GHz processors and a maximum of 8GB \nmemory per JVM process. The last two columns of Table 1 show the size of the family of abstractions searched \nby each analysis for each benchmark. For the type-state analysis, it is 2N where N is the number of pointer-typed \nvariables in reachable methods, since an abstraction determines which variables the analysis can track \nin must-alias sets. For thread-escape analysis, it is 2N where N is the number of object allocation sites \nin reachable methods, since the abstraction determines whether to map each such site to L or E. We presented \nour technique for a single query but in practice a client may pose multiple queries in the same program. \nOur frame\u00adwork has the same effect as running our technique separately for each query but it uses a more \nef.cient implementation: at any instant, it maintains a set of groups {G1, ..., Gn} of unresolved queries \n(i.e., queries that are neither proven nor shown impossible to prove). Two queries belong to the same \ngroup if the sets of un\u00adviable abstractions computed so far for those queries are the same. All queries \nstart in the same group with an empty set of unviable abstractions but split into separate groups when \ndifferent sets of unviable abstractions are computed for them.  description # classes # methods bytecode \n(KB) KLOC log2(# abstractions) app total app total app total app total type-state thread-esc. tsp Traveling \nSalesman implementation 4 997 21 6,423 2.6 391 0.7 269 569 6,175 elevator discrete event simulator 5 \n998 24 6,424 2.3 390 0.6 269 352 6,180 hedc web crawler from ETH 44 1,066 234 6,881 16 442 6 283 1,400 \n7,326 weblech website download/mirror tool 57 1,263 312 8,201 20 504 13 326 2,993 7,663 antlr A parser/translator \ngenerator 118 1,134 1,180 7,786 131 532 29 303 16,563 7,748 avrora microcontroller simulator/analyzer \n1,160 2,192 4,253 10,985 224 634 64 340 37,797 10,151 lusearch text indexing and search tool 229 1,236 \n1,508 8,171 101 511 42 314 14,508 7,395 Table 1. Benchmark statistics computed using a 0-CFA call graph \nanalysis. The total and app columns report numbers with and without counting JDK library code, respectively. \nThe last two columns determine the (log of the) number of abstractions for our two client analyses. To \navoid skewing our results by using a real type-state property to evaluate our type-state analysis, we \nused a .ctitious one that tracks the state of every object allocated in the application code of the program \n(as opposed to, say, only .le objects). The type\u00adstate automaton for this property has two states, init \nand error. The type-state analysis tracks a separate abstract object for each allocation site h in application \ncode that starts in the init state, and transitions to error upon any method call v.m() in application \ncode if the following two conditions hold: (i) v may point to an object created at site h according to \na 0-CFA may-alias analysis that is used by the type-state analysis, and (ii) v is not in the current \nmust-alias set tracked by the type-state analysis. If neither of these conditions holds, then the abstract \nobject remains in the init state, which corresponds to precise type-state tracking by the analysis. To \nenable a comprehensive evaluation of our technique, we generated queries pervasively and uniformly from \nthe application code of each benchmark. For the type-state analysis, we generated a query at each method \ncall site, and for the thread-escape analysis, we generated a query at each instance .eld access and \neach array element access. Speci.c clients of these analyses may pose queries more selectively but our \ntechnique only stands to bene.t in such cases by virtue of being query-driven. To avoid reporting duplicate \nresults across different programs, we did not generate any queries in the JDK standard library, but our \nanalyses analyze all reachable bytecode including that in the JDK. Our type-state analysis answers each \nquery (pc, h) such that the statement at program point pc is a method call v.m() in application code \nand variable v may point to an object allocated at a site h that also occurs in application code. The \nquery is proven if every object allocated at site h that variable v may refer to at the point of this \ncall is in state init (i.e., not error). These queries stress-test our type-state analysis since they \nfail to be proven if the underlying may-alias or must-alias analysis loses precision along any program \npath from the point at which any object is created in application code to the point at which any application \nmethod is called on it. Our thread-escape analysis answers each query (pc, v) such that the statement \nat program point pc in application code accesses (reads or writes) an instance .eld or an array element \nof the object denoted by variable v. Such queries may be posed by a client such as static datarace detection. \nWe chose type-state and thread-escape analyses as they are challenging to scale: both are fully .ow-and \ncontext-sensitive analyses that use radically different heap abstractions. The thread\u00adescape analysis \nis especially hard to scale: simply mapping all allocation sites to L in the abstraction causes the analysis \nto run out of memory even on our smallest benchmark. Moreover, these analyses are useful in their own \nright: type-state analysis is an important general analysis for object state veri.cation while thread\u00adescape \nanalysis is bene.cial to a variety of concurrency analyses. We next summarize our evaluation results, \nincluding precision, scalability, and useful statistics of proven queries. Precision. Figure 12 shows \nthe precision of our technique. The absolute number of queries for each benchmark appears at the top. \nThe queries are classi.ed into three categories: those proven using a cheapest abstraction, those shown \nimpossible to prove using any abstraction, and those that could not be resolved by our technique in 1,000 \nminutes (we elaborate on these queries below). All queries are resolved in the type-state analysis. Of \nthese queries, 25% are proven on average per benchmark. Queries im\u00adpossible to prove are notably more \nthan proven queries for the type-state analysis primarily due to the stress-test nature of the type-state \nproperty that the analysis checks. In contrast, for the thread-escape analysis, our technique proves \n38% queries and it shows 47% queries impossible to prove, for a total of 85% resolved queries on average \nper benchmark. We manually inspected several queries that were unresolved, and found that all of them \nwere true but impossible to prove using our thread-escape analysis, due to its limit of two abstract \nlocations (L and E). There are two possible ways to address such queries depending on the desired goal: \nalter the backward meta-analysis to show impossibility more ef.ciently or alter the forward analysis \nto make the queries provable. In summary, we found our technique useful at quantifying the limitations \nof a parametric data.ow analysis, and inspecting the queries deemed impossible to prove suggests what \naspects of the analysis to change to overcome those limitations. Scalability. It is challenging to scale \nbackward static analyses. We found that underapproximation is crucial to the scalability of our backward \nmeta-analysis: disabling it caused our technique to timeout for all queries even on our smallest benchmark. \nRecall that for disjunctive meta-analysis (Section 4.1) the degree of underap\u00adproximation can be controlled \nby specifying the maximum number of disjuncts k retained in the boolean formulae that are propagated \nbackward by the meta-analysis. We found it optimal to set k = 5 for our two client analyses on all our \nbenchmarks. We arrived at this setting by experimenting with different values of k. Figure 13 illustrates \nthe effect of setting k to 1, 5, and 10 on the running time of our thread-escape analysis. We show these \nresults only for our smallest four benchmarks as the analysis ran out of memory on the larger three benchmarks \nfor k = 1 and k = 10. Intuitively, the rea\u00adson is that doing underapproximation aggressively (k = 1) \nreduces the running time of the backward analysis in each iteration but it increases the number of iterations \nto resolve a query, whereas do\u00ading underapproximation passively (k = 10) reduces the number of iterations \nbut increases the running time of the backward analysis in each iteration. Compared to these two extremes, \nsetting k = 5 results in much fewer timeouts and better scalability overall. Table 2 shows statistics \nabout the number of iterations of our technique for resolved queries using k = 5. Minimum, maximum, and \naverage number of iterations are shown separately for proven queries and for queries found impossible \nto prove. The table high\u00adlights the scalability of our technique as queries for most bench\u00admarks are \nresolved in under ten iterations on average. The only exception is the type-state analysis on avrora \nwhich takes 48 itera\u00adtions on average for proven queries. The reason is that, compared to the remaining \nbenchmarks, for avrora our type-state analysis re\u00adquires many more variables in the cheapest abstraction \nfor most  number of iterations running time of thread-escape analysis (s = seconds, m = minutes, h \n= hours) type-state analysis thread-escape analysis proven impossible proven impossible proven impossible \nmin max avg min max avg min max avg min max avg min max avg min max avg tsp elevator hedc weblech antlr \navrora lusearch 2 2 2 2 2 2 2 2 2 3 2.1 3 2.3 3 2.1 18 8.9 82 47.7 32 2.1 1 2 1.5 1 9 3.8 1 2 1 1 3 1.4 \n1 47 7.8 1 30 3.5 1 23 2 2 2 2 2 2 2 2 2 2 3 2 6 2.4 17 6.9 88 3 97 3 19 2.7 1 1 1 1 5 1.3 1 4 1.8 1 \n3 1.2 1 18 1.4 1 38 1.4 1 20 2.3 14s 29s 21s 12s 107s 34s 17s 6m 89s 20s 16m 5m 18s 77m 98s 16s 28m 67s \n14s 13m 112s 6s 8s 7s 6s 144s 15s 10s 5m 51s 11s 150s 28s 6s 21m 64s 5s 3h 41s 6s 45m 131s Table 2. \nScalability measurements. Table 3. Statistics of cheapest abstraction size for proven queries.  type-state \nanalysis thread-escape analysis min max avg min max avg tsp 2 3 2.3 1 1 1 elevator 2 4 2.8 1 2 1.1 hedc \n2 5 2.9 1 5 1.4 weblech 2 4 3.3 1 16 6.1 antlr 2 20 10.9 1 87 1.9 avrora 2 84 50.2 1 96 2.1 lusearch \n2 34 16.5 1 18 1.7 tsp elevator hedc weblech antlr avrora lusearch type-state analysis # groups min \nmax 4 1 1 8 1 5 26 1 4 18 1 17 101 1 106 158 1 368 151 1 139 avg 1 1.5 1.3 2.3 4.6 8.6 3.6 thread-escape \nanalysis # groups min max avg 3 1 3 2 10 1 13 3.8 34 1 50 7.6 51 1 88 6.4 237 1 374 10.7 890 1 262 9 \n270 1 256 13.7 Table 4. Statistics of cheapest abstraction reuse for proven queries. of the proven queries \n(this is con.rmed below by statistics on the sizes of the cheapest abstractions). The numbers of iterations \nalso show that our technique is effective at .nding queries that are im\u00adpossible to prove since for most \nbenchmarks it .nds such queries in under four iterations on average. We also show the running time for \nthread-escape analysis in the table as it is relatively harder to scale than type-state analysis. For \neach benchmark, our technique takes one to two minutes on average for resolved queries. Statistics of \nProven Queries. We now present some useful statis\u00adtics about proven queries. Table 3 shows the minimum, \nmaximum, and average sizes of the cheapest abstraction computed by our tech\u00adnique for these queries. \nFor type-state analysis, the size of the cheapest abstraction correlates the benchmark size and is greatly \naffected by the depth of method calls. The average number of vari\u00adables that must be tracked in must-alias \nsets ranges from 2 to 50 from our smallest benchmark to our largest. On the other hand, thread-escape \nanalysis only needs 1 to 2 sites mapped to L on aver\u00adage for most benchmarks, though there are queries \nthat need upto 96 such sites (this means that no abstraction with fewer than those many sites can prove \nthose queries). The graphs in Figure 14 show the distribution of the cheapest abstraction sizes for thread-escape \nanalysis on our largest three benchmarks. We see that most queries are indeed proven using 1 or 2 allocation \nsites mapped to L. Finally, it is worth .nding how different the cheapest abstrac\u00adtions computed by our \ntechnique are for these proven queries. Ta\u00adble 4 answers this question by showing the numbers of queries \ngrouped together sharing the same cheapest abstraction. The table shows that around ten or less queries \non average share the same cheapest abstraction for both analyses, indicating that the cheapest abstraction \ntends to be different for different queries, though there are also a few large groups containing up to \n368 queries for type\u00adstate analysis and 374 queries for thread-escape analysis. These statistics underscore \nboth the promise and the challenge of parametric static analysis: on one hand, most queries can be proven \nby instantiating the analysis using very inexpensive abstrac\u00adtions, but on the other hand, these abstractions \ntend to be very dif\u00adferent for queries from different parts of the same program. 7. Related Work Our \nwork is related to iterative re.nement analyses but differs in the goal and the technique. They aim to \n.nd a cheap enough abstraction to prove a query while we aim to .nd a cheapest abstraction or show that \nnone exists. We next contrast the techniques. CEGAR-based model checkers such as SLAM [2] and BLAST [13] \ncompute a predicate abstraction of the given program to prove an assertion (query) in the program. Yogi \n[3, 8] combines CEGAR\u00adbased model checking and directed input generation to simulta\u00adneously search for \nproofs and violations of assertions. All these approaches can be viewed as parametric in which program \npredi\u00adcates to use in the predicate abstraction. They differ from our ap\u00adproach primarily in the manner \nin which they analyze an abstract counterexample trace that is produced as a witness to the failure to \nprove a query using the currently chosen abstraction. In particu\u00adlar, these approaches compute an interpolant, \nwhich can be viewed as a minimal suf.cient condition for the model checker to suc\u00adceed in proving the \nquery on the trace, whereas our meta-analysis computes a suf.cient condition for the failure of the given \nanaly\u00adsis to prove the query on the trace. Intuitively, our meta-analysis attempts to .nd as many other \nabstractions destined to a similar proof failure as the currently chosen abstraction; the next abstrac\u00adtion \nour approach attempts is simply a cheapest one not discarded by the meta-analysis. One advantage of the \nabove approaches over our approach is that they can produce concrete counterexamples for false queries, \nwhereas our approach can at best declare such queries impossible to prove using the given analysis. Conversely, \nour approach can declare when true queries are impossible to prove using the given analysis, whereas \nthe above approaches can diverge for such queries. Re.nement-based pointer analyses compute cause-effect \nde\u00adpendencies for .nding aspects of the abstraction that might be re\u00adsponsible for the failure to prove \na query and then re.ne these as\u00adpects in the hope of proving it. These aspects include .eld reads and \nwrites to be matched [21, 22], methods or object allocation sites to be cloned [14, 18], or memory locations \nto be treated .ow\u00adsensitively [12]. A drawback of these analyses is that they can re.ne much more than \nnecessary and thereby sacri.ce scalability. Combining forward and backward analysis has been proposed \n(e.g., [4]) but our approach differs in three key aspects. First, ex\u00adisting backward analyses are proven \nsound with respect to the pro\u00adgram s concrete semantics, whereas ours is a meta-analysis that is proven \nsound with respect to the abstract semantics of the forward analysis. Second, existing backward analyses \nonly track abstract states (to prune the over-approximation computed by the forward analysis), whereas \nours also tracks parameter values. Finally, exist\u00ading backward analyses may not scale due to tracking \nof program states that are unreachable from the initial state, whereas ours is guided by the abstract \ncounterexample trace provided by the for\u00adward analysis, which also enables underapproximation. Parametric \nanalysis is a search problem that may be tackled using various algorithms with different pros and cons. \nLiang et al. [15] propose iterative coarsening-based algorithms that start with the most precise abstraction \n(instead of the least precise one in the case of iterative re.nement-based algorithms). Besides being \nimpractical, these algorithms solve a different problem and cannot be adapted to ours: they .nd a minimal \nabstraction in terms of precision as opposed to a minimum or cheapest abstraction. Naik et al. [17] use \ndynamic analysis to infer a necessary condition on the abstraction to prove a query. They instantiate \nthe parametric analysis using a cheapest abstraction that satis.es this condition. However, there is \nno guarantee that it will prove the query, and the approach does not do re.nement in case the analysis \nfails. Finally, constraint-based and automated theorem proving tech\u00adniques have been proposed that use \nsearch procedures similar in spirit to our approach: they too combine over-and under\u00adapproximations, \nand compute strongest necessary and weakest suf.cient conditions for proving queries (e.g, [5, 6, 10, \n11]). A key difference is that none of these approaches address .nding minimum-cost abstractions or proving \nimpossibility results.  8. Conclusion We presented a new approach to parametric data.ow analysis with \nthe goal of .nding a cheapest abstraction that proves a given query or showing that no such abstraction \nexists. Our approach is CEGAR-based and applies a novel meta-analysis on abstract coun\u00adterexample traces \nto ef.ciently eliminate unsuitable abstractions. We showed the generality of our approach by applying \nit to two example analyses in the literature. We also showed its practicality by applying it to several \nreal-world Java benchmark programs. Our approach opens intriguing new problems. First, our ap\u00adproach \nrequires the abstract domain of the parametric analysis to be disjunctive in order to be able to provide \na counterexample trace to the meta-analysis. Our meta-analysis relies on the existence of such a trace \nfor scalability: the trace guides the meta-analysis in deciding which parts of the formulae it tracks \nrepresent infeasible states that can be pruned. One possibility is to generalize our meta-analysis to \noperate on DAG counterexamples that have been proposed for non-disjunctive analyses [9]. Second, the \nmeta-analysis is a static analysis, and designing its abstract domain is an art. We proposed a DNF representation \nalong with optimizations that were very ef\u00adfective in compacting the formulas tracked by the meta-analysis \nfor our type-state analysis and our thread-escape analysis. It would be useful to devise a generic semantics-preserving \nsimpli.cation process to assist in compacting such formulas. Finally, manually de.ning the transfer functions \nof the meta-analysis can be tedious and error-prone. One plausible solution is to devise a general recipe \nfor synthesizing these functions automatically from a given abstract domain and parametric analysis. \nAcknowledgments We thank Ravi Mangal for discussions and help with the implemen\u00adtation. We also thank \nthe anonymous reviewers for many insightful comments. This research was supported in part by DARPA contract \n#FA8750-12-2-0020, NSF award #1253867, awards from Google and Microsoft, and EPSRC. References [1] T. \nBall and S. Rajamani. Bebop: a path-sensitive interprocedural data.ow engine. In Proceedings of the ACM \nWorkshop on Program Analysis For Software Tools and Engineering (PASTE 01), 2001. [2] T. Ball and S. \nRajamani. The SLAM project: Debugging system soft\u00adware via static analysis. In Proceedings of the 29th \nACM Symposium on Principles of Programming Languages (POPL 02), 2002. [3] N. Beckman, A. Nori, S. Rajamani, \nR. Simmons, S. Tetali, and A. Thakur. Proofs from tests. IEEE Trans. Software Eng., 36(4):495 508, 2010. \n [4] P. Cousot and R. Cousot. Re.ning model checking by abstract inter\u00adpretation. Autom. Softw. Eng., \n6(1):69 95, 1999. [5] I. Dillig, T. Dillig, and A. Aiken. Sound, complete and scalable path-sensitive \nanalysis. In Proceedings of the 29th ACM Conference on Programming Language Design and Implementation \n(PLDI 08), 2008. [6] I. Dillig, T. Dillig, and A. Aiken. Fluid updates: beyond strong vs. weak updates. \nIn Proceedings of the 19th European Symposium on Programming (ESOP 10), 2010. [7] S. Fink, E. Yahav, \nN. Dor, G. Ramalingam, and E. Geay. Effective typestate veri.cation in the presence of aliasing. ACM \nTrans. Softw. Eng. Methodol., 17(2), 2008. [8] B. Gulavani, T. Henzinger, Y. Kannan, A. Nori, and S. \nRajamani. Synergy: a new algorithm for property checking. In Proceedings of the 14th ACM SIGSOFT International \nSymposium on Foundations of Software Engineering (FSE 06), 2006. [9] B. Gulavani, S. Chakraborty, A. \nNori, and S. Rajamani. Automatically re.ning abstract interpretations. In Proceedings of the 14th Interna\u00adtional \nConference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS 08), 2008. [10] \nS. Gulwani and A. Tiwari. Assertion checking uni.ed. In Proceedings of the 8th International Conference \non Veri.cation, Model Checking, and Abstract Interpretation (VMCAI 07), 2007. [11] S. Gulwani, B. McCloskey, \nand A. Tiwari. Lifting abstract interpreters to quanti.ed logical domains. In Proceedings of the 35th \nACM Sym\u00adposium on Principles of Programming Language (POPL 08), 2008. [12] S. Guyer and C. Lin. Client-driven \npointer analysis. In Proceedings of the 10th International Symposium on Static Analysis (SAS 03), 2003. \n[13] T. Henzinger, R. Jhala, R. Majumdar, and K. McMillan. Abstractions from proofs. In Proceedings of \nthe 31st ACM Symposium on Principles of Programming Languages (POPL 04), 2004. [14] P. Liang and M. Naik. \nScaling abstraction re.nement via pruning. In Proceedings of the 32nd ACM Conference on Programming Language \nDesign and Implementation (PLDI 11), 2011. [15] P. Liang, O. Tripp, and M. Naik. Learning minimal abstractions. \nIn Proceedings of the 38th ACM Symposium on Principles of Program\u00adming Languages (POPL 11), 2011. [16] \nM. Naik. Chord: A static and dynamic program analysis platform for Java. http://code.google.com/p/jchord/. \n[17] M. Naik, H. Yang, G. Castelnuovo, and M. Sagiv. Abstractions from tests. In Proceedings of the 39th \nACM Symposium on Principles of Programming Languages (POPL 12), 2012. [18] J. Plevyak and A. Chien. Precise \nconcrete type inference for object\u00adoriented languages. In Proceedings of the 9th ACM Conference on Object-Oriented \nProgramming Systems, Languages, and Applications (OOPSLA 94), 1994. [19] T. Reps, S. Horwitz, and M. \nSagiv. Precise interprocedural data.ow analysis via graph reachability. In Proceedings of the 22nd ACM \nSymposium on Principles of Programming Languages (POPL 95), 1995. [20] T. Reps, S. Schwoon, S. Jha, and \nD. Melski. Weighted pushdown systems and their application to interprocedural data.ow analysis. Sci. \nComput. Program., 58(1-2):206 263, 2005. [21] M. Sridharan and R. Bod\u00b4ik. Re.nement-based context-sensitive \npoints-to analysis for Java. In Proceedings of the 27th ACM Conference on Programming Language Design \nand Implementation (PLDI 06), 2006. [22] M. Sridharan, D. Gopan, L. Shan, and R. Bod\u00b4ik. Demand-driven \npoints-to analysis for Java. In Proceedings of the 20th ACM Con\u00adference on Object-Oriented Programming, \nSystems, Languages, and Applications (OOPSLA 05), 2005. [23] X. Zhang, M. Naik, and H. Yang. Finding \noptimum abstractions in parametric data.ow analysis. Technical report, Georgia Institute of Technology, \n2013. Available at http://pag.gatech.edu/pubs/ pldi13.pdf.   \n\t\t\t", "proc_id": "2491956", "abstract": "<p>We propose a technique to efficiently search a large family of abstractions in order to prove a query using a parametric dataflow analysis. Our technique either finds the cheapest such abstraction or shows that none exists. It is based on counterexample-guided abstraction refinement but applies a novel meta-analysis on abstract counterexample traces to efficiently find abstractions that are incapable of proving the query. We formalize the technique in a generic framework and apply it to two analyses: a type-state analysis and a thread-escape analysis. We demonstrate the effectiveness of the technique on a suite of Java benchmark programs.</p>", "authors": [{"name": "Xin Zhang", "author_profile_id": "81758711357", "affiliation": "Georgia Institute of Technology, Atlanta, GA, USA", "person_id": "P4149059", "email_address": "xin.zhang@gatech.edu", "orcid_id": ""}, {"name": "Mayur Naik", "author_profile_id": "81100223912", "affiliation": "Georgia Institute of Technology, Atlanta, GA, USA", "person_id": "P4149060", "email_address": "naik@cc.gatech.edu", "orcid_id": ""}, {"name": "Hongseok Yang", "author_profile_id": "81100355747", "affiliation": "University of Oxford, Oxford, United Kingdom", "person_id": "P4149061", "email_address": "hongseok.yang@cs.ox.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462185", "year": "2013", "article_id": "2462185", "conference": "PLDI", "title": "Finding optimum abstractions in parametric dataflow analysis", "url": "http://dl.acm.org/citation.cfm?id=2462185"}