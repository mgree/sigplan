{"article_publication_date": "06-16-2013", "fulltext": "\n How to Combine Widening and Narrowing for Non-monotonic Systems of Equations Kalmer Apinis Helmut Seidl \nVesal Vojdani Technische Universit\u00e4t M\u00fcnchen {apinis,seidl,vojdanig}@in.tum.de Abstract Non-trivial \nanalysis problems require complete lattices with in.nite ascending and descending chains. In order to \ncompute reasonably precise post-.xpoints of the resulting systems of equations, Cousot and Cousot have \nsuggested accelerated .xpoint iteration by means of widening and narrowing [6, 7]. The strict separation \ninto phases, however, may unnecessarily give up precision that cannot be recovered later. While widen\u00ading \nis also applicable if equations are non-monotonic, this is no longer the case for narrowing. A narrowing \niteration to improve a given post-.xpoint, additionally, must assume that all right-hand sides are monotonic. \nThe latter assumption, though, is not met in presence of widening. It is also not met by equation systems \ncorresponding to context-sensitive interprocedural analysis, possi\u00adbly combining context-sensitive analysis \nof local information with .ow-insensitive analysis of globals [1]. As a remedy, we present a novel operator \n that combines a given widening operator with a given narrowing operator . We present adapted versions \nof round-robin as well as of worklist it\u00aderation, local, and side-effecting solving algorithms for the \ncom\u00adbined operator and prove that the resulting solvers always return sound results and are guaranteed \nto terminate for monotonic sys\u00adtems whenever only .nitely many unknowns (constraint variables) are encountered. \nCategories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; F.3.2 \n[Logics and Meanings of Programs]: Semantics of Programming Languages Program analysis; F.2.2 [Analysis \nof Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems Computations on dis\u00adcrete \nstructures Keywords Static Program Analysis, Fixpoint Iteration, Constraint Solving 1. Introduction From \nan algorithmic point of view, static analysis typically boils down to solving systems of equations over \na suitable domain of values. The unknowns of the system correspond to the invariants to be computed, \ne.g., for each program point or for each program point in a given calling context or instances of a class. \nFor abstract Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n13, June 16 19, 2013, Seattle, WA, USA. Copyright &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . $15.00 \n interpretation, often complete lattices are chosen as domains of (ab\u00adstract) values [7]. Then variants \nof Kleene iteration can be applied to determine solutions. Right from the beginning of abstract inter\u00adpretation, \nit has been observed that many interesting invariants are best expressed by means of lattices that have \nin.nite strictly as\u00adcending chains. Possibly in.nite strictly ascending chains, though, imply that naive \nKleene iteration may not terminate. For that rea\u00adson, Cousot and Cousot proposed a widening iteration, \nfollowed by a narrowing iteration in order to determine reasonably precise invariants or, technically \nspeaking, reasonably small post solutions [6]. The widening phase can be considered as a Kleene iteration \nthat is accelerated by means of a widening operator which enforces that only .nitely many increases of \nvalues occur for an unknown. While enforcing termination, it may result in a crude over-approximation \nof the invariants of the program. In order to compensate for that, the subsequent narrowing iteration \ntries to improve a given post so\u00adlution by means of a downward .xpoint iteration, which again may be \naccelerated by means of a narrowing operator. Trying to recover precision once it has been thrown away, \nthough, in general is not possible (see, e.g., [18] for a recent dis\u00adcussion). Some attempts try to improve \nprecision by reducing the number of points where widening applied [4, 10], others rely on re.ned widening \nor narrowing operators (see, e.g., [5, 27]). Recent work has focused methods to guide or stratify the \nexploration of the state space [13 15, 19, 23], including techniques for automatic transformation of \nirregular loops [16, 26]. Our approach here is complementary to such techniques and can, possibly, be \ncombined with these. Our idea is not to postpone narrowing to a second phase where all losses of information \nhave already occurred and been propagated. Instead, an attempt is made to systematically improve the \ncurrent information by narrowing immediately. In particular, this means that widening and narrowing are \napplied in an interleaved manner. A similar idea has been proposed for the static analyzer A STR\u00c9E [2]. \nNarrowing and the narrowing operator are only guaranteed to return meaningful results, i.e., a post solution \nof the given system of equations, if the right-hand sides of equations are monotonic. This assumption, \nhowever, is violated in presence of widening. This requirement is also not met by the equation systems \nfor context\u00adsensitive interprocedural analysis [1, 12]. Moreover, for more com\u00adplicated abstract domains, \nthese systems may be in.nite and thus can be handled by local solvers only. Local solvers query the value \nof an interesting unknown and explore the space of unknowns only insofar as required for answering the \nquery. For this type of al\u00adgorithm, the set of evaluated unknowns is not known beforehand. In particular \nthe values of new unknowns may be queried in the narrowing phase that have not yet been considered before. \nAs a consequence, the strict separation into a widening and a narrowing phase can no longer be maintained. \nAlthough, narrowing iteration  in case of non-monotonicity has been considered before [9], such approaches \nare not directly applicable for local solving. In order to remedy these obstacles, we introduce an operator \n which is a generic combination of a given widening  with a given narrowing operator  and show that \nthis new operator can be plugged into a generic solver of equation systems, be they monotonic or non-monotonic. \nAs a result, solvers are obtained that return reasonably precise post solutions in one go given that \nthey terminate.  Termination, though, is indeed an issue. We present two sim\u00adple example systems of \nmonotonic equations where standard .x\u00adpoint algorithms such as round robin or work-list iteration, when \nenhanced with the new operator, fail to terminate. Therefore, we de\u00advelop a variant of round robin as \nwell as a variant of work-list itera\u00adtion which in absence of widening and narrowing are not or at least \nnot much worse than their standard counter parts but which ad\u00additionally are guaranteed to terminate \nfor monotonic systems when the -operator is used. The idea of plugging the new operator  into a generic \nlocal solver in principle, i.e., modulo termination, works as well. A lo\u00adcal solver such as [21], however, \nis not generic in the sense of the present paper meaning that a naive enhancement with the op\u00aderator \n  is no longer guaranteed to return sound results. As our main contribution, we therefore present a \nvariation of this algo\u00adrithm which always returns a (partial) post solution and, moreover, is guaranteed \nto terminate at least for monotonic equation sys\u00adtems and if only .nitely many unknowns are encountered. \nThis al\u00adgorithm is then extended to a solver for side-effecting constraint systems. Such systems allow \nto conveniently specify analyses that combine context-sensitive analysis of local information with .ow\u00adinsensitive \nanalysis of globals [1] as provided, e.g., by the pro\u00adgram analyzer G OBLINT [29]. Since the different \ncontributions to a global unknown are generated during the evaluation of a subset of right-hand sides, \nwhich is not known before-hand and may vary during .xpoint iteration, further non-trivial changes are \nrequired to handle this situation.  The remaining paper is organized as follows. In section 2, we present \nthe concept of generic solvers. In section 3, we show that any such solver, when instantiated with , \nreturns a post solution of an arbitrary equation system (be it monotonic or not) when\u00adever the solver \nterminates. In order to enforce termination at least for .nite systems of monotonic equations, we provide \nin section 4 new generic variants of round-robin iteration as well as of work-list based .xpoint computation. \nSection 5 introduces the new generic local -solver SLR, which then is generalized to equation systems \nwith side effects in section 6. In section 7, we report about pre\u00adliminary experiments with the novel \n -solver within the analyzer framework GOBLINT and conclude in section 8.  2. Chaotic .xpoint iteration \nConsider a system S of equations x = fx, for a set of unknowns x . X, and over a set Dof values where \nthe right-hand sides fx are mappings (X . D). D. Furthermore, let : D . D . D be a binary operator to \ncombine old values with the new contributions of the right-hand sides. A -solution of S is a assignment \n. : X . D such that for all unknowns x . X , .[x] = .[x] fx . holds. In the case that is de.ned as a \nb = b, a -solution is an ordinary solution of the system, i.e., a mapping . with .[x] = fx . for all \nunknowns x. In case D is a lattice, and the -operator equals the least upper bound operator ., a -solution \nis a post solution of the system, i.e., a mapping .with .[x]. fx .for all unknowns x. Likewise in case \nequals the greatest lower bound operator ., a -solution is a pre solution of the system, i.e., a mapping \n. with .[x] . fx . for all unknowns x. The operator can also be instantiated with widening and nar\u00adrowing \noperators. According to [6, 7, 11], a widening operator for a lattice Dmust satisfy that a. b . a  bfor \nall a, b . D. This implies that a -solution then again provides a post solution of the original system \nS. The situation is slightly more complicated for narrowing operators. For a narrowing operator , a \n. b implies that a . (a b). b. This means that narrowing can only be ap\u00adplied if the right-hand side \nof equations are guaranteed to return values that are less or equal than the values of the current left-hand \nsides. Thus a mapping . can only be a -solution, if it is a post solution of the system. A (chaotic) \nsolver for systems of equations is an algorithm that maintains a mapping . : X . D and performs a sequence \nof update steps, starting from an initial mapping .0 . Each update step selects an unknown x, evaluates \nthe right-hand side fx of x w.r.t. the current mapping .i and updates the value for x, i.e., .i[x] fx \n.i, if x = y .i+1 [y]= .i[y], otherwise. Then the algorithm is a -solver if upon termination the .nal \nmapping (after completing n steps) .n is a -solution of S. The algorithm is a generic solver, if it works \nfor any binary update operator . In this sense, the round-robin iteration of Fig. 1 is a generic solver. \nNote that, in most cases, we omit update step indices and, additionally, use imperative assignment syntax \nof the form .[x]. w to change the value of the unknown x to w in the mapping .. In order to prove that \na given algorithm is a generic solver, i.e., upon termination returns a -solution, one typically veri.es \nthe invariant that for every terminating run of the algorithm producing the sequence .0, .1,. . . , .n \nof mappings, and every unknown x, .i[x] = .i(x) fx .i implies that for some j = i, an update .j+1[x]. \n.j [x] fx .j occurs. Not every solver algorithm, though, may consider right-hand sides of equations as \nblack boxes, as the round-robin algorithm does. The worklist algorithm from Fig. 2 can only be used as \ngeneric solver given that all dependences are provided before\u00adhand. This means that for each right-hand \nside fx a (super-)set depx of unknowns is given such that for all mappings ., . ' , fx . = fx . ' whenever \n. and . ' agree on all unknowns in depx . From these sets, we de.ne the sets in.y of unknowns possibly \nin.uenced by (a change of the value of) unknown y, i.e., in.y = {x . X | y . depx} . {y} . In the case \nthat the value of some unknown y changes, all right\u00adhand sides of unknowns in the set in.y must be re-computed. \nNote that whenever an update to a unknown y provides a new value, we re-schedule y for evaluation as \nwell. This is a precaution for the case that the operator is not (right) idempotent. Here, an operator \nis called idempotent if the following equality: (a b) b = a b holds for all a, b. In this sense, the \noperators . and . are idempo\u00adtent and often also and . An operator such as a+b , however, for 2 a, \nb . R is not idempotent. 3. Enhancing Narrowing First, we observe: FACT 1. Assume that all right-hand \nsides of the system S of equa\u00adtions over a lattice D are monotonic and that .0 is a post solu\u00adtion of \nS, and is a narrowing operator . Then the sequence .0, .1,. . . of mappings produced by a generic -solver, \nis de.ned and decreasing.  do { dirty . false; forall (x . X){ new . .[x] fx .; if (.[x]= new ){ .[x]. \nnew ; dirty . true; } } } while (dirty ); Figure 1. The solver RR. W . X; while (W = \u00d8){ x . extract(W); \nnew . .[x] fx .; if (.[x]= new ){ .[x]. new ; W . W . in.x; } } Figure 2. The Solver W. Thus, any generic \nsolver can be applied to improve a post solution by means of a narrowing iteration given that all right-hand \nsides of equations are monotonic. Equation systems for context-sensitive interprocedural analysis, though, \nare not necessarily monotonic. In the following we show how to lift the the technical restrictions to \nthe applicability of narrowing. Given a widening operator and a narrowing operator , we de.ne a new \nbinary operator by: a b, if b . a a b = a  b, otherwise. Note that the operator is not necessarily \nidempotent, but when\u00adever narrowing is idempotent the following holds: (a b) b = (a b) b and therefore \nalso ((a b) b) b = (a b) b. A .xpoint algorithm equipped with the operator applies widen\u00ading as \nlong as values grow. Once the evaluation of the right-hand side of a unknown results in a smaller or \nequal value, narrowing is applied and values may shrink. For the operator , we observe: LEMMA 1. Consider \na .nite system S of equations over a lattice D. Then every -solution . of S is a post solution, i.e., \nfor all unknowns x, .[x]. fx .. Proof. Consider a mapping . that is a -solution of S and an arbitrary \nunknown x. For a contradiction assume that .[x]. fx .. But then we have: .[x] = .[x] fx . = .[x] fx \n. . fx . in contradiction to our assumption! Accordingly, . must be a post solution of the system of \nequations S. Thus, every generic solver for lattices Dcan be turned into a solver computing post solutions \nby using the combined widening and nar\u00adrowing operator. The intertwined application of widening and nar\u00adrowing, \nwhich naturally occurs when solving the system of equa\u00adtions by means of , has the additional advantage \nthat values may also shrink in-between. Improving possibly too large values, thus, may take place immediately \nresulting in overall smaller, i.e., bet\u00adter post solutions. Moreover, no restriction is imposed any longer \nconcerning monotonicity of right-hand sides. 4. Enforcing termination For the new operator , termination \ncannot generally be guaranteed for all solvers. In this section, we therefore present a modi.cation of \nworklist iteration which is guaranteed to terminate given that all right-hand sides of equations are \nmonotonic. EXAMPLE 1. Consider the system: x1 = x2 x2 = x3 + 1 x3 = x1 with D = N . {8}, the lattice \nof non-negative integers, equipped with the natural ordering . given by = and extended with 8. Consider \na widening where a b = a if a = b and a b = 8 otherwise, together with a narrowing  where for a = \nb, and a  b = b if a = 8, and a  b = a otherwise. Round-robin iter\u00adation with the operator  for \nthis system starting from the mapping .0 = {x1 . 0, x2 . 0, x3 . 0}, will produce the following se\u00adquence \nof mappings:  0 1 2 3 4 5 x1 0 0 8 1 8 2 . . . x2 0 8 1 8 2 8 . . . x3 0 0 8 1 8 2 . . . thus does \nno not terminate although right-hand sides are mono\u00adtonic. A similar example shows that ordinary worklist \niteration, enhanced with ,also may not terminate, even if all equations are monotonic. EXAMPLE 2. Consider \nthe two equations: x1 = (x1 + 1) . (x2 + 1) x2 = (x2 + 1) . (x1 + 1) using the same lattice as in example \n1 where . denotes minimum, i.e., the greatest lower bound. Assume that the work-set is main\u00adtained with \na lifo discipline. For W = [x1 , x2], worklist iteration, starting with the initial mapping .0 = {x1 \n. 0, x2 . 0}, results in the following iteration sequence: W [x1, x2] [x1, x2] [x1, x2] [x2] [x2, x1] \n[x2, x1] [x1] [x1, x2] x1 0 8 1 1 1 1 1 8 . . . x2 0 0 0 0 8 2 2 2 . . . which does not terminate. We \npresent modi.ed versions of the round-robin solver as well as of the worklist solver for which termination \ncan be guaranteed. The worst case complexity for the new round-robin solver turns out to be even by a \nfactor of 2 faster than ordinary round-robin iteration. For the new worklist solver, the theoretical \ncomplexity is at least not far away from the classical iterator. For both algorithms, we assume that \nwe are given a .xed linear ordering on the set of unknowns so that X = {x1 ,. . . , xn}. The ordering \nwill affect the iteration strategy, and therefore, as shown by Bourdoncle [3], has a signi.cant impact \non performance. Hence, the linear ordering should be chosen in a way that innermost loops would be evaluated \nbefore iteration on outer loops. For unknowns xi and the system of equations given by xi = fi, for i \n= 1,. . . , n, the new round-robin algorithm is shown in Fig. 3.  Let us call the new algorithm SRR \n(structured round-robin). For a given initial mapping .0, structured round-robin is started by calling \nsolve n. The idea of the algorithm is, when called for a number i, to iterate on the unknown xi until \nstabilization. Before every update of the unknown xi, however, all unknowns xj , j < i are recursively \nsolved. Clearly, the resulting algorithm is a generic -solver. Recall that a lattice D has height hif \nhis the maximal length of a strictly increasing chain . . d1 . . . . . dh. We .nd: THEOREM 1. Consider \nthe algorithm SRR for a system of n equa\u00adtions over a complete lattice where all right-hand sides are \nmono\u00adtonic and = . Then the following holds: 1. Assume that the lattice has bounded height hand = .. \nThen SRR when started with the initial mapping .0 = {xi . . | i = 1,. . . , n}, terminates after at most \nn + h 2 n(n + 1) evalu\u00adations of right-hand sides fi. 2. Also in presence of unbounded ascending chains, \nthe algorithm SRR will terminate for every initial mapping. Proof. Recall that ordinary round robin iteration \nperforms at most h\u00b7 n rounds due to increases of values of unknowns plus one extra round to detect termination, \ngiving in total n + h\u00b7 n 2 evaluations of right-hand sides. In contrast for structured round robin iteration, \ntermination for unknown xi requires one evalua\u00adtion when solve i is called for the .rst time and then \none further evaluation for every update of one of the unknowns xn,. . . , xi+1. This sums up to h\u00b7 (n \n- i) + 1 evaluations throughout the whole iteration. This gives overhead n 2 h n + h\u00b7 (n - i)= n + \u00b7 \nn \u00b7 (n - 1) 2 i=1 Additionally, there are h\u00b7n evaluations that increase values. In total, the number \nof evaluations, therefore, is h h n + \u00b7 n \u00b7 (n - 1) + h\u00b7 n = n + n(n + 1) 2 2 giving us statement 1. \nFor the second statement, we proceed by in\u00adduction on i. The case i = 0 is vacuously true. For the induction \nstep assume i > 0. For a contradiction assume that solve i for the current mapping does not terminate. \nFirst assume that fi . returns a value smaller than .[xi]while for all j< i, .[xj ]= .[xj ] fj . implying \nthat .[xj ]. fj . for all j < i. Then due to monotonic\u00adity, the subsequent iteration of solve iwill produce \na decreasing se\u00adquence of mappings implying that the operator  during all occur\u00adring updates behaves \nlike  . Since all decreasing chains produced by narrowing are ultimately stable, the call solve iwill \nterminate in contradiction to our assumption. Therefore during the whole run of solve ithe mapping . \n' when evaluating fi, must always return a value that is not subsumed by .[xi]. Since all calls solve \n(i - 1) inbetween terminate by in\u00adduction hypothesis, a strictly increasing sequence of values for xi \nis obtained that is produced by repeatedly applying the widening operator. Due to the properties of widening \noperators, any such sequence is eventually stable in contradiction to our assumption. We conclude that \nsolve iis eventually terminating. EXAMPLE 3. Recall the equation system, for which round-robin iteration \ndid not terminate. With structured round-robin iteration, however, we obtain the following sequence of \nupdates: void solve i { if (i = 0) return; solve (i- 1); new . .[xi] fi .; if (.[xi]= new ) { .[xi]. \nnew ; solve i; } } Figure 3. The new solver SRR. Q. \u00d8; for (i . 1; i = n;i++) add Qxi; while (Q= \u00d8){ \n xi . extract_min (Q); new . .[xi] fi .; if (.[xi]= new ){ .[xi]. new ; add Qxi; forall (xj . in.i)add \nQxj ; } } Figure 4. The new solver SW. i 2 1 2 1 3 2 1 x1 0 0 8 8 1 1 1 8 x2 0 8 8 1 1 1 8 8 x3 0 0 \n0 0 0 8 8 8 where the evaluations of unknowns not resulting in an update, have been omitted. Thus, structured \n.x-point solving quickly stabilizes for this example. The idea of structured iteration can also be lifted \nto worklist iteration. Consider again a system xi = fi, for i = 1,. . . , n, of equations. As for the \nordinary worklist algorithm, we assume that we are given for each right-hand side fi a (super-)set depi \nof unknowns is given such that for all mappings ., . ' , fi . = fi . ' whenever . and . ' agree on all \nunknowns in depi. As before for each unknown xj , let in.j denote the the set consisting of the unknown \nxj together with all unknowns in.uenced by xj . Instead of a plain worklist, the modi.ed algorithm maintains \nthe set of unknowns to be reevaluated, within a priority queue Q. In every round, not an arbitrary element \nis extracted from Q but the unknown with the least index. The resulting algorithm is presented in Fig. \n4. Here, the function add inserts an element into the priority queue or leaves the queue unchanged if \nthe element is already present. Moreover, the function extract_min removes the unknown with the smallest \nindex from the queue and returns it as result. Let us call the resulting algorithm SW (structured worklist \niteration). Clearly, the resulting algorithm is a generic solver. EXAMPLE 4. Consider again the system \nfrom example 2. Struc\u00adtured worklist iteration using for this system results in the fol\u00adlowing iteration: \nQ [x1, x2] [x1, x2] [x1, x2] [x2] [x1, x2] [x1, x2] [x2] [] x1 0 8 1 1 1 8 8 8 x2 0 0 0 0 8 8 8 8 and \nthus terminates.  In general, we have: THEOREM 2. Assume the algorithm SW is applied to a system of \nequations over a complete lattice D and that each right-hand side is monotonic. 1. Assume that the maximal \nlength of a strictly ascending chain is bounded by h. When instantiated with = ., and started with an \ninitial mapping . mapping each unknown to ., the algorithm terminates after at most h\u00b7 N evaluations \nof right\u00ad n hand sides where N= i=1(2 + |depi|). 2. When instantiated with = and started on any mapping, \nthe algorithm is guaranteed to terminate and, thus, always to return a post solution. The .rst statement \nof the theorem indicates that SW behaves complexity-wise like ordinary worklist iteration: the only overhead \nto be paid for is an extra logarithmic factor for maintaining the priority queue. The second statement, \nperhaps, is more surprising: it provides us with a termination guarantee for the operator . Proof. We \nproceed by induction on the number n of unknowns. The case n = 1 is true by de.nition of widening and \nnarrowing. For the induction step assume that the assertion holds for systems of equations of n - 1unknowns. \nNow consider a system of equations for a set X of cardinality n, and assume that xn is the unknown which \nis larger than all other unknowns in X. For a contradiction assume that SW does not terminate for the \nsystem of equations for X. First assume that the unknown xn is extracted from the queue Qonly .nitely \nmany times, say k times where d is the last value computed for xn. This means that after the last extraction, \nan in.nite iteration occurs on the subsystem on the unknowns X ' = X \\ {n} where for xr . X ' , the right\u00adhand \nside is given by fr ' . = fr (. . {xn . d}). By inductive hypothesis, however, the algorithm SW for this \nsystem terminates in contradiction to our assumption. Therefore, we may assume that the unknown xn is \nextracted in.nitely often from Q. Let .i, i . N, denote the sequence of mappings at these extractions. \nSince Qis maintained as a priority queue, we know that for all unknowns xr with r < n, the inequal\u00adities \n.i[xr ]. fr .i hold. Let di = .i[xn]. If for any i, fn .i . di, the next value di+1 for xn then is obtained \nby di+1 = di fn .i which is less or equal to .i. By monotonicity, this implies that in the subsequent \niteration, the values for all unknowns xr , r = n, may only decrease. The remaining iteration therefore \nis a pure narrow\u00ading iteration and therefore terminates. In order to obtain an in.nite sequence of updates \nfor z, we conclude that for no i, fn .i . di. Hence for every i, di+1 = di  fn .i where di . di+1. \nThis, how\u00adever, is impossible due to the properties of the widening operator. In summary, we conclude \nthat xn is extracted only .nitely often from Q. Hence the .xpoint iteration terminates.  Since the algorithm \nSW is a generic solver, it can also be applied to non-monotonic systems. There, however, termination \ncan no longer be guaranteed. One generic idea, though, to enforce termination for all -solvers and in \nall cases, is to equip each unknown with a separate counter that counts how often the solver has switched \nfrom narrowing back to widening. That number then may be taken into account by the -operator, e.g., \nby choosing successively less aggressive narrowing operators 1,. . ., and, ultimately, to give up improving \nthe obtained values. The latter is achieved by de.ning 0, a k b = a for a certain threshold k. 5. Local \ngeneric solvers Similar to generic solvers, we de.ne generic local solvers. Use of local solvers can \nbe considered if systems of equations are in\u00adfeasibly large or even in.nite. Such systems are, e.g., \nencoun\u00adtered for context-sensitive analysis of procedural languages [1, 8]. Local solvers query the system \nof equations for the value of a given unknown of interest and try to evaluate only the right-hand sides \nof those unknowns that are needed for answering the query [12, 22, 28]. For that, it seems convenient \nthat the dynamic de\u00adpendences between unknowns are approximated. For a mapping ., a set X ' . X subsumes \nall dynamic dependences of a function f : (X . D). D (w.r.t. .) in the case that f . = f . ' whenever \n. ' |X' = .|X' . Such sets can be constructed on the .y whenever the function f is pure in the sense \nof [20]. Essentially, purity for a right-hand side f means that evaluating f . for a mapping . operationally \nconsists of a .nite sequence value lookups in . where the next unknown whose value to be looked up may \nonly depend on the values that have already been queried. Once the sequence of lookups has been completed, \nthe .nal value is determined depending on the sequence of values and .nally returned. Apartial -solution \nof an (in.nite) system of pure equations S is a set dom . X and a mapping . : dom . D with the following \ntwo properties: 1. .[x]= .[x] fx .for all x . dom; and 2. depx . dom for all x . dom  In essence, this \nmeans that a partial -solution is a -solution of the subsystem of S restricted to unknowns in dom. EXAMPLE \n5. The following equation system (for n . N = D) y2n = max(yy2n , n) y2n+1 = y6n+4 is in.nite as it uses \nin.nitely many unknowns, but has at least one .nite partial max-solution the set dom = {y1, y2, y4 } \ntogether with the mapping . = {y1 . 2, y2 . 2, y4 . 2}. A local generic solver instantiated with an operator \n, then, is an algorithm that, when given a system of pure equations S, and an initial mapping .0 for \nall unknowns, and an unknown x0, performs a sequence of update operations that, upon termination, results \nin a partial -solution (dom, .), such that x0 . dom. At .rst sight, it may seem surprising that such \nlocal generic solvers may exist. In fact, one such instance can be derived from the round-robin algorithm. \nFor that, the evaluation of right-hand sides is instrumented in such a way that it keeps track of the \nset of accessed unknowns. Each round then operates on a growing set of unknowns. In the .rst round, just \nx0 alone is considered. In any subsequent round all unknowns are added whose values have been newly accessed \nduring the last iteration. One more elaborate algorithm for local solving is formalized by Hofmann et \nal. [21], namely the solver RLD as shown in Figure 5. This algorithm has the bene.t of visiting nodes \nin a more ef.cient order, .rst stabilizing innermost loops before iterating on outer loops. However, \nwhen enhanced with an operator , this algorithm is not a generic solver in our sense, since it is not \nguaranteed to execute as a sequence of atomic updates. Due to the recursive call to procedure solve at \nthe beginning of eval, one evaluation of a right-hand side may occur nested into the evaluation of another \nright-hand side. Therefore, conceptually, it may happen that an evaluation of a right-hand side uses \nthe values of unknowns from several different mappings .i from the sequence .0 , .1,. . . , .n, instead \nof the latest mapping .n. Accordingly, the solver RLD is not guaranteed to return a -solution even if \nit terminates. Here, we therefore, provide a variant of RLD where right-hand sides (conceptually) are \nexecuted atomically. Clearly, a local generic solver does not terminate if in.nitely many unknowns are \nencountered. Therefore, a reasonable local  let rec solve x = if x . stable then stable . stable . {x}; \ntmp . s[x] . fx (eval x); if tmp = s[x] then W . in.[x]; s[x] . tmp; in.[x] . []; stable . stable \\ W; \nforeach x . W do solve x end end and eval x y = solve y ; in.[y] . in.[y] . {x}; s[y] in stable . \u00d8; \nin. . \u00d8; s . \u00d8; solve x0; s Figure 5. The solver RLD from [21]. solver will try to consider as few unknowns \nas possible. Our solver, thus, explores the values of unknowns by recursively descending into solving \nunknowns newly detected while evaluating a right\u00adhand side. Certain equation systems, though, introduce \nin.nite chains of dependences for the unknowns of interest. Those systems then cannot be solved by any \nlocal solver. Here, we show that the new solver is guaranteed to terminate for the operator at least \nfor equation systems which are monotonic and either .nite, or in.nite but where only .nitely many unknowns \nare encountered. Let us call the new solver, on Fig. 6, SLR (structured lo\u00adcal recursive solver). The \nnew algorithm maintains an explicit set dom . X of unknowns that have already been encountered. Be\u00adyond \nRLD, it additionally maintains a counter count which counts the number of elements in dom, and a mapping \nkey : dom . Z that equips each unknown with its priority. Moreover, a global as\u00adsignment in. : dom . \n2X records for each unknown in y . dom, the unknown y itself together with the set of unknowns x . dom \nwith the following two properties: the last evaluation of fx has accessed the unknown y;  since then, \nthe value of the unknown y has not changed.  Unknowns whose equations may possibly be no longer valid, \nwill be scheduled for reevaluation. This means that they are inserted into the global priority queue \nQ. Finally, there is a global mapping . : dom . D that records the current values for the encountered \nunknowns. As in the algorithm RLD, right-hand sides fx are not directly evaluated for the current mapping \n., but instead for a helper func\u00adtion eval which in the end, returns values for unknowns. Before that, \nhowever, the helper function eval provides extra book keeping of the encountered dependence between unknowns. \nAlso, if the en\u00adcountered unknown is new, then it tries not just to return the value ., but to compute \nthe best possible value for the new unknown before-hand. In order to be able to track dependences between \nun\u00adknowns, the helper function eval receives as a .rst argument the unknown x whose right-hand side is \nunder evaluation. The func\u00adtion eval .rst checks whether the unknown y is already contained in the domain \ndom of .. If this is not the case, y is .rst initialized by calling the procedure init. Subsequently, \nthe best possible value for y is computed by calling the procedure solve for y. Then eval let rec solve \nx = if x ./stable then stable . stable . {x} tmp . .[x] fx (eval x); if tmp = .[x] then W . in.[x]; \nforeach y . W do add Q y; .[x] . tmp; in.[x] . {x}; stable . stable \\ W; while (Q= \u00d8).(min_key Q = key[x]) \ndo solve (extract_min Q); end end and init y = dom . dom . {y}; key[y] . -count; count++; in.[y] . \n{y}; .[y] . .0[y] and eval x y = if y ./dom then init y; solve y end; in.[y] . in.[y] . {x}; .[y] in \nstable . \u00d8; in. . \u00d8; . . \u00d8; dom . \u00d8; Q . empty_queue(); count . 0; init x0 ; solve x0; . Figure 6. The \nnew solver SLR. records the fact that x depends on y, by adding x to the set in.[y]. Only then is the \ncorresponding value .[y]returned. Initialization of a fresh unknown y means that y is inserted into dom \nwhere it receives a key less than the keys of all other unknowns in dom. For that, the variable count \nis used. Moreover, in.[y]and .[y]are initialized with {y} and .0 [y], respectively. Thus, the given function \neval differs from the corresponding function in RLD in that solve is recursively called only for fresh \nunknowns, and also that every unknown y always depends on itself. The main .xpoint iteration is implemented \nby the procedure solve. When solve is called for an unknown x, we assume that there is currently no unknown \nx ' . dom with key[x ' ] < key[x] that violates its equation, i.e., for which .[x ' ]= .[x ' ] fx ' .holds. \nIn the procedure solve for x, the call min_key Qreturns the minimal key of an element in Q, and extract_min \nQreturns the unknown in Qwith minimal key and additionally removes it from Q. Besides the global priority \nqueue Q, the procedure solve also requires a set stable of all unknowns introduced so far such that for \nall unknowns x ' in stable one of the following properties hold at each call of procedure solve: a call \nto the procedure solve x ' has been started and the update of .[x ' ]has not yet occurred; or  the equality \n.[x ' ]= .[x ' ] fx ' .holds.  The new function solve essentially behaves like the corresponding function \nin RLD with the notable exception that not necessarily all unknowns that have been found unstable after \nthe update of the value for x in ., are recursively solved right-away. Instead, all these unknowns are \ninserted into the global priority queue Q and then solve is only called for those unknowns x ' in Q whose \nkeys are less or equal than key[x]. Since x0 has received the largest key, the initial call solve x0 \nwill result, upon termination, in an empty priority queue Q.  EXAMPLE 6. Consider again the in.nite \nequation system from ex\u00adample 5. The solver SLR, when solving for y1, will return the par\u00adtial max-solution \n{y0 . 0, y1 . 2, y2 . 2, y4 . 2}. The modi.cations of the algorithm RLD to obtain algorithm SLR allow \nus not only to prove that it is a generic local solver, but also a strong result concerning termination. \nOur main theorem is: THEOREM 3. 1. When applied to any system of pure equations and interesting unknown \nx0, the algorithm SLR returns a par\u00adtial -solution w henever it terminates. 2. Assume that SLR is applied \nto a system of pure equations over a complete lattice D where each right-hand side is monotonic. If the \noperator is instantiated with , then for any initial mapping .0 and interesting unknown x0, SLR is guaranteed \nto terminate and thus always to return a partial post solution whenever only .nitely many unknowns are \nencountered. Proof. We .rst convince ourselves that, upon termination, each right-hand side can be considered \nas being evaluated atomically. For that, we notice that a call solve y will never modify the value .[x] \nof an unknown x with key[x] > key[y]. A recursive call to solve may only occur for an unknown y that \nhas not been considered before, i.e., is fresh. Therefore, it will not affect any unknown that has been \nencountered earlier. From that, we conclude that reevaluating a right-hand side fx for .immediately after \na call fx (eval x), will return the same value but by a computation that does not change .and thus is \natomic. In order to prove that SLR is a local generic solver, it therefore remains to verify that upon \ntermination, . is a partial -solution with x0 . dom. Since x0 is initialized before solve x0 is called, \nx0 must be contained in dom. Upon termination, evaluation of no unknown is still in process and the priority \nqueue is empty. All unknowns in dom \\ stable are either fresh and therefore solved right-away, or non-fresh \nand then inserted into the priority queue. Therefore, we conclude that the equation .[x]= .[x] fx .holds \nfor all x . dom. Furthermore, the invariant for the map in. implies that upon termination, x . in.[y]whenever \nx = y or y . depx .. In particular, in. is de.ned for y implying that y . dom. In summary, correctness \nof the algorithm SLR follows from the stated invariants. The invariants themselves follow by induction \non the number of function calls. Therefore, statement 1 holds. For a proof of statement 2, assume that \nall equations are mono\u00adtonic and only .nitely many unknowns are encountered during the call solve x0. \nLet dom denote this set of unknowns. We proceed by induction on key values of unknowns in dom. First \nconsider the un\u00adknown x . dom with minimal key value. Then for all mappings . and in., the call solve \nx will perform a sequence of updates to .[x]. In an initial segment of this sequence, the operator behaves \nlike . As soon as the same value .[x]or a smaller value is obtained, the operator  behaves like the \noperator  . Due to monotonicity, the remaining sequence may only consist of narrowing steps. By the \nproperties of widening and narrowing operators, the sequence therefore must be .nite.  Now consider \na call solve x for an unknown x . dom where by inductive hypothesis, solve y terminates for all unknowns \ny with smaller keys and all mappings ., in., sets stable and priority queue Q satisfying the invariants \nof the algorithm. In particular, this means that every recursive call to a fresh unknown terminates. \nAssume for a contradiction that the assertion were wrong and the call to solve x would not terminate. \nThen this means that the un\u00adknown x must be destabilized after every evaluation of fx (eval x). Upon \nevery successive call to solve x all unknowns with keys smaller than key[x], are no longer contained \nin Q and therefore are stable. Again we may deduce that the successive updates for .[x]are computed by \n applied to the former value of .[x]and a new value provided by the right-hand side for x, until a narrowing \nphase starts. Then, however, again due to monotonicity a decreas\u00ading sequence of values for .[x] is encountered \nwhere each new value now is combined with the former value by means of . Due to the properties of and \n , we conclude that the iteration must terminate. 6. Side-effecting systems of equations Generic solving, \nas we have discussed in the preceding sections cannot generally be extended to right-hand sides fx that \nnot only return a value for the left-hand side x of the equation x = fx, but additionally may produce \nside effects to other unknowns. This ex\u00adtension, which recasts assert-statements of P ROLOG or DATALOG \nprograms, has been advocated in [1] for an elegant treatment of interprocedural analysis using partial \ncontexts and .ow-insensitive unknowns and thus also of multi-threaded programs [25]. EXAMPLE 7. Consider \nthe following program. int g = 0; void f(int b){ if (b)g = b+ 1; else g = -b- 1; } int main () { f(1); \nf(2); return 0; } The goal is to determine a tight interval for the global program variable g. A .ow-insensitive \nanalysis of globals aims at comput\u00ading a single interval which should comprise all values possibly assigned \nto g. Besides the initialization with 0, this program has two asignments, one inside the call f(1), the \nother inside the call f(2). A context-sensitive analysis of the control-.ow should there\u00adfore collect \nthe three values 0,2,3and combine them into the inter\u00adval [0,3] for g. This requires to record for which \ncontexts the func\u00adtion f is called. This task can nicely be accomplished by means of a local solver. \nThat solver, however, has to be extended to deal with the contributions to global unknowns. In general, \nseveral side effects may occur to the same unknown z. Over an arbitrary domain of values, though, it \nremains unclear how the multiple contributions to z should be combined. Therefore in this section, we \nassume that the values of unknowns are taken from alattice D and also that right-hand sides are pure. \nFor side-effecting constraint systems this means that evaluating a right-hand side fx applied to functions \nget : X . D and side : X . D . unit, consists of a sequence of value lookups for unknowns by means of \ncalls to the .rst argument function get and side effects to unknowns by means of calls to the second \nargument function side which is terminated by returning a contribution in D for the corresponding left-hand \nside. Subsequently, we assume that each right-hand side fx produces no side effect to x itself and also \nto each unknown z = x at most one side effect. Technically, the right-hand side fx of x with side effects \ncan be considered as a succinct representation of a function \u00af fx that takes a mapping . and does not \nreturn just a single value, but again another mapping . ' where . ' [x]equals the return value computed \nby fx for get = ., and for z = x, . ' [z] = d if during evaluation of fx get side, side is called for \nz and d. Otherwise, i.e.,  if no side effect occurs to z, . ' [z]= .. A post solution of a system x \n= fx, x . X , of equations with side effects then is a mapping \u00af . : X . D such that for every x . X \n, . . fx .. A partial post solution with domain dom . X is a mapping . : dom . D such that for every \nx . dom, evaluation of fx for . accesses only unknowns in dom and also produces side effects only to \n\u00af unknowns in dom; moreover, .\u00af. fx .\u00afwhere .\u00afis the total variable assignment obtained from .by setting \n.\u00af[y]. . for all y . dom. In the following, we present a side-effecting variant SLR+ of the algorithm \nSLR from section 5 that for such systems returns a partial -solution whenever it terminates. Moreover, \nthe en\u00adhanced solver SLR+ is guaranteed to terminate whenever all right\u00adhand sides fx are monotonic, \ni.e., the functions f\u00afx all are mono\u00adtonic. EXAMPLE 8. Consider again the analysis of example 7. The \ncon\u00adtributions to the global program variable g by different contexts may well be combined individually \nby widening to the current value of the global. When it comes to narrowing, though, an individual combination \nmay no longer be sound. Therefore, the extension of the local solver SLR should collect all occurring \ncontributions into a set, and use the joint value of all these to possibly improve the value of g. Conceptually, \nthe algorithm SLR+ therefore creates for each side effect to unknown z inside the right-hand side of \nx, a fresh unknown (x, z) which receives that single value during evaluation of the right-hand side fx. \nFurthermore, the algorithm maintains for every unknown z an auxiliary set set[z]which consists of all \nunknowns x whose right-hand sides may possibly contribute to the value of z by means of side effects. \nAccordingly, the original system of side-effecting equations is (implicitly) transformed in the following \nway: 1. Inside a right-hand side fx, the side effect side z d is implicitly replaced with side (x, z) \nd while additionally, x is added to the set set[z].  2. The new right-hand side for an unknown x is \nextended with a least upper bound of all (z, x), z . set[x].  The -operator is applied whenever the \nreturn value of the new right-hand side for x is combined with the previous value of x. Let us now list \nthe required modi.cations of the algorithm SLR. First, the function init y is extended with an extra \ninitialization of the set set[y] with \u00d8. The function eval remains unchanged. Additionally, a function \nside is required for realizing the side\u00adeffects during an evaluation of a right-hand side. As the function \neval, also function side receives the left-hand side of the equation under consideration as its .rst \nargument. We de.ne: side x y d = if (x,y) ./dom then .[(x,y)]. .; if d = .[(x,y)]then .[(x,y)]. d; if \ny . dom then set[y] . set[y] . {x}; stable . stable \\ {y}; add Q y else init y; set[y] . {x}; solve y \nend end When called with x, y, d, the function side .rst initializes the un\u00adknown (x, y) if it is not \nyet contained in dom. If the new value is different from the old value of . for (x, y), .[(x, y)]is updated. \nSubsequently, the set set[y]receives the unknown x, and the un\u00adknown y is triggered for reevaluation. \nIf y has not yet been en\u00adcountered, yis initialized, set[y]is set to {x}, and solve yis called. Otherwise, \nx is only added to set[y], and y is scheduled for re\u00adevaluation by destabilizing y .rst and then inserting \ny into the pri\u00adority queue Q. The third modi.cation concerns the procedure solve. There, the call of \nthe right-hand side fx now receives side x as a second argu\u00adment and additionally evaluates all unknowns \ncollected in set[x]. The corresponding new line reads: tmp . .(x) (fx (eval x) (side x). {.(z, x) | \nz. set x}); EXAMPLE 9. Consider again interval analysis for the program from example 7. Concerning the \nglobal program variable g, the initialization g = 0 is detected .rst, resulting in the value .[g]= [0,0]. \nThen gis scheduled for reevaluation. This occurs im\u00admediately, resulting in no further change. Then the \ncalls f(1), f (2) are analyzed, the side effects of 2 and 3 are recorded and g is rescheduled for evaluation. \nWhen that happens, the value .[g]is increased to [0,0] [0,3] = [0,0] [0,3] = [0,8] if the standard \nwidening for intervals is applied. Since .[g] has changed, z again is scheduled for evaluation resulting \nin the value [0,8] [0,3] = [0,8] [0,3] = [0,3] Further evaluation of g will not change this result any \nmore. Analogously to theorem 3 from the last section, we obtain: THEOREM 4. 1. When applied to any system \nof pure equations with side effects and interesting unknown x0, the algorithm SLR+ returns a partial \npost solution whenever it terminates. 2. Assume that SLR+ is applied to a system of pure equations over \na complete lattice D where each right-hand side is mono\u00adtonic. Then for any initial mapping .0 and interesting \nunknown x0, SLR+ is guaranteed to terminate and thus always to return a partial post solution whenever \nonly .nitely many unknowns are encountered. 7. Experimental evaluation We have implemented the generic \nlocal solver SLR+ and included into the analyzer G OBLINT for multi-threaded C programs. Goblint uses \nCIL as C front-end [24] and is written in OC AML. The tests were performed on 2.7GHz Intel Core i7 laptop, \nwith 8GB DDR3 RAM, running OS X 10.8.2. In order to compare the precision attained by two-phase solving \naccording to [6] using widening and narrowing, and -solving, we used the benchmark suite1 from the M\u00e4rdalen \nWCET research group [17] which collects a series of interesting small examples for WCET analysis, varying \nin size from about 40 lines to 4000 lines of code. On top of standard analyses of pointers, we performed \nan interval analysis where local variables are analyzed context\u00adinsensitively while global variables \nare treated .ow-insensitively. Within this setting, we determined the precision achieved by the -solver \ncompared to a corresponding solver which realizes a distinct widening phase, followed by a distinct narrowing \nphase. The results of this comparison is displayed in .g. 7. Since the absolute run\u00adtimes are negligible \n(about 14 seconds for all programs together), we only display the relative precision. For that, we list, \nsorted 1available at www.mrtc.mdh.se/projects/wcet/benchmarks.html  without context without context \nwith context with context Program Time(s) Unknowns Time(s) Unknowns Time(s) Unknowns Time(s) Unknowns \n401.bzip2 3.3 6 565 3.3 6 578 3.3 7 033 3.3 7 028 429.mcf 0.4 1 245 0.4 1 245 0.5 1 673 0.5 1 673 433.milc \n9.3 8 206 9.3 8 206 13.5 36 720 13.4 36 711 456.hmmer 11.2 11 446 11.2 11 446 12.6 80 938 13.3 81 038 \n458.sjeng 49.1 13 306 52.1 13 306 121.0 97 785 131.0 108 371 470.lbm 0.3 784 0.3 784 0.4 1 577 0.2 899 \n482.sphinx 14.0 11 963 13.9 11 963 6.3 21 610 6.3 21 610 Table 1. Results for programs from the SpecCpu2006 \nbenchmark suite. 100% 80% 60% 40% 20% Figure 7. The percentage of program points with improvement. by \nprogram size, the percentage of program points where the -solver returns better results. With the notable \nexception of the benchmark qsort-exam.c without improvement (number 16 in the list), all other benchmarks \nshow signi.cant improvements, with an weighted average improvement of 39%. In a second experiment, we \nexplored the ef.ciency of our im\u00adplementation of a generic local -solver. Our collection of bench\u00admarks \nconsists of all C projects of the SpecCpu2006 benchmark suite that can be handled by CIL. The programs \n400.perlbench and 445.gobmk could not be analyzed in this setting, as there was (to our best understanding) \ninsuf.cient memory to do so. For the other programs, we performed interval analysis in two variants. \nThe .rst variant (reported in the table 1 to the left) performs a context\u00adinsensitive analysis, while \nthe second variant (reported to the right) analyzes local variables depending on a calling context which \nin\u00adcludes all non-interval values of locals. While the .rst variant of analysis can be realized by means \nof clearly separated phases of widening and narrowing, the second variant cannot, since right\u00adhand sides \nare not monotonic and the sets of contexts and thus also the sets of unknowns encountered during the \nwidening and narrow\u00ading phases may vary. In order to explore the extra costs incurred by the operator \n for each variant, we then compared the run-times if just widening is applied or . While in size, the \nprograms range from 1 to 33 kloc, the effective run-times essentially depend on the number of unknowns \nto be handled by the solvers. Not surprisingly, the run-times for context-insensitive analysis, (as reported \nto the left) are faster than those if context is taken into account, with the exception of 482.sphinx. \nAs we can see here, sometimes the dependency-breaking property of context-sensitive analysis succeeds \nin performing the analysis faster even when the context-sensitive case needs substantially more unknowns. \nIn absence of context, the -solver is only marginally slower than the corresponding -solver. The ef.ciency \npicture for context\u00adsensitive analysis, however, is less clear. Here, it seems that the ef.ciency crucially \ndepends on the number of needed unknowns. For some programs the numbers of encountered unknowns do not \ndepend greatly on the chosen solver, since the sets of occur\u00adring contexts are largely independent of \nthe computed intervals. In these cases, the solvers essentially perform equally well. For the remaining \nbenchmarks, the number of contexts may increase (456 and 458) or decrease (470) with , implying that \nthe run-time of the -solver may increase or decrease compared to the -solver. In summary, the -solver \nSLR+ turns out to be a robust al\u00adgorithm with decent run-times. The new solver allows to signi.\u00adcantly \nimprove precision over the two-phase widening/narrowing approach and also is successfully applicable \nin more general anal\u00adysis scenarios, where the two-phase approach was not applicable. 8. Conclusion We \nhave presented a generic combination of widening and narrow\u00ading into a single operator and systematically \nexplored solver al\u00ad gorithms which, when instantiated with will solve general sys\u00adtems of equations. \nPerhaps surprisingly, standard versions of .x\u00ad point algorithms, when enhanced with , may fail to terminate \neven for .nite systems of monotonic equations. Therefore, we pre\u00adsented variants of round-robin iteration, \nof ordinary worklist itera\u00adtion as well as of recursive local solving with and without side ef\u00adfects \nwhere for monotonic equations and .nitely many unknowns, termination can be guaranteed whenever only \n.nitely many un\u00adknowns are encountered. Furthermore, we provided preliminary practical evidence that \n.xpoint iteration based on the combined operator may increase precision signi.cantly, and that it also \nbehaves well for interproce\u00addural analysis where right-hand sides of equations can no longer be considered \nas monotonic. Our experiments were performed inde\u00adpendent of other methods of increasing the precision \nof the widen\u00ading/narrowing approach. It remains for future work to explore how well different methods \nto increase precision may cooperate for computing precise analysis results at a decent cost. Acknowledgments \nThe research leading to these results has received funding from the ARTEMIS Joint Undertaking under grant \nagreement n\u00b0 269335 and from the German Science Foundation (DFG). The last author is partially supported \nby the Estonian Science Foundation (EstSF) under grant n\u00b0 8421.  References 1. K. Apinis, H. Seidl, \nand V. Vojdani. Side-Effecting Constraint Systems: A Swiss Army Knife for Program Analysis. In APLAS, \npages 157 172. LNCS 7705, Springer, 2012. 2. Bruno Blanchet, Patrick Cousot, Radhia Cousot, J\u00e9rome Feret, \nLaurent Mauborgne, Antoine Min\u00e9, David Monniaux, and Xavier Rival. A static analyzer for large safety-critical \nsoftware. In ACM SIGPLAN Notices, volume 38, pages 196 207. ACM, 2003. 3. Fran\u00e7ois Bourdoncle. Interprocedural \nabstract interpretation of block structured languages with nested procedures, aliasing and recursivity. \nIn Programming Language Implementation and Logic Programming, 2nd International Workshop PLILP 90, volume \n456 of Lecture Notes in Computer Science, pages 307 323. Springer-Verlag, 1990. 4. Fran\u00e7ois Bourdoncle. \nEf.cient chaotic iteration strategies with widen\u00adings. In In Proceedings of the International Conference \non For\u00admal Methods in Programming and their Applications, pages 128 141. Springer-Verlag, 1993. 5. Agostino \nCortesi and Matteo Zanioli. Widening and narrowing op\u00aderators for abstract interpretation. Computer Languages, \nSystems &#38; Structures, 37(1):24 42, 2011. 6. P. Cousot and R. Cousot. Static determination of dynamic \nproperties of programs. In B. Robinet, editor, Second International Symposium on Programming, Paris, \nFrance, page 106 130. Dunod, Paris, 1976. 7. P. Cousot and R. Cousot. Abstract Interpretation: A uni.ed \nlattice model for static analysis of programs by construction or approxima\u00adtion of .xpoints. In 4th ACM \nSymp. on Principles of Programming Languages (POPL 77), pages 238 252. ACM Press, 1977. 8. P. Cousot \nand R. Cousot. Static Determination of Dynamic Properties of Recursive Procedures. In IFIP Conf. on Formal \nDescription of Programming Concepts, pages 237 277. North-Holland, 1977. 9. P. Cousot, R. Cousot, J. \nFeret, L. Mauborgne, A. Min\u00e9, D. Monniaux, and X. Rival. Combination of abstractions in the ASTR\u00c9E static \nana\u00adlyzer. In M. Okada and I. Satoh, editors, Eleventh Annual Asian Com\u00adputing Science Conference (ASIAN \n06), pages 272 300, Tokyo, Japan, LNCS 4435, 2007. Springer, Berlin. 10. Patrick Cousot. Semantic foundations \nof program analysis. In S.S. Muchnick and N.D. Jones, editors, Program Flow Analysis: Theory and Applications, \nchapter 10, page 303 342. Prentice-Hall, Inc., En\u00adglewood Cliffs, New Jersey, U.S.A., 1981. 11. Patrick \nCousot and Radhia Cousot. Comparing the galois connection and widening/narrowing approaches to abstract \ninterpretation. In Mau\u00adrice Bruynooghe and Martin Wirsing, editors, PLILP, volume 631 of LNCS, pages \n269 295. Springer, 1992. 12. Christian Fecht and Helmut Seidl. A Faster Solver for General Systems of \nEquations. Science of Computer Programming, 35(2):137 161, 1999. 13. Denis Gopan and Thomas Reps. Lookahead \nwidening. In Thomas Ball and Robert Jones, editors, Computer Aided Veri.cation, volume 4144 of LNCS, \npages 452 466. Springer, 2006. 14. Denis Gopan and Thomas Reps. Guided static analysis. In Hanne Nielson \nand Gilberto Fil\u00e9, editors, Proc. of the 14th International Static Analysis Symposium (SAS), volume 4634 \nof LNCS, pages 349 365. Springer, 2007.  15. Bhargav Gulavani, Supratik Chakraborty, Aditya Nori, and \nSriram Ra\u00adjamani. Automatically re.ning abstract interpretations. In C. Ramakr\u00adishnan and Jakob Rehof, \neditors, Tools and Algorithms for the Con\u00adstruction and Analysis of Systems (TACAS 08), volume 4963 of \nLNCS, pages 443 458. Springer, 2008. 16. Sumit Gulwani, Sagar Jain, and Eric Koskinen. Control-.ow re.ne\u00adment \nand progress invariants for bound analysis. In Proceedings of the 2009 ACM SIGPLAN conference on Programming \nlanguage design and implementation (PLDI 09), page 375 385, June 2009. 17. Jan Gustafsson, Adam Betts, \nAndreas Ermedahl, and Bj\u00f6rn Lisper. The M\u00e4lardalen WCET benchmarks past, present and future. In Bj\u00f6rn \nLisper, editor, WCET2010, pages 137 147, Brussels, Belgium, July 2010. OCG. 18. Nicolas Halbwachs and \nJulien Henry. When the decreasing sequence fails. In Antoine Min\u00e9 and David Schmidt, editors, SAS, volume \n7460 of LNCS, pages 198 213. Springer, 2012. ISBN 978-3-642-33124-4. 19. Julien Henry, David Monniaux, \nand Matthieu Moy. Succinct represen\u00adtations for abstract interpretation. In Antoine Min\u00e9 and David Schmidt, \neditors, Static Analysis Symposium (SAS 12), volume 7460 of LNCS, pages 283 299. Springer Berlin / Heidelberg, \n2012. 20. Martin Hofmann, Aleksandr Karbyshev, and Helmut Seidl. What is a pure functional? In ICALP \n(2), pages 199 210. LNCS 6199, Springer, 2010. 21. Martin Hofmann, Aleksandr Karbyshev, and Helmut Seidl. \nVerifying a local generic solver in Coq. In SAS 10, pages 340 355. LNCS 6337, Springer, 2010. 22. B. \nLe Charlier and P. Van Hentenryck. A Universal Top-Down Fixpoint Algorithm. Technical Report 92 22, Institute \nof Computer Science, University of Namur, Belgium, 1992. 23. David Monniaux and Julien Le Guen. Strati.ed \nstatic analysis based on variable dependencies. In The Third International Workshop on Numerical and \nSymbolic Abstract Domains, 2011. 24. George C. Necula, Scott McPeak, S. P. Rahul, and Westley Weimer. \nCIL: Intermediate Language and Tools for Analysis and Transforma\u00adtion of C Programs. In CC 02, volume \n2304 of LNCS, pages 213 228. Springer, 2002. 25. Helmut Seidl, Varmo Vene, and Markus M\u00fcller-Olm. Global \ninvari\u00adants for analyzing multithreaded applications. Proc. of the Estonian Academy of Sciences: Phys., \nMath., 52(4):413 436, 2003. 26. Rahul Sharma, Isil Dillig, Thomas Dillig, and Alex Aiken. Simpli\u00adfying \nloop invariant generation using splitter predicates. In Ganesh Gopalakrishnan and Shaz Qadeer, editors, \nComputer Aided Veri.cation (CAV 11), volume 6806 of LNCS, pages 703 719. Springer, 2011. 27. Axel Simon \nand Andy King. Widening polyhedra with landmarks. In Naoki Kobayashi, editor, APLAS, volume 4279 of LNCS, \npages 166  182. Springer, 2006. ISBN 3-540-48937-1. 28. B. Vergauwen, J. Wauman, and J. Lewi. Ef.cient \n.xpoint computation. In SAS 94, volume 864 of LNCS, pages 314 328. Springer, 1994. 29. Vesal Vojdani \nand Varmo Vene. Goblint: Path-sensitive data race analysis. Annales Univ. Sci. Budapest., Sect. Comp., \n30:141 155, 2009.   \n\t\t\t", "proc_id": "2491956", "abstract": "<p>Non-trivial analysis problems require complete lattices with infinite ascending and descending chains. In order to compute reasonably precise post-fixpoints of the resulting systems of equations, Cousot and Cousot have suggested accelerated fixpoint iteration by means of widening and narrowing.</p> <p>The strict separation into phases, however, may unnecessarily give up precision that cannot be recovered later. While widening is also applicable if equations are non-monotonic, this is no longer the case for narrowing. A narrowing iteration to improve a given post-fixpoint, additionally, must assume that all right-hand sides are monotonic. The latter assumption, though, is not met in presence of widening. It is also not met by equation systems corresponding to context-sensitive interprocedural analysis, possibly combining context-sensitive analysis of local information with flow-insensitive analysis of globals.</p> <p>As a remedy, we present a novel operator that combines a given widening operator with a given narrowing operator. We present adapted versions of round-robin as well as of worklist iteration, local, and side-effecting solving algorithms for the combined operator and prove that the resulting solvers always return sound results and are guaranteed to terminate for monotonic systems whenever only finitely many unknowns (constraint variables) are encountered.</p>", "authors": [{"name": "Kalmer Apinis", "author_profile_id": "81502798467", "affiliation": "TU M&#252;nchen, Munich, Germany", "person_id": "P4149062", "email_address": "apinis@in.tum.de", "orcid_id": ""}, {"name": "Helmut Seidl", "author_profile_id": "81100146213", "affiliation": "TU M&#252;nchen, Munich, Germany", "person_id": "P4149063", "email_address": "seidl@in.tum.de", "orcid_id": ""}, {"name": "Vesal Vojdani", "author_profile_id": "81442619799", "affiliation": "TU M&#252;nchen, Munich, Germany", "person_id": "P4149064", "email_address": "vojdanig@in.tum.de", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462190", "year": "2013", "article_id": "2462190", "conference": "PLDI", "title": "How to combine widening and narrowing for non-monotonic systems of equations", "url": "http://dl.acm.org/citation.cfm?id=2462190"}