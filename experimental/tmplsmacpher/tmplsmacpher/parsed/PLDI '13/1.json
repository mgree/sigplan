{"article_publication_date": "06-16-2013", "fulltext": "\n Optimizing Database-Backed Applications with Query Synthesis * Alvin Cheung Armando Solar-Lezama Samuel \nMadden MIT CSAIL {akcheung, asolar, madden}&#38;#169;csail.mit.edu Abstract Object-relational mapping \nlibraries are a popular way for applica\u00adtions to interact with databases because they provide transparent \naccess to the database using the same language as the application. Unfortunately, using such frameworks \noften leads to poor perfor\u00admance, as modularity concerns encourage developers to implement relational \noperations in application code. Such application code does not take advantage of the optimized relational \nimplementa\u00adtions that database systems provide, such as ef.cient implementa\u00adtions of joins or push down \nof selection predicates. In this paper we present QBS, a system that automatically trans\u00adforms fragments \nof application logic into SQL queries. QB S dif\u00adfers from traditional compiler optimizations as it relies \non synthe\u00adsis technology to generate invariants and postconditions for a code fragment. The postconditions \nand invariants are expressed using a new theory of ordered relations that allows us to reason precisely \nabout both the contents and order of the records produced complex code fragments that compute joins and \naggregates. The theory is close in expressiveness to SQL, so the synthesized postconditions can be readily \ntranslated to SQL queries. Using 75 code fragments automatically extracted from over 120k lines of open-source \ncode written using the Java Hibernate ORM, we demonstrate that our approach can convert a variety of \nimperative constructs into rela\u00adtional speci.cations and signi.cantly improve application perfor\u00admance \nasymptotically by orders of magnitude. Categories and Subject Descriptors. D.3.2 [Programming Lan\u00adguages]: \nProcessors Compilers; I.2.2 [Arti.cial Intelligence]: Automatic Programming Program Synthesis Keywords. \nprogram optimization; program synthesis; performance 1. Introduction In this paper, we develop QB S (Query \nBy Synthesis), a new code analysis algorithm designed to make database-backed applications more ef.cient. \nSpeci.cally, QB S identi.es places where applica\u00adtion logic can be pushed into the SQL queries issued \nby the appli\u00adcation, and automatically transforms the code to do this. Moving application code into the \ndatabase reduces the amount of data sent from the database to the application, and it also allows the \ndatabase query optimizer to choose more ef.cient implementations of some operations for instance, using \nindices to evaluate predicates or se\u00adlecting ef.cient join algorithms. * The authors are grateful for \nthe support of Intel Corporation and NSF Grants 1065219 and 1139056. Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 13, June 16 19, 2013, Seattle, WA, USA. \nCopyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . $15.00 One speci.c target of QB S is programs \nthat interact with the database through object-relational mapping layers (ORMs) such as Hibernate for \nJava. Our optimizations are particularly important for such programs because ORM layers often lead programmers \nto write code that iterates over collections of database records, per\u00adforming operations like .lters \nand joins that could be better done inside of the database. Such ORM layers are becoming increas\u00adingly \npopular; for example, as of March, 2013, on the job board dice.com 15% of the 17,000 Java developer jobs \nare for program\u00admers with Hibernate experience. We are not the .rst researchers to address this problem; \nWieder\u00admann et al. [37, 38] identi.ed this as the query extraction problem. However, our work is able \nanalyze a signi.cantly larger class of source programs and generate a more expressive set of SQL queries \nthan this prior work. Speci.cally, to the best of our knowledge, our work is the .rst that is able to \nidentify joins and aggregates in gen\u00aderal purpose application logic and convert them to SQL queries. \nOur analysis ensures that the generated queries are precise in that both the contents and the order of \nrecords in the generated queries are the same as those produced by the original code. At a more foundational \nlevel, our paper is the .rst to demon\u00adstrate the use of constraint-based synthesis technology to attack \na challenging compiler optimization problem. Our approach builds on the observation by Iu et al. [20] \nthat if we can express the postcondition for an imperative code block in relational algebra, then we \ncan translate that code block into SQL. Our approach uses constraint-based synthesis to automatically \nderive loop invariants and postconditions, and then uses an SMT solver to check the resulting veri.cation \nconditions. In order to make synthesis and veri.cation tractable, we de.ne a new theory of ordered relations \n(TOR) that is close in expressiveness to SQL, while being expres\u00adsive enough to concisely describe the \nloop invariants necessary to verify the codes of interest. The postconditions expressed in TOR can be \nreadily translated to SQL, allowing them to be optimized by the database query planner and leading in \nsome cases to orders of magnitude performance improvements. In summary, this paper makes the following \ncontributions: 1. We demonstrate a new approach to compiler optimization based on constraint-based synthesis \nof loop invariants and apply it to the problem of transforming low-level loop nests into high-level SQL \nqueries. 2. We de.ne a theory of ordered relations that allows us to con\u00adcisely represent loop invariants \nand postconditions for code fragments that implement SQL queries, and to ef.ciently trans\u00adlate those \npostconditions into SQL. 3. We de.ne a program analysis algorithm that identi.es candidate code blocks \nthat can potentially be transformed by QB S. 4. We demonstrate our full implementation of QB S and the \ncandi\u00addate identi.cation analysis for Java programs by automatically identifying and transforming 75 \ncode fragments in two large open source projects. These transformations result in order-of\u00admagnitude \nperformance improvements. Although those projects  1 List<User> getRoleUser () { 2 List<User> listUsers \n= new ArrayList<User>(); 3 List<User> users = this.userDao.getUsers(); 4 List<Role> roles = this.roleDao.getRoles(); \n5 for (User u : users) { 6 for (Roles r : roles) { 7 if (u.roleId().equals(r.roleId())) { 8 User userok \n= u; 9 listUsers.add(userok); 10 }}} 11 return listUsers; 12 } Figure 1: Sample code that implements \njoin operation in applica\u00adtion code, abridged from actual source for clarity 1 List listUsers := [ ]; \nint i, j = 0; 2 List users := Query(SELECT * FROM users); 3 List roles = Query(SELECT * FROM roles); \n4 while (i < users.size()) { 5 while (j < roles.size()) { 6 if (users[i].roleId = roles[j].roleId) 7 \nlistUsers := append(listUsers, users[i]); 8 ++j; 9 } 10 ++i;} Figure 2: Sample code expressed in kernel \nlanguage Postcondition listUsers = p\u00a3(N . (users, roles)) where .(eusers , eroles ) := eusers .roleId \n= eroles .roleId i contains all the .elds from the User class Translated code 1 List<User> getRoleUser \n() { 2 List<User> listUsers = db.executeQuery( 3 \"SELECT u 4 FROM users u, roles r 5 WHERE u.roleId == \nr.roleId 6 ORDER BY u.roleId, r.roleId\"); 7 return listUsers; } Figure 3: Postcondition as inferred from \nFig. 1 and code after query transformation use ORM libraries to retrieve persistent data, our analysis \nis not speci.c to ORM libraries and is applicable to programs with embedded SQL queries. 2. Overview \nThis section gives an overview of our compilation infrastructure and the QBS algorithm to translate imperative \ncode fragments to SQL. We use as a running example a block of code extracted from an open source project \nmanagement application [2] written using the Hibernate framework. The original code was distributed across \nseveral methods which our system automatically collapsed into a single continuous block of code as shown \nin Fig. 1. The code retrieves the list of users from the database and produces a list containing a subset \nof users with matching roles. The example implements the desired functionality but performs poorly. Semantically, \nthe code performs a relational join and pro\u00adjection. Unfortunately, due to the lack of global program \ninforma\u00adtion, the ORM library can only fetch all the users and roles from the database and perform the \njoin in application code, without utilizing indices or ef.cient join algorithms the database system has \naccess to. QB S .xes this problem by compiling the sample code to that c . constant ::= True | False \n| number literal | string literal e . expression ::= c | [ ] | var | e.f | {fi = ei } | e1 op e2 | \u00ac \ne | Query(...) | size(e) | get(es ) er | append(er , es ) | unique(e) c . command ::= skip | var := \ne | if (e) then c1 else c2 | while(e) do c | c1 ; c2 | assert e op . binary op ::= . | . | > | = Figure \n4: Abstract syntax of the kernel language  Figure 5: QB S architecture shown at the bottom of Fig. \n3. The nested loop is converted to an SQL query that implements the same functionality in the database \nwhere it can be executed more ef.ciently. Note that the query im\u00adposes an order on the retrieved records; \nthis is because in general, nested loops can constraint the ordering of the output records in ways that \nneed to be captured by the query. In order to apply the QBS algorithm to perform the desired conversion, \nour system must be able to cope with the complexities of real-world Java code such as aliasing and method \ncalls, which obscure opportunities for transformations. For example, it would not be possible to transform \nthe code fragment in Fig. 1 without knowing that getUsers and getRoles execute speci.c queries on the \ndatabase and return non-aliased lists of results, so the .rst step of the system is to identify promising \ncode fragments and translate them into a simpler kernel language shown in Fig. 4. The kernel language \noperates on three types of values: scalars, immutable records, and immutable lists. Lists represent the \ncollec\u00adtions of records and are used to model the results that are returned from database retrieval operations. \nLists store either scalar values or records constructed with scalars, and nested lists are assumed to \nbe appropriately .attened. The language currently does not model the three-valued logic of null values \nin SQL, and does not model updates to the database. The semantics of the constructs in the ker\u00adnel language \nare mostly standard, with a few new ones introduced for record retrievals. Query(...) retrieves records \nfrom the database and the results are returned as a list. The records of a list can be randomly accessed \nusing get, and records can be appended to a list using append. Finally, unique takes in a list and creates \na new list with all duplicate records removed. Fig. 2 shows the example translated to the kernel language. \n2.1 QBS Architecture We now discuss the architecture of QB S and describe the steps in inferring SQL \nqueries from imperative code. The architecture of QB S is shown in Fig. 5. Identify code fragments to \ntransform. Given a web application written in Java, QBS .rst .nds the persistent data methods in the \napplication, which are those that fetch persistent data via ORM li\u00adbrary calls. It also locates all entry \npoints to the application such as servlet handlers. From each persistent data method that is reach\u00adable \nfrom the entry points, the system inlines a neighborhood of calls, i.e. a few of the parent methods that \ncalled the persistent data method and a few of the methods called by them. If there is ambi\u00adguity as \nto the target of a call, all potential targets are considered up to a budget. A series of analyses is \nthen performed on each in\u00adlined method body to identify a continuous code fragment that can be potentially \ntransformed to SQL; ruling out, for example, code fragments with side effects. For each candidate code \nfragment, our system automatically detects the program variable that will contain the results from the \ninferred query (in the case of the running ex\u00adample it is listUsers) we refer this as the result variable. \nAt the end of the process, each code fragment is converted to our kernel language as discussed. Compute \nveri.cation conditions. As the next step, the system computes the veri.cation conditions of the code \nfragment ex\u00adpressed in the kernel language. The veri.cation conditions are written using the predicate \nlanguage derived from the theory of ordered relations to be discussed in Sec. 3. The procedure used to \ncompute veri.cation conditions is a fairly standard one [12, 16]; the only twist is that the veri.cation \ncondition must be computed in terms of an unknown postcondition and loop invariants. The process of computing \nveri.cation conditions is discussed in more detail in Sec. 4.1. Synthesize loop invariants and postconditions. \nThe de.nitions of the postcondition and invariants need to be .lled in and validated before translation \ncan proceed. QBS does this using a synthesis\u00adbased approach that is similar to [31], where a synthesizer \nis used to come up with a postcondition and invariants that satisfy the com\u00adputed veri.cation conditions. \nThe synthesizer uses a symbolic rep\u00adresentation of the space of candidate postconditions and invariants \nand ef.ciently identi.es candidates within the space that are correct according to a bounded veri.cation \nprocedure. It then uses a the\u00adorem prover (Z3 [3], speci.cally) to check if those candidates can be proven \ncorrect. The space of candidate invariants and postcon\u00additions is described by a template generated automatically \nby the compiler. To prevent the synthesizer from generating trivial post\u00adconditions (such as True), the \ntemplate limits the synthesizer to only generate postconditions that can be translated to SQL as de\u00ad.ned \nby our theory of ordered relations, such as that shown at the top of Fig. 3. We observe that it is not \nnecessary to determine the strongest (in terms of logical implication) invariants or postconditions: \nwe are only interested in .nding postconditions that allow us transform the input code fragment into \nSQL. In the case of the running example, we are only interested in .nding a postcondition of the form \nlistUsers = query, where query is an expression translatable to SQL. Similarly, we only need to discover \nloop invariants that are strong enough to prove the postcondition of interest. From the example shown \nin Fig. 1, our system infers the postcondition shown at the top of Fig. 3, where p, s, and N are ordered \nversions of relational projection, selection, and join, respectively to be de.ned in Sec. 3. The process \nof automatic template generation from the input code fragment and synthesis of the postcondition from \nthe template are discussed in Sec. 4. Unfortunately, determining loop invariants is undecidable for arbitrary \nprograms [6], so there will be programs for which the necessary invariants fall outside the space de.ned \nby the templates. However, our system is signi.cantly more expressive than the state of the art as demonstrated \nby our experiments in Sec. 7. Convert to SQL. After the theorem prover veri.es that the com\u00adputed invariants \nand postcondition are correct, the input code frag\u00ad c . constant ::= True | False | number literal | \nstring literal e . expression ::= c | [ ] | program var | {fi = ei } | e1 op e2 | \u00ac e | Query(...) | \nsize(e) | get(er ) | top(er ) es es | p[fi1 ,...,fiN ](e) | s.s (e) | N .N (e1, e2) | sum(e) | max(e) \n| min(e) | append(er , es ) | sort[fi1 ,...,fiN ](e) | unique(e) op . binary op ::= . | . | > | = .s \n. select func ::= ps1 . ... . psN ps . select pred ::= e.fi op c | e.fi op e.fj | contains(e, er ) .N \n. join func ::= pN 1 . ... . pN N pNN . join pred ::= e1.fi op e2.fj Figure 6: Abstract syntax for the \npredicate language based on the theory of ordered relations ment is translated to SQL, as shown in the \nbottom of Fig. 3. The predicate language de.nes syntax-driven rules to translate any ex\u00adpressions in \nthe language into valid SQL. The details of validation is discussed in Sec. 5 while the rules for SQL \nconversion are in\u00adtroduced in Sec. 3.2. The converted SQL queries are patched back into the original \ncode fragments and compiled as Java code. 3. Theory of Finite Ordered Relations QBS uses a theory of \n.nite ordered relations to describe postcon\u00additions and invariants. The theory is de.ned to satisfy four \nmain requirements: precision, expressiveness, conciseness and ease of translation to SQL. For precision, \nwe want to be able to reason about both the contents and order of records retrieved from the database. \nThis is important because in the presence of joins, the order of the result list will not be arbitrary \neven when the origi\u00adnal list was arbitrary, and we do not know what assumptions the rest of the program \nmakes on the order of records. The theory must also be expressive enough not just to express queries \nbut also to express invariants, which must often refer to partially constructed lists. For instance, \nthe loop invariants for the sample code fragment in Fig. 1 must express the fact that listUsers is computed \nfrom the .rst i and j records of users and roles respectively. Conciseness, e.g., the number of relational \noperators involved, is important because the complexity of synthesis grows with the size of the synthesized \nexpressions, so if we can express invariants succinctly, we will be able to synthesize them more ef.ciently. \nFinally, the inferred post\u00adconditions must be translatable to standard SQL. There are many ways to model \nrelational operations (see Sec. 8), but we are not aware of any that ful.lls all of the criteria above. \nFor example, relational algebra is not expressive enough to de\u00adscribe suf.ciently precise loop invariants. \nDe.ned in terms of sets, relational algebra cannot naturally express concepts such as the .rst i elements \nof the list. First order logic (FOL), on the other hand, is very expressive, but it would be hard to \ntranslate arbitrary FOL expressions into SQL. 3.1 Basics Our theory of .nite ordered relations is essentially \nrelational alge\u00adbra de.ned in terms of lists instead of sets. The theory operates on three types of values: \nscalars, records, and ordered relations of .\u00adnite length. Records are collections of named .elds, and \nan ordered relation is a .nite list of records. Each record in the relation is la\u00adbeled with an integer \nindex that can be used to fetch the record. Figure 6 presents the abstract syntax of the theory and shows \nhow to combine operators to form expressions. The semantics of the operators in the theory are de.ned \nrecur\u00adsively by a set of axioms; a sample of which are shown in Fig. 7. get and top take in an ordered \nrelation er and return the record stored at index es or all the records from index 0 up to index es respec\u00ad \n top r = [ ] i = 0 i > 0 r = h : t top(i) = [ ] top(i) = [ ] top(i) = h : topt (i - 1) r r1 =[] N . (r1, \nr2) = [ ] r2 = h : t r r join (N ) r2 = [ ] r1 = h : t N . (r1, r2) = [ ] N . (r1, r2) = cat(N . (h, \nr2), N . (t, r2)) .(e, h) = True r2 = h : t .(e, h) = False N N . (e, r2) = (e, h) : N . (e, r2) = N \n. (e, t) . (e, t) r = [ ] p\u00a3(r) = [ ] r = [ ] r = h : t projection (p) r = h : t fi . i h.fi = ei p\u00a3(r) \n= {fi = ei } : p\u00a3(t) selection (s) .(h) = True r = h : t .(h) = False s.(r) = [ ] s.(r) = h : s.(t) s.(r) \n= s.(t) max r = [ ] r = h : t h > max(t) r = h : t h = max(t) max(r) = -8 max(r) = h max(r) = max(t) \n Figure 7: Some of the axioms that de.ne the theory of ordered relations, Appendix C contains the full \nlist of axioms tively. The de.nitions for p, s and N are modeled after relational projection, selection, \nand join respectively, but they also de.ne an order for the records in the output relation relative to \nthose in the input relations. The projection operator p creates new copies of each record, except that \nfor each record only those .elds listed in [fi1 , ... , fiN ] are retained. Like projection in relational \nalgebra, the same .eld can be replicated multiple times. The s operator uses a selection function .s \nto .lter records from the input relation. .s is de.ned as a conjunction of predicates, where each predicate \ncan compare the value of a record .eld and a constant, the values of two record .elds, or check if the \nrecord is contained in another relation er using contains. Records are added to the resulting relation \nif the function returns True. The N operator iterates over each record from the .rst relation and pairs \nit with each record from the second relation. The two records are passed to the join function .NN. Join \nfunctions are similar to selection functions, except that predicates in join functions compare the values \nof the .elds from the input ordered relations. The axioms that de.ne the aggregate operators max, min, \nand sum assume that the input relation contains only one numeric .eld, namely the .eld to aggregate upon. \nThe de.nitions of unique and sort are standard; in the case of sort, [fi1 , ... , fiN ] contains the \nlist of .elds to sort the relation by. QBS does not actually reason about these two operations in terms \nof their de.nitions; instead it treats them as uninterpreted functions with a few algebraic properties, \nsuch as N . (sort\u00a31 (r1), sort\u00a32 (r2)) = sortcat(\u00a31,\u00a32)(N . (r1, r2)). Because of this, there are some \nformulas involving sort and unique that we cannot prove, but we have not found this to be signi.cant \nin practice (see Sec. 7 for details).  3.2 Translating to SQL The expressions de.ned in the predicate \ngrammar can be converted into semantically equivalent SQL queries. In this section we prove that any \nexpression that does not use append or unique can be com\u00adpiled into an equivalent SQL query. We prove \nthis in three steps; .rst, we de.ne base and sorted expressions, which are formulated based on SQL expressions \nwithout and with ORDER BY clauses respectively. Next, we de.ne translatable expressions and show that \nany expression that does not use append or unique can be con\u00adverted into a translatable expression. Then \nwe show how to produce SQL from translatable expressions. De.nition 1 (Translatable Expressions). Any \ntransExp as de\u00ad.ned below can be translated into SQL: b . baseExp ::= Query(...) | top(s) | N True (b1, \nb2) | agg(t) e s . sortedExp ::= p\u00a3p (sort\u00a3s (s.(b))) t . transExp ::= s | top(s) e where the term agg \nin the grammar denotes any of the aggregation operators (min, max, sum, size). [[Query(string)]] = ( \nstring ) [[top(s)]] = SELECT * FROM [ s] LIMIT [ e] e [ N True (t1, t2)]] = SELECT * FROM [ t1]], [ \nt2] [[agg(t)]] = SELECT agg(.eld) FROM [ t]  [ p\u00a31 (sort\u00a32 (s.s (t)))]] = SELECT [ i1] FROM [ t] WHERE \n[ .s] ORDER BY [ i2]], Order(t) [[unique(t)]] = SELECT DISTINCT * FROM [ t] ORDER BY Order(t) [ .s(e)]] \n= [[e]].f1 op [ e] AND ... AND [ e]].fN op [[e] [[contains(e, t)]] = [[e] IN [ t] [[[fi1 , ... , fiN \n]]] = fi1 , ... , fiN Figure 8: Syntactic rules to convert translatable expressions to SQL Theorem 1 \n(Completeness of Translation Rules). All expres\u00adsions in the predicate grammar in Fig. 6, except for \nthose that con\u00adtain append or unique, can be converted into translatable expres\u00adsions. The theorem is \nproved by de.ning a function Trans that maps any expression to a translatable expression and showing \nthat the mapping is semantics preserving. De.nition of Trans is shown in Appendix B. Semantic equivalence \nbetween the original and the translated expression is proved using the expression equivalences listed \nin Thm. 2. Using those equivalences, for example, we can show that for s . sortedExp and b . baseExp: \nTrans(s.!(s)) = Trans(s.! (p\u00a3p (sort\u00a3s (s.(b))))) [sortedExp def.] s = p\u00a3p (sort\u00a3s (s.s..!(b))) [Trans \ndef.] s = p\u00a3p (s.!(sort\u00a3s (s.s (b)))) [expression equiv.] s = s.!(p\u00a3p (sort\u00a3s (s.s (b)))) [expression \nequiv.] s = s.!(s) [sortedExp def.] s Thus the semantics of the original TOR expression is preserved. \nTranslatable expressions to SQL. Following the syntax-directed rules in Fig. 8, any translatable expression \ncan be converted into an equivalent SQL expression. Most rules in Fig. 8 are direct transla\u00adtions from \nthe operators in the theory into their SQL equivalents. One important aspect of the translation is the \nway that ordering of records is preserved. Ordering is problematic because although the operators in \nthe theory de.ne the order of the output in terms of the order of their inputs, SQL queries are not guaranteed \nto preserve the order of records from nested sub-queries; e.g., the ordering imposed by an ORDER BY clause \nin a nested query is not guaranteed to be respected by an outer query that does not impose any ordering \non the records. To solve this problem, the translation rules introduce a function Order de.ned in Fig. \n9 which scans a translatable expression t and returns a list of .elds that are used to order the subexpressions \n Order(Query(...)) = [record order in DB] Order(agg(e)) = [ ] Order(topi (e)) = Order(e) Order(unique(e)) \n= Order(e) Order(p\u00a3(e)) = Order(e) Order(s.(e)) = Order(e) Order(N . (e1, e2)) = cat(Order(e1), Order(e2)) \nOrder(sort\u00a3(e)) = cat(i, Order(e)) Figure 9: De.nition of Order in t. The list is then used to impose \nan ordering on the outer SQL query with an ORDER BY clause. One detail of the algorithm not shown in \nthe .gure is that some projections in the inner queries need to be modi.ed so they do not eliminate .elds \nthat will be needed by the outer ORDER BY clause, and that we assume Query(...) is ordered by the order \nin which the records are stored in the database (unless the query expression already includes an ORDER \nBY clause). Append and Unique. The append operation is not included in translatable expressions because \nthere is no simple means to com\u00adbine two relations in SQL that preserves the ordering of records in the \nresulting relation 1 . We can still translate unique, how\u00adever, using the SELECT DISTINCT construct at \nthe outermost level, as Fig. 8 shows. Using unique in nested expressions, how\u00adever, can change the semantics \nof the results in ways that are dif\u00ad.cult to reason about (e.g., unique(tope (r)) is not equivalent to \ntope (unique(r))). Thus, the only expressions with unique that we translate to SQL are those that use \nit at the outermost level. In our experiments, we found that omitting those two operators did not signi.cantly \nlimit the expressiveness of the theory. With the theory in mind, we now turn to the process of comput\u00ading \nveri.cation conditions of the input code fragments. 4. Synthesis of Invariants and Postconditions Given \nan input code fragment in the kernel language, the next step in QB S is to come up with an expression \nfor the result variable of the form resultVar = e, where e is a translatable expression as de.ned in \nSec. 3.2. 4.1 Computing Veri.cation Conditions In order to infer the postcondition, we compute veri.cation \ncondi\u00adtions for the input code fragment using standard techniques from axiomatic semantics [19]. As in \ntraditional Hoare style veri.ca\u00ad tion, computing the veri.cation condition of the while statements involves \na loop invariant. Unlike traditional computation of veri.\u00adcation conditions, however, both the postcondition \nand the loop in\u00advariants are unknown when the conditions are generated. This does not pose problems for \nQBS as we simply treat invariants (and the postcondition) as unknown predicates over the program variables \nthat are currently in scope when the loop is entered. As an example, Fig. 11 shows the veri.cation conditions \nthat are generated for the running example. In this case, the veri.cation conditions are split into two \nparts, with invariants de.ned for both loops. The .rst two assertions describe the behavior of the outer \nloop on line 5, with the .rst one asserting that the outer loop invariant must be true on entry of the \nloop (after applying the rule for the assignments prior to loop entry), and the second one asserting \nthat the postcondition for the loop is true when the loop terminates. The third assertion asserts that \nthe inner loop invariant is true when it is .rst entered, given that the outer loop condition and loop \ninvariant 1 One way to preserve record ordering in list append is to use case expres\u00adsions in SQL, although \nsome database systems such as SQL Server limit the number of nested case expressions. Veri.cation conditions \nfor the outer loop (oInv = outerLoopInvariant, iInv = innerLoopInvariant, pcon = postCondition) initialization \noInv(0, users, roles, [ ]) loop exit i = size(users) . oInv(i, users, roles, listUsers) . pcon(listUsers, \nusers, roles) perservation (same as inner loop initialization) Veri.cation conditions for the inner loop \ninitialization i < size(users) . oInv(i, users, roles, listUsers) . iInv(i, 0, users, roles, listUsers) \nloop exit j = size(roles) . iInv(i, j, users, roles, listUsers) . oInv(i + 1, users, roles, listUsers) \npreservation j < size(roles) . iInv(i, j, users, roles, listUsers) . (geti (users).id = getj (roles).id \n. iInv(i, j + 1, users, roles, append(listUsers, geti (users)))) . (geti (users).id = getj (roles).id \n. iInv(i, j + 1, users, roles, listUsers)) Figure 11: Veri.cation conditions for the running example \nare true. The preservation assertion is the inductive argument that the inner loop invariant is preserved \nafter executing one iteration of the loop body. The list listUsers is either appended with a record from \ngeti (users), or remains unchanged, depending on whether the condition for the if statement, geti (users).id \n= getj (roles).id, is true or not. Finally, the loop exit assertion states that the outer loop invariant \nis valid when the inner loop terminates. 4.2 Constraint based synthesis The goal of the synthesis step \nis to derive postcondition and loop invariants that satisfy the veri.cation conditions generated in the \nprevious step. We synthesize these predicates using the SKE T CH constraint-based synthesis system [30]. \nIn general, SK E T CH takes as input a program with holes and uses a counterexample guided synthesis \nalgorithm (C E G IS) to ef.ciently search the space of all possible completions to the holes for one \nthat is correct according to a bounded model checking procedure. For QB S, the program is a simple procedure \nthat asserts that the veri.cation conditions hold for all possible values of the free variables within \na certain bound. For each of the unknown predicates, the synthesizer is given a sketch (i.e., a template) \nthat de.nes a space of possible predicates which the synthesizer will search. The sketches are automatically \ngenerated by QBS from the kernel language representation. 4.3 Inferring the Space of Possible Invariants \nRecall that each invariant is parameterized by the current program variables that are in scope. Our system \nassumes that each loop invariant is a conjunction of predicates, with each predicate having the form \nlv = e, where lv is a program variable that is modi.ed within the loop, and e is an expression in TOR. \nThe space of expressions e is restricted to expressions of the same static type as lv involving the variables \nthat are in scope. The system limits the size of expressions that the synthesizer can consider, and incrementally \nincreases this limit if the synthesizer fails to .nd any candidate solutions (to be explained in Sec. \n4.5). Fig. 10 shows a stylized representation of the set of predicates that our system considers for \nthe outer loop in the running example. The .gure shows the potential expressions for the program variable \ni and listUsers. One advantage of using the theory of ordered relations is that invariants can be relatively \nconcise. This has a big impact for synthesis, because the space of expressions grows exponentially with \nrespect to the size of the candidate expressions. 4.4 Creating Templates for Postconditions The mechanism \nused to generate possible expressions for the re\u00adsult variable is similar to that for invariants, but \nwe have stronger . . . .. . .. . . listUsers | s.(users) |p\u00a3(N . (top(users), top i | size(users) | \nsize(roles) | size(listUsers) | e1 e2 [other relational expressions that return an ordered list] e1 e2 \nsum(p\u00a3(users) | sum(p\u00a3(roles) | max(p\u00a3(users) | [other relational expressions that return a scalar value] \ni op . listUsers = .. . . .. Figure 10: Space of possible invariants for the outer loop of the running \nexample. Type Expression inferred outer loop invariant i = size(users) . listUsers = p\u00a3(N . (topi (users), \nroles)) inner loop invariant i < size(users) . j = size(roles) . listUsers = append( p\u00a3(N . (topi (users), \nroles)), p\u00a3(N . (geti (users), topj (roles))) postcondition listUsers = p\u00a3(N . (users, roles)) restrictions, \nsince we know the postcondition must be of the form resultVar = e in order to be translatable to SQL. \nFor the running example, QB S considers the following possible set of postconditions: . .. . .. users \n| s.(users) | top(users) | e p\u00a3(N . (top(users), top(roles))) | e1 e2 (top listUsers = .. (roles))))) \n| [other relational expressions that return an ordered list] p\u00a3(N .3 (s.1 (tope1 (users), s.2 .. e2 \n 4.5 Optimizations The basic algorithm presented above for generating invariant and postcondition templates \nis suf.cient but not ef.cient for synthesis. In this section we describe two optimizations that improve \nthe synthesis ef.ciency. Incremental solving. As an optimization, the generation of tem\u00adplates for invariants \nand postconditions is done in an iterative man\u00adner: QB S initially scans the input code fragment for \nspeci.c pat\u00adterns and creates simple templates using the production rules from the predicate grammar, \nsuch as considering expressions with only one relational operator, and functions that contains one boolean \nclause. If the synthesizer is able to generate a candidate that can be used to prove the validity of \nthe veri.cation conditions, then our job is done. Otherwise, the system repeats the template gener\u00adation \nprocess, but increases the complexity of the template that is generated by considering expressions consisting \nof more relational operators, and more complicated boolean functions. Our evaluation using real-world \nexamples shows that most code examples require only a few (< 3) iterations before .nding a candidate \nsolution. Ad\u00additionally, the incremental solving process can be run in parallel. Breaking symmetries. \nSymmetries have been shown to be one of sources of inef.ciency in constraint solvers [11, 34]. Unfortunately, \nthe template generation algorithm presented above can generate highly symmetrical expressions. For instance, \nit can generate the following potential candidates for the postcondition: s.2 (s.1 (users)) s.1 (s.2 \n(users)) Notice that the two expressions are semantically equivalent to the expression s.1..2 (users). \nThese are the kind of symmetries that are known to affect solution time dramatically. The template generation \nalgorithm leverages known algebraic relationships be\u00adtween expressions to reduce the search space of \npossible expres\u00adsions. For example, our algebraic relationships tell us that it is unnecessary to consider \nexpressions with nested s like the ones above. Also, when generating templates for postconditions, we \nonly need to consider translatable expressions as de.ned in Sec. 3.2 as potential candidates. Our experiments \nhave shown that applying these symmetric breaking optimizations can reduce the amount of solving time \nby half. Even with these optimizations, the spaces of invariants consid\u00adered are still astronomically \nlarge; on the order of 2300 possible combinations of invariants and postconditions for some problems. \nThanks to these optimizations, however, the spaces can be searched very ef.ciently by the constraint \nbased synthesis procedure. where .(eusers , eroles ) := eusers .roleId = eroles .roleId, i contains all \nthe .elds from the User class Figure 12: Inferred expressions for the running example 5. Formal Validation \nand Source Transformation After the synthesizer comes up with candidate invariants and post\u00adconditions, \nthey need to be validated using a theorem prover, since the synthesizer used in our prototype is only \nable to perform bounded reasoning as discussed earlier. We have implemented the theory of ordered relations \nin the Z3 [3] prover for this purpose. Since the theory of lists is not decidable as it uses universal \nquan\u00adti.ers, the theory of ordered relations is not decidable as well. However, for practical purposes \nwe have not found that to be limit\u00ading in our experiments. In fact, given the appropriate invariants \nand postconditions, the prover is able to validate them within seconds by making use of the axioms that \nare provided. If the prover can establish the validity of the invariants and post\u00adcondition candidates, \nthe postcondition is then converted into SQL according to the rules discussed in Sec. 3.2. For instance, \nfor the running example our algorithm found the invariants and postcondi\u00adtion as shown in Fig. 12, and \nthe input code is transformed into the results in Fig. 3. If the prover is unable to establish validity \nof the candidates (detected via a timeout), we ask the synthesizer to generate other candidate invariants \nand postconditions after increasing the space of possible solutions as described in Sec. 4.5. One reason \nthat the prover may not be able to establish validity is because the maximum size of the relations set \nfor the synthesizer was not large enough. For instance, if the code returns the .rst 100 elements from \nthe relation but the synthesizer only considers relations up to size 10, then it will incorrectly generate \ncandidates that claim that the code was performing a full selection of the entire relation. In such cases \nour algorithm will repeat the synthesis process after increasing the maximum relation size. 5.1 Incorporating \ninferred queries into original code After verifying the transformation, the inferred queries are merged \nback into the code fragment. Before replacing the original frag\u00adment, we run a def-use analysis (which \nuses the points-to informa\u00adtion to be described in Sec. 6.2) starting at the beginning of the code fragment \nuntil the end of the inlined method body. This is to ensure that none of the variables that are de.ned \nin the code fragment to be replaced is used in the rest of the inlined method after replacement. 6. Preprocessing \nof Input Programs In order to handle real-world Java programs, QB S performs a num\u00adber of initial passes \nto identify the code fragments to be transformed to kernel language representation before query inference. \nThe code identi.cation process makes use of several standard analysis tech\u00adniques, and in this section \nwe describe them in detail. 6.1 Generating initial code fragments As discussed in Sec. 2, code identi.cation \n.rst involves locating application entry point methods and data persistent methods. From each data persistent \nmethod, our system currently inlines a neigh\u00adborhood of 5 callers and callees. We only inline callees \nthat are de.ned in the application, and provide models for native Java API calls. For callers we only \ninline those that can be potentially in\u00advoked from an entry point method. The inlined method bodies are \npassed to the next step of the process. Inlining improves the pre\u00adcision of the points-to information \nfor our analysis. While there are other algorithms that can be used to obtain such information [36, 40], \nwe chose inlining for ease of implementation and is suf.\u00ad cient in processing the code fragments used \nin the experiments.  6.2 Identifying code fragments for query inference Given a candidate inlined method \nfor query inference, we would like to identify the code fragment to transform to our kernel lan\u00adguage \nrepresentation. While we can simply use the entire body of the inlined method for this purpose, we would \nlike to limit the amount of code to be analyzed, since including code that does not manipulate persistent \ndata will increase the dif.culty in synthesiz\u00ading invariants and postconditions with no actual bene.t. \nWe ac\u00adcomplish this goal using a series of analyses. First, we run a .ow\u00adsensitive pointer analysis [27] \non the body of the inlined method. The results of this analysis is a set of points-to graphs that map \neach reference variable to one or more abstract memory locations at each program point. Using the points-to \ninformation, we perform two further analyses on the inlined method. Location tainting. We run a data.ow \nanalysis that conservatively marks values that are derived from persistent data retrieved via ORM library \ncalls. This analysis is similar to taint analysis [35], and the obtained information allows the system \nto remove regions of code that do not manipulate persistent data and thus can be ignored for our purpose. \nFor instance, all reference variables and list contents in Fig. 1 will be tainted as they are derived \nfrom persistent data. Value escapement. After that, we perform another data.ow anal\u00adysis to check if \nany abstract memory locations are reachable from references that are outside of the inlined method body. \nThis analy\u00adsis is needed because if an abstract memory location m is accessible from the external environment \n(e.g., via a global variable) after pro\u00adgram point p, then converting m might break the semantics of \nthe original code, as there can be external references to m that rely on the contents of m before the \nconversion. This analysis is similar to classical escape analysis [36]. Speci.cally, we de.ne an abstract \nmemory location m as having escaped at program point p if any of the following is true: It is returned \nfrom the entry point method. It is assigned to a global variable that persists after the entry point \nmethod returns (in the web application context, these can be variables that maintain session state, for \ninstance).  It is assigned to a Runnable object, meaning that it can be accessed by other threads. \n It is passed in as a parameter into the entry point method.  It can be transitively reached from an \nescaped location.   With that in mind, we de.ne the beginning of the code fragment to pass to the QB \nS algorithm as the program point p in the inlined method where tainted data is .rst retrieved from the \ndatabase, and the end as the program point p' where tainted data .rst escapes, where p' appears after \np in terms of control .ow. For instance, in Fig. 1 the return statement marks the end of the code fragment, \nwith the result variable being the value returned. App # persistent data code fragments translated rejected \nfailed Wilos 33 21 9 3 itracker 16 12 0 4 Total 49 33 9 7 Figure 13: Real-world code fragments experiment \n  6.3 Compilation to kernel language Each code fragment that is identi.ed by the previous analysis is \ncompiled to our kernel language. Since the kernel language is based on value semantics and does not model \nheap updates for lists, dur\u00ading the compilation process we translate list references to the ab\u00adstract \nmemory locations that they point to, using the results from earlier analysis. In general, there are cases \nwhere the preprocess\u00ading step fails to identify a code fragment from an inlined method (e.g., persistent \ndata values escape to multiple result variables un\u00adder different branches, code involves operations not \nsupported by the kernel language, etc.), and our system will simply skip such cases. However, the number \nof such cases is relatively small as our experiments show. 7. Experiments In this section we report our \nexperimental results. The goal of the experiments is twofold: .rst, to quantify the ability of our algorithm \nto convert Java code into real-world applications and measure the performance of the converted code fragments, \nand second to explore the limitations of the current implementation. We have implemented a prototype \nof QBS. The source code analysis and computation of veri.cation conditions are imple\u00admented using the \nPolyglot compiler framework [25]. We use Sketch as the synthesizer for invariants and postconditions, \nand Z3 for val\u00adidating the invariants and postconditions. 7.1 Real-World Evaluation In the .rst set of \nexperiments, we evaluated QB S using real-world examples from two large-scale open-source applications, \nWilos and itracker, written in Java. Wilos (rev. 1196) [2] is a project management application with 62k \nLOC, and itracker (ver. 3.0.1) [1] is a software issue management system with 61k LOC. Both applications \nhave multiple contributors with different coding styles, and use the Hibernate ORM library for data persistence \noperations. We passed in the entire source code of these applications to QBS to identify code fragments. \nThe preprocessor initially found 120 unique code fragments that invoke ORM operations. Of those, it failed \nto convert 21 of them into the kernel language representation, as they use data structures that are not \nsupported by our prototype (such as Java arrays), or access persistent objects that can escape from multiple \ncontrol .ow points and hence cannot be converted. Meanwhile, upon manual inspection, we found that those \n120 code fragments correspond to 49 distinct code fragments inlined in different contexts. For instance, \nif A and C both call method B, our system automatically inlines B into the bodies of A and C, and those \nbecome two different code fragments. But if all persistent data manipulation happens in B, then we only \ncount one of the two as part of the 49 distinct code fragments. QB S successfully translated 33 out of \nthe 49 distinct code fragments (and those 33 distinct code fragments correspond to 75 original code fragments). \nThe results are summarized in Fig. 13, and the details can be found in Appendix A. This experiment shows \nthat QB S can infer relational speci.ca\u00adtions from a large fraction of candidate fragments and convert \nthem into SQL equivalents. For the candidate fragments that are reported as translatable by QBS, our \nprototype was able to synthesize post\u00adconditions and invariants, and also validate them using the prover. \nFurthermore, the maximum time that QBS takes to process any one code fragment is under 5 minutes (with \nan average of 2.1 minutes). In the following, we broadly describe the common types of rela\u00adtional operations \nthat our QBS prototype inferred from the frag\u00adments, along with some limitations of the current implementation. \n Projections and Selections. A number of identi.ed fragments perform relational projections and selections \nin imperative code. Typical projections include selecting speci.c .elds from the list of records that \nare fetched from the database, and selections include .ltering a subset of objects using .eld values \nfrom each object (e.g., user ID equals to some numerical constant), and a few use criteria that involve \nprogram variables that are passed into the method. One special case is worth mentioning. In some cases \nonly a sin\u00adgle .eld is projected out and loaded into a set data structure, such as a set of integer values. \nOne way to translate such cases is to gener\u00adate SQL that fetches the .eld from all the records (including \ndupli\u00adcates) into a list, and eliminate the duplicates and return the set to the user code. Our prototype, \nhowever, improves upon that scheme by detecting the type of the result variable and inferring a postcon\u00addition \ninvolving the unique operator, which is then translated to a SELECT DISTINCT query that avoids fetching \nduplicate records from the database. Joins. Another set of code fragments involve join operations. We \nsummarize the join operations in the application code into two categories. The .rst involves obtaining \ntwo lists of objects from two base queries and looping through each pair of objects in a nested for or \nwhile loop. The pairs are .ltered and (typically) one of the objects from each pair is retained. The \nrunning example in Fig. 1 represents such a case. For these cases, QBS translates the code fragment into \na relational join of the two base queries with the appropriate join predicate, projection list, and sort \noperations that preserve the ordering of records in the results. Another type of join also involves obtaining \ntwo lists of objects from two base queries. Instead of a nested loop join, however, the code iterates \nthrough each object e from the .rst list, and searches if e (or one of e s .elds) is contained in the \nsecond. If true, then e (or some of its .elds) is appended to the resulting list. For these cases QB \nS converts the search operation into a contains expression in the predicate language, after which the \nexpression is translated into a correlated subquery in the form of SELECT * FROM r1, r2 WHERE r1 IN r2, \nwith r1 and r2 being the base queries. QB S handles both join idioms mentioned above. However, the loop \ninvariants and postconditions involved in such cases tend to be more complex as compared to selections \nand projections, as illustrated by the running example in Fig. 12. Thus, they require more iterations \nof synthesis and formal validation before .nding a valid solution, with up to 5 minutes in the longest \ncase. Here, the majority of the time is spent in synthesis and bounded veri.cation. We are not aware \nof any prior techniques that can be used to infer join queries from imperative code, and we believe that \nmore optimizations can be devised to speed up the synthesis process for such cases. Aggregations. Aggregations \nare used in fragments in a number of ways. The most straightforward ones are those that return the length \nof the list that is returned from an ORM query, which are translated into COUNT queries. More sophisticated \nuses of aggregates include iterating through all records in a list to .nd the max or min values, or searching \nif a record exists in a list. Aggregates such as maximum and minimum are interesting as they introduce \nloop-carried dependencies [5], where the running value of the aggregate is updated conditionally based \non the value of the current record as compared to previous ones. By using the top operator from the theory \nof ordered relations, QBS is able to generate a loop invariant of the form v = agg(topi(r)) and then \ntranslate the postcondition into the appropriate SQL query. As a special case, a number of fragments \ncheck for the existence of a particular record in a relation by iterating over all records and setting \na result boolean variable to be true if it exists. In such cases, the generated invariants are similar \nto other aggregate invariants, and our prototype translates such code fragments into SELECT COUNT(*) \n> 0 FROM ... WHERE e, where e is the expression to check for existence in the relation. We rely on the \ndatabase query optimizer to further rewrite this query into the more ef.cient form using EXISTS. Limitations. \nWe have veri.ed that in all cases where the generated template is expressive enough for the invariants \nand postconditions, our prototype does indeed .nd the solution within a preset timeout of 10 minutes. \nHowever, there are a few examples from the two applications where our prototype either rejects the input \ncode frag\u00adment or fails to .nd an equivalent SQL expression from the kernel language representation. \nFragments are rejected because they in\u00advolve relational update operations that are not handled by TOR. \nAnother set of fragments include advanced use of types, such as storing polymorphic records in the database, \nand performing differ\u00adent operations based on the type of records retrieved. Incorporating type information \nin the theory of ordered relations is an interesting area for future work. There are also a few that \nQB S fails to trans\u00adlate into SQL, even though we believe that there is an equivalent SQL query without \nupdates. For instance, some fragments involve sorting the input list by Collections.sort, followed by \nretrieving the last record from the sorted list, which is equivalent to max or min depending on the sort \norder. Including extra axioms in the theory would allow us to reason about such cases. 7.2 Performance \nComparisons Next, we quantify the amount of performance improvement as a result of query inference. To \ndo so, we took a few representa\u00adtive code fragments for selection, joins, and aggregation, and pop\u00adulated \ndatabases with different number of persistent objects. We then compared the performance between the original \ncode and our transformed versions of the code with queries inferred by QB S. Since Hibernate can either \nretrieve all nested references from the database (eager) when an object is fetched, or only retrieve \nthe top level references (lazy), we measured the execution times for both modes (the original application \nis con.gured to use the lazy re\u00adtrieval mode). The results shown in Fig. 14 compare the time taken to \ncompletely load the webpages containing the queries between the original and the QB S inferred versions \nof the code. Selection Code Fragment. Fig. 14a and Fig. 14b show the results from running a code fragment \nthat includes persistent data manipu\u00adlations from fragment #40 in Appendix A. The fragment returns the \nlist of un.nished projects. Fig. 14a shows the results where 10% of the projects stored are un.nished, \nand Fig. 14b shows the re\u00ad sults with 50% un.nished projects. While the original version per\u00adforms the \nselection in Java by .rst retrieving all projects from the database, QB S inferred a selection query \nin this case. As expected, the query inferred by QBS outperforms the original fragments in all cases \nas it only needs to retrieve a portion (speci.cally 10 and 50%) of all persistent objects. Join Code \nFragment. Fig. 14c shows the results from a code fragment with contents from fragment #46 in Appendix \nA (which is the same as the example from Fig. 1). The fragment returns the projection of User objects \nafter a join of Roles and Users in the  (a) Selection with 10% selectivity (b) Selection with 50% selectivity \n(c) Join code fragment (d) Aggregation code fragment Figure 14: Webpage load times comparison of representative \ncode fragments database on the roleId .eld. The original version performs the join by retrieving all \nUser and Role objects and joining them in a nested loop fashion as discussed in Sec. 2. The query inferred \nby QBS however, pushes the join and projection into the database. To isolate the effect of performance \nimprovement due to query selectivity (as in the selection code fragment), we purposefully constructed \nthe dataset so that the query returns all User objects in the database in all cases, and the results \nshow that the query inferred by QBS version still has much better performance than the original query. \nThis is due to two reasons. First, even though the number of User objects returned in both versions are \nthe same, the QB S version does not need to retrieve any Role objects since the projection is pushed \ninto the database, unlike the the original version. Secondly, thanks to the automatically created indices \non the Role and User tables by Hibernate, the QB S version essentially transforms the join implementation \nfrom a nested loop join into a hash join, i.e., from an O(n 2) to an O(n) implementation, thus improving \nperformance asymptotically. Aggregation Code Fragment. Finally, Fig. 14d shows the results from running \ncode with contents from fragment #38, which returns the number of users who are process managers. In \nthis case, the original version performs the counting by bringing in all users who are process managers \nfrom the database, and then returning the size of the resulting list. QBS, however, inferred a COUNT \nquery on the selection results. This results in multiple orders of magnitude performance improvement, \nsince the QBS version does not need to retrieve any objects from the database beyond the resulting count. \n 7.3 Advanced Idioms In the .nal set of experiments, we used synthetic code fragments to demonstrate \nthe ability of our prototype to translate more complex expressions into SQL. Although we did not .nd \nsuch examples in either of our two real-world applications, we believe that these can occur in real applications. \nHash Joins. Beyond the join operations that we encountered in the applications, we wrote two synthetic \ntest cases for joins that join relations r and s using the predicate r.a = s.b, where a and b are integer \n.elds. In the .rst case, the join is done via hashing, where we .rst iterate through records in r and \nbuild a hashtable, whose keys are the values of the a .eld, and where each key maps to a list of records \nfrom r that has that corresponding value of a. We then loop through each record in s to .nd the relevant \nrecords from r to join with, using the b .eld as the look up key. QB S currently models hashtables using \nlists, and with that our prototype is able recognize this process as a join operation and convert the \nfragment accordingly, similar to the join code fragments mentioned above. Sort-Merge Joins. Our second \nsynthetic test case joins two lists by .rst sorting r and s on .elds a and b respectively, and then iter\u00adating \nthrough both lists simultaneously. We advance the scan of r as long as the current record from r is less \nthan (in terms of .elds a and b) the current record from s, and similarly advance the scan of s as long \nas the current s record is less than the current r record. Records that represent the join results are \ncreated when the current record from r equals to that from s on the respective .elds. Unfor\u00adtunately, \nour current prototype fails to translate the code fragment into SQL, as the invariants for the loop cannot \nbe expressed using the current the predicate language, since that involves expressing the relationship \nbetween the current record from r and s with all the records that have been previously processed. Iterating \nover Sorted Relations. We next tested our prototype with two usages of sorted lists. We created a relation \nwith one unsigned integer .eld id as primary key, and sorted the list using the sort method from Java. \nWe subsequently scanned through the sorted list as follows: List records = Query(\"SELECT id FROM t\");List \nresults = new ArrayList();Collections.sort(records); // sort by id for (int i = 0; i < 10; ++i){ results.add(records.get(i)); \n} Our prototype correctly processes this code fragment by trans\u00adlating it into SELECT id FROM t ORDER \nBY id LIMIT 10. However, if the loop is instead written as follows: List records = Query(\"SELECT id FROM \nt\"); List results = new ArrayList(); Collections.sort(records); // sort by id int i = 0; while (records.get(i).id \n< 10) { results.add(records.get(i)); ++i;}  The two loops are equivalent since the id .eld is a primary \nkey of the relation, and thus there can at most be 10 records retrieved. However, our prototype is not \nable to reason about the second code fragment, as that requires an understanding of the schema of the \nrelation, and that iterating over id in this case is equivalent to iterating over i in the .rst code \nfragment. Both of which require additional axioms to be added to the theory before such cases can be \nconverted. 8. Related Work Inferring relational speci.cations from imperative code was stud\u00adied in [37, \n38]. The idea is to compute the set of data access paths that the imperative code traverses using abstract \ninterpretation, and replace the imperative code with SQL queries. The analysis is ap\u00adplicable to recursive \nfunction calls, but does not handle code with loop-carried dependencies, or those with join or aggregation. \nIt is unclear how modeling relational operations as access paths can be extended to handle such cases. \nOur implementation is able to infer both join and aggregation from imperative code. We currently do not \nhandle recursive function calls, although we have not encoun\u00adtered such uses in the applications used \nin our experiments. Modeling relational operations. Our ability to infer relational speci.cations from \nimperative code relies on using the TOR to connect the imperative and relational worlds. There are many \nprior work in modeling relational operations, for instance using bags [9], sets [22], and nested relational \ncalculus [39]. There are also the\u00ad oretical models that extend standard relational algebra with order, \nsuch as [4, 24]. Our work does not aim to provide a new theoretical model. Instead, one key insight of \nour work is that TOR is the right abstraction for the query inference, as they are similar to the inter\u00adfaces \nprovided by the ORM libraries in the imperative code, and allow us to design a sound and precise transformation \ninto SQL. To our knowledge, our work is the .rst to address the ordering of records in relational transformations. \nRecord ordering would not be an issue if the source program only operated on orderless data structures \nsuch as sets or did not perform any joins. Unfortunately, most ORM libraries provide interfaces based \non ordered data struc\u00adtures, and imperative implementations of join proves to be common at least in the \nbenchmarks we studied. Finding invariants to validate transformations. Our veri.cation\u00adbased approach \nto .nding a translatable postcondition is similar to earlier work [20, 21], although they acknowledge \nthat .nding invariants is dif.cult. Similar work has been done for general\u00adpurpose language compilers \n[33]. Scanning the source code to gen\u00ad erate the synthesis template is inspired by the PINS algorithm \n[32], although QBS does not need user intervention. There has been ear\u00adlier work on automatically inferring \nloop invariants, such as using predicate re.nement [14] or dynamic detection [13, 18]. Constraint-based \nsynthesis. Constraint-based program synthesis has been an active topic of research in recent years. For \ninstance, there has been work on using synthesis to discover invariants [31]. Our work differs from previous \napproaches in that we only need to .nd invariants and postconditions that are strong enough to vali\u00addate \nthe transformation, and our predicate language greatly prunes the space of invariants to those needed \nfor common relational op\u00aderations. Synthesis has also been applied in other domains, such as generating \ndata structures [29], processor instructions [15], and learning queries from examples [8]. Integrated \nquery languages. Integrating application and database query languages into has been an active research \narea, with projects such as LINQ [23], Kleisli [39], Links [10], JReq [20], the func\u00ad tional language \nproposed in [9], Ferry [17], and DBPL [28]. These solutions embed database queries in imperative programs \nwithout ORM libraries. Unfortunately, many of them do not support all rela\u00adtional operations, and the \nsyntax of such languages resemble SQL, thus developers still need to learn new programming paradigms \nand rewrite existing applications. Improving performance of database programs by code trans\u00adformation. \nThere is also work in improving application perfor\u00admance by transforming loops to allow query batching \n[26], and pushing computations into the database [7]. Our work is orthog\u00ad onal to this line of research. \nAfter converting portions of the source code into SQL queries, such code transformation can be applied \nto gain additional performance improvement. 9. Conclusions In this paper, we presented QB S, a system \nfor inferring relational speci.cations from imperative code that retrieves data using ORM libraries. \nOur system automatically infers loop invariants and post\u00adconditions associated with the source program, \nand converts the validated postcondition into SQL queries. Our approach is both sound and precise in \npreserving the ordering of records. We de\u00adveloped a theory of ordered relations that allows ef.cient \nencoding of relational operations into a predicate language, and we demon\u00adstrated the applicability using \na set of real-world code examples. References [1] itracker Issue Management System. http://itracker. \nsourceforge.net/index.html. [2] Wilos Orchestration Software. http://www.ohloh.net/p/6390. [3] z3 Theorem \nProver. http://research.microsoft.com/en-us/ um/redmond/projects/z3. [4] S. Abiteboul, R. Hull, and V. \nVianu. Foundations of Databases. Addison-Wesley, 1995. [5] J. R. Allen and K. Kennedy. Automatic loop \ninterchange. In Proc. CC, pages 233 246, 1984. [6] A. Blass and Y. Gurevich. Inadequacy of computable \nloop invariants. ACM Trans. Comput. Log., 2(1):1 11, 2001. [7] A. Cheung, O. Arden, S. Madden, and A. \nC. Myers. Automatic partitioning of database applications. PVLDB, 5, 2011. [8] A. Cheung, A. Solar-Lezama, \nand S. Madden. Using program syn\u00adthesis for social recommendations. In Proc. CIKM, pages 1732 1736, 2012. \n[9] E. Cooper. The script-writer s dream: How to write great sql in your own language, and be sure it \nwill succeed. In Proc. DBPL Workshop, pages 36 51, 2009. [10] E. Cooper, S. Lindley, P. Wadler, and J. \nYallop. Links: Web program\u00adming without tiers. In Proc. Int.l Symp. on Formal Methods for Com\u00adponents \nand Objects, pages 266 296, 2006. [11] D. D\u00e9harbe, P. Fontaine, S. Merz, and B. W. Paleo. Exploiting \nsym\u00admetry in smt problems. In Proc. Int.l Conf. on Automated Deduction, pages 222 236, 2011. [12] E. \nW. Dijkstra. Guarded commands, nondeterminacy and formal derivation of programs. Commun. ACM, 18(8):453 \n457, 1975. [13] M. D. Ernst, J. Cockrell, W. G. Griswold, and D. Notkin. Dynamically discovering likely \nprogram invariants to support program evolution. In Proc. ICSE, pages 213 224, 1999. [14] C. Flanagan \nand S. Qadeer. Predicate abstraction for software veri.\u00adcation. In Proc. POPL, pages 191 202, 2002. [15] \nP. Godefroid and A. Taly. Automated synthesis of symbolic instruction encodings from I/O samples. In \nProc. PLDI, pages 441 452, 2012. [16] D. Gries. The Science of Programming. Springer, 1987. [17] T. Grust, \nM. Mayr, J. Rittinger, and T. Schreiber. FERRY: database\u00adsupported program execution. In Proc. SIGMOD, \npages 1063 1066, 2009. [18] A. Gupta and A. Rybalchenko. Invgen: An ef.cient invariant genera\u00adtor. In \nProc. CAV, pages 634 640, 2009. [19] C. A. R. Hoare. An axiomatic basis for computer programming. Commun. \nACM, 12(10):576 580, 1969. [20] M.-Y. Iu, E. Cecchet, and W. Zwaenepoel. Jreq: Database queries in imperative \nlanguages. In Proc. CC, pages 84 103, 2010. [21] M.-Y. Iu and W. Zwaenepoel. HadoopToSQL: a mapreduce \nquery optimizer. In Proc. EuroSys, pages 251 264, 2010. [22] D. Jackson. Alloy: a lightweight object \nmodelling notation. ACM Trans. Softw. Eng. Methodol., 11(2):256 290, 2002. [23] E. Meijer, B. Beckman, \nand G. Bierman. LINQ: Reconciling objects, relations and XML in the .NET framework. In Proc. SIGMOD, \npages 706 706, 2006. [24] W. Ng. An extension of the relational data model to incorporate ordered domains. \nTrans. Database Syst., 26(3):344 383, Sept. 2001. [25] N. Nystrom, M. R. Clarkson, and A. C. Myers. Polyglot: \nAn extensible compiler framework for Java. In Proc. CC, pages 138 152, 2003. [26] K. Ramachandra, R. \nGuravannavar, and S. Sudarshan. Program anal\u00adysis and transformation for holistic optimization of database \napplica\u00adtions. In Proc. SOAP Workshop, pages 39 44, 2012. [27] M. Sagiv, T. Reps, and R. Wilhelm. Parametric \nshape analysis via 3-valued logic. In Proc. POPL, pages 105 118, 1999. [28] J. W. Schmidt and F. Matthes. \nThe DBPL project: Advances in modular database programming. Inf. Syst., 19(2):121 140, 1994. [29] R. \nSingh and A. Solar-Lezama. Synthesizing data structure manipula\u00adtions from storyboards. In Proc. FSE, \npages 289 299, 2011. [31] S. Srivastava and S. Gulwani. Program veri.cation using templates over predicate \nabstraction. In Proc. PLDI, pages 223 234, 2009. [32] S. Srivastava, S. Gulwani, S. Chaudhuri, and J. \nS. Foster. Path-based inductive synthesis for program inversion. In Proc. PLDI, pages 492 503, 2011. \n[33] Z. Tatlock and S. Lerner. Bringing extensibility to veri.ed compilers. In Proc. PLDI, pages 111 \n121, 2010. [34] E. Torlak and D. Jackson. Kodkod: a relational model .nder. In Proc. TACAS, pages 632 \n647, 2007. [35] O. Tripp, M. Pistoia, S. J. Fink, M. Sridharan, and O. Weisman. Taj: effective taint \nanalysis of web applications. In Proc. PLDI, pages 87 97, 2009. [36] J. Whaley and M. Rinard. Compositional \npointer and escape analysis for java programs. In Proc. OOPSLA, pages 187 206, 1999. [37] B. Wiedermann \nand W. R. Cook. Extracting queries by static analysis of transparent persistence. In Proc. POPL, pages \n199 210, 2007. [38] B. Wiedermann, A. Ibrahim, and W. R. Cook. Interprocedural query extraction for transparent \npersistence. In Proc. OOPSLA, pages 19 36, 2008. [39] L. Wong. Kleisli, a functional query system. J. \nFunct. Program., 10(1):19 56, 2000. [40] Y. Xie and A. Aiken. Scalable error detection using boolean \nsatis.a\u00adbility. In Proc. POPL, pages 351 363, 2005. A. Persistent Data Code Fragment Details In this \nsection we describe the code fragments from real-world ex\u00adamples that are used in our experiments. The \ntable below shows the details of the 49 distinct code fragments as mentioned in Sec. 7.1. The times reported \ncorrespond to the time required to synthesize the invariants and postconditions. The time taken for the \nother ini\u00adtial analysis and SQL translation steps are negligible. wilos code fragments itracker code \nfragments # Java Class Name Line Oper. Status Time (s) 17 ActivityService 401 A 18 ActivityService 328 \nA 19 AffectedtoDao 13 B / 72 20 ConcreteActivityDao 139 C * 21 ConcreteActivityService 133 D 22 ConcreteRoleAffectationService \n55 E / 310 23 ConcreteRoleDescriptorService 181 F / 290 24 ConcreteWorkBreakdownElementService 55 G 25 \nConcreteWorkProductDescriptorService 236 F / 284 26 GuidanceService 140 A 27 GuidanceService 154 A 28 \nIterationService 103 A 29 LoginService 103 H / 125 30 LoginService 83 H / 164 31 ParticipantBean 1079 \nB / 31 32 ParticipantBean 681 H / 121 33 ParticipantService 146 E / 281 34 ParticipantService 119 E / \n301 35 ParticipantService 266 F / 260 36 PhaseService 98 A 37 ProcessBean 248 H / 82 38 ProcessManagerBean \n243 B / 50 39 ProjectService 266 K * 40 ProjectService 297 A / 19 41 ProjectService 338 G 42 ProjectService \n394 A / 21 43 ProjectService 410 A / 39 44 ProjectService 248 H / 150 45 RoleDao 15 I * 46 RoleService \n15 E / 150 47 WilosUserBean 717 B / 23 48 WorkProductsExpTableBean 990 B / 52 49 WorkProductsExpTableBean \n974 J / 50  [30] A. Solar-Lezama, L. Tancau, R. Bod\u00edk, S. Seshia, and V. Saraswat. Combinatorial sketching \nfor .nite programs. In Proc. ASPLOS, pages 404 415, 2006.  # Java Class Name Line Operation Status Time \n(s) 1 EditProjectFormActionUtil 219 F / 289 2 IssueServiceImpl 1437 D / 30 3 IssueServiceImpl 1456 L \n* 4 IssueServiceImpl 1567 C * 5 IssueServiceImpl 1583 M / 130 6 IssueServiceImpl 1592 M / 133 7 IssueServiceImpl \n1601 M / 128 8 IssueServiceImpl 1422 D / 34 9 ListProjectsAction 77 N * 10 MoveIssueFormAction 144 K \n* 11 Noti.cationServiceImpl 568 O / 57 12 Noti.cationServiceImpl 848 A / 132 13 Noti.cationServiceImpl \n941 H / 160 14 Noti.cationServiceImpl 244 O / 72 15 UserServiceImpl 155 M / 146 16 UserServiceImpl 412 \nA / 142 where: A: selection of records B: return literal based on result size C: retrieve the max / \nmin record by .rst sorting and then return\u00ading the last element D: projection / selection of records \nand return results as a set E: nested-loop join followed by projection F: join using contains G: type-based \nrecord selection H: check for record existence in list I: record selection and only return the one of \nthe records if mul\u00adtiple ones ful.ll the selection criteria J: record selection followed by count K: \nsort records using a custom comparator L: projection of records and return results as an array M: return \nresult set size N: record selection and in-place removal of records O: retrieve the max / min record \n, indicates those that are translated by. QB S * indicates those that QB S failed to .nd invariants for. \nindicates those that are rejected by QBS due to TOR / pre\u00adprocessing limitations. B. TOR Expression Equivalences \nand De.nition of Trans Before de.ning Trans, we .rst list the set of TOR expression equivalences that \nare used in the de.nition. Theorem 2 (Operator Equivalence). The following equivalences hold, both in \nterms of the contents of the relations and also the ordering of the records in the relations: s.(p\u00a3(r)) \n= p\u00a3(s.(r))  s.2 (s.1 (r)) = s.! (r), where . = .2 . .1  tope (s.(r)) = s.(tope (r))  p\u00a32 (p\u00a31 (r)) \n= p\u00a3! (r), where e is the concatenation of all the .elds in e1 and e2.  (p\u00a3(r)) = p\u00a3(top(r))  tope \ne  top(top(r)) = topmax(e1,e2 )(r)  e2 e1  N . (r1, r2) = s.! (N True (r1, r2)), i.e., joins can be \nconverted into cross products with selections with proper renaming of .elds.  N . (sort\u00a31 (r1), sort\u00a32 \n(r2)) = sort\u00a31:\u00a32 (N . (r1, r2))  N . (p\u00a31 (r1), p\u00a32 (r2)) = p\u00a3! (N . (r1, r2)), where e is the concatenation \nof all the .elds in e1 and e2.  Except for the equivalences involving sort, the other ones can be proven \neasily from the axiomatic de.nitions.    B.1 De.nition of Trans Let s = p\u00a3p (sort\u00a3s (s.(b))). Trans \nis de.ned on expressions whose subexpressions (if any) are in translatable form, so we have to consider \ncases where the sub-expressions are either s or tope (s). Each case is de.ned below. Query(...) Trans(Query(...))) \n= p\u00a3(sort[ ] (sTrue (Query(...)))) append where e projects all the .elds from the input relation. r = \n[ ] append(r, t) = [t] r = h : t append(r, t) = h : append(t, r) p\u00a32 (t) Trans(p\u00a32 (s)) = p\u00a3! (sort\u00a3s \n(s.(b))) Trans(p\u00a32 (tope (s))) = tope (p\u00a3! (sort\u00a3s (s.(b)))) where e is the composition of ep and e2. \nr = [ ] topr (i) = [ ] top i = 0 topr (i) = [ ] i > 0 r = h : t topr (i) = h : topt (i - 1) join (N ) \n size r = [ ] r = h : t size(r) = 0 size(r) = 1 + size(t) get i = 0 r = h : t i > 0 r = h : t geti (r) \n= h geti (r) = geti-1(t) s.2 (t) Trans(s.2 (s)) = p\u00a3p (sort\u00a3s (s...2 (b))) Trans(s.2 (tope (s))) = tope \n(p\u00a3p (sort\u00a3s (s...2 (b)))) N .N (t1, t2)) Trans(N .N (s1, s2)) = p\u00a3! (sort\u00a3! (s.! (N True (b1, b2)))) \np s s where .s = .s1 . .s2 . .NN with .eld names properly renamed, es = cat(es1 , es2 ), and ep = cat(ep1 \n, ep2 ). Trans(N . (tope (s1), tope (s2))) = p\u00a3(sort[ ] (s.(N True (tope (s1), tope (s2))))) where e \ncontains all the .elds from s1 and s2. tope2 (t) Trans(top(s)) = top(s) e2 e2 Trans(top(top(s))) = tope! \n(s) e2 e1 where e is the minimum value of e1 and e2. agg(t) r1 = [ ] r2 = [ ] N . (r1, r2) = [ ] N . \n(r1, r2) = [ ] r1 = h : t N . (r1, r2) = cat(N . (h, r2), N . (t, r2)) r2 = h : t .(e, h) = True r2 \n= h : t .(e, h) = False N . (e, r2) = (e, h) : N . (e, t) N . (e, r2) = N . (e, t) projection (p) r = \n[ ] r = h : t fi . e h.fi = ei p\u00a3(r) = [ ] p\u00a3(r) = {fi = ei } : p\u00a3(t) selection (s) r = [ ] r = h : \nt .(h) = True r = h : t .(h) = False s.(r) = [ ] s.(r) = h : s.(t) s.(r) = s.(t) sum r = [ ] r = h : \nt sum(r) = 0 sum(r) = h + sum(t) max Trans(agg(s)) = p\u00a3(sort[ ] (sTrue (agg(s)))) r = [ ] r = h : t h \n> max(t) r = h : t h = max(t) Trans(agg(tope (s))) = p\u00a3(sort[ ] (sTrue (agg(s)))) max(r) = -8 max(r) \n= h max(r) = max(t) where e contains all the .elds from s. min sort\u00a3s2 (t) r = [ ] r = h : t h < min(t) \nr = h : t h = min(t) min(r) = 8 min(r) = h min(r) = min(t)Trans(sort\u00a3s2 (s)) = p\u00a3p (sort\u00a3! (s.(b))) s \nTrans(sort\u00a3s2 (tope (s))) = tope (p\u00a3p (sort\u00a3! (s.(b)))) s contains where es = cat(es , es2 ). r = [ \n] contains(e, r) = False C. TOR Axioms Below is a listing of all the axioms currently de.ned in the \ntheory e = h r = h : t e = h r = h : t of ordered relations (TOR). cat(e1, e2) concatenates the contents \nof contains(e, r) = True contains(e, r) = contains(e, t) lists e1 and e2.  \n\t\t\t", "proc_id": "2491956", "abstract": "<p>Object-relational mapping libraries are a popular way for applications to interact with databases because they provide transparent access to the database using the same language as the application. Unfortunately, using such frameworks often leads to poor performance, as modularity concerns encourage developers to implement relational operations in application code. Such application code does not take advantage of the optimized relational implementations that database systems provide, such as efficient implementations of joins or push down of selection predicates. In this paper we present QBS, a system that automatically transforms fragments of application logic into SQL queries. QBS differs from traditional compiler optimizations as it relies on synthesis technology to generate invariants and postconditions for a code fragment. The postconditions and invariants are expressed using a new theory of ordered relations that allows us to reason precisely about both the contents and order of the records produced complex code fragments that compute joins and aggregates. The theory is close in expressiveness to SQL, so the synthesized postconditions can be readily translated to SQL queries. Using 75 code fragments automatically extracted from over 120k lines of open-source code written using the Java Hibernate ORM, we demonstrate that our approach can convert a variety of imperative constructs into relational specifications and significantly improve application performance asymptotically by orders of magnitude.</p>", "authors": [{"name": "Alvin Cheung", "author_profile_id": "81321490410", "affiliation": "MIT CSAIL, Cambridge, MA, USA", "person_id": "P4148919", "email_address": "akcheung@csail.mit.edu", "orcid_id": ""}, {"name": "Armando Solar-Lezama", "author_profile_id": "81100173160", "affiliation": "MIT CSAIL, Cambridge, MA, USA", "person_id": "P4148920", "email_address": "asolar@csail.mit.edu", "orcid_id": ""}, {"name": "Samuel Madden", "author_profile_id": "81100092270", "affiliation": "MIT CSAIL, Cambridge, MA, USA", "person_id": "P4148921", "email_address": "madden@csail.mit.edu", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462180", "year": "2013", "article_id": "2462180", "conference": "PLDI", "title": "Optimizing database-backed applications with query synthesis", "url": "http://dl.acm.org/citation.cfm?id=2462180"}