{"article_publication_date": "06-16-2013", "fulltext": "\n P: Safe Asynchronous Event-Driven Programming Ankush Desai Vivek Gupta Damien Zufferey Ethan Jackson \nShaz Qadeer IST Austria Sriram Rajamani Microsoft Abstract We describe the design and implementation \nof P, a domain-speci.c language to write asynchronous event driven code. P allows the programmer to specify \nthe system as a collection of interacting state machines, which communicate with each other using events. \nP uni.es modeling and programming into one activity for the programmer. Not only can a P program be compiled \ninto executable code, but it can also be tested using model checking techniques. P allows the programmer \nto specify the environment, used to close the system during testing, as nondeterministic ghost machines. \nGhost machines are erased during compilation to executable code; a type system ensures that the erasure \nis semantics preserving. The P language is designed so that a P program can be checked for responsiveness \nthe ability to handle every event in a timely manner. By default, a machine needs to handle every event \nthat arrives in every state. But handling every event in every state is im\u00adpractical. The language provides \na notion of deferred events where the programmer can annotate when she wants to delay processing an event. \nThe default safety checker looks for presence of unhan\u00addled events. The language also provides default \nliveness checks that an event cannot be potentially deferred forever. P was used to implement and verify \nthe core of the USB device driver stack that ships with Microsoft Windows 8. The resulting driver is \nmore reliable and performs better than its prior incarnation (which did not use P); we have more con.dence \nin the robustness of its design due to the language abstractions and veri.cation provided by P. Categories \nand Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation Model checking; D.2.5 \n[Software Engineering]: Testing and Debugging; D.3.2 [Pro\u00adgramming Languages]: Language Classi.cations \nSpecialized application languages, Concurrent, distributed, and parallel lan\u00adguages; D.3.3 [Programming \nLanguages]: Language Constructs and Features Concurrent programming structures, Control struc\u00adtures Keywords \ndomain-speci.c language; device driver; event-driven programming; state machine; veri.cation; systematic \ntesting Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n13, June 16 19, 2013, Seattle, WA, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . \n$15.00 1. Introduction Asynchronous systems code that is both performant and correct is hard to write. \nEngineers typically design asynchronous code us\u00ading state machine notations, use modeling and veri.cation \ntools to make sure that they have covered corner cases, and then implement the design in a language like \nC. They use a variety of performance tricks, as a result of which the structure of the state machines \nis lost in myriad of details. Clean state machine diagrams that were initially written down become out-of-date \nwith the actual code as it evolves, and the resulting system becomes hard to understand and maintain. \nDuring the development of Windows 8, the USB team took a bold step and decided to unify modeling and \nprogramming. Various components of the USB driver stack are now speci.ed as state machines and asynchronous \ndriver code is generated from these state machines. We are able to use state exploration tech\u00adniques \ndirectly on the state machines to .nd and .x design bugs. Since the executable code was generated from \nthe source, we could make changes at the level of state machines and perform both ver\u00adi.cation and compilation \nfrom one description. This methodology is used to design, validate and generate code for the USB stack \nthat ships with Windows 8. The resulting driver stack is not only more reliable, but also more performant. \nIn this paper, we formalize and present the salient aspects of this methodology as a domain-speci.c language \nP. Though P has a visual programming interface, we represent P as a textual language with a simple core \ncalculus, so that we can give a formal treatment of the language, compiler and veri.cation algorithms. \nA P program is a collection of state machines communicating via events. Each state machine has a collection \nof states, local variables, and actions. The states and actions are annotated with code statements to \nread and update local variables, send events to other state machines, raise events locally, or call external \nC functions. The external C functions are used to write parts of the code that have do with data transfer. \nA machine responds to received events by executing transitions and actions which in turn causes the aforementioned \ncode fragments to execute. For programming convenience, call transitions are used to factor out common \ncode that needs to be reused (similar to nested modes in state charts [11]). Components in an operating \nsystem are required to be respon\u00adsive. Consequently P programs are required to handle every mes\u00adsage \nthat can possibly arrive in every state. Our notion of respon\u00adsiveness is weaker than synchronous languages \nlike Esterel [4] (which require input events to be handled synchronously during every clock tick, and \nare hence too strong to be implemented in asynchronous software), but stronger than purely asynchronous \nlanguages like Rhapsody [12] (where asynchronous events can be queued arbitrarily long before being handled). \nThus, our notion of responsiveness lies in an interesting design point between syn\u00adchrony and asynchrony. \nIn practice, handling every event at every state would lead to combinatorial explosion in the number \nof con\u00adtrol states, and is hence impractical. The language provides a notion of deferred events to handle \nsuch situations and allow a program\u00admer to explicitly specify that it is acceptable to delay processing \nof certain events in certain states. Reactive systems, such as device drivers, typically interact with \ntheir environment, both synchonously via function calls and asyn\u00adchronously via events. The reliability \nof the system depends crit\u00adically on the correct handling of all interactions via stateful pro\u00adtocols. \nTo allow reasoning about such interactions, we allow pro\u00adgrammers to model the environment of a P program \nusing ghost machines and variables. These ghost elements are used only during modeling and veri.cation \nand elided during compilation. The type system of P ensures that the ghost machines can be erased dur\u00ading \ncompilation without changing the semantics of the program. It is worth noting that both the real and \nghost parts of a P program are based on the computational model of communicating state ma\u00adchines. This \naspect of the P language effectively blurs the distinc\u00adtion between modeling and programming and makes \nthe speci.ca\u00adtion capabilities in the language more accessible to programmers. A P program is validated \nvia systematic testing [9, 17] of its in\u00adherent nondeterminism. Systematic testing is accomplished by \nin\u00adterpreting the operational semantics of a P program (closed using ghost machines) in the explicit-state \nmodel checker Zing [2]. All aspects of the operational semantics of the program are interpreted including \nthe code statements labeling the states and actions of a P machine. The model checker takes care of systematically \nenu\u00admerating all implicit scheduling and explicit modeling choices in the program. The number of states \nand executions of a P program is unbounded in general (in fact, reachability analysis of P pro\u00adgrams \nis undecidable). Therefore, in practice, the enumeration is controlled by bounding techniques. The simplest \napproach to bounding the exploration of nonde\u00adterministic transition systems is depth-bounding [19]. \nWe have im\u00adplemented this approach and found it useful for discovering errors witnessed by short executions. \nHowever, the complexity of depth\u00adbounded search increases exponentially with execution depth, and consequently \ndoes not scale for systematic testing of large P pro\u00adgrams, in which errors may be lurking in long executions. \nWe use delay-bounded scheduling [6] to overcome this problem. A delay\u00ading scheduler is a deterministic \nscheduler with a delay opera\u00adtion, whose invocation causes the scheduler to change its default scheduling \nstrategy. Given a delay budget d, a delaying scheduler naturally de.nes a set of schedules obtained by \nnondeterministi\u00adcally invoking the delay operation at most d times; the number of generated schedules \n(under the assumption that scheduling is the only source of nondeterminism) is independent of execution \nlength and exponential in d; thus arbitrarily long executions can be gen\u00aderated even with a delay bound \nof 0. We expect most bugs that occur in practice to be found using low values of the delay bound. We \nhave developed a new delaying scheduler for P programs; our scheduler prioritizes schedules that follow \nthe causal sequence of events in the program. We provide empirical evidence to demon\u00adstrate that our \nscheduler indeed .nds common errors with a small delay bound. In summary, our contributions are the following: \n We design a DSL P to program asynchronous interacting state machines at a higher level of abstraction \nthan detailed event handlers that lose the state machine structure.  We present formal operational semantics \nand a compiler and runtime that enables P programs to run as KMDF (Kernel Mode Driver Framework) device \ndrivers.  We show how to validate P programs using delay-bounded scheduling and provide a novel delaying \nscheduler that, by  default, attempts to schedule events according to their causal order. We report \non the use of P in a production environment; our case study is the USB stack in Windows 8. 2. Overview \n Figure 1: Elevator example P is a domain-speci.c language for writing asynchronous event\u00addriven programs. \nProtocols governing the interaction among con\u00adcurrently executing components are essential for safe execution \nof such programs. The P language is designed to clearly explicate these control protocols; to process \ndata and perform other func\u00adtions irrelevant to control .ow, P machines have the capability to call external \nfunctions written in C. We call those functions foreign functions. A P program is a collection of machines. \nMachines commu\u00adnicate with each other asynchronously through events. Events are queued, but machines \nare required to handle them in a responsive manner (de.ned precisely later) failure to handle events \nis de\u00adtected by automatic veri.cation. We illustrate the features of P using the example of an elevator, \ntogether with a model of its environment. The elevator machine is shown in Figure 1 and the environment \nmachines in Figure 2. The environment is composed of ghost machines which are used only during veri.cation, \nand elided during compilation and actual execution. Machines that are not ghost are called real machines. \nWe use the term machine in situations where it is not necessary to distinguish between real and ghost \nmachines. Machines communicate with each other using events. An event can be sent from one machine to \nanother and or raised within a machine. Each machine is composed of control states, transitions, actions, \nand variables. The elevator machine has events unit and StopTimerReturned (which are used for communication \nlocally in\u00adside the elevator machine), an action called Ignore, and two ghost  (a) User ghost machine \n (c) Timer ghost machine Figure 2: Environment for elevator variables Timer and Door. Ghost variables \nare used only during veri.cation and are used to hold references to ghost machines. Each state description \nconsists of a 4-tuple (n, d, a, s), where (1) n is a state name, (2) d is a set of events (called deferred \nset), (3) a is a set of (event, action) pairs (called action handlers), and (4) s is a statement (called \nentry statement), which gets exe\u00adcuted when the state is entered. For instance, the Init state in Fig\u00adure \n1 has an empty deferred set, no action handlers, and an en\u00adtry statement that creates an instance of \nthe Timer and Door ma\u00adchines and raises the event unit. As another example, the Open\u00ading state has {CloseDoor} \nas the deferred set, a single action han\u00addler (OpenDoor, Ignore), and send(Door, S endC mdT oOpen) as \nthe entry statement. If the state machine enters the Opening state, the following things happen: on entry \nto the state, the state\u00adment send(Door, S endC mdT oOpen) is executed, which results in the event SendCmdToOpen \nbeing sent to the Door machine. On .nishing the execution of the entry statement, the machine waits for \nevents on the input buffer. The initial state of the Elevator machine is Init. Whenever an instance of \nthe Elevator machine is created (using the new statement), the state of this machine in\u00adstance is initialized \nto Init. Deferred events and action handlers. Events sent to a machine are stored in a FIFO queue. However, \nit is possible to in.uence the order in which the events are delivered. In a given state, some events \ncan be deferred. When trying to receive an event a machine scans its event queue, starting from the front \ndequeuing the .rst event that is not in the deferred set. A dequeued event is either processed by executing \nan action handler or executing an outgoing transition. An action is simply a named piece of code. The \nElevator machine has a single action called Ignore that does nothing. For instance, in the Opening state, \nthe event CloseDoor is deferred and therefore never dequeued. If the event OpenDoor is dequeued, the \nIgnore action is executed (which just drops the event on the .oor) and control stays in Opening. If the \nevent DoorOpened is dequeued, the outgoing transition labeled by DoorOpened is taken and control moves \nto state Opened. Step and call transitions. The edges in Figure 1 specify how the state of the Elevator \nmachine transitions on events. There are two types of transitions: (1) step transitions, and (2) call \ntransitions. Both these transition types have the form (n1, e, n2), where n1 is the source state of the \ntransition, e is an event name, and n2 is the target state of the transition. Step transitions are shown \nby simple edges and call transitions by double edges. For instance, when the machine is in the Init state, \nif an unit event arrives the machine transitions to the Closed state. On the other hand, call transitions \nhave the semantics of pushing the new state on the top of the call stack. Call transitions are used to \nprovide a subroutine-like abstraction for machines. For instance, there is a call transition to the StoppingTimer \nstate from the Opened state on the OpenDoor event, and a similar call transition to the StoppingTimer \nstate from the OkToClose state on the CloseDoor event. One can think about the StoppingTimer state as \nthe starting point of a subroutine that needs to be executed in both these contexts. This subroutine \nhas 3 states: StoppingTimer, WaitingForTimer and ReturnState. The return from the call happens when ReturnState \nraises the StopTimerReturned event. This event gets handled by the callers of the subroutine Opened and \nOkToClose respectively. Unhandled events. The P language has been designed to aid the implementation \nof responsive systems. Responsiveness is under\u00adstood as follows. If an event e arrives in a state n, \nand there is no transition de.ned for e, then the veri.er .ags an unhandled event violation. There are \ncertain circumstances under which the programmer may choose to delay handling of speci.c events or ignore \nthe events by dropping them. These need to be speci.ed ex\u00adplicitly by marking such events in the associated \ndeferred set, so that they are not .agged by the veri.er as unhandled. The veri.er also implements a \nliveness check that prevents deferring events in\u00adde.nitely. This check avoids trivial ways to silence \nthe veri.er by making every event deferred in every state. Environment modeling. Figure 2 shows the environment \nma\u00adchines (which are ghost machines) and initialization statement for the elevator. There are 3 ghost \nmachines: User, Door and Timer. These machines are used to model the environment dur\u00ading veri.cation, \nbut no code is generated for these machines. For the purpose of modeling, the entry statements in the \nstates of these machines are allowed to include nondeterminism. For ex\u00adample, the entry statement of \nthe TimerStarted state is speci.ed as if * then raise(unit) . The * expression evaluates nondeter\u00administically \nto true or false. Thus, when the Timer machine enters this state, it can nondeterministically raise the \nunit event. The ver\u00adi.er considers both possibilities and ensures absence of errors in both circumstances. \nIn the real world, the choice between these program ::= evdecl machine+ m(init * ) machine ::= optghost \nmachine m vrdecl * actdecl * stdecl * spdecl * cldecl * acdecl * optghost ::= e | ghost evdecl ::= event \nedecl+ vrdecl ::= optghost var vdecl+ actdecl ::= action (a, stmt)+ stdecl ::= state (n, {e1, e2, . . \n. , ek}, stmt, stmt)+ spdecl ::= step (n, e, n)+ cldecl ::= call (n, e, n)+ acdecl ::= act (n, e, a)+ \nedecl ::= e(type) vdecl ::= x : type type ::= void | bool | int | event | id stmt ::= skip | x := expr \n| x := new m(init * ) | delete | send(expr, e, expr) | raise (e, expr) | leave | return | assert(expr) \n| stmt; stmt | if expr then stmt else stmt | while expr stmt init ::= x = expr expr ::= this | msg | \narg | b | c |.| x | * | uop expr | expr bop expr c . int b . bool \u00ac, - . uop +, -, ., . . bop r . expr \na, e, m, x . name Figure 3: Syntax possibilities depends on environmental factors (such as timing), \nwhich we choose to ignore during modeling. In this example, the initial machine is the User machine, \nand this is the starting point for a model checker to perform veri.cation. Note that the initial state \nof the User machine creates an instance of Elevator, and the Elevator instance in turn creates instances \nof Timer and Door (in Figure 1). During execution, the external code is responsible for creating an instance \nof the Elevator machine. 3. P Syntax and Semantics Figure 3 shows the syntax of the core of P. Some of \nthe features presented in the examples of Section 2 can be compiled using a pre\u00adprocessor into this core \nlanguage. In particular, state descriptions in the core language are triples of the from (n, d, s1, s2), \nwhere n is a state name, d is a set of deferred events, s1 is an entry statement, and s2 is an exit statement. \nA program in the core language consists of declaration of events, a nonempty list of machines, and one \nmachine creation statement. Each event declaration also speci.es a list of types, which are types of \ndata arguments that are sent along with the event (can be thought of as payload of the event). A machine \ndeclaration consists of (1) a machine name, (2) a list of events, (3) a list of variables, (4) a list \nof actions, (5) a list of states, (6) a list of transitions, and (7) a list of action bindings. Each \nvariable has a declared type, which can be int, byte, bool, event or machine identi.er type (denoted \nid). Actions associate an action name with a statement. Transitions are one of two types: steps or calls, \nand action bindings associate state-event pairs with actions. A machine can optionally be declared as \nghost by pre.xing its declaration by the keyword ghost. Variables can be also declared as ghost. Events \nsent to ghost machines are (implicitly) ghost events. Ghost machines, events and ghost variables are \nused only during veri.cation, and are elided during compilation and execu\u00adtion of the P program. As mentioned \nin Section 2, a state declaration consists of a name n, a set of events (called deferred set), and two \nstatements: (1) an entry statement and (2) an exit statement. Each state declaration must have a distinct \nname. Thus, we can use the name n to denote the state. The entry statement associated with a state n \nis executed whenever control enters n, and the exit statement associated with state n is executed whenever \ncontrol leaves n. Given a machine name m and a state n in m, let Deferred (m, n) denote the associ\u00adated \nset of deferred events and let Action (m, n, e) be an that action a is associated with event e in state \nn, if such a binding exists or . otherwise. Let Entry(m, n) denote the associated entry statement, and \nlet Exit(m, n) denote the associated exit statement. The ini\u00adtial state of the machine m is the .rst \nstate in the state list and is denoted by Init(m). Each action declaration consists of an action name \nand a state\u00adment. Let Stmt(m, a) denote the statement associated with action a in machine m. Transition \ndeclarations describe how a state responds to events. The list of transitions is partitioned into step \ntransitions, and call transitions. A step transition from state n to another state n1 in\u00advolves executing \nthe exit statement of n and the entry statement of n1. A call transition is similar to function calls \nin programming lan\u00adguages and is implemented using a stack (more details below). The set of transitions \nof m must be deterministic, that is, if (n, e, n1) and (n, e, n2) are two transitions then n1 = n2. An \naction binding does not change the state, but merely executes the statement associated with the action. \nA statement (be it an entry statement or exit statement associ\u00adated with a state, or associated with \nan action) is obtained by com\u00adposing primitive statements using standard control .ow constructs such \nas sequential composition, conditionals, and loops. Primitive statements are described below. The skip \nstatement does nothing. The assignment x := r evaluates an expression r and writes the result into x. \nThe statement x := new m(init * ) creates a new machine and stores the identi.er of the created machine \ninto x. The initializers give the initial values of the variables in the cre\u00adated machine. The delete \nstatement terminates the current ma\u00adchine (which is executing the statement) and release its resources. \nThe statement send(r1, e, r2) sends event e to the target machine identi.ed by evaluating the expression \nr1, together with arguments obtained by evaluating r2. When e does not have any argument null is expected. \nIn the examples, we use send(r1, e) as syntactic sugar for send(r1, e, null). The statement raise(e, \nr) terminates the evaluation of the statement raising an event e with arguments obtained by evaluating \nr. The event e must be a local event. The leave statement jumps control to end of the entry function \nto wait for an event to be dequeued. The return statement terminates the evaluation of the statement \nand returns to the caller (see below for more details). The statement assert(r) moves the machine to \nan error state of the expression r evaluates to false, and behaves like skip otherwise. Expressions and \nevaluation. The expressions in the language, in addition to the declared variables, can also refer to \nthree special variables this, msg and arg. While this is a constant contain\u00ading the identi.er of the \nexecuting machine, msg contains the event that is last received from the input buffer of the machine, \nand arg contains the payload from the last event. Expressions also include constants c, the special constant \n., variables, and compound ex\u00adpressions constructed from unary and binary operations on primi\u00adtive expressions. \nBinary and unary operators evaluate to . if any of the operand expressions evaluate to .. The value . \narises ei\u00adther as a constant, or if an expression reads a variable whose value is uninitialized, and \npropagate through operators in an expression. The expression * represents nondeterministic choice of \na Boolean value. Nondeterministic expressions are allowed only in ghost ma\u00adchines to conveniently model \nthe environment. Memory management. P programs manage memory manually by using the new and delete commands. \nThe new command allocates a new instance of a machine and returns its reference, and the delete command \nterminates the machine which executes the command and frees its resources. It is the responsibility of \nthe P programmer to perform cleanup and ensure absence of dangling references, or pending message exchanges \nbefore calling delete. Manually managing the memory add some complexity in order to retain a precise \ncontrol over the footprint of the program. 3.1 Operational semantics The role played by the environment \nis different during execution and veri.cation of a P program. During execution, the environ\u00adment is responsible \nfor creating initial machines in the P program, sending some initial messages to it, and responding to \nevents sent by the P machines. During veri.cation, the environment is speci\u00ad.ed using ghost machines, \nand the program starts execution with a single machine instance of the machine speci.ed by the initializa\u00adtion \nstatement at the end of the program, and this machine begins execution in its initial state with an empty \ninput queue. However, once the initial con.guration is speci.ed (which is different during execution \nand veri.cation), the transition rules are the same for ex\u00adecution as well as veri.cation. We formally \nspecify the transition semantics using a single set of transition rules below. Since our language allows \ndynamic creation of machines, a global con.guration would contain, in general, a collection of machines. \nA machine identi.er id represents a reference to a dynamically-created machine; we denote by Name(id) \nthe name of the machine with identi.er id. A global con.guration M is a map from a machine identi.er \nto a tuple representing the machine con.guration. A machine con.guration corresponding to identi.er id \nis of the form (., s, s, q) with components de.ned as follows: . is a sequence of pairs (n, a), where \nn is a state name, and a is map from events to A.{T, .}, where A is the set of all actions declared in \nmachine Name(id). This sequence functions as a call stack, to implement call and return, and the a values \nare used to inherit deferred events and actions from caller to callee. For an event e, a(e) can be an \naction a, or the value T indicating that the event is deferred, or the value . which indicates that the \nevent does not have an associated action and it is not deferred.  s is a map from variables declared \nin machine Name(id) to their values; this map contains an entry for the local variables this, msg and \narg.  s is the statement remaining to be executed in machine id.  q is a sequence of pairs of a event-argument \npairs representing the input buffer of machine id.  Our type checker veri.es that for any event e and \nstate n, there is at most one outgoing transition labeled with e out of n and at most one action bound \nto e in s. We de.ne Step(m, n, e) to be equal to n' if there is a step transition labeled e between n \nand n' in machine m and . otherwise. Similarly, we de.ne Call (m, n, e) to be equal to n' if there is \na call transition labeled e between n and n' in machine m and . otherwise. We de.ne Trans (m, n, e) to \nbe the union M[id] = (., s, S[x := r], q) s(r) . v (AS SI G N) M -. M[id := (. , s[x := v], S [skip], \nq)] 1 M[id] = (. , s, S[x := new m(x1 = r1, x2 = r2, . . . , xn = rn)], q) 1 111 id = fresh (m) n= Init(m) \nao = .e. . s(r1) . v1 s(r2) . v2 \u00b7 \u00b7 \u00b7 s(rn) . vn 1 1 s= .x. . [this := id][x1 := v1][x2 := v2] \u00b7 \u00b7 \n\u00b7 [xn := vn] (NE W) 1 M -. M[id := (. , s[x := id ], S[skip], q)] 111 11 [id := ((n, ao), s, Entry(m, \nn), e)] M[id] = (. , s, S[delete], q) (DE L ET E) M -. M[id :=.] M[id] = (. , s, S[assert(r)], q) s(r) \n. true (AS S E RT-PA SS) M -. M[id := (. , s, S[skip], q)] M[id] = (., s, S[skip; s], q) (SE Q) M -. \nM[id := (. , s, S[s], q)] M[id] = (. , s, S[if r then s1 else s2], q) s(r) . true (IF-TH E N) M -. M[id \n:= (. , s, S[s1], q)] M[id] = (. , s, S[if r then s1 else s2], q) s(r) . false (IF-EL S E) M -. M[id \n:= (., s, S[s2], q)] M[id] = (. , s, S[while r s], q) s(r) . true (WHI L E -IT ER AT E) M -. M[id := \n(. , s, S [s; while r s], q)] M[id] = (. , s, S[while r s], q) s(r) . false (WH I LE -DO N E) M -. M[id \n:= (. , s, S [skip], q)] M[id] = (., s, S[send(r1, e, r2)], q) 1 1 1111 s(r1) . id s(r2) . v M[id ] = \n(., s, C , q) (SE N D) 11111 M -. M[id := (. , s, S[skip], q)][id := (., s, C , q 0 (e, v))] Figure \n4: Operational semantics: statement execution of Step(m, n, e) and Call (m, n, e). Note that Trans (m, \nn, e) is the static transition in state s on event e, Action (m, n, e) is the static action bound with \nstate n and event e, and Deferred (m, n) is the static set of events deferred in state n. During execution, \nboth deferred events and actions associated with a state can be inherited from callers, and these are \nmodeled in the second component of the call stack, which is a sequence of pairs (n, a). Let S be constructed \naccording to the following grammar: S ::= 0 | S; stmt The leftmost position in S is a hole denoted by \n0; there is exactly one 0 in any derivation for S. We denote by S[s] the substitution of statement s \n. stmt for the unique hole in S. Finally, we have  |q| = {e}. (e,v).q The rules in Figures 4, 5, and \n6 give the operational semantics of our programming language. The program starts execution in a con\u00ad.guration \nM de.ned at a single id0 such that Name(id0) = m, where m is the machine name speci.ed in the program \ns ini\u00adtialization statement (at the end of the program). and M[id0] = ((Init(m), .e. .), .x. ., Entry(m, \nInit(m)), E). The semantics is de.ned as a collection of rules for determining transitions of the form \nM -. M'. All existing state machines are running concur\u00adrently retrieving events from their input queue, \nperforming local computation, and possibly sending events to other machines. Each rule picks an existing \nmachine with identi.er id and executes it for a step. To simplify the rule we use small steps (-.) for \nstatements and big steps (.) for the expression. The rules for expressions are as expected and therefore \nomitted. Figure 4 gives the rules for executing code statements inside a state. These rules execute small \nsteps performed during the com\u00adputation of the entry function of a state. During this computation, M[id] \n= ((n, a) \u00b7 . , s, S[raise (e, r)], q) 1 s(r) . v s= s[msg := e][arg := v] m = Name(id) s = if Pop(m, \nn, a, e) . Step(m, n, e)= . then Exit(m, n) else skip (RA I S E) 1 M -. M[id := ((n, a) \u00b7 ., s, s; raise \n(e, v), q)] M[id] = (. , s, S[leave], q) (LE AVE) M -. M[id := (., s, skip, q)] M[id] = (., s, S[return], \nq) (RE T U RN) M -. M[id := (., s, Exit(m, n); return, q)] M[id ] = ((n, a) \u00b7 ., s, skip, q1 \u00b7 (e, v) \n\u00b7 q2) m = Name(id) t = {e | Trans (m, n, e) =. .Action (m, n, e)=.} 1 d = {e | a(e) = T} d= (d . Deferred \n(m, n)) - t 1 11 |q1| . de . ds= s[msg := e][arg := v] s = if Pop(m, n, a, e) . Step(m, n, e)= . then \nExit(m, n) else skip (DE Q U E U E) 1 M -. M[id := ((n, a) \u00b7 . , s, s; raise (e, v), q1 \u00b7 q2)] M[id] \n= ((n, a) \u00b7 ., s, raise (e, v), q) m = Name(id) Step(m, n, e) = n 1 (ST E P) 1 1 M -. M[id := ((n , \na) \u00b7 . , s, Entry(m, n ), q)] M[id] = ((n, a) \u00b7 . , s, raise (e, v), q) m = Name(id) Trans (m, n, e) \n=. (a(e) = a . Action (m, n, e) =.) . Action (m, n, e) = a a . {., T} (AC T I O N) M -. M[id := ((n, \na) \u00b7 . , s, Stmt(m, a), q)] M[id] = ((n, a) \u00b7 ., s, raise (e, v), q) m = Name(id) Cal l (m, n, e) = n \n1 1 a= .e. if (Trans (m, n, e)=.) then . else if (Action (m, n, e) =.) then Action (m, n, e) else if \n(e . Deferred (m, n)) then T else a(e) (CAL L) 11 1 M -. M[id := ((n , a) \u00b7 (n, a) \u00b7 ., s, Entry(m, n \n), q)] M[id] = ((n, a) \u00b7 ., s, raise (e, v), q) m = Name(id) Pop(m, n, a, e) (PO P1) M -. M[id := (., \ns, raise (e, v), q)] M[id] = ((n, a) \u00b7 ., s, return, q) m = Name(id) (PO P 2) M -. M[id := (. , s, skip, \nq)] Figure 5: Operational semantics: event handling M[id] = (., s, S[assert(r)], q) s(r) . false (AS \nSE RT-FA I L) M -. error M[id] = (., s, S[send(r1, e, r2)], q) s(r1) .. (SE N D -FA I L 1) M -. error \nM[id] = (., s, S[send(r1, e, r2)], q) 1 1 s(r1) . id M[id ] =. (SE N D-FA I L 2) M -. error M[id] = (e, \ns, s, q) (PO P -FA I L) M -. error Figure 6: Operational semantics: error transitions local variables \ncould be modi.ed and events could be sent to other state machines. The rule SEND shows the semantics \nof the statement send(r1, e, r2). First, the target of the send id ' = s(r1), and the payload of the \nevent v = s(r2) are evaluated and the event (e, v) is appended to the queue of the target machine identi.ed \nby id ' using the spe\u00adcial append operator 8. The operator 8 is de.ned as follows. If (e, v) . q, then \nq 8 (e, v) = q \u00b7 (e, v). Otherwise, q 8 (e, v) = q. Thus, event-value pairs in event queues are unique, \nand if the same event-value pair is sent more than once to a machine, only one instance of it is added \nto the queue, avoiding .ooding of the queue due to events generated by hardware, for instance. In some \ncases, the programmer may want multiple events to be queued, and they can enable this by differentiating \nthe instances of these events using a counter value in the payload. Figure 5 gives the rules for how \nevents are generated and pro\u00adcessed. These rules use raise and return, which are dynamic in\u00adstances of \nraise and return statements respectively. The compu\u00adtation terminates either normally via completion \nof all statements in the entry statement, execution of leave to jump control to the end of the entry \nfunction, execution of a return statement (which results in popping from the call stack), or by raising \nan event e. In the .rst two cases, the machine attempts to remove an event from the input queue via the \nrule DE QUEUE prior to raising the retrieved event. Each state in a state machine can opt to defer a \nset of events received from the outside world. The logic for dequeuing an event from the input buffer \nis cognizant of the current set of deferred events and skips over all deferred events from the front \nof the queue. The deferred set of a stack of states is the union of the deferred set at the top of the \ncall stack with the value resulting from evaluating the deferred set expression declared with that state. \nIn case an event e is both in the deferred set and has a de.ned transition from a state, the de.ned transition \noverrides, and the event e is not deferred (see rule DE QU E U E). Once an event is raised, using either \ndequeuing or a raise state\u00adment, it is handled using one of the three transition rules ST E P, AC-T ION \nor CAL L. The ST E P transition results in leaving the current state n and entering a target state n \n'. The AC TI O N transition picks an appropriate action a either from Action (m, n, e) or from the partial \nmap a on the call stack, with the caveat that an action bound on the current state using Action (m, n, \ne) overrides the action in\u00adherited in the call stack using a. Once a suitable action a is picked, the \nstatement Stmt(m, a) is executed. Also, if Step(m, n, e) or Call (m, n, e) is de.ned, it takes higher \npriority over actions. The CA LL transition computes new values for the map a ' in terms of the existing \nvalue of the map a on the top of the stack and the set of transitions and actions de.ned on the current \nstate n. The map a ' (e) is de.ned as follows: if a transition is de.ned for e then it is bound to ., \notherwise if the event e is bound to an action in n then that binding is used, otherwise if event e is \ndeferred in n then it is mapped to T, and all the other events are mapped to the old value a(e). As a \nresult of the transition, the machine enters the target state n ' by pushing the pair (n ' , a ' ) on \nthe stack. If these transition rules are not applicable due to the unavail\u00adability of a suitable transition, \nthen the top most state on the ma\u00adchine stack is popped via the rules PO P 1 and PO P 2 to allow the \nnext state to continue processing. These rules use the predicate Pop(m, n, a, e) to represent the condition \nunder which a state is popped. Pop(m, n, a, e) = Step(m, n, e) =. . Call (m, n, e) =. . Action (m, n, \ne) =. . a(e) . {., T}  If rule PO P 1 executes, the next state must process the unhandled event; if \nrule PO P 2 executes, the next state dequeues a new event from the input queue. The exit function Exit(m, \nn) of a state n in machine m is executed either when a step transition out of s is taken or s is popped. \nWhen an event e is raised or dequeued, the available transitions in s are examined to determined whether \nExit(m, n) needs to be executed, and if so, the code statement E xit(m, n) is inserted into the state. \nExit(m, n) is always executed if the entry function terminates with a return. The rules in Figure 5 assume \nthat Exit(m, n) itself does not contain any explicit raise or return; however, our implementation allows \nthat. Figure 6 speci.es error transitions. The error con.guration, denoted by error , can be reached \nin one of 4 ways: (1) by failing an assertion (rule ASSE RT-FAI L), (2) by executing a statement send(r1, \ne, r2) with r1 evaluating to . (rule SE N D -FA IL1), (3) by executing a statement send(r1, e, r2) with \nr1 evaluating to some id ', but with M[id ' ] =., thereby attempting to send to an uninitialized or deleted \nmachine (rule SEN D -FA IL 1), and (4) The stack becomes empty after a pop (rule PO P -FA IL). In Section \n5, we show how to detect all these 4 types of errors using systematic testing. Other features. We conclude \nthe description of the core language and semantics with two additional features: (1) foreign functions, \nand (2) call statements. Both these features are very important to write real-world asynchronous code, \nbut their semantics is stan\u00addard. Consequently, we describe them informally below. To interact with external \ncode, a P program has the ability to call functions written in the C language. These functions needs \nto be introduced in the scope of a machine by a declaration that give the function s name and type signature. \nThe runtime semantics of a function call to a foreign functions is similar to a standard C method call. \nFor veri.cation purposes we allow the user to give a P body to a foreign function. The body has to be \nerasable, i.e. uses only ghost variables and expressions. The P language also has a call statement of \nthe form call n ' , where n ' is a state. This can be used to transition to the target state n ' by pushing \nn ' on the call stack, much like a call transi\u00adtion. Unlike a call transition, the call statement requires \nsaving a continuation associated with the caller on the stack, so that execu\u00adtion can resume and complete \nthe remaining statements when the callee state is popped.  3.2 Responsiveness Beyond providing constructs \nfor building safe programs, the design of the P language also contains constructs to build responsive \npro\u00adgrams. Explicitly deferring messages instead of doing so implicitly is such a design choice. However, \nit is still possible to excessively defer events, thus not processing them. Therefore, we propose two \nliveness properties that must be satis.ed by a P program. We de\u00adscribe these two properties below in \nterms of a precise description of those in.nite executions which violate these properties; we use linear \ntemporal logic [18] for our speci.cations. Our speci.cations use the following predicates over events \nthat occur during an exe\u00adcution: 1. en(m) holds iff machine m is enabled, i.e., m can take a step. 2. \nsched (m) holds iff machine m is enabled and takes a step. 3. enq(m, e, m ' ) holds iff machine m enqueues \nan event e into machine m ' . 4. deq (m ' , e) holds iff machine m ' dequeues an event e.  The .rst \nproperty speci.es that a machine cannot execute indef\u00adinitely without getting disabled. In particular, \na machine should not get into a cycle of private operations, causing it to loop forever. The set of erroneous \nexecutions is given by .m. O0(sched (m)). The second property speci.es that events are not deferred \nex\u00adcessively; the goal is to prevent events from being always deferred, thus never processed. We .rst \nde.ne the notion of fairly scheduling a machine m. fair(m) = 0O(en(m) . sched (m)) An erroneous execution \nis one in which every machine is fairly scheduled and an event is enqueued which is never subsequently \ndequeued. The set of all erroneous executions is given by ' '' .m. fair(m) . .m, e, m . O(enq(m, e, \nm ) . 0\u00acdeq (m , e)). Our experience with real drivers suggests that in some cases, this property may \nbe too strong. For instance, in a system with priori\u00adtized events, enough high priority events from the \nenvironment may postpone forever the processing of lower priority events. We allow programmers to indicate \nthis expectation in a state s by annotat\u00ading s with a list of postponed events. Our re.nement of the \nsec\u00adond liveness speci.cation uses the predicate ppn(m, e) that holds whenever m is in a state whose \nlist of postponed events contains e. The smaller set of erroneous executions is given by ' .m. fair(m)..m, \ne, m ' . O(enq(m, e, m ' ) . 0\u00acdeq (m , e)). O0\u00acppn(m ' , e). 3.3 Type system and erasure The type system \nof P is, on purpose, kept very simple. It mostly does simple checks to make sure the machines, transitions, \nand statements are well-formed. In particular, the following checks are performed: (1) identi.ers for \nmachines, state names, events, and variables are unique, (2) statements inside real machines are deterministic, \nand (3) ghost machines, ghost variables, and ghost events can be erased during compilation and execution. \nThe only non-trivial part of our type system is the rules that deal with the erasure property of ghost \nvariables, and ghost ma\u00adchines. We identify ghost terms in statements of real machines, and check that \nthey do not affect the runs of real machines (ex\u00adcept for assertions). The separation is needed since \nghost terms are kept only for veri.cation purposes and are erased during the com\u00adpilation. Therefore, \nonly a limited .ow of information is allowed between real and ghost terms. For machine identi.ers we \nenforce complete separation, because we need to unambiguously identify the send operation that targets \nghost machine, so that it can be preserved during veri.cation and erased during compilation. The error \ntransitions speci.ed in Figure 6 cannot be detected by our type checker. Instead, we use state-space \nexploration tech\u00adniques (described in Section 5) to check for these errors statically. 4. Execution This \nsection explains how we generate code from a P program, so that the generated code can run as a Windows \ndevice driver. Execu\u00adtion requires a host driver framework; our current implementation uses Windows Kernel \nMode Driver Framework (KMDF). The com\u00adplete driver, which runs inside Windows, has four components: 1. \nThe generated code is a C .le which is produced by the P compiler from a state machine description. \n2. The runtime is a library that interacts with the generated code and provides utilities for synchronization \nand management of state, execution, and memory. 3. The interface code is a skeletal KMDF driver which \nmediates between the OS and the generated code by creating instances  of P machines and getting the \nexecution started, and translating OS callbacks into P state machine events that are queued into the \nqueues of the respective machines. 4. The foreign functions are provided as C source .les or libraries. \nThe function calls occurring in the machines are linked to those .les. Generated code. The code generated \nfrom a P program comprises a collection of indexed and statically-allocated data structures that are \nexamined by the runtime when it executes the operational se\u00admantics of the program. The set of names \nof events is compiled to a C enumeration, thus giving a globally-known unique index to each event. Similarly, \nnames of machine types and names of local variables and states in each machine are also compiled to C \nenu\u00admerations. At the top level, there is a driver structure that contains pointers to an array of events \nand an array of machine types; these arrays are indexed by the corresponding enumerations for events \nand machine types respectively. Each entry in the machine array contains pointers to an array of variables \nand an array of states, each indexed by the corresponding enumeration. Each entry in the state array \ncontains a table of outgoing transitions, a table of de\u00adferred events, a table of installed actions, \nand pointers for entry and exit functions. In addition to these data structures, the compiler also generates \nC code for the bodies of entry and exit functions of all states and all actions declared in the program. \nWhen P is compiled to C, the state of a machine is wrapped into an object of type StateMachineContext. \nThis object contains data structures to represent the state of the machine, as described in the formal \noperational semantics in Section 3. In addition, it also contains a void* pointer to external memory \nused only by the foreign functions and interface code. To make the P compiler work for another driver \nframework or another operating system, the runtime and foreign code needs to be reimplemented appropriately \nbut the generated code does not need to change. Runtime. The runtime of P provides functionality for \nall opera\u00adtions required for executing the operational semantics of a P pro\u00adgram, such as creating a \nmachine, enqueueing an event into a machine, running a state machine, maintaining the call stack and \navailable event handlers of each machine, etc. This functionality is mostly private to the runtime with \na few exceptions for the bene\u00ad.t of interface code, which can interact with the P runtime using three \nAPIs: create a new state machine using SMCreateMachine, queue an event into a machine using SMAddEvent, \nor request a pointer to the external memory associated with a machine using SMGetContext. Windows drivers \nare parsimonious with threads. Worker threads are rarely created and drivers typically use calling threads \nto do all the work. Thus, when the OS calls the driver, either due to an application request or due to \na hardware interrupt or deferred procedure call, the driver uses the calling thread to process the event \nand run to completion. Multiple such threads could be executing inside the runtime at any time; each \ndynamic instance of a state machine is protected by its own lock for safe synchronization. Interface \ncode. The interface code is used to mediate between the OS and the P code. It is written as a skeletal \nKMDF driver, which handles callbacks from the Windows OS and translates them into events it adds to the \nqueue of the P machine, using the runtime API. In KMDF, the EvtAddDevice callback is used to create the \nstate machine using the SMCreateMachine API. All events such as Plug and Play or Power management or \nother events are handled by the foreign code by queuing a corresponding event using the SMAddEvent API. \nThe EvtRemoveDevice callback results in a special event Delete added to the P driver. Every P state machine \nis required to handle this event by cleaning up and executing the delete statement. Note that the P machine \nmay have to do internal bookkeeping and keep track of other machines it has created, and the state of \nthe interactions it has with other machines, cleanup the state of the interactions, and only then execute \nthe delete statement. In our experience, the interface code is generic enough so that it can be automatically \ngenerated for a particular class of drivers. Foreign functions. The foreign functions are provided by \nthe pro\u00adgrammer to complement the P machines. The foreign functions must have one additional argument \non top of the ones declared in P. This argument, of type void *, points to external memory that can be \nused by the programmer to persist some information as part of the state of calling machine. The foreign \nfunctions are assumed to terminate and to limit any side effect to the provided memory. Unlike the interface \ncode which is generic, foreign functions are typically driver-speci.c and consequently need to be speci.ed \nby the programmer. 4.1 Ef.ciency of generated code and runtime In order to evaluate the ef.ciency of \nthe code generated by P and the runtime, we performed the following experiment. We devel\u00adoped two drivers \nfor a simple switch-and-led device, one using P, and one directly using KMDF. Both drivers use the same \nlevel of asynchrony. The P code is about 150 lines with one driver machine and four ghost machines. The \ndriver machine has 15 states and 23 transitions, and each ghost machines has approximately four states \nand transitions. The foreign code is 1720 lines, written directly in C, interfacing between KMDF and \nthe P code. In contrast, the full KMDF driver (written without using P) is about 6000 lines of C code. \nWe tested both drivers in an environment which sends 100 events per second, and both drivers are able \nto process each event with an average processing time of 4ms, demonstrating that the P compiler and runtime \ndo not introduce additional overhead. We present a more substantial case study in Section 6. 5. Systematic \ntesting P is designed to enable systematic testing of programs written in it. There are two kinds of \nnondeterminism in the semantics of P programs explicit nondeterministic choice in the ghost machines \nand implicit nondeterministic choice of which machine to schedule next. Systematic testing of a P program \nis accomplished by inter\u00adpreting its operational semantics (closed using ghost machines) in the explicit-state \nmodel checker Zing [2]. All aspects of the op\u00aderational semantics of the program are interpreted including \nthe code statements labeling the states and actions of a P machine. The model checker takes care of systematically \nenumerating all implicit scheduling and explicit modeling choices in the program and checks for the possible \nerrors (see Figure 6) namely, (1) as\u00adsertion failures, (2) executing send commands with uninitialized \ntarget identi.ers, (3) sending events to machine that has been al\u00adready freed, and (4) unhandled events. \nWe leave veri.cation of the liveness checks in P programs for future work. Machines in P programs communicate \nvia message-passing; there are only three operations at which a communication between two machines occurs \ncreating a machine, sending an event, and receiving an event. It suf.ces to introduce context-switches \nafter only these operations; since a private operation in a machine com\u00admutes with operations of other \nmachines, a context switch after is redundant. In other words, if an error occur in an execution with \na more .ne-grained context-switching, it can be shown to occur in another equivalent execution in which \ncontext-switches happen only at the points mentioned above. This optimization is an exam\u00adple of atomicity \nreduction [7]. Furthermore, it can be shown that a receive operation is a right mover [15]; therefore, \na context switch after a receive operation can also be eliminated and it suf.ces to in\u00adtroduce context \nswitches only after a machine is created or an event is sent. Delay-bounded scheduling. Unfortunately, \neven the coarse-grained context-switching described above is not suf.cient to prevent the state space \nexplosion problem. If there are k machines enabled at each interleaving point, the number of possible \nschedules for runs with n context switches is kn. Therefore, systematic exploration of long schedules \nbecomes prohibitively expensive. Consequently, we have designed a delaying scheduler to scale our exploration \nto large P programs with long executions. Intuitively, our delaying scheduler explores schedules that \nfol\u00adlow the causal sequence of events. Diverging from that sequence is done by delaying some machine. \nGiven a bound d, the scheduler may introduce at most d delays. Suppose machine m1 sends an event e to \nmachine m2. Then, at a later point m2 removes e from its input buffer, and processes this message, thereby \nresulting in an event e ' sent to machine m3. The delay bounded scheduler follows the causal sequence \nof steps which consists of machine m1 sending the event e to m2, machine m2 processing the event e and \nsending the event e ' to m3, and machine m3 handling the event e '. A delay that the scheduler may choose \nto introduce is, for instance, at the second context-switch delaying m3 and executing m2. More formally, \nour delaying scheduler maintains a stack S of P machine identi.ers, and an integer delay score. Initially, \nthe stack S contains a single machine identi.er corresponding to the instance created by the initialization \nstatement of the P program, and the delay score is set to 0. For example, in the Elevator example from \nSection 2, the stack initially contains the id of the User ghost machine. The scheduler always chooses \nto schedule the machine whose identi.er is at the top of S. The scheduled machine executes until it reaches \na scheduling point (which is a send or the creation of a machine) at which point the scheduler again \nprovides the next machine to be scheduled. The stack S and the delay score is updated in response to \nevents happening in the execution as follows: ' If m is scheduled and m creates a new machine m ', then \nm is pushed on S.  If m is delayed, m is moved from top of S to the bottom of S, and the delay score \nis incremented by 1.  If m is scheduled and m sends an event to machine m and m ' . S, m ' is pushed \non S. ' Given a delay bound d, a delay bounded scheduler explores only those schedules which have a \ndelay score lesser than or equal to d. We can show that for d = 0, the real part of schedules ex\u00adplored \nby the delay bounded scheduler are exactly the same as the one executed by the P runtime in Section 4, \nassuming no mul\u00adtithreading (that is, at most one thread calls into the P runtime from the kernel). Differences \nbetween the runtime and the delay bounded scheduler occur only in the interaction with the ghost ma\u00adchines/environment. \nIncreasing the delay bound d let the scheduler explores more schedules and captures more interactions \nwith the environment. We can also show that as d approaches in.nity, in the limit, the delay bounded \nscheduler explores all possible schedules of a P program, and in particular includes all cases where \nthe P runtime is invoked by an arbitrary number of parallel threads from the kernel. However, even for \nlow values of d, the delay bounded scheduler is very useful in error detection, as shown below. Empirical \nresults. In order to evaluate the ef.cacy of delay bound\u00ading, we conducted the following experiments. \nFor three benchmark  Figure 7: States explored with increasing delay bound. P programs (elevator example \nfrom Section 2, driver for Switch-and-LED device, and for a software implementation of German s cache \ncoherence protocol), we studied the behavior of delay bound\u00ading for varying values of the delay bound \nparameter d. Figure 7 shows how the number of explored states varies as we increase the value of the \ndelay bound parameter. We scaled the number of states in the Switch-LED by a factor of 10 and Elevator \nby a factor of 100 to make the graphs legible. We also experimented with buggy ver\u00adsions of these designs \nand determined that bugs are found within a delay bound of 2. The data can be summarized as follows: \nbugs are found for low values of delay bound (note the low value of number of states explored for delay \nbound of 2 in Figure 7 within which bugs were found), and as we increase the delay bound we eventu\u00adally \nexplore all states within a delay bound of around 12. 6. Case Study USB Hub Driver: Context and challenges. \nThe state machine methodology described in this paper, together with code generation as well as veri.cation, \nwas used in the development of core com\u00adponents of the USB 3.0 stack that was released as part of Microsoft \nWindows 8. In particular, the USB hub driver ( USBHUB3.sys ) was developed using our methodology. The \nUSB hub driver is re\u00adsponsible for managing USB hubs, the ports in these hubs, enu\u00admerating the devices \nand other hubs connected to their downstream ports. It receives a large number of un-coordinated events \nsent from different sources such as OS, hardware and other drivers, in tricky situations when the system \nis suspending or powering down. It can receive unexpected events from disabled or stopped devices, non\u00adcompliant \nhardware and buggy drivers. The hub driver can fail re\u00adquests from incorrect hardware or buggy function \ndrivers. How\u00adever, it is important that the USB hub itself handles all events and does not crash or hang \nitself. State machine P states P transitions Explored states (millions) Time (hh:mm) Memory MB HSM PSM \n3.0 PSM 2.0 DSM 196 295 457 1919 361 752 1386 4238 5.9 1.5 2.2 1.2 2:30 3:30 5:30 5:30 1712 1341 872 \n1127 Figure 8: State machine sizes and exploration time  Experience using P in USB Hub. We designed \nthe USB Hub in P as a collection of state machines. The hub, each of the ports, and each of the devices \nare designed as P machines. Using P helped us serialize the large number of uncoordinated events coming \nin from hardware, operating system, function drivers and other driver components. In order to make hub \nscalable, the processing in the hub should be as asynchronous as possible. We captured all the complexity \nof asynchronous processing using P state machines, and .ne-grained and explicit states for each step \nin the processing. We used sub-state machines to factor common event handling code, and control the explosion \nin the number of states in the P code, and deferred events to delay processing of low-priority events. \nWe made sure that any code in the driver that lives outside the P state machine (as foreign functions) \nis relatively simple and primarily does only data processing, and no control logic. This helped us ensure \nthat the most complex pieces of our driver are veri.ed using the state exploration tools of P. We had \nto carefully constrain the environment machines in several cases to help direct the veri.cation tools. \nEven with such constraints, the actual state spaces explored by the veri.er were on the order of several \nmillions, and the veri.er runs took several hours to .nish (even after using multicores to scale the \nstate exploration), once our designs became mature and the shallow bugs were found and .xed. Figure 8 \nshows the size and scale of state spaces for the various state machines. The second and third columns \nshow the number of states and transitions at the level of P. The fourth column shows the number of states \nexplored by the explored (taking into account values of variables, state of queues, and state of ghost \nmachines modeling the environment). The .fth and sixth column give the time and space needed to complete \nthe exploration. The systematic veri.cation effort enabled by P helped us greatly .esh out corner cases \nin our design, forced us to handle every event (or explicitly defer it) in every state, and greatly contributed \nto the robustness of the shipped product. Overall, state exploration tools helped us identify and .x \nover 300 bugs, and justi.ed their continued use throughout the development cycle. A majority of the bugs \nwere due to unhandled events that we did not anticipate arriving. Other bugs were due to unexpected interactions \nbetween machines, or with the environment, which manifested in either unhandled messages or assertion \nviolations. Comparison with existing USB stack. The old USB driver in Windows has existed for several \nyears and predates P. We com\u00adpare the old USB driver and new driver in terms of functionality, performance, \nand reliability. 1. Functionality. The new USB hub driver has to deal with new USB 3.0 hardware in addition \nto all the requirements for the old driver. Therefore the new USB hub driver implements func\u00adtionality \nthat is a super set of the functionality of the old hub driver. 2. Reliability. The old USB hub driver \nhad signi.cantly more syn\u00adchronization issues in PnP, power and error recovery paths even till date. \nThe number of such issues has dropped dramatically in the new USB hub driver. The number of crashes in \nthe new USB hub driver due to invalid memory accesses and race conditions is insigni.cant. 3. Performance. \nThe new USB hub driver performs much better than the old USB hub driver average enumeration time for \na USB device is 30% faster. We have not seen any instances of worker item starvation that we used to \nsee with the old hub driver.  This gain in performance is mainly due to the highly asyn\u00adchronous nature \nof the new hub driver. In comparison, the old hub driver blocks processing of worker items in several \nsituations, lead\u00ading to performance degradation. It is theoretically possible to de\u00advelop a driver that \nis not based on explicit state machines such as in P, but is equally (or more) performant. However, in \npractice, when we have tried to build such asynchronous drivers directly, we have run into myriad of \nsynchronization issues and unacceptable degradation in reliability. The support for asynchrony in P in \nterms of explicitly documented states and transitions, and the veri.cation tools in P that systematically \nidenti.ed corner cases due to asyn\u00adchrony were the key reasons why we were able to design the new USB \nhub driver with both high performance and high reliability. We note that the new USB hub driver has \nonly been released to the public for about a month at the time of this writing. Once we get more empirical \ndata from usage of USB by Windows 8 users, we can make a more thorough comparison on actual number of \ncrashes and hangs with the old driver. 7. Related work Synchronous languages. Synchronous languages such \nas Esterel [4], Lustre [10] and Signal [3] have been used to model, and gener\u00adate code for real-time \nand embedded systems for several decades. All these languages follow the synchrony hypothesis, where \ntime advances in steps, and concurrency is deterministic that is, given a state and an input at the current \ntime step, there is a unique pos\u00adsible state at the next time step. Lustre and Signal follow a declar\u00adative \ndata.ow model. Every variable or expression in Lustre rep\u00adresents a .ow which is a sequence of values. \nFor a .ow x, Lus\u00adtre uses pre(x) do denote a .ow with values postponed by one time step. A Lustre program \n[10] is a set of de.nitions of .ows, where each .ow is de.ned using some constant .ows or other .ows. \nEven though .ows can be recursively de.ned, each recur\u00adsive cycle should be broken using the pre operator. \nIn contrast, Esterel is an imperative language [4] where a program consists of a collection of nested \nconcurrently running threads, and each step is triggered by an external event, and threads are scheduled \nuntil all internally generated events are consumed. The Esterel compiler en\u00adsures a property called constructive \ncausality, which guarantees ab\u00adsence of cyclical dependencies in propagating events, and ensures that \neach step terminates. Harel s StateCharts [11] is a visual lan\u00adguage, with hierarchical states, broadcast \ncommunication of events and a synchronous .xpoint semantics which involves executing a series of micro-steps \nwithin each time step until all internally gen\u00aderated events are consumed. The synchronous model has \nthe advantage that every event sent to machine is handled in the next clock tick, and is widely used \nin hardware and embedded systems. However, in an OS or a distributed system, it is impossible to have \nall the components of the system clocked using a global clock, and hence asynchronous models are used \nfor these systems. In such models events are queued, and hence can be delayed arbitrarily before being \nhandled. However, arbitrary delays are unacceptable in OS components such as device drivers, which require \nresponsiveness in event handling. The main focus of our work is an asynchronous model where responsiveness \nis enforced using veri.cation, with the ability do code generation. Asynchronous languages. Asynchronous \nlanguages are used to model and program software systems. The adaptation of State-Charts in the Rhapsody \ntool has produced a variant, which is suitable for modeling asynchronous software systems. This vari\u00adant \n(see [12]) allows steps that take non-zero time and resembles a collection of communicating and interacting \nstate machines, where each machine has a named input queue, and each transition of a ma\u00adchine consumes \na message from its input queue and possibly sends messages to the output queues of one or more machines. \nOther asynchronous models include the actor model [13] and process cal\u00adculi, such as CSP [14] and CCS \n[16], and Join Calculus [8], which have asynchronous processes communicating with each other via messages. \nWhile these models are useful in modeling and reason\u00ading about asynchronous systems, our goal is to unify \nmodeling and veri.cation with programming, and generate code that can run in an OS kernel. Domain-speci.c \nlanguages. The Teapot [5] programming lan\u00adguage shares similar goals to our work in that they attempt \nto unify modeling, programming and veri.cation, although in a different ap\u00adplication domain cache coherence \nprotocols. Teapot s continu\u00adation passing design is related to the design of P s call transitions. The \nnotion of deferred sets, ghost machines and erasure property, default safety and liveness checks, delay \nbounding, and the ability of the P compiler and runtime to generate code that runs in an OS kernel are \nall unique to P. Automatic stack management. There have been attempts to pro\u00advide automatic stack management \nfor event-driven programming to allow the possibility of blocking constructs inside procedure calls (e.g., \n[1]). In P, entry functions of states are written in non-blocking style and call transitions are provided \nto conveniently factor com\u00admon event handling code. Thus, stack management is particularly simple in \nour current design. 8. Conclusion We presented P, a domain speci.c language for writing asyn\u00adchronous \nevent-driven programs. We have given a full formal treat\u00adment of various aspects of P, including operational \nsemantics, type system, and veri.er. We also presented experience using P to pro\u00adgram the USB stack that \nships with Windows 8. The main technical contribution of our work is an asynchronous model which forces \neach event in the queue to be handled as soon as the machine asso\u00adciated with the queue is scheduled, \nand has a chance to dequeue the event. Our veri.er systematically explores the state space of ma\u00adchines \nand ensures that there are no unhandled events. In certain circumstances, such as processing a high priority \nevent, or process\u00ading a sequence of event exchanges during a transaction, some other lower priority events \nmay have to be queued temporarily. P has fea\u00adtures such as deferred events for a programmer to explicitly \nspecify such deferrals. Thus, our main contribution is the design of an asyn\u00adchronous language, which \npromotes a discipline of programming where deferrals need to be declared explicitly, and consequently \nleads to responsive systems. Acknowledgments We would like to acknowledge the contribution of Randy Aull, \narchitect of the USB device driver stack in Windows 8, to the design of P. We would also like to thank \nhim for his enthusiastic adoption of the P programming model. Damien Zufferey would like to acknowledge \nthe support of the Austrian Science Fund NFN RiSE (Rigorous Systems Engineering) and the ERC Advanced \nGrant QUAREM (Quantitative Reactive Modeling). References [1] A. Adya, J. Howell, M. Theimer, W. J. \nBolosky, and J. R. Douceur. Cooperative task management without manual stack management. In USENIX Annual \nTechnical Conference, General Track, pages 289 302, 2002. [2] T. Andrews, S. Qadeer, S. K. Rajamani, \nJ. Rehof, and Y. Xie. Zing: A model checker for concurrent software. In CAV: International Conference \non Computer Aided Veri.cation, pages 484 487, 2004. [3] A. Benveniste, P. L. Guernic, and C. Jacquemot. \nSynchronous pro\u00adgramming with events and relations: the Signal language and its se\u00admantics. Sci. Comput. \nProgram., 16(2):103 149, 1991. [4] G. Berry and G. Gonthier. The Esterel synchronous programming language: \ndesign, semantics, implementation. Sci. Comput. Program., 19(2):87 152, Nov. 1992. [5] S. Chandra, B. \nRichards, and J. R. Larus. Teapot: A domain-speci.c language for writing cache coherence protocols. IEEE \nTrans. Software Eng., 25(3):317 333, 1999. [6] M. Emmi, S. Qadeer, and Z. Rakamaric. Delay-bounded scheduling. \nIn POPL: ACM SIGPLAN-SIGACT Symposium on Principles of Pro\u00adgramming Languages, pages 411 422, 2011. [7] \nC. Flanagan and S. Qadeer. A type and effect system for atomicity. In PLDI: ACM SIGPLAN Conference on \nProgramming Language Design and Implementation, pages 338 349, 2003. [8] C. Fournet and G. Gonthier. \nThe re.exive CHAM and the join\u00adcalculus. In H.-J. Boehm and G. L. S. Jr., editors, POPL, pages 372 385. \nACM Press, 1996. [9] P. Godefroid. Model checking for programming languages using Verisoft. In POPL: \n24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 174 186, 1997. [10] N. \nHalbwachs, P. Caspi, P. Raymond, and D. Pilaud. The synchronous data.ow programming language Lustre. \nProceedings of the IEEE, 79(9):1305 1320, September 1991. [11] D. Harel. Statecharts: A visual formalism \nfor complex systems. Sci. Comput. Program., 8(3):231 274, 1987. [12] D. Harel and H. Kugler. The Rhapsody \nsemantics of Statecharts (or, on the executable core of the UML) -preliminary version. In H. Ehrig, W. \nDamm, J. Desel, M. Gro\u00dfe-Rhode, W. Reif, E. Schnieder, and E. Westk \u00a8amper, editors, SoftSpez Final Report, \nvolume 3147 of Lecture Notes in Computer Science, pages 325 354. Springer, 2004. [13] C. Hewitt, P. \nBishop, and R. Steiger. A universal modular actor formal\u00adism for arti.cial intelligence. In Proceedings \nof the 3rd international joint conference on Arti.cial intelligence, IJCAI 73, pages 235 245, San Francisco, \nCA, USA, 1973. Morgan Kaufmann Publishers Inc. [14] C. A. R. Hoare. Communicating sequential processes. \nCommun. ACM, 21(8):666 677, 1978. [15] R. J. Lipton. Reduction: a new method of proving properties of \nsystems of processes. In POPL: ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages \n78 86, 1975. [16] R. Milner. A Calculus of Communicating Systems, volume 92 of Lecture Notes in Computer \nScience. Springer, 1980. [17] M. Musuvathi, S. Qadeer, T. Ball, G. Basler, P. A. Nainar, and I. Neamtiu. \nFinding and reproducing Heisenbugs in concurrent pro\u00adgrams. In OSDI : USENIX Symposium on Operating Systems \nDesign and Implementation, pages 267 280, 2008. [18] A. Pnueli. The temporal logic of programs. In FOCS: \nIEEE Sympo\u00adsium on Foundations of Computer Science, pages 46 67, 1977. [19] S. Russell and P. Norvig. \nArti.cial Intelligence: A Modern Approach (3rd edition). Prentice Hall, 2009.  \n\t\t\t", "proc_id": "2491956", "abstract": "<p>We describe the design and implementation of P, a domain-specific language to write asynchronous event driven code. P allows the programmer to specify the system as a collection of interacting state machines, which communicate with each other using events. P unifies modeling and programming into one activity for the programmer. Not only can a P program be compiled into executable code, but it can also be tested using model checking techniques. P allows the programmer to specify the environment, used to \"close\" the system during testing, as nondeterministic ghost machines. Ghost machines are erased during compilation to executable code; a type system ensures that the erasure is semantics preserving.</p> <p>The P language is designed so that a P program can be checked for responsiveness---the ability to handle every event in a timely manner. By default, a machine needs to handle every event that arrives in every state. But handling every event in every state is impractical. The language provides a notion of deferred events where the programmer can annotate when she wants to delay processing an event. The default safety checker looks for presence of unhandled events. The language also provides default liveness checks that an event cannot be potentially deferred forever.</p> <p>P was used to implement and verify the core of the USB device driver stack that ships with Microsoft Windows 8. The resulting driver is more reliable and performs better than its prior incarnation (which did not use P); we have more confidence in the robustness of its design due to the language abstractions and verification provided by P.</p>", "authors": [{"name": "Ankush Desai", "author_profile_id": "81488650423", "affiliation": "Microsoft Corporation, Bangalore, India", "person_id": "P4149039", "email_address": "t-ankusd@microsoft.com", "orcid_id": ""}, {"name": "Vivek Gupta", "author_profile_id": "81758992457", "affiliation": "Microsoft Corporation, Redmond, WA, USA", "person_id": "P4149040", "email_address": "vivekg@microsoft.com", "orcid_id": ""}, {"name": "Ethan Jackson", "author_profile_id": "81100096068", "affiliation": "Microsoft Corporation, Redmond, WA, USA", "person_id": "P4149041", "email_address": "ejackson@microsoft.com", "orcid_id": ""}, {"name": "Shaz Qadeer", "author_profile_id": "81100286660", "affiliation": "Microsoft Corporation, Redmond, WA, USA", "person_id": "P4149042", "email_address": "qadeer@microsoft.com", "orcid_id": ""}, {"name": "Sriram Rajamani", "author_profile_id": "81100468626", "affiliation": "Microsoft Corporation, Bangalore, India", "person_id": "P4149043", "email_address": "sriram@microsoft.com", "orcid_id": ""}, {"name": "Damien Zufferey", "author_profile_id": "81467658702", "affiliation": "IST Austria, Klosterneuburg, Austria", "person_id": "P4149044", "email_address": "zufferey@ist.ac.at", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462184", "year": "2013", "article_id": "2462184", "conference": "PLDI", "title": "P: safe asynchronous event-driven programming", "url": "http://dl.acm.org/citation.cfm?id=2462184"}