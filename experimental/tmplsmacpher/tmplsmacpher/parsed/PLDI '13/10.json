{"article_publication_date": "06-16-2013", "fulltext": "\n Terra: A Multi-Stage Language for High-Performance Computing Zachary DeVito James Hegarty Alex Aiken \nPat Hanrahan Jan Vitek Stanford University Purdue University (zdevito|jhegarty|aiken|hanrahan)@cs.stanford.edu \njv@cs.purdue.edu Abstract High-performance computing applications, such as auto-tuners and domain-speci.c \nlanguages, rely on generative programming tech\u00adniques to achieve high performance and portability. However, \nthese systems are often implemented in multiple disparate languages and perform code generation in a \nseparate process from program execu\u00adtion, making certain optimizations dif.cult to engineer. We lever\u00adage \na popular scripting language, Lua, to stage the execution of a novel low-level language, Terra. Users \ncan implement optimiza\u00adtions in the high-level language, and use built-in constructs to gen\u00aderate and \nexecute high-performance Terra code. To simplify meta\u00adprogramming, Lua and Terra share the same lexical \nenvironment, but, to ensure performance, Terra code can execute independently of Lua s runtime. We evaluate \nour design by reimplementing exist\u00ading multi-language systems entirely in Terra. Our Terra-based auto\u00adtuner \nfor BLAS routines performs within 20% of ATLAS, and our DSL for stencil computations runs 2.3x faster \nthan hand-written C. Categories and Subject Descriptors D.3.4 [Programming Lan\u00adguages]: Processors Code \nGeneration, Compilers General Terms Design, Performance Keywords Lua, Staged computation, DSL 1. Introduction \nThere is an increasing demand for high-performance power-ef.cient applications on devices ranging from \nphones to supercomput\u00aders. Programming these applications is challenging. For optimum performance, applications \nneed to be tailored to the features of the target architecture, e.g., multi-core, vector instructions, \nand throughput-oriented processors such as GPUs. Applications have turned to generative programming to \nadapt to complex hardware. Auto-tuners like SPIRAL [23], ATLAS [33], or FFTW [12] can express a range \nof implementations for speci.c applications such as FFTs, and choose the best optimizations for a given \narchitecture. In areas such as machine learning [4], or physical simulation [9], domain-speci.c languages \n(DSLs) can achieve the same goal for a range of similar applications through domain-speci.c optimiza\u00adtions. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n13, June 16 19, 2013, Seattle, WA, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . \n$15.00 However, high-performance applications that rely on code gen\u00aderation are often implemented as \nad hoc source-to-source trans\u00adlators. For instance, consider FFTW which implements its genfft compiler \nin OCaml and emits C code [12], or Liszt, a DSL which uses Scala for its transformations and generates \ncode that links against a runtime written in C [9]. While these designs produce high-performance code, \nthey are hard to engineer. A DSL or auto-tuner typically has three compo\u00adnents: an optimizer that performs \ndomain-speci.c transformations to generate a plan of execution, a compiler that generates high\u00adperformance \ncode based on the plan, and a runtime that supports the generated code and provides feedback to the optimizer. \nIf, as in FFTW and Liszt, the optimizer and compiler are separate from the runtime, it is dif.cult to \nfeed runtime statistics back to the com\u00adpiler to perform problem-speci.c optimizations. Transformations \nalso require careful engineering to separate compile-time and run\u00adtime optimizations, making it dif.cult \nto prototype new optimiza\u00adtions. Ideally, it should be easy for domain experts to experiment with domain \nand problem-speci.c transformations, generate high\u00adperformance code dynamically, and provide runtime \nfeedback to improve performance. Furthermore, all parts of the toolchain, com\u00adpiler, generated code, \nand runtimes, should inter-operate amongst themselves and with legacy high-performance libraries. Achieving \nthese goals in a single system is complicated by the fact that each component has different design constraints. \nIt is easier to prototype compiler transformations in an expressive high-level language, but achieving \nhigh performance in the generated code and runtime re\u00adquires .ne-grained control over execution and memory \nresources, which is easier in a low-level language. To address these problems, we use multi-stage programming \n[30] to couple an existing high-level language, Lua, with a new low\u00adlevel language, Terra. Lua is a high-level \ndynamically-typed lan\u00adguage with automatic memory management and .rst-class func\u00adtions [14]. Terra, on \nthe other hand, is a statically-typed language similar to C with manual memory management. Terra code \nis em\u00adbedded in Lua. Using multi-stage programming, programmers can generate and execute Terra code dynamically \nfrom Lua. This two-language design allows domain experts to experiment with high-level transformations \nusing Lua, while still generating high-performance code using Terra. To simplify code generation, the \nevaluation of Lua and the generation of Terra code share the same lexical environment and variable references \nare hygienic across the two languages. To ensure .ne-grained control of exe\u00adcution, Terra executes in \na separate environment: Terra code runs independently of the Lua runtime. It can run in a different thread, \nor (in the future) on accelerators like GPUs. This separation ensures that the high-level features of \nLua do not creep into the execution of Terra. Furthermore, Terra exposes the low-level features of mod\u00adern \nhardware such as vector instructions. Finally, we leverage the fact that Lua was speci.cally designed \nto be embedded in low-level languages such as C [15]. Lua s stack-based C API makes it easy to interface \nwith legacy code, while a built-in foreign-function in\u00adterface [1] makes it possible to pass values between \nLua and Terra. Furthermore, we provide support for type re.ection on Terra types that enables the creation \nof new types via meta-programming. This design keeps the Terra language simple while still allowing the \ncreation of libraries to implement higher-level components such as class systems that can be used in \nhigh-performance runtimes. This paper makes the following contributions: We present the design of Terra \nwhich uniquely combines the staging of a low-level language using a high-level one, shared lexical scoping, \nseparate evaluation, and type re.ection.1  We provide a formal semantics of core Terra to elucidate \nthe interaction between Terra and Lua, focusing on how staging operates in the presence of side effects \nin Lua.  We show that we can reimplement a number of existing multi\u00adlanguage systems entirely in Terra, \nbut still achieve similar per\u00adformance. In particular, we show an auto-tuner for matrix mul\u00adtiply that \nperforms within 20% of ATLAS, but uses fewer than 200 lines of Terra code, and we present a stencil computation \nlanguage that performs 2.3x faster than hand-written C. Finally, we implement a class system and container \nwith parameteriz\u00adable data layout as JIT-compilable Terra libraries, which would be dif.cult to engineer \nin existing languages.  2. Writing Multi-stage Code in Terra We use an example image-processing algorithm \nto introduce Terra. At the top-level, a program executes as Lua, augmented with con\u00adstructs to create \nTerra functions, types, variables, and expressions. The terra keyword introduces a new Terra function \n(Lua functions are introduced with function): terra min(a: int, b: int) : int if a < b then return a \n else return b end end Terra functions are lexically-scoped and statically-typed, with pa\u00adrameters \nand return types explicitly annotated. In contrast, Lua has no type annotations. Terra is also backwards-compatible \nwith C: std = terralib.includec(\"stdlib.h\") The Lua function includec imports the C functions from stdlib.h. \nIt creates a Lua table, an associative map. It then .lls the table with Terra functions that invoke the \ncorresponding C functions found in stdlib.h. In Lua, the expression table.key is syntax sugar for table[\"key\"]. \nSo, for example, std.malloc is C s malloc. Terra entities (functions, types, variables and expressions) \nare .rst-class Lua values. For example, the follow statement constructs a Terra type that holds a square \ngreyscale image: struct GreyscaleImage { data : &#38;float; N : int; } GreyscaleImage is a Lua variable \nwhose value is a Terra type. Terra s types are similar to C s. They include standard base types, arrays, \npointers, and nominally-typed structs. Here data is a pointer to floats, while GreyscaleImage is a type \nthat was created by the struct constructor. We might want to parameterize the image type based on the \ntype stored at each pixel (e.g., an RGB triplet, or a greyscale value). 1Our implementation and additional \nexamples are available at github.com/zdevito/terra  We can de.ne a Lua function Image that creates the \ndesired Terra type at runtime. This is conceptually similar to a C++ template: function Image(PixelType) \nstruct ImageImpl { data : &#38;PixelType,  N : int 5 } --method definitions for the image: terra ImageImpl:init(N: \nint): {} --returns nothing self.data = [&#38;PixelType](std.malloc(N*N*sizeof(PixelType)))  10 self.N \n= N end terra ImageImpl:get(x: int, y: int) : PixelType return self.data[x*self.N + y] end 15 --omitted \nmethods for: set, save, load, free return ImageImpl end In addition to its layout declared on lines \n2 5, each struct can have a set of methods (lines 6 15). Methods are normal Terra functions stored in \na Lua table associated with each type (e.g., ImageImpl.methods). The method declaration syntax is sugar \nfor: ImageImpl.methods.init = terra(self : &#38;ImageImpl, N : int) : {} ... end  Method invocations \n(myimage:init(128)) are also just syntactic sugar (ImageImpl.methods.init(myimage,128)). In the init \nfunc\u00adtion, we call std.malloc to allocate memory for our image. Since std is a Lua table, Terra will \nevaluate the table select operator (std.malloc) during compilation and resolve it to the malloc func\u00adtion. \nWe also de.ne a get function to retrieve each pixel, as well as some utility functions which we omit \nfor brevity. Outside of the Image function, we call Image(float) to de.ne GreyscaleImage. We use it to \nde.ne a laplace function and a driver function runlaplace that will run it on an image loaded from disk \nto calculate the Laplacian of the image: GreyscaleImage = Image(float) terra laplace(img: &#38;GreyscaleImage, \nout: &#38;GreyscaleImage) : {} --shrink result, do not calculate boundaries  5 var newN = img.N -2 \nout:init(newN) for i = 0,newN do for j = 0,newN do var v = img:get(i+0,j+1) + img:get(i+2,j+1) 10 + \nimg:get(i+1,j+2) + img:get(i+1,j+0) -4 * img:get(i+1,j+1) out:set(i,j,v) end end 15 end terra runlaplace(input: \nrawstring, output: rawstring) : {} var i = GreyscaleImage {} var o = GreyscaleImage {}  20 i:load(input) \nlaplace(&#38;i,&#38;o) o:save(output) i:free(); o:free() end  To actually execute this Terra function, \nwe can call it from Lua: runlaplace(\"myinput.bmp\",\"myoutput.bmp\")  Invoking the function from Lua will \ncause the runlaplace function to be JIT compiled. A foreign function interface converts the Lua string \ntype into a raw character array rawstring used in Terra code. Alternatively, we can save the Terra function \nto a .o .le which can be linked to a normal C executable: terralib.saveobj(\"runlaplace.o\", {runlaplace \n= runlaplace}) We may want to optimize the laplace function by blocking the loop nests to make the memory \naccesses more friendly to cache. We could write this optimization manually, but the sizes and numbers \nof levels of cache can vary across machines, so maintaining a multi-level blocked loop can be tedious. \nInstead, we can create a are created, compiled, and called during the evaluation of a Lua program and \nin the presence of side-effects. We will use this for\u00admalism in Section 4.1 to illustrate key design \ndecisions in Terra. The calculus, called Terra Core, is equipped with a big step op- L erational semantics. \nEvaluation starts in Lua ( -. ). When a Terra S term is encountered it is specialized ( -. ), a process \nanalogous to macro expansion in LISP that evaluates any escapes in the term to produce concrete Terra \nterms. Specialized Terra functions can then T be executed ( -. ). We distinguish between Lua expressions \ne, . . e, and specialized Terra expressions e (we use Lua function, blockedloop, to generate the Terra \ncode for the loop Terra expressions nests with a parameterizable number of block sizes. In laplace, \nwe can replace the loop nests (lines 7 12) with a call to blockedloop that generates Terra code for a \n2-level blocking scheme with outer blocks of size 128 and inner blocks of size 64: [blockedloop(newN,{128,64,1}, \nfunction(i,j) return quote var v = img:get(i+0,j+1) + img:get(i+2,j+1) + img:get(i+1,j+2) + img:get(i+1,j+0) \n 5 -4 * img:get(i+1,j+1) a dot to distinguish Terra terms from Lua terms, and a bar to in\u00addicate a Terra \nterm is specialized). For simplicity we model Lua as an imperative language with .rst-class functions \nand Terra as a purely functional language. A namespace G maps variables (x)to addresses a, and a store \nS maps addresses to Lua values v. The namespace G serves as the value environment of Lua (resolving variables \nto values, v), and the syntactic environment of Terra spe\u00ad .  cialization (resolving variables to specialized \nTerra terms e, which . are a subset of Lua values). In contrast, Terra is executed in a sepa\u00adrate environment \n( G). out:set(i,j,v) end end)] The Lua (Core) syntax is given in the following table: The brackets \n([]) around the expression are the Terra equivalent of the escape operator from multi-stage programming, \nallowing a e ::= b | T | x | let x = e in e | x := e | | e(e) | value evaluated in Lua (the code for \nthe loop nest generated by fun(x){e} | tdecl | ter e(x : e): e { . e } | '. e blockedloop) to be spliced \ninto the Terra expression. The third .. argument to blockedloop is a Lua function that is called to create \nv ::= b | l | T | (G, x, e) |e the inner body of the loop. Its arguments (i,j)are the loop indices. . \nT ::= . B | . T . . T The quote expression creates a quotation, a block of Terra code that can be spliced \ninto another Terra expression. Here, we use it to create the loop body using the loop indices. A Lua \nexpression can be a base value (b), a Terra type expression . T), a variable (x), a scoped variable de.nition \n(let x = e in e),( . The implementation of blockedloop walks through the list of an assignment (x := \ne), a function call . e(e), a Lua function e). We separate decla\u00adblocksizes. It uses a quote to create \na level of loop nests for each (fun(x){e}), or a quoted Terra expression ('entry and recursively creates \nthe next level using an escape. At the ration and de.nition of Terra functions to allow for recursive \nfunc\u00ad inner-most level, it calls bodyfn to generate the loop body: tions. A Terra function declaration \n(tdecl)creates a new address for a Terra function, while a Terra de.nition (ter e1 (x : e2 ) : function \nblockedloop(N,blocksizes,bodyfn) . local function generatelevel(n,ii,jj,bb) if n > #blocksizes then \nreturn bodyfn(ii,jj)  5 end local blocksize = blocksizes[n] return quote for i = ii,min(ii+bb,N),blocksize \ndo for j = jj,min(jj+bb,N),blocksize do 10 [ generatelevel(n+1,i,j,blocksize) ] end end . e3 { e }) \n.lls in the declaration at address e1 . For example, the following declares and de.nes a Terra function, \nstoring it in x: let x = ter tdecl(x2 : int): int { x2 } in x Alternatively, tdecl creates just a declaration \nthat can be de.ned later: let x = tdecl in ter x(x2 : int): int { x2 } In real Terra code, a Terra de.nition \nwill create a declaration if it does not already exist. Lua values range over base types (b), addresses \nof Terra functions (l), Terra types (T), Lua closures end  ((G, x, e)) and specialized Terra expressions \n( . e). The syntax of end  return generatelevel(1,0,0,N) Terra terms is de.ned as follows: end Amore \ngeneral version of this function is used to implement multi\u00adlevel blocking for our matrix multiply example. \n .. . . . e ::= b | x | e(e) | tlet x : e = e in e | [e] A Terra expression is either a base type, a \nvariable, a function This example highlights some important features of Terra. We application, a let \nstatement, or a Lua escape (written [e]). The provide syntax sugar for common patterns in runtime code \nsuch as syntax of specialized terms is given next: namespaces (std.malloc)or method invocation (out:init(newN)). \nFurthermore, during the generation of Terra functions, both Lua and Terra share the same lexical environment. \nFor example, the loop nests refer to blocksize, a Lua number, while the Lua code that calls generatelevel \nrefers to i and j, Terra variables. Values .... . .. . e ::= b | x | e(e) | tlet x : T = e in e | l \n In contrast to an unspecialized term, a specialized Terra term does from Lua such as blocksize will \nbe specialized in the staged code not contain escape expressions, but can contain Terra function as constants, \nwhile Terra variables that appear in Lua code such as i addresses (l). The let statement must assign \nTerra types to the will behave as variable references once placed in a Terra quotation. bound variable \nand variables are replaced with specialized Terra . variables x. 3. Terra Core L The judgment e S1 \n-. v S2 describes the evaluation of To make the interaction between Lua and Terra precise, we formal-a \nLua expression. It operates over an environment S consisting ize the essence of both languages focusing \non how Terra functions of G, S, and a Terra function store F which maps addresses (l) S = G, S, F S \n(SBAS) L b S -. b S (LVAR) S (LVAL) v S -. v L x S -. S(G(x)) S S -. S -. . . . . S1 S2 e2 S2 2 S3 \ne1 e e 1 (SAPP) S -. . . e 1 (e) S3 2 LL -. -. . . e1 (e2 ) S1 e1 S1 S2 S2 = G, S, F e2 S2 [x . \nv1 ] v2 S3 v1 L let x = e1 in e2 S -. v2 (S3 . G) L -. . . S -. . . e 1 S3 x fresh S1 S2 e1 S2 T \n e (LLET) S -. . . . S3 = G, S, F e2 S3 [x . x] S4 e 2 . S1 S -. . . . . . L 2 (S4 . G) tlet \nx : e = e1 in e2 tlet x : T = ein 1 e S -. v G, S, F G(x) = a e (LASN) (SLET) L x := e S -. v G, S \n[a . v], F e S1 L -. S -. . . S2 [x] S1 S2 e e (SESC) (SVAR) S =G, S, F S -. S -. . . [e] S1 \nS2 x S1 S2 (LFUN) e e L fun(x){e} S -. (G, x, e) S S Figure 2. The rules -. for specializing Terra \nexpressions. L L e1 S1 -. (G1 , x, e3 ) S2 e2 S2 -. v1 G2 , S, F . . T -. b T -. (TBAS) (TFUN) G, \nF G, F l l b L a fresh e3 G1 [x . a], S [a . v1 ], F -. v2 S3 (LAPP) L -. . . T -. . . e1 (e2 ) \nS1 (S3 . G2 ) (TVAR) G, F G( x) v2 x l fresh S = G, S, F . . T -. T -. . . . G, F G[ x . v1 ], \nF (LTDECL) e v1 ev2 1 2 (TLET) L tdecl S -. l G, S, F [l . ] .. . .. T -. G, F tlet x : T = ein ev2 \n1 2 L L . L . S1 -. l S2 e2 S2 -. T1 S3 e3 S3 -. T2 S4 . . T -. T -. e1 . . G, F G, F l . e e \n v1 1 2 S4 = G1 , S1 , F1 x fresh . .. ... . T -. F (l)= (x, T1 , T2 , e) eG[ x . v1 ], F 3 3 S -. . \n. e S4 [x . x] . v2 G2 , S2 , F2 F2 (l)= e (TAPP) . .. T -. v2 e 1 (e) G, F 2 . . L -. . . x, \n. e1 (x : e2 ): e3 { e } S1 G1 , S2 , F2 [l . ( e)] l T1 , T2 , ter (LTDEFN) T Figure 3. The rules \n-. for evaluating Terra expressions. S S1 -. . e . S2 e (LTQUOTE) F (l) . = T L . . ' e S1 -. \ne S2 (TYFUN1) .  G, F , F . l : T L L S1 -. l S2 e2 S2 -. b1 S3 . ... F (l)= (x, T1 , T2 , e) [x : \nT1 ], .. .. l .. F F [l : e1 . T2 ], F . e : T2T1 . ... . S3 = G, S, F F (l)= (x, T1 , T2 , e) b1 . \nT1 G, F , F . l : . . T1 . T2 .. .. . . .. T -. [x : T1 ], [l : T1 . T2 ], F2 . e : T2 e [x . b], F \nb2 (TYFUN2) e1 (e2 ) S1 L-. b2 S3 (LTAPP) Figure 4. Typing rules for references to Terra functions. \nFigure 1. The rules L-. for evaluating Lua expressions. Rule LTA PP describes how to call a Terra function \nfrom Lua. The actual parameter e2 is evaluated. The Terra function is then typechecked. Semantically, \ntypechecking occurs every time a func\u00ad . . . . to Terra functions. Terra functions can be de.ned ((x, \nT, T, e)), or tion is run. In practice, we cache the result of typechecking. For unde.ned ( ). Figure \n1 de.nes the Lua evaluation rules. We use simplicity, Terra Core only allows values b of base types to \nbe two notational shortcuts: passed and returned from Terra functions (full Terra is less re\u00ad stricted). \nS1 [x . v]= G2 , S2 , F when S1 = G1 , S1 , F . G2 = G1 [x . a]. S S1 -. . . S2 for specializ-Figure \n2 de.nes judgment e e S2 = S1 [a . v]. a fresh ing Terra code, which evaluates all embedded Lua expressions \nin S . G1 = G1 , S, F when S = G2 , S, F type annotations and escape expressions. Similar to LTD EFN, \nrule . SLET generates a unique name x to ensure hygiene. Rule SESC Rule LTD ECL creates a new Terra \nfunction at address l and ini\u00ad evaluates escaped Lua code; it splices the result into the Terra ex\u00ad \ntializes it as unde.ned ( ). Rule LTDEFN takes an unde.ned Terra pression if the resulting value is \nin the subset of values that are function (e1 ) and initializes it. First, and are evaluated as e2 e3 \n . . . . Terra terms e (e.g., a variable x or base value b). Variables in Terra Lua expressions to produce \nthe type of the function, T1 . T2 . The can refer to variables de.ned in Lua and in Terra; they behave \nas . body, e, is specialized. During specialization, Terra variables (x) if they are escaped, as de.ned \nby Rule SVAR. If x is a variable de\u00ad . . are renamed to new symbols ( x)to ensure hygiene. Renaming \nhas .ned in Terra code and renamed x during specialization, then rule . been previously applied in \nstaged-programming [30] and hygienic SVAR will just produce x (assuming no interleaving mutation of x). \n .. macro expansion [2]. In the case of LTDEFN, we generate a fresh . name x for the formal parameter \nx, and place it in the environment. Figure 3 presents the judgment e G, F T -. v for evaluating . \nVariable x will be bound to the value x in the scope of any Lua code specialized Terra expressions. \nThese expressions can be evaluated . evaluated during specialization of the function. During specializa-independently \nfrom the Lua store S, and do not modify F , but are tion, Rule SVAR will replace uses of x in Terra code \nwith the value otherwise is typechecked right straightforward. A Terra function  of x in the environment. \nbefore it is run (LTAPP) with the judgment G, F , F . . e : T,  where G is the typing environment \nfor variables and F is the typing environment for Terra function references (F is the Terra function \nstore from before). The rules (omitted for brevity) are standard, except for the handling of Terra function \nreferences l. If a Terra function l1 refers to another Terra function l2 , then l2 must be typechecked \nwhen typechecking l1 . The rules for handling these references in the presence of mutually recursive \nfunctions are shown in Figure 4. They ensure all functions that are in the connected component of a function \nare typechecked before the function is run. 4. Key Design Decisions We want to make it easier to prototype \ndomain-and problem\u00adspeci.c transformations, dynamically compile the results of the transformations into \nhigh-performance code, and support this code with high-performance runtime libraries. We highlight some \nim\u00adportant design decisions in the semantics of Terra Core that make these goals possible. We then present \nengineering decisions that also address these issues. 4.1 Language Design Hygienic staged programming \nwith a shared lexical environment. The combination of staged programming, shared lexical environ\u00adment, \nand hygiene provides several bene.ts. The staged program\u00adming of Terra from Lua provides interoperability \nbetween com\u00adpiler, generated code, and runtime of a DSL. DSL compilers written in Lua can generate arbitrary \ncode using a combination of quota\u00adtions, escapes, and terra de.nitions. The shared lexical environ\u00adment \nmakes it possible to organize Terra functions in the Lua en\u00advironment, and refer to them directly from \nTerra code without ex\u00adplicit escape expressions. To further reduce the need for escape ex\u00adpressions, \nwe also treat lookups into nested Lua tables of the form x.id1 .id2 ...idn (where id1 ...idn are valid \nentries in nested Lua ta\u00adbles) as if they were escaped. This syntactic sugar allows Terra code to refer \nto functions organized into Lua tables (e.g., std.malloc), removing the need for an explicit namespace \nmechanism in Terra. Finally, maintaining hygiene during staging ensures that it is al\u00adways possible to \ndetermine the relationship between variables and their declarations (across both Lua and Terra) using \nonly the local lexical scope. Terra Core illustrates how we provide a shared lexical environ\u00adment and \nhygiene. The evaluation of Lua code and the specializa\u00adtion of Terra code share the same lexical environment \nG and store S. This environment and store always map variables x to Lua values . v. Terra syntax e is \none type of Lua value. This example illustrates the shared environment: let x1 = 0in ' let x2 = (tlet \ny1 : int = 1in x1 )in let x3 = ter tdecl(y2 : int): int { x2 } in x3 The specialization of the quoted \ntlet expression occurs in the surrounding Lua environment, so Rule SVAR will evaluate x1 to 0. This results \nin the specialized expression: . tlet y: int = 1in 0 1 This Terra expression will be stored as a Lua \nvalue in x2 . Since the Terra function refers to x2 , specialization will result in the following Terra \nfunction: . . (y, int, int, tlet y: int = 1in 0) 2 1 Furthermore, during specialization variables introduced \nby Terra functions and Terra let expressions are bound in the shared lexical environment. Consider this \nexample: let x1 = fun(x2 ){ ' tlet y : int = 0in [x2 ]} in let x3 = ter tdecl(y : int): int { [x1 (y)] \n} in x3 The variable y on line 2 is introduced by the Terra function def\u00adinition. It is referenced by \nthe Lua expression inside the escape ([x1 (y)]). The variable y is then passed as an argument to Lua \nfunc\u00adtion x1 , where it is spliced into a tlet expression. When Terra variables are introduced into the \nenvironment, they are given fresh names to ensure hygiene. For example, without renaming, x3 would specialize \nto the following, causing the tlet expression to unintentionally capture y: (y, int, int, tlet y : int \n= 1in y) To avoid this, rules LTDEFN and SL ET generate fresh names for variables declared in Terra \nexpressions. In this case, the LTDEFN . will generate a fresh name yfor the argument y binding it into \nthe 1 . shared environment (S[y . y]), and SLET will similarly generate 1 . the fresh name yfor the \ntlet expression. Since y on line 2 has the 2 . . value yduring specialization, the variable x2 will \nget the value y, 1 1 and x3 will specialize to the following, avoiding the unintentional capture: . .. \n(y, int, int, tlet y: int = 1in y) 1 21 Eager specialization with lazy typechecking Statically-typed \nlanguages such as Terra are normally compiled ahead-of-time, re\u00adsolving symbols, typechecking, and linking \nin a separate process from execution. However, since Lua is dynamically-typed and can generate arbitrary \nTerra code, it is not possible to typecheck a com\u00adbined Lua-Terra program statically. Instead, the normal \nphases of Terra compilation become part of the evaluation of the Lua pro\u00adgram, and we must decide when \nthose phases run in relation to the Lua program. To better understand how Terra code is compiled in relation \nto Lua, consider where Terra can go wrong. While specializing Terra code, we might encounter an unde.ned \nvariable, resolve a Lua expression used in an escape to a value v that is not . also a Terra term e, \nor resolve a Lua expression used as a Terra . type to a value v that is not a Terra type T. While typechecking \nTerra code, we might encounter a type error. And, while linking Terra code, we might .nd that a Terra \nfunction refers to a declared but unde.ned function. In Terra (and re.ected in Terra Core), we perform \nspecialization eagerly (as soon as a Terra function or quo\u00adtation is de.ned), while we perform typechecking \nand linking lazily (only when a function is called, or is referred to by another function being called). \nEager specialization prevents mutations in Lua code from changing the meaning of a Terra function between \nwhen it is com\u00adpiled and when it is used. For instance, consider the following example (we use the syntax \ne;e as sugar for let = e in e): let x1 = 0in let y = ter tdecl(x2 : int): int { x1 } in x1 := 1; y(0) \n Since specialization is performed eagerly, the statement y(0) will evaluate to 0. In contrast, if specialization \nwere performed once lazily, then it would capture the value of x1 the .rst time y is called and keep \nthat value for the rest of the program, which would lead to surprising results (e.g., if y were used \nbefore x1 := 1 then it would always return 0, otherwise it would always return 1). Alternatively, we \ncould re-specialize (and hence re-compile) the function when a Lua value changes, but this behavior could \nlead to large compiler overheads that would be dif.cult to track down. Eager specialization requires \nall symbols used in a function to be de.ned before it is used, which can be problematic for mutually \nrecursive functions. In order to support recursive functions with eager specialization, we separate the \ndeclaration and de.nition of Terra functions: let x2 = tdecl in let x1 = ter tdecl(y : int): int { x2 \n(y)} in ter x2 (y : int): int { x1 (y)}; x1 (0)  Alternatively, we could have provided a form of Terra \nde.nition that allows the de.nition of multiple mutually-recursive functions at one time. However, this \napproach does not inter-operate well with generative programs such as a DSL compiler that may need to \ncreate an arbitrarily sized connected-component based on dynamic information. In contrast to specialization, \ntypechecking is performed lazily. In Terra Core, it would be possible to perform typechecking eagerly \nif declarations also had types. For instance, in our previous example we could typecheck x1 when it is \nde.ned if x2 was given a type during declaration. However, even though x1 would typecheck, we would still \nreceive a linking error if x1 (0) occurred before the de.nition of x2 . So performing typechecking eagerly \nwould not reduce the number of places an error might occur for function x1 . Furthermore, unlike specialization \nwhere the result can change arbitrarily depending on the Lua state, the result of typechecking and linking \nx can only change monotonically from a type-error to success as the functions it references are de.ned \n(it can also stay as a type-error if the function is actually ill-typed). This property follows from \nthe fact that Terra functions can be de.ned, but not re-de.ned by Rule LTD EFN. In the full Terra language, \nperforming typechecking lazily also provides several advantages. Forward declarations of functions do \nnot have to have type annotations making them easier to maintain, and user-de.ned struct types do not \nneed all their members or methods speci.ed before being used in a Terra function. In the de\u00adfault case, \nwe can keep type-checking monotonic by ensuring that members and methods can only be added to user-de.ned \ntypes and not removed. In actuality, the mechanisms for type-re.ection de\u00adscribed later in this section \nallow user-de.ned libraries to override the default behavior of a type (e.g., by adding inheritance). \nIn this case, to maintain monotonic typechecking, implementors must en\u00adsure that the functionality of \na type only grows over the execution of the program. Separate evaluation of Terra code. After Terra code \nis compiled, it can run independently from Lua. This behavior is captured in Terra Core by the fact that \nTerra expressions are evaluated inde\u00adpendently from the environment Gand the store S, as illustrated \nby this example: let x1 = 1in let y = ter tdecl(x2 : int): int { x1 } in x1 := 2; y(0) . The Terra function \nwill specialize to (x, int, int, 1), so the function call will evaluate to the value 1, despite x1 being \nre-assigned to 2. An alternative design would allow Terra evaluation to directly refer to x1 . For instance, \nin MetaOCaml [29], ref cells share the same store across different stages, allowing mutations in staged \ncode to be seen outside of the staged code. This alternative makes sharing state easier, but it would \ncouple Terra and Lua s runtimes. The re\u00adliance on the Lua runtime, which includes high-level features \nsuch as garbage collection, would make it more dif.cult to reason about the performance of Terra code. \nFurthermore, the required runtime support would make it dif.cult to port Terra to new architectures such \nas GPUs, run code in multiple threads, or link code into exist\u00ading C programs without including the Lua \nruntime. Mechanisms for type re.ection. Terra is a low-level monomor\u00adphic language. Its simplicity makes \nit easier to implement, but can make programming libraries such as DSL runtimes tedious. For instance, \na DSL writer may want to experiment with different data layouts such as array-of-structs or struct-of-arrays. \nInstead of adding this functionality to Terra, we provide a type re.ection API for creating and examining \nTerra types so this higher-level func\u00adtionality can be implemented as libraries. The basis of the API \nlies in the fact that Terra types are Lua values, as illustrated in Terra Core: let x3 = fun(x1 ){ter \ntdecl(x2 : x1 ): x1 { x2 }} in x3 (int)(1) The Lua function x3 will generate a Terra identity function \nfor any given type. Here we call it with int, which will result in the . . specialized Terra function \n(x, int, int, x). In the full language we supplement this behavior with an API to introspect and create \ntypes in Lua. Terra types include methods for introspection (e.g., t:ispointer(), or t:isstruct()) that \ncan be called from Lua. Furthermore, structs can be created programmati\u00adcally. In addition to the methods \ntable presented in Section 2, structs also contain an entries table that describes their in-memory lay\u00adout. \nHere we layout complex number type using its entries table directly: struct Complex {} Complex.entries:insert \n{ field = \"real\", type = float } Complex.entries:insert { field = \"imag\", type = float }  A struct also \ncontains a metamethods table that can override certain compile-time behaviors. For instance, we might \nwant to allow the promotion of a float to a complex number. A user-de.ned implicit conversion can be \ncreated using a Lua function __cast in the struct s metamethod table. During typechecking, when Terra \nneeds to convert one type to another and no default conversions apply, it will call the __cast metamethod \nof either type to see if it could implement the conversion (if both are successful, we favor the metamethod \nof the starting type). The following example de.nes a conversion from a float to a complex number, Complex: \nComplex.metamethods.__cast = function(fromtype,totype,exp) if fromtype == float then --valid, construct \na complex number from the float exp  return ' Complex { exp, 0.f } 5 end error(\"invalid conversion\") \nend If there is a valid conversion, the method returns a quotation that implements the conversion (the \nback-tick is a shorthand for creating single-expression quotations). Using a Lua function to determine \nthe behavior of conversions provides expressibility without the need for a more complicated mechanism. \nTo organize functions related to a particular type, we also pro\u00advide a method invocation syntax obj:my_method(arg) \nthat is desug\u00adared during typechecking to [T.methods.my_method] (obj,arg), where T is the static type \nof obj. The combination of these fea\u00adtures allows many components such as polymorphic class systems to \nbe implemented as libraries (shown later in section 6.3). 4.2 Engineering Design A high-level language \nfor prototyping. Lua provides automatic memory management, .rst-class functions, and built-in tables \nthat make it easy to manage structures like ASTs and graphs, which are frequently used in DSL transformations. \nIts dynamic typing makes it easier to prototype different data structures and to construct arbitrary \nfunctions of Terra types and expressions. A low-level language for performance. High-level programming \nlanguages can make it dif.cult to control when and what optimiza\u00adtions will take place. Auto-tuners and \nDSLs already capture the knowledge of how to generate high-performance code, so it is im\u00adportant to give \nthem as much control as reasonable to express op\u00adtimizations. We designed Terra to be a thin abstraction \nlayer on modern processors. Terra provides much the same functionality as C including manual memory management, \npointer arithmetic, and monomorphic functions. Global state, though not present in Terra Core, is possible \nin the full language using global variables created with the global function. Additionally, Terra includes \n.xed-length vectors of basic types (e.g., vector(float,4)) to re.ect the presence of SIMD units on modern \nprocessors. Since the design of Terra is close to the hardware, users can more precisely express the \nexecu\u00adtion behavior that they desire, and get predictable performance. Cross-language interoperability \nusing a foreign-function inter\u00adface. In Terra Core, Lua can only pass base values to Terra func\u00adtions \nand receive them as results. In the full language, when a Lua environment is available, we use LuaJIT \ns foreign function inter\u00adface(FFI) [1] to translate values between Lua and Terra both along function \ncall boundaries and during specialization. The similar\u00adity of Terra s type system to C s enables us to \nadapt the FFI to work with Terra. In addition to base types, it supports conversion of higher-level objects. \nFor instance, Lua tables can be converted into structs when they contain the required .elds. Lua functions \ncan also be converted into Terra functions by generating wrapper code to dynamically convert the types \non entry and exit. Since con\u00adversions are de.ned for Lua functions, calling a Lua function from Terra \ncode is just a special case of converting a Lua value into a Terra value during specialization. Backwards \ncompatible with C. We believe that the lack of inter\u00adoperability with existing code is a key factor limiting \nthe adoption of DSLs. Terra can call C functions, making it possible to use exist\u00ading high-performance \nlibraries in the implementation of runtimes, and produce code that is binary compatible with C programs. \nSince Lua is easily embedded in C programs, it is easy to incorporate a mixed Lua-Terra program into \nexisting C code. Since most lan\u00adguages have interfaces for calling C functions, this design makes it \npossible to use Terra in existing systems. 5. Implementation Terra expressions are an extension of the \nLua language. We use LuaJIT [1], an implementation of Lua that includes a trace-based JIT compiler. Lua \nitself is implemented as a library in C, with calls to initialize the runtime, load Lua programs, and \nevaluate them. We add additional functions to this library to load combined Lua-Terra programs. This \nprocess is implemented as a preprocessor that parses the combined Lua-Terra text. This design allows \nus to imple\u00adment Terra without having to modify the LuaJIT implementation. The preprocessor parses the \ntext, building an AST for each Terra function. It then replaces the Terra function text with a call to \nspe\u00adcialize the Terra function in the local environment. This constructor takes as arguments the parsed \nAST, as well as a Lua closure that captures the local lexical environment. When this code is executed, \nit will call into an internal library that actually constructs and re\u00adturns the specialized Terra function. \nThe preprocessed code is then passed to the Lua interpreter to load. Terra code is compiled when a Terra \nfunction is typechecked the .rst time it is run. We use LLVM [17] to compile Terra code since it can \nJIT-compile its intermediate representation directly to machine code. To implement backwards compatibility \nwith C, we use Clang, a C front-end that is part of LLVM. Clang is used to compile the C code into LLVM \nand generate Terra function wrappers that will invoke the C code when called. 6. Evaluation To evaluate \nTerra, we use it to reimplement a number of multi\u00adlanguage applications and compare our implementations \nwith ex\u00adisting approaches. We present evidence that the design decisions of Terra make the implementations \nsimpler to engineer compared to existing implementations while achieving high performance. First, we \nevaluate an auto-tuner for BLAS and a DSL for stencil compu\u00adtations. Next, we show a high-performance \nclass system and con\u00adtainer with programmable data layout that can be JIT compiled. Each would be dif.cult \nto implement in a single existing language. 6.1 Tuning DGEMM BLAS routines like double-precision matrix \nmultiply (DGEMM) are used in a wide range of applications and form a basis for many function genkernel(NB, \nRM, RN, V,alpha) local vector_type = vector(double,V) local vector_pointer = &#38;vector_type local A,B,C \n= symbol(\"A\"),symbol(\"B\"),symbol(\"C\")  5 local mm,nn = symbol(\"mn\"),symbol(\"nn\") local lda,ldb,ldc = \nsymbol(\"lda\"),symbol(\"ldb\"),symbol(\"ldc\") local a,b = symmat(\"a\",RM), symmat(\"b\",RN) local c,caddr = \nsymmat(\"c\",RM,RN), symmat(\"caddr\",RM,RN) local k = symbol(\"k\") 10 local loadc,storec = terralib.newlist(),terralib.newlist() \nfor m = 0, RM-1 do for n = 0, RN-1 do loadc:insert(quote var [caddr[m][n]] = C + m*ldc + n*V var [c[m][n]] \n=  15 alpha * @vector_pointer([caddr[m][n]]) end) storec:insert(quote @vector_pointer([caddr[m][n]]) \n= [c[m][n]] end)  20 end end local calcc = terralib.newlist() for n = 0, RN-1 do calcc:insert(quote \nvar [b[n]] = @vector_pointer(&#38;B[n*V])  25 end) end for m = 0, RM-1 do calcc:insert(quote var [a[m]] \n= vector_type(A[m*lda])  30 end) end for m = 0, RM-1 do for n = 0, RN-1 do calcc:insert(quote [c[m][n]] \n= [c[m][n]] + [a[m]] * [b[n]]  35 end) end end return terra([A] : &#38;double, [B] : &#38;double, [C] \n: &#38;double, [lda] : int64,[ldb] : int64,[ldc] : int64) for [mm] = 0, NB, RM do  40 for [nn] = 0, \nNB, RN*V do [loadc]; for [k] = 0, NB do prefetch(B + 4*ldb,0,3,1); [calcc]; 45 B,A = B + ldb,A + 1 end \n [storec]; A,B,C = A -NB,B -ldb*NB + RN*V,C + RN*V end  50 A,B,C = A + lda*RM, B -NB, C + RM * ldb \n-NB end end end  Figure 5. Parameterized Terra code that generates a matrix\u00admultiply kernel optimized \nto .t in L1. of the algorithms used in high-performance scienti.c computing. However, their performance \nis dependent on characteristics of the machine such as cache sizes, vector length, or number of .oating\u00adpoint \nmachine registers. In our tests, a na\u00a8ive DGEMM can run over 65 times slower than the best-tuned algorithm. \nThe ATLAS project [33] was created to maintain high perfor\u00admance BLAS routines via auto-tuning. To demonstrate \nTerra s use\u00adfulness in auto-tuning high-performance code, we implemented a version of matrix multiply, \nthe building block of level-3 BLAS rou\u00adtines. We restrict ourselves to the case C = AB , with both A \nand B stored non-transposed, and base our optimizations on those of AT-LAS [33]. ATLAS breaks down a \nmatrix multiply into smaller op\u00aderations where the matrices .t into L1 cache. An optimized kernel for \nL1-sized multiplies is used for each operation. Tuning DGEMM involves choosing good block sizes, and \ngenerating optimized code for the L1-sized kernel. We found that a simple two-level block\u00ading scheme \nworked well. To generate the L1-sized kernel, we use staging to implement several optimizations. We implement \nregister\u00adblocking of the inner-most loops, where a block of the output ma\u00ad 30 60 Peak  Peak void diffuse(int \nN, int b, float* x, float* x0, float* tmp, MKL25 50 MKL float diff, float dt ){ ATLAS ATLAS (fixed) \nint i, j, k; float a=dt*diff*N*N; 40Terra Terra for (k = 0; k<= iter; k++){ 30 5 for (j = 1; j <= \nN; j++) GFLOPS GFLOPS 20 for (i = 1; i <= N; i++) 10 tmp[IX(i,j)] = (x0[IX(i,j)] + a*(x[IX(i-1,j)]+ \n ATLAS (orig.) Blocked Blocked x[IX(i+1,j)]+x[IX(i,j-1)]+x[IX(i,j+1)]))/(1+4*a);  0 0 5 10 15 20 0 \n5 10 15 20 Matrix Size (in MB) Matrix Size (in MB) (a) DGEMM Performance (b) SGEMM Performance Figure \n6. Performance of matrix multiply using different libraries as a function of matrix size. Size reported \nis the total footprint for both input and output matrices. All matrices are square. trix is stored in \nmachine registers; we vectorize this inner-most loop using vector types; and we use prefetch intrinsics \nto optimize non\u00adcontiguous reads from memory. The code that implements our L1-sized kernel is shown in \nFigure 5. It is parameterized by the blocksize (NB), the amount of the register blocking in 2 dimensions \n(RM and RN), the vector size (V), and a constant (alpha) which parameterizes the multiply operation, \nC = alpha*C + A*B. When generating code with a parameterizable number of variables (e.g., for register \nblocking) it is sometimes useful to selectively violate hygiene. Terra provides the function symbol, \nequivalent to LISP s gensym, which generates a globally unique identi.er that can be used to de.ne and \nrefer to a variable that will not be renamed. We use it on lines 4 9 to generate the intermediate variables \nfor our computation (symmat generates a matrix of symbols). On lines 10 20, we generate the code to load \nthe values of C into registers (loadc), and the code to store them back to memory (storec). Lines 21 \n31 load the A and B matrices, and lines 32 36 generate the unrolled code to perform the outer product(calcc). \nWe compose these pieces into the L1-sized matrix multiply function (lines 37 51). The full matrix-multiply \nroutine (not shown) calls the L1-sized kernel for each block of the multiply. In Lua, we wrote an auto-tuner \nthat searches over reasonable values for the parameters (NB, V, RA, RB), JIT-compiles the code, runs \nit on a user-provided test case, and choses the best-performing con.guration. Our implementation is around \n200 lines of code. We evaluate the performance by comparing to ATLAS and In\u00adtel s MKL on a single core \nof an Intel Core i7-3720QM. ATLAS 3.10 was compiled with GCC 4.8. Figure 6 shows the results for both \ndouble-and single-precision. For DGEMM, the na\u00a8ive algo\u00adrithm performs poorly. While blocking the algorithm \ndoes improve its performance for large matrices, it runs at less than 7% of theo\u00adretical peak GFLOPs \nfor this processor. In contrast, Terra performs within 20% of the ATLAS routine, over 60% of peak GFLOPs \nof the core, and over 65 times faster than the na\u00a8ive unblocked code. The difference between Terra and \nATLAS is likely caused by a reg\u00adister spill in Terra s generated code that is avoided in ATLAS s gen\u00aderated \nassembly. Terra is also competitive with Intel s MKL, which is considered state-of-the-art. For SGEMM, \nTerra outperforms the unmodi.ed ATLAS code by a factor of 5 because ATLAS incurs a transition penalty \nfrom mixing SSE and AVX instructions. Once this performance bug is .xed, ATLAS performs similarly to \nTerra. ATLAS is built using Make.les, C, and assembly programs gen\u00aderated with a custom preprocessor. \nThe Make.les orchestrate the creation and compilation of the code with different parameters. Code generation \nis accomplished through a combination of pre\u00adprocessors and cross-compilation written in C. Auto-tuning \nis per\u00adformed using a C harness for timing. Different stages communicate through the .le system. The \ndesign of Terra allows all of these tasks to be accomplished in one system and as a single process. Terra \nprovides low-level features like vectors and prefetch instructions needed for high\u00ad SWAP(x,tmp); 10 \n} } function diffuse ( x, x0, diff, dt ) local a=dt*diff*N*N for k=0,iter do x = (x0+a*(x(-1,0)+x(1,0)+x(0,-1)+x(0,1)))/(1+4*a) \n 5 end return x,x0 end  Figure 7. A kernel from a real-time .uid solver written in C (top) compared \nto Orion (bottom). Fluid Simulation: Reference C 1x (37 sec) Matching Orion 1x (37 sec) + Vectorization \n1.9x (20 sec)  2.3x (16 sec)+ Line buffering Separated Area Filter: Reference C 1x (4.4 ms) Matching \nOrion  1.1x (4.1 ms) + Vectorization 2.8x (1.6 ms) + Line Buffering 3.4x (1.3 ms)  Figure 8. Speedup \nfrom choosing different Orion schedules. All results on Intel Core i7-3720QM, 1024x1024 .oating point \npixels. performance. In contrast, ATLAS needed to target x86 directly, which resulted in a performance \nbug in SGEMM. Staging annota\u00adtions made it easy to write parameterized optimizations like register unrolling \nwithout requiring a separate preprocessor. Interoperabil\u00adity through the FFI made it possible to generate \nand evaluate the kernels in the same framework. Finally, since Terra code can run without Lua, the resulting \nmultiply routine can be written out as a library and used in other programs; or, for portable performance, \nit can be shipped with the Lua runtime and auto-tuning can be per\u00adformed dynamically, something that \nis not possible with ATLAS. 6.2 Orion: A Stencil DSL for Images To test Terra s suitability for DSL development, \nwe created Orion, a DSL for 2D stencil computations on images. Stencil computations are grid-based kernels \nin which each value in the grid is dependent on a small local neighborhood. They are used in image processing \nand simulation. They present a number of opportunities for opti\u00admization, but implemented like the C \ncode in Figure 7, it is dif.cult to exploit the performance opportunities. For example, fusing two iterations \nof the outer loop in diffuse may reduce memory traf\u00ad.c, but testing this hypothesis can require signi.cant \ncode changes. Figure 7 shows the same diffuse operation written in Orion. Rather than specify loop nests \ndirectly, Orion programs are written using image-wide operators. For instance, f(-1,0) + f(0,1) adds \nthe im\u00adage f translated by -1 in x to f translated by 1 in y. The offsets must be constants, which guarantees \nthe function is a stencil. We base our design on Halide [24], a language for the related domain of image \nprocessing. The user guides optimization by spec\u00adifying a schedule. An Orion expression can be materialized, \nin\u00adlined, or line buffered. Materialized expressions are computed once and stored to main memory. Inlined \nexpressions are recomputed once for each output pixel. Line buffering is a compromise in which computations \nare interleaved and the necessary intermediates are stored in a scratchpad. Additionally, Orion can vectorize \nany sched\u00adule using Terra s vector instructions. Being able to easily change the schedule is a powerful \nabstraction. To demonstrate this, we im\u00adplemented a pipeline of four simple memory-bound point-wise im\u00adage \nprocessing kernels (blacklevel offset, brightness, clamp, and invert). In a traditional image processing \nlibrary, these functions would likely be written separately so they could be composed in an arbitrary \norder. In Orion, the schedule can be changed indepen\u00addently of the algorithm. For example, we can choose \nto inline the four functions, reducing the accesses to main memory by a factor of 4 and resulting in \na 3.8x speedup. To implement Orion, we use operator overloading on Lua ta\u00adbles to build Orion expressions. \nThese operators build an interme\u00addiate representation (IR) suitable for optimization. The user calls \norion.compile to compile the IR into a Terra function. We then use Terra s staging annotations to generate \nthe code for the inner loop. To test that the code generated by Terra performs well, we implemented an \narea .lter and a .uid simulation. We compare each to equivalents hand-written in C. The area .lter is \na common image processing operation that averages the pixels in a 5x5 window. Area .ltering is separable, \nso it is normally implemented as a 1-D area .lter .rst in Y then in X. We compare against a hand-written \nC implementation with results in Figure 8. Given a schedule that matches the C code, Orion performs similarly, \nrunning 10% faster. Enabling vectorization in Orion yields a 2.8x speedup over C, and then line buffering \nbetween the passes in Y and X yields a 3.4x speedup. Explicit vectors are not part of standard C, and \nwriting line-buffering code is tedious and breaks composability, so these optimizations are not normally \ndone when writing code by hand. We also implemented a simple real-time 2D .uid simulation based on an \nexisting C implementation [26]. We made small mod\u00adi.cations to the reference code to make it suitable \nto a stencil lan\u00adguage. We converted the solver from Gauss-Seidel to Gauss-Jacobi so that images are \nnot modi.ed in place and use a zero boundary condition since our implementation does not yet support \nmore com\u00adplicated boundaries. We also corrected a performance bug in the code caused by looping over \nimages in row-major order that were stored in column-major order. We compare against the corrected version. \nWith a matching schedule, Orion performs the same as ref\u00aderence C. Enabling 4-wide vectorization results \nin a 1.9x speedup over the matching code, making each materialized operation mem\u00adory bound. Finally, \nline buffering pairs of the iterations of the dif\u00adfuse and project kernels yielded a 1.25x speedup on \nthe vectorized code, or a 2.3x total speedup over the reference C code. A number of features of Terra \nfacilitated the implementation of Orion. High-level features of Lua made it easy to express transfor\u00admations \non the Orion IR. Terra s built-in support of vector types made it easy to vectorize the compiler by simply \nchanging scalar types into vectors. Backwards compatibility with C allowed us to link to an existing \nlibrary for loading images. The FFI made it pos\u00adsible to use Lua to implement non-performance-critical \ncode such as the kernel scheduler, saving development time. Furthermore, the .uid simulation that we \nported included a semi-Lagrangian advec\u00adtion step, which is not a stencil computation. In this case, \nwe were able to allow the user to pass a Terra function to do the necessary computation, and easily integrate \nthis code with generated Terra code. This interoperability would have been more dif.cult to ac\u00adcomplish \nwith a stand-alone compiler. In contrast to Orion, Halide, a related image processing lan\u00adguage, requires \nthree different languages to provide the same func\u00adtionality as Orion. It uses C++ for the front-end, \nML for manipu\u00adlating the IR, and LLVM for code generation [24]. From our expe\u00adrience implementing Orion, \nusing Lua to stage Terra code accom\u00adplishes the same tasks, but results in a simpler architecture.  \n6.3 Building reuseable components via type re.ection Type re.ection makes it possible to de.ne the behavior \nand lay\u00adout of types at a low-level. First, we show the .exibility of Terra s type re.ection by using \nit to implement a class system with subtyp\u00ading. Then we show how it can be applied speci.cally to building \nruntimes for high-performance computing by implementing a type constructor that can automatically generate \na data table with either array-of-structs or struct-of-arrays layout. 6.3.1 Class Systems Using type-re.ection, \nwe can implement a single-inheritance class system with multiple subtyping of interfaces similar to Java \ns. We specify classes using an interface implemented in Lua: J = terralib.require(\"lib/javalike\") Drawable \n= J.interface { draw = {} -> {} } struct Square { length : int; } J.extends(Square,Shape)  5 J.implements(Square,Drawable) \nterra Square:draw() : {} ... end The function interface creates a new interface given a table of method \nnames and types. The functions J.extends and J.implements install metamethods on the Square type that \nwill implement the be\u00adhavior of the class system. Our implementation, based on vtables, uses the subset \nof Strous\u00adtrup s multiple inheritance [27] that is needed to implement single inheritance with multiple \ninterfaces. For each class, we de.ne a __finalizelayout metamethod. This metamethod is called by the \nTerra typechecker right before a type is examined, allowing it to compute the layout of the type at the \nlatest possible time. For our class system, this metamethod is responsible for calculating the concrete \nlayout of the class, creating the class s vtable, and creating vtables for any interface that the class \nimplements. If the user spec\u00adi.ed a parent class using J.extends, then the class and its vtables are \norganized such that the beginning of each object has the same layout as an object of the parent, making \nit safe to cast a pointer to the class to a pointer to the parent. If the user speci.ed an interface \nusing J.implements then we create a vtable that implements the in\u00adterface, and insert a pointer to the \nvtable in the layout of the class. Finally, for each method de.ned on class, we create a stub method \nto invoke the real method through the class s vtable: for methodname,fn in pairs(concretemethods) do \nlocal fntype = fn:gettype() local params = fntype.parameters:map(symbol) local self = params[1]  5 class.methods[methodname] \n= terra([params]) : fntyp.returns return self.__vtable.[methodname]([params]) end end At this point, \nchild classes can access the methods and members of a parent class, but the Terra compiler will not allow \nthe conversion from a child to its parent or to an interface. To enable conversions, we create a user-de.ned \nconversion that re.ects the subtyping rela\u00adtions of our class system (e.g., &#38;Square <: &#38;Shape). \nWe implement the conversion generically by de.ning a __cast metamethod: class.metamethods.__cast = function(from,to,exp) \nif from:ispointer() and to:ispointer() then if issubclass(from.type,to.type) then return ' [to](exp) \n--cast expression to to type 5 elseif implementsinterface(from.type,to.type) then local imd = interfacemetadata[to.type] \n return ' &#38;exp.[imd.name] --extract subobject end end error(\"not a subtype\") 10 end Since the beginning \nof a child class has the same layout as its par\u00adent, we can convert a child into a parent by simply casting \nthe ob\u00adject s pointer to the parent s type ([to](exp)). Converting an object to one of its interfaces \nrequires selecting the subobject that holds the pointer to the interface s vtable (&#38;exp.[imd.name]). \nThe stubs generated for the interface restore the object s pointer to the origi\u00adnal object before invoking \nthe concrete method implementation. We measured the overhead of function invocation in our imple\u00admentation \nusing a micro-benchmark, and found it performed within 1% of analogous C++ code. The implementation requires \nonly 250 lines of Terra code to provide much of the functionality of Java s class system. Users are not \nlimited to using any particular class sys\u00adtem or implementation. For instance, we have also implemented \na system that implements interfaces using fat pointers that store both the object pointer and vtable \ntogether.  6.3.2 Data Layout Terra s type re.ection should help programmers build reusable components \nin high-performance runtimes. One common prob\u00adlem in high-performance computing is choosing between storing \nrecords as an array of structs (AoS, all .elds of a record stored con\u00adtiguously), or as a struct of arrays \n(SoA, individual .elds stored contiguously). We implement a solution to this problem, and con\u00adtrast it \nwith existing languages. Changing the layout can substantially improve performance. We implemented two \nmicro-benchmarks based on mesh processing. Each vertex of the mesh stores its position, and the vector \nnormal to the surface at that position. The .rst benchmark calculates the vector normal as the average \nnormal of the faces incident to the vertex. The second simply performs a translation on the position \nof every vertex. Figure 9 shows the performance using both AoS and SoA form. Calculating vertex normals \nis 55% faster using AoS form. For each triangle in the mesh, positions of its vertices are gathered, \nand the normals are updated. Since this access is sparse, there is little temporal locality in vertex \naccess. AoS form performs better in this case since it exploits spatial locality of the vertex data \nall elements of the vertex are accessed together. In contrast, translating vertex positions is 43% faster \nusing SoA form. In this case, the vertices are accessed sequentially, but the normals are not needed. \nIn AoS form these normals share the same cache-lines as the positions, and memory bandwidth is wasted \nloading them. To facilitate the process of choosing a data layout in Terra, we implemented a function \nthat can generate either version, but presents the same interface. A Lua function DataTable takes a Lua \ntable specifying the .elds of the record and how to store them (AoS or SoA), returning a new Terra type. \nFor example, a .uid simulation might store several .elds in a cell: FluidData = DataTable({ vx = float, \nvy = float, pressure = float, density = float },\"AoS\") The FluidData type provides methods to access \na row (e.g., fd:row(i)). Each row can access its .elds (e.g., r:setx(1.f), r:x()). The interface abstracts \nthe layout of the data, so it can be changed just by replacing \"AoS\" with \"SoA\". This behavior can be \nemulated ahead-of-time in low-level lan\u00adguages, for example using X-Macros [19] in C, or template meta\u00adprogramming \nin C++, but unlike Terra cannot be generated dy\u00adnamically based on runtime feedback. Dynamic languages \nsuch as Javascript support this ad hoc creation of data types dynamically but do not provide the same \nlow-level of control. 7. Related Work Much work on multi-stage programming has focused on homoge\u00adneous \nmeta-programming [22, 29, 30]. MetaML [30] and MetaO-Caml [29] add staging annotations to ML. Staged \ncode is lexi-Figure 9. Performance of mesh transformations using different data layouts. Benchmark Array-of-Structs \nStruct-of-Arrays Calc. vertex normals 3.42 GB/s 2.20 GB/s Translate positions 9.90 GB/s 14.2 GB/s cally \nscoped, and a type system ensures that the annotations can only produce well-typed programs. MetaHaskell \nis an extension of Haskell for heterogeneous meta-programming that supports em\u00adbedding new object languages \nwhile ensuring that the staging is type-safe [18]. Unlike Terra, the object languages implemented in \nMetaHaskell do not share Haskell s lexical environment and are currently unhygienic. Eckhardt et al. \npropose implicit heteroge\u00adneous programming in OCaml with a translation into C [10] but the type language \nis limited to basic types and arrays. In contrast to statically-typed approaches, Terra supports the \ncreation of user\u00adde.ned types using arbitrary code but precludes static typing of the full Lua-Terra \nprogram. Heterogeneous multi-stage languages with shared lexical scope and different execution environments \nhave occurred organically in the past [10, 32]. Separating compile-time and runtime-time envi\u00adronments \nhas also been used to make macro expansion compos\u00adable [11]. To our knowledge, we are the .rst to argue \nfor these de\u00adsign choices as a way to generate portable high-performance code, retaining interoperability \nthrough an optional FFI. Multi-stage programming has been used to generate high\u00adperformance programs \n[12, 23, 33]. Carette investigates staging of Gaussian elimination in MetaOCaml [5], while Cohen et al. \nin\u00advestigate applying MetaOCaml to problems in high-performance computing like loop unrolling/tiling \nand pipelining [8]. This work has focused on using staging to improve the performance of spe\u00adci.c problems. \nMore generally, Cha. et al. use lightweight modular staging [25] a type-directed staging approach that \ncan be imple\u00admented as a library to stage a subset of the Scala language. The staged code is used to \nimplement DSLs in the Delite framework that can be translated to run on GPUs [4, 7]. Additionally, In\u00adtel \ns ArBB enables runtime generation of vector-style code using a combination of operator overloading and \nmacros in C++ [21]. In contrast to Terra, ArBB and Delite do not have explicit staging annotations, instead \nrelying on types to distinguish object-language expressions from meta-language ones. In practice we have \nfound that this type-directed staging makes it dif.cult to know when code will execute. The macro systems \nof Lisp and Scheme have also been used to build DSLs. In particular, Racket [31] provides an interface \nto the static semantics of the language using macros. Using this interface they implement a typed variant \nof Racket, as well as other DSLs. The macro system is used to translate typed Racket to standard Racket \nwith a few extensions to support unchecked access to .elds. Terra, by contrast, is implemented as a separate \nlanguage from Lua, which allows for different design decisions in each (e.g., automatic memory management \nin Lua, manual management in Terra). Previous work examined the combination of staging and type re\u00ad.ection \nfor statically-typed languages. Template meta-programming in C++ is widely used and allows generation \nand introspection on types. Garcia and Lumsdaine describe a core calculus for compile\u00adtime meta-programming \nbased on template meta-programming in C++ [13]. Similar to Terra, their semantics support code generation \nand type re.ection, but like C++ they focus only on ahead-of\u00adtime code generation. F# allows type-providers \nwhich can specify types and methods based on external data like a SQL schema [28]. Metaphor is a multi-stage \nlanguage with support for type re.ection on a built-in class system [20]. In contrast, Terra s type re.ection \nallows the creation of class-systems as libraries. Dynamic languages have added extensions to produce \nlow-level code. Cython is an extension to the Python language that allows the creation of C extensions \nwhile writing in Python s syntax [3]. Copperhead supplements Python with a vector-style language that \ncan run on GPUs [6]. In both cases, the low-level code depends on the Python runtime to execute. Other \nlanguages have been proposed as a portable target for low-level code [16, 17]. Terra is also usable directly \nas a low-level programming language, making it possible to write runtime code in Terra. 8. Discussion \nand Future Work We have presented Terra, a staged language embedded in Lua and designed for high-performance \ncomputing. By comparing to existing multi-language systems, we have shown that the combi\u00adnation of high-and \nlow-level languages, shared lexical environ\u00adment, separate execution, and type re.ection make designing \nauto\u00adtuners, DSLs, and runtime components simpler, while retaining high-performance. We plan to extend \nTerra in several ways. Accelerators like GPUs or Intel s MIC architecture provide more performance for \ndata\u00adparallel problems. We plan to extend our implementation so that Terra can generate code that runs \non these architectures. Currently Terra does not provide a seamless way to mix Terra code compiled ahead-of-time \nwith dynamically compiled code, which can be prob\u00adlematic for DSLs with a large runtime. We plan to address \nthis with a module system that will allow some code to be generated ahead\u00adof-time, while still allowing \nJIT compilation of code at runtime. Terra addresses the problem of generating high-performance code and \ninteroperating with existing applications. We want to gen\u00aderalize the way Terra is embedded and staged \nto make it easy to em\u00adbed custom DSLs in Lua in the same way that Terra is embedded. In particular, we \nthink that having DSLs share the same lexical en\u00advironment during compilation will open up more opportunities \nfor interoperability between different languages. In the future, we en\u00advision a programming ecosystem \nwhere the right language can be used for a particular task without loss of performance, or signi.cant \neffort to integrate the language with existing systems. Acknowledgments This work has been supported \nby the DOE Of\u00ad.ce of Science ASCR in the ExMatEx and ExaCT Exascale Co-Design Centers, program manager \nKaren Pao; DARPA Contract No. HR0011-11-C-0007; and the Stanford Pervasive Parallelism Lab (supported \nby Oracle, AMD, Intel, and NVIDIA). Any opin\u00adions, .ndings and conclusion or recommendations expressed \nin this material are those of the authors and do not necessarily re.ect the views of DARPA. We thank \nour reviewers for suggesting improve\u00adments to specialization. References [1] The LuaJIT project. http://http://luajit.org/. \n[2] A. Bawden and J. Rees. Syntactic closures. In LFP, 1988. [3] S. Behnel, R. Bradshaw, C. Citro, L. \nDalcin, D. S. Seljebotn, and K. Smith. Cython: The best of both worlds. Computing in Science and Engineering, \n13.2:31 39, 2011. [4] K. J. Brown, A. K. Sujeeth, H. J. Lee, T. Rompf, H. Cha., M. Odersky, and K. Olukotun. \nA heterogeneous parallel framework for domain\u00adspeci.c languages. In PACT, 2011. [5] J. Carette. Gaussian \nelimination: A case study in ef.cient genericity with MetaOCaml. Sci. Comput. Program., 62(1):3 24, Sept. \n2006. [6] B. Catanzaro, M. Garland, and K. Keutzer. Copperhead: Compiling an embedded data parallel language. \nIn PPoPP, 2011. [7] H. Cha., A. K. Sujeeth, K. J. Brown, H. Lee, A. R. Atreya, and K. Olukotun. A domain-speci.c \napproach to heterogeneous paral\u00adlelism. In PPoPP, 2011. [8] A. Cohen, S. Donadio, M. Garzaran, C. Herrmann, \nand D. Padua. In search of a program generator to implement generic transformations for high-performance \ncomputing. In MetaOCaml Workshop, 2004. [9] Z. DeVito, N. Joubert, F. Palacios, S. Oakley, M. Medina, \nM. Barrien\u00adtos, E. Elsen, F. Ham, A. Aiken, K. Duraisamy, E. Darve, J. Alonso, and P. Hanrahan. Liszt: \nA domain speci.c language for building portable mesh-based PDE solvers. In SC, 2011. [10] J. Eckhardt, \nR. Kaiabachev, E. Pasalic, K. Swadi, and W. Taha. Im\u00adplicitly heterogeneous multi-stage programming. \nNew Gen. Comput., 25(3):305 336, Jan. 2007. [11] M. Flatt. Composable and compilable macros: You want \nit when? In ICFP, 2002. [12] M. Frigo and S. Johnson. The design and implementation of FFTW3. Proc. of \nthe IEEE, 93(2):216 231, 2005. [13] R. Garcia and A. Lumsdaine. Toward foundations for type-re.ective \nmetaprogramming. In GPCE, 2009. [14] R. Ierusalimschy, L. H. de Figueiredo, and W. C. Filho. Lua -an \nextensible extension language. Software: Practice and Experience, 26 (6), 1996. [15] R. Ierusalimschy, \nL. H. De Figueiredo, and W. Celes. Passing a language through the eye of a needle. CACM, 54(7):38 43, \n2011. [16] S. Jones, T. Nordin, and D. Oliva. C--: A portable assembly language. In Workshop on Implementing \nFunctional Languages, 1997. [17] C. Lattner and V. Adve. LLVM: A Compilation Framework for Lifelong Program \nAnalysis &#38; Transformation. In CGO, 2004. [18] G. Mainland. Explicitly heterogeneous metaprogramming \nwith meta\u00adhaskell. In ICFP, 2012. [19] R. Meyers. X macros. C/C++ Users J., 19(5):52 56, May 2001. [20] \nG. Neverov and P. Roe. Metaphor: A multi-staged, object-oriented programming language. In GPCE, 2004. \n[21] C. Newburn, B. So, Z. Liu, M. McCool, A. Ghuloum, S. Toit, Z. G. Wang, Z. H. Du, Y. Chen, G. Wu, \nP. Guo, Z. Liu, and D. Zhang. Intel s Array Building Blocks: A retargetable, dynamic compiler and embedded \nlanguage. In CGO, 2011. [22] M. Poletto, W. C. Hsieh, D. R. Engler, and M. F. Kaashoek. C and tcc: A \nlanguage and compiler for dynamic code generation. TOPLAS, 21 (2):1999. [23] M. P \u00a8uschel, J. M. F. Moura, \nB. Singer, J. Xiong, J. Johnson, D. Padua, M. Veloso, and R. W. Johnson. Spiral: A generator for platform\u00adadapted \nlibraries of signal processing algorithms. Int. J. High Perform. Comput. Appl., 18(1):2004. [24] J. \nRagan-Kelley, A. Adams, S. Paris, M. Levoy, S. Amarasinghe, and F. Durand. Decoupling algorithms from \nschedules for easy optimiza\u00adtion of image processing pipelines. In SIGGRAPH, 2012. [25] T. Rompf and \nM. Odersky. Lightweight modular staging: A pragmatic approach to runtime code generation and compiled \nDSLs. In GPCE, 2010. [26] J. Stam. Real-time .uid dynamics for games. In GDC, 2003. [27] B. Stroustrup. \nMultiple inheritance for C++. In European Unix Systems Users s Group Conference, 1987. [28] D. Syme, \nK. Battocchi, K. Takeda, D. Malayeri, J. Fisher, J. Hu, T. Liu, B. McNamara, D. Quirk, M. Taveggia, W. \nChae, U. Matsveyeu, and T. Petricek. F#3.0 Strongly-typed language support for internet-scale information \nsources. Technical report, 2012. [29] W. Taha. A gentle introduction to multi-stage programming. In \nDomain-Speci.c Program Generation, 2004. [30] W. Taha and T. Sheard. MetaML and multi-stage programming \nwith explicit annotations. In Theoretical Computer Science, 1999. [31] S. Tobin-Hochstadt, V. St-Amour, \nR. Culpepper, M. Flatt, and M. Felleisen. Languages as libraries. In PLDI, 2011. [32] Z. Wan, W. Taha, \nand P. Hudak. Real-time FRP. In ICFP, 2001. [33] R. C. Whaley and A. Petitet. Minimizing development \nand mainte\u00adnance costs in supporting persistently optimized BLAS. Softw. Pract. Exper., 35(2):101 121, \n2005.   \n\t\t\t", "proc_id": "2491956", "abstract": "<p>High-performance computing applications, such as auto-tuners and domain-specific languages, rely on generative programming techniques to achieve high performance and portability. However, these systems are often implemented in multiple disparate languages and perform code generation in a separate process from program execution, making certain optimizations difficult to engineer. We leverage a popular scripting language, Lua, to stage the execution of a novel low-level language, Terra. Users can implement optimizations in the high-level language, and use built-in constructs to generate and execute high-performance Terra code. To simplify meta-programming, Lua and Terra share the same lexical environment, but, to ensure performance, Terra code can execute independently of Lua's runtime. We evaluate our design by reimplementing existing multi-language systems entirely in Terra. Our Terra-based auto-tuner for BLAS routines performs within 20% of ATLAS, and our DSL for stencil computations runs 2.3x faster than hand-written C.</p>", "authors": [{"name": "Zachary DeVito", "author_profile_id": "81470655829", "affiliation": "Stanford University, Stanford, USA", "person_id": "P4148956", "email_address": "zdevito@cs.stanford.edu", "orcid_id": ""}, {"name": "James Hegarty", "author_profile_id": "81377591215", "affiliation": "Stanford University, Stanford, USA", "person_id": "P4148957", "email_address": "jhegarty@cs.stanford.edu", "orcid_id": ""}, {"name": "Alex Aiken", "author_profile_id": "81100399954", "affiliation": "Stanford University, Stanford, USA", "person_id": "P4148958", "email_address": "aiken@cs.stanford.edu", "orcid_id": ""}, {"name": "Pat Hanrahan", "author_profile_id": "81100482576", "affiliation": "Stanford University, Stanford, USA", "person_id": "P4148959", "email_address": "hanrahan@cs.stanford.edu", "orcid_id": ""}, {"name": "Jan Vitek", "author_profile_id": "81100018102", "affiliation": "Purdue University, West Lafayette, USA", "person_id": "P4148960", "email_address": "jv@cs.purdue.edu", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462166", "year": "2013", "article_id": "2462166", "conference": "PLDI", "title": "Terra: a multi-stage language for high-performance computing", "url": "http://dl.acm.org/citation.cfm?id=2462166"}