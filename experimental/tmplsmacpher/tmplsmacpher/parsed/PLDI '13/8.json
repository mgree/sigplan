{"article_publication_date": "06-16-2013", "fulltext": "\n Harmonizing Classes, Functions, Tuples, and Type Parameters in Virgil III Ben L. Titzer Google titzer@google.com \nAbstract Languages are becoming increasingly multi-paradigm. Subtype polymorphism in statically-typed \nobject-oriented languages is be\u00ading supplemented with parametric polymorphism in the form of generics. \nFeatures like .rst-class functions and lambdas are ap\u00adpearing everywhere. Yet existing languages like \nJava, C#, C++, D, and Scala seem to accrete ever more complexity when they reach beyond their original \nparadigm into another; inevitably older features have some rough edges that lead to nonuniformity and \npit\u00adfalls. Given a fresh start, a new language designer is faced with a daunting array of potential features. \nWhere to start? What is impor\u00adtant to get right .rst, and what can be added later? What features must \nwork together, and what features are orthogonal? We report on our experience with Virgil III, a practical \nlanguage with a care\u00adful balance of classes, functions, tuples and type parameters. Virgil intentionally \nlacks many advanced features, yet we .nd its core feature set enables new species of design patterns \nthat bridge mul\u00adtiple paradigms and emulate features not directly supported such as interfaces, abstract \ndata types, ad hoc polymorphism, and variant types. Surprisingly, we .nd variance for function types \nand tuple types often replaces the need for other kinds of type variance when libraries are designed \nin a more functional style. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language \nConstructs and Features Keywords Multi-paradigm languages; parametric types; object\u00adoriented programming; \nfunctional programming; monomorphiza\u00adtion; variance; closures; tuples; .attening; unboxing; static compi\u00adlation \n1. Introduction Mainstream languages are becoming increasingly multi-paradigm and increasingly complex. \nStatically-typed object-oriented lan\u00adguages have now ventured beyond the subtype polymorphism of class \nand object inheritance and begun adding parametric polymor\u00adphism in various forms; erased generics in \nJava 5.0, rei.ed gener\u00adics in C# 2.0, C++ templates, and even more complex generics in Scala. Functional \nprogramming constructs are now appearing in nearly all active languages, further adding to language complexity. \nLan- Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n13, June 16 19, 2013, Seattle, WA, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . \n$15.00 guages like Java .rst offered object-oriented emulation of func\u00adtions in the form of single-method \ninterfaces like Runnable and Comparator. Generics gave rise to even more complex emula\u00adtions of functions \nsuch as java.util.concurrent s Callable and Guava s Function [13] and Predicate. Now Java has pro\u00adposals \nfor syntax for function types and closures in JSR 335 [17]. Similar developments occurred in both C++ \nand C#, with libraries .rst evolving functional patterns before languages added syntactic support. C# \n.rst allowed delegates, which are closures bound to a method of an object, and then full lambdas. Scala \nset out to blend object-oriented and functional styles while still primarily targeting the JVM. Not to \nbe outdone, C++11 has added support for lambdas and a host of other new features. Of course the relationship \nbetween functions and objects goes back even further in dynamically-typed languages. Smalltalk had blocks \n[12], popular dynamic languages such as JavaScript, Python and Ruby have .rst class functions, and newcomers \nsuch as Newspeak, Groovy and Dart also incorporate some kind of functional features. A designer of a \nnew programming language faces a daunting lineup of features from which to choose. What features work \nbest? How does this feature enhance or hinder another feature? What feature should be implemented .rst? \nShould objects be primary, or functions be primary? What tools should programmers have to express polymorphism \nand reuse, model side-effects or state, and how can the constructs be implemented ef.ciently? Of course, \nthese are the tough design questions to which the whole of language research is directed. This paper \nexplores just one potential combination of four language features and the im\u00adplications of that combination. \nIn seeking to .nd a smaller, more cohesive language core made from existing parts, and seeking to implement \na practical language in which ef.cient systems can be written, we ve found a number of surprising patterns \narising from just a small set of features. This paper .nds that integrating four particular features \nin a statically-typed language achieves a surprising cohesiveness and simplicity. Classes provide data \nabstraction, encapsulation, and in\u00adformation hiding; .rst-class functions allow .ne-grained reuse; tu\u00adples \nallow for the uniform treatment of multi-argument and multi\u00adreturn function types and simplify composing \nvalues, and type pa\u00adrameters allow type abstraction and representation independence for more reuse of \nfunctions and data structures represented by ob\u00adjects. None of these features are novel, and all of them \nexhibit implementations in mainstream languages, but their seamless in\u00adtegration is key in Virgil s design. \nThis integration yields surpris\u00ading power; enough to build new design patterns that emulate other language \nfeatures not in the language, including interfaces, abstract data types, ad hoc polymorphism, and variants. \nAn interesting aside is Virgil s approach to type variance; a key design dif.culty in re\u00adcent statically \ntyped languages with both subtyping and parametric polymorphism. Surprisingly, we .nd type variance for \nclass types to be far less important when libraries are designed in a more func\u00adtional style because \nbuilt-in variance for tuple and function type constructors is often suf.cient.  2. Four Pieces of the \nPuzzle Virgil I was originally designed [31] for programming severely resource-constrained devices with \nonly a few hundred bytes of RAM. A staged computation model allows applications to exe\u00adcute initialization \ncode during compilation, building a heap of ob\u00adjects that is compiled into a binary that executes directly \non the hardware. Virgil I supported objects and functions but had no dy\u00adnamic memory allocation, no type \nparameters, and no tuples, mak\u00ading it unsuitable for general-purpose programming. Virgil III is a clean \nredesign for a more general-purpose setting. It retains the staged compilation model of Virgil I but \nimproves classes and func\u00adtions, adds tuples, type parameters, dynamic memory allocation, and garbage \ncollection. Virgil includes primitive types such as int, byte, bool, and void1. All types support four \nbasic operators: equality ==, inequal\u00adity !=, type cast !, and type query ?. Control structures, basic \nstate\u00adments and expression syntax are similar to most C language descen\u00addants, but declarations and classes \nlook more like Scala. 2.1 Classes Virgil provides classes that allow encapsulation, data abstraction \nand polymorphism through inheritance. Classes resemble those in Java and C# in that only single inheritance \nis allowed between classes and all methods are virtual except those declared private. All objects are \ncreated by instantiating classes and are always passed by reference, never by value. Unlike most object-oriented \nlanguages, Virgil has no universal superclass akin to Object from which all classes ultimately inherit. \nA class declared without a parent class begins a new hierarchy which is unrelated to other class hierarchies. \nThis means that there is no unifying supertype for all objects, and there are no default methods available \non all objects. Classes are further limited in that there is no concept of an interface which a class \ncan implement. The example below illustrates the basics of Virgil classes. (a1) class A { (a2) var f: \nint; // mutable field (a3) def g: int; // immutable field (a4) new(f, g) { ... } // constructor (a5) \ndef m(a: byte) -> int { ... } // method (a6) def n(a: X, b: T) { ... } (a7) } (a8) class B extends A \n{ // subclass (a9) def m(a: byte) -> int { ... } // override (a10) } Pure object-oriented philosophy \nviews all values as objects with some universal type and a default set of methods. The lack of a uni\u00adversal \nsupertype in Virgil or any kind of interface mechanism at .rst seems crippling, but as we will see in \nthis section, the other features of the language more than make up for the loss of expressiveness. Virgil \ndoes not hold the everything-is-an-object philosophy for sev\u00aderal reasons. First, domains such as system \nsoftware [9] [20] and scienti.c computing [21] demand ef.cient primitive types; model\u00ading these primitives \nas objects can be cumbersome, performance can be unpredictable, and mapping certain object types onto \nhard\u00adware primitives requires signi.cant extra-lingual and compiler sup\u00adport. Second, a universal type \nin object-oriented languages of the past was most often used to implement reuseable datastructures and \nprovide default methods; these roles are better served with proper 1 void has one value, (), which is \nalways equal to itself. design of type parameters and use of .rst class functions, as we will see in \nthe next section. Third, the possibility of subsumption to a universal type weakens con.nement [34] properties \nand may reduce the precision of other static analyses [6][25][31].  2.2 First-class Functions Virgil \nprovides support for statically-typed .rst-class functions. Function types take the form Tp -> Tr, where \nTp is the param\u00adeter type and Tr is the return type. The type void becomes the parameter type of methods \nwith no parameters and the return type of methods without a declared return type. Function types are \nunre\u00adlated to object types, forming a separate universe of values. Func\u00adtion types are co-variant in \ntheir return type and contra-variant in their parameter type. A function type can legally appear anywhere \nany other type can appear, such as the type of a class .eld, method parameter, local variable, or return \ntype of a method. Unlike most traditional functional languages, tuples are used to model multi\u00adargument \nfunctions instead of currying. To bridge the object-oriented and functional worlds, any method of any \nobject can be used as an object method, a function which is bound to the object as its closure. Similarly, \nclass methods are not bound to an object but are functions that accept the receiver object as their .rst \nparameter followed by the method parameters. All of the basic primitive operators can be used as .rst-class \nfunctions as well, and all three kinds of functions can be used interchangeably. Examples (b1-7) illustrate \nthe basics, with the types of each expression given in comments. Continuing with the class A from (a1-6), \nwe can (b1) create an object of that class and (b2) create a closure bound to the m method of that object. \nIn (b3) we use the method m of class A as a .rst-class function that is not bound to an object, but accepts \nthe receiver object as the .rst parameter. In (b4) we invoke m directly on the object, in (b5) apply \nthe function m1 to arguments, and in (b6) apply the function m2, supplying the object as the .rst argument. \nNotice that we can also use the new operator for a class A as a function as well (b7). (b1) var a = A.new(0, \n1); // A (b2) var m1 = a.m; // byte -> int (b3) var m2 = A.m; // (A, byte) -> int (b4) var x = a.m( 5 \n); // int (b5) var y = m1( 4 ); // int (b6) var z = m2(a, 6 ); // int (b7) var w = A.new; // (int, int) \n-> A The four basic operators == != ! ? of every type T are avail\u00adable as .rst class functions. Though \nnormally written with in.x no\u00adtation, comparisons (b8-9) can be used as functions by referring to them \nas members of a type, as can primitive and integer arithmetic operators (b10-11). (b8) var z = byte.==; \n// (byte, byte) -> bool (b9) var w = A.!=; // (A, A) -> bool (b10) var p = int.+; // (int, int) -> int \n(b11) var m = int.-; // (int, int) -> int Type casts (b12) express all type conversions, including down\u00adcasts \nof objects and conversions between primitive values. Type queries (b13) evaluate to true if the value \nis of type T , false otherwise. Type casts and type queries of class types check the dy\u00adnamic type of \ntheir input objects. Both operators each have a type parameter that abstracts the type of the input value. \nParameteriza\u00adtion allows dynamic casts and dynamic type queries between any two types, even polymorphic \ntypes. This is a blatant violation of the parametricity property of type parameters, but is an intentional \ntradeoff that allows dynamic casts to emulate other language fea\u00adtures, as we will see later. In practice, \nthe compiler rejects casts and queries between unrelated types wherever possible, such as be\u00adtween a \nfunction type and a primitive type or between unrelated classes. Like the other operators, casts and \nqueries can be used as functions (b14-15).  (b12) var x = A.!(...); // A (b13) var y = A.?(...); // \nbool (b14) var z = A.!<B>; // B -> A (b15) var w = A.?<B>; // B -> bool  2.3 Tuples Tuples are a lightweight \nmechanism to group multiple values into a single value. The resulting tuple value is not an object and \nhas no identity; tuples with equivalent elements are always equal, no matter when or where in the program \nthey are computed. No re\u00adstrictions are placed on what types may appear as element types of a tuple; \nif A and B are valid types, then (A, B) is a valid tuple type. Inductively, this means that tuples can \nbe inside of tuples, but not recursively, since tuple types have no names. Elements are or\u00addered and \naccessed as if they were .elds named as integer literals beginning at 0. Tuples are not arrays; they \ncannot be indexed by expressions. (c1) var x: (int, int) = (0, 1); (c2) var y: (byte, bool) = ( a , true); \n(c3) var z: ((int, int), (byte, bool)) = (x, y); (c4) var w: (int) = x.0; (c5) var u: byte = (z.1.0); \n(c6) var v: () = (); Tuple types with any number of element types are possible, with two degenerate \ncases: (c6) a tuple type T = () with no elements is exactly the same as the void type, and (c4) a tuple \ntype T = (A) with just one element is exactly the same as the type A. Similarly, tuple values with any \nnumber of element values can be created, with (c6) a tuple value V = () with no elements equivalent to \nthe one void value, and (c5) a tuple V = (e) is equivalent to e. Immutability admits straightforward \ncovariant type rules for tuples. T = (T0...Tm) is a subtype of S = (S0...Sn) if and only if m = n and \nall elements Ti of T are subtypes of the corresponding 2 Si. Like all types in Virgil, every tuple type \nT has the four basic op\u00aderators == != ! ?. Equality and inequality operators operate recur\u00adsively on \nthe elements of a tuple: two tuple values are equivalent if the positionally-correspondent elements are \nequivalent. Casts and queries are also de.ned recursively: a cast of a tuple value to a tuple type succeeds \nif a cast of each element to the positionally\u00adcorresponding element type succeeds, and a type query of \na tuple value against a tuple type is true if all type queries of elements against the positionally-corresponding \nelement type are true. Syntactic choices for tuples give rise to familiar looking calls. For example, \na typical method invocation such as a.m(foo, bar) parses as an application of the expression a.m to the \ntuple expres\u00adsion (foo, bar). The expression a.m itself is an object method expression, but could be \nany expression that evaluates to a function of the appropriate type. Nested calls like f(g(x)) compose \nnicely, even if the inner call has a tuple or void return type. This represents semantics similar to \ntuples in Haskell and ML, but with syntax that resembles Java and C#. Tuple type syntax leads to familiar \nsyntax for function types. (A, B) -> C denotes a function type with two parameters and A -> (B, C) denotes \na function that returns two values. The de\u00adgenerate rules for tuple types imply intuitive equivalences, \nsuch as () -> () = void -> void and (A) -> (B) = A -> B. This also allows the tuple type constructor \n() to be used as a grouping 2 Subtyping rules for tuples could also allow a longer tuple to be a subtype \nof a shorter tuple, but too much static checking would be lost; basic errors such as passing more arguments \nto a function than it expects would go unnoticed. mechanism, either to emphasize the right-associative \nnature of -> by writing A -> (B -> C), or override it with (A -> B) -> C. For type rules, covariance \nof tuple types means that variance rules for function types operate exactly as one would expect when \nap\u00adplied to functions that accept or return tuples.  2.4 Type Parameters Classes, functions and tuples \nall coexist in Virgil, but an important abstraction mechanism is missing. Without abstraction over types, \nthe nonoverlapping universe of primitive types, the separate class hierarchies of user classes, the system \nof tuple types, and the system of function types would be independent of each other forever. Type parameters \nprovide this capability, allowing classes and methods to be parameterized over the types of values they \nmanipulate, greatly increasing the expressive power of the language. A type parameter T introduces a \nnew name for a unknown type within the scope of its declaration. The unknown type is universally quanti.ed \nin the sense that it could be instantiated to any type at a usage site. Within the scope of declaration, \nthe new unknown type T is unrelated to all other types except itself. The compiler typechecks the body \nof the class or method without any information about T except that it supports the same four basic operators \nthat all types support, namely == != ! ?. Separate typechecking means that the bodies of parameterized \ndeclarations are checked independently of any instantiation and type errors in the declaration do not \ngenerate type errors at the usage sites3 . (d1) class List<T> { (d2) var head: T; (d3) var tail: List<T>; \n(d4) new(head, tail) { } (d5) } (d6) def apply<A>(list: List<A>, f: A -> void) { (d7) for (l = list; \nl != null; l = l.tail) f(l.head); (d8) } In (d1-8) we implement a cons list using a generic class. Objects \nof the class (d1) store a value (d2) of the generic type and a reference to the next link (d3) in the \nlist. A generic convenience method (d6) provides a handy way of iterating over the elements of a list \nand applying a function to each element. (d9) def print(i: int) { ... } (d10) var a = List<int>.new(0, \nnull); (d11) var b = List<(int, int)>.new((3, 4), null); (d12) apply<int>(a, print); (d10 ) var c = List.new(0, \nnull); (d11 ) var d = List.new((3, 4), null); (d12 ) apply(c, print); (d13) var e = List<bool>.?(a); \n(d14) var f = List<void>.?(a); At every usage site of a parameterized class or method, type ar\u00adguments \nare supplied for the type parameters, either explicitly by the programmer or inferred by the compiler. \nExplicit type argu\u00adments to a parameterized class or method can always be supplied with a <...> suf.x \n(d10-12) immediately following the identi.er, but the compiler can usually infer them (d10 -12 ). Virgil \nuses a best-effort type inference algorithm4 for type arguments to both classes and methods. Virgil does \nnot perform type erasure; instead, enough information is always retained to recover the type argu\u00ad 3 \nC++ templates are typechecked at instantiation time, leading to famously huge and inscrutable error messages \nwhere type arguments are already substituted for type parameters.  ments of any parameterized usage. \nThat means, among other things, that polymorphic types can be distinguished at runtime (d13-14). Any \ntype can appear as a type argument. That means we can use our list class to create and manipulate homogeneous \nlists of any type, including primitives, objects, tuples, functions, and even void. Allowing unrestricted \ntype arguments has subtle but impor\u00adtant bene.ts. First, since there are no exceptions or special cases \nto remember, the language is actually simpler and more intuitive; any type can be a type argument, no \nexceptions. Secondly, reuse of data structures and functions is greatly enhanced by composability; we \ncan easily create lists of functions, or lists of tuples of func\u00adtions, or functions of arrays of lists \nof functions. Third, it promotes a programming style based on representation independence where no information \nabout the representation of a type is necessary for the class or function to perform its role. (e1) def \ntime<A, B>(func: A -> B, a: A) -> (B, int) { (e2) var start = clock.ticks(); (e3) return (func(a), clock.ticks() \n-start); (e4) } (e5) print(time(sqrt, 37).1); In (e1-5) we make use of three language features to implement \na method that times the execution of a function applied to some given arguments. First, our utility accepts \na function as the routine to be timed. Second, it has type parameters that abstract the parameter and \nreturn type of that function, allowing it to be used with any function and arguments, including tuples \nor even void. Third, it uses a tuple to return both the time elapsed and function s result, even if the \nfunction returned void or another tuple.  2.5 Type Constructor Summary Virgil s type system employs \n.ve kinds of type constructors. Four language-provided type constructors represent primitive types, ar\u00adrays, \ntuples, and functions. The .fth kind of type constructor repre\u00adsents the types of class objects; a new \nclass type constructor is cre\u00adated for each user-de.ned class. The table below summarizes the type constructors, \ntheir type parameters, and their syntax. In this table, the symbol 8 means contravariant, and . means \ncovariant. Typecon Type Parameters Syntax Primitive void|int|byte|bool Array T Array<T > Tuple .T0 \u00b7 \n\u00b7 \u00b7 . Tn ([T (,T )*]) Function 8Tp . Tr T -> T class X T0 \u00b7 \u00b7 \u00b7 Tn X[<T (,T )*>] 3. Patterns Language \ndesigners face an unending series of tradeoffs when choosing which features to add, tradeoffs which become \nmore complex and dif.cult as the language grows. Abstract data types, interfaces, ad hoc polymorphism, \nand variant types are useful, but how should they be prioritized relative to other features? Our experience \nwith the design of Virgil suggests that these features can at least be postponed. Instead we found that \nthe four principal language features were often powerful enough to emulate these other features with \nmulti-paradigm design patterns made possible by the close collaboration of several features at once. \n3.1 Interface Adapters While other OO languages offer complex patterns of inheritance such as interfaces \nand traits, Virgil offers only single inheritance 4 Type inference with both subtyping and type parameters \nis tricky business; see for example [23]. Our compiler uses a bi-directional typechecking approach, but \nthe details are beyond the scope of this paper. between classes. More complex patterns of inheritance \nand inter\u00adface speci.cation can be emulated with .rst class functions. The most straightforward technique \nfor emulating interfaces in Virgil is to de.ne a class whose .elds store .rst-class functions representing \nthe methods of the interface, each with a name and a type. This class is essentially a dictionary of \nnamed interface methods. What would be somewhat awkward and verbose to de\u00ad.ne in other languages is actually \nquite easy in Virgil thanks to a compact syntax for declaring immutable public .elds that are ini\u00adtialized \nin the constructor. In (f1-5) we see an example where the DatastoreInterface de.nes a dictionary with \ncreate, load, and store operations, each of which is a .eld which stores a func\u00adtion. (f1) class DatastoreInterface( \n(f2) create: () -> Record, (f3) load: Key -> Record, (f4) store: Record -> ()) { (f5) } Virgil s ability \nto bridge the object and functional paradigms with class and object methods makes it easy for another \nunrelated class to simply construct an instance of the interface using its own methods. In (g6-7), the \nDatastoreImpl class adapts itself to the DatastoreInterface by instantiating an instance of the class, \npassing object methods bound to itself (i.e. the this object); invocations of those functions through \nthe interface will receive the bound this as the receiver object. (g1) class DatastoreImpl { (g2) def \ncreate() -> Record { ... } (g3) def load(k: Key) -> Record { ... } (g4) def store(r: Record) { ... } \n(g5) def adapt() -> DatastoreInterface { (g6) return DatastoreInterface.new( (g7) create, load, store); \n(g8) } (g9) } Tradeoffs. One advantage to this pattern is that an adapter ob\u00adject can be constructed \nfrom any set of functions, regardless of their names. A class can implement multiple interfaces, and \nthe names of the methods it uses to implement the interface are immaterial, as long as the methods have \nthe correct signature, which avoids name clashes. In fact, there is no requirement that an interface \nbe constructed from class methods at all. An interface adapter object could as well be constructed from \ntop-level functions, built-in op\u00aderators, or any other functions at hand. Notice that in (g2-4), the \nmethods could as well have had any names, since they are simply used as functions when constructing the \ninterface adapter object (g6-7). Unfortunately, because Virgil has no implicit type conver\u00adsions, object \ntypes do not subsume to the interface types they imple\u00adment. Thus the primary disadvantage of this pattern \nis that to use an object as an instance of the interface always requires an extra step, usually the construction \nof another object. Another drawback is that the programmer must manually specify the mapping between \nexist\u00ading functions to the interface by supplying them to the constructor of the interface object, as \ndone in the adapt method in (g5).  3.2 Emulating Abstract Data Types Abstract data types (ADTs) are \nuseful when modeling a type that has unknown representation but has a set of associated operations with \nnames and signatures. One way to model an ADT in Virgil is to parameterize an interface (h1-7). In this \nexample we model a number that has an unknown representation but a known set of associated operations \nand some named values. The availability of the basic operators like int.+ as .rst class functions makes \nit easy to adapt the basic primitive type int to the ADT interface (h8-9).  In this pattern the interface \nis not bound to a particular value or object instance; instead, the values are external so that they \ncan be manipulated by the client. (h1) class NumberInterface<T>( (h2) add: (T, T) -> T, (h3) sub: (T, \nT) -> T, (h4) compare: (T, T) -> bool, (h5) one: T, (h6) zero: T) { (h7) } (h8) var IntInterface = NumberInterface.new( \n(h9) int.+, int.-, int.==, 1, 0); A class interface is not always necessary, especially if the num\u00adber \nof operations associated with the type is very small. In (i1-8) we see one way to design a hash table \nusing the abstract data type pattern, but without the need to supply an interface object. (i1) class \nHashMap<K, V> { (i2) def hash: K -> int; // hash function (i3) def equals: (K, K) -> bool; // equality \nfunction (i4) new(hash, equals) { } (i5) def get(key: K) -> V { ... } (i6) def set(key: K, val: V) { \n... } (i7) def apply(f: (K, V) -> void) { ... } (i8) } HashMap abstracts over the key and value types \nusing type pa\u00adrameters and accepts the hash and equals functions as parame\u00adters to the constructor (i4). \nThis allows this one HashMap imple\u00admentation to be used with any key or value type. This is in con\u00adtrast \nto the typical object-oriented approach, where every key type would necessarily be a class type and implement \nhash and equals methods with appropriate signatures. With unrestricted type param\u00adeters, even primitives \n(i15) and tuples (i18) can serve as the key, as long as they have the associated methods. Moreover, different \nhash and equals methods can be used on a per-instance basis (i13-14) with the help of class methods and \n.rst-class operators like == that bridge the gap between the object-oriented and functional worlds. (i9) \nclass X { (i10) def deepEquals(x: X) -> bool { ... } (i11) def hash() -> int { ... } (i12) } (i13) HashMap<X, \nint>.new(X.hash, X.deepEquals); (i14) HashMap<X, int>.new(X.hash, X.==); (i15) HashMap<int, X>.new(int.!, \nint.==); (i16) var h2: (int, int) -> int; (i17) var e2: ((int, int), (int, int)) -> bool; (i18) HashMap<(int, \nint), X>.new(h2, e2); Tradeoffs. The primary disadvantage to using type parameters and functions to \nmodel abstract data types, rather than a module system, is that type parameters require the client code \nto be param\u00adeterized over the abstract data type. There must be a scope where the client code has declared \na type parameter, whereas with a mod\u00adule system the type can be made available in the namespace of the \nclient code. In the HashMap example, the client code instantiates the HashMap code with the types of \nthe keys and values, but in an\u00adother example, such as the NumberInterface, the code that pro\u00advides the \nabstract data type must instantiate not only the number interface, but the code manipulating the numbers. \n 3.3 Emulating Ad-hoc Polymorphism Virgil provides no direct support for ad-hoc polymorphism such as \nmethod overloading. While other languages make use of argu\u00adments types at call sites to perform overload \nresolution, Virgil al\u00adlows methods to be used in a .rst-class way where enough con\u00adtext may not be available. \nFor example, suppose a method m has several overloaded variants but is used simply as o.m, lacking any \narguments for overload resolution. The inherent ambiguity would require a manual resolution mechanism. \nVirgil chooses to disallow overloading altogether, requiring every method in the same class to have a \nunique name. It views overloaded methods as parameter\u00adized methods, with the type parameters being instantiated \nwith the various overloadings at call sites. This approach admits an emula\u00adtion of method overloading \nand still allows methods to be used in a .rst-class way without ambiguity. Consider a use case like print. \nRemembering to call printInt versus printBool versus printString can become cumbersome. A somewhat cleaner \nsolution is to use a design pattern that admits a small number of overloads, making use of type parameters \nand casts: (j1) def print1<T>(fmt: string, a: T) { (j2) if (int.?(a)) printInt(fmt, int.!(a)); (j3) if \n(bool.?(a)) printBool(fmt, bool.!(a)); (j4) if (string.?(a)) printString(fmt, string.!(a)); (j5) if (byte.?(a)) \nprintByte(fmt, byte.!(a)); (j6) } (j7) print1(\"Result: %1\\n\", 0); (j8) print1(\"Boolean: %1\\n\", false); \n(j9) print1(\"Hello %1!\", name); A parameterized method (j1) is the starting point of this pattern. The \nparameterized method dispatches to the appropriate print* method through a chain of dynamic type queries \nand type casts. The user of the library calls the parameterized method (j7-9), with the compiler inferring \nthe type arguments. The chain of dynamic casts in (j2-5) will be optimized by the compiler. First, the \ncompiler will specialize the parameterized method for each unique type argu\u00adment, then optimize each \nversion independently. The type queries and casts in each version can be decided statically, the chain \nof if statements will be folded away, and only a call to the correspond\u00ading version remains, which the \ncompiler may then inline, resulting in code just as ef.cient as if the caller had called the appropriate \nprint* method directly. Tradeoffs. One clear disadvantage of this approach is that some static checking \nis lost since the parameterized method must neces\u00adsarily accept any type for its type argument. Unless \nall possible types are covered by some case, the programmer will have to re\u00adsort to producing a runtime \nerror or de.ning some default behavior 5. The bene.t, aside from not needing to remember to call the \nap\u00adpropriate unique method, is that there is no longer any ambiguity in .rst-class functions, and the \nparameterized method can be used in a .rst-class way like other methods, supplying explicit type ar\u00adguments \nif necessary. Multi-argument overloads are possible with tuples, but type matching can become painfully \nugly, so in practice one tends to write print1, print2, etc. For complex cases this is admittedly an \nunsatisfyingly clunky solution, but it works and is very ef.cient. It does not require boxing arguments \nin any situa\u00adtion, it optimizes away dynamic type tests, and does not require a varargs mechanism.  \n3.4 A Polymorphic Matcher Subtyping provides a language with a form of information hid\u00ading where the \nexact type of an expression is intentionally for\u00adgotten when it is used in a context requiring only the \nsupertype. This ability of subtyping can also hide information about type pa\u00adrameters. For example, declaring \na base class Any and a subclass Box<T> extends Any allows any value to be boxed and used 5 Our implementation \nof print accepts the standard primitive types and also functions of type StringBuffer -> void; we equip \nthose classes that need to be printed with methods that render the object into a StringBuffer; we can \nthen simply pass o.render to the print method.  wherever the type Any is accepted. Instead of language-provided \nclasses for each primitive type such as java.lang.Integer, java.lang.Double, etc, a single pair of user-de.ned \nclasses suf\u00ad.ces. (k1) class Matcher { (k2) var matches: List<Any>; (k3) def add<T>(f: T -> void) { (k4) \nmatches = List.new(Box.new(f), matches); (k5) } (k6) def dispatch<T>(v: T) { (k7) for (l = matches; l \n!= null; l = l.tail) { (k8) var f = l.head; (k9) if (Box<T -> void>.?(f)) (k10) return Box<T -> void>.!(f).unbox()(v); \n(k11) } (k12) } (k13) } Hiding information about type parameters using class subtyp\u00ading allows us to \nimprove upon our previous emulation of method overloading. In (k2-5), the matcher wraps each function \nin a Box and intentionally forgets its type, treating it as Any, in order to put it in a list. To dispatch \non a polymorphic value, since Virgil does not erase type parameters but can in fact distinguish a Box<int \n-> void> from a Box<bool -> void>, the matcher can search the list for a Box that contains a function \nof the right type that can han\u00addle the polymorphic value. In (m1-8) we see examples of how we could use \nthe Matcher to accomplish polymorphic dispatching for printing without having to write a series of type \nqueries and casts. The Matcher class need only be written once, and it can be reused in whatever context \nis necessary. 6 (m1) var m = Matcher.new(); (m2) m.add(printInt); (m3) m.add(printBool); (m4) m.add(printString); \n(m5) ... (m6) m.dispatch(\"Result: %1\", 1); // printInt (m7) m.dispatch(\"Boolean: %1\", true); // printBool \n(m8) m.dispatch(\"Hello %1\", name); // printString Tradeoffs. The polymorphic matcher pattern improves \nupon the manual type dispatching approach but still lacks static checking. Since the matcher s dispatch \nmethod can be instantiated with any type argument, it may fail at runtime if an appropriate method is \nnot found in the list.  3.5 Emulating Variant types The ability of subtyping to hide information can \nemulate a variety of ad-hoc polymorphism patterns, including the ability to have a number of variant \ntypes, each with the same operation. (n1) class Instr { (n2) def emit(buf: Buffer); (n3) } (n4) class \nInstrOf<T> extends Instr { (n5) var emitFunc: (Buffer, T) -> void; (n6) var val: T; (n7) new(emitFunc, \nval) { } (n8) def emit(buf: Buffer) { (n9) emitFunc(buf, val); (n10) } (n11) } (n12) var i = InstrOf.new(asm.add, \n(rax, rbx)); (n13) var j = InstrOf.new(asm.addi, (rax, -11)); (n14) var k = InstrOf.new(asm.neg, rax); \n 6 Notice also that (m2-8) uses functions with multiple parameters, which works seamlessly due to the \nclean integration between functions and tuples. The example above shows one approach to representing \nma\u00adchine instructions in the backend of a compiler. Instead of manu\u00adally de.ning classes that represent \ninstructions with one operand, two operands, an operand and immediate, etc, the four main fea\u00adtures of \nVirgil can be used to model all variants of instructions with just two class de.nitions. We .rst declare \na base class for instruc\u00adtions (n1) with an abstract method (n2) that emits the instruction to some buffer. \nThen a parameterized subclass (n4) can be instanti\u00adated to each of the different variants, with the function \nthat assem\u00adbles the instruction and the operands themselves stored as .elds (n5-6). The implementation \nof emit then simply calls the supplied function with the operands and the buffer (n9). Without writing \nany more classes, we can reuse methods from the assembler itself (n12\u00ad14) with various kinds of operands \nto create instruction variants. The Instr class in this case is like a super-closure: it not only closes \nover the unknown (variant) parts of the instruction, but can have more than one operation, such as iterating \nover the register operands of the instruction for register allocation. If pattern matching is required \non instructions, we can use a cascade of dynamic type casts and type queries (n15-20), or use a polymorphic \nmatcher from (k1-13). (n15) if (InstrOf<Reg>.?(i)) (n16) printReg(InstrOf<Reg>.!(i)); (n17) if (InstrOf<(Reg, \nReg)>.?(i)) (n18) printRegReg(InstrOf<(Reg, Reg)>.!(i)); (n19) if (InstrOf<(Reg, int)>.?(i)) (n20) printRegInt(InstrOf<Reg>.!(i)); \n This pattern requires all four features to work. Without classes and inheritance, we couldn t hide the \nactual representation type by having an unparameterized superclass, but would instead need some other \nform of existential quanti.cation, a universal supertype, support for algebraic data types, etc. Without \n.rst-class functions, some other form of polymorphism would be required to supply the logic for assembling \neach instruction, e.g. subclassing the Instr class with a lot of redundant classes or using a switch \nor enu\u00admeration, all of which mean writing calls to assembler methods instead of just passing them around. \nWithout tuples, any variant that consisted of more than one parameter would require an aggre\u00adgate datastructure \nof some kind, such as another class. And .nally, without type parameters, some universal representation \nwould have been required to store all the different variants in some polymorphic location. Tradeoffs. \nEmulating variants suffers from two main problems. The .rst problem is similar to emulating ad hoc polymorphism \nwith dynamic casts; a loss of static checking in pattern matches (n15\u00ad20), where the programmer can too \neasily miss a case. The second problem is both an advantage and a disadvantage. This pattern allows an \nunbounded number of new variants to be created simply by instantiating the InstrOf class with new values \nand methods, which is an advantage for extensibility but is a disadvantage if the programmer wants to \nintentionally bound the set of variants that can be created.  3.6 Type Variance Languages that contain \nboth subtyping and type parameters face type variance problems. Java, C#, and Scala have various solutions \nthat range from use-site annotations to declaration site annotations, wildcards, raw types, unsafe casts, \nor all of the above. Virgil only offers variance for tuples and function types; but surprisingly these \ntwo features reduce the need for other kinds of variance. Returning to the cons list example (p1-p10), \nassume for the moment that the .elds of this class are immutable, written only once in the constructor. \nSuppose we have types Animal and Bat with Bat extends Animal. We might intuitively consider List to be \ncovariant, i.e. List<Bat> <: List<Animal>. In the example below (o2), we have a function f that performs \nan operation on every element in a list, and (o5) we have b of type List<Bat>. Virgil classes are invariant \nin their type parameters, so applying f to b is not well-typed (o6).  (o1) def g(a: Animal) { ... } \n(o2) def f(list: List<Animal>) { (o3) for (l = list; l != null; l = l.tail) g(l.head); (o4) } (o5) var \nb: List<Bat>; (o6) f(b); // ERROR (o7) apply(b, g); // OK However, we can invert the control .ow; instead \nwe pass a function g of type Animal -> void which performs the operation for just one Animal to our utility \nfunction apply from (d6). Due to contra-variant function parameter types, Animal -> void <: Bat -> void, \nand (o7) is well-typed. As another example, consider again the HashMap class (h1-h8). If Virgil supported \ndeclaration-site variance annotations, the de\u00adsigner of this class might want to add a contra-variance \nannotation to K so that HashMap<A, V> <: HashMap<B, V> for B <: A. In another situation, a client might \naccept a HashMap<K, V> but only use the get method. In this case, it would be tempting to add vari\u00adance \nat the use site, since the map could be considered co-variant in V and contra-variant in K at that use \nsite. But notice that this is ex\u00adactly the variance of the get method itself, and since function types \ndo have variance, it would be better if the client simply accepted a function of type K -> V, and users \ncould pass the get method of their HashMap, or some other function of their choosing. The client is thus \nmore general, no longer dependent at all on the type of the object (if any) bound to the closure. The \nproli.c reuse of methods from objects radically simpli.es libraries. For example, with help from tuples, \nfunctions, and vari\u00adance, the call a.apply(b.add) copies the contents of HashMap a into HashMap b, without \neven writing a loop or burdening the li\u00adbrary with another convenience method such as addAll. A more \nterse functional style transfers well to other kinds of datastructures, including arrays, sequences, \nmaps, matrices, etc. All manner of fa\u00admiliar operators from functional libraries such as map, fold, zip, \nand unzip are easily de.ned, and surprisingly they don t require variance annotations. Tradeoffs. The \nlack of variance for class types and the lack of either declaration or use site constraints on type parameters \nforces a different kind of programming style. This can make it hard to port code from existing languages \nthat makes use of these features, necessitating both local refactorings and some redesign to rely more \non a functional style. C# 2.0 debuted without variance annotations for generics, but they were later \nadded. We believe this design choice was made because .rst-class functions were only timidly employed \nin their .rst inception as invariant, named delegate types. It may be that evolution of existing programs \nto a more functional style was deemed too radical at the time. 4. Implementation Issues Language goals \nsuch as supporting system and low-level program\u00adming bring important ef.ciency considerations, posing \nchallenges for implementing advanced features. This has driven Virgil s de\u00adsign throughout its earliest \nembodiment for microcontroller pro\u00adgramming until today. The pressure to implement all of Virgil s constructs \nwithout undue reliance on implicitly allocating mem\u00adory on the heap has been a substantial motivator \nfor keeping its feature set conservative. Key in meeting these ef.ciency considera\u00adtions is proper implementation \nof tuples and type parameters. This section describes the unique problems posed by tuples in Virgil and \npresents a solution based on a .attening strategy that guarantees that no implicit boxing or unboxing \noperations need to be inserted. In fact, Virgil s native implementation never allocates memory on the \nheap except when done explicitly by the programmer but still retains all the language .exibility described \nin previous sections. 4.1 Tuple Ambiguity The uniform treatment of functions that accept multiple parameters \nas functions that accept a single tuple parameter is unfortunately not so uniform in implementation. \nThe interaction between tuples and the other features of Virgil can give rise to implementation ambiguity \nin several different ways. In (p1-5) f and g are both of type (int, int) -> void, and the variable x \ncould refer to either at runtime (p3). Two potential problems arise. The caller could legally pass either \ntwo integers (p4) or a tuple of two integers (p5). What calling convention would the compiler use at \nthese call sites? What about within the body of f which expects two integers and g which expects a tuple? \nIn this case, using tuple types to model multiple arguments creates a potential ambiguity because functions \ncan be .rst-class. (p1) def f(a: int, b: int) { ... } (p2) def g(a: (int, int)) { ... } (p3) var x = \nz ? f : g, t = (0, 1); (p4) x(0, 1); // ambiguous invocation (p5) x(t); // ambiguous invocation (p6) \ndef r<A>(a: A) { ... } (p7) var y = z ? r<(int, int)> : f; (p8) y(0, 2); // ambiguous invocation A parameterized \nfunction like the one de.ned in (p6) can also give rise to ambiguity. The method r<(int, int)> (p7) could \nbe used anywhere a function of type (int, int) -> void is ex\u00adpected (p8). Ambiguity can also arise with \nsimple method overrid\u00ading. A class may declare a method (p11) with individual parameters that is overridden \nin a subclass (p14) with an implementation that has a single tuple parameter, leading to ambiguity at \nvirtual method invocation sites (p17). (p10) class A { (p11) def m(a: int, b: int) { ... } (p12) } (p13) \nclass B extends A { (p14) def m(a: (int, int)) { ... } (p15) } (p16) var a = z ? A.new() : B.new(); (p17) \na.m(1, 2); // ambiguous invocation One solution is to place dynamic checks at invocation sites to determine \nwhether the function to be invoked requires a tuple (i.e. boxed) or multiple scalars (i.e. unboxed) representation \nfor its arguments. The Virgil interpreter uses this approach, but the checks are expensive. A small improvement \ncan be made when compiling to a target machine by eliminating the dynamic checks at call sites where \nreceiver methods can be statically determined. This is still suboptimal since too many such sites would \ngive poor performance and might require allocating memory on the heap for tuples. Instead our compiler \nnormalizes the program, rewriting all uses of tuples to eliminate such overhead. This ensures that all \nmethod calls pass scalar arguments regardless of whether the parameters were originally tuples or scalars, \narrays and .elds store dense scalar values, and operations on tuples never allocate on the heap, on both \nthe JVM target and the native x86 targets.  4.2 Normalization Tuples are ideal values: they are immutable, \nhave no identity, and are not extensible. A program cannot discern implementation de\u00adtails such as whether \na tuple is represented by a record or by in\u00addividual scalars. Normalization is the process by which the \nVirgil compiler converts all uses of tuples into uses of scalars, regard\u00adless of where they occur, including \nparameters, return values, local variables, array elements, .elds, and elements inside other tuples. \nVariants of normalization (also known as scalar replacement of ag\u00adgregates or .attening) have been employed \nin numerous functional language implementations, e.g. [3] and [36]. Reducing tuples to individual scalar \nvalues simpli.es the program to a normal form where tuples no longer appear and exposes the individual \nvalues to classical compiler optimizations. It also eliminates the ambigui\u00adties demonstrated in the previous \nsection; all normalized functions accept zero or more scalars and return zero or more scalars.  The \ncompiler performs normalization on an internal represen\u00adtation of the program, but we can illustrate \nthe basics of the al\u00adgorithm with source-to-source translations. First, we see how the compiler treats \nlocal variables (q1) and parameters (q2) that are tuples, replacing them with multiple local variables \n(q1 ) or param\u00adeters (q2 ). A use of a variable which was formerly a tuple (q3) is expanded to the normalized \n(q3 ) variables. An access of a tuple element (q4) is replaced with a reference to the corresponding \nnor\u00admalized variable (q4 ). Parameters (q6) and variables (q7) of type void are replaced with nothing \n(q6 -7 ) 7 . (q1) var b = (\"hello\", 15); (q2) def m(a: (string, int)) { ... } (q3) m(b); (q4) m(\"goodbye\", \nb.1); (q5) m(\"cheers\", (11, 22).0); (q6) def f(v: void) { ... } (q7) var t: void; (q8) f(t); => (q1 \n) var b0 = \"hello\", b1 = 15; (q2 ) def m(a0: string, a1: int) { ... } (q3 ) m(b0, b1); (q4 ) m(\"goodbye\", \nb1); (q5 ) m(\"cheers\", 11); (q6 ) def f() { ... } (q7 ) (q8 ) f(); Normalization can potentially rewrite \nevery expression in the program, whether it be a .eld access, array element access, array creation, method \ncall, comparison, etc. Care is taken to avoid dupli\u00adcating or reordering side-effects in expressions; \nthis is facilitated by the compiler s internal SSA representation of the code. Fields are normalized \nby replacing with them with zero or more normalized .elds; .eld accesses are normalized into multiple \nreads or writes as appropriate. Array element accesses require similar normalization. Depending on the \ncompilation target, an array of tuples may be normalized to an array whose elements store tuple elements \nnext to each other in memory, or to be multiple arrays, each of which stores one element of the tuple. \nReturns of a tuple become a re\u00adturn of multiple values, utilizing multiple return registers on native \ntargets. There are several corner cases that are not immediately obvi\u00adous. Accesses to .elds of type \nvoid are simply removed and re\u00adplaced with null checks; this ensures that a null dereference always throws \nan exception, regardless of the .eld s type. Similarly, arrays of void require no storage for their elements, \nbut accesses are du\u00adtifully bounds checked. The JVM does not support arrays of void so such arrays are \nrepresented with a java.lang.Integer object which distinguishes between null and an array with a length. \nOn native targets a two-word array object that only stores the array 7 Normally programmers do not explicitly \nuse variables of type void, but they often appear when expanding polymorphic code. length is suf.cient. \nThe JVM also does not support returning mul\u00adtiple values from a method call. In this case the Virgil \ncompiler inserts a tuple creation at the return site and deconstructs the tuple return value after call \nsites. Normalization is modular; normalizing a method s body does not require knowledge of the call sites, \nnor do call sites require knowledge of the methods which they call. However, normalization relies on \nknowing the types of all expressions and methods; this is only possible if type arguments have been substituted \nfor type parameters, which is the subject of the next section. Tradeoffs. Normalization removes all boxing \nrelated to tuples, achieving Virgil s implementation goal of avoiding implicit mem\u00adory allocations. For \nsmall tuples, normalization has much better performance than boxing, but large tuples might actually \nperform better if allocated on the heap, depending on how the program uses them; in a program that uses \nlarge tuples, reading and writing point\u00aders to objects on the heap may be cheaper than reading and writing \nthe many tuple elements individually.  4.3 Monomorphization In Virgil, runtime information about type \narguments is needed in some operations, such as allocating or accessing an array of poly\u00admorphic type, \nperforming a dynamic type cast or type query in\u00advolving polymorphic types, or accessing a .eld of a polymorphic \ntype. We saw dynamic type casts and queries were key in allow\u00ading several patterns such as the polymorphic \nmatcher. In the Vir\u00adgil interpreter, type arguments are passed as invisible arguments to polymorphic \nfunction calls and stored as type information within objects, arrays and closures. Even with lazy evaluation \nof the type expressions that represent type arguments, this exacts a consider\u00adable runtime cost. The \nVirgil compiler instead employs monomorphization, where a specialized version of each polymorphic class \nor method is gen\u00aderated for each distinct assignment of type arguments to type pa\u00adrameters. Thus an object \nof type List<(int, int)> has a dif\u00adferent representation than List<byte>, and similarly the method id<int> \nhas a distinct representation from id<byte>. Once the representation of all classes and methods is obtained \nthrough spe\u00adcialization, no type parameters appear in the program. The result\u00ading code is therefore monomorphic \nand can use the most ef.cient, dense representations. Monomorphization affords the opportunity for whole-program \nnormalization which eliminates all tuples from the program, and therefore guarantees that programs can \nbe com\u00adpiled to a form where implicit memory allocations on the heap are not required. This is key for \nsome systems programming problems where some code must be able to run without interruption from the garbage \ncollector, and thus may not allocate memory 8 . Tradeoffs. The implementation of parametric polymorphism \nis full of tradeoffs and has been the subject of much research which we cannot fully summarize in the \nspace alotted. The main draw\u00adback to monomorphization is that polymorphic code can be dupli\u00adcated repeatedly, \nperhaps exponentially, even in.nitely if the lan\u00adguage allows polymorphic recursion, which Virgil disallows \n9. The result can be code explosion where polymorphic methods are du\u00adplicated repeatedly. In our experience, \nthis has not been an issue in real programs. Other language implementations use monomor\u00adphization as \nwell, including MLton [35] which employs whole\u00adprogram monomorphization quite sucessfully for ML, and \nC++ does complete template expansion, which is similar to monomor\u00adphization. Some programming guidelines \ncan reduce code explo\u00ad 8 This has been a constant source of problems in system code written in Java like \nJikes RVM and Maxine VM, especially when writing the garbage collectors themselves in Java. We wrote \nour GC in Virgil without encountering these problems.  sion [33]. Another drawback is that monomorphization \nalso re\u00adquires the whole program to be available, or it must fall back on a universal representation \nwhen instantiations are not known across compilation unit boundaries. One alternative to monomorphization \nis to remove type pa\u00adrameters from the program by simply erasing them [22]. This is only possible if \nall values have a universal representation (e.g. Scala), the compiler forces a universal representation \nthrough box\u00ading (most functional language implementations), or by disallow\u00ading some types as type arguments \n(e.g. Java). With erasure, some polymorphic operations can only be implemented by passing a rep\u00adresentation \nof the type arguments at runtime [15]. Both Scala and Java perform type erasure, but do not pass a runtime \nrepresenta\u00adtion of type parameters, meaning that some polymorphic opera\u00adtions, such as allocating an \narray of a polymorphic type or casting a polymorphic type, are simply not allowed. Simply put, type erasure \ncannot work for Virgil. Also note that both Scala and Java target the JVM, which does not support type \nparameters; dynamic type casts must be inserted to satisfy the JVM s bytecode veri.er. In contrast, monomorphization \nrequires no casts to be inserted. To be fair, Scala recently attempted to address the problem of missing \ntype information with manifests, which are indeed a representation of type parameters, but at .rst they \nwere manual and not fully integrated with the rest of the language. Scala 2.10 uses type tags which can \nbe passed as implicit parameters, subsuming the role of manifests. However, they require the programmer \nto request a type tag be passed to a class or method in order to perform some polymorphic operations. \nScala also recently experimented with annotations to allow programmers to manually instruct the compiler \nto perform specialization [7]. In Java, a programmer can explicitly pass instances of java.lang.Class \nalong with type parameters to act as the miss\u00ading type information, but only one level deep: class objects \ndo not contain information about type arguments to parameterized classes. C# coined the term rei.ed generics; \nthe semantics are closest to Virgil s type parameters. C# mainly targets the CLR which pro\u00advides support \nfor type parameters in bytecode, and the virtual ma\u00adchine performs specialization on demand [18], sharing \nidentical machine code for some specializations. When one can assume a VM with a dynamic compiler, late \nspecialization has strong advan\u00adtages: it avoids the need for the whole program at compile time and reduces \ncode explosion. However it is not an option for com\u00adpiling Virgil statically. Other differences are that \nC# has no tuples, does not allow void as a type argument, and does not allow casts between, e.g., a type \nparameter and a concrete type. Most functional language implementations use a mix of special\u00adization \nand boxing, where the overhead of boxing is removed wher\u00adever the compiler has full knowledge of the \nrepresentation of values [35], even for tuples [36]. There are more complicated schemes for implementing \nparametric polymorphism, such as intensional type analysis [15] which relies on representation passing. \nIn some sense, this is the implementation adopted by the Virgil interpreter as dis\u00adcussed before. 5. \nExperience The balance of features in Virgil has proven to be quite practical in writing small to medium-scale \nprograms. Our experience in writing over 100,000 lines of Virgil code has motivated continual re.ne\u00adment \nof the language. A self-hosted, fully-bootstrapped compiler written in Virgil is the primary implementation. \nIt features com\u00adpilation to both the JVM and native x86 targets, includes a stan\u00addard suite of intraprocedural \ncompiler optimizations, array bounds check elimination, sophisticated instruction selection, a linear-scan \n9 Virgil disallows polymorphic recursion but it is not currently enforced. register allocator, whole-program \noptimizations such as monomor\u00adphization, as well as sophisticated dead code and dead data elimi\u00adnation \n[31]. On native targets Virgil provides a precise semi-space garbage collector (also written in Virgil), \na runtime system (writ\u00adten in Virgil) and direct access to kernel system calls. The compiler also offers \nancillary tools such as a full interpreter, a pro.ler, and a code coverage tool. Despite its small size \n(just 25,000 lines of code), the Virgil compiler generates decent quality machine code and compiles very \nfast. Virgil III is open source and freely avail\u00adable at http://code.google.com/p/virgil. We also wrote \na small number of applications, ported several benchmarks, and created a vast battery of test programs. \nWe found, like many Scala programmers, that the free intermixing of func\u00adtions with objects brings a \nnew kind of expressiveness beyond pure object-oriented and pure functional styles. Objects work well \nfor encapsulating state and related methods, while functions excel at small-scale reuse, such as that \nfound in operations like map, fold, and sort. Our experience has been that unrestricted type argu\u00adments \nand cheap access to tuples have markedly increased expres\u00adsiveness beyond simply throwing objects and \nfunctions together into the same language. For example, the ability to quickly de.ne a list of tuples \nand then sort them by, say, the .rst element, has been very convenient for rapid prototyping. Every pattern \ndescribed in this paper has made it into practical use. The emulation of abstract data types has direct \napplicability in the design of reusable data structures like maps; the emulation of ad hoc polymorphism \nhas been useful in printing and logging; and the emulation of variant types is used the Virgil compiler \nbackend to represent and manipulate machine instructions without requiring a complete duplication of \nthe x86 assembler s interface, nor the de.nition of many small variant classes. 6. Conclusion Virgil \nbrings a new kind of harmony between classes, functions, tuples, and type parameters in a statically-typed \nsetting. The whole is more than the sum of its parts; these features complement each other in subtle \nand powerful ways that reduce the need for more language features, including complex patterns of inheritance, \ntype variance annotations, and a universal super type. Perhaps most in\u00adterestingly, multi-paradigm design \npatterns can be built that al\u00adlow emulation of features not directly supported in the language, including \nabstract data types, ad-hoc polymorphism, and variant types. Each emulation presents some tradeoffs, \nand balancing the inclusion of new features versus those tradeoffs is ongoing chal\u00adlenge in the art of \nlanguage design; a challenge which we by no means claim to have conquered. Moreover, we do not argue \nthat any of the emulated features should necessarily be excluded from this or any other language; rather \nthat the use of patterns can give designers more time to prioritize new language features and ensure \nthey compose well. 6.1 Future Work Virgil lacks many advanced features and there are still rough edges. \nFor example, we .nd our own emulation of printf-like cases still somewhat cumbersome; a well-developed \npattern matching system coupled with a kind of varargs mechanism could greatly increase expressive power \nwithout upsetting the existing design. Our experi\u00adence programming in the language suggests that enumerated \ntypes are of high priority, and certainly other languages offer excellent examples of potential design. \nVirgil lacks a module system, which can offer representation independence and separate compilation units \nfor modularity on a larger scale. Higher-rank polymorphism (i.e. polymorphism over type constructors) \nallows more forms of generic programming [24]. We believe both extensions to be important in the future, \nand like the other features mentioned, Virgil s core design has done nothing to preclude them.  We mentioned \nissues with full monomorphization in section 4.3. We continually track the amount of code expansion due \nto specialization for the compiler and applications we have already built. We consider it an important \ngoal to avoid code explosion, and a hybrid approach to monomorphization is the subject of current research. \nSee for example [29]. Acknowledgments Thanks to Alex Warth, Jan-Willem Maessen, Marek Gilbert, and Jens \nPalsberg for comments on early drafts of this paper. References [1] E. Allen and R. Cartwright. The case \nfor run-time types in generic Java. In Proceedings of the 1st Conference on the Principles and Practice \nof Programming in Java (PPPJ 02). Dublin, Ireland. Jun 2002. [2] C. Baker-Finch, K. Glynn, and S. P. \nJones. Constructed product result analysis for Haskell. In Journal of Functional Programming (JFP), Volume \n14, Issue 2. Mar 2004. [3] L. Bergstrom and J. Reppy. Arity raising in Manticore. In Proceedings of the \n21st International Conference on Implementation and Application of Functional Languages (IFL 09). South \nOrange, NJ. Sep 2009. [4] N. H. Cohen. Type-extension type tests can be performed in constant time. In \nACM Transactions on Programming Languages and Systems (TOPLAS), Volume 13, Issue 4. Oct 1991. [5] J. \nDean, D. Grove and C. Chambers. Optimization of object-oriented programs using static class hierarchy \nanalysis. In Proceedings of the 9th European Conference on Object-Oriented Programming (ECOOP 95). Aarhus, \nDenmark. Aug 1995. [6] A. Diwan, K. McKinley, and J. E. B. Moss. Using types to analyze and optimize \nobject-oriented programs. In ACM Transactions on Programming Languages and Systems (TOPLAS), Volume 23, \nIssue 1. Jan 2001. [7] I. Dragos and M. Odersky. Compiling generics through user-directed type specialization. \nIn Proceedings of the 4th workshop on the Imple\u00admentation, Compilation, Optimization of Object-Oriented \nLanguages and Programming Systems (ICOOOLPS 09). Genova, Italy. Jul 2009. [8] B. Emir, A. Kennedy, C. \nRusso, and D. Yu. Variance and generalized constraints for C# generics. In Proceedings of the 20th Annual \nEuropean Conference on Object-Oriented Programming (ECOOP 06). Nantes, France. Jul 2006. [9] D. Frampton, \nS. M. Blackburn, P. Cheng , R. J. Garner, D. Grove, J. E. B. Moss, and S. I. Salishev. Demystifying magic: \nhigh-level low-level programming. In Proceedings of the International Conference on Virtual Execution \nEnvironments (VEE 09). Washington, DC. Mar 2009. [10] K. Fax\u00b4en. Representation analysis for coercion \nplacement. In Proceedings of the 9th International Symposium on Static Analysis (SAS 02). Madrid, Spain. \nSep 2002. [11] E. Gamma, R. Helm, R. Johnson and J. Vlissides. Design patterns: el\u00adements of reusable \nobject-oriented software. Addison-Wesley Longman Publishing Co., Inc. Boston, MA. 1995. [12] A. Goldberg \nand D. Robson. Smalltalk-80: the language and its implementation. Addison-Wesley Longman Publishing Co., \nInc. Boston, MA. 1983. [13] Guava: Google Core Libraries for Java 1.5+ http://code.google.com/p/guava-libraries/ \n[14] J. J. Hallett, V. Luchangco, S. Ryu and G. L. Steele Jr. Integrating coercion with subtyping and \nmultiple dispatch. In Science of Computer Programming, Volume 75, Issue 9. 2010. [15] R. Harper and G. \nMorrisett. Compiling polymorphism with intensional type analysis. In Proceedings of the 22nd Symposium \non Principles of Programming Languages (POPL 95). San Francisco, CA. Jan 1995. [16] A. Igarashi and M. \nViroli. On variance-based subtyping for parametric types. In Proceedings of the 16th Annual European \nConference on Object-Oriented Programming (ECOOP 02). Malaga, Spain. June 2002. [17] JSR 335: Lambda \nexpressions for the Java(TM) programming language. http://jcp.org/en/jsr/detail?id=335 [18] A. J. Kennedy \nand D. Syme. Design and implementation of generics for the .NET Common Language Runtime. In Proceedings \nof the 23rd Conference on Programming Language Design and Implementation (PLDI 2001). Snowbird, UT. Jun \n2001. [19] A. J. Kennedy and D. Syme. Combining generics, pre-compilation and sharing between software-based \nprocesses. Jan 2004. [20] The Maxine Virtual Machine. http://labs.oracle.com/projects/maxine/ [21] J. \nE. Moreira, S. P. Midkiff, M. Gupta, P. V. Artigas, M. Snir, and R. D. Lawrence. Java programming for \nhigh performance numerical computing. In IBM Systems Journal, Volume 39, Issue 1. Jan 2000. [22] M. Odersky \nand P. Wadler. Pizza into Java: translating theory into practice. In Proceedings of the 24th Symposium \non Principles of Programming Languages (POPL 97). Paris, France. Jan 1997. [23] M. Odersky, M. Sulzmann \nand M. Wehr. Type inference with constrained types. In Proceedigns of the 4th International Workshop \non Foundations of Object-Oriented Programming (FOOL 97). Paris, France. Jan 1997. [24] B. Oliveira and \nJ. Gibbons. Scala for generic programmers. In Proceedings of the Workshop on Generic Programming (WGP \n08). Victoria, BC. Sep 2008. [25] J. Palsberg. Type-based analysis and applications. In Proceedings of \nthe Workshop on Program Analysis for Software Tools (PASTE 01). Snowbird, UT. Jun 2001. [26] B. C. Pierce. \nAdvanced topics in types and programming languages. MIT Press. 2004. [27] B. C. Pierce and D. N. Turner. \nLocal type inference. In Proceedings of the 25th Symposium on Principles of Programming Languages (POPL \n98). San Diego, California. Jan 1998. [28] C. van Reeuwijk and H. J. Sips. Adding tuples to Java: a study \nin lightweight data structures. In Proceedings of the Joint Java Grande/ISCOPE Conference (JGI 02). Seattle, \nWashington. Nov 2002. [29] O. Sallenave and R. Ducournau. Lightweight generics in embedded systems through \nstatic analysis. In Languages, Compilers, Tools and Theory for Embedded Systems (LCTES 12). Beijing, \nChina. Jun 2012. [30] D. Smith and R. Cartwright. Java type inference is broken: can we .x it? In Proceedings \nof the 23rd Annual Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA \n08). Nashville, Tennesee. Oct 2008. [31] B. L. Titzer. Virgil: Objects on the head of a pin. In Proceedings \nof the 21st Annual Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA \n06). Portland, Oregon. Oct 2006. [32] B. L. Titzer and J. Palsberg. Vertical object layout and compression \nfor .xed heaps. In Proceedings of the International Conference on Compilers, Architecture, and Synthesis \nfor Embedded Systems (CASES 07). Salzburg, Austria. Oct 2007. [33] D. Tsafrir, R. W. Wisniewski, D. F. \nBacon, and B. Stroustrup. Mini\u00admizing dependencies within generic classes for faster and smaller pro\u00adgrams. \nIn Proceedings of the 24th Annual Conference on Object-Oriented Programming, Systems, Languages, and \nApplications (OOPSLA 09). Orlando, FL. Oct 2009. [34] J. Vitek and B. Bokowski. Con.ned types. In Proceedings \nof the 14th Annual Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA \n99). Denver, CO. Oct 1999. [35] S. Weeks. Whole-program compilation in MLton. In Proceedings of the 2006 \nworkshop on ML. Portland, OR. Sep 2006. Slides available: http://mlton.org/pages/References/attachments/060916-mlton.pdf \n[36] L. Ziarek, S. Weeks and S. Jagannathan. Flattening tuples in an SSA intermediate representation. \nIn Journal of Higher-Order and Symbolic Computation, Volume 21, Issue 3. Sept 2008.    \n\t\t\t", "proc_id": "2491956", "abstract": "<p>Languages are becoming increasingly multi-paradigm. Subtype polymorphism in statically-typed object-oriented languages is being supplemented with parametric polymorphism in the form of generics. Features like first-class functions and lambdas are appearing everywhere. Yet existing languages like Java, C#, C++, D, and Scala seem to accrete ever more complexity when they reach beyond their original paradigm into another; inevitably older features have some rough edges that lead to nonuniformity and pitfalls. Given a fresh start, a new language designer is faced with a daunting array of potential features. Where to start? What is important to get right first, and what can be added later? What features must work together, and what features are orthogonal? We report on our experience with Virgil III, a practical language with a careful balance of classes, functions, tuples and type parameters. Virgil intentionally lacks many advanced features, yet we find its core feature set enables new species of design patterns that bridge multiple paradigms and emulate features not directly supported such as interfaces, abstract data types, ad hoc polymorphism, and variant types. Surprisingly, we find variance for function types and tuple types often replaces the need for other kinds of type variance when libraries are designed in a more functional style.</p>", "authors": [{"name": "Ben L. Titzer", "author_profile_id": "81100062616", "affiliation": "Google, Mountain View, CA, USA", "person_id": "P4148947", "email_address": "titzer@google.com", "orcid_id": ""}], "doi_number": "10.1145/2491956.2491962", "year": "2013", "article_id": "2491962", "conference": "PLDI", "title": "Harmonizing classes, functions, tuples, and type parameters in virgil iii", "url": "http://dl.acm.org/citation.cfm?id=2491962"}