{"article_publication_date": "06-16-2013", "fulltext": "\n Almost-Correct Speci.cations A Modular Semantic Framework for Assigning Con.dence to Warnings Sam Blackshear \nUniversity of Colorado, Boulder samuel.blackshear@colorado.edu Abstract Modular assertion checkers are \nplagued with false alarms due to the need for precise environment speci.cations (preconditions and callee \npostconditions). Even the fully precise checkers report as\u00adsertion failures under the most demonic environments \nallowed by unconstrained or partial speci.cations. The inability to preclude overly adversarial environments \nmakes such checkers less attrac\u00adtive to developers and severely limits the adoption of such tools in \nthe development cycle. In this work, we propose a parameterized framework for priori\u00adtizing the assertion \nfailures reported by a modular veri.er, with the goal of suppressing warnings from overly demonic environments. \nWe formalize almost-correct speci.cations as the minimal weak\u00adening of an angelic speci.cation (over \na set of predicates) that pre\u00adcludes any dead code intraprocedurally. Our work is inspired by and generalizes \nsome aspects of semantic inconsistency detection. Our formulation allows us to lift this idea to a general \nclass of warnings. We have developed a prototype ACSP E C, which we use to explore a few instantiations \nof the framework and report preliminary .ndings on a diverse set of C benchmarks. Categories and Subject \nDescriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation Keywords Program veri.ers, false \nalarms, predicate abstraction 1. Introduction Talking about false positive rate is simplistic since false \npositives are not all equal. The initial reports matter in\u00adordinately; . . . Furthermore, you never want \nan embar\u00adrassing false positive. A stupid false positive implies the tool is stupid. ( It s not even \nsmart enough to .gure that out? ). [2] Automatic program veri.ers are doomed to report false alarms. \nFalse alarms can be the result of analysis imprecision or the re\u00adsult of underspeci.ed environment assumptions. \nThe problem is relevant not only to modular checkers that analyze each procedure in isolation [12] (and \ntherefore need speci.cation of inputs and callees), but also to the more general setting when interprocedural \nspeci.cation inference (e.g., based on abstract interpretation [4]) Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 13, June 16 19, 2013, Seattle, WA, USA. \nCopyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . $15.00 Shuvendu K. Lahiri Microsoft Research, \nRedmond shuvendu@microsoft.com converges with the best invariants expressible in the domain. Fi\u00adnally, \nthis problem is inevitable when analyzing any open program that has under-constrained inputs and external \nprocedures without source code. This is unfortunate because excessive false alarms (especially stupid \nones) act as a deterrent to the initial adoption of veri.cation tools by average developers. Current \nbest practices (often undocu\u00admented) in designing usable static analysis tools mitigate this issue by \nusing several less-than-ideal techniques for reducing false pos\u00aditives. For example, a tool may bake \nunsound decisions into the analysis, which precludes the tool from .nding a class of bugs. A tool may \nrequire user annotations, which often hurts initial adop\u00adtion by average developers. Finally, a tool \nmay suppress alarms us\u00ading domain-speci.c and often ad-hoc heuristics, which makes the tool brittle and \nunpredictable. In spite of the severity of the prob\u00adlem, the subject of prioritizing warnings from program \nveri.ers systematically is relatively under-studied. In this work, we focus on a post-processing framework \nfor prior\u00aditizing alarms in an intraprocedural setting. We assume that the in\u00adterprocedural speci.cation \ninference [4] has converged with a set of invariants expressible in the underlying analysis. This assumption \nallows us to decouple the analysis and the framework for display\u00ading warnings, which is important because \nour goal is not to de.ne a new static analysis technique. We seek to solve a problem similar to one addressed \nby statistical methods for ranking alarms [17] or user-guided classi.cation of alarms [10]. Our method \nis based on deep semantic reasoning of a program (unlike [17]), and can com\u00adplement the work in [10] \nby identifying the initial set of warnings to display to the user for further classi.cation. In this \nwork, we propose a framework for reporting a high\u00adcon.dence subset of the assertion failures reported \nby a modular veri.er. Our framework is parameterized by a set of predicates Q. We use the following heuristic: \nif a warning can be suppressed by a simple environment speci.cation over Q, it is likely to be a stupid \nfalse alarm. On the other hand, if a warning can only be suppressed by a complicated environment speci.cation, \nit is more more likely to be a true alarm. In this work, we limit ourselves to three metrics for characterizing \nsimple speci.cations: (i) the speci.cation should not preclude the set of angelic environments, (ii) \nthe speci.cation should at least be permissive enough to allow all program locations in a procedure to \nbe reachable (unless they are unreachable even in an unconstrained environment), and (iii) the representation \nof the speci.cation should satisfy some quality measures such as (but not limited to) the number of disjunctions \nin a clausal representation. This paper describes a framework for inferring these almost\u00adcorrect speci.cations. \nWe refer to the high-con.dence warnings that these speci.cations reveal as abstract inconsistency bugs. \nWhen the set of predicates Q contains all the atomic predicates in the representation of the weakest \nprecondition for a procedure, our framework reports a set of warnings corresponding to semantic  void \nFoo(int *c, char *buf, CMD cmd) { 1: if (*) { 2: free(c);//A1:assert(!Freed[c]);Freed[c] := true; 3: \nfree(buf);//A2:assert(!Freed[buf]);Freed[buf] := true; 4: return; 5: } 6: if (cmd == READ) { 7: if (*) \n{ 8: free(c);//A3:assert(!Freed[c]);Freed[c] := true; 9: free(buf);//A4:assert(!Freed[buf]);Freed[buf] \n:= true; 10: /* ERROR: missing return */ 11: } 12: } 13: free(c);//A5:assert(!Freed[c]);Freed[c] := true; \n14: free(buf);//A6:assert(!Freed[buf]);Freed[buf] := true; 15: return; } Figure 1. An example of a C \ndouble free bug. inconsistency bugs [9, 11, 21], a class of high-con.dence bugs that can be identi.ed \nin a modular fashion. On the other hand, when the set of predicates Q is empty, our framework reports \nall of the warnings from the underlying modular veri.er. Our framework can be instantiated with other \npredicate sets between these extremes in order to construct various schemes for .ltering warnings. 1.1 \nOverview We begin by providing an informal overview of our work with the help of two illustrative examples. \n1.1.1 Semantic inconsistency detection Consider the C program in Figure 1, which is a simpli.ed version \nof a real program [11]. Initially, we will ignore the // -commented text. The program frees the pointers \nc and buf by invoking the free procedure. The * denotes a non-deterministic choice. The procedure free \nhas a precondition that the argument should not al\u00adready be freed; the effect of the procedure is to \nfree the pointer. The procedure has a double-free bug when the sequence of locations 1,6,7,8,9,10,11,13,14,15 \nis executed; the pointers c and buf would be freed twice. The error in the program is the missing return \nin line 10. The comments in // encode the program statements into a simple intermediate language (described \nin detail in \u00a7 2.1). The program makes the type-state for freed explicit by maintaining an array Freed \nthat is indexed by an integer address. The free procedure is replaced by its precondition and the update \nto the Freed array. Demonic environments. Given this program, let us consider what a sound and precise \nmodular program veri.er (such as BO O -G IE [1]) would do: (1) It would report a violation of the assertion \nat A1 by pretending that Freed[c] could be true at entry to Foo. Looking at the code, it seems likely \nthat the programmer does not expect this scenario. (2) It would next report a violation of the as\u00adsertion \nat A2 by pretending that Freed[buf] holds on input, or that the c and buf pointers could be aliased (assuming \nwe don t trust the static types of C). Looking at the code, there is no indication that the programmer \nexpects any such aliasing (probably because he/she trusts the static types). (3) It would next complain \nabout locations A3 and A4 for similar reasons. (4) Finally, it would complain about A5 and A6 by assuming \nthat c and buf are not freed on entry and that they are not aliased, which corresponds to the real bug. \nThe exercise illustrates the most severe limitation of modular checking: the absence of precise environment \nassumptions yields a .ood of stupid false alarms that obscure interesting alarms. For this example, the \nenvironment consists of inputs c, buf, cmd and the void Bar(..) { twoints * data = NULL; /* Initialize \ndata */ L1: data = (twoints *)calloc(100, sizeof(twoints)); L2: if(static_returns_t()) { /* FLAW: should \ncheck if memory allocation failed */ A1: data[0].a = 1; ... } else { if (data != NULL) { A2: data[0].a \n= 1; ... L3: } else { } } } Figure 2. Example for abstract semantic inconsistency bug. global Freed. \nSound modular checkers assume the most demonic environments not precluded by the existing procedure contracts \n(preconditions and callee postconditions). Angelic environments. Now consider the other extreme. The \nweakest (liberal) precondition WP(Foo) is the largest set of in\u00adput states for Foo that do not fail any \nassertion; in other words, the weakest angelic environment speci.cation. WP(Foo) can be represented as: \n(cmd != READ &#38;&#38; !Freed[c] &#38;&#38; !Freed[buf] &#38;&#38; c != buf) However, the weakest precondition \nfor this example is too strong. It makes code unreachable (namely A3, A4), which prevents the bug from \nbeing reported. This intuition has been exploited by prior work on semantic inconsistency detection [9, \n11, 21], and has inspired our work. Our insight is that if the weakest precondition is too strong according \nto some metric (such as the absence of intraprocedurally dead code), then we can progressively weaken \nit until it satis.es the metric (makes all code reachable). The weakening process will reveal assertion \nfailures that were previously suppressed by the weakest precondition. We formalize the notion of almost-correct \nspeci.cations as the set of speci.cations that can be obtained by minimally weakening the representation \nof weakest precondition as a conjunction of maximal clauses (\u00a73.3). For the current example, our method \ninfers a single almost-correct speci.cation: (!Freed[c] &#38;&#38; !Freed[buf] &#38;&#38; c != buf) which \nfails only A5, the assertion failure corresponding to the true bug.1  1.1.2 Abstract semantic inconsistency \nbug Consider the following C example in Figure 2 from the SAMATE suite of benchmarks [20]. Let us assume \nthat there is an assertion data != 0 before the access to data in lines A1 and A2. The en\u00advironment for \nthis example consists of the variables modi.ed or re\u00adturned by the two procedure calls calloc and static \nreturns t. In the absence of any speci.cation about the two procedures, a de\u00admonic environment would \nsuggest that the assertion at line A1 can fail. However, the code alone does not give us enough information \nto determine if this the environment is too demonic. On the angelic end, the weakest precondition conjures \nup a correlation between the two procedures and makes it a precondition to the procedure under analysis: \n.L1 .static returns t.return =. .L2 .calloc.return ! = 0 1 In our semantics, assertion failures terminate \nexecution and therefore two assertion failures cannot happen for the same input. Since every input that \nfails A6 also fails A5 under this environment, A6 is unreachable and never reported as a failure.  Here \n.L .pr.return is a fresh constant that denotes the return value of the call to a procedure pr at some \nlocation L. The angelic weakest precondition tries to create correlations between various values in the \nprogram (parameters, returns, globals) in order to avoid an assertion failure. Unlike the previous example, \nthe metric of creating unreachable code cannot be used to counter the angelic speci.cation. There is \nlittle evidence to suggest that either the angelic or demonic speci.cation is (or isn t) the intended \none. Our insight is that we can report this warning (albeit with lesser con.dence) by lifting semantic \ninconsistency detection to a more abstract setting. The idea is to take away some of the angelic power \nof the weakest precondition by restricting the vocabulary over which it can be expressed (i.e., the set \nof predicates Q). One natural abstraction that we describe in this paper is treating condi\u00adtionals in \na program as non-deterministic for the purpose of collect\u00ading the set of predicates in Q. This abstraction \nprevents the correla\u00adtion between the return values of calloc and static returns t that the (concrete) \nweakest precondition inferred for this example. Instead, the most angelic speci.cation possible under \nthis abstrac\u00adtion of Q is .L2 .calloc.return ! = 0, which creates dead code by making location L3 unreachable. \nThe almost-correct speci.ca\u00adtion (over Q) for this example is true, which reveals the bug in lo\u00adcation \nA1. We call such bugs abstract semantic inconsistency bugs, as they are parameterized by the set of predicates \nQ. The example shows that we are able to lift the idea of semantic inconsistency detection from the concrete \ndomain to an abstraction, which allows us to classify more failures using the same underly\u00ading principle. \nThis greatly increases the applicability of semantic inconsistency detection.  1.2 Contributions In \nthis work, we propose a parameterized post-processing frame\u00adwork for prioritizing the assertion failures \nreported by a modular veri.er. Speci.cally, we make the following contributions: (1) We generalize the \nnotion of semantic inconsistency bugs ( [9, 11, 21]) by parameterizing it with a set of predicates. This \nallows us to ap\u00adply the idea of semantic inconsistency to larger classes of warnings. (2) We formalize \nthe concept of almost-correct speci.cations as the minimal weakening of the angelic speci.cations over \na set of pred\u00adicates. These speci.cations can be used to report high-con.dence warnings to the user. \n(3) We provide a set of generic predicate choices that can be automatically constructed and instantiate \nour framework with them. (4) We have implemented our techniques in a tool called ACSP E C. Our tool is \nbased on BO O G IE program ver\u00adi.er, but can be used with any off-the-shelf program veri.er. (5) We have \napplied our tool on a diverse set of C programs measur\u00ading over 1.5 million LOC from open source and \nWindows software, and report our preliminary .ndings. 2. Background In this section, we describe a simple \nprogramming language that we use to formalize the ideas in the paper. 2.1 Programs Figure 3 de.nes the \nsyntax of a simple loop-free and call-free pro\u00adgramming language. A program consists of a set of procedures. \nEach program consists of a set of integer valued variables denoted by Vars . Variables are partitioned \ninto globals, procedure parame\u00adters, returns, and locals. Integer expressions (denoted by Expr) can be \nconstructed from variables, or by applying a function symbol f to a (possibly empty) list of expressions. \nBoolean expressions (de\u00adnoted by Formula ) can be constructed from Boolean constants, or by applying \na predicate symbol p to a (possibly empty) list of ex\u00adpressions. The expressions are closed under Boolean \nconnectives x, y . Vars e . Expr :: x | f(e, . . . , e) f, . . Formula :: true | false | p(e, . . . , \ne) | f . f | \u00acf s, t . Stmt :: skip | assert f | assume f | x := e | havoc x | s; s | if (f) then s \nelse s Figure 3. A simple programming language. {., \u00ac}. Array expressions are modeled with the use of \nspecial function symbols read (to read a location in an array) and write (to return a new array updated \nat a location) that are constrained by the theory of arrays [6]. A (simple) statement can be either a \nskip (skip), an assertion (assert f), an assumption (assume f), or an assignment to a variable. In addition \nto the usual assignment x := e, the statement havoc x assigns a non-deterministic value to the variable \nx this is used to model a non-deterministic value * in an expression. A (compound) statement can be \neither a sequential composition of two statements or a conditional statement if (f) then s else t that \nexecutes the statement s if f is true, or t otherwise. Procedure calls are not part of the programming \nlanguage. In\u00adstead, a procedure call is replaced by its speci.cation. Consider a procedure pr(x) : ret \nthat takes a parameter x, returns ret, and modi.es a global gl . Vars . Further, it has a precondition \n.1 (a formula over parameters and globals) and a postcondition .2 (a for\u00admula over parameters, globals, \nand returns). A call to a procedure r := call pr(e) at a control location l is expressed as: assert .1[e/x] \n; r, gl := .l.pr.r, .l.pr.gl ; assume .2[r/ret] ; where .l.pr.r, .l.pr.gl are fresh constants unique \nto the location l. The constructs in the programming language are fairly standard, and we refer the reader \nto earlier work for an operational seman\u00adtics of the language [7]. The expressive power of the simple \nlan\u00adguage suf.ces to precisely provide semantics to many imperative languages such as C, C#, and Java. \nFields and objects can be mod\u00adeled by a map indexed by object identi.ers. Object allocation and deallocation \ncan be simulated using extra ghost variables. We refer the reader to previous work on modeling Java [12] \nand C [3].  2.2 Program to logic DE FIN I T I ON 1 (WP(pr)). For a procedure pr, the weakest pre\u00adcondition \nWP(pr) is the largest set of input states from which no execution fails an assertion. A procedure satis.es \nits contracts if WP(pr) is the set .x.true. For a loop-free and call-free procedure, the check for partial \ncor\u00adrectness can be reduced to checking satis.ability (modulo the back\u00adground theories) of a logical \nformula by variants of Dijkstra s weak\u00adest (liberal) precondition predicate transformer [8]. The predicate \ntransformer wp(s, .) takes as inputs a statement s . Stmt and a formula . . Formula , and constructs \na formula. It is de.ned recursively over the structure of statements as follows: wp(skip, .) = . wp(assume \nf, .) = \u00acf . . wp(assert f, .) = f . . wp(x := e, .) = .[e/x] wp(havoc x, .) = .x..[x/x] wp(s; t, .) \n= wp(s, wp(t, .)) wp(if (c) then s else t, .) = (\u00acc . wp(s, .)) . (c . wp(t, .)) To verify that pr(. \n. .){body } does not fail any assertions, we check that the formula \u00acwp(body , true) is unsatis.able. \nSince comput\u00ading wp(body , true) can incur an exponential blowup, program veri.ers compute an equisatis.able \nformula by .rst passifying the program [13]. We often overload the expression wp(pr, true) to mean wp(body \n, true), where body is the body of pr. The satis.a\u00adbility of the resultant formula can be checked by \nsuitable decision procedures such as modern Satis.ability Modulo Theories (SMT) solvers [6]. We will \nrefer to the process of converting a program to a formula as veri.cation condition (VC) generation. \n 2.3 Dead and fail set For a procedure pr, let Locs denote the set of locations inside pr, and Asserts \ndenote the set of assertions inside pr. For rest of the discussion, the procedure pr, the set of assertions \nAsserts and the set of locations Locs are implicit in every context, unless otherwise noted. For a formula \nf . Formula representing a set of input states, we de.ne the following concepts: . 1. The set of dead \nlocations Dead (f) = {l . Locs | l is not reachable for any state in f}. .  2. The set of failed assertions \nFail (f) = {a . Asserts | a can fail on at least one execution from an input in f}.  Note that for non-deterministic \nprograms, both Dead (f) and Fail (f) account for all possible executions starting from a given input \nstate. We assume that Dead (true) = {}; that is, that there are no dead locations from the local perspective \nof pr. In practice, we can ensure that this assumption holds by removing Dead (true) from Locs before \nstarting our analysis. To determine the set of dead locations, it suf.ces to restrict ourselves to only \na subset of locations namely the locations that appear immediately inside then , and else branches as \nwell as the locations that appear after each assume statement. The former ensures that each branch can \nbe taken both ways, and the latter ensures that assume statements do not block subsequent statements. \nAlthough we choose to de.ne Dead (f) in terms of branch cov\u00aderage in this paper, the de.nition of Dead \n(f) can be a parameter of our analysis. We can easily replace our de.nition with any com\u00adputable metric \nfor expressing when a speci.cation is too strong. For example, we could have de.ned Dead (f) as the set \nof paths that are infeasible under f (i.e., in terms of path coverage rather than in terms of branch \ncoverage), or as the set of observed runtime values at some locations that are precluded by f.  2.4 \nClauses A predicate p is an atomic formula over some theory (say arith\u00admetic) without any Boolean connectives \n(\u00ac, ., .) at the outermost scope. A literal l is either a predicate or its negation. A clause . c = l1 \n. l2 . . . lk is a disjunction over literals. Dually, a cube . d = l1 . l2 . . . lk is a conjunction \nover literals. For a set of clauses r o C, we denote .(C) to be the formula true .c.C c . LEMM A 1. \nFor any two sets of input clauses C1 . C2, Dead (.(C1)) . Dead (.(C2)), and  Fail (.(C2)) . Fail (.(C1)). \n 3. Semantic inconsistency and almost-correct speci.cations In this section, we formalize the notion \nof abstract semantic in\u00adconsistency bugs (SIB). First, we capture the essential intuition be\u00adhind semantic \ninconsistency [11] in the context of modular asser\u00adtion checking (\u00a7 3.1). We then lift the idea of inconsistency \nto a more general setting by parameterizing it with a set of predicates (abstract SIB). In \u00a7 3.3, we \ndescribe almost-correct speci.cations as a witness for abstract SIBs. 3.1 Semantic inconsistency bugs \nLet us start by formalizing semantic inconsistency bugs in the con\u00adtext of modular assertion checking \nand explaining their relationship with weakest precondition. DE FIN I T I ON 2 (SIB). A procedure pr \nhas a semantic inconsis\u00adtency bug (SIB) if the largest set of input states f that satis.es all assertions \n(i.e. Fail (f) = {}) creates dead code (i.e. Dead (f)= {}). We can establish a connection between inconsistency \nbugs and weakest precondition for a procedure: PRO P O S ITI O N 1. A procedure pr containing at least \none assertion has a SIB if and only if Dead (WP(pr)) = {} . Note that the above formulation is purely \nsemantic and only relies on the assertions present in the code. For the double free() example in \u00a7 1.1.1, \nthe weakest precondition can be expressed as: (cmd != READ &#38;&#38; !Freed[c] &#38;&#38; !Freed[buf] \n&#38;&#38; c != buf) However, this causes A3 and A4 to become unreachable, and thus the procedure has \na SIB. The case where WP(pr) is equivalent to {} (that is, when every input fails at least one assertion) \nis a special case of SIB bugs where Dead (WP(pr)) contains every statement in the procedure.  3.2 Abstract \nsemantic inconsistency bugs Although SIBs are interesting and useful to detect, they represent only a \nsmall fraction of all possible bugs. As the example in \u00a7 1.1.2 shows, the concrete WP(pr) is the most \nangelic speci.cation on the environment, and therefore examining the dead locations it cre\u00adates will \nnot reveal any errors except SIBs. Our goal in this sec\u00adtion is to lift the connection between WP(pr) \nand SIBs to a more general setting. Our intuition is simple: by restricting the abstrac\u00adtion (or vocabulary) \nover which we can describe the environment speci.cations, some warnings can be categorized as SIB bugs \nwith respect to that abstraction, even though there may be no SIB bugs by the concrete de.nition de.ned \nearlier in Proposition 1. We lift the notion of SIB to abstract semantic inconsistency bugs by parameterizing \nthe de.nition of inconsistency with respect to a predicate abstraction [4, 14]. Given a set of atomic \nformulas Q, the abstraction function aQ : Formula . Formula maps a formula f to the strongest approximation \nof f expressible as Boolean combinations of Q. For example, if Q = {x = 0, y = 0} . and f = (x = 0 . \ny = 0) . (x = 1 . y = 1), then . aQ (f) = (x = 0 . y = 0) . (x 0 . y= 0). For a = given formula f . Formula \n, we denote \u00dfQ as the weakest under\u00adapproximation of f with respect to a given set of predicates Q. It \nis represented as \u00acaQ (\u00acf). We can establish a partial order on the set of all predicate abstractions \nby a subset relation . on the set of predicates. It is not hard to see that given a formula f and two \nsets of predicates Q . P, f =. aP (f) =. aQ (f) and \u00dfQ (f) =. \u00dfP (f) =. f. In other words, a larger set \nof predicates provides a more precise approximation (both over and under) of f. DE FINI T I ON 3 (Abstract \nSIB). A procedure pr has an abstract se\u00admantic inconsistency bug (abstract SIB) with respect to a set \nof predicates Q if Dead (\u00dfQ (wp(pr, true))) = {}. The intuition behind this de.nition is quite simple: \nthe set of environments \u00dfQ (wp(pr, true)) is the weakest set of angelic en\u00advironments expressible using \nQ that do not fail any assertion in the procedure. If this set of states gives rise to dead code, then \nthe procedure has an abstract SIB. Henceforth, we will implicitly as\u00adsume Q as the set of predicates \nunder consideration unless other\u00adwise noted.  Note that when Q contains all the atomic predicates from \nwp(pr, true), then abstract SIBs (with respect to Q) and SIBs coincide. Unlike concrete SIBs, abstract \nSIBs are not guaranteed to correspond to either true bugs or dead code. However, the exam\u00adple in \u00a7 1.1.2 \nillustrates that some true bugs can be categorized as abstract SIBs, but not as concrete SIBs. At the \nother extreme when . Q = {}, any assertion failure will manifest itself as an abstract SIB since the \nonly speci.cations allowed over Q = {} are true and false. We can establish the following relationship \nbetween two sets of predicates: PRO P O S IT IO N 2. For two sets of predicates Q . P, if pr has an abstract \nSIB under P, then pr has an abstract SIB under Q.  3.3 Almost-correct speci.cations So far, we have \nonly shown how to determine whether a procedure has an abstract SIB or not. In this section, we explain \nhow to .nd the assertions that might fail in a procedure with a SIB (abstract or concrete). We provide \na witness for each potential assertion fail\u00adure by providing an almost-correct speci.cation under which \nthat assertion might fail. For this section, we assume that the procedure pr is .xed and therefore implicit \nin the de.nitions. Let Formula Q . Formula be the set of all formulas that can be constructed by a Boolean \ncombination over the predicates in Q. DE FI NI TI O N 4 (AlmostCorrectSpecs (Q)). For a set of predi\u00adcates \nQ and an integer k = 0, AlmostCorrectSpecsK (Q, k) . Formula Q is de.ned as set of formulas f where 1. \n\u00dfQ (wp(pr, true)) =. f, and 2. Dead (f) = {}, and 3. |Fail (f)| = k, and 4. for any . . Formula Q \nsuch that \u00dfQ (wp(pr, true)) =. . =. f, either f =. . or Dead (.) = {}.  AlmostCorrectSpecs (Q) is AlmostCorrectSpecsK \n(Q, k) for the smallest k = 0 such that AlmostCorrectSpecsK (Q, k) = {}. AlmostCorrectSpecsK (Q, k) contains \nprecisely those formu\u00adlas f that are at least as weak as the \u00dfQ (wp(pr, true)), do not create any dead \ncode, induce k assertion failures, and cannot be strengthened over the vocabulary Q without creating \ndead code. AlmostCorrectSpecs (Q) contains the set of speci.cations that in\u00adduce the minimum number of \nfailures. When a procedure has no abstract SIBs, then AlmostCorrectSpecs (Q) is precisely the set of \nformulas representing \u00dfQ (wp(pr, true)), which (by de.nition) induce k = 0 failures. Algorithm 1 FindAbstractSIBs \n(pr, Q) Require: A procedure pr with a set of assertions Asserts Require: A set of predicates Q 1: f \n. \u00dfQ (wp(pr, true)) 2: if Dead (f) = {} then 3: s . SIB /* abstract */ 4: else 5: s . MAYBUG /* low con.dence \nwarnings */ 6: end if 7: . . FindAlmostCorrectSpecs (pr, Q) 8: E . Fail (.) ... 9: return (s, E ) Algorithm \n1 shows how to .nd abstract SIBs. Line 7 invokes a method for generating a set of almost-correct speci.cations \nover Q; we describe this method in the next section. Finally, line 8 collects the set of assertion failures \nthat are possible under the almost\u00adcorrect speci.cations. 4. Computing almost-correct speci.cations In \nthis section, we describe one method to compute the set of almost-correct speci.cations formulated in \nDe.nition 4. The steps consist of obtaining a canonical representation of \u00dfQ (wp(pr, true)) in a conjunctive \nnormal form (\u00a7 4.1), and then performing a greedy search (with pruning) to .nd the almost-correct speci.cations \n(\u00a7 4.2). We discuss Boolean simpli.cation of the resultant spec\u00adi.cations and further weakening the speci.cations \nbased on some syntactic clause quality measures (\u00a7 4.3). Finally, we provide dif\u00adferent methods for constructing \nthe set of predicates Q starting with the precise set of predicates for representing wp(pr, true). 4.1 \nPredicate cover PredicateCoverQ (pr) For a procedure pr, let VC (pr) . Formula be the veri.cation condition \n(VC) that is equisatis.able with \u00acwp(pr, true) the size of VC (pr) is usually almost linear in the size \nof pr [1] when pr is converted to static single assignment (SSA) form. Given a set of predicates Q, the \npredicate cover \u00dfQ (wp(pr, true)) is computed by enumerating all the assignments (ALL-SAT) over Q that \nsatisfy VC (pr) and then obtaining a set of clauses by negating these assignments. The clauses obtained \nthis way are maximal i.e., each predicate in Q either appears in a posi\u00adtive or negative polarity in \neach clause. Let us denote this op\u00aderation as PredicateCoverQ (pr). Such a conjunctive normal form over \nmaximal clauses provides a canonical representation of \u00dfQ (wp(pr, true)). The canonical representation \nis important for computing the almost-correct speci.cations, as we will describe in the next section. \nThe algorithm is fairly standard in predicate abstraction and we refer readers to earlier work [19]. \n 4.2 Weakening predicate cover The algorithm FindAlmostCorrectSpecs (pr, Q) .nds the set of almost-correct \nspeci.cations. It .rst computes the set of maximal clauses C using the predicate cover operation described \nearlier. It performs a greedy search over the space of clauses by selecting a clause to drop and then \ninspecting the Dead () and Fail () counts of the resulting clause sets. The algorithm starts with the \nset of clauses C satisfying Fail (.(C)) = {} and computes the minimum number of failures that can result \nfrom dropping clauses from C to make all the code reachable. The procedure returns a set of formulas, \neach representing an almost-correct speci.cation. For the purpose of this section, we will treat the \noperations Normalize and PruneClauses as identity functions that simply return the input set of clauses \n we will consider more interesting uses in \u00a7 4.3. The algorithm maintains a frontier set S of sets of \nclauses that have a non-empty dead set and iterates (via the outer while loop) until S is empty. It also \nmaintains the minimum failure count (MinFail ) for any clause set with an empty dead set. This count \nis initialized to the size of Asserts. At each step, the algorithm extracts a clause set C1 . S, and \nenumerates each subset of clauses C2 (the inner for loop) by dropping a clause c from C1. Each sub-clause \nC2 is either added to S (if Dead (C2) = {} and |Fail (C2)| = MinFail , or Dead (C2) = {} and |Fail (C2)| \n= 0) or pruned (if Dead (C2) = {} and |Fail (C2)| > MinFail ). If |Dead (C2)| = 0 and |Fail (C2)| = MinFail \n, then we add C2 to the output set U. When |Fail (C2)| < MinFail , then the output set is .ushed and \nthe MinFail is reduced to |Fail (C2)|. TH E O R E M 1. The following statements are true: 1. FindAlmostCorrectSpecs \n(pr, Q) . AlmostCorrectSpecs (Q). 2. For each f . AlmostCorrectSpecs (Q), there exists a . . FindAlmostCorrectSpecs \n(pr, Q) such that f . ..  The set AlmostCorrectSpecs (Q) may contain different syntac\u00adtic representations \nof the same speci.cation and therefore may con\u00ad  Algorithm 2 FindAlmostCorrectSpecs(pr, Q) Require: \nA procedure pr with a set of assertions Asserts Require: A set of predicates Q Ensure: Set of formulas \nrepresenting AlmostCorrectSpecs (C) 1: C . PredicateCoverQ (pr) 2: if Dead (.(C)) = {} then 3: return \n{.(PruneClauses(Normalize(C)))} 4: end if 5: S . {C} /*Frontier set */ 6: T . {} /* Visited set */ 7: \nU . {} /* Output set */ 8: MinFail . |Asserts| /* Smallest set of failures*/ 9: while S = {} /* Frontier \nis non-empty */ do 10: C1 . Choose (S) 11: for each clause c . C1 do 12: C2 . C1 \\ {c} /* Weaken by one \nclause */ 13: if C2 . T then 14: continue /* Visited already */ 15: end if 16: T . T . {C2} /* Add to \nVisited */ 17: if |Fail (C2)| > MinFail then 18: continue /* MinFail can only decrease */ 19: end if \n20: if |Dead (C2)| = 0 then 21: S . S . {C2} /* Add to the frontier set */ 22: else if |Fail (C2)| = \n0 then 23: S . S . {C2} /* Add to the frontier set */ 24: else if |Fail (C2)| = MinFail then 25: U . \nU . {C2} /* Add it to U */ 26: else 27: /* |Fail (C2)| < MinFail */ 28: MinFail . |Fail (C2)| /* Decrease \nMinFail */ 29: U . {C2} /* Clear U and add C2 */ 30: end if 31: end for 32: end while 33: return .(PruneClauses(Normalize(C1))) \nC1.U tain more formulas than FindAlmostCorrectSpecs (pr, Q). The proof follows from the observations \nthat (a) the set of maximal cubes (negation of maximal clause) over Q partitions the set of all states, \nand (b) dropping a maximal clause from the set of maximal clauses representing a formula weakens the \nformula by exactly one maximal cube.  4.3 Clause simpli.cation and pruning We can additionally parameterize \nthe almost-correct speci.cations by providing a syntactic quality measure for the set of clauses. For \ninstance, the number of literals in a clause can be a measure of goodness of a speci.cation. Under the \nhypothesis that good speci\u00ad.cations are usually simple and do not contain many disjunctions, we can prune \nclauses that contain a large number of literals. Alter\u00adnately, we might try to avoid clauses that correlate \nthe return values of multiple procedure calls. However, such quality measures cannot be applied directly \non the maximal clauses. Consider the maximal clauses (a . b) . (a . \u00acb) over Q = {a, b}. These clauses \nhave two literals per clause and may be undesirable, whereas an equivalent clause (a) has only one literal. \nWe address this problem by .rst performing Boolean simpli.cation of the maximal clauses. The operation \nNormalize(C) takes a set of clauses C and performs Boolean clause simpli.cation on the set of clauses. \nIt applies the following three rules to a set of clauses (starting with C) until a .x-point is reached: \n(1) Resolution: If there are two clauses (c . l), (d . \u00acl) . C, then add (c . d) to C. (2) Subsumption: \nIf there are two clauses c, (c . l) . C, then remove (c . l) from C. (3) Tautologies: If there is a clause \n(c . l . \u00acl) . C, then remove it from C. The function PruneClauses takes a set of clauses and re\u00adturns \na subset of clauses that satisfy the quality measure. Note that the pruning makes the almost-correct \nspeci.cations weaker and can reveal more warnings it is not just a syntactic trans\u00adformation. For the \nexample in \u00a7 1.1.2, both schemes (limiting the number of literals per clause to one, or removing clauses \ncon\u00adtaining returns from multiple procedures) will reveal the warn\u00ading by pruning the clause .L1 .static \nreturns t.return =. .L2 .calloc.return ! = 0.  4.4 Mining predicates We now describe a few choices for \nconstructing the set of predi\u00adcates in Q automatically for any given procedure pr. We start with a method \nfor collecting all the atomic predicates that appear in the ex\u00adpression representing the weakest precondition \n(\u00a7 4.4.1), followed by two methods that generate smaller sets of predicates (\u00a7 4.4.2 and \u00a7 4.4.3). 4.4.1 \nPredicates in wp(pr, true) Recall that if Q contains all the atomic predicates that con\u00adstitute wp(pr, \ntrue), then \u00dfQ (wp(pr, true)) is equivalent to wp(pr, true), and abstract SIBs and SIBs coincide. For \na pro\u00adcedure pr with body body , the set of predicates collected is Preds (body , {}), wherePreds (, \n) is de.ned recursively as follows: Preds (skip, Q ) = Q Preds (assume f, Q ) = Atoms (f) . Q Preds (assert \nf, Q ) = Atoms (f) . Q Preds (x := e, Q ) = Atoms (Q[e/x]) Preds (havoc x, Q ) = Drop(Q , x) Preds (s; \nt, Q ) = Preds (s, Preds (t, Q )) Preds (if (c) then s else t, Q ) = Atoms (c) . Preds (s, Q ) . Preds \n(t, Q ) Here Atoms (f) collects the set of atomic predicates (those do not contain any Boolean connectives), \nand Drop (Q, x) removes any atomic predicate in Q that contains the variable x. Note the similarity with \nthe wp(s, f) transformer from \u00a7 2.2, as the goal of the predicate collection above is to collect the \natomic predicates that may appear in the wp(pr, true). We describe a few important details about the \npredicates in Preds (body , {}). First, recall that a variable x that is modi.ed by a call to a procedure \npr1 at line l is assigned a special constant .l.pr1 .x (\u00a7 2.1). These constants appear in the set of \npredicates Q and in the speci.cations (see the example in \u00a7 1.1.2). Second, consider the problem of generating \natomic predicates in the presence of arrays or maps. For example, wp(x := write(x, e1, e2), p(read (x, \ne3), e4)) results in the formula p(read (write(x, e1, e2), e3), e4) that con\u00adtains write symbol. We apply \nrewrite rules (omitted for brevity) to eliminate the write symbols in the predicates in order to make \ninput speci.cations more readable and intuitive. After eliminating write, the above expression corresponds \nto e1 = e3 ? p(e2, e4) : p(read (x, e3), e4). The set of atomic predicates in this expression are {e1 \n= e3, p(e2, e4), p(read (x, e3), e4)}. This explains the presence of the predicate c = buf in the weakest \nprecondition for the example of double-free (\u00a7 1.1.1).  4.4.2 Ignoring conditionals Consider the following \nexample: Figure 4. The four abstract con.gurations de.ned by combining our two abstractions, along with \ntheir aliases. Arrows .ow from higher precision to lower precision.  void Foo(bool c1, bool c2, int \n*x) { if (c1) {...; if (x) {*x = 1;} ... } if (c2) {... ; *x = 2; ...} } The weakest precondition avoids \nnon-null errors by conjur\u00ading c2 =. x = 0 as a possible precondition. This precon\u00addition does not create \nany concrete SIBs. One way to take away this angelic power (and reveal warnings as abstract SIBs) is \nto avoid considering the predicates that guard conditionals. We can obtain this by treating a conditional \nif (c) then s else t as {havoc x; if (x) then s else t; } during predicate collection (where x is a fresh \nprogram variable). The set of predicates col\u00adlected for this examples is Q = {x = 0}.  4.4.3 Havoc returns \nAnother way to restrict the set of predicates is to avoid predicates about callee modi.cations. Instead \nof assigning fresh constants (e.g. .l.pr1 .x) to modi.ed variables (as done by default in \u00a7 2.1), we \ncan havoc these variables. However, this can also lead to undesired imprecision in cases such as: void \nBar(...) { havoc x; // x = getValidPointer(..); M[x] := 1; // *x = 1; } For this example, wp(Bar, true) \nwill be false because the predi\u00adcate set is empty. We henceforth refer to the .rst abstraction described \nas ignore conditionals (\u00a7 4.4.2) and the second as havoc returns (\u00a7 4.4.3). The product of the these \ntwo abstractions naturally yields 22 = 4 abstract con.gurations which we name and describe in Figure \n4. The con.guration Conc refers to concrete SIBs (\u00a7 4.4.1). The rest of the con.gurations A0, A1, A2 \ncorrespond to abstract SIBs resulting from combining the schemes in the previous two sections (\u00a7 4.4.2 \nand \u00a7 4.4.3). 5. Implementation and evaluation Implementation. We have constructed a prototype tool ACSP \nE C (Almost-Correct SPECi.cations) that implements the ideas pre\u00adsented in the paper. The tool consists \nof around 2000 lines of C# code. It accepts a source .le in the BO OGI E language [7] and a list of abstractions \nas input. It outputs whether the procedure has a SIB under the abstractions, searches for the set of \nalmost-correct spec\u00adi.cations in the predicate vocabulary allowed by the abstractions, and prints the \nset of errors induced by the speci.cations. We lever\u00adage BO O G I E s optimized veri.cation condition \ngeneration along with the Z3 SMT solver [6] for checking the satis.ability of the veri.cation conditions. \nThe current prototype does not yet use the incremental interface to the Z3 prover and regenerates VC \nfor ev\u00adery call to Z3 this is a major source of inef.ciency in the current implementation. The main \nmodules implemented in the tool are (a) computing the Fail () and Dead () sets, (b) generating the set \nof predicates Figure 5. Benchmark statistics. For each benchmark, we give the lines of code in both C \nand BO O G IE, the number of procedures, and number of assertions. Bench LOC (C) LOC (BPL) Procs Asserts \nCWE476 24582 267510 561 228 CWE690 85855 941045 1865 1009 ansicon 2972 38145 289 325 space 9566 185878 \n263 2144 cancel 827 7411 9 9 event 872 6430 7 4 .re.y 622 8669 9 22 mou.lter 631 7073 7 25 vserial 1396 \n21617 23 102 Drv1 97615 1401949 799 14402 Drv2 77180 1536078 1218 13843 Drv3 31011 77760 67 692 Drv4 \n82720 542049 401 3582 Drv5 151516 981682 661 11250 Drv6 18577 562477 490 7381 Drv7 1171514 21845268 21626 \n227573 Lib1 96158 1121121 1158 10051 Total 1853614 29552162 29453 292642 under the different options \nfrom Figure 4, (c) computing the pred\u00adicate cover and checking for SIBs, (d) searching for almost-correct \nspeci.cations over a set of clauses, and (e) normalizing clauses and performing clause pruning. We only \nmention the computation of Dead () brie.y here. For each location l . Locs (one for each block that has \nan assume statement), we introduce an assertion assert bl. To compute Dead (f), we ask for all assertion \nfailures (over the location asserts) under f the set of assertions that do not fail constitute Dead \n(f). For computing Dead (), we rely on the completeness of the theorem prover. For the logics we use \n(equali\u00adties, arithmetic, arrays), Z3 ensures completeness. Benchmarks. We chose a set of 17 C benchmarks \ndrawn from open source programs and the Windows codebase (Figure 5). The CWE benchmarks are from the \nNIST SAMATE test suite for static analysis2, space is a .ight control software3, ansicon is a con\u00adsole \ntext processor, and the rest of the small benchmarks are sam\u00adple drivers from Windows Driver Kit4. The \nset of larger Windows benchmarks has been anonymized. Each Drv* is a set of multiple drivers in Windows \nand Lib1 is a core component of the Windows kernel. All benchmarks were compiled from C to the BO O G \nIE pro\u00adgramming language using the HAVOC tool [3]. Although our tech\u00adnique works for arbitrary assertions, \nthe only assertions contained in these programs are assertions of the form x != null automati\u00adcally inserted \nby HAVOC before each pointer dereference *x. For each procedure, we unroll the loops twice. This allows \nus to focus on the (still substantial) subset of warnings from program veri.ers that do not arise from \nanalysis imprecision in handling loops. Experiments. We performed experiments with the goal of eval\u00aduating \nboth the reduction in warnings (Section 5.1.1) and the pre\u00adcision/completeness trade offs (Section 5.1.2) \ninduced by the ab\u00adstractions and clause pruning. Finally, we evaluated the usability of AC S PE C on \nlarger programs by running the tool on over 1M lines of Windows code (Section 5.1.3). We triaged the \nhighest priority warnings and compiled statistics on the performance of the tool. Experimental setup. \nFor each benchmark we checked for SIBs with the Conc con.guration and abstract SIBs with the A0, A1, \nand A2 con.gurations. Cons refers to the conservative veri.er we 2 http://samate.nist.gov/SRD/testsuite.php \n3 http://sir.unl.edu/portal/index.html 4 http://www.microsoft.com/whdc/devtools/ddk/default.mspx  Bench \nProc Asrt Conc k=3 k=2 k=1 A1 k=3 k=2 k=1 A2 k=3 k=2 k=1 Cons TO CWE476 561 228 CWE690 1865 1009 ansicon \n289 325 space 263 2144 cancel 9 9 event 7 4 .re.y 9 22 mou.lter 7 25 vserial 23 102 32 36 1 2 0 0 0 0 \n0 32 32 34 36 36 60 4 5 5 94 131 150 0 0 0 0 0 1 2 4 5 0 0 0 10 2 11 32 32 32 34 54 54 54 60 2 17 18 \n20 6 27 18 243 0 0 0 2 0 0 0 0 0 0 2 2 0 0 0 0 0 0 10 11 36 36 36 36 105 105 105 105 5 26 26 28 9 22 \n28 30 0 0 0 2 0 0 0 0 4 4 4 4 5 5 5 5 8 10 12 12 126 348 60 313 2 1 7 8 24 0 0 9 39 1 0 0 0 1 Total 3033 \n3868 71 178 210 266 94 130 134 372 172 208 216 222 889 50 Figure 6. Comparison of abstract con.gurations \nand clause prun\u00ading on small benchmarks. For each abstract con.guration (Conc, A1 , A2 ), we show results \nwith no clause pruning (k = 8) and with pruning from k = 3 to 1. TO denotes the number of timeouts. use \n(BOOG I E). We omit results for A0 because it performed the same as A2 on all benchmarks we tried. Timeout \nwas set to 10 seconds; we omit procedures that timed out in any con.guration. Experiments were run on \na Windows 7 desktop machine with a 2.66 GHz processor and 6 GB of RAM and a Windows 7 laptop with a 1.3 \nGHz processor and 4 GB of RAM. 5.1 Evaluation 5.1.1 Warning reduction In our .rst experiment, we compared \nthe the number of warnings reported by Conc, A1 , and A2 abstract con.gurations both without clause pruning \nand with k-clause pruning for k = 1 to 3 (Figure 6). In k-clause pruning, we prune clauses with > k literals \nout of speci.cations (\u00a7 4.3). We observe that: Without clause pruning, all abstract con.gurations report \nmany fewer warnings than Cons. Even the coarsest abstract con.gu\u00adration (A2) reported at least 2X fewer \nalarms than the conser\u00advative veri.er on almost all benchmarks.  Clause pruning steadily increases the \nnumber of alarms re\u00adported as k decreases. This effect is relatively stable across ab\u00adstract con.gurations, \nbut is much more dramatic for Conc and A1. Even with clause pruning, all con.gurations still report less \nthan half as many alarms as Cons on most benchmarks.  Interestingly, combining aggressive clause pruning \nwith a coarser abstraction can sometimes result in a lower number of errors than a .ner abstraction at \nthe same level of clause pruning (for example, the .re.y benchmark under 1-clause pruning in the Conc \nand A1 con.gurations). This is because abstractions remove predicates and consequently force the generation \nof simpler (and less disjunctive) specs. An example illustrates how this can occur: L1: grid_ptr = malloc(); \nL2: if (grid_ptr == NULL) return; L3: x = *key; The weakest speci.cation for Conc (.L1.malloc.return \n== 0 || key != 0) has a disjunction. However, A1 s predicate vo\u00adcabulary does not allow predicates from \nconditionals, so the angelic speci.cation is the simpler key != 0. Though both specs prove the program \ncorrect without creating dead code, the former con\u00adtains one disjunction, so it is pruned to true by \n1-clause pruning and reports a warning. 5.1.2 Precision and completeness trade offs Our next experiment \ninvestigated whether the additional alarms re\u00advealed by adding abstractions and/or clause pruning to \nthe Conc con.guration were real bugs or false positives. We performed a complete classi.cation of the \nerror reports for Cons, Conc, and Figure 7. Full classi.cation of alarms for the SAMATE bench\u00admark suite \nacross abstract con.gurations with no clause pruning. We give the number of assertions classi.ed correctly \n(C), number of false positives (FP), and number of false negatives (FN). Conc A1 A2 Cons Bnch Asrt C \nFP FN C FP FN C FP FN C FP FN CWE476 CWE490 228 1009 179 0 775 0 49 234 179 0 793 0 49 216 179 2 844 \n0 47 165 183 45 0 931 78 0 Total 1237 954 0 283 972 0 265 1023 2 212 1114 123 0 the abstract con.gurations \nfor two benchmarks: CWE476 and CWE690. We chose these because they are from a NIST test suite for static \nanalysis tools in which dereferences are labeled as safe or buggy (with 36% and 27% assertions buggy \nfor CWE476 and CWE690 respectively). We omit the results for clause pruning be\u00adcause they were nearly \nidentical to the results shown. Figure 7 shows the results. We can observe the following: Adding abstractions \n(such as A1 and A2) to Conc allows us to report more real bugs than the concrete domain while barely \nincreasing the number of false positives. The few false positives our abstract domains report are due \nto the havoc return values abstraction as shown in \u00a7 4.4.2 and \u00a7 4.4.3.  Even the coarsest abstraction \nfails to report lots of real bugs. This is expected our stated goal is to report a small number of high \ncon.dence bugs with a low false positive rate. Many false negatives occur because there is no (abstract) \ninconsistency when the procedures bodies are simple, but buggy (e.g. void Foo(x) { *x = 1;}). To catch \nsuch bugs, we plan to extend our current method to assert the weakest precondition of simple procedures \nat call sites.   5.1.3 Larger benchmarks In this section, we evaluate ACSP E C on the set of core Windows \nbenchmarks, measuring over a million lines. The results are shown5 in Figure 8. Bench Proc Asrt Conc \nA1 A2 Cons TO Drv1 799 14402 2 5 44 399 401 Drv2 1218 13843 0 0 61 766 370 Drv3 67 692 0 0 1 63 18 Drv4 \n401 3582 0 0 12 262 61 Drv5 661 11250 0 0 31 353 294 Drv6 490 7381 0 0 84 287 114 Drv7 16753 172973 1 \n11 876 12596 1369 Lib1 1158 10051 1 3 171 552 317 Total 21547 234174 4 19 1280 15278 2944 Figure 8. \nComparison of abstract con.gurations on large bench\u00admarks. TO denotes the number of timeouts. We brie.y \ncomment on trends in the data: As on the smaller benchmarks, the abstract con.gurations pro\u00advide a knob \nthrough which gradually more errors can be viewed by adding abstractions to Conc.  With the possible \nexception of A2, the abstract con.gurations show a number of warnings small enough that a willing user \ncould feasibly examine them. As expected, the conservative ver\u00adi.er reports more warnings than most users \nwould reasonably want to examine.  5 Our tool did not analyze around 5000 procedures in Drv7 due to \nan out-of-memory error. The results do not include these procedures or their assertions.  We investigated \nmost of the warnings reported by the Conc and A1 con.gurations. All of the reports we examined were false \npos\u00aditives, which is perhaps not entirely surprising since the property we are testing for is very shallow \nand these benchmarks are old and well-tested Windows code. Many false positives were due to expansion \nof macros (a prob\u00adlem also encountered by [11] [21]). One extensively used macro pattern defensively \nchecks for NULL before dereferencing a .eld: #define CheckFieldF(x, a) (x != NULL &#38;&#38; x->f == \na) The short-circuiting semantics of &#38;&#38; causes us to view this as a conditional expression, which \nmeans that a code snippet such as y = *x; if(CheckFieldF(x, a)) ... is expanded to y = *x; if (x != NULL) \n{...} else {L1: ...}. Conc .ags this as a SIB since the location L1 is unreachable for the speci.cation \nx != NULL. We manually validated that x can never be never be NULL in each of these cases, which means \nthat this check is too defensive, but not buggy. Another cause for the Conc warnings is the presence \nof macros that encode an assertion in terms of assert false as follows: #define SL_ASSERT(e) if (!e) \nassert(false) Our tool insists that the then branch of such code be reachable, although the user expects \nit to be reachable only when the assertion fails. Macro expansion corresponds to a form of inlining callees, \nand the heuristic of absence of dead code can sometimes be too strong interprocedurally [9] (due to defensive \ncoding in the callees). Most of the A1 warnings happen either due to one of the reasons above, or due \nto the removal of correlations that appear to be true preconditions. A common pattern that we observe \n(names anonymized) is the following: void Process(size_t mBufferLength, char *mBuffer, ..){ ... 1: if \n(mBufferLength >= 0) { ... 2: for (size_t i = 0; i < mBufferLength; ++i) { ... 3: assert(mBuffer != null); \nmBuffer[i] = ..; } .... } 5: if (mBuffer != null) { .... } where the tool avoids the error in Line 3 \nduring Conc analysis by inferring the correct precondition: mBufferLength >= 0 =. mBuffer != 0, which \ndoes not create any dead code. However, A1 results in a stronger speci.cation mBuffer != 0, which cre\u00adates \ndead code for the else branch for Line 5 and reveals a SIB. A vast majority of the A2 warnings are due \nto an overly con\u00adservative modeling of calls in HAVOC, where all .elds (modeled as maps) are present \nin the set of modi.ed globals for a call. Any nested dereference of a .eld x->f->g (modeled as g[f[x]]) \nafter a call to (say) bar results in a warning since A2 can t capture that x->f != 0 (expressed as f[x] \n!= 0) after the call to bar. On the other hand, both Conc and A1 can add a speci.cation ..bar.f[x] != \n0 since the modi.ed values have associated symbolic constants.  5.1.4 Performance Figure 9 describes \nthe performance of our tool on the large bench\u00admark set. We do not report any statistics for procedures \nthat the con\u00adservative veri.er labels as correct. We note that: (1) As expected, A1 and A2 collect fewer \npredicates than Conc. (2) Interestingly, the number of clauses in the predicate cover is relatively stable \nacross all three con.gurations even though Conc runs noticeably slower than the other two domains. Conc \nA1 A2 Bench P C T P C T P C T Drv1 3.5 1.1 2.7 2.0 1.0 2.2 1.8 0.9 2.1 Drv2 4.5 1.1 2.0 2.4 1.1 1.3 \n2.2 1.0 1.2 Drv3 3.6 1.3 2.3 2.8 1.3 1.6 2.6 1.3 1.6 Drv4 4.1 1.6 2.7 2.6 1.5 1.9 2.5 1.5 1.9 Drv5 3.6 \n1.0 2.3 1.7 0.9 1.4 1.4 0.8 1.4 Drv6 5.3 1.6 2.8 2.8 1.5 1.7 2.8 1.3 1.9 Drv7 3.3 1.3 1.1 2.5 1.2 0.8 \n2.4 1.1 0.8 Lib1 6.1 1.5 2.3 3.1 1.2 1.3 2.0 1.0 1.2 Figure 9. Performance on large benchmarks expressed \nas per\u00adprocedure averages. P is av. predicates/procedure, C is av. clauses in the predicate cover/procedure, \nand T is av. time/procedure in seconds. Finally, as we can see from Figure 8, we time out on 14% of the \nprocedures that the conservative veri.er does not label as correct6 . We found that the sources of timeouts \nare mixed. Some of the larger procedures take more than 10 seconds to compute Fail () and Dead (); others \ntime out during the predicate cover generation, and a smaller number time out during the search for almost-correct \nspeci.cations. In the latter case, we can at least answer the question about the existence of a SIB in \nthe procedure. We believe that using the incremental Z3 interface will signi.cantly reduce timeouts by \npreventing redundant VC generation. 6. Related work Engler et al. introduced inconsistency detection \n[11] as a practical approach for .nding bugs in real programs. They identify a set of templates for inconsistent \nprogrammer beliefs such as *<p> . . . if (<p> != null) that can be matched to patterns in real code in \norder to .nd likely bugs. They rank occurrences of these pat\u00adterns using statistical analysis and use \nthis simple but powerful combination to discover hundreds of new bugs in open source soft\u00adware. They \nbuild on this work with techniques for suppressing false alarms stemming from polluted analysis results \n[17] and a com\u00adbination of this approach with factor-based statistical techniques to automatically infer \nrich function speci.cations, such as which functions allocate and de-allocate memory [18]. Dillig et \nal. provide the .rst semantic formulation of inconsis\u00adtency errors [9]. In their framework, an inconsistency \nis a discrep\u00adancy between two related checks (i.e., a dereference): an incon\u00adsistency exists when there \nare two checks on the same predicate such that one check always succeeds, but the other may fail. They \nformally distinguish inconsistency errors from source-sink errors which require directly tracking the \n.ow of a bad value across the program. Finally, they provide a scheme for interprocedural incon\u00adsistency \ndetection based on inlining failure summaries for proce\u00addures at their call sites. The recent work of \nTomb and Flanagan [21] is the closest to identifying a connection between weakest precondition and (con\u00adcrete) \ninconsistency checking in terms of assertions. Their incon\u00adsistency detection works by splitting a procedure \npr with c con\u00additionals into 2c wedge programs, where each wedge blocks one of the two branches of a \nconditional statement. An inconsistency is reported if any wedge program fails on all inputs. Both of \nthese works [9, 21] validate that numerous bugs can be found using se\u00admantic inconsistency checking. \nOur approach is inspired by both of these formulations of incon\u00adsistency checking, although our goal \nis not limited to .nding incon\u00adsistency bugs. There are several differences between our work and 6 We \nignore the 5000 procedures that were not analyzed due to the memory problem.  theirs. First, our formulation \nof inconsistency checking can be pa\u00adrameterized with an abstraction, which allows us to apply the idea \nto a more general class of errors. Second, we compute the almost\u00adcorrect speci.cations for a procedure, \nwhich allows us to witness inconsistency bugs as the failures induced by these speci.cations. Finally, \nthere are subtle discrepancies in the de.nition of incon\u00adsistency due to differences in formalism. For \nexample, [21] would not report an inconsistency error for the procedure Foo in \u00a7 4.4.2, whereas [9] would \n[21]. Our formulation agrees with [21] in that we would characterize this program as an abstract SIB \nrather than a concrete SIB. On the other hand, we would report a concrete SIB for the program if (*) \nthen assert e else assert \u00ace, since there are no inputs that satisfy both assertions. [21] would not \n.ag this program since neither of the two wedge programs is guaranteed to fail. We believe that [9] would \nnot report this as an error since neither assertion is guarded by a check that guarantees its success. \nSimilar reasoning (due to the presence of non-determinism) shows that [21] will miss reporting a SIB \nfor the example in Figure 1. In addition to prior work on semantic inconsistency, there are other generic \napproaches to reducing false alarms in static analy\u00adsis. Necessary preconditions [5] are conditions that \nare shared by all non-faulting execution traces. Even without abstraction, the pre\u00adconditions inferred \nby our approach are (in general) incomparable to necessary preconditions. For the program if (x) { assert \nx; } assert x, the necessary precondition is x, but the almost\u00adcorrect speci.cation is true, and thus \nthe necessary precondition is stronger. For the program if (*) assert x, the necessary pre\u00adcondition \nis true, and the almost-correct speci.cation is x, and so the almost-correct speci.cation is stronger. \nThe work on doomed program points [15] reduces false alarms by looking for assertions that will fail \nfor all possible inputs. Such assertions are a special case of our SIBs. Recent work by Dillig et al. \n[10] use abductive inference with user feedback to classify alarms. We believe that the two approaches \nare largely complementary. The framework in [10] mainly addresses the problem of false alarms resulting \nfrom anal\u00adysis imprecision instead of imprecision from the environment. Our framework can aid this work \nby identifying the initial set of warn\u00adings to display to the user for further classi.cation. On the \nother hand, the use of quanti.er elimination for abduction can provide an alternate way to discover almost-correct \nspeci.cations. The work on interleaved bugs [16] addresses the underspeci.ed precondition problem for \nthe speci.c case of checking concurrency bugs by us\u00ading the simpler sequential executions as a .lter. \nOur approach applies in the sequential setting and does not use any simpler be\u00adhaviors as oracles. 7. \nConclusions and future work In this paper, we make the case for using semantic methods to make program \nveri.ers less demonic in the face of uncertainty. We introduce the concepts of abstract semantic inconsistency \nbugs and almost-correct speci.cations, which allow program veri.ers to avoid reporting a class of stupid \nfalse alarms without being overly angelic. We show that our framework can be instantiated to .nd the \ndemonstrably useful class of semantic inconsistency bugs. Our preliminary results demonstrate that the \ntechnique can be useful in suppressing many obviously demonic environments and improving the quality \nof warnings. There are several directions for extending this work: We would like to discover more interesting \nabstractions, possibly by using user feedback for guidance. Extending our current work to perform limited \ninterprocedural analysis [9] by asserting failure precondi\u00adtions at call sites will increase the scope \nof analysis and increase the set of abstract SIBs. Finally, we plan to conduct a user study to understand \nthe quality of the alarms we report initially. References [1] M. Barnett, K. R. M. Leino, and W. Schulte. \nThe Spec# programming system: An overview. In Construction and Analysis of Safe, Secure and Interoperable \nSmart Devices, LNCS, 2005. [2] A. Bessey, K. Block, B. Chelf, A. Chou, B. Fulton, S. Hallem, C. Henri-Gros, \nA. Kamsky, S. McPeak, and D. Engler. A few bil\u00adlion lines of code later: using static analysis to .nd \nbugs in the real world. Commun. ACM, 53(2):66 75, Feb. 2010. [3] J. Condit, B. Hackett, S. K. Lahiri, \nand S. Qadeer. Unifying type checking and property checking for low-level code. In Principles of Programming \nLanguages (POPL 09), pages 302 314, 2009. [4] P. Cousot and R. Cousot. Abstract interpretation : A Uni.ed \nLattice Model for the Static Analysis of Programs by Construction or Approx\u00adimation of Fixpoints. In \nSymposium on Principles of Programming Languages (POPL 77). ACM Press, 1977. [5] P. Cousot, R. Cousot, \nM. F \u00a8ahndrich, and F. Logozzo. Automatic inference of necessary preconditions. In VMCAI, pages 128 148, \n2013. [6] L. de Moura and N. Bj\u00f8rner. Z3: An ef.cient SMT solver. In Interna\u00adtional Conference on Tools \nand Algorithms for the Construction and Analysis of Systems (TACAS 08), 2008. [7] R. DeLine and K. R. \nM. Leino. BoogiePL: A typed procedural language for checking object-oriented programs. Technical Report \nMSR-TR-2005-70, Microsoft Research, 2005. [8] E. W. Dijkstra. Guarded commands, nondeterminacy and formal \nderivation of programs. Communications of the ACM, 1975. [9] I. Dillig, T. Dillig, and A. Aiken. Static \nerror detection using seman\u00adtic inconsistency inference. In Programming Language Design and Implementation \n(PLDI 07), pages 435 445, 2007. [10] I. Dillig, T. Dillig, and A. Aiken. Automated error diagnosis using \nabductive inference. In Proceedings of the 33rd ACM SIGPLAN conference on Programming Language Design \nand Implementation, PLDI 12, pages 181 192, New York, NY, USA, 2012. ACM. [11] D. R. Engler, D. Y. Chen, \nand A. Chou. Bugs as inconsistent behavior: A general approach to inferring errors in systems code. In \nSymposium on Operating Systems Principles (SOSP 01), pages 57 72, 2001. [12] C. Flanagan, K. R. M. Leino, \nM. Lillibridge, G. Nelson, J. B. Saxe, and R. Stata. Extended static checking for Java. In Programming \nLanguage Design and Implementation (PLDI 02), 2002. [13] C. Flanagan and J. B. Saxe. Avoiding exponential \nexplosion: gener\u00adating compact veri.cation conditions. In Symposium on Principles of Programming Languages \n(POPL 01), pages 193 205. ACM, 2001. [14] S. Graf and H. Sa\u00a8idi. Construction of abstract state graphs \nwith PVS. In Computer-Aided Veri.cation (CAV 97). [15] J. Hoenicke, K. R. M. Leino, A. Podelski, M. Sch\u00a8af, \nand T. Wies. Doomed program points. Formal Methods in System Design, 37(2\u00ad3):171 199, 2010. [16] S. Joshi, \nS. K. Lahiri, and A. Lal. Underspeci.ed harnesses and interleaved bugs. In Principles of Programming \nLanguages (POPL 12), pages 19 30. ACM, 2012. [17] T. Kremenek and D. R. Engler. Z-ranking: Using statistical \nanalysis to counter the impact of static analysis approximations. In Static Analysis Symposium (SAS 03), \nLNCS 2694, pages 295 315, 2003. [18] T. Kremenek, P. Twohey, G. Back, A. Y. Ng, and D. R. Engler. From \nuncertainty to belief: Inferring the speci.cation within. In OSDI, 2006. [19] S. K. Lahiri, R. Nieuwenhuis, \nand A. Oliveras. Smt techniques for fast predicate abstraction. In Computer Aided Veri.cation (CAV 06), \nLecture Notes in Computer Science, 2006. [20] NIST SAMATE Benchmarks. http://samate.nist.gov/SRD/ testsuite.php. \n[21] A. Tomb and C. Flanagan. Detecting inconsistencies via universal reachability analysis. In International \nSymposium on Software Testing and Analysis (ISSTA 12), 2012.      \n\t\t\t", "proc_id": "2491956", "abstract": "<p>Modular assertion checkers are plagued with false alarms due to the need for precise environment specifications (preconditions and callee postconditions). Even the fully precise checkers report assertion failures under the most demonic environments allowed by unconstrained or partial specifications. The inability to preclude overly adversarial environments makes such checkers less attractive to developers and severely limits the adoption of such tools in the development cycle.</p> <p>In this work, we propose a parameterized framework for prioritizing the assertion failures reported by a modular verifier, with the goal of suppressing warnings from overly demonic environments. We formalize it almost-correct specifications as the minimal weakening of an angelic specification (over a set of predicates) that precludes any dead code intraprocedurally. Our work is inspired by and generalizes some aspects of semantic inconsistency detection. Our formulation allows us to lift this idea to a general class of warnings. We have developed a prototype acspec, which we use to explore a few instantiations of the framework and report preliminary findings on a diverse set of C benchmarks.</p>", "authors": [{"name": "Sam Blackshear", "author_profile_id": "81460655714", "affiliation": "University of Colorado, Boulder, CO, USA", "person_id": "P4149001", "email_address": "samuel.blackshear@colorado.edu", "orcid_id": ""}, {"name": "Shuvendu K. Lahiri", "author_profile_id": "81100338283", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P4149002", "email_address": "shuvendu@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462188", "year": "2013", "article_id": "2462188", "conference": "PLDI", "title": "Almost-correct specifications: a modular semantic framework for assigning confidence to warnings", "url": "http://dl.acm.org/citation.cfm?id=2462188"}