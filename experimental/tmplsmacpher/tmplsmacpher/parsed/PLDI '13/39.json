{"article_publication_date": "06-16-2013", "fulltext": "\n Hybrid Context-Sensitivity for Points-To Analysis George Kastrinis Yannis Smaragdakis Department of \nInformatics University of Athens {gkastrinis,smaragd}@di.uoa.gr Abstract Context-sensitive points-to \nanalysis is valuable for achieving high precision with good performance. The standard .avors of context\u00adsensitivity \nare call-site-sensitivity (kCFA) and object-sensitivity. Combining both .avors of context-sensitivity \nincreases precision but at an infeasibly high cost. We show that a selective combi\u00adnation of call-site-and \nobject-sensitivity for Java points-to anal\u00adysis is highly pro.table. Namely, by keeping a combined context \nonly when analyzing selected language features, we can closely approximate the precision of an analysis \nthat keeps both contexts at all times. In terms of speed, the selective combination of both kinds of \ncontext not only vastly outperforms non-selective combi\u00adnations but is also faster than a mere object-sensitive \nanalysis. This result holds for a large array of analyses (e.g., 1-object-sensitive, 2-object-sensitive \nwith a context-sensitive heap, type-sensitive) es\u00adtablishing a new set of performance/precision sweet \nspots. Categories and Subject Descriptors F.3.2 [Logics and Meanings of Programs]: Semantics of Programming \nLanguages Program Analysis; D.3.4 [Programming Languages]: Processors Compilers General Terms Algorithms, \nLanguages, Performance Keywords points-to analysis; context-sensitivity; object\u00adsensitivity; type-sensitivity \n1. Introduction Points-to analysis is a static program analysis that consists of com\u00adputing all objects \n(typically identi.ed by allocation site) that a pro\u00adgram variable may point to. The area of points-to \nanalysis (and its close relative, alias analysis) has been the focus of intense re\u00adsearch and is among \nthe most standardized and well-understood of inter-procedural analyses. The emphasis of points-to analysis \nalgo\u00adrithms is on combining fairly precise modeling of pointer behavior with scalability. The challenge \nis to pick judicious approximations that will allow satisfactory precision at a reasonable cost. Further\u00admore, \nalthough increasing precision often leads to higher asymp\u00adtotic complexity, this worst-case behavior \nis rarely encountered in actual practice. Instead, techniques that are effective at maintaining good \nprecision often also exhibit better average-case performance, since smaller points-to sets lead to less \nwork. Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n13, June 16 19, 2013, Seattle, WA, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . \n$15.00 One of the major tools for exploiting sweet spots in the pre\u00adcision/performance tradeoff has been \ncontext-sensitivity. Context\u00adsensitivity consists of qualifying local variables and objects with context \ninformation: the analysis uni.es executions that map to the same context value, while separating executions \nthat map to differ\u00adent contexts. This approach tries to counter the loss of precision that naturally \nresults in any static analysis from con.ating information from different dynamic program paths. Two main \nkinds of context\u00adsensitivity have been explored in the literature: call-site-sensitivity [22, 23] and \nobject-sensitivity [18, 19, 24]. A call-site-sensitive/kCFA analysis uses method call-sites (i.e., labels \nof instructions that may call the method) as context elements. That is, the analysis separates information \non local variables (e.g., method arguments) per call-stack (i.e., sequence of k call-sites) of method \ninvocations that led to the current method call. Similarly, the analysis separates information on heap \nobjects per call-stack of method invocations that led to the object s allocation. For instance, in the \ncode example below, a 1-call-site-sensitive analysis (unlike a context-insensitive analysis) will distinguish \nthe two call-sites of method foo on lines 7 and 9. This means that the analysis will treat foo separately \nfor two cases: that of its formal argument, o, pointing to anything obj1 may point to, and that of o \npointing to anything obj2 may point to. 1 class C { 2 void foo(Object o) { ... } 3 } 4 5 class Client \n{ 6 void bar(C c1, C c2) { ... 7 c1.foo(obj1); 8 ... 9 c2.foo(obj2); 10 } 11 } In contrast, object-sensitivity \nuses object allocation sites (i.e., labels of instructions containing a new statement) as context elements. \n(Hence, a better name for object-sensitivity might have been allocation-site sensitivity .) That is, \nwhen a method is called on an object, the analysis separates the inferred facts depending on the allocation \nsite of the receiver object (i.e., the object on which the method is called), as well as other allocation \nsites used as context. Thus, in the above example, a 1-object-sensitive analysis will analyze foo separately \ndepending on the allocation sites of the objects that c1 and c2 may point to. It is not apparent from \nthis code fragment neither whether c1 and c2 may point to different objects, nor to how many objects: \nthe allocation site of the receiver object may be remote and unrelated to the method call itself. Similarly, \nit is not possible to compare the precision of an object-sensitive and a call-site-sensitive analysis \nin principle. In this example, it is not even clear whether the object sensitive analysis will examine \nall calls to foo as one case, as two, or as many more, since this depends on the allocation sites of \nall objects that the analysis itself computes to .ow into c1 and c2.  The question behind our work is \nwhether the two kinds of contexts can be fruitfully combined, since they are quite dissimilar. In order \nto address this question, we map the design space of hybrid call-site-and object-sensitive analyses and \ndescribe the combinations that arise. Naive hybrids, such as always maintaining as context both a call-site \nand an allocation site, do not pay off, due to extremely high cost. For instance, keeping one call-site \nand one allocation site as context yields a very expensive analysis, on average 3.9x slower than a simple \n1-object-sensitive analysis. However, we .nd that more sophisticated hybrids are highly bene.cial. Speci.cally, \nwe show that we can switch per-language\u00adfeature between a combined context and an object-only context. \nFor instance, contexts for static method calls are computed differ\u00adently from contexts for dynamic method \ncalls. This approach yields analyses with both low cost and high precision. Furthermore, adapt\u00ading contexts \nper program feature de.nes a complex design space and allows even further optimization. Design choices \narise, such as, how should the context adapt when a dynamic method call, or an object allocation are \nmade inside a static method? The end result is analyses that closely track the precision of combined \ncall-site-and-object-sensitivity while incurring none of the cost. In fact, the cost of the resulting \nanalysis is usually less (and occasionally much less) than that of just an object-sensitive analysis, \ndue to increased precision. This effect is shown to apply widely, to several variants of analyses. Accordingly, \nthis outcome establishes new sweet spots for the analyses most relevant for prac\u00adtical applications: \n1-object-sensitive, 2-object-sensitive with a 1\u00adcontext-sensitive heap, and analogous type-sensitive \n[24] analyses. For all of them, a selective hybrid context is typically both more precise and faster \nthan the original analysis. In all, our paper makes the following contributions: We model the parameter \nspace of context-sensitive points-to analysis in a way that allows both call-site-and object-sensitivity, \nas well as combinations and switching of context at key points (virtual calls vs. static calls). In this \nspace, we map out choices that produce entirely different .avors of algorithms.  We introduce the idea \nof hybrid call-site-and object-sensitivity where the two kinds of context are freely mixed and the mix \nis adjusted in response to analyzing different program features. The goal is to achieve the precision \nof keeping both kinds of context together, but at the same cost as keeping only one.  We implement our \napproach in the DO O P framework by Braven\u00adboer et al. [4] and apply it to a large variety of algorithms \nwith varying context depth.  We show experimentally, over large Java benchmarks and the Java JDK, that \nhybrid context-sensitivity works remarkably well. The selective application of a combined context achieves \nthe same effective precision as keeping both contexts at all times, at a fraction of the cost, and is \ntypically faster even than keeping only an object context. For instance, in the practically important \ncase of a 2-object-sensitive analysis with a context-sensitive heap, we get an average speedup of 1.53x \nand a more precise analysis. Similarly, for the simple and popular 1-object-sensitive analysis, we get \nan average speedup of 1.12x combined with signi.cant increase in precision.  The rest of the paper introduces \na model for points-to analysis (Section 2) and shows how instantiating the model yields several well-known \nanalyses. In Section 3 we discuss the many choices for combining object-and call-site-sensitivity, as \nwell as the most promising points in this design space. Our evaluation results follow in Section 4, before \ndescribing related work (Section 5). 2. Modeling of Points-To Analysis We begin with a concise modeling \nof the relevant points-to analyses and their context choices. 2.1 Background: Parameterizable Model \nWe model a spectrum of .ow-insensitive points-to analyses and joint (online) call-graph construction \nas a parametric Datalog pro\u00adgram. Datalog rules are monotonic logical inferences that repeat\u00adedly apply \nto infer more facts until .xpoint. Our rules do not use negation in a recursive cycle, or other non-monotonic \nlogic con\u00adstructs, resulting in a declarative speci.cation: the order of evalu\u00adation of rules or examination \nof clauses cannot affect the .nal re\u00adsult. The same abstract model applies to a wealth of analyses. We \nuse it to model a context-insensitive Andersen-style [2] analysis, as well as several context-sensitive \nanalyses, both call-site-sensitive and object-sensitive. The input language is a representative simpli.ed \nintermediate language with a) a new instruction for allocating an object; b) a move instruction for copying \nbetween local variables; c) store and load instructions for writing to the heap (i.e., to object .elds); \nd) a virtual method call instruction that calls the method of the appropriate signature that is de.ned \nin the dynamic class of the receiver object; e) a static method call instruction that calls a statically \nknown target method. This language models well the Java bytecode representation, but also other high-level \nintermediate languages. (It does not, however, model languages such as C or C++ that can create pointers \nthrough an address-of operator. The techniques used in that space are fairly different e.g., [8, 9] although \nour main hybrid approach is likely to be applicable. Also, even though we model regular object .elds \nand static methods, we omit static .elds. Their treatment is a mere engineering complexity, as it does \nnot interact with context choice.) The speci.cation of our points-to analysis as well as the input language \nare in line with those in past literature [6, 16], although we also integrate elements such as on-the-.y \ncall-graph construction, static calls, and .eld\u00adsensitivity. Specifying the analysis logically as Datalog \nrules has the ad\u00advantage that the speci.cation is close to the actual implementation. Datalog has been \nthe basis of several implementations of program analyses, both low-level [4, 11, 20, 30, 31] and high-level \n[5, 7]. Indeed, the analysis we show is a faithful model of the implemen\u00adtation in the DO OP framework \n[4], upon which our work builds. Our speci.cation of the analysis (Figures 1-2) is an abstraction of \nthe actual implementation in the following ways: The implementation has many more rules. It covers the \nfull complexity of Java, including rules for handling re.ection, na\u00adtive methods, static .elds, string \nconstants, implicit initialization, threads, and a lot more. The DO O P implementation1 currently contains \nover 600 rules in the common core of all analyses, and several more rules speci.c to each analysis, as \nopposed to the 9 rules we examine here. (Note, however, that these few rules are the most crucial for \npoints-to analysis. They also correspond fairly closely to the algorithms speci.ed in other formalizations \nof points-to analyses in the literature [17, 24].)  The implementation also re.ects considerations for \nef.cient exe\u00adcution. The most important is that of de.ning indexes for the key relations of the evaluation. \nFurthermore, it designates some rela\u00adtions as functions, de.nes storage models for relations (e.g., how \nmany bits each variable uses), designates intermediate relations as materialized views or not, etc. No \nsuch considerations are re.ected in our model.  1 Available at http://doop.program-analysis.org/  V \nis a set of program variables H is a set of heap abstractions (i.e., allocation sites) M is a set of \nmethod identi.ers S is a set of method signatures (including name, type signature) F is a set of .elds \nI is a set of instructions (mainly used for invocation sites) T is a set of class types Nis the set \nof natural numbers C is a set of contexts H C is a set of heap contexts AL L O C (var : V, heap : H, \ninMeth : M) # var = new ... MOV E (to : V, from : V ) # to = from LOA D (to : V, base : V, .d : F) # \nto = base..d STO R E (base : V, .d : F, from : V ) # base..d = from VCA LL (base : V, sig : S, invo : \nI, inMeth : M) # base.sig(..) SCA L L (meth : M, invo : I, inMeth : M) # Class.meth(..) FOR M A L AR \nG (meth : M, i : N, arg : V ) AC T UAL AR G (invo : I, i : N, arg : V ) FOR M A L RE T U RN (meth : M, \nret : V ) AC T UAL RETUR N (invo : I, var : V ) TH I S VA R (meth : M, this : V ) HE A P TY P E (heap \n: H, type : T ) LO OKUP (type : T, sig : S, meth : M) VA RPOI N T S TO (var : V, ctx : C, heap : H, \nhctx : HC) CA L L GRA P H (invo : I, callerCtx : C, meth : M, calleeCtx : C) FL D PO IN TSTO (baseH: \nH, baseHCtx: HC, .d: F, heap: H, hctx: HC) IN T E R PRO C AS S I G N (to : V, toCtx : C, from : V, fromCtx \n: C) RE AC H A BL E (meth : M, ctx : C) RE CO RD (heap : H, ctx : C) = newHCtx : HC ME R G E (heap : \nH, hctx : HC, invo : I, ctx : C) = newCtx : C ME R G E STAT I C (invo : I, ctx : C) = newCtx : C Figure \n1: Our domain, input relations (representing program instructions with the matching program pattern shown \nin a comment and type information), output relations, and construc\u00adtors of contexts. Figure 1 shows the \ndomain of our analysis (i.e., the different value sets that constitute the space of our computation), \nits input re\u00adlations, the intermediate and output relations, as well as three con\u00adstructor functions, \nresponsible for producing new contexts. Figure 2 shows the points-to analysis and call-graph computation. \nThe rule syntax is simple: the left arrow symbol (.) separates the inferred facts (i.e., the head of \nthe rule) from the previously established facts (i.e., the body of the rule). For instance, the .rst \nrule states that, if we have computed a call-graph edge between invocation site invo and method meth \n(under some contexts see later), then we infer an inter-procedural assignment to the i-th formal argument \nof meth from the i-th actual argument at invo, for every i. We explain the contents of both .gures in \nmore detail below: The input relations correspond to the intermediate language for our analysis. They \nare logically grouped into relations that rep\u00adresent instructions and relations that represent name-and-type \nin\u00adformation. For instance, the AL L O C relation represents every in\u00adstruction that allocates a new \nheap object, heap, and assigns it to local variable var inside method inMeth. (Note that every lo\u00adcal \nvariable is de.ned in a unique method, hence the inMeth ar\u00adgument is also implied by var but is included \nto simplify later rules.) There are similar input relations for all other instruction types (MOVE, LOA \nD, STO R E, VCA L L, and SCA L L). Similarly, there are relations that encode pertinent symbol table \ninformation. Most of these are self-explanatory but some deserve explanation. LO OKUP matches a method \nsignature to the actual method de.ni\u00adtion inside a type. HEA P TYPE matches an object to its type, i.e., \nIN T ER PROC ASSI G N (to, calleeCtx, from, callerCtx) . CA L LGRAPH (invo, callerCtx, meth, calleeCtx), \nFO R M A L ARG (meth, i, to), AC TUA L AR G (invo, i, from). IN T ER PROC ASSI G N (to, callerCtx, from, \ncalleeCtx) . CA L LGRAPH (invo, callerCtx, meth, calleeCtx), FO R M A L RE T U RN (meth, from), ACT UA \nL RE T U RN (invo, to). RE C O R D (heap, ctx) = hctx, VA R PO IN TSTO (var, ctx, heap, hctx) . RE AC \nH A BL E (meth, ctx), AL L O C (var, heap, meth). VA R PO IN TSTO (to, ctx, heap, hctx) . MOVE (to, \nfrom), VA R PO INTSTO (from, ctx, heap, hctx). VA R PO IN TSTO (to, toCtx, heap, hctx) . IN T ER PRO \nC ASS I G N (to, toCtx, from, fromCtx), VA RPO I N TS TO (from, fromCtx, heap, hctx). VA R PO IN TSTO \n(to, ctx, heap, hctx) . LOAD (to, base, .d), VA R PO IN TSTO (base, ctx, baseH, baseHCtx), FL D PO INTSTO \n(baseH, baseHCtx, .d, heap, hctx). FL D PO I NT STO (baseH, baseHCtx, .d, heap, hctx) . STO RE (base, \n.d, from), VA R PO INTSTO (from, ctx, heap, hctx), VA RPO I N TS TO (base, ctx, baseH, baseHCtx). MER \nGE (heap, hctx, invo, callerCtx) = calleeCtx, REACH A BL E (toMeth, calleeCtx), VA R PO IN TSTO (this, \ncalleeCtx, heap, hctx), CA L LGR APH (invo, callerCtx, toMeth, calleeCtx) .  VCA L L (base, sig, invo, \ninMeth), RE AC H A B LE (inMeth, callerCtx), VA RPO I N TS TO (base, callerCtx, heap, hctx), HEA P TYPE \n(heap, heapT ), LO O K UP (heapT, sig, toMeth), TH IS VA R (toMeth, this). MER GE STAT I C (invo, callerCtx) \n= calleeCtx, REACH A BL E (toMeth, calleeCtx), CA L LGR APH (invo, callerCtx, toMeth, calleeCtx) . SCA \nLL (toMeth, invo, inMeth), REAC HAB L E (inMeth, callerCtx). Figure 2: Datalog rules for the points-to \nanalysis and call-graph construction. is a function on its .rst argument. (Note that we are shortening \nthe term heap object to just heap and represent heap objects as allocation sites throughout.) AC TUA \nL RE T U R N is also a func\u00adtion on its .rst argument (a method invocation site) and returns the local \nvariable at the call-site that receives the method call s return value. There are .ve output or intermediate \ncomputed relations (VAR PO I N T S TO, . . ., RE ACHAB L E). Every occurrence of a method or local variable \nin computed relations is quali.ed with a context (i.e., an element of set C), while every occurrence \nof a heap object is quali.ed with a heap context (i.e., an element of HC). The main output relations \nare VAR PO I N T S TO and CA LL -GRA P H, encoding our points-to and call-graph results. The VA R -POI \nN T S TO relation links a variable (var) to a heap object (heap). Other intermediate relations (FL D \nPO IN TSTO, IN TE R PROC AS-S I GN, REACH A BL E) correspond to standard concepts and are introduced \nfor conciseness. For instance, IN T E RPRO CAS S IGN (which encodes all parameter and return value passing) \nuni.es much of the treatment of static and virtual method calls.  The base rules are not concerned with \nwhat kind of context\u00adsensitivity is used. The same rules can be used for a context\u00adinsensitive analysis \n(by only ever creating a single context object and a single heap context object), for a call-site-sensitive \nanal\u00adysis, or for an object-sensitive analysis, for any context depth. These aspects are completely hidden \nbehind constructor func\u00adtions RE C OR D, ME R G E, and MER GE STAT I C. The .rst two fol\u00adlow the usage \nand naming convention of Smaragdakis et al. [24], while ME R G E STAT I C is new and used to differentiate \nthe treat\u00adment of static calls this is a crucial element of our approach. RE C O R D is the function \nthat creates a new heap context. It is invoked whenever an object allocation site (input relation AL-L \nOC) is analyzed. Thus, REC OR D is only used in the rule treating allocation instructions (3rd rule in \nFigure 2). RE C O R D takes all available information at the allocation site of an object and com\u00adbines \nit to produce a new heap context. The rule merely says that an allocation instruction in a reachable \nmethod leads us to infer a points-to fact between the allocated object and the variable it is directly \nassigned to. MERGE and ME R G E STAT I C are used to create new calling contexts (or just contexts ). \nThese contexts are used to qualify method calls, i.e., they are applied to all local variables in a pro\u00adgram. \nThe MERGE and ME RG ESTATIC functions take all avail\u00adable information at the call-site of a method (virtual \nor static) and combine it to create a new context (if one for the same combi\u00adnation of parameters does \nnot already exist). These functions are suf.cient for modeling a very large variety of context-sensitive \nanalyses, as we show in Sections 2.2 and 3. Note that the use of constructors, such as REC ORD, ME R \nG E, and ME R G ESTATI C, is not part of regular Datalog and can result in in.nite structures (e.g., \none can express unbounded call-site sensitivity) if care is not taken. All our later de.nitions statically \nguarantee to create contexts of a pre-set depth. The rules of Figure 2 show how each input instruction \nleads to the inference of facts for the .ve output or intermediate relations. The most complex rule is \nthe second-to-last, which handles virtual method calls (input relation VCAL L). The rule says that if \na reachable method of the program has an instruction making a virtual method call over local variable \nbase (this is an input fact), and the analysis so far has established that base can point to heap object \nheap, then the called method is looked up inside the type of heap and several further facts are inferred: \nthat the looked up method is reachable, that it has an edge in the call-graph from the current invocation \nsite, and that its this variable can point to heap. Additionally, the ME R G E function is used to possibly \ncreate (or look up) the right context for the current invocation.  2.2 Instantiating the Model: Standard \nAnalyses By modifying the de.nitions of the RECO RD, MER GE and ME R G ESTATI C functions as well as \ndomains HC and C, one can create endless variations of points-to analyses. We next discuss the most interesting \ncombinations from past literature, before we intro\u00adduce our own (in Section 3). For every analysis name \nwe also list a common abbreviation, which we often use later. Context-insensitive (insens). As already \nmentioned, our context\u00adsensitive analysis framework can yield a context-insensitive analy\u00adsis by merely \npicking singleton C and HC sets (i.e., C = HC = {*}, where * is merely a name for a distinguished element) \nand con\u00adstructor functions that return the single element of the set: RE C O R D (heap,ctx) = * ME RG \nE (heap, hctx, invo, ctx) = * ME RG ESTATIC (invo, ctx) = * Note that the absence of contexts does not \nmean that the identity of input elements is forgotten. Objects are still represented by their allocation \nsite (i.e., the exact program instruction that allocated the object) and local variables are still distinguished \n(e.g., by their dec\u00adlaration location in the input program). The absence of context just means that there \nis no extra distinguishing information. This can also be seen in the rules of Figure 2, where the var \nand heap predi\u00adcate arguments are present, separately from the context arguments. 1-call-site-sensitive \n(1call). A 1-call-site-sensitive analysis has no heap context to qualify heap abstractions (HC = {*}) \nand uses the current invocation site as a context (C = I). The following de.nitions describe such an \nanalysis. RE C O R D (heap, ctx) = * MERGE (heap, hctx, invo, ctx) = invo MERGE STATI C (invo, ctx) = \ninvo In words: the analysis stores no context when an object is created (RE C O R D) and keeps the invocation \nsite as context in both virtual and static calls. 1-call-site-sensitive with a context-sensitive heap \n(1call+H). The analysis is de.ned similarly to 1call.2 The heap context as well as the main context consist \nof an invocation site (HC = C = I). RE C O R D (heap, ctx) = ctx MERGE (heap, hctx, invo, ctx) = invo \nMERGE STATI C (invo, ctx) = invo In words: the analysis uses the current method s context as a heap context \nfor objects allocated inside the method. The invocation site of a method call is the context of the method \nfor both virtual and static calls. 1-object-sensitive (1obj). Object sensitivity uses allocation sites \nas context components. A 1-object-sensitive analysis has no heap context (HC = {*}) and uses the allocation \nsite of the receiver object as context (C = H). The following de.nitions complete the description. RE \nC O R D (heap, ctx) = * MERGE (heap, hctx, invo, ctx) = heap MERGE STATI C (invo, ctx) = ctx In words: \nthe analysis stores no context for allocated objects. For virtual method calls, the context is the allocation \nsite of the receiver object. For static method calls, the context for the called method is that of the \ncalling method. The above de.nition offers a .rst glimpse of the possibilities that we explore in this \npaper, and can serve as motivation. In static calls, the context of the caller method is copied, i.e., \nthe receiver object of the caller method is used as the new context. Why not try ME R GE STAT I C (invo, \nctx) = invo, instead of the current MERG E STATIC (invo, ctx) = ctx? Isn t it perhaps better to use call\u00adsites \nto differentiate static invocations, instead of blindly copying the context of the last non-static method \ncalled? A simple answer is that invo is an entity of the wrong type, since C = H. The only entity of \ntype H we have available at a static call-site is the current context, ctx. But if we let C = H . I, \nwe have a context type that is a hybrid of both an allocation site and an invocation site, and which \nallows the above alternative de.nition of ME R G ESTAT I C. We explore this and other such directions \nin depth in Section 3. 2-object-sensitive with a 1-context-sensitive heap (2obj+H). In this case, the \nheap context consists of one allocation site (HC = H) 2 The standard convention in the points-to analysis \nliterature is to name an analysis .rst according to the context of methods, and, if a heap context exists, \ndesignate it in a suf.x such as context-sensitive heap or heap cloning.  and the context consists of \ntwo allocation sites (C = H \u00d7 H). The de.nitions of constructor functions are:3 RE C O R D (heap, ctx) \n= .rst(ctx) ME RG E (heap, hctx, invo, ctx) = pair(heap, hctx) ME RG ESTATIC (invo, ctx) = ctx In words: \nthe context of a virtual method (see ME R GE) is a 2\u00adelement list consisting of the receiver object and \nits (heap) context. The heap context of an object (.xed at allocation, via RE CO RD) is the .rst context \nelement of the allocating method, i.e., the receiver object on which it was invoked. Therefore, the context \nof a virtual method is the receiver object together with the parent receiver object (the receiver object \nof the method that allocated the receiver object of the virtual call). Again, static calls just copy \nthe context of the caller method. Although there can be other de.nitions of the ME R G E function, yielding \nalternative 2-obj+H analyses, it has been shown [24] that the above is the most precise and scalable. \nIn intuitive terms, we use as method context the most precise abstraction of the receiver object available \nto the analysis. 2-type-sensitive with a 1-context-sensitive heap (2type+H). A type-sensitive analysis \nis step-by-step analogous to an object\u00adsensitive one, but instead of using allocation sites (i.e., instruc\u00adtions) \na type-sensitive analysis uses the name of the class contain\u00ading the allocation site. In this way, all \nallocation sites in methods de\u00adclared in the same class (though not inherited methods) are merged. This \napproximation was introduced by Smaragdakis et al. [24] and yields much more scalable analyses at the \nexpense of moderate pre\u00adcision loss (as we also determine in our experiments). In order to de.ne type-sensitive \nanalyses we need an auxiliary function which maps each heap abstraction to the class containing the allocation. \nCA : H . T Now we can de.ne a 2type+H analysis by mapping CA over the context of a 2obj+H analysis. The \nheap context uses a type instead of an allocation site (HC = T) and the calling context uses two types \n(C = T \u00d7 T). RE C O R D (heap, ctx) = .rst(ctx) ME RG E (heap, hctx, invo, ctx) = pair(CA(heap), hctx) \nME RG ESTATIC (invo, ctx) = ctx Other Analyses. The above discussion omits several analyses in the literature, \nin order to focus on a manageable set with practical relevance. We do not discuss a 1-object-sensitive \nanalysis with a context-sensitive heap (1obj+H) because it is a strictly inferior choice to other analyses \n(especially 2type+H) in practice: it is both much less precise and much slower. We do not present other \nvarieties of type-sensitivity for a similar reason. Deeper contexts or heap contexts (e.g., 2call+H, \n2obj+2H, 3obj, etc.) quickly make an analysis intractable for a substantial portion of realistic programs \nand modern JDKs. In short, we focus on the speci.c analyses (1call, 1call+H, 1obj, 2obj+H, 2type+H) that \nare of most practical interest: they are quite scalable over a variety of medium-to-large programs, and \nno other analysis supplants them by being uniformly better in both precision and performance. 3 We use \nauxiliary constructor functions pair, triple and accessors .rst, second, and third, with the expected \nmeaning, in order to construct and deconstruct contexts with 2 or 3 elements. This has the added advantage \nthat our context-depth is statically bounded we never create lists of unknown length. Since our most \ncomplex constructor is triple, the possible number of distinct contexts is cubic in the size of the input \nprogram. 3. Hybrid Context-Sensitive Analyses We can now explore interesting combinations of call-site-and \nobject-sensitivity. The design space is large and we will be selective in our presentation and later \nexperiments. Our choice of analyses in this space leverages insights from past studies on what kinds \nof context are bene.cial.4 Such insights include: A call-site-sensitive heap is far less attractive \nthan an object\u00adsensitive heap. Generally, adding a heap context to a call-site\u00adsensitive analysis increases \nprecision very slightly, compared to the overwhelming cost.  When there is a choice between keeping \nan object-context or a call-site-context, the former is typically more pro.table. This is well validated \nin extensive past measurements by Lhot\u00b4  ak and Hendren [14], comparing call-site-sensitive and object-sensitive \nanalyses of various depths. In other words, call-site-sensitivity is best added as extra context over \nan object-sensitive analysis and will almost never pay off as a replacement context, for an object\u00adoriented \nlanguage. 3.1 Uniform Hybrid Analyses The .rst kind of context combination is a straightforward one: \nboth kinds of context are kept. We term such combinations uniform hybrid analyses. In the variants we \ndescribe, a uniform hybrid analysis is guaranteed to be more precise5 than the base analysis being enhanced. \nThe question is whether such precision will justify the added cost. Uniform 1-object-sensitive hybrid \n(U-1obj). Enhancing a 1\u00adobject-sensitive analysis with call-site sensitivity results in an anal\u00adysis \nwith an empty heap context (HC = {*}) but with a context that consists of both the allocation site of \nthe receiver object and the in\u00advocation site of the method (C = H \u00d7 I). The following de.nitions describe \nthe analysis: RE C O R D (heap, ctx) = * MERGE (heap, hctx, invo, ctx) = pair(heap, invo) MERGE STATI \nC (invo, ctx) = pair(.rst(ctx), invo) In words: a virtual method has as context the abstraction of its \nreceiver object, extended with the method s invocation site. A static method keeps a context consisting \nof the most signi.cant part of the caller s context and the method s invocation site. Note that under \nthe above de.nitions, the context of a U-1obj analysis is always a superset of that of 1obj, hence the \nanalysis is strictly more precise. Uniform 2-object-sensitive with 1-context-sensitive heap hy\u00adbrid (U-2obj+H). \nA 2-object-sensitive analysis with a context\u00adsensitive heap can be enhanced in the same way. A heap context \nconsists of an allocation site (HC = H) and a method context con\u00adsists of two allocation sites and one \ninvocation site (C = H \u00d7 H \u00d7 I). The constructor de.nitions for the analysis are: RE C O R D (heap, ctx) \n= .rst(ctx) MERGE (heap, hctx, invo, ctx) = triple(heap, hctx, invo) MERGE STATI C (invo, ctx) = triple(.rst(ctx), \nsecond(ctx), invo) In words: an object s heap context is the receiver object of the method doing the \nallocation. A virtual method s context is its re\u00adceiver object s allocation site and context (the latter \nbeing the allo\u00adcation site of the object that allocated the receiver), followed by the 4 We have validated \nthese insights with extensive measurements on our experimental setup, and have generally explored a much \nlarger portion of the design space than is possible to present in our evaluation section. 5 We use the \nterm more precise colloquially. Strictly speaking, the analy\u00adsis is guaranteed to be at least as precise \n.  invocation site of the method. On a static call, the heap part (i.e., .rst two elements) of the method \ncontext is kept unchanged, and extended with the invocation site of the call. This analysis is also strictly \nmore precise than the plain anal\u00adysis it is based on, 2obj+H. Note that this is achieved partly by placing \nthe receiver object s allocation site in the most signi.cant position of the context triple. In this \nway, the REC ORD function produces the same heap context as 2obj+H on an object s alloca\u00adtion. Alternative \nde.nitions are possible for the same sets of con\u00adtexts, C and HC. For instance, one could choose to place \nhctx in the most signi.cant position. Similarly, one could produce a hybrid analysis based on 2obj+H \nbut with a different kind of heap context, e.g., HC = I, therefore using the invocation site in a method \ns con\u00adtext as an allocation context. These de.nitions make decisively less sense, however, per the insights \nmentioned earlier: invocation sites are rarely advantageous as heap contexts, and, similarly, it is not \nreasonable to invert the natural signi.cance order of heap vs. hctx. (We have also veri.ed experimentally \nthat such combinations yield bad analyses.) Uniform 2-type-sensitive with 1-context-sensitive heap hybrid \n(U\u00ad2type+H). Isomorphically to object-sensitivity, we can enhance type-sensitive analyses with call-site \ninformation in the same way. When applied to a 2-type-sensitive analysis with a context-sensitive heap, \nthis results in an analysis with a heap context of one type (HC = T) and a context of two types and an \ninvocation site (C = T \u00d7 T \u00d7 I) mirroring the 2-object-sensitive analysis with a context sensitive heap. \nThe de.nitions are almost identical: RE C O R D (heap, ctx) = .rst(ctx) ME R G E (heap, hctx, invo, ctx) \n= triple(CA(heap), hctx, invo) ME R G ESTATIC (invo, ctx) = triple(.rst(ctx), second(ctx), invo)  3.2 \nSelective Hybrid Analyses Another approach to hybrid call-site-and object-sensitive analyses is to maintain \na context that varies inside the same analysis. We call such analyses selective hybrid analyses, as opposed \nto the ear\u00adlier uniform hybrid ones. In a selective hybrid analysis, the sets of contexts, C and HC, \nwill be formed as the cartesian product of unions of sets. Depending on the information available at \ndifferent analysis points where new contexts are formed, we shall create con\u00adtexts of a different kind, \ninstead of always keeping a combination of rigid form. We have already hinted at such opportunities in \nSec\u00adtion 2.2: at a static method call, an object-sensitive analysis does not have a heap object available \nto create a new context, hence it can at best propagate the context of the caller. Yet, an invocation \nsite is available and can be used to distinguish different static calls, as long as we are allowed to \nuse it as context. This observation generalizes: static invocations are a language feature that bene.ts \nhighly from the presence of call-site-sensitive elements in the con\u00adtext. This is not hard to explain: \nFor object-sensitive analyses, when analyzing a static invocation, we do not have much information to \nuse in creating a new context, in contrast to a normal virtual invo\u00adcation. Consequently, it is bene.cial \nto be able to use the invocation site as a differentiator of static calls. Selective hybrid analyses \nare among the most interesting parts of our work and, to our knowledge, have never before arisen in the \nliterature, far less speci.ed, implemented, and evaluated. Selective 1-object-sensitive hybrid A (SA-1obj). \nTrying to selec\u00adtively enhance a 1-object-sensitive analysis (HC = {*}) with call\u00adsite sensitive elements, \nwe are presented with two options, relative to how contexts are created in static invocations. The .rst \noption is quite simple: we can keep only a single context element in both virtual and static invocations. \nConsequently, in virtual invocations the context will be an allocation site, but in static invocations \nit will be an invocation site (C = H . I). The de.nitions needed are the following: RE C O R D (heap, \nctx) = * MERGE (heap, hctx, invo, ctx) = heap MERGE STATI C (invo, ctx) = invo Note that this analysis \nis not guaranteed to be more precise than the 1obj analysis it is based on. Nevertheless, it should be \nan excellent reference point for comparison and insights: it will suggest how much precision can be gained \nor lost by call-site-sensitivity as a replacement of object-sensitivity in static method calls. Selective \n1-object-sensitive hybrid B (SB -1obj). The second op\u00adtion for a selective hybrid enhancement of a 1-object-sensitive \nanal\u00adysis is to add extra information to the context of static calls. This means that context in virtual \ninvocations is still an allocation site, but context in static invocations now consists of both the allocation \nsite copied from the caller and the invocation site. In this way, C = H \u00d7 (I . {*}). That is, the context \ncan be either just an alloca\u00adtion site or an allocation site and an invocation site. (This could also \nbe written equivalently as C = H . (H \u00d7 I), but the earlier form streamlines the de.nitions of constructors, \nas it makes all contexts be pairs, thus avoiding case-based de.nitions.) In this way the con\u00adstructor \nde.nitions become: RE C O R D (heap, ctx) = * MERGE (heap, hctx, invo, ctx) = pair(heap, *) MERGE STATI \nC (invo, ctx) = pair(.rst(ctx), invo) This analysis has a context that is always a superset of the 1obj \ncontext and, therefore, is guaranteed to be more precise. Selective 2-object-sensitive with 1-context-sensitive \nheap hybrid (S-2obj+H). When dealing with deeper analyses, the possible design decisions start to vary. \nFor example, for a 2-object-sensitive analysis with a context-sensitive heap, an interesting choice is \nto have allocation sites as heap contexts (HC = H), and for method contexts to keep standard object-sensitive \ninformation for virtual calls but favor call-site-sensitivity for static calls. The constructor de.nitions \nfor the above analysis are: RE C O R D (heap, ctx) = .rst(ctx) MERGE (heap, hctx, invo, ctx) = triple(heap, \nhctx, *) MERGE STATI C (invo, ctx) = triple(.rst(ctx), invo, second(ctx)) (In this way, we have C = \nH \u00d7 (H . I) \u00d7 (H . I . {*}).) Note the interesting behavior of such an analysis: for virtual calls, the \ncontext is equivalent to that of 2obj+H. For the .rst static call (i.e., from inside a virtually called \nmethod), the context is a superset of 2obj+H, augmented by an invocation site. For further static calls \n(i.e., static calls inside statically called methods), however, the analysis favors call-site sensitivity \n(both the last two elements of context are invocation sites) and otherwise only remembers the most-signi.cant \nelement of the object-sensitive context. (The latter is important for creating high-quality heap contexts, \nwhen allocating objects.) It is interesting to see how this analysis fares relative to 2obj+H, since \nthe analyses are in principle incomparable in precision. Selective 2-type-sensitive with 1-context-sensitive \nheap hybrid (S\u00ad2type+H). Finally, type-sensitive analyses can be enhanced with call-site sensitive information \nin much the same way. Mirroring our choices in S-2obj+H, the S-2type+H analysis has heap context HC = \nT and method context C = T \u00d7 (T . I) \u00d7 (T . I . {*}). The constructor de.nitions are isomorphic to the \nS-2obj+H analysis: RE C O R D (heap, ctx) = .rst(ctx) MERGE (heap, hctx, invo, ctx) = triple(CA(heap), \nhctx, *) MERGE STATI C (invo, ctx) = triple(.rst(ctx), invo, second(ctx))  Other analyses. The above \ndiscussion does not nearly exhaust the space of hybrid combinations. Consider selective hybrids for a \n2obj+H analysis: Many more design choices are possible than the one shown. One could change the heap \ncontext into an invo\u00adcation site, or into a union of invocation and call-site (HC = H . I). This combination \nis a bad choice, due to the poor payoff of call-site heap contexts. One could create context structures \nthat let call-site-and object-sensitive context elements freely merge, e.g., C = (H . I) \u00d7 (H . I) \u00d7 \n(H . I . {*}). This allows several differ\u00adent de.nitions of context constructors, but has the drawback \nof di\u00adverging signi.cantly from object-sensitivity (i.e., allowing to skip even the most-signi.cant object-sensitive \ncontext element), which misses the well documented precision and performance advantages of object-sensitivity, \nespecially as a heap context. 4. Evaluation We implemented and evaluated all aforementioned analyses \nusing the DO O P framework [4]. There are interesting and subtle aspects in our measurements, but the \nexecutive summary is clear: uniform hybrid analyses are typically not good choices in practice: their \npre\u00adcision is offset by a very high performance cost. (A relative ex\u00adception is the uniform type-sensitive \nhybrid analysis, U-2type+H, which, although higher-cost, is not prohibitively expensive and offers a \nreasonable precision/performance tradeoff.) Selective hy\u00adbrid analyses, on the other hand, are not just \ninteresting tradeoffs but clear winners: they match or (usually) outperform the object\u00adsensitive analyses \nthey are based on, while offering better precision, closely approaching the precision of the much more \ncostly uniform hybrids. Overall, the best analyses in our evaluation set, both for highest-precision \nand for high performance with good precision, are selective hybrids. Our evaluation setting uses the \nLogicBlox Datalog engine, v.3.9.0, on a Xeon X5650 2.67GHz machine with only one thread running at a \ntime and 24GB of RAM (i.e., ample for the analyses studied). We analyze the DaCapo benchmark programs \n(v.2006-10-MR2) under JDK 1.6.0 37. (This is a much larger set of li\u00adbraries than earlier work [4, 24], \nwhich also results in differences in measurements, since the numbers shown integrate application\u00adand \nlibrary-level metrics.) (All numbers shown are medians of three runs.) All runtime numbers are medians \nof three runs. As in other published work [1, 24], jython and hsqldb are analyzed with re.ec\u00adtion disabled \nand hsqldb has its entry point set manually in a special harness. 4.1 Illustration For an illustration \nof the precision and performance spectrum, con\u00adsider Figure 3, which plots analyses on precision/performance \naxes. The .gure plots execution time against precision in the may-fail casts metric, i.e., the number \nof casts that the analysis cannot stat\u00adically prove safe. Lower numbers are better on both axes, thus \nan analysis that is to the left and below another is better in both pre\u00adcision and performance. Values \nthat are disproportionately high on the Y axis (i.e., large execution times) are clipped and plotted \nat the top of the .gure, with the actual number included in parentheses. (Note that the Y axis starts \nat zero, while the X axis starts at an ar\u00adbitrary point we cannot know what is the ideal reference value \nfor this metric.) In terms of pre-existing analyses, Figure 3 illustrates what has been past experience: \n2obj+H is the most precise analysis, but often heavy. 1obj and 2type+H are both quite fast, with 2type+H \nalso showing very good precision, often approaching 2obj+H. The two call-site-sensitive analyses (1call, \n1call+H) are mostly shown for reference and to demonstrate the insights discussed in Section 3. 1call \nis a fast analysis but vastly imprecise, while 1call+H is a bad tradeoff: its cost grows quite signi.cantly \nrelative to 1call without much precision added call-site sensitivity is a bad choice for heap contexts. \nAs can be seen, the selective hybrid analyses (SA-1obj, SA \u00ad1obj, S-2obj+H, S-2type+H) usually offer \nan advantage over the corresponding base analysis (1obj, 2type+H, 2obj+H) in both pre\u00adcision and performance. \nIn fact, selective hybrids are typically im\u00adperceptibly less precise than the corresponding uniform hybrid, \nyet much more precise than the base analysis. For instance, the plot points for S-2obj+H are always barely \nto the right of those for the theoretically more precise U-2obj+H (but signi.cantly lower uniform hybrids \nare very expensive), while they are clearly to the left of 2obj+H.  4.2 Detailed Results Detailed results \nof our experiments are presented in Table 1. The table shows precision and performance metrics for all \nanalyses. The precision metrics are the average points-to set size (i.e., average over all variables \nof their points-to sets sizes), the number of edges in the computed call-graph (which is typically a \ngood proxy for the overall precision of the analysis, in broad strokes), and the results of two client \nanalyses: the number of virtual calls that could not be de-virtualized, and the number of casts that \ncould not be statically proven safe. A combination of these four metrics gives a reliable picture of \nthe precision of an analysis. (Note that the average points-to set size alone is not necessarily reliable, \nbecause it is in.uenced by a small number of library variables with enormous points-to sets. For comparison, \nthe median points-to set size is 1, for all analyses and benchmarks.) Performance is shown with two metrics: \ntime and total size of all context-sensitive points-to sets. Although time is the ulti\u00admate performance \nmetric, it is brittle: one can argue that our time measurements are in.uenced by a multitude of implementation \nor environment factors, among which are the choice of underlying data structures, indexing, and the overall \nimplementation of the points-to analysis, especially since it is running on a Datalog en\u00adgine, with its \nown complex implementation choices hidden. The context-sensitive points-to set size metric does not suffer \nfrom any such measurement or implementation bias. It is the foremost in\u00adternal complexity metric of a \npoints-to analysis, and typically cor\u00adrelates well with time, for analyses of the same .avor. Note that \nanalysis implementations that fundamentally differ from ours also try hard to minimize this metric in \norder to achieve peak perfor\u00admance: Lhot\u00b4 ak s PADD LE framework [12] is using binary decision diagrams \n(BDDs) for representing relations. The best BDD vari\u00adable ordering (yielding impressive results [3]) \nis one that mini\u00admizes the total size of context-sensitive points-to sets. In short, it is reasonable \nto expect that improvements in this internal metric rein\u00adforce the verdict of which analysis yields better \nperformance, not just in our setting but generally. Furthermore, the size of context\u00adsensitive points-to \nsets serves as a valuable indicator of the inter\u00adnally different computation performed by various analyses: \nAnaly\u00adses with almost identical precision metrics (e.g., context-insensitive points-to set sizes, call-graph \nedges) have vastly different context\u00adsensitive points-to set sizes. Since Table 1 has a high information \ndensity, we guide the reader through some of the most important .ndings below (see also a partial illustration \nin Figure 3, later). General observations. The analyses shown are in 4 groups of closely related analyses: \ncall-site sensitive, 1-object-sensitive, 2-object-sensitive with a 1-context-sensitive heap, and 2-type\u00adsensitive \nwith a 1-context-sensitive heap. These analyses span a large performance and precision spectrum. For \ninstance, for the chart benchmark, the least precise analysis, 1call, runs for under 5mins and computes \nan average points-to size of over 45, while the most precise, U-2obj+H, runs for over 53mins and computes \n  Figure 3: Graphical depiction of performance vs. precision metrics for eight of our benchmarks over \nall analyses. Lower is better on both axes. The Y axis is truncated for readability. Out-of-bounds points \nare included at lower Y values, with their real running time in parentheses. 1call 1call+H 1obj U-1obj \nSA-1obj SB-1obj 2obj+H U-2obj+H S-2obj+H 2type+H U-2type+H S-2type+H antlr avg. objs per var edges (over \n~8.8K meths) poly v-calls (of ~33K) may-fail casts (of ~1.7K) 29.79 60999 1994 1049 29.58 60999 1994 \n1038 24.86 60194 1933 1074 24.55 60194 1933 989 24.90 60202 1936 996 24.61 60194 1933 994 6.42 55548 \n1707 609 6.26 55548 1707 521 6.27 55548 1707 526 17.60 55850 1759 752 7.14 55765 1746 640 17.39 55850 \n1759 665 elapsed time (s) sensitive var-points-to (M) 110 16 366 54.8 166 14.3 544 65 142 10.5 182 17.3 \n217 19.9 532 39.5 162 13.9 108 5.3 184 8.9 106 4.8 bloat avg. objs per var edges (over ~10.2K meths) \npoly v-calls (of ~31K) may-fail casts (of ~2.8K) 43.96 70506 2138 2008 43.94 70506 2138 2008 41.26 69501 \n2076 2013 41.16 69501 2076 1928 41.32 69511 2080 1935 41.18 69501 2076 1933 13.25 60726 1640 1403 ---- \n13.10 60726 1640 1320 16.28 62115 1888 1720 14.71 61753 1827 1611 16.10 62115 1888 1633 elapsed time \n(s) sensitive var-points-to (M) 186 32.9 1351 150.5 374 21.9 2473 287.1 353 20.1 391 24 5060 153.5 -- \n5045 149.8 142 11.4 353 30.3 140 11 chart avg. objs per var edges (over ~15K meths) poly v-calls (of \n~35K) may-fail casts (of ~3.5K) 45.12 82156 2900 2500 45.11 82078 2897 2488 40.80 81423 2821 2548 ---- \n40.72 81075 2815 2385 40.11 81012 2808 2378 5.30 59162 1610 1062 4.99 59142 1603 915 5.00 59152 1610 \n920 7.02 62290 1775 1498 5.89 62172 1756 1309 6.57 62280 1775 1343 elapsed time (s) sensitive var-points-to \n(M) 288 49.6 957 120.9 1240 62.5 -- 1059 39.7 1477 89.7 896 67.6 2363 115.7 1199 53 211 13.3 362 21.3 \n276 16.5 eclipse avg. objs per var edges (over ~9.3K meths) poly v-calls (of ~23K) may-fail casts (of \n~2K) 21.84 53006 1515 1156 21.65 53001 1514 1155 18.65 52114 1429 1204 18.41 51935 1404 1089 18.59 51958 \n1412 1096 18.43 51936 1404 1094 5.75 44900 1163 727 5.60 44899 1163 616 5.61 44900 1163 621 7.93 45318 \n1233 879 6.41 45123 1202 744 7.61 45235 1229 766 elapsed time (s) sensitive var-points-to (M) 81 12.3 \n478 61.5 117 9.4 406 42.3 105 7.6 126 10.8 532 44.6 1332 89.8 359 32.3 152 13.6 278 24.4 135 11.5 hsqldb \navg. objs per var edges (over ~10K meths) poly v-calls (of ~26K) may-fail casts (of ~2K) 18.56 54619 \n1552 1360 18.53 54619 1552 1360 15.41 53726 1480 1385 15.30 53724 1479 1302 15.58 53730 1482 1320 15.32 \n53724 1479 1308 ---- ---- ---- 7.92 49421 1276 1031 6.71 49319 1263 923 7.74 49421 1276 948 elapsed time \n(s) sensitive var-points-to (M) 90 9.6 332 39.8 218 13.9 1351 74.3 183 9.6 329 29.5 -- -- -- 195 13.7 \n583 42.9 238 20.5 jython avg. objs per var edges (over ~8.5K meths) poly v-calls (of ~21K) may-fail casts \n(of ~1.9K) 20.64 50494 1525 1140 20.57 50480 1524 1140 18.21 49622 1448 1157 18.01 49614 1448 1087 18.19 \n49622 1453 1094 18.09 49614 1448 1092 ---- ---- ---- 8.55 43269 1268 909 7.18 43138 1236 822 8.30 43269 \n1268 840 elapsed time (s) sensitive var-points-to (M) 88 10.4 401 50.6 119 8.7 375 43.2 102 6.7 138 10.8 \n-- -- -- 731 52 1363 118.4 676 56.5 luindex avg. objs per var edges (over ~7.9K meths) poly v-calls (of \n~18K) may-fail casts (of ~1.4K) 17.65 41992 1180 838 17.58 41992 1180 838 14.94 41103 1119 864 14.81 \n41103 1119 779 14.97 41111 1122 786 14.83 41103 1119 784 4.77 36580 894 494 4.55 36580 894 406 4.55 36580 \n894 411 6.20 36889 949 622 5.15 36796 932 507 5.92 36889 949 535 elapsed time (s) sensitive var-points-to \n(M) 59 7.8 172 26.1 76 5.4 227 26.3 70 4.1 81 6.4 131 11.1 377 22.4 105 7.2 75 4.5 132 7.6 73 3.5 lusearch \navg. objs per var edges (over ~8.4K meths) poly v-calls (of ~19K) may-fail casts (of ~1.5K) 18.64 45270 \n1360 939 18.47 45270 1360 939 15.71 44371 1299 961 15.57 44365 1299 874 15.79 44379 1302 884 15.60 44371 \n1299 880 4.71 39452 1065 506 4.49 39446 1065 410 4.50 39452 1065 416 6.13 39763 1122 662 5.10 39662 1103 \n537 5.86 39763 1122 568 elapsed time (s) sensitive var-points-to (M) 63 8.7 187 28.5 89 6.2 279 30.3 \n84 5.3 95 7.2 183 13.2 464 26.3 158 10 76 4.2 137 7.8 74 3.6 pmd avg. objs per var edges (over ~9.2K \nmeths) poly v-calls (of ~21K) may-fail casts (of ~2K) 19.94 49097 1249 1274 19.82 49097 1249 1274 17.36 \n48250 1187 1304 17.22 48250 1187 1215 17.37 48258 1190 1222 17.24 48250 1187 1220 4.87 43068 937 844 \n4.68 43067 937 752 4.68 43067 937 757 6.35 43401 988 1000 5.28 43315 976 876 6.10 43400 988 909 elapsed \ntime (s) sensitive var-points-to (M) 90 11.4 245 35.9 135 7.9 420 42.6 128 6.9 142 9.2 167 13.2 465 30.5 \n145 10 114 4.5 201 9.7 113 3.9 xalan avg. objs per var edges (over ~10.5K meths) poly v-calls (of ~26K) \nmay-fail casts (of ~2K) 25.50 57168 1976 1213 25.38 57168 1976 1213 21.86 56412 1920 1236 21.59 56158 \n1905 1132 21.84 56404 1921 1140 21.69 56395 1918 1138 5.48 50148 1619 718 5.22 50054 1615 613 5.23 50054 \n1615 619 7.52 50539 1677 946 6.19 50432 1660 806 7.16 50526 1677 844 elapsed time (s) sensitive var-points-to \n(M) 108 14.5 470 59.8 189 15.5 591 67.5 161 10.9 205 18.2 4521 166.6 3364 171.7 1105 63.3 168 10.2 299 \n17.4 161 9 Table 1: Precision and performance metrics for all benchmarks and analyses, grouped by relevance. \nIn all cases lower is better. Dash (-) entries are for analyses that did not terminate in 90mins. The \n4 precision metrics shown are the average size of points-to sets (how many heap objects are computed \nto be pointed-to per-var), the number of edges in the computed call-graph, the number of virtual calls \nwhose target cannot be disambiguated by the analysis, and the number of casts that cannot be statically \nshown safe by the analysis. Reference numbers (e.g., total reachable casts in the program) are shown \nin parentheses in the metric s heading. These numbers change little per-analysis. Performance is shown \nas running time and size of context-sensitive var-points-to data (the main platform-independent internal \ncomplexity metric). Best performance numbers per-analysis-group are in bold. an average points-to size \nof under 5. The difference in precision is also vividly shown in the may-fail casts metric: the 1call \nanal\u00adysis cannot prove 2500 casts safe, while the U-2obj+H fails to prove safe just 915 casts (both numbers \nfrom a total of about 3.5K reachable casts the exact number varies slightly due to method reachability \nvariation per analysis). Uniform hybrid analyses. Recall that uniform hybrid analyses (U-1obj, U-2obj+H, \nU-2type+H) were de.ned to always keep a combination of object-sensitive and call-site-sensitive context. \nAs a result, the analyses are more precise than their respective base analyses (1obj, 2obj+H, 2type+H), \nespecially in the may-fail casts metric. However, this precision comes at great cost: uni\u00adform hybrid \nanalyses are often 3x or more slower than their base analyses with twice as large, or more, context-sensitive \npoints-to sets. U-1obj and U-2obj+H are plainly bad tradeoffs in the design space: for a slight increase \nin precision, the performance cost is heavy. U-2type+H is a bit more reasonable: it achieves more sig\u00adni.cant \nprecision gains and its performance toll is often under 2x while still terminating comfortably for all \nour benchmarks. In fact, a surprising .nding was that U-2type+H is a tempting alter\u00adnative to 2obj+H \nfor applications that need very high precision, given its good scalability.  1obj hybrids. We presented \ntwo selective hybrids of a 1-object\u00adsensitive analysis: SA-1obj (which keeps either an allocation site \nor a call-site as context, but not both) and SB -1obj (which al\u00adways keeps an allocation site as context \nand occasionally adds a call-site to it). They both turn out to be interesting analyses from a practical \nstandpoint. The former is consistently faster than the base 1obj analysis, with roughly similar precision \nand occa\u00adsionally (for the may-fail casts metric) higher precision. The size of context-sensitive points-to \nsets also con.rms that this is a lighter analysis that is likely to cost less in any context. The SB \n-1obj analysis is always more precise than 1obj (as is statically guaranteed) for a slight extra cost. \nIndeed, SB-1obj is a good ap\u00adproximation of the uniform hybrid analysis, U-1obj, in terms of precision, \nfor a fraction (typically less than a third) of the cost.  2obj+H hybrids. The selective hybrid idea \nyields even more dividends when applied to the very precise 2obj+H analysis. S-2obj+H is more precise \nthan 2obj+H and only very slightly less precise than the uniform hybrid, U-2obj+H. In terms of performance, \nhowever, the analysis is typically well over 3 times faster than U-2obj+H, and signi.cantly faster (an \naverage of 53% speedup) than 2obj+H. This is interesting, given the practical value of 2obj+H, since \nit establishes a new sweet spot in the space of relatively scalable but highly precise analyses: S-2obj+H \nis both more precise than 2obj+H (especially for may-fail casts ) and substantially faster.  2type+H \nhybrids. The 2type+H analysis variations are also highly interesting in practice. This is an analysis \nspace that yields excellent precision relative to its low cost. There are few cases in which one might \nprefer some other inexpensive analysis over 2type+H given the combination of precision and competitive \nperformance of the latter. As we saw, the uniform hybrid, U\u00ad2type+H, is an interesting tradeoff in this \nspace. The selective hybrid, S-2type+H, also performs quite well. It is just as fast or slightly faster \nthan the base analysis 2type+H, while also being more precise.  5. Related Work We have discussed directly \nrelated work throughout the paper. Here we selectively mention a few techniques that, although not directly \nrelated to ours, offer alternative approaches to sweet spots in the precision/performance tradeoff. Special-purpose \ncombinations of context-sensitivity have been used in the past, but have required manual identi.cation \nof classes to be treated separately (e.g., Java collection classes, or library factory methods). An excellent \nrepresentative is the TAJ work for taint analysis of Java web applications [27]. In contrast, we have \nsought to map the space and identify interesting hybrids for general application of context-sensitivity, \nover the entire program. The analyses we examined are context-sensitive but .ow\u00adinsensitive. We can achieve \nseveral of the bene.ts of .ow\u00adsensitivity by applying the analysis on the static single assignment (SSA) \nintermediate form of the program. This is easy to do with a mere .ag setting on the DO O P framework. \nHowever, the impact of the SSA transformation on the input is minimal. The default intermediate language \nused as input in DOO P (the Jimple repre\u00adsentation of the Soot framework [28, 29]) is already close to \nSSA form, although it does not guarantee that every variable is strictly single-assignment without requesting \nit explicitly. Recent work by Lhot\u00b4 ak and Chung [13] has shown that much of the bene.t of .ow-sensitivity \nderives from the ability to do strong updates of the points-to information. Lhot\u00b4 ak and Chung then exploited \nthis insight to derive analyses with similar bene.t to a full .ow-sensitive anal\u00adysis at lower cost. \nA demand-driven evaluation strategy reduces the cost of an analysis by computing only those results that \nare necessary for a client program analysis [10, 25, 26, 32]. This is a useful approach for client analyses \nthat focus on speci.c locations in a program, but if the client needs results from the entire program, \nthen demand\u00addriven analysis is typically slower than an exhaustive analysis. Reps [21] showed how to \nuse the standard magic-sets optimiza\u00adtion to automatically derive a demand-driven analysis from an ex\u00adhaustive \nanalysis (like ours). This optimization combines the ben\u00ade.ts of top-down and bottom-up evaluation of \nlogic programs by adding side-conditions to rules that limit the computation to just the required data. \nAn interesting recent approach to demand-driven analyses was introduced by Liang and Naik [15]. Their \npruning approach con\u00adsists of .rst computing a coarse over-approximation of the points-to information, \nwhile keeping the provenance of this derivation, i.e., recording which input facts have affected each \npart of the output. The input program is then pruned so that parts that did not affect the interesting \npoints of the output are eliminated. Then a precise analysis is run, in order to establish the desired \nproperty. 6. Conclusions and Future Work We presented a comprehensive map for the exploration of context \ncombinations in points-to analysis, and used it to discover several interesting design points. Object-sensitivity \nand call-site-sensitivity had never been fruitfully combined in the past, although the idea is clearly \ntempting. We speculate that the reasons for the paucity of hybrid context-sensitivity results have been \na) the dif.culty of having a good enough model for the space of combinations and a convenient implementation \nto explore it; b) a belief that nothing fruitful will come out of such a combination, because call-site \nsensitivity incurs a high performance cost, which is more pro.tably spent on an extra level of object-sensitivity. \nThe latter insight is mostly true, but only if one considers uniform hybrid analyses. As we saw, much \nof the bene.t of call-site and object-sensitive hybrids comes from allowing the context to vary between \npure object-sensitive and extended. The result of our work has been new sweet spots, in both precision \nand performance, for some of the most practically relevant analysis variations. There are several interesting \ndirections for further work that open up. First, our model gives the ability for further experimen\u00adtation, \ne.g., with deeper-context analyses. Furthermore, it is inter\u00adesting to examine if a hybrid context should \nperhaps change form more aggressively. The ME RG E and MERGE STATI C functions could examine the context \npassed to them as argument and create different kinds of contexts in return. For instance, the context \nof a statically called method could have a different form (e.g., more el\u00adements) for a call made inside \nanother statically called method vs. a call made in a virtual method. Similarly, objects could have dif\u00adferent \ncontext, via the RE C O R D function, depending on the context form of their allocating method. To explore \nthis space without blind guessing, one needs to understand what programming patterns are best handled \nby hybrid contexts and how. For deep contexts this remains a challenge, as it is hard to reason about \nhow context el\u00adements affect precision. (E.g., past work had to offer involved ar\u00adguments for why the \nallocator object of the receiver object of a method is a better context element than the caller object \n[24].) This challenge is, however, worth addressing for the next level of bene.t in context-sensitive \npoints-to analysis.  Acknowledgments We gratefully acknowledge funding by the European Union under a \nMarie Curie International Reintegration Grant and a European Re\u00adsearch Council Starting/Consolidator \ngrant; and by the Greek Sec\u00adretariat for Research and Technology under an Excellence (Aris\u00adteia) award. \nWe thank the anonymous reviewers, who offered sev\u00aderal valuable suggestions, and LogicBlox Inc. for providing \nour Datalog engine, as well as technical and material support. References [1] K. Ali and O. Lhot\u00b4ak. \nApplication-only call graph construc\u00adtion. In European Conf. on Object-Oriented Programming (ECOOP), \n2012. [2] L. O. Andersen. Program Analysis and Specialization for the C Programming Language. PhD thesis, \nDIKU, University of Copenhagen, 1994. [3] M. Berndl, O. Lhot\u00b4ak, F. Qian, L. J. Hendren, and N. Umanee. \nPoints-to analysis using BDDs. In Conf. on Programming Language Design and Implementation (PLDI), 2003. \n[4] M. Bravenboer and Y. Smaragdakis. Strictly declarative spec\u00adi.cation of sophisticated points-to analyses. \nIn Conf. on Ob\u00adject Oriented Programming, Systems, Languages, and Appli\u00adcations (OOPSLA), 2009. [5] M. \nEichberg, S. Kloppenburg, K. Klose, and M. Mezini. De.ning and continuous checking of structural program \nde\u00adpendencies. In Int. Conf. on Software engineering (ICSE), 2008. [6] S. Guarnieri and B. Livshits. \nGateKeeper: mostly static en\u00adforcement of security and reliability policies for Javascript code. In Proceedings \nof the 18th USENIX Security Sympo\u00adsium, 2009. [7] E. Hajiyev, M. Verbaere, and O. de Moor. Codequest: \nScalable source code queries with Datalog. In European Conf. on Object-Oriented Programming (ECOOP), \n2006. [8] B. Hardekopf and C. Lin. The ant and the grasshopper: fast and accurate pointer analysis for \nmillions of lines of code. In Conf. on Programming Language Design and Implementation (PLDI), 2007. [9] \nB. Hardekopf and C. Lin. Semi-sparse .ow-sensitive pointer analysis. In Symposium on Principles of Programming \nLan\u00adguages (POPL), 2009. [10] N. Heintze and O. Tardieu. Demand-driven pointer analysis. In Conf. on \nProgramming Language Design and Implementa\u00adtion (PLDI), 2001. [11] M. S. Lam, J. Whaley, V. B. Livshits, \nM. C. Martin, D. Avots, M. Carbin, and C. Unkel. Context-sensitive program analysis as database queries. \nIn Symposium on Principles of Database Systems (PODS), 2005. [12] O. Lhot\u00b4ak. Program Analysis using \nBinary Decision Dia\u00adgrams. PhD thesis, McGill University, 2006. [13] O. Lhot\u00b4ak and K.-C. A. Chung. Points-to \nanalysis with ef.\u00adcient strong updates. In Symposium on Principles of Program\u00adming Languages (POPL), \n2011. [14] O. Lhot\u00b4ak and L. Hendren. Evaluating the bene.ts of context\u00adsensitive points-to analysis \nusing a BDD-based implementa\u00adtion. ACM Trans. Softw. Eng. Methodol., 18(1):1 53, 2008. [15] P. Liang \nand M. Naik. Scaling abstraction re.nement via pruning. In Conf. on Programming Language Design and Implementation \n(PLDI), 2011. [16] M. Madsen, B. Livshits, and M. Fanning. Practical static anal\u00adysis of Javascript applications \nin the presence of frameworks and libraries. Technical Report MSR-TR-2012-66, MicrosoftResearch, 2012. \n[17] M. Might, Y. Smaragdakis, and D. Van Horn. Resolving and exploiting the k-CFA paradox: Illuminating \nfunctional vs. object-oriented program analysis. In Conf. on Programming Language Design and Implementation \n(PLDI), 2010. [18] A. Milanova, A. Rountev, and B. G. Ryder. Parameterized object sensitivity for points-to \nand side-effect analyses for Java. In International Symposium on Software Testing and Analysis (ISSTA), \n2002. [19] A. Milanova, A. Rountev, and B. G. Ryder. Parameterized object sensitivity for points-to analysis \nfor Java. ACM Trans. Softw. Eng. Methodol., 14(1):1 41, 2005. [20] T. Reps. Demand interprocedural program \nanalysis using logic databases. In Applications of Logic Databases, 1994. [21] T. W. Reps. Solving demand \nversions of interprocedural analysis problems. In Int. Conf. on Compiler Construction (CC), 1994. [22] \nM. Sharir and A. Pnueli. Two approaches to interprocedural data .ow analysis. In Program Flow Analysis, \n1981. [23] O. Shivers. Control-Flow Analysis of Higher-Order Lan\u00adguages. PhD thesis, Carnegie Mellon \nUniversity, 1991. [24] Y. Smaragdakis, M. Bravenboer, and O. Lhot\u00b4ak. Pick your contexts well: Understanding \nobject-sensitivity (the making of a precise and scalable pointer analysis). In Symposium on Principles \nof Programming Languages (POPL), 2011. [25] M. Sridharan and R. Bod\u00b4ik. Re.nement-based context\u00adsensitive \npoints-to analysis for Java. In Conf. on Programming Language Design and Implementation (PLDI), 2006. \n[26] M. Sridharan, D. Gopan, L. Shan, and R. Bod\u00b4ik. Demand\u00addriven points-to analysis for Java. In Conf. \non Object Oriented Programming, Systems, Languages, and Applications (OOP-SLA), 2005. [27] O. Tripp, \nM. Pistoia, S. J. Fink, M. Sridharan, and O. Weis\u00adman. Taj: effective taint analysis of web applications. \nIn Conf. on Programming Language Design and Implementation (PLDI), 2009. [28] R. Vall\u00b4ee-Rai, E. Gagnon, \nL. J. Hendren, P. Lam, P. Pom\u00adinville, and V. Sundaresan. Optimizing Java bytecode using the Soot framework: \nIs it feasible? In Int. Conf. on Compiler Construction (CC), 2000. [29] R. Vall\u00b4ee-Rai, L. Hendren, V. \nSundaresan, P. Lam, E. Gagnon, and P. Co. Soot -a Java optimization framework. In Proceed\u00adings of CASCON \n1999, 1999. [30] J. Whaley, D. Avots, M. Carbin, and M. S. Lam. Using Datalog with binary decision diagrams \nfor program analysis. In APLAS, 2005. [31] J. Whaley and M. S. Lam. Cloning-based context-sensitive pointer \nalias analysis using binary decision diagrams. In Conf. on Programming Language Design and Implementation \n(PLDI), 2004. [32] X. Zheng and R. Rugina. Demand-driven alias analysis for c. In Symposium on Principles \nof Programming Languages (POPL), 2008.   \n\t\t\t", "proc_id": "2491956", "abstract": "<p>Context-sensitive points-to analysis is valuable for achieving high precision with good performance. The standard flavors of context-sensitivity are call-site-sensitivity (kCFA) and object-sensitivity. Combining both flavors of context-sensitivity increases precision but at an infeasibly high cost. We show that a selective combination of call-site- and object-sensitivity for Java points-to analysis is highly profitable. Namely, by keeping a combined context only when analyzing selected language features, we can closely approximate the precision of an analysis that keeps both contexts at all times. In terms of speed, the selective combination of both kinds of context not only vastly outperforms non-selective combinations but is also faster than a mere object-sensitive analysis. This result holds for a large array of analyses (e.g., 1-object-sensitive, 2-object-sensitive with a context-sensitive heap, type-sensitive) establishing a new set of performance/precision sweet spots.</p>", "authors": [{"name": "George Kastrinis", "author_profile_id": "81554797356", "affiliation": "Department of Informatics - University of Athens, Athens, Greece", "person_id": "P4149081", "email_address": "gkastrinis@di.uoa.gr", "orcid_id": ""}, {"name": "Yannis Smaragdakis", "author_profile_id": "81100614708", "affiliation": "Department of Informatics - University of Athens, Athens, Greece", "person_id": "P4149082", "email_address": "smaragd@di.uoa.gr", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462191", "year": "2013", "article_id": "2462191", "conference": "PLDI", "title": "Hybrid context-sensitivity for points-to analysis", "url": "http://dl.acm.org/citation.cfm?id=2462191"}