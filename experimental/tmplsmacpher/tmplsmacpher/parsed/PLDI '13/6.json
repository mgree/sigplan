{"article_publication_date": "06-16-2013", "fulltext": "\n Fast RMWs for TSO: Semantics and Implementation Bharghava Rajaram Vijay Nagarajan Susmit Sarkar University \nof Edinburgh University of Edinburgh University of St Andrews r.bharghava@ed.ac.uk vijay.nagarajan@ed.ac.uk \nss265@st-andrews.ac.uk Marco Elver University of Edinburgh marco.elver@ed.ac.uk Abstract Read-Modify-Write \n(RMW) instructions are widely used as the building blocks of a variety of higher level synchronization \ncon\u00adstructs, including locks, barriers, and lock-free data structures. Un\u00adfortunately, they are expensive \nin architectures such as x86 and SPARC which enforce (variants of) Total-Store-Order (TSO). A key reason \nis that RMWs in these architectures are ordered like a memory barrier, incurring the cost of a write-buffer \ndrain in the critical path. Such strong ordering semantics are dictated by the requirements of the strict \natomicity de.nition (type-1) that exist\u00ading TSO RMWs use. Programmers often do not need such strong semantics. \nBesides, weakening the atomicity de.nition of TSO RMWs, would also weaken their ordering thereby leading \nto more ef.cient hardware implementations. In this paper we argue for TSO RMWs to use weaker atomic\u00adity \nde.nitions we consider two weaker de.nitions: type-2 and type-3, with different relaxed ordering differences. \nWe formally specify how such weaker RMWs would be ordered, and show that type-2 RMWs, in particular, \ncan seamlessly replace existing type-1 RMWs in common synchronization idioms except in situations where \na type-1 RMW is used as a memory barrier. Recent work has shown that the new C/C++11 concurrency model \ncan be real\u00adized by generating conventional (type-1) RMWs for C/C++11 SC\u00adatomic-writes and/or SC-atomic-reads. \nWe formally prove that this is equally valid using the proposed type-2 RMWs; type-3 RMWs, on the other \nhand, could be used for SC-atomic-reads (and option\u00adally SC-atomic-writes). We further propose ef.cient \nmicroarchitec\u00adtural implementations for type-2 (type-3) RMWs simulation re\u00adsults show that our implementation \nreduces the cost of an RMW by up to 58.9% (64.3%), which translates into an overall performance improvement \nof up to 9.0% (9.2%) on a set of parallel programs, in\u00adcluding those from the SPLASH-2, PARSEC, and STAMP \nbench\u00admarks. Categories and Subject Descriptors C.1.2 [Processor Architec\u00adtures]: Multiple Data Stream \nArchitectures (Multiprocessors) Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 13, June 16 19, 2013, Seattle, WA, USA. Copyright c &#38;#169; \n2013 ACM 978-1-4503-2014-6/13/06. . . $15.00 Parallel processors; D.1.3 [Concurrent Programming]: Parallel \nprogramming General Terms Design, Performance, Experimentation Keywords Read-Modify-Write (RMW), Total-Store-Order \n(TSO), Atomics 1. Introduction Read-Modify-Write (RMW) instructions are primitive synchroniza\u00adtion operations \nused to solve a variety of concurrency problems. Herlihy [15] showed that the ability to read and write \nto an ad\u00address atomically is critical to solve the consensus problem, which abstracts important synchronization \nproblems. Most modern pro\u00adcessor architectures have support for such RMW instructions ex\u00adamples include \ntest-and-set (TAS), fetch-and-add (FAA), compare\u00adand-swap (CAS), and load-linked/store conditional (LL/SC). \nIn this paper, we concentrate on Total-Store-Order (TSO) ar\u00adchitectures, variants of which are implemented \non mainstream pro\u00adcessors like x86 and SPARC, and on the use of RMWs to imple\u00adment synchronization constructs \nin TSO. The most pertinent study of such techniques [6, 27] deals with the new C/C++11 concurrency model \n[7, 10], a model which introduces synchronization reads and writes of various .avors; these reads and \nwrites are referred to as atomics. Batty et al. [6] have shown that this model is cor\u00adrectly implementable \non TSO by replacing C/C++11 SC-atomic\u00adwrites and/or SC-atomic-reads by RMWs, leaving other language constructs \n(reads, writes, fences) to be implemented by plain TSO reads, writes and barriers. Unfortunately, RMWs \nare costly in current TSO architectures, where they are ordered similarly to a memory barrier [16, 26], \nin\u00adcurring the cost of a write-buffer drain in the critical path. When an RMW is issued, the write-buffer \nis .rst drained; then the read and the write (of the RMW) are performed atomically typically by locking \nthe cache-line locally and denying coherence requests to the locked cache-line until the write completes. \nThus, instructions following the RMW are allowed to complete only after the write (of the RMW) and the \npending writes prior to it complete [24]. As a quick illustration, we measured an average latency of \n67 cy\u00adcles for an RMW on an 8-core Intel Sandybridge processor, using the Splash-2 benchmark suite. The \nlatency does not signi.cantly change if we insert a memory barrier (mfence instruction) after each RMW, \nstrengthening the hypothesis of a forced write-buffer drain. Since ef.cient synchronization is important \nto effectively harness the power of multicores, it is highly desirable that RMWs are ef.cient. Nevertheless, \nthe optimization of RMWs has histori\u00adcally received little attention [3].  Figure 1. Dekker s Algorithm: \n(a) code snippet. (b) reads and writes involved: W (x) denotes a write to address x, R(x) denotes a read \nfrom address x. (c) using RMWs as memory barriers. (d) replacing reads with RMWs. (e) replacing writes \nwith RMWs. In all sub.gures, initially, x=y=0. Semantically speaking, why are TSO RMWs ordered like a \nmemory barrier? We observe that the ordering of RMWs with other memory accesses in TSO depends on the \nprecise semantics of how atomic they have to be with respect to those other accesses. TSO can be de.ned \nin terms of a global memory order, a relation over memory accesses in the program. Existing TSO RMWs \nare de.ned to prevent writes to any address from appearing between the read and the write in this global \nmemory order [16, 26]. We call this strict de.nition type-1 atomicity. We show that this strict atomicity \nde.nition, combined with the other TSO ordering rules, results in type-1 RMWs being strongly ordered \nwith respect to memory operations before and after it, just like a memory barrier. This strong ordering \nis exploited by programmers in various synchronization primitives. Fig. 1(a) shows the key steps involved \nin the implementation of Dekker s algorithm for achieving mutual exclusion and Fig. 1(b) shows the same \ncode in terms of reads and writes. For correctness, at least one of the reads should return a value of \n1; otherwise both of the threads can enter the critical sec\u00adtion simultaneously. One way to ensure this \nis by inserting mem\u00adory barriers between the writes and the reads. In fact, since type-1 RMWs behave \nlike memory barriers, they can be used instead of memory barriers as shown in Fig. 1(c). Alternatively, \nas shown in Fig. 1d (Fig. 1e), correctness can also be ensured by replacing reads (and/or writes) with \nRMWs, since type-1 RMWs are strongly or\u00addered with respect to memory operations before and after it in \npro\u00adgram order. For the same reason, the C/C++11 concurrency model can be implemented on TSO by replacing \nSC-atomic-reads (and/or SC-atomic-writes) with RMWs [6]. The goal of this paper is to examine whether \nthe ordering of TSO RMWs can be weakened in ways that enable a more ef.cient implementation, while remaining \nstrong enough for it to replace existing RMWs in synchronization idioms. In other words, can we design \nfast yet portable RMWs for TSO? Our approach here is guided by the requirements of general programs, \nin particular by just what properties are needed for the C/C++11 implementation. Thus, this is hardware \ndesign exploiting the freedom provided by language-level concurrency models, and suf.cing for those requirements. \nSince the ordering semantics of an RMW depends on its atomic\u00adity semantics, our approach to weakening \nthe ordering semantics is through weakening the atomicity semantics. In contrast to the strict type-1 \natomicity which disallows writes of any address between the read and the write, we consider two weaker \natomicity de.nitions: the type-2 atomicity which disallows only reads and writes of the same address \nas the RMW; and the even weaker type-3 atomicity, which disallows only writes to the same address as \nthe RMW. Our key contribution is to derive the ordering semantics of the proposed weaker RMWs, and examine \nif the ordering is strong enough to replace existing RMWs in synchronization idioms (\u00a72.4, \u00a72.5). Unlike \na type-1 RMW, a type-2 RMW is not explicitly ordered with respect to memory operations before and after \nit. Thus, a type-2 RMW cannot be used as a memory barrier like in Fig. 1(c). However, we show that a \ntype-2 RMW appears strongly ordered with respect to any memory operation that synchronizes with the RMW \ni.e. any memory operation from another thread that is to the same address as the RMW. Indeed, like before, \nDekker s algorithm can be ported to TSO by replacing reads (and/or writes) with type-2 RMWs. It is worth \nnoting that in the scenario shown in Fig. 1c (Fig. 1d), each of the RMWs appear to be strongly ordered \nwith respect to the writes (reads) from the other thread which synchronize with the RMW; this strong \nordering is again able to guarantee correctness. For similar reasons, C/C++11 can be ported to TSO by \nreplacing SC-atomic-writes (and/or SC-atomic\u00adreads) with type-2 RMWs. Thus, type-2 RMWs are able to replace \nexisting type-1 RMWs in all synchronization idioms, except when used as a memory barrier. A type-3 RMW \nis also not explicitly ordered with respect to memory operations before and after it, and hence cannot \nbe used a memory barrier (like a type-2 RMW). However, unlike a type-2 RMW, it appears strongly ordered \nonly with respect to a write/RMW (but not a read) that synchronizes with the RMW. Therefore, Dekker s \nalgorithm can be ported to TSO by replac\u00ading reads (but not writes) with type-3 RMWs. Similarly, C/C++11 \ncan be ported to TSO by replacing SC-atomic-reads (but not SC\u00adatomic-writes) with type-3 RMWs. Table \n1 summarizes the use of type-1, type-2 and type-3 RMWs in various synchronization idioms. In our .nal \ncontribution, we propose ef.cient microarchitectural implementations of the weaker RMWs, which, in contrast \nto exist\u00ading implementations, do not incur the cost of a write-buffer drain (\u00a73). Our implementation \nof a type-2 RMW allows instructions fol\u00adlowing it to retire as soon as the read obtains exclusive ownership \nof the cache-line and locks it locally. The write simply retires into the tail of the write-buffer thus \nthe write-buffer drain is moved out of the critical path. To guarantee atomicity, coherence requests \nto the locked cache-line are denied until the write (of the RMW) and the pending writes prior to it complete. \nHowever, to prevent a potential deadlock we need to ensure that the above pending writes will eventually \ncomplete, and not be blocked by an RMW from another processor. We ensure this by tracking the list of \nunique RMW addresses in per-processor bloom .lters. When a pending write (before the RMW) is found to \ncon.ict with the list of main\u00adtained RMW addresses, we revert to draining the write-buffer, thus avoiding \nthe possibility of a deadlock (\u00a73.2). The type-3 RMW implementation is almost identical, with one difference. \nSince type-3 atomicity permits reads to the same ad\u00ad Table 1. Conventional RMW (type-1) vs proposed \nRMWs (type-2, type-3) Atomicity De.nition Dekker s with reads replaced by RMWs? Dekker s with writes \nreplaced by RMWs? Dekker s with RMWs as barriers? C/C++11 by replacing SC-atomic-reads with RMWs? C/C++11 \nby replacing SC-atomic-writes with RMWs? type-1 . . . . . type-2 . . . . . type-3 . . . . . dress as \nthe RMW between the read and the write, the read need not obtain exclusive ownership of the cache-line \n leading to a potentially more ef.cient implementation (\u00a73.3). Our experimen\u00adtal results (\u00a74) from benchmarks \nchosen from Splash-2, PARSEC, STAMP, and lock-free data structures show that in comparison with the existing \ntype-1 RMW, our proposed type-2 RMW (type-3 RMW) is up to 58.9% (64.3%) cheaper, which translates into \nan overall performance improvement of upto 9.0%(9.2%) We are not the .rst to propose weaker atomicity \nsemantics for RMWs in general. In fact, Gharachorloo et al. [12] have already observed that it is suf.cient \nfor RMWs to use a type-3 de.nition for atomicity. However, in order for their TSO speci.cation to be \ncompliant with the original TSO speci.cation, additional program order edges are added to RMWs, making \nthe RMWs strongly ordered. In other words, by explicitly adding additional program order edges, the RMWs \nin their speci.cation are effectively made equivalent to type-1 RMWs. In this paper, we consider the \ncase in which the atomicity de.nitions are weakened, but additional program order edges are not added \nto the RMW. Besides, our proposed type-2 atomicity de.nition, to the best of our knowledge has not been \nconsidered before. More on related work in \u00a75.  2. Semantics of TSO RMWs In this section we will propose \nde.nitions of atomicity weaker than the standard strong de.nition for RMWs in TSO, and derive the or\u00addering \nproperties that apply. We will then use those ordering prop\u00aderties to demonstrate the use of weakened \nRMWs in synchroniza\u00adtion in particular, we will demonstrate when they are suf.cient to implement the \nC/C++11 concurrency model. We begin with recalling the base TSO model (without RMWs), and then add our \nnew formulations of atomicity. The base TSO model follows Alglave [2], where our atomicity de.nitions \n.t most naturally. We present here only a brief introduction to Alglave s for\u00admulation published previously. \nReaders, particularly those familiar with alternative TSO formulations, should refer to Alglave s the\u00adsis \nfor more details. The thesis has a proof of equivalence with the SPARC de.nition of TSO [25] is given, \nwhich is separately shown by Owens et al [22] to resemble the x86 multiprocessor model. 2.1 Base TSO \nAs usual in axiomatic memory models, we .rst derive a set of candidate executions from a program. Each \ncandidate execution contains a set of events and relations over them, and represents a conceivable execution \npath (with control-.ow unfolded, and values for each read in the program). In the next step, the memory \nmodel will carve out (via conditions on those relations) which of these candidate executions are allowed \nby the model. The events (memory reads, writes, and barriers) are annotated with their thread, type, \nand for memory accesses the associated address and value. From the program we derive the program order \n(po) relation, a local (per-thread) total order over events from the same thread as they appear in the \nprogram. We also consider two relations which are existentially quanti.ed over: a reads-from map (rf) \nand write-serialization (ws), both relations over events. The relation rf maps, for each read, the write \nthat the read takes its value from to the read. The relation ws is a linear order per location relating \nall (and only) the writes to the same location, and represents the coherence order of the system (in \nprior work, this relation is also called coherence co). For ease of stating the memory model, we derive \nvarious addi\u00adtional relations from the above. The from-reads relation (fr) relates a read to all writes \nto the same location that come after (in ws)the write it reads from (given by rf). The external-reads-from \nrelation (rfe) is the subrelation of rf which is restricted to reads which read from a different-thread \nwrite. The communication relation com is the union of ws, rfe,and fr. A preserved-program-order relation \n(ppo) relates all memory operations from the same thread in program order, according to TSO ordering \nrules. Thus it relates all memory operations, except po writes to program order-subsequent reads: In \nother words, W -. popo W , R -. W , R -. R all belong to ppo also. A barrier-separated relation (bar) \nrelates memory operations (on the same thread) separated in program order by a memory barrier. The behavior \nof a program is the set of corresponding execution witnesses which are valid. A valid execution witness \nis one where the union of com, ppo,and bar is acyclic, and satis.es the uniproc condition. The uniproc \ncondition states that the relation com is consistent with the per-thread order of memory operations to \nthe same location. The .rst condition says that a happens-before-like relation is acyclic. In this case \nwe call a linear extension of of com, ppo,and bar the global-happens-before relation (ghb). Informally, \nit is the global memory order (also known as execution order) in which memory operations appear to perform. \n 2.2 Adding RMWs to the model We now consider events coming from RMWs. These correspond to one read and \none write to the same location we denote the read part of the RMW as Ra and the write part of the RMW \nas Wa. In an RMW, the read part comes before the write in program order consequently, the read Ra reads \nan earlier value and not the value written by Wa. In addition to this, Ra and Wa need to be performed \natomically, where atomicity is one of the following three de.nitions: Type-1 Atomicity. This is a strict \nde.nition of atomicity, used by existing TSO RMWs [16, 26], that prevents writes of any address from \nappearing between the read and the write in the global memory order. More formally, with type-1 RMWs \nadded to the TSO model, valid execution witnesses are ones which further impose that there is no event \nin ghb between Ra and Wa.  Type-2 Atomicity. This is a weakening which only prevents reads and writes \nof the same address as the RMW from appearing between Ra and Wa in the global memory order. More formally: \n ghbghb {.M(x): M(x) --. Ra(x) . Wa(x) --. M(x)}. Type-3 Atomicity. This is a further weakening which \nmerely prevents writes of the same address as the RMW from appearing between Ra and Wa in the global \nmemory order. More formally: ghbghb {.W (x): W (x) --. Ra(x) . Wa(x) --. W (x)}. It is important to \nnote that even type-3 atomicity, the weakest of the atomicity de.nitions, satis.es the notion of atomicity \nrequired for solving the consensus problem [15] consensus being the ab\u00adstract problem that models synchronization \nidioms. Nonetheless, this does not imply that the three types of RMWs can be used inter\u00adchangeably. In \nfact, we shall see that each of the three atomicities gives rise to RMWs that are ordered differently. \n Atomicity-induced orderings. Each atomicity de.nition, by dis\u00adallowing a speci.c set of memory operations \nbetween Ra and Wa in the global memory order effectively requires both Ra and Wa of the RMW to be ordered \nidentically with such disallowed memory operations. For example, if just Ra (and not Wa)isorigi\u00adnally \nordered before a disallowed memory operation M in the ghb ghb (Ra --. M), then atomicity requires Wa \nto also be ordered be\u00ad ghb fore M (Wa --. M) otherwise M could end up between Ra and Wa in the ghb. \nIn other words, the atomicity constraint induces additional memory orderings the atomicity relation \nato is used to refer to such atomicity-induced orderings. In the above example, ato the ordering Wa - \n. M would be an atomicity-induced ordering. Accounting for such atomicity-induced orderings, the global \nmem\u00adory order (ghb) is the linear extension of the union of com, ppo, bar,and ato. A valid execution \nwitness, like before, is one which has an acyclic union of the above relations (including ato), and satis.es \nthe uniproc condition. Next, we will derive the atomicity\u00adinduced memory ordering constraints for each \nof the atomicity def\u00adinitions.  2.3 Type-1 RMWs The strict type-1 de.nition of atomicity combined with \nTSO s preserved program order ensures that a type-1 RMW is strongly ordered with respect to memory operations \nbefore and after it. memory barriers. Below, we demonstrate how type-1 RMWs are used in various synchronization \nidioms:  Figure 3. Dekker s with writes replaced by RMWs. In this and other examples that follow, RMW \n(x, 0, 1) means that the RMW reads a value of 0 from location x and updates it to 1 Dekker s: write-replacement. \nOne way to ensure that Dekker s algorithm works on TSO architectures is to replace the writes with type-1 \nRMWs as shown in Fig. 3 [16, 26] In the above example, we assume that the read R(y) from thread 0 reads \nthe initial value of 0. For Dekker s algorithm to work the read R1(x) should read a value of 1. The following \nsequence of orderings ensure this: atofr ato Wa(x) --. R(y) -. Wa 1 (y) --. R1(x) where ato denotes \nthe additional orderings induced by atomicity.  Figure 2. Additional memory orderings induced by type-1 \nRMW Lemma 1. An RMW placed between a write W1 andaread R2, atoato results in the enforcement of W1 --. \nRa, Wa --. R2 and ato consequently, W1 --. R2. ghb Proof. Type-1 atomicity mandates that either Wa --. \nW1 or ghbppo W1 --. Ra. As shown in Fig. 2, W1 --. Wa. This implies atoato W1 - . Ra. Next, we prove \nthe second part: Wa --. R2.As ppo shown in Fig. 2, Ra --. R2. This implies that either R2 occurs after \nWa in the ghb or R2 is between Ra and Wa. Meanwhile, type-1 atomicity mandates that there cannot be any \nwrites between Ra and Wa in the ghb; in particular there cannot be any writes to location z. This implies \nthat even if R2 were to occur between Ra and Wa, it can be safely be moved after Wa. This in turn atoato \nimplies Wa --. R2. Finally, W1 --. R2, because of transitivity atoppo (W1 --. Ra and Ra --. R2). Such \nstrongly ordered type-1 RMWs result in costly implemen\u00adtations that involve a write-buffer drain; however, \nthey can be used to port synchronization idioms to TSO without requiring additional  Figure 4. Dekker \ns with reads replaced by RMWs. Dekker s: read-replacement. Using similar reasoning, it is easy to see \nthat replacing reads with type-1 RMWs will also ensure that Dekker s algorithm works on TSO (Fig. 4). \n Figure 5. Dekker s with RMWs used as memory barriers. The two RMWs access different addresses z1 and \nz2. Dekker s: RMWs as barriers. One simple way to make Dekker s algorithm work on TSO is to insert memory \nbarriers between the writes and the reads, as the W . R ordering enforced by the memory barriers would \nensure correctness. Since type-1 RMWs order memory operations before and after it, they can very well \nbe used instead of the barriers. As shown in Fig. 5, the following atofr sequence of ordering ensures \ncorrectness: W (x) --. R(y) -. ato W 1 . R1 (y) - (x). Implementing C/C++11 using type-1 RMWs. The C/C++11 \ncon\u00adcurrency model [7, 10] is an adaptation of data-race-free-0 [1] which guarantees SC for data race \nfree programs. It introduces a variety of atomic memory operations parameterized by different memory \norder parameters. Correct compilation depends (among other things) on mapping these atomic memory operations \nto hard\u00adware primitives. Batty et al. [6] recently proved that C/C++11 can be implemented on X86-TSO \nby mapping C/C++11 SC-atomic\u00adreads and SC-atomic-writes to type-1 RMWs supported by x86 ar\u00adchitectures \n(non-SC atomic reads and writes and non-atomic ac\u00adcesses can simply be mapped to ordinary TSO reads and \nwrites). In fact, it is easy to adapt this proof and show that it is suf.cient to map at least one of \nthe SC-atomic-writes or the SC atomic reads to type\u00ad1 RMWs (see appendix). Informally, since TSO already \npreserves all program orders except the W . R order, we only need to ensure SC-atomic-writes are ordered \nwith subsequent SC-atomic\u00adreads; similarly to Dekker s algorithm, this can be accomplished by replacing \neither the reads or writes with type-1 RMWs.  2.4 Type-2 RMWs We show that, unlike a type-1 RMW, a type-2 \nRMW placed be\u00adtween a write W1 and a read R2 does not explicitly enforce any of ghbghbghb W1 --. Ra, \nWa --. R2,or W1 --. R2. However, it disal\u00ad ghbghb lows Ra --. W1 and R2 --. Wa from being enforced 1 \nin effect, a type-2 RMW is implicitly ordered with respect to memory operations before and after it. \n Figure 6. Memory ordering disallowed by a type-2 RMW Lemma 2. A type-2 RMW placed between two memory \noperations W1 and R2, disallows the enforcement of the following two order\u00ad ghbghb ings: Ra --. W1 and \nR2 --. Wa. Proof. Let us attempt to prove by contradiction by assuming the ghb ordering Ra --. W1 is \nenforced. Since there is no ppo edge ghb directly connecting Ra and W1, Ra --. W1 we will need to be \nenforced via a sequence of edges as shown in Fig. 7. More speci.cally, there has to be a write W 1(y) \nwhich con.icts with fr ghbfr Ra(y) such that: Ra(y) -. W 1(y) --. W1(x).But, Ra(y) -. ato W 1(y) implies \nWa(y) --. W 1(y), due to type-2 atomicity. This atoghbppo leads to a cycle: Wa(y) --. W 1(y) --. W1(x) \n--. Wa(y). ghb Similarly for the other part let us assume R2 --. Wa.As shown in Fig. 7, this implies \nthat there has to be a read R11(y) ghb 1 Disallowing an ordering M1 --. M2 (say) is not the same as enforcing \nghb M2 --. M1. The latter implies that M2 will occur before M1 in every valid global memory order, while \nthe former implies that it is not necessary for M1 to occur before M2 in every valid global memory order \n Figure 7. Scenario for proof of lemma 2. ghbfr . R11(y) which con.icts with Wa(y) such that: R2(z) \n---. fr ato Wa(y).But, R11(y) -. Wa(y) implies R11(y) --. Ra(y), ppo due to type-2 atomicity. This \nleads to a cycle: Ra(y) --. R2(z) ghbato . R11 --(y) - . Ra(y). Effect of implicitly ordered type-2 \nRMWs. Since a type-2 RMW neither enforces W1 . Ra nor Wa . R2, it also does not tran\u00adsitively enforce \nW1 . R2. Consequently, a type-2 RMW is not ordered like a memory barrier; in the next section we will \npro\u00adpose an ef.cient implementation that does not incur the cost of a write-buffer drain. At the same \ntime, a type-2 RMW appears to be strongly ordered with respect to any memory operation that syn\u00adchronizes \nwith the RMW i.e any memory operation from another thread that is to the same address as the RMW. As \nshown in Fig. 7, with respect to W 1(y) which synchronizes with Ra, W1 appears to be ordered before the \nRMW. This is because, type-2 atomicity ato induces the ordering Wa(y) --. W 1(y), which results in the \nse\u00ad ppoato quence of orderings: W1(x) --. Wa(y) --. W 1(y), thereby en\u00adsuring W1(x) . W 1(y). Likewise, \nwith respect to R11(y) which synchronizes with Wa, R2(z) appears to perform after the RMW atoppo the \nsequence of orderings R11(y) - . Ra(y) --. R2(z) ensures this. Consequently, type-2 RMWs can seamlessly \nreplace existing RMWs in synchronization idioms, as we will demonstrate next. Dekker s: write-replacement. \nSimilarly to type-1 RMWs, Dekker s algorithm will continue to work with writes replaced by type-2 fr \nato RMWs as shown in in Fig. 3. Since R(y) -. Wa 1 (y), R(y) - . R1 a(y) (due to type-2 atomicity). \nNow, the sequence of order\u00ad ppoatoppo ings Ra(x) --. R(y) --. R1 a(y) --. R1(x) ensures that ghbato \n Ra(x) --. R1(x). This in turn implies that Wa(x) --. R1(x), again due to type-2 atomicity. Dekker s: \nread-replacement. Using a similar reasoning, replacing reads with type-2 RMWs will also ensure that Dekker \ns algorithm fr ato works on TSO (Fig. 4). Since Ra(y) -. W 1(y), Wa(y) - . W 1(y) (due to type-2 atomicity). \nNow, the sequence of order\u00ad ppoatoppo ings W (x) --. Wa(y) - . W 1(y) --. Wa 1 (x) ensures that ghbato \n W (x) --. Wa 1 (x). This in turn implies that W (x) --. R1 a(x), again due to type-2 atomicity. Dekker \ns: RMWs as barriers (different addresses). A type-2 RMW cannot be used as a memory barrier in Dekker \ns algo\u00adrithm if the RMWs used to replace the barriers access different addresses, since they would not \nappear strongly ordered with one another. As shown in Fig. 5, it can potentially allow the following \nsequence of operations Ra(z1),R(y),Ra 1 (z2),R1(x),W (x), Wa(z1),W 1(x),Wa 1 (z1) which would lead \nto R1(x) to read a value of 0.  Figure 8. Dekker s with RMWs used as a memory barrier. The two RMWs \naccess the same addresses z. Dekker s: RMWs as barriers (same address). A type-2 RMW, however, can be \nused as a memory barrier in Dekker s algorithm if the inserted RMWs access the same address, since this \nensures that the RMWs appear strongly ordered to one another. As shown in Fig. 8, type-2 RMWs used in \nthe above fashion ensure that R1(x) will read the correct value of 1. To see why, .rst recall fr that \nbased on our assumption R(y) -. W 1(y). This implies that rf e rf e Wa(z) --. Ra 1 (z) (as the other \npossibility Wa 1 (z) --. Ra(z) rf e ppo would result in the following cycle: Wa 1 (z) --. Ra(z) --. fr \nppo R(y) -. W 1(y --. Wa 1 (z)). This in turn leads to the sequence pporf e ppo W (x) --. Wa(z) --. Ra \n1 (z) --. R1(x), ensuring that R1(x) reads the correct value. Implementing C/C++11 using type-2 RMWs. \nWe formally show that, similarly to type-1 RMWs, C/C++11 can be implemented by mapping at least one of \nSC-atomic-writes or SC-atomic-reads to type-2 RMWs. Recall that, since TSO already preserves all program \norders except the W . R order, we only need to ensure SC-atomic-writes are ordered with subsequent SC-atomic-reads. \nIntuitively, since type-2 RMWs appear strongly ordered when used in synchronization idioms, this can \nbe accomplished by replacing either the SC-atomic-reads or SC-atomic-writes with RMWs. See appendix for \nthe formal proof.  2.5 Type-3 RMWs We show that, similarly to a type-2 RMW, a type-3 RMW placed ghb \nbetween W1 and R2 does not explicitly enforce any of W1 --. Rghb Ra, Wa -.2 ghb,or W1 --. R2. However, \nunlike a type-2 RMW it disallows only Ra . W1 (but could allow R2 . Wa) in effect, a type-3 RMW is implicitly \nordered with respect to memory operations before it, but not with those after it. Lemma 3. A type-3 RMW \nplaced between two memory operations ghbghb W1 and R2, disallows Ra --. W1 (but could allow R2 --. Wa \nto be enforced). ghb Proof. Proof of \u00acRa --. W1 is identical to the .rst part of ghb the proof of lemma \n2. To understand why R2 --. Wa is not disallowed, let us consider the second part of the proof of lemma \n2, ghb where we assumed R2 --. Wa. As shown in Fig. 7, this implies that there has to be a read R11(y) \nwhich con.icts with Wa(y) such ghbfr . R11 that: R2(z) --(y) -. Wa(y). Recall that type-2 atomicity \nFigure 9. Memory ordering disallowed by a type-3 RMW ato induced the ordering: R11(y) --. Ra(y),whichledtoacycle. \nHowever, such an ordering is not induced by type-3 atomicity, which allows for reads to happen between \nthe Ra(y) and Wa(y), and so there is no cycle. Effect of implicitly ordered type-3 RMWs. Since a type-3 \nRMW enforces neither W1 . Ra nor Wa . R2, it also does not transitively enforce W1 . R2. Consequently, \na type-3 RMW is not ordered like a memory barrier. At the same time, a type-3 RMW appears to be strongly \nordered with respect to any write/RMW that synchronizes with the RMW. As shown in Fig. 7, with respect \nto W 1(y) which synchronizes with Ra, W1 appears to be ordered before the RMW. This is because type-3 \natomicity induces Wa(y) ato --. W 1(y), which in turn results in the sequence of orderings: ppoato W1(x) \n--. Wa(y) --. W 1(y) which ensures this. On the other hand, with respect to the read R11(y) which synchronizes \nwith Wa, R2(z) does not appear to be ordered after the RMW, since type\u00ad3 atomicity allows R11(y) to occur \nbetween Ra(y) and Wa(y). Consequently, type-3 RMWs cannot seamlessly replace existing RMWs in synchronization \nidioms, as we will demonstrate next. Dekker s: write-replacement. Unlike type-1 or type-2 RMWs, replacing \nwrites with type-3 RMWs cannot guarantee correctness (Fig. 3). This is because type-3 atomicity is not \nable to induce ato R(y) --. Ra 1 (y). Hence, the following sequence is allowed: Ra(x),R(y),Ra 1 (y),R1(x),Wa(x),Wa \n1 (y) which would lead to R1(x) to read 0. Other Dekker s scenarios. For the other Dekker s algorithm \nsce\u00adnarios (Fig. 4, Fig. 5, and Fig. 8) a type-3 RMW behaves identically to a type-2 RMW. Implementing \nC/C++11 using type-3 RMWs. We formally show that C/C++11 can be implemented by mapping SC-atomic-reads \n(and optionally SC-atomic-writes) to type-3 RMWs. However, it is not suf.cient (unlike type-1 and type-2 \nRMWs) for only the SC\u00adatomic-writes to be so mapped. Intuitively, since type-3 RMWs appear strongly ordered \nonly when synchronizing with writes or RMWs, but not reads, all SC-atomic-reads need to replaced with \nRMWs. See appendix for the formal proof. 2.6 Summary We show that type-2 RMWs can seamlessly replace \ntype-1 RMWs in various synchronization idioms, except when a type-1 RMW is used purely as a memory barrier. \nGiven that all modern TSO(\u00adlike) architectures have a dedicated memory barrier instruction, there is \nno need to use an RMW as a barrier. Furthermore, type\u00ad2 RMWs can still be used as a memory barrier provided \nsuch RMWs are forced to synchronize with each other (by forcing them to access the same address). Similarly \nto type-2 RMWs, type-3 RMWs also do not behave like memory barriers. However, unlike type-2 RMWs, type-3 \nRMWs only appear ordered with respect to writes/RMWs (but not reads) that synchronize with the RMW; thus \ntype-3 RMWs cannot seamlessly replace type-1 RMWs. Neverthe\u00adless, we show that by replacing synchronization \nreads with type-3 RMWs, the above synchronization idioms can still be implemented using type-3 RMWs. \n  3. TSO RMWs: Implementation In this section we .rst discuss how existing type-1 RMWs are implemented. \nWe then describe our proposed type-2 and type-3 RMW implementations. For the following discussion we \nassume a chip multiprocessor with local L1 caches and a shared L2 cache; the local caches are kept coherent \nat the L2 cache using a distributed directory based coherence protocol. 3.1 Type-1 RMW Recall that a \ntype-1 RMW is strongly ordered with respect to memory operations before and after it: a type-1 RMW placed \nbetween write W1 and read R2 results in the enforcement of W1 . Ra and Wa . R2,where Ra/Wa are the read/write \nof the RMW respectively. To enforce W1 . Ra, pending writes in the write\u00adbuffer (if any) must complete \nbefore Ra can retire. Furthermore, type-1 atomicity mandates that there should not be any con.icting \nreads or writes (to the same address as the RMW) between Ra and Wa. To ensure this, existing RMW implemen\u00adtations \nuse a cache-line locking mechanism [16, 20, 26]. The Ra obtains read/write permissions for the cache-line, \nand locks it be\u00adfore it retires, thereby denying coherence requests to the cache-line. Once Wa completes, \nthe cache-line is unlocked. To ensure that Wa . R2 is enforced, R2 is allowed to retire only after Wa \ncompletes. In other words, reads that follow the RMW have to wait until: (a) all writes prior to the \nRMW are performed (the write-buffer is drained) and (b) Ra and Wa are performed. Thus, the type-1 RMW \nincurs the cost of a write-buffer drain and the cost of performing Ra and Wa. Gharachorloo et al. [13] \nproposed two techniques to provide ef.cient memory ordering. Both these techniques can be used to improve \nthe performance of type-1 RMWs. The .rst one involves issuing the read-exclusive request for all pending \nwrites in paral\u00adlel, to ef.ciently enforce the write-buffer drain. The actual writes, however, are completed \nin-order, keeping with TSO. Parallel issue of the read-exclusives will be serialized at the local L1 \ncache and at the directory, but will make full use of the interconnect and over\u00adlap invalidation and \nacknowledgement messages for all the pend\u00ading writes. The second technique is to hide part of the write-buffer \ndrain latency through in-window speculation. Here, the instructions following the RMW are speculatively \nexecuted, but are allowed to complete only after the RMW and all the pending writes before it complete. \n 3.2 Type-2 RMW Recall that a type-2 RMW is not explicitly ordered with respect to memory operations \nbefore and after it in the program order. Since a type-2 RMW that is placed between memory operations \nW1 and R2, does not enforce W1 . Ra, Ra need not wait for the write\u00adbuffer to be drained. However, type-2 \natomicity still disallows con.icting reads or writes from appearing between Ra and Wa in the global memory \norder. Similarly to a type-1 RMW, this is ensured using the cache-line locking mechanism. Like before, \nRa obtains read/write permissions for the cache-line, locks the cache\u00adline, and then retires. After this, \nWa simply retires into the tail of the write-buffer. At this point the RMW effectively retires, and allows \nmemory operations following it (e.g. R2) to retire (since Wa . R2 is not enforced). Finally, when Wa \nreaches the head of the write-buffer and completes, the cache-line is unlocked.  Write-deadlocks. The \nabove implementation, while simple, can potentially result in a deadlock. To guarantee type-2 atomicity, \ncoherence requests to the cache-line locked by an RMW are denied until Wa and the pending writes prior \nto it complete. If such a pending write W1 is to a cache-line which has already been locked by another \nRMW1 from a different processor, then W1 (and hence Wa) will have to wait until Wa 1 completes. If Wa \n1 itself is stalled because of a similar write in its write-buffer, a deadlock manifests. This is illustrated \nin the code segment shown in Fig. 10(a), where W (x) occurs before RMW(y),and W 1(y) occurs before RMW1(x) \nin program order. As shown in Fig. 10(b), let us as\u00adsume that Ra(y) and R1 a(x) have retired after locking \ntheir respec\u00adtive cache-lines, while the writes (W (x) and W 1(y)) have retired into the write-buffer \nand are yet to complete. Cache-line locking ensures that W (x) cannot complete until Wa 1 (x) has completed, \nand W 1(y) cannot complete until Wa(y) has completed. How\u00adever, since writes are ordered in TSO, Wa(y) \ncannot complete until W (x) completes, and Wa 1 (x) cannot complete until W 1(y) com\u00adpletes. This leads \nto a write-deadlock. More formally, our assumptions can be represented by the two fr fr fr orderings: \nR1 a(x) -. W (x) and Ra(y) -. W 1(y).Now,type\u00ad ato 2 atomicity induces the two orderings: Wa 1 (x) --. \nW (x) and atoppo Wa(y) --. W 1(y). This in turn results in a cycle: W (x) --. atoppoato Wa(y) --. W \n1(y) --. Wa 1 (x) --. W (x). Since each of the memory operations which are part of the cycle have not \nyet performed, a deadlock ensues. Deadlock avoidance. In order to ensure that the deadlock scenario discussed \nabove never occurs, we should guarantee that none of the pending writes before an RMW, are to cache-lines \nlocked by other RMWs the deadlock safety property. To ensure this, we propose a mechanism to dynamically \nmaintain the set of unique RMW addresses accessed by RMWs from all processors the addr-list. Furthermore, \nwe make this addr-list available locally to each of the processors. Now, when an RMW is performed, if \nnone of the pending writes in the write-buffer con.ict with the addr-list, we can safely say that these \nwrites are not to locked cache-lines. On the other hand, if any of the pending writes con.icts with the \naddr-list, the deadlock safety property is not guaranteed. In such a case, we revert to type-1 implementation \nby draining the write-buffer before performing the RMW thereby avoiding a deadlock. There are two challenges \nto ef.ciently implementing this mech\u00adanism in hardware: (a) keeping track of the RMW addresses in the \naddr-list ef.ciently; (b) keeping the addr-list coherent across all processors. We implement the addr-list \nusing a bloom .lter [8], which is a well understood mechanism for maintaining sets and supporting membership \nqueries. In order to keep the addr-list co\u00adherent we simply broadcast the address whenever a new RMW \nad\u00address is encountered by a processor. Our design exploits the fact that the number of unique RMW addresses \nis relatively small our experiments show that typically around 1% of the number of dynamic RMWs are \nto unique addresses. This in turn means that the addresses of the RMWs can be stored ef.ciently in a \nrelatively small-sized bloom .lter, with a low probability of false positives. More importantly, the \nnumber of broadcasts required to keep the addr-list coherent is minimal. We now explain the working \nof our mechanism in more detail. When an RMW is ready to perform, we .rst query the bloom .lter for the \nRMW address. If the address is not found in the .lter, we insert the RMW address into the local bloom \n.lter. In addition to this, since the addr-list has changed, we broadcast the new address to all processors. \nEach of the other processors, upon receiving the address, inserts the address into its respective bloom \n.lter and sends back an acknowledgement. Once all acknowledgements have been received (or if the RMW \ns address is found in the addr-list in the .rst place), we query the bloom .lter with the pending writes \naddresses. If any of these write addresses are found in the addr\u00adlist, this .ags a potential deadlock. \nConsequently, the write-buffer is drained before performing the RMW like a type-1 RMW. On the other hand, \nif none of the pending writes addresses are found, the RMW does not wait for the write-buffer to drain. \nIt locks the cache\u00adline and simply retires, while the write of the RMW is retired into the write-buffer. \nTo see why our scheme is correct note that an RMW can lock the cache-line and retire (with pending writes \nin the write-buffer) only when:  c1: the RMW s address is made visible to all processors  c2: none \nof the pending writes con.ict with the addr-list.  Now, c1 implies that any write (W 1) that could be \npotentially involved in a deadlock with the original RMW will con.ict with the local addr-list. c2 implies \nthat an RMW with W 1 in its write\u00adbuffer will revert to type-1, thereby avoiding a deadlock. Consider \nthe deadlock scenario shown in Fig. 10(c). Recall that in the dead\u00adlock scenario, Ra(y) and R1 a(x) have \nretired, but their respective pending writes W (x) and W 1(y) are unable to complete (inducing fr fr \nthe two fr orderings: R1 a(x) -. W (x) and Ra(y) -. W 1(y)). The fact that Ra(y) and R1 a(x) have retired \nimplies that both x and y must be present in the bloom .lter (from c1). In addition to this, W (x) and \nW 1(y) should have checked the .lter for con.icts (from c2). The assumed fr orderings imply that neither \nof the writes con\u00ad.icted with the bloom .lter. This in turn implies that neither x nor y are in the bloom \n.lter leading to a contradiction. False Positives. Bloom .lters suffer from false positives. The cor\u00adrectness \nof our scheme, however, is not compromised. The false positive may result from either an RMW or a pending \nwrite check\u00ading the bloom .lter. When an RMW, whose address has not been encountered before, queries \nthe bloom .lter and the bloom .lter returns a false positive, the RMW address ends up not being broad\u00adcast. \nThis is safe, however, because any write which con.icts with this address will also similarly return \na false positive. It is worth noting that false positives in this case may reduce the number of RMW broadcasts. \nLikewise, When a pending write queries the bloom .lter and the .lter returns a false positive, the write-buffer \nis unnecessarily drained. The correctness of the mechanism, however, is not affected. Finally, in our \ndesign, the bloom .lter keeps track of RMW ad\u00addresses of all contexts. In other words, each bloom .lter \nis indepen\u00addent of the thread context. While this may increase the probability of false positives, it \nagain does not present any correctness issues. It is worth noting that, the probability of false positives \nin the .lter increases with the number of elements inserted into it, leading to a performance degradation \nover time. To handle this, we reset the bloom .lters of all processors when the number of RMW addresses \ninserted into the .lter exceeds a certain threshold, which is a function of the bloom .lter con.guration. \nTo ensure correctness, when a processor receives a reset request, it waits until all in-.ight RMWs have \ncompleted, and responds subsequently.  3.3 Type-3 RMW Recall that a type-3 RMW, like a type-2 RMW, is \nnot explicitly ordered with respect to memory operations before and after it. Ra need not wait for the \nwrite-buffer to be drained it can retire even if there are pending entries in the write-buffer. However, \ntype-3 atomicity still disallows con.icting writes and other RMWs from appearing between Ra and Wa in \nthe global memory order. Since reads to the same memory address can appear between Ra and Wa, it is suf.cient \nfor Ra to get read permissions for the cache-line, unlike type-1/type-2 RMW which require read/write \npermission. If the RMW is to a cache-line owned by the local cache, then it is locked in the cache itself \nbefore retiring Ra, similar to type\u00ad1/type-2 RMWs. If the RMW is to cache-line in shared state, however, \nlocking the cache-line locally cannot prevent an RMW from another processor, which also has the cache-line \nin its local cache, from performing. To resolve this, we propose a directory locking protocol, wherein \nRa to a cache-line in shared state is locked in the directory by transitioning the cache-line to a locked \nstate. When Wa is issued from the write-buffer, the cache-line is transitioned out of the locked state \nallowing subsequent coherence requests to the cache-line to be serviced. This optimization removes any \ninvalidation delay, incurred by the RMW, from the critical execution path. Once Ra obtains a lock and \nretires, Wa simply retires into the tail of the write-buffer. At this point the RMW effectively retires, \nand allows memory operations following it to retire. Thus reads that follow a type-3 RMW will only have \nto wait until Ra obtains read permission for the cache-line and locks it. Finally, when Wa reaches the \nhead of the write-buffer and completes, the lock on the cache-line is released. Similarly to type-2 RMWs, \nthe implementation of type-3 RMWs also makes use of the bloom .lter mechanism to avoid deadlocks.  4. \nExperimental Evaluation The primary goal of our experiments was to compare the cost of type-1, type-2, \nand type-3 RMWs. Furthermore, we evaluated the impact of the different types of RMWs on the overall execution \ntime of the benchmark programs. Since RMWs are also used to im\u00adplement C/C++11 SC-atomic-reads and/or \nSC-atomic-writes, we also investigated the performance of supporting C/C++11 concur\u00adrency model with \ntype-1, type-2 and type-3 RMWs. We brie.y de\u00adscribe our implementation before discussing the results. \n4.1 Implementation Table 2. Architectural Parameters Processor 32 core CMP, inorder Write Buffer 32-entry \ndeep L1 Cache private, 32 KB 4-way 2-cycle latency L2 Cache shared, 1 MB per-core, 16-way 6-cycle latency \nMemory 300 cycle latency Coherence MOESI distributed directory Interconnect 2D Mesh, 1-cycle link, 4-cycle \nrouter latency  Simulator. We use the GEM5 simulator to implement our base\u00adline system, which is an \nx86-based CMP composed of inorder pro\u00adcessors, with local L1 caches and a shared-distributed L2 cache. \n Table 3. Benchmark Characteristics Code Suite Problem Size Ratio of RMWs per 1000 memops % Unique RMWs \n% write-buffer drains for type-2/type-3 RMW RMW broadcasts per 100 RMW ops radiosity SPLASH-2 room 15.56 \n0.28 0.06 0.26 raytrace SPLASH-2 car 13.83 0.02 0.12 0.02 .uidanimate PARSEC simmedium 17.43 0.46 0.09 \n0.46 dedup PARSEC simmedium 8.10 3.31 0.20 3.12 bayes STAMP bayes+ 34.15 0.91 0.01 0.80 genome STAMP \ngenome+ 6.19 0.64 0.10 0.52 wsq-mst Lockfree 10000 nodes 23.41 3.80 0.07 3.71 Cache latencies were obtained \nfrom CACTI [21]. The baseline uses type-1 RMWs. The local caches are kept coherent using a distributed \ndirectory based on the MOESI coherence protocol. We chose inorder cores for our simulation as the GEM5 \ns out-of-order processor model is unstable for full system simulation of the x86 processor architecture. \nThe choice of inorder cores, however, is a valid design point owing to the fact that several present \nand fu\u00adture many-core processors, like the Intel Xeon Phi, Sun Niagara T2, and NVIDIA GPUs, make use \nof inorder cores as opposed to out-of-order cores to achieve better performance to power ratios. As mentioned \nin the previous section, we implemented a parallel write-buffer drain mechanism. This improves the baseline \nsignif\u00adicantly over the serial write-buffer drain. We did not implement in-window speculation as it is \nnot applicable to inorder processors. The architectural parameters for our implementation are presented \nin Table 2. We modi.ed the simulator to implement type-2 and type-3 RMWs with deadlock avoidance. In \nour implementation, we used a 128B bloom .lter with 3 hash functions. It is worth noting that the only \nhardware overhead for type-2/type-3 RMWs is the 128B bloom .lter and a RMW threshold counter per processor. \nAlso, we did not make use of the threshold counter in our simulations as we ran only a single context \nwhich did not require a bloom .lter reset for good performance. Benchmarks. We evaluate our technique \nusing benchmarks in Table 3, which includes both lock-based and a lock-free program. radiosity and raytrace \nare benchmarks from the Splash-2 suite which primarily use RMWs in lock/unlock primitives. Similarly, \n.uidanimate and dedup (from PARSEC) are also lock-based bench\u00admarks. It is worth noting here that we \nchose only the top two bench\u00admarks from each suite, in terms of the ratio of RMW instructions to other \nmemory operations. We do this as traditional lock-based algorithms are highly scalable and do not communicate \n(or syn\u00adchronize) very much and thus do not bene.t from reducing the cost of RMWs. On the other hand, \nlock-free programs use more RMWs taking advantage of low-latency communication on multi\u00adcores. wsq-mst \nis a lock-free parallel spanning tree algorithm [4] using Chase-Lev work stealing queue. bayes and genome, \nfrom the STAMP (using TL2 [11]), use RMWs for locking writes in trans\u00adactions and to commit transactions. \nWe ran the benchmarks in their regions of interest, with the input sizes mentioned in Table 3. C/C++11 \nconcurrency. Because of the recency of the C/C++11 concurrency model, there is no corpus of C/C++11 code \nto test our ideas on. We therefore modi.ed the wsq-mst program to make use of atomic reads/writes as \nprescribed by the C/C++11 model. wsq-mst uses Dekker-like synchronization to update the task queue pointers \nwhile removing tasks from the queue; thus the read and write of this synchronization primitive corresponds \nto an SC\u00adatomic-read and SC-atomic-write respectively. As mentioned ear\u00adlier, the C/C++11 concurrency \nmodel can be realized by replacing SC-atomic-writes and/or SC-atomic-reads with RMWs. We com\u00adpare the \nperformance of the different types of RMWs by replacing either the SC-atomic-reads (wsq-mst rr) or SC-atomic-writes \n(wsq\u00admst wr) with RMWs. We do not consider type-3 RMWs for write replacement here as that cannot guarantee \ncorrectness (as described in \u00a72.5).  4.2 Cost of RMWs We split the cost of an RMW in two parts: the \ncost of performing the read and write (Ra/Wa); and the cost of handling the writes in the write-buffer. \nThe average cost of an RMW across the chosen benchmarks for type-1, type-2, and type-3 RMWs is presented \nin Fig. 11(a). As we can see, RMWs are expensive the average cost of type-1 RMWs is as high as 69 cycles. \nWe also observe that the write-buffer drain signi.cantly contributes to the overall cost of an RMW (58.0% \non average). We can infer from this that a signi.cant number of RMWs have at least one write in the write-buffer \nwhich needs to send out invalidation requests. Also, a signi.cant number of RMWs are to shared cache-lines \nwhich explains the cost contributed by Ra/Wa. Using type-2 RMWs, the cost of an RMW reduces by 38.6%\u00ad58.9% \nwhen compared to type-1 RMWs across the benchmarks. As seen from Fig. 11(a), a signi.cant portion of \nthe performance im\u00adprovement is by avoiding the write-buffer drain in the general case. Recall that we \nrevert to a write-buffer drain, when a write hits in the bloom .lter. As seen from Table 3, the average \nnumber of hits of pending writes in the bloom .lter is negligible for each bench\u00admark, and is sometimes \nzero. This explains the low write-buffer drain cost for type-2 and type-3 RMWs. It is worth noting that \nthe cost of Ra/Wa itself slightly increases when compared with type-1 RMWs as a portion of the RMWs require \nbroadcasts in addition to the invalidation request. The number of such RMW broadcasts depends on the \naccuracy of the bloom .lter. As shown in the table, the percentage of RMWs that require a broadcast is \nless than 1.0% for most lock-based benchmarks except for dedup (3.1%), which has a higher ratio of unique \nRMWs to begin with. We have not pre\u00adsented the increase in network traf.c due to RMW broadcasts, as this \nnumber is negligible across all chosen benchmarks (<0.5%). Type-3 RMWs reduce the cost of the RMW even \nfurther. The average cost of a type-3 RMWs is lower than type-1 RMWs by up to 64.3%. Type-3 RMWs reduce \nthe cost of Ra/Wa but incur a similar write-buffer drain delay as type-2 RMWs. C/C++11 concurrency. Similarly \nto lock-based benchmarks, we observe that using type-2 RMWs reduces the average cost of RMWs by 44.6% \n(write-replacement), and 43.2% (write-replacement) respectively, over type-1 RMWs. As mentioned earlier, \ntype-3 RMWs cannot be used for write-replacement. For read-replacement, type-3 RMWs provide an additional \n11.6% improvement over type\u00ad1RMWs. It is worth noting that the cost of RMWs in read-replacement (wsq-mst \nrr) is higher than in write-replacement (wsq-mst wr)for all types of RMWs; with read replacement, there \nare more entries   (a) Cost of type-1(left), type-2(center), and type-3(right) RMWs(b) Execution time \noverhead of RMWs Figure 11. Experimental Results in the write-buffer per-RMW, which increases draining \ncost. The cost of Ra/Wa, however, is oblivious to whether SC-atomic-read or SC-atomic-write were replaced. \nIn case of type-2 RMWs, we observe that the number of writes con.icting with the bloom .lter increases, \nthereby increasing the cost of an RMW. Also note that this lock-free program, unlike traditional benchmarks, \nhave more RMW broadcasts (3.7%) owing to a relatively larger number of unique RMWs. This affects the \nperformance of type-2 and type-3 RMWs. However, the write-buffer drain cost eclipses the broadcast overhead. \n 4.3 Execution time overhead Although we achieve a signi.cant reduction in the cost of an RMW in all \nchosen benchmarks, its impact on the overall execution time depends on the ratio of RMW operations to \nother memory opera\u00adtions. We call this the density of RMWs. Thus, benchmarks with a larger RMW density \nbene.t more from cheaper RMWs. Table 3 shows the ratio of the number of RMWs to the number of other memory \noperations in each of the benchmarks. From Fig. 11(b) shows the impact of RMWs on the overall execution \ntime for all the chosen benchmarks. As expected, lock-free algorithms suffer more from expensive RMWs \nthan lock-based algorithms. Similarly, bayes and wsq-mst also spend a lot of time performing RMWs. Al\u00adthough \ngenome is a lock-free benchmark, the impact of RMWs on the overall execution time is less owing to a \nlower RMW density. This is because genome performs a lot more operations per trans\u00adaction. As for lock-based \nbenchmarks, radiosity and .uidanimate spend more than 5.0% of their execution time on RMWs. This, however, \nis not the case with raytrace and dedup.Thisisaresult of the effort put into optimizing traditional lock-based \nbenchmarks. We can extrapolate that other benchmarks from Splash-2 and Par\u00adsec will show an even lesser \nimpact of RMWs. With type-2 RMWs, we get up to 9.0% reduction for bayes, where the write-buffer drain \nalmost but eliminated, as seen from Table 3. We also observe a signi.cant reduction in the contribution \nof RMWs to the overall execution time in all other lock-free bench\u00admarks as well. Even radiosity and \n.uidanimate show a reduction in overall execution time albeit lesser than 4%. Type-3 RMWs further improve \nthe overall performance over type-2 RMWs, but only by a minimal amount (<0.5%). C/C++11 concurrency. \nAs for the C/C++11 concurrency model, replacing read atomics with RMWs results in a slightly higher overhead \nof RMWs as can be seen from the .gure. The best performance can be obtained by replacing read atomics \nwith type-3 RMWs (7.7% improvement over type-1 RMWs). In summary, type-2 and type-3 RMWs are signi.cantly \ncheaper than type-1 RMWs across all chosen benchmarks. This translates to a signi.cant reduction in the \noverall execution time for the lock\u00adfree work stealing queue program which exhibits a higher RMW density. \nTraditional lock-based programs also show an improve\u00adment in performance. This improvement, however, \nis only visible in programs with a high RMW density. Other benchmarks show a negligible improvement in \nperformance.  5. Related Work Memory ordering. Over the years, researchers have proposed a number of \ntechniques for achieving memory ordering ef.ciently [9, 14, 17, 18, 23]. While any of the above techniques \ncan be used to ef.ciently implement the barrier-like ordering of a type-1 RMW, the goal of our work, \nhowever, is orthogonal. Instead of striving to implement the barrier-like ordering, we ask the question \nas to why a TSO RMW should be ordered like a memory barrier in the .rst place. Indeed, as we have shown \nthrough our weaker type-2/type-3 RMWs, implementing a barrier-like ordering is not necessary. Weaker \natomicity RMWs. Gharachorloo et al. [12] were the .rst to observe that it is suf.cient for RMWs to use \ntype-3 atomicity in the context of various memory consistency models. However, in order for their TSO \nspeci.cation to be compliant with the original TSO speci.cation, they then added additional program order \nedges to RMWs, making the RMWs strongly ordered hence equivalent to type-1 RMWs. The load-reserve/store-conditional \ninstruction is a classic exam\u00adple of an RMW in weaker models such as Power [19] which uses type-3 atomicity \nsemantics. None of the mainstream TSO archi\u00adtectures, however, provide such an RMW. However, even if \na TSO architecture were to support such an RMW, it would be ordered like a type-1 RMW. Because of its \nspeculative nature, memory opera\u00adtions following such an RMW can only be retired after the store\u00adconditional \nsucceeds, and thus, such memory operations will have to wait for pending writes in the write-buffer, \nmaking the store\u00adconditional act as a full barrier. Hardware locking mechanisms. There have been several \npropos\u00adals (e.g. [28]) which address issues related to hardware based lock\u00ading mechanisms. It is worth \nnoting that these locks refer to the syn\u00adchronization primitive as a whole and not the RMW instructions \nused in these primitives. These proposals primarily deal with lock contention and fairness. Our proposal \nis orthogonal to such work as we deal with the overhead added by the RMW to the local thread. 6. Conclusion \nWe observed that the atomicity semantics of an RMW is the key factor which affects the RMW s ordering \nsemantics, its pro\u00adgrammability, and its implementation cost. Existing TSO RMWs use a strict de.nition \nof atomicity (type-1) which results in the RMW being strongly ordered like a memory barrier. Whereas \ntype-1 RMWs are costly to implement, they can be easily used in synchronization idioms on TSO without \nrequiring additional memory barriers. In this paper, we proposed two weaker atomicity de.nitions: type-2 \nand type-3 atomicity; we formally derived how type-2 and type-3 RMWs would be ordered, and demonstrated \nthat the resultant ordering is strong enough to implement various syn\u00adchronization idioms using the weaker \nRMWs. We then proposed ef.cient architectural implementations of the weaker RMWs ex\u00adperimental results \nshow that our proposed type-2 RMW (type-3 RMW) is 58.9% (64.3%) cheaper than an existing type-1 RMW on \naverage. Based on our analysis and experimental evidence, type-2 RMWs, while performing almost as well \nas type-3 RMWs, are also able to seamlessly replace existing type-1 RMWs in common synchro\u00adnization idioms \n except in situations where an RMW is used as a memory barrier. Thus, they appear to be a promising alternative \nto existing type-1 RMWs. We also show how the proposed type-2 and type-3 RMWs can be used to implement \nC/C++11 atomics thus making it possible for the compiler to transparently utilize the proposed RMWs \nto realize C/C++11 more ef.ciently.  A. C/C++11 implementation proofs Recall that the C/C++11 concurrency \nmodel [7, 10] has marked memory accesses of various kinds (only SC is important on TSO, the properties \nof the others are automatically satis.ed by normal reads and writes on TSO). We work with the formal \ndescription in Batty et al [6]. For a particular execution of a program, various relations among the \nactions corresponding to these operations are de.ned, including a happens-before relation; modi.cation \norder mo, a total order per atomic location on writes to that location; and SC order sc, a total order \non all SC atomic actions in the execution. There are several consistency conditions which these relations \nmust satisfy for the execution to be consistent (brie.y, both mo and sc must be consistent with happens-before; \nthe ithb part of happens\u00adbefore must be acyclic; certain shapes contradicting coherence must not occur \nwithin happens-before; and reads must read from a happens-before consistent write). Furthermore, if any \nconsistent execution in the sense above has a data race, then the program as a whole has no de.ned semantics. \nCorrect compilation to TSO depends (among other things) on mapping the atomic accesses to TSO hardware \nprimitives. Batty et al [6] prove correctness for a few variant mappings on X86-TSO; speci.cally, the \nread-write-mapping of Table 4(a) (from a prototype by Terekhov [27]), which maps SC-atomic-reads and \nSC-atomic-writes to X86-TSO RMWs. It is easy to adapt their proof and weaken the mapping, making only \nthe SC-atomic-reads RMW s as in Table 4(b): read-mapping, or only the SC-atomic\u00adwrites RMW s as in Table \n4(c): write-mapping. We now show that each mapping above would suf.ce for correctly implementing C/C++11 \nusing type-2 RMWs (and reprove for type-1), while for type-3 RMWs, the read-write mapping and the read-mapping \nwork. The write-mapping would not work for type-3 RMWs, by Dekker s counterexample in the paper (Fig. \n3). A.1 A generic outline of the proof strategy The proof is fairly standard, following the proofs in \n[5, 6]. In particular, the way of constructing SC orders is derived from the earlier paper. Mapping read-from \nmaps, and mo First, the events occurring in the hardware models are related to the C/C++ actions from \nthe cor\u00adresponding program. For everything except the C/C++11 SC atom\u00adics, this is straightforward, as \nordinary reads and writes correspond to C/C++11 reads and writes. For the SC actions, we assume that \nthere is a unique mapping that can be derived. Then the hardware rf relation corresponds to the reads-from \nmap of C/C++11, and the hardware ws relation (restricted to atomic locations) corresponds to mo of C/C++11. \nghb contains the C/C++11 ithb Here we notice that under any mapping (and any kind of RMW), each of the \ncomponents of C/C++11 inter-thread-happens-before are part of ghb, by the con\u00adstruction via release sequences. \nThus the ghb is a greater relation than the C/C++11 ithb. Constructing the C/C++11 SC order. This part \nof the proof cru\u00adcially depends on the mapping, so we will have to parametrize the proof by the mapping. \nWe consider, as in the proof of SC actions on Power [5], an arbitrary linearization of the union of posc, \nprogram\u00adorder on SC actions; wssc, ws restricted to SC actions; frsc,which relates SC reads to all SC \nwrites to the same location coherence\u00adafter the write the read reads from; and erfsc, which relates a \nSC read and the last SC write in coherence before the write, or that write if a SC write, that the read \nreads-from. We will then show that these relations are included in the ghb relation, and thus their \nunion is consistent with ghb. As a corollary, by the acyclicity of ghb, we get that the union is acyclic \nand thus can be extended to a linear SC order. C/C++11 concurrency. Assuming we can construct the SC \nor\u00adder as above, we are now in a position to verify the consistency in C/C++11 of all behaviors permitted \nby TSO (with the variant RMWs) for race-free C/C++11 programs: Acyclicity of ithb:First,the ithb is \ncontained within ghb,which is acyclic.  Consistency of happens-before and mo: Second, mo should be consistent \nwith C/C++ happens-before (which we get by ws be\u00ading included in ghb, and the uniproc condition).  Coherence \ndiagrams: Third, the coherence diagrams [6] CoRR, CoRW, CoWR, and CoWW, must not be contradicted by the \nhappens-before, which we get by the construction of ghb.  Consistency of SC order: Fourth, sc should \nbe consistent with happens-before and mo, which we get by our construction of sc.  Reads read from a \nconsistent write: Fifth, SC reads must read\u00adfrom a write not happens-after the sc-last SC write, which \nwe get by construction of sc. Other reads must read from a happens\u00adbefore consistent write, where we \nnote that all reads read from the last write to the same location in ghb. It is possible, however, that \nthere is no C/C++11 happens-before relating the read and write (hb is smaller than ghb). Then, we .nd \na race in the original C/C++ program, contradicting the race-free assumption.  Constructing a race: \nSuppose we have found a read and a write that it reads-from that are not C/C++11 happens-before related. \nWe .nd the minimal such pair in ghb (we know ghb is acyclic, so this is well-founded). Cut off the program \nwithout this read, and anything program-order after that write. Now we add back the read, but read from \na C/C++11 allowed write; and it races with the original write. We complete the program execution in any \nconsistent way, to get a racy consistent execution. Note that without speculative execution as in Power, \nthis proof is much simpler than the corresponding proof for Power [5].  A.2 Instantiating the generic \nproof Now we .ll in the pieces above for each atomicity de.nition and each mapping. The remaining obligation \nis .nding events in the TSO execution corresponding to the C/C++11 SC atomics, and proving that posc, \nwssc, frsc,and erfsc are contained within ghb. Read-write-mapping and read-mapping. For these mappings, \nwe consider the write Wa of the RMW for the SC read, and the write Table 4. Mapping from C/C++11 to \nX86 (a) read-write-mapping (b) read-mapping (c) write-mapping Operation x86 Impl. non-SC read mov SC \nread lock xadd(0) non-SC write mov SC write lock xchg  Operation x86 Impl. non-SC read mov SC read lock \nxadd(0) non-SC write mov SC write mov Operation x86 Impl. non-SC read mov SC read mov non-SC write mov \nSC write lock xchg (either by itself in the read-mapping, or from the RMW for the read-write-mapping) \nfor the SC write. Then poscis a part of ghb (they are same-thread writes). wsscis a part of ghb by de.nition \nof write-serialization. Every frscedge must be consistent with ghb, since the subsequent write cannot \nbe in ghb between Ra and Wa of the RMW, using any atomicity de.nition. Every erfscedge must be consistent \nwith ghb, since the write read-from must be coherence\u00adbefore the Wa of the SC read, and cannot come between \nRa and Wa in any atomicity de.nition. Write-mapping Here SC reads are mapped to plain reads, and thus \nthere is no write to use as above. Instead, we use the read as is for SC reads, and the read Ra of the \nRMW for the SC write. Using this mapping, poscis a part of ghb (they are same-thread reads). For write-serialization, \nwsscis a part of the ghb,since Ra of each write must be before that write in fr. Likewise, erfscis a \npart of ghb, but the proof has two cases. For same threads, Ra of the write is ghb-before the read (same-thread \nreads). For different threads, Ra from the write is ghb before Wa in fr,and Wa is before the SC read \nin rfe. The last piece required is frsc. The SC read is certainly before in fr Wa of the RMW, but we \nare now considering Ra as representing the SC action. For Type-1 and Type-2 RMWs, it is consistent to \nimpose that the SC read is before Ra, since they are to the same location, and no same-location actions \ncan be in ghb between Ra and Wa. Then we get the required result. For Type-3 RMWs, since a read can be \nin between Ra and Wa of a RMW, this strategy will not work. This is the point where the proof fails for \nType-3 RMWs.   Acknowledgements We would like to thank Peter Sewell and the anonymous reviewers for \ntheir helpful comments and advice for improving this paper. This work is supported by the Centre for \nNumerical Algorithms and Intelligent Software, funded by EPSRC grant EP/G036136/1 and the Scottish Funding \nCouncil to the University of Edinburgh. Susmit Sarkar was supported by EPSRC grant EP/H027351.  References \n[1] S.V.Adve. Designing memory consistency models for shared-memory multiprocessors. PhD thesis, Madison, \nWI, USA, 1993. UMI Order No. GAX94-07354. [2] J. Alglave. A Shared Memory Poetics. PhD thesis, 2010. \n[3] H. Attiya, R. Guerraoui, D. Hendler, P. Kuznetsov, M. M. Michael, and M. T. Vechev. Laws of order: \nexpensive synchronization in concurrent algorithms cannot be eliminated. In POPL, pages 487 498, 2011. \n[4] D. A. Bader and G. Cong. A fast, parallel spanning tree algorithm for symmetric multiprocessors (smps). \nJ. Parallel Distrib. Comput., 65(9):994 1006, 2005. [5] M. Batty, K. Memarian, S. Owens, S. Sarkar, and \nP. Sewell. Clarifying and compiling C/C++ concurrency: from C++11 to POWER. In Proc. POPL, 2012. [6] \nM. Batty, S. Owens, S. Sarkar, P. Sewell, and T. Weber. Mathematizing C++ concurrency. In POPL, pages \n55 66, 2011. [7] P. Becker, editor. Programming Languages C++. 2011. ISO/IEC 14882:2011. A non-.nal \nrecent version is available at http://www.open-std.org/jtc1/sc22/wg21/docs/papers/ 2011/n3242.pdf. [8] \nB. H. Bloom. Space/time trade-offs in hash coding with allowable errors. Commun. ACM, 13(7):422 426, \n1970. [9] C. Blundell, M. M. K. Martin, and T. F. Wenisch. Invisifence: performance-transparent memory \nordering in conventional multipro\u00adcessors. In ISCA, 2009. [10] Programming Languages C. 2011. ISO/IEC \n9899:2011. A non\u00ad.nal recent version is available at http://www.open-std.org/ jtc1/sc22/wg14/docs/n1539.pdf. \n[11] D. Dice, O. Shalev, and N. Shavit. Transactional locking ii. In DISC, pages 194 208, 2006. [12] \nK. Gharachorloo, S. Adve, A. Gupta, J. Hennessy, and M. Hill. Speci\u00adfying system requirements for memory \nconsistency models. Computer Systems Laboratory, Stanford University, 1993. [13] K. Gharachorloo, A. \nGupta, and J. L. Hennessy. Two techniques to enhance the performance of memory consistency models. In \nICPP (1), pages 355 364, 1991. [14] C. Gniady, B. Falsa., and T. N. Vijaykumar. Is sc + ilp=rc? In ISCA, \npages 162 171, 1999. [15] M. Herlihy. Wait-free synchronization. ACM Trans. Program. Lang. Syst., 13:124 \n149, January 1991. \u00ae 64 and IA-32 Architectures Software Devel\u00adoper s Manual. Number 253669-033US. December \n2009. [16] Intel Corporation. Intel R [17] E. Ladan-Mozes, I.-T. A. Lee, and D. Vyukov. Location-based \nmem\u00adory fences. In SPAA, pages 75 84, 2011. [18] C. Lin, V. Nagarajan, R. Gupta, and B. Rajaram. Ef.cient \nsequential consistency via con.ict ordering. In ASPLOS, pages 273 286, 2012. [19] I. B. Machine and A. \nC. I. Staff. PowerPC Microprocessor Common Hardware Reference Platform: A System Architecture.Morgan \nKauf\u00admann Publishers Inc., San Francisco, CA, USA, 1995. [20] M. Michael and M. Scott. Implementation \nof atomic primitives on distributed shared memory multiprocessors. In Proc. HPCA, 1995. [21] N. Muralimanohar \nand R. Balasubramonian. Cacti 6.0: A tool to understand large caches. [22] S. Owens, S. Sarkar, and P. \nSewell. A better x86 memory model: x86-TSO. In Proc. TPHOLs, 2009. [23] A. Singh, S. Narayanasamy, D. \nMarino, T. D. Millstein, and M. Musu\u00advathi. End-to-end sequential consistency. In ISCA, pages 524 535, \n2012. [24] D. J. Sorin, M. D. Hill, and D. A. Wood. APrimeronMemory Consistency and Cache Coherence. \nMorgan and ClayPool Publishers, 2011. [25] C. SPARC International, Inc. The SPARC architecture manual \n(ver\u00adsion 8). Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 1992. [26] C. SPARC International, Inc. \nThe SPARC architecture manual (ver\u00adsion 9). Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 1994. [27] \nA. Terekhov. Brief tentative example x86 implementa\u00adtion for C/C++ memory model. cpp-threads mailing \nlist, http://www.decadent.org.uk/pipermail/cpp-threads/ 2008-December/001933.html, Dec. 2008. [28] E. \nVallejo, R. Beivide, A. Cristal, T. Harris, F. Vallejo, O. Unsal, and M. Valero. Architectural support \nfor fair reader-writer locking. In Proc. MICRO, 2010.  \n\t\t\t", "proc_id": "2491956", "abstract": "<p>Read-Modify-Write (RMW) instructions are widely used as the building blocks of a variety of higher level synchronization constructs, including locks, barriers, and lock-free data structures. Unfortunately, they are expensive in architectures such as x86 and SPARC which enforce (variants of) Total-Store-Order (TSO). A key reason is that RMWs in these architectures are ordered like a memory barrier, incurring the cost of a write-buffer drain in the critical path. Such strong ordering semantics are dictated by the requirements of the strict atomicity definition (type-1) that existing TSO RMWs use. Programmers often do not need such strong semantics. Besides, weakening the atomicity definition of TSO RMWs, would also weaken their ordering -- thereby leading to more efficient hardware implementations.</p> <p>In this paper we argue for TSO RMWs to use weaker atomicity definitions -- we consider two weaker definitions: type-2 and type-3, with different relaxed ordering differences. We formally specify how such weaker RMWs would be ordered, and show that type-2 RMWs, in particular, can seamlessly replace existing type-1 RMWs in common synchronization idioms -- except in situations where a type-1 RMW is used as a memory barrier. Recent work has shown that the new C/C++11 concurrency model can be realized by generating conventional (type-1) RMWs for C/C++11 SC-atomic-writes and/or SC-atomic-reads. We formally prove that this is equally valid using the proposed type-2 RMWs; type-3 RMWs, on the other hand, could be used for SC-atomic-reads (and optionally SC-atomic-writes). We further propose efficient microarchitectural implementations for type-2 (type-3) RMWs -- simulation results show that our implementation reduces the cost of an RMW by up to 58.9% (64.3%), which translates into an overall performance improvement of up to 9.0% (9.2%) on a set of parallel programs, including those from the SPLASH-2, PARSEC, and STAMP benchmarks.</p>", "authors": [{"name": "Bharghava Rajaram", "author_profile_id": "81456638755", "affiliation": "University of Edinburgh, Edinburgh, United Kingdom", "person_id": "P4148939", "email_address": "r.bharghava@ed.ac.uk", "orcid_id": ""}, {"name": "Vijay Nagarajan", "author_profile_id": "81351609546", "affiliation": "University of Edinburgh, Edinburgh, United Kingdom", "person_id": "P4148940", "email_address": "vijay.nagarajan@ed.ac.uk", "orcid_id": ""}, {"name": "Susmit Sarkar", "author_profile_id": "81758894457", "affiliation": "University of St. Andrews, St. Andrews, United Kingdom", "person_id": "P4148941", "email_address": "ss265@st-andrews.ac.uk", "orcid_id": ""}, {"name": "Marco Elver", "author_profile_id": "81758839457", "affiliation": "University of Edinburgh, Edinburgh, United Kingdom", "person_id": "P4148942", "email_address": "marco.elver@ed.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462196", "year": "2013", "article_id": "2462196", "conference": "PLDI", "title": "Fast RMWs for TSO: semantics and implementation", "url": "http://dl.acm.org/citation.cfm?id=2462196"}