{"article_publication_date": "06-16-2013", "fulltext": "\n AutoSynch: An Automatic-Signal Monitor Based on Predicate Tagging Wei-Lun Hung Vijay K. Garg Department \nof Electrical and Computer Engineering The University of Texas at Austin wlhung@utexas.edu, garg@ece.utexas.edu \nAbstract Most programming languages use monitors with explicit signals for synchronization in shared-memory \nprograms. Requiring program\u00admers to signal threads explicitly results in many concurrency bugs due to \nmissed noti.cations, or noti.cations on wrong condition variables. In this paper, we describe an implementation \nof an au\u00adtomatic signaling monitor in Java called AutoSynch that eliminates such concurrency bugs by \nremoving the burden of signaling from the programmer. We show that the belief that automatic signaling \nmonitors are prohibitively expensive is wrong. For most problems, programs based on AutoSynch are almost \nas fast as those based on explicit signaling. For some, AutoSynch is even faster than explicit signaling \nbecause it never uses signalAll, whereas the programmers end up using signalAll with the explicit signal \nmechanism. AutoSynch achieves ef.ciency in synchronization based on three novel ideas. We introduce an \noperation called closure that enables the predicate evaluation in every thread, thereby reducing con\u00adtext \nswitches during the execution of the program. Secondly, Au\u00adtoSynch avoids signalAll by using a property \ncalled relay invari\u00adance that guarantees that whenever possible there is always at least one thread whose \ncondition is true which has been signaled. Finally, AutoSynch uses a technique called predicate tagging \nto ef.ciently determine a thread that should be signaled. To evaluate the ef.\u00adciency of AutoSynch, we \nhave implemented many different well\u00adknown synchronization problems such as the producers/consumers problem, \nthe readers/writers problems, and the dining philosophers problem. The results show that AutoSynch is \nalmost as ef.cient as the explicit-signal monitor and even more ef.cient for some cases. Categories and \nSubject Descriptors D.1.3 [Concurrent Pro\u00adgramming]: Parallel programming; D.3.3 [Language Constructs \nand Features]: Concurrent programming structures; classes and objects; control structures General Terms \nAlgorithms, Languages, Performance Keywords automatic signal, explicit signal, implicit signal, mon\u00aditor, \nconcurrency, parallel Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 13, June 16 19, 2013, Seattle, WA, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. \n. . $15.00 1. Introduction Multicore hardware is now ubiquitous. Programming these multi\u00adcore processors \nis still a challenging task due to bugs resulting from concurrency and synchronization. Although there \nis widespread acknowledgement of dif.culties in programming these systems, it is surprising that by and \nlarge the most prevalent methods of dealing with synchronization are based on ideas that were devel\u00adoped \nin early 70 s [2, 9, 14]. For example, the most widely used threads package in C++ [19], pthreads [6], \nand the most widely used threads package in Java [11], java.util.concurrent [18], are based on the notion \nof monitors [2, 14](or semaphores [8, 9]). In this paper, we propose a new approach, AutoSynch, based \non au\u00adtomatic signaling monitor that allows gains in productivity of the programmer as well as gain in \nperformance of the system. Both pthreads and Java require programmers to explicitly signal threads that \nmay be waiting on certain condition. The programmer has to explicitly declare condition variables and \nthen signal one or all of the threads when the associated condition becomes true. Us\u00ading the wrong waiting \nnoti.cation (signal versus signalAll or notify versus notifyAll) is a frequent source of bugs in Java \nmultithreaded programs. In our proposed approach, AutoSynch, there is no no\u00adtion of explicit condition \nvariables and it is the responsibility of the system to signal appropriate threads. This feature signi.cantly \nre\u00adduces the program size and complexity. In addition, it allows us to completely eliminate signaling \nmore than one thread resulting in reduced context switches and better performance. The idea of auto\u00admatic \nsignaling was initially explored by Hoare in [14], but rejected in favor of condition variables due to \nef.ciency considerations. The belief that automatic signaling is extremely inef.cient compared to explicit \nsignaling is widely held since then and all the prevalent concurrent languages based on monitors use \nexplicit signaling. For example, Buhr, Fortier, and Cof.n claim that automatic monitors are 10 to 50 \ntimes slower than explicit signals [4]. We show in this paper that the widely held belief is wrong. The \nreason for this dras\u00adtic slowdown in previous implementations of automatic monitor is that they evaluate \nall possible conditions on which threads are wait\u00ading whenever the monitor becomes available. With careful \nanalysis of the conditions on which the threads are waiting and evaluating as few conditions as possible, \nautomatic signaling can be as ef.\u00adcient as explicit signaling. In AutoSynch, the programmer simply speci.es \nthe predicate P on which the thread is waiting by using the construct waituntil(P) statement. When a \nthread executes the waituntil statement, it checks whether P is true. If it is true, the thread can continue; \notherwise, the thread must wait for the system to signal it. The AutoSynch system has a condition manager \nthat is responsible for determining which thread to signal by analyzing the predicates and the state \nof the shared object.  Fig. 1 shows the difference between the Java and the AutoSynch implementation \nfor the parameterized bounded-buffer problem, a variant bounded-buffer problem (also known as the producer\u00adconsumer \nproblem) [8, 10]. In this problem, producers put items into a shared buffer, while consumers take items \nout of the buffer. The put function has a parameter items;the take function has a parameter, num, indicating \nthe number of items taken. There are two requirements for synchronization. First, every operation on \na shared variable, such as buff, should be done under mutual exclusion. Second, we need conditional synchronization; \na pro\u00adducer must wait when the buffer does not have suf.cient space, and a consumer must wait when the \nbuffer has no suf.cient items. The explicit-signal bounded-buffer is written in Java. Programmers need \nto explicitly associate conditional predicates with condition variables and call signal (signalAll)or \nawait statement manually. Note that, the unlock statement should be done in a .nally block, try and catch \nblocks are also need for the InterruptedException that may be thrown by await. However, for simplicity, \nwe avoid the ex\u00adception handling in Fig. 1. The automatic-signal bounded-buffer is written using AutoSynch \nframework. We use AutoSynch modi.er to indicate that the class is a monitor as in line 1. An AutoSynch \nclass provides mutually exclusive access to its member functions. For conditional synchronization, we \nuse waituntil as in line 9. There are no signal or signalAll calls in the AutoSynch program. Note that, \nthe waituntil statement can take any boolean condition just like the if and while statements. Clearly, \nthe automatic-signal mon\u00aditor is much simpler than the explicit-signal monitor. Figure 2: The framework \nof AutoSynch The framework for the implementation is shown if Fig. 2. It is composed of a preprocessor \nand a Java condition manager library. The preprocessor translates AutoSynch code into traditional Java \ncode. Our automatic-signal mechanism and developed techniques were implemented in the Java condition \nmanager library, which is responsible for monitoring the state of the monitor object and signaling an \nappropriate thread. In this paper, we argue that automatic signaling is generally as fast as explicit \nsignaling (and even faster for some examples). The explicit signaling has to resort to signalAll in some \nexamples; how\u00adever, our automatic signaling never uses signalAll. Thus AutoSynch is considerably faster \nfor synchronization problems that requires signalAll. The design principle underlying AutoSynch is to \nreduce the number of context switches and predicate evaluations. Context switch: A context switch requires \na certain amount of time to save and load registers and update various tables and lists. Reducing unnecessary \ncontext switches boosts the perfor\u00admance of the system. A signalAll call introduces unnecessary context \nswitches; therefore, signalAll calls are never used in Au\u00adtoSynch. Predicate evaluation: In the automatic-signal \nmechanism, signal\u00ading a thread is the responsibility of the system. The number of predicate evaluations \nis crucial for ef.ciency in deciding which thread should be signaled. By analyzing the structure of the \npredicate, our system reduces the number of predicate evalu\u00adations. There are three important novel concepts \nin AutoSynch that enable ef.cient automatic signaling closure of predicates, relay invariance,and predicate \ntagging. The technique of closure of a predicate P is used to reduce the number of context switches for \nits evaluation. In the current sys\u00adtems, only the thread that is waiting for the predicate P can evalu\u00adate \nit. When the thread is signaled, it wakes up, acquires the lock to the monitor and then evaluates the \npredicate P . If the predicate P is false, it goes back to wait resulting in an additional context switch. \nIn AutoSynch system, the thread that is in the monitor evaluates the condition for the waiting thread \nand wakes it only if the condition is true. Since the predicate P may use variables local to the thread \nwaiting on it, AutoSynch system derives a closure predicate P . of the predicate P , such that other \nthreads can evaluate P .. The details of closure are in Section 3.1. Theideaof relay invariance is used \nto avoid signalAll calls in AutoSynch. The relay invariance ensures that if there is any thread whose \nwaiting condition is true, then there exists at least one thread whose waiting condition is true and \nis signaled by the system. With this invariance, the signalAll call is unnecessary in our automatic\u00adsignal \nmechanism. This mechanism reduces the number of context switches by avoiding signalAll calls. The details \nof this approach are in Section 3.2. Theideaof predicate tagging is used to accelerate the process of \ndeciding which thread to signal. All the waiting conditions are analyzed and tags are assigned to every \npredicate according to its semantics. To decide which thread should be signaled, we identify tags that \nare most likely to be true after examining the current state of the monitor. Then we only evaluate the \npredicates with those tags. The details of predicate tagging are in Section 3.3. Our experimental results \nindicate that AutoSynch can signi.\u00adcantly improve performance compared to other automatic-signal mechanisms \n[5]. In [4, 5] the automatic-signal mechanism is 10\u00ad50 times slower than the explicit-signal mechanism; \nhowever, Au\u00adtoSynch is only 2.6 times slower than the explicit-signal mechanism even in the worst case \nof our experiment results. Furthermore, Au\u00adtoSynch is 26.9 times faster than the explicit-signal mechanism \nin the parameterized bounded-buffer problem that relies on signalAll calls. Besides, the experimental \nresults also show that AutoSynch is scalable; the performance of AutoSynch scales well even if the number \nof threads increases for many problems studied in the pa\u00adper. Although the experiment results show that \nAutoSynch is 2.6 times slower than the explicit-signal mechanism in the worst case, it is still desirable \nto have automatic signaling. First, automatic sig\u00adnaling simpli.es the task of concurrent programming. \nIn explicit\u00adsignal monitor, it is the responsibility of programmers to explicitly invoke a signal call \non some condition variable for conditional syn\u00adchronization. Using the wrong noti.cation, and signaling \na wrong condition variable are frequent sources of bugs. The idea is analo\u00adgous to automatic garbage \ncollection. Although garbage collection leads to decreased performance because of the overhead in deciding \nwhich memory to free, programmers avoid manual memory deal\u00adlocation. As a consequence, memory leaks and \ncertain bugs, such as dangling pointers and double free bugs, are reduced. Similarly, automatic-signal \nmechanism consumes computing resources in de\u00adciding which thread to be signaled; programmers avoid explicitly \ninvoking signal calls. As a result, some bugs, such as using wrong noti.cation and signaling a wrong \ncondition variable, are elimi\u00adnated. Secondly, in explicit-signal monitor, the principle of sepa\u00adration \nof concerns is violated. Any method that changes the state of the monitor must be aware of all the conditions, \nwhich other threads could be waiting for, in other methods of the monitor. The intricate relation between \nthreads for conditional synchronization breaks the modularity and encapsulation of programming. Finally, \n Explicit-Signal 1 class BoundedBuffer { 2 Object[] buff; 3 int putPtr, takePtr, count; 4 Lock mutex \n= new ReentrantLock(); 5 Condition insufficientSpace = mutex.newCondition(); 6 Condition insufficientItem \n= mutex.newCondition(); 7 public BoundedBuffer(int n) { 8 buff = new Object[n]; 9 putPtr = takePtr = \ncount = 0; 10 } 11 public void put(Object[] items) { 12 mutex.lock(); 13 while (items.length + count \n> buff.length) { 14 insufficientSpace.await(); 15 } 16 for (int i = 0; i < items.length; i++) { 17 buff[putPtr++] \n= items[i]; 18 putPtr %= buff.length; 19 } 20 count += items.length; 21 insufficientItem.signalAll(); \n22 mutex.unlock(); 23 } 24 public Object[] take(int num) { 25 mutex.lock(); 26 while (count < num) { \n27 insufficientItem.await(); 28 } 29 Object[] ret = new Object[num]; 30 for (int i = 0; i < num; i++) \n{ 31 ret[i] = buff[takePtr++]; 32 takePtr %= buff.length; 33 } 34 count -= num; 35 insufficientSpace.signalAll(); \n36 mutex.unlock(); 37 return ret; 38 } 39 } Automatic-Signal 1 AutoSynch class BoundedBuffer { 2 Object[] \nbuff; 3 int putPtr, takePtr, count; 4 public BoundedBuffer(int n) { 5 buff = new Object[n]; 6 putPtr \n= takePtr = count = 0; 7 } 8 public void put(Object[] items) { 9 waituntil(count + items.length <= buff.length); \n 10 for (int i = 0; i < items.length; i++) { 11 buff[putPtr++] = items[i]; 12 putPtr %= buff.length; \n13 } 14 count += items.length; 15 } 16 public Object[] take(int num) { 17 waituntil(count >= num); 18 \nObject[] ret = new Object[num]; 19 for (int i = 0; i < num; i++) { 20 ret[i] = buff[takePtr++]; 21 takePtr \n%= buff.length; 22 } 23 count -= num; 24 return ret; 25 } 26 } Figure 1: The parameterized bounded-buffer \nexample AutoSynch can provide rapid prototyping in developing programs and accelerating product time \nto market. Although this paper focuses on Java, our techniques are also applicable to other programming \nlanguages and models, such as pthread and C# [13]. This paper is organized as follows. Section 2 gives \nthe back\u00adground of the monitor and explains why signalAll is required for explicit-signal monitor but \nnot automatic-signal monitor. The con\u00adcepts of AutoSynch are presented in Section 3 and the practical \nimplementation details are discussed in Section 4. The proposed methods are then evaluated with experiments \nin Section 5. Section 6 gives the concluding remarks. 2. Background: monitor According to Buhr and Harji \n[5], monitors can be divided into two categories according to the different implementations of con\u00additional \nsynchronization. Explicit-signal monitor In this type of monitor, condition vari\u00adables, signal and await \nstatements are used for synchronization. Programmers need to associate assertions with condition vari\u00adables \nmanually. A thread waits on some condition variable if its predicate is not true. When another thread \ndetects that the state has changed and the predicate is true, it explicitly signals the appropriate condition \nvariable. Automatic-signal (implicit-signal) monitor This kind of moni\u00adtor uses waituntil statements, \nsuch as line 9 in automatic-signal program in Fig. 1, instead of condition variables for synchro\u00adnization. \nProgrammers do not need to associate assertions with variables, but use waituntil statements directly. \nIn monitor, a thread will wait as long as the condition of a waituntil statement is false, and execute \nthe remaining tasks only after the condition becomes true. The responsibility of signaling a waiting \nthread is that of the system rather than of the programmers. We note that the signalAll call is essential \nin explicit-signal mechanism when programmers do not know which thread should be signaled. In Fig. 1, \na producer must wait if there is no space to put num items, while a consumer has to wait when the buffer \nhas insuf.cient items. Since producers and consumers can put and take different numbers of items every \ntime, they may wait on different conditions to be met. Programmers do not know which producer or consumer \nshould be signaled at runtime. Therefore, the signalAll call is used instead of signal calls in line \n21 and 35. Although programmers can avoid using signalAll calls by writing complicated code that associates \ndifferent conditions to different condition variables; the complicated code makes the maintenance of \nthe program hard. The signalAll call is expensive; it generally decreases the perfor\u00admance because it \nintroduces redundant context switches, requiring computing time to save and load registers and update \nvarious tables and lists. Furthermore, signalAll calls cannot increase parallelism because threads are \nforbidden to access a monitor simultaneously. Although multiple threads are signaled at a time, only \none thread is able to acquire the monitor. Other threads may need to go back to waiting state since another \nthread may change the status of the monitor.  3. AutoSynch concepts 3.1 Predicate evaluation In AutoSynch, \nit is the responsibility of the system to signal appro\u00adpriate threads automatically. The predicate evaluation \nis crucial in deciding which thread should be signaled. We discuss how to pre\u00adform predicate evaluations \nof waituntil statements. A predicate P (xx): X . B is a Boolean condition, where X is the space spanned \nby the variables xx =(x1,...,xn).A variable of a monitor object is a shared variable if it is accessible \nby every thread that is accessing the monitor. The set of shared variables is denoted by S. The set of \nlocal variables, denoted by L, is accessible only by a thread calling a function in which the variables \nare declared. Predicates can be used to describe the properties of conditions. In our approach, every \ncondition of waituntil statement is repre\u00adsented by a predicate. We say a condition has been met if its \nrep\u00adresenting predicate is true; otherwise, the predicate is false. Fur\u00adthermore, we assume that every \npredicate, P = i=1ci,isin .n disjunctive normal form (DNF), where ci is de.ned as the con\u00adjunction of \na set of atomic Boolean expressions. For example, a predicate (x =1) . (y =6) . (z=8) is in DNF, where \nc1 =(x =1) . (y =6) and c2 =(z=8). Note that, every Boolean formula can be converted into DNF using De \nMorgan s laws and distributive law. Predicates can be divided into two categories based on the type of \ntheir variables [5]. De.nition 1 (Shared and complex predicate). Consider a predicate P (xx): X . B.If \nX . S, P is a shared predicate. Otherwise, it is a complex predicate. The automatic-signal monitor has \nan ef.cient implementation [16] by limiting the predicate of a waituntil to a shared predicate; however, \nwe do not limit the predicate of a waituntil statement to a shared predicate. The reason is that this \nlimitation will lead Au\u00adtoSynch to be less attractive and practical since conditions including local \nvariables cannot be represented in AutoSynch. Evaluating a complex predicate in all the threads is unattainable \nbecause the accessibility of the local variables in the predicate is limited to the thread declaring \nthem. To evaluate a complex predicate in all the threads, we treat local variables as constant values \nat runtime and de.ne closure as follows. De.nition 2 (Closure). Given a complex predicate P (xx, xa): \nX \u00d7 A . B,where X . S and A . L. The closure of P at runtime t is the new shared predicate Gt(xx)= P \n(xx, xat), where axt is the values of xa at runtime t. The closure can be applied to any complex predicate; \na shared predicate can be derived from the closure. For example, in Fig. 1, the consumer C wants to take \n48 items at some instant of time. Applying the closure to the complex predicate (count = num) in line \n19, we derive the shared predicate (count = 48). The following proposition shows that the complex predicate \nevaluation of waituntil statement in all threads can be achieved through the closure. Proposition 1. \nConsider a complex predicate P (xx, xa) in a wait\u00aduntil statement. P (xx, xa) and its closure P (xx, \nxat) are semantically equivalent during the waituntil period, where t is the time instant immediately \nbefore invoking the waituntil statement. Proof. Only the thread invoking the waituntil statement can \naccess the local variables of the predicate; all other threads are unable to change the values of those \nlocal variables. Therefore, the value of xa cannot be changed during the waituntil period. Since axt \nis the value of xa immediately before invoking the waituntil statement, P (xx, xa) and P (xx, xat) are \nsemantic equivalent during the waituntil period. Proposition 1 enables the complex predicate evaluation \nof wait\u00aduntil statement in all threads. Given a complex predicate in a wait\u00aduntil statement, in the sequel \nwe substitute all the local variables with their values immediately before invoking the statement. The \npredicate can now be evaluated in all other threads during the wait\u00aduntil period.  3.2 Relay invariance \nAs mentioned in Section 2, signalAll calls are sometimes unavoid\u00adable in the explicit-signal mechanism. \nIn AutoSynch, signalAll calls are avoided by providing the relay invariance. De.nition 3 (Active and \ninactive thread). Consider a thread that tries to access a monitor. If it is not waiting in a waituntil \nstatement or has been signaled, then it is an active thread for the monitor. Otherwise, it is an inactive \nthread. De.nition 4 (Relay invariance). If there is a thread waiting for a predicate that is true, then \nthere is at least one active thread; i.e., suppose WT is the set of waiting threads whose conditions \nhave become true, AT is the set of active threads, then WT= f . AT = f holds at all time. AutoSynch uses \nthe following mechanism for signaling. Relay signaling rule: When a thread exits a monitor or goes into \nwaiting state, it checks whether there is some thread waiting on a condition that has become true. If \nat least one such waiting thread exists, it signals that thread. Proposition 2. The relay signaling rule \nguarantees relay invari\u00adance. Proof. Suppose a thread T is waiting on the predicate P that is true. Since \nT is waiting on P , P must be false before T went to waiting state. There must exist another active thread \nR after T such that R changed the state of the monitor and made P true. According to the rule, R must \nsignal T or another thread waiting for a condition that is true before leaving the monitor or going into \nwaiting state. The thread signaled by R then becomes active. Therefore, the relay invariance holds. Our \nframework guarantees progress by providing relay invari\u00adance. The concept behind relay invariance is \nthat, the privilege to enter the monitor is transmitted from one thread to another thread whose condition \nhas become true. For example, in Fig. 1, the consumer C tries to take 32 items; however, only 24 items \nare in the buffer at this moment. Then, C waits for the predicate P :(count = 32) to be true. A producer, \nD, becomes active after C; D puts 16 items into the buffer and then leaves the monitor. Be\u00adfore leaving, \nD .nds that P is true and then signals C; therefore, C becomes active again and takes 32 items of the \nbuffer. Proposition 2 shows that the relay invariance holds in our automatic-signaling mechanism. Thus, \nsignalAll calls are avoidable in AutoSynch.Note that, although at most one thread is signaled at any \ntime; the sig\u00adnaled thread is not guaranteed to get the lock. Some other thread trying to acquire the \nlock could also get the lock. The signaled thread may need to go back as a waiting thread, since the \nstate of the monitor may be changed. However, this situation is very rare in comparison with the signalAll \ncall. The problem is now reduced to .nding a thread waiting for a condition that is true.  3.3 Predicate \ntag In order to ef.ciently .nd an appropriate thread waiting for a predicate that is true, we analyze \nevery waiting condition and assign different tags to every predicate according to its semantics. These \ntags help us prune predicates that are not true by examining the state of the monitor. The idea behind \nthe predicate tag is that, local variables cannot be changed during the waituntil period; thus the values \nof local variables are used as keys when we evaluate predicates. First, we de.ne two types of predicates \naccording to their semantics. De.nition 5 (Local and shared expression). Consider an expres\u00adsion E(x \n): X . D,where D represents one of the primitive data types in Java. If X . L,then E is a local expression. \nOtherwise, if X . S, E is a shared expression. We use SE to denote a shared expression, and LE to denote \na local expression. De.nition 6 (Equivalence predicate). Apredicate P :(SE = LE) is an equivalence predicate. \nDe.nition 7 (Threshold predicate). Apredicate P :(SE op LE) is a threshold predicate, where op .{<, =,>, \n=}. Note that, many predicates that are not equivalence or threshold predicates can be transformed into \nthem. Consider the predicate (x - a = y + b),where x, y . S and a, b . L. This predicate is equivalent \nto (x - y = a + b) which is an equivalence predicate. Thus, these two types of predicates can represent \na wide range of conditions in synchronization problems. Given an Equivalence or a Threshold predicate, \nwe can ap\u00adply the closure operation to derive a constant value on the right hand side of the predicate. \nIn AutoSynch, there are three types of tags, Equivalence, T hreshold,and None.Every Equivalence or T \nhreshold tag represents an equivalence predicate or a thresh\u00adold predicate, respectively. If the predicate \nis neither equivalence nor threshold, it acquires the None tag. For example, consider the T hreshold \npredicate x + b> 2y + a where a and b are lo\u00adcal variables with values 11 and 2.We.rstusetheclosureto \nconvert it to (x - 2y> 9), which is represented by the tag (T hreshold, x - 2y, 9,>). The formal de.nition \nof tag is as follows. De.nition 8. A tag is a four-tuple (M, expr, key, op),where M .{Equivalence, T \nhreshold, None};  expr is a shared expression if M .{Equivalence, T hreshold}; otherwise, expr =.; \n key is the value of a local expression after applying closure if  M .{Equivalence, T hreshold}; otherwise, \nkey =.; op .{<, =,>, =} if M = T hreshold; otherwise, op =.. We say that a tag is true (false) if the \npredicate representing the tag is true (false). 3.3.1 Predicate tagging Tags are given to every predicate \nby the algorithm shown in Fig. 3. A tag is assigned to every conjunction. The tags of conjunctions of \na predicate constitute the set of tags of the predicate. When assigning a tag to a conjunction, the equivalence \ntag has the highest priority because the set of values that make an equivalence predicate true is smaller \nthan the set of values that make a threshold predicate true. For example, the equivalence predicate x \n=8 is true only when the value of x is 8, whereas the threshold predicate x> 3 is true for a much larger \nset of values. Therefore, the Equivalence tags can help us prune predicates that are false more ef.ciently \nthan other kinds of tags. If a conjunction does not include any equivalence predicate, then we check \nwhether it includes any threshold predi\u00adcate. If yes, then a T hreshold tag is assigned to the conjunction; \notherwise, the conjunction has a None tag. tags = empty foreach conjunction c if c contains an equivalence \npredicate se=le tag t = (Equivalence, se, closure(le), null) else if c contains a threshold predicate \nse op le tag t = (Threshold, se, closure(le), op) else tag t = (None, null, null, null) add t to tags \nreturn tags Figure 3: Predicate Tagging Creating all tags for a conjunction is unnecessary. If a conjunc\u00adtion \nincludes multiple equivalence predicates or threshold predi\u00adcates, only one arbitrary Equivalence tag \nor T hreshold tag is assigned to the conjunction. If there are a large number of tags, then the performance \nmay decrease because of the cost of main\u00adtaining tags. Assigning multiple tags to a conjunction cannot \naccel\u00aderate the searching process. For example, consider a conjunction (x =8) . (y =9). If only a tag \n(Equivalence, x, 8,null) is assigned to the conjunction, we check the predicate when the tag is true. \nAdding another tag (Equivalence, y, 9,null) can\u00adnot accelerate the searching process since we need to \ncheck both the tags. Note that multiple predicates with a shared conjunct may share a tag. For example, \nthe predicates (x =5) . (z = 4) and (x =5).(y = 4) would have a shared equivalence tag of (x =5). As \nanother example, consider the predicate p =((x< 5) . (y =3)) . ((x> 5) . (foo2())) . foo1(),where x and \ny are shared variables, and, foo1() and foo2() are boolean functions. The predicate p has three tags, \n(Equivalence, y, 3,null) for the clause (x< 5) . (y =3), (T hreshold, x, 5,>) for the clause (x> 5) . \n(foo2()),and None tag for foo1().  3.3.2 Tag signaling Signaling mechanism is based on tags in AutoSynch. \nSince the equivalence tag is more ef.cient in pruning the search space than the threshold tag, the predicates \nwith equivalence are checked prior to the predicates with other tags. If no true predicate is found after \nchecking Equivalence tags and Threshold tags, our algorithm does the exhaustive search for the predicates \nwith a None tag. Equivalence tag signaling: Observe that, an equivalence predi\u00adcate becomes true only \nwhen its shared expression equals the spe\u00adci.c value of its local expression after applying closure. \nFor distinct equivalence tags related to the same shared expression, at most one tag can be true at a \ntime because the value of its local expression is deterministic and unique at any time. By observing \nthe value of its local expression, the appropriate tag can be identi.ed. For exam\u00adple, suppose there \nare three Equivalence tags for predicates x =3, x =6,and x =8. We examine x and .nd that its value is \n8.Then we know that only the third predicate x =8 is true. Based on this observation, for each unique \nshared expression of an equivalence tag, we create a hash table, where the value of the local expres\u00adsion \nis used as the key. By using this hash table and evaluating the shared expression at runtime, we can \n.nd a tag that is true in O(1) time if there is any. Then we check the predicates having the tag.  Threshold \ntag signaling: Threshold tag signaling exploits mono\u00adtonicity of the predicate to reduce the complexity \nof evaluating predicates. For example, suppose there are two predicates, x> 5 and x> 3. We know that \nif x> 3 is false, then x> 5 can\u00adnot be true. Hence, we only need to check the predicate with the smallest \nlocal expression value for > and = operations. Similarly, the predicate x> 3 cannot be true when x = \n3 is false; i.e., we only need to check the predicate x = 3. We use a min-heap data structure for storing \nthe threshold tags related to a same shared ex\u00adpression with op .{>, =}. If two predicates have the same \nlocal expression value but different operations, then the predicate with = is considered to have a smaller \nvalue than the predicate with > in the min-heap. Dually, the max-heap is used for threshold tags with \nop .{<, =}. The signaling mechanism for T hreshold tag is shown if Fig. 4. In general, the tag in the \nroot of a heap is checked. If the tag is false, all the descendant nodes are also false. Otherwise, all \npredicates having the tag need to be checked for .nding a true predicate. To maintain the correctness, \nif no predicate is true, the tag is removed from the heap temporarily. Then the tag in the position of \nthe new heap root is checked again until a true predicate is found or a false tag is found. Those tags \nremoved temporarily are reinserted in the heap. The reason to remove the tags is that the descendants \nof the tags may also be true since the tags are true. So we also need to check the descendant tags. For \nexample, consider the predicates P1 :(x = 5) . (y =1) and P2 :(x> 7). P1 has the tag Q1 :(T hreshold, \nx, 5, =) and P2 has the tag Q2 :(T hreshold, x, 7,>). Q1 is the root and Q2 is its descendant. Suppose \nat some time instant x =3,then Q1 is false; thus, there is no need to check Q2. Now, suppose x =9 and \ny =1, then Q1 is true. We check all predicates that have tag Q1.Since P1 is false, no predicate having \ntag Q1 is true. Then Q1 is removed form the heap temporarily. We .nd the new root Q2 is true and P2 that \nhas tag Q2 is also true. We signal a thread waiting for P2 and then add Q1 back to the heap. list backup \n= empty; tag t = heap.peek(); //retrieve but not remove the root while t is true foreach predicate p \nwith t if p is true signal a thread waiting on p foreach b in backup heap.add(b) return backup.insert(heap.poll()) \n//retrieve and remove the root t = heap.peek() foreach b in backup heap.add(b) Figure 4: Threshold tag \nsignaling Suppose there are n T hreshold tags for a shared expression with different keys, and these \ntags are assigned to m predicates. The time complexity for maintaining the heap is O(n log(n)) However, \nthe performance is generally much better because we only need to check the predicates of the tags in \nthe root position in the most cases. The time complexity for .nding the root is O(1).Inthe worst case, \nwe need to check all predicates; thus, the time complexity is O(n log(n)+ m). However, this situation \nis rare. Furthermore, this algorithm is optimized for evaluating threshold predicates by sacri.cing performance \nin tag management. 4. AutoSynch implementation The AutoSynch implementation involves two parts, the preproces\u00adsor \nand the Java library of condition manager. The preprocessor, built using JavaCC [17], translates AutoSynch \ncode to Java code. Our signal-mechanism is implemented in the condition manager li\u00adbrary that creates \ncondition variables, and maintains the association between predicates and condition variables. Furthermore, \npredicate tags are also maintained by the condition manager. It is the respon\u00adsibility of the condition \nmanager to decide which thread should be signaled. 4.1 Preprocessor The AutoSynch class provides both \nmutual exclusion and condi\u00adtional synchronization. To maintain these two properties, our pre\u00adprocessor \nadds some additional variables for any AutoSynch class. Fig. 5 summarizes the de.nitions of additional \nvariables in the con\u00adstructor of an AutoSynch class. The lock variable, mutex,isde\u00adclared for mutual \nexclusion, which is acquired at the beginning of every member function and released before the return \nstatement. In addition, a condition manager, condM gr, is declared for synchro\u00adnization. The details \nof the condition manager are discussed in the next section. Lock mutex ConditionManager condMgr foreach \nshared predicate P tags = AnalyzePredicate(toDNF(P)) condMgr.registerSharedPredicate(P, tags) foreach \nshared expression E condMgr.registerSharedExpression(E) Figure 5: The additional variables for an AutoSynch \nclass All predicates are transformed to DNF in the preprocessing pro\u00adcess by De Morgan s laws and distributive \nlaw. Then predicates are analyzed to derive tags by our preprocessor. The shared predicates and shared \nexpressions are identi.ed in the preprocessing stage and registered to the condition manager in the constructor \nof the class for predicate evaluation at runtime as in Fig. 5. Shared predicates and shared expressions \n(but not complex predicates) are registered in the construct because their semantics is static and never \nchanges. A complex predicate is registered dynamically because its closure may change according to the \nvalue of its local variables at runtime. In Java, the predicates and shared expressions are created as \ninner classes that can access the shared variables appearing in them with isT rue() or getV alue() functions \nfor the condition manager to evaluate. The function isT rue() returns the evaluation of a pred\u00adicate \nand the function getV alue() returns the value of a shared expression. For every member function of an \nAutoSynch class, the mu\u00adtex.lock() and mutex.unlock() are inserted at the beginning of the function and \nimmediately before the return statement, respectively. In the waituntil statement, the predicate is checked \ninitially at runtime. If it is true, then the thread can continue. Otherwise, the type of predicate is \nchecked. If the predicate is complex, then closure is applied to it for deriving a new shared predicate. \nThen the condition manager is queried to determine whether the derived predicate has been registered \nearlier. If not, the condition manager registers the predicate with its tags. The corresponding condition \nvariable can be obtained by calling getCondition() function of the condition manager. The relaySignal() \nfunction is called to maintain relay invariance and signal an appropriate thread. Then, the thread goes \ninto the waiting state until its predicate becomes true and some other thread signals it. After exiting \nthe waiting state, if the predicate is complex and the corresponding condition has no other waiting thread, \nthe predicate is deactivated by the condition manager.  if P is false if P is a complex predicate P \n:= Closure(toDNF(P)) if P is not in condMgr tags = AnalyzePredicate(P) condMgr.registerComplexPredicate(P, \ntags) C = condMgr.getCondition(P) do condMgr.relaySignal() wait C while P is false if P is complex predicate \nand C has no waiting thread condMgr.deactivate(P) Figure 6: Preprocessing for a waituntil(P) statement \n 4.2 AutoSynch Java library: condition manager The condition manager maintains the predicates and condition \nvari\u00adables, and provides the signaling mechanism. To avoid creating re\u00addundant predicates and condition \nvariables, predicates that have the same meaning should be mapped to the same condition variable. Two \npredicates are syntax equivalent if they are identical after ap\u00adplying closure. A predicate table, which \nis implemented by using a hash table, records predicates and their associated condition vari\u00adables. When \na predicate is added to the condition manager, its tags are stored in an appropriate data structure depending \nupon the type of its tag. Fig. 7 shows an example. The symbol indicates a condition variable. The gray \nblank indicates that the predicate is deactivated, that is, no thread waits on it. A hash table is used \nfor storing equivalence tags with the shared expression x. In addition, a min-heap and a max-heap are \nused for storing threshold tags. For .nding a predicate that is true in Fig. 7, the value of the shared \nexpression x is evaluated. The hash table of the equivalence tag is checked (with O(1) time complexity) \nusing the value of the shared expression as the key. If a tag is found, then the predicates that have \nthe tag are evaluated. If there exists a predicate that is true, then its corresponding condition variable \nis signaled. Otherwise, the max-heap and the min-heap of the threshold tag are checked. If both tags \nof their roots are false, the predicates with the None tag are searched exhaustively. If one of these \npredicates is true, its cor\u00adresponding condition variable is signaled. As can be expected, the equivalence \nand threshold tags are helpful for searching predicates that are true. A predicate must be removed from \nthe predicate table once it has become deactivated to avoid unnecessary predicate evaluation. A threshold \ntag also needs to be removed once all of its predicates have become deactivated. Predicates may be reused. \nInstead of removing deactivated pred\u00adicates, those predicates are moved to a deactivated list. If they \nare used later, then we remove them from the deactivated list and add them back to the predicate table \nand its tags. Otherwise, when the length of the deactivated list exceeds some prede.ned threshold, we \nremove the oldest predicates from the list. Note that, the shared predicates are never removed since \nthey are static and are added only at the constructor level. 5. Evaluation We present the experimental \nsetup and its results to evaluate the performance of AutoSynch in this section. We compare the per\u00adformance \nof different signaling mechanisms in three sets of clas\u00adsical conditional synchronization problems. The \n.rst set of prob\u00adlems relies on only shared predicates for synchronization. Next, we explore the performance \nfor problems using complex predicates. Finally, we evaluate the problems in which signalAll calls are \nre\u00adquired in the explicit-signal mechanism. 5.1 Experimental environment All of the experiments were \nconducted on a machine with 16 Intel(R) Xeon(R) X5560 Quad Core CPUs (2.80 GHz) and 64 GBs memory running \nLinux 2.6.18. We conducted two types of experiments. The .rst is a saturation test [5], in which only \nmonitor accessing functions performed. That is, no extra work is performed in the monitor or out of the \nmonitor. The other set of experiments simulate different workloads of the monitors [4]. For each monitor \noperation, there is a .xed time to perform other operations out of the monitor. For every experiment, \nwe ran the program 25 times, and removed the best and the worst results. Then we compared the average \nruntime for different signaling mechanisms. We do not report memory usage due to space limitations. Al\u00adthough \nsome additional data structures are created in our frame\u00adwork, the additional memory consumption is insigni.cant. \nThe rea\u00adson is that, whenever a predicate has no waiting thread, it is put in an inactive list for reuse. \nIf the size of the inactive list exceeds a prede.ned threshold, e.g. 2n (n is the number of threads), \nthen we remove the oldest predicate and the conditional variable from the list and the table. Moreover, \nthe size of active predicates is always less than n. 5.2 Signaling mechanisms Four implementations using \ndifferent signaling mechanisms have been compared. Explicit-signal Using the original Java explicit-signal \nmechanism. Baseline Using the automatic-signal mechanism relying on only one condition variable. It calls \nsignalAll to wake every waiting thread. Then each thread that wakes up re-evaluates its own predicate \nafter re-acquiring the monitor. AutoSynch-T Using the approach described in this paper but ex\u00adcluding \npredicate tagging. AutoSynch Using the approach described in this paper.  5.3 Test problems Seven conditional \nsynchronization problems are implemented for evaluating our approach. 5.3.1 Shared predicate synchronization \nproblems Bounded-buffer [8, 10] This is the traditional bounded-buffer problem. Every producer waits \nif the buffer is full, while ev\u00ad ery consumer waits if the buffer is empty. H2O problem [1] This is the \nsimulation of water generation. Ev\u00ad ery H atom waits if there is no O atom or another H atom. Every O \natom waits if the number of H atoms is less than 2.  5.3.2 Complex predicate synchronization problems \nRound-Robin Access Pattern Every test thread accesses the mon\u00aditor in round-robin order. Readers/Writers \n[7] We use the approach given in [5], where a ticket is used to maintain the accessing order of readers \nand  Predicate Table its arrival order. Readers and writers wait on the monitor for their turn. runtime(seconds) \nruntime(seconds) Dining philosophers [10] This problem requires coordination among philosophers sitting \naround a table and is described in [10]. 5.3.3 Synchronization problems requiring signalAll in explicit \n Parameterized bounded-buffer [8, 10] The parameterized bounded\u00ad buffer problem shown in Fig. 1.  5.4 \nExperimental results 2 4 8 16 32 64 128 256 Fig. 8 and 9 plot the results for the bounded-buffer and \nthe H2O # producers/consumers problem. The y-axis shows the runtime in seconds. The x-axis rep- Figure \n8: The results of bounded-buffer problemresents the number of simulating threads. Note that, in the H2O \nproblem, only one thread simulates an O atom. The x-axis rep\u00adresents the number of threads simulating \nH atoms. As expected, the baseline is much slower than other three signaling mechanisms, which have similar \nperformance in the both problems. This phe-300  nomenon can be explained as follows. There is only a \nconstant 250 number of shared predicates in waituntil statements for automatic\u00adsignal mechanisms. For \nexample, in the bounded-buffer problem, there are two waituntil statements with global predicates, count \n200 150 100 > 0 (not empty condition) and count < buff.length (not full con\u00ad dition). Therefore, the \ncomplexity for signaling a thread in Au\u00ad toSynch and AutoSynch-T is also constant. Hence, both AutoSynch \nand AutoSynch-T are as ef.cient as the explicit-signal mechanism. These experiments illustrate that the \nautomatic-signal mechanisms are as ef.cient as the explicit-signal mechanisms for synchroniza\u00ad 50 0 tion \nproblems relying on only shared predicates. Fig. 10, 11 12 present the experimental results for the round\u00adrobin \naccess pattern, the readers/writers problem, and the dining philosophers problem. The result of the baseline \nis not plotted in these .gures since its performance is extremely inef.cient in com\u00adparison with other \nmechanisms. In this set of experiments, the explicit-signal mechanism has an advantage since it can explic\u00aditly \nsignal the next thread to enter the monitor. For example, in the round-robin access pattern, an array \nof condition variables is used for associating the id of each thread and its condition variable. Each \nthread waits on its condition variable until its turn. When a thread leaves the monitor, it signals the \ncondition variable of the next thread. As can be seen, the performance of explicit-signal mecha\u00adnism \nis steady as the number of threads increases in the round-robin access pattern and the reader/writers \nproblem. In AutoSynch-T, its runtime increases signi.cantly as the number of threads increase. For AutoSynch, \nthe performance is between 1.2 to 2.6 times slower # H-Atom Figure 9: The results of H2O problem than \nthe explicit-signal mechanism for the round-robin access pat\u00adtern. However, the performance of AutoSynch \ndoes not decrease as the number of threads increases. Note that, in the readers/writers problem, the \nAutoSynch-T is more ef.cient than AutoSynch when the number of threads is small. The reason is that AutoSynch \nsac\u00adri.ces performance for maintaining predicate tags. The bene.t of predicate tagging increases as the \nnumber of threads increases. An\u00adother interesting point is that the performance of the explicit signal \nmechanism does not outperform implicit signal mechanisms much in the dining philosophers problem. The \nreason is that a philoso\u00adpher only competes with two other philosophers sitting near him mechanism. In \nthis experiment, there is one producer, which ran\u00ad  even when the number of philosophers increases.domly \nputs 1 to 128 items every time. The y-axis indicates the num\u00adber of consumers. Every consumer randomly \ntakes 1 to 128 items every time. As can be seen, the performance of the explicit-signal 25 20 15 10 \n5 0# threads mechanism decreases as the number of consumers increases. Au\u00adtoSynch outperforms the explicit-signal \nmechanism by 26.9 times when the number of threads is 256. This can be explained by Fig. 14 that depicts \nthe number of contexts switches. The number of con\u00ad text switches increases in the explicit-signal mechanism \nin which the number of context switches is around 2.7 million when the num\u00adber of threads is 256. However, \nthe numbers of context switches are stable in AutoSynch even when the number of threads increase. It \nhas around 5440 context switches when the number of threads is 256. This experiment demonstrates that \nthe number of context switches can be dramatically reduced and the performance can be increased in AutoSynch \nfor the problems requiring signalAll calls in the explicit-signal mechanism. runtime(seconds) Figure \n10: The results of round-robin access pattern  Runtime (seconds) 2 4 8 16 32 64 128 256 # consumers \n Figure 13: The results of the parameterized bounded-buffer prob\u00ad# writers lem Figure 11: The results \nof readers/writers problem 3000 0 # context switches (K times) 90 80 70 60 50 40 30 20 runtime(seconds) \n10 2 4 8 16 32 64 128 256 0 2 4 8 16 32 64 128 256 # philosophers Figure 12: The results of dining philosophers \nproblem Table 1 presents the CPU usage (pro.led by YourKit [20]) for the round-robin access pattern with \n128 threads. The relaySignal is the process of deciding which thread should be signaled in both AutoSynch \nand AutoSynch-T. Tag Mger is the computation for maintaining predicate tags in AutoSynch. As can be seen, \nthe predicate tagging signi.cantly improves the process for .nding a predicate that is true. The CPU \ntime of relaySingal process is reduced 95% with a slightly increased cost in tag management. In Fig. \n13, we compare the results of the parameterized bounded\u00adbuffer in which signalAll calls are required \nin the explicit-signal # consumers Figure 14: The number of context switches of the parametrized bounded-buffer \nproblem Fig. 15 and 16 present the run time ratio of our approaches and the explicit approach for the \nround-robin access pattern with 256 threads and the readers/writers problem with 64 writers and 320 readers. \nThe y-axis indicates the runtime ratio and the x-axis shows the delay time, the amount of time in which \nthe threads perform operations out of the monitor between every two monitor opera\u00adtions, in microseconds. \nAs expected, the performance difference decreases as the duration of delay time increases. AutoSynch \nis two times slower than the explicit approach with no delay time (satura\u00adtion test) for round-robin \naccess pattern. However, when the dura\u00adtion of delay time is 5000 microseconds, AutoSynch is only 7.7% \n await lock relaySignal Tag Mger others total T % T % T % T % T % T explicit 21365 99.7% 28 0.15% NA \nNA NA NA 28 0.15% 21433 AutoSynch-T 410377 98.5% 3140 0.7% 2108 0.5% NA NA 1033 0.2% 416658 AutoSynch \n96754 98.8% 812 0.8% 112 0.1% 124 0.1% 148 0.02% 97950 Table 1: The CPU usage for the round robin access \npattern slower than the explicit approach. Note that, even AutoSynch-T per-there is possibility of further \nperformance improvement if the ap\u00adforms well when the duration of delay time increases. The similar proach \nwas to be implemented within the JVM. observation can be seen for the readers/writers problem in Fig. \n16. The results suggest that our approach could be more useful for prac- Acknowledgement tical problems \nthat perform more monitor unrelated operations. The authors thank Himanshu Chauhan, Yen-Jung Chang, John \nBridgman, and Craig Chase for the helpful discussions and com\u00ad 4 3.5 3 2.5 2 1.5 1 delay time(microseconds) \n Figure 15: The runtime ratio of round-robin 2.8 ments to improve the paper. This work was supported \nin part by the NSF Grants CNS-1115808, CNS-0718990, and Cullen Trust for Higher Education Endowed Professorship. \nReferences [1] G.R.Andrews. Multithreaded, Parallel, and Distributed Programming. Addison-Wesley, MA, \n2000. [2] P. Brinch Hansen, The Programming language concurrent Pascal. IEEE Trans. Software Engineering, \n1(2), 199 207, June, 1975. [3] P. Brinch Hansen, Structured multiprogramming. Commun. ACM 15(7), 574 \n578, July 1972. [4] P. A. Buhr, M. Fortier, and M. H. Cof.n, Monitor Classi.cation.ACM Computing Surveys, \nACM, 27(1), 63 107, Mar. 1995. [5] P. A. Buhr and A. S. Harji, Implicit-signal monitors. ACM Transactions \non Programming Languages and Systems ACM, 27(6):1270 1343, Nov. 2005. [6] D. R. Butenhof, Programming \nWith Posix Threads. Addison-Wesley, runtime ratio runtime ratio 2.6 2.4 2.2 2 1.8 1.6 1.4 1.2 1 0.8 \ndelay time(microseconds) Figure 16: The runtime ratio of ticket readers/writers MA, 1997. [7] P.J.Courtois,F.Heymans,D.L.Parnars, \nConcurrent control with readers and writers . Commun. ACM, 14(10), 667 668, Oct. 1971. [8] E.W.Dijkstra, \nCooperating Sequential Processes. Technical Report EWD-123, 1965. [9] E. W. Dijkstra, The structure of \nthe THE -multiprogramming system. Commun. ACM, 11(5), 341 346, May 1968. [10] E. W. Dijkstra, Hierarchical \nOrdering of Sequential Processes. Acta Informatica, 1, 115 138, 1971. [11] J. Gosling, B. Joy, and G. \nSteele, The Java Language Speci.cation. 2nd ed. Addison-Wesley, MA, 2000. [12] V. K. Garg and N. Mittal, \nA Critique of Java for Concurrent Programming, IEEE Distributed Systems online 6(9), 2005. [13] A. Hejisberg, \nS. Wiltamuth, and P. Golde, C# Language Speci.cation. 6. Future Work Addison-Wesley, MA, 2003. [14] C. \nA. R. Hoare, Monitors: an operating system structuring concept. Commun. ACM, 17(10), 549 557, Oct. 1974. \nFairness is not guaranteed in our system. Our approach favors sig\u00adnaling a thread waiting on a predicate \nthat is likely to be true. We focus on the ef.ciency of our automatic-signal monitor at this point. Fairness \nmay be an important issue for some concurrent applica\u00adtions and we plan to address it in future. Buhr \nand Harji simulated implicit-signal monitors with explicit monitors [5]. Their approach provides fairness \nand deals with staleness/freshness issues. How\u00adever, their approach does not focus on the ef.ciency. \nIn the future, we plan to optimize our framework through us\u00ading the architecture information. For example, \nwe can get the num\u00adber of cores of a machine, and then limit the number of executing threads to avoid \nunnecessary contention. Our current implementa\u00adtion of AutoSynch is built upon constructs provided by \nJava. Thus, [15] Y.-J. Joung, Asynchronous group mutual exclusion. ACM Symposium on Principles of Distributed \nComputing, 51 60, Aug. 1998. [16] J. L. W. Kessels. An alternative to event queues for synchronization \nin monitors. Commun. ACM, 20(7), 500 503, July 1977. [17] V. Kodaganallur, Incorporating language processing \ninto Java applications: a JavaCC tutorial. IEEE Software, 21(4), 70 77, July Aug. 2004. [18] D. Lea, \nThe java.util.concurrent synchronizer framework. Science of Computer Programming, 58(3), 293 309, Dec. \n2005. [19] B. Stroustrup, The C++ Programming Language. 3rd ed. Addison-Wesley, MA, 1997. [20] Yourkit \nLLC, Yourkit pro.ler. http://www.yourkir.com    \n\t\t\t", "proc_id": "2491956", "abstract": "<p>Most programming languages use monitors with explicit signals for synchronization in shared-memory programs. Requiring programmers to signal threads explicitly results in many concurrency bugs due to missed notifications, or notifications on wrong condition variables. In this paper, we describe an implementation of an automatic signaling monitor in Java called AutoSynch that eliminates such concurrency bugs by removing the burden of signaling from the programmer. We show that the belief that automatic signaling monitors are prohibitively expensive is wrong. For most problems, programs based on AutoSynch are almost as fast as those based on explicit signaling. For some, AutoSynch is even faster than explicit signaling because it never uses signalAll, whereas the programmers end up using signalAll with the explicit signal mechanism.</p> <p>AutoSynch} achieves efficiency in synchronization based on three novel ideas. We introduce an operation called closure that enables the predicate evaluation in every thread, thereby reducing context switches during the execution of the program. Secondly, AutoSynch avoids signalAll by using a property called relay invariance that guarantees that whenever possible there is always at least one thread whose condition is true which has been signaled. Finally, AutoSynch uses a technique called predicate tagging to efficiently determine a thread that should be signaled. To evaluate the efficiency of AutoSynch, we have implemented many different well-known synchronization problems such as the producers/consumers problem, the readers/writers problems, and the dining philosophers problem. The results show that AutoSynch is almost as efficient as the explicit-signal monitor and even more efficient for some cases.</p>", "authors": [{"name": "Wei-Lun Hung", "author_profile_id": "81758801057", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P4149013", "email_address": "wlhung@utexas.edu", "orcid_id": ""}, {"name": "Vijay K. Garg", "author_profile_id": "81100630621", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P4149014", "email_address": "garg@ece.utexas.edu", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462175", "year": "2013", "article_id": "2462175", "conference": "PLDI", "title": "AutoSynch: an automatic-signal monitor based on predicate tagging", "url": "http://dl.acm.org/citation.cfm?id=2462175"}