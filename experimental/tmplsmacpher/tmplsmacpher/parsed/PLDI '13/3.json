{"article_publication_date": "06-16-2013", "fulltext": "\n Complete Completion using Types and Weights Tihomir Gvero Viktor Kuncak Ivan Kuraj \u00b4 Ecole Polytechnique \nF \u00b4erale de Lausanne (EPFL), ed\u00b4Switzerland .rstname.lastname@ep..ch Abstract Developing modern software \ntypically involves composing func\u00adtionality from existing libraries. This task is dif.cult because li\u00adbraries \nmay expose many methods to the developer. To help de\u00advelopers in such scenarios, we present a technique \nthat synthesizes and suggests valid expressions of a given type at a given program point. As the basis \nof our technique we use type inhabitation for lambda calculus terms in long normal form. We introduce \na suc\u00adcinct representation for type judgements that merges types into equivalence classes to reduce the \nsearch space, then reconstructs any desired number of solutions on demand. Furthermore, we in\u00adtroduce \na method to rank solutions based on weights derived from a corpus of code. We implemented the algorithm \nand deployed it as a plugin for the Eclipse IDE for Scala. We show that the techniques we incorporated \ngreatly increase the effectiveness of the approach. Our evaluation benchmarks are code examples from \nprogramming practice; we make them available for future comparisons. Categories and Subject Descriptors \nI.2.2 [Arti.cial Intelli\u00adgence]: Automatic Programming Program synthesis; D.2.6 [Soft\u00adware Engineering]: \nCoding Tools and Techniques Program Ed\u00aditors; D.2.13 [Software Engineering]: Reusable Software Reuse \nModels General Terms Languages, Algorithms Keywords program synthesis, type inhabitation, code completion, \ntype-driven synthesis, ranking 1. Introduction Libraries are one of the biggest assets for today s software \ndevel\u00adopers. Useful libraries often evolve into complex application pro\u00adgramming interfaces (APIs) with \na large number of classes and methods. It can be dif.cult for a developer to start using such APIs productively, \neven for simple tasks. Existing Integrated Develop\u00adment Environments (IDEs) help developers to use APIs \nby provid\u00ading code completion functionality. For example, an IDE can offer a list of applicable members \nto a given receiver object, extracted by .nding the declared type of the object. Eclipse [26] and Intel\u00adliJ \n[15] recommend methods applicable to an object, and allow the developer to .ll in additional method arguments. \nSuch completion Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. PLDI 13, June 16 19, 2013, Seattle, WA, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. \n. . $15.00 Ruzica Piskac Max Planck Institute for Software Systems (MPI-SWS), Germany piskac@mpi-sws.org \ntypically considers one step of computation. IntelliJ can addition\u00adally compose simple method sequences \nto form a type-correct ex\u00adpression, but requires both the receiver object as well as assistance from \nthe developer to .ll in the arguments. These efforts suggest a general direction for improving modern \nIDEs: introduce the ability to synthesize entire type-correct code fragments and offer them as suggestions \nto the developer. In this paper we describe a tool for automated synthesis of code snippets. The tool \ngenerates and suggests a list of expressions that have a desired type. One observation behind our work \nis that, in addition to the forward-directed completion in existing tools, de\u00advelopers can bene.t from \na backward-directed completion. Indeed, when identifying a computation step, the developer often has \nthe type of a desired object in mind. We therefore do not require the developer to indicate a starting \nvalue (such as a receiver object) explicitly. Instead, we follow a more ambitious approach that con\u00adsiders \nall values in the current scope as the candidate leaf values of expressions to be synthesized. Our approach \ntherefore requires fewer inputs than the pioneering work on the Prospector tool [18], or than the recent \nwork of Perelman et al. [20]. A general idea of our approach and a .rst prototype implementation was \ndemonstrated already in [10]. Finding a code snippet of the given type leads us directly to the type \ninhabitation problem: given a desired type T , and a type environment G (a map from identi.ers to their \ntypes), .nd an expression e of this type T . Formally, .nd e such that G f e : T . In our deployment, \nthe tool computes G from the position of the cursor in the editor buffer. It similarly looks up T by \nexamining the declared type appearing left of the cursor in the editor. The goal of the tool is to .nd \nan expression e, and insert it at the current program point, so that the overall program type checks. \nWhen there are multiple solutions, the tool prompts the developer to select one, much like in simpler \ncode completion scenarios. The type inhabitation in the simply typed lambda calculus cor\u00adresponds to \nprovability in propositional intuitionistic logic; it is de\u00adcidable and PSPACE-complete [24, 28]. We \ndeveloped a version of the algorithm that is complete in the lambda calculus sense (up to a\u00df.-conversion): \nit is guaranteed to synthesize a lambda expres\u00adsion of the given type, if such an expression exists. \nMoreover, if there are multiple solutions, it can enumerate all of them. If there are in.nitely many \nsolutions, then the algorithm can enumerate any desired .nite pre.x of the list of all solutions. Note \nalso that each synthesized expression is a complete in that method calls have all of their arguments \nsynthesized. Because of all these aspects of the algorithm we describe our technique as complete completion. \nWe present our algorithm using a calculus of succinct types, which we tailored for ef.ciently solving \ntype inhabitation queries. The calculus computes equivalence classes of types that reduce the search \nspace in goal-directed search, without losing completeness.  Figure 1. InSynth suggesting .ve highest-ranked \nwell-typed expressions synthesized from declarations visible at a given program point Moreover, our algorithm \ngenerates a representation of all solutions, from which it can then extract any desired .nite subset \nof solutions. Given a possibility of an in.nite number of type inhabitants, it is natural to consider \nthe problem of .nding the best one. To solve this problem, we introduce weights to guide the search and \nrank the presented solutions. Initially we assign the weight to each type declaration. Those weights \nplay a crucial role in the algorithm, since they guide the search and rank the presented solutions. The \nweight is de.ned in a way that a smaller weight indicates a more desirable formula. To estimate the initial \nweights of declarations we leverage 1) the lexical nesting structure, with closer declarations having \nlower weight, and 2) implicit statistical information from a corpus of code, with more frequently occurring \ndeclarations having smaller weight, and thus being preferred. In addition, we used a corpus of open-source \nJava and Scala projects as well as the standard Scala library to collect the usage statistics for the \ninitial weights of declarations. We implemented our tool, InSynth, within the Scala Eclipse plugin. Our \nexperience shows fast response times as well as a high quality of the offered suggestions, even in the \npresence of thousands of candidate API calls. We evaluated InSynth on a set of 50 benchmarks constructed \nfrom examples found on the Web, written to illustrate API usage, as well as examples from larger projects. \nTo estimate the interactive nature of InSynth, we measured the time needed to synthesize the expected \nsnippet. The running times of InSynth were always a fraction of a second. In the great majority of cases \nwe found that the expected snippets were returned among the top dozen solutions. Furthermore, we evaluated \na number of techniques deployed in our .nal tool and found that all of them are important for obtaining \ngood results. We also observed that, even for checking existence of terms InSynth outperforms recent \npropositional intuitionistic provers [9, 19] on our benchmarks. Our overall experience suggests that \nInSynth is effective in providing help to developers. 2. Motivating Examples We illustrate the functionality \nof InSynth through three exam\u00adples. The .rst example is taken from the online repository of Java API \nusage samples http://www.java2s.com/. The second ex\u00adample is a real-world fragment of the code base of \nthe Scala IDE for Eclipse, http://scala-ide.org/, and requires invoking a higher-order function. For \nthese two examples, the original code imports only declarations from a few speci.c classes; to make the \nproblems more challenging and illustrate the task that a program\u00admer faces, we import all declarations \nfrom packages where those classes reside. The third example illustrates that InSynth supports subtyping. \n2.1 Sequence of Streams In this example the goal is to create a SequenceInputStream object, which is \na concatenation of two streams. Suppose that the developer has the code shown in the Eclipse editor in \nFigure 1. If she invokes InSynth at the program point indicated by the cursor, in a fraction of a second \nInSynth displays the ranked list of .ve expressions. Seeing the list, the developer can decide that e.g. \nthe second expression in the list matches their intention, and select it to be inserted into the editor \nbuffer. This example illustrates that InSynth only needs the current program context, and does not require \nadditional information from the developer. InSynth is able to use both imported values (such as the constructors \nin this example) and locally declared ones (such as body and sig). InSynth supports methods with multiple \narguments and synthesizes expressions for each argument. In this example InSynth loads over 3000 declarations \nfrom the context, including local and imported values, and .nds the expected solution in less than 250 \nmilliseconds. The effectiveness of InSynth is characterized by both scalability to many declarations \nand the quality of the returned suggestions. In-Synth ranks the resulting expressions according to the \nweights and selects the ones with the lowest weight. The weights of expressions and types guide the .nal \nranking and also make the search itself more goal-directed and effective. InSynth derives weights from \na corpus of declarations, assigning lower weight to declarations ap\u00adpearing more frequently, and therefore \nfavoring their appearance in the suggested fragments over more exotic declarations.  2.2 TreeFilter: \nUsing Higher-Order Functions We demonstrate the generation of expressions with higher-order functions \non real code from the Scala IDE project. The example shows how a developer should properly check if a \nScala AST tree satis.es a given property. In the code, the tree is an argument of the class TreeWrapper, \nwhereas the property p is an input of the method .lter. import scala.tools.eclipse.javaelements. import \nscala.collection.mutable. trait TypeTreeTraverser { val global: tools.nsc.Global import global. class \nTreeWrapper(tree: Tree) { def .lter(p: Tree => Boolean): List[Tree] = { val ft:FilterTypeTreeTraverser \n= ft.traverse(tree) ft.hits.toList }}}  The property p is a predicate function that takes the tree and \nreturns true if the tree satis.es it. In order to properly use p inside .lter, the developer .rst needs \nto create an object of the type FilterTypeTreeTraverser. If the developer calls InSynth at the place \n, the tool offers several expressions, and the one ranked .rst turns out to be precisely the one found \nin the original code, namely new FilterTypeTreeTraverser(var1 => p(var1)) The constructor FilterTypeTreeTraverser \nis a higher-order function that takes as input another function, in this case p. In this example, InSynth \nloads over 4000 initial declarations and .nds the snippets in less than 300 milliseconds.  2.3 Drawing \nLayout: Using Subtyping The next example illustrates a situation often encountered when using java.awt: \nimplementing a getter method that returns a layout of an object Panel stored in a class Drawing. To implement \nsuch a method, we use code of the following form. import java.awt. class Drawing(panel:Panel) { def getLayout:LayoutManager \n= } Note that handling this example requires support for subtyping, because the type declarations are \ngiven by the following code. class Panel extends Container with Accessible { ... } class Container extends \nComponent { ... def getLayout():LayoutManager = { ... }} The Scala compiler has access to the information \nabout all super\u00adtypes of all types in a given scope. InSynth supports subtyping and, in 426 milliseconds, \nreturns a number of solutions among which the second one is the desired expression panel.getLayout(). \nWhile doing so, it examines 4965 declarations. For more experience with InSynth, we encourage the reader \nto download it from: http://lara.epfl.ch/w/insynth The rest of the paper describes a formalization of \nthe problem that InSynth solves as well as the algorithms we designed to solve it. We then describe the \nimplementation and the evaluation, provide a survey of related efforts, and conclude. 3. Type Inhabitation \nProblem for Succinct Types To answer whether there exists a code snippet of a given type, our starting \npoint is the type inhabitation problem. In this section we establish a connection between type inhabitation \nand the synthesis of code snippets. Let T be a set of types. A type environment G is a .nite set {x1 \n: t1, . . . , xn : tn} of pairs of the form xi : ti, where xi is a variable of a type ti . T . We call \nthe pair xi : ti a type declaration. The type judgment, denoted by G f e : t , states that from the environment \nG, we can derive the type declaration e : t by applying rules of some calculus. The type inhabitation \nproblem for a given calculus is de.ned as follows: given a type t and a type environment G, does there \nexist an expression e such that G f e : t ? In the sequel we .rst describe type rules for the standard \nlambda calculus restricted to normal-form terms. We denote the corre\u00adsponding type judgment relation \nf.. We then introduce a new suc\u00adcinct representation of types and terms, with the corresponding type \njudgment relation fc. 3.1 Simply Typed Lambda Calculus for Deriving Terms in Long Normal Form As background \nwe present relevant rules for the simply typed lambda calculus, focusing on terms in long normal form. \nLet B be a set of basic types. Types are formed according to the following syntax: t ::= t . t | v, where \nv . B We denote the set of all types as t.(B). Let V be a set of typed variables. Typed expressions are \ncon\u00adstructed according to the following syntax: e ::= x | .x.e | e e, where x . V Figure 2 shows the \ntype derivation rules used to derive terms in long normal form. This calculus is slightly more restrictive \nthan (f : t1 . . . . . tn . t) . Go Go f. ei : ti, i = 1..n t . B AP P Go f. f e1 . . . en :t Go . {x1 \n:t1, . . . , xm : tn} f. e:t t . B AB S Go f. .x1 . . . xm.e: t1 . . . . . tm . t Figure 2. Rules for \nderiving lambda terms in long normal form the standard lambda calculus: the APP rule requires that only \nthose functions present in the original environment Go can be applied on terms. DE FIN I T I ON 3.1 (Long \nNormal Form). A judgement Go f. e : te is in long normal form if the following holds: e = .x1 . . . \nxm.f e1...en, where m, n = 0  (f : .1 . . . . . .n . t ) . Go, where t . B  te = t1 . . . . . tm . \nt  G.o f. ei : .i are in long normal form, where G.o = Go . {x1 : t1, . . . , xm : tm}  Note that \nm can be zero. Then, te = t and De.nition 3.1 reduces to the App rule. Otherwise, if M = f e1...en, then \nM : t can be derived by App and .x1 . . . xm.M : te by Abs rule. In long normal form a variable f is \nfollowed by exactly the same number of sub-terms as the number of arguments indicated by the type of \nf. As an illustration, consider f : t1 . t2 . t3 and x : t1. There is no derivation resulting in a judgement \nGo f. f x : t2 . t3 in long normal form, but .y.f xy : t2 . t3 has a long normal form derivation. When \nsolving the type inhabitation problem it suf.ces to derive only terms in long normal form, which restricts \nthe search space. This does not affect the completeness of search, because each simply-typed term can \nbe converted to its long normal form [6]. We de.ne the depth D of a term from a long normal form judgement \nas follows: D(.x1 . . . xm.a) = 1 D(.x1 . . . xm.f e1, . . . , en) = max (D(e1), . . . , D(en)) + 1, \nwhere a and f belong to V .  3.2 Succinct Types To make the search more ef.cient we introduce succinct \ntypes, which are types modulo isomorphisms of products and currying, that is, according to the Curry-Howard \ncorrespondence, modulo commutativity, associativity, and idempotence of the intuitionistic conjunction. \n DE FI NI TI O N 3.2 (Succinct Types). Let B be a set containing ba\u00adsic types. Succinct types ts are \nconstructed according to the gram\u00admar: ts ::= {ts, . . . , ts} . v, where v . B We denote the set of \nall succinct types with ts(B), sometimes also only with ts. A type declaration f : {t1, . . . , tn} . \nt is a type declaration for a function that takes arguments of n different types and returns a value \nof type t. The type \u00d8 . t plays a special role: it is a type of a function that takes no arguments and \nreturns a value of type t, i.e. we consider types t and \u00d8 . t equivalent. Every type t . t.(B) can be \nconverted into a succinct type in ts(B). With s : t.(B).ts(B) we denote this conversion function. Every \nbasic type v . B becomes an element of the set of basic succinct types, and s(v) = \u00d8.v. We also denote \n\u00d8.v only with v. Let A (arguments) and R (return type) be two functions de.ned on ts(B) as follows: A({t1, \n. . . , tn} . v) = {t1, . . . , tn} R({t1, . . . , tn} . v) = v Using A and R we de.ne the s function \nas follows: s(t1 . t2) = {s(t1)} . A(s(t2)) . R(s(t2)) In particular, for v . B, a type of the form t1 \n. . . . . tn . v which often occurs in practice, has the succinct representation {s(t1), . . . , s(tn)} \n. v Given a type environment Go = {x1 : t1, . . . , xn : tn} where ti are types in the simply type lambda \ncalculus, we de.ne G = s(Go) = {s(t1), . . . , s(tn)} It follows immediately that the conversion distributes \nover unions:  s( Gi o) = s(Gi o) i.I i.I To demonstrate the power of the succinct representation, we \nprovide the statistics from the example in Figure 1. In this example, the original type environment with \n3356 declarations is reduced to the compact succinct environment with 1783 succinct types, after the \ns transformation. This drastically reduces the search space later explored by our main algorithm.  3.3 \nSuccinct Patterns Succinct patterns have the following structure: G@{t1, . . . , tn} : t where ti . ts(B), \ni = 1..n, and t . B. A pattern G@{t1, . . . , tn} : t indicates that types t1, . . . , tn are inhabited \nin G and an inhabitant of type t can be computed from them also in G. They abstractly represent an application \nterm in lambda calculus. Our algorithm for .nding all type inhabitants works in two phases. In the .rst \nphase we derive all succinct patterns. They can be seen as a generalization of terms, because they describe \nall the ways in which a term can be computed. In the second phase we do a term reconstruction based on \nthe original type declarations (Go) and the set of succinct patterns. 3.4 Succinct Calculus Figure 3 \ndescribes the calculus for succinct types. Note that the patterns are derived only in the APP rule. The \nrule ABS modi.es G it can either reduce G or enlarge it, depending on whether we are doing backward or \nforward reasoning. {t1, . . . , tn}.t . G G fc ti, i = 1..n t . B AP P G fc G@{t1, . . . , tn} : t G \n. S fc (G . S)@p : t t . B AB S G fc S.t Figure 3. Calculus rules for deriving succinct patterns Consider \nthe example given at the beginning of this section and its type environment Go = {a : Int, f : Int . \nInt . Int . String}. From the type environment Go we compute G = {\u00d8 . Int, {\u00d8 . Int} . String} = {Int, \n{Int} . String}. By applying the APP rule on Int, we derive a succinct pattern G@\u00d8 : Int that we add \nto a set of derived patterns. Having a pattern for Int we apply the ABS rule. By setting S = \u00d8, we derive \nG fc \u00d8.Int. Finally, by applying again the APP rule, we directly derive a pattern G@{Int} : String, for \nthe String type and store it into the set of derived patterns.  3.5 Soundness and Completeness of Succinct \nCalculus In this section we show that the calculus in Figure 3 is sound and complete with respect to \nsynthesis of lambda terms in long normal form. We are interested in generating any desired number of \nexpressions of a given type without missing any expressions equivalent up to \u00df reduction. To formulate \na completeness that captures this ability, we introduce two functions, CL and RCN, shown in Figure 4. \nThese functions describe the terms in long normal form of a desired type, up to a given depth d. They \nrefer directly to fc and are therefore not meant as algorithms, but as a way of expressing the completeness \nof succinct representation and as speci.cations for the algorithms we outline in Section 5. fun CL(G, \nS .t) = {(G . S)@S1 : t | (S1.t) . (G . S), .t . S1.G . S fc t }fun Select(Go, t) := {v:t | v:t . Go \nand s(t) = t}fun RCN(Go, t1. \u00b7 \u00b7 \u00b7 .tn.v, d) := if (d = 0) return \u00d8 else S.v := s(t1. \u00b7 \u00b7 \u00b7 .tn.v) G \n:= s(Go) G:= Go . {x1 : t1, . . . , xn : tn} //x1, . . . , xn are fresh o TERMS := \u00d8 foreach ((G . S)@{t1, \n. . . , tm/ } : v) . CL(G, S.v) foreach (f : t) . Select(G, {t1, . . . , t/ }.v) o m (.1. \u00b7 \u00b7 \u00b7 ..m.v) \n:= t if (m=0) TERMS := TERMS . {.x1 . . . xn.f} else foreach i . [1..m] Ti := RCN(G, .i, d-1) o foreach \n(e1, . . . , em) . (T1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 Tm) TERMS := TERMS . {.x1 . . . xn.f e1 . . . em}return TERMS Figure \n4. The function RCN constructs lambda terms in long normal form up to given depth d, invoking the auxiliary \nfunctions CL and Select. The CL function in Figure 4 takes as arguments a succinct type environment G \nand a succinct type S.t. It returns the set of all pat\u00adterns (G . S)@S1 : t that describe the derivation \nof t. The func\u00adtion RCN uses the initial environment and the desired type to re\u00adconstruct lambda terms. \nAdditionally, RCN takes a non-negative integer d to limit the reconstruction to terms with depth smaller \nor equal to d. It uses type t1. \u00b7 \u00b7 \u00b7 .tn.v to extend the environ\u00adment and .nd all patterns that witness \ninhabitation of v. We ex\u00adtend the environment with fresh variables x1 : t1, . . . , xn : tn, and use \nCL to .nd the patterns. Further, we .nd all declarations f with a return type v in the extended environment. \nIf f has a func\u00adtion type .1. \u00b7 \u00b7 \u00b7 ..m.v, we recursively generate correspond\u00ading sub-terms with types \n.1, . . . , .m. Finally, we use x1, . . . , xn, f and sub-terms to construct terms in long normal form. \n Given the functions CL and RCN we can formalize the com\u00adpleteness theorem: each judgement in long normal \nform derived in the standard lambda calculus can also be derived by reconstruction using derivations \n(patterns) of the succinct calculus. TH EO R E M 3.3 (Soundness and Completeness). Let Go be an original \nenvironment, e an lambda expression, t . t.(B) and functions RCN and D de.ned as above, then: Go f. e \n: t . e . RCN(Go, t, D(e)) We provide the proof of Theorem 3.3 in [11]. 4. Quantitative Type Inhabitation \nProblem When answering the question of the type inhabitation problem, there might be many terms having \nthe required type t . A ques\u00adtion that naturally arises is how to .nd the best term, for some adequate \nmeaning of best . For this purpose we assign a weight to every term. As in resolution-based theorem proving, \na lower weight indicates a higher relevance of the term. Using weights we extend the type inhabitation \nproblem to the quantitative type inhabitation problem given a type environment G, a type t and a weight \nfunc\u00adtion w, is t inhabited and if it is, return a term that has the lowest weight. Nature of Declaration \nor Literal Weight Lambda 1 Local 5 Coercion 10 Class 20 Package 25 Literal 200 785 215 + Imported 1+f(x) \nTable 1. Weights for names appearing in declarations. We found these values to work well in practice, \nbut the quality of results is not highly sensitive to the precise values of parameters. Let w be a function \nthat assigns a weight (a non-negative num\u00adber) to each symbol primarily determined by: 1. the proximity \nto the point at which InSynth is invoked. We as\u00adsume that the user prefers a code snippet composed from \nval\u00adues and methods de.ned closer to the program point and assign the lower weight to the symbols which \nare declared closer. As shown in Table 1, we assign the lowest weight to local sym\u00adbols declared in the \nsame method. We assign a higher weight to symbols de.ned in the class where the query is initiated and \nthe highest weight to symbols that are only in the same package. 2. the frequency with which the symbol \nappears in the training data corpus, as described in Section 7.3. For an imported sym\u00adbol x, we determine \nits weight using the formula in Table 1. Here f(x) is the number of occurrences of x in the corpus. \n We also assign a low weight to a conversion function that wit\u00adnesses the subtyping relation, as explained \nin Section 6. While we believe that our strategy is fairly reasonable, we arrived at the par\u00adticular \nconstants via trial and error, so further improvements are likely possible. The function w also assigns \na weight to a term such that the weight of the term .x1 . . . xm.f e1 . . . en is the sum of the weights \nof all elements that occur in the expression: mn w(.x1 . . . xm.f e1 . . . en) = w(xi) + w(f) + w(ei) \ni=1 i=1 We use the weight of succinct types to guide the algorithm in Figure 5. Given Select in Figure \n4, the weight of a succinct type t in Go is de.ned as: w(t, Go) = min({w(f) | (f : t) . Select(Go, t)}) \n5. Synthesis of All Terms in Long Normal Form In this section we .rst motivate and introduce the backward \nsearch as the core mechanism of the algorithm, then we illustrate the algorithm and optimizations we \nimplement in InSynth. 5.1 Backward Search If we were to apply the rules in Figure 3 in a forward manner \nwe could have started from any environment in the premise(s). However, there are in.nitely many such \nenvironments. Moreover, rule Abs states that we can split G in 3|G/| possible ways into two subsets S \nand G, such that G = G . S. However, only some environments and splittings will lead to the .nal conclusion \nGinit fc Sinit.tinit, where Ginit and Sinit.tinit are the initial environment and the desired type, respectively. \nThis means we would have many unnecessary guesses and computations, leading to the wrong conclusions. \nIn contrast, if we use a backward search, then we start from the conclusion Ginit fc Sinit.tinit in Abs \nrule, and use a premise to create a hypothesis that a pattern (Ginit . Sinit)@p : tinit is derivable. \nFurther, we need to check that it is indeed derivable by applying App rule. Now, unlike in the forward \nmanner, thanks to the conclusion in App, we know the exact environment and the type t of the .rst premise. \nSelecting only types in G that have return types t introduce constraints on the other premises as well. \nThe entire process is applied recursively until the initial hypothesis is proven or disproved. However, \nthe constraints allow us to narrow the search. This is the main advantage of the backward search. All \nthis suggest that the backward search is more ef.cient, revealing only the search space reachable from \nthe initial environment and the desired type, unlike the forward search. To formalize the backward search \nwe reformulate the earlier rules by splitting them into the .ve new rules shown in Figures 6 and 8. One \nshould read and apply the new rules in the forward manner. In the following subsections we explain those \nrules in more detail.  5.2 Main Algorithm In this section we present an algorithm based on the succinct \nground calculus that we use for .nding type inhabitants. This al\u00adgorithm is further used as an interactive \ntool for synthesizing ex\u00adpression suggestions from which a developer can select a suitable expression. \nTo be applicable, such an algorithm needs to 1) gener\u00adate multiple solutions, and 2) rank these solutions \nto maximize the chances of returning relevant expressions to the developer. The algorithm is illustrated \nin Figure 5. As input Synthesize takes a desired type to, and an environment Go and outputs at most N \nterms in long normal form with a type to. We .rst transform Go and to by s into a succinct environment \nand a type, respectively. Then we execute the algorithm in three phases. First, Explore takes the succinct \ntype and the environment as input, and returns the discovered search space reachable from the desired \ntype and the  fun Explore(G, S.t) := { initial environment. Next, GenerateP takes the space as input \nand outputs a set of patterns. Finally, GenerateT takes patterns, Go, to . G ?} and the integer N, and \nproduces at most N ranked terms. space := \u00d8 The Explore and GenerateP use succinct types to prune the \nsearch space in a light way. They leave only a portion where dec\u00ad while(queue \u00d8) { = curr := queue.dequeue \nlaration argument-return types conform. This helps GenerateT to perform heavy reconstruct only when needed, \nreturning compilable t visited := visited . {curr}? := Strip(curr) / . G terms. found := {Match(t . Gf \n?, S .t ) | S .t . G } / space := space . found . G fun Synthesize(Go, to, N):= {space := Explore(s(Go), \ns(to)) newr := {Prop(tf (Sf , \u00d8), t ) | tf (Sf , \u00d8) . found return GenerateT(patterns, Go, to, N) . Gf \n. \\(newr visited)queue := queue } } return space Figure 5. The algorithm that generates all terms with \na given type }to and an environment Go patterns := GenerateP(space) and t . Sf } The algorithm Synthesize \nrepresents the imperative description of RCN, in Figure 4. It is the RCN version with a bound on the \nnumber of terms, N. Moreover, it uses weights to steer the search towards useful terms. We discuss this \nat the end of the section. The backward search and search driven by weights make the new Figure 7. The \nalgorithm that explores the search space. the desired type and the environment. We next give the detailed \ndescription of the Explore algorithm. To initiate the Explore algorithm in Figure 7 we create the . \nG ?, where S.t is the desired type, and G is the algorithm effective, practical and interactive. Synthesize \nproduces request (S.t)the same set of solutions as RCN, given the same input, if we initial type environment. \nWe put the request into a working queue. remove bounds d and N or gradually increase them. Note that \nthe In the loop we process one request at the time, until queue is empty. set of solutions might be in.nite. \nFirst, we use Strip to obtain a new request t? with an extended . G / environment G . Here, Strip is \nthe function that implements the  5.3 Exploration phase corresponding rule, Strip in Figure 3. It takes \nrequest (S.t) ? . G The goal of Explore is to start from the desired succinct type and environment and \ngradually explore the search space. We split the algorithm into three key steps: and returns new request \nt?. In the same fashion, we implement . G .S the other two functions, Match that returns a reachability \nterm, and Prop that returns a request. Next, by applying Match to t? and . G / every type in G we .nd \na set of reachability terms, found. We store 1. Type reachability. Given a succinct type t and G we want \nto .nd all types reachable from t. We specify this request by t r G ?. We use the request to trigger \nthe Match rule in Figure 3. By the rule, types in set S are reachable from type t, A(t) = \u00d8, in G, if \n(S.t) . G holds. We denote this with reachability term, t r G (S, .) (later we explain what the set . \nis). 2. Request propagation. Once we discover that types S are reachable from t, we want to discover \nwhat types are reachable the terms in the set space. The space set represents the entire search space \ndiscovered from the desired type and the initial environment. Finally, we propagate the search by issuing \nnewr requests using the Prop function onto found. We update queue with these requests. We additionally \nkeep the set of all visited requests, to avoid cycles in the exploration.  5.4 Pattern generation phase \nfrom any type t . S. Thus, we generate a new request t r G ?. New requests are issued with the Prop rule. \nIn other words, we In this phase we use the space explored by the Explore algorithm to create patterns. \nWe start from the reachability terms with inhabited use the Prop rule to propagate the search. types, \nand use them to produce patterns and new inhabited types. 3. Environment extension. However, t can be \na function type, We repeat the process until no new types can be inhabited. i.e., t = S . t and S \u00d8. \nThus, we introduce the Strip = r G rule that transforms a request (S . t) .S ? to a request t ?. r \nG r G .S ? in the Match rule. PRO D r G (\u00d8, .) t Now, we can further use the request t G@. : t r G \nt(S . {S t (S, \u00d8) r . t }, .) t G.S/ (S, . . {S . t }) ? (S.t) . G A(t) = \u00d8 r G t TR A N S F E R MAT \nC H r G r G t Figure 8. Pattern synthesis rules. (S . t)? r G PRO P ST R I P Initially, we divide the \nsearch space, space, into two groups: ? ? r G tt 1) leaves that contains reachability terms in the form \nt r G r G (\u00d8, . ) t(S, \u00d8) t . S .S Figure 6. Type reachability rules. i.e., reachability terms with \ninhabited types, and 2) others that contains the remaining terms. The set . collects succinct types A \nset of reachability terms keep the information about the explored that have an inhabitant. It is initialized \nby Match to an empty set. (\u00d8, .), . G The Transfer rule, in Figure 8, turns t (S . {S .t }, .) into \nsearch space. Thus our goal is to derive all such terms starting from . G fun GenerateP(space) := {patterns \n:= \u00d8 visited := \u00d8 leaves := {x | x = t (\u00d8, \u00d8) and x . space} G others := space \\ leaves while (leaves \n= \u00d8) { t (\u00d8, .) := leaves.dequeue G visited := visited . {t (\u00d8, .)} G patterns := patterns . {Prod(t \n(\u00d8, .))} G compatible := {x | x = t (S . {S . t}, . ) G/ and G = G . S and x . others}newt := {Transfer(x, \nt (\u00d8, .)) | x . compatible} G newLeaves := {x | x = t (\u00d8, . ) and x . newt} G/ others := (others \\ compatible) \n. (newt \\ newLeaves) leaves := leaves . (newLeaves \\ visited) } return patterns } Figure 9. The algorithm \nthat generates patterns. t (S, . . {S .t }) if {S .t } is inhabited. We use . to produce G a pattern \nby the Prod rule. In the loop we remove one term t (\u00d8, .) from leaves to gen\u00ad G erate: 1) a pattern G@. \n: t by the Prod function, and 2) the newt reachability terms by the Transfer function. To perform the \nlatter we .rst calculate the set of compatible terms. Those are the reacha\u00adbility terms in form t (S \n. {S . t }, .), such that G = G . S G holds. Every term in compatible can be resolved with t (\u00d8, .) by \nG the Transfer rule. The result is the set of newt terms. These reach\u00adability terms can be split into \ntwo groups. The .rst group contains terms of the form t (\u00d8, . ), that we add to leaves. The second G/ \ngroup contains the remaining terms and we add them to others. We also keep the set of visited leaves \nin order to avoid cycles in gener\u00adation.  5.5 Term generation phase In Figure 10 we illustrate the algorithm \nthat .nds at most N lambda expressions with the smallest weight. First, we introduce the notion of holes \nto de.ne the partial expressions, and later we describe the algorithm GenerateT. A typed hole [ ]h : \nt is a constant [ ] with a name h and a type t . Let V be a set of typed variables, and H a set of typed \nholes. Partial typed expressions are constructed according to the following syntax: e ::= x | [ ]h : \nt | .x :t .e | e e, where x . V and [ ]h : t . H To derive the partial expressions in long normal form \none can use the same APP and ABS rules in Figure 2, where ei, i = [1..m] and e are partial types expressions. \nMoreover, one can substitute all holes in a partial expression and get a new partial or complete expression, \nwithout holes. A hole [ ]h : t, in a judgment Go f [ ]h : t , can be substituted only with a partial \nexpression e : t , where Go f e : t . We next describe the GenerateT algorithm. We start from the de\u00adsired \ntype and original environment, follow patterns and gradually create and unfold partial expressions. During \nthe process we keep partial expressions in the queue. Once a partial expression becomes complete, we \nstore it in the set of snippets. We use a priority queue to process partial expressions. The ex\u00adpressions \nare sorted by the weight in ascending order. We initi\u00adate the queue with [ ]x : tinit, where tinit is \nthe desired type. In the loop we process one partial expression at a time. The loop terminates either \nwhen the queue is empty or we .nd N expres\u00adsion. First, we remove the highest ranked partial expression, \nexprp, from the priority queue. Then, we call the function .ndFirstHole, that for a given judgment Ginit \nf exprp .nds (if it exists) a hole [ ]h : t1. \u00b7 \u00b7 \u00b7 .tn.v and its corresponding environment Go. If exprp \nhas no holes, it is a complete lambda expression, i.e., a snip\u00adpet that we will output to a user. Hence, \nwe append it to snippets. If there is a hole in exprp we build all partial expressions that can sub\u00adstitute \nthe hole. We extend the environment and use patterns with the return type v to .nd declarations f. If \nthe declaration has func\u00adtion type, we build the expression .lling all arguments with fresh holes. (Note \nthat the new holes might be substituted in a later iter\u00adation.) For each expression exprnewp , we build \na substitution that maps a name of the hole to the expressions. We apply the sub\u00adstitution to substitute \nthe hole with the new expression. We use the function w to calculate expression weights and store them \nin the priority queue. The weight of a hole is equal to zero. We .nd fun GenerateT(patterns, Ginit, tinit, \nN) := { snippets := NIL pq := PriorityQueue.empty pq.put(0, [ ]x : tinit) while(pq.size > 0 and |snippets| \n< N){ exprp = pq.dequeue .ndFirstHole(Ginit,exprp) match { case None . snippets.append(exprp) //appends \nto the end case Some((Go, [ ]h : t1. \u00b7 \u00b7 \u00b7 .tn.v)) . S.v := s(t1. \u00b7 \u00b7 \u00b7 .tn.v) G := s(Go) //x1, . . \n. , xn are fresh G:= Go . {x1 : t1, . . . , xn : tn} o foreach ((G . S)@S : v) . patterns //S is binder \nforeach (f : .1. \u00b7 \u00b7 \u00b7 ..m.v) . Select(G, S .v) o exprnewp := sub(exprp, h > (.x1 . . . xn.f[ ]r1 : .1 \n. . . [ ]rm : .m)) //r1, . . . , rm are fresh names pq.put(w(exprnewp ), exprnewp ) } } return snippets \n} fun .ndFirstHole(Go, exp):= exp match {case [ ]x : t . Some((Go, [ ]x : t)) case .x1 . . . xn.f e1 \n. . . em . G:= Go . {x1 : t1, . . . , xn : tn} //x1, . . . , xn are fresh o for(i . [1..m]) .ndFirstHole(G, \nei) match { o case Some(hole) . return Some(hole) case Node . } None } fun sub(expr1, y > expr2):= expr1 \nmatch { case [ ]x : t . if (x = y) expr2 else expr1 case .x1 . . . xn.f e1 . . . em . .x1 . . . xn.f \nsub(e1, y > exp2) . . . sub(em, y > exp2) } Figure 10. A function that constructs the best N lambda \nterms in long normal form. the partial expressions that replace the hole using patterns. First we calculate \na succinct type S.v and environment G. We expand the environment to G . S and use it with type v to .nd \nall pat\u00adterns with form (G . S)@S : v in the pattern set. When we .nd all such sets S we use them to \nselect all type variables in Go whose type maps to a succinct type S .v. Once we have such a variable \nwe use it to create the most general partial expression .x1 . . . xn.f[ ]r1 : .1 . . . [ ]rm : .m. Such \nan expression has holes at the places of f s arguments. In this way we gradually unfold a partial expression \nuntil it becomes complete.  5.6 Responsiveness We use .rst two phases to synthesize patterns starting \nfrom the de\u00adsired type and the initial environment. We referred to those phases as a prover. To be interactive \nwe allow a user to specify a time limit for the prover. Due to time bound, we decide to interleave the \ntwo phases, such that whenever Explore discovers a new leaf, it immediately triggers GenerateP. Every \ntime GenerateP is called it uses all discovered reachability terms to generate as many new pat\u00adterns \nas possible. Moreover, to generate the best solutions, within a given time, we use a priority queue in \nExplore instead of the regu\u00adlar queue. Requests in the priority queue are sorted by weights. A weight \nof a request t ? is equal to a weight of type t in the initial G environment. Additionally, we allow \na user to specify a time limit for GenerateT.  5.7 Optimizations To ef.ciently .nd the compatible set \nin GenerateP, we create a backward map that maps a term to its predecessor terms. Last reachability term \nf that initiated creation of term, through propa\u00adgation, is the predecessor of term. We build the map \nin Explore, that records all predecessors of a given term, by storing an entry (term, predecessors). \nBy using the map, compatible becomes the predecessors set of t (\u00d8, .). This way we do not preform expen\u00ad \nG sive calculation of compatible. However, whenever a new term x is generate by Transfer(y, z) in GenerateP, \nwe need to update the map by substituting every occurrence of y with x in the map. To speed up this process, \nfor every term in the map we keep the list of entries where the term occurs. 6. Subtyping using Coercion \nFunctions We use a simple method of coercion functions [2, 17, 21] to extend our approach to deal with \nsubtyping. We found that this method works well in practice. On the given set of basic types, we model \neach subtyping relation v1 <: v2 by introducing into the environ\u00adment a fresh coercion expression c12 \n: {v1} . v2. If there is an expression e : t , and e was generated using the coercion functions, then \nwhile translating e into simply typed lambda terms, the coer\u00adcion is removed. Up to .-conversion, this \napproach generates all terms of the desired type in a system with subtyping on primitive types with the \nusual subtyping rules on function types. In the standard lambda calculus there are three additional rules \nto handle subtyping: transitivity (t1 <: t2 and t2 <: t3 imply t1 <: t3), subsumption (if e : t1 and \nt1 <: t2 then e : t2), and the cvariant rule (t1 <: .1 and .2 <: t2 imply .1 . .2 <: t1 . t2). We proved \nthat even with those new rules the complexity of the problem does not change and the type inhabitation \nremains a PSPACE-complete problem. If subtyping constraints are present, then the coercion functions \nare used in the construction of succinct patterns. However, in the RCN function the coercion functions \nare omitted when deriving new lambda terms. 7. Evaluation of the Effectiveness of InSynth This section \ndiscusses our implementation, a set of benchmarks we used to evaluate InSynth, and the experimental results. \n7.1 Implementation in Eclipse We implemented InSynth as an Eclipse plugin that extends the code completion \nfeature. It enables developers to accomplish a complex action with only a few keystrokes: declare a type \nof a term, invoke InSynth, and select one of the suggested expressions. InSynth provides its functionality \nin Eclipse as a contribution to the standard Eclipse content assist framework and contributes its results \nto the list of content assist proposals. These proposals can be returned by invoking the content assist \nfeature when Scala source .les are edited (usually with Ctrl + Space). If the code completion is invoked \nat any valid program point in the source code, InSynth attempts to synthesize and return code snippets \nof the desired type. Only the top speci.ed number of snippets are displayed as propos\u00adals in the content \nassist proposal list, in the order corresponding to the weighted ranking. InSynth supports invocation \nat any loca\u00adtion immediately following declaration of a typed value, variable or a method, i.e. in the \nplace of its de.nition and also at the place of method parameters, if condition expressions, and similar \n(where the type can be inferred). InSynth uses the Scala presentation com\u00adpiler to extract program declarations \nand imported API functions visible at a given point. InSynth can be easily con.gured though standard \nEclipse preference pages, and the user can set maximum execution time of the synthesis process, desired \nnumber of synthe\u00adsized solutions and code style of Scala snippets. 7.2 Creating Benchmarks There is \nno standardized set of benchmarks for the problem that we examine, so we constructed our own benchmark \nsuite. We collected examples primarily from http://www.java2s.com/. These ex\u00adamples illustrate correct \nusage of Java API functions and classes in various scenarios. We manually translated the examples from \nJava into equivalent Scala code. Since only single class imports are used in the original examples, we \ngeneralized the import statements for the benchmarks to include more declarations and thereby made the \nsynthesis problem more dif.cult by increasing the size of the search space. One idea of measuring the \neffectiveness of a synthesis tool is to estimate its ability to reconstruct certain expressions from \nexisting code. We arbitrarily chose some expressions from the collected examples, removed them and marked \nthem as goal expressions that needed to be synthesized (we replaced them with a fresh value de.nition \nif the place of the expression was not valid for InSynth invocation). The resulting benchmark is a partial \nprogram, similar to a program sketch [23]. We measure whether InSynth can reconstruct an expression equal \nto the one removed, modulo literal constants (of integer, string, or boolean type). Our benchmark suite \nis available for download from the InSynth web site.  7.3 Corpus for Computing Symbol Usage Frequencies \nOur algorithm searches for typed terms that can be derived from the initial environment and that minimize \nthe weight function. To compute initial declaration weights we follow the steps presented in Section \n4. The key step is to derive declarations frequencies. Hence, we collected a code corpus which dictates \nthose initial weights. The corpus contains code statistics from 18 Java and Scala open-source projects. \nTable 3 lists those projects together with their description. One of the analyzed projects is the Scala \ncompiler, which is mainly written in the Scala language itself. In addition to the projects listed in \nTable 3, we analyzed the Scala standard library, which mainly consists of wrappers around Java API calls. \nWe ex\u00adtracted the relevant information only about Java and Scala APIs, and ignored information speci.c \nto the projects themselves. Over\u00adall, we extracted 7516 declarations and identi.ed a total of 90422 uses \nof these declarations. 98% of declarations have less than 100 Table 2. Results of measuring overall effectiveness. \nThe .rst 4 columns denote the ordinal and name of a benchmark, size of the desired snippet (in terms \nof number of declarations: with coercion function accounted/only visible) and the initial number of declarations \nseen at the invocation point. The subsequent columns denote the rank at which the desired snippet was \nfound and (averaged) execution times in milliseconds for the algorithm with no weights, with weight but \nwithout use of input statistics, and with weights and input statistics (with the distribution of execution \ntime between the engine and reconstruction parts). The last two columns show execution time for checking \n No weights No corpus All Provers Benchmarks Size #Initial Rank Total Rank Total Rank Prove Recon Total \nImogen fCube 1 AWTPermissionStringname 2/2 5615 >10 5157 1 101 1 8 125 133 127 20123 2 BufferedInputStreamFileInputStream \n3/2 3364 >10 2235 1 45 1 7 46 53 44 5827 3 BufferedOutputStream 3/2 3367 >10 2009 1 18 1 7 11 19 44 5781 \n4 BufferedReaderFileReader.leReader 4/2 3364 >10 2276 2 69 1 7 43 50 44 0176 5 BufferedReaderInputStreamReader \n4/2 3364 >10 2481 2 66 1 7 42 49 44 0175 6 BufferedReaderReaderin 5/4 4094 >10 5185 >10 4760 6 7 237 \n244 61 0228 7 ByteArrayInputStreambytebuf 4/4 3366 >10 5146 3 94 >10 4 18 22 44 5836 8 ByteArrayOutputStreamintsize \n2/2 3363 >10 2583 2 51 2 8 63 70 44 5204 9 DatagramSocket 1/1 3246 >10 5024 1 74 1 7 80 88 38 5555 10 \nDataInputStreamFileInput 3/2 3364 >10 2643 1 20 1 6 46 52 44 5791 11 DataOutputStreamFileOutput 3/2 3364 \n>10 5189 1 29 1 7 38 45 44 5839 12 DefaultBoundedRangeModel 1/1 6673 >10 3353 1 220 1 10 257 266 193 \n36337 13 DisplayModeintwidthintheightintbit 2/2 4999 >10 6116 1 136 1 6 147 154 99 10525 14 FileInputStreamFileDescriptorfdObj \n2/2 3366 >10 3882 3 24 2 6 17 23 44 3929 15 FileInputStreamStringname 2/2 3363 >10 2870 1 125 1 9 100 \n109 44 4425 16 FileOutputStreamFile.le 2/2 3364 >10 4878 1 86 1 8 51 60 44 4415 17 FileReaderFile.le \n2/2 3365 >10 3484 2 37 2 7 13 20 44 4495 18 FileStringname 2/2 3363 >10 3697 1 169 1 7 155 163 44 5859 \n19 FileWriterFile.le 2/2 3366 >10 4255 1 40 1 8 28 36 45 4515 20 FileWriterLPT1 2/2 3363 6 3884 1 139 \n1 7 89 96 44 4461 21 GridBagConstraints 1/1 8402 >10 3419 1 3241 1 19 323 342 290 0121 22 GridBagLayout \n1/1 8401 >10 2 1 1 1 0 1 1 290 56553 23 GroupLayoutContainerhost 4/2 6436 >10 4055 1 24 1 10 26 36 190 \n29794 24 ImageIconString.lename 2/2 8277 >10 3625 2 495 1 13 154 167 300 50576 25 InputStreamReaderInputStreamin \n3/3 3363 >10 3558 8 90 4 7 177 184 44 4507 26 JButtonStringtext 2/2 6434 >10 3289 2 117 1 9 85 95 184 \n27828 27 JCheckBoxStringtext 2/2 8401 >10 3738 3 134 2 18 50 68 188 4946 28 JformattedTextFieldAbstractFormatter \n3/2 10700 >10 3087 2 2048 4 21 101 122 520 99238 29 JFormattedTextFieldFormatterformatter 2/2 9783 >10 \n3404 2 67 2 15 85 100 419 74713 30 JTableObjectnameObjectdata 3/3 8280 >10 3676 2 109 2 13 129 142 300 \n46738 31 JTextAreaStringtext 2/2 6433 >10 2012 2 232 >10 9 293 302 183 29601 32 JToggleButtonStringtext \n2/2 8277 >10 3171 2 177 2 12 123 135 299 5231 33 JTree 1/1 8278 2 3534 1 3162 1 16 2022 2039 298 52417 \n34 JViewport 1/1 8282 8 5017 1 20 8 12 7 19 298 22946 35 JWindow 1/1 6434 3 4274 1 296 1 10 425 434 194 \n2862 36 LineNumberReaderReaderin 5/4 3363 >10 2315 >10 3770 9 6 233 239 44 5876 37 ObjectInputStreamInputStreamin \n3/2 3367 >10 3093 1 20 1 6 29 35 44 5849 38 ObjectOutputStreamOutputStreamout 3/2 3364 >10 4883 1 31 \n1 7 47 54 44 5438 39 PipedReaderPipedWritersrc 2/2 3364 >10 2762 2 54 2 8 60 68 44 262 40 PipedWriter \n1/1 3359 >10 4801 1 107 1 6 133 139 44 5432 41 Pointintxinty 3/1 4997 >10 2068 5 133 2 6 96 103 101 8573 \n42 PrintStreamOutputStreamout 3/2 3365 >10 2100 6 16 1 7 20 27 44 5841 43 PrintWriterBufferedWriter 4/3 \n3365 >10 2521 4 135 4 8 36 44 44 448 44 SequenceInputStreamInputStreams 5/3 3365 >10 4777 2 35 2 8 20 \n28 44 5862 45 ServerSocketintport 2/2 4094 >10 2285 2 28 1 6 57 63 61 11123 46 StreamTokenizerFileReader.leReader \n3/2 3365 >10 2012 1 34 1 8 57 65 44 5782 47 StringReaderStrings 2/2 3363 >10 2006 1 35 1 6 37 43 45 5746 \n48 TimerintvalueActionListeneract 3/3 6665 >10 2051 1 123 1 10 189 199 186 34841 49 TransferHandlerStringproperty \n2/2 8648 >10 3911 1 27 1 14 17 31 319 67997 50 URLStringspecthrows 3/3 4093 >10 3302 6 124 1 8 175 183 \n60 11197 provability using the Imogen and fCube provers. uses in the entire corpus, whereas the maximal \nnumber of occur\u00adrences of a single declaration is 5162 (for the symbol &#38;&#38;).  7.4 Platform for \nExperiments We ran all experiments on a machine with a 3Ghz clock speed pro\u00adcessor and 8MB of cache. \nWe imposed a 2GB limit for allowed memory usage. Software con.guration consisted of Ubuntu 12.04.1 LTS \n(64b) with Scala 2.9.3 (a nightly version), and Java(TM) Vir\u00adtual Machine 1.6.0 24. The reconstruction \npart of InSynth is imple\u00admented sequentially and does not make use of multiple CPU cores.  7.5 Measuring \nOverall Effectiveness In each benchmark, we invoked InSynth at the place where the goal expression was \nmissing. We parametrized InSynth with N=10 and used a time limit of 0.5s seconds for prover (Section \n5.6) and 7s for the reconstruction. By using a time limit, our goal was to evaluate the usability of \nInSynth in an interactive environment (which IDEs usually are). We ran InSynth on the set of 50 benchmarks. \nResults are shown in Table 2. The Size column represents the size of the goal expres\u00adsion in terms of \nnumber of declarations in its structure. It is illus\u00adtrated in the form c/nc where c is the size with \ncoercion functions and nc is the size without. Note that when c>nc holds, InSynth needs to deal with \nsubtyping to synthesize the goal expression. The #Initial column represents the size of the initial environment, \ni.e. the number of initial type declarations that InSynth extracts at a given program point. The following \ncolumns are partitioned into three groups, one for each variant of the synthesis algorithm: 1) the  \nProject Akka CCSTM GooChaSca Kestrel LiftWeb LiftTicket O/R Broker scala0.orm ScalaCheck Scala compiler \nScala Migrations ScalaNLP ScalaQuery Scalaz simpledb-scala-binding smr Specs Talking Puf.n Description \nTransactional actors Software transactional memory Google Charts API for Scala Tiny queue system based \non starling Web framework Issue ticket system JDBC framework with support for externalized SQL O/R mapping \ntool Unit test automation Compiles Scala source to Java bytecode Database migrations Natural language \nprocessing Typesafe database query API Scala on steroidz -scala extensions Bindings for Amazon s SimpleDB \nMap Reduce implementation Behaviour Driven Development framework Twitter client Table 3. Scala open-source \nprojects used for the corpus extraction. algorithm without weights (the No weights column), 2) the algo\u00adrithm \nwith weights derived without the corpus (the No corpus col\u00adumn) and 3) .nally, the full algorithm, with \nweights derived using the corpus (the All column). In all groups, Rank represents the rank of the goal \nexpres\u00adsion in the resulting list, and Total represents the total execution time of synthesis. The distribution \nof the execution time between prover and the reconstruction is shown in columns Prove and Re\u00adcon, respectively. \nThe last column group gives execution times of two state-of-the-art intuitionistic theorem provers (Imogen \n[19] and fCube [9]) employed for checking provability of inhabitation prob\u00adlems for the benchmarks. Table \n2 shows the differences in both effectiveness and execu\u00adtion time between the variants of the algorithm. \nFirst, the table shows that the algorithm without weights does not perform well and .nds the goal expressions \nin only 4 out of 50 cases and executes by more than an order of magnitude slower than the other variants. \nThis is due to the fact that without the utilization of the weight function to guide the search, InSynth \nis driven into a wrong direction toward less important solutions, whose ranks are as low as the actual \nsolutions. Second, we can see that adding weights to terms helps the search drastically and the algorithm \nwithout corpus fails to .nd the goal expression in only 2 cases. Also, the running times are decreased \nsubstantially. In 33 cases, this variant .nds the solution with the same rank as the variant which incorporates \ncorpus, while on 4 of them it .nds the solution of a higher rank. This suggests that in some cases, synthesis \ndoes not bene.t from the derived corpus initial weights de.ned by it are not biased favorably and do \nnot direct the search toward the goal expression. Third, we show the times for Imogen and fCube provers \non the same set of benchmarks. We can see that our prover is up to 2 orders of magnitude faster than \nImogen and up to 4 orders than fCube. Note that reconstruction of terms in Imogen was limited to 10 seconds \nand Imogen failed to reconstruct a proof within that time limit in all cases. In the case of the full \nalgorithm, the results show that the desired expressions appear in the top 10 suggested snippets in 48 \nbenchmarks (96%). They appear as the top snippet (with rank 1) in 32 benchmarks (64%). Note that our \ncorpus (Section 7.3) is derived from a source code base that is disjoint (and somewhat different in nature) \nfrom the one used for benchmarks. This suggests that even a knowledge corpus derived from unrelated code \nincreases the effectiveness of the synthesis process; a specialized corpus would probably further increase \nthe quality of results. In summary, the expected snippets were found among the top 10 solutions in many \nbenchmarks. Weights play an important role in .nding and ranking those snippets high in a short period \nof time (on average around just 145ms). Finally, our prover outperforms two state of the art provers \nImogen and fCube. These results sug\u00adgest that InSynth is effective in quickly .nding (i.e. synthesizing) \ndesired expressions at various places in source code. 8. Related Work Several tools including Prospector \n[18], XSnippet [22], Strathcona [13], PARSEWeb [27] and SNIFF [4] that generate or search for relevant \ncode examples have been proposed. In contrast to all these tools we support expressions with higher order \nfunctions. Addition\u00adally, we synthesize snippets using all visible methods in a context, whereas the \nother existing tools build or present them only if they exist in a corpus. Prospector, Strathcona and \nPARSEWeb do not incorporate the extracted examples into the current program con\u00adtext; this requires additional \neffort on the part of the programmer. Moreover, Prospector does not solve queries with multiple argu\u00adment \nmethods unless the user initiates multiple queries. In contrast, we generate full expressions using just \na single query. We could not effectively compare InSynth with those tools, since unfortunately, the authors \ndid not report exact running times. We next provide more detailed descriptions for some of the tools, \nand we compare their functionality to InSynth. InSynth is similar in operation to Eclipse content assist \nproposals [26] and it implements the same behaviour. More advanced solutions appeared recently, such \nas [3], that proposes declarations, and the Eclipse code recommenders [8], that suggests declarations \nand code tem\u00adplates. Both systems use API declaration call statistics from the ex\u00adisting code examples \nin order to offer suggestions to the developer with appropriate statistical con.dence value. InSynth \nis fundamen\u00adtally different from these approaches (it even subsumes them) and can synthesize even code \nfragments that never previously occurred in code. Prospector [18] uses a type graph and searches for \nthe short\u00adest path from a receiver type, typein, to the desire type, typeout. The nodes of the graph \nare monomorphic types, and the edges are the names of the methods. The nodes are connected based on the \nmethod signature. Prospector also encodes subtypes and down\u00adcasts into the graph. The query is formulated \nthrough typein and typeout. The solution is a chain of method calls that starts at typein and ends at \ntypeout. Prospector ranks solutions by the length, pre\u00adferring shorter solutions. In contrast, we .nd \nsolutions that have minimal weights. This potentially enables us to get solutions that have better quality, \nsince the shortest solution may not be the most relevant. Furthermore, in order to .ll in the method \nparameters, a user needs to initiate multiple queries in Prospector. In InSynth this is done automatically. \nProspector uses a corpus for down-casting, whereas we use it to guide the search and rank the solutions. \nMore\u00adover, Prospector has no knowledge of what methods are used most frequently. Unfortunately, we could \nnot compare our implementa\u00adtion with Prospector, because it was not publicly available. XSnip\u00adpet [22] \noffers a range of queries from generalized to specialized. The tool uses them to extract Java code from \nthe sample reposi\u00adtory. XSnippet ranks solutions based on their length, frequency, and context-sensitive \nas well as context-independent heuristics. In order to narrow the search the tool uses the parental structure \nof the class where the query is initiated to compare it with the parents of the classes in the corpus. \nThe returned examples are not adjusted auto\u00admatically into a context the user needs to do this manually. \nSimi\u00adlar to Prospector the user needs to initiate additional queries to .ll in the method parameters. \nIn Strathcona [13], a query based on the structure of the code under development is automatically extracted. \nOne cannot explicitly specify the desired type. Thus, the returned set of examples is often irrelevant. \nMoreover, in contrast to InSynth, those examples can not be .tted into the code without additional in\u00adterventions. \nPARSEWeb [27] uses the Google code search engine to get relevant code examples. The solutions are ranked \nby length and frequency. In InSynth the length of a returned snippet also plays an important role in \nranking the snippets but InSynth also has an additional component by taking into account also the proximity \nof derived snippets and the point where InSynth was invoked. The main idea behind the SNIFF [4] tool \nis to use natural language to search for code examples. The authors collected the corpus of ex\u00adamples \nand annotated them with keywords, and attached them to corresponding method calls in the examples. The \nkeywords are col\u00adlected from the available API documentation. InSynth is based on a logical formalism, \nso it can overcome the gap between program\u00adming languages and natural language.  The synthesized code \nin our approach is extracted from the proof derivation. Similar ideas have been exploited in the context \nof sophisticated dependently typed languages and proof assistants [1]. Our goal is to apply it to simpler \nscenarios, where proposi\u00adtions are only partial speci.cations of the code, as in the current programming \npractice. Agda is a dependently typed programming language and proof assistant. Using Agda s Emacs interface, \npro\u00adgrams can be developed incrementally, leaving parts of the program un.nished. By type checking the \nun.nished program, the program\u00admer can get useful information on how to .ll in the missing parts. The \nEmacs interface also provides syntax highlighting and code navigation facilities. However, because it \nis a new language and lacks large examples, it is dif.cult to evaluate this functionality on larger numbers \nof declarations. There are several tools for the Haskell API search. The Hoogle [14] search engine searches \nfor a single function that has either a given type or a given name in Haskell, but it does not return \na composed expression of the given type. The Hayoo [12] search engine does not use types for searching \nfunctions: its search is based on function names. The main difference between Djinn [25] and our system \nis that Djinn generates a Haskell expression of a given type, but unlike our system it does not use weights \nto guide the algorithm and rank solutions. Recently we have witnessed a renewed interest in semi-automated \ncode completion [20]. The tool [20] generates partial expressions to help a programmer write code more \neasily. While their tool helps to guess the method name based on the given arguments, or it suggests \narguments based on the method name, we generate complete expressions based only on the type constraints. \nIn addition, our approach also supports higher order functions, and the returned code snippets can be \narbitrarily nested and complex: there is no bound on the number and depth of arguments. This allows us \nto automatically synthesize larger pieces of code in practice, as our evaluation shows. In that sense, \nour result is a step further from simple completion to synthesis. The use of type constraints was explored \nin interactive theorem provers, as well as in synthesis of code fragments. SearchIsos [5] uses type constraints \nto search for lemmas in Coq, but it does not use weights to guide the algorithm and rank the solutions. \nHav\u00ading the type constraints, a natural step towards the construction of proofs is the use of the Curry-Howard \nisomorphism. The drawback of this approach is the lack of a mechanism that would automati\u00adcally enumerate \nall the proofs. By representing proofs using graphs, the problem of their enumeration was shown to be \ntheoretically solvable [29], but there is a large gap between a theoretical result and an effective tool. \nFurthermore, InSynth can not only enumerate terms but also rank them and return a desired number of best-ranked \nones. Having a witness term that a type is inhabited is a vital ingredi\u00adent of our tool, so one could \nthink of InSynth as a prover for propo\u00adsitional intuitionistic logic (with substantial additional functional\u00adity). \nAmong recent modern provers are Imogen [19] and fCube [9]. These tools can reason about more expressive \nfragments of logic: they support not only implication but also intuitionistic counter\u00adparts for other \npropositional operators such as ., ., ., and Imo\u00adgen also supports .rst-order and not only propositional \nfragment. Our results on fairly large benchmarks suggests that InSynth is faster for our purpose. This \nis not entirely surprising because these tools are not necessarily optimized for the task that we aim \nto solve (looking for shallow proofs from many assumptions), and often do not have ef.cient representation \nof large initial environments. The main purpose of our comparison is to show that our technique is no \nworse than the existing ones for our purpose, even when used to merely check the existence of proofs. \nWhat is more important than performance is that InSynth produces not only one proof, but a rep\u00adresentation \nof all proofs, along with their ranking. This additional functionality of our algorithm is essential \nfor the intended applica\u00adtion: using type inhabitation as a generalization of code completion. For a \ngiven type InSynth produces a .nite representation of all the type inhabitants. In general, if an expression \nis an inhabitant of the given type, there is a derivation that proves that fact. Us\u00ading Curry-Howard \nisomorphism for each proof derivation there is a lambda term representing it. The problem of enumerating \nall the proofs for a given formula is an important research topic, since it can be also used to answer \nother problems like provability or de.n\u00adability. We keep the system of patterns to represent all the \ntype in\u00adhabitants, achieving this way .nite representation of a possibly in.\u00adnite set of the proofs. \nIn [7] the authors used a semi-grammatically description of all proof-terms for minimal predicate logic \nand a positive sequent calculus. The use of grammars is an alternative to our use of graphs as the representation \nfor all solutions; we there\u00adfore expect that grammars could similarly be used as the starting point for \na practical system such as ours. 9. Conclusions We have presented the design and implementation of a \ncode com\u00adpletion inspired by complete implementation of type inhabitation for the simply typed lambda \ncalculus. Our algorithm uses succinct types, an ef.cient representation for types, terms, and environments \nthat takes into account that the order of assumptions is unimpor\u00adtant. Our approach generates a representation \nof all solutions (a set of pattens), from which it can extract any desired number of solu\u00adtions. To further \nincrease the usefulness of generated results, we in\u00adtroduce the ability to assign weights to terms and \ntypes. The re\u00adsulting algorithm performs search for expressions of a given type in a type environment \nwhile minimizing the weight, and preserves the completeness. The presence of weights increases the quality \nof the generated results. To compute weights we use the proximity to the declaration point as well as \nweights mined from a corpus. We have deployed the algorithm in an IDE for Scala. Our evaluation on synthesis \nproblems constructed from API usage indicate that the technique is practical and that several technical \ningredients had to come together to make it powerful enough to work in practice. Our tool and additional \nevaluation details are publicly available. Our experience suggests that the idea of computing type inhab\u00aditats \nusing succinct types and weights is useful by itself. Moreover, our subsequent exploration suggests that \nthese techniques can also serve as the initial phase of semantic-based synthesis [16]. The idea is to \ngenerate a stream of type-correct solutions and then .lter it to contain only expressions that meet given \nspeci.cations, such as postconditions (or, in the special case, input/output examples). Note that the \napproach based on the techniques we presented can also generate programs with various control patterns, \nbe\u00adcause conditionals, loops, and recursion schemas can themselves be viewed as higher-order functions. \nAlthough we believe the current results to be a good starting point for such tasks, further techniques \nmay be needed to control larger search spaces for more complex code correctness criteria and larger expected \ncode sizes.  Acknowledgments We thank the anonymous reviewers of PLDI 2013 for useful feed\u00adback. We \nare grateful to Iulian Dragos and the Scala IDE team for the collaboration on integrating InSynth into \nScala IDE. We thank Martin Odersky, Aleksandar Prokopec, and Sean McLaugh\u00adlin for useful discussions. \nTihomir Gvero is supported by the Eu\u00adropean Research Council (ERC) Project Implicit Programming , http://lara.epfl.ch/w/impro. \nIvan Kuraj was supported by a Google Summer of Code project. References [1] A. Bove, P. Dybjer, and U. \nNorell. A brief overview of Agda -a functional language with dependent types. In TPHOLs, 2009. [2] V. \nBreazu-Tannen, T. Coquand, C. A. Gunter, and A. Scedrov. Inheritance as implicit coercion. Inf. Comput., \n93:172 221, July 1991. ISSN 0890-5401. doi: 10.1016/0890-5401(91)90055-7. [3] M. Bruch, M. Monperrus, \nand M. Mezini. Learning from examples to improve code completion systems. In ESEC/SIGSOFT FSE, pages \n213 222, 2009. [4] S. Chatterjee, S. Juvekar, and K. Sen. SNIFF: A search engine for java using free-form \nqueries. FASE 09, pages 385 400, 2009. [5] D. Delahaye. Information retrieval in a Coq proof library \nusing type isomorphisms. In TYPES, pages 131 147, 1999. [6] G. Dowek. Higher-order uni.cation and matching. \nHandbook of automated reasoning, II:1009 1062, 2001. [7] G. Dowek and Y. Jiang. Enumerating proofs of \npositive formulae. Comput. J., 52(7):799 807, Oct. 2009. ISSN 0010-4620. [8] Eclipse Code Recommenders. \nhttp://www.eclipse.org/recommenders/. [9] M. Ferrari, C. Fiorentini, and G. Fiorino. fCube: An ef.cient \nprover for intuitionistic propositional logic. In LPAR (Yogyakarta), 2010. [10] T. Gvero, V. Kuncak, \nand R. Piskac. Interactive synthesis of code snippets (tool demonstration). In 23rd Int. Conf. Computer \nAided Veri.cation, July 14-20, 2011. [11] T. Gvero, V. Kuncak, I. Kuraj, and R. Piskac. On complete completion \nusing types and weights. Technical report, EPFL, December 2012. [12] Hayoo! API Search. http://holumbus.fh-wedel.de/hayoo/hayoo.html. \n[13] R. Holmes and G. C. Murphy. Using structural context to recommend source code examples. ICSE 05, \npages 117 125, 2005. [14] Hoogle API Search. http://www.haskell.org/hoogle/. [15] IntelliJ IDEA website, \n2011. URL http://www.jetbrains.com/idea/. [16] I. Kuraj. Interactive code generation. Master s thesis, \nEPFL, February 2013. [17] Z. Luo. Coercions in a polymorphic type system. Mathematical Structures in \nComputer Science, 18(4):729 751, 2008. [18] D. Mandelin, L. Xu, R. Bod\u00b4ik, and D. Kimelman. Jungloid \nmining: helping to navigate the api jungle. In PLDI, 2005. [19] S. McLaughlin and F. Pfenning. Ef.cient \nintuitionistic theorem proving with the polarized inverse method. In CADE, 2009. [20] D. Perelman, S. \nGulwani, T. Ball, and D. Grossman. Type-directed completion of partial expressions. In PLDI, pages 275 \n286, 2012. [21] J. C. Reynolds. Using category theory to design implicit conversions and generic operators. \nIn Semantics-Directed Compiler Generation, pages 211 258, 1980. [22] N. Sahavechaphan and K. Claypool. \nXsnippet: mining for sample code. In OOPSLA, 2006. ISBN 1-59593-348-4. [23] A. Solar-Lezama, G. Arnold, \nL. Tancau, R. Bod\u00b4ik, V. A. Saraswat, and S. A. Seshia. Sketching stencils. In PLDI, 2007. [24] R. Statman. \nIntuitionistic propositional logic is polynomial-space complete. Theoretical Computer Science, 9(1):67 \n 72, 1979. [25] The Djinn Theorem Prover. http://www.augustsson.net/Darcs/Djinn/. [26] The Eclipse Foundation. \nhttp://www.eclipse.org/. [27] S. Thummalapenta and T. Xie. PARSEWeb: a programmer assistant for reusing \nopen source code on the web. In ASE, 2007. [28] P. Urzyczyn. Inhabitation in typed lambda-calculi (a \nsyntactic approach). In TLCA, 1997. [29] J. B. Wells and B. Yakobowski. Graph-based proof counting and \nenumeration with applications for program fragment synthesis. In LOPSTR, pages 262 277, 2004.    \n\t\t\t", "proc_id": "2491956", "abstract": "<p>Developing modern software typically involves composing functionality from existing libraries. This task is difficult because libraries may expose many methods to the developer. To help developers in such scenarios, we present a technique that synthesizes and suggests valid expressions of a given type at a given program point. As the basis of our technique we use type inhabitation for lambda calculus terms in long normal form. We introduce a succinct representation for type judgements that merges types into equivalence classes to reduce the search space, then reconstructs any desired number of solutions on demand. Furthermore, we introduce a method to rank solutions based on weights derived from a corpus of code. We implemented the algorithm and deployed it as a plugin for the Eclipse IDE for Scala. We show that the techniques we incorporated greatly increase the effectiveness of the approach. Our evaluation benchmarks are code examples from programming practice; we make them available for future comparisons.</p>", "authors": [{"name": "Tihomir Gvero", "author_profile_id": "81351597325", "affiliation": "Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland", "person_id": "P4148925", "email_address": "tihomir.gvero@epfl.ch", "orcid_id": ""}, {"name": "Viktor Kuncak", "author_profile_id": "81100277693", "affiliation": "Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland", "person_id": "P4148926", "email_address": "viktor.kuncak@epfl.ch", "orcid_id": ""}, {"name": "Ivan Kuraj", "author_profile_id": "81758642457", "affiliation": "Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland", "person_id": "P4148927", "email_address": "ivan.kuraj@epfl.ch", "orcid_id": ""}, {"name": "Ruzica Piskac", "author_profile_id": "81384606465", "affiliation": "Max Planck Institute for Software Systems (MPI-SWS), Saarbrucken, Germany", "person_id": "P4148928", "email_address": "piskac@mpi-sws.org", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462192", "year": "2013", "article_id": "2462192", "conference": "PLDI", "title": "Complete completion using types and weights", "url": "http://dl.acm.org/citation.cfm?id=2462192"}