{"article_publication_date": "06-16-2013", "fulltext": "\n SPLLIFT Statically Analyzing Software Product Lines in Minutes Instead of Years Eric Bodden1 T \u00b4arsis \nTol edo3 M \u00b4arcio Ribeiro3,4 Claus Brabrand2 Paulo Borba3 Mira Mezini1 1 EC SPRIDE, Technische Universit\u00a8at \nDarmstadt, Darmstadt, Germany 2 IT University of Copenhagen, Copenhagen, Denmark 3 Federal University \nof Pernambuco, Recife, Brazil 4 Federal University of Alagoas, Macei \u00b4o, Brazil bodden@acm.org, {twt, \nphmb}@cin.ufpe.br, marcio@ic.ufal.br, brabrand@itu.dk, mira.mezini@cased.de Abstract A software product \nline (SPL) encodes a potentially large variety of software products as variants of some common code base. \nUp until now, re-using traditional static analyses for SPLs was virtu\u00adally intractable, as it required \nprogrammers to generate and analyze all products individually. In this work, however, we show how an \nimportant class of existing inter-procedural static analyses can be transparently lifted to SPLs. Without \nrequiring programmers to change a single line of code, our approach SPLLIFT automatically converts any \nanalysis formulated for traditional programs within the popular IFDS framework for inter-procedural, \n.nite, distributive, subset problems to an SPL-aware analysis formulated in the IDE framework, a well-known \nextension to IFDS. Using a full imple\u00admentation based on Heros, Soot, CIDE and JavaBDD, we show that \nwith SPLLIFT one can reuse IFDS-based analyses without chang\u00ading a single line of code. Through experiments \nusing three static analyses applied to four Java-based product lines, we were able to show that our approach \nproduces correct results and outperforms the traditional approach by several orders of magnitude. Categories \nand Subject Descriptors F.3.2 [Logics and Meanings of Programs]: Semantics of Programming Languages Program \nanalysis General Terms Design, Languages, Performance Keywords Software product lines, inter-procedural \nstatic analysis, context sensitive, .ow sensitive 1. Introduction A Software Product Line (SPL) describes \na set of software prod\u00aducts as variations of a common code base. Variations, so-called features, are \ntypically expressed through compiler directives such as the well-known # ifdef from the C pre-processor \nor other means of conditional compilation. Figure 1a shows a minimal example prod\u00ad uct line that assigns \nvalues through different methods. Figure 1b shows the product obtained by applying to the product line \na pre\u00adprocessor with the con.guration \u00acF . G . \u00acH, i.e., a product with feature G enabled and features \nF and H disabled. Software product lines have become quite popular in certain application domains, for \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n13, June 16 19, 2013, Seattle, WA, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . \n$15.00 v o i d main () { i n t x = secret(); i n t y= 0; # i f d e f F x = 0 ; # e n d i f # i f d e \nf G y = foo(x); # e n d i f print (y); } i n t foo ( i n t p) { # i f d e f H p = 0 ; # e n d i f r \ne t u r n p ; } (a) Example SPL v o i d main () { i n t x = secret(); i n t y= 0; y = foo(x); print \n(y); } i n t foo ( i n t p) { r e t u r n p ; } (b) Product for \u00acF . G . \u00acH Figure 1: Example product \nline: secret is printed if F and H are disabled but G is enabled instance for the development of games \nand other applications for mobile devices. This is due to the tight resource restrictions of those devices: \ndepending on the hardware capabilities of a certain mobile device, it may be advisable or not to include \ncertain features in a software product for that device, or to include a variant of a given feature. Static \nprogram analyses are a powerful tool to .nd bugs in program code [1 3] or to conduct static optimizations \n[4], and it is therefore highly desirable to apply static analyses also to software product lines. With \nexisting approaches, though, it is often prohibitively expensive to reuse existing static analyses. The \nproblem is that traditional static analyses cannot be directly applied to software product lines. Instead \nthey have to be applied to pre\u00adprocessed programs such as the one from Figure 1b. But for an SPL with \nn optional, independent features, there are 2n possible products, which therefore demands thousands of \nanalysis runs even for small product lines. This exponential blowup is particularly annoying because \nmany of those analysis runs will have large overlaps for different feature combinations. It therefore \nseems quite bene.cial to share analysis information wherever possible. In this work we introduce SPLLIFT, \na simple but very effective approach to re-using existing static program analyses without an exponential \nblowup. SPLLIFT allows programmers to transparently lift an important class of existing static analyses \nto software prod\u00aduct lines. Our approach is fully inter-procedural. It works for any analysis formulated \nfor traditional programs within Reps, Horwitz and Sagiv s popular IFDS [5] framework for inter-procedural, \n.nite, distributive, subset problems. In the past, IFDS has been used to express a variety of analysis \nproblems such as secure information .ow [1], typestate [2, 3, 6], alias sets [7], speci.cation inference \n[8], and shape analysis [9, 10]. SPLLIFT automatically converts any such analysis to a feature-sensitive \nanalysis that operates on the entire product line in one single pass. The converted analysis is formulated \nin the IDE framework [11] for inter-procedural distributed environ\u00ad ment problems, an extension to IFDS. \nIn cases in which the original analysis reports that a data-.ow fact d may hold at a given statement \ns, the resulting converted analysis reports a feature constraint under which d may hold at s. As an example, \nconsider again Figure 1. Imagine that we are conducting a taint analysis [1], determining whether information \ncan .ow from secret to print. In the tradi\u00adtional approach we would generate and analyze all 23 = 8 possible \nproducts individually, eventually discovering that the product from Figure 1b may indeed leak the secret. \nSPLLIFT instead analyzes the product line from Figure 1a in a single pass, informing us that secret may \nleak for the con.guration \u00acF . G . \u00acH (cf. Fig. 1b).  But a reduced analysis time is not the only advantage \nof a feature-sensitive static analysis. In the area of software product lines, conditional-compilation \nconstructs may add much complexity to the code, and can yield subtle and unusual programming mistakes \n[12, 13]. As an example, a plain Java program will not compile if it uses a potentially unde.ned local \nvariable. In a Java-based software product line, any pre-processor would accept such a program; the programming \nproblem would only manifest later, when the pre\u00adprocessed program is compiled. When the mistake is discovered, \nit is laborsome to map the resulting plain-Java error message back to the original product line. Analyzing \nthe product line directly, as in SPLLIFT, circumvents this problem. To obtain meaningful results, SPLLIFT \nfurther takes feature models into account. A feature model de.nes a Boolean constraint that describes \nthe set of all feature combinations that a user intends to generate, the SPL s valid con.gurations (or \nvalid products). For instance, if we were to evaluate the SPL from Figure 1a under the constraint F . \nG (stating that the user intends to generate only products for which both F and G are either enabled \nor disabled), SPLLIFT would detect that the secret information cannot leak after all, as it holds that: \n(\u00acF . G . \u00acH) . (F . G) = false. Considering a feature model complicates the analysis, which may cause \none to expect an increase in analysis cost. Fortunately, our experimental results show that this, in \nfact, is not usually the case. SPLLIFT can gain speed by exploiting the model, terminating the analysis \nfor constraint-violating program paths early. This balances out the expected slowdown in many cases. \nWe have fully implemented SPLLIFT within Heros [14], a self\u00ad written IDE solver integrating with the \nprogram-analysis framework Soot [15], extending this solver to product lines and connecting Soot to CIDE, \nthe Colored IDE [16], an Eclipse [17] extension for writing and maintaining Java-based software product \nlines. Using our solution, existing IFDS-based analyses are automatically converted to feature-sensitive \nversions without changing a single line of code. We used SPLLIFT to lift three standard inter-procedural \nstatic program analyses, and then applied them to four existing CIDE\u00ad a mechanism for automatically \nand transparently converting any IFDS-based static program analysis to an IDE-based analysis over software \nproduct lines,  a full open-source implementation for Java, and  a set of experiments showing that \nour approach yields correct results and outperforms the traditional approach by several orders of magnitude. \n The remainder of this paper is structured as follows. In Section 2, we introduce the IFDS and IDE frameworks, \nalong with their strengths and limitations. Section 3 contains the core of this paper; here we explain \nthe automated lifting of IFDS-based analyses to software product lines. Section 4 explains how we take \ninto account the product line s feature model. In Section 5 we discuss our implementation, while we present \nour experimental setup and results in Section 6. The work presented in this paper bases itself on previous \nwork presented at the 2012 ACM SIGPLAN Workshop on Programming Languages and Analysis for Security [18]. \nIn Section 7 we explain the differences to this paper along with the differences to other related work. \n2. The IFDS framework Our approach builds on top of the so-called IFDS framework by Reps, Horwitz and \nSagiv [5]. This framework de.nes a general solution strategy for the inter-procedural, .ow-sensitive, \nand fully context-sensitive analysis of .nite distributive subset problems. In this section we present \nthe general concepts behind this framework and illustrate them by an example. 2.1 Overview of the IFDS \nFramework The major idea of the IFDS framework is to reduce any program\u00adanalysis problem formulated in \nthis framework to a pure graph\u00adreachability problem. Based on the program s inter-procedural control-.ow \ngraph, the IFDS algorithm builds a so-called exploded super graph , in which a node (s, d) is reachable \nfrom a selected start node (s0, 0) if and only if the data-.ow fact d holds at statement s. In this \nsetting a fact may mean any logical statement that a static analysis can decide, such as variable x may \ncarry a secret value or variables x and y may alias. To achieve this goal, the framework encodes data-.ow \nfunctions as nodes and edges. Figure 2 shows how to represent compositions of typical gen and kill functions \nas they are often used in static analysis. The nodes at the top represent facts before the given statement \ns, the nodes at the bottom represent facts after s. The identity function id maps each data-.ow fact \nbefore a statement onto itself. In IFDS, the unique special value 0, represents a tautology, i.e., a \nfact that always holds. It is therefore an invariant that two nodes representing 0 at different statements \nwill always be connected. This 0 value is used to generate data-.ow facts unconditionally. The .ow function \na generates the data-.ow fact a, and at the same time kills the data-.ow fact b (as there is no edge \nfrom b to b). Function \u00df, on the other hand kills a, generates b and leaves all other values (such as \nc) untouched.  Figure 2: Function representation in IFDS, reproduced from [5]  p The unconditional \nkill-and-gen functions above can be used to model analysis problems that are locally separable, i.e., \nin which a data\u00ad.ow fact does not depend on the previous val\u00adues of other facts. Such problems include \nthe computation of reaching de.nitions or live vari-0 x p ables. Many interesting analysis problems are \n0 x non-locally\u00adnot locally separable, however, for instance the separable .ow taint analysis from our \nexample in the introduc\u00adfunction tion. For instance, the function representation to the right could be \nchosen to model an assignment p=x. Here, x has the same value as before the assignment, modeled by the \narrow from x to x, and p obtains x s value, modeled by the arrow from x to p. If p previously held a \nsecret value, then it will only continue doing so if x holds a secret value, too. This is modeled by \na missing arrow from p to p. It is important to note that data-.ow facts are by no means limited to simple \nvalues such as the local variables in our example. Much more sophisticated abstractions exist, in which \nfacts can, for instance, model aliasing through sets of access paths [1] or even the abstract typestate \nof combinations of multiple objects [3]. The IFDS framework itself, however, is oblivious to the concrete \nabstraction being used; the abstraction is a free parameter to the framework.  2.2 Different classes \nof .ow functions Users implement IFDS-based analyses by providing four classes of .ow functions that \ncan be denoted as: normal: modeling .ow through a statement that is neither a call nor a return (incl. \nnon-branching, unconditionally branching and conditionally branching statements),  call: modeling .ow \nfrom a call site to a possible callee,  return: modeling .ow from a possible callee back to a return \nsite, i.e., a control-.ow successor of the original method-call site, and  call-to-return: modeling \nintra-procedural .ow from just before a call site directly to a given return site.  Normal .ow functions \ntrack simple intra-procedural .ows. Call\u00adto-return functions track intra-procedural .ows at call sites; \nthey are useful to propagate, for instance, information about local variables that are not passed to \na method call, as the call cannot possibly change the value of those variables. Call functions map values \nfrom the caller s context to appropriate values in the callee s context. Return functions model the opposite \n.ow, usually from return values to variables that receive those values. Due to this setup, the analysis \nof each method usually only processes information that is in scope within that method. 2.3 Example: \nTaint analysis in IFDS To encode the assignment of a secret value to a variable x we generate a fact \nx. This fact would be killed to denote that x is assigned a de.nitely non-secret value. To illustrate \nthis encoding, Figure 3 shows the exploded super graph for our example client of the IFDS framework, \nthe taint analysis applied to the product from the running example (Figure 1b). The analysis starts at \nthe top-left node, which resembles the starting node (s0, 0), s0 being the starting statement. According \nto the encoding outlined above, the analysis taints the return value at the call to secret() by generating \nthe data-.ow fact for the variable x that holds this value. The analysis then tracks simple assignments \nto local variables and method parameters as stated above. (For now, let us ignore possible assignments \nthrough .elds and arrays. We will comment on those in Section 5.) At the single call site in the example, \nthe call-to-return function keeps x alive, stating that it is still tainted after the call if it was \ntainted earlier. At the same time, it kills y because the call statement is assigning y a new value. \n(Note that at this point y is already dead, due to the preceding assignment.) The call function encodes \nthe transfer of actual to formal parameters. Since the only variable in scope within foo is p, the graph \nfor method foo has nodes for p but not for x nor y. In the example, a taint violation is detected by \nobserving the data .ow marked with the red/thick arrow: the node for y just before the print statement \nis reachable in the graph, which means that a secret value, referred to by y, may be printed.  2.4 The \nIDE Framework Sagiv, Reps and Horwitz also developed a more general, more ex\u00adpressive framework than \nIFDS, called inter-procedural distributive environment transformers (IDE) [11]. As in IFDS, the IDE frame\u00ad \nwork models data .ow through edges in an exploded super graph. In addition to IFDS, however, IDE allows \nfor the computation of distributive functions along those edges: the label d of each node in the exploded \nsuper graph maps to a value v from a second, inde\u00adpendent analysis domain, the so-called value domain \nV . The .ow functions thus transform environments {d . v} to other environ\u00adments {d' . v'}. Every IFDS \nproblem can be encoded as a special instance of the IDE framework using a binary domain {T, .} where \nd . . states that data-.ow fact d holds at the current statement, and d . T states that it does not hold \n[11]. But this binary do\u00ad main is the least expressive instance of a large set of possible value domains. \nThis we can exploit. 3. Using IDE to lift IFDS-based analyses to Software Product Lines The main idea \nof SPLLIFT is to leverage the gap in expressiveness between IFDS and IDE. To lift IFDS-based data-.ow \nanalyses to a feature-sensitive version for software product lines, we replace the binary domain for \nencoding any IFDS problem as a special instance of the IDE framework by a value domain that consists \nof feature constraints. The lifting is based on the following principle: Assume a statement s that is \nannotated with a feature constraint F (i.e., # ifdef (F) s # endif). Then s should have its usual data-.ow \neffect if F holds, and should have no effect if F does not hold. This principle effectively talks about \ntwo different .ow functions: one function fF for the enabled case F , and one function f \u00acF for the disabled \ncase \u00acF . The idea of SPLLIFT is to combine both .ow functions into one, fLIFT := fF . f \u00acF , while using \nconstraints to track traversals of edges labeled with F and \u00acF respectively. (The labeling effectively \noccurs within IDE s value domain V .) The above de.nition depends on the two notions of a what a statement \ns usual effect should be and what it means to have no effect . The general principle of disjoining two \nlabeled .ow functions fF and f \u00acF into one applies to all .ow functions in SPLLIFT. The two component \n.ow functions fF and f \u00acF differ, however, for the different classes of .ow functions that we described \nin Section 2.2. 3.1 Intra-procedural .ow functions First we consider intra-procedural normal .ow functions, \nwhich exist for non-branching, unconditionally branching and condition\u00adally branching statements. Let \nus .rst discuss the most simple case of a non-branching statement s. For the enabled case F , assume \nthat the statement s original .ow function is f(s). In Figure 4a we show on the left the function fF \n, which we de.ne as f(s)F , i.e., a copy of f(s) in which all edges are labeled with F , the feature \nannotation of s. In the .gure, we show the edges as dashed because they are conditionalized by this feature \nannotation. A label F effectively  0 x y normal int x = secret(); control-.ow edge data-.ow edge \n  Figure 3: Exploded super graph for the single example product from Figure 1b; main method shown on \nleft-hand side, foo shown to the right \u00acF Enabled-case .ow func. fF Disabled-case .ow func. f Lifted \n.ow function fLIFT (a) Normal .ow function for non-branching statements, and call-to-return .ow function \nfor invoke statements 0 a b 0 a 0 a b   b F \u00acF \u00acF \u00acF  \u00acF = \u00acF F F .  0 a b 0  a b 0 a b \n(b) Normal .ow function for unconditionally branching statements (goto, throw)  0 a b 0 a b 0 a b a \naa 0 b 0 b 0 b (c) Normal .ow function for conditionally branching statements ( if (p) goto) 0 a b 0 \na b 0 a b F  F \u00acF \u00acF \u00acF  F . \u00acF \u00acF \u00acF = F b 0 0 a b 0 a a b   F  F F \u00acF F \u00acF  . F \n\u00acF \u00acF \u00acF = F 0 0 a b 0 F a b a b 0 a   b 0 a b 0 a b (d) Call .ow function and return .ow function \n0  a b 0 a b  0 a b = F F .  F F 0 a b 0 a b 0 a b Figure 4: Lifting of different .ow functions \nin SPLLIFT denotes the function .c. c . F that will conjoin the incoming con\u00adstraint c with F when the \nedge is traversed. In the disabled case \u00acF , statement s is disabled because its feature annotation F \ncontradicts the current product s feature selection. This means that the statement simply does not change \nthe intra-procedural data-.ow information at all (cf. the identity function in Figure 2). We hence de.ne \nf \u00acF as shown in the middle column: the identity function labeled with \u00acF . Once both functions have \nbeen labeled, we can combine them into a single .ow function as shown in the rightmost column. This function \nfLIFT effectively represents both previous functions at the same time, as a disjunction f F . f \u00acF . \nEdges such as the one from 0 to 0, which are annotated with F in the one function and with \u00acF in the \nother, are implicitly annotated with true. In the follow\u00ading we show such edges as (unconditional) solid \nblack edges. The intra-procedural call-to-return functions are treated exactly the same way. But how \nabout intra-procedural .ows through branching state\u00adments? We conduct our analysis on the Jimple intermediate \nrepre\u00adsentation, a three-address code, for which we need to distinguish unconditional branches like throw \ne and goto l, from conditional branches of the form if (p) goto l. Figure 4b shows how we lift .ow functions \nfor unconditional branches labeled with a feature annotation F . If the throw or goto statement is enabled, \ndata .ow only exists towards the nodes of the branch target (the primed nodes in Figure 4b). Both edges \nwithin this .gure are assumed to be labeled with F . If the statement is disabled, data .ows only along \nthe fall-through branch, as the branch does not actually execute. Again we use the identity function \nin this case. Just as before, the lifted .ow function fLIFT is obtained through a disjunction of both \nfunctions.  For conditional branches of the form if (p) goto l, the lifted .ow function is basically \na combination of the cases for the unconditional branch and the normal data .ow , which models the case \nin which the branch falls through. We show the respective case in Figure 4c. The disabled case \u00acF is \nhandled just as for unconditional branches; if a branch is disabled, it just falls through, no matter \nwhether it is conditional or not.  3.2 Inter-procedural .ow functions The call and return .ow functions \nmodel inter-procedural control .ows caused by call and return statements. The general idea behind modeling \nthose functions is the same as in the intra-procedural case, however this time we need to consider a \ndifferent .ow function for the disabled case, i.e., when \u00acF holds. Remember that a call .ow function \nleads from a call site to its callee, and a return .ow function from a return statement to just after \nthe call site. Using the identity function to model such situations would be incorrect: If we were to \nuse the identity function then this would propagate information from the call site to the callee (respectively \nvice versa) although under \u00acF the call (or return) never occurs. We must hence use the kill-all function \nto model this situation, as shown in Figure 4d (middle column). This function kills all data-.ow facts, \nmodeling that no .ow between call site and callee occurs if the invoke statement is disabled. 3.3 Computing \nreachability as a useful side effect It is an interesting question to ask whether we should conditionalize \nedges between 0 nodes. As explained earlier, in plain IFDS/IDE, 0 nodes are always connected, unconditionally. \nWe decided for the design shown in Figure 4 where edges between 0 nodes are in fact conditionalized by \nfeature annotations just as any other edges. This has the advantage that, as a side effect, our analysis \ncomputes reachability information: a constraint c that SPLLIFT computes for a node (s, 0), i.e., an environment \n(s, {0 . c}), tells the programmer that s is reachable only in product con.gurations satisfying c. This \ndesign also prevents our implementation to propagate 0-facts through code that is unreachable according \nto the feature model. 3.4 Combining .ow functions and initializing .ows As the analysis explores a path \nin the exploded super graph, we combine all constraint annotations along the path using conjunction. \nAfter all, all constraints on that path must hold for the .ow to be possible. At control-.ow merge points \nwe combine constraints using disjunction, as we could have reached the program point along different \npaths. We initialize the analysis with the constraint true at the program s start node (s0, 0), and with \nfalse at all other nodes.  3.5 Application to running example In Figure 5, we show how our generic .ow-function \nconversion rules are applied to our speci.c running example of our inter-procedural taint analysis, operating \non our example product line from Figure 1a. In the .gure, the violating information .ow leads to the \nfollowing constraint: (true . \u00acF . G . \u00acH . G) . (false . \u00acG) = \u00acF . G . \u00acH Note that this is exactly \nthe constraint that our introduction promised our analysis would compute. 4. Considering the SPL s feature \nmodel In the introduction we already hinted at the fact that it is generally necessary to consider a \nproduct line s feature model during analysis. Without considering the feature model both the lifted and \nthe traditional feature-oblivious analysis may simply produce useless information as the analysis would \nbe unable to distinguish results for valid con.gurations from those for invalid ones (cf. Section 1). \n4.1 Computing the feature-model constraint from the feature model Feature models are usually given in \nthe form of a graphical tree rep\u00adresentation with additional propositional constraints. As proposed by \nBatory [19], we translate the model into a single propositional constraint by creating a conjunction \nof: (i) a bi-implication between every mandatory feature and its parent, (ii) an implication from every \noptional feature to its parent, (iii) a bi-implication from the parent of every OR group to the disjunction \nof the components of said group; and (iv) a bi-implication from the parent of every exclusive-OR group, \nE, to the conjunction of: the pair-wise mutual exclusion of the components E and the disjunction of the \ncomponents of E.  4.2 Taking advantage of the feature-model constraint SPLLIFT uses the feature model \nas follows: for an edge label f and a Boolean feature-model constraint m SPLLIFT implicitly assumes that \nthe edge is instead labeled with f . m. Our tool automatically reduces contradictory constraints to false, \nwhich causes the IDE algorithm to automatically terminate computations for paths that result in such \na contradictory constraint. Due to the fact that the constraint m complicates the overall constraint \ncomputation during the buildup of the exploded super graph, one may expect slowdowns over a version of \nSPLLIFT that ignores the feature model. However, our particular style of imple\u00admentation allows for an \nearly termination of the IDE algorithm. As our experiments show, this often counterbalances the slowdown \neffect. Consider again the example of Figure 5, and in this .gure the top-most node labeled with p. During \nour analysis, when we reach this node, we will have computed the path constraint \u00acF . G. In combination \nwith the feature model F . G, already at this point we obtain: \u00acF . G . F . G = false. But this means \nthat any further data .ow along this path of the graph is actually infeasible. We can hence terminate \nfurther analysis along this path early. Note that .rst we tried an even simpler solution: just replace \nthe start value true at the program s start node by the feature\u00admodel constraint m [18]. While this yields \nthe same analysis results eventually, we found that it wastes performance. The problem is that the IDE \nalgorithm spends most time constructing the graph and internal summary functions, and spends only very \nlittle time actually propagating values through the graph. Exchanging the start value only leads to early \ntermination in the propagation phase but not in the costly construction phase. By conjoining the edge \nconstraints with m we terminate early in the construction phase already, saving the algorithm from computing \nsummary functions that, according to the model, would carry contradictory Boolean constraints. 5. Implementation \nwith Soot and CIDE We have implemented SPLLIFT based on Heros [14], our IDE solver which integrates \nwith the Soot program analysis and transformation framework [15], the Colored Integrated Development \nEnvironment (CIDE) [16] and the JavaBDD1 library. We have implemented an IDE solver [11] in Soot that \nworks directly on Soot s intermediate representation Jimple . Jimple is a three-address code representa\u00adtion \nof Java programs that is particularly simple to analyze. Jimple 1JavaBDD website: http://javabdd.sourceforge.net/ \n  true false false 0 x y  control-.ow edge int x = secret();  data-.ow edge 0 x y conditional data-.ow \nedge int y = 0; violating information .ow 0 x y false  Figure 5: SPLLIFT as it is applied to the \nentire example product line of Figure 1a; an edge labeled with feature constraint C represents the function \n.x. x . C. Constraints at nodes represent initial values (at the top) or intermediate results of the \nconstraint computation. statements are never nested, and all control-.ow constructs are reduced to simple \nconditional and unconditional branches. Soot can produce Jimple code from Java source code or bytecode, \nand compile Jimple back into bytecode or into other intermediate repre\u00adsentations. To be able to actually \nparse software product lines, we used CIDE, an extension of the Eclipse IDE [17]. In CIDE, software produce \nlines are expressed as plain Java programs. This makes them comparatively easy to parse: there are no \nexplicit compiler directives such as # ifdef that a parser would need to handle. Instead, code variations \nare expressed by marking code fragments with different colors. Each color is associated with a feature \nname. In result, every CIDE SPL is also a valid Java program. CIDE forbids so-called undisciplined annotations, \ni.e., enforces that users mark code regions that span entire statements, members or classes. Previous \nresearch has shown that undisciplined annotations do exist in real-world projects but that they can often \nbe eliminated by code expansion [20]. One performance critical aspect of our implementation is what data \nstructures we use to implement the feature constraints that SPLLIFT tracks. After some initial experiments \nwith a hand-written data structure representing constraints in Disjunctive Normal Form, we switched to \nan implementation based on Binary Decision Di\u00adagrams (BDDs) [21], using JavaBDD. Reduced BDDs have the \nadvantage that they are compact and normalized, which allows us to easily detect and exploit contradictions. \nThe size of a BDD can heavily depend on its variable ordering. In our case, because we did not perceive \nthe BDD operations to be a bottleneck, we just pick one ordering and leave the search for an optimal \nordering to future work. Current Limitations # i f d e f F Our current implementation is x = n ew A r \nr a y L i s t ( ) ; # e l s e not as sensitive to feature an\u00ad notations as it could be. This x = n ew \nL i n k e d L i s t ( ) ; is mostly due to the fact that # e n d i f IFDS/IDE requires the pres\u00ad x. add \n(o); ence of a call graph, and currently we compute this call graph with\u00adout taking feature annotations \ninto account. While we follow call\u00adgraph edges in a feature sensitive fashion (as de.ned by our call \n.ow function), the feature-insensitive call graph is also used to compute points-to sets. This precludes \nus from precisely handling situations such as the one shown above. Here, we would conservatively resolve \nthe add-call to both ArrayList.add and LinkedList.add, irrespec\u00adtive of whether F is enabled. In other \nwords, we would propagate the constraint true along the respective call edges. This is sound but not \nmaximally precise. Ideally, our points-to analysis should be feature sensitive as well, propagating F \nto ArrayList.add and \u00acF to LinkedList.add. One could solve this problem by ignoring the pre-computed \npoints-to analysis and handling pointers as part of the IFDS abstraction, e.g., as done by Guarnieri \net al. [1]. Due to our tool chain, our implementation is currently limited to software product lines \nexpressed with CIDE. Having said that, there is nothing that precludes our approach from being applied \nto product lines described in different ways. We are, in fact, currently considering how SPLLIFT could \nbe applied to C, using the TypeChef parser [22]. The C pre-processor features # ifdef constructs that \nare more expressive than the ones in CIDE, and the C language includes more constructs for unstructured \ncontrol .ow than Java. Our current implementation ignores re.ective calls, but those could be treated \nwith approaches such as TamiFlex [23]. Last but not least, SPLLIFT is limited to analyses expressed in \nthe IFDS framework, which requires that the analyses must have .ow functions that are distributive over \nthe merge operator (set union). This is the case for many but not all analysis problems. In the future \nwe plan to investigate to what extent the same ideas are transferable to more expressive static analysis \nframeworks, for instance weighted pushdown systems [24]. 6. Experiments We used a set of extensive experiments \nto answer the following research questions about our implementation: RQ1: Correctness Does SPLLIFT compute \na sound result?  RQ2: Ef.ciency How much ef.ciency do we gain over the traditional feature-oblivious \napproach?  RQ3: Feature Model What is the cost of using the feature model?  6.1 RQ1: Correctness To \nvalidate the correctness of our SPLLIFT implementation, we need an oracle that can tell apart correct \nfrom incorrect results. As an oracle, we implemented a second, simplistic analysis that is also feature \naware but not constraint based. This analysis essentially corresponds to an inter-procedural version \nof the analysis A2 from our earlier publication [25], and we therefore call the analysis A2 in the remainder \nof this paper. A2 operates on the feature-annotated control-.ow graph just as SPLLIFT, however unlike \nSPLLIFT A2 is con.guration-speci.c, i.e., evaluates the product line only with respect to one concrete \ncon.guration c = {F1, . . . , Fn} at a time. If a statement s is labeled with a feature constraint F \nthen A2 .rst checks whether c satis.es F to determine whether s is enabled. If it is, then A2 propagates \n.ow to s s standard successors using the standard IFDS .ow function de.ned for s. If c does not satisfy \nF then A2 uses the identity function to propagate intra-procedural .ows to fall-through successor nodes \nonly. The implementation of A2 is so simple that we consider it as foolproof. We hence assume this A2 \nimplementation as correct, and can therefore use it as an oracle to cross-check the results of SPLLIFT. \nWhenever A2 computes a fact r for some con.guration c, we fetch SPLLIFT s computed feature constraint \nC for r (at the same statement), and check that C allows for c. This ensures that SPLLIFT is not overly \nrestrictive. The other way around, we traverse all of SPLLIFT s results (r, c) for the given .xed c, \nand check that the instance of A2 for c computed each such r as well (at the same statement). This ensures \nthat SPLLIFT is as precise as A2, i.e., does not report any false positives. Our cross-checks initially \nhelped us to .nd bugs in the implementation of SPLLIFT, but we quickly converged to an implementation \nthat does not violate any cross-checks any more.  6.2 RQ2: Ef.ciency To evaluate the performance of \nour approach, we chose four dif\u00adferent product lines used in earlier work [25]. We apply to each benchmark \nsubject three different static analyses both emulating the traditional approach (details below) and using \nSPLLIFT. Table 1 summarizes some core data about these subjects. BerkeleyDB is a feature-enriched database \nlibrary. GPL is a small product line for desktop applications, while Lampiro and MM08 are product lines \nfor J2ME applications. Because whole-program analyses require entry points to start with, we programmed \ndriver classes for three of the benchmarks. For the J2ME SPLs, those methods call life-cycle methods \nusually called by the J2ME framework. For BerkeleyDB, our main class calls the main methods of all driver \nclasses that BerkeleyDB includes. The driver classes are available for download along with all other \ndata and tools to reproduce the experiments. The third column in Table 1 gives the total number of features \nas mentioned in the feature model. The fourth column states the number of features mentioned in feature \nannotations that are actually reachable from our main classes. For Lampiro this number is surprisingly \nlow. K \u00a8 astner reports that the current version of Lampiro is unusual in the sense that it contains \nmany dead features and other anomalies, which may be the explanation of this effect [16, pages 131 132]. \nColumn .ve states the number of con.gurations over those features, i.e., 2Features-reachable. The last \ncolumn states the number of such con.gurations that are valid w.r.t. the feature model. For instance, \nfor Lampiro the feature model ended up not constraining the 4 combinations of the 2 reachable features. \nFor BerkeleyDB, we do not know the number of valid con.gurations. This is because we compute this number \nas a side-effect of running the traditional approach: for each possible con.guration we .rst check whether \nit is valid and, if it is, next apply the traditional analysis approach to this con.guration. But for \nBerkeleyDB, due to the 55 \u00b7 1010 possible con.gurations, this process would take years to complete. For \neach benchmark/analysis combination we de.ne a cutoff time of ten hours, which is why we cannot report \nthe number of valid con.gurations for BerkeleyDB. As analysis clients we used three different generic \nIFDS-based inter-procedural client analyses. Possible Types computes the possi\u00adble types for a value \nreference in the program. Such information can, for instance, be used for virtual-method-call resolution \n[4]. We track typing information through method boundaries. Field and array as\u00adsignments are treated \nwith weak updates in a .eld-sensitive manner, abstracting from receiver objects through their context-insensitive \npoints-to sets. Reaching De.nitions is a reaching-de.nitions anal\u00adysis that computes variable de.nitions \nfor their uses. To obtain inter-procedural .ows, we implement a variant that tracks de.ni\u00adtions through \nparameter and return-value assignments. Uninitialized Variables .nds potentially uninitialized variables. \nAssume a call foo(x), where x is potentially uninitialized. Our analysis will deter\u00admine that all uses \nof the formal parameter of foo may also access an uninitialized value. We provide the source code for \nall three clients (only approx. 550LOC) in our download package. We include the Java 1.7 runtime libraries \nin our analysis. To evaluate the ef.ciency of SPLLIFT against the actual tradi\u00adtional approach, we would \nideally want to use a pre-processor to generate all possible products, and then apply the traditional \nanal\u00adysis approach to each resulting product, an approach which in our earlier work [25] we called A1 \n. However, we quickly found that this approach is so intractable that it would even preclude us from \n.nishing our experiments in due time. This is because the traditional approach would need to generate, \nparse and analyze every single product. A prerequisite for each analysis is a call graph, whose com\u00adputation \ncan easily take minutes on its own. Given the large number of possible con.gurations, it would have taken \nus years to complete the experiments. (Brabrand et al. [25] did not have this problem because their intra-procedural \nanalyses need no call graph and must only consider up to 2k combinations where k is the maximal number \nof features within a single method. For our four benchmark subjects k is always = 9.) We hence decided \nto compare SPLLIFT not to A1 but instead to our implementation of A2 , which only requires a single parsing \nstep and call-graph computation. A2 is thus naturally faster than A1 , and therefore any performance \ngain we can show with respect to A2 would be even higher with respect to A1. We found that even with \nusing A2, some experiments would still take years to complete, though, which is why we nevertheless use \na cutoff-time of ten hours. For our performance measurements we used a Linux machine with kernel version \n2.6.26-1 running on a Quad-Core AMD Opteron Processor 8356 at 2.3GhZ and with 40GB RAM. As Java Virtual \nMachine we used the Hotspot server VM in version 1.7.0 05, con\u00ad.gured to run with 32GB maximal heap space. \nTo make our results easier to reproduce, we con.gured Eclipse to run all analyses with\u00adout requiring \na user interface. Our implementation is single-threaded. JavaBDD was con.gured to use the BuDDy2 BDD \npackage, which implements BDD operations in native code. Table 2 shows our performance comparison between \nSPLLIFT and A2 , based on a single measured run each. In those experiments, both approaches make use \nof the feature model. For convenience, the second column shows again the number of valid con.gurations. \nThe A2 analysis needs to be executed that many times, once for each con.guration. The third column shows \nthe time it takes Soot to 2BuDDy website: http://buddy.sf.net/   Con.gurations Benchmark valid Soot/CG \nBerkeleyDB unknown 7m33s GPL 1,872 4m35s 9h03m39s Lampiro 4 1m52s 4s 13s 42s 3m30s 1m25s 3m09s MM08 \n26 2m57s 3s 2m06s 59s 24m29s 2m13s 27m39s Table 2: Performance comparison of SPLLIFT over A2; values \nin gray show coarse estimates  Features Con.gurations Benchmark KLOC total reachable reachable valid \nBerkeleyDB 84.0 56 39 55 \u00b7 1010 unknown GPL 1.4 29 19 524,288 1,872 Lampiro 45.0 20 2 4 4 MM08 5.7 34 \n9 512 26 Table 1: Key information about benchmarks used construct a call graph and points-to sets for \nthe respective benchmark. This time is the same for SPLLIFT and A2 , as both require a call graph as \nprerequisite. As the table shows, SPLLIFT outperforms A2 clearly. While SPLLIFT never takes more than \nabout 12 minutes to terminate, A2 always takes signi.cantly longer. In .ve cases (shown in gray), A2 \neven took longer than our cut-off time of ten hours. When this was the case we estimated the rough time \nit would take A2 to terminate if we had run it to completion. We computed this estimate by taking the \naverage of a run of A2 with all features enabled and with no features enabled and then multiplying by \nthe number of valid con.gurations. (For BerkeleyDB we estimated the number of valid con.gurations by \nextrapolating the results obtained within 10 hours.) As this estimation has a relatively low con.dence, \nwe only report a very coarse prognosis of days or years. Notice that, while the absolute performance \ngain certainly differs depending on the client analysis and chosen product line, the gain is always substantial, \nand in particular the exponential blowup that A2 suffers from cannot be observed with SPLLIFT . Qualitative \nperformance analysis During our experiments, we found a relatively high variance in the analysis times. \nAs we found, this is caused due to non-determinism in the order in which the IDE solution is computed. \nAs a .xed-point algorithm, IDE computes the same result independently of iteration order, but some orders \nmay compute the result faster (computing fewer .ow functions) than others. The non-determinism is hard \nto avoid; it is caused by hash-based data structures within Soot and our solver. We did .nd, however, \nthat the analysis time taken strongly correlates with the number of .ow functions constructed in the \nexploded super\u00adgraph (the correlation coef.cient was above 0.99 in all cases). Moreover, in all our benchmark \nsetups, the A2 analysis for the full con.guration , in which all features are enabled, constructed almost \nas many edges as SPLLIFT did on its unique run. While SPLLIFT deals with a much more complex analysis \ndomain, i.e., performs more work per edge, our experimental results show that this additional cost is \nrather low.  6.3 RQ3: Feature Model Regarding a product line s feature model is crucial to any analysis \napproach for software product lines, as otherwise the analysis would be unable to distinguish results \nfor valid con.gurations from those for invalid ones, yielding analysis information that would be of little \nuse to clients. Nevertheless it is an interesting question to ask how high is the cost of regarding the \nfeature model. Table 3 compares the running Benchmark Feature Model P. Types R. Def. U. Var. regarded \n24s 12m04s 10m18s BerkeleyDB ignored 23s 11m35s 10m47s average A2 21s 9m35s 7m12s regarded 42s 8m48s \n7m09s GPL ignored 18s 8m21s 7m29s regarded 4s 42s 1m25s Lampiro ignored 4s 48s 1m13s average A2 3s 42s \n49s regarded 3s 59s 2m13s MM08 ignored 2s 45s 1m49s Table 3: Performance impact of feature model on \nSPLLIFT. Values in gray show the average time of the A2 analysis. This number can be seen as lower bound \nfor any feature-sensitive analysis. time of SPLLIFT with the running time of an instance of SPLLIFT where \nthe feature model was explicitly ignored. As our results show, there is usually no signi.cant difference \nin analysis cost. Exceptions are GPL with Possible Types and, to a lesser extent, MM08 with all three \nanalyses. In both cases, the cost of regarding the feature model is clearly observable, albeit far from \nprohibitive. Apel et al. [26] previously observed as well that regarding the feature model does usually \nnot add much cost during analysis. Interestingly, those results are quite different from the ones we \nobtained in our previous approach on intra-procedural analysis for software product lines [25]. There \nwe found that regarding the feature model actually saved time. Our explanation for this difference in \nresults is that the intra-procedural analyses from our earlier work use a different, bitset-based constraint \nrepresentation. This representation is likely less ef.cient than the BDD-based one in SPLLIFT, which \ncauses the baseline to be much higher. With a higher baseline, the inclusion of the feature model can \nsave more time, as the feature model can help to keep analysis con.gurations small. With SPLLIFT the \nbaseline is quite low already. To illustrate this, we included in Table 3 the average duration of all \nexecuted A2 analyses for the respective setup. Since A2 is so simple, it is hard to imagine a feature-sensitive \nanalysis (which by its nature considers all con.gurations, not just one as A2 ) that would complete in \nless time. As the comparison with those values shows, the analysis time of SPLLIFT is often actually \nquite close to this gold standard. 7. Related Work The work presented in this paper extends an initial \neffort on applying the IFDS and IDE analysis frameworks to SPLs [18]. In the earlier work, we only considered \nnormal .ow functions. Here we signi.cantly re.ne the technique and implementation. In particular, to \nachieve soundness and improve performance, we now consider feature model constraints. In our earlier \nwork, we were still speculating about what could be an ef.cient representation for Boolean constraints. \nIn this work we present a solution based on BDDs that is highly ef.cient. In our eyes, BDDs are crucial \nto the performance of SPLLIFT; we found that others do not scale nearly as well for the Boolean operations \nwe require. Finally, for the .rst time we present empirical evidence of the bene.ts of our approach. \n Our work can also be seen as an extension to an approach by Brabrand et al., who present a number of \nmechanisms to lift intra\u00adprocedural data-.ow analyses to SPLs by extending the analysis abstraction with \nfeature constraints [25]. Our approach, on the other hand, lifts information and data-.ow analyses to \nSPLs in an inter\u00adprocedural fashion, using a different analysis framework, and in particular requiring \nno extension of the analysis abstraction. In SPLLIFT, the implementation of the IFDS .ow functions can \nremain unchanged. To the best of our knowledge SPLLIFT is the .rst work that supports such transparent \nreuse of analyses. Another crucial difference is our ef.cient encoding of the distributive Boolean operations \nthrough BDDs in the IDE framework. TypeChef [22, 27] is a parser and analysis engine for product lines \nwritten in C. It can parse the entire Linux kernel, including macros and # ifdef constructs (including \nundisciplined uses), and performs data-.ow analysis. Opposed to SPLLIFT, all analyses are intra-procedural, \nthough, and use a customized analysis domain, thus not providing no support for reusing standard analyses \nin the way we do. We plan to integrate SPLLIFT with TypeChef. Th\u00a8 um et al. survey analysis strategies \nfor SPLs [28], focusing on parsing [22], type checking [26, 29], model checking [30, 31], and veri.cation \n[32 34]. The surveyed work does not include SPL data-.ow analysis approaches, but shares with our work \nthe general goal of checking properties of a SPL with reduced redundancy and ef.ciency. Similar to SPLLIFT, \na number of approaches covered by the survey adopt a family-based analysis strategy, manipulating only \nfamily artifacts such as code assets and feature model. Contrasting, product-based strategies, such as \nthe generate-and-analyze approach we use as baseline, manipulate products and therefore might be too \nexpensive for product lines having a large number of products. Product-based strategies, however, might \nbe appealing because they can simply reuse existing analyses, but this is also the case of the speci.c \nfamily-based strategy proposed here. In the testing context, Kim et al. use conventional inter\u00adprocedural \ndata-.ow analysis to identify features that are reachable from a given test case [35]. The test case \nis then only executed with the SPL products that have these features, reducing the number of combinations \nto test. They are able to use an off-the-shelf analy\u00adsis because they express part of the variability \nusing conditional statements, not conditional compilation or other feature tagging mechanisms. This is \nsimilar to the technique of con.guration lift\u00ading [32], which converts compile time variability into \nruntime variability. In this paper we propose a feature-sensitive analysis to obtain more precision. \nBy applying our family-based analysis followed by their product-based testing one could maybe further \nreduce the effort to test an SPL. Similar bene.ts might apply for other testing approaches based on conventional \nanalyses [36] or even feature-sensitive model level analyses [37]. The idea of making data.ow analysis \nsensitive to statements that may or may not be executed is related to path-sensitive data.ow anal\u00adysis. \nSuch analyses compute different analysis information along different execution paths aiming to improve \nprecision by disregard\u00ading spurious information from infeasible paths [38] or to optimize frequently \nexecuted paths [39]. Earlier, disabling infeasible dead statements has been exploited to improve the \nprecision of constant propagation [40] by essentially running a dead-code analysis capa\u00ad ble of tagging \nstatements as executable or non-executable during constant propagation analysis. Predicated data.ow analysis \n[41] introduced the idea of using propositional logic predicates over runtime values to derive so-called \noptimistic data.ow values guarded by predicates. Such analyses are capable of producing multiple analysis \nversions and keeping them distinct during analysis. However, their predicates are over dynamic state \nrather than SPL feature constraints for which everything is statically decidable. SPLLIFT can be applied \nto a number of contexts, but much motivation comes from the concept of emergent interfaces [42]. These \ninterfaces emerge on demand to give support for speci.c SPL maintenance tasks and thus help developers \nunderstand and manage dependencies between features. Such dependencies are generated by feature-sensitive \nanalyses such as the ones discussed here. In particular, the performance improvements we obtain are very \nimportant to make emergent interfaces useful in practice. 8. Conclusion We have presented SPLLIFT, an \napproach and framework for trans\u00adparently lifting IFDS-based static analysis to software product lines \nusing the more expressive framework IDE. Using a set of experi\u00adments we were able to show that it can \noutperform the traditional feature-oblivious generate-and-analyze approach by several orders of magnitude. \nIn practice, SPLLIFT successfully avoids the exponen\u00adtial blowup usually associated with SPL analysis. \nWe believe this to be primarily the case because, due to its .ne\u00adgrained representation of analysis facts, \nSPLLIFT performs splits and joins of con.gurations as sparsely as possible. Moreover, SPLLIFT piggybacks \nonto the user-de.ned IFDS-based analysis a layer of Boolean feature constraints. The functions generating \nthose Boolean constraints are distributive and hence .nd a very ef.cient encoding in the IDE framework. \nMoreover, we encode all Boolean constraints using minimized binary decision diagrams (BDDs). The Boolean \noperations we require are conjunction, disjunction, negation and is false . The two latter operations \nare constant-time on minimized BDDs. Conjunction and disjunction are, on average, ef.cient on BDDs, too. \nThe JavaBDD engine we use further memoizes the result of all BDD operations, which speeds up repetitive \noperations to constant time. In the future we plan to apply SPLLIFT to C. Further, we will investigate \nthe performance impact of BDD variable orderings, and to what extent a similar lifting approach can be \napplied also to static-analysis frameworks that are more expressive than IFDS. Acknowledgements Thanks \nto Ond.rej Lhot \u00b4 ak for providing useful hints on optimizing BDDs! We also wish to thank the developers \nof CIDE, JavaBDD and Soot for making their tools available to us and for their continuing support. Thanks \nto Phil Pratt-Szeliga and Marc-Andr\u00b4ere-Papineau, who provided help with e Laverdi `analyzing J2ME MIDlets. \nThanks also to Sven Apel who provided helpful feedback on an earlier version of this paper. This work \nwas supported by the BMBF within EC SPRIDE, by the Hessian LOEWE excellence initiative within CASED, \nby the DFG within the project RUNSECURE, and the Brazilian National Institute of Science and Technology \nfor Software Engineering (INES). Finally, we would like to acknowledge the .nancial support from CNPq, \nFACEPE and a CAPES PROBRAL project. References [1] S. Guarnieri, M. Pistoia, O. Tripp, J. Dolby, S. Teilhet, \nand R. Berg, Saving the world wide web from vulnerable JavaScript, in Proc. 2011 int. symp. on Software \nTesting and Analysis, ser. ISSTA 11, 2011, pp. 177 187. [2] S. J. Fink, E. Yahav, N. Dor, G. Ramalingam, \nand E. Geay, Effective typestate veri.cation in the presence of aliasing, ACM Trans. Softw. Eng. Methodol., \nvol. 17, no. 2, pp. 9:1 9:34, May 2008. [3] N. A. Naeem and O. Lhotak, Typestate-like analysis of multiple \ninteracting objects, in OOPSLA, 2008, pp. 347 366.  [4] V. Sundaresan, L. Hendren, C. Raza.mahefa, R. \nVall\u00b4ee-Rai, P. Lam, E. Gagnon, and C. Godin, Practical virtual method call resolution for Java, in OOPSLA, \n2000, pp. 264 280. [5] T. Reps, S. Horwitz, and M. Sagiv, Precise interprocedural data.ow analysis via \ngraph reachability, in Proc. 22nd ACM SIGPLAN-SIGACT symp. on Principles of programming languages, ser. \nPOPL 95, 1995, pp. 49 61. [6] E. Bodden, Ef.cient hybrid typestate analysis by determining continuation-equivalent \nstates, in ICSE 2010, May 2010, pp. 5 14. [7] N. A. Naeem and O. Lhot\u00b4 ak, Ef.cient alias set analysis \nusing SSA form, in Proc. 2009 int. symp. on Memory Management, ser. ISMM 09, 2009, pp. 79 88. [8] S. \nShoham, E. Yahav, S. Fink, and M. Pistoia, Static speci.cation mining using automata-based abstractions, \nIEEE TSE, vol. 34, no. 5, pp. 651 666, 2008. [9] N. Rinetzky, M. Sagiv, and E. Yahav, Interprocedural \nshape analysis for cutpoint-free programs, in Static Analysis, ser. Lecture Notes in Computer Science, \nC. Hankin and I. Siveroni, Eds. Springer Berlin / Heidelberg, 2005, vol. 3672, pp. 284 302. [10] H. Yang, \nO. Lee, J. Berdine, C. Calcagno, B. Cook, D. Distefano, and P. O Hearn, Scalable shape analysis for systems \ncode, in CAV, 2008, pp. 385 398. [11] M. Sagiv, T. Reps, and S. Horwitz, Precise interprocedural data.ow \nanalysis with applications to constant propagation, in TAPSOFT 95, 1996, pp. 131 170. [12] C. K \u00a8astner \nand S. Apel, Virtual separation of concerns -a second chance for preprocessors, Journal of Object Technology, \nvol. 8, no. 6, pp. 59 78, 2009. [13] C. K\u00a8astner, S. Apel, and M. Kuhlemann, Granularity in Software \nProduct Lines, in Proc. 30th int. conf. on Software Engineering (ICSE 08), 2008, pp. 311 320. [14] E. \nBodden, Inter-procedural data-.ow analysis with ifds/ide and soot, in SOAP 2012, Jul. 2012, pp. 3 8, \nheros website: http://sable.github. com/heros/. [15] R. Vall\u00b4ee-Rai, L. Hendren, V. Sundaresan, P. Lam, \nE. Gagnon, and P. Co, Soot -a Java optimization framework, in Proceedings of CASCON 1999, 1999, pp. 125 \n135. [Online]. Available: www.sable.mcgill.ca/publications [16] C. K \u00a8astner, Virtual separation of concerns, \nPh.D. dissertation, Uni\u00adversit\u00a8at Magdeburg, 2010. [17] The Eclipse IDE, http://eclipse.org/. [18] E. \nBodden, Position Paper: Static .ow-sensitive &#38; context-sensitive information-.ow analysis for software \nproduct lines, in PLAS 2012, Jun. 2012, pp. 6:1 6:6. [19] D. Batory, Feature models, grammars, and propositional \nformulas, in Software Product Lines (SPLC) 2005, ser. LNCS, vol. 3714, 2005, pp. 7 20. [20] J. Liebig, \nC. K \u00a8astner, and S. Apel, Analyzing the discipline of preprocessor annotations in 30 million lines of \nc code, in Proc. 10th int. conf. on Aspect-oriented software development, ser. AOSD 11, 2011, pp. 191 \n202. [21] R. Drechsler and B. Becker, Binary decision diagrams: theory and implementation. Springer, \n1998. [22] C. K \u00a8astner, P. G. Giarrusso, T. Rendel, S. Erdweg, K. Ostermann, and T. Berger, Variability-aware \nparsing in the presence of lexical macros and conditional compilation, in Proc. 2011 ACM int. conf. on \nObject oriented programming systems languages and applications, ser. OOPSLA 11, 2011, pp. 805 824. [23] \nE. Bodden, A. Sewe, J. Sinschek, H. Oueslati, and M. Mezini, Taming re.ection: Aiding static analysis \nin the presence of re.ection and custom class loaders, in ICSE 2011, May 2011, pp. 241 250. [24] T. Reps, \nS. Schwoon, and S. Jha, Weighted pushdown systems and their application to interprocedural data.ow analysis, \nin Static Analysis, ser. Lecture Notes in Computer Science, R. Cousot, Ed. Springer Berlin / Heidelberg, \n2003, vol. 2694, pp. 1075 1075. [25] C. Brabrand, M. Ribeiro, T. Tol edo, and P. Borba, Intraprocedural \ndata.ow analysis for software product lines, in Proc. 11th annual int. conf. on Aspect-oriented Software \nDevelopment, ser. AOSD 12, 2012, pp. 13 24. [26] S. Apel, C. K\u00a8osslinger, and C. Lengauer, Type safety \nastner, A. Gr \u00a8for feature-oriented product lines, Automated Software Eng., vol. 17, no. 3, pp. 251 300, \nSep. 2010. [27] Typechef analysis engine, http://ckaestne.github.com/TypeChef/. [28] T. Th \u00a8astner, M. \nKuhlemann, I. Schaefer, and G. Saake, um, S. Apel, C. K\u00a8 Analysis strategies for software product lines, \nSchool of Computer Science, University of Magdeburg, Tech. Rep. FIN-004-2012, Apr. 2012. [29] C. K \u00a8 \n\u00ad astner and S. Apel, Type-checking software product lines a formal approach, in Proc. 2008 23rd IEEE/ACM \nint. conf. on Automated Software Engineering, ser. ASE 08, 2008, pp. 258 267. [30] A. Classen, P. Heymans, \nP.-Y. Schobbens, A. Legay, and J.-F. Raskin, Model checking lots of systems: ef.cient veri.cation of \ntemporal properties in software product lines, in Proc. 32nd ACM/IEEE int. conf. on Software Engineering \n-Volume 1, ser. ICSE 10, 2010, pp. 335 344. [31] A. Classen, P. Heymans, P.-Y. Schobbens, and A. Legay, \nSymbolic model checking of software product lines, in Proc. 33rd int. conf. on Software Engineering, \nser. ICSE 11, 2011, pp. 321 330. [32] H. Post and C. Sinz, Con.guration lifting: Veri.cation meets software \ncon.guration, in Proc. 2008 23rd IEEE/ACM int. conf. on Automated Software Engineering, ser. ASE 08, \n2008, pp. 347 350. [33] C. H. P. Kim, E. Bodden, D. Batory, and S. Khurshid, Reducing con.gurations to \nmonitor in a software product line, in Proc. First int. conf. on Runtime veri.cation, ser. RV 10, 2010, \npp. 285 299. [34] S. Apel, H. Speidel, P. Wendler, A. von Rhein, and D. Beyer, Detection of feature interactions \nusing feature-aware veri.cation, in Proc. 2011 26th IEEE/ACM int. conf. on Automated Software Engineering, \nser. ASE 11, 2011, pp. 372 375. [35] C. Hwan, P. Kim, D. Batory, and S. Khurshid, Reducing combinatorics \nin testing product lines, in Proc. 10th int. conf. on Aspect-oriented Software Development (AOSD 11), \n2011, pp. 57 68. [36] J. Shi, M. Cohen, and M. Dwyer, Integration testing of software product lines using \ncompositional symbolic execution, in Fundamental Approaches to Software Engineering, ser. Lecture Notes \nin Computer Science, J. de Lara and A. Zisman, Eds. Springer Berlin / Heidelberg, 2012, vol. 7212, pp. \n270 284. [37] V. Stricker, A. Metzger, and K. Pohl, Avoiding redundant testing in application engineering, \nin Software Product Lines: Going Beyond, ser. Lecture Notes in Computer Science, J. Bosch and J. Lee, \nEds. Springer Berlin / Heidelberg, 2010, vol. 6287, pp. 226 240. [38] T. Ball and S. K. Rajamani, Bebop: \na path-sensitive interprocedural data.ow engine, in Proc. 2001 ACM SIGPLAN-SIGSOFT workshop on Program \nanalysis for software tools and engineering, ser. PASTE 01, 2001, pp. 97 103. [39] G. Ammons and J. R. \nLarus, Improving data-.ow analysis with path pro.les, SIGPLAN Not., vol. 39, no. 4, pp. 568 582, Apr. \n2004. [40] M. N. Wegman and F. K. Zadeck, Constant propagation with condi\u00adtional branches, ACM Trans. \nProgram. Lang. Syst., vol. 13, no. 2, pp. 181 210, Apr. 1991. [41] S. Moon, M. W. Hall, and B. R. Murphy, \nPredicated array data\u00ad.ow analysis for run-time parallelization, in Proc. 12th int. conf. on Supercomputing, \nser. ICS 98, 1998, pp. 204 211. [42] M. Ribeiro, H. Pacheco, L. Teixeira, and P. Borba, Emergent feature \nmodularization, in Proc. ACM int. conf. companion on Object oriented programming systems languages and \napplications companion, ser. SPLASH 10, 2010, pp. 11 18.    \n\t\t\t", "proc_id": "2491956", "abstract": "<p>A software product line (SPL) encodes a potentially large variety of software products as variants of some common code base. Up until now, re-using traditional static analyses for SPLs was virtually intractable, as it required programmers to generate and analyze all products individually. In this work, however, we show how an important class of existing inter-procedural static analyses can be transparently lifted to SPLs. Without requiring programmers to change a single line of code, our approach SPLLIFT automatically converts any analysis formulated for traditional programs within the popular IFDS framework for inter-procedural, finite, distributive, subset problems to an SPL-aware analysis formulated in the IDE framework, a well-known extension to IFDS. Using a full implementation based on Heros, Soot, CIDE and JavaBDD, we show that with SPLLIFT one can reuse IFDS-based analyses without changing a single line of code. Through experiments using three static analyses applied to four Java-based product lines, we were able to show that our approach produces correct results and outperforms the traditional approach by several orders of magnitude.</p>", "authors": [{"name": "Eric Bodden", "author_profile_id": "81100018194", "affiliation": "Technische Universit&#228;t Darmstadt, Darmstadt, Germany", "person_id": "P4149053", "email_address": "eric.bodden@ec-spride.de", "orcid_id": ""}, {"name": "T&#225;rsis Tol&#234;do", "author_profile_id": "81490687651", "affiliation": "Federal University of Pernambuco, Recife, Brazil", "person_id": "P4149054", "email_address": "twt@cin.ufpe.br", "orcid_id": ""}, {"name": "M&#225;rcio Ribeiro", "author_profile_id": "81500654656", "affiliation": "Federal University of Alagoas, Macei&#243;, Brazil", "person_id": "P4149055", "email_address": "marcio@ic.ufal.br", "orcid_id": ""}, {"name": "Claus Brabrand", "author_profile_id": "81100176672", "affiliation": "IT University of Copenhagen, Copenhagen, Denmark", "person_id": "P4149056", "email_address": "brabrand@itu.dk", "orcid_id": ""}, {"name": "Paulo Borba", "author_profile_id": "81100549562", "affiliation": "Federal University of Pernambuco, Recife, Brazil", "person_id": "P4149057", "email_address": "phmb@cin.ufpe.br", "orcid_id": ""}, {"name": "Mira Mezini", "author_profile_id": "81100583946", "affiliation": "Technische Universit&#228;t Darmstadt, Darmstadt, Germany", "person_id": "P4149058", "email_address": "mira.mezini@cased.de", "orcid_id": ""}], "doi_number": "10.1145/2491956.2491976", "year": "2013", "article_id": "2491976", "conference": "PLDI", "title": "SPL<sup>LIFT</sup>: statically analyzing software product lines in minutes instead of years", "url": "http://dl.acm.org/citation.cfm?id=2491976"}