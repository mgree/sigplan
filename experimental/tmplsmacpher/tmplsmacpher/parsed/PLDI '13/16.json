{"article_publication_date": "06-16-2013", "fulltext": "\n Dynamic Determinacy Analysis Max Sch\u00e4fer * Manu Sridharan Julian Dolby Frank Tip Nanyang Technological \nUniversity IBM T.J. Watson Research Center University of Waterloo schaefer@ntu.edu.sg {msridhar, dolby}@us.ibm.com \nftip@uwaterloo.ca Abstract We present an analysis for identifying determinate variables and expressions \nthat always have the same value at a given program point. This information can be exploited by client \nanalyses and tools to, e.g., identify dead code or specialize uses of dynamic language constructs such \nas eval, replacing them with equiva\u00adlent static constructs. Our analysis is completely dynamic and only \nneeds to observe a single execution of the program, yet the deter\u00adminacy facts it infers hold for any \nexecution. We present a formal soundness proof of the analysis for a simple imperative language, and \na prototype implementation that handles full JavaScript. Fi\u00adnally, we report on two case studies that \nexplored how static ana\u00adlysis for JavaScript could leverage the information gathered by dy\u00adnamic determinacy \nanalysis. We found that in some cases scalabil\u00adity of static pointer analysis was improved dramatically, \nand that many uses of runtime code generation could be eliminated. Categories and Subject Descriptors \nF.3.2 [Logics and Meanings of Programs]: Semantics of Programming Languages Program analysis Keywords \nstatic analysis; dynamic analysis; JavaScript 1. Introduction Most modern programming languages offer \nsupport for re.ective programming. For instance, Java programs can inspect an object s class at runtime \nto discover or access its .elds and methods, and they can dynamically load classes by name, or even create \nnew classes from scratch. Modern dynamic languages such as Ruby or JavaScript are even more liberal and \npermit almost arbitrary re.ec\u00adtive changes to a running program s state. JavaScript, for example, provides \nfor-in loops to discover an object s properties, and dy\u00adnamic property accesses to read, write or even \ndelete properties ref\u00aderenced by a computed name. Finally, the notorious eval function can execute arbitrary \ntext as code, which can access or even declare local variables of the enclosing scope. While cherished \nby many programmers for their conciseness and expressiveness, these features make any form of sound pro\u00adgram \nanalysis very hard. As an extreme example, a program could evaluate arbitrary user input as program code, \nthus defeating any * This paper was written while the author was with IBM Research. Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 13, June 16 19, 2013, \nSeattle, WA, USA. Cop yright c &#38;#169; 2013 ACM 978-1-4503-2014-6/13/06. . . $15.00 attempts to \nobtain useful analysis results. In practice, however, pro\u00adgrammers tend to use re.ective features in \na more disciplined fash\u00adion. For instance, Bodden et al. [5] found that Java programs using re.ective \nclass loading tend to always load the same classes, so by observing the classes loaded on some test runs, \nan analysis can gain a fairly complete picture of the program s re.ective behavior. Simi\u00adlarly, Furr \net al. [13] report that while dynamic features in Ruby are used pervasively, most uses are highly constrained \nand can be re\u00adplaced with static alternatives, and Jensen et al. [17] show similar results for uses of \neval in JavaScript. This paper proposes a general approach for soundly identifying such constrained uses \nof dynamic language features. The basic concept behind our approach is determinacy. 1 Roughly speaking, \na variable x is determinate at a program point p if x must have the same value, say v, whenever program \nexecution reaches p. In that case, we will also say that x determinately has value v at p. We allow the \nprogram point p to be quali.ed by a calling context c to account for cases where x is only guaranteed \nto have value v if p is reached while executing inside calling context c. By extension, an expression \nis determinate at at program point p if its value is computed only from variables that are determinate \nat p. Determinacy information can be used by a client to reason about re.ective code. For instance, if \nfor some use of eval the argument is known to determinately have some string value s, then a static analysis \ncan analyze the code represented by s and maintain soundness. Type checkers, program transformation tools, \nand static optimizers could also bene.t from this kind of specialization. Determinacy information is \nnot only useful for dealing with dy\u00adnamic features. For example, in JavaScript it is not uncommon for \nhighly polymorphic functions to behave very differently depend\u00ading on the type and number of arguments \nthey are passed. Figure 1 shows a short, highly simpli.ed excerpt from the popular jQuery library,2 which \nde.nes a utility function $ that performs different 1 Determinacy should not be confused with the notion \nof determinism in concurrent programming. 2 See http://www.jquery.com 1 function $(selector) { 2 if(typeof \nselector === \"string\") { 3 if(isHTML(selector)) 4 // parse as HTML and return DOM tree 5 else 6 // interpret \nas CSS query 7 } else if(typeof selector === \"function\") { 8 // install as event handler for document \nready 9 } else { 10 return [selector]; 11 } 12 } Figure 1. Example of polymorphic function in JavaScript \n tasks depending on its argument. If the argument is a string (line 2), it is either parsed as HTML \nand the corresponding DOM fragment is returned (line 3), or it is interpreted as a CSS selector and all \nmatching elements are returned (line 5). If the argument is a func\u00adtion (line 7), it is installed as \nan event handler to be executed once the HTML document has .nished loading. Otherwise (line 9), the argument \nis wrapped in a single-element array and returned. Individual call sites of $ tend to be monomorphic, \ni.e., they only exercise one particular functionality of the function, so the condi\u00adtions of the if statements \nbecome determinate for that site. For instance, under a call $(function() { ... }), the conditional expression \non line 2 must be false, whereas line 7 must evaluate to true. A .ow-insensitive static analysis can \nuse this information to identify code that is unreachable for this particular invocation of $, thereby \ngaining a degree of .ow sensitivity. Similarly, a partial evaluator could use determinacy information \nto complement bind\u00ading time analysis for specializing a program with respect to deter\u00adminate input, and \nan optimizer could use it to detect dead code. Statically computing determinacy information, however, \nis very challenging, especially for dynamic languages like JavaScript, where even a call graph is hard \nto construct without an effective approach to dealing with dynamic language features [30], the very problem \ndeterminacy analysis is supposed to help with. In this paper, we propose a dynamic determinacy analysis \nthat analyzes one or more concrete executions to infer determinacy facts that are guaranteed to hold \nin any execution. Our analysis is similar in spirit to dynamic information .ow analysis [32], in the \nsense that we consider indeterminate program inputs to be tainted and track the .ow of this taint. Any \nvalue that is not tainted must then be determinate. As in dynamic information .ow, our analysis must \nconsider how indeterminate inputs can in.uence other values both directly (by participating in computations) \nand indirectly (e.g., by being used as an if condition). Since our determinacy analysis is dynamic, it \ncan only observe one execution at a time and has to carefully account for the possible effects of code \nthat was not exercised in this execution, but may be exercised in another. Determinacy information itself \ncan help here: if the conditional expression of an if statement is determinate, for instance, the dynamic \nanalysis only has to explore one branch, since the other branch is de.nitely not run in any execution. \nTo handle indeterminate conditionals, we introduce the technique of counterfactual execution, where we \nexplore both the branch that would ordinarily be executed, and the other branch that would not normally \nbe run. In this way, we can more precisely account for the behavior of other executions and infer more \ndeterminacy facts. We have formalized our analysis for a simple imperative lan\u00adguage with records and \nhigher-order functions and proved its cor\u00adrectness: variables marked as determinate by the analysis at \na cer\u00adtain program point will in fact have the predicted value any time an execution reaches that point. \nWe have implemented a prototype determinacy analysis that handles all of JavaScript, and obtained promising \nresults on two case studies where we combined the de\u00adterminacy analysis with a static analysis: .rst, \nwe extended the static points-to analysis for JavaScript implemented in WALA [30] to make use of determinacy \nfacts, dramatically increasing precision and scalability in some cases; second, we further extended the \nstatic analysis to use determinacy facts for eliminating uses of eval. In summary, this paper makes the \nfollowing main contributions: We introduce a dynamic determinacy analysis, which ana\u00adlyzes one or more \nconcrete executions to identify variables and expressions that have the same value at a given program \npoint in any execution. (Section 2).  We give a formalization and a correctness proof of our deter\u00adminacy \nanalysis for a simple imperative language. (Section 3).  1 (function () { 2 function checkf (p) { 3 \n// [ p.f<32] 16.4 = true; [ p.f<32 ] 25.4 = ? 4 if (p.f < 32) 5 setg (p , 42); 6 } 7 8 function setg \n(r , v) { 9 r.g = v;  10 } // [ r.g ] 18.5.10 = 42 11 12 var x = { f : 23 }, 13 y = { f : Math . random \n()*100 }; 14 // [ x.f ] 14 = 23, [ y.f ] 14 = ? 15 16 checkf (x ); 17 // [ x.f ] 17 = 23, [ x.g ] 17 \n= 42 18 checkf (y ); 19 // [ y.g ] 19 = ? 20 21 (y.f > 50 ? checkf : setg )(x, 72); 22 // [ x.g ] 22 \n= ? 23 24 var z = { f: x.g -16 , h: true }; 25 checkf (z ); 26 })(); Figure 2. Example program for illustrating \ndynamic determinacy analysis. Some key determinacy facts are given in comments. We present a prototype \nimplementation of the analysis for JavaScript. (Section 4).  We report on two case studies, demonstrating \nthat the infor\u00admation gathered by our dynamic determinacy analysis can sig\u00adni.cantly improve the precision \nof static pointer analysis and identify many uses of eval that can be eliminated. (Section 5).  Finally, \nSection 6 surveys related work, and Section 7 concludes. 2. Overview This section provides a high-level \noverview of determinacy and its applications. First, we introduce some terminology and informally explain \nhow determinacy facts can be computed using dynamic analysis, using a small JavaScript example that was \ncarefully con\u00adtrived to demonstrate the key issues involved. Then, we illustrate the usefulness of determinacy \nanalysis by showing how determi\u00adnacy facts can be used to improve static pointer analysis for Java-Script \nand eliminate common uses of the eval function. 2.1 Determinacy To illustrate key challenges for determinacy \nanalysis, consider the example program in Figure 2. It consists of two functions checkf (lines 2 6) and \nsetg (lines 8 10), and a sequence of statements (lines 12 25). These functions and statements are wrapped \ninto an anonymous function call to provide lexical scope. Running the example program. Program execution \nstarts with the call on line 26, which invokes the anonymous function de.ned on lines 1 26. Executing \nits body, we .rst encounter the function de.nitions for checkf and setg. Then, when line 12 is reached, \nvariables x and y are initialized to object literals, both containing a single property f. While property \nx.f is set to the constant value 23, property y.f is initialized to Math.random()*100, a random .oating \npoint number between 0 and 100; let us assume that it evaluates to 31.4 in our concrete execution. Execution \nthen proceeds by calling checkf twice, on lines 16 and 18, passing x and y as the argument, respectively. \nIf the condi\u00adtion on line 4 evaluates to true, checkf calls setg, which assigns the value 42 to the g \nproperty of the argument. In our example ex\u00adecution, the condition evaluates to true for both calls, \nso x.g and y.g both hold the value 42 after line 18. Then, line 21 invokes a function whose name is \ndetermined by the conditional expression (y.f > 50 ? checkf : setg). Since y.f holds the value 31.4 at \nthis point, setg is called, with arguments x and 72, causing the value 72 to be assigned into x.g. Next, \non line 24, a third local variable z is initialized to an object literal with properties f and h containing \nvalues 56 and true, respectively. Finally, when checkf is called with z as an argument on line 25, the \ncondition on line 4 evaluates to false so that setg is not called. Determinacy facts. The goal of determinacy \nanalysis is to iden\u00adtify situations where a variable or expression must hold the same value at a given \nlocation in any execution of the program. For example, x.f is determinate on line 14: it must always \nhave the value 23 here because its initialization does not depend in any way on program input, or on \nvalues in the environment. On the other hand, y.f is indeterminate on line 14, because the value returned \nby Math.random may vary in different executions. We express these observations using the following determinacy \nfacts: [ x.f ] 14 = 23 [ y.f ] 14 = ?  Likewise, variables x and y are both determinate at line 14.3 \nSometimes, determinacy facts only hold under a given calling context. For instance, for the call to checkf \non line 16, the condi\u00adtion p.f < 32 on line 4 will evaluate to true in any program exe\u00adcution, but this \nis not the case for the calls to checkf on lines 18 and 25. We express this as a quali.ed determinacy \nfact [ p.f < 32 ] 16.4 = true stating that the condition p.f < 32 is determinately true on line 4 if \nthis line is reached from the call at line 16. Determinacy facts in\u00adferred by our dynamic analysis are \nalways quali.ed with a complete call stack reaching all the way back to the program s entrypoint. Dynamic \ndeterminacy analysis. To infer determinacy facts, we instrument the program to compute not only the values \nof variables, properties and other expressions, but also whether they are deter\u00adminate at the current \nprogram point. This is done using techniques reminiscent of dynamic information .ow analysis, where instead \nof high and low security levels we track indeterminacy. Program inputs (including, for JavaScript, the \nDOM) are con\u00adsidered indeterminate, as are the results of certain functions like Math.random. Constants, \non the other hand, are determinate, so the analysis marks x and x.f as determinate on line 12. Starting \nfrom these sources, indeterminacy (like high-security annotations in information .ow) propagates both \ndirectly and in\u00addirectly: a variable becomes indeterminate when it is assigned an expression involving \nother indeterminate variables, but also when it is modi.ed in code that is control dependent on an indeterminate \ncondition and hence not necessarily run in every execution. Direct propagation of indeterminacy is easy \nto track by com\u00adputing a compound expression s determinacy from its constituent expressions: e.g., Math.random()*100 \nis indeterminate, so y.f is indeterminate at line 13. To track indirect .ow of indeterminacy, the dynamic \nanalysis has to carefully reason about conditionals. Conditionals and counterfactual execution. Conditionals \nwhere the condition is itself determinate are easy to handle, since any other execution will take the \nsame branch as the one we are ob\u00adserving. This case arises in the call to checkf on line 16, where the \n3 While y.f is indeterminate, y itself must hold the object literal assigned to it at line 13. condition \np.f < 32 is determinately true, so by simply continuing execution we can infer the fact [ x.g ] 17 = \n42. Indeterminate conditions require a more careful treatment. For the second call to checkf (line 18), \nthe condition p.f < 32 on line 4 is indeterminate, but happens to be true. In another execution it may \nwell be false, causing the branch not to be executed. To account for this possibility, we execute the \nbranch as usual, but record any variable or property write. After the branch has .nished executing, we \nmark all written variables and properties (in this case only y.g) as indeterminate, giving [ y.g ] 19 \n= ?. By marking variables indeterminate only after the branch has .nished executing, we can infer more \ndeterminacy facts inside it. Note that both arguments to setg are determinate at line 5 when checkf is \ninvoked from line 18. So, we infer [ r.g ] 18.5.10 = 42, even though y.g is later marked indeterminate. \nOf course, x.f and x.g stay determinate, as they are not written to in the branch. The third, and most \ndif.cult, case arises with conditions that are indeterminate and happen to be false, as is the case for \np.f < 32 in the third call to checkf on line 25. Here, we have to account for the fact that the condition \nmay evaluate to true in another execution, causing the branch to be taken. A simple approach would be \nto statically examine the code to determine which local variables it could write to (none in this case) \nand mark them indeterminate. However, this does not account for possible heap writes by functions called \nwithin the branch. Since a dynamic analysis does not have access to a static call graph, a conservative \napproach is to .ush the heap, marking every property of every object as indeterminate. This is clearly \nvery imprecise, so our analysis takes another approach, which we refer to as counterfactual execution. \nEven though the condition is false, we still (counterfactually) execute the branch, recording any determinacy \nfacts that may arise. After it has .nished executing, we (i) undo the effect of any writes to variables \nor properties (since the branch was not originally meant to execute), and (ii) mark any written variables \nand properties as indeterminate (since other executions may not perform these writes). In our case, this \nleads to z.g being marked indeterminate after the conditional, while, for instance, z.h is still determinate. \nIndeterminate calls. Since JavaScript functions are .rst-class, the target of a function call must itself \nbe computed as a value, which may be indeterminate. An example is the call on line 21, where the callee \nis computed by the indeterminate expression y.f > 50 ? checkf : setg. In the concrete execution we are \ncon\u00adsidering, it evaluates to setg, which is then invoked to set x.g to 72. However, the value of the \ncallee expression is indeterminate since y.f is indeterminate at line 21, so another execution may well \ninvoke checkf instead, which would result in x.g being 42. To account for this, we conservatively .ush \nthe heap, marking all properties as indeterminate after every indeterminate call. In our example, this \nmeans that x.f, x.g, y.f and y.g are indeterminate at line 22. While this is overly conservative (x.f \nis, in fact, still determinate), it is the best thing we can do, since we do not track alternative values \nfor indeterminate expressions. Note that x and y need not be made indeterminate, since they are local \nvariables and cannot possibly be written by any called function. 2.2 Improving pointer analysis We now \nshow how determinacy facts can be used to improve static pointer analysis for JavaScript. Static analysis \nof JavaScript is very challenging [18, 27, 30], due to pervasive use of re.ective constructs in JavaScript \nprograms and the absence of of static types. Determinacy facts can be used to rewrite uses of re.ection \ninto more verbose code that is easier to analyze, as we illustrate below. 1 function Rectangle (w , \nh) { 2 this . width = w; 3 this . height = h; 4 } 5 6 Rectangle . prototype . toString = function () \n{ 7 return \"[\"+ this . width +\"x\"+ this . height +\"]\"; 8 }; 9 10 String . prototype . cap = function \n() { 11 return this [0]. toUpperCase ()+ this . substr (1); 12 }; 13 14 function defAccessors ( prop \n) { 15 Rectangle . prototype [\" get \" + prop . cap ()] = 16 function () { return this [ prop ]; }; 17 \n18 Rectangle . prototype [\" set \" + prop . cap ()] = 19 function (v) { this [ prop ] = v; }; 20 } 21 \n22 var props = [\" width \" , \" height \"]; 23 for (var i=0; i < props . length ; i ++) 24 defAccessors \n( props [i ]); 25 26 var r = new Rectangle (20 , 30); 27 r. setWidth (r. getWidth ()+20); 28 alert (r. \ntoString ()); // [40 x30 ] Figure 3. Example program illustrating the use of determinacy facts for improving \na static pointer analysis Example. Consider the example program in Figure 3, which is loosely modeled \nafter code seen in jQuery and other commonly\u00adused JavaScript frameworks. The program de.nes a Rectangle \nconstructor function on lines 1 4, which initializes properties width and height to the values passed \nin parameters w and h, re\u00adspectively. A toString() method is de.ned on the Rectangle. prototype object \n(lines 6 8), thereby making it available on all objects created by Rectangle. Similarly, a utility method \ncap for performing string capitalization is de.ned on String.prototype (line 10), which means that it \ncan be invoked on any string object. We now use a standard trick employing dynamic property ac\u00adcesses \nto concisely de.ne getter and setter methods for the width and height properties. We iterate over the \narray [\"width\", \"height\"] using the for loop on lines 23 24, invoking the defAccessors function twice, \n.rst with prop set to \"width\", then to \"height\". Function defAccessors (lines 14 20) de.nes a getter \nfunction (line 15 16) and a setter function (line 18 19), and stores them into Rectangle.prototype. The \nnames of these accessor methods are computed dynamically, capitalizing the prop\u00aderty name using cap and \nprepending \"get\" and \"set\", respec\u00adtively. Thus, the getter methods end up in properties getWidth and \ngetHeight, and similar for the setters. Lines 26 28 illustrate how these getter and setter methods can \nbe used: Executing these lines will bring up an alert box that reads [40x30]. Applying static pointer \nanalysis. Now let us consider how a standard static pointer analysis algorithm such as 0-CFA [29] would \nanalyze this program. Since such algorithms typically do not track string values, they would conservatively \ntreat the writes on lines 15 and 18 as possibly writing to any property of Rectangle.prototype. From \nthis, they would conclude that the call to getWidth on line 27 could invoke either of these functions, \nand that the call to toString on line 28 could invoke the getter, the setter, or the actual toString \nmethod, which is very imprecise. Even a recent, more advanced analysis that reasons about correlated \ndynamic property accesses [30] is unable to determine the result of applying cap to the property name, \nyielding the same result. Static string analyses [8] can reason abstractly about string op\u00aderations, \nbut are expensive and rely on a call graph. If, as in this ex\u00adample, such reasoning is required to construct \na precise call graph to begin with, an iterative scheme interleaving call graph construc\u00adtion and string \nanalysis would have to be devised. By contrast, a context-sensitive static analysis can be adapted to \nleverage deter\u00adminacy facts in a fairly straightforward manner, as we now show. Using determinacy facts. \nOur determinacy analysis produces facts that can help the static pointer analysis handle complex string \noperations. For example: The analysis shows that the prop argument to defAccessors is determinate in \nthe .rst iteration of the loop at lines 23 24: [ prop ] 240.15 = \"width\" Here, 240 denotes the .rst time \nexecution reaches line 24. Within the defAccessors call, the result of the prop.cap() call is also determinate: \n[ this[0].toUpperCase()+... ] 240.15.11 = \"Width\" which makes the result of the string concatenation \ndeterminate: [ \"get\" + prop.cap() ] 240.15 = \"getWidth\" Similar facts hold for the second loop iteration, \nand since props.length is determinate at line 23, the determinacy ana\u00adlysis can also show that the loop \nexecutes at most two times. Given these determinacy facts, the pointer analysis can use loop unrolling \nand context sensitivity to precisely handle the property writes at lines 15 and 18. First, the analysis \nunrolls the loop at lines 23 24 twice, using the iteration bound given by the determinacy analysis. Then, \nvia context sensitivity, each call site of defAccessors in the unrolled loop is treated as invoking a \nfunction specialized by the corresponding determinacy facts. For example, the .rst call site, corresponding \nto the loop iteration with props[i] == \"width\", invokes the following specialized function: function \ndefAccessors ( prop ) { Rectangle . prototype . getWidth = function () { return this . width ; }; Rectangle \n. prototype . setWidth = function (v) { this . width = v; }; }  For this specialized code, the pointer \nanalysis can easily prove that only the getter function is written into property getWidth, and that only \nthe setter function is written into property setWidth, thus enabling precise resolution of the function \ncall at line 27. Besides replacing dynamic property accesses with static ones, determinacy facts can \nalso be used to eliminate conditionals where the condition is determinate, helping to analyze cases like \nthat shown in Figure 1. In Section 5.1, we shall show how our imple\u00admentation of these techniques achieved \nlarge speedups when ana\u00adlyzing certain versions of jQuery. 2.3 Eliminating eval JavaScript s eval function \ntransforms text into executable code at run time. Although strongly discouraged by leading practition\u00aders \n[11], it is pervasively used in practice [26], leaving static anal\u00adyses with a stark choice: if eval \nis not handled, soundness is com\u00adpromised; if it is handled conservatively, analysis results will be\u00adcome \nextremely imprecise, and thus useless for most applications. Recent research suggests that many uses \nof eval could, in fact, be replaced by equivalent eval-free code [17, 23]. For example, 1 ivymap = window.ivymap \n|| {}; 2 function showIvyViaJs(locationId) { 3 var _f = undefined; 4 var _fconv = \"ivymap[\\ \"+locationId+\"\\ \n]\"; 5 try { 6 _f = eval(_fconv); 7 if (_f!=undefined) { 8 _f(); 9 } 10 } catch(e) { 11 } 12 } 13 14 \nshowIvyViaJs( pc.sy.banner.tcck. ); 15 showIvyViaJs( pc.sy.banner.duilian. ); Figure 4. Program (taken \nfrom [17]) for which determinacy ana\u00adlysis can show that all calls to eval have a determinate argument. \nconsider the code in Figure 4, taken from Jensen et al. [17], who extracted it from a real-world website. \nClearly, the strings passed to eval are determinate in both invocations of showIvyViaJS: _fconv 14.6 \n= \"ivymap[ pc.sy.banner.tcck. ]\" [ _fconv ] 15.6 = \"ivymap[ pc.sy.banner.duilian. ]\" Using the same approach \nas in the previous subsection, a static analysis can specialize each call to showIvyViaJS, replacing \ncalls to eval with the code obtained by (statically) parsing the string values found by the determinacy \nanalysis, thus eliminating the calls to eval altogether. Section 5.2 presents encouraging results from \nan initial experiment using this approach, which showed that eval elimination via determinacy facts can \ncomplement existing purely\u00adstatic approaches like that of TAJS [17]. 3. Formalization In this section, \nwe formalize the dynamic determinacy analysis from Section 2 on a simple imperative language \u00b5JS with \nrecords, dynamic property accesses and .rst-order functions. \u00b5JS contains most of the features that make \ndeterminacy analysis for JavaScript challenging. We exclude prototypes, constructors and other fea\u00adtures \nusually modeled in JavaScript-based core calculi [15], since they are orthogonal to determinacy analysis. \nFor simplicity, we also exclude unstructured control .ow. We start out by formalizing the syntax and \n(concrete) semantics of \u00b5JS. Then, the analysis is formalized as an instrumented seman\u00adtics over values \nwith determinacy annotations \u00b7 ! and \u00b7 ? . Finally, we show soundness of the analysis: if a variable \nhas a value v ! at some program point p in some instrumented execution, it has value v at the same point \nin every concrete execution. 3.1 Syntax and semantics of \u00b5JS Figure 5 presents the syntax of \u00b5JS, which \nis mostly a subset of that of JavaScript, except that we abbreviate the keyword function as fun. Instead \nof the complex statement and expression syntax of JavaScript, \u00b5JS only allows simple statements reminiscent \nof three address code. In particular, conditionals have only a single branch and their conditional expression \nmust be a variable. Values in \u00b5JS are either primitive values, closures, or heap\u00adallocated records. Primitive \nvalues are taken from an unspeci.ed set PrimVal containing a special value unde.ned. We assume that all \nprimitive values are silently coerced to strings or Boolean val\u00adues where necessary. When viewed as a \nBoolean value, addresses and records evaluate to true. We also assume a set PrimOp of binary operators \non primitive values. Closures are represented as l . Literal ::= pv primitive value | fun(x) { function \nvalue var y; s; return z; }| {} empty record s . Stmt ::= x = l literal load | x = y variable copy | \nx = y[z] property load | x[y] = z property store | x = y o z primitive operator | x = f(y) function call \n| if(x){s} conditional | while(x){s} loop x, y, z, f . Name; o . PrimOp; pv . PrimVal; a . Address v \n. Value ::= pv | a | (fun(x) {b}, .) r . Rec ::= {x: v}. . Env := Name -Value h . Heap := Address -Rec \n Figure 5. Syntax and semantic domains of \u00b5JS; b abbreviates function bodies e . Event ::= x = v variable \nwrite t . Trace |||:= a[x] = v if(v){t}fun(v){t}. e heap write conditional function call Figure 6. Concrete \nexecution traces a function value plus an environment, as usual. Record literals are always empty, but \nproperty load and store statements can be used to add more properties; we do not model property deletion. \nNote that the name of the property accessed by these statements is itself a variable, and hence can be \ncomputed at runtime, just as in Java-Script. There is no designated prototype property, since \u00b5JS does \nnot model JavaScript s prototype system. For convenience, we treat records r as total functions from \nnames to values: if r = {x: v}, then r(xi) = vi, and r(y) = unde.ned for y . x. Our semantics for \u00b5JS \nis big-step. While a small-step seman\u00adtics would allow more direct reasoning about individual program \npoints, it makes it hard to match up control .ow forks and joins, which play a crucial role in computing \ndeterminacy information. To be able to speak about intermediate states, we use a trace\u00adbased semantics \n[22] with an evaluation judgement of the form (h, ., s) . (h', .', t): h and . are the initial heap and \nenvironment, s is the statement to evaluate; h' and .' are the resulting heap and environment, and t \nis a trace recording all assignments, condition\u00adals and function calls executed during evaluation of \ns. Figure 6 gives the grammar of trace events and traces; the envi\u00adronment . in a function call event \ndenotes the closure environment of the called function. Figure 8 lists the evaluation rules, which are \nmostly standard, except that they each add an event to the trace. We assume that the semantics of built-in \nprimitive operators o is given by a partial function [o]. If this function is unde.ned on the pro\u00advided \narguments, execution gets stuck, as is the case when access\u00ading unde.ned local variables or trying to \ninvoke a non-function. In full JavaScript, these situations give rise to elaborate implicit con\u00adversions \nor exceptions, which we do not model. Local variables have to be declared before use (hence the pre\u00adcondition \nx . dom(.) in most rules), and we do not model globals. d . D := {!, ?} v . .::= pv d | a d | (fun(x) \n{b}, . )d Value Rec ::= {x: v} | {x: v, . . .} r . R R h . H:= Rec Heap Address \u00ad. . R:= Name -Value \nEnv e . .| (fun( v){t })d Event ::= x = v | a d[x d1 ] = v | if( v){t } . t . .:= eTrace Figure 7. Instrumented \nsemantic domains and traces While local variables can be modi.ed, their semantics is quite id\u00adiosyncratic: \nupdates are only visible inside the updating function, so updating a closure variable will not have the \ndesired effect. A more standard semantics can be achieved by modeling local vari\u00adables that are accessed \nin a nested functions as immutable refer\u00adences to records with a single property, and accessing that \nproperty instead. Given a trace t, we can reconstruct what effects the execution that produced it had \non the heap and the environment. Its variable domain vd(t) is the set of all variables written during \nthe execution; it consists of all variables x such that t or one of its sub-traces (excluding sub-traces \ninside function calls4) contains an event x = v. The property domain pd(t) contains all address-property \nname pairs (a, p) such that property p of the record at a was modi.ed during the execution, which is \nthe case iff t or one of its sub\u00adtraces (including sub-traces inside function calls) contains an event \na[p] = v. We also de.ne the variable domain of a sequence of statements, vd(s), to contain all variables \nx such that one of the statements in s (without nested functions) is an assignment to x. Clearly, if \n(h, ., s) . (h ' , . ' , t), then .x . vd(t)..(x) = . ' (x), and similarly .(a, p) . pd(t).h(a)(p) = \nh ' (a)(p). 5  3.2 Instrumented semantics We formalize determinacy analysis via an instrumented semantics \nof \u00b5JS where variables and properties are bound to annotated val\u00adues of the form v ! and v ?, representing \ndeterminate and indetermi\u00adnate values, respectively. Instrumented values, records, heaps, environments \nand traces are de.ned in Figure 7. An instrumented value of the form v ! represents the single concrete \nvalue v, whereas v ? represents any concrete value. For records, a closed record of the form {x: v}represents \nall records that have precisely the properties x with values represented by the corresponding instrumented \nvalues v ; an open record of the form {x: v, . . .}, on the other hand, represents all records that have \nat least the properties x (again with the same restrictions on their values), but may have more. Like \ntheir concrete counterparts, we also interpret instrumented records as functions; looking up a non-existent \nproperty on a closed record yields unde.ned!, and on an open record unde.ned? . For an instrumented value \nv , we de.ne v ? as v with all \u00b7 ! annotations replaced by \u00b7 ?. For records r , r ? additionally turns \nr into an open record. For heaps, we let h ? be the heap resulting from h by replacing every record r \nwith r ?, which corresponds to a heap .ush. We also de.ne v ! := v, r ! := r, h ! := h i.e., the extant \ndeterminacy annotations are retained. 4 Function calls need not be considered, since callees cannot update \ntheir caller s local variables. 5 These equalities should be considered to hold if either both sides \nare unde.ned, or both are de.ned and equal. x . dom(.) (L DLI T) (h, ., x = pv) . (h, .[x . pv], x = \npv) F = fun(y) { var y; s; return z; } x . dom(.)  (LDCL O S) (h, ., x = F ) . (h, .[x . (F, .)], x \n= (F, .)) x . dom(.) a . dom(.) (LDRE C) (h, ., x = {}) . (h[a . {}], .[x . a], x = a) x . dom(.) .(y) \n= v (A S S I G N) (h, ., x = y) . (h, .[x . v], x = v) x . dom(.) .(y) = a .(z) = z ' h(a) = r r(z ' \n) = v (LD) (h, ., x = y[z]) . (h, .[x . v], x = v) .(x) = a .(y) = y ' h(a) = r .(z) = v (S TO) (h, \n., x[y] = z) . (h[a . r[y ' . v]], ., a[y ' ] = v) x . dom(.) .(y) = pv1 .(z) = pv2 pv1[o]pv2 = pv3 \n(P R I M OP) (h, ., x = y o z) . (h, .[x . pv3], x = pv3) x . dom(.) .(f) = (fun(z) {var x ' ; s; return \ny ' ; }, . ' ) .(y) = v '. '' (y ' (h, . ' [z . v, x . unde.ned], s) .(h ' , . '' , t) ' ) = v (I N \nV) (h, ., x = f(y)) . (h ' , .[x . v ' ], (fun(v){t}.1 ; x = v ' )) .(x) = v v = true (h, ., s) .(h ' \n, . ' , t) (I F1) (h, ., if(x){s}) . (h ' , . ' , if(v){t}) .(x) = v v = false (I F2) (h, ., if(x){s}) \n. (h, ., if(v){}) (h, ., if(x){s; while(x){s}}) . (h ' , . ' , t) (WH I L E) (h, ., while(x){s}) . (h \n' , . ' , t) (hi, .i, si) . (hi+1, .i+1, ei) (SE Q) (h0, .0, s) .(hn, .n, e) Figure 8. Concrete semantics \nof \u00b5JS An instrumented trace looks like a concrete trace, except that it contains instrumented values \ninstead of concrete ones. For a function call event (fun( v){t })d . , for instance, v is the argument \nvalue, . is the closure environment of the callee, and t is the trace resulting from the call. The annotation \nd indicates whether the callee is determinate or not. The variable and property domains vd(t ) and pd(t \n) are de.ned exactly as for concrete traces, simply disregarding determinacy annotations. As described \nin Section 2, after executing a branch guarded by an indeterminate but true condition, the analysis marks \nevery variable written in the branch as indeterminate. Similarly, after counterfactually executing a \nbranch, every written variable is reset to its previous value and marked indeterminate. To model this \nin our semantics, we use the notation . ' [V := .d], where ., . ' are instrumented environments, V is \na set of variable names, and d is a determinacy .ag. Roughly, this means that . ' is updated so that \nevery variable x . V is reset to the value it had in . , and marked as indeterminate if d =?. More precisely, \nwe de.ne ' d . (x)d if x . dom( .) n V . [V := .](x) := . ' (x) otherwise  Thus, for a trace t , . \n' [vd(t ) := . '?] marks every variable x written by h as indeterminate, and . ' [vd(t ) := . ?] additionally \nresets its value to . (x). ' ' d For records r r := ] as for environments. r, , we de.ne [V r For heaps \nh ' , a set A . Address \u00d7 Name of address-property h, name pairs and a determinacy .ag d, we de.ne . \n. h ' (a)[Aa := h (a)d] if a . dom(h ' ) n h ' [A := h d](a) := dom(h ) . h ' (a) otherwise where Aa \n:= {p | (a, p) . A}. Given these technical preliminaries, we can now de.ne the eval\u00aduation judgement \n( ., s) n (h ' , . ' , t ) of the instrumented seman\u00ad h, . tics as shown in Figure 9. The index n is \nused to bound the nesting depth of counter-factual executions, to be discussed shortly. We omit (LDCLOS), \n(LDRE C), (AS SI G N), (WH I LE) and ( R SE Q), which are straightforward adaptations of their concrete \ncounter\u00adparts. In (PR I M OP), the determinacy .ags d1 and d2 of both operands are applied to the result, \nso it will be indeterminate if at least one of the operands is. Similarly in (LLD), the result of a property \nload is only determinate if both the address and the prop\u00ad erty name are. Rule ( R STO) applies the determinacy \n.ag d of the address to be accessed to the whole heap: if d =?, the heap is .ushed. Similarly, the .ag \nd ' of the property name is applied to the record being accessed: if d ' =?, all properties are made \ninde\u00adterminate and it becomes an open record, since any of the existing properties may be written, or \na new one added. The most interesting rules are the ones concerning condition\u00adals. (ILF1) handles the \ncase where the condition is (determinate or indeterminate) true by simply executing the branch, and afterwards \nmarking all written properties and variables as indeterminate if the condition is indeterminate. (IF2-DE \nT) applies when the condition is determinate false; in this case, the conditional is a no-op. (CN T R) \ninitiates counterfactual execution if the condition is in\u00addeterminate false, executing the branch while \nincreasing the coun\u00adterfactuality level to n + 1. After the branch has .nished executing, (CN TR) reverts \nto the heap and environment before the counterfac\u00ad tual (i.e., assignments performed by the counterfactually \nexecuted branch are not visible), and marks any variable or property possibly written by counterfactual \ncode as indeterminate. In general, counterfactually executing branches may lead to non-termination, so \nwe introduce a cut-off: when the number of nested counterfactual executions is about to exceed some .xed \nnumber k, the pre-condition n < k prevents the (CNTR) from applying; instead, rule (CN TR AB O RT) shortcuts \nevaluation and conservatively .ushes the heap and marks any variable that may possible be assigned anywhere \nin the branch indeterminate.  3.3 Soundness To show soundness, we will now prove that the instrumented \ntrace generated by an execution under the instrumented semantics cor\u00adrectly predicts any concrete trace \nproduced by an execution under the normal semantics: where the instrumented trace has v !, a con\u00adcrete \ntrace must have v; where the instrumented trace has v ?, we cannot predict the corresponding value in \nthe concrete trace. Obviously, however, this can only hold if instrumented and con\u00adcrete execution start \nin compatible states. To formalize this notion, we inductively de.ne a modeling relation \u00b7 |= \u00b5 \u00b7 relating \ninstru\u00admented values, environments, records, heaps and traces to their concrete counterparts (Figure \n10). The mapping \u00b5: Address . Address maps addresses of the concrete execution to correspond\u00ading addresses \nof the instrumented execution, since the choice of a x . dom( .) (LDLI T) n ! ( ( !) h, ., x = pv) . \nh, . [x . pv ], x = pv d 'd1 ' x . dom( .) . (y) = a . (z) = z h(a) = r r (z ) = v (LLD) n ( ., x = \ny[z]) ( .[x . ( d)d1 ], x = ( d)d1 ) h, . h, v v d 'd1 . (x) = a . (y) = y h(a) = r . (z) = v ST O) \n( R(h, ., x [y] = z) (( r[y 'v])d1 ])d , 'd1 ] = . n h[a . ( . ., ad[y v) d1 d2 x . dom( .) . (y) = pv \n. (z) = pv pv1[o]pv2 = pv3 1 2 (P R I M OP) ( ., x = y o z) . ( .[x . (pv d1 d1 )d2 ) h, h, 3 )d2 ], \nx = (pv3 ' . ' )d x . dom( .) . (f) = (fun(z) {var x ' ; s; return z ; }, . (y) = v . '' . '' ' ' ' ( \n. ' v, x . n h ' , , t) (z ) = v h, [z . . unde.ned!], s) ( (IRN V) n ( (h 'd 'd v) {t }d 'd h, ., \nx = f(y)) . , . [x . v ], (fun( . 1 ; x = v )) n . ' d h ' . (x) = v v = true ( ., s) ( , , t) h, . \n(ILF1) n h 'd . 'd d ( ., if(x){s}) ( [pd( ], [vd( ], if(v t}) h, . h ' t) := . ' t) := ){ . (x) = v \n! v = false (IF2-DE T) (h, ., if(x){s}) . ( ., if(v h, !){}) ? ( n+1 (h ' . ' . (x) = v v = false n < \nk h, ., s) . , , t) (CN T R) n ( ., if(x){s}) ( [pd( h? . ' t) := ], if(v ? t}) h, . h ' t) := ], [vd( \n.? ){ . (x) = v ? v = false n = k (CN T R AB O RT) n ( (h ? .? ? h, ., if(x){s}) . , . [vd(s) := ], \nif(v ){}) Figure 9. Instrumented semantics for determinacy analysis. F = fun(y) {b} . |= \u00b5 . v ? |= \n\u00b5 v ' pv ! |= \u00b5 pv \u00b5(a)! |= \u00b5 a (F, . )! |= \u00b5 (F, .) .x . dom(.).. (x) |= \u00b5 .(x) .a . dom(h).h(\u00b5(a)) \n|= \u00b5 h(a) . |= \u00b5 . h |= \u00b5 h .x.r (x) |= \u00b5 r(x) v |= \u00b5 v a d |= \u00b5 a ' p d1 |= \u00b5 p ' v |= \u00b5 v r |= \u00b5 r \nx = v |= \u00b5 x = v a d[p d1 ] = v |= \u00b5 a ' [p ' ] = v ' v |= \u00b5 v t |= \u00b5 t v = false if( v){t } |if(v){t} \nif(v ?){t } |= \u00b5 if(v ' ){}= \u00b5 v |= \u00b5 v t |= \u00b5 t v |= \u00b5 v . |= \u00b5 . (fun( v){t }). ? |= \u00b5 fun(v){t}. \n(fun( v){t }). ! |= \u00b5 fun(v){t} Figure 10. Modeling relations between instrumented values, envi\u00adronments, \nrecords, heaps, traces and their concrete counterparts in (LDRE C) is not constrained enough to require \nboth executions to choose precisely the same addresses. The rules for values, environments, records and \nheaps are fairly straightforward. For traces, note that the instrumented and concrete traces of the branches \nof a conditional need not match if the con\u00addition variable is indeterminate false. Similarly, for a function \ncall event we do not require the traces of the called function to corre\u00adspond if the called function \nis not determinate. We can now state the soundness of the instrumented semantics:  Theorem 1. If ( ., \ns) n (h ' , . ' , t ) and (h, ., s) . (h ' , . ' , t) h, . where h |= \u00b5 h and . |= \u00b5 . for some \u00b5 that \nis injective on dom(h), h ' h ' . ' then |= \u00b51 , |= \u00b51 . ', and t |= \u00b51 t for some \u00b5 ' that is injective \non dom(h ' ), and agrees with \u00b5 and dom(h). A proof of this theorem and its mechanization in Coq are \navail\u00adable online at http://github.com/xiemaisi/determinacy. To relate this result to our intuitive description \nof a determinacy analysis, note that every event in a (concrete or instrumented) trace corresponds to \na statement in the program being executed under a certain call stack. The soundness result essentially \nshows that the instrumented heap and environment at some position p in an instrumented trace correctly \nmodel all concrete heaps and environments that may be encountered by a concrete execution at p, provided \nits initial heap and environment are correctly modeled by the initial instrumented heap and environment. \n4. Implementation We have implemented a prototype dynamic determinacy analysis for JavaScript, which \ninstruments a program to track determinacy .ags as in the instrumented semantics of the previous section. \nInstrumented programs can run in a browser or atop Node.js, using ZombieJS for DOM emulation.6 For instrumentation, \nthe program is .rst translated into a form similar to \u00b5JS with a small number of additional statement \nforms. Almost all of the ECMAScript 5.1 standard is handled, except implicit conversions using toString \nand valueOf; getters and setters are partially supported. To handle unstructured control .ow, the instrumented \nprogram adjusts determinacy information at every control .ow merge point, not just after ifs. To implement \nheap .ushes, we keep a global epoch counter. Every property has a recency annotation, and is only considered \ndeterminate if this annotation equals the current epoch. Thus, in\u00adcrementing the epoch counter .ushes \nthe heap. Native functions from the standard library cannot be instru\u00admented. For some of them, we provide \nhand-written models that conservatively approximate their effects on determinacy informa\u00adtion; e.g., \nmost string handling functions do not affect the determi\u00adnacy of heap objects. Calling a native function \nwithout a model, however, yields an indeterminate result and causes a heap .ush. For DOM functions, we \nassume that they can only modify DOM data structures, so calling them does not affect the determinacy \nof other heap locations. Return values of DOM functions, however, are always considered indeterminate, \nas is any value that is read from a DOM data structure. This is very conservative, and could be improved \nby providing a more detailed model of the DOM. Since DOM events can .re in any order, we perform a heap \n.ush immediately upon entering an event handler. In practice, this means that few useful determinacy \nfacts can be derived for them. If counterfactual execution encounters a call to a native function that \nis not known to be side effect-free, we immediately abort the counterfactual execution and .ush the heap. \nExceptions during counterfactual execution are handled similarly. Finally, note that eval is easy to \nhandle in a dynamic analysis: calls to eval are instrumented to recursively instrument any code loaded \nat runtime, .ushing the heap if the code is not determinate. Currently, our instrumentation is not optimized, \nso instrumented code is expected to run slower. In typical applications, however, the main focus of the \nanalysis is on the program s initialization phase, which for most JavaScript programs tends to be fairly \nshort. 6 See http://nodejs.org and http://zombie.labnotes.org. jQuery Version Baseline Spec Spec +DetDOM \n1.0 X , (82) , (2) 1.1 X X (107) , (4) 1.2 , , (>1000) , (0) 1.3 X X (>1000) X (>1000) Table 1. Comparison \nof pointer analysis scalability on several jQuery versions; the number of heap .ushes is given in parentheses. \n5. Case Studies This section reports on two case studies combining determinacy analysis with static analysis \nto improve pointer analysis scalability and to eliminate calls to eval as suggested in Section 2. 5.1 \nImproving pointer analysis We enhanced the points-to analysis of WALA [30] to exploit deter\u00adminacy facts \ncomputed by our dynamic analysis. This is done by creating clones of functions based on the full call \nstacks present in determinacy facts to enable specialization, extending the baseline context sensitivity \npolicy used in [30], as discussed in Section 2. We perform three kinds of specializations: (i) removing \nbranches guarded by determinately false conditions; (ii) making dynamic property accesses with determinate \nproperty names static; (iii) un\u00adrolling loops with a determinate maximum number of iterations if this \nenables other specializations. We compared our specializing analysis (Spec) to the analysis of [30] \n(Baseline) on several versions of jQuery, as shown in Table 1. For each version, we analyzed an HTML \n.le that includes the jQuery library itself with no additional client code; this is not trivial due to \njQuery s complex initialization code [30]. In all cases, the static analysis either completed in less \nthan 5 seconds, indicated by , in the table,7 or it did not complete within a 10-minute timeout, indicated \nby X. We also give the number of heap .ushes performed by the dynamic analysis in parentheses; note that \nwe stop the dynamic analysis after 1000 heap .ushes, since at this point it is unlikely to detect new \ndeterminacy facts. Since the DOM model used by the dynamic analysis is very limited, we also ran the \ndynamic analysis with the additional (un\u00adsound) assumption that all properties of DOM objects are deter\u00adminate, \nand that operations on the DOM return determinate val\u00adues (column Spec+DetDOM). This avoids many heap \n.ushes and yields more determinacy facts, effectively specializing the code to one particular browser \nand one HTML document. While unsound in general, this con.guration is an indicator of possible improve\u00adments \nto be gained from a richer DOM model. The results show that determinacy facts can dramatically en\u00adhance \nthe scalability of a static pointer analysis: while Baseline fails to analyze jQuery 1.0 in 10 minutes, \nSpec analyzes it in a matter of seconds. All specializations listed above were necessary to make this \nversion analyzable; in particular, one loop had to be unrolled 21 times to enable specialization of two \ncritical property writes (similar in style to Figure 3) to make the pointer analysis terminate. The additional \ncontext sensitivity needed to make use of determinacy facts is moderate: up to four levels of calling \ncon\u00adtext are required, but only for call sites where a determinacy fact is available; this additional \neffort pays for itself, since the special\u00adized functions are much easier to analyze than their unspecialized \ncounterparts. For jQuery 1.1, the determinacy facts were insuf.cient to make our specializing analysis \nterminate. Further investigation suggested 7 As measured on a Lenovo ThinkPad W520 with a 2.20 GHz Intel \nCore i7-2720QM processor and 8GB RAM running Linux 3.2.0-32, using the OpenJDK 64-Bit Server VM, version \n1.7.0_09, with a 5GB maximum heap. that our imprecise DOM model was to blame, and indeed assuming a \ndeterminate DOM makes this version analyzable as well. Again, adding determinacy facts required no more \nthan four levels of context sensitivity and made the analysis dramatically faster. Interestingly, jQuery \n1.2 is easy to analyze for all analysis con\u00ad.gurations, even the baseline. This is due to a change that \nmade complex initialization code execute lazily; without client code, this code is dead and need not \nbe analyzed. jQuery 1.3 (and later versions) are not yet analyzable, even us\u00ading a determinate DOM. We \nsuspect this is due to more complex event handlers being installed during initialization. Some handlers \nare not exercised by the dynamic analysis, but even for the ones that are we need to perform a heap .ush \non entry (see Section 4). Nonetheless, it is clear from our experiments that determinacy ana\u00adlysis has \nthe potential for signi.cantly improving the scalability of pointer analysis of complex JavaScript frameworks \nsuch as jQuery.  5.2 Eliminating calls to eval We further enhanced our analysis to also specialize calls \nto eval where eval is the only call target and its argument string is deter\u00adminate. We ran this analysis \non the benchmark suite used by Jensen et al. [17]. As they note, there are some dif.culties in eliminating \nuses of eval even with constant arguments. Many of these issues do not arise in our case, since we perform \nspecialization on an in\u00adtermediate representation with fully resolved name bindings. Jensen et al. report \nthat their unevalizer tool could eliminate all uses of eval in 19 of 28 benchmarks. Our dynamic analysis \nneeds to be able to run the program, so we had to disregard 3 benchmarks that are missing required code, \nand one that cannot be run in ZombieJS. On 14 out of the remaining 24 programs, our analysis could specialize \nall uses of eval. Interestingly, this includes six programs that unevalizer cannot handle, including \nthe code shown in Figure 4. In this program, the code to be evaluated results from a string concatenation, \nbut their analysis requires the concatenation to be a syntactic part of the eval argument expression, \nwhich is not the case here. Other cases involve for-in loops: if the set of properties to iterate over \nis determinate, our analysis assumes that the iteration order is also determinate. This is true for all \nmajor JavaScript implementations, but unevalizer does not assume this. In the remaining 10 programs, \nour analysis fails to specialize away at least one use of eval. This is either because the evaluated \nstring is genuinely indeterminate (1 case); the dynamic analysis does not cover a use that WALA considers \nreachable (4 cases); or incomplete DOM modeling causes heap .ushes, making the callee of a use of eval \nindeterminate (1 case). In the remaining 4 cases, eval occurs inside a loop for which the dynamic analysis \ncannot derive a determinate upper bound, and which hence cannot be specialized. In only one of these \ncases is the loop bound truly indeterminate; in the other cases, the imprecision is again caused by heap \n.ushes due to missing DOM modeling. We also ran our analysis with the potentially unsound determi\u00adnate \nDOM assumption described in Section 5.1. This enabled better inference of determinate loop bounds and \ndetection of unreachable code, allowing it to handle 20 benchmarks. In conclusion, we found that determinacy \nanalysis can be an effective tool for eliminating calls to eval.  5.3 Discussion The case studies above \nshow that determinacy facts can be useful for client analyses like .ow-insensitive static analyses. In \nprinci\u00adple, the additional context sensitivity needed to take advantage of the facts could be very expensive, \nbut it seems that, in practice, scalability problems are often due to a lack of determinacy facts. A \nmore sophisticated DOM model could help .nding more de\u00adterminacy facts, as could a more precise treatment \nof event han\u00addlers. However, soundly reasoning about all possible interleavings of event handlers is \na challenging task that we leave to future work. 6. Related Work Constant Propagation Like determinacy \nanalysis, constant prop\u00adagation aims to discover expressions that have the same value in every execution. \nUnlike in determinacy analysis, this value is usu\u00adally required to be independent of calling context \n(though context\u00adquali.ed constants have also been considered [24]) and primitive (i.e., not an object \nor array). Constant propagation typically relies on a sound static call graph, which is hard to obtain \nin dynamic lan\u00adguages like JavaScript. Our approach does not require a static call graph, but can only \nproduce fully quali.ed determinacy facts. Partial Evaluation Partial evaluation [19] seeks to identify \nand evaluate program parts that only depend on designated static inputs, yielding a residual program \nthat can be run on the remaining inputs. Online partial evaluation generates the residual program in \none pass, whereas of.ine evaluation relies on static analysis to specialize the program. Usually, it \n.rst computes a call graph, and then performs a binding time analysis to determine expressions whose \nvalue only depends on static inputs. A monovariant binding time analysis assigns a single classi.cation \nto every expression, whereas a polyvariant analysis [10] takes contexts into account. Our determinacy \nanalysis can be viewed as a polyvariant bind\u00ading time analysis where static program inputs are considered \nde\u00adterminate. Typical binding time analyses are completely static and hence do not need to know the concrete \nvalues of any inputs. On\u00adline partial evaluators, on the other hand, operate on given concrete values \nfor the static inputs. By contrast, our analysis is completely dynamic, and hence requires concrete values \nfor all inputs. The main advantage of our approach for JavaScript is that it does not rely on a static \nanalysis. Unlike an online partial evaluator, we do not need heuristics for ensuring termination: our \nanalysis can be run as long as desired and aborted at any point without endangering the soundness of \nthe results. Symbolic Execution Our counterfactual execution can be viewed as a very limited form of \nsymbolic execution [20]. Unlike sym\u00adbolic execution, our analysis performs a merge at control-.ow join \npoints, rather than maintaining two forked executions. This trades precision for performance, since we \ncannot reason about all possible values of indeterminate expressions. Information Flow Analysis Our determinacy \nanalysis is similar to a dynamic information .ow analysis [3, 32] with indeterminate inputs corresponding \nto high-security inputs. Since we want to in\u00adfer determinacy facts even under indeterminate conditionals, \nwe do not mark constants under such conditionals as indeterminate imme\u00addiately (as an information .ow \nanalysis would), but only after the branch has .nished executing. Counterfactual execution is similar \nto faceted execution [4], but rather than creating faceted values at control-.ow merge points, we mark \nthe values as indeterminate. Self-Adjusting Computation The goal of self-adjusting compu\u00adtation [1] (a \ngeneralization of incremental computation [25]) is to incrementally update the result of a computation \ngiven changes to some of its inputs. This is achieved using a dynamic dependence graph tracking computations \nthat depend on changeable inputs. Earlier systems for self-adjusting computation require programs to \nfollow a particular programming style, whereas our analysis works on arbitrary programs. More recent \nsystems [6, 7] automatically transform appropriately annotated programs into the required form, using \nan inference algorithm based on static information .ow. Such a system could be used for static determinacy \nanalysis of typed lan\u00adguages. Conversely, our analysis (which is similar to dynamic in\u00adformation .ow) \nmay itself be useful for self-adjusting computation. Trace-Based Abstract Interpretation The instrumented \ntraces in our formalization are similar to abstract derivation trees used in trace-based abstract interpretation \n[28] in that they describe a class of concrete executions. However, our traces are obtained by dy\u00adnamic \nanalysis, not static abstract interpretation. Our semantics does not yet cover in.nite derivations and \nin.nite traces. Combinations of Static and Dynamic Analysis Several re\u00adsearchers have proposed using \ninformation gathered by a dynamic analysis to specialize uses of dynamic language constructs. Furr et \nal. [13] present a type inferencer for Ruby that uses information obtained during a pro.le run to replace \ndynamic features with stat\u00adically analyzable alternatives. While their approach is technically similar \nto ours, their dynamic analysis is not sound, so a client has to account for cases where later runs do \nnot match the pro.le. Bod\u00adden et al. [5] use a similar approach to specialize re.ective Java programs, \nalso without soundness guarantees. Kneuss et al. [21] describe an (unsound) analysis for .nding type \nerrors in PHP that uses a .ow-sensitive static analysis starting from a program state recorded by a dynamic \nanalysis. Dufour et al. [12] perform static analysis for Java based on a dynamic call graph, thus essentially \nanalyzing only a single execu\u00adtion; this suf.ces for their application area of performance analysis. \nWei et al. [31] apply the same approach to JavaScript, additionally using dynamic information to eliminate \nuses of eval. They argue that this approach, while unsound, can be useful for applications such as taint \nanalysis where soundness is not always required. Combining static and dynamic analysis the other way \naround, an unsound static analysis can be supplemented with additional runtime checks to catch cases \nnot covered by the analysis. This technique has been used to enforce information .ow policies [9, 14], \nand to infer type information for JIT compilation [16]. 7. Conclusions We have presented a purely dynamic \nanalysis for identifying deter\u00adminate expressions which always have the same value at a given program \npoint. While the analysis only observes one program ex\u00adecution at a time, the facts it derives hold for \nall executions. We have proved the analysis correct for a simple imperative language, implemented it \nfor full JavaScript, and shown how its results can be used by a static analysis to deal with re.ective \nlanguage features. While our results are promising, more work is needed for the combined static-dynamic \nanalysis to realize its full potential. To generate more determinacy facts, we plan to explore automated \ntest generation [2] to improve coverage of the dynamic analysis. Run\u00adning the determinacy analysis on \ndifferent inputs yields more facts, which are all sound and hence can be used together. To generate better \ndeterminacy facts, we will work on inferring determinacy facts with shallower calling contexts. We will \ninvestigate whether these improvements are enough to make WALA scale to realistic web applications, or \nwhether more work is needed. Finally, we also plan to apply determinacy analysis to other problems such \nas par\u00adtial evaluation and dead code detection, and explore potential uses for counterfactual execution \noutside the setting of determinacy ana\u00adlysis, for instance in dynamic taint analysis. References 1. Umut \nA. Acar. Self-Adjusting Computation. Ph.D. thesis, CMU, 2005. 2. Shay Artzi, Julian Dolby, Simon Holm \nJensen, Anders M\u00f8ller, and Frank Tip. A Framework for Automated Testing of JavaScript Web Applications. \nIn ICSE, 2011. 3. Thomas H. Austin and Cormac Flanagan. Ef.cient Purely-Dynamic Information Flow Analysis. \nIn PLAS, 2009. 4. Thomas H. Austin and Cormac Flanagan. Multiple Facets for Dynamic Information Flow. \nIn POPL, 2012.  5. Eric Bodden, Andreas Sewe, Jan Sinschek, Hela Oueslati, and Mira Mezini. Taming \nRe.ection: Aiding Static Analysis in the Presence of Re.ection and Custom Class Loaders. In ICSE, 2011. \n 6. Yan Chen, Joshua Dun.eld, and Umut A. Acar. Type-Directed Auto\u00admatic Incrementalization. In PLDI, \n2012. 7. Yan Chen, Joshua Dun.eld, Matthew Hammer, and Umut Acar. Im\u00adplicit Self-Adjusting Computation \nfor Purely Functional Programs. In ICFP, 2011. 8. Aske Simon Christensen, Anders M\u00f8ller, and Michael \nI. Schwartzbach. Precise Analysis of String Expressions. In SAS, 2003. 9. Ravi Chugh, Jeffrey A. Meister, \nRanjit Jhala, and Sorin Lerner. Staged Information Flow for JavaScript. In PLDI, 2009. 10. Charles Consel. \nPolyvariant Binding-Time Analysis For Applicative Languages. In PEPM, 1993. 11. Douglas Crockford. JavaScript: \nThe Good Parts. O Reilly, 2008. 12. Bruno Dufour, Barbara G. Ryder, and Gary Sevitsky. Blended Analysis \nfor Performance Understanding of Framework-based Applications. In ISSTA, 2007. 13. Michael Furr, Jong-hoon \nAn, and Jeffrey S. Foster. Pro.le-guided Static Typing for Dynamic Scripting Languages. In OOPSLA, 2009. \n 14. Salvatore Guarnieri and V. Benjamin Livshits. GAT E K E E P E R: Mostly Static Enforcement of Security \nand Reliability Policies for JavaScript Code. In USENIX Security Symposium, 2009. 15. Arjun Guha, Claudiu \nSaftoiu, and Shriram Krishnamurthi. The Essence of JavaScript. In ECOOP, 2010. 16. Brian Hackett and \nShu-yu Guo. Fast and Precise Hybrid Type Inference for JavaScript. In PLDI, 2012. 17. Simon Holm Jensen, \nPeter A. Jonsson, and Anders M\u00f8ller. Remedying the Eval That Men Do. In ISSTA, 2012. 18. Simon Holm \nJensen, Anders M\u00f8ller, and Peter Thiemann. Type Ana\u00adlysis for JavaScript. In SAS, 2009. 19. Neil D. \nJones, Carsten K. Gomard, and Peter Sestoft. Partial evaluation and automatic program generation. Prentice-Hall, \nInc., 1993. 20. James C. King. Symbolic Execution and Program Testing. Communi\u00adcations of the ACM, 19(7), \nJuly 1976. 21. Etienne Kneuss, Philippe Suter, and Viktor Kuncak. Runtime Instru\u00admentation for Precise \nFlow-Sensitive Type Analysis. In RV, 2010. 22. Xavier Leroy and Herv\u00e9 Grall. Coinductive Big-Step Operational \nSemantics. Inf. Comput., 207(2):284 304, 2009. 23. Fadi Meawad, Gregor Richards, Flor\u00e9al Morandat, and \nJan Vitek. Eval Begone! Semi-Automated Removal of Eval from JavaScript Programs. In OOPSLA, 2012. 24. \nThomas W. Reps, Stefan Schwoon, Somesh Jha, and David Melski. Weighted Pushdown Systems and Their Application \nto Interprocedural Data.ow Analysis. Sci. Comput. Program., 58(1-2):206 263, 2005. 25. Thomas W. Reps \nand Tim Teitelbaum. The Synthesizer Generator. In SDE, 1984. 26. Gregor Richards, Christian Hammer, \nBrian Burg, and Jan Vitek. The Eval That Men Do A Large-Scale Study of the Use of Eval in Java-Script \nApplications. In ECOOP, 2011. 27. Gregor Richards, Sylvain Lebresne, Brian Burg, and Jan Vitek. An Analysis \nof the Dynamic Behavior of JavaScript Programs. In PLDI, 2010. 28. David A. Schmidt. Trace-Based Abstract \nInterpretation of Operational Semantics. Lisp and Symbolic Computation, 10(3):237 271, 1998. 29. O. \nShivers. Control Flow Analysis in Scheme. In PLDI, 1988. 30. Manu Sridharan, Julian Dolby, Satish Chandra, \nMax Sch\u00e4fer, and Frank Tip. Correlation Tracking for Points-To Analysis of JavaScript. In ECOOP, 2012. \n 31. Shiyi Wei and Barbara G. Ryder. A Practical Blended Analysis for Dynamic Features in JavaScript. \nTR 12-18, Virginia Tech, 2012. 32. Steve Zdancewic. Programming Languages for Information Security. \nPhD thesis, Cornell University, 2002.    \n\t\t\t", "proc_id": "2491956", "abstract": "<p>We present an analysis for identifying <i>determinate</i> variables and expressions that always have the same value at a given program point. This information can be exploited by client analyses and tools to, e.g., identify dead code or specialize uses of dynamic language constructs such as eval, replacing them with equivalent static constructs. Our analysis is completely dynamic and only needs to observe a single execution of the program, yet the determinacy facts it infers hold for any execution. We present a formal soundness proof of the analysis for a simple imperative language, and a prototype implementation that handles full JavaScript. Finally, we report on two case studies that explored how static analysis for JavaScript could leverage the information gathered by dynamic determinacy analysis. We found that in some cases scalability of static pointer analysis was improved dramatically, and that many uses of runtime code generation could be eliminated.</p>", "authors": [{"name": "Max Sch&#228;fer", "author_profile_id": "81381592942", "affiliation": "Nanyang Technological University, Singapore, Singapore", "person_id": "P4148981", "email_address": "schaefer@ntu.edu.sg", "orcid_id": ""}, {"name": "Manu Sridharan", "author_profile_id": "81548007966", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY, USA", "person_id": "P4148982", "email_address": "msridhar@us.ibm.com", "orcid_id": ""}, {"name": "Julian Dolby", "author_profile_id": "81548007967", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY, USA", "person_id": "P4148983", "email_address": "dolby@us.ibm.com", "orcid_id": ""}, {"name": "Frank Tip", "author_profile_id": "81548007970", "affiliation": "University of Waterloo, Waterloo, ON, Canada", "person_id": "P4148984", "email_address": "ftip@uwaterloo.ca", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462168", "year": "2013", "article_id": "2462168", "conference": "PLDI", "title": "Dynamic determinacy analysis", "url": "http://dl.acm.org/citation.cfm?id=2462168"}