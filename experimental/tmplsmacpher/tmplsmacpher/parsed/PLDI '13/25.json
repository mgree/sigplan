{"article_publication_date": "06-16-2013", "fulltext": "\n Concurrent Libraries with Foresight Guy Golan-Gueta G. Ramalingam Mooly Sagiv Tel Aviv University Microsoft \nResearch Tel Aviv University ggolan@tau.ac.il grama@microsoft.com msagiv@tau.ac.il Eran Yahav Technion \nyahave@cs.technion.ac.il Abstract Linearizable libraries provide operations that appear to execute atomically. \nClients, however, may need to execute a sequence of op\u00aderations (a composite operation) atomically. We \nconsider the prob\u00adlem of extending a linearizable library to support arbitrary atomic composite operations \nby clients. We introduce a novel approach in which the concurrent library ensures atomicity of composite \noper\u00adations by exploiting information (foresight) provided by its clients. We use a correctness condition, \nbased on a notion of dynamic right\u00admovers, that guarantees that composite operations execute atomi\u00adcally \nwithout deadlocks, and without using rollbacks. We present a static analysis to infer the foresight information \nrequired by our approach, allowing a compiler to automatically insert the foresight information into \nthe client. This relieves the client programmer of this burden and simpli.es writing client code. We \npresent a generic technique for extending the library im\u00adplementation to realize foresight-based synchronization. \nThis tech\u00adnique is used to implement a general-purpose Java library for Map data structures the library \npermits composite operations to si\u00admultaneously work with multiple instances of Map data structures. \nWe use the Maps library and the static analysis to enforce atom\u00adicity of a wide selection of real-life \nJava composite operations. Our experiments indicate that our approach enables realizing ef.cient and \nscalable synchronization for real-life composite operations. Categories and Subject Descriptors D.1.3 \n[Programming Tech\u00adniques]: Concurrent Programming; D.3.1 [Programming Lan\u00adguages]: Formal De.nitions \nand Theory; D.3.3 [Programming Languages]: Language Constructs and Features Abstract data types, Concurrent \nprogramming structures, Data types and struc\u00adtures Keywords Concurrency, Composition, Transactions, Data \nStruc\u00adtures, Automatic Synchronization Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 13, June 16 19, 2013, Seattle, WA, USA. Copyright &#38;#169; 2013 \nACM 978-1-4503-2014-6/13/06. . . $15.00  1. Introduction Writing concurrent software is hard and error \nprone. To ease the programmer s burden, programming languages such as Java, Scala, and C# provide libraries \nof ef.cient concurrent data structures. These libraries provide operations that are guaranteed to be \natomic, while hiding the complexity of the implementation from clients. Unfortunately, clients often \nneed to perform a sequence of library operations that appears to execute atomically, referred to hereafter \nas an atomic composite operation. The problem of realizing atomic composite operations is an im\u00adportant \nand widespread one [9]. Atomic composite operations are a restricted form of software transactions [15]. \nHowever, general\u00adpurpose software transaction implementations have not gained ac\u00adceptance [10] due to \ntheir high overhead as well as dif.culties in us\u00ading libraries that are incompatible with software transactions. \nPro\u00adgrammers typically realize such composite operations using ad-hoc synchronization leading to many \nconcurrency bugs in practice [27]. Concurrency Control with Foresight In this paper, we address the problem \nof extending a linearizable library [19] to allow clients to execute an arbitrary composite operation \natomically. Our basic methodology requires the client code to demarcate the sequence of operations for \nwhich atomicity is desired and provide declarative information to the library (foresight) about the library \noperations that the composite operation may invoke (as illustrated later). It is the library s responsibility \nto ensure the desired atomicity, exploit\u00ading the foresight information for effective synchronization. \nOur .rst contribution is a formalization of this approach. We formalize the desired goals and present \na suf.cient correctness condition. As long as the clients and the library extension satisfy the correctness \ncondition, all composite operations are guaranteed atomicity without deadlocks. Furthermore, our condition \ndoes not require the use of rollbacks. Our suf.ciency condition is broad and permits a range of implementation \noptions and .ne-grained synchronization. It is based on a notion of dynamic right-movers, which generalizes \ntraditional notions of static right-movers and commutativity [21, 23]. Our formulation decouples the \nimplementation of the library from the client. Thus, the correctness of the client does not depend on \nthe way the foresight information is used by library implementa\u00adtion. The client only needs to ensure \nthe correctness of the foresight information. Automatic Foresight for Clients We then present a simple \nstatic analysis to infer calls (in the client code) to the API used to pass the foresight information. \nGiven a description of a library s API, our algorithm conservatively infers the required calls. This \nrelieves the client programmer of this burden and simpli.es writing atomic composite operations. Library \nExtension Realization Our approach permits the use of customized, hand-crafted, implementations of the \nlibrary exten\u00adsion. However, we also present a generic technique for extending a linearizable library \nwith foresight. The technique is based on a variant of the tree locking protocol in which the tree is \ndesigned according to semantic properties of the library s operations. We used our technique to implement \na general-purpose Java library for Map data structures. Our library permits composite operations to simultaneously \nwork with multiple instances of Map data structures. Experimental Evaluation We use the Maps library \nand the static analysis to enforce atomicity of a wide selection of real-life Java composite operations, \nincluding composite operations that manip\u00adulate multiple instances of Map data structures. Our experiments \nindicate that our approach enables realizing ef.cient and scalable synchronization for real-life composite \noperations. Main Contributions We develop the concept of concurrent li\u00adbraries with foresight along several \ndimensions, providing the the\u00adoretical foundations, an implementation methodology, and an em\u00adpirical \nevaluation. Our main contributions are: We introduce the concept of concurrent libraries with foresight, \nin which the concurrent library ensures atomicity of composite operations by exploiting information (foresight) \nprovided by its clients. The main idea is to shift the responsibility of synchro\u00adnizing composite operations \nof the clients to the hands of the library, and have the client provide useful foresight information \nto make ef.cient library-side synchronization possible.  We de.ne a suf.cient correctness condition \nfor clients and the library extension. Satisfying this condition guarantees atomicity and deadlock-freedom \nof composite operations (Sec. 4).  We show how to realize both the client-side (Sec. 5) and the library-side \n(Sec. 6) for leveraging foresight. Speci.cally, we present a static analysis algorithm that provides \nforesight infor\u00admation to the library (Sec. 5), and show a generic technique for implementing a family \nof libraries with foresight (Sec. 6).  We realized our approach and evaluated it on a number of real-world \ncomposite operations. We show that our approach provides ef.cient synchronization (Sec. 7).  2. Overview \nWe now present an informal overview of our approach, for extend\u00ading a linearizable library into a library \nwith foresight-based syn\u00adchronization, using a toy example. Fig. 1 presents the speci.ca\u00adtion of a single \nCounter (library). The counter can be incremented (via the Inc() operation), decremented (via the Dec() \noperation), or read (via the Get() operation). The counter s value is always nonnegative: the execution \nof Dec() has an effect only when the counter s value is positive. All the counter s procedures are atomic. \nFig. 2 shows an example of two threads each executing a com\u00adposite operation: a code fragment consisting \nof multiple counter operations. (The mayUse annotations will be explained later.) Our goal is to execute \nthese composite operations atomically: a serializ\u00adable execution of these two threads is one that is \nequivalent to either thread T1 executing completely before T2 executes or vice versa. Assume that the \ncounter value is initially zero. If T2 executes .rst, then neither decrement operation will change the \ncounter value, and the subsequent execution of T1 will produce a counter value of 2. If T1 executes .rst \nand then T2 executes, the .nal value of the counter will be 0. Fig. 3 shows a slightly more complex example. \n int value = I; void Inc() { atomic { value=value+1; } } void Dec() { atomic { if (value > 0) then value=value-1; \n} } int Get() { atomic { return value; } } Figure 1. Speci.cation of the Counter library. I denotes \nthe initial value of the counter. 1 /* Thread T1 */ 1 /* Thread T2 */ 2 /* @atomic */ { 2 /* @atomic \n*/ { 3 @mayUseInc() 3 @mayUseDec() 4 Inc(); 4 Dec(); 5 Inc(); 5 Dec(); 6 @mayUseNone() 6 @mayUseNone() \n7 } 7 } Figure 2. Simple compositions of counter operations. 1 /* Thread T1 */ 2 /* @atomic */ { 3 @mayUseAll() \n1 /* Thread T2 */ 4 c = Get(); 2 /* @atomic */ { 5 @mayUseInc() 3 @mayUseDec() 6 while (c > 0) { 4 Dec(); \n7 c = c-1; 5 Dec(); 8 Inc(); 6 @mayUseNone() 9 } 7 } 10 @mayUseNone() 11 } Figure 3. Compositions of \ncounter dependent operations.  Figure 4. Execution pre.xes of the code shown in Fig. 2, for a counter \nwith I = 0. Each node represents a pre.x of an execution; a leaf node represents a complete execution. \n2.1 Serializable and Serializably-Completable Executions Fig. 4 shows pre.xes of various interleaved \nexecutions of the code shown in Fig. 2 for an initial counter value of 0. Nodes are annotated with the \nvalues of the counter. Bold double cir\u00adcles depict non-serializable nodes: these nodes denote execu\u00adtion \npre.xes that are not serializable. E.g., node #18 is a non\u00adserializable node since it represents the \nnon-serializable execution T2.Dec(); T1.I nc(); T2.Dec(); T1.I nc() (which produces a .nal counter value \nof 1). Bold single circles depict doomed nodes: once we reach a doomed node, there is no way to order \nthe remaining operations in a way that achieves serializability. E.g., node #6 is a doomed node since \nit only leads to non-serializable complete executions (rep\u00adresented by nodes #17 and #18). Finally, dashed \ncircles depict safe nodes, which represent serializably-completable executions. We formalize this notion \nlater, but safe nodes guarantee that the execution can make progress, while ensuring serializability. \nOur goal is to ensure that execution stays within safe nodes. Even in this simple example, the set of \nsafe nodes and, hence, the potential for parallelism depends on the initial value I of the counter. For \nI = 1 all nodes are safe and thus no further syn\u00adchronization is necessary. Using our approach enables \nrealizing all available parallelism in this example (for every I = 0), while avoiding the need for any \nbacktracking (i.e., rollbacks).  2.2 Serializably-Completable Execution: A Characterization We now present \na characterization of serializably-completable ex\u00adecutions based on a generalization of the notion of \nstatic right movers [23]. We restrict ourselves to executions of two threads here, but our later formalization \nconsiders the general case. We de.ne an operation o by a thread T to be a dynamic right\u00admover with respect \nto thread T ' after an execution p, iff for any sequence of operations s executed by T ', if p; T .o; \ns is feasible, then p; s; T .o is feasible and equivalent to the .rst execution. Given an execution ., \nwe de.ne a relation c on the threads as follows: T c T ' if . contains a pre.x p; T .o such that o is \nnot a dynamic right-mover with respect to T ' after p. As shown later, if c is acyclic, then . is a serializably-completable \nexecution (as long as every sequential execution of the threads terminates). In Fig. 4, node #2 represents \nthe execution pre.x T1.I nc() for which T1 c T2.This is because T2.Dec() is a possible suf\u00ad.x executed \nby T2, and T1.I nc(); T2.Dec() is not equivalent to T2.Dec(); T1.I nc(). On the other hand, node #5 represents \nthe execution pre.x T1.I nc(); T2.Dec() for which T2 c T1.This ex\u00adecution has one possible suf.x executed \nby T1 (i.e., T1.I nc()), and the execution T1.I nc(); T2.Dec(); T1.I nc() is equivalent to the execution \nT1.I nc(); T1.I nc(); T2.Dec(). Observe that the relation c corresponding to any non-serializable or \ndoomed node has a cycle, while it is acyclic for all safe nodes. Note that the use of a dynamic (i.e., \nstate-dependent) right\u00admover relation is critical to a precise characterization above. E.g., I nc and \nDec are not static right-movers with respect to each other.  2.3 Synchronization Using Foresight We \nnow show how we exploit the above characterization to ensure that an interleaved execution stays within \nsafe nodes. Foresight. A key aspect of our approach is to exploit knowledge about the possible future \nbehavior of composite operations for more effective concurrency control. We enrich the interface of the \nlibrary with operations that allow the composite operations to assert temporal properties of their future \nbehavior. In the Counter example, assume that we add the following operations: mayUseAll(): indicates \ntransaction may execute arbitrary oper\u00adations in the future.  mayUseNone(): indicates transaction will \nexecute no more op\u00aderation.  mayUseDec(): indicates transaction will invoke only Dec oper\u00adations in \nthe future.  mayUseInc(): indicates transaction will invoke only Inc oper\u00ad  ations in the future. The \ncode in Fig. 2 is annotated with calls to these operations in a straightforward manner. The code shown \nin Fig. 3, is conservatively annotated with a call to mayUseAll() since the interface does not provide \na way to indicate that the transaction will only invoke Get and Inc operations. Utilizing Foresight. \nWe utilize a suitably modi.ed de.nition of the dynamic right mover relation, where we check for the right \nmover condition only with respect to the set of all sequences of operations the other threads are allowed \nto invoke (as per their foresight assertions). To utilize foresight information, a library implementation \nmaintains a conservative over-approximation c' of the c relation. The implementation permits an operation \nto proceed iff it will not cause the relation c' to become cyclic (and blocks the operation otherwise \nuntil it is safe to execute it). This is suf.cient to guarantee that the composite operations appear \nto execute atomically, without any deadlocks. We have created an implementation of the counter that (implic\u00aditly) \nmaintains a conservative over-approximation c' (see [14]). Our implementation permits all serializably-completable \nexecution pre.xes for the example shown in Fig. 2 (for every I = 0). Our implementation also provides \nhigh degree of parallelism for the ex\u00adample shown in Fig. 3 for this example the loop of T1 can be executed \nin parallel to the execution of T2. Fine-grained Foresight. We de.ne a library operation to be a tuple \nthat identi.es a procedure as well as the values of the procedure s arguments. For example, removeKey(1) \nand removeKey(2) are two different operations of a library with the procedure removeKey(int k). In order \nto distinguish between different op\u00aderations which are invoked using the same procedure, a mayUse procedure \n(which is used to pass the foresight information) can have parameters. For example, a library that represents \na single Map data structure can have a mayUse procedure mayUseKey(int k), where mayUseKey(1) is de.ned \nto refer to all operations on key 1 (including, for example, removeKey(1)), and mayUseKey(2) is de.ned \nto refer to all operations on key 2 (including, for example, removeKey(2)). Special Cases. Our approach \ngeneralizes several ideas that have been proposed before. One example, from databases, is locking that \nis based on operations-commutativity (e.g., see [8, chapter 3.8]). Such locking provides several lock \nmodes where each mode cor\u00adresponds to a set of operations; two threads are allowed to execute in parallel \nas long as they do not hold lock modes that correspond to non-commutative operations. A simple common \ninstance is a read-write lock [12], in which threads are allowed to simultane\u00adously hold locks in a read-mode \n(which corresponds with read-only operations that are commutative with each other). Interestingly, the \ncommon lock-acquire and lock-release operations used for locking, can be seen as special cases of the \nprocedures used to pass the foresight information. 2.4 Realizing Foresight Based Synchronization What \nwe have described so far is a methodology and formalism for foresight-based concurrency control. This \nprescribes the conditions that must be satis.ed by the clients and library implementations to ensure \natomicity for composite operations. Automating Foresight For Clients. One can argue that adding calls \nto mayUse operations is an error prone process. Therefore, in Sec\u00adtion 5 we show a simple static analysis \nalgorithm which conser\u00advatively infers calls to mayUse operations (given a description of the mayUse \noperations supported by the library). Our experience indicates that our simple algorithm can handle real-life \nprograms. Library Implementation. We permit creating customized, hand\u00adcrafted, implementations of the \nlibrary extension (a simple example is demonstrated in [14]). However, in order to simplify creating \nsuch libraries, we present a generic technique for implementing a family of libraries with foresight \n(Section 6). The technique is based on a variant of the tree locking protocol in which the tree is designed \naccording to semantic properties of the library s operations. We have utilized the technique to implement \na general purpose Java library for Map data structures. Our library permits a composite operation to \nsimultaneously work with multiple maps. 3. Preliminaries 3.1 Libraries A library A exposes a set of \nprocedures PROCSA. We de.ne a library operation to be a tuple (p, v1, \u00b7 \u00b7 \u00b7 , vk) consisting of a pro\u00adcedure \nname p and a sequence of values (representing actual values of the procedure arguments). The set of operations \nof a library A is denoted by OPA. Library operations are invoked by client threads (de.ned later). Let \nT denote the set of all thread identi.ers. An event is a tuple (t, m, r), where t is a thread identi.er, \nm is a li\u00adbrary operation, and r is a return value. An event captures both an operation invocation as \nwell as its return value. A history is de.ned to be a .nite sequence of events. The seman\u00adtics of a library \nA is captured by a set of histories HA. If h . HA, then we say that h is feasible for A. Histories capture \nthe inter\u00adaction between a library and its client (a set of threads). Though multiple threads may concurrently \ninvoke operations, this simple formalism suf.ces in our setting, since we assume the library to be linearizable. \nAn empty history is an empty sequence of events. Let h . h ' denote the concatenation of history h ' \nto the end of history h. Note that the set HA captures multiple aspects of the library s speci.cation. \nIf h is feasible, but h . (t, m, r) is not, this could mean one of three different things: r may not \nbe a valid return value in this context, or t is not allowed to invoke m is this context, or t is allowed \nto invoke m in this context, but the library will block and not return until some other event has happened. \nA library A is said to be total if for any thread t, operation m . OPA and h . HA, there exists r such \nthat h.(t, m, r) . HA.  3.2 Clients We now brie.y describe clients and their semantics. (A more com\u00adplete \nde.nition appears in [14].) A client t1 || t2 || \u00b7 \u00b7 \u00b7 || tn con\u00adsists of the parallel composition of \na set of client programs ti (also referred to as threads). Each ti is a sequential program built out \nof two types of statements: statements that change only the thread s local-state, and statements that \ninvoke a library operation. Threads have no shared state except the (internal) state of the library, \nwhich is accessed or modi.ed only via library operations. The semantics [ ti] of a single thread ti is \nde.ned to be a la\u00adbelled transition system (Si, .i) over a set of thread-local states Si, with some states \ndesignated as initial and .nal states. The exe\u00adcution of any instruction other than a library operation \ninvocation is } represented by a (thread-local) transition s .i s ' . The execution of a library operation \ninvocation is represented by a transition of the form s .ei s ' , where event e captures both the invocation \nas well as the return value. This semantics captures the semantics of the open program ti. When ti is \nclosed by combining it with a library A, the semantics of the resulting closed program is obtained by \ncombining [ ti] with the semantics of A, as illustrated later. A ti-execution is de.ned to be a sequence \nof ti-transitions a1a2ak s0 .i s1, s1 .i s2, \u00b7 \u00b7 \u00b7 , sk-1 .i sk such that s0 is an initial state of ti \nand every aj is either E or an event. Such an execution is said to be complete if sk is a .nal state \nof ti. The semantics of a client C = t1 || \u00b7 \u00b7 \u00b7 || tn is obtained by composing the semantics of the \nindividual threads, permitting any arbitrary interleaving of the executions of the threads. We de.ne \nthe set of transitions of C to be the disjoint union of the set of transitions of the individual threads. \nA C-execution is de.ned to be a sequence . of C-transitions such that each . | ti is a ti-execution, \nwhere . | ti is the subsequence of . consisting of all ti-transitions. We now de.ne the semantics of \nthe composition of a client C with a library A. Given a C-execution ., we de.ne f(.) to be the sequence \nof event labels in .. The set of (C, A)-executions is de.ned to be the set of all C-executions . such \nthat f(.) . HA. We abbreviate (C, A)-execution to execution if no confusion is likely. Threads as Transactions \nOur goal is to enable threads to execute code fragments containing multiple library operations as atomic \ntransactions (i.e., in isolation). For notational simplicity, we assume that we wish to execute each \nthread as a single transaction. (Our results can be generalized to the case where each thread may wish \nto perform a sequence of transactions.) In the sequel, we may think of threads and transactions interchangeably. \nThis motivates the following de.nitions. Non-Interleaved and Sequential Executions An execution . is \nsaid to be a non-interleaved execution if for every thread t all t\u00adtransitions in . appear contiguously. \nThus, a non-interleaved execu\u00adtion . is of the form .1, \u00b7 \u00b7 \u00b7 , .k, where each .i represents a different \nthread s (possibly incomplete) execution. Such a non-interleaved execution is said to be a sequential \nexecution if for each 1 = i < k, .i represents a complete thread execution. Serializability Two executions \n. and . ' are said to be equivalent iff for every thread t, . | t = . ' | t. An execution . is said to \nbe serializable iff it is equivalent to some non-interleaved execution. Serializably Completable Executions \nFor any execution ., let W(.) denote the set of all threads that have at least one transi\u00adtion in .. \nAn execution . is said to be a complete execution iff . | t is complete for every thread t . W(.). A \nclient execution . is completable if . is a pre.x of a complete execution .c such that W(.) = W(.c). \nAn execution . is said to be serializably com\u00adpletable iff . is a pre.x of a complete serializable execution \n.c such that W(.) = W(.c). Otherwise, we say that . is a doomed execution. An execution may be incompletable \ndue to problems in a client thread (e.g., a non-terminating loop) or due to problems in the library (e.g., \nblocking by a library procedure leading to deadlocks). 4. Foresight-Based Synchronization We now formalize \nour goal of extending a base library B into a foresight-based library E that permits clients to execute \narbitrary composite operations atomically. 4.1 The Problem Let B be a given total library. (Note that \nB can also be considered to be a speci.cation.) We say that a library E is a restrictive extension of \nB if (i) PROCSE . PROCSB, (ii) {h . B | h . HE } . HB, where h . B is the subsequence of events in h \nthat represent calls of operations in OPB, and (iii) PROCSE \\ PROCSB do not have a return value. We are \ninterested in extensions where the extension procedures (PROCSE \\ PROCSB) are used for synchronization \nto ensure that each thread appears to execute in isolation. Given a client C of the extended library \nE, let C . B denote the program obtained by replacing every extension procedure invo\u00adcation in C by the \nskip statement. Similarly, for any execution . of (C, E), we de.ne . . B to be the sequence obtained \nfrom . by omit\u00adting transitions representing extension procedures. We say that an execution . of (C, \nE) is B-serializable if . . B is a serializable ex\u00adecution of (C . B, B). We say that . is B-serializably-completable \nif . . B is a serializably completable execution of (C . B, B). We say that E is a transactional extension \nof B if for any (correct) client C of E, every (C, E)-execution is B-serializably-completable. Our goal \nis to build transactional extensions of a given library.  4.2 The Client Protocol In our approach, the \nextension procedures are used by transactions (threads) to provide information to the library about the \nfuture operations they may perform. We refer to procedures in PROCSE \\ PROCSB as mayUse procedures, and \nto operations in MUE = OPE \\ OPB as mayUse operations. We now formalize the client protocol, which captures \nthe preconditions the client must satisfy, namely that the foresight information provided via the mayUse \noperations must be correct. The semantics of mayUse operations is speci.ed by a function mayE : MUE . \nP(OPB) that maps every mayUse operation to a set of base library operations1. In Section 5 we show simple \nprocedure annotations that can be used to de.ne the set MUE and the function mayE . The mayUse operations \nde.ne an intention-function IE : HE \u00d7 T . P (OPB) where IE (h, t) represents the set of (base library) \noperations thread t is allowed to invoke after the execution of h. For every thread t . T and a history \nh . HE , the value of IE (h, t) is de.ned as follows. Let M denote the set of all mayUse operations invoked \nby t in h. (I) I F M I S N ON-E M P T Y, T HE N IE (h, t) = i mayE (m). (I I) I F M I S E M P T Y, T \nH E N IE (h, t) = {}. We m.M extend the notation and de.ne IE (h, T ), for any set of threads T , to \nbe t.T IE (h, t). Once a thread executes its .rst mayUse operation, the intention set IE (h, t) can only \nshrink as the execution proceeds. Subsequent mayUse operations cannot be used to increase the intention \nset. DE FI NI TI O N 1 (Client Protocol). Let h be a history of library E. We say that h follows the \nclient protocol if for any pre.x h ' . (t, m, r) of h, we have m . IE (h ' , t) . MUE . We say that an \nexecution . follows the client protocol, if f(.) follows the client protocol.  4.3 Dynamic Right Movers \nWe now consider how the library extension can exploit the foresight information provided by the client \nto ensure that the interleaved ex\u00adecution of multiple threads is restricted to safe nodes (as described \nin Section 2). First, we formalize the notion of a dynamic right mover. Given a history h of a library \nA, we de.ne the set EA[h] to be {h ' | h . h ' . HA}. (Note that if h is not feasible for A, then EA[h] \n= \u00d8.) Note that if EA[h1] = EA[h2], then the concrete library states produced by h1 and h2 cannot be \ndistinguished by any client (using any sequence of operations). Dually, if the concrete states produced \nby histories h1 and h2 are equal, then EA[h1] = EA[h2]. DE FI NI TI O N 2 (Dynamic Right Movers). Given \na library A, a history h1 is said to be a dynamic right mover with respect to a history h2 in the context \nof a history h, denoted h : h1 CA h2, iff EA[h . h1 . h2] . EA[h . h2 . h1]. An operation m is said to \nbe a dynamic right mover with respect to a set of operations Ms in the context of a history h, denoted \nh : m CA Ms, iff for any event (t,m,r) and any history hs consisting of operations in Ms, we have h : \n(t, m, r) CA hs. The following example shows that an operation m can be a dynamic right mover with respect \nto a set M after some histories but not after some other histories. 1 Our approach can be extended to \nuse a more precise semantic function mayE : MUE . P(OP* ) that maps each mayUse operation to a set B \nof sequence of operations, enabling client transactions to more precisely describe their future behavior. \n EX A M PL E 4.1. Consider the Counter described in Section 2. Let hp be a history that ends with a counter \nvalue of p > 0. The operation Dec is a dynamic right mover with respect to the set {Inc} in the context \nof hp since for every n the histories hp . (t, Dec, r) . (t1, I nc, r1), . . . , (tn, I nc, rn) and hp \n. (t1, I nc, r1), . . . , (tn, I nc, rn) . (t, Dec, r) have the same set of suf.xes (since the counter \nvalue is p - 1 + n after both histories). Let h0 be a history that ends with a counter value of 0. The \noperation Dec is not a dynamic right mover with respect to the set {Inc} in the context of h0 since after \na history h0 . (t, Dec, r) . (t ' , I nc, r ' ) the counter s value is 1, and after h0 . (t ' , I nc, \nr ' ) . (t, Dec, r) the counter s value is 0. Thus, (t, Get, 1) is a feasible suf.x after the .rst history \nbut not the second. The following example shows that the dynamic right mover is not a symmetric property. \nEX A M PL E 4.2. Let hi be a history that ends with a counter value of i > 0. The operation Inc is not \na dynamic right mover with respect to the set {Dec} in the context of hi since after a history hi .(t, \nI nc, r).(t1, Dec, r1), . . . , (ti+1, Dec, ri+1) the Counter s value is 0, and after hi . (t1, Dec, \nr1), . . . , (ti+1, Dec, ri+1) . (t, I nc, r) the Counter s value is 1. One important aspect of the de.nition \nof dynamic right movers is the following: it is possible to have h : m CA {m1} and h : m CA {m2} but \nnot h : m CA {m1, m2}. Static Movers. We say that an operation m is a static right mover with respect \nto operation m ', if every feasible history h satis.es h : m CA {m ' }. We say that m and m ' are statically-commutative, \nif m is a static right mover with respect to m ' and vice versa. 4.4 Serializability It follows from \nthe preceding discussion that an incomplete history h may already re.ect some execution-order constraints \namong the threads that must be satis.ed by any other history that is equivalent to h. These execution-order \nconstraints can be captured as a partial\u00adordering on thread-ids. DE FIN I T I ON 3 (Safe Ordering). Given \na history h of E, a partial ordering g . T \u00d7 T , is said to be safe for h iff for any pre.x h ' . (t, \nm, r) of h, where m . OPB, we have h ' . B : m CB I(h ' , T ), where T = {t ' . T | t g t ' }. A safe \nordering represents a conservative over-approximation of the execution-order constraints among thread-ids \n(required for serializability). Note that in the above de.nition, the right-mover property is checked \nonly with respect to the base library B. EX A M PL E 4.3. Assume that the Counter is initialized with \na value I > 0. Consider the history (return values omitted for brevity): h = (t, mayU seDec), (t ' , \nmayU seI nc), (t, Dec), (t ' , I nc). If g is a safe partial order for h, then t ' g t because after \nthe third event Inc is not a dynamic right mover with respect to the operations allowed for t (i.e., \n{Dec}). Dually, the total order de.ned by t ' g ' t is safe for h since after the second event, the operation \nDec is a dynamic right mover with respect to the operations allowed for t ' (i.e., {Inc}) because the \nCounter s value is larger than 0. DE FINI T I ON 4 (Safe Extension). We say that library E is safe ex\u00adtension \nof B, if for every h . HE that follows the client protocol there exists a partial ordering gh on threads \nthat is safe for h. The above de.nition prescribes the synchronization (speci.\u00adcally, blocking) that \na safe extension must enforce. In particular, assume that h is feasible history allowed by the library. \nIf the his\u00adtory h . (t, m, r) has no safe partial ordering, then the library must block the call to m \nby t rather than return the value r. TH EO R E M 4.1 (Serializability). Let E be a safe extension of \na library B. Let C be a client of E. Any execution . of (C, E) that follows the client protocol is B-serializable. \nThe proofs appear in [14].  4.5 B-Serializable-Completability We saw in Section 2 and Fig. 4 that some \nserializable (incomplete) executions may be doomed: i.e., there may be no way of complet\u00ading the execution \nin a serializable way. Safe extensions, however, ensure that all executions avoid doomed nodes and are \nserializ\u00adably completable. However, we cannot guarantee completability if a client thread contains a \nnon-terminating loop or violates the client protocol. This leads us to the following conditional theorem. \nTH EO R E M 4.2 (B-Serializable-Completability). Let E be a safe extension of a total library B. Let \nC be a client of E. If every sequential execution of (C, E) follows the client protocol and is completable, \nthen every execution of (C, E) is B-serializably\u00adcompletable. The precondition in the above theorem is \nworth noting. We re\u00adquire client threads to follow the client protocol and terminate. However, it is \nsuf.cient to check that clients satisfy these require\u00adments in sequential executions. This simpli.es \nreasoning about the clients. 4.6 E-Completability The preceding theorem about B-Serializable-Completability \nhas a subtle point: it indicates that it is possible to complete any execu\u00adtion of (C, E) in a serializable \nfashion in B. The extended library E, however, could choose to block operations unnecessarily and pre\u00advent \nprogress. This is undesirable. We now formulate a desirable progress condition that the extended library \nmust satisfy. In the sequel we assume that every thread (transaction) always executes a mayUse operation \nm such that mayE (m) = {} before it terminates. (Essentially, this is an end-transaction operation.) \nGiven a history h and a thread t, we say that t is incomplete after h iff IE (h, t) = \u00d8. We say that \nhistory h is incomplete if there exists some incomplete thread after h. We say that a thread t is enabled \nafter history h, if for all events (t, m, r) such that h . (t, m, r) satis.es the client protocol and \nh . (t, m, r) . B . HB, we have h . (t, m, r) . HE . Note that this essentially means that E will not \nblock t from performing any legal operation. DE FI NI TI O N 5 (Progress Condition). We say that a library \nE sat\u00adis.es the progress condition iff for every history h . HE that fol\u00adlows the client protocol the \nfollowing holds: If h is incomplete, then at least one of the incomplete threads t is enabled after \nh.  If h is complete, then every thread t that does not appear in h is enabled after h.  TH EO R E \nM 4.3 (E-Completability). Let E be a safe extension of a total library B that satis.es the progress condition. \nLet C be a client of E. If every sequential execution of (C, E) follows the client protocol and is completable, \nthen every execution of (C, E) is completable and B-serializable.  4.7 Special Cases In this subsection \nwe describe two special cases of safe extension. int createNewMap(); int put(int mapId,int k,int v); \nint get(int mapId,int k); int remove(int mapId,int k); bool isEmpty(int mapId); int size(int mapId); \n Figure 5. Base procedures of the example Maps library. Eager-Ordering Library Our notion of safe-ordering \npermits gto be a partial order. In effect, this allows the system to deter\u00admine the execution-ordering \nbetween transactions lazily, only when forced to do so (e.g., when one of the transactions executes a \nnon\u00adright-mover operation). One special case of this approach is to use a total order on threads, eagerly \nordering threads in the order in which they execute their .rst operations. The idea of shared\u00adordered \nlocking [7] in databases is similar to this. Using such ap\u00adproach guarantees strict-serializability [25] \nwhich preserves the runtime order of the threads. DE FIN I T I ON 6. Given a history h we de.ne an order \n=h of the threads in h such that: t =h t ' iff t = t ' or the .rst event of t precedes the the .rst event \nof t ' (in h). DE FIN I T I ON 7 (Eager-Ordering Library). We say that library E is eager-ordering if \nfor every h . HE that follows the client protocol, =h is safe for h. Commutative-Blocking Library A special \ncase of eager-ordering library is commutative-blocking library. (This special case is com\u00admon in the \ndatabase literature, e.g., see [8, chapter 3.8]). The idea here is to ensure that two threads are allowed \nto execute concur\u00adrently only if any operations they can invoke commute with each other. This is achieved \nby treating each mayUse operation as a lock acquisition (on the set of operations it denotes). A mayUse \nopera\u00adtion m by any thread t, after a history h, will be blocked if there exists a thread t ' = t such \nthat some operation in mayE (m) does not statically commute with some operation in IE (h, t ' ). DE FIN \nI T I ON 8 (Commutative-Blocking Library). We say that li\u00adbrary E is commutative-blocking, if for every \nh . HE that follows the client protocol: '' ' if t = t , m . IE (h, t) and m . IE (h, t ' ), then m \nand m are statically-commutative. Note that, for the examples shown in Section 2 such library will not \nallow the threads to run concurrently. This is because the operations Inc and Dec are not statically-commutative. \n5. Automatic Foresight for Clients In this section, we present our static analysis to infer calls (in \nthe client code) to the API used to pass the foresight information. The static analysis works for the \ngeneral case covered by our formalism, and does not depend on the speci.c implementation of the extended \nlibrary. We assume that we are given the interface of a library E that extends a base library B, along \nwith a speci.cation of the seman\u00adtic function mayE using a simple annotation language. We use a static \nalgorithm for analyzing a client C of B and instrumenting it by inserting calls to mayUse operations \nthat guarantee that (all sequential executions of) C correctly follows the client protocol. Example Library. \nIn this section, we use a library of Maps as an example. The base procedures of the library are shown \nin Fig. 5 (their semantics will be described later). The mayUse procedures are shown in Fig. 6 their \nsemantic function is speci.ed using the annotations that are shown in this .gure. void mayUseAll();@{(createNewMap),(put,*,*,*),(get,*,*), \n(remove,*,*),(isEmpty,*),(size,*)} void mayUseMap(int m);@{(put,m,*,*),(get,m,*),(remove,m,*), (isEmpty,m),(size,m)} \nvoid mayUseKey(int m,int k);@{(put,m,k,*),(get,m,k), (remove,m,k)} void mayUseNone();@{} Figure 6. Annotated \nmayUse procedures of the example library. mayUseMap(m); if (get(m,x) == get(m,y)) { mayUseKey(m,x); remove(m,x); \nmayUseNone(); } else { remove(m,x); mayUseKey(m,y); remove(m,y); mayUseNone(); } Figure 7. Code section \nwith inferred calls to mayUse procedures. Fig. 7 shows an example of a code section with calls to the \nbase library procedures. The calls to mayUse procedures shown in bold are inferred by our algorithm. \n 5.1 Annotation Language The semantic function is speci.ed using annotations. These anno\u00adtations are \ndescribed by symbolic operations and symbolic sets. Let PVar be a set of variables, and * be a symbol \nsuch that * . PVar. A symbolic operation (over PVar) is a tuple of the form (p, a1, \u00b7 \u00b7 \u00b7 , an), where \np is a base library procedure name, and each ai . PVar . {*}. A symbolic set is a set of symbolic operations. \nEX A M P L E 5.1. Here are four symbolic sets for the example library (we assume that m, k . PVar): SY1 \n= {(createNewMap), (put, *, *, *), (get, *, *), (remove , *, *), (isEmpty, *), (size, *)} SY2 = {(put, \nm, *, *), (get, m, *), (remove , m, *), (isEmpty, m), (size, m)} SY3 = {(put, m, k, *), (get, m, k), \n(remove , m, k)}. SY4 = {} Let Value be the set of possible values (of parameters of base library procedures). \nGiven a function asn : P V ar . Value and a symbolic set SY, we de.ne the set of operations SY(asn) to \nbe  {(p, v1, . . . , vn) | .i.(ai = *) . (vi = asn(ai))}. (p,a1,...,an).SY EX A M P L E 5.2. Consider \nthe symbolic sets from Example 5.1. The set SY3(asn) contains all operations with the procedures put, \nget, and remove in which the .rst parameter is equal to asn(m) and the second parameter is equal to asn(k). \nThe sets SY1(asn) and SY4(asn) are not dependent on asn. The set SY1(asn) contains all operations with \nthe procedures createNewMap, put, get, remove, isEmpty and size. The set SY4(asn) is empty. The Annotations \nEvery mayUse procedure p is annotated with a symbolic set over the the set of formal parameters of p. \nIn Fig. 6, the procedure mayUseAll is annotated with SY1, mayUseMap is annotated with SY2, mayUseKey \nis annotated with SY3, and mayUseNone is annotated with SY4. Let p be a mayUse procedure with parameters \nx1, . . . , xn which is annotated with SYp. An invocation of p with the val\u00adues v1, . . . , vn is a mayUse \noperation that refers to the set de.ned by SYp and a function that maps xi to vi (for every 1 = i = n). \nEX A M P L E 5.3. In Fig. 6, the procedure mayUseAll() is an\u00adnotated with SY1, hence its invocation is \na mayUse operation that refers to all the base library operations . The procedure mayUseKey(int m, int \nk) is annotated with SY3, hence mayUseKey(0,7) refers to all operations with the procedures put, get, \nand remove in which the .rst parameter is 0 and the the sec\u00adond parameter is 7.  5.2 Inferring Calls \nto mayUse Procedures We use a simple abstract interpretation algorithm to infer calls to mayUse procedures. \nGiven a client C of B and annotated mayUse procedures, our algorithm conservatively infers calls to the \nmayUse procedures such that the client protocol is satis.ed in all sequential executions of C. We have \nimplemented the algorithm for Java programs in which the relevant code sections are annotated as atomic. \nMore details are described in [14]. Assumptions. The algorithm assumes that there exists a mayUse procedure \n(with no parameters) that refers to the set of all base library operations (the client protocol can always \nbe enforced by adding a call to this procedure at the beginning of each code section). It also assumes \nthat there exists a mayUse procedure (with no parameters) that refers to an empty set, the algorithm \nadds a call to this procedure at the end of each code section. Limitations. Our implementation may fail \nto enforce atomicity of the code sections because: (i) Java code can access shared-memory which is not \npart of the extended library (e.g., by accessing a global variable); (ii) our simple implementation does \nnot analyze the procedures which are invoked by the annotated code sections. The implementation reports \n(warnings) about suspected accesses (to shared-memory) and about invocations of procedures that do not \nbelong to the extended library. These reports should be handled by a programmer or by a static algorithm \n(e.g., purity analysis [28]) that veri.es that they will not be used for inter-thread communication (in \nour formal model, they can be seen as thread-local operations). 6. Implementing Libraries with Foresight \nIn this section we present a generic technique for realizing an eager\u00adordering safe extension (see De.nition \n7) of a given base library B. Our approach exploits a variant of the tree locking protocol over a tree \nthat is designed according to semantic properties of the library s operations. In Section 6.1 we describe \nthe basic idea of our technique which is based on locking and static commutativity. In Section 6.2 we \nshow how to utilize dynamic properties like dynamic right-movers. In Section 6.3 we show an optimistic \nsynchronization that enables mitigating lock contention that may be caused by the locking in our approach. \nFurther extensions of our technique are described in [14]. 6.1 The Basic Approach Example Library. Here, \nwe use the example from Section 5. The procedures of the base library are shown in Fig. 5. The procedure \ncreateNewMap creates a new Map and returns a unique identi.er corresponding to this Map. The other procedures \nhave the standard meaning (e.g., as in java.util.Map), and identify the Map to be operated on using the \nunique mapId identi.er. In all procedures, k is a key, v is a value. We now describe the mayUse procedures \nwe use to extend the library interface (formally de.ned in Fig. 6): (1) mayUseAll(): indicates that the \ntransaction may invoke any library operations. (2) mayUseMap(int mapId): indicates that the transaction \nwill invoke operations only on Map mapId; (3) mayUseKey(int mapId, int k) : indicates that the transaction \nwill invoke opera\u00adtions only on Map mapId and key k; (4) mayUseNone(): indicates the end of transaction \n(it will invoke no more operations). In the following, we write mayE (m) to denote the the set of operations \nassociated with the mayUse operation m. Figure 8. A locking-tree used in the example. Implementation \nParameters Our technique is parameterized and permits the creation of different instantiations offering \ntradeoffs between concurrency granularity and overheads. The parameters to our extension are a locking-tree \nand a lock-mapping. A locking-tree is a directed static tree where each node n rep\u00adresents a (potentially \nunbounded) set of library operations On, and satis.es the following requirements: (i) the root of the \nlocking-tree represents all operations of the base library; (ii) if n ' is a child of n, then On1 . On; \n(iii) if n and n ' are roots of disjoint sub-trees, then every m . On and m ' . On1 are statically-commutative. \nEX A M P L E 6.1. Fig. 8 shows a possible locking-tree for the Map library. The root A represents all \n(library) operations. Each Mi (i = 0, 1) represents all operations with argument mapId that satis.es2 \n: i = mapId % 2. Each Kj i (i = 0, 1 and j = 0, 1, 2) represents all operations with arguments mapId \nand k that satisfy: i = mapId % 2 . j = k% 3. The lock-mapping is a function P from mayUse operations \nto tree nodes and a special value .. For a mayUse operation m, P (m) is the node which is associated \nwith m. For each mayUse operation m, P should satisfy: if mayE (m) = \u00d8, then mayE (m) . OP (m), otherwise \nP (m) = .. EX A M P L E 6.2. Here is a possible lock-mapping for our example. mayUseAll() is mapped to \nthe root A. mayUseMap(mapId) is mapped to Mi where i = mapId % 2. mayUseKey(mapId,k) is mapped to Kj \ni where i = mapId % 2 . j = k% 3. mayUseNone() is mapped to .. Implementation We associate a lock with \neach node of the locking\u00adtree. The mayUse operations are implemented as follows: The .rst invocation \nof a mayUse operation m by a thread or transaction (that has not previously invoked any mayUse operation) \nacquires the lock on P (m) as follows. The thread follows the path in the tree from the root to P (m), \nlocking each node n in the path before accessing n s child. Once P (m) has been locked, the locks on \nall nodes except P (m) are released.3  An invocation of a mayUse operation m ' by a thread that holds \nthe lock on P (m), locks all nodes in the path from P (m) to P (m ' ) (in the same tree order), and then \nreleases all locks  '' ' except P (m ). If P (m ) = P (m) or P (m ) is not reachable ' from P (m), 4 \nthen the execution of m has no impact. If a mayUse operation m is invoked by t and P (m) = ., then t \nreleases all its owned locks . Furthermore, our extension adds a wrapper around every base library procedure, \nwhich works as follows. When a non-mayUse 2 We write % to denote the modulus operator. Note that we can \nuse a hash function (before applying the modulus operator). 3 This is simpli.ed version. Other variants, \nsuch as hand-over-hand locking, will work as well. 4 This may happen, for example, when OP (m1) . OP \n(m). operation m is invoked, the current thread t must hold a lock on some node n (otherwise, the client \nprotocol is violated). Conceptu\u00adally, this operation performs the following steps: (1) wait until all \nthe nodes reachable from n are unlocked; (2) invoke m of the base library and return its return value. \nHere is a possible pseudo-code for isEmpty: bool isEmpty(int mapId) { n := the node locked by the current \nthread if(n is not defined) error // optional wait until all nodes reachable from n are unlocked return \nbaseLibrary.isEmpty(mapId); } Correctness The implementation satis.es the progress condition because: \nif there exist threads that hold locks, then at least one of them will never wait for other threads (because \nof the tree structure, and because the base library is total). We say that t is smaller than t ', if \nthe lock held by t is reachable from the lock held by t '. The following property is guaranteed: if t \n=h t ' (see De.nition 6) then either t is smaller than t ' or all oper\u00adations allowed for t and t ' are \nstatically-commutative. In an imple\u00admentation, a non-mayUse operation waits until all smaller threads \nare completed, hence the extended library is a safe extension. Further Extensions In [14] we show extensions \nof the basic ap\u00adproach. We show how to associate several nodes with the same mayUse operation this enables, \nfor example, mayUse operation that is associated with operations on several different keys. We also show \nhow to utilize read-write locks this enables situations in which several threads hold the same lock \n(node). 6.2 Using Dynamic Information The dynamic information utilized by the basic approach is limited. \nIn this section we show two ways that enable (in some cases) to avoid blocking by utilizing dynamic information. \n6.2.1 Utilizing the State of the Locks In the basic approach, a non-mayUse operation, invoked by thread \nt, waits until all the reachable nodes (i.e., reachable from the node which is locked by t) are unlocked \n this ensures that the operation is a right-mover with respect to the preceding threads. In some cases \nthis is too conservative; for example: EX A M PL E 6.3. Consider the example from Section 6.1, and a \ncase in which thread t holds a lock on M0 (assume t is allowed to use all operations of a single Map). \nIf t invokes remove(0,6) it will wait until K0 0 , K1 0 and K2 0 are unlocked. But, waiting for K1 0 \nand K2 0 is not needed, because threads that hold locks on these nodes are only allowed to invoke operations \nthat are commutative with remove(0,6). In this case it is suf.cient to wait until K0 0 is unlocked. So, \nif a non-mayUse operation m is invoked, then it is suf.cient to wait until all reachable nodes in the \nfollowing set are unlocked: {n | .m ' . On : m is not static-right-mover with m ' }  6.2.2 Utilizing \nthe State of the Base Library In some cases, the state of the base library can be used to avoid waiting. \nFor example: EX A M PL E 6.4. Consider the example from Section 6.1, and a case in which thread t holds \na lock on M0 (assume t is allowed to use all operations of a single Map), and other threads hold locks \non K0 0 , K1 0 and K2 0. If t invokes isEmpty, it will have to wait until all the other threads unlock \nK0 0 , K1 0 and K2 0. This is not always needed, for example, if the Map manipulated by t has 4 elements, \nthen the other threads will never be able to make the Map empty (because, according to the Map semantics, \nthey can only affect 3 keys, so they cannot remove more than 3 elements). Hence, the execution of isEmpty \nby t is a dynamic-right-mover. A library designer can add code that observes the library s state and \nchecks that the operation is a dynamic-right-mover; in such a case, it executes the operation of the \nbase library (without waiting). For example, the following code lines can be added to the beginning of \nisEmpty(int mapId): bool c1 = M0 or M1 are held by the current thread ; bool c2 = baseLibrary.size(mapId) \n> 3 ; if(c1 and c2) return baseLibrary.isEmpty(mapId); ... // the remaining code of isEmpty This code \nveri.es that the actual Map cannot become empty by the preceding threads; in such a case we know that \nthe operation is a dynamic-right-mover. Note that writing code that dynamically ver\u00adi.es right-moverness \nmay be challenging, because it may observe inconsistent state of the library (i.e., the library may be \nconcurrently changed by the other threads).  6.3 Optimistic Locking In the approach, the threads are \nrequired to lock the root of the locking-tree. This may create contention (because of several threads \ntrying to lock the root at the same time) and potentially degrade performance [18]. To avoid contention, \nwe use the following technique. For each lock we add a counter the counter is incremented whenever the \nlock is acquired. When a mayUse operation m is invoked (by a thread that has not invoked a mayUse operation) \nit performs the following steps: (1) go over all nodes from the root to P (m) and read the counter values; \n(2) lock P (m); (3) go over all nodes from the root to P (m) (again), if one node is locked or its counter \nhas been modi.ed then unlock P (m) and restart (i.e., go to step 1). The idea is to simulate hand-over-hand \nlocking by avoid writing to shared memory. This is done by only locking the node P (m) (and only read \nthe state of the other nodes). When we do not restart in step 3, we know that the execution is equivalent \nto one in which the thread performs hand-over-hand locking from the root to P (m). 7. Experimental Evaluation \nIn this section we present an experimental evaluation of our ap\u00adproach. The goals of the evaluation are: \n(i) to measure the preci\u00adsion and applicability of our simple static analysis algorithm (ii) to compare \nthe performance of our approach to a synchronization im\u00adplemented by experts, and (iii) to determine \nif our approach can be used to perform synchronization in realistic software with reason\u00adable performance. \nTowards these goals, we implemented a general purpose Java library for Map data structures using the \ntechnique presented in Section 6 (we used the extensions from Sections 6.2 and 6.3). Implementation details \ncan be found in [14]. In all cases, in which our library is used, the calls to the mayUse operations \nhave been automatically inferred by our static algorithm. Evaluation Methodology For all performance \nbenchmarks (ex\u00adcept the GossipRouter), we followed the evaluation methodology of [17]. We used a Sun \nSPARC enterprise T5140 server machine running Solaris 10 this is a 2-chip Niagara system in which each \nchip has 8 cores (the machine s hyperthreading was disabled). More details about the evaluation methodology \ncan be found in [14]. 7.1 Applicability and Precision Of The Static Analysis We applied our static analysis \nto 58 Java code sections (compos\u00adite operations) from [27] that manipulate Maps (taken from open\u00adsource \nprojects). We have found that for all composite operations, Figure 9. Throughput of ComputeIfAbsent. \n our simple algorithm infers calls to mayUse operations which can\u00adnot be further improved manually. For \n18 composite operations, our implementation reported (warnings) about procedure invoca\u00adtions that did \nnot belong to the library we manually veri.ed that these invocations are pure5 (so they can be seen \nas thread-local op\u00aderations). These results are summarized in [14]. 7.2 Comparison To Hand-Crafted Implementations \nWe selected several composite operations over a single Map: the computeIfAbsent pattern [1], and a few \nother common composite Map operations (that are supported by [2]). For these composite operations, we \ncompare the performance of our approach to a synchronization implemented by experts in the .eld. The \nresults of the computeIfAbsent pattern are reported here, and the rest of the results are reported in \n[14]. ComputeIfAbsent The ComputeIfAbsent pattern appears in many Java applications. Many bugs in Java \nprograms are caused by non\u00adatomic realizations of this simple pattern (see [27]). It can be described \nwith the following pseudo-code: if(!map.containsKey(key)) { value = ... // pure computation map.put(key, \nvalue); } The idea is to compute a value and store it in a Map, if and only if, the given key is not \nalready present in the Map. We chose this benchmark because there exists a new version of Java Map, called \nConcurrentHashMapV8, with a procedure that gets the computa\u00adtion as a parameter (i.e., a function is \npassed as a parameter), and atomically executes the pattern s code [1]. We compare four implementations \nof this pattern: (i) an imple\u00admentation which is based on a global lock; (ii) an implementation which \nis based on our approach; (iii) an implementation which is based on ConcurrentHashMapV8; (iv) an implementation \nwhich is based on hand-crafted .ne-grained locking (we used lock stripping, similar to [16], with 32 \nlocks; this is an attempt to estimate the bene.ts of manual hand-crafted synchronization w/o changing \nthe underlying library). The computation was emulated by allocating a relatively-large Java object (~ \n128 bytes). The results are shown in Fig. 9. We are encouraged by the fact that our approach provides \nbetter performance than Concurren\u00adtHashMapV8 for at least 8 threads. Also, it is (at most) 25% slower \nthan the hand-crafted .ne-grained locking. 7.3 Evaluating The Approach On Realistic Software We applied \nour approach to three benchmarks with multiple Maps in these benchmarks, several Maps are simultaneously \nmanip\u00adulated by the composite operations. We used the Graph bench\u00admark [16], Tomcat s Cache [3], and \na multi-threaded application 5 We have found that the purity of the invoked procedures is obvious, and \ncan be veri.ed by existing static algorithms such as [28].  ciated with the same key (such type of Maps \nis supported by our library; also [5] contains an example for such type of Maps). We compare a synchronization \nwhich is based on a global lock, and a synchronization which is based on our approach. We use the workloads \nfrom [16]. The results are shown in Fig. 10(a) (d). For some of the workloads, we see that there is a \ndrop of performance between 8 and 16 threads. This can be explained by the fact that each chip of the \nmachine has 8 cores, so using 16 threads requires using both chips (this creates more overhead). Tomcat \ns Cache This benchmark is based on a Java implementation of Tomcat s cache [3]. This cache uses two types \nof Maps which are supported by our library: a standard Map, and a weak Map (see [4]). The cache consists \nof two composite operations Put and Get which manipulate the internal Maps. In this cache, the Get is \nnot a read\u00adonly operation (in some cases, it copies an element from one Map to another). The cache gets \na parameter (size) which is used by its algorithm. Fig. 10(e) and Fig. 10(f) show results for two workloads. \nGossipRouter The GossipRouter is a Java multi-threaded routing service from [6]. Its main state is a \nrouting table which consists of several Map data structures. (The exact number of Maps is dynamically \ndetermined). We use a version of the router (\"3.1.0.Alpha3\") with several bugs that are caused by an \ninadequate synchronization in the code that access the routing table. We have manually identi.ed all \ncode sections that access the routing table as atomic sections; and ver\u00adi.ed (manually) that: whenever \nthese code sections are executed atomically, the known bugs are not occurred. We compare two ways to \nenforce atomicity of the code sec\u00adtions: a synchronization which is based on a global lock, and a synchronization \nwhich is based on our approach. We used a perfor\u00admance tester from [6] (called MPerf ) to simulate 16 \nclients where each client sends 5000 messages. In this experiment the number of threads cannot be controlled \nfrom the outside (because the threads are autonomously managed by the router). Therefore, instead of \nchanging the number of threads, we changed the number of active cores. The results are shown in Fig. \n11. For the router s code, our static analysis has reported (warn\u00adings) about invocations of procedures \nthat do not belong to the Maps library. Interestingly, these procedures perform I/O and do not violate \natomicity of the code sections. Speci.cally, they per\u00adform two types of I/O operations: logging operation \n(used to print debug messages), and operations that send network messages (to the router s clients). \nThey do not violate the atomicity of the atomic sections, because they are not used to communicate between \nthe threads (from the perspective of our formal model, they can be seen as thread-local operations). \n8. Related Work 8.1 Concurrent Data Structures Many sophisticated concurrent data structures (e.g., [2, \n18, 24]) were developed and integrated into modern software libraries. These data structures ensure atomicity \nof their basic operations, while hiding the complexity of synchronization inside their li\u00adbraries. Unfortunately \nas shown in [27] employing concurrent data structures in client code is error prone. The problem stems \nfrom the inability of concurrent data structures to ensure atomicity of client operations composed from \nseveral data structure operations. In this paper we focus on enabling ef.cient atomicity of client operations \ncomposed from several data structure operations. The foresight information enables the library to provide \nconcurrency without violating atomicity of composite client operations. This prevents the errors reported \nin [27] without the need for the library to directly support composite operations as suggested in [1]. \n 8.2 Synchronization by Utilizing Semantics Properties Many synchronization approaches aim to utilize \nsemantics proper\u00adties of concurrent operations for the sake of concurrency and ef.\u00adciency. (e.g., by \nutilizing commutativity of read-only operations.) These approaches are developed for databases (e.g.,[26, \n29]) and for general programming models (e.g.,[21, 22]). Rollbacks A notable property of most approaches \n(e.g., all the ap\u00adproaches discussed in [21, 22, 26, 29]) is that they require a roll\u00adback mechanism \n(otherwise atomicity and deadlock-freedom are not guaranteed). In contrast, in this paper we show an \napproach that ensures atomicity and deadlock-freedom without using a rollback mechanism. This may be \nan advantage in some cases (e.g., when a rollback mechanism has a high runtime and memory overhead [10], \nor when I/O operations are involved). Using foresight may also be bene.cial for approaches with a rollback \nmechanism. Though, in this work we focus on synchro\u00adnization that does not require rollback mechanisms. \nCommutativity and Movers We base our approach on right-movers whereas most approaches are based on commutativity. \nIndeed, [21] shows that many synchronization schemes can be based on either right-movers or left-movers. \nIn [21], they use a variant of a \"static\" right-mover which is a special case of our de.nition for dynamic\u00adright-mover. \nLocking Mechanisms Locking mechanisms are widely used for synchronization, some of them utilize semantics \nproperties of shared operations (e.g., [12, 20]). Usually these mechanisms do not allow several threads \nto hold locks which correspond to non\u00adcommutative operations. An interesting locking mechanism is shared-ordered \nlocking [7] which allow several threads to hold locks which correspond to non-commutative operations. \nSuch lock\u00ading mechanisms can be seen as special cases of libraries with foresight-based synchronization. \n 8.3 Synchronization via Locking Locking is a widely used approach for software synchronization. Writing \nsoftware with locking that permits concurrency, such as .ne-grain locking, is considered hard and error \nprone. In order to mitigate this problem several algorithms for automat\u00adically inferring locks using \nstatic analysis were recently suggested (e.g. [11, 13]). Our algorithm for inferring mayUse operations \nis similar to these algorithms; still with the following differences: (i) we deal mayUse operations which \ncan be seen as generalizations of lock-acquire and lock-release operations this enables our ap\u00adproach \nto utilize non-trivial semantic properties of shared opera\u00adtions; (ii) lock inference algorithms usually \nneed to consider the structure of a dynamically manipulated state, we avoid this by con\u00adsidering a single \nshared library that can be statistically identi.ed. Acknowledgments We thank Yehuda Afek, Adam Morrison, \nNoam Rinetzky, Omer Tripp and the anonymous referees for their insightful feedbacks. This work was partially \nsupported by Microsoft Research through its PhD Scholarship Programme, and by The Israeli Science Foun\u00addation \n(grant no. 965/10). References [1] gee.cs.oswego.edu/dl/jsr166/dist/jsr166edocs/ jsr166e/ConcurrentHashMapV8.html. \n [2] docs.oracle.com/javase/6/docs/api/java/ util/concurrent/ConcurrentHashMap.html. [3] www.devdaily.com/java/jwarehouse/apache-tomcat\u00ad6.0.16/java/org/apache/el/util/ConcurrentCache.java.shtml. \n [4] docs.oracle.com/javase/6/docs/api/java/util/WeakHashMap.html. [5] guava-libraries. code.google.com/p/guava-libraries/. \n[6] Jgroups toolkit. www.jgroups.org/index.html. [7] AG R AWA L , D., A N D EL AB BA D I , A . Constrained \nshared locks for increasing concurrency in databases. In Selected papers of the ACM SIGMOD symposium \non Principles of database systems (1995). [8] BE R N S T E I N , P. A . , HA D Z I L AC O S , V., A N \nD GO O D M A N , N. Concur\u00adrency Control and Recovery in Database Systems. Addison-Wesley, 1987. [9] \nBRO N S O N , N. Composable Operations on High-Performance Con\u00adcurrent Collections. PhD thesis, Stanford \nUniversity, Dec. 2011. [10] CA S C AVA L , C., B L U N D E L L , C., MI C H A E L , M . , C A I N , \nH. W., WU, P., CH I R A S , S., A N D CH AT T E R J E E , S . Software transactional mem\u00adory: Why is \nit only a research toy? Queue 6, 5 (Sept. 2008), 46 58. [11] CH E R E M , S., CH I L I M B I , T., A \nN D GU LWA N I , S . Inferring locks for atomic sections. In PLDI (2008). [12] CO U RTO I S , P. J ., \nH E Y M A N S , F., A N D PA R NA S , D . L. Concurrent control with readers and writers. Commun. ACM \n14, 10 (Oct. 1971). [13] GO L A N -G U E TA , G . , BRO N S O N , N. , A I K E N , A . , RA M A L I N \nG A M , G., SAG I V, M . , A N D YA H AV, E. Automatic .ne-grain locking using shape properties. In OOPSLA \n(2011). [14] GO L A N -G U E TA , G . , RA M A L I N G A M , G., SAG I V, M . , A N D YA H AV, E. Concurrent \nlibraries with foresight. Tech. Rep. TR-2012-89, Tel Aviv University, 2012. [15] HA R R I S , T., L \nA RU S , J . , A N D RA J WA R , R . Transactional memory, 2nd edition. Synthesis Lectures on Computer \nArchitecture 5, 1 (2010). [16] HAW K I N S , P., A I K E N , A., FI S H E R , K., RI NA R D , M., A N \nD SAG I V, M . Concurrent data representation synthesis. In PLDI (2012). [17] HE R L I H Y, M . , LE \nV, Y., LU C H A N G C O , V., A N D SH AV I T, N . A provably correct scalable concurrent skip list. \nIn OPODIS (2006). [18] HE R L I H Y, M., A N D SH AV I T, N . The Art of Multiprocessor Program\u00adming. \nMorgan Kauffman, Feb. 2008. [19] HE R L I H Y, M. P., A N D WI N G , J . M . Linearizability: a correctness \ncondition for concurrent objects. ACM Trans. Program. Lang. Syst. 12 (July 1990). [20] KO RT H , H . \nF. Locking primitives in a database system. J. ACM 30 (January 1983), 55 79. [21] KO S K I N E N , E \n. , PA R K I N S O N , M ., A N D HE R L I H Y, M. Coarse-grained transactions. In POPL (2010), pp. 19 \n30. [22] KU L K A R N I , M., PI N G A L I , K., WA LT E R , B., RA M A NA R AYA NA N , G., BA L A , \nK., A N D CH E W, L . P. Optimistic parallelism requires abstractions. In PLDI (2007). [23] LI P T O \nN , R. J. Reduction: a method of proving properties of parallel programs. Commun. ACM 18, 12 (Dec. 1975), \n717 721. [24] MI C H A E L , M. M., A N D SC OT T, M. L. Simple, fast, and practical non-blocking and \nblocking concurrent queue algorithms. In PODC (1996), pp. 267 275. [25] PA PA D I M I T R I O U , C . \nH. The serializability of concurrent database updates. J. ACM 26, 4 (1979), 631 653. [26] SC H WA R Z \n, P. M . , A N D SP E C T O R , A. Z . Synchronizing shared abstract types. ACM Trans. Comput. Syst. \n2, 3 (Aug. 1984), 223 250. [27] SH AC H A M , O . , B RO N S O N , N., A I K E N , A., SAG I V, M . , \nVE C H E V, M ., A N D YA H AV, E. Testing atomicity of composed concurrent operations. In OOPSLA (2011). \n[28] S .A L C I A N U , A., A N D RI NA R D , M. Purity and side effect analysis for Java programs. In \nVMCAI (2005), pp. 199 215. [29] WE I H L , W. E. Commutativity-based concurrency control for abstract \ndata types. IEEE Trans. Comput. 37 (December 1988), 1488 1505.     \n\t\t\t", "proc_id": "2491956", "abstract": "<p>Linearizable libraries provide operations that appear to execute atomically. Clients, however, may need to execute a sequence of operations (a composite operation) atomically. We consider the problem of extending a linearizable library to support arbitrary atomic composite operations by clients. We introduce a novel approach in which the concurrent library ensures atomicity of composite operations by exploiting information (foresight) provided by its clients. We use a correctness condition, based on a notion of dynamic right-movers, that guarantees that composite operations execute atomically without deadlocks, and without using rollbacks.</p> <p>We present a static analysis to infer the foresight information required by our approach, allowing a compiler to automatically insert the foresight information into the client. This relieves the client programmer of this burden and simplifies writing client code.</p> <p>We present a generic technique for extending the library implementation to realize foresight-based synchronization. This technique is used to implement a general-purpose Java library for Map data structures -- the library permits composite operations to simultaneously work with multiple instances of Map data structures.</p> <p>We use the Maps library and the static analysis to enforce atomicity of a wide selection of real-life Java composite operations. Our experiments indicate that our approach enables realizing efficient and scalable synchronization for real-life composite operations.</p>", "authors": [{"name": "Guy Golan-Gueta", "author_profile_id": "81490696196", "affiliation": "Tel Aviv University, Tel Aviv, Israel", "person_id": "P4149015", "email_address": "ggolan@tau.ac.il", "orcid_id": ""}, {"name": "G. Ramalingam", "author_profile_id": "81479640532", "affiliation": "Microsoft Research, Bangalore, India", "person_id": "P4149016", "email_address": "grama@microsoft.com", "orcid_id": ""}, {"name": "Mooly Sagiv", "author_profile_id": "81100150928", "affiliation": "Tel Aviv University, Tel Aviv, Israel", "person_id": "P4149017", "email_address": "msagiv@tau.ac.il", "orcid_id": ""}, {"name": "Eran Yahav", "author_profile_id": "81100285431", "affiliation": "Technion, Haifa, Israel", "person_id": "P4149018", "email_address": "yahave@cs.technion.ac.il", "orcid_id": ""}], "doi_number": "10.1145/2491956.2462172", "year": "2013", "article_id": "2462172", "conference": "PLDI", "title": "Concurrent libraries with foresight", "url": "http://dl.acm.org/citation.cfm?id=2462172"}