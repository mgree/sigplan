{"article_publication_date": "06-01-1994", "fulltext": "\n Type Analysis of Prolog Using Type Graphs* P. Van Hentenryck A. Cortesi B. Le Charlier Brown University \nUniversity of Venezia University of Namur Box 1910 Via Torino 155 21 rue Grandgagnage Providence RI 02912 \n(USA) 1-30170 Mestre-VE (Italy) B-5000 Namur (Belgium) pvh@cs brown. edu cortesi@moo. dsi .uni-ve. it \nbletlinfo .fundp. ac .be I&#38;trzzt Type analyis of Prolog is of primary importance for high-performance \ncompilers, since type information may lead to better indexing and to sophisticated specializa\u00adtions of \nunification and built-in predicates to name a few. However, these optimizations often require a so\u00adphisticated \ntype inference system capable of inferring disjunctive and recursive types and hence expensive in computation \ntime. The purpose of this paper is to describe a type anal\u00adysis system for Prolog based on abstract interpretation \nand type graphs (i.e. disjunctive rational trees) with this functionality. The system (about 15,000 lines \nof C) consists of the combination of a generic fixpoint al\u00adgorithm, a generic pattern domain, and a type \ngraph domain. The main contribution of thepaperis to show that this approach can be engineered to be \npractical for medium-sized programs without sacrificing accuracy. The main technical contributions to \nachieve this result are (1) a novel widening operator for type graphs which appears to be accurate and \neffective in keeping the sizes of the graphs, and hence the computation time, reason\u00adably small; (2) \nthe use of the generic pattern domain to obtain a compact representation of equality constraints between \nsubterms and to factor out sure structural in\u00ad formation. Introduction Although Prolog is an untyped \nlanguage, type analy\u00adsis of the language is important since it enables to im\u00adprove indexing, to specialize \nunification, and to produce more efficient code for built-in predicates to name a few. However, to provide \ncompilers with sufficiently precise *This research was partly supported by the Office of Naval Re\u00adsearch \nunder grant NOO014-91-J-4052 ARPA order 8225 and the National Science Foundation under grant numbers \nCCR-9357704 and a National Young Investigator Award. Permission to co without fee all or part of this \nmatedal is grxdcdpmvidecl% t at the copies are not made or distributed for direct commercial advantage, \nthe ACM copyright notice and the title of the publication and its date appear, and notice is given that \ncopyin is by permission of the Association of Computing Machinety. + o copy otherwise, or to republish, \nrequires a fee andlor specific permission. information, type analyses must be rather sophisticated and \ncontain disjunctive and recursive types. Consider for instance the simple program to insert an element \nin a binary tree: insert (E, void, tree (void, E,void) ) . insert (E, tree(L, V, R), tree(Ln, V, R)) \n:-E < V, insert (E, L,Ln) . insert (E, tree(L, V, R), tree(L, V,Rn)) :-E > V, insert (E, R,Rn) . If compilers \nare given the information that the first ar\u00adgument is not a variable and that the type T of the second \nargument is described the grammar T ::= void I tree(T, Any, T) then at most two tests are necessary to \nselect the appro\u00adpriate clause to execute. Note that a recurgive type is needed because of the recursive \ncall. Information about the functor of the second armment would onlv enable to specialize the first canto \ninsert. Extensive research has been devoted to type infer\u00adence in logic programming, although few systems \nhave actually been developed. A popular line of research, called the Cartesian closw-eapproach in [?], \nwas initiated by [?] and further developed in many authors (See [?] foracomplete account). Thekeyidea \nis to approximate the traditional TP operator by replacing substitutions by sets of substitutions and \nusing a cartesian closure operator toignore inter-variable and inter-argument de\u00adpendencies. This approach \noriginated in type checking applications but can be used for type analysis as well. Thetype inference \nproblem in this approach was shown to be decidable by Heintze and Jaffar [?] using a re\u00adduction to set \nconstraints. By reducing the problem to the inference of (a subclass of) monadic logic programs, Fruehwirth \net aL ~?l gave an exponential lower bound for type checking ;n~ ;n exponential algorithm for type inference. \nTheappealing feature of this approach is that the problem is amenable to precise characterization and \nhence itsproperties can restudied more easily. Itslimi\u00adtation for type analyis is that the relationships \nbetween predicate arguments are ignored which may entail a loss of precision and makes it difficult to \nintegrate the sys\u00adtem with other analyses such as modes and sharing. A SIGPLAN 84-6/94 Orlando, Florida \nUSA Q 1984 ACM 0-89791 -662-x18410006..~.5O 337 type inference system based on this approach was de\u00adveloped \nby Heintze [?] and the experiments results (on programs up to 32 clauses) indicate that there is hope \nto make this approach practical. Another line of research is the approach of Bruynooghe and Janssens \n(e.g. [?, ?]) which is based on a traditional abstract interpretation approach [?]. The key idea is to \napproximate a co~ecting semantics of the language by an abstract semantics where sets of substitutions \nare described by type graphs, i.e. disjunctive rational trees. A fixpoint algorithm is then used to compute \nthe least fixpoint or a postfixpoint of the abstract semantics. The problem of inferring the set of principal \nfunctors for an argument in a program is undecidable and the result of the analvsis is thus an auDroximation \nas is traditional in . .. abstract interpretation. The appealing features of this approach is the possibility \nof exploiting variable depen\u00addencies and the ease with which type analysis can be combined with other \nanalyses as required by applica\u00ad tions such as compile-time garbage collection [?]. The drawback is that \nthe result of the analysis is more dif\u00adficult to characterize formally as the design of the ab\u00adstract \ndomain is an experimental endeavour. This ap\u00adproach has been implemented in a prototype system [?] but \nexperimental results have only been reported on very small programs and were not very encouraging. Hence \nthe practicability of this approach remains open. Note also that the two approaches, which use fundamen\u00adtally \ndifferent algorithms, are not directly comparable in accuracv. since the accuracv of the abstract interDre\u00ad \n., . tation approach depends upon the choices made in the abstract domain. The purpose of this paper \nis to describe the de\u00adsign and implementation of a type system based on the second approach. The system \nis best described as GAIA (Pat (Type)), where GAIA is a generic top-down fix\u00adpoint algorithm for Prolog \n[?, ?]l, pat is a generic pat\u00adtern domain for structural information [?], and Type is a type graph domain. \nThe main contribution of the sys\u00adtem (about 15,000 lines of C) is to show that type analy\u00adsis based on \nabstract interpretation and type graphs can be engineered to be practical, at least for medium-sized \nprograms (up to 45o lines of Prolog). It also shows that type graphs can be practical and this is of \nimportance for many applications such as compile-time garbage col\u00adlection (e.g. [?] ) and automatic termination \nanalysis (e.g. [?]). The technical contributions to obtain this result are (1) a novel widening operator \nfor type graphs which appears to be accurate and effective in keeping the sizes of the graphs, and hence \nthe computation time, reasonably small; (2) the use of the pattern domain to obtain a compact representation \nof equality constraints between subterms and to factoring sure structural in\u00adformation. This should be \ncontrasted with Bruynooghe and Janssens s approach which restricts attention to a finite domain to guarantee \nthe finiteness of the analysis and represents all information in the type graph domain. Note also that \nthe use of widening operators for type in\u00adference has been recently investigated in the context of 1 \nGAIA is available by anonymous ftp from Brown University. functional programming but the technical details \nof this work are fundamentally different [?]. The rest of this paper is organized as follows. Section \n2 illustrates the functionality of the system on a variety of small but representative examples. Section \n3 gives an overview of the paper. Sections 4 and 5 briefly review our abstract interpret ation framework \nand the generic pattern domain. Section 6 describes our design of the type graph domain. Section 7 reports \nthe experimen\u00adtal results. Section 8 concludes the paper. Appendices A and B show the relations between \ntype graphs and context-free grammars. Appendix C cent ains the for\u00admalization of the widening operation \nand the proofs of the main results. 2 An 171ustration of the Type System The purpose of this section \nis to illustrate the behaviour of the type analysis system on a number of examples. It should give the \nreader an intuitive idea of the accuracy and efficiency of the type analysis system. The examples are \nsmall for clarity but they represent abstractions of existing procedures and illustrate many aspects \nof Pro\u00adlog programming. Results on medium-sized programs are given in Section 7. Our type analysis system \nreceives as input a Prolog program and an input pattern, i.e. a predicate sym\u00adbol and some type information \non each of the argu\u00adments. The input pattern gives information on how the program is used, i.e. it specifies \nthe top-level goal and the type properties satisfied by the arguments. In this section, for simplicity, \nall input patterns are of the form p (Any . . . . . Any), where Any represents the set of all terms. \nThe output of the system is an output pat\u00adtern, i.e. a predicate symbol and some type information on \neach of the arguments. The output pattern repre\u00adsents type information of the arguments on success of \nthe predicate. The system also returns a set of tuples (~t~, P, Pw) which represent the input and output \npat\u00ad terns for a predicate symbol p needed to compute the result. Note that the system performs a polyvariant \nanalysis, i.e. there may be multiple tuples associated with the same predicate symbol. In the following, \nwe mainly show the top-level result for simplicity. The re\u00adsults are present ed as context free grammars, \nsince there is a close analogy between grammars and type graphs (see Appendix A). Consider first the \ntraditional naive reverse program nreverse ([1 ,[1) . nreverse ( [F IT] ,Res) :\u00adnreverse (T, Trev) , \nappend (Trev, [F], Res). append( [1 ,X,X) . append ([ FIT], S, [FIR]) :-append (T, S, R). For an input \npattern nreverse (Any, Any), the system produces the output pattern nreverse (T, T) where T is defined \nas follows: T : := [1 I cons(Any, T). 338 In other words, both arguments should be lists after exe\u00adcutionofnreverse. \nThe analysis also concludes tha,t the first argument toappend isalways a list. Note that the system has \nno predefine notion of list: [] and cons/2 are uninterpreted functors. The analysis time for this example \nis about 0.01 seconds. Consider now the fol\u00adlowing program which is an abstraction of a procedure used \nin the parser of Prolog. process (X, Y) :-process(X,O,Y). process([],X,X). process([c(Xl) lY],Acc,X) \n:\u00adprocess(Y,c(Xl ,Acc),X). process([d(Xi) lY],Acc,X) :\u00adprocess(Y,d(Xl,Acc) ,X). The program is int cresting \nbecause it cent ains a sophis\u00adticated form of accumulator, a traditional Prolog pro\u00adgramming technique. \nFor the input process(Any,Any), the analysis returns the output pattern process (T, S) such that T ::= \n[1 I cons(Tl,T). T] ::= c(Any) I d(any). s ::= O I c(Any,S) I d(Any,S). The first argument is inferred \nto be a list with two types of elements while the second argument captures per\u00adfectly the structure of \nthe accumulator. The analysis time is about 0.34 seconds. Consider now a slight varia\u00adtionof the program \ntointroduce twomutua.lly recursive procedures: process(X,Y) :-process(X,O,Y). process([l ,X,X) . process([c(Xl) \nlY],Acc,X) :\u00adother-process(Y,c(Xl ,Acc),X). other.process( [d(Xl)lY],Acc,X) :\u00adprocess(Y,d(Xl ,Acc) ,X). \nFor the input pattern process(Any,Any), the analysis returns the output pattern process (T, S) such that \nT ::= [1 I cone.(c(Any),cons(d(Any),T)). s ::= O I d(Any,c(Any,S)). Once again the types of the accumulator \nand of the list are inferred perfectly and the analysis time is about 0.08 seconds. Consider now the \nfollowing program: llist([l). llist([FIT]) :-lLvt(F), ll&#38;t(T). list([l). list([FIT]) :-p(F), list(T). \n p(a). p(b). reverse(X,Y) :-reverse(X,[l,Y). reverse([l ,X,X). reverse([FIT] ,Acc,Res) :-reverse(T, \n[FIAcc],Res) . which contains imbricated lists and an accumulator. Given the input pattern get(Any), \ntheanrdysis system returns the output pattern get(T) where T ::= [1 I cons(Tl,T). T] ::= [1 I cons(Tz,Tl). \nT2 ::= alb. The analysis time is about 0.09 seconds. The example illustrates well how the imbricated \nlist structure is in\u00adferred by the system and preserved when used inside the accumulator of reverse. \nConsider the following pro\u00adgram which collects information in arithmetic expres\u00adsions. add(O, []). add(X \n+ Y,Res) :\u00adadd(X,Resl), mult(Y,Res2) , aPPend(Resl ,Res2,ReS). mult(l, [l)o mult(X * Y,Res) :-mult(X,Resl) \n, basic(Y,Res2), aPPend(Resl ,Res2,Res). basic(var(X), [X] ). basic(cst(C), []) . basic(par(X),Res) :-add(X,Res). \n For the input pattern add(Any,Any), the analysis pro\u00adduces the output pattern add(T, S) where T ::=T+TI \nIO. T1 ::=TI*T2 I 1. Tz ::= cst(Any) I par(T) I var(Any). s ::= [1 I cons(Any,S). The interesting point \nin this example is that the rule for Tz contains an occurrence of T showing that our analysis can generate \ngrammars with mutually recursive rules. The analysis timeis about 0.11 seconds. Consider now the even \nmore sophisticated program on arithmetic ex\u00adpressions: add(X,Res) :-mult(X,Res). add(X + Y,Res) :\u00adadd(X,Rl), \nmult(Y,R2), append(Rl,R2 ,Res). mult(X,Res) :-basic(X,Res). mult(X * Y,Res) :-mult(X,Rl), basic(Y,R2), \nappend(Rl,R2 ,Res). basic(var(X), [Xl). basic(cst(X), [] ). basic(par(X),Res) :-add(X,Res). For the \ninput pattern add(Any,Any), the analysis pro-gat(Res) :-llist(X), reverse(X,Res). duces the optimal output \npattern add (T,S) where 339 T ::=T1 I 1 +TI. TI ::=T2 I TI*T2. T2 : := cst(Any) [ var(Any) I par(T) \n. s ::= [1 I cons(Any, S). The analysis time is about 0.56 seconds. The difficulty in this example is \nto avoid mixing the definition of T, T1 and TZ. Finally, we would like to mention the analysis of the \ntokenizer of Prolog which produces the result T : := [1 \\ cons(Tl, T). TI ::= ( ] ) I , 1 [ I 1 I { \n\\ I [ } I atom(Any) I string(T2) I integer (Any) I var(Any ,Any) T2 : := [1 I cons(Any, Tz) . The analysis \ntime is about 0.42 seconds and the inter\u00ad esting point was the ability of the widening to preserve the \nstring type. 3 Overview of the Type Analysw System Our type analysis system can be described as the com\u00ad \nbination GAIA (Pat (Type)) where 1. GAIA ( R) is a generic fixpoint algorithm for Pro\u00adlog which, given \nan abstract domain ~, computes the least fixpoint (finite domains) or a postfixpoint (infinite domains) \nof an abstract semantics based on 7?-; 2. Pat (7?) is a generic pattern domain which en\u00adhances any domain \n%?.with structural information and equalhy constraints between subterms; 3. Type is the type graph domain \nto represent type information.  The next three sections are devoted to each of the sub\u00adsystems with \na special emphasis on Type since the other two systems have been presented elsewhere. 4 The Abstract \nInterpretation Framework In this section, we briefly review our abstract interpre\u00adtation framework. The \nframework is presented in de\u00adtails in [?] and is close to the work of Marriott and Sondergaard [?] and \nWinsborough [?]. It follows the traditional approach to abstract interpretation [?]. Concrete Semantzcs \nAs is traditional in abstract inter\u00adpretation, the starting point of the analysis is a collect\u00ading semantics \nfor the programming language. Our con\u00adcrete semantics is a collecting fixpoint semantics which captures \nthe top-down execution of logic programs using a left-to-right computation rule and ignores the clause \nselection rule. The semantics manipulates sets of sub\u00adstitutions which are of the form {Z I _ tl,....zn \n+ &#38;} for some n z O. Two main operations are performed on substitutions: unification and pro j ection. \nThe seman\u00adtics associates to each of the predicate symbol p in the program a set of tuples of the form \n(~t~, p, ~~~t ) which can be interpreted as follows: the execution of P(z1, . . . . z~)~ with .9 G ~,~ \nproduces a sequence 01, . . . . On, . . . of sub\u00adstitutions, all of which belongs to @oUt. Abstract Semantzcs \nThe second step of the methodol\u00adogy 1S the abstraction of the concrete semantics. Our abstract semantics \nconsists in abstracting a set of sub\u00adstit utions by a single abstract substitutions, i.e. an ab\u00adstract \nsubstitution represents a set of substitutions. As a consequence, the abstract semantics associates with \neach predicate symbol p a set of tuples of the form (~,~, P, p~tit) which can be read informally as follows: \nthe execution of P(Z1, . . ., z~)o with 6 satis\u00adfying the property described by p,~ produces a sequence \n01, . . . . On, . . . of substitutions, all of which satisfying the property described by ,i30ut. The \nabstract semantics assumes a number of operations on abstract substitutions, in particular unification, \npro\u00adjection, and upper bound. The first two operations are simply consistent approximations of the corresponding \nconcrete operations. The upper bound operation is a consistent abstraction of the union of sets of substitu\u00ad \ntions. The I%zpoint Algorithm The last step of the method\u00adology consists in computing the least fixpoint \nor a post\u00adfixpoint of the abstract semantics. The fixpoint algo\u00adrithm GAIA [?] is a top-down fixpoint \nalgorithm com\u00ad puting a small, but sufficient, subset of least fixpoint (or of a postfixpoint) necessary \nto answer a user query. The algorithm uses memorization, a dependency graph to avoid redundant computation, \nthe abstract opera\u00ad tions of the abstract semantics, and the ordering rela\u00ad tion on the abstract domain. \nIt has many similarities with P LA I [?] and can be seen either as an implemen\u00ad tation of Bruynooghe \ns framework [?] or as an instance of a general fixpoint algorithm [?]. In the experimental results, we \nuse the prefix version of the algorithm [?]. 5 The Generic Pattern Domain In this section, we briefly \nrecall the basic notions be\u00adhind the generic abstract domain Pat ( 72.). The main significance of Pat \n( %Z) for type analysis is the reduc\u00adtion in the size of the type graphs by factoring out sure structural \ninformation and, more importantly, by pro\u00adviding a compact representation of equalities between subterms. \nThis allows the domain Type to be kept as simple as possible and should be contrasted with the approach \nof [?] where both information are handled in the same domain. The key intuition behind Pat ( R) is to \nrepresent in\u00adformation on some subterms occurring in a substitu\u00ad tion instead of information on terms \nbound to variables only. More precisely, Pat (Z) may associate the follow\u00ading information with each considered \nsubterm: (I) its pattern which specifies the main functor of the subterm (if any) and the subterms which \nare its arguments; ( 2) 340 its properties which are left unspecified and are given in the domain X?. \nA subterm is said to be a leaf iff its pattern is unspecified. In addition to the above infor\u00admation, \neach variable in the domain of the substitutions is associated with one of the subterms. Note that the \ndomain can express that two arguments have the same value (and hence that two variables are bound together) \nby associating both arguments with the same subterm. This feature produces additional accuracy by avoiding \ndecoupling terms that are equal but it also contributes in complicating the design and implementation \nof the domain. It should be emphasized that the pattern in\u00adformation is optional. In theory, information \non all sub\u00adterms could be kept but the requirement for a finite analysis makes this impossible for almost \nall applica\u00adtions. As a consequence, the domain shares some fea\u00adtures with the depth-k abstraction [?], \nalthough Pat (%?) does not impose a fixed depth but adjusts it dynamically through upper bound and widening \noperations. Pat (Z) is thus composed of three components: a pattern component, a same value component, \nand a 7?,\u00adcomponent. The first two components provide the skele\u00adton which contains structural and same-value \ninforma\u00adtion but leaves unspecified which information is main\u00adtained on the subterms. The Z-domain is \nthe generic part which specifies this information by describing prop\u00aderties of a set of tuples < tl,....tp> \nwhere t],....tp are terms. As a consequence, defining the %dornain amounts essentially to defining a \ntraditional domain on substitutions. In particular, it should cent ain opera\u00adtions for unification, projection, \nupper bound, and or\u00addering. The only difference is that the X-domain is an abstraction of a concrete \ndomain whose elements are sets of tuples (of terms) instead of sets of substi\u00adtutions. This difference \nis conceptual and does not fun\u00addamentally affect the nature or complexity of the %1\u00adoperations. The implementation \nof the abstract operations of Pat (1?) is expressed in terms of the %L-domain oper\u00adations. In general, \nthe implementations are guided by the structural information and call the Zdomain oper\u00adations for basic \ncases. Pat (7? ) can be designed in two different ways, depending upon the fact that we main\u00adtain information \non all terms or only on the leaves. For Pat (Type), we only maintain type information on the leaves. \nSince Pat (Z) and Type are both infinite do\u00admains, a widening operation is needed as well. This op\u00aderation \nis simply the upper-bound operation on Pat (7Z ) with the upper bound operation on the subdomain re\u00adplaced \nby a widening operation. The widening opera\u00adtion on Type is the critical design decision in Type and \nis discussed in Section 6.3. 6 The Type Graph Domain In this section, we present the design of the domain \nType. We start with type graphs and then define the domain, its operations, and the widening operator. \nCc(((V, E),r)) = lfp(~) (r). D: (V+ SST) + (V-+ SST) ~(@) = {(v, T) I vCV&#38;T=Denot(v, Q)}. Denot (v, \n0) = if type (v) = Any then ST else if type (v) = or then Ul<3<arity@)@(succ(v i)) else {f(t,,..., arity(v)) \nI f = f~ctor(v) &#38; t, C @(succ(v, i))} Figure 1: The Denotation of Type Graphs 6.1 Type Graphs Our \ntype graphs are essentially what Bruynooghe and Janssens call rigid types and readers are referred to \n[?] for a complete coverage of type graphs. Our presenta\u00adtion uses more algorithmic concepts to simplify \nthe rest of the presentation. Definition and Denotation A type graph g is a rooted graph ( G, r ), where \nG = (V, E) is a directed graph such that, for any vertex v in G, the successors of v are ordered and \nr is a distinguished vertex called the root of g and denoted by root (g). In the following, type graphs \nare denoted by the letter g and vertices by the letter v, both possibly subscripted or superscripted. \nA vertex v in a type graph g is associated with the following information: type(v): an element of {Any, \nfunctor, or}; functor(v): a string if type(v) = functor; arity(v): a natural number if type(v) # Any \nIf type(v) = or, arity(v) > 1. The successors of a vertex v are denoted by succ (v) and the ith succes\u00adsor \nof v by SUCC(V, i) for 1 < i ~ arity(v). More types (e.g. Integer, Real, Ground) can be added eas\u00adily \nwithout affecting the results described here. The denotation of a type graph g, denoted by Cc (g), is \ndepicted in Figure 1. In the figure, ST denotes the set of all terms, SST the powerset of ST, and lfp \nis the least fixpoint operator. @ is a function from vertices to sets of terms which is described by \nits table in the result of the transformation D. Note also that, in the following, we also talk about \nthe denotation of a vertex v in a graph g, i.e. lfp(~) (v), and we use CC9(V) to denote it. Finally, \nobserve that type graphs have a natural correspondence with context-free grammars and monadic logic programs. \nThis correspondence is given in Appendices A and B. Additional Definitions The following definitions \nwill be useful subsequently. We assume for simplicity an underlying type graph g. The depth of a vertex \nv, de\u00adnoted by depth(v), is the shortest path from root (g) 341 to v. An ancestor of a vertex v is any \nvertex v # v on the shortest path from root (v) to v. The set of ancestors of v is denoted by ancestor(v). \nIt is some\u00adtimes convenient to identify a vertex by a path, i.e. a sequence of integers. Given a type \ngraph g and a path p, the vertex is obtained by follow (root (g), p) where follow (v, [l) = v; follow \n(v, [ii,. ... inl) = follow(succ(v,il) ,[i2,. ..,inl) . The size ofa graph g, denoted bysize (g),is simply \nthe number of vertices and edges in the graph. The vertices (resp. the edges) of g are denoted by vertices \n(g) (resp. edges(g)). Wealsouse the function removeUncormected to remove the vertices which are not connected \nto the root. It is defined as removeUnconnected( (( V, E), r)) = (( V , E ), r) where V ={ v\\v EVkr Cencestor(v) \n} E, = { (~,v>) I (V,V ) ~ E %v,v C J } Pragmatic Restrictions Oursystem enforces a number of pragmatic \nrestrictions on type graphs for efficiency and convenience reasons: 1. thesuccessms of anor-vertex are \nfunctor-vertices; 2. if VI and V2 are successors of an or-vertex v, functor(vl) # functor(vz); 3. if \nv is a successor of a functor-vertex v, v is an or-vertex or depth(v ) > depth(v); 4. for anvvertex \nv. ancestor(v) fl medecessor(v) = {v~}and there isasingle edge (v,v ).  Restrictions 1,2, and4are adaptations \nofsimilarrestric\u00adtionsin [?]. The second restriction actually reduces the expressive power of type graphs \nand is called the prin\u00adcipal functor restriction in [?] (pf-restriction for short). Restriction 3 requires \ncycles to start at functor-vertices and to end at or-vertices while restriction 4 prevents subgraphs \nfrom sharing. When these restrictions are adopted, it makes sense to refer to the pf-set of an or\u00advertex \nas the set of all functors of its successors. The pf-set of an or-vertex v is denoted pf(v). The pf-set \nof a functor-vertex is simply the singleton set contain\u00ading its functor. We will also assume in the following \nthat the successors of or-vertices with the same pf-set are ordered in such a way that successors with \nthe same functor are at the same position. The Domain The abstract domain Type simply ab\u00adstracts asetofterm \ntuplesofthe form (tl, . . ..t~) by an abstract tuple (gl, . . . ,g~). Theconcretization function is simply \ngiven by Cc((gl, . . ..gn)) = {(to,..., tn) I t, C Cc(g,) (1 ~ i ~ n)}.  6.2 Operations on Type Graphs \nThe abstract operations of Type can beobtainedimme\u00addiately from three operations on type graphs: 1. gl \n~ g2: returns true iff Cc(gl) ~Cc(g2); 2. gl n gz: returns gs such that Cc(g3) ~ Cc(gl) n cc(g2); 3. \ngl u gz: returns gs such that Cc(gl) U Cc(g2) g cc(g3).  The first twooperations are describedin [?]. \nNote that intersection is used for unification since our type graphs are downward-closed. The third operation \nis not de\u00adscribed in [?] which uses an indirect approach: first, an or-vertex is created with the two \ninputs as successors; then a compaction algorithm is applied to satisfy the restrictions. Our system \nuses a direct implementation which does not raise any difficulty. It is only necessary to take care of \nthepf-restriction inthecases functor/or and or/or by applying the algorithm recursively. Of course, memoization \nis used to guarantee termination. Note also that, in the following, we often use operation s on vertices \nto denote inclusion of their denotation. The algorithm is the same as for type graphs. 6.3 The Widening \nOperator The main difficulty in the type graph domain comes from the fact that the domain is infinite \nand does not satisfy the ascending chain property. In fact, it is not even a cpo. To overcome this difficulty, \nBruynooghe and Janssens [?] use a finite subdomain by restricting the number of occurrences of a functional \nsymbol on the paths of the graphs. Readopted a different, less syntac\u00adtic, solution based on a widening \noperator as proposed in [?]. The design of widening operators is experimental in nature and it affects \nboth the performance and ac\u00adcuracy of the analysis. The examples given previously in the paper shows \nthat our widening operator leads to accurate results and is effective in keeping the graph sizes small. \nThe purpose of this section is to describe the widening operator informally. Appendix Ccontains the formal \nresults in detail. In abstract interpretation of Prolog, widening needs to be applied in two different \nsituations: (1) when the result of a procedure is updated; (2) when a procedure is about to be called. \nIn the first case, widening avoids the result of a procedure to be refined infinitely often while, in \nthe second case, widening avoids an infinite sequence of procedure calls. Hence, the widening op\u00aderator \nis always applied to an old graph gold (e.g. the previous result of a procedure) and a new graph gn.W \n(e.g. theunion of thenew clause results) to producea new graph gre, (e.g. the new result of the procedure). \nThe main idea behind our widening operator is to consider two graphs, go = gold and gn = gO[d U gneW, \nand to exploit the topology of the graphs to guess where g~ is growing compared to go. The key notion \nis the concept of topological clash which occurs in situations where T. ::= OIO+T1. T1 ::=1 [ T1 *T-J. \nT2 ::= cste(Any) [ par(0) I var(Any). T. ::=0 [ T3+Tlj. T3 ::= OIO+T4. T4 ::= 1[T4*T5. T5 ::= cste(Any) \nI par(0) I var(Any). T6 ::=1 I T6*T7. T7 ::= cste(Any) [ par(T3) [ var(Any). Figure 2: Widening for \nthe First Arithmetic Program afunctor-vertexin go corresponds to an or-vertex in gn;  an or-vertex \nv. in gO corresponds to an or-vertex v~ in g~ where pf(v~) # pf(v~);  c an or-vertex v. in go corresponds \nto an or-vertex V. in gm where depth(vo) < depth (vn). Inthese three cases, the widening operator tries \ntopre\u00advent the graph from growing by introducing a cycle in g~. Given a clash (vo,v~), the widening searches \nfor an ancestor VG to v~ such that pf(v~) G pf(va). If such an ancestor is found and if vo z v~, a cycle \ncan be introduced. Consider for instance append/3. The second itera\u00adtion has produced the following type \ngraph for the first argument To ::= [1 I cons(Any, [l). The union of the clause results for the third \niteration gives the following type graph for the first argument T new::= [1 I cons(Any, cons(Any, H)). \nTaking the union of To and TneW produces the type graph described by T. ::= [1 I cons(Any,T). T ::= [1 \nI cons(hy,[ l). There is a topological clash between To and T~ for the path [2,2] which corresponds \nto [1 and T respectively. The widening selects T. as an ancestor and introduces a cycle producing the \nfinal result T, ::= [1 I cons(Any,T,). Note also that an ancestor at any depth can be se\u00adlected. For \nthe first arithmetic program shown previ\u00adously, the widening applies tothethe type graphs T~and Tn depicted \nin Figure 2. Consider the clash occurring for the path [2,2,2,2,2,1 ]for T0 and Tn. An appropriate ancestor \nfor Ts is T~ which is not a direct ancestor. This results in the optimal result T, T, ::=OIO+T]. T] ::=1 \nI T1*T2. TZ ::= cste(Any) I par(T,) \\ var(Any) Whenno ancestor with asuitablepf-set canbefound, the widening \noperator simply allows the graph to grow. Termination will be guaranteed because this growth nec\u00adessarily \nadds along the branch a pf-set which is not a subset of any existing pf-set in the branch. This case \nof course happens frequently in early iterations of the fixpoint. Returning thearithmetic program, the \nsecond iteration for the predicate basic/2 requires a widening for the first argument with the following \ntwo graphs: T. ::= cste(Any) I var(Any). T. ::= cste(Any) I par(0) I var(Any). A topological clash of \ntype 2 is encountered but there is no suitable ancestor. The result will simply be T~ in this case. The \nlast case to consider appears when there is an ancestor v~ with a suitable pf-set but unfortunately v~ \n> Vn is false. In this case, introducing a cycle would produce a graph T, whose denotation may not include \nthe denotation of T. and hence our widening operator cannot perform cycle introduction. Instead the widen\u00ading \noperation replaces VG by a new or-vertex which is an upper bound to V. and V. but decreases the overall \nsize of the type graph. The widening operator is then applied again on the resulting graph, In summary, \nour widening operator is best viewed i as a sequence of transformations on T~, which are of two types: \n(1) cycle introduction; (2) vertex replacement, until no more topological clashes can be resolved. These \nnotions are formalized in Appendix C. 7 Experimental Evaluation We now describe the experimental result \nof our type system. We first describe the benchmarks and discuss the efficiency and accuracy of the analysis. \nI he Benchmarks The benchmark programs2 are hope\u00adfully representative of pure logic programs. KAis an \nalpha-beta program to play the game of kalah [?]. PR is a symbolic equation-solver [?]. CS is a program \nto generate a number of configurations representing vari\u00adous ways of cutting awoodboard into small shelves \n[?]. DS is the generate and test equivalent of a disjunctive scheduling problem [?]. RE is the Prolog \ntokeniser and reader of R. O keefe and D. H. D. Warren. PGis a program written by W. Older to solve a \nspecific mathematical problem. BR is a program taken from Gabriel bench\u00admark. PLis a planning program \nfrom [?]. QU solves the n-queens problem. Finally, PEis a the peephole opti\u00admizer of SB-Prolog, written \nby Debray. We will also prefix some programs by L to indicate that the input query assigns lists to some \narguments. Finally, we will also use the arithmetic programs discussed previously and denote them by \nAR and ARI. Table 1 gives some in\u00addication on the size of these programs while Table 2 re\u00adports the number \nof non-recursive, tail recursive, locally 2l he ben&#38;~arks are available by anonymous ftP frOm BrOWn \nUnivers]t y 343 recursive (more than one recursive call or a nontermi\u00adnal recursive call), and mutually \nrecursive procedures in each of the benchmarks. Four programs have only tail recursive procedures or \nnon-recursive procedures. Many programs have mutually recursive procedures and some have many of them. \nIn general, the majority of proce\u00addures are non-recursive and in many programs, most of the recursive \nprocedures are tail recursive. Program PR cent ains locally recursive procedures due to their divide \n&#38;conquer approach. Computation Times In this section, weanalyse thee f\u00adficiency of our type system \nexperimentally. Table 3 de\u00adscribes the CPU time (on a Sun Spare-l O), the number of procedure iterations \nand the number of clause itera\u00adtions. We also give the CPU time when the number of . successors to or-vertices \nis restricted to 5 and 2 respec\u00adtively. As can be seen, the analysis is very fast (below 3 seconds) for \nall programs except RE which takes about 153, 20, and 10 seconds depending on the various re\u00adstrictions. \nNote that PR is heavily mutually recursive, that CS manipulates heavily imbricated lists, and that PE \nhas large disjunctions, yet the running time of these programs is excellent. Program RE is time-consuming, \nsince it manipulates large graphs (the result of the to\u00adkeniser shown previously is only the first step), \nis heavily mutually recursive, and cent ains an accumulator-based procedure (very much like the process \npredicate shown previously) in the middle of the recursion. This proce\u00addure is actually where the time \ngoes since it is expensive in itself, is applied on the largest graphes occurring in the program, and \nis recomputed each time a new ap\u00adproximation for the main predicate is obtained. Pro\u00adgram RE is a worst \ncase scenario for our analyser, al\u00adthough the time remains acceptable. If more efficiency is desirable, \nthere are various ways of speeding up the computation, including the use of a monovariant anal\u00adysis (instead \nof the polyvariant analysis used here) or the imposition of restrictions on the size of the graphs or \nvertices as shown in the table. Overall, the results are very encouraging and seems to indicate that \ntype graphs can be engineered to be practical. The tradeoff between efficiency and accuracy remains obviously \nan important topic for further research. Accuracy To give an idea of the accuracy of the system, we measure \ntag information that can be extracted from the analysis under following assumptions. First, no mul\u00adtiple \nspecializations take place, i.e. a procedure is as\u00adsociat ed wit h a single version. Second, we consider \nthe following tag information: NI (empty list), CO (cons), LI (list), ST (structure), DI (atom), and \nHY (structure or atom). For each program, we extract the tag of each procedure argument. These tags will \nallow us to gener\u00adate more efficient code by avoiding tests and specializing indexing. Hence the analysis \nshould infer as many tags as possible. In addition, we compare the information so obtained with the information \nproduced by an analysis preserving only principal functors, i.e. the pattern do\u00admain of [?]. The type \nanalysis described here is always more precise than the pattern domain and the gain can come from disjunctive \nand recursive types. Note also that when the pattern domain infers a single functor for an argument, \nso does our type analysis. The results are described in Tables 4 and 5 for the output and in\u00adput tags \nrespectively. A column is associated with each tag and contains the number of arguments whose tag corresponds \nto the column. We also give in parenthesis the number of arguments inferred by a principfl functor analysis \nwhen this number is non-zero. Columns A, AI and AR represent the number of arguments, the num\u00adbers of \narguments for which the type analysis improves over the functor analysis (i.e. infer more tag informa\u00adtion) \nand the ratio between the last two figures. The last three figures collect the same information at the \nclause level wit h the understanding that a clause is im\u00adproved if any of its arguments is inferred more \nprecisely. The results indicate that type analysis significantly im\u00adproves a principal functor analysis. \nIn the average, the type analysis produces an improvement on about 50% of the output tags and about 2170 \nof the input tags. The tag information is improved in 67% of the clauses (output) and 38% of the clauses \n(input). Most of the improvement is divided into the tags LI, DI, ST, and HY with a majority of the tags \nbeing lists. The results also show that the combination of type and freeness analysis should produce \nsignificant improvement in code gener\u00adation, since the two analyses are complementary. 8 Conclusion In \nthis paper, we have described a sophisticated type analysis system for Prolog. The system is based on \nab\u00adstract interpretation and uses three main components: a fixpoint algorithm, a generic pattern domain, \nand the type graph domain of Bruynooghe and Janssens. The main contribution of our work is to show that \ntype anal\u00adysis of Prolog based on type graphs can be engineered to be practical without sacrificing efficiency. \nThis has implications beyond type analysis since type graphs are used for a variety of other analysis \nsuch as termination and compile-time garbage collection. The key technical contribution of this work \nis a novel widening operator which appears to be rather accurate and effective in keeping the sizes of \nthe graphs, and hence the compu\u00adtation time, reasonably small. There are many ways to extend this work. \nA natu\u00adral extension is to consider integrated type graphs which allow variable-vertices and should enable \ndifference-list programs to be handled precisely. Another extension consists of providing a database \nof types that the widen\u00ading can use whenever necessary. Finally, on the theo\u00ad retical level, it would \nbe interesting to characterize for which classes of programs our widening is optimal in accuracy. 9 \nAcknowledgments Stimulating discussions with David MacAllester are grate\u00adfully acknowledged. 344 KA \nQU PR PE Cs DS PG RE BR PL Number of Procedures 44 5 52 19 32 28 10 42 20 13 Number of Clauses 82 9 158 \n168 55 52 18 163 45 26 Number of Program Points 475 38 742 808 336 296 93 820 207 94 Number of Goals \n84 8 130 90 57 60 17 168 37 29 Static Call Tree Size 73 5 75 80 46 47 11 144 21 25 Table 1: Sizes of \nthe Programs KA QUPRPECsDSPGREBRPL Tailrecursive 12 4 12 6 9 14 6 6 11 4 Locallyrecursive o 0 5010 0 \n0 10 Mutuallyrecursive 7 0 8 4 2 0 0 16 0 0 Non-recumive 25 1 27 9 20 14 4 20 8 9 Table 2: Syntactic \nForm of the Programs KAQUPRPECsDSPG REBRPL CPU Time 1.66 0.01 2.64 2.82 1.14 0.77 0.39 152.38 0.43 0.31 \nProcedure Iterations 142 18 236 100 96 78 51 1075 70 45 Clause Iterations 276 35 740 548 182 142 107 \n3369 161 88 CPU Time (5) 1.40 001 2.50 2.32 1.14 0.77 0.39 26.28 0.43 0.31 CPU Time (2) 1,36 0.01 2.48 \n1.74 1.14 0.77 0.39 10.25 0.43 0.31 Table 3: Computation Results Type Graphs (Principal lhnctors) Comparison \nPrograms NI co LI ST DI JiY AAI AR c CI CR AR o 06 1 0 3 10101.00 5 51.00 AR1 o 4 0 0 1010100 55100 Cs \no31(30; 2: 0 0 93 24 026 33 12 037 DS o 5(4) 29 1(1; o 59 30 0.51 29 13 0.45 BR 0 8(8) 13 2(2; 10(lo) \no 59 13 0.22 20 11 055 KA 0 11(11) 20 27 13(1) 2 124 34 0.27 45 22 049 LDS o 5(4) 39 1(1) o 61 40 0.66 \n31 23 0.56 LPE 0 6(6) 25 8(3; 6 4 63 40 0.66 19 19 1.00 LPL o 9(9) 10 7(3) o 1 33 150.45 14 80.57 PE \n0 6(6) 23 8(3) 6 4 63380.60 19191.00 PG 0 6(6) 14 0 0 31 140.45 10 70.70 PL 0 9(9) 5 7(3; 1 33 100.30 \n14 80.57 PR 0 19 (19) 24 24 (20) 10 (6; o 144 32 0.22 53 22 0.41 QU o 1(1) 6 0 0 01160.55540.80 RE 2(2) \n6(6) 28 1(1) 8(2) 3 123 37 0.30 43 27 0.63 Mean 0.50 0.67 Table 4: Accuracy Results: Output Tags Type \nGraph .omp lson I ST DI HY A ?ir -?i lT T m TT&#38;- I 2 0 o 0 10-5-m-r-r 0.20 2 0 0 0 10 20.20 5 10.20 \n14 0 0 93 150.16 33 100.30 15 0 1(1; o 59 16027 29 120.41 10(10) o 59 5 008 20 5 0.25 KA o 2 (2) 1: 181($] \n7 (1) 2 124 21 0.17 45 18 0.40 LDS o 2(1) 23 1(1) o 61 24 0.39 31 13 0.42 LPE o 18 5(3; 0 0 63 20032 \n19 140.74 LPL o 3(3; 12 4(3) 0 1 33 14 0.42 14 10 0.71 PE o 8 5(3) 0 0 6310016 19 60.32 PG o5(5; 7 0 \n0 31 7022 10 50.50 PL o3(3) 1 4(3; 1 33 30.09 14 30.21 PR o 9(9) 18 9(7) 5(3; o 144 22 015 53 19 0.36 \nQU o 2 0 11 20.18 52040 RE 1 2(2; 10 1(1; 5(2; 3 123 16 013 43 14 0.33 . 1L _ Mean 021 0.38 = Table \n5: Accuracy Results: Input Tags 345 l+fmmEs [1] [2] [3] [4] [5] [6] [7] [8] [9]  [10] [11] M. Bruynooghe. \nA Practical Framework for the Abstract Interpretation of Logic Programs. Jow-\u00adnal of Logic Programming, \n10(2):91-124, February 1991. MBruynooghe and GJanssens. An Instance of Ab\u00adstract Interpretation: Integrating \nType and Mode Inferencing. In Proc. Fifth International Confer\u00ad ence on Logic Programming, pages 669 \n683, Seat\u00adtle, WA, August 1988. MIT Press, Cambridge. A. Cortesi, B. Le Charlier, and P. Van Henten\u00adryck. \nCombinations of Abstract Domains for Logic Programming. In .21st Annual ACM SIGPLAN-SIGA CT Symposium \non Principles Of Program\u00adming Languages, Portland, OR, January 1994. P Cousot and R. Cousot. Abstract \nInterpretation: A Unified Lattice Model for Static Analysis of Pro\u00adgrams by Construction or Approximation \nof Fix\u00adpoints. In New York ACM Press, editor, Conf. Record of Fourth ACM Symposium on Program\u00ad ming Languages \n(POPL 77), pages 238 252, Los Angeles, CA, January 1977. M. Dincbas, H. Simonis, and P. Van Hentenryck. \nSolving Large Combinatorial Problems in Logic Programming. Journal of Logic Programming, 8(1\u00ad2):75-93, \nJanuary/March 1990. V. Englebert, B. Le Charlier, D. Roland, and P. Van Hentenryck. Generic Abstract \nInt erpre\u00adt ation Algorithms for Prolog: Two Optimization Techniques and Their Experiment al Evaluation. \nSoflware Practice and Experience, 23(4), April 1993. T. Fruehwirth, E. Shapiro, M. Vardi, and E. Yardeni. \nLogic Programs as Types for Logic Pro\u00adgrams. In IEEE 6th Annual Symposium on Logic in Computer Science, \npages 300 309, 1991. N. Heintze. Practical Aspects of Set-based Anal\u00ad ysis. In Proceedings of the International \nJotnt Conference and Symposium on Logic Programming (JICSLP-92), Washington, DC, November 1992. N. Heintze \nand J. Jaffar. A Finite Presentation Theorem for Approximating Logic Programs. In Proc. 17th ACM Symp. \non Principles of Program\u00adming Languages, pages 197 209, 1990. G. Janssens and M. Bruynooghe. Deriving \nDe\u00adscription of Possible Values of Program Variables by Means of Abstract Interpretation. Journal of \nLogic Programming, 13(2-3):205-258, 1992. T. Kanamori and T. Kawamura. Analysing Success Patterns of \nLogic Programs by Abstract Hybrid In\u00adterpretation. Technical report, ICOT, 1987. [12] B. Le Charlier \nand P. Van Hentenryck. Experi\u00admental Evaluation of a Generic Abstract Interpre\u00adtation Algorithm for Prolog. \nACM Transactions on Programming Languages and Systems. To ap\u00adpear. An extended abstract appeared in the \nPro\u00adceedings of Fourth IEEE International Conference on Computer Languages (ICCL 92), San Francisco, \nCA, April 1992. [13] B. Le Charlier and P. Van Hentenryck. A Universal Top-Down Fixpoint Algorithm. Technical \nReport CS-92-25, CS Department, Brown University, 1992. [14] K. Marriott and H. Sondergaard. Notes for \na Tuto\u00adrial on Abstract Interpretation of Logic Programs. North American Conference on Logic Program\u00adming, \nCleveland, Ohio, October 1989. [15] P. Mishra. Towards a Theory of Types in Prolog. In International \nSymposaum on Logic Programming, pages 289-298, 1984. [16] B. Monsuez. Polymorphic Types and Widen\u00ading \nOperators. In International Workshop on Static Analysis (WSA-9.9), Padova, Italy, Septem\u00adber 1993. [17] \nA. Mulkers, W. Winsborough, and M. Bruynooghe. Analysis of Shared Data Structures for Compile-Time Garbage \nCollection in Logic Programs. In Seventh International Conference on Logac Pro\u00adgramming (ICLP-90), pages \n747 764, JerusaJem, Israel, June 1990. MIT Press, Cambridge. [18] K. Muthukumar and M. Hermenegildo. \nCompile-Time Derivation of Variable Dependency Using Ab\u00adstract Interpretation. Journal of Logic Program\u00adming, \n13(2-3):315 347, August 1992. [19] L. Sterling and E. Shapiro. The Art of Prolog: Ad\u00advanced Programming \nTechniques. MIT Press, Cam\u00adbridge, Ma, 1986. [20] P. Van Hentenryck. Constraint Satisfaction in Logic \nProgramming. Logic Programming Series, The MIT Press, Cambridge, MA, 1989. [21] P. Van Hentenryck, A. \nCortesi, and B. Le Charlier. Type Analysis of Prolog Using Type Graphs. Tech\u00adnical Report CS-93-52, CS \nDepartment, Brown University, November 1993. [22] K. Verschaetse and D. De Schreye. Deriving Termi\u00adnation \nProofs for Logic Programs Using Abstract Procedures. In Eighth International Conference on Logic Programming \n(ICLP-91), Paris (France), June 1991. [23] W. Winsborough. Multiple Specialization using Minimal-Function \nGraph Semantics. Journal of Logic Programming, 13(4), July 1992. 346 A Relation to Context-Free Grammars \nType graphs can easily be related to context-free gramm\u00adars and we exploited this correspondence in the \ninfor\u00admal introduction to display the results. A simple idea is to associate a non-terminal symbol TV \nwith each vertex v. The rule aasociat ed with an or-vertex v with succes\u00adsors VI ,. ... Vn is simply \nT, ::= TV, I ... I TVn. The rule associated with afunctor-vertex having f as functor and Vi,..., vn assuccessors \nis simply To ::= f(Tvl,.. ., Tvn). Theruleaasociated with anany-vertex is simply To ::= Any. In the presentation \nof the results, we generallY applY some partial evaluation of the grammar to improve its readability. \nB Relation to Monadic Logic Programs Type graphs can also be related to monadic logic pro\u00adgrams of [?]. \nThe logic program associated with a type graph succeeds for all well-typed terms. A simple way is to \nassociate a procedure pV with each vertex v. The procedure for an any-vertex is simply any(x) . The procedure \nfor a functor-vertex having f as functor andvl, ..., Vn as successors is simply pv(f(xl,. ... xn)) :- \nPv, (xl), . . . . pvm(xn). The procedure asso ciated with an or-vertex with suc\u00ad cessors VI ,. ... Vn \nis simply W(x) :-pv, (x). .. pv(x) :-pvn(x). Note that this rewriting shows that inferring even the \nprincipal functors of an argument is undecidable, since the halting problem for aprogramprog (Input,Output) \ncan be expressed as the type inference problem: p(a,Input) :-prog(Input,Output), p(b,Input). C The Widening \nand its Formal Properties To simplify presentation, we assume, without loss of generality, that type \ngraphs aresuch that their roots are or-vertices and that the successors of or-vertices (resp. functor-vertices) \nare functor-vertices (resp. or-vertices). This assumption requires replacing some functor-vertices (resp. \nany-vertices) by or-vertices with a single suc\u00adcessor which is the original functor-vertex (resp. any\u00advertex). \nThis convention is purely a matter of presen\u00adtation, all our algorithms being defined on the original \ngraphs. The following abbreviations will also be useful in this section. OR(V1) -type(vl) = or. e-depth(vl,vz) \n= depth(vl) = depth(vz). e-pf(vl,v2) = pf(vl) =pf(v2). We also use (nl, . . ..n., nP), nP) J i to denote \nelement n,. This notation is generalized to sets of tuples by defining SJi={s Jils GS}. Topological Clashes \nAs mentioned previously, the key idea behind ourwidening operator is to exploit thetopol\u00adogy of the graphs \nto guess where the sequence is grow\u00ading. We can establish a correspondence between the vertices of two \ngraphs as follows. Definition The correspondencesetbetween twotype graphsgl and gz, denoted by C(gl, \ngz), is the smallest relation R closed by the following two rules: (root (gl),root(gz)) CR  (v1,v2) \nE R k e-depth(vl,vz) k e-pf(vl,vz) ~ (succ(vl,i),succ(vz,i)) G R (1 S i S amity).  The set of topological \nclashes can now be defined in a simple way. Deflnition2 Let gl,gz be two type graphs such that gl < g2. \nThe set of topological clashes between gl and g2, denoted TC(gl,g2), is defined as follows: Tc(gl,gz) \n= { (V>v ) I (V,v ) c c(gl,g2) k 7 (e-depth(gl,gz) t e-pf(gl,gz)) }. The following proposition is an \nimmediate consequence of the definitions. Proposition 3 Let gl, gz be two type graphs such that gl ~ \ngz, If (v, v ) E TC(gl, g2), then OR(v) k OR(V ). Moreover, there exists a unique tuple (va,val) c C(gl,g2), \ndenoted byca(v,v ), such that v ~ succ(va) and v c Succ(val). Our widening operation focuses on a subset \nof topolog\u00adical clashes which lead to a growth in the graph. Definition Let gl,gz be two type graphs \nsuch that gl < g2. The set of widening clashes between gl and g2, denoted WTC(gl,g2), is defined aa follows \n347 v. ancestor &#38; replaceEdge(g,e,e ) = removeUmonnected(g ) v. ~Vn&#38; where depth(vo) ~ depth(v.) \n&#38; vertices(g)) = vertices(g) v= ca(v0,vn)~2}. edges(g ) = edges(g) \\ {e} U {e } root(g ) = root(g). \n The cycle introduction rule can be specified as follows: replaceVertex(g,v,v ) = removeUnconnected(g \n) fR,(g.,gm) = g, where Precondition: CI(go,gn) # 0. vertices(g~) = vertices(g) U {vi,...,vn Postcondition: \n} edges(g)) = edges(g) \\ EI U E2 U E3 g. = replaceEdge(gn,e,e ) root(g ) = root(g) for some (e,e ) c \nCI(g~,g~). vertice(g) n {Vi,...,Vn} # 0 The replacement rule applies when a cycle cannot be EI = { (Va,vb) \n] (V.,vb) c edges(g) &#38; Vb = v } introduced because the denotation of the ancestors notE2 = { (Va,V~) \n\\ (Va,vb) edges(g) %vb = v ] greater than the vertices in the clash. It replaces the (Va,vb) eE3+vac \n{v,,...,v~}&#38; ancestor by an upper bound of the vertices. vb E vertices(g))} v? > v, v) Definition \n[Replacement Rule] Let go and gnbetwo size(relnoveUnconnected(g )) < size(g). type graphs and let GR(go,gm) \n= { (Vn,va) [ (V.,vn) ~ WTC(go,gm) %Figure 3: replaceEdge and replaceVertex va C Sncestor(v.) k 1(V. \n>v.) &#38; pf(vn) g pf(v.) &#38; TWC(gl,g2) = depth(vo) ~ depth(va) }. { (V, v ) I (V,V ) ~ Tc(g,,gz) \nk pf(v ) # {Any} k The replacement rule can be specified as follows: (pf(v) #pf(v ) v TRr(go>gn) = g, \n depth(v) < depth(v))) } Precondition: GR(go,gn) # 0. Postcondition: Transformation Rules The widening \noperator essen-g, = replaceVertex(gm,v.,vn) tially consists in applying two transformation rules to for \nsome (v~,v~) G CR(g~,g~). eliminate (a subset of) topological clashes. The trans- Note that this rule \nonly applies when pf(v~) ~ pf(va)formation rules nondeterministically produce anew type andhenceitleaves \nroom fortheexpansion oftypegraphsgraphg, from two type graphs go and gn withgo ~ gn. before the widening \napplies. They are defined intermsoftwo functions: replaceEdge and replaceVertex. Informally speaking, \nThe Widening Operation We are now in position to present the widening operation. The widening essen\u00adtially \napplies the transformation rules until the sets CI replaces edge e by edge e in the graph while and CR \nare empty. replaceEdge(g, e,e ) Definition [Widening Operator] The widening oper\u00adreplaceVertex(g,v, v \n) ator go ~ g. is defined as follows: replaces vertex v by a new vertex greater or equal than govgn= \nvandv and decreases thesizeofthe graph. The formal if gn < go then go else widen(g~,g~ U g.). definitions \nof the functions are given in Figure 3. The first operation is straightforward. The second op-widen(go,g~) \n= eration can be implemented easily by makingvl an any-if CI(gO,gm) # @ then vertex. It is however possible \nto obtain much more pre-widen(go,TR, (g~,g~)) cision by using a variant of the union operation which \nelse if CR(go,gn) # @ then avoids creating or-vertices which would lead to a growth widen(g~,TR~(g~,g~)) \nin size. Note also that the case where v~ > v can be else handled inastraightforward manner. Wear~now \nready gn. to specify the transformation rules. Thecycleintroduc-We now state two important results on \noperation V. tion rule introduces a cycle in the graph by replacing The proofs can be found in [?]. The \nfirst proof is sim\u00adedges to a vertex by edges to one of its ancestors. ple while thesecond proof requires \na sophisticated well\u00adfounded ordering since our domain is infinite. Definition 5 [Cycle Introduction \nRule] Let go and g. be two type graphs and let Proposition 8 [Termination] Operation Vterminates. Theorem \n9 Operator Vis awidening operator. C1(~o{fj$$)VE), (V,Va)} \\ (VO,Vn) C WTC(ge,gn) % 348 \n\t\t\t", "proc_id": "178243", "abstract": "<p>Type analysis of Prolog is of primary importance for high-performance compilers, since type information may lead to better indexing and to sophisticated specializations of unification and built-in predicates to name a few. However, these optimizations often require a sophisticated type inference system capable of inferring disjunctive and recursive types and hence expensive in computation time.</p><p>The purpose of this paper is to describe a type analysis system for Prolog based on abstract interpretation and type graphs (i.e. disjunctive rational trees) with this functionality. The system (about 15,000 lines of C) consists of the combination of a generic fixpoint algorithm, a generic pattern domain, and a type graph domain. The main contribution of the paper is to show that this approach can be engineered to be practical for medium-sized programs without sacrificing accuracy. The main technical contributions to achieve this result are (1) a novel widening operator for type graphs which appears to be accurate and effective in keeping the sizes of the graphs, and hence the computation time, reasonably small; (2) the use of the generic pattern domain to obtain a compact representation of equality constraints between subterms and to factor out sure structural information.</p>", "authors": [{"name": "P. Van Hentenryck", "author_profile_id": "81100594830", "affiliation": "Brown University Box 1910 Providence RI (USA)", "person_id": "PP39084870", "email_address": "", "orcid_id": ""}, {"name": "A. Cortesi", "author_profile_id": "81100077606", "affiliation": "University of Venezia Via Torino 155 1-30170 Mestre-VE (Italy)", "person_id": "PP39070616", "email_address": "", "orcid_id": ""}, {"name": "B. Le Charlier", "author_profile_id": "81100163814", "affiliation": "University of Namur, 21 rue Grandgagnage, B-5000 Namur (Belgium)", "person_id": "PP31084214", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/178243.178479", "year": "1994", "article_id": "178479", "conference": "PLDI", "title": "Type analysis of Prolog using type graphs", "url": "http://dl.acm.org/citation.cfm?id=178479"}