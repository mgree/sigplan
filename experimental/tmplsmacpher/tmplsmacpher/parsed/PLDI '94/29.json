{"article_publication_date": "06-01-1994", "fulltext": "\n Backtracking without Trailing in CLP (!f?Lin ) * Pascal Brown Van Hentenryck and Viswanath University, \nBox 1910, Providence, Email: pvh,vrtlcs.brown. Ramachandran RI 02912 (USA) edu I%trti Constraint logic \nprogramming (CLP) is a generalization of logic programming where unification is replaced by constraint \nsolving as the basic operation of the language. The combination of constraint solving and nondetermin\u00ad \nism (approximated by backtracking) makes these lan\u00ad guages appealing for a variety of combinatorial search \nproblems. Existing CLP languages support backtrack\u00ad ing by generalizing traditional Prolog implementations: \nmodifications to the constraint system are trailed and rest ored on backtracking. Alt bough simple and \neilicient, trailing may be very demanding in memory space, since the constraint system may potentially \nbe saved at each choice point. This paper proposes a fundamentally new implementation scheme for backtracking \nin CLP lan\u00ad guages over linear (rationsl or real) arithmetic. The new scheme, called semantic backtracking, \ndoes not use trail\u00ad ing but rather exploits the semantics of the constraints to undo the effect of newly \nadded constraints. Semantic backtracking reduces the space complexity by an or\u00ad der of magnitude compared \nto implementations based on trailing and makes space complexity essentially in\u00ad dependent of the number \nof choice points. In addition, semantic backtracking introduces negligible space and time overhead on \ndeterministic programs. The price for this improvement is an increase in backtracking time, al\u00ad though \nconstraint-solving time may actually decrease. The scheme has been implemented as part of a com\u00ad plete \nCLP system CLP (V?L,n) and compared analytically and experimentally with an optimized trailing imple\u00ad \nment ation. Experimental results indicate that seman\u00ad tic backtracking produces significant reduction \nin mem\u00ad ory space, while keeping the time overhead reasonably small. * This research was partly supported \nby the Office of Naval Re\u00adsearch under grant NOO014-91-J-4052 ARPA order 8225 and the National Science \nFoundation under grant numbers CCR-910832 and a National Young Investigator Award. Permission to 00 y \nwithout fee all or part of this material is granted provid J that the copies are not made or distributed \nfor direct commercial advantage, the ACM copyrigM notice and the title of the publication and its date \nappear, and notice is given that copying is by permission of the Association of Computing Machinery. \nTo copy otherwise, or to republish, requires a fee andor specific permission. 1 Introduction Constraint \nlogic programming (CLP) [5] is a general\u00adization of logic programming where unification is re\u00adplaced \nby constraint solving as the basic operation of the language. The combination of constraint solving and \nnondeterminism (approximated by backtracking) makes these languages appealing for a variety of combinato\u00adrial \nsearch problems. Existing CLP languages support backtracking by generalizing traditional Prolog imple\u00admentations: \nmodifications to the constraint system are trailed (i.e. saved on a special stack which contains pairs \n(address, value)) and restored on backtracking. In addition, techniques such as timestamps (e.g. [1]) \nare used to avoid trailing the same object several times in between two choice points. Although reasonably \nsimple and efficient, trailing may be very demanding in mem\u00adory space, since the constraint system can \npotentially be saved entirely in between each two choice points. As a consequence, it seems worthwhile \ninvestigating other backtracking schemes that would depart from the syn\u00adtactic nature of trailing. In \nthis paper, we consider an instance of the CLP scheme over the constraint system J?L,~. !J?I,,~ consists \nof linear equations, inequalities, and disequations over real numbersl and is included in several languages, \nin\u00adcluding CHIP [4, 10], CLP(R) [7, 6, 8], and Prolog [2]. Its implementation maintains the current set \nof con\u00adstraints (which is known to be satisfiable) in a solved form and the fundamental operation of \nthese languages is an incremental satisfiability test which checks if the conjunction of a new constraint \nc and the existing con\u00adstraints is satisfiable. This satisfiability test in $?~?~ may fundamentally change \nthe nature of the solved form, implying that trailing can be very expensive in space and that alternative \nschemes are important to investi\u00adgate. The main contribution of this paper is to present a new backtracking \nscheme for J?Lt ~. The new scheme, called semantic backtracking does not use trailing but 1All results \ndescribed in this paper hold for real and ratio\u00adnal numbers since the two structures are elementary equivalent. \nOur implementation uses ]nfinite-precision numbers to guarantee numerical stability We also give experimental \nresults on finite precision numbers. SIGPLAN 94-6/94 Orlando, Florida USA @ 1994 ACM O-89791 -662-Xf94/0006..@.5O \n349 rather exploits the semantics of the constraints to undo their effect on the solved form during backtracking. \nSe\u00admantic backtracking reduces the memory requirements of CLP (Y?L,~) by an order of magnitude asymptotically, \nkeeping the space and time overhead of nondetermin\u00adism to a minimum and ensurimz that sBace comdex\u00ad . \nity is independent from the number of ch oice points for numbers. In addition, semantic backtracking \nintroduces negligible space and time overhead on deterministic pro\u00adgrams. The price to pay for this functionality \nis an increase in backtracking time, since backtracking now needs to compute inverse linear transformations. \nTo demonstrate the practicability of the scheme, se\u00admantic backtracking has been implemented as part \nof a complete system CLP (!l?~,~) (about 20,000 lines of C) and analysed both experimentally and theoretically. \nIt has also been compared with a trailing implementation using exactly the same solver to quantify precisely \nthe loss in efficiency. The experimental results indicate that semantic backtracking achieve a promising \nspace/time tradeoff for J?L,~, since the time overhead of semantic backtracking is kept small while the \nspace requirements are reduced siznificantlv. The rest of~his pape r is organized as follows. Section \n2 illustrates CLP (~~,~ ) on a simple example to illustrate some of the functionalities of the language \nand the im\u00adplementation problems raised by the language. Section 3 provides some background about the \nconstraint sys\u00adtem while Section 4 presents the general architecture of the implementation. Sections \n5, 6, and 7 discuss the implementation of the new scheme. Section 8 presents some experimental results, \nwhile Section 9 contains the conclusion of this research. 2 A Motivating Example To illustrate the functionalities \nof CLP (Y? L,n), we use an example from [2]. Consider an infinite sequence of numbers Z1, Z2, . . . defined \nby where Z1 and Z2 are arbitrary real numbers. The prob\u00adlem consists in showing that the sequence is \nalways pe\u00adriodic and has a period of 9 or, in other words, that the sequences Z1, Z2, . and ZIO, XII, \n. . are always identi\u00adcal. The problem can be solved indirectly by using the following idea: since the \ntwo sequences are completely determined as soon as their first two elements are fixed, it is sufficient \nto show that any sequence xl, Z2, . . . ,Xll), xll implies xl = Zlo and X2 = Zll. The program then con\u00adsists \nin searching for a solution such that (ZI, Z2 ) # (ZIO, ZII ). The absence of solutions proves the conjec\u00adture. \nThe complete program is shown in Figure 1. This example illustrates nicely the combination of constraint \nsolving (including strict inequalities and dise\u00adquations) and nondeterminism. The predicate sequence \ndefines the sequence in reverse order. It is defined recur\u00adsively and uses the predicate abs to compute \nthe abso\u00adlute value. abs is nondeterministic (since the values are invalidate :\u00ad [x1, x21#[x10, xIll, \nsequence ([Xll, X10, X9, X8, X7, X6, X5, X4, X3, X2, Xl]) . sequence( [X2,X11 ) . sequence ([Xll, X10, \nX91 XsI) :- abs(XIO,XIOa) , X11 = XIOa -X9, sequence([XIO ,X91XS]). abs(X,X) :-X>O. abs(X,-X) :-X < \n0. Figure 1: The Periodic Sequence Program not known originally) and first enforces the constraint that \nits argument is positive. On backtracking, abs en\u00adforces the constraint that its argument is strictly \nnega\u00adtive. Note that theprogram never gives anyvalue to the variables, yet it fails in all cases thanks \nto the complete constraint solver. Any implementation of CLP(Y?L,~) needs to address two issues: incremental \nconstraint solv\u00ading and backtracking. Incremental constraint solving amounts to deciding dynamically \nthe satisfiability oflin\u00adear constraints. Backtracking amounts to undoing the effect of some constraint \naddition on the constraints ac\u00adcumulated so far. For instance, in our example, back\u00adtracking needs to \nundo the effect of constraints of the form y ~ O and y < 0 on previously encountered con\u00adstraints. As \nmentioned already, traditional approaches simply undo the effect of new constraints by saving all modifications \nto the solved form in a purely syntactic manner. This paper proposes a new solution to imple\u00adment backtracking. \n3 The Constraint System The constraint system of CLP(~L,n) deals with linear constraints. Definition \n1 Let tl and tztwo linear expressions con\u00adstructed with variables, rational numbers, and the op\u00aderations \n+,*, and /. A constraint is a relation tl8t2 with 6 E {>, ~,=, #, s,<}. The constraint system is a generalization \nof linear pro\u00adgramming [3] due to the presence of strict inequalities (> and <) and disequations (#). \nImplementations of this constraint system use a set of rewriting rules (usu\u00ad ally applied dynamically) \nto consider only equations and disequations. In particular, wehavetl ~t2 is rewritten astl s= tz, tl>tzastl \ns =t2&#38;s#0, andtl~t2 astl+s= tz, tl<tzastl +s=t2&#38;s#0, wheresis a slack variable, i.e. a variable \nconstrained to take only nonnegative values. In the following, arbitrary variables will be denoted by \nthe letter z, slack variables by the letters s and a, and rational numbers by the letter 6, all of them \npossibly subscripted. 350 4 The Architecture of the Implementation The implement ation of CLP (Y2L,n) \nis organized around four modules, the engine, the interface, the G-system (Gauss system), and the S-system \n(Simplex system), with a left-to-right communication pattern. The engine is responsible for the control \npart of the system (e.g. clause and goal selection) while the G-and S-systems are responsible for constraint \nsolving. The interface module converts the engine representation of constraints into their solver representation. \nThe engine and the G\u00adand S-systems have their own choice point stacks, since there is no reason to save \ninformation in the constraint system if no activity takes place. Design decisions sim\u00adilar in spirit \nwere adopted in CLP (J?) [7]. The inter\u00adface and the G-and S-systems can be seen as abstract data types \nproviding seven operations: SolveEqual, SolveGreatereq, SolveGreater, SolveNotEqual. and Try, Retry, \nTrust. The first four operations are used to insert a new constraint and returns a Boolean value. The \nmain cliffer\u00ad ences between these functions in the different modules is the constraints they manipulate. \nThe interface receives constraints in the engine representation and transmits them to the G-system in \nthe solver representation. The G-system receives constraints containing only arbitrary variables, while \nthe S-system receives constraints con\u00adtaining only slack variables. The second set of opera\u00adtions corresponds \nto the traditional or-level instructions of WAM-based implementations of Prolog [11]. Trysig\u00adnals the \ncreation of a choice point, Retry signals the selection of the next (but not the last) alternative in \nthe choice point, while Trust signals the selection of the last alternative in the choice point. Backtracking \nin the solver is initiated by the instructions Retry and Trust. In the G-and S-systems, inequalities \nare transformed immediately into equations and disequations (by adding slack variables) when they are \nnot trivially satisfiable or unsatisfiable. Hence, in the rest of the presentation, we only consider \nequations and disequations. The rest of the implementation will be described as follows. Section 5 discusses \nthe G-system while Section 6 discusses the S-system. To ease the presentation, we assume in Section 5 \nthat the G-system contains only ar\u00adbitrary variables (i.e. in other words, weignore inequal\u00adities). Section \n7 shows how to integrate inequalities in a simple way. Both Sections 5 and 6 are organized in five sections: \nthe solved form, constraint solving, backtrack\u00ading with trailing, semantic backtracking, and analysis. \nIn thefollowing, weuse Trai.lto refer tothe CLP(R~,~) implementation using traihng and Semantic to refer \nto the implementation using semantic backtracking. 5 The Gauss System In this section, we consider constraint \nsolving and back\u00adtracking for systems of equations and disequations over arbitrary variables. Constraint \nsolving and semantic backtracking are relatively simple in the G-system but they introduce the main ideas \nused in the more complex S-system. 5.1 The Solved Form Informally, the solved form in the G-system consists \nin isolating one variable per equation and making sure that the disequations do not reduce to O # O, \nDefinition 2 An equation is in solved form iff it is of the form z, = lJO + blzl + . . . + b, lx; l + \nb,+lz,+l + . . . + b~z~. Z, is called a basic variable. Definition 3 A system of equations &#38;is in \nsolved form iff (1) each equation of t is in solved form; (2) all ba\u00adsic variables are distinct; (3) \nthe right-hand side of the equations do not contain any basic variable. Definition 4 A system of equations \nand disequations S U D is in solved form iff &#38; is in solved form and each disequation in D is of \nthe form O # bo+blzl +. . .+ bnzn, does not contain any basic variable, and has at least one non-zero \ncoefficient b, (O < i < n). 512 Constraint Solving Constraint solving in the G-system is based on Gaussian \nelimination and backpropagation. Insertion of a Disequation Adding a disequation re\u00adquires to dereference \n(i.e. to remove the basic variables of) the constraint first. If the dereferenced constraint is of the \nform O # b, it is trivially satisfiable or unsatis\u00adfiable. Otherwise, it contains at least one variable \nand must be added to the disequations. Insertion of an Equation Adding a new equation e to a system S \nU D consists of three steps: (1) dereferencing e; (2) choosing a basic variable for e; and (3) backprop\u00adagation. \nDereferencing amounts to replacing each basic variable of ~ in e by its right-hand side producing a new \nconstraint e of the form O == bo+blxl+. . .+ bnzn. If the b, (1 ~ b, ~ n) are all zeros, then the constraint \nis either trivially satisfiable or unsatisfiable. Otherwise, a vari\u00adable with a non-zero coefficient \nis selected to become the new basic variable and the constraint is rewritten accordingly. Backpropagation \nthen replaces each occur\u00adrence of this new basic variable by its right-hand side in the old system ~ \nU D and makes sure that no disequa\u00adtion reduces to O # O, in which case the system would be unsatisfiable. \nThe new system is then obtained by adding the new constraint. 5.3 Backtracking with Trailing In this \nsection, we give an overview of the trail imple\u00adment ation of CLP ( Y2L,n ) which will be used in the \ncom\u00adparison with semantic backtracking. Although it uses some ideas well-known in the folklore of CLP, \nalgorithm Trail improves on many existing implementations in its memory usage and will be used in the \ncomparison with semantic backtracking. Algorithm Trail follows the traditional approach of CLP languages \nwhich is an extension of the Prolog back\u00adtracking strategy. The basic idea is to store on a special \n351 stack, called the trail, the address and current value of each object about to be modified. The trail \nthus con\u00adtains pairs < address, value > and, in cLP (~~,~), the value is often a pointer to an infinite \nprecision number. Backtracking simply unwinds the trail and restores the values as the contents of the \naddresses. To avoid trailing several times the same object, algo\u00adrithm Trail uses time stamps to determine \nif the object has been modified since the last choice point, in which case it does not need to be trailed \nagain. Time stamps have been used in several implementations of CLP lan\u00adguages, including GHIP and CLP(32), \nand lead to the following pattern to update an object IF it k necessary to trad THEN BEGIN trail; update \nthe time stamp; END update the object; Since (!Lp (!J?Lzn ) deals with infinite precision num\u00adbers, algorithm \nTrail devotes extra care (which is often omitted in existing implementations which are based on a stack \narchitecture) to release the numbers which are no longer necessary. This arises in two situations: (1) \nwhen a coefficient is updated several times in between two choice points and (2) on backtracking. In \nbetween two choice points, it is only important to have access to two numbers for each coefficient: its \nfirst and its last values. All intermediary numbers can be freed since they are not needed for backtracking. \nThis leads to the following pattern for updating coefficients IF it is necessary to tr~ THEN BEGIN trail; \nupdate the time stamp; END ELSE release the old number: store the new number; On backtracking, all numbers \nallocated since the last choice point can be released. Once again, using time stamps enables us to perform \nthis efficiently. Note that the first situation defined above precludes the use of a stack to allocate \nthe numbers which would allow the second step to be performed in constant time. Such a stack organization \nwould not enable the reuse of inter\u00ad mediary numbers. Algorithm Trail uses the number of active choice \npoints to update the time stamps. This makes sure to recover all unnecessary numbers during the computation \nat the cost of having to restore the time stamps. A simple scheme using a counter incre\u00ad mented by the \nTry, Retry and Trust operations would be suboptimal. Finally, since the solved form is generally organized \nusing linked-list data structures, algorithm Trail de\u00ad votes extra care to recover cells which are no \nlonger needed. This happens when a new coefficient is created (i.e. it becomes different from zero) and \nsubsequently deleted (i.e. it becomes zero) in between two choice points. Algorithm Trail detects this \nsituation using time stamps once again and is able to reuse the space. Note that once again this precludes \nstack allocation for cells.  p(ZI,~2,~3) :- Xl+2XZ+3X3 #l, x~ +x2+x3=4, q(zl, z2, z3), r(zl, z2, z3), \n... q(zl, z2, z3) :-XI-2X2+4X3=7 . q(zl, z2, z3) :-.... r(zl,zz,za) :-z~+3x2-3z3=4 . r(zl, z2, z3) :-.... \nFigure 2: A simple CLP program for the G-system Our trailing implement ation preserves the minimal amount \nof numbers and cells (contrary to most imple\u00admentations we are aware of). Note that trailing can be further \nreduced by several techniques such as the recon\u00adstruction of some of the data structures at backtracking \ntime (e.g. cross-reference tables in the CLP (R) system [7]). These techniques may increase the backtracking \ntime. For space reasons, we do not discuss these tech\u00adniques in this abstract. We are now in position \nto sum\u00admarize the various actions performed by the operations. Constraint Solving Constraint solving \ntrails any mod\u00adification to the solved form. Operation Try This operation saves the dimensions of the \nsolved form and the top of the trail. Backtracking Backtracking unwinds the trail to re\u00adstore the old \nvalues at the appropriate addresses. It also releases the numbers allocated since the last choice point \nand resets the top of the trail. Operations Retry and Trust Operation Retry simply performs backtracking \nwhile operation Trust per\u00adforms backtracking and pops the choice point. 5.4 Semantic Backtracking This \nsection considers the implement ation of semantic backtracking for the G-system. Its main motivation \nis to avoid the drawback of algorithm Trail which may potentially save the whole solved form in between \ntwo choice points. It starts with a motivating example and then describes the operations precisely. An \nExample Consider the (partial) CLP Program de\u00ad picted in Figure 2 and using the same convention as for \nthe constraint system for simplicity. Assuming a goal p(zl, x2, X3), the solved form before calling q/3 \nis {O#3+zz+2zs,zI = 4 X2 z3}. Before caK ing r/3, the solved form becomes {O # 2 + 3z3 , xl = 5 2x3 \n, zz = 1 + z3}. The solved form after r/3 is simply{O# l,zlm7,zz D 2,zsn 1}. 352 Observe now that backtracking \nto select the second clause of r/3 consists in removing the effect of last con\u00adstraint which can be achieved \nin a simple way by adding to the first three constraints the last constraint after multiplying it by \n-3, 2, and -1 respectively. Note also that 3, -2, and 1 are in fact the coefficients of Z3 in the previous \nsolved form. Similarly, backtracking over the third constraint to select the second clause of q/3 amounts \nto adding the third constraint to the first two aft er multiplying it by -1 and 1. Now observe the co\u00adefficients \nof Q and Z3 in the first two solved form. It becomes clear that, to backtrack in the G-system, it is \nsufficient to remember the coefficients of the new basic variable in the old solved form. These coefficients \ncan be used at backtracking time to restore the previous states by adding multiples of the last constraint. \nWe now consider how to implement this idea. Constraint Soh.nng Equation solving needs to be mod\u00adified \nslightly. The modification occurs when the new basic variable is present in the old solved form. In this \ncase, backpropagation should save the coefficients of the new variable for subsequent backtracking, when \nin a nondeterministic state. Note that no saving is required when the new basic variable is a new variable, \nsince it does not appear in the old system. The handling of disequations is left unchanged. Instruction \nTry Instruction Try is postponed until some activity occurs in the solver. At this point, it simply saves \nthe dimension of the constraint system. Backtracking Backtracking undoes the effect of all con\u00adstraints \ninserted since the last choice point one at a time. No work is necessary when the constraint is a dis\u00adequation \nor an equation which contained a new variable at insertion time. Otherwise, multiples of the removed \nconstraints are added to the solved form, using the co\u00adefficients saved during equation solving. Backtracking \nalso restores the dimensions of the solved form. Instruction Retry and Trust Instruction Retry sim\u00ad ply \nperforms backtracking. Instruction Trust performs backtracking and pops the choice point.  5.5 Analysis \nIn this section, we compare the space and time complex\u00ad ity of the two algorithms. In the complexity \nanalysis, we distinguish between numbers and words for space complexity and arithmetic and word operations \nfor time complexity. This distinction is useful, since several im\u00adplementations of the constraint system \nuse infinite pre\u00adcision numbers. The complexity results are expressed in terms of the computation state \nof the system which can be described for our purposes by three numbers, c, v and b, representing the \nnumber of constraints c and variables u of the constraint system in the computation state and the number \nof choice points which are active in the state. Note also that c is necessarily smaller or equal to v \nin the analysis, as the system would be over\u00adconstrained otherwise. We first consider space complexity. \nAlgorithm Trail may need to trail almost the whole constraint system in between two choice points, since \nbackpropagation may affect the coefficients of all non-basic variables. Algo\u00adrit hm Semantic requires \nsaving the coefficients of the new basic variable in the old solved form when a new equation is added \nto the solved form. Hence, Algorithm Semantic reduces the space overhead and complexity by an order of \nmagnitude for numbers and words. Proposition 5 [Space Complexity of Trail] In the worst case, algorithm \nTrail requires O(cvb) num\u00adbers and O(cvb) words for some computation state to support nondeterminism. \nThe space complexity of al\u00adgorithm Trail is thus O(cvb) numbers + O(cvb) words in the worst case.2 Proposition \n6 [Space Complexity of Semantic] In the worst case, algorithm Semantic requires 0(c2) numbers and O(b) \nwords for some computation state to support nondeterminism. The space complexity of algo\u00adrithm Semantic \nis thus O(cv) numbers + O(rmm(co, b)) words in the worst case. We now consider time complexity. The \ntime over\u00adhead of Trail consists in trailing the (addresses of) modified coefficients. The time overhead \nof Semantic comes from the saving of the pointers to the modified co\u00adefficients. Interestingly, the time \noverhead of Semantic is an order of magnitude lower than Trail. Proposition 7 [Time Complexity of Constraint \nSolv\u00ading in Trail] In the worst case, the overhead of algo\u00adrithm Trail is O(cv) word operations per constraint \ninsertion. Its time complexity for constraint insertion is thus O(cv) word and arithmetic operations \nin the worst case. Proposition 8 [Time Complexity of Constraint Solv\u00ading in Semantic] In the worst case, \nthe overhead of algo\u00adrithm Semsnt ic is O(c) word operations per constraint insertion. Its time complexity \nfor constraint insertion is thus O(cv) word and arithmetic operations in the worst case. The price to \npay for the space improvement is in fact in the backtracking time. Algorithm Trail only needs to restore \nthe previous coefficients which can be done by manipulating addresses. Algorithm Semantic needs to perform \narithmetic operations and cannot amortize the cost over several constraint deletions. Proposition 9 [Time \nComplexity of Backtracking in Trail] In the worst case, algorithm Trail performs O(cv) word operations \nto backtrack over any number of con\u00adstraints. 2Theoretically, it k possible to reduce the space complexity \nto take only O(maz(cv,b)) words. However, thu? would entail a time penalty for constraint solving which \nwould need to store coefficients on the tr.ml instead of pointers. 353 Proposition 10 [Time Complexity \nof Backtracking in Semantic] In the worst case, algorithm Semantic per\u00adforms O(cv) arithmetic operations \nto backtrack over a constraint. It performs O(ncv) arithmetic operations to backtrack over n constraints. \n6 The Stmplex System We now consider consider equations and disequations over slack variables. Constraint \nsolving and backtrack\u00ading are substantially more complex this case. 6.1 The Solved Form The only difference \nbetween the solved forms of the G\u00adsystem and S-system is a lexicographic requirement im\u00adposed on the \nsolved form of the equations. The lexi\u00adcographic requirement, proposed in [1 O], assumes a to\u00adtal ordering \non the variables (e.g. .s1 < sz < . . .) and generalizes the positivity requirement of the simplex al\u00adgorithm, \nThe positivit y requirement makes sure that the equations are satisfiable, while the lexicographic re\u00adquirement \nguarantees that all fixed variables (i.e. vari\u00adables constrained to take a single value) are made ex\u00adplicit. \nThe guarantee that all fixed variables are made explicit makes it easy to check the disequations, since \nit is sufficient to check if a disequation does not reduce to O # O. See [10] for complete account on \nthe solved form. Semantic backtracking can also be applied to sys\u00adtems not based on the lexicographic \nsolved form such as CLP(!R) and Prolog III. Definition 11 An equation over slack variables is in solved \nform iff it is of the form s, = /)0+fqsl + . ..+ b._ls,_l +bt+lst+l +.. .+ bnsn and either the first \nnon-zero coefficient in the sequence (be, b,,..., b,_l, 1) is positive or all b,, i.e. bo, . . .. bl.b, \n+1,1, bn, ,bn, are zeros. The definitions for systems of equations and disequa\u00ad tions are the same as \nfor the G-system. 6.2 Constraint Solving Insertion of a Disequation Disequations are handled in the \nsame way as in the G-system. The disequation is dereferenced, tested for satisfiability, and inserted \nin the solved form if necessary. Insertion of an Equation The addition of a new equa\u00adtion is based on \nthe simplex algorithm. The main idea is to dereference the constraint and to make a case anal\u00adysis considering \nat least three cases: 1. New Variable Case: the constraint contains a new variable that can be put in \nbasis while satisfying the lexicographic requirement; 2. Faxed Variables Case: the constraint is of the \nform ()=bo+bls l+... +b~s~ (b, ~Ofor O~i <n); 3. General Case: all other cases.  The case new variable \nis simple, since a new solved form is obtained easily and the disequations are clearly satisfiable. The \ngeneral case is handled through the simplex algorithm. The key idea is to introduce an artificial variable \na to obtain a new constraint a = bo+blsl +... + bn sn. The simplex algorithm is then used to minimize \nthe value of a in an extended system where the above constraint has been added with a in basis. If the \nminimization returns a strictly positive value, the system of equations is inconsistent. Other\u00adwise, \nthe system is consistent and the artificial variable can be removed (perhaps after some preliminary work \nif the artificial variable is still in basis). The final step consists in dereferencing all disequations \nto make sure that thev. do not reduce to O 40. Recall as well that the simplex algorithm performs a sequencing \nof operations, each of them consisting of three steps: (1) choosing a variable to enter the basis; (2) \nchoosing a variable to leave the basis; and (3) pivoting the system to intro\u00adduce the entering variable \nin basis in place of the leaving variable. Pivoting is the main operation and consists in adding multiples \nof the constraint c whose basic vari\u00adable is the leaving variable to all other constraints to make sure \nthan the entering variable occurs only in c. The constraint c itself is also divided by the coefficient \nof the ent erimz variable to uroduce the new solved form. Pivoting pres&#38;ves the sol~ed form provided \nthat a lex\u00adicographic pivoting rule is used [10]. The case jixed variable is more subtle but does not \nrequire the full simplex algorithm. If bo is greater than zero, the constraint is unsatisfiable. Otherwise, \nall slack variables with a non-zero coefficient must be equal to zero and this fact needs to be propagated \nin the solved form. This can be achieved by simply removing these variables from the solved form. However, \nthe result\u00ading system may not be in solved form anymore due to the lexicographic requirement. Two main \ncases must be distinguished when this happens for a constraint: 1. the constraint is of the form O = \nalzl + +a~zn with a~< 0for all i; 2. the constraint is of the form O = alzl + . . . +anzn with some \na, > 0for 2s i~ n.  In the first case, the algorithm has discovered new fixed variables and they can \nbe handled as the initial fixed variables. In the second case, pivoting takes place to introduce into \nthe basis a variable with a positive coeffi\u00adcient. Note that pivoting may possibly reveal more fixed \nvariables. The final step consists of course in checking the disequations. We now consider backtracking \nin the S-system and focus on semantic backtracking since the trailing implementation uses the same techniques \nas in the G-system. We now consider backtracking in the S-system and focus on semantic backtracking since \nthe trailing imple\u00admentation uses the same techniques as in the G-system. 354  6.3 Semantic Backtracking \nafter removal of the artificial variable. Note also that Backtracking in the S-system is substantially \nmore in\u00advolved than in the G-system. The simplicity of back\u00adtracking in the G-system comes from two facts: \non the one hand, older constraints are never added or sub\u00adtracted from new constraints; on the other \nhand, new constraints only extend the basis. None of these proper\u00adties hold in the S-system. However, \nconstraint solving in the S-system still performs linear transformations and hence, with some care, it \nshould be possible to invert them. The rest of this section starts with an informal overview of the approach \n(including examples) and then specify more precisely the various instructions. Informal Presentation \nAlgorithm Sement ic performs backtracking in the S-system in two main steps: (1) undoing the effect of \nthe new constraints, i.e. the con\u00adstraints introduced since the last choice point; (2) restor\u00ading the \nprevious solved form, i.e. the solved form in use when the last choice point was created. The first step \nis similar in spirit to backtracking in the G-system but is more subtle for reasons that will become \nclear shortly. The second step is necessary be\u00adcause the first step may not return to a solved form or \nmay return to a different solved form. The only guar\u00adantee provided by step 1 is that it returns to a \nsystem which is equivalent to the previous solved form. We now consider each step in detail, focusing \nmainly on the general case for simplicity. For the first step, observe that, after the minimiza\u00adtion \nprocedure, the coefficients of the artificial variable contains the information necessary to undo the \neffect of the constraint. Hence, it seems natural to save these coefficients to enable backtracking subsequently. \nUnfor\u00adtunately, this simple solution is not correct because of subsequent pivotings which may affect \nthe relationships between the constraints. Consider the following incom\u00adplete CLP program (the s, are \nthus assumed to be slack variables): p(sl, s2, s3, s5, s6, S7) :\u00ad S1~2S2~S3-S5=8 , q(sl, s2, s3, s5, \ns6, s7), ... q(sl, s2, s3, s5, s6, S7) :\u00adssI+ssz+s3-s~=ls, S2 -s7 =3. q(sl,s2,s3,s5,s6,S7) :\u00ad... The \nfirst solved form before the call to q/6 is (SS = 8 S1 2s2 s-s}. Insertion of the first constraint \nin q/6 leads to the general case producing the system and its associated solved form S3 = s2+2s5 Ls6 \nH ;,+~s, SI = 5 5s2 s { the coefficients of the artificial variable. Insertion of the second constraint \nof q/6 induces a change of basis and leads to the system S2 = 3+s7 al 51 = 2 L~3+&#38;S6-97+ aI 2 { .95 \n= o+~s3+~s6+s7 al Now assume that we need to backtrack to the second clause of q/6. Using the coefficients \nof al, backtracking produces the system S2 = 3 2s3+s5 1S6 .$1 = 2+$3 -s5+~s6 { Using the coefficients \nof uo, backtracking would produce the incorrect system 11 sl+s2=5 :s3+~s6 The problem comes from the \nfact that the first con\u00adstraint has been divided by 2 during pivoting and then added to the other constraints, \nbut this information has not been propagated on the coefficients. The solution adopted in algorithm Semantic \nis to preserve the artificial variable until the next (solver) choice point and to perform traditional \npivoting opera\u00adtions on artificial variables as well. In other words, algo\u00adrithm Semantic works with \nan extended system which, in addition to the solved form, contains the artificial variables int reduced \nsince the last choice point. The solved form can be obtained easily by removing the ar\u00adtificial variables. \nAll the operations (e.g. dereferencing, selection of the entering variables) use the solved form except \npivoting which also updates the coefficients of the artificial variables. It is sound to save the coeffi\u00adcients \nof the artificial variables at the next choice point, since backtracking returns to the same solved form \nand hence the validity of our coefficients is guaranteed. Con\u00adsider our example again. The final system, \nkeeping the artificial variables ao and al for backtracking purposes, becomes S2 = 3+s7 al S1 = z AS3+LS6 \nS7 LaiJ+al {S5 3 = ()+~.$3+ ~s6+s7-~a0 -al The solved form can of course be obtained by remov\u00ading the \nartificial variables. Backtracking over the last constraint leads to the system 3 z S3+s5 L56+AC10 .92 \n= S1 = z+~S3 s5+]S6 ~ao { Now backtracking over the second constraint leads to the system {2s2 + SI = \n8 ss + ss } correctly undoing the effect of the new constraints. The second step, restoring the solvedform, \nis necessary3 since the first step may not return to a solved form or 31t is possible to imagine an implementation \nreturning to a different solved form See Section 6,4, 355 may return to a solved form which is different \nfrom the initial solved form, invalidating the coefficients of the artificial variables saved in the \nchoice point. For in\u00adstance, the first step for our example may lead to a system {2SZ = 8 S1 .s3 + \nS5} which is not in solved form. It is of course easy to restore the solved form in this example by putting \nss in basis instead of sz but, in general, the system obtained by the first step may be far from the \nold solved form. Al~orithm Semantic overcomes this problem in two steps: (1) at each choice point, it \nsaves the variable in basis for each constraint; (2) during backtracking, it restores the old basis by \nsolv\u00ading the system of equations in terms of these variables. We illustrate this on an example. Assume \nthat the first step returns the system and assume that the basic variables saved in the choice point \nare SI, sz, ss. The initiaJ system is simply obtained by dividing the first constraint by the coefficient \nof S1 and removing S1 from the other constraints to obtain %5 = 1 1s1 3s4 1s6 S7 = 3 s7, -5s4-s5-s6 Ss \n= 4 s3 2.54-5s5-slj { The old solved form is then obtained by putting S1, sz, ss in basis to produce \nSI = 1 3s4 2s5 1s6 .92 = 3 5s4 s5 56 s7 { S3 = 4 2s4 5s5 s6 s6 In summary, algorithm Semantic stores \ntwo kinds of information in between two choice points to perform backtracking: (1) for each equation, \nit saves a witness variable which is essentially the first basic variable of the equation in between \nthe choice points. In particu\u00adlar, it is the basic variable for the constraints existing before the choice \npoint, the artificial variable for the general case of insertion, and the new variable for the new variable \ncase; (2) tt also saves the coefficients of the artificial variables when a new choice point is created. \nConstraint Solving The disequation solving algorithm is left unchanged. Equation solving is modified \ndiffer\u00adently depending on the various cases. The new basic variable case requires only to remember the \nnew basic variable as the witness variable. The ge nercd case is modified to remember the artificial \nvariable as the wit. ness variable and to avoid removing the artificial vari\u00adables. Pivoting operations \napply to the artificial vari\u00adables as well but all other operations do not involve them. The jized oat-tables \ncase is more subtle since re\u00admoving the fixed variables from the solved form would prevent us from undoing \ncorrectly later on. The key idea is to consider each fixed variable s at a time and introduce a constraint \ns = a where a is a new artifi\u00adcial variable which will be the witness variable for the constraint. This \nconstraint is then used to eliminate s from the solved form. The rest of the algorithm is left unchanged \nexcept that new fixed variables are handled as just described. Operation Try Recall that this operation \nis postponed until some activity takes place. Try consists of three steps: (1) the saving of the coefficients \nof the artificial variables of the current system; (2) the saving of the witness variable for each equation \nof the solved form; (3) the saving of the dimensions of the constraint system. Backtracking Backtracking \nin the S-system is performed in four steps: (1) undoing the effect of the new con\u00adstraints; (2) restoring \nthe old dimensions; (3) restoring the old solved form; (4) dereferencing the disequations. The first \nstep considers each equation at a time and un\u00addoes its effect. Undoing a single equation e consists in \nusing the witness variable s to eliminate all occurrences of s in the rest of the constraint system, \nthe only oc\u00adcurrence of s being now in e. This can be done easily by using linear transformations on \nthe constraint sys\u00adtem. The third step uses the witness variables of the old equations to restore the \nold solved form. Assume that sl, ..., s~ are the witness variables. The key idea is to apply linear transformations \nso that the column of the constraint system associated with S1, . . . . sn make up a unit matrix. This \namounts to solving the system of equations for variables S1, . . . . s ~. Finally, the last step dereferences \nthe disequations to remove any occur\u00adrence of a basic variable.. Operation Retry and Trust Retry simply \nperforms back\u00adtracking. Trust performs backtracking, pops the last choice point, and rest ores the coefficients \nof the artifi\u00adcial variables. This last step is necessary, since, on the one hand, future backtracking \nneeds to use these coef\u00adficients to undo the effect of the constraints inserted in between the last two \nchoice points and, on the other hand, subsequent pivotings must update these coeffi\u00adcients. 6.4 Analysis \nWe first consider space complexity. Algorithm Trail may trail the whole constraint system in between \ntwo choice points, since pivoting may affect the coefficients of all variables. The space complexity \nof Semantic for the S-system is similar to the complexity of Semantic for the G-system, except that we \nneed to account for the witness variables. Proposition 12 [Space Complexity of Trail] In the worst case, \nalgorithm Trail requires O(cvb) numbers and O(cvb) words for some computation state to sup\u00adport nondeterminism. \nIts space complexity of algorithm Trail is thus O(cvb) numbers + O(cvb) words in the worst case.4 40nce \n~~ain, in theory, it is possible to reduce the sPace com\u00adplexity to take only O(maz(cv,cb)) words. 356 \n Proposition 13 [Space Complexity of Semantic] In the worst case, algorithm Semantic requires 0(c2) numbers \nand O(cb) words for some computation state to sup\u00adport nondeterminism. Its space complexity of algorithm \nSemanticist thus O(cv) numbers + O(rnaz(cv, ctJ)) words in the worst case. Once again, algorithm Semantic \nreduces the space over\u00adhead and complexity by an order of magnitude for num\u00adbers and words. We now consider \nthe time overhead for constraint solving and restrict attention to the over\u00adhead of pivoting since this \nis the kernel operation of the solver. In each pivoting, algorithm Trail checks if the modified coefficients \nneed to be trailed and pushes their addresses on the trail. The time overhead of Semantic for pivoting \ncomes from the use of additional variables (i.e. the artificial variables). In the worst case, there \nare as many additional variables as new constraints. Proposition 14 [Time Overhead for Pivoting in hail] \nIn the worst case, algorithm Trail performs an addi\u00adtional O(cv) word operations per constraint insertion \ncompared to a deterministic algorithm. Proposition 15 [Time Overhead for Pivoting in Semantic] In the \nworst case, algorithm Semsnt ic performs an ad\u00additional O(nc) operations per constraint insertion com\u00adpared \nto a deterministic algorithm, where n is the num\u00adber of constraints inserted since the last choice point. \nIt is easy to see that algorithms Trail and Semantic do not increase the overall time complexity asymptoti\u00adcally. \nWe now consider backtracking time. Backtrack\u00ading in algorithm Trail is simple and consists in freeing \nsome numbers and restoring some coefficients. Back\u00adtracking in algorithm Semantic requires solving a \nsystem of equations in terms of the witness variables. Proposition 16 [Time Complexity of Backtracking \nin Trail] In the worst case, algorithm Trail performs O(cv) word operations for backtracking. Proposition \n17 [Time Complexity of Backtracking in Semantic] In the worst case, algorithm Trail performs 0(c2 v) \narithmetic operations for backtracking. The complexity of backtracking increases not only be\u00adcause arithmetic \noperations are considered but also be\u00adcause the number of operations increases by a factor c. It is interesting \nto note that there exists a backtrack\u00ading scheme which is asymptotically better in memory space than \nSemantic. The key idea is to avoid storing the witness variables for the old constraints, reducing to \nthe space complexity to O(cv) numbers +0( rrzwc(cv, b)) words and the overhead of O(b) words. To achieve \nthis space complexity, the coefficients of the artificial vari\u00adables need to be preserved for the whole \ncomputation to allow the system to return to any solved form. A price to pay is a further increase in \nbacktracking time, since backtracking has no information to come back to a solved form. 7 Integration \nof the G-system and the S-system The G-system and the S-system can be integrated by al\u00adlowing slack variables \nto appear in G-system as well but never as basic variables. The solved form then contains both arbitrary \nand slack variables on the right-hand side. All algorithms remain the same except that (1) if dereferencing \nproduces a constraint containing only slack variables, this constraint is transferred from the G-system \nto the S-system; and (2) if backpropagation leads to a disequation containing only slack variables, it \nis sent to the S-system. 8 Experimental Results The Benchmarks Our benchmarks are mainly taken from \n[2, 7, 9] with a couple of additional programs. The first four programs are cryptarithmetic puzzles with \ntwo versions for each problem. The two versions corre\u00adspond to different representations of the constraint \n(a natural and a carry representation) which lead to very different search spaces. SendMoryl is from \n[7] while Donald is from [2]. The programs have the property that backtracking undoes only constraints \nof the form s = Z), where s is a slack variable and b is a value. The next two programs, Investment and \nLaplace, are de\u00adterministic programs. The first program is taken from [2] while the second program is \nfrom [7]. Investment is a program to compute installments with strong re\u00adlationships between the same \nvalues. Laplace com\u00adputes an approximation method for Laplace s equation. Both programs manipulate large \ncoefficients and pro\u00adduce overflows with finite precision numbers. Note also that, although the programs \nare deterministic, they pro\u00adduce some choice points (which would lead to failure if tried). The last \nprograms illustrate backtracking over arbitrary constraints. Magic and Permutation solves two problems \nfrom combinatory theory [9]. Periodic is the problem described in Section 2. Square [2] is a very combinatorial \nproblem which amounts to placing squares, all of different sizes, in a rectangle such that no two squares \noverlap and no empty space is left. The only input to the program is the number of squares, i.e. the \nsizes of the squares and of the rectangle are left unspecified. We use various instances of this problem. \nThe Systems Algorithms Semantic and Trail are both WAM-based compilers using infinite precision integers \nto guarantee numerical stability. The solved form in the algorithms uses a linked list representation \nand the two systems (resp. 20,000 and 19,000 lines of C) only differ in the way backtracking is handled. \nMemory Space For each system, we measure the space requirement at the end of the computation and at each \nbacktracking. In the table, we report the space at the end of the computation and the maximum over all \nback\u00adtracking points. The space itself is divided into var\u00adiou~ categories, inclnding the integers, the \nrationals, the cells in the linked lists, and the data structures 357 nal Stz Backtrackln= Folncs Programs \n--TiiF---Ra-- 7Xll-7mis7 Ot a nt --TGr mm= T5Gl-Donald 8180 4144 10080 5414 27818 9180 4664 11712 6480 \n32028 Donaldl 9324 4824 10944 5238 30330 9356 4848 10992 5250 30446 SendMory 3540 1792 4056 3276 12664 \n3596 1840 4224 3302 12774 SendMoryl 6396 3240 8064 3546 21246 6428 3264 8112 3608 21042 Investment (200) \n50424 9576 19152 5612 84764 Laplace (12) 14704 7320 19560 1534 43118 Magic 4408 2232 3672 4156 14468 \n5076 2560 4608 5120 17004 Permut at Ion 7064 3544 8040 6460 25108 Periodic 2216 1168 2784 932 7100 Square \n9 (A) 13976 7056 18600 10360 49992 16476 8306 22536 10716 58032 Square9 (F) 11344 5744 14664 6698 38450 \n15692 7928 21408 10162 54862 Square 14(F) 35084 17648 48216 24176 125124 45368 22808 63984 32222 125124 \nSquare 17 (F) 64788 32520 91296 41072 229676 73752 37000 105048 56880 272642 1 rable 1: Space Requirement \nof Algorithm Semantic in Bytes Ga-lz q Programs ----- m Rat Cell ---ma nimsr ------m -T% Tot al Donald \n11296 3528 10976 31096 56896 16764 4184 13792 77680 Donaldl 18496 6256 20320 40948 86020 18496 6352 20800 \n40964 86028 SendMory 7036 1776 5344 20240 34396 7036 1832 5600 20256 34412 SendMoryl 7120 2480 7712 21108 \n38420 7120 2560 8288 21124 38436 Investment (200) 55992 9568 25504 43116 134180 Laplace (12) 19784 7240 \n25760 29820 82604 Magic 13008 2056 4192 35900 54844 11788 2408 5600 37528 58288 Permut atlon 18044 3896 \n12160 57500 92672 Periodic 3296 1072 3360 10136 18232 Square 9(A) 35504 7256 22400 112348 177508 45768 \n9056 28840 125272 207712 Square 9 (F) 32388 6696 20440 97952 157476 41752 8560 27188 120316 194368 Square \n14(F) 121792 20440 75456 364404 582092 143440 24096 90400 386408 639752 Square 17(F) 208076 33112 108584 \n620860 970632 249560 38656 128268 700104 1106920 Table 2: Space Requirement of Algorithm Trail in Bytes \nnal S te B acl ,ackir Points Programs Int Tm Cell Other Tot al Int TGr Cell Other Tot al Donald 0.72 \n117 6-m-017 049 055 1.11 0.85 014 041 Donaldl 0.50 0.77 0.54 0.13 0.35 051 0.76 0.53 013 035 SendMory \n050 1.01 0.76 0.16 037 051 1.00 0.75 0.16 037 SendMoryl 090 1.31 105 0.17 0.55 0.90 1,28 0.98 017 056 \nInvestment (200) 0.90 1.00 0.75 013 0.63 Laplace (12) 0.74 101 0.76 005 052 Periodic 0.67 109 083 0.09 \n0.39 Magic 0.39 1.09 0.88 0.11 0.26 0.43 1.06 0.82 0413 0,29 Permut at Ion 0.39 091 0.66 0.11 027 Square \n9 (A) 039 0.97 0.83 009 028 0,36 0.92 0.78 0.09 0.28 Square 9 (F) 0.35 0.86 0.72 0.07 0.24 038 093 0.79 \n008 0.28 Square 14 (F) 029 0.86 064 0.07 0.21 0.32 0.95 0.71 0.08 0.20 Square 17 (F) 0.31 0.98 0.84 007 \n0.24 030 0.96 0.82 008 0.25 Table 3: Space Requirement: Ratio Sement it/Trail 358 needed to support \nnondeterminism. Tables 1 and 2 report the results for algorithms Semantic and Trail; Table 3 deDicts \nthe ratios between the ahzorithms. The experiment al results indicate that Semantic uses in the average \na third of the space used by Trail both at the end of the computation and over the backtrack\u00ading points. \nThe space requirement for Square 14 is divided by 5 and substantial improvements also occur for deterministic \nprograms, since Semantic requires half the space of Trail in Laplace, which creates choice points not \nleading to any solution. In general, the space improvement is higher for programs which add gen\u00aderal \nconstraints nondeterministically (about a quarter of the space). It is also interesting to identify where \nthe space goes. In the average, Semantic produces about a 55% reduction on the integers, a 25~0 reduction \non the cells. and a 90% reduction on the additional data structures, indicating that the trail and the \nintegers that need to be preserved are mainly responsible for the space difference. Table 4 presents \nthe theoretical minimum space for each benchmarks, i.e. the space needed by the solved form, and compares \nthe space consumption of Semantic and Trail with the theoretical minimum at backtracking points. It appears \nthat, in the aver\u00adage, Sement ic requires about twice the theoretical min\u00adimum, while Trail requires \nabout 6.5 times the mini\u00admum space. The additional space is taken mainly by additional data structures \nin both cases. Note also the excellent behaviour of Semantic on deterministic pro\u00adgrams for ,which it \nrequires negligible overhead, contrary to Trail. Finally, Table 5 depicts the results where the rationak \nare imdernented usiruz finite-mecision num\u00adbers. Not all pro~rams can be r&#38; with ~his restriction. \nThe overall average is even more impressive than for finite precision numbers, since Semantic produces \nre\u00adductions of about 70%. Computation Time Semantic backtracking trades mem\u00adory for time and we now quantify \nexperimentally the loss in computation time of Sement ic compared to Trail. The results are reported \nin Table 6. They indicate that Trail is 20% faster than Semantic in the average. In the worst case (i.e. \nSquare 17), Trail is 37~o faster while, in the best case (i.e. Magic), Semantic is 1.20 times faster \nthan Trail. This last case is mainly due to the fact that little undoing is performed during backtrack\u00ading \nand that the system is extremely sparse. Hence, the time overhead of Trail becomes significant. For fi\u00adr,ite \nprecision, the difference between both algorithms is even lower wit h an average reduction of 15~o for \nTrail. 9 Conclusion In traditional CLP implementations, backtracking is per\u00adformed by trailing all modifications \nto the solved form and restoring them at backtracking time. Although sim\u00adple and efficient, this scheme \nis potentially expensive in memory, since the entire solved form may need to be trailed between two choice \npoints. In this paper, we proposed a fundamentally different backtracking scheme for CLP (!)? L,n). The \nnew scheme, called semantic back\u00ad tracking, avoids trailing and exploits the semantics of the constraints \nto come back to a previous state. The scheme has been analysed both theoretically and ex\u00adperiment ally. \nOn the theoretical side, semantic back\u00adtracking produces an order of magnitude reduction in memory space, \nmaking the space requirement for num\u00adbers independent from the number of choice points. The cost for \nthis improvement is a higher backtracking time, since backtracking now requires solving a set of linear \nequations. The experimental results show that semantic backtracking requires, in the average, about 1/3 \nof the space of a traditional trailing implementation, and 1/5 on some benchmarks. The overhead in time \nis very rea\u00adsonable, since trailing produces about a 2070 reduction in computation time in the average. \nMoreover, on deter\u00administic programs (possibly leaving some choice points leading to failures), semantic \nbacktracking is superior to trailing, since it exhibits little time and space overhead to support nondeterminism. \nRferenxs [1] A. Aggoun and N. Beldiceanu. An Overview of the CHIP compiler. In Eighth International Conference \non Logic Programming (ICLP-91), Paris (France), June 1991. [2] A. Colmerauer. An Introduction to Prolog \nIII. CACM, 28(4):412-418, 1990. [3] G.B. Dantzig. Linear Programming and Exten\u00adsions. Princeton University \nPress, 1963. [4] M. Dincbas, P. Van Hentenryck, H. Simonis, ~. Aggoun, T. Graf, and F. Berthier. The \nConstraint Logic Programming Language CHIP. In FGCS-88, Tokyo, Japan, Dec. 1988. [5] J. Jaffar and J-L. \nLassez. Constraint Logic Pro\u00adgramming. In POPL-87, Munich, Jan. 1987. [6] J. Jaffar, S. Michaylov, P. \nStuckey, and R. Yap. An Abstract Machine for CLP(!R). In PLDI 92, San Francisco, CA, June 1992. [7] J. \nJaffar, S. Michaylov, P.J. Stuckey, and R. Yap. The CLP(!R) Language and System. ACM Transac\u00adtions on \nProgramming Languages, 14(3):339 3951 1992. [8] P. Stuckey. Incremental Linear Constraint Solving and \nDetection of Implicit Equalities. ORSA Jour\u00adnal of Computing, 3:269 274, 1991. [9] P. Van Hentenryck. \nConstraint Satisfaction in Logic Programming. The MIT Press, 1989. [10] P. Van Hentenryck and T. Graf. \nStandard Forms for Rational Linear Arithmetics in Constraint Logic Programming. Annals of Mathematics \nand Artifi\u00adcial Intelligence, 5(2-4), 1992. [11] D.H.D Warren. An Abstract Prolog Instruction Set. Technical \nReport 309, SRI, October 1983. 360 Minimum Semantic 1 rail Programs I nt Rat Cell Total Int Rat Cell \nTot al Int Rat Cell Tot al Donald 4788 2464 5160 12412 1.92 189 227 2.58 3.50 170 2.67 626 Donaldl 8688 \n4584 10440 23680 1.08 1.06 105 1.29 2.13 1.39 199 3.63 SendMOry 2800 1480 3288 7568 128 124 1.28 1.69 \n2.51 124 170 4.55 SendMoryl 3788 1992 4512 10292 1.70 164 180 3.05 1.88 129 1.84 373 Investment (200) \n50408 9568 19128 79104 1.00 1.00 100 107 1.11 100 1.33 170 Laplace (12) 14544 7240 19320 41104 101 1.01 \n1.01 1.05 1.36 100 133 2.01 Magic 3748 1912 2616 8272 1.35 134 176 2.06 315 1.126 2.14 705 Permutation \n5632 2904 6360 14896 1.25 1,22 1.26 1.69 320 134 1.91 622 Periodic 1612 864 1896 4372 1.37 1.35 147 162 \n2.04 1.24 177 4.17 Square 9 (A) 10336 5248 13416 29000 159 1.58 168 2.00 443 173 2.15 7.16 Square 9 (F) \n9432 4792 12072 26296 166 165 1.77 2,09 4.43 179 2.25 7,39 Square 14 (F) 25044 12640 33504 71188 1.81 \n180 1.91 176 5.73 1.91 270 8.99 Square 17 (F) 38744 19496 52536 110776 1.90 190 200 246 644 198 2.44 \n999 Table 4: Space Requirement: Ratios over Strict Minimum Space Final State Backtracking Points Programs \nSemantic Trail rat 10 Semantic Trail Semantic/Tk all Donald 19638 45600 0,43 22856 60916 038 SendMory \n9124 27360 033 9222 27376 034 SendMoryl 14850 31300 0.47 14980 31316 0.48 Perlodlc 4884 14976 0.33 Magic \n10060 43012 0,23 12024 45892 0.26 Permut at ion 18044 73120 025 Square 9 (A) 36016 142004 025 41556 161944 \n026 Square 9 (F) 27106 125088 022 39170 152804 0.26 Square 14 (F) 90040 460300 0,20 119006 496312 0.24 \nSquare 17 (F) 164888 762556 0,22 198890 857360 0.23 Table 5: Space Requirement on Finite Precision Numbers \nInf lte Preclsic te Precision --lET Semantic rat 10 --mm Semant Ic rat 10 backtracks 1350 1570 086 970 \n1030 0.94 772 10730 12220 0,88 3625 SendMOry 115250 120280 096 74940 77320 097 51618 SendMoryl 25o 250 \n1.00 210 160 131 161 Investment (200) 16690 17040 098 0 Laplace (12) 490 470 1.04 0 Periodic 310 290 \n107 220 180 1.22 107 Magic 77280 64410 120 37850 41910 0,90 63983 Permut at ion 16280 23030 0.71 9710 \n11630 0.83 8751 Square 9 (A) 117050 180600 0.65 75590 97850 077 14948 Square 9 (F) 11050 16330 0,68 7150 \n9080 079 1511 Square 14 (F) 139030 216060 064 83420 120520 0.69 8813 Square 17 F 363340 576350 0.63 184950 \n279360 0.66 12505 ttE5f-- L Table 6: Computation Time in Milliseconds: Comparison of Trail and Semantic \n359  \n\t\t\t", "proc_id": "178243", "abstract": "<p>Constraint logic programming (CLP) is a generalization of logicprogramming where unification is replaced by constraint solving as thebasic operation of the language. The combination of constraint solvingand nondeterminism (approximated by backtracking) makes these languagesappealing for a variety of combinatorial search problems. Existing CLPlanguages support backtracking by generalizing traditional Prologimplementations: modifications to the constraint system are trailed andrestored on backtracking. Although simple and efficient, trailing may bevery demanding in memory space, since the constraint system maypotentially be saved at each choice point. This paper proposes afundamentally new implementation scheme for backtracking inCLP languages over linear  (rational or real)  arithmetic. The newscheme, called <?Pub Fmt italic>semantic backtracking<?Pub Fmt /italic>,does not use trailing but rather exploits the semantics of the constraints to undo the effect of newly added constraints. Semantic backtracking reduces the space complexity by an order of magnitude compared to implementations based on trailing and makes space complexity essentially independent of the number of choice points. In addition, semantic backtracking introduces negligible space and time overhead on deterministic programs. The price for this improvement is an increase in backtracking time, although constraint-solving time may actually decrease. The scheme has been implemented as part of a complete CLPsystem  CLP(<inline-equation><f><ge>R</ge></f></inline-equation><subscrpt><italic>Lin</italic></subscrpt>) and compared analytically and experimentally withan optimized trailing implementation. Experimental results indicate that semantic backtracking produces significant reduction in memory space, while keeping the time overhead reasonably small.</p>", "authors": [{"name": "Pascal Van Hentenryck", "author_profile_id": "81100594830", "affiliation": "", "person_id": "PP14205263", "email_address": "", "orcid_id": ""}, {"name": "Viswanath Ramachandran", "author_profile_id": "81100155124", "affiliation": "", "person_id": "PP14064093", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/178243.178488", "year": "1994", "article_id": "178488", "conference": "PLDI", "title": "Backtracking without trailing in CLP (R<sub><i>Lin</i></sub>)", "url": "http://dl.acm.org/citation.cfm?id=178488"}