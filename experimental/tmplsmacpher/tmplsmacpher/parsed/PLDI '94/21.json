{"article_publication_date": "06-01-1994", "fulltext": "\n Zero-cost Range Splitting Steven M. Kurlander Charles N. Fischer* University of Wisconsin Madisont Abstract \nThis paper presents a new optimization technique that uses empty delay slots to improve code scheduling. \nWe are able to split live ranges for free, by inserting spill code into empty delay slots. Splitting \na live range can reduce interferences with other live ranges and can sometimes free registers. Live ranges \nno longer inter\u00ad fering with the split live range can sometimes make use of the extra register. Our algorithm, \nas a final pass over the code, exploits empty delay slots that would remain unused if spill code was \nnot inserted. This paper proposes a vari\u00ad ety of optimizations that use the extra registers gener\u00ad ated \nfrom live range splitting, including coalescing live ranges and improving code scheduling. We present \nan algorithm for improving code scheduling and present implementation results. 1 Introduction Compiler \nwriters use heuristics for register allocation and instruction scheduling, as both are NP-Complete [Set75] \n[HG82] [PS90]. Instruction scheduling tries to minimize the number of unfilled delay slots, cy\u00ad cles \nfollowing an instruction in which its result is un\u00ad available, by filling these slots with useful instructions. \nRegister allocation policies almost never exploit delay slots even though register allocation and instruction \nscheduling are highly interdependent. Register allo\u00ad cation and instruction scheduling create a well-known \n*This work was supported by NSF grant CCR-9122267. tAuthor~5ad(jre~s:Dept. of Computer Sciences, 1210 \nW. Dayton St., Madison, WI 53706. Email: {smk,fischer}Qcs.wise.edu Permission to co y without fee all \nor patt of this material is granted prowd Jthat the copies are not made or distributed for direct commercial \nadvantaqe, the ACM copyright notice and the title of the publication and Its date appear, and notice \nis given that copying is by permission of the Association of Computing Machinery. To copy otherwise, \nor to republish, requires a fee and/or specific permission. SIGPLAN 94-6/94 Orlando, Florida USA Q 1994 \nACM 0-89791 -662-x19410006..$3.5O phase-ordering problem. Scheduling code before regis\u00adter allocation \nmay increase register usage and that may force costly register spilling. By introducing inessential dependencies \nbetween instructions, performing register assignment before code scheduling may limit the sched\u00aduler \ns ability to rearrange code to fill empty delay slots. This paper presents a new technique to improve \ncode quality by using empty delay slots to improve code scheduling. Our technique tries to split a live \nrange into smaller disjoint live ranges, placing the spill code into unfilled delay slots (making the \nspill free ). Live ranges that no longer interfere with the split live range can sometimes use the register \nassigned to the split live range. In Figure 1, we split live range A (shown on the left-hand side), into \nlive ranges A and A (shown on the right-hand side). Assuming A is unchanged (a never-killed value [CAC+81] \n), we simply reload A in the delay slot shown. Live range B can now use the register assigned to A, as \nB s live range does not inter\u00adsect with A or A s live range. The split live range is no more costly than \nthe original (in Section 6 we con\u00adsider the effects on the cache of splitting live ranges), but usually \ninduces fewer interferences. This paper studies optimizations that make use of registers made available \nby our zero-cost live range splitting. We discuss an implementation of one of these optimizations and \npresent results. 2 Related Work Splitting a live range into smaller pieces allows for fewer interferences, \nbut leads to more loads and stores. A longer live range conflicts with more live ranges than does a shorter \none but costs less, as there are fewer loads and stores. Chaitin [Cha82] assumes all values reside in \nvirtual registers. Chaitin then spills virtual registers until there are an equal number of virtual and \nreal registers. Chaitin-style spilling creates very short live ranges, allowing for fewer conflicts with \nother live ranges. Chow and Hennessy [CH90], in contrast, as\u00adsume that all variables reside entirely \nin memory. If r t li $f4, A ~, ~ 11$f4r A add $f8, $f8, $f4 add $f8, $f8, $f4 Ie load $f8, B load $f4, \nB BB L add $fl O, $fl O, $f8 add $fl O, $fl O, $f4 A e @ <delay slot> < li $f4, A > I * e L add $fl \nO, $fl O, $f4 add $fl O, $fl O, $f4 Figure 1: Splitting live range A, by placing spill code in a delay \nslot, allows live range B to use the register assigned to A. a live range cannot be mapped to a single \nregister, then loads and stores are added to generate smaller live ranges. This process can lead to fewer \nloads and stores than in Chaitin s approach as the live ranges can be longer. Neither of these algorithms \nconsider delay slots, however. Splitting a long live range using empty delay slots allows for the creation \nof shorter live ranges, (which conflict with fewer live ranges), but at the same cost as a long live \nrange, since the spilling is free. Pinter [Pin93] proposes a parallel interference graph which includes \nthe edges of a live range interference graph and a false dependence graph. False dependen\u00adcies include \nanti and output-dependencies. A coloring of this graph produces code with no spills and no false register \ndependencies, which may limit code schedul\u00ad ing. However, given an ters to color the graph, cies will \nbe introduced. fewer empty delay slots interference graph, pendencies during ter allocator uses a live \nrange results essary extra loads Briggs, Cooper, tag with individual The tag indicates as the insufficient \nnumber of regis\u00adspills and/or false dependen-The generated code can have than a simple coloring of an \nalgorithm considers false de\u00ad register allocation. Since the regis\u00adChaitin s coloring algorithm, spilling \nin very short live ranges and unnec\u00ad and stores. and Torczon [BCT92] associate a values in a procedure \ns SSA graph. how a value should be spilled, as some values can be recomputed rather than saved in a \ntemporary. After propagating the tags throughout a procedure, live ranges can be broken into smaller \nlive ranges whose values have identical tags. Their algo\u00adrithm can use fewer instructions to spill a \nlive range than in Chaitin s approach. Exploiting extra registers The more register candidates a program \nhas, the greater is the potential to take advantage of ex\u00ad tra registers generated by our live range \nsplitting. Loop unrolling, software pipelining, scalar replacement [CCK90], code inlining, and interprocedural \nregister al\u00adlocation [Wa186] [Cho88] [S090], significantly increase the demand for registers. A greater \ncompetition for registers can lead to an increase in register spilling and false register dependencies \nbetween instructions. The following is a (non-exhaustive) list of optimiza\u00adtion that are possible as \npart of a final pass over the code. These optimizations are possible because of fewer interferences after \nlive range splitting. 1. Coalesce live ranges, removing loads and stores, by assigning a freed register \nto two ranges of the same variable. 2. Remove false register dependencies moving instructions into empty \ndelay  3. Avoid breaking a live range around signing a freed callee\u00ad saved register range. 4. Applying \ninterprocedural register disjoint live (that prevent slots). a call by as\u00adto the live allocation, a freed \nregister around a call can allow the called procedure and its descendants in the call-graph (assuming \nthe current procedure dominates these procedures in the call-graph) to make use of the register [S090] \nIn this paper we will use live range move false register dependencies. 4 Live Range Splitting We aim \nfor Chaitin s style of live range is, we try to insert a load for each use and a store after each definition. \nSince be close to the uses and stores close to this will maximize the fraction of code splitting to re\u00ad \nsplitting, that of a live range the loads can the definitions, where registers are freed. As the loads \nand stores are inserted into otherwise empty delay slots, the splitting is ideal tiny live ranges having \nfew interferences. We assume the scheduler has inserted nop instruc\u00adtions to represent empty delay slots. \nThese nop in\u00adstructions identify where live range splitting might re\u00adplace empty delay slots with loads \nand stores. After live range splitting, a pass over the code can remove those remaining nop instructions \nthat are unnecessary for the correct execution of the code. Our algorithm calls InsertLoadsStores to \nsplit a live range 1, and then calls Mark WhereRegStillAllocated to determine where, after splitting \n1, a register is freed. 4.1 Inserting Loads and Stores Routine InsertLoadsStores splits live range 1. \nIf 1 is a never-killed value [CAC+81], we can avoid spilling to a temporary. We present the general case \nin which both loads and stores are needed to split 1. Instructions storing the value of 1into a temporary \ntl are added after each definition of 1, and load instructions reloading the value of 1 from tl are added \nbefore each use of 1 (but not close enough to force an empty delay slot between the two instructions). \nInsertLoadsStores first inserts the load instructions. Delay slots can appear anywhere within a live \nrange. The algorithm may not be able to cover all definitions and uses with loads and stores. In this \ncase, after split\u00adting the live range, the register assigned to 1 will be live throughout more of the \nlive range than using Chaitin s register allocator. To find a delay slot in which a load of tlcan be \ninserted, InsertLoadsStores start its search at each use of 1 and searches backwards using a reverse \ndepth-first search across basic blocks. InsertLoadsStores does not search a basic block if it has previously \nsearched it for 1. We stop searching within a block ifi an empty delay slot is found, where we will \ninsert the load of tl,or  a definition of 1 is found (in this case the value will be register resident \nfrom the definition to the use of 1), or  a use of 1 is found (in this case, the value of t will be \nregister resident along a path from the use of 1 we have just reached to the use of 1 where our search \nbegan.)  Should a delay slot be found, a load of tlis inserted. Ideally, we will insert a sufficient \nnumber of load in\u00adstructions so that there is a load along each path from a definition of 1 to a use \nof 1. Otherwise, there will be a path between a definition of 1 to a use of 1 where l s value will remain \nregister resident. This simply leads to more interferences than we might wish. Figure 2(a) shows a control-flow \ngraph, in which the live range 1 includes the entire loop. A load tlis in\u00adserted into the bottom empty \ndelay slot, as shown in (b). As inserting instructions into empty delay slots is free, there is no penalty \nfor inserting loads and stores into an empty delay slot even in a loop. Next, store instructions are \ninserted. The process of inserting stores is similar to that of inserting loads ex\u00adcept the traversal \nstarts at each definition, the traver\u00adsal is downwards through the live range (visiting those blocks \nsuccessors in which 1 is live on entrance), and store instructions can traverse past uses of 1. A block \nis not entered if it has previously been visited to insert a store. The conditions in which we stop searching \nin a block are: e an empty delay slot is found, in which case a store of tlis inserted, or the end of \nthe current live range is reached. If we pass a load of tl,which was inserted, we change it back to a \nnop, as there exists a path from a definition of 1to the load of tlin which the value of 1 was not stored \ninto tt.In Figure 3(a), a store is inserted into the remaining delay slot of Figure 2(b). Replacing a \nload with a nop if the store traverses past it ensures the remaining load instructions will find the \ncorrect value in t~. During register allocation we can determine in which successor blocks 1 is live. \nHowever, since instruction scheduling can affect which instruction ends a live range in a basic block, \nlive ranges are regenerated be\u00adtween instruction scheduling and live range splitting, which is neither \ndifficult nor costly.  4.2 Mark Where Register Remains Al\u00adlocated After spill code is inserted, we call \nthe routine Mark WhereRegStillAllocated to mark where the value of 1 still resides in a register. We \ncan simply mark the exits of basic blocks, since we can identify if 1 resides in a register when traversing \nup a block if we know whether it is live on exit to the block. Beginning at each use of 1 (including \nthe stores of tl inserted above), the control-flow graph is traversed upwards until: a definition of \n1, which begins former live range 1, is found, or . a load of tl is found, as a live range begins at \nthe load, or a store of tl or use of 1 is found, as the routine begins its traversal from these instructions. \n def 1 ,// ~ ,,m< < delay slot> delay slot> / / < delay slot> use 1 k; \\ \\ ~ (a) Figure Example control-flow \ngraph showing live The gray region in Figure 3(b) is where the value of 1 is no longer register-resident, \nso the register assigned to 1 is freed there. The darker region is where the value of 1 remains in a \nregister. We can now determine wherein the former live range 1 a register is freed, by starting before \neach inserted load tl, traversing up the control-flow graph, and stopping along a path if the value of \n1 is marked register resident. Breaking live ranges and marking where a variable is still register resident \nis linear in the number of instruc\u00adtions IV in a program. Given R registers, there can be at most R live \nranges at any given instruction in the code. So, over all live ranges, this algorithm does not traverse \nmore than 0(.iV) instructions, as R is a constant. 4.3 Splitting for the MIPS R2000 Our live range splitting \nalgorithm was implemented on a MIPS R2000 processor. A couple of minor changes to our uve range spnttmg \nalgornnm were maae to nanale the MIPS R2000 instruction set. Loading (and storing) a double-precision \nfloating\u00adpoint value requires a pair of load (and store) in\u00adstructions on the MIPS R2000. When splitting \na live range, our algorithm always inserts each instruction of a pair into the same basic block (though \nnot necessarily in contiguous delay slots). This allows us to avoid revisiting a block to add two loads \n(or stores) if only one was inserted pre\u00adviously.  Generating addresses can require an extra instruc\u00adtion \nto load the upper bits of the address. If we  (b) range 1. In (b), load tl is inserted into a delay \nslot . split a live range whose definition can generate one of these addresses, an additional delay slot \nwill be needed if we choose to recompute the value rather than spilling its value to a temporary. In \nthis case, we choose to spill the value.  4.4 Effect on the Code We gathered statistics to better understand \nthe impact of our live range splitting algorithm on the code. We chose to split a live range only if \nall registers are allo\u00adcated across the live range and the live range does not form spill code, since \nfreeing registers in regions where all registers are in use is often beneficial.. As shown in Figure \n4, live range splitting can sub\u00adstantially decrease the size of live ranges. Column two shows the number \nof live ranges split for each benchmark. The benchmarks shown are floating-point, which we have observed \nto have a large number of register candidates and a large number of empty de\u00adlay slots. The first two \nbenchmarks are SPEC bench\u00admarks and the rest have been optimized using scalar replacement [C CK90]. The \nthird and fourth columns represent the average length of these live ranges be\u00adfore they were split and \nthe average decrease in size of these live ranges afterwards. Splitting can significantly decrease the \nspan of instructions where registers are allocated. The remaining columns present the the number of available \nfloating-point and integer registers per in\u00adstruction before and after live range splitting. The register \ncounts are averaged only over those live ranges that are candidates for splitting. We do not count reg\u00adisters \nthat will be allocated to temporary values, def 1 ~, Figure 3: (a) shows the insertion of store tJ into \nthe remaining delay slot. (b) shows two regions. The light colored region is where the value of 1 is \nno longer register resident, whereas the dark region is where the value of 1 remains register resident. \nbenchmark splat avg. length decrease in size avg. available int registers avg. available fp registers \nbefore splitting after sphtttng before splitting after splitting doduc 708 156.8 46.2% 3.7 4.5 (+0.8) \n1.2 4.1 (+2.9) fpppp 369 414.7 73.1% 3.2 4.8 (+1.6) 1.3 6.0 (+4.7) onedim 271 320.3 31!5% 2.8 4.5 (+1.7) \n1.0 2.6 (+1.6) shal 28 177.6 34.3% 1.3 1.3 (+0.0) 0.8 2.8 (+2.0) simple 261 289.4 64.7% 3.8 5.2 (+1.4) \n1.4 4.5 (+3.1) Figure 4: Effect of Splitting Live Ranges 5 Scheduling the Code table information that \nhelps us to distinguish among variable and determine which are aliased. Register allocators often generate \nfalse register depen\u00addencies, which can prevent apostpass code scheduler 5.1 Algorithm from filling \nsome delay slots. To try to improve the quality of code that was generated by a postpass sched-The driver \nroutine used to split live ranges and sched\u00aduler, we chose to remove false register dependencies ule \nload instructions is shown in Figure 5. We call this (optimization 2 in Section 3) by assigning freed \nreg-routine for each procedure (all analysis is global and isters to instructions that can fill empty \ndelay slots. intraprocedural). Both routines InsertLoadsStores and As we observed the code generated \nfor floating-point Mark WhereRegStillAllocated are as described in Sec\u00adbenchmarks tended to have more \nunfilled delay slots tions 4.1 and 4.2, respectively. and more register candidates, we were most interested \nin these benchmarks. 5.1.1 Selecting Live Ranges To generate code, we used the lcc compiler [FH91], \nwith a coloring allocator [Cha82], followed by the CSP The live ranges are ordered in increasing value \nbased phase of Goodman and Hsu s scheduler [GH88], as the on the function -. This function is adapted \nfrom back end. As noted in Section 4, the scheduler in-graph coloring [Cha82]. We refer to cost as the \nnumber cludes nop instructions, indicating where empty delay of instructions needed to split a live range \ninto trivial slots can be filled by instructions. Our algorithm is a single instruction ranges. A larger \nvalue of cost sug\u00adfinal pass over the code, intended to glean any remain-gests more empty delay slots \nwill be needed to insert ing opportunities for optimizations. We utilize symbol spill code. Unlike Chaitin \nwe do not include instruc\u00ad procedure Driver Routine(P) \\\\ P is the current procedure L = live ranges \nof P in increasing value of * for (Z = 1 to I L 1) do \\\\ start with the live range having the least - \n1 = L[i] if (Split(l)) then \\\\ do not split live ranges scheduled by routine ScheduleCode InsertLoadsStores(l); \nMarkWhereRegStillAllocated(l ); success = ScheduleCode(l); if (not success) RemoveLoadsStores( l); \\\\ \nmaintain a list of inserted loads and stores end if end if end for end procedure Figure 5: Driver routine \nfor splitting live ranges and scheduling code. tion frequency to compute cost, since executing a load \nor store in a delay slot is essentially free. The value of degree for a live range is the number of distinct \nlive ranges that conflict with it before live range splitting begins. Unlike in [Cha82], the value of \na live range s degree does not change to avoid recomputing = and reordering the live ranges after splitting \na live range. Splitting a live range with a large degree potentially makes the register available to \nmore live ranges. A live range with low cost and high degree is an ideal candi\u00addate for splitting. When \nsplitting a live range, it is unsafe to avoid store instructions if a live range 1 is defined by a load \nA, since the scheduler could move a store A within 1. We only split those live ranges within which all \nreg\u00adisters are allocated and which do not form spill code. Live ranges whose definitions are scheduled \nin this fi\u00adnal pass are also not split. With this last restriction, we can avoid visiting a particular \ninstruction during the splitting process more than a constant number of times over the entire algorithm. \nA call to Spht in the driver routine returns true if a live range should be split. 5.1.2 Removing False \nDependencies After splitting a live range, routine Schedule Code uses the freed register to move the \ndefinitions of live ranges that are enclosed entirely within a basic block into empty delay slots. Assigning \na new register to an in\u00adstruction can allow the instruction to move past in\u00adstructions with which it \nhad a false dependence. For example, in the left-hand column of Figure 6, the load of B at line 3 has \na false dependence with the add in\u00adstruction at line 2. By assigning a freed register $f4 to the load \nof B, we can move it into the empty delay slot at line 1, as shown in the right-hand column. We prefer \nassigning freed registers to smaller live ranges (those that fit within a basic block) to allow for many \nlive ranges to be assigned that register. Moving a floating-point operation into an empty de\u00adlay slot \nmay not necessarily be beneficial, as an inter\u00adlock between it and a nearby instruction can occur. To \ncorrect these decisions, after splitting live ranges and removing false dependencies, the CSP phase of \nGood\u00adman and Hsu s scheduler is rerun.  5.1.3 Scheduling Process Routine ScheduleCode traverses up \nthrough basic blocks, beginning at load instructions as described in Section 4.2. When reaching an instruction \nthat ends a live range 1, we check if the live range is contained en\u00adtirely within a basic block with \nthe definition preceding the use, that is, if the live range has a single definition d and d is in the \nsame basic block as the instruction ending the live range. If we find d is not in a delay slot, a copy \nof d is added to list ilist with a pointer from the real instruction to this copy. When d is reached \na copy of the instruction is moved from ilist and added to an array of lists indexed by register number. \nIf an instruction z is encountered that assigns or references the same register assigned to d, then moving \nd into an upcoming empty delay slot will move d past an instruction with which it has a false register \ndependence. Upon reaching an instruction with which d has a false register dependence, we move the copy \nof d from the array to list intop-or-ld, if the instruction is an integer operator or load, or to list \njloatop, if the in\u00adstruction is a floating-point operation. Empty delay slots are only filled with instructions \nfrom these two lists. We prefer to fill delay slots with instructions from intop-or-ld, since scheduling \ntwo floating-point opera\u00adtions near each other can cause a pipeline interlock. When an empty delay slot \nis found, we can moved into the slot and allocate it a freed register. As all other live (1) <delay \nslot> (2) add $f6, $f6, $f8 (3) load $f8, B (4)  add $flO, $flO, $f8 Figure 6: We can fill empty \ndelay slot in left-hand column ranges with instructions on a list will interfere with 1, these live ranges \ncannot deallocated the current freed register, and so all the lists are set to null. Our live range splitting \nalgorithm relies on knowing the instructions that end a live range. Definition d, which is moved into \na delay slot, may reference live range 1 and represent the end of that live range in the current block. \nAfter moving d, it may no longer end live range 1 . When sliding dinto the delay slot from its previous \nposition, wecheck if we pass another instruction that also references 1 . The first instruction that \nis passed and references 1 now ends live range 1 in the current block. When encountering an instruction \ni with which d has a true dependence, the copy of d is removed from its current list. We stop traversing \na block when we reach the beginning or we reach an instruction where the value of 1 is register resident. \nShould we be unable to move an instruction into a delay slot (success = jblse in the driver routine), \nthe driver routine calls RemoveLoadsStores to remove the loads and stores that were inserted by routine \nInsertLoadsStores. As we can keep a list of the in\u00adserted loads and stores, this does not lead to general \nbacktracking.  5.2 Complexity Scheduling code within a basic block is O(N), where N is the number of \ninstructions. Checking if a live range begins with an instruction that is enclosed within the current \nblock can be done in constant time. Because of the linear nature of a basic block, the number of true, \nanti and output-dependencies between instructions in the same basic block is linear in the number of \ninstruc\u00adtions in the block. Removing an instruction from any of the lists if the instruction has a true \ndependence with the current instruction can be done in linear time over the entire basic block. Code \nscheduling does not affect the O(N) complexity of live range splitting, since an instruction can only \nbe moved once. Thus, an instruction can be part of no more than 2R live ranges that are split. As there \nare N instructions in the program, the complexity is still O(N). < load $f4, B > add $.f6, $f6, $f8 add \n$flO, $flO, $f4 by assigning freed register ($~4) to the load of B.  5.3 Improvement to Splitting and \nScheduling Live Ranges  As will be mentioned in Section 6, inserting loads and stores is not always \nabsolutely free. Therefore, after we finish splitting and scheduling live ranges in a procedure, we maybe \nable to remove some of the spill code inserted into delay slots by live range splitting. Simple dataflow \nanalysis can be used to remove them. 6 Impact on the cache Cache performance benefits from temporal locality \n(a location will soon be referenced again) and spatial lo\u00adcality (if a location is referenced, nearby \nlocations will soon be referenced) [HP90]. Entries in the current ac\u00adtivation record are likely to exhibit \ntemporal locality, as locals and temporaries will be rereferenced in the current activation record and \nexhibit spatial locality, as the activation record is contiguous. Optimizations (such as common subexpression \nelimi\u00adnation) generally allocate temporaries if it can improve the code. We expect adding temporaries \nto the acti\u00advation record for code improving transformations will minimally impact cache performance. \nWe can be aggressive in limiting the number of tem\u00adporaries generated from splitting live ranges. If \na set of live ranges did not interfere before being split, then they will not interfere after being split. \nWe can spill them into the same temporary location. 7 Results Our live range splitting algorithm and \nscheduler were run on a MIPS R2000 processor with the benchmarks listed in Figure 7. The benchmarks listed \nare floating\u00adpoint intensive. We found floating-point benchmarks tended to have more delay slots and \nregister candidates. The first four listed in Figure 7 are SPEC benchmarks. The scalar replacement optimization \n[CCK90] has been run on the latter three benchmarks. As our algorithm is a final pass over the code, \nthese speedups are pure profit. Column speedups gives the speedup from our live range splitting algorithm \nand scheduler. Column wzlh\u00adout round-robin assumes a round-robin register as\u00adsignment is not included \nas part of code generation, whereas with round-~o bin assumes it is included. A round-robin register \nassignment avoids some false reg\u00adist er dependencies between neighboring instructions. The algorithm \nsequentially visits instructions in a ba\u00adsic block, treating the register set as a circular list. The \nalgorithm assigns the next valid register in the cycle, such that it has not been allocated to any live \nrange that conflicts with the one defined by the current instruction. Round-robin assignment has significantly \nimproved the execution time of benchmark fpppp. The speedups for the benchmarks that have been opti\u00admized \nusing scalar replacement tend to show the largest speedups. benchmark speedups split live ranges compile \ntime without round-robin with round-robin dnasa7 0.3% 0.2% 5.1% 5.0s doduc 3.8% 2.2% 13.9% 17.6s fpppp \n35.2% 4.1% 16.2% 23.1s tomcatv 3.0% 1.8% 40.0% 2.4s onedim 5.5% 3.5% 7.9% 11.0s shal 5.2% 3.1% 21.4% \n2.7s simple 7.4% 5.0% 7.3% 12.1s Figure 7: Speedups from the scheduler. We allowed only those live ranges \nto be split in which all registers were allocated and which do not form spill code. Column split live \nranges gives the percentage of live ranges split from among this set. In the majority of the cases, our \nscheduler uses only a small fraction of these live ranges. Column time gives the compile time in seconds \nfor running this algorithm. The algorithm is not too ex\u00adpensive, running under 30 seconds in the examples \nabove. Overall, we feel that our live range splitting algorithm and scheduler is worthwhile. ~ture Work \nUsing other optimizations with our live range split\u00adting algorithm is worthy of investigation. Handling \nlive range coalescing as a final pass over the code might be done as follows. Live ranges can be represented \nby the basic blocks that they enclose[LH86] [CH90]. If the ba\u00adsic blocks where a register is freed encloses \na live range that has been spilled during register allocation, the live range can sometimes be allocated \nthe freed register and the spill code removed. With additional analysis parts of the original live range \ncan be coalesced, allowing load instructions to be removed [KH93]. Intersecting sets of basic blocks \nin which different registers are freed can sometimes be treated as a single set by inserting register \nmove instructions into empty delay slots. We believe our live range splitting algorithm should be quite \neffective on superscalar processors, which is\u00ad sue multiple instructions per cycle. If a supers calar \nprocessor cannot find a sufficient number of instruc\u00adtions to issue in a cycle, it may be able to issue \na spill instruction. Integer benchmarks running on a proces\u00adsor issuing one instruction per cycle tend \nto have few empty delay slots, since most integer instructions exe\u00adcute in a single cycle. Running an \ninteger benchmark on a superscalar processor would generate more oppor\u00adtunities for splitting live ranges \nand using the freed registers to improve the code. 9 Conclusions We have presented a novel technique \nthat splits live ranges at zero-cost. Splitting a live range can free reg\u00adisters by reducing interferences \nwith other live ranges. In addition, we have listed optimizations that can ben\u00adefit from these free registers. \nWe implemented one opti\u00admization that improves code scheduling. Given the per\u00adformance benefit from this \noptimization, we feel that the other optimizations listed deserve investigation. 10 Acknowledgements \nWe would like to thank Steve Carr for supplying bench\u00admarks optimized with the scalar replacement transfor\u00admation \nand the anonymous referees for their very de\u00adtailed comments. References [BCT92] Preston Briggs, Keith \nD. Cooper, and Linda Torczon. Rematerialization. In Proceedings of the SIGPLAN 92 Conference on Pro\u00adgramming \nLanguage Design and Implemen\u00adtation, pages 311 321, June 1992. [CAC+81] [CCK90] [CH90] [Cha82] [Cho88] \n[FH91] [GH88] [HG82] [HP90] [KH93] Gregory J. Chaitin, Marc A. Auslander, Ashok K. Chandra, John Cocke, \nMartin E. Hopkins, and Peter W. Markstein. Regis\u00adter allocation via coloring. Computer Lan\u00adguages, pages \n47-57, 1981. David Callahan, Steve Carr, and Ken Kennedy. Improving register allocation for subscripted \nvariables. In Proceedings of the SIGPLAN 90 Conference on Program\u00adming Language Design and Implementa\u00adtion, \npages 53 64, June 1990. Fred C. Chow and John L. Hennessy. The priority-based coloring approach to register \nallocation. ACM Transactions on Program\u00adming Languages and Systems, 12(4):501\u00ad536, October 1990. Gregory \nJ. Chaitin. Register allocation and spilling via graph coloring. In Proceedings of the SIGPLAN 82 Symposium \non Compiler Construction, pages 98-105, June 1982. Fred C. Chow. Minimizing register usage penalty at \nprocedure calls. In Proceedings of the SIGPLAN 88 Conference on Pro\u00adgramming Language Design and Implemen\u00adtation, \npages 85 94, June 1988. Christopher W. Fraser and David R. Han\u00adson. A retargetable compiler for ANSI \nC. SIGPLAN Notices, 26(10), October 1991. James R. Goodman and Wei-Chung Hsu. Code scheduling and register \nallocation in large basic blocks. In International Con\u00adference on Supercomputing, pages 442-452, July \n1988. John L. Hennessy and Thomas R. Gross. Code generation and reorganization in the presence of pipeline \nconstraints. In Proceed\u00adings of the 9th Annual Symposium on Prin\u00adciples of Programming Languages, pages \n120-127, 1982. John L. Hennessy and David A. Patterson. Computer Architecture: A Quantitative Ap\u00adproach. \nMorgan Kaufmann, 1990. Priyadarshan Kolte and Mary Jean Har\u00adrold. Load/store range analysis for global \nregister allocation. In Proceedings of the SIGPLAN 93 Conference on Program\u00adming Language Design and \nImplementa\u00adtion, pages 268-277, 1993. [LH86] James R. Larus and Paul N. Hilfinger. Reg\u00adister allocation \nin the SPUR lisp compiler. In Proceedings of the SIGPLAN 86 Sympo\u00adsium on Compiler Construction, pages \n255 263, 1986. [Pin93] Shlomit S. Pinter. Register allocation with instruction scheduling: a new approach. \nIn Proceedings of SIGPLAN 93 Conference on Programming Languages Design and Imple\u00admentation, pages 248 \n257, June 1993. [PS90] Krishna Palem and Barbara Simons. Scheduling time-critical instructions on RISC \nmachines. In Proceedings of the 17th Annual Symposium on Principals of Pro\u00adgramming Languages, pages \n270-280, 1990. [Set75] Ravi Sethi. problems. 1975. Complete register SIAM J. Comput, allocation 4:226-248, \n[s090] Vatsa Santhanam and Daryl Odnert. Reg\u00adister allocation across procedure and mod\u00adule boundaries, \nIn Proceedings of SIGPLAN 90 Conference on Programming Language Design and Implementation, pages 28-39, \nJune 1990. [Wa186] David W. Wall. Global register allocation at link-time. In Proceedings of SIGPLAN \n86 Symposium on Compiler Construction, pages 264-275, July 1986.  \n\t\t\t", "proc_id": "178243", "abstract": "<p>This paper presents a new optimization technique that uses empty delay slots to improve code scheduling. We are able to split live ranges for free, by inserting spill code into empty delay slots. Splitting a live range can reduce interferences with other live ranges and can sometimes free registers. Live ranges no longer interfering with the split live range can sometimes make use of the extra register.</p><p>Our algorithm, as a final pass over the code, exploits empty delay slots that would remain unused if spill code was not inserted. This paper proposes a variety of optimizations that use the extra registers generated from live range splitting, including coalescing live ranges and improving code scheduling. We present an algorithm for improving code scheduling and present implementation results.</p>", "authors": [{"name": "Steven M. Kurlander", "author_profile_id": "81100041498", "affiliation": "University of Wisconsin-Madison", "person_id": "P270048", "email_address": "", "orcid_id": ""}, {"name": "Charles N. Fischer", "author_profile_id": "81100312451", "affiliation": "University of Wisconsin-Madison", "person_id": "P43394", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/178243.178420", "year": "1994", "article_id": "178420", "conference": "PLDI", "title": "Zero-cost range splitting", "url": "http://dl.acm.org/citation.cfm?id=178420"}