{"article_publication_date": "06-01-1994", "fulltext": "\n Debugging of Globally Optimized Programs Using Data Flow Analysis* Roland Wismiiller Institut fiir Informatik \n(Department of Computer Science) Technische Universitit Munchen (Munich University of Technology) D-80290 \nMiinchen, Germany Tel.: +49-89-2105-81(54 wismuell(ijihformatik.tu-muenchen.de Abstract Advanced processor \nand machine architectures need opti\u00admizing compilers to be efficiently programmed in high level languages. \nTherefore the need for source level debuggers that can hanclle optimized programs is rising. One diffi\u00adculty \nin debugging optimized code arises from the problem to determine the values of source code variables. \nTo en\u00adsure correct debugger behaviour with optimized programs, the debugger not only has to determine \nthe variable s stor\u00adage location or associated register. It must also verify that the variable is cur-renf, \ni.e. the value determined from that location is really the value the variable would have in unopti\u00admized \ncode. We will deduce requirements on algorithms for currentness determination and present an algorithm \nmeeting this rcqdrements that is more general than previous work. We will also give first experiences \nwith an implementa\u00adtion. To our knowledge this is the first implementation of a currentness determination \nalgorithm for globally optimized code. 1 Introduction Source level debuggers have been proved to be valuable \ntools for program development. Current implementations, however, rely heavily on the code not being optimized \nby the compiler. Although earlier phases of program development do not have a strong need for optimizers, \nin later stages, e.g. prototype versions, optimization is desirable. There is a couple of reasons why \ndebuggers should be usable with optimized code. Even if the optimizer is corrwt, there may his work is \npartly funded by the German Science Foundation, Con\u00ad traw. SFB 342, TP Al Permission to co y w thout \nfee all or part of this material is gra.tedprovidecfthatthe copie.s are not macieordistributedfor direct \ncommercial advantaqe, the ACM copyright notice and the title of the publication and Its date appear, \nand notice is given that copying is by permission of the Association of Computing Machinery. To copy \notherwise, or to republish, requires a fee and/or specific permission. SIGPIAN 94-6/94 Orlando, Florida \nUSA @ 1994 ACM 0-89791 -662-xIWO006... $505O be bugs in a program that only have effects in the optimized \nversion [Cop93]. Furthermore, some bugs may not appear until the code is already in production use, at \na point when it should be optimized. Figure 1 shows a fragment of a C-program together with its corresponding \nSpare assembly codel. Using this exam\u00adple, we will demonstrate some of the problems a symbolic debugger \nfor optimized code must deal with. The code location problem [Ze184] arises as soon as the programmer \nsets a breakpoint. If he wants to break at line 4, where should the debugger halt the optimized program? \nThe appropriate mapping depends on the programmer s intention in setting the breakpoint. If he wants \nto examine the old value of ~ the program should be stopped at instruction (semuntic mupping). However, \nif he wants to determine which a [i] are positive, the breakpoint should be mapped to instruction 10 \nor 11 (syntactic mapping). If he is interested in the value of y, it maybe the best to stop at instruction \n17, if register i5 is positive. Suppose the program has been stopped at instruction 11. When the user \nties to inspect the value of $, the debugger must first determine the register assigned to ~. In our \nexam\u00adple this is register 16. In addition, the debugger must ensure that ~ is current in /6, i.e. the \nvalue contained in 16 is the value ~ should have according to the source code. This is commonly referred \nto as the duta value problem. In Fig. 1, j is noncurrent in the iirst loop iteration, since ~ should \nstill contain the value assigned prior to the loop, but instruction 2 has already assigned a new value \nto register /6. Since the value of ~ is loop invariant, $ is current in all later iterations. However, \nwithout information about the loop s iteration count, the debugger must conservatively regard ~ as noncurrent. \nSeveral techniques have been developed to avoid these problems by disabling code transformations that \nhinder transparent debugging. They either require specification of debugging requests prior to compilation \n[Gup90, PS88] or restrict the program points where a debugger can be invoked [HCU92, ZJ91]. 1AUvariables \nexcept z are assumed to be live after tbe loop. 1 mov 1 2 3 4 5 6 7 8} 9 10 11 12 13 14 15 16 for (i= \nO;i<l O;i++) if (a [i] > O) { y=y+a[i]; f = g+h; w = a[i] * 2; z = z-l-w; x = a[i] + 1; else { w = a[i] \n* 2; x = -a [i] + 1; z = z-w; y=y+a[i]; f = g+h; } } { 2 3 4 5 Ll: ~ 7 [1 9 1() 1:1 12 13 L2: 14 L3: \n15 16 1 7 18 add add ld tst ble Sll b add sub inc cmp add bl inc 19 Figurel: Aprogram fiagmentbefore \n !i=o %00,%15,%16 ! f = g+h %fpr-48, %i2 ! i2 = &#38;a[i] ! loop: ! 0,%i3 [%i2] ,%i5 i5 = a[i] %i5 L2 \n%i5rl, %il w = a[i] * 2 if (a[i] > O) L3 %i4,%ilr%i4 z = Z+w else %i4r%ilr%i4 z = z-w %i3 i++ %i3r 10 \n%17,%i5r%17 y=y+a[i] L1 4r%i2 i2 = &#38;a [i] if (i< IO) goto loop andafter optimization Although these \nmethods allow for some optimization dur\u00ading program development, they are of limited use for de\u00adbugging \nproduction code or if bugs only show up in fully optimized code. In these cases optimization must be \nhan\u00addled by the debugger. Additional symbol tables can inform the debugger of the effects of the transformations \napplied [Ze184, CMR88, BHS92]. Different transformations often require different tables that must be \nupdated in each opti\u00admization step, so the debugger depends on the optimizer s implementation and usually \nhandles only few optimization. Furthermore, tables cannot easily support different brea\u00adkpoint mappings \nor the use of run-time information. The most promising approach to handle a large number of optimization \nin a general, fiexible way is to use data flow analysis to detect their effects on debugging. Until now, \nall algorithms based on this concept have severe drawbacks. [Hen82] and [ATG93a] are usable exclusively \nfor local op\u00adtimization, [ATG93b] only solves the restricted problem of finding the register assigned \nto a variable. The most general algorithm so far has been published in [COP93]. However, it has never \nbeen implemented, cannot use run-time infcmna\u00adtion and supports only a fixed syntactic breakpoint mapping. \nIn this paper we present an algorithm solving the data value problem that is more general than previous \nwork and has been fully implemented. In Section 2 we will specify the properties met by this algorithm. \nSection 3 gives the formal definition of currency, that is the basis of the algorithm outlined in Section \n4. Finally, Section 5 presents fist results obtained with an implementation.  2 Requirements on Solutions \nof the Data Value Problem Independence of Optimization Details. Since the algo\u00adrithm should be independent \nof the optimizer s internals and optimization specific data structures, the interface between compiler \nand debugger must be geneml enough to repre\u00adsent at least a large subset of common global optimization. \nA suitable interface consists of flow graphs of both source and object program and an explicit mapping \nbetween corre\u00adsponding entities. Representing source and object code in a single graph as in [Cop93] \nis problematic, if the basic block structure is heavily changed by the optimizer. Arbitrary Breakpoint \nMapping. In contrast to previous work, that is based on a fixed syntactic breakpoint mapping, our algorithm \ncan be used with any mapping. As shown in Section 1, syntactic breakpoints are neither unique, nor nec\u00adessarily \nthe best points to stop the program. If currency de\u00adtermination allows for arbitrary breakpoint mappings, \nthere is some freedom to choose an optimal mapping, where most variables that are of interest for the \nuser are current. In addition, an algorithm with this property can be used when the program is halted \ndue to an exception and allows recovery of noncurrent variables [Hen82]. In both cases no syntactic mapping \ncan be assumed. Usage of Run-Time Information. As shown in Section 1, run-time information can lead to \nmore precise results when analyzing currency. In order to use information about the paths the program \nhas taken in the mst2, the algorithm MS information may be gathered by coarse grained traces or invisible \nbreakpoints. must distinguish between different instances of the same statement. Assume that the program \nin Fig. 1 is halted at statement 4 and instruction 11 in the second loop iteration. If a [0] >0, the \nvalue of y has been computed by statement 3, while the value of the associated register 17 has been stored \nby instruction 16. Although instruction 16 has been generated from statement 3, y is noncurrent, since \nits vahte should have been computed in the current loop iteration but the store to 17 has been performed \nin the previous one. Handling Non-Live Variables. Most current techniques, e.g. [CMR88, Cop93], rely \non a unique mapping between source and object variables, that may depend on the program counter to support \nvariables with changing locations (e.g. due to register allocation). The optimizer maintains this mapping \nby storing the register or memory location used for each segment of a variable s live range. So the values \nof non-live variables cannot be determined by the debugger, since no information on the proper location \nis available. The algorithm in [ATG93b] computes the proper location of non-live variables, but requires \nthat the same register is used for all segments of a variable s live range, which is not the case for \na variety of compilers. The algorithm presented in Section 4 does not rely on this assumption. Handling \nof Indirect Assignments. To be usable for real programs, an algorithm determining currency must be able \nto handle indirect assignments through pointers correctly. Section 4.3 shows how this is accomplished \nin our algorithm. Assurance of Currency by the Compiler. Marty compilers regard assignments through pointers \nas an implicit use of all variables the pointer may access. So these variables must be current at the \nlocation given by the assignment and its associated store instruction. Using such information may significantly \nspeed up analysis and lead to more precise results. 3 A General Definition of the Term Current Intuitively, \nat a breakpoint a variable v, is current in a register or memory location VO,iff the value of v. is always \nthe same as the value V, should have according to the source program. In this context always means in \neach possible execution of the program . Since we are concerned about the the original source program \nand the optimized object program, we need a definition of the term execution that characterizes the behaviour \nof both program versions Definition 1: A path is a sequence (ZI . . . z. ) of state\u00adments, where z~+ \n1 is a possible successor statement of z~. An execution of a program is a pair (p., pO), where PO is \nthe path the object program takes with some input, while p. is the path the source program would take, \nif it were executed with the same input. Since the value of a variable is determined by its last as\u00adsignment, \nv, is current at a breakpoint in v., iff for each execution of the program the statement instance3 d: \nthat as\u00adsigned the last value to v, according to the source code has a semantically corresponding statement \ninstance ~ in the object code that stored the same value into VOand reached the breakpoint. In the most \ngeneral case, the breakpoint position is identitiedbyapairof statement instances (b?, b:). We will first \ndefine currency of single definitions, that is important for the algorithm presented in Section 4. Definition \n2: A &#38;jim tion d, is current at a breakpoint (~$, b:) with respect to a source variable v, and an \nobject variable vO,iff the following condition holds for each execution (p., PO) and each instance d: \nof d~ on Ps: If d: writesto v. and reaches bf along p, then on PO there is art instance ~ of a store \nthat semantically corresponds to d;, writes to VO and reaches bj along PO* Note that the terms writes \nand reaches in this definition refer to an actual program exeeution. Since in the presence of indirect \n(pointer) assignments static analysis can only decide whether or not a definition muy write to a variable \nand muy reach a breakpoint, Definition 2 is not directly usable, if the paths to be tested contain such \nassignments. In Section 4.3 we will present an efficient static analysis method for this case. Now, a \nvariable is current, if each definition that may have assigned the variable s last vahte is current. \nDefinition 3: LetRD(b, v) be the set of definitions of vari\u00adable v that reach location b. Then a vuriuble \nv, is current at (b!, b:) in object variable VO, iff each ds E RD(b., v.) is current at (b?, bj) with \nrespect to v, and V.. The information about semantic correspondence between statement instances summarizes \nall program transformations performed by the optimizer. If a vector of iteration indices is used to distinguish \nbetween instances (as in FW86]), the above definitions also hold in the presence of loop trans\u00adformations, \ne.g. interchanging or skewing. However, using index vectors requires the program s loop structure to \nbe known and well defined. In the rest of this paper we assume that theprogram s loop structure is not \nchanged by optimization. Then the number of back edges on the path to a statement can be used to distinguish \nbetween different instances. 3A statement instance is an occurrence of a statement in a path. We will \nuse upper Greek indices to distinguish between differrmt instances of the same statement. 4I.e. no instruction \nbetween d; and the breakpoint stored into w,. 51n well structured programs, back edges correspond m loops. \nSee [Hec77] for art exact definition. 4 An Algorithm to Determine Cur-each instance of a definition \nof v, that reaches the break\u00ad  rent Variables 4.1 Program Representation A program is represented by \na pair of flow graphs for each procedure The source graph S represents the orig\u00adinal source code, while \nthe objecf graph 0 represents the optimized code. The nodes of these graphs are basic blocks that contain \na sequence of statements. Since the analysis only has to consider operations that either change variables \nor control flow, only these operations are included. They are chameterize.d by the following information: \nStatement type we distinguish between assignments, indirect assignments, procedure calls and jumps. For \nassignments there is a field assigned.var contain\u00ad ing a description of rhe destination variable that \nis either a vatiable name, an address or a register number. Off\u00ad set and length fields are used to handle \nassignments to structure or array components. Indirect assignments and calls are associated with a set \nMAYKILL of variables that maybe modified. An additional relation coDE mapping source statements to semantically \nequivalent instructions summarizes all code transformations. So an assignment in the source code is mapped \nto the instruction that stores the value of the assign\u00adment s right hand side. Relation CODE also holds \nbetween corresponding edges of branch or join nodes in order to model control flow transformations. In \ngeneral, CO13E is neither a total nor a unique mapping. Figure 2 shows the representation of the program \nin Fig. 16. Instruction 8 corresponds to both statement 5 and 10, since it always stores the same value \nas these (equivalent) statements. (7, 13) E CODE((2, 10)) holds, since in eaeh execution, where 10 is \nthe successor of statement 2, instruc\u00adtion 7 branches to instruction 13. In order to simplify analysis, \nflow graphs have single en~ nodes with zero in-degree, that contain initial pseudo assignments to each \nvariable used in the graph. In this way there is at least one reaching definition for a variable along \neach path. Although the flow graph nodes are basic blocks, for ease of explanation we subsequently assume \na node being a single statement. If a node consists of more than one statement, additional local analysis \nmust be performed.  4.2 Algorithm Disregarding indirect assignments for the moment, we can use Definitions \n2 and 3 to develop au algorithm comput\u00ading currency of a given variable VS. The idea is to look at 6Nodes \n7 and 8 in the object graph are interchanged, with res~ct to the assembler listing since instruction \n8 always executes befomthe delayed branch 7 is executed. point in the source program. Each such definition \nreaches the breakpoint along a set of paths in the source program. This set defines a set of corresponding \npaths in the object program. Likewise, the tested source definition leads to a set of semantically corresponding \ndefinition instances in the object code. If along each of the above paths one of these definitions reaches \nthe breakpoint in the object code, and all definitions write to the same object variable TJO,then v. \nis current in VO. Unfortunately this idea cannot be converted to an algo\u00adrithm immediately, since an \ninfinity of possible instances and an infinity of program executions is tested. Furthermore, since the \ninstance of the breakpoint is usually unknown, all possible breakpoint instances have to be considered. \nHowever, if no loop transformations have been applied, there is usually no reason to stop the program \nat a breakpoint (b?, b:) where b! and b: are located in different iterations of the same loop. For syntactic \nbreakpoints, b. and bo are always located in the same loop (or outside any loops) and have to be reached \nin the same loop iterations to achieve transparent debugger behaviour. So in this case it is justified \nto require that ,L?= 6. To support semantic breakpoints, we must also consider cases where bo is ahead \nof the loop that contains b., e.g. when a semantic breakpoint is set on a statement that has been moved \nout of a loop. In this case, bj should be the last instance of bo ahead of the loop iteration containing \nb!. The reverse situation occurs, if bo is located after the loop containing bs. Other situations do \nnot occur regularly. A compiler maybe able to move some load instructions to a previous loop iteration, \nbut the statement s key effect, i.e. the computation of its value that determines the position of the \nsemantic breakpoint, is either left in the same iteration or moved out of the loop. So instances of corresponding \nbreakpoint locations are no longer independent, but coupled by above conditions. The same conditions \ncan also be used to extend the c ODE relation to statement instanti @ semantically corresponds to d:, \nif do c coDE(d, ) and the above relation holds betwt?fm d$ and d:. To determine currentness of a definition, \nall paths ending in an ribitrary instance of a breakpoint must be examined. Standard data flow analysis \nalgorithms can be used to com\u00ad pute combined information, e.g. reaching definitions, from all such paths. \nHowever, as shown in Section 2, we must be able to distinguish between different instances of a definition \nreaching along some path. This can be accomplished by un\u00ad rolling the flow graphs in a way, such that \nall instances that need to be distinguished are represented by different nodes in the unrolled graph. \nSo standard data flow analysis in the transformed path provides information on different state\u00ad ment \ninstances. A parameter m determines the number of instances prior to the breakpoint that must be distinguished. \nThe unrolled graph then represents all possible paths that contain at least m back edges. Figure 3 shows \nan exam\u00ad ple of such a graph for m = 1, where the original graph cor)E mapping l~i 1 i3 Source I Obiect \n 2 T 216 1i 1 14 3 8K il 3,13 16 4,14 24 5,10 8 6 11 5 12 13 6 m 7 L (7, 1 ) (11, 14) (14, 1 ) (13, \n14) (1,2) (2, 8) (1 , 2) (17,8)1 Figure 2: Representation of the program in Fig. 1 Nodes (n,-2) Nodes \n(n,-1) Nodes (n,O) Nodes (n,l) Figure 3: A flow graph G with two nested loops and its unrolled graph&#38; \ncontains two nested loops. Roughly nodes (n, O) represent Using unrolled graphs to model the execution \nof the the current loop iteration, while nodes (n, 1) represent source and object program, currency \nof a definition d. can the previous iteration of either the inner or outer loop. The be testedin the \nfollowing way, according to Definition 2 In subgraphs (n, 2) and (n, 1)summarize all instances that &#38;, \nthe considered instance of the source breakpoint (i.e. need not be distinguished. @ is represented by \nnode (bs, O). If some instance d; of More formally, the umolled graph Q = (N~, I&#38;) of a a definition \nreaches this breakpoint along a path contain\u00adgraph ~ = (N, l?) is defined as follows: ing m back edges, \nnode (d$, m) reaches (b,, O) in Sm. 1. Nmg Nx[ m l,l]. Now we have to test, whether in all executions \nwhere this 2. If (z, y) E E is a forward edge, then ((z, i), (y, i)) ~ instance reaches the breakpoint \nin the source program, a Em foratli ~ [ n 1,1]. semantically corresponding definition instance reaches \nthe If (z, y) c E is a back edge, then ((z, m breakpoint in the object program. In order to test all \nthese 1), (Y, m 1)) e J%, ((z, 1), (Y, 1)) c &#38; and execution simultaneously, we restrict the unrolled \ngraph 0~ ((z, i), (y, i+ 1)) E 13mfor alli 6 [-m-1,0]. in a way, that only those paths remain that belong \nto these 3. Ifs c Nisthestartnode of Gande c Ntheexitnode, executions. This is done using information \ncomputed in S~. then (n, i) E IVm, only if there is a path from a node In the restricted object graph, \nfor each path there has to be a (s, j) with j < mtoanode (e, k)withk>O that definition corresponding \nto d: that reaehes the breakpoint. contains (n, i), i.e. all nodes are removed that are not This data \nflow problem is very similar to the avduble ex\u00adpart of a path through Gm. pressions problem and can be \nsolved by a standard analysis  algorithm. In order to test all possible executions, these steps must \nbe repeated form = 0,1,... However, it is not necessary to consider paths of arbitrary length. In standard \n(scalar) data flow problems, all possible executions are examined by testing paths containing at most \n1 back edges, where i is the flow graph s loop connectedness [Hec77]. For the analysis above we have \nproved that 3.1 + 2 is a legal upper bound for m. The proof is based on the fact that a path containing \nmore than lbaek edges must have a cycle. If there is a program execution, where some definition reaehing \nthe source breakpoint along a path with more than 3. / + 2 back edges is noncurrent, then there is also \na shorter exeeution with that property. The factor of three shows up, since the path must be divided \ninto three sub-paths where cycles may be removed, in order not to remove the object breakpoint or some \ninstruction killing the definition s value from the execution. Finally the back edges immediately after \nthe definition and immediately preceding the breakpoint in the source program must not be removed, increasing \nthe bound by two. There is some evidenee that the least upper bound is reasonably smaller, but there \nis no proof yet. In practical cases, 1is usually not greater than 2, for most well structured programs \nour target compiler creates flow graphs with 1 = 1. There are still three problems that have to be solved \nin the algorithm 1. How ean 0. be restricted in the required way? 2. Which nodes in 0~ represent possible \ninstances of the object breakpoint and which represent an instance corresponding to d;? 3. How ean we \nfind the object variable associated with  4.2.1 Restricting the Unrolled Object Graph In the unrolled \ngraph $m we examine all paths where node (d,, -m) reaehes node (b., O). An edge ((z,, i), (YS, ~)) cannot \nbe a part of such a path, if (d., m) reaehes (y,, j) but does not reaeh the point immediately after (z., \ni) 7. In this ease (y., j) is a join node and must be reaehed along another incoming edge. Therefore \nthe corresponding edge in the object graph (i.e. ((x., i), (y., j)) with {z., Y.) G CODE((Z., ys))) cannot \nbe part of a path through Om for these program executions and is deleted from 0~. Likewise, we ean remove \nan edge from Om, if its corresponding edge in the unrolled source graph is not part of any path through&#38; \ncontaining the breakpoint location (b., O). Finally, all nodes that are not part of a path through 0~ \nare deleted, since they are not relevant in the considered program executions. By properly restricting \nboth&#38; and Om, run-time infor\u00admation can be taken into aeeount in a very similar way. 71.e. either \n(d~, m) doesn t reach (zS, i) or is killed by (zs, i). 4.2.2 Finding Possible Breakpoints and Definitions \nin the Unrolled Object Graph In Section 4.2 we have defined which instance b: of a break\u00adpoint in the \nobject program correspond to an arbitrary in\u00adstance b! of the source breakpoin~ If bo and b, are heated \nin the same loops, then 6 =/3 must hold. If bo has been moved in front of a loop surrounding b$, then \nbj is the last instance of bo prior to the iteration containing b!. Likewise, b: is the first instance \nafter this iteration, if bo has been moved behind the loop. In the unrolled flow graphs, b? is mapped \nto (b,, O) in f%. Which nodes in 0~ represent the corresponding instance b:? In the first ease, b: is \nmapped to (b., O), since 6 = ~ holds. In the seeond ease, b: is represented by node (be, O), if we consider \nthe tirst loop iteration, or by the last node (be, i) with i G [ m 1, 1] prior to the current iteration. \nIn this situation, the current loop iteration is reaehed via a baekedge, that corresponds to some edge \n((z., 1), (v., 0)) in the unrolled object graph. bo is located ahead of this loop, if b. < YOin the reverse \npost orde~ [Hec77] in 0, i.e. if there is a path from bo to YOthat doesn t contain any back edge. Similar \nconditions arise, if bo is located after the loop containing bs. So the set of nodes in 0~ that may represent \na possible instance of breakpoint bo ean be summarized as: {(be,i) \\i E [ m 1, 1] A there is a path \nin Om starting at (b., i) that ends in a back edge ((zO, l), (yO, O)) with bo < y. A there is m (bO, \nj) between (be, i) and (YO, O) } U { (bO, O)} u { (be, 1) I there is a path to (be, 1) starting with \na bxk edge ((z., O), (y., 1)) with bo > Z. A there is no (b., j) between (~., O) and (be, 1) } As an \nexample, consider a breakpoint at line4 in theprogmm given in Fig. 1. Figure 5 shows the unrolled object \ngraphs (Io and 01 of this programg. If the breakpoint is mapped to instruction 2, node (2, O) represents \nthe only instance of this breakpoint in 00. In CJI, both nodes (2, 2) and (2, 1) are possible breakpoints, \nsince there is a path from either of these nodes ending in back edge ((17, l), (8, O)) and node 2 precedes \nnode 8 in 0, i.e. instruction 2 is located prior to this loop. Since there are no other nodes (2, i) \non these paths, both (2, 2) and (2, 1) represent the last instance of instruction 2 ahead of the current \nloop iteration. Although not considered explicitly in the explanation above, the set is also correct \nfor nested loops. Since the relation CODE definhtg semantic correspon\u00ad dence between statements has been \nextended to statement instances using the same mapping as above, the set of nodes corresponding to d: \nis very similar. However, there is a shift in the indices, since d: is mapped to (d,, m). Furthermore, \nsemantic correspondence must hold for all possible paths. 8Also called depthjirst order. Nodes are only \npartially numbered in order to keep the picaut clear.  Input: Flow graphs S and 0, a source variable \nW$and a breakpoint location b,. Output: The setcurrent of object variables, such that VS is current at \n(b,, bo) in each VO~ CURRENT. If v, is noncurrent, current = 0. Algorithm: Determine the set OBJECT-VARS \nof object code variables corresponding to WS as explained in 4.2.3 For all nodes n in 0: CURRENT(n) = \nOBJECT_VARS Form= 0t03 .1+2: For each definition (d., m) of v, that reaches (b,, O) in Sm: Restrict \nOm such that only paths are possible, that correspond to reaching paths from (d,, m) to (b$, O) in Sm \n(see 4.2.1). Determine the set of nodes representing possible breakpoints and definitions as shown in \n4.2.2 Solve the data flow equation for .4vAm(n, i) in Om: AVAIL (n, i) = n [[AVAIL (P, j) MAYKILL(p)] \nU MUSTGEN(p, j) (P,~)EPRED(~,i) 1 where {assigned.var(p)} n OBJECT_VARS if (p, j) represents a definition \nMUSTGEN(~, j) = 0 else { For each (n, i) representing a possible breakpoint CURRENT(n) = CURRENT(n) \nn AVAIL(T2, i) Figure 4: The complete algorithm for currency determination So the following set results: \n{ (dO, -m -1) ] do c coDE(ds) A for all paths from (d., m 1) ending in some back edge ((z., m 1), (y., \nm)) : do < YO A there k no (dO, j) between (dO, m 1) and (yO, m) } U { (do, m) I do E CODE(d3) } U \n{(do, i) 1 do c CoDE(d, ) A i c [ m+ 1,1] A for all paths to (d., i) that start with a back edge ((x., \nm), (y., m + 1)) : d. > ZO A there k no (dO, j) between (zO, m) and (d., i) }  4.2.3 Finding Appropriate \nObject Variables In principle, the algorithm in Fig. 4 doesn t require computa\u00adtion of object variables \ncorresponding to v. prior to currency determination, since it computes the set of object variables where \nv~ is current in. However, there are a lot of set opera\u00adtions that are more efficient for small sets, \nso it is beneficial to start with a small set of variables that might correspond to v. rather than the \nset of all variables. When a single definition of v, is executed, the value of v. is stored in the destination \nvariable of the corresponding definition in the object code. If there is more than one corresponding \ndefinition, the value is stored in more than one object variable. So after a given definition d. has \nbeen executed, its value is stored in all variables contained in: u assigned.var(do) doECODE(d.) At \na given breakpoint b, in the source code, the value of v. may have been computed by any definition in \nRD(b~, v.). Since it is unknown, which of these definitions actually assigned the current value of v,, \nan object variable is eligible Only, if it is COnt2ined in the above set forrdl d. c m(bs, v,). So the \nsetof variables that may contain the value of v, can be computed by: assigned-var(do)) n(u d, cRD(b,,u, \n) decode  4.2.4 The Complete Algorithm The resulting algorithm is shown in Fig. 4. There is no need \nto explicitly build the umolled graph Sm, since the defini\u00adtions (d,, m) reaching (b,, O) in &#38; can \nbe computed by a slightly modified iterative algorithm for reaching definitions in S. An iterative algorithm \n[Hec77, MJ81] can also be used to solve the equation for AvAIL (n, i). 4.2.5 An Example Again we consider \nvariable ~ at breakpoint (4,1 1) in the pro\u00adgram shown in Fig. 1 and Fig. 2. Assuming that statement \nO iSth13d13finit.iOnOf ~pIiOrtOtheh)OP,RD(A, ~) = {O, 4, 14}. If statement O has a corresponding instruction \nO storing to 16, the set of object variables that may contain the value of ~ evaluates to assigned.var(0) \nn assigned-var(2) n assigned.var(2) = {/6}. If instruction O had been elim\u00adinated or stored to another \nregister, this set would be empty, so the value of ~ could not be determined, since ~ would have no associated \nlocation. In the rest of this example we assume that ~ is associated with 16. 1 . . . ~. 9 0,0 2 3 4 \n5 6 7 1 ~,, Unrolled object graph (m=O) source graph 4$ Definition of f 0 Breal@nt @ O Object graphx \nNo&#38;sin DEF Nodes (Il,i) inBRK .:,:,; .,., :[: ,,,,,..,.,. .,:,: ,,:,,?::.. @ ::: --> Nodes (Li) with \nAVAIL@,i) = {16) Nodes and edges deleted due to path restriction Umolled object v graph (m=l) t . ,::,.,.,., \nFigure 5: An example for currency determination In the first step (m = O), the algorithm tests all executions, \nwhere a definition of ~ reaches the breakpoint along a path without back edges. There is only one such \nexecution, that is shown in Fig. 6 as a trace of both source and object program. Looking at this execution, \nit is clear, that $ is noncurrent, since the value assigned to ~ by statement O is stored in register \n16 by instruction O, but is overwritten by instruction 2. The same result is computed by the algorithm \nin Fig. 4. First, analysis of the unrolled source graph shows, that only node (O, O) reaches node (4, \nO), i.e. statement O k the only definition to look at. In a next step, edges and nodes, that cannot occur \nin these executions are removed from the unrolled object graph. The resulting graph 00 is shown in the \nupper half of Fig. 5. Edge ((17, l), (8, O)) has been eliminated, since no reaching path from (4, O) \nto (O, O) in SO can contain the corresponding edge ((l , -l), (2, O)). Likewise ((13, O), (14, O)) has \nbeen deleted, since a path in&#38; containing node (4, O) can t contain ((14, O), (l , O)). Elimination \nof all nodes that are not part of a path through (9o removes the dotted nodes and edges in Fig. 5. So \nthis graph roughly contains the same information as the object program s trace in Fig. 6. Next, (11, \nO) is determined as the node representing the appropriate instance of the breakpoint instruction 11, \nwhile node (O, O) is computed as the only representative of a defi\u00adnition that semantically corresponds \nto statement O. Finally, the algorithm checks, whether the value assigned by this definition is available \nat the breakpoint. Since instruction assigns to register 16, node (2, O) kills 16, so the result is AVAIL(ll, \nO) = 0 and therefore CURRENT(11) = O. In ! definition ... of=...; 1 mov 0r%i3 . . . 2 add %00,%15,%16 \n! kills %16 1 for (i=O;i<lO;i++) { 3 add %fp, 48,%i2 2 if (a[i] > O) { 5 Ll: ld [%i2],%i5 3 y=y+a[i]; \n6 tst %i5 7 ble L2 ! not taken 8 S1l %i5,1,%il o mov . . ..%16 Figure 6: A program trace of fig.1 until \nthe ftrst occurrence of breakpoint (4, 11) 11 sethi %hi(_a),%oOS1 a=x; 12 st %11, [%oO+%lo(_a)l ! a = \nx *p = y;S2 ! *p=y 13 st %12, [%i5]S3 b=*p; 14 mov [%i5]r%13 lb= *PS4 ... 15 ... Figure 7: An example \nprogram with an indirect assignment later iterationsofthe m-loop,thisresult can tchangeany more, so~isnoncurrent. \nWhen there is some runtime information, telling the de\u00adbugger that the program has not been stopped in \nthe first loop iteration, abetter result can reachieved. To reflect the given rnntime information, edge \n((1, O), (2, O)) can be deleted in the umolled source graph SO, since it is only part of a program execution, \nwhen the breakpoint occurs in the iirst loop iteration. Now form = Othere is no node (d,, O) in So that \nreaches node (4, O), i.e. there is no louger any definition of ~ reaching the breakpoint within the same \nloop iteration. In this case, CURRENT( 11) is still initialized with the set {/6}, when analysis is repeated \nwith m = 1. For m = 1, definitions (4, 1) and (14, 1) reach the break\u00adpoint in&#38;. For both definitions \nthe same situation occurs, so only the analysis for (4, 1) is explained. The unrolled graph 01 is shown \nin the lower half or Fig. 5. As above, node (13, O) has been removed during path restriction. node (11, \nO) represents the current break\u00adpoint instance. Since CODE(4) = 2 and instruction 2 has been moved in \nfront of the loop, both nodes (2, 2) and (2, 1) represent instances of an instruction that semanti\u00adcally \ncorresponds to the source definition being tested. Node (2, 2) is included, since forallpaths from this \nnode to some back edge ((z, 2), (y, l)), the only candidate for y isin\u00adstruction 8 that is preceded by \ninstruction 2 in reverse post order. In addition there are no other occurrences of instruc\u00adtion 2 on \nthese paths, so (2, 2) represents the last instance of this instruction prior to the loop iteration containing \nthe breakpoint. In this case, AVAIL(11, O) = {16}, since on every path in 01 a possible definition reaches \nnode (11, O) in 16. There\u00adfore CURRENT(ll) = {/6} after iteration m = 1. No subsequent iteration changes \nthis result, so ~ is current in 16, if the breakpoint is not reached in the tirst loop iteration.  4.3 \nCurrency Determination in the Presence of Indhwct Assignments In the presence of indirect assignments, \ne.g. *P = z, the algorithm presented in Section 4.2 is too conservative. Con\u00adsider the program fragment \nin Fig. 7, where p may point to a. If variable a is examined at breakpoint (S4715), two reaching definitions \nare tested. While definition S2 is cur\u00adrent with respect to a and .a, the algorithm will classify S1 \nas noncurrent, since instruction 13 may kill m. The problem is that in assuming S1 to be a s last definition, \nit is assumed that S2 does not access a. However, the algorithm doesn t take into account that in this \ncase 13 cannot write to -a, if it semantically corresponds to S2. The following theorem allows a slightly \nmodified recursive version of our algorithm to be used in the presence of pointer assignments. Theorem \n1: Let ID(6, v) be the set of definitions c1 of v, such that there is a path from d to b that must not \nkill v. So ID(b, v) is the minimal subset of RD(b, v) such that for each path to b, the last reaching \ndefinition of v is in lD(b, w). Then VS is current at (b., bo) in vO, if each d, E ID(bs, vS) is current \nat (b., bo) with respectto v. and WOand, if d$ is an indirect assignment, VSis current in v. at (d,, \ndo) for each do E coDE(ds). We will justify this theorem using the example above. S2 ~ ID(S4, a), so \nthere are no statements between S2 and S4 that may write to a. Since S2 is current at (S4,15), there \nare also no instructions between 13 and 15 that may change -a. So in an arbitrary execution, if S2 writes \nto a, a is current in -a. Otherwise, a is current in ._aat (S4J5), if and only if iropt flow iropt flow \nlocal var. local var. ref d var. ref d var. ............ ............... ...... ....................... \n.......................... ; 100.0 % current noncurrent recoverable undefined eliminated nonunique . \n a) percentage of breakpoints that have variables in the indicated class iropt flow iropt flow local \nvar. local var. ref d var. ref d var. ................................................ .................. \ncurrent, undefined } 80.0 % ! or recoverable ; 60.0 current or tmdefmed ; 40.0 current or recoverable \n ; 20.0 current 0; ,... ,.  -:-0.0 b) percentage of breakpoints where all variables are in the indicated \nclass Figure 8: Effects of optimization on debugging it is current at (S2J3), since between these points \nneither a nor .a is modified. Theorem 1 also allows us to reduce the algorithm s com\u00adplexity by using \ncompiler information that assures currency of a variable. In the example, if a is guaranteed to be current \nin m at (S2J3), no recursive analysis is needed.  5 Results and Future Work The algorithm developed \nin Sections 4.2 and 4.3 has been implemented based on the SUN C-compiler for Spare work\u00adstations [Muc90]. \nOptimizationsperformedby this compiler include global common subexpression elimination, regis\u00adter allocation, \nglobal copy and constant propagation, global dead store elimination, loop invariant code motion and com\u00adposite \nbreaking. We have modified the optimizer and code generator to generate the proposed program representation \nin addition to traditional debugging information. Of about 94,000 lines of code, only 2,200 lines had \nto be changed or added for this purpose, where most of the additional code consists of output routines. \nThe overhead in compile time and object file size intro\u00adduced by this debugging information has been \nmeasured by compiling the optimizer itself, that consists of 69 files. Creating traditional debugging \ninformation for nnoptimized code increases compile time by 19%, while file size in\u00adcreases by a factor \nof 5.5. In comparison, generating the extended information for optimized code results in a com\u00adpile time \noverhead of 29% and output files that increase by a factor of 20 in size. However, the output format \nis very redundant at the moment, so we expect that the size of the program representation could be reduced \nby a factor of 2, resulting in a comparable reduction in compile time and file size overhead. Currency \nanalysis is performedbya separate program that takes as input a breakpoint location, given by line number \nand object code address, and a variable, given by its name, an offset and its length. Although worst \ncase complexity of this analysis is quadratic in the number of basic blocks, in practice response time \nof the algorithm is only a few tenths of a second on a SPARCstation 10, so the algorithm is usable for \ninteractive debugging. To gain empirical results on the effects of global opti\u00admization on debugging, \nwe have analyzed several programs using input scripts that request currency state of each vari\u00adable at \neach possible breakpoint. The usual syntactic break\u00adpoint mapping, that is generated by the compiler \nin the same undefined: 1 undefined: 21. 23.4 % current 24.99 0 bk 1.5% eeoverable: 0.4 ~0 curren~ 62.7 \n70 curren~ 53.4 VO a) iropt b) flOW Figure 9: Average number of current and noncurrent variables way \nas for unoptimized programs, has been used for this analysis. Figure 8 shows some results for two different \npro\u00adgrams: iropt is the optimizer of our target compiler, f low is the currency algorithm itself. The \nfigure comprises about 16,800 breakpoints and 170,000 currency tests. Variables include locals and parameters \nof all types, where structures and arrays are broken into their components. In order to keep the size \nof the input scripts manageable, global vari\u00ad ables have not been considered in this picture. In the \ncolumns labelled local var. all variables have been examined at all breakpoints. Fig. 8a shows that there \nare vir\u00adtually no breakpoints where no variable is current, however at a large number of breakpoints \n(80%) also noncurrent vari\u00adables occur. Some noncurrent variables can be recovered at 4 to 109ZOof all \nanalyzed locations, while variables that have not yet been assigned occur at about half of all breakpoints \n(37-48%). Although in Fig. 8 these variables are Iabelled as undefined, they also include procedure parameters \nthat are not changed prior to the breakpoint. For these param\u00adeters, the variable s value ean be correctly \ndetermined by the debugger, if no interprocedural optimization has been performed, as it is the case \nwith our compiler. Figure 9 shows another view of these results, namely what percentage of all variables \nexisting at a breakpoint is current, noncurrent, undefined or recoverable. Only one forth of all variables \nare noncurrent, so on an average there is a 7570 chance to determine the expected value of a variable. \nRecovery is moderately successful for global optimization: about 2 to570 of all noncurrent variables \ncan be recovered. To some extent, also the reasons, why variables are non\u00adcurrent are shown in Fig. 8a \nAtupto31 ZO of all breakpoints there is no associated object variable due to code elimina\u00adtion, in about \n7% of all cases, the object variable is not unique, since different registers are used for different \nsec\u00adtions of a variable s live range. It is not easily possible to further analyze which optimization \ncaused a variable to be noncurrent, since the program representation only models the accumulative effect \nof all optimization. Finally, Fig. 8b shows the relative number of breakpoints, where full debugging \nis possible, i.e. all considered vari\u00adables are current, undefined or recoverable. If only variables \nare taken into account that are referenced at the breakpoint line or the preceding line in the source \ncode, the results change significantly, as the columns Iabelled ref d van in Fig. 8 show. This restriction \nmodels a situation, where a user sets a breakpoint either to see the value of a variable used at this \npoint or defined immediately ahead of it. In this situation, the number of breakpoints with noncurrent \nor undefined variables is greatly reduced, while the number of breakpoints with full debugging capabilities \nincreases. Although it is possible to obtain statistical data, it is not yet known how the presence of \nnoncurrent variables affects debugging in practice, i.e. how often a programmer is in\u00adterested in the \nvalue of such a variable in a real debugging session. To answer this question, we will integrate our \nal\u00adgorithm into the source level debugger DETOP, that is part of the programming environment TOPSYS [BB9 \n1]. We will also investigate how the usage of run-time information affects the results presented in this \nsection. Further work will be done in algorithms to determine syntactic breakpoint mappings and optimal \nmappings with respect to the number of current variables.  References [ATG93a] A. Adl-Tabatabai and \nT. Gross. Detection and Recovery of Endangered Variables Caused by Instruction Scheduling. In Proceedings \nof the ACMISIGPLAN Conference on Programing Language Design andImplementationPLDI 93, volume 28(6) of \nACM SIGPLAN Notices, pages 13 25, Albuquerque, New Mexico, June 1993. [ATG93b] A. Adl-Tabatabai and T. \nGross. Evicted Vari\u00ad ables and the Interaction of Global Register Allocation and Symbolic Debugging. \nIn Pro\u00adceedings of the 20th Annual ACM SIGACT-SIGPLAN Symposium on Principles ofProgram\u00adnukg Languages, \npages 37 1 383, Charleston, South-Carolina, January 1993. ACM Press. [BB91] T. Bemmerl and A. Bode. An \nIntegrated Envi\u00adronment for Programming Distributed Memory Multiprocessors. In A. Bode, editor, Distributed \nMemory Computing, 2ndEuropean Conference, EDMCC2, volume 487 ofLecture Notes in Com\u00ad puter Science, \npages 130-142, Miinchen, FRG, April 1991. Springer-Verlag. [BHS92] G. Brooks, G. J. Hansen, and S. Simmons. \nA New Approach to Debugging Optimized Code. In ACM SIGPLAN 92 Conference on Program\u00adming Language Design \nand Implementation, volume 27(7) of ACM SIGPLAN Notices, pages 1 1 1, San Francisco, California, June \n1992. ACM Press. [CMR88] D. S. Coutant, S. Meloy, and M. Ruscetta. DOC: A Practical Approach to Source-Level \nDebug\u00adging of Globally Optimized Code. In Proceed\u00adings of the SIGPLAN 88 Conference on Pro\u00adgraming Language \nDesign and Implementa\u00adtion, volume 23(7) of ACM SIGPLAN Notices, pages 125 134, June 1988. [Cop93] M. \nCopperman. Debugging Optindzed Co&#38; WithoutBeing Misled. PhD thesis, Univ. of Cali\u00adfornia, Santa Cru.z, \nMay 1993. Technical Report UCSC-CRL-93-21. [Gup90] R. Gupta. Debugging Code Reorganized by a Trace Scheduling \nCompiler. Structured Pro\u00adgraming, 11(3):141 150, 1990. [HCU92] U. H61zle, C. Chambers, and D. Ungar. \nDe\u00adbugging Optimized Code with Dynamic Deopti\u00admizat.ion. In ACMSIGPLAN 92 Conference on Programming Language \nDesign andlmplemen\u00adtation, volume 27(7) of ACM SIGPLANNotices, pages 3243, San Francisco, California, \nJune 1992. ACM preSS. [Hec77] M. S. Hecht. Flow Analysis of Computer Pro\u00adgrams. The Computer Science \nLibrary. Elsevier North-Holland, New York, 1977. [Hen82] J. Hennessy. Symbolic Debugging of Optimized \nCode. ACM Transactions on Programming Lan\u00adguages and Systems, 4(3):323 344, July 1982. [MJ81] S. S. \nMuchnick and N. D. Jones. Program Flow Analysis, Theory and Applications. Prentice Hall, Englewood Cliffs, \n1981. [Muc90] S. S. Muchnick. Compiling forRISC-Based Sys\u00adtems. In RISC Compilers Tutorial, SIGPLAN 90 \nConference on Programmhg Language Design and Implementation, White Plains, New York, June 1990. rPs88] \nL. L. Pollock and M. L. Soffa. High-Level De\u00adbugging with the Aid of an Incremental Gpti\u00admizer. In Proceedings \nof the Twenty-First An\u00ad nual Hawaii International tem Sciences, volume II, 524-532,1988. Conference on \nSys-Software Track, pages pW86] D. A. Padua and M. J. Wolfe. Advanced Com\u00adpiler G@imiza.ions for Supercomputers. \nCom\u00admunications of the ACM, 29(12):1184-1201, December 1986. [Ze184] P.T. Zellweger. Interactive Source-I-xwel \nDebug\u00adging of Optimized Programs. Technical Report CSL-84-5, Xerox Corporation, Palo Alto Re\u00adsearch Center, \nPalo Alto, California, May 1984. [ZJ91] L. W. Zurawski and R. E. Johnson. Debugging Optimized Code with \nExpexted Behaviour. un\u00adpublished manuscript, April 1991.  \n\t\t\t", "proc_id": "178243", "abstract": "<p>Advanced processor and machine architectures need optimizing compilers to be efficiently programmed in high level languages. Therefore the need for source level debuggers that can handle optimized programs is rising. One difficulty in debugging optimized code arises from the problem to determine the values of source code variables. To ensure correct debugger behaviour with optimized programs, the debugger not only has to determine the variable's storage location or associated register. It must also verify that the variable is <italic>current</italic>, i.e. the value determined from that location is really the value that the variable would have in unoptimized code. We will deduce requirements on algorithms for currentness determination and present an algorithm meeting this requirements that is more general than previous work. We will also give first experiences with an implementation. To our knowledge this is the first implementation of a currentness determination algorithm for globally optimized code.</p>", "authors": [{"name": "Roland Wism&#252;ller", "author_profile_id": "81100053874", "affiliation": "Institut f&#252; Informatik (Department of Computer Science), Technische Universit&#228; M&#252;nchen (Munich University of Technology), D-80290 M&#252;nchen, Germany", "person_id": "P248343", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/178243.178430", "year": "1994", "article_id": "178430", "conference": "PLDI", "title": "Debugging of globally optimized programs using data flow analysis", "url": "http://dl.acm.org/citation.cfm?id=178430"}