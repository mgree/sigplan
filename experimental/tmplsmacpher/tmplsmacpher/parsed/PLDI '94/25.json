{"article_publication_date": "06-01-1994", "fulltext": "\n On Slicing Programs with Jump Statements Hiralal Agrawal Bellcore 445 South Street Morristown, NJ 07960 \nhira42bellcore. com Abstract Program slices have potential uses in many software en\u00adgineering applications. \nTraditional slicing algorithms, however, do not work correctly on programs that con\u00adtain explicit jump \nstatements. Two similar algorithms were proposed recently to alleviate this problem. Both require the \nflowgraph and the program dependence graph of the program to be modified. In this paper, we propose an \nalternative algorithm that leaves these graphs intact and uses a separate graph to store the additional \nrequired information. WJe also show that this algorithm permits an extremely efficient, conser\u00ad vative \nadaptation for use with programs that contain only (structured jump statements. 1 Introduction A program \nslice of a program, P, with respect to a vari\u00adable, var, and a location, ioc, is a subprogram, Pt, of \nP such that P computes the same value(s) of var at ioc as that computed by P [29]. Program slices have \napplications in many areas including program under\u00adstanding, testing, debugging, maintenance, optimiza\u00adtion, \nparallelization, and integration of program ver\u00adsions (see, e.g., [1, 2, 12, 16, 19, 29]). Algorithms \nto compute program slices are based on finding the transitive closure of the data and control de\u00adpendence \nof the appropriate statement(s) in the pro\u00adgram [17, 24]. Although the algorithms to compute A preliminary \nposition paper on the work reported here was presented at the Workshop on Increasing the Practical Impact \nof Formal Methods for Computer-Aided Software Development: Soft ware Slicing, Merging and Integration, \nheld at Naval Post\u00adgraduate School, Monterey, California, october 13 15, 1993. Permission to copy without \nfee all or part of this material is granted provided that the copies are not made or distributed for \ndirect commercial advantage, the ACM copyright notice arid the title of the publication and its date \nappear, and notice is given that copying is by permission of the Association of Computing Machinery. \nTo copy otherwise, or to republish, requires a fee and/or specific permission. SIGPIAN 84-6/94 Odando, \nflorida USA 0 1994 ACM 0-89791 -662-xIWOO06..$=O control dependence in the presence of jump statements \nhave been available for some time [9, 10, 14], the algo\u00adrithms to decide which jump statements themselves \nto include in a slice have obtained relatively little atten\u00adtion (see Section 5, Related Work). Even \nthe struc\u00adtured derivatives of the goto statement such as the break, continue, and return statements, \nas in C, have not been adequately considered in this contextl. Not surprisingly, use of program slices \nwithout the relevant jump statements included in them may produce mis\u00adleading results in many applications \nmentioned above. Two similar algorithms to determine which jump statements to include in a slice were \nproposed recently by Ball and Horwitz [5] and Choi and Ferrante [8]. Both algorithms require that the \ncontrol dependence graph of a program be constructed from an aug\u00admented control flowgraph of the program \nwhile the data dependence graph be constructed from the the standard control flowgraph, In this paper \nwe present an alternative algorithm that does not require the con\u00adstruction of the augmented flowgraph. \nInst cad, it re\u00adquires that a separate lexical successor tree of the program be maintained. The algorithm \nworks by first finding the statements included in the slice by the con\u00adventional slicing algorithm and \nthen determining the appropriate jump statements to be included in the slice. A jump statement is added \nto the slice if its nearest postdominator in the slice is different from its nearest lexical successor \nin the slice. Our algorithm has the same precision as that of Ball and Horwit z and Choi and Ferrante. \nIt is, however, appealing in that it leaves the flowgraph and the pro\u00adgram dependence graph of the program \nintact and uses a separate graph to store the additional required infor\u00admation. More importantly, it \nlends itself to substantial simplification when all jump statements in a program are structured jump \nstatements, such as break, con\u00adtinue, and return statements, or goto statements that I we use the tem \n~~jup ~taternent here to refer tO bOth the goto statement as well as its structured derivatives such \nas the break, continue and return statements. 1: sum=O; 2: positives= O; 3: while (Ieofo) ( 4: read(x); \n2 positives= O; 5: if (x <= O) 3 while (!eofo) { 6 sum = sum+ fl (x); 4 read(x); else{ s if(xc=O) 7; \npositives = positives+ 1; else { 8: if (x%2 == O) 7: positives = positives+ 1: 9: sum = sum + f2(x); \n) else ) 10: eum = eum + f3(x); 12: write(positives); ) (b) the slice obtained using the conventional \nalgorithm 11: write(sum); 12: wtite(positives); (a) an example program Figure 1: An example program without \nany jump statements and its program slice with respect to posi\u00adtives on line 12. transfer control in \nthe forward direction. In this case, only those jump statements that are directly control dependent on \na predicate in the slice need to be con\u00adsidered for possible inclusion in the slice. The simpli\u00adfied \nalgorithm, in turn, directly leads to a conservative approximation algorithm that permits on-the-fly \ndetec\u00adtion of the relevant jump statements to be included in the slice while applying the conventional \nslicing algo\u00adrithm. This algorithm is extremely efficient and should suffice for use with most programs \nwritten in modern procedural languages. In the next section, we review the conventional slic\u00ading algorithm \nused to find slices of programs that do not cent ain any jump statements. In Section 3, we propose a \ngeneral algorithm to determine which jump statements to include in a slice when the program un\u00adder consideration \ncontains jump statements. Then, in Section 4, we discuss how this algorithm maybe simpli\u00adfied for use \nwith programs that contain only structured jump statements. Finally, we discuss related work in Section \n5 and summarize our results in Section 6.  2 The Conventional Slicing Al\u00adgorithm The conventional slicing \nalgorithm involves finding the transitive closure of the data and control dependence of the appropriate \nnode(s) in the program dependence graph of the program [17, 24]. The program depen\u00ad dence graph of a \nprogram is obtained by merging its data and control dependence graphs, which depict the inter-statement \ndata and control dependence, respec\u00ad tively, in the program. For example, consider the program in Figure \nl-a and 1 2 8 w (b) data dependence graph (a) flowgraph (c) control dependence graph (d) program dependence \ngraph Figure 2: Various graphs of the program in Figure l-a. The shaded nodes represent the statements \nincluded in the slice by the conventional slicing algorithm. its slice with respect to positives on line \n12. Figure 2 shows the flowgraph and the data-, control-, and pro\u00adgram dependence graphs of this program. \nNode 12 is data dependent on nodes 2 and 7 as the assignments on lines 2 and 7 assign a value to positives \nthat may be used by the write statement on line 12. Node 7 is control dependent on node 5 as the ij statement \non line 5 determines whether or not the assignment on line 7 is executed. The shaded nodes in the program \ndependence graph in Figure 2-d depict the nodes in the transitive closure of the data-and control dependence \nof node 12. Figure l-b shows the corresponding pro\u00adgram slice.  3 Finding the Relevant Jump Statements \n A jump statement does not assign a value to any vari\u00adable. Thus no statement may be data dependent on \nit. Also, a jump statement is not a predicate. SO no statement may be control dependent on it. Hence, \nthe 2: positives = O; 3: L3: if (eofo) goto L1 q 1: sum =O; 4 read(x); 2: positives = O; 5: if (x > \nO)goto L8; 3: L3: if (eofo) goto LI ~ 8: L8: positives = positives+ 1; 4: read(x); L14: 5: if (x > \nO) goto L&#38; 15: write(posifives); 6: sums sum + fl (x); (b) tbe slice obtained using 7: gotoL13; \nthe conventional algorithm 8: L8:positives =positives+l; 9: if (x%2 != O) goto LI 2; 2: positives = O; \n10: sum = sum+ f2(x); 3: L3: if (eofo) goto L1~ 11: goto LI 3; 4: read(x); 12: L12:sum=sum+f3(x); 5: \nif (x > O) goto L8; 13: L13:goto L3; 7: gotoL13; 14 L14write(sum); 8: L8: positives= positives+ 1; 15: \nwrite(posifives); 13: L13: goto L3; L14 (a) a goto version of 15: write(positives);the example program \n(c) the slice obtained using the new algorithm Figure 3: A goto version of the program in Figure l-a, \nand its program slice with respect to posi\u00adtives on line 15. conventional slicing algorithm may not cause \nany jump statement to be included in a slice. It is easy to adapt the conventional slicing algorithm \nto determine which conditional jump statements, such as those on lines 3 and 5 in Figure 3-a, to include \nin a slice: If the predicate in a conditional jump statement is included in a slice because some other \nstatement is control dependent on it, then the associated jump must also be included, for the predicate \nwill not serve any purpose in the slice without the accompanying jump. Hereafter, we will use the phrase \nconventional slicing algorithm to refer to this adaptation of the conven\u00adtional slicing algorithm. Figure \n3-a shows a program with goto statements that is equivalent in functionality to that in Figure l-a. Figure \n3-b shows its slice with respect to positives on line 15 obtained using the conventional slicing algo\u00adrit \nhm. Unfortunately, unlike the original, program, the slice fails to ensure that the assignment on line \n8 is executed iff z > 0 because it does not include the rele\u00advant unconditional jump statements. Figure \n3-c shows the correct slice. Note that although the unconditional jumps on lines 7 and 13 are included \nin it, that on line 11 is not. The same situation occurs in the presence of break, continue, and return \nstatements, which may be thought of as special cases of the unconditional goto statement wit h their \ntargets implicit 1y defined. Figure 5-a shows a program with continue statements that is equiva\u00adlent \nin functionality to the program in Figure 3-a. Figure 5-b shows the corresponding slice with respect \nto positives on line 14 obtained using the conventional (b) postdominator tree (a) flowgraph (c) control \ndependence graph 1 6 (d) lexical successor tree Figure 4: Various graphs of the program in Figure \n3-a. The shaded nodes represent the statements included in the slice by the conventional slicing algorithm. \nslicing algorithm. Note that, without the relevant con\u00adtinue statement(s) in the slice, the assignment \non line 8 is incorrectly executed during each loop iteration irre\u00adspective of the value of x. Figure \n5-c shows the correct slice. Note that although the continue statement on line 7 is included in the slice, \nthat on line 11 is not. The question, then, is: how does one determine which unconditional jump statements \nto include in a slice? Consider a sequence, S1; S2; S3, of three state\u00adments in a program. Suppose S1 \nand S3 do not have any explicit jump statements embedded in them. Also suppose S1 and S3 belong to a \nslice obtained using the conventional slicing algorithm whereas S2 does not. If S2 is an assignment statement, \nthen control always passes from S1 to S2 to S3 in the original program. Deleting S2 from the program \nwill cause it to always transfer from S1 to S3. The same holds true if S2 is a compound statement, e.g., \nan if or a while statement, provided its body does not contain any explicit jump statement. If the body \nof S2 does contain one or more explicit jump statements, then control need not always pass 2: positives= \nO; 3: while (!eofo) { 1: sum=o; 4 read(x); Z positives = 0; 5 if (x<= O) { 3: while (!aofo) { ) 4 read(x); \n8: positives. positives +1; 5 if (x<= O) { ) 6 aum = sum + fl (x); 14 wnte(positives);7: continue; Pg0t01ine3 \n/ ) (b) the slice obtained using 8 posiives = pesitives + 1; fhe conventional algorithm 9: i (x%2== o) \n( 10 sum = sum + f2(x); 2 posfives. 0; 11: continu% r goto Hne 3 1 3: while (Ieofo) ( } 4 read(x); 12 \nsum = sum+ f3(x); 5 If(x <= o) { } 7 contmu% r goto fine 3 al 13: write(sum); ) 14 write(positives); \n&#38; posilvess posltwee + 1; (a) a continue version of )the example program 14 wrke(pasitivaa); (c) \nthe slice obteirred using the new slgorifhm Figure 5: A continue version of the program in Figure 3-a \nand its slice with respect to positives on line 14. from S2 to S3 in the original program as the explicit \njump(s) in S2 may cause the control to transfer else\u00adwhere. In this case we may not omit S2 from the \nslice, because otherwise, unlike in the original program, the control will always pass unconditionally \nfrom S1 to S3 in the slice. We need not, however, include all state\u00adments in S2 in the slice. We only \nneed to include certain jump statements in it along with the statements they transitively depend on. \nThis is required because in the presence of jump statements, the statement that lexi\u00adcally follows a \nstatement in a program need not also be its immediate post dominator, as discussed below. A statement, \nS , is said to postdominate a statement, S, in a program if S dominates [3] S in the reverse flowgraph \nof the program. In other words, S post\u00addominates S if every path from S to the exit node in the flowgraph \ncontains S . S is said to be the im\u00admediate postdomznator of S if every other postdomi\u00adnator of S also \npostdominates S . The postdomina\u00adtor relationship among statements maybe represented in the form of a \npost dominator tree. S postdomi\u00adnates S iff S is an ancestor of S in the postdomi\u00adnator tree. Algorithms \nused to construct dominator trees [3, 13, 20, 25] may also be used to construct post dominator trees. \nPost dominator trees are also re\u00adquired by the algorithms used to construct the con\u00adtrol dependence graphs \nof programs that cent ain jump statements [9, 10]. Figures 4-b and 6-b show the post\u00ad dominator trees \nof the programs in Figures 3-a and 5-a, respectively. A statement, S, is said to be the immediate lexical \nsuccessor of a statement, S, in a program if deleting S (b) postdominator tree (a) flowgraph >. d 7 \n.;* 96 ,.: 10 11 12 k (d) lexical successor tree (c) control dependence graph Figure 6: Various graphs \nof the program in Figure 5-a. The shaded nodes represent the statements included in the slice by the \nconventional slicing algorithm. from the program will cause the control to pass to S whenever it reaches \nthe corresponding location in the new program2. This notion of the immediate lexical successor is the \nsame as that of the continuation state\u00adment in [5] and the fall-through statement in [8]. Like the postdominator \nrelationship, the lexical succes\u00adsor relationship may be represented graphically in the form of a lexical \nsuccessor tree. It may be constructed in a purely syntax directed manner. A statement, S, is said to \nbe a lexical successor of a statement, S, in a program if S is an ancestor of S in the lexical succes\u00adsor \ntree of the program. Figures 4-d and 6-d show the lexical successor trees of the programs in Figures \n3-a and 5-a, respectively. In a program that does not contain any jump state\u00adments, the immediate lexical \nsuccessor of a statement is always the same as its immediate post dominator. In other words, the lexical \nsuccessor and the post domina\u00adtor trees of such programs are identical. Consequently, 2 If S ie a compound \nstatement, such ae an i.f or a while etate\u00adment, deleting it meane deleting it along with the staternente \nthat constitute ite body. Slice = the slice obtained using the conventional slicing algorithm, do { \n Traverse the postdominator tree using the preorder traversal, and for each jump statement, J, encountered \nthat is (i) not in Slice and (ii) whose nearest postdominator in Slice is different from the nearest \nlexical successor in Slice) do { Add J to Slicq Add the transitive closure of the dependence of J to \nSlica ) ) until no new jump statements maybe added to Slicg For each goto statement, Goto L, in Slice, \nif the statement labeled L is not in Slice then associate the label L with its nearest postdominator \nin Slicq return (Slice); Figure 7: An algorithm to find slices of programs with jump statements. a slice \nof such a program may be constructed by delet-It employs the preorder traversal of the postdominator \ning all those statements from the program that are not tree. selected for inclusion in the slice by the \nconventional Figure 4 shows the flowgraph, the postdominator slicing algorithm. For a program that cent \nains jump tree, the control dependence graph, and the lexical suc\u00adstatements, however, the lexical successor \nof a state-cessor tree of the program in Figure 3-a. Nodes with ment need not also be its immediate postdominator. \nthick outlines in these graphs denote unconditional Hence, we may not obtain a slice of such programs \njump statements3. by simply deleting the statements not selected by the The shaded nodes in the graphs \nin Figure 4 repre\u00adconventional slicing algorithm. We must also include sent statements included in the \nslice by the conven\u00adcertain jump statements, as well as the statements they tional slicing algorithm. \nDuring the preorder traversal transitively depend on, to ensure that the statements of the postdominator \ntree, Node 13 is the first jump included in the slice by the conventional slicing algo-statement encountered. \nFigures 4-b and 4-d show that rithm get executed in the same relative order as in the nodes 3 and 15 \nare the nearest post dominator and the original program. nearest lexical successor nodes, respectively, \nof node 13 The decision about whether or not to include a jump in the slice. As the two are different, \nnode 13 is in\u00adstatement, J, in a slice depends on whether or not its cluded in the slice. Its inclusion \ndoes not cause any nearest postdominator in the slice is the same as its other nodes to be included in \nthe slice as the nodes on nearest lexical successor in the slice. If the two are which it is control \ndependent are already in the slice. different, we must include J as well as the closure of Node 7 is \nthe next jump node encountered during the its dependence in the slice, which, in turn, may cause preorder \ntraversal of the postdominator tree. As the other jump statements to be included in the slice. If, nearest \npostdominator and lexical successor of node 7 however, the nearest postdominator of J in the slice in \nthe slice are also different, it too is included in the is the same as its nearest lexical successor \nin the slice, slice. Node 11 is the only remaining jump node not then omitting J from the slice will \nnot adversely affect yet examined. Inclusion of node 13 in the slice above the flow of control among \nthe statements included in makes it both the nearest postdominator as well as the the slice. nearest \nlexical successor of node 11 in the slice. There- As the inclusion or exclusion of one jump statement \nfore, node 11 is not included in the slice. Figure 3-c in a slice may affect the inclusion or exclusion \nof an-shows the final program slice. other jump statement, care must be taken in the order Figure 8-a \nshows another version of the program in in which various jump statements are considered for Figure 3-a \nwhere the indirect jumps from lines 7 and 11 possible inclusion in the slice. Preorder traversal of the \nvia line 13 to line 3 have been replaced with direct postdominator tree, where a node is visited before \nany jumps to line 3. Figure 9 shows the corresponding of its children are visited, ensures that all jump \nstate-graphs for this program. Node 7 is the first jump ments are examined in the desired order. Alternatively, \nstatement visited during the preorder traversal of the the preorder traversal of the lexical successor \ntree may 3The control dependence graph also contains a dumm y pred\u00ad be used. Figure 7 shows an algorithm \nto determine icate node, viz., node O. All top-level nodes nodes that are not which statements to include \nin a slice when the pro-control dependent on any predicate in the progran-are made gram under consideration \ncontains jump statements. control dependent on this node. 2 positives. O; 3: L3 if (eofo) goto L14; 4 \nread(x); 1: sum=0; 5: il(x>O)gotoL&#38; 2 positivffi. &#38; 8: W positives. Pc6itives + 1; 3 L3:lf(eofo)gotoLl~ \nL14 4 read(x); 15 write(pmsitives); 5 if (x > O)goto La (b) tbe slice obtained using 6 sum = sum+ fl \n(x); the conventional algorithm 7 goto L3; &#38; L&#38;poaitives .poaitives+l; 2 positwes = O; 3: L3: \nif (eofo) goto Ll~ 9 if (x%2 1=O) goto L12 4 read(x); 5 if (x > O) goto L8; 10: sum = sum + f2(x); 11: \ngoto L3; 7 goto L3; 12 LIz sum= sum+ f3(x); 8: L8: positives= peaitivss + 1; 13 goto L3; 9: tf (x %2 \n1=O) goto L1.2f 14: L14:write(sum); 11: goto L3; 15: write(pdtives); L12 t3: goto L3 of the example program \nL14 (a) another goto version 15 wrle(positives); (c) the slice obtained using the new algoritbnr Figure \n8: Another goto version of the program in Figure 3-a and its slice with respect to positives on line \n15. postdominator tree. As its nearest postdominator and lexical successor nodes in the slice are different, \nit is included in the slice. Further traversal of the post dom\u00adinator tree causes nodes 11 and 13 to \nalso be included in the slice. Their inclusion, in turn, causes node 9 to be included in the slice, as \nboth nodes 11 and 13 are control dependent on it, as shown in Figure 9-c. Figure 8-c shows the final \nprogram slice. For both examples above, a single traversal of the postdominator tree waa sufficient, \ni.e., no new nodes could be added to the slice after the first traversal. For some uncommon programs, \nthough, multiple traversals of the postdominator tree may be required. Consider, for example, the program \nin Figure 10-a, adapted from a similar example in [5], and its slice with respect to y on line 9. Figure \n11 shows the corresponding graphs. During the first preorder traversal of the postdomina\u00adtor tree, node \n4 is not added to the slice as its nearest postdominator and the nearest lexical successor are the same, \nviz., node 9. Nodes 7 and 2, however, are added to the slice aa their nearest postdominator and lexi\u00adcal \nsuccessors in the slice are different. The addition of node 2, in turn, causes node 1 to be added to \nthe slice as the former is control dependent on the latter. Also, the addition of node 7 to the slice \nduring the first traversal causes it to become the nearest lexical succes\u00adsor of node 4 in the slice. \nNode 9, on the other hand, continues to be its nearest post dominator in the slice. Thus node 4 is added \nto the slice during the second pre\u00adorder traversal of the postdominator tree. Figure 10-b shows the final \nprogram slice. The algorithm in Figure 7 uses the preorder traversal (b) postdominator tree ! 9 ,..., \n(01   /-,..;.<:. dif q$ihitl7 (a) flowgraph (c) control dependence graph @ (d) lexical successortree \nFigure 9: Various graphs of the program in Figure 8-a. The shaded nodes represent the statements included \nin the slice by the conventional slicing algorithm. of the postdominator tree to decide the order in \nwhich jump statements are examined for possible inclusion in the slice. As mentioned earlier, we could \nalso have used the preorder traversal of the lexical successor tree. Al\u00adthough the choice of the tree \nused to drive the search may cause a difference in the number of traversals re\u00adquired, the same final \nslice is obtained in each case. While one method may require less traversals than the other in the case \nof one slice, the opposite may be true in the case of another slice. Multiple traversals are required, \nin general, when a program contains a pair of nodes, iVl and lVz, such that iV1 postdominates IVz and \nIVz lexically suc\u00adceeds N1. For example, consider nodes 4 and 7 in Figures 1l-b and 1l-d. Whereas node \n4 postdominates node 7, node 7 lexically succeeds node 4. When a pro\u00adgram contains no such pairs, a single \ntraversal is suffi\u00adcient to identify all jump statements to be included in a slice. As the programs in \nFigures 3 and 8 contain no such pairs, a single traversal of the post dominator tree was sufficient to \nobtain slices of those programs4. It can be shown that the algorithm in Figure 7 always produces correct \nprogram slices. Alternatively, it can 4This is not to say that multiple traversals are always required \nwhenever a program cent ains such pairs. 1: if (Cl){ 2 geto L6; 1: if (Cl) ( 3 L3: y=...; 2: goto L6; \n4 goto I-S; 3: L3: y= ...; ) 4 ) goto L8; 5 z= .... L&#38; 6 L6: x= .... ? goto L3; ? goto u; L8 &#38; \nL&#38; write(xh 9: wriie( y);, 9 write(y); 10 write(z); (b) tbe slice obtained using (a) the originel \nprogram the new rdgoritbm Figure 10: An unstructured program and its slice with respect to y on line \n9.  be shown that a statement is included in a slice by this algorithm iff it is included in the corresponding \nslice obtained using Ball and Horwitz s algorithm [5]. Ball and Horwitz have shown that their algorithm \nalways yields correct slices. Hence the equivalence of the two algorithms may also be used to infer that \nthe algorithm in Figure 7 produces correct slices. 4 Slicing Programs with Struc\u00adtured Jumps A jump statement \nis said to be a structured jump state\u00adment if its target statement is also its lexical successor. Break, \ncontinue, and return statements, as in C, are ex\u00adamples of structured jumps aa they all pass control \nto their lexical successors, though not necessarily to their immediate lexical successors. A program \nis said to be a structured program if all jump statements in it are structured jump statements. Otherwise, \nit is said to be an unstructured program. It can be shown that a structured program always satisfies \nthe following two properties: 1. It does not contain any pair (iVi, Nj ) of nodes such that Nt is a postdominator \nof Nj and Nj is a lex\u00adical successor of Nt. 2. If a jump statement, J, is directly control depen\u00addent \non a predicate, P, then J will not be included in a slice if P is not included in it by the conven\u00adtional \nslicing algorithm.  The first conclusion implies that for structured pro\u00adgrams, a single traversal of \nthe postdominator tree is sufficient to identify all jump statements to be included in a slice. The second \nconclusion implies that a jump statement may be included in a slice only if a predi\u00adcate on which it \nis directly control dependent is also included in the slice. It also implies that when a jump statement \nis included in a slice, there is no need to explicitly include the closure of its dependence in the 10 \nQ 7 5 6 14 251  d iib iii (b) postdominator tree (d) lexical successor tree 25 cm (c) control dependence \ngraph Figure 11: Various graphs of the program in Figure 10-a. The shaded nodes represent the state\u00adments \nincluded in the slice by the conventional slicing algorithm. slice as they have already been included \nin it. Conse\u00ad quently, we may simplify the algorithm in Figure 7 for use with structured programs to \nthat shown in Fig\u00adure 12. The program in Figure 5-a is a structured program. The simplified algorithm \nin Figure 12 will yield the same slice as that obtained using the algo\u00adrithm in Figure 7 for this program \nfor all slicing criteria. For example, both algorithms will find the same slice with respect to positives \non line 14 the slice shown in Figure 5-c. Figure 13 shows a further simplification of the algo\u00adrithm \nin Figure 12. It does not require any preorder traversals of the postdominator tree nor does it require \nthat the lexical successor tree of the program be avail\u00adable. It is, however, a conservative simplification \nof the algorithm in Figure 12. A slice obtained using the former may include more jump statements than \nthat obtained using the latter. This is so because, unlike the algorithm in Figure 12, the algorithm \nin Figure 13 includes any jump statement in the slice that is directly control dependent on a predicate \nin the slice, even if its nearest postdominator and lexical successor nodes in the slice are the same. \nSlice = the slice obtained using the conventional slicing algorithm; Traverse the postdominator tree \nusing the preorder traversal, and add each jump statement encountered that is (i) directly control dependent \non a predicate in Slice and (ii) whose nearest postdominator in Slice is different from its nearest lexical \nsuccessor in Slice, to Slice; For each goto statement, Goto L, in Slice, if the statement labeled L is \nnot in Slice then associate the label L with its nearest postdominator in Slice; return (Slice); Figure \n12: An algorithm to find slices of programs with structured jump statements. Slice = the slice obtained \nusing the conventional slicing algorithm, Add all jump statements that are directly control dependent \non a predicate in Slice, to Slicq For each goto statement, Goto L, in Slice, if the statement labeled \nL is not in Slice, then associate the label L with its nearest postdominator in Slicq return (Slice); \n Figure 13: A conservative algorithm to find slices of programs with structured jump statements. For \nthe example shown in Figure 5-a, this algorithm bugging, verification, maintenance, regression testing, \nwill give the same slice as that given by the algorithm automatic parallelization of program execution, \nauto\u00adin Figure 12. Figure 14-a shows an example of a struc-matic integration of program versions, and \nsoftware tured program for which the algorithm in Figure 13 metrics (see, e.g., [1, 2, 6, 12, 16, 19, \n21, 23, 29]). may yield a bigger slice than that given by the algo-None of the references cited above, \nhowever, addresses rithm in Figure 12. Figures 14-b and 14-c show its two the question of how to determine \nthe appropriate jump slices with respect to y on line 9 obtained using the two stat ements to include \nin a slice. algorithms. Note that the latter slice also includes the Lyle proposed an extremely conservative \nalgorithm jump statements on lines 5 and 7 that are not included to determine which jump statements to \ninclude in a in the former. slice [22]. Suppose a statement, S, is included in a slice with respect to \na variable, var, and a location, !OC, in a program. Then, except in certain degenerate cases, 5 Related \nWork Lyle s algorithm will include all jump statements that lie between S and 10C in the control flowgraph \nof the The concept of program slicing was first proposed by program, in the slice. For example, consider \nthe exam-Weiser [29]. He also presented an algorithm to compute ple in Figure 5. Unlike any of the algorithms \npresented program slices based on an iterative solution of data-in this paper, L yle s algorithm will \nalso include the flow equations. His algorithm was able to determine continue statement on line 11, and \ntherefore the pred\u00adwhich predicates to include in the slice even when the icate on line 9, in the slice. \nSimilarly, it will include program contained jump statements. It did not, how-all goto statements and \nall predicates in the example ever, make any attempt to determine the relevant jump in Figure 3, although \nsome of them could be omitted. statements themselves to be included in the slice. Gallagher proposed \na modification of the above al- Use of the program dependence graph to compute gorithm where a jump statement, \nGoto L, is included program slices was first proposed by Ottenstein and Ot-in a slice only if a statement \nin the block labeled L and tenstein [24]. They proposed a slicing algorithm based the predicates on which \nthe jump statement is con\u00adon graph reachability in the program dependence graph trol dependent are included \nin the slice [11]. Although but they only considered the intraprocedural case. this algorithm only considered \nthe goto statement, we Horwitz, Reps, and Binkley extended the program de-assume it can be extended to \nhandle other jump state\u00adpendence graph representation to what they call the ments such as break and continue \nif we think of them system dependence graph to find interprocedural as having dummy labels associated \nwith them. Assum\u00ad program slices [17]. Several studies investigating the ing this extension, the above \nalgorithm will correctly semantic basis of program slicing have also been con-omit the continue statement \non line 11, and thus the ducted [7, 15, 26, 27, 28]. Uses of program slices have predicate on line 9, \nfrom being included in the slice been suggested in many applications, e.g., program de-in Figure 5. Unfortunately, \nthis algorithm may fail to 1: awtch (C) { caae 1: 3 brealr 1: avmch (C) { 4 } ease 2 y-...; 2 caael: \nx=...; 9 write(y); 3 break (b) the slice obtained using y=..,; 4: case 2 the simplified algorithm 5 \nbreatc 6 case 3: z = .... 1: switch (C) ( 7 break caael: 3: break a write(x); 4 case 2 y = .... 9 write(y); \n5 breals 10 writs(z); caaa 3 7. braa~ (a) the original program ) 9 write(y); (c) the slice obtained using \nthe conservative algorithm Figure 14: A structured program and its two slices with respect to y on line \n9 obtained using the algorithms in Figures 12 and 13. identify all relevant jump statements for inclusion \nin a slice in some other programs. Consider, for example, the program in Figure 16-a and its slice with \nrespect to y on line 10. Figure 16-b shows the incorrect slice obtained using the above algorithm. It \nfails to include the jump statement on line 4 because no statement in the block labeled L6 is included \nin the slice. Without this jump statement the assignment to y on line 5 will always be executed in the \nslice irrespective of the value of x, unlike in the correct slice, shown in Figure 16-c, where it is \nonly executed when x is nonnegative. Jiang, Zhou, and Robson have also proposed a set of rules to determine \nwhich jump statements to include in a slice [18]. Unfortunately their rules also fail to iden\u00adtify all \nrelevant jump statements. For example, they will fail to include both jump statements on lines 11 and \n13 in the slice in Figure 8. As mentioned in Section 1, recently two similar al\u00adgorithms to determine \nthe relevant jump statements to include in a slice were independently proposed by Ball and Horwitz [5] \nand Choi and Ferrante [8]. Both require that the control dependence graph of a pro\u00adgram be constructed \nfrom an augmented flowgraph of the program. The augmented flowgraph is obtained by adding new edges to \nthe flowgraph from the nodes rep\u00adresenting jump statements to the nodes that immedi\u00adately lexically succeed \nthem in the program. The data dependence graph, on the other hand, is constructed from the unaugmerzted \nflowgraph. Both algorithms, then, involve applying the conventional slicing algo\u00adrithm on the augmented \nprogram dependence graph obtained by merging the control-and the data depen\u00addence graphs. As mentioned \nearlier, our algorithm in Figure 7 has the same precision as that of the above two algorithms. It is, \nhowever, appealing in that it leaves the flowgraph 10 >*,,,8 (U) ~USIUU1llll~dlU1 10 t ..... (a) flowgraph \n(0) (c) control dependence graph (d) lexical successortree  Figure 15: Various graphs of the program \nin Figure 14-a. The shaded nodes represent the state\u00adments included in the slice by the conventional \nslicing algorithm. and the program dependence graph of the program in\u00adtact and uses a separate graph \nto store the additional required information. More import antly, it lends itself to substantial simplification, \nas discussed in the previ\u00adous section, when the program under consideration is a structured program. \nAlso, the simplified algorithm di\u00adrectly leads to a conservative approximation algorithm that permits \non-the-fly detection of the relevant jump statements while applying the conventional slicing al\u00ad gorithm. \nIt is unclear if the algorithms mentioned in the previous paragraph permit similar adaptations. Choi \nand Ferrante have also proposed another algo\u00adrithm to construct an executable slice in the presence of \njump statements when a slice is not constrained to be a subprogram of the original program [8]. This \nalgorithm, like our algorithm, proceeds by first find\u00ading the statements included in the slice by the \nconven\u00adtional slicing algorithm. Then, unlike our algorithm which finds the relevant jump statements \nin the orig\u00adinal program to include in the slice, it constructs new jump statements to add to the slice \nto ensure that other statements in it are executed in the correct order. Also, when a jump statement \nis added to a slice, it does not require the transitive closure of its control and data dependence to \nbe added to the slice. This may lead to construction of smaller slices compared to those produced by \nalgorithms that require a slice to be a subprogram of the original program. It may, however, cause the \nrelative nesting structure of statements in\u00adcluded in the slice to be different from that in the orig\u00ad \n1: read(x); 2 if(x< O){ 3: y= fl(x); 4 goto L6; ) 5: y = f2(x); 6 L6: if(y< O){ 7: z =gl(y); 8: goto \nL1O; } 9: z = g2(y); 10: L1O: write(y); 11: write(z); (a) an example progmnr 1: read(x); 2: if(xc O){ \n3: y= fl(x); ) 5: y = f2(x); 10: L1O: write(y); (b) incorrect slice 1: read(x); 2: if(xc O){ 3: y= fl(x); \n4 goto L6; ) 5: y = f2(x); L6 10: L1O: write(y); (c) the correct slice Figure 16: An example program \nand its slice with re\u00adspect to y on line 10. inal program. An alternative approach to find a slice that \nneed not be a projection of the original program would be, as noted by Ball and Horwitz [5], to apply \na flowgraph structuring algorithm [4] on the flowgraph induced by the statements included in the slice \nby the conventional slicing algorithm. Summary In a program with jump statements the lexical succes\u00adsor \nof a statement need not be the same as its imme\u00addiate postdominator. Hence, a slice obtained using the \nconventional slicing algorithm for such a program may not preserve the behavior of the original program \nwith respect to the slicing criterion. In this paper, we have proposed an algorithm that uses the lexical \nsuccessor and the postdominator trees of the program to iden\u00adtify the appropriate jump statements to \ninclude in a slice. We have also presented a simpler version of this algorithm for use with programs \nthat contain struc\u00adtured jump statements, and an efficient, conservative approximation algorithm that \ndoes not require the con\u00adstruction of the lexical successor tree of the program at all. Acknowledgements \nWe would like to thank Thomas Ball, Jong-Deok Choi, Jeanne Ferrante, and the anonymous referees for their \nuseful comments on an earlier draft of this paper.  References [1] H. Agrawal, R. A. DeMillo, and E. \nH. Spafford. Debugging with dynamic slicing and backtracking. Software Practice and Experience, 23(6):589-616, \nJune 1993. [2] H. Agrawal, J. R. Horgan, E. W. Krauser, and S. L. London. Incremental regression testing. \nIn Proceedings of the IEEE Conference on Sofiware Maintenance, pages 348 357. The IEEE Com\u00adputer Society \nPress, Sept. 1993. [3] A. V. Aho, R. Sethi, and J. D. Unman. Compil\u00aders: Principles, Techniques, and \nToots. Addison-Wesley, 1986. [4] B. S. Baker. An algorithm for structuring flow\u00adgraphs. Journal of the \nACM, 24(1):98-120, Jan. 1977. [5] T. Ball and S. Horwitz. Slicing programs with ar\u00adbitrary control flow. \nIn Proceedings of the 1st In\u00adternational Workshop on Automated and Algorith\u00admic Debugging (Lecture Notes \nin Computer Sci\u00adence 749), pages 206 222. Springer-Verlag, Nov. 1993. [6] J.-F. Bergeretti and B. A. \nCarr6. Information-flow and data-flow analysis of while programs. ACM Transactions on Programming Languages \nand Sys\u00adtems, 7(1):37-61, Jan. 1985. [7] R. Cartwright and M. Felleisen. The semantics of program dependence. \nIn Proceedings of the ACM SIGPLAN 89 Conference on Programming Lan\u00adguage Design and Implementation. ACM \nPress, June 1989. SIGPLAN Notices, 24(7):13-27, July 1989. [8] J.-D. Choi and J. Ferrante. Static slicing \nin the presence of GOTO statements. ACM Letters on Programmmg Languages and Systems, 1994. To appear. \n[9] D. E. Denning and P. J. Denning. Certification of programs for secure information flow. Communi\u00adcations \nof the ACM, 20(7):504 513, July 1977. [10] J. Ferrante, K. J. Ottenstein, and J. D. Warren. The program \ndependence graph and its uses in optimization. ACM Transactions on Programming Languages and Systems, \n9(3):319-349, July 1987. [11] K. B. Gallagher. Using Program Slicing for Pro\u00adgram Maintenance. PhD thesis, \nUniversity of Maryland, College Park, MaryLand, 1990. [12] K. B. Gallagher and J. R. Lyle. Using program \nslicing in software maintenance. IEEE Trans\u00adactions on Software Engineering, 17(8):751-761, Aug. 1991. \n 311 [13] D. Harel. A linear time algorithm for finding dom\u00adinators in flow graphs and related problems. \nIn Proceedings of the 17th ACM Symposium on The\u00adory of Computing, pages 185 194, May 1985. [14] M. J. \nHarrolci, B. Malloy, and G. Rothermel. EfE\u00adcient construction of program dependence graphs. In Proceedings \nof the 1993 International Sympo\u00adsium on Sofiware Testing and Analysis (ISSTA), pages 160-170. ACM Press, \nJune 1993. [15] P. Hausler. Denotational program slicing. In Pro\u00adceedings of the Twenty-Second Annual \nHawaii In\u00adternational Conference on System Sciences, vol\u00adume II, pages 486 494, 1989. [16] S. Horwitz, \nJ. Prins, and T. Reps. Integrating noninterfering versions of programs. ACM Trans\u00adactions on Programming \nLanguages and Systems, 11(3):345-387, July 1989. [17] S. Horwitz, T. Reps, and D. Binkley. Interpro\u00adcedural \nslicing using dependence graphs. ACM Transactions on Programming Languages and Sys\u00adtems, 12(1):26-60, \nJan. 1990. [18] J. Jiang, X. Zhou, and D. J. Robson. Program slicing for C the problems in implementation. \nIn Proceedings of the IEEE Conference on Soflware Maintenance. IEEE Computer Society Press, Oct. 1991. \n[19] B. Korel and J. Laski. Dynamic slicing of com\u00adputer programs. Journal of Systems and Soflware, 13(3):187-195, \nNov. 1990. [20] T. Lengauer and R. E. Tarjan. A fast algorithm for finding dominators in a flowgraph. \nACM Trans\u00adactions on Programming Languages and Systems, 1(1):121-141, July 1979. [21] H. Longworth, L. \nOtt, and M. Smith. The re\u00adlationship between program complexity and slice complexity during debugging \ntasks. In Proceedings of COMPSA C. IEEE Computer Society Press, 1986. [22] J. R. Lyle. Evaluating Variations \non Program Slicing for Debugging. PhD thesis, University of Maryland, College Park, MaryLand, 1984. [23] \nL. Ott and J. Thuss. The relationship between slices and module cohesion. In Proceedings of the Eleventh \nInternational Conference on Soflware Engineering. IEEE Computer Society Press, May 1989. [24] K. J. \nOttenstein and L. M. Ottenstein. The program dependence graph in a software de\u00advelopment environment. \nIn Proceedings of the ACM SIG SOFT/SIGPLAN Symposium on Prac\u00ad tical Software Development Environments. \nACM Press, Apr. 1984. SIGPLAN Notices, 19(5):177\u00ad 184, May 1984. [25] P. W. Purdom, Jr. and E. F. Moore. \nImmediate predominators in directed graphs. Communica\u00adtions of the ACM, 15(8):777-778, Aug. 1972. [26] \nT. Reps and W. Yang. The semantics of program slicing. Technical Report TR-777, Computer Sci\u00adence Department, \nUniversity of Wisconsin, Madi\u00adson, Wisconsin, June 1988. [27] R. P. Selke. A rewriting semantics for \nprogram dependence graphs. In Conference Record of the Sixteenth ACM Symposium on Principles of Pro\u00adgramming \nLanguages, pages 12 24. ACM Press, Jan. 1989. [28] G. A. Venkatesh. The semantic approach to pro\u00adgram \nslicing. In Proceedings of the SIGPLAN 91 Conference on Programming Language Design and Implementation. \nACM Press, June 1991. SIG-PLAN Notices, 26(6):107-119, June 1991. [29] M. Weiser. Program slicing. IEEE \nTransactions on Software Engineering, SE-10(4):352 357, July 1984. \n\t\t\t", "proc_id": "178243", "abstract": "<p>Program slices have potential uses in many software engineering applications. Traditional slicing algorithms, however, do not work correctly on programs that contain explicit jump statements. Two similar algorithms were proposed recently to alleviate this problem. Both require the flowgraph and the program dependence graph of the program to be modified. In this paper, we propose an alternative algorithm that leaves these graphs intact and uses a separate graph to store the additional required information. We also show that this algorithm permits an extremely efficient, conservative adaptation for use with programs that contain only &#8220;structured&#8221; jump statements.</p>", "authors": [{"name": "Hiralal Agrawal", "author_profile_id": "81452609139", "affiliation": "Bellcore, 445 South Street, Morristown, NJ", "person_id": "P110654", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/178243.178456", "year": "1994", "article_id": "178456", "conference": "PLDI", "title": "On slicing programs with jump statements", "url": "http://dl.acm.org/citation.cfm?id=178456"}