{"article_publication_date": "06-01-1994", "fulltext": "\n Counting Solutions to Presburger Formulas: How and Why William Pugh http: Univ. pugh@cs .umd. edu //www. \ncs. umd. edu/f acuity/pugh Dept. of Computer Science of Maryland, College Park, MD .html 20742 Abstract \nRedescribe methods that areable to count the number of integer solutions to selected free variables of \na Presburger formula, or sum a polynomial over all integer solutions of selected free variables of aPresburger \nformula. This answer is given symbolically, in terms of symbolic constants (the remaining free variables \nin the Presburger formula). For example, we can create a Presburger formula who s solutions correspond \ntotheiterations ofa loop. Bycormting these, we obtain an estimate of the execution time of the loop. \nIn more complicated applications, we can create Pres\u00ad burger formulas who s solutions correspond to the \ndistinct memory locations or cache lines touched by a loop, the flops executed by a loop, or the array \nelements that need to be communicated at a particular point in a distributed compu\u00adtation. By counting \nthe number of solutions, we can evaluate the computation/memory balance of a computation, deter\u00admine \nif a loop is load balanced and evaluate message traffic and allocate message buffers. Introduction In \nthis paper, we describe methods that are able to count the number of integer solutions to selected free \nvariables of a Presburger formula, or sum a polyno\u00admial over all integer solutions of selected free variables \nof a Presburger formula. This answer is given symboli\u00adcally, in terms of symbolic constants (the remaining \nfree variables in the Presburger formula). This answer can be given symbolically, in terms of symbolic \nconstants (other free variables in the Presburger formula). Pres\u00adburger formulas are those formulas that \ncan be built up out of linear constraints over integer variables, the Permissionto co without fee all \nor pan of this material is grantedpovi,e$~ t at the ccrpks are not made or distributed for direct commercial \nadvantage, the ACM mpyright notice and the title of the publication and its date appear, and notice is \ngiven that copyin is by permission of the Association of Computing Machinery. f o copy otherwise, or \nto republish, requires a fee andor specific permission. SIGPIAN 94-6/94 Orlando, Florfda USA @ 1994 ACM \nO-89791-662-XJWIOO06..$3.5O usual logical connective A , V , m, and existential and universal quantifiers. \nThe following table gives some simple examples of traditional symbolic summations: Sum Answer 10 &#38;1 \n~x;=, 1 n (ifn>l) n (ifn>1) Xi=lZ; 11 * (ifnz2) Z:=l X;=i+l 1 I A number of symbolic math packages (such \nas Math\u00adematical and Maple) are able to compute symbolic sums. However, the methods they use assume that \na sum\u00admation is never empty (i.e., the lower bound is never greater than the upper bound). The answer \nthey give is incorrect if this assumption is violated. For example, Mathematical reports that is =~(m-z+~)=n(z~;n+l) \ni=l j=i i=l In fact, this answer is valid only if 1 < n ~ m. If 1< m <n, the answer is m(m + 1)/2. The \nnotation used above strongly suggests that the sum over j must be performed before the sum over i. In \nour work, we don t assume any predefine order in which the variables must be eliminated. We also allow \narbitrary constraints, not just a upper and lower bound on each variable. We therefore use a more generaJ \nno\u00adtation: (xvi,...,vm : P : z) is the sum, for all values of VI, ..., v~ that satisfy P (a Presburger \nformula with free variables), of Z. As a special case, (2 VI,.,., Vm : P : 1) is the number of solutions \nof VI ,. ... Vm to P. Any variables appearing free in P or z and not in V are assumed to be symbolic \nconstants. The answer ret urned will be in terms of the symbolic constants. Since answers may need to \nbe guarded (i.e., n2 if n ~ 1), we utilize the nullary form of a summation to in\u00addicate a guarded sum. \nIf V is empty (i.e., (X : P : z)) 121 the result is a conditional value: if P is true, the value of this \nexpression is Z, otherwise O. As an example, our previous summations would be reported as: (Ei : l<i~lO: \n1) = 10 (Xi : l<i<n :l)=(z:l<n:n) (.M,j : l<i, j<n:l)=(X:l<n:n2) 72(?2 1) (Zi,j : lsi<j <n: l)=(X:2 <n: \n2) 1.1 Applications This capability has a number of applications in analysis and transformations of scientific \nprograms. Within pro\u00adgrams with affine loop bounds, guards and subscripts, we can define formulas who \ns solutions correspond to: e the flops executed by a loop . the memory locations touched by a loop . \nthe cache lines touched by a loop o the array elements that need to be transmitted from one processor \nto another during the execution of a loop (in a distributed memory multicomputer), By counting the number \nof solutions to these formulas, we can estimate the execution time of a code segment, compare the memory \nbandwidth requirements vs. the flop counts of a code segment, determine which loops will flush the cache, \nallowing us to calculate the cache miss rate [FST91], determine whether a parallel loop is load balanced \n(i.e., does each iteration perform the same number Of flOpS) [TF92] , given an unbalanced loop, assign \ndifferent number of iterations to each processor so that each proces\u00adsor gets the same total number of \nflops (Balanced chunk-scheduling, as described in [HP93a] ), quantify message traffic, and allocate space \nfor message buffers. In this paper, we Review the Omega test and how it can be used to simplify Presburger \nformulas (Section 2), Describe how to represent some nonlinear con\u00adstraints, such as z = ~y/3j, in Presburger \nformulas (Section 3). Describe techniques for computing sums, starting with the most simple forms of \nsummations and pro\u00adgressing to more general sums (Section 4).  Describe techniques for producing simplified \ncon\u00adstraints in disjoint disjunctive normal form. Pre\u00adviously, we have produced simplified constraints \nin (overlapping) disjunctive normal form. The need to do this is explained in Section 4.5.1 and techniques \nto do it are described in Section 5.  Show the application of our techniques to a number of examples \nand compare our techniques with rela\u00adtion work [FST91, TF92, HP93a, Taw94] (Section 6).  2 The Omega \ntest The Omega test [Pug92] was originally developed to check if a set of linear constraints had an integer \nso\u00adlution, and was initially used in array data dependence testing. Since then, its capabilities and \nuses have grown substantially. In this section, we describe the various capabilities of the Omega test. \n2.1 Eliminating an existentially quantified vari\u00adable The basic operation of the Omega test is the elimination \nof an existentially quantified variable, also refered to as shadow-casting or projection, For example, \ngiven a set of constraints P over z, y and z that define, for example, a dodecahedron, the Omega test \ncan compute the constraints on x and y that define the shadow of the dodecahedron. Mathematically, these \nconstraints are equivalent to 3Z s,t. P, But the Omega test is able to remove the existentially quantified \nvariables, and report the answer just in terms of the free variables (z and y). Over rational variables, \nprojection of a convex re\u00adgion aIways gives a convex result, Unfortunately, the same does not apply for \ninteger variables, For example, 2ys,t. l~y~4Ax=2yhas x=2,x =4, x=6 and x = 8 M solutions, Sometimes, \nthe result is even more complicated. For example, the solutions for z in: (~i,j : l~~<8Al <j<5Az=6i+9j \n7) are all numbers between 8 and 86 (inclusive) that have remainder 2 when divided by 3, exceDt for \n11 and 83. In general, the Omega test produces &#38; answer in dis\u00adjunctive normal form: the union of \na list of clauses. A clause may need to describe a nonconvex region. There are two methods of describing \nthese regions: Stride format The Omega test can produce clauses that consist of affine constraints over \nthe free vari\u00adables and stride constraints. A stride constraint c[e 122 is interpreted as c evenly divides \ne . In this form, the above solution could be represented as: Z=8V 14<z S80A3](Z+1) VX =86 Projected \nformat Alternatively, the Omega test can produce clauses that consist of a set of linear con\u00adstraints \nover a set of auxiliary variables and an affine 1-1 mapping from those variables to the free variables. \nUsing this format, the above solution could be represented as z=8v (3a: 55a~27Ax =3a l)V X=86 These two \nrepresentations are equivalent and there are simple and efficient methods for converting between the \ntwo of them. While the first representation is more intuitive, the second representation works better \nfor the purposes of this paper. Disjoint disjunctive normal form Normally, the Omega test does not produce \ndisjoint clauses: there may be assignments to the free variables that satisfy multiple clauses (i.e., \nthe clauses may overlap). For purposes of this paper, it is preferable to have disjoint clauses. This \nallows us to compute the summation by simply adding together the results of summing the individual clauses. \nIf a set of clauses are disjoint, we refer to this as disjoint disjunctive normal form. If two clauses \nare guaranteed to be disjoint, we denote their conjunction as P i-Q (as opposed to P V Q). In our previous \nwork, we did not need disjoint clauses. Some straightforward but naive methods would be capa\u00adble of converting \nan arbitrary disjunction normal form formula into disjoint disjunctive normal form. However, the cost \nof doing so would be quite high in many cases. In Section 5, we discuss some methods that allow us to \ndirectly generate disjoint disjunctive normal form (without first generating overlapping disjunctive \nnormal form) and more sophisticated methods for converting an arbitrary disjunctive normal form formula \ninto a disjoint disjunctive normal form. Disjoint disjunctive normal form may generate more clauses and \nrequire more time to generate than disjunctive normal form. 2.2 Verifying the Existence of Solutions \nThe Omega test also provides direct support for check\u00ading if integer solutions exist to a set of linear \nconstraints. It does this by treating all the variables as existentially quantified and eliminating variables \nuntil it produces a problem containing a single variable; such problems are easy to check for integer \nsolutions. The Omega test in\u00adcorporates several extensions over a naive application of variable elimination. \n 2.3 Removing Redundant Constraints In the normal operation of the Omega test, we eliminate any constraint \nthat is made redundant by any other sin\u00ad gle constraint (e.g., z + y ~ 10 is made redundant by z + y \n< 5). Upon request, we can use more aggressive techniques to eliminate redundant constraints. We use \nfast but incomplete tests that can flag a constraint as definitely redundant or definitely not redundant, \nand a backup complete test. This capability is used when ver\u00adifying implications and simplifying formulas \ninvolving negation. We also use these techniques to define a gist opera\u00adtor, which is defined such that \n(gist P given Q) is what is interesting about P, given that we already know Q. In other words, we guarantee \nthat ((gist P given Q) A Q) s PA Q and try to make the result of the gist opera\u00adtor aa simple as possible. \nMore formally, gist P given Q returns a subset of the constraint of P such that none of the constraints \nreturned are implied by the constraints of Q and the other constraints in the result. 2.4 Verifying \nImplications By using our ability to eliminate redundant constraints, we can verify formulas of the form \nP + Q, by checking to see if the constraints of P are redundant, given that the constraints of Q are \ntrue. (i.e., (gist P given Q) E True). We can combine this capability with our abil\u00adity to eliminate \nexistentially quantified variables to ver\u00adify more complicated formulas such as (3y s.t. P) + (3z sot. \nQ). 2.5 Simplifying Formulas Involving Negation There are two problems involved in simplifying formulas \ncent aining negated conjuncts, such as lO~Z+j, Z j <10 A 1(2si, jS12A21i+j) Naively converting such \nformulas to disjunctive normal form generally leads to an explosive growth in the size of the formula. \nIn the worst-case, this cannot be pre\u00advented. But we [P W93a] have described methods that are effective \nin dealing with these problems for the cases we encounter. Secondly, previous techniques for negat\u00ading \nnon-convex constraints, based on quasilinear con\u00adstraints [A191], were discovered to be incomplete in \ncer\u00adtain pathological cases [PW93a]. We [PW93a] describe a method that is exact and complete for all \ncases. 2.6 Simplifying Arbitrary Presburger Formulas Utilizing the capabilities described above, we \ncan sim\u00adplify and/or verify arbitrary Presburger formulas. In general, this may be prohibitively expensive. \nThere is a nondeterministic lower b~~~d of 220( ) and a deter\u00ad ministic upper bound of 222 on the time \nrequired to verify a Presburger formula. However, we have found that we are able to efficiently analyze \nmany Presburger formulas that arise in practice. For example, our current implementation requires 12 \nmilliseconds on a Sun Spare IPX to simplify l<i<2n Al<i <2n Ai=i Am(3i , j s.t. l<i <2n Al <j < n l Ai<i \nAi =i A2j = i ) Av(3i , j s.t. l<i <2n Al <j < n l Ai<i Ai =i A2j +l=i ) to (l=i=i sn)V(lsi=i =2n) \n3 Nonlinear constraints Generally, Presburger formulas are thought to allow only linear constraints. \nIt turns out that there are a number of nonlinear constraints that can be supported while remaining in \nthe class of Presburger formulas. 3.1 Floors, ceilings and mods If a term [z/cJ appears in a constraint \nC, we replace C with %s.t. ca<x<c(cr+l)AC where C is C with [z/cJ replaced with a. If a term [x/c] appears \nin a constraint C, we replace C with 3~s.t. c(~ l)<z<c/?AC where C! is C with [x/cJ replaced with ~. \nIf a term z mod c appears in a constraint C, we re\u00adplace C with ~~s.t,c~~x<c(~+l)AC where C is C with \nx mod c replaced with x y. 3.2 Stride constraints A stride constraint cle requires that e be evenly \ndivisible by c. This is equivalent to % s.t. e = ca. A negated stride constraint =(cle) requires that \ne not be evenly divisible by c. This is equivalent to ~cr s.t, ca < e < C(a + 1).  3.3 Applications \nAmong other applications, nonlinear constraints of this form show up in analyzing and compiling HPF code \nwith distributed arrays. Assume a one dimensional template T(O: 1024) has been distributed in block-cyclic \nfashion to 8 processors, using blocks of 4. This means elements T (O: 3) are mapped to processor O, T \n(4:7) to processor 1, T (28:31) to processor 7, and T (32:35) to processor O %ain. ThiS can be described \nas a mapping from a template index t to a processor number p and an index [c, 1] of a two\u00addimensional \narray of local data. This mapping can be described as: which is equivalent to t=l+4P+ 32c A0<l<3A0<P~7 \n4 Computing sums In this section, we describe our methods for comput\u00ading sums. In computing a sum, there \nare two places where we are given the option of computing the sum exactly, or computing upper and lower \nbounds. Per\u00adforming the calculation exactly will likely be more ex\u00adpensive. Also, if the answer is symbolic, \nan exact answer may be more complicated and harder to utilize. It may often be preferable to compute \nboth an upper and lower bound on the sum. Only if these values are far apart may it be worthwhile to \ncompute the exact answer. 4.1 Simple sums There are fairly standard formulas for sums of powers of integers. \nThese formulas are described in the CRC Stan\u00addard Mathematical Tables [Bey81] and are reviewed in [TF92, \nTaw94]. For example, (zi:l<2< n:22)=(2: l<n:~(~+l)2~+l)) Within our implementation, we expect it will \nbe suffi\u00adcient to hard code the formulas for p up to 10. In each of these sums, the guard produced is \n1 s n.  4.2 Basic sums In this section, we concern ourselves with the more gen\u00aderal problem of computing \n(XZ : [A/al < z< lB/bJ : i ) where a, b and p are known nonnegative integer con\u00adstants and A and B are \ninteger expressions (equiva\u00adlently, variables). There are three issues we need to address: lower bounds \nother than 1, negative upper or lower bounds, and the cases when a or b is not 1. If p is equal to zero, \nthe sum is simply: (X :L<U: U L+l) If p is greater than zero, we handle the first two issues by breaking \ndown the sum into four pieces: = (.m : l~i~UAL~U:ip) -(.zi : l~i~L-l<U:ip) +(M : L<i< l AL< U:ip) -(Xi \n: L< U+l~i~ l:ip) z (Xi : l<i~UAL<U:ip) -(Zi : l~i~L l<U : ip) +(Xi : l<i< LAL~U: (-i)p) -(Zi : l~i~ \nU 1< L: (-i)p) z (Xi : l~i<UAL<U:ip) (Zi : l~i~L-l<U:ip) +( l)p(Zi :l~i~L~U:ip) -(-l)p(Xi :l~i~-U-l< \nL:ip) 4.2.1 Handling rational bounds To compute a summation involving a floor or ceiling, such aa (xi: \nIsi<l;j :ip) we have three options: compute symbolic answers, compute approximate answers, or splinter \nthe problem (i.e., break it up into subcases) so as to produce exact bounds. For each of these techniques, \nwe will consider the example problem: Compute symbolic answers We can simply intro\u00ad duce a variable for \n[U/uJ, and produce a result in terms of this variable. In this case, the answer would be [n/3J ([n/3J \n+ 1) 2 The problem with this answer is that we cannot sym\u00adbolically sum it over n. Therefore, we can \nonly produce symbolic answers if the upper bound is a function only of symbolic constants. An eventual \nanswer that involved terms such as 17z/3J, [(n -1)/3J and n may be hard to analyze. It may be better \nto substit ute (U U )/U for [U/UJ, where U! is a new variable defined to be U mod u. Since O ~ U < u, \nwe can find the most significant terms of the answer by just looking for the highest powers of n. For \nthis example, this gives: (n nmod3)(n +3 nmod3) . 18 =n2i-3n 2n+3 (nmod3) - -(nmod3) 18 18 Computing \napproximate answers We can caJcu\u00adlate three kinds of approximate answers: upper bounds, lower bounds \nor best-guess answers. For any positive integers U and u: So for any function ~(n) that is non-decreasing \nfor non\u00adnegative n: Since the formula for is a non-decreasing function of n, we can use this tech\u00adnique \nto compute upper and lower bounds on a rational sum. We can also choose to approximate $(n) as .f(n ), \nwhere n is the approximate value of n. In our example summation, the lower bound, upper bound and approx\u00adimation \nof [n/3J are (n 2)/3, n/3 and ((n 2)/3+ n/3)/2 respectively. This gives results of of (n-2)(n +1),lower \nbound: (Z : 3< n : 18 n(n +3) upper bound: (Z :3s n : 18 ) (n -l)(n+ 2), approximation: (Z : 3 S n : \n18 We could also approximate the answer as the average of the upper and lower bound, Note that this does \nnot give the same answer w the other method of approxi\u00admation. Splintering Our other choice is to splinter \nthe prob\u00adlem. Consider the cases u[U, u[(U+l), . . . . u[(U+u 1). These cases are all obviously disjoint, \nso we generate a separate sum for each. Within case, the upper bound on i becomes integral. n 1 +(Si \n: 31n l AI SiS~ : i) n 2 +(Ei :3\\n 2AlSiS--j-: i) -(Z : 3\\n A3Sn : (nl~3)) (n-l) (n+2), +(E : 31n 1A4 \n<n: (n -2~7n+ 1), +(22 :31n 2A5sn: 18  4.2.2 Producing a guard for rational sums If both L and U involve \nfloor and ceilings, we may not be able to produce a simple and exact guard to ensure (~i : L ~ i ~ U). \nIf we use the splintering technique described above, our problem is resolved: within each splinter, we \nwill be able to produce a simple and exact guard. Otherwise, we can choose to splinter the guard or have \nthe Omega test produce a simple but approximate guard. The guard could be an upper or lower bound, depending \non whether we are computing an upper and lower bound on the result.  4.3 Polynomial Sums If the value \nz we are summing i over is not of the form ip, we rewrite x as a polynomial of i: (Ei : L<i<U : aO+ali+a2i2 \n+...) = ao(~i : L<i<U : l)+al(.Ei : L~i~U:i) +az(Xi :L~i~U:i2) +...  4.4 Convex Sums We now consider \na more general form of summation: (2V:P:Z) which denotes the sum, for all values of the variables V \nthat satisfy P, of x. For the moment, we require P to be a conjunction of linear inequalities over variables \nin V and variables representing symbolic constants (i.e., free variables). Our algorithm for dealing \nwith a convex sum (W: P:Z) is as follows: 1. Eliminate redundant constraints from P, 2. Pick a variable \nv c V to consider. In picking a variable, we try to pick a variable who s bounds can be expressed without \nfloors or ceilings, and that has as few upper and lower bounds as possible. 3. If v haa multiple upper \nbounds UI, U2,..., UP in P, we replace the summation with the sum of p new summations, where in the ith \nsummation, the upper bounds on v in P are replaced with:  ?.)~ Ui <U~+l, Ui+2, ..., up Au~<uI, u2,. \n... uI I In each resulting summation, we simplify the re\u00adsulting conditions (the new, more restrictive \ncon\u00adstraints might allow us to substantially simplify the conditions), remove redundant constraints and \nre\u00adconsider which variable to eliminate (it might not be v), 4. The case where v has a single upper bound \nbut multiple lower bounds is handled similarly. 5. If v has a single upper bound U and a single lower \nbound L, compute the sum as  (zV-{v} :P : (XV :L<v<U: Z)) Once we have simplified the term (Ew : L < \nv S U : z), we can simplify the result using the rewrite rules: (-zv:P: z+y)=(xv: P:z)+(2v:P :?./) (EV:P:(Z: \nP :Z))=(XV:PAP :Z) If variables remain to be summed over, we will need to repeat this process.  4.5 \nGeneral Sums We now consider summations where the conditions P are an arbitrary Presburger formula. We \ncan use the Omega test, as described in Section 2, to simplify an arbitrary Presburger formula into the \nunion of several clauses. In many cases, the clauses can be described by the conjunction of a set of \nlinear inequalities. In general, a clause may need to be rep\u00adresented aa a conjunction of linear inequalities \nfrom a set of auxiliary, existentially quantified variables and an affine, 1-1 mapping from the auxiliary \nvariables to vari\u00adables in V and symbolic constants. There are three issues we need to deal with: Dealing \nwith overlaps between clauses o Dealing with clauses that are represented by a pro\u00adjection Allowing the \nOmega test to perform approximate simplification 126 4.5.1 Overlapping clauses The problem is that some \nsolutions might be solutions to more than one clause. If we sum over the clauses independently, we will \ncount some solutions more than once. One way to handle this, as described in [FST91], is to subtract \nthe count of elements counted twice: (SV :PvQ :z) s(ZV :P :z)+(ZV :Q :z)-(ZV :PAQ :Z) The problem with \nthis is that it quickly gets out of control if there are more than a few clauses (7 sum\u00admations are needed \nfor 3 clauses). An alternative is to put the formula in disjoint disjunctive normal form, in which the \nclauses are mutually exclusive. We provide two techniques that let us avoid generating overlapping clauses \nin disjunctive normal form, and a method that converts an arbitrary formula in disjunctive normal form \ninto disjoint disjunctive normal form. These techniques are described in Section 5.  4.5.2 Projected \nSums For a clause P in projected form, we can assume the constraints are of the form: Ek3s.t, AZ s ; \nA~=Q6+~A 17= RZ+7 Here, F is a vector of symbolic constants (variables not in V), U is a vector of the \nvariables in V, and d is a vec\u00adtor of wildcards: quantified variables used only in this clause. We have \nused matrix notation here because we will utilize some linear algebra theory, This form is the worst-case \nsituation we will need to encounter (gener\u00adally, only a few or no symbolic variables or variables in \nV are defined by projections). However, we can easily convert an arbitrary clause into this form, We \ncalculate the Smith normal form [Sch86] of Q: UDOV[1 00 where U and V are unimodular matrices and D \nIIS a integer diagonal matrix (in Smith normal form, D has other properties but these are not important \nto us here). The constraints defining ii can be rewritten as U-l(F @ = : : V(j [1 We substitute ~ for \nVG, and partition U-l and /3 into top and bottom portions to reflect the block structure DO of This \ngives00 [1 s U~l(j -i/) =D/3T A U#(F-@=O Let #be the diagonal of D. These constraints can be rewritten \nas: d[ U#(3 @ ) A U;l(? @) =0 We can now CdCUkik c? in terms of $ and $L?: In the following equations, \nwe need to syntactly sub\u00adstitute this expression for a. To keep the expressions simple, we do not show \nthe results of this substitution. Therefore, our constraints P are equivalent to: A@Bs.t. (/hi<$ A 5= \nRZ+7) Therefore, (ZV : P : x) is equivalent to (2&#38; : Atis; : z )) where x is x with Rd! i-7 substituted \nfor V.  4.6 Approximate simplification If we are only counting solutions, and are interesting in computing \nsimple upper and lower bounds (as op\u00adposed to more complicated but exact answers), we can allow the Omega \ntest to simplify P approximately. The Omega test can produce an answers that are an upper bound or lower \nbound on the solutions to P. The key place where this approximation occurs is in performing elimination. \nWhen an elimination would cause splinter\u00ading, the Omega test can instead return the real shadow (i.e., \nallow the eliminated variable to take on real val\u00adues) or the dark shadow (a conservative bound on the \nsolution, described in [Pug92]). 5 Disjoint disjunctive normal form We now describe techniques that allow \nus to simplify Presburger formulas so as to produce disjoint disjunc\u00adtive normal form. We use three different \ntechniques: Summarizing uniformly generated sets In a num\u00adber of applications, we need to express the \nmemory locations touched by a set of array references (e.g., by the array references a [i] and a[i+ll \nin a loop in which i runs from 1 to n). Naively building a Presburger formula to represent the memory \nlocations m touched by this loop: (3z:l<z <nAm=i)v(3z: l<isnAm=z+l) 127 will result in an answer with \noverlapping clauses. By building the formula in a better way: (%,d : l~i<n AO~d~l Am=i+d) we avoid this \nproblem. e Disjoint splintering When the Omega test projects away a variable, it may need to splinter \nthe problem: describe the result as the union of several problems. In practice, this can often be avoided \nbut we need to be prepared for it. The splinters the Omega test normally generates may be overlapping. \nWe describe here a way to gener\u00adate splinters that are guaranteed to be disjoint. Conversion to disjoint \ndisjunctive normal form We describe a method for converting an arbitrary formula in disjunctive normal \nform into disjoint dis\u00adjunctive normal form. 5.1 Summarizing uniformly generated sets When computing \nthe number of memory locations or cache lines touched by a set of references in a set of loops, we often \nhave a situation where many of the ref\u00aderences differ only in constant parts, as in the SOR ex\u00adample \ngiven by [FST91]: for i =2to N-1 do for j =2to N-1 do a(i, j) = (2*a(i, j) + a(i-l, j) + a(i+l, j) + \na(i, j-1) + a(i, j+l))/6)/6 The elements of a touched by this loop are: {[i, j] [ 2<i,j < N 1} u {[2 \n l,j] 2<2, j<.N-1} u {[i+ l,j] 2<i, j<J V-1} u {[z, j 1] 2<2, j< N 1} u {[z,.j+l] 2<2, j5N 1} We can \nrecognize this as a uniformly generated set [GJ88] with offsets {(0,0), (-1,0), (1,0), (O, -l), (O, l)}. \nThis set can be described exactly as the integer points inside the convex hull of the points. Therefore, \nwe can summarize the elements Z, y of a touched by iteration i,j of this loop as: {[z+ Az,j+Aj] ] -l~Az+Aj, \nAz-Aj<l} and the elements touched by the entire execution of the loop are: {[z+ Az, j+Aj] I 2si,j5N-1 \nA l<Ai+Aj, Ai Aj <l} Using standard techniques, we can simplify this by eliminating Ai and Aj: {[i, j]ll~i, \nj< NA3<i+j<2N-1 A2 ~~i j~N-2} 5.1.1 Describing a set of constant offsets with linear constraints In cases \nsuch as this, we must convert a set of m constant offsets pI, p2, . . . pm into a set of linear constraints. \nWe describe two methods: 1. As described by Ancourt [A191], we can use O-1 programming methods. Create \nm new variables Zl, .q,. . . .zm, and a set of new constraints C :0 S Zi~lAl=~&#38;lZ~. The points can \nbe summa\u00ad rized by {~] : (3z1, z2, ...z~ : P = X:1 GPi : c )}. The stencil above can be summarized as: \n{[z,y] : (3 Z,, Z7,, Z3, Z4, Z5 : x=zl ~zAy=%s ~4 5 AO<~I, Z2, ~3, ~4, Z5<l Al=~z2)} &#38;l 2. We can \nconstruct the convex hull of the points and check for non-unit strides among the points (e.g., is the \nfirst coordinate always odd or the difference of the first two coordinates always a multiple of three). \nThe hull and any stride constraints we find are con\u00adservative. We next have to check to see if they are \nexact. One way to do this is to count the number of solutions to the hull and stride constraints, and \ncompare this to the number of points. The problem with the first technique is that it de\u00adpends on the \nconstraint system being able to simplify a O-1 integer programming problem, an iffy proposition at best. \nWe found that although the Omega test can sum\u00admarize 4-point and 5-point stencils specified this way \nas a convex region plus stride constraints, it was unable to produce a convex summary for a 9-point stencil. \nHow\u00adever, the first approach might be able to summarize sets that are missed by the second. Until we \nhave more ex\u00ad perience with these techniques in practice, we plan to try both and use whichever give \nthe better result for each case. 5.2 Disjoint splintering when eliminating vari\u00adables If ~ s b.z and \naz < Q (where a and b are positive in\u00adtegers), then a~ ~ ab.z < bci. If z is a real variable, 3Z s.t. \na~ ~ abz < ba if and only if a/3 < ba. Fourier variable elimination eliminates a variable z by combin\u00ading \ntogether all pairs of upper and lower bounds on z and adding the resulting constraints to those constraints \nthat do not involve z. This produces a set of constraints that has a solution if and only if there exists \na real value of z that satisfies the original set of constraints. In [Pug92], we showed how to compute \nthe dark shadow of a set of constraints: a set of constraints that, if it has solutions, implies the \nexistence of an in\u00ad teger z such that the original set of constraints is sat\u00ad isfied. Of course, not \nall solutions are contained in the dark shadow. For example, consider the constraints: l~s.t.0~3~ a~7Al~a \n2~~5 Using Fourier variable elimination, we find that 3 ~ a ~ 27 if we allow /3 to take on non-integer \nvalues. The dark shadow of these constraints is 5 ~ a <25. In fact, this equation has solutions for a \n= 3,5 s a s 27 and a = 29. In [Pug92], we gave a method for generating an addi\u00ad tional sets of constraints \nthat would contain any solu\u00ad tions not contained in the dark shadow, These splint\u00ad ers still contain \nreferences to the eliminated variable, but also contain an equality constraint (i.e., are flat). This \nequality constraint allows us to eliminate the de\u00ad sired variable exactly. For the example given previously, \nthe splinters are: (38 : a=3@AOs3P-as7Al Sa-2/3S5) (30 : a+l=3~AOS3/3 -a S7Al Sa-28S5) (q@ : Q-5= 2/3A/3 \ns.t. O ~ 3fi-a s 7A1 s CV-2P s 5) Simplifying these produces: (+Y : a=37A1<=7<=5) (37 : a=3~-l A2<=~<=6) \n(2v : a=2~+5A5<=~<=12) Our goal was to do so in a way that generate as few sets of constraints as possible. \nUnfortunately for our current situation, the solutions contained in the addi\u00adtional sets of constraints \ncould overlap with each other and with the solutions in the dark shadow. In Figure 1 we give a technique \nfor eliminating integer variables that produces disjoint subproblems. For contrast, we also give our \nstandard algorithm for performing elim\u00adination that produces overlapping subproblems. With the new algorithm, \nthe number of subproblems may be larger, but the fact that they are disjoint is much more valuable for \nour current applications. For this example, the splinters produced are: (3@: a=3Ao<3@-a 57 Al<a-20<5) \n(3P : a=4A053/3-QS7A15a-2fi S5) (3D : a=26Aa>5A053@-a57A1 Sa-2/3S5) (3P : a=27Aa> 5AO~3~-a< 7A15a-2P<5) \nSimplifying these produces a = 3 and a = 27 (the other two clauses simplify to false). This disjoint \nsplintering is primarily useful only as the last projection step. Consider computing 3y, z s.t. P, where \nP is a set of constraints over z, y and z. If neither y nor z can be eliminated exactly without splintering, \nwe have a problem. Say we perform disjoint elimination of zto get: 3ys.t. Pl+P2+... +Pq The problem is \nthat we cannot distribute the ~y over the disjoint union s without destroying the disjoint prop\u00aderty. \nFor example, 1 ~ z ~ y ~ 10 is disjoint from l<y<z~lO, but3ys.t. l~z ~y~ 10 is not disjoint from 3y s,t. \n1 ~ y < z ~ 10. Fortunately, this problem is not too severe. We have found that we frequently do not \nneed to splinter any eliminations. When we do, we often need do only one such elimination and we can \npostpone it to the very last elimination. If we are forced to perform multi\u00adple splintering eliminations, \nonly the last elimination is done with disjoint splinters, and then the techniques described in the next \nsection are used to transform the entire formula into disjoint disjunctive normal form. 5.3 Converting \narbitrary DNF formulas into disjoint DNF formulas Given a formula in disjunctive normal form that may \nhave overlapping conjunctions, we perform the following steps. Step 1 Check to see if any conjunct is \na subset of another conjunct [PW92]. If so, eliminate the one that is a subset. Step 2 Compute the connected \ncomponents of the conjunctions, where there is an edge between two con\u00adjunctions if they overlap. Consider \neach connected component separately in steps 3 and 4. Step 3 Within each component, pick a conjunction \nto extract, The selection criteria are: 1. If possible, pick a conjunction that is an articula\u00adtion point \nof the graph constructed in step 2. 2. Pick the conjunction with the fewest constraints  Assume the \nformula being considered is Clvcjlv... vcp and we extract Cl, Transform the formula to CI+(lCIA (C2V.., \nVCP)) Eliminate z from C, producing possibly overlapping sub problems R = False C = all constraints \nfrom C that do not involve z Cll =c for each lower bound on z: ~ < bz for each upper bound on z: az < \na C =C AaP +(a l)(b l)~ba % Missesa~ < abz< ba < a/3+ (a l)(b -1) %Misses B< bz <D+_ let a~ax = max \ncoefficient of z in upper bound on z for i = Oto ((a~~ l)(b 1) l)/amm do R= RVCAP+i=bz % C is the \ndark shadow % R contains the splinters % C V (3 integer z s.t. R) = 3 integer 2 s.t. C Figure 1: Algorithms \nfor integer variable elimination If Cl was an articulation point, removal of Cl will dlOW us to breakup \nCz V . . sV CP into disjoint sections: CI+(TCI A((CI,I V.. .VC1,pl)+(Cz,l V. ..v CZ,PZ)+...)) We distribute \nthe negated Cl term across the disjoint sections:  CI+7C1A(C1,1V. .. VCI,PI) +1 CIA(C2,1V. .. VCZ,PZ)+. \n. . Step 4 To simplify a term @A(clV. .. VCq) we first replace C with C Z gist C given Cl V ...V C q \nThis is valid because AA+3 = AA T(AAB) E A A -I(A A (gist B given A)) -A A T(gist B given A) We calculate \ngist C given Cl V ...V C~ as (gist C given Cl ) A . ~. A (gist C given Cq) Next, we perform a disjoint \nnegation of C . If C is C1AC2AC3 A... The disjoint negation of C is 7C1+C1ATCZ+C1A C2A__iC3+. O. We now \ndistribute the disjoint negation of C across c1 v . . . v C~, and reapply the techniques described here \nto convert it to disjoint DNF. Eliminate z from C, producing disjoint subproblems R = False ifexistsconstraints \na~cz~ a+ bsuch that b< c 1then %need to perform parallel splintering C = False fori=Otobdo R= RVlzs.t. \nCA~=cz i else C = all constraints from C that do not involve z @ =c for each lower bound on z: @ ~ bz \nfor each upper bound on z: az ~ a if C A a/3+ (a l)(b 1) > bci is feaaible C =C A@ +(a-l)(b-l)~bo % \nMisses a~ ~ abz < ba < a~+(a l)(b 1) fori=Oto (a l)(b 1) ldo R= RVC Aa/l+i=ba @ =C A a~+(a-l)(b-l)~ba \nSimplify and check for feasibility each clause in C and R % C is the dark shadow % R contains the splinters \n% C v (3 integer z s.t. R) s 3 integer z s.t. C with overlapping and with disjoint splintering 6 Related \nwork and examples Nadia Tawbi [Taw91, TF92, Taw94] describes an algo\u00adrithm for summing a polynomial \nover a polytope. This is used [TF92] to estimate the execution time of loops and evaluate the load balance \nof a loop. Tawbi de\u00adscribes techniques roughly equivalent to what we have described in Sections 4.1-4,3, \nFor rational bounds, she computes symbolic answers when feasible and computes average values otherwise, \nShe does not describe how to compute upper and lower bounds or split the problem to compute exact answers. \nThe significant differences between our work and hers are the techniques for han\u00addling convex sums (ours \nare an improvement on hers) and general sums (which she does not address). In Tawbi s algorithm for convex \nsums, the variables in the summation must be eliminated in a predetermined order, no attempt is made \nto eliminate redundant con\u00adst raints. Tawbi handles the problem of empty summations by performing an \ninitial polyhedral splitting step, de\u00adscribed in [Taw91, Taw94], so that no summation can be empty. Since \nthis splitting step respects the original elimination order, it may split a summation into more pieces \nthan we do. Example 1 Tawbi [Taw94] gives an example of: 2221 i=l ~=1 k=j Her polyhedral splitting technique \ntransforms this to: ?%i m    xxx i=l j=l k=j otherwise 222 + 222 i=l jzl k=j iam 1 jcl k=j The summations \ncan then be computed using stan\u00ad dard computer symbolic algebra techniques. Our techniques work as follows \non this example: (Zi, j, k : l<isnAl<j~iAj<k<m:l) Eliminate redundant constraint 1 ~ i = (M, j, k : l<j<i<n \nAj<k<nz:l) Sum over k (single upper and lower bound) = (Ei, j :l<j~i~n Aj<m:m-j+l) Sum over i (single \nupper and lower bound) = (Xj : l<jsn,m : (n-j+ l)(m-j+l)) Splinter upper bounds for j = (,?2j : lsj~n~m \n: (n-j+ l)(m-j+l)) +(x~ : l~j~m<n : (n-j+ l)(m-j-1)) Sum over j =(~:l~n~rn:~-~+~+~) +(x :l~m<n:~ $+~+ \n~) In comparing our technique with Tawbi s, we find that our greater flexibility and our ability to eliminate \nredun\u00ad dant constraints makes our techniques more efficient for many cases (in this example, we only \nneeded to consider 2 terms rather than 3). Also, the techniques described in Sections 4.5 and 5 are a \nuseful contribution above and beyond her work. Example 2 Mohammad Haghighat and Constantine Polychronopoulos \n[HP93a, HP93b] describe a method for volume computation, and give two examples. Their first example is: \n225 i=l j=3 k=j Our techniques compute this as: (.Xi, j, k : l<i~nA3~j~iAj~k~5:l) Eliminate redundant \nconstraint 1 ~ i = (Xi, j, k : 3~j~i~nAj~k~5:l) Sum over k =(~i, j:3<j~i<n Aj <5:6-j) Sum over i =(YJ \n: 3sj S5, n : (n+l-j)(6-j)) Splinter upper bounds for j =(Z~(~J3<jS5sn : (n+l-j)(6-j)) : 3Sj Sn<5 : (n+l-j)(6-j)) \nSum over j =(X: 5<n:6n 16) 24-3 Sm+15n2-n3 +(2 :3~n <5: 6) If we further recognize that the second \nsummation is only defined at two points (TZ= 3 and n = 4), we realize that it can be defined by a first \ndegree polynomial (i.e., a linear term), and find that it is 5n 12. This allows us to simplify the above \nexpression to: (x:5<n : 6n 16)+(S : 3sn<5 : 5n 12) Haghighat and Polychronopoulos [HP93a, HP93b] de\u00adrive \nan answer of p(min(n 2, 3))( (min(n, 5))3+15(min(n, 5))2 38 min(n, 5)+24)/6 +6max(n 5, O) where p(z) \nis defined to be 1 if z is positive, O otherwise, The answer they derive gives the same answers as ours; \nthe form of their answer is quite different because of the min and max expressions they introduce. We \nhave de\u00adveloped a way of introducing rein s and max s into the result. Although it sometimes allows us \nto avoid split\u00adting a summation because of a multiple upper or lower bound, the results tend to be much \nmore complicated. We have decided that in general that it is not worth generating rein s and max s. Example \n3 The second example in [HP93a, HP93b] z~ min(i,2n j) Zxl i=l jzl is easily handled by our system: (X~,j: \n1~ i<2nAl~j~iAi+j<%z: 1) Eliminate redundant constraints 1 ~ i < 2n = (~i,j : l~j~i<2n j : 1) Sum over \ni =(zj : l~j~n : 2n-2j+l) Sum over j =(X: l<n:n2) In comparison, Haghighat s and Polychronopoulos techniques \nrequire 9 steps for their first example and 15 steps for their second example. Haghighat and Poly\u00adchronopoulos \n[HP93a, HP93b] do not describe their technique in detail. They give a number of rules that can be used \nin transforming expressions (e.g., P(ZY) = P(Z)P(V) + P( z)P( v)), but do not describe how to decide \nwhich rule to apply when. They, like [TF92], ~\u00adsume the summation must be performed in a predeter\u00admined \norder and do not attempt to eliminate redundant constraints. In comparing our techniques with theirs, \nwe find that ours is fully defined and is much easy to apply for a number of examples (such M Example \n2 from [HP93a], which is much harder for their syst;m to analyze). Example 4 Ferrante, Sarkar and Thrash \n[FST91] give methods for computing the number of distinct memory locations and cache lines accessed by \na loop nest. This information is useful in evaluating cache effectiveness. The first example they give \nis calculating the number of distinct memory locations touched by: for i :=lto8do for j :=lto5do a(6i+9j-7) \n= a(6i+9j-7) + 5 This question can be phrased and answered within our system as follows: (xx : (%,j \n: l<i<8Al<j<5 Ax= 6i+9j 7) : 1) Simplify using omega test =(M:z =8:1) + (XZ:(3CX:5 <a< 27 Ax=3cI-1) : \n1) + (ZZ : x=86 : 1) =( Zz:z=8: l)+(Xa:5<a S27: I) +(.Xx :X=86: 1) = 25 Example 5 The second example \nin [FST91] is to cal\u00adculate the number of memory locations touched in a Successive Over-Relaxation (SOR) \ncode: for i =2to N-1 do for j =2to N-1 do a(i, j) = 2*a(l, j) + a(i-l, j) + a(i+l, j) + a(i, j-1) + a(i, \nj+l) Using techniques described in Section 5.1, we can state and solve this as shown in Figure 2 (to \nbe sim\u00ad ilar to [FST91], we assume N = 500). To calculate the number of cache lines touched, we need \na mapping from array elements to cache lines. A simple mapping 1 is to state that a reference to element \na[i, J of an array references cache line [(i 1) + 16, j] (where + stands for integer division). With \nthis map\u00ad ping, we generate the following answer for the number of cache lines touched by this loop: \n(xx, y : (~i,j, Ai, Aj : z=(i+Ai l):16AY=j+ AjA2<z, j< 499 A l<Ai+Aj, Ai Aj <l) : 1) Simplify using \nomega test = (Xx, y :O~C~31Al<y <500:1) = 16000 We can also perform these computations symbolically. \nWefind that theloop touches (X :Nz3 :N2 4) distinct memory accesses and (.X : N>3 : N(l+(N 2)+-16)) +(.X \n: Nmod16=l AN~17 : N 2) 1we could ~ISo ~sume more general mappings, in which the cache lines can wrap \nfrom one row to another and in which we don t know the alignment of the first element of the array with \nthe cache lines. distinct cache lines. The method described in [FST911 works well for many simple cases, \nbut: cannot handle coupled subscripts or iterations spaces, e waa not originally designed to compute \nsymbolic answers (although it might be adapted), e often computes a conservative approximation, and @ \nuses expensive methods to handle the cache lines touched by a set of references (comparing with our methods \nfor summarizing uniformly generated ref\u00aderences). Example 6 We now work through a more elaborate example, \nwhich will require us to utilize a number of the techniques we have described. We also mention some additional \ntechniques, not elaborated here, that allow us to further simplify our result. (Xi, j : l~iAj~nA2i~3j \n: 1) Splinter by considering 3j as even or odd = (Zi, j :213j Al~i Aj~n A2i<3j : 1) +(Xli, j : 2[3j l \nAl<i Aj<n A2i< 3j :1) Simplify using Omega test e (Xi,j : (3@ : j = 2ctAl < iA3aA2@ < n) : 1) +(Ei, j \n: (3P : j=2P-l Al <i< 3,6-2 A2P<n+l) : 1) Deal with projected clauses Z (Xi, a :l~i~3a A2a~n:l) +(zi, \n,f3 : l~i~3/3-2A2~sn+l : 1) Sum over i = (Ea : l~2a<n: 3a) +(zp : l~2~~n+l : 3P 2) Sum over u and ,6 \n3(n-nmod2)(n-nmod 2+2 =(z:2<n: )in+mmo~2)(3?t+3(mmod2)-2) +(x :1<n: ) s If we now do some additional \nsimplification, we can get a even better result. The guard of the first term is identical to the guard \nof the second term except that it excludes n = 1. Upon checking, we find the the value of the first clause \nfor n = 1 is O, even if we ignore the guard. So we can safely relax the guard of the first clause to \nn a 1 and combine the terms: 3(n nmod 2)(n nmod2+2)(X:l<n: 8 +(n+nmod 2)(3n+3(nmod 2)-2), 8 Simplifying \nthis gives: 3n2+2n 4(n mod 2)2+ 3(n mod 2) (x:l~n: )4 We can further simplify this by recognizing that \n(n mod (Xx, y : (%,j, Ai, Aj : x=i+Ai Ay=j+&#38;A2Si, j S499A lSAi+&#38;,Ai-&#38; <1) : 1) Simplify \nusing omega test = (Xx, y : l<x, vS500A3S X+?JS999A -498s X-y S498 : 1) Put in terms of upper and lower \nbounds on z = (Zx, y : 1,3 y,498+ ySx S500,999 g,498+y Alsys 500 : 1) Splinter upper bounds on x = (Ex, \ny : 1,3 y,498+ ySZS500S 999-V,498+ IIAls VS500 : 1) +(zz, y : 1,3 Y,498+Y SZS999 gIS498+y A999-v< 500 \nAl S!IS 500 : 1) +(%y : 1,3 y,498+ y~x<498+y <999 y,500Al~y~ 500 : 1) Resimplify = (Xx, y :2~x~499A l~y~500:l) \n+(xz, y : z=500A2~y <499 : 1) +(zz, y : x=l A2<y~499: 1) = 249996 Figure 2: Computation of number of \ndistinct memory locations touched by SOR loop 2)2 = (n mod 2): 3n2+2n nmod2 (X:l<n: )4 Conclusions \nWe have described methods that are able to count the number of integer solutions to selected free variables \nof a Presburger formula, or sum a polynomial over all integer solutions of selected free variables of \na Presburger for\u00admula. This answer can be given symbolically, in terms of symbolic constants (the remaining \nfree variables in the Presburger formula). This ability has many appli\u00adcations in the analysis and transformation \nof scientific programs. The techniques we have described are rather elabo\u00adrate and complicated. This \nwas necessitated by our de\u00adsire for a method that could handle an arbitrary Pres\u00adburger formula. This \nis necessary for applications such as counting distinct memory accesses, cache line ac\u00adcesses and array \nelements that need to be communicated in a distributed process. For simpler applications requir\u00ading only \nmore limited capabilities, such as described by [TF92, HP93a], we make two simple but important ob\u00adservations: \n Summations over several variables should not pre\u00adsume a order in which to perform the summation  Eliminating \nredundant constraints is useful  As of March 1994, we have not implemented the com\u00adplete system described \nhere. As we do so, we will un\u00addoubted learn more about efficient techniques for coumt\u00ading solutions and \nperforming summations over Pres\u00adburger formulas. 8 Acknowledgements Thanks to Wayne Kelly and Dave Wonnacott \nfor their close readings of this manuscript, and to my entire re\u00adsearch team Wayne Kelly Vadim Maslov \nEvan Rosser Tatiana Shpeisman Dave Wonnacott for their work on the implementation. This work is sup\u00adported \nby an NSF PYI grant CCR-9157384 and by a Packard Fellowship. 9 Further Info The Omega project is exploring \nthe use of advanced con\u00adstraint technology in analyzing and transforming scien\u00adtific programs for execution \non supercomputers. Among other topics, we are investigating unified frameworks for reordering transformations \n[KP93b, KP93a], ad\u00advanced forms of dependence analysis [PW93b, PW93a], and techniques for dealing with \npolynomial constraints [MP94]. Much of our research is implemented in pub\u00adlicly available implementations, \nwhich are being used by other research groups around the world. More info about our research project \nor software can be obtained via: email: omega@cs. umd. edu  anonymous ftp: ftp.cs.umd.edu: pub/omega \n  world wide web:  http : //www.cs.umd.edu/pro j ect S./omega William Pugh. The Omega test: a fast \nand REFERENCES [Pug92] [A191] [Bey81] [FST91] [GJ88] [HP93a] [HP93b] [KP93a] [KP93b] [MP94] Corinne \nAncourt and Franqois Irigoin. Scan\u00adning polyhedra with DO loops. In I%oc. of the .%-dACM SIGPLAN Symposium \non Prin\u00ad ciples and Practice of Parallel Programming, pages 39-5o, April 1991. William H. Beyer, editor. \nCRC Standard Mathematical/ Tables. CRC Press, 1981. J. Ferrante, V. Sarkar, and W. Thrash. On estimating \nand enhancing cache effectiveness. In Advances in Languages and Compilers for Parallel Processing, pages \n328-343. The MIT Press, 1991. D. Gannon and W. Jalby. Strategies for cache and local memory management \nby global pro\u00adgram transformation. Journal of Parallel and Distributed Computing, pages 587-616, 1988. \nM. Haghighat and C. Polychronopoulos. Sym\u00adbolic analysis: A basis for parallelization, op\u00adtimization \nand scheduling of programs. In Utpal Banerjee et al., editor, Languages and Compilers for Parallel Computing. \nSpringer-Verlag, August 1993. LNCS vol. 768; pro\u00adceedings of the Sixth Annual Workshop on Programming \nLanguages and Compilers for Parallel Computing. M. Haghighat and C. Polychronopoulos. Sym\u00adbolic analysis: \nA basis for parallelization, op\u00adtimization and scheduling of programs. Tech\u00adnical Report 1317, CSRD, \nUniv. of Illinois, August 1993. Wayne Kelly and William Pugh. Determin\u00ad ing schedules based on performance \nestima\u00ad tion. Technical Report CS-TR-3108, Dept. of Computer Science, University of Maryland, College \nPark, July 1993. to appear in Parallel Processing Letters (1994). Wayne Kelly and William Pugh, A frame\u00adwork \nfor unifying reordering transformations, Technical Report CS-TR-3193, Dept. of Com\u00adputer Science, University \nof Maryland, Col\u00adlege Park, April 1993. Vadim Maslov and William Pugh. Simpli\u00adfying polynomial constraints \nover integers to make dependence analysis more precise. Tech\u00adnical Report CS-TR-3109.O1, Dept. of Com\u00adputer \nScience, University of Maryland, Col\u00adlege Park, February 1994. Submitted to CON-PAR 94. [PW92] [PW93a] \n[PW93b] [Sch86] [Taw91] [Taw94] [TF92] practical integer programming algorithm for dependence analysis. \nCommunications of the ACM, 8:102-114, August 1992. William Pugh and David Wonnacott. Go\u00ading beyond integer \nprogramming with the Omega test to eliminate false data depen\u00addence. Technical Report CS-TR-3191, Dept. \nof Computer Science, University of Maryland, College Park, December 1992. An earlier ver\u00adsion of this \npaper appeared at the SIGPLAN PLDI 92 conference. William Pugh and David Wonnacott. An eval\u00aduation of \nexact methods for analysis of value\u00adbased array data dependence. In Sixth An\u00adnual Workshop on Programming \nLanguages and Compilers for Parallel Computing, Port\u00adland, OR, August 1993. William Pugh and David Wonnacott. \nStatic analysis of upper and lower bounds on depen\u00addence and parallelism. ACM Transactions on Programming \nLanguages and Systems, 1993. accepted for publication. A. Schrijver. Theory of Linear and Integer Programming. \nJohn Wiley and Sons, Chich\u00adester, Great Britain, 1986. Nadia Tawbi. Paral161ization Automatique: Estimation \ndes Dur%es d Ex6cution et Allo\u00adcation Statique de Processeurs. PhD thesis, Universit6 Pierre et Marie \nCurie, April 1991. Nadia Tawbi. Estimation of nested loop exe\u00adcution time by integer arithmetics in convex \npolyhedra. In Proc. of the 1994 International Parallel Processing Symposium, April 1994. Nadia Tawbi \nand Paul Feautrier. Processor al\u00adlocation and loop scheduling on multiproces\u00adsor computers, In Proc. \nof the 1992 Interna\u00adtional Conference on Supercomputing, pages 63-71, July 1992. \n\t\t\t", "proc_id": "178243", "abstract": "<p>We describe methods that are able to count the number of integer solutions to selected free variables of a Presburger formula, or sum a polynomial over all integer solutions of selected free variables of a Presburger formula. This answer is given symbolically, in terms of symbolic constants (the remaining free variables in the Presburger formula).</p><p>For example, we can create a Presburger formula who's solutions correspond to the iterations of a loop. By counting these, we obtain an estimate of the execution time of the loop.</p><p>In more complicated applications, we can create Presburger formulas who's solutions correspond to the distinct memory locations or cache lines touched by a loop, the flops executed by a loop, or the array elements that need to be communicated at a particular point in a distributed computation. By counting the number of solutions, we can evaluate the computation/memory balance of a computation, determine if a loop is load balanced and evaluate message traffic and allocate message buffers.</p>", "authors": [{"name": "William Pugh", "author_profile_id": "81100057068", "affiliation": "Dept. of Computer Science, Univ. of Maryland, College Park, MD", "person_id": "PP15020758", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/178243.178254", "year": "1994", "article_id": "178254", "conference": "PLDI", "title": "Counting solutions to Presburger formulas: how and why", "url": "http://dl.acm.org/citation.cfm?id=178254"}