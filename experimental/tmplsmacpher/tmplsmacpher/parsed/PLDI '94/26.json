{"article_publication_date": "06-01-1994", "fulltext": "\n Optimal Tracing and Incremental Reexecution for Debugging Long-Running Programs Robert H. B. Netzer \nMark H. Weaver r n@cs.brown.edu hk_Weaver@brown.edu Dept. of Computer Science Brown University Box 1910 \nProvidence, RI 02912 1. Introduction Debugging requires execution replay. Locations of bugs are rarely \nknown in advance, so an execution must be repeated over and over to track down bugs. A problem arises \nwith repeated reexecution for long-running programs and programs that have complex interactions with \ntheir environment. Replaying long-running programs from the start incurs too much delay. Replaying programs \nthat inter\u00adact with their environment requires the difticult (and some\u00adtimes impossible) task of exactly \nreproducing this environ\u00adment (such as the connections over a one-day period to an X server), These problems \ncan be solved by periodically checkpointing the execution s state so it can be incremen\u00adtally replayed \nor restarted from intermediate points. Restarting from checkpoints bounds the delay to replay any part \nof the execution if checkpoints were taken often enough, and allows pals of the execution having interac\u00adtions \nwith the environment difficult to reproduce to be skipped. However, the time and space costs of such \ncheck\u00adpointing can be prohibitive. To reduce this cost, we present adaptive tracing strategies that provide \nbounded-time incre\u00admental replay and that are nearly optimal. Our implemen\u00adtation on a Spare 10 traces \nless than 15 kilobytes/see for CPU-intensive programs and for interactive programs the slowdown is low \nenough that tracing can be left on all the time. Our first result is a tracing strategy that adaptively \ndecides when and what to trace to provide bounded-time incremental replay. To decide when to trace, we \ndivide the execution into windows, which are regions of the execution we can individually replay. To \ndecide what to trace, we observe that a window s correct reexecution requires each of its reads to return \nthe same value during replay as during the original execution. Each such value need not be traced if \nthe read is preceded in the same window by a write to the same location (the write will restore during \nreplay the origi\u00adnal value) or if the value was aheady traced. To bound the This research was partly \nsupported by ONR Contract NOO014-91-J-4052 (ARPA Order 8225) and NSF grant CCR-93093 11. Permission to \nco y without fee all or part of this material is granted provid J that the copies are not made or distributed \nfor direct mmmercial advanta~e, the ACM copyri@t notice and the title of the publication and W date appear, \nand notice is given that eopyfng is by permission of the Association of Computing Machinery. To copy \notherwise, or to republish, requires a fee anctlor spa fic permission. SIGPLAN 94-6/94 Orlando, Florida \nUSA @ 1994 ACM 0-89791 -662-x19410006..$3.5O replay time, we trace reads often enough so their values \nare never very far back in the trace, allowing the state required for the replay to be quickly restored. \nWe also place a maxi\u00admum length on the windows. The optimal tracing problem is to adaptively decide where \nto start windows, and what memory references in each to trace, to minimize the num\u00adber of references \ntraced. We show that the problem can be reduced to computing the shortest path through a directed graph, \nsolvable in O(nT) time (where n is the number of member references made during execution, and T is the \nmaximum number of references allowed in a window). Although the optimal problem is solvable, it is proba\u00adbly \nimpractical as it seems to require more than constant work at each memory reference. For efficient tracing, \nwe present approximations that employ jixed-size windows. These approximations are simple and efficient. \nThey per\u00adform simple bitvector lookups at each read and write using space-efficient two-level bitvectors. \nExperiments show they usually trace at most twice more than optimal. Our implementation on a Spare 10 \nincurs a factor of 1.75 7 slowdown and generates less than 15 kilobytes/see of trace on CPU-intensive \nprograms. In addition, we instrument system calls to automatically trace only those interactions a program \nhas with its environment that affect its outcome. This feature addresses one of the difficult aspects \nof replay, allowing us to trace and replay interactive systems. Our work is novel in that our tracing \nalgorithms adapt to the particulm execution being debugged. A diffi\u00adcult paxt of supporting incremental \nreplay is bounding the replay time while tracing only what is necessary. We achieve both of these objectives. \nPrevious systems that provide incremental replay can trace more than necessary and can incur large delays \nduring replay [5, 10, 4, 3]. We guarantee a user-specified bound on the time of any replay by fixing \nthe size of windows and by tracing often enough. Adaptive tracing is becoming not only practical but \nnecessary. In the past, the cost of disk 1/0 was insignificant compared to even a small amount of computation \n(such as the bitvector manipulation our algorithms perform). Now, processors are so fast that a significant \nwork can be per\u00adformed in the time it takes to write only a single trace record. Since this trend is \ncontinuing, in the future it witt be cheaper to use adaptive strategies that do on-line analy\u00adsis to \nminimize tracing than to trace more than necessary. 2. Related Work An execution must be traced to provide \nincremental replay. Enough must be recorded so that during replay suf\u00adficient state can be restored for \neach read from memory to obtain the same value as during the original execution. Below we describe past \napproaches to this problem[5, 10, 4,3, 1]. These approaches either trace orders of magnitude more than \nnecessay (as shown later), or do not bound the time required to replay up to an arbit.my point of the \nexe\u00adcution. The IGOR system uses the virtual memory system to periodically trace, at fixed time intervals, \nthose pages modi\u00adfied since the last checkpoint[5]. To restart the execution from an intermediate point \nrequires scanning the trace to find the most recent checkpoint of each page. Because checkpoints are \ntaken at fixed time intervals, IGOR bounds the amount time required to replay any part of the execu\u00adtion \nonce replay begins. However, setting up the state for replay requires potentially scanning through the \nentire trace tile, which can take time proportional to the length of the execution. Although this approach \nis adaptive in the sense that it traces only pages that have been recently written, our experiments show \nthat a page granularity of tracing is too large to be practical; orders of magnitude more data than necessary \nis traced. The PPD system uses compile-time analysis to decide what and when to trace[lO, 4, 3]. PPD \nwrites a prelog on the entry of each procedure, containing the vari\u00adables the procedure might possibly \nread before defining. The prelog allows a procedure to be re-executed in isola\u00adtion since it contains \nall variables the procedure might read. A postlog is written on procedure exit, containing the vari\u00adables \nthe procedure might have modified. The postlog allows the execution of a procedure to be skipped during \nreplay since it contains the changes the procedure might make to the state. PPD has the drawback of statically \ncom\u00adputing what variables are traced and when they are traced. Since compile-time analyses must be conservative, \nmore variables can be placed in the logs than necessary. In addi\u00adtion, tracing only at procedure entry \nand exit can sometimes incur high overhead and provide no guarantees on replay time. For example, a 1000-iteration \nloop that contains a procedure call incurs many needless traces[4], and a very long-running procedure \nmay not be traced often enough to replay any part of it in a reasonable time. As an attempt to alleviate \nthese problems, prelogs and postlogs can option\u00adally be generated for loops, and not generated for some \npro\u00adcedures[4], but the basic idea is limited by its static nature. The Spyder system traces, before \neach statement (or group of statements), its change set, the values of the vari\u00adables the statement might \nmodify[l]. A debugger can baclcup execution over a statement by restoring the state from its change set. \nAs an optimization to bound the trace size, only the most recent change set from each statement can be \nkept. Spyder statically computes the change sets, and for programs that use pointers and arrays, it must \ntrace each such access. Spyder s main disadvantage is that it does not bound the time required to perform \na replay, since we must tist back up to before the desired interval and then reexecute forward. Although \nSpyder provides a valuable backup tool, like PPD it is limited by its static nature (and must trace every \narray or pointer reference), and it was not designed to provide a general replay facility that can quickly \nreexecute any requested part of the execution. Wtlson proposes an idea called Demonic Memory as a way \nto recreate any past state of a process[14]. By main\u00adtaining a hierarchy of checkpoints, each taken at \nsucces\u00adsively larger time granularities, recent states can be repro\u00adduced quickly while older states \nincur more delay. He pro\u00adposes virtual snapshots as a way to checkpoint, where only the parts of a checkpoint \nthat differ from the previous one are saved. Our techniques are complementary to Demonic Memory as they \nprovide another way to take the check\u00adpoints, and a hierarchy of different window sizes can be used to \ncompact our trace on-the-fly. CheckPointing and tracing strategies have been pro\u00adposed for problems such \nas fault tolerance, profiling, and others[8, 11, 2, 7, 6]. The incremental replay problem is more difficult \nthan these problems since user replay requests occur often (unlike faults, for example) and they must \ncomplete quickly. In addition, unlike performance measurement, the tracing requirements are substantial, \nsince enough state must be recorded to make the replay identical to the traced execution. Tracing strategies \nfor these other problems therefore do not solve the incremental replay problem. 3. Adaptive Tracing for \nBounded-Time Replay Past techniques are limited by their static nature, deciding at compile-time what \nor when to trace (or both). As a result, they trace more than absolutely necessary and may incur lengthy \ndelays in replaying up to a rquested part of the execution. We overcome these problems by aa ap\u00adtively \ndeciding what and when to trace, To decide when to trace, we divide the execution into windows contiguous \nintervals of the execution that can be individually replayed and produce a set of traces for each window. \nTo decide what to trace, we perform on-line analysis at each memory ~ference to dynamically determine \nwhich to record. Below we outline our adaptive approach. We show that optimally deciding what and when \nto trace has polynomial time complexity, but is too expensive to be practical. In the next section we \npresent nearly optimal approximations that are efficient. Providing bounded-time replay involves two \nconsid\u00aderations. First, the time it takes to setup the state (from the trace) for any xeplay must be \nbounded. We bound this time by tracing often enough so that restoring the state any window will need \nrequires reading at most M previous trace ~cords. Second, the time it takes to replay up to any part \nof the execution, once replay begins, must be bounded. We bound this time by placing a limit of T memory \nrefer\u00adences on the length of any window. There is a tradeoff between fast replay and small traces; targer \nvatues of T and M result in smaller traces but longer replay times. In prac\u00adtice we expect the user to \nprovide T and M to tune this run\u00adtime vs replay-time overhead tradeoff. 3.1. What to Trace To support \nthe replay of some portion of the execu\u00adtion (a window), we wish to trace just enough to ensure that \na reexecution from the window s start correctly reproduces the original. We consider a replay correct \niff each read from memory receives the same value as during the origi\u00adnat execution. We atso wish to \ntrace often enough so the state necessary for the replay can be restored from the trace in bounded time. \nWe consider a window s replay to be M\u00adbozfnded iff we need to scan at most the M previous trace records \nbefore the window s trace to restore its state. The following proposition shows what must be traced. \nProposition 1 In general, enough trace data exists to provide an M-bounded replay of a window iff for \nevery read in the window, either (1) the value read is saved in one of the M trace records preceding \nthe start of the window s trace, or (2) a write to the same memory location is previ\u00adously made within \nthe same window.  If a memory location being read was already written in the same window, there is \nno need to save its valuw dur\u00ading replay the preceding write will restore the original value. If a location \nis read in a window but its value was recently traced (within the current window or last M mace records \nbefore the window), it need not be traced again; to replay, the wdue can be retrieved without scanning \ntoo far back in the trace file. For M-bounded replay, we only need to trace reads that would violate \nthe above two conditions if not traced. We call such reads unique-spanning~ reads. A unique-spanning~ \nread is the first read from an address A in a window where A was written in an earlier window but its \nvatue not traced in the M trace records recorded before the window. Without knowing the semantics of \na window s com\u00adputation, tracing unique-spanning~ reads is both necessary and sufficient for supporting \nM-bounded incremental replay. If we do not trace the value of a unique-spanning~ read, then there would \nexist a window which, when reexe\u00adcuted in isolation, would contain some read not preceded by a write \nto the same address, nor saved in last M trace records. We would be unable to start this window s reptay \nby reading at most M trace records. An alternative for supporting incremental replay is to instead trace \nthe writes to memory. There are tradeoffs between tracing reads and writes, which we discuss later. If \nwe define a unique write as the last write to each location in a window, then tracing the unique writes \nin each window provides sufficient information for oo-bounded replay (i.e., no bound can be guaranteed). \nNo bound can be guaranteed because if we trace only the writes, we do not know what addresses a window \ns replay will read, so we have to restore the state from the traces of all preceding windows. As discussed \nin Section 2, this potentially requires scanning through the entire trace. We explore this alternative \nbecause (as we show later) less run-time overhead is incurred in locating unique writes than unique-spanning \nreads, so they provide an alternative when run-time over\u00adhead must be minimized. Figure 1 shows examples \nof unique-spanning reads and unique writes. 3.2. When to Trace Deciding the second part of adaptive \ntracing, when to trace, involves determining when to start a new window. We wish to adaptively start \na new window subject to two constraints: (1) the number of references traced is mini\u00admized, and (2) no \nwindow is longer than T references, the user-specified bound on the maximum allowable replay time. We \ncan minimize the number of references traced by placing windows carefutly, for example to group together \nas many references to the same address as possible. By keeping windows no longer than T references, the \ntime to actually reexecute up to any part of any window remains bounded. A surprising result is that \ncomputing where to start new windows to minimize the number of unique\u00adspanning~ reads traced is not NP-complete \nfor M = O or M = CO. Determining optimally where to start each win\u00addow can be performed in O(nT) time, \nwhere n is the num\u00adber of memory references. Although we omit the proof details for brevity, the basic \nidea is that determining when rWRITE A Window 1 READ A L WRITE A ~ unique wrile READ A ~ unique\u00ad spanningoread \nWindow 2 [ READ A Window 3 [READ A ~ unique spanningl read iff A not traced in Window 2 Figure 1. Example \nexecution broken into windows. to start new windows can be reduced to computing the least-cost path \nthrough a directed graph. Each memory ref\u00aderence is a node in the graph. Each node has edges to nodes \nrepresenting each of the subsequent T references, with each edge labeled with the cost of tracing (the \nnumber of unique-spanning~ reads) if the two connected nodes were to delimit a window. A least-cost path \nis found in time O(nT) because each of the n nodes has degree T (the head of each edge in this path shows \nwhere each window should be started). We are unsure of the complexity for other values of M and leave \nan investigation to future work. However, because the cases M = O and M = IX per\u00adform well (discussed \nlater), it is unclear whether other val\u00adues of M are of practical interest. 4. Fixed-Window Tracing Algorithms \nEven though optimally deciding when to start a new window has polynomial time complexity, it seems to \nrequire more than constant work at each memory reference, which is too inefficient to run on-line. We \novercome this problem with an approximation by simply fixing each win\u00addow size at T. The problem then \nreduces to adaptively deciding which references to trace in each window. Below we conceptually outline \ntracing algorithms for providing M-bounded replay for any M, and for the special cases of M = O and M \n=00 which have simple algorithms. We also present details of an implementation for the Spare. When M \n= O we trace enough so that a window can be replayed by simply restoring the state from its own trace. \nOther parts of the trace need not be scanned, provid\u00ading the lowest replay setup time. When M = co we \ndo not worry about how far back in the trace we must scan. This allows fewer reads to ke traced at the \nexpense of longer replay time, as there are no more unique-spanning-reads than unique-spanning~ reads \nfor any M. We present these two special cases since they have simple implementations and are probably \nof the most practicat interest.  4.1. Conceptual Algorithms Figure 2 shows our algorithms. An action \nis per\u00adformed when a window boundary is reached (the win\u00addow_bounda~_hook function) and after each read \nor write to memory (read_hook and write_hook, where the parame\u00adter a is the address being accessed). \nThe special case of tracing unique-spanning-reads works as follows. Traced is a bitvector that indicates \nwhich addresses have been traced since last written, and the NeedToTrace bitvector marks which addresses \nhave not been written in the current window or traced since last written. When a write occurs to address \na, we reset the a* bit in NeedToTrace (indicating that a has been written in the current window so a \nsubse\u00ad quent read in the same window need not be traced) and in Traced (indicating that a new value has \nbeen written into a which has not yet been traced). When a read from a occurs, we check to see if it \nis unique-spanning-: if the value in address a has not been traced since last written or written yet \nin the window, NeedToTrace[a] will be 1 and the read s address and value are traced. Otherwise, the read \nis not unique-spanning-and can be ignored. At the start of each window we set the NeedToTrace bitvector \nas the complement of Traced since any addresses traced since last written need not be traced again. We \ngeneralize this algorithm to detect unique\u00adspanning~ reads as follows. By changing Traced into a counter, \nwe track how many windows elapse before a traced value expires in the sense that it must be traced again \nif read. Traced only need be large enough to store values between O and an expiration count, C, and only \nthe number of windows since a value is traced need be counted. In the implementation we could count the \nactual number of trace records (e.g., by counting the number of times a trace buffer is flushed to disk), \nbut for simplicity we count win\u00addows. Any read not previously written in the same window is traced if \nits value was not traced within the last C win\u00addows. At each window boundary we decrement the Traced \ncounter associated with each address and set the NeedTo-Trace bit when the count reaches O. The algorithms \nto trace unique writes and unique\u00adspanningO reads are similax To detect unique-spanning. reads we simply \ntrace the first read to an address in a win\u00addow if it was not previously written in that window, so a \ncounter is unnecessary. Since most memory references are four-byte accesses, as a bitvector optimization \nwe need not assign one bit per address but only one bit per word. Sub-word references are handled as \nshown in Figure 3. If we are trac\u00ading unique writes, a sub-word write is treated as a write to the entire \nword. If we are tracing unique-spanning reads, we must handle sub-word writes by resetting Traced to \nO, ensuring that subsequent reads to any part of the word will be traced if not already written in the \nwindow. When trac\u00ading unique-spanning. reads, the Traced counter is not used, so the sub-word hook becomes \nempty. An advantage of tracking reads and writes on-line is that the values a window s replay will need \n(and that will not be recomputed during replay) are automatically traced. We can extend this feature \nof the algorithm to handle one of the challenging aspects of replay: programs that have inter\u00adactions \nwith their environment. If we specially treat system calls, we need not reexecute them during replay, \nand any interactions a program has with its external environment through these calls can automatically \nbe reproduced. We instrument each system call to perform several actions (sys_call_hook in Figure 3), \nalthough we need not track each read and write it makes. First, we estimate which addresses might possibly \nbe written during the call. Estimating these addresses is usually straightforward since window.boundary.hook \n{ (no read hook required) write_hook(a) { trace addresses &#38; values of Written[a]=l; locations in \nWritten; } Written bit-vector = O s; ) (a): unique writes window_boundary_hook { read_hook(a) { write_hook(a) \n{ foreach a if ( NeedToTrace[a] ) NeedToTrace[a]=O; if ( Traced[a] >0 ) trace address &#38; value; Traced[a]=O; \nNeedT Zhzce[a]=O; NeedToTrace[a]=O; ) Traced[a]- ; Traced[a]=C; else ) iVeedT Trace[a]=l; ) (b): unique-spanningM \nreads window.boundary.hook { rmd_hook(a) { write_hook(a) { NeedToTrace bit-vector= 1 s; if ( NeedToTrace[a] \n) NeedToTrace[a]=O; } trace address &#38; value; ) NeedToTrace[a]=O; ) (c): unique-spanningO reads window.boundary.hook \n{ read_hook(a) { write_hook(a) { NeedToTrace bit-vector= if ( NeedToTrace[a] ) NeedToTrace[a]=O; NOT \n( Traced bit-vector); trace address &#38; valuty Traced[a]=O; ) NeedToTrace[a]=O; } Traced[a]=l; } (d): \nunique-spanning\u00ad reads Figure 2. Fixed-window-size tracing algorithms, performed at each window boundary \n(window_boundary_hook), each read (read_hook) and each write (write_hook). most system calls access \ncontiguous regions of memory locations will be detected as unique-spanning and traced as (such as reading \nfrom disk into a buffer). usual. We could immediately trace the values as done when tracing unique writes, \nbut resetting the bits has the Second, after the system call we must either specially advantage that \nvalues not subsequently used will not beupdate the bltvectors or emit a trace, depending on the type \n traced. of tracing being done. If we are tmcing unique writes, we must immediately trace the values \nof the locations possibly Fina31y, we always emit a trace record (not shown in modified. We cannot wait \nuntil the window s end since the Figure 3) indicating that a system call was made, but need values might \nbe read or written any time after the call. We not record which one since exactly the same call will \nbe must also zero the associated bits in Written so the locations issued during replay. As an optimization, \nif we know that will not be re-traced at the window s end unless they are reexecuting a particular system \ncall will exactly reproduce subsequently written. However, if we are tracing unique-its original execution \n(e.g., a read from a read-only file), we spanning reads, we can fool the atgorithm into automati-can \ntreat it as any other sequence of reads and writes. cally tracing these values at the point where they \nare subse- This scheme fails for interactions with the environ\u00ad quently read. By resetting bitvector \nentries corresponding ment where state is maintained outside of the user s process to the modified locations, \nany subsequent reads of these (such as on a bit-mapped display). When state changes to an external device \nmust be reproduced, the device s state must also be traced during execution and restored during replay \nwhen the system call is reached. Instrumentation must be added to the system call to handle the details \nof how the device s state is accessed. We can also integrate into our scheme an approach for tracing \nwhen interrupts occur and producing them dur\u00ading replay[9]. By instrumenting the program to maintain \na software instruction counter, interrupt handlers can trace the value of the counter and the PC when \nan interrupt occurs. During replay a watchpoint can be set for the loca\u00adtion at which the interrupt initially \ncecurred to check the instruction counter against the traced value. When the counter reaches the traced \nvalue, a jump can be made to the interrupt handler. We finally mention an attractive property of the \nalgo\u00adrithm: it can gracefully degrade in the presence of limited disk space for traces. If trace space \nis limited, the trace (or parts of it) can be compacted on-the-flyby suspending exe\u00adcution and compressing \nthe trace file genemted so far. By re-running the tracing algorithm from the trace, and increasing T \nor M, a new trace file is produced smaller than the original For example, doubling T will double the \nreplay bound but reduce the trace size. This doubling can be performed indefinitely and will in the limit \nwill reduce the trace to only the reads of uninitialized variables and the values traced tlom system \ncalls (with T at its maximum, only these reads are unique-spanning). Thus, executions of great length \ncan probably be traced, with T or M doubling automatically as needed. (no sub-word read hook required) \nsubword_write_hook(a) { sys_call_hooko { w = addr of word containing x make the system call; Written[w]= \n1; estimate addresses written; } for all written locations, a trace a &#38; value at w Written[a] = O \n} (a): unique writes subword_read_hook(a) { subword_write_hook(a) { sys_call_hook { w = addr of word \ncontaining &#38; w = addr of word containing w make the system cal~ call regular read_hook(w); Traced[w] \n= O; estimate addresses written; } } for all written locations, a Traced[a] = O; NeedToTrace[a] = 1; \n} (b): unique-spanningM reads subword_read_hook(a) { (no sub-word write hook required) sys_call_hooko \n{ w = addr of word containing % make the system cal~ call regular read_hook(w); estimate addresses written; \n} for all written locations, a NeedToTrace[a] = 1; } (c): unique-spanuin~ reads subword_read_hook(a) \n{ subword_write_hook(a) { sys_call_hooko { w = addr of word containing T w = addr of word containing \nz make the system cal~ call regular read_hook(w); Traced[w] = O; estimate addresses written; ) } for \nall written locations, a Traced[a] = O; NeedToTrace[a] = 1; ) (d): unique-spannti~ reads Figure 3. Hooks \nfor tracing partial-word reads and writes, and system calls. 4.2. Implementation on the Spare The tracing \nalgorithms me conceptually simple but because they perform on-line analysis at each read and write operation \nthey require careful implementation. We have developed several strategies to instrument programs at the \nassembly level to keep the run-time overhead accept\u00adable. We focus on the Spare, but the general ideas \nare applicable to any RISC processor. Although the instrumen\u00adtation could also be added by a compiler, \nby editing the executable to jump to an appropriate hook after every memory reference[12, 7], or by hardware \nsupport, our implementation is tuned for our particular application. To make the bitvector operations \nefficient, we employ two-level bitvectors and maintain one bit per four\u00adbyte word as discussed above. \nSince we do not know in advance which addresses the program may reference, a flat bitvector for a 32-bit \naddress space would occupy 128 megabytes of storage. A two-level bitvector is a table of pointers to \nbitvector fragments, with each fragment being allocated only when a reference is made to the memory region \nit represents. Accessing them is still quick, requir\u00ading only two memory references, and we show in Section \n6 that their space overhead is low. Other work has also reported good experience with two-level bitvectors[13]. \nIn addition, assigning only one bit per word leaves the bottom two bits of each address to be used as \ntags to encode the trace record type (to indicate a value, system call, signal, or end-of-window marker). \nSince the bitvector operations must be performed at each read or write, we optimize them for the common \ncase. The common case is a read that is not unique-spanning and thus not traced (Section 6 shows that \nonly a small percent\u00adage of reads require tracing). Since writes occur less fre\u00adquently than reads, the \nperformance of the write hook is less critical (except when tracing unique writes, which requires no \nread hook). A crucial part of the instrumenta\u00adtion is that condition codes must not be a.lte~d since \ninstru\u00admentation can be inserted anywhere a load or store occurs. However, there is no user-level instruction \non the Spare to save condition codes, although an (expensive) operating system trap exists to save them. \nWe overcome this problem by coding the instrumentation so it does not atter the condi\u00adtion codes in the \ncommon case. Even though the instru\u00admentation must do several checks, such as determining whether a bitvector \nsegment is currently altocated or whether the bit itself is zero, we can perform these checks without \naltering the condition codes. The idea is to do an indirecl jump to an address computed from the value \nof the bit being tested, thereby avoiding a traditional conditional jump (which would require altering \nthe condition codes). The jump either returns from the instrumentation or calls another routine to perform \nadditional work (if a bitvector segment must be allocated or if a read requires tracing). Another important \ntrick we employ is to implement a software instruction counter (SIC) to provide the ability to replay \ninterrupts and avoid doing end-of-window checks at each load and store instruction. We adapt an idea \nproposed by Mellor-Cmmmey[9] of incrementing a counter at each backward branch and procedure call. The \nvalue of this counter together with the PC uniquely identifies each instruction instance. We could use \nsuch a counter to deter\u00admine when a window boundary is reached, but if such a check were done before \neach backward branch, the condi\u00adtion codes would have to be saved. To avoid this overhead, we instead \nincrement and test the counter before each instruction that alters the condition codes so they need not \nbe saved. Since there is probably one such instruction for each conditional branch, such a check still \nlocates window boundaries with reasonable accuracy. Another way to determine when a window boundary is \nreached is to employ an interval timer that causes a signal handler to be called periodically (with the \nperiod specitied by the user). The handler patches one word in the common part of the instrumentation \ncode (which every read or write hook calls) so that on the next memory reference the window boundary \nprocessing is performed (window_boundary hook in Figure 2) and the code is patched back to its origfird \nstate. This scheme avoids doing a test each time the SIC is incre\u00admented, but requires that an interval \ntimer be available. Since we expand each assembly instruction that ref\u00aderences memory into a sequence \nof instructions, we must also carefully handle instruction delay slots (such as those for branches). \nWe move the instrumented instruction out of the delay slot to before the branch, or move one copy to \neach target of the branch. Correctly handling delay slots in all cases is actually more complex, but \nwe omit the details here. 5. Replaying from the Trace We now discuss how to replay any of the execution \ns windows. There are two parts to replay: restoring the ini\u00adtial state of the window s memory from the \ntrace, and per\u00adforming the replay itself. An important point is that the same instrumented code must \nbe used during reexecution as during the original execution. Otherwise, if a different (uninstrumented) \nversion of the program were reexecuted, any function pointers restored from the trace might not have \nthe proper value, although the hooks can be changed to perform replay-specific tasks as long as their \nsize remains unchanged.  5.1. Restoring the State spanning. reads, and unique-spanningm reads. Second, \nwe To replay a given window, we must restore some of the memory s state (and all the registers) before \nreexecu\u00adtion. This state is restored differently depending on what type of tracing was performed. When \nunique-spanning~ read tracing was done, the values that the window will need (and that will not be recomputed \nduring replay) are guaran\u00adteed to be in the window s traces or the tmces of the previ\u00adous M/T windows. \nWe simply restore the state by scan\u00adning the previous M/T windows traces, and the current window s trace \nbut only up to the tmce of the first system call. Traces made after a system call must not be restored \nuntil after the call is skipped during replay (we address this issue below). Restoring this state is \nstraightforward: we make a linear pass through the trace and place into memory the value in each trace \nrecord. Restoring the state when unique write tracing was done is more complex. For unique writes, we \ndo not know which memory locations will be read by the window s replay (this information was not initially \ntraced). We must therefore restore tie entire state of memory which appears in the trace before the window \ns traces. System calls are handled as above. With the exception of handling system calls, this scheme \nis identical to how the IGOR system (dis\u00adcussed in Section 2) restores its state, and might be made easier \nby perhaps constructing indexes to identify the most recent trace of each address. An alternative is \nto trace the addresses that each window actually reads and restore only these locations, but such an \napproach would incur more run-time overhead and still require scanning the trace to find the necessary \ntrace records. 5.2. Handling the Replay Once the state is restored, the reexecution begins by jumping \nto the appropriate location in the program (we assume the program counter was traced at each window boundary). \nOnce reexecution begins, we must also spe\u00adcially handle system calls. We instrument system calls so they \nknow that a replay is in progress and the call into the system is not made. Instead, additional state \nis restored before returning to reproduce the side-effects of the call. We read and restore values from \nthe trace file from the point last read up to the trace record for the next system call (or to the win\u00addow \ns end, whichever occurs tlrst). This restores sufficient state to replay up to the next system call, \nsince during exe\u00adcution any values possibly modified by the call were either traced when the call returned \nor traced when eventually read. Once these values are restored, the program can con\u00adtinue reexecuting. \n6. Experimental Measurements We performed four experiments to assess our ideas. First, we compared the \ntracing of unique writes, unique\u00adlarger than optimal. Third, we compared our approaches to the IGOR[5] \nand PPD[4, 10] systems. We trace 1-2 orders of magnitude less than IGOR, and usually 4 50 times less \nthan PPD when PPD provides quick replay. In some cases the PPD traces are small but they cannot pro\u00advide \nquick replay, and in these cases we provide quick replay with a trace of less than twice as large. Finally, \nwe measured the run-time overhead of an implementation of our algorithms on a Spare 10. Our algorithms \nincur slow\u00addowns of about a factor of 1.75 7 (depending on which type of tracing is done) and generate \nabout 15 kilobytes of trace per second. We conclude that our scheme simultane\u00adously bounds the replay \ntime while keeping mace genera\u00adtion low, and is probably faster than writing large traces to relatively \nslow disks. compared trace sizes produced by our fixed-window size algorithms to the optimal algorithms. \nThe fixed-window algorithms are effective, producing traces less than 50% We divided our experiments \ninto two parts: one to analyze the trace sizes and another to measure run-time overhead. To analyze the \ntrace sizes, we ran four programs using the vmon tool which rewrites executable to obtain the necessary \nhooks[12]. This allowed us to call a function at each memory reference that simulated our tracing algo\u00adrithm \non all possible window sizes simultaneously. We analyzed the C compiler supplied with SunOS version 4.1.3 \n(ccom) when compiling an 11,214-line program, the UNIX compress utility (comprem) when compressing the \nlex exe\u00adcutable, a program that randomly generates directed graphs and runs two scheduling algorithms \non the graph to com\u00adpare their results (event), and a program that computes finite differences by making \none pass over a 2011x 200 mesh (mesh). The ccom, compress, and event programs ~present computations of \na symbolic nature; mesh is numerical. We analyzed other programs as well, but the trace sizes of these \nfour are representative. The ccom, com\u00adpress, event, and mesh programs performed 15 million, 1.34 million, \n122 thousand, and 539 thousand memory ref\u00aderences, respectively. To analyze run-time overhead, we wrote \nan assembly level instrumentor using the techniques outlined in Section 4 and ran several long-running \nprograms (discussed later). The curves in this section plot the replay bound (i.e., the fixed window \nsize T) vs trace size. Since the programs had different execution lengths, the replay bound and trace \nsize are given as a percentage of the total number of mem\u00adory references. Due to the large difference \nbetween some of the curves, the plots appear on log-log scales.  6.1. Comparison of the Three Types \nof Tracing Figure 4 compmes for each program the trace sizes of unique writes, unique-spanning. reads, \nand unique\u00ad10 1 01 1 0.01I A 001 0.1 100 Replay Bound (OA of execution ~i%e) (a): ccom ~ u al s 10+ \n g c $!2 ~ 1 A!? ~ E 3 0.1 3 s 001 0,01 0.1 100 Replay Bound (O/~lof execution ;i%e) (c): event Figure \n4. Comparison of the three spanning-reads. There are 3 100 times fewer unique\u00adspanningm reads than other \ntypes of operations, and unique writes did as well or better than unique-spanning. reads. Locality of \nreference means that many reads are often pre\u00adceded by writes in the same window and thus are not unique-spanning \n(but the writes are still unique writes). However, in some cases (notably ccom), data that is written \nonce and read many times (such as the compiler s symbol table) causes fewer unique writes to exist than \nunique\u00adspanningO reads. We conclude that Unique-spanningm reads are preferably when trace size must be \nreduced as much as possible. Otherwise, the run-time vs replay-time overhead tradeoff must be considered, \nunique-spanniingo reads guarantee bounded replay time, but detecting unique writes incurs less run-time \noverhead (discussed later). Note that the trace sizes often tend to decrease exponentially with increasing \nwindow sizes, suggesting that a window size as large as tolerable should be used. ++-...+..._+_ *...a.e.= \n.....=..=.e.m-... ~.. 1 0.1 t Unique-Spannin Unique-Spanning n! l (O m Reads ritesReads -+--\u00ad --=---- \nI ---. 0.01 0.1 100 Replay Bound (% of execution ;i~e) (b): compress 10 1 0.1 JI0.01 0.01 0.1 1 10 \n100 Replay Bound (% of execution time) (d): mesh styles of adaptive tracing. 6.2. Comparison of Fixed-Window \nand Optimal Tracing Figure 5 compares the trace sizes for the fixed\u00adwindow algorithm and the optimal \nalgorithm for uuique\u00adspauningo and unique-spanning= reads (the fixed-window algorithm for unique writes \nis already optimal). By opti\u00admal we mean that the fewest number of unique-spanning reads are traced (under \nthe assumptions discussed in Sec\u00adtion 3). We implemented the optimal algorithm by con\u00adstructing a weighted \ndirected graph on-line and computing the shortest-path through the gmph. The fixed-window algorithms \ngenemted traces at most 50% larger than opti\u00admal for ccom and event. For compress and mesh, the algo\u00ad \nrithms were nearly optimal, Because this analysis required O(nT) time (where n is the number of memory \nreferences and T is the maximum window size) it became expensive as T grew and for ccom (the longest \nrunning program) opti\u00admat data points beyond T = O.3 % could not be obtained. Fixing the window size \nappears to work well because of locality: for almost any window placement, most reads inside the window \nare not unique-spanning. Thus, fixed windows are nearly as good as carefully placed, optimal windows. \n6.3. Comparison to IGOR and PPD Figure 6 compares the size of our adaptive traces to traces generated \nby the IGOR and PPD systems. IGOR checkpoints periodically, such as every S seconds (where S is given \nby the user), although we checkpointed every T memory references for this study. Each checkpoint saves \nto disk the pages written since the last checkpoint (our page size was 4k bytes)[5]. However, as discussed \nin Section 2, IGOR does not guarantee how Ion!g it can take to restore the state for a replay since the \nentire trace file might need to be read. IGOR wrote huge traces, over two orders of mag\u00adnitude larger \nthan the unique-spanning read trace. Despite , 10 1 01 n ni  0.01 10 100 R~p;ay Bound (% of execution \ntime) (a): ccom 100 * 10 --=%......m... --m... .-a 1 q 0.1 .1 .E%i%iE%~i~m~\\: Upwards-Exposed(In Rds \noptimal -*\u00ad 0.01 0.01 0.1 100 Replay Bound (% IDf execution ;i~e) (c): event locality, a page granularity \nof tracing is too large to keep the trace size small, especially when T is small (i.e., when the user \nneeds quick replay). The IGOR curves in Figure 6 go off the top of the scale and are not completely shown. \nPPD generates a prelog and postlog for each proce\u00addure called. We simulated PPD tracing by computing \nthe exact logs. A real PPD system uses compile-time analyses to conservatively determine which variables \nshould be in the log, and traces every access to variables it is unsure about (such as references through \npointers). Our simula\u00adtion thus underestimates the PPD trace size. Since check\u00adpoints are not written \nat regular intervals, PPD does not guarantee how long a replay may take. Note that the PPD curves are \nflat in Figure 6 since T is not a pammeter to PPD (but we still show PPD s trace size on the figure for \ncom\u00adptison). 10 1 1 0.1 M=:=$=:$l :2 %: =\u00ad Upwards-Exposed(O Rds optimal 001 t I Upwards-Exposed(in ) \nRds [ optimal 1 -- -*- IJ 0.01 0.1 10 100 Replay Bound (% of execution time) (b): compress 100 1 10 \n1 0.1 0.01 0.01 0.1 100 Replay Bound (OA of execution ;i~e) (d): mesh  Figure 5. Comparison of fixed-window \nand optimal tracing. 10 1 0.1 -. , 0.01 0.1 100 Replay Bound (% of execution &#38;e) (a): ccom 10 1 \nIGOR + 01 PPD .-+--\u00ad Unique-Spanning m Reads -A-\u00ad t ni ue-span$?i::z :  0.01 0.1 100 Replay Bound (% \nof execution ~i~e) (c): event Figure 6. Comparison of trace To make a fair comparison, we must consider \nthis issue. For ccom and compress, the PPD traces were suffi\u00adcient to provide a replay bound of about \nO. 170 of the execu\u00adtion (i.e., most procedures lasted about O.1% of the total execution time). For event \nthe bound was between O. 1 and 17%, and for mesh the bound was 99%. Mesh consists of one large procedure, \nand since PPD writes a trace onlly on procedure entry and exit, it is unable to start the replay from \ninside the procedure. Figure 6 shows that when PPD provides quick replay, we can achieve the same replay \nbound with traces 4 50 times smaller. For mesh (where PPD provides slow replay), we can provide quick \nreplay while tracing only O 2 times more. These results show that adaptive tracing with fixed-size windows \nprovides bounded replay while recording only a few percent of the memory references. 100 10 -......m...*a*m-......m...m.m.mm\u00ad---------.. \n_-A 1 IGOR v0.1 P,PD -+--\u00ad Unique-Spanmng m Reads -A-\u00ad 0401 0,01 0.1 100 Replay Bound (% of execution \n&#38;e) ni ue-span$?!!g:z 1 (b): compress 100b -m ...-.m..-.G.m@-. .....=..*. IGOR + 0.1 PPD -+--\u00ad  \n  1 1 0.01 L ni ue-span$?!r pzUnique-Spanmng m Reads 2:-+-. .4 0.01 0.1 10 100 Replay Bound (% of \nexecution time) (d): mesh sizes to other systems. 6.4. Rnn-Time Overhead Our last experiment addressed \nour algorithms run\u00adtime overheads. We measured the overhead of an imple\u00admentation on a Spare 10 running \nSunOS 4.1.3. This imple\u00admentation instruments programs at the assembly level using the techniques outlined \nearlier. Our implementation detects window boundaries by using an interval timer, instruments all Spare \ninstructions that reference memory, and the pro\u00adgrams we tested were linked with instrumented versions \nof libraries and system-call hooks. We analyzed several exe\u00adcutions that ran long enough to be difficult \nto debug with\u00adout a replay tool. We ran longer executions of mesh and even~ mesh performed 30,000 iterations \nover the mesh, and event ran two scheduling algorithms on 30,000 randomly generated graphs of about 700 \nnodes each. We ran a l~e program which computed 8500 generations on a 100x 100 grid. To test interactive \nprograms, we played a 20-minute game of nethack, and edited this section of the paper with 323 Figure \n7. Overheads mesh Uninstrumented running time (rein) 16.48 Unique writes: running time (rein) 35.46 slowdown \n2.15 trace size (kbytes) 34,248 trace rate (kbytes/see) 16 bitvector size (bytes) 16,384 Unique-spanningO \nreads: running time (rein) 112.7 slowdown 6.83 trace size @bytes) 35,847 trace rate (kbytes/see) 5 bitvector \nsize (bytes) 16,384 Unique-spanning\u00ad reads: running time (rein) 113.0 slowdown 6.85 tmce size (kbytes) \n35,848 trace rate (kbytes/see) 5 bitvector size (bytes) 16,384 an instrumented version of the vi editor. \nThese two pro\u00adgrams are very interactive, performing little computation between keystrokes. We measured \neach program s original execution time, the slowdown incurred by each tracing algorithm, the trace size \nand rate of trace generation, and the total size of all bitvector segments allocated during the run. \nFigure 7 shows the results. The window length was chosen to be approximately five seconds of uninstrwnented \nexecution time, Since the slowdowns for each type of trac\u00ading are different, we chose a window length \nof 10 seconds for unique write tracing (since it runs about twice as slow as the uninstrumented program), \nand 30 seconds for unique--spanning read tracing. Unique-write tracing incurred the least slowdown, usually \na factor of two, although slowdowns are greater for programs that write to many distinct locations. Having \nno read hook, and having to write out the trace only at a win\u00addow s end, takes less time on a SpCarc10 \nthan writing the extra trace data that unique writes incur. Even though unique-spanning read tracing \nrecords less, the time taken by the algorithms on-line analyses is currently greater than the cost savings \nof reduced disk I/O. However, the run-time vs replay-time tradeoff must also be considered. In cases \nwhere the time to setup the state for a replay must be low, unique-spanningO reads have the advantage. \nIn cases where the trace size must be mini\u00admized, unique-spanning-reads have the edge, although our event \nlife nethack vi 40.75 8.25 =20 = 10 75.01 14.53 1.73 1.76 44,266 1,760 10 2 16,384 4,096 321.01 23.0 \n7.87 2.78 43,288 920 2 0.67 16,384 8,192 319.13 21.49 =20 = 10 7.83 2.60 not noticeable not noticeable \n41,227 880 86 208 2 0.68 0.07 0.367 20,480 8,192 180,224 36,864 of tracing algorithms. data suggests \nthat the trace size of unique-sparmingO reads is competitive. Thus, we expect that users would currently \nchoose between unique writes (when overhead must be minimized) and unique-spanningO reads (when replay \nsetup time must be minimized). In addition, as machines become faster and the gap between CPU speed and \ndisk I/O contin\u00adues to widen, the slowdown of unique writes should start to approach that of the others. \nEventually the run-time analy\u00adsis required for detecting unique-spanning reads will be cheaper than writing \nthe extra trace required by unique writes. An important finding is that the rate of trace genera\u00adtion \nis acceptable (less than about 15 kilobytes/see) even though the window length was only 10 30 seconds. \nThis tmce rate suggests that a gigabyte disk will suffice to trace executions of a day s length without \nrequiring trace com\u00adpression (as discussed in Section 4.1). With trace compres\u00adsion, executions of several \nday s length can be accommo\u00addated. As suggested by the curves in Figure 4, we also found that the rate \nof trace generation depends on the selected window length with respect to the execution s locality of \nreference. Choosing too small a window length for executions with large working sets can increase trace \nrates dramatically (for a window length of one second, mesh s trace rate increases to 143 kilobytes/see \nfor unique writes and to 32 kilobytes/see for unique-spanning reads). Experimentation is required to \ndetermine values that work well, although very small window lengths (under five sec\u00adonds) are often impractical. \nThe window lengths we chose above (about five seconds of uninstrumented running time) allows any five-second \nportion of the original executions to be replayed. Our tracing algorithms perform particularly well on \ninteractive programs. The slowdown of the instrumented versions of nethack and vi was not noticeable. \nThe interac\u00adtive nature of these programs caused traces to be generated at a low rate (70 367 bytes/see \nfor unique-spanning\u00adreads). We expect our tracing techniques to have low enough overhead on interactive \nprograms that they can be left on during the entire testing and debugging phase. Figure 7 also shows \nthat the space overhead of the bitvector segments is low. We used four kilobyte segments, which required \na 128 kilobyte table of segment pointers for each bitvector (space for this table is not included in \nthe figure). The pointer table size can be reduced by increasing the segment size, and we expect that \nthis overhead is not significant. 7. Conclusions Our adaptive tracing strategies make possible the trace-and-replay \ndebugging of long-running programs that interact with their environment. We can automatically trace long-running \nprograms with a 1.75 7 times slowdown, generating less than 15 kilobytes/see of trace (and some\u00adtimes \nas little as 2 kilobyteskc). Interactive programs can be traced with trace generation on the order of \n100 s of bytes/see and no noticeable slowdown. The run-time slow\u00addowns are probably acceptable given \nthe functionality that is being provided, especially for interactive programs. Although our implementation \nwas carefully tuned, we see more short-term improvements possible, such as optimizing the read and write \nhooks more by hand, exploring the use of dedicated registers (e.g., to store the address of the bitvector \nsegment pointer table), and the use of additional processors on a multi-processor workstation. In addition, \nwe expect that static analysis might be able to provide a significant reduction in overhead by determining \nthat some references need not be analyzed at all (because they will either never be traced or will always \nbe traced). Such improvements are left to future work. Acknowledgements We thank David Vorbnch for discovering \nthat the optimal tracing problem is not NP-hard and for implement\u00ading some of the simulations. Steve \nReiss wrote the vmon tool used to obtain the read/write hooks for some of the simulations. References \n[1] Hiralal Agrawal, Richard A. DeMillo, and Eugene H. Spafford, An Execution-Backtracking Approach to \nDebugging, IEEE Sofmare, pp. 21-26 (May 1991). [2] Thomas Ball and James R. Larus, Optimally Pro\u00adfiling \nand Tracing Programs, Symp. on Principles of Programming Languages, pp. 59-70 (January 1992). [3] Jong-Deok \nChoi and Janice M. Stone, Balancing Runtime and Replay Costs in a Trace-and-Replay System, ACMIONR Workshop \non Parallel and Distributed Debugging, pp. 26-35 Santa Cruz, CA, (May 1991). [4] Jong-Deok Choi, Barton \nP. Miller, and Robert H. B. Netzer, Techniques for Debugging Parallel Pro\u00adgrams with Flowback Analysis, \nACM Trans. on Programming Languages and Systems 13(4) pp. 491-530 (October 1991). [5] Stuart I. Feldman \nand Charming B. Brown, IGOR A System for Program Debugging via Reversible Execution, Proc. of the SIGPLANISIGOPS \nWork\u00adshop on Parallel and Distributed Debugging, Madi\u00adson, WI, (May 1988). [6] James R. Larus, Abstract \nExecution: A Technique for Efficiently Tracing Programs, Software Practice and Experience 20(12) pp. \n1241-1258 (December 1990). [7] James R. Larus, Efficient Program Tracing, IEEE Computer 26(5) pp. 52-61 \n(May 1993). [8] Kai Li and W. K. Fuchs, Compiler Assisted Static Checkpoint Insertion, Proc. of Fault \nTolerant Computing Systems, (1992). [91 J. M. Mellor-Crummey and T. J. LeBlanc, A Soft\u00adware Instruction \nCounter, Proc. of the Third ASP-LOS, (April, 1989). [10] Barton P. Miller and Jong-Deok Choi, A Mecha\u00adnism \nfor Efficient Debugging of Parallel Pro\u00adgrams, SIGPLAN Corf on Programming Lan\u00adguage Design and Implementation, \npp. 135-144 Atlanta, GA, (June 1988). [11] James S. Plank and Kai Li, Faster CheckPointing with N+ 1 \nParity, Tech Report CS-93-219, Univ. of Tennessee, (Dee 1993). [12] Steven P. Reiss, Trace-Based Debugging, \nAADE-BUG 93, Linkoping, Sweden, (May 1993). [13] Robert Wahbe, Steven Lucco, and Susan L. Gra\u00adham, Practical \nData Breakpoints: Design and Implementation, SIGPLAN 93 Conference on Pro\u00adgramming Language Design and \nImplementation, pp. 1-12 Albuquerque, NM, (June 1993). [14] Paul R. Wilson and Thomas G. Moher, Demonic \nMemory for Process Histories, Proc. of the SIG-PLAN 89 PLDI Conf., pp. 330-343 (June 1989).  \n\t\t\t", "proc_id": "178243", "abstract": "", "authors": [{"name": "Robert H. B. Netzer", "author_profile_id": "81332518128", "affiliation": "Brown Univ., Providence, RI", "person_id": "PP31090636", "email_address": "", "orcid_id": ""}, {"name": "Mark H. Weaver", "author_profile_id": "81406593407", "affiliation": "Brown Univ., Providence, RI", "person_id": "PP43116057", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/178243.178477", "year": "1994", "article_id": "178477", "conference": "PLDI", "title": "Optimal tracing and incremental reexecution for debugging long-running programs", "url": "http://dl.acm.org/citation.cfm?id=178477"}