{"article_publication_date": "06-01-1994", "fulltext": "\n ATOM A System for Building Customized Program Analysis Tools Amitabh Srivastava and Alan Eustace Digital \nEquipment Western Research Laboratory 250 University Ave., Palo Alto, CA 94301 {amitabh, eustace}(!decwrl \n.pa. dec. com Abstract 1 Introduction ATOM (Analysis Tools with OM) is a single framework for Program \nanalysis tools are extremely important for under\u00adbuilding a wide range of customized program analysis \ntools. standing program behavior. Computer architects need such It provides the common infrastructure \npresent in all code-tools to evaluate how well programs will perform on new instrumenting tools; this \nis the difficult and time-consuming architectures. Software writers need tools to analyze their part. \nThe user simply defines the tool-specific details in programs and identify critical pieces of code. Compiler \nwrit\u00adinstrumentation and analysis routines. Building a basic block ers often use such tools to find out \nhow well their instruction counting tool like Pixie with ATOM requires only a page of scheduling or branch \nprediction atgorithm is performing or code. to provide input for profile-driven optimizations. ATOM, \nusing OM link-time technology, organizes the fi-Over the past decade three classes of tools for different \nnal executable such that the application program and user s machines and applications have been developed. \nThe tirst analysis routines run in the same address space. Informa-class consists of basic block counting \ntools like Pixie[9], tion is directly passed from the application program to the Epoxie[14] and QPT[8] \nthat count the number of times each analysis routines through simple procedure calls instead of basic \nblock is executed. The second class consists of ad\u00adinter-process communication or files on disk. ATOM \ntakes dress tracing tools that generate data and instruction traces. care that anatysis routines do not \ninterfere with the program s Pixie and QPT also generate address traces and commu\u00adexecution, and precise \ninformation about the program is pre-nicate trace data to analysis routines through inter-process sented \nto the analysis routines at all times. ATOM uses no communication. Tracing and analysis on the WRL Titan \n[3] simulation or interpretation. communicated via shared memory but required operating ATOM has been \nimplemented on the Alpha AXP under system modifications. MPTRACE [6] is also similar to Pixie OSF/1. \nIt is efficient and has been used to build a diverse but it collects traces for multiprocessors by instrumenting \nset of tools for basic block counting, profiling, dynamic assembly code. ATUM [1] generates address traces \nby mod\u00admemory recording, instruction and data cache simulation, ifying microcode and saves a compressed \ntrace in a file that pipeline simulation, evaluating branch prediction, and in-is analyzed offline. The \nthird class of tools consists of sim\u00adstruction scheduling. ulators. Tango Lite[7] supports multiprocessor \nsimulation by instrumenting assembly language code. PROTEUS [4]Permission to cop without fee all or part \nof this material is granted provided t{ at the copies are not made or distributed for also supports \nmultiprocessor simulation but instrumentation direct commercial advantage, the ACM copyright notice and \nthe is done by the compiler. g88[2] simulates Motorola 88000 title of the publication and its date appear, \nand notice is given using threaded interpreter techniques. Shade[5] attempts to that copying is by permission \nof the Association of Computing Machinery. To copy otherwise, or to republish, requires a fee address \nthe problem of large address traces by allowing selec\u00adand/or specific permission. tive generation of \ntraces but has to resort to instruction-level SIGPLAN 94-6/94 Orlando, Florida USA simulation. Q 1994 \nACM 0-89791 -662-xJ9410006..$3.5O These existing tools have several limitations. First, most tools are \ndesigned to perform a single specific type of instrumentation, typically block counting or address tracing. \nModifying these tools to produce more detailed or less detailed information is difficult. A tool generating \ninsufficient information is of no use to the user. Second, most address tracing tools compute detailed \nad\u00address information. However, too much computed informa\u00adtion renders the tool inefficient for the user. \nFor example, a user interested in branch behavior has to sift through the en\u00adtire instruction trace, \neven though only conditional branches need to be examined. The instruction and address traces are extremely \nlarge even for small programs and typically run into gigabytes. Third, tools based on instruction-level \nsimulation add large overheads to the processing time. Several techniques have been used to make the \nsimulation faster, such as in the Shade system, but simulation nevertheless makes the programs run many \ntimes slower. Fourth, tools such as Tango Lite, which instrument assem\u00adbly language code, change the \napplication program s heap addresses. Instrumenting library routines is inconvenient as all libraries \nhave to be available in assembly language form. Finally, most address tracing tools provide trace data \ncol\u00adlection mechanisms. Data in form of address traces is com\u00admunicated to the data analysis routines \nthrough inter-process communication, or files on disk, Both are expensive, and the large size of address \ntraces further aggravates this problem. Using a shared buffer reduces this expense but still requires \na lot of process switching and sometimes can be implemented efficiently only with changes to the operating \nsystem. ATOM overcomes these limitations by providing the prin\u00adcipal ingredient in building performance \ntools. The important features that distinguish it from previous systems are listed below. ATOM is a tool-building \nsystem. A diverse set of tools ranging from basic block counting to cache modeling can be easily built. \nATOM provides the common infrastructure in all code\u00adinstrumenting tools, which is the cumbersome part. \nThe user simply specifies the tool details. ATOM allows selective instrumentation. The user spec\u00adifies \nthe points in the application program to be irMru\u00admented, the procedure calls to be made, and the argu\u00adments \nto be passed. The communication of data is through procedure calls. Information is directly passed from \nthe application pro\u00adgram to the specified analysis routine with a procedure call instead of through interprocess \ncommunication, files on disk, or a shared buffer with central dispatch mechanism. Even though the anatysis \nroutines run in the same ad\u00address space as the application, precise information about the application \nprogram is presented to analysis routines at all times. As ATOM works on object modules, it is independent \nof compiler and language systems. In this paper, we describe the design and implementation of ATOM. We \nshow through a real example how to build tools. Finally, we evaluate the system s performance. 2 Design \nof ATOM The design of ATOM is based on the observation that al\u00adthough tasks like basic block counting \nand cache simulation appear vastly different, all can be accomplished by instru\u00admenting a program at \na few selected points. For example, basic block counting tools instrument the beginning of each basic \nblock, data cache simulators instrument each load and store instruction, and branch prediction analyzers \ninstrument each conditional branch instruction. Therefore, ATOM al\u00adlows a procedure call to be inserted \nbefore or after any pro\u00adgram, procedure, basic block, or instruction. A program is viewed as a linear \ncollection of procedures, procedures as a collection of basic blocks, and basic blocks as a collection \nof instructions. Furthermore, ATOM separates the tool-specific part from the common infrastructure needed \nin all tools. It provides the infrastructure for object-code manipulation and a high\u00adlevel view of the \nprogram in object-module form. The user defines the tool-specific part in instrumentation routines by \nindicating the points in the application program to be instru\u00admented, the procedure calls to be made, \nand the arguments to be passed. The user also provides code for these proce\u00addures in the analysis routines. \nThe analysis routines do not share any procedures or data with the application program; if both the application \nprogram and the analysis routines use the same library procedure, like print f, there are two copies \nof print f in the final executable, one in the application program and the other in the analysis routines. \nATOM1 internally works in two steps, as shown in Figure 1. In the first step, common machinery is combined \nwith the user s instrumentation routines to build a custom tool. This tool will instrument an application \nprogram at points specified by the user s instrumentation routines. In the second step, this custom tool \nis applied to the appli\u00ad cation program to build an instrumented application program executable. The \ninstrumented executable is organized so that information from application program is communicated 1ExtemaUy, \nthe user specifies: atomprog in.rt.c ard.c -o Prog.atom to produce dre instrumented program prog.atom. \n n user applia2a3ion application generic object moditier analysis output n user instruouenting user \na~:~is application output Figure 1: The ATOM Process directly to procedures in the analysis routines \nthrough proce\u00addure calls. The data is passed as arguments to the handling routine in the requested form, \nand does not have to go through a central dispatch mechanism. To reduce the communication to a procedure \ncall, the ap\u00adplication program and the analysis routines run in the same address space. ATOM partitions \nthe symbol name space and places the application and analysis routines in the executable such that they \ndo not interfere with each other s execution. More importantly, the analysis routine is always presented \nwith the information (data and text addresses) about the ap\u00adplication program as if it was executing \nuninstrumented. Section 4 describes how the system guarantees the precise information. ATOM, built using \nOM[l 1], is independent of any com\u00adpiler and language system because it operates on object\u00admodules. Since \nOM is designed to work with different architectures, ATOM can be applied to other architectures. Building \nCustomized Tools: An Example  In this section we show how to build a simple tool that counts how many \ntimes each conditional branch in the program is taken and how many times it is not taken. The final results \nare written to a file. zoM ~a~inltiauy implemented on the DECStations running under UL-TRIX and was ported \nto Alpha AXP running under OSF/1. UL~IX, DEC-Statlon and Alpha AXP are trademarks of Digital Equipment \nCorporation. The user provides three files to ATOM: the application program object module that is to \nbe instrumented, a file con\u00adtaining the instrumentation routines, and a file containing the analysis \nroutines. The instrumentation routines spec\u00adify where the application program is to be instrumented and \nwhat procedure calls are to be made. The user provides code for these procedures in the analysis routines. \nThe next two sections show how to write the instrumentation and analysis routines for our example tool. \nDefhing Instrumentation Routines Our branch counting tool needs to examine all the conditional branches \nin the program. We traverse the program a proce\u00addure at a time, and examine each basic block in the proce\u00addure. \nIf the last instruction in the basic block is a conditional branch, we instrument the instruction. The \ninstrumentation routines are given in Figure 2. ATOM starts the instrumentation process by invoking the \n Instrument contain the Ins process begins in the analysis program. This guments. The the prototypes. \nprOCedure3. All instrumentation modules t rument procedure. The instrumentation by defining the prototype \nof each procedure routine that will be called from the application enables ATOM to correctly interpret \nthe ar-AddCal 1P rot o primitive is used to define In our example, prototypes of four analysis procedures \nOpenFi.le, CondBranch, PrintBranch, and Cl o seFile are defined. Besides the standard C data s~e Instmment \nprocedure takes argc and argv as arguments which can be optionally passedfrom the atom command line. \nInstrument(int iargc, char **iargv) { Proc *p; Block *b; Inst *insq int nbranch = O; AddCaBProto( OpenFile(int) \n); AddCaBProto( CondBranch(int, VALUE) ); AddCalWroto( PrintBranch(int, long) ); AddCallProto( CloseFileo \n); for(p=GetFirstProco; p!=NULL;p=GetNextProc(p)){ for(b=GetFirstBlock(p) ;b!=NULL;b=GetNextBlock(b)){ \ninst = GetLastInst(b); if(IsInstType(inst, InstTypeCondBr)){ AddCallInst(inst, InstBefore, CondBrattch \n, nbranch,BrCondValue); AddCallProgram(ProgramAfter, PrintBranch , nbranch, InstPC(inst)); nbranch++; \n) } } AddCallProgram(ProgramBefore, OpenFile , nbranch); AddCallProgram(ProgramAfter, CloseFile ); \n} Figure 2: Instrumentation Routines: Branch Counting Tool types as arguments, A IXIM supports additional \ntypes such as REGV and VALUE. If the argument type is REGV, the ac\u00adtual argument is not an integer but \na register number, and the run-time contents of the specified register are passed. For the VALUE argument \ntype, the actual argument may be Ef fAddrValue or BrCondValue. Ef fAddrValue passes the memory address \nbeing referenced by load and store instructions. BrCondValue k used for conditional branches and passes \nzero if the run-time branch condition evatttates to a false and a non-zero value if the condition evaluates \nto true. CondBranch uses the argument type VALUE. ATOM atlows the user to traverse the whole program \nby modeling a program as consisting of a sequence of proce\u00addures, basic blocks and instructions. Get \nFirst P roc re\u00adturns the first procedure in the program, and Get Next P roc returns the next procedure. \nThe outermost for loop tra\u00adverses the program a procedure at a time. In each proce\u00addure, Get First Block \nreturns the first basic block and GetNext Block returns the next basic block. Using these primitives \nthe inner loop traverses all the basic blocks of a procedure. In this example, we are interested only \nin conditional branch instructions. We find the last instruction in the ba\u00adsic block using the Get Last \nI nst primitive and check if it is a conditional branch using the Is I nst Type pl im\u00aditive. All other \ninstructions are ignored. With the AddCall Inst primitive, a call to the analysis procedure CondBranch \nis added at the conditional branch instruction. The Inst Bef ore argument specifies that the call is \nto be made before the instruction is executed. The two arguments to be passed to CondBranch are the linear \nnumber of the branch and its condition value. The condition vatue specifies whether the branch will be \ntaken. The AddCallP rogram k used to insert calls before (programBef ore) the application program starts \nexecut\u00ading aud after (P rog ramAf t e r) the application program finishes executing. These calls are \ngenerally used to initial\u00adize analysis routine data and print results at the end, respec\u00adtively. A catl \nto OpenFi le before the application program starts executing creates the branch statistics array and \nopens the output file. We insert calls for each branch to print its PC (program counter) and its accumulated \ncount at the end. Note that these calls are made only once for each conditional branch after the application \nprogram has finished executing. Finally, the CloseFile procedure is executed which closes the output \nfile. If more than one procedure is to be called at a point, the calls are made in the order in which \nthey were added by the instrumentation routines. Defining Analysis Routines The anatysis routines contain \ncode and data for all procedures needed to analyze information that is passed from the applica\u00adtion program. \nThese include procedures that were specified in the instrumentation routines but may contain other proce\u00addures \nthat these procedures may call. The analysis routines do not share the code for any procedure with the \napplication program, including library routines. Code for procedures OpenFi le, CondBranch, PrintBranch, \nand CloseFile whose prototypes were defined in instrumentation routines are given in Figure 3. The OpenFile \nuses its argument containing the number of branches to atlocate the branch statistics array. It also \nopens a file to print results. The CondBranch routine in\u00ad dArl~t,fterme~od would be to store the PC of \neach branch in ~ arraY and pass the array at the end to be printed along wittr ttre counts. ATOM allows \npassing of arrays as arguments. #include <stdio.h> File Wile struct BranchInfo{ long taken; long notTaken; \n} *bstats; void OpenFile(int n){ bstats = (strttctBrrmchInfo *) malloc (n * sizeof(struct BranchInfo)); \nfile = fopen( btaken.out , w ); fprintf(file, PC \\t Taken \\t Not Taken \\n ); } void CondBranch(int n, \nlong taken){ if (taken) bstats[n] taken++; else bstats[n] .notTaken++; } void PrintBranch(int n, long \npc){ fprintf(file, OX%lX \\t %d \\t %d\\n , PC, bstats[n].taken, bstats[n].notTaken); } void CloseFileo{ \nfclose(file); } Figure 3: Analysis Routines: Branch Counting Tool crements the branch taken or branch \nnot taken counters for the specified branch by examining the condition value ar\u00adgument. Print Branch \nprints the PC of the branch, the number of times the branch is taken and number of times it is not taken. \nCloseFi.le closes the output file. Collecting Program Statistics To find the branch statistics, ATOM \nis given as input the fully linked application program in object-module format, the instrumentation routines, \nand the analysis routines. The output is the instrumented program executable. When this instrumented \nprogram is executed, the branch statistics are produced as a side effect of the normal program execution. \n 4 Implementation of ATOM ATOM is built using OM[l 1], a link-time code modifica\u00adtion system. OM takes \nas input a collection of object files and libraries that make up a complete program, builds a symbolic \nintermediate representation, applies instrumenta\u00adtion and optimizations[12, 13] to the intermediate represen\u00adtation, \nand finally outputs an executable. ATOM starts by linking the user s instrumentation rou\u00adtines with OM \nusing the standard linker to produce a custom tool. This tool is given as input the application program \nand the analysis routines. It uses OM S infrastructure to build symbolic representations of the application \nprogram and the analysis routines. The traversal and query primitives inter\u00adface with the intermediate \nrepresentation of the program to provide the information requested. More details of OM S intermediate \nrepresentation and how it is built are described in [11]. We extended the OM S representation so it can \nbe conveniently annotated for procedure call insertions. OM S code generation pass builds the instrumented \nexe\u00adcutable from the intermediate representation. This pass is modified to organize the data and text \nsections in a specific order because ATOM has to ensure that precise information about the application \nis presented to the analysis routines at all times. In this section, we first describe the extensions \nto the inter\u00admediate representation and the insertion of procedure calls. Next, we discuss how we minimize \nthe number of registers that need to be saved and restored. Finally, we describe how ATOM organizes the \nfinal executable. Inserting Procedure Calls We extended the intermediate representation of OM to have \na slot for actions that may be performed before or after the en\u00adtity is executed. The entity maybe a \nprocedure, basic block, ittSttWCtiOtt or an edges. The AddCal 1 primitives annotate the intermediate \nrepresentation by adding a structure to the action slot describing the call to be inserted, arguments \nto be passed, and indicating when the call is to be made. Cur\u00adrently, adding calls to edges is not implemented. \nThe proto\u00adtype of the procedure must already have been added with the AddCa 11P rot o primitive, and \nATOM VtXifi(X that. The action slot contains a linked list of all such actions to be per\u00adformed as multiple \ncalls can be added at a point. The order in which they are added is maintained so that calls will be \nmade in the order they were specified. After the intermediate representation has been fully anno\u00adtated, \nthe procedure calls are inserted. This process is easy 5An edge ~onnect~two basic blocks and representsthe \ntransfer of control between them. 200 because all insertion is done on OM S intermediate represen\u00adtation \nand no address tixups are needed. ATOM, like QPT, does not steal any registers from the application programb. \nIt allocates space on the stack before the call, saves regis\u00adters that may be modified during the call, \nrestores the saved registers after the call and deallocates the stack space. This enables a number of \nmechanisms such as signals, setjmp and vfork to work correctly without needing any special attention. \nThe calling conventions are followed in setting up calls to analysis routines. The first six arguments \nare passed in registers and the rest are passed on the stack. The number of instructions needed to setup \nan argument depends on the type of the argument. For example, a 16-bit integer constant can be built \nin 1 instruction, a 32-bit constant in two instructions, a 64-bit program counter in 3 instructions and \nso on. Passing contents of a register takes 1 instruction. To make the call, a pc-relative subroutine \nbranch instruction is used if the analysis routine is within range, otherwise, the value of the procedure \nis loaded in a register and a js r instruction is used for the procedure call. There\u00adturn address register \nis always modified when a call is made so we always save the return address register. This register becomes \na scratch registeq it is used for holding the proce\u00addure s address for the js r instruction. Reducing \nProcedure Call Overhead The application program may have been compiled with in\u00adterprocedural optimization \nand may contain routines that do not follow the catling conventions 8. Therefore, all regis\u00adters that \nmay be modified in the call to the analysis routines need to be saved, The analysis routines, on the \nother hand, have to follow the calling conventions as they have to allow arbitrary procedures to be linked \nin. The calling conven\u00adtions define some registers as callee-save registers that are preserved across \nprocedure calls, and others as caller-save registers that are not preserved across procedure calls. All \nthe caller-save registers need to be saved before the call to the analysis routine and restored on return \nfrom the analysis routines. This is necessary to maintain the execution state of the application program. \nThe callee-save registers would automatically be saved and restored in analysis routines if they are \nused by them. Iivo issues need to be addressed Gpixie ~te~s three registers away from the application \nprogram for its own use. Pixie maintains three memory locations that have the values of these three registers, \nand replaces the use of dtese registers by uses of the memory locations. 7~pha[10] ha5asigned21-bitpc-relative \nsubroutinebranch~stm~tion. The application may contain hand-crafted assembly language code that often \ndoes not follow standard conventions. All)M can handle such programs. $ AnalYsis routines are analogous \nto standard library routines hat have to follow calling conventions so they can be linked wirb progrants. \nhere where to save these caller-save registers, and which caller-save registers to save. Saving registers \nin the application code, where the call is being inserted, is not a good idea if there are more than \na few registers to be saved, as it may cause code explosion. We create a wrapper routine for each analysis \nprocedure. The wrapper routine saves and restores the necessary registers, and makes the call to the \nanalysis routine. The application program now calls the wrapper routine instead of the analysis routine. \nUnfortunately, this creates an indirection in calls to analysis routines. However, this has the advantage \nthat it makes no changes to the analysis code so it works well with a debugger like dbx. This is the \ndefault mechanism. ATOM provides an additional facility in which the saves and restores of caller-save \nregisters are added to the analysis routines. No wrapper routines are created in this case. The extra \nspace is allocated in the anrttysis routine s stack frame. This requires bumping the stack frame and \nfixing stack refer\u00adences in the analysis routines as needed. This is more work but is more efficient \nas analysis routines are called directly. Since this modifies the analysis routines, it hampers source\u00adlevel \ndebugging. This mechanism is available as a higher optimization option. The number of registers that \nneed to be saved and restored is reduced by examining the analysis routines. The data flow summary information \nof the analysis routines determines all the registers that may be modified when the control reaches a \nparticular analysis procedure. Only these registers need to be saved and restored. We use register renaming \nto minimize the number of different caller-save registers used in the analysis routines. Moreover, if \nan analysis routine contains procedure calls to other analysis routines, we save only the registers directly \nused in this analysis routine and delay the saves of other registers to procedures that maybe called. \nWe only do this if none of theprocedttrecalls occur in a loop. Thus we distribute the cost of saving \nregisters; the overhead now depends on the path the program takes. This helps analysis routines that \nnormally return if their argument is valid but otherwise raise an error. Raising an error typically involves \nprinting art error message and touching a lot more registers. For such routines, the common case of a \nvatid argument has low overhead as few registers are saved. This optimization is available in the current \nimplementation. The number of registers that need to be saved may be further reduced by computing live \nregisters in the appli\u00ad cation program. OM can do interprocehral live variable anatysis[l 1] and compute \nall registers live at a point. Only the live registers need to be saved and restored to preserve the \nstate of the program execution. Optimization such as inlining further reduce the overhead of procedure \ncalls at the A t Stack I -textstart ~ cad-only data ~xcedion data program text new datastart \\ old \ndatastart program data initialized program data uninitialized /\\ Uninstrumented Proaram LayZut a instrumented \nprogram text program data initialized I program data uninitialized nHeap I t Instrumented Program Layout \nProgram Text Addresses Changed analysis gp ~a::ram Addresses Unchanged Figure 4: Memory layout cost \nof increasing the code size. These refinements have not been added to the current system. Keeping Pristine \nBehavior One major goal of ATOM is to avoid perturbing the addresses in the application program. Therefore, \nthe analysis routines are put in the space between the application program s text and data segments. \nAnalysis routines do not share any pro\u00adcedures or data with the application program; they contain data \nand code for all procedures including library routines that they may need. The data sections of the application \nprogram are not moved, so the data addresses in the application program are unchanged. The initialized \nand uninitialized data of analysis routines is put in the space between the application program s text \nand data segments. In an executable, all initialized data must be located before all uninitialized data, \nso the uninitial\u00adized data of the analysis routines is converted to initialized data by initializing \nit with zero. The start of the stack and heap10 are unchanged, so all stack and heap addresses are lo~ \nthe MPha Am Mder OSF/1 stack begins at start of text S9gItIetIt same as before. This is shown in Figure \n4. The text addresses of the application program have changed because of the addition of instrumented \ncode. How\u00adever, we statically know the map from the new to original addresses. If an analysis routine \nasks for the PC of an in\u00adstruction in the application program, the original PC is simply supplied. This \nworks well for most of the tools. However, if the address of a procedure in the application program is \ntaken, its address may exist in a register. If the analysis routine asks for the contents of such a register, \nthe value supplied is not the original text address. We have not implemented in our current system the \nability to return original text address in such cases. Analysis routines may dynamically allocate data \non heap. Since analysis routines and the application program do not share any procedures, there are two \nsbrkl 1 routines, one in the application program and the other in the analysis routines that atlocate \nspace on the same heap. ATOM provides two options for tools that must allocate dynamic memory. and grows \ntowards low memory, and heap starts at end of uninitialized data and grows towards high memory. 11sbrk \nroutines ~ocate more data spacefor tie program. The first method links the variables of the two sbrks, \nso both allocate space on the same heap without stepping on each other. Each starts where the other left \noff. This method is useful for tools that are not concerned with the heap addresses being same as in \nthe uninstrumented version of the program. Such tools include basic block counting, branch analysis, \ninline analysis and so on. This method is also sufficient for tools such as cache modeling that require \nprecise heap addresses but do not allocate dynamic memory in analysis routines. This is the default behavior. \nThe second method is for tools that allocate dynamic mem\u00adory and also require heap addresses to be same \nas in the tmin\u00adstrumented version of the application program. To keep the application heap addresses \nas before, the heap is partitioned between the application and the analysis routines. The appli\u00adcation \nheap starts at the same address but the analysis heap is now made to start at a higher address. The user \nsupplies the offset by which the start of analysis heap is changed. ATOM modifies the sbrk in analysis \nroutines to start at the new address; the two sbrks are not linked this time. The disad\u00advantage of this \nmethod is that there is no runtime check if the application heap grows and enters into the analysis heap. \nPerformance To find how well ATOM performs, two measurements are of interest how long ATOM takes to instrument \na program, and how the instrumented program s execution time compares to the uninstrumented program s \nexecution time. We used ATOM to instrument 20 SPEC92 progr~s with 11 tools, The tools are briefly described \nin Figure 5. The time taken to instrument a program is the sum of the ATOM s pro\u00adcessing time and the \ntime taken by the user s instrumentation routines. The time taken by a tool varies as each tool does \ndifferent amounts of processing. For example, the malfoc tool simply asks for the malloc procedure and \ninstruments i~ the processing time is very small. The pipe tool does static CPU pipeline scheduling for \neach basic block at instrttmen\u00adtation time and takes more time to instrument an application. The time \ntaken to instrument 20 SPEC92 programs with each tool is also shown in Figure 5. The execution time of \nthe instrumented program is the sum of the execution time of the uninstrumented application program, \nthe procedure call setup, and the time spent in the analysis routines. This total time represents the \ntime needed by the user to get the final answers. Many systems process the collected data offline and \ndo not include those numbers as part of data collecting statistics. The time spent in analysis routines \nis analogous to the postprocessing time required by other systems. We compared each instrumented program \ns execution time to the uninstrumented program s execution time for each tool. Figure 6 shows the ratios \nfor the SPEC92 programs. The procedure call overhead is dependent on the code in the analysis routines, \nand the number and type of arguments that are passed. ATOM uses the data flow summary information along \nwith register renaming to find the necessary registers to save. The contribution of procedure call overhead \nin the instrumented program execution time is also dependent on the number of times the procedure calls \ntake place. The inline tool instruments only procedure call sites; the total overhead is much less than \nthe cache tool, which instruments each memory reference. The amount of work the analysis routines do \nwhen the control reaches them is totally dependent on information the user is trying to compute. Although \nthe communication overhead is small, we expect it to decrease further when we implement live register \nanalysis and inlining. All measurements were done on Digital Alpha AXP 3000 Model 400 with 128 Mb memory. \n 6 Status ATOM is built using OM and currently runs on Alpha AXP under OSF/1. It has been used with programs \ncompiled with Fortrart, C++ and two different C compilers. The system currently works on non-shared library \nmodules. Work is in progress for adding support for shared libraries. ATOM has been used both in hardware \nand software projects. Besides the SPEC92 benchmarks, it has success\u00adfully instrumented real applications \nof up to 96 Megabytes. The system is being used extensively inside Digital and at a few universities12. \nOur focus until now has mainly been on functionality. Few optimization have been added to reduce the \nprocedure call overhead. Currently, reduction in register saves has been obtained by computing data flow \nsummary information of analysis routines. We plan to implement live register analysis along with inlining \nto further improve the performance. We are just starting to instrument the operating system. 12A~M is \navailable to external users. If you would like a copY. Please contact the authors. Analysis Tool Tool \nDescription Time to instrument Average SPEC92 suite Time branch prediction using 2-bit history table \n110.46 WCS 5.52 WCS cache model direct mapped 8k byte cache 120.58 SCXX 6.03 WX dyninst computes dynamic \ninstruction counts 126.31 WCS 6.32 St%X gprof call graph based profiling tool 113.24 SeCS 5.66 S(3(3 \ninline finds potential inlining call sites 146.50 S(XS 7.33 Sees io inpui/output summary tool 121.60 \nWCS 6.08 sees malloc histogam of dynamic memory 97.93 Sees 4.90 sees pipe pipeline stall tool 257.48 \nSCXX 12.87 WCS prof Instruction profiling tool 122.53 WCS 6.13 WCS Syscall system call summary tool 120.53 \nSt?CS 6.03 WCS unalign unalign access tool 135.61 S(?CS 6.78 WCS Figure 5: Time taken by ATOM to instrument \n20 SPEC92 benchmark programs Analysis Tool Instrumentation Number of Time taken by points Arguments Instrumented \nProgram branch each conditional branch 3 3.03X cache each memory reference 1 11.84x dyninst eaeh basic \nblock 3 2.91x gprof each procedure/each basic block 2 2.70x inline each call site 1 1.03X io before/after \nwrite procedure 4 1.OIX malloc before/after malloc procedure 1 1.02X pipe each basic block 2 1.80x prof \neach procedure/each basic block 2 2.33x Syseall before/after each system call 2 1.OIX unalign each basic \nblock 3 2.93x Figure 6: Execution time of instrumented SPEC92 Programs as compared to uninstrumented \nSPEC92 programs   Conclusion Acknowledgements By separating object-module modification details from \ntool Great many people have helped us bring ATOM to its current details and by presenting a high-level \nview of the program, form. Jim Keller, Mike Burrows, Roger Cruz, John Edmond-ATOM has transferred the \npower of building tools to hard-son, Mike McCallig, Dirk Meyer, Richard Swan and Mike ware and software \ndesigners. A tool designer concentrates Uhler were ottrtirst users and they braved through amine field \nonly on what information is to be collected and how to pro-of bugs and instability during the early development \nprocess. cess it. Tools can be built with few pages of code and they Jeremy Dion, Ramsey Haddad, Russel \nKao, Greg Lueck and compute only what the user asks for. ATOM s fast commu-Louis Monier built popular \ntools with ATOM. Many peo\u00adnication between application and analysis means that there ple, too many to \nname, gave comments, reported bugs, and is no need to record traces as all data is immediately pro-provided \nencouragement. Roger Cruz, Jeremy Dion, Ramsey cessed, and final results are computed in one execution \nof the Haddad, Russell Kao, Jeff Mogul, Louis Monier, David Wall, instrumented program. Thus, one can \nprocess long-running Linda Wilson and anonymous PLDI reviewers gave useful programs. It has already been \nused to build a wide variety comments on the earlier drafts of this paper. Our thanks to of tools to \nsolve hardware and software problems. We hope atl. ATOM will continue to be an effective platform for \nstudies in software and architectural design. References [1] Anant Agarwal, Richard Sites, and Mark \nHorwitz, ATUM A New Technique for Capturing Address Traces Using Microcode. Proceedings of the 13th International \nSymposium on Computer Architec\u00adture, June 1986. [2] Robert Bedichek. Some Efficient Architectures Simulation \nTechniques. Winter 1990 USENIX Con\u00adference, January 1990. [3] Anita Borg, R.E. Kessler, Georgia Lazana, \nand David Wall. Long Address Traces from RISC Ma\u00adchines: Generation and Analysis, Proceedings of the \n17th Annual Symposium on ComputerArchitec\u00adture, May 1990, also available as WRL Reseasch Report 89/14, \nSep 1989. [4] Eric A. Brewer, Chrysanthos N. Dellarocas, Adrian Colbrook, and William E. Weihl. PROTEUS: \nA High-Performance Parallel-Architecture Simula\u00adtor. MIT/LCS/l_ R-5 16, MIT, 1991. [51 RobertF.Cmelikand \nDavid Keppel, Shade A Fast Instruction-Set Simulator for Execution Profiling. Technical Report UWCSE \n93-06-06, University of Washington. [6] Susan J. Eggers, David R. Keppel, Eric J. Koldinger, and Henry \nM. Levy. T&#38;hniques for Ef\u00adficient Inline Tracing on a Shared-Memory Multi\u00adprocessor. SIGMETRICS Conference \non A4eastwe\u00adment and Modeling of Computer Systems,VOI8, no 1, May 1990. [7] Stephen R. Goldschmidt and \nJohn L. Hennessy, The Accuracy of Trace-Driven Simulations of Mul\u00adtiprocessors. CSL-TR-92-546, Computer \nSystems Laboratory, Stanford University, September 1992. [8] James R. Larus and Thomas Ball. Rewriting \nex\u00adecutable files to measure program behavior. Soft\u00adware, Practice and Experience, vol 24, no. 2, pp \n197-218, February 1994. [9] MIPS Computer Systems, Inc. Assembly Language Programmer s Guide, 1986. [10] \nRichard L, Sites, ed. Alpha Architecture Reference Manual Digital Press, 1992. [11] Amitabh Srivastava \nand David W. Wall. A Prac\u00adtical System for Intermodule Code Optimization at Link-Time. Journal of Programming \nLanguage, l(l), pp 1-18, March 1993. Also available as WRL Research Report 92/6, December 1992. [12] \nAmitabh Srivastava and David W. Wall. Link-Time Optimization of Address Calculation on a 64\u00adbit Architecture. \nProceedings of the SIGPLAN 94 Conference on Programming Language Design and Implementation, to appear. \nAlso available as WRL Research Report 94/1, February 1994. [13] Amitabh Srivastava. Unreachable procedures \nin object-oriented programming, ACM LOPLAS, Vol 1, #4, pp 355-364, December 1992. Also available as WRL \nResearch Report 93/4, August 1993. [14] David W. Wall. Systems for late code modification. In Robert \nGiegerich and Susan L. Graham, eds, Code Generation -Concepts, Tals, Techniques, pp. 275-293, Springer-Verlag, \n1992. Also available as WRL Research Report 92/3, May 1992.  \n\t\t\t", "proc_id": "178243", "abstract": "<p>ATOM (Analysis Tools with OM) is a single framework for building a wide range of customized program analysis tools. It provides the common infrastructure present in all code-instrumenting tools; this is the difficult and time-consuming part. The user simply defines the tool-specific details in instrumentation and analysis routines. Building a basic block counting tool like Pixie with ATOM requires only a page of code.</p><p>ATOM, using OM link-time technology, organizes the final executable such that the application program and user's analysis routines run in the same address space. Information is directly passed from the application program to the analysis routines through simple procedure calls instead of inter-process communication or files on disk. ATOM takes care that analysis routines do not interfere with the program's execution, and precise information about the program is presented to the analysis routines at all times. ATOM uses no simulation or interpretation.</p><p>ATOM has been implemented on the Alpha AXP under OSF/1. It is efficient and has been used to build a diverse set of tools for basic block counting, profiling, dynamic memory recording, instruction and data cache simulation, pipeline simulation, evaluating branch prediction, and instruction scheduling.</p>", "authors": [{"name": "Amitabh Srivastava", "author_profile_id": "81100062504", "affiliation": "Digital Equipment Western Research Laboratory, 250 University Ave., Palo Alto, CA", "person_id": "PP31025371", "email_address": "", "orcid_id": ""}, {"name": "Alan Eustace", "author_profile_id": "81100485823", "affiliation": "Digital Equipment Western Research Laboratory, 250 University Ave., Palo Alto, CA", "person_id": "P12408", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/178243.178260", "year": "1994", "article_id": "178260", "conference": "PLDI", "title": "ATOM: a system for building customized program analysis tools", "url": "http://dl.acm.org/citation.cfm?id=178260"}