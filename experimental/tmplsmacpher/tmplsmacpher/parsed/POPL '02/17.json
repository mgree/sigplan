{"article_publication_date": "01-01-2002", "fulltext": "\n Predicate Abstraction for Software Veri.cation Cormac Flanagan Shaz Qadeer Compaq Systems Research Center \n130 Lytton Ave, Palo Alto, CA 94301 Abstract Software veri.cation is an important and di.cult prob\u00adlem. \nMany static checking techniques for software re\u00adquire annotations from the programmer in the form of \nmethod speci.cations and loop invariants. This anno\u00adtation overhead, particularly of loop invariants, \nis a sig\u00adni.cant hurdle in the acceptance of static checking. We reduce the annotation burden by inferring \nloop invari\u00adants automatically. Our method is based on predicate abstraction, an abstract interpretation \ntechnique in which the abstract domain is constructed from a given set of predicates over program variables. \nA novel feature of our approach is that it infers universally-quanti.ed loop invariants, which are crucial \nfor verifying programs that manipu\u00adlate unbounded data such as arrays. We present heuris\u00adtics for generating \nappropriate predicates for each loop automatically; the programmer can specify additional predicates \nas well. We also present an e.cient algo\u00adrithm for computing the abstraction of a set of states in terms \nof a collection of predicates. Experiments on a 44KLOC program show that our approach can automatically \ninfer the necessary predi\u00adcates and invariants for all but 31 of the 396 routines that contain loops. \nIntroduction Ensuring the reliability of software systems is impor\u00adtant but extremely di.cult, due to \nthe test coverage problem. Static analysis techniques could potentially verify that a program satis.es \na (lightweight) speci.\u00adcation, for example, that it should not crash. A com- Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 02, Jan. 16-18, 2002 Portland, OR USA \n&#38;#169;2002 ACM cISBN 1-58113-450-9/02/01...$5.00 pletely automatic solution to this checking problem \nis impossible in general since the problem is undecidable. Semi-automatic techniques rely on the programmer \nto provide additional annotations describing method spec\u00adi.cations and loop invariants. This annotation \noverhead is a signi.cant obstacle to the use of formal techniques in software design. While method speci.cations \nalso function as useful documentation and may be helpful for code maintenance, loop invariants do not \nprovide comparable bene.ts along these lines. Thus, the task of writing appropriate loop invariants for \na large pro\u00adgram is perceived to be especially tedious. In this paper, we present a new method for automat\u00adically \ninferring loop invariants. Our method is based on predicate abstraction [GS97], which is a special form \nof abstract interpretation [CC77] in which the abstract domain is constructed using a given set of predicates. \nThese predicates are generated in a heuristic manner from the program text; the programmer is free to \npro\u00advide additional predicates. Given a suitable set of pred\u00adicates for a given loop, our algorithm infers \nloop invari\u00adants that are boolean combinations of these predicates. Thus, the problem of computing loop \ninvariants is re\u00adduced to the easier problem of guessing a relevant set of simple predicates. Our algorithm \nanalyzes the loops of a method in or\u00adder, since knowing the invariant for one loop constrains the possible \ninitial states of a subsequent loop, and helps infer a more precise invariant for that loop. The invari\u00adant \nfor each loop is computed by iterative approxima\u00adtion. The .rst approximation is obtained by abstracting \nthe set of reachable states at loop entry. Each succes\u00adsive approximation enlarges the current approximation \nto include the states reachable by executing the loop body once from the states in the current approxima\u00adtion. \nThe iteration terminates in a loop invariant since the abstract domain is .nite. The fundamental operation \nin the algorithm de\u00adscribed above is the abstraction of a set of reachable states. The abstraction operation \nis performed by mak\u00ading queries to an automatic theorem prover, and may re\u00adquire an exponential number \nof queries. Existing meth\u00adods [DDP99, SS99] perform much better in practice, but are still costly. We \ndescribe a new abstraction al\u00adgorithm that requires fewer queries than existing algo\u00adrithms, particularly \nfor large numbers of predicates. The loop invariant inference method described above is inadequate for \nverifying loops that manipulate un\u00adbounded data such as arrays. For such loops, the re\u00adquired invariants \nare universally quanti.ed. Naive ap\u00adplication of predicate abstraction requires the user to guess the \nfull quanti.ed expression as a predicate, which is no simpler than guessing the loop invariant itself. \nWe avoid this limitation by allowing the predicates to re\u00adfer to skolem constants, which are fresh variables \nnot mentioned anywhere else in the program. These skolem constants represent some .xed, unknown value, \nthus allowing us to universally quantify them out from the inferred invariant without loss of soundness. \nWe have implemented our algorithm using the in\u00adfrastructure of the Extended Static Checker for Java (ESC/Java) \n[DLNS98, LSS99]. The goal of ESC/Java is to detect statically programming errors that are nor\u00admally detected \nonly at run-time, if ever. Such er\u00adrors include null pointer dereferences, array bounds er\u00adrors, division \nby zero, and the violation of programmer\u00adspeci.ed properties such as method speci.cations and object \ninvariants. We have evaluated our method on several small but interesting examples, including the list \npartition algorithm from the SLAM paper [BMMR01] and a selection sort example. We have also evaluated \nour method on the front end for ESC/Java, which con\u00adtains about 44K lines of Java code and 520 loops. \nOur loop invariant inference algorithm, using heuristics we develop for guessing candidate predicates, \nwas able to verify the correctness of all but 31 of the 396 methods that contain loops. Background. Beginning \nin the 1970 s, a num\u00adber of researchers have addressed the problem of au\u00adtomatically inferring loop invariants. \nThe .rst pa\u00adpers [GW74, Weg74, KM76] proposed heuristics for gen\u00aderating loop invariants for sequential \nprograms. Algo\u00adrithms based on iterative forward and backward traver\u00adsal, with heuristics for terminating \nthe iteration, ap\u00adpeared soon after [GW75, SI77]. Abstract interpreta\u00adtion [CC77] introduced the widening \noperator, which was used to compute [CH78] .xpoints more system\u00adatically. ESC/Modula-3 [DLNS98] experimented \nwith generating loop invariants using both abstract inter\u00adpretation and a second technique called loop \nmodi.\u00adcation inference. In the 1990 s, a number of researchers worked on generating auxiliary invariants \nfor proving safety properties of concurrent algorithms and proto\u00adcols [MP92, BLS96, BBM97]. /*@ requires \na != null &#38;&#38; b != null */ /*@ requires a.length == b.length */ /*@ ensures \\result == a.length \n|| b[\\result] */ int find(int[] a, boolean[] b) { int spot = a.length; for (int i = 0; i < a.length; \ni++) { if (spot == a.length &#38;&#38; a[i] != 0) spot = i; b[i] = (a[i] != 0); } return spot; } Figure \n1: Method find Predicate abstraction has also been used for verify\u00ading protocols [DDP99, SS99] and hardware \n[CGJ+00]. Recently the SLAM project [BMMR01] has also ex\u00adplored predicate abstraction for sequential \nprograms. They perform abstraction on each program statement, whereas our method abstracts only when \nnecessary, that is, at loop headers. As a result, our inferred in\u00advariants are more precise and we require \nfewer predi\u00adcates. In addition, the SLAM approach is unable to infer universally-quanti.ed invariants, \nwhich we have found crucial for verifying many programs. Outline. Section 2 motivates our approach with \na simple example. Section 3 describes an idealized pro\u00adgramming language and Section 4describes how to \ninfer loop invariants for this language. Our inference algo\u00adrithm depends on the predicate abstraction \nalgorithm described in Section 5. Section 6 describes our heuris\u00adtics for guessing suitable predicates. \nSection 7 reports on our experience using our method on various exam\u00adples. Finally, we conclude in Section \n8. 2 Motivating example We illustrate our technique for inferring loop invariants using the method find \nshown in Figure 1. This method takes as parameters an array of integers a andanar\u00adray of booleans b. \nThe method returns the index of the .rst nonzero element of a if one exists and a.length otherwise. The \nmethod also sets the i-th element of b to true if the i-th element of a is nonzero, and to false otherwise. \nThe preconditions of the method speci.ed by the annotation /*@ requires .. */ states that the arrays \nare nonnull and of the same length. The post\u00adcondition /*@ ensures .. */ states that the returned index \n(denoted by \\result)is either a.length or b is true at that index. The method body consists of a loop \nthat iterates over the elements of a and sets the elements of b appro\u00adpriately. A variable spot, initialized \nto a.length,is set to the index of the .rst nonzero element if one exists. Proving that no array bounds \nviolation occurs requires the loop invariant 0<=i. Thisisasimple invariant involving a single predicate \nand can be stated without much e.ort. Proving the postcondition of this method requires the more complex \nloop invariant: /*@ loop_invariant spot == a.length || (b[spot] &#38;&#38; spot < i) */ Constructing \nthis loop invariant requires ingenu\u00adity in choosing the correct boolean combination of the three predicates \nspot == a.length, b[spot],and spot < i. Predicate abstraction allows us to specify only the predicates \n(none of which is a loop invariant by itself), and derive the loop invariant automatically from them. \nThese loop predicates are suggested to the algorithm by the annotation: /*@ loop_predicate spot == a.length, \nb[spot], spot < i */ The predicate abstraction algorithm computes the strongest boolean combination of \nthese three predicates by iterative approximation. The .rst approximation is spot == a.length, which \nholds at loop entry. The second approximation, after one loop iteration, is spot == a.length || (b[spot] \n&#38;&#38; spot < i). This approximation is a .xpoint and is therefore the desired loop invariant. Now \nsuppose we want to verify the following addi\u00adtional postcondition, which states that every element of \nthe array b before the returned value contains false: /*@ ensures (\\forall int j; 0 <= j &#38;&#38; j \n< \\result ==> b[j] == false) */ Proving this postcondition requires the additional loop invariant: /*@ \nloop_invariant (\\forall int j; 0 <= j &#38;&#38; j< i &#38;&#38; j < spot ==>b[j]==false) */ The loop \ninvariant is universally quanti.ed; the compo\u00adnent predicates of the invariant refer to the quanti.ed \nvariable j as well to the program variables. Therefore, in order to use predicate abstraction as before, \nwe have to specify the whole loop invariant as a predicate, which does not simplify the problem. We get \naround this dif\u00ad.culty by introducing a skolem constant j,which is a fresh variable not mentioned elsewhere \nin the program, and by introducing extra predicates that refer to the skolem constant j as well as to \nthe program variables. /*@ skolem_constant int j; loop_predicate 0 <= j, j < i, j < spot, b[j]; */ We \nnow perform predicate abstraction yielding the new invariant: A,B .Stmt ::= assert e |assume e |x := \ne |A ; B |A B |{P,I}while e do B end x .Var (variables) e .Expr (expressions) I .Formula (logical formulae) \nP.Formula (loop predicates) Figure 2: A guarded command language 0<= j &#38;&#38; j < i&#38;&#38; j <spot \n==> b[j] == false Since the skolem constant j represents some .xed unknown value, this invariant is valid \nfor any value of j. Therefore, the skolem constant can be safely quanti.ed out to yield the desired universally-quanti.ed \nloop in\u00advariant. We have found this technique to be crucial when checking programs that manipulate unbounded \ndata, such as arrays. 3 A guarded command language We have implemented our technique as part of ESC/Java. \nTo verify a Java program, ESC/Java trans\u00adlates each Java method and its speci.cation into a log\u00adical \nformula called a veri.cation condition (VC). Ide\u00adally, the VC has the property that if it is valid then \nthe method is correct, i.e., it implements its speci.ca\u00adtion and never performs an erroneous operation \nsuch as dereferencing a null pointer. Deriving veri.cation conditions for a large and real\u00adistic language \nsuch as Java is quite complex. To help structure and modularize this translation, ESC/Java .rst translates \neach method and its speci.cation into an intermediate representation, known as a guarded com\u00admand. This \ntranslation eliminates many of the com\u00adplexities of the Java programming language; it is out\u00adlined elsewhere \n[LSS99]. In this paper, we concentrate on the subsequent task of inferring suitable invariants for the \nloops in the intermediate representation. We base our development on the intermediate lan\u00adguage shown \nin Figure 2. The language is a variation of Dijkstra s guarded commands [Dij76], together with some more \nrecent additions (see, e.g., [Nel89, BvW98]). The language includes assert and assume statements, assignment \nstatements, sequential composition, nonde\u00adterministic choice, and loops. By including assume statements, \nwe no longer need the guards that origi\u00adnally gave the language its name. S Norm(Q, S) Wrong(Q, S) x \n:= e .x'.x = e(x . x') . Q(x . x') false assert P Q . P Q .\u00acP assume P Q . P false A B Norm(Q, A) . Norm(Q, \nB) Wrong(Q, A) . Wrong(Q, B) A ; B Norm(Norm(Q, A),B) Wrong(Q, A) . Wrong(Norm(Q, A),B) {P,I} while e \ndo B end Norm(Q, desugar(S)) Wrong(Q, desugar(S)) Figure 3: Strongest-postcondition semantics Expressions \nin the language are intentionally unspec\u00adi.ed, since their structure is mostly irrelevant to our development. \nWe assume that the set Expr contains expressions that are pure (side-e.ect free), and include at least \nthe boolean constants true and false.The set Formula of logical formulae is an extension of boolean expressions \nthat includes at least the usual boolean op\u00aderators ( . , . , \u00ac, . , =) and quanti.cation, and is closed \nunder substitution of expressions for variables. We let Var denote the set of program variables, and \nuse Q(x . e) to denote the capture-free substitution of e for every free occurrence of x in a formula \nQ.Where appropriate, we use double-quotes ... to distinguish constructed syntax from mathematical de.nitions \nand algorithms. 3.1 Informal semantics The execution of a statement may either terminate nor\u00admally or \nit may go wrong due to a failed assertion. The execution of the statement assert e terminates normally \nif the condition e evaluates to true in the cur\u00adrent program state, and goes wrong otherwise. The as\u00adsume \nstatement is partial: assume e terminatesnor\u00admally if the condition e evaluates to true,and simply cannot \nbe executed from a state where e evaluates to false . The assignment statement x := e updates the program \nstate so that x is bound to the current value of the expression e. The statement A ; B denotes the sequential \ncomposition of A and B. The execution of the choice statement A B executes either A or B, but the choice \nbetween the two is made arbitrarily. The while loop {P,I} while e do B end has the conven\u00adtional semantics \nthat B is executed as long as the con\u00addition e remains true. The loop invariant I is provided to aid \nin the veri.cation process; it is required to hold at the beginning of each loop iteration. The set P \nof predicates is used for the automatic inference of loop invariants. All variables have arbitrary values \nin a program s initial state. The indeterminism arising from choice statements and from the program s \ninitial (arbitrary) state can be tamed by assume statements: the se\u00admantics of a program considers only \nthose execu\u00adtions in which the condition of each executed as\u00adsume statement evaluates to true. For example, \nthe statement (assume e ; A) (assume \u00ace ; B) is the deterministic statement commonly written as if e \nthen A else B end .  3.2 Formal semantics We formally de.ne the semantics of our language using the \nstrongest postcondition translations Norm, Wrong : Formula \u00d7 Stmt . Formula shown in Figure 3. For an \nexecution of S that starts in an initial state satisfying the formula Q, the postcondi\u00adtion Norm(Q, S) \ncharacterizes post-states in which that execution could terminate normally. The postcondition Wrong(Q, \nS) characterizes the post-states in which that execution could go wrong by failing an assert. The de.nition \nof Norm and Wrong is straightfor\u00adward. The normal postcondition Norm(Q, x := e)of an assignment statement \nwith respect to a precondi\u00ad tion Q is .x.x = e(x . x') . Q(x . x'); this formula holds in the post-state \nof the assignment provided there exists some xrepresenting the initial value of x such that Q holds in \nthat initial state and x contains the results of evaluating e in that initial state. An assign\u00adment statement \ncan never go wrong, and thus its wrong postcondition is false. The strongest postcondition translation \nfor a while loop relies on an auxiliary function that desugars loops into more primitive statements. \nThis desugaring relies on the loop invariant I whichisrequired to holdatthe beginning of each iteration \nof the loop; it is de.ned as: desugar( {P,I} while e do B end ) = assert I ; havoc(targets(B)) ; assume \nI ; ((assume e ; B ; assert I ; assume false ) assume \u00ace) . 2Var The function targets : Stmt returns \nthe set of variables assigned in the loop body. The function havoc :2Var .Stmt assigns arbitrary values \nto these variables; it is de.ned by havoc({x1,...,xn})= x1 := y1 ; ... ; xn := yn where y1,...,yn are \nfresh variables that hold arbitrary values (from the program s initial state). The desugared code ensures \nthat the loop invariant I holds initially, and then sets the loop targets (the vari\u00adables modi.ed by \nthe loop body) to arbitrary values that satisfy the loop invariant. The code then checks that if e is \ntrue, then the loop invariant still holds af\u00adter executing B;if e is false, then the desugared loop terminates \n(and execution continues at the subsequent statement). An important aspect of this desugaring is that \nthe invariant need only explicate properties of loop targets, since properties of other variables that \nheld in the pre\u00adstate of the loop will be known to still hold in the loop body and after loop termination. \nTo show that a statement S cannot go wrong from any initial state, it su.ces to prove that the veri.cation \ncondition1 \u00ac(Wrong(true,S)) is valid, for example, by using an automatic theorem prover [Nel81]. 4 Inferring \nloop invariants Verifying a program using the techniques outlined in the previous section requires that \neach loop of the program is .rst annotated with a suitable loop invariant. Our experience with ESC/Java \nindicates that the burden of specifying loop invariants is substantial. In this section, we describe \nan algorithm for inferring such invariants automatically. Our inference algorithm processes the loops \nof a program in order, since knowing the invariant for one loop constrains the possible initial states \nof a subse\u00adquent loop, and helps infer a precise invariant for that loop. This in-order processing is \nfacilitated by our use of strongest postconditions (as opposed to the more com\u00admon weakest preconditions). \nThe procedure traverse, de.ned in Figure 4, takes as input a statement S,and returns a modi.ed version \nof S that includes an inferred invariant for each loop in S. The procedure also takes as input a context \nC, which is the code preceding S, and hence constrains the initial states for the execution of S. We \nassume suitable invariants have been inferred for any loops in C. 1ESC/Java actually uses a more e.cient \nalgorithm for generating veri.cation conditions that avoids the exponential blowup associated with the \nstandard weakest precondition and strongest postcondition translations [FS01]. Stmt traverse(Stmt C, \nStmt S) { case S of { x := e .{return S; } assert P .{return S; } assume P .{return S; } A B .{A' = \ntraverse(C, A); B' = traverse(C, B); return A' B' ; } A ; B .{A' = traverse(C, A); B' = traverse( C \n; A' ,B); return A' ; B' ; } {P,I}while e do B end .{(J, B')= infer(C, S); return {P,I .J}while e do \nB' end }}} (Formula, Stmt)infer(Stmt C, Stmt S) {let {P,I}while e do B end = S; Stmt H = havoc(targets(B)); \nAbsDomain r = a(Norm(true,C)); while (true) { Formula J = .(r); Stmt A = assume e .I .J ; Stmt B' = traverse( \nC ; H ; A ,B); Formula Q = Norm(true, C ; H ; A ; B' ); AbsDomain next = r .a(Q); if (next = r) return \n(J, B'); r = next; }} Figure 4: Procedures traverse and infer If S is an assert, assume, or assignment \nstatement, then it does not contain any loops, and traverse returns S unmodi.ed. If S is a choice statement, \nthen its sub\u00adstatements are processed recursively. Similarly, if S is a sequential composition A ; B, \nthe sub-statements A and B are also processed recursively, with A' (the ver\u00adsion of A with inferred invariants) \nbeing appended to the context used when inferring invariants for B.For the interesting case where S is \na while loop, the helper procedure infer (see Figure 4) is called to infer a suit\u00adable invariant for \nthat loop. The required invariant for S could, in theory, be computed iteratively, by repeatedly applying \nthe strongest postcondition transformer to the loop body. However, because the set of possible program \nstates is in.nite, in most cases this iterative algorithm does not converge. To solve this convergence \nproblem, we use the pred\u00adicates P = {p1,...,pn} associated with the loop to abstract the in.nite concrete \nstate space to a .nite abstract domain. This abstract domain is the set of all boolean functions of n \nboolean variables B = {b1,...,bn}, where each boolean variable bi corresponds to the predicate pi. An \nabstract domain element f is thus a boolean function over B, and represents the con\u00adcrete states described \nby the concretization .(f)= f(b1 . p1,...,bn . pn) which replaces each variable bi in f by the correspond\u00ading \npredicate pi. Conversely, for any predicate Q over the concrete state space, the corresponding abstract \ndomain ele\u00adment is obtained via the abstraction a(Q), which is the strongest boolean function on B such \nthat Q. .(a(Q)). Section 5 describes an e.cient algorithm for comput\u00ading a(Q); the remainder of this \nsection describes how to use the abstraction and concretization operations to converge on a suitable \nloop invariant. The procedure infer takesasarguments aloop con\u00adtext C and a loop S. The procedure keeps \ntrack of an abstraction r of the set of reachable states. The set of reachable states is initially Norm(true,C), \nand so r is initialized with the corresponding abstraction. The pro\u00adcedure iteratively analyzes the loop \nbody and updates r until a .xpoint is reached. At each iteration, a concrete representation of the current \nset of reachable states is generated in J.The statement A explicates assumptions that hold at the beginning \nof the loop body. These assumptions include the loop guard e, the supplied loop invariant I,and the current \napproximation J to the invariant being in\u00adferred. The resulting context for the loop body B is then C \n; H ; A , where H havocs the targets of B. Suitable invariants for nested loops in B are computed by \nrecursively calling traverse on B with the new con\u00ad ' text, yielding a modi.ed loop body B . Applying \n' the normal postcondition operator to C ; H ; A; B yields a predicate Q approximating the set of states \nthat are reachable at the end of the analyzed loop. We extend r with the corresponding abstraction a(Q)and \niterate. Eventually a .xpoint is reached, and the invari\u00adant J = .(r) is then a valid invariant for the \nloop. This invariant, together with the modi.ed loop body B ',is returned as the result of infer. The \nfollowing theorem states that the loop invariant computed by infer is correct; that is, it holds on entry \nto the loop and also holds after an arbitrary loop iteration. Theorem 4.1 (Correctness of infer) Suppose \nthe procedure call infer(C, {P,I} while e do B end ) returns the tuple (J,B ' ).Let H = havoc(targets(B)). \nThenthefollowing arevalid: Norm(true,C) . J Norm(true, C ; H ; assume e. I . J ; B ' ) . J Our correctness \ncondition for traverse is that if the supplied loop invariants in a statement S are correct (although \npossibly not su.cient to verify the assertions in S), then the loop invariants inferred by traverse are \nalso correct. To formalize the notion of an incorrect loop invariant, we introduce a function h : Stmt \n. Stmt that removes all assertions from the given statement. Thus h(S) behaves exactly like S, except \nthat it never goes wrong due to a failed assertion; if h(S)goes wrong, it must be due to an incorrect \nloop invariant. Thus, the loop invariants of S are correct if the veri.cation condition \u00ac(Wrong(true,h(S))) \nis valid. Theorem 4.2 (Correctness of traverse) Suppose S ' is a statement and S = traverse(S, assume \ntrue ). If theloopinvariantsof S are correct then theloop in\u00ad ' variants of S are correct. 4.1 Inferring \nquanti.ed loop invariants The algorithm outlined above infers loop invariants that are boolean combinations \nof the given predicates. In many situations, such loop invariants are insu.cient, particularly for loops \nthat manipulate unbounded data such as arrays. For example, verifying that a loop clears an array requires \na loop invariant stating that all ele\u00adments in the array up to the current index are zero. Automatically \nverifying such loops requires the ability to infer universally-quanti.ed loop invariants. This section \ndescribes how to extend our approach to infer such universally-quanti.ed loop invariants. We achieve \nthis by allowing the predicates to refer to skolem constants, which are fresh variables not mentioned \nelse\u00adwhere in the program. We use S to denote the set of skolem constants, and use SCFormula to denote \nformu\u00adlae that may contain references to these constants. The candidate predicates P accompanying each \nloop may now include skolem constants, i.e., P. SCFormula. To infer universally-quanti.ed loop invariants, \nwe .rst proceed as outlined earlier. The concretization op\u00aderation of the procedure infer: J = .(r); \nreturns a boolean combination of the predicates, which now includes references to skolem constants. Since \nthese skolem constants do not appear elsewhere in the pro\u00adgram, they are simply variables with some .xed, \nun\u00adknown value, and we can universal quantify over them without loss of soundness Thus, we replace the \nabove assignment with: J = .S..(r) ; This universally-quanti.ed loop invariant is used when analyzing \nsubsequent iterations of the loop, and it is also returned as the inferred invariant once the .xpoint \nis reached. No other changes are required, and the cor\u00adrectness arguments of Theorems 4.1 and 4.2 still \nhold. This ability to infer universally-quanti.ed loop invari\u00adants is often crucial, as illustrated by \nthe examples in Section 7. Predicate abstraction The invariant inference algorithm relies on an imple\u00admentation \nof the abstraction operation a(Q), which is the focus of the present section. We begin by introducing \nsome useful terminology. Let P = {p1,...,pn} be the given set of predicates, and let B = {b1,...,bn} \nbe the corresponding set of boolean variables. A literal l is either bi or \u00acbi for some 1 = i = n.A clause \nd is a set of literals in which each boolean variable appears at most once. A clause of size n thus mentions \nall boolean variables, and is called a maximal clause. The meaning of a clause is the disjunction of \nits literals. The size of a clause is its cardinality. We extend the usual boolean operations to clauses. \nRecalling the de.nition of the previous section, the abstraction operation a(Q) returns the strongest \nboolean function f over the boolean variables such that Q . .(f). The abstraction a(Q) is computed us\u00ading \nan automatic theorem prover; a sequence of validity queries are used to identify the relationship between \nQ and various boolean combinations of the predicates pi. A naive implementation of the abstraction operation, \nrequiring 2n validity queries, is: a(Q)= {d | d is a maximal clause and Q . .(d)} The procedure Union \nadapts this algorithm to the computation of the abstract domain element r . a(Q), which is required by \ninfer. As an optimization, when computing r . a(Q), we only need to consider clauses that are implied \nby r. AbsDomain Union(AbsDomain r, Formula Q) { AbsDomain result = true; for each maximal clause m { \nif ((r . m) . (Q . .(m)) ) result = result . m; } return result; } The abstract domain element computed \nby this algo\u00adrithm is a conjunction of clauses of length n.Our expe\u00adrience with predicate abstraction \nindicates that the re\u00adquired abstract domain element can often be expressed as a conjunct of much smaller \nclauses, where the length of each clause is typically at most 3. We use this insight to optimize the \nabove algorithm. In particular, when\u00adever we .nd a maximal clause m such that r . m and Q . .(m), we \ntry to shrink m to a stronger (smaller) clause c such that c also enjoys the prop\u00aderty r . c and Q . \n.(c). This strengthening oper\u00adation can be performed in a greedy manner, by starting with c equal to \nm, and iteratively dropping as many lit\u00aderalsaspossiblefrom c while preserving this property. Having \nderived a stronger clause c, we can conjoin it to result, and subsequently skip consideration of all \nmaxi\u00admal clauses m that are implied by result. The following algorithm re.nes the previous one with these \nideas. AbsDomain Union(AbsDomain r, Formula Q) { AbsDomain result = true; for each maximal clause m { \nif ((result . . m) . (r . m) . (Q . .(m)) ) {c = m; for each literal l in m { d = c \\{l}; if ((r . d) \n. (Q . .(d)) ) { c = d; }} result = result . c; } } return result; } As a .nal improvement, we replace \nthe iterative al\u00adgorithm that shrinks m to a stronger clause c such that r . c and Q . .(c) with a divide-and-conquer \nalgorithm. This algorithm splits m into two clauses m1 and m2 such that m = m1 . m2.If m2 satis.es the \nproperties r . m2 and Q . .(m2)then we ig\u00adnore m1 and proceed to extract c from m2. However, if m2 does \nnot satisfy these properties, then we .rst recursively extract from m1 a stronger clause c1 such that \nr . c1 . m2 and Q . .(c1 . m2); we then re\u00adcursively extract from m2 a stronger clause c2 such that r \n. c1 . c2 and Q . .(c1 . c2), thus yielding the resulting clause c = c1 . c2 with the desired property. \nAlthough this algorithm may require O(n.2n)theorem prover queries in the worst-case, in practice it performs \nquite well (see Section 7.4). Our implementation of this algorithm uses a dual representation for the \nabstract domain. Each abstract domain element is represented as a binary decision di\u00adagram (BDD) [Bry86], \nthus allowing the implication tests on abstract domain elements ( result .m , . r . m , and r . d ) to \nbe performed e.ciently. In addition, we also represent abstract domain elements as conjuncts-of-clauses. \nThe procedure union naturally computes its results as a conjunct-of-clauses. By pre\u00adserving this structure, \nwe can present the inferred in\u00advariant for each loop as a conjuncts of (typically small) clauses, each \nof which can be comprehended as a sepa\u00adrate invariant by the programmer. This presentation is more comprehensible \nthan the BDD representation for all the inferred invariants we have inspected. 5.1 Related work We know \nof two other predicate abstraction algorithms. The .rst method [DDP99] uses a binary decision tree where \neach vertex at depth k represents a clause of size k. The clause at a vertex is a superset of the clause \nat its parent. The ordering of the variables in the decision tree is .xed using some heuristic. While \ncomputing a(Q), if there is a clause d at a vertex such that Q . .(d), then the clauses at the descendants \nof that vertex can be ignored. Thus, this algorithm also tries to .nd small clauses, but its ability \nto do so is strongly constrained by the .xed variable ordering. This procedure may require O(2n+1) theorem \nprover queries. The second method [SS99] generates all clauses in increasing order of size. Again, if \nQ . .(d)for some clause d, then the algorithm ignores all clauses d ' such that d . d ' . This algorithm \nalso searches for small clauses that are implied by Q but this search may re\u00adquire enumerating excessively \nmany clauses (up to 3n clauses). Thus, this algorithm may require O(3n)theo\u00adrem prover queries. Our algorithm \ndoes not su.er from the ordering problem of the binary decision tree algorithm to the same extent. At \nthe same time, it reliably .nds small clauses that are implied by Q without enumerating too many clauses. \nWe show experimental results on several examples in Section 7.4demonstrating that our algo\u00adrithm performs \nfewer queries than the two algorithms discussed above. 6 Heuristics for generating predicates The previous \nsections reduce the problem of specifying correct invariants to the simpler problem of specifying potentially \nuseful predicates. However, providing such predicates can be still tedious, particularly for large programs. \nThis section presents heuristics for guessing many of these predicates automatically. When desugaring \neach loop, ESC/Java .rst com\u00adputes a set of loop targets, which are the data loca\u00adtions possibly modi.ed \nby the loop body. A target is expressed in terms of variables that are in scope at the beginning of the \nloop. Each target is either pre\u00adcise or imprecise. A precise target is an l-value: either avariable x, \na .eld reference e.f, or an array refer\u00adence e1[e2], and speci.es a unique location. An im\u00adprecise target \ndenotes a set of locations and is of the form *.f, e1[*], *[e2],or *[*], where either an ob\u00adject reference \nor an array index is unknown. These loop targets are havoced on entry to the loop; we would like to infer \ninvariants that capture relevant properties of the havoced targets. If the loop targets include the imprecise \ntar\u00adget e1[*], then we would like to infer universally\u00adquanti.ed loop invariants that explicate properties \nof the modi.ed array e1. For this purpose, we introduce a skolem constant sc of type int, together with \nthe pred\u00adicates 0<=sc and sc<x,where x ranges over integer variables in scope. We also guess predicates \nabout the skolemized target expression e1[sc], as described be\u00adlow. For each (precise or skolemized) \ntarget expression t (of the form x, e.f, e1[e2],or e1[sc]), we proceed basedonthe type of t.If t is of \nreference type, we guess that t is not null.If t is an integer, we then guess the predicates t<= \\old(t), \nt>= \\old(t),and t<sc, where the ESC/Java syntax \\old(t) refers to the value of t on entry to the loop. \nTo illustrate these heuristics, we brie.y describe their application to a loop that clears the array \na: (for int i=0; i<a.length; i++) a[i] = null; For this loop, the heuristics will generate the pred\u00adicate \ni>= \\old(i), which is also a loop invariant. Since \\old(i) = 0, this invariant, together with the loop \nguard i < a.length, is su.cient to verify the ab\u00adsence of array bounds errors. In addition, the heuris\u00adtics \ngenerate three crucial predicates: 0<=sc, sc<i, and a[sc] != null. Predicate abstraction subse\u00adquently \ncombines these predicates into the invariant that all array entries below i have been cleared: (\\forall \nint sc; 0 <= sc &#38;&#38; sc < i ==> a[sc] == null) This invariant is crucial in allowing ESC/Java to \nverify that after the loop terminates the array contains only nulls. These heuristics are targeted towards \ngenerating predicates that are useful for the typical proof obliga\u00adtions in ESC/Java. If ESC/Java is \nused to prove more compilcated properties, these heuristics will have to be augmented. Currently, we \ndo not infer loop invariants stating properties of all elements in a list or a tree, be\u00adcause ESC/Java \ndoes not allow convenient expression of the set of objects reachable from an object reference. Cell partition(Cell \nl, int v) { Cell curr = l, prev = null, newl = null; Cell nextCurr; while (curr != null) { nextCurr = \ncurr.next; if (curr.val > v) { if (prev != null) prev.next = nextCurr; if (curr == l) l = nextCurr; curr.next \n= newl; L: //@ assert curr != prev; newl = curr; } else { prev = curr; } curr = nextCurr; } return newl; \n} Figure 5: Method partition 7 Implementation and evaluation We have implemented our method, described \nin earlier sections, as part of ESC/Java. In this section, we de\u00adscribe the application of our technique \nto two small il\u00adlustrative examples, as well as to a substantial program containing over 44K lines of \ncode. 7.1 List partition Figure 5 shows a list partitioning example adapted from a paper describing the \nSLAM project [BMMR01]. Each list element is an instance of the class Cell, and con\u00adtains two .elds an \ninteger val and a reference next to the following cell in the list. The method partition takes two arguments, \na list l and an integer v.It re\u00admoves every cell with value greater than v from l and returns a new list \ncontaining all those cells. The SLAM tool can verify, using their predicate ab\u00adstraction algorithm, that \nat the control point L the vari\u00adable curr is not aliased to prev. We explicate this property as an assertion \nin the program. To verify this assertion using our technique, we sim\u00adply need to provide the two predicates: \n/*@ loop_predicate prev == null, prev.val > v */ Using these predicates, our technique infers the loop \ninvariant: /*@ loop_invariant prev == null || !(prev.val > v) */ /*@ requires a != null; ensures (\\forall \nint x, y; 0<= x &#38;&#38; x< y&#38;&#38; y <a.length ==> a[x] <= a[y]); */ void sort(int[] a) { inti=0; \nwhile (i < a.length) { int k = i, w = a[i],j = i + 1; while (j < a.length) { if (a[j]< w) { k= j; w = \na[j]; } j=j +1; } a[k] = a[i]; a[i] = w; i=i+1; } } Figure 6: Method sort The correctness of the assertion \nfollows from this loop invariant and from the two conditions (curr != null and curr.val > v) on the path \nfrom loop entry to L. In contrast, because SLAM performs predicate ab\u00adstraction for each individual statement, \nit requires the following two additional predicates to track the values of the two conditions. curr == \nnull, curr.val > v Since deriving predicates may still require manual inter\u00advention (both in our system \nand in SLAM), this need for extra predicates results in an increased burden on the programmer. In addition, \nby abstracting only when necessary, our approach requires many fewer theorem prover queries. In particular, \nusing all four predicates, we require only 27 queries to verify the non-aliasing as\u00adsertion whereas SLAM \nrequires 263 queries.  7.2 Selection sort The next example illustrates that our method works on programs \nwith nested loops and is able to infer complex loop invariants. The method sort, shown in Figure 6, takes \nan array of integers a and sorts it in place. The method contains two nested loops. The outer loop uses \nthe integer variable i to iterate over the elements of a. The inner loop .nds the smallest element of \na at or after the index i, which is then swapped with the element at i. The outer loop ensures that the \ni-th pre.x of a is sorted. Based on the annotations /*@ skolem_constant int x, y; loop_predicate i >= \n0, 0 <= x, x < i, x < y, y < a.length, a[x] <= a[y]; */ our technique infers the required invariants \nfor the outer loop: /*@ loop_invariant (\\forall int x, y; 0<=x&#38;&#38;x <i&#38;&#38;x< y&#38;&#38;y \n<a.length ==> a[x] <= a[y]); loop_invariant 0 <= i; */ The second loop invariant is needed to prove that \nthere are no array bounds violations in the loop. The inner loop computes in k and w the index and the \nvalue respectively of the least element with an index in the range [i, j). Based on the annotations /*@ \nskolem_constant int z; loop_predicate w == a[k], i <= z, z < j, w <= a[z], i <=k,k< j,j<= a.length; */ \nour technique infers the required invariants for the inner loop: /*@ loop_invariant w == a[k]; loop_invariant \n(\\forall int z; i <= z &#38;&#38; z < j ==>w<=a[z]); loop_invariant i <= k; loop_invariant k < j; loop_invariant \nj <= a.length; */  7.3 The Java front-end toolkit The examples presented so far illustrate various as\u00adpects \nof our technique, but are too small to provide compelling evidence that our technique is practical on \nlarge, realistic programs. Therefore, we next consider the application of our technique to a signi.cantly \nlarger program. The benchmark we use is the front-end to ESC/Java called Javafe, which consists of 44,388 \nlines of code, with 2418 routine de.nitions and 520 loops. This code was already annotated with appropriate \nESC/Java lightweight method speci.cations, but did not include any loop invariants. Instead, the code \nwas checked by .rst unrolling each loop some small .nite number of times, typically 1 or 2. Although \nthis unrolling tech\u00adnique is clearly unsound, it signi.cantly reduces the annotation burden of using \nESC/Java. Using this un\u00adsound loop analysis, ESC/Java can verify all of the rou\u00adtines in the benchmark. \nIn comparison, when using the sound loop desugar\u00ading of Section 3 (without providing or inferring any \nloop invariants) ESC/Java is unable to verify 326 of the 2418 routines in this program, including most \nof the routines containing non-trivial loops. Manually providing suit\u00adable invariants for all of these \nloops is a daunting task. We have been unwilling to invest this e.ort on our own code base, and do not \nexpect software engineers to do so either. However, using the techniques presented in this pa\u00adper, we \nhave extended ESC/Java to perform a sound analysis of loops, without signi.cantly increasing the annotation \nburden. To achieve this sound loop anal\u00adysis, we did not provide any additional annotations, such as \nloop invariants or loop predicates. Instead, we .rst used the heuristics of Section 6, which sug\u00adgested \nan average of 3.6 predicates for each loop al\u00adthough it suggested many more predicates for complex loops. \nWe subsequently used predicate abstraction to infer universally-quanti.ed loop invariants over these \npredicates, which produced an average of 2.6 invariants per loop although again producing many more invari\u00adants \nfor complex loops. Using these inferred invariants, ESC/Java veri.es almost all (98.7%) of the routines \nin the program. An inspection of the remaining 31 failing routines showed that they all require subtle \nloop invariants. For these routines, the appropriate invariants or component predicates must still be \nprovided manually. However, the techniques of this paper reduce the number of rou\u00adtines for which such \nmanual annotation is necessary by order of magnitude, from 326 to 31. In addition, our technique decreases \nthe cost of such manual annotation by reducing the problem of specifying correct loop in\u00advariants to \nthe problem of writing possibly useful pred\u00adicates. We believe the overhead of providing these annota\u00adtions \nis justi.ed by the increased rigor of the sound loop analysis, which is capable of detecting additional \nerrors. In particular, during our inspection of the 31 failing rou\u00adtines, we uncovered several routines \nthat could actually crash due to array bounds violations. The driving goal of ESC/Java is to identify \nsuch possible defects; how\u00adever, ESC/Java s initial, unsound treatment of loops caused it to originally \nmiss these defects.  7.4 Experiments The results presented above have focused on the e.ec\u00adtiveness of \nour invariant inference technique; we next discuss the computational cost of this technique. We analyzed \nthe Javafe benchmark using three di.erent but equivalently-precise predicate abstraction algorithms: \nour new algorithm (FQ), and the two existing algo\u00adrithms of Das, Dill and Park (DDP), and Sa\u00a8idi and \nShankar (SS). Figure 7 compares these algorithms and describes how the performance of each algorithm \nvaries according to the number of predicates in each loop. For loops with six or fewer predicates, all \nalgorithms perform compa\u00adrably well. However, as the number of predicates in\u00adcreases, we begin to see \nsigni.cant di.erences in the behavior of the three algorithms. The data point for 14 1000 900 800 700 \n600 Queries 500 400 300 200 100 0 Predicates per loop Figure 7: Comparison of the three predicate abstraction \nalgorithms (FQ, DDP, and SS) on Javafe Benchmark Number of Queries predicates FQ DDP SS partition sort \n(outer) sort (inner) find create 4 6 7 8 15 27 44 37 111 358 28 54 32 110 1191 41 111 40 129 2012 Figure \n8: Comparison of the three predicate abstrac\u00adtion algorithms (FQ, DDP, and SS) on the micro\u00adbenchmarks \npredicates is somewhat of an outlier. There is only one loop in Javafe for which our heuristics generate \n14pred\u00adicates, and all algorithms perform well on this loop be\u00adcause its invariants are particularly \nsimple. Apart from this loop, the data suggests that our new algorithm scales better than earlier algorithms \nto large numbers of predicates. This scalability is an important charac\u00adteristic of our predicate abstraction \nalgorithm. In par\u00adticular, it gives us the freedom to introduce additional predicate-generating heuristics, \nshould such additional heuristics become necessary when examining other pro\u00adgrams. We performed these \nexperiments using a 667MHz EV7 Alpha processor. Over the entire Javafe bench\u00admark (44,380 LOC), our algorithm \nperformed 11901 queries, which required roughly 40 minutes of theorem proving time (an average of 0.2 \nseconds per queries). The entire loop invariant inference process took a little under an hour, proceeding \nat a rate of roughly 13 lines per second. We expect further progress in automatic theorem proving to \nsigni.cantly improve this rate. As a second experiment, we also applied our method to to verify a Java \nmodel of the procedure create from the .le system Frangipani [TML97]. This procedure contains a loop \nthat ensures that the newly-created .le does not duplicate the name of an existing .le in the same directory. \nDue to the sophistication of the .le system s data structures, the veri.cation of this loop requires \n15 moderately complex predicates. The per\u00adformance of the the three predicate abstraction algo\u00adrithms \non this benchmark, and on the three other micro\u00adbenchmarks (find, partition,and thetwo loops in sort) \nis shown in Figure 8. 8 Conclusions The ESC/Java project has shown that extended static checking can \n.nd a variety of errors in large programs. But the perceived burden of annotating programs has been a \nbig hurdle to the use of static checking in pro\u00adgram development. Although programmers are willing to \ndocument exported methods, they are not willing to specify every method and write invariants for every \nloop in the program. This paper helps make extended static checking more acceptable to programmers by \nreducing the an\u00adnotation burden of loop invariants. We present heuris\u00adtics for generating appropriate \npredicates for each loop. Using these predicates, our loop invariant inference al\u00adgorithm infers (universally-quanti.ed) \nloop invariants. Our algorithm abstracts only when necessary, thus re\u00adducing the number of predicates \nrequired. Finally, our invariant inference algorithm exploits a new predicate abstraction algorithm. \nThe combination of these techniques reduces the an\u00adnotation burden of loop invariants by an order of \nmag\u00adnitude. In particular, we can now perform an auto\u00admatic yet sound analysis of the loops in over 90% \nof the 396 loop-containing routines in Javafe. For the re\u00admaining 31 routines that require predicates \nnot gen\u00aderated by our heuristics, our approach still reduces the problem of specifying correct loop invariants \nto the sim\u00adpler problem of writing possibly-useful loop predicates. Acknowledgments We gratefully acknowledge \nthe contributions of Chandu Thekkath, who helped us to model the method create of Frangipani in Java, \nand the ESC/Java team whose work provided the infrastructure that enabled us to im\u00adplement and evaluate \nour ideas. References [BBM97] N.S. Bj\u00f8rner, A. Browne, and Z. Manna. Automatic generation of invariants \nand intermediate assertions. Theoretical Computer Science, 173(1):49 87, 1997. \u00a8 techniques for the automatic \ngeneration of invariants. In R. Alur and T.A. Henzinger, editors, CAV 96: Computer Aided Veri.cation, \nLecture Notes in Com\u00adputer Science 1102, pages 325 335. Springer-Verlag, 1996. [BLS96] S. Bensalem, Y. \nLakhnech, and H. Saidi. Powerful [BMMR01] T. Ball, R. Majumdar, T. Millstein, and S. K. Ra\u00adjamani. Automatic \npredicate abstraction of C pro\u00adgrams. In Proceedings of the ACM SIGPLAN Con\u00adference on Programming Language \nDesign and Im\u00adplementation (PLDI), pages 203 213, 2001. [Bry86] R.E. Bryant. Graph-based algorithms for \nboolean function manipulation. IEEE Transactions on Com\u00adputers, C-35(8):677 691, 1986. [BvW98] R.-J. \nBack and J. von Wright. Re.nement Calcu\u00adlus: A Systematic Introduction. Graduate Texts in Computer Science. \nSpringer-Verlag, 1998. [CC77] P. Cousot and R. Cousot. Abstract interpretation: a uni.ed lattice model \nfor the static analysis of pro\u00adgrams by construction or approximation of .xpoints. In Proceedings of \nthe Fourth Annual Symposium on Principles of Programming Languages. ACM Press, 1977. [CGJ+00] E.M. Clarke, \nO. Grumberg, S. Jha, Y. Lu, and H. Veith. Counterexample-guided abstraction re.ne\u00adment. In E.A. Emerson \nand A.P. Sistla, editors, CAV 2000: Computer Aided Veri.cation, Lecture Notes in Computer Science 1855, \npages 154 169. Springer-Verlag, 2000. [CH78] P. Cousot and N. Halbwachs. Automatic discovery of linear \nrestraints among variables of a program. In Proceedings of the 5th Annual Symposium on Princi\u00adples of \nProgramming Languages, pages 84 96. ACM Press, 1978. [DDP99] S. Das, D. L. Dill, and S. Park. Experience \nwith predicate abstraction. In N. Halbwachs and D. Peled, editors, CAV 99: Computer Aided Veri.cation,Lec\u00adture \nNotes in Computer Science 1633, pages 160 171. Springer-Verlag, 1999. [Dij76] E.W. Dijkstra. A Discipline \nof Programming. Prentice-Hall, 1976. [DLNS98] D. L. Detlefs, K. R. M. Leino, C. G. Nelson, and J. B. \nSaxe. Extended static checking. Research Report 159, Compaq Systems Research Center, December 1998. [FS01] \nC. Flanagan and J. B. Saxe. Avoiding exponential ex\u00adplosion: Generating compact veri.cation conditions. \nIn Conference Record of the 28th Annual ACM Sym\u00adposium on Principles of Programming Languages, pages \n193 205. ACM, January 2001. \u00a8 graphs with PVS. In O. Grumberg, editor, CAV 97: Computer Aided Veri.cation, \nLecture Notes in Com\u00ad puter Science 1254, pages 72 83. Springer-Verlag, 1997. [GS97] S. Graf and H. Sa \nidi. Construction of abstract state [GW74] I. Greif and R. Waldinger. A more mechanical heuris\u00adtic approach \nto program veri.cation. In Proceedings of the International Symposium on Programming, pages 83 90, 1974. \n[GW75] S.M. German and B. Wegbreit. A synthesizer of in\u00adductive assertions. IEEE Transactions on Software \nEngineering, SE-1(1):68 75, 1975. [KM76] S.M. Katz and Z. Manna. A logical analysis of pro\u00adgrams. Communications \nof the ACM, 19(4):188 206, 1976. [LSS99] K. R. M. Leino, J. B. Saxe, and R. Stata. Check\u00ading Java programs \nvia guarded commands. In Bart Jacobs, Gary T. Leavens, Peter M\u00a8uller, and Arnd Poetzsch-He.ter, editors, \nFormal Techniques for Java Programs, Technical Report 251. Fernuni\u00adversit\u00a8at Hagen, May 1999. [MP92] \nZ. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems: Speci.cation. Springer-Verlag, \n1992. [Nel81] C. G. Nelson. Techniques for program veri.cation. Technical Report CSL-81-10, Xerox Palo \nAlto Re\u00adsearch Center, 1981. [Nel89] C. G. Nelson. A generalization of Dijkstra s calculus. ACM Transactions \non Programming Languages and Systems, 11(4):517 561, 1989. [SI77] N. Suzuki and K. Ishihata. Implementation \nof an array bound checker. In Proceedings of the 4th An\u00adnual Symposium on Principles of Programming Lan\u00adguages, \npages 132 143. ACM Press, 1977. \u00a8 while you prove. In N. Halbwachs and D. Peled, ed\u00ad itors, CAV 99: Computer \nAided Veri.cation,Lec\u00ad ture Notes in Computer Science 1633, pages 443 454. Springer-Verlag, 1999. [SS99] \nS. Sa idi and N. Shankar. Abstract and model check [TML97] C.A. Thekkath, T. Mann, and E.K. Lee. Frangipani: \nA scalable distributed .le system. In Proceedings of the 16th ACM Symposium on Operating Systems Principles, \npages 224 237, October 1997. [Weg74] B. Wegbreit. The synthesis of loop predicates. Com\u00admunications of \nthe ACM, 17(2):102 112, 1974.   \n\t\t\t", "proc_id": "503272", "abstract": "Software verification is an important and difficult problem. Many static checking techniques for software require annotations from the programmer in the form of method specifications and loop invariants. This annotation overhead, particularly of loop invariants, is a significant hurdle in the acceptance of static checking. We reduce the annotation burden by inferring loop invariants automatically.Our method is based on predicate abstraction, an abstract interpretation technique in which the abstract domain is constructed from a given set of predicates over program variables. A novel feature of our approach is that it infers universally-quantified loop invariants, which are crucial for verifying programs that manipulate unbounded data such as arrays. We present heuristics for generating appropriate predicates for each loop automatically; the programmer can specify additional predicates as well. We also present an efficient algorithm for computing the abstraction of a set of states in terms of a collection of predicates.Experiments on a 44KLOC program show that our approach can automatically infer the necessary predicates and invariants for all but 31 of the 396 routines that contain loops.", "authors": [{"name": "Cormac Flanagan", "author_profile_id": "81100538763", "affiliation": "Compaq Systems Research Center, Palo Alto, CA", "person_id": "PP14187273", "email_address": "", "orcid_id": ""}, {"name": "Shaz Qadeer", "author_profile_id": "81100286660", "affiliation": "Compaq Systems Research Center, Palo Alto, CA", "person_id": "PP14106781", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/503272.503291", "year": "2002", "article_id": "503291", "conference": "POPL", "title": "Predicate abstraction for software verification", "url": "http://dl.acm.org/citation.cfm?id=503291"}