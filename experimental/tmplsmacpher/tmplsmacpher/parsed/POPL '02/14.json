{"article_publication_date": "01-01-2002", "fulltext": "\n Stochastic Lambda Calculus and Monads of Probability Distributions Norman Ramsey Avi Pfeffer Division \nof Engineering and Applied Sciences Harvard University  Abstract Probability distributions are useful \nfor expressing the mean\u00adings of probabilistic languages, which support formal mod\u00adeling of and reasoning \nabout uncertainty. Probability dis\u00adtributions form a monad, and the monadic de.nition leads to a simple, \nnatural semantics for a stochastic lambda cal\u00adculus, as well as simple, clean implementations of common \nqueries. But the monadic implementation of the expectation query can be much less e.cient than current \nbest practices in probabilistic modeling. We therefore present a language of measure terms, which can \nnot only denote discrete prob\u00adability distributions but can also support the best known modeling techniques. \nWe give a translation of stochastic lambda calculus into measure terms. Whether one trans\u00adlates into \nthe probability monad or into measure terms, the results of the translations denote the same probability \ndis\u00adtribution. 1. Introduction Researchers have long modeled the behavior of agents using logic, but \nlogical models are a poor choice for dealing with the uncertainty of the real world. For dealing with \ninherent uncertainty and with incomplete knowledge, probabilistic models are better. There are a variety \nof representations and reasoning tech\u00adniques for probabilistic models. These techniques, which include \nBayesian networks (Pearl 1988) and other kinds of graphical models (Jordan 1998), are centered around \nthe structuring and decomposition of probability distribu\u00adtions. Recent work focuses on scaling up the \ntechniques to deal with large, complex domains. Domains that re\u00adquire large-scale modeling techniques \ninclude medical di\u00adagnosis (Jaakkola and Jordan 1999) and military intelli\u00adgence (Mahoney and Laskey \n1998). As models grow large, it becomes more important to be able to build them easily and to reuse the \nparts but con- Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. POPL 02, Jan. 16-18, 2002 Portland, OR USA .2002 ACM ISBN 1-58113-450-9/02/01. . . $5.00 sidered \nas programming languages, the techniques used to build probabilistic models are weak. We would like to \ndraw on the large body of knowledge about programming lan\u00adguages to design a good language that supports \nprobabilis\u00adtic modeling. Stochastic lambda calculus,in which the deno\u00adtations of expressions are probability \ndistributions, not val\u00adues, is a suitable basis for such a language. To express the semantics of a stochastic \nlambda calculus, we exploit the monadic structure of probability distributions (Giry 1981; Jones and \nPlotkin 1989). The contributions of this paper are: We show that the probability monad leads to simple, \nel\u00adegant implementations of three queries commonly posed of probabilistic models: expectation, sampling, \nand sup\u00adport. Using the monad as an intermediate form simpli\u00ad.es proofs of desirable properties, e.g., \nthat the sampling function draws values from any model using appropriate probabilities.  We show that \nthe monadic implementation of expecta\u00adtion is potentially much less e.cient than techniques currently \nused in probabilistic reasoning. The problem arises because a monad does not exploit intensional prop\u00aderties \nof functions; it only applies functions. To support an alternative implementation of expectation, we \ntrans\u00adlate stochastic lambda calculus into a simple language we call measure terms. By algebraic manipulation \nof mea\u00adsure terms, we can express variable elimination,which is the standard technique for e.ciently \ncomputing expec\u00adtation. Measure terms denote measures, and our trans\u00adlation into measure terms is consistent \nwith our monadic de.nition of stochastic lambda calculus.  Our work has implications for both design \nand imple\u00admentation of probabilistic languages. For design, we show that one can support e.cient probabilistic \nreasoning sim\u00adply by adding a choose operator to an ordinary func\u00adtional language; it is not necessary \nto include language features that expose common implementation techniques such as variable elimination. \nFor implementation, we show that standard techniques of programming-language implementation monadic interpreters \nand algebraic ma\u00adnipulation of programs (including common-subexpression elimination) can apply to probabilistic \nlanguages. Prob\u00adabilistic reasoners can enjoy the bene.ts of higher-order, typed languages, without requiring \nundue e.ort from im\u00adplementors. 2. Probabilistic models and queries The simplest language we have found \nto describe probabilis\u00adtic models is a lambda calculus in which expressions denote probability distributions. \nThe primary means of creating interesting probability distributions is a new construct that makes a probabilistic \nchoice. choose pe1 e2 represents a linear combination of two distributions. Operationally, to take a \nvalue from the combined distribution, with proba\u00adbility pwe take a value from e1 and with probability \n1 - p we take a value from e2. 2.1. An example model To illustrate our ideas, we present a simple model \nof tra.c lights and drivers, using a Haskell-like notation. Tra.c lights are probabilistically red, yellow, \nor green. (tra.c example)= light1 = dist [ 0.45 : Red, 0.1 : Yellow, 0.45 : Green ] dist is a version \nof choose that is extended to combine two or more weighted distributions. Here it means that light1 has \nvalue Red with probability 0.45, value Yellow with probability 0.1, and value Green with probability \n0.45. Drivers behave di.erently depending on the colors of the lights they see. A cautious driver is \nmore likely to brake than an aggressive driver. (tra.c example)+= cautious_driver light = case light \nof Red -> dist [ 0.2 : Braking, 0.8 : Stopped ] Yellow -> dist [ 0.9 : Braking, 0.1 : Driving ] Green \n-> Driving aggressive_driver light = case light of Red -> dist [ 0.3 : Braking, 0.6 : Stopped, 0.1 : \nDriving ] Yellow -> dist [ 0.1 : Braking, 0.9 : Driving ] Green -> Driving We estimate that if two drivers \ngo through a single light from di.erent streets, there is a 90% probability of a crash. (tra.c example)+= \ncrash d1 d2 light = [ 0.90 : d1 light == Driving &#38;&#38; d2 (other light) == Driving, 0.10 : False \n] where other Red = Green other Green = Red other Yellow = Yellow  2.2. Queries Having de.ned a probabilistic \nmodel, we might wish to ask questions about it. For example, if two drivers, one cau\u00adtious and one aggressive, \nare approaching light1,what is the probability of a crash? This question and many others can be answered \nusing three kinds of queries: expectation, sampling,and support. The expectation of a function his the \nmean of hover the distribution. Expectation subsumes some other queries as special cases. The mean value \nof a distribution is  Ovals are representations; boxes are queries Figure 1: Implementation paths the \nexpectation of the identity function. The probabil\u00adity of an outcome satisfying predicate p is the expecta\u00adtion \nof the function \\x -> ifp xthen 1 else 0. Condi\u00adtional probability can be computed from probability, \nsince P(p| q)= P(p.q)\u00f7P(q). In the example above, we can an\u00adswer the question about the probability of \na crash by build\u00ading the probability distribution of crash cautious driver aggressive driver light1 and \ncomputing the probability of the identity predicate. Sampling means drawing a value from the distribution. \nBy sampling repeatedly, we can not only approximate ex\u00adpectation but also get an idea of the shape of \na distribution, or of some function over the distribution. Like true exper\u00adimental data, samples can \nbe .t to analytic solutions to equations; Monte Carlo techniques used in the physical sciences rely on \nsampling. Support tells us from what subset of the entire sample space a sample might be drawn with nonzero \nprobability. It is seldom interesting by itself, but a good implementa\u00adtion of support can make it easier \nto compute expectations e.ciently. Support therefore plays a signi.cant role in our implementation. \n2.3. Implementing probabilistic models This paper presents two representations that are useful for answering \nqueries about probabilistic models: probability monads and measure terms. Figure 1 shows the translations \ninvolved. 1. A user writes a model and a query using a domain\u00adspeci.c, probabilistic language. In this \npaper, we take the language to be the stochastic lambda calculus that is de.ned formally in Section 4. \nIn practice, we would pre\u00adfer a richer language, e.g., one providing types, modules, and either an explicit \n.xed-point operator or recursion equations. Even in practice, however, stochastic lambda calculus is \na useful intermediate form. 2. We translate the model into a more restricted target form: a value in \nthe probability monad, or a measure term. Section 4 gives a translation into the probability monad, the \nsemantics of which we explain in Section 3. Section 6 gives a translation into measure terms.   3. \nWe use the target form to answer the query. The prob\u00adability monad can answer all three kinds of query; \nmea\u00adsure terms are designed to answer expectation queries e.ciently. The probability monad is easy to \nimplement in Haskell (Section 5), so we could also use Haskell as an embedded domain-speci.c language \nfor probabilistic modeling. E.\u00adcient implementation of measure terms is more di.cult; our current implementation \nis written in Objective Caml in order to exploit mutable state (Pfe.er 2001).  3. Semantics of probability \nand the probabil\u00adity monad 3.1. Measure theory Both discrete and continuous probability are easily de\u00adscribed \nusing measure theory; we borrow notation from Rudin (1974). The values over which a probability dis\u00adtribution \nis de.ned are drawn from some space X. Ob\u00adservable events in an experiment are typically represented \nby subsets of X. We call these subsets the measurable sets of X, and we require that the entire space \nbe measurable and that the measurable sets be closed under complement and countable union, i.e., that \nthe measurable sets form a s-algebra. The classical de.nition of a measurable function is a function \nfrom X to a topological space (e.g., R)such that the inverse images of open sets are measurable. We restrict \nour attention to functions between measure spaces and de.ne the measurable functions as those such that \nin\u00adverse images of measurable sets are measurable; that way the composition of measurable functions is \nmeasurable. Fi\u00adnally, a measure is a function \u00b5 that maps each measurable set to a real number in the \nrange [0,8]and that is countably additive.That is, if {Ai} is a disjoint countable collection of measurable \nsets, \u00b5( i Ai)=i \u00b5(Ai).A probability dis\u00adtribution is a measure such that \u00b5(X) = 1. We use Greek letters \n. and \u00b5 to stand for measures. Abstract integration plays a signi.cant role in probability. If f is a \nreal-valued, measurable function on a measurable space X with measure \u00b5,and if A is a measurable subset \n of X,we writefd\u00b5 for the Lebesgue integral of f over A set A.If eis an expression in which xappears \nfree, we often writeed\u00b5(x) instead of(.x.e) d\u00b5. A A 3.2. Queries We de.ne our queries in terms of measure \ntheory and ab\u00adstract integration. The simplest query to de.ne is expecta\u00adtion. If we have a probability \ndistribution . over space X, then the expectation of a function h ishd.. X A support of a distribution \nis a measurable set outside which the distribution is zero. A set S is a support of a distribution . \nif for any measurable set A, .(A)= .(AnS). In the language of real analysis, S is a support of . i. . \nis concentrated on S. A good support can make it easier to compute expectations, by exploitinghd. =hd.. \nXS There are many ways to formulate sampling. We could de.ne a sampling as a function from a probability \ndistribu\u00adtion to an in.nite sequence of values, but we prefer to de\u00ad.ne sampling directly in terms of \nmeasure theory. Accord\u00adingly, we say that a measurable function s:[0,1] . X is a sampling function for \n. if for any measurable set A . X, .(A)= \u00b5(s -1(A)), where \u00b5 is the Lebesgue measure, which describes \nuniform distributions. We use this formulation for its practical value: if you give us a way of sampling \nuni\u00adformly on the unit interval, by applying s we ll give you a way of sampling from the probability \ndistribution ..The equation implies that if r is drawn uniformly from the unit interval, the probability \nthat s(r) . A is the same as the probability that r . s -1(A). 3.3. The probability monad It has long \nbeen known that probability distributions form a monad (Lawvere 1962; Giry 1981; Jones and Plotkin 1989). \nIn this section, we recapitulate some previous work, dis\u00adcussing the relationship of the monad operations \nto proba\u00adbility. The monadic bind operation, in particular, provides much of the functionality one needs \nto create interesting probability distributions for use in models. In Section 5, we extend the probability \nmonad with additional opera\u00adtions that support queries. Throughout the paper, rather than use category-theoretic \nnotation, we write return for the unit operation and >>= for bind (monadic extension). This notation \nwill be more familiar to Haskell programmers and to readers of Wadler (1992). The denotation of the unit \noperation is simplicity itself: return x stands for a distribution that is, a measure which assigns unit \nprobability to any measurable set con\u00adtaining x and zero probability to any measurable set not containing \nx: { 1, if x. A M[[return x]](A)= 0, if x/. A. This measure is sometimes called the unit mass concen\u00adtrated \nat x. It enjoys the property that for any measurable function f, fdM[[return x]] = f(x). (1) X The proof \nappeals directly to the de.nition of Lebesgue integration. Property 1 plays a key role in the proofs \nof the monad laws for probability measures. To motivate the de.nition of monadic bind, we appeal to conditional \nprobability. If d denotes a probability measure over space X and k denotes a function from values in \nX to probability measures over space Y,then k may be inter\u00adpreted as de.ning a conditional probability \nof Y given X. Because d denotes the probability of X, applying the chain rule says that the joint probability \nof X and Y is equal to the probability of X times the conditional probability of Y given X. We can get \nthe probability of Y by integrating over X.Since we wish d>>= k to denote the probability of Y, we de.ne \n M[[d>>= k]](A)=M[[k(x)]](A) dM[[d]](x). X The notation may be confusing; the integral uses the measure \nM[[d] , and the function being integrated over is .x.M[[k(x)]](A). The following property of monadic \nbind plays a signi.\u00adcant role in several of our proofs: g(y) dM[[d>>= k]](y)=Given properties 1 and \n2, it is straightforward to prove that the de.nitions of return and >>= satisfy the monad laws. Y  (2) \ng(y) dM[[k(x)]](y) dM[[d]](x) X Y To create some interesting distributions, we need at least one more \noperation in our monad. The choose function is a two-argument version of the dist used in Section 2.1. \nProbabilistic choice is linear combination of measures: M[[choose pd1 d2]](A)= p\u00b7M[[d1]](A)+(1 -p) \u00b7M[[d2]](A), \nwhere 0 = p= 1and the \u00b7 symbol stands for multiplica\u00adtion. choose su.ces to create any distribution with \n.nite support. Creating other kinds of distributions, including in\u00adteresting continuous distributions, \nwould require additional operations. (One can also create continuous distributions by taking limits of \ndiscrete distributions with .nite sup\u00adport.) It is easy to show by induction on the structure of the \nmonad that any value created using return, >>=, and choose denotes a probability measure; the only interesting \nstep uses property 2 with g(y)= 1. 3.4. Probability mass and density functions Although it is possible \nto work directly with probability measures, it is often easier to work with functions that map values \nto their probability or probability density. Any nonnegative, Lebesgue integrable function f de.nes a \nmeasure, because if \u00b5 is a bounded measure, then the function . de.ned by .(A)= fd\u00b5 is also a measure. \nA Furthermore, for any measurable A, gd. = g\u00b7fd\u00b5. AA This theorem plays a signi.cant role in the proof \nof the associativity law for the probability monad. Even better, many measures can be described by a \nfunc\u00adtion like f. The Radon-Nikodym theorem says that if . is bounded and if \u00b5(A) = 0 implies that .(A) \n= 0 (i.e., . is absolutely continuous with respect to \u00b5), then there exists a nonnegative integrable \nf such that .(A)= fd\u00b5.In this A case, we write the function f as .; .is the Radon-Nikodym derivative \nof .. Most implementations of probability use functions such as .; this use is justi.ed when the measure \n.has a Radon-Nikodym derivative with respect to an underlying mea\u00adsure \u00b5. Whether probability is discrete \nor continuous depends on the underlying measure. For discrete probability, countable sets are measurable, \nand the appropriate measure \u00b5is the counting measure. This measure is useful for countable spaces; the \nmeasure of a set is the number of elements it contains. Because the counting measure assigns measure \nzero only to the empty set, every discrete probability distribution has a Radon-Nikodym derivative, i.e., \nevery such distribution can be represented as a probability-mass function f that assigns a nonnegative \nprobability to each element of X and which satis.es fd\u00b5= 1. When using the count- X ing measure, wemay \nusea symbol instead of the integral: fd\u00b5= f(xi). Axi.A For continuous probability over real variables, \nwhich may model such processes as queueing or radioactive decay, the appropriate measure is the Lebesgue \nmeasure on real numbers. The Lebesgue measure of an interval is the length of the interval; see Rudin \n(1974) for an explana\u00adtion of how to extend this measure to a much larger class of sets. Provided it \nassigns zero probability to sets of Lebesgue measure zero, a continuous probability distri\u00adbution . can \nbe represented as an integrable function . that assigns a nonnegative probability density to each point \nof X and which satis.es .du=1. Many inter- X esting continuous distributions fall into this class. For \ncomputing probabilities over in.nite data structures, neither the counting measure nor the Lebesgue measure \nis necessarily useful. For example, if we consider in.\u00adnite sequences of .ips of a fair coin, there are \nuncount\u00adably many such sequences, and the probability of any particular sequence is zero, so the counting \nmeasure is useless. To know what questions we can sensibly ask about in.nite data structures, we need \nto know what are the measurable sets. A good place to start is the smallest s-algebra containing the \nthe sets Ux de.ned by Ux = {y| x. y},where xis .nite. Subject to some tech\u00adnical conditions, this is \nthe Borel algebra of the Scott topology on a partially ordered set (Smyth 1983). We can use probability \nmeasures over this s-algebra to an\u00adswer such questions as what is the probability that a sequence begins \nwith three consecutive heads? It is not clear to us when Radon-Nikodym derivatives (mass or density functions) \nexist for these kinds of measures. Because it is often easier to work with probablity mass functions \ninstead of measures, we give de.nitions of the monad operations in terms of these functions. These de.\u00adnitions \napply only to discrete probability. { 1, if x= v M[[return v]](x)= 0, if x. = v M[[d>>= k]](x)= v M[[d]](v) \n\u00b7M[[k(v)]](x) M[[choose pd1 d2]](x)= p\u00b7M[[d1]](x)+ (1 -p) \u00b7M[[d2]](x)  4. A stochastic lambda calculus \nand its se\u00admantics Here we present a formal calculus for expressing probability distributions, and we \ngive a denotational de.nition using the probability monad. To simplify the presentation, we use pairs \ninstead of general products, binary sums instead of general sums, and binary choice (choose) instead \nof the general dist. e::= x| v| .x.e| e1 e2 | let x= e . in e | choose pe1 e2 | (e1,e2) | e.1 | e.2 | \nL e1 | R e2 | case eel er The case expression may need explanation; eis an expres\u00adsion of sum type, which \nis either left (L v)orright (R v). If left, we apply el to the carried value; otherwise we apply er.Our \ncase is analogous to the either function found in the standard Haskell Prelude. In our semantics, the \nprobability monad is a type con\u00adstructor M, together with unit, bind, and choose opera\u00adtions. If X is \na type, MX is the type of probability measures over X. Semantically, we wish to limit our at\u00adtention \nto measures that restrict to continuous evaluations, so that MX is a probabilistic powerdomain (Jones \nand Plotkin 1989). In Figure 2, we use the probability monad to de.ne the semantics of the stochastic \nlambda calculus. By using suitable domains with the translation in Figure 2, we can make a denotational \nsemantics for the stochastic P[[x]]. = return (.x) P[[v]]. = return v P[[.x.e]]. = return (.v.P[[e]].{x. \nv}) P[[let x = e' in e]]. = P[[e']].>>= .v.P[[e]].{x . v} P[[e1 e2]]. = P[[e1]].>>= .v1.P[[e2]].>>= .v2.v1v2 \nP[[(e1,e2)]]. = P[[e1]].>>= .v1.P[[e2]].>>= .v2.return (v1,v2) P[[e.1]]. = P[[e]].>>=(return . fst) P[[e.2]]. \n= P[[e]].>>=(return . snd) P[[choose pe1 e2]]. = choose p (P[[e1]].)(P[[e2]].) P[[L e]]. = P[[e]].>>=(return \n. Left) P[[R e]]. = P[[e]].>>=(return . Right) P[[case eel er]]. = P[[e]].>>= either (.v.P[[el]].>>= \n.f.f v)(.v.P[[er]].>>= .f.f v) Figure 2: Translation of stochastic calculus into the probability monad \nlambda calculus (Jones 1990, Chapter 8). This translation has two signi.cant properties: The denotations \nof expressions are not the same kinds of objects that appear in environments. Expressions denote probability \ndistributions, but environments bind identi\u00ad.ers to values, not to distributions.  The denotation of \na lambda abstraction of type a-> b is a function from values of type a to probability distri\u00adbutions \nover values of type b.  These properties, as well as the rest of the translation, are what you would \nexpect to .nd in a monadic semantics of a call-by-value language with imperative features, except that \nwe use the probability monad instead of a state or I/O monad. We expect that an analogous lazy semantics \nshould also exist, but we have not explored that avenue. Denotational de.nitions are out of fashion. \nWhy don t we have a syntactic theory with an operational seman\u00adtics? Because a denotational de.nition \nmakes it easier to show how the mathematical foundations of probability ap\u00adply to the semantics of probabilistic \nlanguages. Our de\u00adnotational de.nitions also correspond closely to the struc\u00adtures of our implementations. \nIt is a drawback that a reader has to work harder to see that the denotation of (.x.x - x)(choose 12 \n0 1) is the unit mass concentrated at 0. In other words, when reducing lambda terms, it is not permissible \nto duplicate a redex.  5. Probability monads in Haskell Using Haskell, we have implemented the probability \nmonad for discrete distributions. We have taken advantage of Haskell s system of type and constructor \nclasses to pro\u00advide three specialized implementations: one for each kind of query. The probability monad \nprovides choose; it inherits return and >>= from class Monad. For simplicity, we represent probabilities \nas double-precision .oating-point numbers. By using Haskell s type classes, we could support more general \nrepresentations, but the details would be distracting. (probability monads)= type Probability = Double \n--number from 0 to 1 class Monad m => ProbabilityMonad m where choose :: Probability -> m a -> m a -> \nm a Like any other monad, the probability monad needs at least one operation that observes what is inside \na monadic computation (Hughes 1995, \u00a75). The obvious observations are our three queries. Rather than \nrequire one implemen\u00adtation to support all three queries, however, we structure the code so that we can \nprovide three di.erent implemen\u00adtations, one for each kind of query. Since distributions created with \nthis interface have count\u00adable support, it is easiest to represent a support of a dis\u00adtribution by a \nset of elements. To make the code more readable, we use lists instead of sets, and we permit that some \nelements appear more than once; at need, Haskell programmers can eliminate duplicates using List.nub. \n(probability monads)+= class ProbabilityMonad m => SupportMonad m where support :: m a -> [a] --support \n(return x) = [x] --support (d >>= k) = --concat [support (k x) | x <-support d] --support (choose p d \nd ) = --support d ++ support d The comments show algebraic laws that support must sat\u00adisfy; the support \nmonad is a simple extension of the list monad. In the law we give for choose, the value support (choose \np d d ) does not depend on p, even when p is 0 or 1. Indeed, if we remove p from the signature of choose, \nwe get the well-known nondeterminism monad. Our law for choose is sound, and we have chosen it for its \nsimplicity, but it is really an oversimpli.cation. In practice it is important to add the side condition \n0 < p < 1and to add laws to cover the cases p =0 and p = 1. Probabilities of 0 and 1 can arise in real \nmodels from, e.g., idiomatic trans\u00adlations of Bayesian networks, and cutting down the support as much \nas possible can save signi.cant computation. It is easy to show that any implementation of support satisfying \nthe laws above produces a list of values that, when taken as a set, forms a support for the measure de\u00adnoted \nby the monadic value. The proof relies on the dis\u00adcreteness of the measure; the inductive hypothesis \nis that M[[d]](x) > 0 implies x . support d. For simplicity, we de.ne expectation only of real-valued \nfunctions. It is not di.cult to de.ne a version of the ex\u00adpectation monad that can compute the expectation \nof any function whose range is a vector space over the reals. The expectation monad and its laws are \nas follows. (probability monads)+= class ProbabilityMonad m => ExpMonad m where expectation :: (a -> \nDouble) -> m a -> Double --expectation h (return x) = h x --expectation h (d >>= k) = expectation g d \n--where g x = expectation h (k x) --expectation h (choose p d d ) = --p * expectation h d + --(1-p) * \nexpectation h d Using property 2 from Section 3.3, it is easy to prove that any implementation of expectation \nsatisfying these laws computes expectation as de.ned by the measure. Stipulating true real-number arithmetic, \nwith in.nitely many bits of precision, we present laws for a sampling func\u00adtion. If d is a distribution, \nfst . sample d is a sampling function in the sense of Section 3.2. (probability monads)+= --sample (return \nx) r = (x, r) --sample (d >>= k) r = --let (x, r ) = sample d r in sample (k x) r --sample (choose p \nd d ) r = --if r < p then sample d (r/p) --else sample d ((1-r)/(1-p)) The law for choose is the interesting \nlaw; it uses as many bits of precision as are needed to compare r and p,then renormalizes so that the \nremaining bits can be used for further samples. The computation is like what happens to the output of \nan arithmetic coder (Witten, Neal, and Cleary 1987). The proof of correctness of the sampling laws is \nthe most di.cult proof in this paper. The key is .nding a good induction hypothesis: for any distribution \nd and any real function f de.ned on the product space X \u00d7 R, f(sample dr) d\u00b5(r)= f(x, r) dM[[d]](x) d\u00b5(r), \nI IX where I is the unit interval and \u00b5 is Lebesgue measure. From this hypothesis it is straightforward \nto show that \u00b5((fst.sample d)-1(A)) = M[[d]](A), so that fst.sample d is a sampling function for M[[d]]. \nThis de.nition of sampling would not be very useful in an implementation, because it is based on a single \nrandom number with arbitrarily many bits of precision. It is more consistent with Haskell s standard \nlibrary to use a random\u00adnumber generator for sampling: (probability monads)+= class ProbabilityMonad \nm => SamplingMonad m where sample :: RandomGen g => m a -> g -> (a, g) --sample (return x) g = (x, g) \n--sample (d >>= k) g = --let (x, g ) = sample d g in sample (k x) g --sample (choose p d d ) g = --let \n(x, g ) = random g in --sample (if x < p then d else d ) g Although we can give a denotational semantics \nto the sampling monad purely in terms of sampling functions, the sampling monad has an appealing operational \ninterpreta\u00adtion as a monad of random experiments.If m is in the class SamplingMonad, then a value of \ntype ma represents an experiment that returns a value of type a. The unit com\u00adputation return x represents \nthe experiment that always returns x. A computation produced by bind, d>>= k, represents the experiment \nthat begins by running d to gen\u00aderate an intermediate value, applies k to the value to get a second experiment, \nand returns the result of the second experiment. choose pd1 d2 represents the experiment that runs d1 \nwith probability p and d2 with probability 1 - p. The algebraic laws above lead directly to implementa\u00adtions \nof the monads. Additional notation is needed to make legal Haskell; the code appears in Appendix A. \n5.1. Performance The monads above compute support and sampling about as e.ciently as possible, asymptotically \nspeaking. The ex\u00adpectation monad, by contrast, is inherently ine.cient, and for some terms in the stochastic \nlambda calculus, it may perform exponentially worse than other algorithms. The problem with the monadic \ncomputation of expectation is that when we compute expectation hd,we don t have any information about \nthe structure of the function h.We must therefore apply h to every value in its domain,1 at a cost proportional \nto the size of that domain. But if h is de.ned over a product domain, it may be possible to compute the \nexpectation of h at a lower cost, depend\u00ading on the structure of h. For example, if the domain of h is \nthe product space X \u00d7 Y , and if there exist func\u00adtions h1,i and h2,i such that h(x, y)= i h1,i(x)h2,i(y), \nand if \u00b5 can be similarly split, then hd\u00b5(x, y)= X\u00d7Y ( h1,i(x) d\u00b51(x)) \u00b7 ( h2,i(y) d\u00b52(y)). The cost \nof iX Y computing the left-hand side is O(|X \u00d7 Y |), but the cost of computing the right-hand side is \nO(|X| + |Y |). Ifweare computing the expectation of a function of a large num\u00adber of variables (e.g., \nthe expected number of heads in a sequence of 10 coin .ips), the monad can take exponential time to solve \na linear problem. Many functions over which we might wish to take expec\u00adtations have a structure that \ncan be exploited. For example, in a probabilistic grammar for natural language, a model might say that \na sentence is made up of a noun phrase and a verb phrase. In many models, such as probabilistic context-free \ngrammars (Charniak 1993), the two phrases de.ne independent probability distributions, so the prob\u00adability \ndistribution over the string generated by the verb phrase does not depend on that generated by the noun \nphrase. If we want to compute the expected number of words in a sentence, h is the number of words in \nthe noun phrase plus the number of words in the verb phrase, and it has the structure required. Even \nif the noun phrase and verb phrase are not quite independent, but the verb phrase is in.uenced by the \n.rst word of the noun phrase, the verb phrase is still conditionally independent of the remaining words \nof the noun phrase given the .rst word, and the independence can be exploited. The probability monad \ncannot exploit the independence, because it must produce the entire sentence, including both phrases, \nbefore it can apply h. 1Actually it su.ces to apply h only to those values that are inthe support of \nd. This re.nement is important in practice, but it does not a.ect the asymptotic costs. t::= t1 \u00d7t2 \n|t1 + t2 | t|(f: w) y::Y T[[t1 \u00d7t2]]G(.)= T[[t1]]G(.) \u00b7T[[t2]]G(.) T[[t1 + t2]]G(.)= T[[t1]]G(.)+ T[[t2]]G(.) \nT[[ t]]G(.)= T[[t]]({y :: Y}lG)(.{y .v}) y::Yv.Y T[[(f : w)]]G(.)= w\u00b7sat(f,.) { 1, if formula f is \nsatis.ed by the assignment . sat(f,.)= 0, otherwise The bound variable in a sum must be distinct from \nother variables; the union {y :: Y}lG is de.ned only if variable y does not appear in any pair in G. \nFigure 3: Syntax and semantics of measure terms  6. A term language for computing discrete expectation \nThe probability monad leads to elegant implementations of our three queries, but a monadic computation \nof expecta\u00adtion over a product space can take time exponential in the number of dimensions in the space. \nThe rest of this paper is devoted to a di.erent abstraction: measure terms.Us\u00ading measure terms, we can \nexpose the structure of h and rewrite sums (integrals) over product spaces into products of sums, thereby \nreducing the cost of computing the expec\u00adtation of h. Measure terms de.ne measures over product spaces. \nThe simplest kind of term is a weighted formula (f: w),which is a generalization of unit mass; it assigns \na real, nonnegative weight wto a set in the product space. The set is de.ned by aformula f, which is \nsimply a predicate. The angle brack\u00adets and colon serve only to delimit the weighted formula; they have \nno semantic signi.cance. Measure terms may be multiplied and added, and we can also sum over variables. \nThe syntax of measure terms is as follows: t::= (f: w)|t1 \u00d7t2 |t1 + t2 | t x::X We write terms assuming \nthat \u00d7binds more tightly than +, and the scope of extends as far to the right as possible. Our notation \nhas one subtlety; the colons in x::X indicate that this summation symbol is syntax. When we mean sum\u00admation \nin a semantic domain, over a measurable space X, we write . x.X One reason to use measure terms is be \nable to choose the order in which we do sums. We therefore use a representa\u00adtion of product spaces in \nwhich we identify dimensions by name, not by the way they are ordered. In particular, we represent an \nn-dimensional product space as a set of pairs xi :: Xi,where xi is a name and Xi is a measurable space. \nWe represent a value in this product space by an environ\u00adment mapping names to values such that the domain \nof the environment is {xi |1 =i=n}. Every name de.ned in the environment identi.es one dimension of the \nproduct space. A measure term denotes a measure over a product space, but its denotation may depend on \ncontext, i.e., what prod\u00aduct space we are interested in. We therefore specify a product space when giving \nthe semantics of a term. By analogy with type environments, we write this product space as G= {xi :: \nXi |1 =i =n}.We write a value in the product space as .= {x1 .v1,...,xn .vn}.Fig\u00ad ure 3 gives the meanings \nof terms. The function T[[t]]G de.nes a probability-mass function on G; to get a mea\u00adsure, we integrate \nusing the counting measure. That is, T[[t]]G(A)= ..A T[[t]]G(.). The context G plays no role in the evaluation \nof T, but we need it to prove that our trans\u00adlation of stochastic lambda calculus into measure terms \nis equivalent to our translation into the probability monad. Measure terms obey useful algebraic laws: \n The term (true :1) is a unit of term product \u00d7,and (false : w)is a unit of term addition +.  Term product \n\u00d7and sum + obey associative, commuta\u00adtive, and distributive laws.  We can rename variables in sums; \nthe x in x::X is a binding instance.  We can interchange sums over di.erent variables.  We can sometimes \nmove terms outside sums, i.e., we have t1 \u00d7t2 = t1 \u00d7 t2,provided xis not free in t1.  x::Xx::X The soundness \nof these laws follows immediately from the de.nition of T. Thelawsmakeit possible toimplement variable \nelimina\u00adtion, which is a code-improving transformation that reduces work by moving products outside sums. \nA full treatment of variable elimination is beyond the scope of this paper, but we can state the idea \nbrie.y. If each of two terms t1 and t2 contains free variables that do not appear free in the other, \nthe laws enable us to convert a sum of products to a product of sums. For example, if x1 is not free \nin t2 and x2 is not free in t1,then t1 \u00d7t2 = x1::X1 x2::X2 ( t1) \u00d7( t2). The cost of computing T on x1::X1 \nx2::X2 the left-hand side is O(|X1|\u00b7|X2|), but the cost of comput\u00ading T on the right-hand side is O(|X1|+ \n|X2|). Rewriting a term to minimize the cost of computing T is an NP-hard problem, but there are heuristics \nthat work well in practice (Jensen 1996). 6.1. Measure terms for probability To represent a probability \ndistribution, we use a measure term with a distinguished free variable, arbitrarily called * (pronounced \nresult ). Figure 4 shows how to translate a term in the stochastic lambda calculus into a measure term \nwith the additional free variable *.We have left the domains of variables out of the sums; the domains \nare com\u00adputed using the support function S. Figure 4 uses two metanotations that may require explanation. \nWe write sub\u00adstitution using superscripts and subscripts; txe stands for E[[x]]. = (*= x :1) E[[v]]. \n= (*= v :1) E[[.x.e]]. = (*= .v.E[[e]].{x .{v}}:1)  '' ' E[[let x = e in e]]. =(E[[e ]].)x * \u00d7E[[e]].{x \n.S[[e ]].} x  E[[e1 e2]]. =(E[[e1]].)* xf \u00d7(E[[e2]].)xa \u00d7 * xfxa () (vf va \u00d7(xf = vf .xa = va :1))+ \n(\u00ac(xf = vf .xa = va):1) vf .S[[e1]].,va.S[[e2]]. E[[choose pe1 e2]]. =(E[[e1]]. \u00d7(true : p))+(E[[e2]]. \n\u00d7(true :1 -p)) *.1 *.2 E[[(e1,e2)]]. =(E[[e1]].) \u00d7(E[[e2]].) ** (*,xnew) E[[e.1]]. =(E[[e]].) * xnew \n (xnew,*) E[[e.2]]. =(E[[e]].) * xnew left * E[[L e]]. =(E[[e]].)* \u00d7(isLeft *:1) right * E[[R e]]. \n=(E[[e]].)* \u00d7(isRight *:1) E[[case eel er]]. = E[[either el er e]]. Here S is the support function, \nwhich gives us the set of possible values to which an expression e could evaluate; the environment . \nis used only to compute support. The variables xnew, xf ,and xa are unique, fresh variables. We notate \nsubstitution using superscripts and subscripts; txe stands for the measure term t with expression e substituted \nfor variable x. Functions either, left, right, isLeft,and isRight are prede.ned functions that support \nsum types; the name either represents a literal value, not a variable. Figure 4: Translation of stochastic \ncalculus into terms the measure term t with expression e substituted for vari-of choose: able x. In \nthe rule for application, the product symbolis t \u00d7(true : p)+ t ' \u00d7(true :1 -p)= a metalanguage symbol \nand not part of the measure-term (t \u00d7(xnew : p)+ (\u00acxnew :1))\u00d7 xnew::Bool language; it stands for a large \nmultiplication. This mul\u00ad(t ' \u00d7(\u00acxnew :1 -p)+ (xnew :1)). tiplication is a device for applying functions \nto get mea\u00ad  sure terms. If we write the multiplication as t =\u00b7\u00b7\u00b7, On the right-hand side, we now have \na chance to move other then given any record . that maps xf to vf and xa to va, sums inside . T[[t]]G(.)= \nT[[vf va]]G(.). xnew Making variable elimination work e.ectively on the re\u00ad  6.2. Equivalence of two \ntranslations sults of the translation requires two steps not shown in Fig\u00adure 4: introducing multiple \nvariables for product spaces A term in the stochastic lambda calculus denotes the same and manipulating \nthe translation of choose to keep inde-probability measure whether we compute the measure using pendent \nterms separate. the probability monad or using measure terms. This claim Because the single free variable \n* often stands for a is central to our contribution, linking up elegant techniques value in a product \nspace, we need a way to split up for de.ning languages with e.cient techniques for proba\u00adthe variable \ninto its constituent parts. The product spaces bilistic reasoning. G l{x :: X1 \u00d7X2}and G l{x1 :: X1,x2 \n:: X2}are isomor-The proof requires some technicalities associated with de\u00adphic; we take them to be equivalent, \nand we use the equality notations of functions. The problem is this: in the Ptrans\u00adT[[t]](G l{x :: X1 \n\u00d7X2})(.{x .(v1,v2)})= lation, the denotation of a lambda abstraction is made using (x1,x2) T[[tx ]](G \nl{x1 :: X1,x2 :: X2})(.{x1 v1,x2. ) a function returning a value in the probability monad; in .v2} the \nEtranslation, the denotation of a lambda abstraction is to change variables within terms. This equality \nsupports made using a function returning a measure term; to prove the following additional algebraic \nlaw:them equivalent, we need to reason about functions return\u00ad  (x1,x2) ing probability measures. We \ntherefore have three di.erent t =tx . spaces of values, which we call M (monadic) space, T (term) xx1x2 \nspace, and V (value) space. To show the two translations In the translation of choose shown in Figure \n4, terms are equivalent, we need to be able to map both M space E[[e1]]. and E[[e2]]. are combined using \naddition. As a con-and T space into V space. sequence, even if each of the terms contains free variables \nWe de.ne the mappings we need using a type-indexed not found in the other, we will not be able to move \nthe family of transformations we call lift.If v is an atomic, addition outside sums over those free variables. \nIn our im-zero-order value (integer, string, etc), then lift F v = v. plementation, we apply the following \nlaw to the translation If v is a pair, then lift F (v1,v2)=(lift F v1, lift F v2), and similarly for \nsum types. Finally, if v is a function, we de.ne lift such that (lift F v)(lift F v ' )= F(vv ' ). The \nlift transformation is closely related to the reify transformation used in type-directed partial evaluation \n(Danvy 1996). Having de.ned lift, we extend it to expressions, formulas, and environments by saying that \nlift F e is the expression obtained by replacing all literal values in e with their lifted forms, and \nsimilarly for formulas and environments. In par\u00adticular, when .x.e is syntax, lift F (.x.e)= .x.lift \nF e. Finally, we have to adjust the de.nitions of M and T . { 1, if x = lift M v M[[return v]](x)= 0, \nif x =.lift M v M[[d>>= k]](x)= v M[[d]](lift M v) \u00b7M[[k(v)]](x) T [[(f : w)]]G(.)= w \u00b7 sat(lift T f, \n.) With the new de.nitions, a lambda term e that is trans\u00adlated via the probability monad has literal \nvalues that live in M space, a lambda term that is translated via measure terms has literal values that \nlive in T space, but the denota\u00adtions of both are probability measures that apply to values in V space. \nWith lift,wehave the machineryweneed to statethat the two translations are equivalent. The proof is by \nstruc\u00adtural induction on lambda terms, and the induction hy\u00adpothesis is that if em and et are two lambda \nterms such that lift M em = lift T et,then M(P[[em]].)(v)= T (E[[et]].)(G. l{* :: Y })((lift M .){* . \nv}) where G. gives the names and types of variables in the domain of .,and Y is thetypeof e (and also \nthe measurable space from which v is drawn). It follows that if e is a lambda term in which the only \nliterals are zero-order literals such as integers, we can translate it either way and get the same probability \ndistribution. A lemma that applies frequently to the proof is that adding variables to the environment \nof a term doesn t matter: T [[t]]G(.)= T [[t]](G .{y})(.{y . v}) provided y does not appear in G, in \nthe domain of .,or free in t. In this lemma, v is arbitrary.  6.3. Expectation Using measure terms, \nwe can speed up the computation of the expectation of a function h, provided we expose the structure \nof h to the variable-elimination algorithm. Our implementation doesn t compute expectations of general \nfunctions expressed in lambda terms; it computes expec\u00adtations only of functions that can be expressed \nin the form h(v)= w1 \u00b7 sat(f1, {* . v})+ \u00b7\u00b7\u00b7 + wn \u00b7 sat(fn, {* . v}). For such a function, we de.ne expectation \n' ht = T [[ ((f1 : w1) + \u00b7\u00b7\u00b7 + (fn : wn))]]{}{}.Using the equiv\u00ad * alence of the previous section, it \nis not hard to show that for a suitable closed lambda-term e, expectation ' h (E[[e]]{})= expectation \nh (P[[e]]{}). Using variable elimination on the left-hand side can produce exponential speedups for some \nfunctions h.  7. Related work Monads are used both in the study of language features and in the implementation \nof programming languages; Wadler (1992) introduces and motivates the topic. Mon\u00adads come to us from category \ntheory, and category theorists have long been aware of the monadic structure of probabil\u00adity (Lawvere \n1962; Giry 1981). The support and sampling monads are also well known in the programming commu\u00adnity, \nespecially the support monad, because it describes nondeterministic choice. It appears that the expectation \nmonad is not well known, perhaps because of its inherent ine.ciency. A tool called QuickCheck uses the \nsampling monad to generate random values for testing functional programs (Claessen and Hughes 2000). \nQuickCheck s probabilistic\u00adchoice operator, although also called choose,is somewhat di.erent from ours; \nit produces an integer distributed uni\u00adformly over a speci.ed range. Either version of choose can be \nsimulated using the other. QuickCheck also provides a frequency function, which is analogous to dist. \nClaessen and Hughes (2000) also presents generator transformers, which use existing generators to build \nnew ones in ways that cannot be done using monadic bind alone. It is not obvious how the idea relates \nto the general probability monad. Substantial e.ort has been devoted to developing Scott\u00adstyle domain \ntheory that could help specify semantics of probabilistic languages. Saheb-Djahromi (1980) shows the \ncomplete-partial-order structure of probability distri\u00adbutions on a domain. Jones and Plotkin (1989) \nuses eval\u00aduations rather than measures to build probabilistic pow\u00aderdomains. Jones s (1990) doctoral \nthesis is slightly more accessible to the amateur; Section 1.4 provides a brief guide to the literature. \nIt would be pleasant to extend our calculus with recur\u00adsive functions, recursion equations, or a .xed-point \noper\u00adator, but to give a careful semantics to such an extended calculus would require domain theory, \ncategory theory, and analysis that are beyond the scope of this paper. The par\u00adticularly sticky bits \nhave to do with permitting probability distributions over functions, which we wish to do in our models. \nWe have identi.ed two related languages that sup\u00adport recursion. Saheb-Djahromi (1978) presents a probabilistic \nversion of LCF, in which expressions of base types (integer or Boolean) denote probability distributions \nbut expressions of function type denote functions, not distributions over functions. The language includes \nboth call-by-name and call-by-value abstraction constructs; only values of base types may be passed to \ncall-by-value functions. The pa\u00adper presents both denotational and operational semantics and shows them \nequivalent. Jones (1990), Chapter 8 presents a call-by-value language that is much closer to ours. The \nmajor distinctions are that the language includes a .xed-point operator and that it has not one but two \nsyntactic categories: expressions and function expressions. Expressions denote probability distri\u00adbutions; \nfunction expressions denote functions from values to probability distributions. The syntax is structured \nsuch that only function expressions can be applied, and the .xed\u00adpoint operator can be applied only to \nfunction expressions, not to ordinary expressions. Using syntax whose meaning corresponds to the monadic \nunit operation, every function expression can be made into an ordinary expression, but there is no reverse \npath. Thus, although the language does support recursive functions, it is not possible to apply a function \nthat is stored in a tuple or passed as an argument. The thesis presents both denotational and operational \nse\u00admantics for the language and shows them equivalent. To avoid di.culties with product spaces, the denotational \nse\u00admantics uses evaluations, not measures, to represent prob\u00adability distributions. Modulo this di.erence \nand our omis\u00adsion of recursive functions, the denotational semantics ap\u00adpears to be isomorphic to ours. \nBenveniste et al. (1995) and Gupta, Jagadeesan, and Panangaden (1999) discuss languages for the description \nof concurrent probabilistic systems. Their work di.ers in .avor from ours, since it combines the probabilistic \nspeci.\u00adcation of stochastic behavior with unquanti.ed, constraint\u00adbased non-determinism. As a result, \na program may or may not de.ne a single probability distribution. In our language, there is only probabilistic \nnon-determinism, and a program de.nes a unique probability measure. There is a signi.cant body of work \navailable on vari\u00adable elimination. Pearl (1988) popularized graphical mod\u00adels, including Bayesian networks, \nas well as the polytree reasoning algorithm. Commercial reasoning systems com\u00admonly use the junction-tree \nalgorithm of Lauritzen and Spiegelhalter (1988). Zhang and Poole (1994) describes a variable-elimination \nalgorithm for Bayesian networks; Li and d Ambrosio (1994) presents an algebraic variation. Dechter (1996) \nshows that the polytree and junction-tree algorithms are also forms of variable elimination, and that \nthe variable-elimination framework unites probabilistic rea\u00adsoning with a variety of other tasks such \nas constraint sat\u00adisfaction. Arnborg (1985) lays the graph-theoretic founda\u00adtions for variable elimination. \nMost implementations of variable elimination seem to be based on more specialized representations than \nwe use. For example, the basic unit of representation may be a table that corresponds to a measure term \nof the form n (.mj=1pj = vij : wi),where p is a path x.k1.k2 ...kn i=1and vij is a value or don t care. \nThe generality of mea\u00adsure terms signi.cantly simpli.es the implementation, and it appears not to impose \nunacceptable e.ciency costs. Learning algorithms that use variable elimination often combine it with \nmemoization (frequently called caching in the probabilistic-reasoning literature). We believe that we \ncan achieve similar performance gains, without introduc\u00ading mutable state into an implementation, by \nintroducing let-binding for measure terms and by using hash-consing to implement common-subexpression \nelimination. Other researchers in probabilistic modeling have used languages that resemble our stochastic \nlambda calculus. Koller, McAllester, and Pfe.er (1997) presents a simple Lisp-like language with a coin-toss \nfunction, giving it an op\u00aderational semantics based on sampling experiments. Mug\u00adgleton (2001) presents \na similar extension to logic programs. Luger and Pless (2001) proposes using a stochastic lambda calculus, \nwith a traditional reduction semantics, as a foun\u00addation for probabilistic-modeling languages. Lambda \nterms are reduced to sets of (value, probability) pairs, and ad\u00additional rules are needed to distribute \nfunction applica\u00adtion over these sets; in our framework, the monadic bind solves this problem. The paper \nargues that deBruijn in\u00addices should make it easy to identify equal values and to support memoization. \n 8. Discussion We have elucidated connections between the measure\u00adtheoretic basis of probability, monadic \ntechniques for de\u00adscribing programming languages, and variable-elimination techniques used for e.cient \nprobabilistic reasoning. Using a monad to describe the stochastic lambda calculus is not only entertaining \nit reduces proof obligations. For exam\u00adple, given our theorems about the various probability mon\u00adads, \nwe can take any probabilistic language, translate it into the probability monad, and be sure sampling \nis consistent with expectation. Using a monad enables us to separate the structure of our semantic domain \nfrom the details of any particular probabilistic language. It is not clear whether we can retain these \nadvantages and also exploit the greater e.ciency of measure terms. We can create an instance of the probability \nmonad that produces measure terms, but the cost of the obvious algo\u00adrithm is proportional to the size \nof the product space. The open question is whether we can create an instance of the probability monad \nthat produces measure terms at a cost no greater than the cost of evaluating those terms after variable \nelimination. Techniques inspired by type-directed partial evaluation, which can produce abstract syntax \nfor native functions, might solve this problem (Danvy 1996). Another challenge is to add recursion to \nour calculus. From the point of view of the probability monad, this would appear to present few di.culties. \nSuppose we wish to de\u00ad.ne a recursive function f = .x.e,where both f and x appear free in e. The key \nis that when we consider the meaning of e, f must stand for a function, not a probability distribution \nover functions. It would therefore be di.cult to use the classical style or .xed-point combinator. It \nis easy, however, to use a style that takes .xed points only of syntactic lambda abstractions; we write \n.x fxe,with P[[.x fxe]]. = .x(.w..v.P[[e]].{f . w, x . v},where 8 .x (g)= i=0 g(i)(.). Generalizing such \na construct to mu\u00adtually recursive functions is straightforward (Appel 1992). Jones (1990) explains why \nthe .xed point exists. Unfortunately it is not clear what to do with recursive functions in the measure-term \ntranslation. Since it is not practical to build and evaluate in.nite measure terms, some sort of approximation \nis necessary. Pfe.er and Koller (2000) presents an approximation technique over probabilistic re\u00adlational \nknowledge bases, which can be expressed as in.\u00adnite measure terms. It remains to be seen how to extend \nsuch techniques to arbitrary measure terms and how to ap\u00adproximate expressions involving higher-order \nand recursive functions that produce measure terms. Although our presentation of the probability monad \nis general, as are our laws for sample and expectation,much of the work in this paper is focused on discrete \ndistribu\u00adtions with .nite support. The moment we introduce recur\u00adsive functions, however, we can use \nthe probability monad to de.ne distributions with uncountable support. For ex\u00adample, there are uncountably \nmany in.nite sequences of tosses of a fair coin. If we have a lazy variant of a stochas\u00adtic lambda calculus, \nor if we embed the probability monad in Haskell, it is perfectly reasonable to write functions that produce \nin.nite data structures and to make queries over them. Queries that depend only on .nite sub-structures \n(e.g., the the probability that the .rst ten tosses of a coin come out heads) should be computable in \n.nite time us\u00ading lazy evaluation. We would like to extend our monadic implementation to incorporate \nsuch in.nite models and to answer such queries e.ectively. The natural measurable space over which such \nqueries would make sense should be the Borel sets of the Scott topology. In the long term, we would like \nto explore Bayesian learn\u00ading in a monadic framework. In the Bayesian paradigm, the parameters p passed \nto choose are not known exactly, but are themselves de.ned only by a probability distribution. A Bayesian \nexperiment consists of a model, a prior distri\u00adbution over parameters p, and a set of observations; the \nresult is a posterior distribution over the parameters. For example, we could use Bayesian experiments \nto estimate the probability that an aggressive driver runs a red light. To incorporate the Bayesian approach \ninto our monadic frame\u00adwork, we would need to make the parameter p an expres\u00adsion, not a value. Such \nan extension might provide a useful declarative foundation for an active area of machine learn\u00ading. \n Acknowledgments Simon Peyton Jones helped unstick our discussions of mea\u00adsure terms and variable elimination. \nBob Muller helped us work out lift and guided us through the thickets of do\u00admain theory. We enjoyed many \nstimulating discussions with members of the CS 252 seminar, especially Chung-chieh Shan and Dylan Thurston. \nJon Eddy, Simon Peyton Jones, and Chung-chieh Shan provided helpful comments on the manuscript. The anonymous \nreferees not only directed us to useful related work but also made suggestions that helped us improve \nthe paper signi.cantly. This work was supported by NSF grant CCR-0096069, by an Alfred P. Sloan Research \nFellowship, and by Harvard University. References Appel, Andrew W. 1992. Compiling with Continuations. \nCambridge: Cambridge University Press. Arnborg, Stefan. 1985. E.cient algorithms for combinato\u00adrial problems \non graphs with bounded decomposability. BIT, 25(1):2 23. Benveniste, Albert, Bernard C. Levy, Eric Fabre, \nand Paul Le Guernic. 1995. A calculus of stochastic systems for the speci.cation, simulation, and hidden \nstate estima\u00adtion of mixed stochastic/nonstochastic systems. Theo\u00adretical Computer Science, 152(2):171 \n217. Charniak, Eugene. 1993. Statistical Language Learning. MIT Press. Claessen, Koen and John Hughes. \n2000 (September). QuickCheck: a lightweight tool for random test\u00ading of Haskell programs. Proceedings \nof the Fifth ACM SIGPLAN International Conference on Func\u00adtional Programming (ICFP 00), in SIGPLAN Notices, \n35(9):268 279. Danvy, Olivier. 1996. Type-directed partial evaluation. In Conference Record of the 23rd \nAnnual ACM Sympo\u00adsium on Principles of Programming Languages, pages 242 257, New York, NY. Dechter, Rina. \n1996 (August). Bucket elimination: A uni\u00adfying framework for probabilistic inference. In Proceed\u00adings \nof the 12th Conference on Uncertainty in Arti.cial Intelligence (UAI-96), pages 211 219, San Francisco. \nGiry, Mich`ele. 1981. A categorical approach to probability theory. In Banaschewski, Bernhard, editor, \nCategorical Aspects of Topology and Analysis, Vol. 915 of Lecture Notes In Mathematics, pages 68 85. \nSpringer Verlag. Gupta, Vineet, Radha Jagadeesan, and Prakash Panan\u00adgaden. 1999 (January). Stochastic \nprocesses as concur\u00adrent constraint programs. In Conference Record of the 26th Annual ACM Symposium on \nPrinciples of Pro\u00adgramming Languages, pages 189 202. Hughes, John. 1989 (April). Why functional programming \nmatters. The Computer Journal, 32(2):98 107. . 1995. The design of a pretty-printing library. In Jeuring, \nJohan and Erik Meijer, editors, Advanced Functional Programming, Vol. 925 of Lecture Notes in Computer \nScience. Springer Verlag. Jaakkola, Tommi S. and Michael I. Jordan. 1999. Varia\u00adtional probabilistic \ninference and the QMR-DT net\u00adwork. Journal of Arti.cial Intelligence Research, 10:291 322. Jensen, Finn \nV. 1996. An Introduction to Bayesian Net\u00adworks. New York: Springer. Jones, Claire. 1990 (July). Probabilistic \nNon-determinism. PhD thesis, Department of Computer Science, Univer\u00adsity of Edinburgh. Also Laboratory \nfor the Foundations of Computer Science technical report ECS-LFCS-90\u00ad 105. Available online. Jones, Claire \nand Gordon D. Plotkin. 1989. A probabilis\u00adtic powerdomain of evaluations. In Proceedings of the Fourth \nAnnual IEEE Symposium On Logic In Com\u00adputer Science, pages 186 195. Jordan, Michael I., editor. 1998. \nLearning in Graphical Models.Kluwer. Koller, Daphne, David McAllester, and Avi Pfe.er. 1997. E.ective \nBayesian inference for stochastic programs. In Fourteenth National Conference on Arti.cial Intel\u00adligence \n(AAAI), pages 740 747. Lauritzen, Ste.en L. and David J. Spiegelhalter. 1988. Lo\u00adcal computations with \nprobabilities on graphical struc\u00adtures and their application to expert systems. Journal of the Royal \nStatistical Society, pages 157 224. Lawvere, F. William. 1962. The category of probabilistic mappings. \nUnpublished. Li, Zhaoyu and Bruce d Ambrosio. 1994. E.cient inference in Bayes nets as a combinatorial \noptimization prob\u00adlem. International Journal of Approximate Reasoning, 11(1):55 81. Luger, George and \nDan Pless. 2001. A stochastic .-calculus. Technical Report TR-CS-2001-04, Depart\u00adment of Computer Science, \nUniversity of New Mexico. Mahoney, Suzanne M. and Kathryn Blackmond Laskey. 1998 (July). Constructing \nsituation speci.c belief net\u00ad works. In Proceedings of the 14th Conference on Uncer\u00adtainty in Arti.cial \nIntelligence (UAI-98), pages 370 378. Morgan Kaufmann. Muggleton, Stephen. 2001. Stochastic logic programs. \nJour\u00ad nal of Logic Programming. Accepted subject to revi\u00adsion. Pearl, Judea. 1988. Probabilistic Reasoning \nin Intelligent Systems: Networks of Plausible Inference. San Mateo, CA: Morgan Kaufmann. Pfe.er, Avi. \n2001 (August). IBAL: A probabilistic ratio\u00adnal programming language. In Seventeenth Interna\u00adtional Joint \nConference on Arti.cial Intelligence (IJ-CAI), pages 733 740, Seattle. Pfe.er, Avi and Daphne Koller. \n2000 (July). Semantics and inference for recursive probability models. In Pro\u00adceedings of the 7th Conference \non Arti.cial Intelligence (AAAI-00), pages 538 544, Menlo Park, CA. Ramsey, Norman. 1994 (September). \nLiterate programming simpli.ed. IEEE Software, 11(5):97 105. Rudin, Walter. 1974. Real and Complex Analysis.Series \nin Higher Mathematics. Second edition. New York: McGraw-Hill. Saheb-Djahromi, N. 1978 (September). Probabilistic \nLCF. In Winkowski, J\u00b4ozef, editor, Proceedings of the 7th Symposium on Mathematical Foundations of Computer \nScience,Vol. 64of Lecture Notes in Computer Science, pages 442 451. Springer. . 1980 (September). CPO \ns of measures for nondeter\u00adminism. Theoretical Computer Science, 12(1):19 37. Smyth, Michael B. 1983 \n(July). Power domains and predi\u00adcate transformers: A topological view. In D\u00b4iaz, Josep, editor, Automata, \nLanguages and Programming, 10th Colloquium (ICALP-83), Vol. 154 of Lecture Notes in Computer Science, \npages 662 675, Barcelona, Spain. Wadler, Philip. 1992 (January). The essence of functional programming \n(invited talk). In Conference Record of the 19th Annual ACM Symposium on Principles of Programming Languages, \npages 1 14. New York, NY: ACM Press. Witten, IanH., RadfordM.Neal, andJohnG.Cleary. 1987 (June). Arithmetic \ncoding for data compression. Communications of the ACM, 30(6):520 540. Zhang, Nevin L. and David Poole. \n1994. A simple approach to Bayesian network computations. In Tenth Biennial Canadian Arti.cial Intelligence \nConference. A. Implementations of probability monads These implementations are derived from the algebraic \nlaws in Section 5, using techniques explained by Hughes (1989). This paper was prepared using the Noweb \nsystem for lit\u00aderate programming (Ramsey 1994), and all the Haskell code in the paper has been automatically \nextracted and run through the Glasgow Haskell Compiler, version 4.06. The support monad In the support \nmonad, we repre\u00adsent a distribution by a list of values it could contain. (probability monads)+= newtype \nSupport a = Support [a] instance Monad Support where return x = Support [x] (Support l) >>= k = Support \n(concat [s | x <-l, let Support s = k x]) instance ProbabilityMonad Support where choose _ (Support l) \n(Support l ) = Support (l ++ l ) instance SupportMonad Support where support (Support l) = l The expectation \nmonad We represent the expectation monad by a function that computes expectation directly. (probability \nmonads)+= newtype Expa=Exp ((a -> Double) -> Double) instance Monad Exp where return x= Exp (\\h -> hx) \n(Expd)>>=k= Exp (\\h -> let apply (Exp f) arg = f arg gx =apply (k x) h in dg) instance ProbabilityMonad \nExp where choose p (Exp d1) (Exp d2) = Exp (\\h -> p *d1 h +(1-p) * d2 h) instance ExpMonad Exp where \nexpectation h (Exp d) = d h The sampling monad Again, we represent the sampling monad as a suitable function. \n(probability monads)+= newtype Sample a = Sample (RandomGen g => g -> (a, g)) instance Monad Sample where \nreturn x = Sample (\\ g -> (x, g)) (Sample s) >>= k = Sample(\\ g->let(a,g ) =sg Sample s = ka in s g ) \ninstance ProbabilityMonad Sample where choose p (Sample s1) (Sample s2) = Sample (\\g -> let (x, g ) = \nRandom.random g in (ifx<p thens1elses2)g ) instance SamplingMonad Sample where sample (Sample s) g = \ns g  \n\t\t\t", "proc_id": "503272", "abstract": "Probability distributions are useful for expressing the meanings of probabilistic languages, which support formal modeling of and reasoning about uncertainty. Probability distributions form a monad, and the monadic definition leads to a simple, natural semantics for a stochastic lambda calculus, as well as simple, clean implementations of common queries. But the monadic implementation of the <i>expectation</i> query can be much less efficient than current best practices in probabilistic modeling. We therefore present a language of <i>measure terms</i>, which can not only denote discrete probability distributions but can also support the best known modeling techniques. We give a translation of stochastic lambda calculus into measure terms. Whether one translates into the probability monad or into measure terms, the results of the translations denote the same probability distribution.", "authors": [{"name": "Norman Ramsey", "author_profile_id": "81100300481", "affiliation": "Harvard University", "person_id": "PP14110628", "email_address": "", "orcid_id": ""}, {"name": "Avi Pfeffer", "author_profile_id": "81100218791", "affiliation": "Harvard University", "person_id": "P23127", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/503272.503288", "year": "2002", "article_id": "503288", "conference": "POPL", "title": "Stochastic lambda calculus and monads of probability distributions", "url": "http://dl.acm.org/citation.cfm?id=503288"}