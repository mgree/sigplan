{"article_publication_date": "01-01-2002", "fulltext": "\n A Type System for Certi.ed Binaries* Zhong Shao Bratin Saha Valery Trifonov Nikolaos Papaspyrou Department \nof Computer Science, Yale University New Haven, CT 06520-8285, U.S.A. {shao, saha, trifonov, nickie}@cs.yale.edu \n Abstract A certi.ed binary is a value together with a proof that the value satis.es a given speci.cation. \nExisting compilers that generate cer\u00adti.ed code have focused on simple memory and control-.ow safety \nrather than more advanced properties. In this paper, we present a general framework for explicitly representing \ncomplex proposi\u00adtions and proofs in typed intermediate and assembly languages. The new framework allows \nus to reason about certi.ed programs that involve effects while still maintaining decidable typechecking. \nWe show how to integrate an entire proof system (the calculus of inductive constructions) into a compiler \nintermediate language and how the intermediate language can undergo complex transforma\u00adtions (CPS and \nclosure conversion) while preserving proofs rep\u00adresented in the type system. Our work provides a foundation \nfor the process of automatically generating certi.ed binaries in a type\u00adtheoretic framework. 1 Introduction \nProof-carrying code (PCC), as pioneered by Necula and Lee [30, 28], allows a code producer to provide \na machine-language pro\u00adgram to a host, along with a formal proof of its safety. The proof can be mechanically \nchecked by the host; the producer need not be trusted because a valid proof is incontrovertible evidence \nof safety. The PCC framework is general because it can be applied to cer\u00adtify arbitrary data objects \nwith complex speci.cations [29, 2]. For example, the Foundational PCC system [3] can certify any property \nexpressible in Church s higher-order logic. Harper et al. [19, 7] call all these proof-carrying constructs \ncerti.ed binaries (or deliv\u00aderables [7]). A certi.ed binary is a value (which can be a function, a data \nstructure, or a combination of both) together with a proof that the value satis.es a given speci.cation. \nUnfortunately, little is known on how to construct or generate certi.ed binaries. Existing certifying \ncompilers [31, 9] have fo\u00adcused on simple memory and control-.ow safety only. Typed inter\u00admediate languages \n[21] and typed assembly languages [27] are ef\u00adfective techniques for automatically generating certi.ed \ncode; how\u00ad *This research is based on work supported in part by DARPA OASIS grant F30602\u00ad99-1-0519, NSF \ngrant CCR-9901011, and NSF ITR grant CCR-0081590. Any opin\u00adions, .ndings, and conclusions contained in \nthis document are those of the authors and do not re.ect the views of these agencies. Permission to make \ndigital or hard copies of all or part of this work for per\u00adsonal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to re\u00adpublish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 02, Jan. 16-18, \n2002 Portland, OR, USA c . 2002 ACM ISBN 1-58113-450-9/02/01...$5.00 ever, none of these type systems \ncan rival the expressiveness of the actual higher-order logic as used in some PCC systems [3]. In this \npaper, we present a type-theoretic framework for con\u00adstructing, composing, and reasoning about certi.ed \nbinaries. Our plan is to use the formulae-as-types principle [23] to represent propositions and proofs \nin a general type system, and then to in\u00advestigate their relationship with compiler intermediate and \nassem\u00adbly languages. We show how to integrate an entire proof system (the calculus of inductive constructions \n[34, 11]) into an intermedi\u00adate language, and how to de.ne complex transformations (CPS and closure conversion) \nof programs in this language so that they pre\u00adserve proofs represented in the type system. Our paper \nbuilds upon a large body of previous work in the logic and theorem-proving community (see Barendregt \net al. [5, 4] for a good summary), and makes the following new contributions: We show how to design \nnew typed intermediate languages that are capable of representing and manipulating proposi\u00adtions and \nproofs. In particular, we show how to maintain decidability of typechecking when reasoning about certi.ed \nprograms that involve effects. This is different from the work done in the logic community which focuses \non strongly nor\u00admalizing (primitive recursive) programs.  We maintain a phase distinction between compile-time \ntype\u00adchecking and run-time evaluation. This property is often lost in the presence of dependent types \n(which are necessary for representing proofs in predicate logic). We achieve this by never having the \ntype language (see Section 3) dependent on the computation language (see Section 4). Proofs are instead \nalways represented at the type level using dependent kinds.  We show how to use propositions to express \nprogram invari\u00adants and how to use proofs to serve as static capabilities. Fol\u00adlowing Xi and Pfenning \n[44], we use singleton types [22] to support the necessary interaction between the type and computation \nlanguages. We can assign an accurate type to unchecked vector (or array) access (see Section 4.2). Xi \nand Pfenning [44] can achieve the same using constraint check\u00ading, but their system does not support \narbitrary propositions and (explicit) proofs, so it is less general than ours.  We use a single type \nlanguage to typecheck different com\u00adpiler intermediate languages. This is crucial because it is im\u00adpractical \nto have separate proof libraries for each intermedi\u00adate language. We achieve this by using inductive \nde.nitions to de.ne all types used to classify computation terms. This in turn nicely .ts our work on \n(fully re.exive) intensional type analysis [39] into a single system.  We show how to perform CPS and \nclosure conversion on our intermediate languages while still preserving proofs repre\u00ad  sented in the \ntype system. Existing algorithms [27, 20, 25, 6] all require that the transformation be performed on \nthe entire type language. This is impractical because proofs are large in size; transforming them can \nalter their meanings and break the sharing among different languages. We present new tech\u00adniques that \ncompletely solve these problems (Sections 5 6). Our type language is a variant of the calculus of inductive \nconstructions [34, 11]. Following Werner [41], we give rig\u00adorous proofs for its meta-theoretic properties \n(subject reduc\u00adtion, strong normalization, con.uence, and consistency of the underlying logic). We also \ngive the soundness proof for our sample computation language. See Sections 3 4, the ap\u00adpendix, and the \ncompanion technical report [37] for details. As far as we know, our work is the .rst comprehensive study \non how to incorporate higher-order predicate logic (with inductive terms and predicates) into typed intermediate \nlanguages. Our re\u00adsults are signi.cant because they open up many new exciting pos\u00adsibilities in the area \nof type-based language design and compila\u00adtion. The fact that we can internalize a very expressive logic \ninto our type system means that formal reasoning traditionally done at the meta level can now be expressed \ninside the actual language it\u00adself. For example, much of the past work on program veri.cation using Hoare-like \nlogics may now be captured and made explicit in a typed intermediate language. From the standpoint of \ntype-based language design, recent work [21, 44, 13, 15, 40, 39] has produced many specialized, increasingly \ncomplex type systems, each with its own meta\u00adtheoretical proofs, yet it is unclear how they will .t together. \nWe can hope to replace them with one very general type system whose meta theory is proved once and for \nall, and that allows the de.nition of specialized type operators via the general mechanism of induc\u00adtive \nde.nitions. For example, inductive de.nitions subsume and generalize earlier systems on intensional type \nanalysis [21, 14, 39]. We have started implementing our new type system in the FLINT compiler [35, 36], \nbut making the implementation realis\u00adtic still involves solving many remaining problems (e.g., ef.cient \nproof representations). Nevertheless, we believe our current contri\u00adbutions constitute a signi.cant step \ntoward the goal of providing a practical end-to-end compiler that generates certi.ed binaries. 2 Approach \nOur main objectives are to design typed intermediate and low-level languages that can directly manipulate \npropositions and proofs, and then to use them to certify realistic programs. We want our type system \nto be simple but general; we also want to support complex transformations (CPS and closure conversion) \nthat preserve proofs represented in the type system. In this section, we describe the main challenges \ninvolved in achieving these goals and give a high-level overview of our main techniques. Before diving \ninto the details, we .rst establish a few naming conventions that we will use in the rest of this paper. \nTyped inter\u00admediate languages are usually structured in the same way as typed .-calculi. Figure 1 gives \na fragment of a richly typed .-calculus, organized into four levels: kind schema (kscm) u, kind ., type \nt, and expression (exp) e. If we ignore kind schema and other exten\u00adsions, this is just the polymorphic \n.-calculus F. [18]. We divide each typed intermediate language into a type sub\u00adlanguage and a computation \nsub-language. The type language con\u00adtains the top three levels. Kind schemas classify kind terms while \nkinds classify type terms. We often say that a kind term . has kind schema u, or a type term t has kind \n.. We assume all kinds used to classify type terms have kind schema Kind, and all types used to classify \nexpressions have kind .. Both the function type t1 .t2 THE TYPE LANGUAGE: (kscm) u ::= Kind |... (kind) \n. ::= .1 ..2 |. |... (type) t ::= t |.t: .. t |t1 t2 |t1 .t2 |.t: .. t |... THE COMPUTATION LANGUAGE: \n(exp) e ::= x |.x: t.e |e1 e2 |.t: ..e |e[t] |... Figure 1: Typed .-calculi a skeleton and the polymorphic \ntype .t : .. t have kind .. Following the tradition, we sometimes say a kind . to imply that . has kind \nschema Kind, a type t to imply that t has kind ., and a type constructor t to imply that t has kind ..\u00b7\u00b7\u00b7... \nKind terms with other kind schemas, or type terms with other kinds are strictly referred to as kind terms \nor type terms. The computation language contains just the lowest level which is where we write the actual \nprogram. This language will eventu\u00adally be compiled into machine code. We often use names such as computation \nterms, computation values, and computation functions to refer to various constructs at this level. 2.1 \nRepresenting propositions and proofs The .rst step is to represent propositions and proofs for a particular \nlogic in a type-theoretic setting. The most established technique is to use the formulae-as-types principle \n(a.k.a. the Curry-Howard correspondence) [23] to map propositions and proofs into a typed .-calculus. \nThe essential idea, which is inspired by constructive logic, is to use types (of kind .) to represent \npropositions, and expressions to represent proofs. A proof of an implication P .Q is a function object \nthat yields a proof of proposition Q when applied to a proof of proposition P. A proof of a conjunction \nP .Q is a pair (e1,e2) such that e1 is a proof of P and e2 is a proof of Q.A proof of disjunction P .Q \nis a pair (b, e) a tagged union where b is either 0 or 1 and if b=0, then e is a proof of P;if b=1 then \ne is a proof of Q. There is no proof for the false proposition. A proof of a universally quanti.ed proposition \n.x.B.P(x) is a function that maps every element b of the domain B into a proof of P(b) where P is a unary \npredicate on elements of B. Finally, a proof of an existentially quanti.ed proposition .x.B.P(x) is a \npair (b, e) where b is an element of B and e is a proof of P(b). Proof-checking in the logic now becomes \ntypechecking in the corresponding typed .-calculus. There has been a large body of work done along this \nline in the last 30 years; most type-based proof assistants are based on this fundamental principle. \nBaren\u00addregt et al. [5, 4] give a good survey on previous work in this area. 2.2 Representing certi.ed \nbinaries Under the type-theoretic setting, a certi.ed binary S is just a pair (v, e) that consists of: \n a value v of type t where v could be a function, a data struc\u00adture, or any combination of both;  and \na proof e of P(v) where P is a unary predicate on ele\u00adments of type t.  Here e is just an expression \nwith type P(v). The predicate P is a dependent type constructor with kind t ... The entire package S \nhas a dependent strong-sum type Sx: t.P(x). For example, suppose Nat is the domain for natural numbers \nand Prime is a unary predicate that asserts an element of Nat as a prime number, we introduce a type \nnat representing Nat, and a type constructor prime (of kind nat..) representing Prime.We can build a \ncerti.ed prime-number package by pairing a value v (a natural number) with a proof for the proposition \nprime(v); the resulting certi.ed binary has type Sx : nat. prime(x). Function values can be certi.ed \nin the same way. Given a func\u00adtion f that takes a natural number and returns another one as the result \n(i.e., f has type nat . nat), in order to show that f always maps a prime to another prime, we need a \nproof for the following proposition: .x.Nat. Prime(x) . Prime(f(x)) In a typed setting, this universally \nquanti.ed proposition is repre\u00adsented as a dependent product type: .x : nat. prime(x) . prime(f(x)) The \nresulting certi.ed binary has type Sf : nat . nat. .x : nat. prime(x) . prime(f(x)) Here the type is \nnot only dependent on values but also on function applications such as f(x), so verifying a certi.ed \nbinary involves typechecking the proof which in turn requires evaluating the under\u00adlying function application. \n 2.3 The problems with dependent types The above scheme unfortunately fails to work in the context of \ntyped intermediate (or assembly) languages. There are at least four problems with dependent types; the \nthird and fourth are present even in the general context. First, real programs often involve effects \nsuch as assignment, I/O, or non-termination. Effects interact badly with dependent types. In our previous \nexample, suppose the function f does not ter\u00adminate on certain inputs; then clearly, typechecking which \ncould involve applying f would become undecidable. It is possible to use the effect discipline [38] to \nforce types to be dependent on pure computation only, but this does not work in some typed .-calculi; \nfor example, a pure term in Girard s .U [18] could still diverge. Even if applying f does not involve \nany effects, we still have more serious problems. In a type-preserving compiler, the body of the function \nf has to be compiled down to typed low-level lan\u00adguages. A few compilers perform typed CPS conversion \n[27], but in the presence of dependent types, this is a very dif.cult prob\u00adlem [6]. Also, typechecking \nin low-level languages would now re\u00adquire performing the equivalent of \u00df-reductions on the low-level \n(assembly) code; this is awkward and dif.cult to support cleanly. Third, it is important to maintain \na phase distinction between compile-time typechecking and run-time evaluation. Having de\u00adpendent strong-sum \nand dependent product types makes it harder to preserve this property. It is also dif.cult to support \n.rst-class certi.ed binaries. Finally, it would be nice to support a notion of subset types [10, 32]. \nA certi.ed binary of type Sx : nat. prime(x) contains a natural number v and a proof that v is a prime. \nHowever, in some cases, we just want v to belong to a subset type {x : nat | prime(x)}, i.e., v is a \nprime number but the proof of this is not together with v; instead, it can be constructed from the current \ncontext. 2.4 Separating the type and computation languages We solve these problems by making sure that \nour type language is never dependent on the computation language. Because the actual computation term \nhas to be compiled down to assembly code in any case, it is a bad idea to treat it as part of types. \nThis separation immediately gives us back the phase-distinction property. To represent propositions and \nproofs, we lift everything one level up: we use kinds to represent propositions, and type terms for proofs. \nThe domain Nat is represented by a kind Nat; the predicate Prime is represented by a dependent kind term \nPrime which maps a type term of kind Nat into a proposition. A proof for proposition Prime(n) certi.es \nthat the type term n is a prime number. To maintain decidable typechecking, we insist that the type lan\u00adguage \nis strongly normalizing and free of side effects. This is pos\u00adsible because the type language no longer \ndepends on any runtime computation. Given a type-level function g of kind Nat.Nat,we can certify that \nit always maps a prime to another prime by build\u00ading a proof tp for the following proposition, now represented \nas a dependent product kind: .t : Nat.Prime(t) .Prime(g(t)). Essentially, we circumvent the problems \nwith dependent types by replacing them with dependent kinds and by lifting everything (in the proof language) \none level up. To reason about actual programs, we still have to connect terms in the type language with \nthose in the computation language. We follow Xi and Pfenning [44] and use singleton types [22] to relate \ncomputation values to type terms. In the previous example, we in\u00adtroduce a singleton type constructor \nsnat of kind Nat ... Given a type term n of kind Nat, if a computation value v has type snat(n), then \nv denotes the natural number represented by n. A certi.ed binary for a prime number now contains three \nparts: a type term n of kind Nat, a proof for the proposition Prime(n), and a computation value of type \nsnat(n). We can pack it up into an existential package and make it a .rst-class value with type: .n : \nNat..t : Prime(n).snat(n). Here we use . rather than S to emphasize that types and kinds are no longer \ndependent on computation terms. Under the erasure semantics [16], this certi.ed binary is just an integer \nvalue of type snat(n) at run time. A value v of the subset type (for prime numbers) would simply have \ntype snat(n) as long as we can construct a proof for Prime(n) based on the information from the context. \nWe can also build certi.ed binaries for programs that involve effects. Returning to our example, assume \nagain that f is a func\u00adtion in the computation language which may not terminate on some inputs. Suppose \nwe want to certify that if the input to f is a prime, and the call to f does return, then the result \nis also a prime. We can achieve this in two steps. First, we construct a type-level function g of kind \nNat . Nat to simulate the behavior of f (on all inputs where f does terminate) and show that f has the \nfollowing type: .n : Nat. snat(n) . snat(g(n)) Here following Figure 1, we use . and . to denote the \npolymor\u00adphic and function types for the computation language. The type for f says that if it takes an \ninteger of type snat(n) as input and does not loop forever, then it will return an integer of type snat(g(n)). \nSecond, we construct a proof tp showing that g always maps a prime to another prime. The certi.ed binary \nfor f now also con\u00adtains three parts: the type-level function g, the proof tp, and the computation function \nf itself. We can pack it into an existential package with type: .g : Nat.Nat. .p :(.t : Nat.Prime(t) \n.Prime(g(t))). .n : Nat. snat(n) . snat(g(n)) Notice this type also contains function applications such \nas g(n), but g is a type-level function which is always strongly normalizing, so typechecking is still \ndecidable. 2.5 Designing the type language We can incorporate propositions and proofs into typed intermedi\u00adate \nlanguages, but designing the actual type language is still a chal\u00adlenge. For decidable typechecking, \nthe type language should not depend on the computation language and it must satisfy the usual meta-theoretical \nproperties (e.g. strong normalization). But the type language also has to ful.ll its usual responsibil\u00adities. \nFirst, it must provide a set of types (of kind .) to classify the computation terms. A typical compiler \nintermediate language supports a large number of basic type constructors (e.g., integer, ar\u00adray, record, \ntagged union, and function). These types may change their forms during compilation, so different intermediate \nlanguages may have different de.nitions of .; for example, a computation function at the source level \nmay be turned into CPS-style, or later, to one whose arguments are machine registers [27]. We also want \nto support intensional type analysis [21] which is crucial for type\u00adchecking runtime services [26]. Our \nsolution is to provide a general mechanism of inductive de.nitions in our type language and to de.ne \neach such . as an inductive kind. This was made possible only recently [39] and it relies on the use \nof polymorphic kinds. Taking the type language in Figure 1 as an example, we add kind variables k and \npolymorphic kinds .k : u. ., and replace . and its associated type constructors with inductive de.nitions \n(not shown): (kscm) u ::= Kind |... (kind) . ::= .1 ..2 |k |.k : u. . |... (type) t ::= t |.t : .. t \n|t1 t2 |.k : u. t |t [.] |... At the type level, we add kind abstraction .k : u. t and kind appli\u00adcation \nt [.]. The kind . is now inductively de.ned as follows (see Sections 3 4 for more details): Inductive \n.: Kind := . :. .. .. |.. :.k : Kind. (k ..) .. . . . Here . and . are two of the constructors (of .). \nThe polymorphic type .t : .. t is now written as . [.](.t : .. t ); the function type t1 .t2 is just \n. t1t2. Inductive de.nitions also greatly increase the programming power of our type language. We can \nintroduce new data objects (e.g., integers, lists) and de.ne primitive recursive functions, all at the \ntype level; these in turn are used to help model the behaviors of the computation terms. To have the \ntype language double up as a proof language for higher-order predicate logic, we add dependent product \nkind .t : .1..2, which subsumes the arrow kind .1 ..2; we also add kind-level functions to represent \npredicates. Thus the type language naturally becomes the calculus of inductive constructions [34]. 2.6 \nProof-preserving compilation Even with a proof system integrated into our intermediate lan\u00adguages, we \nstill have to make sure that they can be CPS-and closure-converted down to low-level languages. These \ntransforma\u00adtions should preserve proofs represented in the type system; in fact, they should not traverse \nthe proofs at all since doing so is impracti\u00adcal with large proof libraries. These challenges are non-trivial \nbut the way we set up our type system makes it easier to solve them. First, because our type lan\u00adguage \ndoes not depend on the computation language, we do not have the dif.culties involved in CPS-converting \ndependently typed .-calculi [6]. Second, all our intermediate languages share the same type language \nthus also the same proof library; this is possible because the . kind (and the associated types) for \neach intermediate language is just a regular inductive de.nition. Finally, a type-preserving program \ntransformation often re\u00adquires translating the source types (of the source . kind) into the target types \n(of the target . kind). Existing CPS-and closure\u00adconversion algorithms [27, 20, 25] all perform such \ntranslation at the meta-level; they have to go through every type term (thus every proof term in our \nsetting) during the translation, because any type term may contain a sub-term which has the source . \nkind. In our framework, the fact that each . kind is inductively de.ned means that we can internalize \nand write the type-translation function in\u00adside our type language itself. This leads to elegant algorithms \nthat do not traverse any proof terms but still preserve typing and proofs (see Sections 5 6 for details). \n 2.7 Putting it all together A certifying compiler in our framework will have a series of in\u00adtermediate \nlanguages, each corresponding to a particular stage in the compilation process; all will share the same \ntype language. An intermediate language is now just the type language plus the cor\u00adresponding computation \nterms, along with the inductive de.nition for the corresponding . kind. In the rest of this paper, we \n.rst give a formal de.nition of our type language (which will be named as TL from now on) in Section \n3; we then present a sample computa\u00adtion language .H in Section 4; we show how .H can be CPS-and closure-converted \ninto low-level languages in Sections 5 6; .nally, we discuss related work and then conclude.  3 The \nType Language TL Our type language TL resembles the calculus of inductive construc\u00adtions (CIC) implemented \nin the Coq proof assistant [24]. This is a great advantage because Coq is a very mature system and it \nhas a large set of proof libraries which we can potentially reuse. For this paper, we decided not to \ndirectly use CIC as our type language for three reasons. First, CIC contains some features designed for \nprogram extraction [33] which are not required in our case (where proofs are only used as speci.cations \nfor the computation terms). Second, as far as we know, there are still no formal studies covering the \nentire CIC language. Third, for theoretical purposes, we want to understand what are the most essential \nfeatures for modeling cer\u00adti.ed binaries. Motivations Following the discussion in Section 2.5, we orga\u00adnize \nTL into the following three levels: (kscm) u ::= z |.t : .. u |.k : u1.u2 |Kind (kind) . ::= k |.t : \n.1..2 |.[t ] |.k : u. . |.1 .2 |.t : .1..2 |.k : u. . |.z : Kscm.. |Ind(k : Kind){T.}|Elim[.',u](t ){T.} \n(type) t ::= t |.t : .. t |t1 t2 |.k : u. t |t [.] |.z : Kscm.t |t [u] |Ctor (i, .) |Elim[.',.](t'){Tt \n} Here kind schemas (kscm) classify kind terms while kinds classify type terms. There are variables \nat all three levels: kind-schema variables z, kind variables k, and type variables t. We have an ex\u00adternal \nconstant Kscm classifying all the kind schemas; essentially, TL has an additional level above kscm, of \nwhich Kscm is the sole member. A good way to comprehend TL is to look at its .ve . con\u00adstructs: there \nare three at the kind level and two at the kind-schema level. We use a few examples to explain why each \nof them is neces\u00adsary. Following the tradition, we use arrow terms (e.g., .1 ..2)as a syntactic sugar \nfor the non-dependent . terms (e.g., .t: .1..2 is non-dependent if t does not occur free in .2). Kinds \n.t : .1..2 and .1 . .2 are used to typecheck the type-level function .t : .. t and its application form \nt1 t2. Assuming . and Nat are inductive kinds (de.ned later) and Prime is a predicate with kind schema \nNat . Kind,we can write a type term such as .t :..t which has kind . . ., a type-level arithmetic function \nsuch as plus which has kind Nat . Nat . Nat, or the universally quanti.ed proposition in Section 2.2 \nwhich is represented as a kind .t: Nat.Prime(t) .Prime(g(t)). Kinds .k : u. . and u . . are used to typecheck \nthe type\u00adlevel kind abstraction .k : u. t and its application form t[.]. As mentioned in Section 2.5, \nthis is needed to support inten\u00adsional analysis of quanti.ed types [39]. It can also be used to de.ne \nlogic connectives and constants, e.g. True : Kind =.k : Kind.k .k False : Kind =.k : Kind.k True has \nthe polymorphic identity as a proof: id : True = .k : Kind..t: k. t but False is not inhabited (this \nis essentially the consistency property of TL which we will show later). Kind .z : Kscm.. is used to \ntypecheck the type-level kind\u00adschema abstraction .z : Kscm.t and its application form t[u]. This is not \nin the core calculus of constructions [11]. We use it in the inductive de.nition of . (see Section 4) \nwhere both the . Kscm and . Kscm constructors have kind .z : Kscm. (z ..) ... These two constructors \nin turn allow us to typecheck predicate-polymorphic computation terms, which occur fairly often since \nthe closure-conversion phase turns all functions with free predicate variables (e.g, Prime) into predicate-polymorphic \nones.  Kind schemas .t : .. u and . . u are used to typecheck the kind-level type abstraction .t: .1..2 \nand its application form .[t]. The predicate Prime has kind schema Nat . Kind. A predicate with kind \nschema .t : Nat. Prime(t) .Kind is only applicable to prime numbers. We can also de.ne e.g. a binary \nrelation:  LT : Nat.Nat.Kind so that LT t1 t2 is a proposition asserting that the natural number represented \nby t1 is less than that of t2. Kind schemas .k : u1.u2 and u1 . u2 are used to type\u00adcheck the kind-level \nfunction .k : u. . and its application form .1 .2. We use it to write higher-order predicates and logic \nconnectives. For example, the logical negation operator can be written as follows: Not : Kind . Kind \n= .k : Kind. (k .False) The consistency of TL implies that a proposition and its nega\u00adtion cannot be \nboth inhabited otherwise applying the proof of the second to that of the .rst would yield a proof of \nFalse. TL also provides a general mechanism of inductive de.ni\u00adtions [34]. The term Ind(k : Kind){T.} \nintroduces an inductive kind k containing a list of constructors whose kinds are speci\u00ad.ed by T.. Here \nk must only occur positively inside each .i Inductive Bool : Kind := true : Bool | false : Bool Inductive \nNat : Kind := zero : Nat | succ : Nat.Nat plus : Nat.Nat.Nat plus(zero)= .t: Nat.t plus(succ t)= .t ' \n: Nat. succ ((plus t) t ' ) ifez : Nat .(.k : Kind.k .(Nat.k) .k) ifez(zero)= .k : Kind..t1 : k. .t2 \n: Nat.k. t1 ifez(succ t)= .k : Kind..t1 : k. .t2 : Nat.k. t2 t le : Nat .Nat.Bool le(zero)= .t: Nat. \ntrue le(succ t)= .t ' : Nat. ifez t ' Bool false (le t) lt : Nat.Nat.Bool lt = .t: Nat. le (succ t) Cond \n: Bool .Kind.Kind.Kind Cond(true)= .k1 : Kind..k2 : Kind.k1 Cond(false)= .k1 : Kind..k2 : Kind.k2 Figure \n2: Examples of inductive de.nitions (see Appendix A for the formal de.nition of positivity). The term \nCtor (i, .) refers to the i-th constructor in an inductive kind ..For presentation, we will use a more \nfriendly syntax in the rest of this paper. An inductive kind I = Ind(k : Kind){T.} will be written as: \nInductive I : Kind := c1 :[I/k].1 | c2 :[I/k].2 . . . | cn :[I/k].n We give an explicit name ci to each \nconstructor, so ci is just an abbreviation of Ctor (i, I). For simplicity, the current version of TL \ndoes not include parameterized inductive kinds, but supporting them is quite straightforward [41, 34]. \nTL provides two iterators to support primitive recursion on in\u00adductive kinds. The small elimination Elim[. \n' ,.](t ' ){Tt} takes a type term t ' of inductive kind . ' , performs the iterative operation speci.ed \nby Tt (which contains a branch for each constructor of . ' ), and returns a type term of kind .[t ' ] \nas the result. The large elimi\u00adnation Elim[. ' ,u](t){T.} takes a type term t of inductive kind . ' , \nperforms the iterative operation speci.ed by T., and returns a kind term of kind schema u as the result. \nThese iterators generalize the Typerec operator used in intensional type analysis [21, 14, 39]. Figure \n2 gives a few examples of inductive de.nitions including the inductive kinds Bool and Nat and several \ntype-level functions which we will use in Section 4. The small elimination for Nat takes the following \nform Elim[Nat,.](t ' ){t1; t2}. Here, . is a dependent kind with kind schema Nat . Kind; t ' is the argument \nwhich has kind Nat. The term in the zero branch, t1, has kind .[t ' ]. The term in the succ branch, t2, \nhas kind Nat . .[t ' ] . .[t ' ]. TL uses the .-reduction to perform the iterator operation. For example, \nthe two .-reduction rules for Nat work as follows: Elim[Nat,.](zero){t1; t2} r. t1 Elim[Nat,.](succ t){t1; \nt2} r. t2 t (Elim[Nat,.](t){t1; t2}) The general .-reduction rule is de.ned formally in Appendix A. In \nour examples, we take the liberty of using the pattern-matching (sort) s ::= Kind |Kscm |Ext (var) X \n::= z |k |t (ptm) A, B ::= s |X |.X : A. B |AB |.X : A. B |Ind(X : Kind){AT}|Ctor (i, A) |Elim[A ' ,B \n' ](A){BT} Figure 3: Syntax of the type language TL syntax (as in ML) to express the iterator operations, \nbut they can be easily converted back to the Elim form. In Figure 2, plus is a function which calculates \nthe sum of two natural numbers. The function ifez behaves like a switch statement: if its argument is \nzero, it returns a function that selects the .rst branch; otherwise, the result takes the second branch \nand applies it to the predecessor of the argument. The function le evaluates to true if its .rst argument \nis less than or equal to the second. The function lt performs the less-than comparison. The de.nition \nof function Cond, which implements a condi\u00adtional with result at the kind level, uses large elimination \non Bool. It has the form Elim[Bool,u](t ){.1; .2}, where t is of kind Bool; both the true and false branches \n(.1 and .2) have kind schema u. Formalization We want to give a formal semantics to TL and then reason \nabout its meta-theoretical properties. But the .ve . constructs have many redundancies, so in the rest \nof this paper, we will model TL as a pure type system (PTS) [4] extended with in\u00adductive de.nitions. \nIntuitively, instead of having a separate syntac\u00adtical category for each level, we collapse all kind \nschemas u, kind terms ., type terms t , and the external constant Kscm into a single set of pseudoterms \n(ptm), denoted as A or B. Similar constructs can now share typing rules and reduction relations. Figure \n3 gives the syntax of TL, written in PTS style. There is now only one . construct (.X : A. B), one .-abstraction \n(.X : A. B), and one application form (AB); two iterators for inductive de.nitions are also merged into \none (Elim[A ' ,B ' ](A){BT}). We use X and Y to represent generic variables, but we will still use t, \nk, and z if the class of a variable is clear from the context. TL has the following PTS speci.cation \nwhich we will use to derive its typing rules: S = Kind, Kscm, Ext A = Kind : Kscm, Kscm : Ext R = (Kind, \nKind), (Kscm, Kind), (Ext, Kind) (Kind, Kscm), (Kscm, Kscm) Here Scontains the set of sorts used to denote \nuniverses. We have to add the constant Ext to support quanti.cation over Kscm. Our names for the sorts \nre.ect the fact we lifted everything one level up; they are related to other systems via the following \ntable: Systems Notations TL Kind Kscm Ext Werner [41] Set Type Ext Coq/CIC [24] Set,Prop Type(0) Type(1) \nBarendregt [4] * 0 D The axioms in the set Adenote the relationship between different sorts; an axiom \ns1 : s2 means that s2 classi.es s1. The rules in the set Rare used to de.ne well-formed . constructs, \nfrom which we can deduce the set of well-formed .-de.nitions and applica\u00adtions. For example, the .ve \nrules for TL can be related to the .ve . constructs through the following table: PTS rules\\ptm .X : A. \nB .X : A. B AB (Kind, Kind) .t : .1..2 .t : .. t t1 t2 (Kscm, Kind) .k : u. . .k : u. t t [.] (Ext, Kind) \n.z : Kscm.. .z : Kscm.t t [u] (Kind, Kscm) .t : .. u .t : .1..2 .[t ] (Kscm, Kscm) .k : u1.u2 .k : u. \n. .. ' We de.ne a context . as a list of bindings from variables to pseu\u00addoterms: (ctxt) . ::= \u00b7|.,X \n: A The typing judgment for the PTS-style TL now takes the form . f A : A ' meaning that within context \n., the pseudoterm A is well\u00adformed and has A ' as its classi.er. We can now write a single typing rule \nfor all the . constructs: . f A : s1 .,X : A f B : s2 (s1,s2) .R (PROD) . f .X : A. B : s2 Take the rule \n(Kind, Kscm) as an example. To build a well-formed term .X : A. B, which will be a kind schema (because \ns2 is Kscm), we need to show that A is a well-formed kind and B is a well-formed kind schema assuming \nX has kind A. We can also share the typing rules for all the .-de.nitions and applications: .,X : A f \nB : B ' . f .X : A. B ' : s (FUN) . f .X : A. B :.X : A. B ' . f A :.X : B ' .A ' . f B : B ' (APP) . \nf AB :[B/X]A ' The reduction relations can also be shared. TL supports the stan\u00addard \u00df-and .-reductions \n(denoted as r\u00df and r.) plus the previ\u00adously mentioned .-reduction (denoted as r.) on inductive objects \n(see Appendix A). We use 1\u00df, 1., and 1. to denote the relations that correspond to the rewriting of subterms \nusing the relations r\u00df, r., and r. respectively. We use r and 1 for the unions of the above relations. \nWe also write = \u00df.. for the re.exive-symmetric\u00adtransitive closure of 1. The complete typing rules for \nTL and the de.nitions of all the reduction relations are given in Appendix A. Following Werner [41] and \nGeuvers [17], we have shown that TL satis.es all the key meta-theoretic properties including subject \nreduction, strong normalization, Church-Rosser (and con.uence), and consis\u00adtency of the underlying logic. \nThe detailed proofs for these proper\u00adties are given in the companion technical report [37].  4 The Computation \nLanguage .H The language of computations .H for our high-level certi.ed in\u00adtermediate format uses proofs, \nconstructed in the type language, to verify propositions which ensure the runtime safety of the program. \nFurthermore, in comparison with other higher-order typed calculi, the types assigned to programs can \nbe more re.ned, since program invariants expressible in higher-order predicate logic can be rep\u00adresented \nin our type language. These more precise types serve as more complete speci.cations of the behavior of \nprogram compo\u00adnents, and thus allow the static veri.cation of more programs. One approach to presenting \na language of computations is to encode its syntax and semantics in a proof system, with the bene.t of \nobtaining machine-checkable proofs of its properties, e.g. type safety. This appears to be even more \npromising for a system with a type language like CIC, which is more expressive than higher\u00adorder predicate \nlogic: The CIC proofs of some program properties, embedded as type terms in the program, may not be easily \nrepre\u00adsentable in meta-logical terms, thus it may be simpler to perform (exp) e ::= x |n |tt |. |f |.x \nx: A.f |ee ' |e[A] |(X = A, e: A ')|open e as (X, x)in e ' |(e0,... en-1)|sel[A](e, e ' ) |e aop e ' \n|e cop e ' |if[A, A ' ](e, X1.e1,X2.e2) where n .N (fun) f ::= .x: A.e |.X : A. f (arith) aop ::= + |... \n(cmp) cop ::= < |... Figure 4: Syntax of the computation language .H . all the reasoning in CIC. However \nour exposition of the language TL is focused on its use as a type language, and consequently it does \nnot include all features of CIC. We therefore leave this possi\u00adbility for future work, and give a standard \nmeta-logical presentation instead; we address some of the issues related to adequacy in our discussion \nof type safety. In this section we often use the unquali.ed term to refer to a computation term (expression) \ne, with syntax de.ned in Figure 4. Most of the constructs are borrowed from standard higher-order typed \ncalculi. To simplify the exposition we only consider con\u00adstants representing natural numbers (n is the \nvalue representing n .N) and boolean values (tt and .). The term-level abstraction and application are \nstandard; type abstractions and .xed points are restricted to function values, with the call-by-value \nsemantics in mind and to simplify the CPS and closure conversions. The type variable bound by a type \nabstraction, as well as the one bound by the open construct for packages of existential type, can have \neither a kind or a kind schema. Dually, the type argument in a type ap\u00adplication, and the witness type \nterm A in the package construction (X = A, e: A ')can be either a type term or a kind term. The constructs \nimplementing tuple operations, arithmetic, and comparisons have nonstandard static semantics, on which \nwe focus in section 4.1, but their runtime behavior is standard. The branch\u00ading construct is parameterized \nat the type level with a proposition (which is dependent on the value of the test term) and its proof; \nthe proof is passed to the executed branch. Dynamic semantics We present a small step call-by-value op\u00aderational \nsemantics for .H in the style of Wright and Felleisen [42]. The values are de.ned as v ::= n |tt |. |f \n|.x x: A.f |(X = A, v: A ')|(v0,... vn-1) The reduction relation .is speci.ed by the rules (.x: A.e) \nv . [v/x]e (R-\u00df) (.X : B. f)[A] . [A/X]f (R-TY-\u00df) sel[A]((v0,... vn-1),m) . vm (m<n) (R-SEL) open (X \n' = A, v: A ')as (X, x)in e (R-OPEN) . [v/x][A/X]e (.x x: A.f) v . ([.x x: A.f/x]f) v (R-FIX) (.x x: \nA.f)[A ' ] . ([.x x: A.f/x]f)[A ' ] (R-TYFIX) m+ n . m + n (R-ADD) m < n . tt (m<n) (R-LT-T) m< n . . \n(m =n) (R-LT-F) if[B, A](tt,X1.e1,X2.e2) . [A/X1]e1 (R-IF-T) if[B, A](.,X1.e1,X2.e2) . [A/X2]e2 (R-IF-F) \nAn evaluation context E encodes the call-by-value discipline: E ::= |Ee |vE |E[A] |(X = A, E: A ') |open \nE as (X, x)in e |open v as (X, x)in E |(v0, ...vi,E, ei+2, ..., en-1)|sel[A](E, e) |sel[A](v, E) |E aop \ne |v aop E |E cop e |v cop E |if[A, A ' ](E, X1.e1,X2.e2) The notation E{e}stands for the term obtained \nby replacing the hole in E by e. The single step computation e}to .relates E{E{e ' }when e .e ' , and \n. * is its re.exive transitive closure. As shown the semantics is standard except for some additional \npassing of type terms in R-SEL and R-IF-T/F. However an inspec\u00adtion of the rules shows that types are \nirrelevant for the evaluation, hence a type-erasure semantics, in which all type-related operations and \nparameters are erased, would be entirely standard. 4.1 Static semantics The static semantics of .H shows \nthe bene.ts of using a type lan\u00adguage as expressive as TL. We can now de.ne the type construc\u00adtors of \n.H as constructors of an inductive kind ., instead of having them built into .H . As we will show in \nSection 5, this property is crucial for the conversion to CPS, since it makes possible trans\u00adforming \ndirect-style types to CPS types within the type language. Inductive .: Kind := snat : Nat.. |sbool : \nBool .. |.:. .. .. . |tup : Nat.(Nat..) .. |..Kind :.k: Kind. (k..) .. |..Kind :.k: Kind. (k..) .. |..Kscm \n:.z: Kscm. (z..) .. |..Kscm :.z: Kscm. (z..) .. Informally, all well-formed computations have types of \nkind ., in\u00adcluding singleton types of natural numbers snat A and boolean val\u00adues sbool B, as well as \nfunction, tuple, polymorphic and existential types. To improve readability we also de.ne the syntactic \nsugar A .B =. . AB .sX : A. B =. s A (.X : A.B) where s .{Kind, Kscm} .sX : A. B =. s A (.X : A.B) and \noften drop the sort s when s = Kind; e.g. the type void, con\u00adtaining no values, is de.ned as .t:..t =..Kind \n.(.t:..t). Using this syntactic sugar we can give a familiar look to many of the formation rules for \n.H expressions and functional values. Figure 5 contains the inference rules for deriving judgments of \nthe form .; G f e : A, which assign type A to the expression e in a context . and a type environment \nG de.ned by (type env) G ::= \u00b7|G,x: A We introduce some of the notation used in these rules in the course \nof the discussion. Rules E-NAT,E-TRUE, and E-FALSE assign singleton types to numeric and boolean constants. \nFor instance the constant 1 has type snat (succ zero) in any valid environment. In rule E-NAT we use \nthe meta-function i\u00b7 to map natural numbers n . N to their representations as type terms. It is de.ned \ninductively by i0= zero and n= n,so . f ni: Nat holds for all valid . and n+1 succ in .N. . fKind : \nKscm . fG ok . fG ok (TE-MT) (E-VAR) (E-TRUE) . f\u00b7ok .; G fx:G(x) .;G ftt : sbool true . fG ok . fA:. \n. fG ok . fG ok (TE-EXT) (E-NAT) (E-FALSE) . fG,x: A ok .; G fn: snat ni.; G f. : sbool false . fA:. \n.;G,x: A ff : A .; G fe: snat A .; G fe ' : snat A ' (E-FIX) '' (E-ADD) .; G f.x x: A.f : A .; G fe+ \ne : snat (plus AA ) . fA:. .;G,x: A fe: A ' '' .; G fe: snat A .; G fe : snat A (E-FUN) ' (E-LT) .; \nG f.x: A.e: A.A '' .; G fe< e : sbool (lt AA) .; G fe1 : A.A ' .; G fe2 : A for all i<n .; G fei : Ai \n (E-APP) .; G fe1 e2 : A ' .; G f(e0, ... en-1) (E-TUP) : tup ni(nth (A0:: ...::An-1::nil)) . fB : s \n.,X: B;G ff : A X/.. (E-TFUN) s '' '' = Ext .; G f.X: B.f : .sX: B.A.; G fe: tup AB .; G fe : snat \nA . fA: LT A ' A '' (E-SEL) .; G fe: .sX: B.A ' . fA: B = Ext) .;G fsel[A](e,e .; G fe[A]:[A/X]A ' . \nfB : Bool .Kind .; G fe: sbool A '' . fA: B . fB : s '' ' (s (E-TAPP) ' ): BA ' . fA: BA .,X1 : B true;G \nfe1 : A .; G fe:[A/X]A ' '' (E-IF) (E-PACK) . fA :. .,X2 : B false;G fe2 : A(s = Ext) .; G f(X= A, e: \nA ' ): .sX: B.A '' .; G fif[B,A](e, X1.e1,X2.e2) : A .; G fe: .sX ' : B.A . fA ' :. '' .; G fe: AA= \n\u00df.. A . fA :. ' '' .,X: B;G,x:[X/X ]A fe : A X/.. (E-OPEN) ' (E-CONV) .; G fe: A .; G fopen eas (X, \nx)in e ' : A 's = Ext Figure 5: Static semantics of the computation language .H. Singleton types play \na central role in re.ecting properties of values in the type language, where we can reason about them \ncon\u00adstructively. For instance rules E-ADD and E-LT use respectively the type terms plus and lt (de.ned \nin Section 3) to re.ect the semantics of the term operations into the type level via singleton types. \nHowever, if we could only assign singleton types to computa\u00adtion terms, in a decidable type system we \nwould only be able to typecheck terminating programs. We regain expressiveness of the computation language \nusing existential types to hide some of the too detailed type information. Thus for example one can de.ne \nthe usual types of all natural numbers and boolean values as nat :.= .t: Nat.snat t bool :.= .t: Bool.sbool \nt For any term ewith singleton type snat Athe package (t= A, e: snat t)has type nat. Since in a type-erasure \nsemantics of .H all types and operations on them are erased, there is no runtime overhead for the packaging. \nFor each n .N there is a value of this type denoted by ni=(t = n, n : snat t). iOperations on terms of \ntype nat are derived from operations on terms of singleton types of the form snat A; for example an addition \nfunction of type nat .nat .nat is de.ned as the expression add = .x1 : nat..x2 : nat. open x1 as (t1, \nx ' 1)in open x2 as (t2, x ' 2)in (t= plus t1 t2, x1 ' + x2 ' : snat t) Rule E-TUP assigns to a tuple \na type of the form tup AB,in which the tup constructor is applied to a type A representing the tuple \nsize, and a function B mapping offsets to the types of the tuple components. This function is de.ned \nin terms of operations on lists of types: Inductive List : Kind := nil : List |cons :. .List.List nth \n: List .Nat.. nth nil = .t: Nat.void nth (cons t1 t2)= .t: Nat.ifez t . t1 (nth t2) Thus nth L nireduces \nto the n-th element of the list L when n is less than the length of L, and to void otherwise. We also \nuse the in.x form A::A ' =cons AA ' . The type of pairs is derived: A\u00d7 A ' =tup i2(nth (A::A ' ::nil)). \nThus for instance \u00b7;\u00b7f (42,7): snat 442 \u00d7snat i7 is a valid judgment. The rules for selection and testing \nfor the less-than relation (the only comparison we discuss for brevity) refer to the kind term LT with \nkind schema Nat .Nat .Kind. Intuitively, LT represents a binary relation on kind Nat,so LT in is the \nkind of type terms m irepresenting proofs of m<n. LT can be thought of as the param\u00adeterized inductive \nkind of proofs constructed from instances of the axioms .n.N.0 <n+1 and .m,n .N.m<n.m+1 <n+1: Inductive \nLT : Nat .Nat.Kind := ltzs :.t: Nat.LT zero (succ t) '' ' |ltss :.t: Nat..t : Nat.LT tt .LT (succ t)(succ \nt ) To simplify the presentation of our type language, we allowed in\u00adductive kinds of kind scheme Kind \nonly. Thus to stay within the scope of this paper we actually use a Church encoding of LT (see Appendix \nC for details); this is suf.cient since proof objects are never analyzed in .H, so the full power of \nelimination is not nec\u00adessary for LT. In the component selection construct sel[A](e,e ' ) the type A \nrepresents a proof that the value of the subscript e ' is less than the size of the tuple e. In rule \nE-SEL this condition is expressed as an application of the type term LT. Due to the consistency of the \nlogic represented in the type language, only the existence and not the structure of the proof object \nA is important. Since its existence is ensured statically in a well-formed expression, Awould be elim\u00adinated \nin a type-erasure semantics. The branching construct if[B,A](e, X1.e1,X2.e2) takes a type term A representing \na proof of the proposition encoded as ei\u00adther B true or B false, depending on the value of e. The proof \nis passed to the appropriate branch in its bound type variable (X1 or X2). The correspondence between \nthe value of e and the kind of A is again established through a singleton type. Note that unlike Xi and \nHarper [43] we allow imprecise information .ow into the branches by not restricting B false to be the \nnegation of B true.In particular this makes possible the encoding of the usual oblivious (in proof-passing \nsense) if using B = .t:Bool.True.  4.2 Example: bound check elimination A simple example of the generation, \npropagation, and use of proofs in .H is a function which computes the sum of the components of any vector \nof naturals. Let us .rst introduce some auxiliary types and functions. The type assigned to a homogeneous \ntuple (vector) of n terms of type A is \u00df..-convertible to the form vec i nA for vec : Nat .... vec = \n.t:Nat..t ' :..tup t (nth (repeat tt ' )) where repeat : Nat ...List repeat zero = .t ' :..nil '' ' \nrepeat (succ t)= .t :..t ::(repeat t) t Then we can de.ne a term which sums the elements of a vector \nwith a given length as follows: sumVec : .t:Nat.snat t . vec t nat . nat = .t:Nat..n:snat t..v :vec t \nnat. (.x loop :nat . nat . nat. .i :nat..sum:nat. open i as (t ' , i ' )in if[LTOrTrue t ' t,ltPrf t \n' t] (i ' < n, t1.loop (add i i1) (add sum (sel[t1](v,i ' ))), t2 .sum))i0i0 where LTOrTrue : Nat.Nat.Bool \n.Kind LTOrTrue = .t1 :Nat..t2 :Nat..t:Bool.Cond t (LT t1 t2)True ' '' and ltPrf of kind .t : Nat..t : \nNat.LTOrTrue tt (lt tt) is a type term de.ned in Appendix C. The comparison i ' < n, used in this example \nas a loop termina\u00adtion test, checks whether the index i ' is smaller than the vector size n. If it is, \nthe adequacy of the type term lt with respect to the less\u00adthan relation ensures that the type term ltPrf \nt ' t represents a proof of the corresponding proposition at the type level, namely LT t ' t. This proof \nis then bound to t1 in the .rst branch of the if, and the sel construct uses it to verify that the i \n' -th element of v exists, thus avoiding a second test. The type safety of .H (Theorem 1) guaran\u00adtees \nthat implementations of sel need not check the subscript at run\u00adtime. Since the proof t2 is ignored in \nthe else branch, ltPrf t ' t is de.ned to reduce to the trivial proof of True when the value of i ' is \nnot less than that of n. The usual vector type, which keeps the length packaged with the content, is \n' '' vector :...= .t:...t :Nat.snat t \u00d7vec t t. Now we can write a wrapper function for sumVec with the \nstandard type vector nat . nat; we leave the details to the reader. 4.3 Type safety The type safety \nof .H is a corollary of its properties of progress and subject reduction. A pivoting element in proving \nprogress (Lemma 4 in Appendix B) is the connection between the existence of a proof (type) term of kind \nLT in, provided by rule E-SEL, and m ithe existence of a (meta-logical) proof of the side condition m<n, \nrequired by rule R-SEL. Similarly, subject reduction (Lemma 5 in Appendix B) in the cases of R-ADD and \nR-LT-T/F relies on the adequate representation of addition and comparison by plus and lt. Lemma 1 (Adequacy \nof the TL representation of arithmetic) 1. For all m,n . N, plus mini= \u00df.. . m+n. 2. For all m,n . N, \nlt in \u00df.. true if and only if m<n. m i= 3. For all m,n . N, m<n if and only if there exists a type A \nsuch that \u00b7f A : LT in. m i Proof sketch (3) For the forward direction it suf.ces to observe that the \nstructure of the meta-logical proof of m<n (in terms of the above axioms of ordering) can be directly \nre.ected in a type term of kind LT in. The inverse direction is shown by examining m i the structure \nof closed type terms of this kind in normal form. 0 Theorem 1 (Safety of .H) If \u00b7;\u00b7f e : A, then either \ne . * v and \u00b7;\u00b7f v : A,or e diverges (i.e., for each e ' ,if e . * e ' , then there exists e '' such \nthat e ' . e '' ). Proof sketch Follows from Lemmas 4 and 5 (Appendix B). 0 Since CIC and TL are more \nexpressive than higher-order predi\u00adcate logic, adequacy of the representations of meta-proofs does not \nhold in general; in particular, the ability to eliminate inductive kinds in TL allows analysis of proof \nderivations to be used in proof con\u00adstruction, a technique not employed in standard meta-reasoning. This \nissue does not arise for .rst-order proof representations like LT (where no constructors have parameters \nof a function kind), and we do not expect it to be a concern in practice. In cases when it does arise, \nit could be resolved by using the underlying consistent logic of CIC instead of the meta-logic; for instance \nin our presentation the question of adequacy is raised because the operational seman\u00adtics of .H is de.ned \nin meta-logical terms, but this question would be moot if .H and its semantics were de.ned as CIC terms. \nTo eliminate the interaction with the meta-logic, this approach should be applied all the way down to \nthe hardware speci.cation (as done in some PCC system [3]); we plan to pursue this in the future.  \n5 CPS Conversion In this section we show how to perform CPS conversion on .H while still preserving proofs \nrepresented in the type system. This stage transforms all unconditional control transfers, including \nfunc\u00adtion invocation and return, to function calls and gives explicit names to all intermediate computations. \nThe basics of our ap\u00adproach, i.e. the target language and the transformation of types, are shown in this \nsection. The static semantics of the target language and the transformation of terms are given in Appendix \nD. We call the target calculus for this phase .K, with syntax: (val) v ::= x | n | tt | . |(X = A, v \n: A ' )|(v0,... vn-1) | .x x ' [X1 : A1, ...Xn : An](x : A).e (exp) e ::= v[A1, ...An](v ' ) | let x \n= v in e | let (X, x) = open v in e | let x = sel[A](v, v ' ) in e | let x = v aop v ' in e | let x = \nv cop v ' in e | if[A, A ' ](v, X1.e1,X2.e2) Expressions in .K consist of a series of let bindings followed \nby a function application or a conditional branch. There is only one ab\u00adstraction mechanism, .x, which \ncombines type and value abstrac\u00adtion. Multiple arguments may be passed by packing them in a tuple. .K \nshares the TL type language with .H. The types for .K all have kind .K which, as in .H, is an inductive \nkind de.ned in TL. The .K kind has all the constructors of . plus one more (func). Since functions in \nCPS do not return values, the function type constructor of .K has a different kind: . :.K . .K We use \nthe more conventional syntax A .. for . A. The new constructor func forms the types of function values: \nfunc :.K . .K Every function value is implicitly associated with a closure envi\u00adronment (for all the \nfree variables), so the func constructor is useful in the closure-conversion phase (see Section 6). Typed \nCPS conversion involves translating both types and com\u00adputation terms. Existing algorithms [20, 27] require \ntraversing and transforming every term in the type language (which would include all the proofs in our \nsetting). This is impractical because proofs are large in size, and transforming them can alter their \nmeanings and break the sharing among different intermediate languages. To see the actual problem, let \nus convert the .H expression (X = A, e : B) to CPS, assuming that it has type .X : A ' .B.We use Ktyp \nto denote the meta-level translation function for the type language and Kexp for the computation language. \nUnder existing algorithms, the translation also transforms the witness A: Kexp [[(X = A, e : B)]] = .k: \nKtyp[[.X : A ' .B ]]. Kexp [[e]] (.x : Ktyp[[[A/X]B ]]. k (X = Ktyp[[A]],x : Ktyp[[B ]])) Here we CPS-convert \ne and apply it to a continuation, which puts the result of its evaluation in a package and hands it to \nthe return continuation k. With proper de.nition of Ktyp and assuming that Ktyp[[X ]] = X on all variables \nX, we can show that the two types Ktyp[[[A/X]B ]] and [Ktyp[[A]]/X](Ktyp[[B ]]) are equivalent (under \n= \u00df..). Thus the translation preserves typing. But we do not want to touch the witness A, so the translation \nfunction should be de.ned as follows: Kexp [[(X = A, e : B)]] = .k: Ktyp[[.X : A ' .B ]]. Kexp [[e]] \n(.x : Ktyp[[[A/X]B ]]. k (X = A, x : Ktyp[[B ]])) To preserve typing, we have to make sure that the two \ntypes Ktyp[[[A/X]B ]] and [A/X](Ktyp[[B ]]) are equivalent. This seems impossible to achieve if Ktyp \nis de.ned at the meta level. Our solution is to internalize the de.nition of Ktyp in our type language. \nWe replace Ktyp by a type function K of kind . . .K. For readability, we use the pattern-matching syntax, \nbut it can be easily coded using the Elim construct. K (snat t)= snat t K (sbool t)= sbool t K (t1 . \nt2)= func ((K(t1) \u00d7 Kc(t2)) ..) K (tup t1 t2)= tup t1 (.t : Nat. K(t2 t)) K (. Kind kt)= func (. Kind \nk (.t1 : k. Kc(tt1)..)) K (. Kind kt)= . Kind k (.t1 : k. K(tt1)) K (. Kscm zt)= func (. Kscm z (.k : \nz. Kc(tk)..)) K (. Kscm zt)= . Kscm z (.k : z. K(tk)) Kc = .t :.. func (K(t)..) The de.nition of K is \nin the spirit of the interp function of Crary and Weirich [14]. However interp cannot be used in de.ning \na sim\u00adilar CPS conversion, because its domain does not cover (nor is there an injection to it from) all \ntypes appearing in type annotations. In .H these types are in the inductive kind . and can be analyzed \nby K. We can now prove K ([A/X]B)=\u00df.. [A/X](K (B)) by .rst reducing B to the normal form B ' . Clearly, \nK ([A/X]B)=\u00df.. K ([A/X]B ' ) and [A/X](K (B ' )) = \u00df.. [A/X](K (B)).We then prove K ([A/X]B ' )=\u00df.. [A/X](K \n(B ' )) by induction over the structure of the normal form B ' . The complete CPS-conversion algorithm \nis given in Appendix D. 6 Closure Conversion In this section we address the issue of how to make closures \nexplicit for all the CPS terms in .K. This stage rewrites all functions so that they contain no free \nvariables. Any variables that appear free in a function value are packaged in an environment, which together \nwith the closed code of the function form a closure. When a function is applied, the closed code and \nthe environment are extracted from the closure and then the closed code is called with the environment \nas an additional parameter. Again, the basics of our approach are shown in this section and more details \nare given in Appendix E. Our approach to closure conversion is based on Morrisett et al. [27], who adopt \na type-erasure interpretation of polymorphism. We use the same idea for existential types. The language \nthat we use for this phase is called .C with syntax: (val) v ::= x | n | tt | . | .x x ' [X1 : A1, ...Xn \n: An](x : A).e | v[A] |(v0,... vn-1)|(X = A, v : A ' ) (exp) e ::= vv ' | let x = v in e | let x = sel[A](v, \nv ' ) in e | let (X, x) = open v in e | let x = v aop v ' in e | let x = v cop v ' in e | if[B, A](v, \nX1.e1,X2.e2) .C is similar to .K, the main difference being that type applica\u00adtion and value application \nare again separate. Type applications are values in .C re.ecting the fact that they have no runtime ef\u00adfect \nin a type-erasure interpretation. We use the same kind of types .K as in .K. We de.ne the transformation \nof types as a function Cl :.K . .K . .K, the second argument of which represents the type of the environment. \nAs in CPS conversion, we write Cl as a TL function so that the closure-conversion algorithm does not \nhave to traverse proofs represented in the type system. Cl (snat t)= .t ' :.K. snat t Cl (sbool t)= .t \n' :.K. sbool t Cl (t ..)= .t ' :.K. (t ' \u00d7 Cl (t) .) .. Cl (func t)= .t ' :.K. .t1 :.K. (Cl (t) t1 \u00d7 \nt1) Cl (tup t1 t2)= .t ' :.K. tup t1 (.t '' : Nat. Cl (t2 t '' ) t ' ) Cl (. Kind kt)= .t ' :.K. . Kind \nk (.t1 : k. Cl (tt1) t ' ) Cl (. Kind kt)= .t ' :.K. . Kind k (.t1 : k. Cl (tt1) t ' ) Cl (. Kscm zt)= \n.t ' :.K. . Kind z (.k : z. Cl (tk) t ' ) Cl (. Kscm zt)= .t ' :.K. . Kscm z (.k : z. Cl (tk) t ' ) \n7 Related Work Our type language is a variant of the calculus of constructions [11] extended with inductive \nde.nitions (with both small and large elim\u00adination) [34, 41]. We omitted parameterized inductive kinds \nand dependent large elimination to simplify our presentation, however, all our meta-theoretic proofs \ncarry over to a language that includes them. We support .-reduction in our language while the of.cial \nCoq system does not. The proofs for the properties of TL are adapted from Geuvers [17] and Werner [41] \n(which in turn bor\u00adrows ideas from Altenkirch [1]); the main difference is that our language has kind-schema \nvariables and a new product formation rule (Ext, Kind) which are not in Werner s system. The Coq proof \nassistant provides support for extracting pro\u00adgrams from proofs [34]. It separates propositions and sets \ninto two distinct universes Prop and Set. We do not distinguish be\u00adtween them because we are not aiming \nto extract programs from our proofs, instead, we are using proofs as speci.cations for our computation \nterms. Burstall and McKinna [7] proposed the notion of deliverables, which is essentially the same as \nour notion of certi.ed binaries. They use dependent strong sums to model each deliverable and give its \ncategorical semantics. Their work does not support programs with effects and has all the problems mentioned \nin Section 2.3. Xi and Pfenning s DML [44] is the .rst language that nicely combines dependent types \nwith programs that may involve effects. Our ideas of using singleton types and lifting the level of the \nproof language are directly inspired by their work. Xi s system, however, does not support arbitrary \npropositions and explicit proofs. It also does not de.ne the . kind as an inductive de.nition so it is \nun\u00adclear how it interacts with intensional type analysis [39] and how it preserves proofs during compilation. \nWe have discussed the relationship between our work and those on PCC, typed assembly languages, and intensional \ntype analysis in Section 1. Inductive de.nitions subsume and generalize earlier systems on intensional \ntype analysis [21, 14, 39]; the type-analysis construct in the computation language can be eliminated \nusing the technique proposed by Crary et al. [16]. Concurrently with our work, Crary and Vanderwaart \n[12] re\u00adcently proposed a system called LTT which also aims at adding explicit proofs to typed intermediate \nlanguages. LTT uses Linear LF [8] as its proof language. It shares some similarities with our system \nin that both are using singleton types [44] to circumvent the problems of dependent types. However, since \nLF does not have inductive de.nitions and the Elim construct, it is unclear how LTT can support intensional \ntype analysis and type-level primitive recur\u00adsive functions [15]. In fact, to de.ne . as an inductive \nkind [39], LTT would have to add proof-kind variables and proof-kind poly\u00admorphism, which could signi.cantly \ncomplicate the meta-theory of its proof language. LTT requires different type languages for different \nintermediate languages; it is unclear whether it can pre\u00adserve proofs during CPS and closure conversion. \nThe power of linear reasoning in LTT is desirable for tracking ephemeral prop\u00aderties that hold only for \ncertain program states; we are working on adding such support into our framework. 8 Conclusions We presented \na general framework for explicitly representing propositions and proofs in typed intermediate or assembly \nlan\u00adguages. We showed how to integrate an entire proof system into our type language and how to perform \nCPS and closure conversion while still preserving proofs represented in the type system. Our work is \na .rst step toward the goal of building realistic infrastruc\u00adture for certi.ed programming and certifying \ncompilation. Our type system is fairly concise and simple with respect to the number of syntactic constructs, \nyet it is powerful enough to express all the propositions and proofs in the higher-order predicate logic \n(extended with induction principles). In the future, we would like to use our type system to express \nadvanced program invariants such as those involved in low-level mutable recursive data structures. Our \ntype language is not designed around any particular pro\u00adgramming language. We can use it to typecheck \nas many different computation languages as we like; all we need is to de.ne the cor\u00adresponding . kind \nas an inductive de.nition. We hope to evolve our framework into a realistic typed common intermediate \nformat.  Acknowledgment We would like to thank Thorsten Altenkirch, Gilles Barthe, Thierry Coquand, \nAntony Courtney, Karl Crary, Christopher League, Zhao\u00adhui Luo, Christine Paulin-Mohring, Stefan Monnier, \nHenrik Nils\u00adson, Walid Taha, and anonymous referees for discussions and com\u00adments on an earlier version \nof this paper. Benjamin Werner helped us understand the intricacies in the strong-normalization proof \nfor the core calculus of inductive constructions. References [1] T. Altenkirch. Constructions, Inductive \nTypes and Strong Normaliza\u00adtion. PhD thesis, University of Edinburgh, UK, 1993. [2] A. W. Appel and E. \nW. Felten. Models for security policies in proof\u00adcarrying code. Technical Report CS-TR-636-01, Princeton \nUniv., Dept. of Computer Science, March 2001. [3] A. W. Appel and A. P. Felty. A semantic model of types \nand machine instructions for proof-carrying code. In Proc. 27th ACM Symp. on Principles of Prog. Lang., \npages 243 253. ACM Press, 2000. [4] H. P. Barendregt. Lambda calculi with types. In S. Abramsky, D. Gab\u00adbay, \nand T. Maibaum, editors, Handbook of Logic in Computer Sci\u00adence (volume 2). Oxford Univ. Press, 1991. \n[5] H. P. Barendregt and H. Geuvers. Proof-assistants using dependent type systems. In A. Robinson and \nA. Voronkov, editors, Handbook of Automated Reasoning. Elsevier Sci. Pub. B.V., 1999. [6] G. Barthe, \nJ. Hatcliff, and M. Sorensen. CPS translations and applica\u00adtions: the cube and beyond. Higher Order and \nSymbolic Computation, 12(2):125 170, September 1999. [7] R. Burstall and J. McKinna. Deliverables: an \napproach to program development in constructions. Technical Report ECS-LFCS-91-133, Univ. of Edinburgh, \nUK, 1991. [8] I. Cervesato and F. Pfenning. A linear logical framework. In Proc. 11th IEEE Symp. on Logic \nin Computer Science, pages 264 275, July 1996. [9] C. Colby, P. Lee, G. C. Necula, F. Blau, M. Plesko, \nand K. Cline. A certifying compiler for Java. In Proc. 2000 ACM Conf. on Prog. Lang. Design and Impl., \npages 95 107, New York, 2000. ACM Press. [10] R. Constable. Constructive mathematics as a programming \nlogic I: Some principles of theory. Ann. of Discrete Mathemathics, 24, 1985. [11] T. Coquand and G. Huet. \nThe calculus of constructions. Information and Computation, 76:95 120, 1988. [12] K. Crary and J. Vanderwaart. \nAn expressive, scalable type theory for certi.ed code. Technical Report CMU-CS-01-113, School of Com\u00adputer \nScience, Carnegie Mellon Univ., Pittsburg, PA, May 2001. [13] K. Crary, D. Walker, and G. Morrisett. \nTyped memory management in a calculus of capabilities. In Proc. 26th ACM Symp. on Principles of Prog. \nLang., pages 262 275. ACM Press, 1999. [14] K. Crary and S. Weirich. Flexible type analysis. In Proc. \n1999 ACM SIGPLAN Int l Conf. on Functional Prog., pages 233 248. ACM Press, Sept. 1999. [15] K. Crary \nand S. Weirich. Resource bound certi.cation. In Proc. 27th ACM Symp. on Principles of Prog. Lang., pages \n184 198. ACM Press, 2000. [16] K. Crary, S. Weirich, and G. Morrisett. Intensional polymorphism in type-erasure \nsemantics. In Proc. 1998 ACM SIGPLAN Int l Conf. on Functional Prog., pages 301 312. ACM Press, Sept. \n1998. [17] H. Geuvers. Logics and Type Systems. PhD thesis, Catholic University of Nijmegen, The Netherlands, \n1993. \u00b4 res dans l Arithm\u00b4etique d Ordre Sup\u00b4erieur. PhD thesis, University of Paris VII, 1972. [18] \nJ.-Y. Girard. Interpr\u00b4etation Fonctionnelle et Elimination des Coupu\u00ad [19] R. Harper. The practice of \ntype theory. Talk presented at 2000 Alan J. Perlis Symposium, Yale University, New Haven, CT, April 2000. \n[20] R. Harper and M. Lillibridge. Explicit polymorphism and CPS con\u00adversion. In Proc. 20th ACM Symp. \non Principles of Prog. Lang., pages 206 219. ACM Press, 1993. [21] R. Harper and G. Morrisett. Compiling \npolymorphism using inten\u00adsional type analysis. In Proc. 22nd ACM Symp. on Principles of Prog. Lang., \npages 130 141. ACM Press, 1995. [22] S. Hayashi. Singleton, union and intersection types for program \nex\u00adtraction. In A. R. Meyer, editor, Proc. International Conference on Theoretical Aspects of Computer \nSoftware, pages 701 730, 1991. [23] W. A. Howard. The formulae-as-types notion of constructions. In To \nH.B.Curry: Essays on Computational Logic, Lambda Calculus and Formalism. Academic Press, 1980. [24] G. \nHuet, C. Paulin-Mohring, et al. The Coq proof assistant reference manual. Part of the Coq system version \n6.3.1, May 2000. [25] Y. Minamide, G. Morrisett, and R. Harper. Typed closure conversion. In Proc. 23rd \nACM Symp. on Principles of Prog. Lang., pages 271 283. ACM Press, 1996. [26] S. Monnier, B. Saha, and \nZ. Shao. Principled scavenging. In Proc. 2001 ACM Conf. on Prog. Lang. Design and Impl., pages 81 91, \nNew York, 2001. ACM Press. [27] G. Morrisett, D. Walker, K. Crary, and N. Glew. From System F to typed \nassembly language. In Proc. 25th ACM Symp. on Principles of Prog. Lang., pages 85 97. ACM Press, Jan. \n1998. [28] G. Necula. Proof-carrying code. In Proc. 24th ACM Symp. on Princi\u00adples of Prog. Lang., pages \n106 119, New York, Jan 1997. ACM Press. [29] G. Necula. Compiling with Proofs. PhD thesis, School of \nComputer Science, Carnegie Mellon Univ., Sept. 1998. [30] G. Necula and P. Lee. Safe kernel extensions \nwithout run-time check\u00ading. In Proc. 2nd USENIX Symp. on Operating System Design and Impl., pages 229 \n243. USENIX Assoc., 1996. [31] G. Necula and P. Lee. The design and implementation of a certifying compiler. \nIn Proc. 1998 ACM Conf. on Prog. Lang. Design and Impl., pages 333 344, New York, 1998. ACM Press. [32] \nB. Nordstrom, K. Petersson, and J. Smith. Programming in Martin\u00adL\u00a8of s type theory. Oxford University \nPress, 1990. [33] C. Paulin-Mohring. Extracting F. s programs from proofs in the Cal\u00adculus of Constructions. \nIn Proc. 16th ACM Symp. on Principles of Prog. Lang., pages 89 104, New York, Jan 1989. ACM Press. [34] \nC. Paulin-Mohring. Inductive de.nitions in the system Coq rules and properties. In M. Bezem and J. Groote, \neditors, Proc. TLCA. LNCS 664, Springer-Verlag, 1993. [35] Z. Shao. An overview of the FLINT/ML compiler. \nIn Proc. 1997 ACM SIGPLAN Workshop on Types in Compilation, June 1997. [36] Z. Shao, C. League, and S. \nMonnier. Implementing typed intermedi\u00adate languages. In Proc. 1998 ACM SIGPLAN Int l Conf. on Functional \nProg., pages 313 323. ACM Press, 1998. [37] Z. Shao, B. Saha, V. Trifonov, and N. Papaspyrou. A type \nsystem for certi.ed binaries. Technical Report YALEU/DCS/TR-1211, Dept. of Computer Science, Yale University, \nNew Haven, CT, March 2001. [38] M. A. Sheldon and D. K. Gifford. Static dependent types for .rst class \nmodules. In 1990 ACM Conference on Lisp and Functional Programming, pages 20 29, New York, June 1990. \nACM Press. [39] V. Trifonov, B. Saha, and Z. Shao. Fully re.exive intensional type analysis. In Proc. \n2000 ACM SIGPLAN Int l Conf. on Functional Prog., pages 82 93. ACM Press, September 2000. [40] D. Walker. \nA type system for expressive security policies. In Proc. 27th ACM Symp. on Principles of Prog. Lang., \npages 254 267, 2000. [41] B. Werner. Une Th\u00b4eorie des Constructions Inductives. PhD thesis, A L Universit\u00b4e \nParis 7, Paris, France, 1994. [42] A. K. Wright and M. Felleisen. A syntactic approach to type sound\u00adness. \nInformation and Computation, 115(1):38 94, 1994. [43] H. Xi and R. Harper. A dependently typed assembly \nlanguage. In Proc. 2001 ACM SIGPLAN Int l Conf. on Functional Prog., pages 169 180. ACM Press, September \n2001. [44] H. Xi and F. Pfenning. Dependent types in practical programming. In Proc. 26th ACM Symp. on \nPrinciples of Prog. Lang., pages 214 227. ACM Press, 1999. A Formalization of TL (Details) In this appendix \nwe supply the rest of the details involved in the formalization of our type language TL. Most of our \nnotations and de.nitions are directly borrowed from Werner [41]. In addition to the symbols de.ned in \nthe syntax, we will also use C to denote general terms, Y and Z for variables, and I for inductive de.ni\u00adtions. \nIn order to ensure that the interpretation of inductive de.nitions remains consistent, and they can be \ninterpreted as terms closed un\u00adder their introduction rules, we impose positivity constraints on the \nconstructors of an inductive de.nition. The positivity constraints are de.ned in De.nition 2 and 3. De.nition \n2 A term A is strictly positive in X if A is either X or .Y : B. A ' , where A ' is strictly positive \nin X, X does not occur free in B, and X = Y . De.nition 3 A term C is a well-formed constructor kind \nfor X (written wfcX (C)) if it has one of the following forms: 1. X; 2. .Y : B. C ' , where Y = X, X \nis not free in B, and C ' is a well-formed constructor kind for X;or 3. A . C ' , where A is strictly \npositive in X and C ' is a well\u00adformed constructor kind for X.  Note that in the de.nition of wfcX (C), \nthe second clause covers the case where C is of the form A . C ' , and X does not occur free in A. Therefore, \nwe only allow the occurrence of X in the non-dependent case. In the rest of this paper we often write \nthe well-formed con\u00adstructor kind for X as .TB.X. We also denote terms that are Y : Tstrictly positive \nin X by .YT: TB. B. X, where X is not free in T De.nition 4 Let C be a well-formed constructor kind for \nX. Then C is of the form .YT: TIf all the Y s are t s, that is, C is of A. X. the form .Tt: T A. X, then \nwe say that C is a small constructor kind (or just small constructor when there is no ambiguity) and \ndenote it as small(C). Our inductive de.nitions reside in Kind, whereas a small construc\u00adtor does not \nmake universal quanti.cation over objects of type Kind. Therefore, an inductive de.nition with small \nconstructors is a predicative de.nition. While dealing with impredicative induc\u00adtive de.nitions, we must \nforbid projections on universes equal to or bigger than the one inhabited by the de.nition. In particular, \nwe restrict large elimination to inductive de.nitions with only small constructors. Next, we de.ne the \nset of reductions on our terms. The de.\u00adnition of \u00df-and .-reduction is standard. The .-reduction de.nes \nprimitive recursion over inductive objects. De.nition 5 Let C be a well-formed constructor kind for X \nand let A ' , B ' , and I be pseudoterms. We de.ne FX,I,B. (C,A ' ) re\u00adcursively based on the structure \nof C: def '' FX,I,B. (X,A )= A def FX,I,B. (.Y : B.C ' ,A ' )= .Y : B.FX,I,B. (C ' ,A ' Y ) def FX,I,B. \n((.YT: B.XT) .C ' ,A ' )= .Z:(.YT: T,A ' Y : T(ZT B.I).FX,I,B. (C ' Z (.TB.B ' Y ))) De.nition 6 The \nreduction relations on our terms are de.ned as: (.X: A.B) A ' r\u00df [A ' /X]B .X : A.(BX) r. B, if X/.FV \n(B) Elim[I,A '' ](Ctor (i,I) AT){BT} r. (FX,I,B. (Ci,Bi)) ATT I = Ind(X : Kind){C} where B ' '' T = .Y \n: I.(Elim[I,A ](Y ){B}) By 1\u00df, 1., and 1. we denote the relations that correspond to the rewriting of \nsubterms using the relations r\u00df, r., and r. respec\u00adtively. We use r and 1 for the unions of the above \nrelations. We also write = \u00df.. for the re.exive-symmetric-transitive closure of 1. Let us examine the \n.-reduction in detail. In Elim[I,A '' ](A){BT}, the term A of type I is being analyzed. The sequence \nBTcontains the set of branches for Elim, one for each constructor of I. In the case when Ci = X, which \nimplies that A is of the form Ctor (i,I), the Elim just selects the Bi branch: T Elim[I,A '' ](Ctor (i,I)){B} \nr. Bi Y : Tin BT, then A must be in the form Ctor (i,I) ATwith Ai of type Bi. None of the arguments are \nrecursive. Therefore, the Elim should just select the Bi branch and pass the constructor arguments to \nit. Accordingly, the reduction yields (by expanding the F macro): In the case when Ci =.TB.X where X \ndoes not occur free T Elim[I,A '' ](Ctor (i,I) AT){BT} r. Bi A The recursive case is the most interesting. \nFor simplicity assume Y : BT'' : BT'' that the i-th constructor has the form .T.X ..YT.X. Therefore, \nA is of the form Ctor (i,I) ATwith A1 being the re\u00adcursive component of type .YT: BT' .X, and A2 ...An \nbeing non\u00adrecursive. The reduction rule then yields: T Elim[I,A '' ](Ctor (i,I) AT){B} T r. Bi A1 (.YT: \nBT' .Elim[I,A '' ](A1 YT){B}) A2 ...An The Elim construct selects the Bi branch and passes the arguments \nA1,...,An, and the result of recursively processing A1. In the general case, it would process each recursive \nargument. De.nition 7 de.nes the . macro which represents the type of the large Elim branches. De.nition \n8 de.nes the . macro which represents the type of the small elimination branches. The different cases \nfollow from the .-reduction rule in De.nition 6. De.nition 7 Let C be a well-formed constructor kind \nfor X and let A ' and I be two terms. We de.ne .X,I (C,A ' ) recursively based on the structure of C: \ndef .X,I(X,A ' )= A ' def .X,I(.Y : B.C ' ,A ' )=.Y : B..X,I(C ' ,A ' ) C ' def ' '' .X,I(A.,A ) =[I/X]A.[A \n/X]A..X,I(C ' ,A ) where X is not free in B and A is strictly positive in X. De.nition 8 Let C be a well-formed \nconstructor kind for X and let A ' , I, and B ' be terms. We de.ne .X,I (C,A ' ,B ' ) recursively based \non the structure of C: def .X,I(X,A ' ,B ' )= A ' B ' def .X,I(.Y : B.C ' ,A ' ,B ' ) =.Y : B..X,I(C \n' ,A ' ,B ' Y ) .X,I(.TB.X .C ' ,A ' ,B ' )= Y : Tdef .Z:(.YT: TY : T' (ZT,A ' ,B ' B.I)..TB.(AY )) ..X,I(C \n' Z) where X is not free in B and BT. De.nition 9 We use .|t,k to denote that the environment does not \ncontain any z variables. Here are the complete typing rules for TL. The three weakening rules make sure \nthat all variables are bound to the right classes of terms in the context. There are no separate context-formation \nrules; a context . is well-formed if we can derive the judgment . f Kind : Kscm (notice we can only add \nnew variables to the context via the weakening rules). \u00b7fKind : Kscm (AX1) \u00b7fKscm : Ext (AX2) . fC : \nKind . fA : Bt/.Dom(.) (WEAK1) .,t: C fA : B . fC : Kscm . fA : Bk/.Dom(.) (WEAK2) .,k: C fA : B . fC \n: Ext . fA : Bz/.Dom(.) (WEAK3) .,z: C fA : B . fKind : Kscm X .Dom(.) (VAR) . fX :.(X) .,X: A fB : B \n' . f.X: A.B ' : s (FUN) . f.X: A.B :.X: A.B ' . fA :.X : B ' .A ' . fB : B ' (APP) . fAB :[B/X]A ' . \nfA : s1 .,X : A fB : s2 (s1,s2) .R (PROD) . f.X: A.B : s2 for all i .,X : Kind fCi : Kind wfcX (Ci) (IND) \nT . fInd(X : Kind){C}: Kind T . fI : Kind where I = Ind(X: Kind){C} (CON) . fCtor (i,I):[I/X]Ci . fA \n: I . fA ' : I .Kind for all i . fBi : .X,I(Ci,A ' ,Ctor (i,I)) (ELIM) T . fElim[I,A ' ](A){B}: A ' \nA T where I = Ind(X : Kind){C} . fA : I .|t,k fA ' : Kscm for all i small(Ci). fBi :.X,I (Ci,A ' ) (L-ELIM) \n. fElim[I,A ' ](A){BT}: A ' T where I = Ind(X : Kind){C} . f A:B . f B ' :s . f B :sB = \u00df.. B ' (CONV) \n . f A:B ' Next we state the formal properties of TL. We omit the proofs due to lack of space and refer \nthe reader to the companion technical report [37] for the details. Our proofs are mostly adapted from \nWerner [41] and Geuvers [17], but we have to add support for kind\u00adschema variables which is not part \nof Werner s system. Theorem 10 (Subject reduction) If the judgment . f A:B is derivable, and if A1 A \n' and .1 . ' , then the following are derivable: . f A ' :B and . ' f A:B. Theorem 11 (Strong normalization) \nAll well typed terms are strongly normalizing. Theorem 12 (Church-Rosser) Let . f A:B and . f A ' :B \nbe two derivable judgments. If A= \u00df.. A ' , and if Aand A ' are in normal form, then A=A ' . Theorem \n13 (Consistency of the logic) There exists no term A for which \u00b7f A:False. B Properties of .H The proof \nof the following lemma is by induction on the structure of typing derivations. Lemma 2 If .,X:B;G f e:A \n' and . f A:B, then .;G f [A/X]e :[A/X]A ' . We also need a proposition guaranteeing that equivalence \nof con\u00adstructor applications implies equivalence of their arguments; it is a corollary of the con.uence \nof TL (Theorem 12). ' ' ' Lemma 3 If Ctor (i,I)AT= \u00df.. Ctor (i,I )AT', then i =i and ' I = \u00df.. I ' and \nAT= \u00df.. AT. Lemma 4 (Progress) If \u00b7;\u00b7f e:A, then either eis a value, or there exists e ' such that e. \ne ' . Proof sketch By standard techniques [42] using induction on computation terms. Due to the transitivity \nof = \u00df.. any derivation of .;G f e :Acan be converted to a standard form in which there is an application \nof rule E-CONV at its root, whose .rst premise ends with an instance of a rule other than E-CONV, all \nof whose term derivation premises are in standard form. We omit the proofs for the cases of standard \nconstructs and the induction on the structure of evaluation contexts. The interesting case is that of \nthe dependently typed sel. If e = sel[A ' ](v,v ' ), by inspection of the typing rules the derivation \nof \u00b7;\u00b7f e :Ain standard form must have an instance of rule E-SEL in the premise of its root. Hence the \nsubderivation for v must assign to it a tuple type, and the whole derivation has the form DD ' E ''' \n' \u00b7;\u00b7f v :tup A2 A \u00b7;\u00b7f v :snat A1 \u00b7f A :LT A1 A2 \u00b7;\u00b7f sel[A ' ](v,v ' ):A '' A1 \u00b7;\u00b7f sel[A ' ](v,v ' \n):A where A = \u00df.. A '' A1. By inspection of the typing rules, rules otherthan E-CONV assigntoallvaluestypeswhichareapplications \nof constructors of .. Since the derivation D is in standard form, it ends with an E-CONV, in the premise \nof which another rule assigns va type \u00df..-equivalent to tup A2 A '' . Then by Lemma 3 this type must \nbe an application of tup, and again by inspection the only rule which applies is E-TUP, which implies \nv = (v0, ... vn-1), and the derivation D must have the form Di .i<n '' i \u00b7;\u00b7f vi :A1 i \u00b7;\u00b7f (v0,...vnA \n'' n-1) :tup i1 Also by Lemma 3 A2 = \u00df.. ni. Similarly the only rule assigning to a value a type convertible \nto that in the conclusion of D ' is E-NAT, hence A1 = \u00df.. mifor some m . N, and v ' = m. Then, by adequacy \nof LT (Lemma 1(3)), the conclusion of E implies that m<n. Hence by rule R-SEL e. vm. 0 Lemma 5 (Subject \nReduction) If \u00b7;\u00b7f e :Aand e. e ' , then \u00b7;\u00b7f e ' :A. Proof sketch Since evaluation contexts bind no \nvariables, it suf\u00ad.ces to prove subject reduction for . and a standard term substi\u00adtution lemma. We show \nonly some cases of redexes involving sel and if. The derivation for e = sel[A ' ]((v0,... vn-1),m)in \nstan\u00addard form has the shape ' ]((v0, ... v Di .i<n \u00b7;\u00b7f vi :A1 i '' i D ' '' \u00b7;\u00b7f (TnA1v) :tup i\u00b7;\u00b7f \n(Tv) :tup A2 A '' \u00b7;\u00b7f m:snat mi\u00b7;\u00b7f m:snat A1 E \u00b7f A ' :LT A1 A2 '' \u00b7;\u00b7f sel[A n-1),m):AA1 \u00b7;\u00b7f sel[A \n' ]((v0, ... vn-1),m):A '' '' where A= \u00df.. AA1, A1 = \u00df.. A '' , and A1 = \u00df.. mi. Since e. e ' only by \nrule R-SEL, we have m<nand e ' =vm,so '' '' '' from Dm and A1 mi= \u00df.. Ami= \u00df.. AA1 = \u00df.. A we obtain \na derivation of \u00b7;\u00b7f e ' :A. In the case of if the standard derivation D of \u00b7;\u00b7f if[B,A ' ](tt,X1.e1,X2.e2) \n:A ends with an instance of E-CONV, preceded by an instance of E-IF. Using the notation from Figure 5, \nfrom the premises of this rule it follows that we have a derivation E of \u00b7f A ' : BA '' , and A '' = \n\u00df.. true (since rule E-TRUE assigns sbool true to tt), hence we have \u00b7f A ' :B true by CONV. By Lemma \n2 from E and the derivation of X1 :B true;\u00b7f e1 :A(provided as another premise), since X1 is not free \nin A(ensured by the premise \u00b7f A:.) we obtain a derivation of \u00b7;\u00b7f [A ' /X1]e1 :A. 0 C Example of Proof \nConstruction Here we show the type term ltPrf which generates the proof of the proposition LTOrTrue t \n' t (lt t ' t), needed in the sumVec exam\u00adple in Section 4. We .rst present a Church encoding of the \nkind term LT and its constructors ltzs and ltss. LT : Nat.Nat.Kind LT =.t:Nat..t ' :Nat. .R:Nat.Nat.Kind. \n(.t:Nat.R zero (succ t)). '' ' (.t:Nat..t :Nat.R t t .R (succ t)(succ t )). Rtt ' ltzs :.t: Nat.LT zero \n(succ t) ltzs = .t: Nat..R: Nat.Nat.Kind. .z:(.t: Nat.R zero (succ t)). '' ' .s:(.t: Nat..t : Nat.R t \nt .R (succ t)(succ t )). zt ltss :.t: Nat..t ' : Nat.LT tt ' .LT (succ t)(succ t ' ) ltss = .t: Nat..t \n' : Nat..p: LT tt ' ..R: Nat.Nat.Kind. .z:(.t: Nat.R zero (succ t)). '' ' .s:(.t: Nat..t : Nat.R t t \n.R (succ t)(succ t )). stt ' (pRzs) Next we de.ne dependent conditionals on kinds Nat and Bool. dep ifez \n:.t: Nat..k: Nat.Kind. k zero .(.t ' : Nat.k (succ t ' )) .kt dep ifez zero = .k: Nat.Kind..t1 : k zero. \n.t2 :(.t ' : Nat.k (succ t ' )).t1 dep ifez (succ t)= .k: Nat.Kind..t1 : k zero. .t2 :(.t ' : Nat.k (succ \nt ' )).t2 t dep if :.t: Bool..k: Bool .Kind.k true.k false .kt dep if true = .k: Bool .Kind..t1 : k \ntrue..t2 : k false.t1 dep if false = .k: Bool .Kind..t1 : k true..t2 : k false.t2 Finally, some abbreviations, \nand then the proof generator itself. LTcond : Nat .Nat.Kind ' '' LTcond = .t : Nat..t: Nat.LTOrTrue tt \n(lt tt) LTimp : Nat .Nat.Bool .Kind LTimp = .t ' : Nat..t: Nat..t '' : Bool. ' ''' LTOrTrue t tt '' .LTOrTrue \n(succ t )(succ t) t ltPrf :.t ' : Nat..t: Nat.LTcond t ' t ltPrf = .t ' : Nat. ' '' Elim[Nat,.t 1 : Nat..t1 \n: Nat.LTcond t1 t1](t ){.t1 : Nat.dep ifez t1 (LTcond zero) id ltzs; .t1 ' : Nat..tP :(.t1 : Nat.LTcond \nt1 ' t1)..t1 : Nat. dep ifez t1 (LTcond (succ t1' )) id (.t1 : Nat.dep if (lt t1 ' t1) (LTimp t1 ' t1) \n(ltss t1 ' t1) (id True) (tP t1))} D CPS Conversion (Details) We start by de.ning a version of .H using \ntype-annotated terms. \u00af By f and e\u00afwe denote the terms without annotations. Type annota\u00adtions allow us \nto present the CPS transformation based on syntactic instead of typing derivations. (exp) e ::= \u00afe A \ne\u00af::= x|n|tt |. |f |.x x: A.f |ee ' |e[A] |(X= A, e: A ' )|open eas (X, x)in e ' |(e0, ... en-1)|sel[A](e,e \n' ) |eaop e ' |ecop e ' |if[A,A ' ](e, X1.e1,X2.e2) f\u00afA (fun) f ::= \u00af f ::= .x: A.e|.X: A.f The target \nlanguage .K of the CPS conversion stage has been de\u00ad.ned in Section 5. We use the following syntactic \nsugar to de\u00adnote non-recursive function de.nitions and value applications in .K (here x ' is a fresh \nvariable): .x: A.e=.x x ' [](x: A).e vv ' =v[](v ' ) .X1 : A1. ....Xn : An..x: A.e =.x x ' [X1 : A1, \n...Xn : An](x: A).e In the static semantics of .K we use two forms of judgments. As in .H , the judgment \n.; G fK v : Aindicates that the value v is well formed and of type Ain the type and value contexts . \nand G respectively. Moreover, .; G fK e indicates that the expression eis well formed in . and G. In \nboth forms of judgments, we omit the subscript from fK when it can be deduced from the context. The static \nsemantics of .K is speci.ed by the following forma\u00adtion rules (we omit the rules for environment formation, \nvariables, constants, tuples, packages, and type conversion on values, which are the same as in .H ): \nfor all i .{1 ...n} . f Ai : si .,X1 : A1 ...,Xn : An f A:. .,X1 : A1 ...,Xn : An;G,x ' : A ' ,x: A f \ne (K-FIX) .; G f .x x ' [X1 : A1, ...Xn : An](x: A).e: A ' where A ' = func (.s1 X1 : A1.....sn Xn : \nAn.A..) for all i .{1 ...n} . f Ai : Bi .; G fv ' : func (.s1 X1 : B1.....sn Xn : Bn.A..) (K-APP) .; \nG f v :[A1/X1] ...[An/Xn]A .; G f v ' [A1, ...An](v) .; G f v : A .; G,x: A f e (K-VAL) .; G f let x= \nv in e '' '' .; G f v : tup AB .; G f v : snat A ''' ' . f A: LT AA .; G,x: BA f e (K-SEL) .; G f let \nx= sel[A](v,v ' ) in e .; G f v : .sY : B.A .,X: B;G,x:[X/Y]A f e X/.. (K-OPEN) .; G f let (X, x)= open \nv in e s= Ext .; G f v : snat A .; G f v ' : snat A ' .; G,x: snat (plus AA ' ) f e (K-ADD) .; G f let \nx= v+ v ' in e .; G f v : snat A .; G f v ' : snat A ' .; G,x: sbool (lt AA ' ) f e (K-LT) .; G f let \nx= v< v ' in e . f B : Bool .Kind . f A: BA ' .; G f v : sbool A ' (K-IF) .,X1 : B true;G f e1 .,X2 \n: B false;G f e2 .; G f if[B,A](v, X1.e1,X2.e2) Except for the rules K-FIX and K-APP, which must take \ninto ac\u00adcount the presence of func, the static semantics for .K is a natural consequence of the static \nsemantics for .H . The de.nition of the CPS transformation for computation terms of .H to computation \nterms of .K is given in Figure 6, where we use the abbreviations introduced in Section 5. Proposition \n14 (Type Correctness of CPS Conversion) If \u00b7;\u00b7fH e: A, then \u00b7;\u00b7fK Kexp [[ \u00afe A ]] : func (Kc(A)..). Kfval[[( \n.x: A.eB)A.B]] = .xarg : K(A) \u00d7 Kc(B). let x= sel[ltPrf i0 i2 ](xarg,0) in let k = sel[ltPrf i1 i2 ](xarg,1) \nin Kexp [[ e B]] k ).sX:A.B Kfval[[(. X: A.fB]] = .X: A..k: Kc(B).k (Kfval[[ fB]]) Kexp [[ \u00afe A]] = .k: \nKc(A).k (\u00afe) A snat nisbool true , .sbool false for e\u00afA one of x,n , ttKexp [[ fA]] = .k: Kc(A).k (Kfval[[ \nfA)]] Kexp [[( .x x: A.fA)A]] = .k: Kc(A).k (.x x[](k: Kc(A)).k (Kfval[[ fA]])) A.BA Kexp [[( e1 e2 )B]] \n= .k: Kc(B). Kexp [[ e1 A.B]] ( .x1 : K(A. B). Kexp [[ e2 A]] ( .x2 : K(A). x1 (x2,k))) . s Kexp [[( \ne A. B[A])BA]] = .k: Kc(BA). . s ' Kexp [[ e A. B]] ( .x: K(. s AB). x[A](k)) A0 n-1 Kexp [[ (e , ...e \nA)A]] = .k: Kc(A). 0 n-1 Kexp [[ e A0 0 ]] ( .x0 : K(A0). . . . An-1 ]] ( .xk (x0, ...xn-1)) ...) Kexp \n[[ en-1 n-1 : K(An-1). tup A. B snat A. )BA. Kexp [[ sel[A](e1,e2 ]] = ' tup A. B'' .k: Kc(BA ).Kexp[[ \ne1]] ( .x1 : K(tup AB). snat A. ' Kexp[[ e2 ]] ( .x2 : K(snat A ). let x ' = sel[A](x1,x2) in k x ' )) \nKexp [[ (X= A, e[A/X]B: B)A. ]] = ' [A/X]B .k: Kc(A ).Kexp [[ e]] ( .x: K([A/X]B) . k (X= A, x: K(B))) \n.sY:A.B Kexp [[( open e1 as (X, x) in e2 A)A]] = .sY:A.B' .k: Kc(A).Kexp[[ e1 ]] ( .x1 : K(.sY : A .B). \nlet (X, x) = open x1 in Kexp[[ e2 A]] k) snat Asnat A. )snat (plus AA) ]] Kexp [[( e1 + e2 = .k: Kc(snat \n(plus AA ' )).Kexp [[ e1 snat A]] ( .x1 : K(snat A). snat A. Kexp [[ e2 ]] ( .x2 : K(snat A ' ). let \nx ' = x1 + x2 in k x ' )) snat Asnat A. )sbool (lt AA) ]] Kexp [[( e1 < e2 = .k: Kc(sbool (lt AA ' )).Kexp \n[[ e1 snat A]] ( .x1 : K(snat A). snat A. Kexp [[ e2 ]] ( .x2 : K(snat A ' ). let x ' = x1 < x2 in k \nx ' )) A. A. sbool A. ))A. Kexp [[( if[B,A](e ,X1.e1 ,X2.e2 ]] = ' sbool A. '' .k: Kc(A ).Kexp [[ e ]] \n( .x: K(sbool A ). A. A. if[B,A](x, X1.Kexp [[ e1 ]] k,X2.Kexp [[ e2 ]] k)) Figure 6: CPS conversion: \nfrom .H to .K. E Closure Conversion (Details) The main difference in the static semantics between .K \nand .C is that in the latter the body of a function must not contain free type or term variables. This \nis formalized in the rule C-FIX below. The rules C-TAPP and C-APP corresponding to the separate type \nand Cval[[ v]] = v, for vone of x, n, tt, . Cval[[ (v0, ... vn-1)]] = (Cval[[ v0 ]] , ...Cval[[ vn-1 \n]] ) Cval[[ (X= A, v: B)]] = (X= A, Cval[[ v]] : Cl (B) .) Cval[[ .x x ' [X1 : A1, ...Xn: An](x: A).e]] \n= (X= Aenv, (vcode[Y1] ...[Ym],venv): AX)where AX = A ' X \u00d7 X A ' X = .s1 X1 : A1.....sn Xn: An.(X \u00d7 \nCl (A) .) .. A. A. 0 k-1 {x , ...x } = FV (e) -{x, x ' } 0 k-1 {YB. 1 , ...YB. m } = 1 m FTV (.x x ' \n[X1 : A1, ...Xn: An](x: A).e) '' Aenv = Cl (tup ik (nth (A 0:: ...Ak-1::nil))) . venv = (x0 ...xk-1) \nvcode = .x v.x[Y1 : B ' 1, ...Ym: B ' m,X1 : A1, ...Xn: An] (xarg : Aenv \u00d7 Cl (A) .). let xenv = sel[ltPrf \ni0 i2 ](xarg,0) in let x= sel[ltPrf i1 i2](xarg,1) in let x ' = (X= Aenv, (v.x[Y1] ...[Ym],xenv): AX) \nin let x0 = sel[ltPrf i0 ik](xenv,0) in ... k- 1 i let xk-1 = sel[ltPrf nk](xenv,k- 1) in Cexp[[ e]] \nCexp[[ v1[A1, ...An](v2)]] = let (Xenv,xarg) = open Cval[[ v1 ]] in let xcode = sel[ltPrf i0 i2](xarg,0) \nin let xenv = sel[ltPrf i1 i2](xarg,1) in xcode[A1] ...[An] (xenv,Cval[[ v2 ]] ) Cexp[[ let x= v in e]] \n= let x= Cval[[ v]] in Cexp[[ e]] Cexp[[ let x= sel[A](v,v ' ) in e]] = let x= sel[A](Cval[[ v]] ,Cval[[ \nv ' ]]) in Cexp[[ e]] Cexp[[ let (X, x) = open v in e]] = let (X, x) = open Cval[[ v]] in Cexp[[ e]] \nCexp[[ let x= v1 + v2 in e]] = let x= Cval[[ v1 ]] + Cval[[ v2 ]] in Cexp[[ e]] Cexp[[ let x= v1 < v2 \nin e]] = let x= Cval[[ v1 ]] < Cval[[ v2 ]] in Cexp[[ e]] Cexp[[ if[B,A](v, X1.e1,X2.e2)]] = if[B,A](Cval[[ \nv]] ,X1.Cexp[[ e1 ]] ,X2.Cexp[[ e2 ]] ) Figure 7: Closure conversion: from .K to .C. value application \nin .C are standard. for all i<n \u00b7f Ai : si \u00b7,X1 : A1 ...,Xn: An f A:. \u00b7,X1 : A1 ...,Xn: An; \u00b7,x ' : B,x: \nA f e (C-FIX) .; G f .x x ' [X1 : A1, ...Xn: An](x: A).e: B where B = .s1 X1 : A1.....sn Xn: An.A.. ' \n' .; G f v : .sX: A.B . f A: A .; G f v[A]: [A/X]B (C-TAPP) .; G f v1 : A.. .; G f .; G v1 v2 f v2 : \nA (C-APP) The de.nition of the closure transformation for the computation terms of .K is given in Figure \n7. Proposition 15 (Type Correctness of Closure Conversion) If \u00b7;\u00b7fK v : A, then \u00b7;\u00b7fC Cval[[ v]] : Cl \n(A) ..  \n\t\t\t", "proc_id": "503272", "abstract": "A <i>certified binary</i> is a value together with a proof that the value satisfies a given specification. Existing compilers that generate certified code have focused on simple memory and control-flow safety rather than more advanced properties. In this paper, we present a general framework for explicitly representing complex propositions and proofs in typed intermediate and assembly languages. The new framework allows us to reason about certified programs that involve effects while still maintaining decidable typechecking. We show how to integrate an entire proof system (the calculus of inductive constructions) into a compiler intermediate language and how the intermediate language can undergo complex transformations (CPS and closure conversion) while preserving proofs represented in the type system. Our work provides a foundation for the process of automatically generating certified binaries in a typetheoretic framework.", "authors": [{"name": "Zhong Shao", "author_profile_id": "81351597965", "affiliation": "Yale University, New Haven, CT", "person_id": "PP14127817", "email_address": "", "orcid_id": ""}, {"name": "Bratin Saha", "author_profile_id": "81100311903", "affiliation": "Yale University, New Haven, CT", "person_id": "P32179", "email_address": "", "orcid_id": ""}, {"name": "Valery Trifonov", "author_profile_id": "81100016457", "affiliation": "Yale University, New Haven, CT", "person_id": "P290011", "email_address": "", "orcid_id": ""}, {"name": "Nikolaos Papaspyrou", "author_profile_id": "81100572837", "affiliation": "Yale University, New Haven, CT", "person_id": "P343131", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/503272.503293", "year": "2002", "article_id": "503293", "conference": "POPL", "title": "A type system for certified binaries", "url": "http://dl.acm.org/citation.cfm?id=503293"}