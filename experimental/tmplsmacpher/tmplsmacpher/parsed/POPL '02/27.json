{"article_publication_date": "01-01-2002", "fulltext": "\n Stack Inspection: Theory and Variants C\u00b4edric Fournet Andrew D. Gordon Microsoft Research ABSTRACT \nStack inspection is a security mechanism implemented in runtimes such as the JVM and the CLR to accommodate \ncomponents with diverse levels of trust. Although stack in\u00adspection enables the .ne-grained expression \nof access control policies, it has rather a complex and subtle semantics. We present a formal semantics \nand an equational theory to ex\u00adplain how stack inspection a.ects program behaviour and code optimisations. \nWe discuss the security properties en\u00adforced by stack inspection, and also consider variants with stronger, \nsimpler properties. 1. SECURITY BY STACK INSPECTION? Stack inspection is a software-based access control \nmech\u00adanism. Its purpose is to allow components with diverse ori\u00adgins to share the same runtime and access \nits resources in a controlled manner, according to their respective levels of trust. It is a key security \nmechanism in typed runtime en\u00advironments such as the JVM [19, 11] and the CLR [8] that support distributed \ncomputation based on mobile code. It enables the .ne-grained expression of access control policies, and \nhence is more liberal and .exible than a strict sand\u00adboxing mechanism. It has received much attention \nin the literature [5, 7, 9, 16, 17, 27, 29, 30]. Now, stack inspection is often marketed as a feature \nthat: (1) allows security-conscious developers, such as the au\u00adthors of trusted libraries, to express \ntheir security re\u00adquirements easily and precisely, and (2) can safely be ignored by everyone else. \n We began this work with the realisation that these two claims are problematic and need careful quali.cation: \n(1) The .rst problem is that stack inspection, as its name suggests, is usually thought of in speci.c, \nlow level terms. It seems to be remarkably hard to give a gen\u00aderal account of what actually is guaranteed \nby stack in\u00adspection. Hence, it can be di.cult to assess whether it Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 02, Jan. 16-18, 2002 Portland, OR USA \n. 2002 ACM ISBN 1-58113-450-9/02/01...$5.00 is correctly implementing a higher level security policy. \nBesides, certain higher-order features, such as threads and method delegation, need careful treatment. \n(2) The second problem is that stack inspection profoundly a.ects the semantics of all programs. In particular, \nit invalidates a wide variety of program transformations, such as inlining and tail call optimisations. \nWe address these two problems in the setting of a .\u00adcalculus model [27, 29] of stack inspection. We formally \nstate some of the guarantees given by stack inspection and suggest variations of stack inspection with \nstronger, simpler properties. We develop an equational theory of stack in\u00adspection that helps to highlight \nits subtle e.ects and also justi.es certain transformations. Having outlined our motivations, we next \nreview the ideas of stack inspection. Then we elaborate on the di.culties it raises. We close this introductory \nsection by describing our contributions in more detail. An Outline of Stack Inspection. The situation \naddressed by stack inspection mechanisms is as follows. Applications are collections of components, possibly \ncompiled from dif\u00adferent languages, that share the same runtime. Compo\u00adnents have a variety of origins, \nmore or less trusted. Some mechanism such as scoping or typing rules prevents di\u00adrect access from untrusted \ncomponents to resources pro\u00adtected by trusted components. Still, untrusted code may call trusted code, \nand the other way round. We express access to di.erent kinds of protected resources in terms of permissions, \nsuch as may perform screen I/O or may perform .le I/O . A con.gurable policy determines the access rights \navailable to each component given evidence of its origin, that is, where it came from and who wrote it. \nThe access rights are simply a set of allowed permissions. Here we abstract from the details of policy \nand evidence, and simply refer to this set of permissions itself as the principal that owns the code. \nFor example, a System principal might consist of all per\u00admissions, whereas an Applet principal might \nconsist of a very limited set of rights, including may perform screen I/O, but not including may perform \n.le I/O. During compilation and loading, but before execution, each function or method body securely \nreceives an annota\u00adtion (here called a frame) specifying the principal owning it. During execution, when \ntrusted code is about to access some protected resource, it invokes the stack inspection prim\u00aditive (here \ncalled test) to determine whether the appropriate permission is present. A .rst requirement is that its \nimme\u00addiate caller be statically annotated with the permission. In fact, the basic algorithm is to inspect \nthe whole call stack to ensure that indirect callers as well as the immediate caller are all statically \nannotated with the permission. The pur\u00adpose of inspecting the whole stack is to prevent the possibil\u00adity \nthat untrusted code lacking the permission could some\u00adhow cause an indirect call to a trusted function \nthat itself accesses the resource an instance of the Confused Deputy attack [14, 30]. Abstractly, this \nbasic algorithm computes a compound principal whose access rights are the intersec\u00adtion of the access \nrights of all the principals on the stack, and then checks whether this compound principal has the appropriate \npermission. The full algorithm allows trusted code to invoke a prim\u00aditive (here called grant) to override \nthe inspection of its callers for some permissions and hence to assert responsi\u00adbility for use of those \npermissions in every context. For example, suppose some System-owned function im\u00adplementing screen I/O \nneeds to write into a log-.le, for per\u00adformance debugging purposes, and hence needs the may perform .le \nI/O permission. If this function is called by an Applet-owned function, access to the log-.le is denied \nbecause Applet does not have the may perform .le I/O permission. The function would override inspection \nof its callers for the may perform .le I/O permission so that the .le write is allowed even if its caller \nis Applet-owned. Limitations of Stack Inspection. The permissions autho\u00adrised by stack inspection (the \ntest primitive) are determined by a clever algorithm, outlined above, that scans control stacks on demand. \nThe authorisation decision depends solely on the current series of nested calls. Therefore, it does not \ndepend on other kinds of interaction between software com\u00adponents. Such interactions include, for instance, \nthe use of results returned by untrusted code, mutable state, in\u00adheritance, side e.ects, concurrency, \nand dynamic loading. These interactions are commonplace, and their impact on security must be addressed \nindependently. In the formal\u00adism of this paper, the problem appears when trusted and untrusted code exchange \nfunctions as values. As a result, a careful analysis of any code that explicitly manipulates permissions \nmay not in fact yield any strong guarantee (although it may reveal security problems). This signi.cantly \nrestricts the scope of stack inspection, in iso\u00adlation. On the other hand, stricter mechanisms, based \nfor instance on systematic .ow analyses, yield stronger guaran\u00adtees, but may be harder and more costly \nto implement and to use. Living in Harmony with Stack Inspection. Assuming the target platform features \nstack inspection, the programmer faces two con.icting problems. Some untrusted component may take advantage \nof the programmer s code to breach security this is potentially quite bad, but it is hard to char\u00adacterize. \nA more immediate concern is that some permission may be missing in the middle of a computation involving \nthis code (even if the code statically has those permissions); typically, an unexpected security exception \nis raised this complies with the policy, but remains undesirable. In addition, the compiler writer must \ndeal with a speci.c problem: stack inspection makes the control stack observ\u00adable, hence the actual runtime \nstack must agree with the stack as it appears to the source program. This correctness issue hinders any \nprogram transformation that changes the structure of the stack. (A prerequisite to using stack in\u00adspection \nis to make the control stack apparent in the source language. This may be troublesome in declarative \nlanguages like, for instance, Haskell or Mercury.) There are two further problems. Programmers and com\u00adpiler \nwriters may be concerned about the runtime costs in\u00adcurred by stack inspection and by other operations \non per\u00admissions. Besides, they have little control of the security policy that will be applied to their \ncode, and must program without knowing exactly which static permissions their code will receive. Contributions \nof the Paper. We discuss stack inspection in the precise and abstract setting of .sec, a call-by-value \n.-calculus [26] with notions of permissions, principals, and stack inspection, introduced by Pottier, \nSkalka, and Smith [27, 29]. Previous studies of .sec focus on type systems for checking information about \npermissions. Here, we use the untyped .sec-calculus as a minimal formalism for investigat\u00ading the runtime \nbehaviour of stack inspection. We present the .rst equational theory for a calculus of stack inspection. \nWe prove soundness of a primitive set of equations with respect to Morris-style contex\u00adtual equivalence \n(Theorem 1), and completeness with respect to the reduction semantics (Theorem 2).  To obtain a co-inductive \nproof technique to justify our equational theory, we recast Abramsky s applicative bisimilarity for the \n.sec-calculus. We show that bisim\u00adilarity is a congruence by Howe s method (Theorem 3). Hence, we prove \nthat bisimilarity in fact equals contex\u00adtual equivalence (Theorem 4), admitting bisimulation\u00ad style proofs \nof program equivalence.  Applications of the equational theory include justi.\u00adcation of compiler transformations \nsuch as elimina\u00adtion of redundant frames and tests and programming techniques such as performing security \ntests eagerly to speed up stack inspection. Moreover, we use the equational theory to discuss the e.ect \nof stack inspec\u00adtion on inlining and tail call optimisations.  We explain how stack inspection can be \nunderstood as a form of data dependency analysis and relying in part on our equational theory discuss \nsomewhat lim\u00adited properties guaranteed by stack inspection (Theo\u00adrems 5 and 6). We describe how stack \ninspection only partly ful.ls its intent with respect to the higher-order features of .sec. (Similar \nlimitations arise in practice with side-e.ects, exception handling, and method del\u00adegates). We give precise \nrules for how stack inspection could be amended to overcome these limitations, and formalize guarantees \nprovided by the amended seman\u00adtics (Theorems 7 and 8).  Some details and all proofs appear in a technical \nreport [10]. Although the technical contributions of this paper are phrased in terms of a formalism, \nthe formalism is not an end in itself: the development is inspired by a study of stack in\u00adspection in \nthe CLR, in relation to the compilation of func\u00adtional languages. It also suggests potential improvements \nand validates optimisations performed by its JIT compiler. 2. A CALCULUS OF STACK INSPECTION We describe \nthe syntax and informal semantics of a ver\u00adsion of the .sec-calculus [27], present an operational seman\u00ad \ntics, and explain how we use .sec to model loading modules of diverse origins. 2.1 Syntax and Informal \nSemantics We assume there is a set P of atomic permissions. Let a principal be a subset of P. Permissions \nand principals p, q .P permission R, S, T, D .P principal: a set of permissions This presentation is \na little more abstract than the original .sec, where a principal is a name, and a function maps each \nprincipal to its set of permissions. For our purposes we may as well eliminate this indirection. Expressions \ninclude variables, functions, and applications, as usual, plus constructs for stack inspection. A framed \nex\u00adpression R[e] is the expression e framed with the principal R; the principal represents permissions \nconferred on the code e given its origin. We have grant and test expressions as dis\u00adcussed in the introduction. \nFinally, fail is an exception, used, for example, to indicate a security failure. Expressions e, f ::= \nexpression variable .x.e function ef application R[e] framed expression grant R in e permission grant \ntest R then e else f permission test fail abnormal termination Abstractly, the behaviour of an expression \ndepends on two sets of permissions: the static permissions, S, and the dynamic permissions, D, with D \n. S. The static permis\u00adsions are the principal in the nearest enclosing frame, an upper bound on the \npermissions available to the expression. The dynamic permissions are those e.ectively available at runtime; \nthey represent what can be retrieved by a stack inspection. We consider a top-level expression to be \nfully trusted, so take the static and dynamic permission sets to be P initially. The expression R[e] \nbehaves as e, but with static permis\u00adsions set to R, and dynamic permissions intersected with R. The \nexpression grant R in e behaves as e, but with the dy\u00adnamic permissions extended with all the static \npermissions that appear in R. The expression test R then e else f be\u00adhaves as e if all permissions in \nR are dynamic permissions, but otherwise behaves as f. The other expressions do not inspect or modify \nthe permission sets. They behave as in a standard call-by-value .-calculus with a single uncatchable \nexception fail and left-to-right evaluation order. We follow some standard syntactic conventions. In \na func\u00adtion .x.e, the variable x is bound, with scope e. We write fv(e) for the set of variables occurring \nfree in e, and write e{x.e'} for the outcome of a capture-avoiding substitution ' of the expression efor \neach free occurrence of the variable x in e. An expression e is closed when fv(e)= \u00d8. We iden\u00adtify expressions \nup to capture-avoiding renamings of bound variables, that is, .x.e = .x'.(e{x.x'}) if x' ./fv(e). We \nintroduce notions of values and outcomes. A value is a function or a variable; values represent the formal \nand actual arguments passed to a function. An outcome is a value or the exception fail; outcomes are \nfully-reduced expressions. Values and outcomes u, v ::= x | .x.e value o ::= v | fail outcome The .rst \nfour of the following abbreviations are fairly stan\u00addard. The .fth de.nes an arbitrary value ok to indicate \nnor\u00admal termination in our examples. The last, check p for e, represents a common idiom, a primitive \nin earlier formula\u00adtions of .sec [27, 29]: test whether permission p is e.ectively available; if so, \nrun e; otherwise, raise a security exception. Abbreviations . .x1 \u00b7\u00b7\u00b7 xn.e = .x1. . . . .xn.e . let x \n= e1 in e2 =(.x.e2) e1 . . .e = .x.e for any x . fv(e) . e1; e2 = let = e1 in e2 . ok = .x.x . check \np for e = test {p} then e else fail 2.2 Operational Semantics We formalize the behaviour of expressions \nas a small-step reduction relation, indexed by the security context: the re\u00adlation e .S ' means that, \nin a context with static permis- D esions S and dynamic permissions D, the expression e may ' evolve \nto e. D, we always assume D . S. When we write .S Security-indexed reduction rules (Ctx Rator) (Ctx Rand) \n'' D e e1 e2 .S 1 ' e2 D v1 e ' e1 .SD e1 e2 .S 2 D ev1 e2 .S 2 (Red Appl) (Fail Rator) (Fail Rand) (.x.e) \nv .SD e{x.v} fail e .S v fail .S D fail D fail (Ctx Frame) (Ctx Grant) e .R ' e .S ' DnR e D.(RnS) e \n'' R[e] .S grant R in e .S D R[e] D grant R in e (Red Frame) (Red Grant) R[o] .S grant R in o .S D o \nD o (Red Test) D eR.D test R then etrue else efalse .S Rules (Ctx Rator), (Ctx Rand), and (Red Appl) \nimple\u00ad ment call-by-value function evaluation; as usual, we do not reduce within function bodies. Rules \n(Fail Rator) and (Fail Rand) propagate exceptions through applications. The con\u00ad text rules (Ctx Frame) \nand (Ctx Grant) specify how a frame and a grant, respectively, manipulate permission sets, as de\u00adscribed \nabove. Rules (Red Frame) and (Red Grant) discard a frame and a grant, respectively, once its body has \nreduced to an outcome this re.ects the deletion of the actual stack frame for that body. Finally, (Red \nTest) speci.es how a test inspects the dynamic permission set. As usual, contexts C(\u00b7) are expressions \nwith a placeholder (\u00b7) and evaluation contexts E(\u00b7) are derived from the (Ctx-) rules: E(\u00b7) ::= \u00b7|E(\u00b7) \ne | v E(\u00b7) | R[E(\u00b7)] | grant R in E(\u00b7). The top-level reduction relation, e . e ' , describes the single-step \nevolution of a fully trusted expression e (which may of course contain partially trusted subexpressions). \nIt is de.ned from the security-indexed relation by setting the static and dynamic permissions to be the \nfull set, P. The top-level evaluation relation, e . o, computes the outcome o of evaluating an expression \ne. Our semantic rules (in particular, (Ctx Frame) and (Ctx Grant)) specify how to update the dynamic \npermission set upon change of security context. This strategy is known as the security-passing style \n[30] or the eager semantics [3, 11]. The alternative strategy the lazy semantics used by most implementations \nis to compute the dynamic permissions indirectly by inspecting the stack. We show in an appendix that \nour eager semantics corresponds exactly to a lazy se\u00admantics given by Pottier, Skalka, and Smith [27]. \nThe eager semantics is more convenient for the theory of this paper. Still, the lazy semantics appears \nto lead to more e.cient implementations [11, 30]. Top-level reduction and evaluation . e . e ' = e .P' \ntop-level reduction P e . e . o = e . * o top-level evaluation 2.3 Framing The syntax of .sec enables \nframed subexpressions any\u00adwhere in an expression. In practice, framed subexpressions would appear only \nas the result of applying a security policy, for example, when code is .rst loaded. (Without a similar \nrestriction, untrusted code could grant itself any right.) We can describe the application of a policy \nas a func\u00adtion from the frameless fragment of .sec to the full calculus, that inserts the same, given \nframe under every abstraction: R[ .x.e] = .x.R[R[ e]]] and R[ \u00b7] commutes with all other constructs. \nFraming an expression with principal R . R[ x] = x . R[ .x.e] = .x.R[R[ e]]] . R[ e1 e2] = R[ e1] R[ \ne2] . R[ grant S in e] = grant S in R[ e] . R[ test S then e1 else e2] = test S then R[ e1] else R[ \ne2] . R[ fail] = fail Initially, we model a runtime con.guration by an expres\u00adsion of the form eR1[ \nv1] ... Rn[ vn] where e accounts for the runtime, linker, and low-level re\u00adsources, while v1,...,vn \nare miscellaneous additional mod\u00adules, with respective static permissions R1,...Rn attributed by the \nsecure loader.  3. PROGRAMMING EXAMPLES Our series of examples models interaction between I/O li\u00adbrary \nfunctions and applets. The intent is to prevent applets from accessing the content of arbitrary .les. \nWe consider permissions screenIO and .leIO and principals Applet = {screenIO} and System = {screenIO, \n.leIO}. Direct Access. First, consider an I/O library function that protects read access to the .le system \nby requiring the .leIO permission. We assume some encoding for strings, and let primRF be a primitive \nfor returning the contents of a .le as a string. . readFile = .n.System[check .leIO for primRF n] For \ninstance, we have Applet[readFile secrets ] . fail (1) System[readFile version ] . Build 2601 (2) In \nthis setting, the applet code (here, readFile secrets ) may refer to readFile but not to primRF, and \nmust be framed with principal Applet. Such expressions can be obtained by framing and linking; for instance, \nthe expression in (1) is obtained from the initial con.guration (.sa.a s) System[ .n.check .leIO for \nprimRF n] Applet[ .readFile.readFile secrets ]] One may check that no (frameless, closed) applet code \nsubstituted for readFile secrets can cause any .le to be read. We state a more general result in Section \n6. Indirect Access. Consider now a System-routine that calls another System-routine. We assume that \nprimDS is the primitive that displays a string and returns ok. . displayString = .s.System[check screenIO \nfor primDS s] . displayFile = .n.System[displayString (readFile n)] For example: Applet[displayString \nhi ] . ok (3) Applet[displayFile secrets ] . fail (4) System[displayFile version ] . ok (5) If stack \ninspection did not compound principals, the call in example (4) would succeed. Overriding Policy. Sometimes \nit is acceptable for trusted code to make exceptions to a standard policy. For instance, we may wish \nto allow any code read access to a .le contain\u00ading the operating system version. readVersion . = ..System[grant \n{.leIO} in readFile version ] For example: Applet[readVersion ok] . Build 2601 (6) The above are examples \nof calls from less trusted to more trusted code. A symmetric situation is where more trusted code calls \nless trusted, such as when trusted libraries call methods such as ToString or Equals on untrusted objects. \nAttempts by such methods to exploit the greater privileges of their callers are also thwarted by stack \ninspection. Untrusted Results. The following example describes some trusted code depending on data supplied \nby untrusted code. We have a System-function foolishDisplayFile that calls a function parameter h to \ncompute a .lename s, and then calls displayFile s to display it. . foolishDisplayFile = .h.System[displayFile \n(h ok)] Now, since the call to h completes before the call to display-File begins, the principal associated \nwith h has disappeared from the stack before the access tests in displayFile occur. So the following \ncall, which allows an untrusted function to determine which .le is displayed, succeeds. foolishDisplayFile \n(..Applet[ secrets ]) . ok (7) Stack inspection does prevent the function parameter from making privileged \ncalls while it is running, but it does not prevent it in.uencing computation, perhaps against policy, \nonce it has terminated and returned a result. Higher Order. Our last example is more involved. Trusted \ncode (main) calls an applet; the applet calls trusted code (.leHandler) to build a System-closure for \nits choice of pa\u00adrameters ( secrets and leak) and returns that closure; later, a trusted call triggers \nthe closure: . main = System[ .h.(h ok ok)]] .leHandler . = System[ . s c . c (readFile s)]] leak . = \nApplet[ .s.displayString s]  main ..Applet[.leHandler secrets leak] . ok (8) Since the security context \nused to create the closure is dis\u00adcarded as Applet[.leHandler secrets leak] returns, the clo\u00adsure gets \naccess to secrets . In more detail, we have the following, where okS is short for System[ ok]]. main \n..Applet[.leHandler secrets leak] .2 System[Applet[.leHandler secrets leak] okS ] System[Applet[System[System[ \n. 2 . 3  ..System[leak (readFile secrets )]]]] okS ] System[..System[leak (readFile secrets )] okS \n] . 5 System[System[leak (content of secrets )]] . 6 .3  System[System[Applet[ok]]] ok In this situation, \nit is quite hard to modify the code so that a suitably framed closure is returned. A safe approach may \nbe to request the permissions that will be used within the closure before returning the closure. However, \nthis re\u00adquires speci.c knowledge of those permissions. Instead of .leHandler, one may write, for instance: \n. safeFileHandler = .s.test {.leIO}then System[ .c .c (readFile s)]] else System[ .c .fail] Another, \nmore uniform approach is to provide a general mechanism to capture the current dynamic permissions (D) \nand restore them as the closure is triggered. In the JVM and in the CLR, such a mechanism is used internally \nfor special cases of closures, for instance to start a new thread. As the corresponding closure is created, \nthe stack is scanned to compute D, then D is used to build the .rst frame of the new stack. This design \nissue is discussed in [11, section 3.11]. The example above may seem a little contrived, but in fact \nis very common in an object-oriented setting: whenever a call returns an object from untrusted code, \nfurther calls to its methods will be performed using virtual calls, and there is no simple, uniform way \nto test whether that object encapsulates low-trust parameters (or even code). 4. EQUATIONAL REASONING \nIn order to transform programs while preserving their se\u00admantics, we rely on Morris-style contextual \nequivalence [23]. Since it is preserved by all contexts, local transformations based on contextual equivalence \nmay be used anywhere in a program. Contextual equivalence Let e. if and only if there is an outcome o \nwith e . o. Let e . e ' if and only if, for all contexts C, if both C(e) and C(e ' ) are closed, then \nC(e). .. C(e ' ).. Contextual equivalence is strictly more discriminating than in the call-by-value \n.-calculus (CBV), even for pure .-terms. For instance, the terms .x.let z = x ok in . .z and .x.let z \n= x ok in ..(x ok) are equivalent in CBV but can be separated using the con\u00adtext \u00d8[(\u00b7)(..test P then \nO else ok)] ok where O is an ex\u00adpression that diverges. This suggests that usual optimiza\u00adtions may break, \nand motivates our study of contextual equivalence. 4.1 Equational Properties of .sec We present a new \nequational theory for .sec that is sound for contextual equivalence and complete with respect to the \nreduction semantics. We .rst state the theory and brie.y comment on its equations. Let e = e ' be the \nsmallest congruence that is, a re\u00ad .exive, symmetric, and transitive relation preserved by all contexts \nto satisfy the primitive equations listed below. Primitive equations (Fun Beta) (.x.e) v = e{x.v}(Fun \nEta) x/. fv(v)=. .x.v x = v (Let Eta) let x = e in x = e (Let Let) x1 ./fv(e3)=. let x1 = e1 in (let \nx2 = e2 in e3) = let x2 =(let x1 = e1 in e2) in e3 (Frame o) R[o] = o (Frame Frame Appl) R1[R2[e1 e2]] \n= R1[R2[(R1[R2[e1]]) (R1[R2[e2]])]] (Frame Let) R[let x = e1 in e2] = let x = R[e1] in R[e2] (Frame Frame) \nR1 . R2 =. R1[R2[e]] = R2[e] (Frame Frame Frame) R1[R2[R3[e]]] = (R1nR2)[R3[e]] (Frame Frame Grant) R1[R2[grant \nR3 in e]] = (R1.R3)[R2[grant R3 in e]] (Frame Grant) R1[grant R2 in e] = R1[grant R1nR2 in e] (Frame \nGrant Frame) R1 . R2 =. R1[grant R2 in R3[e]] = R1[R3[grant R2 in e]] (Frame Grant Test) R1 . R2 . R3 \n=. R1[grant R2 in test R3 then e1 else e2] = R1[grant R2 in e1] (Frame Test Then) R1 . R2 =. R1[test \nR2 then e1 else e2] = test R2 then R1[e1] else R1[e2] (Frame Test Else) \u00ac(R1 . R2)=. R1[test R2 then \ne1 else e2] = R1[e2] (Grant \u00d8) grant \u00d8 in e = e (Grant o) grant R in o = o (Grant Appl) grant R in (e1 \ne2) = grant R in ((grant R in e1) grant R in e2) (Grant Let) grant R in (let x = e1 in e2) = let x =(grant \nR in e1) in (grant R in e2) (Grant Grant) grant R1 in grant R2 in e = grant R1.R2 in e (Grant Frame) \ngrant R1 in R2[e] = grant R1nR2 in R2[e] (Grant Frame Grant) grant R2 in R1[grant R2 in e] = R1[grant \nR2 in e] (Test \u00d8) test \u00d8 then e1 else e2 = e1 (Test Re.) test R then e else e = e (Test .) test R1.R2 \nthen e1 else e2 = test R1 then (test R2 then e1 else e2) else e2 (Test Grant) test R then e1 else e2 \n= test R then (grant R in e1) else e2 (Eq Fail Rator) fail e = fail (Eq Fail Rand) v fail = fail Derived \nequations (Let Beta) let x = v in e = e{x.v} (Frame Dup) R[R[e]] = R[e] (Frame Appl) R[e1 e2] = R[R[e1] \nR[e2]] (Frame Frame n) R1[R2[e]] = (R1nR2)[R2[e]] (Frame Frame Test Else) \u00ac(R1 . R3)=. R1[R2[test R3 \nthen e1 else e2]] = R1[R2[e2]] Proposition 1. The equations in the preceding table are derivable within \nthe equational theory. The .sec-calculus extends Plotkin s call-by-value .v; ac\u00adcordingly, we retain \n\u00dfv and .v equations, here named (Fun Beta) and (Fun Eta). As in Plotkin s calculus, the following more \ngeneral laws are unsound: (.x.e) e ' = e{x.e ' } and x/. fv(e)=. .x.e x = e. We also have the standard \nmonad laws for let from Moggi s computational .-calculus [22], here named (Let Beta), (Let Eta), and \n(Let Let). Speci.c rules manipulate nested security constructors. In R1[R2[e]], the e.ect of a grant \nin e is determined by R2 but not by R1. Therefore, R1[R2[e]] = (R1nR2)[e] is not sound in general. Still, \n(Frame Frame) coalesces two frames into one when the outer principal dominates the inner, and (Frame \nFrame Frame) unconditionally coalesces three frames into two. Rules (Frame Let) and (Grant Let) are limited \nforms of the more general equations R[e1 e2] = R[e1] R[e2] and grant R in (e1 e2) = (grant R in e1)(grant \nR in e2), which are not sound. Rule (Frame Frame Appl) pushes dou\u00adbly nested frames into applications. \nWhen the enclosing permission modi.ers are available, the outcome of a grant may be determined, independently \nof the enclosing context. We obtain partial commutativity laws (Frame Grant), (Grant Frame), (Frame Grant \nFrame), (Grant Frame Grant). Similarly, the outcome of a test may be determined. Regarding (Frame Test \nElse), if the princi\u00adpal R1 cannot access the resource R2, testing for that re\u00adsource must fail. On the \nother hand, R1 . R2 does not imply R1[test R2 then e1 else e2] = R1[e1], because the call\u00ading context \nmay not have been granted R2. A corollary of (Frame Grant) and (Grant \u00d8) is the rule R1 n R2 = \u00d8 =. R1[grant \nR2 in e] = R1[e]. If the principal R1 cannot access the resources R2, it is futile for code framed by \nR1 to try to grant R2. Using bisimulation proof techniques discussed in the next section, we can show \nthe equational theory to be sound with respect to contextual equivalence. Theorem 1. If e = e ' then \nee ' . We cannot expect the converse, completeness with respect to contextual equivalence. The set of \nprovable equations e = e ' is recursively enumerable whereas the set of contextual equivalences ee ' \nis not. Still, we do obtain a limited completeness result with re\u00adspect to the security-indexed reduction \nsemantics. To state the theorem, we introduce security-setters, CS D(\u00b7), evaluation contexts that set \nthe static and dynamic permissions within the context to S and D, respectively. More precisely, when \nrunning CS and D ' , the D(e) with arbitrary permission sets S ' expression e runs with permission sets \nS and D. Security-setters CS . D(\u00b7)= D[grant D in S[\u00b7]] where D . S Theorem 2. If e .S ' then CSD(e ' \n). D e D(e) =CS The proof shows there are su.cient equations to distribute information about the security \ncontext to where it is needed to justify reduction steps; indeed, the proof prompted the discovery of \nvarious equations. If we view the equational theory as a new axiomatic semantics of .sec, the theorem \nshows that the reduction relation is a correct algorithm for computing certain equations. 4.2 Basic Applications \nIn addition to justifying contextual equivalences mentioned in Section 5, we can apply the theory as \nfollows. Framing versus Currying. As illustrated in example (8), the framing translation of Section 2.3 \nyields multiple nested frames when applied to functions with multiple arguments. Using (Frame o), we \ncan discard these duplicate frames: . R[ .xy.e] = .x.R[.y.R[R[ e]]]] = .xy.R[R[ e]]] Hence, we can choose \nthe latter form as a more e.cient translation when dealing with multiple arguments (or more generally \nwith functions that have multiple entry points). Shortening Stack Inspections. In typical implementa\u00adtions \nof stack inspection, permissions are tested on demand, with a runtime cost that grows linearly with the \ndepth of the stack. When the same permissions are frequently tested, it may be worth testing those permissions \nin advance, then granting them, so that all further tests succeed faster. In\u00addeed, this is a recommended \nidiom for optimizing programs that perform frequent checks in the CLR [20]. In the theory, we can use \n(Test Grant) to justify this kind of program transformations by deriving the equation: e = test R then \n(grant R in e) else e Normal Forms for Security-Modifiers. We say that an evaluation context is a security-modi.er \nwhen it is built using one or more frames and any number of grants. Using the equational theory, we can \nsystematically simplify such contexts. (We lift the relation = pointwise from expressions to contexts \nseen as functions: C(\u00b7) =C ' (\u00b7) when for all e we have C(e) =C ' (e).) Proposition 2. For every security-modi.er \nC(\u00b7), there ex\u00adist unique permission sets D . A . R . S such that C(\u00b7) = grant A in R[S[grant D in (\u00b7)]] \nInformally, D collects the dynamic permissions always present in (\u00b7), A collects the permissions present \nwhen stat\u00adically available in the enclosing context, R collects the per\u00admissions present when dynamically \navailable in the enclos\u00ading context, and S collects the permissions present when self-granted. These \ncontexts summarize the security content of arbi\u00adtrary slices of the stack; they may be used to rearrange \nstacks at runtime. The security-setter contexts CS D(\u00b7) used in Theorem 2 are a special case. The two \nforms are equiv\u00adalent only when A = R = D, that is, when C(\u00b7) does not depend on its environment. 4.3 \nProof Technique: Applicative Bisimilarity As usual, the quanti.cation over arbitrary contexts in the \nde.nition of contextual equivalence makes it cumbersome to apply the de.nition directly when proving \nequivalences. In this section, we present a secondary equivalence, a form of Abramsky s applicative bisimilarity \n[2], that avoids any quanti.cation over contexts, and hence is easier to estab\u00adlish. We can show that \nbisimilarity is a congruence relation using Howe s method [15], and hence that it coincides with contextual \nequivalence. Therefore, we can use bisimulation arguments to establish contextual equivalences. We use \nthis technique to prove Theorem 1. Two closed expressions are applicatively bisimilar if, given any \nstatic and dynamic permissions, S and D, whenever one expression reduces to an outcome, so does the other, \nand moreover, the two outcomes match in the sense that either (1) both are failures, or (2) both are \nabstractions such that when they receive identical values they are themselves applicatively bisimilar. \nWe formally de.ne applicative bisimilarity by the follow\u00ading fairly standard series of de.nitions. The \nnovelty rela\u00adtive to previous versions of applicative bisimilarity is the quanti.cation over static and \ndynamic permissions; without this quanti.cation, we would lose congruence with respect to frames and \ngrants. For several papers discussing applica\u00adtive bisimilarity, and related techniques, see the book \nedited by Gordon and Pitts [12].  Let e .S D) * D o if and only if both D . S and e(.S o.  An applicative \nsimulation is a relation S on closed ex\u00adpressions such that e1 S e2 implies:  (1) if e1 .SD fail; D \nfail then e2 .S (2) if e1 .S D D .x.f1 then there is .x.f2 such that e2 .S .x.f2 and for every closed \nvalue v, f1{x.v}S f2{x.v}. An applicative bisimulation is a relation S such that both S and S-1 are \napplicative simulations.  Let ground applicative bisimilarity, ~, be the great\u00adest applicative bisimulation, \nthat is, the union of all applicative bisimulations.  Let (applicative) bisimilarity, ~., be such that \ne ~. e ' if and only if es ~ e ' s for all substitutions s such that s = {x1.v1}\u00b7\u00b7\u00b7{xn.vn} for some closed \nv1, ..., vn where {x1,...,xn} = fv(ee ' ). We prove congruence by Howe s method. The idea is to construct \nan auxiliary relation, the congruence candidate, that clearly includes bisimilarity and is a congruence. \nBy showing that the congruence candidate is a bisimulation, it follows that it is included in bisimilarity, \nand therefore the two are one. Hence, we obtain: Theorem 3. Bisimilarity is a congruence. Given congruence, \nthe identity of contextual equivalence and applicative bisimilarity follows easily. The interesting step \nin the proof is to show that contextual equivalence is an applicative bisimulation. Theorem 4. Bisimilarity \nequals contextual equivalence. Some (though not all) of the equations of Section 4.1 are justi.ed by \nTheorem 4 in combination with the following simple proof principle. It is justi.ed by a bisimulation \nar\u00adgument. Using this proposition is considerably simpler than attempting direct proofs of contextual \nequivalence. Proposition 3. For any expressions e1 and e2, e1 ~. e2 if for all D and S such that D . \nS, and for all substitutions s sending variables to closed values with dom(s)= fv(e1 e2) and for all \no, we have e1s .SD o. D o .. e2s .S We can D(\u00b7) relate show that security-setting contexts CS top-level \nand security-indexed evaluation in the sense that in general CSD o. D(e) . o .. e .S Therefore, this \nproof prin\u00adciple can be read as a simple context lemma [21] reducing proofs of contextual equivalence \nto the consideration of a limited set of contexts.  5. PROGRAM TRANSFORMATIONS We consider two categories \nof program transformations. One may try to optimize the use of permissions and stack inspections to reduce \ntheir runtime costs; such optimizations are studied in the literature, and illustrated in Section 4.1. \nAlternatively, one may try to carry over standard optimiza\u00adtions to a setting with stack inspection. \nThe examples given below suggest that this requires some care, even for simple optimizations. As can \nbe expected, it is important (and hard) to e.ectively combine both kinds of optimizations. We largely \nignore this issue, and instead establish the cor\u00adrectness of individual transformations. Runtime behaviour \nis complicated by the application of a security policy. We may consider program transformations in di.erent \nsituations: (1) Seen from the front-end compiler (usually in charge of performing global optimizations), \noptimizations op\u00aderate before the framing translation, so their correct\u00adness must be assessed in every \ncontext after framing R[[(\u00b7)]], for every principal R. One may also consider cross-module optimizations \nsuch that R varies. (2) From the JIT viewpoint, optimizations operate on ex\u00adpressions obtained by framing; \nthis gives structural guarantees, such as the presence of a frame in every function.  (3) For later \noptimizations, such as runtime optimizations, one can no longer assume all expressions are obtained by \nframing. In case (1), we are considering equations before framing, so we have to lift contextual equivalence, \nassuming a sin\u00adgle, uniform but unknown frame. Accordingly, we introduce front-end equivalence, e [ ] \ne ' , de.ned as follows. Front-end equivalence e [ ] e ' if and only if for all R, R[ e] R[ e ' ]]. 5.1 \nFunction Inlining Code inlining is a fundamental program transformation, used by most global program \noptimizations. Informally, inlining is problematic when it merges several frames that may have di.erent \npermissions at runtime. For instance, when the caller and the inlined code have di.erent static permissions, \nthe inlined code is run with its caller s permissions. This e.ectively rules out cross-module inlining \nprior to setting the security policy. In the following, we inline a function with principal R; we let \nD(\u00b7) abbreviate the context let h = R[ .x.e] in C(\u00b7) and assume a preliminary renaming to prevent variable \ncaptures. Inlining of framed code may be described by the equation D(hv) .-. D(R[ e] {x.v}) (9) that \ntransforms a function call hv into an inlined copy of the body e of h with v taking place of the formal \nparameter x and thereby discards the inner frame. This di.ers from the literal inlining justi.ed by equation \n(Fun Beta): D(hv) =D(R[ .x.e] v) . = D((.x.R[R[ e]]]) v) =D(R[ R[ e] {x.v}] ) (10) This is correct \nin .sec, but leaves the frame R[\u00b7] around inlined code. Conversely, (9) may or may not be a contextual \nequivalence, depending on the context D(\u00b7). As a consequence, literal inlining before framing (as per\u00adformed \nby a source compiler) is also problematic, even if .x.e and v have the same principal. In the case v \n= R[ w]], an instance of (9) is . e0 = let h = R[ .x.e] in R[ hw] . .-. e1 = let h = R[ .x.e] in R[ \ne{x.w}] Again, this transformation is not generally correct. Consider the inlined code e = grant R in \ntest R then ok else fail. Assuming R = \u00d8, we have \u00d8[e0] . ok versus \u00d8[e1] . fail. In contrast, we do \nhave R[ let h = .x.e in hw] R[ let h = .x.e in e{x.w}] because our encoding of let introduces an extra \nframe R[\u00b7] on both sides of the equation which enable us to apply equa\u00adtion (Frame Frame). We have a \nmore general correctness result for inlining be\u00adfore framing, which justi.es a limited form of (9): \nLemma 1 (Local Inlining). For all expressions e, values w, and contexts B(\u00b7) in the frameless .sec, we \nhave let h = .x.e in B(hw) [ ] let h = .x.e in B(e{x.w}) 5.2 Tail Call Elimination Tail call elimination \nis a useful optimization which also a.ects the structure of the stack. Instead of building a new frame \nfor the last call in a function, the optimization over\u00adwrites the current frame so that the callee directly \nreturns to the caller s caller. In the CLR, this may occur when the call is annotated as tail callable \nin the component [8], and the decision is made by the JIT compiler according to the security policy. \nInformally, optimizing a tail call may create two problems: an untrusted caller may thereby remove its \ntracks from the calling stack; less importantly, perhaps, a trusted caller may inadvertently cancel permissions \nit has just granted. For these reasons, most implementations of stack inspection dis\u00adallow or restrict \ntail calls. Various workarounds have been proposed [6, 28]. In our model, we re.ect tail call elimination \nas a runtime transformation just before the call, rather than a speci.c language construct: R[vw] .-. \nvw (11) in some evaluation context or, more generally for callers that grant permissions, R[grant S in \nvw] .-. vw. As in Sec\u00adtion 2, we interpret (Red Frame) reduction steps as popping a runtime frame from \nthe evaluation stack. With an ordi\u00adnary call, the frame R is kept until vw completes, whereas it is immediately \ndiscarded with the tail call optimization. For instance, if the callee is of the form v = .x.S[e], compare: \nR[vw] . R[S[e{x.w}]] ordinary call R[vw] .-.. S[e{x.w}] optimized call As with inlining, a frame is erased, \nbut one level deeper in the stack. Clearly, (11) may not preserve contextual equiv\u00adalence: we can formulate \nthe two problems above as inequa\u00adtions. First, with examples (4) and (5) of Section 3, we have: System[Applet[displayFile \nsecrets ]] .-. System[displayFile secrets ] and the permission check fails only in the .rst expression, \nleading to di.erent outcomes. Second, with example (6) from Section 3, we have Applet[readVersion ok] \n. Applet[System[grant {.leIO} in readFile version ]] .-. Applet[readFile version ] and the latter expression \nfails instead of returning the string Build 2601 . Fortunately, tail call elimination is actually correct \nin most common cases. For instance: Assume the callee has at most the static permissions of the caller, \nthat is, v = .x.S[e] with S . R. Then, we can prove R[vw] vw using rules (Fun Beta) and (Frame Frame) \nfrom Section 4.1. In particular, any tail call within the same module can be optimized as long as the \ncaller does not grant permissions.  Even if the caller grants permissions T , and as long as both the \nstatic permissions of the callee and the granted permissions are statically given to the caller (T . \nS . R), the runtime may still be able to copy the grant to the new frame. With the same nota\u00adtions, let \nv ' be v with the same additional grant (v ' =  .x.S[grant T in e]). Similarly, we can prove the equa\u00adtion \nR[grant T in vw] v ' w using (Fun Beta), (Frame Grant Frame), and (Frame Frame).   6. KEEPING TRACK \nOF DEPENDENCIES Informally, stack inspection is a mechanism that prevents untrusted code from causing \nharm. However, it is surpris\u00adingly hard to state a useful theorem that captures this intent for a general \nclass of trusted and untrusted code. We give it a try, and also explore variants of the operational semantics \nthat yield stronger, easier-to-explain theorems. Our results are meant to illustrate these semantics, \nrather than provide the most general statements. 6.1 What is Guaranteed by Stack Inspection? A .rst problem \nis that there is no generic notion of some\u00adthing bad happens . To this end, we re-interpret failures \n(fail) as security failures, rather than security exceptions. That is, we de.ne e does dangerous things \nas e . fail. In the following, S .P represents an upper bound on the permissions e.ectively given to \nuntrusted code. We intro\u00adduce syntactic restrictions required in the results below, for any code (both \ntrusted and untrusted). Syntactic requirements An expression e is safe against S when (1) grant R in \ne ' occurs only with R . S. (2) fail occurs only as test R then fail else e ' with R . S.  Conservatively, \nfail in (2) stands for any potentially dan\u00adgerous code protected by R, such as primRF in the exam\u00adples, \nand (1) rules out any dangerous grant. Theorem 5 (Sandbox). If e is safe against S, then S[e] does not \nfail. This basic result states that applets do nothing danger\u00adous on their own, but does not capture \nthe behaviour of a system that runs S[e] in a more trusted environment, as il\u00adlustrated in Section 3. \nRather, it describes a sandbox policy with maximal permissions S. Such a policy can be enforced without \nthe complications of dynamic stack inspections, us\u00ading the constant set of permissions S or relying on \ntypes [18]. Next, we focus on trusted code that discards any un\u00adtrusted result. With this discipline, \napplet code framed with S should not a.ect any code protected by permis\u00adsions beyond S. The next theorem \nformalizes this reasonable property. Its statement relies on a partial erasure operator: Partial erasure \nof untrusted code Let S .P. The function on terms (\u00b7) \\S is de.ned by . -(S[e]; e ' ) \\S = ok;(e ' \\S) \n-(\u00b7) \\S otherwise commutes with all constructors. The intent of the erasure is to make independence \nfrom the untrusted subterms syntactically obvious. We erase code that is framed with the permission set \nS exactly. However, we can apply our theorems several times with di.erent S pa\u00adrameters to erase more \ncode, and conversely we can add an extra permission to S and to some S-frames for a more se\u00adlective erasure. \nIn general, erasure and evaluation do not commute, be\u00adcause diverging or failing computations may be \nerased. In our setting, we have: Theorem 6 (Protection from untrusted procedures). Assume e is safe against \nS. If e . o, then e \\S . o \\S. Hence, if e . fail, then also e\\S . fail on its own. Informally, security \nfailures do not depend on any untrusted code that is erased. As can be expected from our examples, the \ntheorem would not hold for a more general erasure operator that may discard untrusted expressions whose \nresults are actually used by trusted code. The theorem does not distinguish between trusted and untrusted \ncode. Indeed, an erased frame S[e] may contain both trusted and untrusted parts; such frames naturally \noc\u00adcur by reduction from the initial con.gurations obtained by framing, described in Section 2.3. Due \nto its strict syntactic requirements, Theorem 6 may not immediately apply to these con.gurations, but \nwe can use our equational theory to rearrange them. Speci.cally: (1) As a prerequisite, both trusted \nand untrusted code must be safe against S. In the case untrusted code con\u00adtains grants of permissions \nnot in S, one can sometimes apply equations (Frame Grant) and (Grant Frame) to lower those grants and \nmeet requirement (1). (2) The theorem is useful inasmuch as untrusted frames are discarded. Hence, S \nframes should be moved into contexts such that (\u00b7) \\S erases them, when possible.  Typically, after \nframing untrusted code, S frames ap\u00adpear under abstractions rather than in contexts (\u00b7); e. Consider, \nfor instance, an expression that links trusted code (ze); e ' and untrusted code S[ v] = .x.S[e '' ] \nfor some x . fv(ee ' ). We have: ' '' ''' (.z.(ze); e ) .x.S[e ] = ((.x.S[e ]) e); e . '' ' =(let x = \ne in S[e ]); e = let x = e in (S[e '' ]; e ' ) (\u00b7) \\S let x = e \\S in (ok; e ' \\S) = (.z.(ze); e ' ) \n\\S .x.ok applying .rst equations (Fun Beta) and (Let Let), then erasing the S frame, and .nally applying \nthose equa\u00adtions again. Thus, we can extend Theorem 6 to a stronger notion of erasure that embeds this \npattern. (3) After applying the theorem, if there is any residual untrusted code, such as functions whose \nresults are not discarded, some more equational reasoning may be required to assess their e.ect on the \ncomputation. An interesting approach to obtain similar guarantees (and to bene.t further from stack inspection) \nis to modify the in\u00adterface between trusted and untrusted code. For instance, one can perform a local \ncontinuation-passing style trans\u00adform (CPS) on untrusted functions: whenever the results of untrusted \napplets are used in trusted code, one can in\u00adstead pass the result to a trusted continuation. (While \nit is tempting to apply a global CPS, this has little practical interest, inasmuch as its e.ective implementation \nrules out the stack-based, on demand inspection algorithm.) For example, if (e1 S[f]); e2 is modi.ed \nby CPS-transform into (...(S[.f ]; e2)) e1, and as long as the whole expression is safe against S, we \ncan erase f and apply Theorem 6 to show that the outcome of the expression does not depend on f . However, \nthis modi.cation is not a contextual equiv\u00adalence in .sec.  6.2 Tracking all Call-by-Value Dependencies \nReduction rules with framed values To get a better understanding of the limitations of stack (Red Appl \nW) (Red Appl) is replaced by inspection, we now consider alternative operational seman\u00ad (.x.e) w . SD \ne{x.w} tics that keep track of dependencies more systematically. For simplicity, in the following we \nonly consider .sec with\u00adout permission grants. We let w range over framed values, given by the grammar \nw ::= v | R[w]. According to the semantics of Section 2, values and framed values are equivalent, as \nwe can always discard frames using (Red Frame) or equation (Frame o). Our .rst modi.ed semantics keeps \ntrack of all dependen\u00adcies, much like information-.ow. Reduction rules for CBV dependency tracking Other \nrules are unchanged from Sections 2.2 and 6.2: (Ctx Rator), (Ctx Rand W), (Ctx Frame), (Red Test), \n(Red Frame Rator)(Fail Frame)(Fail Rator)(Fail Rand W).  Alternatively, we can obtain a similar semantics \nwithout modifying (Red Appl) by pushing the frame constructors under abstractions instead of discarding \nthem. Reduction rules with frame capture in functions (Red Frame Fun)(Red Frame), (Ctx Rand), and (Fail \nRand) are replaced by: (Red Frame) is replaced by R[.x.e] . SD .x.R[e] (Ctx Rand W)(Red Frame Rand) \n' SD Other rules are unchanged from Sections 2.2 and 6.2: e2 .e 2 v1 R[w2] . SD R[v1 w2] ' (Ctx Rator), \n(Ctx Rand), (Ctx Frame), (Red Appl), SD w1 e2 .w1 e 2 (Red Test), (Fail Frame), (Fail Rator), (Fail Rand). \n (Red Frame Rator) (Fail Frame) (Fail Rand W) R[w1] w2 . SD R[w1 w2] R[fail] . SD fail w fail . SD fail \nThese two intermediate semantics model the capture of the dynamic security environment (here D) that \nsometimes Other rules are unchanged from Section 2.2: (Red Appl), (Red Test), (Ctx Rator), (Ctx Frame), \n(Fail Rator). Rules (Red Frame Rand), (Red Frame Rator), and (Fail Frame) re.ne rule (Red Frame) with \nthree disjoint cases. The net e.ect of the re.ned semantics is to accumulate ev\u00adery frame that ever occurs \nin evaluation context, instead of discarding frames after local evaluation. Pragmatically, this variant \nis much harder to implement lazily: stack inspection must be supplemented with a mech\u00adanism that captures \nthe current security environment and attaches it to any value. Conversely, a security-passing style implementation \nof the .-calculus, at least, could easily ac\u00adcommodate this variation. Rules (Red Frame Rand) and (Red \nFrame Rator) for frames correspond to the two operational rules for labels in the call-by-value semantics \ngiven by Abadi, Lampson, and L\u00b4evy in [1, section 3.7]. Their semantics also strictly keep track of dependencies, \nalthough their intent is quite di.erent. With our modi.ed semantics, we have a stronger, simpler variant \nof Theorem 6. We rede.ne the erasure operator as follows: S[e] \\S = S[ok], and (\u00b7) \\S commutes with all \nother constructors. Hence, we uniformly erase untrusted code, independently of its usage. Theorem 7 (Independence \nfrom untrusted code). Assume e is safe against S. With the dependency tracking semantics above, e . fail \n.. e \\S . fail and e . w .. e \\S . w \\S for any extended value w not framed by S. The .rst claim of the \ntheorem asserts that failures in e do not depend on any S-framed code. Less importantly, perhaps, the \nsecond claim describes computations that do not use S-framed code.  6.3 Two Intermediate Tracking Semantics \nStarting from the semantics for CBV dependency track\u00ading, we can give up the preservation of convergence \nand get a coarser semantics by (1) discarding rule (Red Frame Rand), and (2) generalizing (Red Appl) \nto substitute framed values. This is similar in spirit to the .rst labelled semantics of [1], where labels \nare parts of values. occurs in runtimes, for example when preparing the .rst call to a new thread. They \nare weaker than CBV depen\u00addency tracking; for instance, the divergence properties of low-privileged, \nunused subterms are not taken into account. For both of these semantics, we have R[.x.e] .x.R[e] and \nso they are roughly equivalent. We summarise our semantics variants by considering re\u00adductions for the \nexpression e0 =(.x.e) R[.y.f], from the coarsest to the most restrictive: standard stack inspection; \nstack inspection with frame capture; stack inspection with framed values; and CBV dependency tracking. \n (Red Frame)(Red Appl)e0 - -----------.- ----------. e{x..y.f}(Red Frame Fun)(Red Appl)e0 --------------.- \n----------. e{x..y.R[f]}(Red Appl W)e0 - ------------. e{x.R[.y.f]}(Red Frame Rand)(Red Appl)e0 ---------------.- \n----------. R[e{x..y.f}] In order to get an adequate theorem for the intermediate semantics, we adapt \nagain the erasure operator, as follows. To preserve convergence, we use a closed value t instead of ok \nsuch that ..t t. We let S[e] \\S = t, and let (\u00b7) \\S commute with all other constructors. Theorem 8 (Protection \nfrom untrusted code). Assume e is safe against S. With any of the two semantics above, we have e . fail \n=. e \\S . fail.  7. CONCLUSIONS AND RELATED WORK We began the paper by casting doubt on the claims \nthat stack inspection (1) allows easy and precise statement of security requirements and (2) is transparent \nfor most pro\u00adgrammers. To be clear, we are not denying the entirety of these claims; after all, stack \ninspection has been an e.ective security tool in runtimes like the JVM or the CLR. Instead, we are probing \nits limitations. The limits of (1) appear in Sections 3 and 6 as we model complex interac\u00adtions between \ntrusted and untrusted code. The limits of (2) appear as we investigate standard program transforma\u00adtions \nin Sections 4 and 5. Although we use a formalism, we attempted throughout also to explain the issues \nin im\u00adplementation terms. Inevitably, we leave aside important issues in the details of the implementations. \nAs well as casting doubt, the paper casts light on the semantics of stack inspection. The equational \ntheory in Section 4.1 allows us to reason carefully about compiler transformations. The variations in \nSection 6 strike di.er\u00ad ent balances between security requirements and their imple\u00admentation cost. Still, \nthese variations are exploratory, and so far purely theoretical. Implementation experiments re\u00admain future \nwork. To the best of our knowledge, ours is the .rst work to analyse contextual equivalence in the presence \nof stack inspection, or to attempt to formulate high-level program-independent guarantees. Wallach, Appel, \nand Felten [30] provide an alternative semantics, security-passing style, that makes explicit the se\u00adcurity \nenvironment as an extra argument passed to every function; they clearly separate the security intent \nfrom its implementation mechanism; they also present a semantics in terms of authentication logic. Our \nsecurity-indexed seman\u00adtics amounts to a direct account of security-passing style. Besson, Jensen, Le \nM\u00b4etayer, and Thorn [16, 7] propose a logic for security properties of the control .ow graph of a program. \nTheir strategy is to identify speci.c properties, construct a .ow graph, and apply a model-checker. Their \nlogic can express the behaviour of stack inspection as a for\u00admula. Their work is notable for its success \nin proving inter\u00adesting program-dependent guarantees. Erlingsson and Schneider [9] implement two formulations \nof stack inspection by constructing an inlined reference mon\u00aditor. They informally outline shortcomings \nof stack inspec\u00adtion with respect to thread creation and method inheritance. Pottier, Skalka, and Smith \n[27, 29] introduce the .sec \u00adcalculus in their work on avoiding dynamic stack inspections by type-based \nstatic analysis. Their types express detailed information on permissions, which may be useful in a typed \nequational theory. Banerjee and Naumann [3] develop an eager denotational semantics for a .-calculus \nsimilar to .sec, and show its cor\u00ad annotations remain attached to values, much like labels or S-frames \nin Section 6.2, but they can cancel one another, with for instance trust (distrust e) . trust e. Their \nse\u00admantics does not .x a particular evaluation strategy. They provide a type system that rules out erroneous \nexpressions check (distrust e). Myers [24] also proposes a .ow analy\u00adsis for protecting privacy and integrity \nproperties in Java programs. Grossman, Morrisett, and Zdancewic [13] model multi\u00adple principals within \na typed .-calculus, with a reduction semantics similar to the tracking semantics of Section 6. They are \nnot concerned with access control, but prove vari\u00adous safety and abstraction properties. Acknowledgments. \nThis work bene.ted from discussion with Mart\u00b4in Abadi, Tony Hoare, Butler Lampson, and Erik Meijer. APPENDIX: \nSEMANTICS WITH EXPLICIT STACK INSPECTION Pottier, Skalka, and Smith [27] give two di.erent seman\u00adtics \nfor .sec. The .rst semantics gives an explicit account of stack inspection: it closely models the complex \ninspec\u00adtion mechanism that occurs on demand when testing per\u00admissions, as an inductive predicate on the \ncurrent evalua\u00adtion context. Still, modulo minor syntactic di.erences, we can prove that our top-level \nreduction relation equals their reduction relation with stack inspection (Corollary 1). In short, our \nde.nition is equivalent but more abstract. Their second semantics is by translation to a standard .\u00adcalculus \nplus primitive operations on permission sets. This is the security-passing style transformation proposed \nby Wal\u00adlach, Appel, and Felten [30]. Our security-indexed opera\u00adtional semantics represents this style \ndirectly rather than by translation; the dynamic permissions set D in . SD is es\u00ad sentially the additional \nparameter in security-passing style. We recall on the next page the .rst semantics given in [27] for \nour variant of .sec. The semantics is given as reduction steps in evaluation context. Crucially, permission \ntests de\u00ad pend on a stack-inspection predicate that takes the current context as a parameter. (Evaluation \ncontexts E(\u00b7) are de\u00ad .ned in Section 2.2.) For simplicity, we describe stack in\u00ad spection independently \nfor each requested permission and aggregate the results in (SI Test). respondence to a lazy operational \nsemantics. They present a static analysis, similar to but more abstract than the anal\u00ad ysis of Pottier, \nSkalka, and Smith, that can safely eliminate certain stack inspections. They identify program transfor\u00ad \nmations validated by their denotational semantics; this is the only other work we know of to analyse \nprogram equiv-Next, we relate this semantics to the one given in Sec\u00ad tion 2. The .rst lemma states that \nthe sets S and D passed in reductions . SD collect the static and dynamic permissions that can be read \non demand from the stack, in order to pro\u00ad cess a permission test. As a corollary, we obtain agreement \nbetween the two semantics. alence in the presence of stack inspection. In subsequent work, Banerjee and \nNaumann extend their denotational se\u00ad mantics to model stack inspection in a Java-like class-based language \n[4]. An abstraction theorem for their semantics is the basis for ongoing work on proving security properties \nof SD programs. Karjoth [17] gives a detailed operational semantics of the Lemma 2 (Stack Inspection \nvs Security Passing). stack inspection mechanism in Java 2, but does not consider Let E be an evaluation \ncontext. Let S = {p |E(\u00b7) .s p} and the e.ect of stack inspection on code optimisations. D = {p |E(\u00b7) \n. p}. We have E(e) .E(e Bartoletti, Degano, and Ferrari [5] analyse bytecode to ' ' ) .. e . e approximate \nthe set of permissions e.ectively granted or denied at run-time, and use this information to optimize \nstack inspection mechanisms. We discussed in Section 6 the view that stack inspec\u00adtion approximates a \n.ow analysis. Several authors consider .ow analyses for security. For instance, \u00d8rb\u00e6k and Pals\u00adberg model \ntrust in a pure .-calculus supplemented with trust, distrust, and check constructors. Trust and distrust \nCorollary 1 (Agreement). e . e -w' .. e . e '  8. REFERENCES [1] M. Abadi, B. Lampson, and J.-J. L\u00b4evy. \nAnalysis and caching of dependencies. In First ACM SIGPLAN International Conference on Functional Programming \n(ICFP 96), pages 83 91, May 1996. Operational semantics with stack inspection [14] N. Hardy. The confused \ndeputy. ACM Operating Sys\u00ad(SI Fail) tems Review, 22(4):36 38, Oct 1988. http://www.cis. .E(fail) .E(e{x.v}) \n- .E(fail) w-w w- (SI Appl) E(fail e) upenn.edu/~KeyKOS/ConfusedDeputy.html. E((.x.e) v) E(v fail) [15] \nD. J. Howe. Proving congruence of bisimulation in func\u00adtional programming languages. Information and \nCom\u00ad (SI Frame) (SI Grant) putation, 124(2):103 112, 1996. .E(o) (SI Test) w- .E(o) else efalse) .E(e(.p.R. \nE.p)) 1999 IEEE Symposium on Security and Privacy, pages w-w- E(R[o]) E(grant R in o) [16] T. Jensen, \nD. L. Metayer, and T. Thorn. Veri.cation of control .ow based security properties. In Proceedings E(test \nR then etrue (Walk Further) (Walk Frame) E(\u00b7) . p (Walk Top) E(\u00b7) . pp . S E(\u00b7 e) . p (\u00b7) . p E(S[\u00b7]) \n. p E(v \u00b7) . p E(grant T in \u00b7) . p (Walk Grant) E(\u00b7) .s pp . T E(grant T in \u00b7) . p (Find Further) (Find \nFrame) E(\u00b7) .s p (Find Top) p . S E(\u00b7 e) .s p (\u00b7) .s p E(S[\u00b7]) .s p E(v \u00b7) .s p E(grant T in \u00b7) .s p \n[2] S. Abramsky and L. Ong. Full abstraction in the lazy lambda calculus. Information and Computation, \n105:159 267, 1993. [3] A. Banerjee and D. Naumann. A simple semantics and static analysis for Java security. \nCS Report 2001 1, Stevens Institute of Technology, 2001. [4] A. Banerjee and D. Naumann. Representation \nindepen\u00addence, con.nement, and access control. In 29th ACM Symposium on Principles of Programming Languages \n(POPL 02), 2002. This volume. [5] M. Bartoletti, P. Degano, and G. Ferrari. Static analysis for stack \ninspection. In ConCoord: International Work\u00adshop on Concurrency and Coordination, volume 54 of ENTCS. \nElsevier, 2001. [6] N. Benton, A. Kennedy, and G. Russell. Compiling Standard ML to Java bytecodes. In \nThird ACM SIG-PLAN International Conference on Functional Pro\u00adgramming (ICFP 98), pages 129 140, 1998. \n[7] F. Besson, T. Jensen, D. L. M\u00b4etayer, and T. Thorn. Model checking security properties of control \n.ow graphs. Journal of Computer Security, 9:217 250, 2001. [8] D. Box. Essential .NET Volume I: The Common \nLan\u00ad guage Runtime. Addison Wesley, 2002. To appear. \u00b4 [9] U. Erlingsson and F. Schneider. IRM enforcement \nof Java stack inspection. In Proceedings 2000 IEEE Sym\u00adposium on Security and Privacy, pages 246 255. \nIEEE Computer Society Press, 2000. [10] C. Fournet and A. D. Gordon. Stack inspection: The\u00adory and variants. \nTechnical Report MSR TR 2001 103, Microsoft Research, 2001. [11] L. Gong. Inside JavaTM 2 Platform Security. \nAddison Wesley, 1999. [12] A. Gordon and A. Pitts, editors. Higher Order Oper\u00adational Techniques in Semantics, \nPublications of the Newton Institute. Cambridge University Press, 1998. [13] D. Grossman, G. Morrisett, \nand S. Zdancewic. Syntac\u00adtic type abstraction. ACM Transactions on Program\u00adming Languages and Systems, \n22(6):1037 1080, 2000. 89 103. IEEE Computer Society Press, 1999. [17] G. Karjoth. An operational semantics \nfor Java 2 access control. In 13th Computer Security Foundations Work\u00adshop, pages 224 232. IEEE Computer \nSociety Press, 2000. [18] X. Leroy and F. Rouaix. Security properties of typed applets. In J. Vitek and \nC. Jensen, editors, Secure In\u00adternet Programming Security issues for Mobile and Distributed Objects, \nvolume 1603 of LNCS, pages 147 182. Springer-Verlag, 1999. [19] T. Lindholm and F. Yellin. The JavaTM \nVirtual Ma\u00adchine Speci.cation. Addison Wesley, 1997. [20] Microsoft Corporation. .NET Framework Developer \ns Guide: Security Optimizations, 2001. http://msdn.microsoft.com/library/en-us/ cpguidnf/html/cpconsecurityoptimizations.asp. \n [21] R. Milner. Fully abstract models of typed lambda\u00adcalculi. Theoretical Computer Science, 4:1 23, \n1977. [22] E. Moggi. Notions of computations and monads. Theo\u00adretical Computer Science, 93:55 92, 1989. \n[23] J. H. Morris. Lambda-Calculus Models of Programming Languages. PhD thesis, MIT, Dec. 1968. [24] \nA. C. Myers. JFlow: Practical, mostly-static informa\u00adtion .ow control. In 26th ACM Symposium on Princi\u00adples \nof Programming Languages (POPL 99), pages 228 241, 1999. [25] P. \u00d8rb\u00e6k and J. Palsberg. Trust in the \n.-calculus. Jour\u00adnal of Functional Programming, 3(2):75 85, 1997. [26] G. D. Plotkin. Call-by-name, call-by-value \nand the .-calculus. Theoretical Computer Science, 1:125 159, 1975. [27] F. Pottier, C. Skalka, and S. \nSmith. A systematic ap\u00adproach to access control. In Programming Languages and Systems (ESOP 2001), volume \n2028 of LNCS, pages 30 45. Springer, 2001. [28] M. Schinz and M. Odersky. Tail call elimination on the \nJava Virtual Machine. In SIGPLAN Workshop on Multi-Language Infrastructure and Interoperability (BABEL \n01), volume 59(1) of ENTCS, pages 155 168. Elsevier, 2001. [29] C. Skalka and S. Smith. Static enforcement \nof secu\u00adrity with types. In Fifth ACM SIGPLAN International Conference on Functional Programming (ICFP \n00), pages 34 45, 2000. [30] D. S. Wallach, A. W. Appel, and E. W. Felten. Safkasi: A security mechanism \nfor language-based sys\u00adtems. ACM Transactions on Software Engineering and Methodology, 9(4):341 378, \n2000.  \n\t\t\t", "proc_id": "503272", "abstract": "Stack inspection is a security mechanism implemented in runtimes such as the JVM and the CLR to accommodate components with diverse levels of trust. Although stack inspection enables the fine-grained expression of access control policies, it has rather a complex and subtle semantics. We present a formal semantics and an equational theory to explain how stack inspection affects program behaviour and code optimisations. We discuss the security properties enforced by stack inspection, and also consider variants with stronger, simpler properties.", "authors": [{"name": "C&#233;dric Fournet", "author_profile_id": "81100547450", "affiliation": "Microsoft Research", "person_id": "PP14190246", "email_address": "", "orcid_id": ""}, {"name": "Andrew D. Gordon", "author_profile_id": "81100037731", "affiliation": "Microsoft Research", "person_id": "PP15020291", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/503272.503301", "year": "2002", "article_id": "503301", "conference": "POPL", "title": "Stack inspection: theory and variants", "url": "http://dl.acm.org/citation.cfm?id=503301"}