{"article_publication_date": "01-01-2002", "fulltext": "\n Mining Speci.cations Glenn Ammons Rastislav Bod\u00b4ik James R. Larus Dept. of Computer Sciences Dept. of \nComputer Sciences Microsoft Research University of Wisconsin University of Wisconsin One Microsoft Way \nMadison, Wisconsin, USA Madison, Wisconsin, USA Redmond, Washington, USA ammons@cs.wisc.edu bodik@cs.wisc.edu \nlarus@microsoft.com ABSTRACT Program veri.cation is a promising approach to improving program quality, \nbecause it can search all possible program executions for speci.c errors. However, the need to formally \ndescribe correct be\u00adhavior or errors is a major barrier to the widespread adoption of program veri.cation, \nsince programmers historically have been re\u00adluctant to write formal speci.cations. Automating the process \nof formulating speci.cations would remove a barrier to program ver\u00adi.cation and enhance its practicality. \nThis paper describes speci.cation mining, a machine learning approach to discovering formal speci.cations \nof the protocols that code must obey when interacting with an application program in\u00adterface or abstract \ndata type. Starting from the assumption that a working program is well enough debugged to reveal strong \nhints of correct protocols, our tool infers a speci.cation by observing program execution and concisely \nsummarizing the frequent inter\u00adaction patterns as state machines that capture both temporal and data \ndependences. These state machines can be examined by a pro\u00adgrammer, to re.ne the speci.cation and identify \nerrors, and can be utilized by automatic veri.cation tools, to .nd bugs. Our preliminary experience with \nthe mining tool has been promising. We were able to learn speci.cations that not only cap\u00adtured the correct \nprotocol, but also discovered serious bugs.  1. INTRODUCTION It is dif.cult to imagine software without \nbugs. The richness and variety of errors require an equally diverse set of techniques to avoid, detect, \nand correct them. Testing currently is the detec\u00adtion method of choice. However, the high cost and inherent \nlimita\u00adtions of testing has lead to a renewed interest in other approaches to .nding bugs. One of the \nmost promising directions is tools that systematically detect important classes of errors [1 3, 5, 6, \n9, 10]. While program veri.cation tools do not prevent programming errors, they can quickly and cheaply \nidentify oversights early in the development process, when an error can be corrected by a pro\u00adgrammer \nfamiliar with the code. Moreover, unlike testing, some veri.cation tools can provide strong assurances \nthat a program is free of a certain type of error. Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 02, Jan. 16-18, 2002 Portland, OR USA Copyright 2002 ACM \nISBN 1-58113-450-9/02/01 ...$5.00. These tools, in general, statically compute an approximation of a \nprogram s possible dynamic behaviors and compare it against a speci.cation of correct behavior. These \nspeci.cations often are easy to develop for language-speci.c properties such as avoid\u00ading null dereferences \nand staying within array bounds. Even when language properties are more dif.cult to express and check, \nthey potentially apply to every program written in the language, so an investment in a veri.cation tool \ncan be amortized easily. On the other hand, speci.cations particular to a program, say of its abstractions \nor datatypes, may be dif.cult and expensive to de\u00advelop because of the complexity of these mechanisms \nand the lim\u00adited number of people who understand them. Also, as these spec\u00adi.cations may apply to only \none program, their bene.ts are corre\u00adspondingly reduced. Program veri.cation is unlikely to be widely \nused without cheaper and easier ways to formulate speci.cations. This paper explores one approach to \nautomating much of the pro\u00adcess of producing speci.cations. This approach, called speci.ca\u00adtion mining, \ndiscovers some of the temporal and data-dependence relationships that a program follows when it interacts \nwith an ap\u00adplication programming interface (API) or abstract datatype (ADT). A speci.cation miner observes \nthese interactions in a running pro\u00adgram and uses this empirical data to infer a general rule about how \nprograms should interact with the API or ADT. These rules are con\u00adcisely summarized as state machines \nthat capture both temporal and data dependences. These state machines can be both examined by a programmer, \nto re.ne the speci.cation and identify errors, and utilized by automatic veri.cation tools, to .nd bugs. \nMining proceeds under the assumption that an executing pro\u00adgram, which presumably has passed some tests, \ngenerally uses an API or ADT correctly, so that if a miner can identify the common behavior, it can produce \na correct speci.cation, even from pro\u00adgrams that contain errors. Rather than start from the program s \ntext, in which feasible and infeasible paths are intermixed and correct paths are indistinguishable from \nbuggy paths, mining begins with traces of a program s run-time interaction with an API or ADT. These \ntraces are not only limited to feasible paths, but in general do not contain errors. The program in Figure \n1 illustrates these points. The program uses the server-side socket API [7]. It generally observes the \ncor\u00adrect protocol: create a new socket s through a call to socket, prepare s to accept connections by \ncalling bind and listen, call accept for each connection, service each connection, and .nally call close \nto destroy s. Unfortunately, the program is buggy: if the return statement on line 14 is executed, s \nis never closed. Even though a program is buggy, individual interaction traces can be correct. Figure \n2 shows one such trace. If cond1 is rarely true, it might be dif.cult to invent a test to force the program \nto behave badly. On the other hand, correct traces enable a miner 1 int s = socket(AF_INET, SOCK_STREAM, \n0); 2 ... 3 bind(s, &#38;serv_addr, sizeof(serv_addr)); 4 ... 5 listen(s, 5); 6 ... 7 while(1) { 8 int \nns = accept(s, &#38;addr, &#38;len); 9 if (ns < 0) break; 10 do{ 11 read(ns, buffer, 255); 12 ... 13 \nwrite(ns, buffer, size); 14 if (cond1) return; 15 } while (cond2) 16 close(ns); 17 } 18 close(s); Figure \n1: An example program using the socket API. 1 socket(domain = 2, type = 1, proto = 0, return = 7) 2 bind(so \n= 7, addr = 0x400120, addr_len = 6, return = 0) 3 listen(so = 7, backlog = 5, return = 0) 4 accept(so \n= 7, addr = 0x400200, addr_len = 0x400240, return = 8) 5 read(fd = 8, buf = 0x400320, len = 255, return \n= 12) 6 write(fd = 8, buf = 0x400320, len = 12, return = 12) 7 read(fd = 8, buf = 0x400320, len = 255, \nreturn = 7) 8 write(fd = 8, buf = 0x400320, len = 7, return = 7) 9 close(fd = 8, return = 0) 10 accept(so \n= 7, addr = 0x400200, addr_len = 0x400240, return = 10) 11 read(fd = 10, buf = 0x400320, len = 255, return \n= 13) 12 write(fd = 10, buf = 0x400320, len = 13, return = 13) 13 close(fd = 10, return = 0) 14 close(fd \n= 7, return = 0) Figure 2: Part of the input to our mining process: a trace of an execution of the program \nin Figure 1. to infer a speci.cation of the correct protocol. A veri.cation tool that uses the speci.cation \nto examine all program paths (such as Bebop [2] or xgcc [10]) could then .nd the rare bug. Our speci.cation \nmining system is composed of four parts: tracer, .ow dependence annotator, scenario extractor, and automa\u00adton \nlearner (Figure 4). The tracer instruments programs so that they trace and record their interactions \nwith an API or ADT, as well as compute their usual results. We implemented two tracers. One is a replacement \nfor the C stdio library, which requires recompiling programs. The other is a more general executable \nediting tool that allows arbitrary tracing code to be inserted at call sites. The tracers produce traces \nin a standard form, so that the rest of the process is independent of the tracing technology. Flow dependence \nannotation is the .rst step in re.ning the traces into interaction scenarios, which can be fed to the \nlearner. It con\u00adnects an interaction that produces a value with the interactions that consume the value. \nNext, the scenario extractor uses these depen\u00addences to extract interaction scenarios small sets of dependent \nsocket(return = x) bind(so = x) listen(so = x)  close(fd = y) close(fd = x) Figure 3: The output \nof our mining process: a speci.cation automaton for the socket protocol. interactions and puts the scenarios \ninto a standard, abstract form. The automaton learner is composed of two parts: an off-the-shelf probablistic \n.nite state automaton (PFSA) learner and a postpro\u00adcessor called the corer. The PFSA learner analyzes \nthe abstract scenario strings and generates a PFSA, which should be both small and likely to generate \nthe scenarios. A PFSA is a nondeterministic .nite automaton (NFA) in which each edge is labelled by an \nab\u00adstract interaction and weighted by how often the edge is traversed while generating or accepting scenario \nstrings. Rarely-used edges correspond to infrequent behavior, so the corer removes them. The corer also \ndiscards the weights, leaving an NFA. A human can val\u00adidate the NFA by inspection, at which point the \nNFA speci.cation can be used for program veri.cation. Figure 1 shows a speci.cation for the socket protocol \nof the program in Figure 1. This paper makes the following contributions: We introduce a new approach, \ncalled speci.cations mining, for learning formal correctness speci.cations. Since speci.\u00adcation is the \nportion of program veri.cation still dependent primarily on people, automating this step can improve \nthe appeal of veri.cation and help improve software quality.  We use the observation that common behavior \nis often cor\u00adrect behavior to re.ne the speci.cations mining problem into a problem of probabilistic \nlearning from execution traces.  We develop and demonstrate a practical technique for prob\u00adabilistic \nlearning from execution traces. Our technique re\u00adduces speci.cation mining to the problem of learning \nregular languages, for which off-the-shelf learners exist.  The rest of the paper is organized as follows. \nSection 2 develops Program Tracer Instrumented program Test inputs Traces Flow dependence Annotated \nannotator traces Abstract scenario Scenario seeds Scenario extractor strings  Automaton Specification \nlearner Figure 4: Overview of our speci.cation mining system. a formal statement of the speci.cation \nmining problem. Section 3 discusses tracers and the .ow dependence annotator. Section 4 de\u00adscribes the \nscenario extractor and the automaton learner. Section 5 discusses veri.cation of the mined speci.cations \nand presents a trace veri.cation tool. Section 6 discusses the results of an ex\u00adperiment with the mining \nand trace veri.cation tools . Section 7 discusses related work and Section 8 concludes the paper.  2. \nTHE PROBLEM This section develops a formal statement of the speci.cation mining problem. At its most \nambitious, speci.cation mining at\u00adtempts to solve an unsolvable problem: PROBLEM 2.1. Let I be the set \nof all traces of interactions with an API or ADT, and C < I be the set of all correct traces of in\u00adteractions \nwith the API or ADT. Given an unlabelled training set T of interaction traces1 from I, .nd an automaton \nA that generates exactly the traces in C. A is called a speci.cation. An algorithm that .nds A is called \na speci.cation miner. The rest of this section examines successive restrictions of this problem, which \nlead to a problem that can be attacked with the methods of this paper. These simpli.cations were choosen \nto acco\u00admodate our techniques, and other restatements of the speci.cation mining problem are certainly \npossible. Problem 2.1 can not be solved because it places no restrictions on the set C. If C is not recursively \nenumerable, then A does not exist. In this paper, we require that C be generated by a .nite\u00adstate automaton \n(that is, C is a regular language). This decision is forced by two practical considerations. First, model \ncheckers re\u00adquire .nite-state speci.cations. Second, the algorithms for learning .nite-state automata \nare relatively well-developed. It is not enough to simply say that C must be regular, because traces \nof most programs are not regular. For example, consider a C program (LinkedList) that takes a number \nn on the com\u00admand line, constructs a linked list of size n (allocating the nodes 1 By an unlabelled training \nset , we mean that no information is provided as to which of the elements in T are also in C. with malloc), \nand then destroys the linked list, deallocating the nodes with free in .rst-allocated, last-freed order. \nIgnoring the .nite arithmetic, the traces do not form a regular language. First, a regular language must \nbe de.ned over a .nite alphabet, but LinkedList can make an unbounded number of distinct mal\u00adloc and \nfree calls. Second, LinkedList always makes a num\u00adber of malloc calls followed by an equal number of \nfree calls, which is the canonical non-regular language. Although LinkedList s traces do not form a regular \nlanguage, its traces contain subtraces that do. Given a trace and an object o mentioned in that trace, \nconsider the subtrace of the trace contain\u00ading calls to malloc that return o and calls to free that are \npassed o. The subtrace is simply a malloc call, followed by a free call. If the trace mentions n objects, \nthere is one such subtrace for each object. Each subtrace is exactly like all of the others, except for \nthe particular object that it allocates and frees. Now replace that object in each subtrace with a standard \nname, say ostd . Now, all of the subtraces are identical, and the learner has a very strong hint that \nfree should always follow malloc. We call the renamed subtraces interaction scenarios. Our approach simpli.es \nProblem 2.1 in two ways. First, the learner does not learn directly from traces. Instead, a preprocessor \nextracts interaction scenarios from the traces. The scenarios manip\u00adulate no more than k data objects, \nfor some k; in the LinkedList example, k =1. Second, the set CS of correct scenarios is required to be \nregular. The simpli.ed speci.cation mining problem can now be de.ned: PROBLEM 2.2. Let IS be the set \nof all interaction scenarios with an API or ADT that manipulate no more than k data objects. Let CS < \nIS be the regular set of all correct scenarios. Given an unlabelled training set TS of interaction scenarios \nfrom IS, .nd a .nite-state automaton AS that generates exactly the scenarios in CS. Problem 2.2 is also \nimpossible to solve. The careful reader may have noticed that the training set TS does not depend on \nCS . That is, no matter what CS is, any subset of IS is a valid training set! Obviously, under these \nconditions, there is no basis on which to choose AS. The de.nition of Problem 2.2 allowed the training \nsets to be chosen so liberally in order to allow noisy training sets that contain bad examples (that \nis, bugs) that are not in CS .A satisfactory de.nition of noise must wait until the problem has been \nsimpli.ed further. For now, we simplify the problem by assuming that the training set is in fact an in.nite \nsequence of scenarios from CS alone, such that each element of CS occurs at least once: PROBLEM 2.3. \nLet IS be the set of all interaction scenarios with an API or ADT that manipulate no more than k data \nobjects. Let CS < IS be the regular set of all such correct scenarios. Fi\u00adnally, let TS = c0,c1,... be \nan in.nite sequence of elements from CS in which each element of CS occurs at least once. For each n> \n0, examine the .rst n elements of TS and produce a .nite-state automaton ASn , such that the sequence \nof .nite-state automata AS0 ,AS1 ,... has this property: for some N ? 0, ASN generates exactly the scenarios \nin CS and ASn = ASN for all n ? N. We say that the sequence AS0 ,AS1 ,... identi.es CS in the limit. \nPerhaps surprisingly, Problem 2.3 is also undecidable. Our def\u00adinition of Problem 2.3 is inspired by \nE Mark Gold s seminal paper on language identi.cation in the limit [14], in which Gold shows that regular \nlanguages can not be identi.ed in the limit [14, The\u00adorem I.8]. His proof is too long to repeat here, \nbut the idea of the proof is to present the members of an in.nite regular language to the learner in \nsuch a way that the learner is forced to change its guess in.nitely often, cycling through a never ending \nsequence of .nite sublanguages of the in.nite language. Intuitively, the learner s dilemma is that any \n.nite sequence of examples from the in.nite language is also a sequence of examples from a .nite lan\u00adguage, \nand the learner has no basis for preferring one of these over the other. Since CS is a possibly in.nite \nregular language, Gold s theorem applies to Problem 2.3. Gold s paper did not end work on learning regular \nlanguages from examples. Subsequent work avoids the dilemma exploited in Gold s proof by providing the \nlearner with extra information that allows it to justify choosing a less general automaton over a more \ngeneral one (and vice versa). One class of approaches presents the learner with examples generated according \nto a probability distri\u00adbution; this sort of approach is particularly interesting to us because it also \ngives the learner a method for dealing with noise in its in\u00adput. The task of the learner is to learn \na close approximation of the probability distribution: Let IS be the set of all interaction scenarios \nwith an API or ADT that manipulate no more than k data ob\u00ad jects. Let P andP be probability distributions \nover IS. We say thatP is an E-good approximation of P, for E ? 0, if D(P,P) : E where D(P,P) is some \nmeasure of distance between P andP. Just as Problem 2.2 restricted CS to be a regular set, P must be \nrestricted to a manageable class of distributions. We choose the distributions generated by probabilistic \n.nite state automata (PF-SAs). A PFSA is a probabilistic analogue of a nondeterministic .nite state automaton. \nThat is, a PFSA is a tuple (., Q,qs,qf ,p) where . is an output alphabet.  Q is a set of states.  \nqs = Q is the start state of the automaton.  qf = Q is the .nal state of the automaton.  ' p(q,q,a) \nis a probability function, giving the probability of ' transitioning from q = Q to q= Q while outputting \nthe ' symbol a = .. Note that p(qf ,q,a)=0 for all q = Q and a = .. Thus, a PFSA generates a distribution \nthat assigns positive prob\u00adabilities to the strings in a regular language. Basing our de.ni\u00adtion on the \nstandard de.nition for learning probabilistic .nite au\u00adtomata [20], we can now give our .nal formulation \nof the speci.\u00adcation mining problem: PROBLEM 2.4. Let IS be the set of all interaction scenarios with \nan API or ADT that manipulate no more than k data objects. Let M be a target PFSA, and PM be the distribution \nover IS that M generates. Intuitively, PM assigns high probabilities to correct traces and low probabilities \nto incorrect traces. Given a con.dence parameter 8> 0 and an approximation pa\u00adrameter E> 0, ef.ciently \n.nd with probability at least 1 - 8 a PFSAM such that its distribution PM is an E-good approximation \nof PM . Ef.ciently means that the mining algorithm must run in time polynomial in 1/E, 1/8, an upper \nbound n on the number of states of M, and the size of the alphabet . of I. int instrumented_socket(int \ndomain, int type, int proto) { int rc = socket(domain, type, proto); fprintf(the_trace_fp, \"socket(domain \n= %d, type = %d, \" \"proto = %d, return = %d)\\n\", domain, type, proto, rc); return rc; } Figure 5: Illustration \nof trace instrumentation (instrumented version of socket). Unfortunately, with reasonable distance metrics \nD, it has been shown that Problem 2.4 is not ef.ciently learnable [16]. An ef\u00ad .cient solution has been \nfound for the case where M andM are required to be acyclic and deterministic [24]. Since many interest\u00ading \nspeci.cations of program behavior contain loops, we chose to use a greedy PFSA learning algorithm that \nis not guaranteed to .nd an E-good approximation of M, but in practice generates succinct speci.cations. \n 3. TRACING AND FLOW DEPENDENCE ANNOTATION This section describes the tracing and .ow dependence annota\u00adtion \nthat produce the input to the scenario extractor. Tracing A tracer instruments a program, so that running \nit pro\u00adduces a trace of its interactions with an API or ADT, as well as its usual results. This paper \nassumes that a tracer only records function calls and returns, although depending on the API/ADT, the \nmining system allows tracing other events, such as variable accesses or net\u00adwork messages. Figure 5 shows \nan illustration of the trace instrumentation, speci.cally the C code for an instrumented version of the \nsocket call. This wrapper calls the real socket and records information about the interaction: the name \nof the call (socket), arguments, and return value. The entire socket API could be traced with an instrumented \nversion of each function. Our system currently uses two tracers. The .rst instruments the C stdio library, \nby capturing all library calls and macro invocations in that API. The second consists of two parts: Perl \nscripts that au\u00adtomatically generate instrumented versions of the function calls in the X11 API, and \na tool that edits program executables to replace calls on these routines with calls to instrumented versions. \nThe lat\u00adter tool is based on the EEL Executable Editing Library [17] and is very general. It takes as \ninput an executable, a library of in\u00adstrumented functions, and a .le specifying which calls in the exe\u00adcutable \nto replace with calls to instrumented functions. The most time-consuming part of tracing an interface \nis writing the instru\u00admented version of each API call, but we believe that this step is easily automated. \nAll tracers record interactions in the same format, so that the rest of the mining system is independent \nof the particular tracer used. An interaction skeleton is of the form interaction (attribute 0,... , \nattribute n) where interaction names the interaction (that is, the name of a function) and attribute \ni names the ith attribute of the interaction. Skeletons are just a convenient way of grouping interactions. \nThey do not appear in traces. An interaction instantiates a skeleton by assigning values to the attributes: \ninteraction (attribute 0 = v0 ,... , attribute n = vn) When tracing function calls, interaction attributes \nusually represent function arguments and return values, as in Figure 2. Structured data can be represented \nby .attening the structures. For example, given this C code struct S { int x; int y; }; void f(S* s); \nthe tracer could record interactions with f with instances of this skeleton f(s, s_x, s_y) By convention, \nthis paper names traces with the letter T and in\u00adteractions with variations of the letter t. The actual \ninteractions in a trace of length n +1 are numbered from 0 to n; for example, T = t0,... ,tn. The notation \nt.a denotes the a attribute of the interaction t. Flow dependence annotator Untyped trace Traces Dependence \nanalysis with dependences Type inference Annotated traces Figure 6: Detailed view of the .ow dependence \nannotator. Flow dependence annotation Flow dependence annotation anno\u00adtates each input trace with .ow \ndependences and type assignments. The scenario extractor uses these annotations to extract scenarios \nsmall sets of dependent interactions from the trace and to put each scenario into a canonical form. The \ndetailed view in Figure 6 shows that .ow dependence annotation is a two-step process. First, de\u00adpendence \nanalysis marks the trace with .ow dependences, which constrain how interactions may be reordered and \nidentify related interactions that could form scenarios. Next, type inference assigns a type to each \ninteraction attribute in the trace. The scenario extrac\u00adtor uses the types to avoid naming con.icts when \nit puts a scenario into standard form. Dependence analysis and type inference both examine the entirety \nof each input trace, so their running time must be nearly linear. The miner treats all values as abstract \nobjects whose underly\u00ading representation is unknown. However, interactions can depend on results from \nother interactions. For example, in Figure 2, the bind call (line 2) depends on the socket call (line \n1), because the bind call uses .le descriptor 7 returned by the socket call. The order of these two interactions \ncan not be reversed. By con\u00adtrast, the interactions that manipulate .le descriptor 8 (lines 4 9) could \nbe exchanged with the interactions that manipulate .le de\u00adscriptor 10 (lines 10 13), since these groups \nof operations are in\u00addependent of each other. More importantly, a scenario that contains all interactions \nrelated to the close on line 13 should not include the interactions on lines 4 9. De.ners: socket.return \nbind.so listen.so accept.return close.fd Users: bind.so listen.so accept.so read.fd write.fd close.fd \nFigure 7: Attributes of socket interactions that de.ne and use their values. Flow dependences connect \nattributes that change the state of an abstract object (that is, attributes that de.ne the object) to \ninterac\u00adtion attributes that depend on the state of an abstract object (that is, attributes that use \nthe object). Ideally, the dependence analyzer would annotate a trace with .ow dependences using no information \nbeyond the trace itself. Our current system, however, relies on an expert to tell the analyzer which \nattributes of interactions may de\u00ad.ne objects, and which attributes may use objects. This work must be \ndone once for each API/ADT. Extending the system to infer the sets of de.ners and users automatically \nis future work. For simplicity, the examples in this paper assume that only socket-valued attributes \nof the interactions in Figure 2 carry depen\u00addences. Figure 7 lists attributes of interactions in Figure \n2 that de\u00ad.ne and use socket values. We constructed this table as follows. For each socket, the kernel \nmaintains a hidden data structure. Some of the .elds of that structure carry the state of the socket: \nwhether the socket is closed or open, whether or not it can accept connections, and so on. Other .elds \nsimply hold data: bytes that are outstanding, the port to which the socket is connected, and so on. De.ners \nin Figure 2 typically modify one or more of the state .elds of the data structure. Users typically read \none or more of those .elds. Fields of the structure that merely hold data are ignored. Creating Figure \n7 required expert knowledge. In future work, we hope to replace the expert with an automatic tool. The \ntool would exploit the fact that whenever the state .elds of a socket s data structure change, the set \nof API calls that may follow also changes. For example, after a socket is closed, read and write calls \nare no longer allowed. Thus, the fact that close changes the state of the socket can be inferred from \nthe trace: before a close, there are reads and writes; after a close, there are no reads and writes. \nGiven the lists of attributes that de.ne or use objects, dependence analysis is a dynamic version of \nthe reaching de.nitions problem. The analyzer traverses the trace T = t0 ,... ,tn in order from t0 to \ntn, maintaining a table M that maps values to attributes of in\u00adteractions. Initially, M is empty. If \nti.a de.nes an object o, the annotator updates M to map o to ti.a. If ti. .a ' uses an object o and M \nmaps o to ti.a, then the analyzer places a .ow dependence from ti.a to ti. .a ' . The running time of \nthe algorithm scales linearly in the length of the trace. The space required scales linearly in the number \nof different values referenced by the trace. For notational convenience, we introduce a relation df such \nthat df (ti.a, ti. .a ' ) if and only if there is a .ow dependence from ti.a to ti. .a ' . The relation \nis extended from interaction attributes to interactions in the natural way: df (ti,ti. ) holds if and \nonly if there is some f and f ' such that df (ti.a, ti. .a ' ). Type(socket.return)= T0 Type(bind.so)= \nT0 Type(listen.so)= T0 Type(accept.so)= T0 Type(accept.return)= T0 Type(read.fd)= T0 Type(write.fd)= \nT0 Type(close.fd)= T0 Figure 8: The only valid typing for the skeleton attributes used by the trace in \nFigure 2. Type inference is the next step in the .ow dependence annota\u00adtor. Type inference assigns a \nmonomorphic type to each skeleton attribute that is involved in dependences. If a value never .ows between \nan instance of one skeleton attribute and an instance of another skeleton attribute, then type inference \nassigns the skeleton attributes separate types. Strictly speaking, .ow dependences alone give the scenario \nextractor enough information to extract scenarios and put them into a standard form. However, as Section \n4 explains, the scenario extractor can use the assurance that values will never .ow between certain attributes \nin a scenario to reduce naming con\u00ad.icts. Type inference infers the most general typing that satis.es \nthis condition: If df (ti.a, ti. .a ' ), then the typing gives the skeleton attribute of ti.a and the \nskeleton attribute of ti. .a ' the same type. where a typing 10 is more general than a typing 11 iff \nsome sub\u00adstitution for the type variables of 10 makes 10 =11. Figure 8 gives a typing for the skeleton \nattributes used by the socket trace in Figure 2. In this example, every skeleton attribute must have \nthe same type because all socket attributes in the trace are on some dependence chain with an instance \nof a close.fd attribute. The inference algorithm uses Tarjan s union-.nd algorithm [26] and requires \ntime nearly linear in the trace. The type inferer starts with an initial typing that gives each skeleton \nattribute its own unique type. Then, the inferer visits each dependence df (ti.a, ti. .a ' ) and uni.es \nthe types of the skeleton attribute of ti.a and the skeleton attribute of ti. .a '. Type inference is \ncomplete when all dependences have been visited.  4. SCENARIO EXTRACTION AND AUTOMATON LEARNING This \nsection explains how the scenario extractor and automaton learner work. The .rst tool extracts interaction \nscenarios small sets of interdependent interactions from annotated traces and pre\u00adpares them for the \nautomaton learner. The second tool infers spec\u00adi.cations from scenarios, not complete traces, for two \nreasons. The primary reason is that scenarios are much shorter than traces and the running time of our \nPFSA learner increases as the third power of the length of its input this is typical for automaton learn\u00aders. \nAlso, we restrict scenarios to refer to a small number of objects by bounding the size of the scenario. \nSection 2 argues that bound\u00ading the number of objects makes speci.cation mining tractable. Bounding the \nnumber of objects is not a severe limitation because veri.cation tools can verify that the speci.cation \nholds for multiple bindings of program objects to speci.cation objects. For example, although the protocol \nspeci.ed in Figure 1 mentions two objects, x and y, a tool that attempts to verify the program in Figure \n1 might bind y to more than one instance of ns as it simulates the loop in lines 7 17. The scenario extractor \nsimpli.es and standardizes the scenarios before passing them to the automaton learner, because our speci\u00ad.cation \nmining system uses an off-the-shelf PFSA learner. An al\u00adternative, which we have not tried, is to design \na special-purpose learner for scenarios. Both schemes have bene.ts and costs. There are several off-the-shelf \nlearners that learn PFSAs and similar automata from strings. Since our design transforms sce\u00adnarios to \nstrings, a new learner can be substituted for the learner currently used. If the new learner learns PFSAs, \nno changes to the mining system are necessary. If the learner does not learn PFSAs, the corer may need \nto be changed, but none of the components be\u00adfore the automaton learner in Figure 4 would require modi.cation. \nIn our experience, this .exible design was helpful. Before settling on the PFSA learner as use it now, \nwe tried and rejected one other PFSA learner [21]. On the other hand, a special-purpose learner could \ndefer deci\u00adsions that our mining system now must make before invoking the off-the-shelf learner. For \nexample, when the scenario extractor re\u00adplaces the concrete values in a scenario with abstract names, \nit does so without regard to the names given to values in other scenarios. Although the extractor always \nnames equivalent scenarios in the exact same way (see below for details), when two scenarios are close \nbut not equivalent, the extractor s choice of names can pre\u00advent the PFSA learner from merging states \nthat it would be able to merge with a different naming.  4.1 Scenario extraction scenario strings Figure \n9: Detailed view of the scenario extractor. Figure 9 is a detailed view of the scenario extractor. It \nreceives two inputs. The .rst is a set of traces, annotated as described in Section 3. In addition, the \nuser controls which scenarios will be extracted by supplying a set of scenario seeds. Each seed is an \ninteraction skeleton. The extractor searches the input traces for interactions that match the seeds and \nextracts a scenario from each interaction. For example, suppose the extractor was given the trace of \nsocket interactions in Figure 2 and accept(so, return) as the seed. The extractor would produce two scenarios, \none around the accept on line 4 and the other around the accept on line 10. Extraction Producing scenarios \nfrom input traces is the .rst step of the extraction process. Informally, a scenario is a set of interactions \nrelated by .ow dependences. Formally, given an annotated trace 1 socket(domain = 2, type = 1, proto = \n0, return = 7) 2 bind(so = 7, addr = 0x400120, addr_len = 6, return = 0) 3 listen(so = 7, backlog = \n5, return = 0) 4 accept(so = 7, addr = 0x400200, addr_len = 0x400240, return = 8) [seed] 5 read(fd = \n8, buf = 0x400320, len = 255, return = 12) 6 write(fd = 8, buf = 0x400320, len = 12, return = 12) 7 read(fd \n= 8, buf = 0x400320, len = 255, return = 7) 8 write(fd = 8, buf = 0x400320, len = 7, return = 7) 9 close(fd \n= 8, return = 0) Figure 10: A scenario extracted from around line 4 of Figure 2, with N = 10 T = t0,... \n,tn, a scenario is a set S <{t0 ,... ,tn} with the property: If ti0 = S, tin = S, and ti0 ,... ,tin is \na chain of .ow dependent interactions in T , then tij = S for any 0 : j : n. The extractor builds a scenario \naround each interaction in the trace that matches a scenario seed. For any scenario S, seed (S) = S is \nthe interaction that initially matches the seed. A user-tunable parameter N restricts the number of interactions \nin the extracted scenarios. Each scenario contains at most N an\u00adcestors and at most N descendants of \nthe seed interaction. The extractor prefers ancestors and descendants whose position in the input trace \nis close to the position of seed interaction. Once an interaction ts matching a seed is found, the extractor \nuses a two-step algorithm to produce a scenario. First, the extractor constructs the sets: Sa = {N closest \nancestors of ts} Sd = {N closest descendants of ts} Sad = {ts}. Sa . Sd The extractor uses a simple prioritized \nworklist algorithm to con\u00adstruct the set of ancestors (descendants). The initial worklist is the set \nof immediate ancestors (descendants) of ts. Repeatedly, un\u00adtil the worklist is empty or N ancestors (descendants) \nare found, the extractor removes from the worklist the ancestor (descendant) whose position in the trace \nis nearest ts, adds it to the set of ances\u00adtors (descendants), and adds its immediate ancestors (descendants) \nto the worklist. The result, Sad , is not necessarily a scenario, because interac\u00adtions along some .ow \ndependence chains from ancestors of ts to descendants of ts might be missing. Any such interactions must \nlie in the trace between the earliest ancestor ta in Sad and the lat\u00adest descendant td in Sad , and must \nbe reachable both by following .ow dependences from some ancestor of ts and by following .ow dependences \nin reverse from some descendant of ts. Thus, the ex\u00adtractor searches depth-.rst forwards from each element \nof Sa and backwards from each element of Sd to construct Sar = {t = [ta,td] |=t ' = Sa.t ' reaches t} \nSdr = {t = [ta,td] |=t ' = Sd.t ' reaches in reverse t} The .nal scenario is S = Sad . (Sar = Sdr ). \nFigure 10 shows a scenario extracted from the trace in Figure 2 with N = 10, around 1 socket(return = \n7) 2 bind(so = 7) 3 listen(so = 7) 4 accept(so = 7, return = 8) [seed] 5 read(fd = 8) 6 write(fd = 8) \n7 read(fd = 8) 8 write(fd = 8) 9 close(fd = 8) Figure 11: The simpli.cation of the scenario in Figure \n10. 1 socket(return = x0:T0) (A) 2 bind(so = x0:T0) (B) 3 listen(so = x0:T0) (C) 4 accept(so = x0:T0, \nreturn = x1:T0) [seed] (D) 5 read(fd = x1:T0) (E) 7 read(fd = x1:T0) (E) 6 write(fd = x1:T0) (F) 8 write(fd \n= x1:T0) (F) 9 close(fd = x1:T0) (G) Figure 12: Scenario string for the simpli.ed scenario from Fig\u00adure \n11. the accept on line 4. The seed is marked. Also note that the interactions in S inherit the dependences \nfrom the annotated trace. Simpli.cation Given the extracted scenarios, simpli.cation elimi\u00adnates all \ninteraction attributes that do not carry a .ow dependence in any training traces. The typing inferred \nby the dependence an\u00adnotator (see Section 3) assigns a type to an skeleton attribute if and only if an \ninstance of that attribute is involved in a .ow dependence somewhere in a trace. So, simpli.cation preserves \nan interaction at\u00adtribute if and only if the corresponding skeleton attribute is typed. Figure 11 is \nthe simpli.ed version of the scenario in Figure 10. Standardization Standardization converts a scenario \ninto a sce\u00adnario string for the PFSA learner. Standardization improves the performance of the PFSA learner \nby producing scenario strings so that similar scenarios receive similar strings. Figure 12 shows the \nresult of standardizing the scenario in Fig\u00adure 11. Standardization applies two transformations: naming \nand reordering. Naming replaces attribute values with symbolic variables. In Figure 12, value 7 is replaced \nwith the symbolic name x0:T0, and value 8 is replaced with the symbolic name x1:T0. Naming ex\u00adposes similarities \nbetween different scenarios by naming .ow de\u00adpendences. For example, a scenario extracted around line \n10 of Figure 2 manipulates different socket values (7 and 10 instead of 7 and 8), but naming still calls \none of these values x0:T0 and the other x1:T0. When a value .ows from one attribute to another, naming \nindi\u00adcates the dependence by assigning the same name to both attributes. The dependence annotation typing \n(section 3) guarantees that, if two skeleton attributes are assigned different types, values never .ow \nbetween instances of those attributes. Thus, naming uses a separate namespace for attributes of each \ntype. Figure 13 illus\u00adtrates how separate namespaces help expose more similarities to the PFSA learner. \nLines 2 and 3 of S0 and S1 are the same, but line 1 differs in each scenario. Assume that naming assigns \nnames to each interaction in turn, starting at the seed interaction. Without types, naming treats lines \n2 and 3 differently. Reordering standardizes the order of scenario interactions. A scenario contains \ninteractions that are partially ordered by .ow, anti, and output dependences. That is, each scenario \ncorresponds to Original S0 S1 SS 01 A(x=0, y=0) [seed] E(x=0, v=1) [seed] 01 1  0 B(x=0, y=0) B(x=0, \ny=0) 3 C(x=0, y=0) C(x=0, y=0) Untyped 1 A(x=x0, y=x1) E(x=x0, v=x1) B(x=x0, y=x1) B(x=x0, y=x2) 3 C(x=x0, \ny=x1) C(x=x0, y=x2) Typed 1 A(x=x0:T0, y=x0:T1) E(x=x0:T0, v=x0:T2) 2 B(x=x0:T0, y=x0:T1) B(x=x0:T0, \ny=x0:T1) 3 C(x=x0:T0, y=x0:T1) C(x=x0:T0, y=x0:T1) Figure 15: Equivalent scenarios. Naive(S) MaxSize \n:= maximum size of a scenario X := a totally ordered set of MaxSize symbolic names AllStrings := = Permutes \n:= all dependence-preserving permutations of S Foreach ( . Permutes Namings := all dependence-preserving \nnamings of ((S) from X Foreach r . Namings Add r(((S)) to AllStrings Return the lexicographically smallest \nelement of AllStrings Figure 16: Naive standardization algorithm. Now let S0 = s0,0,... ,s0,n and S1 \n= s1,0 ,... ,s1,n be two simpli.ed scenarios. S0 and S1 are equivalent iff there are Figure 14: Standardization, \nas a many-to-one mapping. dependence-preserving permutations 00 of S0 and 01 of S1 and dependence-preserving \nnamings 10 of 00(S0 ) and 11 of 01(S1 ) such that 10 (00(S0))= 11 (01(S1)) (Figure 15). In fact, the \na directed acyclic graph (DAG). The order in which the interactions appear in the original traces is \njust one legal total order. Reorder\u00ading puts two scenarios with the same DAG into the same total order, \neven when their trace order differs, so that a PFSA learner is pre\u00adsented with fewer distinct strings. \nIn Figure 12, reordering swapped the write on line 6 with the read on line 7. To a PFSA learner, each \ninteraction in a scenario string is merely an atomic letter. To emphasize this point, the right-hand \nside of Figure 12 replaces each interaction with a shorthand letter. Stan\u00addardization uses a small number \nof letters to represent a given set of scenarios. Using a small alphabet increases the PFSA learner s \nopportunities to .nd similarities in the scenario strings. Also, PFSA learners run more slowly with large \nalphabets. The rest of this section discusses our standardization algorithm in detail. At a high level, \nstandardization is a many-to-one mapping from simpli.ed scenarios to scenario strings (Figure 14). Under \nthis mapping, the preimage of a scenario string is a set of equiva\u00adlent scenarios. Intuitively, equivalent \nscenarios manipulate abstract objects in the same way. In the following, we de.ne equivalence, present \nour standardization algorithm, and show that equivalence characterizes the scenarios that standardization \nmaps to the same scenario string. Let S = s0,... ,sn be a simpli.ed scenario. A dependence\u00adpreserving \npermutation of S is a permutation 0 of S such that if d(si,sit ), then 0(i) <0(i ' ). That is, the permutation \ndoes not swap the source and sink of any dependence. Figure 12 illustrates a dependence-preserving permutation \nthat swaps the read on line 6 with the write on line 7. A naming 1 of S replaces each value in S with \na symbolic name, taken from a set X. If si.a is an attribute in S, 1(si.a) is the symbolic name given \nto that attribute in 1(S). We say that 1 is dependence-preserving if, for any si.a and sit .a ' , d(si.a, \nsit .a ' ) . 1(si.a) = 1(si.a ' ). choice of 00 and 10 is not important. We assert that if S0 and S1 \nare equivalent, then for any dependence-preserving 00 of S0 and dependence-preserving 10 of 00 (S0), \nthere is a dependence\u00adpreserving 01 of S1 and a dependence-preserving 11 of 01(11 ) such that 10 (00(S0 \n)) = 11 (01(S1)). Figure 16 presents a naive standardization algorithm. Naive tries all dependence-preserving \npermutations of S and all dependence-preserving namings of each permutation and returns the scenario \nstring that comes .rst in lexicographic order. If Naive assigns S0 and S1 the same scenario string, then \nS0 and S1 are equivalent, since the algorithm has found permutations and nam\u00adings that make them equal. \nAnd, if S0 and S1 are equivalent, then Naive generates the same AllStrings set for both of them. So, \nequivalence characterizes the preimage of Naive, as promised. However, the running time of the algorithm \nis exponential in |X| and |S|. The algorithm in Figure 17 removes the exponential behavior in |X| by \nconsidering only one standard naming for each permuted scenario. This optimization is safe because if \nS0 and S1 are equiv\u00adalent up to a dependence-preserving naming, then they differ only in their values, \nand StandardName does not depend on the iden\u00adtities of the values at attributes, but only on their types \nand the dependences that they carry. StandardName draws names from separate name spaces for separate \ntypes. The GetNextName operation returns the next available name in a name space in some .xed order, \nand resetting a name space causes it to begin again with the .rst name in the space. StandardName names \nthe seed interaction .rst, and then works outward. Because the name of a value must be chosen consistently, \nthe constraints on naming increase as interactions are named. In\u00adteractions near seeds are most likely \nto be similar across scenarios, so they are named .rst. The worst-case running time of Better is still \nexponential in NameInteraction(s) Foreach attribute s.a Type := the type of s.a s skeleton attribute \nValue := the value at s.a NameSpace := name space for Type If NameSpace[Value] has not been set NameSpace[Value] \n:= GetNextName(NameSpace) Replace Value with NameSpace[Value] in s.a StandardName(S = s0,... ,sn) is \n:= index of the seed in S NameInteraction(sis ) dist := 1 While is - dist . 0 or is + dist . n If is \n- dist . 0 NameInteraction(s is-dist) If is + dist . n NameInteraction(s is+dist) dist := dist +1 Better(S) \nReset all name spaces AllStrings := = Permutes := all dependence-preserving permutations of S Foreach \n( . Permutes Snamed := StandardName(((S)) Add Snamed to AllStrings Return the lexicographically smallest \nelement of AllStrings Figure 17: Better standardization algorithm. |S|. We can not expect to do better \nin the worst-case, because Better can be used to solve the DAG-isomorphism problem by encoding arbitrary \nDAGs as scenarios, and DAG-isomorphism is NP-complete. However, better performance is possible in the \ncom\u00admon case, since trace scenarios are not arbitrary DAGs. In particu\u00adlar, the interactions in a scenario \nhave names and named attributes. Our .nal standardization algorithm (Figure 18) uses those names to reduce \nthe number of permutations it considers. Standardize considers only dependence-preserving permu\u00adtations \nthat put the skeletons of the interactions in the smallest pos\u00adsible lexicographic order. Although there \ncan be an exponential number of such orderings, there is often only one. In that case, the set of interactions \nSelected (line *) always has one element, and the recursion never branches. With an appropriate implementation \nof OfLeastKinds (which sorts the interactions), the algorithm runs in that case in time proportional \nto n log n. In our experience, the time spent running Standardize is an insigni.cant part of the scenario \nextraction time.  4.2 Automaton learning This section presents the algorithms and data structures used \nin learning the speci.cation automaton. The automaton A is an NFA with edges labelled by standardized \ninteractions, whose language includes the most common substrings of the scenario strings ex\u00adtracted from \nthe training traces, plus other strings that the PFSA learner adds as it generalizes. Automaton learning \nhas two steps. First, an off-the-shelf learner learns a PFSA. Then, the corer re\u00admoves infrequently traversed \nedges and converts the PFSA into an NFA. The PFSA learner is an off-the-shelf learner [22] that learns \na PFSA that accepts the training strings, plus other strings. The learner is a variation on the classic \nk-tails algorithm [4]. Brie.y, the k-tails algorithm works as follows. First, a retrieval tree is con\u00adstructed \nfrom the input strings. The algorithm then computes all strings of length up to k (k-strings) that can \nbe generated from each state in the trie. If two states qa and qb generate the same k-strings, OfLeastSkeletons(S) \n'' Return {s . S | \u00ac.s. skeleton of s precedes skeleton of s lexicographically} RestrictedPermutations(S, \nPos) Permutes := = '' Ready := {s . S | \u00ac.s . S. d(s ,s)} * Selected := OfLeastSkeletons(Ready) Foreach \ns . Selected Rest := RestrictedPermutations(S -{s}, Pos +1) Foreach (r . Rest ( := (r ={Pos . s} Permutes \n:= Permutes ={(} Return Permutes Standardize(S) Reset all name spaces AllStrings := = Permutes := RestrictedPermutations(S, \n0) Foreach ( . Permutes Snamed := StandardName(((S)) Add Snamed to AllStrings Return the lexicographically \nsmallest element of AllStrings start 5 5 10000 5 5 final Figure 19: A PFSA for which dropping edges \nwith low weights does not identify the hot core. Edge labels are omitted. they are merged. The process \nrepeats until no more merges are pos\u00adsible. The PFSA learner modi.es k-tails by comparing how likely \ntwo states are to generate the same k-strings. The resulting PFSA accepts a superset of all the strings \nin the training scenarios, due to the generalizations performed by the learner. The parameter N that \ncontrols the size of the training sce\u00adnarios is chosen by the user to be large enough to include all \nof the interesting behavior. It is therefore very likely that the ends of the training scenarios contain \nuninteresting behavior. This is in fact what we see experimentally: the typical PFSA has a hot core with \na few transitions that occur frequently, with the core surrounded by a cold region with many transitions, \neach of which occurs infre\u00adquently. The corer whittles away the cold region, leaving just the hot core. \nThe corer can not simply drop edges with low weights. Consider the PFSA in Figure 19 (edge labels are \nnot important and are omit\u00adted). Four edges have a weight of 5, which is low compared to the three edges \nwith a weight of 10000. However, any string through this PFSA must traverse the edge out of the start \nstate and the edge into the end state. Despite their low weight, a string is more likely to traverse \nthese edges than it is to traverse the edges with a weight of 10000. Thus, a better measure of an edge \ns heat is its likeli\u00adhood of being traversed while generating a string from the PFSA. The problem of \ncomputing this measure is known as the Markov -1 -1 chain problem [15]. The problem reduces to inverting \na square ma\u00adtrix with the number of rows and columns equal to the number of transitions in the PFSA. \nAfter computing the heat of each edge, the corer removes all edges below a cutoff parameter, removes \nunreachable states from the PFSA, and drops the frequencies on the edges. The result is an NFA, which \na human can validate by inspection. 5. VERIFICATION This section discusses how veri.cation tools can \nuse the miner s speci.cations. Program veri.cation tools distinguish programs that satisfy a speci.cation \nfrom programs that do not. Before we can discuss these tools, we must clarify what we mean by satisfying \na speci.cation . Let A be a speci.cation. By construction, the language of A con\u00adtains a set of scenario \nstrings (Figure 20). The containment might be strict since the automaton learner can introduce strings \ninto A that are not scenario strings. Because standardization is a many\u00adto-one mapping (see Figure 14), \neach scenario string corresponds to a set of simpli.ed scenarios. In turn, each scenario string corre\u00adsponds \nto a set of concrete scenarios. Figure 20 shows the chain of mappings. We say that the scenarios of Figure \n20 satisfy A. Now let T be an interaction trace. We say that T satis.es A if for every seed interaction \nis = T , there is an interaction scenario Sis seeded by is such that Sis satis.es A. We say that a program \nP sat\u00adis.es a speci.cation A if any interaction trace T of P s execution satis.es A. Constructing program \nveri.cation tools for speci.cations is out\u00adside the scope of this paper, but is the subject of ongoing \nresearch. There are two ways that such a tool could work. First, the tool could construct a scenario \nthat satis.es A for each interaction seed encountered while simulating some abstraction of P , reporting \nan error if no such scenario can be constructed for some seed. Al\u00adternatively, the tool could .rst translate \nA into an automaton that generates traces instead of scenario strings. The trace automaton generates \nall traces that satisfy A. The veri.cation tool would then exhaustively search for a trace that is not \nin A, reporting an error if one is found. Both sorts of tools must be able to simulate simpli.\u00adcation \nand standardization. Figure 21 shows a trace veri.cation algorithm (not a program veri.cation algorithm) \nthat works in the .rst way. This is the al\u00adgorithm used in our experiments (see Section 6). Verify takes \na trace, a speci.cation, and a maximum scenario size. It attempts to verify that the trace satis.es the \nspeci.cation by extracting suc\u00adcessively larger scenarios until it .nds a satisfactory one or until it \nreaches the maximum scenario size. Because interactions in the trace are not necessarily ordered as they \nwere in the training traces, the algorithm does not use exactly the same extraction algorithm as the \nlearner. Instead, Extract'(ti, Size) returns all scenarios seeded by ti with a total of exactly Size \nancestors and descen\u00addants. The distance between the seed and its ancestors and descen\u00addants is not important. \nSatisfies(S, Spec) If S is in the language of Spec Return true Else Return false Verify(T = t0 ,... ,tn, \nSpec, MaxSize) Loop: Foreach ti . SeedsOf(T ) Size := 0 While Size : MaxSize Scenarios := Extract'(ti, \nSize) Foreach S . Scenarios Sstd := Standardize(S) If Satisfies(Sstd , Spec) Next Loop Size := Size +1 \nReturn Fails(ti) Figure 21: Trace veri.cation algorithm. Name bitmap xclipboard xconsole xcutsel xterm \nclipboard cxterm display e93 kterm nedit pixmap rxvt ted test canvas ups xcb  Source distrib distrib \ndistrib distrib distrib contrib contrib contrib contrib contrib contrib contrib contrib contrib contrib \ncontrib contrib Static seeds 1 2 1 1 1 1 1 4 1 1 2 1 1 3 1 1 1 Scenarios 6 2 1 4 6 2 9 16 2 4 2 11 4 \n9 4 3 11 Table 1: X11 client programs studied in the experiment.  6. EXPERIMENTAL RESULTS This section \npresents the results of an experiment in mining spec\u00adi.cations from traces of X11 programs. We analyzed \ntraces from programs that use the Xlib and X Toolkit Intrinsics libraries for the X11 windowing system. \nThe traces record an interaction for each X library call and callback from the X library to client code. \nThe interaction attributes include all arguments and return values of calls, plus the .elds of the structures \nthat represent X protocol events. The tracing tool uses the Executable Editing Library (EEL) [17] to \ninstrument Solaris/SPARC executables. Traces were collected from full runs of widely distributed pro\u00adgrams \nthat use the X11 selection mechanism. We studied the selec\u00adtion mechanism since the Interclient Communication \nConventions Manual (ICCCM) [25] gives English descriptions of several rules for how well-behaved programs \nshould use the mechanism. The experiment concentrated on a rule that speci.es how programs ob\u00adtain ownership \nof the selection: the rule says that a client calling XtOwnSelection or XSetSelectionOwner must pass \nin a timestamp derived from the X event that triggered the call. Table 1 lists each program studied, \nits origin (either the X11 dis\u00adtribution or the X11 contrib directory), the number of static calls to \nthe X library routines chosen as seeds, and the number of training scenarios extracted from each trace. \nOne of the authors gathered the traces by running each program for a few minutes, while trying to exercise \nthe selection code by doing cut-and-paste operations, as well as exercising as much other functionality \nas possible in a short time. Speci.cation mining depends on a sizable training set of well\u00addebugged traces. \nIn our case, the number of training traces was small, and as it turned out, several contained violations \nof the rule. As a result, the miner was not able to discover the rule when trained on all of the programs. \nIn order to learn the rule, we needed to remove the buggy traces from the training set. We hypothesized \nthat our miner could help .nd the bugs, even with a poor training set. Identifying the buggy traces without \nthe miner would require inspecting each trace manually for bugs. Using the miner, we predicted that, \nwhile we would have to in\u00adspect the .rst few traces, once a few correct traces had been col\u00adlected, the \nminer s rule could be used to automatically validate the remaining traces. In this experiment, we arranged \nthe client pro\u00adgrams in random order and went through the following iterative process: Run the .rst program \nand gather a trace Mine a speci.cation from the trace Expert examines the speci.cation Expert extracts \nhot core If the speci.cation is not correct Select another random order and start over For each remaining \nclient program in order Run the program and gather a trace Verify the trace against the speci.cation \nIf veri.cation succeeds Add the trace to the training set Generate a new speci.cation Else Examine the \nscenarios that failed If no scenario violates the ICCCM rule Add the trace to the training set Generate \na new, more general speci.cation Else Report the bug For each trace that fails to verify, the expert \neither marks it as buggy or includes it in the training set. The expert decides whether the initial speci.cation \nis correct: in our experiment, we accepted the initial speci.cation if we did not see any obvious bugs \nin the .rst set of training scenarios. The expert also needs to extract the hot core, since the training \nset is too small to use the corer. The experiment tested three hypotheses: Hypothesis 1 The process will \n.nd bugs and reduce the number of traces that the expert must inspect. Hypothesis 2 The miner s .nal \nspeci.cation will match the rule in the ICCCM. Hypothesis 3 The corer and the human will agree on which \nstates in the .nal PFSA belong in the .nal speci.cation. Table 2 lists the client programs in the order \nin which they were processed. Out of the .rst six traces accepted (not including the ini\u00adtial trace), \n.ve were rejected by an overly narrow speci.cation. At this point, the speci.cation seemed to stabilize: \nout of the next four accepted, only one was initially rejected by the dynamic veri.er. The expert did \nnot have to inspect 4 out of the 16 the traces, which supports the second part of Hypothesis 1. We conjecture \nthat if the process had continued, the false rejection rate would have contin\u00adued to drop.   Name \nVeri.es? Reason for failure Action xcb n/a n/a accept bitmap no spec. too narrow accept ups no bug! reject \nted no spec. too narrow accept rxvt yes n/a accept xterm no spec. too narrow accept display no spec. \ntoo narrow accept xcutsel no spec. too narrow accept kterm yes n/a accept pixmap yes n/a accept cxterm \nyes n/a accept xconsole no benign violation reject nedit no spec. too narrow accept e93 no bug! reject \nxclipboard no benign violation reject clipboard no benign violation reject Table 2: Results of processing \neach client program, in the order in which they were processed. D A B = XNextEvent(time = X21_0) or \nB = XtDispatchEvent(time = X21_0) or B = XIfEvent(time = X21_0) C = XtDispatchEvent(time = X21_0) or \nC = XtEventHandler(time = X21_0) or C = XtLastTimeStampProcessed(time = X21_0) D = XGetSelectionOwner \nE = XSetSelectionOwner(time = X21_0) F = XtOwnSelection(time = X21_0) G = XtActionHookProc(time = X21_0) \nH = XInternAtom Figure 22: The NFA from the selection ownership speci.cation. Five of the programs violated \nthe rule in the ICCCM. We found three programs with benign violations of the speci.cation and two programs \nwith bugs. The speci.cation applies to programs that use the selection mechanism to do cut-and-paste, \nwhile the programs with benign violations used the selection mechanism to implement their own communication \nprotocol. These violations indicate that the rule described by the ICCCM is not universally applicable \nand that the document should be clari.ed. Thus, the speci.cation miner helped .nd bugs and a documentation \nomission (an unexpected bene.t). Figure 22 is the speci.cation from the experiment. For legibil\u00adity s \nsake, the .gure omits some arguments. These arguments did not participate in dependences within the core \nof the speci.cation. The speci.cation is compact, with six states and nine edges. It also matches the \nEnglish rule very closely, with most complexity aris\u00ading from the several ways in which the X API receives \nan event. In addition, the speci.cation exposes a common pattern in which the client calls XSetSelectionOwner \nrepeatedly until XGetSe\u00adlectionOwner indicates that the call was successful. Our .nal hypothesis was \nthat the corer and the expert would agree on which states in the .nal PFSA should be thrown out. The \n.nal PFSA had 27 states. The expert, who did not have access to the corer s results, threw out 15 of \nthese and retained 12; the remaining twelve were merged to form the NFA in Figure 22. The corer and the \nexpert disagreed on .ve out of the 27 states, or 19%. The corer assigned likelihoods lower than 6% to \n13 of the 15 deleted states, and likelihoods higher than 13% to 9 of the 12 retained states. The other \n2 deleted states had likelihoods of 13% and 20%, while the remaining retained states had likelihoods \nof 5%, 6%, and 9%.  7. RELATED WORK Ernst et al. also proposed automatic deduction of formal speci.\u00adcations \n[11]. Their Daikon tool works by learning likely invariants involving program variables from dynamic \ntraces. The resulting formal speci.cations is the key difference between their approach and ours. Daikon \ns speci.cations are arithmetic relationships that hold at speci.c program points (e.g., a precondition \nx<y at entry to a procedure f). By contrast, our speci.cations express temporal and data-dependence relationships \namong calls to an API. Our tem\u00adporal speci.cations capture a different aspect of program behavior than \nDaikon s predicates on values and structures. The two forms of speci.cations are complementary, but naturally \nrequire radically different learning algorithms. Recently, Ernst et al. presented techniques for suppressing \nparts of their learned speci.cations that are not useful to a program\u00admer [19]. In the context of our \ntemporal speci.cations, this result corresponds to appropriately selecting the heavy core of the initial \nPFSA. Another related tool is Houdini [12], an annotation assistant for ESC/Java. Starting from an initial \n(guessed) candidate set of annotations, which are similar to those of Daikon, Houdini uses ESC/Java to \nrefute invalid annotations. The focus of Houdini is on annotating points of a single program with true \nproperties, while the focus of our tool is on discovering temporal properties that hold across all programs \nthat use an interface. Other authors have described tools that extract automaton-based models. Cook and \nWolf describe a tool for extracing FA models of software development processes from traces of events \n[8]. Our work differs in that we extract speci.cations from program traces, which must be reduced to \na simpler form before they are palat\u00adable for an FA learner. Ghosh et al. describe several techniques \nfor learning the typical behavior of programs that make system calls [13, 18]. Since they intend their \nmodels for intrusion detec\u00adtion, the models need only characterize a particular program s be\u00adhavior, \nwhile our miner .nds rules that are generally applicable and understandable by humans. Wagner and Dean \ns intrusion detection system also extracts automaton models, but from source code, not traces [27]. Their \nsystem also extracts models that apply only to a single program. Finally, Reiss and Renieris also extract \nstruc\u00adture from traces [23], but they model the sequence of operations on individual objects, not the \ndata and temporal dependences across several objects. 8. CONCLUSION This paper addresses an important \nproblem in the program\u00adveri.cation tool chain, namely the problem of semi-automatic for\u00admulation of correctness \nspeci.cations that could be accepted by model checkers and other similar tools. We have formulated the \nproblem as a machine learning problem and provided an algorithm based on a reduction to .nite automaton \nlearning. While some more experimental work remains ahead of us, initial experience is promising. Acknowledgements \nWe thank Anand Raman, Peter Andreae, and Jon D. Patrick for al\u00adlowing us to use their PFSA learner, as \nwell as the anonymous refer\u00adees for their many helpful comments on an early draft of this paper. This \nwork was supported in part by the National Science Founda\u00adtion with grants CCR-0093275 and CCR-0103670, \nthe University of Wisconsin Graduate School, and donations from IBM and Mi\u00adcrosoft Research. 9. REFERENCES \n[1] Thomas Ball, Rupak Majumdar, Todd Millstein, and Sriram K. Rajamani. Automatic predicate abstraction \nof C programs. In Proceedings of the 2001 ACM SIGPLAN Conference on Programming Language Design and Implementation, \nvolume 36 of ACM SIGPLAN Notices, pages 203 213, July 2001. [2] Thomas Ball and Sriram K. Rajamani. \nAutomatically validating temporal safety properties of interfaces. In Proceedings of the 8th International \nSPIN Workshop on Model Checking of Software, number 2057 in Lecture Notes in Computer Science, pages \n103 122, May 2001. [3] Thomas Ball and Sriram K. Rajamani. Bebop: a path-sensitive interprocedural data.ow \nengine. In Proceedings of the 2001 ACM SIGPLAN-SOGSOFT Workshop on Program Analysis for Software Tools \nand Engineering, ACM SIGPLAN Notices, pages 97 103, July 2001. [4] A. W. Biermann and J. A. Feldman. \nOn the synthesis of .nite-state machines from samples of their behaviour. IEEE Transactions on Computers, \n21:591 597, 1972. [5] William R. Bush, Jonathan D. Pincus, and David J. Sielaff. A static analyzer for \n.nding dynamic programming errors. Software Practice and Experience, 30:775 802, 2000. [6] Andy Chou, \nJunfeng Yang, Benjamin Chelf, Seth Hallem, and Dawson Engler. An empirical study of operating systems \nerrors. In Proceedings of the 18th ACM Symposium on Operating Systems Principles (SOSP18), pages 73 88, \nOctober 2001. [7] Douglas E. Comer and David L. Stevens. Internetworking with TCP/IP. Client-server Programming \nand Applications, BSD Socket Version. Prentice-Hall, Englewood Cliffs, NJ 07632, USA, 1993. [8] Jonathan \nE. Cook and Alexander L. Wolf. Discovering models of software processes from event-based data. ACM Transactions \non Software Engineering and Methodology, 7(3):215 249, July 1998. [9] Robert DeLine and Manuel F\u00a8ahndrich. \nEnforcing high-level protocols in low-level software. In Proceedings of the SIGPLAN 01 Conference on \nProgramming Language Design and Implementation (PLDI), pages 59 69, June 2001. [10] Dawson Engler, David \nYu Chen, Seth Hallem, Andy Chou, and Benjamin Chelf. Bugs as deviant behavior: a general approach to \ninferring errors in system code. In Proceedings of the 18th ACM Symposium on Operating Systems Principles \n(SOSP18), pages 57 72, October 2001. [11] Michael D. Ernst, Jake Cockrell, William G. Griswold, and David \nNotkin. Dynamically discovering likely program invariants to support program evolution. IEEE Transactions \nin Software Engineering, 27(2):1 25, February 2001. [12] Cormac Flanagan and K. Rustan M. Leino. Houdini, \nan annotation assistant for ESC/java. In International Symposium on FME 2001: Formal Methods for Increasing \nSoftware Productivity, LNCS, volume 1, 2001. [13] Anup K. Ghosh, Christoph Michael, and Michael Shatz. \nA real-time intrusion detection system based on learning program behavior. In RAID 2000, volume 1907 \nof Lecture Notes in Computer Science, pages 93 109, 2000. [14] E Mark Gold. Language identi.cation in \nthe limit. Information and Control, 10:447 474, 1967. [15] Michel Gondran and Michel Minoux. Graphs and \nAlgorithms. John Wiley and Sons, 1984. [16] Michael Kearns, Yishay Mansour, Dana Ron, Ronitt Rubinfeld, \nRobert E. Schapire, and Linda Sellie. On the learnability of discrete distributions. In Proceedings of \nthe Twenty-sixth ACM Symposium on Theory of Computing, pages 273 282, 1994. [17] James R. Larus and Eric \nSchnarr. EEL: Machine-independent executable editing. In Proceedings of the SIGPLAN 95 Conference on \nProgramming Language Design and Implementation (PLDI), pages 291 300, June 1995. [18] Christoph Michael \nand Anup Ghosh. Using .nite automata to mine execution data for intrusion detection: a preliminary report. \nIn RAID 2000, volume 1907 of Lecture Notes in Computer Science, pages 66 79, 2000. [19] William G. Griswold \nMichael D. Ernst, Adam Czeisler and David Notkin. Quickly detecting relevant program invariants. In Proceedings \nof the 22nd International Conference on Software Engineering, June 2000. [20] Kevin P. Murphy. Passively \nlearning .nite automata. Technical Report 96-04-017, Santa Fe Institute, 1996. [21] Anand Raman, Peter \nAndreae, and Jon Patrick. A beam search algorithm for pfsa inference. Pattern Analysis and Applications, \n1(2), 1998. [22] Anand V. Raman and Jon D. Patrick. The sk-strings method for inferring PFSA. In Proceedings \nof the workshop on automata induction, grammatical inference and language acquisition at the 14th international \nconference on machine learning (ICML97), 1997. [23] S. P. Reiss and M. Renieris. Encoding program executions. \nIn Proceedings of the 23rd International Conference on Software Engeneering (ICSE-01), pages 221 232, \nLos Alamitos, California, May12 19 2001. IEEE Computer Society. [24] Dana Ron, Yoram Singer, and Naftali \nTishby. On the learnability and usage of acyclic probabilistic .nite automata. In Proceedings of the \n8th Annual Conference on Computational Learning Theory, pages 31 40. ACM Press, New York, NY, 1995. [25] \nDavid Rosenthal. Inter-client communication conventions manual (ICCCM), version 2.0. X Consortium, Inc. \nand Sun Microsystems, 1994. Part of the X11R6 distribution. [26] Robert Endre Tarjan. Ef.ciency of a \ngood but not linear set union algorithm. Journal of the ACM, 22(2):215 225, 1975. [27] David Wagner and \nDrew Dean. Intrusion detection via static analysis. In Proceedings of the 2001 IEEE Symposium on Security \nand Privacy, May 2001.  \n\t\t\t", "proc_id": "503272", "abstract": "Program verification is a promising approach to improving program quality, because it can search all possible program executions for specific errors. However, the need to formally describe correct behavior or errors is a major barrier to the widespread adoption of program verification, since programmers historically have been reluctant to write formal specifications. Automating the process of formulating specifications would remove a barrier to program verification and enhance its practicality.This paper describes <i>specification mining</i>, a machine learning approach to discovering formal specifications of the protocols that code must obey when interacting with an application program interface or abstract data type. Starting from the assumption that a working program is well enough debugged to reveal strong hints of correct protocols, our tool infers a specification by observing program execution and concisely summarizing the frequent interaction patterns as state machines that capture both temporal and data dependences. These state machines can be examined by a programmer, to refine the specification and identify errors, and can be utilized by automatic verification tools, to find bugs.Our preliminary experience with the mining tool has been promising. We were able to learn specifications that not only captured the correct protocol, but also discovered serious bugs.", "authors": [{"name": "Glenn Ammons", "author_profile_id": "81546156556", "affiliation": "University of Wisconsin, Madison, Wisconsin", "person_id": "PP39040589", "email_address": "", "orcid_id": ""}, {"name": "Rastislav Bod&#237;k", "author_profile_id": "81100033082", "affiliation": "University of Wisconsin, Madison, Wisconsin", "person_id": "P239460", "email_address": "", "orcid_id": ""}, {"name": "James R. Larus", "author_profile_id": "81100277326", "affiliation": "Microsoft Research, One Microsoft Way, Redmond, Washington", "person_id": "P132790", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/503272.503275", "year": "2002", "article_id": "503275", "conference": "POPL", "title": "Mining specifications", "url": "http://dl.acm.org/citation.cfm?id=503275"}