{"article_publication_date": "01-01-2002", "fulltext": "\n Exploiting Proli.c Types for Memory Management and Optimizations ... Ye.m Shuf Manish Gupta tRajesh \nBordawekar tJaswinder Pal Singh \u00a7 tIBM T. J. Watson Research Center P. O. Box 218 Yorktown Heights, NY \n10598 ye.m, mgupta, bordaw}@us.ibm.com  ABSTRACT In this paper, we introduce the notion of proli.c \nand non-proli.c types, based on the number of instantiated objects of those types. We demonstrate that \ndistinguishing between these types enables a new class of techniques for memory management and data locality, \nand facilitates the deployment of known techniques. Speci.cally, we .rst present a new type-based approach \nto garbage collection that has similar attributes but lower cost than generational collec\u00adtion. Then \nwe describe the short type pointer technique for reduc\u00ading memory requirements of objects (data) used \nby the program. We also discuss techniques to facilitate the recycling of proli.c ob\u00adjects and to simplify \nobject co-allocation decisions. We evaluate the .rst two techniques on a standard set of Java benchmarks \n(SPECjvm98 and SPECjbb2000). An implementation of the type-based collector in the Jalape no VM shows \nimproved pause times, elimination of unnecessary write barriers, and reduc\u00adtion in garbage collection \ntime (compared to the analogous gener\u00adational collector) by up to 15%. A study to evaluate the bene.ts \nof the short-type pointer technique shows a potential reduction in the heap space requirements of programs \nby up to 16%. 1. INTRODUCTION A number of software and hardware technological trends point to the growing \nimportance of automatic memory management and optimizations oriented towards reducing the cost of memory \nac\u00adcesses. On the hardware side, the gap between processor and mem\u00adory speeds continues to grow, motivating \nthe need for optimizations to enhance data locality, including those that reduce the amount of memory \nbeing consumed by applications. On the software side, the use of object-oriented programming and reliance \non automatic memory management is becoming more prevalent due to the ac\u00adcompanying productivity gains. \nIn particular, the popularity of the Java programming language [21] has increased a great deal the in\u00adterest \nin automatic memory management. Java is being widely used on systems ranging from embedded devices to \nhigh-end servers. On all of these systems, the ef.cient utilization of memory and re\u00adduced space requirements \nof applications (besides being inherently useful for memory-limited embedded devices) lead to higher \nper- Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PPOPL \n02, Jan. 16-18, 2002 Portland, OR USA c 2002 ACM ISBN 1-58113-450-9/02/01 ...$5.00. \u00a7Computer Science \nDepartment Princeton University Princeton, NJ 08544 yshuf, jps}@cs.princeton.edu formance and lower \npower consumption. Proli.c and non-proli.c types. In this paper, we introduce the notion of proli.c and \nnon-proli.c types as a framework for improv\u00ading automatic memory management. We present results from \nan empirical study of some well-known Java applications, which show that for each program, relatively \nfew object types usually account for a large percentage of objects (and heap space) cumulatively al\u00adlocated \nby the program. We refer to those frequently instantiated object types as proli.c types and the remaining \nobject types as non\u00adproli.c types. We suggest several optimizations that can potentially exploit the \ndistinction between proli.c and non-proli.c types, both to improve performance with new memory management \ntechniques as well as to simplify the deployment of some well-known tech\u00adniques. In this paper, we primarily \nfocus on two speci.c applica\u00adtions of the idea: type-based garbage collection 1 and reducing the amount \nof memory consumed by objects. Type-based garbage collection We .rst present a novel type\u00adbased approach \nto garbage collection based on the notion of proli.c and non-proli.c object types. We propose a new proli.c \nhypothe\u00adsis, which states that objects of proli.c types die younger than ob\u00adjects of non-proli.c types. \nOur approach relies on .nding garbage primarily among proli.c objects. It is, therefore, conceptually \nsim\u00adilar to generational garbage collection, but it distinguishes between generations of objects based \non type rather than age. Generational garbage collection [29, 6] is one of the popular ap\u00adproaches to \ngarbage collection. It is inspired by an observation, known as the weak generational hypothesis, that \nmost objects die young [45]. A simple generational scheme involves partitioning the heap space into two \nregions a nursery (or new generation) and an old generation (or a mature space) 2. All new objects are \nallocated in the nursery. Most collections, termed minor collections, only re\u00adclaim garbage from the \nnursery. Survivors from a minor collection are promoted to the older generation, which is subjected to \ncollec\u00adtion only during infrequent, major collections. In order to support a generational collection, \nthe compiler has to insert a write barrier for each statement writing into a pointer .eld of an object, \nto keep track of all pointers from objects in the old generation to objects in the nursery. These source \nobjects in the old generation are added as roots for minor collection, so that objects in the nursery \nwhich are reachable from those objects are not collected by mistake. Com\u00adpared with their non-generational \ncounterparts, generational col\u00adlectors typically cause shorter pauses for garbage collection, due to \nthe need to look at a smaller heap partition at a time, but lead to Not to be confused with type-accurate \ngarbage collection. There are also multi-generational garbage collection schemes with more than two generations. \n lower throughput of applications due to the overhead of executing write barriers. In our type-based \ngarbage collector, all objects of proli.c types are assigned at allocation time to a proli.c region (P-region), \nwhich is analogous to a nursery in a conventional generational collector. All minor collections are performed \nin the P-region. All objects of non-proli.c types are allocated to a non-proli.c region (NP\u00adregion), \nwhich corresponds to the old generation in a generational collector with two generations.3 Unlike generational \ncollection, ob\u00adjects are not promoted from the P-region to the NP-region after a minor collection. This \napproach leads to several bene.ts over generational collection: It allows a compiler to identify and \neliminate unnecessary write barriers using simple type checks. This leads to per\u00adformance bene.ts like: \n reduction in the direct overhead of executing write bar\u00adriers; and  for some write barrier implementations, \na reduction in the number of roots that are considered during minor collections, leading to fewer objects \nbeing scanned and potentially fewer collections.  It reduces the number of reference .elds examined \nduring garbage collection by using static type information to infer the direction of pointers. It avoids \nthe problems associated with premature promotion of young objects that are going to die soon anyway, \nsuch as executing more write barriers, dragging dead objects into the old generation, and requiring more \nmajor collections. In a copying collector, the overhead of copying objects of non-proli.c types across \ngenerations is avoided. With an implementation of the type-based (non-copying) col\u00adlector in the Jalape \nno VM [2], the number of dynamically exe\u00adcuted write barriers is reduced by up to 74% for SPECjvm98 [37] \nand SPECjbb2000 [38] benchmarks, and we observe shorter pause times. The total garbage collection times \nare reduced by an average of 7.4% over all benchmark programs, with an improvement of up to 15.2% for \njavac. Reducing memory consumed by objects We also use the con\u00adcept of proli.c types in a technique that \nreduces the space require\u00adments of applications written in object-oriented languages such as Java and \nincreases the data locality in those applications. The tech\u00adnique relies on three observations: (i) the \nnumber of proli.c types in a program is usually small, (ii) the pointers to type descriptors (run-time \nobjects with class information) in two different objects of the same type are identical, (iii) objects \nof a proli.c type are usu\u00adally quite small. The short type pointer technique eliminates much of the space \noverhead in the headers of proli.c objects by eliminat\u00ading the pointer to a type descriptor and replacing \nit with only a few bits. An initial study on a suite of Java benchmarks (SPECjvm98, SPECjbb200, and JavaGrande \napplication suite) indicates potential memory savings of 9% to 16% using this approach. Using smaller \nheap space can lead to less frequent garbage collections as well as fewer main memory accesses and improved \ndata locality during program execution. Other optimizations We describe a technique for recycling pro\u00adli.c \nobjects. This technique can streamline the memory manage\u00adment of commonly allocated objects. We also \nbrie.y discuss a new m We can extend our approach to be analogous to a generational col\u00adlector with several \ngenerations by de.ning multiple levels of pro\u00adli.cacy of types. approach to object co-allocation which \nrelies on the proli.cacy of types to make object co-allocation decisions. By placing closely\u00adrelated \nobjects together, this technique can improve the data local\u00adity of applications. Organization The rest \nof the paper is organized as follows. Sec\u00adtion 2 describes proli.c and non-proli.c types and techniques \nto identify proli.c types. Section 3 discusses our proposed approach to type-based garbage collection. \nIn Section 4, we discuss the short type pointer scheme. In Section 5, we describe other optimizations \nlike object recycling and object co-allocation that can bene.t from exploiting the distinction between \nproli.c and non-proli.c objects. Section 6 describes an implementation of the simplest, non-copying version \nof the type-based collection approach in the Jalape no VM, and presents our experimental results; it \nalso presents empirical data demonstrating the potential of the short type pointer technique. Section \n7 discusses related work. Section 8 presents conclusions and Section 9 presents ideas for future work. \n 2. PROLIFIC AND NON-PROLIFIC TYPES It is well known that for most applications, a large percentage of \nthe program execution time is spent in a relatively small section of code. This behavior is exploited \nby adaptive runtime compil\u00aders like the Hotspot compiler [26] and the Jalape no adaptive opti\u00admization \nsystem [4], as they focus expensive optimizations on those hot-spots . It is not surprising that a similar \nhot-spot behavior is exhibited by object-oriented programs with respect to the types of objects that \nare created in those programs. In a study of some well\u00adknown Java benchmarks (namely, SPECjvm98 and SPECjbb2000), \nwe have con.rmed this observation. For example, in the jackpro\u00adgram, 13 types account for 95% of all \nallocated objects, which also occupy 95% of the heap space allocated by this program. The data for other \napplications we studied can be found in Table 6, Figure 2, and Figure 3. We de.ne the term proli.c to \nrefer to a type that has a suf.\u00adciently large number of instances. In other words, a type is proli.c \nwith respect to a program if the fraction of objects allocated by the program that are of this type exceeds \na certain threshold.4 All remaining types are referred to as non-proli.c. 2.1 Identifying Proli.c Types \nWe now discuss a few approaches that may be used to identify proli.c types. These approaches vary in \nterms of their overhead and accuracy. However, a misclassi.cation of types does not create a correctness \nproblem. The simplest method of identifying proli.c types is to use of.ine pro.ling. In an of.ine run, \na runtime system monitors memory al\u00adlocation requests issued by an application and counts the number \nof objects of each type that are allocated on behalf of an applica\u00adtion. When an application exits, the \ncollected allocation pro.le is saved by a JVM into a .le. During an actual run, the runtime sys\u00adtem uses \npreviously collected allocation pro.les to perform various optimizations. Thus, no monitoring overhead \nis incurred during the production run of the application. An adaptive approach, in contrast to the of.ine \npro.ling ap\u00adproach, is more accurate and attempts to identify proli.c types dur\u00ading the actual production \nrun of the program. An obvious adaptive strategy would be to monitor each memory allocation in an appli\u00adcation. \nTo reduce the overhead of monitoring object allocations, sampling techniques, such as those presented \nin [1], can be used. It is not clear whether a static compile-time analysis alone (with\u00adout pro.ling) \ncan be effective in identifying proli.c types. In pro\u00ad o In our experiments, the threshold is set to \n1% of the total number of objects created by an application. grams where the number of objects created \nat run time depends on the input data, it may not even be possible. Therefore, pro.ling is a good choice \nfor determining proli.c types.  2.2 Checking a Variable for Proli.c Type Most of our optimizations that \nexploit the distinction between proli.c and non-proli.c types require a compile-time test for whether \nan object is of a proli.c type. In an object-oriented language with polymorphism, such as Java, this \ntest requires analyses like class hierarchy analysis [16] or rapid type analysis [5], similar to those \nneeded for inlining or devirtualization of methods. Given a de\u00adclared type Tof an object 0, the compiler \nchecks for 0being de.\u00adnitely proli.c by checking that all children of Tin the class hierar\u00adchy are proli.c. \nDynamic class loading [21] is another feature of Java that forces us to do compile-time analysis more \nconservatively. Again, the problem is similar to the problem with inlining of virtual methods in the \npresence of dynamic class loading [17, 36]. Due to dynamic class loading, a program can load a new class \nthat is non-proli.c but subclasses a proli.c class, unless the proli.c class is declared final. It is \npossible to use the techniques for inlining virtual methods in the presence of dynamic class loading, \nlike preexistence analy\u00adsis [17] and extant analysis [36], to improve the effectiveness of the test for \na type being de.nitely proli.c. For example, using extant analysis, if we create a specialized method \nin which the reference to 0is known to be extant (i.e., pointing to an existing object) [36], the test \nfor 0being proli.c can be performed based on the existing class hierarchy, without worrying about any \nnew classes that might be loaded. We propose an alternate approach, described below, which leads to a \nmuch simpler compile-time test. We postulate that the proli.c types are likely to be leaves, or close \nto leaves, in a type hierarchy. The intermediate classes are typically used for de.ning functional\u00adity \nthat is common to all of their children classes. The subclasses re.ne the behavior of their parent classes \nand are usually instan\u00adtiated more frequently than their respective parent classes. While it is possible \nthat a proli.c class may have one or more subclasses that are not proli.c, we have made a choice to treat \nall children of proli.c types as proli.c. This greatly simpli.es the test to check if a type is de.nitely \nproli.c. The test returns true if the declared type of the variable is proli.c, and returns falseotherwise \n(with\u00adout looking any further at the class hierarchy). Our decision to treat the children of a proli.c \ntype as proli.c seems to work well in practice. We have pro.led all SPECjvm98 applications and the SPECjbb2000 \nbenchmark and discovered that with three exceptions, proli.c types are indeed the leaves in a type hierarchy. \nThere are only two cases in which a subclass of a proli.c class would have been regarded as non-proli.c, \nbut the arti.cial re\u00adstriction we put in causes those subclasses to be treated as proli.c.  3. TYPE-BASED \nMEMORY MANAGEMENT In this section, we use the concept of proli.c and non-proli.c types to propose a proli.c \nhypothesis. We then discuss a type-based approach to memory management, based on the proli.c hypothesis. \n 3.1 The Proli.c Hypothesis We postulate a hypothesis that objects of proli.c types have short lifetimes \n we refer to it as the proli.c hypothesis. An intuitive ba\u00adsis for this hypothesis is that if this were \nnot true, an application that continuously allocates dynamic memory would have unsustainable memory requirements, \nas it would keep creating objects of proli.c types at a fast pace without reclaiming suf.cient space. \nStated an\u00adother way, our hypothesis predicts that the objects of proli.c types die younger than objects \nof non-proli.c types. It follows that most of the garbage collectible at various stages of the application \nwould consist of objects of proli.c types. We validated this hypothesis and found that the relative \nsurvival rates are usually lower for objects of proli.c types than for objects of non-proli.c types. \nWe also found that most of the dead objects and most of the garbage comes from short-lived objects of \nproli.c\u00adtypes. The empirical data can be found in [32]. Interestingly, the proli.c hypothesis has some \nresemblance to a phenomenon commonly found in nature. Offsprings of proli.c species are often short-lived \n[47]. 3.2 Type-Based Approach Our approach is to distinguish between proli.c and non-proli.c objects \nin the heap and direct the collection effort .rst towards pro\u00adli.c objects. 3.2.1 Type-based allocation \nThe type-based memory allocator partitions heap space into a proli.c region and a non-proli.c region: \nP-region and NP-region, respectively. The actual allocation mechanism is related to the kind of collector \nused by the system. When used with a copying collec\u00adtor, the allocator uses different regions of memory \nfor the P-region and NP-region. With a non-copying collector, the objects of proli.c and non-proli.c \ntypes are tagged differently, but not necessarily al\u00adlocated in separate memory regions. When an object \nof a certain type is to be allocated, the allocator checks the type pro.le of the application (with information \nabout whether or not the type is proli.c) to decide whether to place the object in the P-region or NP-region. \nHence, compared to a tradi\u00adtional memory allocator, the allocation path of the type-based allo\u00adcator \nwould have an extra step for checking the type of the object. However, since the proli.cacy of types \nis known at compile-time, the compiler can avoid the overhead of the run-time type check by simply inserting \na call to (or inlining) a specialized version of the allocation routine for proli.c or non-proli.c types.5 \n 3.2.2 Type-Based Collection Based on the proli.c hypothesis, the type-based garbage collec\u00adtor assumes \nthat most objects of proli.c types die young, and per\u00adforms (frequent) minor collections only in the \nP-region. Since objects of proli.c types account for most of heap space, we hope to collect enough garbage \non each P-region collection. When a P\u00adregion collection does not yield a suf.cient amount of free space, \na full collection of both P-region and NP-region is performed. If enough unreachable objects are uncovered \nduring a P-collection, full collections will be infrequent. Objects remain in their respec\u00adtive regions \nafter both P-region and full collections i.e., unlike generational collection, objects that survive \na P-region (minor) col\u00adlection stay there and are not promoted to the NP-region. This enables the compiler \nto eliminate unnecessary write barriers with a relatively simple type check, as described in Section \n3.2.3. Since the survival rates of objects in the P-region are usually low, we ex\u00adpect the pollution \nof the P-region due to longer lived objects to be insigni.cant. To ensure that during a P-region (minor) \ncollection no object reachable from an object in the NP-region is collected, we have to keep track of \nall pointers from objects in the NP-region to objects in the P-region. This is accomplished by executing \na write barrier code for pointer assignments, which records such inter-region ref\u00aderences and places \nthem in a write buffer. The contents of the write buffer represents roots used in a P-region collection. \n Our implementation does not perform this optimization. Benchmark compress 53 db 1 jack 99 javac 42 \njess 99 mpegaudio 63 mtrt 80 jbb 73 Table 1: The percentage of dynamic assignments into the refer\u00adence \n.elds of objects of proli.c types % of pe-+{ pP ,N p }  3.2.3 Eliminating Unnecessary Write Barriers \nwith Compile-Time Analysis In the type-based collection, we do not move objects from the P-region to \nthe NP-region or vice versa. Hence, unnecessary write barriers (other than those that keep track of references \nfrom the NP\u00adregion to the P-region) can be eliminated at compile time based on a simple type check. More \nspeci.cally, given an assignment state\u00adment where the pointer of an object of type sourceis assigned \na value corresponding to a pointer of an object of type target, we express the condition for eliminating \na write barrier as: m ffs t bB h D t B b e w r m ffd D r h wb e h D t B b P re w r m ffd t s w u b t \ne (1) Potential Opportunity. Table 1 shows the percentage of pointer assignments into the reference .elds \nof objects of proli.c types, D e w r m ffd D r h wb e i.e., those for which gis true at run time. These \ndata were obtained by running SPECjvm98 benchmarks (with size 100) and the SPECjbb2000 benchmark with \nthe Jalape no VM, using the optimizing compiler and a non-copying generational col\u00adlector. The high percentages \nfor all programs, except for db, show that there is clearly a potential to eliminate a substantial percentage \nof write barriers. Note that the numbers presented in Table 1 only give an estimate regarding how many \nof the write barriers can be fd D r h wb e eliminated (based on the gD e w r m fpart of the test). The \nactual numbers may be lower due to language features like polymorphism and dynamic class loading that \nintroduce conserva\u00adtiveness in the compiler analysis. Dealing with Polymorphism and Dynamic Class Loading \nWe use the approach described in Section 2.2 of ensuring that each subclass of a proli.c type is (arti.cially) \nregarded as proli.c. This leads to a simple compile-time test for eliminating write barriers, which can \nbe applied without worrying about any new classes that may be dynamically loaded in the future. The test \ndescribed in (1) above is simpli.ed to: m ffs t bB Dbm s w be w r m ffd D r h wb e gh D t B b P re w \nr m ffd t s w u b t e (2)  3.2.4 Processing Fewer Pointers In the type-based scheme, the number of pointers \nprocessed dur\u00ading a P-region collection can be reduced: not all pointers stored in objects that are scanned \nneed to be examined. During the P-region scanning process, for each object, the garbage collector requests \nthe list of reference .elds. This list is created when a class is loaded. Normally, the returned list \ncontains all such reference .elds. Consequently, all such references are .rst processed and then some \nof them (e.g., in a generational scheme, those that point to young objects) are scanned. However, in \nthe type-based scheme, there is no need to return a complete list of ref\u00aderence .elds to the collector \nduring a P-region collection. Only the Table 2: Many pointers scanned during garbage collection are \nreference .elds in object headers that point to type information block (TIB) objects (i.e., type descriptors). \nReferences Scanned Benchmark # of TIB refs. # of all refs. % of TIB refs. compress 8885294 28923650 \n30.719 db 1561864 2795719 55.866 jack 1446534 3796136 38.105 javac 4563270 14301008 31.908 jess 1940900 \n6551758 29.624 mpegaudio 409520 1421784 28.803 mtrt 2139610 3873905 55.231 jbb 2008508 5582408 35.979 \n references pointing to objects of proli.c types have to be returned (because object residing in the \nNP-region are only scanned during a full collection). To support this optimization, the class loader \nneeds to provide to the collector with two different sets of methods returning the lists of reference \n.elds: one (returning a partial list) for a P-region collection and one (returning a full list) for a \nfull collection. (Our current implementation does not perform this op\u00adtimization yet. Therefore, the \nperformance of our implementation can be improved further.) 3.2.5 Avoiding Processing References to \nType De\u00adscriptors We will now discuss a special case of the optimization technique presented in Section \n3.2.4. Usually, one of the .elds in an object header points to a special object describing its type (or \nclass) infor\u00admation: a type descriptor. For example, in the Jalape no VM, this .eld points to a type \ninformation block (TIB) and is called a TIB .eld. Table 2 provides data showing that a large fraction \nof scanned pointers (28%-55% depending on the benchmark) are TIB pointers. Scanning TIB pointers for \nevery reachable object is not necessary and can be avoided in the type-based scheme. It is suf.cient \nfor only one object of a type to survive a collection to ensure that the TIB of that object is scanned \nand marked as live. The scanning of TIB .elds in all other instances of that type is un\u00adnecessary, although \nthe garbage collector will realize after reaching the TIB object that it has already been marked. Since \nthe number of distinct types is small, the number of TIB objects representing them is also small. It \nfollows that such objects can be classi.ed as instances of a non-proli.c type and placed in the NP-region. \nAs a result, the TIB .elds (which now point to the NP\u00adregion) do not have to be examined during a P-region \ncollection.  3.3 Discussion The type-based approach, while similar to the generational ap\u00adproach in \nspirit, has some important differences. It involves pre-tenuring objects of non-proli.c types into the \nheap partition which is collected less often. These objects do not need to be scanned during P-region \n(minor) collections. However, we expect those savings to be limited because non\u00adproli.c types, by their \nvery nature, would not have occupied a lot of space in the nursery. Objects of proli.c types are never \npromoted to the heap par\u00adtition which is collected less often. This can be a double\u00adedged sword. If objects \nof proli.c types live for a long time, they can pollute the P-region, causing the scanning time to increase \nduring future minor collections.6 However, this ap\u00ad  Our experimental results show that the times for \nminor collections proach can also help avoid the negative side effects of pre\u00admature promotion of young \nobjects which are going to die soon anyway (namely, executing more write barriers; drag\u00adging more objects \nvia write buffers into the old generation; and requiring more major collections). The separation between \nthe heap partitions is based on static characteristics, i.e. the types of objects, rather than dynamic \ncharacteristics such as their ages. This allows unnecessary write barriers to be eliminated with a simple \n(and well-known in the context of dealing with virtual methods) compile-time analysis. This, apart from \nsaving the direct overhead of exe\u00adcuting write barriers, can also help avoid adding unnecessary objects \nto the write buffer, thus leading to fewer roots for mi\u00adnor collections, and potentially, more effective \ngarbage col\u00adlection. During a P-region collection, only objects of proli.c types have to be scanned. \nAs a result, reference .elds that can only point to objects of non-proli.c types do not even need to \nbe examined. Fewer pointers to be examined translates into shorter garbage collection pauses. This optimization \nis also a consequence of the type-based nature of the division. It is possible because in our scheme, \nthe assignment of an object to a separate region of collection depends only on the proli.\u00adcacy of its \ntype. This optimization cannot be performed in a generational scheme in which a reference .eld can point \nto either the nursery or the mature space; because the direction of a pointer cannot be known without \nactually examining it, all reference .elds have to be checked for pointers into the nursery. The performance \nimplications of these characteristics will be ex\u00adplored in Section 6.  4. USING SHORT TYPE POINTERS \nTO RE-DUCE HEAP SPACE REQUIREMENTS Each object in Java has an object header whose .elds contain (or refer \nto) various bookkeeping information used by the Java Virtual Machine (JVM) and its components such as \na garbage collector. A typical object header occupies two machine words. For example, in the Jalape no \nVM, one of the .elds in the object header, the sta\u00adtus .eld, is used to support garbage collection and \nsynchronization. The other .eld, the type .eld, is a class pointer and points to a spe\u00adcial object describing \nthe type of the object in question. Since most objects in Java programs are small (16-32 bytes),7 the \neight-byte object header carries 25%-50% space overhead. In this section, we use the notion of proli.c \ntypes to describe a short type pointer tech\u00adnique which in many cases allows us eliminate the pointer \nto a type descriptor completely and reduce the length of the object header for many objects drastically \n(e.g., in half, for two-word object headers). 4.1 Exploiting Proli.c Types Our technique takes advantage \nof three observations and reduces the space requirements of Java applications. (The quantitative data \nwill be presented in Section 6.2.) First, objects of the same type have the same pointer to a type descriptor. \nSecond, only a handful of object types (proli.c types) generate most of the objects that occupy most \nof the heap space. Third, objects of proli.c types are are, in fact, lower for our type-based collector \nthan for a genera\u00adtional collector. t We veri.ed this by pro.ling more than a dozen of Java programs \nfrom three different industry standard application suites. The data on object sizes is presented later \nin this paper. usually small. We will now show how to eliminate the pointer to a type descriptor completely \nin many cases (for objects of proli.c types) by utilizing only a few bits in the status .eld, which are \nusually available. Hence, the name a short type pointer (STP). A few bits, type bits, in the status \n.eld may be used to encode the types of proli.c objects. A special value, say all zeros, is used to denote \na non-proli.c type. Given a maximum of kproli.c types, we need l( knprpbits for this encoding (e.g., \n4bits for ki tp15). The JVM creates a type table with an entry for the class object for each proli.c \ntype. Proli.c objects no longer need a separate type pointer in the object header. In order to get the \ntype descriptor of an object (for a virtual method call or for an operation requiring a dynamic type \ncheck), its type bits are examined. If they do not contain the special value denoting a non-proli.c type, \nthe type bits are used to determine an index into the type table, which yields the needed type descrip\u00adtor. \nOtherwise, the type descriptor is obtained via the type pointer which is stored as usual in the object \nheader for non-proli.c ob\u00adjects. 4.2 Discussion The discussed technique has a number of important advantages. \nFirst, because no space is wasted for the pointer to the type descrip\u00adtor in the object header of commonly \noccurring (proli.c) objects, memory requirements of applications will be reduced noticeably. Smaller \nmemory footprint can lead to higher performance due to better cache and page locality, and for long-running \napplications, less frequent garbage collections. Although some extra instructions have to be executed \nto deter\u00admine the type of an object, this overhead should be extremely small on modern superscalar processors. \nOne of the extra instructions in\u00adtroduced is a memory (load) instruction. However, since it loads a reference \nfrom a very small type table which should .t in a few cache lines, most of those memory loads will hit \nin the .rst level cache. Furthermore, the frequency with which programs access the pointer to a type \ndescriptor (for virtual method calls and dy\u00adnamic type checks) is usually quite small in optimized Java \ncodes [35]. The short type pointer approach has several advantages over the big bag of pages (BiBoP) \ntechnique [48] according to which ob\u00adjects of the same type are placed into the same page. While the \nBiBoP technique avoids the need to store the type information in any object, it has several disadvantages. \nFirst, since only objects of a particular type can reside in one page, objects of different types which \npoint to each other cannot be allocated close to each other. Hence, the BiBoP approach may reduce the \ndata locality of appli\u00adcations. Second, the BiBoP approach leads to the problem of mem\u00adory fragmentation, \nas memory pages allocated for objects of many (non-proli.c) types remain un.lled. Hence, this approach \nincreases the TLB miss rates in applications that employ many different types of objects. Interestingly, \nthe notion of proli.c and non-proli.c types can be used to alleviate the memory fragmentation problem \nof the BiBoP technique by applying the BiBoP approach selectively and only to objects of proli.c types. \nConsequently, all non-proli.c objects would be co-allocated together. This would also reduce the TLB \nmiss rates in applications with many different object types.  5. OTHER APPLICATIONS In this section, \nwe discuss additional applications of the notion of proli.c and non-proli.c types. 5.1 Object Recycling \nRecycling dead objects is a technique that has often been used explicitly by programmers. Recently, Brown \nand Hendren [11] Table 3: The reduction of write barrier overhead. Static count Dynamic count % of WB \neliminated # of write barriers executed # of ref. added to the write buffer Benchmark optimized original \noptimized % elim. original optimized % elim. compress 0.000 3514 3514 0 149 149 0 db 3.048 81440517 81407032 \n0 63 54 14.2 jack 0.840 29326975 20849265 28.9 3912 3775 3.5 javac 31.967 41026080 33728942 17.8 714812 \n603352 15.5 jess 15.838 30777556 8106063 73.7 1765 1602 10.2 mpegaudio 0.000 17436480 17436480 0 310 \n310 0 mtrt 17.187 9832002 3513591 64.3 1073 167 84.4 jbb 0.622 26740265 19967459 25.3 46707 8803 71.1 \n Table 4: Comparison of the best throughput results (collected in the GC timing run). Execution times \nare given in secs. for SPECjvm98 programs (smaller is better) and throughput is given in ops/sec. for \nSPECjbb2000 (larger is better). Non-Copying GC Generational Non-Generational Type-Based Benchmark Raw \nRaw Normalized w.r.t Generational GC (%) Raw Normalized w.r.t. Generational GC (%) compress db jack javac \njess mpegaudio mtrt jbb 58.598 88.546 51.619 53.369 31.728 27.121 22.485 1137.590 55.272 87.979 52.478 \n47.349 34.813 26.974 23.239 1119.240 106.017 100.644 98.363 112.714 91.138 100.544 96.755 98.386 56.994 \n88.249 50.732 52.171 31.122 26.785 22.975 1171.350 102.814 100.336 101.748 102.296 101.947 101.254 97.867 \n102.967 have discussed automating this technique using sophisticated whole\u00adprogram interprocedural .ow \nanalysis. We propose a simpler ap\u00adproach that may capture many of the bene.ts. As discussed earlier, \nobjects of proli.c types tend to have short lifetimes and account for most of the collectible garbage \nduring program execution. Since most of the objects allocated in a pro\u00adgram are of proli.c types, it \nis worthwhile to recycle dead proli.c objects by placing them into a special free pool instead of returning \nthem to a general free pool. A special free pool is simply a linked list of free, not necessarily contiguous, \nobjects of a particular type. Picking an object from such a pool requires a much shorter instruc\u00adtion \nsequence than allocating an object of arbitrary size. Hence, re\u00adcycling of proli.c objects can lead to \nmore ef.cient allocation, es\u00adpecially with support for specialization of the allocation site based on \nthe object type.  5.2 Object Co-allocation Object co-allocation is known to have a positive impact on \nthe performance of programs with heap allocated data [13, 14]. The problem is that it is usually very \ndif.cult to decide which objects should be co-allocated together. In this section, we will discuss a \nsimple technique in which the knowledge of which types are pro\u00adli.c and which are non-proli.c is used \nto drive object co-allocation decisions. Considering our classi.cation of objects into instances of proli.c \nand non-proli.c types, we argue that objects of proli.c types should be allocated together with other \nobjects of proli.c types. First, in looking for instances of objects which are likely to be accessed \ntogether (such as objects connected via reference .elds), there is a greater chance of a one-to-one relationship \nbetween objects of proli.c types than between proli.c and non-proli.c objects (since there are many more \nproli.c objects than non-proli.c objects). Sec\u00adond, given the larger number of objects of proli.c types, \ngreater performance bene.t may be achieved by focusing the effort on co\u00adallocating proli.c objects. We \nare investigating the effectiveness of this approach further [34].  6. EVALUATION In this section, \nwe provide an evaluation of our type-based mem\u00adory management approach, based on an implementation inthe \nJalape no VM [2]. We also provide a preliminary evaluation of the poten\u00adtial memory reduction from the \nSTP technique, ahead of an ac\u00adtual implementation. We studied applications from the industry standard \nSPECjvm98 benchmark suite [37] and the SPECjbb2000 benchmark [38]. The SPECjbb2000 benchmark, which we \nrefer to as jbb, is based on the pBOB (portable business object bench\u00admark) [8], which follows the business \nmodel of the TPC-C bench\u00admark [43] and measures the scalability and throughput of the JVM. We used the \nlargest data set size (set to 100) to run SPECjvm98 applications. 6.1 Type-Based Memory Management We \nnow describe our implementation in the Jalape no VM and the experimental results. 6.1.1 Implementation \nThe Jalape no VM supports a number of different garbage collec\u00adtors in different con.gurations of the \nVM. We implemented our type-based scheme by making several modi.cations to the non\u00adcopying generational \ngarbage collector, which we found the sim\u00adplest to start with. Execution Modes. We modi.ed the Jalape \nno VM to introduce two modes of execution. In the pro.ling mode, the allocation pro.le is collected. \nIn the production mode, the allocation pro.le collected in the pro.ling run is used by the memory allocator \nand garbage collector to implement type-based heap management, and by the compiler to optimize away unnecessary \nwrite barrier code. Table 5: Garbage collection statistics. Execution times are given in seconds. Non-copying \nGC Type-Based # of GCs GC Time P-region col. pause time Full col. pause time Benchmark P-region Full \nTotal P-region Full Total Min Max Min Max compress db jack javac jess mpegaudio mtrt jbb 2 14 64 28 56 \n1 30 10 94 3 9 31 11 2 5 5 96 17 73 59 67 3 35 15 0.184 5.041 8.682 20.845 7.006 0.177 8.419 3.497 50.935 \n2.682 5.724 46.723 7.667 1.222 4.378 4.911 51.120 7.724 14.406 67.569 14.674 1.400 12.798 8.409 0.068 \n0.150 0.101 0.232 0.111 0.179 0.126 0.266 0.121 0.172 0.455 0.815 0.208 0.179 0.674 0.572 0.531 0.590 \n0.592 0.595 0.639 0.592 0.877 0.658 0.631 1.061 0.674 1.935 0.769 0.634 1.170 1.344 Non-copying GC Generational \n# of GCs GC Time Minor col. pause time Major col. pause time Benchmark Minor Major Total Minor Major \nTotal Min Max Min Max compress db jack javac jess mpegaudio mtrt jbb 2 14 64 53 57 1 27 10 94 3 9 38 \n11 2 5 5 96 17 73 91 68 3 32 15 0.193 5.314 9.180 17.468 7.417 0.183 8.728 3.751 55.786 2.967 6.228 62.253 \n8.280 1.313 4.223 5.373 55.979 8.282 15.408 79.721 15.697 1.497 12.952 9.125 0.102 0.180 0.130 0.250 \n0.137 0.209 0.169 0.304 0.142 0.186 0.490 0.913 0.234 0.209 0.766 0.641 0.604 0.661 0.661 0.672 0.717 \n0.660 0.660 0.726 0.756 1.202 0.743 2.119 0.843 0.703 1.043 1.600 Non-copying GC # of GCs GC Time Minor \ncol. pause time Major col. pause time Benchmark Minor Major Total Minor Major Total Min Max Min Max compress \ndb jack javac jess mpegaudio mtrt jbb . . . . . . . . 96 14 62 58 64 3 26 11 96 14 62 58 64 3 26 11 . \n. . . . . . . 45.563 10.710 31.271 46.948 36.630 1.398 19.018 9.137 45.563 10.710 31.271 46.948 36.630 \n1.398 19.018 9.137 . . . . . . . . . . . . . . . . 0.436 0.448 0.436 0.436 0.439 0.435 0.435 0.447 0.505 \n0.826 0.619 1.080 0.689 0.488 0.874 0.963 Allocator and Collector. In the pro.ling mode, the memory \nallo\u00adcator monitors all allocation requests, collects a type pro.le, and produces a .le with the pro.le \ninformation, including class hier\u00adarchy information. In the production mode, the memory allocator uses \nthe previously collected type pro.le to make allocation de\u00adcisions. Also, in the production mode, the \ngarbage collector re\u00adpeatedly collects space occupied by dead objects of proli.c types (P-region collections). \nWhen only a small portion of memory is freed, it collects the entire heap (full collections). Write Barriers. \nWe have made modi.cations to the write barrier code to ensure that the write barriers work appropriately \nfor our type-based approach. We also modi.ed the Jalape no optimizing compiler to eliminate unnecessary \nwrite barriers during the pro\u00adduction run of a program. The compiler analysis to identify un\u00adnecessary \nwrite barriers is based on the simpli.ed test shown in Equation (2).  6.1.2 Experimental Results Our \nexperiments were performed on an RS/6000 system with a 333 MHz PowerPC 604e processor and 768 MB of memory. \nFor all SPECjvm98 benchmarks, we used a 64 MB heap, except for javac(80 MB). The jbbprogram ran with \na 128 MB heap. Reducing the Overhead of Write Barriers Table 3 demonstrates the effect of our write barrier \nelimination technique on reducing the overhead associated with execution of write barriers. Each SPECjvm98 \nprogram ran through three iterations. The jbbbench\u00admark ran for two minutes after the initial ramp up \nstage. For some benchmarks, the fraction of sites at which write bar\u00adriers have been eliminated is fairly \nsmall (column 2). For others, it is quite signi.cant and ranges from 15% to 32%. The number of write \nbarriers eliminated at compile time does not translate lin\u00adearly to the number of write barriers eliminated \nat run time (column 5). It can be seen that the programs that are amenable to our op\u00adtimization execute \n18%-74% fewer write barriers, which improves the throughput of these programs. Interestingly, a comparison \nwith data presented in Table 1 suggests that there is a considerable po\u00adtential for eliminating more \nwrite barriers by using more precise compiler analysis. In those programs, 3%-84% fewer entries are added \nto the write buffer for processing (column 8), which reduces the GC pauses and reduces the pollution \nof the heap. Benchmarks like compress and mpegaudiodo not allocate a lot of objects which could be classi.ed \nas instances of proli.c types. Conse\u00adquently, on these benchmarks, we are not able to eliminate write \nbarriers. In db, most of the pointer assignments were to a few large arrays of references (which were \nclassi.ed as non-proli.c) used for sorting data. As a result, the reduction of write barrier overhead \nfor that benchmark is insigni.cant. Performance and Throughput of Applications Table 4 shows the execution \ntimes of SPECjvm98 applications and the through\u00adput of SPECjbb200 benchmark under the Jalape no VM built \nwith different garbage collectors (GC): our non-copying type\u00adbased GC, the non-copying generational GC, \nand the non-copying (non-generational mark-and-sweep) GC. Interestingly, our scheme yields the highest \nthroughput numbers on three benchmarks, most Figure 1: Normalized GC times of the type-based GC (with \nrespect to the generational GC). Cumulative P-region (minor) collections time Normalized GC times of \nthe type-based GC (%) Cumulative full (major) collections time Total GC time 100 80 60 notably jackand \njbb. Compared to the generational GC, our scheme performs up to 3% better on all benchmarks, except for \nmtrtwhere the through\u00adput is 2% worse. (We believe this anomaly is due to data locality effects and are \ninvestigating this further.) This is an encouraging result, suggesting that our scheme can improve the \nthroughput of applications in systems where the generational GC is used. Compared to the non-generational \nnon-copying GC, our scheme performs noticeably better (by almost 12%) on jess, and some\u00adwhat better on \njack, mtrt and jbb on which it shows a 1.5%\u00ad4.7% improvement. The non-generational GC performs better \nthan our scheme on compress, db, and mpegaudio, probably be\u00adcause these programs do not generate a lot \nof objects. This program behavior limits the opportunities where our optimizations can ap\u00adply. Garbage \nCollection Statistics. Table 5 shows the bene.ts of our technique for garbage collection. The data was \ncollected during performance runs for which the data was presented above. Compared to the non-copying \ngenerational collector, our scheme has fewer garbage collections during the execution of javac and jess. \nInterestingly, on javac, the number of both P-region and full collections (compared to minor and major \ncollections in the generational scheme) is reduced. On mtrt, the number of P\u00adregion collections went \nup slightly. On all other benchmarks, the number of collections is the same. Overall, except for the \natypi\u00adcal Java benchmarks like compressand mpegaudio, both the type-based and the generational collectors \nhave a higher number of collections than the non-generational GC (which is expected). However, the number \nof expensive full collections is signi.cantly smaller in the type-based scheme (and in the generational \nscheme) compared to the non-generational GC. This is done at the ex\u00adpense of performing more frequent, \nless-costly P-region (minor) collections. Compared to the generational scheme, the type-based GC spends \nless time collecting the P-region. The javacprogram is an excep\u00adtion. For this benchmark, the average \ntime spent on collecting the jbb mtrtmpegaudiojessjavacjackdbcompress P-region is approximately twice \nas much as the time spent on col\u00adlecting the nursery in the generational scheme. At the same time, the \naverage time spent on collecting the whole heap is noticeably less (25%). Although the type based-scheme \nexecutes more inex\u00adpensive collections than the generational scheme during the execu\u00adtion of the mtrtbenchmark, \nits average time for collecting young objects is smaller. With exception of mtrt, the total time spent \non collecting the whole heap is smaller in the type-based scheme than in the generational GC. Finally, \nfor all benchmarks, the to\u00adtal time spent on garbage collection is smaller in the type-based scheme compared \nto the generational GC. The improvements range from 1.2% to 15.2%, with an average improvement of 7.4%. \nShort average GC times is an attractive characteristic of the type-based scheme. Both the minimum and \nmaximum GC pauses during collection of young and all objects are shorter in the type-based scheme than \nthose exhibited by the generational GC. This observation is im\u00adportant since short GC pauses is a critical \nrequirement for some systems. The mtrt program is an exception where the maximum pause time for a full \ncollection is slightly longer.  6.2 Short Type Pointers In order to evaluate the potential bene.ts of \nthe short type pointer (STP) technique before implementing this scheme, we instrumented the Jalape no \nVM. We present the data we obtained, which serves as a preliminary evaluation. In addition to the SPECjvm98 \nand SPECjbb2000 benchmarks, we selected applications from the Java Grande suite for this study. Table \n6 presents various information about all objects as well as the number of types of proli.c scalar and \narray objects. It can be seen that the number of proli.c types is very small. Usually, there are less \nthan 16 of them. This implies that we will need only 4 bits to encode interesting proli.c types. Figures \n2 and 3 illustrate that most of the objects are instances of proli.c types and that instances of proli.c \ntypes consume much of heap space, respectively. Figure 4 depicts the average sizes of all objects as \nwell as the sizes of proli.c scalar and array objects. Object sizes include the sizes of object headers: \n8 bytes for scalar and 12 bytes for array objects. It appears that proli.c array objects are often twice \nbigger than proli.c scalar objects. Interestingly, the average size of proli.c scalar objects (PSO) in \nnon-scienti.c applications ranges from 16 to 27 bytes while in scienti.c applications the sizes of PSO \nrange from 30 to 39 bytes. This difference in sizes is partially due to a frequent use of double types \nin scienti.c programs and a large num\u00adber of instance .elds in some proli.c objects. For objects that \nare 16-32 bytes long, one four-byte type pointer carries a considerable 12.5%-25% space overhead. Table \n7 shows how much space can be saved by shortening object headers in proli.c objects. Eliminating the \ntype pointer from the headers of proli.c scalar objects (PSO) leads to 10%-25% reduc\u00adtion of space occupied \nby PSO. The same technique applied to the headers of proli.c array objects (PAO), results in somewhat \nsmaller (8%-16%) reduction of space occupied by PAO. Larger sizes of PAO contribute to this difference. \nAs can be seen from the data in Table 7, most of the savings come from shortening the headers of PSO. \nThis is due to the fact that PSO consume much of the heap space but tend to be smaller than PAO. For \nsome programs (e.g., jack, jbb, search), short\u00adening headers of proli.c arrays is also bene.cial. Programs \nlike compress and montecarlo which allocate huge arrays will not bene.t from smaller object headers. \nOverall, 9%-16% of heap space can be saved by eliminating the type pointer from the headers of proli.c \nobjects (both arrays and scalars). Figure 5 illustrates the data presented in Table 7. Table 6: Basic \ncharacteristics of SPECjvm98, SPECjbb2000, and Java Grande benchmarks.  Figure 3: Most of the heap \nspace is consumed by instances of proli.c types. Space Occupied by Instances of Prolific Array Objects \nSpace Occupied by Instances of Prolific Scalar Objects % of all space 100 50 searchraytracermontecarloeulerjbbmtrtmpegaudiojessjavacjackdbcompress \n0 % of all instances searchraytracermontecarloeulerjbbmtrtmpegaudiojessjavacjackdbcompress Figure 4: \nAverage sizes of proli.c and all objects. Figure 5: Reduction of heap space requirements. 20  Reduction \nin Space Occupied by Instances of Average Size of Instances of Prolific Array Objects Prolific Arrays \nAverage Size of Instances of Prolific Scalar Objects Reduction in Space Occupied by Instances of Average \nSize of All Objects Prolific Scalar Objects average object size (bytes) 100 535 1842 624 50 0  searchraytracermontecarloeulerjbbmtrtmpegaudiojessjavacjackdbcompress \n  7. RELATED WORK The notion of hot regions in a program, wherein a program spends much of its execution \ntime in small sections of code, is well-known. However, we are not aware of any previous work that applies \nthe analogous idea in the context of different object types. Garbage collection Jones and Lins [28] present \na comprehen\u00adsive overview of various memory allocation and garbage collection strategies. Surveys by \nWilson [48], and Wilson, Johnstone, and others [49], discuss uniprocessor garbage collection and dynamic \nmemory allocation algorithms, respectively. Exploitation of object lifetimes for garbage collection has \nbeen investigated extensively. The key observation that the lifetime of many objects is short was reported \nas early as 1976 [18]. This in\u00adsight then led to the formulation and exploitation of the weak gen\u00aderational \nhypothesis [45] which states that most objects die young. This hypothesis forms the basis of generational \ngarbage collec\u00adtion [29, 6]: focus on reclaiming objects that are most likely to die, i.e., young objects. \nStefanovic et al. have investigated alternatives to the traditional young-.rst generational collectors \n[39]. They propose age-based garbage collection [40] algorithms, some of which use an older-.rst collector \nthat collects older objects before the younger ones. This approach primarily reduces copying costs over \nthe traditional gen\u00aderation collectors. Both the age-based and traditional generational collectors follow \nthe same philosophy: both use age as a criterion for identifying objects for collection (young objects \nin generational and old objects in age-based collectors). On the contrary, our type\u00adbased garbage collector \nuses the proli.cacy of object types as the criterion for identifying prospective moribund objects. Experimental \nstudies by Zorn [50], and Tarditi and Diwan [42] have shown that the cost of generational garbage collection \nis be\u00adtween 5% to 20%. Generational collectors usually segregate heap objects by their age. However, \nsubstantial performance improve\u00adment can be achieved by allocating large objects in a separate non\u00adcopy \nregion, usually termed as large object space(LOS) [12]. Iden\u00adti.cation of large objects can be an absolute \nmeasure (e.g., more than 1024 bytes [46] or 256 bytes [27]) or a relative one (i.e., iden\u00adtify the object \ntype whose instances occupy substantial space [25]). Many recent generation collection implementations \nuse the LOS for storing large objects [23, 2]. The cost of write barriers is also signi.cant, especially \nfor pointer\u00adintensive applications [42]. While there have been several efforts for improving the write \nbarrier performance [24, 25], we did not come across any work that eliminates write barriers via static \ncompile\u00adtime analysis. Previous studies have investigated off-line feedback-driven ap\u00adproaches for segregating \nobjects using criteria such as object life\u00adtime and reference behavior. Barrett and Zorn [7] use full-run \npro\u00ad.les on allocation-intensive C programs to predict short-lived ob\u00adjects, place them contiguously \nand delay their deallocation until large 4KB batches become free. Seidl and Zorn [31] propose par\u00adtitioning \nheap for storing objects according to their reference be\u00adhavior (the frequently vs. infrequently referenced \nobjects) and life\u00adtimes (short-lived vs. long-lived) objects. Blackburn et al. describe pro.le-driven \ntechnique for reducing copying by pre-tenuring long\u00adlived objects, i.e., storing long-lived objects in \nan uncollected re\u00adgion [9]. Recently, Harris [22] has presented a dynamic technique in which selection \nof objects for pre-tenuring is performed at run\u00adtime. Stefanovic et al. [41] describe analytical models \nfor object life\u00adtimes in object-oriented programs. Appel [3] has proposed that a plausible object lifetime \ndistribution should use the following prop\u00aderty: the expected future lifetime of an object is proportional \nto its current age. Reducing space requirements We have compared the STP ap\u00adproach with the big bag of \npages (BiBoP) technique in Section 4.2. The STP approach is different from the techniques aimed at pro\u00adducing \ncompact code for embedded processors [30, 15], in that it reduces memory consumed by data rather than \ncode. It is also different from the hardware-based techniques for compressing the contents of main memory \n[44]. A technique for delayed allocation of infrequently accessed or cold objects, a construction on \ndemand, which aims to reduce space occupied by cold objects was suggested in [35]. Object recycling Bonwick \n[10] describes a slab allocator, a ker\u00adnel memory allocator that reduces the cost of allocating complex \nobjects by retaining the state of those objects between their uses. On the other hand, we consider object \nrecycling of proli.c objects in the context of a Java Virtual Machine. Recently, Brown and Hendren [11] \nproposed an object recy\u00adcling mechanism and implemented it as an automatic compiler op\u00adtimization in \nthe Soot Java optimization framework. Their compiler performs a conservative local program analysis to \nidentify dead Java objects (and return them to per-class object pools) and trans\u00adforms a program to recycle \ndead objects (from the object pools) instead of creating new ones. Object co-allocation Object co-allocation \nat allocation time, based on hints supplied by the programmer, was reported by Chilimbi et al in [13]. \nObject co-allocation at garbage collection time was de\u00adscribed in [14]. Object inlining was proposed \nby Dolby et al. in [19, 20].  8. CONCLUSIONS We introduced a new framework of proli.c and non-proli.c \ntypes based on the number of instances of those types. This type-based rather than age-based framework \nserves as the foundation for sev\u00aderal techniques that aim to improve memory management and data locality \nof programs with dynamic memory allocation. We have presented a new type-based approach to garbage collec\u00adtion. \nOur approach directs the frequent collections towards objects of proli.c types, much like generational \ncollection directs them to\u00adwards young objects. This leads to some important advantages over generational \ncollection fewer write barriers, potentially more ef\u00adfective collections, need to scan fewer pointers, \nand lower copying costs (the last one not veri.ed yet, because our current implemen\u00adtation only performs \nnon-copying collection). Withapreliminary implementation of thisapproach inthe Jalape no VM, we have \nobserved signi.cant improvements over the gener\u00adational collector. For the SPECjvm98 and SPECjbb2000 \nbench\u00admarks, the number of dynamically executed write barriers is re\u00adduced by 18% to 74% (except for \nthree programs, for which there is no reduction). The total garbage collection times are reduced by an \naverage of 7.4% over all benchmark programs. The overall performance improves modestly for most programs. \nBased on the same framework, we have presented a technique for reducing the memory requirements of object-oriented \napplications. The technique is based on the observations that objects of the same type have the same \ntype information pointer and that the number of proli.c types is very small. The basic idea is to eliminate \ntype pointers from the headers of proli.c objects (which tend to be small and occupy much of the heap \nspace) and to encode the types of pro\u00adli.c objects using only a few bits instead. The empirical data \nwe collected shows that when applied to twelve Java programs (from SPECjvm98, SPECjbb200, and the Java \nGrande suites of applica\u00adtions) representing a variety of workloads, this technique can save 9%-16% of \nheap space. Finally, we presented the use of proli.c types for recycling and co-allocation of objects. \nThe former approach is based on the ob\u00adservation that most of the dead objects are those of proli.c types \nand attempts to recycle them instead of returning them to the main free pool. The latter approach is \nbased on the idea that an object of a proli.c type is likely to be referenced through another object \nof proli.c type.  9. FUTURE WORK This work opens up a number of interesting possibilities for fu\u00adture \nresearch. We plan to implement and measure the impact of the short type pointer technique on program \nperformance and on the frequency of garbage collections. We also plan to investigate the impact of object \nrecycling and object co-allocation techniques discussed in this paper on locality and performance [34]. \nAnother interesting direction would be to investigate a more dy\u00adnamic version of our automatic memory \nmanagement approach, where the detection of proli.c types is done during program ex\u00adecution in an adaptive \nmanner. Changing the status of a type from proli.c to non-proli.c, or vice versa, would require selective \nre\u00adcompilation of sections of code where write barriers may have been eliminated based on the older classi.cation \nof types (we do not an\u00adticipate a need to undo the effect of a previously eliminated write barrier, as \nlong as the existing objects are not moved across their respective regions). It would also be interesting \nto develop a copying version of our type-based collector. This would also involve allocating objects \nof proli.c and non-proli.c types in distinct regions of memory, which will have a further impact on the \ndata locality characteristics. Designing and implementing a hybrid scheme, which combines the characteristics \nof both type-based and age-based approaches, is another interesting direction for future research. We \nare investigat\u00ading the effectiveness of this approach further [33]. Acknowledgments We would like to \nthank the members of the Jalape no team for pro\u00adviding us with an infrastructure for this work. We would \nalso like to thank Pratap Pattnaik for valuable technical discussions. 10. REFERENCES [1] O. Agesen and \nA. Garthwaite. Ef.cient object sampling via weak references. In Proc. of ISMM 2000, pages 127 136, 2000. \n [2] B. Alpern, C. R. Attanasio, J. J. Burton, M. G. Burke, P. Cheng, J.-D. Choi, A. Cocchi, S. J. Fink, \nD. Grove, M. Hind, S. F. Hummel, D. Lieber, V. Litvinov, M. F. Mergen, T. Ngo, J. R. Russell, V. Sarkar, \nM. J. Serrano, J. C. Shephard, S. E. Smith, V. C. Sreedhar, H. Srinivasan, and J. Whaley. The Jalapeno \nVirtual Machine. IBM Systems Journal, 39(1):194 211, 2000. [3] A. Appel. A better analytical model for \nthe strong generational hypothesis, November 1997. [4] M. Arnold, S. Fink, D. Grove, M. Hind, and P. \nSweeney. Adaptive optimization in the Jalape no JVM. In Proc. of OOPSLA 2000. [5] D. Bacon and P. Sweeney. \nFast static analysis of C++ virtual function calls. In Proc. of OOPSLA 1996, pages 324 341, 1996. [6] \nH. G. Baker. Infant mortality and generational garbage collection. SIGPLAN Notices, 28(4):55 57, 1993. \n [7] D. A. Barrett and B. G. Zorn. Using lifetime predictors to improve memory allocation performance. \nACM SIGPLAN Notices, 28(6):187 196, June 1993. [8] S. J. Baylor, M. Devarakonda, S. Fink, E. Gluzberg, \nM. Kalantar, P. Muttineni, E. Barsness, R. Arora, R. Dimpsey, and S. J. Munroe. Java server benchmarks. \nIBM Systems Journal, 39(1):57 81, 2000. [9] S. Blackburn, J. Cavazos, S. Singhai, A. Khan, K. McKinley, \nand J. E. B. Moss. Pro.le-driven pretenuring for Java. Poster in OOPSLA 2000, October 2000. [10] J. \nBonwick. The slab allocator: An object-caching kernel memory allocator. In USENIX Summer 1994 Technical \nConference, pages 87 98, 1994. [11] R. Brown and L. Hendren. Automatic recycling of Java objects. Technical \nReport, McGill University, 2000. [12] P. J. Caudill and A. Wirfs-Brock. A third-generation Smalltalk-80 \nimplementation. In Proc. of OOPSLA 1986, pages 119 130. [13] T. M. Chilimbi, M. D. Hill, and J. R. Larus. \nCache-conscious structure layout. In Proc. of PLDI, pages 1 12, 1999. [14] T. M. Chilimbi and J. R. \nLarus. Using generational garbage collection to implement cache-conscious data placement. In Proc. of \nthe 1998 ISMM, Oct. 1998. [15] K. Cooper and N. McIntosh. Enhanced code compression for embedded RISC \nprocessors. In Proc. of PLDI 1999, pages 139 149, Atlanta, GA USA, May 1999. [16] J. Dean, D. Grove, \nand C. Chambers. Optimization of object-oriented programs using static class hierarchy. In Proc. of 9th \nEuropean Conference on Object-Oriented Programming, pages 77 101, 1995. [17] D. Detlefs and O. Agesen. \nInlining of virtual methods. In Proc. of 13th ECOOP, pages 258 278, 1999. [18] L. P. Deutch and D. Bobrow. \nAn ef.cient incremental automatic garbage collector. CACM, 19(7), July 1976. [19] J. Dolby. Automatic \ninline allocation of objects. In Proc. of PLDI, 1997. [20] J. Dolby and A. Chien. An automatic object \ninlining optimization and its evaluation. In Proc. of PLDI 2000, pages 345 357, 2000. [21] J. Gosling, \nB. Joy, and G. Steele. The Java(TM) Language Speci.cation. Addison-Wesley, 1996. [22] T. Harris. Dynamic \nadaptive pre-tenuring. In Proc. of ISMM 00, pages 127 137, 2000. [23] M. Hicks, L. Hornof, J. T. Moore, \nand S. M. Nettles. A study of large object spaces. In Proc. of ISMM 1998, pages 138 146. [24] U. Hoelzle. \nA fast write barrier for generational garbage collectors. In Proc. of OOPSLA 93 Workshop on Garbage Collection, \n1993. [25] A. L. Hosking, J. E. B. Moss, and D. Stefanovi\u00b4c. A comparative performance evaluation of \nwrite barrier implementations. In Proc. of OOPSLA 1992, pages 92 109, 1992. [26] The Java Hotspot performance \nengine architecture. http://java.sun.com/products/hotspot/ whitepaper.html. [27] R. Hudson, J. E. B. \nMoss, A. Diwan, and C. Weight. A language-independent garbage collector toolkit. Technical Report TR91-47, \nUniversity of Massachusetts at Amherst, September 1991. [28] R. Jones and R. Lins. Garbage Collection: \nAlgorithms for Automatic Dynamic Memory Management. John Wiley and Sons, 1996. [29] H. Lieberman and \nC. Hewitt. A real-time garbage collector based on the lifetimes of objects. CACM, 26(6):419 429, June \n1983. [30] A. Rao and S. Pande. Storage assignment optimizations to generate compact and ef.cient code \non embedded DSP. In Proc. of PLDI 1999, pages 128 138, Atlanta, GA USA, May 1999. [31] M. L. Seidl and \nB. G. Zorn. Segregating heap objects by reference behavior and lifetime. In Proc. of ASPLOS, pages 12 \n23, 1998. [32] Y. Shuf, M. Gupta, R. Bordawekar, and J. P. Singh. Distinguishing between proli.c and \nnon-proli.c types for ef.cient memory management. Technical report, IBM T.J. Watson Research Center, \nYorktown Heights, NY, 2001. [33] Y. Shuf, M. Gupta, R. Bordawekar, and J. P. Singh. A hybrid memory management \nscheme using proli.c types and object ages. Technical report, IBM T.J. Watson Research Center, Yorktown \nHeights, NY, 2001. [34] Y. Shuf, M. Gupta, H. Franke, and J. P. Singh. Creating and preserving locality \nof Java applications at allocation and garbage collection times. Technical report, IBM T.J. Watson Research \nCenter, Yorktown Heights, NY, 2001. [35] Y. Shuf, M. J. Serrano, M. Gupta, and J. P. Singh. Characterizing \nthe memory behavior of Java workloads: A structured view and opportunities for optimizations. In Proc. \nof SIGMETRICS 2001. [36] V. Sreedhar, M. Burke, and J.-D. Choi. A framework for interprocedural optimization \nin the presence of dynamic class loading. In Proc. of PLDI 2000, 2000. [37] Standard Performance Evaluation \nCouncil. SPEC JVM98 Benchmarks, 1998. http://www.spec.org/osg/jvm98/. [38] Standard Performance Evaluation \nCouncil. SPEC JBB2000 Benchmark, 2000. http://www.spec.org/osg/jbb2000/. [39] D. Stefanovi\u00b4c. Properties \nof Age-based Automatic Memory Reclamation Algorithms. PhD thesis, University of Massachusetts, Amherst, \nMA, February 1999. [40] D. Stefanovi\u00b4c, K. McKinley, and J. E. B. Moss. Age-based garbage collection. \nIn Proc. of OOPSLA 1999, pages 370 381, October 1999. [41] D. Stefanovic, K. S. McKinley, and J. E. B. \nMoss. On models for object lifetime distributions. In Proc. of ISMM 2000. [42] D. Tarditi and A. Diwan. \nThe full cost of a generational copying garbage collection implementation. In Proc. of the OOPSLA93 Workshop \non Memory Management and Garbage Collection, October 1993. [43] Transaction Processing Performance Council. \nTPC-C Benchmark, 2000. http://www.tpc.org/cspec.html . [44] R. Tremaine, P. Franaszek, J. Robinson, C. \nSchulz, T. Smith, M. Wazlowski, and P. Bland. IBM Memory Expansion Technology (MXT). IBM Journal of Research \nDevelopment, 45(2), 2001. [45] D. M. Ungar. Generational scavenging: A non-disruptive high performance \nstorage reclamation algorithm. ACM SIGPLAN Notices, 19(5):157 167, April 1984. [46] D. M. Ungar and F. \nJackson. Tenuring policies for generation based storage reclamation. ACM Transactions on Programming \nLanguages and Systems, 14(1):1 27, 1992. [47] A. R. Wallace. On the tendency of varieties to depart inde.nitely \nfrom the original type. In Letters to the Royal Society, Feb. 1858. [48] P. Wilson. Uniprocessor garbage \ncollection techniques. Technical report, University of Texas at Austin, 1994. [49] P. Wilson, M. Johnstone, \nM. Neely, and D. Boles. Dynamic storage allocation: A survey and critical review. In Proc. of International \nWorkshop on Memory Management, September 1995. [50] B. Zorn. Comparative Performance Evaluation of Garbage \nCollection Algorithms. PhD thesis, EECS Department, University of California at Berkeley, 1989.  \n\t\t\t", "proc_id": "503272", "abstract": "In this paper, we introduce the notion of <i>prolific</i> and <i>non-prolific</i> types, based on the number of instantiated objects of those types. We demonstrate that distinguishing between these types enables a new class of techniques for memory management and data locality, and facilitates the deployment of known techniques. Specifically, we first present a new <i>type-based</i> approach to garbage collection that has similar attributes but lower cost than generational collection. Then we describe the <i>short type pointer</i> technique for reducing memory requirements of objects (data) used by the program. We also discuss techniques to facilitate the recycling of prolific objects and to simplify object co-allocation decisions.We evaluate the first two techniques on a standard set of Java benchmarks (SPECjvm98 and SPECjbb2000). An implementation of the type-based collector in the Jalape&#241;o VM shows improved pause times, elimination of unnecessary write barriers, and reduction in garbage collection time (compared to the analogous generational collector) by up to 15%. A study to evaluate the benefits of the short-type pointer technique shows a potential reduction in the heap space requirements of programs by up to 16%.", "authors": [{"name": "Yefim Shuf", "author_profile_id": "81339528339", "affiliation": "IBM T. J. Watson Research Center, Yorktown Heights, NY and Princeton University, Princeton, NJ", "person_id": "PP43116241", "email_address": "", "orcid_id": ""}, {"name": "Manish Gupta", "author_profile_id": "81100021061", "affiliation": "IBM T. J. Watson Research Center, Yorktown Heights, NY", "person_id": "PP43115237", "email_address": "", "orcid_id": ""}, {"name": "Rajesh Bordawekar", "author_profile_id": "81430619508", "affiliation": "IBM T. J. Watson Research Center, Yorktown Heights, NY", "person_id": "PP309983700", "email_address": "", "orcid_id": ""}, {"name": "Jaswinder Pal Singh", "author_profile_id": "81100279098", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP39035729", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/503272.503300", "year": "2002", "article_id": "503300", "conference": "POPL", "title": "Exploiting prolific types for memory management and optimizations", "url": "http://dl.acm.org/citation.cfm?id=503300"}