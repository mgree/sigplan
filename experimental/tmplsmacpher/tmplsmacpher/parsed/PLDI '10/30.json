{"article_publication_date": "06-05-2010", "fulltext": "\n DRFx: A Simple and Ef.cient Memory Model for Concurrent Programming Languages DanielMarino AbhayendraSingh* \nToddMillstein MadanlalMusuvathi SatishNarayanasamy* University ofCalifornia,LosAngeles * University ofMichigan,AnnArbor \nMicrosoftResearch,Redmond Abstract The most intuitive memory model for shared-memory multi\u00adthreaded programming \nis sequential consistency (SC),butit disal\u00adlowsthe use ofmany compiler andhardware optimizationsthereby \nimpacting performance. Data-race-free(DRF) models, such as the proposed C++0x memory model,guaranteeSC \nexecutionfordata\u00adrace-free programs. But these models provide no guarantee at all for racy programs, \ncompromising the safety and debuggability of such programs. To address the safety issue, the Java memory \nmodel, which is also based on the DRF model, provides a weak semantics for racy executions. However, \nthis semantics is subtle and complex, making it dif.cult for programmers to reason about their programs \nand for compiler writers to ensure the correctness of compiler optimizations. We present the DRFx memory \nmodel, which is simple for pro\u00adgrammers to understand and use while still supporting many com\u00admon optimizations. \nWe introduce a memory model (MM) excep\u00adtion which can be signaled to halt execution. If a program exe\u00adcutes \nwithout throwing this exception, then DRFx guarantees that the execution is SC. If a program throws an \nMM exception dur\u00adingan execution, then DRFx guarantees that theprogramhas adata race. We observe that \nSC violations can be detected in hardware through a lightweight form of con.ict detection. Furthermore, \nour model safely allows aggressive compiler and hardware optimiza\u00adtions within compiler-designated program \nregions. We formalize our memory model,prove severalproperties aboutthismodel,de\u00adscribe a compiler andhardwaredesign \nsuitablefor DRFx, and eval\u00aduate the performance overhead due to our compiler and hardware requirements. \nCategories and Subject Descriptors D.3.2[LanguageClassi.ca\u00adtions]:Concurrent,distributed, andparallellanguages \nGeneral Terms Design,Languages Keywords memory models, sequential consistency, data races, memory model \nexception, softfences 1. Introduction A memory consistency model (or simply memory model) forms the foundation \nof shared-memory multi-threaded programming. It Permission to make digital or hard copies of all or part \nof this work for personal or classroomuseisgranted withoutfeeprovided that copiesarenot madeordistributed \nforpro.tor commercial advantage andthat copiesbearthis notice andthefull citation onthe .rstpage.Tocopy \notherwise,torepublish,topostonserversortoredistribute tolists, requiresprior speci.cpermission and/or \nafee. PLDI 10, June5 10,2010,Toronto,Ontario,Canada. Copyright c &#38;#169; 2010 ACM 978-1-4503-0019-3/10/06. \n. . $10.00 de.nesthesetofpossible ordersinwhich memory operations can execute andthepossible values a \nread can return,therebyproviding a contract that programmers can assume and that compilers and hardware \nmust obey.Whileitisdesirabletoprovideprogrammers with a simple and strong guarantee about the behavior \nof their programs, doing so can reduce the .exibility of compilers and hardware to perform optimizations \nand thereby negatively impact performance. Acaseinpointisthememory modelknown as sequential con\u00adsistency \n(SC)[23], whichrequires all memory operationsin an ex\u00adecution of a program to appear to have executed \nin a global se\u00adquential order consistent with the per-thread program order. This memory modelis arguably \nthe most simpleforprogrammers, since itmatches theintuition of a concurrentprogram sbehavior as a set \nofpossible threadinterleavings.However, manyprogram transfor\u00admationsthat are sequentially valid (i.e.,correctwhen \nconsidered on an individual thread in isolation) can potentially violate SC in the presence ofmultiple \nthreads.For example, reordering two accesses to different memory locations in a thread can violate SC \nsince an\u00adother thread could view this reordering via concurrent accesses to those locations. As a result, \nSC precludes the use of common compiler optimizations (code motion, loop transformations, etc.) andhardware \noptimizations(out-of-order execution, storebuffers, lockup-free caches, etc.). In recent years, there \nhave been signi.cant efforts to bring to\u00adgether language, compiler and hardware designers to standardize \nmemory modelsfor mainstreamprogramminglanguages.The con\u00adsensus has been around memory models based on \nthe data-race\u00adfree-0(DRF0)model[1], which attemptsto strike a middleground between simplicity for programmers \nand .exibility for compilers and hardware. In the DRF0 model, a programmer explicitly dis\u00adtinguishes \nsynchronization accessesfrom otherdata accesses(us\u00ading type quali.ers such as volatile inJava[28] and \natomic in C++[7].) The compiler andhardware arelimitedinthe optimiza\u00adtions and reorderings they can perform \nacross synchronization ac\u00adcesses,in orderto ensuretheir semanticsisproperly respected.The DRF0modelthenguaranteesSCfor \nallproperly synchronizedpro\u00adgrams(i.e.,programsthatarefree of data races).UnlikethefullSC model, DRF0 \ncan achieve good performance since many standard sequentially valid compiler optimizationspreserveSCforproperly \nsynchronizedprograms. The DRF0 model provides a simple and strong guarantee for race-free programs, but \nit does not specify any semantics for pro\u00adgrams that contain data races. While such programs are typically \nconsidered erroneous, data races are easy for programmers to ac\u00adcidentally introduce and are dif.cult \nto detect. The DRF0 model thereforeposes twoimportantproblemsforprogrammers: Since a racyexecution canbehave \narbitrarilyinDRF0,it can vi\u00adolatedesired safetyproperties.Forexample,Boehm andAdve showhow a sequentially \nvalid compiler optimization can cause aprogramtojump to arbitrary codeinthepresence of adata race[7]. \n Debugging an erroneous program execution is dif.cult under theDRF0 model,because theprogrammer must \nalways assume that there may have been a data race. Therefore, it may not be suf.cient to reason about \nthe execution using the intuitive se\u00adquential consistency model in order to understand and identify the \nerror. The recentlyproposed C++ memory model C++0x[7]isbased ontheDRF0 model and shares these shortcomings.TheJava \nmem\u00adory model[28] addressesthe .rstproblemabovebyproviding ase\u00admanticsfor racyprograms whichis weaker \nthanSCbut still strong enough to ensure a useful form of safety. However, this weaker semanticsis subtle \nand complex, so thedebuggabilityproblemde\u00adscribed aboveis notgreatlyimproved.Further,proving the correct\u00adness \nand safety of various compiler andhardware optimizations un\u00adder this memory model continues tobe a challenge[10,35]. \nSome researchers have proposed the use of dynamic data-race detection tohaltexecution whenit wouldbecome \nunde.nedby the memory model[2,6].This approach would resolvetheproblems withtheDRF0 memory model, since \naprogram execution wouldbe guaranteed tobeSC unless the executionishalted.However, tobe useful such detection \nmust be precise, neither allowing a program to complete its execution after a data race nor allowing \na race-free execution tobe erroneously rejected.Precisedata-racedetectionin software is very expensive \neven with recently proposed optimiza\u00adtions[14], andhardware solutions[2,30] arequite complex. 1.1 The \nDRFx MemoryModel In this paper we introduce the DRFx memory model, which pro\u00advides a simple and strongguaranteetoprogrammers \nwhile support\u00ading many standard compiler and hardware optimizations. We take inspirationfromthe observation \nofGharachorloo andGibbons[16] that toprovide a usefulguarantee toprogrammers it suf.ces tode\u00adtect only \nthe data races that cause SC violations, and that such de\u00adtection canbe much simpler thanfull-.edged \nracedetection. The DRFx model introduces the notion of a dynamic memory model (MM) exception which halts \na program s execution. DRFx guarantees twokeypropertiesfor anyprogramP: DRF:IfPisdata-racefree then \neveryexecution ofPis sequen\u00adtially consistent anddoes not raise anMM exception.  Soundness: If sequential \nconsistency is violated in an execu\u00adtion ofP, then the execution eventually terminates with anMM exception. \n These twoproperties allowprogrammers to safelyreason about all programs, whether race-free or not, \nusing SC semantics: any pro\u00adgram s executionthatdoes notraiseanMM exceptionisguaranteed tobeSC.On the \notherhand,if an execution ofP raises anMM ex\u00adception, then the programmer knows that the program has \na data race. While our Soundness guarantee ensures that an SC violation will eventually be caught, an \nexecution sbehavioris unde.ned be\u00adtween thepoint at which theSC violation occurs and the exception is \nraised. The DRFx model thereforeguarantees an additionalprop\u00aderty: Safety: If an execution of P invokes \na system call, then the observable program state at that point is reachable through an SCexecution ofP. \nIntuitively the above property ensures that any system call in an execution of P would also be invoked \nwith exactly the same ar\u00adguments in some SC execution of P. This property ensures an im\u00adportantmeasure \nof safety and securityforprograms byprohibiting unde.nedbehaviorfrombeing externally visible. 1.2 ACompilerandHardwareDesignfor \nDRFx Gharachorloo andGibbonsdescribe ahardware mechanismtode\u00adtectSC violations[16].Their approachdynamicallydetects \ncon\u00ad.icts between concurrently executing instructions. Two memory operations are said to con.ict if they \naccess the same memory lo\u00adcation, at least one operation is a write, and at least one of the operations \nis not a synchronization access. While simple and ef\u00ad.cient, this approach only handles hardware reorderings \nand does not consider the effect of compiler optimizations.As a result, their approach guarantees our \nDRF and Soundness properties with re\u00adspecttothe compiled version of aprogrambutdoes notprovide any guarantees \nwithrespect to the original source program[12,16]. Our key contribution is the design and implementation \nof a de\u00adtection mechanism for SC violations that properly takes into ac\u00adcount the effect of both compiler \noptimizations and hardware re\u00adorderings while remaining lightweight and ef.cient.Our approach employs \na novelform of cooperationbetween the compiler and the hardware. We introduce the notion of a region, \nwhich is a single\u00adentry, multiple-exitportion of aprogram.The compilerpartitions a programinto regions, \nandboththe compiler and thehardware may only optimize within a region. Each synchronization access must \nbe placed in its own region, thereby preventing reorderings across such accesses.Wealsorequireeach systemcall \ntobeplacedinits own region, which allows us toguarantee the DRFx model sSafety property.Otherwise, a \ncompiler maychoose regionsin any manner in order to aid optimization and/or simplify runtime con.ictdetec\u00adtion.Within \na region,both the compiler andhardware canperform many standard sequentially valid optimizations. For \nexample, un\u00adrelated memory operations canbefreely reordered within a region, unlike the casefor the traditionalSC \nmodel. To ensure the DRFx model s DRF and Soundness properties with respect to the originalprogram, we \nshow thatit suf.ces tode\u00adtect region con.icts between concurrently executing regions. Two regions R1 \nand R2 con.ictifthere exists apair of con.icting oper\u00adations (o1,o2 ) such that o1 . R1 and o2 . R2.Such \ncon.icts can be detected using runtime support similar to con.ict detection in transactional memory(TM) \nsystems[19].AsinTM systems,both software and hardware con.ict detection mechanisms can be con\u00adsidered \nfor supporting DRFx. In this paper, we pursue a hardware detection mechanism, since the required hardware \nlogic is fairly simple and is similar to thatin existingbounded hardware transac\u00adtionalmemory(HTM)implementations \nsuch asSun sRockproces\u00adsor[13].Infact, ourhardwaredesign canbe signi.cantly simpler than that of a TM \nsystem. Unlike TM hardware, which needs the complex support for versioning and checkpointing to enable \nroll\u00adback on a con.ict, a DRFx hardware only needs support for rais\u00ading an exception on a con.ict. Also, \na DRFx compiler can bound the number of memorybytes accessedin each region, enabling the hardwaretoperform \ncon.ictdetection using.nite resources.While small regions limit the scope of compiler and hardware optimiza\u00adtions, \nwe discuss an approach inSection 4 that allows us to regain most of thelost optimizationpotential.  \n1.3 Contributions Thispaper makes thefollowing contributions: We de.ne the DRFx memory model for concurrent \nprogram\u00adminglanguages via three simple and strongguaranteesforpro\u00adgrammers(Section2).Wedescribe asetofconditions \non a com\u00adpiler andhardwaredesignthatare suf.cientto enforcethe DRFx memory model.  Wepresent aformalization \nof the DRFx memory model as well as of our compiler andhardware requirements(Section3).We have proven \nthat these requirements are suf.cient to enforce DRFx.  We describe a concrete compiler and hardware \ninstantiation of the approach (Section 4) and have implemented a DRFx\u00adcompliant compilerby modifyingLLVM[24].Wediscuss \nan ef.cient solution for bounding region sizes so that a processor candetect con.ictsusing .nitehardwareresources. \n We evaluatetheperformance costof our compiler andhardware instantiation in terms of lost optimization \nopportunity for pro\u00adgramsintheParsecbenchmark suite(Section5).We .nd that theperformance overheadis on \naverage3.25% when compared to thebaselinefully optimizedimplementation.  2. MotivationandOverview This \nsection motivates the problem addressed in the paper and provides an overview ofour solution through \na set of examples. 2.1 DataRaces Two memory accesses con.ict ifthey access the samelocation and at least \none of them is a write. A program state is racy if two different threads are about to execute con.icting \nmemory accesses fromthatstate.Aprogram contains adata race(or simply a race)if it has a sequentially \nconsistent execution that reaches a racy state. Consider the C++ example in Figure 1(a). After thread \nt executes theinstruction A, theprogram enters a racy statein which thread t is about to write to init \nwhile thread u is about to read that same variable.Therefore theprogram contains adata race. 2.2 CompilerTransformationsinthePresenceofRaces \nIt is well known that sequentially valid compiler transformations, which are correct when considered \non a single thread in isolation, can changeprogrambehaviorinthepresence ofdata races[1,17, 28]. Consider \nthe example in Figure 1(a)described above. Thread t uses a Boolean variable init to communicate to thread \nu that the object x is initialized. Note that although the program has a datarace,theprogram will notincuranulldereference \nonanySC execution. Consider a compiler optimization that transforms the program byreorderinginstructionsA \nandBinthread t.Thistransformation is sequentially valid, sinceit reorders writes to twodifferent mem\u00adory \nlocations. However, this reordering introduces a null derefer\u00adence (and violates SC) in the interleaving \nshown in Figure 1(b). The same problem can occur as a result of out-of-order execution at thehardwarelevel. \nTo avoid SC violations, languages have adopted memory mod\u00adelsbased ontheDRF0 model[1].Such modelsguaranteeSCfor \nprograms that are free of data races. The data race in our exam\u00adpleprogram canbe eliminatedbyexplicitly \nannotating the variable init as atomic (volatile in Java 5 and later). This annotation tells the compiler \nand hardware to treat all accesses to these vari\u00adables as synchronization . As such, (many) compiler \nand hard\u00adware reorderings are restricted across these accesses, and concur\u00adrent con.icting accesses to \nthese variables do not constitute a data race.As a result, the revisedprogram showninFigure1(c)isdata\u00adrace-free \nand cannotbe reorderedin a manner that violatesSC. 2.3 WritingRace-FreeProgramsisHard For racyprograms, \non the otherhand,DRF0modelsprovide much weakerguarantees thanSC.For example, theproposed C++ mem\u00adory \nmodel[7] considersdataraces aserrors akintoout-of-bounds array accesses and provides no semantics to \nracy programs. This approach requires that programmers write race-free programs in order to be able to \nmeaningfully reason about their program s be\u00adhavior, which we argueis an unacceptable burden.As an example, \nconsider the program in Figure 3(a) in which the programmer at\u00adtempted to .x the data race in Figure \n1(a) using locks. Unfortu\u00adnately, the two threads use different locks, an error that is easy to make, \nespecially in large software systems with multiple develop\u00aders. Unlike out-of-bounds arrayaccesses,thereis \nno comprehensive language orlibrary support to avoiddata race errorsin mainstream programming languages. \nFurther, like other concurrency errors, data races are nondeterministic andcanbedif.culttotriggerduring \ntesting.Evenif a raceis triggeredduring testing,it can manifestit\u00adself as an errorin any number of ways, \nmakingdebuggingdif.cult. Finally, the interaction between data races and compiler/hardware transformation \ncanbe counter-intuitive toprogrammers, who natu\u00adrally assumeSCbehavior when reasoning about their code. \n 2.4 DetectingDataRacesIsExpensive This problem with prior data-race-free models has led researchers \nto propose to detect and terminate executions that exhibit a data raceintheprogram[2,6].Notethatitis \nnot suf.cientto simplyde\u00adtect executions that encounter a racy state asde.nedinSection2.1. While the \nexistence of such an executionimplies the existence of a data racein theprogram, other executions can \nalsobe racy and can suffer from SC violations. Informally, an execution is considered racyifithastwo \ncon.icting accessesthat are notproperly synchro\u00adnized,regardlessofhow faraway they arefromoneanother. \nThe notion ofa racyprogram executionismadeprecisebyLam\u00adport shappens-before constraints[22],whichde.neapartialorder \non the operations in a concurrent execution. Operations within the same thread are totally orderedby \ntheirprogram order.In addition, synchronization operations on the same synchronization variable induce \ninter-thread happens-before edges, depending on the order in whichthethreadsperformthese operations.An \nexecutionis con\u00adsidered to be racy if two con.icting operations are not ordered in this partial order.1 \nFor example, consider the interleaving in Fig\u00adure 3(b). Since the two threads acquire different locks, \nthere are no happens-before edges between operations belonging to differ\u00adent threads.Therefore, the con.icting \naccesses to init and x each constitute a race. Precise dynamic data-race detection algorithms typically \nuse vector-clocks [22] to reason about the happens-before ordering during executions. These algorithms \nare inherently costly, as they require maintaining metadata per memory location and updating this metadata \nat each memory access. Furthermore, an access may participate in a data race with an access that occurred \narbitrarily far in the past, foiling attempts to discard metadata as the exe\u00adcution proceeds. Despite \nyears of research, ef.cient and precise dynamic data-race detection in software has not been achieved. \nEven after recent optimizations, software-based data-race detec\u00adtion slows down the execution of the \nprogram by a factor of 8 or more[14].Proposedhardware mechanisms canbe more ef.cient but are complex \nand require signi.cant changes to existing archi\u00adtectures[2,30].Also,hardwareschemescannoteasily detect \nfar away races since such schemes are limited by bounded hardware resources[30]. 1A program can then \nbe considered to have a data race if it has an SC execution thatis racy.One can show that thisde.nitionis \nequivalent to our simplerde.nition fromSection2.1, whichis more convenient to usein our formalism(Section \n3).  X* x= null; bool init = false; // Thread t // Thread u A: x = new X(); C: if(init) B: init = \ntrue; D: x->f++; (a) X* x =null; bool init = false; // Thread t // Thread u B: init = true; C: if(init) \n D: x->f++;  A: x =new X(); (b) X* x= null; atomic bool init = false; // Thread t // Thread u A: \nx = new X(); C: if(init) B: init = true; D: x->f++; (c) Figure1. (a)Originalprogram.(b)Transformedprogram.(c)Data-race-freeprogram. \n Figure2. The relationships amongvariousproperties of aprogram execution.  2.5 DetectingSCViolationsisEnough \nThe DRFx model is inspired by the observation that full happens\u00adbeforedata-racedetectionis unnecessary[16].While \nsuchdetec\u00adtion can bequite useful fordebugging purposes, itis overly strong if our goal is to ensure \nthat executions are SC. For example, even though theinterleavinginFigure3(b) contains adata race,the \nexe\u00adcutiondoes not resultin aprogram error.Thehardwareguarantees that all thememory accessesissued whileholding \nalock arecom\u00adpletedbefore thelockis released.Sincetheunlock atD completes before the lock at E, the execution \nis sequentially consistent even though the compiler reordered theinstructionsB andC.Therefore, the memory \nmodel can safely allow this execution to continue. On the other hand, executions like the one in Figure \n3(c) do in fact violateSC and shouldbehalted with a memory model(MM) ex\u00adception. TheVenndiagraminFigure2clari.esthis \nargument(ignorethe RCF and RS sets for now). SC represents the set of all executions that are sequentially \nconsistent with respect to a program P. DRF is the set of executions that are data-race free. To satisfy \nthe DRF and Soundness properties described in Section 1, we must accept all executions in DRF and terminate \nall executions that are not in SC. However, our model allows .exibility for executions that are not DRF \nbut are SC: it is acceptable to admit such executions since they are sequentially consistent, but it \nis also acceptable to terminate such executions since they are racy. As we describe below,this .exibilityallowsforamuch \nmoreef.cientdetectorthan full-.edged racedetection. Our memory model only guarantees that non-SC executions \neventually terminate with an exception. This allows us to perform SCdetection lazily, therebyfurther \nreducing the con.ictdetector s complexity and overhead. Nevertheless, the Safety property de\u00adscribed \nin Section 1 guarantees that an MM exception is thrown before the effects of a non-SC execution can reach \nany external component via a system call. 2.6 Enforcing the DRFx Model The key idea behind enforcing \nthe DRFx model is to partition a program into regions. Each region is a single-entry, multiple-exit portion \nof theprogram.Both thehardware and the compiler agree on the exactde.nition of these regions andperformprogram \ntrans\u00adformations only within a region. We require each synchronization operation and each system calltobeinits \nown region.Forinstance, onepossible regionizationfor theprograminFigure3 would make each of {B,C}and \n{F,G}a region and put each lock and unlock operationinits own region. During execution, the DRFx runtime \nsignals an MM exception if a con.ict is detected between regions that are concurrently ex\u00adecuting in \ndifferent processors. We de.ne two regions to con.ict if there exists any instruction in one region that \ncon.icts with any instruction in the other region. More precisely, we only need to signal an MM exception \nif the second of the two con.icting ac\u00adcesses executes before the .rst region completes. In the interleav\u00ading \nof Figure 3(b), no regions execute concurrently and thus the DRFx runtime will not throw an exception, \neven though the exe\u00adcution contains a data race. On the other hand, in the interleaving shown in Figure \n3(c), the con.icting regions {B,C}and {F,G}do execute concurrently, so anMM exception willbe thrown. \n 2.7 From Region Con.icts to DRFx The Venn diagram in Figure 2 illustrates the intuition for why our \ncompiler and hardware design satis.es the DRFx properties. If a program execution is data-race-free (DRF), \nthen concurrent regions will never con.ictduring that execution,i.e.,the execution is region-con.ict \nfree (RCF).Sincesynchronization operationsare in their own regions, this property holds even in the presence \nof intra-region compiler and hardware optimizations, as long as the optimizations do not introduce speculative \nreads or writes. If an execution is RCF, then it is also region-serializable (RS): it is equivalent to \nan execution in which all regions execute in some globalsequential order.Thatpropertyin turnimplies the \nexecution isSCwithrespecttothe originalprogram.This establishestheDRF property of the DRFx model. On \nthe otherhand, suppose thatan executionis notSC.Then as the Venn diagram shows, that execution is also \nnot region-con.ict free, so an MM exception will be signaled. Again this property holds even in the presence \nof non-speculative intra-region opti\u00admizations. Therefore the Soundness property of the DRFx model is \nenforced. Ingeneral,each ofthe setsillustratedintheVenndiagramisdis\u00adtinct:there exists some elementin \neach setthatis notin any subset. In some sensethisfactimpliesthatour notion of region-con.ictde\u00adtectionis \njustright to satisfy the two main DRFx properties.On the onehand,itispossiblefor a racyprogram execution \nto nonetheless be region-con.ict free. In that case the execution is guaranteed to beSC,sothereis no \nneedto signalanMM exception.This situation was described above for the example in Figure 3(b). On the \nother  X* x= null; bool init = false; // Thread t // Thread u A: lock(L); E: lock(M) B: x = new X(); \nF: if(init) C: init = true; G: x->f++; D: unlock(L); H: unlock(M) (a) // Thread t // Thread u A: \nlock(L); C: init = true; B: x= new X(); D: unlock(L);  E: lock(M) F: if(init) G: x->f++; H: unlock(M) \n (b) // Thread t // Thread u A: lock(L); E: lock(M) C: init = true; F: if(init) G: x->f++; B: x= \nnew X(); D: unlock(L); H: unlock(M) (c) Figure3. (a)Program withadata race.(b)Interleaving thatdoes \nnot expose the effect of a compiler reordering.(c)Interleaving thatdoes. for(i=0; i<n; i++) sum += a[i]; \n (a) if(n>0) { reg = sum; reg = sum; for(i=0; i<n; i++) for(i=0; i<n; i++) reg += a[i]; reg += \na[i]; sum = reg; sum = reg; } (b) (c) Figure4. Atransformation thatintroduces a read and a write. \nhand,itispossiblefor anSCexecution tohave a concurrent region con.ict and therefore trigger anMM exception. \nAlthough the exe\u00adcution is SC, it is nonetheless guaranteed to be racy. For example, consider again theprograminFigure3(a).Any \nexecutionin which instructions B and C are not reordered willbe SC,but with the re\u00adgionization described \nearlier some of these executions will trigger anMM exception.  2.8 TheCompilerand theHardwareContract \nThe compiler andhardware are allowedtoperform anytransforma\u00adtion within a region thatis consistent withthe \nsingle-thread seman\u00adtics of the region, with one limitation: the set of memory locations read(written) \nby a regioninthe originalprogram shouldbe a su\u00adpersetofthose read(written)bythe compiled version ofthe \nregion. This constraintensuresthat an optimization cannotintroduce adata racein an originally race-freeprogram. \nMany traditional compiler optimizations(constantpropagation, common subexpression elimination, dead-code \nelimination, etc.) satisfy the constraints above and are thus allowed by the DRFx model.Figure4describes \nan optimizationthatisdisallowedby our model.Figure4(a) shows aloopthat accumulatesthe result of some \ncomputation in the sum variable. A transformation that allocates a registerfor this variable is shown \ninFigure 4(b).The variable sum is readinto a register at thebeginning of theloop and writtenback at the \nend of the loop. However, on code paths in which the loop is never entered, this transformationintroduces \na spurious read and write of sum. While such behavior is harmless for sequential pro\u00adgrams, it can introduce \na race with another thread modifying sum. One way to avoid this behavior is to explicitly check that \nthe loop is executed atleast once, as shownin Figure 4(c). The DRFx model allows the transformation with \nthis modi.cation, although our cur\u00adrent compiler simply disables the transformation. In spite of this, \nthe experimental resultsin Section5indicate that theperformance reductionduetolost optimizationpotentialisquitereasonable, \non average3.25% on ourbenchmarks. In addition to obeying the requirement above, the hardware is also \nresponsible for detecting con.icts on concurrently executing regions. While performing con.ict detection \nin software would avoid the need for special-purpose hardware, con.ict detection in software can lead \nto unacceptable runtime overhead due to the need for extra computation on each memory access. On the \nother hand, performing con.ict detection in hardware is ef.cient and lightweight. Sun s TM support in \nthe Rock processor has demon\u00adstrated that con.ict detection is feasible in hardware [13]. DRFx hardwarecanactuallybesimplerthanTMhardware, \naswedonot require speculation support. Further, unlike in a TM system, the DRFx compiler can partition \na program into regions of bounded size, thereby further reducing hardware complexity by safely al\u00adlowing \ncon.ictdetectiontobeperformed with.xed-sizehardware resources. 3. FormalDescription of DRFx In this section \nwe describe our formalization of the DRFx model. We introduce preliminary notation and de.nitions in \nSection 3.1. Section 3.2 formally presents the requirements that DRFx places on the compiler and establishes \ntwo key lemmas relating a source programtothe outputof a DRFx-compliant compiler.InSection3.3 weformalize \nthe responsibilities of the execution environment and establish twoimportantproperties of a DRFx-compliant \nexecution. Finally, Section 3.4 uses these results to establish the properties of the DRFx model. We \nomit full proofs here but have made them availablein a companion technical report[29]. 3.1 PreliminaryDe.nitions \nAprogram P is a set of threads T1,T2 , \u00b7\u00b7\u00b7 ,Tn where each thread is a sequence ofdeterministicinstructionsincluding: \n regularloads and stores(regular accesses)  atomicloads and stores(atomic operations)  branches and \narithmetic operations on registers  a special END instruction indicating the end of a thread s exe\u00adcution \n a FENCE instruction used onlyin compiledprograms  Note that we assume the source language and target \nlanguage arethesame(actually thesourcelanguageisasubset of thetarget language), so both source programs \nand compiled programs are represented in the same way. An argument extending the results to ahigh-level \nsourcelanguage willbepresentedlater. We assume the semantics of our language is given in terms of how \nan instruction changes a machine state M that contains shared global memory locations as well as a separate \nset of local registers for each thread. This semantics dictates how a thread s abstract execution proceeds. \nWe write (M, I) -.T M, I ) to ( mean that executing instruction I in machine state M results in machine \nstate M with I poised to execute next in thread T . We write (M, I) -. * T M, I ) to indicate several \nsteps of execution ( (transitive closure ofabove). A FENCE instructionbehaves as a no\u00adop: (M, FENCE) \n-.T (M, I) where I is the next instruction in program orderinT .  We extend the notion of a thread s \nabstract execution to a pro\u00adgrambyhaving executionproceedby choosing any thread and ex\u00adecuting a singleinstructionfrom \nthat thread.We write: ( I j , (M, {I1 , \u00b7\u00b7\u00b7 ,Ij , \u00b7\u00b7\u00b7 ,In}) -.P M, {I1 , \u00b7\u00b7\u00b7 , \u00b7\u00b7\u00b7 ,In}) ifand onlyif \n(M, Ij ) -.Tj ( M, I j ).We call one or more ofthese steps a(partial) abstract sequential execution: \n(M, {I1 , \u00b7\u00b7\u00b7 ,In}) -. * M, {I 1 , \u00b7\u00b7\u00b7 , }). P ( I n Wede.ne a behavior tobeapairof machine statesanddenote \nit by Mstart . Mend. Intuitively, we use behaviors to describe a starting machine state and a machine \nstate that is arrived at after executing some or all of a program. The standard notion of sequential \nconsistency can be phrased in terms of behaviors and abstract sequential executions. De.nition 1. M0 \n. M is a sequentially consistent behav\u00adior for a program P , or M0 . M is SC for P , if there ex\u00adists \nan abstract sequential execution (M0 , {I10 , \u00b7\u00b7\u00b7 ,In0 }) -. * P (M, {END, \u00b7\u00b7\u00b7 , END}) where each Ii0 \nis the .rst instruction in thread Ti. We say that M0 . M is a sequentially consistent par\u00adtialbehaviorfor \nP ifthereis apartialabstract sequential execution (M0 , {I10 , \u00b7\u00b7\u00b7 ,In0 }) -. P * (M, {I1 , \u00b7\u00b7\u00b7 ,In}) \nwhere each Ii0 is the .rstinstructioninthread Ti. We say that two memory access instructions u and v \ncon.ictif they access the same memory location, at least one is a write, and atleast oneis not an atomic \noperation.We say that aprogramhas a data race ifithas apartialabstract sequential execution where two \ncon.icting accesses are ready to execute.Moreformally: De.nition 2. A program P has a data race if for \nsome M0 , u, v, (M0, {I10 , \u00b7\u00b7\u00b7 ,In0}) -.P * (M, {I1 , \u00b7\u00b7\u00b7 , u, \u00b7\u00b7\u00b7 , v, \u00b7\u00b7\u00b7 ,In}) where u and v are \ncon.icting accesses. We shall say that such a partial abstract sequential execution exhibits adata race. \n 3.2 DRFx-compliantCompilation A partition Q of a thread T is a set of disjoint, contiguous sub\u00adsequences \nof T that cover T . Call each of these subsequences a region.Regions willbedenotedby the metavariable \nR. De.nition3. Apartition Q is valid if: each atomic operation and END operation isinits own region \n each region has a single entry point (i.e. every branch has a targetthatiseitherinthesameregion oristhe \n.rstinstruction in another region)  We extend the notion of abstract execution of a thread from instructions \nto regions asfollows.We write (M, R) -.T M, R ) ( if(M, I1) -.T \u00b7 \u00b7 \u00b7 -.T ( ) where M,In I1 isthe .rstinstructioninR, \n Ik I1 for each 2 = k =  = n, I2, \u00b7\u00b7\u00b7 ,In-1 . R, and  In isthe .rstinstructioninregion R (itispossiblethat \nR = R).  For threads with valid partitions, (M, R) -.T ( R) intu- M, itively means that beginning with \nmemory in state M, executing theinstructionsin R inisolation willresultin memoryhaving state M and T \nready toexecutethe .rstinstructioninregion R .Extend\u00ading this toprograms, an abstract region-sequential \nexecutionis one where a scheduler arbitrarily chooses athread and executes a single regionfrom that thread.Wede.ne \nregion-serializable behaviorfor aprogram P in terms ofan abstract region-sequential execution. De.nition \n4. We say M0 . M is region-serializable behavior, or RS, for P with respect to thread partitions Qi if \nthere is an ab\u00adstract region-sequential execution (M0, {R10 , \u00b7\u00b7\u00b7 ,Rn0 }) -.* P (M, {R1 , \u00b7\u00b7\u00b7 ,Rn}) where \neach Ri0 is the .rst region given by partition Qi for thread Ti. Now let us introduce notation for the \nread and write sets for a region given a starting memory state. read(M, R) is the set of locations readwhen \nexecuting R inisolation startingfrom memory state M. write(M, R) isde.nedsimilarly.Notethatthese are \nsets and not sequences. We can now describe the requirements our model places on a compiler. Consider \na compilation P r P ' where each thread Ti in P ispartitionedinto some number, mi, of regionsby Qi.So \nwe have,P = {T1 , \u00b7\u00b7\u00b7 ,Tn}= {R11 \u00b7\u00b7\u00b7 R1m1 , \u00b7\u00b7\u00b7 ,Rn1 \u00b7\u00b7\u00b7 Rnmn }. Furthermore, the compiled program has \nthe same number of threads and each is partitioned by some Q ' i into the same num\u00adber of regions as \nin the original program. So we have, P ' = {R ' \u00b7\u00b7\u00b7 R ' , \u00b7\u00b7\u00b7 ,R ' \u00b7\u00b7\u00b7 R ' }. 11 1m1 n1 nmn We consider \nsuch a compilation tobe DRFx-compliant if: (C1) Thepartitions Qi and Q ' i are valid. (C2) For all i, \nj, M, we have (M, Rij ) -. * M,Rik) .. Ti ( (M, R ij ' ) -.* ' ( ik T M,R ' ) i (C3) For alli, j, M, \nwehave read(M, Rij ) . ij ) and read(M, R ' write(M, Rij ) . write(M, R ' ij ) (C4) Each region R ' in \nthe compiled program contains exactly ij one FENCE operationanditisthe .rstinstruction. Intuitively, \nthe above de.nition of a DRFx-compliant compila\u00adtion requires that a DRFx-compliant compiler choose valid \nparti\u00adtions for a program s threads, perform optimizations only within regions, maintain the read and \nwrite sets of each region, and in\u00adtroduce FENCE instructions todemarcate regionboundaries. These FENCE \ninstructions communicate the threadpartitions chosen by a DRFx-compliant compilertothe execution environment.Inthe \nnext section, we will refertothese asthe fence-induced threadpartitions of aprogram. We now state the \ntwo key lemmas we have proven for DRFx\u00adcompliant compilations. Lemma 1. If P r P ' is a DRFx-compliant \ncompilation and M0 . M is a region-serializable behavior for P ' with respect toitsfence-induced threadpartitions, \nthen M0 . M is a(partial) sequentially consistentbehavior for P . Proof Sketch. We can transform an abstract \nregion-sequential execution of P ' to an abstract region-sequential execution of P due to(C2).Clearly \nan abstract region-sequential executionquali.es as an abstract sequential execution. D Lemma 2. If P \nr P ' is a DRFx-compliant compilation and P ' has adata race, then P has adata race. Proof Sketch. Essentially, \nwe take a partial abstract sequential execution of P ' that exhibits the data race and reorder the trace \nmaintainingprogramdependencies to achieve atrace with a region\u00adsequential pre.x and a suf.x containing \nthe race. The reordering relieson(C1).Wethen use(C2) and(C3) to construct an abstract sequential execution \nof P exhibiting adata race. D  3.3 DRFx-compliantExecution We now formally specify the requirements \nthat the DRFx model places on a machine executing a program. We will represent a (partial) relaxed execution, \nE, of a program as a 5-tuple E = (M0, T, EO, FO, err) where M0 is the initial machine state, T is the \nset of individual thread traces (T = {dT1, \u00b7\u00b7\u00b7 , dTn}), EO is a relation on operations that speci.es \nthe order in which each pair of con.icting operations occurs, FO is a global, total order on FENCE operations, \nand err is either \u00d8 or a single element of EO, u<EO v. Intuitively, a non-empty err will indicate a con.icting \npair of accesses in concurrently executing regions. We require that EO and FO are each consistent with \neach thread trace.Inparticular, ifu<EO v fortwo operationsu and v inthe samethreadtrace,then u must occur \nbefore v in that thread trace, and similarly for each pairf<FO f ' from the same thread trace.  We say \nthat an execution E =(M0, T, EO, FO, err) is well\u00adformed for a program P if each operation in a thread \ntrace dTi is an operation from thread i in P and each thread trace dTi satis\u00ad.es intra-thread data, control, \nand fence dependencies. The fence dependencies ensure that all operations program-ordered before a FENCE \ncomplete before it, and all operations program-ordered after a FENCE complete after it. We model all \nof these depen\u00addencies as a partial order D on operations from the same thread trace. Well-formedness \nalso requires that EO|wr . D is acyclic, where EO|wr is the subset of EO containing only write-to-read(i.e. \nread-after-write, ortrue) dependencies(u<EO|wr v .. u<EO v .u a write .v a read).This ensures thatE has \na unique, well\u00adde.nedbehavior M0 M. Beforede.ningthe restrictions weplace on a relaxedexecution, wede.ne \nan order on memory accesses thatisderivedfrom E.For a memory access u . dTi .T, de.ne postFence(u) to \nbe the closest FENCEoperationthat executed after u indTi, or \u00d8ifno such operation exists.We use this \nnotion toinduce an order on memory accesses based on the fence order FO. Two memory accesses are weakly-fence-ordered, \nu<WFO v,if postFence(u)= \u00d8and either postFence(u) =FO postFence(v) or postFence(v)= \u00d8. We also de.ne \nan operator on a partial relaxed execution that truncates incomplete thread traces to their most recent \nFENCE op\u00aderation, removespairs from EO if at least one operation in thepair has been truncated from its \nthread trace, and sets err to \u00d8. We no\u00adtate this asfollows: .(M0 , T, EO, FO, err). =(M0 , .T., .EO., \nFO, \u00d8) WecallanexecutionE =(M0 , T, EO, FO, err) DRFx-compliant if E satis.es one of thefollowing conditions, \nwhich formalize our notion of region-con.ictdetection: (E1) err = \u00d8andfor all operations u and v, u<EO \nv . u<WFO v or (E2) Allof thefollowing conditionshold: err = u<EO v  u and v arefromdifferent threads \n postFence(u)= \u00d8and postFence(v)= \u00d8  for alloperations w and z wehave w<WFO z . z .EO w  .E.DRFx-compliant \n WerefertoaDRFx-compliantexecution satisfying(E1)as exception\u00adfree and one satisfying(E2) as exceptional. \nWehaveproven twokeyresultsfor DRFx-compliant executions. Lemma 3. Given a well-formed exception-free \nDRFx-compliant execution E =(M0, T, EO, FO, \u00d8) of a program P with valid fence-induced thread partitions, \n.E. exhibits region-serializable behavior w.r.t. to thefence-inducedpartitions. Proof Sketch. The total \norder on fences FO can be viewed as a commit order for fence-induced regions where a region R1 commits \nbefore R2 if the fence following R1 is ordered by FO before the fence following R2 . From (E1) we know \nthat, even if portions of R1 and R2 executed concurrently, any con.icting accesses between them are ordered \nby EO in one direction, from the access in R1 to the access in R2 .This allows us to ensure that the \nEO relation lifted to regions is acyclic, which implies that the executionis serializable w.r.t. to the \nregions. D Lemma 4. If there is a well-formed exceptional DRFx-compliant execution of a program P with \nvalid fence-induced thread parti\u00adtions, then P has adata race. Proof Sketch. From (E2) we have two con.icting \naccesses in regions that are not yet committed in the sense that no FENCE has executed afterthe accessin \neitherthread.Alsofrom(E2) we can showthatthe executionhas a region-serializablepre.x.This allows us to \nconstruct an abstract sequential execution in which the two con.icting accesses areboth ready to execute, \nthereby exhibiting a data racein P . D  3.4 DRFx Guarantees Putting together the lemmas from Sections \n3.2 and 3.3, we can prove thefollowingtheorem, which ensures that a DRFx-compliant compiler along with \na DRFx-compliant execution environment en\u00adforce ourDRFandSoundnessproperties. Theorem 1. If P r P ' is \na DRFx-compliant compilation, and E is a complete DRFx-compliant execution of P ' with behavior M0 M, \nthen either: E is exception-free and M0 M is sequentially consistent behavior for P or E is exceptional \nand P contains adata race. The arguments presented above were developed entirely in the context of a \nlow-level machine language. The results can how\u00adever be extended to a high-level source language in the \nfollow\u00ading way.Imaginea canonical compiler thattranslateseachhigh\u00adlevel statement into a series of low-level \noperations that read the operands from memory into registers, perform appropriate arith\u00admetic operations \non the registers, and then store results back to memory. Any optimizations are then applied after this \ncanonical compiler is run. We can extend our results to the high-level lan\u00adguage simply by requiring \nthat the compiler choose a region par\u00adtition that does not split up instructions that came from the same \nhigh-level sourcelanguage expression or statement. The de.nition of a DRFx-compliant execution and Lemma \n3 establishthat all DRFx-compliant executions are region-serializable up to the latest completed region \nin each thread. Combining this fact with Lemma 1, we can see that, up to the completed regions, an execution \nis SC with respect to the original source program. Therefore, if we require that system calls are placed \nin their own region and that they are only passed thread-local data, we ensure that whatever behavior \nthey exhibit would have been reachable in anSCexecution ofthe originalprogram.ThisestablishestheSafety \nproperty of our DRFx model. 4. CompilerandHardwareDesign There are several possible compiler and hardware \ndesigns that meet the requirements necessary to ensure the DRFx properties as described in the previous \nsection. In this section we describe one concrete approach, whichis evaluated in the next section.Our \napproach is based on two key ideas crucial for a simple hardware design. Bounded regions: First, the \ncompiler bounds the size of each re\u00adgion in terms of number of memory bytes it can access using a conservative \nstatic analysis. Bounding ensures that the hardware can perform con.ict detection with .xed-size data \nstructures. De\u00adtectingcon.icts with unbounded regionsinhardware would require complex mechanisms, such \nasfallingback to software on resource over.ow, that arelikely tobeinef.cient.  Soft fences: When splitting \nregions to guarantee boundedness, the compiler inserts a soft fence. We distinguish this from regu\u00adlar \nfences discussed in Section 3, and call the latter hard fences in the rest of the paper. Hard fences \nare necessary to respect the se\u00admantics of synchronization accesses andguaranteetheproperties of DRFx.Softfences \nmerely conveytothehardwarethe regionbound\u00adaries across which the compiler did not optimize. These smaller, \nsoft-fence-delimited regions ensure that the hardware can soundly perform con.ict detection with .xed-size \nresources. But, we ob\u00adserve that it is in fact safe for the hardware to reorder instructions across soft \nfences whenever hardware resources are available, es\u00adsentially erasing any hardwareperformancepenaltydue \nto our use ofbounded-size regions. 4.1 CompilerDesign Wehave modi.ed theLLVM compiler[24] tobe DRFx-compliant. \nAs speci.edbythe requirements(C1)-(C4)intheprevious section, to ensure the DRFx properties the compiler \nmust simply partition theprograminto valid regions, optimize only within regions, avoid inserting speculative \nmemory accesses, and insert fences at region boundaries. 4.1.1 InsertingHardFencesforDRF andSafety Ahard \nfenceis similar to a traditionalfenceinstruction.Thehard\u00adware ensures that prior instructions have committed \nbefore allow\u00ading subsequent instructions to execute. To guarantee SC for race\u00adfree programs, the compiler \nmust insert a hard fence before and after each synchronization access. On some architectures, the syn\u00adchronization \naccessitself canbetranslatedto aninstructionthathas hard-fence semantics(e.g., the atomic xchg instructioninAMD64 \nand Intel64 [7]), obviating the need for additional fence instruc\u00adtions. In our current implementation, \nthe compiler treats all calls to the pthread library and lock-pre.xed memory operations as atomic accesses.In \naddition, since theLLVM compilerdoes not support the atomic keyword proposed in the new C++ standard, \nwe treat all volatile variables as atomic.All other memory oper\u00adations are treated asdata accesses. To \nguarantee DRFx s Safety property, the compiler also inserts hardfencesfor eachsystem callinvocation, \nonebefore enteringthe kernel mode and another after exiting the kernel mode. Any state that could be \nread by the system call is .rst copied into a thread\u00adlocal data structure before the .rst hard fence \nis executed. This approach ensuresthatthe external system can observe onlyportions of the execution state \nthat are reachablein someSC execution. To insert a hard fence, we used the llvm.memory.barrier intrinsicinLLVMwithall \nofitsparameters settotrue.This ensures that the LLVM compilerpasses do not reorder memory operations \nacross the fence. Also, the LLVM s code generator translates it correctly to an mfence instructionin \nx86 which restrictshardware optimizations across thefence. 4.1.2 InsertingSoftFencestoBoundRegions In \naddition tohardfences, the compilerinserts softfences tobound the number of memory operationsin any region.We \nemploy a sim\u00adple and conservative static analysis in the compiler to bound the number of memory operations \nin a region. While overly small re\u00adgionsdolimitthe scope ofcompiler optimizations, our experiments in \nSection 5 illustrate that the performance loss due to this limita\u00adtion is about 1.7% on average. After \ninserting all the hard fences described earlier,the compilerperformsfunctioninlining.We then insertsoftfences \non theinlined code.A softfenceis conservatively insertedbefore eachfunction call and return, andbefore \neach loop back-edge. Finally, we insert additional soft fences in a function body asnecessary tobound \nregionsizes.Thecompilerperformsa conservative static analysis to ensure that no region contains more \nthan R memory operations, thereby bounding the number of bytes that can be accessed by any region. The \nconstant R is determined based on the size of hardware buffers provisioned for con.ict de\u00adtection. The \nabove algorithm prevents compiler optimizations across loop iterations, since a soft fence is inserted \nat each back-edge. However, we could apply a transformation analogous toloop tiling which has the effect \nof placing a soft fence only once every R/L iterations, where L is the maximum number of memory operations \nin a single loop iteration. Restructuring loops in this way would allow us to safely perform compiler \noptimizations across each block of R/L iterations. 4.1.3 CompilerOptimization After region boundaries \nhave been determined, the compiler may perform its optimizations. By requirements(C2) and(C3), any se\u00adquentially \nvalid optimizationis allowed within a region, aslong as itdoes notintroduce anyspeculative reads or writes.As \nsuch,in our current implementation, we explicitly disable all speculative opti\u00admizationsinLLVM.2 We note,however, \nthat there are several use\u00adful speculative optimizations that have simple variants that would be allowedby \nour model.For example,instead ofinserting a spec\u00adulative read,the compiler couldinsert a specialprefetchinstruction \nwhich the hardware would not track for purposes of con.ict de\u00adtection.TheItaniumISAhas supportfor such \nspeculation[38] in order to hide the memory latency of reads. Also, as shown earlier inFigure4,loop-invariantcode \nmotionis allowedby our model, as long as the hoisted reads and writes are guarded to ensure that the \nloopbody willbe executed atleast once.  4.2 HardwareSupport The hardware support required for DRFx \nis similar to con.ict de\u00adtectioninhardware transactional memory(HTM) systems, such as Sun sRockprocessor[13].Ourbasichardwaredesign \nadaptsthe lazy con.ictdetectionapproach ofHammond etal.[18].Oursup\u00adportisin some ways simpler than that \nof HTM, since we throw an exception upondetecting a con.ict rather thanperforming rollback and re-execution.On \nthe otherhand, our con.ictdetection mustbe precise since afalse con.ictwould resultin afalseMM exception, \nwhile a false con.ict in an HTM system is acceptable as it simply causes an unnecessary re-execution. \n 4.2.1 BasicHardwareDesign HTM systems commonly detect con.icts by maintaining read and write accessbitsper \ncacheline.However, this approach canlead to false con.ictsiftwodifferentmemory words accessed concurrently \nindifferentthreadshappentobe assignedtothe same cacheline.To addressthisproblem, wetrack read and writeaccesses \nof aregion using a circularqueuebufferthatwe calla regionbuffer and employ lazy con.ictdetection. At \nthe beginning of a region, a region-start record is inserted into the region buffer along with the current \ntimestamp of the processor(obtainedby executing the x86 RDTSC instruction). On committing a read or a \nwrite operation,theprocessor coreinserts an entry into the buffer consisting of the memory operation \ns address along with a bit indicating whether the operation was a read or a write, and three bits indicating \nthe number of bytes accessed by the operation(for a total of 68 bitsper buffer entry).At the end of a \nregion, a region-end log is inserted into the region buffer along with the current timestamp. 2The LLVM \nimplementation has functions called isSafeToSpeculativelyExecute, isSafeToLoadUnconditionally and isSafeToMove, \nwhich we modi.ed to return false for both loads and stores.  We perform con.ict detection lazily, only \nonce when all of a region s instructions have completed. At that point, the processor core P broadcasts \nthe region s read/write sets along with the start and end timestamps to all the other processor cores. \nEach remote processor core checksifthereis any read-write or write-write con\u00ad.ict with its region buffer. \nOn detecting a con.ict, an MM excep\u00adtion is thrown. Otherwise, each core sends an acknowledgment to P \n.On receiving acknowledgments from all theprocessor cores, P commits its regionby clearingits entriesin \nthe regionbuffer. Becausewedetect con.ictslazily,itispossiblethatthe execu\u00adtion is in a non-SC state \nfor some time before the violation is de\u00adtected.This couldlead to twoproblems which we need to address. \nFirst, it is possible for a non-SC execution to cause an exception otherthan anMM exception(e.g., a nulldereference) \ntobethrown, halting theprogram before we detect the con.ict and violating the DRFx sSoundnessproperty.Toprevent \nthisproblem, thehardware performs con.ict detection immediately when an instruction in a region encounters \nan exception. If a con.ict is detected, then an MM exception is thrown instead of the original exception. \nOth\u00aderwise, the execution is SC and we can safely throw the original exception. Second, a non-SCexecution \nmight enter a non-terminatingloop that is not possible in an SC execution. Therefore, the hardware eagerly \nperforms con.ict detection if a region has executed for more than some constant C cycles.If a con.ictisdetected, \nanMM exception is thrown. Otherwise, execution continues as usual and thehardware waits another C cycles \nor until the end of the region, whichevercomes .rst,toperformcon.ictdetection.Notethatour use of bounded \nregions does not solve this problem, as we only bound the number of memory operationsperformed rather \nthan the number ofinstructions.  4.2.2 HandlingHard andSoftFences The current region ends whenever either \na hard or soft fence in\u00adstructionis encountered. If thefence terminating a regionis ahard fence, theprocessor \ncore thatexecuted the region stalls until allthe memory operations executed aspart ofthe region completes, \nwhich requires it to wait for all the outstanding coherence operations to .nish. Once they .nish, con.ict \ndetection is initiated as described above. The hardware cannot safely reorder memory operations across \nhard fences since that could violate the semantics of a synchro\u00adnization access and introduce a false \nrace. However, the hardware can safely reorder memory operations across regionsdelimitedby a softfence. \nBecause the two adjacent regions have no synchroniza\u00adtion accesses or system calls, it is impossible \nfor such reordering to introduce a false race: if a reordering causes a con.ict with a concurrent region \non another processor, then the original program musthave adata race. Therefore, on encountering a soft \nfence the processor immedi\u00adately continues its execution of the next region without stalling. When all \nthe outstanding coherence operations for the .rst region .nish, its end time is recorded in the region \nbuffer, and then the processor core follows the same protocol as described earlier to commit that region. \nTo commit a region, a processor core deletes all the entries corresponding to that region from its region \nbuffer, making spacefor recordingfuture memory operations. Aprocessor core can only run out of regionbuffer \nspacedue to the overlapped execution of multiple regions, since our approach to bounding regions prevents \ncon.ict detection of any single re\u00adgion from over.owing hardware resources. When this situation is encountered, \nthe core simply has to stall and wait for the earliest uncommitted region to complete, which will happen \nonce all out\u00adstanding coherenceoperationsforthat regionare .nished. In this way, the hardware can overlap \nthe execution of most re\u00adgions, achieving performance close to that of DRF0 relaxed mem\u00adory models while \nmaintaining the DRFx guarantees.  4.2.3 OptimizingCon.ictDetection There are opportunities for optimizing \nthe above hardware design in several ways. First, we can avoid inserting the same address re\u00addundantly \ninto the region buffer. This can be achieved by keeping track of a read con.ict bit and a write con.ict \nbit for each byte in each processor core s L1 cache. Second, we can use a read and a writebloom .lter[34] \ntoacceleratecon.ictdetections.Tocom\u00admit a region, only the bloom .lters signatures are broadcasted to \nthe remote processors. On detecting a potential con.ict, a precise con.ictdetectionisinitiated to avoidfalse \ncon.icts.Third,if there were no cache miss, cache evictions, and coherence downgrade re\u00adquests(invalidate \nor requestfor sharedaccess)duringthe execution of a region,thenitimpliesthatno otherprocessor corehas \na con\u00ad.ict. Therefore, it is safe to commit that region without checking for con.icts with otherprocessors.We \nexpect this tobe a common case. 5. Evaluation We implemented a DRFx-compliant compiler using LLVM [24], \nevaluatedthe compiler withprogramsfromtheParsec[4] bench\u00admark suite, anddeveloped apro.ling tool usingPin[27] \nto study theproperties of regions createdbythis compiler.We usedParsec s sim-large inputsetforour evaluation, \nand eachprogram was con\u00ad.gured to use four threads. To perform our experiments, we used a 64-bit machine \nwith Intel Core-2 2.40 GHZ Quad CPU, 4MB cache size, and4GBRAM.For each experiment, we executed each \nprogram35times and took an average of their execution times. Figure5showstheperformance overheaddue to \nseveral restric\u00adtions imposed on the compiler and hardware optimizations. The overheads are normalized \nto the performance of a binary that is compiled withthe unmodi.edLLVM compiler at -O3 optimization level. \nThe .rst overhead we study is due to disabling compiler opti\u00admizations andhardware reorderings when weinserthardfencesfor \nsynchronization calls and system callsbut without softfences.The overhead includes that from restricting \nthe scope of optimizations as well as from turning off all speculative optimizations done in LLVM.Thisexperiment \nmeasuresthe overhead wewouldincurif we had ideal hardware with support for unbounded regions. We canseethatthecompilercostduetohardfencesisabout0.3% \non average(maximum 2.53% for facesim). When we add the hard\u00adware costfor executinghardfences,the average \noverheadincreases to about1.55%. Next we measured the cost of inserting soft fences to bound the region \nsizes.We used the static analysisdescribed inSection4 with a bound of 512 memory operations per region, \nwhich would require eachprocessor core tohave a regionbuffer of roughly4KB orlarger(512 entries *68bits/entry).Bounding \nthe regions using soft fences incurs an additional 1.7% overhead which is caused by restricting compiler \noptimizations to smaller regions. The soft fences were translatedto nops in the compiledbinary and thusdid \nnot restricthardware optimization. To measure the importance of distinguishing soft fences, we also evaluated \na version that executes soft fences as hard fences (usingmfence)on ourIntelCore-2 machine.This version \nsuffered asigni.cantperformancedegradation, about92% on average(max\u00adimum is145.5% for facesim). The main \nreason for this overhead is that thehardware is now restrictedfrom reordering and overlap\u00adping memory \noperations from soft-fence delimited regions. How\u00adever, as discussed in Section 4.2.2, we can indeed \nallow hardware tooptimizeacross softfences.Thus,if wehaveef.cienthardware  Hard Fence Compiler Cost \n Hard Fence Hardware Cost 1000 Soft Fence Compiler Cost Soft Fence Unoptimized Hardware Cost 100 10 1 \n 0.1 0.01  % Perf. Overhead 0.001 blackscholes ferret facesim swaptions bodytrack canneal fld.animate \nx264 streamcluster Avg Figure 5. Performance overhead with respect to the performance of an uninstrumented \nbinary, compiled with all the traditional compiler optimizations enabled. 100,000,000 1,000,000  Bytes \n10,000 100 1 Figure6. Maximum number ofunique memorybytes accessedin any region. Hard Fence only Regions \nHard+Soft Fence Regions  1,000,000 Instr/Region 10,000 100 1 Figure7. Average number ofinstructions \nexecutedin a region. supportfor con.ictdetection, we expect that the only main sources ofperformance \noverheadinDRFx wouldbethe compiler andhard\u00adware costdue tohardfences(1.55%),plusthe compiler cost of \nsoft fences(1.7%) which sums up to atotal of about3.25% overhead on average. Figure6 showsthemaximumnumberof \nunique memorybytes (footprint)accessedin any region.Thegraph shows resultsfor two con.gurations. One \nis for binaries that contains only hard fences, with no softfences inserted, while the otherisforbinaries \nthat ad\u00additionallycontain softfences usedtobound regions.As we can see, without region bounding there \ncan be regions that access over 34 millionunique memorybytes(ferret), andthe average footprint of aregion(notshowninthe \n.gure) isashigh asabout800,000 memory bytes for blacksholes. With soft fences inserted, the maximumfootprintisbounded \nwithin776 memorybytes(ferret) (the upper limit was set to 512*8 bytes in the static analysis). The large \nsize of unbounded regions implies that hardware detection with unbounded regionsislikely tobeinef.cient. \nFigure 7 shows the average number of instructions executed in a region.With softfencesinserted,the regions \nare much smaller, as expected. While soft fences allow for bounded con.ict detection, thehardware may \nstillfreely reorderinstructions across them.The hardware maynot reorderinstructions acrosshardfences,but \nas we can seethe number ofinstructionsbetween consecutivehardfences is suf.ciently large to allow for \nmemory-level parallelism close to that of a relaxed memory modelimplementation. 6. RelatedWork 6.1 Reducing \ntheCost ofSequentialConsistency Weak memory models are not necessary if both the compiler and the hardware \ncan guarantee SC without prohibitive performance cost.Prior workhas explored thispossibility. Several \nstatic analyses insert fences in a program to guarantee SC.Shasha andSnirproposed the delay sets algorithmforthispur\u00adpose[36].KrishnamurthyandYelick[21]proved \nthat computing a minimaldelay set(i.e.,set offences)for aprogramisNP-complete. Two recentprojects,Titanium[20] \nandPensieve[37], extendthe delay set algorithm to reduce the number offences needed toguar-anteeSC.These \nanalysesleverage a number oftechniques todeter\u00admine whether a memory location can potentially be involved \nin a race,including sharinginference[25],pointer alias analysis, and thread escape analysis. These techniques \nrequire fairly-complex whole-program analyses that are dif.cult to scale to large pro\u00adgrams, especially \nfor languages like C++. In contrast, our DRFx model allows the compiler andhardware tofreelyperform sequen\u00adtially \nvalid reorderings(otherthan speculative accesses) within a region(in addition,hardware can optimize across \nregionsdelim\u00aditedbysoftfences) without requiring any additional static analysis.  Onthe otherhand, DRFx \nonlyguaranteesSCfordata-racefreepro\u00adgrams. At the hardware level, various forms of speculation have been \nproposedtoreducetheperformance overheadofSC[5,11,33]. Of course, these techniques can only guarantee \nSC of the com\u00adpiledprogram andcannotdetectthenon-SCbehaviorintroducedby the compiler. Recent work on \nthe BulkCompiler[3] addresses this problemin the context ofJavaprograms that uselocks.Even then, all \nthese hardware proposals above require speculative execution, checkpointing, and rollback in case of \ncon.icts, which tremen\u00addously increases the hardware complexity. Unlike ours, these pro\u00adposals require \npossibly unbounded resources and thus have to in\u00adclude appropriate mechanisms tohandle over.ow cases. \n 6.2 SupportforaMemoryModelException Adve et al.[2]proposed todetectdata races at runtime usinghard\u00adware \nsupport.Recently,Boehm[6]provided aninformal argument for integrating an ef.cient always-on data-race \ndetector to extend the DRF0 model by throwing an exception on a data race. How\u00adever, detecting data races \neither incurs 8x or more performance overheadinsoftware[14] orincurssigni.canthardware complex\u00adity[30,32]despite \nmanyproposed optimizations to thebasic tech\u00adnique. The large overhead comes from the need to dynamically \nbuild the happens-before relation [22] between pairs of memory operations.Furthermore,whenamemory operation \noccurs,it may need to be compared with other memory operations that occurred arbitrarily far inthepast(which \nmeansthatahardwaredetec\u00adtor wouldhave to somehow maintaininformationfor evicted cache blocks as well).In \ncontrast,thehardware supportrequiredfor DRFx is much simpler as it requires only that we maintain a set \nof ac\u00adcessesper region and only compare two regions setsif the regions execute concurrently. The complexity \nis further simpli.ed by en\u00adsuring that the sizes of regions arebounded. Our workbuilds onthatofGharachorloo \nandGibbons[16], who recognized that it suf.ces to detect SC violations directly rather thandata races.Theydescribe \na simple con.ictdetection algorithm that ensures our DRF and Soundness properties, but only with respect \ntothe compiled version of aprogram.Theirdetectionis not suf.cienttoguaranteeSCinterms ofthe originalprogram,because \nitignores the effects ofpossible compiler reorderings[12,16].We extend their approach with a notion of \nregions to safely allow such compiler reorderings while stilldetecting allSC violations. In concurrent \nwork to ours, Lucia et al. [26] have also pro\u00adposed a hardware exception mechanism to simplify memory \ncon\u00adsistency models for programming languages. Lucia et al. ensure a stronger property than SC, namely \natomicity of synchronization\u00adfree regions, which are maximal regions of code delimitedby syn\u00adchronization \noperations. This property can be quite useful for un\u00adderstanding and debugging concurrent programs. However, \nit in\u00adtroduces additional complexity for con.ict detection as they have to deal with unbounded regions. \nAlso, con.icts must be caught as soon as they occur to prevent non-SC state being exposed to sys\u00adtem \ncalls.Finally,likeDRFx,they toohave to avoidfalse con.icts. Performing precise and eager con.ict detection \nat byte granular\u00adity for unbounded-size regions is arguably more complex than our lazycon.ictdetection \nwithbounded regions.We achieve ef.ciency in spite of smaller bounded regions by distinguishing soft fences \nfromhardfences andallowingthehardware to optimize across soft fences. 6.3 Data-RaceFreedombyConstruction \nRatherthan signalinga run-time memory model exception,thelim\u00aditations of the DRF0 model could be resolved \nby preventing racy programs from being written in the .rst place. Several static type systemshavebeenproposedforthispurpose(e.g.,[8,9,15]).While \ntype systemsprovide a usefuldiscipline onprogrammers to ensure race-freedom, they typically only account \nfor lock-based synchro\u00adnizationand will rejectrace-freeprogramsthatuseother synchro\u00adnization mechanisms. \nFurther, many correctprograms that employ locks will be conservatively rejected due to imprecise information \nabout pointer aliasing. More precision in static race detection can be achieved throughinterprocedural \nanalysis[31],but such whole\u00adprogram analyses tend tobeheavyweight.  6.4 TransactionalMemorySystems Hammond \net al.[18]proposed a memory consistency modelbased onatransactionalprogramming model[19].Intheirapproach,the \nprogrammer andcompiler cooperate to ensure that eachinstruction is part of some transaction. The hardware \nthen ensures that each transaction executes atomically, whichin turnguarantees SC.This approach is applicable \nforprograms written using explicit transac\u00adtions, whereas DRFx is usefulforprograms written usinglocks \nand other traditionalforms of synchronization. Our hardware con.ict detection algorithm is similar to \nthe one proposedby Hammond et al.[18] butissimpli.edin afew ways. First,transactions require additionalruntime \nsupportfor versioning and rollback, which adds overhead and is dif.cult across system events such asI/O.Second,becauseprogrammersde.ne \ntheir own transactions, the system cannot bound their size, whereas regions in DRFx are constructedby \nthe compiler and so are easilybounded. However,transactionalmemory systems canincurfalse con.icts at \nthe expense of extra overhead, while con.ictdetectionin the DRFx model must be precise, which adds some \nextra complexity in the hardware. 7. Conclusion We have proposed the DRFx memory model for concurrent \npro\u00adgramming languages. Like prior data-race-free memory models, DRFx guaranteesthat all executions of \narace-freeprogramwillbe sequentially consistent.However, whiledata-race-free models typ\u00adicallygive no \nor weakerguarantees for racyprograms, DRFx guar\u00adanteesthatthe execution of a racyprogram willalsobe sequentially \nconsistent as long as a memory model exception is not thrown. In this way, DRFx guarantees safety, allows \ncompiler writersto ensure correctness oftheir optimizations, and also enablesprogrammersto easily reason \nabout all programs usingtheintuitiveSC semantics. We described an approach to ensuring the DRFx properties \nthrough a novel form of cooperation between the compiler and the hardware. The compiler partitions a \nprogram into regions and can only optimize within a region. By communicating these regions to the hardware \n(via fences), we can ensure that both compiler optimizations and hardware reorderings preserve SC for \nrace-free programs.Weformalizeda set of requirements onthe compiler and the hardware and proved that \nthey are suf.cient to obey the DRFx model.We also described a concrete instantiation of the approach, \nwhereby the compiler creates bounded-size regions and employs a form of soft fences to allow the hardware \nmore .exibility for performingits optimizations. Acknowledgments We thank the anonymous reviewers for \ncomments that improved this paper. This work is supported by the National Science Foun\u00addation under awards \nCNS-0725354, CNS-0905149, and CCF\u00ad0916770 as well as by the Defense Advanced Research Projects Agency \nunder awardHR0011-09-1-0037. References [1] S. V. Adve and M. D. Hill. Weak ordering a new de.nition. \nIn Proceedings ofISCA,pages2 14.ACM,1990.  [2] S. V. Adve, M. D. Hill, B. P. Miller, and R. H. B. Netzer. \nDetecting data races on weak memory systems. In ISCA,pages234 243,1991. [3] W. Ahn, S. Qi, J.-W. Lee, \nM. Nicolaides, X. Fang, J. Torrellas, D. Wong, and S. Midkiff. Bulkcompiler: High-performance sequen\u00adtial \nconsistency through cooperative compiler and hardware support. In 42ndInternationalSymposium onMicroarchitecture, \n2009. [4] C. Bienia, S. Kumar, J. P. Singh, and K. Li. The parsec benchmark suite: Characterization and \narchitectural implications. In Proceedings of the 17th International Conference on Parallel Architectures \nand Compilation Techniques, October 2008. [5] C. Blundell, M. Martin, and T. Wenisch. Invisifence: performance\u00adtransparent \nmemory ordering in conventional multiprocessors. In ISCA,2009. [6] H.J.Boehm. Simplethread semantics \nrequire racedetection. In FIT session atPLDI,2009. [7] H. J. Boehm and S. Adve. Foundations of the c++ \nconcurrency memory model. In Proceedings ofPLDI,pages68 78.ACM,2008. [8] C.Boyapati andM.Rinard.Aparameterized \ntypesystemforrace-free Javaprograms. InProceedings ofOOPSLA,pages56 69.ACMPress, 2001. [9] C. Boyapati, \nR. Lee, and M. Rinard. Ownership types for safe pro\u00adgramming: Preventing data races and deadlocks. In \nProceedings of OOPSLA,2002. [10] P.Cenciarelli,A.Knapp,andE.Sibilio. Thejavamemory model: Operationally, \ndenotationally, axiomatically. In ESOP, pages 331 346,2007. [11] L. Ceze, J. Tuck, P. Montesinos, and \nJ. Torrellas. Bulksc: bulk en\u00adforcement of sequential consistency. InISCA,pages278 289,2007. [12] L. \nCeze, J. Devietti, B. Lucia, and S. Qadeer. The case for system supportforconcurrency exceptions. In \nUSENIXHotPar,2009. [13] D. Dice, Y. Lev, M. Moir, and D. Nussbaum. Early experience with a commercial \nhardware transactional memory implementation. In Proceedings of ASPLOS,2009. [14] C. Flanagan and S. \nFreund. FastTrack: ef.cient and precise dynamic racedetection. In Proceedings of PLDI,2009. [15] C.Flanagan \nandS.N.Freund. Type-based racedetectionforJava. In Proceedings of PLDI,pages219 232,2000. [16] K. Gharachorloo \nand P. Gibbons. Detecting violations of sequential consistency. In Proceedings of the third annual ACM \nsymposium on Parallel algorithms and architectures, pages 316 326. ACM New York,NY,USA,1991. [17] K. \nGharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. Memory consistency and event \nordering in scalable shared-memory multiprocessors. In Proceedings of ISCA, pages 15 26,1990. [18] L. \nHammond, V. Wong, M. K. Chen, B. D. Carlstrom, J. D. Davis, B.Hertzberg,M.K.Prabhu,H.Wijaya,C.Kozyrakis, \nandK.Oluko\u00adtun. Transactional memory coherence and consistency. In ISCA,pages 102 113,2004. [19] M. Herlihy \nand J. E. B. Moss. Transactional memory: architectural support for lock-free data structures. In Proceedings \nof ISCA, pages 289 300.ACM,1993. [20] A.Kamil,J.Su,andK.Yelick.Making sequential consistencypracti\u00adcalinTitanium. \nIn Proceedings of the2005ACM/IEEE conference on Supercomputing,page15.IEEEComputerSociety,2005. [21] \nA. Krishnamurthy and K. Yelick. Analyses and optimizations for shared address space programs. Journal \nof Parallel and Distributed Computing,38(2):130 144, 1996. [22] L. Lamport. Time, clocks, and the ordering \nof events in a distributed system. Communications of theACM,21(7):558 565, 1978. [23] L. Lamport. How \nto make a multiprocessor computer that correctly executes multiprocess programs. IEEE transactions on \ncomputers, 100(28):690 691, 1979. [24] C. Lattner and V. Adve. LLVM: A compilation framework for life\u00adlong \nprogram analysis &#38; transformation. In Proceedings of the inter\u00adnational symposium on Code generation \nand optimization: feedback\u00addirected and runtime optimization. IEEEComputerSociety,2004. [25] B.Liblit,A.Aiken, \nandK.Yelick. Typesystemsfordistributeddata sharing. In Proceedings of the Tenth International Static \nAnalysis Symposium,2003. [26] B. Lucia, L. Ceze, K. Strauss, S. Qadeer, and H. Boehm. Con.ict exceptions:Providing \nsimpleparallellanguage semantics withprecise hardware exceptions. In 37th Annual International Symposium \non Computer Architecture,June2010. [27] C.K.Luk,R.Cohn,R.Muth,H.Patil,A.Klauser,G.Lowney,S.Wal\u00adlace, \nV. J. Reddi, and K. Hazelwood. Pin: Building customized pro\u00adgram analysis tools with dynamic instrumentation. \nIn Programming LanguageDesign andImplementation, Chicago,IL,June2005. [28] J. Manson, W. Pugh, and S. \nAdve. The java memory model. In Proceedings ofPOPL,pages378 391.ACM,2005. [29] D. Marino, A. Singh, T. \nMillstein, M. Musuvathi, and S. Narayanasamy. DRFx: A simple and ef.cient memory model for concurrent \nprogramming languages. Technical Re\u00adport090021,UCLAComputerScienceDepartment,Nov.2009. URL http://fmdb.cs.ucla.edu/Treports/090021.pdf. \n [30] A. Muzahid, D. Suarez, S. Qi, and J. Torrellas. Sigrace: signature\u00adbaseddata racedetection. In \nISCA,2009. [31] P.Pratikakis,J.S.Foster,andM.Hicks.Locksmith: context-sensitive correlation analysisforracedetection.In \nProceedings ofPLDI,pages 320 331,2006. [32] M.Prvulovic andJ.Torrelas.Reenact:Using thread-level speculation \nmechanisms to debug data races in multithreaded codes. In Proceed\u00adings ofISCA,SanDiego,CA,June2003. [33] \nP.Ranganathan,V.Pai,andS.Adve.Using speculative retirement and larger instruction windows to narrow the \nperformance gap between memory consistency models. In Proceedings of the ninth annualACM symposium on \nParallel algorithms and architectures, pages 199 210, 1997. [34] S.Sethumadhavan,R.Desikan,D.Burger,C.Moore, \nandS.Keckler. Scalable hardware memory disambiguation for high ILP processors. In Proceedings of the \n36th annual IEEE/ACM International Sympo\u00adsium onMicroarchitecture. IEEEComputer Society,2003. [35] J.Sevc\u00b4ik \nandD.Aspinall. On validity ofprogramtransformationsin thejava memory model. In ECOOP,pages27 51,2008. \n[36] D. Shasha and M. Snir. Ef.cient and correct execution of parallel programs that share memory. ACM \nTransactions on Programming Languages andSystems(TOPLAS),10(2):282 312, 1988. [37] Z. Sura, X. Fang, \nC. Wong, S. Midkiff, J. Lee, and D. Padua. Com\u00adpiler techniquesforhighperformance sequentially consistentjavapro\u00adgrams. \nIn Proceedings of the tenth ACM SIGPLAN symposium on Principles andpractice ofparallelprogramming,pages2 \n13,2005. [38] W. Triebel, J. Bissell, and R. Booth. Programming Itanium-based Systems. Intel Press,2001. \n    \n\t\t\t", "proc_id": "1806596", "abstract": "<p>The most intuitive memory model for shared-memory multithreaded programming is <i>sequential consistency</i>(SC), but it disallows the use of many compiler and hardware optimizations thereby impacting performance. Data-race-free (DRF) models, such as the proposed C++0x memory model, guarantee SC execution for datarace-free programs. But these models provide no guarantee at all for racy programs, compromising the safety and debuggability of such programs. To address the safety issue, the Java memory model, which is also based on the DRF model, provides a weak semantics for racy executions. However, this semantics is subtle and complex, making it difficult for programmers to reason about their programs and for compiler writers to ensure the correctness of compiler optimizations.</p> <p>We present the DRFx memory model, which is simple for programmers to understand and use while still supporting many common optimizations. We introduce a <i>memory model (MM) exception</i> which can be signaled to halt execution. If a program executes without throwing this exception, then DRFx guarantees that the execution is SC. If a program throws an MM exception during an execution, then DRFx guarantees that the program has a data race. We observe that SC violations can be detected in hardware through a lightweight form of conflict detection. Furthermore, our model safely allows aggressive compiler and hardware optimizations within compiler-designated program regions. We formalize our memory model, prove several properties about this model, describe a compiler and hardware design suitable for DRFx, and evaluate the performance overhead due to our compiler and hardware requirements.</p>", "authors": [{"name": "Daniel Marino", "author_profile_id": "81410595225", "affiliation": "University of California, Los Angeles, Los Angeles, CA, USA", "person_id": "P2184583", "email_address": "", "orcid_id": ""}, {"name": "Abhayendra Singh", "author_profile_id": "81464655647", "affiliation": "University of Michigan, Ann Arbor, Ann Arbor, MI, USA", "person_id": "P2184584", "email_address": "", "orcid_id": ""}, {"name": "Todd Millstein", "author_profile_id": "81100018064", "affiliation": "University of California, Los Angeles, Los Angeles, CA, USA", "person_id": "P2184585", "email_address": "", "orcid_id": ""}, {"name": "Madanlal Musuvathi", "author_profile_id": "81100333862", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P2184586", "email_address": "", "orcid_id": ""}, {"name": "Satish Narayanasamy", "author_profile_id": "81100556410", "affiliation": "University of Michigan, Ann Arbor, Ann Arbor, MI, USA", "person_id": "P2184587", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806636", "year": "2010", "article_id": "1806636", "conference": "PLDI", "title": "DRFX: a simple and efficient memory model for concurrent programming languages", "url": "http://dl.acm.org/citation.cfm?id=1806636"}