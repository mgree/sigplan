{"article_publication_date": "06-05-2010", "fulltext": "\n Adversarial Memory for Detecting Destructive Races Cormac Flanagan Stephen N. Freund Computer Science \nDepartment Computer Science Department University of California at Santa Cruz Williams College Santa \nCruz, CA 95064 Williamstown, MA 01267 Abstract Multithreaded programs are notoriously prone to race conditions, \na problem exacerbated by the widespread adoption of multi-core processors with complex memory models \nand cache coherence pro\u00adtocols. Much prior work has focused on static and dynamic analy\u00adses for race \ndetection, but these algorithms typically are unable to distinguish destructive races that cause erroneous \nbehavior from benign races that do not. Performing this classi.cation manually is dif.cult, time consuming, \nand error prone. This paper presents a new dynamic analysis technique that uses adversarial memory to \nclassify race conditions as destructive or benign on systems with relaxed memory models. Unlike a typi\u00adcal \nlanguage implementation, which may only infrequently exhibit non-sequentially consistent behavior, our \nadversarial memory im\u00adplementation exploits the full freedom of the memory model to re\u00adturn older, unexpected, \nor stale values for memory reads whenever possible, in an attempt to crash the target program (that is, \nto force the program to behave erroneously). A crashing execution provides concrete evidence of a destructive \nbug, and this bug can be strongly correlated with a speci.c race condition in the target program. Experimental \nresults with our JUMBLE prototype for Java demonstrate that adversarial memory is highly effective at \nidenti\u00adfying destructive race conditions, and in distinguishing them from race conditions that are real \nbut benign. Adversarial memory can also reveal destructive races that would not be detected by tradi\u00adtional \ntesting (even after thousands of runs) or by model checkers that assume sequential consistency. Categories \nand Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation reliability; D.2.5 \n[Software Engineering]: Testing and Debugging monitors, testing tools; F.3.1 [Logics and Meanings of \nPrograms]: Specifying and Veri\u00adfying and Reasoning about Programs General Terms Languages, Algorithms, \nVeri.cation Keywords Race conditions, concurrency, dynamic analysis, re\u00adlaxed memory models 1. Introduction \nMultithreaded software systems are notoriously prone to race con\u00additions, which occur when two threads \naccess the same memory lo\u00adcation at the same time without synchronization, and at least one of Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 10, June 5 \n10, 2010, Toronto, Ontario, Canada. Copyright c &#38;#169; 2010 ACM 978-1-4503-0019-3/10/06. . . $10.00 \nthese accesses is a write. Race conditions are particularly problem\u00adatic because they often cause errors \nonly on certain rare executions, which makes them dif.cult to detect, reproduce, and eliminate. The widespread \nadoption of multi-core processors signi.cantly exacer\u00adbates these problems, both by increasing the degree \nof thread inter\u00adleaving and by making memory model and cache coherence issues much more prevalent. In \nparticular, relaxed memory models cause programs with intentional race conditions to behave in ways that \neven experienced programmers .nd subtle, complex, and counter\u00adintuitive. The insidious nature of race \nconditions has motivated much prior work on race detection analyses, both static [1, 4, 5, 8, 16, 20, \n28, 38, 43] and dynamic [14, 15, 30, 33, 35, 41, 45], as well as via post-mortem analysis [3, 13, 34]. \nWhile many of these race detectors are effective at locating potential races, they tend to report a large \nnumber of warnings. A substantial .rst task for a programmer using these tools is to manually classify \nthe reported potential race conditions into the following categories: False alarms that are caused by \nanalysis imprecisions.  Benign races that exist but do not cause erroneous behavior.  Destructive races \nthat can cause erroneous behavior and should be .xed.  In practice, large software applications typically \ninclude a num\u00adber of intentional and hopefully benign race conditions to mitigate performance concerns. \nWhile precise race detectors (e.g., [14, 17]) facilitate race classi.cation by guaranteeing that they \nnever pro\u00adduce false alarms, they still fail to distinguish between benign and destructive race conditions. \nCorrect classi.cation is critical, since attempts to .x benign races may introduce additional real bugs \n(such as deadlocks) or per\u00adformance bottlenecks (due to unnecessary synchronization). More\u00adover, warnings \nof destructive races could be ignored by the pro\u00adgrammer on the mistaken assumption that the races are \nbenign or that the memory model ensures sequentially consistent behavior. Classi.cation by hand is also \nquite dif.cult and time consuming and requires a deep understanding of the target code base. Overall, \ntherefore, this classi.cation problem signi.cantly limits the usabil\u00adity and utility of race detection \nalgorithms. Adversarial Execution. This paper presents a dynamic analysis technique that facilitates \nprecisely identifying destructive race con\u00additions. We .rst use a standard precise race detector to identify \npro\u00adgram variables that have (benign or destructive) race conditions. For each racy variable, we then \nattempt to generate an execu\u00adtion in which that race condition causes the program to behave incorrectly. \nAn erroneous execution is one that exhibits incorrect observable behavior, such as a crash, an uncaught \nexception, incor\u00adrect output, divergence, etc. If this approach generates an erroneous execution, then \nwe can guarantee that the target program is buggy Figure 1. Racy initialization. Initially x == null. \n Thread 1 Thread 2 x = new Circle(); if (x != null) { x.draw(); } and we have strong evidence for classifying \nthat race condition as destructive. This approach of adversarial execution provides two bene.ts: it only \nwarns the programmer about real errors in the soft\u00adware (that is, no false alarms); and it provides a \nconcrete execution as a witness to that error. 1.1 Memory Models The essence of our approach to adversarial \nexecution is to exploit the full range of possible behaviors permitted by the relaxed mem\u00adory models \nfound in most current architectures. In general, a mem\u00adory model speci.es what values may be returned \nfor each read op\u00aderation in a trace. The sequentially consistent memory model (SCMM) [22] re\u00adquires each \nread from an address to return the value of the most recent write by any thread to that address. Although \nsequential con\u00adsistency is an intuitive memory model, it signi.cantly limits the optimizations used by \nthe compiler, virtual machine, or hardware. Relaxed memory models [2, 19], such as the Java Memory Model \n(JMM) [25] or x86-TSO [31], admit additional optimizations by imposing fewer constraints on the value \nreturned from read op\u00aderations. For data-race-free programs, each read returns the same value as under \nSCMM. For programs with (intentional or uninten\u00adtional) races, however, a read operation could return \nmultiple val\u00adues, as illustrated by the following two examples. Racy Initialization Example. In this \nprogram, Thread 1 initial\u00adizes x while Thread 2 checks x!=null and then calls x.draw(). Both reads of \nx by Thread 2 are in a race with the write by Thread 1. Nevertheless,under SCMM,allinterleavingsofthisprogrambehave \ncorrectly, since once x is initialized as non-null it stays non-null. Under the Java relaxed memory model, \nhowever, each read of x could independently read either null or an initialized reference. Hence the check \nx!=null could succeed (by reading the initialized value) after which the call x.draw() could read null \nand fail with a NullPointerException.1 Double-Checked Locking Example. As a more interesting exam\u00adple, \nconsider the Java program in Figure 2. The class Point con\u00adtains a static .eld p referring to a singleton \nPoint object. This static .eld is initialized lazily on the .rst call to get(), via a double\u00adchecked \ninitialization pattern. Prior precise race detectors such as FASTTRACK [17] and DJIT+ [33] can identify \nrace conditions on three .elds (p, p.x, and p.y), but they do not identify which of these race conditions \nare destructive. We .rst consider the race condition on p. Line 8 reads p into a local variable t, so \nthe return value of get() is never null. Reading stale null values at line 8 only causes extra executions \nof the synchronized block, so the race on p is not destructive. We next consider the race between the \nwrite of x at line 5 and the read at line 17. These accesses never overlap because of the initialization \nlogic in get(). Nevertheless, a thread calling get() could return the initialized value of p without \nsynchronization, meaning that there is no happens-before edge between a different thread s initialization \nof x and that thread s read of x. Hence, the read at line 17 could return the default initial value of \nzero for 1 Note that speci.c JVM implementations may not exhibit all behaviors permissible by the Java \nMemory Model, and so a speci.c JVM on speci.c hardware might never reorder reads in a way that exposes \nthis bug. Figure 2. Double-checked locking. 1 class Point { 2 double x, y; 3 static Point p; 4 5 Point() \n{ x = 1.0; y = 1.0; } 6 7 static Point get() { 8 Point t = p; 9 if (t != null) return t; 10 synchronized \n(Point.class) { 11 if (p==null) p = new Point(); 12 return p; 13 } 14 } 15 16 static double slope() { \n17 return get().y / get().x; 18 } 19 20 public static void main(String[] args) { 21 fork { System.out.println( \nslope() ); } 22 fork { System.out.println( slope() ); } 23 } 24 } x, causing an immediate DivisionByZeroException \nat line 17. Thus, the race on x is destructive. Similarly, the read of y at line 17 could also return \na stale zero value, causing incorrect printouts. Therefore, this race is also destructive.  1.2 Adversarial \nMemory A key dif.culty in detecting destructive race conditions like those above via testing alone is \nthat the memory system is likely to exhibit sequentially-consistent behavior most of the time. Unex\u00adpected \nvalues will be read from memory only in certain unlucky circumstances (such as when two con.icting accesses \nare sched\u00aduled closely together on cores without a shared cache, or when two object are allocated at \naddresses that cause cache con.icts). Thus, even though the memory system is always allowed to exhibit \ncounter-intuitive relaxed behavior, the fact that it behaves nicely most of the time makes testing problematic. \nTo overcome this limitation, we have developed an adversarial memory system, JUMBLE, that continually \nexploits the full .exibil\u00adity of the relaxed memory model to try to crash the target applica\u00adtion.2 Essentially, \nJUMBLE stress-tests racy programs by returning older (but still legal) values for read operations whenever \npossi\u00adble. To determine which values are legal under the memory model, JUMBLE monitors memory and synchronization \noperations of the target program and keeps a write buffer recording the history of write operations to \neach racy shared variable. For each read oper\u00adation, JUMBLE computes the set of visible values in that \nvariable s write buffer that can be legally returned according to the memory model. This visible set \nalways contains at least the value of the last write to that variable, but may also contain older values. \nJUMBLE attempts to heuristically pick an element likely to trigger a program crash and thus provide evidence \nof a destructive race condition. To provide a formal foundation for our approach, we .rst de\u00advelop an \noperational speci.cation for a subset of the Java Memory Model. This operational speci.cation expresses \nthe inherent non\u00addeterminism of the memory model in terms of familiar data struc\u00ad 2 JUMBLE targets Java \nprograms, but adversarial memory can be used in any system with a relaxed memory model.  tures such \nas vector clocks and write buffers. The JUMBLE adver\u00adsarial memory implementation then rei.es this non-deterministic \noperational speci.cation using heuristics to choose read values that expose destructive races. Fairness. \nJUMBLE uses a variety of heuristics to choose which visible value to return for each read operation of \nthe target pro\u00adgram. Our simplest heuristic returns the oldest or most stale vis\u00adible value for each \nread. Interestingly, this heuristic violates fair\u00adness properties typically assumed by applications. \nFor example, consider the following busy-waiting loop, which contains an in\u00adtentional race on the non-volatile \nboolean variable done. while (!done) { yield(); } Even after a concurrent thread sets done to true via \na racy write, our oldest heuristic continued to return the original (and still visible) false value for \ndone, resulting in an in.nite loop. There is some tension between memory model fairness (which helps \napplications behave correctly) and adversarial memory (which tries to crash applications). Although JMM \ndoes not mandate a par\u00adticular notion of fairness, our implementation guarantees that any unbounded sequence \nof reads to a particular variable will some\u00adtimes return the most recently-written value. This fairness \nguaran\u00adtee proved suf.cient on all our experiments. Experimental Results. Experimental results on a range \nof mul\u00adtithreaded benchmarks show that adversarial memory, although a straightforward concept, is highly \neffective at exposing destructive races. Each destructive race typically causes incorrect behavior on \nbetween 25% and 100% of test runs, as compared to essentially 0% under normal testing. For the example \nprogram of Figure 1, JUM-BLE reveals this destructive race on roughly every other run, while traditional \ntesting failed to reveal this bug after 10,000 runs. Much prior work (see, for example, [27, 29, 36, \n40]) developed tools that explore multiple interleavings of multithreaded programs, in an attempt to \nidentify defects, including destructive races. Inter\u00adestingly, because these tools assume sequentially \nconsistency, they cannot detect destructive race conditions, such as those in Figures 1 and 2 and in \nseveral of our benchmarks, which only appear under relaxed memory assumptions. Conversely, JUMBLE does \nnot ex\u00adplore all interleavings, and so may not detect destructive races that cause problems only under \nsome interleavings. In general, multi\u00adthreaded Java programs are prone to both scheduling nondetermin\u00adism \nand memory-model nondeterminism, and model checkers need to exhaustively explore both sources of nondeterminism \nin order to detect all errors.  1.3 Contributions In summary, this paper: introduces the concept of \nadversarial memory for detecting destructive races;  formalizes an operational speci.cation for a subset \nof the JMM, providing a foundation for our approach (Section 4);  proves that this operational speci.cation \nis sound with respect to its declarative speci.cation (Section 4.2);  describes our adversarial memory \nimplementation and its heuristics for exposing destructive races (Section 5); and  presents experimental \nresults demonstrating that this approach is effective at identifying destructive race conditions, with \nmod\u00adest performance overhead (Section 6).  2. Multithreaded Program Traces To provide a sound basis \nfor our development, we begin by for\u00admalizing multithreaded program traces. A multithreaded program Figure \n3. Multithreaded program traces. a . Trace ::= Operation * a, b . Operation ::= rd(t, x, v) | wr(t, x, \nv) | acq(t, m) | rel(t, m) | fork(t, u) | join(t, u) s, t, u . Tid x, y . Var m . Lock v . Value consists \nof a number of concurrently executing threads, each with a thread identi.er t . Tid. These threads manipulate \nvariables x . Var and locks m . Lock.A trace a captures an execution of a multithreaded program by listing \nthe sequence of operations performed by the various threads in the system. We ignore control operations \n(branches, looping, method calls, etc) and local compu\u00adtations, as they are orthogonal to memory model \nissues. Thus, the set of operations that a thread t can perform are: rd(t, x, v) and wr(t, x, v), which \nread and write a value v from a variable x;  acq(t, m) and rel(t, m), which acquire and release a lock \nm;  fork(t, u), which forks a new thread u; and  join(t, u), which blocks until thread u terminates. \n This set of operations suf.ces for an initial presentation of our anal\u00adysis; our implementation supports \na variety of additional synchro\u00adnization constructs, including wait, notify, volatile variables, etc. \nThe happens-before relation <a for a trace a is the smallest transitively-closed relation over the operations3 \nin a such that the relation a<a b holds whenever a occurs before b in a and one of the following holds: \n [PROGRAM ORDER] Both operations are by the same thread.  [LOCKING ORDER]: a releases a lock that is \nlater acquired by b.  [FORK ORDER]: a is fork(t, u) and b is by thread u.  [JOIN ORDER]: a is by thread \nu and b is join(t, u).  If a happens before b, then we also say that b happens after a. If two operations \nin a trace are not related by the happens-before relation, then they are considered concurrent. Two memory \naccess con.ict if they both access (read or write) the same variable, and at least one of the operations \nis a write. Using this terminology, a trace has a race condition if it has two concurrent con.icting \naccesses. 3. Memory Models A memory model speci.es what values can be returned for each read operation \nin a program trace. A trace a is legal under a memory model if the value v produced by each read operation \nrd(t, x, v) in the trace a is permitted under that memory model. The simplest memory model is sequential \nconsistency: Sequential Consistent Memory Model (SCMM): A read operation a = rd(t, x, v) in a trace a \nmay only return the value of the most recent write to that variable in a. Although sequential consistency \nis intuitive, it limits the optimiza\u00adtions that may be performed by the compiler, the virtual machine, \n3 In theory, a particular operation a could occur multiple times in a trace. We avoid this complication \nby assuming that each operation includes a unique identi.er (often called an issue index [31]), but, \nto avoid clutter, we do not include this unique identi.er in the concrete syntax of operations.  Figure \n4. A trace with a read-then-write race on x. The assertion can fail under JMM and HBMM but not under \nPJMM. Initially x==y ==0. Thread 1 Thread 2 assert (x == 0); y= 1; while(y== 0) {}; x = 1; or by the \nhardware itself. The desire for additional optimization op\u00adportunities motivated the introduction of \na variety of relaxed mem\u00adory models, which impose weaker constraints on the values re\u00adturned for read \noperations in the presence of race conditions [2, 19]. The happens-before memory model relaxes the requirements \non which value is returned by a read operation: Happens-Before Memory Model (HBMM): A read oper\u00ad ation \na = rd(t, x, v) in a trace a may return the value v written by any write operation b = wr(u, x, v) provided: \n1. b does not happen after a (i.e., b happens before or is concurrent with a), and 2. there is no intervening \nwrite c to x where b<a c<a a.  Condition (1) is quite permissive, and it allows a read operation to \nlook into the future , as in the following trace where the operation rd(t1, x, 1) reads the value 1 from \nthe write wr(t2, x, 1) that ap\u00adpears later in the trace (but which is considered a concurrent write by \nthe happens-before relation): wr(t1, x, 0).rd(t1, x, 1).wr(t2, x, 1) This permissiveness introduces the \npotential for out-of-thin-air vio\u00adlations, as described in the Java Memory Model Speci.cation [25]. We \nbrie.y illustrate this problem via the following program in which each thread copies one variable into \nanother: x := y || y := x Even if x and y are zero-initialized, this program can generate the following \ntrace under HBMM for any value of v, since the .rst read reads the second write, etc. rd(t1, x, v).wr(t1, \ny, v).rd(t2, y, v).wr(t2, x, v) Out-of-thin-air violations are problematic for garbage-collected languages \n(since the out of thin air value v could be an invalid pointer) and they introduce potential security \nloopholes. To avoid out-of-thin-air violations, the Java Memory Model [25] (JMM) ex\u00adtends the happens-before \nmemory model with a complex causality requirement, essentially precluding nonsensical traces such as \nthe one shown above. In our setting, this causality requirement is un\u00adnecessary because our dynamic online \nanalysis is unable to look into the future . Thus, in the following section we formalize our analysis \nfor a restriction of the JMM, called the Progressive Java Memory Model, that removes this ability. 4. \nThe Progressive Java Memory Model The Progressive Java Memory Model is a slight restriction of the Happens-Before \nMemory Model that removes the ability for a read operation to see a write operation that has not happened \nyet. Progressive Java Memory Model (PJMM): A read opera\u00ad tion a = rd(t, x, v) in trace a may return the \nvalue v writ\u00ad ten by any write operation b = wr(u, x, v) provided that 1. b executes before a in the \ntrace a; and Figure 5. An illustration of four memory models and two memory implementations, including \na typical JVM. 2. there is no intervening write c to x where b<a c<a a. Here, condition 1 permits only \nreading past writes, and is more restrictive than HBMM for traces involving read-then-write race conditions,whereareadisinaracewithalaterwrite.Under \nHBMM and JMM, the read can see the later write; under PJMM, it can not. Figure 4 illustrates such a trace \nwith a read-then-write race on x, where the assertion of Thread 1 can read a future value for x and thus \nfail under HBMM and JMM, but the assertion cannot fail under PJMM. Excluding such traces from PJMM greatly \nsimpli.es our JUMBLE implementation, without in practice signi.cantly limiting its ability to expose \ndestructive races. We illustrate the relationship between these four memory mod\u00adels discussed so far \n(HBMM, JMM, PJMM, and SCMM) via the Venn diagram of Figure 5. The more .exible memory models permit a \ngreater set of program behaviors than the more restrictive. This di\u00adagram also roughly sketches the memory \nmodel behaviors exposed by two implementations: a typical Java Virtual Machine (JVM) im\u00adplementation, \nand by our adversarial memory implementation. A typical JVM running on commodity hardware exposes behaviors \nthat are not sequentially consistent relatively infrequently, because, for example, those platforms do \nnot perform all optimizations per\u00admissible under the JMM. In contrast, JUMBLE explores a larger (and \nmore adversarial ) fraction of the behavior permitted by the JMM, thereby exposing more destructive races. \n 4.1 An Operational Speci.cation of the PJMM To guide our implementation of an adversarial memory system, \nwe now present an operational formulation of the PJMM, called the Operational PJMM.4 In particular, whereas \nthe above PJMM de.\u00adnition is expressed in terms of a mathematical characterization of the happens-before \nrelation, the Operational PJMM is expressed in terms of data structures analogous to those used in our \nimplemen\u00adtation: vector clocks that represent the happens-before relation and write buffers that record \nthe history of writes to each variable. A vector clock K : Tid . Nat records a clock for each thread \nin the system [26]. Vector clocks are partially-ordered (.) in a point-wise manner, with an associated \njoin operation (U) and minimal element (.). The helper function inct increments the t\u00ad 4 The Operational \nPJMM is motivated by similar goals as [7], but is less complex as we only provide a semantics for traces, \nnot programs.  component of a vector clock: K1 K2 iff .t. K1(t) = K2(t) def K1 U K2 = .t. max(K1(t), \nK2(t)) def . = .t. 0 def inct(K )= .u. if u = t then K (u)+1 else K (u) We express the Operational PJMM \nas an online analysis that maintains a memory state s. This memory state is updated by each operation \na in the observed trace via the relation: s .a s' This relational formulation naturally supports non-deterministic \nreads: for a read of x by thread t from s, it may be possible to s and s .rd(t,x,v2) conclude both s \n.rd(t,x,v1) s, indicating that the read may return either v1 or v2. (Note that read operations do not \naffect the memory state s.) Memory State. A memory state s is a tuple (C, L, W ), where: C : Tid . K \nidenti.es the current vector clock of each thread t. Initially, each thread t starts with the vector \nclock C(t)= inct(.), indicating that this thread has performed one clock tick.  L : Lock . K is the \nvector clock of the last release of each lock. Each lock L(m) is initially ., indicating that the lock \nwas never acquired.  W : Var . WriteBu.er contains a non-empty write buffer for each variable in the \nprogram. A WriteBuffer = (Value@K )+ records the sequence of values written to that variable together \nwith a vector clock timestamp for each write. Initially, each write buffer W (x) contains a single entry \n0@., re.ecting that memory is zero-initialized before execution.  Thus, the initial memory state is: \ndef s0 =(.t.inct(.), .m.., .x.(0@.)) Transition Rules. Figure 6 describes how the Operational PJMM handles \neach operation of the observed trace. [ACQUIRE]: The rule for acq(t, m) updates the vector clock Ct to \nre.ect that subsequent operations of thread t happen after the last release of lock m, which happened \nat time Lm. Here, C is a function, Ct abbreviates the function application C(t), and C[t := b] denotes \nthe function that is identical to C except that it maps t to b. [RELEASE]: The rule for rel(t, m) updates \nLm with the current vector clock Ct of thread t, and then increments the t-component of Ct, so that the \nvector clocks can distinguish operations by thread t that happen before and after that release operation. \n[FORK]: The rule for fork(t, u) updates Cu to be after Ct (re.ect\u00ading that the .rst operation of the \nforked thread u happens after this fork operation) and increments the t-component of Ct. [JOIN]: The \nrule for join(t, u) updates Ct to be after Cu (re.ecting that this join operation of thread t happens \nafter the last operation of the joined thread u). As a technical device to simplify proof invariants, \nthis rule also increments the u-component of Cu. [WRITE]: The rule for wr(t, x, v) extends the write \nbuffer Wx with an entry v@Ct recording that the value v was written at time Ct. [READ]: The rule for \nrd(t, x, vi) non-deterministically picks some value vi from the current write buffer, which in general \nhas the form: Wx = v1@K1 \u00b7 v2@K2 \u00b7 ... \u00b7 vn@Kn Figure 6. The Operational Progressive Java Memory Model. \nC' = C[t := (Ct U Lm)] [ACQUIRE] (C, L, W ) .acq(t,m) (C', L, W ) L' C' = L[m := Ct]= C[t := inct(Ct)] \n[RELEASE] (C, L, W ) .rel(t,m) (C',L',W ) C' = C[u := Cu U Ct,t := inct(Ct)] [FORK] (C, L, W ) .fork(t,u) \n(C', L, W ) C' = C[t := Ct U Cu,u := incu(Cu)] [JOIN] (C, L, W ) .join(t,u) (C', L, W ) W ' = W [x := \nWx \u00b7 v@Ct] [WRITE] (C, L, W ) .wr(t,x,v) (C, L, W ') Wx =(vj @Kj )j.1..n i . 1..n .j . i +1..n. \u00ac(Ki \nKj Ct) [READ] (C, L, W ) .rd(t,x,vi) (C, L, W ) Wx =(vj @Kj )j.1..n i . 1..n .t . Tid. .j . i +1..n. \nKi Kj Ct \u00b7 (vj @Kj )j.i+1..n W ' = W [x := (vj @Kj )j.1..i-1 ] [GC1] (C, L, W ) .0 (C, L, W ') Wx =(vj \n@Kj )j.1..n vi = vm Ki = Km 1 = i<m = n \u00b7 (vj @Kj )j.i+1..n W ' = W [x := (vj @Kj )j.1..i-1 ] [GC2] (C, \nL, W ) .0 (C, L, W ') Wx =(vj @Kj )j.1..n n> 1 W ' = W [x := (vj @Kj )j.2..n] [REMOVE OLDEST] (C, L, \nW ) .0 (C, L, W ') To yield a legal PJMM trace, that rule ensures there is no subse\u00adquent write vj @Kj \nin the buffer at position j . i +1..n that 1. happens after the write of vi (so Ki Kj ) and 2. that \nhappens before this read operation (so Kj Ct).  If there is no such j, then this read operation can \nlegally return the value vi. Note that [READ] always permits the most recent value vn to be returned, \nand possibly older writes as well. If there are multiple en\u00adtries in the write buffer that satisfy the \nrequirements of the [READ] rule, then we say that the read operation has an sequential consis\u00adtency violation, \nsince it could return values that are not permitted under the SCMM. As an example, entries i and m in \nthe write buffer ... \u00b7 vi@Ki \u00b7 ... \u00b7 vm@Km \u00b7 ... could both be read provided that either (1) the second \nwrite is in a race with the .rst write (Ki .Km) or (2) the second write is in a race with the read (Km \n.Ct). Thus, even if the read operation is race-free (Ki Ct and Km Ct), it can still produce a sequential \nconsistency violation if the previous write operations are racy (Ki .Km). Conversely, if the trace has \nno race conditions on a particular variable, then all accesses are totally ordered, and so are the vector \nFigure 7. Example execution trace.  clocks K1 K2 \u00b7\u00b7\u00b7 Kn Ct. Hence, any read will return the value vn \nof the most recent write. Example. The example trace in Figure 7 illustrates the key points of the Operational \nPJMM, including the need for ordered write buffers. That .gure includes the relevant parts of the memory \nstate s: the vector clocks C0 and C1 of Thread 0 and Thread 1; the vector lock Lm of the lock m; and \nthe write buffer Wx for the variable x. The .rst write wr(0, x, 13) at time C0 = (4, 0) extends the \nwrite buffer Wx with a second entry 13@(4, 0).  The next write adds a third entry 42@(4, 0). Note that \nthe last two entries in the write buffer now contain identical vector clocks. Nevertheless, the order \nof the write buffer entries still indicates that 42 was written sometime after 13.  The release rel(0,m) \nupdates Lm to (4, 0).  The .rst read rd(1, x, v) then reads x without holding the lock. The [READ] rule \nenables us to determine which of the three entries in Wx are visible to that read at time C1 = (0, 7): \n 42@(4, 0) is visible: it is the last entry in the write buffer. 13@(4, 0) is visible: the later entry \n42@(4, 0) is concurrent with the current clock C1 since (4, 0)(0, 7) = C1. 0@. is also visible: again, \nthe later entries at time (4, 0) are concurrent with the current clock C1. Thus, the read operation rd(1, \nx, v) can return any value in the write buffer (0, 13, or 42) as v, resulting in a sequential consistency \nviolation. The acquire acq(1,m) increases C1 to be at least Lm, re.ect\u00ading the happens-before edge from \nthe release to the acquire.  The second read operation rd(1, x, v ' ) now reads x in a race\u00adfree manner, \nand the [READ] rule again enables us to determine which entries in Wx are visible to that read at time \nC1 = (4, 7):  42@(4, 0) is visible: it is the last entry in the write buffer. 13@(4, 0) is not visible: \nthe later entry 42@(4, 0) now prevents Thread 1 from seeing this value, since (4, 0) (4, 7) = C1. Note \nthat the order of write buffer entries al\u00adlows us to correctly distinguish between these two entries \n(13 and 42) that have the same vector clock. 0@. is not visible: due to the later entries at time (4, \n0). Thus, the second read rd(1, x, v ' ) must return 42, not 13 or 0, and thus does not have a sequential \nconsistency violation. Write Buffer Compression. Our operational memory model in\u00adcludes three additional \nrules to prevent write buffers from becom\u00ading arbitrarily large. [GC1]: This rule discards an entry vi@Ki \nfrom a write buffer Wx = v1@K1 \u00b7 v2@K2 \u00b7 ... \u00b7 vn@Kn provided vi is not visible to any thread. To ensure \nthis invisi\u00adbility property, the rule checks that, for each thread t, there is some intervening write \nvj @Kj such that Ki Kj Ct. In this situation, removing the entry vi@Ki from the write buffer does not \nchange the set of traces accepted from the current state. For the .nal memory state of Figure 7, this \nrule can remove the entries 0@. and 13@(4, 0), since the last write 42@(4, 0) serves an an intervening \nwrite in both cases. [GC2]: This rule identi.es situations where some thread t writes a value v to a \nvariable x twice in a row, with no intervening synchronization operations, yielding a write buffer of \nthe form: Wx = ... \u00b7 v@Ct \u00b7 ... \u00b7 v@Ct \u00b7 ... The .rst occurrence of v@Ct is now redundant. If thread \nt reads from x, the .rst write is hidden due to program order. If a different thread reads from x and \nthe .rst write by t is visible, then the second write by t is also visible. Thus we can remove the earlier \nwrite from the write buffer without changing the set of traces accepted from the current state. [REMOVE \nOLDEST]: The previous two techniques work well in practice most of the time, but races on frequently \nmodi.ed vari\u00adables could still cause buffers to grow quite large. The .nal rule allows the oldest entry \nto be dropped from the write buffer at any point, provided that there is still at least one write remain\u00ading. \nThis rule is sound, in the sense that it will never accept an invalid trace, but it limits the subsequent \nfreedom of our adversar\u00adial memory implementation to return stale values that are likely to cause crashes. \nHence, we apply this rule only when necessary, that is, when write buffers would otherwise grow too large. \nUs\u00ading a maximum buffer size of 32 did not impact the precision of JUMBLE for those programs requiring \nmuch larger buffers to hold the entire visible history.  4.2 Correctness of the Operational PJMM We \nnow address the correctness of the Operational PJMM. Suppose the target program P behaves incorrectly \non a trace a that is legal under the Operational PJMM. Theorem 1 below implies that a is also a legal \nPJMM trace. The PJMM is essentially a restriction of JMM, and follows a similar speci.cation style based \non the happens-before relation, indicating that a is therefore also a legal JMM trace, and so P could \nalso behave incorrectly on a JVM. Before proving Theorem 1, we .rst introduce some additional notation. \nFor any transition s .a s ' , we use Ca , La, and W a to denote the components of s, and we use Caa to \nabbreviate Ca tid(a), which denotes the clock vector of the thread executing a just before that operation \nis executed. We restrict our attention to feasible traces that respect the fol\u00adlowing expected constraints \non forks, joins, and locking operations.  1. There can be no instructions of thread u preceding an instruc\u00adtion \nfork(t, u) or following an instruction join(t, u). 2. No thread can release a lock it did not previously \nacquire. 3. No thread can acquire a lock previously acquired but not re\u00adleased by another thread.  \nTHEOREM 1. If s0 .a s then a is a legal PJMM trace. PROOF A commuting argument [23] can be used to show \nthat the garbage collection rules ([GC1], [GC2], [REMOVE OLDEST]) all right-commute with the other rules. \nHence, applications of the GC rules can be moved to the end of the trace, yielding a trace pre.x \u00df that \ndoes not include any GC rules. We now show that this theorem holds for \u00df. Consider any read a = rd(t, \nx, v) . \u00df in a memory state where the write buffer has the form: W a x = v1@K1 \u00b7\u00b7\u00b7 vi@Ki \u00b7\u00b7\u00b7 vn@Kn The \nrule [READ] implies that v = vi for some i, and that: Ca .j . i +1..n. \u00ac(Ki Kja ) From an inspection \nof the rules, the write buffer entry vi@Ki must have been added to Wx by the rule [WRITE] for some operation \nb = wr(u, x, v) . \u00df, where Ki = Cbb . Now suppose there was an intervening write c = wr(u ' , x, v ' \n) . \u00df with b<\u00df c<\u00df a. By Lemma 1 below, we have that Cbb Ccc Caa. Also, c occurs between b and a in the \ntrace, meaning the entry v ' @Ccc must have been added to the write buffer after b. Thus there exists \nj . i +1..n such that Kj = Ccc. Hence, we have that: Ca Ki Kja , which is a contradiction. Thus, there \nis no intervening write c such that b<\u00df c<a a, and the operation a can thus read the value written by \nb under PJMM. 0 The following lemma clari.es that vector clocks correctly represent the happens-before \nrelation. Previous work proves a similar lemma by induction [17]. LEMMA 1 (Happens-Before implies Vector \nClocks). Suppose s0 .a s and a, b . a are both read or write operations. If a<a b then Caa b . Cb 5. \nAdversarial Memory Implementation The Operational PJMM expresses the inherent non-determinism of the \nmemory model in an operational manner. The JUMBLE adversarial memory implementation resolves this non-determinism \nin a manner designed to expose destructive races. Suppose we have previously identi.ed data races on \na speci.c variable x in our target program. JUMBLE executes that program in a special environment where \nall writes to x are recorded in a write buffer, and all reads from x are adversarial in that JUMBLE attempts \nto pick visible values that are likely to trigger erroneous behavior. If the target program behaves erroneously \nunder such adversarial reads on x, then we characterize that race condition on x as being destructive. \n5.1 Heuristics In more detail, consider a read operation rd(t, x, ) performed in a memory state s =(C, \nL, W ) where the write buffer for x is: Wx = v1@K1 \u00b7 v2@K2 \u00b7 ... \u00b7 vn@Kn By the [READ] rule, the read \noperation can return any value vi in the write buffer that does not have an intervening write vj with \nFigure 8. Racy initialization revisited. Initially x == null. Thread 1 Thread 2 x = new Circle(); for(int \ni=0; i<10; i++) { if (x != null) { x.draw(); } } Ki Kj Ct. Thus, the set Vis of visible values is: def \nVis = {vi | i . 1..n and .j . i +1..n. \u00ac(Ki Kj Ct)} This set always contains the most recent write vn, \nbut possibly additional values as well. We have implemented .ve heuristics for resolving this non-determinism \nin the case where Vis is not the singleton set {vn}. Sequentially-Consistent. This heuristic always \nreturns the most recently written value vn, and provides a baseline with which to compare our more adversarial \nheuristics.  Oldest. This heuristic picks the oldest element of V , based on the intuition that this \nmost stale value is likely to induce bad behav\u00adior. Occasionally, this heuristic returns the most recently \nwritten value vn instead, in order to satisfy fairness properties assumed by busy-waiting loops, as mentioned \nin the introduction.  Oldest-But-Different. Consider the example of Figure 8, in which a for loop encloses \nthe check-then-dereference idiom from Fig\u00adure 1:  if (x != null) { x.draw(); } For this program, the \nOldest heuristic consistently returns the same value for all reads of x, and thus fails to expose this \ndestruc\u00adtive race. In contrast, the Oldest-But-Different heuristic picks the oldest element of Vis that \nis different from the last value read from that variable. Once the write buffer contains the write to \nx from Thread 1, Oldest-But-Different alternately returns null and non-null pointers and detects this \ndestructive race on essentially every execution. (No error was detected on traces in which the initialization \nhappened only after the loop terminated.) Random. Pick a random value from Vis.  Random-But-Different. \nPick a random value from Vis that is different from the last value read for that variable.  Section \n6 presents an experimental comparison of these heuristics.  5.2 JUMBLE Implementation Details Our JUMBLE \nimplementation is based on the ROADRUNNER framework [17, 18]. ROADRUNNER inserts instrumentation code \ninto the target bytecode program at load time that will generate a stream of events for synchronization \noperations, .eld accesses, etc, and JUMBLE processes this event stream as it is generated. Our implementation \nsupports additional synchronization primi\u00adtives not described in our memory model, including wait/notify, \nand volatile variables. Extending a happens-before analysis based on vector clocks to handle these cases \nis straightforward, as de\u00adscribed in [17]. For simplicity, re-entrant lock acquires and releases (which \nare redundant) are .ltered out by ROADRUNNER and are never passed to JUMBLE. JUMBLE is con.gurable to \nrecord write buffers for the memory locations corresponding to any set of syntactic .elds in the source \nprogram. While we could record write buffers for all memory locations used by a program, we have found \nit more useful during our initial experiments to con.gure it to analyze instances of only one syntactic \n.eld (identi.ed earlier by a precise race detector) at a time. If crashes occur only under those conditions, \nthe underlying cause is most likely a destructive race condition on the .eld being jumbled . Tracking \nonly a single syntactic .eld at a time may miss some errors that involve multiple .elds, as described \nin [24, 39], but we leave tracking multiple .elds for future work.  JUMBLE State. JUMBLE associates \nwith each thread in the target program a vector clock represented by an array of 32-bit integers.5 JUMBLE \nalso maintains a write buffer of value/clock-vector pairs for each monitored memory location. When a \nread occurs, JUMBLE uses the reading thread s vector clock to identify which writes are visible, and \napplies one of the previously-described heuristics to choose among them. The JUMBLE implementation limits \nwrite buffers to contain a bounded number of entries, typically 32. Non-Atomic Longs and Doubles. JUMBLE \nfollows the Java memory model speci.cation in treating reads from 8-byte longs and doubles as non-atomic, \nand it implements them as two separate 4-byte reads. That is, when JUMBLE performs a read from a loca\u00adtion \nstoring a 8-byte value, it extracts two distinct, visible writes from that location s write buffer, using \nthe top part of one and the bottom part of the other to construct the value returned to the pro\u00adgram. \nIn this manner, racy reads from 8-byte locations often return corrupted values that are likely to result \nin erroneous executions. Arrays. JUMBLE can also jumble the values returned by array reads. To avoid \nhigh overheads on array intensive programs with huge numbers of array accesses, JUMBLE incorporates a \nsampling technique. We use a precise race detector to identify the array in\u00addices at which data races \noccur. JUMBLE then tracks values associ\u00adated with a small subset of those indices for every array created \nby the target. This approach proved quite effective in practice JUM-BLE induced crashes for our test \nprograms with array races when only jumbling accesses to arrays at index 0 or 1. The overhead was usually \nhigher than when tracking a single syntactic .eld, but still acceptable. 6. Experimental Results We used \nJUMBLE to examine all 10 race conditions detected by the FASTTRACK precise race detector [17] in a variety \nof multi\u00adthreaded benchmarks.6 The programs examined include jbb, the SPEC JBB2000 busi\u00adness object simulator \n[37]; montecarlo, sor, lufact, moldyn, and raytracer from the Java Grande benchmark suite [21]; mtrt, \na multithreaded ray-tracing program from the SPEC JVM98 benchmark suite [37]; and tsp, a Traveling Salesman \nProblem solver [42]. Their sizes, number of threads, and running times are shown in Figure 10. Experiments \nwere performed on an Apple Mac Pro with dual 3GHz quad-core Pentium Xeon processors and 12GB of memory, \nrunning OS X 10.5.8 and Sun s Java HotSpot 64-bit Server VM version 1.6.0. 6.1 Effectiveness of Adversarial \nMemory We compared the behavior of JUMBLE under six different memory implementations: No Jumble (in which \nthe target program is exe\u00adcuted directly by the HotSpot JVM) and the .ve JUMBLE heuris\u00adtics described \nin Section 5. For each of the races and each of the six con.gurations, we ran 100 tests to detect how \noften that race 5 While 32-bit integers were suf.cient for our tests, switching to 64-bits would enable \nJUMBLE to handle larger clocks, but with additional overhead. 6 The reported races on these programs \ndiffer slightly from our earlier published results [17] due to changes in the FASTTRACK implementation, \nincluding improvements in how it creates happens-before edges for calls to Thread.interrupt(). condition \ncaused erroneous behavior. For races on .elds, we jum\u00adbled reads from all instances of that .eld. For \nraces on arrays, we jumbled reads from all arrays at index 0 and 1, as described above. Figure 9 summarizes \nthe results for our benchmark programs, and also for the example programs in Figures 2 and 8. The last \ncolumn of that .gure presents the results of our manual (and time\u00adconsuming) classi.cation of each race \ncondition as benign or de\u00adstructive. We classi.ed a race as destructive only if we could ob\u00adserve deviant \nprogram behavior by doing nothing more than insert\u00ading Thread.sleep() operations to guide the scheduler \nto poten\u00adtially bad interleavings. The No Jumble heuristic exposed none of the destructive races, which \ncon.rms the conventional folklore that race conditions are extremely dif.cult to detect via traditional \ntesting alone. The Sequentially-Consistent heuristic demonstrates that our instru\u00admentation and monitoring \nframework, while invariably impacting thread scheduling, does not in itself expose destructive behaviors. \nThe remaining columns demonstrate that the other JUMBLE heuristics are highly effective at exposing destructive \nrace condi\u00adtions. Seven of the nine race conditions were destructive, and each destructive race condition \nis detected by at least one heuristic with high probability. We again examined program behavior manually \nto identify incorrect behavior. As expected by the correctness arguments of Section 4.2, none of the \nbenign races caused incorrect behavior under any of the con.gurations. We discuss each race condition \nin turn: Programs in Figures 8 and 2: Under JUMBLE, the code in Figure 8 generated a null pointer exception. \nTwo values become visible in the write buffer for x after the initialization in Thread 1 occurs: the \nnew, non-null value, and the original null value. As previously mentioned, the Oldest heuristic fails \nto uncover the error because it always returns the same null value for every access. In contrast, the \nOldest-But-Different heuristic causes the crash with high probability. The random schemes are also effective \nin this case. No crash occurs only on traces in which Thread 1 writes to x only after Thread 2 has .nished. \nSimilarly, the destructive races previously described for the program in Figure 2 are detected with fairly \nhigh probability, but the benign race triggers no visible errors. Program jbb, Company.elapsed time: \nThe main thread reads each company s elapsed time .eld while computing timing data. However, due to the \nlack of synchronization, multiple values are visible in the write buffer, including the initial value \nof 0. Since this .eld is a long, JUMBLE merges 4-byte words from different writes, causing corrupted \nstatistics to be reported. Since some values con\u00adstructed in this way result in reasonable output for \nthe program, the Oldest-But-Different and random heuristics do not uncover the errors 100% of the time. \nProgram jbb, Company.mode: This variable records the state of a company object during simulation. The \ntransaction manager tests whether mode is RAMP DOWN to decide whether to wake up a waiting object. If \na stale value is read, the waiting object will never awaken, and the program fails to terminate. Program \nmontecarlo, Universal.UNIVERSAL DEBUG: During the test runs, all writes to this global debugging .ag \nwrote the same value, so no difference in behavior could be discerned by JUMBLE, and we considered this \nrace benign. Program mtrt, RayTracer.threadCount: In this program a RayTracer object creates a group \nof Runner worker threads that all refer to the RayTracer as parent. The parent increments threadCount \neach time a runner is created, and each Runner decrements that variable without synchronization upon \ncompletion. JUMBLE causes the threadCount variable to become corrupted, Figure 9. Observation rate for \nerroneous behavior under various heuristics. Destructive races are marked in bold. QoS indicates that \nthe only observed difference was signi.cant slowdown.  Program Field Erroneous Behavior Observation \nRate (%) Destructive Race? No Jumble JUMBLE Con.gurations Sequentially Consistent Oldest Oldest-But-Different \nRandom Random-But-Different Figure 8 x 0 0 0 83 84 92 Yes Figure 2 p 0 0 0 0 0 0 No Figure 2 p.x 0 0 \n60 52 32 30 Yes Figure 2 p.y 0 0 48 53 27 30 Yes jbb Company.elapsed time 0 0 100 0 15 5 Yes jbb Company.mode \n0 0 100 100 95 98 Yes montecarlo Universal.UNIVERSAL DEBUG 0 0 0 0 0 0 No mtrt RayTracer.threadCount \n0 0 0 0 0 0 No raytracer JGFRayTracerBench.checksum1 0 0 100 100 100 100 Yes tsp TspSolver.MinTourLen \n0 0 100 100 100 100 QoS sor array index [0] and [1] 0 0 100 100 100 100 Yes lufact array index [0] and \n[1] 0 0 100 100 100 100 Yes moldyn array index [0] and [1] 0 0 100 100 100 100 Yes but the value of \nthat variable is not used anywhere else in the pro\u00adgram. Thus we consider this race benign. Program raytracer, \nJGFRayTracerBench.checksum1: This program creates a group of worker threads that, upon completion, add \na thread-local checksum to the global checksum checksum1, without synchronization. Under JUMBLE, checksum1 \nbecomes corrupted, and the program detects and reports a failed execution. JUMBLE s treatment of longs \nhelps uncover this error. Program tsp, TspSolver.MinTourLen: This TSP solver uses worker threads to explore \nand evaluate routes, using a branch-and\u00adbound algorithm in which the length of the current best route \nis stored in MinTourLen and monotonically decreases. The protect\u00ading lock MinLock is held for updates \nto MinTourLen, but not for reads, via the following variant of double-checked locking: static void set_best(int \nbest, int[] path) { if (best >= MinTourLen) return; synchronized(MinLock) { if (best < MinTourLen) { \nMinTourLen = best; for (int i = 0; i < Tsp.TspSize; i++) MinTour[i] = path[i]; } } Worker threads check \nand discard partially constructed paths longer than MinTourLen. This check is performed without acquir\u00ading \nMinLock, meaning that stale (i.e., larger) values could be read, which would cause redundant path exploration. \nThe program ran up to twice as slow under JUMBLE because of redundant path ex\u00adploration, which we consider \na Quality of Service (QoS) problem rather than a destructive race. Program sor, arrays: Between each \niteration of this algorithm, worker threads wait for their neighboring threads to .nish using a barrier \nimplemented with the array sync, where sync[id][0] counts iterations .nished by the thread id. The following \ncode signals that id has .nished and waits for its neighbors. public static volatile long sync[][]; ... \nsync[id][0]++; if(id >0) while (sync[id-1][0] < sync[id][0]) ; if (id < JGFSORBench.nthreads -1) while \n(sync[id+1][0] < sync[id][0]) ; Unfortunately, this code does not include any synchronization perhaps \nbecause the programmer mistakenly assumed that reads of the volatile variable sync would be suf.cient. \nTherefore, the barrier does not introduce happens-before edges between writes before the barrier and \nreads following the barrier, so read operations could read stale data, causing the program to compute \nthe incorrect .nal value. The program recognizes and reports this failure when validating its result \n100% of the time under JUMBLE. Programs lufact and moldyn, arrays: A TournamentBarrier class shared by \nthese programs has a similar .aw. It maintains an array IsDone of boolean .ags to indicate whether a \nthread has .nished and is now waiting at the barrier: Since writes to the elements of IsDone are not \nordered, a thread reading an older value can get out of sync and essentially live-lock waiting at the \nbarrier. All of our heuristics triggered non-termination 100% of the time.  6.2 JUMBLE Performance Figure \n10 investigates JUMBLE s performance overhead and other run-time statistics. It .rst shows the base running \ntime of each benchmark, when no instrumentation or monitoring is performed, and then shows the slowdown \nunder ROADRUNNER using both the EMPTY checker and JUMBLE. The EMPTY checker performs no analysis and \njust measures the overhead of using the ROADRUN-NER. We con.gured JUMBLE to use the Sequentially Consistent \nheuristic when measuring performance in order to avoid the extra path exploration performed by benchmarks \nsuch as TspSolver un\u00adder other heuristics. The other heuristics have comparable perfor\u00admance to Sequentially \nConsistent, except in degenerate cases like TspSolver. Each measurement averages ten test runs. Programs \nincur a slowdown between roughly 1.2x and 5x when run under EMPTY. Most of this overhead is due to instrumenting \nclass .les and generating events for synchronization operations. The slowdown for JUMBLE is roughly the \nsame as EMPTY in most cases, with only minor variations due to instrumentation and event handling. This \nlow overhead is because JUMBLE performs rela\u00adtively few write-buffer operations, since it tracks a small \nnumber of racy memory locations and each one is updated only a small number of times (as shown in the \nNum. Instances and Num. Writes columns). More signi.cant differences were seen for the array-based programs, \nsince the barrier defects in those programs described above cause the write buffers to become much larger \nand more heavily used. In these cases, more aggressive sampling or tracking fewer arrays would help keep \nthe overhead lower. The last two columns of Figure 10 shows the maximum buffer size required, both with \nand without the use of our three compres\u00adsion rules. When using these rules, JUMBLE limited buffers to \ncon\u00adtain at most 32 entries, but the garbage collection rules [GC1] and [GC2] were suf.cient to ensure \nthat this bound was never reached for all but two programs, and the garbage collection overhead was negligible. \nThe montecarlo and lufact benchmarks bene.ted the most, and garbage collection enabled the buffers for \nthose pro\u00adgrams to be several orders of magnitude smaller that otherwise. For some array-intensive benchmarks, \nJUMBLE had to apply the [REMOVE OLDEST] rule to maintain this bound on write buffers, but in practice \nthis rule did not limit JUMBLE s ability to detect de\u00adstructive races.  Program Size (lines) Num. Threads \nField Base Time (s) Slowdown Num. Instances Num. Writes Max. Buffer Size Empty Jumble No Comp. With Comp. \njbb 30,491 5 Company.elapsed time 74.4 1.3 1.3 1 2 2 2 jbb 30,491 5 Company.mode 74.4 1.3 1.4 2 10 8 \n4 montecarlo 3,669 4 Universal.UNIVERSAL DEBUG 1.6 1.2 1.2 1 40,005 40,005 5 mtrt 11,317 5 RayTracer.threadCount \n0.5 4.5 4.9 1 10 10 5 raytracer 1,970 4 JGFRayTracerBench.checksum 5.6 1.1 1.1 1 6 6 5 tsp 742 5 TspSolver.MinTourLen \n0.7 2.3 4.0 1 26 26 23 sor 883 4 array index [0] and [1] 0.6 3.9 5.8 2,106 104,620 255 32 lufact 1,627 \n4 array index [0] and [1] 0.4 4.1 4.2 1,108 14,526 2,047 7 moldyn 1,407 4 array index [0] and [1] 0.9 \n4.1 8.9 62 53,433 16,383 32 Figure 10. Performance of JUMBLE under the Sequentially-Consistent con.guration. \n  6.3 Checking the Eclipse Development Environment To validate JUMBLE in a more realistic environment, \nwe also ap\u00adplied it to the Eclipse development environment, version 3.4.0. FASTTRACK reported 27 race \nconditions on a test con.guration that involved starting-up Eclipse and rebuilding a collection of projects. \nOur subsequent experiments were limited by the require\u00adment to run Eclipse interactively, since we did \nnot have an appro\u00adpriate automated test harness. Therefore, for each of these 27 racy .elds, we interactively \nran JUMBLE only a single time looking for incorrect behaviors. For four of these racy .elds, these JUMBLE \ntests produced null pointer exceptions, providing clear evidence of a destructive race. Four other .elds \nproduced non-deterministic reads, but the read value did not cause incorrect behavior (at least in this \nsingle run). For the remaining .elds, JUMBLE did not detect non-deterministic reads, indicating that \nthe races were on .elds to which the same value was written, or were similar to the read-then-write race \nin Figure 4. An automated test infrastructure would provide the ability to perform more test runs and \nto identify more destructive races. Nevertheless, by showing how to easily identify four previously\u00adunknown \ndestructive race conditions in a well-tested and robust software system such as Eclipse, these preliminary \nexperiments already demonstrate the effectiveness of adversarial memory. 7. Related Work The dif.culty \nof manually identifying destructive races has moti\u00advated prior work on this problem. One approach uses \nreplay anal\u00adysis [29] to re-execute a racy trace after swapping the relative or\u00adder of the two racy operations. \nUnlike JUMBLE, this approach re\u00adquires a somewhat complex replay infrastructure, and is prone to falling \noff the trace during replay, resulting in false positives. Race-directed random testing [36] explores \na similar approach, but avoids the need for a replay infrastructure. Both of these approaches assume \nsequential consistency and will not detect destructive race conditions as in Figures 1 and 2 (or in the \nmoldyn benchmark) that cause incorrect behavior only under relaxed memory models. In particular, results \nfrom race-directed random testing [36] suggest that the race conditions in moldyn are benign (under the \nassump\u00adtion of sequential consistency). In concurrent work, Burnim et al also explore testing-based methodologies \nfor relaxed memory models. For three hardware\u00adlevel memory models (TSO, PSO, and PSLO), their work success\u00adfully \ndetects violations of sequential consistency [9, 10], but does not identify which sequential consistency \nviolations cause destruc\u00adtive behavior. An interesting area for future work is to adapt Jum\u00adble s adversarial \nmemory approach to detect destructive race con\u00additions for these memory models. Much other work (including, \nfor example, [27, 40]) identi.es defects in multithreaded programs by exploring many (or possibly all) \npossible interleavings. Most of these tools assume sequential consistency. In contrast to this prior \nwork based on scheduling non\u00addeterminism, this paper proposes a complementary approach of using memory-model \nnon-determinism to expose destructive races. Dynamic analyses to detect race conditions include Eraser \ns LockSet algorithm [35] and its re.nements [30, 41], happens\u00adbefore-based detectors [32], and detectors \ncombining those two approaches, e.g., [15, 33, 45]. Others have also combined dy\u00adnamic analysis with \na global static analysis to improve precision and performance [12, 42]. Post-mortem race identi.cation \ntech\u00adniques record program events for later analysis (see, for exam\u00adple, [3, 13, 34]), but might be dif.cult \nto use for long-running programs. The FASTTRACK algorithm preserves the precision of happens-before-based \ndetectors, but with signi.cantly improved performance [17], and the PACER algorithm uses sampling to \npro\u00advide increased performance, while still providing strong probabilis\u00adtic coverage guarantees [6]. \nMany type-based and whole program static analysis techniques have been developed for identifying races \nin various languages, in\u00adcluding C [16, 38], Java [1, 4, 8, 28, 43], and SPMD programs [5]. While static \nrace detection provides the potential to detect all race conditions over all program paths, decidability \nlimitations imply that, for all realistic programming languages, any sound static race detector is incomplete \nand may produce false alarms. A variety of other approaches have also been developed, including model \nchecking [11, 27, 44]. Recent work [7] developed an operational semantics for pro\u00adgrams under a relaxed \nmemory model. Operational PJMM is sim\u00adilar in some ways (e.g., in making write buffers explicit), but \nour speci.cation only needs to de.ne the legality of traces, not pro\u00adgrams, and is somewhat less involved. \nIn addition, whereas [7] de\u00advelops a new relaxed memory model, the development of JUMBLE required an \noperational formulation of a subset of an existing mem\u00adory model, namely the JMM. 8. Conclusions and \nFuture Work Race conditions are becoming increasingly problematic given the relaxed memory models implemented \nby modern multi-core pro\u00adcessors and virtual machines. This work presents a promising dy\u00adnamic analysis \napproach of using adversarial memory to expose destructive race conditions, which has proven highly effective \nin our experiments. Adversarial memory complements the traditional approach of exploring many or all \npossible thread interleavings un\u00adder the assumption of sequential consistency (as in [27, 40]), and suggests \nthat future tools should exploit both scheduling and mem\u00adory model non-determinism for detecting concurrency \nerrors.  Acknowledgments This work was supported in part by NSF Grants 0341179, 0644130, 0707885, and \n0905650. We thank Jae\u00adheon Yi, Michael Bond, and Kathryn McKinley for comments on a draft of this paper. \nWe also thank Doug Lea, Bill Pugh, and Sarita Adve for helping to clarify aspects of the Java Memory \nModel. References [1] M. Abadi, C. Flanagan, and S. N. Freund. Types for safe locking: Static race detection \nfor Java. TOPLAS, 28(2):207 255, 2006. [2] S. V. Adve and K. Gharachorloo. Shared memory consistency \nmodels: A tutorial. IEEE Computer, 29(12):66 76, 1996. [3] S. V. Adve, M. D. Hill, B. P. Miller, and \nR. H. B. Netzer. Detecting data races on weak memory systems. In ISCA, pages 234 243, 1991. [4] R. Agarwal \nand S. D. Stoller. Type inference for parameterized race\u00adfree Java. In VMCAI, pages 149 160, 2004. [5] \nA. Aiken and D. Gay. Barrier inference. In POPL, pages 243 354, 1998. [6] M. D. Bond, K. E. Coons, and \nK. S. McKinley. Pacer: Proportional detection of data races. In PLDI, 2010. [7] G. Boudol and G. Petri. \nRelaxed memory models: an operational approach. In POPL, pages 392 403, 2009. [8] C. Boyapati and M. \nRinard. A parameterized type system for race-free Java programs. In OOPSLA, pages 56 69, 2001. [9] J. \nBurnim, K. Sen, and C. Stergiou. Sound and complete monitor\u00ading of sequential consistency in relaxed \nmemory models. Technical Report UCB/EECS-2010-31, EECS Department, University of Cali\u00adfornia, Berkeley, \n2010. [10] J. Burnim, K. Sen, and C. Stergiou. Testing concurrent programs on relaxed memory models. \nTechnical Report UCB/EECS-2010-32, EECS Department, University of California, Berkeley, 2010. [11] A. \nT. Chamillard, L. A. Clarke, and G. S. Avrunin. An empirical comparison of static concurrency analysis \ntechniques. Technical Re\u00adport 96-084, Department of Computer Science, University of Mas\u00adsachusetts at \nAmherst, 1996. [12] J.-D. Choi, K. Lee, A. Loginov, R. O Callahan, V. Sarkar, and M. Srid\u00adhara. Ef.cient \nand precise datarace detection for multithreaded object\u00adoriented programs. In PLDI, pages 258 269, 2002. \n[13] J.-D. Choi, B. P. Miller, and R. H. B. Netzer. Techniques for debugging parallel programs with .owback \nanalysis. TOPLAS, 13(4):491 530, 1991. [14] M. Christiaens and K. D. Bosschere. TRaDe: Data Race Detection \nfor Java. In International Conference on Computational Science, pages 761 770, 2001. [15] T. Elmas, S. \nQadeer, and S. Tasiran. Goldilocks: A race and transaction-aware Java runtime. In PLDI, pages 245 255, \n2007. [16] D. R. Engler and K. Ashcraft. RacerX: Effective, static detection of race conditions and deadlocks. \nIn SOSP, pages 237 252, 2003. [17] C. Flanagan and S. N. Freund. FastTrack: Ef.cient and precise dy\u00adnamic \nrace detection. In PLDI, pages 121 133, 2009. [18] C. Flanagan and S. N. Freund. The RoadRunner dynamic \nanalysis framework for concurrent programs. In ACM Workshop on Program Analysis for Software Tools and \nEngineering, 2010. [19] K. Gharachorloo. Memory Consistency Models for Shared-Memory Multiprocessors. \nPhD thesis, Stanford University, 1995. [20] D. Grossman. Type-safe multithreading in Cyclone. In TLDI, \npages 13 25, 2003. [21] Java Grande Forum. Java Grande benchmark suite. Available at http://www.javagrande.org/, \n2008. [22] L. Lamport. How to make a multiprocessor computer that correctly executes multiprocess programs. \nIEEE Trans. Comput., 28(9):690 691, 1979. [23] R. J. Lipton. Reduction: A method of proving properties \nof parallel programs. Communications of the ACM, 18(12):717 721, 1975. [24] S. Lu, S. Park, C. Hu, X. \nMa, W. Jiang, Z. Li, R. A. Popa, and Y. Zhou. Muvi: automatically inferring multi-variable access correlations \nand detecting related semantic and concurrency bugs. In SOSP, pages 103 116, 2007. [25] J. Manson, W. \nPugh, and S. V. Adve. The Java memory model. In POPL, pages 378 391, 2005. [26] F. Mattern. Virtual time \nand global states of distributed systems. In Workshop on Parallel and Distributed Algorithms, 1988. [27] \nM. Musuvathi, S. Qadeer, T. Ball, G. Basler, P. A. Nainar, and I. Neamtiu. Finding and reproducing heisenbugs \nin concurrent pro\u00adgrams. In OSDI, 2008.  [28] M. Naik, A. Aiken, and J. Whaley. Effective static race \ndetection for Java. In PLDI, pages 308 319, 2006. [29] S. Narayanasamy, Z. Wang, J. Tigani, A. Edwards, \nand B. Calder. Automatically classifying benign and harmful data races using replay analysis. In PLDI, \npages 22 31, 2007. [30] H. Nishiyama. Detecting data races using dynamic escape analysis based on read \nbarrier. In Virtual Machine Research and Technology Symposium, pages 127 138, 2004. [31] S. Owens, S. \nSarkar, and P. Sewell. A better x86 memory model: x86-TSO. In TPHOLs, pages 391 407, 2009. [32] E. Pozniansky \nand A. Schuster. Ef.cient on-the-.y data race detection in multihreaded C++ programs. In PPOPP, pages \n179 190, 2003. [33] E. Pozniansky and A. Schuster. MultiRace: Ef.cient on-the-.y data race detection \nin multithreaded C++ programs. Concurrency and Computation: Practice and Experience, 19(3):327 340, 2007. \n[34] M. Ronsse and K. D. Bosschere. RecPlay: A fully integrated practical record/replay system. TCS, \n17(2):133 152, 1999. [35] S. Savage, M. Burrows, G. Nelson, P. Sobalvarro, and T. E. Anderson. Eraser: \nA dynamic data race detector for multi-threaded programs. TOCS, 15(4):391 411, 1997. [36] K. Sen. Race \ndirected random testing of concurrent programs. In PLDI, pages 11 21, 2008. [37] Standard Performance \nEvaluation Corporation. SPEC benchmarks. http://www.spec.org/, 2003. [38] N. Sterling. Warlock: A static \ndata race analysis tool. In USENIX Winter Technical Conference, pages 97 106, 1993. [39] M. Vaziri, F. \nTip, and J. Dolby. Associating synchronization con\u00adstraints with data in an object-oriented language. \nIn POPL, pages 334 345, 2006. [40] W. Visser and P. C. Mehlitz. Model checking programs with Java PathFinder. \nIn SPIN, page 27, 2005. [41] C. von Praun and T. Gross. Object race detection. In OOPSLA, pages 70 82, \n2001. [42] C. von Praun and T. Gross. Static con.ict analysis for multi-threaded object-oriented programs. \nIn PLDI, pages 115 128, 2003. [43] J. W. Voung, R. Jhala, and S. Lerner. Relay: Static race detection \non millions of lines of code. In FSE, pages 205 214, 2007. [44] E. Yahav. Verifying safety properties \nof concurrent Java programs using 3-valued logic. In POPL, pages 27 40, 2001. [45] Y. Yu, T. Rodeheffer, \nand W. Chen. RaceTrack: Ef.cient detection of data race conditions via adaptive tracking. In SOSP, pages \n221 234, 2005.    \n\t\t\t", "proc_id": "1806596", "abstract": "<p>Multithreaded programs are notoriously prone to race conditions, a problem exacerbated by the widespread adoption of multi-core processors with complex memory models and cache coherence protocols. Much prior work has focused on static and dynamic analyses for race detection, but these algorithms typically are unable to distinguish destructive races that cause erroneous behavior from benign races that do not. Performing this classification manually is difficult, time consuming, and error prone.</p> <p>This paper presents a new dynamic analysis technique that uses <i>adversarial memory</i> to classify race conditions as destructive or benign on systems with relaxed memory models. Unlike a typical language implementation, which may only infrequently exhibit non-sequentially consistent behavior, our adversarial memory implementation exploits the full freedom of the memory model to return older, unexpected, or stale values for memory reads whenever possible, in an attempt to crash the target program (that is, to force the program to behave erroneously). A crashing execution provides concrete evidence of a destructive bug, and this bug can be strongly correlated with a specific race condition in the target program.</p> <p>Experimental results with our Jumble prototype for Java demonstrate that adversarial memory is highly effective at identifying destructive race conditions, and in distinguishing them from race conditions that are real but benign. Adversarial memory can also reveal destructive races that would not be detected by traditional testing (even after thousands of runs) or by model checkers that assume sequential consistency.</p>", "authors": [{"name": "Cormac Flanagan", "author_profile_id": "81100538763", "affiliation": "University of California at Santa Cruz, Santa Cruz, CA, USA", "person_id": "P2184556", "email_address": "", "orcid_id": ""}, {"name": "Stephen N. Freund", "author_profile_id": "81100165065", "affiliation": "Williams College, Williamstown, MA, USA", "person_id": "P2184557", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806625", "year": "2010", "article_id": "1806625", "conference": "PLDI", "title": "Adversarial memory for detecting destructive races", "url": "http://dl.acm.org/citation.cfm?id=1806625"}