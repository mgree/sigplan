{"article_publication_date": "06-05-2010", "fulltext": "\n The Reachability-Bound Problem Sumit Gulwani Florian Zuleger * Microsoft Research TU Vienna sumitg@microsoft.com \nzuleger@forstye.tuwien.ac.at Abstract We de.ne the reachability-bound problem to be the problem of .nding \na symbolic worst-case bound on the number of times a given control location inside a procedure is visited \nin terms of the inputs to that procedure. This has applications in bounding re\u00adsources consumed by a \nprogram such as time, memory, network\u00adtraf.c, power, as well as estimating quantitative properties (as \nop\u00adposed to boolean properties) of data in programs, such as informa\u00adtion leakage or uncertainty propagation. \nOur approach to solving the reachability-bound problem brings together two different techniques for reasoning \nabout loops in an effective manner. One of these techniques is an abstract\u00adinterpretation based iterative \ntechnique for computing precise dis\u00adjunctive invariants (to summarize nested loops). The other tech\u00adnique \nis a non-iterative proof-rules based technique (for loop bound computation) that takes over the role \nof doing inductive reasoning, while deriving its power from the use of SMT solvers to reason about abstract \nloop-free fragments. Our solution to the reachability-bound problem allows us to compute precise symbolic \ncomplexity bounds for several loops in .Net base-class libraries for which earlier techniques fail. We \nalso illustrate the precision of our algorithm for disjunctive invariant computation (which has a more \ngeneral applicability beyond the reachability-bound problem) on a set of benchmark examples. Categories \nand Subject Descriptors C.4 [Performance of Sys\u00adtems]: Measurement techniques; Reliability, availability, \nand ser\u00adviceability; D.2.4 [Software Engineering]: Software/Program Ver\u00adi.cation; F.3.1 [Logics and Meanings \nof Programs]: Specifying and Verifying and Reasoning about Programs General Terms Veri.cation, Performance, \nReliability Keywords Resource Bound Analysis, Disjunctive Invariants, Transitive Closure, Ranking Functions, \nPattern Matching 1. Introduction Program execution makes use of physical resources, and it is of\u00adten \nimportant to compute worst-case bounds on usage of those resources as a function of the program inputs. \nFor example, in * The research of the second author was performed during an internship at MSR Redmond \nand was supported in part by Microsoft Research through its PhD Scholarship Programme. Permission to \nmake digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 10, June 5 \n10, 2010, Toronto, Ontario, Canada. Copyright c &#38;#169; 2010 ACM 978-1-4503-0019-3/10/06. . . $10.00 \n memory-constrained environments such as embedded systems, it is important to bound the amount of memory \nrequired to run cer\u00adtain applications. In real-time systems, it is important to bound the worst-case \nexecution-time of the program. Applications running on low-power devices or low-bandwidth environments \nmust use up little power or bandwidth respectively. With the advent of cloud computing, where users would \nbe charged per program execution, predicting resource usage characteristics would be a crucial com\u00adponent \nof accurate bid placement by cloud providers. One of the fundamental questions that needs to be answered \nfor computing such resource bounds is: How many times is a given control loca\u00adtion inside the program \nthat consumes these resources executed? Program execution also affects certain quantitative properties \nof data that it operates on. For example, how much secret information is leaked by a program depends \non the number of times a certain operation that leaks the data, either by direct or indirect information \n.ow, is executed [23]. Or the amount of perturbation in the output data values resulting from a small \nperturbation or uncertainty in the input values depends on the number of times additive error propagation \noperators are applied. This is the quantitative version of the boolean problem of continuity studied \nin [7]. Estimating such quantitative properties again requires addressing a similar question as above: \nHow many times is a given control location inside the program that performs certain operations executed? \nWe refer to the problem of bounding the number of visits to a given control location p as the reachability-bound \nproblem. Our two-step solution to this problem brings together two different techniques for reasoning \nabout loops: an iterative technique for computing disjunctive invariants, and a non-iterative proof-rule \nbased technique for computing bounds of transition systems. The .rst step consists of generating a disjunctive \ntransition\u00adsystem that describes relationships between values of program vari\u00adables that are live at \np and their values in the immediate next visit to p. This requires summarizing inner loops that lie on \na path from p back to itself for which we present an abstract interpretation based iterative algorithm \nthat generates disjunctive loop invariants. The precision of our algorithm relies on a convexity-like \nassumption, which appears satis.ed by all instances that we came across in practice, and leads to an \ninteresting completeness theorem (The\u00adorem 12). We also evaluated the precision of this algorithm on \nbenchmark examples taken from recent work on computing dis\u00adjunctive invariants. Our algorithm can discover \nrequired invariants in all examples, suggesting its potential for effective use in other applications \nrequiring disjunctive invariants besides bound analy\u00adsis. The second step consists of generating bounds \nfor the dis\u00adjunctive transition system thus generated. For this, we propose a non-iterative proof-rules \nbased technique that requires discharging queries using an off-the-shelf SMT solver. These proof rules \nde\u00adscribe conditions that are suf.cient for combining the ranking func\u00adtions for individual transitions \ninto an overall bound of the transi\u00adtion system using three different mathematical operators, namely \nmax, sum, and product. This is unlike existing work [4, 8, 28] (a) Ex1(uint n, bool[ ] A) 1 i := 0; \n2 while (i<n) 3 j := i + 1; 4 while (j < n) 5 if (A[j]) 6 ConsumeResource(); 7 j--; 8 n--; 9 j++; 10 \ni++; (b) (d) (c)  Figure 1. This .gure illustrates generation of transition system for a given control \nlocation. (a) A loop skeleton from .Net base-class library. (b) Flow-graph representation of the program \nin (a). (c) Flow-graph obtained from (b) by splitting location p6 into p6a and p6b. (d) Part of the .ow-graph \nfrom (c) between p6a and p6b after re-drawing it. (e) Body of inner loop in (d) replaced by its transition \nsystem representation T1. (f) Inner loop in (e) replaced by transitive closure T1{of transition system \nT1. (g) Body of outer loop in (f) replaced by its transition system representation T2. (h) Outer loop \nin (g) replaced by Transitive closure T2{of transition system T2. (i) Transition system for p6. on termination \nanalysis where the goal is to generate any rank\u00ading function for a transition system with disregard to \nthe precision of the ranking function. This methodology represents an interest\u00ading design choice for \nreasoning about loops, because SMT solvers are used to perform precise reasoning about transitions (loop-free \ncode-fragments), whereas a simple proof-rules based technique takes over the role of performing inductive \nreasoning effectively. It will be interesting to consider applying such a methodology to other problems. \nWe have implemented our solution to the reachability-bound problem in a tool that computes symbolic computational \ncom\u00adplexity bounds for procedures in .Net codebases. This involves computing amortized complexity for \nnested loops by solving the reachability-bound problem for nested loops. To our knowledge, our analysis \nis the .rst that addresses the problem of computing the amortized complexity for nested loops. Existing \ntechniques for bound analysis [16, 19, 15, 2] do not compute amortized complex\u00adity of nested loops, but \ninstead over-approximate it by the product of the iterations of the outer loop and the worst-case complexity \nof the inner loop for any iteration of the outer loop, thereby leading to imprecise bounds. Contributions \nand Organization We de.ne the reachability-bound problem and the notion of a precise solution to that \nproblem (Section 3). This contributes to the problem of de.ning an entire quantitative logic, which is \npart of the quantitative agenda set forth recently [21] (as opposed to the Boolean agenda). We describe \nan algorithm for the generation of a transition system based on transformations on reducible .owgraphs \nfor reducing the problem of computing the reachability-bound to the problem of computing the bound for \na transition system (Section 4).  We describe an abstract interpretation based iterative algorithm for \ncomputing the transitive closure of a transition system, or, equivalently, disjunctive invariants for \na loop. (Section 5).  We describe non-iterative proof rules (Section 7) that allow computing precise \nsymbolic bounds for a transition system from the ranking functions of individual transitions, which can \nbe obtained using the technique described in Section 6.  We present experimental results evaluating \nthe effectiveness of various aspects of our solution (Section 8).  2. Motivating Examples and Technical \nOverview In this section, we discuss some examples that are representative of some challenges that arise \nduring the computation of symbolic bounds for the reachability-bound problem. We also provide a technical \noverview of our solution. 2.1 Bounding number of visits to a given control location Consider the program \nshown in Figure 1, and consider the problem of computing symbolic bounds on the number of times the proce\u00addure \nConsumeResource() is called at Line 6. One approach would be to approximate it by computing a bound on \nthe number of iter\u00adations of the closest enclosing loop at Line 4 using techniques for loop bound computation \n(as in [16, 19]). However, this approach will yield quite conservative results since the number of iterations \nof the loop at Line 4 is bounded above by n 2, while the number of executions of Line 6 is bounded above \nby n. Our approach .rst computes the following symbolic relation\u00adship between values of variables i, \nj, n at Line 6 with their values i{,j{,n{ in the immediate next visit to Line 6. The relationship is \nexpressed as the disjunction of two transitions given as two dis\u00adjuncts: { {{ (n= n - 1 . j<n - 1 . j= \nj . i= i) { . (n= n - 1 . i<n - 1 . i{ = i +1 . j{ = i + 2) This is done using the GenerateTransitionSystem \nalgorithm described in Figure 4 in Section 4. The algorithm enumerates all paths in the control-.ow graph \nin Figure 1(d) between the locations p6a and p6b obtained after splitting the location p6 in the original \ncontrol-.ow graph (in Figure 1(b)) into p6a and p6b (as shown in Figure 1(c)). (Note, that such a relationship \nis different from tran\u00adsition invariants [28] or variance assertions [4] that relate values of variables \nat a control location with their values in any successive iteration, as opposed to the immediate next \niteration). The chal\u00adlenge in such an enumeration is that the number of paths in pres\u00adence of loops between \ncontrol locations p6a and p6b is not .nite. For this purpose, the loops are summarized by disjunctive \nrelation\u00adships between the inputs/outputs of the loop. These disjunctive re\u00adlationships are generated \nby computing the transition system of the loop (recursively, using the same algorithm applied to the \ncontrol location immediately after the loop-header) and then computing its transitive closure (using \nthe algorithm TransitiveClosure de\u00adscribed in Fig. 6 in Section 5). The transition system of the inner \nloop in Figure 1(d) is shown in Figure 1(e). The transitive closure of the inner loop is given in Figure \n1(f). The transition system of the outer loop is shown in Figure 1(g). The transitive closure of the \nouter loop is given in Figure 1(h). The resulting transition system for location p6 is given in Figure \n1(i). Next, bounds are computed for the transition system thus gen\u00aderated. This involves computing the \nranking functions for the two transitions of the transition system for location (p6). A ranking function \nfor a transition s is an integer-valued function (of the vari\u00adables that occur in s) that is bounded \nbelow by 0 and decreases every time the transition s is taken. (For a formal de.nition see Sec\u00adtion 6.) \nBy using the pattern matching techniques described in Sec\u00adtion 6 we compute the ranking functions n-j \nresp. n-i-2 for the transition given by the .rst resp. second disjunct of the transition system for (p6). \nThese ranking functions are then composed using one of the proof rules described in Section 7 (in this \ncase, the proof rule in Theorem 16) to obtain a bound of Max(0,n - j, n - i - 2) in terms of the inputs \nto the transition system (For details, see Ex\u00adample 17). Using the invariants i = 0 . j = 1 that hold \nduring the .rst visit to p6) (which can be obtained by generating invariants at control location p6b \nin Figure 1(d)), we obtain a bound of n - 1 on the transition system in terms of procedure inputs. This \nimplies a bound of n on the number of visits to control location p6.  2.2 Bounding iterations of a loop \nComputing bounds on the number of loop iterations is a special case of the reachability-bound problem \nwhere the control loca\u00adtion under consideration is the location immediately after the loop header. Under \nthat case, our technique outperforms recent tech\u00adniques for loop bound computation and termination. In \nparticular, our technique is able to compute the bounds for loops whose iterations are affected by inner \nloops for which exist\u00ading bound techniques (such as [2, 16, 19]) mostly fail (for details, see related \nwork in Section 9). Such loops are quite common in .Net base-class library, and Figure 2 gives some examples. \nOne of Ex7(uint n, uint m) Ex6(int n, int x, int z) 1 Assume(0 <n<m); 1 while (x<n) 2 j := n +1; 2 if \n(z>x) x++; 3 while (j<n . j>n) 3 else z++; 4 if (j>m) j := 0; 5 else j++; Figure 3. Loop templates Ex6 \nand Ex7 (from Microsoft product\u00adcode) taken respectively from recent work on proving termina\u00adtion [8] \nand loop bound computation [16]. Our proof rules for bound computation provide an alternative, but simpler, \nformalism for computing bounds. (For details see Example 20 and Exam\u00adple 23.) the key challenges addressed \nby our technique in such examples is the summarization of the inner loops by precise transitive-closure \nof the transition system represented by these loops (in effect, dis\u00ad junctive relationships between the \ninputs and outputs of the loop). Also, even in case of loops with no nested loops, our technique is \nable to compute bounds for loops using a much simpler uniform algorithm compared to existing termination \ntechniques or special\u00ad ized bound computation techniques. Figure 3 shows two such ex\u00ad amples that have \nbeen used as motivating examples by previous techniques. The computation of the transition system for \nthese ex\u00ad amples is almost trivial, and the bound computation of the result\u00ad ing transition system is \nenabled by simple but precise proof rules (Theorem 19 and Theorem 21) for bound computation from rank\u00ad \ning functions of individual transitions (for details, see Example 20 and 23). 3. The Reachability-Bound \nProblem There are two classical problems associated with the reachability of a control location p inside \na procedure P with inputs n .  Safety Problem: Is the control location p never reached/visited?  Termination \nProblem: Is the control location p visited at most a .nite number of times?  In this paper, we have \nmotivated the following bound problem, which is a more general instance of both the safety and termination \nproblem. In fact, as we will see, our solution to the bound problem builds over techniques for safety \nand termination checking. Reachability-bound Problem: Compute a worst-case symbolic bound B(n ) on the \nnumber of visits to p for any execution of P . The notion of a worst-case symbolic bound is de.ned below. \nDEFINITION 1 (Worst-case symbolic bound). An integer-valued function B(n ) is a worst-case symbolic bound \nfor a control lo\u00adcation p inside a procedure P with inputs n if for any input state n 0, the number of \ntimes p is visited is at most B(n 0). There may be multiple worst-case symbolic bounds for a given location. \nIt is desirable to produce a bound that is precise in the sense that there exists a family f(n ) of worst-case \ninputs that exhibit the bound (up to some constant factor, as motivated by the de.nition of asymptotic \ncomplexity), formally de.ned as follows: DEFINITION 2 (Precision of a worst-case symbolic bound). A \nworst\u00adcase symbolic bound B(n ) for a control location p inside a pro\u00adcedure P with inputs n is said \nto be precise (up to multiplicative constant factors) if there exist positive integers c1, c2, and a \nfor\u00admula f(n ) such that: E1. For any assignment n 0 to variables n such that f(n 0) holds, the number \nof times control location p is visited (when procedure n0) P is executed in the input state n 0) is at \nleast B(n- c2. c1  Ex5(uint n) Ex4(uint n) 1 i := 0; Ex2(uint n, uint m) Ex3(uint n, bool[ ] A) 1 flag \n:= true; 2 while (i<n)1 while (n> 0 . m> 0) 1 while (n> 0) 2 while (flag) 3 flag := false;2 n--; m--; \n2 t := A[n]; 3 flag := false; 4 while (nondet())3 while (nondet()) 3 while (n> 0 . t = A[n]) 4 while \n(n> 0 . nondet()) 5 if (nondet())4 n--; m++; 4 n--; 5 n--; flag := true; 6 flag:=true;n--; 7 if (\u00acflag) \ni++; (n{ = n - 1 . flag{) (n{ = n-1 . flag{ . i{ = i)n{ = n . m{ = m n{ = n .(Same({n, flag})) .(Same({i, \nn, flag})) (n>0 . n{=n . A[n] {]) (flag .flag{ . n>0 . n{=n-1) =A[n (i<n . flag{ . n{=n-1 . i{=i)n>0 \n. m>0 . n{=n-1 . (n>0 . n{=0) .(flag .\u00acflag{ . n{ = n) . (i<n .\u00acflag{ . i{=i+1 . n{=n) n n n n +1 \nFigure 2. Loop templates from .Net class libraries where iterators of a loop are modi.ed by inner loops. \nThe second row shows the required transitive closure of the inner loops to enable precise symbolic bound \ncomputation of respective outer loops. The third row shows the resultant transition-system generated \nfor the outer loops after summarizing the respective inner loops by the transitive closure of their transition-system \n(using the algorithm in Figure 4). The .nal (fourth) row shows the bound computed from the transition-system \nby the algorithm in Figure 7. i We use the predicate Same(V ) inside a transition to denote that the \nvariables in V do not change their value, i.e., Same(V )= (x{ = x). E2. For any integer k, there exists \na satisfying assignment n 1 for f(n ) such that B(n 1) >k. In other words, the formula .n : (B(n ) = \nk . f(n )) has a satisfying assignment. We refer to the triple (f, c1,c2) as precision-witness for bound \nB. The following example explains and motivates the requirements E1 and E2 in the above de.nition. EXAMPLE \n3. A precision-witness for the bound of n on the number of times Line 6 is visited in the example program \nEx1 in Figure 1 can be f = .k(0 = k<n . A[k]), c1 =1 and c2 =1 since it can be shown that under the precondition \nf, Line 6 is visited at least n - 1 times. A precision-witness for the bound of n 2 on the number of \ntimes the inner loop (Line 5) is executed can be f = .k(0 = k<n . \u00acA[k]), c1 =4 and c2 =1 since it can \nbe shown that under the precondition f, Line 5 is visited at least n 2/4 times. This is because, for \nexample, i takes all values between 0 to n/2 - 1 at Line 2 (hence the number of visits to Line 2 is at \nleast n/2), and for each of those visits, j takes all values between n/2 to n - 1 at Line 4 (i.e., the \nnumber of visits to Line 4 is at least n/2). Note that if we did not relax the requirement E1 to allow \nfor constants c1 and c2, then computation of a precise bound would have required us to compute the exact \nbound of (n-1)(n-2) . It would be impractical to 2 .nd such exact closed-form solutions. A bound of, \nsay, 100, on the number of times Line 6 is visited is not precise. It may appear that f =(.k(0 = k< 100 \n. A[k]) . n = 100), c1 =1 and c2 =1 is a precision-witness. However, note that it violates requirement \nE2 since for k = 101 (in fact, for any k greater than 100), there does not exist a satisfying assignment \nfor the formula f . 100 = 101. In this paper, we describe an algorithm for computing a worst\u00adcase symbolic \nbound. Manual investigation of the bounds returned by our algorithm on our benchmark examples con.rms \nthat the bounds are precise. Automatically establishing the precision of a bound B returned by our algorithm \nis an orthogonal problem that we are currently working on. It requires identifying a precision\u00adwitness \n(f, c1,c2) and establishing that B - c2 is a lower bound c1 for all inputs that satisfy f. The duality \nbetween the problems of computing a symbolic bound B and the problem of .nding a wit\u00adness f to show that \nB is precise is similar to the duality between the problems of proving a given safety property, or .nding \na concrete counterexample/witness to the violation of a safety property. How\u00adever, the challenge in our \ncase is that the witness f that establishes the precision of a given symbolic bound is symbolic as opposed \nto being concrete. x.V We next describe our overall algorithm for bound computation. 3.1 Algorithm Our \nalgorithm for the reachability-bound problem is as follows. ReachabilityBound(p) 1 T := GenerateTransitionSystem(p); \n2 B := 1+ ComputeBound(T ); 3 return TranslateBound(B,p); Line 1 of the algorithm .rst computes a disjunctive \ntransition system T for the control location p that describes how the variables at p get updated in \nthe immediate next visit to control location p. This is done using the algorithm described in Figure \n4 (Section 4), which in turn uses the algorithm for transitive closure computation described in Figure \n6 (Section 5) to summarize any inner loops. Line 2 of the algorithm computes a bound for the transition \nsystem T using the algorithm described in Figure 7 (Section 7), which in turn makes use of techniques \ndescribed in Section 6 for computing ranking functions of individual transitions. The bound B on number \nof visits to p is then obtained by adding 1 to the bound for transition system T to account for the .rst \nvisit to p. The bound B is expressed in terms of inputs to the transition system, which may not necessarily \nbe the procedure inputs. The function TranslateBound at Line 3 then translates the bound B at p in terms \nof the procedure inputs. This can be done either by using invariants (computed with an invariant generation \ntool) that relate the procedure inputs with the inputs to the transition system T , or by using a backward \nsymbolic engine to express the transition system inputs in terms of the procedure inputs. We implemented \nthe latter approach, which we found to be extremely effective in terms of both precision and ef.ciency. \nThis technique is detailed in [17]. Notice, how our solution builds on techniques for safety or termination \nchecking. Step 1 uses disjunctive invariants, which is essentially what is needed for safety checking. \nStep 2 uses ranking functions, which are required for termination checking. Use of these techniques together \nwith novel proof-rules for composing ranking functions yields an effective solution to the bound problem. \n4. Generation of Transition System We .rst de.ne the notion of a transition and a transition system with \nregard to a control location p. DEFINITION 4 (Transition for a Control Location p). Let nx be the tuple \nof the variables live at p.A transition for p is a relation n{ T (nx, xn{) between variables nx and their \nprimed counterparts xsuch that if nx take values vn1 and vn2 during any two immediate successive/consecutive \nvisits to p, then T (vn1, nv2) holds. A transition is always assumed to be represented as a conjunc\u00adtion \nof formulae over the variables nx and xn{. DEFINITION 5 (Transition System for a Control Location p). \nA tran\u00adsition system is a set of transitions. A transition system is always assumed to be represented \nas a DNF formula where every disjunct corresponds to the representa\u00adtion of a transition of the transition \nsystem. We desire a disjunctive representation for our transition system since our bound computation \nalgorithm in Section 7 works by identifying precise ranking functions for a single transition/path, and \nthen using proof rules to obtain the ranking function/bound for the entire transition system. The key \nidea for generating a transition system for a control location p is to split the control location p into \nthe two locations (pa,pb) (using the Split transformation shown in Figure 5(a)) and enumerate all paths \nthat start at pa and end at pb and take the dis\u00adjunctions of the transitions represented by each path. \nThe challenge that arises in such an enumeration is the presence of any nested loops. We address this \nchallenge by replacing the nested loop by the transitive closure of the transition system of the nested \nloop (using the Summarize transformation shown in Figure 5(b)). Since path enumeration leads to an exponential \nblowup, we generate the transition systems on the .owgraph that has been sliced with re\u00adspect to the \nstatements on which p is control-dependent [25] (since these are the statements that determine the number \nof times p is ex\u00adecuted). This usually leads to transition systems with a very small number of transitions, \nas is exempli.ed by statistics in Fig. 8 (Sec\u00adtion 8.1). Figure 4 describes the algorithm to generate \nthe transition sys\u00adtem for a control location p. The algorithm is described at .ow\u00adgraph level. We make \nthe assumption about the .owgraphs being reducible, but not necessarily structured. Our algorithm can \nbe ex\u00adtended to irreducible .owgraphs too; but we avoid that for ease of presentation, and the fact that \nmost .owgraphs in practice are in fact reducible [25]. However, it is important to consider the case \nof unstructured .owgraphs because even if the original .owgraph was structured, after the splitting transformation, \nthe new .ow\u00adgraph would no longer be structured. The splitting transformation, however, is reducibility-preserving. \n1 Line 1 transforms the .owgraph by splitting the input control location p into two locations pa and \npb using the Split transfor\u00admation described in Figure 5(a). The loop in Line 2 iterates over each top-level \nloop L in the transformed .owgraph. (Recall that any graph can be decomposed into a DAG of maximal strongly\u00adconnected \ncomponents.) Line 3 makes use of the fact that every loop in a reducible .ow-graph has a unique header \nnode. Line 4 re\u00adcursively generates the transition system for the loop L in the trans\u00adformed .ow-graph, \nwhile Line 5 generates its transitive closure (us\u00ading the algorithm described in Figure 6 in Section \n5). Lines 6 and 7 replace the loop L by its summary obtained by generating tran\u00adsitive closure of the \ntransition system represented by it (using the Summarize transformation shown in Figure 5(b)). The effect \nof the foreach-loop in Line 2 is to replace all loops on the paths between pa and pb by (disjunctive) \nloop-free abstract code-fragments. The transition system can now simply be generated by enumerating all \npaths (which are now .nite in number) between pa and pb. Lines 8-10 generate the transition system for \nan acyclic .ow\u00adgraph by a simple forward data.ow analysis that associates a (dis\u00adjunctive) transition \nsystem F [p] with each edge/control location p in the transformed .owgraph. For this purpose, we associate \nthe 1 It is interesting to observe that the nesting structure of the loops inside which p was originally \nnested, is completely reversed after the splitting transformation, but the .owgraph stays reducible. \n GenerateTransitionSystem(p) 1 (pa,pb) := Split(p); 2 foreach top-level loop L: 3 pL := location before \nheader of L; 4 T := GenerateTransitionSystem(pL); 5 Tc := TransitiveClosure(T ); 6 Insert Summary(Tc) \nbefore header; 7 Remove back-edges; 8 Initialize F [pa] to the transition system Id; 9 Propagate transitions \nF using Merge/Compose rules; 10 return F [pb]; Figure 4. Generation of transition system for a control \nlocation p. entry location pa with the transition system consisting of a single transition Id, which \nis the identity mapping between the variables and their primed versions. The transfer functions for performing \nthis data.ow analysis are described in Figure 5. Without loss of any generality, we assume that all conditional \nguards have been trans\u00adlated into Assume statements. The Merge transfer function simply returns the disjunctions \nof the transitions in the two input transition systems. The Compose transfer function makes use of the \ncompose operator . that returns the composition of two transitions. DEFINITION 6 (Composition of Transition \nSystems). Given two ee { transition systems T (nx, xn{)= si and T {(nx, xn{)= sj , we ij de.ne their \nbinary composition to be def { T . T { =si . sj , i,j { where si . sj denotes the transition def si(nx, \nxn{) . s{j (nx, xn{)= .xn{{si[xn{{/xn{] . s{j [xn{{/nx], {{/nn where si[xnx{] denotes the substitution \nof xn{ by x{{ in si. The Translate function converts a statement into a transition system as follows. \nWithout loss of any generality, we assume that the only assignment statement is of the form x := e since \nmemory can be modeled using Select and Update expressions. The other kinds of statements can be either \nan Assume statement (obtained from the conditional guards) or a Summary statement (obtained from the \nsummarization of nested loops). {{ Translate(x := e)=(x= e) . (y= y) y =x Translate(Assume(guard)) = \nId . guard Translate(Summary(T )) = T  EXAMPLE 7. The transition system for control location p6 in Fig\u00adure \n1(b) is shown in Figure 1(e) along with the various steps re\u00adquired to obtain it from the .owgraph in \nFigure 1(d). These include computing the transition system for the inner loop and then replac\u00ading the \ninner loop by its transitive closure. Next, the process is re\u00adpeated for the outer loop. 5. Computation \nof Transitive Closure In this section, we describe an algorithm for computing a transitive closure (de.ned \nbelow) of a transition system. This operation is re\u00adquired by the GenerateTransitionSystem algorithm \ndescribed in Figure 6 in the previous section. DEFINITION 8 (Transitive Closure). We say that T {(nx, \nxn{) is a transitive closure of a transition system T (nx, xn{) if { {{ Id . T and T . T . T  (c) Compose \n(d) Merge (b) Summarize (a) Split Figure 5. This .gure describes the .owgraph transformations Split \nand Summarize, and the transfer functions Compose and Merge required in the algorithm GenerateTransitionSystem \nfor computing the transition system for any control location. n e i=1 { sj := false; EXAMPLE 9. Figure \n1(e) provides an example of a transition sys- TransitiveClosure( si) tem T and its transitive closure. \nNote that i{ = i is another choice for the transitive closure for T . However, it is not as precise \nas the 1 for j .{1,..,m}-{d}: one shown in Figure 1(e), and would lead to the generation of a d := Id; \n{ 2 s transition system for location p6 for which no bound exists. 3 do {4 for i {.{1,..,n} and {j .{{1,..,m}: \nGenerating the transitive closure of a transition system is like 5 ss(j,i) := Join(ss(j,i),sj . si) computing \nthe invariants for a loop which represents the transition system. Example 9 suggests the importance of \nthese invariants to be precise, and hence disjunctive. There has been some work on e m 6 } while any \nchange in s j=1 { j e m s j=1 { j ; 7 return discovering disjunctive invariants [5, 16, 20, 29, 13, 14] \nin general. We present below a technique that takes advantage of its particular application to bound \nanalysis. (We also remark that our technique can be used in general for proving safety properties of \nprograms. In Section 8.2, we present preliminary results that demonstrate the effectiveness of our technique \non a set of benchmark examples taken from a variety of recent literature on generating disjunctive invariants.) \nOur algorithm for the computation of precise transitive closures is inspired by a convexity-like assumption \nthat we found to hold true for all examples we have come across in practice. (This includes the Figure \n6. Transitive closure computation of a transition system. e m The tuple (d, s) is referred to as a convexity-witness \nof s { j . j=1 The convexity-like assumption essentially implies that no case-split reasoning is needed \nto prove inductiveness of transitive closure. EXAMPLE 11. All the transitive closures of the respective \ntran\u00ad sition systems described in Figure 1(e) and Figure 2 satisfy the desired transitive closure of \nthe transitions-systems of nested loops to compute precise bounds, as well as the benchmarks considered \nby previous work on computing disjunctive invariants.) Recall that a theory is said to be convex iff \nfor every quanti.er\u00ad convexity-like assumption. For example, the convexity-witness for the transitive \nclosure of the transition system T shown in Fig\u00ad ure 1(e) is d =1 and s = {(1, 1) . 2, (2, 1) . 2}. A \nconvexity\u00adwitness for the transitive closure of the transition system T { shown free formula f in that \ntheory, if f implies a disjunction of equalities, in Figure 1(e) is d =1 and s = {(1, 1) . 1, (2, 1) \n. 2, (1, 2) . then it implies one of those equalities, i.e.,2, (2, 2) . 2}.   e Given a convexity-witness \n(d, s) of any transitive-closure T { f .(xi = yi)=.(f . (xi = yi))(1) (that satis.es the convexity-like \nassumption) of a transition system iminT , the algorithm in Figure 6 describes a way to compute a transitive \ne closure that is at least as precise as T {. This property (stated for\u00ad { j Now, if s is a transitive \nclosure of si, then it fol\u00ad j=1 i=1 lows from the de.nition of the transitive closure, that for all i \n. {1,..,n} and j .{1,..,m}, the following holds: m m Id . s{k and s{j . si . s{k k=1 k=1 After distributing \nimplication over disjunctions in the above equa\u00adtions (in a manner similar similar to in Equation 1), \nwe obtain the mally in the following theorem) is quite signi.cant in light of the fact that discovering \ndisjunctive invariants has been quite a chal\u00adlenging task in literature and several merging heuristics \nbased on semantics of the constituent data.ow facts have been suggested. The following theorem states \nthe remarkable result that a semantic merging criterion cannot be better than a static syntactic criterion \nfor merging data-.ow facts. THEOREM 12 (Precision of TransitiveClosure Algorithm). e mj=1 s {{ j be any \ntransitive closure of a given transition system convexity-like assumption, which is de.ned formally below. \n Let DEFINITION 10 (Convexity-like Assumption). e ni=1 si that satis.es the convexity-like assumption. \nGiven the num\u00ad e m = s Let T { { j (nx, xn{) be a transitive closure for a transition ber of disjuncts \nm and a convexity-witness (d, s), algorithm in j=1 e n system T = si(n e {is a conjunc-Figure 6 outputs \na transitive closure that is at least as precise as j m x, xn{), where each si and s i=1 {{ sj . e { \nj satis.es the tive relation. We say that the transitive closure s j=1 j convexity-like assumption if \nthere exists an integer d .{1,..,m}, {{{ PROOF: We can prove that sj . sj by induction on the number \nof a map s : {1,..,m}\u00d7{1,..,n} .{1,..,m}, such that for all i .{1,..,n} and j .{1,..,m}, the following \nholds: loop iterations; the base case as well as the inductive case both follows easily from the de.nition \nof convexity-like assumption. {{{ Id . sand (sj . si) . s D d s(j,i)  The algorithm in Figure 6 performs \nabstract interpretation over the power-set extension of an underlying abstract domain (such as polyhedra \n[10], octagons [24], conjunctions of a given set of pred\u00adicates), where the elements are restricted to \nat most m disjuncts. We assume, that the underlying abstract domain is equipped with a Join operator, \nwhich takes two elements and returns the least upper bound of both elements. The algorithm uses the map \ns to determine how to merge the n \u00d7 m different disjuncts (into m dis\u00adjuncts) that are obtained after \nthe propagation of m disjuncts across n transitions using the Join operator. The key distinguishing fea\u00adture \nof the algorithm from earlier work on computing disjunctive invariants is that our algorithm uses a syntactic \ncriterion based on s to merge disjuncts as opposed to using a semantic criterion based on the notion \nof differences between disjuncts. This is justi.ed by Theorem 12, which, in effect, says that no semantic \nmerging crite\u00adrion can be more powerful than a static syntactic criterion. There are two issues with \nthe algorithm presented in Figure 6 that we dis\u00adcuss below. Abstract Domains with In.nite Height The \nalgorithm may not on domains with in.nite height. The standard solution would be to the apply a Widen \noperator (as de.ned in [9]) in place of the Join operator, in order to enforce termination. Since the \nuse of widening may overapproximate the least .xed point in general, it is no longer possible to formally \nprove precision results as in Theorem 12. However, we show experimentally (in Section 8.2) that our algorithm \nis able to compute precise enough invariants with the use of standard widening techniques when ap\u00adplied \non benchmarks taken from recent work on computing dis\u00adjunctive invariants. Choice of m and a convexity-witness \n(d, s) Since we do not know the desired transitive closure and its convexity-witness (d, s) upfront, \nwe have two options. Option 1: We can enumerate all possible (d, s) for a speci.cally chosen m. There \nare m mn such possible maps since without loss of any generality, we can assume that d is 1. If m and \nn are small constants, say 2 (which is quite often an important special case), then there are 16 possibilities. \nEach choice for s and d results in some transitive closure computation by the algorithm. One can then \nselect the strongest transitive closure among the various transitive closures thus obtained (or heuristically \nselect between incomparable transitive closures). However, if m or n is large, then this approach quickly \nbecomes prohibitive. Option 2: We can use some heuristics to construct m, d, s. The following heuristic \nturns out to be the most effective for our appli\u00adcation of bound computation. We set m and d to n +1, \nand select the map s from the DAG of dependencies between transitions of T generated from bound computation \nof T (as described in Section 7). In particular, for any i, j .{1,..,n}, we de.ne s(n +1,i) := i, s(i, \ni) := i, and s(i, j) := i except when \u00acNI(sj ,si,r) (where r . RankC(si) was the ranking function that \ncontributed to the bound computation of T ) in which case we de.ne s(i, j) := j. It can be proved that \nsuch a choice of the map d and s would gener\u00adate a transitive closure that would allow for computing \nthe bound of (T . TransitiveClosure(T )) using the bound computation algorithm described in Section 7, \nprovided it was able to gener\u00adate a bound for the transition system T . Such a transitive closure preserves \nimportant relationships (between the program variables) for the application of computing the bound of \nthe transition sys\u00adtem that is to be obtained after replacing the corresponding loop by the transitive \nclosure. In particular, note that this heuristic for the construction of a convexity-witness, when used \nin conjunction with the algorithm in Figure 6 discovers the required transitive-closures of the respective \ntransition systems mentioned in Figure 1(e) and Figure 2. 6. Ranking Function for a Transition In this \nsection, we show how to compute a ranking function for a transition. These ranking functions are made \nuse of by the bound computation algorithm described in Section 7. DEFINITION 13 (Ranking Function for \na Transition). We say that an integer-valued function r(nx) is a ranking function for a transi\u00adtion s(nx, \nxn{) if it is bounded below by 0 and if it decreases by at least 1 in each execution of the transition, \ni.e., s . (r> 0)  s . (r[xn{/nx] = r - 1)  We denote this by Rank(s, r). We say that a ranking function \nr1(nx) is more precise than a ranking function r2(nx) if r1 = r2 (because in that case, r1 provides a \nmore precise bound for the transition than r2). We discuss below the design of a functionality RankC \nthat takes as input a transition s(nx, xn{) and outputs a set of ranking func\u00adtions r(nx) for that transition. \nWe use a pattern-matching based technique that relies on asking queries that can be discharged by an \nSMT solver. We found this technique to be effective (fast and precise) for most of the transitions that \nwe encountered during the process of bound computation on .Net base-class libraries. How\u00adever, other \ntechniques, such as constraint-based techniques [27] or counter instrumentation enabled iterative .xed-point \ncomputation based techniques [15, 19] can also be used for generating ranking functions. Clearly, there \nare examples where the constraint-based or iterative techniques that perform precise arithmetic reasoning \nwould be more precise, but nothing beats the versatility of sim\u00adple pattern matching that can handle \nnon-arithmetic patterns with equal ease. We list below some patterns that we found to be most effective. \n 6.1 Arithmetic Iteration Patterns One standard way to iterate over loops is to use an arithmetic counter. \nRanking functions for such an iteration pattern can be computed using the following pattern. If s . (e> \n0 . e[xn{/nx] <e), then e . RankC(s) The candidates for expression e while applying the above pat\u00adtern \nare restricted to those expressions that only involve variables from nx and those that occur syntactically \nas an operator of con\u00additionals when normalized to the form (e> 0), after rewriting a conditional of \nthe form (e1 >e2) to (e1 - e2 > 0). In the fol\u00adlowing we give example transitions whose ranking functions \ncan be computed using an application of this pattern. RankC(i{=i+1 . i<n . i<m . n{=n . m{=m)={n-i,m-i} \nRankC(n> 0 . n{ = n . A[n]= A[n{]) = {n} The second example transition above (obtained from the transition \nsystem generated for the loop in the example program Ex3 in Fig\u00adure 2) is a good illustration of how \nsimple pattern matching is used to guess a ranking function, and an SMT solver (that can reason about \ncombination of theory of linear arithmetic and theory of ar\u00adrays) can be used to perform the relatively \ncomplicated reasoning of verifying the ranking function over a loop-free code fragment. Another common \narithmetic pattern is the use of a multiplica\u00adtive counter whose value doubles or halves in each iteration \n(as in case of binary search). A more precise ranking function for such a transition can be computed \nby using the pattern below. If s . (e = 1 . e[xn{/nx] = e/2), then log e . RankC(s) The candidates for \nexpression e while applying the above pat\u00adtern are restricted to those expressions that only involve \nvariables from nx and those that occur syntactically as an operator of con\u00additionals when normalized \nto the form (e> 1), after rewriting a conditional of the form (e1 >e2) that occurs in s to ( e1 > 1), \n e2 provided e2 is known to be positive. In the following we give ex\u00adample transitions whose ranking \nfunctions can be computed using an application of this pattern. RankC(i{ = i/2 . i> 1) = {log i}  RankC(i{ \n=2\u00d7i . i> 0 . n>i . n{ = n)= {log (n/i)}  The above two patterns are good enough to compute ranking \nfunc\u00adtions for most loops that iterate using arithmetic counters. However, for the purpose of completeness, \nwe describe below two examples (taken from some recent work on proving termination) that can\u00adnot be matched \nusing the above two patterns, and hence illustrate the limitations of pattern-matching. However, we can \n.nd ranking functions or bounds for these examples using the counter instru\u00admentation and invariant generation \ntechniques described in [15]. {{ Consider the terminating transition system (x= x + y . y= y +1 . x<n \n. n{ = n) from [6], which uses the principle of polyranking lexicographic functions for proving its termination. \nNote that the reason why the transition system terminates is because even though y is not known to be \nalways positive, it will eventually become positive by virtue of the assignment y{ = y +1. {{ Consider \nthe terminating transition system (x= y . y= x-1.x> 0). This transition system can be proven terminating \nby monotonicity constraints as introduced in [3]). Note, that the reason why the transition system terminates \nis because in every two iterations the value of x decreases by 1.  6.2 Boolean Iteration Patterns Often \nloops contain a path/transition that is meant to execute just once. The purpose of such a transition \nis to switch between different phases of a loop, or to perform the cleanup action immediately before \nloop termination. Such an iteration pattern can be captured by the following rule/lemma, where the operator \nBool2Int(e) maps boolean values true and false to 1 and 0 respectively. If s . (e .\u00ac(e[xn{/nx])), then \nBool2Int(e) . RankC(s) The candidates for boolean expression e while applying the above pattern are restricted \nto those expressions that only involve variables from nx and those that occur syntactically in the transition \ns. In the following we give example transitions whose ranking functions can be computed using an application \nof this pattern. RankC(flag{ = false . flag)= {Bool2Int(flag)} RankC(x{ = 100 . x< 100) = {Bool2Int(x< \n100)}  6.3 Bit-vector Iteration Patterns One standard way to iterate over a bit-vector is to change \nthe position of the lsb, i.e., the least signi.cant one bit (or msb, i.e., most signi.cant one bit). \nSuch an iteration pattern can be captured by the following rule/lemma, where the function LSB(x) denotes \nthe position of the least signi.cant 1-bit, counting from 1, and starting from the most signi.cant bit-position. \nLSB(x) is de.ned to be 0 if there is no 1-bit in x. Note that LSB(x) is bounded above by the total number \nof bits in bit-vector x. If s . (LSB(x{) < LSB(x) . x = 0), then LSB(x) . RankC(s) The candidates for \nthe variable x while applying the above pattern are all the bit-vector variables that occur in the transition \ns. The query in the above pattern can be discharged using an SMT solver that provides support for bit-vector \nreasoning, and, in particular, the LSB operator. (If the SMT solver does not provide .rst-class support \nfor the LSB operator, then one can encode the LSB operator using bit-level manipulation as described \nin [31].) In the following we give example transitions whose bound can be computed using the above rule. \n RankC(x{ = x << 1 . x = 0) = {LSB(x)}  RankC(x{ = x&#38;(x - 1) . x = 0) = {LSB(x)}  6.4 Data-structure \nIteration Patterns Iteration over data-structures or collections is quite common, and one standard way \nto iterate over a data-structure is to follow .eld dereferences until some designated object is reached. \nSuch an iter\u00adation pattern can be captured by the following rule/lemma, where the function Dist(x, z, \nf) denotes the number of .eld dereferences along .eld f required to reach z from x. If s . (x = z . (Dist(x{, \nz, f) < Dist(x, z, f))), then Dist(x, z, f) . RankC(s). The candidates for variables x, z and .eld f, \nwhile applying the above pattern are all variables nx and .eld names that occur in s. The query in the \nabove pattern can be discharged using an SMT solver that implements a decision procedure for the theory \nof reachability and can reason about its cardinalities (e.g., [18]). Note, that Dist(x, z, f) denotes \nthe cardinality of the set of all nodes that are reachable from x before reaching z along .eld f. In \nthe following we give example transitions whose ranking functions can be computed using an application \nof this pattern. RankC(x = Null . x{ = x.next)= {Dist(x, Null, next)}  RankC(Mem{=Update(Mem, x.next, \nx.next.next) . x = Null . x.next = Null)= {Dist(x, Null, next)}  7. Bound Computation for Transition \nSystems In this section, we show how to compute a bound for a transition system T . If a transition system \nconsists of a single transition s, then a bound for the transition system can be obtained simply from \nany ranking function r of the transition s using the following theorem. THEOREM 14. Let r . Rank(s). \nThen, Bound(s)= Max(0,r) where the Max operator returns the maximum of its arguments. PROOF: If the \ntransition s is ever taken, then r denotes an upper bound on number of iterations of s (since, by our \nde.nition of a ranking function, transition s implies that r is bounded below by 0 and decreases by at \nleast 1 in each iteration). The other case is when s is never executed (i.e., the number of iterations \nof s is 0). Combining these two cases, we obtain the result. D The signi.cance of sanitizing the bound \nby applying the Max oper\u00adator in Theorem 14 is illustrated in Example 20. Obtaining a bound for a transition \nsystem consisting of multi\u00adple transitions is not as straight-forward. We cannot simply add the ranking \nfunctions of all individual transitions to obtain the bound for the transition system, since the interleaving \nof those transitions with each other can invalidate the decreasing measure of the rank\u00ading function. \nAn alternative can be to de.ne the notion of lexico\u00adgraphic ranking functions [6] or disjunctively well-founded \nranking functions [28] for transition systems consisting of multiple transi\u00adtions. Such an approach may \nsometimes work for proving termina\u00adtion, but would usually not be precise for yielding bounds. For the \npurpose of precise bound computation, we distinguish between the different ways in which two transitions \nof a transition system can interact with each other. These cases (described in Sec\u00adtions 7.1, 7.2, and \n7.3) allow for composing the ranking functions of the two transitions using one of three operators max, \nsum, and product. These cases can be ef.ciently identi.ed asking queries to SMT solvers. 7.1 Max Composition \nof Ranking Functions The bound for a transition system consisting of two transitions s1 . s2 can be obtained \nby applying the Max operator to ranking functions for the individual transitions under cases when the \ntransi\u00adtions are either disjoint, or they decrease each other s ranking func\u00adtions. In fact, the criterion \nis slightly more general, and is formal\u00adized in Theorem 16, which makes use of the following de.nition. \nDEFINITION 15 (Cooperative-interference). We say there is coop\u00aderative interference between transitions \ns1 and s2 through their ranking functions r1 and r2, if any of the conditions below hold: (Non-enabling \ncondition) s1 . s2 = false.  (Rank-decrease condition) s1 . r2[xn{/nx] = Max(r1,r2) - 1. We denote such \na cooperative-interference by CI(s1,r1,s2,r2).  THEOREM 16 (Proof Rule for Max-Composition). Let r1 \n. RankC(s1) and r2 . RankC(s2). If CI(s1,r1,s2,r2) . CI(s2,r2,s1,r1), then Bound(s1 . s2)= Max(0,r1,r2) \nPROOF: We consider four cases below. (1) If both transitions s1 and s2 satisfy the non-enabling condition, \nthen either only tran\u00adsition s1 can execute or only transition s2 can execute. Hence, the result. (2) \nIf both transitions satisfy the rank-decrease con\u00addition, then it can be shown that Max(r1,r2) is a ranking \nfunc\u00adtion for both the transitions s1 and s2. Hence, the result. (3) Now suppose transition s1 satis.es \nthe non-enabling condition, while transition s2 satis.es the rank-decrease condition. The only possibility \nis that a sequence of transitions s2 is followed by a sequence of transitions s1. The result now follows \nfrom the fact that Max(r1,r2) is a ranking function for s2, while r1 is a ranking function for s1. (4) \nThe last case is similar to (3). D EXAMPLE 17. Consider the transition system s1 . s2 from Fig\u00adure 1(i) \nwith the following 2 transitions: def { {{ s1 =(n= n - 1 . j<n . j= j . i= i) def { {{ s2 =(n= n - 1 \n. i<n - 2 . i= i +1 . j= i + 2) We can compute RankC(s1)= {n - j} and RankC(s2)= {n - i - 2}. We can \nprove CI(s1,n - j, s2,n - i - 2) and CI(s1,n - i - 2,s2,n - j). An application of the max-composition \ntheorem yields a bound of Max(0,n - i - 2,n - j) for the transition system s1 . s2.  7.2 Additive Composition \nof Ranking Functions The bound for a transition system consisting of two transitions s1 . s2 can be obtained \nby adding together the ranking functions for the two transitions under cases when the transitions do \nnot interfere with each other s ranking functions. To state this formally (Theorem 19), we .rst de.ne \nthe notion of non-interference of a transition with respect to the ranking function of another transition. \nDEFINITION 18 (Non-interference). We say that a transition s1 does not interfere with the ranking function \nr2 of another transition s2, if any of the following conditions hold:  (Non-enabling condition) s1 . \ns2 = false  (Rank-preserving condition) s1 . (r2[xn{/nx] = r2) We denote such a non-interference by \nNI(s1,s2,r2).  The following theorem holds. We use the notation Iter(s) to denote the total number of \niterations of transition s inside its transition system. THEOREM 19 (Proof Rule for Additive-Composition). \nLet r1 . RankC(s1), r2.RankC(s2). If NI(s1,s2,r2) . NI(s2,s1,r1), then Bound(s1 . s2)= Iter(s1)+ Iter(s2), \nwhere Iter(s1)= Max(0,r1) Iter(s2)= Max(0,r2) PROOF: The non-interference conditions NI(s2,s1,r1) ensure \nthat the value of the ranking function r1 for transition s1 is not increased by any interleaving of transition \ns2. Hence, the total number of iterations of the transition s1 is given by Max(0,r1) (based on an argument \nsimilar to that in proof of Theorem 14). Similarly, the total number of iterations of the transition \ns2 is given by Max(0,r2). Hence, the result. D EXAMPLE 20. Consider the transition system s1 . s2 (obtained \nfrom the loop in the example program Ex6 in Fig. 3) with the following 2 transitions: def s1 = z>x . \nx<n . x{ = x +1 . Same({z, n}) def s2 = z = x . x<n . z{ = z +1 . Same({x, n}) We can compute RankC(s1)= \n{n-x} and RankC(s2)= {n-z}. We can prove NI(s1,s2,n - z) and NI(s2,s1,n - x). An applica\u00adtion of additive-composition \ntheorem yields a bound of Max(0,n - x)+ Max(0,n - z) for the transition system s1 . s2. We now explain \nthe importance of using the Max operators in the statement of Theorem 14 and Theorem 19. If we de.ned \nIter(s) to simply r instead of Max(0,r), then we would incorrectly conclude the bound on the transition \nsystem s1 . s2 to be 2n - x - z. This is incorrect because, for example, suppose that the transition \nsystem was executed in the initial state n = 100,x =0,z = 200, then the expression n - x - z evaluates \nto 0, while the transition system s1 . s2 executes for 100 iterations. This example is also a good illustration \nof how our technique differs signi.cantly from (and, in fact, provides a simpler alterna\u00adtive to) recently \nproposed techniques for proving termination [8] and loop bound analysis [16]. The control-.ow re.nement \ntech\u00adnique used in [16] unravels the exact interleaving pattern between the two transitions to conclude \nthat s1 and s2 interleave in lock\u00adsteps, only after which it is able to derive the bound. In contrast, \nour proof rule stated in Theorem 19 only requires to establish the non-interference property between \nthe two transitions. The prin\u00adciple of disjunctively well-founded ranking functions used in [8] requires \ncomputing the transitive closure of the transition system only to conclude a quadratic bound. In contrast, \nour proof rule stated in Theorem 19 does not require computing any transitive\u00adclosure, and is even able \nto obtain a precise linear bound. (The transitive-closure is required in our technique only to summarize \nany inner nested loops, which, however, are not present in the loop in the example program Ex6). Observe, \nthat the additive-composition and max-composition Theorems provide quite orthogonal proof-rules. The \nbound for the transition system in Example 17 can be computed using the max\u00adcomposition Theorem, but \nnot using the additive-composition The\u00adorem. Similarly, the bound for the transition system in Example \n20 can be computed using the additive-composition Theorem, but not using the max-composition Theorem. \n 7.3 Multiplicative Composition of Ranking Functions If we cannot establish mutual cooperative-interference \nor mutual non-interference properties of two transitions, then it is still possi\u00adble to compute bounds \nprovided one of the transition satis.es the non-interference property. The bound in such a case is obtained \nby multiplying together the ranking functions for the two transitions, as made precise in the following \ntheorem. This is a common case for bounding iterations of an inner loop when its iterators are re\u00adinitialized \ninside the outer loop leading to a multiplicative bound. THEOREM 21 (Proof Rule for Multiplicative-Composition). \nLet r1 . RankC(s1), and r2 . RankC(s2). If NI(s2,s1,r1), then Bound(s1 . s2)= Iter(s1)+ Iter(s2), where \nIter(s1)= Max(0,r1) Iter(s2)= Max(0,r2)+ Max(0,u2) \u00d7 factor where factor = Max(0,r1) where u2(nx) denotes \nan upper bound on expression r2(xn{) in terms of nx as implied by TC(s1). For the special case when (r1 \n> 0) . s2 is unsatis.able, we can choose factor to be 1. PROOF: From the non-interference condition NI(s2,s1,r1), \nwe can conclude that Iter(s1) = Max(0,r1) (the same argument as in the proof of Theorem 19). However, \nthe same thing cannot be s2. Instead we observe that the maximum number of itera\u00adtions of s2 in between \nany two interleavings of s1 is bounded above by Max(0,u2) (since the starting value of the ranking function \nr2 is reset to u2 by any execution of s1). However, the number of iterations of s2 before any interleaving \nof s1 is still bounded by Max(0,r2). Hence, the total number of iterations of s2 is bounded by Max(0,r2)+ \nMax(0,u2) \u00d7 Max(0,r1). The special case follows from the observation that even though s1 interferes with \nthe ranking function r2 of s2, it can interfere at most once since s2 is enabled only after completion \nof all iterations (as opposed to somewhere in the middle) of s1. In other words, the worst-case possibility \nis a sequence of transi\u00adtions s2, followed by a sequence of transitions s1, followed by a sequence of \ntransitions s2. D EXAMPLE 22. Consider the transition system with the following two transitions s1 and \ns2. def s1 = i{=i-1 . i>0 . j{=j-1 . j>0 . Same({k{,m{}) def s2 = j{ = m . k{=k-1 . k> 0 . Same({i{,m{}) \nWe can compute RankC(s1)= {i, j} and RankC(s2)= {k}. We can prove NI(s1,s2,k) and NI(s2,s1,i). An application \nof additive-composition theorem yields a bound of Max(0,i)+ Max(0,k) for the transition system s1 . s2. \nAn application of multiplicative-composition theorem yields an incomparable bound of Max(0,j)+ Max(0,m) \n\u00d7 Max(0,k).  7.4 Combining the Composition Rules In this section, we discuss how to compute bounds for \na transition system with multiple (including more than 2 transitions) by putting together the proof rules \nmentioned in Theorem 16, 19, and 21. First, observe that an optimal way of applying the proof rules in \nadditive-composition Theorem and multiplicative-composition Theorems (Theorem 19 and Theorem 21) is to \ncompute the total number of iterations for each transition individually, and then sum them up together. \nThe algorithm described in Figure 7 implements n e ComputeBound( si) i=1 1 for i .{1,..,n}: Iter[si] \n:= .; 2 do { 3 for i .{1,..,n} and r . RankC(si): 4 J := {j |\u00acNI(sj ,si,r)}; 5 if (Iter[si]= .) . (.j \n. J : Iter[sj ]= .) 6 factor := 0; 7 foreach j . J: factor:=factor+Iter[sj ]; 8 Let u(nx) be an upper \nbound on r[xn{/nx] e as implied by TC( sj ). j=i 9 Iter[si] := Max(0,r)+ Max(0,u) \u00d7 factor{; 10 } while \nany change in Iter array;  11 if (.j .{1,..,n} : Iter[sj ]= .), returnIter[sj ]; j 12 else return \nPotentially Unbounded n e Figure 7. Bound Computation for a Transition System si from i=1 ranking functions \nRankC(si) of individual transitions. such a strategy based on a simple extension of Theorem 19 and Theorem \n21 to the case when a transition system contains more than 2 transitions. The algorithm iteratively computes \nan array Iter such that Iter[si] denotes a bound on the total number of iterations of the transition \nsi during any execution of the transition system s1 ....sn. The array J at Line 4 contains the indices \nof all transitions that interfere with the ranking function r of transition si. If a bound on the total \nnumber of iterations of all those transitions is known (test on Line 5), then the iterations of si is \nobtained using a generalization of Theorems 19 and 21 (Line 9). A bound on the entire transition system \nis obtained by simply summing up the bound on the total number of iterations of the individual transitions \n(Line 11). For simplicity, we have presented the algorithm to output only one bound, but the algorithm \ncan be easily extended to output multiple bounds by relaxing the condition Iter[si]= . in Line 5 and \nby associating a set of bounds (as opposed to a single bound) with Iter[si]. EXAMPLE 23. Consider the \ntransition system s1 . s2 . s3 (ob\u00adtained from the loop in Ex7 in Figure 3) with the following 3 tran\u00adsitions: \ns1 = j<n . j<m . j{=j+1 . 0 <n<m . Same({n, m}) s2 = j>n . j<m . j{=j+1 . 0 <n<m . Same({n, m}) s3 = \nj = m . j{ =0 . 0 <n<m . Same({n, m}) We can compute RankC(s1)= {n-j, m-j}, RankC(s2)= {m- j}, RankC(s3)= \n{Bool2Int(j = m)}. Since NI(s1,s2,m - j) and NI(s3,s2,m - j), the algorithm in Figure 7 .rst computes \nIter[s2]= Max(0,m - j). Using NI(s1,s3, Bool2Int(j = m)), the algorithm now computes Iter[s3]= Bool2Int(j \n= m) \u00d7 (1 + 1) = 2. From NI(s2,s1,n - j), the algorithm now computes Iter[s1]= Max(0,n - j)+ Max(0,n) \n\u00d7 2. The algorithm now returns a total bound of Max(0,m - j)+2+ Max(0,n - j)+ Max(0,n) \u00d7 2. This bound \ncan be translated to a bound in terms of the inputs in the example program Ex7 by substituting n +1 for \nj (as obtained from the initial state before the loop) to yield m +1+ n, which is a factor of 2 away \nfrom the real bound of m +1 (since n<m). This example also illustrates how our technique differs signi.\u00adcantly \nfrom (and, in fact, provides a simpler alternative to) recently proposed techniques for termination and \nloop bound analysis. The control-.ow re.nement technique used in [16] uses a sophisticated machinery \nto unravel the exact interleaving pattern between the three transitions (in particular, s2 follows s3 \nwhich in turn follows s1) and is able to obtain the exact bound of m +1. In contrast, our proof rules \nyield a bound of m+1+n, but using a much simpler for\u00admalism. We do not know of any other technique (including \n[8, 19]) that can even prove termination of this example. We now brie.y discuss an extension to the \nabove-described al\u00adgorithm that also takes advantage of the proof rule in the max\u00adcomposition Theorem \n(Theorem 16). Before running the algorithm, { we extend RankC(s) for any transition s with Max(r, r), \nwhere {{{ r . RankC(s) and r. RankC(s) for some other transition s, { provided Rank(s, Max(r, r)) holds. \nThis allows for an application of additive-composition Theorem to obtain an additive bound that is a \nconstant factor of 2 away from what would have been obtain\u00adable from application of the max-composition \nTheorem (but much better than a multiplicative-bound). A more complete scheme that directly takes advantage \nof the max-composition Theorem is a bit involved and is left out for lack of space. 8. Experiments We \nhave implemented our proposed solution to the reachability\u00adbound problem in C# using the Phoenix Compiler \nInfrastruc\u00adture [26] and the SMT solver Z3 [1]. This implementation is part of a tool that computes symbolic \ncomplexity for procedures in .Net bi\u00adnaries. Below we present two different sets of experimental results \nthat measure the effectiveness of various aspects of our solution. 8.1 Loop Bound Computation We considered \nthe problem of computing symbolic bounds on the number of loop iterations, which is an instance of the \nreachability\u00adbound problem where the control location under consideration is the loop header. We chose \nmscorlib.dll (a .Net base-class library), which had 2185 loops, as our benchmark. Our tool analyzes these \n2185 loops in less than 5 minutes and is able to compute bounds for 1677 loops. The problem of loop bound \ncomputation is espe\u00adcially challenging under the following two cases for which earlier techniques for \nbound computation do not perform as well. Case 1: Iterations of outer loops depending on inner loops \n(exam\u00adples of the kind described in Figure 2). There were 113 such loops out of the total 2185 loops. \nThe key idea of our paper to address such challenges is to replace the inner loops by their transitive\u00adclosure \nthat preserves required relationships between the inputs and outputs of the loop. The effectiveness of \nour transitive closure com\u00adputation algorithm is illustrated by the fact that our success ratio for such \ncases (80 out of 113, i.e., 70%) is similar to our overall success ratio (1677 out of 2185, i.e., 76%). \nCase 2: Loop bound computation for nested loops. The challenge here is to compute precise amortized bounds \non the total number of iterations of those loops, as opposed to the number of iterations per iteration \nof the immediate outer loop (the latter is an easier problem than the former). This is the same issue \nas exempli.ed by the example in Figure 1. There were 250 such loops out of the to\u00adtal 2185 loops. Unfortunately, \nwe cannot evaluate the precision of our bounds automatically. As described in Section 3, the problem \nof computing a precision-witness for a given symbolic bound is an orthogonal problem that we are currently \nworking on. Instead, we manually investigated the generated bounds for most of these loops and found \nall these bounds to be precise (according to De.ni\u00adtion 2). This points out the effectiveness of our \nbound-computation algorithm based on the three proof rules presented in Section 7. Another interesting \nstatistic is the distribution of the number of transitions generated for each loop, as shown in Figure \n8. The small number of transitions validates the design choice behind our transition system generation \nalgorithm that enumerates all paths Figure 8. Number of loops for respective number of transitions. \n# Transitions 1 2 3 4 5 6 7 8 9 =10 # Loops 1561 224 107 44 25 11 9 5 8 191 between two program points \n(in order not to loose any precision) after slicing has been performed. Out of the 508 loops for which \nwe failed to compute a bound, the failure for 503 loops is attributed to not being able to com\u00adpute ranking \nfunctions for some transition in the transition sys\u00adtem corresponding to the loop. There were two main \ncauses. (i) Our implementation is intra-procedural, meaning that our transi\u00adtion system generation algorithm \nfails when the value of loop iter\u00adators gets modi.ed because of procedure calls. This problem can be \naddressed by simply inlining the procedure, provided there are no recursive calls. (ii) Of the various \nproof rules described in Sec\u00adtion 6, we only implemented those corresponding to arithmetic and boolean \niteration patterns, while several transitions were iterating using .eld dereferences or bit-vector manipulation. \nA sound han\u00addling of .eld dereferences would require use of an alias analysis. A more optimistic way \nto read this statistic is to observe the effective\u00adness of the proof-rule based technique for .nding \nranking functions : a handful of patterns are suf.cient to compute ranking functions for transitions \narising in 76% of the examples. There were only 5 cases (out of 1682 cases) for which we were able to \ncompute a ranking function for each transition, but were not able to compute a bound for the transition \nsystem. This points out the effectiveness of our proof rules for bound computation from composition of \nranking functions of individual transitions. 8.2 Disjunctive Invariant Computation We also evaluated \nthe effectiveness of our transitive closure algo\u00adrithm on a variety of benchmark examples chosen by recent \nstate\u00adof-the-art papers on computing disjunctive invariants. Figure 9 de\u00adscribes these four examples \nthat have been used as .agship exam\u00adples to motivate new techniques for proving non-trivial safety as\u00adsertions. \nProving validity of the assertions in all these examples re\u00adquires disjunctive loop invariants. It turns \nout that the required dis\u00adjunctive invariant for each of these examples satis.es the convexity\u00adlike assumption, \nand hence can be discovered by our transitive clo\u00adsure algorithm in Figure 6. We adapt our algorithm \nslightly to take advantage of the initial condition (as is done by all the other ap\u00ad { proaches) by \ninitializing s1 to Init . Id at Line 2, instead of only Id since Init is known at the beginning of each \nloop. This allows our algorithm to establish the desired assertion using a disjunctive invariant with \nfewer disjuncts. (For a more detailed discussion on this adaptation, see the end of this section). Given \nthat the number of disjuncts in the desired transitive closure is 2 for all examples, and that the number \nof transitions in the transition system represented by the loop is either 2 or 3, the total number of \npossibilities for the map s is 16 or 64 respectively. Hence, by trying out all possible maps, the algorithm \nin Figure 6 can discover the desired disjunctive invariants. Instead, we experimented with a heuristic \nfor dynamic construc\u00adtion of map s that we found to be effective for all examples. We { choose m =1 \nand initialize s1 to Init . Id. We maintain a par\u00adtial map s that is completely unde.ned to start with, \nand use the following heuristic to construct s on the .y. For each choice of (i, j) on Line 4 in the \nalgorithm, if s(j, i) is unde.ned, we com\u00ad { pute s = sj . si in the abstract domain. If s is not equal \nto false, then we use a semantic-merging criterion to .nd any k such that { s is close to an existing \ndisjunct sk and de.ne s(j, i) to be k. If no such k exists, we increase m by 1 and de.ne s(j, i) to the \nnew value of m. The semantic-merging criterion that we used for our experiments was one that checks agreements \non variable equalities (as opposed to the more general inequality relationships expressible Original \nExample Various Details Gopan and Reps 06. P. 3, F. 1 x:=0, y:=0; while (*) if (x = 50) y++; else y--; \nif (y<0) break; x++; assert(x=102) (x = 50.y+1 = 0.yl = y+1.xl = x+1)s1 .(x > 50 . y - 1 = 0 . yl = y \n- 1 . xl = x + 1)s2 Init = x = 0 . y = 0 (0 = xl = 51 . xl = yl)sl1 .(52 = xl = 102 . xl + yl = 102)sl2 \nd = 1, s = {(1, 1) . 1, (1, 2) . 2, (2, 2) . 2, (2, 1) . 1} Beyer et al. 07. P. 306, F. 4. x:=0; y:=50; \nwhile (x<100) if (x<50) x++; else x++; y++; assert(y=100); (x = 50 . xl = x + 1 . yl = y)s1 .(51 = x \n= 100.xl = x+1.yl = y +1)s2 Init = x = 0 . y = 50 (0 = xl = 50 . yl = 50)sl1 .(51 = xl = 100 . xl = yl)sl2 \nd = 1, s = {(1, 1) . 1, (1, 2) . 2, (2, 2) . 2, (2, 1) . 1} Gulavani et al. 06. P. 5, F. 3. Henzinger \net al. 02. P. 2, F. 1. lock:=0;assume(x = y) while (x = y) lock := 1; x := y; if (*) lock := 0; y++; \nassert(lock = 1); (x = y . lockl = 1 . xl = y . yl = y)s1 .(x = y .lockl = 0.xl = y .yl = y +1)s2 Init \n= x = y . lock = 0 (x l = yl . lockl = 1)sl1 .(xl + 1 = yl . lockl = 0)sl2 d = 1, s = {(1, 1) . 1, (2, \n1) . 1, (1, 2) . 2, (2, 2) . 2} Popeea and Chin 06. P. 2 x := 0; upd := 0; while (x < N) if (*) l := \nx; upd := 1; x++; assert(upd = 1 . 0 = l < N); (x < N .x l = x+1.ll = l.updl = upd)s1 .(x < N .xl = x+1.ll \n= x.updl = 1)s2 Init = x = 0 . upd = 0 (xl = 0 . ll = l . updl = 0 . Nl = N)sl 1 .(xl = 1.updl=1 . Nl=N.0 \n= ll < N)sl2 d = 1, s = {(1, 1) . 1, (1, 2) . 2, (2, 2) . 2, (2, 1) . 2} Figure 9. Prominent disjunctive \ninvariant challenges from recent literature. Entries in 2nd column show the following details in that \norder: transition-system representation of the loop, initial condition Init, transitive closure of the \ntransition-system required to prove the assertion, and the convexity-witness (d, s). in the octagon domain \n[24] used by our prototype implementation). This heuristic is an excellent example of combining the strengths \nof semantic-merging criterions in the light of the importance of hav\u00ading a static syntactic merging criterion \nas suggested by Theorem 12 (if we do not want to iterate over all maps s). We implemented this heuristic \nand our prototype implementation is able to validate the assertion in each of the examples in less than \n0.2sec. We now return to the discussion on what would happen if we do not adapt our algorithm to make \nuse of the initial condition Init while computing a loop summary. We can still prove the desired assertion, \nbut the required transitive closure would consist of more disjuncts, and would involve elements from \na numerical domain richer than the octagon abstract domain. For example, for the .rst example, we would \nrequire the following disjunctive invariant: (Id)l. (x = 50 . x{ = 51 . x{ - x = y{ - y)l ss 12 . (x \n= 51 . x{ = 52 . x{ - x = y{ - y)l s 3 . (x = 50 . x{ = 52 . 102 - x{ - x = y - y{)l s 4 Observe, that \nthe above invariant again satis.es the convexity\u00adlike assumption, where a convexity-witness s is as follows: \ns = {(1, 1) . 2, (2, 1) . 2, (3, 1) . 3, (4, 1) . 4, (1, 2) . 3, (2, 2) . 4, (3, 2) . 3, (4, 2) . 4}. \nHence, our approach can be used to discover this invariant. In contrast, none of the techniques presented \nfor the respective examples can analyze the loops in such a modular setting where the initial condition \nis not initially known. Further discussion on the use of our technique for modular analysis is beyond \nthe scope of this paper. 9. Comparison with Related Work Disjunctive Invariant Generation A variety \nof techniques exist to lift classical abstract domains (like intervals, octagons [24], and polyhedra \n[10]), which typically infer conjunctive invariants, to the powerset extension or some approximation \nof it for discovering disjunctive invariants [20, 29, 13, 14]. These techniques address the hardness \ninherent in this problem by proposing various semantic\u00admerging heuristics. In contrast, we present a \nresult that calls for working with a static syntactic merge criterion under the convexity\u00adlike assumption \n(which appears to be satis.ed by the benchmark examples). Some syntactic techniques based on program \nrestriction [5] or control-.ow re.nement [16] have also been suggested for discov\u00adering disjunctive invariants. \nThese can be viewed as instantiations of our more general framework based on a convexity-witness s. Symbolic \nBound Generation There is recent work on generating symbolic bounds on the number of loop iterations \n[16, 19, 15, 2], but none of these techniques directly addresses the more general problem of reachability-bound \nthat we introduce in our paper. Our solution reduces the reachability-bound problem to the problem of \ncomputing bounds of an outer loop, but one whose iterations are in.uenced by inner loops. None of [16, \n19, 15, 2] directly address the challenge of computing bounds for such loops, and hence would fail to \ncompute bounds for most of the examples presented in the paper. In contrast, our technique can compute \nbounds for all the motivating examples presented in [16, 19, 15, 2]. [19] would fail to compute bounds \nfor the example programs Ex1, Ex3, Ex4, Ex5, Ex7 because the invariants required for estab\u00adlishing bounds \non the counters are disjunctive. (It can only compute bounds for Ex2 and Ex6.) The multiplicative counter \ninstrumenta\u00adtion strategies that are meant to alleviate the problem of computing disjunctive invariants \ndo not help in this case because there is only one back-edge for the outer loop and only one counter \ncan be in\u00adstrumented. [16] would fail to compute bounds for Ex1, Ex3, Ex4, Ex5 for the same reason of \nrequiring disjunctive invariants for performing the desired reasoning on inner loops. (It can only compute \nbounds for Ex2, Ex6 and Ex7.) The control-.ow re.nement strategy is meant to alleviate the problem of \ncomputing disjunctive invariants, but it does not help in any of these cases since the control-.ow is \nalready re.ned, and it cannot be re.ned any further. [15] requires user annotations to identify interesting \nnon-linear and disjunctive expressions to compute bounds for transition sys\u00adtems with multiple transitions. \nWe address these challenges by means of novel proof rules. However, the technique described in [15] can \nbe used in a synergistic manner with our technique, in particular, as an extension to the pattern-matching \nbased tech\u00adnique to compute bounds/ranking-functions for single transitions. [2] computes bounds by generating \nrecurrence relations and then deriving a closed form expression for the maximum size of the unfoldings \nof the recurrence relations into trees. Since they do not precisely summarize inner loops, they cannot \nhandle loops where the inner loop changes the iterators of the outer loop as in the example programs \nEx2, Ex3, Ex4, Ex5. Also, they can t handle examples Ex6, Ex7 and are unable to compute the amortized \ncomplexity as in the example program Ex1. We report the .rst implementation of symbolic bound genera\u00adtion \nfor .Net binaries, while [19, 16, 15] and [2] implemented bound generation for C++ and Java programs \nrespectively. Hence, we only provide analytical (not experimental) comparison with these tech\u00adniques. \nQuite signi.cantly, our implementation scales to large pro\u00adgrams, while [19, 15, 2] have been applied \nto only small bench\u00admarks. [12] computes symbolic bounds by curve-.tting timing data ob\u00adtained from \npro.ling. Their technique has the advantage of measur\u00ading real time in seconds for a representative workload, \nbut does not provide worst-case bounds. There is a large body of work on es\u00adtimating worst case execution \ntime (WCET) in the embedded and real-time systems community [30, 32]. WCET research is largely orthogonal, \nfocused on distinguishing between the complexity of different code-paths and low-level modeling of architectural \nfea\u00adtures such as caches, branch prediction, instruction pipelines. For establishing loop bounds, WCET \ntechniques either require user an\u00adnotation, or use simple techniques based on pattern matching or simple \nnumerical analysis. These WCET techniques cannot com\u00adpute bounds for most of the examples considered \nin this paper. [11] presents a type system for the certi.cation of resource bounds (once they are provided \nby the programmer). In contrast, we infer bounds. [22] uses linear programming to infer bounds for functional \nprograms, but they are restricted to computing only linear bounds. Termination Analysis There has been \na large body of work on proving termination of programs and the standard approach used has been that \nof .nding ranking functions. We also use ranking functions to compute bounds, but our focus is on .nding \nprecise ranking functions, using composition by Max or + operators if possible, that can yield precise \nsymbolic bounds. Bounds can also be obtained from the standard lexicographic ranking functions or disjunctively \nwell-founded ranking relations [8], but only using multiplicative-composition, which is imprecise compared \nto the bounds that can be obtained from max-or additive-composition. In fact, our proof rules can also \nbe regarded as an alternative new technique for proving termination. For example, the recently proposed \napproach based on variance assertions or disjunctively well-founded ranking relations cannot be used \nto prove termination of the loop in the example program Ex7, while our technique can. There is super.cial \nsimilarity between termination techniques based on computing variance assertions [4], transition invari\u00adants \n[28] and disjunctively well-founded ranking relations [8] in that they also summarize relationships between \ntwo different visits to a control location, and often require disjunctive invariants. How\u00adever, there \nare two key technical differences: (a) Our technique re\u00adquires computing relationships between two immediate \nvisits to a control location, while the approach based on transition invariants or variance assertions \nrequires computing relationships between any two visits to a control location. (b) Our technique requires \nuse of disjunctive invariants only to summarize nested loops. 10. Future Work and Conclusion This paper \nde.ned and motivated the reachability-bound problem. The paper also presented a solution to the reachability-bound \nprob\u00adlem in the context of non-recursive and sequential programs. The next technical challenge is to \naddress the reachability-bound prob\u00adlem in context of recursive procedures and concurrent execution. \nOn the applications side, we are working on integrating the proposed solution to the reachability-bound \nproblem with other speci.c techniques to provide an integrated solution for resource bound analysis in \nsome contexts such as memory bound analysis, and active-task graph size analysis in asynchronous programs. \nReferences [1] Z3 Theorem Prover. research.microsoft.com/projects/Z3/. [2] E. Albert, P. Arenas, S. Genaim, \nand G. Puebla. Automatic inference of upper bounds for recurrence relations in cost analysis. In SAS, \n2008. [3] A. M. Ben-Amram. Size-change termination, monotonicity con\u00adstraints and ranking functions. \nIn CAV, pages 109 123, 2009. [4] J. Berdine, A. Chawdhary, B. Cook, D. Distefano, and P. O Hearn. Variance \nanalyses from invariance analyses. In POPL, 2007. [5] D. Beyer, T. A. Henzinger, R. Majumdar, and A. \nRybalchenko. Path invariants. In PLDI, pages 300 309, 2007. [6] A. Bradley, Z. Manna, and H. Sipma. Termination \nof polynomial programs. In VMCAI, 2005. [7] S. Chaudhuri, S. Gulwani, and R. Lublinerman. Continuity \nanalysis of programs. In POPL, 2010. [8] B. Cook, A. Podelski, and A. Rybalchenko. Termination proofs \nfor systems code. In PLDI, pages 415 426, 2006. [9] P. Cousot and R. Cousot. Abstract Interpretation: \nA Uni.ed Lattice Model for Static Analysis of Programs by Construction or Approxi\u00admation of Fixpoints. \nIn POPL, pages 238 252, 1977. [10] P. Cousot and N. Halbwachs. Automatic Discovery of Linear Re\u00adstraints \namong Variables of a Program. In POPL, 1978. [11] K. Crary and S. Weirich. Resource bound certi.cation. \nIn POPL 00. [12] S. Goldsmith, A. Aiken, and D. S. Wilkerson. Measuring empirical computational complexity. \nIn ESEC/SIGSOFT FSE, 2007. [13] D. Gopan and T. W. Reps. Lookahead widening. In CAV, 2006. [14] D. Gopan \nand T. W. Reps. Guided static analysis. In SAS, 2007. [15] B. S. Gulavani and S. Gulwani. A numerical \nabstract domain based on expression abstraction and max operator with application in timing analysis. \nIn CAV, pages 370 384, 2008. [16] S. Gulwani, S. Jain, and E. Koskinen. Control-.ow re.nement and progress \ninvariants for bound analysis. In PLDI, 2009. [17] S. Gulwani and S. Juvekar. Bound analysis using backward \nsymbolic execution. Technical report, Oct 2009. [18] S. Gulwani, T. Lev-Ami, and M. Sagiv. A combination \nframework for tracking partition sizes. In POPL, 2009. [19] S. Gulwani, K. Mehra, and T. Chilimbi. Speed: \nprecise and ef.cient static estimation of program computational complexity. In POPL 09. [20] M. Handjieva \nand S. Tzolovski. Re.ning static analyses by trace\u00adbased partitioning using control .ow. In SAS, pages \n200 214, 1998. [21] T. Henzinger. From boolean to quantitative system speci.cations, keynote. In Ist \nWorkshop on Quantitative Analysis of Software. http://research.microsoft.com/users/sumitg/qa09/keynote.pdf, \n2009. [22] S. Jost, H. Loidl, K. Hammond, and M. Hofmann. Static determination of quant. resource usage \nfor higher-order programs. In POPL 10. [23] P. Malacaria. Assessing security threats of looping constructs. \nIn POPL, pages 225 235, 2007. [24] A. Min\u00b4 e. The octagon abstract domain. In WCRE, 2001. [25] S. S. \nMuchnick. Advanced Compiler Design and Implementation. Morgan Kaufmann, 1997. [26] Microsoft Phoenix \nCompiler, research.microsoft.com/phoenix/. [27] A. Podelski and A. Rybalchenko. A complete method for \nthe synthesis of linear ranking functions. In VMCAI 04. [28] A. Podelski and A. Rybalchenko. Transition \ninvariants. In LICS 04. [29] C. Popeea and W.-N. Chin. Inferring disjunctive postconditions. In ASIAN, \npages 331 345, 2006. [30] A. Prantl, J. Knoop, M. Schordan, and M. Triska. Constraint solving for high-level \nwcet analysis. CoRR, 2009. [31] H. S. Warren. Hacker s Delight. Addison-Wesley Longman Publish\u00ading Co., \nInc., Boston, MA, USA, 2002. [32] R. Wilhelm, J. Engblom, A. Ermedahl, N. Holsti, S. Thesing, D. Whal\u00adley, \nG. Bernat, C. Ferdinand, R. Heckmann, F. Mueller, I. Puaut, P. Puschner, J. Staschulat, and P. Stenstr\u00a8The \nDetermination of om. Worst-Case Execution Times Overview of the Methods and Survey of Tools. In ACM Transactions \non Embedded Computing Systems (TECS), 2007.    \n\t\t\t", "proc_id": "1806596", "abstract": "<p>We define the <i>reachability-bound problem</i> to be the problem of finding a symbolic worst-case bound on the number of times a given control location inside a procedure is visited in terms of the inputs to that procedure. This has applications in bounding resources consumed by a program such as time, memory, network-traffic, power, as well as estimating quantitative properties (as opposed to boolean properties) of data in programs, such as information leakage or uncertainty propagation. Our approach to solving the reachability-bound problem brings together two different techniques for reasoning about loops in an effective manner. One of these techniques is an abstract-interpretation based iterative technique for computing precise disjunctive invariants (to summarize nested loops). The other technique is a non-iterative proof-rules based technique (for loop bound computation) that takes over the role of doing inductive reasoning, while deriving its power from the use of SMT solvers to reason about abstract loop-free fragments.</p> <p>Our solution to the reachability-bound problem allows us to compute precise symbolic complexity bounds for several loops in .Net base-class libraries for which earlier techniques fail. We also illustrate the precision of our algorithm for disjunctive invariant computation (which has a more general applicability beyond the reachability-bound problem) on a set of benchmark examples.</p>", "authors": [{"name": "Sumit Gulwani", "author_profile_id": "81100315615", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P2184566", "email_address": "", "orcid_id": ""}, {"name": "Florian Zuleger", "author_profile_id": "81413607185", "affiliation": "TU Vienna, Vienna, Austria", "person_id": "P2184567", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806630", "year": "2010", "article_id": "1806630", "conference": "PLDI", "title": "The reachability-bound problem", "url": "http://dl.acm.org/citation.cfm?id=1806630"}