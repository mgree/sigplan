{"article_publication_date": "06-05-2010", "fulltext": "\n Safe Programmable Speculative Parallelism Prakash Prabhu G. Ramalingam Kapil Vaswani Princeton University \nMicrosoft Research, India pprabhu@cs.princeton.edu kapilv,grama@microsoft.com Abstract Execution order \nconstraints imposed by dependences can serialize computation, preventing parallelization of code and \nalgorithms. Speculating on the value(s) carried by dependences is one way to break such critical dependences. \nValue speculation has been used effectively at a low level, by compilers and hardware. In this paper, \nwe focus on the use of speculation by programmers as an algorithmic paradigm to parallelize seemingly \nsequential code. We propose two new language constructs, speculative compo\u00adsition and speculative iteration. \nThese constructs enable program\u00admers to declaratively express speculative parallelism in programs: to \nindicate when and how to speculate, increasing the parallelism in the program, without concerning themselves \nwith mundane im\u00adplementation details. We present a core language with speculation constructs and mutable \nstate and present a formal operational semantics for the language. We use the semantics to de.ne the \nnotion of a correct speculative execution as one that is equivalent to a non-speculative execution. In \ngeneral, speculation requires a runtime mechanism to undo the effects of speculative computation in the \ncase of mis\u00adpredictions. We describe a set of conditions under which such rollback can be avoided. We \npresent a static analysis that checks if a given program satis.es these conditions. This allows us to \nimplement speculation ef.ciently, without the overhead required for rollbacks. We have implemented the \nspeculation constructs as a C# library, along with the static checker for safety. We present an empirical \nevaluation of the ef.cacy of this approach to parallelization. Categories and Subject Descriptors D.1.3 \n[Programming Tech\u00adniques -Concurrent Programming]: Parallel Programming; D.3.3 [Programming Languages \n-Language Constructs and Features]: Concurrent Programming Structures General Terms Languages Keywords \nspeculative parallelism, value speculation, safety, pu\u00adrity, rollback freedom 1. Introduction Speculation \nrefers to the act of taking risks in anticipation of re\u00adward. While speculation is almost second nature \nof humans, it has been recognized as an important system design principle [12]. Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 10, June 5 10, 2010, Toronto, Ontario, \nCanada. Copyright c . 2010 ACM 978-1-4503-0019-3/10/06. . . $10.00 Many high performance systems such \nas microprocessors, .le sys\u00adtems, and databases use speculation to improve performance. Mi\u00adcroprocessors, \nfor example, speculate past branch instructions, pre\u00addict memory addresses, and cache frequently used \ndata to improve performance. Software transactions and futures use speculation to increase parallelism \nin programs. In this paper we focus on the use of value speculation to achieve parallelism. Value speculation \nis a mechanism for increasing paral\u00adlelism by predicting values of data dependencies between tasks. Value \nspeculation is by no means a new concept. Compiler writers and computer architects have investigated \nthe use of value specula\u00adtion for extracting instruction-level parallelism. This type of value speculation \nis completely transparent to the programmer and the compiler/processor decide when and how to speculate. \nIn this paper, however, we focus on the use of speculation by programmers as an algorithm design idiom \nto parallelize seemingly sequential code. We show, using real world examples, that value speculation \ncan be used to extract thread level parallelism and de\u00advelop speculatively parallel algorithms. This \nmotivates our devel\u00adopment of language features that enable programmers to conve\u00adniently express such \nspeculatively parallel algorithms and to declar\u00adatively expose value speculation opportunities, without \nconcerning themselves with mundane implementation details. We show how these constructs can be implemented \nef.ciently, relying on static safety checkers to avoid expensive runtime mechanisms. 1.1 Speculatively \nParallel Algorithms Examples Of Inherently Sequential Algorithms. We start with some motivating examples. \nLexical analysis is the problem of con\u00adverting a sequence of characters into a sequence of tokens, encoded \nas a .nite state machine (FSM). Given an FSM and a sequence of characters, lexical analysis starts in \nthe initial state and processes characters one at a time. At every step, the analyzer transitions to \nthe next state in the FSM based on the character just read. When the analyzer reaches a .nal state, it \nemits a token, resets its state to the initial state and continues processing the rest of the sequence. \nAs a second example, consider Huffman decoding. Huffman coding is a widely used data compression technique \nthat uses a variable length binary encoding. Given a document, the encoder constructs a binary tree representing \ncodes for all symbols in the document as well as a binary string representing the document. The decoder \nwalks the binary tree starting at the root, matching bits in the compressed data with bits on the tree \nedges. When a leaf is reached, the symbol corresponding to the leaf is emitted and decoding continues \nfrom the root and the next available input bit. A common feature of both these algorithms is the presence \nof a data dependence between successive iterations in the computation. In lexical analysis, the source \nof the dependence is the FSM state: each iteration uses the state value computed by the previous iter\u00adation. \nSuch dependences prevent a straightforward parallelization of the algorithm. Recent studies show that \nsuch computations are not hard to .nd [3]. These computations are often key components  Figure 1. Value \nspeculation of large applications such as browsers, databases, games, media players and machine learning \napplications. If not parallelized, they inhibit performance of these applications as a whole. Speculative \nParallel Composition. We now illustrate how se\u00adquential algorithms such as lexical analysis can be parallelized \n[8] with the use of value prediction. The task of lexical analysis of an input sequence c1 \u00b7\u00b7\u00b7 cn can \nbe decomposed into two subtasks, the analysis of a segment c1 \u00b7\u00b7\u00b7 ck and the analysis of a second segment \nck+1 \u00b7\u00b7\u00b7 cn. Unfortunately, the second subtask needs the FSM state computed by the .rst subtask as input \nand cannot be run in parallel with the .rst subtask. This is an instance of a common scenario, depicted \nabstractly in Fig. 1. A computation P produces a value and a dependent com\u00adputation C consumes the value. \nThis data dependence between P and C serializes the execution of P and C. Value speculation in\u00advolves \npredicting the value computed by P ahead of time and us\u00ading the predicted value to execute C speculatively \nand concurrently with P . When P completes execution, we validate the prediction by checking the actual \nvalue computed by P and the predicted value. If the values match, we gain performance because the execution \nof P and C overlapped in time. However, if the values do not match, corrective action must be taken and \nC must be re-executed with the correct value to preserve semantics. We can use this idea to obtain a \nspeculatively parallel lexical analysis algorithm, as long as we have some means of predicting the FSM \nstate at the end of the .rst subtask (i.e., after processing the .rst input segment c1 \u00b7\u00b7\u00b7 ck). Whenever \nthe prediction is correct, the segments are processed in parallel. Whenever the prediction is incorrect, \nwe effectively have a sequential algorithm (with some added overhead). Speculative Parallel Iteration. \nIt is straightforward to extend the previous idea to partition the input into k segments (e.g., where \nk is chosen based on the number of available processors) and process all k segments in parallel speculatively. \nIn the worst case, it is possible for mis-predictions to produce a cascading effect, forcing corrective \naction and re-execution of all subsequent partitions. However, it is possible for subsequent predictions \nto be correct even when predic\u00adtions for one or more of the previous partitions fail. Therefore, even \nin the presence of mispredictions, we can gain performance as long as the number of mispredictions is \nreasonably small. The Prediction Function. The performance bene.t of specula\u00adtive parallelization depends \ncritically on the accuracy of the value prediction mechanism. A key point to note here is that it is \nnot nec\u00adessary to use a single, generic, value prediction mechanism for ex\u00adploiting speculative parallelism. \nWe believe that, in general, better prediction accuracy can be achieved by using problem-speci.c pre\u00addiction \nfunctions that incorporate domain knowledge and insights. We believe that speculative parallelization \nbased on programmer\u00adspeci.ed prediction functions is a very useful paradigm. In the case of lexical analysis, \nthe state of the lexical analyzer when it is about to process character ck+1 can be predicted quite accurately \nby lexically analyzing just a few characters preceding ck+1 [8]. This prediction scheme relies on the \ninsight that in lexical analysis, some states of the FSM are frequently visited (such as the end of token \nstates). Hence, it is likely that the prediction function, while lexically analyzing a few characters \npreceding ck+1, reaches one of these states at the same character as the sequential analysis. If this \nhappens, the prediction function will make the right guess. We were able to come up with accurate prediction \nfunctions for several other problems we looked at as well.  1.2 Language Support For Speculative Parallelism \nEven after an algorithm designer has identi.ed suitable opportuni\u00adties for speculative parallelism and \nreasonably accurate prediction schemes, implementing such speculative algorithms while ensur\u00ading correctness \nand high performance, can be a non-trivial pro\u00adgramming exercise. This is because in existing languages, \nspecu\u00adlation must be expressed using low level primitives such as threads and locks. Tasks such as spawning \nand scheduling speculative and non-speculative computations, checking for mis-predictions, and re-executing \nspeculatively executed code if required, must all be performed manually. A more important concern is \nthat of ensur\u00ading correctness, especially when the implementation uses mutable state. (a) What happens \nto the side-effects of speculatively executed code in the case of mis-prediction? (b) What happens if \nthe pro\u00adducer and consumer access the same mutable state, and at least one of these accesses is a write? \nIn this paper, we propose new language constructs that enable programmers to declaratively express value \nspeculation opportu\u00adnities, as well as the prediction functions, exposing more paral\u00adlelism in the program. \nThe compiler and/or the runtime can take care of the tedious aspects mentioned above, ensuring performance \nand safety. Speci.cally, we enhance a simple language that permits muta\u00adble state with two language constructs, \nspeculative application and speculative iteration. The construct spec pgc is used for the idea of speculative \napplication illustrated earlier: it has three parame\u00adters, identifying a producer,a consumer that depends \non the value produced by the producer and a prediction ( guess ) function that predicts the value computed \nby the producer. The construct specfold fgmn is used for the idea of speculative iteration illustrated \nearlier: it takes four parameters, a function f representing the loop body, a prediction function g, \nand the lower and upper bounds m and n for the iteration. The semantics of these two constructs was informally \ndescribed earlier. In the paper, we present a formal operational semantics for these constructs, which \nwe call the speculative semantics. The notable aspect of this semantics is that any speculative sub\u00adcomputation \nthat used a mis-predicted value is not used, but its side-effects are not undone! We also de.ne a non-speculative \nse\u00admantics for the language. This semantics ignores the speculation hints contained in the speculation \nconstructs and, instead, executes them sequentially. The non-speculative semantics provides us with a \nway to interpret the program as a speci.cation . It serves to de.ne the desired behavior.  Ideally, \nwe would like to ensure that any speculative execution should be equivalent to some non-speculative execution. \nAs a .rst step towards this goal, we formalize the notion of an equivalence between speculative and non-speculative \nexecutions. This formal\u00adization is based on the notion of a dependence-preserving embed\u00adding of a non-speculative \nexecution into a speculative execution, which adapts the notion of con.ict-serializability [23] to support \nspeculation. Several options exist for ensuring equivalence: (a) Use a pure functional language. In the \nabsence of destructive updates, the spec\u00adulative optimizations are inherently safe. (b) Use a static \nchecker to determine whether the use of speculation in a given program con\u00adtext is safe. (c) Use a runtime \nmechanism for detecting con.icts and/or taking corrective action to ensure correctness. A rollback mechanism \nto undo the side-effects of a computation (as used in STMs) is an example of such a runtime solution. \nWe can also use, e.g., a combination of static checking and runtime mechanisms. In this paper, we explore \nthe second option of using a static checker to ensure the safety of speculation in a language that supports \nmutable state. We de.ne a safety condition called rollback freedom for a program. We show that in a program \nthat satis.es rollback freedom, any speculative execution is equivalent to a non\u00adspeculative execution, \neven without any runtime mechanism for logging, con.ict detection and rollback. In a rollback-free program, \nit suf.ces to simply re-execute speculatively executed consumers when mis-predictions occurs. Rollback \nfreedom is weaker than conditions such as side-effect freedom and purity [19] that are traditionally \nused to ensure safety, as it allows certain forms of side\u00adeffects that are quite useful in practice. \nWe .nally describe an inter-procedural, .ow sensitive static analysis that checks for rollback freedom. \nOur analysis uses a .ow\u00adsensitive heap abstraction and an interval abstraction to precisely characterize \nparts of the heap that may be accessed by a given computation. This analysis ensures safe speculative \nparallelism at no runtime complexity and overheads. We have implemented the speculation constructs as \na C# library, along with the static checker for safety. We present an empirical evaluation of the ef.cacy \nof this approach to parallelization.  1.3 Contributions In summary, our paper makes the following contributions: \n We propose new language constructs to enable programmers to express speculative parallelism in programs. \n We present a formal operational semantics for a language that supports mutable state as well as the \nproposed speculation con\u00adstructs. The semantics formalizes an unsafe but ef.cient imple\u00admentation that \ndoes not rollback side-effects of mis-predicted speculative computation. We also present a non-speculative \nse\u00admantics for the language, which we use to de.ne the notion of a correct speculative execution as one \nthat is equivalent to a non-speculative execution.  We present a set of safety conditions (rollback \nfreedom) for a program that guarantee that every speculative execution of the program is correct. We \nalso present a static analysis to check that a program satis.es these safety conditions.  We have implemented \nthe speculation constructs as a C# li\u00adbrary. We present experimental results showing how speculative \nversions of several real-world applications implemented using our library are able to exploit parallelism. \nWe have also imple\u00admented an initial version of our static safety analysis and used it to verify that \nour implementations are correct.  2. A Language for Speculative Parallelism In this section, we present \nthe syntax and semantics of Speculate, a language with explicit support for speculative parallelism. \nThe core language consists of call-by-value lambda calculus with dy\u00adnamically allocatable mutable heap \ncells. Syntax and Informal Semantics. Figure 2(a) presents the ab\u00adstract syntax of Speculate. The language \nincludes constants (inte\u00adger constants as well as arithmetic operators), standard .-calculus expression \nforms such as variables, functions, function application, sequential composition and conditionals. We \nsupport shared mem\u00adory with constructs for memory allocation (new e), assignment (e1 := e2) and memory \ndereferences (!e). The language includes fold expressions, similar to those found in functional languages, \nwhich model a simple form of iteration where each iteration depends on the value computed in the previous \niteration. Informally, fold fslu represents the value fu (\u00b7\u00b7\u00b7 f (l+ 1) (fls) \u00b7\u00b7\u00b7 ) computed by the loop: \nresult := s; for i=ltoudo result := f (i, result); The .rst new construct in the language is speculative \napplication (spec pgc), which we also refer to as speculative composition. This construct takes three \nparameters, a producer p and a predictor g, and a consumer g. Informally, speculative application computes \nthe value of c(p), but does this concurrently with the computation of p by predicting that the value \nof p will be g and computing c(g) and taking corrective action if the prediction fails. The second new \nconstruct is speculative fold (specfold f glu), which we also refer to as speculative iteration). This \ncomputes a fold expression using speculative parallelism. This construct has a signature slightly different \nfrom that of fold: the second parameter g is a prediction function that takes an integer (in the range \nl..u) as a parameter. The value g(l) is taken to be the initial value s used in a fold expression. For \nany i>l, g(i) is the value predicted to be the value of result at the beginning of the i-th iteration \nof the loop described above (that evaluates a fold expression). Operationally, speculative fold executes \nall the iterations of the loop in parallel, using the predicted values, and takes corrective action when \nthe prediction fails. The language does not provide any other parallelism construct. However, the speculation \nconstructs are expressive enough to en\u00adcode common parallel programming patterns. E.g., the parallel \nevaluation construct e1 . e2 is a special case of speculative com\u00adposition with no dependence between \nthe producer and consumer. Similarly, a do all parallel loop is a special case of speculative iter\u00adation \nwith no loop-carried dependence. (These special cases can be encoded using the unit value () as the predicted \nvalue.) Semantic Domains. The execution state of a program is repre\u00adsented by a con.guration H, T consisting \nof a heap H and a set of threads T. A heap is a partial map from locations l to values v.A thread t[e] \nconsists of a thread-id t and an expression e that is being evaluated by the thread. We use the construct \nt1[e1] . \u00b7 \u00b7\u00b7 . tk[ek] to represent the set of threads {t1[e1], \u00b7\u00b7\u00b7 ,tk[ek]} mnemonically, but note that \nthe ordering of these threads is immaterial. The language of runtime expressions is richer than the language \nof expressions allowed by our language, as it includes some auxil\u00adiary constructs we use to de.ne the \nsemantics of the language. The new constructs include wait t and cancel t, where t is a thread\u00adid. wait \nand cancel are used to synchronize between threads and preempt threads in speculative computations. Operational \nSemantics. Fig. 2 presents two different operational semantics for Speculate. Rules C . S de.ne the actual \nsemantics,  (a) Syntax and Semantic Domains x . Var c . Const t . Tid l . Loc v . Val e . Exp H . Heap \n= Loc .. Val e ::= c | x | .x.e | e1 e2 | e1; e2 | if e1 e2 e3 | new e | e1 := e2 | !e | fold ef ei el \neu | spec ep eg ec | specfold ef eg el eu | r r ::= wait t | cancel t | check tp tg tc ec | auxfold ef \neg el eutp v ::= c | x | .x.e | l | t | unit (b) Evaluation Context E ::= [\u00b7] | Ee | vE | E; e | if Ee2 \ne3 | new E | !E | E := e | l := E | spec ep eg E | opk v1 \u00b7\u00b7\u00b7 vi-1 Eei+1 \u00b7\u00b7\u00b7 ek (fold, specfold . op4, \ncheck, auxfold . op5) (c) Common Evaluation Rules (C) [THREAD] [CONTEXT-1] [CONTEXT-2] [APPLY] H,e . \nH. ,e H,e . H. ,e H,t[e] . T . H. ,t[e ] . T. H,t[e] . T . H.,t[e .] . TH,E[e] . H.,E[e .] H,t[E[e]] \n. T . H.,t[E[e .]] . T. H, (.x.e) v . H,e[v/x] [SEQ] [IF-ZERO] [IF-NON-ZERO] [ALLOC] [SET]  c .= 0 l \n/. Dom(H) H, v; e . H, e H, if 0 e2 e3 . H, e3 H, if c e2 e3 . H, e2 H, new v . H[l .. v], l H, l := \nv . H[l .. v], v [GET] H, !l . H, H(l) [FOLD-1] H, fold vf vl > vu vinit vl vu . H, vinit [FOLD-2] H, \nfold vf vinit vl vu vl = vu . H, fold vf ( vf vl vinit) (vl + 1) vu (d) Speculative Evaluation Rules \n(S) [WAIT] [CANCEL] . . . . H,t [wait t] . t[v] . T . H,t [v] . t[v] . TH,t [cancel t] . t[e] . T . \nH,t [()] . T [SPEC-APPLY] tp,tg,tc fresh in T H,t[spec ep eg vc] . T . H,tp[ep] . tg[eg] . tc[vc (wait \ntg)] . t[check tp tg tc vc] . T [CHECK] xp,xg not free in vc H, check tp tg tc vc . H, (.xp,xg.if(xp \n=int xg)(wait tc)(cancel tc; vc xp))(wait tp)(wait tg) [SPEC-ITERATE-1] vl = vu and tg,tb fresh in T \nH,t[specfold vf vg vl vu] . T . H,t[auxfold vf vg (vl + 1) vutb] . tg[vg vl] . tb[vf (wait tg)vl] . T \n[SPEC-ITERATE-2] vl = vu and tg,tb,tc fresh in T H,t[auxfold vf vg vl vutp] . T . H,t[auxfold vf vg \n(vl + 1) vutc] . tg[vg vl] . tb[vf vl (wait tg)] . tc[check tp tg tb (vf vl)] . T [SPEC-ITERATE-3] vl \n>vu H,t[auxfold vf vg vl vutp] . T . H,t[wait tp] . T (e) Non-Speculative Evaluation Rules For Speculative \nConstructs (N) [NONSPEC-APPLY] [NONSPEC-ITERATE] vl = vu H, spec ep eg ec . H, ec ep H, specfold vf vg \nvl vu . fold vf (vg vl) vl vu Figure 2. Syntax and two operational semantics for Speculate. The expressions \nr are used by the runtime; they are not available in the source language. Rules C . S de.ne the speculative \nsemantics. Rules C . N de.ne the non-speculative semantics. . which we call the speculative semantics. \nRules C . N de.ne a se\u00admantics, the non-speculative semantics, that ignores the speculation hints and \nis used subsequently in our discussion of safety. (Seman\u00adtics of primitive arithmetic operations such \nas + are assumed.) Reductions that do not involve multiple threads are described using rules of the simpler \nform H,e . H. ,e ., which indicates that an expression e, with an initial heap H, reduces to e ., transform\u00ading \nthe heap to H. in the process. Reductions involving multiple threads are described using rules of the \nform H, T . H. , T., which indicates that state H; T reduces to state H.; T.. The rule THREAD relates \nthe two forms of reduction rules. Furthermore, the rule also indicates that the scheduling is non-deterministic: \nany thread ready to perform a reduction may be chosen to execute at any point dur\u00ading execution. The \nevaluation of a program e starts in the initial state .; main[e] consisting of an empty heap and a main \nthread evaluating e. As usual, we use evaluation contexts (see Fig. 2(b)) to de.ne the order of evaluation \nwithin an expression. An evaluation context is an expression with a hole, denoted [\u00b7], that identi.es \nthe next reduction to be performed. Given an evaluation context E, let E[e .] denote the expression obtained \nby replacing the hole in E by e .. For any expression e, there is at most one evaluation context E and \na reducible sub-expression e . such that e = E[e .], and this identi.es the sub-expression e . that is \nreduced next. E.g., the de.nition of evaluation context vE indicates that in an application e1e2, the \nsub\u00adexpression e2 is evaluated only after e1 has been reduced to a value v. The CONTEXT rules show how \nthe reduction is performed at the appropriate sub-expression chosen by the evaluation context. Common \nexpression forms such as function application, se\u00adquential composition, conditional expressions and memory \nalloca\u00adtion have standard semantics. The WAIT rule de.nes semantics of wait, a synchronization primitive \nthat allows threads in Speculate to communicate and co-ordinate. The evaluation of wait t in a thread \nt. blocks until t completes evaluation and the expression evaluates to the value computed by t. Observe \nthat the rule permits multiple threads to successfully wait and retrieve the value computed by any thread \nt. A thread t. may abort another existing thread t using the cancel t primitive, as indicated by the \nCANCEL rule. Note that the evaluation of a cancel blocks until the cancellation is success\u00adful. The non-deterministic \nscheduling may permit t to execute any number of reductions before the cancellation completes success\u00adfully. \n(Preemptive cancellation is hard to implement in practice. We discuss the implications of non-preemptive \ncancellation on the semantics of the speculative constructs later in this section.) We now consider the \nsemantics of spec. Rule NONSPEC-APPLY presents a straightforward non-speculative semantics for this con\u00adstruct \nthat ignores the speculation hint. The rule SPEC-APPLY describes the speculative semantics of spec. The \nevaluation of spec ep eg vc proceeds as follows: a producer thread tp starts evaluating ep and a predictor \nthread tg starts evaluating eg. A spec\u00adulative consumer thread tc waits for the predicted value and ap\u00adplies \nthe consumer function vc to the predicted value. The original thread t uses the auxiliary function check \nto coordinate the specu\u00adlative computation, as de.ned by rule CHECK. The check function waits for both \nthe producer and predictor to complete execution, and compares the value produced by these two threads. \nIf they are the same, then the check function waits for the value computed by the speculative consumer. \nOtherwise, the speculative consumer is aborted, and the consumer function is applied to the correct input \nvalue. Some of the key observations about the semantics of spec. We restrict the predicted values to \nbe of type integer, and the equality operator used is the integer equality operator. We use three new \nthreads solely to simplify the description. In an implementation, one new thread (for the predictor and \nspeculative consumer) is suf.cient, while the original thread can evaluate the producer and do the .nal \ncheck.  The evaluation of spec blocks until the producer and the con\u00adsumer complete evaluation.  The \nspeculative executions may behave differently from non\u00adspeculative executions for two reasons. (i) In \nthe speculative semantics, side-effects of speculative consumers are not rolled back in the case of mispredictions. \nThe consumers are simply re-evaluated. (ii) Producers and consumers may also race if they access the \nsame shared state. As explained later, we rely on a static analysis to ensure correct speculation . \n In the presence of speculation, scheduling policies (e.g., thread prioritization) and thread-cancellation \npolicies (e.g., preemp\u00adtive vs. non-preemptive) have implications for both termina\u00adtion and performance. \nA program that terminates under the non-speculative semantics may fail to terminate in the specula\u00adtive \nsemantics if a (mispredicted) speculative consumer is non\u00adterminating and the scheduling policy is unfavorable. \nNote that other speculative systems such as transactional memory also face similar issues. We discuss \nthese issues in more detail in section 3.3.  We now consider the semantics of specfold. Rule NONSPEC-ITERATE \npresents the non-speculative semantics for this construct. The speculative semantics of specfold are \na natural generalization of speculative application to loops with loop-carried dependences. As the rules \nSPEC-ITERATE-1 and SPEC-ITERATE-2 indicate, threads are created to execute all the iterations in parallel, \nusing predicted values instead of the loop-carried dependence. The predictor vg is a function that takes \nthe iteration index i as a parameter and predicts the incoming value for the i-th iteration. The .rst \nitera\u00adtion is non-speculative and is described by rules SPEC-ITERATE-1. Rule SPEC-ITERATE-2 describes \nthe remaining iterations, which are speculative and utilize a checker thread tc to validate the predic\u00adtion \nand re-execute the loop body in case of mispredictions. Rule SPEC-ITERATE-3 indicates the .nal termination \nof the computation, which happens once the .nal loop iteration successfully completes. Note that our \nsemantics describes one speci.c validation scheme. It is possible to increase the speculative parallelism \nin the program with other validation schemes. E.g., assume that the speculative execution of the i-th \niteration completes before the i - 1-th itera\u00adtion. The speculative output of the i-th iteration, if \ndifferent from the value predicted by the i +1-th iteration, can be used to initiate further speculative \nexecutions of the i +1-the iteration. We discuss such a variation in Section 4. 3. Safe Speculation Without \nRollback One of the potential advantages of language support for speculation is that speculation constructs \ncan be seen as hints used solely to improve performance, without affecting correctness. In general, a \nprogram s behavior under the speculative semantics may not be the same as its behavior under the non-speculative \nsemantics due to side-effects. We would like to treat the non-speculative semantics as the intended behavior \nand statically check a speculative program to see if we can guarantee that its speculative behavior will \nbe equivalent to its non-speculative behavior. We take the following three step approach to this goal: \n1. We de.ne a notion of equivalence between speculative and non\u00adspeculative executions. We de.ne a speculative \nexecution to be correct if it is equivalent to a non-speculative execution.  2. We de.ne a safety criterion, \nrollback freedom, for the use of speculation constructs. We show that all speculative executions of a \nprogram that satis.es rollback freedom are correct. 3. We then present (in Section 5) a static analysis \nto check if a given speculative program satis.es rollback freedom.  Some of these notions become complicated \nif the predicted value consists of a (mutable) heap-allocated data structure. We focus on the essence \nof speculation by restricting attention to the case where the predicted value is of primitive type (e.g., \ninteger). 3.1 Correctness Criterion We now de.ne two, related, notions of equivalence between specu\u00adlative \nand non-speculative executions: a weaker notion that requires the .nal-states produced by the two executions \nto be equivalent and a stronger notion that also requires a correspondence between the (interesting) \ntransitions of the two executions. The stronger notion is useful because it covers operational aspects \nand is also relevant for language extensions such as I/O with externally visible effects. (The second \nnotion is a natural adaptation of the notion of con.ict equivalence and con.ict serializability [23] \nto permit speculation.) The following de.nitions are asymmetric because the speculative execution is \nallowed to have extraneous steps (transitions) as long as they don t affect the rest of the computation \nor the .nal state, and the heap is allowed to have extraneous heap cells (created by the extraneous steps) \nthat are garbage (unreachable). a Preliminary De.nitions. A transition c . c . represents a single execution \nstep, with a label a explained below. An execution is a a1an sequence of transitions c0 . c1 \u00b7\u00b7\u00b7 . cn, \nwhere c0 is the initial con.guration. Let label(t ) denote the label on a transition t. We de.ne the \nlabels of transitions generated by the ALLOC, SET, and GET rules to be ALLOC (., v) , SET (., v) , and \nGET (., v) , respectively, where . and v represent the location and the value read/written respectively. \nWe refer to these transitions as interesting transitions. We de.ne the labels of all other transitions \nto be .. We say that a transition t1 is data-dependent on a transition t2 if t2 writes to a location \n. that t1 reads and no transition in between t2 and t1 writes to .. We say that a location . in the .nal \nheap produced by an execution is data-dependent on a transition t if t writes to location . and no transition \nafter t writes to .. Since different executions may use different location addresses, we compare different \nexecutions modulo a correspondence be\u00adtween the heap locations of the two executions. For this reason, \nwe de.ne a correspondence mapping from one execution p1 to an\u00adother execution p2 to be a function \u00b5 that \nmaps every interesting transition t of p1 to a distinct interesting transition \u00b5(t ) of p2, and every \nheap location . in p1 to a distinct heap location \u00b5(.) in p2. We extend such a given mapping \u00b5 to map \naction labels and values: \u00b5(a), where a is an action label or value, is obtained by replacing every occurrence \nof a location . in a by \u00b5(.). Final-State Equivalence. The .nal con.guration of a complete execution \nis of the form H, main[v] . T, indicating that the main thread main has completed evaluating the original \nprogram. We say that the .nal state of this execution is (H,v). Let pn and ps be a complete non-speculative \nand speculative execution with .nal states (Hn,vn) and (Hs,vs) respectively. We say that ps is .nal\u00adstate \nequivalent to pn, modulo a correspondence mapping \u00b5, if 1. vs = \u00b5(vn), and 2. for every location . in \nHn, Hs(\u00b5(.)) = \u00b5(Hn(.)).  Dependence Equivalence. We say that a correspondence map\u00adping \u00b5 from an execution \npn to an execution ps is a dependence\u00adpreserving embedding if 1. The mapping preserves transition labels: \nfor every interesting transition t in pn, we have label(\u00b5(t)) = \u00b5(label(t )) 2. The mapping preserves \ndata-dependences between transitions: for every transition t1 and t2 in pn, t1 is data-dependent on t2 \niff \u00b5(t1) is data-dependent on \u00b5(t2). 3. The mapping preserves data-dependences of the .nal heap: for \nevery . in the .nal heap produced by pn and transition t in pn, . is data-dependent on t iff \u00b5(.) is \ndata-dependent on \u00b5(t).  We say that a speculative execution ps is dependence equivalent to a non-speculative \nexecution pn if there exists a dependence\u00adpreserving embedding from pn into ps. Note that dependence \nequivalence is a stronger guarantee than .nal-state equivalence. We say that a speculative execution \nis correct if it is dependence equivalent to some non-speculative execution. Note. The notion of dependence \nequivalence can be further strengthened by including other primitive reductions as interesting transitions \nand enriching transition labels to include the id of the thread performing the execution step, the redex \nbeing performed, and the evaluation-context to establish a much tighter correspon\u00addence between the executions. \nAs this would signi.cantly compli\u00adcate the notation, we restrict ourselves to the simpler equivalence \nnotion in this paper.  3.2 Rollback Freedom: A Safety Criterion We now consider the problems that can \nprevent a speculative exe\u00adcution of spec ep eg ec from satisfying the correctness criterion. The .rst \nproblem is the common one of data races: if the pro\u00adducer and the speculative consumer both access the \nsame location, and at least one of these accesses is a write, the resulting execution may not be equivalent \nto the non-speculative execution (where the producer and consumer execute sequentially one after another). \nIf no such con.icting accesses are possible between the producer and speculative consumer, then this \nproblem does not arise. The second problem, however, is speci.c to speculative execu\u00adtion without rollback. \nIn the case of misprediction, heap updates performed by the speculative consumer can affect correctness. \nThe key idea we exploit in our safety check for this problem is the fol\u00adlowing. If the locations read \nby the consumer re-execution are dis\u00adjoint from the locations written by the speculative consumer, then \nthe invalid speculative consumer execution does not affect the cor\u00adrectness of the subsequent consumer \nre-execution. Furthermore, if the consumer re-execution is guaranteed to overwrite all locations written \nby the speculative consumer, then the invalid speculative consumer execution will not affect the correctness \nof any subse\u00adquent computation (or the correctness of the .nal state). E.g., consider an iterative loop \nin which the i-th iteration com\u00adputes a value vi and stores it in a (pre-existing) location .i. If the \nspeculative execution of the i-th iteration, because of a mispredic\u00adtion, stores a wrong value vi . in \n.i, the execution will still be correct as long as the re-execution of the i-th iteration stores the \nright value vi in .i (and it does not read the pre-existing value of .i). We now state the safety condition \nformally. For any expression e and heap H, we de.ne R(e, H) to be the set of locations in the initial \nheap H that are read before they are written by the non\u00adspeculative evaluation of e with initial heap \nH. We de.ne W(e, H) to be the set of locations in the initial heap H that are written during the non-speculative \nevaluation of e with initial heap H. (These de.nitions can be extended to accomodate the case where the \nevaluation of e in initial heap H is non-terminating.)  We say that (spec ep eg ec, H) is safe if (a) \nW(ep, H) nR(eceg, H)= \u00d8, (b) R(ep, H) nW(eceg, H)= \u00d8, (c) W(ep, H) nW(eceg, H)= \u00d8,  (d) R(ecep, H) \nnW(eceg, H)= \u00d8, (e) W(ecep, H) .W(eceg, H).  Note that condition (b) is subsumed by condition (d), \nbut we include it for expository reasons. We obtain an analogous safety condition for the construct specfold \nvf vg vl vu by treating, for every vl = i<vu, the i-th iteration as the producer and the i +1\u00adthe iteration \nas the consumer. We say that the pair (H,e2) is reachable from e1 if, in the non\u00adspeculative semantics, \n.,e1 . * H,E[e2]. We say that a program e is safe if every (H, spec ep eg ec) and (H, specfold vf vg \nvl vu) reachable from e is safe. We also say that a program satis.es rollback freedom if it is safe. \nNote that rollback freedom is expressed in terms of the non\u00adspeculative semantics (which is a sequential \nsemantics). This sim\u00adpli.es the analysis required to check for rollback freedom because the analysis \ndoes not have deal with interleaved (concurrent) exe\u00adcutions produced by speculation. Theorem 1. If e \nsatis.es rollback freedom, then every complete speculative execution of e is correct. Proof. We present \na brief proof sketch here. We .rst prove a weaker result that a given speculative execution of a construct \nspec ep eg ec that satis.es the safety conditions is correct. Conditions (a) to (c) imply that there \nis no con.icting access between the execution steps of the producer and the speculative consumer. Hence, \nthe execution steps of the producer and the speculative consumer commute with each other. Thus, the speculative \nexecution is equivalent to the com\u00adplete execution of the producer followed by the speculative con\u00adsumer. \nIf the prediction is correct, then this particular execution is correct. If the prediction is incorrect, \nthen consider the speculative consumer and the re-execution of the consumer. Since the locations read \nby the consumer re-execution are disjoint from the locations written by the speculative consumer (condition \n(d)), the speculative consumer execution does not affect the correctness of the consumer re-execution. \nSince the consumer re-execution overwrites all loca\u00adtions written by speculative consumer (condition \n(e)), the writes by the speculative consumer do not affect the correctness of any subse\u00adquent computation \n(or the correctness of the .nal state). It follows that the speculative execution is correct. However, \nour safety criterion checks for conditions (a)-(e) only using non-speculative executions. This may seem \nunintuitive, but is suf.cient. We can prove, by induction, that speculative executions must also satisfy \nthe same conditions and be equivalent to non\u00adspeculative executions. Details omitted.  3.3 Termination \nGuarantees Ideally, the speculation scheme should provide a termination guar\u00adantee: if a non-speculative \nexecution terminates, the speculative ex\u00adecution should also terminate. With minor modi.cations, the \nspec\u00adulative semantics does provide this guarantee. First, note that the speculation-validation step \nwaits for both producer and predictor to complete execution. If the predictor is non-terminating, this \nis a problem as the non-speculative execution does not invoke the predictor. This is easy to .x: if the \nproducer completes execution before the predictor, there is no point in con\u00adtinuing with the speculation; \nwe can abort the predictor and specu\u00adlative consumer and execute the consumer with the correct input. \nSecond, when the validation step detects mis-prediction, it at\u00adtempts to cancel the speculative consumer. \nIf the speculative con\u00adsumer is non-terminating (e.g., because it is processing the wrong 1 public class \nSpeculation { 2 public static void Apply <T >( 3 Func(T) producer , 4 Func(T) predictor , 5 void Action(T) \nconsumer) 6 7 public enum ValidationMode { Seq , Par }; 8 9 public static void Iterate <T >( 10 int \nlow , int high , 11 Func( int , T, T) loopBody , 12 Func( int , T) predictor, 13 ValidationType val /* \noptional */ ) 14 15 public static void Iterate <T , U >( 16 int low , int high , 17 Func(U) initializer \n, 18 Func( int , U, T) loopBody, 19 Func( int , T) predictor, 20 Action( int , U) finalizer, 21 ValidationMode \nval) 22 } Figure 3. An API for speculative parallelism. Func is a C# generic type for delegates that \ntake zero or more arguments and return a value. Action is a C# type for delegates that do not return \na value. input), then we need to ensure that the cancellation step eventually takes place to guarantee \ntermination. Either a fair scheduler or a prioritized scheduler that prioritizes non-speculative threads \nhigher than speculative threads suf.ces to guarantee termination. 4. A Speculation Library In this section \nwe describe how we realized the speculation con\u00adstructs presented earlier as a C# library. Programming \nmodel. Our API (see Fig. 3) consists of a method Speculation.Apply that implements speculative application, \nand a set of methods Speculation.Iterate that support speculative itera\u00adtion. The classes and methods \nin the API are generic with types representing the type of the value(s) being speculated. The API re\u00adquires \nthat all computations be speci.ed as C# delegates. Apply provides the same interface and semantics as \nspec. Our API supports several variations of specfold. There are several meth\u00adods that support speculative \niteration. In its simplest form, the Speculation.Iterate method requires four arguments, the low and \nhigh loop indices, and delegates representing the loop body and prediction function. Both delegates are \nparameterized with the loop index; this permits the prediction delegate to make iteration speci.c predictions. \nThe call to Speculation.Iterate takes an optional validation mode parameter. This parameter can be used \nto specify the vali\u00addation mode an implementation should use to validate speculative iterations. We currently \nsupport two validation modes. In the se\u00adquential validation mode, speculatively executed iterations are \nval\u00adidated (and re-executed) in sequence, starting from the low to the high loop index. Sequential validation \nmatches the semantics de\u00adscribed in section 2. The parallel mode does validation specula\u00adtively. In this \nmode, a speculatively executed iteration i is validated speculatively as soon as the previous iteration \ni-1 completes, even if iteration i - 1 itself has not been validated. We .nd that a common usage scenario \nfor speculative iteration is one where each iteration allocates local objects, computes results in the \nobjects and then publishes the results to global state. We provide a variant of speculative iteration \nthat explicitly supports this scenario. This variant requires the user to provide a local  1 public \nclass LexicalAnalysis { 2 private TokenCollection [] tc = 3 new TokenCollection [NUM _TASKS]; 4 5 public \nToken [] SpeculativeLex(char[] input) { 6 7 int fragmentSize = 8 input.Length() / NUM _TASKS; 9 10 Speculation \n.Iterate < State >(0, NUM _TASKS , 11 (i, state) => /* loop body */ { 12 State finalState; 13 tc[i] = \nSequentialLex(input, 14 i * fragmentSize , 15 (i + 1) * fragmentSize , 16 state, out finalState); 17 \nreturn finalState; 18 }, 19 (i) => /* prediction function */ { 20 if (i == 0) 21 return START_ STATE; \n22 else { 23 State predictedState; 24 SequentialLex(input , 25 i * fragmentSize -10 /* overlap */ , 26 \ni * fragmentSize , 27 START _STATE , out predictState ); 28 return predictedState; 29 } 30 }); 31 32 \n/* assimilate tokens in tc */ 33 \u00b7\u00b7\u00b7 34 } 35 36 private TokenCollection SequentialLex( 37 char [] input \n, 38 int from, int to, 39 State inputState , 40 out State finalState) 41 { 42 LatexLexer lexer = 43 new \nLatexLexer (input, from, to); 44 return lexer.Lex(inputState , out finalState); 45 } 46 } Figure 4. \nAn implementation of speculative lexical analysis using the Speculation API. initialization and a local \n.nalization delegate. The local initializer is a function delegate that returns the initial state of \nthe local data for each iteration and the local .nalizer is a delegate that performs a .nal action on \nthe local state of each iteration. Figure 4 shows an implementation of speculative lexical analy\u00adsis \nusing our API. The implementation lifts an existing sequential lexcial analysis routine (SequentialLex) \nto a speculatively paral\u00adlel version. The usage closely resembles the usage of Parallel.For (a C# API \nfor parallel loops), with the only difference being the presence of a prediction function. Implementation. \nWe have implemented this API using the .NET Task Parallel Library [1]. Some aspects of our implementation \nnot covered by our earlier theoretical description include the following, and extending the theory to \nhandle these aspects is future work. The implementation ensures that only validated consumers/iter\u00adations \nthrow exceptions. The library hides all exceptions from code that was speculatively executed with the \nwrong values. We also try and provide sequential exception semantics. Un\u00adder these semantics, a call \nto Speculation.Iterate throws the exception corresponding the .rst valid iteration, irrespective of the \norder in which the runtime executes iterations. Our implementation is based on the .NET Task Parallel \nLibrary, which supports a co-operative cancellation model (as opposed to preemptive cancellations). Consequently, \nour implementa\u00adtion does not preserve termination. We rely on the user to in\u00adject cancellation checks \nto ensure that speculatively executed codes terminates even with incorrect values. These checks can be \nautomatically injected in user code, as is done in STMs.  We use the abstract Equals method of the generic \ntype T to check for equality. This allows a user of the library to supply their own abstract equality \nfunction. This may be useful in scenarios where strict equality is not required and a prediction can \nbe considered correct as long as it satis.es a more relaxed equality check. If the programmer speci.es \nher own equality function, it is her responsibility to ensure that the equality function does not affect \ncorrectness. Our safety correctness results currently apply only when strict equality is used.  5. Static \nAnalysis For Safety In this section, we describe a static analysis that checks whether a C# program that \nuses our API satis.es rollback freedom conditions described in Section 3.2. The core analysis is combined \npointer and escape analysis (sim\u00adilar to the purity and side-effect analysis described in [19]). The \ngoal of the analysis is to compute precise over-approximations of the R and W sets de.ned in Section \n3.2. The analysis is an inter\u00adprocedural .ow and .eld sensitive analysis that computes an ab\u00adstract model \nof the heap at every program point. The model rep\u00adresents the heap accessed by the given method when \nthe program point is reached. The heap is modeled as a graph, with nodes rep\u00adresenting abstract heap \nlocations, and edges representing heap ref\u00aderences. All heap locations that share the same allocation \nsite are represented by the same abstract location. This analysis is speci.cally designed to distinguish \nparts of the heap allocated for internal use by a method during its execution from parts of the heap \nexist before the call to the method such as parameters, objects loaded through parameters and static \nobjects. This is a critical distinction since speculatively executed code may create new objects in the \nheap, but we do not have to worry about writes to such objects as long as they do not escape to the caller. \n(The de.nitions of R and W in Section 3.2 re.ect this.) For example, consider the speculative lexical \nanalysis imple\u00admentation in Figure 4. Figure 5 shows a simpli.ed heap graph ob\u00adtained after analyzing \nSequentialLex. The method requires three parameters, an input character array input, an object initialState \nrepresenting the state in which lexical analysis should start, and .\u00adnalState, which is a reference to \nthe .nal state of the FSM. Edges are annotated with names of .elds (e.g. yy input, yy initial, to\u00adkens \nand yy .nal are .elds in the class LatexLexer; these .elds are accessed inside the constructor and the \nmethod Lex). Edges from array objects are annotated with intervals representing a set of ar\u00adray indices \n(e.g. [from, to]). As in [19], dashed nodes represent pre-existing objects (such as parameter objects) \nand dashed edges represent reads from escaping objects. This method creates an ob\u00adject of type LatexLexer \nfor processing the input string. Since this object does not escape to the caller, any writes to .elds \nof this ob\u00adject do not affect safety. The analysis is modular analysis that analyzes each method in\u00addependent \nof its calling contexts. The analysis assumes that formal parameters do not alias and computes a summary \nthat describes the set of abstract locations in the pre-existing heap that are read/writ\u00adten during the \nmethod execution. The inter-procedural component Figure 5. Model representing the heap accessed by SequentialLex \n  of the pointer analysis utilizes aliasing information available at the call site to merge the summary \nof the callee into the caller. Modeling array accesses. We extend the core analysis to model array accesses \nand accesses to static objects more precisely. This analysis identi.es locations in an array that may \nbe read/written and describes them using symbolic intervals, whose lower bounds and upper bounds are \nlinear expressions over program variables (in particular, the procedure parameters). The inter-procedural \ncompo\u00adnent of the range analysis re-interprets intervals in terms of param\u00adeters of the caller. This \nis an important extension because some of the common scenarios where speculative parallelism is likely \nto be used (including the benchmark programs in this paper) involve ar\u00adrays and other indexed collections. \nFor example, in SequentialLex, the interval [from, to] describes the set of indices of the array input \nread by the method. Similarly, the internal [i, i] describes the set of indices of the array tc written \nto by the loop body delegate. Computing must information. The analysis de.ned above com\u00adputes an over \napproximation (may information) of R and W sets. Using over-approximate read and write sets is sound \nin all cases except the LHS of condition (e). In condition (e), ensuring sound\u00adness requires that we \nuse an under-approximation of the write set W(eceg). We achieve this using the following two extensions \nto the core pointer and range analysis. We extend the pointer analysis to maintain a single bit with \nevery abstract heap node, which rep\u00adresents whether the node models a single (concrete) object or sum\u00admary \nobjects. We say that a reference is must-written in a method if the object containing the reference is \na single object and if the reference has been written to on all paths in the method. We also extend the \nrange analysis to compute an under-approximate inter\u00adval of values for every variable. The must write \nset at any program point consists of the writes to all single objects in the heap graph. 6. Experiments \nIn this section, we present an empirical evaluation of the proposed approach, using real-world applications \nwe implemented using the library described in Section 4. Benchmark programs. We implemented three representative \nbenchmark programs using the speculation library. These include lexical analyzers for C, HTML, Java and \nLatex, Huffman decoding algorithm, and a dynamic programming algorithm for .nding the maximal weighted \nindependent set (MWIS) of a given path graph. We implemented prediction functions for all the algorithms. \nThe prediction functions use a speci.ed number of elements preceding a given segment (referred to as \nthe overlap) to predict the required value at the beginning of the segment (similar to the lexical analysis \nprediction function described in Section 1). Our implementation of MWIS has two speculatively parallel \nphases. In the .rst phase, we identify the elements that will be a part of the MWIS using dynamic programming. \nThis phase oper\u00adates on segments of the path graph in parallel. The prediction func\u00adtion predicts whether \nthe pair of nodes immediately preceding the current segment will be a part of MWIS. The second phase \nwalks backwards along the path graph and emits the MWIS. We note that the speculation library itself \ntook about 4 man months to design, develop and validate. Subsequently, each specu\u00adlative algorithm took \nonly about a day s effort to implement starting from a pre-existing sequential implementation. Setup. \nWe conducted all our experiments on a 2.66 Ghz, Intel Core 2 Duo server with 4 GB RAM, running Windows \nServer 2008. We measured time using the DateTime class in C#. All the times we report are averages over \n10 executions measured using the ptime utility. We used the .NET PeakVirtualMemorySize64 API to measure \npeak memory consumption. We also identi.ed input datasets of different .avors for each benchmark to study \nthe effect of the input dataset on the observa\u00adtions. We generated lexical analyzers for 4 different \nlanguages (C, HTML, Java and Latex). We created three representative data sets for Huffman decoding, \nmedia (mp3 .les), rawdata (trace data from an Intel pro.ling tool) and text (a collection of books). \nFor MWIS, we generated path graphs with uniformly distributed numbers be\u00adtween intervals 0 to 50 and \n0 to 5000. Speedup and Scalability. First, we measured the speedup of the parallel implementations for \neach dataset, while varying the num\u00adber of threads and the amount of overlap. Figure 6 shows the results \nof this experiment. For each data set, we plot two sets of speedup, a max speedup (on the left) obtained \nwith an overlap that is large enough to eliminate mis-predictions (this represents our best case), and \na min speedup (on the right) obtained with a very small overlap. We make several observations from this \ndata. Several of the benchmark/dataset combinations scale almost linearly with the number of threads \nwhen the overlap is large enough to make accurate predictions. The actual speedups de\u00adpend on the datasets. \nFor example, the latex lexical analysis im\u00adplementation achieves a speedup of 4 with 4 threads.  The \nspeedups obtained with smaller overlap vary from no speedup (Huffman decoding/media dataset) to near \nlinear speedup (Java lexical analysis). In the case of the Java lexi\u00adcal analyzer, we .nd that predictions \nare often accurate even with a small overlap.  In the lexical analysis implementations, we observe a \ncorrela\u00adtion between the speedup and the size of the .nite state ma\u00adchine. The lexical analyzer for C \nhas the largest FSM whereas the one for Latex has the smallest FSM. This suggests that the speedup may \nbe in.uenced by the memory subsystem, which is stressed more when .nite state machines are larger.  \nThe MWIS benchmark does not scale as well as the other benchmarks even with a large overlap . We .nd \nthat this bench\u00admark is memory bound and performance is limited by the mem\u00adory subsystem.  There are \na small number of cases where speedup is marginally less than 1. This shows that the runtime overheads \nintroduced by our library are negligible.  Prediction Accuracy. The scalability of a speculative algorithm \nlargely depends on the accuracy of the prediction function. If a pre\u00addiction function rarely mis-predicts, \nwe expect a speculative imple\u00admentation to behave like a parallel implementation. On the other hand, \nif a prediction function mis-predicts often, the implementa\u00adFigure 6. Variation in scalability of the \nthree benchmark programs with number of threads, data sets and prediction quality.  tion reduces to \na sequential implementation, plus the library s own overheads. We measured the accuracy of prediction \nusing different overlap lengths for all our datasets. In each case, we made 32 predictions using the \nprediction function at equally separated points in the input data, and measured the prediction accuracy. \nAs shown in Figure 7, we .nd that the prediction accuracy increases as the overlap increases. Except \nfor the HTML Lexer and MWIS (uni\u00ad5000), a 100% prediction accuracy was achievable with reasonable overlap \nsizes. We also repeated this experiment increasingly larger number of predictions (upto 500,000 predictions) \nand found that the prediction accuracy remains more or less the same. These experiments highlights the \npotential for domain speci.c prediction functions to be very accurate and the value of programmer speci.ed \nprediction functions. Validation modes. As described in Section 4, we support two val\u00adidation modes in \nthe Speculation.Iterate API, a sequential vali\u00addation mode (seq) and a parallel/optimistic validation \nmode (par). Figure 8 shows the variation in speedup with the choice of the vali\u00addation mode and the accuracy \nof prediction for one dataset in each of the benchmark programs. We present two sets of speedups, a min \nFigure 7. Variations in prediction accuracy for various data-sets. Benchmark Overlap Prediction Accuracy \n% HTML Java Latex Lexical analysis 16 64 256 28% 41% 50% 90% 100% 100% 62% 100% 100% media rawdata text \nHuffman 2 4 38% 47% 72% 81% 66% 75% 8 72% 100% 91% 16 91% 100% 100% 64 100% 100% 100% uni-50 uni-5000 \n8 81% 38% MWIS 16 97% 38% 32 100% 38% speedup obtained with a small overlap, and a max speedup obtained \nwith a large overlap that eliminates mis-predictions. Both validation modes performed equally well in \nmany cases, but sequential validation seems to do better when the number of threads is increased to 4 \nand we use a good predictor. This is slightly counter intuitive since we would expect parallel validation \nto perform better in exactly such scenarios. Our investigation sug\u00adgests that the overheads of creating \na larger number of validation tasks outweighs the bene.ts of parallel validation as the number of speculative \nthreads increase. We believe this is an artifact of the task library we are using and we are working \non optimizing this aspect of our implementation. We propose to further investigate the rela\u00adtive performance \nof the two options, e.g., in machines with more than 4 cores. Dataset size. We also conducted experiments \nto study the effect of the data set size on scalability. For example, in the case of Huffman decoding, \nwe varied the size of input data from 10 MB to 50 MB. Our experiments suggest that the speedups do not \nvary signi.cantly within the data size intervals we chose. On an average, we see a small drop in speedup \nwith the increase in data set size. We studied this behavior closely using performance counters and we \n.nd that the memory subsystem plays an increasingly important role as data sets sizes increase, which \nlimits speedup. We omit the details of this experiment due to space constraints. Static analysis. We \nhave built a prototype implementation of the analysis for checking rollback freedom (described in Section \n5) and used it to verify correctness of our benchmark programs. Cur\u00adrently, our implementation does not \nanalyze methods in the .NET base class library. We manually provided summaries for BCL meth\u00adods called \nfrom within our programs. Table 9 shows some of the characteristics of the benchmarks programs and the \ntime taken by our analysis to verify correctness. All of our benchmarks are mod\u00aderately sized with a \nreasonably small number of methods. In all three case, the time taken to verify rollback freedom was \nunder 30 seconds (unfortunately, with relatively high peak memory usage). We believe that the scalability \nof our implementation can be im\u00adproved further. We leave a more detailed analysis of the precision\u00adperformance \ntrade-off for future work. 7. Related Work Speculatively Parallel Algorithms. Several speculatively parallel \nalgorithms have been designed in recent years, for use in speci.c domains. Jones et al. [8] devised an \noverlap-based speculative lexi\u00adcal analysis for parallelizing a web browser s front-end. Luchaup et al. \n[14] speculatively identify attacks within an intrusion detection system using hot state prediction within \na pattern matching FSM.  Figure 8. Variation in scalability of benchmarks with the type of speculation \nvalidation sequential or parallel. Benchmark LOC # methods Time (sec.) Memory Usage (MB) Lexical Analysis \n(Java) 493 76 23.62 50 Huffman Decoding 578 83 21.25 66 MWIS 412 44 29.89 64 Figure 9. Characteristics \nof benchmark programs and time &#38; memory consumed to verify rollback freedom. Klein et al. [10] designed \na parallel JPEG decoder by specula\u00adtive identi.cation of synchronization points within Huffman codes. \nSpeculative parsing [9] and speculative simulated annealing [25] are other examples of speculative algorithms. \nAll these algorithms can be easily expressed using our speculation constructs. Language Constructs and \nImplementation Mechanisms For Safe Parallelism. Futures is a well-known language construct for ini\u00adtiating \nthe concurrent computation of a value for later use. Welc et al. [24] formalized the concept of safe \nfutures for Java as one that guaranteed behavior equivalent to a sequential implementa\u00adtion. They utilize \na runtime mechanism to ensure sequential se\u00admantics in the presence of memory con.icts. Software transac\u00adtions \n[4, 7, 2, 22] are a well-known construct for safe parallelism, with a well-studied formal semantics [15, \n2]. Implementations of software transactions typically rely on optimistic concurrency and runtime techniques \nto detect con.icts and use rollback for correc\u00adtive action. The Galois system provides set iterators \nfor specifying optimistic parallelism and uses high level commutativity checks for runtime validation \n[11]. The constructs we propose meet a need not addressed by the above constructs: programmable value \nspecula\u00adtion. Further, we use static analysis techniques to ensure safety and avoid the need for runtime \ntechniques. The use of runtime tech\u00adniques to detect con.icts and/or take corrective action in an imple\u00admentation \nof our speculation constructs (e.g., when static veri.ca\u00adtion is not possible) is an interesting problem \nworth exploring. Software BOP [6] is a system that speculatively executes code regions annotated as possibly \nparallel by the programmer. Value checking is used as an optimization for speculation validation in certain \nrestricted cases, while address-based checking is used in the general case. Speculatively parallel algorithms \nwhich can be ex\u00adpressed using our constructs cannot be expressed in Software BOP as there is no support \nfor specifying ordered possibly parallel regions. This ordering is important in deciding the regions \nto re\u00adexecute on mis-speculation detection. Software BOP supports roll\u00adback at runtime by leveraging \npage-based protection mechanisms, while we rely on static analysis to prove rollback freedom. Compiler \nand hardware driven value speculation. Computer ar\u00adchitects and compiler writers have proposed the use \nof value spec\u00adulation for extracting parallelism at both the instruction level (ILP) and thread-level \n(TLP). For example, value speculation has been used to to drive ILP optimizations such as register value \nre-use [21] and load/store reordering [13]. Hardware-assisted TLS systems use value prediction for mask\u00ading \ncommunication latency between threads [20] and predicting silent stores [5] and return values [16]. Mitosis \nis a system that uses slice based value prediction for initializing speculative thread state [17]. SPICE \n[18] uses selective value prediction to convert loops into data parallel form. In this paper, we focus \non user-programmable speculation for TLP. Our constructs are complementary to low-level value specu\u00adlation \nused in compilers and the hardware. Our constructs enable programmers to specify custom prediction functions \nthat exploit domain knowledge, which is often critical for prediction accuracy. 8. Future Work We believe \nthat speculative parallelism is an important algorithm design idiom for improving performance of algorithms \nthat are commonly perceived as sequential. The language extensions we propose simplify writing speculatively \nparallel programs. However, these are initial designs and there are several interesting avenues for future \nwork. We de.ned the semantics of our speculative constructs in a sim\u00adple language. Formally de.ning the \nsemantics of these constructs in a richer language that supports features such as exceptions, syn\u00adchronization \nprimitives is an interesting problem. Ideally, we would like to guarantee non-speculative exception semantics \nfor the spec\u00adulative constructs. However, providing these guarantees statically or even with low runtime \noverheads appears challenging. For ex\u00adample, consider the scenario when a producer or a speculative iter\u00adation \nthrows an exception. In such a scenario, the consumer or any subsequent speculative iterations should \nnot appear to have been executed at all. We would also like to weaken the conditions we use check for \nrollback freedom to permit common programming idioms such as caching. By weakening these conditions and \nstatically verifying larger fragments of code as rollback free, we may be able to signi.\u00adcantly reduce \nthe burden of runtime mechanisms that ensure safety such as transactional memory.  Finally, we believe \nthat expressing speculative algorithms us\u00ading constructs may permit more ef.cient implementations of \nthese algorithms. For example, it may be possible to exploit knowledge about whether or not a task is \nspeculative (and the degree of specu\u00adlation) to improve task scheduling. Acknowledgments We would like \nto acknowledge Tim Harris for his inputs during the initial stages of this work. We also thank Ashish \nAgarwal for his contributions to this paper. References [1] What s new in Beta 2 for the Task Parallel \nLibrary. In blogs.msdn.com, 2009. [2] Mart\u00b4in Abadi, Andrew Birrell, Tim Harris, and Michael Isard. Semantics \nof transactional memory and automatic mutual exclusion. In Proc. of POPL, pages 63 74, 2008. [3] Krste \nAsanovic, Rastislav Bodik, James Demmel, Tony Keaveny, Kurt Keutzer, John Kubiatowicz, Nelson Morgan, \nDavid Patterson, Koushik Sen, John Wawrzynek, David Wessel, and Katherine Yelick. A view of the parallel \ncomputing landscape. Communications of ACM, 2009. [4] Brian D. Carlstrom, Austen McDonald, Hassan Cha., \nJaeWoong Chung, Chi Cao Minh, Christos Kozyrakis, and Kunle Olukotun. The atomos transactional programming \nlanguage. SIGPLAN Not., 41(6):1 13, 2006. [5] Marcelo Cintra and Josep Torrellas. Eliminating squashes \nthrough learning cross-thread violations in speculative parallelization for multiprocessors. In Proc. \nof HPCA, page 43, Washington, DC, USA, 2002. IEEE Computer Society. [6] Chen Ding, Xipeng Shen, Kirk \nKelsey, Chris Tice, Ruke Huang, and Chengliang Zhang. Software behavior oriented parallelization. In \nProc. of PLDI, pages 223 234, 2007. [7] Tim Harris, Simon Marlow, Simon Peyton-Jones, and Maurice Herlihy. \nComposable memory transactions. In Proc. of PPoPP, pages 48 60, New York, NY, USA, 2005. ACM. [8] Christopher \nGrant Jones, Rose Liu, Leo Meyerovich, Krste Asanovic, and Rastislav Bodik. Parallelizing the web browser. \nIn Proc. of HOTPAR, 2009. [9] Blake Kaplan. Speculative parsing patch. In bugzilla.mozilla.org, 2009. \n[10] Shmuel Tomi Klein and Yair Wiseman. Parallel huffman decoding with applications to jpeg .les. Journal \nof Computing, 46(5):487 497, 2003. [11] Milind Kulkarni, Keshav Pingali, Bruce Walter, Ganesh Rama\u00adnarayanan, \nKavita Bala, and L. Paul Chew. Optimistic parallelism requires abstractions. In PLDI, pages 211 222, \n2007. [12] Butler W. Lampson. Lazy and speculative execution in computer systems. In Proc. of ICFP, pages \n1 2, New York, NY, USA, 2008. ACM. [13] Mikko H. Lipasti, Christopher B. Wilkerson, and John Paul Shen. \nValue locality and load value prediction. In Proc. of ASPLOS, pages 138 147, 1996. [14] Daniel Luchaup, \nRandy Smith, Cristian Estan, and Somesh Jha. Multi-byte regular expression matching with speculation. \nIn Proc. of RAID, pages 284 303, 2009. [15] Katherine F. Moore and Dan Grossman. High-level small-step \noperational semantics for transactions. In Proc. of POPL, pages 51 62, 2008. [16] Jeffrey T. Oplinger, \nDavid L. Heine, and Monica S. Lam. In search of speculative thread-level parallelism. In Proc. of PACT, \npage 303, Washington, DC, USA, 1999. IEEE Computer Society. [17] Carlos Garc\u00b4ia Qui nones, Carlos Madriles, \nJes\u00b4anchez, Pedro us S\u00b4Marcuello, Antonio Gonz\u00b4alez, and Dean M. Tullsen. Mitosis compiler: an infrastructure \nfor speculative threading based on pre\u00adcomputation slices. SIGPLAN Not., 40(6):269 279, 2005. [18] Easwaran \nRaman, Neil Vachharajani, Ram Rangan, and David I. August. Spice: speculative parallel iteration chunk \nexecution. In Proc. of CGO, pages 175 184, 2008. [19] Alexandru Salcianu and Martin C. Rinard. Purity \nand side effect analysis for java programs. In Proc. of VMCAI, pages 199 215, 2005. [20] J. Gregory Steffan, \nChristopher B. Colohan, Antonia Zhai, and Todd C. Mowry. Improving value communication for thread-level \nspeculation. In Proc. of HPCA, page 65, Washington, DC, USA, 2002. IEEE Computer Society. [21] Dean M. \nTullsen and John S. Seng. Storageless value prediction using prior register values. In Proc. of ISCA, \npages 270 279, 1999. [22] Christoph von Praun, Luis Ceze, and Calin Cascaval. Implicit parallelism with \nordered transactions. In Proc. of PPoPP, pages 79 89, 2007. [23] G. Weikum and Gottfried Vossen. Transactional \nInformation Systems: Theory, Algorithms, and the Practice of Concurrency Control and Recovery. Morgan \nKaufmann, 2002. [24] Adam Welc, Suresh Jagannathan, and Antony Hosking. Safe futures for java. In Proc. \nof OOPSLA, pages 439 453, New York, NY, USA, 2005. ACM. [25] E. E. Witte, R. D. Chamberlain, and M. A. \nFranklin. Parallel simulated annealing using speculative computation. IEEE Trans. Parallel Distrib. Syst., \n2(4):483 494, 1991.   \n\t\t\t", "proc_id": "1806596", "abstract": "<p>Execution order constraints imposed by dependences can serialize computation, preventing parallelization of code and algorithms. Speculating on the value(s) carried by dependences is one way to break such critical dependences. Value speculation has been used effectively at a low level, by compilers and hardware. In this paper, we focus on the use of speculation <i>by programmers</i> as an algorithmic paradigm to parallelize seemingly sequential code.</p> <p>We propose two new language constructs, <i>speculative composition</i> and <i>speculative iteration</i>. These constructs enable programmers to declaratively express speculative parallelism in programs: to indicate when and how to speculate, increasing the parallelism in the program, without concerning themselves with mundane implementation details.</p> <p>We present a core language with speculation constructs and mutable state and present a formal operational semantics for the language. We use the semantics to define the notion of a correct speculative execution as one that is equivalent to a non-speculative execution. In general, speculation requires a runtime mechanism to undo the effects of speculative computation in the case of mis predictions. We describe a set of conditions under which such rollback can be avoided. We present a static analysis that checks if a given program satisfies these conditions. This allows us to implement speculation efficiently, without the overhead required for rollbacks.</p> <p>We have implemented the speculation constructs as a C# library, along with the static checker for safety. We present an empirical evaluation of the efficacy of this approach to parallelization.</p>", "authors": [{"name": "Prakash Prabhu", "author_profile_id": "81464645003", "affiliation": "Princeton University, Princeton, NJ, USA", "person_id": "P2184500", "email_address": "", "orcid_id": ""}, {"name": "Ganesan Ramalingam", "author_profile_id": "81100519054", "affiliation": "Microsoft Research, Bangalore, India", "person_id": "P2184501", "email_address": "", "orcid_id": ""}, {"name": "Kapil Vaswani", "author_profile_id": "81100057042", "affiliation": "Microsoft Research, Bangalore, India", "person_id": "P2184502", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806603", "year": "2010", "article_id": "1806603", "conference": "PLDI", "title": "Safe programmable speculative parallelism", "url": "http://dl.acm.org/citation.cfm?id=1806603"}