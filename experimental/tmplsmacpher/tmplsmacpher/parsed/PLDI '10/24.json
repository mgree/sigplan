{"article_publication_date": "06-05-2010", "fulltext": "\n Smooth Interpretation * Swarat Chaudhuri Armando Solar-Lezama Pennsylvania State University MIT swarat \nse.psu.edu asolar sail.mit.edu Abstract We present smooth interpretation, a method to systematically \nap\u00adproximate numerical imperative programs by smooth mathemati\u00adcal functions. This approximation facilitates \nthe use of numerical search techniques like gradient descent for program analysis and synthesis. The \nmethod extends to programs the notion of Gaus\u00adsian smoothing, a popular signal-processing technique that \n.lters out noise and discontinuities from a signal by taking its convolu\u00adtion with a Gaussian function. \nIn our setting, Gaussian smoothing executes a program accord\u00ading to a probabilistic semantics; the execution \nof program P on an input x after Gaussian smoothing can be summarized as follows: (1) Apply a Gaussian \nperturbation to x the perturbed input is a random variable following a normal distribution with mean \nx.(2) Compute and return the expected output of P on this perturbed in\u00adput. Computing the expectation \nexplicitly would require the execu\u00adtion of P on all possible inputs, but smooth interpretation bypasses \nthis requirement by using a form of symbolic execution to approx\u00adimate the effect of Gaussian smoothing \non P . The result is an ef\u00ad.cient but approximate implementation of Gaussian smoothing of programs. Smooth \ninterpretation has the effect of attenuating features of a program that impede numerical searches of \nits input space for example, discontinuities resulting from conditional branches are re\u00adplaced by continuous \ntransitions. We apply smooth interpretation to the problem of synthesizing values of numerical control \nparameters in embedded control applications. This problem is naturally formu\u00adlated as one of numerical \noptimization: the goal is to .nd param\u00adeter values that minimize the error between the resulting program \nand a programmer-provided behavioral speci.cation. Solving this problem by directly applying numerical \noptimization techniques is often impractical due to the discontinuities in the error function. By eliminating \nthese discontinuities, smooth interpretation makes it possible to search the parameter space ef.ciently \nby means of simple gradient descent. Our experiments demonstrate the value of this strategy in synthesizing \nparameters for several challenging programs, including models of an automated gear shift and a PID controller. \n* The research in this paper was supported by the MIT CSAI Lab and the National Science Foundation (CAREER \nAward #0953507). Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. PLDI 10, June 5 10, 2010, Toronto, Ontario, Canada. Copyright c 2010 AC M 978-1-4503-0019-3/10/06. \n. . $10. 00 (a) (b)  x2 Figure 1. (a) A crisp image. (b) Gaussian smoothing. (c) Error: z := 0; if \n(x1 > 0 . x2 > 0) then z := z - 2 . (c) Gaussian smoothing of Error. Categories and Subject Descriptors \nD.2.2 [Software Engineer\u00ading]: Design Tools and Techniques; F.3.2 [Logics and Meanings of Programs]: \nSemantics of Programming Languages; G.1.6 [Nu\u00admerical Analysis]: Optimization Gradient methods; G.1.0 \n[Nu\u00admerical Analysis]: Approximation. General Terms Theory, Design, Veri.cation Keywords Program Smoothing, \nContinuity, Parameter Synthesis, Abstract Interpretation, Operational Semantics 1. Introduction It is \naccepted wisdom in software engineering that the dynamics of software systems are inherently discontinuous, \nand that this makes them fundamentally different from analog systems whose dynam\u00adics are given by smooth \nmathematical functions. Twenty-.ve years ago, Parnas [15] attributed the dif.culty of engineering reliable \nsoftware to the fact that the mathematical functions that describe the behavior of [software] systems \nare not continuous. His argu\u00adment for using logical methods in software analysis was grounded in the \nfact that logic, unlike classical analysis, can handle discon\u00adtinuous systems. This view had its detractors: \nDeMillo and Lipton argued [6] that there is no reason in principle that the behavior of software cannot \nbe described by continuous functions, or that the methods of classical analysis cannot be used in program \nanalysis. However, to this date, practitioners and researchers have mostly agreed with Parnas, and the \nuse of smooth functions in modeling program semantics has remained a largely unexplored idea. In the \npresent paper, we demonstrate that DeMillo and Lipton were almost correct: while it may not be feasible \nto model program semantics exactly by smooth mathematical functions, approxima\u00adtion of program semantics \nby smooth functions is not only plausible but also of signi.cant practical value. In particular, we show \nthat such approximations facilitate the use of numerical search tech\u00adniques like gradient descent in \nthe analysis of control programs manipulating .oating-point data. Numerical search is usually in\u00adfeasible \nfor real-world programs because the search spaces derived from them are full of local minima and discontinuities, \ntwo b\u00eates noires of local search algorithms like gradient descent. However, we show that both of these \nproblems can be overcome if numerical search is made to operate on smooth approximations of programs. \n Gaussian smoothing Smooth approximations of programs can be de.ned in many ways. Our de.nition is inspired \nby the literature on computer vision and signal processing, where gradient descent is routinely used \non noisy real-world signals, and often runs into problems as well. In signal processing, a standard solution \nto these problems is to preprocess a signal using Gaussian smoothing [17], an elementary technique for \n.ltering out noise and discontinuities from a signal by taking its convolution with a Gaussian function. \nThe result of Gaussian smoothing is a smooth, comparatively well\u00adbehaved signal for example, applying \nGaussian smoothing to the image in Figure 1-(a) results in an image as in Figure 1-(b). Gradi\u00adent descent \nis now applied more pro.tably to this smoothed signal. We show that a similar strategy can enable the \nuse of numerical search techniques in the analysis of programs. Our .rst contribution is to introduce \na notion of Gaussian smoothing for programs. In our setting, a Gaussian smoothing transform is an interpreter \nthat takes a program P whose inputs range over RK , and executes it on an input x according to the following \nnontraditional semantics: 1. Perturb x using a Gaussian probability distribution with mean 0. The perturbed \ninput is a random variable following a normal distribution with mean x. 2. Execute the program P on this \nperturbed input. The output is also a random variable compute and return its expectation. If [[P ]] \nis the denotational semantics of P , the semantics used by Gaussian smoothing is captured by the following \nfunction [[P ]]: [[P ]](x)= [[P ]](y) fx,s (y) dy. (1) y.RK where fx,s is the density function of the \nrandom input obtained by perturbing x. Note that [[P ]] is obtained by taking the convolution of [[P \n]] with a Gaussian function. Thus, the above de.nition is consistent with the standard de.nition of Gaussian \nsmoothing for signals and images. To see the effect of smoothing de.ned this way, let P be z := 0; if \n(x1 > 0 . x2 > 0) then z := z - 2 where z is an output variable and x1 and x2 are input variables. The \nsemantics of P is graphed in Figure 1-(c). Smoothing P attenuates its discontinuities, resulting in a \nprogram with the semantic map shown in Figure 1-(d). Smooth interpretation The main challenge in program \nsmooth\u00ading is to algorithmically perform Gaussian smoothing on a program i.e., for a program P and an \ninput x, we want to compute the convolution integral in Equation 1. Unfortunately, solving this in\u00adtegral \nexactly is not possible in general P is a complex imper\u00adative program, and its Gaussian convolution is \nunlikely to have a closed-form representation. Consequently, we must seek approx\u00adimate solutions. One \npossibility is to discretize or sample the input space of P and compute the convolution numerically. \nThis approach, while standard in signal processing, just does not work in our setting. The problem is \nthat there is no known way to sample the input space of P while guaranteeing coverage of the execu\u00adtions \nthat signi.cantly in.uence the result of smoothing (a similar problem af.icts approaches to program testing \nbased on random sampling). This means that approximations of [[P ]](x) using dis\u00adcretization will usually \nbe hopelessly inaccurate. Consequently, we compute the integral using approximate symbolic methods. As \nour integral involves programs rather than closed-form math\u00adematical functions, the symbolic methods \nwe use to solve it come from abstract interpretation and symbolic execution [5, 10, 13, 16, 18] rather \nthan computer algebra. Our algorithm called smooth interpretation uses symbolic execution to approximate \nthe prob\u00adabilistic semantics de.ned earlier. The symbolic states used by smooth interpretation are probabil\u00adity \ndistributions (more precisely, each such state is represented as a Gaussian mixture distribution; see \nSection 3). Given an input x, the algorithm .rst generates a symbolic state representing a normal distribution \nwith mean x. Recall that this is the distribution of the random variable capturing a Gaussian perturbation \nof x.Now P is symbolically executed on this distribution, and the expected value of the resulting distribution \nis the result of smooth interpretation. The approximations in smooth interpretation are required be\u00adcause \nwhat starts as a simple Gaussian distribution can turn arbi\u00adtrarily complex through the execution of \nthe program. For exam\u00adple, conditional branches introduce conditional probabilities; as\u00adsignments can \nlead to pathological distributions de.ned in terms of Dirac delta functions, and join points in the program \nrequire us to compute the mixture of the distributions from each incoming branch. All of these situations \nrequire smooth interpretation to ap\u00adproximate highly complex distributions with simple Gaussian mix\u00adture \ndistributions. Despite these approximations, smooth interpretation effectively smoothes away the discontinuities \nof the original input program. By tuning the standard deviation of the input distribution, it is possible \nto control not just the extent of smoothing, but also the amount of information lost by the approximations \nperformed by smooth interpretation. Gradient descent and parameter synthesis Finally, we show that smooth \ninterpretation allows easier use of numerical search techniques like gradient descent in program analysis. \nThe con\u00adcrete problem that we consider is parameter synthesis,where the goal is to automatically instantiate \nunknown program parameters such that the resultant program matches a behavioral speci.ca\u00adtion. This problem \nis especially important for programs controlling cyber-physical systems. The dynamics of such systems \noften de\u00adpend crucially on certain numerical parameters referenced in their controllers e.g., the behavior \nof a system controlled by a PID controller is affected in complex ways by the values of the lat\u00adter s \ncontrol parameters. At the same time, correct values of these parameters are often dif.cult to determine \nfrom high-level insights. In our formulation, parameter synthesis is a problem of numer\u00adical optimization. \nAn instance here consists of a control program P with unknown parameters, a model of the physical system \nthat it controls, and a speci.cation de.ning the desired trajectories of the cyber-physical system on \nvarious initial conditions. We de.ne a function Error that maps each instantiation x of the control pa\u00adrameters \nto real value that captures the deviation of the observed and speci.ed trajectories of the system on \nthe test inputs. Our goal is to .nd x such that Error(x) is minimized. In theory, the above optimization \nproblem can be solved by a local search technique like gradient descent [21], which starts with an arbitrary \nvalue for the parameters, then greedily follows the landscape of the function Error in the direction \nin which its output decreases fastest. In practice, such search fails because the function Error is only \navailable as an imperative program with a search landscape infested with local minima and discontinuities. \nAn example of such a failure scenario is shown in Figure 1-(c). Here, if gradient descent starts with \na point that is even slightly outside the quadrant (x1 > 0) . (x2 > 0), it will be stuck in a plateau \nwhere the program output is far from the desired global minimum. In more realistic examples, Error will \nhave many such plateaus, as well as isolated, suboptimal peaks and troughs.  However, this dif.culty \ncan often be overcome if the search runs on a smoothed version of Error (Figure 1-(d)). The sharp cliffs \nof Figure 1-(c) are now gone, and any point reasonably close to the quadrant (x1 > 0) . (x2 > 0) has \na nonzero downhill gradient. Hence, gradient descent is now able to converge to a value close to the \nglobal minimum for a much larger range of initial points. The above observation is exploited in an algorithm \nfor param\u00adeter synthesis that combines gradient descent with smooth inter\u00adpretation. The algorithm tries \nto reconcile the con.icting goal of smoothing away the hindrances to gradient descent, while also re\u00adtaining \nthe core features of the expression to be minimized. The algorithm is empirically evaluated on a controller \nfor a gear shift, a thermostat controller, and a PID controller controlling a wheel. Our method can successfully \nsynthesize parameters for these ap\u00adplications, while gradient descent alone cannot. Summary of contributions \nand Organization Now we list the main contributions of this paper and the sections where they appear: \n We introduce Gaussian smoothing of programs. (Section 2)  We present an algorithm smooth interpretation \nthat uses symbolic execution to approximately compute the smoothed version of a program. (Section 3) \n We demonstrate, via the concrete application of parameter syn\u00adthesis, that smooth interpretation facilitates \nthe use of numerical search techniques like gradient descent in program analysis and synthesis. (Section \n4)  We experimentally demonstrate the value of our method using three control applications. (Section \n5)   2. Gaussian smoothing of programs In this section, we introduce Gaussian smoothing of programs. \nWe start by .xing, for the rest of the paper, a simple language of imperative programs. Programs in our \nlanguage maintain their state in K real-valued variables named x1 through xk . Expressions can be real \nor boolean-valued. Let E and B respectively be the nonterminals for real and boolean expressions, op \nstand for real addition or multiplication, and m be a real constant. We have: E ::= xi | m | op(E1, E2) \nB ::= E1 > E2 | B1 . B2 |\u00acB Note that there is no test for equality in our language. This is not an arti.cial \nrestriction: as equality tests on computer representations of real numbers are unstable, good programmers \nnever use them. Programs P are now given by: P ::= skip | zi := E | P ; P | while B { P } | if B then \nP else P. 2.1 Crisp semantics Now we give a traditional denotational semantics to a program. To distinguish \nthis semantics from the smoothed semantics that we will soon introduce, we refer to it as the crisp semantics. \nLetus.rstde.ne a state of a program P in our language as a vector x . RK ,where x(i),the i-th component \nof the vector, corresponds to the value of the variable xi . The crisp semantics of each real-valued \nexpression E appearing in P is a map [[E]] : RK . R such that [[E]](x) is the value of E at the state \nx. The crisp semantics of a boolean expression B is also a map [[B]] : RK . R;we have [[B]](x)=0 if B \nis false at the state x, and 1 otherwise. Finally, for m . R, x[i . m] denotes the state ' x' that satis.es \nx(i)= m, and agrees with x otherwise. Using these de.nitions, we can now express the crisp seman\u00adtics \nof P . For simplicity, we assume that each subprogram of P (including P itself) terminates on all inputs. \nDe.nition 1 (Crisp semantics). Let P ' be an arbitrary subprogram of P . The crisp semantics of P ' is \na function [[P ']] : RK . RK de.ned as follows: [[skip]](x)= x.  [[xi := E]](x)= x[i . [[E]](x)] [[P1; \nP2]](x)= [ P2]]([[P1]](x)).  [[if B then P1 else P2]](x)= [[B]](x) \u00b7 [[P1]](x)+[[\u00acB]](x) \u00b7 [[P2]](x). \nLet P ' = while B { P1 }.Then we have [[P ']](x)= x \u00b7 [[\u00acB]](x)+[ B]](x) \u00b7 [[P ']]([[P1]](x)). Note that \n[[P ']](x) is well-de.ned as P ' terminates on all inputs. If [[P ]](x)= x',then x' is the output of \nP on the input x.  2.2 Smoothed semantics and Gaussian smoothing Let us now brie.y review Gaussian (or \nnormal) distributions. Re\u00adcall, .rst, the probability density function for a random variable Y following \na 1-D Gaussian distribution: v 2 -(y-\u00b5)2/2s f\u00b5,s (y)= (1/(2ps)) e. (2) Here \u00b5 . R is the mean and s> \n0 the standard deviation. A more general setting involves random variables Y ranging over vectors of \nreals. This is the setting in which we are interested. We assume that Y has K components (i.e., Y ranges \nover states of P ), and that these components are independent variables. In this case, the joint density \nfunction of Y is a K-D Gaussian function K f\u00b5,s (y)= f\u00b5(i),s(i)(y(i)) (3) i=1 Here s . RK > 0 is the \nstandard deviation,and \u00b5 . RK is the mean.The smoothed semantics of P can now be de.ned as a smooth approximation \nof [[P ]] in terms of f\u00b5,s . De.nition 2 (Smoothed semantics). Let \u00df> 0, s =(\u00df,..., \u00df), and let the function \nfx,s be de.ned as in Equation (3). The smoothed semantics of P with respect to \u00df is the function [[P \n]]\u00df : RK . RK de.ned as follows: 1 [[P ]]\u00df(x)= [[P ]](y) fx,s (y) dy. y.RK The function [[P ]]\u00df (x) is \nthe convolution of the function [[P ]] and a K-D Gaussian with mean 0 and standard deviation s = (\u00df,...,\u00df). \nThe constant \u00df is said to be the smoothing parameter. When \u00df is clear from the context, we often denote \n[[P ]]\u00df by [[P ]]. Smoothed semantics is de.ned not only at the level of the whole program, but also \nat the level of individual expressions. For example, the smoothed semantics of a boolean expression B \nis 1 [[B]]\u00df (x)= [[B]](y)fx,s (y) dy y.RK where s =(\u00df,... ,\u00df). We use the phrase Gaussian smoothing of \nP (with respect to \u00df) to refer to the interpretation of P according to the smoothed semantics [[.]]\u00df. \nNote that Gaussian smoothing involves comput\u00ad ing the convolution of [[P ]] and a Gaussian function thus, \nour terminology is consistent with the standard de.nition of Gaussian smoothing in image and signal processing. \nThe following examples shed light on the nature of Gaussian smoothing.  Figure 2. (a) A sigmoid. (b) \nA bump. Example 1. Consider the boolean expression B :(x0 - a) > 0, where a . R.We have: 1 8 1 8 [[B]]\u00df \n(x)= [[P ]](y)fx,\u00df (y) dy =0+ fx,\u00df(y) dy -8 a 1 8v 1+erf( x-a ) 1 -(y-x+a)2/2\u00df2 2\u00df = v e dy = 0 2p\u00df 2 \nwhere x ranges over the reals, and erf is the Gauss error function. Figure 2-(a) plots the crisp semantics \n[[B]] of B with a = 2,as well as [[B]]\u00df for smoothing with Gaussians with standard deviations \u00df =0.5 \nand \u00df =3. While [[B]] has a discontinuous step, [[B]]\u00df is a smooth S-shaped curve, or a sigmoid.As we \ndecrease \u00df, the sigmoid [[B]]\u00df becomes steeper and steeper, and at the limit, approaches [[B]]. Along \nthe same lines, consider the boolean expression B ' : a< x0 <c,where a, c . R. We can show that vv erf( \nc-x )+erf( x-a ) 2\u00df 2\u00df [[B']]\u00df (x)= . 2 ' The functions [[B ' ]] and [[B]]\u00df, with a = -5, c =5,and \u00df \n=0.5 and 2, are plotted in Figure 2-(b). Once again, discontinuities are smoothed, and as \u00df decreases, \n[[B ' ]] approaches [[B]]. Example 2. Let us now consider the following program P : if x0 > 0 then skip \nelse x0 := 0. It can be shown that for all x . R, 1+ erf( vx ) 2/2\u00df2 2\u00df \u00dfe-x [[P ]]\u00df(x)= x + . 22 We \nnote that the smoothed semantics of a program P can be for\u00admulated as the composition of the smoothed \nsemantics of P with respect to 1-D Gaussians. This follows directly from our assump\u00adtion of independence \namong the variables in the input distribution. Speci.cally, we have: fx,s = fx(1),\u00df fx(2),\u00df ...fx(K),\u00df \n,where fx(i),\u00df is a 1-D Gaussian with mean x(i) and standard deviation \u00df. Let us denote by [[ P ]]i,\u00df \nthe smoothed semantics of P with re\u00adspect to the i-th variable of the input state, while all other variables \nare held constant. Formally, we have [[P ]]i,\u00df (x)= [[P ]](x ' ) fx(i),\u00df (x ' ) dy y.R where f is as \nin Equation 2, and x ' is such that x ' (i)= y,and for all j ' (j)= x(j). It is now easy to see that: \n= i, x Theorem 1. [[P ]](x)=([[P ]].\u00b7\u00b7\u00b7. [[P ]])(x). \u00df1,\u00df K,\u00df  2.3 Smoothed semantics: a structural \nview As mentioned earlier, De.nition 2 matches the traditional signal\u00adprocessing de.nition of Gaussian \nsmoothing. In signal process\u00ading, however, signals are just data sets, and convolutions are easy to compute \nnumerically. The semantics of programs, on the other hand, are de.ned structurally, so a structural de.nition \nof smooth\u00ading is much more desirable. Our structural de.nition of Gaussian smoothing is probabilistic, \nand forms the basis of our smooth inter\u00adpretation algorithm de.ned in Section 3. In order to provide \nan inductive de.nition of [[P ]]\u00df,we view the smoothed program as applying a transformation on random \nvariables. Speci.cally, the smoothed version P of P performs the following steps on an input x . RK : \n1. Construct the (vector-valued) random variable Yx with density function fx,s from Equation (3). Note \nthat Yx has mean x and standard deviation s =(\u00df, ...,\u00df). Intuitively, the variable Yx captures the result \nof perturbing the state x using a Gaussian distribution with mean 0 and standard deviation s. 2. Apply \nthe transformation Yx ' =[[P ]](Yx). Note that Yx ' is a random variable; intuitively, it captures the \noutput of the program P when executed on the input Yx. Observe, however, that Yx ' is not required to \nbe Gaussian. 3. Compute and return the expectation of Yx' .  One can see that the smoothed semantics \n[[P ]]\u00df of P is the function mapping x to the above output, and that this de.nition is consistent with \nDe.nition 2. With this model in mind, we now de.ne a proba\u00adbilistic semantics that lets us de.ne [[P \n]]\u00df structurally. The key idea here is to de.ne a semantic map [[P ]]# that models the effect of P on \na random variable. For example, in the above discussion, we have Yx ' =[[P ]]#(Yx). The semantics is \nvery similar to Kozen s probabilistic semantics of programs [12]. Our smooth interpreta\u00adtion algorithm \nimplements an approximation of this semantics. Preliminaries For the rest of the section, we will let \nY be a random vector over RK . If the probability density function of Y is hY, we write Y ~ hY. In an \nabuse of notation, we will de.ne the probabilistic semantics of a boolean expression B as a map [[B]]# \n: RK . [0, 1]: [[B]]#(Y)= ProbY[[[B]](Y)= 1]. (4) Assignments Modeling assignments is a challenge because \nas\u00adsignments can introduce dependencies between variables, which can often lead to very pathological \ndistribution functions. For ex\u00adample, consider a program with two variables x0 and x1 , and con\u00adsider \nthe semantics of the assignment x0 := x1 . [[x0 := x1 ]]#(Y)= Y ' After the assignment, the probability \ndensity hYl (x0,x1) of Y ' will have some peculiar properties. Speci.cally, h ' Y (x0,x1)=0 for any x0 \nx1, yet it s integral over all x must equal one. The = only way to satisfy this property is to de.ne \nthe new probability density in terms of the Dirac d function. The Dirac d is de.ned formally as a function \nwhich satis.es d(x)=0 for all x =0,and J8 with the property that -8 d(x)f(x) dx = f(0); informally, it \ncan be thought of as a Gaussian with an in.nitesimally small s. Now we de.ne the semantics of assignment \nas follows: [[xi := E]]#(Y)= Y ' ~ hYl (5) where hYl is de.ned by the following integral. 1 hYl (x ' \n)= D(E, i, x, x ' ) \u00b7 hY(x)dx x.RK Here, hY is the density of Y, and the function D(E, i, x, x ' ) above \nis a product of deltas d(x(0) - x ' (0)) \u00b7 ... \u00b7 d([[E]](x) - x ' (i)) \u00b7 ... \u00b7 d(x(K - 1) - x ' (K - \n1)), which captures the condition that all variables must have their old values, except for the ith variable, \nwhich must now be equal to [[E]](x).  From this de.nition, we can see that the probability density for \nY ' =[[x0 := x1 ]]#(Y) will equal hYl (x ' ) 1 1 ' ' = d(x(1) - x (0)) \u00b7 d(x(1) - x (1)) \u00b7 hY(x)dx x0.R \nx1.R 1 ' ' ' = d(x(0) - x (1)) \u00b7 hY(x(0), x (0))dx(0) x0.R 1 ' ' ' = d(x(0) - x (1)) \u00b7 hY(x(0), x (0))dx(0) \nx0.R It is easy to see from the properties of the Dirac delta that the solution above has exactly the \nproperties we want. Conditionals De.ning the semantics of conditionals and loops will require us to work \nwith conditional probabilities. Speci.cally, let B be a boolean expression. We use the notation (Y | \nB) to denote the random variable with probability distribution hY(x) if [[B]](x)=1 hY|B (x)=[[B]]# (6) \n0 otherwise. Intuitively, the distribution of (Y | B) is obtained by restricting the domain of the distribution \nof Y to the points where the boolean condition B is satis.ed. Thus, (Y | B) is a random variable following \na truncated distribution. For example, if Y follows a 1-D normal distribution and [[B]] equals (x> 0), \nthen the density function of (Y | B) is a half-Gaussian which has the shape of a Gaussian for x> 0, and \nequals 0 elsewhere. Note that the density function of (Y | B) is normalized so that its integral still \nequals 1. Conditionals also require us to de.ne the notion of mixture of random variables to model the \njoining of information about the behavior of the program on two different branches. Consider two vector-valued \nrandom variables Y1 and Y2 such that Y1 ~ h1 and Y2 ~ h2.We de.ne the mixture of Y1 and Y2 with respect \nto a constant v = 0 to be a random variable Y1 Uv Y2 with the following density function: h(x)= v \u00b7 h1(x)+ \n(1 - v) \u00b7 h2(x). (7) By combining all of the above concepts, we can now give a concise de.nition of the \nprobabilistic semantics of programs. De.nition 3 (Probabilistic semantics of programs). Let P ' be an \narbitrary subprogram of P (including, possibly, P itself), and let Y be a random vector over RK . The \nprobabilistic semantics of P ' is a partial function [[P ' ]]# de.ned by the following rules: [[P ' ]]# \nis as follows: [[skip]]#(Y)= Y.  [[xi := E]]#(Y)= Y ' de.ned by Equation (5).  [[P1; P2]]#(Y)=[[P2]]#([[P1]]#(Y)). \n [[if B then P1 else P2]]#(Y)= let v =[[B]]#(Y) in ([[P1]]#(Y | B)) Uv ([[P2]]#(Y |\u00acB)). Let P ' = while \nB { P1 }; let us also set Y1 =[[P1]]#(Y | B). For all j = 0, let us de.ne a map: . . Y if j =0 [[P ' \n]]# j (Y)= let v =[[B]]#(Y) in . ' # ([[P ]]j-1(Y1)) Uv Y otherwise. ' ' # Now we de.ne: [[P ]]#(Y) = \nlimj.8[[P ]]j . Of particular interest in the above are the rules for branches and loops. Suppose P ' \nequals if B then P1 else P2, and suppose [[P ' ]]#(Y) ~ h ' . Now consider any x . RK . We note that \nan out\u00adput of P ' in the neighborhood of x could have arisen from either the true or the false branch \nof P ' . These two sources are described by the distribution functions of the variables [[P1]]#(Y | B) \nand [[P2]]#(Y |\u00acB).The value h(x) is then the sum of these two sources, weighted by their respective \nprobabilities. This intuition directly leads to the expression in the rule for branches. The semantics \nof loops is more challenging. Let P ' now equal while B { P1 }. While each approximation [[P ' ]]# j \n(Y) is com\u00adputable, the limit [[P ' ]]#(Y) is not guaranteed to exist. While it is possible to give suf.cient \nconditions on P ' under which the above limit exists, developing these results properly will require \na more rigorous, measure-theoretic treatment of probabilistic seman\u00adtics than what this paper offers. \nFortunately, our smooth interpreta\u00adtion algorithm does not depend on the existence of this limit, and \nonly uses the approximations [[P ' ]]# j (Y). Therefore, in this paper, we simply assume the existence \nof the above limit for all P ' and Y.Inother words, [[P ' ]]# is always a total function. Smoothed semantics \nThe smoothed semantics of P is now easily de.ned in terms of the probabilistic semantics: De.nition 4 \n(Smoothed semantics). Let \u00df> 0, x . RK ,and let Y ~ fx,s,where s =(\u00df,..., \u00df) and fx,s is as in De.nition \n2. Further, suppose that for all subprograms P ' of the program P , [[P ' ]]# is a total function. The \nsmoothed semantics of the program P is de.ned as [[P ]]\u00df(x)= Exp[[[P ]]#(Y)].  2.4 Properties of smoothed \nsemantics Before .nishing this section, we make a few obesrvations about the smoothing transform. First, \nnote that as \u00df becomes smaller, [[P ]]\u00df approaches [[P ]]. Indeed, the following limit theorem may be \nshown to hold: Theorem 2. lim\u00df.0 [[P ]]\u00df =[[P ]]. Interestingly, the above property would not hold in \na language permitting equality tests. For example, if P represented the func\u00adtion if x =0 then 1 else \n0, then [[P ]]\u00df would evaluate to 0 on all inputs, for every value of \u00df. The same property can be restated \nin terms of the probabilistic semantics. In this case, the theorem involves the behavior of the probabilistic \nsemantics when the input distribution has all its mass concentrated around a point x0. Such a random \nvariable can be modeled by a Dirac delta, leading to the following theorem. Theorem 3. Let Y be a random \nvector with a distribution: h(x)= d(x - x0) Then the variable [[P ]]#(Y) follows the distribution h ' \n(x)= d(x - [[P ]](x0)) Informally speaking, the random vector Y is equivalent to the (non-random) vector \nx0. The above theorem states that [[P ]]#(Y) is also equivalent, in the same sense, to the output [[P \n]](x0).  3. Smooth interpretation The last section de.ned Gaussian smoothing in terms of a prob\u00adabilistic \nsemantics based on transformations of random variables. The semantics of De.nition 3, however, do not \nlend themselves to algorithmic implementation. The immediate problem is that many of the evaluation rules \nrequire complex manipulations on arbitrary probability density functions. More abstractly, the smoothed \nse\u00admantics of De.nition 3 essentially encodes the precise behavior of the program on all possible inputs, \na losing proposition from the point of view of a practical algorithm. This section describes four approximations \nthat form the basis of our practical smooth inter\u00adpretation algorithm. The approximations focus on four \noperations that introduce signi.cant complexity in the representation of den\u00adsity functions. These approximations \nare guided by our choice of representation for the probability density functions; arguably the most important \ndesign decision in our algorithm.  Conditional probabilities: The use of conditional probabilities \nallows the probability density functions to encode the path constraints leading to a particular point \nin the execution. Path constraints can be arbitrarily complex, so having to encode them precisely as \npart of the representation of the state poses a challenge for any practical algorithm.  Mixture: The \nmixture procedure combines the state of two different paths in the program without any loss of information. \nThis poses a problem because it means that by the end of the execution, the probability density function \nencodes the behavior of the program on all possible paths.  Update: The semantics of update involve \ncomplex integrals and Dirac deltas; a practical smoothing algorithm needs a simple update procedure. \n where Yi follows the Gaussian distribution with mean \u00b5i and standard deviation \u00dfi. This de.nition still \nrequires us to compute [[B]]#(Yi), but it is easy to do so approximately at runtime. Exam\u00adple 1 showed \nhow to compute this exactly for the case when B is .Othercasescanbehandled oftheform )()(<aa<<cor xxii \nX heuristically by rules such as X [[B1 . B2]]#(Yi)=[[B1]]#(Yi) \u00b7 [[B2]]#(Yi). X [[\u00acB]]#(Yi) =1 - [[B]]#(Yi). \nAs for computing [[B]]#(Y), it turns out we do not have to. If we observe the rules in De.nition 3, we \nsee that every time we use Y|B, the resulting density function gets multiplied by a factor [[B]]#(Y). \nTherefore, we can perform a few simple adjustments to X the evaluation rules of De.nition 3 to avoid \nhaving to renormal\u00adize the representation of the distribution after every step. Skipping X normalization \nhas other bene.ts besides ef.ciency. Speci.cally, the total weight of the un-normalized representation \nof the distribution gives us a good estimate of the probability that the execution will reach a particular \nprogram point. This becomes useful when deal\u00ading with loop termination, as we will see further ahead. \nMixture The mixture operation is easy to implement accurately on our chosen representation. Given two \nrandom variables X ~ hX and Y ~ hY with 0 ,\u00b50 ,\u00dfM ,\u00b5M ,\u00dfM )] Loop approximation: The probabilistic semantics \nde.nes the hX =[(w behavior of loops as the limit of an in.nite sequence of opera- X ),..., (w 0 be able \nto ef.ciently approximate this limit. 3.1 Random variables as Gaussian mixtures The .rst important design \ndecision in the smooth interpretation al\u00adgorithm is that each random variable is approximated by a random \nvariable following a Gaussian mixture distribution. The density Y Y Y Y Y 0 ,\u00b50 ,\u00dfN ,\u00b5N ,\u00dfN )], the mixture \nX Uv Y has the probability density function shown be\u00adlow. It simply contains the components of both of \nthe initial distri\u00adbutions weighted by the appropriate factor. Note that the result be\u00adlow assumes normalized \nrepresentations for hX and hY,if they are unnormalized, the scaling factor is already implicit in the \nweights, and all we have to do is concatenate the two lists. Y tions. In order to make smooth interpretation \npractical, we must hY =[(w ),..., (w 0 function hY of a variable following a Gaussian mixture distribu- \nY ), ...] [(v\u00b7w tion has the following form: 0 hY = wi \u00b7 f\u00b5i(j),\u00dfi(j) = wi \u00b7 f\u00b5i,\u00dfi (8) i=0..M j=0..K \ni=0..M where f\u00b5i,\u00dfi is the density function of a Gaussian with mean \u00b5i . F K and standard deviation \u00dfi \n. RK . The above equation represents a distribution with M distinct components, where each component \nis a weighted Gaussian in K independent variables. The weights wi must addupto 1 to ensure that the function \nabove is a legal probability density function. By assuming that all density functions have the form above, \nour system can represent a random variable very compactly as a list of triples of the form hY =[(w0,\u00b50,\u00df0),..., \n(wM ,\u00b5M ,\u00dfM )] where \u00b5i,\u00dfi . RK for all i. Conditional probabilities The probabilistic semantics makes \nex\u00adtensive use of conditional probabilities. Unfortunately, if a ran- Y )]M anenormousnumberevenformodestlysizedprograms. \nX Y X X X X X X 0 ,\u00b50 ,\u00df0 ), ..., (v\u00b7wM ,\u00b5M ,\u00dfM ), ((1-v)\u00b7w0 ,\u00b50 ,\u00df One drawback of this representation \nis that it can grow signif\u00adicantly in the process of applying mixtures. Every time we mix a random variable \nwith a representation of size M with one of size N, the result is a random variable with a representation \nof size M +N. Performing mixtures in the process of evaluating the prob\u00adabilistic semantics leads to \nan explosion in the number of compo\u00adnents; by the end of the program, the total number of components \nwill be equal to the number of possible paths through the program, To prevent this explosion, our interpreter \nestablishes a bound N, so if a mixture causes the number of components to exceed N, the result is approximated \nwith a representation of size N. The approximation is performed according to the pseudocode in Algorithm \n1. Algorithm 1 Restrict(hX,N) Input: Density function X X XXX 0 ,\u00b50 ,\u00df0 ),..., (wM ,\u00b5M ,\u00df Equation \n(8), the variable Y|B for some Boolean expression B of size M needs to be reduced to size N<M. is most \nlikely not going to have that form. Our solution is to .nd dom variable Y has a density function of \nthe form de.ned in hX =[(w an approximation of Y|B that matches our canonical form. Let hY =[m0,m1,...mN \n] where mi =(wi,\u00b5i,\u00dfi) is a Gaus\u00ad 1: while Size(hX) >N do X X X XXX j ) . hX that j ,\u00b5j ,\u00dfj )) 0,m1,...mN \n] that best approximates the probability density of ' i =(ti,\u00b5i,\u00dfi). 3: hX := replace components i and \nj in hX with j ,\u00b5j ,\u00dfj )) XXX X j ,\u00b5,\u00df ,\u00dfj X X ), (w .nd pair (w 2: ,\u00b5,\u00df ), (w i i i sian component. \nOur goal is to .nd a density function hY|B = '' ' [m XXX minimizes cost((w ,\u00b5 i i i Y|B. To simplify \nthe problem, we require that m With a bit of calculus, it is easy to see that the solution is to let \n X i ,\u00b5 X i ,\u00df X i ), (w merge((w 4: end while [[B]]#(Yi) 5: return hX ti = wi \u00b7 , [[B]]#(Y)  In this \nalgorithm, the merge operation takes two components in the distribution hX and replaces them with a single \ncomponent computed according to the following function. abbb''' merge((w ,\u00b5a,\u00dfa), (w ,\u00b5,\u00df)) = (w ,\u00b5 ,\u00df \n) ' ab w = w + w \u00b5 ' a bab where =(\u00b5a \u00b7 w + \u00b5b \u00b7 w )/(w + w ) \u00df ' a bb w \u00b7(\u00dfa+21\u00b5a-\u00b5l12)+w \u00b7(\u00dfb+21\u00b5b-\u00b5l12) \n= wa+w The mean is computed as one would expect, as the weighted average of the two components to be \nmerged; the new variance will grow in proportion to how far the old means were from the mean of the merged \ncomponent. The de.nition of merge is optimal: it produces the best possible approximation of the two \ncomponents. The algorithm merges in a greedy fashion, always trying to merge components that will cause \nthe smallest possible change to the distribution hX. The cost of a merge is computed according to the \nfollowing function. cost((w a,\u00b5a,\u00dfa), (w b,\u00b5b,\u00dfb)) = w al\u00b5a - \u00b5 ' l + w bl\u00b5b - \u00b5 ' l a bab where \u00b5 ' \n=(\u00b5a \u00b7w +\u00b5b \u00b7w )/(w +w ). The cost is an estimate of how much information will be lost when the two components \nare merged into one. The algorithm as stated is quite inef.cient in that it does a lot of repeated work, \nbut it is simple to state and implement, and for the values of N we used for our experiments, it was \nreasonably ef.cient. As we have stated before, each component in the density func\u00adtion hX carries information \nof the behavior of the program on a particular path. The Restrict operation has the effect of summariz\u00ading \nthe behavior of multiple paths in a single component. The result is an algorithm with very selective \npath sensitivity; paths with very high probability, or whose behavior is very different from the oth\u00aders \nare analyzed very accurately, while paths with similar behaviors are merged into a single summary component. \nThe price paid for this selective path sensitivity is a small amount of discontinuity in the smooth semantics. \nThis is because a small change in one com\u00adponent can cause components to merge differently. In Section \n5, we will explore this effect in the context of one of our benchmarks. Update Our interpreter implements \nassignments according to the following rule: If X ~ hX =[q0,q1,...qN ] where qi = (wi,\u00b5i,\u00dfi),then [[xj \n= E]]#(X)= X ' ''' ' where X ' =[q0,q1,...qN ],and qi =(wi,\u00b5i[j . [[E]](\u00b5i)],\u00dfi). From the rule for assignments \nin our probabilistic semantics, it is possible to determine that the above de.nition is optimal under \nthe constraint that \u00dfi remain unchanged. We could have gotten a more accurate de.nition if we allowed \n\u00dfi to change, but the added accuracy would have been at the expense of greater complexity. Loop approximation \nA .nal approximation has to do with loop termination. Consider a program P of form while B { ... },and \n# recall the approximations [[P ]]j de.ned in De.nition De.nition 3. Our interpreter uses [[P ]]# j (Y), \nfor a suf.ciently high j,as an approximation to the idealized output [[P ]]#(Y). An advantage of this \napproach is that [[P ]]# j (Y) is de.ned for all j, even when the limit in the de.nition of [[P ]]#(Y) \ndoes not exist. To select a suitable value of j, we apply a simple heuristic. Sup\u00adpose Y ' is the unnormalized \nrandom variable obtained by execut\u00ading the body of the loop j times on the input random variable Y. Our \nsystem monitors the weight of Y ' . Because our representations are unnormalized, the weight of Y ' is \nan estimate of how much (a) Source code of controller: tOff := ??; tOn := ??; repeat { temp := readTemp(); \nif (isOn() and temp > tOff) switchHeater (Off); else if (not isOn() and temp < tOn) switchHeater (On); \n} (b) Temperature variation in warming phase: d temp = -k \u00b7 temp + h dt (c) Temperature variation in \ncooling phase: d temp = -k \u00b7 temp dt Figure 3. Parameter synthesis in a thermostat an execution with \nj iterations will contribute to the end solution. Further, as weights get multiplied along paths, an \nexecution with j ' >j loop iterations will contribute strictly less than Y ' .When the weights associated \nwith Y ' become suf.ciently small (less than 10-8 in our implementation), we determine that an execution \nwith j or more iterations has nothing to contribute to the output of the smooth interpreter, and take \n[[P ]]# j as an approximation of [[P ]]# . The above strategy essentially amounts to a dynamic version \nof loop unrolling, where the amount of unrolling is based on the prob\u00adability that the loop will iterate \na certain number of iterations. Once that probability falls below threshold, the unrolling is terminated. \nExample 3. Let us consider the following program P , previously seen in Example 2: if x0 > 0 then skip \nelse x0 := 0 We sketch the smooth interpretation of P on the input 0.5 and \u00df =1. Here, the input random \nvariable Y has the representation hY =[(1, 0.5, 1)]. To propagate it through P ,we must .rst compute \n[[x0 > 0)] #(Y). This is done following Example 1 the result is approximately 0.69. Thus, the random \nvariables Y1 and Y2 propagated into the true and the false branch of P respectively have densities hY1 \n=[(0.69, 0.5, 1)] and hY2 =[(0.31, 0.5, 1)]. Now we have [[skip]]#(Y1)= Y1 and [[x0 := 0]]#(Y2)= [(0.31, \n0, 1)]. The estimation of Y2 =[[P ]]#(Y) thus has the representation hY2 =[(0.69, 0.5, 1), (0.31, 0, \n1)], and the output of the smooth interpretation is 0.69 \u00d7 0.5=0.345. Now, let P ' equal if x0 > 5 then \nskip else x0 := x0 + 5 and consider the program P ; P ' . To do smooth interpretation of this program, \nwe must propagate hY2 through P ' . The resulting distribution hY3 will equal: [(0.69, 0.5, 1), (0.31, \n0, 1), (2.3 \u00b7 10-6 , 5.5, 1), (9.8 \u00b7 10-8 , 5, 1)], Now, if our limit of components equals 3, then the \nRestrict opera\u00adtion will merge the last two components, which together have such a small weight that \nthe effect of the merge on the accuracy of the solution will be negligible.  4. Parameter synthesis \nIn this section, we introduce the parameter synthesis problem for embedded control programs as a concrete \napplication of smooth interpretation. 4.1 Problem de.nition Motivating example: Thermostat Let us consider \na simple cyber\u00adphysical system: a thermostat that controls the temperature of a room by switching on \nor off a heater. The program controlling the thermostat is shown in Figure 3-(a). The program repeatedly \nreads in the temperature of the room using a routine readTemp.If this temperature is above a certain \nthreshold tOff, the heater is switched off; if it is below a threshold tOn, the heater is switched on. \nWe as\u00adsume that the time gap between two successive temperature read\u00adings equals a known constant dt. \nAlso, the differential equations that govern the change of room temperature during the warming or cooling \nphase are known from the laws of physics and the charac\u00adteristics of the heater. These are as in Figure \n3-(b) and Figure 3-(c).  What we do not know are the values of the thresholds tOn and tOff. These thresholds \nare the control parameters of the thermo\u00adstat. For the room s temperature to be controlled desirably, \nthese parameters must be instantiated properly. At the same, the correct values of these parameters do \nnot easily follow from high-level pro\u00adgramming insights. Consequently, we aim to synthesize these val\u00adues \nautomatically. Let a trajectory be a .nite sequence of real values. An instance of our synthesis problem \nconsists of the system S described above (consisting of the control program, the model of temperature \nvari\u00adation, as well as the constant dt), and a speci.cation Spec consist\u00ading of a .nite set of reference \ntrajectories. Intuitively, the i-th value t [i] in a reference trajectory t is the desired temperature \nof the room during the i-th loop iteration. In more complex applications, a trajectory may need to be \nde.ned as a sequence of observable program states for brevity, we avoid this generalization. Let us now \n.x an instantiation of the parameters tOn and tOff with real values. Now consider any reference trajectory \nt ;the .rst value in t corresponds to the initial condition of t and is denoted by Init(t ). Now let \nus consider an execution of the system from a point where the room is at temperature Init(t ) (note that \nthis ex\u00adecution is deterministic). Let tObs be the sequence of temperature readings returned by the .rst \nN = |t | calls to readTemp.This se\u00adquence captures the observable behavior of the system under the present \ninstantiation of the control parameters and the same initial condition as t , and is known as the observed \ntrajectory of S.We refer to the distance (de.ned for this example as the L2-distance) between t and tObs \nas the t -error between S and Spec.The error between S and Spec is the sum of t -errors between S and \nSpec over all t . Spec (note that the this error is a function of tOn and tOff). The goal of parameter \nsynthesis is to .nd values for the control parameters such that the error between S and Spec is minimized. \nObserve that we do not aim to match the observed and reference trajectories of the system exactly. This \nis because in our setting, where parameters range over real domains, a problem may often lack exact solutions \nbut have good approximate ones. When this happens, a good synthesis technique should .nd the best approxi\u00admate \nanswer rather than report that the program could not be made to match the speci.cation. Parameter synthesis \nas numerical optimization More generally, an instance of the parameter synthesis problem consists of \na physi\u00adcal system with known characteristics, a program with uninitialized parameters that controls \nit, the rates at which the program invokes its sensors and actuators, and a reference trajectory de.ning \nthe desired observable behavior of the system. The goal of parameter synthesis is once again to minimize \nthe distance between the refer\u00adence and observed trajectories. A rigorous de.nition of the problem would \nrequire us to formally de.ne the semantics of cyber-physical systems we omit this for brevity and also \nbecause we do not solve the parameter synthesis problem directly. Instead, we reduce the problem to a \nproblem of numerical optimization. We illustrate the reduction using the thermostat example. Con\u00adsider \nthe procedure singleTrajError in Figure 4. This procedure is obtained by weaving the dynamics of the \nroom s temperature float singleTrajError (float tOn, float tOff, trajectory t ){ float temp := Init(t); \nfloat Err := 0; bool isOn = false; for (i:= 0;i< N;i:= i+1){ Err :=Err + (temp - t [i])2; if(isOn){ temp \n:= temp + dt K (h -temp); } ** else{ temp := temp (1-K dt); } ** if (isOn and temp > tOff) isOn := false; \nelse if (not isOn and temp < tOn) isOn := true; } v return Err; } Figure 4. Parameter synthesis in a \nthermostat (contd.) into the code for the controller (we take dt to be an approxima\u00adtion of an in.nitesimal \ntimestep), and recording the L2-distance between the observed and reference trajectories in a special \nvari\u00adable Err. The input variables of the routine are tOn and tOff the control parameters that we want \nto synthesize. Now let Error be a function returing the sum of the return values of singleTrajError for \nt . Spec (tOn and tOff are .xed), and consider the problem of .nding an initial assignment to the inputs \nof Error such that the value it returns is minimized. It is easy to see that assuming small dt, an optimal \nsolution to this problem is also an optimal solution to the parameter synthesis problem for the system \nS, and vice-versa. Generalizing, let P be any program with a single real-valued output variable out.The \noutput minimization problem for P is to .nd an input q to P such that the value of the output q ' (we \nhave q ' =[[P ]](q)) is minimized. The parameter synthesis problem for embedded control applications \nmanipulating .oating-point data can be reduced to the output minimization problem for programs such as \nP .  4.2 Algorithm Algorithm 2 GRADIENT-DESCENT(F, pin,.,E) Input: Function F : RK . R to be minimized \n(coded as a program), initial point pin . RK , step size . . R, stopping threshold . . R. Output: Local \nminimum p . RK of F. 1: p := pin 2: repeat 3: Numerically estimate .F(p)). 4: p ' := p - . .F 5: dE := \nF(p) -F(p ' ) ' 6: p := p 7: until dE <. 8: return p Our approach to the output minimization problem \n(and hence, parameter synthesis) is based on local numerical search techniques [21] popular in root-.nding \nand optimization. Perhaps the most popular technique of this sort is gradient descent (Algorithm 2). \nThe goal here is to .nd a local minimum of a real-valued function F. To do so, the search starts from \nan initial input state of F;at each state p, the search takes steps proportional to the negative of the \ngradient vector .F(p) of F at p, moving to a new state. The key observation here is that the function \nF decreases fastest in the direction of -.F. The search terminates when we reach   Algorithm 3 SMOOTHED-GRADIENT-DESCENT(F,.,E) \n1: repeat 2: Randomly select starting point p . RK 3: Select large \u00df> 0. 4: repeat 5: p := GRADIENT-DESCENT(SMOOTH(F,\u00df), \np,.,E) 6: \u00df := new value smaller than old value of \u00df. 7: until \u00df<E 8: if F(p) < F(bestp) then bestp := \np 9: until timeout 10: return bestp an approximate .xpoint i.e., when the value of F between two iterations \ndiffers by less than a threshold E. In settings like ours, the gradient of F at a state p is not directly \navailable. Indeed, the gradient may not exist, as F is unlikely to be differentiable everywhere. For \nsuch settings, gradient descent is not directly applicable, and we must use an algorithm that computes \na substitute of the gradient by querying F for the value of F(q), for various states q in the vicinity \nof p.As the difference between these algorithms and gradient descent are not too relevant for our purposes, \nwe will, abusing terminology, use the term gradient descent to also refer to these algorithms. Naive \nand smoothing-based algorithms A simple way to solve parameter synthesis using gradient descent would \nbe to generate the function Error, then call GRADIENT-DESCENT(Error, pin,., E) with suitable . and E; \nthe function could even be called repeatedly from a number of different starting points pin to increase \nthe likelihood of hitting a global minima. Unfortunately, Error is only available as an imperative program, \nand in most cases of interest to us, proves to be too ill-behaved to be minimized using gradient descent. \nFor example, consider again our thermostat, where Error is a function of tOn and tOff. In Figure 5-(a), \nwe plot the value of Error as tOn and tOff vary this plot is the search landscape that the gradient descent \nalgorithm navigates. In Figure 5-(b), we plot the magnitude of the gradient of Error vs tOn and tOff.The \nplots are thermal plots, where lighter colors indicate a high value. Now note the highly irregular nature \nof the gradient landscape. In particular, note the black squares in the bottom left corner of the gradient \nplot: these represent plateaus where the gradient is 0 but the value of Error is far from minimal. It \nis therefore not a surprise that empirically, gradient descent fails to solve the parameter synthesis \nproblem even in this simple-looking example. The problem of plateaus and discontinuities goes away with \nthe introduction of smoothing. Consider the algorithm for smoothed gradient descent shown in Algorithm \n3. This time, local search op\u00aderates on the smoothed version of Error we start with a highly smooth search \nlandscape, then progressively reduce the value of the smoothing parameter \u00df to increase the accuracy \nof the analysis. Of course, the accuracy of smoothing and the tradeoffs of accu\u00adracy and scalability \nalso depend on the path-sensitivity of smooth interpretation. We do not believe that there is a single \npolicy of path-sensitivity that will be successful for all applications; there\u00adfore, we allow the user \nto play with various strategies in different benchmark applications. Let us now consider the thermostat \napplication again. Let K = 1.0, h = 150.0,and dt =0.5. Also, let us use a partially path\u00adsensitive smooth \ninterpretation where we track only up to 2 paths simultaneously i.e., an abstract state has at most 2 \ncomponents. Figures 5-(c)-(h) depict the values of Error and its gradient un\u00adder this smooth interpretation, \nfor various values of \u00df.Note how (b) (a)  (c)  (d) (e) (f)  (h) (g)  Figure 5. (a) Error vs. (tOn, \ntOff): no smoothing. (b) Magni\u00adtude of gradient of Error: no smoothing. (c) Error: \u00df2 =0.5.(d) Gradient: \n\u00df2 =0.5.(e) Error: \u00df2 =5. (f) Gradient: \u00df2 =5.(g) Error: \u00df2 =50. (h) Gradient: \u00df2 =50. the gradient smooths \nout into a uniform slope as \u00df increases empirically, this causes gradient descent to converge rapidly. \n  5. Evaluation In this section, we describe a series of experiments that we per\u00adformed to evaluate \nthe bene.ts of smoothed gradient descent in pa\u00adrameter synthesis. We used an implementation of numerical \nsearch available in the GNU Scienti.c Library (GSL). Our evaluation cen\u00adters on three questions that \nare central to the viability of our ap\u00adproach: 1. Do typical control applications actually exhibit discontinuities \nthat would be signi.cant enough to require smoothing? 2. If discontinuities do exist, are they eliminated \nby smooth inter\u00adpretation? We are particularly interested in how the approxima\u00adtions made by our algorithm \naffect the quality of smoothing. 3. Does smoothing actually make a difference for parameter syn\u00adthesis? \n To answer these questions, we analyzed three applications: the thermostat controller introduced in \nSection 4, a gearbox controller, and a PID controller with brakes. We have already discussed the thermostat \napplication in some detail; also, it is less real-world than the other two applications. Consequently, \nin this section we focus on the gearbox and the PID controller. 5.1 Gearbox The gearbox benchmark models \nthe gearbox of a car. Here we have .ve gears, the i-th of which (1 = i = 5) has an associated ef.ciency \ncurve of the form 1 a(i, v):= . 1+(v - pi)2/25 Here v represents the current velocity of the car, and \n(p1,...,p5) = (5, 15, 25, 40, 60) are known parameters. Note that at gear i,the gearbox achieves maximum \nef.ciency at v = pi. At gear i,the velocity of the car changes according to the equation dv/dt = v \u00b7 \na(i, v)+ u.  while(t<T){ if (gear > 0) v:= v+dt*(a(gear, v) v + 5.0); * ** else v:= v-dt*(v v drag); \nif (gear = 1 and v = s1){ gear:=0;nxt:=2;w:=0.8; } if (gear = 2 and v = s2){ gear:=0,nxt:=3,w:=0.8; } \nif (grear = 3 and v = s3){ gear:= 0; nxt:= 4;w := 0.8;} if (gear = 4 and v = s4){ gear:= 0, nxt:= 5,w \n:= 0.8;} if (w < 0.0 and gear = 0) gear := nxt; t:= t+dt; w:= w-dt; } Figure 6. The gearbox benchmark \n(s1, s2, s3,and s4 are the control parameters) where u is a known constant. When the gearbox is disengaged, \nthe velocity of the car follows the equation dv/dt = -(v 2 \u00b7 drag) where drag is a known constant. We \nassume that u =5.0 and drag =0.0005. The controller for the gearbox decides when to shift from one gear \nto the next. The system only allows consecutive gear transitions i.e., from gear i, we can only shift \nto gear (i +1). For i =1 to 4, we have a control parameter si whose value is the velocity at which gear \ni is released and gear (i +1) is engaged. There is a second complicating factor: gear changes are not \ninstan\u00adtaneous. In our model, each shift takes 0.8 seconds thus, for 0.8 seconds after gear i is released, \nthe gearbox stays disengaged. We de.ne a trajectory of the system to be the sequence of val\u00adues of the \nvelocity v at the beginning of loop iterations. We want to make the system reach a target velocity vtarget \nas soon as pos\u00adsible; accordingly, we use a single reference trajectory of the form (0,vtarget,vtarget,... \n). Our goal is to synthesize values for the control parameters s1 -s4 such that the L2-distance between \nthe ob\u00adserved and reference trajectories is minimized. As in the thermostat example, we write a program \nthat folds the dynamics of the phys\u00adical component (car) into the source code of the controller it is \nthis program that we analyze. The main loop of this benchmark is shown in Figure 6 (we have omitted the \nlines computing the error). Smooth interpretation in this application requires us to run the program \non Gaussian distributions corresponding to the variables s1 -s4. This proves to be highly challenging. \nFirst, the number of paths in the system is O(2T/dt), making completely path-sensitive smooth interpretation \ninfeasible. At the same time, indiscriminate merging of distributions propagated along different paths \nwill lead to inaccurate smoothing, causing the minima of the smoothed pro\u00adgram to become meaningless. \nIn particular, the delay in the shifting of gears makes a certain level of path-sensitivity essential. \nIf the system loses track of the concrete values of variables nxt or w,it risks losing track of how much \ntime has elapsed since the gear got disengaged, or of what gear should be engaged next. Thus, the val\u00adues \nof these variables must be tracked precisely across iterations. We studied this benchmark using our implementation \nof smoothed gradient descent (based on the gsl library). We assumed that dt =0.1 and T =20.0. We limited \nthe number of distinct com\u00adponents of the distribution to 80, a very small number compared to the astronomical \nnumber of paths in the program. For our .rst experiment, we ran gradient descent with a number of initial \nvalues for the si, and with various degrees of smoothing. Since one of our goals was to understand the \neffect of \u00df on gradi\u00adent descent, all the experiments were run keeping \u00df constant, rather than progressively \nreducing it as we did in Algorithm 3. The results are summarized in the plots in Figure 8. The lines \nin each .gure show how the solution evolves with each iteration of gradient de\u00adscent; the solid region \nat the bottom of the graph shows how the er\u00adror value changes with each iteration. Each row in the .gure \ncorre\u00adsponds to a different initial value s1 = s2 = s3 = s4 = sini.The .rst column, with \u00df =0.0001, corresponds \nto the case where there is virtually no smoothing; the second column involves moderate smoothing, and \nthe last column involves a huge amount of smooth\u00ading. The correct settings are s1 =14,s2 =24,s3 =40,s4 \n=65. The .rst two rows show very clearly the effect of smoothing on the ability of gradient descent to \n.nd a solution. Without smooth\u00ading, the solver searches in vain for a gradient, but the error remains \nconstant after every try: the method is stuck in a plateau. By con\u00adtrast, the smoothed version of the \nproblem quickly .nds a good, if not necessarily optimal solution. Another interesting aspect is that \nfrom some starting points, the method is able to .nd a correct so\u00adlution even in the absence of smoothing. \nIn fact, in the third row of Figure 8, the solution found without smoothing is actually better than the \nsolution found with smoothing. To understand these effects better, we ran a series of experi\u00adments to \nhelp us visualize the error as a function of the different si. The results are shown in Figure 7. Illustrating \na function of a four dimensional parameter space is tricky; for these plots, we held all the parameters \nconstant at their optimal value and we plotted the error as a function of one of the parameters. For \nexample, in Fig\u00adure 7(a), we held s2,s3 and s4 constant and plotted the error as a function of s1 for \ndifferent values of \u00df. The unsmoothed functions all have a very smooth region close to the middle, with \nbig plateaus and discontinuities closer to the edges. This explains why for some cases, the unsmoothed \nfunction was able to converge to a correct solution, but for others it was completely lost. If the gradient \ndescent starts in the smooth region, it easily converges to the correct solution, but if it starts in \na plateau, it will be unable to .nd a solution. When we do apply smoothing, the results are very dramatic; \neven small degrees of smoothing completely eliminate the discontinuities and cause the plateaus to have \na small amount of slope. This helps the gradient descent method to see the deep valleys at the end of \nthe plateau. A .nal observation from these plots is that while smoothing eliminates discontinuities and \nplateaus, the smoothed function can still have sub-optimal local minima. Additionally, smoothing can \nchange the position of the actual minima, so the minima of the smoothed function may be different from \nthe minima of the original function. This explains why in Figure 8 with starting value 30, the unsmoothed \nfunction produced a better solution than the smoothed version. The solution to this problem is to start \nwith a very smooth function and then progressively reduce the degree of smoothing so that the most accurate \nsolution can be found.  5.2 PID Controller with a brake In this problem, we want to synthesize parameters \nfor a Proportional\u00adIntegral-Derivative (PID) controller for a wheel. To make the prob\u00adlem more interesting, \nwe have considered a version of the problem where the wheel has brakes. The brake allows for a much .ner \ncon\u00adtrol of the motion, and consequently a more effective controller. At the same time, they lead to \na signi.cant increase in the size of the parameter space and the number of control-.ow paths to be considered, \nmaking parameter synthesis much more dif.cult. The code for the benchmark, obtained by combining the \ndy\u00adnamics of the wheel with the code for the controller, is shown in  variable s1 variable s2 variable \ns3 variable s4 s2=24, s3=40, s4=65 s1=14, s3=40, s4=65 s1=14, s2=24, s4=65 s1=14, s2=24, s3=40 250 240 \n290 240 230 270 230 220 220 250 210 210 230 beta= 7 beta= 7 200beta= 7 beta= 7 Error Error Error \n200 beta= 5 beta= 5 190 beta= 3 beta= 5 beta= 5 210 beta= 3 beta= 3 beta= 3 190 0 2040 value of s1 \n6080 beta= 1.5 beta= 0.00005 150 160 170 180 0 2040 value of s2 6080 beta= 1.5 beta= 0.00005 150 160 \n170 180 0 2040 value of s3 6080 beta= 1.5 beta= 0.00005 150 170 190 0 2040 value of s4 6080 beta= 1.5 \nbeta= 0.00005 (a) (b) (c) (d) Figure 7. Error in the gearbox benchmark as a function of (a) s1,(b) s2,(c) \ns3,(d) s4 Initial value 80 \u00df =0.005 Gradient Descent beta = 0.005 500 160 \u00df =1.5 Gradient Descent beta \n= 1.5 500 100 \u00df =5 Gradient Descent beta = 5 500 40 60 400 450 110 400 450 60 80 400 450 Value of control \nValue of control value of control error error 60 error s1350 350 350 40 value of s value of s value of \ns value of s value of s value of s s1 s1 s2 20 s2 s2 300 300 20 300 s3 s3 s310 s4 s4 s4 error 0 250 \n0 1020 3040 506070 250 0 250 -40 0 102030405060 0 1020 3040 506070 -20 200 200 -20 200 -40 150 -90 150 \n-40 150 sini = 50 Iteration of gradient descent Iteration of gradient descent Iteration of gradient \ndescent Gradient Descent beta = 0.005 Gradient Descent beta = 1.5 Gradient Descent beta = 5 80 500 80 \n500 100 500 450 450 80 45060 60 400 400 60 400 40 40 error error 350 350 350 40 s1 s2 s1 s2 s1 s220 20 \n300 300 20 300 s3 s3 s3 s4 s4 0 s4 error 0 250 250 0 250 0 1020 3040 506070 0 102030 40506070 0 102030 \n40506070 -20 -20200 200 -20 200 -40 150 -40 150 -40 150 sini = 40 Iteration of gradient descent Iteration \nof gradient descent Iteration of gradient descent Gradient Descent beta = 0.005 Gradient Descent beta \n= 1.5 Gradient Descent beta = 5 80 500 80 500 100 500 450 450 80 45060 60 400 400 60 400 40 40 error \nerror 350 350 350 40 s1 s2 s1 s2 s1 s220 20 300 300 20 300 s3 s3 s3 s4 s4 0 s40 -20 0 102030 200 25040506070 \n-20 0 102030 200 25040506070 -20 0 0 1020 3040 200 250 506070 sini = 30 -40 Iteration of gradient descent \n150 -40 Iteration of gradient descent 150 -40 Iteration of gradient descent 150 Figure 8. Effect of gradient \ndescent on the control parameters of gearbox Figure 9. The parameters we want to synthesize are s1, \ns2,and s3 This function Error is highly discontinuous. Within a small (the coef.cients of the proportional, \nderivative, and integral com-subset of the input space, it evaluates to 0 everywhere else, it ponents \nof the controller), and b1 -b8 (parameters in the Boolean evaluates to 10. Such functions lead to the \nworst-case scenario expression deciding when to apply the brake). Known constants in-for a gradient descent \nalgorithm as the latter has no gradient to clude dt =0.1, target = p, inertia =10.0,and decay =0.9. follow. \nOn the other hand, smooth execution really shines in this As for the speci.cation, we want to ensure \nthat after exactly T is example. Smoothing creates a gradient that gradient descent can seconds, the \nwheel reaches its target position of target = p.The follow, and allows the algorithm to .nd optimal parameters \nfrom a precise error function is de.ned as follows: variety of starting points. To illustrate the effect \nof smoothing, consider Figure 10(a), Error(s1,s2,s3,b1,...,b8)= which shows Error as a function of s3 \nwith all other controls held if (target - E< ang < target + E) then 0 else 10, constant. Once again, \nthe effect of smoothing is dramatic. When \u00df is very small, the error function only has two deep groves, \nand it where E =0.00001 for all our experiments. A notion of trajectories is zero everywhere else. As \nwe increase the value of \u00df, the deep corresponding to this error function is easily de.ned we skip the \ngroves turn into gentle slopes. details. Error while(t<T){ if(b1 *d+ b2 >0 and b3 *v+ b4 >0 or b5 *d+ \nb6 >0 and b7 *v+ b8 >0){ if(v>0) brakev := -1; else brakev := 1; } else brakev := 0; d := dist(ang, target); \ntorq := s0 *d+ s1 *v+ s2 * id + brakev; id:=id decay+d; // id: integral of distance * oldv := v; // \nvelocity v: derivative of distance v := v + (torq / inertia) dt; * ang := ang + ( v + oldv)/2 dt; * \n* if (ang >2 p) ang:= ang-2 p; * else if (ang < 0) ang:= ang+ 2 p; * } Figure 9. PID controller with \na brake beta = 0.0001 start = 0.1 2.005 1.2 1 2 0.8 In the plot in Figure 10, we can observe the effect \nof setting N to higher or lower values. In this plot, N is the number of states maintained by the analysis. \nNotice that in most of the graph, the value of N doesn t really matter; the plot is very smooth regardless. \nWhen s3 starts becoming more positive, however, the system starts to become unstable, so path sensitivity \nbegins to matter more and more. Notice that for N =30, the loss of information due to merging of paths \ncauses major discontinuities in the function. Increasing N up to 150 virtually eliminates these effects, \nsince now the system can maintain enough path information to avoid building up approximation errors. \nOf course, higher values of N come at the cost of scalability. Finally, Figure 11 shows the effect that \nsmoothing has on our .nal goal of synthesizing parameters. The plots show the behavior of the solution \nfound by gradient descent after 90 iterations, with and without smoothing. The solution found without \nsmoothing is essentially useless; in this solution, the wheel starts with an angle of 2 radians, and \ndrifts slowly without much direction. The blue line in the chart shows the brake, which in this solution \nis engaged the whole time. In other words, without smoothing, gradient descent was completely unable \nto .nd an acceptable solution. By contrast, when we applied smoothing with \u00df =0.01 (which is actually \nfairly large, given that the unit here is a radian), the system was able to .nd a very good solution. \nThe wheel starts at two radians, and rotates in a very controlled manner towards its goal of p radians. \nAlso, the brake (blue line) is mostly disengaged until around 6 time units, when the brake suddenly becomes \nengaged, helping the angle in radians 0.6 1.995 wheel reach the desired position exactly at the desired \ntime.  0.4 ang Overall, we can see that for these benchmarks, discontinuities -2 024 6810 12 0.2 BREAK \nare a real obstacle to solving the parameter synthesis problem with 0 numerical optimization techniques. \nSmoothing is able to eliminate 1.99 1.985 -0.2 these discontinuities, making parameter synthesis possible. \nAddi\u00ad time tionally, the most signi.cant effect of our approximations are the beta = 0.01 start = 0.1 \nsmall discontinuities introduced by the Restrict operation. 6.14 7.14 1 1.2 6. Related work 4.14 5.14 \nGoal 0.8 So far as we know, the present paper is the .rst to develop a notion of smoothing for programs. \nWhile the idea of modeling software -0.86 0.14 1.14 2.14 3.14 024 68 10 0 0.2 0.4 0.6 12 ang BREAK by \nsmooth mathematical functions was previously considered by DeMillo and Lipton [6] in a brief note, their \nonly technical result was a simple proof that every discrete transition system can be captured by a smooth \nfunction. Neither did DeMillo and Lipton identify an application of this view of program semantics. \nangle in radians -1.86 -0.2 time Figure 11. Execution of the PID controller with the best parame\u00adters \nfound with \u00df=0.01 and 0.0001 Two interesting features are worth pointing out in Figure 10(a). First, \nas in the previous benchmark, smoothing has the effect of shifting the minima slightly. In fact, in this \ncase, we see a new local minimum appear around -0.1. If this appears strange, remember that the plot \nis only showing a slice of a multi-dimensional plot. What is happening is that smoothing is allowing \nus to observe a local minimum in a different dimension. The second feature is the noise to the right \nof the plot, par\u00adticularly for the most-smoothed curve (\u00df =0.3). This noise, it turns out, is an artifact \nof the approximation that we make with the Restrict operation to limit the number of components in our \nrep\u00adresentation of the distribution (see Section 3). These plots were all generated by setting the maximum \nnumber of components of a dis\u00adtribution to N =90. As we mentioned in Section 3, this Restrict operation \nis the only approximation we make that is capable of in\u00adtroducing discontinuities. However, Gaussian \nsmoothing is ubiquitous in signal and im\u00adage processing [17], and smooth approximations of boolean func\u00adtions \nis a well-studied topic in theoretical computer science [14]. The idea of using smooth approximations \nto improve the perfor\u00admance of gradient descent is well-known in the domain of neural networks [3]. The \nbasic unit of a neural network is a perceptron which has several real-valued inputs, and outputs 1 if \nand only if a weighted sum of these inputs is above a certain threshold. In mul\u00adtilayer perceptrons, \ncomparison of the weighted sum with a thresh\u00adold is replaced with the application of a sigmoid function, \nmaking learning more ef.cient. At a high level, our strategy is similar, as we also replace conditionals \nwith sigmoids. The difference is that in our setting, smoothing is tied to a speci.c probabilistic seman\u00adtics \nof programs, and the extent of smoothing at different points in the program are globally related by this \nsemantics. As for smooth interpretation, it is related to a line of recent work on probabilistic abstract \nand operational semantics [10, 13, 16] that builds on classic work on abstract interpretation [5] and \nproba\u00adbilistic semantics [12]. In particular, our work is related to Smith s work [18] on abstract interpretation \nusing truncated normal distri\u00adbutions. There are several important differences between Smith s approach \nand ours in particular, not being interested in veri.ca\u00ad Error as a function of s3, s1=0, s2=0 Effect \nof N on the quality of the smoothing for beta = 0.2 Error 10 9 8 7 6 5 4   Beta = 0.3 Beta = 0.2 Beta \n= 0.1 Beta = 0.05 Beta = 0.01 Beta = 0.001 -0.1 0 0.1 0.2 0.3 0.4 Value of S3 value of s3 (a) (b) Figure \n10. (a) Error function for PID controller as a function of s3 for different values of \u00df. (b) Error function \nas a function of s3 for different extents of path-sensitivity (N is the number of distinct distributions \nin an abstract state) tion of probabilistic safety properties, we do not use a collecting semantics or \noffer a notion of probabilistic soundness. The problem of tuning real-valued system parameters is a clas\u00adsic \nproblem in systems theory. In particular, the hybrid systems community has studied the problem [7, 9, \n11] in the context of embedded control applications such as ours. In their approach to the problem, a \ncyber-physical system is typically modeled as a hybrid automaton [1]; analysis approaches include simula\u00adtion, \nsymbolic reachability analysis, and counterexample-guided abstraction-re.nement. To the best of our knowledge, \nnone of this prior work frames parameter synthesis as a problem in numerical optimization, or uses smoothing \nor path-insensitivity. Related efforts on program synthesis includes the Sketch sys\u00adtem for combinatorial \nprogram sketching [19, 20], the ALisp sys\u00adtem [2], and the Autobayes system [8] for synthesis of Bayesian \nclassi.ers. Like our approach to parameter synthesis, these ap\u00adproaches aim to produce a program satisfying \na speci.cation given a partial program conveying the high-level insight of a solution. However, none \nof these systems use a notion of program approxi\u00admation akin to Gaussian smoothing.  7. Conclusion \nIn this paper, we have introduced a notion of Gaussian smoothing of programs, and presented an implementation \nof the smoothing trans\u00adform based on symbolic execution. Using the concrete problem of parameter synthesis \nand three embedded control applications, we have demonstrated that smoothing facilitates the use of numerical \nsearch techniques in the analysis of embedded control programs. The development of probabilistic and \nsmoothed semantics in this paper was fairly informal. We leave a rigorous study of the mathematical properties \nof smoothed semantics, as well as the bene.ts of program smoothing to numerical methods, for future work. \nA second thread of future work will study the interplay of program smoothing with static analysis. Approximations \nobtained from smoothing are more accurate if smoothing is applied only on regions of the input space \nwhere the program behaves in a discontinuous manner. It may be possible to use recent results on continuity \nanalysis of programs [4] to statically identify these regions. Finally, we plan to expand our technique \nfor parameter synthesis into a method that can synthesize discrete as well as real-valued program parameters \nand expressions. Such an approach will integrate the present approach with the sketching approach to \nprogram synthesis [19, 20].  References [1] R. Alur, C. Courcoubetis, N. Halbwachs, T. A. Henzinger, \nP.-H. Ho, X. Nicollin, A. Olivero, J. Sifakis, and S. Yovine. The algorithmic analysis of hybrid systems. \nTheor. Comput. Sci., 138(1):3 34, 1995. [2] D. Andre and S. Russell. State abstraction for programmable \nrein\u00adforcement learning agents. In AAAI/IAAI, pages 119 125, 2002. [3] C. Bishop. Neural Networks for \nPattern Recognition. 1995. [4] S. Chaudhuri, S. Gulwani, and R. Lublinerman. Continuity analysis of programs. \nIn POPL, 2010. [5] P. Cousot and R. Cousot. Abstract interpretation: a uni.ed lattice model for static \nanalysis of programs by construction or approxima\u00adtion of .xpoints. In POPL, 1977. [6] R. DeMillo and \nR. Lipton. De.ning software by continuous, smooth functions. IEEE Transactions on Software Engineering, \n17(4):383 384, 1991. [7] A. Donz\u00e9, B. Krogh, and A. Rajhans. Parameter synthesis for hybrid systems with \nan application to Simulink models. In HSCC, 2009. [8] B. Fischer and J. Schumann. AutoBayes: A system \nfor generating data analysis programs from statistical models. Journal of Functional Programming, 13(03):483 \n508, 2003. [9] G. Frehse, S. Jha, and B. Krogh. A counterexample-guided approach to parameter synthesis \nfor linear hybrid automata. In HSCC, pages 187 200, 2008. [10] S. Gulwani and G. Necula. Discovering \naf.ne equalities using random interpretation. In POPL, 2003. [11] T. Henzinger and H. Wong-Toi. Using \nHyTech to synthesize control parameters for a steam boiler. In Formal Methods for Industrial Applications, \npages 265 282, 1995. [12] D. Kozen. Semantics of probabilistic programs. J. Comput. Syst. Sci., 22(3):328 \n350, 1981. [13] D. Monniaux. Abstract interpretation of probabilistic semantics. In SAS, pages 322 339, \n2000. [14] N. Nisan and M. Szegedy. On the degree of Boolean functions as real polynomials. Computational \nComplexity, 4(4):301 313, 1994. [15] D. Parnas. Software aspects of strategic defense systems. Communi\u00adcations \nof the ACM, 28(12):1326 1335, 1985. [16] A. Di Pierro and H. Wiklicky. Probabilistic abstract interpretation \nand statistical testing. In PAPM-PROBMIV, pages 211 212, 2002. [17] J. Russ. The image processing handbook. \nCRC Press, 2007. [18] M. Smith. Probabilistic abstract interpretation of imperative programs using truncated \nnormal distributions. Electron. Notes Theor. Comput. Sci., 220(3):43 59, 2008. [19] A. Solar-Lezama, \nR. M. Rabbah, R. Bod\u00edk, and K. Ebcioglu. Pro\u00adgramming by sketching for bit-streaming programs. In PLDI, \npages 281 294, 2005. [20] A. Solar-Lezama, L. Tancau, R. Bodik, V. Saraswat, and S. Seshia. Combinatorial \nsketching for .nite programs. In ASPLOS 06, 2006. [21] G. N. Vanderplaats. Numerical optimization techniques. \nSpringer-Verlag, 1987.  \n\t\t\t", "proc_id": "1806596", "abstract": "<p>We present <i>smooth interpretation</i>, a method to systematically approximate numerical imperative programs by smooth mathematical functions. This approximation facilitates the use of numerical search techniques like gradient descent for program analysis and synthesis. The method extends to programs the notion of <i>Gaussian smoothing</i>, a popular signal-processing technique that filters out noise and discontinuities from a signal by taking its convolution with a Gaussian function.</p> <p>In our setting, Gaussian smoothing executes a program according to a probabilistic semantics; the execution of program <i>P</i> on an input <i>x</i> after Gaussian smoothing can be summarized as follows: (1) Apply a Gaussian perturbation to <i>x</i> -- the perturbed input is a random variable following a normal distribution with mean <i>x</i>. (2) Compute and return the <i>expected output</i> of <i>P</i> on this perturbed input. Computing the expectation explicitly would require the execution of <i>P</i> on all possible inputs, but smooth interpretation bypasses this requirement by using a form of symbolic execution to approximate the effect of Gaussian smoothing on <i>P</i>. The result is an efficient but approximate implementation of Gaussian smoothing of programs.</p> <p>Smooth interpretation has the effect of attenuating features of a program that impede numerical searches of its input space -- for example, discontinuities resulting from conditional branches are replaced by continuous transitions. We apply smooth interpretation to the problem of synthesizing values of numerical control parameters in embedded control applications. This problem is naturally formulated as one of numerical optimization: the goal is to find parameter values that minimize the error between the resulting program and a programmer-provided behavioral specification. Solving this problem by directly applying numerical optimization techniques is often impractical due to the discontinuities in the error function. By eliminating these discontinuities, smooth interpretation makes it possible to search the parameter space efficiently by means of simple gradient descent. Our experiments demonstrate the value of this strategy in synthesizing parameters for several challenging programs, including models of an automated gear shift and a PID controller.</p>", "authors": [{"name": "Swarat Chaudhuri", "author_profile_id": "81309496839", "affiliation": "Pensylvania State University, University Park, USA", "person_id": "P2184564", "email_address": "", "orcid_id": ""}, {"name": "Armando Solar-Lezama", "author_profile_id": "81100173160", "affiliation": "MIT, Cambridge, MA, USA", "person_id": "P2184565", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806629", "year": "2010", "article_id": "1806629", "conference": "PLDI", "title": "Smooth interpretation", "url": "http://dl.acm.org/citation.cfm?id=1806629"}