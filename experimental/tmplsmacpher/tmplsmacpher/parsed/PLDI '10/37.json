{"article_publication_date": "06-05-2010", "fulltext": "\n Mixing Type Checking and Symbolic Execution Khoo Yit Phang Bor-Yuh Evan Chang Jeffrey S. Foster University \nof Maryland, College Park University of Colorado, Boulder University of Maryland, College Park khooyp@cs.umd.edu \nbec@cs.colorado.edu jfoster@cs.umd.edu Abstract Static analysis designers must carefully balance precision \nand ef\u00ad.ciency. In our experience, many static analysis tools are built around an elegant, core algorithm, \nbut that algorithm is then exten\u00adsively tweaked to add just enough precision for the coding idioms seen \nin practice, without sacri.cing too much ef.ciency. There are several downsides to adding precision in \nthis way: the tool s imple\u00admentation becomes much more complicated; it can be hard for an end-user to \ninterpret the tool s results; and as software systems vary tremendously in their coding styles, it may \nrequire signi.cant algo\u00adrithmic engineering to enhance a tool to perform well in a particular software \ndomain. In this paper, we present MIX, a novel system that mixes type checking and symbolic execution. \nThe key aspect of our approach is that these analyses are applied independently on disjoint parts of \nthe program, in an off-the-shelf manner. At the boundaries between nested type checked and symbolically \nexecuted code regions, we use special mix rules to communicate information between the off\u00adthe-shelf \nsystems. The resulting mixture is a provably sound analy\u00adsis that is more precise than type checking \nalone and more ef.cient than exclusive symbolic execution. In addition, we also describe a prototypeimplementation, \nMIXY,forC. MIXY checksforpotential null dereferences by mixing a null/non-null type quali.er inference \nsystem with a symbolic executor. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program \nVeri.cation; D.2.5 [Software Engineer\u00ading]: Testing and Debugging Symbolic execution; F.3.2 [Log\u00adics \nand Meanings of Programs]: Semantics of Programming Lang\u00aduages Program analysis General Terms Languages, \nVeri.cation Keywords Mix, mixed off-the-shelf analysis, symbolic execution, type checking, mix rules, \nfalse alarms, precision 1. Introduction All static analysis designers necessarily make compromises be\u00adtween \nprecision and ef.ciency. On the one hand, static analysis must be precise enough to prove properties \nof realistic software systems, and on the other hand, it must run in a reasonable amount of time and \nspace. One manifestation of this trade-off is that, in our experience, many practical static analysis \ntools begin with a rel- Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 10, June 5 10, 2010, Toronto, Ontario, Canada. Copyright &#38;#169; 2010 ACM 978-1-4503-0019-3/10/06. \n. . $10.00 atively straightforward algorithm at their core, but then gradually accrete a multitude of \nspecial cases to add just enough precision without sacri.cing ef.ciency. Some degree of .ne tuning is \ninevitable undecidability of static analysis means that analyses must be targeted to programs of interest \nbut an ad-hoc approach has a number of disadvan\u00adtages: it signi.cantly complicates the implementation \nof a static analysis algorithm; it is hard to be sure that all the special cases are handled correctly; \nand it makes the tool less predictable and understandable for an end-user since the exact analysis algorithm \nbecomes obscured by the special cases. Perhaps most signi.cantly, software systems are extremely diverse, \nand programming styles vary greatly depending on the application domain and the idiosyn\u00adcrasies of the \nprogrammer and her community s coding standards. Thus an analysis that is carefully tuned to work in \none domain may not be effective in another domain. In this paper, we present MIX, a novel system that \ntrades off pre\u00adcision and ef.ciency by mixing type checking a coarse but highly scalable analysis with \nsymbolic execution [King 1976], which is very precise but inef.cient. In MIX, precision versus ef.ciency \nis adjusted using typed blocks {t e t} and symbolic blocks {s e s}that indicate whether expression e \nshould be analyzed with type checking or symbolic execution, respectively. Blocks may nest ar\u00adbitrarily \nto achieve the desired level of precision versus ef.ciency. The distinguishing feature of MIX is that \nits type checking and symbolic execution engines are completely standard, off-the-shelf implementations. \nWithin a typed or symbolic block, the analyses run as usual. It is only at the boundary between blocks \nthat we use special mix rules to translate information back-and-forth between the two analyses. In this \nway, MIX gains precision at limited cost, while potentially avoiding many of the pitfalls of more complicated \napproaches. As a hypothetical example, consider the following code: 1 {s 2 if (multithreaded){t fork(); \nt} 3 {t ... t} 4 if (multithreaded){t lock(); t} 5 {t ... t} 6 if (multithreaded){t unlock(); t} 7 s} \n This code uses multiple threads only if multithreaded is set to true. Suppose we have a type-based analysis \nthat checks for data races. Then assuming the analysis is path-insensitive, it cannot tell whether a \nthread is created on line 2, and it does not know the lock state after lines 4 and 6 all of which will \nlead to false positives. Rather than add path-sensitivity to our core data race analysis, we can instead \nuse MIX to gain precision. We wrap the program in a symbolic block at the top level so that the executions \nfor each setting of multithreaded will be explored independently. Then for performance, we wrap all the \nother code (lines 3 and 5 and the calls to fork, lock, and unlock) in typed blocks, so that they are \nanalyzed with the type-based analysis. In this case, these block annotations effectively cause the type-based \nanalysis to be run twice, once for each possible setting of multithreaded; and by separating those two \ncases, we avoid con.ation and eliminate false positives.  While MIX cannot address every precision/ef.ciency \ntradeoff issue (for example, the lexical scoping of typed and symbolic blocks is one limitation), there \nare nonetheless many potential ap\u00adplications. Among other uses, MIX can encode forms of .ow\u00adsensitivity, \ncontext-sensitivity, path-sensitivity, and local type re\u00ad.nements. MIX can also use type checking to \novercome some lim\u00aditations of symbolic execution (Section 2). Also, for the purposes of this paper, we \nleave the placement of block annotations to the programmer, but we envision that an automated re.nement \nalgo\u00adrithm could heuristically insert blocks as needed. In this scenario, MIX becomes an intermediate \nlanguage for modularly combining off-the-shelf analyzer implementations. In this paper, we formalize \nMIX for a small imperative lan\u00adguage, mixing a standard type checking system with symbolic ex\u00adecution \nto yield a system to check for the absence of run-time type errors. Thus, rather than checking for assertion \nfailures, as a typical symbolic executor might do, our formal symbolic executor reports any type mismatches \nit detects. To mix these two systems together, we introduce two new rules: one rule in the type system \nthat type checks blocks {s e s} using the symbolic executor; and one rule in the symbolic executor that \nexecutes blocks {t e t} using the type checker. We prove that the type system, symbolic executor, and \nmix of the two systems are sound. The soundness proof of MIX uses the proofs of type soundness and symbolic \nexecution sound\u00adness essentially as-is, which provides some additional evidence of a clean modularization. \nAdditionally, two features of our formalism for symbolic execution may be of independent interest: we \ndiscuss the tradeoff between forking the symbolic executor and giving more work to the solver; and we \nprovide a soundness proof, which, surprisingly, we have been unable to .nd for previous symbolic ex\u00adecution \nsystems (Section 3). Finally, we describe MIXY, a prototype implementation of MIX for C. MIXY combines \na simple, monomorphic type quali.er in\u00adference system (a reimplementation of Foster et al. [2006]) with \na C symbolic executor. There are two key challenges that arise when mixing type inference rather than \nchecking: we need to perform a .xed-point computation as we switch between typed and sym\u00adbolic blocks \nsince data values can pass from one to the other and back; and we need to integrate aliasing information \ninto our analy\u00adsis so that pointer manipulations performed within symbolic blocks correctly in.uence \ntyped blocks. Additionally, we extend MIXY to support caching block results as well as recursion between \nblocks. We use MIXY to look for null pointer errors in a reasonably-sized benchmark vsftpd; we found \nseveral examples where adding sym\u00adbolic blocks can eliminate false positives compared to pure type quali.er \ninference (Section 4). We believe that MIX provides a promising new approach to trading off precision \nand ef.ciency in static analysis. We expect that the ideas behind MIX can be applied to many different \ncombi\u00adnations of many different analyses. 2. Motivating Examples Before describing MIX formally, we examine \nsome coding idioms for which type inference and symbolic execution can pro.tably be mixed. Our examples \nwill be written in either an ML-like language or C-like language, depending on which one is more natural \nfor the particular example. Path, Flow, and Context Sensitivity. In the introduction, we saw one example \nin which symbolic execution introduced a small amount of path sensitivity to type inference. There are \nseveral po\u00adtential variations on this example where we can locally add a little bit of path sensitivity \nto increase the precision of type checking. For example, we can avoid analyzing unreachable code: {t \n... {s if true then{t 5 t}else {t foo + 3 t}s} ... t} This code runs without errors, but pure type checking \nwould com\u00adplain about the potential type error in the false branch. However, with these block annotations \nadded in MIX, the symbolic executor will only invoke the type checker for the true branch and hence will \navoid a false positive. We can also use symbolic execution to gain some .ow sensi\u00adtivity. For example, \nin a dynamically-typed imperative language, programmers may reuse variables as different types, such \nas in the following: {t ... {s var x = 1;{t ... t}; x = foo ; s} ... t} Here the local variable x is \n.rst assigned an integer and is later reused to refer to a string. With the annotations above, we can \nsuccessfully statically check such code using the symbolic executor to distinguish the two different \nassignments to x, then type check the code in between. Similar cases can occur if we try to apply a non-standard \ntype system to existing code. For example, in our case study (Sec\u00ad tion 4.5), we applied a nullness checker \nbased on type quali.ers to C. We found some examples like the following code: {t ... {s x.obj = NULL; \nx.obj = (...)malloc( ...); s} ...t} Here x.obj is initially assigned to NULL, immediately before be\u00ading \nassigned a freshly allocated location. A .ow-insensitive type quali.er system would think that x.obj \ncould be NULL after this pair of assignments, even though it cannot be. Finally, we can also use symbolic \nexecution to gain context\u00adsensitivity, though at the cost of duplicate work. For example, in the following: \n{s let id x = x in{t ... {s id 3 s} ... {s id 3.0 s} ... t} s} the identity function id is called with \nan int and a .oat. Rather than adding parametric polymorphism to type check this example, we could wrap \nthose calls in symbolic blocks, which in MIX causes the calls to be checked with symbolic execution. \nWhile this is likely not useful for standard type checking, for which parametric polymorphism is well-understood, \nit could be very useful for a more advanced type system for which fully general parametric polymorphic \ntype inference might be dif.cult to implement or perhaps even undecidable. A combination of context sensitivity \nand path sensitivity is possible with MIX. For example, consider the following: {s let div x y = if y=0 \nthen err else x/y in {t ...+{s div 7 4 s} t} s} where the div function may return an int or a string, \nbut it returns a string (indicating error) only when the second argument is 0. Note that this level of \nprecision would be out of the reach of parametric polymorphism by itself. Local Re.nements of Data. Symbolic \nexecution can also poten\u00adtially be used to model data more precisely for non-standard type systems. As \none example, suppose we introduce a type quali.er system that distinguishes the sign of an integer as \neither positive, negative, zero, or unknown. Then we can use symbolic execution to re.ne the type of \nan integer after a test: {t let x: unknown int = ...in {s  if x > 0 then{t (* x : pos int *) ...t} else \nif x=0 then{t (* x : zero int *) ...t} else{t (* x : neg int *) ...t} s} t} Here on entry to the symbolic \nblock, x is an unknown integer, so the symbolic executor will assign it an initial symbolic value ax \nranging over all possible integers. Then at the conditional branches, the symbolic executor will fork \nand explore the three possibilities: ax > 0, ax =0, and ax < 0. On entering the typed block in each branch, \nsince the value of x is constrained in the symbolic execution, the type system will start with the appropriate \ntype for x, either pos, zero, or neg int, respectively. As another example, suppose we have a type system \nto prevent data races in C. Then a common problem that arises is analyzing local initialization of shared \ndata [Pratikakis et al. 2006]. Consider the following code: {t {s x=(struct foo *) malloc(sizeof(struct \nfoo)); x.bar = ... ; x.baz = ...; x.qux = ... ; s} insert(shared data structure, x); t} Here we allocate \na new block of memory and then initialize it in several steps before it becomes shared. A .ow-insensitive \ntype\u00adbased analysis would report an error because the writes through x occur without a lock held. On \nthe other hand, if we wrap the allocation and initialization in a symbolic block, as above, symbolic \nexecution can easily observe that x is local during the initialization phase, and hence the writes need \nnot be protected by a lock. Helping Symbolic Execution. The previous examples considered adding precision \nin type checking through symbolic execution. Alternatively, typed blocks can potentially be used to introduce \nconservative abstraction in symbolic execution when the latter is not viable. For example: {s let x={t \nunknown function() t}in ... let y={t 2**z (* operation not supported by solver *) t}in ... {t while true \ndo{s loop body s}t}s} The .rst line contains a call to a function whose source code is not available, \nso we cannot symbolically execute the call. However, if we know the called function s type, then we can \nwrap the call in a typed block (assuming the function has no side effects), conser\u00advatively modeling \nits return value as any possible member of its return type. Similarly, on the second line, we are performing \nan exponentiation operation, and let us suppose the symbolic execu\u00adtor s solver cannot model this operation \nif z is symbolic. Then by wrapping the operation in a typed block, we can continue symbolic execution, \nagain conservatively assuming the result of the exponen\u00adtiation is any member of the result type. The \nthird line shows how we could potentially handle long-running loops by wrapping them in typed blocks, \nso that symbolic execution would effectively skip over them rather than unroll them (in.nitely). We can \nalso recover some precision within the loop body by further wrapping the loop body with a symbolic block. \n3. The MIX System In the previous section, we considered a number of idioms that motiviate the design \nof MIX. Here, we consider a core language, Source Language. e ::= x | v variables, constants | e + e \narithmetic | e = e |\u00ace | e . e predicates | if e then e else e conditional | let x = e in e let-binding \n| ref e | !e | e := e references |{t e t} type checking block |{s e s} symbolic execution block v ::= \nn | true | false concrete values Types, Symbolic Expressions, and Environments. t ::= int | bool | t \nref types G ::= \u00d8| G,x : t typing environment s ::= u:t typed symbolic expressions g ::= u:bool guards \nu ::= a | v symbolic variables, constants | u:int + u:int arithmetic | s = s |\u00acg | g . g predicates | \nm[u:t ref] memory select m ::= \u00b5 arbitrary memory | m, (s -s) memory update | m, (s -as) memory allocation \nS ::= \u00d8| S,x : s symbolic environment Figure 1. Program expressions, types, and symbolic expressions. \nshown in the top portion of Figure 1, with which we study the essence of switching blocks for mixing \nanalyses. Our language in\u00adcludes variables x; integers n; booleans true and false; selected arithmetic \nand boolean operations +, =, \u00ac, and .; conditionals with if; let bindings; and ML-style updatable references \nwith ref (construction), ! (dereference), and := (assignment). We also in\u00adclude two new block forms, \ntyped blocks {t e t} and symbolic blocks {s e s}, which indicate e should be analyzed with type checking \nor symbolic execution, respectively. We leave unspeci\u00ad.ed whether the outermost scope of a program is \ntreated as a typed block or a symbolic block; MIX can handle either case. 3.1 Type Checking and Symbolic \nExecution Type checking for our source language is entirely standard, and so we omit those rules here. \nOur type checking system proves judgments of the form G f e : t , where G is the type environment and \nt is e s type. Grammars for G and t are given in the bottom portion of Figure 1. The remainder of this \nsection describes a generic symbolic ex\u00adecutor. While the concept of symbolic execution is widely known, \nthere does not appear to be a clear consensus of its de.nition. Thus, we make explicit our de.nition \nof symbolic execution here through a formalization similar to an operational semantics. Such a formal\u00adization \nenables us to describe the switching between type checking and symbolic execution in a uniform manner. \nSymbolic Expressions, Memories, and Environments. The re\u00admainder of Figure 1 describes the symbolic expressions \nand en\u00ad vironments used by our symbolic executor. Symbolic expressions are used to accumulate constraints \nin dereferral rules. For example, the symbolic expression (a:int + 3:int):int represents a value that \nis three more than the unknown integer a. Because we are concerned with checking for run-time type er\u00adrors, \nin our system symbolic expressions s have the form u:t , where u is a bare symbolic expression and t \nis its type. With these type annotations, we can immediately determine the type of a sym\u00adbolic expression, \njust like in a concrete evaluator with values. As a  Symbolic Execution. S f(S ; e).(S' ; s) S = (g \n; m) may be symbolic variables a (e.g., a:int is a symbolic integer, and a:bool is a symbolic boolean); \nknown values v; or operations +, =, \u00ac, . applied to symbolic expressions of the appropriate type. Notice \nthat our syntax forbids the formation of certain ill-typed symbolic expression (e.g., a1:int + a2:bool \nis not allowed). Symbolic expressions also include symbolic memory accesses m[u:t ref], which represents \nan access through pointer u in sym\u00adbolic memory m. A symbolic memory may be \u00b5, representing an ' arbitrary \nbut well-typed memory; m, (ss), a memory that - is the same as m except location s is updated to contain \ns'; or ' m, (s a s), which is the same as m except newly allocated lo\u00ad - cation s points to s'. These \nare essentially McCarthy-style sel and upd expressions that allow the symbolic executor to accumulate \na log of writes and allocations while deferring alias analysis. An allocation always creates a new location \nthat is distinct from the lo\u00adcations in the base unknown memory, so we distinguish them from arbitrary \nwrites. Finally, symbolic environments S map local variables x to (typed) symbolic expressions s. Symbolic \nExecution for Pure Expressions. Figure 2 describes our symbolic executor on pure expressions using what \nare essen\u00adtially big-step operational semantics rules. The rules in Figure 2 prove judgments of the form \n' S f(S ; e).(S; s) meaning with local variables bound in S, starting in state S, expres\u00adsion e evaluates \nto symbolic expression s and updates the state to S'. In our symbolic execution judgment, a state S is \na tuple (g ;m), where g is a path condition constraining the current state and m is the current symbolic \nmemory. The path condition begins as true, and whenever the symbolic executor makes a choice at a condi\u00adtional, \nwe extend the path condition to remember that choice (more on this below). We write X(S) for the X component \nof S, with X .{g, m}, and similarly we write S[X . Y ] for the state that is the same as S, except its \nX component is now Y . Most of the rules in Figure 2 are straightforward and intend to summarize typical \nsymbolic executors. Rule SEVAR evaluates a local variable by looking it up in the current environment. \nNotice that, as with standard operational semantics, there is no reduction possible if the variable is \nnot in the current environment. Rule SEVAL reduces values to themselves, using the auxiliary function \ntypeof(v) that examines the value form to return its type (i.e., typeof(n)= int and typeof(true) = typeof(false)= \nbool). Rules SEPLUS, SEEQ, SENOT, and SEAND execute the subexpressions and then form a new symbolic expression \nwith +, =, \u00ac, or ., respectively. Notice that these rules place requirements on the subexpressions for \nexample, SEPLUS requires that the subexpressions reduce to symbolic integers, and SENOT requires that \nthe subexpression reduces to a guard (a symbolic boolean). If the subexpression does not reduce to an \nexpression of the right type, then symbolic execution fails. Thus, these rules form a symbolic execution \nengine that does very precise dynamic type checking. Rule SELET symbolicallyexecutes e1 and then binds \ne1 to x for execution of e2. The last two rules, SEIF-TRUE and SEIF-FALSE, model a pure, non-deterministic \nversion of the kind of symbolic ex\u00adecution popularized by DART [Godefroid et al. 2005], CUTE [Sen et \nal. 2005], EXE [Cadar et al. 2006], and KLEE [Cadar et al. 2008]. When we reach a conditional, we conceptually \nfork exe\u00ad cution, extending the path condition with g1 or \u00acg1 to indicate the branch taken. EXE and KLEE \nwould both invoke an SMT solver at this point to decide whether one or both branches are feasible, and \nthen try all feasible paths. DART and CUTE, in contrast, would continue down one path as guided by an \nunderlying concrete run SEVAR S,x : s f(S ; x).(S ; s) SEVAL S f(S ; v).(S ;(v: typeof(v))) SEPLUS S \nf(S ; e1).(S1 ; u1:int) S f(S1 ; e2).(S2 ; u2:int) S f(S ; e1 + e2).(S2 ;(u1:int + u2:int):int) SEEQ \nS f(S ; e1).(S1 ; u1:t) S f(S1 ; e2).(S2 ; u2:t ) S f(S ; e1 = e2).(S2 ;(u1:t = u2:t ):bool) SENOT S \nf(S ; e1).(S1 ; g1) S f(S ; \u00ace1).(S1 ; \u00acg1:bool) SEAND S f(S ; e1).(S1 ; g1) S f(S1 ; e2).(S2 ; g2) S \nf(S ; e1 . e2).(S2 ;(g1 . g2):bool) SELET S f(S ; e1).(S1 ; s1) S,x : s1 f(S1 ; e2).(S2 ; s2) S f(S ; \nlet x = e1 in e2).(S2 ; s2) SEIF-TRUE S f(S ; e1).(S1 ; g1) S f(S1[g . g(S1) . g1]; e2).(S2 ; s2) S f(S \n; if e1 then e2 else e3).(S2 ; s2) SEIF-FALSE S f(S ; e1).(S1 ; g1) S f(S[g . g(S1) .\u00acg1]; e3).(S3 ; \ns3) S f(S ; if e1 then e2 else e3).(S3 ; s3) Figure 2. Symbolic execution for pure expressions. (so-called \nconcolic execution ), but then would ask an SMT solver later whether the path not taken was feasible \nand, if so, come back and take it eventually. All of these implementation choices can be viewed as optimizations \nto prune infeasible paths or hints to focus the exploration. Since we are not concerned with performance \nin our formalism, we simply extend the path condition and continue eventually, when symbolic execution \ncompletes, we will check the path condition and discard the path if it is infeasible. To get sound symbolic \nexecution, we will compute a set of symbolic executions and require that all feasible paths are explored \n(see Section 3.2). Sometimes, the symbolic executor may want to throw away information (e.g., replace \na symbolic expression for a compli\u00adcated memory read with a fresh symbolic variable). Such a rule is \nstraightforward to add, but as discussed in Section 3.2, a nested typed block {t e t} serves a similar \npurpose. Deferral Versus Execution. Consider again the rules for sym\u00adbolic execution on pure expressions \nin Figure 2. Excluding the triv\u00ad ial SEVAL rule, the .rst set of rules (SEPLUS, SEEQ, SENOT, and SEAND) \nversus the second set (SELET, SEVAR, SEIF-TRUE, SEIF-FALSE) seem qualitatively different. The .rst set \nsimply get symbolic expressions for their subexpressions and form a new sym\u00adbolic expression of the corresponding \noperator, essentially defer\u00adring any reasoning about the operation (e.g., to an SMT solver). In contrast, \nthe second set does not accumulate any such symbolic expression but rather chooses a possible concrete \nexecution to fol\u00adlow. For example, we can view SEIF-TRUE as choosing to assume that g1 is concretely \ntrue and proceeding to symbolically execute e2. This assumption is recorded in the path condition. (The \nSELET and SEVAR rules are degenerate execution rules where no assump\u00adtions need to be made because there \nis only one possible concrete execution for each.) Alternatively, we see that there are symbolic expression \nforms for +, =, \u00ac, and . but not for let, program vari\u00adables, and if.  Although it is not commonly presented \nas such, the decision of deferral versus execution is a design choice. For example, let us include an \nif-then-else symbolic expression g?s1:s2 (using a C\u00adstyle conditional syntax) that evaluates to s1 if \ng evaluates to true and s2 otherwise. Then, we could defer to the evaluation of the conditional to the \nsolver with the following rule: SEIF-DEFER S f(S ; e1).(S1 ; g1) S f(S[g . g(S1) . g1]; e2).(S2 ; u2:t \n) S f(S[g . g(S1) .\u00acg1]; e3).(S3 ; u3:t) S ' = ((g1?g(S2):g(S3)) ; (g1?m(S2):m(S3))) S f(S ;(if e1 then \ne2 else e3)).(S ' ;(g1?(u2:t):(u3:t )):t) Here notice we also have to extend the \u00b7? \u00b7 :\u00b7 relation to \noperate over memory as well. With this rule, we need not fork symbolic execution at all. However, note \nthat even with conditional symbolic expressions and condition symbolic memory, this rule is more con\u00adservative \nthan the SEIF-TRUE and SEIF-FALSE execution rules, as it requires both branches to have the same type. \nConversely, other rules may also be made non-deterministic in mannersimilarto SEIF-*.Forexample, SEVAR \nmayinsteadreturn an arbitrary value v and add S(x)= v to the path condition, a style that resembles hybrid \nconcolic testing [Majumdar and Sen 2007]. A special case of execution rules are ones that apply only \nwhen we have concrete values during symbolic execution and thus do not need to fork. For example, we \ncould have a SEPLUS-CONC that applies to two concrete values n1, n2 and returns the sum. This approach \nis reminiscent of partial evaluation. These choices trade off the amount of work done between the symbolic \nexecutor and the underlying SMT solver. For example, SEIF-DEFER introduces many disjunctions into symbolic \nexpres\u00adsions, which then may be hard to solve ef.ciently. To match current practice, we stick with the \nforking variant for conditionals, but we believe our system would also be sound with SEIF-DEFER. Symbolic \nReferences. Figure 3 continues our symbolic executor de.nition with rules for updatable references. We \nuse deferral rules for all aspects of references in our formalization. Rule SEREF eval\u00aduates e1 and extends \nm(S1) with an allocation for fresh symbolic pointer a. Similarly, rule SEASSIGN extends S2 to record \nthat s1 now points to s2. Observe that allocations and writes are simply logged during symbolic execution \nfor later inspection. Also, no\u00adtice that we allow any value to be written to s1, even if it does not \nmatch the type annotation on s1. In contrast, standard type systems require that any writes to memory \nmust preserve types since the type system does not track enough information about pointers to be sound \nif that property is violated. Symbolic execution tracks every possible program execution precisely, and \nso it can allow arbitrary memory writes. In SEDEREF, we evaluate e1 to a pointer u1:t ref and then produce \nthe symbolic expression m(S1)[u1:t ref]:t to represent the contents of that location. However, here we \nare faced with a challenge: we are not actually looking up the contents of memory; rather, we are simply \nforming a symbolic expression to represent Symbolic Execution for References. S f(S ; e).(S ' ; s) SEREF \nS f(S ; e1).(S1 ; u1:t ) a/. S, S, S1,u1 S ' = S1[m . (m(S1), (a:t ref a u1:t ))] - S f(S1 ; ref e1).(S \n' ; a:t ref) SEASSIGN S f(S ; e1).(S1 ; s1) S f(S1 ; e2).(S2 ; s2) S f(S ; e1 := e2).(S2[m . (m(S2), \n(s1 s2))] ; s2) - SEDEREF S f(S ; e1).(S1 ; u1:t ref)f m(S1) ok S f(S ;!e1).(S1 ; m(S1)[u1:t ref]:t ) \nMemory Type Consistency. f m ok U f m ok EMPTY-OK ALLOC-OK f m ok U f \u00b5 ok \u00d8f m, (a:t ref a u2:t) ok \nU - OVERWRITE-OK f m ok UU ' = U\\{s1 s2 | s1 = u1:t ref . s1 s2 . U} f m, (u1:t ref -u2:t) ok U ARBITRARY-NOTOK \nf m ok U f m, (s1 -s2) ok (U . {s1 -s2}) ' M-OK f m ok \u00d8 f m ok Figure 3. Symbolic execution for updatable \nreferences. the contents. How, then, do we determine the type of the pointed\u00adto value? We need the type \nso that we can halt symbolic execution later if that value is used in a type-incorrect manner. That is, \nwe do not want to defer the discovery of a potential type error. Our solution is to use the type annotation \non the pointer to get the type of the contents but above we just explained that SEASSIGN allows writes \nto violate those type annotations. There are many potential ways to solve this problem. We could invoke \nan SMT solver to compute the actual set of addresses that could be dereferenced and fork execution for \neach one. Or we could proceed as our implementation and use an external alias analysis to conservatively \nmodel all possible locations that could be read to check that the values at all locations have the same \ntype (Section 4). However, to keep the formal system simple, we choose a very coarse solution: we require \nthat all pointers in memory are well\u00adtyped with the check f m(S1) ok. This judgment is de.ned in the \nbottom portion of Figure 3 in terms of the auxiliary judgment f m ok U, which means mem\u00adory m is consistently \ntyped (pointers point to values of the right type), except for mappings in U. There are four cases for \nthis judg\u00adment. EMPTY-OK says that arbitrary well-typed memory \u00b5 is con\u00adsistently typed. Similarly, ALLOC-OK \nsays that if m is consistently typed except for potentially inconsistent writes in U, then adding an \nallocation preserves consistent typing up to U . Rule OVERWRITE-OK says that if f m ok U and we extend \nm with a well-typed write to u1, then any previous, inconsistent writes to locations s1 = u1:t ref can \nbe ignored. Here by = we mean syntactic equiv\u00adalence, but in practice we could query a solver to validate \nsuch an equality given the current path condition. Rule ARBITRARY-NOTOK says that any write can be added \nto U and viewed as po\u00adtentially inconsistent. Finally, M-OK says that f m ok if m has no  TSYMBLOCK \nS(x)= ax:G(x) (for all x . dom(G)) S f(S ; e).(Si ; ui:t) S = (true ; \u00b5) \u00b5/. S f m(Si) ok exhaustive(g(S1),...,g(Sn)) \n(i . 1..n) G f{s e s} : t exhaustive(g1,...,gn) .. (g1 . ... . gn is a tautology) Block Symbolic Execution. \nS f(S ; e).(S ' ; s) SETYPBLOCK f S:G f m(S) ok G f e : t\u00b5 ' ,a /. S,S S f(S ; {t e t}) . (S[m . \u00b5 ' \n]; a:t) Symbolic and Typing Environment Conformance. f S:G dom(S) = dom(G) S(x)= u:G(x) (for all x . \ndom(G)) f S:G Figure 4. Mixing symbolic execution and type checking. inconsistent writes that persist. \nTogether, these rules ensure that the type assigned to the result of a dereference is sound. We can also \nsee how the SEDEREF may be made more precise by only requir\u00ading consistency up to a set of writes U and \nquerying a solver to show that u1:t ref are disequal to all the address expressions in U.  3.2 Mixing \nIn the previous section, we considered type checking and symbolic execution separately, ignoring the \nblocks that indicate a switch in analysis. Figure 4 shows the two mix rules that capture switching between \nanalyses. Rule TSYMBLOCK describes how to type check a symbolic block {s e s}, that is, how to apply \nsymbolic execution to de\u00adrive a type of a subexpression for a type checker. First, we con\u00adstruct an environment \nS that maps each variable x in G to a fresh symbolic variable ax, whose type is extracted from G. Then \nwe run the symbolic execution under S, starting in a state with true for the path condition and a fresh \nsymbolic variable \u00b5 to stand for the current memory. Recall that, because of SEIF-TRUE and SEIF-FALSE, \nsymbolic execution is actually non-deterministic it conceptually can branch at conditionals. If we want \nto soundly model the entire possible behavior of e, we need to execute all paths. Thus, we run the symbolic \nexecutor n times, yielding .nal states (Si ; ui:t ) for i . 1..n, and we require that the disjunction \nof the guards from all executions form a tautology. This constraint ensures that we exhaustively explore \nevery possible path (see Sec\u00ad tion 3.3 about soundness). And if all those paths executed success\u00ad fully \nwithout type errors and returned a value of the same type t , then that is the type of expression e. \nWe also check that all paths leave memory in a consistent state. Symbolic execution has typically been \nused as an unsound anal\u00adysis where there is no exhaustiveness check like exhaustive(...) in the TSYMBLOCK. \nWe can also model such unsound analysis by weakening exhaustive(...) to a good enough check. The other \nrule, SETYPBLOCK, describes how to symbolically execute a typed block {t e t}, that is, how to apply \nthe type checker in the middle of a symbolic execution. We begin by deriving a type environment G that \nmaps local variables to the types of the symbols they are mapped to in S. This mapping is described precisely \nby the judgment f S:G, which is straightforward. We also require that the current symbolic memory state \nbe consistent, since the typed block relies purely on type information (rather than tracking pointer \nvalues as symbolic execution does). Then we type check e in G, yielding a type t. The typed block itself \nsymbolically evaluates to a fresh symbolic variable a of type t . Since the typed block may have written \nto memory, we conservatively set the memory of the output state to a fresh \u00b5 ', indicating we know nothing \nabout the memory state at that point except that it is consistent. Note that in our formalism, we do \nnot have typed blocks within typed blocks, or symbolic blocks within symbolic blocks, though these would \nbe trivial to add (by passing-through). Why Mix? The mix rules are essentially as precise as possible \ngiven the strengths and limitations of each analysis. The nested analysis starts with the maximum amount \nof information that can be extracted from the other static analysis for symbolic blocks, the only available \ninformation for symbolic execution is types, whereas for typed blocks, the type checker only cares about \ntypes of variables and thus abstracts away the symbolic expressions. After the nested analysis is complete, \nthe result is similarly passed back to the enclosing analysis as precisely as possible. For this paper, \nwe deliberately chose two analyses at oppo\u00adsite ends of the precision spectrum: type checking is cheap, \n.ow\u00adinsensitive with a rather coarse abstraction, while symbolic execu\u00adtion is expensive, .ow-and path-sensitive \n(and context-sensitive if we add functions) with a minimal amount of abstraction (i.e., it is not even \na proper program analysis per se, as there are no ter\u00admination guarantees). They also work in such a \ndifferent manner that it does not seem particularly natural to combine them in tighter ways (e.g., as \na reduced product of abstract interpreters [Cousot and Cousot 1979]). We think it is surprising just \nhow much additional precision we can obtain and the kinds of idioms we can analyze from such a simple \nmixing of an entirely standard type system and a typical symbolic executor as-is (as we see in Section \n2). We note that a type system capturing all of the examples in Section 2 would likely be quite advanced \n(involving, for example, dependent types). However, as can be seen in Figure 4, the conversion between \nthese two analyses may be extremely lossy. For example, in SETYPBLOCK, the memory after returning from \nthe type checker must be a fresh arbitrary memory \u00b5 ' because e may make any num\u00adber of writes not captured \nby the type system and thus not seen by the symbolic executor. We can also imagine mixing any number \nof analyses in arbitrary combination, yielding different precision/ef.\u00adciency tradeoffs. For example, \nif we were to use a type and effect system rather than just a type system, we could avoid introducing \na completely fresh memory \u00b5 ' in SETYPBLOCK instead, we could .nd the effect of e and limit applying \nthis havoc operation only to locations that could have been changed.  3.3 Soundness In this section, \nwe sketch the soundness of MIX, which is de\u00adscribed in full detail in the appendix of our companion technical \nreport [Khoo et al. 2010]. The key feature of our proof is that aside from the mix rule cases, it reuses \nthe standalone type soundness and symbolic execution soundness proofs essentially as-is. We show soundness \nwith respect to a standard big-step opera\u00adtional semantics for our simple language of expressions. Our \nse\u00admantics is given by a judgment E f(M; e). r. This says that in a concrete environment E, an initial \nconcrete memory M and an expression e evaluate to a result r. A concrete environment maps variables to \nvalues, while a concrete memory maps locations to val\u00adues. The evaluation result r is either a concrete \nmemory-value pair (M ' ; v) or a distinguished error token. To prove mix soundness, we consider simultaneously \ntype and symbolic execution soundness. While type soundness is standard, we discuss it brie.y, as it \nis a part of mix soundness, and provides intuition for symbolic execution soundness.  For type soundness, \nwe introduce a memory type environment . that maps locations to types, and we update the typing judgment \nto carry this additional environment, as G f. e : t where . is constant in all rules. In many proofs, \n. is included in G rather than being called out separately, but for Mix soundness separat\u00ading locations \nfrom variables makes the proof easier. To show type soundness, we need a relation between the concrete \nenvironment and memory (E; M) and the type environment and memory typing (G; .). We write this relation \nas (E; M)~(G; .), which infor\u00admally says two things: (1) the type environment G abstracts the concrete \nenvironment E, that is, the concrete value v mapped by each variable x in E has type G(x), and (2) the \nmemory typing . abstracts the concrete memory M, that is, the concrete value v at each location l in \nM has type .(l). We also talk about the second component in isolation, in which case we write M ~ . to \nmean memory typing . abstracts the concrete memory M. Type soundness is the .rst part of mix soundness \n(statement 1 in Theorem 1, shown below). Let us consider the pieces. Suppose we have a concrete evaluation \nE f(M; e). r. We further suppose that e has type t in typing environments that are sound with respect \nto the concrete state (i.e., (E; M)~(G; .)). Then, the result r must be a memory-value pair (M ' ; v) \nwhere the resulting concrete memory is abstracted by . ', an extension of ., and the resulting value \nv has the same type t in G with the extended memory typing . ' . Notice this captures the notions that \nwell-typed expressions cannot evaluate to error and that evaluation preserves typing. For symbolic execution \nsoundness, we need to ensure that a symbolic execution faithfully models actual concrete executions. \nLet V be a valuation, which is a .nite mapping from symbolic values a to concrete values v or concrete \nmemories M. We write [s]V , [m]V , and [S]V for the natural extension of V to operate on arbitrary symbolic \nexpressions, memories, and the symbolic en\u00advironment. Symbolic execution begins with symbolic values \na for unknown inputs and accumulates a symbolic expression s that rep\u00adresents the result of the program. \nThen at a high-level, if symbolic execution is sound, then a concrete run that begins with [a]V for inputs \nshould produce the expression [s]V . To formalize this notion, we need a soundness relation between the \nconcrete evaluation state and the symbolic execution state, just as in type soundness. The form of our \nsoundness relations for symbolic execution states is as follows: (E; M)~.0\u00b7V \u00b7. (S; m) This relation \ncaptures two key properties. First, applying the valu\u00adation V to the symbolic state should yield the \nconcrete state (i.e., [S]V = E and [m]V = M). Second, the types of symbolic ex\u00adpressions in S and m must \nbe correctly related. Recall that an addi\u00adtional property of our typed symbolic execution is that it \ntracks the type of symbolic expressions and halts upon encountering ill-typed expressions. The typing \nof symbolic reference expressions must be with respect to some memory typing. This memory typing is given \nby .0 and .. For technical reasons, we need to separate the loca\u00adtions in the arbitrary memory on entry \n.0 from the locations that come from allocations during symbolic execution .; to get typing for the entire \nmemory, we write .0 * . to mean the union of sub\u00admemory typings .0 and . with disjoint domains. Analogously, \nwe also have a symbolic soundness relation that applies to memory\u00advalue pairs: (M; v)~.0\u00b7V \u00b7. (m; s). \nAs alluded to above, we .rst consider a notion of symbolic ex\u00adecution soundness with respect to a concrete \nexecution. This no\u00adtion is what is stated in the second part of mix soundness (Theo\u00ad rem 1). Analogous \nto type soundness, it says that suppose we have a concrete evaluation E f(M; e). r and a symbolic execution \nS f(S;e).(S ' ;s) such that the symbolic state is an abstraction of the concrete state (i.e., (E; M)~.0\u00b7V \n\u00b7. (S; m(S))). There is one more premise, [g(S ' )]V , which says that the path condition accu\u00admulated \nduring symbolic execution holds under this valuation. This constrains the concrete and symbolic executions \nto follow the same path. With these premises, symbolic execution soundness says that the result of symbolic \nexecution, that is the memory-symbolic ex\u00adpression pair (m(S ' ); s), is an abstraction of the concrete \nevalua\u00adtion result, which must be a memory-value pair (M ' ; v). Theorem 1 (MIX Soundness) 1. If E f(M; \ne). r and G f. e : t such that (E; M)~(G; .) , then \u00d8f.N v : t and M ' ~ . ' for some M ' , v, . ' such \nthat r = (M ' ; v) and . ' . .. 2. If E f(M; e). r and S f(S ; e).(S ' ; s) such that (E; M)~.0\u00b7V \u00b7. \n(S; m(S)) and [g(S ' )]V , then r ~.N\u00b7V NN (m(S ' ); s) for some V ' . V and some \u00b7. 0 . ' 0, . ' such \nthat .0 ' * . ' . .0 * .. PROOF By simultaneous induction on the derivations of E f(M; e). r. The proof \nis given in the appendix of our companion technical report [Khoo et al. 2010].  This statement of symbolic \nexecution soundness (part 2 in The\u00ad orem 1) is what we need to show MIX sound, but at .rst glance, it \nseems suspect because it does not say anything about symbolic execution being exhaustive. However, if \nwe look at type checking a symbolicblock(i.e.,rule TSYMBLOCK),exhaustivenessisensured through the exhaustive(...) \nconstraint. In particular, we can state exhaustive symbolic execution as a corollary, and the case for \nTSYMBLOCK proceeds in the same manner as this corollary. Corollary 1.1 (Exhaustive Symbolic Execution) \nSuppose E f(M; e).(M ' ; v) and we have n> 0 symbolic executions S f ((true; m) ; e).(Si ; si) such that \nexhaustive(g(S1),...,g(Sn)) and (E; M)~.0\u00b7V \u00b7. (S; m) , then (M ' ; v)~.N\u00b7V N\u00b7.N (m(Si); si) for some \ni . 1..n, V ' . 0 V , and some . ' 0, . ' such that . ' 0 * . ' . .0 * .. Here we say that if we have \nn> 0 symbolic executions that each start with a path condition of true and where their resulting path \nconditions are exhaustive (i.e., g(S1) . ... . g(Sn) is a tautology meaning it holds under any valuation \nV ), then one of those sym\u00adbolic executions must match the concrete execution. Observe that in this statement, \nthere is no premise on the resulting path condi\u00adtion, but rather that we start with a initial path condition \nof true. 4. MIXY: A Prototype of MIX for C We have developed MIXY, a prototype tool for C that uses MIX \nto detect null pointer errors. MIXY mixes a (.ow-insensitive) type quali.er inference system with a symbolic \nexecutor. MIXY is built on top of the CIL front-end for C [Necula et al. 2002], and our type quali.er \ninference system, CilQual, is essentially a simpli.ed CIL reimplementation of the type quali.er inference \nalgorithm described by Foster et al. [2006]. Our symbolic executor, Otter [Reisner et al. 2010], uses \nSTP [Ganesh and Dill 2007] as its SMT solver and works in a manner similar to KLEE [Cadar et al. 2008]. \n Type Quali.ers and Null Pointer Errors. For this application, we introduce two quali.er annotations \nfor pointers: nonnull indicates that a pointer must not be null, and null indicates that a pointer may \nbe null. Our inference system automatically annotates uses of the NULL macro with the null quali.er annotation. \nThe type quali.er inference system generates constraints among known quali.ers and unknown quali.er variables, \nsolves those constraints, and then reports a warning if null values may .ow to nonnull positions. Thus, \nour type quali.er inference system ensures pointers that may be null cannot be used where non-null pointers \nare required. For example, consider the following C code: 1 void free(int *nonnull x); 2 int *id(int \n*p) { return p; } 3 int *x = NULL; 4 int *y = id(x); 5 free(y); Here on line 1 we annotate free to indicate \nit takes a nonnull pointer. Then on line 3, we initialize x to be NULL, pass that value through id, and \nstore the result in y on line 4. Then on line 5 we call free with NULL. Our quali.er inference system \nwill generate the following types and constraints (with some simpli.cations, and ignoring l-and r\u00advalue \nissues): free : int * nonnull . void x : int *\u00df id : int *. . int *d y : int *E null = \u00df\u00df = .. = dd = \nEE = nonnull Here \u00df, ., d, and E are variables that standard for unknown quali\u00ad.ers. Put together, these \nconstraints require null = nonnull, which is not allowed, and hence quali.er inference will report an \nerror for this program. Our symbolic executor also looks for null pointer errors. The symbolic executor \ntracks C values at the bit level, using a repre\u00adsentation similar to KLEE [Cadar et al. 2008]. A null \npointer is represented as the value 0, and the symbolic executor reports an error if 0 is ever dereferenced. \nTyped and Symbolic Blocks. In our formal system, we allow typed and symbolic blocks to be introduced \nanywhere in the program. In MIXY, these blocks can only be introduced around whole function bodies by \nannotating a function as MIX(typed) or MIX(symbolic), and MIXY switches between quali.er inference and \nsymbolic execution at function calls. We can simulate blocks within functions by manually extracting \nthe relevant code into a fresh function. Skipping some details for the moment, this switching process \nworks as follows. When MIXY is invoked, the programmer speci\u00ad.es (as a command-line option) whether to \nbegin in a typed block or a symbolic block. In either case, we .rst initialize global variables as appropriate \nfor the analysis, and then analyze the program start\u00ading with main. In symbolic execution mode, we begin \nsimulating the program at the entry function, and at calls to functions that are either unmarked or are \nmarked as symbolic, we continue symbolic execution into the function body. At calls to functions marked \nwith MIX(typed), we switch to type inference starting with that function. In type inference mode, we \nbegin analysis at the entry function f, applying quali.er inference to f and all functions reachable \nfrom f in the call graph, up to the frontier of any functions that are marked with MIX(symbolic). We \nuse CIL s built-in pointer analysis to .nd the targets of calls through function pointers. Finally, we \nswitch to symbolic execution for each function marked MIX(symbolic) that was discovered at the frontier. \nIn this section, we describe implementation details that are not captured by our formal system from Section \n3: The formal system MIX is based on a type checking system where all types are given. Since type quali.er \ninference in\u00advolves variables, we need to handle variables that are not yet constrained to concrete type \nquali.ers when transitioning to a symbolic block (Section 4.1).  We need to translate information about \naliasing between blocks (Section 4.2).  Since the same block or function may be called from multiple \ncontexts, we need to avoid repeating analysis of the same func\u00adtion (Section 4.3).  Since functions \ncan contain blocks and be recursive, we need to handle recursion between typed and symbolic blocks (Sec\u00ad \ntion 4.4).  Finally, we present our initial experience with MIXY (Section 4.5), and we discuss some \nlimitations and future work (Section 4.6). 4.1 Translating Null/Non-null and Type Variables At transitions \nbetween typed and symbolic blocks, we need to translate null and nonnull annotations back and forth. \nFrom Types to Symbolic Values. Suppose local variable x has type int *nonnull. Then in the symbolic executor, \nwe initialize x to point to a fresh memory cell. If x has type int *null, then we ini\u00adtialize x to be \n(a:bool)?loc:0, where a is a fresh boolean that may be either true or false, loc is a newly initialized \npointer (described in Section 4.2), and 0 represents null. Hence this expression means x may be either \nnull or non-null, and the symbolic executor will try both possibilities. A more interesting case occurs \nif a variable x has a type with a quali.er variable (e.g., int *\u00df ). In this case, we .rst try to solve \nthe current set of constraints to see whether \u00df has a solution as either null or nonnull, and if it does, \nwe perform the translation given above. Otherwise, if \u00df could be either, we .rst optimistically assume \nit is nonnull. We can safely use this assumption when returning from a typed block to a symbolic block \nsince such a quali.er variable can only be introduced when variables are aliased (e.g., via pointer assign\u00adment), \na case that is separately taken into account by the MIXY memory model (Section 4.2). However, if we use \nthis assumption when entering a symbolic block from a typed block, we may later discover our assumption \nwas too optimistic. For example, consider the following code: 1 {t int *x; {s x = NULL; s};{s free(x); \ns}t} In the type system, x has type int * \u00df , where initially \u00df is uncon\u00adstrained. Suppose that we analyze \nthe symbolic block on the right before the one on the left. This scenario could happen because the analysis \nof the enclosing typed block does not model control-.ow order (i.e., is .ow-insensitive). Then initially, \nwe would think the call to free was safe because we optimistically treat unconstrained \u00df as nonnull but \nthis is clearly not accurate here. The solution is, as expected, to repeat our analyses until we reach \na .xed point. In this case, after we analyze the left symbolic block, we will discover a new constraint \non x, and hence when we iterate and reanalyze the right symbolic block, we will discover the error. We \nare computing a least .xed point because we start with optimistic assumptions nothing is null and then \nmonotonically discover more expressions may be null.  From Symbolic Values to Types. We use the SMT \nsolver to discover the possible .nal values of variables and translate those to the appropriate types. \nGiven a variable x that is mapped to symbolic expression s, we ask whether g . (s = 0) is satis.able \nwhere g is the path condition. If the condition is satis.able, we constrain x to be null in the type \nsystem. There are no nonnull constraints to be added since they correspond to places in code where pointers \nare dereferenced, which is not re.ected in symbolic values. Thus, null pointers from symbolic blocks \nwill lead to errors in typed blocks if they .ow to a nonnull position; whereas null pointers from typed \nblocks will lead to errors in symbolic blocks if they are dereferenced symbolically.  4.2 Aliasing and \nMIXY s Memory Model The formal system MIX defers all reasoning about aliasing to as late of a time as \npossible. As alluded to in Section 3, this choice may be dif.cult to implement in practice given limitations \nin the constraint solver. Thus in MIXY, we use a pre-pass pointer analysis to initialize aliasing relationships. \nTyped to Symbolic Block. When we switch from a typed block to a symbolic block, we initialize a fresh \nsymbolic memory, which may include pointers. We use a variant of the approach described in Section 3 \nthat makes use of aliasing information to be more precise. Rather than modeling memory as one big array, \nMIXY models memory as a map from locations to separate arrays. Aliasing within arrays is modeled as in \nour formalism, and aliasing between arrays is modeled using Morris s general axiom of assignment [Bornat \n2000; Morris 1982]. C also supports a richer variety of types such as arrays and structs, as well as \nrecursive data structures. MIXY lazily initializes memory in an incremental manner so that we can sidestep \nthe issue of initializing an arbitrarily recursive data structure; MIXY only initializes as much as is \nrequired by the symbolic block. We use CIL s pointer analysis to determine possible points-to relationships \nand initialize memory accordingly. Symbolic to Typed Block. An issue arises from using type infer\u00adencing \nwhen we switch from a symbolic block to a typed block. Consider the following code snippets, which are \nidentical except that y points to r on the left, and y points to x on the right: {s {s // *y not aliased \nto x // *y aliased to x int *x= ...; int *x= ...; int *r= ..., **y = &#38;r; int **y = &#38;x; {t // \nokay {t // should fail x = NULL; x = NULL; assert nonnull(*y); t} assert nonnull(*y); t}s} s} In both \ncases, at entry to the typed blocks, x and *y are assigned types \u00df ref and . ref respectively, based \non their current values. Notice, however, that for the code on the right, we should also have \u00df = . . \nOtherwise, after the assignment x = NULL, we will not know that *y is also NULL. This example illustrates \nan important difference between type inference and type checking. In type checking, this problem cannot \narise because every value has a known type, and we only have to check that those types are consistent. \nHowever, type inference actually has to discover richer information, such as what types must be equal \nbecause of aliasing, in order to .nd a valid typing. One solution to this problem would be to translate \naliasing in\u00adformation from symbolic execution to and from type constraints. In MIXY, we use an alternative \nsolution that is easier to implement: we use CIL s built-in may pointer analysis to conservatively dis\u00adcover \npoints-to relationships. When we transition from a symbolic block to a typed block, we add constraints \nto require that all may\u00adaliased expressions have the same type. 4.3 Caching Blocks In C, a block or \nfunction may be called from many different call sites, so we may need to analyze that block in the context \nof each call site. Since it can be quite costly to analyze that block repeatedly, we cache the calling \ncontext and the results of the analysis for that block, and we reuse the results when the block is called \nagain with a compatible calling context. Conceptually, caching is similar to compositional symbolic execution \n[Godefroid 2007]; in MIXY, we implement caching as an extension to the mix rules, using types to summarize \nblocks rather than symbolic constraints. Caching Symbolic Blocks. Before we translate the types from \nthe enclosing typed block to symbolic values, we .rst check to see if we have previously analyzed the \nsame symbolic block with a compatible calling context. We de.ne the calling context to be the types for \nall variables that will be translated into symbolic values, and we say two calling contexts are compatible \nif every variable has the same type in both contexts. If we have not analyzed the symbolic block before \nwith a com\u00adpatible calling context, we translate the types into symbolic values, analyze the symbolic \nblock, and translate the symbolic values to types by adding type constraints as usual. At this point, \nwe will cache the translated types for this calling context; we cache the translated types instead of \nthe symbolic values since the translation from symbolic values to types is expensive. Otherwise, if we \nhave analyzed the symbolic block before with a compatible calling con\u00adtext, we use the cached results \nby adding null type constraints for null cached types in a manner similar to translating symbolic val\u00adues. \nFinally, in both cached and uncached cases, we restore aliasing relationships and return to the enclosing \ntyped block as usual. Caching Typed Blocks. Caching for typed blocks is similarly im\u00adplemented, but with \none difference: unlike above, we .rst translate symbolic values into types, then use the translated types \nas the call\u00ading context, and .nally cache the .nal types as the result of analyz\u00ading the typed block. \nWe could have chosen to use symbolic values as the calling context and the result, but since translating \nsymbolic values to types or comparing symbolic values both involve similar number of calls to the SMT \nsolver, we chose to use types to unify the implementation.  4.4 Recursion between Typed and Symbolic \nBlocks A typed block and a symbolic block may recursively call each other, and we found block recursion \nto be surprisingly common in our experiments. Without special handling for recursion, MIXY will keep \nswitching between them inde.nitely since a block is analyzed with a fresh initial state upon every entry. \nTherefore, we need to detect when recursion occurs, either beginning with a typed block or a symbolic \nblock, and handle it specially. To handle recursion, we maintain a block stack to keep track of blocks \nthat are currently being analyzed. Similar to a function call stack, the block stack is a stack of blocks \nand their calling contexts, which are de.ned in terms of types as in caching (Section 4.3). We push blocks \nonto the stack upon entry and pop them upon return. Before entering a block, we .rst look for recursion \nby search\u00ading the block stack for the same block with a compatible calling context. If recursion is detected, \nthen instead of entering the block, we mark the matching block on the stack as recursive and return an \nassumption about the result. For the initial assumption, we use the calling context of the marked block, \noptimistically assuming that the block has no effect. When we eventually return to the marked block, \nwe compare the assumption with the actual result of analyz\u00ad  4.5 Preliminary Experience We gained some \ninitial experience with MIXY by running it on vsftpd-2.0.7 and looking for false null pointer warnings \nfrom pure type quali.er inference that can be eliminated with the addi\u00adtion of symbolic execution. Since \nMIXY is in the prototype stage, we started small. Rather than annotate all dereferences as requiring \nnonnull, we added just one nonnull annotation: sysutil free(void * nonnull p ptr) MIX(typed) { ... } \nThe sysutil free function wraps the free system call and checks, at run time, that the pointer argument \nis not null. In essence, our anal\u00adysis tries to check this property statically. We annotated sysutil \nfree itself with MIX(typed), so MIXY need not symbolically execute its body our annotation captures the \nimportant part of its behavior for our analysis. We then ran MIXY on vsftpd, beginning with typing at \nthe out\u00adermost level. We examined the resulting warnings and then tried adding MIX(symbolic) annotations \nto eliminate warnings. We suc\u00adceeded in several cases, discussed next. We did not fully examine many \nof the other cases, but Section 4.6 describes some prelimi\u00ad nary observations about MIXY in practice. \nNote that the code snip\u00adpets shown below are abbreviated, and many identi.ers have been shortened. We \nshould also point out that all the examples below eliminate one or more imprecise quali.er .ows from \ntype quali.er inference; this pruning may or may not suppress a given warning, depending on whether other \n.ows could produce the same warning. Case 1: Flow and path insensivitity in sockaddr clear 1 2 3 void \nsockaddr clear(struct sockaddr **p sock) MIX(symbolic) {if (*p sock != NULL) {sysutil free(*p sock); \n4 *p sock = NULL; 5 6 }} This function is implicated in a false warning: due to .ow insen\u00adtivity in \nthe type system, the null assignment on line 4 .ows to the argument to sysutil free on line 3, even though \nthe assignment oc\u00ad curs after the call. Also, the type system ignores the null check on line 2 due to \npath-insensitivity. Marking sockaddr clear with MIX(symbolic) successfully resolves this warning: the \nsymbolic executor determines that *p sock is not null when used as an argument to sysutil free(). Case \n2: Path and context insensitivity in str next dirent 1 void str alloc text(struct mystr* p str) MIX(typed); \n2 const char* sysutil next dirent( ...) MIX(typed) { 3 if (p dirent == NULL) return NULL; 4 } 5 void \nstr next dirent( ...) MIX(symbolic) { 6 const char* p .lename = sysutil next dirent( ...); 7 if (p .lename \n!= NULL) 8 str alloc text(p .lename); 9 } 10 ...str alloc text(str); sysutil free(str); ... In this \nexample, the function str next direct calls sysutil next dirent on line 6, which may return a null value. \nHence p .lename may be null. The type system ignores the null check on line 7 and due to context-insensitivity, \ncon.ates p .lename with other variables, such as str, that are passed to str alloc text (lines 8 and \n10). Hence the type system believes str may be null. However, str is used as an argument to sysutil free \n(line 10), which leads the type system to report a false warning. Annotating function str next dirent \nas symbolic, while leaving sysutil next dirent and str alloc text as typed, successfully elim\u00adinates \nthis warning: the symbolic executor correctly determines that p .lename is not null when it is used as \nan argument to str alloc text. And although the extra precision does not matter in this particular example, \nnotice that the call on line 8 will be an\u00ad alyzed in a separate invocation of the type system than the \ncall on line 10, thus introducing some context-sensitivity. Case 3: Flow-and path-insensitivity in dns \nresolve and main 1 2 void main BLOCK(struct sockaddr** p sock) MIX(symbolic) {*p sock = NULL; 3 dns resolve(p \nsock, tunable pasv address); 4 5 6 }int main(. . . ) {. . . main BLOCK(&#38;p addr); . . .; sysutil free(p \naddr); . . . 7 8 }void dns resolve(struct sockaddr** p sock, 9 10 const char* p name) {struct hostent* \nhent = gethostbyname(p name); 11 sockaddr clear(p sock); 12 if (hent.h addrtype == AF INET) 13 sockaddr \nalloc ipv4(p sock); 14 else if (hent.h addrtype == AF INET6) 15 sockaddr alloc ipv6(p sock); 16 else \n17 die( gethostbyname(): neither IPv4 nor IPv6 ); 18 } There are two sources of null values in the code \nabove: *p sock is set to null on line 2; and sockaddr clear, which was previously marked as symbolic \nin Case 1 above, also sets *p sock to null on line 11 in dns resolve. Due to .ow insensitivity in the \ntype system, both these null values eventually reach sysutil free on line 6, leading to false warnings. \nHowever, we can see that these null values are actually overwrit\u00adten by non-null values on lines 13 and \n15, where sockaddr alloc ipv4 or sockaddr alloc ipv6 allocates the appropriate structure and as\u00adsigns \nit to *p sock (not shown). We can eliminate these warnings by extracting the code in main that includes \nboth null sources into a symbolic block. Also, there is a system call gethostbyname on line 10 that we \nneed to handle. Here, we de.ne a well-behaved, symbolic model of gethostbyname that returns only AF INET \nand AF INET6 as is standard (not shown). This will cause the symbolic executor to skip the last branch \non line 17, which we need to do because we cannot analyze die symbolically as it eventually calls a function \npointer, an operation that our symbolic executor currently has limited support for. We also cannot put \ngethostbyname or die in typed blocks in this case, since *p sock is null and will result in false warnings. \nCase 4: Helping symbolic execution with symbolic function point\u00aders 1 void sysutil exit BLOCK(void) MIX(typed) \n{ 2 if (s exit func) (*s exit func)(); 3 } 4 void sysutil exit(int exit code) { 5 sysutil exit BLOCK(); \n6 exit(exit code); 7 } In several instances, we would like to evaluate symbolic blocks that call sysutil \nexit, de.ned on line 4, which in turn calls exit to terminate the program. However, before terminating \nthe program, sysutil exit calls the function pointer s exit func on line 2. Our sym\u00ad bolic executor does \nnot support calling symbolic function pointers (i.e., which targets are unknown), so instead, we extract \nthe call to s exit func into a typed block to analyze the call conservatively.  4.6 Discussion and \nFuture Work Our preliminary experience provides some real-world validation of MIX s ef.cacy in removing \nfalse positives. However, there are several limitations to be addressed in future work. Most importantly, \nthe overwhelming source of issues in MIXY is its coarse treatment of aliasing, which relies on an imprecise \npointer analysis. One immediate consequence is that it impedes per\u00adformance in the symbolic executor: \nif an imprecise pointer analysis returns large points-to sets for pointers, translating symbolic point\u00aders \nto type constraints becomes slow because we .rst need to check if each pointer target is valid in the \ncurrent path condition by call\u00ading the SMT solver, then determine if any valid targets may be null. This \nleads to a signi.cant slowdown: our small examples from Sec\u00ad tion 4.5 take less than a second to run \nwithout symbolic blocks, but from 5 to 25 seconds to run with one symbolic block, and about 60 seconds \nwith two symbolic blocks. This issue is further com\u00adpounded by the .xed-point computation that repeatedly \nanalyzes symbolic blocks nested in typed blocks or for handling recursion. We also noticed several cases \nin vsftpd where calls to symbolic blocks would help introduce context sensitivity to distinguish calls \nto malloc. However, since we rely on a context-insensitive pointer analysis to restore aliasing relationships \nwhen switching to typed blocks, these calls will again be con.ated. The issue especially af\u00adfects the \nanalysis of typed-to-symbolic-to-typed recursive blocks because the nested typed blocks are polluted \nby aliasing relation\u00adships from the entire program. A similar issue occurs with symbolic blocks, as pointers \nare initialized to point to targets from the entire program, rather than being limited to the enclosing \ncontext. Just as in the formalism, MIXY has to consider the entire mem\u00adory when switching from typed \nto symbolic or vice-versa. Since this was a deliberate design decision, we were not surprised to .nd \nout that this has an impact on performance and leads to many limi\u00adtations in practice. Any temporary \nviolation of type invariants from symbolic blocks would immediately be .agged when switching to typed \nblocks, even if they have no effect on the code in the typed blocks. In the other direction, symbolic \nblocks are forced to start with a fresh memory when switching from typed blocks even if there were no \neffects. Ultimately, we believe that these issues can be addressed with more precise information about \naliasing as well as effects, perhaps extracted directly from the type inference constraints and symbolic \nexecution. In addition to checking for null pointer errors, we plan to ex\u00adtend MIXY to check other properties, \nsuch as data races, and to mix other types of analysis together. We also plan to investigate au\u00adtomatic \nplacement of type/symbolic blocks, i.e., essentially using MIX as an intermediate language for combining \nanalyses. One idea is to begin with just typed blocks and then incrementally add sym\u00adbolic blocks to \nre.ne the result. This approach resembles abstrac\u00adtion re.nement (e.g., Ball and Rajamani [2002]; Henzinger \net al. [2004]), except the re.nement can be obtained using completely different analyses instead of one \nparticular family of abstractions. 5. Related Work There are several threads of related work. There have \nbeen numer\u00adous proposals for static analyses based on type systems; see Pals\u00ad berg and Millstein [2008] \nfor pointers. Symbolic execution was .rst proposed by King [1976] as an enhanced testing strategy, but \nwas dif.cult to apply for many years. Recently, SMT solvers have be\u00adcome very powerful, making symbolic \nexecution much more at\u00adtractive as even very complex path conditions can be solved sur\u00adprisingly fast. \nThere have been many recent, impressive results us\u00ading symbolic execution for bug .nding [Cadar et al. \n2006, 2008; Godefroid et al. 2005; Sen et al. 2005]. These systems use symbolic execution to explore \na small subset of the possible program paths, since in the presence of loops with symbolic bounds, pure \nsymbolic execution will not terminate in a reasonable amount of time (unless loop invariants are assumed). \nIn the MIX formalism, in contrast, we use symbolic execution in a sound manner by exploring all paths, \nwhich is possible because we can use type checking on parts of the code where symbolic execution takes \ntoo long. Of course, it is also possible to mix unsound symbolic execution with type checking, to gain \nwhatever level of assurance the user desires. There are several static analyses that can operate at different \nlev\u00adels of abstraction. Bandera [Corbett et al. 2000] is a model check\u00ad ing system that uses abstraction-based \nprogram specialization, in which the user speci.es the exact abstractions to use. System Z is an abstract \ninterpreter generator in which the user can tune the level of abstraction to trade off cost and precision \n[Yi and Harri\u00ad son 1993]. Tuning these systems requires a deep knowledge of pro\u00ad gram analysis. In contrast, \nwe believe that MIX s tradeoff is eas\u00adier to understand one selects between essentially no abstraction \n(symbolic execution), or abstraction in terms of types, which are arguably the most successful, well-understood \nstatic analysis. MIX bears some resemblance to static analysis based on ab\u00adstraction re.nement, such \nas SLAM [Ball and Rajamani 2002], BLAST [Henzinger et al. 2004], and client-driven pointer analy\u00ad sis \n[Guyer and Lin 2005]. These tools incrementally re.ne their abstraction of the program as necessary for \nanalysis. Adding sym\u00adbolic blocks to a program can be seen as introducing a very precise re.nement of \nthe program abstraction. There are a few systems that combine type checking or infer\u00adence with other \nanalyses. Dependent types provide an elegant way to augment standard type with very rich type re.nements \n[Xi and Pfenning 1999]. Liquid types combines Hindley-Milner style type inference with predicate abstraction \n[Rondon et al. 2008, 2010]. Hybrid types combines static typing, theorem proving, and dy\u00adnamic typing \n[Flanagan 2006]. All of these systems combine types with re.nements at a deep level the re.nements are \nplaced on top of the type structure. In contrast, MIX uses a much coarser approach in which the precise \nanalysis is almost entirely separated from the type system, except for a thin interface between the two \nsystems. Many others have considered the problem of combining pro\u00adgram analyses. A reduced product in \nabstract interpretation [Cousot and Cousot 1979] is a theoretical description of the most precise combination \nof two abstract domains. It is typically obtained via manually de.ned reduction operators that depend \non the domains being combined. Another example of combining abstract domains is the logical product of \nGulwani and Tiwari [2006]. Combining program analyses for compiler optimizations is also well-studied \n(e.g., Lerner et al. [2002]). In all of these cases, the combinations strengthen the kinds of derivable \nfacts over the entire program. With MIX, we instead analyze separate parts of the program with different \nanalyses. Finally, MIX was partially inspired by Nelson-Oppen style cooperating decision procedures [Nelson \nand Oppen 1979]. One important feature of the Nelson-Oppen framework is that it provides an automatic \nmethod for distributing the appropri\u00adate formula fragments to each solver (if that the solvers match \ncer\u00adtain criteria). Clearly MIX is targeted at solving a very different problem, but it would be an interesting \ndirection for future work to try to extend MIX into a similar framework that can automatically integrate \nanalyses that have appropriately structured interfaces. 6. Conclusion We presented MIX, a new approach \nfor mixing type checking and symbolic execution to trade off ef.ciency and precision. The key feature \nof our approach is that the mixed systems are essentially completely independent, and they are used in \nan off-the-shelf man\u00adner. Only at the boundaries between typed blocks which the user inserts to indicate \nwhere type checking should be used and sym\u00adbolic blocks the symbolic checking annotation do we invoke \nspecial mix rules to translate information between the two sys\u00adtems. We proved that MIX is sound (which \nimplies that type check\u00ading and symbolic execution are also independently sound). We also described a \npreliminary implementation, MIXY, which per\u00adforms null/non-null type quali.er inference for C. We identi.ed \nseveral cases in which symbolic execution could eliminate false positivesfromtypeinference.Insum,webelievethat \nMIX provides a promising new approach to trade off precision and ef.ciency in static analysis.  Acknowledgments \nWe would like to thank the anonymous reviewers and Patrice Gode\u00adfroid for their helpful comments and \nsuggestions. This research was supported in part by DARPA ODOD.HR00110810073, NSF CCF\u00ad0541036, and NSF \nCCF-0915978. References Thomas Ball and Sriram K. Rajamani. The SLAM project: debugging system software \nvia static analysis. In Principles of Programming Languages (POPL), pages 1 3, 2002. Richard Bornat. \nProving pointer programs in Hoare logic. In Mathematics of Program Construction (MPC), pages 102 126, \n2000. Cristian Cadar, Vijay Ganesh, Peter M. Pawlowski, David L. Dill, and Dawson R. Engler. EXE: automatically \ngenerating inputs of death. In Computer and Communications Security (CCS), pages 322 335, 2006. Cristian \nCadar, Daniel Dunbar, and Dawson R. Engler. KLEE: Unassisted and automatic generation of high-coverage \ntests for complex systems programs. In Operating Systems Design and Implementation (OSDI), pages 209 \n224, 2008. James C. Corbett, Matthew B. Dwyer, John Hatcliff, Shawn Laubach, Corina S. P.as.areanu, Robby, \nand Hongjun Zheng. Bandera: extracting .nite-state models from Java source code. In International Conference \non Software Engineering (ICSE), pages 439 448, 2000. Patrick Cousot and Radhia Cousot. Systematic design \nof program analysis frameworks. In Principles of Programming Languages (POPL), pages 269 282, 1979. Cormac \nFlanagan. Hybrid type checking. In Principles of Programming Languages (POPL), pages 245 256, 2006. Jeffrey \nS. Foster, Robert Johnson, John Kodumal, and Alex Aiken. Flow\u00adinsensitive type quali.ers. ACM Trans. \nProgram. Lang. Syst., 28(6): 1035 1087, 2006. Vijay Ganesh and David L. Dill. A decision procedure for \nbit-vectors and arrays. In Computer-Aided Veri.cation (CAV), pages 519 531, July 2007. Patrice Godefroid. \nCompositional dynamic test generation. In Principles of Programming Languages (POPL), pages 47 54, 2007. \nPatrice Godefroid, Nils Klarlund, and Koushik Sen. DART: directed auto\u00admated random testing. In Programming \nLanguage Design and Imple\u00admentation (PLDI), pages 213 223, 2005. Sumit Gulwani and Ashish Tiwari. Combining \nabstract interpreters. In Pro\u00adgramming Language Design and Implementation (PLDI), pages 376 386, 2006. \nSamuel Z. Guyer and Calvin Lin. Error checking with client-driven pointer analysis. Sci. Comput. Program., \n58(1-2):83 114, 2005. Thomas A. Henzinger, Ranjit Jhala, Rupak Majumdar, and Kenneth L. McMillan. Abstractions \nfrom proofs. In Principles of Programming Languages (POPL), pages 232 244, 2004. Khoo Yit Phang, Bor-Yuh \nEvan Chang, and Jeffrey S. Foster. Mixing type checking and symbolic execution (extended version). Technical \nReport CS-TR-4954, Department of Computer Science, University of Maryland, College Park, 2010. James \nC. King. Symbolic execution and program testing. Commun. ACM, 19(7):385 394, 1976. Sorin Lerner, David \nGrove, and Craig Chambers. Composing data.ow analyses and transformations. In Principles of Programming \nLanguages (POPL), pages 270 282, 2002. Rupak Majumdar and Koushik Sen. Hybrid concolic testing. In Inter\u00adnational \nConference on Software Engineering (ICSE), pages 416 426, 2007. Joe M. Morris. A general axiom of assignment. \nAssignment and linked data structure. A proof of the Schorr-Waite algorithm. In Theoretical Foundations \nof Programming Methodology, pages 25 51, 1982. George C. Necula, Scott McPeak, Shree Prakash Rahul, and \nWestley Weimer. CIL: Intermediate language and tools for analysis and transfor\u00admation of C programs. \nIn Compiler Construction (CC), pages 213 228, 2002. Greg Nelson and Derek C. Oppen. Simpli.cation by \ncooperating decision procedures. ACM Trans. Program. Lang. Syst., 1(2):245 257, 1979. Jens Palsberg and \nTodd Millstein. Type Systems: Advances and Applica\u00adtions. In The Compiler Design Handbook: Optimizations \nand Machine Code Generation, chapter 9. 2008. Polyvios Pratikakis, Jeffrey S. Foster, and Michael W. \nHicks. Locksmith: context-sensitive correlation analysis for race detection. In PLDI, pages 320 331, \n2006. Elnatan Reisner, Charles Song, Kin-Keung Ma, Jeffrey S. Foster, and Adam Porter. Using symbolic \nevaluation to understand behavior in con.g\u00adurable software systems. In International Conference on Software \nEngi\u00adneering (ICSE), 2010. To appear. Patrick M. Rondon, Ming Kawaguci, and Ranjit Jhala. Liquid types. \nIn Programming Language Design and Implementation (PLDI), pages 159 169, 2008. Patrick M. Rondon, Ming \nKawaguchi, and Ranjit Jhala. Low-level liquid types. In Principles of Programming Languages (POPL), pages \n131 144, 2010. Koushik Sen, Darko Marinov, and Gul Agha. CUTE: a concolic unit testing engine for C. \nIn Foundations of Software Engineering (FSE), pages 263 272, 2005. Hongwei Xi and Frank Pfenning. Dependent \ntypes in practical program\u00adming. In Principles of Programming Languages (POPL), pages 214 227, 1999. \nKwangkeun Yi and Williams Ludwell Harrison, III. Automatic generation and management of interprocedural \nprogram analyses. In Principles of Programming Languages (POPL), pages 246 259, 1993.  \n\t\t\t", "proc_id": "1806596", "abstract": "<p>Static analysis designers must carefully balance precision and efficiency. In our experience, many static analysis tools are built around an elegant, core algorithm, but that algorithm is then extensively tweaked to add just enough precision for the coding idioms seen in practice, without sacrificing too much efficiency. There are several downsides to adding precision in this way: the tool's implementation becomes much more complicated; it can be hard for an end-user to interpret the tool's results; and as software systems vary tremendously in their coding styles, it may require significant algorithmic engineering to enhance a tool to perform well in a particular software domain.</p> <p>In this paper, we present Mix, a novel system that mixes type checking and symbolic execution. The key aspect of our approach is that these analyses are applied independently on disjoint parts of the program, in an off-the-shelf manner. At the boundaries between nested type checked and symbolically executed code regions, we use special mix rules to communicate information between the off-the-shelf systems. The resulting mixture is a provably sound analysis that is more precise than type checking alone and more efficient than exclusive symbolic execution. In addition, we also describe a prototype implementation, Mixy, for C. Mixy checks for potential null dereferences by mixing a null/non-null type qualifier inference system with a symbolic executor.</p>", "authors": [{"name": "Yit Phang Khoo", "author_profile_id": "81414618977", "affiliation": "University of Maryland, College Park, MD, USA", "person_id": "P2184614", "email_address": "", "orcid_id": ""}, {"name": "Bor-Yuh Evan Chang", "author_profile_id": "81464662824", "affiliation": "University of Colorado, Boulder, CO, USA", "person_id": "P2184615", "email_address": "", "orcid_id": ""}, {"name": "Jeffrey S. Foster", "author_profile_id": "81338488852", "affiliation": "University of Maryland, College Park, MD, USA", "person_id": "P2184616", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806645", "year": "2010", "article_id": "1806645", "conference": "PLDI", "title": "Mixing type checking and symbolic execution", "url": "http://dl.acm.org/citation.cfm?id=1806645"}