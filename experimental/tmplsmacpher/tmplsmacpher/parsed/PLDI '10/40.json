{"article_publication_date": "06-05-2010", "fulltext": "\n Z-Rays: Divide Arrays and Conquer Speed and Flexibility * Jennifer B. Sartor Stephen M. Blackburn Daniel \nFrampton Martin Hirzel\u00a7 Kathryn S. McKinley UniversityofTexasat Austin Australian NationalUniversity \n\u00a7IBMWatson Research Center {jbsartor,mckinley}@cs.utexas.edu {Steve.Blackburn,Daniel.Frampton}@anu.edu.au \nhirzel@us.ibm.com Abstract Arrays are the ubiquitous organization for indexed data. Through\u00adout programming \nlanguage evolution, implementations have laid out arrays contiguously in memory. This layout is problematic \nin space and time. It causes heap fragmentation, garbage collec\u00adtion pauses in proportion to array size, \nand wasted memory for sparse and over-provisioned arrays. Because of array virtualization in managed \nlanguages, an array layout that consists of indirection pointers to .xed-size discontiguous memory blocks \ncan mitigate these problems transparently. This design however incurs signi.\u00adcantoverhead,butis justi.ed \nwhen real-time deadlines and space constraints trump performance. This paper proposes z-rays, a discontiguous \narray design with .exibilityandef.ciency.Az-rayhasa spine with indirection point\u00aders to .xed-size memory \nblocks called arraylets,and uses .veopti\u00admizations: (1) inlining the .rst Narray bytes into the spine, \n(2) lazy allocation, (3) zero compression, (4) fast array copy, and (5) ar\u00adraylet copy-on-write. Whereas \ndiscontiguous arrays in prior work improve responsiveness and space ef.ciency, z-rays combine time ef.ciencyand \n.exibility. On average, the best z-ray con.guration performs within 12.7% of an unmodi.ed JavaVirtual \nMachine on 19 benchmarks, whereas previous designs have two to three times higheroverheads. Furthermore, \nlanguage implementers can con.g\u00adure z-ray optimizations for various design goals. This combination of \nperformance and .exibility creates a better building block for past and future array optimization. Categories \nand Subject Descriptors D3.4[Programming Lan\u00adguages]: Processors Memory management (garbage collection); \nOptimization; Run-time environments GeneralTerms Performance, Measurement, Experimentation Keywords Heap, \nCompression, Arrays, Arraylets, Z-rays 1. Introduction KonradZuseinvented arraysin1946;Fortran .rst implementedar\u00adrays; \nandevery modern language includes arrays.Traditional im\u00adplementations use contiguous storage, which often \nwastes space and leadsto unpredictable performance.Forexample,large arrays cause fragmentation, which \ncan trigger premature out-of-memory errors and make it impossible for real-time collectors to offer prov\u00adable \ntime and space bounds. Over-provisioning and redundancy * This work is supported by ARC DP0666059, NSF \nSHF0910818, NSF CSR0917191, NSF CCF0811524, NSF CNS0719966, Intel, and Google. Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page.To copyotherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 10, June 5 10, 2010,Toronto, Ontario, \nCanada. Copyright c . 2010 ACM 978-1-4503-0019-3/10/06... $10.00 in arrays wastes space. Prior work \nshows that just eliminating zero bytes from arrays reduces program footprints by 41% in Java benchmarks \n[27]. In managed languages,garbage collection uses copying to coalesce free space and reduce fragmentation. \nCopying and scanning arrays incur large unpredictable collector pause times, and make it impossible to \nguarantee real-time deadlines. Managed languages, such as Java and C#, give programmers a high-level \ncontiguous array abstraction that hides implementa\u00adtion details and offers virtual machines (VMs) an \nopportunity to ameliorate the above problems.To meet space ef.ciencyand time predictability,researchers \nproposed discontiguous arrays, which di\u00advide arrays into indexed chunks [5, 12, 28]. Siebert s design \norga\u00adnizes arraymemory in trees to reduce fragmentation,but requires an expensive tree traversal for \nevery array access [28]. Bacon et al. and Pizlo et al. use a single level of indirection to .xed-size \nar\u00adraylets [5, 25]. Chen et al. contemporaneously invented arraylets to aggressively compress arrays \nduring collection and decompress on demand for memory-constrained embedded systems [12]. They use lazy \nallocation to materialize arraylets upon the .rst non-zero store. All prior work introduces substantial \noverheads. Regardless, three productionJavaVirtual Machines (JVMs) already use discon\u00adtiguous arrays \nto achieve real-time bounds: IBMWebSphere Real Time [5, 19], AICAS Jamaica VM [1, 28], and Fiji VM [14, \n25]. Thus, although discontiguous arrays are needed for their .exibil\u00adity, which achieves space and time \npredictability, sofar theyhave sacri.ced throughput and time ef.ciency. This paper presents z-rays, a \ndiscontiguous array design and JVM implementation that combines .exibility, memory ef.ciency, and performance. \nZ-rays store indirection pointers to arraylets in a spine. Z-rays optimizations include: a novel .rst-Noptimization, \nlazy allocation, zero compression, fast array copy, and copy-on\u00adwrite. Our novel .rst-Noptimization inlines \nthe .rst Nbytes of the array into the spine, for direct access. First-Neliminates the major\u00adity of pointer \nindirections because manyarrays are small and most array accesses,eventolarge arrays,fall withinthe .rst4KB. \nThese properties are similar to .le access properties exploited by Unix indexed .les, which inline small \n.les and the beginning of large .les in i-nodes [26]. First-Nis our most effective optimization. Be\u00adsides \nmaking indirections rare, it makes other optimizations more effective.Forexample, with lazy allocation, \nthe allocator lazily cre\u00adates arraylet upon the .rst non-zero write. This additional indirec\u00adtion logicdegrades \nperformancein priorwork,but improves per\u00adformance when used together with .rst-N. The collector performs \nzero-compression at the granularity of arraylets by eliminating arraylets that are entirely zero. When \nthe program copies arrays, ourfast array copyimplementation copies contiguous chunks of memory, instead \nof copying element-by\u00adelement. Our copy-on-write optimization always initially shares whole arraylets \nthat are copied and only copies later if and when the program subsequently writestoacopied arraylet.Toourknowl\u00adedge, \nthis study is the .rst to implement array copy-on-write, show that it is does not signi.cantly hurt performance, \nand show that it saves signi.cant amounts of space. This study is also the .rst to rig\u00adorously evaluate \nand report Java array properties and their impact on discontiguous array optimization choices. Our experimental \nre\u00adsults on 19 SPEC and DaCapo Java benchmarks show that our best z-ray con.gurationaddsanaverageof12.7%overhead, \nincludinga reduction ingarbage collection costof 11.3%dueto reduced space consumption. In contrast, we \nshow that previously proposed de\u00adsigns have overheads two to three times higher than z-rays. Z-rays \nare thus immediately applicable to discontiguous arrays in embedded and real-time systems, since theyimprove \n.exibility, space ef.ciency, and add time ef.ciency. Since the largest object size determines heap fragmentation \nand pause times, and .rst-N increases it by N, some system-speci.c tuning may be necessary to achieve \nparticular space and time design goals. We believe z\u00adrays may also help to ameliorate challenges in general-purpose \nmulticore hardware trends. For example, multicore hardware is becoming more memory-bandwidth limited \nbecause the number of processors is growing much faster than memory size. Lazy allocation and copy-on-write \neliminate unnecessary, voluminous, andbursty writetraf.cthatwould otherwiseslowthe entire system down. \nZ-rays not only make discontiguous arrays more appealing for real-time virtual machines, but also make \nthem feasible for general-purpose systems. Our results demonstrate that z-rays achieve both performance \nand .exibility, making them an attractive building block for lan\u00adguage implementation on current and \nfuture architectures. 2. RelatedWork This section surveys work on implementations of discontiguous arrays, \ndescribes work on optimizing read and write barriers, and establishes how array representations relate \nto space consumption. Implementing discontiguous arrays. Siebert s tree representa\u00adtion for arrays limits \nfragmentationina non-movinggarbage col\u00adlector for a real-time virtual machine [1, 28]. Both Siebert s \nand our work break arrays into parts, but Siebert requires a loop for each array access, whereas we require \nat most one indirection. Discontiguous arrays provide a foundation for achieving real\u00adtime guaranteesinthe \nMetronomegarbage collector[4,5]. Metro\u00adnome uses a two-level layout, where a spine contains indirection \npointers to .xed-size arraylets and inlined remainder elements. The authors state that Metronome arraylets \nare not yet highly optimized [5]. MetronomeisusedinIBM sWebSphereRealTime product [19]to quantizethegarbage \ncollector sworkto meet real\u00adtime deadlines. Our performance optimizations are immediately and directly \napplicable to their system. Similar to the Metronome collector, Fiji VM [14, 25] also uses arraylets \nto meet real-time system demands,but the arraylet implementation is not currently optimized for throughput \n[24]. The use of discontiguous arrays in manyproduction Javavirtual machines establishes that arraylets \nare required in real-time Java systems to bound pause-times and fragmentation [1, 14, 19]. Appli\u00adcations \nthat use these JVMs include control systems and high fre\u00adquencystock trading.To provide real-time guarantees, \nthese VMs sacri.ce throughput. Z-rays provide the same bene.ts,but greatly reduce the sacri.ce. Chen \net al. use discontiguous arrays for compression in em\u00adbedded systems, independently developing a spine-with-arraylets \ndesign [12]. If the system exhausts memory, their collector com\u00adpresses arraylets into non-uniform sizes \nby eliding zero bytes and storing a separate bit-map to indicate the elided bytes. They also perform \nlazy allocation of arraylets. In contrast to our work, their implementation does not support multi-threading, \nand is not opti\u00admized for ef.ciency. Theyrequire object handles, which introduce space overhead as well \nas time overhead due to the indirection on every object access. Read and write barriers. Akeyelement \nof our design is ef.cient read and write barriers. Read and write barriers are actions per\u00adformeduponeveryloador \nstore.Hoskingetal. werethe.rsttoem\u00adpirically compare the performance of write barriers [18]. Optimiza\u00adtions \nand hardware features such as instruction level parallelism and out-of-order processors have reduced \nbarrier overheads over the years [7, 8, 15]. If needed, special hardware can further reduce their overheads \n[13, 17]. We borrow Blackburn and McKinley s fast path barrier inlining optimization and Blackburn and \nHosking s evaluation methodology. Section 5.1 discusses the potential added performance bene.t of compiler \noptimizations such as strip-mining in barriers. In summary, we exploit recent progress in barrier opti\u00admization \nto make z-rays ef.cient. Heap object compression. High-level languages abstract mem\u00adory management and \nobject layout to improveprogrammer produc\u00adtivity,usability, and security,but abstraction usually costs. \nMitchell and Sevitskystudy bloat,spurious memory consumption causedby careless programming[22].Ashocking \nfractionoftheJavaheapis bloat, motivating the need for space savings. Sartor et al. s limit study of \nJava estimates the effect of compression, and .nds that ar\u00adray compression is likely to yield the most \nbene.t [27]. Ananian and Rinard propose using of.ine pro.ling and an ahead-of-time compiler to perform \ncompression techniques such as bit-width re\u00adduction [3]. Zilles reduces the bit-width of unicode character \narrays from16bitsto8bits[31].Chenetal. compress arraylets[12].All these techniques trade time for space, \nincurring time overheads to reduce space consumption in embedded systems. This paper pri\u00admarily studies \nways to improve discontiguous array performance and is complementary to using them for compression. Z-rays \nof\u00adfera much betterbuilding block for compression and future array optimization needs. 3. Background \nThis section brie.y discusses our implementation context for dis\u00adcontiguous arraysinJava.Weimplement \nz-raysinJikesRVM[2],a high performanceJava-in-Javavirtual machine,but our useofJikes RVM is not integral \nto our approach. Java Arrays. All arrays in Java are one-dimensional; multi\u00addimensional arrays are implemented \nas arrays of references to ar\u00adrays. Hence, Java explicitly exposes its discontiguous implementa\u00adtion \nof array dimensions greater than one. Accesses to these arrays require an indirection for each dimension \ngreater than one, whereas languages likeC andFortran compute arrayoffsets from bounds and index expressions, \nwithout indirection. Java directly supports nine array types: arrays of each of Java s eight primitive \ntypes (boolean, byte, float, etc.), and arrays of references. Java en\u00adforces array bounds with bounds \nchecks, and enforces co-variance on reference arrays by cast checks on stores to reference arrays. The \nprogrammer cannot directly access the underlying implemen\u00adtation of an array because (1) Java does not \nhave pointers (unlike C), and (2) native code accesses to Java must use the Java Native Interface (JNI). \nThesefactors combinetomakediscontiguous array representations feasible in managed languages such as Java. \nAllocation. Java memory managers conventionally use either a bump-pointer allocator or a free list, and \nmay copy objects dur\u00adinggarbage collection. The contentsof objects are zero-initialized. Because copying \nlarge objects is expensive and typically size and lifetime are correlated, large objects are usually \nallocated intoadis\u00adtinct non-moving space that is managed at the page granularity us\u00ading operating system \nsupport. One of the primary motivations for discontiguous arrays in prior work is that they reduce fragmenta\u00adtion, \nsince large arrays are implemented in terms of discontiguous .xed-size chunks of storage. The baseversion \nof JikesRVM we\n\t\t\t", "proc_id": "1806596", "abstract": "<p>Arrays are the ubiquitous organization for indexed data. Throughout programming language evolution, implementations have laid out arrays contiguously in memory. This layout is problematic in space and time. It causes heap fragmentation, garbage collection pauses in proportion to array size, and wasted memory for sparse and over-provisioned arrays. Because of array virtualization in managed languages, an array layout that consists of indirection pointers to fixed-size discontiguous memory blocks can mitigate these problems transparently. This design however incurs significant overhead, but is justified when real-time deadlines and space constraints trump performance.</p> <p>This paper proposes <i>z-rays</i>, a discontiguous array design with flexibility and efficiency. A z-ray has a spine with indirection pointers to fixed-size memory blocks called <i>arraylets</i>, and uses five optimizations: (1) inlining the first N array bytes into the spine, (2) lazy allocation, (3) zero compression, (4) fast array copy, and (5) arraylet copy-on-write. Whereas discontiguous arrays in prior work improve responsiveness and space efficiency, z-rays combine time efficiency and flexibility. On average, the best z-ray configuration performs within 12.7% of an unmodified Java Virtual Machine on 19 benchmarks, whereas previous designs have <i>two to three times</i> higher overheads. Furthermore, language implementers can configure z-ray optimizations for various design goals. This combination of performance and flexibility creates a better building block for past and future array optimization.</p>", "authors": [{"name": "Jennifer B. Sartor", "author_profile_id": "81100262404", "affiliation": "University of Texas at Austin, Austin, TX, USA", "person_id": "P2184628", "email_address": "", "orcid_id": ""}, {"name": "Stephen M. Blackburn", "author_profile_id": "81100547435", "affiliation": "Australian National University, Canberra, Australia", "person_id": "P2184629", "email_address": "", "orcid_id": ""}, {"name": "Daniel Frampton", "author_profile_id": "81314488699", "affiliation": "Australian National University, Canberra, Australia", "person_id": "P2184630", "email_address": "", "orcid_id": ""}, {"name": "Martin Hirzel", "author_profile_id": "81100572340", "affiliation": "IBM Watson Research Center, Hawthorne, NY, USA", "person_id": "P2184631", "email_address": "", "orcid_id": ""}, {"name": "Kathryn S. McKinley", "author_profile_id": "81100402805", "affiliation": "University of Texas at Austin, Austin, TX, USA", "person_id": "P2184632", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806649", "year": "2010", "article_id": "1806649", "conference": "PLDI", "title": "Z-rays: divide arrays and conquer speed and flexibility", "url": "http://dl.acm.org/citation.cfm?id=1806649"}