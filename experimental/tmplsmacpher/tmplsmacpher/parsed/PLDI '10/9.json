{"article_publication_date": "06-05-2010", "fulltext": "\n Safe to the Last Instruction: Automated Veri.cation of a Type-Safe Operating System Jean Yang Massachusetts \nInstitute of Technology Computer Science and Arti.cial Intelligence Laboratory Abstract Typed assembly \nlanguage (TAL) and Hoare logic can verify the absence of many kinds of errors in low-level code. We use \nTAL and Hoare logic to achieve highly automated, static veri.cation of the safety of a new operating \nsystem called Verve. Our techniques and tools mechanically verify the safety of every assembly language \ninstruction in the operating system, run-time system, drivers, and applications (in fact, every part \nof the system software except the boot loader). Verve consists of a Nucleus that provides primitive access \nto hardware and memory, a kernel that builds services on top of the Nucleus, and applications that run \non top of the kernel. The Nucleus, written in veri.ed assembly language, implements allocation, garbage \ncollection, multiple stacks, interrupt handling, and device access. The kernel, written in C# and compiled \nto TAL, builds higher-level services, such as preemptive threads, on top of the Nucleus. A TAL checker \nveri.es the safety of the kernel and applications. A Hoare-style veri.er with an automated theorem prover \nveri.es both the safety and correctness of the Nucleus. Verve is, to the best of our knowledge, the .rst \noperating system mechanically veri.ed to guarantee both type and memory safety. More generally, Verve \ns approach demonstrates a practical way to mix high-level typed code with low-level untyped code in a \nveri.ably safe manner. Categories and Subject Descriptors D.2.4 [SOFTWARE ENGI-NEERING]: Software/Program \nVeri.cation General Terms Veri.cation Keywords Operating system, run-time system, veri.cation, type safety \n1. Introduction High-level computer applications build on services provided by lower-level software layers, \nsuch as operating systems and lan\u00adguage run-time systems. These lower-level software layers should be \nreliable and secure. Without reliability, users endure frustration and potential data loss when the system \nsoftware crashes. Without security, users are vulnerable to attacks from the network, which often exploit \nlow-level bugs such as buffer over.ows to take over Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 10, June 5 10, 2010, Toronto, Ontario, Canada. Copyright \nc &#38;#169; 2010 ACM 978-1-4503-0019-3/10/06. . . $10.00 Chris Hawblitzel Microsoft Research a user \ns computer. Unfortunately, today s low-level software still suffers from a steady stream of bugs, often \nleaving computers vul\u00adnerable to attack until the bugs are patched. Many projects have proposed using \nsafe languages to increase the reliability and security of low-level systems. Safe languages ensure type \nsafety and memory safety: accesses to data are guar\u00adanteed to be well-typed and guaranteed not to over.ow \nmemory boundaries or dereference dangling pointers. This safety rules out many common bugs, such as buffer \nover.ow vulnerabilities. Un\u00adfortunately, even if a language is safe, implementations of the lan\u00adguage \ns underlying run-time system might have bugs that under\u00admine the safety. For example, such bugs have \nleft web browsers open to attack. This paper presents Verve, an operating system and run-time system \nthat we have veri.ed to ensure type and memory safety. Verve has a simple mantra: every assembly language \ninstruction in the software stack must be mechanically veri.ed for safety. This includes every instruction \nof every piece of software except the boot loader: applications, device drivers, thread scheduler, interrupt \nhandler, allocator, garbage collector, etc. The goal of formally verifying low-level OS and run-time \nsys\u00adtem code is not new. Nevertheless, very little mechanically veri.ed low-level OS and run-time system \ncode exists, and that code still requires man-years of effort to verify [9, 14]. This paper argues that \nrecent programming language and theorem-proving technolo\u00adgies reduce this effort substantially, making \nit practical to verify strong properties throughout a complex system. The key idea is to split a traditional \nOS kernel into two layers: a critical low-level Nucleus, which exports essential runtime abstractions \nof the un\u00adderlying hardware and memory, and a higher-level kernel, which provides more fully-.edged services. \nBecause of these two dis\u00adtinct layers, we can leverage two distinct automated technologies to verify \nVerve: TAL (typed assembly language [18]) and automated SMT (satis.ability modulo theories) theorem provers. \nSpeci.cally, we verify the Nucleus using automated theorem proving (based on Hoare Logic) and we ensure \nthe safety of the kernel using TAL (generated from C#). Note that this two-layer approach is not spe\u00adci.c \nto just Verve, but should apply more generally to systems that want to mix lower-level untyped code with \nhigher-level typed code in a veri.ably safe way. A complete Verve system consists of a Nucleus, a kernel, \nand one or more applications. We wrote the kernel and applications in safe C#, which is automatically \ncompiled to TAL. An existing TAL checker [6] veri.es this TAL (again, automatically). We wrote the Nucleus \ndirectly in assembly language, hand-annotating it with assertions (preconditions, postconditions, and \nloop invariants). An existing Hoare-style program veri.er called Boogie [2] veri.es the assembly language \nagainst a speci.cation of safety and correctness. This ensures the safety and correctness of the Nucleus \ns implemen\u00adtation, including safe interaction with the TAL code and safe in\u00adteraction with hardware (including \nmemory, interrupts, timer, key\u00adboard, and screen). Boogie relies on Z3 [7], an automated SMT the\u00adorem \nprover, to check that the assertions are satis.ed. Writing the assertions requires human effort, but \nonce they are written, Boogie and Z3 verify them completely automatically. As a result, the Verve Nucleus \nrequires only 2-3 lines of proof annotation per executable statement, an order of magnitude less than \nsimilar projects based on interactive theorem provers [9, 14].  The Verve operating system demonstrates \nthe following: It is, to the best of our knowledge, the .rst operating system mechanically veri.ed to \nensure type safety. Furthermore, every assembly language instruction that runs after booting is stat\u00adically \nveri.ed (we do not have to trust a high-level-language compiler, nor do we have to trust any unveri.ed \nlibrary code).  It is a real system: it boots and runs on real, off-the-shelf x86 hardware, and supports \nrealistic language features, including classes, virtual methods, arrays, and preemptive threads.  It \nis ef.cient: it supports ef.cient TAL code generated by an op\u00adtimizing C#-to-TAL compiler, Bartok [6], \nusing Bartok s native layouts for objects, method tables, and arrays. It incorporates the code from earlier \nveri.ed garbage collectors [13], which, as shown in [13], can run realistic macro-benchmarks at near \nthe performance of Bartok s native garbage collectors.  It demonstrates that automated techniques (TAL \nand automated theorem proving) are powerful enough to verify the safety of the complex, low-level code \nthat makes up an operating system and run-time system. Furthermore, it demonstrates that a small amount \nof code veri.ed with automated theorem proving can support an arbitrary large amount of TAL code.  In \nits current implementation, Verve is a small system and has many limitations. It lacks support for many \nC# features: exception handling, for example, is implemented by killing a thread entirely, rather than \nwith try/catch. It lacks the standard .NET class library, since the library s implementation currently \ncontains much unsafe code. It lacks dynamic loading of code. It runs only on a single pro\u00adcessor. Although \nit protects applications from each other using type safety, it lacks a more comprehensive isolation mechanism \nbetween applications, such as Java Isolates, C# AppDomains, or Singularity SIPs [8]. The veri.cation \ndoes not guarantee termination. Finally, Verve uses veri.ed garbage collectors [13] that are stop-the-world \nrather than incremental or real-time, and Verve keeps interrupts dis\u00adabled throughout the collection. \nExcept for multi-processor support, none of the limitations in Verve s present implementation are fundamental. \nWe expect that with more time, the high degree of automation in Verve s veri.ca\u00adtion will allow Verve \nto scale to a more realistic feature set, such as a large library of safe code and a veri.ed incremental \ngarbage collector. 1.1 Availability All of the Verve source code is freely available for download or \nbrowsing at the following URL (browse the latest version under Source Code to see the verify directory, \nwhich contains Verve): http://www.codeplex.com/singularity 2. Tools for constructing a safe OS Two complementary \nveri.cation technologies, TAL and automated theorem proving, drive Verve s design. On one hand, TAL is \nrela\u00adtively easy to generate, since the compiler automatically turns C# code into TAL code, relying only \non lightweight type annotations Figure 1. Verve structure, showing all 20 functions exported by the \nNucleus already present in the C# code. This enables TAL to scale easily to large amounts of code. For \nVerve, we use the Bartok compiler [6] to generate TAL code. On the other hand, automated theorem provers \ncan verify deeper logical properties about the code than a typical TAL type system can express. Leveraging \nthis power requires more effort, though, in the form of heavyweight programmer-supplied preconditions, \npostconditions, and loop invariants. To exploit the tradeoff between TAL and automated theorem proving, \nwe decided to split the Verve operating system code into two parts, shown in Figure 1: a Nucleus, veri.ed \nwith automated theorem proving, and a kernel, veri.ed with TAL. The dif.culty of theorem proving motivated \nthe balance between the two parts: only the functionality that TAL could not verify as safe went into \nthe Nucleus; all other code went into the kernel. The Nucleus s source code is not expressed in TAL, \nbut rather in Boogie s programming language, called BoogiePL (or just Boo\u00adgie), so that the Boogie veri.er \ncan check it. Since the Nucleus code consists of assembly language instructions, these assembly language \ninstructions must appear in a form that the Boogie veri.er can understand. As described in detail below, \nwe decided to encode assembly language instructions as sequences of calls to BoogiePL procedures (e.g. \nan Add procedure, a Load procedure, etc.), so that the Boogie veri.er can check that each instruction \ns precon\u00addition is satis.ed. After Boogie veri.cation, a separate tool called BoogieAsm , developed for \nan earlier project [13], extracts stan\u00addard assembly language instructions from the BoogiePL code. A \nstandard assembler then turns these instructions into an object .le. Rather than hand-code all of the \nNucleus in assembly language, we wrote some of the less performance-critical parts in a high-level extension \nof BoogiePL that we call Beat . Our (non-optimizing) Beat compiler transforms veri.able Beat expressions \nand state\u00adments into veri.able BoogiePL assembly language instructions. In Figure 2 we show the trusted \nand untrusted components of our system. Besides the boot loader, the only trusted components are the \ntools used to verify, assemble, and link the veri.ed Nucleus and kernel. Note that none of our compilers \nare part of our trusted computing base: we do not need to trust the compilers to ensure the correctness \nof the Nucleus and safety of the Verve system as a whole. As shown in Figure 2, the TAL checker and Boogie/Z3 \nveri.er check that the output of the compilers conforms to the TAL type system and the Nucleus speci.cation, \nso we just need to trust these checkers.  Figure 2. Building the Verve system: trusted, untrusted components \nBeyond the TAL checker and Boogie/Z3 veri.ers, Figure 2 shows additional components in Verve s trusted \ncomputing base: the assembler, the linker, the ISO CD-ROM image generator, and the boot loader. In addition, \nthe trusted computing base includes the speci.cation of correctness for the Nucleus s BoogiePL code. \nThis includes speci.cations of the behavior of functions exported by the Nucleus, shown in Figure 1. \n(For example, the speci.cation of YieldTo ensures that the Nucleus sets the stack pointer to the top \nof the correct stack during a yield.) It also includes speci.cations for assembly language instructions \nand for interaction with hard\u00adware devices and memory; we took some of these speci.cations from existing \nwork [13], and wrote some of them from scratch. All Boogie speci.cations are written as .rst-order logic \nformulas in the BoogiePL language. By expressing and checking properties at a low level (assem\u00adbly language), \nwe can ensure non-trivial properties with high con\u00ad.dence. The bulk of this paper focuses on these properties, \nwith an emphasis on the speci.cation and veri.cation of the Nucleus s correctness properties. The next \nsection discusses the Nucleus s de\u00adsign, and subsequent sections discuss speci.cation and veri.cation. \n3. The Nucleus interface The core of our veri.cation is the Nucleus, which provides a ver\u00adi.ed interface \nto the low-level functionality of the operating sys\u00adtem. We verify the Nucleus using Hoare logic in Boogie, \nbased on a trusted speci.cation for x86 assembly language instructions. In Verve, all access to low-level \nfunctionality must occur through the Nucleus the kernel s TAL code and application s TAL code can only \naccess low-level functionality indirectly, through the Nucleus. For example, TAL code cannot directly \naccess device registers. Fur\u00adthermore, even though TAL code can directly read and write words of memory, \nit can only read and write words designated as safe-for-TAL by the Nucleus s garbage collector. The Nucleus \nconsists of a minimal set of functions necessary to support the TAL code that runs above it. We wanted \na minimal set because even with an automated theorem prover, Hoare-style veri.cation is still hard work; \nless code in the Nucleus means less code to verify. At the same time, the set has to guarantee safety \nin the presence of arbitrary TAL code; it can assume that the TAL code is well typed, but can make no \nfurther assumptions about the behavior of the TAL code. For example, when an interrupt occurs, the Nucleus \nattempts to transfer control to a designated TAL interrupt handler. The Nucleus cannot assume that this \nhandler is in the correct state to handle the interrupt, and must therefore check the handler s state \nat run-time (see section 4.5). One design decision greatly simpli.ed the Nucleus: following a design \nused in recent micro-kernels [11, 14], no Nucleus function ever blocks. In other words, every Nucleus \nfunction performs a .nite (and usually small) amount of work and then returns. The Nucleus may, however, \nreturn to a different thread than the thread that invoked the function. This allows the kernel built \non top of the Nucleus to implement blocking thread operations, such as waiting on a semaphore. These \ndesign decisions led us to a small Nucleus API consist\u00ading of just 20 functions, all shown in Figure \n1. These 20 func\u00adtions, implemented with a total of about 1500 x86 instructions, in\u00adclude 3 memory management \nfunctions (AllocObject, AllocVec\u00adtor, GarbageCollect), one very limited exception handling func\u00adtion \n(Throw), 3 stack management functions (GetStackState, Re\u00adsetStack, YieldTo), and 4 device access functions \n(VgaTextWrite, TryReadKeyboard, StartTimer, SendEoi). Most of the functions are intended for use only \nby the kernel, not by applications. However, applications may call AllocObject and AllocVector directly. \nThe Nucleus exports four pseudo-functions, readField, write-Field, readStack, and writeStack, to the \nkernel and applications. These functions, described further in section 4, contain no exe\u00adcutable code, \nbut their veri.cation guarantees that the kernel and applications will .nd the values that they expect \nwhen they try to access .elds or objects or slots on the current stack. The Nucleus exports another 4 \nfunctions to the hardware for handling faults and interrupts: FatalHandler halts the system, while FaultHandler, \nEr\u00adrorHandler, and InterruptHandler yield execution to kernel TAL code running on a designated interrupt-handling \nstack. Finally, the Nucleus exports an entry point, NucleusEntryPoint to the boot loader. As more devices \nare added to the system, more Nucleus func\u00adtions may be required. However, a minimal Nucleus only needs \nto include the portion of the device interfaces critical the rest of the system s safety; if desired, \nVerve could use an I/O MMU to protect the system from devices, minimizing the device code that needs \nto reside in the Nucleus. Following the approach taken by the recent veri.ed L4 micro\u00adkernel, seL4 [14], \nVerve keeps interrupts disabled throughout the execution of any single Nucleus function. (On the other \nhand, in\u00adterrupts may be enabled during the TAL kernel s execution, with no loss of safety.) Since Nucleus \nfunctions do not block, Verve still guarantees that eventually, interrupts will always be re-enabled, \nand usually will be re-enabled very quickly. However, Verve s current implementation sacri.ces real-time \ninterrupt handling because of one particularly long function: GarbageCollect , which performs an entire \nstop-the-world garbage collection. This is currently a sub\u00adstantial limitation for the responsiveness \nof the system, but it is not fundamental to Verve s approach. Given a veri.ed incremental col\u00adlector, \nVerve could reduce the execution time of GarbageCollect to, say, just the time required to scan the stacks \n(or even a single stack), rather than the time required to garbage collect the whole heap. (Alternatively, \nVerve could poll for interrupts periodically, as in seL4. However, delivering these interrupts to the \nkernel TAL code would still require that the garbage collector reach a state that is safe for the kernel.) \nThe next two sections describes how Verve speci.es, imple\u00adments, and veri.es the Nucleus functions listed \nabove. 4. The Nucleus speci.cation To verify that the Nucleus behaves correctly, we have to spec\u00adify \nwhat correct behavior is. Formally, this speci.cation con\u00adsists of preconditions and postconditions for \neach of the 20 func\u00adtions exported by the Nucleus (Figure 1). The preconditions re.ect the guarantees \nmade by other components of the sys\u00adtem when calling the Nucleus. For example, the precondition to NucleusEntryPoint \ndescribes the state of memory when the Nu\u00adcleus begins execution; the (trusted) boot loader is responsible \nfor establishing this precondition. The preconditions for functions ex\u00adported to the kernel and applications \ndescribe the state of regis\u00adters and the current stack when making a call to the Nucleus; the (trusted) \nTAL checker is responsible for guaranteeing that these preconditions hold when the (untrusted) kernel \nand applications transfer control to the Nucleus. (Note that any property not guar\u00adanteed by the TAL \nchecker cannot be assumed by the Nucleus s preconditions for functions exported to the kernel and applications; \nas a result, the Nucleus must occasionally perform run-time checks to validate the values passed from \nthe kernel and applications.)  When writing the Nucleus s speci.cation, we are not interested so much \nin the Nucleus s private, internal behaviors, but rather how the Nucleus interacts with other components \nof the system. For example, the Verve speci.cation of garbage collection does not specify which algorithm \nthe garbage collector should imple\u00adment (e.g. copying or mark-sweep), since the algorithm is an in\u00adternal \nbehavior that is irrelevant to the other components of the system. Instead, following the approach of \nMcCreight et al [17], the speci.cation simply says that the garbage collector must main\u00adtain the well-formedness \nof the stacks and heap, so that subsequent reads and writes to the stack and heap other components of \nthe sys\u00adtem behave as expected. (Internally, the garbage collectors used by Verve [13] do have stronger \ninvariants about speci.c details of the algorithm, but these invariants are kept hidden from the other \nVerve system components.) The Nucleus interacts with .ve components: memory, hard\u00adware devices, the boot \nloader, interrupt handling, and TAL code (kernel and application code). Memory and hardware devices ex\u00adport \nfunctionality to the Nucleus, such as the ability to read mem\u00adory locations and write hardware registers. \nVerve must verify that the Nucleus satis.es the preconditions to each operation on mem\u00adory and hardware. \nIn turn, the Nucleus exports functionality to the boot loader (the Nucleus entry point), the interrupt \nhandling (the Nucleus s interrupt handlers), and the TAL code (AllocObject, YieldTo, etc.). 4.1 Speci.cation \nlogistics Verve expresses the speci.cation for interacting with these compo\u00adnents as .rst-order logical \nformulas in BoogiePL [2]. These formu\u00adlas follow C/Java/C# syntax and consist of: arithmetic operators: \n+, -, *, >, ==, !=, ...  boolean operators: !, &#38;&#38;, ||, ==>, ...  variables: foo, Bar, old(foo), \n...  boolean constants: true, false  integer constants: 5, ...  bit vector contants: 5bv16, 5bv32, \n...  function application: Factorial(5), Max(3,7), IsOdd(9), ...  array indexing: foo[3], ...  array \nupdate: foo[3 := Bar], ...  quanti.ed formulas: (.i:int::foo[i]==Factorial(i)), ...  For a variable \nfoo, the expression old(foo) refers to the value of foo at the beginning of the procedure. BoogieAsm \nalso enforces the convention that capitalized variable names correspond with read-only variables. For \ninstance, the variable corresponding to the instruction pointer Eip is read-only, while variable corresponding \nto the register eax is directly readable and writable. BoogiePL bit vectors correspond to integers in \nC/Java/C#, which are limited to numbers that .t inside a .xed number of bits. BoogiePL integers, on the \nother hand, are unbounded mathemati\u00adcal integers. BoogiePL arrays are unbounded mathematical maps from \nsome type (usually integers) to some other type. Unlike ar\u00adrays in C/Java/C#, BoogiePL arrays are immutable \nvalues (there are no references to arrays and arrays are not updated in place). An array update expression \na[x := y] creates a new array, which is equal to the old array a at all locations except x, where it \ncon\u00adtains a new value, y. For example, (a[x := y])[x] == y and (a[x := y])[x + 1] == a[x + 1]). BoogiePL \nprocedures have preconditions and postconditions, written as BoogiePL logical formulas: var a:int, b:int; \nprocedure P(x:int, y:int) requiresa <b &#38;&#38;x<y; modifies a, b; ensuresa<b&#38;&#38;a ==x +old(a); \n{ a :=a+x; b :=b+y; } In this example, the procedure P can only be called in a state where global variable \na is less than global variable b, and the parameter x is less than the parameter y. Upon exit, the procedure \ns postconditions ensure that a is still less than b, and that a is equal to x plus the old version of \na (before P executed). Note that the procedure must explicitly reveal all the global variables that it \nmodi.es ( modifies a, b; in this example), so that callers to the procedure will be aware of the modi.cations. \nTo verify that a program s code obeys its speci.cation, the Boo\u00adgie tool relies on the Z3 [7] automated \ntheorem prover. Z3 automat\u00adically checks logical formulas involving linear arithmetic (addition, subtraction, \ncomparison), arrays, bit vectors, and functions. Z3 also checks quanti.ed formulas (formulas with forall \nand exists); however, Z3 relies on programmer-supplied hints in the form of triggers to help with quanti.ers, \nsince checking quanti.ed formu\u00adlas with arithmetic and arrays is undecidable in general. Earlier work \n[13] describes how Verve s garbage collectors use triggers. For each function exported to the boot loader, \ninterrupt han\u00addling, and TAL code, the Nucleus implements a BoogiePL proce\u00addure whose speci.cation is \ngiven in terms of requires , ensures , and modi.es clauses. The Nucleus implements these procedures in \nterms of more primitive hardware procedures: each BoogiePL procedure exported from the memory and hardware \ndevices to the Nucleus corresponds to exactly one assembly language instruction, such as an instruction \nto read a single memory location or write to a single hardware register. In order to convey concretely \nwhat the Nucleus speci.cation and veri.cation entail, subsections 4.2-4.6 describe in detail the BoogiePL \nspeci.cations of the Nucleus s interaction with the mem\u00adory (4.2), hardware devices (4.3), boot loader \n(4.4), interrupt han\u00addling (4.5), and TAL code (4.6). Note that the interfaces in sub\u00adsections 4.2-4.5 \nare for use only by the Nucleus, not by kernel and application code. Kernel and application code can \nonly make use of these interfaces indirectly, via calls to the Nucleus.  4.2 Memory Verve s initial \nmemory layout is set by the boot loader. Verve uses the boot loader from the Singularity project [8], \nwhich sets up an initial virtual-memory address space (i.e. it sets up a page table), loads the executable \nimage into memory, and jumps to the exe\u00adcutable s entry point, passing detailed information about the \nmem\u00adory layout to the entry point. The boot-loader-supplied address space simply maps virtual memory \ndirectly to physical memory, except for a small range of low addresses that are left unmapped (to catch \nnull pointer dereferences). A traditional operating system would create new virtual memory address spaces \nto protect appli\u00adcations from each other. However, unlike traditional operating sys\u00adtems, Verve guarantees \ntype safety, and can therefore rely on type safety for protection. Because of this, Verve simply keeps \nthe initial boot-loader-supplied address space.  Verve s mapped address space consists of three parts. \nFirst is the memory occupied by the executable image, including code, static .elds, method tables, and \nmemory layout information for the garbage collector. Verve may read this memory, but may write only to \nthe static .elds, not the code, method tables, or layout infor\u00admation. Second, the Verve speci.cation \nreserves the memory just above the executable image for the interrupt table. Verve may write to the table, \nbut it can only write values that obey the speci.cation for interrupt handlers. Third, the remaining \nmemory above the in\u00adterrupt handler is general-purpose memory, free for arbitrary use; the Nucleus may \nread and write it at any time as it wishes (as long as it ensures the well-formedness of the heap and \ncurrent stack be\u00adfore transferring control to TAL code, as discussed in section 4.6). The speci.cation \ndescribes the state of general-purpose memory using a global variable Mem, which is an array that maps \ninteger byte addresses to integer values. For any 4-byte-aligned address i in general-purpose memory, \nMem[i] contains the 32-bit memory contents stored at address i, represented as an integer in the range \n0 ... 232 - 1. The memory exports two operations to the Nucleus, Load and Store: procedure Load(ptr:int) \nreturns (val:int); requires memAddr(ptr); requires Aligned(ptr); modifies Eip; ensures word(val); ensures \nval == Mem[ptr]; procedure Store(ptr:int, val:int); requires memAddr(ptr); requires Aligned(ptr); requires \nword(val); modifies Eip, Mem; ensures Mem == old(Mem)[ptr := val]; Each of these two operations requires \na 4-byte-aligned pointer ( Aligned(...) ) to memory inside the general-purpose memory region ( memAddr(...) \n). The loaded or stored value must be in the range 0 ... 232 - 1 ( word(...) ). Any Store operation updates \nthe contents of Mem, so that subsequent Load operations are guaranteed to see the updated value. Loads \nand stores have an additional side effect, noted in the modi.es clause: they modify the current instruction \npointer (program counter), Eip . The executable image memory exports its own load/store inter\u00adface to \nthe Nucleus, but with a store operation that applies only to static .elds. Finally, the interrupt table \nexports a store operation that allows the Nucleus to write to the interrupt descriptor table (IDT). On \nx86 processors, the interrupt descriptor table contains a sequence of 8\u00adbyte entries that describe what \ncode the processor should jump to when receiving various kinds of faults and interrupts. This is a very \nsensitive data structure, since an invalid entry could cause a jump to an arbitrary address in memory, \nwhich would be unsafe. We had originally hoped to use general-purpose memory for the interrupt table, \nand to guarantee the well-formedness of the interrupt table whenever the Nucleus transfers control to \nTAL code. Under this hope, the Nucleus would be allowed to arbitrarily modify the in\u00adterrupt table temporarily, \nwhich would be safe while interrupts are disabled. However, some x86 platforms support non-maskable in\u00adterrupts \n, which can occur even with interrupts disabled. If such an interrupt ever occurred, we d feel safer \ntransferring control to a designated fatal error handler than allowing arbitrary behavior. Therefore, \nthe interrupt table exports an interface that only allows stores of approved entries: procedure IdtStore(entry:int, \noffset:int, handler:int, ptr:int, val:int); requires 0 <= entry &#38;&#38; entry < 256; requires (offset \n== 0 &#38;&#38; val == IdtWord0(handler)) || (offset == 4 &#38;&#38; val == IdtWord4(handler)); requires \nIsHandlerForEntry(entry, handler); requires ptr == idtLo + 8 * entry + offset; modifies Eip, IdtMem, \nIdtMemOk; ensures IdtMem == old(IdtMem)[ptr := val]; ensures IdtMemOk == old(IdtMemOk)[ptr := true]; \nLike Store, IdtStore corresponds to a single x86 store in\u00adstruction. Using IdtStore, the Nucleus may \nwrite to either 4-byte word of any 8-byte entry in the table, as long as the word describes a valid interrupt \nhandler for the entry. After a valid word is writ\u00adten to address ptr, the speci.cation updates an array \nof booleans IdtMemOk to re.ect that the word at address ptr is now valid. Valid words obey a strange \nIntel speci.cation that splits the han\u00addler s address across the two words in 16-bit pieces; we show \nthe BoogiePL for this speci.cation just to demonstrate that Verve can deal with such low-level architectural \ndetails safely (and, or, and shl are 32-bit bitwise AND/OR/SHIFT-LEFT): function IdtWord0(handler:int) \nreturns(int) { or(shl(CSS, 16), and(handler, 0x0000ffff)) }function IdtWord4(handler:int) returns(int) \n{ or(and(handler, 0xffff0000), 0x8e00) }  4.3 Hardware devices Verve currently supports four hardware \ndevices: a programmable interrupt controller (PIC), a programmable interval timer (PIT), a VGA text screen, \nand a keyboard. Verve speci.es the interaction with this hardware using unbounded streams of events. \nThe Nu\u00adcleus delivers events to the PIC, PIT, and screen, and it receives events from the keyboard. For \nthe screen, the events are commands to draw a character at a particular position on the screen. For the \nkeyboard, events are keystrokes received from the keyboard. For the PIC and PIT, particular sequences \nof events initialize interrupt handling and start timers. We present the keyboard speci.cation as an \nexample. Verve represents the stream of events from the keyboard as an immutable array KbdEvents mapping \nevent sequence numbers (represented as integers, starting from 0) to events (also represented as integers). \nAs the Nucleus queries the keyboard, it discovers more and more events from the stream. Two indices into \nthe array, KbdAvailable and KbdDone, indicate the state of the Nucleus s interaction with the keyboard. \nEvents 0...KbdDone-1 have already been read by the Nucleus, while events KbdDone...KbdAvailable-1 are \navailable to read but have not yet been read. Two operations, KbdStatusIn8 and KbdDataIn8, query the \nkeyboard. Each of these procedures represents a single 8-bit x86 assembly language I/O instruction, and \nBoogieAsm translates each call to these procedures into a single x86 in instruction. By invoking KbdStatusIn8, \nthe Nucleus discovers the current state of KbdAvailable and KbdDone. If this operation places a 0 in \nthe eax register s lowest bit, then no events are available; if the operation places a 1 in eax s lowest \nbit, then at least one event is available. If the Nucleus can prove that at least one event is available, \nit may call KbdDataIn8 to receive the .rst available event.  var KbdEvents:[int]int; var KbdAvailable:int, \nKbdDone:int; procedure KbdStatusIn8(); modifies Eip, eax, KbdAvailable; ensures and(eax,1)==0 ==> KbdAvailable==KbdDone; \nensures and(eax,1)!=0 ==> KbdAvailable> KbdDone; procedure KbdDataIn8(); requires KbdAvailable > KbdDone; \nmodifies Eip, eax, KbdDone; ensures KbdDone == old(KbdDone) + 1; ensures and(eax,255) == KbdEvents[old(KbdDone)]; \nFor example, the Nucleus implementation of the TryReadKeyboard function .rst calls KeyboardStatusIn8, \nand then performs a bitwise AND operation to discover the status: implementation TryReadKeyboard() { \ncall KeyboardStatusIn8(); call eax := And(eax, 1); ...  4.4 Boot loader and Nucleus initialization Interaction \nwith the boot loader, interrupt handling, and TAL code is speci.ed by preconditions and postconditions \non Nucleus\u00adimplemented procedures. The .rst such procedure to execute is the Nucleus entry point, NucleusEntryPoint. \nWhen booting com\u00adpletes, the boot loader transfers control to NucleusEntryPoint. (After this control \ntransfer, no boot loader code ever runs again.) The Nucleus entry point implementation must obey the \nfollowing speci.cation (for brevity, we omit some of the requires, modi.es, and ensures clauses): procedure \nNucleusEntryPoint(...); requires...idtLo == ro32(ro32(ecx+40)+72+0) &#38;&#38; memHi == ro32(ro32(ecx+40)+72+8)+idtLo \n... requires RET == ReturnToAddr(KernelEntryPoint); requires S == 0; ... ensures esp == StackHi(S) -4 \n&#38;&#38; ebp == 0; ensures StackCheckInv(S, StackCheck); ensures IdtOk &#38;&#38; PicOk(...) &#38;&#38; \nTimerOk(...); ensures NucleusInv(S, StackState[S:=StackRunning],...); The boot loader passes information \nabout available memory in the ecx register. This information supplies the Nucleus with the bounds of \nthe memory above the executable image, which ranges from the low end of the interrupt table (idtLo) to \nthe high end of general-purpose memory. (The function ro32 maps each address in read-only memory to the \n32-bit value stored at that address.) The RET value speci.es how the procedure must return. It equals \none of two values: ReturnToAddr(i), which speci.es that the procedure must perform a normal return (the \nx86 ret instruc\u00adtion) to address i, or ReturnToInterrupted(i, cs, eflags), which speci.es that the procedure \nmust perform an interrupt return (the x86 iretd instruction) to return address i, restoring code seg\u00adment \ncs and status .ags eflags. The speci.cation shown above requires that the Nucleus entry point return \nto the TAL kernel en\u00adtry point. (Notice that Nucleus functions do not necessarily return to their direct \ncaller; the Nucleus entry point returns to TAL, not to the boot loader.) Furthermore, the Nucleus entry \npoint must set correct initial stack pointer (esp) and frame pointer (ebp) values. It must also set a \nglobal variable StackCheck with the address of the low end of the stack; TAL functions compare the stack \npointer to StackCheck to check for stack over.ow. Several postconditions ensure that devices and interrupts \nare set up correctly: IdtOk guarantees that the Nucleus has completely .lled in the interrupt table and \nset up the x86 s pointer to the interrupt table, PicOk guarantees that the Nucleus has initialized the \nprogrammable interrupt controller, and TimerOk guarantees that the Nucleus has initialized the programmable \ninterval timer. One of the Nucleus s key roles is to manage multiple stacks, so that the TAL kernel can \nimplement multiple threads. (To dis\u00adtinguish the Nucleus s functionality from the kernel s function\u00adality, \nwe say that the Nucleus implements stacks and the ker\u00adnel implements threads .) The speci.cation uses \ntwo variables, S and StackState, to specify the current state of the Verve stacks. Stacks are numbered \nstarting from 0, and S contains the current running stack. The Nucleus entry point speci.cation S=0 indicates \nthat the nucleus should run the TAL kernel entry point in stack 0. At any time, each stack s is in one \nof four states, speci.ed by StackState[s]: empty, running, yielded, or interrupted. Initially, stack \n0 is set to running (StackRunning), and all other stacks are empty. When TAL code is interrupted, its \ncurrent stack s state changes to interrupted. When TAL code voluntarily yields, its cur\u00adrent stack s \nstate changes to yielded. NucleusEntryPoint s .nal postcondition sets up the Nu\u00adcleus s private invariant, \nNucleusInv. This invariant is a Nucleus\u00adspeci.ed function that takes as arguments the Nucleus s pri\u00advate \nglobal variables, along with some speci.cation variables like Mem, S, and StackState. The Nucleus may \nde.ne NucleusInv any way it wants. If it de.nes too weak an invariant (e.g. NucleusInv(...) = true), \nthough, then the Nucleus will be not have enough information to implement other Nucleus functions, such \nas allocation. On the other hand, if the invariant is too strong (e.g. NucleusInv(...) = false), the \nNucleus entry point will not be able to ensure it in the .rst place. For successful veri.ca\u00adtion, the \nNucleus must de.ne an invariant strong enough to ensure the well-formedness of the stacks and heaps, \nas well as the well\u00adformedness of the Nucleus s own internal data structures.  4.5 Interrupt handling \nAfter the TAL kernel begins execution in stack 0, it voluntarily yields control to another stack and \nenables interrupts. When a stack voluntarily yields, its state changes from StackRunning to StackYielded(_ebp, \n_esp, _eip), where _ebp, _esp, and _eip indicate the values that the stack pointer, frame pointer, and \ninstruction pointer must be restored with in order to resume the stack s execution. Upon receiving an \ninterrupt or fault, the Nucleus s inter\u00adrupt and fault handlers (InterruptHandler, FaultHandler, and \nErrorHandler) transfer control back to the TAL code in stack 0, which then services the interrupt or \nfault. To specify this behav\u00adior, the handler procedure s preconditions and postconditions force the \ninterrupt and fault handlers to restore stack 0 s stack and frame pointers and return to stack 0 s instruction \npointer: procedure InterruptHandler(...); requires NucleusInv(S, ...); requires (Tag(StackState[0])==STACK \nYIELDED ==> RET == ReturnToAddr(eip) &#38;&#38; StackState[0]==StackYielded( ebp, esp, eip)); ...  ensures \n(Tag(StackState[0])==STACK YIELDED ==> NucleusInv(0, ...) &#38;&#38; ebp == ebp &#38;&#38; esp == esp); \nThe interrupted stack changes from state StackRunning to state: StackInterrupted( eax, ebx, ecx, edx, \nesi, edi, ebp, esp, eip, cs, efl) The values _eax..._efl indicate the x86 registers that must be restored \nto resume the interrupted stack s execution. (Verve does not yet handle .oating point code, so no .oating \npoint state needs to be restored.) Verve veri.es the correctness of the Nucleus, but only veri.es the \nsafety of the kernel. As a result, a buggy TAL kernel might leave stack 0 in some state besides yielded. \n(For example, a buggy kernel might enable interrupts while running in stack 0, which could cause stack \n0 to be in the running state when an interrupt occurs.) To ensure safety even in the presence of a buggy \nkernel, the Nucleus must check stack 0 s state at run-time; if it not in the yielded state, the Nucleus \nhalts the system. InterruptHandler s precondition enforces this run-time check: it allows the stack to \nbe in any state, but RET is only known in the case where the state is yielded, so that InterruptHandler \ns implementation has to check that the state is yielded to use RET and return to the kernel.  4.6 TAL \nkernel and applications The Nucleus exports various functions directly to TAL code. First, it exports \nthree stack manipulation functions to the TAL kernel: GetStackState, ResetStack, and YieldTo. GetStackState \nsimply returns the state of any stack. ResetStack changes the state of a stack to empty; the kernel may \nuse this to terminate an unused thread. Finally, YieldTo transfers control to another stack. The kernel \nuses YieldTo to implement thread scheduling; for example, the kernel s timer interrupt handler calls \nYieldTo to preempt one thread and switch to another thread. The exact behavior of YieldTo depends on \nthe state of the target stack that is being yielded to. If the target stack is in the yielded or interrupted \nstate, YieldTo restores the target stack s state and resumes its execution. If the target stack is in \nthe empty state, YieldTo runs the TAL kernel s entry point in the target stack; the kernel uses this \nto start new threads. If the target state is in the running state, then the stack is switching to itself; \nin this case, YieldTo simply returns. For brevity, we omit most of the speci.cation for YieldTo here; \nit looks much like InterruptHandler s speci.cation from section 4.5, but with cases for all four stack \nstates, rather than just for the yielded state: procedure YieldTo(...); requires NucleusInv(S, ...); \nrequires ScanStackInv(S, ..., esp, ebp); requires ( StackState[s]==StackRunning &#38;&#38; s==S &#38;&#38; \nRET==ReturnToAddr(Mem[esp])) || (StackState[s]==StackYielded( ebp, esp, eip) &#38;&#38; RET==ReturnToAddr( \neip)) || (StackState[s]==StackInterrupted( eax,..., efl) &#38;&#38; RET==ReturnToInterrupted( eip, cs, \nefl)) || (StackState[s]==StackEmpty &#38;&#38; RET==ReturnToAddr(KernelEntryPoint) &#38;&#38; ...); ... \nYieldTo differs from InterruptHandler in one crucial re\u00adspect. When TAL code voluntarily calls a Nucleus \nfunction, the TAL code leaves its stack contents in a state that the veri.ed garbage collector can scan: \nthe garbage collector follows the chain of saved frame pointers until it reaches a saved frame pointer \nequal to 0. For each frame, the collector uses the frame s return address as an index into tables of \nGC layout information. By contrast, an interrupted stack is not necessarily scannable. The requirement \nScanStackInv(...) expresses the layout of the stack that allows scanning by the garbage collector, and \nthe TAL checker enforces that the TAL code satis.es this requirement. The Nucleus exports several run-time \nsystem functions to both TAL kernel and TAL application code: AllocObject, AllocVector, GarbageCollect, \nand Throw. Currently, Verve implements only trivial exception handling: when TAL tries to throw an exception, \nThrow simply terminates the current stack by setting its state to empty and transferring control to stack \n0. Verve takes its allocation and garbage collection implementations (both mark-sweep and copying collection) \ndirectly from another project on veri.ed garbage collection [13]; more information about them can be \nfound there. Verve makes only minor changes to the alloca\u00adtion and GC implementation. First, the allocators \nreturn null when the heap is full, rather than invoking garbage collection directly. This allows the \nTAL kernel to schedule the remaining threads to prepare for garbage collection, as described in section \n6. Second, the original veri.ed collectors scanned only a single stack; Verve adds a loop that scans \nall the stacks. Following earlier work by [17], the veri.ed garbage collec\u00adtors [13] export functions \nreadField and writeField that read and write heap object .elds on behalf of the TAL code. More pre\u00adcisely, \nthese functions grant the TAL code permission to read and write .elds of objects, by ensuring that the \n.elds reside at valid memory locations and, for reads, that the .elds contain the correct value. The \ncorrect value is de.ned by an abstract heap that the speci.cation maintains [13, 17]. The key invariant \nin the garbage collector veri.cation is that the concrete values stored in memory accurately re.ect the \nabstract heap whenever the TAL code is run\u00adning. Verve extends the abstract heap with multiple abstract \nstacks, each consisting of zero or more abstract stack frames. Prior work [13, 17] used auxiliary variables \nto describe the contents of the abstract heap. In the same way, Verve uses auxiliary vari\u00adables FrameCount \nand FrameAbs to describe the number of frames in each stack and the abstract contents of each word of \neach frame of each stack. The Nucleus exports functions readStack and writeStack that guarantee that \nthe concrete stack contents in Mem match the abstract contents. As in prior work [13, 17], this matching \nis loose enough to allow the garbage collector to update concrete pointers as objects move in memory \n(since the copying collector moves objects). In the speci.cation for readStack, the InteriorValue predicate \nmatches a concrete value val at mem\u00adory address ptr to the abstract value at offset j in the abstract \nframe frame of the current stack S: procedure readStack(ptr:int, frame:int, j:int) returns(val:int); \nrequires StackState[S] == StackRunning; requires NucleusInv(S,...); requires 0 <= frame < FrameCounts[S]; \nrequires ... ensures ... ensures val == Mem[ptr]; ensures InteriorValue(val,..., FrameAbs[S][frame][j],...); \n(The name InteriorValue re.ects the fact that a stack value might be an interior pointer to the inside \nof an object, which the garbage collector must properly track [13].) Note that readStack does not modify \nthe instruction pointer, Eip, because it contains no instructions (the same is true for readField, writeField, \nand writeStack). Because of this, the TAL code need not generate any code to call readStack at run-time. \nInstead, it simply reads the data at Mem[ptr] directly.  Finally, the Nucleus exports device management \nfunc\u00adtions to the TAL kernel: VgaTextWrite, TryReadKeyboard, StartTimer, and SendEoi (send end-of-interrupt). \nThe speci.ca\u00adtion for TryReadKeyboard, for example, requires that the Nucleus return a keystroke (in \nthe range 0-255) if one is available, and oth\u00aderwise return the value 256: procedure TryReadKeyboard(); \n... ensures KbdAvailable==old(KbdDone) ==> eax==256; ensures KbdAvailable> old(KbdDone) ==> eax==KbdEvents[old(KbdDone)]; \n5. The Nucleus implementation and veri.cation Verve follows earlier work [13] by using BoogiePL to express \nver\u00adi.ed assembly language instructions, but improves on the earlier work by generating much of the veri.ed \nassembly language auto\u00admatically from higher-level source code. We illustrate the veri.ed assembly language \ncode with a small, but complete, example the veri.ed source code implementing TryReadKeyboard: implementation \nTryReadKeyboard() { call KeyboardStatusIn8(); call eax := And(eax, 1); call Go(); if (eax != 0) {goto \nskip;} call eax:=Mov(256); call Ret(old(RET)); return; skip: call KeyboardDataIn8(); call eax := And(eax, \n255); call Ret(old(RET)); return; } To verify this, we simply run the Boogie tool on the source code, \nwhich queries the Z3 theorem prover to check that the procedure satis.es its postconditions, and that \nall calls inside the procedure satisfy the necessary preconditions. Given the BoogiePL source code, this \nprocess is entirely automatic, requiring no scripts or human interactive assistance to guide the theorem \nprover. Each statement in the veri.ed BoogiePL code corresponds to 0, 1, or 2 assembly language instructions. \n( If statements require 2 instructions, a compare and branch. Dynamically checked arith\u00admetic statements \nalso require 2 instructions, an arithmetic operation followed by a jump-on-over.ow.) BoogieAsm, a tool \ndeveloped for earlier work [13], transforms this veri.ed BoogiePL source code into valid assembly code: \n?TryReadKeyboard proc in al, 064h and eax, 1 cmp eax, 0 jne TryReadKeyboard$skip mov eax, 256 ret TryReadKeyboard$skip: \nin al, 060h and eax, 255 ret BoogieAsm checks that the source code contains no circular de.nitions of \nconstants or functions (which would cause the ver\u00adi.cation to be unsound), and no recursive de.nitions \nof proce\u00addures (which the translator currently cannot generate code for [13]). BoogieAsm also checks \nthat the veri.ed source code conforms to a restricted subset of the BoogiePL syntax. For example, be\u00adfore \nperforming an if or return statement, the code must per\u00adform call Go() or call Ret(old(RET)) operations \nto update the global variables that re.ect the machine state: procedure Go(); modifies Eip; procedure \nRet(oldRET:ReturnTo); requires oldRET == ReturnToAddr(Mem[esp]); requires Aligned(esp); modifies Eip, \nesp; ensures esp == old(esp) + 4; ensures Aligned(esp); 5.1 Beat To relieve some of the burden of writing \ndetailed, annotated as\u00adsembly and to clarify the code, we developed a small extension of BoogiePL called \nBeat, which we compile to BoogiePL. Beat pro\u00advides some modest conveniences, such as de.ning named aliases \nfor x86 assembly language registers, and very simple high-level\u00adto-assembly-level compilation of statements \nand expressions. This aids readability, since named variables and structured control con\u00adstructs ( if/else \n, while ) are easier to read than unstructured as\u00adsembly language branches, without straying too far \nfrom the low\u00adlevel assembly language model. For non-performance-critical code, we used Beat s high-level \nstatements rather than writing assembly language instructions directly. As a very simple example of using \nBeat, here is an alternate implementation of TryReadKeyboard, rewritten to use Beat s structured if/else \nconstruct: implementation TryReadKeyboard() { call KeyboardStatusIn8(); call eax := And(eax, 1); if (eax \n== 0) { eax := 256; } else { call KeyboardDataIn8(); call eax := And(eax, 255); } call Ret(old(RET)); \nreturn; } As shown in Figure 2, the Beat compiler generates (untrusted) BoogiePL assembly language code \nfor the Nucleus from (un\u00adtrusted) Beat code. The close correspondence between the Beat code and the generated \nBoogiePL assembly language code ensures that veri.able Beat compiles to veri.able BoogiePL assembly lan\u00adguage. \n 5.2 The Nucleus Invariant As mentioned in section 4.4, the Nucleus is free to choose its own internal \ninvariant, NucleusInv, that describes the state of its internal data structures. Verve s de.nition of \nNucleusInv consists of two parts. The .rst part holds the garbage collector s internal invariants, as \ndescribed in more detail in [13]. The second part holds the invariants about stacks. For example, the \nsecond part contains an invariant for each stack s in the yielded state:  Tag(StackState[s])==STACK \nYIELDED ==> ... &#38;&#38; Aligned(StackEsp(s,...)) &#38;&#38; StackState[s]==StackYielded(StackEbp(s,...),...) \n&#38;&#38; ScanStackInv(s,...,StackEbp(s,...)) This invariant says that each yielded stack has an aligned \nstack pointer (Aligned(...)), contains the appropriate ebp register, esp register, and return address \n(StackState[s]==...), and is scannable by the garbage collector (ScanStackInv(...)). The Nucleus keeps \nan internal data structure that holds each stack s saved context, including the saved esp register, the \nsaved ebp reg\u00adister, etc. This data structure occupies TSize bytes of memory per stack and starts at \naddress tLo. The Nucleus de.nes the functions StackEsp, StackEbp, etc. to describe the layout of the \nsaved con\u00adtext for each stack s: function StackEsp(s,...){tMems[s][tLo+s*TSize+4]}function StackEbp(s,...){tMems[s][tLo+s*TSize+8]}function \nStackEax(s,...){tMems[s][tLo+s*TSize+12]}... In the de.nitions above, tMems is an auxiliary variable \ndescrib\u00ading the subset of memory devoted to storing saved stack contexts; for this subset, tMems[s][...] \nis equal to Mem[...]. The Nu\u00adcleus uses Load and Store operations to read and write the saved contexts. \nThe NucleusInv invariant makes sure that each saved context contains correctly saved registers, so that \nthe Nucleus s im\u00adplementation of InterruptHandler and YieldTo can veri.ably restore each saved context. \n6. Kernel On top of the Nucleus, Verve provides a simple kernel, writ\u00adten in C# and compiled to TAL. \nThis kernel follows closely in the footsteps of other operating systems developed in safe lan\u00adguages \n[1, 4, 8, 20], so this section focuses on the interaction of the kernel with the Nucleus. The kernel \nimplements round-robin preemptive threading on top of Nucleus stacks, allowing threads to block on semaphores. \nThe kernel scheduler maintains two queues: a ready queue of threads that are ready to run, and a collection \nqueue of threads waiting for the next garbage collection. A running thread may voluntarily ask the kernel \nto yield. In this case, the thread goes to the back of the ready queue. The scheduler then selects another \nthread from the front of the ready queue and calls the Nucleus YieldTo function to transfer control to \nthe newly running thread. The kernel TAL code may execute the x86 disable-interrupt and enable-interrupt \ninstructions whenever it wishes. While perform\u00ading scheduling operations, the kernel keeps interrupts \ndisabled. It enables interrupts before transferring control to application TAL code. Thus, a thread running \napplication code may get interrupted by a timer interrupt. When this happens, the Nucleus transfers con\u00adtrol \nback to the kernel TAL code running on stack 0. This code uses the Nucleus GetStackState function to \ndiscover that the previ\u00adously running thread was interrupted. It then moves the interrupted thread to \nthe back of the scheduler queue, and calls YieldTo to yield control to a thread from the front of the \nready queue. When an application asks the kernel to spawn a new thread, the kernel allocates an empty \nNucleus stack, if available, and places the new thread in the ready queue. When the empty thread runs \n(via a scheduler call to YieldTo), it enters the kernel s en\u00adtry point, KernelEntryPoint, which calls \nthe application code. When the application code is .nished running, it may return back to KernelEntryPoint, \nwhich marks the thread as exited and yields control back to the kernel s stack 0 code. The stack 0 code \nthen calls ResetThread to mark the exited thread s stack as empty (and thus available for future threads \nto use). (Note that KernelEntryPoint is not allowed to return, since it sits in the bottom-most frame \nof its stack and has no return address to return to. The TAL checker veri.es that KernelEntryPoint never \ntries to return, simply by assigning KernelEntryPoint a TAL type that lacks a return address to return \nto.) Applications may allocate and share semaphore objects to co\u00adordinate execution among threads. The \nVerve keyboard driver, for example, consists of a thread that polls for keyboard events and signals a \nsemaphore upon receiving an event. Each semaphore sup\u00adports two operations, Wait and Signal. If a running \nthread re\u00adquests to wait on a semaphore, the kernel scheduler moves the thread into the semaphore s private \nwait queue, so that the thread blocks waiting for someone to signal the thread. A subsequent re\u00adquest \nto signal the semaphore may release the thread from the wait queue into the ready queue. The kernel s \nscheduler also coordinates garbage collection. We modi.ed the Bartok compiler so that at each C# allocation \nsite, the compiler generates TAL code to check the allocator s return value. If the value is null, the \nTAL code calls the kernel to block awaiting garbage collection, then jumps back to retry the allocation \nafter the collection. The kernel maintains a collection queue of threads wait\u00ading for garbage collection. \nFollowing existing Bartok design [6] (and Singularity design [8]), before performing a collection Verve \nwaits for each thread in the system to block on a semaphore or at an allocation site. This ensures that \nthe collector is able to scan the stack of every thread. It does raise the possibility that one thread \nin an in.nite loop could starve the other threads of garbage collec\u00adtions. If this is a concern, Bartok \ncould be modi.ed to poll for col\u00adlection requests at backwards branches, at a small run-time cost and \nwith larger GC tables. Alternatively, if Bartok were able to gener\u00adate GC information for all program \ncounter values in the program, we could add a precondition to InterruptHandler saying that an interrupted \nstack is scannable, so that the kernel need not wait for threads to block before calling the garbage \ncollector. 7. Measurements This section describes Verve s performance. We believe our mea\u00adsurements are, \nalong with seL4, the .rst measurements showing ef.cient execution of realistic, veri.ed kernels on real-world \nhard\u00adware. (Feng et al [9] do not present performance results. On an ARM processor, the seL4 implementation \n[14] reports just one micro-benchmark: a one-way IPC time of 224 cycles (448 cycles round-trip). Note \nthat, as of the time of publication [14], this was the time for a fast path IPC that had not yet been \nfully veri.ed. All the results we present for Verve are for fully veri.ed code that is, code that has \nbeen fully checked against a speci.cation.) We also describe the size of the Nucleus implementation (in\u00adcluding \nannotations) and the veri.cation time. The small size of the annotated Nucleus implementation and the \nrelatively small amount of time for automated veri.cation suggests that this is feasible as a general \napproach for developing veri.ed low-level systems. 7.1 Performance We wrote our micro-benchmarks in \nC#, compiled them to TAL, veri.ed the TAL code, and linked them with the kernel and Nu\u00adcleus. We then \nran them on a 1.8 GHz AMD Athlon 64 3000+ with 1GB RAM, using the processor s cycle counters to measure \ntime and averaging over multiple iterations, after warming caches. The benchmarks exercise the performance-critical \ninterfaces exported by the Nucleus: stack management and memory management. All benchmarks were performed \non two con.gurations Verve built with a copying collector, and Verve built with a mark-sweep col\u00adlector: \n Copying (cycles) MS (cycles) 2*YieldTo 98 98 2*Wait+2*Signal 216 216 Allocate 16-byte object 46 61 \nAllocate 1000-byte array 1289 1364 GC per 16-byte object (0MB live) 1 34 GC per 16-byte object (256MB \nlive) 193 105 Our numbers compare favorably with round-trip inter-process communication times for even \nthe fastest x86 micro-kernels, and compares very well with seL4 s fast path . The YieldTo bench\u00admark \nshows that the Verve Nucleus requires 98 cycles to switch from one stack to another and back (49 cycles \nper invocation of YieldTo). The kernel builds thread scheduling and semaphores on top of the raw Nucleus \nYieldTo operation. Using semaphore wait and signal operations, it takes 216 cycles to switch from one \nthread to another and back (108 cycles per thread switch). This 216 cy\u00adcles is actually considerably \nfaster than the measured performance of the round-trip intra-process wait/signal time measured by Fah\u00adndrich \net al [8], on the same hardware as our measurements were taken, for the Singularity operating system \n(2156 cycles), the Linux operating system (2390 cycles), and the Windows operating system (3554 cycles). \nIn fairness, of course, Singularity, Linux, and Win\u00addows support far more features than Verve, and Verve \nmight be\u00adcome slower as it grows to include more features. The wait/signal performance is comparable \nto the round-trip IPC performance of fast micro-kernels such as L4 (242 cycles on a 166 MHz Pen\u00adtium \n[15]) and seL4 (448 cycles on an ARM processor [14]), al\u00adthough in fairness, IPC involves an address \nspace switch as well as a thread switch. We split the memory management measurements into allocation \ntime (when no GC runs) and GC time. The allocation times show the time taken to allocate individual 16-byte \nobjects and 1000-byte arrays in a con.guration with very little fragmentation. (The mark\u00adsweep times \nmay become worse under heavy fragmentation.) The GC times show the time taken to perform a collection \ndivided by the number of objects (all 16 bytes each) allocated in each collection cycle. One measurement \nshows the time with no live data (the collection clears out the heap entirely) and with 256MB of live \ndata retained across each collection. (256MB is 50% of the maximum capacity of the copying collector \nand about 30% of the maximum capacity of the mark-sweep collector; as the live data approaches 100% of \ncapacity, GC time per allocation approaches in.nity.) Because Verve does not support all C# features \nand libraries yet, we have not been able to port existing C# macro-benchmarks to Verve. The micro-benchmarks \npresented in the section, though, give us hope that Verve compares favorably with existing, un\u00adveri.ed \noperating systems and run-time systems. Furthermore, the veri.ed allocators and garbage collectors used \nby Verve have shown competitive performance on macro-benchmarks when com\u00adpared to native garbage collectors \n[13]. The TAL code generated by Bartok has also shown competitive performance on macro\u00adbenchmarks [6]. \n 7.2 Implementation and veri.cation We next present the size of various parts of the Nucleus speci.ca\u00adtion \nand implementation. All measurements are lines of BoogiePL and/or Beat code, after removing blank lines \nand comment-only lines. The following table shows the size of various portions of the trusted speci.cation: \nBasic de.nitions 61 Memory and stacks 116 Interrupts and devices 111 x86 instructions 126 GC tables and \nlayouts 317 Nucleus GC, allocation functions 239 Nucleus other functions 215 Total BoogiePL lines 1185 \n Overall, 1185 lines of BoogiePL is fairly large, but most of this is devoted to de.nitions about the \nhardware platform and memory layout. The GC table and layout information, originally de.ned by the Bartok \ncompiler, occupies a substantial fraction of the speci.cation. The speci.cations for all the functions \nexported by the Nucleus total 239 + 215 = 454 lines. We measure the size of the Nucleus implementation \nfor two con.gurations of Verve, one with the copying collector and one with the mark-sweep collector. \n(Note that the trusted speci.cations are the same for both collectors.) 1610 lines of BoogiePL are shared \nbetween the two con.gurations: Copying Mark-Sweep Shared BoogiePL lines 1610 1610 Private BoogiePL lines \n2699 3243 Total BoogiePL lines 4309 4854 Speci.cation BoogiePL lines 1185 1185 Total BoogiePL lines w/ \nspec 5494 6039 x86 instructions 1377 1489 BoogiePL/x86 ratio 3.1 3.3 BoogiePL+spec/x86 ratio 4.0 4.1 \n In total, each con.guration contains about 4500 lines of Boo\u00adgiePL. From these, BoogieAsm extracts about \n1400 x86 instruc\u00adtions. (Note: the BoogieAsm tool can perform macro-inlining of as\u00adsembly language blocks; \nwe report the number of x86 instructions before inlining occurs.) This corresponds roughly to a 3-to-1 \nratio (or 4-to-1 ratio, if the speci.cation is included) of BoogiePL to x86 instructions (or, roughly, \n2-to-1 or 3-to-1 ratio of non-executable annotation to executable code). This is about an order of magnitude \nfewer lines of annotation and script than related projects [9, 14]. Of course, some annotations are easier \nto write than others. In particular, annotations with quanti.ers (forall and exists) require programmer-chosen \ntriggers for the quanti.ers. The 7552 lines of BoogiePL listed in the table above contain 389 quanti.ers, \neach requiring a trigger. Fortunately, in practice, Verve s quanti.ers tend use the same triggers over \nand over: across the 389 quanti.ers, there were only 15 unique choices of triggers. Another issue is \nthat Verve sometimes requires the BoogiePL code to contain explicit assertions of triggers, which serve \nas hints to the theorem prover to instantiate a quanti.ed variable at some particular value (see [13] \nfor details). The 7552 lines of BoogiePL listed above contain 528 such assertions more than we d like, \nbut still a small fraction of the annotations. Using Boogie/Z3 to verify all the Nucleus components, \ninclud\u00ading both the mark-sweep and copying collectors, takes 272 seconds on a 2.4GHz Intel Core2 with \n4GB of memory. The vast majority of this time is spent verifying the collectors; only 33 seconds were \nrequired to verify the system s other components. This small veri.cation time enormously aided the Nucleus \nde\u00adsign and implementation, because it gave us the freedom to exper\u00adiment with different designs. Often \nwe would .nish implementing and verifying a feature using one design, only to become dissatis\u00ad.ed with \nthe complexity of the interface or limitations in the design. In such cases, we were able to redesign \nand re-implement the fea\u00adture in a matter of days rather than months, because we could make minor changes \nto large, Nucleus-wide invariants and then run the automated theorem prover to quickly re-verify the \nentire Nucleus. In fact, some of our re-designs were dramatic: mid-way through the project, we switched \nfrom an implementation based on blocking Nucleus calls to an implementation based on non-blocking Nucleus \ncalls. We also had to revise the garbage collector invariants to re\u00ad.ect the possibility of multiple \nstacks, which weren t present in the original veri.ed GC implementations [13]. In the end, the Verve \nde\u00adsign, implementation, and veri.cation described in this paper took just 9 person-months, spread between \ntwo people.  8. Related Work The Verve project follows in a long line of operating system and run-time \nsystem veri.cation efforts. More than 20 years ago, the Boyer-Moore mechanical theorem prover veri.ed \na small operating system and a small high-level language implementation [5]. These were not integrated \ninto a single system, though, and each piece in isolation was quite limited. The operating system, Kit, \nwas quite small, containing just a few hundred assembly language instruc\u00adtions. It supported a .xed number \nof preemptive threads, but did not implement dynamic memory allocation or thread allocation. It ran on \nan arti.cial machine rather than on standard hardware. The language, micro-Gypsy, was small enough that \nit did not require a signi.cant run-time system, as it had no heap allocation or threads. More recently, \nthe seL4 project veri.ed all of the C code for an entire microkernel [14]. The goals of seL4 and the \nVerve Nu\u00adcleus are similar in some ways and different in others. Both work on uni-processors, providing \npreemption via interrupts. seL4 pro\u00advides non-blocking system calls; this inspired us to move the Verve \nNucleus to a non-blocking design as well. Both Verve and seL4 pro\u00advide memory protection, but in different \nways. Verve provides ob\u00adjects protected by type safety, while seL4 provides address spaces of pages protected \nby hardware page tables. Verve applications can communicate using shared objects and semaphores, while \nseL4 processes communicate through shared memory or message pass\u00ading. seL4 veri.es its C code, but its \nassembly language (600 lines of ARM assembler) is currently unveri.ed. The seL4 microkernel contained \n8700 lines of C code, substantially larger than earlier veri.ed operating systems like Kit. On the other \nhand, the effort required was also large: they report 20 person-years of research de\u00advoted to developing \ntheir proofs, including 11 person-years specif\u00adically for the seL4 code base. The proof required 200,000 \nlines of Isabelle scripts a 20-to-1 script-to-code ratio. We hope that while seL4 demonstrates that \nmicrokernels are within the reach of inter\u00adactive theorem proving, Verve demonstrates that automated \ntheo\u00adrem proving can provide a less time-consuming alternative to inter\u00adactive theorem proving for realistic \nsystems software veri.cation. The seL4 kernel is bigger than Verve s Nucleus, so seL4 s cor\u00adrectness \nproof veri.es more than the Verve Nucleus s correctness proof (except for seL4 s unveri.ed assembly language \ninstruc\u00adtions). On the other hand, seL4 is still a microkernel most tradi\u00adtional OS features are implemented \noutside the microkernel as un\u00adveri.ed C/C++ code, and this unveri.ed code isn t necessarily type safe \n(although it is protected by virtual memory at a page granular\u00adity). By contrast, Verve s type safety \nis a system-wide guarantee. (Of course, type safety restricts which programs can run seL4 s use of page-level \nprotection provides a way to run unsafe programs as well as safe programs.) The FLINT project sets an \nambitious goal to build founda\u00adtional certi.ed machine code, where certi.cation produces a proof about \nan executable program, and a very small proof checker can verify the proof [9]. Such a system would have \na much smaller trusted computing base than Verve. The FLINT project uses pow\u00aderful higher-order logic \nto verify properties of low-level code, but achieves less automation than Verve: their preemptive thread \nli\u00adbrary (which, unlike Verve, proves the partial correctness of thread implementation, not just safety) \nrequires 35,000 lines of script for about 300 lines of assembly language (plus many tens of thou\u00adsands \nof lines of script to build up foundational lemmas about the program logic [10]). Separately, the FLINT \nproject also cre\u00adated a certi.ed system combining TAL with certi.ed garbage col\u00adlection [16]. However, \nthe TAL/GC system was less realistic than Verve: it supported only objects containing exactly two words, \nit performed only conservative collection, and did not support mul\u00adtiple threads. A combination of automated \nproof and foundational certi.cation would be valuable, to get the certainty of foundational certi.ed \ncode with the scalability of automated veri.cation. Like the Verve Nucleus, the H monad [12] exports \na set of operating system primitives usable to develop an operating system in a high-level language. \nH was used to build the House operating system [12]. However, H itself is not formally veri.ed, and relies \non a large Haskell run-time system for correctness. 9. Conclusions and Future Work Using a combination \nof typed assembly language and automated theorem proving, we have completely veri.ed the safety of Verve \nat the assembly language level, and completely veri.ed the par\u00adtial correctness of Verve s Nucleus at \nthe assembly language level. Both Verve and its veri.cation are ef.cient. So what happens when we boot \nand run Verve? Since it s veri.ed, did it run perfectly (or at least safely?) every time we ran it? We \ngive a short answer ( al\u00admost ), and a slightly longer answer composed of two anecdotes: Anecdote 1: \nThe Debugger. Initially, we admitted two pieces of unveri.ed code into Verve: the boot loader and a debugger \nstub, both written for earlier projects in C and C++. Our rationale was that neither piece would run \nany instructions in a booted, deployed system: the boot loader permanently exits after ceding control \nto the Nucleus, and the debugger stub can be stripped from deployed systems. (In the future, we could \ndevelop a veri.ably safe debugger stub, but using existing code was very appealing.) The debugger stub \nallows a remote debugger to connect to the kernel, so that we could examine the kernel memory and debug \nany inadvertent traps that might occur. Unfortunately, the debugger stub turned out to cause more bugs \nthan it .xed: it required its own memory, its own interrupt handling, and its own thread context de.nition, \nand we implemented these things wrong as often as right. Debugging the debugger stub itself was hardly \nfun, so after a while, we decided to banish the debugger stub from Verve entirely. Developing a kernel \nwithout a kernel debugger requires a bit of faith in the veri.cation process. After all, any bugs that \nsomehow slipped through the veri.cation process would be very painful to .nd with no debugger. But the \ndecision paid off: we felt far more secure about Verve s invariants without the presence of unveri.ed \ncode to undermine them. And after dropping the debugger, we encountered only one bug that broke type \nsafety or violated the Nucleus s correctness guarantees, described in the next anecdote. Anecdote 2: \nThe Linker. After dropping the debugger, we started to get used to the veri.ed Nucleus code working the \n.rst time for each new feature we implemented. When we set up the .rst inter\u00adrupt table, fault handling \nworked correctly the .rst time. When we programmed and enabled the timer, preemptive interrupts worked \ncorrectly the .rst time. In fact, after dropping the debugger stub, ev\u00aderything worked the .rst time, \nexcept when we .rst ran the garbage collector. Intriguingly, the garbage collector did run correctly \nthe .rst time when we con.gured Bartok to generate assembly lan\u00adguage code, which we assembled to an \nobject .le with the standard assembler. But the GC broke when we con.gured Bartok to gener\u00adate the object \n.le directly (even though we ran our TAL checker on the object .le): it failed to scan the stack frames \nreturn addresses correctly. To our surprise, this bug was due to a linking problem: al\u00adthough the assembler \nattached relocation information to the entries in the GC s return address table when generating object \n.les, the object .le generated directly by Bartok lacked this relocation infor\u00admation (because Bartok \nhas its own, special linking process for GC tables, which doesn t rely on the relocations). Thus, the \ntables re\u00adturn addresses were incorrect after linking and loading, causing the GC to fail. Once we .xed \nthis problem, the GC worked perfectly with both assembler-generated and Bartok-generated object .les. \n 9.1 Future work Verve is still a small system, and there are many directions for it to grow. The .rst \ncandidate is an incremental or real-time garbage collector. Such a collector would require read and/or \nwrite barri\u00aders; prior work [17] has addressed this issue for veri.ed garbage collection, but it remains \nto be seen whether this work can be im\u00adplemented ef.ciently in a realistic system. Another large area \nof research is multicore and multiprocessor machines. For Verve s TAL code, multiprocessing poses few \nprob\u00adlems; Bartok TAL is thread-safe. For the Nucleus, any shared data between processors makes veri.cation \nmuch harder. The Barrel.sh project [3] advocates one approach that would ease multiproces\u00adsor veri.cation: \nminimize sharing by treating the multiprocessor as a distributed system of cores or processors communicating \nvia message passing. Another approach would be to increase the gran\u00adularity of the Nucleus interface; \nprocessors could allocate large chunks from a centralized Nucleus memory manager, and the cen\u00adtralized \nmemory manager could use locks to minimize concurrency. At least one TAL type system, for example, can \nverify allocation from thread-local chunks [19]. A third area of research is to incorporate virtual memory \nman\u00adagement into the Nucleus and kernel (following, for example, seL4 [14]). In its full generality, \nvirtual memory would complicate the semantics of Load and Store, and would thus be a non-trivial extension \nto the system. In addition, swapping garbage collectable memory to disk would bring the disk and disk \ndriver into the Nu\u00adcleus s trusted computing base. However, some applications of vir\u00adtual memory hardware, \nsuch as sandboxing unsafe code and using IO/MMUs to protect against untrusted device interfaces, could \nbe implemented without requiring all of virtual memory s generality. A fourth area of research is to \nverify stronger properties of the TAL kernel. High-level languages like JML and Spec# could provide light-weight \nveri.cation, weaker than the Nucleus veri\u00ad.cation, but beyond standard Java/C# type safety. This might \nal\u00adlow us to prove, for example, that threads correctly enter and exit the runnable queue, and that each \nrunnable thread is scheduled promptly. Finally, we would like to improve Verve s TAL checking to be more \nfoundational (as in FLINT) and to support dynamic loading. For dynamic loading, a key question is whether \nto run the TAL checker (currently written in C#) in the kernel or port the checker to run in the Nucleus. \nThe former would be easier to implement, but the latter would keep the Nucleus independent from the kernel \nand would allow more foundational veri.cation of the checker itself. Acknowledgments We would like to \nthank Jeremy Condit, Galen Hunt, Ed Nightin\u00adgale, Don Porter, Shaz Qadeer, Rustan Leino, Juan Chen, and \nDavid Tarditi for their suggestions and assistance. References [1] G. Back, W. C. Hsieh, and J. Lepreau. \nProcesses in kaffeos: isolation, resource management, and sharing in Java. In OSDI 00: Proceedings of \nthe 4th conference on Symposium on Operating System Design &#38; Implementation, pages 23 23, Berkeley, \nCA, USA, 2000. USENIX Association. [2] M. Barnett, B.-Y. E. Chang, R. DeLine, B. Jacobs, and K. R. M. \nLeino. Boogie: A modular reusable veri.er for object-oriented programs. In Formal Methods for Components \nand Objects (FMCO), volume 4111 of Lecture Notes in Computer Science, 2006. [3] A. Baumann, P. Barham, \nP.-E. Dagand, T. Harris, R. Isaacs, S. Peter, T. Roscoe, A. Sch\u00a8upbach, and A. Singhania. The multikernel: \na new os architecture for scalable multicore systems. In SOSP 09, pages 29 44, 2009. [4] B. N. Bershad, \nS. Savage, P. Pardyak, E. G. Sirer, M. E. Fiuczynski, D. Becker, C. Chambers, and S. Eggers. Extensibility \nsafety and performance in the SPIN operating system. In SOSP 95: Proceedings of the .fteenth ACM symposium \non Operating systems principles, pages 267 283, New York, NY, USA, 1995. ACM. [5] W. R. Bevier, W. A. \nH. Jr., J. S. Moore, and W. D. Young. An approach to systems veri.cation. J. Autom. Reasoning, 5(4):411 \n428, 1989. [6] J. Chen, C. Hawblitzel, F. Perry, M. Emmi, J. Condit, D. Coetzee, and P. Pratikakis. Type-preserving \ncompilation for large-scale optimiz\u00ading object-oriented compilers. SIGPLAN Not., 43(6):183 192, 2008. \nISSN 0362-1340. doi: http://doi.acm.org/10.1145/1379022.1375604. [7] L. M. de Moura and N. Bj\u00f8rner. Z3: \nAn ef.cient SMT solver. In TACAS, pages 337 340, 2008. [8] M. F\u00a8ahndrich, M. Aiken, C. Hawblitzel, O. \nHodson, G. C. Hunt, J. R. Larus, and S. Levi. Language support for fast and reliable message\u00adbased communication \nin Singularity OS. In EuroSys, pages 177 190, 2006. [9] X. Feng, Z. Shao, Y. Dong, and Y. Guo. Certifying \nlow-level programs with hardware interrupts and preemptive threads. In PLDI, pages 170 182, 2008. [10] \nX. Feng, Z. Shao, Y. Guo, and Y. Dong. Certifying low-level programs with hardware interrupts and preemptive \nthreads. J. Autom. Reason., 42(2-4):301 347, 2009. [11] B. Ford, M. Hibler, J. Lepreau, R. McGrath, and \nP. Tullmann. Interface and execution models in the Fluke kernel. In OSDI, pages 101 115, 1999. [12] T. \nHallgren, M. P. Jones, R. Leslie, and A. P. Tolmach. A principled approach to operating system construction \nin Haskell. In ICFP, pages 116 128, 2005. [13] C. Hawblitzel and E. Petrank. Automated veri.cation of \npractical garbage collectors. In POPL, pages 441 453, 2009. [14] G. Klein, K. Elphinstone, G. Heiser, \nJ. Andronick, D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt, R. Kolanski, M. Norrish, T. Sewell, H. \nTuch, and S. Winwood. seL4: Formal veri.cation of an OS kernel. In Proc. 22nd ACM Symposium on Operating \nSystems Principles (SOSP), pages 207 220, Big Sky, MT, USA, Oct. 2009. ACM. [15] J. Liedtke, K. Elphinstone, \nS. Sch\u00a8onberg, H. H\u00a8artig, G. Heiser, N. Is\u00adlam, and T. Jaeger. Achieved ipc performance (still the foundation \nfor extensibility). In Proceedings of the 6th Workshop on Hot Topics in Operating Systems (HotOS-VI), \nCape Cod, MA, May 5 6 1997. URL http://l4ka.org/publications/. [16] C. Lin, A. McCreight, Z. Shao, Y. \nChen, and Y. Guo. Foundational typed assembly language with certi.ed garbage collection. Theoreti\u00adcal \nAspects of Software Engineering, 2007. [17] A. McCreight, Z. Shao, C. Lin, and L. Li. A general framework \nfor certifying garbage collectors and their mutators. In PLDI, pages 468 479, 2007. [18] G. Morrisett, \nD. Walker, K. Crary, and N. Glew. From System F to typed assembly language. In POPL 98: 25th ACM Symposium \non Principles of Programming Languages, pages 85 97, Jan. 1998. [19] L. Petersen, R. Harper, K. Crary, \nand F. Pfenning. A type theory for memory allocation and data layout. In POPL, pages 172 184, 2003. [20] \nD. D. Redell, Y. K. Dalal, T. R. Horsley, H. C. Lauer, W. C. Lynch, P. R. McJones, H. G. Murray, and \nS. C. Purcell. Pilot: an operating system for a personal computer. Commun. ACM, 23(2):81 92, 1980.  \n   \n\t\t\t", "proc_id": "1806596", "abstract": "<p>Typed assembly language (TAL) and Hoare logic can verify the absence of many kinds of errors in low-level code. We use TAL and Hoare logic to achieve highly automated, static verification of the safety of a new operating system called Verve. Our techniques and tools mechanically verify the safety of every assembly language instruction in the operating system, run-time system, drivers, and applications (in fact, every part of the system software except the boot loader). Verve consists of a \"Nucleus\" that provides primitive access to hardware and memory, a kernel that builds services on top of the Nucleus, and applications that run on top of the kernel. The Nucleus, written in verified assembly language, implements allocation, garbage collection, multiple stacks, interrupt handling, and device access. The kernel, written in C# and compiled to TAL, builds higher-level services, such as preemptive threads, on top of the Nucleus. A TAL checker verifies the safety of the kernel and applications. A Hoare-style verifier with an automated theorem prover verifies both the safety and correctness of the Nucleus. Verve is, to the best of our knowledge, the first operating system mechanically verified to guarantee both type and memory safety. More generally, Verve's approach demonstrates a practical way to mix high-level typed code with low-level untyped code in a verifiably safe manner.</p>", "authors": [{"name": "Jean Yang", "author_profile_id": "81464641126", "affiliation": "Massachusetts Institute of Technology, Boston, MA, USA", "person_id": "P2184519", "email_address": "", "orcid_id": ""}, {"name": "Chris Hawblitzel", "author_profile_id": "81100064145", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P2184520", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806610", "year": "2010", "article_id": "1806610", "conference": "PLDI", "title": "Safe to the last instruction: automated verification of a type-safe operating system", "url": "http://dl.acm.org/citation.cfm?id=1806610"}