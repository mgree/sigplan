{"article_publication_date": "06-05-2010", "fulltext": "\n Schism: Fragmentation-Tolerant Real-Time Garbage Collection Filip Pizlo Lukasz Ziarek Petr Maj Antony \nL. Hosking Ethan Blanton Jan Vitek , Fiji Systems Inc., Indianapolis, IN 46202. Department of Computer \nScience, Purdue University, West Lafayette, IN 47907, USA {.l,luke,elb}@.ji-systems.com {pmaj,hosking,jv}@cs.purdue.edu \nAbstract Managed languages such as Java and C# are being considered for use in hard real-time systems. \nA hurdle to their widespread adoption is the lack of garbage collection algorithms that offer predictable \nspace-and-time performance in the face of fragmen\u00adtation. We introduce SCHISM/CMR, a new concurrent and \nreal\u00adtime garbage collector that is fragmentation tolerant and guarantees time-and-space worst-case bounds \nwhile providing good through\u00adput. SCHISM/CMR combines mark-region collection of fragmented objects and \narrays (arraylets) with separate replication-copying col\u00adlection of immutable arraylet spines, so as \nto cope with external fragmentation when running in small heaps. We present an imple\u00admentation of SCHISM/CMR \nin the Fiji VM, a high-performance Java virtual machine for mission-critical systems, along with a thorough \nexperimental evaluation on a wide variety of architec\u00adtures, including server-class and embedded systems. \nThe results show that SCHISM/CMR tolerates fragmentation better than previ\u00adous schemes, with a much more \nacceptable throughput penalty. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language \nConstructs and Features dynamic storage management; D.3.4 [Programming Languages]: Processors memory \nmanagement (garbage collection); D.4.2 [Operating Sys\u00adtems]: Storage Management garbage collection; D.4.7 \n[Oper\u00adating Systems]: Organization and Design real-time systems and embedded systems; D.4.8 [Operating \nSystems]: Performance measurements General Terms Algorithms, Experimentation, Languages, Mea\u00adsurement, \nPerformance, Reliability Keywords fragmentation, real-time, mark-sweep, mark-region, replication-copying \n1. Introduction Real-time systems span application domains that range from .nan\u00adcial systems to aerospace, \neach with its own domain-speci.c re\u00adquirements and constraints. Nevertheless, they share common char\u00adacteristics. \nReal-time systems are resource-constrained and long\u00adlived; they must be extremely predictable and exhibit \ngood through\u00adput. Real-time developers emphasize knowing and limiting the worst-case execution time of \ncode to manage predictability. Pressed Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 10 June 5 10, Toronto, Ontario, Canada. Copyright c &#38;#169; \n2010 ACM 978-1-4503-0019-3/10/06. . . $10.00 to provide such strict guarantees for exponentially-increasing \ncode bases, the real-time community is steadily moving towards higher\u00adlevel programming languages. Managed \nlanguages, and in partic\u00adular Java, have already been used in a handful of high-visibility projects with \nencouraging results. Developers report improved pro\u00adductivity and appreciate the bene.ts of automatic \nmemory man\u00adagement. To gain widespread acceptance, however, managed lan\u00adguages must demonstrate predictability, \nin both time and space, that is comparable to handwritten low-level code. Memory management is one of \nthe key technical challenges. Real-time programmers are used to managing memory by hand, because they \ndo not trust off-the-shelf memory allocators to be suf\u00ad.ciently predictable and because they fear that \nmemory fragmenta\u00adtion will cause long running applications to eventually fail. To com\u00adpete, managed languages \nmust offer highly predictable garbage col\u00adlection (GC) algorithms that preserve overall application through\u00adput. \nIt is crucial that the space bounds of GC be clearly established. Given a memory budget and knowledge \nof allocation patterns, de\u00advelopers must be con.dent that suf.cient memory is available for the application \nto operate. For long running applications, GC must be able to cope with fragmentation without introducing \nsevere over\u00adheads and restrictions on the application. Moreover, though most real-time applications still \nrun on embedded uniprocessors, some are now moving towards careful use of multiprocessors. Thus, GC must \nalso permit applications to scale to multiprocessors. We argue that garbage collection can be used in \nall real-time applications, including safety-critical hard real-time systems that have stringent resource \nconstraints. To cope with the requirements of such systems, we introduce a new real-time garbage collec\u00adtion \n(RTGC) algorithm called SCHISM/CMR that tolerates exter\u00adnal fragmentation while providing good throughput \nand scalability on modern multi-cores. Table 1 illustrates the bene.ts of our al\u00ad gorithm. It is concurrent, \nmeaning that it can operate concurrently with mutator threads (i.e., the application). This is essential \nfor real\u00adtime applications, as high-priority tasks must be able to preempt everything in the system, \nincluding the garbage collector. While there are other RTGCs that operate concurrently, they typically \ndo so at the expense of other guarantees. Consider the following prop\u00aderties that one takes for granted \nwhen using a standard Java virtual machine (JVM): (i) progress for heap accesses is guaranteed (i.e., \nthey acquire no locks, and they never spin), (ii) a heap access never costs more than a handful of instructions, \n(iii) end-to-end through\u00adput is good, and (iv) fragmentation is never an issue. SCHISM/CMR supports concurrency \nwithout sacri.cing any of these properties. Prior approaches either impose an O(log(heap size)) cost \non heap accesses, require the mutator to spin on some heap accesses, fail to handle fragmentation, or \nseverely degrade overall throughput. The main contribution of this work is an approach to allocation \nthat can be thought of as embracing fragmentation by combining fragmented allocation with concurrent \nreplication. We refer to this approach as Schism and its implementation in Fiji VM as SCHIS\u00adTable 1: \nComparing features of collectors. SCHISM/CMR is the only collector that supports all the features; other \ncollectors either can not deal with fragmentation or increasing the cost of heap accesses. H is the heap \nsize.  Sun JDK Jamaica Java RTS WebSphere SRT Clover Chicken CMR SCHISM/CMR Concurrent no yes yes yes \nyes yes yes yes Heap access progress wait-free wait-free wait-free wait-free lock-free wait-free wait-free \nwait-free Heap access cost O(1) O(log(H)) O(log(H)) O(1) O(1) O(1) O(1) O(1) Throughput relative to JDK \n100% unknown 37% 62% unknown unknown 84% 65% Fragmentation tolerant yes yes yes no yes no no yes M/CMR. \nTo quantify the effect of the Schism approach on through\u00adput, we compare it with a state-of-the-art throughput-oriented \ncon\u00adcurrent mark-region (CMR) collector implemented in the same execution environment. We use two real-time \nbenchmarks in this comparison (the CDx collision detection algorithm and worst-case transaction times \nfor SPECjbb2000). We also run in a mode where all slow-paths are taken to get an upper bound on worst-case \nexe\u00adcution time. We run these benchmarks on a multi-core server-class machine and on a representative \nembedded platform: the 40MHz LEON3 SPARC architecture used by the European Space Agency and NASA. We \ncomplement the real-time benchmarks with a syn\u00adthetic benchmark designed to trigger worst-case fragmentation, \nplus the standard SPECjvm98 and SPECjbb2000 benchmarks for measuring throughput. To keep ourselves honest, \nwe calibrate our execution environment against two production real-time JVMs, and best-of-breed throughput \nJVMs. 2. Schism and Fragmentation in RTGC When fragmentation and space usage is not a concern, RTGC is \nreasonably well-understood. Unfortunately, without a solution for fragmentation, tight bounds on worst-case \nspace utilization cannot be guaranteed. But space is just as important as time: real-time developers \nmust provide bounds on both to ensure robustness. There are three broad approaches for handling fragmentation: \n1. Fragmented allocation: Allocate objects in fragments of .xed size; larger objects span multiple fragments \nwhich may not be contiguous. A standard non-moving concurrent mark-sweep collector can then be used without \nconcern for fragmentation. 2. Replication: Split the heap into semi-spaces, and have the con\u00adcurrent \ncollector copy live objects from one space to the other, even as mutator threads are operating on the \nheap. Mutator writes to the heap are captured by a write barrier that updates both the original and its \nreplica, if one exists. 3. Defragment on-demand: When necessary, activate a separate defragmentation \nphase, requiring synchronization with the mu\u00adtator. This may be combined with replication or other copy\u00ading \ncollection, but usually employs slower and more expensive techniques that try to make heap mutations \natomic and lock\u00adfree.  Fragmented allocation is attractive as it can be combined with a simple non-moving \ncollector and completely side-steps fragmenta\u00adtion. Implementations of this approach have had two main \ndraw\u00adbacks [18]. Larger objects incur signi.cantly higher overhead to access, and arrays are indexed \nusing a trie data structure which, for a 32-bit address space, may be 10 levels deep, causing every array \naccess to go through 10 indirections. The worst-case performance of this approach has not previously \nbeen comprehensively studied. Replication, as proposed by Cheng and Blelloch [6], is com\u00ad pelling, especially \nfor languages in which writes are very rare, or if writes need not be coherent. To ensure coherence of \nconcurrent writes, expensive protocols (such as locking) must be used. Like any copying collector, replication \nentails a 2\u00d7 space overhead. On-demand defragmentation was introduced in the original Metronome [3]. \nThat algorithm required stopping all mutator threads (though only brie.y) during defragmentation. Stopping \nthe world can cause a real-time thread to miss a hard deadline. We argue that high-priority tasks must \nbe able to preempt the collector whenever necessary. Previously proposed techniques for concur\u00adrent on-demand \ndefragmentation [11, 13, 14] either impede the progress of defragmentation (thus preventing space bounds) \nor im\u00adpose prohibitive throughput overheads on the mutator, up to a 5\u00d7 slowdown [14]. Defragmenting-on-demand \napproaches typically assume that fragmentation happens rarely and affects only a small fraction of the \nheap. While this is certainly true for typical pro\u00adgrams, the approach degenerates in the worst case \nto copying the majority of the heap, resulting in 2\u00d7 space overhead. 2.1 Schism: Fragmentation With \na Touch of Replication We propose combining fragmented allocation for objects and arrays with replication \nfor array meta-data. In Schism, object and array fragments are always of .xed size and never move. A \nconcurrent mark-sweep collector manages the non-moving fragments. A sepa\u00adrate replicated semi-space manages \narray meta-data. This approach exploits the best of both worlds: (i) constant-time heap access, (ii) \nconstant space-bounds for internal fragmentation with no external fragmentation, and (iii) coherence \nof heap accesses. The key insight to getting constant-time heap access is to re\u00adplace tries with arraylets. \nArraylets represent arrays as a spine (a contiguous array) containing pointers to a set of array fragments. \nWhile objects can also be represented as arraylets, the Schism ap\u00adproach follows Siebert [18] and allocates \nthese as linked lists of .xed-size fragments. This choice is motivated by the fact that most objects \nare small and are always of statically known size. Thus even with a linked representation it is possible \nto have a precise cost of any .eld access, and this cost does not vary. In Schism, a large array is split \ninto multiple arraylet fragments carrying the array payload. Arraylets have a worst-case perfor\u00admance \nthat is roughly twice that of contiguous arrays. Whereas addressing an element in a contiguous array \nsimply requires array + index \u00d7 elementSize, with a fragmented array the address computation becomes: \no.set = index * elementSize fragmentIndex = o.set / fragmentSize fragmentO.set = o.set % fragmentSize \naddress = spine[fragmentIndex] + fragmentO.set Array payload fragments have .xed size and never move. \nUsing a .xed (and small) size for array and object fragments ensures that external fragmentation is never \nan issue and internal fragmentation is bounded. However, the spines themselves vary with the size of \nthe array so they may still cause fragmentation. In Schism the spines are managed by a separate replicating \nsemi-space collector. Recall that a complication with concurrent replication is ensuring the coherence \nof writes to replicas. Luckily, this is not an issue for spines as their contents (pointers to non-moving \narray fragments) are never updated. This allows us to use wait-free barriers for reading and writing \nthe spine. Allocation of spines can be made lock-free. Moreover, the space overhead of copying is reduced \nsince the copy reserve is only needed for the spines.  Schism yields a simple algorithm composed from \nwell-under\u00adstood building blocks: spine-indexed arraylets, fragmented alloca\u00adtion, concurrent mark-sweep \ncollection of .xed-size fragments, and concurrent replicating semi-space collection of spines. The key \nin\u00adsight is simply that the array spines can be copied concurrently without sacri.cing mutator performance \nor coherence. Because of its simplicity, Schism can be implemented in a variety of ways all that is \nneeded is a concurrent semi-space framework for the im\u00admutable spines, and a concurrent mark-sweep framework \nfor ob\u00adject and array fragments, both of which are well-understood. In this study we implement Schism \nfor the existing concurrent mark\u00adregion collector in Fiji VM [15, 16]. In this scheme, fragmented allocation \nis only used when fragmentation is observed allowing for hard bounds with good throughput. 3. The Fiji \nVM Experimental Platform Fiji VM is a new JVM that aims to provide developers with an automated tool \nfor converting high-level, memory safe Java appli\u00adcations into small, ef.cient, and predictable executables \nfor a wide range of embedded devices. This section introduces the character\u00adistics of Fiji VM that are \nrelevant to the implementation of SCHIS-M/CMR. Fiji VM is an ahead-of-time compiler that transforms Java \nbyte\u00adcode into fast ANSI C code. It runs on any platform that has a C compiler, threads, and locks. It \ndoes not require a memory management unit since null-checks and safepoints do not rely on protection-based \nmechanisms. Supported platforms include Linux, Darwin, NetBSD, RTEMS, x86, PowerPC, ERC32, LEON2, and \nLEON3.Both32-bitand64-bitarchitecturesaresupported; SCHIS-M/CMR does run in 64-bit mode though only 32-bit \nmode is exam\u00adined in this paper. A noteworthy feature of Fiji VM is its ability to run on very restricted \nreal-time embedded micro-kernels such as the Real Time Executive for Multiprocessor Systems (RTEMS).1 \nFiji VM supports priority-aware locking and real-time priorities for threads, and takes care not to use \nany unpredictable operating system facilities, like OS-provided dynamic memory allocation, except inside \nlibrary calls (e.g., creating a direct NIO byte buffer requires calling some variant of malloc). Additionally, \nFiji VM employs a variety of techniques [15, 16] for ensuring that the generated C code obeys Java semantics, \nand so that accurate stack maps can be generated for GC stack scanning. Fiji VM was designed speci.cally \nto support RTGC. At present, Fiji VM has no stop-the-world GC; it does not even have a stop-the\u00adworld \ncapability. Instead we offer the following facilities to make the implementation of RTGCs simple: Safepoints: \nA safepoint is a lightweight check to see if a thread should perform any task on behalf of the collector. \nCalls to na\u00adtive methods are effective safepoints, in that we mark the thread as running without JVM-access. \nThis allows the col\u00adlector to make changes to the thread s Java state without syn\u00adchronizing with the \nthread. The compiler ensures that there is a worst-case bound on the time between safepoints. Ragged \nsafepoints: A ragged safepoint is an asynchronous re\u00adquest to all threads to perform an action exactly \nonce. Un\u00adlike a stop-the-world barrier that stops all mutator threads, a ragged safepoint does not block \nany threads. Threads simply acknowledge having performed the desired action at the safe\u00ad 1 http://www.rtems.org \npoint. Priority-boosting is used to ensure that threads perform the requested action in a timely fashion. \nRagged safepoints are essential for implementing on-the-.y concurrent collectors. The safepoint functionality \nis built around the observation that a high-priority task that always preempts the collector and only \nyields to it explicitly can have its roots scanned in a non-blocking fashion [17]. The result is that \nwhen running on a real-time operat\u00ad ing system, the collector infrastructure never pauses the mutator \nfor root scanning. Indeed, the only pauses that we have are: slow-path executions of barriers and allocations, \nand synchronous collections in the event that the collector is outpaced by the mutator. Whether the former \nis actually a pause is debatable, as it is only a call to a procedure that takes slightly longer than \nthe inlined fast-path. How\u00adever, we count this as a pause because it may disrupt the timeliness of a \nreal-time task. 4. The Schism Concurrent Mark-Region RTGC We now describe SCHISM/CMR, our implementation \nof the Schism approach on top of a concurrent mark-region (CMR) garbage collector. A CMR collector extends \nthe mark-region collector of Blackburn and McKinley [4] to be concurrent (mutator and col\u00ad lector threads \ninterleave heap accesses) and on-the-.y (no stop-the\u00adworld phase). We start with an overview of the base \nCMR collector. 4.1 Concurrent Mark-Region (CMR) GC Mark-region garbage collectors like Immix [4] partition \nthe heap into .xed-size regions that form the units of space management for a traditional mark-sweep \ngarbage collector. The key insight of mark-region collectors is to allocate and reclaim memory in contiguous \nregions, at a coarse page granularity when possible, and otherwise at the level of .ne-grained lines. \nObjects are allocated within and spanning lines. Marking notes the live lines holding live objects, and \nsweeping proceeds to discover entirely free pages, as well as the free lines within pages. Unlike Immix, \nCMR does not perform opportunistic defragmentation. CMR implements Immix s mark-region approach as follows. \nHybrid slack-based, concurrent, and time-based scheduling. The CMR collector can run concurrently on \na separate processor core so as to minimize interference with mutator threads. In slack\u00adbased mode the \ncollector runs at a priority that is lower than the mutator s critical real-time threads so it never \npreempts them. On uniprocessor systems, CMR s scheduling is identical to the slack\u00adbased Minuteman [10]; \nas such all of the schedulability tests and analytical results from Minuteman directly apply. CMR has \na Java API for changing the priority of the collector thread allowing it to be run in a time-based mode \nlike the Metronome. However, for the purposes of this study we run CMR in a purely slack-based mode. \nHybrid bump-pointer, best-.t, and .rst-.t allocation. The CMR collector allocates objects in bump-pointer \nfashion, similarly to Immix [4]. The sweep phase notes lines of contiguous free bytes within partially-occupied \npages, as well as pages that are com\u00adpletely free. An allocation request .nds the .rst page with a free \nline big enough to satisfy the request (.rst-.t), and then chooses the smallest line within that page \nfrom which to allocate (best\u00ad.t). Bump-pointer allocation proceeds within the last line and page from \nwhich allocation occurred, until a new line is needed. Bump\u00adpointer allocation is used most of the time, \ngiven suf.cient memory. In practice, most free memory is in the form of free pages, not free lines, but \nfree line allocation is preferred free pages are used only when free lines are exhausted. The base CMR \ncollector is concurrent, mostly lock-free, on-the\u00ad.y, exhibits throughput that is comparable to production \ngenera\u00adtional collectors, and has very short pauses. In fact, the only pauses are due to stack scanning, \nwhich affects only low-priority threads. CMR s main limitation is its lack of a strategy for coping with \nfrag\u00admentation, since it does not perform opportunistic defragmentation.  4.2 Adding Schism to CMR \nSCHISM/CMR applies the fragmented-allocation Schism approach to CMR. Both the collector, and the part \nof the compiler that deals with representation of objects (the object model) were modi.ed to cope with \nfragmented allocation. The heap is split into two spaces: a CMR space and a pair of spine semi-spaces. \nThe semi-spaces are 30% of the size of the CMR space. The allocator can allocate objects either contiguously \n(unfragmented) or fragmented into 32\u00adbyte fragments. If opportunistic contiguous array allocation fails, \na 32-byte array sentinel fragment is allocated in the CMR space. The sentinel holds the array s object \nheader and contains a pointer to the spine, which is allocated in the currently active spine semi-space. \nThe spine is populated with pointers to 32-byte arraylet fragments in the CMR space. Every collection \ncycle completely evacuates the old semi-space, and populates the other with survivors. This process is \nentirely lock-free because the semi-space holds only array spines, which are immutable. Array accesses \nhave a guarded fast path that assumes that the array is contiguous, and a slow path for fragmented arrays \nthat indirects via the spine to access the appropriate arraylet, incurring one indirection to get to \nthe spine and one more indirection to get to the payload. All non-array object accesses require n hops, \nwhere n is the offset of the .eld divided by 32 bytes. As observed in [18], very few objects are larger \nthan 64 bytes. It would be easy to convert the collector to use arraylets for large non-array objects, \nbut we have not done this yet. The following sections give a more detailed look inside SCHIS-M/CMR. Section \n4.3 discusses our object model. Section 4.4 de\u00ad scribes our replicating semi-space framework along with \nthe barrier used. Opportunistic optimizations and the associated con.guration parameters are shown in \nSection 4.5. SCHISM/CMR provides hard bounds on space usage; an overview of those bounds is given in \nSection 4.6 with further details in Appendix A. Section 5 gives a qualitative comparison to other RTGCs. \n 4.3 Fragmented Allocation The structure of objects in SCHISM/CMR is shown in Figure 1. The .rst object \nfragment has three header words: a fragmenta\u00adtion header that either points to the next fragment of the \nobject (Figure 1(a)) or to the arraylet spine (Figure 1(c) and 1(d)), and a GC word used for marking \nand a type header that holds both type and locking information. Arrays have an additional pseudo-length \nheader holding either the actual array length (for contiguous ar\u00adrays) or zero. Array accesses .rst perform \nan array bounds check on the pseudo-length; it will always fail for fragmented arrays caus\u00ading the slow \npath to be taken. For normal objects, subsequent frag\u00adments only have a fragmentation header; the rest \nof the space is devoted to the payload. For arrays, the .rst fragment (the sentinel) may point to a spine \nor may have the entire array inlined (if it is small enough to .t in the remaining 16 bytes or if opportunistic \ncontiguous array allocation succeeded). The inline payload case is shown in Figure 1(b). The spine itself \nmay live inside the sentinel if it can .t in 16 bytes. In that case the spine uses one word for the length \nand the remaining 12 bytes for pointers to payload frag\u00adments (Figure 1(c)). If the array payload requires \nmore than three fragments (i.e., is more than 96 bytes) then the spine will be al\u00adlocated in the spine \nspace (Figure 1(d)). In this case the sentinel has just four words in it and the remaining 16 bytes are \nwasted to achieve 32-byte alignment. An out-of-line spine allocated in the spine space requires a two \nword header: a forwarding pointer to support replication and the length. (a) A 2-fragment object. The \n.rst fragment has three header words: a fragmentation header, a GC header, and a type header. (b) An \narray with = 16-byte payload. The sentinel fragment has four header words: fragmentation header, GC header, \ntype header, and pseudo-length. The payload is inlined. (c) An array with a (17,96)-byte payload. The \nsentinel fragment has .ve header words: fragmentation header, GC header, type header, pseudo\u00adlength 0 \nto indicate fragmentation, and the length. The remainder of the sentinel contains an inlined spine. \n(d) An array with a payload > 96 bytes. The sentinel has four header words: fragmentation header, GC \nheader, type header, and pseudo-length. The remainder of the sentinel is unused. The spine has a two-word \nheader: the length and a forwarding pointer at negative offsets. The payloads have no headers.   Figure \n1: Fragmented allocation in SCHISM/CMR.  4.4 Updating Pointers to Arraylet Spines The SCHISM/CMR semi-space \nspine collector is similar to earlier replicating collectors [6, 12] with one major restriction: we do \nnot have a strong from-space invariant. These replicating collectors preserve the invariant that pointers \ninto from-space all originate from from-space. The mutator operates entirely in from-space un\u00adtil the \n.ip occurs at the end of collection when the to-space and from-space roles are reversed. They never modify \nthe from-space; they simply discard it atomically in a global stop-the-world .ip phase. This has two \nattractive properties. First, a collection cycle requires only one trace of the heap. Second, the mutator \nnever sees a to-space object before that object has been fully copied. This ap\u00adproach is dif.cult to \nincorporate into SCHISM/CMR, since the non-movingCMRspacemayhavespinepointers.Evenif SCHISM/CMR employed \na global stop-the-world .ip, we would still require some mechanism for ensuring that the CMR space s \nspine pointers were updated only after copying was .nished. We considered a num\u00adber of solutions to this \nproblem. Performing a second trace of the CMR space after copying would solve the problem, but we feared \nthis would increase collection times too much. We also considered doubling the size of the semi-spaces \nand alternating between copy\u00ading and .xup (where pointers in CMR space are .ipped to refer to the to-space). \nUnfortunately, this solution has the potential to in\u00adcrease space overhead and .oating garbage. In the \nend, we chose to add an extra indirection on arraylet accesses by introducing an arraylet sentinel fragment \nin the CMR space as shown in Figure 1. This fragment holds all of the array s meta-data as well as a \npointer to the spine. The mutator never holds pointers to spines directly. The only objects in the CMR \nspace that hold pointers to spines are the arraylet sentinels themselves. This leads to a simple, on-the\u00ad.y, \nand concurrent copying algorithm that has no global stop-the\u00adworld phase. Only one heap trace is required \nper collection cycle. Copying and .xup are performed in a separate phase, which only considers live sentinels. \nThe steps of the algorithm are as follows.  1. Mutator threads switch to allocating in to-space before \ntracing starts. 2. The CMR trace loop allocates to-space spines but defers copy\u00ading. When a sentinel \nis encountered, a spine is allocated and zeroed in to-space. Copying is deferred by placing the sentinel \non a live sentinel list. A forwarding pointer is installed in the from-space spine. 3. After tracing \n.nishes, mutator threads perform a ragged safe\u00adpoint to acknowledge the installation of forwarding pointers \nin from-space spines. On-going array allocations will start writing arraylet pointers to both from-and \nto-space spines. 4. Spines are copied. The collector processes the live sentinel list built during the \ntracing phase. The copy algorithm ensures that it does not corrupt spines that are being initialized. \nTo do this, it relies on properties of the write barrier used for array initialization:  oldSpine[index] \n= fragmentPointer STORE FENCE() oldSpine.forward[index] = fragmentPointer This initializes the from-space \nspine .rst. The spine copy loop exploits this assumption: oldSpine = sentinel.spine newSpine = oldSpine.forward \nfor (i = 0;i < spineLength ; ++i) if (oldSpine[i] != null) newSpine[i] = oldSpine[i] sentinel.spine \n= newSpine The from-space spine can be null or have a value. In the latter case, it will never change \nagain. If an entry is null, it has not yet been initialized by the mutator; we also know that the mutator \nhas yet to store anything to the to-space copy, thanks to the use of the store fence. The mutator is \nguaranteed to initialize the entry at some point in the future, and the replicating barrier en\u00adsures \nthat both the from-space and to-space will be initialized. If the entry has a value, the mutator may \nnot have stored the same value to the to-space, but when it does the value it stores will be identical. \nThus, copying the value into to-space is both neces\u00adsary (if the initialization of this entry happened \nin the past) and harmless (since at worst we will write the same value that the mutator writes). After \ncopying .nishes, the sentinel is updated to point to the to-space. 5. The mutator threads perform another \nragged safepoint to ac\u00adknowledge that sentinels have been updated to to-space, so they no longer access \nthe from-space. 6. The from-space is zeroed.   4.5 Predictability Levels Contiguous objects lead to \nbetter performance than fragmented ones. Of course, we have designed SCHISM/CMR to have good performance \neven if all objects are fragmented but even in a real\u00adtime system an opportunistic throughput boost \ncan be a good thing. Thus, SCHISM/CMR has multiple predictability levels which vary the heuristics for \nopportunistic contiguous allocation. Predictability level C: optimize for throughput. The collector tries \nto allocate objects contiguously, reverting to fragmented allo\u00adcation if the former fails. Field access \nbarriers do not exploit conti\u00adguity; they always perform n hops to get to the nth object fragment. Thus, \ncontiguity of plain objects is used solely for accelerating al\u00adlocation and locality. Array access barriers \nare branch-predicted in favor of contiguous access, but fragmented access is still inlined to ensure \ngood worst-case performance. Predictability level A: optimize for predictability. Arrays are al\u00adways \nallocated in 32-byte fragments. An array will only be con\u00adtiguous if its payload is 16 bytes or smaller. \nObjects are allocated opportunistically contiguous as in level C. Array access barriers are branch-predicted \nin favor of fragmented access. Predictability level CW: simulate worst-case. This is the worst\u00adcase execution \ntime mode. It behaves as in level C, except that all fast paths are poisoned. They execute but always \nfail causing the mutator to exercise the out of line slow-paths. CW poisons array accesses, GC write \nbarriers, and allocations. This mode helps users estimate how slowly the program would run if all of \nthe collector s heuristics fail. Note however that CW does not trigger worst-case space usage as some \ncontiguous arrays may require more memory than fragmented ones.  4.6 Space Bounds: Predictability Level \nA We now consider bounds for the memory used by SCHISM/CMR. The collector ensures that no object will \nuse more memory than speci.ed by these formulas regardless of heap structure or level of fragmentation. \nWe focus on Level A; the precise formulas as well as a discussion of level C appears in the appendix. \nFor simplicity, we assume a 32-bit architecture with a 4096-byte page size. Similar formulas can be derived \nfor 64-bit architectures and different page sizes. Bounding GC space usage is important. Many real-time \nsystems are certi.ed empirically but the qualitative justi.cation of those techniques relies on analytical \nresults. Because space usage is com\u00adpletely deterministic in predictability level A, we suspect that \nin many settings the actual analysis of the space usage of a program will be done empirically so long \nas level A is used for both analysis and deployment. Regardless of predictability level the formulas \ncan be used for an analytical proof that the collector is correctly con\u00ad.gured, since the analyses used \nfor proving the schedulability of a time-based or slack-based collector will need to know the precise \nnumber of bytes used by each object [10]. We provide separate formulas for plain objects and arrays. \nWe account for the worst case assuming an adversarial program. All of the collector meta-data and space \nto hold spines is accounted for. Thus, it is possible to bound the memory footprint of the entire JVM \nby adding the size of the .text and .data segments and an OS\u00adspeci.c constant for each thread to the \nresults from this section. The equations in the appendix give us the following formula for computing \nthe size in bytes of a plain object with n .elds: 1.3104 \u00d7 321(2 + n)/7l (1) This is the exact amount \nof memory used by the JVM for that object, under the simplifying assumption that .elds are homoge\u00adneously \n4-bytes long (the appendix gives the general case that accounts for alignment). The 1.3104 coef.cient \naccounts for the spine-space reserve and page table meta-data. For an array with a p-byte payload, the \nformula is if p = 16 then 1.3104 \u00d7 32 else 1.3104 \u00d7 (32 + 32 1p/32l) (2) This accounts for the different \nallocation modes of arrays and is exact at level A.   (b) Objects: SCHISM/CMR converges at an overhead \nof 1.5\u00d7 TMC and peaks at 3.5\u00d7 for small objects. Figure 2: Analytical Overheads. Memory overhead of \nSCHIS-M/CMR for data of varying size compared to theoretical mark-and\u00adcompact and semi-space collectors \n(relative to TMC). Analytical Comparison. To illustrate the effect of space over\u00adheads, we analytically \ncompare SCHISM/CMR s guaranteed worst\u00adcase to that of two theoretical baseline collectors: TMC, a three\u00adphase \nstop-the-world mark-compact framework that requires no ex\u00adternal meta-data, packs all object .elds ignoring \nalignment, uses two header words for objects and three for arrays, and maintains 4\u00adbyte alignment for \nobjects;2 and TSS, a stop-the-world semi-space framework that uses an identical object model to TMC but \nrequires twice as much space due to its copy reserve. The TMC and TSS object layouts are similar to what \nis found in Jikes RVM and Sun HotSpot. Thus, when meta-data overheads are factored in we ex\u00adpect those \nsystems to use slightly more memory than TMC but con\u00adsiderably less than TSS. The exact overheads of \nobjects and arrays are shown in Figure 2; the plot is relative to the TMC size and is speci.c to level \nA. For arrays, the payload size is set to range be\u00adtween 1 and 1000 bytes. For objects, the number of \n.elds ranges between 1 and 100. The graphs show that SCHISM/CMR s over\u00adheads converge to roughly 1.4\u00d7 \nTMC for large arrays, and 1.5\u00d7 for large objects. The overheads peak at roughly 2.6\u00d7 for small arrays \nand 3.5\u00d7 for objects that have only one .eld. 2 For comparison, the space requirements of TMC for an \nobject with n 4\u00adbyte .elds is 8 + 4n, and for an array with a p-byte payload TMC requires 12 + 41p/4l \nbytes. 5. State of the Art in RTGC Commercially available virtual machines with real-time garbage collectors \ninclude the IBM WebSphere Realtime [1, 2], Sun Java RTS [5], Aicas Jamaica [18], Aonix s PERC, and the \nAzul JVM. There are also a number of academic RTGC projects including the original Jikes RVM-based uniprocessor \nversion of Metronome [3], a suite of RTGCs for .NET [13, 14], Minuteman [10], Sapphire [8], and a parallel \nreal-time collector for ML [6]. RTGCs differ in two main regards: .rst, how collection work is scheduled, \nand second, what object model is used to deal with fragmentation. 5.1 Scheduling Strategies RTGCs use \ntwo different scheduling strategies: either the user chooses the collector s schedule with time-based \nor slack-based scheduling, or it automatically adapts to the allocation rate with work-based scheduling. \nSCHISM/CMR, WebSphere SRT, and Java RTS use the former while Jamaica uses the latter. Time-based and \nslack-based scheduling. Time-based schedul\u00ading, pioneered in [3], runs the collector periodically for \nshort tightly-bounded increments. This yields uniform mutator utiliza\u00adtion and is easy to understand \nand con.gure. However, it is not ideal for low-latency hard real-time tasks for such tasks it is better \nto avoid all collector interference. This is achieved by slack-based scheduling where the collector runs \nat a .xed priority that is lower than that of real-time tasks, which can always preempt the collec\u00adtor. \nSlack-based scheduling by itself will not work in every appli\u00adcation: if real-time tasks run for too \nlong the collector will starve. Neither scheme is ideal, so most JVMs support both approaches. Websphere \nincludes an innovative scheduling scheme [2], which invokes the time-based collector only when the slack-based \none is starved. Java RTS and SCHISM/CMR are slack-based by default but provide APIs for controlling the \ncollector thread directly, which allows for time-based scheduling to be enabled if needed. These schemes \nmay fail if the mutator outpaces the collector by allocating too much too quickly. In this case the RTGC \nmay have to suspend allocating threads. Ensuring that this does not happen is up to the developer, and \nrequires computing the worst-case (i.e., highest) allocation rate, worst-case (i.e., lowest) collection \nrate, and object lifetimes. Given this information it is possible to determine the optimal heap size \nand mutator utilization target (for time-based collectors) or heap size and thread priority (for slack-based \ncollec\u00adtors) [10]. Work-based scheduling. A work-based collector will perform an increment of collection \nwork on every allocation [18]. This scheme can be made to provide linear-time allocation, though with \na larger constant factor than other schemes. Thus, work-based scheduling punishes threads that allocate \na lot but rewards those that allo\u00adcate little, and can be thought of as precisely matching the col\u00adlection \nrate to the allocation rate. The main advantage of work\u00adbased scheduling is that it is easier to con.gure \nthe collector: only a heap size needs to be picked. The collector can then perform ex\u00adactly enough work \non each allocation to ensure that a full collec\u00adtion cycle completes before memory is exhausted. However, \nthis scheme requires that collector work can be uniformly partitioned into very short bursts, and that \nthese bursts can be ef.ciently dis\u00adtributed among all threads in the system. Concurrent collection. A \nconcurrent collector that never of.oads collector work to application threads can be used in a real-time \nen\u00advironment without any modi.cations, provided that spare CPUs are available. This is the primary mechanism \nused in the Azul JVM [7]. The other RTGCs all support concurrent scheduling and will use that as their \nprimary scheduling facility if unused CPU cores are available. As with time-based scheduling, a concurrent \nschedule Real-time Java Virtual Machines:  WebSphere SRT -Xgcpolicy:metronome (build 2.5, J2RE 1.6.0 \nIBM J9 2.5 Linux x86-32 jvmxi3260srt-20081016 24573 (JIT and AOT enabled)) Java RTS Java 2 Runtime Environment, \nStandard Edition (build 1.5.0 16 Java-RTS-2.1 fcs-b11 RTSJ-1.0.2) Java Real-Time System HotSpot Client \n(build 1.5.0 16-b11, mixed mode) Fiji VM 0.0.3-r1206f3ecc7c2 Desktop Java Virtual Machines: IBM J9 \nIBM J9 (build 2.4, J2RE 1.6.0 IBM J9 2.4 Linux x86-32 jvmxi3260-20080816 22093 (JIT and AOT enabled) \nSun JDK Java SE Runtime Environment (build 1.6.0 12-b04) Java HotSpot Server (build 11.2-b01, mixed mode) \n All JVMs were run with the options -Xmx50M, -Xms50M unless otherwise indicated. Platforms: Sharpay Intel \nZeon CPU X5460, 3.16Ghz, 8-core, 8GB of RAM. Ubuntu 7.10 Linux kernel 2.6.22-14-server. LEON3 Gaisler \nGR-XC3S-1500 / Xilinx Spartan3-1500 FPGA .ashed with a LEON3 con.guration running at 40Mhz, 8MB .ash \nPROM and 64MB of PC133 SDRAM split into two 32MB banks. RTEMS 4.9.2 as the operating system. Table 2: \nExperimental Setup. requires knowing the collection rate, allocation rate, and object life\u00adtimes, as \nwell as a schedulability test, to choose a con.guration that does not result in the collector being outpaced. \n 5.2 Object Model and Fragmentation Except for Azul, all other real-time garbage collectors may frag\u00adment \nobjects. WebSphere SRT fragments large arrays using ar\u00adraylets. Java RTS and Jamaica may fragment any \nobject; non-array objects may become linked lists and arrays become tries. The origi\u00adnal Metronome [3] \nused on-demand defragmentation in addition to arraylets to handle fragmentation. Even without concurrent \ncopying, WebSphere SRT will tend to perform well for most programs thanks to its use of segregated free\u00adlist \nallocation and arraylets for large arrays however, it is not completely fragmentation-tolerant and thus \ncannot bound space us\u00adage as aggressively as SCHISM/CMR. Like SCHISM/CMR, Jamaica and Java RTS are fragmentation-tolerant \nbut have a worst-case ar\u00adray access cost of O(log(H)). Azul copies objects concurrently and achieves \ncomplete fragmentation tolerance; it can do so ef\u00ad.ciently thanks to specialized hardware. Concurrent \nobject copy\u00ading requires a copy reserve. SCHISM/CMR needs only a very small copy reserve but has large \n(though predictable) per-object over\u00adheads, while Azul may in the worst case need a 100% copy re\u00adserve \nbut has extremely compact objects (to our knowledge, it is the only JVM that uses one-word headers). \nOverall, we expect that Azul is more space-ef.cient than SCHISM/CMR for small objects and slightly less \nspace-ef.cient for large ones. It is the only RTGC that has demonstrated scalability to hundreds of cores. \nThere has been extensive work in the literature on real-time garbage collection. The Cheng and Blelloch \n[6] collector was one of the .rst to offer hard real-time bounds on multi-processors. SCHISM/CMR s use \nof replication is largely inspired from that work s emphasis on immutability. One way to view SCHISM/CMR \nis that it achieves immutability in Java by boxing the payload and storing it in a non-moving space. \nSapphire [8] is another at\u00ad tempt to bring replication to Java, though at the cost of some object access \ncoherence. Unlike SCHISM/CMR, both Cheng-Blelloch and Sapphire may have to resort to locking for some \nobject accesses if both coherence and mutability are required. Minuteman [10] is an open-source uniprocessor \nimplementation of the Metronome segre\u00adgated free-list mark-sweep collector complete with on-demand de\u00adfragmentation. \nIt can be made to use either pure time-based or pure slack-based scheduling allowing the two styles to \nbe compared di\u00adrectly. Stopless, Chicken, and Clover are real-time garbage collec\u00adtors for .NET [13, \n14]. These collectors enable concurrent copying of objects on multiprocessors, though with higher worst-case \ncosts than SCHISM/CMR. 6. Evaluation This section aims to demonstrate that SCHISM/CMR can handle fragmentation \n(Section 6.1), has competitive throughput (Sec\u00adtion 6.2), delivers on predictability (Section 6.3), and \nis able to scale (Section 6.4). To demonstrate these properties in a convinc\u00ad ing manner, we have selected \na number of benchmark programs, architectures and operating systems, and Java implementations. This broad \nrange of experiment yields the most thorough compari\u00adson of real-time Java virtual machines to date. \nOur experimental setup is summarized in Table 2. We evalu\u00ad ate three real-time virtual machine con.gurations: \nIBM WebSphere SRT, Sun Java RTS, and Fiji VM. WebSphere SRT is IBM s soft real-time product based on \nthe latest variant of the Metronome. The hard real-time version of WebSphere (WRT) adds support for scoped \nmemory and is usually substantially slower than SRT. Java RTS is a production real-time JVM with a memory \nmanage\u00adment strategy that bears some similarities to Fiji VM. It uses the HotSpot client compiler. For \nFiji VM, we evaluate four con.g\u00adurations: CMR, the base concurrent mark-region algorithm; and three predictability \nlevels of SCHISM/CMR (C=highest throughput, A=most predictable, CW=worst-case). For the purpose of estab\u00adlishing \na baseline on throughput, we also evaluate two JVMs that are optimized for throughput rather than for \npredictability. These are IBM s J9 and Sun s JDK 1.6 (HotSpot Server). We selected two platforms for \nour measurements. The .rst (Sharpay) is a powerful server machine that we use to explore the throughput \nof SCHISM/CMR on a modern multi-core architecture. The second platform is a LEON3 with the RTEMS hard-real-time \noperating system. This single-core platform is more representative of current embedded systems. In fact, \nit was selected because it is used by NASA and the European Space Agency in aerospace applications. \n6.1 Fragmentation We evaluate the ability of various GCs to deal with fragmentation using a synthetic \nbenchmark (Fragger). Fragger maximizes frag\u00admentation by allocating small arrays until memory is exhausted, \nthen freeing every other array. Fragger then tries to allocate as many large arrays as possible. The \nbenchmark is run three times for four sizes of arrays (small arrays range between 200 bytes and 88KB, \nlarge from 600 to 168KB). GCs that are able to deal with frag\u00admentation, either through relocation or \nfragmented allocation, can allocate all of the large arrays. Table 3 reports the number of arrays successfully \nallocated and the approximate free memory utilization. Approximate free mem\u00adory utilization is a measure \nof fragmentation tolerance; higher num\u00adbers are better. This column does not account for object layout \nor any meta-data overheads; thus getting exactly 100% is unlikely. As Table 3: Fragger results. Percentage \nof memory different JVMs are able to reuse when the heap becomes fragmented due to either re\u00adlocation \nor fragmented allocation. SCHISM/CMR performs as well as JDK. Java RTS performs almost as well, but WebSphere \nSRT performs poorly except for large arrays.   Table 4: Analytical vs. Observed. Comparing analytical \nresults for fragger using memory usage formulas and the empirical results for SCHISM/CMR level A. They \ncorrespond exactly: SCHISM/CMR level A can never allocate more or less arrays than predicted. CMR is \nnon-compacting, it will not be able to handle fragmenta\u00adtion at all. At the opposite end of the spectrum \nJDK behaves well as it has a GC that is free to stop the world and relocate objects at will. The different \npredictability levels of SCHISM/CMR perfectly handle fragmentation. Level C has slightly fewer space \noverheads due to its ability to allocate contiguously in some cases. Java RTS is close to SCHISM/CMR \nwhile WebSphere SRT performs poorly except for large arrays, for which it is able to use arraylets. Table4comparestheanalyticalmemoryusagemodelof \nSCHIS-M/CMR level A from Section 4.6 to the observed values. The num\u00ad bers match up exactly, con.rming \nthe tightness of the space bounds. This comparison further illustrates the effect shown in Figure 2: \nlarge arrays have lower per-element overheads than smaller ones; this is the reason why switching from \na 200 byte payload to a 600 byte one results in 120% utilization. Figure 3 shows the average access time \nof random array ele\u00ad ments. The graph has solid lines for accesses before fragmentation occurs and dashed \nlines for accesses after allocating in fragmented memory. This is an indication of execution time costs \nincurred by Figure 3: Performance of fragmented array accesses. Solid lines depict access cost prior \nto large array allocation and dotted lines after. Since JDK does not fragment, performance is identical. \nJava RTS, SCHISM/CMR, and WebSphere SRT all fragment arrays. WebSphere SRT performs the best out of the \nreal-time collectors, while Java RTS (which uses tries) has the most extreme worst-case. fragmentation. \nWe can observe that JDK, which never fragments objects but can defragment the heap through stop-the-world \nobject copying, has consistently faster access times that the other JVMs. Java RTS has good performance \nbefore fragmentation, but exhibits the worst performance once memory is fragmented due to its use of \ntries instead of arraylets. Java RTS improves average case ac\u00adcess times through caching [5], but Fragger \nrandomizes accesses to force worst-case behavior. WebSphere SRT performs just as well with fragmentation \nas without. SCHISM/CMR at all predictability levels provides reasonable performance but is somewhat more \nef.\u00adcient when arrays are not fragmented.  6.2 Throughput To evaluate the impact of SCHISM/CMR on throughput \nwe com\u00adpare performance of the different con.gurations on the SPECjvm98 benchmark.3 We run SPECjvm98 \nexperiments as follows. We in\u00advoke each JVM three times, running the given benchmark for seven iterations, \nand averaging the last three iterations. Those averages are again averaged. This gives a four-iteration \nwarm-up as neces\u00adsary for the JIT-based JVMs to reach steady state. We note that for individual benchmarks \nthe execution time differences between the non-real-time JVMs (JDK and J9) and any of the other JVMs \nare statistically signi.cant and almost always quite large. For brevity, our throughput overview focuses \non a geometric mean comparison that takes into account all SPEC benchmarks at once. We are not aware \nof a statistically sound formulation of con.dence intervals for the geometric mean over averages of non-independent \nbench\u00admarks; thus we avoid using con.dence intervals. The differences between con.gurations are very \npronounced (typically exceeding 10%) and easy to reproduce. Figure 4 shows a summary of SPECjvm98 performance. \nThe two desktop JVMs are the fastest (JDK and J9). SCHISM/CMR level C runs at 65% of JDK s throughput. \nSCHISM/CMR level C appears to be faster than the other two commercial real-time JVMs. The .gure also \nshows that there is approximately a 20% difference in performance between level C and level CW, which \nforces all fast 3 While there are benchmarks that are more revealing than SPECjvm98, it would be dif.cult \nto run them on an embedded JVM. Fiji VM s library is tailored for JavaME applications and lacks some \nof the class libraries needed by larger benchmark suites. In fact, running SPECjvm98 itself requires \nquite a few dedicated extensions.  Figure 4: SPECjvm98 Throughput. Fiji VM with CMR runs at roughly \n84% throughput relative to JDK, and SCHISM/CMR at 65%. Both appear to be faster than other real-time \nJava products.    paths to fail. It should be noted that there are reasons to take these numbers with \na grain of salt. For instance, all the JVMs were given the same heap size (50MB), but it is unclear how \nthat number is used. Some JVMs account for their meta-data separately from the heap. Fiji VM accounts \nfor all of the meta-data as part of the heap size. Moreover, the JVMs have very different compilation \nstrategies and optimizations. Our argument here is simply that the performance of SCHISM/CMR is competitive. \nFigure 5 focuses on Fiji VM and gives time-memory curves. The curves show the execution time of benchmark \nprograms for various heap sizes. The x-axis in these graphs represents multiples of the minimum heap \nsize needed to run the benchmark in any of the Fiji VM collectors. If a curve does not reach 1, it means \nthat at least one run of the benchmark failed at that heap size multiple. Figure 5(a) gives the geometric \nmean for the entire SPECjvm98 suite. The results clearly show that SCHISM/CMR can run in less memory \nthan CMR (which starts at a 3.3 multiple), illustrating that fragmentation matters even in SPECjvm98. \nTo better explore the effects of the different collectors, we show details for two benchmarks with particularly \nextreme behavior: 202 jess (Figure 5(a)) and 209 db (Figure 5(b)). The conclusion that can be reached \nfrom these outliers is that some benchmarks run better in CMR, while others run better in SCHISM/CMR. \nFor exam\u00adple 202 jess and 213 javac run in smaller heap sizes in SCHIS-M/CMR because they can fragment \na small heap quite rapidly in a non-moving collector. While SCHISM/CMR can often run in a smaller heap, \nthis is not always the case. 209 db seems to gener\u00adate no fragmentation, but uses a lot of small objects \n(we witnessed, for example, a large number of Enumerations that are less than 16 bytes). For small objects, \nSCHISM/CMR has enough of a size over\u00adhead that it can, and in this case does, outweigh the bene.ts of \nfragmentation tolerance. Table 5 reports data for external fragmentation of the different Fiji VM collectors \nfor SPECjvm98. The minimum heap size was obtained by running each benchmark with increasing heap sizes \n(in 100KB steps) until the program was able to run. Then, running at the minimum heap size, we record \nthe total memory used by live objects at each collection. The maximum is the maximum live size. This \ndoes not count external fragmentation but does include all meta-data as well as internal fragmentation. \nThe external fragmen\u00adtation is reported as the wasted space ( wastage ): the difference between maximum \nlive size and minimum heap size, scaled by the heap size. For some benchmarks, CMR exhibits > 50% wastage. \nFor example, 202 jess has the largest wastage (63.7%), which ex\u00adplains why SCHISM/CMR allows for smaller \nheap sizes than CMR. SCHISM/CMR on average requires a 20% (for level C) or 24% (for level A) larger heap \nsize to run. Note that according to Table 5, a benchmark only runs in a smaller heap size in SCHISM/CMR \nif it exhibits high wastage (>50%). The reason why wastage in SCHIS-M/CMR is not 0% is that both our \nminimum heap size and our max\u00adimum live size measurements are imprecise: minimum heap size may be off \nby nearly 100KB, and the maximum live size is not measured on every allocation but only when the collector \nruns in response to heap exhaustion. This .gure also shows the typical ob\u00adject size overheads of SCHISM/CMR: \n65% for level C and 67% for level A. This is substantially better than the predicted worst case memory \nusage (i.e., the prohibitive 3.5\u00d7 overhead of allocating very small objects) overheads as computed in \nSection 4.6. These results lead us to two conclusions. First, if typical memory usage is of the utmost \nconcern, CMR will tend to outperform SCHISM/CMR. On average it will run in a 20% smaller heap. But SCHISM/CMR \nal\u00adlows for smaller heaps in some pathological programs and always provides a hard bound on space usage. \n   Figure 9: Worst-case execution time as a function of heap size. SCHISM/CMR degrades sooner, implying \nthat this benchmark does not experience fragmentation. Levels A and C have similar per\u00adformance on larger \nheaps, but A performs worse for small heaps because it uses more memory.  6.3 Predictability To evaluate \npredictability we switch to the LEON3 platform and select a representative real-time benchmark, the well-known \nopen\u00adsource Collision Detector (CDx) [9]. We use C as our baseline, as it is the language of choice for \nreal-time developers. CDx is an idealized air traf.c collision detection algorithm that iteratively attempts \nto detect potential collisions based on simulated radar frames. It utilizes many arrays and performs \nsigni.cant math\u00adematical computations, making it ideally suited to low-level C pro\u00adgramming idioms but \nit has been deliberately implemented us\u00ading Java idioms even when they may be slow. For example, CDx \nuses classes in java.util extensively, and makes no effort to resize, preallocate, or pool any objects. \nWe con.gure CDx with a single real-time periodic task running with a period of 120 milliseconds. We have \nalso implemented a version of the collision detector in C. The implementation is idiomatic C that tries \nto follow the al\u00adgorithmic behavior of the Java code with some differences. For in\u00adstance, the hash table \nused by the C code requires almost no allo\u00adcation and has constant time traversal. The code size of the \nJava version of CDx used in this experiment is 3859 LoC and the C ver\u00adsion is 3371. (The C version is \nsomewhat simpler since it does not have hooks for the multiple con.gurations supported by the Java version). \nAll versions of CDx were run for 1,000 iterations. Note that on LEON3, execution is fully deterministic: \nthough we ran the benchmarks multiple times for sanity, we observe that for iteration i in a particular \ncon.guration, the execution time is always identical. Figure 6 compares the performance of Java and C. \nJava s perfor\u00ad mance is only 40% worse than that of C for SCHISM/CMR level A. For level C, the performance \nis 38% worse, and for CMR, the performance is 37% worse. Figure 7 shows a zoomed in view of just 100 \niterations (out of 1,000). Observe the similarity in the shape of the plots for C and Java. Clearly the \nvariations are algo\u00adrithmic and not due to the JVM or the GC. The overhead of CW is clear but remains \nacceptable. Figure 8 shows the ratio between C and SCHISM/CMR level C for each iteration. This again \nshows that there are no outliers. The performance difference is accounted for by the various checks performed \nby Java (for a more detailed look at the overheads of Java see [16]). Figure 9 gives the worst\u00ad case \nobserved behavior of the different collectors when the heap size ranges between 500 KB and 1500 KB. For \nSCHISM/CMR, the minimum heap size in which the program can run without missing deadlines is 1000 KB whereas \nfor CMR it is 600 KB. Figure 10 gives the minimum mutator utilization (MMU) of the different collectors \nfor CDx. MMU is often used as a metric for real-time garbage collectors [6]. It measures the minimum \namount of time that the mutator was able to run in a time window of a given size. MMU is interesting \nbecause it embodies a metric that combines the length of GC pauses with their frequency. Unfortun\u00adtely, \nthe notion of collector pause is a little tricky to de.ne. We considered two de.nitions: (i) time during \nwhich the mutator is preempted by the collector, or (ii) time spent by the mutator in allocation, store \nbarrier, array access, and stack scan slow paths. Under the .rst de.nition our collectors exhibit an \nMMU of 100% with no pauses (provided that the heap size is > 1100KB and the collector is the lowest priority \nthread, which is the default). But this is not particularly informative since all collectors have slow \npaths which may slow down execution. Thus, we chose (ii) and measure it conservatively as pauses include \nsome mutator work: array ac\u00adcess and allocation slow paths include some of the same logic as the fast \npaths that we charge to the mutator. The longest pauses are in SCHISM/CMR level CW, which are due to \nthe allocation of large ar\u00adrays: level CW simulates the effect of level C attempting to allocate a large \narray contiguously, failing, and then attempting to allocate payload fragments the quick way (bump pointer) \nbut failing again, and having to go into a deeper slow path for each fragment. Level A exhibits the smallest \npauses (roughly 0.4 ms) because almost all allocation is done 32 bytes at a time. The 0.4 ms pause corresponds \nto the time it takes to zero-initialize a fresh 4096 byte page, and is to our knowledge the smallest \nGC pause ever reported on a 40 MHz LEON3. We have also measured the performance of CDx against other \nreal-time Java virtual machines on Sharpay. Because Sharpay is at least an order of magnitude faster, \nwe have increased the workload of CDx to 60 planes as opposed to just 6. We see that the worst-case observed \nexecution time for one iteration of the benchmark on Java RTS is 25.4 ms, WebSphere SRT is 16.7 ms, while \nFiji VM is 9.9 ms. Speci.cally, CMR and SCHISM/CMR level C has a worst-case of 5.2 ms, and levels A and \nCW are 6.4 ms and 9.9 ms respectively.  6.4 Scaling Predictability So far we have shown that SCHISM/CMR \nperforms respectably on mostly uniprocessor benchmarks. The predictability of collectors is good, and \nSCHISM/CMR does a good job of managing fragmenta\u00adtion. But real-time systems are slowly and steadily \nmoving towards the adoption of multiprocessors. We evaluate scalability using the SPECjbb2000 benchmark \nrunning on an 8-way machine (Sharpay). We think of SPECjbb2000 as a soft real-time workload, in that \nit is reasonable to assume that in a real transaction processing system worst-case processing times are \nimportant.   Figure 11 shows that our performance does scale but not as well as some of the other systems. \nThe reason, we believe, is simple: our collectors are not parallel. While the algorithms we have pre\u00adsented \ndo not preclude parallelization, we have not done this yet. At 8 warehouses on an 8-way machine, the \nbenchmark ends up com\u00adpeting for CPU time against the collector itself. WebSphere SRT scales much better \nthan Fiji VM. Both CMR and SCHISM/CMR exhibit better performance than Java RTS when we overload the processor. \nWhen the processor is not overloaded, Java RTS scales about as well as CMR. Figure 12 gives the worst-case \ntransaction times for all JVMs. Because we opted not to use real-time scheduling, these measure\u00adments \ntend to be somewhat noisy a millisecond hiccup due to OS scheduling is common, but not common enough \nto be visi\u00adble on every run. Thus we ran the experiment three times and re\u00adport the average. For measurements \nup to 7 warehouses, all of Fiji VM s collectors produce better results than any other JVM. With either \nCMR or SCHISM/CMR at any predictability level we are able to guarantee millisecond-level worst-case transaction \ntimes. At 8 warehouses, Fiji VM performs about the same as WebSphere SRT, requiring between 52 and 171 \nmilliseconds in the worst case (SRT requires 165 milliseconds). For 9 or more warehouses, all JVMs steadily \ndegrade to worst-case transaction times in excess of 200 milliseconds. These results show that SCHISM/CMR \nscales about as well as Java RTS while achieving signi.cantly better predictability than any other JVM \nso long as the collector has a spare core on which to run. 7. Conclusion We have introduced a novel approach \nto fragmentation-tolerant garbage collection, dubbed Schism, and implemented it on a hard real-time Java \nvirtual machine. Schism employs fragmented allo\u00adcation of objects and arrays, managed with a mark-region \ngarbage collector, along with separate replication-copying of array spines, to achieve real-time bounds \nwith good throughput. Our perfor\u00admance evaluation is, to our knowledge, the most thorough to date for \nreal time garbage collectors. Our experiments show that SCHIS-M/CMR allows for signi.cantly better fragmentation \ntolerance than any of the other RTGCs while still producing throughput to within 40% of C code. In addition \nSCHISM/CMR shows good performance and scalability even when compared to non real-time production JVMs \non well-known benchmarks. A. Detailed Derivation of Space Bounds This appendix gives the detailed derivation \nof space bounds. For simplicity, we assume a 32-bit architecture with a 4096-byte page size. Similar \nformulas can be derived for 64-bit architectures and different page sizes.   A.1 Methodology We begin \nby deriving the base size, denoted B, for an object. To this we add the collector s meta-data overheads. \nThese are the page header overhead due to both the headers the collector adds to individual pages and \nthe space used by the page table, and the spine space overhead. In our implementation, the size of the \nspine space is set to 30% of the size of the CMR space. That is, given 10 heap size H, 13 H bytes are \nalways used for the CMR space that 3 stores 32-byte payload fragments and 13 H bytes are always held \nin reserve for arraylet spines even if no spines are ever allocated; Appendix A.5 proves that this is \nsuf.cient even for adversarial programs. We denote these overheads as P and S, respectively. This allows \nus to compute the total memory size used by an object using: M = B + P(B)+ S(B) (3)  A.2 Plain Objects \nNon-array objects consist of an ordered collection of .elds. The compiler guarantees deterministic layout \nof .elds allowing the total object size to be derived as follows. A three word header (12 bytes) is prepended \nto every object.4 Fields are laid out in program order starting with Object and walking down the extends \nchain. They are aligned in memory according to their size (for example an 8-byte .eld will always lie \non an 8-byte boundary). The size of an n-.eld object can thus be obtained by the following recurrence \nrelation, in which b0 denotes the header size and bi denotes the size after 4 The object header comprises: \na fragmentation word, used for linking the various 32-byte fragments together (accounting for this header \nis slightly tricky as it repeats every 32 bytes); a GC word used for marking by CMR; and a type word \nused to store both a Java lock and a pointer to the object s type.  adding the ith .eld, whose size \nis denoted by fi for 1 = i = n: b0 = 12 (4) bi = align(bi-1, fi)+ fi (5) The align function accounts \nfor byte-boundary padding and the fragmentation header inserted every 32 bytes to link to the next fragment. \nIt can be computed as the recurrence relation ak(bi-1, fi) that is executed until .xpoint: a0 = bi-1 \n(6) . . ak-1 + 4 if ak-1 mod 32 = 0 ak = ak-1 + 1 if ak-1 mod fi = 0 (7). ak-1 otherwise A .xpoint is \nguaranteed provided that fi = 16; in Java we are guaranteed that fi = 8. Given n .elds, we de.ne the \nbase size B as follows: bn B = 32(8) 32  A.3 Arrays Arrays comprise a sentinel, a spine, and the payload \nfragments. For very small arrays, the sentinel may contain the entire array payload, or its spine. At \nlevel C, some arrays will be allocated contiguously, which results in a smaller size. We ignore optimization \nin deriving the worst case. Additionally, we do not include the spine size in the computation as it is \npart of S. The sentinel is a single 32-byte fragment which contains 16 bytes of header and pseudo-length \nmeta-data.5 The remaining 16 bytes may be used for the payload if the array is small. Otherwise, there \nwill be 0 or more 32-byte fragments for storing the payload. Thus the base size B of an array is as follows. \nWe use l to denote the array length and e to denote the element size in bytes: 32 if l \u00d7 e = 16 B =l\u00d7e \n(9) 32 + 32if l \u00d7 e > 16 32 For arrays B is precise at level A, but an upper bound at level C. A.4 Page \noverhead The CMR space is a collection of pages that are contiguous in memory and separate from the spine \nspace. The default allocation mode for level A is that one page may contain multiple objects, but that \nno contiguous object ever straddles multiple pages. In level C, contiguous objects are allowed, in some \ncases, to cross page boundaries. Each page is then devoted entirely to that one object and even if there \nis free space in the page it cannot be used so long as that object is alive. Page status is maintained \nin a page table and in page headers. The page table has a 4-bit state per page. Page headers are 32-bytes, \nleaving 4096 -32 = 4064 bytes for data in each page. We compute page overheads such that they may be \nfractional: for example if an 10 object is 10 bytes long then we say that it uses 4064 th of the page \n10 header and 4064 th of the 4-bit page table .eld. We compute this by .rst introducing a helper function \np(B) which gives the number of pages (which may fractional) used by the object: B p(B)= (10) 4096 - 32 \n5 The sentinel header consists of a fragmentation word, a GC word and type word as before. The fragmentation \nword is used for linking to the spine. The pseudo-length is used to determine the length of the array \nas well as to indicate if the array is contiguous or fragmented. If the array is fragmented, this .eld \nwill be 0 and the true array length will be stored in the spine. Thus, if we just consider the page header \nthen the number of bytes used is 4096 \u00d7 p(B), so a 4064 byte object will use exactly one page. If we \njust consider the page table, the number of bytes used is 1 2 p(B), so for every 4064 bytes we use 4 \nbits. Putting this together, the page overhead for level A is as follows: 1 P(B) = 4096 p(B) + 2 p(B) \n- B (11) = 65 8128 B (12) 0.007997 B (13) This is a precise account of the overhead at level A. For \nlevel C, arrays that are larger than the 4064 maximum size for single-page contiguous allocation can \nbe allocated over multiple pages. In that case the .rst page requires 16 bytes for the CMR s large object \nheader and any free space on the last page is wasted until the object dies. Thus the total page overhead \nconsidering a contiguous large object allocation is: B + 16 0.5 Plarge(B)=40961 + - B (14) 40964096 \nThis is only needed for B > 4064 on level C. In fact, depending on the object size, sometimes P(B) can \nbe larger than Plarge(B), so to account for the worst case we take the maximum of the two. A.5 Provisioning \nSpine Space Spines are allocated in the separate spine space which is set to 30% the size of the CMR \nspace. We show that this is suf.cient even for adversarial programs. A spine requires a 8-byte header \n(a forwarding pointer and the length), and a 4-byte pointer for every fragment of the payload. We de.ne \nthe spine size s as follows, assuming that l is the array length and e is the element size: l \u00d7 e s \n= 8 + 4(15) 32 We conservatively assume a heap .lled with arrays, and that the sizes of those arrays \nare chosen adversarially resulting in the largest possible spine space overheads. For payloads = 16 bytes \nno spine is needed as the data .ts in the sentinel. For payloads between 16 and 96 bytes, the spine can \nbe inlined in the sentinel. Thus, spine space allocation can only happen for arrays with payloads larger \nthan 96 bytes. The worst-case occurs for the smallest array that results in spine allocation. Taking \nl \u00d7 e = 97, we obtain B = 160 and s = 24. Thus we need s/B = 24 = 0.15 bytes of spine space for every \nbyte 160 of CMR memory, excluding page overheads. As l \u00d7e increases then s/B converges to 0.125 thus \n0.15 is indeed the worst-case. We double this amount to account for the spine space s copy reserve to \nget an overhead of 0.3. Thus setting aside 0.3 bytes in the spine space for every byte in the CMR space \nis suf.cient to ensure that the spine space is never exhausted. This analysis is slightly pessimistic. \nInstead of using s/B, we should use s/(B + P(B)), which is slightly smaller; it gives us 0.29762 instead \nof 0.3. Using round numbers has its bene.ts: when the user speci.es a heap size we need to slice the \nheap into a spine region and a CMR region; the rounder the number the more likely we are to be able to \ndo so precisely. Because the heap is always divided in this .xed way we always assume that the spine \noverhead of every object is: S(B)= 0.3[B + P(B)] (16)  A.6 Total Object Size The total object size is \nthe sum of B and the two sources of overheads: page allocation overhead and spine space overhead.  Thus \nwe write the total object size as follows: M = B + P(B)+ S(B) (17) For predictability level A both P(B) \nand S(B) have a simple closed form, so this simpli.es to: M = 1.3104B (18) This formulation allows the \nprogrammer to compute exactly what heap size to pick given an analysis of the number and type of objects \nknown to be live at the high watermark. Simply summing the sizes M and rounding up to the nearest page \nsize yields the heap size necessary to never run out of memory. Even if the heap structure changes and \nthe programmer suddenly decides to allocate arrays instead of objects or vice versa, it is guaranteed \nthat an out\u00adof-memory condition will not be reached provided that the total sizes of objects are less \nthan or equal to the heap size. Acknowledgments We thank Tomas Kalibera, Gaith Haddad and Ales Plsek \nfor their help with CDx, and the anonymous reviewers for their detailed comments. This work is supported \nin part by NSF grants CCF\u00ad0702240, and CCF-0811691, and IIP-0912730. References [1] Joshua Auerbach, \nDavid F. Bacon, Bob Blainey, Perry Cheng, Michael Dawson, Mike Fulton, David Grove, Darren Hart, and \nMark Stoodley. Design and implementation of a comprehensive real-time Java virtual machine. In Conference \non Embedded Software (EMSOFT), 2007, pages 249 258. doi: 10.1145/1289927.1289967. [2] Joshua Auerbach, \nDavid F. Bacon, Perry Cheng, David Grove, Ben Biron, Charlie Gracie, Bill McCloskey, Aleksandar Micic, \nand Ryan Sciampacone. Tax-and-spend: democratic scheduling for real-time garbage collection. In Conference \non Embedded Software (EM-SOFT), October 2008, pages 245 254. doi: 10.1145/1450058. 1450092. [3] David \nF. Bacon, Perry Cheng, and V. T. Rajan. A real-time garbage collector with low overhead and consistent \nutilization. In Symposium on Principles of Programming Languages (POPL), January 2003, pages 285 298. \ndoi: 10.1145/604131.604155. [4] Steve Blackburn and Kathryn McKinley. Immix: A mark-region garbage collector \nwith space ef.ciency, fast collection, and mutator performance. In Programming Language Design and Implementation \n(PLDI), 2008, pages 22 32. doi: 10.1145/1375581.1375586. [5] Eric Bruno and Greg Bollella. Real-Time \nJava Programming: With Java RTS. Addison-Wesley, 2009. [6] Perry Cheng and Guy E. Blelloch. A parallel, \nreal-time garbage col\u00adlector. In Conference on Programming Language Design and Imple\u00admentation (PLDI), \n2001, pages 125 136. doi: 10.1145/378795. 378823. [7] Cliff Click, Gil Tene, and Michael Wolf. The Pauseless \nGC algo\u00adrithm. In International Conference on Virtual Execution Environments (VEE), 2005, pages 46 56. \ndoi: 10.1145/1064979.1064988. [8] Richard L. Hudson and J. Eliot B. Moss. Sapphire: Copying garbage collection \nwithout stopping the world. Concurrency and Computation: Practice and Experience, 15(3 5):223 261, 2003. \ndoi: 10.1002/ cpe.712. [9] Tomas Kalibera, Jeff Hagelberg, Filip Pizlo, Ales Plsek, and Jan Vitek Ben \nTitzer and. Cdx: A family of real-time Java benchmarks. In In\u00adternational Workshop on Java Technologies \nfor Real-time and Em\u00adbedded Systems (JTRES), September 2009, pages 110 119. doi: 10.1145/1620405.1620421. \n[10] Tomas Kalibera, Filip Pizlo, Antony L. Hosking, and Jan Vitek. Scheduling hard real-time garbage \ncollection. In Real-Time Systems Symposium (RTSS), December 2009, pages 81 92. doi: 10.1109/ RTSS.2009.40. \n[11] B. McCloskey, David Bacon, Perry Cheng, and David Grove. Stac\u00adcato: A parallel and concurrent real-time \ncompacting garbage collec\u00adtor for multiprocessors. Technical Report RC24505, IBM Research, 2008. [12] \nScott Nettles and James O Toole. Real-time replication-based garbage collection. In Conference on Programming \nLanguage Design and Implementation (PLDI), 1993, pages 217 226. doi: 10.1145/ 155090.155111. [13] Filip \nPizlo, Daniel Frampton, Erez Petrank, and Bjarne Steensgaard. Stopless: A real-time garbage collector \nfor modern platforms. In In\u00adternational Symposium on Memory Managment (ISMM), 2007, pages 159 172. doi: \n10.1145/1296907.1296927. [14] Filip Pizlo, Erez Petrank, and Bjarne Steensgaard. A study of concur\u00adrent \nreal-time garbage collectors. In Conference on Programming Lan\u00adguage Design and Implementation (PLDI), \n2008, pages 33 44. doi: 10.1145/1375581.1375587. [15] Filip Pizlo, Lukasz Ziarek, and Jan Vitek. Real \ntime Java on resource-constrained platforms with Fiji VM. In International Workshop on Java Technologies \nfor Real-time and Embedded Sys\u00adtems (JTRES), September 2009, pages 110 119. doi: 10.1145/ 1620405.1620421. \n[16] Filip Pizlo, Lukasz Ziarek, Ethan Blanton, Petr Maj, and Jan Vitek. High-level programming of embedded \nhard real-time devices. In EuroSys Conference, April 2010. [17] Wolfgang Puf.tsch and Martin Schoeberl. \nNon-blocking root scan\u00adning for real-time garbage collection. In International Workshop on Java Technologies \nfor Real-Time and Embedded Systems (JTRES), 2008, pages 68 76. doi: 10.1145/1434790.1434801. [18] Fridtjof \nSiebert. Realtime garbage collection in the JamaicaVM 3.0. In Java Technologies for Real-time and Embedded \nSystems (JTRES), September 2007, pages 277 278. doi: 10.1145/1288940. 1288954.  \n\t\t\t", "proc_id": "1806596", "abstract": "<p>Managed languages such as Java and C# are being considered for use in hard real-time systems. A hurdle to their widespread adoption is the lack of garbage collection algorithms that offer predictable space-and-time performance in the face of fragmentation. We introduce SCHISM/CMR, a new concurrent and real-time garbage collector that is fragmentation tolerant and guarantees time-and-space worst-case bounds while providing good throughput. SCHISM/CMR combines mark-region collection of fragmented objects and arrays (arraylets) with separate replication-copying collection of immutable arraylet spines, so as to cope with external fragmentation when running in small heaps. We present an implementation of SCHISM/CMR in the Fiji VM, a high-performance Java virtual machine for mission-critical systems, along with a thorough experimental evaluation on a wide variety of architectures, including server-class and embedded systems. The results show that SCHISM/CMR tolerates fragmentation better than previous schemes, with a much more acceptable throughput penalty.</p>", "authors": [{"name": "Filip Pizlo", "author_profile_id": "81312485539", "affiliation": "Fiji Systems, Inc., Indianapolis, IN, USA", "person_id": "P2184528", "email_address": "", "orcid_id": ""}, {"name": "Lukasz Ziarek", "author_profile_id": "81318492573", "affiliation": "Fiji Systems, Inc., Indianapolis, IN, USA", "person_id": "P2184529", "email_address": "", "orcid_id": ""}, {"name": "Petr Maj", "author_profile_id": "81460643812", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2184530", "email_address": "", "orcid_id": ""}, {"name": "Antony L. Hosking", "author_profile_id": "81100554713", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2184531", "email_address": "", "orcid_id": ""}, {"name": "Ethan Blanton", "author_profile_id": "86058655857", "affiliation": "Fiji Systems, Inc., Indianapolis, IN, USA", "person_id": "P2184532", "email_address": "", "orcid_id": ""}, {"name": "Jan Vitek", "author_profile_id": "81100018102", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2184533", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806615", "year": "2010", "article_id": "1806615", "conference": "PLDI", "title": "Schism: fragmentation-tolerant real-time garbage collection", "url": "http://dl.acm.org/citation.cfm?id=1806615"}