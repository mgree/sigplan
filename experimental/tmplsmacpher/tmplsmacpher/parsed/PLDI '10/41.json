{"article_publication_date": "06-05-2010", "fulltext": "\n Traceable Data Types for Self-Adjusting Computation Umut A. Acar * Guy Blelloch Ruy Ley-Wild Duru T\u00a8urko.glu \nMax-Planck Institute Kanat Tangwongsan University of Chicago for Software Systems Carnegie Mellon University \nduru@cs.uchicago.edu umut@mpi-sws.org {blelloch,rleywild,ktangwon}@cs.cmu.edu Abstract Self-adjusting \ncomputation provides an evaluation model where computations can respond automatically to modi.cations \nto their data by using a mechanism for propagating modi.cations through the computation. Current approaches \nto self-adjusting computation guarantee correctness by recording dependencies in a trace at the granularity \nof individual memory operations. Tracing at the granu\u00adlarity of memory operations, however, has some \nlimitations: it can be asymptotically inef.cient (e.g., compared to optimal solutions) because it cannot \ntake advantage of problem-speci.c structure, it requires keeping a large computation trace (often proportional \nto the runtime of the program on the current input), and it introduces moderately large constant factors \nin practice. In this paper, we extend dependence-tracing to work at the gran\u00adularity of the query and \nupdate operations of arbitrary (abstract) data types, instead of just reads and writes on memory cells. \nThis can signi.cantly reduce the number of dependencies that need to be kept in the trace and followed \nduring an update. We de.ne an interface for supporting a traceable version of a data type, which reports \nthe earliest query that depends on (is changed by) revis\u00ading operations back in time, and implement several \nsuch structures, including priority queues, queues, dictionaries, and counters. We develop a semantics \nfor tracing, extend an existing self-adjusting language, .ML, and its implementation to support traceable \ndata types, and present an experimental evaluation by considering a number of benchmarks. Our experiments \nshow dramatic improve\u00adments on space and time, sometimes by as much as two orders of magnitude. Categories \nand Subject Descriptors D.3.0 [Programming Lan\u00adguages]: General; D.3.3 [Programming Languages]: Language \nConstructs and Features General Terms Languages Keywords self-adjusting computation, traceable data types \n* Acar is partially supported by gifts from Intel, Microsoft Research, and Jane Street Capital. Ley-Wild \nis partially supported by a Bell Labs Graduate Fellowship. T\u00a8urko.glu is partially supported by gifts \nfrom Intel and Jane Street Capital. Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 10, June 5 10, 2010, Toronto, Ontario, Canada. Copyright c &#38;#169; \n2010 ACM 978-1-4503-0019-3/10/06. . . $10.00  1. Introduction Many applications must process data that \nchanges, sometimes con\u00adtinuously, over time possibly with small changes at each step. For example, a \ntraf.c controller needs to update a traf.c map after an accident blocks a road segment, a robot may need \nto update its motion plan after encountering a new obstacle, a theorem prover may need to update its \nconclusions after discovering a new fact, or a blood-.ow simulator must compute properties of molecules \nthat move continuously over time. In these and similar applica\u00adtions, small or continuous changes to \ndata often cause only small updates to the output, making it possible to respond to dynamically\u00adchanging \ndata more ef.ciently than re-computing the output from scratch, often asymptotically. To exploit this \npotential, one can de\u00advelop so called dynamic of kinetic algorithms that are opti\u00admized to deal with \nparticular forms of changing input. Indeed, there has been signi.cant progress on such algorithms (e.g., \n[7, 11, 14]). Designing and implementing these algorithms turns out to be quite dif.cult even for problems \nthat are simple in the absence of data changes, such as many of the simple graph and computational ge\u00adometry \nalgorithms. All too often, when such algorithms exist, they are quite complex and dif.cult to implement. \nAlternatively, the programming languages community has de\u00adveloped techniques that automate or mostly \nautomate the process of translating an implementation of an algorithm for .xed input into a version for \nchanging input (e.g., [12, 15, 23]) by storing certain trace information during the computation. A recent \napproach based on a combination of dynamic dependence graphs [2] and memoiza\u00adtion has been used to develop \nasymptotically ef.cient versions of a reasonably broad set of problems [5, 25]. This approach, called \nself\u00adadjusting computation (SAC), generates a computation dependence graph while running the program \non the initial data, and stores infor\u00admation at each node of the graph representing the code that needs \nto be rerun if its input changes. A change-propagation algorithm propagates any input changes through \nthis graph, updating the parts of the graph and the output that depend on them. Memoization al\u00adlows the \nalgorithm to reuse portions of the graph during propaga\u00adtion. The time taken by change-propagation depends \non how stable the computation trace is with respect to changes in input [20]. Re\u00adcent work shows that \nself-adjusting computation and its variants can be supported by extending existing languages, such as \nC [16], Java [25], and Standard ML [19]. To achieve automatic and correct updates under data modi.ca\u00adtions, \nexisting self-adjusting computation techniques trace depen\u00addencies at the (memory) cell level by recording \nmemory operations. Although very .exible, this .ne-grained approach to tracing has some performance problems, \nboth in terms of time and space. First, it creates a considerable time overhead, slowing down essentially \nevery memory operation. Second, it requires signi.cant memory space for storing .ne-grained dependence \ninformation. Third, when implementing data types using the approach, updates can cause many changes internal \nto the data type implementation, even when the changes that propagate to the interface are small i.e., \nthe com\u00adputation can be stable with respect to operations of the data type, but not stable with respect \nto individual cell accesses ultimately causing sub-optimal updates. An example of this third problem \nis in maintaining a priority queue, where inserting a single element can require linear time for change-propagation \nat the cell level even if it only creates a single change (an additional insert operation) at the interface \nlevel. Many algorithms that use a priority queue will suffer from this problem.  In this paper, we extend \nthe tracing of dependencies to support the query and update operations of arbitrary (abstract) data types, \ninstead of just the reads and writes of a cell. For many applications, this asymptotically reduces the \nnumber of dependencies that are traced, reducing memory and time overhead, and for some it can speed \nup change propagation dramatically by making them more stable. This extension involves developing traceable \nversions of any data type that needs its dependencies to be traced directly, and adapting the change-propagation \nalgorithm to handle the more general dependence tracing. The change propagation algorithm itself remains \ninsensitive to the speci.cs of the data structures, which we achieve by providing a uni.ed interface \nfor all traceable data types. From the perspective of a user who is implementing self\u00adadjusting programs, \nthe changes to the code are minimal: all this requires is to substitute a different library or implementation \nfor the data type. In addition to improving performance, the approach can also greatly simplify the analysis \nof stability since the user need only consider the operations on the data type instead of all the memory \naccesses inside of it. In Section 2, we explain the problem of tracing dependencies at the memory cell \nlevel in more detail, give an overview of our approach, and present algorithms that use traceable data \ntypes. We de.ne a relatively simple interface that one must implement to support a traceable data type \n(TDT) (Section 3). It is based on maintaining an operation trace for each instance and allowing any operation \nof the standard data type to be invoked or revoked anywhere in the trace. Such revisions must return \na pointer to the earliest following query in the trace made inconsistent by the revision, if any. Implementations \nof TDTs do not need to be aware of the change-propagation algorithm beyond the interface. We have implemented \ntraceable versions of several data types, including queues, priority queues, dictionaries, and accumulators \n(Section 3.1). We note that we do not expect that new data types would be implemented very often. To \nsupport traceable data types uniformly, we modify change propagation in some relatively small but subtle \nways. First, instead of storing closures with just the read operations on each cell, we store a closure \nfor each query on TDTs. In fact, we treat cells as a TDT instance with read and write operations, and \nrefer to them as modi.able references. Second, as with standard change prop\u00adagation, during execution \nwe keep a time-ordered priority queue of inconsistent queries (reads), but instead of tracking all incon\u00adsistencies \nfor all TDT instances, we only keep the earliest incon\u00adsistency for each instance. This is critical for \nef.ciently handling certain data types (Section 3). We present a formal self-adjusting core calculus \nthat is extensible by arbitrary TDTs (Section 4). We present a static and dynamic semantics for the core \ncalculus, in\u00adcluding change propagation for traceable data types. A key com\u00adponent of the calculus is \nthe open-endedness of the tracing and change-propagation semantics to support arbitrary traceable data \ntypes, without knowledge of how they are implemented. We assess the effectiveness of the approach by \nextending the .ML language [19, 20] to support TDTs, and implementing a num\u00adber of benchmarks, including \nheap sort, Dijkstra s shortest path al\u00adgorithm, breadth-.rst search on graphs, Huffman coding, and inter\u00adval \nstabbing (Section 6). An interesting property of TDTsis that they enable operating ef.ciently on certain \ncontinuously varying values such as time . Taking advantage of this property, we im\u00adplement a library \nfor algorithmic motion simulation that enables performing motion simulation with self-adjusting programs \nby ap\u00adpropriately changing the time (Section 7). Speci.cally, we con\u00adsider an algorithm for computing \nconvex hulls in 3D making it pos\u00adsible to safely implement motion simulation without requiring un\u00adsafe \nmanipulation of the internals of the run-time system to ensure ef.ciency as in previous work [4]. Using \nthese benchmarks, we perform an experimental evalua\u00adtion of the proposed approach (Section 6). The experiments \nshow substantial time and space improvements. Even on moderate input sizes, the improvements range between \na factor of 3 and 20 reduc\u00adtion in from-scratch running time, between a factor of 4 and 50 reduction \nin space, and between a factor of 4 and 5, 000 reduction in update time compared to the version using \nonly modi.able refer\u00adences (memory cells).  2. Overview We motivate traceable data types, overview their \nstructure, and consider some examples in the .ML language. 2.1 Motivation Consider a priority queue \nwhose signature is shown in Figure 1. The priority queue provides a new operation that takes a compari\u00adson \nfunction on keys returns an empty priority queue, an insert function for inserting a key and a value \ninto a priority queue, and a delMin function for removing the element with the minimum pri\u00adority. Consider \na program that uses this priority queue data struc\u00adture. Using existing self-adjusting computation techniques \n(e.g., [16, 20]), we can write a self-adjusting version of priority queues and the program. A self-adjusting \nprogram responds interactively to modi.ca\u00adtions to its input data. To achieve this, as the program executes, \nthe run-time system constructs a trace of the execution. A change\u00adpropagation algorithm uses this trace \nto update the output when the input is modi.ed. In existing self-adjusting computation tech\u00adniques, the \ntrace will be constructed by recording operations on so called modi.able references (modi.ables for short) \nthat hold changeable data, i.e., data that can change over time. For exam\u00adple, to make a heap data structure \n(a priority queue) self-adjusting, the child pointers of each heap node can be replaced by modi.\u00adables. \nLanguages such as .ML [19, 20] make this transformation relatively straightforward. By placing data in \nmodi.ables, it is possible for a program to respond to input changes ef.ciently. Although relatively \nstraight\u00adforward, this approach suffers from several limitations. First, the execution is traced at a \n.ne granularity constructing a relatively large trace, typically asymptotically as large as the running \ntime of the program. Second, by tracing every operation on a modi.able, the program is slowed down signi.cantly \nby introducing reason\u00adably large overheads. Third, our response times could suffer be\u00adcause change-propagation \ncan spend signi.cant time maintaining the .ne-grain dependence information recorded in the trace. As \na concrete example, consider a self-adjusting version of a heap data structure where each child pointer \nis placed in a mod\u00adi.able. The trace would record every access to the child pointer, contributing signi.cantly \nto the size of the program trace. Since the work performed after each child access is essentially a com\u00adparison \nbetween priorities (keys) and thus relatively small, trac\u00ading would slow down the computation signi.cantly. \nInterestingly, dependence-tracing at the level of modi.ables can also result in sub-optimal update performance \nwith change-propagation. To see this we will need to look further into the structure of the trace. As \nan example, we consider a worst-case scenario. Consider a self-adjusting program P that takes as input \nan in\u00adteger list, creates an empty queue and inserts the .rst element of  signature PRIORITY QUEUE = \nsig signature PRIORITY QUEUE TRACEABLE = sig type ( k, v) t type ( k, v) t val new: ( k * k -> order) \n-> ( k, v) t val new: ( k * k -> order) -> ( k, v) t val insert: ( k, v) t * k * v -> unit val invoke \ninsert: ts * (( k, v) t * k * v) -> ts option * unit val revoke insert: ts -> ts option val delMin: ( \nk, v) t -> ( k * v) option val invoke delMin: ts * ( k, v) t -> ts option * ( k * v) option val revoke \ndelMin: ts -> ts option end end Figure 1. The signature for priority queues. Figure 2. The signature \nfor traceable priority queues. [new () . Q][a . Q][1 . Q] (1,a) [Q . 1] [2 . Q] (2,a) [Q . 2] [3 . Q] \n(3,a) [Q . 3] \u00b7\u00b7\u00b7 [n . Q] (n, a) [Q . n] ...........\u00b7\u00b7\u00b7 ... [new () . Q][b . Q][1 . Q] (1,b) [Q . 1] \n[2 . Q] (2,b) [Q . 2] [3 . Q] (3,b) [Q . 3] \u00b7\u00b7\u00b7 [n . Q] (n, b) [Q . n] [new () . Q][a . Q][1 . Q][Q . \n1] [2 . Q][Q . 2] [3 . Q][Q . 3] \u00b7\u00b7\u00b7 [n . Q][Q . n] ........\u00b7\u00b7\u00b7 .. [new () . Q][b . Q][1 . Q][Q . 1] \n[2 . Q][Q . 2] [3 . Q][Q . 3] \u00b7\u00b7\u00b7 [n . Q][Q . n] Figure 3. Two pairs of traces of a hypothetical program \nP at the level of queue operations and comparisons (top) and at the level of abstract queue operations \n(bottom). Each pair corresponds to a run of P with inputs [a, 1, 2,...,n] and [b, 1, 2,...,n]. the list \ninto the priority queue. Starting with the second element, the program then inserts each element into \nthe priority queue us\u00ading the element both as a priority and as a value and removes the minimum element \nby performing a delMin. Assume that the pri\u00adority queue is implemented via conventional self-adjusting \ncompu\u00adtation techniques requiring the tracing of every comparison. Fig\u00adure 3 (top) shows the traces (represented \nabstractly) for an execu\u00adtion of P with the input [a, 1, 2,...,n] and [b, 1, 2,...,n],where a,b > n and \nab. We write [i .Q] for an instance of the op\u00ad = eration insert(Q, i, i), [Q .i] for an instance of the \noperation delMin(Q) that returns i as the minimum priority, and (i, j)for a comparison of the keys i \nand j. Now comparing the two traces, note that every comparison in the .rst trace has the form (i, a)and \nev\u00adery comparison in the second trace has the form (i, b)(1 =i =n) and no two comparisons match the difference \nbetween the two traces is T(n). In the .gure, we use .and .to indicate the oper\u00adations of the trace that \nmatch and that do not match (respectively). Consequently, starting with the .rst input running the program \nP , changing the input by replacing a by b, and performing change\u00adpropagation would require at least \nlinear time to update the output (a more precise account of the relationship between the trace dis\u00adtances \nand change-propagation can be found elsewhere [20]). This argument extends to any priority queue data \nstructure, because every time a new key i is inserted, the priority queue contains only the element with \nthe largest key, either a or b and thus a comparison with i must be performed to determine the minimum \npriority required by the next operation. It is thus not possible to use change-propagation based on conventional \nself\u00adadjusting computation to update the output in less than linear time. Fortunately, there is great \npotential for improvement. To see this suppose that we record just the priority queue operations in the \ntrace and not the comparisons. As shown in Figure 3 (bottom), the traces of the two runs of P are very \nsimilar; they differ in only one operation. The example shows that if we can record dependencies at the \nlevel of priority queue operations instead of the internal compar\u00adisons performed by the priority queue \noperations, then the trace is smaller and there are fewer differences between the computations, and thus \nchange-propagation can be performed more ef.ciently. This is the main idea behind traceable data types. \nAs we discuss in Section 6 both the improvements in the size of the trace and the update time can be \nasymptotic. Challenges to realizing traceable data types include the question of whether it is possible \nto design and implement them ef.ciently, whether they can be made to work with change-propagation so \nthat programs can still respond auto\u00admatically to modi.cations to their data, and whether they can be \nsupported naturally without requiring a cumbersome interface.  2.2 Traceable Data Types A traceable \ndata type (TDT) permits tracing dependencies at the level of its operations rather than memory cells. \nFor an abstract data type, a traceable version of the data type provides an analogous op\u00aderation to initialize \nthe data type and two versions, called invoke and revoke, for each of the remaining operations. These \noperations essentially allow revisions to the sequence of operations performed on a data structure by \ninserting new operations (via invoke) and deleting existing operations (via revoke). To enable ef.cient \nrevi\u00adsions, TDTs maintain an internal operation trace of the operations performed labelled with their \ntimestamp (of type ts). If the abstract data type has an operation op: a -> \u00df,the traceable version has \nthe operations invoke op: ts * a -> ts option * \u00df revoke op: ts -> ts option These operations revise \nthe operation trace by inserting a new op operation at a given timestamp (invoke op) and by removing \nan op operation at a given timestamp from the operation trace (revoke op). Both the invoke and revoke \noperations return an optional timestamp corresponding to the next operation, if any, that has been invalidated \nby the revision. As an example, Figure 2 shows the signature for the traceable priority queue. To enable \nchange-propagation, invoke and revoke operations identify the .rst operation of the trace made inconsistent \nby the revision by returning the timestamp for that operation. We call an operation inconsistent if its \nreturn value changes after the revision. Suppose for example that we perform the operations  insert(pq,3,3), \ninsert(pq,2,2), insert(pq,1,1), delMin(pq), delMin(pq), delMin(pq). The delMin operations will return \nthe values 1, 2, 3 in sorted or\u00adder. If we now revoke insert (pq,1),the .rst delMin opera\u00adtion will be \nthe earliest affected operation and thus its timestamp be returned by this revision. Note that in fact \nall other delMin oper\u00adations are inconsistent. In Section 3 we de.ne traceable data types more precisely, \nconsider several examples, and describe how they can be implemented ef.ciently. In Section 4 we present \nan extensi\u00adble semantics for integrating TDTs into a self-adjusting language including change-propagation. \nThe proposed interface with invoke and revoke operations are signi.cantly more cumbersome to use than \nthe standard data types. Fortunately, these operations need not be used by the programmer at all. In \nfact, it is possible to present a user-level interface for traceable data types that is essentially the \nsame as the standard version. We describe how to achieve this in the context of the .ML language.  2.3 \n.ML with Traceable Data Types The .ML language extends Standard ML (SML) with support for self-adjusting \ncomputation. The principal extensions to SML are modi.able references which are ML-style references with \nsupport for dependence-tracing, adaptive functions that help identify oppor\u00adtunities for computation \nreuse, and a change-propagation mecha\u00adnism for updating computations and outputs. In .ML, after a self\u00adadjusting \nprogram executes, the contents of the input modi.ables may be modi.ed and the output can be updated by \ncalling change\u00adpropagation. To support ef.cient compilation and updates, .ML offers two kinds of function \nspaces: conventional functions of type a->\u00df and adaptive functions of type a-$>\u00df. Application of adap\u00adtive \nfunction f to argument a is written f$a. Adaptive functions, de.ned by keywords afun and mfun, can be \neither non-memoized or memoized (respectively), and can call conventional function as well as adaptive \nfunctions. Conventional functions are not permit\u00adted to call adaptive functions.1 Consider a program \nthat uses some (standard) data type, e.g., a priority queue, and suppose that we have a traceable version \nof that data type. To enable the user to operate on the traceable data types in the same way as the standard \ndata types, we provide a user-level interface to the data type that essentially matches the standard \ninterface with the exception of requiring each operation to be an adaptive function. More speci.cally, \neach operation of type a->\u00df becomes a-$>\u00df. For example, the user-level interface for the traceable priority \nqueue would be: signature PRIORITY QUEUE TDT USER = sig type ( k, v) t valnew:( k* k->order) -$> ( k, \nv) t val insert: ( k, v) t * k * v -$> unit val delMin: ( k, v) t -$> ( k * v) option end Given a program \nusing the user-level interface to traceable data types, our (extended) .ML compiler can translate the \nprogram to use the corresponding invoke and revoke operations and integrate them with change-propagation. \nTo this end, the compiler generates the necessary code for tracing the invoke and revoke operations and \nfor .nding and re-executing them when necessary during change\u00adpropagation. For example, we can compile \nsome program that uses the above interface to traceable priority queues shown in Figure 2. 1 Each self-adjusting \nprogram has a single entry point which itself is an adaptive function. structure PQ : PRIORITY QUEUE \nTDT USER afun heapsort (compare, l) = let val heap = PQ.new $ compare afun insert x = PQ.insert $ (heap, \nx, ()) mfun loop m = case m of NONE => NIL | SOME (k, ()) => let val t = loop $ (PQ.deleteMin $ heap) \nin CONS(k, put $ t) end in (List.app insert $ l; put $ (loop $ (PQ.deleteMin $ heap))) end Figure 4. \nCode for heap sort in .ML. 2.4 Example: Heap Sort As an example of how a traceable data type can be \nused in a user program, we consider a .ML implementation of heap sort as shown in Figure 4. The algorithm \n.rst allocates an empty prior\u00adity queue and inserts all the keys in its input to the priority queue (with \nunit payload). It then constructs the sorted output by repeat\u00adedly removing the minimum element until \nthe queue is empty and returning them in a list. This algorithm has several notable features: First, \nit has an optimal O(n log n) running time. Second, but most importantly, it is highly stable under small \nmodi.cations to its in\u00adput when the trace is at the granularity of priority queue operations. Thus, with \ntraceable priority queues, we can obtain an ef.cient self\u00adadjusting sorter (our experiments in Section \n6 con.rms that the al\u00adgorithm performs well in practice). Finally, the self-adjusting version in .ML \nonly differs from the standard SML implementation in the underlined code fragments (also highlighted \nin red) and the use of the user-level traceable priority queue. The only major differences are the use \nof modi.able lists where the tail of each cell is placed in a modi.able, and that the priority queue \nfunctions have the adaptive function type. We de.ne loop as a memoized function as it performs non-constant \nwork. This example provides evidence that programming with TDTs requires little modi.cations to existing \ncode. Note also that in\u00adstead of using a traceable priority queue, we could also use a self\u00adadjusting \nversion of a priority queue that has the same interface (e.g., a heap or a treap implemented using modi.ables). \nAs dis\u00adcussed in Section 2.1 and further in Section 6, such modi.able\u00adbased implementations, however, \nperform signi.cantly worse.  2.5 Example: Dijkstra s Algorithm As another example, we consider Dijkstra \ns algorithm for comput\u00ading single-source shortest-paths, whose .ML code is shown in Fig\u00adure 5. The code \nstrongly resembles the SML implementation: drop\u00adping the underlined text yields the SML code. We omit \nsome details to focus attention on the aspects relevant to our interest here. Dijk\u00adstra s algorithm takes \na graph and a root node and .nds the shortest\u00adpath distance from the root to every node in the graph. \nWe represent the input graph as a dictionary of nodes (t graph), mapping each node to the list of its \nneighbors along with the edge weights. Sim\u00adilarly, we represent the output as a dictionary of nodes (dict \nsp), mapping each node to its distance to the root. The key idea in the al\u00adgorithm is to maintain a set \nof explored vertices and their distances to the root and expand this set iteratively. For this purpose, \nwe main\u00adtain a priority queue (pq v) of visited vertices and their current dis\u00adtances. The algorithm \nstarts by inserting the root into the priority queue with distance 0. It then repeatedly visits the vertices \nin the order of their current distance by calling the function loop.Given   structure Dict : DICTIONARY \n= struct ... end structure PQ : PRIORITY QUEUE TDT USER structure List : LIST = struct ... end type \nt node = ... type t dist = ... type t graph = (t node, (t node * t dist) List.t) Dict.t afun dijkstra \n(root: t node, graph: t graph) = let val dict sp: (t node, t dist) Dict.t = Dict.new $ () val pq v: (t \ndist * t node) PQ.t = PQ.new $ () afun visit (u, d:t dist) = let afun ins (v,w) = PQ.insert $ (pq v, \n(d + w, v)) in case Dict.lookup $ (graph, u) of NONE=>() |SOMEns=>List.app ins $ ns end mfunloop(u:t \nnode, d:t dist) = (if (Dict.lookup $ (dict sp, u)) = NONE then (Dict.insert $ (dict sp, u, d); visit \n(u,d)) else (); case PQ.deleteMin $ pq vof NONE => dict sp | SOME (d, v) => loop $ (v,d)) in loop $ \n(root, 0) end Figure 5. Code for Dijkstra s algorithm in .ML. avertex u and its current distance d, the \nfunction loop checks if u is already visited. If so then it continues by removing the next ver\u00adtex from \nthe priority queue. If not then the exact distance for u is found; it inserts u into the output (dict \nsp) and visits it. To visit a vertex, it traverses each outgoing edge (u, v) by inserting v into the \npriority queue with an updated distance. As with the heap sort algo\u00adrithm, we are able to obtain a self-adjusting \nversion of the algorithm without modifying its structure, and we can use both a traceable pri\u00adority queue \nor a self-adjusting priority queue implemented by using modi.ables directly (Section 6 compares these \nimplementations).  3. Traceable Data Types We de.ne an (conventional) abstract data type D as a quadruple \n(t tdt,S,mk, {op 1, ...,op n}) consisting of a type constructor t tdt,  a state constructor S,  a \ncreation (make) operation mk,and  a set of operations op i (1 =i =n).  A speci.cation of a data type \nis a set of state-transformation rela\u00adtions, one for each constructor or operation. The state-transformation \nrelation for the constructor maps a given value v to an initial state mk S0, written v .S0. The state-transformation \nrelations for the other operations map a state and a given value to another state and an\u00ad op i S' other \nvalue, e.g., S; v .; v . de.nes how op i operation with argument v transforms the state from S to S. \nand yields result v . . Any data type can, however complex, be speci.ed in this way by coming up with \nan appropriate representation for the state and by specifying the state-transformation function. To de.ne \nthe traceable version of a data type D=(t tdt,S,mk, {op 1, ...,op n}), we let T denote a totally ordered \nset of times\u00adtamps. We de.ne a operation-trace H for a data type as an initial state S0 and a sequence \n[(t1,o1,v1), (t2,o2,v2),..., (tn,on,vn)], where the ti .T,ti <ti+1, and each oi is an operation of the \nform op kvi . that takes some vi . as an argument to return vi.Let vD(H, t) be the value returned by \nperforming the sequence of op\u00ad     operation: type state-transformation put : t . t modref get : \nunit . t set : t . unit v put. modref v modref v;() get. modref v; v modref v; v. set. modref v';() mod \n: t cmp \u00d7 t . t mod mget :(t, t') dis . t. (vc ,v) mod. mod (vc ,v) mod (vc,v); vd mget. mod (vc,v); \nv. pq : unit . (tk,tv) pq ins : tk \u00d7 tv . unit min : unit . tk \u00d7 tv () pq. pq () pq PQ ;(vk ,vv ) ins. \npq PQ +(vk ,vv ); () pq PQ ;() min. pq PQ - (vk ,vv ); (vk ,vv ) Table 1. Formal speci.cation of modi.ables, \nmodular modi.ables, and priority queues. erations (o1,o2,...) in H up to time t, inclusive. We say that \nan element (ti,oi,vi) .H of the operation-trace is inconsistent if vD(H, ti)= vi. We say that an operation-trace \nis inconsistent if any element is inconsistent and consistent otherwise. For a data type D,the traceable \nversion Dr abstractly maintains an operation-trace H for each instance and provides the following operations: \nmk(v) : Returns a new operation-trace H with initial state S0 mk (where v .S0) and empty operation sequence. \n invoke(H, o, t) : Computes v = vD(H, t), updates the operation-trace H by inserting (t, o, v), and returns \nv and the time of the earliest inconsistent operation.  revoke(H, t) : Removes the element with time \nt from H (if any) and returns the time of the earliest inconsistent operation. We refer to invoke and \nrevoke (meta-)operations as revisions  and require them to be applied as part of a revision sequence \na sequence of revisions on an initially consistent operation-trace such that (1) the times of the revisions \nare increasing, and (2) for each revision at time t, all operation at times before t are consistent.2 \nIt may seem odd that revisions only return the earliest incon\u00adsistent operation as opposed to all of \nthem. In fact, this suf.ces because revision sequences require that the earliest inconsistency is .xed \n(revoked and possibly reinvoked) before proceeding to the next one. Fixing the .rst inconsistency will \nthen return the next inconsistent operation, if any. This ability to return inconsistent op\u00aderations \nlazily is critical for ef.ciency because otherwise we would have to maintain a potentially large sequence \nof inconsistent op\u00aderations as some become consistent or others become inconsistent, and we would not \nbe able to take advantage of subsequent revisions .xing inconsistencies. For example imagine invoking \nan additional insert operation on a priority queue inserting an element with higher priority than all \nthe others. This will cause all the rest of operations to become inconsistent. Invoking another deleteMin \noperation subsequently, however, would make all operations con\u00adsistent by removing the newly inserted \nelement. As we formalize in Section 4, a traceable data type can be used to support the underlying data \ntype in self-adjusting computation. This allows a modular way to use new data types without having to \nknow anything about the change-propagation algorithm itself. 3.1 Examples We describe the interface \nof several TDTs. Sample formal speci.\u00adcations of abstract data type are given in Table 1. Modi.ables. \nA modi.able provides the functionality an ML\u00adstyle reference with type constructor t modref and state \ncon\u00adstructor modref v where v is a value of type t . This is what we have 2 Multiple revision sequences \ncan be applied to an operation-trace sequen\u00adtially, each returning the operation-trace to a consistent \nstate before the next starts.  informally referred to as memory cells. Modi.able commands in\u00adclude the \ncreation operation put and manipulation operations get for dereference and set for update. Table 1 shows \nthe signature types and state-transformations. Intuitively, creating a modi.able with contents v and \nthen dereferencing the modi.able multiple times yields an operation-trace with initial state modref v \nand oper\u00adation sequence [(t1, get (),v),..., (tn, get (),v)]. If we change the initial value to v . then \nthe initial state becomes modref v . and the timestamp t1 identi.es the earliest inconsistent operation. \nChange propagation can successively reinvoke each revision to obtain the consistent sequence [(t1, get \n(),v '),..., (tn, get (),v ')]. Modular Modi.ables. In some applications the domain of data may be continuous \neven when the computation produces a discrete result, e.g., a program computing the convex hull of a \nset of mov\u00ading points represented combinatorially. In such a case, using mod\u00adi.ables makes change-propagation \nsensitive to any change forcing recomputation even if the result is the same. In many of these cases, \nwe partition the continuous domain into some discrete number of sets and consider values equal if they \nfall into the same set. For example, we may care only about the sign of a real number. Our motion simulation \nbenchmarks make critical use of modular modi\u00ad.ables for storing the time variable. A modular modi.able \nallows discretizing a totally-ordered con\u00adtinuous set to avoid recomputation when modi.cations don t \naffect the discrete outcome. The type of modular modi.ables is t mod and the state constructor is acc \n(vc,v),where vc is a comparison function of type t cmp(= t \u00d7t .order) (where order is the SML order datatype) \nand v is the value of the modi.able. Modu\u00adlar modi.ables are created by the mod operation and manipulated \nby the modular dereferencing operation mget: A modular derefer\u00adence takes a discretization argument vd \nof type (t, t ') dis which is a (.nite) partition of the continuous type t together with an assign\u00adment \nof values from the discrete type t . to each equivalence class. Formally, the discretization is represented \nby a list [c1,...,cn] that partitions t into intervals and the assignment is a list [d0,...,dn] of t \n. elements. The result of such a dereference is v . = di where the current value of the modular modi.able \nis ci =v<ci+1. Due to the structure of the partition, the outcome of a modular dereference only changes \nwhen the value of the modular modi.\u00adable changes equivalence classes. Priority Queues. A priority queue \nwith tk priorities and tv val\u00adues has type (tk,tv) pq. The state constructor is pq PQ where PQ is a sequence \nof pairs ((vki,vvi))where entry vvi has priority vki. Priority queue commands include the creation operation \npq and manipulation operation ins for inserting an element vv with pri\u00adority vk and min for deleting \nthe element with lowest priority: where PQ +(vk,vv) adds the element vv with priority vk,and PQ -(vk,vv) \nremoves the element vv with highest priority vk. Accumulator Modi.ables. An accumulator modi.able provides \nef.cient change-propagation for adding elements from a commuta\u00adtive group and querying the total. The \nquery must come after all updates. Adding to a (regular) modi.able-based accumulator in\u00advolves fetching \nthe current value of the accumulator and storing the updated sum, which makes the operation sensitive \nto the cur\u00adrent partial sum and thus change-propagation may take linear time in the number of additions. \nAn accumulator modi.able provides a primitive addition operation that is not sensitive to the intermedi\u00adate \nsums and can change-propagate in constant time by using the group s inverse operation to update the result \nof querying a total. Queues and Dictionaries. In addition to the above examples, traceable versions of \nmany other data structures can be speci.ed by giving their state-transformations functions. We have also \nfor\u00admulated and implemented traceable .rst-in-.rst-out queues and un\u00adordered dictionaries.  3.2 Implementing \nTraceable Data Types We brie.y describe how to implement the traceable version of the data types described \nin the previous subsection. In the context of this paper, these descriptions indicate how to implement \nfunctions for signatures such as one in Figure 2. A more complete description of the data types and how \nto implement others can be found else\u00adwhere [3]. The basic idea behind the implementations is to keep \nan augmented version of the operation trace. In particular, most of our structures maintain a data structure \nfor the trace that is or\u00addered by timestamps and supports insert(T, v, t) (insert v at time t), delete(T,t) \n(delete the element at time t), .ndPrev(T,t) (returns the greatest element in T that is less that t)and \n.ndNext(T,t).For a trace with n entries, all these can be implemented in O(log n) time using balanced \ntrees. Some of our traceable data types also maintain balanced trees ordered by keys (e.g., the priority \nqueue, and modular modi.ables). We .rst consider the traceable implementation of a modi.able (a read/write \ncell). Our implementation maintains a time-ordered sequence of operations. Each operation is tagged with \nthe value it has read or written. To invoke a get (read) or put (write) at time t, we insert the operation \ninto the trace data structure at t.If the operation is a get, thenwealsouse .ndPrev(T,t) to access the \nvalue returned by the read the previous element in the trace might either be a get or put, but both types \nof operation are stored with values. Note that a revision sequence requires that all operations before \ntime t are consistent; therefore, the value of this previous element contains the correct value for time \nt.To revoke a get or put at time t, we simply delete the operation from the trace. For all revisions \n(invokes or revokes) we can use .ndNext(T,t) to return the earliest inconsistent operation, if any. In \nparticular, if the next operation is a get and has a different value, then it is inconsistent and is \nreturned, otherwise nothing is returned. All operations on a trace with n elements take O(log n) time. \nThe implementation of dictionaries is based on modi.ables as described in the previous paragraph. Basically, \nwe create a standard hash table, where each entry in the table is a modi.able with its own trace. The \n.rst time an operation is invoked on a particular key k, we create a new modi.able for that key with \nits own trace we refer to this as mk. Any insert of a key-value pair (k, v) into the dictionary at time \nt will correspond to a put of value v into mk at t. Any delete of a key k from the dictionary at time \nt will correspond to a put of value \u00d8into mk at t,where \u00d8is a special value indicating that the dictionary \nhas no entry at that key. Any search of a key k at time t corresponds to a get mk at t. Finally, if a \nrevoke of an operation on key k removes the last operation from the trace of mk, then we can delete mk \nfrom the dictionary (this avoids a memory leak). The implementation of priority queues is beyond the \nscope of this paper, but we note that it can be done with two balanced trees one ordered by time for \nthe trace and the other by key. In addition, during an update sequence, the implementation maintains \ntwo additional balanced trees, one for insertions invoked during the current update sequence and the \nother for insertions revoked during the sequence. All operations take O(log n) time. A modular modi.able \nis implemented by keeping all the boundary elements ci for all mget operations on a modular modi.able \nm sorted by their ordering. We call this Sm. Invoking or revoking a mget operation on m corresponds to \ninserting or deleting the partitioning elements from Sm. Changing the initial value will identify all \npartitions that are crossed by the change of value and return the earliest as inconsistent. An accumulator \nmodi.able is implemented simply by adding to the sum using the commutative operator on an invoke and \nsubtracting from the sum on a revoke. For any value other than the identity, this will return the next \nread as the earliest inconsistent operation.  Finally, we use an order-maintenance data structure [13] \nto implement time stamps. Simpler alternatives such as using integers, .xed-precision .oating-point numbers \ndo not work because they do not allow insertions of new timestamps between two adjacent integers. Arbitrary \nprecision real numbers would work but are not ef.cient.  4. The Tgt Language The .ML language (Section \n2) is compiled into the Tgt language by the .ML compiler. In this section we present the Tgt language \nto show how TDTs can be integrated orthogonally into a language with intrinsic support for self-adjusting \ncomputation. The Tgt language provides both evaluation to reduce expres\u00adsions to values and change propagation \nto adapt computations to input changes, and is open-ended to extension by any TDT.The semantics of the \nTgt language uses traces to capture the struc\u00adture of the computation, which are used by change-propagation \nto identify the need for recomputation and the opportunity for com\u00adputation reuse. The former approach \nto self-adjusting computation used trace actions that correspond to individual memory operations. To \nsupport TDTs, the new approach to self-adjusting computation uses trace actions that correspond to high-level \nTDT operations. The invoke and revoke operations of TDTs are used by the seman\u00adtics of the Tgt language \nto identify which parts of a computation, i.e., which actions of the trace, are affected by changes. \nThe Tgt language is a simply-typed .-calculus with natural numbers and recursive functions3, extended \nwith a memoization primitive and any number of traceable data types (TDTs). The syntax of Tgt is given \nby the following grammar, which de.nes types t , expressions e,values v, and adaptive commands .,using \nidenti.er metavariables f and x. t ::= res | nat | tx . t | t tdt e ::= v | caseN vn ez (x.es ) | ef \nvx v ::= x | zero | succ v | fun f .x.e | i | . . ::= halt v | memo e | mk vmk vk | op vl varg vk Tgt \nenforces a continuation-passing style (CPS) discipline to help identify opportunities for reuse and computations \nfor re-execution.4 The type res is an opaque answer type for continuations, while halt is a continuation \nthat injects a .nal value into the res type. The CPS discipline allows pure computations (e.g., natural \nnum\u00adbers and recursive functions) to be introduced by values and elim\u00adinated by expressions, with the \ncaseN scrutinee and function ap\u00adplication argument restricted to be values. The caseN primitive case-analyzes \na natural number vn and branches to ez or es ac\u00adcording to whether it is zero or a successor number. \nThe mk and op primitives correspond to schematic TDT operations with an ex\u00adplicit continuation vk.The \nmk primitive creates a TDT initialized by the seed value vmk, while the op primitive takes the a reference \nvl to a TDT and argument value varg. Since adaptivity identi.es the need for recomputation, Tgt pro\u00adgrams \nuse an indirection through the store to manipulate TDTsand isolate the differences between computations. \nWe take a store s to bea.nite mapfrom locations f to TDT state constructors S;the notation s[f .S] denotes \nthe store s updated with f mapped to S. Contexts G and S,and TDT signatures . are maps from variables, \nlocations, and TDT commands to types, respectively. The Tgt language is open-ended to extension by any \nnumber of TDTs. As described in Section 3, a TDT is classi.ed by a type t tdt and has a state constructor \nS. Furthermore, each TDT extends the language with a creation command mk vmk vk and 3 The Tgt language \nmay easily be extended with products, sums, recursive types, etc.; we have omitted such constructs as \nthey provide no additional insight, but are supported by the implementation. 4 Previous work shows how \nto compile a direct-style language into this continuation-passing style [19]. any number of manipulation \n(i.e., queries and updates) commands op vl varg vk; TDT commands are formulated in CPS with an ex\u00adplicit \ncontinuation vk identifying the computation that follows the command and manipulation commands take a \nlocation argument vl. The typing judgement S; G fe : t (rules elided) ascribes the type t to the expression \ne in the contexts G and S. TDT commands have type res if their arguments match the types prescribed by \nthe TDT signature. A creation command mk must have an argument vmk of type tmk and a continuation vk \nexpecting a t tdt.A manipulation command op must have a location argument vl of type t tdt, an argument \nvarg of type targ, and its continuation vk should expect a tres. Figure 6 gives the evaluation semantics \nof Tgt.The large\u00adstep evaluation relation T.; s; e .E T '; s'; v' (resp. T.; s; . .K T '; s'; v') reduces \nthe expression e (resp. the adaptive command .) under the store s to the value v' and the updated store \ns'.For the present time, we suggest that the reader ignore the T.and T ' components; we discuss them \nin detail in Section 4.1. The auxil\u00adiary evaluation relation e .v' reduces an expression e to a value \nv'; such evaluation is pure and independent of the store. A mk vmk vk creation command (mk) generates \na TDT state S' with seed vmk according to the state-transformation semantics, extends the store s with \na fresh location f bound to S', and delivers f to the continuation vk.An op fvarg vk manipulation command \n(op) fetches the TDT state S from the store s at f, performs the corresponding state-transformation, \nupdates the store with f bound to the new state S', and delivers the result vres to the continua\u00ad mk \n\u00a3op \u00a3 tion vk. For the present time vmk ; T..S'; T.' and S; varg; T.. S'; vres; T.' (discussed in detail \nin Section 4.1) should be read as the mkop state-transformation judgements vmk .S and S; varg .S'; vres. \nA memoized expression memo e simply evaluates the expres\u00adsion when evaluated from scratch (memo/miss), \nbut enables the reuse of computations across runs during change-propagation (Sec\u00adtion 4.1). The halt \nv command yields a computation s .nal result value. 4.1 Change Propagation In order to update a program \ns output in response to changes in its input, a change-propagation mechanism is employed to re-execute \nthe portions of the computation affected by the changes and to reuse the unaffected portions. The evaluation \nrelation records information necessary for change-propagation in a trace T , a sequence of TDT state \nand memo actions terminated by a halt action: As ::= mkvmk .\u00a3 | op \u00a3,varg .vres vk vk D D ::= .| . e \nA ::= As | memo T ::= haltv | A\u00b7T . T ::= .| T The evaluation relation T.; s; e .E T '; s'; v' (resp. \nT.; s; . .K T '; s'; v') may now be interpreted as reducing the expression e (resp. the command .) under \nthe store s and the (optional) reuse trace T. , yielding the value v', the updated store s', and the \ncompu\u00adtation trace T ' for the current run. The evaluation of each command extends the computation trace \nwith the corresponding trace action labeled by the relevant argu\u00adments and results. A halt action carries \nthe .nal result value and a memo action carries the memoized expression. A creation action records the \nseed value, the location allocated, and the continuation. In order for the semantics to identify the \npossibility of computation reuse, each TDT manipulation action records the location accessed, the argument \nand result values, and the continuation; the action is additionally labeled by a checkmark 0 to indicate \nits replayabil\u00adity during change-propagation. Furthermore, the dynamic seman\u00adtics maintains consistency \nof the reuse trace, i.e., the pre.x trace  ez . v [vn /x]es . vef . fun f .x.e [vx /x][fun f .x.e/f \n]e . v v . v caseN zero ez (x.es ) . v caseN (succ vn ) ez (x.es ) . vef vx . v mk \u00a3 '' i/. dom svmk \n; T.. S ; T. .'' ' ] T. '' ; s '' e . .T ; s; . .K T ; s ' ; vsl = s[i . S ; sl ; vk i .E T ; v '' .vmk \n.\u00a3 '' T.; s; e .E T ; s ' ; vT ; s; mk vmk vk .K mk\u00b7T ; s ' ; v vk .'' m op \u00a3 '' s(i)= SS; varg ; T.. \nS ; vres ; T.' ].' '' sl = s[i . S T ; sl ; vk vres .E T ; s ' ; v mk \u00a3,varg .vres '' T.; s; op ivarg \nvk .K op \u00b7T ; s ' ; v op vk . '' T ; s; e .E T ; s ' ; vs; T ; e . Te Te ; s f T ; s ' ; v memo/miss \nmemo/hit e '' e '' T.; s; memo e .K memo \u00b7T ; s ' ; vT ; s; memo e .K memo \u00b7T ; s ' ; vT.; s; halt v \n.K haltv; s; v '' '' Figure 6. Reduction e .v (top) and evaluation T.; s; e .E T ; s ' ; v and T.; s; \n. .K T ; s ' ; v (bottom). of actions with a valid checkmark .are replayable by change\u00ad propagation and \nthe earliest (if any) manipulation action with an invalid checkmark .must be re-executed by change-propagation. \nThe trace reparation and operation invocation judgements (Fig\u00adure 7) use the state-transformation rules \nto maintain trace consis\u00adtency. rep \u00a3 The trace reparation judgement S; T..T.' takes a TDT state S at \nlocation f and an optional reuse trace T.(with possible incon\u00adsistencies in actions that manipulate f) \nto produce the consistent optional trace T.' . Intuitively, trace reparation identi.es the earliest inconsistent \naction that manipulates f and marks it with an invalid checkmark. A halt action isn t subject to any \nrepair. Any action that does not manipulate f is preserved and the tail of the trace is recursively repaired \n(rep/indep). For any action that manipu\u00adlates f, the state-transformation is simulated on the TDT state \nS. If the state-transformation produces the same answer, the action re\u00adceives a valid checkmark .and \nthe tail of the trace is recursively repaired with the simulated new TDT state S ' (rep/.). Otherwise \nthe action receives an invalid checkmark .and the resulting trace is consistent (rep/.). mk \u00a3' ;.op \u00a3 \nThe invocation judgements vmk ; T..S T ' and S; varg; T..S ' ; vres; T.' use the corresponding state-transformation \njudgements for creating and manipulating TDT state. Furthermore, since in\u00advoking the operation may affect \nthe consistency of actions in the reuse trace T.(if any) that manipulate location f, the trace repa\u00adration \njudgement is used to maintain the consistency of the reuse trace (mk/invoke and op/invoke). Hence, the \nmk and op evaluation rules use the invocation judgements to perform the state\u00adtransformation and preserve \ntrace consistency; moreover the ma\u00adnipulation action is labeled by a valid checkmark because it is consistent \nwith the rest of the execution trace. The memo/miss rule evaluates a memoization expression memo e and \nyields a trace memo e \u00b7T ' ,where T ' is the trace of the evaluation of e. A present reuse trace T is \nitself a computation trace from a previous evaluation and is supplied to change-propagation to guide \nthe update. In particular, evaluation may reuse computations memoized in the previous evaluation: the \nmemo/hit evaluation m rule uses the memoization judgement s; T ; e . Te (Figure 8) to .nd a reuse trace \nTe that corresponds to a previous run of e (under a (possibly) different store) and switches to change-propagating \nTe under the current store. Note that while the expression e may have free locations, the memoization \njudgement is independent of the store. Hence, the rule switches to change-propagating Te under the current \nstore to correct any invalid actions in the reuse trace Te. m The memoization judgement s; T ; e . Te \nsearches the reuse trace T for a suf.x trace Te that follows a memoization action memo e; since some \nactions may be discarded from the reuse trace T , the remaining tail of the trace needs to be made consistent \nrelative to the current store s. A matching memo action (hit) returns the tail of the trace for change-propagation. \nMemo and TDT state actions can be discarded by proceeding to match the tail of the trace. Discarding \na memo does not affect the consistency of the trace because it does not touch the store. Discarding a \ncreation action of location f or a manipulation action on a location f that is not in the store does \nnot affect the consistency of the trace because the location ceases to be in the store; if the location \nis later re-allocated during evaluation (mk), then the reuse trace will be made consistent by the invocation \njudgement. A manipulation \u00a3,varg.vres action opvkD on a location f that is in the store (op/rev) must \nbe explicitly revoked because it will no longer be performed, thus the tail of the trace must be repaired \nrelative to the current state S = s(f). Turning to the change-propagation relation (Figure 8), recall \nthat we interpret T ; s r T ' ; s ' ; v ' as replaying the computation trace T under the store s, yielding \nthe value v ' , the updated store s ' , and the updated computation trace T ' . Replaying a halt ac\u00adtion \nyields the (unchanged) computation result. Replaying a mem\u00adoization action recursively change-propagates \nthe tail of the trace. Whenever change-propagation is recursively applied, the updated computation trace \nis extended with an appropriate action. A cre\u00ad vmk.\u00a3 ation operation mkvk is consistent with the current \nstore if f/.dom s and can thus be replayed (mk/reuse) by regener\u00adating the TDT state S ' with seed vmk \n, extending the store with f bound to S ' , and recursively change-propagating the tail of the \u00a3,varg.vres \ntrace. A manipulation operation opvkD is consistent with the current store if it has a valid checkmark \nand thus can be replayed (op/reuse) by reexecuting the state-transformation to yield, by invariant, the \nsame result vres, updating the store with f bound to the new state S ' , and recursively change-propagating \nthe tail of the trace. Change-propagation falls back to execution either nondetermin\u00adistically or because \nthe head action is inconsistent with the current store and thus not replayable. A creation operation \nis inconsistent if the location is already in the store and a manipulation operation is inconsistent \nif it has an invalid checkmark. Since actions capture their continuation, a trace T can be rei.ed back \ninto an command iT lthat represents the rest of the computation: e ihaltvl = halt v imemo \u00b7T l = memo \ne vmk .\u00a3 \u00a3,varg .vres imkvk \u00b7T l = mk vmk vk iopvk D \u00b7T l = op ivarg vk Thus, change-propagation can \nreify and re-evaluate an inconsistent trace T (change), while keeping the trace T for possible reuse \nlater. Note that the rei.ed mk (resp. op) command forgets the (stale) location (resp. result value). \nWe can now sketch the use of change-propagation by a host pro\u00adgram that (re-)evaluates a self-adjusting \ncomputation. Suppose we have a Tgt program e such that S; \u00b7fe : res and an initial store s0 such that \nfs0 :S lS0. Thus, we may (initially) evaluate e under  rep \u00a3 \u00a3,varg .vres ' A S; T = op . T vk D rep/indep \nrep \u00a3 rep \u00a3 rep \u00a3 ' S; ... S; haltv . haltv S; A\u00b7T . A\u00b7T oprep \u00a3 op ' '' ''' S; varg . S ; vres S ; \nT . T S; varg . S ; vv = vres res res rep/. rep/. rep \u00a3 rep \u00a3 \u00a3,varg .vres \u00a3,varg .vres ' \u00a3,varg .vres \n\u00a3,varg .vres S; op \u00b7T . op \u00b7T S; op \u00b7T . op \u00b7T vk D vk D vk . vk . mkrep \u00a3 '' .' vmk . SS ; T.. T mk/inv \nmk \u00a3 '' vmk ; T. . S ; T.op'' ;.rep \u00a3 .' S; varg . S ; vres S T . T op/inv op \u00a3 '' S; varg ; T.. S ; \nvres ; T. rep \u00a3 mk \u00a3 op \u00a3 .' '' '' Figure 7. Trace reparation S; T..T (left) and invocation vmk ; T. \n.S ; T. and S; varg ; T. .S ; vres ; T. (right). op/rev s(i)= S i/. dom s m rep \u00a3 m mm '' s; T ; eTe \ns; T ; eTe s; T ; eTe S; T . Ts; T ; eTe e m hit e' m vmk .\u00a3 m \u00a3,varg .vres m \u00a3,varg .vres m s; memo \n\u00b7T ; eT s; memo \u00b7T ; eTe s; mk\u00b7T ; eTe s; op \u00b7T ; eTe s; op \u00b7T ; eTe vk vk D vk D mk ' i/. dom svmk . \nS '' '' T ; s f T ; s ' ; vsl = s[i . S ' ] T ; sl f T ; s ' ; v mk/reuse ee '' vmk .\u00a3vmk .\u00a3 '' haltv; \ns f haltv; s; v memo \u00b7T ; s f memo \u00b7T ; s ' ; v mk\u00b7T ; s f mk\u00b7T ; s ' ; v vk vk op ' s(i)= SS; varg . \nS ; vres '' sl = s[i . S ' ] T ; sl f T ; s ' ; v '' op/reuse iT l = .T ; s; . .K T ; s ' ; v \u00a3,varg \n.vres \u00a3,varg .vres '' change op \u00b7T ; s f op \u00b7T ; s ' ; v '' vk . vk . T ; s f T ; s ' ; v ' '' Figure \n8. Memoization s; T ; e m T (top) and change-propagation T ; s r T ; s ' ; v (bottom). the store s0 and \nan empty reuse trace, yielding the (initial) result ' ''' v0 and a computation trace T0: .; s0; e .E \nT0; s0' ; v0.Now,sup\u00adpose we have a modi.ed store s1 such that fs1 :S lS1.We are interested in the result \nv1 ' yielded by (re-)evaluating e under s1.To obtain v1' , we may change-propagate the trace T0 ' under \nthe store ' '' s1: T0; s1 r T1; s1' ; v1. The correctness of change-propagation asserts that the v1' \n, s1' ,and T1 ' obtained via the change-propagation relation could also have been obtained via the evaluation \nrelation: .; s1; e .E T1' ; s1' ; v1' . Hence, change-propagation suf.ces to de\u00adtermine the output of \na program on changed inputs.  5. Extensions to .ML We extended the .ML language to support TDTs and \nimple\u00admented a number of traceable data structures (as speci.ed in Sec\u00adtion 3). The .ML language is implemented \nas an extension to the MLton compiler and a library for self-adjusting computation imple\u00admented in Standard \nML. Our extensions to .ML consist of some small modi.cations to the change-propagation implementation \nand a mechanism for integrating TDTs with change propagation. Like earlier implementations of change \npropagation, we use a totally ordered set of timestamps to represent trace elements, which now include \nthe TDT operations. Each TDT is implemented as a Standard ML module (see Sec\u00adtion 3.2) but integrated \nwith the library for self-adjusting compu\u00adtation through the use of boilerplate code. For each invoke \nopera\u00adtion, we create a timestamp, essentially making the operation an el\u00adement of the trace. When the \nchange-propagation algorithm deletes a timestamp, we revoke the operation that is associated with that \ntimestamp. During change-propagation, trace elements that need re-evaluation are stored in a queue prioritized \nby their timestamps, including the inconsistent operations of all TDTs. Since the set of inconsistent \noperations dynamically changes over time as a result of invokes and revokes, we adjust the priority queue \ndynamically to maintain the correct set of inconsistent operations. Benchmark Data Types Used hsort-int \ndot-product intersection hu.man stabbing graham-scan dijkstra bfs Motion Simulation priority queue accumulator \ndictionary priority queue priority queue, counter priority queue priority queue, dictionary queue, dictionary \nmodular modi.able Table 2. Summary of data types used in our benchmarks. Every self-adjusting program \nalso use the modi.able data type.  6. Experiments We empirically investigate the performance of the \nproposed ap\u00adproach. We use a set of diverse benchmarks to compare the space usage and time performance \nof programs using TDTsto thatof programs using standard, modi.able-based implementations. The results \nshow that traceable data structures signi.cantly help im\u00adprove speed and reduce memory consumption. To \nunderstand the source of this performance improvement, we study how tracing at the granularity of data-structuring \noperations affects the trace size and stability. Our .ndings suggest that tracing operations on data \nstructures helps reduce the trace size and improve stability by asymptotic factors. In Section 7, we \ndemonstrate the utility of the proposed approach to motion simulation. 6.1 Benchmarks We developed a \nset of benchmark to study the performance char\u00adacteristics of the proposed approach. Each benchmark is \nspeci\u00ad.ed by a static algorithm s description. Based on this description, we implemented three versions: \n(1) a static program ( static ), (2) a self-adjusting program that does not utilize TDTs ( modref\u00adbased \n), and (3) a self-adjusting program that makes use of TDTs whenever appropriate ( traceable ). In developing \nthe test suite, we .rst implemented the static program and transformed it into a self-adjusting program \nusing approaches taken in previous work. The traceable version is identical to the modref-based version, \nex\u00adcept the traceable version makes calls to traceable data structures whereas the modref-based version \nmakes calls to modref-based im\u00adplementations of data structures. We summarize in Table 6.1 the data types \nused in each benchmark.  Heap sort (hsort-int): sort an integer list using the standard heap sort algorithm. \n Dot product (dot-product): compute the dot product of two real-number vectors represented as a list \nof ordered pairs, by .rst computing the product for each component and using an accumulator to compute \nthe sum.  List intersection (intersection): compute the intersection of lists f1 and f2, by inserting \nthe elements of f1 into a dictionary and selecting the elements of f2 that are present in the dictio\u00adnary. \n Huffman code (hu.man): construct a Huffman tree for a list of keys and frequencies using the standard \nHuffman algorithm.  Interval stabbing (stabbing): take as input a list of intervals I = {[ai,bi)}n and \na list of queries Q = {qj }mj=1,and i=1 report for each query qj how many intervals this query stabs \n(i.e., the size of the set {(ai,bi) .I : ai =qj <bi}). We present a plane-sweep algorithm: First, insert \ninto a priority queue the endpoints of all the intervals and the query values, known as events, and set \ninitialize a counter c to 0. Then, to answer queries, consider the events in an increasing order of their \nvalues, incrementing the counter on a left endpoint, decrementing it on a right endpoint, and outputting \nthe counter value on a query.  Graham Scan (graham-scan): compute the convex hull of a set of points \nin 2D using the Graham s scan algorithm (more in Section 6.8).  Dijkstra (dijkstra): compute the shortest-path \ndistances in a weighted graph from a speci.ed source node using Dijkstra s algorithm and output a dictionary \nmapping each node to its distance to the source.  Breadth-First Search (bfs): perform a breadth-.rst \nsearch, which computes the shortest paths in an unweighted graph from a speci.ed source node and outputs \na dictionary mapping each node to its distance to the source.   6.2 Modref-based Data Structures We \nimplemented modref-based data structures for every data type used in the benchmarks. These implementations \nmay not be the best one can obtain using modi.ables alone, but they are reason\u00adable baselines because \nwe believe they are representative of what a programmer with signi.cant background in self-adjusting \ncom\u00adputation would come up with after some optimization. The accu\u00admulator data structure is implemented \nby maintaining a modi.able list and running a self-adjusting fold operation to obtain the so\u00adlution. \nBoth the dictionary and priority queue data structures are implemented using the Treap data structure. \nFor priority queues, we found that Treap is more stable than common alternatives (e.g., leftist heap, \nbinary heap). The queue data structure is obtained by essentially transforming a standard purely functional \nimplementa\u00adtion of a queue, one which maintains two lists; however, we are especially careful about when \nthe front list is reserved to enhance stability. 6.3 Input Generation We use randomly generated data \nsets for all the experiments. Let n be the target input size. For the sorting benchmarks, we generate \na random permutation of {1, 2,...,n}.For dot-product, we gener\u00adate random vectors by picking .oating-point \nnumbers uniformly at random from [0.0, 10.0] (with 5 signi.cant digits). For inter\u00adsection, We generate \na pair of lists of lengths n and m by pick\u00ading integers uniformly at random from the set {0,...,t},where \nt = 1 min{n, m}; this choice of t ensures that the two lists have a 4 common element with high probability. \nFor hu.man, the alphabets are simply the numbers 1 to n, and the frequencies are random in\u00adtegers drawn \nfrom the range [1, 10n].For stabbing, the endpoints and query values are random numbers in the range \n[0,n/10] cho\u00adsen uniformly at random. For convex hulls, we generate inputs by drawing points uniformly \nfrom the circumference of a unit-radius circle. This arrangement is known to be a challenging pattern \nfor many convex-hull algorithms. For our graph benchmarks, we gen\u00ad v erate random, connected graphs with \napproximately n-separators, mimicking the fact that many real-world graphs have small separa\u00adtors (e.g., \nn 1-e). 6.4 Metrics and Measurements The metrics for this study are (1) the time to run a program from \nscratch, denoted by Ti (2) the average update time after a modi.\u00adcation, denoted by Tu,and (3) the space \nconsumption, denoted by S. To measure the second metric, for example, in list-based experi\u00adments, we \napply a delete-propagate-insert-propagate step to each el\u00adement (i.e., in each step, delete an element, \nrun change-propagation, insert the element back, and run change-propagation) and divide the end-to-end \ntime by 2n,where n is the list s length. This quantity represents the expected running time of change-propagation \nif a random update to the input is performed. We can use this measure\u00adment in graph experiments, where \nhere the delete-propagate-insert\u00adpropagate is applied to each edge in turn. All measurements were taken \non a standard Linux machine5. We measure the space consumption by noting the maximum amount of live data \nas reported by .ML s garbage collector. This is an approximation of the actual space usage because garbage \ncollection may miss the high-water mark. When measuring time, we carefully break down the execution time \ninto application time and garbage collection (GC) time. In these experiments, we have found that GC is \nat most 20%of the execution time. For this reason, we only report the application time to isolate the \nGC effects and highlight the asymptotic performance.  6.5 Modref-based Programs vs. Traceable Programs \nThe .rst set of experiments studies how TDTs provide the perfor\u00admance bene.ts over traditional, modref-based \nimplementations. Re\u00adcall that Ti is the time to run a program from scratch and Tu is the average time \nthat change propagation takes to perform an update. Table 3 shows the performance of our benchmark programs, \ncom\u00adparing the traceable versions to their modref-based counterparts. Note that for graham-scan, the \nmodref-based program uses merge sort whereas the traceable program uses heap sort; the modref\u00adbased version \nof heap sort is too slow except for extremely small inputs. We explore this in more detail in Sections \n6.8 and 6.9. We .nd that compared to the modref-based programs, the trace\u00adable versions are 3 20 times \nfaster to run from scratch and 4 5000 times faster to perform an update. Moreover, traceable versions \ncon\u00adsume 4 50 times less space than the modref-based ones. We remark that these experiments involve relatively \nsmall input sizes because with larger inputs our experiments with some modref-based appli\u00adcations require \ntoo much time to complete. 5 Technical Setup: Our experiments were conducted on a 2.0Ghz Intel Xeon E5405 \nwith 32 GB of memory running Ubuntu 8.04 (kernel 2.6.24\u00ad19). Programs were compiled using the .ML compiler \n[19], a modi\u00ad.ed version of the MLton compiler version 20070826, with the option -runtime ram-slop 0.9 \ngc-summary These options direct the run\u00adtime system to make available 90% of the physical memory to the \nbench\u00admark and report statistics about garbage collection (GC).  Experiment Size Traceable Modref-based \nModref-based \u00f7Traceable NTi (ms) Tu (\u00b5s) S (MB) Ti (ms) Tu (\u00b5s) S (MB) Ti Tu S hsort-int 103 7.50 35.00 \n0.61 85.00 27695.00 14.04 11.33 791.28 23.02 dot-product 105 280.00 6.75 52.88 872.50 121.55 223.80 3.11 \n18.00 4.23 intersection 105 1372.50 82.00 382.78 11207.50 1948.45 1509.17 8.16 23.53 3.94 hu.man 104 \n157.50 492.00 22.13 2575.00 2530000.00 707.61 16.34 5142.28 31.98 stabbing 103 17.50 115.00 1.92 240.00 \n98195.00 23.56 13.71 853.87 12.27 graham-scan 104 375.00 265.50 24.90 1542.50 1105.50 277.24 4.11 4.16 \n11.13 bfs 103 37.50 845.56 2.74 717.50 23784.07 139.39 19.13 28.12 50.82 dijkstra 103 42.50 1160.03 2.74 \n725.00 34528.30 72.41 17.05 29.76 26.42 Table 3. Traceable vs. modref-based implementations: Ti (in ms) \nis the from-scratch execution time, Tu (in \u00b5s) is the average time per update, and S (in MB) is the maximum \nspace usage as measured at garbage collection. Experiment Size Traceable Static Overhead Speedup NTi \n(ms) Tu (\u00b5s) S (GB) Ti (ms) (SAC Ti)/(static Ti) ((static Ti)/SAC Tu hsort-int 106 14390.00 59.02 1.75 \n2599.75 5.54.4 \u00d7104 dot-product 106 2787.50 7.45 0.44 100.25 27.80 1.3 \u00d7104 intersection 106 12820.00 \n74.91 2.19 1091.50 11.74 1.5 \u00d7104 hu.man 106 22975.00 1021.04 1.08 6447.25 3.56 6.3 \u00d7103 stabbing 106 \n38832.50 202.11 1.70 10609.75 3.60 5.2 \u00d7104 graham-scan 105 4307.50 297.30 0.70 547.75 7.86 1.8 \u00d7103 \nbfs 104 445.00 1310.59 0.12 47.50 9.36 36.2 dijkstra 104 490.00 1783.68 0.12 52.50 9.33 29.4 Table 4. \nTraceable SAC versus static: Ti (in ms) is the from-scratch execution time, and Tu (in \u00b5s) is the average \ntime per update. Update times are reported in microseconds (\u00b5s). 6.6 Traceable Programs vs. Static Programs \nOur second set of experiments, shown in Table 4, draws a com\u00adparison between traceable programs and static \nprograms, quantify\u00ading the effectiveness of the approach in more absolute terms. First, consider the \noverhead column, calculated as the ratio of the from\u00adscratch run of the traceable implementation to that \nof the static implementation. This quantity represents the overhead of the pro\u00adposed approach (e.g., \ndue to dependence tracing, runtime system). We .nd the overhead to relatively small: the traceable versions \nare about a factor of 10 slower than their static counterparts, except for dot-product, which is about \n30 time slower. We believe this is because the benchmark dot-product is relatively lightweight com\u00adputationally. \nSecond, consider the speedup column, calculated as the ratio of the static from-scratch run time to the \nupdate time. Results show that the traceable versions can perform updates many orders of magnitude faster. \nOne exception is our graph algorithms, which are output-sensitive and may need to update the results \nat many nodes even after a small modi.cation, e.g., deleting a single edge can change the shortest distance \nof many nodes. We discuss this in greater depth next.  6.7 Graph Algorithms Graph algorithms can be \nchallenging with previous approaches to SAC. We discuss how TDTs can help overcome some of these challenges. \nWhile previous SAC approaches worked well on prob\u00adlems with structured data (e.g., lists and trees), \ncomputations involv\u00ading unstructured data (e.g., graphs) often require use dynamic data structures whose \ntraditional self-adjusting versions can require the tracing and updating of large amount of dependencies. \nTraceable data types address this problem by reducing the amount of required tracing and exploiting problem-speci.c \nstructures, thereby dramat\u00adically decreasing the update time. From-Scratch Run: Time (in ms) 1000 800 \n600 400 200 0 Figure 9. From-scratch runs with our graph benchmarks: timing (vertical axis in ms) as \ninput size (horizonal axis) varies. Comparing Avg. Update Time (in ms) 50 40 30 20 10 0 Figure 10. Updates \nwith our graph benchmarks: timing (vertical axis in ms) as input size (horizonal axis) varies.   From-Scratch \nRun: Time (in ms) Comparing Avg. Update Time (in ms) Comparing Avg. Update Time (in ms) 0 5 10 15 20 \n0 5 10 15 20 0 5 10 15 Trace Size (in thousands): hsort traceableTrace Size (Normalized by hsort traceable) \nAvg. Trace Difference (log scale) 14 12 10 8 6 4 2 0  20 15 10 5 0  107106 105 104 103 102 101 100 \n Figure 12. Trace size (in thousands of trace elements) and average trace difference (in trace elements \non a log scale) of sorting benchmarks as input size is varied: trace size of traceable heap sort (left), \ntrace size of quick sort and modref-based heap sort as normalized by the trace size of traceable heap \nsort (center), and average trace difference (right). We consider two algorithms: the Dijkstra s single-source \nshort\u00adest path algorithm (dijkstra) and the classic breath-.rst-search al\u00adgorithm (bfs). Our implementations \nfollow the standard textbook descriptions (Figure 5 shows the pseudo-code for dijkstra). Both algorithms \nuse a dictionary to represent a graph. Figures 9 and 10 contrast the performance of traceable versions \nof shortest-path algorithms with that of the traditional, modref\u00adbased versions. Figure 9 shows from-scratch \nexecution times of dijkstra and bfs. Both perform similarly, and their traceable ver\u00adsions are signi.cantly \nfaster than their traditional versions, by more than an order of magnitude at peak. Figure 9 shows the \naverage up\u00addate times for an edge deletion/insertion. Again, both benchmarks perform similarly and the \ntraceable versions are signi.cantly faster than the traditional, by approximately an order of magnitude \nat N =1, 000. We note that both dijkstra and bfs are highly output sensitive al\u00adgorithms. Since inserting/deleting \nan edge can change the shortest\u00adpath distances on a large number of nodes, these benchmarks are highly \noutput sensitive. Speci.cally, if the shortest-path distances change on t nodes, both benchmarks will \nneed to update all t nodes, requiring at least O(t) time.  6.8 Sorting and Convex Hulls Another noteworthy \nfeature of the TDT framework is modularity, speci.cally the fact that we can often enjoy substantial \nperformance improvements by simply replacing the modref-based implementa\u00adtions of data structures with \nthe compatible traceable versions. As an example, consider the problem of computing the convex hull of \n2D data points. Given a set of 2D points, Graham s scan algorithm .rst orders the points by the x coordinates \nand computes the con\u00advex hull by scanning the sorted points. Here we compare the trace\u00adable version of \nour heap sort (hsort)and graham-scan benchmarks with other modref-based algorithms considered in previous \nwork. The fastest version turns out to be identical to the old graham-scan code, except the sort routine \nis now a traceable heap sort. As shown in Figure 11 (left and center plots), traceable heap sort outperforms \nthe quick-sort and merge-sort algorithms by nearly an order of magnitude for both from-scratch runs and \nupdates. Since graham-scan uses sorting as a substep, it shows the same perfor\u00admance trends (rightmost \nplot). Compared to the previous modref\u00adbased implementation of the quick-hull algorithm [8], graham\u00adscan \nis extremely fast.  6.9 Trace Size and Stability Our empirical measurements thus far illustrate the \nperformance bene.ts of TDTs, both in running time and space consumption. Here we investigate the question \nof whether these improvements are related to potential constant factor improvements in the run\u00adtime systems \nor to the bene.ts of TDTs as we expect them to be. Our measurements suggest the latter and indicate asymptotic \nim\u00adprovements in performance. To this end we consider two abstract measures: trace size and trace stability. \nTrace size measures the size of the memory consumed. Trace stability measures how much the trace changes \nas a result of an input modi.cation this ultimately determines how fast the program can respond to modi.cations. \nIn our experiments, we measure the trace size by the number of trace elements, and the trace stability \nby counting the average number of trace elements created and deleted during change propagation after \na single insertion/deletion. These measures are independent of the speci.cs of the hardware as well as \nthe speci.cs of the data structures used for change propagation they only depend on the abstract representation \nof the trace. They are, however, speci.c to the particular self-adjusting program and the class of input \nchanges considered. As an example, we consider here sorting with inte\u00adgers, speci.cally hsort-int, with \ntraceable and modref-based pri\u00adority queues, and a self-adjusting implementation of quicksort. Figure \n12 (leftmost) shows the trace size for traceable heap sort as the input size increases. Regression analysis \nshows a perfect .t with 10n +12 (n is the input size), providing strong evidence that the trace size \nof traceable heap sort is O(n). This is consistent with  Event-based simulation with up to 15000 points \nSpeedup: From Scratch Run / Update Kinetic simulation with 5000 points 6 800 700 700 5 600 600 4 500 \n 400 500 3 300 2 200 400 100 300 1 0 Figure 13. Left: Time per kinetic event. Center: Speedup for an \nupdate. Right: Total simulation time (seconds) with time-slicing.   a simple analytical reasoning on \ntraces: since we record dependen\u00adcies at the level of priority-queue operations and since heap-sort performs \nlinear number of such operations, the trace has linear size. Figure 12 (center) shows the trace size \nof hsort-int using both traceable and modref-based priority queues normalized to the trace size of the \ntraceable heap sort. The .gure suggests that the traces of traceable heap sort are by a factor of T(log \nn) smaller than those of the modref-based. This explains why traceable heap sort has a signi.cantly smaller \nmemory footprint than the modref-based counterpart. Figure 12 (right) shows our measurements of average \ntrace difference on a vertical log scale for a single insertion/deletion. Trace difference is constant \nfor traceable heap sort, because a single insertion/deletion requires inserting/deleting a single priority \nqueue operation from the trace. The modref-based implementation heap sort appears to have super-logarithmically \nlarger trace difference. The reason for this is the internal comparisons traced by the modref\u00adbased priority \nqueues. This .nding explains the difference in the runtime performance between the two implementations \nof heap sort. Figure 12 also compares the traceable heap sort to our self\u00adadjusting quicksort implementation, \nwhich, until now, has been the most ef.cient self-adjusting sorter. Traceable heap sort appears faster \nby at least a moderate constant factor.  7. Motion Simulation With traceable data types, programs can \nnatively and safely handle continuous-domain input, so that the output may be updated ef.\u00adciently when \nthe input changes. We consider motion simulation as an interesting application of this capability. Consider \na program P that computes a geometric property (e.g., convex hull) of a given set of static objects (e.g., \npoints). In motion simulation, we want to compute the output of P as the objects move continuously, i.e., \nwhen each coordinate is a function of time . Motion simulation can be performed by time slicing and recomputing \nthe output at .xed intervals. This approach, however, is inaccurate because it only approximates the \ntimes at which the output changes, and inef\u00ad.cient because it cannot take advantage of the similarity \nof output at consecutive intervals. With no advance knowledge of how points move, time slicing can be \nthe only option. In some cases, however, we can represent the coordinates of moving objects with polynomi\u00adals \nof time and compute exactly the times at which the output can change by .nding the roots of certain polynomials \n(e.g., [7]). We call this an event-based simulation. We implement a library for motion simulation by \nusing both event-based and time-slicing simulation techniques while taking advantage of self-adjusting \ncomputation to update the output. The library allows the time to be set arbitrarily and uses change\u00adpropagation \nto update the output. We use modular modi.ables (Sec\u00adtion 3) to represent outcomes of geometric tests. \nThe library consist of 3, 200 lines of .ML code supplying primitives for polynomi\u00adals, geometric operations, \nand performing motion simulation. As benchmarks, we implement self-adjusting versions of several 2D convex \nhulls algorithms and one 3D convex hull algorithm called incremental-hull algorithm. We also implement \na visualizer that helps us observe motion simulations in real time by simultaneously running the visualizer \nand the self-adjusting program performing the simulation. Some example movies can be found on the web \nsite http://sites.google.com/site/sacmotion/ . Figure 13 shows some experimental results with 3D hulls \nusing event-based approach. For both .gures the horizontal axis is the input size consisting of points \n(up to 15000). The plot on the left shows the average time to update the output by change propagation \nafter changing the time in an event-based simulation (average taken over n updates for each input size \nn). The update time appears to grow slowly (poly-logarithmically) with the input size. The plot on the \nright shows that updates are nearly three orders of magnitude faster for larger inputs; speedups are \ncomputed by comparing to static from-scratch execution. Imagine performing motion simulation by recomputing \nthe con\u00advex hull periodically every d milliseconds, i.e., by time slicing. If d is reasonably small, \nwe expect the output computed at consecutive intervals to be similar. Self-adjusting computation allows \nus to take advantage of this similarity. Figure 13 (right) shows the total simu\u00adlation time for varying \ninterval sizes with 5000 moving points. The horizontal axis represents d in milliseconds and the vertical \naxis represents the total simulation time. As the interval size increases the total simulation time decreases \nquite dramatically especially ini\u00adtially, because as the interval size increases, more events can be \nprocessed simultaneously and fewer events occur in total. Finally, although we do not discuss here in \ndetail, the ability to handle continuous-domain inputs makes a range of modi.cations possible. For example, \nour approach allows the time to be set to any value, even in the past and update the output ef.ciently. \n 8. Related Work The problem of having computation respond to slowly changing data has been studied \nextensively. Early work in the programming languages community, broadly called incremental computation,fo\u00adcused \non developing techniques for translating static/conventional programs into incremental programs that \ncan respond automatically to input modi.cations. Recent advances on self-adjusting computa\u00adtion have \ngeneralized these approaches and dramatically improved their effectiveness. The algorithms community \ndevised dynamic and kinetic data structures to address these same problems. This section is a brief survey \nof related work in these two areas; detailed information can be found elsewhere [7, 11, 14, 24]. Incremental \nComputation. The most effective incremental com\u00adputation techniques are based on dependence graphs, memoization, \nand partial evaluation. Dependence graph techniques record the de-pendencies between data in a computation \nand rely on a change\u00adpropagation algorithm to update the computation when the input is modi.ed (e.g., \n[12, 18]). These techniques have been shown to be effective in some applications, e.g., syntax-directed \ncomputa\u00adtions. They are not general-purpose because they do not allow the change-propagation algorithm \nto update the dependence structure. For example, the INC language [27], which uses static dependence \ngraphs, does not permit recursion. As an alternative to dependence graphs, memoization (also called function \ncaching) has been inves\u00adtigated (e.g., [1, 17, 23]). This classic idea dating back to the late 1950 s \n[9, 21, 22] applies to any purely functional program and therefore is more broadly applicable than static \ndependence graphs. In incremental computation, memoization can improve ef.ciency when executions of a \nprogram with similar inputs perform similar function calls. This turns out to be relatively rare: it \nis often the case that small input modi.cations can prevent reuse via memoization as the arguments to \nmany functions are modi.ed. Partial incremen\u00adtal computation with partial evaluation [15, 26] requires \nthe user to .x the partition of the input that the program will be specialized on and can then process \nmodi.cation faster by partially evaluating the program with respect to the .xed part of the input. The \nmain limitation of this approach is that it allows input modi.cations only within a predetermined partition. \n  Self-Adjusting Computation. Self-adjusting computation com\u00adbines dynamic dependence graphs [2] and \na form of computa\u00adtion memoization [5] to achieve ef.cient updates. Variants of self\u00adadjusting computation \nhave been implemented in several host lan\u00adguages such as C [16], Java [25], Haskell [10], and SML [19]. \nThe approach has been shown to be effective for a reasonably broad range of problems (e.g., [4, 5]. Recently, \ntechniques inspired by self-adjusting computation have resulted in an ef.cient algorithm for dynamic \nmaintenance of well-spaced point sets, settling an open problem [6].  9. Conclusion We present an approach \nto tracing dependencies in computations at the level of (abstract) data types operations. Since the number \nof accesses to an abstract data type can be asymptotically less than the number of accesses to memory, \nour approach can asymptoti\u00adcally reduce the number of dependencies to be traced. For exam\u00adple in heapsort \nthere are only O(n) accesses to the heap (priority queue) instead of O(n log n) total operations, and \nindeed our exper\u00adiments show an order of magnitude improvement. In the context of self-adjusting computation, \nthese techniques translate to dramatic improvements in space and time. Furthermore in some cases the \ntrace with respect to the data type operations can be stable even if at the memory cell level it is not. \nThis can greatly improve the performance of change propagation, as seen in the Huffman code benchmark. \n References [1] M. Abadi, B. W. Lampson, and J.-J. L\u00b4evy. Analysis and Caching of Dependencies. In Proceedings \nof the International Conference on Functional Programming, pages 83 91, 1996. [2] U. A. Acar, G. E. Blelloch, \nand R. Harper. Adaptive functional programming. ACM Transactions on Programming Languages and Systems, \n28(6):990 1034, 2006. [3] U. A. Acar, G. E. Blelloch, and K. Tangwongsan. Non-oblivious retroactive data \nstructures. Technical report, Carnegie Mellon Uni\u00adversity, 2007. [4] U. A. Acar, G. E. Blelloch, K. Tangwongsan, \nand D. T\u00a8urko.glu. Robust Kinetic Convex Hulls in 3D. In Proceedings of the 16th Annual European Symposium \non Algorithms, September 2008. [5] U. A. Acar, G. E. Blelloch, M. Blume, R. Harper, and K. Tangwongsan. \nAn experimental analysis of self-adjusting computation. ACM Trans\u00adactions on Programming Languages and \nSystems (TOPLAS), 32(1): 3:1 3:53, 2009. [6] U. A. Acar, A. Cotter, B. Hudson, and D. T\u00a8urko.glu. Dynamic \nwell\u00adspaced point sets. In SCG 10: Proceedings of the 26th Annual Symposium on Computational Geometry, \n2010. [7] P. K. Agarwal, L. J. Guibas, H. Edelsbrunner, J. Erickson, M. Isard, S. Har-Peled, J. Hershberger, \nC. Jensen, L. Kavraki, P. Koehl, M. Lin, D. Manocha, D. Metaxas, B. Mirtich, D. Mount, S. Muthukrishnan, \nD. Pai, E. Sacks, J. Snoeyink, S. Suri, and O. Wolefson. Algorithmic issues in modeling motion. ACM Comput. \nSurv., 34(4):550 572, 2002. ISSN 0360-0300. [8] C. B. Barber, D. P. Dobkin, and H. Huhdanpaa. The Quickhull \nAlgorithm for Convex Hulls. ACM Trans. Math. Softw., 22(4):469 483, 1996. [9] R. Bellman. Dynamic Programming. \nPrinceton University Press, 1957. [10] M. Carlsson. Monads for Incremental Computing. In Proceedings \nof the 7th ACM SIGPLAN International Conference on Functional programming, pages 26 35. ACM Press, 2002. \n[11] Y.-J. Chiang and R. Tamassia. Dynamic algorithms in computational geometry. Proceedings of the IEEE, \n80(9):1412 1434, 1992. [12] A. Demers, T. Reps, and T. Teitelbaum. Incremental Evaluation of Attribute \nGrammars with Application to Syntax-directed Editors. In Proceedings of the 8th Annual ACM Symposium \non Principles of Programming Languages, pages 105 116, 1981. [13] P. F. Dietz and D. D. Sleator. Two \nalgorithms for maintaining order in a list. In Proceedings of the 19th ACM Symposium on Theory of Computing, \npages 365 372, 1987. [14] D. Eppstein, Z. Galil, and G. F. Italiano. Dynamic graph algorithms. In M. \nJ. Atallah, editor, Algorithms and Theory of Computation Hand\u00adbook, chapter 8. CRC Press, 1999. [15] \nJ. Field and T. Teitelbaum. Incremental reduction in the lambda calculus. In Proceedings of the ACM 90 \nConference on LISP and Functional Programming, pages 307 322, June 1990. [16] M. A. Hammer, U. A. Acar, \nand Y. Chen. CEAL: A C-based language for self-adjusting computation. In Proceedings of the 2009 ACM \nSIG-PLAN Conference on Programming Language Design and Implemen\u00adtation, June 2009. [17] A. Heydon, R. \nLevin, and Y. Yu. Caching Function Calls Using Precise Dependencies. In Proceedings of the 2000 ACM SIGPLAN \nConference on Programming Language Design and Implementation, pages 311 320, 2000. [18] R. Hoover. Incremental \nGraph Evaluation. PhD thesis, Department of Computer Science, Cornell University, May 1987. [19] R. Ley-Wild, \nM. Fluet, and U. A. Acar. Compiling self-adjusting programs with continuations. In Proceedings of the \nInternational Conference on Functional Programming, 2008. [20] R. Ley-Wild, U. A. Acar, and M. Fluet. \nA cost semantics for self\u00adadjusting computation. In Proceedings of the 26th Annual ACM Symposium on Principles \nof Programming Languages, 2009. [21] J. McCarthy. A Basis for a Mathematical Theory of Computation. In \nP. Braffort and D. Hirschberg, editors, Computer Programming and Formal Systems, pages 33 70. North-Holland, \nAmsterdam, 1963. [22] D. Michie. Memo Functions and Machine Learning. Nature, 218: 19 22, 1968. [23] \nW. Pugh and T. Teitelbaum. Incremental computation via function caching. In Proceedings of the 16th Annual \nACM Symposium on Principles of Programming Languages, pages 315 328, 1989. [24] G. Ramalingam and T. \nReps. A Categorized Bibliography on Incre\u00admental Computation. In Proceedings of the 20th Annual ACM Sympo\u00adsium \non Principles of Programming Languages, pages 502 510, 1993. [25] A. Shankar and R. Bodik. DITTO: Automatic \nIncrementalization of Data Structure Invariant Checks (in Java). In Proceedings of the ACM SIGPLAN 2007 \nConference on Programming language Design and Implementation, 2007. [26] R. S. Sundaresh and P. Hudak. \nIncremental compilation via partial evaluation. In Conference Record of the 18th Annual ACM Symposium \non Principles of Programming Languages, pages 1 13, 1991. [27] D. M. Yellin and R. E. Strom. INC: A Language \nfor Incremental Computations. ACM Transactions on Programming Languages and Systems, 13(2):211 236, Apr. \n1991.  \n\t\t\t", "proc_id": "1806596", "abstract": "<p>Self-adjusting computation provides an evaluation model where computations can respond automatically to modifications to their data by using a mechanism for propagating modifications through the computation. Current approaches to self-adjusting computation guarantee correctness by recording dependencies in a trace at the granularity of individual memory operations. Tracing at the granularity of memory operations, however, has some limitations: it can be asymptotically inefficient (\\eg, compared to optimal solutions) because it cannot take advantage of problem-specific structure, it requires keeping a large computation trace (often proportional to the runtime of the program on the current input), and it introduces moderately large constant factors in practice.</p> <p>In this paper, we extend dependence-tracing to work at the granularity of the query and update operations of arbitrary (abstract) data types, instead of just reads and writes on memory cells. This can significantly reduce the number of dependencies that need to be kept in the trace and followed during an update. We define an interface for supporting a traceable version of a data type, which reports the earliest query that depends on (is changed by) revising operations back in time, and implement several such structures, including priority queues, queues, dictionaries, and counters. We develop a semantics for tracing, extend an existing self-adjusting language, &#916;ML, and its implementation to support traceable data types, and present an experimental evaluation by considering a number of benchmarks. Our experiments show dramatic improvements on space and time, sometimes by as much as two orders of magnitude.</p>", "authors": [{"name": "Umut A. Acar", "author_profile_id": "81100077236", "affiliation": "Max-Planck Institute for Software Systems, Kaiserslautern, Germany", "person_id": "P2184633", "email_address": "", "orcid_id": ""}, {"name": "Guy Blelloch", "author_profile_id": "81100282539", "affiliation": "Carnegie Mellon University, Pittsburgh, PA, USA", "person_id": "P2184634", "email_address": "", "orcid_id": ""}, {"name": "Ruy Ley-Wild", "author_profile_id": "81351606631", "affiliation": "Carnegie Mellon University, Pittsburgh, PA, USA", "person_id": "P2184635", "email_address": "", "orcid_id": ""}, {"name": "Kanat Tangwongsan", "author_profile_id": "81314492749", "affiliation": "Carnegie Mellon University, Pittsburgh, PA, USA", "person_id": "P2184636", "email_address": "", "orcid_id": ""}, {"name": "Duru Turkoglu", "author_profile_id": "81384599207", "affiliation": "University of Chicago, Chicago, IL, USA", "person_id": "P2184637", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806650", "year": "2010", "article_id": "1806650", "conference": "PLDI", "title": "Traceable data types for self-adjusting computation", "url": "http://dl.acm.org/citation.cfm?id=1806650"}