{"article_publication_date": "06-05-2010", "fulltext": "\n GUESSTIMATE: A Programming Model for Collaborative Distributed Systems Kaushik Rajan Sriram Rajamani \nShashank Yaduvanshi Microsoft Research India Microsoft Research India Indian Institute of Technology, \nDelhi krajan@microsoft.com sriram@microsoft.com hyaduvanshi@gmail.com Abstract We present a new programming \nmodel GUESSTIMATE for devel\u00adoping collaborative distributed systems. The model allows atomic, isolated \noperations that transform a system from consistent state to consistent state, and provides a shared transactional \nstore for a collection of such operations executed by various machines in a dis\u00adtributed system. In addition \nto committed state which is identical in all machines in the distributed system, GUESSTIMATE allows each \nmachine to have a replicated local copy of the state (called guesstimated state ) so that operations \non shared state can be ex\u00adecuted locally without any blocking, while also guaranteeing that eventually \nall machines agree on the sequences of operations exe\u00adcuted. Thus, each operation is executed multiple \ntimes, once at the time of issue when it updates the guesstimated state of the issuing machine, once \nwhen the operation is committed (atomically) to the committed state of all machines, and several times \nin between as the guesstimated state converges toward the committed state. While we expect the results \nof these executions of the operation to be identical most of the time in the class of applications we \nstudy, it is possible for an operation to succeed the .rst time when it is executed on the guesstimated \nstate, and fail when it is committed. GUESSTIMATE provides facilities that allow the programmer to deal \nwith this po\u00adtential discrepancy. This paper presents our programming model, its operational semantics, \nits realization as an API in C#, and our experience building collaborative distributed applications with \nthis model. Categories and Subject Descriptors D.1.3 [Programming Tech\u00adniques]: Concurrent Programming \nDistributed programming; D.3.3 [Programming Languages]: Language Constructs and Fea\u00adtures; F.3.1 [Logics \nand Meanings of Programs]: Specifying and Verifying and Reasoning about Programs General Terms Design, \nLanguages Keywords Distributed systems, collaborative applications, con\u00adcurrency, language extensions \n1. Introduction Programming distributed systems is dif.cult for several reasons. Latency between different \ncomponents is high, and thus any com- Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 10, June 5 10, 2010, Toronto, Ontario, Canada. Copyright c &#38;#169; \n2010 ACM 978-1-4503-0019-3/10/06. . . $10.00 munication between components leads to large delays. Concur\u00adrency \nbetween components is intrinsic, and concurrent program\u00adming is inherently hard. The programmer needs \nto deal with fail\u00adures of various forms such as nodes, links, and disks. Consistency between components \nin various machines needs to be traded off with performance. In this paper we propose a programming model \nGUESSTIMATE, which explores a new design point in the trade-off between consistency and performance. \nOne way to build a distributed system is to centralize shared data in the server, but this can affect \nresponsiveness due to latency and contention at the server. If we start caching or replicating the shared \ndata locally at each machine, we open a different can of worms it is non-trivial to keep all copies consistent. \nThus, there is an inherent tradeoff between responsiveness and consistency, and there is a lot of prior \nwork in this area. On the one extreme, we have one copy serializability [4]. In this model, every action \non shared data is committed and made visible to all machines at the same time. One copy serializability \nis the best form of consistency we can hope for. However, this programming model is inherently slow. \nThe other extreme is replicated execution, where each machine has its own local copy of the shared data, \nand can update the local copies independently, which is very high performance, but there is no consistency \nbetween the states of the various machines. Decades of research has been done to explore the tradeoff \nbetween these two models including sequential consistency [11], serializability [4], linearizability \n[9], and eventual consistency [14]. GUESSTIMATE explores a new design point in the consistency\u00adperformance \ntradeoff. In order to allow performance, GUESSTI-MATE allows each machine to maintain a local copy of \nthe shared state (called guesstimated state ). At any point in time, the guessti\u00admated copy in each machine \ncontains the expected outcome of the sequence of operations issued by that machine, assuming no con.icts \nwith operations executed by other machines. Eventually, the sequences of operations on all machines converge \nto the same value. However, until this happens, each machine proceeds inde\u00adpendently with the current \nguesstimate it has. The advantage of the programming model is that operations can be executed by any \nma\u00adchine on its guesstimated state without waiting for any communica\u00adtion with other machines. The disadvantage \nis that each operation executes multiple times from the time of issue up to the time of commit the operation \nupdates the guesstimated copy, and .nally at the time of commit the operation atomically updates the \ncommitted copy of all the machines and the result of these executions is not guaranteed to be identical, \nand the programmer has to deal with this discrepancy. In our model, operations transform shared objects \nfrom consis\u00adtent state to consistent state. Consistency is speci.ed by precondi\u00adtions on operations. \nIf at the time of issue an operation fails pre\u00adconditions on the guesstimated state, it is not even issued, \nand re\u00adjected.1 Otherwise, if an operation has no precondition violations, it is immediately executed \non the guesstimated state, without any blocking. The same operation is executed again at commit time \non a different copy of the shared state (referred to as committed state) that is guaranteed to be identical \nin all machines. In between issue and commit of an operation issued by a machine mi, operations from \nother machines can commit, and GUESSTIMATE attempts to update the guesstimated state of mi with the knowledge \nof these committed operations from other machines. As a results, each op\u00aderation can be executed several \ntimes on the guesstimated state, as it progressively converges toward the committed state. For the class \nof applications we study, we expect that most of the time the result of the various executions of an \noperation from issue to commit are identical, but this is not guaranteed.  We believe that the GUESSTIMATE \nprogramming model is par\u00adticularly useful in building collaborative distributed applications, where a \ngroup of users are collaborating to perform a shared task, such as solving a puzzle, for example. We \nhave built six such ap\u00adplications with GUESSTIMATE a multi-player Sudoku game, an event planning application, \na message board application, a car pool system, an auction system, and a small twitter-like application \n(see Section 6). GUESSTIMATE provides facilities by which the pro\u00adgrammer can annotate operations with \nparticular kinds of speci.ca\u00adtions, and use off-the-shelf program veri.ers to check that the im\u00adplementations \nof the operations satisfy these speci.cations. These facilities enable the programming model to guarantee \nthat even if there are certain kinds of discrepancies between the results of ex\u00adecution of the operation \non the guesstimated state and the actual committed state, as long as these differences do not matter \nwith respect to the speci.cation of the operation, the model can simply tolerate them. For other, more \nextreme kind of discrepancies which violate the speci.cation of the operation, the model provides com\u00adpletion \nfunctions which can be used to inform the user of discrep\u00adancies, and have the users deal with such discrepancies. \nChallenges also arise due to interaction between operations. A user might per\u00adform two operations o1 \nand o2 where the inputs to o2 depend on the results of o1. Thus, a discrepancy in the execution of o1 \naffects the execution of o2. GUESSTIMATE provides facilities by which such operations with dependencies \ncan be grouped into atomic opera\u00adtions with an all-or-nothing execution semantics. In the extreme, the \nprogrammer might want one copy serializability for some im\u00adportant operations, and this can be implemented \nby the programmer explicitly doing blocking until the operations commit. This paper explores such a programming \nmodel, presents an op\u00aderational semantics for the programming model, a language exten\u00adsion to C# to use \nthis programming model, and our experience in writing some applications with the programming model. 2. \nProgramming with GUESSTIMATE We motivate GUESSTIMATE s programming model using the example of a multi-player \ncollaborative Sudoku puzzle. The Su\u00addoku puzzle consists of a 9x9 square, where each square needs to \nbe .lled with some integer between 1 and 9. The 9x9 square is divided into nine 3x3 sub-squares uniformly. \nEach instance of the puzzle comes with some pre-populated numbers. The objective of the game is to .ll \nall the entries in the 9x9 square subject to 3 con\u00adstraints (1) the same number cannot repeat in a row, \n(2) the same number cannot repeat in a column, (3) the same number cannot re\u00adpeat in a 3x3 sub-square. \nSuppose we wish to program a collabora\u00adtive Sudoku game, where players are distributed across the Internet. \nThat is, we wish to allow different players to collaboratively work 1 In addition to better response \ntimes, the user gets feedback on operations that fail on the guesstimated state quickly, so that they \ncan potentially alter the operation and resubmit it. on different portions of the puzzle. Maintaining \nthe state of the ma\u00adchine in a server is in.exible, and can lead to poor response times. Thus, we might \nwish to replicate the state of the puzzle locally in each of the machines. Programming such an application \nwith replicated state is non\u00adtrivial. In each machine, we need to have three components: (1) model that \nmaintains the state of the puzzle, (2) a component that manages the user interface, and (3) a synchronizer \nthat performs synchronization between the states of various machines. The syn\u00adchronizer is responsible \nfor communication between all the repli\u00adcated instances of the model in various machines. Whenever the \nmodel changes in any machine, the synchronizer needs to propagate changes to all other machines. There \ncould be con.icts because two updates by two different machines could violate the constraints of Sudoku \nmentioned above. There could be races because both the UI and synchronizer could simultaneously update \nthe model in each machine. Programming the application correctly taking all these is\u00adsues into account \nis dif.cult. GUESSTIMATE s goal is to hide much of this complexity from the programmer, and offer a simpli.ed \npro\u00adgramming model where the programmer only needs to worry about expressing the application logic. All \nthe complex logic related to keeping the model synchronized across various machines is han\u00addled by the \nrun-time system. We describe how GUESSTIMATE s programming model can be used to program this application. \nFigure 1 shows the class Sudoku, which represents the model(state shared by multiple computers). In GUESSTIMATE \nthe programmer declares shared objects by deriv\u00ading from the abstract base class GSharedObject. Other \nthan deriv\u00ading this abstract base class, which forces providing code for a Copy method, the programmer \ncan program this class in whatever way she wants. In this case, the class has a 9x9 array puzzle declared \nin line 2. The method Check de.ned in lines 4 10 returns true if on updating puzzle[row,col] with val \nthe constraints of Sudoku are satis.ed, and false otherwise. The method Update de.ned in lines 12 23 \nupdates puzzle[r,c] to value v if it is a legal update, and returns true. If the update is not legal, \nit returns false. Finally the programmer has to de.ne a copy method (line 24) that when passed a source \nobject copies the array puzzle from the source to the this object. Note that other than deriving from \nthe abstract base class GSharedObject, the programmer does not have to do anything different from the \nway she would write this class for a non-distributed application. Figure 2 shows the user interface class \nfor this applica\u00adtion, which uses the Sudoku class from Figure 1. In line 6, a new instance of the Sudoku \nclass is created using a call to Guesstimate.CreateInstance. Internally, GUESSTIMATE cre\u00adates an instance \nof the Sudoku class and assigns it a unique identi\u00ad.er. Other machines can now share this Sudoku instance \nby calling the JoinInstance method. All machines that have joined this Su\u00addoku instance can now update \nthis object while the run-time takes care of all communication and synchronization. In lines 15 24 of \nFigure 2 we see the event handler in the UI that is executed in response to an update of row r, column \nc with value v. In response to this event, in the case of a non-distributed program, this code would \nsimply call s.Update(r,c,v). With GUESSTIMATE, the programmer has to create an operation us\u00ading Guesstimate.CreateOperation \nas seen in line 17, and is\u00adsue the operation using Guesstimate.IssueOperation as seen in line 19. When \nthe operation is issued, GUESSTIMATE exe\u00adcutes it on the guesstimated copy of the Sudoku object. If the \nexecution fails due to violation of any of the constraints of Su\u00addoku (that is s.Update(r,c,v) returns \nfalse), the operation is dropped. Otherwise, GUESSTIMATE submits it internally to a queue, to be committed \nlater simultaneously in all machines. The code in lines 22 23 calls the redraw function if the operation \nsuc\u00ad  1 class Sudoku : GSharedObject { 1 2 private int[9,9] puzzle; 2 3 ... 3 4 private bool Check(int \nrow, int col, int val) 4 5 { 5 6 //returns true if adding val at puzzle[row,col] 6 7 //does not violate \nthe constraints of Sudoku 7 8 // and false otherwise 8 9 ... 9 10 } 10 11 11 12 public bool Update(int \nr, int c, int v) 12 13 { 13 14 //adds value to puzzle[r,c] if all constraints 14 15 // are satisfied \n15 16 if (r > 9 || r <= 0) return false; 16 17 if (c > 9 || c <= 0) return false; 17 18 if (v > 9 || \nv <= 0) return false; 18 19 if (!Check(r, c, v)) 19 20 return false; 20 21 puzzle[r, c] = v; 21 22 return \ntrue; 22 23 } 23 24 public void copy(GSharedObject src)... 24 25 } 25 Figure 1. Sudoku class ceeded on \nthe guesstimated copy. The Redraw function (lines 9 14) reads out the updated value from the guesstimate \ncopy and re\u00adfreshes the UI by changing the text on the square and painting it YELLOW. Enclosing reads \nwithin Guesstimate.BeginRead and Guesstimate.EndRead ensures that they are isolated from con\u00adcurrent \nwrites via the synchronizer. At the time of commitment, this operation s.Update(r,c,v) may succeed or \nfail. In particular, the operation can fail if between the time instant when s.Update(r,c,v) was issued \nand the time instant when the operation is committed, operations issued by some other machine got committed, \nand these other operations violate the precondition for the execution of s.Update(r,c,v). After commitment, \nGUESSTIMATE calls a completion func\u00adtion, which is supplied as a delegate in the last argument of Guesstimate.IssueOperation \n(lines 20 21). The completion function takes a boolean value as argument. This boolean is the result \nof executing the shared operation (in this case Update) dur\u00ading commitment. The completion operation \nis used to change the colors on the UI as follows. If the update operation is successful, the completion \noperation changes the color of the square at row r, column c to GREEN and if update fails the color is \nset to RED. The way colors are manipulated by the UI in this example demonstrates how GUESSTIMATE allows \nthe programmer to deal with changes to the shared state if some operations succeeded initially but failed \nlater due to con.icting operations from other machines. Thus, programming with GUESSTIMATE involves the \nfollowing steps: 1. Create shared classes (that is, classes for objects that the programmer wants to \nbe shared across multi\u00adple machines) such that they are derived from the abstract base class GSharedObject. \nWhen creating shared objects use Guesstimate.CreateInstance or Guesstimate.JoinInstance methods provided \nby GUESSTIMATE. 2. To invoke an operation on a shared object, .rst create the oper\u00adation using Guesstimate.CreateOperation, \nand then issue the operation using Guesstimate.IssueOperation. 3. Supply completion routines through \nGuesstimate.IssueOperation to reconcile the client of the shared object in case the operation fails during \ncommit.  public class UI { enum Color {RED, YELLOW, GREEN, BLUE, COLORLESS}; Sudoku s; OnCreate() { \n//Here is how we create a shared object. s = (Sudoku) Guesstimate.CreateInstance(typeof(Sudoku)); } \n... void ReDraw(int r, int c, COLOR color){ Guesstimate.BeginRead(s); Board[r,c].Text=s.puzzle[r,c]; \nGuesstimate.EndRead(s); Board[r,c].BackColor=color;  } void OnUpdate(int r, int c, int v){ // the operation \nwe want to do is: s.Update(r,c,v) Operation op = Guesstimate.CreateOperation( s, Update , r,c,v); //Issue \nthe shared operation, together with a completion function bool res = Guesstimate.IssueOperation(op, (bool \nb) => {if (b) ReDraw(r, c, Color.GREEN); else ReDraw(r, c, Color.RED)}); if(res) ReDraw(r, c, Color.YELLOW); \n} } Figure 2. UI class GUESSTIMATE API. The above example motivates the various aspects of the GUESSTIMATE \nprogramming model. We now give a complete description of the GUESSTIMATE API. GSharedObject CreateInstance(Type \ntype) takes the type of the shared object as input and creates a unique object of that type and returns \nit to the client. The new object is internally assigned a unique identi.er and is registered with GUESSTI-MATE. \n List <string> AvailableObjects() returns a list of unique identi.ers of all objects.  Type GetType(string \nuniqueID) returns the type of a shared object, given its unique identi.er as input.  string GetUniqueID(GSharedObject \nobj) returns the uniqueID of a shared object.  GSharedObject JoinInstance(string uniqueID) takes the \nuniqueID of an available object and returns a reference to that object. In, addition the machine executing \nthis operation is registered for future synchronizations on the object.  sharedOp CreateOperation(GSharedObject \nobj, string methodName, params object[] parameterList) takes a shared object, the method name and the \nparameters of the method as input and returns a shared operation of type sharedOp.  A programmer can \ncombine multiple shared operations to form hierarchical operations. A shared operation can have a hierarchical \nstructure as de.ned in the grammar below: SharedOp := PrimitiveOp| AtomicOp| OrElseOp AtomicOp := Atomic \n{ SharedOp* } OrElseOp := SharedOp OrElse SharedOp An AtomicOp is treated as an indivisible operation \nwith all or nothing semantics. That is, if any one of the enclosed fail, then none of the operations \nupdate the shared state. If all the enclosed operations were to succeed then the shared state is updated \nby all of them. The implementation of Atomic operations is done using copy-on-write at the granularity \nof objects (see Section 4). The OrElseOp is a hierarchical operation that allows the programmer to specify \nan alternate operation in case of failure. The semantics of op1 OrElse op2 is that at most one of op1 \nor op2 is allowed to succeed with priority given to op1. If both op1 and op2 fail, then op1 OrElse op2 \nfails. The programmer is allowed to arbitrarily nest these two hierarchical constructors. The following \nAPI is used to create and issue shared operations:  sharedOp CreateAtomic(List <sharedOp> ops) takes \na list of shared operations as input and returns a hierarchical shared operation.  sharedOp CreateOrElse(sharedOp \nop1, sharedOp op2) takes two shared operations as input and returns a new hierarchical shared operation. \n IssueOperation(sharedOp s,completionOp c) takes as .rst parameter a sharedOp s created using CreateOperation, \nCreateAtomic or CreateOrElse, and a second parame\u00adter of type completionOp. The type completionOp is \na delegate type de.ned with the signature delegate void CompletionOp(bool v). IssueOperation applies \ns to up\u00addate the guesstimated state immediately. Further, the opera\u00adtion is added to a pending list for \ncommitting on all machines. GUESSTIMATE also remembers the machine m that submitted the operation. At \nthe time of commitment the completion oper\u00adation c is executed on machine m. More details can be found \nin Section 3.  The following API is used to protect a shared object during read operations: void BeginRead(GSharedObject \nobj) and void EndRead(GSharedObject obj) are used to directly read the guesstimated state without issuing \noperations. All reads of obj performed between BeginRead(obj) and EndRead(obj) are guaranteed to be isolated \nfrom concurrent writes to obj through the synchronizer. More details can be found in Section 4. Apart \nfrom using this API to create shared objects, and issue oper\u00adations on shared objects, the programmer \ncan choose to implement the application as she pleases. 3. Formal Model In this section, we describe \nthe GUESSTIMATE programming model formally, and give an operational semantics for the model. The programming \nmodel is presented at the level of abstraction a programmer needs to understand in order to write programs. \nThus, the internal details of how the GUESSTIMATE runtime performs replication and synchronization are \nsomewhat hidden in this pre\u00adsentation. Section 4 presents the GUESSTIMATE runtime and ar\u00adgues that the \nruntime indeed faithfully implements the operational semantics presented in this section. Objects and \nstate. A distributed system is a pair (M, S), where M is a tuple of |M| machines (m1,m2,...,m|M|), and \nS is a set of shared objects. In the example in Section 2, the Sudoku object is a shared object. An application \ncan have several such shared objects. A shared state is a valuation to the set of shared objects. S is \nthe set of all shared states. In addition, each machine mi . M maintains a set of local objects Li, and \nthis set could be different for different machines. A local state is a valuation to the local objects. \nG is the set of all local states. The state of a machine is a 5-tuple (., C, sc, P, sg), where . . G \nis the local state at the machine, C is a sequence of completed shared operations, sc . S is the committed \nstate at the machine, P is a sequence of pending composite operations at the machine, and sg . S is the \nguesstimated state at the machine. The committed state sc is obtained by executing the sequence of completed \noperations C from the initial state. The programming model guarantees that the sequence C of completed \noperations is identical across all machines, and thus C and sc are equal for all machines in the distributed \nsystem (this is an invariant that can be proved by induction on the operational semantics). The sequence \nP consists of pending operations that have been submitted at this machine, and guesstimated state sg \nis obtained by executing this sequence of operations P starting from the committed state sc. Since the \nsequence P may be different for different machines, the guesstimated state sg could be different for \ndifferent machines. As the system proceeds executing, operations from P are moved to C, and the guesstimated \nstate sg and the committed state sc converge to the same value when P becomes empty. The set of machine \nstates is denoted by .. The state of the distributed system is a function . from machine index to .. \nWe use the notation (.(i),C(i),sc(i),P (i),sg(i)) to denote the state of the ith machine .(i). Operations. \nThe programming model has four kinds of operations: (1) local operation, (2) shared operation, (3) completion \noperation, and (4) composite operation, described formally below. Each machine can modify its local state \nusing local operations that can read the guesstimated state and local state, but can update only local \nstate. A local operation therefore has signature (S \u00d7 G) . G. Local operations do not change shared state, \nand they are not applied on other machines. In addition to managing local state, local operations can \nbe used to maintain information regarding submitted operations or to query the shared state before applying \nan operation to change the shared state. The set of all local operations is L. A shared operation reads \nand updates the shared state. Shared operations can succeed or fail. We can think of each shared opera\u00adtion \nas having a precondition S/ . S and the operation fails if it is attempted to be executed from a state \ns . S/. For example, if a shared operation tries to buy tickets on an airplane, then it can fail if there \nare not enough seats available. Thus, in addition to updating the shared state, a shared operation returns \na boolean value as well. A shared operation therefore has signature S . (S \u00d7 B). The set of all shared \noperations is S. We associate a speci.cation .s . S \u00d7 S with every shared operation s. A shared operation \ns conforms to speci.cation .s if for any pair of shared states s1 and s2 (1) if s(s1)= (s2, true), then \n(s1,s2). .s, and (2) if s(s1)= (s2, false), then s1 = s2. That is, a shared operation either returns \ntrue and satis.es its speci.cation, or returns false and does not modify the shared state. We use speci.cations \non shared operations to reason about applications written using GUESSTIMATE. More details can be found \nin Section 5. A completion operation reads the local state, shared state, and a boolean value, and updates \nthe local state. A completion operation therefore has signature (S\u00d7G\u00d7B) . G. The set of all completion \noperations is C. A composite operation o is a pair (s, c) where s .S is a shared operation and c .C is \na completion operation. In a composite operation, the boolean value produced by the shared operation \nis passed as an argument to the corresponding completion operation. The set of all composite operations \nis O. The semantics of a composite operation (s, c) can thus be understood as: .(s, .). let (s1,b)= s(s) \nin let .1 = c(s1, ., b) in (s1,.1) Given a composite operation o = (s, c) we use the notation [o] or \nequivalently [(s, c)] to denote a function with signature S . S with the following semantics: [(s, c)]= \n.s.let (s1,b)= s(s) in s1  R1 : ., o . L issued at machine i, true . .{ .(i) := o(sg(i), .(i)) } R2 \n: ., o = (s, c) . C issued at machine i, s(sg(i)) = (s, true) . .{ P (i) sg(i) := := Append(P (i), o); \n[o](sg(i)) } .{ P (i) C(i) := := AllButFirst(P (i)); Append(C(i), s); R3 : ., E, o = (s, c) = First(P \n(i)) . (sc(i), .(i)) .(j = i).C(j) := := o(sc(i), .(i)); Append(C(j), s); .(j = i).sc(j) := s(sc(j)); \n.(j = i).sg(j) := [P (j)](s(sc(j))) } Figure 3. Operational semantics We also extend the notation [.] \nto map a sequence of composite operations to a function with signature S . S with the semantics: [(o1,o2,...on)] \n= .s.([on]([on-1] \u00b7\u00b7\u00b7 ([o2]([o1](s))) \u00b7\u00b7\u00b7 )) Operational semantics. Each machine mi issues a sequence \nof local and composite operations (o1i ,o 2i ,...). Local operations are executed locally on each machine, \nwith no communication to other machines. Each composite operation is .rst executed locally on the guesstimated \nstate of the issuing machine, and queued in the sequence of pending operations. Atomically, a pending \noperation is picked from the front of a pending queue of some machine, and executed and committed on \nall machines. The operational semantics of GUESSTIMATE is given by the three rules in Figure 3. The rules \nare guarded commands of the form ., input, . . ./, where . is the current state, input is the input and \n. is a guard (a predicate that needs to evaluate to true on current state and the input for the rule \nto be enabled), and ./ is the next state. ./ is obtained by updating some components of .. We use the \nnotation .{c1 := v1,c2 := v2,...} to denote a new state where component c1 in . gets updated to value \nv1, component c2 in . gets updated to value v2, etc. Any component not speci.ed as updated retains its \nold value. To state the operational semantics formally, we need a few de.nitions. The function First(list) \nreturns the oldest entry in list. The function AllButFirst(list) removes First(list) from the list, and \nreturns all the other elements preserved intact in the same order. The function Append(list, o) returns \na new list with o appended as the last element of list. Rule R1 states that a local operation at machine \ni merely mod\u00adi.es the local state at machine i. Rule R2 states that a composite operation issued at machine \ni is appended at the end of the pending queue at machine i, and updates the guesstimated state at machine \ni. Note that this rule has a guard s(sg(i)) = (s, true), which re\u00adquires that the operation s succeed \nbefore it is added to the pending queue. If s(sg(i)) = (s, false), then the operation o is dropped. Rule \nR3 describes commitment of a shared operation. A shared operation o = (s, c) is picked from the front \nof the pending queue P (i) of some machine i. The operation is removed from the pend\u00ading queue P (i) \nof machine i, and moved to the committed queue C(i) of machine i. The committed state sc(i) and local \nstate .(i) of machine i are updated by executing the operation o. For every machine j, such that j = \ni, the shared operation s is also exe\u00adcuted to update the committed state sc(j). The operation is also \nappended to the committed sequence C(j) and updates the guessti\u00admated state sg(j) by executing the pending \noperations P (j) on the updated committed state. The rule R3 does not have a guard which requires that \nthe operation s be successful. The operation is exe\u00adcuted regardless of whether the operation s is successful \nor not. Also, note that the guesstimated state sg(i) does not need to be updated, since the concatenation \nof C(i) followed by P (i) is in\u00advariant due to the operation the .rst element of P (i) is moved to be \nthe last element of C(i). During commitment, the operation s is executed on all machines simultaneously \nand atomically, and up\u00addates the committed state and guesstimated state in each machine. In reality, \nthis takes several rounds of communication between the machines, but the programming model gives the \nillusion that the commitment happens atomically on all machines. Section 4 gives details on how the runtime \nimplements atomic commitment. Dur\u00ading the commitment process, the completion routine c is run on the \nmachine mi which issued the operation, and if the operation s fails, then the completion routine c will \nhave the opportunity to take re\u00admedial action. Invariants. GUESSTIMATE guarantees that when the system \nqui\u00adesces and the pending queues of all machines is empty, the guessti\u00admated state and the committed \nstate of all the machines converge to the same value. Formally, every machine state (., C, sc, P, sg) \nsatis.es the in\u00advariant [P ](sc)= sg. The entire system (which comprises all ma\u00adchine states) satis.es \nthe invariant that for any pair of machines mi and mj , we have that sc(i)= sc(j) and C(i)= C(j). These \ninvariants can be proved by induction over the transition rules R1, R2 and R3 allowed by the operational \nsemantics. 4. The GUESSTIMATE runtime Synchronization. The operational semantics given in Section 3 suf.ces \nto use GUESSTIMATE. In this section, we describe our spe\u00adci.c implementation of synchronization in the \nGUESSTIMATE run\u00adtime. A salient feature of the implementation is that though the op\u00aderational semantics \nallows an operation to be executed many times, our implementation of the GUESSTIMATE runtime ensures \nthat an operation is executed at most three times. If the reader is merely in\u00adterested in using GUESSTIMATE, \nthis description can be skipped. However, if the reader is curious about how the GUESSTIMATE runtime \nguarantees the semantics given in Section 3 or how the im\u00adplementation ensures that each operation is \nexecuted at most three times, we give some details below. The synchronizer component of the GUESSTIMATE \nruntime, maintains all the necessary state needed to coordinate among the machines. At each machine mi \nit maintains a list of all shared objects in the system (all calls to CreateInstance) and a list of all \nobjects that machine mi is subscribed to (calls to JoinInstance made by mi). For each object that machine \nmi is subscribed to, the synchronizer keeps two copies of the object, one to maintain the committed state \nsc(i), and another to maintain the guesstimated state sg(i). It also maintains an ordered list of pending \noperations P (i) and a list of committed operations C(i). Every operation that is issued by machine mi \nvia IssueOperation is added to P (i).  To communicate between machines the synchronizer uses Peer-Channel, \na peer-to-peer (P2P) communication technology that is part of .NET 3.5. PeerChannel allows multiple machines \nto be com\u00adbined together to form a mesh. Any member of the mesh can broad\u00adcast messages to all other \nmembers via a channel associated with the mesh. The GUESSTIMATE runtime uses two meshes, one for sending \nsignals and another for passing operations. Both meshes contain all participating machines. Synchronization \namong the machines is done in a master-slave mode. One of the machines is designated to be the master \nand is responsible for periodically initiating the synchronization process. The synchronization happens \nover 3 stages. 1. AddUpdatesToMesh. In the .rst stage the pending opera\u00adtions from all machines are gathered \nto construct a consol\u00adidated pending list Pall(i) at each machine mi. This hap\u00adpens as follows. Starting \nwith the master each machine mi, on its turn, .ushes out all operations in P (i) as triples of the form \n(machineID, operationnumber, operation) via the Operations channel to all the other machines, and then \npasses the turn to the next machine i +1 via a con.rmation message on the Signals channel. We will refer \nto the time instant at which machine mi starts .ushing operations as tBeginF lush(i) and the time instant \nat which it completes .ushing operations as tEndF lush(i). In the time interval between tBeginF lush(i) \nand tEndF lush(i) the implementation does not allow any new oper\u00adations to be issued. Therefore at the \ntime instant tEndF lush(i), P (i) is empty. The number of operations sent on the Operations channel \nis also sent along with the con.rmation message. As all machines see these con.rmation messages and know \nthe number of par\u00adticipating machines, they know the number of operations to ex\u00adpect in Pall(i). Once \ncon.rmation messages from all the par\u00adticipants are received the master signals the beginning of the \nsecond stage, ApplyUpdatesFromMesh. 2. ApplyUpdatesFromMesh. Each machine mi waits until it re\u00adceives \nall the expected operations and then applies operations from Pall(i) to the committed state sc(i) in \nlexicographic or\u00adder of the pair (machineID, operationnumber).  There can be two kinds of operations \nin Pall(i), those is\u00adsued at machine mi and those issued at other machines. Applying an operation o results \nin the following. If o = (s, c) was issued at mi then the committed state sc(i) is updated to s(sc(i)) \nand the boolean result of the operation along with the completion routine is queued into a temporary \nP endingCompletionRoutines queue. If the operation was issued at some other machine then only the committed \nstate sc(i) is updated to s(sc(i)). Once an operation has been ap\u00adplied it is moved to the Completed \nlist C(i). After machine mi has applied all operations in Pall(i) it sends an acknowledgment on the Signals \nchannel. After sending the acknowledgment the guesstimated state sg(i) is updated to [P (i)](sg(i)) to \nre.ect the changes made since tEndF lush and the completion routines in P endingCompletionRoutines are \napplied to update the local state .(i). This is done through the following three steps (i) the committed \nstate is copied to the guesstimated state by calling Copy (ii) all the completion routines in P endingCompletionRoutines \nare applied to up\u00addate the local state and (iii) each operation in [P (i)] is applied to sg(i). We will \nrefer to the time at which machine mi be\u00adgins copying the committed state on to the guesstimated state \nas tBeginUpdate(i) and the time at which the last operation from [P (i)] has .nished updating sg(i) as \ntEndUpdate(i). In the time interval between tBeginUpdate(i) and tEndUpdate(i) the imple\u00admentation does \nnot allow any new operations to be issued. 3. FlagCompletion. Once the master receives acknowledgments \nfrom all the machines the synchronization is complete. The master can start another synchronization any \ntime after this. Concurrency control. Within the guesstimate runtime concurrent updates to shared state \nare possible. Fine grained locks are used internally by the Synchronizer to avoid races. These locks \nare used to ensure the following: Operations are queued atomically into the pending list.  In the time \ninterval [tBeginF lush(i),tEndF lush(i)] no opera\u00adtions are issued.  The execution of an operation on \nthe guesstimated state hap\u00adpens atomically.  In the time interval [tBeginUpdate(i),tEndUpdate(i)] no \nopera\u00adtions are issued.  All reads to shared object o enclosed between BeginRead(o) and EndRead(o) are \nguaranteed to be atomic.  Note that all these blocking synchronization operations are used from within \nthe Synchronizer and none of them involve more than one machine. While the current implementation uses \npes\u00adsimistic concurrency control, lock free implementations and opti\u00admistic concurrency control could \nalso have been used. For exam\u00adple, the pending list could be implemented as a lock-free queue and updates \nto the shared state could be serialized with optimistic con\u00adcurrency control. This would be useful especially \nif the shared state were large, as it would allow concurrent independent operations to be applied without \nblocking. All or nothing semantics are provided for atomic operations using copy on write. The .rst time \nan object is updated within an atomic operation a temporary copy of its state is made and from then on \nall updates within the atomic operation are made to this copy. If the atomic operation succeeds, the \ntemporary state is copied back to the shared state. Conformance to the operational semantics. It can \nbe shown that there is a simulation relation between the state transitions in the GUESSTIMATE runtime \nand the rules for operational seman\u00adtics in Figure 3. The proof for local operations (corresponding to \nR1) and issuing composite operations (corresponding to R2) are straightforward. For commitment of operations \n(corresponding to R3), the crux of the argument is that even though commitment takes several rounds of \nmessages, all composite operations sub\u00admitted in this duration can be thought of as being submitted ei\u00adther \nbefore or after the entire commitment operation completes. In particular, all composite operations issued \nat machine mi be\u00adfore tBeginUpdate(i) can be thought of as issued before the atomic commit, and all composite \noperations issued at machine mi af\u00adter tEndUpdate(i) can be thought of as issued after the atomic commit. \nNote that no operations can be issued in the interval [tBeginUpdate(i),tEndUpdate(i)]. Bounded re-executions. \nA salient feature of the implementation is that though the operational semantics allows an operation \nto be ex\u00adecuted multiple (possibly unbounded) number of times, our imple\u00admentation of the GUESSTIMATE \nruntime ensures that an operation is executed at most three times (including issue and commit). We present \nan argument for why an operation can execute at most three times. An operation can be submitted at machine \nmi either outside the time interval [tBeginF lush(i),tEndUpdate(i)] or within the time interval [tEndF \nlush(i), tBeginUpdate(i)]. Note that no operation  can be submitted in the intervals [tBeginF lush(i),tEndF \nlush(i)] and [tBeginUpdate(i),tEndUpdate(i)]. Suppose an operation o is submitted outside the time inter\u00adval \n[tBeginF lush(i),tEndUpdate(i)]. Then, operation o is executed once during issue. During the next synchronization, \nthe operation o is guaranteed to get committed (because all operations in the pending list are guaranteed \nto be committed). The operation o is executed once again during commit, thus executing a total of two \ntimes. Suppose an operation o is submitted within the time inter\u00adval [tEndF lush(i),tBeginUpdate(i)]. \nAs before, operation o is ex\u00adecuted once during issue. Next, at the time tBeginUpdate(i) op\u00aderation o \nis part of the pending list P (i) and all operations that committed during the current synchronization \nhave updated the committed state sc(i). o is executed for the second time some\u00adwhere in the time interval \n[tBeginUpdate(i),tEndUpdate(i)] to up\u00addate the guesstimated state and re-establish the invariant sg(i)= \n[p](sc(i)). Finally, during the next synchronization, the operation o is guaranteed to commit and executes \none more time (as in the previous case), thus executing a total of three times.  Entering and leaving \nthe distributed system. Machines can dy\u00adnamically enter and leave the distributed system. When an appli\u00adcation \nwritten with GUESSTIMATE is started up on a new machine the GUESSTIMATE runtime adds the machine to the \nSignals and Operations meshes and broadcasts a special message on the sig\u00adnals channel. The master processes \nthis message before the next synchronization and sends the new device both the list of available objects \nand the list of completed operations. The new device ini\u00adtializes its state based on these and intimates \nthe master, who then begins synchronization. A machine that leaves the system intimates the master and \nthe master removes this machine from the next syn\u00adchronization onward. Failures and fault tolerance. \nWhen the master starts a new syn\u00adchronization phase it assumes all machines are active. However, if the \nsynchronization is stalled for more than a threshold duration, the master goes through the log of messages \nsent on the signals channel to detect the stalling machine. It resends the signal to which the machine \nfailed to respond. If the fault were transient the ma\u00adchine might respond to this resent signal. If the \nmachine still does not respond, the master removes the machine from the current syn\u00adchronization phase \nand sends it a restart signal. On receiving the restart signal the machine shuts down the current instance \nof the application and restarts the application. Upon restart the machine re-enters the system in a consistent \nstate. Our current implementation is not tolerant to failure of the master. This support can be added \nby designating a new machine as master if no synchronization messages are received for a threshold duration. \n5. Design Patterns The two main advantages of programming with GUESSTIMATE are simplicity and responsiveness. \nThe programming model is very close to sequential programming in that the programmer creates shared objects, \nand issues shared operations on them which exe\u00adcute synchronously without blocking on the guesstimated \nstate. The simple (and common) case is when the results of the operation dur\u00ading the commitment phase \nare the same as the results obtained from the guesstimated state. However, the programmer needs to handle \nthe case when the two results are indeed different. We encountered several such situations in the applications \nwe have written using GUESSTIMATE, and we have been able to handle these using a few design patterns \ninvolving speci.cations, completions, atomic oper\u00adations and blocking constructs. We describe these design \npatterns below. Speci.cations. As noted in Section 3, we recommend a program\u00adming discipline where every \nshared operation s conforms to a spec\u00adi.cation .s . S\u00d7S (recall from Section 3 that s conforming to .s \nmeans that if s returns true then s respects .s, and if s returns false then the shared state is unchanged). \nWe have written such speci.ca\u00adtions .s using Spec# [3], and checked that the body of s conforms to .s \nusing the Boogie program veri.er [2]. Consider a machine mi that executes a sequence of operations (s, \nt, . . .), where each shared operation s conforms to a speci.\u00adcation .s. Suppose all these operations \nsucceed during execution on the guesstimated state. Suppose also that each of the opera\u00adtions succeeds \nduring commitment (we consider the case where some of these operations fail during commitment later). \nThis means that the committed sequence of operations could be of the form 12 i (o1, . . . , s, o i , \n. . . , t, . . .) where operations oj submitted by other machines are interleaved between the operations \n(s, t, . . .). How\u00adever, due to de.nition of conformance, the pre and post states of operations s and \nt in the committed sequence necessarily satisfy .s and .t respectively. For example, in our car pool \napplication, a method GetRide(Event e) searches through various ride sharing options to get a ride for \nthe user to attend event e. The operation succeeds if some vehicle has space for the user. However, it \nmay so happen that during the execution of the method on the guesstimated state the user gets a ride \non vehicle v3 and by the time the operation is committed, vehicle v3 is full. We have written a predicate \n.GetRide which is satis.ed if the user gets a ride on some vehicle, and estab\u00adlished that the implementation \nGetRide conforms to .GetRide using Boogie. This ensures that as long as GetRide succeeds in the com\u00admitted \nsequence, the user will have some ride, though perhaps not in the initial vehicle v3 that was obtained \nduring execution on the guesstimated state. This design pattern is easily extended to hierarchical OrElse \noperations. If operations s and t both conform to a speci.cation ., it can be established that the operation \ns OrElse t also conforms to .. Thus, the programmer can compose several alternatives to achieve a goal \n. using using the OrElse constructor, and still re\u00adspect this design pattern, allowing the .exibility \nthat the operation could succeed using one alternative during the execution on the guesstimated state \nand another alternative during commitment. Completions. Writing speci.cations for each shared operation \nandchecking for conformance greatly simpli.es the task of writingcompletion routines. If we use this \ndiscipline, then completionroutines can be written using the form: (bool b) => if (b) \"indicate in UI \nthat the operation successfully committed\" else \"indicate in UI that the operation failed, and ask the \nuser to take remedial action\" Note that the completion routine for the Sudoku application seen in Figure \n2 follows this pattern. In essence, the above two design patterns split up the respon\u00adsibility for handling \nvariances between the guesstimated state and actual committed state between the programmer and the user. \nThe programmer codes up several alternatives for achieving the goals of an operation s such that the \noperation s returns true if any of these alternatives can be executed successfully, and ensures that \na speci\u00ad.cation .s (derived from the goal of the operation) holds for each of these alternatives using \nstatic analysis. If all the alternatives fail during commitment, the completion routine throws up the \nproblem to the user, and asks the user to deal with the failure. Atomic operations. There are two kinds \nscenarios where we have found use for atomic operations. The .rst is obvious when we want a set of operations \nto be executed with all-or-nothing seman-1 tics. This happens in our event planning application when \na user 32 wants to sign up for two events or none. 4  The second kind of scenario where we have found \nuse for 5 atomic operations is when there is a value dependency between 6 operations. Suppose we have \ntwo operations s and t such that a 87 location written by s is read or written by t. Then, there is the \npos-9 sibility that s and t succeed during execution on the guesstimated 10 state, and that s could fail \nduring commitment, and t could succeed. 11 12 In such situations if the dependence has to be enforced \nwe suggest 13 grouping s and t together as a single atomic operation. 14 15 Blocking operations. Finally, \nthere are certain situations where we 16 really want to be sure that an operation commits before executing \n17 18 subsequent operations. We have encountered this situation, for in-19 stance, in our event planning \napplication, where we .rst require a 20 user to login, and we do not want to allow the user to do anything \n21 before we are sure that the login has succeeded.22 We have been able to program such scenarios by \nblocking the23 main thread on issuing the operation and waiting until the comple-24 tion routine unblocks \nit. The general template for doing so is asbelow. res = IssueOperation(loginOperation, (bool b) => if \n(b) \"release the thread and allow access\" else \"release the thread and deny access\" if(res) \"block the \nthread\" In summary, we have presented four design patterns that we have found useful in writing GUESSTIMATE \napplications. Our ex\u00adperience is that the above design patterns provide simple ways to handle common \nsituations that arise in programming collaborative applications using GUESSTIMATE. 6. Experience We have \nbuilt 6 collaborative applications using the GUESSTIMATE programming model. These are a collaborative \nmulti-player Su\u00addoku puzzle, an event planning application, a message board appli\u00adcation, a car pool \nsystem, an auction system and a small scale twit\u00adter application. In all these applications the shared \nstate and shared operations are encapsulated together in a shared object class. This class derives from \nthe abstract base class GSharedObject exposed through GUESSTIMATE and implements a copy method. For exam\u00adple, \nthe Sudoku class contains a 9x9 array and an update operation that form the shared data and operation \nrespectively. It also imple\u00adments a copy method that when passed a source object, copies the 9x9 array \nfrom the source to the this object. At a high level the rest of the application design typically involves \nhaving to call ap\u00adpropriate API functions to create new instances of shared objects and issue operations \nbased on user interaction. All applications are written with about 500-700 lines of code. Below we share \nour ex\u00adperience in developing these applications using GUESSTIMATE by highlighting some interesting design \ndecisions that we made. Updating local state. While the shared state is kept globally con\u00adsistent and \nup-to-date by the runtime, the programmer has to en\u00adsure that the local state is kept up-to-date. The \nstate used by the GUI has to not only be updated in response to user actions but also in response to \nsynchronizer events, and this can be done us\u00ading GUESSTIMATE s completion operations. Designing completion \noperations correctly for the multi-player Sudoku was challenging. Our .rst design of the GUI was as de\u00adscribed \nin Section 2 where initially when an operation is submitted, the color of the square is changed to yellow, \nand later depending private void button_signin_Click(object sender, EventArgs e){ string usrnm = textBox_username.Text; \nstring passwd = TextBox_password.Text; sharedOp op = Guesstimate.CreateOperation(handle,usrnm,passwd); \nSemaphore s=new Semaphore(0,1); bool res = Guesstimate.IssueOperation(op, (bool b) => { if (b) { my_name \n= username; s.Release();} else { register_failed r = new register_failed(); r.ShowDialog(); s.Release(); \n} } ); if (!res) this.Close(); else{ this.Cursor = Cursors.WaitCursor; s.WaitOne(); this.Cursor = Cursors.Default; \nthis.Close(); } } Figure 4. Sample code to implement a blocking operation on success or failure the \ncolor is changed to green or red respec\u00adtively. However, this design differentiated successful operations \nof the current user from the successful operations done by other users, and our users did not like this \ndistinction. Ultimately, we chose to remove the green color all together and depict all successful op\u00aderations \nfrom all users uniformly. Thus, we decided to use special markings only for tentative operations and \nfailing operations. When an operation succeeds at commit time, we use the completion op\u00aderation to remove \ntentative markings. Another interesting design decision was with regards to refresh\u00ading the GUI. In most \napplications the GUI displays only user spe\u00adci.c information in detail, while displaying other information \nonly on demand. For example, in event planner the list of activities joined by the user is always on \ndisplay and is kept up-to-date via completion operations. On the other hand information regarding va\u00adcancy \nstatus of events is not displayed unless asked for. Therefore it is often suf.cient to frequently refresh \nonly the user speci.c state of the GUI while updating other state less frequently. Completion operations \nare well suited to do this. The one exception we found is in Sudoku where it is essential for updates \nfrom other users to re.ect on the grid as and when they happen. In our initial design, the grid was refreshed \nevery time the user submitted an operation and every time a completion operation was run. However, this \nalone was not suf.cient. The user often did not see updates from operations submitted elsewhere. In our \n.nal design we choose to call refresh based on user activity. Every time the user moves the mouse around \non a grid or the grid comes to the fore, refresh is called. So as long as the user is active the display \nis kept up-to-date. Our user experience study suggests that this is an effective solution. Additional \nAPI support, that provides a call back for changes to a shared object via remote operations, could provide \nan alternate solution. Blocking via completion operations. In .ve of the applications (all but Sudoku) \nwe needed to implement two functionalities, signin and new user registration, as blocking functions. \nNew user registra\u00adtion is made blocking to ensure that the same username is not si\u00admultaneously registered \nat two machines. And we choose to make signin blocking to ensure that a user is signed in only on one \nma\u00adchine at a time. Blocking is implemented as shown in Figure 4 by waiting on a semaphore until the \ncompletion operation releases it. Here, the login operation is created in line 4, and issued in line \n6. If the result of the IssueOperation is true, then the issuing thread simply waits on semaphore s at \nline 20. The wait is released by the completion routine executing s.Release() in line 9. Apart from these \ntwo functionalities the rest of the operations in all applications are better suited to a non-blocking \ndesign.  Atomic and OrElse Operations. Atomic operations and OrElse operations are used extensively \nin the event planner application. Users can choose to join one among many events and we im\u00adplemented \nthis using an OrElse operation. Atomic operations are used when a user wants to perform multiple operations \nwith all-or\u00adnothing semantics, for example a user chooses to go to a party only if she also gets a ride \nto the party. Atomic operations are also used when there is a value dependence via the shared state. \nIn the event planner, a request to join an event can fail either because there is no more vacancy in \nthe event or because the user has already joined the maximum allowed events. In case a user wants to \njoin an im\u00adportant event (eventa), but cannot because she is already used her quota, she might want to \nleave some other event (eventb) and join eventa. However, she wants to retain eventb unless she can join \neventa for sure. We use Atomic operations to ensure that such de\u00adpendencies are respected during execution. \nSpeci.cations and contracts. We designed all classes that imple\u00adment GSharedObject in Spec#. Speci.cations \nof two kinds were useful. Method contracts were used to specify that when a shared operation returns \nfalse no updates are made to the shared state and when it returns true changes are made only to the relevant \nparts. Object invariants were used to express that both the state before and after a method satisfy the \nobject invariant. Spec# translates contracts into a set of assertions and uses Boo\u00adgie to statically \nverify these assertions. Boogie classi.es assertions into provably correct assertions, provably failing \nassertions (these are .agged as warnings at compile time) and other assertions which cannot be proven \nstatically. Spec# translates the last category of as\u00adsertions into checks and throws up a warning if \nthere is a violation at runtime. Programming with Spec# helped us in a few occasions to catch bugs in \nour application logic. For example, the Sudoku grid row check had an off by one error in array indexing \nwhich was caught with the aid of Spec#. For our .nal version of Sudoku with contracts, Spec# generated \n323 assertions out of which boogie was able to verify 271 as correct while the remaining 52 were translated \ninto runtime checks. Maintaining local state. All updates to shared state happen via GUESSTIMATE and \nare internally protected by locks from within the GUESSTIMATE runtime. However, ensuring that updates \nto local state are protected by locks is the programmers responsibility. Particularly, as both completion \noperations and local operations can update local state, all state accessed within completion operations \nmust be synchronized appropriately. For example, in the event planner application, both the local operations \nthat mark tentative changes and the completion operations, update a tentative joined list. Care must \nbe taken to protect this list with a lock. In our experience, we .nd that the non-blocking nature of \nGUESSTIMATE is well suited to programming collaborative dis\u00adtributed applications. In the rare cases \nthat blocking operations are required, they can implemented as shown in Figure 4. 7. Performance Evaluation \nIn this section we report the performance of the GUESSTIMATE runtime in terms of the time it takes for \neach synchronization (all three stages put together) to complete. We also study the scalability of applications \nwritten with guesstimate by measuring how increas\u00ading the number of users impacts (i) the synchronization \ntime and (ii) the number of con.icts. All measurements were made while run\u00adning the Sudoku application \nwith 2 to 8 users within a local area network over a one hour time period. We chose to use Sudoku as \nthe test application, since we could get several volunteers to use it with concurrent user activity. \n Figure 5. Distribution of time taken for synchronization Synchronization time. Figure 5 plots the distribution \nof the time taken for synchronizations over a long run of the application in\u00advolving 8 users solving \n2 Sudoku grids. It can be seen that the time taken by guesstimate to complete a synchronization is within \n0.5 seconds most of the time. There are 2 outliers in the distribution where a synchronization takes \nmore than 12 seconds. These corre\u00adspond to the times when synchronization stalled and the master had \nto perform a fault recovery. However, owing to the non-blocking nature of guesstimate even during these \ntimes the user could con\u00adtinue performing operations. Any blocking implementation would have rendered \nthe system unresponsive at these times. Figure 6. Average time to synchronize vs. number of users Figure \n6 shows the impact of number of users on synchroniza\u00adtion time both in the presence and absence of user \nactivity. The average synchronization time is measured by ignoring the outliers (time > 12 seconds), \nas including them would skew the average away from the median. Two interesting observations can be made \nfrom this plot. First, the plot indicates that presence or absence of user activity does not affect the \nsynchronization time by much. This indicates that the dominant component of the time for synchroniza\u00adtion \nis network delay. Second, it can be seen that the time for synchronization in\u00adcreases linearly with number \nof users. This can be attributed to the serial nature of the .rst stage (AddUpdatesToMesh) of syn\u00adchronization \n(refer to Section 4). However, even assuming a linear increase guesstimate should easily scale to a 100 \nusers as even with 100 users the average time to synchronize would be within 3 sec\u00adonds. This is reasonable \neven for a high user activity event like a multi-player game, but possibly not for a highly sophisticated \nreal time game. For collaborative applications which do not have such high user activity, guesstimate \nin its current form should scale to a 1000 users. To scale it further we would have to parallelize the \n.rst stage, which should also not be very hard. In our current de\u00adsign the .rst stage is kept serial \npurely for ease of monitoring and debugging.  Figure 7. Number of con.icts vs. number of users Con.icts. \nFigure 7 shows the number of instances when an oper\u00adation that succeeded on issue failed at commit time \nduring our ex\u00adperiments. These measurements were made by adding a new user for every 100 synchronizations \nperformed by the runtime. As can be seen con.icts are very rare even the presence of 8 active users. \nFailure and recovery. During the one hour period for which we gathered statistics, GUESSTIMATE encountered \nthree failures, once when one of the machines was restarted while the application was running, and twice \nwhen the synchronization was stalled possibly because a message was lost in transmission. GUESSTIMATE \nrecov\u00adered in all three cases automatically, once by resending the lost message and twice by removing \nthe machine from the stalled syn\u00adchronization loop and sending a restart message, and none of the other \nusers were even aware of the failure. 8. Related Work Distributed systems have existed for several decades \nnow. Early re\u00adsearch on consistency guarantees for data shared across distributed systems was from the \ndatabase community [4]. The notions of replicated databases with one-copy serializability was introduced. \nOne-copy serializability allows for pessimistic replication as the replicas are kept consistent at all \ntimes. These systems guaran\u00adtee high consistency but can lead to low performance and avail\u00adability [16]. \nOptimistic replication on the other hand allows for higher availability and faster performance than pessimistic \nrepli\u00adcation. However, the replicas can diverge and safeguards need to be provided to ensure that some \nform of consistency is guaran\u00adteed. Systems with optimistic replication typically guarantee even\u00adtual \nconsistency [14]. Many systems have been built for mobile and Internet services that support optimistic \nreplication with an eventual consistency guarantee. The work most closely related to the guesstimate \nsys\u00adtem is the mobile database system Bayou [12]. Bayou replicates a database on multiple servers and \nallows clients to submit SQL like queries to the database. This query is processed in one server and \nthen propagated across to other servers using pairwise entropy. It allows for speci.cation of per write \nmerge functions to resolve con.icts. Bayou relies on features in the database storage system to log all \noperations on the database and to rollback and re-execute them multiple times so that all servers see \noperations in the same order. Little is known about the way to program applications for Bayou. GUESSTIMATE \ndiffers in that it provides a well de.ned API to build applications for distributed systems. It also \ndoes not need any guarantees from the underlying storage system. Unlike Bayou, GUESSTIMATE maintains \nall state in memory. In addition to OrElse operations that are similar to the merge functions de\u00ad.ned \nin Bayou, GUESSTIMATE provides completion operations to notify application users about con.icts. Further, \nit allows users to naturally express related operations as Atomic operations. The IceCube system [10] \nallows for users to specify constraints on the order in which operations should be executed. Constraints \nlike either op1 or op2 should be performed and op1 should only be performed if op2 is performed can be \nspeci.ed. The .nal commit order can then be any order that satis.es all constraints. GUESSTI-MATE respects \nthe natural or causal ordering between operations submitted by the same user. In addition it allows for \nhierarchical operations. Operational transformation [7] is a technique used for building collaborative \napplications that allows operations to be committed as soon as they are submitted. Operations received \nfrom other replicas are suitably transformed before being applied so that their seman\u00adtic effect is preserved. \nWhile this is well suited for text applications where transformations can be carefully de.ned, writing \nsuch trans\u00adformers is hard for other applications. Some of the design principles of GUESSTIMATE like \nreplication, availability and con.ict resolu\u00adtion are also used in the design of replicated and distributed \n.le systems such as Unison [13], Coda [15] and GFS [8]. Mace is a language extension for C++ that allows \nthe program\u00admer to specify components of a distributed system in the form of a state transition model \nand transforms them into a C++ imple\u00admentation. Mace also enables the use of code pro.lers and model \ncheckers to help identify performance and correctness errors in dis\u00adtributed applications. GUESSTIMATE \non the other hand provides speci.c support for the development of interactive applications and chooses \na particular design point in the performance-consistency trade-off that is well suited to such applications. \nOther languages like X10 [6] target distributed systems with a partitioned global ad\u00address space. Extensions \nto software transactional memory that scale to distributed systems with a partitioned global address \nspace have also been proposed [5]. GUESSTIMATE is not restricted to any par\u00adticular distributed system \narchitecture. In summary, the twin goals of providing a performance\u00adconsistency trade-off that is well \nsuited to collaborative applica\u00adtions and a programming API that allows the programmer to build such \napplications sets GUESSTIMATE apart from existing work. 9. Limitations and Future Work GUESSTIMATE has \nseveral limitations. We list them below together with some directions for future work. Modularity and \nlayering. Applications are often written in a lay\u00adered fashion. While we have abundant experience using \nGUESSTI-MATE to write applications in which the user directly interacts with the API via a user interface, \nwe do not know if we can develop multi-layered software with it. Size of shared state. GUESSTIMATE maintains \nmultiple copies of the shared state and copies the committed state to the guesstimated state at the end \nof each synchronization. Dealing with large shared objects could therefore slow down guesstimate. However, \noptimiz\u00ading copy-on-write has been studied in several contexts, such as STMs [1], and by using programming \nlanguage features to inform the runtime about side-effect free code and optimize copying in such situations. \n Updating local state. With GUESSTIMATE updating the local state whenever changes are made to shared \nstate still remains the pro\u00adgrammer s responsibility. Completion operations provide one way to update \nlocal state but these do not handle updates from remote operations. A mechanism to register a callback \nfunction for remote updates could prove useful. Scalable run-time. As mentioned in Section 7 the current \nversion of GUESSTIMATE might not scale beyond 1000 nodes, as the syn\u00adchronization time increases linearly \nwith number of users. While the non-blocking nature of GUESSTIMATE ensures that users are not blocked \nduring synchronization, slow synchronization affects the lag between submission and completion, and hence \naffects user experience. One possibility is to parallelize the .rst stage of the synchronization protocol \nso that the time taken depends only on the number of operations and the network delay but not on the \nnumber of users. Fault tolerance. While the current version of GUESSTIMATE toler\u00adates some faults, the \ndependence of the runtime on a single master creates a single point of failure. One possibility is to \nextend the im\u00adplementation to dynamically change the master in case the master fails. Off-line updates. \nGUESSTIMATE does not currently support off\u00adline updates. Adding such support could be non-trivial in \nthe sense that if the time gap between the executions on the guesstimated and committed states is large, \nthe scope for discrepancy and con.icts also becomes large. ACKNOWLEDGMENTS We thank Dave Campbell, Dave \nDetlefs, Anders Hejlsberg, Jim Larus, Sanjiva Prasad, Rama Ramasubramanian and the anony\u00admous reviewers \nfor their insightful comments on earlier drafts of this paper. References [1] Ali-Reza Adl-Tabatabai, \nBrian T. Lewis, Vijay Menon, Brian R. Murphy, Bratin Saha, and Tatiana Shpeisman. Compiler and runtime \nsupport for ef.cient software transactional memory. In PLDI 06: Programming language design and implementation, \n2006. [2] Mike Barnett, Bor Yuh Evan Chang, Robert Deline, Bart Jacobs, and K. Rustanm. Leino. Boogie: \nA modular reusable veri.er for object\u00adoriented programs. In FMCO 05: Formal Methods for Components and \nObjects, 2006. [3] Mike Barnett, K. Rustan M. Leino, and Wolfram Schulte. The Spec# programming system: \nAn overview. In CASSIS 04: Construction and Analysis of Safe, Secure and Interoperable Smart Devices, \n2004. [4] Philip A. Bernstein, Vassos Hadzilacos, and Nathan Goodman. Concurrency Control and Recovery \nin Database Systems. 1987. [5] Robert L. Bocchino, Vikram S. Adve, and Bradford L. Chamberlain. Software \ntransactional memory for large scale clusters. In PPoPP 08: Principles and practice of parallel programming, \n2008. [6] Philippe Charles, Christian Grothoff, Vijay Saraswat, Christopher Donawa, Allan Kielstra, Kemal \nEbcioglu, Christoph von Praun, and Vivek Sarkar. X10: An object-oriented approach to non-uniform cluster \ncomputing. In OOPSLA 05: Object-oriented programming, systems, languages, and applications, 2005. [7] \nC. A. Ellis and S. J. Gibbs. Concurrency control in groupware systems. In SIGMOD 89: SIGMOD international \nconference on Management of data, 1989. [8] Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. The \nGoogle .le system. In SOSP 03: Symposium on Operating systems principles, 2003. [9] Maurice P. Herlihy \nand Jeannette M. Wing. Linearizability: A correctness condition for concurrent objects. ACM Trans. Program. \nLang. Syst., 12(3):463 492, 1990. [10] Anne-Marie Kermarrec, Antony Rowstron, Marc Shapiro, and Peter \nDruschel. The Icecube approach to the reconciliation of divergent replicas. In PODC 01: Principles of \ndistributed computing, 2001. [11] Leslie Lamport. How to make a multiprocessor computer that correctly \nexecutes multiprocess programs. IEEE Trans. Computers, 28(9), 1979. [12] Karin Petersen, Mike Spreitzer, \nDouglas Terry, and Marvin Theimer. Bayou: Replicated database services for world-wide applications. In \nEW 7: Proceedings of the 7th workshop on ACM SIGOPS European workshop, 1996. [13] Benjamin C. Pierce \nand J\u00b4ome Vouillon. What s in Unison? A formal er speci.cation and reference implementation of a .le \nsynchronizer. Technical Report MS-CIS-03-36, Dept. of Computer and Information Science, University of \nPennsylvania, 2004. [14] Yasushi Saito and Marc Shapiro. Optimistic replication. ACM Comput. Surv., 37(1), \n2005. [15] M. Satyanarayanan. The evolution of Coda. ACM Trans. Comput. Syst., 20(2), 2002. [16] Haifeng \nYu and Amin Vahdat. The costs and limits of availability for replicated services. In SOSP 01: Symposium \non Operating systems principles, 2001.  \n\t\t\t", "proc_id": "1806596", "abstract": "<p>We present a new programming model GUEESSTIMATE for developing collaborative distributed systems. The model allows atomic, isolated operations that transform a system from consistent state to consistent state, and provides a shared transactional store for a collection of such operations executed by various machines in a distributed system. In addition to \"committed state\" which is identical in all machines in the distributed system, GUESSTIMATE allows each machine to have a replicated local copy of the state (called \"guesstimated state\") so that operations on shared state can be executed locally without any blocking, while also guaranteeing that eventually all machines agree on the sequences of operations executed. Thus, each operation is executed multiple times, once at the time of issue when it updates the guesstimated state of the issuing machine, once when the operation is committed (atomically) to the committed state of all machines, and several times in between as the guesstimated state converges toward the committed state. While we expect the results of these executions of the operation to be identical most of the time in the class of applications we study, it is possible for an operation to succeed the first time when it is executed on the guesstimated state, and fail when it is committed. GUESSTIMATE provides facilities that allow the programmer to deal with this potential discrepancy. This paper presents our programming model, its operational semantics, its realization as an API in C#, and our experience building collaborative distributed applications with this model.</p>", "authors": [{"name": "Kaushik Rajan", "author_profile_id": "81100661664", "affiliation": "Microsoft Research, bangalore, India", "person_id": "P2184549", "email_address": "", "orcid_id": ""}, {"name": "Sriram Rajamani", "author_profile_id": "81100468626", "affiliation": "Microsoft Research, Bangalore, India", "person_id": "P2184550", "email_address": "", "orcid_id": ""}, {"name": "Shashank Yaduvanshi", "author_profile_id": "81435609650", "affiliation": "Indian Institute of Technology, Delhi, India", "person_id": "P2184551", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806621", "year": "2010", "article_id": "1806621", "conference": "PLDI", "title": "GUESSTIMATE: a programming model for collaborative distributed systems", "url": "http://dl.acm.org/citation.cfm?id=1806621"}