{"article_publication_date": "06-05-2010", "fulltext": "\n Ur: Statically-Typed Metaprogramming with Type-Level Record Computation Adam Chlipala Impredicative \nLLC, Cambridge, MA, USA adamc@impredicative.com Abstract Dependent types provide a strong foundation \nfor specifying and verifying rich properties of programs through type-checking. The earliest implementations \ncombined dependency, which allows types to mention program variables; with type-level computation, which \nfacilitates expressive speci.cations that compute with re\u00adcursive functions over types. While many recent \napplications of dependent types omit the latter facility, we argue in this paper that it deserves more \nattention, even when implemented without depen\u00addency. In particular, the ability to use functional programs \nas speci.\u00adcations enables statically-typed metaprogramming: programs write programs, and static type-checking \nguarantees that the generating process never produces invalid code. Since our focus is on generic validity \nproperties rather than full correctness veri.cation, it is pos\u00adsible to engineer type inference systems \nthat are very effective in narrow domains. As a demonstration, we present Ur, a program\u00adming language \ndesigned to facilitate metaprogramming with .rst\u00adclass records and names. On top of Ur, we implement \nUr/Web, a special standard library that enables the development of modern Web applications. Ad-hoc code \ngeneration is already in wide use in the popular Web application frameworks, and we show how that generation \nmay be tamed using types, without forcing metaprogram authors to write proofs or forcing metaprogram \nusers to write any fancy types. Categories and Subject Descriptors D.3.2 [Programming Lan\u00adguages]: Applicative \n(Functional) Programming; F.3.3 [Logics and Meanings of Programs]: Type Structure General Terms Languages, \nReliability, Security Keywords dependent types, metaprogramming 1. Introduction Dependent types are a \ntechnique that is picking up momentum in practical language design. A dependent type system allows types \nto refer to program variables whose values are not determined un\u00adtil runtime. The classical approach, \nexempli.ed by Coq [3] and Agda [17], is based on dependent type theory. These languages combine dependent \ntyping with rich facilities for type-level com- Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 10, June 5 10, 2010, Toronto, Ontario, Canada. Copyright \nc &#38;#169; 2010 ACM 978-1-4503-0019-3/10/06. . . $10.00 putation. Types may be computed via calls to \nrecursive functions. This paper is about a very practical application of type-level com\u00adputation, without \ndependency, in a system that is still very much inspired by Coq and Agda. Until recently, languages with \ndependent type systems were in\u00advariably designed to be usable for full correctness veri.cation. A type \nsystem must be quite complex to support that goal. It will almost certainly have undecidable type inference, \nas well as in\u00adtractable type inference in practice. Thus, to use such a system to verify serious applications, \na programmer must inevitably spend signi.cant effort writing annotations and proofs that exist only to \nappease the type checker. At the same time, the same language fea\u00adtures can be very useful in checking \ngeneral program validity prop\u00aderties, in a sense more in line with mainstream usage of type sys\u00adtems. \nBy identifying a narrow domain of properties, we can hope to build an effective type inference procedure, \nwithout compromising the programmer s ability to employ clever abstractions. We suggest metaprogramming \nin Web applications as one such killer application. The term metaprogramming is used to de\u00adscribe programs \nthat perform code generation, code introspection, or both. In this paper, we restrict our attention to \ncode generation. This will include both heterogeneous metaprogramming, where programs in our Turing-complete \nlanguage build SQL queries and HTML pages; and homogeneous metaprogramming, where pro\u00adgrams in our Turing-complete \nlanguage generate other such pro\u00adgrams. In the latter category, we follow standard ideas from the world \nof dependent typing, using type-level computation to avoid explicit syntax manipulation. Nonetheless, \nwe achieve the same functionality that is traditionally implemented with code genera\u00adtion. The most popular \napproach to Web application programming today involves usage of frameworks implemented in dynamic lan\u00adguages, \nincluding Ruby on Rails1 and Django2. These systems in\u00adclude metaprogramming components to help coders \nget new Web applications up and running quickly. In some cases, this is ad-hoc generation of source code \nas strings; in other cases, it is re.ection\u00adbased runtime code generation. No matter the details, there \nis no static checking of code generators. It is easy to have bugs that go uncaught even by systematic \ntesting. Lurking bugs in Web code generators are a serious business. One study [7] found that over 30% \nof Web applications are sus\u00adceptible to some kind of code injection attack, where code from an untrusted \nsource is relayed to browsers or database servers through a Web application that does insuf.cient input \nsanitization. It is hard enough to treat input securely in a standalone application; it is even harder \nto write a code generator that never outputs a vulnerable pro\u00ad 1 http://www.rubyonrails.org/ 2 http://www.djangoproject.com/ \n gram. A rich enough static type system can guarantee that metapro\u00adgrams are valid in this sense. For \ninstance, we can model HTML pages and SQL queries with rich abstract syntax tree types. When treating \nthese types as simple strings, it is easy to splice in unsanitized user input in a way that has surprising \nparsing consequences. By working instead with syntax trees, we avoid such complexities. We can go even \nfurther and use advanced type system features to guarantee that, for instance, every constructible SQL \nquery makes correct assumptions about a database schema. Finally, with further type system sophistication, \nwe can assign static types to programs that generate code; for instance, we can assign a static type \nto a function that is generic in a database schema, producing different queries for different schemas. \nAny type-correct metaprogram of this kind is guaranteed to output query code that is immune to code injection \nattacks. Statically-typed code generation is attractive for reasons beside security. A serious barrier \nin the way of wider use of metaprogram\u00adming is the dif.culty in building abstractions that programmers \ncan .gure out how to use. A good static type system can provide a structuring principle and a source \nof machine-checked documenta\u00adtion about the interfaces of generic components. How can we arrive at a \nlanguage environment that can support our vision? One strategy is to start with a less esoteric program\u00adming \nlanguage and gradually add expressivity. In particular, fea\u00adtures once associated only with dependently-typed \nlanguages have recently been added to Haskell, in the form of extensions like multi\u00adparameter type classes \nwith functional dependencies [12], general\u00adized algebraic datatypes [27], and open type functions [26]. \n An alternative strategy is to design a new programming lan\u00adguage, picking and choosing features inspired \nby traditional dependently\u00adtyped languages. Languages like Cayenne [2] and Sage [14] sacri\u00ad.ce decidable \ntype-checking but keep all three of dependent types, type-level computation, and broad applicability. \nAnother popu\u00adlar approach is to introduce some form of dependent types with\u00adout type-level computation, \nas in ATS [5], Deputy [6], and liquid types [25]. Finally, a language can support rich type-level compu\u00adtation \nwithout dependent typing, as in Omega [29]. Considering classical tools like Coq and Agda, Haskell exten\u00adsions, \nand the previous paragraph s new languages, there is a seri\u00adous common weakness. They do not provide \nvery good support for the construction of new abstractions that manipulate richly-typed values. In each \ncase, either the type system is too weak to sup\u00adport interesting metaprogramming applications, or the \nannotation and/or proof burden needed to support metaprogramming is very high. In the latter category, \ntype checkers are usually very good at checking normal programs, where all relevant pieces of type-level \ndata are fully determined. However, when some of these pieces of data are unknown, the undecidability \nof type inference becomes a serious problem. Serious metaprograms generally need to include some kind \nof explicit proof terms to convince the type-checker. We illustrate the problem with some example code \nin Coq, a system that can be considered as maximally expressive within this design space. Consider code \nthat manipulates heterogeneous lists, where the type of a list conveys exactly how many elements it has, \nas well as what type each element should have. These types may be different for different list positions. \nIt is natural to de.ne a concate\u00adnation operator +++ for heterogeneous lists, whose type is de.ned in \nterms of normal list concatenation ++. Richer versions of all of these constructions are very useful \nin our metaprogramming do\u00admain, for such tasks as modeling database schemas. This particular contrived \nexample is chosen for its simplicity, but the problem of satisfying the type-checker is a pervasive one \nthat underlies the practical differences between Ur and related languages. Definition l1 := [int, string]. \nDefinition l2 := [bool]. Definition l3 := [int]. Definition h1 : hlist l1 = [< 1, \"ABC\" >]. Definition \nh2 : hlist l2 = [< true >]. Definition h3 : hlist l3 = [< 4 >]. Definition h123 : hlist (l1 ++ (l2 ++ \nl3)) = (h1 +++ h2) +++ h3. The li variables are lists of types, written in usual ML-like notation. In \nthe de.nitions of the hi variables, each type list is used to describe the shape of a heterogeneous list. \nThe .nal de.nition of h123 concatenates our three lists into a single list. Notice that, in the type \nof h123, we apply normal list concatenation as if it were right-associative, while, in the body of the \nde.nition, we apply heterogeneous list concatenation left-associatively. In Coq (and in the other languages \nwe surveyed above with type-level computation), it is easy to see that this implicit use of associativity \nis legal. The lists li are constants, so we simply evaluate the two type lists l1 ++ (l2 ++ l3) and (l1 \n++ l2) ++ l3, verifying that the resulting constant lists are equal. Things get more complicated if we \nwant to write a generic associative-concatenation function. Definition acat l1 l2 l3 (h1 : hlist l1) \n(h2 : hlist l2) (h3 : hlist l3) : hlist (l1 ++ (l2 ++ l3)) = cast (assoc l1 l2 l3) ((h1 +++ h2) +++ h3). \nHere, the variables li are type parameters, as in paramet\u00adric polymorphism. Since we do not know their \nvalues, we can\u00adnot check type equivalences via the simple evaluate-and-compare method. Instead, to get \nour function to type-check, we had to in\u00adclude an explicit cast expression. The sub-expression assoc \nl1 l2 l3 is a proof term, establishing the fact (l1++l2) ++l3= l1 ++ (l2 ++ l3). The theorem assoc was \nproved separately in a library, using techniques more mathematical than programming\u00adoriented. In all \nof the systems we mentioned earlier, this kind of explicit casting is the best that can be done to support \nthe combination of rich typing and genericity. The burden may not seem too great from the classical perspective \nof dependent-types-for-full-veri.cation. However, when writing a code generator for a Web application, \nsuch typing details are far from the main point of the code. Facts like concatenation associativity should \nbe applied automatically. Today s type system state of the art fails to provide this facility. In this \npaper, we argue for use of a language with type-level computation but no dependency. Moreover, we are \nnot interested in supporting full correctness veri.cation. We only care to handle the sorts of typing \nissues that come up in metaprogramming. This is an opportunity to avoid any need for explicit proof terms \nby building a customized type inference engine. Our approach is by no means a deep theoretical advancement. \nThe key structuring ideas are already there in Coq and Agda, and our system could be implemented as a \nlibrary in one of those languages. However, using such a library would require heroic efforts in type \nannotation and theorem-proving. Dependent types are popularly viewed as more theory than practice; in \nthis work, we show that, with just a small injection of domain-speci.c smarts, this old piece of theory \nleads to a practical tool that is highly competitive in a popular real-world application domain. We present \nthe Ur programming language, whose novel fea\u00adtures center on .rst-class, type-level names and records. \nUr in\u00adcludes specialized heuristic type inference that makes it possible to write record-manipulating \nmetaprograms that are free of explicit proof terms. On top of Ur, we have built Ur/Web, a domain-speci.c \nlanguage for constructing modern Web applications. Ur/Web adds a special standard library, some parsing \nextensions, and a special\u00adized compiler, but it relies only on the generic Ur type inference engine. \nThe signature of the Ur/Web library describes the syntax and typing constraints of HTML documents and \nSQL queries, and the inference engine is suf.cient to type-check metaprograms that build programs that \nbuild documents and queries.  Type inference for Ur is undecidable, and we have no theorems that support \nour choice of inference procedure. Instead, we point to empirical evidence of Ur/Web s effectiveness. \nWe have built the tool set to be a real, practical Web application framework that is highly competitive \nwith mainstream frameworks. We claim that, in the hands of an experienced functional programmer, Ur/Web \nis far ahead of the competition in each of the critical areas of programmer productivity, security, and \nperformance. In this paper, we focus on productivity, measured in terms of case studies in using Ur/Web \nto build practically-useful metaprograms. In particular, we have based our design on two .rm principles. \n1. The author of a metaprogram should never need to write a proof term. He may write more involved types \nthan usual, and he may need to add new type parameters to some functions, but he should never need to \ndo any work to show that his program really has the type he wrote. 2. The users of a metaprogram should \nneed to write neither proofs nor types more complex than those found in main\u00adstream programming languages. \n In the next section, we introduce the key features of Ur by example. In Section 3, we formalize a core \ncalculus based on these features. The following section discusses effective type inference for the full \nlanguage. After that, we describe our implementation and provide evidence for its practicality, in the \nform of case studies building statically-typed versions of common metaprogramming functionality. We conclude \nby discussing related and future work. The open source distribution of the Ur/Web compiler, along with \nthe source code for our case studies, is available at http://www.impredicative.com/ur/ 2. Ur By Example \nUr is an extension of System F. [22], the higher-order polymorphic lambda calculus, presented with ML-style \nsyntax. The foundation of the key extensions to F. is support for type-level names and records. As a \nsimple introduction to these features and their use\u00adfulness, we will write a generic record .eld projection \nfunction. For example, the function call proj [#A] {A=1, B=2.3}will evaluate to 1, while the call proj \n[#D] {C = True, D = \"xyz\", E=8} will evaluate to \"xyz\". This proj function will be usable on any record, \nwith arbitrary .elds of arbitrary types. Further, proj will have a static type that expresses its requirements \nexactly, and the Ur type-checker will verify that proj will work correctly on any input compatible with \nits type. The de.nition of proj is not very long, but it depends on a few unusual constructs, which we \nwill introduce below. fun proj [nm :: Name] [t :: Type] [r :: {Type}] [[nm]~r](x :$([nm=t] ++r))= x.nm \nType-level formal arguments to functions are declared inside square brackets. Our proj function binds \nthree type-level variables nm, t, and r. Unlike in usual ML code, the type variables appear explicitly \nin the function de.nition. Each type variable is assigned a kind. Kinds are to types as types are to \nvalues; kinds classify different varieties of types. The kind annotations above indicate that nm is a \n.eld name, t is a normal type, and r is a record of types, otherwise known in the literature as a row \ntype. The next piece of the function de.nition is [[nm] ~ r], which declares a disjointness constraint. \nThis particular constraint asserts that the name nm is not used by the type-level record r. The .nal \nformal argument is x, which is a normal, value-level argument. We write x s type using the $ operator, \nwhich converts a type-level record r (of kind {Type}) to a record type (of kind Type) with .eld names \nand types as indicated by r. The code [nm =t] is an example of a type-level record literal, denoting \nthe singleton record associating the name nm with the type t. We use record concatenation ++ to add this \nsingleton to the other .elds r. This concatenation would be invalid if we had not included the disjointness \nconstraint; Ur enforces lack of .eld name duplication in any concatenation. The function body just uses \nthe primitive record .eld projection operator. By encapsulating that operator in this way, we arrive \nat a function with the following Ur type. nm :: Name -> t :: Type -> r :: {Type} ->[[nm]~ r]=>$([nm=t] \n++r)-> t Here code like x:: K-> T indicates a polymorphic function, whose argument is of kind K. The \nfunction s argument is given name x, which may appear free in the function result type T. For instance, \nthe normal polymorphic identity function has type a :: Type-> a-> a. The parsing precedence of the :: \noperator is such that it binds more tightly than any other, in any situation where ambiguity would arise \notherwise. Our proj function is straightforward to apply. For instance, proj [#A] [int] [[B = float]] \n! {A = 1, B = 2.3} has type int and reduces to 1. We write type-level arguments to value\u00adlevel functions \ninside square brackets, and a .rst-class name literal is written by pre.xing the name with a # character. \nThe ! stands for a disjointness proof to be inferred. The Ur type inference engine contains a special \nprover for this purpose. There is no syntax for writing manual proofs; disjointness proofs are always \ninferred. The Ur implementation contains a facility for marking some type-level function arguments as \nimplicit. We will not go into detail here on that facility, but we can use it so that our function can \nbe called as simply as proj [#A] {A =1, B= 2.3}. If the remaining arguments are marked as implicit at \nproj s de.nition site, the Ur compiler knows to expand this call to proj [#A] [] [] ! {A=1,B =2.3}. Each \nunderscore is treated as a distinct uni.cation variable. A specialized uni.cation procedure for type-level \nrecords infers values for these variables. 2.1 A Generic Table Formatter One very common source of repetitive \ncoding in Web applica\u00adtions is formatting application-speci.c records for display as ta\u00adbles. In this \nsubsection, we show how a particular copy-and-paste recipe can be rei.ed as a well-typed Ur function. \nThe example will demonstrate how code generators may work by iteration over all .elds of records of metadata. \nOur end product is a function mkTable that we will be able to call like this, assuming that we have available \nfunctions showInt : int -> string and showFloat : float -> string. val f = mkTable {A = {Label = \"A\", \nShow = showInt}, B = {Label = \"B\", Show = showFloat}} This de.nes a function f of type {A : int, B : \nfloat} -> string. When called with a record of the right type, f will format it as an HTML table, using \nthe labels \"A\" and \"B\" as headings, and using the functions showInt and showFloat to render columns of \nthe table. For example, the call f {A = 2, B = 3.4} would evaluate to the HTML  <tr> <th>A</th> <td>2</td> \n</tr> <tr> <th>B</th> <td>3.4</td> </tr> To write mkTable in a completely generic way, such that it works \nwith arbitrary sets of .elds of arbitrary types, we must develop some type system machinery. This machinery \nis involved, but the .nal product is a function that may be called as simply as above. The .rst ingredient \nis a way of folding over the .elds of a type\u00adlevel record. We de.ne a type family folder, such that folder \nr is the type of permutations of the .elds of record r. To avoid in\u00adtroducing too much detail at once, \nwe will give some de.nitions specialized to records of normal types, though our implementation uses kind \npolymorphism to generalize the de.nitions to other vari\u00adeties of type-level data. This is the de.nition \nof folder in terms of simpler constructs. We present it in full .rst and then consider it a piece at \na time, introducing syntactic and semantic elements as they appear. type folder (r :: {Type}) = tf :: \n({Type} -> Type) -> (nm :: Name -> t :: Type -> r :: {Type} ->[[nm]~r]=> tfr->tf([nm=t]++r)) -> tf [] \n-> tf r This is a type-level function de.nition. In general, code like typef (x::K) =T introduces a function \nf of kind K -> K , when T has kind K in an environment where variable x has kind K. The body of folder \ns de.nition has the form tf:: ({Type}-> Type) -> STEP -> INIT -> RESULT.A folder is simply a .rst-class \npolymorphic function that may be called to iterate over the .elds of r. The type-level argument tf is \nthe counterpart of the accumulator type, in analogy to the standard list fold functions of functional \nprogramming. The component STEP gives the type of a suitable function for computing one iteration of \nthe fold, INIT the type of the initial value for the fold, and RESULT the .nal result type of the fold. \nFollowing this analogy with traditional list fold functions, one notable difference is that INIT and \nRESULT are not the same type. This is because we want to allow the accumulator type to depend on which \npre.x of the record s .elds we have already stepped through. That is, when folding over record r, the \ninitial accumulator should have type tf [] (where [] is the empty record), and the .nal accumulator should \nhave type tf r. We see this progression re.ected in the last line of folder s de.nition, in the concrete \nchoices of INIT and RESULT. The most interesting part of the de.nition comes in the second and third \nlines, where we have the type STEP of the function to fold over r: nm :: Name -> t :: Type -> r :: {Type} \n->[[nm]~r] =>tfr->tf([nm=t]++r) This function takes three type-level arguments: nm, the name of the .eld \nwe are processing; t, the type associated with nm; and r,a record of all of the .elds that we already \nprocessed. A disjointness constraint asserts that r does not use the name nm. Finally, we have a normal \nfunction type, with different versions of the accumulator type tf as the domain and range. In the domain, \nwe have an accumulator type appropriate for the point just after processing every .eld in r. In the range, \nwe extend r to indicate that we have now also processed nm. Building on the generic concept of a folder, \nwe can implement our table generator. We de.ne a type-level function that expresses which metadata we \nwill need for each record .eld. In particular, for each .eld of type t, we need a display label and a \nfunction for rendering t values as strings. type meta (t :: Type) = {Label : string, Show : t -> string} \nWe use meta to express the type of our table generator, which we call mkTable. To render a record with \n.elds r, we require a folder r. We also need a metadata record, whose type is $(map meta r). When r is \n[f1 = t1, ..., fn = tn], the type of this metadata record is {f1 : meta t1, ..., fn : meta tn}, which \nis syntactic sugar for $[f1 = meta t1, ..., fn = meta tn]. Here is the de.nition of mkTable. fun mkTable \n[r :: {Type}] (fl : folder r) (mr : $(map meta r)) (x : $r) = fl [fn r => $(map meta r) -> $r -> string] \n(fn [nm] [t] [r] [[nm] ~ r] acc mr x => \"<tr> <th>\" ^ mr.nm.Label ^ \"</th> <td>\" ^ mr.nm.Show x.nm ^ \n\"</td> </tr>\" ^ acc (mr --nm) (x --nm)) (fn __=>\"\")mrx The function body is a call to the input folder \nfl. In passing the .rst argument of fl, we choose our accumulator type so that each accumulated value \nis a function to a string from a metadata record and a record of .eld values. These record types have \nan explicit dependency on the set of record .elds considered so far. In the step function, the value-level \nvariables are acc, the string rendering of the .elds already processed; mr, a version of the input metadata \nrecord where already-processed .elds have been removed; and x, a similarly abbreviated version of the \norigi\u00adnal argument x. We build a string with the concatenation operator ^. We use the name variable nm \nto project individual entries out of the local versions of the records mr and x. Additionally, we use \nthe operator x --nm, which removes the .eld nm from value-level record x. This .eld removal is necessary \nto produce arguments of the proper types to pass to the accumulator acc. The type of mkTable is easily \nread off from the function de.ni\u00adtion: val mkTable : r :: {Type} -> folder r -> $(map meta r) -> $r -> \nstring Ur s implicit argument facility does more than just infer types; it can also generate folders \nautomatically, using the order of .eld names in code as a hint to the permutation the programmer wants. \nTaking advantage of this possibility, it is easy to bind a version of mkTable specialized to a particular \nrecord type, with the code we used to introduce this example. val f = mkTable {A = {Label = \"A\", Show \n= showInt}, B = {Label = \"B\", Show = showFloat}} The type of f is inferred to be {A : int, B : float} \n-> string. Notice that we did not need to write the type-level record [A = int, B = float] explicitly. \nRather, the compiler infers that type from the type of the record we pass to mkTable. The inference engine \nis able to solve uni.cation problems like this one to .nd the value of r: $(map meta r) = {A : {Label \n: string, Show : int -> string}, B : {Label : string, Show : float -> string}} We call this kind of inference \nreverse-engineering uni.cation, because a record is inferred by looking at the output of some opera\u00adtion \nperformed on it. This is the key feature behind making Ur/Web metaprograms no harder to use than the \nad-hoc code generators that are popular today.  While mkTable is easy to use, its de.nition is somewhat \nin\u00advolved. Our vision for the real-world use of these techniques follows the trajectory of today s mainstream \nmetaprogramming. We .nd relatively expert developers building metaprogramming tools and dealing with \nthe dif.culty of debugging them. Many novice programmers rely on the libraries that the experts build. \nThe novices need simple interfaces. Our experience with Ur leads us to believe that a similar decomposition \nis plausible with statically\u00adtyped metaprogramming. The novice s experience is almost un\u00adchanged, and \nthe expert trades off between dynamic debugging and static checking with extra typing-induced overhead. \nThe expert must learn type system idioms that are outside even today s func\u00adtional programming mainstream, \nbut we hope our examples here provide evidence that this extra training can pay off. When high security \nis critical, as is the case with many Web applications, we believe that the static typing approach reduces \nthe overall cost of development. We simpli.ed our de.nition of mkTable by outputting HTML in the string \ntype. The real Ur/Web implementation uses a special XML tree type whose type indices track which tags \nare allowed. Thus, a real Ur/Web de.nition of mkTable would look more like this: fun mkTable [r :: {Type}] \n(fl : folder r) (mr : $(map meta r)) (x : $r) = fl [fn r => $(map meta r) -> $r -> xml table] (fn [nm] \n[t] [r] [[nm] ~ r] acc mr x => concat (tr (th (cdata mr.nm.Label) :: td (cdata (mr.nm.Show x.nm)) :: \nnil)) (acc (mr --nm) (x --nm))) (fn__ =>empty)mr x Compared to the string-based version, we get a stronger \nguar\u00adantee: no matter which record we pass to mkTable, the result\u00ading program is free of code injection \nvulnerabilities. Strings can only be included in XML trees via the explicit cdata constructor, which \nforces appropriate quoting. In general, Ur/Web uses similar strongly-typed syntax trees for any kind \nof code that Web browsers or database servers might run, providing a global guarantee of free\u00addom from \ncode injection attacks, even in the presence of an expres\u00adsive metaprogramming facility, and without \nthe need to evaluate speci.c metaprogram applications to determine if they are safe.  2.2 Generic Database \nModi.cation It is common for Web applications to work with native represen\u00adtations of data when possible \nbut then convert such representations into alternate formats for database access. In this section, we \nde\u00advelop a toy example inspired by that kind of usage. In particular, we want to write a function that \nadds a row to a database table, where doing so requires .rst applying a conversion operation to each \nelement of a record. The larger lesson from this example has to do with how we may write generic functions \nthat output SQL-like queries. We want these queries to be expressed using rich types that guarantee va\u00adlidity, \nincluding type compatibility with a .xed database schema. Therefore, few type systems outside of the \ndependent types world are equipped to capture the essential well-formedness invariants. Ur supports this \nkind of programming using the same relatively lightweight features that we have been introducing, with \neffective inference to minimize the cost of applying generic functions. Assume we have two abstract type \nfamilies, corresponding to database tables and to expressions that the database engine under\u00adstands. \ntype table :: {Type} -> Type type exp :: {Type} -> Type -> Type A table type is parameterized by a record \nassigning types to the table s columns. An expression type is parameterized .rst, by a record expressing \nwhich free variables may be mentioned and what their types are; and second, by the type of the expression, \naccording to the database s expression typing rules. These type families are abstract in the sense that \nthe program\u00admer may not rely on any details of their implementation. In our con\u00adcrete implementation, \nboth table and exp are aliases for string, but programmers should think of them as abstract syntax tree \ntypes. While there are varieties of metaprogramming that deal with both code generation and code introspection, \nwe only deal with the for\u00admer in Ur/Web and in this paper. No method is provided to, for example, pattern-match \non the syntax of an exp, as that turns out not to be needed in our domain. In this example, we do not \nneed to work with expressions that mention table columns. We only need to rely on a single function for \nconstructing expressions: const, which converts a constant value into an expression. This function s \npolymorphic type expresses the fact that the output expression mentions no free variables; since we abstract \nover an arbitrary environment r and assert that the output expression is valid in r, it must be the case \nthat there is no particular variable that const depends on being able to mention. val const:r:: {Type}->t::Type->t->exprt \nAssume that there is a primitive function for adding a row to a table. The column values for a new row \nare expressed as a record of expressions with no free column variables. val insert : r :: {Type} -> table \nr -> $(map (exp []) r) -> unit Our .nal function toDb will be expressed in terms of a type parameter \nof kind {Type * Type}, the kind of records of pairs of types. The convention is that each pair (native, \ndb) describes a column represented natively in type native but converted to type db for database insertion. \nEach column must have an associated function for translating from native to db, and we use a type function \narrow to express that. The type-level functions fst and snd from the standard library project the .rst \nand second elements of type-level pairs, respectively. type arrow (dom :: Type, ran :: Type) = dom -> \nran val toDb : r :: {Type * Type} -> folder r -> $(map arrow r) -> table (map snd r) -> $(map fst r) \n-> unit We can implement toDb using mostly the same techniques as from our last example. We fold over \nthe record of type pairs, build\u00ading a value-level record that is a suitable parameter to insert. We use \nthe value-level operator ++, which implements record concate\u00adnation. fun toDb [r :: {Type * Type}] (fl \n: folder r) (mr : $(map arrow r)) (tab : table (map snd r)) (x : $(map fst r)) = insert tab (fl [fn r \n=> $(map arrow r) -> $(map fst r) -> $(map (fn p => exp [] (snd p)) r)] (fn [nm] [p] [r] [[nm] ~ r] \nacc mr x => {nm = const (mr.nm x.nm)} ++ acc (mr --nm) (x --nm)) (fn_ _=> {}) mrx)  There is a subtlety \nin type-checking the de.nition of toDb. The result type of the fold over r is not in the right form to \nbe a valid argument to insert. The Ur type inference engine applies this type equality implicitly: $(map \n(fn p => exp [] (snd p)) r) = $(map (exp []) (map snd r)) This is a corollary of a more general fusion \nlaw: mapf(mapgr) =map(fnx=>f(gx))r In all related systems that we are aware of, the programmer would \nneed to apply an explicit coercion to make use of this law. The coercion would most likely appeal to \nan explicit inductive proof of the fusion law. For a general-purpose language intended to be used in \ncorrectness veri.cation, it is not clear how to do any better. However, since Ur is only intended to \nhandle reasoning about records and names, we can streamline the programming process. The fusion law and \na handful of other algebraic identities are built into our inference engine, and they are applied automatically \nduring uni.cation whenever possible. The formal presentation of Ur in Section 3 gives the complete list \nof laws that we have added. Our present implementation only includes .ve laws that would be proved by \ninduction in traditional dependently-typed program\u00adming. These laws have been suf.cient to avoid any \nproofs about type equality in all of the Ur/Web case studies we have undertaken. Our toDb function has \na type even more involved than that of last subsection s mkTable function. It is unlikely that many non-expert \nprogrammers are prepared to deal with types of this complexity. Luckily, implicit arguments and reverse-engineering \nuni.cation do not fail us. The following example code is suf.cient to instantiate toDb at a speci.c record \ntype. funaddInts (n:int,m:int)=n+m val inserter = toDb {A = addInts, B = fn x : float => x} Ur infers \nthat the type of inserter is table [A = int, B = float] -> {A : int * int, B : float} -> unit Reverse-engineering \nuni.cation found that the proper value for r is [A = (int * int, int), B = (float, float)].  2.3 Building \nTyped Expressions Many database operations accept predicates over the columns of a table. For instance, \nthe SQL delete command removes all rows of a table that satisfy a particular user-speci.ed predicate. \nTo interface with a database, it can be useful to convert a record of values into a database expression \nthat characterizes those table rows whose columns match the record. A function to do this generically \nwill be our .nal worked example, and the implementation will demonstrate how more complicated richly-typed \nabstract syntax trees may be built generically. We will need a few more of the constructors for the exp \ntype. The following functions reference a database column, compare two expressions for equality, and \nform the conjunction of two boolean expressions, respectively. val column : nm :: Name -> t :: Type -> \nr :: {Type} ->[[nm]~r] =>exp([nm=t]++r)t valeq :r::{Type}->t:: Type ->exprt-> exp rt->exprbool val and \n: r :: {Type} -> exp r bool -> exp r bool -> exp r bool We are able to give our generic function, selector, \na type that is simple in comparison to those from the earlier examples. The implementation of the function \nis interesting because it performs a fold with an accumulator type that involves an explicit record disjointness \nassertion. fun selector [r :: {Type}] (fl : folder r) (x : $r) : exp r bool = fl [fn r => $r -> rest \n:: {Type} -> [rest ~ r] => exp (r ++ rest) bool] (fn [nm] [t] [r] [[nm] ~ r] acc x [rest] [rest ~ r] \n=> and (eq (column [nm]) (const x.nm)) (acc (x --nm) [[nm = t] ++ rest] !)) (fn _ [rest] [rest ~ []] \n=> const True) x [[]] ! At each stage of folding through the record r, our accumulator is a function. \nIts .rst argument is a record containing one .eld for every .eld of r that we have already folded over. \nThe next argument, rest, is a type-level argument, which is meant to be instantiated to those .elds that \nwe have not yet folded over. In the course of the fold, we gradually shift .elds from rest to r, until \nat the end rest may be the empty record. After binding rest, the accumulator type includes an explicit \nassertion that rest and r share no .eld names, which is a prerequisite of being able to concatenate these \nrecords. We include just such a concatenation in the result type of accumulator functions, which is the \ntype of boolean expressions that may mention columns included in either of r or rest. The step function \nused in the fold takes many arguments, but it mostly uses features that we have already seen. The interesting \npart is in the application of the accumulator acc. We need to choose the right rest record to pass to \nit. This turns out to be the current rest value, extended with the current .eld mapping from nm to t. \nWe write ! to denote a proof of the disjointness assertion in acc s type. As always in Ur, there are \nno proof terms; rather, the ! is just a signal that the inference engine should prove the assertion auto\u00admatically. \nThis proof is assembled from the disjointness assertions [nm] ~ r and rest ~ r that are available in \nthe typing context. Last subsection s example demonstrated the Ur inference en\u00adgine s smarts in reasoning \nabout equality of records, through the automatic application of algebraic equivalences. Our new exam\u00adple \nshowcases the other kind of domain-speci.c reasoning in in\u00adference, which is automatic proof of record \ndisjointness facts. The disjointness prover is able to prove a wide range of implications in\u00advolving \nrecord concatenation and mapping, without burdening the programmer with any of the details. 3. Syntax \nand Semantics of Featherweight Ur We hope that the previous section s examples have motivated why Ur \nhas the features that it does. In this section, we re.ne that design down to its core elements, presenting \na formal de.nition of the idealized language Featherweight Ur. 3.1 Syntax Figure 1 presents the syntax \nof Featherweight Ur, which is in.u\u00adenced heavily by System F. [22], the higher-order polymorphic lambda \ncalculus. This syntax closely follows what we have seen in ASCII format in the examples; we hope that \nthe correspondence is plain. One change that we make is referring to the general class of compile-time \nvalues as constructors rather than types. Types are the subset of constructors that have kind Type. We \ntry to use metavariables t for types and c for constructors that may not be types. Guarded types, which \nwe have also referred to as disjoint\u00ad  Kinds k ::= Type | Name | k . k | {k} Constructors c, t ::= t1 \n. t2 | a | .a :: k. t | c c | .a :: k. c | #n | $c | []k | [c = c] | c + c | mapk,k | [c ~ c] . t Expressions \ne ::= x | e e | .x : t. e | e [c] | .a :: k. e | {} | {c = e} | e.c | e - c | e + e | [c ~ c] . e | e \n! Figure 1. Syntax of Featherweight Ur ness assertions, are written [c1 ~ c2] . t , with analogous notation \nfor guarded expression abstraction. In a general-purpose dependently-typed language like Agda, we would \nbuild a type of records and its associated operations from .rst principles. In contrast, Ur omits the \ntraditional facilities for inductive and recursive de.nitions, instead building the key kinds and type-level \noperators into the language. Type-level concatena\u00adtion and mapping are the sole type-level computation \nfacilities that would be implemented as recursive de.nitions in Agda. This ap\u00adproach is entirely compatible \nwith viewing Ur as a convenient sur\u00adface language for Coq or Agda, such that it is possible to fall back \non the more expressive language when Ur s feature set is insuf.\u00adcient. However, it seems desirable to \nstick to this restricted frag\u00adment because we have been able to implement an effective type inference \nprocedure for it, as described in the next section. Our experience writing programs in Ur/Web suggests \nthat the feature set we have chosen is more than suf.cient for our appli\u00adcation domain. It is also true \nthat a few apparent omissions have solid theoretical justi.cation. For instance, it may seem more natu\u00adral \nto choose fold over map as a primitive traversal. However, in combination with considering records as \nunordered sets of keys and values, this would lead to an unsound semantics, unless we increased the language \ncomplexity to the point where it could be proved that any function used with fold is insensitive to the \nor\u00adder in which record .elds are visited. The choice of record .eld disjointness as the sole variety \nof constraint may also seem arbi\u00adtrary. However, from this base, it is easy to de.ne other constraints, \nincluding record equality and inclusion. In fact, the Ur/Web stan\u00addard library relies critically on such \nconstraints to encode the typing rules of SQL.  3.2 Static Semantics Figure 2 gives selected rules of \nthe kinding judgment, which assigns kinds to constructors. We omit those rules already used by F.. To \nsimplify the presentation, we assume side conditions for each rule asserting the well-typedness of all \nexpressions and well-kindedness of all constructors that appear. We de.ne all of our judgments in terms \nof a single variety of context G. Entries in such contexts are kinding assertions a :: k, typing assertions \nx : t , or row disjointness assertions c1 ~ c2. The kinding judgment only uses the .rst and last of these \nassertion sorts. We hope that the rules are intuitive, following our examples. The two interesting cases \nare for row concatenation and guarded constructors. To concatenate rows c1 and c2, it must be proved \nthat c1 and c2 share no .eld names. This is captured by the judgment G f c1 ~ c2. In the rule for guarded \ntypes [c1 ~ c2] . t, within the body t , the context is extended with the fact that c1 is disjoint from \nc2. We omit here the details of the disjointness judgment; it simply captures decomposition of each side \nof the constraint into irreducible pieces and checking of disjointness between all pairs of pieces. This \ndecomposition is phrased via a de.nitional equality judg\u00adment c = c', which encodes the computational \nsemantics of con\u00adstructors. In checking disjointness, we may replace any constructor with another that \nis computationally equivalent. Figure 3 presents the de.nitional equality. On the .rst line of the .gure, \nwe include the standard rules from F.. The next set of rules de.nes the semantics of the basic row op\u00aderations. \nWe have that the empty record is an identity element for concatenation, and that concatenation is commutative \nand associa\u00adtive. After this, we have the semantics of map. The rules for map mostly mirror a list map \nde.nition in Haskell. Perhaps the most surprising set of rules comes in the last two lines of the .gure. \nWithin the de.nitional equality, we have row equivalents of standard theorems about higher-order list \nfunctions. In order, the last three rules of Figure 3 express the fact that map applied to an identity \nfunction is itself an identity function, the distributivity of map over concatenation, and a fusion law \nfor one map over another. One of our (perhaps surprising) empirical results is that these are the only \nlaws we have needed to implement a variety of practical metaprograms. Finally, we come to the typing \nrules, with selected rules shown in Figure 4. Most of the novelties of Featherweight Ur have already \ncome up in relation to the previous judgments. One rule makes the typing judgment a congruence over the \nde.nitional equality; when e has type t, it also automatically has type t', for any t ' = t. The typing \nrule for guarded expressions [c1 ~ c2] . e shows that they have types like [c1 ~ c2] . t ; we apply the \nrule for the ! operator to reduce this type to simply t , when the constraint is provable. Like other \nlanguages with symmetric concatenation of records, Ur lacks subtyping, since this could lead to ambiguous \nsituations where it is not clear which of two records being concatenated to drop a .eld from. However, \nmany of subtyping s common us\u00adage patterns can be encoded with polymorphism over type-level records. \n 3.3 Dynamic Semantics Rather than de.ning an operational semantics for Featherweight Ur, we give an \nelaborative semantics, translating Featherweight Ur programs into terms of the Calculus of Inductive \nConstructions, the logic behind the Coq proof assistant [3]. We do not have space to go into the details \nhere. The exact translation is available in the src/coq directory of the Ur/Web distribution, as part \nof a Coq formalization of Featherweight Ur syntax and semantics. The basic idea is that we translate \nkinds to CIC types, construc\u00adtors to terms of those types, and typing derivations to terms of those further \ntypes. A derivation c = c' is compiled to a proof that c and c' have equal denotations. Our implementation \nof records is a standard exercise in programming with heterogeneous list types, a common tool in dependently-typed \nlanguages. It is worth stating explicitly that, since we give our semantics elaboratively, there is no \nneed to prove a separate type soundness theorem. The translation is implemented in Coq and outputs native \nCoq terms directly, so we get type preservation by construction. Since CIC has been proved type-sound, \nFeatherweight Ur is type\u00adsound, too, almost by de.nition. This formalization also inherits other properties \nof CIC, like strong normalization [20], that do not hold of the full Ur language. This elaboration is \nmeant only to specify the semantics of Ur, rather than an implementation technique. The actual Ur/Web \ncom\u00adpiler works more traditionally, as sketched in Section 5. 4. Effective Type Inference Ur, or even \nplain F., includes type system features that are rarely found outside of programming languages based \non dependent type theory. Type inference for CIC and other such systems is unde\u00ad  G f c :: {Type} G \nf c1 :: Name G f c2 :: k G f c1 :: {k} G f c2 :: {k} G f c1 ~ c2 G f #n :: Name G f $c :: Type G f []k \n:: {k} G f [c1 = c2] :: {k} G f c1 + c2 :: {k} G f c1 :: {k1} G f c2 :: {k2} G,c1 ~ c2 f t :: Type G \nf mapk1,k2 :: (k1 . k2) .{k1}.{k2} G f [c1 ~ c2] . t :: Type Figure 2. Selected kinding rules of Featherweight \nUr c2 = c1 c1 = c2 c2 = c3 ' c = c (.a :: k. c1) c2 = c1[a . c2] c = cc1 = c2 c1 = c3 C[c] = C[c ' ] \n[]k + c = cc1 + c2 = c2 + c1 c1 + (c2 + c3) = (c1 + c2)+ c3 mapk1,k2 f []k1 = []k2 mapk1,k2 f ([c1 = \nc2]+ c3) = [c1 = fc2]+ mapk1,k2 fc3 mapk,k (.a : k. a) c = c mapk1,k2 f (c1 + c2) = mapk1,k2 fc1 + mapk1,k2 \nfc2 mapk2,k3 f (mapk1,k2 f ' c) = mapk1,k3 (.a :: k1.f (f ' a)) c Figure 3. De.nitional equality rules \nof Featherweight Ur t = t ' G f e : t ' G f c :: Name G f e : t G f e : $([c = t ]+ c ' )G f e : $([c \n= t ]+ c ' ) G f e : t G f {} : $[]Type G f{c = e} : $[c = t ]G f e.c : t G f e - c :$c ' G f e1 :$c1 \nG f e2 :$c2 G f c1 ~ c2 G f c1 :: {k1} G f c2 :: {k2} G,c1 ~ c2 f e : t G f e :[c1 ~ c2] . t G f c1 ~ \nc2 G f e1 + e2 : $(c1 + c2)G f [c1 ~ c2] . e :[c1 ~ c2] . t G f e !: t Figure 4. Selected typing rules \nof Featherweight Ur cidable, seen via fairly straightforward arguments: general mathe\u00admatical proof search \ncan be reduced to type inference in such rich type systems, with uni.cation variables standing for mathemati\u00adcal \nproofs encoded syntactically. Even type inference for System F has been proved undecidable [32], and \nimpredicative (or .rst\u00adclass ) polymorphism is crucial to Ur s usefulness, as the exam\u00adple of folder \nfunctions demonstrates. To this already undecidable base, Ur adds the type-level computation features \nof F. and type\u00adlevel map. There may very well be worthwhile theoretical com\u00adpleteness results for Ur \nthat fall short of providing full inference, but we leave such results for future work. In this section, \nwe present the type inference heuristics that we have had success with. Like in some proposed solutions \nto the type inference problem for System F, we require that all polymorphism be annotated ex\u00adplicitly \nat the de.nitions of functions. In practice, most type argu\u00adments may be inferred, making uses of polymorphic \nfunctions look similar to uses in ML, while de.nitions may be considerably more verbose. We follow the \nusual approach of type-checking expressions by introducing uni.cation variables, whose values are determined \nlater during uni.cation of constructors. Since our type system is more complex than those handled by \nclassic Hindley-Milner inference, we must do more than just solve type equality constraints as they appear. \nWe follow more recent formulations based on systems of constraints. Type-checking generates a set of \nconstructor equal\u00adity and record disjointness constraints. As an optimization, we try to solve constraints \nwhen they are .rst generated, but the general case involves building a global set of constraints and \nthen iterating through .nding an immediately-solvable constraint, until no con\u00adstraints remain. Most \nof Ur constructor uni.cation could be implemented by normalizing constructors and then comparing normal \nforms for simple syntactic equality. We can refactor the de.nitional equal\u00adity rules of Figure 3 so that, \nwhen applied only left-to-right, they form a rewrite system that we conjecture is terminating and con\u00ad.uent. \nThis requires removing at least the concatenation commuta\u00adtivity rule, so we handle row uni.cation in \na special way that we will describe shortly. For the other constructor language elements, rather than \nfollowing the naive normalize-and-compare uni.cation strategy, we apply a standard optimization. We use \na loop of re\u00adducing constructors to head normal form, where we reduce only as much as is needed to expose \ntop-level structure. Head normal forms are compared syntactically, where uni.cation of subterms appeals \nto the original algorithm, which will head-normalize and compare those subterms, and so on. There is \nno doubt further opportunity for optimizing type inference performance by applying techniques from the \ntype-preserving compilation literature [28]. Higher-order uni.cation is a well-studied subject with some \nstandard heuristic approaches [21]. There, the key problem is in\u00adferring type-level functions. In contrast, \nthe Ur/Web implementa\u00adtion has more in common with the GHC Haskell compiler, in that only .rst-order \nuni.cation techniques are used to make a best ef\u00adfort at guessing functions. This is because we have \nnot found the classical higher-order uni.cation techniques to be critical in our setting of metaprogramming. \nInstead, our inference engine focuses on understanding type-level records and computations over them. \nSince Ur does support general type-level ., the result is easy-to\u00adobserve inference incompleteness that \nstill tends not to cause trou\u00adble in practice. For instance, our inference engine is unable to type the \nfollowing code.  funid [f::Type->Type][t](x :f t):ft =x val x = id 0 4.1 Proving Disjointness All proofs \nof row disjointness happen automatically. Whenever a new known constraint is introduced via an expression \nlike fn [r1 ~ r2] => e, our type-checker calculates all atomic disjointness facts implied by r1~ r2. \nEach of r1 and r2 is decomposed using a function D de.ned as follows, where hnf is the constructor head \nnormalization function. D(c)= D ' (hnf(c)) D ' ([c1 = c2]) = {[c1]} D ' (c1 + c2)= D(c1) . D(c2) D ' \n(x)= {x} D ' (map fc)= D(c) D ' () = \u00d8 The calls to D yield two .nite sets, and we calculate the sym\u00admetric \nclosure of their Cartesian product to add to the typing con\u00adtext. When we encounter a disjointness goal \nr1~ r2, we decom\u00adpose these rows with the same function and again take the Cartesian product of the results. \nThis time, we check that every resulting pair is either in our database of facts or consists of two singleton \nrows with constant, distinct .eld names. In checking constraints, the last, wildcard case of the de.nition \nof D ' must be changed to instead signal that the constraint is not provable yet. In such cases, we hope \nthat when we revisit this constraint after solving other constraints .rst, some uni.cation variables \nwill have been determined, so that the proof can .nish successfully. 4.2 Reverse-Engineering Rows Another \nkey element of our type inference process is the reverse\u00adengineering uni.cation that we have mentioned \nseveral times. Sometimes we want to infer implicit arguments to polymorphic functions whose types contain \nmaps. This often leads to inference queries of the form mapk1,k2 fa = c, for some uni.cation vari\u00adable \na and (usually ground) constructor c. If c is empty, then we can set a to be empty, too. When c =[c1 \n= c2]+ c3, to choose a value for a, we can generate fresh uni.cation variable a ' and then unify fa ' \nwith c2. Afterward, we can replace a by [c1 = a ' ]+ a '' for some new a ''. We can repeat this process \nto reverse-engineer the value of a in a wide variety of cases. 4.3 Unifying Rows During uni.cation, \nwhen the standard algorithm .nds a row oper\u00adator like concatenation at the top level of one of the constructors \nthat it is comparing, it switches to using a special row uni.cation algorithm. First, each constructor \nis summarized using a summary function S from constructors to triples of sets. S works like the D function \nin decomposing a record, and the triples it outputs break a record s components into singleton .eld mappings, \nuni.cation variables, and other miscellaneous components. To unify two records, we .rst consider each \ncomponent of their summarizing triples separately, looking for uni.able pieces be\u00adtween the ith component \nof the .rst summary and the ith compo\u00adnent of the second summary. Any such uni.cations trigger cross\u00ading \noff of components on both sides. If both sides are now empty, we are done. If either side is reduced \nto a single uni.cation variable, then we .nish by replacing it everywhere with the other side s con\u00adtents. \nIf each side is reduced to a single uni.cation variable plus zero or more singleton .elds, and if the \nsingleton .elds on one side do not overlap with those on the other, then each of the two uni.\u00adcation \nvariables may be rewritten in terms of a single new variable. When none of these rules apply, we make \na last attempt to apply reverse-engineering uni.cation. If iterating these rules leaves any contents \non either side of the equation, we remember the new uni\u00ad.cation variable values that we learned, but \nwe leave this equality in the set of unsolved constraints.  4.4 Generating Folders Instances of the \nfolder type family from Section 2 may be omit\u00adted, in which case the compiler waits to generate concrete \ninstances until after type inference is complete and the type of every subterm of the program is known. \nSince the type inference process never commutes the order of .elds in a record type unnecessarily, the \nor\u00adder of record .elds in the elaborated program is easy to predict, based on the order in which .elds \nwere written in the source code. Because of this, it works well for the compiler to generate any un\u00adknown \nfolder using the permutation implied by the order in which .elds appear in the folder s inferred type. \n5. The Ur/Web Compiler We have used the generic Ur type inference engine to implement Ur/Web, a domain-speci.c \nlanguage for Web application develop\u00adment. To the programmer, Ur/Web appears as a special standard library \nfor Ur, plus helpful parsing extensions supporting features like inline XML and SQL code. Under the hood, \nthe Ur/Web com\u00adpiler is specialized to deal with this library and with the require\u00adments of real Web \nbrowsers and database servers. Even setting metaprogramming aside, we found many uses for Ur s facility \nfor building type-level records with mapping. To sup\u00adport richly-typed versions of the standard structures \nthat Web ap\u00adplications manipulate, we did not need to write any custom type inference code. Instead, \nwe encoded those structures in the signa\u00adture of the main module of the standard library. In particular, \nUr records show up throughout the encodings of the syntax and typing rules of SQL queries and commands \nand HTML documents. Our experience applying Ur/Web suggests that any application using these features, \nwritten without polymorphism, can be type\u00adchecked with no more type annotation than is needed when repre\u00adsenting \nthese structures as strings. Moreover, the inference engine is quite effective at dealing with polymorphic \nand metaprogram\u00adming uses of these library types. As we use rich tree types to classify any structure \nthat browsers will interpret, Ur/Web applications are automatically immune to cross-site scripting, code \ninjection, and several other of the most common security vulnerabilities. One might worry that we need \nto trade performance for this bene.t, due to the use of an advanced type system. However, we compile \nUr/Web programs with a whole\u00adprogram optimizing compiler. In the tradition of MLton3, we elim\u00adinate all \npolymorphism at compile time, which, given the complex\u00adity of our type system, requires simple partial \nevaluation by reduc\u00adtion. This produces an intermediate form that is much like ML. 6. Case Studies In \nthis section, we discuss some case studies centered on Ur/Web versions of common metaprogramming components \nfrom the world of Web application frameworks. We highlight interesting uses of type-level map, the most \ndistinguishing feature of Ur com\u00adpared to other systems that require little annotation. The message 3 \nhttp://mlton.org/  of this section is that, despite the relatively minimalistic set of type\u00adlevel features \nwe chose for Ur, each of these case studies meets our two main design criteria of no proofs for library \nwriters and no fancy types for rank-and-.le programmers. Object-Relational Mapping Many applications \nmaintain a dual view of SQL database tables. There is a view where table rows are represented with the \nprogramming language s native records or ob\u00adjects; and there is the database view, which can only be \nmanipulated via queries and commands sent to the database server. The popular Web frameworks provide \ntheir own, untyped implementations of such object-relational mapping, or ORM. We implemented ORM as a \nrichly-typed generic component in Ur/Web. Here are two ex\u00adample invocations of our component. These examples \nuse the Ur module system, which is inspired by the ML module systems [16], with few surprises encountered \nin adapting that idea to Ur s base language. structure T = Table(struct val cols = {A = local [int], \nB = local [string]} end) structure S = Table(struct val cols = {C = T.id, D = local [float]} end) We \nbuild ORM modules customized to two speci.c tables. The identi.er Table names a functor, i.e., a function \nfrom modules to modules. The Table functor is a function from a module describing a table to a module \nimplementing the classic ORM operations: listing all rows and adding, deleting, modifying, or looking \nup a row. All operations work directly on native Ur records. The argument used to build module T says \nthat we want a table with a column A of type int and a column B of type string. The argument used for \nS dictates that there be a column D of type .oat and a column C that is a foreign key reference to rows \nof T. Module S thus contains a function for retrieving the T record associated with an S record. Input \nmodules to Table must contain more type-level informa\u00adtion than is included explicitly here. Ur includes \nan extension to the ML module system paradigm, where type-level module com\u00adponents may be omitted to \nask that they be inferred. In this way, the client of a metaprogram can be shielded from the complexity \nof its type. To support foreign keys, we require that a table be described in a terms of a record of \nkind {Type * Type}, where each .eld is associated both with its own type and with the type of the table \nit references, if it is a foreign key. The foreign key link-following function is typed in terms of a \nmap over this record. We also use map to support an abstract type of columns speci.c to a table. These \ncolumns may be combined to form predicates in a table-speci.c ab\u00adstract type of .lters, and .lters may \nbe passed to lookup and search functions. Versioned Database Access In some applications, it is important \nnot only to be able to query the current state of a database, but also to roll back to a past view of \nthe database at a particular time. We implemented a versioned database access component that provides \nthis functionality generically, for any set of table columns. Normal database access is just as easy \nas with the ORM component, but a table-speci.c abstract type of versions may be used to look up old values. \nOutput modules of our versioning functor provide functions for listing all versions that exist and for \nlooking up an old row by version and key. The versioning functor takes two type-level records as input. \nThe .rst describes which rows should collectively be considered the primary key of the table, such that \nthey are enforced to be unique across rows. The second type-level record describes the remaining columns. \nOur concrete SQL implementation of the versioning ab\u00adstraction involves a table whose columns consist \nof a version ID, the key columns, and a nullable version of each non-key column. The idea is that each \nupdate to a virtual row adds a new concrete row where every non-key column that has not changed is repre\u00adsented \nas NULL, while those columns that have changed have their new values recorded. We represent the type \nof the concrete database table with a type-level map over the non-key record, replacing each type t with \noption t. This example also tests the versatility of our domain-speci.c proving by including types based \non the con\u00adcatenation of the key and non-key records, which are asserted to be disjoint in an explicit \nconstraint. Database Admin Interface The most popular Ruby on Rails metaprogram builds a standard interface \nfor administering an arbi\u00adtrary database table, including viewing and modifying its contents in a Web \nbrowser via HTML tables and forms. We implemented comparable functionality as an Ur/Web functor. The \nfunctor may be used by providing just an SQL table reference, a string to display as the page title, \nand a record of metadata for each table column. Metadata values for common types can be built with expressions \nlike int \"A\" and float \"B\" (passing a display name for the col\u00adumn), and support is provided for building \ncustom metadata for domain-speci.c column handling. Each column is associated with a pair of types, giving \nits SQL and client-side representations. Maps over this record of pairs are used to calculate types for \nthe database table and for the widget environments that occur in HTML forms. Web 2.0 Admin Interface \nWe also implemented a batched coun\u00adterpart to the last component. This modernized version takes ad\u00advantage \nof the possibility to run some code in Web browsers as JavaScript. In particular, when the user submits \na form asking to add a new row, the remote Web server is not contacted. Instead, local code adds the \nnew row data to an HTML table. The user can click a button to submit his batched changes en masse. This \nfunc\u00adtor may be used in the same way as its Web 1.0 ancestor, despite the fact that we are checking a \nmore complicated piece of code. Every implementation that our functor outputs includes new URL\u00adaddressed \nremote procedure calls (RPCs) for client-server commu\u00adnication, and types guarantee that any functor \noutput uses RPCs correctly. This functor is similar to the previous example in involving a record assigning \neach table column an SQL version and a client\u00adside version. To come up with the proper type for the RPC \nthat adds a list of rows, we need to map over this record, forming a table-speci.c type of records that \nmust be passed to the RPC in serialized form. In-Browser Spreadsheet Another Ur/Web component imple\u00adments \ncommon spreadsheet functionality, such that most code is run in browsers, but the remote Web server is \ncontacted to query and modify a database table storing the persistent version of a spreadsheet. The functor \nsupports foreign keys represented as automatically-populated dropdown listboxes, and each spreadsheet \napplication provides input validation, summary rows displaying aggregate information, paging, sorting, \nper-column .ltering, and an access point that other program modules can use to check which rows of the \nspreadsheet the user has selected. Here is a simple example of constructing a spreadsheet implementation. \ntablet :{Id:int, A:int, B:bool} sequence s  Component Int. Imp. Disj. Id. Dist. Fuse ORM 40 77 580 - \n13 5 Versioned 20 122 616 6 4 2 Table Admin 22 158 1412 - 1 2 Web 2.0 Admin 21 134 1105 - 1 1 Spreadsh. \n(base) 46 291 1667 6 - 1 Spreadsh. (SQL) 110 391 1257 3 11 - Figure 5. Code sizes (in lines of code) \nof case study components interfaces and implementations, along with invocation counts for critical pieces \nof type inference open Make(struct valtab= t conkey= [Id =_] val raw = {Id = init (nextval s), A = init \n(return 0), B = init (return False)} val cols = {Id = readOnly [#Id] \"Id\" int, A = editable [#A] \"A\" \nint, B = editable [#B] \"B\" bool, DA = computed \"2A\" (fn r => 2 * r.A)} val aggregates = {Sum = fold (fn \nr n => r.A + n) 0, AllTrue = fold (fn r b => r.B &#38;&#38; b) True} end) The key component identi.es \nwhich table columns make up the table key. The raw record explains how to generate the initial value \nof each column of a fresh row. The cols record contains metadata values for the four columns to be displayed \nin our spreadsheet: a read-only rendering of the key Id, widgets for editing the values of the A and \nB columns, and a computed column that always shows twice the current value of A. The .nal record, aggregates, \nre\u00adquests to include a summary row at the bottom of the spreadsheet, where we are told the sum of all \nA values and the iterated boolean and of all B values. The main type-level record behind this component \nhas kind {Type * Type * Type}. Each displayed column is associated with a type of global state, a type \nreturned by its main input wid\u00adget, and a type returned by its .ltering widget. Many applications of \nmap are used throughout the functor to express the typing rela\u00adtionship among these different elements. \nWe reduce the complexity of our code by .rst building a functor for constructing spreadsheets backed \nby arbitrary data sources, and we then derive a functor for spreadsheets backed by SQL databases. 6.1 \nEvaluation As far as we know, ours is the .rst investigation into statically\u00adtyped instances of this \nvariety of practical metaprogramming. It was not obvious at .rst that it would be possible to write such \nprograms without violating one or both of our two central design principles: 1. Metaprograms should contain \nno proofs or other type-cast ex\u00adpressions with no computational effects.  2. Client code should contain \nno proofs or types more complicated than types found in mainstream programming languages.  Nonetheless, \nall of our case studies .t this description, as do all of the other Ur/Web metaprograms we have written. \nFigure 5 summarizes the amount of code needed to implement our components, measured in lines with content \nbesides whitespace and comments. We also gathered some statistics that give a sense of how much annotation \neffort Ur/Web saves the programmer over similar coding in related statically-typed systems, which all \nrequire proof terms to apply algebraic identities that Ur inference applies automatically. For each component \nin the Figure 5, we note how many times the main type inference procedure invoked the disjoint\u00adness prover, \nalong with how many times inference applied the map\u00adover-identity-function, map distributivity, and map \nfusion laws, re\u00adspectively. These numbers consider only the generic components; client code usually triggers \nadditional uses of the laws. 7. Related Work The design of Ur was in.uenced heavily by our experience \nwith programming in Coq [3]. The possibilities for generic program\u00adming in dependently-typed languages \nhave been recognized and implemented for several years now, at least [1]. This body of work has tended \nto focus on more involved examples like generation of parsers and pretty-printers for arbitrary algebraic \ndatatypes. We mean to argue that Ur, by focusing on a speci.c domain, provides a much more user-friendly \nexperience to programmers, both attract\u00ading a broader range of developers and enhancing productivity \nof those who are attracted. Dependent ML [33] follows a similar path, with convenient automated reasoning \nthat is mostly restricted to formulas of linear arithmetic. There have been many investigations into \nthe inclusion of ex\u00adtensible records in statically-typed languages. Wand s initial work on row types \n[31] has inspired many follow-ups. The work of R\u00b4 emy [24] is also well-known, as it has directly in.uenced \nthe ob\u00adject system and polymorphic variant facilities of Objective Caml. Ohori [18] developed a compiler \nfor a language with extensible records, demonstrating an index-passing encoding that facilitates separate \ncompilation. Harper and Pierce [10] de.ned a calculus supporting general record concatenation, via row-quanti.ed \ntypes that include general disjointness constraints like those in Ur, but without discussion of type \ninference. Gaster and Jones [9] de.ne a system for extensible records and variants, achieving a complete \ntype inference algorithm by restricting constraints to the form la\u00adbel l is not present in row r. Pottier \n[23] demonstrated a gen\u00aderal type inference system equipped to deal with general record concatenation \nand .rst-class names. Blume et al. implemented the MLPolyR language [4], which, using type-level records, \nexploits the duality of records and variants to support an extensible case construct. The idea of extensible \nrecords is a natural one, and it has appeared in many other cases that we do not have space to cite. \nAs far as we are aware, every construction with records that can be coded in these past languages can \nalso be coded in Ur, with no ad\u00additional type annotation needed at uses of polymorphic functions, though \npolymorphism must be annotated explicitly in function def\u00adinitions. The crucial facility distinguishing \nUr from this past work is type-level computation, in the form of F. features and type-level map. Embedding \nSQL syntax in general-purpose languages has been studied before, with various levels of static assurance. \nOhori and Buneman [19] added explicit support for typing associated with database operations to an ML-like \nlanguage while maintaining principal typing. Leijen and Meijer [15] embedded a subset of SQL in an extension \nof Haskell, with static validation of a subset of the properties enforced by Ur/Web. Silva and Visser \n[30] later com\u00adpleted a similar project with broader static validation, using more of the harnessing \nof type classes with functional dependencies that has become very popular in the Haskell community. The \nHList li\u00adbrary [13] for GHC Haskell is a prominent example of this trend; it provides extensible records, \nusing a notion of type-level compu\u00adtation driven by Haskell s type class resolution mechanisms. We (somewhat \nsubjectively) feel that this style leads to code that is needlessly more complicated and verbose than \nwhat is possible in Ur. It is also unclear how to handle in Haskell applications of the kinds of algebraic \nlaws that are at the heart of Ur s type inference; at best, it seems that explicit proof terms must be \nwritten.  There is a long history of code generation in the worlds of object-oriented and procedural \nprogramming, and the standard techniques in this area suffer from lack of static validation of metaprograms. \nRecent language extensions like Compile-Time Re.ection (CTR) [8] for C# and MorphJ [11] for Java address \nthis shortcoming for programs that inspect and generate classes in stylized ways. Similar issues of name \ndisjointness checking arise in these tools. One signi.cant advantage of Ur s approach is that metaprograms \nare not only checked statically, but they are also as\u00adsigned self-contained types, which makes it possible \nfor functions to abstract over metaprograms in a statically-safe way. Another difference is that Ur is \nbuilt from simple, orthogonal constructs of type theory, which can make it easier to see the essence \nof metapro\u00adgramming with names. 8. Conclusion While novice programmers can use Ur metaprograms without \nwrit\u00ading fancy types, erroneous metaprogram applications can trigger hard-to-understand error messages \nthat do use advanced concepts explicitly. Improved heuristics for phrasing these messages would be a \nuseful subject for future work. We are also still investigat\u00ading the limitations that arise from use \nof a compiler that must re\u00adsolve all polymorphism statically. This policy limits opportunities for constructing \nsyntax of dynamically-varying type; for instance, to access different database tables based on values \nread from a con\u00ad.guration .le. Perhaps genuine dependent types will even prove crucial in supporting \nsuch use cases. Ur/Web is already a practical system for implementing mod\u00adern Web applications with metaprogramming. \nPrograms that write programs are notoriously hard to debug, and Ur helps reduce devel\u00adopment cost by \nusing static types to guarantee validity of metapro\u00adgrams. We built on the rich body of work on dependent \ntype theory and added just a few domain-speci.c conveniences, in the form of a specialized type inference \nengine. This last mile effort makes a crucial difference in building a tool to be competitive with the \ntools used in the Web application domain today, where few pro\u00adgrammers are willing to write formal proofs \njust to get programs to type-check. Acknowledgments We thank Manu Sridharan, Ryan Wisnesky, and the anonymous \nreferees for helpful feedback on drafts of this paper. References [1] Thorsten Altenkirch and Conor McBride. \nGeneric programming within dependently typed programming. In Proc. IFIP TC2/WG2.1 Working Conference \non Generic Programming, 2003. [2] Lennart Augustsson. Cayenne -a language with dependent types. In Proc. \nICFP, 1998. [3] Yves Bertot and Pierre Cast\u00b4eran. Interactive Theorem Proving and Program Development. \nCoq Art: The Calculus of Inductive Construc\u00adtions. Texts in Theoretical Computer Science. Springer Verlag, \n2004. [4] Matthias Blume, Umut A. Acar, and Wonseok Chae. Extensible programming with .rst-class cases. \nIn Proc. ICFP, 2006. [5] Chiyan Chen and Hongwei Xi. Combining programming with theo\u00adrem proving. In \nProc. ICFP, 2005. [6] Jeremy Condit, Matthew Harren, Zachary Anderson, David Gay, and George Necula. \nDependent types for low-level programming. In Proc. ESOP, 2007. [7] Web Application Security Consortium. \n2007 Web applica\u00adtion security statistics. http://projects.webappsec.org/ Web-Application-Security-Statistics. \n[8] Manuel F\u00a8 Re.ective ahndrich, Michael Carbin, and James R. Larus. program generation with patterns. \nIn Proc. GPCE, 2006. [9] Benedict R. Gaster and Mark P. Jones. A polymorphic type system for extensible \nrecords and variants. Technical Report NOTTCS-TR-96-3, University of Nottingham, 1996. [10] Robert Harper \nand Benjamin Pierce. A record calculus based on symmetric concatenation. In Proc. POPL, 1991. [11] Shan \nShan Huang and Yannis Smaragdakis. Expressive and safe static re.ection with MorphJ. In Proc. PLDI, 2008. \n[12] Mark P. Jones. Type classes with functional dependencies. In Proc. ESOP, 2000. [13] Oleg Kiselyov, \nRalf L\u00a8ammel, and Keean Schupke. Strongly typed heterogeneous collections. In Proc. Haskell Workshop, \n2004. [14] Kenneth Knowles, Aaron Tomb, Jessica Gronski, Stephen N. Freund, and Cormac Flanagan. Sage: \nUni.ed hybrid checking for .rst-class types, general re.nement types, and Dynamic. In Proc. Scheme Workshop, \n2006. [15] Daan Leijen and Erik Meijer. Domain speci.c embedded compilers. In Proc. DSL, 1999. [16] David \nMacQueen. Modules for Standard ML. In Proc. LFP, 1984. [17] Ulf Norell. Towards a practical programming \nlanguage based on de\u00adpendent type theory. PhD thesis, Chalmers University of Technology, 2007. [18] Atsushi \nOhori. A polymorphic record calculus and its compilation. TOPLAS, 17(6), 1995. [19] Atsushi Ohori and \nPeter Buneman. Type inference in a database programming language. In Proc. LFP, 1988. [20] Christine \nPaulin-Mohring. Inductive de.nitions in the system Coq \u00adrules and properties. In Proc. TLCA, 1993. [21] \nFrank Pfenning. Partial polymorphic type inference and higher-order uni.cation. In Proc. LFP, 1988. [22] \nBenjamin C. Pierce. Higher-order polymorphism. In Types and Programming Languages, chapter 30. MIT Press, \n2002. [23] Franc\u00b8ois Pottier. A 3-part type inference engine. In Proc. ESOP, 2000. [24] Didier R\u00b4emy. \nType inference for records in a natural extension of ML. Theoretical Aspects of Object-Oriented Programming, \n1994. [25] Patrick Rondon, Ming Kawaguchi, and Ranjit Jhala. Liquid types. In Proc. PLDI, 2008. [26] \nTom Schrijvers, Simon Peyton Jones, Manuel Chakravarty, and Martin Sulzmann. Type checking with open \ntype functions. In Proc. ICFP, 2008. [27] Tom Schrijvers, Simon Peyton Jones, Martin Sulzmann, and Dimitrios \nVytiniotis. Complete and decidable type inference for GADTs. In Proc. ICFP, 2009. [28] Zhong Shao, Christopher \nLeague, and Stefan Monnier. Implementing typed intermediate languages. In Proc. ICFP, 1998. [29] Tim \nSheard. Languages of the future. In Proc. OOPSLA, 2004. [30] Alexandra Silva and Joost Visser. Strong \ntypes for relational databases. In Proc. Haskell Workshop, 2006. [31] Mitchell Wand. Type inference for \nrecord concatenation and multiple inheritance. Information and Computation, 93(1), 1991. [32] J. B. Wells. \nTypability and type checking in System F are equivalent and undecidable. Annals of Pure and Applied Logic, \n98:111 156, 1999. [33] Hongwei Xi. Dependent ML: an approach to practical programming with dependent \ntypes. J. Functional Programming, 17(2):215 286, 2007.    \n\t\t\t", "proc_id": "1806596", "abstract": "<p><i>Dependent types</i> provide a strong foundation for specifying and verifying rich properties of programs through type-checking. The earliest implementations combined dependency, which allows types to mention program variables; with type-level computation, which facilitates expressive specifications that compute with recursive functions over types. While many recent applications of dependent types omit the latter facility, we argue in this paper that it deserves more attention, even when implemented without dependency.</p> <p>In particular, the ability to use functional programs as specifications enables <i>statically-typed metaprogramming</i>: programs write programs, and static type-checking guarantees that the generating process never produces invalid code. Since our focus is on generic validity properties rather than full correctness verification, it is possible to engineer type inference systems that are very effective in narrow domains. As a demonstration, we present Ur, a programming language designed to facilitate metaprogramming with first-class records and names. On top of Ur, we implement Ur/Web, a special standard library that enables the development of modern Web applications. Ad-hoc code generation is already in wide use in the popular Web application frameworks, and we show how that generation may be tamed using types, without forcing metaprogram authors to write proofs or forcing metaprogram users to write any fancy types.</p>", "authors": [{"name": "Adam Chlipala", "author_profile_id": "81100341086", "affiliation": "Impredicative LLC, Cambridge, MA, USA", "person_id": "P2184523", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806612", "year": "2010", "article_id": "1806612", "conference": "PLDI", "title": "Ur: statically-typed metaprogramming with type-level record computation", "url": "http://dl.acm.org/citation.cfm?id=1806612"}