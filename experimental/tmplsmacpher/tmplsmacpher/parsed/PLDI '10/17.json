{"article_publication_date": "06-05-2010", "fulltext": "\n Green: A Framework for Supporting Energy-Conscious Programming using Controlled Approximation * Woongki \nBaek Computer Systems Laboratory Stanford University Stanford, CA 94305 wkbaek@stanford.edu Trishul \nM. Chilimbi Microsoft Research One MicrosoftWay Redmond,WA98052 trishulc@microsoft.com Abstract Energy-ef.cient \ncomputing is important in several systems rang\u00ading from embedded devices to large scale data centers. \nSeveral ap\u00adplication domains offer the opportunity to tradeoff quality of ser\u00advice/solution (QoS) for \nimprovements in performance and reduc\u00adtion in energy consumption. Programmers sometimes take advan\u00adtage \nof such opportunities, albeit in an ad-hoc manner and often without providing anyQoS guarantees. We propose \na system called Green that provides a simple and .exible framework that allows programmers to take advantage \nof such approximation opportunities in a systematic manner while providing statistical QoS guarantees. \nGreen enables programmers to approximate expensive functions and loops and operates in two phases.Inthe \ncalibrationphase,itbuildsamodeloftheQoSloss produced by the approximation. This model is used in the \nopera\u00adtional phase to make approximation decisions based on the QoS constraints speci.ed by the programmer. \nThe operational phase also includes an adaptation function that occasionally monitors the runtime behavior \nand changes the approximation decisions and QoS model to provide strong statistical QoS guarantees. ToevaluatetheeffectivenessofGreen,we \nimplementedoursys\u00adtem and language extensions using the Phoenix compiler frame\u00adwork. Our experiments \nusing benchmarks from domains such as graphics, machine learning, signal processing, and .nance, and \nan in-production, real-world web search engine, indicate that Green can produce signi.cant improvements \nin performance and energy consumption with small and controlled QoS degradation. Categories and Subject \nDescriptors D.1.m[ProgrammingTech\u00adniques]: Miscellaneous; D.3.3[Programming Languages]: Lan\u00adguage Constructs \nand Features General Terms Performance, Measurement, Languages, Designs Keywords Energy-Conscious Programming, \nControlled Approx\u00adimation * A part of this work was performed while the author was an intern at Microsoft \nResearch, Redmond. Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page.To copyotherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. PLDI 10, June 5 10, 2010,Toronto, Ontario, Canada. Copyright c &#38;#169; 2010 ACM 978-1-4503-0019-3/10/06... \n$10.00 1. Introduction Companies such as Amazon, Google, Microsoft, and Yahoo are building several large \ndata centers containing tens of thousands of machines to provide the processing capability necessary \nto support web services such as search, email, online shopping, etc. [3]. Not surprisingly,powerisalarge \ncomponentofthe monthly operational costs of running thesefacilities and companies have attempted to address \nthisby locatingthemin places wherepoweris cheap [13]. In addition, energyis oftenakey design constraintin \nthe mobile and embeddeddevices spacegiventhe current limitationsof battery technology. There are several \napplication domains where it is acceptable to provide an approximate answer when the cost and resources \nre\u00adquired to provide a precise answer are unavailable or not justi.ed. For example, real-time ray tracing \nis infeasible on current PCs so games employa variety of techniques to produce realistic looking lighting \nand shadows while still rendering at 60 frames per second. Content such as images, music, and movies \nare compressed and encoded to various degrees that provide a tradeoff between size requirements and .delity. \nSuch approximations typically result in the program performing a smaller amount of processing and con\u00adsequently \nconsuming less energy while still producing acceptable output. Programmers often take advantage of such \nQuality of Service (QoS) tradeoffs by making use of domain-speci.c characteristics and employing a variety \nof heuristics. Unfortunately, these tech\u00adniques are often used in an ad-hoc manner and programmers rarely \nquantify the impact of these approximations on the application. Even in cases where they attempt to quantify \nthe impact of the heuristics used, these are hard to maintain andkeep up-to-date as programs evolve and \nadd new features and functionality. Toaddress these issues, this paper proposes Green shown in Fig\u00adure \n1, which is a framework for supporting energy-conscious pro\u00adgramming using loop and function approximation. \nGreen provides a simple, yet .exible framework and programming support for ap\u00adproximating expensive loops \nand functions in programs. It allows programmers to specify a maximal QoS loss that will be tolerated \nand provides statistical guarantees that the application will meet this QoS target. Programmers must \nprovide (possibly multiple) ap\u00adproximateversionsofthe functionfor function approximation.Un\u00adless directed \notherwise, Green uses the function return value as the QoS measure and computes loss in QoS by comparing \nagainst the value returnedbythe precise functionversiongiven the same input. Loops are approximated by \nrunning fewer loop iterations. In this case, a programmer must provide a function that computes QoS to \nenable Green to calculate the loss in QoS that arises from early loop termination.  Figure 1. Overview \nof the Green system. Green uses this information about loops and functions that are candidates for approximation \nto construct a calibration program version. Green runs this application version with a programmer\u00adprovided \nset of calibration inputs to construct a QoS model that quanti.es the loss in QoS that results from using \nthe approximate version of the function or loop and the corresponding improve\u00adment in application performance \nand energy consumption. Green then generates an approximate version of the program that uses this QoS \nmodel in conjunction with the programmer supplied QoS target to determine when to use the approximate \nversion of the function or terminate the loop early while still meeting the QoS requirement. Since the \nQoS degradation on actual program inputs may differ from that observed during calibration, Green also \nsam\u00adples the QoS loss observed at runtime and updates the approxima\u00adtion decision logic to meet the speci.ed \nQoS target. In this way, Green attempts to provide statistical guarantees that the speci.ed QoS will \nbe met. Such statistical guarantees are becoming impor\u00adtant as cloud-based companies provide web services \nwith Service Level Agreements (SLAs) that typically take the form: the service will provide a response \nwithin 300ms for 99.9% of its requests for a peak client load of 500 requests per second [8]. Our experimental \nresults indicate that Green can signi.cantly improve performance and reduce energy consumption of several \napplications with only a small degradation in QoS. In particular, we improved the performance and reduced \nthe energy consump\u00adtion of Bing Search,aback-end implementationofacommercial, in-production web-search \nengineby 21.0% and 14.0% respectively with 0.27%ofQoSdegradation (three queries outofa thousand re\u00adturned \na search result that included at least one different document orthe same documentsinadifferent rank order).We \nalso empiri\u00adcally demonstratethatGreencan generatearobustQoSmodelwith a relatively small training data-set \nand that runtime re-calibration can enable applications to meet their QoS targets even if they use imperfectQoS \nmodels.TheQoS models producedbyGreen during the calibration phase have also proved useful in providing \ndevelop\u00aders with a better understanding of their application. This paper makes the following main contributions. \n Describes the design and implementation of the Green sys\u00adtem, which provides simple, yet .exible support \nfor energy\u00adconscious programming using function and loop approxima\u00adtions.  Experimental evaluation of \nthe Green system that shows sig\u00adni.cant improvements in performance and energy consumption with little \nQoS degradation.  Experimental evidence that indicates that Green s QoS model\u00ading is robust and that \nits adaptation supports meeting target QoS requirements.  The restofthe paperisorganizedas follows. \nSection2describes the designof the Green system. Section3discusses our implemen\u00adtation of Green. Experimental \nevaluation of Green is described in Section4. Section5providesa briefoverviewof relatedwork, and Section6concludes \nthe paper. 2. Green Design Figure1providesa high-leveloverviewof the Green system that we introduce and \ndiscuss in more detail in this section. 2.1 Controlled Program Approximation Expensive functions and \nloops present attractive targets for pro\u00adgram approximation because theyare modular and time-consuming \nportions of programs. Green considers function approximations that use an alternative, programmer-supplied \napproximate version of the function and loop approximations that terminate the loop ear\u00adlier than the \nbase (precise) version. But we would like to quantify the impact these approximations have on the QoS \nof the program. To do this, the programmer must supply code to compute a QoS metric for the application \nand some training inputs. These training inputs are used during a calibration phase as shown in Figure \n1. During these training runs, Green monitors and records the impact function or loop approximation has \non the program s QoS and its performanceand energy consumption. This datais usedtobuilda QoS model that \nis subsequently used by Green to decide when to approximateandwhentousethepreciseversioninorderto guaran\u00adtee \nuser-speci.edQoS ServiceLevel Agreements (SLAs). Figure2 illustrates at a high-level how Green approximates \nloops or func\u00adtions while still attempting to meet required QoS SLAs. The QoS model constructed in the \ncalibration phase is used by the Green synthesized QoS Approx() to decide whether approximation is ap\u00adpropriate \nin the current situation as determined by the function in\u00adput or loop iteration count. Since the QoS \ndegradation on the actual program inputs may differ from that observed during the calibra\u00adtion phase, \nGreen provides a mechanism to occasionally measure the program s QoS and update the QoS approximation \ndecisions at runtime.  2.2 Green Mechanisms As described, Green requires a QoS Compute() function for \ncom\u00adputing the program s QoS (for function approximation, the origi\u00adnal precise function serves this \npurpose), and then synthesizes a QoS Approx() function for determining whether to perform an ap\u00adproximation, \nand a QoS ReCalibrate() function for revisiting ap\u00adproximation decisions at runtime. In addition, it \nrequires a set of training inputs to construct the QoS model used to synthesize the QoS Approx() function \nand a QoS SLA value that must be met.  Figure 2. High-level overview of Green s approximation. We provide \na high-level description of these mechanisms here and leave a detailed discussion to the next section. \n2.2.1 QoS Calibration and Modeling Green s calibration phase collects the data required to build the \nQoS model. It requires QoS Compute(), which is application de\u00adpendent and can range from trivial asin \nthe case of using the ap\u00adproximated function s returnvaluetoa moreinvolved computation involvingpixelvalues \nrenderedonthe screen.Green usesthisfunc\u00adtion along with the set of training inputs to construct a QoS \nmodel that relates function inputs in the case of function approximation and loop iteration count in \nthe case of loop approximation to loss in QoS and performance and energy consumption improvements. This \nQoS model is used in conjunction with a provided target QoS SLA to make approximation decisions. 2.2.2 \nQoS Approximation QoS Approx() comes in twomain .avors for loop approximations. In the static variety, \nthe approximation is solely determined by the QoS model constructed in the calibration phase. Here the \nloop it\u00aderation count threshold is determined by the QoS model and the user-speci.ed QoS SLA. Once the \nloop iteration countexceeds this threshold, the approximation breaks out of the loop. The adaptive variety \nis based on the lawof diminishing returns. Here the approx\u00adimation uses the QoS model in conjunction \nwith the QoS SLA to determine appropriate intervals at which to measure change in QoS and the amount \nof QoS improvement needed to continue iterating the loop. For function approximation, the QoS model is \nused in conjunction with the QoS SLA and the function input to determine ifthe function shouldbe approximatedand \nwhich approximatever\u00adsion of the function to use. 2.2.3 QoS Re-Calibration The program sbehavior may \noccasionally differ from that observed on its training inputs and QoS ReCalibrate() provides a mecha\u00adnism \nto detect and correct for this effect. In the case of loop ap\u00adproximation, when used with static approximation \nre-calibration can update the QoS model and increase the loop iteration count threshold to compensate \nfor higher than expected QoS degradation or decrease this threshold to improve performance and energy \ncon\u00adsumption when QoS degradation is lower than expected. Similarly, when used with adaptive approximation \nre-calibration can appro\u00adpriately change the interval used to measure change in QoS and/or QoS improvement \nrequired to continue. For function approxima\u00adtion, re-calibration allows Green to switch the approximate \nversion of the function used to one that is more or less precise as determined by the observed QoS loss. \n 2.2.4 Discussion To tie these concepts together,we illustrate an end-to-end example of applying loop \napproximation to the main loop of a simple pro\u00adgram that estimates Pi in Figure 3. The underlined terms \ncorrespond to functions or variables that are supplied by the programmer. The rest of the code is generated \nby the Green system. Since, as shown in Section 4, Green s re-calibration mechanism is quite effective, \none might underestimate the importance of the calibration phase and attempt to solely rely on the re-calibration \nmechanism. However, the calibration phase is still important and necessary becauseitprovides(1)faster \nconvergencetoagood state, (2) reliable operation even when users choose to avoid or mini\u00admize re-calibration \nto lower overhead, and (3) programmer insight into the application s QoS tradeoff through the QoS model \ncon\u00adstructedby Green during the calibration phase.Infact, Green users have provided consistent feedback \nthat the QoS model constructed has provided extremely valuable and often unexpected information about \ntheir application behavior. Green s reliance on a runtime re-calibration mechanism to en\u00adsure that the \ndesired QoS is met permits approximating multiple expensive loops and functions within the same application. \nIn con\u00adtrast,astatic approachto estimatingQoSwouldhaveto accountfor non-linear effects arising from combining \nmultiple approximations. Our current implementation builds a local QoS model for each approximated program \nunit, uses these to construct a global QoS model for the application, and coordinates re-calibration \nacross these. 3. Green Implementation This section describes our implementation of the Green system that \nprovides a simple and .exible framework for constructing a wide varietyof approximation policies(see \nFigure1foroverview).Our goal is to provide a minimal and simple interface that satis.es the requirements \nof the majority of programmers while providing the hooks that allow expert programmers to craft and implement \ncus\u00adtom, complex policies.To achieve this, Green comes witha couple of simple, default policies that \nmeet the needs of manyapplications and enables them to bene.t from using controlled QoS approxima\u00adtion \nwith minimal effort. At the same time, it allows programmers to override these default policies and supply \ntheir own by writing custom versions of QoS Approx() and QoS ReCalibrate() while still bene.ting from \nGreen s calibration and modeling capability. We discuss Green s interface and default policies and provide \nan instance of a customized policy. 3.1 Green Programming Support 3.1.1 Loop Approximation Green supports \nloop approximation with a new language key\u00adword approx loop as shown in Figure 2. The programmer uses \napprox loop just before the target loop and supplies a pointer to a user-de.ned QoS Compute() function, \nthe value of the desired QoS SLA and indicates whether they want to use static or adap\u00adtive approximation.In \naddition,ifthe programmer wantstoavail of runtime re-calibration she must provide the sampling rate(sam\u00adple \nQoS) to perform re-calibration. If a programmer wishes to construct a custom policy, they must also supply \npointers to cus\u00adtom QoS Approx() and/or QoS ReCalibrate() routines.  3.1.2 Function Approximation For \nfunction approximation, Green introducesa newkeywordap\u00adprox function as shown in Figure 2. The programmer \nuses ap\u00adprox function before the target function implementation and sup\u00adplies a function pointer array \nthat contains pointers to user-de.ned  Figure 3. An end-to-end example of applying loop approximation \nto the Pi estimation program. approximate versions of that function in increasing order of pre\u00adcision, \nalong with the value of the desired QoS SLA and a sam\u00adpling rate(sample QoS)if re-calibration is required. \nIf the func\u00adtion return value does not provide the desired QoS metric, the pro\u00adgrammer must also supply \na pointer to a custom QoS Compute() function. If the function takes multiple arguments, Green requires \nthe parameter positions of the arguments that should be used while building the QoS model1. As with approx \nloop, pointers to cus\u00adtom QoS Approx() and/or QoS ReCalibrate() routines are op\u00adtional and only needed \nfor custom policies.  3.2 Green System Implementation Figure 1 and Figure 3 provide an overview of \nthe Green system implementation. The Green compiler .rst generates a calibration Figure 4. QoS Compute \nfor Bing Search. version of the program that is run with user-provided calibration inputs to generate \nQoS data needed tobuild the QoS model. Then the compiler uses this constructed QoS model to generate \nan ap\u00ad  3.2.1 Loop Approximation proximate version of the program that can be run in place of the original. \nIt synthesizes code to implement QoS Approx() and The programmer-supplied QoS Compute() function is used \nin QoS ReCalibrate(). the calibration phase to tabulate the loss in QoS resulting from early loop termination \nat loop iteration counts speci.ed by Cal\u00ad ibrate QoS. QoS Compute() function has the following inter\u00ad1Our \ncurrent implementation constructs models based on a single input face: QoS Compute (return QoS, loop \ncount, calibrate, Cal\u00adparameter. However, this can be extended to multiple parameters. ibrate QoS, ...) \nand the search application s version is shown  Figure 5. Code generated for loop approximation. Figure \n6. Calibration data for Bing Search. in Figure 4. Note that when QoS Compute() is called with re\u00adturn \nQoS unset it stores the QoS computed at that point and only returns QoS loss when this .ag is set. Then, \nit compares the current QoS against the stored QoS to return the QoS loss. When it is called with the \ncalibrate .ag set at the end of the loop in calibration mode, it computes and stores the% QoS loss when \nthe loop terminates early at loop iteration counts speci.ed by Calibrate QoS. Figure6shows the calibration \ndata generated for Bing Search, that quanti.esthe impactof limitingthe documents searchedtoM rather than \nall matching documents on QoS and throughput. This calibration data is then used by Green s QoS modeling \nroutine that is implemented as a MATLAB program. The MATLAB program is used for interpolation and curve \n.tting to construct a function from these measurements. It automatically selects the appropriate approximation \nlevel based on the QoS value desired by the pro\u00adgrammer and this empirically constructed model. The programmer \nonly supplies the desired QoSValue. This model supports the fol\u00adlowing interface for loops: M = QoS Model \nLoop(QoS SLA, static) (1) < M, P eriod, T arget Delta >= QoS Model Loop(QoS SLA, adaptive) (2) For static \napproximation the QoS model supplies the loop itera\u00adtion count thatis usedby QoS Approx() for early loop \ntermination. In the adaptiveapproximation case,the QoS model additionally de\u00adtermines the period and \ntarget QoS improvement required to con\u00adtinue iterating the loop. The synthesized QoS Approx() codeshowninFigure5usesthe \nparameters generatedbytheQoS modelto perform approximation. Figure 7. Code generated for function approximation. \nWhen the approximation is being re-calibrated, the synthesized approximation code stores the QoS value \nthat would have been generated with early loop termination and continues running the loop as manytimes \nas the original (precise) programversionwould have in order to compute the QoS loss (see Figure 3). The \nQoS ReCalibrate() code generatedbyGreen compares this QoS loss against the target QoS SLA and either \ndecreases/increases the approximationby either increasing/decreasing thevalueMof the early termination \nloop iteration count (static approximation) or decreasing/increasing the value of Target Delta (adaptive \napprox\u00adimation).  3.2.2 Function Approximation By default, Green uses the function return value to compute \nQoS unless the programmer de.nes a separate QoS Compute() func\u00adtion.For calibration, Green generates \ncode that computes and stores the loss in precision that results from using thefamily of approx\u00adimation \nfunctions at each call site of the function selected for ap\u00adproximationbut our current implementation \ndoes not differentiate between call sites and uses the same QoS Approx() function for all sites. Figures \n8(a) and 8(b) shows the calibration data generated for the exp and log functions in the blacksholes application \nover the input argument range observed on the training inputs. Green s modeling routine uses this data \nand supports the fol\u00adlowing interface for functions2: < (Mi, lbi, ubi) >= QoS Model Func(QoS SLA) where \nit returns the best approximate function version and corre\u00adsponding input argument range where the QoS \nloss for that func\u00adtion satis.es the speci.ed target QoS SLA. In the event that none of the approximate \nfunction versions meet the QoS requirement, it returns an empty set and the precise function is used. \nThe synthesized QoS Approx() function for the exp function in blacksholes is shown in Figure 7, where \nit uses exp(3) for 0.5 = abs(x) < 0.8, exp(4) for 0.8 = abs(x) < 1.1 and the precise exp function for \nabs(x) = 1.1 and abs(x) < 0.53. Note that exp(5) and exp(6) (see Figure 8(a)) were discarded because \ntheydid not providea competitiveQoS lossto performance improvement ratio. The QoS ReCalibrate() function \nreplaces the current approximate function version with a more precise one, to address low QoS, and usesa \nmore approximateversionto address higher than necessary QoS. 2Our current QoS modeling scheme only works \nfor functions that take numerical data as input and would need to be extended to handle functions that \ntake structured data as input. 3The approximate versions of the exp (and log)functions correspond to \ndifferentTaylor seriesexpansions with the number indicating the highest degree polynomial used.  (a) \nQoS(exp functions) (b) QoS(log functions) (c) Performance Figure 8. Calibration data for blacksholes. \n 3.3 Custom Approximation Green allows programmers to override its default synthesis of QoS Approx() \nand QoS ReCalibrate() to implement custom ap\u00adproximation policies. Figure 9 shows an example of a custom \nQoS ReCalibrate() that we used for the Search application. For Bing Search, QoS Compute() returns a QoS \nloss of1 (100%) if the top N documents returned by the precise and approximate version do not exactly \nmatch and a QoS loss of 0 otherwise. To perform re-calibration and compare against a target QoS SLA that \nis of the form, the application returns identical results for 99% of the queries , we need to measure \nthe QoS loss across multiple queries as implemented in the code shown. It is certainly possi\u00adble to relax \nthis stringent QoS requirement and allow document reordering within the topNdocuments returned. But we \nused this strictQoS requirementforthe searchexperimentstoavoid address\u00ading how such reorderings may affect \nthe perceived quality of the search results returned. The calibration and QoS Approx() uses the default \ncode synthesizedby Green. Bing Search was the only application of those evaluated in this paper that \nneeded a custom recalibration routine mainly because its QoS metric is computed over an aggregate set \nof queries and not an individual query.  3.4 Green Support for Multiple Approximations So far, we have \ndiscussed Green support for individual loop or function approximation and this section discusses Green \ns mech\u00adanisms for combining multiple approximations. Green requires the application developer to provide \nan additional QoS Compute() function for the application and an application QoS SLA. In many cases, this \nis identical to the QoS Compute() function already sup\u00adplied for loop approximation. 3.4.1 QoS Approximation \nModeling Green performs the calibration for each function or loop approxi\u00admation in isolation as shown \nin Figures 6, 8(a), and 8(b), and then performs an exhaustive search space exploration that attempts \nto combine these and still meet the speci.ed application QoS SLA. Figure 8(c) illustrates this process \nfor the exp and log functions in the blacksholes application, where exp(cb) represents the com\u00adbination \nof exp(3) and exp(4) that was selected for approximating exp as shown in Figure 7. This search process \ncan result in in\u00addividual function/loop approximation decisions being changed so that the overall application \nQoS SLA is still satis.ed. In the case of blacksholes, the local approximation decision to use log(2) \nwas changed to use log(4), so that the combined approximation of using exp(cb) with log(4) was able to \nsatisfy the application QoS. Note that unlike exp the calibration process did not .nd a combination of \nlog functions viable for this application (strictly Figure 9. Customized QoS ReCalibrate for Bing Search. \nworse than the individual log approximations) and hence there are no combined log(cb) bars shown in Figure \n8(c).  3.4.2 Global Recalibration When an application that has multiple approximate functions and/or \nloops requires recalibration to meet its QoS SLA, Green initiates a global recalibration process. This \nentails selecting a sub\u00adset of functions and loops for recalibration and then performing local recalibration \nof these. Our current implementation of global recalibration initially assumes that the individual approximations \nare independent of each other and the approximations are addi\u00adtive,but subsequently detects and applies \ncorrections to the cases where this assumption is not valid. In the case where the measured application \nQoSfalls below the speci.ed SLA, recalibration can\u00addidates are rankedby their QoS loss/performancegain \nsensitivity as per the QoS model. This enables recalibration to be .rst ap\u00adplied to candidates where \na large QoS change produces a small performance change.To handle the case where the approximations interact \nand produce non-linear effects, Green uses an exponential backoff scheme similar to that used for TCP/IP \npacket retrans\u00admission [19]. In this scheme, individual approximations are recal\u00adibrated as follows. \nLoop approximations are recalibrated using a random increase in the number of iterations within an acceptable \nrange and approximated functions are replacedby higher precision ones over a random portion of their \ninput argument range, until the non-linear effects disappear and the application QoS SLA is satis\u00ad.ed \nor the approximation is disabled and the precise loop/function is used. This scheme appears to perform \nwell and convergefast on arti.cial testexamples we constructed tovalidateits ef.cacybut we have been \nunable to force such non-linear behavior in any of our benchmark applications.  4. Green Evaluation \nWe performedtwo typesofexperiments. First, we show that Green can produce signi.cant improvements in \nperformance and reduc\u00adtion in energy consumption with little QoS degradation. Next, we show that the \nQoS models Green constructs are robust and in conjunction with runtime re-calibration provide strong \nQoS guar\u00adantees. For evaluation, we use .ve applications including Bing Search, a back-end implementation \nof a commercial web-search engine, and four other benchmarks including 252.eon from SPEC CPU2000 [24], \nCluster GA(CGA)[14], DiscreteFourierTransfor-mation(DFT)[7], andblackscholes from the PARSEC bench\u00admark \nsuite [4]. The choice of blackscholes was drivenbyconver\u00adsations with computational .nance practitioners \nwho pointed out that microseconds matter and controlled approximation is appro\u00adpriate for their domain \nas theyemploysophisticated risk analysis models. 4.1 Environment We use two different machines for our \nexperiments. A desktop machine is used for experiments with 252.eon, CGA, DFT, and blackscholes. The \ndesktop machine runs an Intel Core 2 Duo (3GHz) processorwith4GB(dual channelDDR2667MHz)main memory.Aserver-class \nmachineisusedforexperimentswith Bing Search. The server machine has two Intel 64-bit Xeon Quad Core (2.33GHz) \nwith8GB main memory. For each application, we compare the approximated versions generated by the Green \ncompiler implemented using the Phoenix compiler framework [20] against their corresponding precise (base) \nversions.Forevaluation, we measure threekeyparameters for each version: performance, energy consumption, \nand QoSloss.For the other benchmarks, the wall-clock time between start and end of each run is used for \nperformance evaluation. For Bing Search, we.rstrunasetofwarmupqueriesandusethe measuredthrough\u00adput (i.e., \nqueries per second (QPS)) while serving the test queries as the performance metric.Tomeasure the energy \nconsumption, we use an instrumentation device that measures the entire system en\u00adergy consumptionby periodically \nsampling the current andvoltage values from the main power cable. The sampling period of the de\u00adviceis1 \nsecond. Since theexecution timeof the applications we study are signi.cantly longer, this sampling period \nis acceptable. Finally, we compute the QoS loss of each approximate version by comparing against results \nfrom the base versions. The QoS metric usedforeach applicationwillbe discussedlater.Wealso measured the \noverhead of Green by having each call to QoS Approx() even\u00adtually returnfalse and found the performance \nto be indistinguish\u00adable from the base versions of the applications without the Green code, when the \nrecalibration sampling rate was set to 1%.  4.2 Applications In this section, we provide a high-level \ndescription and discuss Green approximation opportunities for each application. In addi\u00adtion, we discuss \nthe evaluation metrics and input data-sets used. 4.2.1 Bing Search Description: Bing Search is a back-end \nimplementation of a commercial web-search engine that accepts a stream of user queries, searches its \nindex for all documents that match the query, and ranks these documents before returning the top N documents \nthat matchthe queryinrank order.Webcrawlingandindexupdates are disabled. There are a number of places \nin this and subsequent sections where additional information about the Bing Search application may have \nbeen appropriate but where protecting Mi\u00adcrosoft sbusiness interests require us to reduce some level \nof de\u00adtail. For this reason, performance metrics are normalized to the base version and the absolute \nnumber of documents processed are not disclosed. Opportunities for Approximation: The base version of \nBing Search processes all the matching candidate documents. Instead, we can limit the maximum number \nof documents(M)that each query must process to improve performance and reduce energy consumption while \nstill attempting to provide a high QoS. Evaluation Metrics:We use QPS as the performance metric since \nthroughputiskeyfor server applications.We use Joules per Query as the energy consumption metric. Finally, \nfor our QoS loss metric, we use the percentage of queries that either return a different set of top N \ndocuments or return the same set of top N documentsbut in a different rank order, as compared to the \nbase version. Input data-sets: The Bing Search experiments are performed with a production index .le \nand production query logs obtained from our data center. Each performance run uses two sets of queries: \n(1) warm-up queries: 200K queries to warm up the sys\u00adtem and (2) test queries: 550K queries to measure \nthe performance of the system. 4.2.2 Graphics: 252.eon Description: 252.eon is a probabilistic ray tracer \nthat sends N2 rays to rasterize a 3D polygonal model [24]. Among the three implemented algorithms in \n252.eon, we only used the Kajiya algorithm [12]. Opportunities for Approximation: The main loop in 252.eon \niterates N2 iterations and sends a ray at each iteration to re.ne the rasterization. As the loop iteration \ncount goes higher, QoS improvement per iteration can become more marginal. In this case, the main loop \ncan be early terminated while still attempting to meet QoS requirements. Evaluation Metrics:We measure \nthe execution time and energy consumption to rasterize an input 3D model.To quantify the QoS loss of \napproximate versions, we compute the average normalized difference of pixel values between the precise \nand approximate versions. Input data-sets: We generated 100 input data-sets by randomly changing the \ncamera view using a reference input 3D model of 252.eon.  4.2.3 Machine Learning: Cluster GA Description: \nCluster GA (CGA) solves the problem of schedul\u00ading a parallel program using a genetic algorithm [14]. \nCGA takes a task graph as an input where the execution time of each task, dependencies among tasks, and \ncommunication costs between pro\u00adcessors are encoded using node weights, directed edges, and edge weights, \nrespectively. CGA re.nes the QoS until it reaches the max\u00adimum generation (G). The output of CGA is the \nexecution time of a parallel program scheduled by CGA. Opportunities for Approximation: Depending on \nthe size and characteristics of a problem, CGA can converge to a near-optimal solution even before reaching \nG. In addition, similar to 252.eon, QoS improvement per iteration can become more marginal at higher \niteration counts (i.e., generation). By terminating the main loop earlier, we can achieve signi.cant \nimprovement in perfor\u00admance and reduction in energy consumption with little QoS degra\u00addation. Evaluation \nMetrics:Weuse the same metrics for performance and energy consumption as for 252.eon.For a QoS metric, \nwe com\u00adpute the normalized difference in the execution time of a parallel program scheduledby the base \nand approximateversions. Input data-sets: We use 30 randomly generated task graphs de\u00adscribedin [15].To \nensurevarious characteristicsin the constructed task graphs, the number of nodes varies from 50 to 500 \nand com\u00admunication to computation ratio (CCR) varies from 0.1 to 10 in randomly generating task graphs. \n  4.2.4 Signal Processing: Discrete Fourier Transform Description: Discrete Fourier Transform (DFT) \nis one of the most widely used signal processing applications [7] that trans\u00adforms signals in time domain \nto signals in frequencydomain. Opportunities for Approximation: In the core of DFT, sin and cos functions \nare heavily used. Since the precise version imple\u00admented in standard libraries can be expensive especially \nwhen the underlying architecture does not support complex FP operations, the approximated version of \nsin and cos functions can be effec\u00adtively usedifit provides suf.cient QoS.We implement several ap\u00adproximated \nversions of sin and cos functions [9] and apply them to our DFT application. Evaluation Metrics:Weuse \nthe same metrics for performance and energy consumption as 252.eon.AsaQoS metric,we computethe normalized \ndifference in each output sample of DFT between the precise and approximated versions. Input data-sets:We \nrandomly generate 100 different input data\u00adsets.Eachinputsamplehasa randomrealvaluefrom0to1. 4.2.5 Finance: \nblackscholes Description: blackscholes computes the price of a portfolio of European options using a \npartial differentialequation. The imple\u00admented method is a very popular technique for pricing options. \nOpportunities for Approximation: The core computation makes heavy use of the exponentiation exp and logarithm \nlog functions. We provided a series of approximate versions of these functions that use the correspondingTaylor \nseriesexpansions withvarying number of polynomial terms4. Evaluation Metrics:Weuse the same metrics for \nperformance and energy consumption as 252.eon. As a QoS metric, we compute thedifferenceinoptionprices \nproducedbythepreciseand approx\u00adimate versions of the programs. Input data-sets:We use the large simulation \ndata set provided by theParsec benchmark suite for training and report results using the native execution \ndata set. The training data set prices 64 thousand options and the native data set prices 10 million \noptions.  4.3 Experimental Results with Bing Search Figures 10 and 11 demonstrate the tradeoffbetween \nthe QoS loss and the improvement in performance5 and reduction in energy con\u00adsumption. The base version \nis the current implementation of Bing 4The blackscholes Parsec benchmark includes a loop that repeatedly \ncomputes the value of the option portfolio to increase the work performed by the application. All iterations \nof this loop except for the .rst can be skipped without affecting the results. We did not approximate \nthis loop and measured similar improvements when this loop was executed once and when it executed the \nnumber of times speci.ed in the benchmark. 5Figure 12 illustrates how the performance of each version \nof Bing Search is determined by the cutoffQPS metric. CutoffQPS is de.ned as QPS where the success rate \nof queries goes as low as (100 - 4d)%shown as the dotted line. Anylower and the Search QoS SLA is considered \nto be violated.  Search, while M-* versions are approximated. Speci.cally, M-*N statically terminates \nthe main loop after processing *N matching documents for each query. M-PRO-0.5N samples QoS improve\u00adment \nafter processing every 0.5N documents and adaptively ter\u00adminates the main loop when there is no QoS improvementin \nthe currentperiod.As canbe seen, some approximatedversions signif\u00adicantly improve the performance and \nreduce the energy consump\u00adtion(i.e.,Joulesperquery)withvery littleQoSloss.Forexample, M-N improves throughputby \n24.3% and reduces energy consump\u00adtion by 17% with 0.94% of QoS loss. Another interesting point is that \nM-PRO-0.5N that uses the adaptive approximation leads to slightly better performance and less energy \nconsumption while pro\u00adviding better QoS compared to M-2N version that uses the static approximation. \nThis showcases the potential of adaptivetechniques to optimize Bing Search.    To study the sensitivity \nof Green s QoS model to the training data-set size, we randomly permuted the warm-up and test queries \nand injected different number of queries ranging from 10K to 250K queries tobuild the QoS model. Figure \n13 demonstrates the difference in estimated QoS loss (when M=N) with the varying size of training data-sets. \nQoS models generated with much fewer number of queries are very close to the one generated with 250K. \nFor example, the QoS model generated using only 10K queries differs by only 0.1% compared to the one \ngenerated using 250K inputs. This provides empirical evidence that Green can construct a robust QoS model \nfor Bing Search without requiring huge training data-sets. To evaluate the effectiveness of Green s re-calibration \nmecha\u00adnism, we performed an experiment simulating an imperfect QoS model.Saya user indicates his/her \ndesiredQoStargetas2%,but the constructed QoS model incorrectly suppliesM = 0.1N (which typically results \nin a 10% QoS loss). Thus, without re-calibration Bing Search will perform poorly and not meet the target \nQoS. Figure 14 demonstrates how can Green provide robust QoS guar\u00adantees even when supplied with an inaccurate \nQoS model. After processing every 10K queries, Green monitors the next 100 con\u00adsecutivequeries (i.e., \nSample QoS=1%)byrunning the precisever\u00adsion while also computing the QoS loss, if it hadused the approxi\u00admatedversionfor \nthose100 queries. Sincethe currentQoS modelis not accurate enough, the monitored results willkeep reportinglow \nQoS. Then, Green s re-calibration mechanismkeeps increasing the accuracylevel (i.e.,by increasing theMvalueby \n0.1N) untilit sat\u00adis.es the user-de.ned QoS target. In Figure 14, Green meets the QoS target after processing \n180K queries. The user could use a pe\u00adriod smaller than 10K to make Green adapt faster but there is a \ntradeoffbetween quick adaptation and degradation in performance and energy consumption causedby more \nfrequent monitoring.We performed identical re-calibration experiments for the other appli\u00adcations with \nsimilar results.   4.4 Experimental Results with Benchmarks Figures 15 and 16 show the results for \n252.eon using 100 ran\u00addomly generated input data-sets. Similar to Bing Search, approx\u00adimatedversions \nof 252.eon signi.cantly improve the performance and energy consumption with relatively low QoS loss. \nFigure 17 demonstrates the sensitivity of Green s QoS model for 252.eon to the size of training data-sets. \nWe varied the training data size from 10 to 100, and compared the estimated QoS loss difference (when \nN=9) of the generated QoS model to the one generated us\u00ading 100 inputs. Figure 17 provides empirical \nevidence that Green s QoS model for 252.eon can be constructed robustly with relatively small training \ndata-sets.Forexample,theQoS model generated us\u00ading10 inputsdiffersbyonly 0.12% comparedtothe one generated \nusing 100 inputs.   Figures 18 and 19 demonstrate the Green model of CGA using 30 randomly generated \ninput data-sets. Up to G=1500, QoS loss is reasonable(<10%), while signi.cantly improving performance \nand energy consumption by 50.1% and 49.8%, respectively. In Figure20,Wealso presentthe sensitivityof \nGreen sQoSmodelof CGA tothe training data-set size.Wevariedthe numberof training inputsfrom5to30and comparedthe \nestimatedQoSloss (G=2500) from the generated QoS model to the one generated using 30 inputs. While the \ndifference in the estimated QoS loss is higher than other applications due to the discrete nature of \nthe outcome of a parallel task scheduling problem, the difference is still low(<0.5% even when5inputs \nare used). Figures 21 and 22 show the tradeoffbetween QoS loss and im\u00adprovement in performance and energy \nconsumption using various approximated versions of DFT generated by Green. More speci.\u00adcally, each DFT \nversion uses sin and cos functions that provide different accuracyranging from 3.2 digits to 23.1 (base) \ndigits [9]. Up to the accuracyof 7.3 digits, no accuracyloss is observed due to the combined sin and \ncos approximation while improving per\u00adformance and energy consumption of DFT by around 20.0%. Even usingthe \naccuracyof3.2 digits,the observedQoSlossisverylow (0.22%), while improving performance and energy consumption \nof DFT by 26.3% and 26.8%, respectively. This clearly indicates the potential of function-level approximation \nusing Green. While not shown, the QoS model constructed for DFT is also similarly robust and can be accurately \ngenerated with very few inputs.  Figures 23 and 24 show the tradeoffbetween QoS loss and im\u00adprovement \nin performance and energy consumption using various approximated versions of blacksholes generated by \nGreen. The version .nally selected by Green uses a combination of approxi\u00admate exp functions,(exp(3) \nand exp(4))over different portions of the input argument range, with the log(4) function to provide performance \nand energy improvements of 28.5% and 28% respec\u00adtively with a QoS loss of less than 0.8%. This result \ndemonstrates that Green is able to successfully combine multiple approxima\u00adtions. The .nal approximation \nchoice of exp(cb)+log(4) was au\u00adtomatically re.ned from the local choices of exp(cb) and log(2) to reduce \nthe overall application QoS loss to less than 1%. The QoS model constructed for blackscholes is also \nvery robust and the training data set used (64 thousand options) accurately predicts QoS loss on the \ntest data to within 0.1%. 5. Related Work There are several application domains such as machine learning \nand multimedia data processing where applications exhibit soft com\u00adputing properties [5]. The common \nsoft computing properties are user-de.ned, relaxed correctness, redundancy in computation, and adaptivity \nto errors [2,16].Researchershavestudiedimprovingthe performance, energy consumption, andfault tolerance \nof applica\u00adtions and systems by exploiting these soft computing properties. However, to the best of our \nknowledge, we believe Green is the .rst system that provides a simple, yet .exible framework and pro\u00adgramming \nsupport for controlled approximations that attempts to meet speci.ed QoS requirements. Greenis most similarto \nRinard spreviouswork[21,22]inthe senseof proposingaprobabilisticQoS model (i.e., distortion model in \n[21]) and exploiting the tradeoff between the performance im\u00adprovement and QoS loss. However, our proposal \nsigni.cantly dif\u00adfers in several aspects. Their focus was on surviving errors and faults with no mechanism \nfor guaranteeing a desired goal would be met. Theyused a very coarse granularity approach of dropping \ntasks that only seems appropriate for their domain, which was par\u00adallel programs. On the other hand, \nGreen provides support for .ner\u00adgrain approximation at the loop and function level. In addition, Greenprovidesare-calibration \nmechanismthatcaneffectivelypro\u00advide strong QoS guarantees even in the presence of some degree of inaccuracyin \nthe constructed QoS model. Finally, we experimen\u00adtally demonstrate that controlled approximation can \nbe effectivefor a wider range of application domains (i.e., not only scienti.c appli\u00adcations) including \nan in-production, real-world web-search engine. In parallelwiththiswork,Hoffmannetal. proposed SpeedPress, \na framework designed for exploiting performance/accuracytrade\u00adoffusing loop approximation [11]. In contrast \nto SpeedPress, Green also supports function approximation to target a wider range of ap\u00adplications (i.e., \nnot only iterative algorithms) and provides a uni\u00adfying framework for applying both loop and function \napproxima\u00adtions. SpeedPress only supports loop approximationbut it pursues this goal much more aggressively \nthan Green. It not only skips it\u00aderations at the end of a loop but also removes intermediate loop iterations. \nGreen is a programmer assisted framework based on the principle that carefully optimizing a small number \nof application loops and functions in a controlled manner can provide signi.cant bene.ts. On the other \nhand, SpeedPress is positioned as a compiler optimization framework that attempts to approximate as manypro\u00adgram \nloops as possible. While that is a worthwhile goal, we do not believe it is safely achievable given the \ncurrent state of pro\u00adgram analysis technology and could result in unexpected program crashes, especially \nwhen intermediate loop iterations are skipped. Sorber et al. proposed Eon, a language and runtime system \nfor low-power embedded sensor systems [23]. Using Eon, control .ows of a program may be annotated with \nabstract energy states. Then, Eon s runtime dynamically adapts the execution by adjust\u00ading the frequencyof \nperiodic tasks or providing high or low service levels by consulting the annotated energy state and the \npredicted energy availability. While Green is similar to Eon in the sense of exploiting the tradeoff \nbetween energy consumption and QoS loss and providing a dynamic runtime adaptation mechanism, our proposal \nsigni.cantly differs in three aspects. First, Greenbuilds upona probabilisticQoS modelthat enablesafastandrobust \ncon\u00advergence to a desired QoS target. Second, Green directly extends C/C++ languages to allow programmers \nto implement .ne-grained and modular approximations at loop-and function-levels and fully exploit existing \ncode optimizations implemented in C/C++ com\u00adpilers. In contrast, Eon is based on a high-level coordination \nlan\u00adguage [10] that can compose with conventional languages such as C/C++. Finally, we experimentally \ndemonstrate Green s controlled approximation mechanismis highlyeffectiveandrobustforawider range of application \ndomains (i.e., not only embedded sensor appli\u00adcations) including a commercial web-search engine. In [18], \nLiu et al. discussed the imprecise computation tech\u00adnique with which each time-critical task can produce \na usable, ap\u00adproximate resultevenin the presenceofa transientfailure orover\u00adload in real-time systems. \nIn addition, theydescribed a conceptual architectural framework that allows the integration of an imprecise \nmechanism witha traditionalfault-tolerance mechanism. Ourwork differs in the following ways. First, Green \nsupports approximation at a .ner granularity than tasks. Second, Green provides a calibra\u00adtion mechanism \nthat supports modeling sophisticated, application\u00adspeci.c error functions. In contrast, Liu et al. assumed \na rather simple, prede.ned error function such as linear or convex. Finally, we implemented and evaluated \na real (i.e., not conceptual) system to quantify the effectiveness of Green s controlled approximation \nmechanism. Several researches focused on .oating-point approximation techniques [1, 25]. Alvarez et al. \nproposed fuzzy memoization for .oating-point (FP) multimedia applications [1]. Unlike the classi\u00adcal \ninstruction memoization, fuzzy memoization associates similar inputstothe same output.Tongetal. proposeda \nbitwidthreduction technique that learns the fewest required bits in the FP representa\u00adtion for a set \nof signal processing applications to reduce the power dissipation in FP units without sacri.cing anyQoS \n[25]. While ef\u00adfective in improving performance and energy consumption of FP applications, applications \nwith infrequent use of FP operations will not bene.t from these schemes signi.cantly. In addition, they \ndo not provide any runtime re-calibration support for statistical QoS guarantees.In contrast, Greenismore \ngeneral, targetsawider range of applications (i.e., not only FP applications) and attempts to meet speci.ed \nQoS requirements. Several researches studied the impact of the soft computing properties on the error \ntolerance of systems in the presence of de\u00adfectsorfaultsinchips[6,17]. Breueretal. demonstratedthatmany \nVLSI implementations of multimedia-related algorithms are error\u00adtolerant due to the relaxed correctness. \nBased on this, they pro\u00adposed design techniques to implement more error-resilient multi\u00admedia chips [6]. \nLi andYeung investigated thefault tolerance of soft computationsby performingfault-injectionexperiments \n[17]. Theydemonstrated that soft computations are much more resilient tofaults than conventionalworkloads \ndue to the relaxed program correctness. Our work differs as it focuses on performance and en\u00adergy optimizations \nthat meetspeci.ed QoS requirements instead of fault tolerance.  6. Conclusions In this paper, we propose \nthe Green system that supports energy\u00adconscious programming using controlled approximation forexpen\u00adsive \nloops and functions. Green generates a calibration version of the program that it executes to construct \na QoS model that quanti\u00ad.es the impact of the approximation. Next, it uses this QoS model to synthesize \nan approximate version of the program that attempts to meet a user-speci.ed QoS target. Green also provides \na run\u00adtime re-calibration mechanism to adjust the approximation decision logic to meet the QoS target. \nToevaluate theeffectivenessof Green, webuilta prototype im\u00adplementation using the Phoenix compiler framework \nand applied it to four programs including a real-world search application. The experimental results demonstrate \nthat the Green version of these applications perform signi.cantly better and consume less energy with \nonly a small loss in QoS. In particular, we improved the performance and energy consumption of Bing Search \nby 21.0% and 14.0% respectively with 0.27% of QoS degradation.We also showed that the QoS models constructed \nfor these applications are robust. In conjunction with Green s runtime re-calibration mecha\u00adnism, this \nenables approximated applications to meet user-speci.ed QoS targets. Acknowledgements We would like to \nthank Preet Bawa, William Casperson, Engin Ipek, Utkarsh Jain, Benjamin Lee, Onur Mutlu, Xuehai Qian, \nGau\u00adrav Sareen, Neil Sharman, andKushagraVaid, who made contribu\u00adtions to this paper in the form of productive \ndiscussions and help with theevaluation infrastructure.Woongki Baekwas supportedby a Samsung Scholarship \nand an STMicroelectronics Stanford Grad\u00aduate Fellowship. References [1] C. Alvarez and J. Corbal. Fuzzy \nmemoization for .oating\u00adpoint multimedia applications. IEEE Trans. Comput., 54(7):922 927, 2005. [2]W.Baek,J. \nChung,C.CaoMinh,C.Kozyrakis,andK.Oluko\u00adtun. Towards soft optimization techniques for parallel cogni\u00adtive \napplications. In 19thACM Symposium onParallelism in Algorithms and Architectures. June 2007. [3] L. A. \nBarroso. Warehouse-scale computers. In USENIX AnnualTechnical Conference, 2007. [4]C.Bienia,S.Kumar,J.P.Singh,andK.Li.The \nparsec bench\u00admark suite: Characterization and architectural implications. In Proceedingsof the 17th International \nConference onParallel Architectures and CompilationTechniques, October 2008. [5]P.P. Bonissone. Soft \ncomputing:the convergenceof emerging reasoning technologies. Soft Computing A Fusion ofFoun\u00addations, \nMethodologies and Applications, 1(1):6 18, 1997. [6] M. A. Breuer, S. K. Gupta, and T. Mak. Defect and \nerror tolerance in the presence of massivenumbers of defects. IEEE Design andTestof Computers, 21(3):216 \n227, 2004. [7] E. O. Brigham. The fastFourier transform and its applica\u00adtions. Prentice-Hall, Inc., Upper \nSaddle River,NJ, USA, 1988. [8] G. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati, A. Lakshman, A. \nPilchin, S. Sivasubramanian, P. Vosshall, andW.Vogels. Dynamo: amazon shighlyavailablekey-value store. \nSIGOPS Oper. Syst. Rev., 41(6):205 220, 2007. [9] J. G. Ganssle. A Guide to Approximation. http://www. \nganssle.com/approx/approx.pdf. [10] D. Gelernter and N. Carriero. Coordination languages and their signi.cance. \nCommun.ACM, 35(2):97 107, 1992. [11] H. Hoffmann, S. Misailovic, S. Sidiroglou, A. Agarwal, and M. Rinard. \nUsing code perforation to improve performance, reduce energy consumption, and respond to failures. Tech\u00adnical \nReport MIT-CSAIL-TR-2209-037, EECS, MIT, August 2009. [12] J.T. Kajiya. The rendering equation. SIGGRAPH \nComput. Graph., 20(4):143 150, 1986. [13] R. Katz. Research directions in internet-scale computing. In \n3rd InternationalWeek on Management of Networks and Services, 2007. [14] V. Kianzad and S. S. Bhattacharyya. \nMultiprocessor clus\u00adtering for embedded systems. In Euro-Par 01: Proceed\u00adings of the 7th International \nEuro-Par Conference Manchester onParallel Processing, pages 697 701, London, UK, 2001. Springer-Verlag. \n[15] Y.-K. Kwok and I. Ahmad. Benchmarking the task graph scheduling algorithms. Parallel Processing \nSymposium, 1998. IPPS/SPDP 1998.Proceedingsof the Symposium onParallel and DistributedProcessing 1998, \npages 531 537, Mar-3 Apr 1998. [16]X.LiandD.Yeung. Exploitingsoft computingfor increased fault tolerance. \nIn In Proceedings ofWorkshop on Architec\u00adtural Support for Gigascale Integration, 2006. [17] X.Li andD.Yeung. \nApplication-level correctness and its im\u00adpact on fault tolerance. In HPCA 07: Proceedings of the 2007 \nIEEE 13th International Symposium on High Perfor\u00admance Computer Architecture, pages 181 192, Washington, \nDC, USA, 2007. IEEE Computer Society. [18] J. Liu, W.-K. Shih, K.-J. Lin, R. Bettati, and J.-Y. Chung. \nImprecise computations. Proceedings of the IEEE, 82(1):83 94, Jan 1994. [19] R. M. Metcalfe and D. R. \nBoggs. Ethernet: distributed packet switching for local computer networks. Commun. ACM, 19(7):395 404, \n1976. [20] Phoenix Academic Program. http://research. microsoft.com/Phoenix/. [21] M. Rinard. Probabilistic \naccuracy bounds for fault-tolerant computations that discard tasks. In ICS 06: Proceedings of the 20th \nannual international conference on Supercomputing, pages 324 334,NewYork,NY, USA, 2006.ACM. [22] M. C. \nRinard. Using early phase termination to eliminate load imbalances at barrier synchronization points. \nIn OOPSLA 07: Proceedings of the 22nd annual ACM SIGPLAN conference on Object-oriented programming systems \nand applications, pages 369 386,NewYork,NY, USA, 2007.ACM. [23] J. Sorber, A. Kostadinov, M. Garber, \nM. Brennan, M. D. Corner,andE.D.Berger. Eon:alanguageand runtime system for perpetual systems. In SenSys \n07: Proceedings of the 5th international conference on Embedded networked sensor systems, pages 161 174,NewYork,NY, \nUSA, 2007.ACM. [24] Standard Performance Evaluation Corporation, SPEC CPU Benchmarks. http://www.specbench.org/, \n1995 2000. [25]J.Tong,D. Nagle,andR. Rutenbar. Reducingpowerbyop\u00adtimizing the necessary precision/range \nof .oating-point arith\u00admetic. Very Large Scale Integration (VLSI) Systems, IEEE Transactions on, 8(3):273 \n286, Jun 2000.    \n\t\t\t", "proc_id": "1806596", "abstract": "<p>Energy-efficient computing is important in several systems ranging from embedded devices to large scale data centers. Several application domains offer the opportunity to tradeoff quality of service/solution (QoS) for improvements in performance and reduction in energy consumption. Programmers sometimes take advantage of such opportunities, albeit in an ad-hoc manner and often without providing any QoS guarantees.</p> <p>We propose a system called Green that provides a simple and flexible framework that allows programmers to take advantage of such approximation opportunities in a systematic manner while providing statistical QoS guarantees. Green enables programmers to approximate expensive functions and loops and operates in two phases. In the calibration phase, it builds a model of the QoS loss produced by the approximation. This model is used in the operational phase to make approximation decisions based on the QoS constraints specified by the programmer. The operational phase also includes an adaptation function that occasionally monitors the runtime behavior and changes the approximation decisions and QoS model to provide strong statistical QoS guarantees.</p> <p>To evaluate the effectiveness of Green, we implemented our system and language extensions using the Phoenix compiler framework. Our experiments using benchmarks from domains such as graphics, machine learning, signal processing, and finance, and an in-production, real-world web search engine, indicate that Green can produce significant improvements in performance and energy consumption with small and controlled QoS degradation.</p>", "authors": [{"name": "Woongki Baek", "author_profile_id": "81331488337", "affiliation": "Stanford University, Stanford, CA, USA", "person_id": "P2184547", "email_address": "", "orcid_id": ""}, {"name": "Trishul M. Chilimbi", "author_profile_id": "81100578606", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P2184548", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1806596.1806620", "year": "2010", "article_id": "1806620", "conference": "PLDI", "title": "Green: a framework for supporting energy-conscious programming using controlled approximation", "url": "http://dl.acm.org/citation.cfm?id=1806620"}