{"article_publication_date": "08-01-1997", "fulltext": "\n Systematic Realisation of Control Flow Analyses for CML Kirsten L. Solberg Gasser, Flemming Nielson, \nHanne Riis Nielson Computer Science Department, Aarhus University, Ny Munkegade, DK-8000 Aarhus C, Denmark \nElectronic mail: {kls, f n ,hrn}@daimi. aau. dk Abstract We present a methodology for the systematic \nre\u00adalisation of control flow analyses and illustrate it for Con\u00adcurrent ML. We start with an abstract \nspecijicution of the analysis that is next proved semantically sound with respect to a traditional small-step \noperational semantics; this result holds for terminating w well as non-terminating programs. The analysis \nis defined coinductively and it is shown that all programs have a least analysis result (that is indeed \nthe best one). To realise the analysis we massage the specification in three stages: (i) to explicitly \nrecord reachability of subex\u00adpressions, (ii) to be defined in a syntax-directed manner, and (iii) to \ngenerate a set of constraints that subsequently can be solved by standard techniques. We prove equivalence \nresults between the different versions of the analysis; in par\u00adticular it follows that the least solution \nto the constraints generated will be the least analysis result also to the initial specification. 1 Introduction \nMany compiler optimisation techniques rely on control flow information: for a given program point, which \nprogram points can the flow of control jump to? For imperative pro\u00adgrams without procedures this question \nmay be simple to answer but for more powerful languages, whether imperative languages with procedures, \nfunctional languages, concurrent languages, or object-oriented languages, it is much more complicated. \nIn the literature quite some effort has been devoted to the development of control flow analyses for \nfunc\u00adtional languages, seee.g. [1, 5,8,9, 10, 13, 15,18, 19,20, 21]. We believe that the overall development \nof control flow anal\u00adyses should follow the core methodology of abstract interpre\u00adtation [2, 3, 4, 11]: \n sern~pa+ ... + po,n -irnpl Given a programming language and its semantics (sern), we consider an abstract \nanalysis (pao) and show it to be seman\u00adticzdly correct. We then systematically massage the analy\u00adses \nin such a way that (i) semantic correctness is maintained, and (ii) we end up with an analysis (p%) that \nmay be iwle\u00admented efficiently (irnpl). The core methodology also opens up for the possibility of coarsening \nthe analyses (using Galois Permission to make digitrd/hard copy of part or all this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for profit or \ncommercial advan\u00adtage, the copyright notice, the title of the publication and its date appear, and notice \nis given that copying is by permission of ACM, Inc. To copy otherwise, to republish, to post on servers, \nor to redistribute to lists, requires prior specific permission and/or a fee. ICFP 97 Amsterdam, ND 8 \n1997 ACM 0-89791 -918 -1/97 /0006 ...$3.50 connections, widening operators, and narrowing operators) \nbut we are not going to explore this in the present paper. We shall illustrate the methodology by developing \na control flow analysis for Concurrent ML (CML) [17]. CML is an ex\u00adtension of the functional language \nStandard ML (SML) [12] with primitives for the dynamic creation of processes and channels and for the \nsynchronous communication of values over channels. Channels as well as functions are first class values \nand thus they can be supplied to functions as param\u00adeters, returned as results, and transmitted over \nchannels. Compared with traditional functional languages, the control flow of CML programs is further \ncomplicated by the fact that closures may be communicanted over channels and hence invoked on other \nprocesses than where they are created, and  channels may be communicated over channels and later used \nfor new communications.  The analysis we present in this paper is an extension of the traditional O-CFA \nanalyses for functional languages to the concurrency primitives of CML. Relationship to other work In \nthe literature several con\u00adtrol flow analyses have been developed for functional lan\u00adguages; some using \nthe standard syntax for such languages ad others using an intermediate language (like continuation passing \nstyle or A-normal form ) of a specific implementa\u00adtion. The analyses have been specified in different \nstyles and even if we restrict attention to those lending themselves naturally to a constraint based \nformalisation the variation is surprisingly Izge. In one end of the spectrum the spec\u00adifications are \nrather abstract: constraints are only specified implicitly and subexpressions may be analysed several \ntimes depending on the context in which they arise. In the other end of the spectrum we have analyses \nthat axe specified at a level much closer to the actual realisation: they are explicit about the generation \nof constraints and they proceed in a syntax-directed manner such that subexpressions are anal\u00adysed at \nmost once. Only very recently [13] it was pointed out that the first kind of analyses should be defined \ncoin\u00adductiuely (and not inductively) in order to make sense; the second kind of analyses are naturally \ndefined inductively. We believe the present paper is the fist to explore the formal relationship between \nthe two styles of specification. Control flow analysis of concurrent languages have only re\u00adceived rather \nlittle attention: Jagannathan and Weeks [8] study a lambda calculus extended with a spawn construct for \ncreating parallel threads that communicate via first class shared locations, and they present a O-CFA \nlike analysis with the additional twist that a 1-CFA like approach is used to distinguish processes. \nFlanagen and Felleisen [6] study a lambda calculus with a future construct for creating par\u00adallel threads \nand they present a set-based analysis [7]; the precision of the analysis corresponds to that of a O-CFA \nanal\u00adysis. Nielson and Nielson [14] study a subset of CML and present am analysis that predicts the communication \ntopol\u00adogy of programs expressed as terms in a process algebra; the analysis is presented as a type and \neffect system and is primarily concerned with the prediction of the (annotated) types of the various \nprogram fragments. Overview In Section 2 we present the syntax and semantics of a subset of CML. The \nsyntax is the standard one [17]; here we deviate from much of the literature in that we do not require \nprograms to be written in some intermediate form like A-normal form or continuation passing style. The \nsemantics is a traditional small-step operational semantics using environments [16]; this means that \nwe do not require the semantics to operate on contours or to be at the level of an abstract machine. \nThe abstmct closure analysis is specified in Section 3. It is defined coinductively as the greatest fixed \npoint of a cer\u00adtain function and specifies all acceptable analyses of the pro\u00adgrams. Obviously this includes \nthe least acceptable analysis but the present approach opens up for the possibility of hav\u00ading the implementation \ncompute a more approximate (and hence cheaper) solution; this is indeed a scenario common in abstract \ninterpretation. The correctness of the analysis is formulated as a subject re\u00adduction resulfi this is \nan approach borrowed from type the\u00adory. The correctness result is not restricted to terminating programs \nand this is important not least for concurrent lan\u00adguages where non-terminating programs (as operating \nsy~ terns) are of interest on their own. We also show that the analysis enjoys a Moore family property \n(sometimes called a model intersection property); this means that all programs can be analysed and that \nall programs have a least analysis result (which is indeed the best one). The next step towards realisation \nof the analysis is to turn it into a syntax-directed specification. To do that we first note that the \nabstract analysis may analyse the same pro\u00adgram fragments several times but (unlike type systems) it \nis only concerned with the reachable program fragments. As a first step towards the syntax-directed analysis, \nSection 4 reformulates the abstract analysis to explicitly keep track of the reachable program fragments \nalthough they may still be analysed several times. The resulting reachability closure analysis is also \ndefined as the greatest fixed point of a func\u00adtion, and a conductive proof shows that it admits the same \nanalyses as the abstract closure analysis of Section 3, and that it enjoys a Moore family property. This \nmeans that the least anrdysis result of the modified analysis also is the least analysis result of the \noriginal one and vice versa. In Section 5 we present the synta.z-direded closure analysis. It incorporates \nthe reachability aepect of the previous analy\u00adsis but in such a way that each program fragment is analysed \nat most once. Since this analysis is syntax-directed we can safely define it % the least fixed point \nof the specification as indeed it will only have one tied point. We show that the analysis results obtainable \nby the syntax-directed specifica\u00adtion also are obtainable in the reachability specification and furthermore, \nthat the least (or best) analysis result that can be obtained by the reachability specification equals \nthe one obtained by the syntax-directed specification. The syntax-directed specification can then be \nturned into a syntax-directed function C for collecting constraint. We illustrate this in Section 6 where \nwe also show that the con\u00adstraints generated have the same solutions as the syntax\u00addirected specification. \nStandard constraint solving algo\u00adrithms can now be employed to find the least solution to the constraints, \nand we briefly sketch an 0(n3 ) algorithm for this (where n is the size of the program). Composing the \ncorrectness results then yields an implementation that will compute the least analysis result with respect \nto the ab\u00adstract specification of the analysis and we know that it will be semantically correct. Finally, \nSection 7 contains the concluding remarks. The Ap\u00adpendix contains the non-trivial parts of the proofs \nof the main results of the paper but can safely be omitted; it also contains details of the constraint \nsolving technique. 2 Concurrent ML Concurrent ML is an extension of SML with concurrency primitives for \nsynchronous communication over channels. We shall be interested in the following operations: fork e creates \na new process; the expression e must eval\u00ad uate to a function expecting a unit argument and the  process \nwill execute the expression e (). channel e creates a new channel; the expression e must evaluate to \nthe value (). send el ez transmits the value of ez on the channel that e1 evaluates to (provided that \nanother process will en\u00adgage in the communication). receive e accepts a value on the channel that e evaluates \nto (provided that another process will engage in the communication). We shall consider a subset of CML \nthat additionally has explicit operators for conditions.f, recursion and local defini\u00adtions. Note that \nsend and receive take care of their own synchronisation; hence we can dispense with the sync opera\u00adtion. \nFor the presentation of our analysis it is important that we are able to label all program fragments \nand we therefore present the syntax using expressions and terms: e E Ezp (expressions, i.e. labelled \nterms) e ::= tl t c Term (terms, i.e. unlabeled expressions) t::=clx lfnz=>eolfun~ z=> eo I el e* I if \neo then el else e~ Ilet z = el in ez Ifork e Ichannel e I send el e~ I receive e 1 E Lab (labels) cE \nConst (constants) zC Var (variables) Here fn x => e is the function abstraction, fun ~ z => e is a recursive \nvariant of fn x => e where all tiee occurrences of f inerefertofun ~x=>eitself,andlet z=elinez is a non-recursive \nlocal definition that is equivalent to (fn ~ => ~z) (el ), AS Usua] we shall use parentheses to disam\u00adbiguate \nthe parsing whenever needed. Also we shall assume throughout that all occurrences of fun ~ z => e have \n~ and z to be distinct. Forsimplicity ofpresentation weshall assume that there areno functional constants; \nhowever, it would be straightforward toaddasyntactic clause like t ::= el opez foraclaas opofbinary operators \n(like addition). We shall equip this language with a small-step operational semantics using environments \nin the style proposed by Plotkin [16]. This necessitates augmenting the syntax with notation for closures \nand for local environments. We there\u00adfore define intermediate expressions andtermsm follows: ie~ IEzp \n(intermediate expressions) ie ::= itl it E ITemn (intermediate terms) it::=cl~lfn~=>eolfun~ Z=>eo I iel \niez I if ieo then el else e, Ilet z =iel in e~Ifork ie I chsmel ie I send iel iez I receive ie Ich Ibind \np in ie Iclose tin p vE Val (values) v ::=clchlclosetinp p G Env (environments) P::= [11 P[~+vl ch E \nChid (channel identifiers) The top-level semantics of the sequential subset of the language is given \nby the transition system pE ie + ie of Table 1. To overcome the restriction to top-level we shall make \nuse of evaluation contexts E: E ::= [][(E ez)l I (V l?) I (if E then e, else e~) [ (let z = E in e~) \nI (fork E)J I (channel E) I (send E ez) I (send v E) I (receive E)t 1 (bind p in l?) We have been very \ndeliberate in when to use intermediate ex\u00adpressions and when to use expressions. Since we do not eval\u00aduate \nthe body of a function before it is applied we continue to let the body be an expression rather than \nan intermedl\u00adate expression. Similar remarks apply to the branches of the conditional and the body of \nthe local definitions. Note that although an environment only records the terms fn x => eo and fun ~ \nx => eo occurring in the closures, we do not lose the identity of the function abstractions as eo will \nbe of the form t? and 10may be used to uniquely identify the func\u00adtion abstraction. In order not to lose \nthe identity of the channel identifiers we shall introduce a finitary function K : Chid + Term that specifies \nwhich occurrence of channel e that gives rise to the channel identifier. The concurrent semantics is \ngiven by the transition system K, PP -+ K , PP of Table 1. Con\u00adfigurations have the form K, PP where \nK is as above and PP is a finitary mapping from process identifiers p G PId to intermediate expressions; \nthese intermediate expressions will always be closed (having no free variables) but they may contain \nchannel identifiers that are present in the domain of K. In order to evaluate inside a bind-construct \nwe have to re\u00adconstruct the local environment. For this we use the function &#38; defined by: &#38;(p,[]) \n= p f(p, (E ez) ) = &#38;(p, E) f(p, (v E)J) = &#38;(p, E) &#38;(p, (if E then el else ez)[) = S(p, E) \n&#38;(p, (let z =E in ez)~) = E(p, E) &#38;(p, (fork E) ) = S(p, E) S(p, (channel E)i ) = &#38;(p,E) \n&#38;(p, (send E ez)*) = &#38;(p, E) &#38;(p, (send v E) ) = &#38;(p, E) Z(p, (receive E)l) = E(p, E) \n S(P, (bind pl in E)l) = S(pl, E) Remark One might have expected the rule for the fork\u00adconstruct to look \nlike: K,PP~ : E[(fork (close tin p)[ )~] + K,PP~ : .?3[() ]] ~ : (t? () ) ] ifp @ dorn(PP) U {p} However, \nwith this approach it is unclear what labels to put instead of the questions-marks. 3 Abstract Closure \nAnalysis The result of the O-CFA analysis for CML is a triple (~1 ~, ~) where ~ is the abstmct cache \nassociating an abstract value with each labelled program point; this denotes the set of values that the \nprogram point could evaluate to; b ~ is the abstmct environment associating an abstract value with each \nvaxiable; this denotes the set of values that the variable could be bound to; and  ~ is the abstract \nchannel environment which associates an abstract value with each Iabelled program point de\u00adnoting a channel; \nthis denotes the set of values that could-be transmitted over a channel created at that program point. \n This is made precise by the following definitions: Here an abstract value ~ only records a set of terms \nof form fn x =>e, fun ~z =>e, or channel () . It does not record abstract versions of the corresponding \nlocal environments as these are collapsed into the global environment ~ in O-CFA analyses; also it means \nthat the analysis will be unable to record any form of causality. So for functions we record the corresponding \nabstraction in the program aa usual and for channels we record the occurrence of channel t that gives \n (Var) p fix~+u~ifp(x)=v (fn) p 1-(fn z => e)t + (close (fn z => e) in p)l (fun) p1-(funj x=>e)~+ (close \n(fun~x=>e)inp)t (aPPfn) p 1-((close (fn x => e) in pl)~ v~ )~ + (bind pl[z * v] in e)t (app~.n) p i-((close \n(fun ~ z => e) in pl)t v ) + (bind pZ[Z + u] in e) ifpz = pl[~ * close (fun ~2 => e) in pl] (let) p 1-(let \nz = v in e) + (bind p[z I+ v] in e)i (iff) p E (if true~ then t: else t$)~ + t: (ifF) p 1-(if false~ \nthen t! else t$)~ + t~ (bind) p 1-(bind pl in Uil)1 + v~ (seq) K, PP~ : E[el]] -+ K, PP~ : E[ez]] if \n&#38;(O,E) 1-el + ez (Chan) K,PP~ : E[(channel 01 )[]] + K[ch I+ channel 01 ], PP~ : E[ch ]] ifch @ cZorn(K) \n(forkf~) K, PP~ : E[(fork (cloee (fn z => ti ) in p) J )t]] + ~,ppk : ~[()~11 ~ : (bind p[z I+ ()] in \nt ) ] f f om(pp) u p} (forkf.m) K,PP~ : ,??[(fork (close (fun j z => t ) in p)ll)l]] + ~,ppk ~[()~11 \n~ : (bind p[~ * close (fun ~ z => t ) in p][z I+ ()] in t ) ] if p @ dom(PP) U {p} ~, ppb :El[(send ch[ \nu~ )~]] -~, pp b, :E,[vJ]] (comm) ~z : E2[(receive Ch g) ]] k-n : E,[v ]] if P # P2 Table 1: Small-Step \nSemantics rise to the channel. However, t is not stable under evacuation and therefore we decide to use \nits final value () instead, We will not be recording any constants among the abstract values and we thus \nobtain a pure control flow analysis with no data flow analysis component. As previously mentioned it \nis straightforward to extend the development to record simple properties of simple data structures (like \ndetection of signs for integers); algebraic data structures requires a little more work se does the use \nof infinite sets of properties. We do not need to assume that all bound variables are distinct but clearly \ngreater precision is achieved if this is the case; parts of the development will need to assume that \nall labels are distinct (see Section 5). We shall shortly formulate the correctness of the analysis as \na eubject reduction property and this means that we will need to analyse a pool PP of processes. Each \nprocess identifier p is mapped to an intermediate expression so we will also have to specify the analysis \nfor the intermediate terms ch, close t in p, and bind p in e. The general formulation of the O-CFA analysis \nwill therefore have the form (6, ~,~) +K ie and it expresses that (~, ~, ~) is an acceptable closure \nanafy\u00adsis of the intermediatee expression ie where the channel iden\u00adtifiers are mapped to their syntactic \ncreation points by the function K. The analysis of expressions is specified in Table 2 and it is extended \nto an analysis of a process pool by (e, p,2) l=K PP m Vp c dorn(PP) : (a,;, k) *K PP(p)  The clauses \nof Table 2 contain a number of inclusions of the form lhs ~ rhs where rhs is of the form ~(l), fiz) \nor ~(l) and where lhs is of the form C(l), ~(z), ~(l), or {t}. These inclusions express how the higher-order \nentities may flow through the program: actuaf parameters flow into formal parameters, results of function \ncalls flow back to the call sites, etc. A number of clauses also contain recursive calls to the acceptability \nrelation ( FK ). The noteworthy exceptions to this pattern are the clauses (fn), (fun), and (close) that \nin\u00adTable 2: Abstract stead rely on (app) and (fork) to perform the recursive call\u00ads on all closures that \nare possibly applied. As a consequence some expressions will be analyeed more than once since they may \nbe applied at diEerent program points whereas other will not be analysed at all since they will not be \nreachable. The latter is a phenomenon common in program analysis, where there is no need to analyse unreachable \nfragments, but is different from the perspective of type inference, where even unreachable fragments \nmust be correctly typed. Closure Analysis (~K) To explain the clauses (close) and (bind) we shall first \nin\u00adtroduce the correctness relation ~K that expresses when an environment of the semantics is correctly \nmodelled by an abstract environment of the analysis: p~J(j iff VxE dom(p) ~ donz(~ : p(z) VK (~, j(~)) \n~ VK (F, q iff (Vt, p : (v= (closet in p))* (tE~A(p~K~)/1 (Vch : (w= Ch) + (K(ch) 6 ;)) These relations \nare defined mutually recursively in terms of one another. Note that in the definition of V~ the local \nen\u00advironment p is related to the global abstract environment ~ as the abstract value ~ does not contain \nan abstract envi\u00adronment. Also note that the semantic entities (values v and environments p) decrease \nin size w we perform the recursive calls ; thus a simple well-founded induction in the finite size of \nthe semantic entities suffices for showing well-definedness of these relations. Finally, we need to clarify \nthat the clauses of Table 2 in\u00addeed define a relation. The difficulty here is that the clauses for (app) \nand (fork) are not of a form that allows to de\u00ad fine (~, ~, ~) ~K ie by structural induction in the inter\u00admediate \nexpression ie. Instead we note [13] that all right hand sides are monotone in ~ and hence we can define \n(~, ~,~) ~K ie aa the greatest fixed point of the above spec\u00adification; this is often called a conductive \ndefinition. Properties of the Analysis We shall formulate semantic correctness of the analysis as a subject \nreduction result: Theorem 1 Semantic Correctnes~ If K, PP + K , PP and (C, P,;) #K PI then (~, ~,;) \n*K, PP . . Thus the analysis results obtained for the initial configura\u00adtion will also hold for all \nsubsequent configurations. Having defined the analysis in Table 2 it is natural to ask for each pro~am, \nwhether or not it admits a closure analysis and if so, whether or not there is a least (or best) closure \nanalysis. Here least is defined with respect to the partial order We shall show that the answers to both \nquestions are yes. In fact we can show that the least analysis of a program only mentions terms appeaxing \nin the program. To show these results let PP. be a finitary mapping from PId to closed expressions in \nEzp; this will be the process pool of main interest throughout the rest of the paper. Let Lab* ~ Lab \nbe the finite set of labels occurring in the range of PP.; let Var. ~ Var be the finite set of variables \noccurring in the range of PP.; let Term. ~ Term be the finite set of subterms occurrin in the range of \nPP. together with ? all terms channel () such that some channel tt occurs in the range of PP.; and let \nEzp* ~ Exp be the finite set of subexpressions occurring in the range of PP.. Now define (C-T, ~, ~T) \nby: Note that the claim (&#38;, ~, ~) ~ (C~, p:, ts~) is for all if x fl Var. J(x) = { :em* if x E Var. \n2(1) = { 0 Term. if 1 @ Lab. if 1 E Lab.  practical purposes equivalent to the claim (~, ~, ~) E C~e. \nx E=. x K%v. where C~e. = Lab. + %., E%. = Var. + %., K~v. = Lab. -+ ~. and~. = P( Term.). Thus the condition \n(~, ~, ;) G (C~T, ~, ~) expresses that only terms occurring in PP. are present in the range of 8, ~ and \n~. Theorem 2 Moore Family Property Both of the sets {(~, 6, ~) I (~, ~, ~) ~K PP. } and {(~, ~, ~) ~ \n(C~T,=, ~) I(C, ~, ~) ~~ PP.} are Moore families and are independent of K; their greatest elements - \nare (N. Term, kc. Term, Al. Term) and (C:, p~, ~?), respec\u00adtively; also they have the same least element. \n. This result shows that for the purpose of finding (least) solu\u00ad tions it suffices to restrict (8, ~, \n~) E C~he x E~v x K~v . to(~, ~,~) c Cache. x E=. x K~v.. To remind us of this we shall allow to write \n(~, ~, ~) ~ . and from now on we shall assume that (~, ~, ~) is restricted in this manner. One can prove \nthat the Moore family property would fail to hold for an inductive rather than conductive detlnition \nof +K 4 Reachability The aim now is to massage the specification of the analysis of the previous section \nso as to make it amenable for efficient implementation. It follows that we are no longer interested in \nthe analysis of intermediate expressions; these were only necessary for establishing the semantic correctness \nresult. Henceforth we will need no counterpzuts of the clauses (ch), (close) and (bind) in Table 2 and \ntherefore we can dispense with the K-component. We will be aiming for a syntax-directed procedure for \ncol\u00adlecting constraints such that only expressions that are reachable will actually be analysed, and \nthe same expression is analysed at most once. We shall proceed in three stages: First we modify the \nanal\u00adysis of Table 2 to track the reachability of subexpressions explicitly (Section 4), then we modify \nit such that subexpres\u00adsions are analysed at most once (Section 5), and finally we introduce the syntax-directed \nprocedure for collecting con\u00adstraints (Section 6). We shall extend the analysis of Table 2 to track the \nreacha\u00adbility of the subexpressions explicitly. To this end we define The idea is that if ~(l) = o then \nthe program point 1 is not reachable and hence the corresponding expression will not be analysed. For \nthis to work (in Section 5) we shafl demand that all expressions in PP. are uniquely labelled (but we \nstill do not demand that variables are unique). Table 3: Reachability The judgments of the previous \nanalysis are now extended to additionally determine the reachability component: The modtied clauses are \ngiven in Table 3. The idea is here that 1c Lab is the program point of intereat ; if this pro\u00adgram point \nis reachable according to E then we have condi\u00adtions on the flow of values similar to those of the previous \nanalysis. The program point of intcrest is changed when\u00adever we need to analyse au expression that is \nnot guaran\u00adteed to be a proper subexpression of the current expression, Closure Analysis (#t) i.e. when \nwe start analysing the body of a fimction in a func\u00adtion application or in the fork-construct. It is \nimportant to note that for the recursive functions we introduce the condition (on E ~(10) = (fun \\ z \n=> t$) E F(f)) refiectirw that the recursive cdl only will happen if the body of the function is to be \nanalysed. An @terna\u00adtive would have been to replace it with (on c R(t) * (fun ~ z => t$ ) E ~(f)); while \nthis is correct , it turns out to be less usable for obtaining the syntax-directed spec\u00adificat ion. The \nanalysis is extended to process pools as follows: 6 Constraint Formulation It is useful to define 0 if \n1 @ Lab. R~(~) = { {on} if 1 E Lab. as we then have Theorem 3 Preservation of Solutions If (~, ~, ~) \nl=fi PP. then (R-:, ~, ~, ~) ~ PP.. If (fi, ~, ~,;) + PP. then (~, ~, ~) +2 PP.. Here PP. is as above \nand K is arbitrary. 1 In analogy with Theorem 2 we get that also {(i, e, F,R) [(R, 8, ~,2) +* PP.} \nis a Moore family so in particular the least analysis result obtained using Table 3 will correspond to \nthe least analysis result obtained using Table 2 and vice versa. Syntax-Directed Specification We shall \nnow reformulate the specification of the closure analysis in Table 3 such that all subexpressions are \nanal\u00adysed at most once. So the aim will be to use the explicit reachability information to guide when \nthe body of function abstractions have to be analysed and then to proceed in a syntax-directed manner. \nThe judgments have the form much as in the previous section and the clauses are given in Table 4. Note \nthat the the two function abstractions give rise to recursive calls of the aaalysis and that the clauses \nfor function application and process creation only contain recursive calls for proper subexpressions. \nConsequently the recursive definition of ~~ has precisely one solution. The component ~ controls whether \nor not to impose the appropriate inclusions between the flow information. The analysis is extended to \nprocess pools as follows: The following result says that the analysis of Table 4 admits the same results \nas that of Table 3: Theorem 4 Preservation of Solutions Suppose that all labels of PP. are unique. If \n(~, ~, ~, ~) ~; PP. then (fi, 6, ~, ~) ~ PP.. If(R, ~, ~,~) is least such that (fi, d, ~, ~) + PP. then \n(E, ~, ~, ~) F1 PP.. . Technically, this is the hardest of the theorems to prove, because Tables 3 and \n4 have different perspectives upon what is global and what is local ; see the Appendix for details. Intuitively, \nit is the Ieastness of the R component that is essential. We are now ready to consider efficient ways \nof finding the least solution (E, 6, ~, ~) such that (R, ~, j, ~) l=: PP.. To do so we first construct \na finite set C. [PP. ] of constraints of the forms {u} c rhs (1) {UI} ~ rhsl + lhs ~ rhs (2) {u1} G rhsl \n+ {IW} ~ rhsz -lhs ~ rhs (3) where rhs is of the form R(l), ~(l), j(z) or k(1); lhs is of the form ~(l), \n~(z), ii(l), or {u}; and u is of the form on or t. All occurrences oft are oftheformfn z=>e,fun ~x=>e \nor channel () ~. The constraints are obtained by expanding (~, ~, ~, ~) ~~ PP. into a finite set of constraints \nof the above form and then let C. [PP.] be the set of indhidual conjuncts; at the same time we change \nall occurrences of - into . ~. to avoid confusion: so ~(l) will be a set of terms whereas ~(l) is a formal \nsymbol and similarly for ~(x) and ~(z), ~(t) and %(1), and @ and fi(l). More precisely the definition \nof C. [PP.] is given by C*[PP.] = U{C:[tl] U {{on} ~ R(l)} IP C dom(PP.) A PP.(P) = t } where C: [tt]is \ngiven in Table 5. It makes use of the set Term. of subterms in order to generate only a finite number \nof constraints. If the size of PP. is n then it might seem that there could be 0(n2) constraints of form \n(l), 0(n4) constraints of form (2) and 0(n6) constraints of form (3). However, inspection of the definitions \nof C: [ti]and C*[PP. ] shows that there will be at most O(n) constraints of form (1) and (2) and O(n \n) constraints of form (3). It is important to stress that while (~, ~, ~, ~) ~. PP. is a logicaJ formula, \nC. [PP.] is a set of formal symbols. We can turn the latter into a logical formula by first translating \nthe . ~. symbols into the sets - : (i, e, p, ;)[{t}] = {t} (E, ~, ~, ;)[{on}] = @} (R, 6, ~, R)[R(J)] \n= g(l) (i, e, p, R)[e(l)] = c(l) (ii, 5, p, R)[p(z)] = p(z) (ii, e,&#38; R)[k(l)] = ;(1) Next we Mine \na satisfaction relation (E, ~, ~, ~) ~. ~. ~on constraints: (F, ~, ~, Z) KC (ihs G rhs) ii7 (~, ~, ~, \nZ)[lhs] ~ (R, ~, ~, =)[rhs] (R, ~, ~, ;) +C ((lhsl ~ rhsl) * (UW ~ rhs)) fi ((E, ~, ~, Z) += (Uwl ~ rhsl) \n+ (R, ~, ~, R) ~= (ihs ~ rhs)) (i, ~, ~, ;) 1==((lhsl ~ rhsl) + (Ihsz ~ rhsz) + (lhs ~ rhs)) iff ((R, \n5, ~, ~) ~c (Uwl ~ rhsl) A(R, ~, ~,;) ~. (lhs2 c rhSz) + (R, ~, ~, Z) +C (Ihs ~ rhs)) Table 4: Syntax-Directed \nAnalysis (~~) Thk definition can be lifted to sets of constraints by: It follows that the least solution \n(2, G, p, R) to (R, e, p,2) +: PP. equals the least solution to (fi,~,~,=)l=c Ciff VCGC:(fi, ~, fi, R)+c \nC (R, e, p,i) +: C*[PP.]. We can then show that Tables 4 and 5 have the same solu\u00adtions: Solving the \nConstraints Theorem 5 Preservation of Solutions The constraints generated by C. [PP.] can be solved \nusing (fi, ~, ~, ~) ~~ PP. if and only if (~, ~, ~, ~) ~~ standard techniques. One possibility is to \nuse a graph for-C.[PP.]. 1 mulation of the constraints. The graph will have nodes R(i), Table5: Constraint \nGeneration (C~) 6(I), ~(z) and R(l) forl c Lab, andz c Var.. Associated D[qz]. We make certain only to \ntraverse an edge from ql with each node q we have a data field D[q] that initially is to qz when D[ql] \nis extended with a term not previously given by there. Furthermore, an edge decorated with a constraint \nD[g]= {u I({u} c g) c C*[PP.]} {u} ~ q* ql Gqz is only t~aversed if in fact u E D[q], and similarly an \nedge decorated with a constraint {u} ~ q~ The graph will have edges for a subset of the constraints in \n{u } ~q * ql~qz is only traversed if u E D[q] as well C. [PP.]; each edge will be decorated with the \nconstraint as u E D[q ]. For a node q the data field D[q] is a value in that gives rise to it: 7( Term.) \nso it can be increased at most O(n) times. Since we make sure only to traverse an edge when a new term \ncam a constraint ql ~ qz gives rise to an edge from ql to q2, be added this gives am overall bound of \n0(n3) for solving the constraints, which is the best result known for O-CFA a constraint {u} c q* ql \nGqz gives rise to an edge analysis. Further details of the algorithm may be found in from ql to qz and \nan edge from q to qz, and the Appendix. a constraint {u} ~ q* {u } Cq + ql Gq2 gives rise to an edge \nfrom ql to q2, an edge from q to q2 and an 7 Conclusion edge from q to qz. We have shown how the core \nmethodology of abstract inter- Thus the resulting graph has O(n) nodes and at most 0(n2) pretation can \nbe adapted to the specification of control flow analyses. The starting point haa been an abstract specifi-Having \nconstructed the graph we now traverse all edges in edges. cation of a O-CFA analysis for CML that is \nproved seman\u00adorder to propagate information horn one D[ql] to another tically correct, and by gradually \nmassaging it we arrive at a syntax-directed procedure for collecting constraints that subsequently can \nbe solved by standard techniques, The various stages of the process have been proved correct; in several \ncases it was necessary to perform fairly complicated proofs by conduction. The reason for this complication \nis that the initial analysis has to be specified as a greatest fixed point in order to enjoy the Moore \nfamily property, whereas the resulting syntax-directed analysis is naturally defined as a lezst fixed \npoint. The O-CFA analysis is indeed a rather simple analysis in that it does not dktinguish between the \nvarious occurrences of program points and variables and hence it captures no aspects of causality. However, \nwe conjecture that parts of the overall methodology can be applied to more sophisticated control flow \nanalyses [13]. Acknowledgements This work is partly funded by LOMAPS (ESPRIT BRA Project) and DART (Danish \nNatural Science Research Council Project). The final version of this paper benefited from discussions \nwith Torben Amtoft. Appendix This appendix is somewhat technical and may be skipped on a first reading. \nProof of Theorem 1 Lemma 6 If (~, j, i) ~K E[iel] then we also have that (~, F, Z) #K iel. . The proofs \nare by straightforward induction on the evalua\u00adtion context. Lemma S Ifp . it> + it~then 11= lz. . The \nproof is by a straightforward inspection of the inference. Proposition 9 If &#38;(@, E) 1-iel + iez and \n(~, j,;) ~K l?[iel] then (~, j, ~) ~K E[iez]. . Proof First we show that if p 1-iel -+ iez, (~, ~, ~) \n*K iel aud p RK ~ then (~, ~, ;) #K iez by inspection of the inference p 1-tel + iez. Next we establish \nthat if (e, ~, ~) *K E[ae] then E(O,E) ~K ~bya stm@t\u00adforward induction on the evaluation context, E. \nNow the Proposition follows from the above and Lemmas 6, 7 and 8. Theorem 1 Semantic Correctness- If \nK, PP + K , PP and (C, ~, ~) #K PP then (~, ~,~) +KJ PP . . Proof The proof is by case analysis on \nthe semantics: for the case (seq) we use Proposition 9 and for the remaining cases we use Lemmas 6 and \n7. Proof of Theorem 2 Proposition 10 Both of the sets fl~, ~, X) [ (~, j,;) &#38;K e} and {(~, j, ;) \n~ (C?, ~, ~) (~, ~,;) *K e} are Moore families for all e Exp, and are independent of K; their greatest \nelements are (N.2 erm, Xc. Term, M. Term) and (ET, fi, ~~), respec\u00adtively; also they have the same least \nelement. 1 Proof A straightforward application of conduction. Theorem 2 Moore F:mily Property Both of \nthe sets {(C, ~, k) I (~, ~, ~) ~K PP, } and {(~, ~, ~) Q (C~T,~, ~~) ] (~, j, ~) +K PP. } are Moore \nfamilies and are independent of K; their greatest elements - are (N. Term, Ax. Term, Al. Term) and (C~, \np:, ~:), respec\u00adtively; also they have the same least element. . Proof Immediate by Proposition 10. Proof \nof Theorem 3 Proposition 11 For all expressions e c Exp* and all la\u00ad bels 16 Lab.: if (~, ~, ~) +2 e \nthen (R-:,@, ~, k) +*Z e; and if (~, ~, ~, ~) ~ f e and on E E(t) then (~, ~, ~) ~fi e. 1 Proof For the \nfirst result we proceed as follows. First write where the relation +; is defined in Table 2 and the relation \n+*I is defined in Table 3. Then note that these tables define monotonic functions Fz and Fs such that \n~j = 9jjr(F2) and S: = gfi(Fs). Next we prove by inspection of all clauses. Finally ~~ ~ ~~ follows by \nconduction. For the second result we write where again ~~ = gfi (F2) and +; = gjp (F3) for monotonic \nfunctions F2 and F3 given by Tables 2 and 3. Next we prove by inspection of all clauses. This shows l=; \nn ON~ Fz (~~ n ON)and hence ~~ (l ON~ l=; follows by conduction. Theorem 3 Preservation of Solutions \nIf (8, j, ~) l=; PP. then (R-:, ~, ~,~) ~ PP.. If (fi, ~, ~, ~) ~ PP. then (~, ~, ~) ~~ PP.. Here PP. \nis as above and K is arbitrary. . Proof Immediate by Proposition 11. Proof of Theorem 4 must be empty. \nSince + ~ F 3(~ ) ~ F3(~ ) there are Proof The result is immediate from the syntax-directed na\u00adture of \nTable 4 and the construction of Term.. Lemma 13 Suppose that all labels of PP. are unique. If (E, ~, \n~, ~) is least such that (E, ~, ~, ~) ~ PP. then (i) (fn z => i!$) E Term. ensures (fi, ~, ~,;) l= l \nt$,and (ii) (fun f z => t$) E Term. ensures (fi, ~, ~, F) ~ l t~ andon~F(1o)= (funfx=> t$)E ~(f). c1 \nProof Sketch Let L be the set of thos~lo E Lab. violating the above. If some 10 E L has on E R(10) we \nproceed as follows. Let E = ~[10 +) 0] and note that by construction of (fi, ~, ~,@ wehave (R , ~, ~,;) \n~ PP.. Since ~ is defined coinductively (or to be precise: each ~ t is) this means that ~ is defined \ninductively (or to be precise: each +*Z is). There must be some PP.(p)= t such that a fmitary unfolding \nof the clauses for (E , e, ~, ~) ~ $ shows that (fi , ~, j, ~) is not a solution (because 1# 10thanks \nto the uniqueness of labels). Inspection of the defining clauses of + in Table 3 show that thisAmust \noccur in ~pp) or (fork) because of a condition on ~ R (l ) * on E R (10); in other words on 6 fi (1 ) \nbut on f? ~ (lo). In the analogous unfolding of (F, ~, ~, ~) ~ ~ t~ the con\u00addition on E fi(l ) -on c \nfi(lo) no longer is offending and inspection of (app) and (fork) ensures that one of is established as \nrequired depending on whether (fn x > t~)ETerm. or(funj z =>t$)E Term. (using again that labels are \nunique) and hence 10 @ C. Thk shows that all 10~ L have R(1o) = 0. ((ii,e, j, 2) ** O ty ) v ((fnz => \nt$)G Term. Aio E L A t? is an exposed subexpression of t$ ) v ((funfz => t~)~ Term. AIOEL A ty is an \nexposed subexpression of t$ ) where an exposed subexpression is one that is not occurring inthebody \nofanyfn x =>. ..orfun f x => int$. We now want to show that ~ ~ F 3(~ ) where Fs is the monotonic function \ndefined by Table 3 such that l= = gfp(Fs); conduction then gives # ~ l= showing that L only two c~es \nto consider. The first case is where (f n z => t$) E Term., 10 E C, and ty is an exposed subexpression \nof i$,and where we .. must establish (R, C, ~, ~) FS(~ )JO t?. We prove this by inspection of the clauses \nof T~ble 3. Since fi(lo) = 0 all conditions of the form (on E R(lo) + ...) are immedi- A. ate; also all \n(R, C, F, ~) + 0 t$ that are not inside the scope of a universal quantifier are immediate by the con\u00adstruction \nof ~ ; finally we are left with considering the bod\u00adies of the universal quantifiers appearing in rules \n(app) and (fork). Here the universal quantifier ranges over some (fn X2 => t~) E Term. or (fun f2 X2 \n=> tf)E Term. and we must prove (~, ~, ~, ~) ~ ~z t$and possible also on E ~(lz) =+ (fun fz X2+ t;) E \nF(fz); if (~, ~, ~, k) +*Z2 tf then the first claim is immediate and otherwise 12 c L in which case the \nfirst claim follows from construction of ~ ; the sec\u00ad ond claim is immediate unless on E ~(lz) in which \ncase 12 $! L and hence the desired result follows from construction of . L. The second case is where \n(fun fzzz =>tf)c Term. and is similar. Theorem 4 Preservation of Solutions Suppose that all labels of \nPP. are unique. If (~, ~, ~, ~) ~: PP. then (E, ~, ~, k) ~ PP.. If(fi, ~, ~,~) is least such that (fi, \n~, 3, ~) ~ PP. then (~, ~, ~, ~) l=: PP.. . Proof We write ~~ = gfp(Fs) for l= and ~~ = gfi(Fq) for ~j. \nFor the first result we prove as conduction then gives ~~ ~ ~~ ss desired. To prove (4) we simply inspect \nthe clauses; most clauses are straight\u00adforward except for (app) and (fork) where we make use of Lemma \n12. For the second result we prove as conduction then gives ~~ ~ +; as desired. To prove (5) we simply \ninspect the clauses; moat clauses are straight\u00adforward except for (fn) and (fun) where we make use of \nLemma 13. Proof of Theorem 5 Proof A simple structural induction on e shows that for all e C Ezp*. Theorem \n5 Preservation of Solutions (fi, 6, ~, ~) l=; PP. if and only if (R, d, ~, ~) ~~ C*[PP.]. . Proof Immediate \nby Proposition 14. INPUT: c.~PP*] OUTPUT: (fi, ~, ~,fi) METHOD: Step 1: Initialisation W := nil; for \nq in Nodes do D[q] := 0; for q in Nodes do E[q] := nil; Step 2: Building the graph for c in C*[PP.] do \ncase c of {u} ~ q: add(q,{u}); ql c qz: E[ql] := cons(c,E[ql]); {n, }gq; +... + {Uk} Cqj +ql c qz: \nE[ql] := cons(c,E[ql]); E[q{] := cons(c,E[q~]); . . . E[q~] := conS(C,E[qj]); Step 3: Iteration while \nW # nil do q := head(W); W := tail(W); for c in E[q] do  case c of ql ~qq: add(q2, D[ql]); c D[q(] A. \n~.~ ~k E D[q~] then add(qz, D[gI]); Step 4: Recording the solution for 1 in Lab. do ~(l) := D[fi(i)]; \nfor 1 in Lab. do C(l) := D[~(l)]; for z in Var. do ~(z) := DE(z)]; for 1 in Lab. do ~(l) := D[k(l)]; \n USING: procedure add(q,d) is if -I (d ~ D[q]) then D[q] := D[q] U d; W := cons(q,W);  Table 6: Algorithm \nfor Solving Constraints. Constraint Solving The following result shows that the algorithm does indeed \ncompute the solution we want: For completeness we present an abstract algorithm for solv\u00ading constraints. \nIt operates on the main data structures Proposition 15 Given input C. [PP. ] the algorithm of Table 6 \nterminates a worklist W that is a list of nodes whose outgoing edges and the result (~, ~, ~, ~) produced \nby the algorithm satis\u00ad should be traversed; fies  (fi,~,fi,~) = n{(~l,~l,~ll~l) I . an array D that \nfor each node gives an element of Val.; and (R,, c,, ~l,21) += c*[PP*~} and hence is the least solution \nto C. [PP.]. . nodes. Proof It is immediate that Steps 1, 2 and 4 terminate, and this leaves us with \nStep 3. It is immediate that the values of . an array E that for ech node gives a list of the successor \n The set Nodes contains R(l), ~(l), and ii(l) for all 1 in Lab. D[q] never decrease and that they can \nbe increased at most and j(z) for all x in Var.. a finite number of times. It is also immediate that \na node The first step of the algorithm is to suitable initialise the is added to the work list only if \nsome value of D[q] actually data structures. The second step is to build the graph and increased. To \neach node placed on the work list only a finite to perform the initial assignments to the data fields. \nThis is amount of calculation (bounded by the number of outgoing established using the procedure add(p,d) \nthat incorporates d edges) needs to be performed in order to remove the node into D[p] and adds p to \nthe work list if d was not part of D[p]. from the work list. This guarantees termination. The third step \nis to continue propagating contributions along edges as long as the work list is non-empty. The fourth \nand Next let (El, 61, ~1,~1) be a solution to (RI, 81, ~1,:1 ) ~~ final step is to record the solution \nin a more familiar form. C. [PP.]. It is possible to show that the following invariant is maintained \nal zdl points after Step 1. It follows that (E, @, ~, Z) ~ (Rl, @l, ~1, Z, ) upon completion of the algo\u00adrithm. \nWe prove that (R, 6, ~, ~) +. C. [PP.] by contradiction. So suppose there exists c c C. [PP. ] such that \n(fi, ~, ~, ~) KC c does not hold. If c is {u} ~ q then Step 2 ensures that {u} G D[q] and this is maintained \nthroughout the algorithm; hence c cannot have this form. If c is ql ~qz it must be the case that the \ntinal value of D satisfies D[ql] # 0 since otherwise (E, @, ~, ~) ~. c would hold; now consider the last \ntime D[ql] was modified and note that ql was placed on the work list at that time (by the procedure add); \nsince the final work list is empty we must have considered the constraint c (which is in E[ql]) and updated \nD[qz] accordingly; hence c cannot have this form. Ifcis {UI} ~ q; -..{Uk} ~q~ =ql ~q2 it must be the \ncase that the finaf value of D satisfies D[q~] +0,., D[q~] # 0 and D[ql] # 0; now consider the last time \none of D[qj], . . .. D[q~] and D[ql] was modified and note that 9;> > qj, or ql was placed on the work \nlist at that time; since the final work list is empty we must have considered the constraint c and updated \nD[qz] accordingly; hence c cannot have this form. We have now shown that (E, ~, ~, ~) KC C. [PP.] and \nthat (~, ~,~,~) G (fil, ~,, j,, i,) whenever (fi,,el,~l,%) += c*~PP.]. It now follows that (~,~,~,~) \n= fl{(fil,cl,~l,~l) I (fil!~l,~l!~l) +. C*[PP,]} as required. References [1] J.M. Ashley. A practical \nand flexible flow analysis for higher-order languages. In Proc. 23th POPL, pages 184-195. ACM Press, \n1996. [2] P. Cousot and R. Cousot. Abstract Interpretation: a unified lattice model for static analysis \nof programs by construction or approximation of fixpoints. In Proc. ~th POPL, pages 238-252. ACM Press, \n1977. [3] P. Cousot and R. Cousot. Systematic design of program analysis frameworks. In Proc. 6th POPL, \npages 269\u00ad 282. ACM Press, 1979. [4] P. Cousot and R. Cousot. Formal language, grammar aud set-constraint-based \nprogram analysis by abstract interpretation. In Proc. FPCA 95, pages 170-181. ACM Press, 1995. [5] K.-F. \nFamfm.Optimizing lazy functional programs using flow inference. In Proc. SAS 95, pages 136-153. SLNCS \n983, 1995. [6] C. Flanagan and M. Felleisen. The semantics of Future and its use in program optimization. \nIn Proc. POPL. ACM Press, 1995. [7] N. Heintze. Set-based analysis of ML programs. In Proc. Lisp and \nFunctional Progmmming. ACM Press, 1994. [8] S. Jagannathan and S. Weeks. Analysing stores and ref\u00aderences \nin a parallel symbolic language. In Proc. Lisp and Functional Programming. ACM Press, 1994. [9] S. Jagannathan \nand S. Weeks. A unified treatment of flow analysis in higher-order languages. In Proc. POPL 95. ACM Press, \n1995. [10] S. Jagannathan and A. Wright. Effective flow analysis for avoiding run-time checks. In Proc. \nSAS 95, pages 207-224. SLNCS 983, 1995. [11] N.D. Jones and F. Nielson. Abstract Interpretation: a semantics-based \ntool for program analysis. In Handbook of Logic in Computer Science vol. 4. Oxford University Press, \n1995. [12] R. Milner, M. Tofte and R. Harper. The Definition of Standard ML. The MIT Press, Cambridge, \nMass, 1990. [13] F. Nielson and H.R. Nielson. Infidary Control Flow Analysis: a Collecting Semantics \nfor Closure Analysis. Proc. POPL, pages 332-345, 1997. [14] H.R. Nielson and F. Nielson. Higher-order \nconcurrent programs with finite communication topology. In Proc. POPL 94, pages 84-97. ACM Press, 1994. \n[15] J. Palsberg. Closure analysis in constraint form. ACM TOPLAS, 17 (1):47+2, 1995. [16] G.D. Plotkin. \nA structural approach to operational se\u00admantics. Technical Report FN-19, DAIMI, Aarhus Uni\u00adversity, Denmark, \n1981. [17] J.H. Reppy. Concurrent ML: Design, application and semantics. In Proc. l%nctional progmmming, \nConcur\u00adrency, Simulation and Automated Reasoning, pages 165-198. SLNCS 693, 1993. [18] P. Sestoft. Analysis \nand efjlcient implementation of functional programs. Ph.D.-thesis, Department of Com\u00adputer Science, University \nof Copenhagen, Denmark, 1991. [19] 0. Shivers. Control flow analysis in Scheme. In F t-oc. PLDI 88, pages \n164-174. ACM Sigplan Notices 7 (l), 1988. [20] 0. Shivers. The semantics of Scheme control-flow anal\u00adysis. \nIn Partial Evaluation and Semantics-Based Pro\u00adgram Manipulation. ACM SIGPLAN Notices 26 (9), 1991. [21] \nM. Wand and P. Steckler. Selective and lightweight closure conversion. In Proc. POPL 94, pages 435445. \nACM Press, 1994.  \n\t\t\t", "proc_id": "258948", "abstract": "We present a methodology for the systematic realisation of control flow analyses and illustrate it for Concurrent ML. We start with an abstract <i>specification</i> of the analysis that is next proved semantically sound with respect to a traditional small-step operational semantics; this result holds for terminating w well as non-terminating programs. The analysis is defined coinductively and it is shown that all programs have a least analysis result (that is indeed the best one). To realise the analysis we massage the specification in three stages: (i) to explicitly record reachability of subexpressions, (ii) to be defined in a syntax-directed manner, and (iii) to generate a set of constraints that subsequently can be solved by standard techniques. We prove equivalence results between the different versions of the analysis; in particular it follows that the least solution to the constraints generated will be the least analysis result also to the initial specification.", "authors": [{"name": "Kirsten L. Solberg Gasser", "author_profile_id": "81100270549", "affiliation": "Computer Science Department, Aarhus University, Ny Munkegade, DK-8000 Aarhus C, Denmark", "person_id": "P161979", "email_address": "", "orcid_id": ""}, {"name": "Flemming Nielson", "author_profile_id": "81100316685", "affiliation": "Computer Science Department, Aarhus University, Ny Munkegade, DK-8000 Aarhus C, Denmark", "person_id": "P84491", "email_address": "", "orcid_id": ""}, {"name": "Hanne Riis Nielson", "author_profile_id": "81100316576", "affiliation": "", "person_id": "PP43118881", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258948.258954", "year": "1997", "article_id": "258954", "conference": "ICFP", "title": "Systematic realisation of control flow analyses for CML", "url": "http://dl.acm.org/citation.cfm?id=258954"}