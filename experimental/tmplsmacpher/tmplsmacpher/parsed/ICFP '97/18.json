{"article_publication_date": "08-01-1997", "fulltext": "\n Koji Kagawa Department of Information Science Kagawa University 2-1 Saiwai-cho Takamatsu 760, Japan \nE-mail: kagawa@ec.kagawa-u .ac.jp Abstract We introduce the notion of compositional references into \nthe framework of monadic functional programming and propose a set of new primitives baaed on this notion. \nThey enable us to use a wide range of mutable data structures. There, references may be passed around \nexplicitly, or mutable data str-uct.uressuch as arrays and tuples may be passed implicitly N hidden state. \nThe former style is called the ezphcit style mti is usually more expressive, while the latter is called \nthe imphcit style and has simpler semantics. We investigate the relation between the two styles and discus \nimplementation Issues. 1 Introduction Many proposals have been made toward a safe integration of a purely, \nlazy functional language with in-place updatable state [.3, 1, etc.], In a series of proposals [16, 1I], \nthe notion of monads [7] provides A basis for such an integration. Based on monads, Launchbury and Peyton \nJones [5] pro\u00adposed a way to express computations which deal with multi\u00adple mutable objects by providing \nprimitives for ML-like ref\u00aderences, and at the same time to securely encapsulate such computations by \nusing rank-? polymorphism. Such refer\u00admces are passed explicitly in statefull programs, On the other \nhand, m Wadler s former proposal [16], ~ata structures such as arrays are used directly as state and \npassed implicitly. No explicit reference is passed around. We will refer to, in what follows, Wadler \ns style, implicit style rmd Launchbury and Peyton Jones s style, ezplicit style. Each style has its merits \nand demerits: . The implicit style has a simpler functional account. We do not need ttle notion of global \nstates in order to explain the behaviour of programs. . The explicit style enables us to write stateful \nprograms in a traditional imperative fashion, In addition, it is, in general, more expressive.  1Followlng \n[5], we use tlie term stateful to refer to computations m which we would like to dea! with state destructively. \nPermission to make digital/hard copy of parl or all this work for personal or classroom use is granted \nwithout fee provided that copies are not made or distributed for profit or commercial advan\u00adtage, the \ncopyright notice, the title of the publication and its date appear, and notice is given that copying \nis by permission of ACM, Inc. To copy otherwise, to republish, to post on servers, or 10 redistribute \nto Iiats, requires prior specific permission and/or a fee. ICFP 97 Amsterdam, ND ~ 1997 ACM 0-89791 -918 \n-1/97 /0006 . ..$3.50 Having simpler types is sometimes advantageous in exprea\u00adsivenees. As we will see \nlater, Launchbury and Peyton Jones s approach requires all state transformers to be polymorphic with \nrespect to the state parameter in order to confine ref\u00aderences. This prevents state transformers from \nbeing used as function parameters in languages based on the Damaa-Milner type system. In general, however, \nthe implicit style is less expressive. First of all, it is impossible to deal with multiple mutable objects \nin Wadler s original proposal. And even if it is possible, it seems at least difficult to express mutable \ngraph structures without introducing a mechanism equivalent to references. Therefore, it would be desirable \nto enjoy merits of both styles in a single program. So far, how\u00adever, there has been no proposal which \nmakes such mixed style possible. In this paper, we will propose a set of new primitives into the monadic \nstyle of functional programming in order to extend both styles and to make it possible for us to enjoy \nmerits of the two styles. As a result, we will be able to write state transformers more concisely and \nto use a wide range of mutable data structures. We introduce the notion of cotnpositionai references \naa a key mechanism. The idea of compositional references is as follows. In\u00adstead of introducing mutable \ndata types aa new data types independent of existing immutable ones, we introduce a mu\u00adtability wrapper \nHutable aa a type constructor so that when Array a is the type of ordinary (immutable) arrays, Mutable \ne (Array a) is the type of mutable arrays with state parameter s. We will call such mutable data struc\u00adtures \ncompositional references. We also provide some aaao\u00adciated operators to combine such compositional references \nwith state transformers. Instead of introducing compositional references as an ad\u00adhoc extension, we will \ngive functional account of the type constructor and associated operators. Compositional Refer\u00adences are \nessentially ezpansion morphisms in the category of state shapes [13, 9], which were introduced in order \nto explain block strut tures of Algol-like languages. Pierce and Turner [12] and Hofmann and Pierce [2] \nalso used the same mechanism in order to explain inheritance and subtyping in object-oriented programs. \nUsing functional account, we can reason about the behaviour of stateful programs aa ordinary functions. \nThe rest of the paper is organized as follows. In Sec\u00adtion 2, we explain monadic functional programming \nand its two styles more in depth, Then, in Section 3, we introduce In the earlier version which appeared \nin SIPL 95 [4], they were called cornposab(e references andNstsbl* below was written as CE. 217 :ome \nItmv Jwimit ives anti t he not iml of compo.stl! onal re,~er\u00adtcnce.s. in Section 4, we formulate the \nrelation I]et ween the two styles. Then, Sect ion .:) discusses implementation issues. +x-tion 6 concludes. \nWC will use the syntax of Haskell [1 O] Imthe following. 2 Previous Work [n this section, we explain \nprevious work on monadic func\u00ad~ional programming and describe the difference between Wadler s style and \nLaunchbury and Peyton Jones s style. 2.1 Implicit style It has been shown that monads provide a uniform \nframe\u00ad work for various forms of sequential computations (i.e. those with sid~-eflects). And they have \nbeen popularized in the functional programming community. For motivations and ?xamples, see [7, 15, 16]. \nWhen we would like to deal with state, we use the ~ollowing data type: type STsa=s->(a, s) with monadic \nconstructs such as: returnST : : a-> STsa returnST a=\\ s -> (a, s) thenST :: STsa->(a -> STsb)->ST sb \nm thenST k = \\ sO -> let (a, s1) = msO inkasl Values of type ST s a(called state transformers) represent \ncomputations which modify state of type s and produce re\u00ad.ults of type a. The operator returnST does \nnot change 4 ate and simply returns a value which is supplied as the wgument. The operator thens~ is \nused to sequentialize two state transformers. I he monad of state transformers [s considered to be a \nsuitiible abstraction in order to hide state from programmers, and to sequentialize accesses to ~tate. \nWe hide the implementation of state transformers kom programmers and carefully provide read/write primi\u00adtivw \nso that they do not destroy single-threadedness of state. rhen, it becomes possible to design primitives \nso that they update data structures in place. In order to deal with mutable arrays, Wadler [15] pro\u00adposed \nusing the following iirray pnmitives4: readArr :: Int -> ST (Array a) a uriteArr ; : Int -> a -> ST (Array \na) () which read and overwrite ,an array in the index given as the first argument, and: initST :: s-> \nST SX->X initST =\\s st -> fst (st s) which gives an initial state to state transformers, Note that the \ntype parameter s is instantiated to specific types such W+Array Int here. This contrasts with Launchbury \nand Peyton .Jones s proposal explained next. W? WIII use thetil ~ an Infix operator in the following \nusing llc Hwkell notation - for infix operators In Haskell 1.3, thenST]s Wrlttel] as >>= The names and \nthe types of prim) t!vesdiffer)n an inessent. ial way rem the orig]nal ones 2.2 Explicit style Launchbury \nand Peyton Jones s proposal also uses the monadic framework explained above. However, in their proposal, \nthe state type parameter of ST is used for a rather technical rea\u00adson. They proposed a primitive operator \nnamed newVar which creates a new ML-like reference (of type HutVar s a): neWar :: a -> ST s (HutVar s \na) and associated operators readVar and writeVar which re\u00adspectively read and update a reference. readVar \n:: NutVar s a -> ST s a writeVar :: HutVarsa->a->STs () Here, the type of references (tfut Var s a) is \nparameterized over the type of the state (s) as welf as the type of the object being referred to (a). \nThough s is intuitively the type of the global state, it is used in a speciaf typing rule explained next \nwhich prevents references from escaping their scopes. In order to execute state transformers, we use \na buihin construct (it is not an ordinary function) named runST of the following special type: runST \n:: Va. (Vs. ST s a) -> a When runST is applied to a state transformer, it passes an empty , initial state \nto the state transformer and then ex\u00adtracts its final result. In this way, runST extracts a pure value \nfrom a stateful computation. The special typing above is necessary for the following reason. If a reference \ncreated in one state transformer could be used in another transformer, the result. of the program would \ndepend on the evaluation order. Detecting errors caused by such cross pointers at run\u00adtime wouJd be expensive. \nBy requiring state transformers to be polymorphic with respect to the state parameter, they proved, using \nparametricity, that values within one state transformer cannot depend on references generated by other \nstate transformers and therefore that it is safe to interleave evaluation of such state transformers. \nThey also gave primitive operators for mutable arrays (HutArr s a). A simplified version of the array \noperators is shown below, where arrays are indexed by integers. neuArr :: Int -> a -> ST s (HutArr s \na) readArr :: MutArr s a -> Int -> ST s a writeArr :: HutArrsa->Int-> a-> STS() The first argument of \nneuArr is the size of the newly cre\u00adated array. This operator creates anew mutable array. The other two \noperators are used toreadand overwrite the array given as the first argumentin theindex given as the \nsecond argument. The type of mutable arrays (f4utArr s a) is also parameterized over thetypeof the state \n(s), and its second parameter (a) is the type of array elements. In their pro\u00adposal, programs which deal \nwith mutable arrays have type KutArrs a-> . . . -> STSX. Mutable array s(HutArr s a)aredifferent from \narraysof references (Array (MutVar s a)) they have different rep\u00adresentations [5, Section 3]. HutArr \ns aismore space-efficient since it is directly mutable and does not require indirection cells. On the \nother hand, Array (HutVar s a) needs in\u00addirection cells, however, it is more expressive since it can \nrepresent shared mutable cells. (For example, the second and the third elementscan be the same reference. \nIn such a case, if we modify the second element, the third element is modified simultaneously due to \nsharing. ) 218 [n the implicit style, we were not able to deal with more than one piece of state. This \nis why Launchbury and Peyton Jones introduced new primitives and an encapsulation mech\u00adanism for them. \nHowever, when we deal with only one nlu\u00adtable array, the implicit style seems to have an aclvantage \nprograms have simpler accounts and types. In this section, we will introduce some new primitives so that. \nwc can ~vrite stateful l>rograms enjoying advantages of both styles. 3.1 Compositional References For \nthe moment, we introduce the following primitive data type: type Mutable s t as a simple generalization \nof MutArr to general data struc\u00adtures other than arrays. [t stands for the mutable version of type t \nwith a state parameter s. Then, MutArr s a is a type synonym of Mutable s (Array a), For example, Mutable \ns (a, b, c) is the type of mutable triples. We will calf values of type Mutable s t compositional references \njrom s to t, ~he reason for this name will be explained later. Mutable s (a, b, c) and (MutVar s a, t4tttVar \ns b, MutVar s c) are different in the same way as MutArr s a and Array (MutVar s a) are different. That \nis, the former is the type of directly mutatie triples, while the latter is the type of triples of references. \nNeedless to say, Mutable s (a, b, c) and MutVar s (a, b, c) (more generally, Mutable s t and MutVar s \nt ) are different types. The former is the type of mutable triples, while the latter is the type of refer\u00adences \nto immutable triples. Actually, MutVar s a is a spe\u00adcial case of MutArr s a where the size of the array \nis exactly one. Therefore, we define the following data type as a record type with only one field. data \nAtom a = MkAtom a Then, MutVar can be explained as follows. type MutVar s a = Mutable s (Atom a) our \nintention here is that Mutable s _ makes only topleoel fields of data structures mutable. For example, \nMutable s (a, (b, c)) is the type of mutable pairs whose second com\u00ad ponents are wrrmukrbie pair}. while \nMutable s (a, b, c) is the type of mutable triples. Therefore, they are not equiv\u00adalent. The reason for \nthis (lesign decision will be discussed later in Section 5. Note that there is a c,mrespondence between \nimplicit <tyle state transformers an{l explicit style ones as follows: ]mplicit style: . . . -> ST t \nx Explicit style: . . . -> Mutable s t -> ST s x }ror example, the array updating operation has type \nInt -> a -> (Array a) ( ) in the former, while it has type Int -> a -> Hutabie s (Array a) -> ST s () \nin the iatter (ig\u00adnoring t be order of parameters), This correspondence will play an important role in \ntile following development. formers Next, we introduce some operators associated with compo\u00adsitional \nreferences. We would like to combine an array reference ar (of type Mutable s (Array a)) with a state \ntransformer of the im\u00adplicit style st (of type ST (Array a) x) so that they can produce a state transformer \nof type ST s x. For this pur\u00adpose. we introduce the following operator: appR :: Mutable st->STt x-> STSX \nWhen t is the type of arrays, it takes an array reference ar and a state transformer for arrays st and \nproduces a state transformer for the globaf state (s) in which the ref\u00aderenced array resi ales. That \nis, ar appR sts has type ST s x and is a globaf state transformer which only afTects the referenced array \nand has no effect on the rest of the state. Though appR deals with references, we will still call this \nstyle implicit, if state transformers use only appR and the operators introduced in the next subsection, \nsince muta\u00adble data structures are finally passed to state transformers as their hidden parameters. From \nthe implementation point of view, Mutable s t should be a primitive data type since we would like its \nval\u00adues to be represented as efficiently as possible. Intuitively, they should be direct pointers to \nmutable data structures. Still, we can consider a functional account of compositional references, like \nthat of state transformers, We introduce two auxiliary functions for this purpose: rd : Mutable st+ s+ \nt wr : Mutable st-+s+t-+s which read and overwrite the substructure of type tin the structure of type \ns. (In other words, we can view Mutable as the foUowing data type: type A4utabie st = (s -+ t,s + t+ \ns) when we explain their behaviour. ) We require that these two functions satisfy some natural equations \ntaken from ~~], rdr(wrrst) = t (1) wrr.s(rdrs) == s (~) wrr(wrrstl)tz = wrrstz. (3) Then appR can be \ndefined using these two functions. r appR st ~f As-+ Iett=rdrs; (a, t )=stt (4) in (a, uwrs t ) Intuitively, \nappR extracts the data structure of type t from the state (of type s), and applies the state transformer \nfor type t to the extracted substructure. In other words, com\u00adpositional references of type J4utable \ns t can extend the state parameter of state transformers from a smaller one (t) to a larger one (s). \nGlobal states conjured up by runST can be considered as very large data structures such as: &#38;f (al, \n~,..., al,ml, . . ..am-l.mm_l, an,l, . . ..an. mm, an+l,l, ..., a~,l,...,a~,m~) 90 5Wre assume appn \nbinds tighter than cthenST 219 [f a state transformer st :: ST (Array a) ( ) transforms (a,,, ~,..., \na~,~n) to (aA,,,.. .,a~,,nn) and cr :: Mutable s (Array a) is a compositional reference which points \nto  a ,l, . . ..an. ~n in SO: d cr so = (an,, ... ..an.mn) wrcrsO (a~,,,..., o:,,mn) = (a~,l,..., ai,m,, \n. . ..an-l.m=_,, w an+l,l, ..., aN,l, . . ..aiv. mN) their composition cr appR ( st transforms so to \n(al,l,.. ., a77-l, nzn_,j an, l,...,  I.LQd an+ a m ) As mentioned in the introduction, compositional \nrefer\u00adences are known in semantics of imperative programs as ez\u00adpansion rnorphisms in the category of \nstate shapes [13, 9]. They are used in order to explain block structures of imper\u00adative languages. What \nwe do in this paper is to use them as first-class objects in order to deal with various data types as \nstate in monadic functional programs rather than as a concept in semantics. Pierce and Turner [12] used \npairs of functions for extract\u00ading (get : s + t) and overwriting (ptit :s+ t+ s) sub\u00adstructures in order \nto explain inheritance in object-oriented programs. Hofmann and Pierce [2] directly associated such pairs \nto subtyping. Our use of compositional references is similar to theirs of such pairs of functions. However, \ntheir main interest is to give a type-theoretic foundation of object\u00adoriented programming. In contrast, \nwe use compositional references as a generalization of references and hence, as first-ck~ss values. An \nadvantage of the implicit style state transformers is that they have simple monomorphic types. As we \nmentioned in the introduction, Launchbury and Peyton Jones s method requires state transformers to be \npolymorphic with respect to the state, which sometimes prevents state transformers from being passed \nas function parameters. For example, it is impossible to type-check the following function. {\u00ad useArr \n: : (V s. MutArr s Int -> ST s ()) -> Int useArr ast = runST (newArr 10 0 thenST \\ ar -> ast ar thenST \n\\ --> readArr ar O) -} This is because runST requires the state parameter to be polymorphic while ast \nis used as a function parameter and must be monomorphic. On the other hand, if we define a state transformer \n( ast ) of type ST (Array Int) (), itis possible to pass them as a parameter of a function such as above \nand then to use it as ar appR ast in the function. .4nother possible solution to this problem would \nbe to extend the type checker as described in [8] and to use rank\u00ad2 types in type signatures. We will \nreturn to this point later, Once we introduce appR, we have to slightly modify the type of primitives \nsuch as newVar and neuArr which create new mutable data structures . The? can no longer be given unrestricted \npolymorphic tvpes, since specific data types such as arrays are used as the state parameter of state \ntrans\u00adformers. Here, we introduce a built-in (prim ltiue) type class Global s in order to show that s \nis the type of global states conjured up by runST and that it has an ability to return any number of \nand any type of fresh locations for rr.utable data structures, neuVar : : Global s => a -> ST s (MutVar \ns a) neuArr :: Global s => Int -> a -> ST s (MutArr s a) When global state transformers are appfied to \nnmST, the type constraint Global s is eliminated. Therefore, the type of runST shoufd be: rtmST :: Va. \n(Vs. Global s=>STsa) -> a In general, such type constraints are considered as hidden parameters. In the \ncase of Global s, it woufd be a function which returns a fresh location when applied to the globaf state. \nInstead of introducing new primitives for each data type such as newPair and neuTriple, we introduce \nthe folfowing primitive which creates a mutable version of its argument by creating the copy of its topleuel \nfields. nerWutable :: Global s => a -> ST s (Mutable s a) For example, newMutable (1,2) creates a new \nmutable pair in the global state. Of course, it would be possible to avoid cop ying when the argument \nof newf4ut able is a constructor application like (1, 2). Since its behaviour depends on the size and \ntherefore on the type of its argument, it might be better to constrain its type with say, Copyable a \nas we117. 3.3 Intermediate References In the implicit style, we will need primitives corresponding to \nreadVar and writeVar in order to define state transform\u00aders for each data type. In the design of such \nprimitives, we can use the correspondence of types between implicit and explicit styles explained in \nSection 3.1. Implicit style: . . . -> ST t x Expficit style: . . . -> Mutable s t -> ST s x Then, the \nprimitive read/write operators in the explicit style readVar :: MutVarsa->STsa writeVar :: UutVar s a \n-> a -> ST s () correspond to the following new primitives in the implicit style respectively: fetch \n:: ST (Atom a) a ass ign :: a -> ST (Atom a) () Their behaviour can be explained as follows: fetch = \n\\ (FlkAtom a) -> (a, f4kAtom a) assign a = \\ (MkAtom a) -> (() , f4kAtorn a ) (For the moment, we ignore \nthe issue of in-place updating.) For example, the following state transformer increments Atom cells. \n6Anot. her possible way would be to include the constraint }n the type of the state ss follows. nswVar \n:: a > ST (Global 6) (htVsr (Global s) a) If we could use mu]ti-paremeter type classes, type constraint \nof the form Globa12 s a might be better. 220 assign (n+l) In order to apply them to, say, the first \nfield of triples, we need a function of type: ST (Atom a) x-> ST (a, b, c) x However, we notice that \nthis is exactly what a composi\u00ad tionafreference oftype Hutable (a, b, c) (Atom a) and appRcan generate. \nTherefore, weprovide the following corn\u00ad positional references as primitives for triples: fst3R :: Hutable \n(a, b, c) (Atom a) snd3R :: Hutable (a, b, c) (Atom b) thd3R :: Hutable (a, b, c) (Atom c) In practice, \nsuch compositional references should be pr~ vialed automatically, when new data types are defined. One \npossible way is to extend the Haskell declaration of labeled fields [10, Section 4.2.1] so that the following \ndeclaration: dataC = F {fl,f2 :: Int, f3 :: Bool} generates three compositional references fl, f2 and \nf3 of type Mutable C (Atom Int), Hutable C (Atom Int) and Mutable C (Atom Bool) respectively. Suchcompositionaf \nreferences stand for reiatiuelocations of fields with respect to thebasestructure, For example, the functional \naccount. of f st3R is given as follows: rdj9t3R = A(a, b,c) + (Mk.4tor7za) u1rfst311 = A(a, b,c) + J(MJ9tom \na ) + (a , b,c) The expression fst3R appR incrST has type ST (Int, b, c) () and it changes the state \nfrom (n, b,c) to (n+ l,b,c). In practice, fst3R would have a representation quite dif\u00adferent from those \nreferences which arecreated by operators such msnewArr andneuMutable. In order to distinguish the twokinds \nofreferences explicit.fy, weuse the term global ref\u00aderences for those which are created by newMutable \nand so on and intermediate references for fst3R, snd3R and so on. We can also think of compositional \nreferences which stand for the location of substructures more general than fields. Forexample, we can \nthink ofacompositional referencefstSnd3R which stands for the location of the first and the second fields \nof triples, It has type Mutable (a, b, c) (a, b) and its behaviour can be explained by the following \nequations.  rdjstSnd,9R = J(a, b,c)+(a, b) wrfstSnd.3R = J(a, b,c)+J(a , b ) +(a , b , c)  When the \nHaskell data type declaration is extended to sup\u00adports omeformo finheritance,it improbable that such \ncorn\u00adpositional references are provided when new data types are defirmdby inheritingexisting ones. Then, \ncompositionafref\u00aderences such as Mutable (a, b,c) (a, c) where the mutable piece is notcontiguousc annot \nreintroduced, In this paper, we do not discuss particular syntax for inheritance, though. Forexample, \nlet fstR :: Hutable (a, b) (Atom a) sndR :: Mutable (a, b) (Atom b) forms (x, y) to (Jcost gsint, zsint+ycost): \nrotST :: Double -> ST (Double, Double) () rotST t = fstR appR fetch thenST \\ x -> sndR appR fetch thenST \n\\ y -> fstR appR assign (X*COS t -y*sin t) thenST \\ _ -> sndR appR assign (x*sin t + y*cos t) we can \nreuse rotST in the definition of spiralST, a state transformer fortriples which transforms (z, y,z) to(xcost \ngsint,xsint +gcost,z+t). spiralST :: Double -> ST (Double, Double, Double) () spiralST t = fstSnd3R appR \nrotST thenST \\ --> thd3R (fetch thenST \\ z -> assign (z+t)) Note that though they are written imperatively, \ntheir func\u00adtional accounts can be givenas follows: roLSTt = A(x,y) +  ((),(xcost-ysint,zsint+ycost)) \n spiralSTt = A (z, y,z)+ ((),(zcost-ysint,zsint+ycost,z+t)) If they are written in the explicit style, \nsuch accounts would involve the globaf state, even though its most part is not relevant. 3.4 An Example \nHere, we givea smafl example in the implicit style which uses primitives introduced so far. For arrays, \nwe assume that arrIdxis aprimitive such that the expression arrIdx i stands for the location of the i~h \nelement. arrIdx :: Int -> Mutable (Array a) (Atom a) Then applyST applies the given state transformer \naccording to the given list. applyST :: [Intl -> ST (Atom a) () -> ST (Array a) () applyST [1 st = returnST \n() aPPIYST (i:is) st \u00adarrIclx i appR st thenST \\ _ -> applyST is st If thesupplied list is [1,2,..., \nn] where nisthe number of elements, applyST behaves as the apply to all function. Suppose that adrr :: \nHutArr s Int isa mutable array of size three with all elements initialized to O, then the ex\u00ad pression \nSnArr appR (applyST [1, 2, 2, 2, 2, 1, 31 incrST) counts the frequency of the elements of the given list \nthe array is modified so that its first, second and third elements are2, 4 and I respectively. Ofcourse, \nan equivalent program can be written intheexpficit style. Theacfvantage of the implicit style here is \nthat it is obvious from the type that applyST only affects the array and does not interfere with the \nrest of the state. Another advantage is that if we provide avanant of initSTas follows, 221 initST \n: : s > ST s X > (X,5) can be ~iewed as a generalization ofrunST8and as an oper\u00adinitST = \\ s st > (st \ns) ator which extends the global state temporarily. It creates a new global state which is empty except \nthat it contains it becomes possible to use the modified state in the rest of theexisting state oftypet, \nThen, itpases thenew state to the program. the given state transformer with a compositional reference \ndesignating the location of the existing state. After execu\u00adtion, it throws away thenewly created part \nof the state and 3.5 Compositional References in the Ex\u00adbehaves astatetransformer forthestate oftypet. \nWithout plicit Style thecompositional reference oftype Mutable s t,two states In the explicit style, \nthe following primitive operator: of type s and t would be irrelevant-it would be impossi\u00adble to access \nthe existing state (of type t) from the state cnrpR :: transformer forthe extended state (of type s). \n?lutable s t -> Mutable t u -> Mutable s u which composes two compositional references of appropri\u00ad \n 4 Relation between the Two Styles ate types will be useful. The name compositional rejerence comes from \nthis operator. Intuitively, it simply returns the At first, programs which are written in the implicit \nstyle sum oftwo relative locations. Its behaviouris characterized and which use appR may seem inefficient \nsince the functional by the equations below: account of appR given in Section 3.2 conceptually requires \ncopying substructures before passing them to state trarw-  rrf(r<cmpR q) = (rdq)o(rdr) (5) formers. \nForexample, the expressionfstSnd3R appR rotST um(r cmpfi q)su = wrrs(wrq(rdrs)u) (6) t requires, at \nleast conceptually, copying of the first and the p cmpR (q cmpR r) = (p cmpR q) cmpR r (7) second fields \nof triples. On the other hand, if we write pro\u00adgrams entirely in the explicit style, we would not need \nsuch Then. \\ x -> x cispR fst3R gives the reference to the copying. For example, iftrR :: Mutable s (a, \nb, c), first field of the mutable triple x. theexpressiontrR cmpR fstSnd3R :: Mutable s (a, b) For example, \nif we write rotST in the explicit style, it can probably be implemented only by simple pointer arith\u00ad \nbecomes as follows: metic on references. States are not touched in the meantime and are accessed only \nvia readVar and uriteVar. They are rot ST T :: Double -> single-threaded, and state transformers can \nbe destructive Mutable s (Double, Double) -> ST s () in the explicit style. rotST t=\\r-> Even in the \nimplicit style, it seems possible to implement readVar (r cmpR fstR) thenST \\ x -> appR so that it takes \nas an argument a pointer to a triple, readVar (r cmpR sndR) thenST / y -> simply adds the offset corresponding \nto fstSnd3R and then writeVar (r crnpR fstR) passes the result pointer to state transformers, since \nstate (X*COS t. -y*sin t) thenST \\ _ -> transformers should be designedso that they update states writeVar \n(r cmpR sndR) destructively. However, we have not discussed in-place up\u00ad(x*sin t. + y*cos t) thenST \n\\ _ -> dating in the implicit style, so far. In the (extended) explicit style. weusecmpR instead of \nThe purpose of this section is to show that there is a certain relation between the two styles and therefore \nthat ences, instead of the state. Only readVar and uriteVar the implicit style programs can be implemented \nas the cor\u00adoperates upon the state, responding explicit style ones. The relation itself can be ~7ith \ncmpR, compositional references such as fstSnd3R shown irrespective of in-place updating. Then it will \nbe can behave a< cast operators of references by hiding some shown that in-place updating is also possible \nin the implicit appR. All operations are carried out with respect to refer\u00ad part of mutable data structures. \nSuppose we have pt :: style. Mutable s (Int, Int)andcpt :: Mutable s (Int, Int, The key is theequations \nderived from theories given in Color), then pts = [pt, cpt cmpR fstSnd3R] has type Section 3. [Mutable \ns (Int, Int)]. Borrowing from object-oriented terminology, cmpRis used for subtyping, while appRis used \n p appR (m thenST k) = for inheriting methods. (p appR m) thenST Aa+p appR ka (8) [n a sense, appR \n(or more precisely, flip appR where p appR (returnSTa) = returnSTa (9) flip f x y = f y x) can be thought \nofae atransformation  p appR (q LappR rn) = from the implicit style to the explicit style. In the other \ndirection, it becomes also possible to convert (polymorphic) (p cmpR q) appR m (10) explicit style state \ntransformers into implicit style ones, if we provide a built-in construct of type: Equations (8) and \n(9) state that (p appR ) behaves as a monad morphism. For the exact definition and examples extendST \n:: of monad morphisms, please refer to [15]. The equation (8) (V s. Global s=>Mutable st->STsa)->STta \nstates that appR( candktribute over thenST and (10) says that appR can be substituted by cmp~ in some \ncases. In the explicit style, we ran freely use operators such as We will make use of these facts in \norder to give efficient neuVar and can extend the state temporarily. [n this way, implementation of implicit \nstyle state transformers. we can go between the two styles and enjoy merits of both st,.~les. 8And \nit IS a generalization of the operator (of type (V s. ST s We can use extendST also when the state of \ntype t is cre-a) -> ST t a) which Peyton Jones proposed in his invited talk at ated by runSToranot.her \nextendST, In that case, extendST SIPL 95 222 type STCP.SO = s+ (a, s) we consider an alternative interpretation \nof state transform\u00aders:  type ST , qa = Mutable Gs+ G+ (a,G ) where G is some fixed data type for global \nstate and there\u00adfore Mutable G.9 is the type of global references. (So far, the type of global state \nis abstract in order to make encapsula\u00adtion of references possible. Therefore, we can think of the type \nabove as the following rank-2 type. type sT.c.sa = Vg. Mutable gs+g+(a, g) Here, however. it is considered \nas a fixed and universal data t~peinorder toconcentrate onthe essential issue.) Wedis\u00adtmguish the two \nsemantics by subscripting their components by cp (for copy) or nc (for no copy). Then we give mean\u00adings \nof the primitives in these two semantics so that they are properly related and that we obtain the same \nresults for values of observable types. The point is that primitives are defined in the non-copying semantics \nso that, roughly speak\u00ading, the following relation holds bet ween the two semantics of state transformers: \n.st c = A])+ pcappR:P st=P (11) Here st,,. and SL. are the meanings of some term of type S Tsa in the \ncopying and the non-copying semantics respec\u00adtively. The meanings of primitive state transformers including \n/etch and assign are given so that they satisfy the relation. jetc~C ~f Ap + p <appR~P fetc~P (12) asszg~c \na =f Ap + p appR;P assig&#38;P a (13) Note that in the non-copying semantics they are almost the same \nas new V ar and write Var except the order of argu\u00adments. The other primitives are defined as: q appR~C \nm :* Ap + m. (p cmpR q) (14) m thenST\\, k :* Ap + m p thenS7 2P Aa + k ap (15) return,STnC a ~f A-+ \nreturnSTcP a (16) Note that we use the convention in the definitions above and the equations below that \np and q are compositional references of appropriate types and: m: .s+ (%s) f  : Mutable Gs + G + (a, \nG) : : a+s+(b,9) k : a+ Mutable Gs+ G + (b, G). The definition of app~C (14) is the key step to avoid \ncopying since app~P requires copying of substructures while cmpR, and hence app~c require only simple \npointer calcu\u00adlation. These definitions are justified by the following equa\u00adtions (8), (9) and ( 10), \nThen from these equations, we can show that if we define primitives as in ( 14), (15) and (16), the following \nequations hold between the meanings of appR, thenST and returrzST in the two semantics, where we write \nm for Ap + p appR&#38; m.. (q appR&#38; m)* = q appR~c m*  (m thenSTLP k) = m * thenSTiC (,la + (k a)*) \n( returnST&#38; a)* = returnSTnC a From these equations and the design of the other constants, state \ntransformers constructed from them satisfy the rela\u00adtion (11). More precisely, we need to define a type-indexed \nfamily of logical relations [6, Chapter 8] between the copying and the non-copying semantics. The relations \nare defined by induction on types as follows: c-be (b: base type) (e,,ez And the elation for the type \nconstructor ST is defined as follows. def St *ST aa St = for any s, g, q, if sWO rd qg then sts *(a,O) \n(a, rdqgl) and wrqgl(rdqg)=g where (a, gl) = d qg Then we can show: Lemma: All the constants (returnST, \nthenST, appR, fetch, and assign) satisfy the logicaf relations. Proofi (See Appendix A.) Then from the \nbasic lemma of Iogicaf relations, terms built from such constants all satisfy the relations. Espe\u00adcially, \nfor a closed program with an observable type such as Int, its meanings in the two representations are \nthe same. This result shows that implicit style programs can be im\u00adplemented efficiently as explicit \nstyle ones that do not need copying of substructures. As for safety of in-place updating, the discussion \nin [5] can be applied to our set of primitives. That is, in-place updating is safe if primitives are \ndesigned so that the state is used only in a single-threaded manner and if afl read/write primitives \nare strict in the state. Of course, our read/write primitives (fetch and assign) can be implemented so \nthat they satisfy these requirements. Note that afl read/write primitives operate on fields and that \nthe contents of fields themselves are not mutable. Therefore, there is no operator that duplicates state. \n5 Discussion In this section, we give some remarks on implementation issues. From the result of the previous \nsection, we can draw the following implementation strategy. First, state transformers should take a reference \nM an Mgument and then modify the state destructively. For uni\u00adformity, even global state transformers \nshould take a dummy 223 parameter. k-oncf, conlljositional references arr divided into three kinds \nordinary global references created by newlhtable, intermediate references such as fst R and sndR, and \nglobal references produced by composing references of the first and the second kinds. Ordinary global \nreferences are represented as before (i .e. as pointers). Interior pointers (i e. pointers into the middle \nof data structures) maybe nec\u00ad essarv for references of the t bird kind, which may complicate garbage \ncollectors. In that case, they can be represented ~~ a pair of a pointer and an offset with a special \ntag. Note that this difficulty always arises when we would like to deal with pointers into the middle \nwith garbage collection, and therefore is not specific to our framework. Intermediate references are \nrepresented as a function from global references to global references also with a special tag in order \nto be distinguished from ordinary globaf references. Then, cmpR just applies this function to the global \nreference given a< the first argument. If we do not. need to deal with variant types, intermediate references \nmay be represented simply as an offset. In the rest of this section, we explain why Mutable s makes only \ntoplevel fields of data structures mutable as we mentioned in Section 3.1. For example, in Mutable x \n(a, b, c). all the three fields of triple are independently mutable, while in Mutable x (a, (b, c)) only \ntwo fields of type a and (b, c) are mutable-two fields of type b and c are not in toplevel and cannot \nbe updated destructively. If we would like to make such updates possible, we would need rather complicated \ncopying operations to keep further in-place updating safe. Suppose that state transformers of type ST \n(a, (b, c)) _ could update all fields of type b, c and (b, c) respectively This would be the case, if \nwe provided both compositional references: sndR :: Fhrtable (x, y) y sndR :: 14utable (x, y) (Atom y) \nThen we could update the field of type (b, c) with an im\u00admutable pair say, (1, 2) using sndR. Since fields \nb and c would be afso updatable by using sndR cMpR f stR and sndft cmpR sndR, we would have to make \na fresh copy of (1, 2) in order to make further updating safe, Other\u00adwise, the data structure which should \nbe immutable woufd be updated and this is, of course, wrong. However, if such copying is necessary, we \ncan use Mutable s (a, b, c) in\u00adstead. There is little reason to use Mutable s (a, (b, c) ). On the other \nhand, we can use references in data structures (i.e. Mutable s (a, Mutable s (b, c))) in order to deal \nwith deeply mutable data structures. Therefore, at least in most cases. it is sufficient to make only \ntoplevel fields muta\u00adble and is reasonable not to provide compositional references of type Mutable (a, \nb) b. Note that the framework of compositional references it\u00ad seIf does not pmhibit such compositional \nreferences. When in-place updating is not required, it is possible to provide both compositional references \nsndR :: Mutable (a, b) (Atom  b) and sndR :: Mutable (a, b) b, the latter of which makes (functional) \nupdate of deep fields without using ref\u00aderences in data structures. For recursive data types such as \nlists, the restriction above seems more problematic. We can not provide a com\u00adpositional reference of \ntype Mutable [a] [a]. Instead, we can provide only two compositional references of type Mutable [a] (Atom \na) and Mutable [al (Atom [al) for updating the head (car) and the tail (cdr) fields, Therefore, we can \nmake m~/y fhf first cons cell mutable, In order to make afl the cons cells mutable, we must clefine the \nfoflowing new data type: data MutList s a = MutCons a (Mutable s (MutList s a)) I HutNil One of the main \nreasons to introduce compositional refer\u00adences (Mutable ) is to avoid introducing new mutable data types \nfor corresponding immutable ones. However, we can\u00adnot obtain the type of mutable lists by just attaching \nMutable s to the type of ordinary fists. In order to make automatic definition of the type of mutable \nlists possible, it might be necessary to change the form of recursive data type defini\u00adtions as follows: \ndata List a = Cons a Self I Nil where Self is a reserved word corresponding to the type being defined \n(1 ike Current in Eiffel). Then, it would be possible to provide the mutable version of the type of lists \n(generally, recursive data types) automatically. Such modifi\u00adcation would be also necessary for object-oriented \nstyle data type definitions where data types are defined incrementally as discussed in Section 3.3. Then, \noverloading would play a more important role in order to treat such families of data types uniformly. \n 6 Conclusion We proposed a new type constructor t!utable and a set of new primitives (e.g. appR, cmpR,fetch \nand assign) based on the notion of compositional references. First of all, it enables us to use various \nspace-efficient mutable data structures otherwise, we would need to introduce primitive mutable data \ntypes in an ad-hoc manner. Second, when we do not need the expressiveness of the explicit style, we can \nwrite statefuf programs in the implicit style. State transform\u00aders can use data structures such as arrays \nand tuples di\u00adrectly as state and have simple functional accounts and sim\u00adple monomorphic types. Then \nthey can be freely used as function parameters. We showed that such implicit style computations can be \nimplemented efficiently by utilizing the relation between the implicit and the explicit styles. Acknowledgments \nThe author would like to thank Atsushi Ohori and the anony\u00admous referees for their helpful comments on \nearfier versions of this paper. References [1] Peter Achten, John van Groningen, and Rinus Plas\u00admeijer. \nHigh level specification of l/O in functional languages. In Launchbury et al., editors, Proceed\u00adings \nof Gias,qo w Workshop on Functional Programming. Springer Verlag, 1993. [2] Martin Hofmann and Benjamin \nPierce. Positive sub\u00adtyping. In Annual ACM Symp. on Principles of Prog. Languages, pages 186-197, 1995. \n 224 [:3] Paul Huda!i. Tllulabif, abstract datatylws, Research Report YALE(/DCS/RR-914, Yale (university \nDepart\u00adment of C omputer Science, December 19%2. [4] Koji Kagawa. Mutable data structures and composable \nreferences in a pure functional language. In Proc. oj the Second A C~MSIGPL.4 N lVorkshop on State in \nPro\u00adgraming Languages. pages 79 94, January 1995. Techni\u00adcal Report UILJCDCS-R-95-1900, University of \nIllinois at Llrbana-Champaigll. [5] John Launchbury and Simon L. Peyton Jones. State in Haake]l. L is-p \nand Syrnbofic Computation, 8(4):293-341, 199.5. [6] John C. Mitchell. Foundations for Programming Lan\u00adguages. \nMIT Press, June 1996. [7] Eugenio Moggi. Computational lambda-calculus and monads. In IEEE Symposium \non Logic in Computer Science, June 1989. [8] Martin Odersky and l<onstantin Laufer. Putting type annotations \nto work. In Proc. 23rd A Chf Symposium on Principles oj Programming Languages, pages 65 77, January 1996. \n[9] Frank Joseph Oles. Type algebras, functor categories, and block structure. In Algebraic Methods in \nSemantics, pages 543-573. Cambridge University Press, 1985. [10] John Peterson, I(evin Hammond, et al. \nRe\u00adport on the programming language Haskell version 1.3. http: //haskell. cs. yale. edu/haekell-report/ \nhaskell-report. htral, 1996. [11] Simon L. Peyton Jones and Philip Wadler. Imperative functional programming. \nIn Annual ACM Symp. on Principles of Prog. Languages, 1993. [12] Benjamin C. Pierce and David N. Turner. \nObject\u00adorient ed programming without recursive types. In An\u00adnual .4 CM Symp. on Principles of Prog. Languages, \nJanuary 1993. [13] John C. Reynolds. The essence of Algol. In J. W. de Bakker and J. C. van Vliet, editor, \nInternational Sympos:um on Algorithmic Languages, pages 345-372. North-Holland, 1981, [14] Philip Wadler. \nTheorems for free! In Proc. A CM Conj. Functional Programming and Computer Architecture, pages 347-359, \n1989. [15] Philip Wadler. Comprehending monads. In A CM Symp. on Lisp and Functional Programming, pages \n61 78, 1990. [16] Philip Wadler. The essence of functional programming. In Annual ACM Symp. on Principles \nof Prog. Lan\u00adguages, 1992.  A Proof of the Lemma Lemma: All the constants ( returnST, thenST, appR, \njetch and assign ) satisfy the logical relations. Proofi We show the cases for thenST and appR. The other \ncases are easier. (case for thenST) Suppose that m STU a m and k =+sTop k . And sup\u00adpose that for any \ns, g, q (17) s -0 s where s = rdqg Let (a,sl) = ms,(a ,gl) = m qg ands; = rd qgl then (a, s,) ~(a,c) \n(a , s{ ) therefore ka -ST c p k s . From this we can conclude that kasl W(@,m)(b , s;) where (b ,92) \n= k a gl ands; = rdqg2. Moreover, from gl = wrqg2s~, g = wrqgl s and (3), we can conclude that g = wr \nq g2 s . (case for appR) Assume that r ~.tabf, c,. r and st ~~T mo st and (17). We must show that (r \nappR~P st) s *(0,0) (a , s;) and g= wrqgl s where (a , gl) = (r appR~cst )qg, and sj = rdqgl. From s \nNO s : rdrs ~T rdr s = rdr (rdgg) rd (q cmpR r ) g Then, it folfows from st *STO~ d that (a, tl) (~,~) \n(a , t{) and g= wr (q CcmpR r ) g] t where t = rdrs (a, tl) = stt (a , gl) = st (q cmpR r )g = (r appl?~c \nst ) qg t{ = rd (q cmpR r ) gl t = rd (q cmpR r ) g Then, we have to show that wr r s tl W. s;. For this, \nit is sufficient to show that sj = wr r s tj.To show this: (r.h.s.) = wr r (rdq~) (rd (q cmpR r ) gl) \n= wr r (rdq (wr (q cmpR r ) gl t )) (rd (q cmpR r ) g,) = wrr (rdq(wrqgl (wrr (rdqgl) t ))) (rd (q cmpR \nr ) gl ) = wrr (wr r (rdqgl) t ) (rd(q cmpR r )gl) = wrr (rd qgl)(rdr (rdqgl)) = rd qgl = (1.h.s.) In \naddition, we must show that wrqgl(rdqg)=g To show this: (1.h.s.) = wr qg~ (rdq (wr (q cmpR< r )g, t \n))  = wrqgl (rdq(wrqgl (wrr (rdqgl) t ))) 225  Wr q{),(UI r (fdqg,) t ) !L,r (q crnpl? r )gl t = (r.h.s.) \nThis completes the proof.  \n\t\t\t", "proc_id": "258948", "abstract": "We introduce the notion of <i>compositional references</i> into the framework of monadic functional programming and propose a set of new primitives based on this notion. They enable us to use a wide range of mutable data structures. There, references may be passed around explicitly, or mutable data structures such as arrays and tuples may be passed implicitly as hidden state. The former style is called <i>the explicit style</i> and is usually more expressive, while the latter is called <i>the implicit style</i> and has simpler semantics. We investigate the relation between the two styles and discus implementation issues.", "authors": [{"name": "Koji Kagawa", "author_profile_id": "81100510902", "affiliation": "Department of Information Science, Kagawa University, 2-1 Saiwai-cho Takamatsu 760, Japan", "person_id": "PP14177666", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258948.258969", "year": "1997", "article_id": "258969", "conference": "ICFP", "title": "Compositional references for stateful functional programming", "url": "http://dl.acm.org/citation.cfm?id=258969"}