{"article_publication_date": "08-01-1997", "fulltext": "\n Formal Models of Distributed Memory Management Cristian Ungureanu and Benjamin Goldberg Department of \nComputer Science New York University email: {ungurean,goldberg} @cs.nyu.edu Abstract We develop am abstract \nmodel of memory management in distributed systems. The model is low-level enough so that we can express \ncommunication, allocation and garbage col\u00adlection, but otherwise hides many of the lower-level details \nof an actual implement ation. Recently, such formal models have been developed for memory management \nin :Lfunctional, sequential setting [10]. The models are rewriting systems whose terms are pro\u00adgrams. \nPrograms have both the code (control string) and the store synt act ically apparent. Evaluation is ex\u00adpressed \nas conditional rewriting and includes store opera\u00adtions. Garbage collection becomes a rewriting relation \nthat removes part of the store without ailecting the behavior of the program. Distribution adds another \ndimension to an already com\u00adplex problem. By using techniques developed for com\u00admunicating and concurrent \nsystems [9], we extend their work to a distributed environment. Sending and receiving messages is also \nmade apparent at the syntactic level. A very general garbage collection rule based on reachability is \nintroduced and proved correct. Now proving correct a specific collection strategy is reduced to showing \nthat the relation between programs defined by the strategy is a sub\u00adrelation of the general relation. \nAny actual implementa\u00adtion which is capable of providing the transitions (includ\u00ading their atomicity \nconstraints) specified by the strategy is therefore correct. This model allows us to specify and prove \ncorrect in a compact manner two garbage collectors; the first one does a simple garbage collection local \nto a node. The second Permission to make dlgilel/hard copy of part or all this work for personal or classroom \nuse is granled wilhout fee provided that copies are not made or distributed for profit or commercial \nadvan \u00adtege, the copyright notice, the title of the publication and its date aPPear. and notice is given \nthat copying is by permission of ACM, Inc. To copy otherwise, to republish, to post on servers, or ro \nredistribute to lists, requires prior specific permission and/or a fee. ICFP 97 Amslerdam, ND @ 1997 \nACM 0-89791 .918 -1/97 /0006 .,, $3,50 garbage collector uses migration of data in order to be able to \nreclaim inter-node cyclic garbage. 1 Introduction Automatic memory management, or garbage collection, \nis a valuable service, significantly freeing programmer s re\u00adsources. Programmers can rely on the language \nimple\u00admentation to find and deallocate unneeded objects while also ensuring memory safety: no program \nwill use dan\u00adgling pointers. Although garbage collectors come with their problems (e.g. run-time costs, \npossibly additional synchronization costs in concurrent systems) the benefits usually outweigh the drawbacks \nif the collector indeed en\u00adsures memory safety. Unfortunately, the correctness of the garbage collector \nis very rarely proved in a satisfactory manner; this happens not only because of the complexity of the \nstrategies used, but also because of the lack of a simple model of memory operations. In this paper, \nwe are presenting such a model. Start\u00ading from the AU-S calculus of Felleisen and Hieb [4], and from \nMilner s CCS [9], we introduce a language, All, which roughly corresponds to a distributed, impure functional \nlanguage. In Section 2, we present the language All with a rewriting semantics that makes allocation \nand commu\u00adnication explicit. A program is a collection of one or more processes running in parallel on \none or more nodes of a distributed system. A process consists of a thread and the local store it has \naccess to, also called heap. The thread part of the process may contain sub-threads, all of which share \nthe local store. The heap contains bindings. The semantics defined allows us to use many of the proof \ntech\u00adniques developed for CCS, such as bisimulation and tran\u00adsition induction. In Section 3, we define \nthe semantic notion of garbage and introduce and prove correct the fr-ee-variable garbage collection \nrule which models trace-based collectors. In Sec\u00adtion 4 we provide two implementations at the syntactic \nlevel: one that corresponds to a simple local garbage collec\u00adtor which scans a local heap starting from \nthe stack and the incoming reference list , and another one which is able to collect garbage cycles which \nspan multiple nodes by mi\u00adgrating objects not referenced locally. We prove that they axe subrelations \nof the garbage collection relation, hence their correctness follows. Section 5 discusses related work \nand Section 6 presents a summary and future work. Due to space limitations, many proofs have been omitted \nfrom this paper. A technical report including full proofs can be found at http: //es. nyu. edu/csd/reports. \nhtml. 2 The programming language All Our model of memory management is based on a language and its accompanying \nsemantics. To be adequate for this task the language has to be expressive, with a natural allo\u00adcation \nmodel andanatural concurrency model. In order to have a manageable formalism (fewer cases, shorter proofs, \netc. ) wehaveonly included essential constructs which per\u00admit us to make our point. While our language \ndoesn t correspond exactly to an existing one, it roughly corresponds to an impure func\u00adtional language \nwith threads in a distributed environment. Computation is distributed among a number of nodes, each node \nhaving a collection of local threads running in par\u00adallel and sharing a Iocaf heap. The communication \nmech\u00adanism it uses is that of CCS: communication consists of synchronously sending and receiving a value \nvia a port. The allowable expressions, which include assignment, and their evaluation rules are based \non AO-S. Below, we will de\u00adscribe the syntax of the language, its semantics, and intro\u00adduce the concept \nof observational bisimulationl on which we base the equivalence of programs.  2.1 Syntax A program is \na collection of one or more processes running in parallel; they are intended to model the nodes, or sites, \nof a distributed system. A process P consists of a thread T and the local store it has access to, also \ncalled heap H. The thread part of the process, which may be thought of as the code of the process, may \ncontain sub-threads, all of which share the local store. The heap contains bindings which can be mutuafly \nrecursive, since we allow modification of bindings through assignment. The syntax is presented in Figure \n1; parentheses are necessary to disambignate cer\u00adtain syntactic constructs. Essentially, the thread specifies \nwhat communication is possible. Using CCS terminology, the syntactic forms a thread can take are called \ncombiraators. We have the fol\u00adlowing combinators: idle thread, prefix, composition, sum, conditional, \nand recursion. The intention behind these combinators is that the idle thread E cannot perform any actions; \nprefix allows the specification of a communication (send or receive), and composition allows threads \nto run in parallel. The sum combinator allows a nondeterminis\u00adtic choice between the two component threads. \nRecursion allows a thread to be specified as the unique solution of an equation containing a thread variable. \nNot all such equa\u00adtions have unique solutions; a sufficient condition for an equation X = T to have a \nunique solution is for the vari\u00adable X to only occur in T in a prefix combinator. A well formed program \ndoes not contain recursive definitions with multiple solutions. If the solution is unique, it is denoted \nby &#38; {X = T}. We will precisely describe the behavior of all combina tors when we present the se \nmantics of the language. We are only providing enough combinators to achieve the desired expressibility \nof the language. As in CCS, we can add relabeling and restriction, but that would make our models more \ncomplicated than is necessary. In CCS, relabeling is only a convenience: programs can be written more \ncompactly by reusing components. Restriction of ports makes it possible to isolate transitions internaf \nto a component of the program from interference from other parts of the program. Because our language \ndoes not allow us to hide transitions, we have the extra burden to take these transitions into account \nwhen proving bieimilarity of programs. In the programs written in All, in order to achieve a similar \neffect, we can give unique names to the ports involved. In All, the values are either integers i or abstractions \nk .e. Expressions may be values, applications (e L ez) or assignments x := e. The assignment produces \nboth a value (that of e) and a side effect. The heap is a set of pairs, also called bindings. The pairs \nconsists of a variable and a value. The variable in such a pair can be thought of as the location where \nthe value is stored, rather than a pro\u00adgram variable . In all the rules requiring allocation (AUOC, App, \nand crv) we have to ensure that a fresh variable is chosen for a bindhg; this in effect guarantees the \nunique\u00adness of locations in memory. On the other hand, in the control string we expect to work with program \nvariables. However, since each program variable is allocated at a unique location, we can keep the correspondence \nbetween a program variable and its location by repkwing all occur\u00adrences of that variable in the control \nstring with the heap variable (the location). We could have chosen to repre\u00adsent program variables and \nlocations by difTerentsyntactic categories, but since no confusion is possible we preferred to have a \nsimpler syntax. This notation is also consistent with that found in the referenced papers. A variable \nmay be bound to only a single value. Con\u00adsequently, a heap can also be considered a finite function. \nllom(ZI) denotes the bound variables of If, and Rng(H) denotes the values bound in H. Moreover, we require \nthat a well formed program has the domains of all component heaps disjoint (i.e. a variable is bound \nin at most one heap). Notation: All, AI, w. All is the set of all well formed programs. A; is the set \nof all closed programs (no free variables or free process (variables) z,g,.z . Var (integers) i~ Int \n::=.. l10 [1121 (expressions) e Exp ::= z I i I Axe I (el ez) I (z := e) ~~k;~mlues) h Hval ::= i I \nAxe (Potisj H a, p 6 Heap Poi ::={z, =h,, z,=h,...} (thread war) X, Y G TVar (threads) T,U Thread ::= \nE idle thread I ~ +Tz) sum ~z/71) composition I thread variable prefix (receive) I tix{X=T} recursion \n~!e,T prefix (send) I if x then T else U conditional {vrocess) P. Q Process ::= ((H, T)) ~progmrns) E: \nF Prog ::= F I (i@ F) Figure 1: Syntax of All variables). For a definition of free variables see Figure \n5. The union of two heaps H1 and Hz with disjoint domains is denoted by H1 w H2. 2.2 Semantics Operational \nsemantics is usually represented by a state transition system. In our case, the state of the program \nis syntactically apparent (it is available in the heap and thread parts of processes). Consequently, \nour semantics will consist of a number of (transition) relations between programs (see Figure 3). The \nrelations are specified by de\u00adcomposing the program into an instruction and an evalua\u00adtion contezt, and \nthen giving rewrite rules for each possible instruction, together with the possible side conditions. \nAn execution step consists of selecting a pair from the rela\u00adtion such that the program matches its left \nterm; the right term is the resulting program. Informally, we will also say that the program made that \ntransition, resulting in the new program. Note that, unlike in the sequential case, the exe\u00adcution step \nis not uniquely determined, Non-determinism can occur directly, as a rezult of the sum combinator, or \nindirectly as a result of parallel composition (more on this later). When no rules are applicable, the \nexecution halts. Because processes need not be contiguous to commu\u00adnicate, we shall use the technique \nof labeled tmnsitions to express the laws of process reduction. Formally, we have a set of labels Lbl \n= {cr. la c Port, v E Hval) U {@vlcY E Port, v E Hval} U{comp, ifo, ifl, sum, comml, comw} and each \nIabel has associated a transition relation. Note that we have an infinite number of labels au and Z., \none for each possible port-value pair. We will say that, for any a and v, the labels a and ~ are complementary, \nwritten a -E . The definitions of the relations associated with each la\u00adbel are given inductively. The \nfact that a pair belongs to a relation will be asserted by some rules in the case the pair occurs as \nthe conclusion of that rules. As a notational convention, we will denote the relations with names start\u00ading \nwith lowercase letters. The rules have their first letter capitalized (with the exception of ao and =ti). \nThe dis\u00adtinction is necessary since a relation can be specified by more than one rule. Also, the compatible \nclosure rules help define many relations. A rule can also have hypothe\u00adses, possibly requiring that some \nother pair of programs belongs to the same or different transition relation. Rules without hypotheses \nare called axioms. The other rules are called in~erence rules. This mode of defining the relations will \nallow us to prove transition invariants by induction on the length of the proof that the transition is \npossible. This proof method is called transition induction [9]. As an example, the relation sum is defined \nby the rules Sum, F iz, Parl and Parz. Rule Sum is an axiom, while rule Parl haa a hypothesis. The rule \nParl helps define not only Sum but also relations au, XV, if., ifl, comp and comnq. With the exception \nof rule Com~ the left term of the pair is a process (thread-heap pair). The transitions that a process \ncan perform are all determined by the thread expression (combinators) of that process. In rule EV, a \nthread a!y.T is able to send the value of y at port a, after which it behavea like T. The side condition \nexpresses the fact that the value v used in the label E. must coincide with the value y is bound to. \nThe binding may occur anywhere in the program, not necessarily the local heap. In order to simplify the \npresentation we did not introduce a transition to signal program errors like unbound variable error . \nIf no transition rule applies, the program is simply stuck. In rule cr., a thread a?x T is able to receive \nat port a a value v. A new variable (z in this ciwe) is chosen and is bound in the local heap to the \nvalue received. The thread continues to behave like T (where the variable x haz been substituted for \nz). The capture-avoiding substitution of a variable for another variable is defined for all the syntactic \nExpression evaluation contexts, and instruction expression: (contexts) C[ ] E Ckct (instructions) I E \nInstr ::= L][ (Y;; ;/;:: Yq[ 1) I (~ = C[ ]) Evaluation rules for expressions: (Allot) (H, C[h], H ) \n*(H w {z = h}, C[x]) x $ZDom(H u H ) (App) (H, C[z y],ll ) % (H&#38; {z = h}, C[e{z /z}]) (HW H )(z) \n= Az.e, (Hw H )(y)= h,z @ Dom(HW H ) (:=) (Hw{z=hI}, C[z := y], H ) ~ (Hu{z =hz}, C[z]) (H W H )(y) \n= hz Figure 2: Expression evaluation contexts, instructions and evaluation rules for expressions Program \ncontexts: &#38;[] ::= [ ] I (E[ ] o E) I (Eo &#38;[ ]) Rewriting rules for programs:  (= ) S[((H, Q!y.T))] \nI% S[((H, T))] (Hw Heap(S[ ]))(y) = v (cr.) ti[((H, cr?z.T))] I% ~[((H &#38; {z = h}, T{z /z}))] x @ \nDom(H M Heap(&#38;[ ])) (If, ) &#38;[((H, if z then T else U))] ~ .5[((H, T))] (H U Heap(&#38;[ ]))(z) \n# O (Ifo) &#38;[((Z-Z,if z then T else .?7))] M S[((H, L ))] (H u Heap(&#38;[ ]))(z) = O (Sum) S[((H,T, \n+ T,))] * S[((H, Ti))] 2 =1,2 (Comp) &#38;[((H, a! C[e].T))] % g[((H , cr!C[e ].T))] (H, C[e], Heap(&#38;[ \n])) ~ (H , C[e ]), ezp E {allot, app, :=} ( Comml) &#38;[((H, T [1u))] co~m &#38;[((H , T IIU ))] &#38;[((H, \nT))] ~ &#38;[((H, T ))] &#38;[((H, U))] ~ S[((H , U ))], a A b (Com~) &#38;[Eo F] ~mr &#38;[E @ F ] \n&#38;[Eo F] ~ &#38;[E oF] &#38;[E@F]~&#38;[EOF ], a_b (Fix) &#38;[((H, fix {Y = T}))] ~ &#38;[((H , \nT ))] &#38;[((H, T[fix {Y= T}/Y]))] % S[((H , T ))] (Par, ) &#38;[((H, T IIu))] ~ &#38;[((H , T IIu))] \n&#38;[((H, T))] ~ S[((H , T ))] (Par,) E{{(H, T IIU))] ~ &#38;[((H , T IIU ))] &#38;[((H, U))] ~ S[((H \n, U ))] where a c {a., ?G, ifo, ifl, comp, commi, sum}. Figure 3: Process evaluation rules Programs: \nContexts: Heap(((H, T))) = H Heap([ ]) =0 Heap(E @ F) = Heap(E) w Heap(F) Heap(E @ &#38;[ ]) = Hap(&#38;[ \n] @ E) = Heap(E) u Heap(&#38;[ ]) Figure 4: Definition of function Heap Free variables: Expressions \nThreads FV(X) FV(i) FV(Az.e) FV(el ez) FV(Z := e) Sets of values = {z} =0 = FV(e)\\{r} = FV(el) U FV(e2) \n= {z} U FV(e) FV(e) FV(CY?Z.T) FV(a!e.T) FV(X) FV(fi {X= 2 }) FV(T [1U) FV(if x then T else U) . 0 = \nFv(z )\\{z} = {V(e) U FV(Z ) = = FV(T) = FV(Z + U) = FV(Z ) U FV(U) = {z} U FV(T) U FV(U) FV(0) FV(S w \n{v)) Heaps =0 = FV(S) U FV(U) Processes and FV(((H, T))) FV(E @ F) Programs = = (FV(H) (FV(E) U ~V(~))\\~om(~) \nU FV(F))\\Dorn(Heap(E) w Heap(F)) FV(H) = Fv(Rn,9(H))\\Do?n(H) Free process variables: FP(E) FP(cr?z.T) \nFP(T [1U) ~ = 0 FP(a!e.T) FP(T + U) = = FP(T) FP(T) U FP(U) FP(X) FP(fix {X= T}) FP(if x then T else \nU) = = = {x} FP(T)\\{X} FP(T) U FP(U) Figure 5: Definition of FV and FP functions components of programs \n(see Figure 7). The substitution of x with a new variable is necessary to maintain unique bindings for \nvariables in the presence of recursive threads. Rules IfO and If, say that a thread if x then T else \nU behaves like U in case that x is bound in some heap to the integer O, and like T if z is bound to some \nother value. Rule Sum says that the thread (TI + T2) can behave (non\u00addeterministically) as either 2 1 \nor Tz. Transition relation comp describes a computation step, whereby an expression is reduced to a value \n(in one or more steps); it is defined as the transitive closure of the union of relations allot, app \nand :=. These sub-relations, which describe sequential computation, correspond to the reduction rules \nin AV-S. They are modified to account for the possibility of non-local bindings of variables. The computation \nrelation is intended to define a left\u00adto-right call-by-value evaluation order. The expression is decomposed \ninto an evaluation context and an instruction. The decomposition is guaranteed to be unique [10], and \nis obtained by scanning the expression from left to right and taking as the instruction the first redex \nencountered. The context is the expression with a hole replacing the redex. Because of this mode of choosing \nthe instruction, a context will always have at the left of the hole only variables, hence the definition \nof expression contexts C[ ] in Figure 2. In all the evaluation rules for expression, we need to supply \nboth the local heap H (which may be modified by the transi\u00adtion) and the union H of all nonlocal heaps \n(in case that some variable is bound non-locally). The transition rule Allot applies when the instruction \nis a value, and specifies that a binding of a new variable to that value is added to the local heap. \nThe value is replaced by the variable in the expression part. Recall that we required that all heaps \nhave disjoint domains. This translates into the side condition we have for this rule: x @ Dom(H u H ). \nRule App specifies that the parameter of the abstraction must be bound to the value of the argument y. \nAlpha-conversion is necessary to ensure that no conflicts occur in the heap. In rule (:=), the value \nof y replaces the value z is bound to. There are also compatible closure rules: Fiz, Parl and Par2. The \ntwo Par rules say that if the thread is a composition, and one of the component threads is able to make \na transition, then the originti thread is able to make a transition with the same label. The F iz rule \nspecifies how the unwinding of the recursion is made. Rules Comml and Comm specify how two threads ca\u00adpable \nof transitions with complementary labels (sending and receiving a value v at some port a) communicate \nwith each other. Rule Comm+ describes communication local to a node. Note that the local heap is modified. \nFinally, rule ComW specifies that communication can take place between processes E and F if, in the context \nprovided by f[ ], they are able to make transitions with complementary labels. Note that an effect of \napplying the Comw rule is that we may obtain remote pointers . However, they are ss-m (({}!fi {x = ~?~@(~ \nO)x})) @ (({},~!(~~l)&#38;)) cflp (({}, fix{~ = cY?z.~!(Z ()).x})) @ (({h= k .l), dh.E)) Co&#38;?p (({z \n= Az.l}, p!(z 0).fix{x =a?z.p!(z0).x}))@(({h=Ax.l},c))  c~P (({~ =~~1>~ =o}>~!(~ ~ )fix{x =~?~.~!(~O).x}))@(({~=~~l},&#38;)) \nCfqp (({z = Az.l, h = O,z = ~ },P!l.fi {x = ~?~l!(~ O)x})) @ (({~= ~~.l}!c)) Figure 6: Example of execution \nof a program not syntactically distinguished from local pointers , and applying that value to O. Note \nthat if the value received is the same rules apply to them. Circularities between differ-not a function, \nthis process would become stuck. The sec\u00adent local stores can be obtained by embedding pointers in ond \nprocesses is a non-deterministic choice between send\u00adclosures. ing Ax.0 or k. 1 and then becoming idle. \nAs we have already said, the program is partitioned into The first transition, using rule Sum, is a non-determin\u00adan \ninstruction and an evaluation context. However, un-istic choice. Then, the expression to be send is evaluated \nlike in the sequential case, this partitioning is not unique. (rule comp, sub-relation aUoc). In the \nnext transition, by Non-determinism can occur directly, as a result of the sum rule Fiz, the two processes \nexchange a value via port a; comblnator, or indirectly as a result of parallel composi-the hypothesis \nof this transition relation is met because tion. We can have non-determinism because the order of after \nunwinding the recursion representing the left term, transitions made by different threads is arbitrary \nand the the process is able to receive a vafue at port a. The vafue language has assignment; a typical \nexample is a that of received is allocated in the left process heap, and the fresh a thread reading a \nglobal variable and another thread variable chosen for this binding is used to replace the free assigning \nto that variable a new value. Another source of occurrences of z in the thread. Two computation steps \nfol\u00adnon-determinism is overlapping redexes: two threads at-low; the first is evaluating the argument \nof the application tempt to send different values via some port a. These dif-(an allot step which results \nin the allocation of O onto the ficulties have to be dealt with when defining the semantics heap) and \nthen an app step. The formal parameter z of of the language. the function kc. 1 is bound (upon renaming) \nto the axtual The evafuation of programs is just a union of some of argument h , and the body of the \nfunction replaces the the relations described above: ~i and @i which model how application expression. \nNote that at the end of the steps the program interacts with the environment, and compj described, both \nheaps contain only garbage. sum, ZfO,i~l, comml, com~ which describe how the com\u00adputation can proceed \nwithout such interaction. We will 2.3 Observational equivalence use the following not ation: The semantics \ndefined is intended to model the behavior of R = {cr;la C Port, zEM} U {ti~la C Port, i E Int} U a program \nwhich executes in some environment with which {comp, ijo, ifl,sum, Comml, Corn%} it can communicate through \nmessages. But the program can also make transitions, like Ijo which do not involve R+ = R u {avlcr ~ \nPort, VE ~VU~} U communication. Two pro~ams which cannot be distin\u00ad {@ la E Port, v E Hval} guished \nby an observer are observationally equivalent. The question is: what is considered observable? We propose \nR is the evaluation relation. We will make use of R+ that observable is only the communication the program \nin various prootk. Here, al stands for the set of port has with the environment. The other transitions \nare un\u00advalue pairs where the vafue can only be an integer. An observable, also called internal. explanation \nof why we don t use the full relations au and It remains to decide when two programs communicate ?L \nto define the evaluation relation will be given ai%er we with the environment in an equivalent way. Naturally, \nif introduce observational simulation. both programs send (respectively receive) equivalent values Perhaps \nan example would help clarify how evaluation via equivalent ports, they communicate in an equivalentis \ndone. The program in Figure 6 consists of two processes. way. In our case the values are integers, and \ntheir equiva-The left one is recursive; it is capable of continually receiv\u00adlence is mathematical equality; \non ports, the equivalence is ing a value at port o and sending to port ~ the result of the identity relation. \nEquality is certainly decidable on in\u00adtegers. We disallow communicating A-abstractions with the environment, \nsince equality on functions is not decidable. Note, however, that internal communication of closures \nis possible. Formally, we define observational simulation with respect to a relation (~) which abstracts \nfrom unob\u00adservable comput ation. Definition 1 The transition relation ~ on All with labels from {CG, \nEi} is defined reductively: E%E if E6E E$-E ifE ~ E andE ~ E E~E ifE ~ E andE +% E where a E {cta,~i} \nand b c {comp, wm~, comw, ijo, ifl, sum}. Definition2 A relation 72. ~ All x All is an observa\u00ad tional \nsimulation if it satisfies: EIZFand E%E ~ 3F s.t. F% F and E ?ZF where a . {~i, =i }. An observational \nbisimulation is a symmetric observational simulation. Lemma 1 Let S1, SZ be observational bisimulations. \nThen the identity relation Id on programs, the inverse relation S1-1, the imposition relation SI SZ, \nand the union relation S1 u S2 are all observational bisimulations. Definition 3 (Program Equivalence, \nx) Our seman\u00adtic equivalence on progmms is the coarsest observational bisimulation: x= U{S :S is an observational \nbisimulation } Lemma 2 Relation z is an observational bisimulation and also an equivalence on progmms. \n Garbage collection Definition4 (Garbage collection relation) R ~ All x All is called a garbage collection \nrelation ij it preserves bisimilatity, and has the potential of wllecting garbage: E 7?F ifl E %F and \nDom(Heap(F)) ~ Dom(Heap(E)) The garbage collected wnsists of all the bindings of vari\u00adables in Dom(Heap(E))\\ \nDom(Heap(F)). F is called a collection oj E. Note that the relation leaves open the possibility of a \ngarbage collection algorithm to replace the value a variable is bound to with something else (the integer \nzero, for ex\u00adample), as long as the programs remain bisimilar. ( This corresponds to replacing a pointer \nwith NULL. ) This is done in [10] to reclaim space occupied by objects which, although reachable, would \nnever be accessed by the pro\u00adgram. 3.1 Free variable rule The garbage collection algorithms we are going \nto define are all based on tracing: all the reachable bindings are preserved. Following [4], reachability \nis modeled by con\u00adsidering the free variables. If a heap binding is reachable, and the value bound contains \nfree variables, the bindings of these variables are reachable. Since our garbage collectors will leave \nthe thread pmt of the program intact, we first define a relation to assert exact ly this. Definition \n5 (Thread equivalence,) ~~ All x All, is a relation defined by: ((H, T)) ~ ((H , T)) VII, H E Heap E@F \nLE OF if E~E and F~F We use the same notation for the thread equivalence rela\u00ad tion on contexts: and \nE~F Definition 6 (Free variable relation) The free variable relation (~) ~ A; xA; is defined by: E d \nF if E ~ F and Heap(F) ~ Heap(E) Note that this is a relation between closed programs. Our goal is to \nprove that the free variable relation is also a garbage collection relation. In order to show this we \nneed a number of technical lemmas. We plan to proceed as fol\u00adlows: we define strong bisimulation on All, \nand show that if two programs are strongly bisimilar, then they are observa\u00adtionally bisimilar. We will \nthen show that a-conversion is a strong bisimilarity. We need this result because two identi\u00adcal programs, \nmaking an allot transition for example, may choose different fresh variables, leading to syntactically \ndif\u00adferent programs. We then define strong bisimulation up to =, and show that if S is a strong bisimulation \nup to =, then S ~ =; it follows that S ~ x. Then, it is sufficient to prove that (~) is a strong bisimulation \nup to ~. Definition 7 (Strong simulation) A strong bisimulation is a symmetric strong simulation. A relation \nS ~ All x All is a strong simulation if it satisfies; Va~R. ES FAE~E @3F . F~ F AE SF Lemma 3 Let S1, \nS2 be strong bisimulations. Then: the identity relation Id on programs, the inverse relation S1-1, the \ncomposition relation SISZJ and the union dation S1 U SZ are all strong bisirnulations. Definition 8 The \nstrong equivalence relation, ~, is the coarsest strong bisimulation: ~= U{S :S is a strong bisirnulation \n} Expressions: Heaps: .i 00 0 l?(H13{z=v}) = (e H) M{ez=ev} 6% = y 2=X z otherwise { Threads: O (el \nez) = (0 el) (f3 e,) 6E = E B(.r:=e) = (Oz):=(f3e) ..   ex A CY?Z.U .Z=Z .k.e ~=x ~?z.((jq z#x,.z#y \nAz. (@e) z#x, z#y e Q?z.u 19(CY?W.(W)) z = y6 A.z.e = 6(Aw.(0 e)) z = y w $! FV(e) U {z, y} w g FV(e) \nU {z, g} { O ={Z*W}{ L9 ={zl-+w} ~!e e.(e q Labels: (f3u) II(e v) 6 if x then U else V= if Ozthenf?Uelse \nOV o CY. = ~(e v) @(u+v) = (0u) +(ev)@E = a (# .) efix{x=u} = fix{x=eu} @a = a, otherwise Processes \nand programs:  o ((H, T)) ((0 H, 8 T)) = 6(EOF) (eE) @(eF) (e o[z H g])F = [z * y](eF). Fi~re 7: Definition \nof substitution Lemma 4 Relation z w a strong bisimulation and also (a)z Sz isa strong bisimulation, \nan equivalence on progmms. The result follows from the (b) S ~ z. previous lemma. Lemma 5 Relation z \nis an observational bisimulation. The proof can be found in the appendix. Lemma 7 (&#38;) is a strong \nbisimulation upto s. The proof of this lemma is quite long. It crucially uses the fact Definition 9 (Substitution) \nA substitution d is an in\u00ad that the relation is on closed programs. The proof can be jective finite map \nfrom variables to variables. 9 is natu\u00ad found in the technical report mentioned in the introduction. \nrally extended to a function for all syntactic categories in the language in Figure 7. Theorem 2 (Correctness \nof GC) The relation (~) isTheorem 1 (Correctness of a-conversion) a garbage collection relation. The \nresult follows immedi- LetS = {(E, F)IE, F c Al and 38.F = @l?}. S is a strong ately from Lemmas 7, 6 \nand 5. bisimulation. Definition 10 S is a strong bisimulation uptoz ifESF 4 Implementation implies, for \nall a: IfE&#38;E then, 3F , F&#38;F and E ~Srx F . The garbage collection rule we have given is just \na specifi\u00adcation of an algorithm, saying what has to be done: paz- If F&#38;F then, 3E , E~E and E =S= \nF . tition the program in some way into the useful bindings Where=S z isthe composition of the three \nbinary rela\u00ad  and the garbage ones. It does not say how to do it. We tions E, S and z. are now going \nto present two algorithms to achieve this partitioning. Lemma 6 If S is a strong bisimulation up to =, \nthen  4.1 The Free-Variable Tracing Algorithm We have as a model a two space copying garbage collec\u00adtor. \nThe collector traverses the graph of the computation (the from-heap) putting all reachable objects into \na to\u00adheap. The traversal is started from a set of roots, and the addresses of objects reachable but not \nyet moved to the to-heap are kept into a scan set. But what are the roots of the computation? Since we \ndo not want a system-wide copying but only one local to each node. the roots for each node will be the \nfree vari\u00adables in the thread expression (corresponding to the lo\u00adcal stack ) and all variables bound \nlocally but referenced globally (since a remote node may want to access the val\u00adues they are bound to). \nIn our model this is done as follows: first we define the ( an) relation (see Figure 8). The + relation \nis the reflexive and transitive closure of +. The from-heap is Zlf, the scan set is S and the to-heap \nis H~. The process works as follows: a variable (say z) is chosen from the scan set. Then, x s binding \nis moved into the t~heap. The value z was bound to may have free variables; we add to the scan set only \nthose variables which are bound in the remaining from-heap. There are two classes of variables which \nmay occur free, but are not added to S: variables which are bound in remote heaps, and variables which \nare bound in the to-heap. The former are not added to S in order to keep the garbage collection local; \nas such, it does not propagate to other nodes. The latter variables have aheady been considered reachable, \nand retained. It is easy to see that the scan relation can only be ap\u00adplied a finite number of times, \nsince each application de\u00adcreases the size of the from-heap. This also guarantees that S will eventually \nbecome empty if initially it is composed only of variables from Dorn(from-heap). The algorithm to collect \ngarbage is specified by the re\u00ad lation (~) from Figure 8. It specifies that scanning is started with \nthe local heap H as the from-heap, the scan set is composed of the roots of the computation, and the \nto-heap is empty. After scanning is finished (the scan set is empty), the live data is in H and H contains \nonly garbage. The (~) relation still doesn t specify how the root set is computed but only what it is \ncomposed of. In an actual implementation, the first part, FV(Z ), is obtained scanning the stack. The \nother part, FV(&#38;[ ]), is maintained during computation. This can be done for example by using a variant \nof reference counting which uses lists of sites referencing an object (instead of a simple count of them). \nEach site maintains a list of potential incoming and outgoing references, called the entry table and \nexit table respectively. Both tables are conservative estimates. When a pointer is exported, the entry \ntable on the local node and the exit table on the remote node are updated (if necessary). Each local \nGC cleans the exit table of useless entries. In turn, exit tables are used to clean remote entry tables, \nyielding successively better estimates. More details about this method can be found in [12] It is important \nto note that these steps can be described in our framework (the domain of the transition relations can \nbe augmented with sets for these tables). However, in\u00adcluding them would have made the presentation less \nclear. Theorem 3 establishes the correctness of the algorithm. Theorem 3 (I%) ~ (&#38;). The proof can \nbe found in the appendix.  4.2 The second free-variable tracing algo\u00adrithm The idea of the second algorithm, \npresented in Figure 9, is that we can also use object migration to help collect inter\u00adnode garbage cycles. \nWe start from the free variables in the local thread. The heap is partitioned in locally acces\u00adsible \ndata H~ and locally inaccessible data Hi. The latter is further partitioned into data accessible from \nthe entry tables H,, and garbage H9. Note that H, is only ref\u00aderenced from other nodes. Objects in H, \nare potentially part of garbage structures (possibly including cycles) span\u00adning multiple nodes. But \nthen, if we migratel 27,, say to a node which references it, the resulting program is bisim\u00adilar with \nthe original program. However, the new program has shortened the length of at least one garbage cycle \n(if it spanned the node garbage collected). We do not claim that this algorithm guarantees the collection \nof cyclic garbage spanning multiple nodes; improvements of the algorithm to make it guarantee such a \ncollection are beyond the scope of this paper. Here, we are only interested in showing how a proof of \ncorrectness can be given using the model devel\u00adoped. Theorem 4 (M) ~ (~). The proof can be found in the \nappendix. It may appear surprising that we didn t have any dead\u00adlock considerations in our proofs. Note, \nhowever, that our proofs rely on the transitions being atomic. An even lower\u00adlevel implementation of \nthe second algorithm would have to address how fuc can assure that sending and receiv\u00ading parts of the \nheap can be achieved atomically, so as to avoid deadlock, or inconsistencies, caused by two nodes simultaneously \ninitiating ~ towards each other. Such a lower-level implementation might employ for exzunple a simple \ntoken protocol for achieving this: before initiating ~ a node requests the token (only one token exists \nin the system). When it receives the token, it sends H, and update messages to all nodes which reference \nit. After it receives acknowledgments that the data has been received, lThis migration necessitates sending \nmessages to all remote nodes having references to that part of the heap, to inform them of the new destination \nof their references. Figure 8: The algorithm fua (SWL) (Hf w{X= h}, su {X},lft) An (Iff, Su(Fv(h) nllO~(l+ff)), \nJY, w {Z = h}) (recv~ ) &#38;[((H, 2 ))] ~Hr t[((ll w H,, 2 ))] if Dorn(H) n Dom(lI, ) = 0 and H. # O \n(send~) t[((lff, T ))] IX S[((H~, T))] if (fIf, IT (Z ) n Dorn(Hf), 0) = (lIi, 0, Ht) and (Hi, FV(&#38;[ \n]) n Dom(Hi))O) = (Hg, O,H.) (fuc) &#38;@]&#38; &#38;[E ] if &#38;[E] N &#38;[E ] (fvc) &#38;[E o F] \nw &#38;[E @ F ] if &#38;[ll @F] ~ &#38;[E @ F] and S[E @ F ] ~ E @F Figure 9: The algorithm fvc it releases \nthe token. Thus, Iiveness is guaranteed. Note garbage collectors. In these systems, the collector is \nal\u00adthat no such considerations are necessary for the first al-lowed to proceed in parallel with the mutator, \nbut other\u00adwise the mutator itself is not distributed. The first garbage gorithm, since the ~ rule does \nnot involve two nodes. collector of this kind is that proposed by Dijkstra et al. [3], It is only these \nlower-level implementations that would together with a proof of correctness. Ben-Ari [I] improves make \na sharper distinction in their proofs between the local on the algorithm and simplifies the proof. and \nremote communication relations. There has been considerable more work on proving cor\u00adrectness of sequential \nprograms with state. The work which 5 Related Work inspired our paper is that of Morrisett et al. on \na syn\u00ad tactic theory of memory management [10]. The theoret-There are many papers describing distributed \ngarbage col-ical background of their treatment is given by the work lection algorithms. However, most \nare concerned with pre-of Felleisen and Hieb [4], who extend the Ao calculus of senting the algorithms \nrather than proving formally their Plotkin [11], to a calculus called A.-S, suitable for rea\u00adcorrectness. \nExample of such papers are [6, 7, 12]. Hudak soning about state and control in sequential programming \nand Keller describe in [6] the marking-tree coUector, suit-languages. While in [4] an important effort \nis made in able for a real-time distributed garbage collector. This col-their model to avoid the garbage \ngenerated during compu\u00adlector, of the tracing kind, is capable of also deleting irrel-tation, in order \nto obtain a clean equational reasoning, evant processes and dormant subgraphs. Hughes describes in [10] \nthe main topic is exactly that garbage. Using the in [7] a collector for a distributed mchitecture. His \ncollec-model developed for a typed language with polymorphism, tor, capable of collecting garbage cycles \nspanning multi-they were able to prove formally that some reachatde data ple nodes, uses time-stamps \nto coordinate local collections is garbage (it will never be accessed). This property was with the global \nones. Shapiro et al. [12] describe a pro-previously reported [5], but its proof was less formal, tocol \nfor garbage collection in a fault-tolerant, distributed The communication model in our language is based \non object-oriented system. Given the complexity of these al-Milner s CCS [8]. A full description of CCS \nand its proof gorithms, and the low level of abstraction at which they methods is [9]. Our calculus also \nhas some similarities with are presented, the proof of correctness is too complex to the ~-calculus proposed \nby Boudol in [2]: his r-actions, on be given formally (however, in the papers mentioned proof which the \nevaluation of the language is based, corresponds sketches are given). More importantly, the proofs given \nto our unobservable transitions. However, the goal of his are ad-hoc, and involve proving both high-level \ninvariants, paper is to develop a calculus for communicating systems such as accessible nodes are never \ndeleted , with low-level which has A-calculus as a sub-calculus. invariants concerning local state (e.g. \ncorrectness of time stamps). By contrast, our approach permits the specifica\u00adtion of the algorithms at \na higher level of abstraction, while 6 Summary and future work still allowing for a refining of the implementation \ntowards A strength of our model is that, being high-level, the var\u00adlower-level details. ious correctness \nproofs can be given formally in a concise Proofs of correctness have been given for concurrent manner, \nHowever, the atomicity of the transitions in the examples provided is too coarse. This can be addressed \nwithin the model developed by allowing the transitions to be more fragmented; for example the communication \ntran\u00adsition may be split in its two components, sending and receiving, with a way of recording that a \nmessage is in trsmsit . Also, the garbage collection may be allowed to proceed in parallel with the computation \neven on the same node (as described in [3]). This can be achieved by raising the scan relation to a transition \nin the language, together with a way of synchronizing the mutator with the collec\u00adtor. However, the more \nrefined the models are, the more complicated the proofs become. An interesting extension of this work \nis to take into consideration various faults which can occur in distributed systems. To this aim, relations \ndescribing specific faults (e.g. a communication relation where the message is not received at the other \nnode) can be added to the garbage collector relation. Proving that the algorithm implement\u00ading the garbage \ncollector preserves bisimilarity even in the presence of these relations would be proof that the collector \nis resilient to these failures. A Proofs Lemma 5 Relation z is an observational bisinaulation. Proof. \nWe have to show that: E~Fand Ed E @ 3F s.t. F% F and E = F , where a E {cti, ~i}. We show this by induction \non the length of proof of E $ E . E % E becauseE #+ E . ButEz F implies 3F .F ~ F andE z F . It follows \nthat F &#38; F and E = F . . E ~ E because 3E .E ~ E and E d E , where b . {comp, comml, comw, ifo, ijl, \nsum). But E z F implies 3F .F ~ F and E z F . Using the induction hypothesis, jrom E ~ E and E z F jollows \nthat 3F .F ~ F and E z F . . E ~ E because 3E .E &#38; E and E ~ E . from the induction hypothesis, we \nhave that 3F .F ~ F andE = F . from E = F and E ~ E jollows that 3F .F ~ F and E z F . Definition 11 \n(The sub-heap relation, CH) E ~~ F iffHeap(E) ~ Heap(F). Theorem 3 (W) ~ (~). Proof. Suppose E @r F; \nwe have to show that E ~ F, F ~H E andFV(F) =0. We jirst show that the jollowing invariants are preserved \nwhenever (Hf, S, Ift) an (H;, S , H() 1. Hj U Ht =Hi U H:. Obvious. 2. S U Dom(H~) ~ S U llom(llo. It \ncan be seen that  ~ removes a variable x jrom S only when it adds a binding x = h to Ht. ~ [FV(Rng(Ht)) \n~ Dom(H,) USU (FV(H)) ] ~ [FV(Rng(Hj)) ~ Dom(H() US U (FV(H)) ] Consider an arbitray element z E FV(Rng(H{)). \n. If z ~ FV(Rng(H~)), the conclusion follows from the induction hypothesis and invariant 2. . Ifz E FV(h)\\FV(Rng(Ht)), \nwe have the joliow\u00ading cases: z @ Dom(H), but then z E (FV(H)) z E Dorn(H) = Dom(Hf) w Dom(Ht\\. If zG \nDom(Htj we are d~n~. Ifz G Dorn(Hfj then z E (FV(H) fl Dom(Hf)), hence z E s . E~F is obvious since \nthe thread part is unaffected by this transition. F ~H E is derived easily from invariant 1. FV(F) =0. \nConsider E = &#38;[((H, T))] and F s &#38;[((H , z ))], where (H, (FV(Z )UFV(&#38;[ ]))flH, 0) t (H , \n0, H ). Initially, H~ = 0, so FV(Rng(Ht)) ~ Dorn(H~) U SU (FV(H)) is trivially satisfied. Since invariant \n3 proves the correctness oj the induc\u00adtion step, it jollows that J V(H ) ~ FV(H) =0.  Theorem 4 (~) \n~ (~) Proof We have to show that: if E ~ F for some closed E, thenE~F,F~H EandFclosed. There are two \ncases to consider: . E ~ F because 3&#38;[ ], E , s.t.E ~ &#38;[E ] ~ &#38;[E ]. But ~ coincides with \nM. . E fi F because 3&#38;[ ], E , F , H, s.t. E s &#38;[E oF ] and S[E oF ] efi$r S[E oF ] and E[E o \nF ] e~~ &#38;[E @ F ]. Let E = ((Hf, T)) and F s ((H;, U)). We have: (Hf, Dom(Hf ) fl FV(Z ), 0) ~ (H,, \n0, H,) and (Hi, Dom(H~) n FV(&#38;[ ]),0) = (Hg, O,H,). Consider E ~ E . (Hf, Dom(Hf )n(FV(T)uFV(&#38;[ \n])), 0) ~ (H , 0, H ) It is easily seen that H = Ht U H,. Using theorem 3, &#38;[E 0 F ] GCI E and FV(S[E \n @ F ]) = 0. On the other hand, Heap(E @ F ) = Heap(E @ F ). The conclusion follows using simple properties \nof jree variables.  [1] M. Ben-Ari. Algorithms foron-the-fly garbage collec\u00adtion. ACM Transactions on \nProgramming Languages and Systems, 6, 1984.  [2] Gerard Boudol. Towards a lambda-calculus for con\u00adcurrent \nand communicating systems. TAPSOFT 89 LNC S 351, pages 149-161, 1989. [3] Edsger Dijkstra, Leslie Lamport, \nA.J. Martin, C.S. Scholten, and E.F.M. Steffens. On-the-fly garbage col\u00adlection: An exercise in cooperation. \nCommunications of the ACM, 21(11):966 975, 1978. [4] Matthias Felleisen and Robert Hieb. The revised \nre\u00adport on the syntactic theories of sequential control and state. Theoretical Computer Science, 102, \n1992. [5] Benjamin Goldberg and Michael Gloger. Polymor\u00adphic type reconstruction for garbage collection \nwith\u00adout tags. Symposium on LISP and Functional Pro\u00adgramming, 1992. [6] Paul Hudak and Robert Keller. \nGarbage collection and task deletion in distributed applicative processing systems. Symposium on LISP \nand fictional Pro\u00adgramming, pages 168-178, 1982. [7] John Hughes. A distributed garbage collection al\u00adgorithm. \nIn Ilmctional Programming Languages and Computer Architectures, number 201 in Lecture Notes in Computer \nScience, pages 256 271. Springer-Verlag, 1985. [8] Robin Milner. A calculus for communicating systems. \nLecture Notes in Computer Science, 92, 1980, [9] Robin Milner. Communication and Concurrency. In\u00adternational \nSeries in Computer Science. Prentice Hall, 1989. [10] Greg Morrisett, Matthiaa Felleisen, and Robert \nHarper. Abstract models of memory management. In Functional Progmmming Languages and Computer Architectures, \n1995. [11] Gordon Plotkin. Call-by-name, call-by-value and the A-cafculus. Theoretical Computer Science, \n1:125 159, 1975. [12] Mark Shapiro, David Plainfos%, and Olivier Gruber. A garbage detection protocol \nfor a realistic distributed object-support system. Technical Report 1320, IN-RIA, 1990.  \n\t\t\t", "proc_id": "258948", "abstract": "We develop am abstract model of memory management in distributed systems. The model is low-level enough so that we can express communication, allocation and garbage collection, but otherwise hides many of the lower-level details of an actual implementation.Recently, such formal models have been developed for memory management in a functional, sequential setting [10]. The models are rewriting systems whose terms are programs. Programs have both the \"code\" (control string) and the \"store\" syntactically apparent. Evaluation is expressed as conditional rewriting and includes store operations. Garbage collection becomes a rewriting relation that removes part of the store without affecting the behavior of the program.Distribution adds another dimension to an already complex problem. By using techniques developed for communicating and concurrent systems [9], we extend their work to a distributed environment. Sending and receiving messages is also made apparent at the syntactic level. A very general garbage collection rule based on reachability is introduced and proved correct. Now proving correct a specific collection strategy is reduced to showing that the relation between programs defined by the strategy is a sub-relation of the general relation. Any actual implementation which is capable of providing the transitions (including their atomicity constraints) specified by the strategy is therefore correct.This model allows us to specify and prove correct in a compact manner two garbage collectors; the first one does a simple garbage collection local to a node. The second garbage collector uses migration of data in order to be able to reclaim inter-node cyclic garbage.", "authors": [{"name": "Christian Ungureanu", "author_profile_id": "81542468056", "affiliation": "Department of Computer Science, New York University", "person_id": "P46855", "email_address": "", "orcid_id": ""}, {"name": "Benjamin Goldberg", "author_profile_id": "81100491830", "affiliation": "Department of Computer Science, New York University", "person_id": "PP39045430", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258948.258975", "year": "1997", "article_id": "258975", "conference": "ICFP", "title": "Formal models of distributed memory management", "url": "http://dl.acm.org/citation.cfm?id=258975"}