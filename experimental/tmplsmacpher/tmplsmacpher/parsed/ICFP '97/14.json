{"article_publication_date": "08-01-1997", "fulltext": "\n A Bounds Inference Method for Vector-Based Memorization Wei-Ngan CHIN* Masami HAGIYA National University \nof Singapore University of Tokyo chinwn@iscs. nus.sg hagiya@is.s.u-tokyo. ac.jp Abstract The dynamic-sized \ntabulation method can be used to elim\u00ad inate redundant calls for certain classes of recursive pro\u00ad grams. \nAn innovative aspect of the method is the use of lambda abstractions that may subsequently be converted \nto bounded vectors, in order to share redundant calls via vector lookup. To facilitate this conversion \nto vector form, we propose a new inference method to conservatively determine the bounds for arithmetic \nparameters of recursive functions. Suitable techniques for inferring the safe bounds of these parameters \nare introduced, together with supporting transformations. The resulting method can obtain efficient vector-based \npro\u00ad grams without the need for run-time bounds checking, Introduction Redundant calls frequently occur \nin recursive programs caus\u00ading run-time inefficiency. Two examples are: fib(n) =cmen Of{ O-+l; l~ 1; \nm+2 * fib(m+l)+fib(m) } bin(n,k) = case n of{ O+ 1; m+-1 -if k<o or k~n then I else bin(m,k-I)+bin(m,k) \n} Program transformation techniques can be used to elim\u00ad inate some of these redundant calls. Where successfully \napplied, they can deliver a.symptopic improvements to the time-complexity of these programs. A classic \nfold/unfold transformation tactic that could achieve this is called tu\u00ad piing [3, 14], with an automated \nversion presented in [4]. This particular tactic is capable of eliminating the redun\u00ad dant calls of naive \nfibonacci definition via a static-sized tu\u00ad ple of two calls (fib(m+l),fib(m)), but it is unable to handle \nthe binomial function which requires a dynamic-sized table of memoized results. The difference between \nfib and bin can be seen in the first two call dependency graphs (DGs) in Fig. 1. While Part of this work \nwss done while the first author was visiting In\u00adstitute of Information Science, Academia Sinica, Taiwan, \nand Hitachi Advanced Research Laboratory, Japan. Permasslon to mame cltgltallhard copy ot part or all \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor profit or commercial advan\u00ad tage, the copyright notice, the title of the publication and its date \naPPear. and notice is given that copying is by permission of ACM, Inc. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. ICFP \n97 Ams~erdam, ND @ 1997 ACM 0-89791 -918 -1/97 /0006,,. $3,50 the width of the DG for fib is kept at \ntwo calls, the width of the DG for bin increases, the further it is from its root. As a result, dynamic-sized \ntable is needed to compute the binomial function in a non-redundant fashion. In particu\u00adlar, each row \nof calls can only be computed, without redun\u00addancy, from a slightly larger row of calls down the recur\u00adsion. \nFor example, bin(rr,k) requires the results of two calls, bin(n-1 ,k-l),bin(n-l,k), which in turn require \nthe results of three calls, bin(n-2,k-2),bin(n-2, k-l), birr(n-2,k), and so on. To widen the class of \nprograms that could be tabulated, we previously proposed a transformation method [6] which uses two additional \ntactics, named: (i) lambda abstraction tactic, and (ii) vector conversion tactic. The lambda abstraction \ntactic is used to lift out problem\u00adatic accumulative parameters whose functions are rejected by the tupling \ntactic of [4]. A parameter is said to be ac\u00adcumulative if it syntactically becomes larger with successive \nrecursive calls. An example is the second parameter of bin. Though this parameter s value decreases with \nsuccessive re\u00adcursive calls, its symbolic form actually becomes syntacti\u00adcally larger when the call of \nbin is repeatedly unfolded dur\u00ading program transformation. In contrast, the first parameter of bin shrinks \nor remains the same size (syntactically) with successive unfolding of the recursive calls during transforma\u00adtion. \n(We rely on pattern-matching case construct to ensure this non-accumulating property. ) Accumulative \nparameters could cause successive tuples to have increasing number of calls during transformation, as \nindicated by DGs with increasing width. This can cause tupling to be non-terminating -an effect similar \nto infinite specialisation in partial evaluation [10]. Our remedy is to lift out accumulating parameter(s) \nvia the lambda abstraction tactic. This has the effect of currying the lifted parame\u00adter(s), as can be \nseen for bin, as outlined below. ; Apply Lambda Abstraction Tactic (to lift k) bin(n,k) = let { bin (n) \n= case n of{ O ~ fik ~ 1); m+l ~ fik~ ifk<Oork~n then I eke bin (m) (k-1) + bin (m)(k) ) } } in bin (n)(k) \n; Apply Tupling Tactic (to share bin (m) call) =let{bin (n) =casenof{O~fik~ l); m+l ~ let z= bin (m) \nin flk-+ ifk<O ork~rr then 1 else z(k-l)+z(k) ) } } in bin (n)(k)  After lifting the accumulative k \nparameter, our new bin function will be in a form that could be accepted by tupling, as evident from \nthe fixed-width DG of bin calls in Figure 1. 176 bm [n) R  4 ............................-.........-....-.U \n 4 ...........   increasing width fixed width bd(n-1) Q bm (n-z) 9 +. ----\u00ad fixed width Figurel: Dependency \nGraphs Note also that tupling simply shares the two function\u00adtype bin (m) calls via a local z variable. \nHowever, unlike ground-type calls, the sharing of function-type calls is only effective if their functions \nare being memoized. Given a func\u00adtion of type A+ B,we could either memoize its mapping via a list of \ntype [(A, B)], or via a vector of type Array A 1?. The list implementation is more general but suffers \nfrom a higher lookup overhead. Where possible, we advocate the use of the vector conversion tactic, to \nreplace lambda ab\u00adstraction by a bounded vector. A crucial requirement is that the lambda abstraction \ns parameter(s) must be of vector in\u00addex type. A vector indez is either an enumerated type or a jinitely \nbounded integer type, or a tuple of such types. Such types have finite sets of ordered values which are \nsuitable for use as indexes to bounded vectors. The method for inferring sa}e parameter bounds was a \nmissing puzzle in our previous work[6]. However, it is very crucial towards the automation of vector \nconversion. We propose a collection of systematic techniques to infer sate bounds for parameters of recursive \nfunctions. Formally: Definition 1: Saje Parameter Bounds The bounds for a parameter, a,, of a recursive \nfunction, j, are said to be sate if the value for that parameter will never exceed its stated bounds, \nlower < a, ~ upper, for each of Its recursive calls, f(al, ... at, ... an). We are also interested in \nobtaining tighter parameter bounds, where possible. Formally: Definition 2: Tighter Parameter Bounds \nGiven a safe bound mar {/owerl , lower2 } < a,, we say that /owerl is tighter than lower2 if /owe.2 < \nlowerl for all recursive calls encountered. Similarly, given ., < min{upperf, upper2}, we say that upperl \nis tighter than upper2 if upperl < uPPer2 for all recursive calls encountered. With a little insight, \none may propose the following set of safe parameter bounds for the bin function: for fib(n), bin(n,k) \nand bin (n). (O~k~ min{n, kn}) A (k~n~nn) where I ID,kfl refer to the argument values for the very first \nbin call, while (O < N < no) is a required pre-condition for this call. Specifically, (O< k< n) came \nfrom the conditional test for recursive branches, while (k < ko) A (n < no) came from the strictly decreasing \nnature of the two parameters for successive recursive calls. Our proposed bounds inference method can \ndo even bet\u00adter. As we shall see, it can systematically deduce the follow\u00ading equally safe but somewhat \ntighter parameter bounds: (O < ko) A (maz{l ,kfl} < no) implies (maz{o, n -(TLII-ko)} < k< min{n, ko}) \nA(maz{l, k}<n<nu+k-kn) where (O < kfl) A (maz{2, ko} < no) is its pre-condition. The bound maz{O, n \n (no -k-o)} < k s min{n, kn} gives a safe range for the k parameter in terms of the other parameters. \nIt can be used, by vector conversion and related transfor\u00admations, to obtain the following efficient \nO(n x k) definition. Note the adoption of Haskell s primitive functions, array and (!), for array construction \nand indexing. data Assoc ab= a:= b; array :: 1xa => (a,a) * [Assoc a b] ~ Array a b ; bin(n,k) = let \n{nO= n;kO = k; bin (n) =casenof{O~ fik~ 1); m+l A let {z= bin (m) ; bn k = if k<Oor k~n then 1 else \nz(k-l)+z(k) ; i= max(O,n-(nO-kO)) ; u = min(n,kO) ; vec = array (l,u) [a := bn a I a + /_l..u]] } in \n(!) VEX} } inif(0 < kO A max(l ,kO) < nO) then bin (nO)(kO) eke 1 Section 2 introduces a simple language \nand some prelim\u00adinary notations for labelling self-recursive functions. Sec\u00adtion 3 presents the inference \ntechniques for determining the 177 Definition 4: 5el/-Recur.stze Furzchons safe and tightbounds of arithmetic \nparameters of recur- A function, f, is said to be self-recursive if its (mutual) re\u00ad sive functions. \nSection 4 and 5 intrmiuce some transforma\u00ad cursive set of functions is just a singleton set {j}. In par\u00ad \ntion tactics which are needed to support vector conversion. ticular, each self-recursive function definition \nwill have Section 6 contains some performance figures to justify the the following form where m~ 1. bounds \ninference method. Section 7 describes related work before a conclusion. Appendix A rehearses the bounds \nin\u00adference method on yet another example. 2 Language and Labelled Recursion We consider a simple functional \nlanguage: Definition 3: A Simple Language Components of our simple language include: P ::= [M,]p=o (Program) \nM ::= {f, (vi,..., Vn) = tji}~= ~ (Mutual Rec. Set) A ,,= Q + ~ie~.l X .$ (Linear Arith. Term) B::= \nAI<A2 IAI<A2 IAI>A2 IAI>A2 lAl=A21Al#A217B I El A Bz IB1 V Bz (Boolean Arith. Term)  t :;=v(tf,..., \ntn) IC(tf, ....tn) Ij(ff,. ... tn) I let {p, = t,}~=o in t Icase t of {Pi + t,}~=o l\\(~l,..., vn)+t lif \nBlthent2eket3; (Expression) p ::=V Ic(pf,. ..)l%); (Pattern) The expressions allowed include variables \n(.), data con\u00adstructors ( c), integer constants (c), functions (j), let and case constructs and a special \nconditional with boolean arith\u00admetic expression (f? ) which is formed from a class of arith\u00admetic variables, \nmarked as u@. The linear arithmetic terms are ideal for use in Presburger formulae. We shall abbrevi\u00adate \na sequence of terms t~,...,tnby ?, so that a function call j(tl,. . . . tn) can be abbreviated as f (~ \n) or more precisely as j(ti)icl..n. We assume that the langnage s standard semantics is non-strict by \ndefault, with the exception of scalar-type pa\u00adrameters which are aggressively treated as strict. Such \na compromise has been adopted in Imperial College s Hope language [13] which could give good performance \nwithout losing much on expressiveness. The main reason we adopt this semantics is that the vector conversion \ntactic will force parameters that are converted to vector indexes, to be strict. Alternatively, if a \ntruly non-strict semantics is adopted, we must use a strictness analyser to ensure that parameters are \nstrict before they are selected by the vector conversion t attic. Our language is a near first-order \nlanguage, with some residual higher-order features. Programs of this restricted form can be obtained \nvia the higher-order removal method proposed in [5]. This method can remove most higher-order functions \nby either junction specialisation or eta-abstraction until programs of the above form remains. The residual \nhigher-order features are either inherently higher-order or have complex control dependencies that may \nbe ignored by our analysis. Adopting this restricted language considerably simplifies our present ation, \nwit bout much loss of generality. In particular, we can avoid the more complex control depen\u00addencies \npresent in certain higher-order programs. For simplicity, our bounds inference method shall be for\u00admulated \nfor self-recursive functions, defined below. M E {j(iq =:(j(t; ),.., f(t; ))} Note the use of a special \ncontext notation, ;(tl,.. ..tm), with m holes for sub-terms, tl , . . . . tm. Though not de\u00adscribed \nin this paper, extension to mutual-recursive func\u00adtions is possible. We classify the variables (both \nparameters and local vari\u00adables) of our functions into two groups, namely: . Arithmetic variables: An \ninteger-type variable is said to be arithmetic if it can be expressed as V@= co + ~,,-~ c, x vt@where \n{V9}i~N are other arithmetic variables. An integer\u00ad ty~e parameter is said to be arithmetic if its change \nacross successive recursive calls can be expressed as above. For clarity, we shall use the @ annotation \nto mark out arithmetic terms and/or variables.  . Non-Arithmetic variables: These are variables that \nare not arithmetic in form (e.g. non-integer variables or integer ones that are not expressed in linear \narithmetic form.). It is straightforward to formulate an analysis to distin\u00adguish arithmetic variables \nfrom non-arithmetic ones. Due to space consideration, we omit its presentation in the present paper. \nTo help formalise bounds inference for arithmetic param\u00adeters, we introduce a labelling scheme to uniquely \nidentify successive recursive calls that may arise from a given func\u00adtion. Definition 5: Labelled Recursion \nScheme Given a self-recursive function j, we shall label each of its recursive calls nniquely as fL( \niiL) where L is the path of the call from the root of its dependency graph (DG). The first recursive \ncall at the root of the DG wilf be labelled as jfl ( ad ). This initial call is also referred to as the \nroot call of j. Its immediate m child recursive calls wilf be labelled as {j[il( till )}Jef ,,m. Subsequently, \neach function call jL( ZL) may have upto m child recursive calls that are labelled as {f :L(d L)}iEl \n,m.  The superscripted suffix, L, given to each recursive call (and its parameters) identifies the position \nof the recursive call within its DG. Also, the recursion level of the calf (dis\u00adtance from the root of \nDG) is #L where # finds the length ~~,: sequence. In accordance with our labelling scheme, and a2 L denote \ntwo different argument values, while jl:Landj2:Ld enote two different call instances of the same function. \nFor example, the root call of bin is denoted by binfl(nu, k[l). Its two recursive calls children in its \nDG are denoted by birr{ll (nI1l, kI1l ) and bini2{~(n[zl, k[z ). This pair of calls in turn can result \nin four more recursive calls, namely: {bjn[l,ll(n(l,ll, k[l,ll), bin[z,l](n[z,l], k[z.1])} and {bi~121(n11,21, \n1-11,21),bin12,21(n12,21,k[ 2.21)} ~ L, kL) can result in two recursive Cdk In general, each bm (n labelled \nas binl L(nl L, kl L) and bin2 L(n2:L, /c2 L). Based on this labelling scheme, we can annotate, in a \ngeneral way, the parameters and recursive calls for the bin function definition, as follows. 178 binL(n \nL,k L)= casenL of{ 0-1; m+l+ifk L<lJork L >nLthenl else binl L(m, kL -l)+bin (m, kL)} Notice that the \nparameters of binL function call are named nL and kL. Also, there are two recursive calls which can be \nwritten as: binl~(nl:L, kI:L) . binl:L(m, kL 1) and bin2:L(n2:L, k2 L) a binl:L(m, kL) since they are \nthe children of the biz# (nL, kL ) call. Hence, the above two recursive calls have argument values: \n ~nj~:;fl=n - ,: L=kLk}andand nL-f, k2:L = kL}, respectively. 3 Bounds Inference Method We shall now \npresent a bounds inference method which is made up of four main techniques: Procedure 1: Bounds Inference \nMethod To infer the safe bounds of arithmetic parameters, we perform the following: (1) Determine a backward \nparameter substitution for each recursive call. (2) Determine an individual constraint for each recur\u00adsive \ncall. (3) Determine a unijied constraint for all recursive calls. (4) Determine a monotonic constraint \nfor each mono\u00adtonically decreasing (or increasing) arithmetic pa\u00adrameter, as well as for groups of such \nparameters.  The four techniques together are aimed at accumulating safe bound constraints on the arithmetic \nparameters of self\u00adrecursive functions. The inference techniques are presented next, using bin as an \nexample. 3.1 Backwards Parameter Substitutions Consider a recursive function j with arithmetic parameters \n{a~}jcN. For each recursive call of {f L(Z :L)}ief,, m, we can obtain a set of forward substitutions \n(for arithmetic ar\u00adguments F L) of the form: By solving the linear equations of the above forward sub\u00adstitutions. \nwe can obtain backward substitutions of the form (z~ejv ai L X C~k)}j~N. We shall denote such a backward \nparameter substitution by Bf (i : -C)for each re\u00adcursive call, ft ~(~i:~). For the bin function, the \nforward substitutions are: ~b~n(~ ,~) ~ {n] L = n~ lj/c1 L = kL 1} Fb1n(2 :~) ~ {nz L = nL I,k* L \n= kL} which are obtained from the two recursive calls of bid L and bin2 , respectively. After solving \nthe two sets of equations, we obtain backward substitutions: {aj = Cj(? +~ Bb,n(l :L) s {n~ = nl L +1, \nP =P L +1} Bbin(2 :L) s {nL = n2 L + l,kL = k2 L} 3.2 Individual Constraints The second technique is \nto determine constraints of the z L < ~pperj for each of the recursive lou,erj < aj _ form Al ~N calls, \n{j~~(z~ ~)}tcl m. Our technique consists of two steps. Consider a function j with m self-recursive calls: \nIn the first step, we determine a valid constraint, called the contezt constraint, for each of the self-recursive \ncalls, Context constraints are based on the {.f : L(Z* L)}icl..m. particular contexts of individual self-recursive \ncalls. We denote the context contraint of call j L ( 7i:L) by Cf(i :L). Each of these context constraints \nis made up of a conjunction of boolean arithmetic terms on the arithmetic parameters of dL. (Non-arithmetic \nparameters are ignored.) The infer\u00adence rules to gather the context constraints are given in Fig\u00adure \n2. Apart from gathering the context constraint of form C L B for each recursive call (marked by jL), \nour rules J(So g a~her relevant contexts of form c (v) ~ B for each vari\u00adable, rJ. This is to allow context \nconstraints to be inferred also for arguments of function calls and let abstractions. No fix-point iteration \nis necessary since our inference is not per\u00adformed beyond mutual-recursive function talk. Note how rule \n(4) simply glosses over its mutual-recursive call, while rule (5) attempts to infer beyond the non mutual-recursive \ncall it is handling. Consider the binL function definition. Based on the given inference rules, we can \ndeduce that nL = o is a valid con\u00adtext for the first case branch; while (nL =m+I) A(m > O) is a valid \ncontext for the second branch. Under the con\u00adtext of the else branch (of the if conditional), we also \nhave (kL > O) A (kL < nL). As the two recursive calls (of binl L and bin2: L ) lie inside the same context, \nwe have the fol\u00adlowing context constraints, expressed in terms of the LHS arithmetic parameters, kL, \nn~. cbln(l , ~) ~ cb,n(2 : ~) E (nL=rn+l)A(m~O) A(kL >O)A(kL <nL) In order to proceed further, we must \nsimplify and nor\u00admalise the boolean arithmetic terms. Initially, the local arithmetic variables are eliminated \nvia their substitutions. After this, the normalisation rules (modulo associative and commutative properties \nof +/x) in Figure 3 are exhaus\u00adtively applied until the boolean arithmetic terms are in a canonical form. \nSpecifically, the above context constraint normalises to: Cb~n(l : L) ~ Cbtn(2 , L) S(-nL+l <O A(-kL+l \n<O)1 A(kL n +1 <0) In the second step, we re-express the context constraint in terms of arithmetic parameters, \nN: , of the correspond\u00ading recursive call, fvL( # L). This results in individual call constraint, denoted \nby If (i : L). Formally: where Cf(i :L) is the context constraint for ji L( Z L), and Bf(i : L) is its \nbackward parameter substitution. In the case I con~tr~nts me increming used by language ~se=hem in heir \n attempt at making further advances in program analyses and opti\u00admization techniques. For example, TaImno \n[16] advocated their use in the generalized partial computation met hod to help achieve a greater level \nof program specialization. 179 (0) 6P = ~WAc[tf] True lf(vl,..., ul)=tf EP] (I) AC[v(tl,..., tn)]B = \n{C(U)= B} u U;=l -4c[G] ~ (2) (3) AcIC(tl,..., Ac[(\\(u~,..., tn)] B vn)+ t)] B = = u:= AC[t~ Ac[t,] B \nB (4) (5) Ac[fL(tl,..., Ac[f(tl,..., in)] B tn)] B = {Cf(L) . B} u U;=l Ac[tt] B = U;=l Ac[~d (B A V \npc v.,, p) where Var, = {p I (C(~~) . P) 6 (@PVl)}[t:/Vtlt f(v~,..., vn)=f.f E P Gl.. n (6) Ac[if b@ \nthen tl else t,g] B = Ac[tl] (BA b) UAc[tz] (B A =b) (7) (8) Ac[case Ac[-e b@ of {pi ~ t,},eN] t of {P, \n-+ ~t},ENl B B = = &#38;N Ac[~] AoIGI (BA(b =P,)A(VV B u U,EN Ac[G] ~ G P,. o s v)) (9) Ac[let {v, = \nt1}3EN in t] B = Ac[t] B U U, EN, Ac[til (B A Vp=v.r, where N! = N M M = {i I i 6 NA]sArith(t,)} B = \nB A (AiEM Vi = ti) Var, = {P I (c(w) . P) EL} Vi EN L = Ac[t] Trueu U,~~Ac[t,] p) True Figure 2: Context \nConstraints Inference for Program F of bin function, we can obtain the followiruz two individual For \nthe root call, \\Ll( d] ). we can alwavs use a twe-condition call constraints: to guarantee that-the &#38;ified \nconstrti-nt holds-for this call. Ib$n(l : L) . ( nl ~ SO) A ( kl ~ ~ O) We denote such a pre-condition \nby U; s ( Uj Bj (0)) where A (kl ~ + 1-nl L ~ O) B ((J)s {z = ;fl} and d] denotes the arithmetic parameters \n1b,n(2:L) ~ ( n2 ~ <0)A( k2 L+1~ O)A(k2:L _ n2,L < 0) o{ the root call. For the non-root f calls, we \npropose two approaches Using Bledsoe s SUP-INF proce~ure [2], we can project to obtain unijied constraints, \nthat are as tight as possible. the above two constraints as bounds on the k and n param- They are (i) \ndeductive approach, and (ii) inductive ap eters, giving: preach. Both approaches use the same set of \ninference rules lb,n(l :L) ~ (maz{l, kl L + 1} ~ nl L) to unify bounds constraints, given in Figure \n5. (Note that A (O< kl L < nl L -1) T and L are binary operators for finding maximum and min\u00ad 1&#38;n(2 \n: L.) ~ (maz{l, k2 L} ~ n2 L)A(l < k2 L ~ n2 L) imum values, respectively. ) In addition, the inductive \nap-As the bounds constraints are specified over the respec\u00ad proach is allowed to use an induction hypothesis \nin its as\u00adtive parameters of each recursive call, we can omit the suf\u00ad sumption set. However, this hypothesis \nwould have to be fixes given to the parameters, without any ambiguity. Hence, predicted in advance, We \nshall propose a simple but effec\u00adwe have: tive prediction strategy later in Section 3.3.2. ~b,n(l,L) \ns (mar{ l,k+l}< n) A(O~k~n 1) 1b,n(2:L) z (rnaz{l, k}~n)A(l~k~n)   3.3.1 Unified Constraint by Deduction \nThe SUP-INF procedure has to be enhanced to obtain bounds that are as ti~ht as Dossible. A set of tight \nbounds One way of obtaining a unified constraint, which holds for checking rules, given ~n Figure 4, \nallows arithm&#38;ic bounds all non-root calls, is to deduce it directly from the individual to be ordered, \nwhere possible. tail constraints. Formally, we have: VL.Vi E f..m. lf(i :L)-+ Uf 3.3 Unified Constraints \n The above proposition is equivalent to: With the help of individual call constraints, we can proceed \nto obtain a unified constraint, denoted by Uj, that would be valid for all self-recursive calls, namely: \nHence, to infer an appropriate unified constraint, U f, we can apply deduction steps to the disjunction \nV,El ,,m If (i : L). Our deduction attempts to obtain unified constraints that This unified constraint \nmust be safe and should be as are as tight as possible. In the case of the bin function,tight as possible. \nSpecifically, we must show that it holds for we can apply deduction to its individual call constraints, \nas all the recursive calls of j, with an exception for the root call. shown below: 180 ( 4, ;. .42) \n+ (~~ < .41) (.4, <.42)= (~,+1<.42) (A, ZA2)+ (A2 <AI) =(AI =Az)a (A, #Az) =(A1 ~ A,)a (A1 > A,) -(AI \n# A2) ~ (AI = .42) 7(BI AB2) + (-+?,) v (-B2) T(B1 V ~2)~ (-~, ) A (TB2) -.!(-+3) * B Al #A2~ (AI <A, \n)v (A] >A2) B A (v,eM B:)+ vtE# A B:) (Al < A,)a (Al+ (-lx A2))~0 (A1 =A2)~ (A1+(-lx A2))=0 A+cIxv+c2xv \naA+ (CI+C2)XU A+ Oxv~A A+CX (~teMCt x~i)a A+ (~, EM(cx c,) x t) Figure 3: Normalisation Rules for (Boolean) \nArithmetic Terms (C, XW)+A, <( C2XV)+A2 (0<.4, )A(Og A2) A1<((C2-C1)XV)+A2 05 A1+A2 Figure 4: Tight Bounds \nChecking Rules Vi E 1..2.1btn(i : L)  Ib,n(i:L)+ V6.2 +(mGz{l, k+l}~n) A(O<k~(n 1)) V(max{l, k} < rz)A(l \n~ k< n) F (min{rnaz{l, k + l}, rncm{l, k}} f n) A (rnin{O,l} < k < maz{n l,n}) I-(tmm{l, k} < n) A(O~ \nk< n) This results in the following unified constraint for the two arithmetic parameters of bi~. ~b,n \n(rrl.~{~,k}< n)A(O <k < n) Effectively, this set of constraints has been shown to hold for all non-root \ncalls of bin. Also, to cover the root call, we can simply add a pre-condition (suitably optimised) to \nthe unified constraint, as follows: Ub,n . (maz{l, k~} < n~)A(O < k[l) implies (rnaz{l, k} <n) A (O < \nk< n) 3.3.2 Unified Constraint by Induction Occasionally, the deductive approach may fail to obtain \ntight bounds for the unified constraint. In this case, we can resort to an inductive approach, based \non the following formula: VL. Vi. (Uf Bf(i :L)) A ~j(~ : L)-+ U~ This formula assumes that b f holds \nfor a prior recur\u00adsive call f~ ( 7L), and is only valid when the same constraint holds for all subsequent \nrecursive calls {fi L( ;i ~)},~l ,,m. Such use of an induction hypothesis can provide additional power \nfor our inference method. However, one may justifi\u00adably think that it is non-trivial to predict plausible \nconjuncts that could be used as induction hypothesis of Uf. To rectify this difficulty, we propose a \nunique strategy that combines both the deductive and inductive approaches. We begin with the deductive \napproach to find suitable bounds for the unified constraint. Some of these bounds will be im\u00admediately \naccepted since they hold for all the recursive calls via deduction. Other bounds may be contradictory \nand can be immediately rejected. Between these two extremes, we may find bounds that are not accepted \nby the deductive ap\u00adproach but could be candidates for the inductive approach. In the case of bin function, \nall the bounds obtained via deductions could be immediately accepted for the unified constraint. To better \nhighlight the inductive approach, con\u00adsider another classic problem : Given n items of positive weights \nand a knapsack which can be filled with selected items up to a total weight of w, maximise the value \nof the knapsack. The maximum value for this knapsack can be specified in the following definition where \nweight(i) and value(i) are constant expressions for the weight and value of the i-th item. knap(nL, WL) \n= casenLof{O~O; m+1~ if WL < weight(nL ) then knapl L (m, WL) eke max(kna~ L (m, w~), knap3 L (m, wL-weight(nL))+ \nvdue(nL)) } The backward parameter substitutions for the three re\u00adcursive calls are: 2 Such expressions \nwith unknown constsnts sctuslly violate the Presburger arithmetic form. In order to handle them correctly, \nwe shall treat them as unique (arithmetic) vsriablss whose bounds need not be inferred. 181 %wp(l : \nL) = {nL = TZ] L+ I,J = IJ L} Bknap(2 : L) z {nL = n2 L + l,WL = W2 L} 13kn.p(3 : L) = {nL = ?13 L+ 1 \n, WL = W3 L + weight(n3 L + 1)} Using the second inference technique, we can obtain the following individual \ncall constraints: lknaP(I :L) E (O~ n) A(w < weighf(n + 1) 1) 1knap(2 : L) s (O ~ ?~)A (IJ~ ~) 1knaP(3: \nL) E (O ~ n) A (wet9ht(n + 1) < ~) An attempt to obtain a unified constraint via deduction results in \nthe following: Y,61,.3 Zknap(i L) + (min{O, O,O} < n) A min{ co, O,weight(n + 1)} ~ w ~ rnaz{weight(n \n+ 1) -l,co} t_(O~n)A-co<w<oa In the above deduct=n, the conjunct o s n was immedi\u00adately accepted. However, \nthe bound -co < w s co is useless Figure 5: Deductive Rules to obtain Unified Constraints since its \ncondition is true for ysis. Nevertheless, during the some (disjunctive) bounds on vidual call constraints) \nwhich powerful induction mechanism all parameters without anal\u00adabove deduction, there were the parameter \nw (from indi\u00admight be accepted if a more is available. The three disjunctive bounds are: 1. (0<w) 2. \n(weight(n + 1) < w)  3. (w< weight(n + f) f) The second and third bounds contradict each other and \nshould be immediately rejected. This leaves (o < w) as a possible bound for the inductive approach. The \nprocedure for accepting plausible inductive bounds is as follows: Assume that PC is a plausible inductive \nbound. Apply the following deduction to obtain Uf: VL. Vi. (F c Bf(i : L)) A l~(a :L) + Uf If it can \nbe shown that u ~ Pc holds, then Pc is an acceptable inductive bound {or the unified constraint. In the \ncase of knap function, we add (O < w) to the induction hypothesis, and re-apply the SUP-INF deduction \nprocedure, as follows: V, EI.,3 ((0< L) ~knap(~ : ~)) A hmp(i : L) b (O < n)A(O <w< (weight(n+l) l))V \n(O<n)A(O<w)V (O< n) A (mwz{O, weight(n + 1)} < w) i-(min{O, O, O} < n) A fnin{O, O, rnaz{O, weight(n \n+ l)}} < w< maz{weight(n + 1) 1,m} +( O<n)A(O<w <co) The presence of (O < w) in the final result confirms \nthat it is an acceptable inductive bound for I!Jj. By adding a pre-condition on the root call, we get \nthe following unified constraint for all recursive calls of knap. Uknap~ (O< nD)A(O ~ w[l) implies (O \n~ n)A(O < w) 3.4 Monotonic Constraints Another source of bounds constraints, called monotonic con\u00adstraints, \ncan be obtained from arithmetic parameters that are monotonically increasing (or decreasing). Formally: \nDefinition 6: Monotonic Parameters A parameter, al, is said to be a monotonic parameter if in each self-recursive \ncall f8:L(aj:L, ... a~:~, ... a~~), we have aj; ~ = ~JL+ e,J where eij is an expression whose sign (positive, \nnegative or zero) is determinable. This param\u00ad eter is said to be monotonically increasing if Vi. .,J \n~ 0; or monotonic~y decreasing if Vi. eij ~ O. The monotonic constraint for f, denoted by Mf, must hold \nfor all calls of f~( ii~). This is made up of a conjunction of inequalities of the form: . (a~ an) for \nmonotonically decreasing parameter, a. . (a ~ au) for monotonically increasing parameter, a. . (~1xal \n+k2xa2s kl xa! +k2xa!) foranarithmetic expression that is monotonically decreasing, with mono\u00ad  tonic \nparameters (or expressions) al, az and constants kl, k2. (k~ x al + ~2 x a2 2 ki x ~~+ k2 x a~)for an \narithmetic expression that is monotomcally increasing, with mono\u00adtonic parameters (or expressions) al \n, a2 and constants kl, k2. To illustrate the above classifications, consider the fol\u00adlowing self-recursive \nfunction. g(z, v)= Q(9(Z 2, Y-I),9(Z I, V+ I)) ; Function g has two monotonic parameters z and y. Pa\u00adrameter \nz is monotonically decreasing, but parameter y is neither monotonically decreasing nor increasing. Neverthe\u00adless, \na linear arithmetic expression x + g is monotonically decreasing, while . + 2y is monotonically increasing. \nSuch relationships can help us obtain new monotonic constraints for our parameters. Monotonic constraints \nshould, of course, be shown to hold for all recursive calls. A general inductive formula for 182 this \npurpose is shown below. Base : (M, B~(o)) Induction : VL. Vi E I..rn. (?vff 13f(i : L)) AAj(z : -L) + \nA f~ where Af (i : L) is an assumption set (of constraints) that is valid for the j) ~ call. To simplify \nmatters, we can just use Af (i:L) ~ I (i :L). While this induction formula is similar to that use i for \nunified constraints, it differs in its reliance on monotonic parameters rather than context constraints \nto predict suitable induction hypothesis. Given suitable monotonic parameter(s), the base case is trivially \ntrue for all their monotonic constraints, while the inductive case follows trivially from the monotonically \nincreasing (or decreasing) properties of the parameters or arithmetic terms. Our main task is therefore \nto find useful monotonic con\u00adstraints. We propose a simple technique, based purely on monotonic properties \nof parameters, to predict suitable mono\u00adtonic constraints. For simplicity, we assume that the mono\u00adtonic \nparameters are of a simpler form: a~ ~ = aj~ + Cij where C,j is a constant. With this simpler form, we \ncan ignore {Af (i : L)},=l. .m in the above induction formula since its monotonic behaviour can be determined \ndirectly, without the assumption set. For single increasing (or decreasing) monotonic parame\u00adters, the \nfollowing technique can find suitable conjuncts for the monotonic constraint. Procedure 2: Handling Single \nMonotonic Parameters Consider a monotonic parameter, a~, whose for\u00ad ward substitutions for the m recursive \ncalls are {ll~ L = aJ4+ Cij}iel.. m where {cij}ief.. m are constants with determinable signs. we allow \nnew conjuncts to be added to Mf under the following scenarios: For example, the two parameters of bin \nsatisfy the mono\u00adtonically decreasing property. Hence, n < no and k < k[l. It is also possible to apply \nmonotonic constraints to a group of two or more arithmetic parameters. For example, given two monotonically \ndecreasing parameters, it automatically follows that their sum is also decreasing. In the case of bin, \nwe have (n + k < rcu+ ko) for its two parameters. This fact follows automatically but does not result \nin tighter bounds. What is perhaps more interesting is that the differ\u00adence of the two parameters might \nbe monotonically decreas\u00ading (or increasing). Exploiting this fact, allows new tighter bounds to be inferred. \nFor example, the difference (n k) is monotonically decreasing since (n 1 L -kl L = nL -kL) and (nz:~ \n kz:~ = n~ kL I ) hold for the two recursive calls. Thus, the conjunct, (n -k s no -k[l), can be added \nto ob\u00adtain tighter bounds. We propose the following technique to predict plausible bounds for two monotonic \nparameters. Procedure 3: Handlzrzg Double ,Vonotonic Parameters Consider two monotonic parameters. al \n, az, defined by   u,61,.2@; L= a;+ %}tcf.m ith {Ctlctz}tcf.m as constants. To find suitable monotonic \nconstraint M for the two monotonic parameters, we attempt to fin i two non-zero values {kl, k2 } which \nsatisfy the following inequalities: AtE=.m(kIx C!I +kz x c82 s 0) AA, E1..2(kj # O) Such a relationship \nis a sufficient condition for the exis\u00adtence of a monotonic constraint (for two monotonic param\u00adeters) \nof the form: (kl xal + kz xaz <kI xau+kz xu:). However, some of these constraints may actu all y be redun\u00addant \n(or looser than existing bounds). To select only tighter monotonic constraint, where possible, we impose \ntwo extra conditions, namely: 2. Minimise mar{ I kf xcl~+kzX ci2 I }i~~..m. The first condition permits \nthe boundary relationship between the two parameters to be detected, and also avoids the summation of \ntwo parameters that are both increasing (or both decreasing). In other words, it forces us to consider \nthe difference (rather than the sum) of the two monotonic parameters. The second condition is to obtain \na normalised set of values for {kl, k2 }. Though the above proposal is presently formulated for two parameters, \nit is straightfor\u00adward to extend to multiple parameters. This can be achieved by regarding previous monotonic \nexpressions as parameters. For the bin example, a tighter constraint for its pair of monotonic parameters \nis (n -k< nu ko). After projecting the bounds on the two parameters, we obtain: MbinE(n nB+kU)<k<kOA~< \nmin{rd-kn+k, nn} ~(n-nu+kU) <k<k[l An<n[l-ko+k Note that the new upper bound of (n < no -kfl+ k) (from \ntwo parameters) is actually tighter than the earlier mono\u00adtonic bound, (n < n[l ) (from one parameter). \nThis redun\u00addant bound can be detected by the tight bounds checking rules of Figure 4, and then eliminated \nas shown above. 3.5 Final Bounds Constraint The final bounds constraint is obtained by combining the \nunijied and monotonic constraints, as follows: BOUNDSf ~ Uj AMf In the case of bin function, the combined \nbounds con\u00adstraint for k, n is:  BO UND.$ bin s (O < kn) A (maz{l, ko} ~ no) implies (O< k<n) A (?naz{l, \nk}< n) A(n<nu kO+k)A(n (nD kB) <k<k[l) s (O < ku) A (maz{l, kn} < n[l) implies rnaz{O,n -(no -ko)} < \nk < rnin{n, ko} A rnaz{l, k}<rt<no-kn+k The bound, rnaz{O, n -(no ko)} < k < min{n, ku}, is needed when \nour tactic introduces a lambda abstraction with the k parameter. The bound, rnaz{l, k} < n < no kfl+ \nk, is use\u00adful under a different scenario should a lambda abstraction with the n parameter be introduced \ninstead (see Section 5). 183 4 Supporting Tactics With the bounds constraint for the various parameters, \nit is possible to proceed with the vector conversion tactic [6]. However, two basic supporting transformations \nare needed, namely: 1. The pre-condition U~](~ Uf Bf (lJ)) must be explicitly added for the root call. \n 2. Initial arithmetic parameters of d] may have to be made available to zdl recursive calls. Consider \na self-recursive function f: ~(o = $(.f(~; )! ..>f(~~)) To incorporate the pre-condition, we introduce \nan iden\u00adticaf local function and add ~~], as follows: ~(~ = ~e~{ f (~ = ~(j (~~),..,f (~;)) } in if \nU} then j (u7 else Cf[l where C,[l is the value (possibly L) of f when (7\u00b0 is false. The value of C,[l \ncould either be obtained by sym~olic eval\u00ad uation or directly by calling the old definition of j. Also, \nthe bounds constraint may refer to the arithmetic parameters, #, of the root recursive call. These parameters \ncan be made available via 10CSJvariables, v~, which captures the argument values of the root call, w \nshown below. i(~ = let{ vb = O ; f (d) = ~(j (~~), ..,~ (t;)) } in if Uf(0) then ~ (~1 eke Cf[l Applying \nthese two support ing transformations to bin results in: bin(n,k)= Iet{nO =n;kO =k; bin (n,k) = case \nn of{ O ~ 1 ; m+l~ifk<Oork~n then I else bin (rrr,k-l)+bin (m,k)}} in if (0 < k A max{l,k} < n) then \nbin (n,k) else 1 where Cbin[l = I since the bin function returns the value I if its pre-condition is \nfalse. This result is now in a form suitable for vector conversion to the target program shown in Section \n1. 5 Improvement Tactics Two more advanced transformation tactics are frequently needed to enhance the \nlambda abstraction tactic. This may be required when different parameters are targeted for elim\u00adination \nvia lambda abstraction. They are (i) invariant test j?oating tactic, and (ii) circular variable tactic. \nDue to space limitation, we shall only provide an outline of the two tactics using bin as an example. \nFor the earlier bin function, we could actually decide to keep k as the main recursion parameter, and \nhave n lifted as part of the lambda abstraction. This results in: bin(n,k) = let{nO=n; kO=k; bin2(k) \n=fin~casenof{O~l; m+l~ifk<Oork~n then 1 else ~in2(k-l)(m)+bin2(k) (m)})} inif(0 < k A max(l ,k) < n) \nthen bin2(k)(n) eIse 1 Often, after such a lambda abstraction tactic, we may have one or more conditional \ntests (or case selections) that are invariant within the lambda abstraction (i.e. not de\u00adpending on its \nbound variables). As the lambda abstraction may be invoked multiple times, it is beneficial to float \nout such conditional tests (or case selections) to a location where it would be invoked only once. This \ncan help improve the overall performance of the resulting code. We propose to float invariant tests (selections) \nof re\u00adcursive conditionals (case), out of the lambda abstraction. Recursive conditionals (or case) are \nconstructs with self\u00adrecursive calls in one or more of their branches. There is no need to deal with \nnon-recursive conditionals (or case) since they are invoked only once on reaching their respec\u00adtive base \ncases. The two rules for floating invariant tests are given below. Note that n @ jree Vars(b) holds, \nwhile lsRec is a predicate to check for recursive calls. (\\n~ ~(if ~(~) thentf efset2)) =+ if b then \n(\\rz ~ ~*(if ~( Z me) then tl eke t2)) eke(\\n 4 ~a (if ~b(Fake) then tf eke t,?)) IF fsRec(tl) V 1sRec(t2) \n (\\n + ;(case b of {Pa 4 fi}~EN)) * ( case b Of {p, ~ (\\n ~ e(t;)ki/b])}te~) IF 3j c N. IsRec(tj) The \nabove float ations enable the invariant tests to be evaluated and invoked only once per lambda abstraction. \nIn addition, we can propagate the test results contexts (e.g. b = True, b = False or b = pi) to enable \nfurther optimisation. However, there is a minor change to the program s semantics due to the possibility \nof floating conditional/case that lies in a non-strict context (e.g. inside the branch of another conditional/case). \nTo avoid introducing non-termination, we require such (non-strict) invariant tests be terminating, assuming \nthat the arithmetic parameters are strict. In the case of bin, there are two base tests, (k s 0) and \n(k ~ n). As the first base test is invariant (of the bound parameter n) and terminating, we can float \nit out, followed by further optimisation, as follows: bin(n,k) =let{nO=n; kO=k; bin2(k) =if(k<O) then \nfin~casen of{ O~l; m+l ~ 1}) else fln~casen Of{O~ 1; m+l ~ ifk ~,n then I efse bm2(k-l)(m)+bin2 (k)(m)) \n} } inif(0 < k A max(l ,k) < n) then bin2(k)(n) else 1 ; =let{nO=n; kO=k; bin2(k) = if (k < 0) then fin \n~ 1) elsefin~ ifk~ n then I else bin2(k-l)(n-l)+ bin2(k)(n-1)) } } inif(0 < k A max(l ,k) < n) then bin2(k)(n) \nelse 1 Such floating of invariant tests can often lead to further optimisation. In particular, note \nhow the two case constructs which test on variable n can be eliminated. The first case has two identical \nbranches which can be combined, while the specisl context of n > 0 in the second c-allowed us to reduce \nit to a single branch, before its elimination. A remaining problem of the above bin2 definition is that \nthere is a recursive call bin2(k) which is an exact copy of its LHS. Using a rule of the circular variable \ntactic, we can eliminate such calls, as follows: 3This is typically so for boolean arithmetic terms using \nprimitive operators. 104 Together with vector conversion, our final target pro\u00adgram becomes: bin(n,k) \n= let {nO =n;kO =k; bin2(k) = if@ < 0) then fin -t 1) else let { r = (!) vec ;z = bin2(k-1) ; bnn=ifk~nthenl \n eke z(n-l)+r(n-1) ; 1= max(],k) ; u= mh(nO~k-kO,nO) ; vec = array (1,u) [a := bn a [ a + fl..u]] } inr} \ninif(0 < kO A max(l ,kO) < nO) then bin else 1 Note that r is a circular variable to represent the vector \nof bin2(k). This vector is computed from the elements of the previous vector z down the recursion, as \nwell as from other elements of r itself. 6 Run-Time Performance To help justify our transformation (and \nanalysis), we col\u00adlected the CPU times and heap space statistics for five dif\u00adferent versions of bin \nin Table 1. They are for (i) original definition of bin (ii) fully -memoized version (iii) vectorized \nversion with a Ioose bound of O < k < n (iv) vectorized ver\u00adsion with a tighter bound from o~r b&#38;nd~ \ninference method (v) circular version. As expected, the original version per\u00adformed badly (those with \n- did not complete after an hour). The fully-memoized version is also impractical for large ar\u00adguments. \nThe vectorized version with tighter bounds is still 7-26% faster than a corresDond&#38; vectorized version \nwith looser bound typically give; by pr~grammer. This improve\u00adment represents a good payoff from using \nour more sophis\u00adticated bounds inference method for obtaining tighter pa\u00adrameter bounds. Lastly, the \ncircular bin function performed even better due to a further reduction of its conditional test, achieved \nusing the invariant test floating tactic from Sec\u00adtion 5. 7 Related Work and Conclusion On the analyses \nfront, a typebased analysis was recently proposed in [9] to obtain information about the sizes of recursively \ndefined data structures. This analysis can be used to prove some basic properties (such as deadlocks, \nnon\u00adtermination) of reactive systems. We considered the option of using this sized analysis for bounds \ninference but found it to be unsuitable. Apart from its restriction to the natural number domain and \nthe adoption of type-checking (rather than inference), the present sized analysis can only relate the \nsizes of parameters, not the values of the parameters themselves. In other words, it could state that \ntwo parame\u00adters have the same bound (size) but not that one parameter is always less than another -a \nmore precise result achieved by our bounds inference. The omega calculator of [15] uses constraint solving \nto support exact dependence analysis for vectorising and par\u00adallelizing compilers. Pugh s work is complimentary \nto our bounds inference analysis, since we could make use of practi\u00adcal advances in his constraint technology \nfor efficiently solv\u00ading our Presburger bounds too. The bounds inference work here is also related to \na compiler optimization technique, called array subscript range checks elimination [8, 11]. While we \ninfer the bounds of the parameters of lambda abstrac\u00adtions in order to convert to arrays, range checks \noptimiza\u00adtion attempts to remove redundant checks present in user\u00adsupplied array-based loops. Our work \ncan be seen as an utopian alternative to range checking. It is formulated for the more general recursive \nprograms, and automatically pro\u00advides 100~0 elimination of range checks, whenever lambda abstraction \nare successfully converted to vectors with safe bounds. An interesting fut ure work is to adapt our bounds \ninference method to handle array-based programs directly. Apart from the possibility of static bounds \nchecking, we can expect the sizes of arrays (that are dynamically allocated) to be adjusted downwards \nwhenever tighter bounds could be inferred. On the transformation front, many techniques have been proposed \nin the past for avoiding redundant function calls. One of the earliest techniques uses memo-functions \n[12]. Memo-functions are special functions which remember/store either some or all of their previously \ncomputed function calls in a memo-table, so that re-occurring function calls can have their results retrieved \nfrom the memo-table rather than re-computed. Though general (with no analysis required), memo-functions \nsuffer from large table management over\u00adheads. Other transformation techniques (e.g. tupling and tabu\u00adlation) \nmay result in more efficient programs but they usu\u00adally require program analyses and may be restricted \nto sub\u00adclasses of programs. Most of these techniques analyse the DGs algebraically. This approach typically \nuses appropriate conditions of descent functions to infer redundancy patterns in the DGs. Descent functions \nare functions applied to the arguments of subsidiary recursive calls. Some common re\u00adlationships of descent \nfunctions which were discovered by Cohen[7] are the common generator, periodic commutative and commutative \nredundancy relationships. Though fairly extensive, there are still other classes of programs which are \nnot easily addressed by the algebraic approach, without get\u00adting ad-hoc via an increasing set of exceptions. \nOur approach advocates the use of a collection of trans\u00adformation tactics. By a novel combination of \ntupling and lambda abstraction, we can efficiently memoize programs which require dynamic-sized tabulations. \nTo obtain efficient memoiz ation, we have also proposed the vector conversion tactic together with a \nbunch of supporting tactics, includ\u00ading more advanced ones given in Section 5. The main con\u00adtribution \nof this paper is a systematic collection of bounds inference analyses needed to support vector conversion. \nOur analyses can collect relevant context constraint for each r~ cursive call before attempting to obtain \na unified constraint which holds for all recursive calls. In addition, each set of parameters which are \nmonotonically increasing (or decreas\u00ading) can also be used to obtain new monotonic constraints. The final \nparameter bounds are formed by combining uni\u00adfied and monotonic constraints together. The decidability \nof the analyses is facilitated by our use of arithmetic expres\u00adsions in Presburger form. With this analyses, \nmany of the more exotic transformations that are hand-analysed in [1] can now be systematically handled. \nAcknowledgements We would like to thank Aik-Hni and Siau-Cheng for their helpful discussions, and to \nICFP refer\u00adees for providing insightful comments. 185 Table 1: Time &#38; Space Statistics for different \nbin under the Glasgow Haskell Compiler Calls Original Fully Memoazed Vectorized (loose) L ectorized (tight) \nCircula- Sec Cells Sec Cells Sec Cells Sec Cells Sec Cells bin(10,5) 0.034 46924 0.044 15632 0.034 10904 \n0.032 9628 0.021 7068 bin(25, 12) 218.04 936054720 0.480 93616 0.058 47168 0.054 37956 0.044 28612 birr(30,15) \n0.91 134648 0.74 64920 0.070 51484 0.046 39604 bin(100,50) - 99.24 1501772 0.400 606044 0.296 449248 \n0.250 366948 bin(200, 100) 1.422 2331032 1.070 1697424 0.870 1412524 References [1] Richard S. Bird. \nTabulation techniques for recursive programs. ACM Computing Surueys, 12(4):403-417, December 1980. [2] \nW. W. Bledsoe. Anew method forproving certain Pres\u00adburger formulae. In ProcoflCJA1, pages 15-21, 1975. \n[3] R.M. Burstall and J. Darlington. A transformation system for developing recursive programs. Journal \noj ACM, 24(1) :44 67, January 1977. [4] Wei-Ngan Chin. Towards an automated tuplingstrat\u00adegy. In %-d \nACM Symposium on Partial Evaluation and Semantics-Based Progmm Manipulation, pages 119\u00ad132, Copenhagen, \nDenmark, ACM Press, June 1993. ACM Press. [5] Wei-Ngan Chin and John Darlington. A higher-order removal \nmethod. LISP and Symbolic Computation, 9{4):287-322, 1996. [6] Wei-Ngan Chin and Masami Hagiya. A transformation \nmethod for dynamic-sized tabulation. Acts Informat\u00adica, 32:93 1 15, March 1995. [7] Norman H. Cohen. \nEliminating redundant recursive calls. ACM Tmns. on Programming Languages and Sys\u00adtems, 5(3):265-299, \nJuly 1983. [8] R. Gupta. A fresh look at optimizing array bound checking. In ACM SIGPLA N Con}. on Program \nLang. Design and ImpL, pages 272-282, New York, June 1990. [9] J Hughes, L Pareto, ilnd A Sabry. Proving \nthe cor\u00adrectness of reactive systems using sized types. In 29rd ACM Principles of Progmmming Languages \nConfer\u00adence, pages 410 423. ACM Press, January 1996. [10] N.D. Jones, C.K. Gomard, and P. Sestoft. Partial \nEval\u00aduation and Automatic Progmm Generation. Prentice Hall, 1993. [11] P Kolte and M Wolfe. Elimination \nof redundant array subscript range checks. In ACM Conference on Pro\u00adgramming Language Design and Implementation, \npages 270-278. ACM Press, June 1995. [12] Donald Michie. Memo functions and machine learning. Nature, \n218:19-22, April 1968. [13] N. Perry. Hope+. Tech Note: IC/FPR/LANG/2.5 .l/7, DoC, Imperial College. \n1989. [14] Alberto Pettorossi. A powerful strategy for deriving programs by transformation. In 3rd ACM \nLISP and Functional Programming Conference, pages 273-281. ACM Press, 1984. [15] William. Pugh. The omega \ntest: A fast practical in\u00adteger programming algorithm for dependence analysis. Communications of ACM, \n8:102-114, 1992. [16] Akihiko Takano. Generalized partial computation for a lazy functional language. \nIn ACM Symposium on Par\u00adtial Evaluation and Semantics-Based Program Manip\u00adulation, pages 1 11, New Haven, \nConnecticut, August 1991. ACM Press. A One More Example We show how the bounds inference method can be \nused to optimize the longest common sub-sequence problem. Con\u00adsider the folJowing function to find the \nlongest common sub\u00adsequence of two strings, XS and YS, where N=length(XS), M=length(YS). csub(jL,kL) \n= if jL >N or kL >M then O else if XS !!jL = YS !!kL then l+c.sub(jL+l,kL +1) else max(csub(jL ,kL +l),c.sub(j \nL +l,kL)); The backwards parameter substitutions for the three re\u00adcursive calls are: BC.U~(l : L) ~ \n{jL = jl L l, kL = kl L 1} Bc,Ub(2 : L) z {jL = j2 L, kL= k2:L 1} Bc~U*(3 : L) ~ {jL = j3 L -l,kL = \nk3 L} Also, the individual call constraints for the three recur\u00adsive cslls are: ZC8U6(1:L) ~(j<IV+ l) \nA(k~A.l +1) ZC~U6(2:L) S(j~lV)A(k~M+l) 1C$U*(3:L) S(j:N+l)A(k<M) An attempt is now made to obtain its \nunified bounds constraint, as follows: Vi. Zc,ti~(i : L) 1-Viel,,z lc.U~(i : L) b((j<N+l)A(ks M+ l)) \nV((j<N)A(k~M+ l)) v((j<N+l)A(k SM)) F (j ~ rnin{lV+l, N, fV+l}) A(k < rnin{M+l, M+ l, M}) l-(j<N)A(k \n<M) Adding in the pre-condition, we have: Uc,ub s (jo ~~) A (ko < ~) implies (j ~~) A(k < ~) Since the \ntwo parameters of =ub are monotonically in\u00adcreasing parameters, we propose: Mc,tib s (j ~ ja) A(k ~ kn) \n 186 Though both parameters are monotonically increasing, it is not possible to find an appropriate \ndifference that is mono\u00adtonically increasing. This fact is predicted by our technique on the pair of \nmonotonic parameters (see Defn 3). Both the unified constraint and the monotonic constraint can be used \nto obtain the following the projected bounds constraint. BOUND.SC,Ub s (j[l ~ N) A (k[l < M) implies \n(.?[]sj~N)A(k[l~k~M) With the bounds for k, we can apply the lambda ab\u00adstraction tactic (plus supporting \ntactics), before vector con\u00adversion to obtain the following dynamically-tabulated defi\u00adnition: csub(j,k) \n=let{jO=j; kO=k; csub (j) = ifj > N then Ok~ 0) elze let { r= (!) vec ; Z= Czub (j+l) ; cnk=ifk>M then \nO elseif(XS !!j == YS !!k) then 1 +z(k+l) else max(r(k+ I),z(k)) ; l=kO; u=M vec = array (1,u) [8:= cn \na I a + f-1..u]j } inr} in if~o< N AkO < M) then chub Note that (j > N), an invariant test, is lifted \nout of its lambda abstraction by the tactic in Section 5, while (k> M), which has a bound variable, is \nnot lifted.  \n\t\t\t", "proc_id": "258948", "abstract": "The dynamic-sized tabulation method can be used to eliminate redundant calls for certain classes of recursive programs. An innovative aspect of the method is the use of <i>lambda abstractions</i> that may subsequently be converted to <i>bounded vectors</i>, in order to share redundant calls via vector lookup.To facilitate this conversion to vector form, we propose a new inference method to conservatively determine the bounds for arithmetic parameters of recursive functions. Suitable techniques for inferring the safe bounds of these parameters are introduced, together with supporting transformations. The resulting method can obtain efficient vector-based programs without the need for run-time bounds checking.", "authors": [{"name": "Wei-Ngan Chin", "author_profile_id": "81100655104", "affiliation": "National University of Singapore", "person_id": "PP39052727", "email_address": "", "orcid_id": ""}, {"name": "Masami Hagiya", "author_profile_id": "81100613829", "affiliation": "University of Tokyo", "person_id": "PP39050860", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258948.258965", "year": "1997", "article_id": "258965", "conference": "ICFP", "title": "A bounds inference method for vector-based memoization", "url": "http://dl.acm.org/citation.cfm?id=258965"}