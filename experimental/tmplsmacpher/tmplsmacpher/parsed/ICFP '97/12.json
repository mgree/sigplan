{"article_publication_date": "08-01-1997", "fulltext": "\n On the Complexity of Set-Based Analysis Nevin Heintze David McAllestert Abstract: We define a general \nnotion of set-based analysis any language whose operational semantics is defined by environment evaluation \nhas a well defined set-baaed abstrac\u00adtion. This general definition covers both Aiken and Wlm\u00admers type \nsystem and Heintze set-baaed analysis. Alken and Wimmers give a nondeterministic exponential time al\u00adgorithm \nfor their analysis. Heintze gives an O(ng ) proce\u00addure. We show that this discrepancy is due to the com\u00adplexity \nof the case statements analyzed. For polymorphic programs with deep patterns in case statements (as in \nthe AAen-Wimmers language) we ahow that the problem of de\u00adtermining type-safety under set-based abstraction \nis com\u00adplete for deterministic exponential time. The problem re\u00admains complete for deterministic exponential \ntime for pro\u00adgrams without let (monovariant programs). However, for monovariant programs in which all \npat tems in case state\u00adments are shallow, as in the Heintze language, type-safety under set-baaed abstraction \nis decidable in cubic time. We give five additional theorems which (nearly exhaustively) &#38;wacterize \nthe time complexity of set-baaed analysis as a function of the complexity of case statements. Introduction \nThe programming language ML provides automatic type inference for procedures but requires type declarations \nfor data constructors. Other statically typed languages, how\u00adever, do not require data type definitions. \nThese languages infer types for both procedures and data. Automated infer\u00adence of data types has been \nstudied both in the context of logic programming [12, 8, 5, 9] and in the context of func\u00adtional programming \n[13, 1, 2, 6]. Many different analyses have been developed. These approaches all share a common framework \nin that they assign sets (or types) to program ex\u00adpressions. Although the various approaches to inferring \ndata types seem to share certain basic assumptions, considerable energy has been put into developing \nappropriate analyses for various languages. Here we give a general definition of the set-baaed abstraction \nof any language whose semantics can be defined by environment evaluation. Intuitively, this generrd definition \nof set-baaed analysis yields the most ac\u00adcurate analysis possible subject to the constraint that eaeh \nBell Labs, 600 Mountain Ave, Murray Hill, NJ 07974, nchObell\u00adlabs.com. AT&#38;T Labm, 600 Mountain Ave, \nMurray Hill, NJ 07974, dmacmreaearch.att .com. expression in the program is taken to denote a set. We \nalso give a general definition SBA-safety intuitively, a program is SBA-safe if it is type-safe under \nset-based ab\u00adstraction. We address the computational complexity of de\u00adtermining SBA-safety in a functional \nlanguage with case state\u00adments. In all cases SBA-safety is deeidable in deterministic exponential time \n(even with polyvariance). But the com\u00adplexity of determining SBA-safety is sensitive to the com\u00adplexity \nof case statements. We ahow here that if we restrict the case statements to have only shallow patterns \nthen SBA\u00adsafety (of monovariant programs) is deeidable in 0(n9 ) time under all standard operational \nsemantics. If we allow deep patterns and use the standard serial semantics for case statements then determining \nSBA-safety is complete for de\u00adterministic exponential time. We give a systematic study of the computational \ncomplexity of determining SBA-safety as a function of the complexity of case statements. The O(r? ) procedure \nfor determining SBA-safety for shal\u00adlow patterns is baaed on a flow analysis and is related to the set-baaed \nanalysis methods of Hcintze [6]. The analysis is also similar to that of Shivers [16] or Jagannathan \nand Wright [10] but includes data constructors and union types. It can also be viewed as an extension \nof the recently estab\u00adlished equivalence between flow analysis and recursive types in the absence of \ndata constructors [3, 14, 7, 15]. These connections are explored more deeply in [11]. Earlier procedures \nfor determining SBA-safety for pro\u00adgrams with deep patterns have been based on general meth\u00adods of solving \nset constraints [1, 2]. The general set con\u00adstraint solvers run in nondeterministic exponential time \nin the worst case. Here we ahow that the full power of these set constraint solvers is not needed in \ndeterminingg SBA-safety. SBA-safety can be determined in deterministic exponential time using a direct \nabstract interpretation of the program.1 The basic definition of SBA-safety only applies to mono\u00advsriant \nprograms. However, the monovariant notion of SBA\u00adsafety immediately induces a polyvariant notion of SBA-safety \n a polyvariant program is SBA-safe if and only if its let\u00adexpansion is SBA-safe (as a monovariant program). \nGhen 1The abstract interpretation used here seems outside tbe technical framework described by Coucot \nand Corwot [4]. We use an abotract domain derived from the particular program being analymd. For example, \nin many cams the abstract values are the program nodes themselves. In more traditional abstract interpretation \nthe program\u00adming language as a whole is given an abstractcemantics using a single abstract semantic domain. \n 150 BETA EVAL((f EVAL(~, W), p), P) EVAL(W, p) BETA EVAL((f w), p) (f! P) + (~~.u, a) (w! P) +* lDENT \nEVAL(Az.e, p) (u w)! P) + (u, 42 := v]) (Az.e, p) + (.Xz.e, p) CALL (u, p) -t (w, u) VAR EVAL(Z, p) EVAL(W, \nu) (z, p) -tp(z) RETURN (u, p) -+ (W, a), (w, u) + a CONS EVAL(O, p) (u, p) -t W (o, p) + o ~lgure 1: \nEnvironment evaluation for the pure A-calculus. A value is either the constant O or a pair of the form \n(As.., u) where u it an environment mapping the free variable of Az .e to values. In the rulec BETA and \nRETURN we require that v be a value. a definition of polyvariant SBA-safety one can consider the question \nof the computational complexity of determining polyvariant SBA-aafet y for a variety of programming lan\u00adguages. \nMcAllister has shown [11] that even for first order programs restricted to procedures of at most one \nargument and &#38;allow case statements determining polyvariant SBA\u00adsafety ia PSPACEhard. This is in \ncontrast to Hindley-Milner typabfity which can be done in nearly linear time for pro\u00adgrams of bounded \norder and arity [11]. This result indicates that polyvariant SBA-safety for shallow case statements is \nharder to determine than Hmdley-Milner typability. On the other hand, we show here that polyvariant SBA-safety \nwith deep case statements is decidable in deterministic singly ex\u00adponential time, so in a theoretical \nsense it is no harder than Hmdley-MJner typability with unbounded order and arity. Our results also completely \ncharacterize the complexity of monomorphic analysis. One gap remains for polyvariant programs for shallow \ncase statements the polyvariant problem has a lower bound of PSPACEand an upper bound of exponential \ntime. An important open problem is the effiaency of determin\u00ad i~ poly~=t SBA-safety in practice. Constrained \ntypes seem to provide a promising practical approach [1, 2, 15]. Constrained types are beyond the scope \nof this paper. 2 SBA-safet y In this section we define the general notion of set-based ab\u00adstraction and \nSBA-safety. Ultimately we are interested in performing set-based analysis on programs involving data \nconstructors and case statements. However, our notion of set-based abstract is well defined for any language \nwith an operational semantics defined by environment evaluation. As a preliminary example we consider \nthe pure A-calculus extended with a constant O. The terms of this language are defined by the following \ngrammar. e ::= z \\O I,kz.e [ (el ea) As usual for the A-calculus, we let AaV.e abbreviate AZ .Ag.e and \nwe let (~ el ez ) abbreviate ((~ el ) e~). Similar abbre\u00adviations hold for larger numbers of arguments. \nF@re 1 gives environment evaluation rules for the pure A-calculus (with the constant O). The rules can \nbe viewed as a bot t em-up logic program. The assertions describe events occurring in a more traditional \nenvironment evaluator. The assertion EVAL(e, a) means that the evaluator is to evaluate e in the environment \na. An evaluation is initiated by mak\u00ading an assertion of the form EVAL(e, o) where e is a closed term \nand u is the empty environment. The rule BETA states that if one is to evaluate an application (~ w) \nthen one must recursively evaluate both ~ and w. This rule, as all rules in figure 1, is intended to \nbe used in a forward chaining man\u00adner the evaluation of an application causes the evaluation of the \noperator and operand. The rule BETA uses values re\u00adturned from the evaluation of ~ and w. A value is \ndefined to be either the constant O or a pair of the form (Az.e, a) where u is an environment mapping \nthe free variables of Ax .e to values. In the rule BETA and RETURN we require that w be a value. Suppose \nwe seed the inference rules with the initial aa\u00adsertion EVAL(( AZ .Z O), H). Then from BETA we can derive \nEVAL(AZ.Z, o) and EVAL(O, 0). ~om IDENT we can infer (Az.z, u)+ (Az.z, 0). From COWSwe can infer  (o, \no)+ o. So, from BETAwe can derive ((AZ.Z o), I-J)+ (z, [z:= o]). By CALL we get EVAL(Z, [z := O]). \nBy VAR we then get (z, [z:= o]) + O. And finally, by RETTJIMwe get ((AZ.Z o), u)+ o. The presence of \nthe constant O provides a notion of run time error. A run time error is generated if there is an attempt \nto apply the constant O as a procedure. This notion of run time error is captured in the following inference \nrule. ERROR EVAL((f W), P) (f, P)-+ o ERROR BETA EVAL((j W)) BETA EVAL((f W)) f + Az.u EVAL(f), EVAL(W \n) W+v IDENT EVAL(2z.e) Z+V, (fw)+u Az. e + Az. e CALL U-+w CONS EVAL(0) EVAL(W ) 0+0 RETURN U+w W+tl \nERROR EVAL((f w)), f + O U+V ERROR Figure 2: Determining SBA-safety. In BETA and RETURN we require that \nw beeither O or a A-expression. e is SBA-safe under the semantics l-a if and only EVAL(e) ~~ ERROR where \nR is the above rule set. We let t-~ be the inference relation defined by the infer\u00adence rules in figure \n1 plus the above error rule. For example, we have the following facts about the inference relation l-~. \n13VAL(((kv.zO) O), o) t-~ ((k.z O), n) ~ O EVAL(((k.Z O) O), o) l-~ ERROR  We say that a closed term \ne generates a run time error if EVAL(e, o) E2 ERROR.The term ((Az.z O) O) generates a run time error. \nThe problem of determining whether a given term generates a run time error is undecidable. We now formally \ndefine set-based abstraction and SBA-safety. These definitions am.dy to arw environment evaluation se\u00admantics \ngiven by inference rules for deriving assertions of the form EVAL(e, a) and (e, p) + u. Definition: Let \nR be any set of inference rules. We define EB to be the inference relation gen\u00aderated by those rules. \nWe define A to be the following abstraction rule. SEA EVAL(U,p) (u, p)+ u EVAL(U,V)  (% -Y)+ t The \nset-based abstraction of R is defined to be the rule set R U {A}. For smy set R of environment evaluation \nrules, the rule set Ru{A} defines the set-based abstraction of the semantics R. For example, let Abe \nthe set of inference rules in figure 1 plus the above error rule. The inference relation ~~ {A} de\u00adfines \nthe set-based abstraction of the pure A-calculus under the semantics given in figure 1. As an example \nconsider the following term where 1 abbreviates Az.z and K abbreviates Azy.z. ((Af. (K ((f 1) O) (f O))) \nAy.y) This term evaluatea to O and does not generate a run time error. But the variable y is evaluated \nin two different envi\u00adronments. The variable ~ becomes bound to Ay.y and the evaluation of (~ Z) results \nin an environment in which y is bound to 1 while the evaluation of (~ O) results in an envi\u00adronment \nin which y is bound to O. So we have the following facts where e is the above term. EVAL(e, u) I-A EVAL(y, \n[y:= ~) EVAL(e, n) l-a EVAL(y, [y := O]) Now the above set-based abstraction rule can be used to obtain \nthe following. EVAL(e, o) I-AU{A} (y, [y := 11) + O This implies the following. EVAL(e, u) EAU{A} ((f \n1), [~:= Ay.y]) + (y, [y:= 1]) EVAL(e, o) E~u{-4} ((f Z), [j := Ay.y]) + O EVAL(e, u) I-au{A} ERROR So \neven though e does not generate a run-time error, under the set-based abstraction an error is generated. \nIntuitively, the set-based abstraction rule states that each expression is assoaat ed with a set of values \nindependent of environment. The set of values associated withy must include both 1 and O and hence any \napplication of Ay.y can return either I or o. Definition: Let R be any set of inference rules. A term \ne is called SBA-safe under semantics R if EVAL(e, o) ~RUIA] ERROR. Intuitively, a term is SBA-safe under \nsemantics R ifit ia type-safe where the types are the sets of values generated by the rules Ru{A}. SBA-safetyis \ndecidable for most languages. The decision procedure for SBA-safetyfor the pure A-calculus with the constant \nOis shown in figure 2. Under the SEAinfer\u00adence rule A, each expression has a set of values independent \nof the environment in which it is evaluated. Since the value set is independent of the environment, the \nenvironments can be removed from the evaluation rules. The rules of figure 2 generate statements of the \nform EVAL(u) and u + w where u and w are subterms of the top level term being evaluated. There are 0(n2 \n) such assertions of the form u + w where n is the number of subterms of the top level input. The rules \ncan be run to completion in O(ns ) time. 13ETA0 EVAL((j w), P) EVAL(j, p), EVAL(W, p) IDENT EVAL(W , \np) (w, p) + (w, p) VAR EVAL(Z, p) (z, p) +p(z) CONS EVAL(O, p) (o, p) + o BETA EVAL((j W), p) (f, (w, \nP) + (Az.u,p) + v a) ((f w)! P) + (% + := w]) CALL (u, p) + (w, a) EVAL(W, u) RETURN (u, p) + (w, u), \n(w, u) + u (u, p) + v SYM EVAL(2z.e, p) EVAL(e, p[Z :=?])  F@re 3: An arbitraryreductionenvironmentevaluator. \nA .mpended computation is either the conctant O or . pair of the form (Az. e, u) where c is srr environment \nmapping the free variable of A=. e to suspended computations. In the roles BETA and RETURN we let v be \nan arbitrary suspended computation. The notation ~z :=?] uced in the rule SYM denotes an environment \nin which z is bound to a fresh variable. The rules in figure 2 can be viewed as defining a kind of abstract \ninterpret ation where the abstract values are subex\u00ad pressions of the input program. All of the decision \npro\u00adcedures for SBA-safety given in this paper are presented as abstract evaluation rules. In many cases, \nhowever, there can be exponentially many abstract values. Evaluation Strategies The environment evaluator \nshown in figure I implements call by value semantics. We also discuss two other evaluation strategies \n lazy evaluation and arbitrary reduction. Both of these other evaluation strategies can be implemented \nin an environment evaluator analogous to the one shown in fig\u00adure 1. Set-based abstraction and the notion \nof SBA-safety is defined relative to an arbitrary environment evaluator and hence is also defined for \nlazy and arbitrary reduction se\u00admantics. The notion of SBA-safety is difkrent for these dif\u00adferent evaluation \nstrategies. Here we describe the changes needed to the inference rules to implement the other eval\u00aduation \nstrategies and the consequences for the notion of of SBA-safety. Fwst we consider lazy evaluation. To \nimplement lazy evaluation we first define an appropriatee notion of a lazy value. A lazy value is either \nO or a pair of the form (Az.e, a) where a maps the ffee variables of AZ.e to suspended com\u00adputations \n a suspended computation is either O or a pair of the form (u, u) where u is any term and a maps the \nfree variables of u to other suspended computations. Note that values are a special case of suspended \ncomputations in which the expression must be a A-expression. We can modify the rules in figure 1 to implement \nlazy evaluation with three changes. First, we change the restriction on v in the rule RETURNso that it \nranges over lazy values rather than strict values. Second, we modify the rule BETA so that EVAL((f w) \np) generates EVAL(~, p) but does not gen\u00aderate EVAL(W,p). Finally, we replace the rule BETAwith the following. \nLAZY EVAL((f W), P) ((f TD),P)+ (u, +:= (w, P)]) Let UROIiGbe the expression (O O). Under lazy evaluation \nthe term (Az.O WRONG)does not generate a run time error because the term WRONGis never evaluated. Now \nconsider adding the set-based abstraction rule which forces expres\u00adsions to denote sets independent of \nenvironments. The set\u00adbased abstraction does not change the fact that this term does not generate an \nerror the term is SBA-safe under lazy semantics. As another example, let 1 be (( Ah.(h h)) (Ah. (h h))). \nUnder the call by value semantics given in figure 1 the term (Az.UROIJG 1) does not generate a run time \nerror. This is also true under the set-based abstraction this term is SBA-safe under call by value semantics. \nUnder lasy semantics this term generates a run time error and fails to be SBA-safe. Arbhrary reduction \nsemantics is d.Werentfrom both strict and lazy evaluation. Arbitrary reduction semantics is most easily \nformulated using reduction rules. In particular we have the following reduction rules. (kc.e w) + e[w/z] \n(O w) + ERROR e + ERROR if e contains ERROR These rules can be applied anywhere inside a term. For example, \nunder both lazy and strict semantics the term AZ.WRONGdoes not generate a run time error. Under ar\u00adbitrary \nreduction, however, we have WRONG+ ERRORand hence As .URONG+ ERROR To formulate a notion of SBA-safety \nbased on arbhu-y reduction semantics we must first implement the arbitrary reduction semantics as an \nenvironment evaluator. An en\u00advironment evaluator implementing arbitrary reduction se\u00admantics is shown \nin figure 3. Under the arbitrary reduction BETA EVAL( e) EVAL(U) u a mbterm of e IDENT EVAL(U) U+u ERROR \nEVAL((f w)), j + O ERROR ~lgure 4: Determining SBA-safety under arbitrary reduction. semantics a given \nterm can be rewritten in many cMTerent ways and terms generally do not have unique values. If the rules \ngenerate (u, p) + (w, a) then the term represented by (u, p) reduces under the above reduction rules \nto the term represent ed by (w, u). ALso, it is possible to show that for any closed term e, we have \nthat e + ERROR if and ordy if EVAL(e, 0) E ERROR where E is the inference relation de\u00adfied by the inference \nrules in figure 3. In other words, the notion of run time error defined by figure 3 is the same as the \nnotion of run time error defined by the reduction rules. For example, note that the term AZ.URONGgenerates \na run time error under the semantics in figure 3 the rule SYM allows evaluation to proceed into the \nbody of a A-expression even if that A-expression is never applied. The notation p[z :=?] denotes an environment \nwhich maps z to a fresh variable. The proof that the notion of run time error defined by figure 3 is \nthe same as that defined by the reduction rules involves establishing an invariant relating the two systems. \nUnfortunately, this invariant is somewhat difficult to state and we omit the proof here. In the remainder \nof this paper we consider only arbitrary reduction semantics. Arbkwy reduction semantics has the drawback \nof being less accurate in cases where a more re\u00adstricted reduction strategy is actually used. But we \nfocus on arbitrary reduction semantics here for three reasons. First, it can be argued that set-based \nanalysis derived from ar\u00adbkrary reduction semantics catches more programming er\u00adrors because it rejects \nintuitively ill-typed terms, such as Ac.URONG,that can be accepted under other semantics. Sec\u00adond, arbitrary \nreduction semantics is not fundamentally dif\u00adferent from the semantics of other evaluation strategies \n the complexity of determining SBA-safety seems insensitive the choice of reduction strategy. Fh-mlly, \narbhmwy reduc\u00adtion semantics simplifies the algorithms for determining SBA\u00adsafety. Figure 4 gives the \nalgorithm for determining SBA\u00adsafety for the pure A-calculus with O under arbitrary reduc\u00adtion semantics. \nIt useful to compare figures 2 and 4 and note the simplicity gained from arbitrary reduction semantics. \nIt is also interesting to note that a term of this calculus is SBA\u00adsafe under arbitrary reduction if \nand only if it is typable in the Amadio-Cardelli type system [3, 14]. 4 Case Statements and their Semantics \nThe syntax and arbitrary reduction semantics of a simple operational language with case statements and \nnondeter\u00ad minism is given in figure 5. The nondeterminism primitive BETA EVAL((j W)) f + Az.u Z+W, (fto)+u \nTRANS u-)w, w+a U+8  AMB does not effect the simplicity or rum time of set-based analysis and is convenient \nfor giving examples. Case is a pattern matching conatmct. In the expression CASE(e of pl :bl, .... pn:h) \neachpi isa pattern to be matched against the value of e. A successful mat ch binds the variables in pi \nand continues by executing bi under those bindings. We consider four differ\u00adent semantics for case statements. \nCase statements can be serial or parallel. The serial case reduction rule generates the reduction CASE(C(U)of \nc(z): z, y: y) +. a but not the reduction CASE(c(a) of c(z) : z, v: y) +P c(a); the latter is however \ngenerated by the parallel rule. Case statements can also be strict or nonstrict. Strict case statements \ngenerate an error when no pattern matches the given value. Nonstrict case statements do not generate \nsuch an error they sim\u00adply diverge if no patterm matches. The choice of serial or parallel and strict \nor nonstrict gives four possibilities each of which corresponds to a particular subsets of the reduc\u00adtion \nrules in figure 5. In all cases the order of reduction is unconstrained. As an example let e be the following \nterm. (Ah. C((h h)) Ala.C((h h))) We have that e + c(e). Intuitively, e can be viewed as the infinite \nterm c(c(c(.. .))). However, the reduction rules only manipulate finite terms such as c(c(e) ). Now consider \nthe following case statement under the serial semantics. CASE(eof c(c(z)) :z, c(y) :y) Under the serial \nsemantics the branch corresponding to c(y) is never taken. The term e neither matches nor clashes with \nthe pattern C(C(Z)). The term c(e) again neither matches nor clashes with c(c(z)). But c(c(e)) matches \nc(c(z)) with z bound to e. As in the case of the pure A-calculus, the reduction rule semantics can be \ntranslated into an environment evaluator which implements the same notion of run time error for any \nclosed term e we have e + w where w contains ERROR if and only if EVAL(e, H) F ERRORwhere E is the inference \nrelation defined by the environment evaluator. The envi\u00adronment evaluator for the language with case \nis given in figure 6. The case statements can be either serial or parallel and either strict or nonstrict. \nThe evaluator in figure 6 is serial and strict. To get a semantics for parallel case the clash antecedent \nis removed from the rule CASE. To get a nonstrict semantics we delete the rule CERR. .. .. . . e ::= \nz (el ez)l~z.elc[el, . . . . e~)l CASE(eOofpl:el, . . . . p~:e~ / AMB(el, .2) p ::= z C(P1! . ..! Pn)lzas \nP (( AC..) w)+ e[v/m] P p-error (C(vl, .... vZ) v) -) ERROR AMB 1 AMB(el, e2) + el AMB2 AMB(el, e2) \n+ e2 parallel case CASE(U ofpl :el, . . . . p~:e~) + u(e~) where u = u(p~) anda(z) =zforz~p; serial \ncase CASE(uofpl:el, . . . . p~:e~) + a(e; ) where u = u(p~) andu(z) =zforz~p{ and Pj clashes with u for \nj < i error case CASE(uofpl:el, . . . . p~:en) + ERROR pi cI-he~ with a fOr1 ~ j S fl Figure 5: R.duct \nion cemantics for case statement,. A term in any expression generated by e in the above grammar subject \nto the constraint that the patterns in cate expressions must be linear, i.e., a given variable occurm \nat most once in any given pattern. The operational semanticn of terms is dctined by the above set of \nterm reduction rulen. We will only consider certain subsets of the reduction rules. We adopt either the \nparallel or the serial case rule, but not both, and the case error rule is optional. A term e clmhes \nwith a pattern C(PI, . . . . p-) if e is a ~-expression, an application of a different constructor, or \na-term of the form C(U1, . . . . u-) where some U{ clashes with P;. BETA EVAL((f w), P) BETA EVAL((f \nw), p) (f, P) + (A=.u, ~) (w, p)+ u EVAL(f, P), EVAL(W, p) ((f w)) P)+ (% U[z:=v]) CASE 1EVAL(CASE(U \nof pi : t?l , . . . . p-: en), p) CASE EVAL(CASE(U of pl : el, . . . . p~:e~), P) 1EVAL(U, p) (% P)+v \n v clashet with Pj for all 1~j<i CONS EVAL(c(el, e~), p) .... vmatches pi EVAL(el, p), .... EVAL(en, \np) (CASE(W ofpl :el, . . . . pn:e~), p) -t (e~, p~~ := v]) VAR EVAL(Z, p) CONS EVAL(c(el, . . . . e-), \np) (z, P) + P(z) (e~, P)+w1, . . . . (em, p)+um CALL (u, p)+ (w, a) (c(e,, .... e=), p) +e(ul, .... \nv=) EVAL(W, a) AMB EVAL(AMB(.l, e~), p) RETURN (u, p)+ (w, a), (w, a)+ u (AMB(el, .2), p) + (cl, p) \n(AMB(el, .z), p) -) (.2, p) (u, p)+ v IDENT EVAL(U, f?)BERR EVAL((f w), p) (f, P)+ 4W1,.... v=) (u, \np)+ (u, p) ERROR SYM1 EVAL(AZ.U, p) CERR EVAL(CASE(U of pl :el, . . . . p~:e~), p) EVAL(U, p[7, :=?]) \n(w, p) + w v clashen with pi for all 1< ~<n SYM2 EVAL(CASE(U of pl : el, . . . . p~:e~), p) ERROR EVAL(el, \np~l :=?]) EVAL(e_, p~~ :=?]) Fiirure 6: Environment evaluation for case statements. A #u#vended comrmtataon \nis a uair (u, aj where u i~ a term .. . and a is a substitution, i.e., a finite mapping from variables \nto values. A wake i; either a variable, a srmpended computation or an expression of the form C(V1, . \n. . . v-) where each v+ is a value. A procadure is a value of the form (Xz.u, a). A value v clashes with \na pattern C(PI, .... P-) ~f u is either a. procedure, an application of a different constructor, or of \nthe form C(UI, . .. . u=) where ~Ome wi cl~he~ with p;. Matclnng is defined in the usual way. The substitution \n@ := u] is the mbstitution identical to p except that it maps variablen in p to the corresponding values \nderived from matching p to v. The substitution p~ :=?] is identical to p except that variables occurring \nin p are bound to fresh variables, i.e., ones not occurring free in values in p. 155 Polyvariance Deep \nas Overlapping Serial Strict Lower Bound Upper Bound 1. + + + + + + EXPTIME EXPTIME 2. ++ ++ O(n3) \n3. + + EXPTIME EXPTIME 4. + -+ + -EXPTIME EXPTIME   5. +-+ O(ns)  6. +-++ CONP CONP 7. +-+- O(n3) \n  8. + -+ + O(nslogra)  Figure 7: Complexity results. The above table shows the computational complexity \nof determining SBA-mfety for a variety of operational semantics and syntactic restrictions on the cme \nntatement. A polyvariant term is one in which the grammar ia extended tolet-expremions. Thelet-expansion \nofapolyvsriant term is the result ofreplacing each let expression let z = e in u by the expansion u[e/z]. \nBy definition, apolyvarirmt term is SBA-ssfe if itsIet-expsnsionis SBA-safe. A plus in the first column \nindicates that Iet-exprescions are allowed. A shallow pattern is either a vsriableor a pattern of the \nform c(zl, . . . . z=)orya~p(zl, . . . . z-). Aminusecondmeansweallowonly shallow patterns in case inthe.column \nstatements. A minus in tbe third column means that we do not allow ss in patterns. A minus in the fourth \ncolumn meam that the patterns inagiven case statement must bedisjoint, i.e., novduecan match twopatterns \nsimultaneously. Aminrmin the fifth column means that we drop the clash antecedent from the rule CASE \nin figure 6. A minus in the last column mesns that we drop the rule CERRformfigure6. Changing anentry \nfrom aminuntoaplrm always makes determining SBA-safety more difficult. Thin monotonicity property implies \nthat the remlta in the table completely characterize the complexity of SBA-safety formonovsriant term; \n.- Any environment evaluator determines a well defined no\u00adtion of act-based abstraction and SBA-safety. \nHere we are interested in the complexity of determining SBA-safety as a function of the complexity of \ncase statements. In addi\u00adtion to the variations discussed above we consider various restrictions on the \npatterns allowed in case statements. In particular, we consider restricting case statements so that all \npatterns are shallow, i.e., are of the form z or c(z1, . . . . z=) or z as p where p is ahallow. Shallow \npatterns are suf\u00adficient to express arbkrary case statements but the conver\u00adsion of an arbitrary case \nstatement to shallow patterns alters the set-baaed abstraction. SBA-safet y is easier to determine with \nshallow patterns. We also consider whether the pro\u00adgrams are allowed to have let constructs, i.e., be \npolyvariant, whether patterns are allowed to contain as, and whether the patterns in a single case statement \nare allowed to overlap, i.e., have common inat antes. Our result a on the complexity of determining SBA-safety \nare shown in figure 7. 5 Determining SBA-Safety In this section we prove all of the upper bounds in fig\u00adure \n7, except that in line 8, plus the lower bound in line 6. The upper bounds are proved by giving decision \nprocedures for determining SBA-safety under the various conditions cor\u00adresponding to the lines in the \ntable. All these decision pro\u00adcedures can be viewed as a form of abstract evaluation with abstract valuea \nderived from program text. F@re 8 defines the abatract evaluation process for shallow patterns. Intu\u00aditively, \nthe abstract values are the subterms of the input expression that are of the form kc.u or c(el, . . . \n. e-). To simplify the rules, however, other subterms of the input are alao treated os abstract values, \nalthough these other sub\u00adterms do not match or clash with nontrivial patterns. The correctness of the \ndecision procedure encoded in figure 8 relies on the fact that match and clash are well defined operations \non the abstract values and shallow pat\u00adterns, i.e., if w is a subterm of the input of the form Az.u or \nc(el, . . . . em), and p is a shallow pattern, then v matches p if and only if every concrete value represented \nby u matches p and w clashes with p if and only if only if every concrete value represented by u clashes \nwith p. The set of concrete values represented by an abstract value v is simply the set of values of \nu under the set baaed abstraction of environment evaluation. A more detailed discussion of 0(n3 ) decision \nprocedures for shallow case statement, and the relationship to the infer\u00adence of recursive types, can \nbe found in [11]. When deep patterns are allowed the match and clash op\u00aderations cease to be well defined \nfor abstract values of the form c(el, . . . . em). For example, the some concrete val\u00adues of c((~ u)) \nmay match the pattern c(c(z)) while others may clash with this pattern. The abatract value c((~ u)) is \nnot sufficiently refined to allow accurate abstract eval\u00aduation. This problem is solved by adding sets \nof pattern skeletons to the abstract values. The skeleton of a patterm is the result of replacing each \nvariable by the constant (uni\u00adversal set) 1, e.g., C(Z, b(y, z)) becomes c(1, b(l, l)). The language \nis restricted so that only linear patterns are al\u00adlowed. The skeleton of a linear pattern completely \ndeter\u00admines the aet of values which match and clash with that pattern. To handle deep patterns we construct \nabstract val\u00adues of the form (c(el, . . . . e.), ~, J/) where P and Af are sets of skeletons of patterns \nin the input. The abstract value (c(el, .... e=), P, ~) represents the set of concrete values of the \nterm c(el, . . . . en) that match all akeletona in P and clash with all skeletons in Af. We require that \nin abstract values of the form (c(el, . . . . en), P, N) we have that each skeleton in P or ~ starts \nwith the constructor c. These skeletons suffice to make match and clash operationa well defined on abstract \nvalues. We now have that the abatract value (c((f u)), {c(c(l))}, {}) matches the pattern c(c(z)) and \nthe abstract value (c((/ u)), {}, {c(c(l))}) clashea with the pattern c(c(z)). Note that in practice \nthere is likely to be only a small number of skeletons of patterns in the input starting with a given \nconstructor. Note that let-expanaion does not introduce new pattern skeletons. This implies that even \nafter let-expansion there ia only a singly exponential number of abstract values in the worst case. F@re \n9 gives the abatract evaluation process for deep pat terns. The rules exploit a variety of aimplilications. \nFhwt, they assume that only bhry constructors are used in the program. Standard methods of representing \nhigher arity B ETA EVAL((j j + A..u W)) D OWN EVAL(e) Z+w, (jw)+w EVAL(U) u a subterm of e CASE EVAL(CASE(U \nofpl :el, . . . . p~:em)) U+tl u clashes with Pj for 1 $ j < i u matchc~ pi with substitution a CASE(uofpl:el, \n. . . . p~:en) + ei z + a(z) for afl z in p< IDENT TRANS EVAL(U) U+u e+u, e-w u+w Ah4B EVAL(AMB(el, AMB(el, \ne~) -t e2)) el, AMB(el, e2) + e2 CERR EVAL(CASE(U U+rl v clashet with of pi :el, . . . . p\u00ad:e~), pi for \nall 1 ~ i ~ n p) BERR EVAL((j, j+c(ul, w)) ...,%) ERROR ERROR Figure 8: Flow rules for shallow patterns. \nWhen we only allow shallow patternl, morrovariant SBA-safety can be determined by a Wow analycis wMlch \ngenerates arcs of the formu + w where u ~-d w are mbterms of the input expressions. 111this case the \nassertionBVAL(U)simply meansthat u appearsin the input, i.e., h a programnode. Th~ full deductive closure \nof the above rules on a given input program can be computed in O(rLS) time. A monovariant term u with \n.hallow case statements is SBA-safe if and only if the above rules fail to derive ERROR from EVAL(U ), \nBETA EVAL((~ w)) DOWN EVAL(.) j + A..u EVAL(U), u a mrbterm of e Z+w, (fw)+u TEMP EVAL(c(el, e2)) CASE \nEVAL(CASE(rI ofpl :el, . . . . pn:en), p) P and ~ mrbnets of the skeletons of U+w patterns in the input \nstarting with c w clashes with Pj forall1~j <i v matchem pi EVAL((c(el, .2), ?, ~) CASE(uofpl:el, . \n. . . p~:e%) + e+ TRANS U+la, w+v BIND(p~, v) U+V  CONS EVAL((c(el, .2), T, Af)) e, +VI, e~+v.J IDENT \nEVAL(U) EVAL(WI ), EVAL(a2 ) C(V~, V2) matchea every element of P U+u C(O~, V2) clashes with every element \nof N BIND(c(pl , p~ ), u) v + C(lq, q) BIND(PI , al), BIND(Pz, W2) AMB EVAL(AMB(el, ez)) BIND2 BIND(z, \nv) AMB(el, e~) + el, AMB(el, e2) + e2 Z+v BERR EVAL((f, W)) f + .(*1, q) BIND3 BIND(z as p, a) ERROR \nz + W, BIND(p, W) CERR EVAL(CASE(U of p~ :e~, . . . . p=:en), P) U-)v v clashes with pi for all 1< i~n \nERROR ~lgure 9: The general case. These rules are to be applied to the let-expansion of the input term. \nThe ikeieton of a pattern is the result of replacing variables by 1, e.g., C(Z, b(y, z)) becomes C(1, \nb( 1, 1)). The rules define an evaluation process over abstract valuea. Each abstract value is either \na subterm of tbe input or a template of the form (c( El , e2 ), 7, N) where c(e~, e2)is a .ubt erm of \nthe input and T and N are sets of skeletons. The template (c(el, e~ ), P, Af) represents the set of values \nof C(el, e2 ) that match elements of P and clash with elements of N. A template value ( c(e ~, e2 ), \nP, Af) matches a pattern p if the skeleton of p i-in P and clashec with a pattern q if either q starts \nwith a constructor other than c or the skeleton of q is in N. A pair r,(tq, VZ) of abstract valuer VI \nand vz matches C(PI, p2 ) if WI matches pl and wz matrhes PZ and clashes with C(PI, p2) if u~ clashes \nwith PI orU2 clashec with ~. The rules manipulate only abstract values and pain of abstract values. Since \nlet-expansion does not introduce new Dattem skeletons. the number of abstract values is bounded by a \nmingle exponential in inpu~ term size. 157 BETA EVAL((j w)), j -i Az.u IDENT Z+w, (fw)+u CASE EVAL(CASE(U \nINTER(u, Pi) ofpl :el, . . . . pn:em)) TRANS CASE(uofpl:el, BIND(p; , u) . . . . p~:e~) + e, INT1 AMB \nEVAL(AMB(.l, ez)) AMB(el, ez) + el, AMB(el, ez) + ea INT2 BERR EVAL((~, W)), f + C(UI, .... %) DOWN1 \nERROR EVAL(e) 1NT3 DOWN2 EVAL(U) EVAL(.) u a mbterm of e BIND1 SKEL(~ p a pattern in e BINDZ EVAL(U) \nU-tu e+u, U+W e-tw EVAL(U) INTER(u, 1) EVAL(c(el, . . . . e-)), SKEL(c(#I, . . . . t-)) INTER(el, 81), \n. . . . INTER(e_, t-) INTER(c(el, . . . . e-), C(sl, . . . . s=)) EVAL(U), u + ., INTER(w, s) INTER(u, \n,) BIND(c(pl , .... P_)$ *), u + c(el, .... em) INTER(el, ~), . . . . INTER(em, ~) BIND(P1, el ), . \n. . . BIND(p_, e-) BIND(z, v) *+V Figure 10: Abstract Evaluation for monovariant terms without ss using \nnormtrict parallel cue statements. We write j$ to denote the skeleton of a pattern p. The assertion INTER(u, \n#) represents the statement that come value of the term u matches the skeleton #, i.e., the value sets \nrepresented by u and # intersect. These rules can be rwn to completion (forward chaining) in 0(n3 ) time. \nconstructors in terms of pairing constructors turn out to preserve SBA-safet y. So without loss of generality \nwe can assume that all constructors are bkmry. The second simpli\u00adfication involves the use of expressions \nof the form C(V1, V2) where V1 and V2 are abstract values. Such expressions are not themselves considered \nto be abstract values but rather simply a way of holding a pair of abstract values. The ab\u00adstract values \nare those expressions v such that the inference rules prove EVAL(V). The rules ensure that the expression \nC(V1, V2) is constructed only when VI and V2 are abstract values. The notion of match and clash is defined \nin the ob\u00advious way for value pairs of the form C(V1, V2). The rules in figure 9 can be run (forward \nchaining) to completion in time singly exponential in the size of the (polyvariant) input term. Figure \n10 gives an abstract evaluation process which is used for lines 5 through 8 in figure 7. In all these \ncases we consider monomorphic programs without as . In the case of non-overlapping patterns (lines 7 \nand 8) parallel and serial case statements behave identically. So lines 5 through 8 can all be viewed \nas having parallel case statements. Lines 5 and 7 are essentially identical. In line 5 overlapping patterns \nare allowed but the case statements must be parallel. In line 7 the patterns must be non-overlapping \nbut the case statements can be sequential. But sequentiality is irrelevant for non-overlapping patt ems. \nFor lines 5 and 7 a given term is SBA-safeif and only if the rules in figure 10 do not derive ERRORwhen \napplied to that term. In lines 6 and 8 the case statements are strict and in order or a term to be safe \nwe need perform an additional escape amdysis as described below. Before considering escape analysis we \nwill give some com\u00adments about the inference rules in figure 10. For parallel case statements without \nas we can take the abstract values to be subterms of the input of the form Az.u and c(el, . . . . em). \nBecause we are allowing deep patterns, match and clash op\u00aderations are not well defied on these abstract \nvalues. How\u00adever, because we consider only parallel case statements we do not need to test for clashes \nwhile computing values. Further\u00admore, because patterns do not contain as we do not need to consider binding \nvariables to proper subsets of the sets represented by subterms. Note that matching the pattern z as \nc(a) to the abstract value C((~ u)) may involves bind\u00ading z to a proper subset of the values of the term \nc((~ u)). But if the patterns do not contain as then no such proper subsets are needed. One must still \nbe careful to avoid extra\u00adneous bindings. For example, consider matching c(a, y) to the term c((~ u), \nw). This should generate y + w provided that (~ u) + a. Note that the set based abstraction rule, combmed \nwith the rule CONS in figure 6, ensures that the set represented c(e 1, ea ) corresponds to the cross \nproduct of the sets represented by el and e~. Matching C(P, y) to C(U, ~) sho~d generate y + w provided \nthat the set of vsd. ues represented by u contains a value matching the pattern p. The rules INT1, INT2, \nand INT3 in figure 10 are used to keep track of intersections between the sets represented by subterms \nof the input and the skeletons of patterms. Lines 6 and 8 in figure 7 require the case statements to \nbe strict, i.e., an error is generated when a value clashes with all patterns in a case statement. The \ninclusion of this error condition for case statements does not change the set of values associated with \nany given term. Hence the rules in figure 10 can still be used to compute a representation of the set \nof values associated with each subterm of the input term. We can now associate each subterm u with a \nregular term language generated by a nonterminal Xu in a certain regular grammar. The grammar for a given \ninput term e is defined by the following productions. X.+1 Xu + A if EVAL(e) 1-u + Ax.w Xu-+c(xe,, \n. . . . X=-) if EVAL(e)1-u + c(el, .... en) In these productions -1-and A are special tokens representing \ndivergent computations and procedures respectively. The input term e is SBA-safeif the rules do not derive \nERRORform EVAL(e) and for each subterm of e of the form CASE(Uof PI : el, .... p :em) no term generated \nby X. under the above grammar clashes with all pi. We now define an escape problem to consist of a regular \n _ge defined by a pair (X, G) where X is a nonterminal symbol and G is a regular term grammar (a set \nof produc\u00adtions) plus a set of patterns (first order terms) pI, . . .. p.. An escape problem is gatisjiableif \nthere exists a term t gen\u00ad erated by X under G such that t clashes with all pi. An escape problem is \ncalled disjoint if the patterns do not over\u00adlap, i.e., no patterns share a common instance. An escape \nproblem is called linear if each pi is linear, i.e., no variable in pi occurs multiple times in pi. Using \nthe method just de\u00adscribed for constructing grammars, each case statement in an input term defines a \nlinear escape problem. For lines 7 and 8 in figure 7 a term is SBA-safe if and only if the rules in figure \n10 fail to derive ERRORand the escape problem defined by each case statement in the input term is unsolvable. \nSo we are left with the problem of determining solvability of escape problems. Note that with a linear \nnumber of nondeterministic choices one can guess the escaping term, i.e., the one that clashes with all \npatterns. So the set of satisfiable escape problems in NP and hence the set of SBA-safeterms is in CONP.This \ngives the upper bound in line 6. The lower bound in line six follows from the fact that satisfiabtit \ny for linear escape problems is NP hard. This can be proved by a simple re\u00adduction from Boolean satisfiabtity \nwhere truth assignments correspond to terms and clashing corresponds to satisfying a clause. The situation \nis quite diKerent for the linear disjoint es\u00adcape problems that arise in line 8. In this case satisfiabfity \nis polynomial time decidable. The decision procedure involves a mathematically curious non-constructive \nalgorithm. Intu\u00aditively, the algorithm computes the volume of the set of terms generated by the grammar \nand the volume covered by each pattern. !%nce the patterns are non-overlapping, the volume covered by \nall patterns together is just the sum of the volumes of each pattern individually. The escape problem \nis satisfiable if and only if the sum of the volumes of the patterns is strictly less than the volume \nof the gram\u00admar. However, this calculation does not provide an escaping term. An escaping term can be \nfound in polynomial time by using the decision procedure for satisfiabilit y to flter a binary search \nfor the escaping term. But the fundamental decision procedure is non-constmctive. The details of the \nproof, including the definition of volume, are given in sec\u00adtion 7. 6 EXPTIME Hardness In this section \nwe prove the EXPTIME hardness results listed in figure 7. These hardness results are baaed on a lemma \nof possibly independent interest. We start with the notion of a disjunctive pattern . Definition: A disjunctive \npattern is an expres\u00adsion of form pl V ... V pn where each pi is a fit order term possibly containing \nvariables. A disjunctive pattern is linear if each p; is linear, i.e., any given variable occurs at most \nonce in pi. A term tis said to satisfy a disjunctive pattern pl v ... V pn if t is a substitution instance \nof some pi. For example we have that c(a, z) V C(Z, b) is a linear disjunctive pattern and c(a, d) and \nc(d, b) both satisfy this pattern. Definition: A disjunctive pattern problem is a set Dl, ..., D= of \ndisjunctive patterns plus a first order term p possibly containing variables. The disjunctive pattern \nproblem is solvable if there exists a substitution instance t of p such that every subterm of tsatisfies \nevery Di. Lemma: Determining satisfiabllit y of a disjunc\u00adtive pattern problem is EXPTIMEhard. The proof \nis by reduction of linear space alternating Tur\u00ading machines. A configuration of a machine with n tape \npositions can be represented by a tuple (s, U1, . . . . U-+l ) where s is a machine state, each ui is \neither the special con\u00adstant H (for head) or a constant representing a tape sym\u00adbol. It is EXPTIME hard \nto determine whether a given initial machine configuration has an accepting computation. We use terms \nto represent proofs that a given configura\u00adtion is accepting. There are two kinds of proofs depend\u00ading \non whether the machine sate is universal or existen\u00adtial. For existential states the proof terms have \nthe form E(s, Ul, .... u-+1, P) where (u, UI, ... , Um+I)is a ma\u00adchine configuration snd p is a proof \nfor one of the two pos\u00adsible successor configurations. For universal stat es proofs have the form A(s, \nu1, .... Un+l, PI, ~) where pl and w are proofs for the two possible successor configurations. We can \nassume that successor states of univemal sates are existential and that successor states of existential \nstates are universal. We can also assume that all accepting states are existential. We translate a given \nmachine into a set of dis\u00adjunctive patterns. Fh-st we construct a set of transition patterns . For each \nright-moving universal state s, each head position i, and each pair al, a~ of tape symbols there is a \ntransition pattern of the form A(s, z1, .... ~i-~t m, H! UZ, ~i+~!..., zn+l, -E(W1, yl, .... ~i-a, m, \nh H, yi+a,. . . . Yn+II ) Y7a+a, E(W2, Zl, .... zi z, al, &#38; H, zi+x,...l Z~+I, Zm+z)) Where WI, \nbl, W2, and h are derived from the transition table of the machine. Note that this pattern is linear \nand does not enforce the constraint that the tapes of the sub\u00adconfigurations match the tape of the top \nlevel configuration. This constraint is expressed elsewhere. Left moving symbols are treated analogously. \nFor each right moving existential state s, head position i, tape symbols al, az, possible suc\u00adcessor \nstate w, and appropriate symbol b derived from the transition table we have a transition pattern of the \nform E(s, x1, . . . . zi-a, al, H, al, zi+a,. ... zn+l, A(wI, W, .... yi-~, al, b H, yi+~,..., .Yn+I, \nYn+a, Yn+s)) Left moving existential states generate similar patterns. For each accepting state B we \nhave the transition pattern E(a, xl, . . . . Z +l, %+2) The first disjunctive pattern is the disjunction \nof all con\u00adstants (representing machine states and tape symbols) and all transition patterns every term \nis required to be either a constant or an instance of a transition pattern. Now we must ensure that \nmachine configurations are pre\u00adserved as one descends into the structure of the proof terms. For each \ntape position i we construct the disjunction of all constants plus all patterns of the following forms. \nA( S,Zl, .... ~i--l,a, Zi+l> ...} ~n+l, E(uJ], !/1, ...7 Yi-1~ at Yi+lt...> Yn+l> Yn+~ > ) E(~z, z1, \n. . . . zi-~, a, zi+l,.. ., %TI+l, zm+z)) E( S,zl,. . . , Xi-l, a, Zi+lj. ..j Zn+l, A(wl, Ill, . . . \n. Yi-lt al Yi+l,... I Yn+l I Yn+~))I A( S, Zl, .... Zi-l, H, ~i+l,..., 2 +3) A( S,zl, . . . . zi z, H, \nzi,. ... Zn+s) A( S, Z1, . . . . z;, H, xi+~,..., Zm+s) E( S, Zl, . . . . zi l, Hr~i+lt. ... zn+a) E( \nS, Z*, . . . . Zi-2, H, Zij..., zn+2) E( 9, Zl, .... zi, HI zi+~)..., Z~+z) The disjunction of these \npatterns implies that the ith po\u00adsition behaves correctly. The final set of disjunctive pat\u00adterns consists \nof the transition disjunction and, for each position i, the above disjunction. The top level term is \nE(so, H,al, .... %, z) where (sO,H,al, . . . . a~) is the initial configuration of the Turing machine. \ns Now we will argue that we can assume without loss of generality that the pat terns involve only a \nsingle binary con\u00adstructor p and a single comtant a. Starting with an arbitrary set of disjunctive patterns \nand we represent a constructor app~cation c(el ~ . . . . en) by p(e., (cl, (.. . (em-l, em)))) where \nec is a term built from p and a which is unique to the constructor c and (el, e~) abbreviates p(p(e~~~, \ncl), ea) where ene~ is a term distinct from all e. and which clashes with p(e. z) for all et and where \nemc~ is used to flag syntax nodes which are introduced by this translation. The syn\u00ad tax nodes (el, e~) \nintroduced by the translation need not satisfy (the translation of) the given disjunctive patterns. However, \nwe can add p(e~e~, z) and p(p(em.w, Z) Y) to each disjunctive pattern so that the newly introduced syn\u00ad \ntax nodes trivially satisfy all patterns. We then have that translation of the disjunctive pattern problem \nis solvable if and only if the original is solvable. We now prove that determining SBA-safetyis EXPTIME \nhard by reducing satisfiability of disjunctive pattern prob\u00adlems to SBA-safety. Consider a disjunctive \npattern problem consisting of disjunctive patterns D1 .... D. and top level term p. We need to determine \nif there is a ground substitu\u00adtion inst ante of p every subterm of which satisfies every Di. For technical \nreasons described below we add the following special disjunctive pattern which we denote by DO. aVp(a, \na) Vp(p(z, y), a) Vp(a, p(z, y)) Vp(p(z, y), p(z, w)) Since we are only concerned with terms constructed \nfrom p and a this final pattern is tautological, i.e., every term satisfies it. The need for this tautological \npattern is di5 cussed below. For each disjunctive pattern D; we define ii to be the following term where \nJ-denotes the diver\u00adgent term (( Az.(z z))(Az.(z z))) and Di is the disjunction ql V... vqn. ~;=A~.AMB( \nCASEzofzlasql : ZI,TD:L CASEZ of Z as qn: z~, w:1) For any iirst order term t we have that ~;(t) =tif \ntsatisfies Di and otherwise fi(t)= J-(no error is ever generated). Note that this construction works \nunder any of the four se\u00admantics oft he case statement. Under the set baaed abstrac\u00adtion the use of AMBis \nnot essential for the purposes of anal\u00adysis we can replace AMBby Azy.((A1.(Azw.w (1 z) (1 y))) Aw.w). \nWe now let F be the following procedure that faltersits input over all patterns. F= Az. (fo(fl . ..(L \nZ)...)) Here ji is the filter for pattern Di and note that we have included fO which fdt ers for the \ntautological disjunctive pat\u00ad tern DO. Next we construct a term that generates those terms tsuch that \nevery subterm of t satisfies every disjunctive pattern. We let Y be the traditional recursion combmtor \nAj((Ah.(f (h h)))(h(j (h h)))). TERM= (YM.AMB(a, (F p(t, t)))) This should be viewed as a recursive \ndefinition of the set of possible values of the variable t.The values of t are pre\u00adcisely the values \nof AMB(a, (F p( t, t))). We can assume that a satisfies all disjunctive patterns and all other terms \nare filtered by F so they must also satisfy all disjunctive pat\u00adterns. The inclusion of the tautological \npattern DO prevents the creation of incomplete values. Note that any construc\u00adtor application returned \nby the tautological filter ~0 is either the constant a or an expression of the form p(el, e~) where el \nand e~ are constructor applications. If DO were not in\u00adcluded then we could get values of the form p(el, \nea ) where el and e~ where suspended computations. But DO ensures that there are no suspended computations \nas arguments to the top level constructor. This property is satisfied by every value of t.Hence values \nof tinp(t, t) also have the prop\u00aderty that no suspended computations appear near the root. In fact, it \nis easy to show by induction on the process of generating values of tthat any value which is a constructor \napplication has no suspended computations whatsoever. It is important that suspended computations inside \nthe data structures are avoided to ensure that the term can be com\u00ad pleted in a way that satisfies all \nthe constraints. Fhmlly we construct the following term. ((CASE TERMof p :a, z :d-) a) Here p is the \ntarget term of the given disjunctive pattern problem the problem is determining if there an instance \nof p such that every subterm of that instance satisfies every disjunctive constraint. This term is SBA-safe \nif and only if the given disjunctive pattern problem is unsolvable. We have now shown that SBA-safety \nis EXPTIllLhard for deep patterns with as under any semantics of case state\u00adments. It also possible to \nmodify the construction to use non-overlapping patterns. Consider any linear term p, i.e., term where \neach variable in the term occurs at most once. When working with a finite set of constructor symbols \nthe set of terms that clash with p can be expressed by a num\u00adber of patterns linear in the size of p. \nFor example, the set of terms clashing with p(p(z, g), p(z, w)) is the set of in\u00adstances of a, p(a, z) \nand P(Z, a). The patterns covering the complement of a given pattern can be made to be disjoint no two \nof them share a common instance. To modify the construction to use disjoint patterns we simply replace \nthe case statements of the form CASE~ofzjasqj: zj,~:~ in the definition of the filter ~i by where ~j,l, \n. . . , ~j,m are patterns covering the complement of qj. A similar transformation can be applied to the \ncase stat ement in the top level term. Now the construction is both insensitive to the semantics of case \nand uses only non\u00adoverlapping pat t ems. When using sequential case with overlapping patterns we can \nalso eliminate the use of as . We simply replace each case statement CASE~ofzja~gj: zj,~:l in the definition \nof the filter ~i by CASEXOf Wj,l: d_, . . . . Wj,m:l, Zj:zj where wj,1, . . .. wj,-are patterns covering \nthe complement of qj. Note that the EXPTIII&#38;hardness is independent of whether the case statements \nare strict, i.e., generate an error when no pattern matches. 7 A Non-constructive Algorithm We now return \nto the escape problems defied at the end of sect ion s. Recall that an escape problem consists of a pair \n(X, G) where X is a nonterminal symbol and G is a regu\u00adlm grammar plus a set of patterns (terms) pl, \n....pn. The escape problem is satisfiable if some term generated by X under G escapes (clashes with) \nall the pi. An escape prob\u00adlem is called linear if all pi are linear and disjoint if not two pi share \na common instance. Here we prove that satisfiabil\u00adity of linear disjoint escape problems can be determined \nin O(lGllpl, . . . . p~l log]pl, . . . . p~l) time where IG[ is the sum over all production in G of the \nsize of the production, i.e., the number of arguments to the constructor on the right hand side of the \nproduction, and Ipl, .... p l is the sum over expressions in the patterns pi (including subexpressions) \nof the arity (number of arguments) in that expression. Note that in the escape problems generated in \ndetermin\u00ading SBA-safety we have that IGI can be at most 0(n2 ) where n is the size of the input term. \nAlso, lpI, .... pnl can be at most O(n). So, as a function of program size we get a running time which \nis O(ne log n). Of course in practice this analysis is applied to each individual case statement separately. \nThe complexity of case statements tends to be bounded so the cost of the escape analysis should be linear \nin the size of the program in practice. The basic idea behind the decision procedure is simple. Each \npattern can be associated with a number which intu\u00aditively counts the number of instances of that pattern. \nWe might call this the volume of the pattern. The total vol\u00adume of the terms generated by the grammar \ncan also be computed. Since the pat terns are disjoint the volume cov\u00adered by the patterns is just the \nsum of the volume of each individual pattern. The escape problem is solvable if and only if the sum of \nthe volume of the patterms is strictly less than the volume of the grammar. Note that this analysis can \ndetermine that an escape is possible but provides no direct way of finding an escaping term. Before formalizing \nthis argument in general, it is instruc\u00adtive to consider a simple special case. Consider lists of n Boolean \nvalues. A Boolean value can be modeled as being one of two constant symbols T and F. A list of n Boolean \nvalues can be represented using a binary constructor func\u00adtion by a term of the form p(zl, p(zz, . . \n. z~)) where each ~i is either T or F. It is e~y to write a simple grammar involving O(n) productions \nwhich generates exactly the set of 2 lists of n Boolean values. Now we consider patterns where each Dattem \nsDecifies some subset of the Boolean val\u00adues. In this case the volume of the grammar is 2 and the volume \nof each pattern is 2m where m is the number of Boolean values left unspecified by the pattern. The pat\u00adt \nems must be disjoint (an easily verified condition) so an escape is possible if and only the sum of the \nvolumes of the patterns is strictly less than 2 . If an escape is possible then we can fmd an escaping \nvalue by testing the Boolean values one at a time to see if an escape remains possible when that value \nis restricted to, say, T. Fkling the witness involves running the escape test n separate times. The escape \ntest is fundamentally non-constmctive. Now we consider the general case nested patterns and arbitrary \ngrammar. Let PI, .... pm be linear non\u00adoverlapping patterns and let G be a regular grammar where the \npatterns and the grammar involving only constants and a single bkmry constructor. First we rewrite both \nthe pat\u00adterns and the grammar so that they use only constants and a single binary constructor. Under \nthe measure of grammar and pattern size given above this transformation increases the size of both the \ngrammar and patterns by at most a linear factor. Next we convert both the patterns and the grammar to \nuse a three argument constructor where the first argument is always a constant symbol. We replace each \npro\u00adduction in G of the form X -i p(Y, Z) byX +p(a, Y,Z) where a is a constant unique to that production. \nWe then add a fresh variable as the fit argument to each use of the binary constmctor in each pattern. \nThe new patterns cover the new grammar if and only if the original patterns cover the original grammar. \nThe advantage of the new grammar is that parse trees are unique a given term has at most one parse. \nThis means that counting terms is the same as counting parses. . If P is nonempty, i.e., if P contains \nthe root position, A nonterminal will be called empty if it does not gen\u00aderate any term. We now remove \nall productions involving empty nonterminals. To determine which nonterminals are empty we run the following \ninference rule on the grammar where the assertion 3X indicates that the nonterminal X is nonempty. X-+c \nx+ C(z, w), 3Z, 3W  ax 3X These inference rules have 0( lG\\) prefix firings where IGI is the number \nof productions in (the binary constructor grammar) G. Since inferential closures can be computed in time \nlinear in the number of prefix firings [11] we can com\u00adpute the inferential closure of these rule in \n0( IG[). Hence in linear time we can identity and remove all empty nontermi\u00adnals. A position is a (possibly \nempty) finite sequence of in\u00adtegers indicating how one should descend into a term. For example, the position \n2.1 the place one gets by taking the second argument and then the fist argument of that in the term \nc(a, g(b)) is occupied by the constant b. The position 2 in this term is an application of the constructor \ng. The root position is occupied by an application of c. We say that the position 3 in the term c(a, \ng(b)) is occupied by -L. In general, a ground term can be viewed as a function from positions to constructors \nplus 1 if t is a term and pis a position then tp is either the constructor applied at position p in \nt or 1 if the position p is not occupied in t. Let P be a set$positions. We will consider two terms \nto be P-equivalent If they agree on all positions in P. The number of P-equivalence classes is at most \nIC + 2 I p t where C is the number of constant symbols (not counting the three place constmctor). Let \nPO be the set of positions occupied by a constructor symbol in at least one of the given pat\u00adterns. Note \nthat if s and t are 1%-equivalent then they are either both instances or both non-instances of each pattern. \nSo there exists a term generated by the grammar but not covered by the patterns if and only if there \nexists a Po\u00adequivalence class of terms generated by the grammar and not covered by the patterns. Our \nprocedure will count Po\u00adequivalences classes. We use the number of PO equivalence classes as a measure \nof volume. The patterns cover the grammar if and only if the number of 1%-equiwdence classes in sets \nof the form pi n G, where pi is one of the given pat\u00adterns, equals the total number of PO-equivalences \nclasses of terms generated by G. For any nonterminal X in G, any linear pattern p, and any upward-closed \nset of positions P, we define V[X, p, P] to be the number of P-equivalence classes of terms gener\u00adated \nby G and which are instances of p. For the grammar constructed above where parses are unique and where \nevery nonterminal is nonempt y the function V satisfies the follow\u00ading conditions. lif X-+c . V[x, c, \nP]= O otherwise { then V[x, p(z, q, w), P] = . If P is nonempty, i.e., if P contains the root position, \nthen v[x, z, P]=~l + x+. ~ V[z, z, {r :2.r E P}]J [JK z, {r:3.r E P}]. x+., z, w) . V[x, z ,{}] = 1. \n Now let X be the distinguished nonterminal appearing in the input pair (X, G) of the escape problem. \nThe volume of the language represented by (X, G) is V[X, z, Po]. The escape problem is solvable if this \ngrammar volume is strictly larger than the sum over the given patterns pi of the pat\u00adtern volume V[X, \npi, Po]. The above equations can be used to compute these quantities. During the recursive calcula\u00adtions \nwe get expressions of the form V[X, p, P] where P is a smaller set of positions. But we only encounter \nexpres\u00adsions of the form we V[X, c, P] and V[X, p(z, q, w), P] where P is nonempty. When we run off the \nbottom of the uattern we encounter exmessions of the form VIX. z, PI. Computing the value of ~hese expressions \ninvolv&#38; cornpu;\u00ading values of the form V[X, z, Q] for smaller position sets Q until the set of positions \nbecomes empty at which case we can use the final equation above as a base case. To do the complexity \nanalysis let [Gl be the number of productions in G. Let Ipl...pnl be the total number of occurrences \nof expressions in pi, .... pn. The computa\u00adtion cost is dominated by the cost of the multiplications \nin the above conditions. Each multiplication corresponds to a unique triple of a production in G, a pattern \noccurring in In, .... Pm (possibly as a subpattern), and a position in P. So the total number of multiplications \nis bounded by lGllp,, . . . . pn12. The integers involved in the multiplica\u00adtions get large so we will \nuse a blt complexity analysis of the cost of each multiplication. We have that V[X, p, P]< (ICl + 2) \np 1for all the calculations involved. Hence the num\u00ad ber of b its in the binary notation for the numbers \nis bounded by log((lCl + 2) IPoI) which equals POlog(lC\\ + 2). Mukipli\u00adcation takes quadratic time so \neach multiplication can take O(lpl, . . . . Pn12log Ipl, .... pn~ time. So the overall time complexity \nis O(IGIIP1, . . . . p~l log IP1, .... pnl). 8 Conclusions This paper contains two significant results. \nThe first is a uni\u00adfication of various notions of set-based analysis into a single definition which can \nbe applied to any language whose oper\u00adational semantics can be defined by environment evaluation. The \nsecond is a systematic treatment of the complexity of determining SBA-safety as a function of the semantics \nand syntactic complexity of case statements in a functional lan\u00adguage. We leave some open problems. First \nthere, is the prob\u00adlem of working out the worst case complexity of determin\u00ading polyvariant SBA-safety \nfor shallow case statements. We now have a lower bound The second major open problem is harder to state \ntechnically. It is the in-practice efficiency of determining SBA-safety. It seems that in practice the \npres\u00adence of deep case statements is not a problem. Monovariant programs, even with deep patterns, can \napparently be ana\u00adlyzed in cub]c time or better in practice. Worst case com\u00adplexity analysis aside, it \nseems that polyvariance is the more significant performance issue in practice. References [1]A. Aiken \nand E. Wimmers. Type inclusion constraints and type inference. In Proceedings of the 1993 Confer\u00adence \non Functional Programming Languages and Com\u00adputer Architecture, pages 31 41, June 1993. [2] A. Aiken, \nE. Wlmmers, and T.K. Lakahman. Soft typ\u00ading with conditional types. In ACM Symposium on Principles of \nProgramming Languages, pages 163-173. Association for Computing Machinery, 1994. [3] R. Amadio and L. \nCardelli. Subtyping recursive types. ACM Transactions on Programming Languages and Systems, 15(4):575-631, \n1993. Also in Proc. POPL91. [4] P. Cousot and R. Cousot. Abstract interpretation: A unified lattice model \nfor static analysis of programs by construction or approximation of fixed points. In ACM Symposium on \nPrinciples of Programming Languagea, pages 238-252, 1977. [5] Thorn Friihwirth, Ehud Shapiro, Moshe Vardi, \nand Eyal Yardeni. Logic programs aa t ypes for logic programs. In Proceedings, Sizth Annual IEEE Symposium \non Logic in Computer Science, pages 75 83. IEEE Computer So\u00adciety Press, 1991. [6] N. Heintze. Set based \nanalysis of ml programs. In ACM Conference on Lisp and Functional Programming, pages 306-317, 1994. [7] \nN. Heintze. Control flow analysis and type systems. In Second Static Analysis Symposium (SAS95), pages \n189\u00ad 206. Springer Verlag, 1995. Lecture Notes in Computer Science 983. [8] N. Heintze and J. Jaffar. \nA finite presentation theorem for approximating logic programs. In ACM Symposium on Principles of Pragmmming \nLanguagea, pages 197 209. Association for Computing Machinery, 1990. [9] P. Van Hentenryck, A. Cortesi, \nand B. Le Charlier. Type analysis of prolog using type graphs. Journal of Logic Programming, 22(3), March \n1995. Also in PLDI\u00ad 94. [10] S. Jagannathan and A. Wright. Effective flow analysis for avoiding run \ntime checks. In Second Static Analysis Symposium (SAS95), pages 207 224. Springer Verlag, 1995. Lecture \nNotes in Computer Science 983. [11] David McAllister. Inferring recursive data types. http: //www.ai.mit \n.edu/people/dam/rect ypes.ps. [12] P. Mishra. Towards a theory of types in prolog. In International Symposium \non Logic Programming, pages 289-298. IEEE, 1984. [13] P. Mishra and U. S. Reddy. Declaration-free type \ncheck\u00ading. In Proceedings of the Twelfth Annual ACM Sym\u00adposium on Principles of Programming Languages, \npages 7-21. ACM, 1985. [14] J. Palsberg and P. O Keefe. A type system equivalent to flow analysis. In \nPOPL95, pages 367-378, 1995. [15] J. Palaberg and S. Smith. Constrained types and their expressivelness. \nTran~actions on Progmmming Lan\u00adguage.t and Sy8tems. to appear. [16] Olin Shivers. Data flow analysis \nand type recovery in scheme. In Peter Lee, editor, Topics in Advanced Lan\u00adguage Implementation, pages \n47 87. MIT Press, 1991. Permission to make digital/hard copy of part or all this work for personal or \nclassroom use k granted without fee provided that copies are not made or distributed for profit or commercial \nadvan\u00adtage, the copyright notice, the title of the publication and its date aPPear, and notice is given \nthat copying is by permission of ACM, Inc. To copy otherwise, to republish, to POSI on servers, or to \nredistribute to lists, requires prior specific permission and/or a fee ICFP 97 Amsterdam, ND 0 1997 ACM \n0-89791 -918 -1/97 /0006 . ..$3.50 163  \n\t\t\t", "proc_id": "258948", "abstract": "We define a general notion of set-based analysis --- any language whose operational semantics is defined by environment evaluation has a well defined set-based abstraction. This general definition covers both Aiken and Wimmers' type system and Heintze' set-based analysis. Aiken and Wimmers give a nondeterministic exponential time algorithm for their analysis. Heintze gives an <i>O</i>(<i>n</i><sup>3</sup>) procedure. We show that this discrepancy is due to the complexity of the case statements analyzed. For polymorphic programs with deep patterns in case statements (as in the Aiken-Wimmers language) we show that the problem of determining type-safety under set-based abstraction is complete for deterministic exponential time. The problem remains complete for deterministic exponential time for programs without let (monovariant programs). However, for monovariant programs in which all patterns in case statements are shallow, as in the Heintze language, type-safety under set-based abstraction is decidable in cubic time. We give five additional theorems which (nearly exhaustively) characterize the time complexity of set-based analysis as a function of the complexity of case statements.", "authors": [{"name": "Nevin Heintze", "author_profile_id": "81100251839", "affiliation": "Bell Labs, 600 Mountain Ave, Murray Hill, NJ", "person_id": "P208265", "email_address": "", "orcid_id": ""}, {"name": "David McAllester", "author_profile_id": "81100488875", "affiliation": "AT&T Labs, 600 Mountain Ave, Murray Hill, NJ", "person_id": "PP43121220", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258948.258963", "year": "1997", "article_id": "258963", "conference": "ICFP", "title": "On the complexity of set-based analysis", "url": "http://dl.acm.org/citation.cfm?id=258963"}