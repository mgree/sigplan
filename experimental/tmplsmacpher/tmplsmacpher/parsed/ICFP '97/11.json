{"article_publication_date": "08-01-1997", "fulltext": "\n .4 Practical Subtyping System For Erlang Simon Marlow Philip Wadler simonm@dcs .gla. ac. uk wadler@research \n.bell-labs. com University of Glasgow Bell Labs, Lucent Technologies Abstract We present a type system \nfor the programming language Er\u00adlang. Thetype system supports subtyping and declaration\u00adfree recursive \ntypes, using subtyping constraints. Oursys\u00adtem is similar to one explored by Aiken and Wimmers, though \nit sacrifices expressive power in favourof simplicity. We cover our techniques for type inference, type \nsimplific\u00adation, and checking when an inferred type conforms to a user-supplied type signature, and report \non early experience with our prototype. 1 Introduction We can stop waiting for functional languages to \nbe used in practice-that day is here! Erlangis a strict, untyped func\u00adtional language with support for \nconcurrency, communica\u00adtion, dktribution, fault-tolerance, on-the-fly code reloading, and multiple platforms \n[AVW93]. Applications exist that consist of upwards of half a million lines of code. This paper documents \nour experience in designing and building atypesystem for Erlang. Ourtype system provides type inference \nwith subtyping, declaration-free recursive types, type signature checking, and data abstraction. So far \nwe have successfully applied ourprototype to about 5000 of the 13000 lines of code in the Erlang standard \nlibrary, and anticipate no difficulties in applying it to the remainder. We expect that adding a type \nsystem to Erlang will improve documentation, maintenance, and reliability. Our type system had two goals. \nFirst, itshould type existing Er\u00adlang code with little or no modification. Second, it should be easy \nto comprehend. Whereaa many type systems strive to maximise expressive power, our aim is to maximise \nsim\u00adplicity, consistent with having sufficient power to describe Erlang as it is typically used in practice. \nOur fist goal rules out the popular type system devised by Hindley and Milner [Hin79, Mi178, DM82]. The \ndifficulty is that with HindIey-Milner each type must involve a set of constructors distinct from those \nused in any other types, a convention not adhered to by Erlang programmers. So we need a type system \nthat allows one constructor to belong to several different types. One possibility is types Permission \nto make digital/hard copy of part or all this work for personal or classroom use is granted without fee \nprovided thal copies are not made or distributed for profit or commercial advan\u00ad tage, the copyright \nnotice, the title of the publication and its data appear, and notice is given that copying w by permission \nof ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires \nprior specific permission and/or a fee ICFP 97 Amsterdam, ND @ 1997 ACM 0-89791 -918 -1/97 /0006,., \n$3.50 based on row variables, as introduced by Wand [Wan87], and used aa the basis of the soft type system \nfor Scheme by Cartwright, Fagan, and Wright [CF91, WC94]. It turns out that the row variable system rejects \nsome programs that seem quite natural to us, and the circumlocutions we had to go through to construct \nan equivalent program that was well typed struck us as hard to explain. This isn t a prob\u00adlem for soft \ntyping systems, where the goal is to improve per\u00adformance by removing run-time type checking, and therefore \nmaximum information is of greater benefit than a natural notion of typing. The alternative that we adopted \nis to build a type system based on subtyping. Type systems with subtyping have been studied by several \nresearchers [Mit91, FM88, MR85, Rey85], and are baaed on solving systems of typing constraints of the \nform U~ V, where U and V are types. Hindley-Milner systems, by cent rast, are based around equality constraints \nof the form U= V, which can be solved by unification. Subtyping systems are strictly more general than \nHindley-Milner systems: each program that can be typed by Hindley-Milner has a typing in a subtyping \nsystem, but not vice versa. Our type system is based around the system developed by Aiken and Wimmers \n[AW93], except sacrifice express\u00adive power in favour of simplicity. We chose the smallest type language \nconsistent with describing typical Erlang pro\u00adgrams: we support disjoint unions, a limited form of com\u00adplement, \nand recursive types; but not general unions or in\u00adtersections, or conditional types [AWL94]. Our expectation \nwas that these additional features would not help programm\u00aders, but would make inferred types less readable. \nWe have succeeded in that our simplified inferred types are usually readable. On the other hand, we have \nencountered at least one situation where conditional types would be useful, as discussed in Section 9.3). \nThe type system presented here does not include func\u00adtion types, since first-class functions are not \na feature of the current version of Erlang. However, the soon-to-be-released Erlang 4.4 supports first-class \nfunctions and we have suc\u00adcessfully extended our prototype implementation to include function types. \nWhile we conjecture that our type check\u00ading algorithm without function types is complete, the work of \nTrifonov and Smith [TS96] shows a similar system with function types is incomplete, although they claim \nthis is not a serious problem in practice. We discuss this in Section 8.1. We demonstrate our system \nwith a small program to manipulate sorted binary trees of keyi and values. Figure 1 shows a type declaration \nand three Erlang functions with -deftype tree(A,B) = T uhen T = empty I branch<A,B,T,T}. -type nevo \n-> tree(O,O). neuo -> empty. -type insert(A,B,tree(A,B)) -> tree(A,B). insert(KO,VO,empty) -> {branch,KO,VO,empty \n,empty}; insert(KO,VO,{branch,K,V,L,R~) -> if KO< K-> {branch,K,V,lnsert(KO,VO,L) ,R}; KO== K -> {branch,KO,VO,L,R}; \ntrue {bran~~,K,V,L,insert {KO,VO,R)I end.  -type lookup(A,tree(A,B)) -> B I error when B \\ error. lookup(KO,empty) \n-> error; lookup(KO,{branch,K,V,L,R}) -> if KO < K -> lookup(KO,L); KO== K-> V; true -> lookup(KO,R) \n end. Figure 1: Binary Tree Example type signatures. All type information is treated aa annota\u00adtions, \nwhich in Erlang are prefaced with a dash (-). The basic data structures in Erlang are integers, floats, \natoms (such as empty) and tuples (such as {branch,K,V,L,Rl, where branch is an atom and K, V, L, R are \nstructures). In our system, the types of these are respectively written integer (), f lost (), empty, \nand branch{A,B,T,T} (where Khaa type A, Vhas typeB, and Land Rhavetype T). (Why we write brsnch~A,B,T,T} \nin\u00adstead of {branch,A,B,T,T} will be explainedin Section 2.) The empty type, containing no values, is \nwritten O and the universal type, containing all values, is written 1. In Erlang, atoms and functions \nbegin with a small letter while variables begin with a capital letter; functions may be distinguished \nfrom atoms because they are followed by parentheses. The same thing works at the type level, where empty \nis the type ofan atom, integero is abuilt-in type returning the type of all integers, and A is a type \nvariable. The deftype annotation defines the type tree(A,B), while the three type annotations specify \ntype signatures for the functions new, insert, and lookup. These annotations allow the user to document \nthe program, and the type tool checks that the program conforms to that documentation. When multiple \nmodules are processed, one may specify that thenameof atype is exported without exporting itsdefin\u00adition, \nthereby supporting type abstraction. For instance, if this module exports the type tree without exporting \nits definition, then the type system will ensure that only the three functions defined in it have access \nto the representa\u00adtion of trees. The function empty takes no arguments and returns a tree; the function \ninsert takes a key, a value, and a tree newo -> A when empty <= A insert(B, C, D) -> A when brench{E,F,G,A} \n<= A; brsnchlB,C,G,H} <= A; branch{E,F,A,H} <= A; brsnch{B,C,empty,empty) <= A D <= empty I br &#38;chxE-,F,G,H] \nG <= empty I branch{E,F,G,H~ H <= empty I branch{E,F,G,H} H<=D; G<= D. lookup(B, C) -> A when error \n<= A C <= empty I branch{D,E,F,G]; F <= empty I branch{D,E,F, G]; G <= empty I branch{D,E,F,G}; E<=A; \nF<= c; G<= c. Figure 2: Inferred Types new () -> empty. insert(D, E, F) -> A when empty I branch{D,E,A,A} \n<= A; F <= empty I branch{D,E,F,F]. lookup(l, B) -> error I A when B <= empty I branch{l, error I A, \nB, B]; A i error. Figure3: Simplified Types and returns a new tree with the key and value inserted; \nand the finction lookup takes atreeaud akey, and returns the value corresponding to that key or the atom \nerror if the key is not found. To avoid any possibility of confusing a success and failure, the type \nspecified for lookup adds the constraint that the value type B cannot include the atom error, written \nB \\ error. In general, the form ofatype signature is U when C, where U isatype and Cisaset of constraints. \nOne problem with using a type system built around sub\u00adtyping is that the set of constraints can be arbitrarily \nlarge, and inferred types can be difficult to read if they are not simplified. This is one reason for \nfavouring simplicity over expressiveness: the more expressive the type language, the more difficult it \nis to simplify types. Experiments with our prototype have been promising, as for most functions we can \nderive a natural and readable version of its inferred type. Figure 2 shows the types derived by our inference \nal\u00adgorithm for the three tree operations, and Figure 3 shows the same types after simplification. The \nuser-provided type signatures differ considerably from the inferred and simpli\u00adfied types. First, user-provided \ntypes may refer to type definitions, which do not appear in inferred or simplified types. For instance, \nsignature for new declares the function to have type tree (O, O), where O is the empty type; whereas \nthe simplified inferred type is simply empty, the empty tree. Second, the user-provided types may be \nmore specific than the inferred type. For instance, the signature for lookup restricts the type A of \nthe lookup key to be the same as the key fields in the tree, and the type B of the value fields in the \ntree not to contain error; whereas in the simplified inferred type B is the type of the tree, and A is \nthe type of non-error value fields, but value fields may specifically include error. Inferred types are \nprincipal, in that the inferred type of a function has all other possible types of that function as instances. \nHowever, as simplification demonstrates, the same type may be written in many forms. Simplified types \nare equivalent to the original, in that they represent the same set of values in the semantic domain. \nTo check user-supplied type signatures, we need to de\u00adtermine when a one type is an instance of another \ntype. This problem turns out to be surprisingly tricky. The prob\u00adlem has been analysed by Tkifonov and \nSmith [TS96] for a type language containing function types but no type union (conversely, ours contains \ntype union but no function types), and they provide an algorithm which is sound but not com\u00adplete, and \nleave the question of decidabiiity open. In this paper, we give an algorithm which we believe is both \nsound and complete for our type language, but so far we have been unable to find a proof. The paper is \norganised as follows. Section 2 introduces the syntax of expressions and types. Section 3 describes the \ntyping rules for expressions. Section 4 presents a type recon\u00adstruction algorithm. Section 5 shows how \nto solve systems of typing constraints. Section 6 explains how to simplify types. Section 7 describes \nour algorithm for type signature matching. Section 8 sketches extensions to the type system for processes \nand higher-order functions. Section 9 relates our experience with the prototype implementation. Section \n10 concludes. 2 Expressions and Types The syntax of expressions we will be using is given in Figure 4. \nThe language is a small subset of Erlangl containing variables, constructor applications (called tagged \ntuples in Erkmg), function caIls and simple case expressions. We use t~e overbar to indicate a sequence \nof objects, for example E = El,.. ., En. The length of the sequence is normafly discernible from_the \ncontext. Each constructor has a fixed arity, so in c{E} the length of the sequence of expressions ~ is \nequal to the arity of the constructor c. When there is no length-fining context, the length of the sequence \nis arbitrary. Standard Erlang doesn t have constructor applications. It has atoms, which we represent \nas nullary constructor ap\u00adplications, and it has arbitrary tuples, written {El,. ...En}. In our type \nsystem we use the convention that if the first element of a tuple in an Erlang program is an atom, then \nwe convert the tuple to a tagged tuple, using the atom name as the constructor. If the first element \nis some other expres\u00ad sion, then the tuple is an anonymous tuple, and we assign the constructor tuplen, \nwhere n is its arity. There we several other differences between Erlang and our small subset: . All pattern \nmatching is compiled into simple case f> 9 function names C, d constructors x, Y,z variables E .. ,. \n expression I ~E1,..., En} I Joe,,..., En) I case EO of c1{z} -) El;  c.{Xn} + En; x -) E.+l end prog \n::= f,(x) + E,; program f. (x) -) E. Figure 4: Expressions C, d constructors CrlP type vaziables U, V \n::= P IU union type IR P,Q ::= c{~} prime type Figure 5: Types expressions. Algorithms to do this are \nwell known [Aug85, Wad87]. . Case expressions always have a default alternative, of theform X + E. A \nspecial form of this is used to indicate that the alternative should never be taken: X+ empty(X), where \nempty is a built-in function which always fails. . Interprocess communication is omitted for now. We \ndiscuss an extension to handle this in Section 8.2. Programs consist of a set of toplevel function declara\u00adtions, \nwhich may be recursive. Our type system will assign polymorphic types to these function declarations. \nThe semantics of our language is strict i.e. function argu\u00adments are always evaluated before the function \nis called, and constructor arguments are evaluated before the structure is built. The syntax of types \nis given in Figure 5. Prime types are written c{ U1,.... u.}, and represent the type of a tagged tuple \nwith tag c, arity n, and field types U1... Un. The general form of a union type, U, is cl{m}l. ..lcn{un}l \nR where R represents a remumder. A remainder is either a type variable a , the universal type 1c , or \nthe empty type 0. The syntax a s for a type variable means that a ranges over all types not containing \nelements with the tags c1,. . . . C~ (= CS). The tags cs are called the ezcluded tags on the type variable \n~. Similarly, the syntax l S represents the universal type excluding types with tags cl, . . . . c.. \nIf the list cs is empty, it is normally omitted. When the remainder is O or 1= , the type is called a \nmonotype. The operator 1 is a dkjoint union. This means that in the type expression PI U, the types P \nand U cannot overlap under any legal substitution for the free variables of either type. This implies \ntwo further restrictions on the form of the general union type c1{n} I. . . I c.{ U.} IR: the tags cs \nmust be distinct, and if R is of the form ad or 1 S then cs~ds, where csis cl,.. ., c . This syntax of \ntypes provides exactly the level of gen\u00aderality we require for typing Erlang. The main differences between \nthis system and that of Aiken and Wimmers [AW93] are: . the lack of a general intersection, instead we \nonly al\u00adlow excluded tags (which would be represented with intersection in the Aiken-Wirnmers system). \n . the lack of function types. As mentioned in the in\u00adtroduction, we leave out function types because \nthe current version of Erlang doesn t support them.  Our union operator is equivalent to that used \nin the Aiken-Wimmers system except that we do not aflow general (non-disjoint) union on the left of a \nconstraint. However, general union on the left of a constraint can always be re\u00adplaced by several constraints \nwithout union operators. The presence of the universal type is interesting: in fact, we never infer types \ncontaining the universal type, although some types are simplified by replacing type variables in neg\u00adative \npositional by the universal type. Experimentation with the prototype persuaded us that the universal \ntype in a positive position is useful for expressing the type of certain Erlang built-in functions for \nwhich our type system cannot provide precise types, For example, the function element selects the nth \nelement of an arbitrary tuple. The best type for this function in our system is (into, tupleo) + 1, where \nint() and tuple() are built-in types representing integers and tuples respectively. Without the universal \ntype, it would not be possible to give a sound type to this function. 2.1 Subtyping Constraints Subtyping \nconstraints are written U~ V. A constraint is valid if all values of the type U are also values of the \ntype V. We use the identifiers C and D to refer to sets of subtyping constraints, where a constraint \nset is valid if and only if all the individual constraints are valid. If the types in a constraint set \ncontain type variables, the validity of the set depends on a substitution u from type 1A type is in a \nnegative position if it appears in an argument posi\u00adtion of a function type or on the right hand side \nof a constraint. Result types and the left hand sides of constraints are positive positions. variables \nto type values. A type value is a certain portion of the semantic domain, for example: integer , list \nof char\u00adacters , and tree of integer pairs are all type values (a set of values is another way of thinking \nof it). An ideal model similar to that in [MPS86] or recursive type equations as used by Trifonov and \nSmith [TS96] would provide a suitable framework for defining type values. A substitution u is a solution \nof a constraint set iff its application renders the constraint set valid. We use some shorthand forms \nfor sequences of similar subtyping constraints: Tcv +Ulgvl,..., ungvn Ugv *U GV1,... ,UGV Vcv +-ul&#38;v,..., \nuncv 2.2 Entailment We also introduce an entailment operator over constraint sets, written as follows: \nCII-D which is true if all solutions of C are also solutions of D. Entailment is reflexive and transitive. \nWe will also use another form of entailment: Wi.3~. C It-D which is true if every substitution mapping \n@ to type values that solves C ~an be extended to a solution of D by adding mappings for ~. It follows \nfrom this definition that ~ must contain at least the fkee type variables of C. If the free type variables \nof D are a subset of those of C, then the two operators above are equivalent. The latter operator is \nused to define type instance, in Section 7. 2.3 Rmction Types Although our type language does not have \na general func\u00adtion space operator (+), we assign type schemes to top-level functions in the source program. \nTop-level function type schemes are polymorphic and constrained. They take the following form: =.(~) \n+ V when C Function type @heroes cannot have any free type variables (that is, FTV(( U)+ V when C)~@. \n3 Typing Rules We give the typing rules for expressions in two forms. This section describes a traditional \nset of typing rules for subtyp\u00ading, and the following two sections describe our algorithm to determine \nthe most general typing of an expression. The typing rules in traditional format are given in Figure \n 6. The form of a judgement is F; A; CEE:U Elements of F have the form j : =.(~) + V when C. Elements \nof A have the form z : U. The judgement asserts that under function assumption F and variable assumption \nF; A; C1-E:iJ clFugv Sub w F; A, X: U; CkX:U F; A; CkE, V F;A; C1-~:~ F; A; C+ f:(~)+V F;A;Ck~:~ Con \nF; A; C t-c{~} :c{~} Call F; A; C+ f(~): V F; A; Ck~O:cI{T}l...l{un}lulu . F; A, XI:UI; CI-EI:V . . . \nF; A, Xn:Ur,; Ct-E :V Case F; A, X: U; CkEn+I:V F; A; CE(case Eo of C1{X1}+ E1; . ..{X}+E+.X; +E++l+l \nend) : V F; A; CkEI:UI . . . F; A; CkEn:Un Multi F; A; Ct-E:~ ~~f F, f: ((~)+ Vwhen C); X: U; Cl-E: \nV FTV((~)+ Vwhen C)=?i F; 0; C1-f(%) + E :(Wi. (~) + V when C) Figure 6: Typing Rules A, expression E \nhas type U whenever the constraint set C is satisiied. The typing rule for function names (fin) instantiates \nthe quantified variables with arbitrary types. It also copies the constraints D horn the function type \ninto the current con\u00adstraint set C, ensuring that the constraints on the function type are satisfied \neach time the function is called. As mentioned in Section 2 we assume one built-in func\u00adtion empty, with \ntype empty :(0) + O The empty function is the only means by which a func\u00adtion may fail: if empty is ever \ncalled at runtime, the program exits. The rules allow any expression to be assigned a typing, but only \ntypings in which C has at least one solution are useful (these are called valid typings). If any valid \ntyping exists, then it is guaranteed that the program will never call empty at runtime. Subtyping is \nintroduced with the subsumption rule (Sub), which allows the type U of an expression to be re\u00adplaced \nwith any larger type V provided the entailment re\u00adlation C It-U$ V holds (the entailment operator was \nde\u00adscribed in SectIon 2.1). The simplest way for this relation to hold is if C contains U< V. For case \nexpressions, the type of the selector E. is re\u00adquired to be smaller than the union of the types of the \npat\u00adtern alternatives and the t~e of the variable X bound in the default alternative (cl { UI } 1. . \n. I C. {~} I U, where each type ci {v} is the type of a pattern, and U is the type of X). By the rules \nof the disjoint union operator, this implies that the type U cannot contain any elements with the tags \nCl, . . ..cn. Compare this with traditional Hindley-Milner type checking, where there is no way of representing \nor ex\u00adploiting the fact that the type of the default variable may exclude types handled by earlier case \nbranches. In order to type an arbitrary expression we need to know two things: whether a valid typing \nexists, and the most general form of that typing. Note that in general there is no unique most-general \ntype for a given function in this system. Indeed, the type simpli\u00adfication process that we will describe \nin Section 6 attempts to replace a type with an equivalent simpler type. Two types me equivalent if they \nare instances of each other; we will discuss subtype instance in Section 7. In our implementation, typings \nme derived in two stages: . Firstly, type reconstruction derives a type and a set of typing constraints \nfor the expression. This is the most general typing of the expression if the constraints are satisfiable. \n . The second stage, constraint set reduction, determines the solvabilityy of the constraint set. If \nthe set is solv\u00adable, then we have a type for the expression,  These two stages are described in the \nnext two sections. 4 Type reconstruction The typing rules can be used in a syntax-directed way to generate \na constrained type as follows: . Assign a fresh type variable to each new bound vari\u00ad able. Thus the \nassumption A binds variables to unique type variables, . Assign a fresh type variable for the type of \neach case expression. . Use subsumption in the following places: to promote the type of each function \nargument in a function call, to promote the type of each branch in a case expres\u00adsion to a common supertype \n(which is a fresh type variable), and to promote the type of the selector in a case expression to the \nunion of the pattern types. For each use of subsumption place the required con\u00adstraint in C, so that \nthe entailment relation is trivially satisfied. 2. Any rule that can be applied would take the constraint \nset into a state that has occurred before. otherwise if ds~ cs otherwise if ds~ cs otherwise ifc=c C{-u} \nc l s 3 none ifcfcs fail otherwise C{-u} g Clcs - C{77} g c? ifcflcs fail otherwise u g CY j a s ~v \n* ugv, ugcrc , clcs~v Figure 7: Reduction Rules Proposition 1 (principal type property) Every type \nderiv\u00adable for a function using the typing rules is an instance of the type derived by the type reconstruction \nalgorithm. The proof of this proposition is similar to Mitchell s proof of principal types for his subtyping \nsystem [Mit91]. 5 Constraint Set Reduction Constraint Reduction is the process of determining whether \na system of constraints is solvable. If a constraint system generated by the type reconstruction algorithm \nis not solv\u00adable, it indicates that the program has a type error. We do not have to discover an actual \nsolution to the set, merely prove that one or more solutions exist. This is done by repeatedly transforming \nthe constraint system while maintaining transitive closure and checking for type errors. The transformation \nsystem is given in Figure 7. Each rule applies to one or more constraints born the current set, and yields \none of the following results: . fail , indicating that the constraint system has no solu\u00adtions, and the \noriginal function therefore contains a type error, . none , indicating that the constraint should be \nre\u00admoved from the system, . one or more transformed constraints. The original con\u00adstraints are to be \nremoved from the set.  A constraint set is only fully reduced when both of the following conditions \napply: 1. Each constraint in the set is of the form a ~ U or U~ac , and If the reduction process terminates \nwithout failure, the resulting constraint set is said to be consistent. For reasons of efficiency, we \nignore the strictness of con\u00adstructors for type inference purposes. In other words, the type of c{l} \nin our system is c{ O}, not O. A similar situation is found in [AW93] where some solutions to the constraint \nset are discarded for efficiency. Proposition 2 When applied to an arbitrary constraint set, the reduction \nprocess either fails or terminates yield\u00ading a consistent constraint set. Proof sketch. Observe that \nall rules in the transform\u00adation algorithm, except the last (transitivity), either fail or split a constraint \ninto zero or more constraints on subterms of the originals, until all the constraints have a variable \non one side or the other. All the cases are covered; so any con\u00adstraint set can be reduced to a state \nwhere all constraints are of the form a= ~ U or U ~ a . The transitivity rule forms a new constraint \nfrom exist\u00ading types. This rule cannot be applied indefinitely without reaching a fixed point because \nthere are only a finite number of possible constraints to add. We must therefore reach a state where \n(1) all constraints are on variables, and (2) the only rule which can be applied to change the set is \ntransit\u00adivity, and all possible constraints have already been added to the set. . Proposition 3 A consistent \nconstraint set is solvable. Proof sketch. We prove this property by relation with the inductive constraint \nsystem of Aiken and Wlm\u00admers [AW93]. A consistent constraint set in our system can be transformed into \nan inductive constraint set, and the pro\u00adcess cannot fail. Inductive constraint sets were shown to be \nsolvable by Aiken and Wimmers. The subject of inductive form and the algorithm for con\u00adverting a consistent \nconstraint set into an inductive con\u00adstraint set are discussed in Section 7. 6 Type Simplification The \ntype assigned to a function by the type inference al\u00adgorithm can be large and unwieldy, making it difficult \nfor a user to interpret, and expensive for an implementation to deal with. Therefore we apply a number \nof simplifying trans\u00adformations to the type, in an attempt to derive an equivalent type that contains \nfewer typing constraints. Our simplification transformations are similar to those of Fiihndrich and Aiken \n[FA96], who use type simplification amongst other techniques to show that set-constraint-based analyses \nare scalable to large examples. We have not found a suitable normal form for a con\u00adstrained type, nor \nhave other researchers in this area. We cannot therefore hope for a simplification procedure that is \ncomplete. There are sometimes typing constraints which cannot be eliminated; one example is when the \nconstraints are being used to represent a recursive type. However, the transformations given in this \nsection =e based on heurist\u00adics that we have found to be effective. In many cases, the derived type can \nbe simplified to the type that one would normally assign to the function. The constraint set generated \nby the type inference al\u00adgorithm satisfies three important properties that we can make use of during \nsimplification. . Each constraint in the system is of the form a= ~ U or U ~ 0 , termed upper and lower \nbounds on a respectively. For an implementation, this means that we can represent the constraint set \nas a mapping from variables to sets of upper and lower bounds. This prop\u00aderty will hold throughout simplification. \n. Separate occurrences of the same variable will have identical excluded tag lists. This property will \nhold throughout simplification. . The constraint set is transitively closed. That is, for each constraint \npair o $,3dS and /3d ~ U, the set contains the constraint a ~ U, and for each pair U ~ fid and ~d ~ ac \n, the set contains U c a , We will not retain this property during simplification, although the transitive \nclosure can always be recovered by adding the necessary constraints to the system. 6.1 General Simplifications \nThe following transformations are applied whenever the op\u00adportunity arises during the simplification \nprocess. 6.2 Eliminating Cycles Our implementation eliminates cycles in the constraint set as a first \nstep, since it has a dramatic effect on the efi\u00adciency of the rest of the simplification process and \nis relat\u00adively cheap to perform. The idea is to first identify all cycles between variables. Since in \nany solution of this constraint set the values of these variables must be identical, we can replace all \noccurrences of the variables with a new variable. The transformation is given in Figure 8a. If the constraint \nset is treated as a graph with the vari\u00adables as nodes, then cycles can be found in linear time using \nstandard algorithms, and removed in linear time using the above substitution. The result is a directed \nacyclic graph. A constraint set in this form is called contractile [TS96]. 6.3 Combining Upper and Lower \nBounds In general, a variable may have several upper and lower bounds. The purpose of this simplification \nstage is to reduce the number of upper and lower bounds on each variable by combining them where possible. \n6.3.1 Combining Lower Bounds It is always possible to combine the lower bounds on a vari\u00adable such that \nwe achieve a normal form: p] q ad p. ~ a Cl{m}l. ..lcn{un}lo gads After combination, the lower bounds \non a variable will consist of zero or more variable-only lower bounds, and at most one constructed lower \nbound (a union type where the remainder is O). This is achieved by applying the transform\u00adation rules \nof Figure 8b, and collecting the (now distinct) prime type lower bounds on each variable into a singe \nunion type. For example, if we have the following constraint set: C{u}ccr, C{v}gcr then we can replace \nthis with where there is now only a single lower bound on the variable a. There are now two lower bounds \non the variable ~, which can be combined in the same way. 6.3.2 Combining Upper Bounds Unlike lower bounds, \nwe have found no useful normal form for upper bounds because we cannot compute the intersec\u00adtion of several \nunion types and represent the result in our type syntax. Instead, we use some heuristics to combine upper \nbounds where possible. An example of one of the transformations used is given in Figure 8c, where two \nupper bounds are combined if they are monotypes. This is an important transformation for our type checking \nalgorithm, in Section 7. 6.4 !IYansitive Kernel During the simplification process, we work with the trans\u00aditive \nkernel of the constraint set, The transitive kernel of a transitively closed constraint set C is defined \nas the small\u00adest constraint set D such that the transitive closure of D is C. If C is contractile (Section \n6.2), then there is a single unique D, computed by applying the transformation rule in Figure 8d as many \ntimes as possible to the constraint set. The advantages of working with the transitive kernel are: . \nThe set is smaller, but contains the same information. The original constraint set can be recovered by \nforming the transitive closure. . Our simplifying transformations are equally valid when applied to the \ntransitive kernel. In fact, remov\u00ading the transitive constraints can enable some trans\u00adformations that \nwere not previously possible. As an example of the second point, the variable elimin\u00adation transformation \nis only applicable when a variable has a single upper or lower bound; if there are other constraints \non the variable that are present due to transitivity then the transformation cannot be applied. We could \ntake into ac\u00adcount these transitive constraints during the transformation, but it is simpler to compute \nthe transitive kernel once and maintain it throughout simplification. 6.5 Eliminating Variables The transformation \ndescribed in this section is simple, and yet remarkably effective in simplifying types. The basic idea \nis to find a variable with a single upper bound or a single (2; 1 ~clp, ,,,,a; ~ a; , c* c[/ 3d /clp,. \n,/3d /&#38;] where ~ fresh, ds= CS1UU csm a. Eliminating Cycles crcs~cl{m} l.. .] c.{~} I al{~} 1...[ \nam{vm} I RI a ~cl{~} 1...1 Cn{~} I &#38;{V~} 1...1 bi{~} I R2 ~ tics G Cl{=} 1,..1 c~{~} I {a, {W} I \nin(a,, Rz)} I {h{~} ~~~ l<i<n ~cz l<i~?l where z fresh I<i<n in(c, lc ) = c @ cs in(c, O) = false c. \nCombining Upper Bounds I in(bi, Rl)} u1gu2, ,.. ,un-l~un, ul gun *ulgu2, d. Tramxtive Kernel . . .._lgu \nnun Figure 8: Simplifying Transformations lower bound and replace it with this bound when it is legal \nto do so. For example, the type a when c{} ~ a is equi\u00advalent to simply c{}, and the first type can be \nsimplified to the second by replacing the variable a with its single lower bound c{}. The first transformation \napplies to variables with a single upper bound: U when a Q V,C + (U when C)[V/(aC )] There are some restrictions \non this transformation: . There are no cycles in the constraint set involving a= , . a s appears only \nnegatively in U and C, . a must have variable-only lower bounds, unless V is a variable. This is to \nretain the invariant that all constraints are on variables.  . The substitution ( U when C) [ V/CIcs] \nmust be legal with respect to the disjoint union operator. The first restriction is to prevent the transformation \nfrom being applied indefinitely, as would be the case if the variable a c were put of the definition \nof a recursive type in the constraint set. The dual of this transformation applies to single lower bounds: \nU when V ~ crc ,C + (U when C)[V/(acS)] The restrictions are similar to the upper-bound case: . There \nare no cycles in the constraint set involving a==, . a appears only positively in U and C,  . Clcs \nmust have variable-only upper bounds, unless V is a variable. There is no need for a restriction equivalent \nto the fourth restriction for upper bounds, since it would always be satis\u00adfied. There are two subsidiary \ntransformations, which apply to variables with no upper bounds or no lower bounds: If a has no upper \nbounds and appears only negatively in U and C: U when C= (U when C)[(lcS)/(acS)] And the dual case, when \na= has no lower bounds and appears only positively in U and C: U when Ca (U when C)[O/(crc )] 6.6 Eliminating \nlower bounds The following transformation has less restrictions than the variable elimination transformation, \nbut it is less beneficial in general since it doesn t eliminate any type variables, only constraints. \nWe generally use this transformation as the last stage of simplification. u when cl{~} 1,..1 c.{Z} 10~adS,C~ \n(U when C)[(cl{~} 1... I c.{n} I a(d ucS))/ads] . c1c must have no constructed upper bounds (this is \nto retain the property that constraints are on variables). . There must be no cycles in the constraint \nset involving Crcs.  7 Type Checking Type inference systems normally provide a way for the user to \nsupply a type for a function and have that type checked against the inferred one. This serves two purposes: \n. The user-supplied types serve as documentation for the function, and the documentation is always guaranteed \nto be correct because it is checked by the type system. . The user-surmlied type may be more restrictive \nthan the inferred ~ype. This is useful in cases where the user wishes to place additional restrictions \non the use of a function over those provided by the inferred type, or to use a more general definition \nof a function when this would be more efficient.  A user-supplied type is valid if it is an instance \nof the in\u00adferred type. In Hindley-Milner type systems, an instance of a type is formed by replacing one \nor more of its universally\u00adquantified type variables by more specific types, and it is straightforward \nto check whether one type is an instance of another. When subtyping constraints are involved, however, \nthe problem is somewhat more difficult. Determining when one constrained type is an instance of another \nhas so far received little attention in the literature [TS96, FF96]. In this sec\u00adtion, we outline an \nalgorithm for determining this relation. We do not have proofs of soundness or completeness, but we also \nhave not found any counter examples to either property. There doesn t seem to be a straightforward extension \nof our algorithm to handle function types, since the obvious exten\u00adsion suffers from incompleteness (Section \n8.1). In a subtyping system, the instance relation is really a subtype relation: we are determining whether \none type rep\u00adresents a smaller portion of the semantic domain than an\u00adother. The term instance makes \nsense in Hindley-Milner style systems where the problem reduces to an instance re\u00adlation, but in a subtyping \nsystem we must be more general. The subtyping relation over quantified constrained types can be defined \nusing the~ntailment operator. For two types (V?Z.U when C) and (V/3. V when D) where the quantified variables \n?i and ~ are distinct, (VE. U when C) ~ (VP. V when D) if V~.3z.D IF U~ V,C In the context of type checking, \nthe term on the left of the subtype relation is the inferred type, and the type on the right is the user-supplied \ntype. In brief, the algorithm works as follows. The constraint sets on either side of the entailment \nrelation are converted to inductive form [AW93], and canonical lower and upper bounds are computed for \neach type variable in the set D. The algorithm then proceeds in a similar way to that pro\u00adposed by Tkifonov/Smith \n[TS96], the main difference being that canonical upper bounds are more complicated to com\u00adpute since \nwe cannot form the intersection of several types in general. 7.1 Induct ive Form Our entailment algorithm \nmakes use of an inductive form for constraint sets [AW93]. An inductive constraint set C= be formed from \na consistent constraint set (i.e. one that has been reduced, Section 5), by first choosing an ordering \non variable names and then applying the transformations in Figure 9. The transformation makes use of \na function TLV( U), which returns the top-level variable (the variable remainder) of the type U if it \nexists. Thus a > TLV( U) iff Z LV( U) exists and is smaller than a in the chosen variable ordering. Two \nother operations are used in the transformation. The first, @, forms the union of a type and a set of \ncon\u00adstructor applications whose elements ~e all 1: u~cs+cl{i} 1...1 Cn{i} I (fJ\\cs) The second operator \nis \\, which excludes certain tags from a type: (C{u}l u)\\cs * u@ ifc~cs c{ U}l( U\\cs) otherwise (c# )\\cs \n* a(dsuc ) _ ~(ddh) (ld )\\cs ~cs *O Once the transformations have been fully applied, each constraint \nin the set will be of the form cr C U or Uc CY.where cr > TLV ( U1. In other worda. e~h constraint ., \nis expressed as a bound on a variable a that only refers to variables lower than a at the top level. \nIn the Aiken-Wimmers system this allows the constraint set to be solved, whereas we use this form to \ncalculate upper bounds for our entailment algorithm. One problem with using constraints in inductive \nform is that we no longer have the invariant that separate occur\u00adrences of the same variable have identical \nsets of excluded tags. Our entailment algorithm needs to reduce constraints which do not satisfy this \nproperty, so we must alter the reduction algorithm accordingly. The new reduction al\u00adgorithm is identical \nto Figure 7 except that we remove the transitivity rule (the last rule in the figure) and add the following \ntwo rules: crc g ad * crc g Ids Ugcrc , crdsc V *U~V@ds, UqcrcS, crdS~V The ~cond of the two new rules \nis a new transitivity rule that takes into account the differing excluded tags on the variable cr. In \nthe following discussion of the entailment algorithm, we will use the functions reduce(C) and induct(C) \nto refer to the new reduction and inductive transformations respect\u00adive y. 7.2 Computing Canonical Upper \nand Lower Bounds We have already presented a canonicalisation of lower bounds, as part of type simplification \nin Section 6.3.1. We use that transformation again here. If C is an inductive constraint set that has \nhad the lower-bound transformation applied, then the function lowers(C, a) returns a pair con\u00adsisting \nof a set of variables (all less than o in the inductive ordering) and a union type with a remainder of \nzero. Canonicalising upper bounds is somewhat more difficult, as we cannot form the intersection of several \nunion types in our type language. However, the following two sections describe a method that allows us \nto combine several upper bounds into a single type for the purposes of our entailment algorithm. The \nproblem is to determine entailments of the following form: agvl, . . ..clg.cl Fcrgugu which is true \nif and only if agvl, . . ..a Cvn. ctFV1 n.. .nvngu The problem is that we cannot compute the value of \nthe intersection in general. However, for the purposes of entailment, there are two met hods that can \nbe used to prove this entailment relation. 7.2.1 U is a monotype When U is a monotype, we cap calculate \nthe largest type that each top-level variable in the intersection can take, re\u00adducing the intersection \nto an intersection between mono\u00adtypes which we can reduce to a single type. Definition 1 If V1 V. are \nthe upper bounds of a in the inductive constraint set C, then the absolute upper bound of the type variable \na is calculated as follows: for each top level variable @c= in VI . V., replace @c with V\\cs where V \nis the absolute upper bound of /3. Then form the intersection of the remaining monotypes using the transformations \nfrom Section 6.3.2. This definition is recursive, but it is guaranteed to ter\u00adminate because we are working \nwith inductive constraints. The lowest variable in the ordering cannot refer to any top\u00adlevel variables \nin its upper bounds, so its absolute upper bound can be calculated, the second variable in the order\u00ading \ncan only refer to the first, and so on. Using the absolute upper bound we can form the correct constraint \nif U is a monotype: for the entailment to hold, upper(C, a) ~ U where upper( C, CY) is the absolute \nupper bound of the type variable a in the inductive constraint set C. Absolute upper bounds can be pre-calculated \nfor any given constraint set. 7.2.2 U is not a monotype When the type U is not a monotype, using the \nabsolute upper bound is not good enough: it doesn t allow us to prove the following entailment: ~ ~ C{} \nI cr{c d}, ~ ~ d{} I @{c d} It_ y ~ a{c d} The absolute upper bound for ~ is l{c d}, and it is not true \nthat I{ d} ~ O{ d} for all cr. We need to calculate the absolute upper bound with respect to a particular \nvariable, a in this case. In general, the problem is how to prove the entailment relation: clFvln... \nnvng P1l Pnlpcnlpc Firstly, we can split the inequation on the right as fol\u00adlows: vln. ..nvn clJ1l...lPnllc$ \n(vIn... n V.)\\ds ~ @ where ds are the tags of PI. Pm. The first inequation has a monotype on the right, \nso we can solve it using the method above. For the second inequation, we can form the absolute upper \nbound with respect to D for the type on the left: Definition 2 If VI. V. are the upper bounds of a in \nthe inductive constraint set C, then the absolute upper bound of a with respect to /? is calculated as \nfollows: for each top\u00adlevel variable -yc in VI. V. where ~ # /3, replace -y= with V\\ cs where V is the \nabsolute upper bound of -ywith respect to ~. Express the result as an intersection of unions by distributing \n1 where necessary. Combine all intersections of monotypes into a single monotype using the transformations \nof Section 6.3.2. The absolute upper bound of a with respect to ,B looks like this: (ullpc )n . ..n(unlpc \nn)n M where M is a monotype. If we multiply out the intersec\u00adtion, we get ((ullo)n... n(unlo)nftf)u... \n where the final . . represents the rest of the terms, all of which are intersections involving /?. Now, \nback to our original problem, we have (((u, lo)n... n(unlo) nM)u...)\\dsgp We can discount all the terms \nrepresented by . . since they are all smaller than ~ by virtue of being intersections involving ~. The \nintersection on the left can be normalised to a single union type, and the problem is solved. To recap, \nthe entailment clEC2g P,[...l Pn3c c holds, if and only if C IFupper(cr, C) C PI I IP. IlCS and c t+upper(a, \n/3, C)\\ds g P where upper(a, 13,C) is the absolute upper bound of a with respect to /3 in the constraint \nset C, and ds are the tags of P1. ,.Pn. where new(U c V)=F = induct(reduce( U ~ V)) F =F F~C ~~ ~ c ))) \n~~#;&#38;e(tr~s(F , c :=c u F u T Q := Q+ F ++~ where trans ( C, D) represents the set of constraints \nrequired to retain transitive closure of the set D when the constraints from set C are added. The operator \ni-t stands for list ap\u00adpend. If the algorithm completes, then the specified entailment relation holds. \nIf any of the reduce operations fail, the the entailment relation is false. 7.3 Algorithm to determine \nentailment The following algorithm determines whether the entailment relation V~.3G.D It-U~ V,C holds. \nWe express the algorithm in an imperative manner, using global variables C , D and Q, where C is an evolving \nconstraint set initialised from the inductive reduced form of C, D is an evolving constraint set initialised \nfrom the induct ive reduced form of D, and Q is a queue of inequations left to prove. The general strategy \nused is to attempt to prove that each constraint on the right of the relation is implied by D. The proof \nprocess generates new constraints which must also be shown to be implied by D, along with any constraints \nwhich are required for the transitive closure of the constraint set on the right. 1. Let D = induct(reduce(D)). \nIf this fails, then the en\u00adtailment is trivially satisfied since D has no solutions. 2. Compute lower \nand upper bounds for D . 3. Initialise C = induct(reduce({ U~ V} U C)). If the reduction fails, then \nfail. 4. Initialise queue Q = C . 5. Remove a constraint from Q, and analyse it using the following \ntable, where continue means repeat step 5 until Q is empty:  continue continue let(~, V) = lo~ers(/3, \nD ) if U E(V U {~}), continue else new( V ~ U), continue analvse U: Pi!... lPnl @c V= upper(~, D ) neuf(V~P1l \n. ..l Pnl l) ) V= upper(~, @, D ) new( V ~ @), continue otherwise V= upper(/3, D ) new( V ~ U), continue \n8 Extensions 8.1 First-class Functions Plans are afoot to extend Erlang to include first-class func\u00adtions, \nby including lambda expressions and application in the syntax. Our type inference system extends in a \nstraight\u00adforward way to include function types, as follows. Add a new prime type ( WI,.... U.) + V and \na new tag + to the type syntax, and add lambda expressions J( U1,....U ) + V, application E(EI, ....En), \nand references to top-level func\u00adtions f/n (where n is the arity of f) to the expression syntax. Add \nthe following rules to the type system F; A,~:~; C+E:V Lam F; A; C+(A(~)+E):(~)+V F; A; Ct-E:(~)+V F; \nA; CEE:U App F; A; Ct-E(~):V The reduction algorithm can be extended to function types with the addition \nof two rules: (U)+ vc((v)+v )lu * Vcv, vcv (u) + v g C{m}lu + (V)+v Our algorithm for determining entailment \ncan be exten\u00added to support function types, but the resulting algorithm is known to be incomplete [TS96]. \nDecidability of entailment in the presence of function types is not known. 8.2 Interprocess Communication \nOne of the most important features of Erlang is its support for concurrency and transparent distribution. \nWith some straightforward extensions, we can extend our type system to check the types of messages passing \nbetween processes. Erlang provides primitives for sending and receiving mes\u00adsages, and spawning new processes. \nTo type check message passing, it is necessary to keep track of the types of messages received by a given \nexpression. Therefore, we propose extending the typing rules to provide two types for an expression: \nthe type of values it returns, and the type of messages it accepts. Typing judgments now have the form \nF;X; C\\ E:U receives R, where R is the type of messages received by the expression. Similarly, function \ntypes should be written (U) % V, where R is the type of messages received by the function body. In addition, \nwe need to provide a new primitive data type, of the form pid( V) which is the type of a process that \naccepts messages of type U. We can then support type checking of message sending with a primitive send \n: (pid( U), V)+ O when VQ u and process spawning with a primitive spawn :((~) % V, ~) + pid(R) This \nextension is a special case of effect type systems [TJ94]. It would allow the construction of polymorphic \nserver applications, but it doesn t support checking of pro\u00adtocols or detection of possible deadlocks. \nPractical Experience The original goal of designing a type system for Erlang was for the resulting system \nto be usable in a production envir\u00adonment by Erlang programmers. We have so far constructed a proof-of-concept \nprototype implementation in Haskell. While lacking in performance in certain areas, the prototype has \nprovided valuable insight into how our type system will co-exist with the Erlang envir\u00adonment and what \nchanges are required to typecheck existing Erlang code. The prototype supports the following features: \n. Type inference for the whole Erlang 4.4 language. . Type simplification for derived types. . Type \nsignature checking. . Type abbreviations for use in type signatures (for ex\u00adample, see the tree datatype \nin Figure 1). . Separate compilation through the use of interface files which record the types of exported \nfunctions in a mod\u00adule. . Type abstraction. By default, type abbreviations are exported abstractly, \nso the definition of a type is hid\u00adden from external modules. The programmer may op\u00adtionally request \nthat certain type definitions be ex\u00adported in full. The type checker detects abstraction violations and \nreports these to the programmer. . Partial type checking. On a function-by-function baais, the-programmer-may \nprovide types that the type system will assume without type checking the function definition. This is \nimplemented with an unchecked directive in the code.  This prototype has been used to typecheck a large \npor\u00adtion of the Erlang standard library, and we are currently us\u00ading it to construct a production version \nof the type checker in Erlang. The production version consists of 3500 lines of typed Erlang. 9.1 Performance \nWe have found performance of the type inference engine to be adequate in most cases, although due to \nthe quadratic complexity of constraint reduction it can blow up on large constraint sets. Programs that \ncause most problems are those involving large groups of mutually recursive functions, which must be typechecked \ntogether. It is not unusual to find types with upwards of ten thousand constraints. Performance of the \ntype simplification process is poor for large examples. This is due to two factors: simplific\u00adation usually \nhas to be performed several times before a fixed-point is reached, and our prototype implementation uses \nalgorithms with worse complexity than is achievable for some of the simplification transformations. We \nexpect performance of the simplifier to improve with the production version of the type checker. There \nis a tradeoff involving type simplification and type checking: if the user supplies a type signature, \nshould the inferred type be simplified before checking against the signa\u00adture, or should the original \ninferred type be used? If the type is simplified, type checking should be faster, but we would pay for \nsimplification time instead. By experimentation we have found that type checking is a relatively cheap \noperation compared to simplification, so we opt not to simplify types if the user has supplied a signature. \nIn practice, we have found it convenient to use type sig\u00adnatures almost everywhere, for two reasons: \n. supplying a type signature avoids the poor perform\u00adance of the type simplifier, and . type signatures \nmay use abbreviations making them more readable than inferred types. To provide some concrete numbers, \nhere are some of the timings for typechecking some modules from the production version of the type checker: \nModule Lines Time(s) tc.types. terl 526 2.7 tc.typeut ils. terl 274 5.1 tc_reduce. terl 288 101.2 tc_syn. \nterl 250 60.0 These times were produced by the prototype type checker (written in Haskell) on a 200Mhz \nPentium Pro. The mod\u00adule t c-types. terl contains a large number of small unre\u00adlated functions and type \ndefinitions, whereas the module tc-reduce. terl contains a small number of complicated mutually recursive \nfunctions, hence the large typechecking time. 9.2 Diagnostics The usability of a type system is directly \naffected by the quality of error messages generated for untypable expres\u00adsions. It is possible to generate \ntype errors which include function and line number information in our type system us\u00ading the following \ntechnique: instead of generating the whole constrained type for a function before reducing it, we can \nre\u00adduce constraints as they are generated and maintain a fully reduced constraint set. Using this method \nit is possible to identify the program construct that generated the constraint that led to an incon\u00adsistent \ntyping. This technique is not perfect: for example, it is not possible to identify whether a type error \nis caused by an error in a function definition or in an application of that function. In our system the \nerror is always reported at the application site. Errors in type signatures are another matter: when \na signature is found not to be an instance of the inferred type, we simply report the inferred type and \nthe constraint that failed during the entailment algorithm. In most cases, this information is insufficient \nto identify the cause of the error, and matters are worse when the inferred type is large and complicated. \nWe intend to explore this problem as future work. 9.3 Pattern Matching In order to typecheck the full \nErlang language, we must compile the pattern matching into simple case expressions. Standard algorithms \nexist to perform this transformation [Aug85, Wad87]. Inmost cases, theuseof pattern matching compilation \nin our type checker is transparent to the pro\u00adgrammer, but there are cases where unexpected types are \nderived. For example, one possible waytowrite the boolean and function is as follows: and(true, true) \n-> true; snd(f alse, X) -> false; and(X, false) -> false. Given the type declaration boolo = true I false, \nwe would expect tobe able to assign the type -type and(boolo, boolo) -> boolo. as an instance of the \ninferred type. However, in our system this is not the case. Pattern matching compilation trans\u00adforms \nthe function as follows: snd(X, Y) -> let Z = (case Y of false -> false end) in case X of true -> case \nY of true -> true; X->z end; false -> false; X->z end. which yields the type (1, false) -> false I true. \nThe second argument is restricted to being false, due to the first case expression on Y in the transformed \ncode. The type is unexpected, since it does not have the type (boolo, boolo) -> boolo as an instance. \nThis example displays a difference between our system and Hindley-Milner, since in that system the declaration \nof boolo would enable thetype system toderive theexpected type. Our system does not require a type declaration \nand assumes the worst, namely that in order to ensure that the function can never fail it isnecessary \nto restrict the second argument to being false only. A generalisation of our type system, such as con\u00additional \ntypes [AWL94], would be necessary to de\u00adrive a more accurate type which would have the type (boolo, boolo) \n-> booloasaninstance. However, such an extension would also increase the complexity of type checking, \nand decrease the readability of types. 9.4 Changes to existing code We were pleasantly surprised that \nvery little existing code needed to be changed to get through the typechecker. The changes we have had \nto make fall into the following categor\u00adies: . Actual programming errors, or (more commonly) cases where \nthe original programmer had deliberately left out a failure case. Our type system guarantees that typechecked \ncode will never fail except where the pro\u00adgrammer has used an explicit exit call. This means that all \nfailure csses must beexplicitly checked for in typed code. s Clashes between tagged tuples and anonymous \ntupks. In our type system, it is not the case that (for instance) {a, 1} z= {1, 1}, although some Erlang \ncode assumes this. . Pattern matching oddities, as described in Section 9.3).  10 Conclusion While \nmuch has been achieved in our Typed Erlang project, several areas remain to be explored. Our principle \nachieve\u00adments to date are the type system itself, several heuristics for simplifying inferred types, \nthe entailment algorithm for determining type instance, and our experience with a pro\u00adtotype implementation \nwhich supports many of the features one would expect from a typed programming language. Several gaps \nremain in the theory; most notably is a proof of completeness for our entailment algorithm (without function \ntypes). Once this proof is complete we intend to use the entailment algorithm to prove the correctness \nof our type simplifications. The production version of our type checker is currently under construction, \nand will be distributed along with a future version of the Erlang system. We expect the fial version \nto improve on the prototype in areas of performance, robustness and the quality of diagnostics. References \n[Aug85] L. Augustsson. Compiling pattern matching. In Functional Programming Languages and Computer Architecture, \nnumber 201 in Lecture Notes in Com\u00adputing Science, pages 368 381, Nancy, September 1985. Springer-Verlag. \n[AVW93] J. Armstrong, R. Virding, and M. Williams. Con\u00adcurrent Programming with Erlang. Prentice Hall, \n1993. [AW93] A. Aiken and E. L. Wimmers. Type inclusion con\u00adstraints and type inference. In Functional \nProgram\u00adming Languages and Computer Architecture, pages 31-41, 1993. [AWL94] A. Aiken, E.L. Wimmers, \nand T.K. Lakshman, Soft typing with conditional types. In Symposium on Principles of Programming Languages, \npages 163-173, 1994. [CF91] R. Cartwright and M. Fagan. Soft typing. In ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 278-292, June 1991. [DM82] L. Damas and R. Nfilner. Principal \ntype schemes for functional programs. In Symposium on Principles of Programming Languages, 1982. [FA96] \nM. Fahndrich and A. Aiken. Making set-constraint\u00adbased program analyses scale. Technical Report CSD-96-917, \nUC Berkeley, 1996. Also Workshop on Set Constmints, Cambridge, MA, August 1996. [FF96] C. Flanagan and \nM. Felleisen. Modular and poly\u00admorphic set-based analysis: Theory and practice. Technical Report TR96-266, \nRice University, 1996. [FM88] Y.-C. Fuh and P. Mishra. Type inference with sub\u00adtypes. In European Symposium \non Programming, 1988. [Hin79] R. Hindley. The principal type scheme of am object in combinatory logic. \n11-ansactions of the American Mathematics Society, 146:26-60, 1979. [Mi178] R. Milner. A theory of type \npolymorphism in pro\u00adgramming. Journal of Computer and System Sci\u00adences, 17(3):348 375, December 1978. \n[Mit91] J. C. Mitchell. Type inference with simple sub\u00adtypes. Journal of Functional Programming, 1:245\u00ad285, \n1991. [MPS86] D. B. MacQueen, G. Plotkin, and R. Sethi. An ideal model for recursive polymorphic types. \nIn Zn\u00adjor-mation and Control, volume 71, pages 95-130, 1986. [MR85] P. Mishra and U. Reddy. Declaration-free \ntype checking. In Symposium on Principles of Progmm\u00adming Languages, pages 7 21, 1985. [Pey87] S. L. Peyton \nJones. The Implementation of Func\u00adtional Programming Languages. Prentice Hall, 1987. [Rey85] J. C. Reynolds. \nThree approaches to type struc\u00adture. In Proc. TAPSOFT Advanced Seminar on the Role of Semantics in Software \nDevelopment, Lec\u00adture Notes in Computing Science. Springer-Verlag, 1985. [TJ94] Jean-Pierre Talpin and \nPierre Jouvelot. The type and effect discipline. Information and Computation, 111(2):245-296, 1994. [TS96) \nV. Trifonov and S. Smith. Subtyping constrained types. In Third International Static Analysis Sym\u00adposium, \nSeptember 1996. To Appear. [Wad87] P. Wadler. Efficient compilation of pattern\u00admatching. In [Pey87], \n1987. [Wan87] M. Wand. Complete type inference for simple ob\u00adjects. In Proc. 2nd IEEE Symposium on Logic \nin Computer Science, pagea 37-44, 1987. [WC94] A. K. Wright and R. Cartwright. A practical soft type \nsystem for scheme. In ACM Symposium on Lisp and Functional Programming, 1994. \n\t\t\t", "proc_id": "258948", "abstract": "We present a type system for the programming language Erlang. The type system supports subtyping and declaration-free recursive types, using subtyping constraints. Our system is similar to one explored by Aiken and Wimmers, though it sacrifices expressive power in favour of simplicity. We cover our techniques for type inference, type simplification, and checking when an inferred type conforms to a user-supplied type signature, and report on early experience with our prototype.", "authors": [{"name": "Simon Marlow", "author_profile_id": "81100515135", "affiliation": "University of Glasgow", "person_id": "P265492", "email_address": "", "orcid_id": ""}, {"name": "Philip Wadler", "author_profile_id": "81100173596", "affiliation": "Bell Labs, Lucent Technologies", "person_id": "PP39030941", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258948.258962", "year": "1997", "article_id": "258962", "conference": "ICFP", "title": "A practical subtyping system for Erlang", "url": "http://dl.acm.org/citation.cfm?id=258962"}