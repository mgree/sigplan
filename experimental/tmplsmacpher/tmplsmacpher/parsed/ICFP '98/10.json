{"article_publication_date": "09-29-1998", "fulltext": "\n YALE: Yet Another Lambda Evaluator Based on Interaction Nets Ian Mackie CNRS (UMR 7650) and ficole \nPolytechnique Laboratoire d Informatique (LIX) 91128 Palaiseau Cedex, France mackie@lix.polytechnique.fr \nAbstract Interaction nets provide a graphical paradigm of computa- tion based on net rewriting. They \nhave proved most suc-cessful in understanding the dynamics of reduction in the X- calculus, where the \nprime example is the implementation of optimal reduction for the X-calculus (Lamping s algorithm), given \nby Gonthier, Abadi and Levy. However, efficient im-plementations of optimal reduction have had to break \naway from the interaction net paradigm. In this paper we give a new eficient interaction net encoding \nof the X-calculus which is not optimal, but overcomes the inefficiencies caused by the bookkeeping operations \nin the implementations of op- timal reduction. We believe that this implementation of the X-calculus \ncould provide the basis for highly efficient imple-mentations of functional languages. 1 Introduction \nIt is well-known that the X-calculus can be seen as a proto- typical functional programming language, \nand moreover as the foundation for an implementation. However, from the point of view of a compiler writer, \nthe theory falls a long way short of this ideal, because of two defects : 1. The reduction steps are \ntoo big in that P-reduction (Xz.t)u + t[u/z] already takes us out of the realms of the pure theory since \nsubstitutions, which are the hard part to implement, are not captured by the basic theory. Several possible \nsolutions to the problem that have been put forward include: l Combinators (S, K) eliminate the problem \nof variables and substitutions, but the steps are still far from being atomic: SPQR + PR(QR), KPQ + P. \nIn the first we have to duplicate R and in the second we have to erase Q. Both of these operations cannot \nbe seen as atomic com-putation steps. l Explicit substitution calculi (for instance the Aa- calculus \n[l]) are another approach, but they seem to be too tied up with syntactical problems (which 0 1998 ACM \n1.58113.024.4/99/0009...$5.00 have nothing to do with the actual computation) to be of practical use. \nl A third solution is graph reduction, specifically Lamping s algorithm for optimal reduction 1161, and \nthe reformulation of the algorithm as an in-teraction net, as developed by Gonthier, Abadi and Levy [ll]. \nHowever, the total cost of reduc- tion includes expensive bookkeeping operations which makes the algorithm \nimpractical in general. 2. There is no implicit or explicit notion of a strategy. This is of course a \nstrength and a weakness. A strength because we have the flexibility to do reductions how we please, but \na weakness in that there is no built in notion of sharing, which is essential for any efficient implementation. \nIt is also well known that neither call-by-value nor call-by-name is the best strategy to use, simply \nbecause there is always the risk that we either duplicate work, or do work that will be erased later. \nCall-by-need (24, Chapter 41 is one solution to this problem. However, there is an unfortunate problem \nin that the reduction is usually to weak head normal form and thus any re-ductions inside the X-abstraction \nwill often be dupli-cated. Again, Lamping s algorithm can be seen as a solution to this problem, since \nit overcomes the prob-lem of which is the best strategy to take, but introduces a huge overhead to ensure \nthat the minimum number of /?-reductions are done. Summarizing these points, we claim that a coding of \nthe X-calculus requires that we impose a strategy which captures a natural notion of sharing, and moreover \nwe should give a set of atomic computation steps for reduction. Linear logic [9] offers a new and exciting \nperspective on these issues, since it offers new insights into sharing com-putations and evaluation strategies. \nIn particular, the cut-elimination process in linear logic makes explicit the dupli-cation and erasing \nof terms which gives a handle on sharing and garbage collection. For functional languages there are basically \ntwo approaches to using linear logic, which we clas- sify as follows: Intuitionistic Linear Logic. The \ntyped X-calculus re-lates to intuitionistic logic by the Curry-Howard ISO-morphism. If we shift to intuitionistic \nlinear logic, then we can construct various linear A-calculi which correspond to linear logic proofs. \nSeveral languages have been proposed based in these ideas, amongst oth-ers: Holmstrijm [12], Lafont [13], \nAbramsky (31, Wake- ling [25], and the language Lilac [18] of the present au-thor. More recently, abstract \nmachines based on linear explicit substitution calculi have been developed (41. Classical Linear Logic. \nA second approach is classical linear logic, which offers tools such as proof nets [9] and the geometry \nof interaction [lo]. Using translations of the X-calculus into prook of classical linear logic, we can \nreason about P-reduction in a completely different way. Proof nets also gave birth to interaction nets \n[14], which have proved most successful for the implementation of optimal reduction in the X-calculus, \nas given by Gonthier, Abadi, Levy [ll]. Implementations of the X-calculus via the geometry of interaction \nhave also been proposed: local and asyn-chronous P-reduction [7], and the geometry of interac- tion machine \n[19]. It seems that to date the approach based on classical linear logic has been more fruitful. Whether \nthis is just a consequence of the fact that real implementations have not been developed to take advantage \nof the theory, or whether there are inherent limitations to the first approach remains an open question. \nBut many of the original claims and hopes of these ideas do not seem to have materialized. With classi-cal \nlinear logic there is now a clear understanding of optimal reduction, new evaluation strategies, and \nnew ways of im- plementing. In this paper we add another way of implementing the X-calculus using ideas \nbased on classical linear logic. Specif-ically, an analysis of the cut-elimination process for linear \nlogic [20] suggests an obvious strategy for the X-calculus. Roughly, the strategy that we introduce never \ncopies terms with free variables, or containing redexes. This gives a new strategy for reduction in the \nX-calculus which captures a great deal of sharing (but not optimal) and overcomes many of the inefficiencies \nmentioned above. Specifically, we give yet another X-evaluator (YALE) based on interaction nets. There \nare already several sys-tems of interaction nets for the X-calculus: l Gonthier, Abadi and Levy [II] \ngave an optimal one, using an infinite set of (indexed) agents. However, this system turns out to be \nvery expensive in practice. l In [17] an interaction system is given which uses a finite number of agents, \nbut it does not implement substitu-tion through X-abstractions, which is essential to ob-tain sharing. \nAlthough very little sharing is captured by this system it does better than call-by-need. l In [21] another \napproach is developed based on the in- teraction combinators of Lafont [15]. Although the sys- tem of \nrewriting is perhaps the simplest one, the atom- icity of the system leads to a great deal of work. \nThe system of interaction nets that we present in this paper is an attempt to improve on all of these \nsystems. The key ingredients of this work are: l We introduce a new calculus of explicit substitutions \nbased on linear logic, which appears to overcome many of the syntactical problems usually associated \nwith such calculi. l We give a new encoding of the X-calculus in interaction nets, which is derived directly \nfrom the calculus of ex- plicit substitutions. Moreover, it has a solid foundation from cut-elimination \nin linear logic (we refer the reader to [20]). l We extend the theory to cover a simple programming language \nwith conditional and recursion (PCF). Related Work. This work can be seen as an alternative thread of \nresearch to that of the successful implementation of optimal reduction given in [5]. Our work relates \nto this in that we start with a system of interaction nets for linear logic, and implement the X-calculus. \nThe key difference is that we stick with interaction nets throughout. Moreover, this work is not based \naround optimal reduction, but on a natural encoding of linear logic into interaction nets. Remark. No \nknowledge of linear logic is required to un-derstand this paper since it can be understood directly as \na simple graph reduction mechanism. However, it is fruit- ful to know that there is a solid logical background \nto this implementation. Overview. The rest of this paper is structured as follows. In the next section \nwe recall the basic notions of interactions nets. In Section 3 we introduce a calculus of explicit sub-stitutions \nfor the X-calculus. In Section 4 we introduce our interaction system for the X-calculus. Section 5 in \nconcerned with the dynamics of the system. Sections 6 gives some ex- tensions to the language PCF. In \nSection 7 we give some benchmark results, comparing our interaction net evaluator with optimal reducers \nbased on the same technology. We conclude the paper in Section 8. 2 Background We assume that the reader \nis familiar with both interaction nets [14, 151 and X-calculus [6]. Here we set up the notation and conventions \nfor interaction nets. Interaction Nets. An interaction net system is specified by giving a set C of symbols, \nand a set R of interaction rules. Each symbol Q E C has an associated (fixed) arity. An occurrence of \na symbol CY E C is called an agent. If the arity of cy is n,, then the agent has n+ 1 ports: a distinguished \none called the principal port depicted by an arrow, and n auxiliary ports labeled x1, . . , xn corresponding \nto the arity of the symbol. We will say that the agent has n + 1 free ports. We index ports clockwise \nfrom the principal port, hence the orientation of an agent is not important. A net N built on C is a \ngraph (not necessarily connected) with agents at the vertices. The edges of the graph connect agents \ntogether at the ports such that there is only one edge at every port (edges may connect two ports of \nthe same agent). The ports of an agent that are not connected to another agent are called the free ports \nof the net. There are two special instances of a net: a wiring (no agents), and the empty net. A pair \nof agents (CCC,,@E C x C connected together on their principal ports is called an active pair; the interaction \nnet analog of a. redex. An interaction rule ((cK,~) * N) E 77, replaces an occurrence of the active pair \n(cr,/3) by a net N. The rule has to satisfy a very strong condition: all the 118 free ports are preserved \nduring reduction, and there is at most one rule for each pair of agents. The following diagram illustrates \nthe idea, where N is any net built from C. )xJ++f; *y-T--~~~ We do not require that there is a rule \nfor each pair of agents, but if we create a net with an active pair for which there is no rewrite rule, \nthen we have a deadlock. The interaction net system that we present in this paper will be deadlock- free \nin this sense. An interaction net is in normal form when there are no active pairs. 3 Explicit Substitutions \nfor the Simply Typed X-calculus It will be convenient, so that we can express certain strate-gies in \nthe typed X-calculus, to use a calculus of explicit substitutions. Moreover, since we are interested \nin control- ling duplication and erasing of terms explicitly during re-duction, we use a notation inspired \nby various calculi for linear logic, and include explicit syntactical operations for duplication and \nerasing. Hence, we have a calculus where we can monitor precisely the propagation of a substitution. \nWe will be concerned with weak reduction in the first in-stance, then mention extensions of the results \nto strong re-duction later. In the &#38;calculus, weak reduction (also known as lazy reduction [2]) imposes \nthat we do not reduce under a X-abstraction (where A is seen as a constructor), whereas in the calculus \nof explicit substitutions this is often interpreted as not pushing substitutions through a X-abstraction. \nThere are various motivations for weak reduction: one is that we can distinguish between Xx.R and R, \nwhere R is a non-terminating term. A second is that the process of pushing a substitution through a X-abstraction \nis a delicate operation since free variables may become bound, thus re-naming may be necessary (or shifting \noperations in the XPcalculus) which can be regarded as an expensive syntac-tical overhead on the calculus. \nWe have two objections to these restrictions for our work, which are motivated purely from an efficiency \npoint of view: 1. Avoiding reduction under a X-abstraction may cause duplication of work later. A typical \nexample of this situation is the term: where I = Xx.x. The underlined redex Iz will be con- tracted twice, \nwhereas allowing reduction under a X-abstraction only requires one contraction of this redex. Of course, \nreducing under a A introduces a weakness into the system since internal reductions may not ter-minate. \nHowever, for the first part of our work we will only consider the simply typed X-calculus where all reduction \nsequences terminate. Later we will in-troduce recursion, and come back to the issue of non-termination. \n2. The restriction of not pushing substitutions through a X-abstraction seems too strong, since the only \ntime we need to worry about variable capture problems is when there are free variables in the term being \nsub-stituted. There seems to be no fundamental reason to block substitutions which do not contain free \nvariables (i.e., closed terms). Avoiding substitution through a X-abstraction may also cause duplication \nof work later. A simple instance of this is the following term: oz. VW-M)) (ZI)) P/xl The underlined \nterm x1 will become a redex after sub-stitution, and can thus be contracted before duplica-tion. If we \npostpone the substitution then two sub-stitutions will need to be made, thus duplicating the redex. \nIn addition, copying terms with free variables introduces a weakness in the strategy in that redexes \nthat might be created later during reduction will also be duplicated. An obvious solution to this would \nsimply be to only copy terms that have no free variables, and moreover, when they are in normal form. \nPutting all of these ideas together suggests a strategy for implementing the simply typed X-calculus. \nThe strategy is clearly a weak one since it will not always be the case that substitutions wiil be closed \nterms, but we shall show that it is adequate for the evaluation of programs (i.e., terms of ground base \ntype). We will also suggest ways of extending this strategy to cope with strong reduction. This strategy \nin fact comes directly from general obser- vations about efficient strategies for cut-elimination in \nlinear logic, for which we refer the reader to [20]. We now give the calculus of explicit substitutions \nthat we will use, and give the corresponding reduction rules. This provides the basis for an implementation \nin terms of inter- action nets which is well suited to capture this strategy. Definition 3.1 (Types) \nTypes are builtfrom the follovling grammar, where u,r are used to range over type metavari- ables. u \n::= int 1 boo1 1 u + T where int is the type of integers, boo1 for booleans, and + is the (right associative) \nfunction type constructor. Definition 3.2 (Typed Terms) We write t : u for a typed term t as usual. The \nsyntax of our calculus is shown in Figure 1, where we define in parallel the term construction, type \nconstraint, va,riable constral;nt, and free variables of a term. Convention 3.3 (Linearity) We adopt \na strong version of the usual variable convention [6] in that all variables (free and bound) are chosen \nto be different. Thus in a term t all the variables occur exactly once. A few remarks on the notation \nare in order. Abstraction Xx.t enforces that the variable actually does occur at least once free in the \nterm t. The construct [x = -]t is a term t where we make the variable x occur free explicitly. Appli-cation \ntrr enforces that the free variables in t and u are dis-joint, thus do not occur more than once. The \nconstruction [x = y, z]t ensures that all variables have a unique name: If t has two occurrences of the \nvariable x, then we rename one to y, the other to t and then use the construct. If x occurs more than \ntwice, then we can use this construct repeatedly. The notation t[u/x] is our notation for substitution1 \nThere are obvious translations of the usual X-calculus into this notation which we will not elaborate. \nOne of the key advantages of this notation is that the variable counts have already been done, which \nwill be of significant use when we give the translation into interaction nets. Hence from one perspective \nthis is nothing more than a convenient notation that serves as an intermediate language for our translations, \nwhere the main bureaucratic issue of counting occurrences of variables in a term has already been taken \ninto account. We give some examples of terms in this calculus. s = Ax.Xy.Az.[z = 21,.22](xz1)(yz2) 2 \n= Xf.Xx.[f = fl,fi](fl(fiX)) Definition 3.4 (Equivalences) We write t x u if term t and u are related \nby the following structural equivalence. We write X for an explicit operation [x = -1, [x = y, z], and \nS for a substitution [v/x]. In the following, the obvious vari-able constraints are implied: i.e., no \nvariable capture occurs. (tsl )S2 25 (ts2)sl (1) Xl (x2t) = Xz(Xlt) (2) (xt)u x X(tu) (3) Wu) M X(tu) \n(4) (Xt)S z x(ts) (5) In addition, if t and u are related by the obvious notion of a-equivalence (renaming), \nthen t M u. These equivalences apply in any context. We give several examples to illustrate the idea: \nIx = -MY = -It) zz [y = -]([x = -It) w4)[~lYl = @I~lYl)bl4 (Ix = -1UY = Yl,Y$))bl4 = ([Y = Yl,YZl([X \n= -1eJl4))) Definition 3.5 (Values) A closed term t is a value (value(t)) if it is a weak head normal \nform: Xx3 ii tt ff where t is any term such that fv(t ) = {x}. Definition 3.6 (Weak reduction) We define \na weak no- tion of reduction Mu, as shown in Figure .2. We write w-nf(t) if no reduction rule can be \napplied to t, i.e., t fiy. These reductions are applied modulo the structural con-gruence: t M t t -+y \nu u z 11 t-+u and moreover, can be applied in any context C[.], including within substitutions and under \nX. t--+wu C[t] -+w C[u] Remark 3.7 There are many conditions on the reduction relation +-+lu,here we \ntry to informally motivate them. The application (Ax.t)u is restricted to the case when the only free \nvariable occurring in t id x. Thus before appli-cation can take place we must perform all the substitutions \nfor the other free variables for t. This forces substitutions to take place before P-reduction. Only \nvalues can be substi- tuted through a X which avoids all problems due to variable capture, and requires \nthat we have at least reduced the substi- tution to weak head normal form. Terms can only be copied when \nthere are no free variables, and moreover when the term is in weak normal form. This condition avoids \ndupli-cation of reduction, and moreover avoids the duplication of potential redeaes. The final rude allows \nsubstitutions to be moved inside other substitutions, which is essential for the previous rules explained \nabove. Definition 3.8 (Programs) A program is a closed term of ground type fint or bool). Theorem 3.9 \n(Adequacy) If t is a program, then exactly one of the following holds: 0 t -f E. for some unique A, if \nt : int. l t-;:tt, 2, t:bool. l t -,: ff, if t : bool. Proof: This can be proved by first showing that \nthe cal-culus preserves types during reduction (Subject Reduction), and then showing for a closed term \nof ground type all substi- tutions will eventually complete, i.e., that there are enough closed substitutions. \ncl 4 Nets for X-calculus We now show how we can implement our X-calculus, by giv- ing an encoding as \nan interaction net. We give the transla- tion 7(.) of the typed X-calculus into interaction nets. The \nagents required for the translation will be introduced on de- mand: in Section 5 we give the interaction \nrules. A term t in the X:calculus, with fvyt) = {xl,. . . , xn}, will be translated as a net T(t) = N \nwith the root edge at the top, and n free edges corresponding to the free variables, which we draw as \neither I N or just N I I I k .x1 Xfl fv;t ) We will drop t!le labeling on the edges since they aTe derived \ndirectly from the term, and the order is preserved. Constants at Base Type. Natural numbers and Boolean \nconstants k E {n, tt, ff} are all coded by introducing a new unary agent for each constant. The only \nport is the principal port, and we slightly abuse notation and overload the agents which will simplify \nour presentation. These constants are drawn as follows: Term 1 Type Constraint 1 Variable Constraint \n1 Free Variables ?i : int tt,ff : boo1 -:U 62 ~GX%U-+T t:r x E fqt) fv(t) -(x} (tu) : r t:u+r,u:u fv(t) \nf-l fv(u) = 0 fv(t) + fv(u) ([x0 = -It) : r t:r x e WI w + ($1 y7.y: m : 7- t:r,y:u,z:u E g ;e~, Y # \nz, {Y, z> c w fv(t) -{YT zl + ix)t:r.x:(T.u:u fv(tl -lzF + fvlul Figure 1: Syntax: Typed X-calculus Reduction \nCondition (Xxd)u +w t[u/x] if fv t = x 4v/4 WUJ ;It[v/x])u if x E fv(t) [: H j ] +w u vx -+w mJl4) if \nz E fv(u) @y*t) b/xl XY.tlvlxl if value(v) ([x = y, z]t)[v/x] 2 t[v/y][v/z] if fv(v) = 0 and w-nf(v) \n~~w=,-i / l ---+uJ t if fv(v) = 0 and w-nf(v) vx ---+w t[w[v/x]/y] if x E fv(w) Figure 2: Weak Reductions \nk 6  Hence we have introduced an agent for ti, an agent for ff and an infinite set of agents corresponding \nto the natural numbers n. Variable. If t then T(t) simply is a variable, is translated into an edge. \nX Abstraction. Let T(t) = N, then T(Xx.t) is given by the following net, where we have introduced three \ndifferent kinds of agent. First, an agent X of arity 3, which corresponds to abstraction. The remaining \ntwo kinds of agents represent a list of the free variables of the term. We use the agent b, one for each \nfree variable, and an agent v which represents the end of this list. 4 4 The key idea is that the coding \ncontains a pointer to all the free variables of the abstraction; the body of the abstraction is encapsulated \nin a box structure. We have assumed, without loss of generality, that the uni ue occurrence of the variable \nx is in the left-most po-Aitioz 0: N. Application. Let T(t) = 44, and 7(u) = N, then T(h) is given by \nthe following net, where we have introduced an agent @I of arity 2 which corresponds to an application \nagent in the usual graph representations of the A-calculus. 0 A4 N ;jt Erasing. Let T(t) = N, then 7([x \n= -It) is given by the following net using a new agent e, of arity 0. N E Q c Duplication. Let T(t) \n= N, then 7([x = y, z]t) is given by the following net using a new agent c, of arity 2. N C @ We have \nassumed, without loss of generality, that the (unique) occurrences of the variables y,z are in the right-most \npositions of N. Substitution. Let 7(t) = M, and 7(u) = N, then T(t[u/x]) is given by the following net, \nwhere we simply connect the free edge x from the net M to the net N. M 2 N Ef 1 The following result \nshows that the structural equiva-lence introduced on terms becomes an equivalence in nets, which can \nbe proved by a straightforward case analysis on the definition oft M u. Proposition 4.1 If t M u then \n7(t) = 7(u). We thus see an advantage of using nets rather than X-terms. Remark 4.2 For readers familiar \nwith the translations of X-calculus into linear logic, we remark that we are using the D =!(D -o D) \ntranslation, but we have hidden (as much as possible) the linear logic decomposation by using hybrid \nagents wherever we could (the agent X corresponds to I) and promotion, and 0 corresponds to @ and dereliction). \nWe feel that this approach leads to a representation that is much closer to standard graph representations \nof the X-calculus, but we can still gain from the linear logic foundation for the dynamics of the system. \nThe reader is referred to I.201 for the corresponding system of interaction for linear logic proofs. \nWe end this section with several examples of the trans-lation. In Figure 3 we show the nets corresponding \nto I = Xx.x, K = Xx.Xy.x and the function twice 2 = xf.xz.f(fx). Dynamics In this section we give the \ninteraction rules for our X-evaluator. We begin by giving the weak system, then go on to show how we \ncan improve to rewriting process by giv- ing the encoding of strong reduction. We show how each rewrite \nrule dw in the calculus is implemented in the inter- action system, which is sufficient to show that \nthe encoding is correct. First, we note that 4 of the reduction rules are implicit. The translation of \nthe rule x[v/x] hw v is implicit in this system of interaction, since 7(+/x]) = 7(v), thus no in- teraction \nrules are required. The rules for pushing a sub- stitution through an application: (tu)[v/z] -w (t[v/x])u \nand (tu)[u/x] +, t(u[v/z]) are also implicit. The last rule (+JlYl)[vl~l +-+?at[w[v/x]/y] is equally \nimplicit. We leave the reader to check that the translation of both sides of the rules yield the same \ninteraction net. We therefore only need to encode the remaining 4 rewrite rules. The first interaction \nrule is the linear part of P-reduction. This single rule captures the notion of connecting the body of \nthe abstraction to the root, and the argument to the vari- able occurrences. A new agent d is introduced \nwhich serves to erase the box structure used in the translation, which will be explained in the following. \n ,B-(;k The second rule shows that if the term t was a closed X- term in the above P-reduction, then \nthe d agent introduced simply erases the v agent which marks the empty list. Thus if fv(t) = {x}, then \nclearly we have T((Xx.t)u) ** T(t[u/.x]), thus correctly implementing the first rule for -+,,. The next \nthree rules are for the substitution of a value v through an abstraction: (Xy.t)[v/x] ww Xy.t[v/x]. The \nfirst allows a base value (k E {n, tt, ff}) to be moved inside an abstraction, corresponding to (Xy.t)[k/x] \n-+w Xy.t[k/x], in a single interaction: k 0 For abstraction values, we require two interactions to complete \nthe substitution. The first interaction rule almost performs the substitution (Ax.t)[(Xy.u)/z] --+w Xx.t[(Xy.u)/z]. \nb x ===t-b x 6 + :; Since the abstraction (Xy.u) has no free variables, then the reduction successfully \ncompletes with the following in-teraction which erases the b agent corresponding to the free variable \nz. U V V x 73 (a) 7-w (b) VK) Cc) VI Figure 3: Example nets Thus substitution of an abstraction value \nis translated into Duplication. We next give the dynamics of the rules for two interactions. 6 which \ncomplete the duplication of a term. There are three Thus far we have only been concerned with linear \nre-rules, and one rule schema which captures all the other cases. ductions (without copying or erasing). \nThe following in-The first shows the special case when two ~5 agents meet teraction rules shows how a \nw-nf with no free variables and simply cancel each other out. This indicates that the can be duplicated, \ncorresponding to the term reduction duplication process is complete. (Ix = Y7 MJl4 t[v/y][v/z]. The first \nrule shows that +--+w the copying agent can duplicate base values k: 6 k -0 6 C k - D--o k -0 i -1 \nThe next rule is when a copying agent meets an abstrac- tion. We copy the X, and propagate S agents \ninside the body The second rule performs a blocking of the duplication of the abstraction for which we \nshow the dynamics later. We process. The correctness of this system of interaction relies also propagate \nthe c agent along the list of free variables. heavily on the principle that all 6 agents are well-balanced \ninside the body of an abstraction during the duplication process, thus we should not allow 6 agents to \nenter the body C x x in this way. The blocking is achieved by introducing a new agent h which will allow \nother interactions to complete, as we shall see below. x C 6 6 rx*m If the term is closed, then the following \nreduction dupli-cates the end of list agent. V -0 hc third rule allows the list of free variable agents \nto V be duplicated by 6 agents. A 6 agent is propagated along -0 the list of free variables, inside the \nbody of the abstraction, and also along the free variable edge. In the process of Remark that a 6 agent \nis introduced to duplicate the body duplication we also convert the 6 agent back to a b agent, of the \nabstraction, in the same way as we copied the ab- which will allow for further substitutions to be made. \nstraction agent. The final rule allows the b agents to be erased by the d agent which opens the box of \nthe abstraction. The final rule, or rather rule scheme, shows that all the remaining interactions with \n6 simply duplicate the agent and propagate along all the auxiliary ports. 6 cy . . 1 Next we show the \nremaining rules for interaction with the agent b which basically allow many of the blocked re-ductions \nto complete. The following rule allows some sub-stitutions to complete. Specifically, an abstraction \nwhich has free variables marked with b can be pushed through another abstraction. We introduce another \n6 agent which corresponds to lifting (or shifting) in the terminology of explicit substitutions. The \nnext rule allows abstractions with free variables marked with b to be copied: The following result states \nthat we can duplicate values correctly. Proposition 5.1 If N is a net in normal form, then there is a \nsequence of interactions that duplicates the net using S agents connected to every free edge of the net \nN. Garbage collection. The final set of rules for the sys-tem concerns the process of erasing. We give \na single rule scheme, which simply indicates that E interacting with any-thing simply erases the agent, \nand then erases all the net connected to the auxiliary ports. Remark that if the arity of Q is 0, then \nthe right-hand side of the rule is the empty net. One particular case of this is when (Y is an e agent \nitself; in these cases the interaction marks the end of the erasing process. These rules provide the \ngarbage collection mechanism for interaction nets. Proposition 5.2 If N is a net in normal form, then \nthere is a sequence of interactions that erases the net N completely using e agents connected to every \nfree edge of the net N. This completes the dynamics of the system of interaction, and as we have illustrated, \ncorrectly implements the term reduction wU,. Proposition 5.3 Let t be a program. If t -L u, for some \nnormal form u, then there is a finite sequenceof interactions such that T(t) ==+* 7(u). 5.1 Strong Reduction \nOur evaluator of course does something on any term, not only on closed terms of ground type. However, \nthe net will usually be in a form that makes is quite difficult to extract the corresponding term: for \ninstance a net may be partially duplicated, then blocked waiting for a free variable to be bound. Here \nwe will show a way of extending our weak reduction mechanism to allow for complete reductions to normal \nform. The intuition is that the reduction system stops short of normal form since there are free variables \nin the term, or au argument is required to complete reduction because the duplication process cannot \ncomplete until all terms are closed. To this end we introduce a new agent 4, and a set of interaction \nrules, which will be used to force reductions. It can be thought of as supplying dummy argu-ments to \na term to allow reductions to complete (in a similar way that environment machines, for instance, can \nbe sup- plied dummy arguments to force reduction to normal form). The translation T (t) of a term t, \nto obtain full reduction, is now the following: -7-G)I I 4 . . 4 0 In Figure 4 we show the interaction \nrules for the new agent 4. This new agent essentially behaves like an identity agent-it simply passes \nover all agents without effect, as shown by the first interaction rule. However, there are three special \ncases. The first special case is when 4 interacts with itself, in this case both instances just cancel \neach other out, indicating that the forcing is complete. The final two rules are the most important: \none converts the b agent into a b agent which will be used to allow other reductions to complete, and \nthe last rule converts the b agent back to a b agent. The intuition of the entire process is nothing \nother than allowing blocked computations to complete: when no further substitutions can be done, the \nfree variables of an abstraction are allowed to be duplicated and erased. Using these additional agents, \nwe can show that we get strong reduction in the X-calculus. Proposition 5.4 Let t be any term. Zf t -+I; \nu, for some ,f3- normal form u, then there is a finite sequence of interactions such that 7 (t) ** T(u). \nExtensions In this section we show how to extend the ideas illustrated thus far so that we can deal \nwith more realistic languages. In particular, we show how to extend to a language with conditionals and \nrecursion. To keep the concepts as simple as possible, we will use a minimalist language which is rich \nenough to explain the basic ideas, but simplistic at the level of syntax. We shall use the syntax of \nthe language PCF (231, which is well suited for this purpose. We have already intro-duced the constants \nat base type for PCF (natural numbers and booleans). In Figure 5 we show the remaining construc-tions \nof the language. The reduction rules for the constants of PCF are the following (also known as &#38;rules): \npredn+l -n pred 0 4 0 iszero n+ 1 -+ ff iszero 0 m-4 tt cond tt t u u-) t cond ff t u -+ u Yt -t(Yt) \nsucc n -+ ntl  In addition to these reduction rules, we also give the rules for substitution with the \nnew constants. We write f for all of the constant functions except conditional. f (Wl~l --h f(tbl4 cond(b, \nt, u)[v/z] +2u cond(b[v/z], t, u) if z E fv(b) Remark that there are no rules for pushing substitutions \ninside the branches of a conditional. The intuition is that since the variables are shared between the \nbranches, then we do not want to duplicate any term which is just going to be erased later. Thus we just \npostpone all substitutions until the appropriate branch is known. We will now extend the system of interaction \nto han-dle these additional features. Remark that we have already introduced the constants k E {ti, ff, \nn}. Arithmetic Functions. The constant functions f E {succ, pred, iszero} are binary agents which we \nwill draw ZiS: f 0  The intended meaning of the ports are: the result (at the top); and the principal \nport (at the bottom) where commu-nication takes place with a constant of base type. Recursion. We code \nrecursion without needing to intro-duce any additional agents. To code Y(t), let 7(t) = N, then T(Yt) \nis given by the following configuration: I I This cyclic structure explicitly ties the knot , and corre-sponds \nexactly to an encoding of recursion in graph reduc-tion, see 1221 for instance. We now get the coding \nof the PCF constant R as YI which is represented as the follow-ing cyclic structure, using two interactions. \nb #  -G-o- Figure 4: Forcing Reduction Term Type Constraint Variable Constraint Free Variables succ(t \n:1nt t : int -fv( ) pred(t) : int t : int f&#38; iszero : boo1 t : int fdt) cond(b, t, u) : 7 b : bool, \nt : T, u : T fv(t) = fv(u), fv(t) II fv(b) = IZI fv(b) U fv(t) Y(t) : u t:u-ba w - Figure 5: Syntax: \nPCF Extensions It is an interesting phenomenon that a non-terminating the branches, we will allow the \nfree variables to be shared program in PCF terminates in this interaction system until we know which \nbranch we require. This will become (there are no possible interactions, so the net is in normal clear \nwhen we give the interaction rules for the conditional form). However, the resulting net contains a cycle \nso now the below. problem has been pushed into the extraction of the result. Remark however, that there \nis no way that we can sub-This is reminiscent of black hole detection in functional stitute inside the \nbranches of the conditional, since there are languages. no possible interactions with the box structure. \nConditional. The coding of the conditional corresponds 6.1 Dynamics for PCF to the use of the additives \nin linear logic. This implies that We now show how these additional agents interact with eachwe need \nsome kind of box , in the same spirit as we used for other. We assume terms are well typed which means \nthatabstraction. We thus compile the conditional cond(b, t, u) there is no possibility for interactions \nof, for example, succin the following way. Let 7(b) = P, 7(t) = Q, 7(u) = R, and ti. There are several \nnew interaction rules that we need then we build the following net, using three kinds of agent. to add \nto this rewrite system, and we need to extend the rules for interactions with 6 and e. For the arithmetic \nfunctions we overload the notation (if+ and write j for succ, pred and iszero, and k for a constant. \nThe general scheme of the interaction rule is given by the following: f k 8 We use the agent if of arity \n4, which combines together the boolean test, true and false branch. In addition, we have a where f(k) \nis the reduction rule for PCF. We can read this list of variables occurring in the branches (cb) of the \ncon-in two ways. The first is to allow an infinite number of ditional, in a similar way as we used for \nthe coding of ab- rules, so that in fact we are giving interactions for succ n stractions. The idea is \nthat since we will only need one of for all n. A second way is to think that there is just one agent \nfor natural numbers with holds the value n, and the interaction with a constant actually applies the \nfunction to the agent. Either way gives the same result, but the latter is more intuitive from an implementation \npoint of view. The next two rules show the dynamics of the conditional. We synchronize on the boolean \ntest, then connect the re-sult of the conditional to the appropriate branch. An eras-ing agent is then \nintroduced to garbage collect the unused branch. We propagate the tt and ff agents along the list of \nfree variables of the conditional, which will be explained below. tt o- e tt 0&#38;-if if A of benchmark \nresults. Church numerals provide an excel-lent way of generating large X-terms, since application cor-responds \nto exponentiation: nm = mn. In the following table n = Xf.Xz.f z, and I = XZX. We apply Church numerals \nto II which is sufficient to force reduction to full normal form. The following table gives a summary \nof a number of benchmark results that we have obtained. We compare our results with the optimal system \nof interaction of Gonthier, Abadi and Levy. The first column shows the X-term un-der teat, and the next \ntwo columns give the total number of interactions for our algorithm (YALE) and for Gonthier, Abadi and \nLevy s (GAL), respectively. Of the interactions performed, the number of redex families reduced is given \nin parenthesis (thus the value given for GAL is the optimal one). We also show the results for BOHM [5], \nwhich is an opti- mized version of Lamping s algorithm, but it is important to note that this is not \nan interaction net (the numbers written [.I correspond to the number of non-interaction rewrite rules \napplied during reduction). The next two rules complete the dynamics of the condi- tional by connecting \nthe free variables of the conditional to the appropriate branch. tt -0 These interactions work along \nthe list of free variables until they reach its end, at which point they just cancel out the agent 21. \nWe next need to show how these additional agents for PCF interact with the existing ones. However, this \nis very straightforward in that the interactions for k, f, and cond with E and 6 (for erasing and duplication) \nfollow the rule scheme already given. To complete this section, we mention issues related to the correctness \nof this implementation. Here, of course, the real problem is that we need a strategy for reducing interaction \nnets, since now we have the possibility of non-terminating computation, particularly when used in conjunction \nwith a conditional. The unfortunate aspect is that non-terminating nets will become disconnected, but \nwe have no automatic mechanism for detecting this. We refer the reader to [8] for a detailed study of \nan operational account of interaction nets, and possible strategies which overcome this problem. Experimental \nResults There is no point in giving a new method of reduction with-out actually demonstrating how useful \nit is. We have im-plemented this system of interaction, and we show a set Term YALE GAL BOHM 2211 43(9) \n204(9) 37[3](9) 2 2 2 I I 128(20) 789(16) 90[10](16) 311 W5) 75(5) 17[21(5) 3311 88(15) 649(15) 80[7lW \n3 2 2 I I 385(51) 7055(21) 157[27](21) 2 2 3 I I 214(31) 1750(19) 125[20](19) 4411 149(23) 3456(23) 136[13](23) \n5511 226(33) 33971(33) 208[21](33) These benchmark results indicate that, although the al-gorithm is \nsometimes far from optimal, the number of inter- actions, which we take as our measure of computation \ntime, is always less than the one for optimal reduction. We also remark that if the term is linear (i.e., \nbuilt from the combi- nators I, B, and C) then the algorithm is always optimal, and moreover always does \nless work than any extant inter-action net implementation of the X-calculus, thus indicating that the \noverheads of this implementation are very small. We have not been able to compute a term which generates \nmore work for our algorithm, since known examples where optimality is really useful explode all these \nevaluators (and others implementations of the X-calculus). This supports the claim that realistic programs \ndo not need all the power of optimality to be efficient. As a final remark, we find it quite surprising \nthat the magnitude of our best results corresponds very closely to that of BOHM. Maybe this suggests \nthat these figures are representing more or less the minimum amount of work that is required to inplement \nthe X-calculus. It remains for us to implement optrmizations of our algorithm to see what can be gained. \n8 Conclusions We have presented a new algorithm for the implementa-tion of the X-calculus, based on a \nsystem of interaction nets. The design of this system comes directly from general obser-vations about \nefficient strategies for implementing the cut-elimination procedure in linear logic. Our experilnce with \nan implementation indicates that this system m7.y provide a more realistic starting point for implementations \nof languages based on the X-calculus using interaction nets rather than ones based on Lamping s. For \nmost programs written in functional languages, the cases where we fail to be optimal, and where the optimal \nreducers do better, simply do not arise. It remains for us to extend these ideas to more realistic functional \nlanguages so that a detailed comparison of performance can be obtained. Further work is underway to improve \n(optimize) the translations. One approach is to use a language where the programmer can explicitly declare \nlinear terms which can avoid the use of the b agents, which are only there for non-linear terms, and \ncause most of the overheads in the re-duction. For instance we could use the language Lilac [18]. There \nis also a lot of scope for optimizing the reduction sys-tem by adding additional rules which do not break \nthe cor-rectness of the system, but leave the interaction net frame-work. Finally, we remark that the \nexplicit substitution calculus that we introduced in this paper seems to enjoy a lot of interesting properties, \nand deserves further study. Acknowledgements I am most grateful to Maribel Fernhdez and Jorge Sousa Pinto \nfor comments and careful proof reading of this paper. References Martin Abadi, Luca Cardelli, Pierre-Louis \nCurien, and PI Jean-Jacques L&#38;y. Explicit substitutions. Journal of Fzlnctional Programming, 1(4):375-416, \nOctober 1991. Samson Abramsky. The lazy X-calculus. In David A. PI Turner, editor, Research Topics in \nFunctional Program-ming, chapter 4, pages 65-117. Addison Wesley, 1990. Samson Abramsky. Computational \nInterpretations of PI Linear Logic. Theoretical Computer Science, 111:3-57, 1993. Francisco Alberti. \nAn abstract machine based on linear PI logic and explicit substitutions. Master s thesis, Uni-versity \nof Birmingham, 1997. Andrea Asperti, Cecilia Giovannetti, and Andrea [51 Naletto. The bologna optimal \nhigher-order ma-chine. Journal of Functional Programming, 6(6):763-810, November 1996. Henk P. Barendregt. \nThe Lambda Calculus: Its Syntax and Semantics, volume 103 of Studies in Logic and the Foundations of \nMathematics. North-Holland Publish-ing Company, second, revised edition, 1984. Vincent Danos and Laurent \nRegnier. Local and asyn- chronous beta-reduction (an analysis of Girard s execu-tion formula). In Proceedings \nof the 8th Annual IEEE Symposium on Logic in Computer Science (LICS 93), pages 296-306. IEEE Computer \nSociety Press, 1993. Maribel Fern&#38;ndez and Ian Mackie. A calcu- PI lus for interaction nets, 1998. \nAvailable from http://lix.polytechnique.fr/Nmackie. Jean-Yves Girard. Linear Logic. Theoretical Computer \nPI Science, 50(1):1-102, 1987. PO! Jean-Yves Girard. Geometry of interaction 1: Interpre- tation of System \nF. In R. Ferro, C. Bonotto, S. Valen- tini, and A. Zanardo, editors, Logic Colloquium 88, Studies in \nLogic and the Foundations of Mathemat-ics. North Holland Publishing Company, Amsterdam, August 1989. \nGeorges Gonthier, Martin Abadi, and 1111 L&#38;y. The geometry of optimal lambda Proceedings of the 19th \nACM Symposium of Programming Languages (POPL 92), ACM Press, January 1992. Jean-Jacques reduction. In \non Principles pages 15-26. PI Siiren Holmstrijm. Linear functional programming. In T. Johnsson, Simon \nL. Peyton Jones, and K. Karlsson, editors, Proceedings of the Workshop on Implementa-tion of Ln.q Functional \nLanguages, pages 13-32, 1988. Yves Lafont. The Linear Abstract Machine. Theoretical Computer Science, \n59(1,2):157-180, 1988. P31 Yves Lafont. Interaction nets. In Proceedings of the 17th ACM Symposium on \nPrinciples of Programmang Langmges (POPL 90), pages 95-108. ACM Press, Jan- uary 1390. 1141 Yves L&#38;font. \nInteraction combinators. Information and Coxputntion, 137(1):69-101, 1997. 1151 John Lamping. An algorithm \nfor optimal lambda calcu-lus reduction. In Proceedings of the 17th ACM Sympo-siux on I rkiples of Programming \nLanguages, pages 16-30. ACM Press, January 1990. PI Ian Maciiie. The Geometry of Implementation. PhD \nthesis, Department of Computing, Imperial College of Scienc?, Technology and Medicine, September 1994. \n1171 P81 Ian Mackie. Lilac: A functional programming language based on linear logic. Journal of Functional \nProgram-ming, 4(4):395-433, October 1994. 1191 Ian MXki 2 The geometry of interaction machine. In Proct:ed@qs \nof the 22nd ACM Symposium on Principles of I .~oyra~~iming Languages (POPL 95), pages 198-208. AC% Press, \nJanuary 1995. PO1 Ian Mackie. Linear logic with boxes. In Proceedings of the i3t!b Annual IEEE Symposium \non Logic in Com-puter S&#38;rice (LICS 98), pages 309-320. IEEE Com- puter Society Press, June 1998. \nWI Ian Ma&#38;e and Jorge Sousa Pinto. piling the X-calculus into interaction hinators, January 1998. \nAvailable http://lix.polytechnique.fr/Nmackie. PI Simon L. feyton Jones. The Implementation to~uil Programming \nLanguages. Prentice Hall tional, 1987. Com-com-from of fine Interna- Gordon Tlotkin. LCF considered \nas a programming 1231 language. Theoretical Computer Science, 5(3):223-256, 1977. Christol;!*ie: P. Wadsworth. \nSemantks and Pragmatics PI cf the Lamtda- Calculus. PhD thesis, Oxford University, 1972. Da\\,id \\Vakeling. \nLinearity and Laziness. PhD thesis, [251 Uui .er+y tif York, 1990.  \n\t\t\t", "proc_id": "289423", "abstract": "Interaction nets provide a graphical paradigm of computation based on net rewriting. They have proved most successful in understanding the dynamics of reduction in the &amp;lambda;-calculus, where the prime example is the implementation of optimal reduction for the &amp;lambda;-calculus (Lamping's algorithm), given by Gonthier, Abadi and L&amp;eacute;vy. However, efficient implementations of optimal reduction have had to break away from the interaction net paradigm. In this paper we give a new <i>efficient</i> interaction net encoding of the &amp;lambda;-calculus which is not optimal, but overcomes the inefficiencies caused by the bookkeeping operations in the implementations of optimal reduction. We believe that this implementation of the &amp;lambda;-calculus could provide the basis for highly efficient implementations of functional languages.", "authors": [{"name": "Ian Mackie", "author_profile_id": "81100651343", "affiliation": "CNRS (UMR 7650) and &#201;cole Polytechnique, Laboratoire d'Informatique(LIX), 91128 Palaiseau Cedex, France", "person_id": "PP40029491", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/289423.289434", "year": "1998", "article_id": "289434", "conference": "ICFP", "title": "YALE: yet another lambda evaluator based on interaction nets", "url": "http://dl.acm.org/citation.cfm?id=289434"}