{"article_publication_date": "09-29-1998", "fulltext": "\n Building Program Optimizers with Rewriting Strategies* Eelco Visserl, Zine-el-Abidine Benaissa , Andrew \nTolmach1T2 Pacific Software Research Center r Dept. of Comp. Science and Engineering, Oregon Graduate \nInstitute, P.O. Box 91000, Portland, Oregon 97291-1000, USA z Dept. of Computer Science, Portland State \nUniversity, P.O. Box 751, Portland, Oregon 97207 USA visserOacm.org, benaissaOcse.ogi.edu, aptQcs.pdx.edu \nAbstract We describe a language for defining term rewriting strate-gies, and its application to the production \nof program op-timizers. Valid transformations on program terms can be described by a set of rewrite rules; \nrewriting strategies are used to describe when and how the various rules should be applied in order to \nobtain the desired optimization effects. Separating rules from strategies in this fashion makes it eas-ier \nto reason about the behaviof of the optimizer as a whole, compared to traditional monolithic optimizer \nimplementa-tions. We illustrate the expressiveness of our language by using it to describe a simple optimizer \nfor an ML-like inter-mediate representation. The basic strategy language uses operators such as se- quential \ncomposition, choice, and recursion to build trans-formers from a set of labeled unconditional rewrite \nrules. We also define an extended language in which the side-conditions and contextual rules that arise \nin realistic opti-mizer specifications can themselves be expressed as strategy- driven rewrites. We show \nthat the features of the basic and extended languages can be expressed by breaking down the rewrite rules \ninto their primitive building blocks, namely matching and building terms in variable binding environ-ments. \nThis gives us a low-level core language which has a clear semantics, can be implemented straightforwardly \nand can itself be optimized. The current implementation gener-ates C code from a strategy specification. \nIntroduction Compiler components such as parsers, pretty-printers and code generators are routinely \nproduced using program gen-erators. The component is specified in a high-level lan-guage from which the \nprogram generator produces its imple- mentation. Program optimizers are difficult labor-intensive components \nthat are usually still developed manually, de-spite many attempts at producing optimizer generators (e.g., \n[19, 12, 28, 25, 18, 111). This work was supported. in part. by the US Air Force Materiel Corrmar~I under \ncontract F19628-93-C-0069 and by the National Sci-ence Foundation under grant CCR-9503383. A program \noptimizer transforms the source code of a program into a program that has the same meaning, but is more \nefficient. On the level of specification and documenta- tion, optimizers are often presented as a set \nof correctness- preserving rewrite rules that transform code fragments into equivalent more efficient \ncode fragments (e.g., see Table 5). This is particularly attractive for functional language com-pilers \n(e.g., [3, 4, 241) that operate via successive small trans-formations, and don t rely on analyses requiring \nsignificant auxiliary data structures. The paradigm provided by con-ventional rewrite engines is to compute \nthe normal form of a program with respect to a set of rewrite rules. However, optimizers are usually \nnot implemented in this way. In-stead, an algorithm is produced that implements a strategy for applying \nthe optimization rules. Such a strategy con-tains meta-knowledge about the set of rewrite rules and the \nprogramming language they are applied to in order to (1) control the application of rules; (2) guarantee \ntermination of optimization; (3) make optimization more efficient. Such an ad-hoc implementation of a \nrewriting system has several drawbacks, even when implemented in a lan-guage with good support for pattern \nmatching, such as ML or Haskell. First of all, the transformation rules are em-bedded in the code of \nthe optimizer, making them hard to understand, to maintain, and to reuse individual rules in other transformations. \nSecondly, the strategy is not speci-fied at the same level of abstraction as the transformation rules, \nmaking it hard to reason about the correctness of the optimizer even if the individual rules are correct. \nFinally, the host language has no awareness of the transformation domain underlying the implementation \nand can therefore not use this domain knowledge to optimize the optimizer itself. It would be desirable \nto apply term rewriting technol-ogy directly to produce program optimizers. However, the standard approach \nto rewriting is to provide a fixed strategy (e.g., innermost or outermost) for normalizing a term with \nrespect to a set of user-defined rewrite rules. This is not satisfactory when-as is usually the case \nfor optimizers-the rewrite rules are neither confluent nor terminating. A common work-around is to encode \na strategy into the rules themselves, e.g., by using an explicit function symbol that controls where \nrewrites are allowed. But this approach has the same disadvantages as the ad-hoc implementation of rewriting \ndescribed above: the rules are hard to read, and the strategies are still expressed at a low level of \nabstraction. In this paper we argue that a better solution is to use explicit specification of rewriting \nstrategies. We show how program optimizers can be built by means of a set of labeled rewrite rules and \na user-defined strategy for applying these rules. In this approach transformation rules can be defined \nindependently of any strategy, so the designer can concen- trate on defining a set of correct transformation \nrules for a programming language. The transformation rules can then be used in many independent strategies \nthat are specified in a formally defined strategy language. Given such a high- level specification of \na program optimizer, a compiler can generate efficient code for executing the optimization rules. Starting \nwith simple unconditional rewrite rules as atomic strategies we introduce in Section 2 the basic com- \nbinators for building rewriting strategies. We give examples of strategies and define their operational \nsemantics. In Sec- tion 3 we explore optimization rules for RML programs, an intermediate format for \nML-like programs (261. This ex- ample shows that there is a gap between the unconditional rewrite rules \nused in rewriting and the transformation rules used for optimization. For this reason, we need to enrich \nrewrite rules with features such as conditions and contexts. In order to avoid complicating the implementation \nby many ad-hoc features, we refine our language by breaking down rewrite rules into the notions of matching \nand building terms (Section 4). This gives us a low-level core language which has a clear semantics, \ncan be implemented straightforwardly and can itself be optimized. The current implementation generates \nC code from a strategy specification. In Section 5 we show how this core language can be used to encode \nhigh- level rules with conditions and contexts. In Section 6 we use the resulting language to give a \nformal specification of the RML rules presented earlier. Section 7 describes the implementation and Section \n8 discusses related work. 2 Rewriting Strategies A rewriting strategy is an algorithm for applying rewrite \nrules. In this section we introduce the building blocks for specifying such algorithms and give several \nexamples of their application. The strategy language presented in this section is an extension of previous \nwork [20] of one of the present authors. 2.1 Terms We will represent expressions in the object language \nby means of first-order terms. A first-order term is a variable, a constant, a tuple of one or more terms, \nor an application of a constructor to one or more terms. This is summarized by the following grammar: \nt::=xIc)(t1,..., tn)If(tl)...) tn) where 2 represents variables (lowercase identifiers), c rep resents \nconstants (uppercase identifiers or integers) and f represents constructors (uppercase identifiers). \nWe denote the set of all variables by X, the set of terms with variables by T(X) and the set of ground \nterms (terms without vari-ables) by T. Terms can be typed by means of signatures. For simplicity of presentation, \nwe will consider only untyped terms in this paper until Section 6. For now, we assume that a signature \nC is a function mapping operators to their ari-ties. We will also use a shorthand notation for lists. \nA term [tl, tz, . , tn] denotes a term Cons(tl, Cons(t2,. . . , Cons(t,,Nil))) Constants are considered \nto be constructors with zero-arity and tuples are considered to be constructed with a special constructor \nfor each arity. 2.2 Rewrite Rules A labeled rewrite rule has the form ! : 1 -+ r, where e is a label \nand 1, T are first-order terms. For example, consider a calculus of lists constructed with Cons and Nil \nand Boolean values True and False that defines transformation rules for the constructor Member as: Meml \n: Member(z, Nil) -+ False Mem2 : Member(z, Cons(z, ys)) 3 True Mem3 : Member(z, Cons(y, ys)) --f Member(s, \nys) A rewrite rule specifies a single step transformation of a term. For example, rule Mem3 induces the \nfollowing trans-formation: Member (A, Cons(B, Cons(A, Nil))) q Member(A, Cons(A, Nil)) In general, a \nrewrite rule defines a labeled transition re-lation between terms and reducts, as formalized in the op- \nerational semantics in Table 1. A reduct is either a term or t, which denotes failure. The first rule \ndefines that a rule e transforms a term t into a term t if there exists a substitu- tion 0 mapping variables \nto terms such that t is a o-instance of the left-hand side 1 and t is a cr-instance of the right-hand \nside T. The second rule states that an attempt to transform a term t with rule e fails, if there is no \nsubstitution u such that t is a o-instance of 1. For instance, in our membership example we have Member(A, \nCons(B, Cons(A, Nil))) 5 7 Note that a rewrite rule applies at the root of a term. Later on we will introduce \noperators for applying a rule to a sub- term. t e i+r> t if 30 : u(1) = t A g(r) = t t e +r>t if 7% : \na(l) = t Table 1: Operational semantics for unconditional rules.  2.3 Reduction-Graph Traversal The \nreduction graph induced by a set of rewrite rules is the transitive closure of the single step transition \nrelation. It forms the space of all possible transformations that can be performed with those rules. \nFor instance, one path in the reduction graph induced by the rules Meml and Mem3 is the following: Member(A, \nCons(B, Cons(C, Nil))) z Member(A, Cons(C, Nil)) a Member(A, Nil) a False  t-At t-t t 4 t t=%t t-% \nr t-&#38;t t -%t t-=+-r t-t t-&#38;t t-%t t s1++2 t-r t-t t%t t ~l+l-~Z b-7 t s[+:=pz(s)] w(s) I t \nw(s) tt t----k t rt (a) positive rules (b) negative rules Table 2: Operational semantics for basic combinators. \nA strategy is an algorithm for exploring the reduction graph induced by a set of rules. Rewrite rules \nare atomic strategies that describe a path of length one. In this section we consider combinators for \ncombining rules into more com-plex strategies. The operational semantics of these strategy operators \nis defined in Table 2. The fundamental operation for compounding the effects of two transformations is \nthe sequential composition 91;s~ of two strategies. It first applies si and, if that succeeds, it ap- \nplies 92. For example, the reduction path above is described by the strategy Mem3 ; Mem3 ; Meml. The \nnon-deterministic choice SI +s2 chooses between the strategies si and s2 such that the strategy chosen \nsucceeds. For instance, the strategy Meml + Mem2 applies either Meml or Mem2. Note that due to this operator \nthere can be more than one way in which a strategy can succeed. With the non-deterministic choice operator \nthe program- mer has no control over which strategy is chosen. The deter-ministic or left choice operator \nsi + 92 is biased to choose its left argument fist. It will consider the second strategy only if the \nfirst does not succeed. This operator can be used to give higher priority to rules. For example, rule \nMemP and Mem3 are overlapping rules. To express that Mem3 should be applied only after it is certain \nthat Mem2 does not apply, the strategy (Meml + Mem2) +t Mem3 can be used. Strategies that repeatedly \napply some rules can be de- fined using the recursion operator px(s). For instance, the strategy p((Meml \n+ Mem2) +t (Mem3 ; z)) repeatedly applies rule Mem3 (if possible) until either rule Meml or Mem2 is applicable. \nThe strategy fails if neither Meml nor MemZ is ever applicable. (Note that ; has higher prece-dence than \n+ and +k. Therefore, (Meml + Mem2) + (Mem3 ; z) could also be written as (Meml + Mem2) + Memd ; z.) The \nidentity strategy e always succeeds. It is often used in conjunction with left choice to build an optional \nstrategy: s +t e tries to apply s, but when that fails just succeeds with e. The failure strategy 6 is \nthe dual of identity and always fails. The strategy tests can be used to test whether a strat- egy s \nwould succeed or fail without having the transforming effect of s. The negation 7s of a strategy s is \nsimilar to test, but tests for failure of s. We will see examples of the application of these operators \nin Section 6. Redex and Normal Form We will call a term an e-redex if it can be transformed with a rule \ne, otherwise it is in !-normal form. We will generalize this terminology to general strategies, i.e., \nif t -4 t , then t is an s-redex and if t 4 t, then t is in s-normal form. Strategy Definitions In order \nto name common patterns of strategies we will use strategy definitions. A definition p(Zl,. . . ,x,) \n= s introduces a new n-ary strategy operator cp. An application p(si , . . . , sn) of cp to n strategies \ndenotes the instantiation s[zi := si . . . xn := sn] of the body s of the definition. Strategy definitions \nare not recursive and not higher-order, i.e., it is not possible to give a strategy operator as argument \nto a strategy operator. An example of a common pattern is the application of a strategy to a term as \noften as possible. This is expressed by the definitions repeat(s) = pz((s ; CC) +t- E) repeatl(s) = s; \nrepeat(s) The strategy repeat(s) applies s as many times (zero or more) as possible. The strategy repeatl(s) \nis like repeat, except that it must succeed at least once. Using repeat, we can define the strategy repeat \n((Meml + Mem2) +t Mem3) which is equivalent to pz((((Mem1 + Mem2) +t Mem3) ; z) tf e). It applies rules \nMeml, Mem2 and Mem3 as often as possible and will always succeed. 1.5 7 ti 4 ti f(h,, . . ) ti, . , tn) \na0 f(h,. . . ) t;, . . , tn) t1 At; . . t, Sn, t:, f(tl,. . ) tn) f(s13-3sn)+ f(t;, . . ,t n) ti -4 \nt i f(tl) ) ti ,. . ,tn)%f(tl ,... ,t: ) . ,tn) t1 -% t; . . t, -% t:, f(b)... ,tn)Sf(t; ,... ,tg 3jvi \n: i,j E {l..n} A P(ti) = ti if ti -% 6 ti if ti --% t A i # j { fttl,. , t,) % f(P(tl), . ) P&#38;L)) \n(a) positive rules Table 3: Operational semantics for term traversal operators all rules n E C(f), m \ns C(g) and 1 _< i _< n. Backtracking Operationally, the non-deterministic choice operator SI + sz randomly \nchooses one strategy to apply and if that fails backtracks and attempts to apply the other one. However, \nbacktracking is local only; if the first strategy succeeds the second will never be attempted. If both \ns1 and sz succeed, then the order in which they are tried can affect the outcome of the larger strategy \nthat encompasses the choice. For example, suppose that t -% t and t -% t , but t 3, t and t a t . Then \n(~l+~zh p, or t (sl+Q)iR3 f depending on the either t choice made for s1 + ~2. The left choice operator \n+t is also a local backtracking operator, but the order in which the alternatives are tried is fixed. \nTherefore, a strategy composed without + is deterministic and either fails or succeeds. 2.4 Term Traversal \nThe operators introduced above apply strategies to the root of a term. This is not adequate for achieving \nall transfor-mations. For instance, consider the extension of our list calculus with a concatenation \noperator Cone: Cncl : Conc(Ni1, zs) -+ xs Cnc2 : Conc(Cons(z, zs), ys) + Cons(z,Conc(zs, ys)) Application \nof rule Cnc2 leads to an opportunity to apply these rules below the root of the term. For example, consider \nthe reduction path: Cone (Cons (1, Nil) , Cons (2, Nil)) % Cons(l, Conc(Ni1, Cons(2, Nil))) z(cncl)> \nCons(l, Cons(2, Nil)) The second step in this reduction is an application of rub Cncl to the second argument \nof the Cons. fV1,... ,tn)3t ifi>n ti 47 f(tl )... ,ti ) .. ,tn) i(s),1. ti 41 L (b) negative rules These \nrules are schemata that define a rule for each f E C. In In general, we want to be able to apply transformation \nrules at arbitrary depth in a term. For this purpose we introduce five basic operators for applying a \ntransformation to the children of a constructor. The operational semantics of these operators is defined \nin Table 3. In conjunction with the operators defined above, these are sufficient to define a wide range \nof full term traversals. The fundamental operation for term traversal is the ap-plication of a strategy \nto a specific child of a term. The strategy i(s) applies strategy s to the i-th child. If it suc-ceeds \nthe child is replaced with the result of the transforma- tion. If it fails the application of i(s) fails. \nIt also fails if i is greater than then the arity of the constructor of the term to which it is applied. \nWe saw an example above, Z(Cncl) applies rule Cncl to the second argument of the root. Congs-uence operators \nspecify application of strategies to the children of terms constructed with a specific constructor. For \neach term constructor f E dam(C) there is a correspond- ing strategy operator f with arity C(f). If sl,...,s~(f) \nare strategies then f(sl, . . . . SC(~)) is the strategy that applies only to terms t with outermost \nconstructor f and applies each si to the i-th child of t. For example, the strategy Cons(sl,sz) applies \nto Cons terms and applies s1 to the head of the list and s2 to the tail. In the example above Cons(c,Cncl) \nis equivalent to 2(Cncl). To apply the con-catenation rules until the application of Cone is eliminated \nwe can use the strategy px(Cnc1 + (Cncl ; Cons(e, x))) The strategy either terminates with rule Cncl \nor else applies rule Cnc2 and then recursively applies the strategy to the Cone created in the the use \nof congruence applies a strategy s t tail of the operators o each element list. Another is the strategy \nof a list: example map(s) that of map(s) = pz(Nil+ Cons(s,z)) The path and congruence operators are \nuseful for con-structing strategies for a specific data structure. To con-struct more general strategies \nthat can traverse arbitrary data structures we introduce the operators Cl(s), O(s) and q . These operators \nare defined generically on all terms over a signature C. The strategy U(s) applies s to each child of \nthe root and succeeds if s succeeds for each child. It fails if s fails for one or more of the children. \nIn case of constants, i.e., con-structors without arguments, the strategy always succeeds, since there \nare no children. (As a consequence the strat-egy O(6) succeeds exactly on constants.) This allows us \nto define very general traversal strategies. For example, the following strategies apply a strategy s \nto each node in a term, in preorder (top-down), postorder (bottom-up) and a combination of pre- and postorder \n(downup): topdown = pz(s ; Cl(e)) bottomup = ~z(O(Z) ; s) downup = ~Z(S ; U(Z) ; s) For example, the \nstrategy topdown((Cnc1 + Cnc2) + e) tries to apply the rules Cncl and Cnc2 everywhere in a term in a \ntopdown traversal. It always succeeds because of the escape +e. The strategy O(s) is the dual of O(s); \nIt applies s non- deterministically to one child for which it succeeds. It fails if there is no child \nfor which it succeeds. In particular, it fails for constants, since they have no child for which s can \nsucceed. As a consequence the strategy O(E) succeeds ex-actly on non-constants. The duals of the pre- \nand post-order traversals defined above apply a strategy s exactly once in a term while traversing the \nterm in a top-down or bottom-up order: oncetd(s) = ,KZ(S it O(x)) oncebu(s) = p~(O(x) et s) The strategy \noncetd(s) first tries to apply s at the root and terminates if that succeeds. Otherwise if s fails on \nthe root, it tries to apply the strategy to one of the children. The strategy oncebu(s) first tries to \nfind an application of s below the root. If that fails s must succeed at the root. For instance, the \nstrategy oncetd(Cncl+ Cnc2) succeeds if it finds an application of either rule Cncl or Cnc2 in the term \nand fails otherwise. Finally, m(s) is a hybrid of O(s) and O(s) that applies s to some children. It is \nlike 0 because it has to succeed for at least one child and it is like 0 because it applies to all children. \nThe difference from 0 is that it does not have to succeed for all children. The analogue of oncebu with \ngS is the strategy somebu, defined as: somebu(s) = ~x(~(x) + s) Where oncebu finds a single subterm for \nwhich s succeeds, somebu finds as many subterms as possible to which s ap- plies, but at least one. However, \nas soon as s succeeds for a subterm t of t, s is not applied to any of the nodes in the spine from t \nto t . A version of this strategy that finds still more subterms to apply to is manybu, defined as: manybu(s) \n= px( (Kl(x) ; (s +t E)) + s) After applying s to as many subterms as possible with a(z), s is also tried \nat the root. If s did not succeed on any subterm, it has to succeed on the root for the strategy to succeed. \nThe analogous pre-order strategies are: sometd(s) = ~X(S tt Q(X)) manytd(s) = pz((s ; q (Z +t E)) +t \na(,)) These strategies perform a single traversal over a term. A normalization strategy for a strategy \ns keeps traversing the term until it finds no more s-redexes. Examples of well- known normalization strategies \nare reduce, which repeat-edly finds a redex somewhere in the term, outermost, which repeatedly finds \na redex starting from the root of the term and innermost, which looks for redexes from the leafs of the \nterm. Their definitions are: reduce(s) = repeat(puz(O(x) + s)) outermost(s) = repeat(oncetd(s)) innermost(s) \n= repeat(oncebu(s)) Note that this definition of innermost reduction is not very efficient. After finding \na redex, search for the next redex starts at the root again. A more efficient definition of innermost \nreduction is the following. innermost (s) = pz(Cl(0) ; ((s ; X) tt e)) It first normalizes all subterms \n(O(x)), i.e., all strict sub-terms we in s-normal-form. Then it tries to apply s at the root. If that \nfails this means the term is in s-normal-form and normalization terminates with E. Otherwise, the reduct \nresulting from applying s is normalized again. Using the other traversal strategies defined above a wide \nrange of al- ternative normalization strategies can be defined. See also [27] for examples of alternative \nevaluation strategies. 3 Case Study: RML Optimizer RML (261 is a strict functional language, essentially \nsimilar to the core of Standard ML [22] with a few restrictions. In this paper we consider a subset of \nRML that includes ba-sic features of functional languages, namely basic constants (integer, boolean, \netc.) and primitive built-in functions, tu-ples and selection, let-bindings and mutually recursive func-tions. \nPrograms are pre-processed by the compiler of RML to A-normal form. The syntax of this restriction of \nRML is presented in Table 4. Table 5 describes a set of meaning preserving source-to-source transformation \nrules for RML. The transformations are intended to improve the performance of programs either directly \n(e.g., (Deadl) and (DeadS), which perform dead code elimination) or by enabling future improving trans-formations \n(e.g., (Hoi&#38;l) and (Hoist2), which sequentialize code). For in-depth discussions of the intent and \ncorrectness of these rules we refer the reader to the literature on trans- formation of functional programs, \ne.g. [3, 4, 13, 241. These particular rules were inspired by those presented in [4]. In the sequel, we \nconcentrate on the details of the implemen-tation of these rules. In these rules we use the following \nnotation and auxil-iary notions: We write a for a list of phrases al . . . a, with the appropriate separator \nfor the list type. The function vars produces the set of free variables of an expression. An expression \nis safe if it contains no calls to side-effecting prim-itives or to user-defined functions; any safe \nfunction is guar- anteed to be pure and terminating. An expression is small if let x : t = let y : t \n= eo in el in ez * let g : t = eo in let z : t = el in ez (Hoistl) if y # vars(ez) let 2 : t = letrec \nf&#38;c in el in ez + letrec fdc in let x : t = el in e2 (Hoist2) if for each f : t(2) = e in fd> : f \n@ vars(e2) let 2 : t = el in e2 + e2 if x g vars(e2) and el is safe (Deadl) letrec f&#38;c in e -+ e \nif for each f : t (Z) = e in f&#38;c: f 4 vars(e) (Dead2) let 2 : t = se in e + let z : t = se in e{se/z} \nProp) letrec f : t (2) = e in e[f (s e)] ---+ letrec f : t (3) = e in e[rename(e {G/Z})] (Inline) if \nf e (vars(G) U vars(e[-I)) or e is small letx:t=(ael,..., se,) in e[select(i,z)] ---t let 2 : t = (sel, \n. . . , se,) in e[sei] (Select) let f : {+ t = el in e2 + letrec f : X-t t (2) = let f : C--b t = el \nin f (2) in e2 (EtaExp) if [Z/ = ITI, f and the xi are fresh variables and el is safe Table 5: Transformation \nrules for RML t::=bItl-+tzItl,...,tn (Types) se ::= x 1 c (Simple expressions) fdec ::= f : t (21,. . \n. , z,) = e (Function declarations) vdec :I= x : t = e (Variable bindings) e ::= se (Expressions) 1 x(=1,. \n. . , se,) I d(sel,...,.m) (sel,...,.m) select(i, se) let udec in e letrec fdecl . . . fdec, in e where \n2, f, fl,... range over variables, c over constants, md d over primitive built-in functions, i over integers, \nz,el,.. . over expressions, b over basic types, and t, tl , . . . lver types. No variable is bound twice. \nTable 4: Syntax of RML it contains no nested declarations; inlining a function whose body is small cannot \nincrease the size of the program (mea-sured in number of expressions). It might seem straightforward \nto implement these rules by a rewriting system using the strategy combinators intro-duced in the previous \nsection. Unfortunately, this is not the case! There is a gap between these transformation rules and the \nsimple rewrite rules defined above. Only (Hoistl) and (Hoist2) conform to the format. (The conditions \nof these rules are redundant in case no variable is bound twice.) All the other rules use features that \nare not provided by basic rewrite systems. (Deadl) and (Dead2) are conditional rewrite rules that remove \npieces of dead code. The condition (Deadl) tests whether the variable defined by the let occurs in the \nbody of the let. The condition of (Dead2) tests whether any of the functions defined in the list of function \ndeclarations occur in the body. (Prop), which performs constant and variable propagation, requires substitution \nof free occurrences of a variable by an expression. (Inline) is a context-sensitive rule which replaces \nan application of the function f somewhere in the expression e by the body of the function. This is expressed \nby the use of a contest e[f (s-6)]. Inlining should only occur if f appears only once in e (expressed \nhere as f $! (vars(a%) U vars(e[-I))) or its body is small. (Inline) uses simultaneous substitution of \na list of expressions for a list of variables. Furthermore, the rule renames all occurrences of bound \nvariables with fresh variables, to preserve the invari- ant that no variable is bound twice. This invariant \nsimplifies substitution and testing for the occurrence of a variable in an expression. Finally, (EtaExp) \nrequires the generation of variables that are fresh with respect to the entire program. 4 Refining the \nStrategy Language The RML example shows that simple unconditional rules lack the expressivity to describe \noptimization rules for pro- gramming languages and that we need enriched rewrite rules with features \nsuch as side conditions and contexts and sup- port for variable renaming and substitution of object vari-ables. \nFor other applications we might need other features such as list matching and matching modulo associativity \nand commutativity. Adding each of these features as an ad-hoc extension of basic rewrite rules would \nmake the language difficult to implement and maintain. It is desirable to find a more uniform method \nto deal with such extensions. If we take a closer look at the features discussed above, we observe that \nthey all have strategy-like behaviour. For instance, a rule with a context c[Z ] in the left-hand side \nand c[r ] in the right-hand side can be seen as a strategy that tra-verses the subterm that matches c \nand applies rule 1 + P . Also, checking that some term tl occurs as a subterm of a term t2 requires traversing \nt2. Therefore, instead of cre-ating more complex primitives such as rules with contexts, we break down \nrewrite rules into their primitives: match-ing against term patterns and building terms. Using these \nprimitives we can implement a wide range of features in the strategy language itself by translating rules \nwhich use those features into strategy expressions. match(t ) mstch(t ) t:&#38; f t : E if E &#38;I &#38; \nA &#38; (t ) = t t:&#38; b t if 4E It! &#38; A &#38; (t ) = t build(t ) t:&#38; ) &#38;(t ) : &#38; if \nvars(t ) c dom(&#38;) fI . &#38; b i d(t )) t if vars(t ) g dom(&#38;) t:EAt :&#38; t:&#38;At where8 \nt : E, where s t:&#38; t:&#38; tt t : (&#38;\\Z) 4 t : E t : &#38; il:s), t : (&#38;I\\?) u (El2) tl:&#38;(J%t::El \n. . . tn:Elt-l*t:,:En tl: Eo-%t: : 61 ..a ti: Ei-l -%t f(h,. .. )tn) : &#38;o f(slv-.rsn)+f(t;, ... ,tl,) \n: &#38;, f(tl ,... ,tn): E. f(s1 - 9n),-f t1 : Eoe, t: : El ... t, : En-1 4 t:, : R tl : E. 8, t; : El \n. . . ti : Ei-1 -% t f(h).. ) tn):&#38;+%f(t: ).. ( qJ:En . . ,tn): EoO t f@l,. tj if ti : &#38;i-l \n9, ti : &#38;i 3jVi : i,j E {l..n} A P(ti) = ti if ti : &#38;i-l 8, t A tl:&#38;--%t . . . t,:E*t { &#38;=&#38;i-l \nAi#j f(tl, . . . , tn) : E % t f (tl, . )tn) : &#38;ow f (P(h), ... )P(t,)) : &#38;,, (a) positive rules \n(b) negative rules Table 6: Operational semantics for environment operators. Match, Build and Scope We \nfirst define the semantics of matching and building terms. A rewrite rule f? : 1 + T first matches the \nterm against the left-hand side 1 producing a binding of subterms to the variables in 1. Then it builds \na new term by instantiating the right-hand side T with those variable bindings. By introducing the new \nstrategy primi-tives match and build we can break down e into a strategy match(l) ; build(r). However, \nthis requires that we carry the bindings obtained by match over the sequential composition to build. \nFor this reason, we introduce the notion of envi-ronments explicitly in the semantics. An environment \nE is a mapping of variables to ground terms. We denote the instantiation of a term t by an en-vironment \n&#38; by E(t). An environment E is an extension of environment E (notation E 2 E) if for each z E dom(&#38;) \nwe have E (x) = E(x). An environment E is the smallest extension of E with respect to a term t (notation \nE zt E), if E 2 E and if dom(E ) = dam(E) U vars(t). Now we can formally define the semantics of match \nand build. We extend the reduction relation &#38; from a relation between terms and reducts to a relation \non pairs of terms and environments, i.e. a strategy 3 transforms a term t and an environment E into a \ntransformed term t and an extended environment E , denoted by t : &#38; d, t : E , or fails, denoted \nby t : E -% t. The operational semantics of the environment operators are defined in Table 6. The change \nin the format of the operational semantics should be reflected in the semantics of the operators introduced \nearlier. In the remainder of the paper the rules in Tables 2 and 3 should be read as follows: a transition \nt -% t denotes a transition t : E --% t : E . The only exceptions are the rules for congruence, 0 and \nKY See Table 6 for their definitions in the extended semantics, Once a variable is bound it cannot be \nrebound to a dif-ferent term. To use a variable name more than once we introduce variable scopes. A scope \n(3 : s} locally undefines the variables Z. That is, the binding to a variable xi outside the scope (2 \n: s} is not visible inside it, nor is the binding to xi inside the scope visible outside it. The notation \n&#38; \\ 5 denotes &#38; without bindings for variables in j?. E(4 denotes E restricted to Z The strategy \noperator where is similar to the test operator of Section 2 in that it tries a strategy and returns the \noriginal term if it succeeds. However, it keeps the transformation on the environment. This operator \ncan be used to encode a local computation that binds the an-swer to a variable to be used outside it, \nwithout actually transforming the term. Note that this definition supports matching with non-linear patterns. \nIf a variable z occurs more than once in a pattern t, then match(t) succeeds only if all occurrences \nof x in t are bound to the same term. Moreover, if a variable x in t was already bound by a previous \nmatch, it should match to the exact same term as it was bound to before. For example, consider the strategy \nin that tests whether x is a subterm of J/. It is defined as in = {x, y : match((x, y)) ; test(build(y) \n; oncetd(match(x)))} The first match matches a pair of terms (tl, t2), binding tl to x and t2 toy. The \nbuild replaces the pair by t2. The traversal oncetd searches for an occurrence of tl in t2 by matching \nz (which is bound to tl) against subterms of t2. The strategy succeeds if it actually finds a matching \nsubterm. The use of test ensures that the predicate does not affect the term to which it is applied. \n5 Implementation of Transformation Rules We now have a strategy language that consists of match and build \nas atomic strategies (instead of rewrite rules) and all the combinators introduced in Section 2. Using \nthis refined strategy language, we can implement transformation rules by translating them to strategy \nexpressions. In this higher-level view of strategies we can use both the low-level fea-tures match, build \nand scope and the high-level features such as contexts and conditions. We start by defining the meaning \nof unconditional rewrite rules in terms of our re-fined strategy language. 5.1 Unconditional Rewrite \nRules Revisited A labeled rewrite rule e : 1 -+ r translates to a strategy definition ! = {vars(l, r) \n: match(l) ; build(r)} It introduces a local scope for the variables vars(l, P) used in the rule, matches \nthe term against 1 and then builds r using the binding obtained by matching. 5.2 Subcomputation Many \ntransformation rules require a subcomputation in or-der to achieve the transformation from left-hand \nside to right-hand side. For instance, the inlining rule in Table 5 applies a substitution and a renaming \nto an expression in the right-hand side. Where The where clause is the basic extension of rewrite rules \nto achieve subcomputations. A rule e: 1 --t rwheres corresponds to the strategy ! = {vars(l, r, s) : \nmatch(l) ; where(s) ; build(r)} that first matches I, then tests s and finally builds r. The strategy \ns can be any strategy that affects the environment in order to bind variables used in r or just tests \na property of the left-hand side. Note that s can transform the original term, but the effect of t,his \nis canceled by the where. Only the side-effect of s on the environment matters. Boolean Conditions Conditions \nthat check whether some predicate holds are implemented as strategies using the where clause. Failure \nof such a strategy means that the condition does not hold, while a success means that it does hold. Predicates \nare user-defined strategy operators. Con-ditions can be combined by means of the strategy combina-tors. \nIn particular, conjunction of conditions is expressed by means of sequential composition and disjunction \nby means of choice. In such conditions we use the notation (s) t, which corresponds to build(t) ; s. \nFor instance, the encoding of the dead code elimination rule (Deadl) is: Dead1 : Let(Vdec(z, t, er), \nez) + er where -((in) (Var(z), ez)) ; (safe) er Where (in) (tl, t2) tests that tl is a subterm of t2 \nas defined before and safe tests that an expression is terminating and side-effect free. Matching Condition \nAnother kind of subcomputation is the application of a strategy to a term built with vari-ables from \nthe left-hand side 1, matching the result against a pattern with variables used in the right-hand side \nr. The notation s =+ t is a shorthand for s ; match(t ). The com-bined notation (s) t + t thus stands \nfor build(t);s;match(t ). It first applies s to t and then matches the result against t binding its variables. \nApplication in Right-hand Side Often it is annoying to introduce an intermediate name for the result \nof applying a strategy to a subterm of the right-hand side. Therefore, the application (s) t can be used \ndirectly in the right-hand side r. That is, a rule e: 1 -+ v-[(3) t] is an abbreviation of e : 1 -+ r \n[cc] where (s) t 3 z where z is a new variable. The notation t [t ] denotes a meta- context, i.e. a term \nt with a specific occurrence of a subterm t . The replacement by t of the subterm t in t is denoted by \nt [t ]. 5.3 Contexts A useful class of rules are those whose left-hand sides do not match a fixed pattern \nbut match a top pattern and some in-ner patterns which occur in contexts. For instance, consider the \n(Inline) and (Select) rules in Table 5. Contexts can also be implemented with the where clause. A rule \nwith a context c[-] occurring in the left-hand side and the right-hand side corresponds to the rule \n e: 1 [c]-+ r [c ] where (p({vars(l , r )\\vars(l [c], r [c ]) : match(?) ; build(r )})) c =S c where \nc is a fresh variable. The strategy in the where clause traverses the subterm matching c to find one \nor more occur-rences of 1 and replaces them with r . The result of the traversal is bound to c , which \nis then used in the right-hand side of the rule. Note that the variables of 1 and r are locally scoped \nexcept those common with the variables of 1 and r, since those are instantiated in 1 and/or used in r. \nThe strategy operator p that is specified in conjunc- tion with the contexts indicates the strategy used \nfor the traversal. This determines where and how often the rule is applied. As an example, consider the \nencoding of the (Select) rule: Se1 : Let(Vdec(z, t, ses), e[Select(i, z)]) + Let(Vdec(z, t, ses), e[(index) \n(i, ses)](sometd)) It uses the traversal strategy sometd to replace all occur-rences of Select(i,z) in \ne by the corresponding element of the record. The strategy index takes the i-th element from the list \nses of simple expresions. Using the encoding defined above this rule translates to the rule: Se1 : Let(Vdec(z, \nt, SW), e) + Let(Vdec(z, t, ses), e ) where (sometd({i : match(Select(i,z)) ; build((index) (i, ses))})) \ne 3 e Note that the variable i is local to the context traversal and can thus be instantiated to more \nthan one value. We have only discussed rules with one context. Rules with more than one context are beyond \nthe scope of this paper. 5.4 Variable Renaming An important feature of program manipulation is bound \nvariable renaming. A major requirement is to provide re-naming as an object language independent operation. \nThis means that the designer should indicate the binding con-structs of the language. This is done by \nmapping each bind- ing construct to the list of variables that it binds. For exam- ple, the following \nrules map the variable binding constructs of RML to the list of variables they bind. Bind1 : Let(Vdec(,x, \n-), -) + [x]; Bind2 : Letrec(fdecs, -) + (map({f : match(Fdec(, f, -, -)); build(f)})) fdecs Bind3 : \nFdec(, -, xs, -) -i xs Given these rules and a couple of additional rules for indi- cating in which arguments \nthe constructs are binding (see Appendix A) the strategy rename renames all bound object variables. This \nstrategy uses the built-in strategy new which generates fresh names. See Appendix D for its definition. \n6 Rules and Strategy for RML Rules Table 7 presents the specification of RML optimiza-tion. It consists \nof a signature, rewrite rules and strategy definitions. The signature defines the abstract syntax of \nthe object language of the optimizer. The rules section defines the individual transformation rules. \nThe strategies section defines two strategies for combining these rules into an op- timization algorithm. \nThe module imports several auxiliary modules that are defined in the appendices. Observe that the specification \nof the rules is very close to the original rules in Table 5. The main difference is that the inline rule \nhas been split into two rules. Rule In11 handles the case that the body of the function is small and \nhence can be inlined everywhere in the body of the Letrec. Rule In12 has no condition and replaces exactly \none occurence of an application of the function f in the body of the Letrec. To achieve the condition \nthat this rule should only be applied when f does not occur in the body of the Letrec after inlin-ing \nthe rule is always followed by an application of Dead2. If Dead2 succeeds this guarantees that f does \nnot occur any-more. Strategies An advantage of our approach of separating the specification of rules \nfrom strategies is the ability to experiment with alternative strategies for the same set of rules. We \npresent the strategies optimize1 and optimize2 for the RML transformation rules. In optimize1 and optimize2, \nwe have avoided applying EtaExp repeatedly since this rule is not terminating. Both optimize1 and optimize2 \nfirst apply EtaExp once every-where in the term. The strategy optimize1 uses the generic strategies innermost \nand manydownup (see Appendix B) to apply the rules. The strategy manydownup applies a strategy s at all \nposi- tions of a term once while going down into the term and once on the way back. It fails when none \nof these applications succeed. If it succeeds we know that some redex has been reduced. Hence, we can \nrepeat manydownup to normalize a term. While optimize1 uses generic strategies, optimize2 uses the properties \nof the rules in order to apply them in a more restricted way. It first tries to hoist a Let at the root. \nNotice that it repeats Hoist1 since it may reapply at the root, whereas Hoist2 cannot reapply after one \napplication. Then, only Let or Letrec expressions can be redexes. For each case there are specific rules \nthat can apply. This leads us to define a sub-strategy for each case and compose them non-deterministically. \nIn both cases we first normalize the body of the Let or Letrec expression. For a Let we try the rules \nProp and Se1 and then Deadl. For a Letrec, we first normalize the bodies of the functions of the Letrec \nexpression. Then we try In11 or In12 and if they succeed we try Dead2. Since inlining gives rise to new \nopportunities for optimization, we try to reapply the strategy to this term. 7 Implementation The strategy \nlanguage presented in this paper has been im- plemented in Standard ML. The programming environment consists \nof a simple interactive shell that can be used to load specifications and terms, to apply strategies \nto terms using an interpreter and to inspect the result. A simple inclu-sion mechanism is provided for \nmodularizing specifications. The current implementation does not yet implement the sort checking for \nrules and strategies. In addition to an interpreter, the programming envi-ronment contains a compiler \nthat generates C code. The compilation of non-deterministic strategies is reminiscent of the implementation \nof Prolog in WAM [l] using success and failure continuations and a stack of choicepoints to imple-ment \nbacktracking. The run-time environment of compiled strategies is based on the ATerm C-library [23]. It \npro-vides functionality for building and manipulating a term data-structure, reference count garbage \ncollection, a parser and pretty-printer for terms. An important feature is that full sharing of terms \nis maintained (hash-consing) to reduce memory usage. We have used the implementation to exper- iment \nwith the optimizer for RML discussed in this paper. No performance results are available yet. The compiler \nimplements a straightforward translation of strategy expressions to C programs that performs no optimizations. \nCurrently we are bootstrapping the com-piler by specifying it in the strategy language itself. This gives \nus the opportunity to apply optimizations to strategies. There are several levels of optimization we \nare considering: simplification of expressions by applying simple algebraic laws; factoring out common \nprefixes from the alternatives of choices; propagating knowledge about matching history through traversals. \nFinally, it is worth considering the au-tomatic derivation of more refined strategies by specializing \napplications of generic strategies to specific rules. An exam-ple would be to derive a strategy in the \nstyle of optimize2 from a strategy in the style of optimize1 in Table 7. An alternative approach to implementation \nof the lan-guage would be as a library of functions in a general pur-pose language, e.g., a functional \nlanguage such as ML or Haskell. For each operator in the core language a corre-sponding function is defined. \nIn fact, our interpreter uses such a library. The advantage of such an embedded imple-mentation is that \nwork on run-time environment and such can be borrowed from the host language. However, since a more general \nframework is used, the host compiler cannot take advantage of knowledge of the specific domain of term \ntransformation. Related Work Program Optimization There have been many at- tempts to build frameworks \nfor program analysis and opti- mization, often using special-purpose formalisms. The sys- tems closest \nto ours in spirit are probably OPTRAN [19] and Dora/Tess 1121. Like our system, these are based on ideas \nfrom term rewriting and emphasize separating the declar- ative specification of rewrite rules from the \nstrategy to be used in applying them. Unlike our system, however, they support only a fixed set of pre-defined \nstrategy options, and the same strategy must be used for all rules and for the whole tree. The options \nprovided by the two systems are similar: traverse the tree top-down or bottom-up; traverse children left-to-right \nor right-to-left; rewrite each node only once per traversal or iterate at each node until a fixed point \nis reached. Our strategy language can easily implement these options (e.g., in a general-purpose library), \nbut can also define much more fine-grained strategies where needed. Numerous other systems provide mechanisms \nfor gener- ating transformation code, but none appears to offer our flexible combination of generic and \nrule-specific strategies. DFA&#38;OPT-MetaFrame [18], Sharlit [25], Genesis [28], and OPTIMIX [5] are \nall primarily designed as analyzer gener- ator systems, each focused on a particular style of analysis. \nTheir published descriptions do not give many details about their transformation capabilities, but none \nappears to give the user any control over transformation order. At the oppo- site extreme, KHEPERA [ll], \nTXL 19, 211, and Puma 1151, provide succinct primitives for matching and building sub- trees, but for \nthe most part require that tree traversal be programmed explicitly in imperative style, node by node. \nTXL includes a searching version of the match operator which behaves like an application of our oncetd \nstrategy. KHEPERA provides a built-in construct to iterate over the immediate children of a node. Other \nrecent approaches to high-level description of opti- mizations include Aspect-Oriented Programming (1.61, \nwhich advocates the use of domain-specific aspect languages to describe optimization of program IR trees \n(in practice, LISP is generally used), and Intentional Programming [2], which provides a library of routines \nfor manipulating ASTs. Nei-ther of these approaches particularly encourages separation of rules from \nstrategies for their application. Strategies In conventional term rewriting languages, rewrite systems \nare assumed to be confluent and terminat- ing and therefore, strategies are only considered at the meta- \nlevel of language design and implementation. In particular, algebraic specification formalisms such as \nASF+SDF [lo] only provide one fixed strategy for normalizing terms with respect to a set of rewrite rules. \nA common work-around to implement strategies in such a setting is to encode a strat- egy into the rewrite \nsystem by providing an extra outermost constructor that determines at which point in the term a rewrite \nrule can be applied. In theorem proving such fixed strategies are not sufficient since a theorem can \nbe proved in many ways. The theorem proving framework LCF [14] introduced tactics for proving theorems. \nA tactic transforms a goal to be proved into a list of subgoals and a proof. By repeatedly applying tactics \na list of goals is reduced to the empty list, which indicates that the original goal is proven. A series \nof basic tactics are provided, including a simplification tactic that applies a set of rewrite rules \nusing a fixed strategy. New tactics can be formed from existing ones using tacticals. The standard tacticals \nare similar to our identity, sequential composition, left choice and repeat strategy operators, although \nthey have a somewhat different semantics since they apply to a subgoal instead of to the root of a term. \nIn the theorem proving domain there is no need for traversal tacticals. In the specification formalism \nELAN [17] the notion of transformation of goals to a list of subgoals is generalized to arbitrary term \nrewrite rules. Strategies are regular expres- sions over the set of rule labels. In 1171 this approach \nis used to define constraint solvers that consist of rules that rewrite a list of constraint into a new \nlist of constraints. A strategy repeatedly applies such rules until a solution is found. In later versions \nof the language, e.g., [7], the set of strategy operators is extended with congruence operators to support \nterm traversal. ELAN does not provide generic traversal operators anal- ogous to our i(s), Cl, 0 and \nE3. Instead traversals have to be defined explicitly for each datatype using congruences. Recursive strategies \nare expressed in ELAN using recursive strategy definitions. Further differences with ELAN are the negation \nand test operators and the breakdown of rules into primitives. Where ELAN has a fixed syntax for rewrite \nrules our strategy language can easily be extended with expressive features that are implemented in terms \nof the core language. Maude [S] is a specification formalism based on rewrit- ing logic. It provides \nequations that are interpreted with innermost rewriting and labeled rules that are used with an outermost \nstrategy. Strategies for applying labeled rules can be defined in Maude itself by means of reflection. \nThe language described in this paper was inspired by the strategy language of ELAN. The first version \nwas described in [20], which presents a strategy language with identity, se-quential composition, choice, \nrecursion, and a generic push- down operator that is used to define Cl and 1. Its design was guided by \nthe process algebra ACP [6]. An interpreter for strategy expressions is specified in the algebraic specifi-cation \nformalism ASF+SDF [lo]. Basic strategies are un-conditional ASF+SDF rewrite rules In this paper we have \nextended our first language with the operators failure, negation, test, path, congruence and 0. Furthermore, \nwe cater for a much more expressive set of rules by means of the breakdown of rewrite rules into match, \nbuild and scope. In addition, our current language is implemented by compilation to C. Technical contributions \nof our work in the setting of strategy languages include the modal operators El, 0 and q that enable \nvery concise specification of term traversal; a set general purpose traversal strategies; the explicit \nre-cursion operator pz(s); the refinement of rewrite rules into match and build; and the encoding of \ncomplex rewrite rules into strategies, in particular the expression of rules with con-texts. In [27] \nwe describe how our core strategy language can be used to implement conventional term rewriting engines \nand how these can be extended with non-standard evaluation strategies. nodule rml imports traversal imports \nlist imports substitution imports renaming imports rml-aux signature sorts TExp Vdec Fdec Se Exp operations \nFuntype : List(TRxp) * TExp -> TExp --Type expressions Recordtype : List(TExp) -> TExp Primtype : String \n-> TExp Vdec : TExp * String * Exp -> Vdec --Variable declarations Fdec : TExp * String + List(String) \n* Exp -> Fdec --Function declarations Const : TExp * String -> Se --Simple expressions k3.r : String \n-> Se Simple : Se -> Exp --Expressions Record : List(%) -> Exp Select : Int * Se -> Exp Paw : String \n* List(Se) -> Exp APP : Se * List(Se) -> Exp Let : Vdec * Exp -> Exp Letrec : List(Fdec) * Exp -> Exp \n :ules Ioistl : Let(Vdec(t, x, Let(vdec, el)), e2) -> Let(vdec, Let(Vdec(t, x, el>, e2)) Ioist2 : Let(Vdec(t, \nx, Letrec(fdecs, el)), e2> -> Letrec(fdecs, Let(Vdec(t, x, ei>, e2)> lead1 : Let(Vdec(t, x, el), e2) \n-> e2 where not(<in> (Var(x), e2>>; <safe> el )ead2 : Letrec(fdecs, el) -> el where <map(Cf : match(Fdec(-,f,-,-)I; \nnot(<in> (Var(f), el>>)>> fdecs 'rap : Let(Vdec(t, x, Simple(se)), eCVar(x)l> -> Let(Vdec(t, x, Simple(se)), \neke1 (sometd)) :n11 : Letrec([Fdec(t, f, xs, el)], ePCApp(Var(f), ss)l> -> Letrec([Fdec(t, f, xs, ei)], \ne2ksubs; rrename) (x8, 88, el>](sometd)> where <small> el Yn12 : Letrec([Fdec(t, f, xs, el)], e2[App(Var(f), \nsdl) -> Letrec([Fdec(t, f, xs, el)l, e2[<rsubs; rrename) (xs, ss, el>l(oncetd)> lel : Let(Vdec(t, x, \nRecord(ss)), e[Select(i, Var(x))l> -> Let(Vdec(t, x, Record(ss)), e[Simple(<index> (i, ss))l(sometd>> \n:taExp : Let(Vdec(Funtype(ts, t>, fl, el>, e2) -> Letrec([Fdec(Funtype(ts, t), fl, x8, Let(Vdec(Funtype(ts, \nt), f2, el), App(Var (f2), ses))>l, e2) where <safe> al; new => f2; <map(new)> ts => x8; Qnap(MkVar)> \nx8 => ses strategies 1pti = innermost'(Hoist1 + HoistSI; manydownup(((Inl1 <+ (In12; Dead21 + Se1 + Prop); \nrepeat(Dead1 + Dead2) <+ repeatl(Dead1 + Dead2111 Nptimizel = bottomup(try(EtaExp)); repeat(opt1) pt2 \n= ret x(repeat(Hoist1); try(Hoist2); try(Let(id, x1; try(Prop + Sell; try(Deadl; x) t Letrec(id, x); \n(Dead2 <+ try(Letrec(map(Fdec(id,id,id,x)),id); try((Inl1; try(Dead2) <+ In12; Deada); x))))) ptimixe2 \n= bottomup(try(EtaExp)) ; opt2 Table 7: Specification of RML transformation rules Conclusions We have \nillustrated how separating transformation rules from the application strategy can promote concise, under-standable \ndescriptions of complex rewriting tasks. Our ex-ample compiler optimizer takes about 50 lines; the corre-sponding \nhandwritten Standard ML code is several hundred lines. Moreover, we can completely alter the optimizer \ns rewriting strategy by changing just two or three lines, or add a new transformation rule and inserting \nits tag at the appropriate place in the strategy; similar changes to the ML version would require extensive \nstructural edits throughout the code. Although we concentrate on program optimizers in this paper, we \nbelieve that the techniques are equally well appli-cable in other areas where source to source transformations \nare used, including tion and software Acknowledgements sions that started didn t make it into simplification, \ntypechecking, interpreta-renovation. We thank Bas Luttik for the discus- our work on strategies. Several \nideas that [20] have been included here. The imple- mentation of the strategy language was speeded up \nconsid- erably by the use of Tim Sheard s programs for generation of C code and by the use of Pieter \nOlivier s ATerm library. We thank Eugenio Moggi and Philip Wadler for remarks on the semantics and Patricia \nJohann for remarks on a previous version of this paper. References Hassan Ait-Kaci. Warren s Abstract \nMachine. A Tuto- PI rial Reconstruction. The MIT Press, Cambridge, Mas-sachusetts, 1991. William Aitken, \nBrian Dickens, Paul Kwiatkowski, PI Oege de Moor, David Richter, and Charles Simonyi. Transformation \nin intentional programming. In Pro-ceedings ICRSS, June 1998. (To appear). Andrew W. Appel. Compiling \nwith Continuations. 131 Cambridge University Press, 1992. Andrew W. Appel and Trevor Jim. Shrinking lambda \n141 expressions in linear time. Journal of Functional Pro- gramming, 7(5):515-540, September 1997. Uwe \nAssmann. How to uniformly specify program anal- 151 ysis and transformation with graph rewrite systems. \nIn Proceedings Compiler Construction 1996, number 1060 in Lecture Notes in Computer Science, 1996. J.A. \nBergstra and J.W. Klop. Process algebra for 161 synchronous communication. Information I3 Control, 60:82-95, \n1984. 171 Peter Borovansky, Claude Kirchner, and Helene Kirch-ner. Controlling rewriting by rewriting. \nIn Jose Meseguer, editor, Proceedings of the First International Workshop on Rewriting Logic and its \nApplications, vol-ume 4 of Electronic Notes in Theoretical Computer Sci-ence, Asilornar, Pacific Grove, \nCA, September 1996. El- sevier. Manuel Clavel, Steven Eker, Patrick Lincoln, and Jo&#38; I81 Meseguer. \nPrinciples of Maude. In Jose Meseguer, edi-tor, Proceedings of the First International Workshop on Rewriting \nLogic and its Applications, volume 4 of Elec-tronic Notes in Theoretical Computer Scaence, pages 65-89, \nAsilomar, Pacific Grove, CA, September 1996. Elsevier. James R. Cordy, Ian H. Carmichael, and Russell \nHal- PI liday. The TXL Programming Language, Version 8, April 1995. [lOI A. Van Deursen, J. Heering, \nand P. Klint, editors. Language Prototyping. An Algebraic Specification Ap-proach, volume 5 of AMAST \nSeries in Computing. World Scientific, Singapore, September 1996. Rickard E. Faith, Lars S. Nyland, and \nJan F. Prins. WI KHEPERA: A system for rapid implementation of do- main specific languages, In Proceedings \nUSENIX Con-ference on Domain-Specific Languages, pages 243-255, October 1997. PI Charles Donald Farnum. \nPattern-Based Languages for Prototyping of Compiler Optimizers. PhD thesis, Uni-versity of California, \nBerkeley, 1990. Technical Report CSD-90-608. Pascal Fradet and Daniel Le Mktayer. Compilation of functional \nlanguages by program transformation. ACM Transactions on Programming Languages and Systems, 13(1):21-51, \nJanuary 1991. 1131 P41 M. J. Gordon, A. J. Milner, and C. P. Wadsworth. Edinburgh LCF. A Mechanised Logic \nof Computation, volume 78 of Lecture Notes in Computer Science. Springer-Verlag, Berlin, 1979. Joseph \nGrosch. Puma -a generator for the trans-formation of attributed trees. Technical Report 26, Gesellschaft \nfiir Mathematik und Datenverarbeitung mbH, Forschungsstelle an der Universitlt Karlsruhe, November 1991. \nP51 Gregor Kiczales, John Lamping, Anurag Mendhekar, W Chris Maeda, Cristina Lopes, Jean-Marc Loingtier, \nand John Irwin. Aspect-oriented programming. Technical report, Xerox Palo Alto Research Center, 1997. \nC. Kirchner, H. Kirchner, and M. Vittek. Implementing 1171 computational systems with constraints. In \nP. Kanel- lakis, J-L. Lassez, and V. Saraswat, editors, Proceed-ings of the first Workshop on Princzples \nand Practice of Constraint Programming, pages 166-175, Providence RI., USA, 1993. Brown University. P81 \nMarion Klein, Jens Knoop, Dirk Koschiitzki, and Bern- hard Steffen. DFA &#38; OPT-METAFrame: A toolkit \nfor program analysis and optimization. In Proceed-ings of the 2nd International Workshop on Tools and \nAlgorithms for the Construction and Analysis of Sys-tems (TACAS 96), volume 1055 of Lecture Notes in \nComputer Science, pages 418-121, Passau (Germany), March 1996. Springer Verlag. Peter Lipps, Ulrich Miincke, \nand Reinhard Wilhelm. PI OPTRAN -a language/system for the specification of program transformations: \nSystem overview and experi- ences. In Proceedings 2nd Workshop on Compiler Com-pilers and High Speed \nCompilation, volume 371 of Lec-ture Notes in Computer Science, pages 52-65, October 1988. Bas Luttik \nand Eelco Visser. Specification of rewriting PO1 strategies. In M. P. A. Sellink, editor, 2nd Interna-tional \nWorkshop on the Theory and Practice of Alge-braic Specifications (ASF+SDF 97), Electronic Work-shops \nin Computing, Berlin, November 1997. Springer- Verlag. Andrew Malton. The denotational semantics of a \nPI functional tree-manipulation language. Computer Lan- guages, 19(3):157-168, 1993. P21 Robin Milner, \nMads Tofte, Robert Harper, and David MacQueen. The Definition of Standard ML (Revised). MIT press, 2nd \nedition, 1997. Pieter Olivier. Term data-structure library -C API. [231 Programming Research Group, University \nof Amster- dam, 1997. (Unpublished software documentation.). S. L. Peyton Jones and A. L. M. Santos. \nA P41 transformation-based optimiser for Haskell. Science of Computer Programming, 1998. (To appear). \nP51 Steven W. K. Tjiang and John L. Hennessy. Sharlit-A tool for building optimizers. In ACM SIGPLAN \n92 Conference on Programming Language Design and Im-plementation, July 1992. P61 Andrew Tolmach and Dino \nOliva. From ML to Ada: Strongly-typed language interoperability via source translation. Journal of Functional \nProgramming, 1998. (To appear). I271 Eelco Visser and Zine-el-Abidine Benaissa. A core lan-guage for \nrewriting. In C. Kirchner and H. Kirch-ner, editors, Second International Workshop on Rewrit-ing Logic \nand its Applications (WRLA 98), Elec-tronic Notes in Theoretical Computer Science, Pont-8-Mousson, France, \nSeptember l-4 1998. Elsevier. PI Deborah Whitfield and Mary Lou Soffa. The design and implementation \nof Genesis. Software-Practice and Experience, 24(3):307-325, March 1994. A Auxiliary Strategies for RML \nThe module rml-aux defines the predicates small and safe. Furthermore, it defines the strategies rsubs \nfor substitution in RML expressions and rrename for renaming bound vari- ables in RML expresions. These \nstrategies are instantiations of the language independent strategies subs (Appendix D) and rename (Appendix \nE). module rml-aux imports substitution imports renaming strategies small = SimpleCid) + Record(id) + \nSelect(id, id) + Pappcid, id) + App(id, id) safe = not(oncetd(App(id,id) + match(Papp(\"assign\", ->))) \n rules IsVar : Var(x> -> x Mkvar : x -> Var(x> Bind1 : Let(Vdec(-,x,-),-) -> [xl Bind2 : Letreccfdecs, \n-1 -> <map({f : match(Fdec(-.f ,-,->I; build(f)))> fdecs Bind3 : Fdec(-,-,xs,-) -> xs PutVar : (f, Fdec(t, \nf', xs, e>> -> Fdec(t, f, xs, e> PutVars(nvs, nbnd) : fdecs -> <zip(PutVar; nbnd)> (fs, fdecs) where \nnvs => fs strategies rsubs = subs(IsVar) rn-apply(nvs, bnd, nbnd) = Let(Vdec(id, nvs; Hd, nbnd), bnd) \n + Fdeclid, id, nvs, bnd) + Letrec(PutVars(nvs. nbnd), bnd)  rrename = reneme(IsVar, MkVar, Bind1 + \nBind2 + Bind31 B Traversal Strategies In this and the next appendices we present three sets of generally \napplicable strategy operators. Note that all, one, and some stand for q i, 0, and q , respectively. module \ntraversal strategies try&#38;> = s <+ id repeat(s) = ret x(try(s; X)> repeatl(s) = s; repeat(s) bottomup \n= ret x(all(x>; s> topdown = ret x(s; all(x)> downup = ret x(s; all(x); s> oncebuts) = ret x(one (xl \n<+ s> oncetd(s) = ret x(8 <+ one(x)> somebu(s) = ret x(some(x> <+ s) sometd(s) = ret x(8 <+ some(x)) \n manybu(s) = ret x((some(x>; try(s)) <+ s) manytd(s) = ret ~((8; all(try(x))) <+ some(x)> manydownup(s) \n5: ret x((s; all(try(x)); try(s)) <t (some(x); try(s)>) alltdk) = ret x(6 <+ all(x)> reduce(s) = repeatcrec \nx(some(x> + s>> outermost(s) = repeat(oncetd(s)) innermost(s) = repeat(oncebu(s)) innermost'(s) = ret \nx(all(x); tryk; x1) in = {x,y: match((x,y)); test(<oncetd(match(x))> y) C List Strategies module list \nsignature operations Nil Cons rules Hd : Indl : Ind2 : strategies index map(s) at-tail(s) fetch(s) rules \ncone : : List(a) : a * List(a) -> List (a> Cons(x, xs) -> x (1, Cons(x, x6)) -> x h, Cons(x, xs>> -> \n(<minus> (n, where <geq> (n, 2) = repeat (Ind2) ; Indl = ret x(Ni1 + Cons(s, x1> 11, x8> = ret x(Ni1; \ns + Conscid, xl> = ret x(Cons(s, id) <+ Conscid, x>) (11, 12) -> <at_tail(build(l2))> 11 lookup(mklst) \n: x -> .v where mklst; fetch(match((x, y))) Zip0 : (Nil, Nil) -> Nil Zipl(a, b) : (Cons(x, xs), Cons(y, \nys)) -> Cons(<a> (x, y), <b> (xs, ys)) strategies zip(s) = ret x(Zip0 + Zipl(s, x1) D Substitution The \nstrategy subs(isvar), applied to a triple (xs, ts, t) of a list of strings xs, a list of terms ts places \neach occurence in t of a variable corresponding term in ts; The parameter should be a rule (or choice \nof rules) that resenting an (object) variable to its name. rule is of the form Vex(x) -> x. and a term \nt, re-x from xs by the strategy isvar maps a term rep- Typically such a The strategy first matches its \narguments. Then it zips together the string list and the term list to get a table tbl that associates \nvariable names with terms they have to be substituted with. (This fails if xs and ts are lists of dif- \nferent length, because zip will fail.) Finally, a traversal of the term t replaces each variable occuring \nin the table by its target. Note that the strategy alltd stops after it has found an application of its \nargument strategy. This is nec- essary to avoid applying the substitution to the terms being substituted. \nThis strategy assumes that bound variables are renamed such that no variable is bound twice. module substitution \nimports traversal imports list rules GetVar (mktbl) : x -> z where mktbl; fetch(match((x, z>>> strategies \nsubs (isvar) = {tbl, xs, ts, t : match((xs, ts, t)) ; <zip(id)> (xs, ts) => tbl; <alltd(isvar; CetVar(build(tbl)))> \nt 3 E Renaming The strategy rename(isvar, mkvar, bnd) renames all bound variables in a term to new variables. \nIt is param- eterized with strategies that express what the variables and the binding constructs of the \nlanguage are. The parameter isvar recognizes variables and maps them to their name. The parameter mkvar \nmaps a string to a variable. The pa-rameter bnd maps each binding construct to the list of vari- ables \nthat it binds. In addition, the user should specify the strategy operator m-apply (a, b, c) such that \nfor each variable binding con-struct a is applied to the subterm containing the variable(s) b is applied \nto the subterms in which the variables are bound c is applied to the subterms in which the variables \nare not bound. For an example, see Appendix A. module renaming imports traversal imports list strategies \nrename (isvar, mkvar, bnd) = Ct : match(t); build((t, [I)>); ret reni (11: It: match((t, 1)); build(t)); \nret ren2 (isvar ; lookup (build (1) > ; mkvar <+ cxs, ys, 1 : where(bnd s> xs; map(new) => ys; <cone> \n(<zip(id)> (x8, ys), 1) rn-apply(build(ys), {x: match(x); build((x, 1'))); Ix: match(x); build((x, 1))); \n<+ all(ren2)) 3) -> 1'); renl, renl))  \n\t\t\t", "proc_id": "289423", "abstract": "We describe a language for defining term rewriting strategies, and its application to the production of program optimizers. Valid transformations on program terms can be described by a set of rewrite rules; rewriting strategies are used to describe when and how the various rules should be applied in order to obtain the desired optimization effects. Separating rules from strategies in this fashion makes it easier to reason about the behavior of the optimizer as a whole, compared to traditional monolithic optimizer implementations. We illustrate the expressiveness of our language by using it to describe a simple optimizer for an ML-like intermediate representation.The basic strategy language uses operators such as sequential composition, choice, and recursion to build transformers from a set of labeled unconditional rewrite rules. We also define an extended language in which the side-conditions and contextual rules that arise in realistic optimizer specifications can themselves be expressed as strategy-driven rewrites. We show that the features of the basic and extended languages can be expressed by breaking down the rewrite rules into their primitive building blocks, namely matching and building terms in variable binding environments. This gives us a low-level core language which has a clear semantics, can be implemented straightforwardly and can itself be optimized. The current implementation generates C code from a strategy specification.", "authors": [{"name": "Eelco Visser", "author_profile_id": "81100561215", "affiliation": "Pacific Software Research Center and Dept. of Comp. Science and Engineering, Oregon Graduate Institute, P.O. Box 91000, Portland, Oregon", "person_id": "PP43121329", "email_address": "", "orcid_id": ""}, {"name": "Zine-el-Abidine Benaissa", "author_profile_id": "81100182896", "affiliation": "Pacific Software Research Center and Dept. of Comp. Science and Engineering, Oregon Graduate Institute, P.O. Box 91000, Portland, Oregon", "person_id": "P310311", "email_address": "", "orcid_id": ""}, {"name": "Andrew Tolmach", "author_profile_id": "81100247872", "affiliation": "Pacific Software Research Center and Dept. of Comp. Science and Engineering, Oregon Graduate Institute, P.O. Box 91000, Portland, Oregon and Dept. of Comp. Science and Engineering, Oregon Graduate Institute, P.O. Box 91000, Portland, Oregon and Dept. of Computer Science, Portland State University, P.O. Box 751, Portland, Oregon", "person_id": "P18423", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/289423.289425", "year": "1998", "article_id": "289425", "conference": "ICFP", "title": "Building program optimizers with rewriting strategies", "url": "http://dl.acm.org/citation.cfm?id=289425"}