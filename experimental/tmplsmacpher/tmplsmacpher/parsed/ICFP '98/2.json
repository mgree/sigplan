{"article_publication_date": "09-29-1998", "fulltext": "\n Higher-Order Arity Raising John Hannan Patrick Hicks* Department of Computer Science and Engineering \nSt. Vincent Archabbey The Pennsylvania State University 300 Fraser Purchase Road University Park, PA \n16802 Latrobe, PA 15650 Abstract Arity raising, also known as variable splitting or flattening, is the \nprogram optimization which transforms a function of one argument into a function of several arguments \nby de-composing the structure of the original one argument into individual components in that structure. \nThis optimization eliminates the need for the structuring of the components and also allows more arguments \nto be passed in registers during a function call. We present a formal specification of arity raising \nfor a higher-order functional language. This specification supports the general arity raising of functions, \neven for functions which are passed as arguments or returned as values. We define a practical algorithm, \nbased on al-gorithm W, which implements arity raising, and we prove this algorithm sound with respect \nto the deductive system. These results provide a declarative framework for reasoning about arity raising \nand support a richer form of the trans-formation than is currently found in compilers for functional \nlanguages. Introduction Arity raising is the transformation of a function of one ar-gument into the function \nof multiple arguments obtained by destructing the original argument into smaller components. For example, \na function of one argument of type (int x int) can be arity raised to a function of two arguments, each \nof type int. For a language like Standard ML, in which all functions take exactly one argument, the construction \nof ac- tual parameters into pairs and the destruction of pairs into individual components provide unnecessary \noverhead. Ar-ity raising is an optimization which removes this overhead, but it also modifies the protocol \nfor passing arguments to a function. Work performed while at Penn State University Traditional approaches \nto arity raising have been based on ad hoc and relatively simple techniques. Because of this, its use \nhas previously been limited to first-order functions in which all of a function s call sites can be easily \ndetermined. In higher-order languages, the ability to pass a function as an argument and return a function \nas a value greatly com-plicates the task of determining all the call sites of a given function. Such \na task is required if arity raising is to be applied to higher-order functions and their arguments. We \nrefer to arity raising of such functions as higher-order ar-ity raising. We give a formal, declarative \nspecification of higher-order arity raising which provides a setting for rea-soning about the transformation \nand a basis for constructing efficient algorithms. We define a deductive system for a higher-order, func-tional \nlanguage, providing a general description of higher- order arity raising. We model our approach after \nthat used in the specification of type inference for functional lan-guages, but in addition to type inference, \nthe specification also relates a source term with an arity-raised form of the term. We introduce intermediate \ndata structures and types which support the translation. The specification is declara- tive and non-deterministic, \npossibly relating a single source term to many arity-raised forms of that term. Towards a more algorithmic \nspecification, we then give an alternative specification using a two-level meta-language. This specifi- \ncation separates the processes of inferring types and trans-lating the terms. We also give an algorithm, \nbased on Mil- ner s algorithm W [12], which performs the translation. We demonstrate how our algorithm \nworks for several illustrative examples. We implemented this algorithm in Standard ML and tested it on \nthese and other, more complicated exam-ples. We prove the correctness of the deductive system with respect \nto operational semantics for the source and target languages. This work continues our effort to use formal \nsystems to specify and verify compilation techniques for functional lan-guages. In previous work we studied \nclosure conversion [7], escape analysis [8], uncurrying [9], and live variable analysis [lo]. These works \nall have in common the use of deductive systems to specify program analyses and properties, the use of \nthe LF type theory to represent these systems and proofs about these systems, and the use of the Elf \nprogramming language to provide experimental implementations and to provide machine verification of proofs. \nThe current work is closely related to our work on uncurrying. Many of the techniques developed in that \nwork applied to the present work, though arity raising proved more difficult -arity rais- Xx.e Vs Xx.e \nel Vs X2.e e2 Lfg v2 e [v2/x] v, v el @ e2 v3 v el v, VI e2 v, v2 (0, e2) 9, (WI, ~2) e vs (VI, v2) e \nvs (~1,212) fst e V, 2rl snd e vs 212 Figure 1: Source Operational Semantics X[Xl,. , Xk].rl vt X[x,, \n,x,].m 'rn vt X[xl,...,xk].m' m, Vt Wifor i E [l..k] m [Wl/Xl,. , Wk/Xk] vt W mQ[ml,...,mk]Vtw ml vt \n201 m2 vt w2 (ml, m) vt (WI, ~2) m vt (~1, ~2) m vt (~1, w2) fst m vt WI snd m vt w2 Figure 2: Target \nOperational Semantics ing requires the introduction of new variable names and the static reduction of \nprojections. The introduction of a two- level language to support the latter operation is new to this \ne . . - x 1Xx.e 1el Q e2 1 (el,e2) 1fst e 1snd E work. m 1: = x 1 x[xl,. , Xk].m ( m0 Q [ml,. ,mk] The \nremainder of the paper is organized as follows. In the next section we introduce source and target languages, \n(ml,mz) 1fst m I snd m both based on the typed X-calculus. We give high-level op- erational semantics \nfor both languages. In Section 3 we In a term X]zr,. , zk1.m we require all the zCEto be distinct, define \narity raising via a deductive system which relates a In the target language, abstractions and applications \nhave term with an arity-raised form. We give several illustra-an arity k > 1. If k = 1 then we may simply \nwrite Xx1.m tive examples of the capabilities of this system. We also and mo 0 ml. We refer to [Xl,. \n,Xk] and [ml,. ,mk] as introduce an alternative specification which uses a two-level parameter lists \nand operand lists, respectively. (These lists meta-language to separate the type inference phase from \nthe should not be confused with general list expressions.) translation phase. In Section 4 we discuss \nthe correctness of The types of the source language are the traditional sim- the deductive system with \nrespect to the type systems and ple types, and the types of the target language extend sim-operational \nsemantics of the source and target languages. In ple types by allowing a list of parameter types in a \nfunction Section 5 we present an algorithm for arity raising based on type. We let 4 and @ range over \nsource types and target Milner s algorithm W and outline the proof of its soundness. types, respectively. \n(We assume the same set of base types In Section 6 we compare our results with related work and L for \nboth languages.) in Section 7 we conclude with a discussion of future work. 2 Two Typed Languages Our \nspecification of arity raising is given as a relation be- tween programs in a source language and a \ntarget language. we drop the superscripts from types when it can be inferred Both these languages are \nbased on the typed X-calculus. The from context. source language is the typed A-calculus with pairs and \npro-We define an operational semantics for each of these lan-jections, while the target language generalizes \nupon this to guages by axiomatizing judgments of the form e vs u and permit functions with a list of \narguments and applications m vt 20. To provide a high-level description for these se-in which the operand \nis a list of expressions. We let e and m mantics, we use variable substitution rather than environ-range \nover source and target language expressions, respec-ments to manage the binding of variables to values. \nThus, tively. The following grammars define the syntax for these in both languages, values are limited \nto X-abstractions and languages. pairs of values. This simplifies correctness proofs. The rules are given \nin Figures 1 and 2. ~:r cih : r 4: r [$I, , b] + 4 : r $1 : r 42 : r 41 : c 42 : c $4 X 4%: r 41 c3 \n42 : c b:r c$:c Figure 3: Kinding System 3 Formal Specification of Arity Raising We give a formal specification \nof the arity-raising transfor-mation as a deductive system which axiomatizes a relation between a source \nterm, a type, and a target term (an arity- raised form of the source term). To avoid algorithmic details \nwe define a non-deterministic system which can relate a sin- gle source term to many possible arity-raised \nforms of the term. The inference rules follow the structure of a tradi- tional type system for simple \ntypes, but they also contain information specific to arity raising. 3.1 Preliminaries To facilitate \nthe presentation of the formal system we first introduce kinds, an extension to the target language types \nand terms, and a kinding system for these extended types. - K - cl r - m -I (ml,mz) q? :: = ,.. 1 &#38;@c$ \nWe use kinds to distinguish between compile-time ( c ) and run-time ( r ) types, and this use is based \nupon the two-level type system of Nielson and Nielson [15, 16, 171. The term (mi,mz) is called a tuple \nand represents an intermediate data structure which, during the process of arity raising, will either \nbe reduced to an operand list or be reduced via projections. We use the new type constructor 8 to denote \nthe types of tuples. We introduce a judgment 4 : K. to characterize target types as either compile-time \nor run-time. The axiomatiza-tion of this judgment is given in Figure 3. This kinding sys-tem serves multiple \npurposes, but its essential contribution is restricting the occurrences of the type constructor 8. In-formally, \nwe can motivate these rules as follows. All of the original target-language types are of kind r (and \nso are all types contained within them). The type (41 8 42) has kind c and its components are also of \nkind c. Observe that any run-time type can be considered a compile-time type, but not vice-versa. This \nallows any type to appear (in a typing derivation) where a compile-time type is required, but only run-time \ntypes can appear where they are required. For a tuplc (with a compile-time type) to appear as a subterm \nof a term with type of kind r, this tuple must be in a context where a sufficient number of projections \nare applied t,o it, to construct a term with a type of kind r. As a con. we write c$ as an abbreviation \nfor $J : K. The superscrip, ., should not be considered an annotation on the type 4. m : d =5 [m] : [c#J] \n(ml, mz) : $1 ~3 $2 % append(msl, msz) : append(4sl, 41s~) Figure 4: Flattening System Next we axiomatize \na simple judgment for reducing terms of the form (ml, mz) to lists of terms. The judgment is m : 4 3 \nms : 4s and is axiomatized by the rules in Figure 4. This judgment describes the flattening of (possibly \nnested) tuples (with a type of kind c) into a list (either an operand list or a parameter list), in which \neach list element has a type with kind r. Flattening provides the means to translate a tupled operand \ninto an operand list, e.g., ((mi,m;?) , rns) into [ml, mz, ma]. It also provides the means for generating \nthe parameter list of a function.  3.2 The Inference System Finally, we axiomatize a judgment for arity \nraising. This judgment, e : 4 + m, is given by the rules in Figure 5. As with the operational semantics, \nwe avoid using an explicit type context in the judgment. Instead we use hypothetical assumptions (via \nlogical implication) to introduce assump-tions about variables. Observe that this implies that we do \nnot require a rule for handling variables. The first two rules treat pairs. The kinding on the types \ndetermines whether a pair is translated into a pair or a tu- ple. The next four rules treat projections. \nProjections on a tuple are reduced while projections on a pair are recon-structed. Note that these rules \nallow expressions of the form fst(el, ez) to be translated to ml, provided (ei, ez) translates to (ml, \nm2). This is not the intended purpose of statically reducing projections (and could lead to a change \nin the be- havior of programs). We will eventually discard derivations which involve such reductions. \nThe next rule treats appli-cations. The type of the operator must have kind r, which forces the parameters \nto all have kind r. The kind of the operand is c and the term m is a single term, possibly a tunle. The \nflatten Yiudement relates this term to a list of terms, based on the structure of the term and its type \n4 . The tvnes of the terms in the operand list must match the .,I types of the variables in the parameter \nlist. Because these all have kind r (as enforced by the flatten judgment), none of the corresponding \nterms are tuples. The final rule treats X-abstractions. The kinding specifi-cation on the types ensures \nthat the type of the abstraction is well-kinded. The meta-variable ys stands for an interme- diate term \nconsisting only of the tupling of unique variables. This restriction on the instances of ys is actually \nenforced by the flattening judgment and the occurrence of the list [yi, , yn] as the parameter list in \nthe translated function. The rule can be read as follows. If, under the assumption that y of type 4 translates \nto the tupling of variables ys, e of type $J translates to m, and furthermore, if ys of type 4 flattens \nto the list [yi, , yn] with corresponding types 141, ,&#38;I, then Xy.e translates to X[yi, , y,].m of \ntype LPI> , ft>,,] -+ 4. In the assumption we need y to translate to a structured t,uple of variables \n(and not simply a list) so that during the translation of the body e the projection functions originally \napplied to y (in e) can be properly re-duced to some yi (in m). The structure of the inference rules \nensures that any occurrence of y in the body of the original function is in a context in which enough \nprojections are applied to it to correspond to some yi. For example, an assumption of the form el : q$ \n(el,e2) * ml : 41 842 e2 : &#38; * (ml,m2) * mz el : 4: (el,e2) =+ ml : 41 x 42 e2 : q5: * * (ml,m2) \nm2 e : (41 @ 452) * (ml, (fst e) : 431 *ml m2) e : (41 @ (snd 42) * (ml,m2) e) : $9 =+ m2 e : (41 (fst \ne) x $2) * : $1 * (fst m m) e : (41 x 42) (snd e) : $2 j * m (snd m) el : ([h,. ,&#38;I --+ 4) * m e2 \n: (4 ) * m e10e2:~~mQ[ml,...,mn] m : 4 S- [ml,. , m,] : [$I,. , (bn] y : (4 ) * ys 3 e : qb =+ m Xy.e \n: [h,. . ,&#38;I Y~4 ~[Yl,. ., + d * X[yl, . . . ,yJ.m yn]:[h , .., 4n] Figure 5: The Arity-Raise Inference \nSystem Y : (41 @ (42 Q9 43)) * (Yl, (Y2, Y3)) can be used to derive the judgment fst (snd y) : 42 + \n~2, and the flattening of (yr, (yz, ya)) yields the parameter list [yi, ys, ys]. Note that the term ys \nmust be chosen carefully to ensure that no occurrences of tuples remain in m, the translation of the \nbody of the function. The kinding 4 : r (and the structure of the entire inference system) guarantees \nthis. This inference system provides a general specification of arity raising. For a given source term \ne, there may exist several &#38;, rni such that e : 4; =+ mi. Included among these is one in which no \narity raising occurs. Our goal in designing an algorithm based on this specification is to produce a \nterm m with as much arity raising as possible. However, if we do not know the context of e (say, for \nexample, during separate compilation) then we must require a translation e : r + m in which m and I$ \nare restricted to the original target language (hence, they contain none of the extensions introduced \nat the beginning of this section). This ensures that the translated term m can be used in the same context \nin which e can be used. The kinding system and its use in the arity-raising sys-tem provide essential \nconstraints to ensure the proper rela-tionship between terms in the two languages and the rea-sonable \nformation of types. Observe that types of the form ((&#38; @ c$~) x +a) are not well-kinded. A compile-time \ntype cannot occur inside a run-time type. Furthermore, the re-quirement in the inference system that \ncertain types have kind r ensures that a translated term with a type of kind r has no occurrences of \ntuples in it. More formally, we have the following theorem. Theorem 1 If e : r#~ + m and 4 : r then m \ncontains no tuples.  3.3 Examples We present here several small examples to illustrate the transformations \nderivable using the arity-raising inference system. For convenience we assume some terms ei such that \nei : c#$ j mi, for i E [1..5]. (Xz.fst z) 0 (el, e2) : $1 * (Xk.k Q (el,ez)) Q (Xz.fst (Xk.k 0 [ml, m2]) \n(Xy.((Xz.snd(fst x))(y,es)))(el,ez) All of the following are derivable. (+I, 221.21) 0 [ml, mz] z) : \nq!q * @I X[z1,22].21 : 42 * (~[~1,~21.((~[~1,~2,~3l.sl) I~l,~z,msl)) bl,mzl (Xy.(fst y) (snd y)) (Ap.(snd \nP, fst p), (el, e2)) : 42 x 41 * (~[Yl,Y2,Y3]~Yl[Y2~Y3])(~~l,P2].(P2,Pl),ml,m2) As observed above, some \ndeductions allowed by this sys-tem perform static reductions of projections applied to pairs existing \nin the source term. For example, a term of the form fst(1, e) can be translated to just 1. For non-terminating \nex-pressions e, such a static reduction does not preserve the meaning of the original expressions and \nso we would like to prohibit such deductions. Alternatively, we can characterize the set of deductions \nwhich only statically reduce projections applied to a function parameter. We can do this by restrict- \ning the use of the rule which translates a pair into a tuple to apply only to operands or values. This \nrequires a precise notion of operand. Deflnition 1 (Operands) A term eu is an operand in e if it is a \nsubterm of e and it occurs in a context 1. (e'eo) for some e'; or 2. (es, e ) for some e in which (eo, \ne ) is an operand; or 3. (e ,ee) for some e in urhich (e ,es) is an operand.  r-r 71 : c 72 : r 71 \n-+ 7-z : r r1 : r 7-z: r Tl : c rz : c 71 x 72 : r rlxrz : c r:r T:c Figure 6: Kinding System for Two-Level \nTypes An operand term is either the direct operand of an applica- tion or a subterm (involving pairs) \nof an operand. Observe that an operand cannot be the argument of a projection. Definition 2 (Values) \nA value e is either a X-abstraction 0~ a pair (el, ez) in which both el and e2 are both values. Values \nare precisely those expression which can be the result of evaluation in the source-language operational \nsemantics. (We would extend this definition given a larger language including, for example, constants;) \nDefinition 3 (Valid Deductions) A deduction Z of e : 4 + m is valid iff for all sub-deductions with conclusion \n(el,e2) : (41 8 42) * (ml,m2) (for any el,ez,#l,$~z,ml,m2), either (el,ez) is an operand in e or el and \ne2 are both values. Valid deductions exclude sub-deductions in which, for example, an expression fst \n(el, e2) can be arity raised to the translated form of el. We use the notion of valid deduction in Section \n4 when we discuss the operational correctness of the arity-raising specification.  3.4 A Two-Level Presentation \nFor an alternative specification of arity raising, we can intro- duce a two-level intermediate language \nand use it during the translation from source to target languages. Observe that the original system provides \ntwo general services. First, it describes a typing system, similar to the standard simple type system. \nSecond, it describes a translation from inter-mediate forms to lists of parameters and arguments. We \ncan separate these two descriptions to yield simpler specifi-cations. The introduction of these new systems \nserves mul-tiple purposes. First, it provides a step towards our algo-rithm which contains two distinct \nphases. Second, it pro-vides a specification more suitable for reasoning about type correctness. The \noriginal system, however, is more suitable for reasoning about operational correctness. Thus, both the \noriginal specification and the one introduced here are useful. We begin by introducing a two-level version \nof the source language. This approach follows that of [15], where the pur- pose there was to distinguish \nbetween compile-time and run- time operations. Our two-level language and types are sim- pler than theirs, \nas we only need focus on compile-time pairs and projections, and not functions and applications. m =5 \n[m] ml =S msl m2 S ms2 (ml, mz) % append(ms1, msz) - c st (41 x$2) * (YS,, YS2) Figure 7: The Structuring \nand Flattening Systems 7 . . --Ll7-t7lTXTITTTT Next we introduce a kinding system for two-level types. \nThis system is given in Figure 6. Observe that in this kinding system the argument type of a function \ncan have kind c. For convenience, we define the new judgments with con-texts. This provides a representation \nmore suitable for relat- ing to the type systems of the two languages. (Note that we can straightforwardly \nmodify the inference system of Fig- ure 5 to use a context which maps variables y to a pair (4, ys).) \nWe introduce the auxiliary judgments u &#38; us and 4 4 ys for flattening tuples and generating tuplings \nof vari- ables based on a type, respectively. (See Figure 7.) For the two-level specification of arity \nraising we introduce the judgments I D2 e : 7- + u and H D2 u + m. (See Figures 8 and 9.) The context \nI? maps variables to two-level types and the context H maps variables to tuplings of variables. Observe \nhow these two contexts together simulate the one context required by the original inference system. This \ntwo-level system provides a clean separation be-tween the type inference process (identifying which pairs \nshould become tuples, for example) and the translation pro-cess. 3.5 Equivalence of the Two Systems \nWe can demonstrate the equivalence of the two specifica-tions of arity raising by first introducing a \nvariant of the original one which uses contexts, then defining a relation- ship between the various contexts, \nand then reasoning by induction over the structure of derivations. The introduction of explicit contexts \nto the original sys-tem is straightforward. Let 0 denote a partial mapping from variables to pairs of \nthe form (4, ys) in which C$ is a target language type and ys is a tupling of variables. The new judgment \nis of the form G D e : cj a m. Note how the con-text replaces the assumptions introduced by the X-rule \nin the original system. l?(x) = 7 rDzx:rJx r D2 el : 7-f * UI r ~~ e2 : r: * u2 r ~~ (el, e2) : (717~2) \n* (ul, uz) r Dz el : r: * UI r ~~ e2 : 7; a u2  r D2 (el,e2) : (~1 X 2t) * (ul,w) - rD2e: (T~XTZ)~*U \nr Do e : (~-~X72) * u rD2(fst e):q=k(Gu) l? ~~ (snd e) : 72 a (snd IL) r ~~ e : (TV x ~22)~ * u r DZ \ne : (71 X 7~)~ * U r D2 (fSt e) : 71 + (fst u) r [>2 (snd e) : 72 =P (snd u) r D2 el : (71 + 7~)~ + \n'U1 r Dz e2 : 71 * u2 r ~~ el @ e2 : 72 * ul Q u2 riy : T:} ~~ e : 7; * 21 r ~~ Xy.e : ~~ -+ 72 * Xy \n: T~.U Figure 8: The Inference Phase H(Y) = YS HD2y*ys HDzul *ml H DZ uz a mz H DZ 2~1 =+- ml HD2u2+m2 \nH DZ <UI, UZ) + (ml, mz) H DZ ( 111, UZ) * (ml, mz) HDzu=S-(ml,mz) HD~u+(ml,m2) H Dz (Eu) =2 ml H Dz \n(snd u) + mz HDzu=km HDzu+m H Dz (fst u) =a (fst m) H ~~ (snd u) =F (snd m) H DZ UI + ml H D2 UQ + m2 \nHD2m2 4,: HDzul @uz *ml am , cpc4 ys H{y b-b ys} DZ u + m ys Ji [Yl>...,Y?ll H D2 xy : 4.u =+ x[yl, . \n, y,].m Figure 9: The Translation Phase To facilitate the comparison of these systems (and their type \nsystems in the next section), we give a translation from two-level types to both source and target language \ntypes. Definition 4 For every kinded, two-level type 7, its corre-sponding source type, Ir.j, and correspondzng \ntarget type I)TII, are gzven by: 111= L 17-l + T2l = IT11 + 1721 In x 721 = InI x lrzl 171X7iI = IT11 \nx lrzl IILII = 1 1171--f 7211 = -+ IIQII 11~111 b-1 x rzll = Il~lll x lbll 1171~7211= @ II7211 11~111 \n We extend this definition to type contexts in the natural way: if r(x) = r then III(x) = 171 and IlIYll(x) \n= llrll. Definition 5 The context G and contexts I and H are equivalent, written 6 E I, H, iff for all \nx, 1. zf G(x) = (4, xs) then there exists some r such that l?(x) = 7, H(x) = xs, and llr[( = I$; 2. \nif I (z) = r and H(x) = zs then there exists some $J such that G(x) = (4, xs) and ~~r~~= $.  Theorem \n2 If 6 E T , H then 1. G D e : C$ + m implies there exist u and r such that l? D2 e : r 3 U, H Dz u + \nm, and ~~r~~= $J; 2. I I>2 e : T + u and H DZ u + m implies there exists a 4 such that 4 De : 4 + m \nand Il~ll = 4.  The proofs of both parts are straightforward by induction on the structure of deductions. \n4 Correctness We briefly outline some correctness issues of our arity-raising inference system. We consider \nits relation to the type sys-terns and operational semantics of the source and target languages. 4.1 \nType Correctness We show that this system derives judgments over exactly the terms typable in these two \nsystems. Additionally, we show that every typable source term can be related to some target term. Let \nI Ds e : c#? and I Dt m : C$ be the judgments for typing expressions in the two languages. In both cases, \nI is a type context, mapping term variables to types (in the appropriate language). The axiomatizations \nof these two judgments are straightforward and not given here. Theorem 3 (Type Completeness) If I? Ds \ne : 4 then there exists a target term m such that I D e : 4 + m. The proof follows by constructing a \ndeduction which per-forms no arity raising. Thus, every typable source term can be related to some target \nterm. We additionally have that the arity-raising inference sys-tem relates only terms typable in their \nlanguage s type sys-tems Theorem 4 (Type Correctness) If I D2 e : r + u and H Dz u + m then II / D, e \n: 1~1 and llI ll Dt m : Il~ll. 4.2 Operational Correctness To demonstrate the correctness of the inference \nsystem with respect to the operational semantics, we prove a general statement which accounts for intermediate \nvalues which are tuples. To accomplish this, we first extend the target oper-ational semantics with a \nrule for treating tuples: ml 5 WI m2 -h w2 (ml,mz) *t (w1,wz) Theorem 5 (Operational Correctness) 1. \nIf E is a valid deduction of e : 4 + m and e it, v then there exists a term w such that m oft w and v \n: 4 + w; 2. IfE as a valid deduction of e : C$ + m and m +t w then there exists a term v such that e \n~t~ v and v : 4 =+ w.  The restriction to valid arity-raising deductions prohibits, as suggested above, \nthe static reduction of projections which might eliminate non-terminating expressions. Valid deduc-tions \ninvolve only the reduction of projections applied to tuples of parameters or values. Instead of restricting \nthe set of deductions to valid ones, we could possibly have incor-porated the restrictions of validity \ninto the inference system for arity raising. This approach seemed to complicate the structure of the \nsystem and also complicate reasoning about it. The current presentation supports a reasonable explana-tion \nfor the correctness of the inference system and also of the algorithm introduced in the next section. \n5 An Arity-raising Algorithm We have developed an algorithm for arity raising based on the inference \nsystem presented in Figures 6, 7, 8, and 9. This algorithm is similar to algorithm W for type inference \non simple types, and similarly has a running time propor-tional to the size of the input term. We implemented \nthis algorithm in Standard ML, tested it using all the examples presented in this paper as well as other \nsmall, demonstrative test programs. For the purpose of establishing and solving constraints on annotated \ntypes and kinds, we extend the grammars for these types and kinds to include type and kind variables: \n-  r; -clrl-~ 7 ::= TX,7-T-+Tlp,IL Observe that we annotate type variables with kinds. WC require \nthis because at some point during the algorithm, we may not know anything about the type of a term except \nthat its kind should be r. In this case we might give the type /3r to the term, where ,O is a new type \nvariable. (The algorithm will require that any type later substituted for p occur within a function type \nin r. The result of grndtp(-r) is also have kind r.) At several points the algorithm specifies a substitution \n0 such that 07 : r. the introduction of a new variable &#38;. In every case, we assume that both p and \ny are new variable names. We let 0 range over substitutions, mapping annotated type and kind variables \nto annotated types and kinds, re-spectively. We let Bc be the substitution which maps all annotation \nvariables to c. The algorithm ensures that all substitutions are idempotent. It also disallows cyclic \nrefer-ences by using an occurs check in the unification algorithm. We introduce annotated terms, similar \nto the two-level terms introduced in Section 3. These terms contain kind an-notations on pairs and projections. \nAdditionally, the bound variable of a lambda abstraction is explicitly tagged with its annotated type. \nu :: = x I u 0 u I Xx:r.u I (u, u), I fst, u 1 sndn u Like the two-phase inference systems, the arity-raise \nal-gorithm ar consists of two steps, W and translate: ar(e) = let (tV,~,u) = W ([],e) in translate([],&#38;(&#38;)) \nThe first step involves type inference and kinding. In this step, similar to algorithm W, the function \nW takes a type environment (mapping source term variables to anno-tated types) and a source term and \nreturns a triple (0, 7, u) consisting of a substitution 0, an annotated type r, and an annotated term \n1~. (See Figure 10.) In addition to per-forming the usual type inference, this step also generates constraints \non kind variables annotating terms and types. More specifically, when the algorithm finds a pair which \nis not an operand, it produces a pair and a product type with annotations r. Unification will propagate \nthis information to other parts of the program (just as with traditional type inference) to ensure that \nthis annotation is consistent with the rest of the program. Note that the function W never explicitly \nsets kind variables to the value c. We can assume that any kind variable not bound to r can be bound \nto c. Intuitively, the function W detects where arity raising can-not occur. In all other places (involving \npairs), it can occur. This observation justifies the use of the substitution Bc. In the second step, \nthe function translate takes an an-notated term and transforms argument pairs and parame-ter variables \ninto operand lists and parameter lists wherever possible, as indicated by the kinds on terms. (See Figure \n12.) The function translate also reduces occurrences of fstc and sndc, all of which will be applied to \ntuples. The function W consists of six cases corresponding to the structure of the source term. The variable \ncase fails if the variable is not in the domain of r, but otherwise the variable s type is found in l?. \nThe abstraction case generates a new type variable &#38; for the bound variable and infers the annotated \ntype and term for the body. The return type of the abstraction is then given a kind r, indicating that \ntuples cannot be return values of functions. This is done by calling the function grndtp on the return \ntype of the function. The function grndtp takes a type r and returns a substitution mapping all top-level \nannotations in r to r. (See Figure 11.) An annotation occurs at the top-level in a type if it does not \nThe application case is similar to the one found in algo- rithm W, with unification used to ensure that \nthe types of operator and operand correspond. Because the operand may be a pair which is to be arity \nraised, this case uses the func- tion W arg to process the operand e2. The function W arg recursively \ndescends through operands (pairs), constructing pairs annotated with fresh annotation variables. When \nan operand other than a pair is found, W arg simply calls W . Note that this corresponds to the notion \nof maintaining a valid deduction in which no tupling of pairs occurs other than in operands. In the case \nfor pairs, W is called recursively on the two subterms and the corresponding annotated product type is \ngiven a kind r by the function grndtp. This ensures that the pair will not be translated into a tuple, \ncorresponding to the restriction of valid deductions. In the case for fst, the sub- term is typed and \nunified with an annotated product type. The resulting annotation on the product is then attached to the \noutput fst constructor. The case for snd is handled similarly. The function unify takes two annotated \ntypes and returns the most general substitution which unifies the annotated types. (See Figure 11.) The \nalgorithm for unify is identical to the traditional one for types with the addition that kinds on product \ntypes must also be unified. The function unifykind handles this. Also, when a type variable is annotated \nwith kind r, the type with which it is being unified must also be of kind r. In this case the function \ngrndtp is used on the type.The final step in the algorithm is to translate the an-notated term into its \narity-raised form in the target lan-guage. The function translate takes a context H (mapping variables \nto tuplings of variables) and an annotated term, and proceeds by cases on the structure of the term, \nand ap- plies transformations based on annotations and the types of bound variables. For the case that \nthe annotated term is a variable IC, the function simply returns H(z). For the abstraction case, the \nfunction first calls makeparams to generate a tupling of variables based on the type of the bound variable. \nIt then extends the context H by mapping the bound variable x to this tupling and translates the body. \nThe parameter list in translated function is obtained by flattening the variable tu-pling. For the application \ncase, the function translates both operator and operand and then flattens the operand (which could be \na tuple) into an operand list before constructing the application in the target languages. We have two \ncases for pairs, based on the annotations on the them. If a pair is annotated by r, then the function \nconstructs a pair from the translated subterms. If a pair is annotated by c, then the function constructs \na tuple from the translated subterms. Similarly, we have two cases for each projection. The function \ntranslates a projection annotated with r into a target projection, and it reduces a projection annotated \nwith c. We have proven that the algorithm is sound with respect to the inference system presented in \nFigures 6, 7, 8, and 9. Theorem 6 (Soundness of Arity Raising) 1. #L , 7, u) = W ([], e) and 8 = Bc 0 \n0 then De : B r + 2. Ifrn = transfate([],u) then D u + m.  w/p, x) = if x $ dam(r) then fail else \n(ID, qx), x) w/p, he) = let fir be a new variable (e,, T, u) = w (r{x : &#38;}, e) 6% = grndtp(7)  \ne3= ez0 e1 W'(r,.3 @ e2) = let (&#38;,TI,uI) = W'(r,el) (e2,Tz,7h) = W'arg(&#38;r,e2) let /3, be a new \nvariable 03 = unify(&#38;rl, r2 -+ p,) 04 = 03 0 020 01 in(Q4,e4Pr, B4(u1 @u2)) w'(r, (el, e2)) = let \n(el,~l,t4 = w'(r,a) (82,72,~2) = W'(Qlr,e2) T = (02-n xr T2) O3 = grndtp(r) o .!!12 o O1 in(e3,e3~,e2((ul,u2)r)) \nFigure W(r,fst e) = let (64, 7, u) = W (r, e) let &#38;,, &#38;, , y be new variables 02 = unify@ xy~~ \n,f+,7) in(02 0 81, &#38;&#38;, B(fst-p u)) W'(r,snd e) = let (el17,2L) = W'(r,e) let /I,, &#38;, , y \nbe new variables 02 = unify&#38; x+1 &#38;,7-) in(e2 o 64, S2,$,, , O(snd,~~ u)) W'arg(r,(el,ez)) = \nlet (~?,T~,u~)= W'arg(r,el) (02,r2,u2) = W'arg(&#38;r,e2) let y be a new variable -J-= (n x7 T2) e3 = \ne2 0 e1 in(O2 0 el, (B2rl xy 7-2),(e2ul, 7~~)~) W arg(r, e) = W (r, e) 10: Algorithm W unify(P%, 7-) \n= if Pn = T then ID else if occurs(P,, T) then fail else if K. = r then grndtp(-r) o ID{,&#38; ti T} \nelse ID{,&#38; e 7) unify(r, /3&#38;) = unify(&#38;, 7) unify(L, L) = ID unify(rl + ~2,7: + T;:) = let \n81 = unify(rl,T:) e2 = unify(8172, elT;) in 02 0 81 83= unify(B2&#38;72, &#38;OIT~) in e3 0 e2 0 01 \nunify(7-1, ~2) = fail Figure unifykind(y, PC) = ID{y ++ K} unifykind(n,y) = ID{y +-+ K} unifykind(r, \nr) = ID unifykind(c, c) = ID unifykind(nl, ~2) = fail grndknd(r) = ID grndknd(c) = fail grndknd(y) = \nID{y C) r} grndtp@,) = grndknd(n) grndtp(L) = ID grndtp(71 --+ ~2) = ID grndtp(Tl x, 72)= grndtp(~~)ogrndtp(~2) \n o grndknd(K) 11: Unification translate(H, z) = H(z) flatten (ml, mz) = append(flatten ml, flatten ,mz) \ntranslate(H, Xx : r.u) = flatten m = [m] let ys = makeparams T in Xflatten(ys).translate(H{z t-+ ys},u) \nmakeparams(rl XC ~2) = (makeparamsq, makeparamsT2) translate(H, UI @ ~2) = makeparams r = yi, where yi \nis a new variable. (translate(H, 2~1)) @ (flatten(translate(H, 7~2))) translate(H, (zri , uz)r) = (translate(H, \n%I), translate(H, 2~2)) translate(H, (1~1, UZ)C) = (translate(H, 1~1)~ translate(H, ~2)) translate(H, \nfstc u) = let (ml, mz) = translate(H, u) in ml translate(H, fstr u) = fst(translate(H, u)) translate(H, \nsndc u) = let (ml) rnz) = translate(H, u) in m2 translate(H, sndr u) = snd(translate(H, u)) Figure 12 \nTranslation Related Work Compilers for functional languages typically make some use of arity raising \nto improve performance of the generated code, but most previous approaches have been ad hoc and rather \nconservative. The Standard ML of New Jersey com-piler performs a limited amount of first-order arity \nraising, but uses only the information provided from patterns in function definitions to determine which \narguments can be arity raised [l]. This can result in less arity raising than our method, even when restricted \nto first-order programs. An approach taken by some compilers is to use wrapper functions and inlining \nto achieve optimizations such as arity raising. For example, given a function definition f(x,y) = e, \n this approach introduces a wrapper function in place of f as follows: f b,~l = e f(X,Y) = f @ b,Yl \nThen calls to f can be inlined, replacing f with f . This approach works fine in cases where inlining \nis practical. But for large function definitions, such inlining is typically im-practical. For higher-order \nfunctions, inlining can also be impractical because all the call-sites of a functional param-eter may \nnot easily be determined. The problem of arity raising has also been studied in the context of partial \nevaluation. In this setting, the structure of static data (known at the time of partial evaluation) di-rects \nthe splitting of a dynamic variable into several new variables. For example, consider an interpreter \nusing a vari- able p to range over environments represented as lists of variable/value pairs. During \npartial evaluation of the inter- preter applied to a known program, the variables names in the environment \nmight be known, while the values are un-known However, the number of values in the environment is known. \nVariable splitting potentially allows the single variable p to be replaced by new variables representing \nthe individual, unknown values in the environment. The static data provides enough information to make \nsuch a transfor- mation possible and useful. In [19], Sestoft describes variable splitting, but does \nnot describe automatic techniques supporting it. The system Mix described in that paper relies on manually-added \nan-notations to perform variable splitting. Mogensen s work on partially-static structures [14] provides \nan automatic so-lution to variable splitting in this setting. A more general description of arity raising, \nthough still motivated by partial evaluation, is given in [18]. The approach presented in that work uses \ntwo global analyses on a program: a forward anal-ysis to determine where raising is possible and a backward \nanalysis to determine whether raising is useful. As with most flow analyses, this work is inherently \nglobal, requir-ing analysis of the entire program. Using a closure analysis, later work extended this \napproach to a higher-order lan-guage [22]. Launchbury uses dependent types to support a principled mechanism \nfor arity raising during partial evalu-ation [ll]. Finally, Thiemann and Gliick describe a partial evaluator \nwhich, as a by-product, can be used to perform higher-order arity raising [23]. Other work has addressed \nfunction-call protocols using flow-baaed approaches. Closure analysis and closure con-version have been \nstudied using abstract interpretation and related flow analyses [5, 20, 251. Type-based analyses gen-erally \nhave the advantage of being more modular, though separate compilation issues still pose problems. In \n[5], Go- mard presents a brief description of arity raising using infer- ence rules and two-level terms. \nUnfortunately, the problem is only given cursory discussion. The task of type recon-struction for variable-arity \nprocedures [4] is related to our work on arity raising, as that work uses types to verify the proper \nuse of functions based on their arity. Typed clo-sure conversion is studied in [13] where a rich formulation \nof types and type systems provides a framework for reasoning about closures. Type-based partial evaluation \n[3] is another example of type information directing the transformation of programs. The current work \ngrew out of our previous work on un- Currying [9]. Both arity raising and uncurrying address the protocol \nfor function calls, and so many of the tech-niques utilized for specifying and implementing uncurrying \ncould be adapted for arity raising. For both problems we use annotated types to convey information regarding \nthe trans-lation of functions and applications. Additionally, we de-compose initial specifications into \nmodular ones, separating inference and translation phases. Based on these separated specifications we \nderive algorithms for both problems. In both settings, we exploit the idea that identifying when an optimization \n(uncurrying or arity raising) cannot be per- formed is a local operation. However, arity raising posed \nnew problems, primarily due to the need to perform non-trivial translations and reductions on terms. \nFor example, our formulation of arity raising requires reducing projections applied to arity-raised variables. \nAdditionally, while unCur-rying can be reduced to combining two adjacent applications or abstractions, \narity raising can involve the flattening of arbitrarily nested pairs. As a result of these problems, \nwe introduced a two-level type system to facilitate the separa-tion of our original specification into \none with distinct infer-ence and translation phases. The algorithm for arity raising, then, must manage \ntwo-level types, ensuring that types can always be well-kinded. 7 Conclusions and Future Work We have \npresented a formal specification of higher-order arity-raising and developed a practical algorithm which \nim-plements this transformation on a simple, functional lan-guage This specification provides a general \nframework for reasoning about arity raising, independent of a particular algorithm, and also supports \na richer transformation than is currently found in compilers for functional languages. Fur-thermore, \nthe specification provides a basis for studying op-timizations related to arity raising. A number of \nimportant and related issues remain to be explored in conjunction with this work. We briefly outline \nsome of them here. Other Language Constructs. The current work treats only a core functional language. \nThe inclusion of additional programming language features is an important next step, but one which appears \nto pose no difficulties. Polymor-phism is orthogonal to arity raising, though we can arity raise a polymorphic \nfunction only when all of its instances can be arity raised. (We do not consider polyvariant arity raising.) \nGiven an order of evaluation of lists of arguments corresponding to the order of evaluation for pairs \n(e.g., left- to-right), then side effects do not cause any problem. Sep-arate compilation is, of course, \nan obstacle. In a practical system, we might choose to arity raise aggressively and then provide an alternative \nintcrfacc to a function. Or, we could use profiling information to determine the use of functions across \nmodule boundaries. Pattern Matching. The current work treats arity raising in a language with explicit \nprojections rather than pattern matching. We can modify our specification for a language with pattern \nmatching without any difficulty. Related Optimizations. We studied arity raising in iso- lation, but \ncompilers typically employ many other transfor-mations that modify the protocol of function calls, including \nclosure conversion, uncurrying, and useless variable elimi-nation We have previously studied uncurrying \nand closure conversion. We plan to study useless variable elimination in a similar setting and then study \nthe interaction of these optimizations when considered together. Arity Raising with Other Data Structures. \nThe cur-rent work treats arity raising involving pairs, but this op-timization is not limited to pairs. \nFunctions manipulating other concrete data types, such as lists or trees, could also benefit from arity \nraising. The application to lists is related to the work on list unrolling [21] and optimized list repre-sentation \n[6]. The application to trees is related to defor-estation [24], though deforestation typically involves \nmore transformation of the functions involved. Returning Multiple Values. The current work requires functions \nto return objects with a type of kind r, prohibiting functions which return multiple values in a tuple. \nThis limi-tation can be removed, as long as the operational semantics supports functions returning multiple \nvalues. For example, consider the following contrived example: Since the value (1,l) is passed as an \nargument to the func- tion Xp.e, we could conceivably transform this expression to something like ($l,pzl.e) \n((XZ.[~,~) 1). This idea is related to work on supporting multiple return values in Scheme [2], though \nwe have the benefits of a strong typing system in our setting. Acknowledgments. This work was supported \nin part by NSF CAREER Award #CCR-9502356. We thank David Liben-Nowell for his comments on earlier versions \nof the paper. References APPEL, A. W. Compiling with Continuations. Cam- PI bridge University Press, \n1992. PI ASHLEY, J. M., AND DYBVIG, R. K. An efficient im-plementation of multiple return values in \nscheme. In 1994 Conference on Lisp and Functional Programming (1994), ACM Press, pp. 140-149. DANVY, \n0. Type-directed partial evaluation. In PTO-ceedings of the Twenty-third Annual ACM SIGPLAN-SIGACT Symposium \non Principles of Programming Languages (1996). [31 DZENG, H. Type reconstruction for variable-arity \npro- PI cedures In 1994 Conference on Lisp and Functional Programming (1994), ACM Press, pp. 2399249. \nGOMARD, C. K. Program Analysis Matters. Diku re-port 91/17, University of Copenhagen, 1991. [51 HALL, \nC. V. Using Hindley-Milner type inference to optimise list representation. In 1994 Conference 07~ Lisp \nand Functional Programming (1994), ACM Press, pp. 1622172. PI HANNAN, J. Type systems for closure conversions. \nIn Participants Proceedings of the Workshop on Types for Program Analysis (May 1995), H. R. Nielson and \n171 K. L. Solberg, Eds., Aarhus University, DAIMI PB-493, pp. 48-62. (81 HANNAN, J. A type-based escape \nanalysis for func-tional languages. Journal of Functional Programming (September 1997). To appear. [9] \nHANNAN, J., AND HICKS, P. Higher-order uncurrying. In Proceedings of the 25th Annual ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages (January 1998), pp. l-11. [lo] HANNAN, J., HICKS, P., \nAND LIBEN-NOWELL, D. A lifetime analysis for higher-order languages, Tech. Rep. CSE-97-014, Penn State \nUniversity, September 1997. [ll] LAUNCHBURY, J. Projection Factorisations in Partial Evaluation. Cambridge \nUniversity Press, 1991. [12] MILNER, R. A theory of type polymorphism in pro-gramming. Journal of Computer \nand System Sciences 17, 3 (1978), 348-375. [13] MINAMIDE, Y., MORRISETT, G., AND HARPER, R. Typed closure \nconversion. In 23rd ACM Symposium on Principles of Programming Languages (St. Petersburg, FL, January \n1996), pp. 271-283. [14] MOGENSEN, T. Partially static structures in a self-applicable partial evaluator. \nIn Partial Evaluation and Mixed Computation, D. Bjorner, A. P. Ershov, and N. D. Jones, Eds. North-Holland, \n1987, pp. 325-347. [15] NIELSON, F., AND NIELSON, H. R. Two-level semantics and code generation. Theoretical \nComputer Science 56 (1988), 59-133. [16] NIELSON, H., AND NIELSON, F. Automatic binding time analysis \nfor a typed X-calculus. Science of Com-puter Programming 10, 2 (1988), 1399176. [17] NIELSON, H. R., \nAND NIELSON, F. Using transfor-mations in the implementation of higher-order func-tions. Journal of Functional \nProgramming 1, 4 (Oc-tober 1991), 4599494. [18] ROMANENKO, S. A. Arity raiser and its use in program \nspecialization. In 3rd European Symposium on Programming (Copenhagen, Denmark, May 1990), N. Jones, Ed., \nvol. 432 of Lecture Notes in Computer Science, Springer-Verlag, pp. 341-360. 1191 SESTOFT, P. The structure \nof a self-applicable par-tial evaluator. In Programs as Data Objects (1985), H. Ganzinger and N. Jones, \nEds., vol. 217 of Lecture Notes in Computer Science, Springer-Verlag, pp. 236- 256. [20] SESTOFT, P. \nAnalysis and Eficient Implementation of Functional Programs. Rapport nr 92/6, DIKU, Gopen-hagen, October \n1991. [21] SHAO, Z., REPPY, J. H., AND APPEL, A. W. Unrolling lists. In 1994 Conference on Lisp and Functional \nPro-gramming (1994), ACM Press, pp. 185-195. [22] STEENGAARD, B., AND MARQUARD, M. Parameter splitting \nin a higher order functional language. Stu-dent Project 90-7-1, DIKU, University of Copenhagen, Denmark, \nAugust 1990. [23] THIEMANN, P., AND GL~~cK, R. The generation of a higher-order online partial evaluator. \nIn Fuji Znter-national Workshop on Functional and Logic Program-ming, M. Takeichi and T. Ida, Eds. World \nScientific, July 1995, pp. 239-253. [24] WADLER, P. Deforestation: Transforming programs to eliminate \ntrees. Theoretical Computer Science 73 (1990), 231-248. [25] WAND, M., AND STECKLER, P. Lightweight closure \nconversion. ACM Trans. Program. Lang. Syst. 19, 1 (January 1997), 48-86.  \n\t\t\t", "proc_id": "289423", "abstract": "Arity raising, also known as variable splitting or flattening, is the program optimization which transforms a function of one argument into a function of several arguments by decomposing the structure of the original one argument into individual components in that structure. This optimization eliminates the need for the structuring of the components and also allows more arguments to be passed in registers during a function call. We present a formal specification of arity raising for a higher-order functional language. This specification supports the general arity raising of functions, even for functions which are passed as arguments or returned as values. We define a practical algorithm, based on algorithm <i>W</i>, which implements arity raising, and we prove this algorithm sound with respect to the deductive system. These results provide a declarative framework for reasoning about arity raising and support a richer form of the transformation than is currently found in compilers for functional languages.", "authors": [{"name": "John Hannan", "author_profile_id": "81100168458", "affiliation": "Department of Computer Science and Engineering The Pennsylvania State University University Park, PA", "person_id": "PP39030699", "email_address": "", "orcid_id": ""}, {"name": "Patrick Hicks", "author_profile_id": "81100060874", "affiliation": "St. Vincent Archabbey, 300 Fraser Purchase Road, Latrobe, PA", "person_id": "P220390", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/289423.289426", "year": "1998", "article_id": "289426", "conference": "ICFP", "title": "Higher-order arity raising", "url": "http://dl.acm.org/citation.cfm?id=289426"}