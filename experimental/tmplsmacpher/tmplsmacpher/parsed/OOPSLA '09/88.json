{"article_publication_date": "10-25-2009", "fulltext": "\n The Commenting Practice of Open Source Oliver Arafat Siemens AG, Corporate Technology Otto-Hahn-Ring \n6, 81739 M\u00fcnchen oarafat@gmail.com Dirk Riehle SAP Research, SAP Labs LLC 3410 Hillview Ave, Palo Alto, \nCA 94304, USA dirk@riehle.org Abstract The development processes of open source software are different \nfrom traditional closed source development proc\u00adesses. Still, open source software is frequently of high \nquality. This raises the question of how and why open source software creates high quality and whether \nit can maintain this quality for ever larger project sizes. In this paper, we look at one particular \nquality indicator, the den\u00adsity of comments in open source software code. We find that successful open \nsource projects follow a consistent practice of documenting their source code, and we find that the comment \ndensity is independent of team and pro\u00adject size. Categories and Subject Descriptors D.2.8 [Metrics]: \nSoftware Science General Terms: Measurement, Documentation, Languages  1. Introduction Open source software \nhas become an important part of commercial software development and use. Its continued growth emphasizes \nthis importance [1]. Projects like the Linux kernel and the Apache web server demonstrate that open source \nsoftware can be of high quality. Most interest\u00adingly, open source projects have reached a size and com\u00adplexity \nthat rivals the size of some of the largest commer\u00adcial projects [2], yet they are being developed in \na manner quite different from traditional software engineering proc\u00adesses. Our research goal is to understand \nthe processes and practices of open source software development and to as\u00adsess whether they can be applied \nin a corporate environ\u00adment. This has become particularly important because most well-known processes \nfind it hard to scale up to lar\u00adger project sizes. Traditional life-cycle processes like the waterfall \nmodel are best used in contexts where the prob- Permission to make digital or hard copies of all or part \nof this work for not made or distributed for profit or commercial advantage and that copies bear this \nnotice and the full citation on the first page. To copy otherwise, or republish, to post on servers or \nto redistribute to lists, requires prior specific permission and/or a fee OOPSLA 2009, October 25 29, \n2009, Orlando, Florida, USA. Copyright &#38;#169; 2009 ACM 978-1-60558-768-4/09/10 $10.00. lem domain \nis well understood [15]. Agile software devel\u00adopment methods can cope with changing requirements and \npoorly understood problem domains, but typically require co-location of developers and fail to scale \nto large project sizes [16]. A host of successful open source projects in both well and poorly understood \nproblem domains and of small to large sizes suggests that open source can cope both with changing requirements \nand large project sizes. In this pa\u00adper we focus on one particular code metric, the comment density, \nand assess it across 5,229 active open source pro\u00adjects, representing about 30% of all active open source \nprojects. We show that commenting source code is an on\u00adgoing and integrated practice of open source software \nde\u00advelopment that is consistently found across all these pro\u00adjects. This practice is independent of the \nchosen program\u00adming language, the age of project, the size of the project in lines of code, and their \nteam sizes. The contributions of this paper are the following: It assesses the metric of comment density \nfor the first time for open source projects on a broad scale;  It shows that commenting source code \nis a consis\u00adtently exercised practice of open source software de\u00advelopment;  It reviews a variety of \ndependencies between proper\u00adties of open source projects and their comment den\u00adsity.  The paper is organized \nas follows. Section 2 reviews our data source and the taken approach. Section 3 gives an aggregate overview \nof comment density in open source projects, discusses how it varies by programming lan\u00adguage, and shows \nhow commenting source code is a con\u00adsistently followed practice in open source. Section 4 re\u00adviews the \ndependencies of comment density on multiple variables relevant to scaling up projects. Section 5 summa\u00adrizes \nour conclusions and discusses threats to their validity. Section 6 reviews related work and Section 7 \nends the pa\u00adper with some final conclusions and an outlook on future work.  2. Data source, filters, \nand definitions Our analyses use the database of the open source analytics firm Ohloh, Inc. [9]. The \ndata is accessible through an API [10]. We work with a database snapshot of March 2008, but have cut \noff all analysis data after December 31st, 2007. The database contains data from about 10,000 open source \nprojects, including project name, description, com\u00admitter information, and the code contribution history \nof a project.  In this paper we are interested in active well-working open source projects, not dead \nprojects. We define and apply an active project filter to let a project pass only if it is at least two \nyears old and if the code activity of the last year has been at least 60% of the activity of the previous \nyear. This active project filter reduces the original 10,000 projects to 5,229 projects. Using a comparable \napproach, Daffara estimates that there were about 18,000 active open source projects in the world by \nAugust 2007 [7], so our sample size represents about 30% of the total population. The code contribution \nhistory is a time series of com\u00admits (code contributions) to the source code repository. A commit represents \na set of changes to the source code per\u00adformed as one chunk of work. When analyzing commits we apply \nfilters to improve data quality. For example, we filter out file rename and move operations where no \nreal work has been done. A commit consists of multiple diffs. A diff describes the differences between \ntwo consecutive versions of the same file as changed in the commit. It is split into three parts: The \nnumber of lines of source code that have been added to the file or removed from it, the number of com\u00adment \nlines that have been added or removed, and the num\u00adber of empty lines that have been added or removed. \n A source line of code, or SLoC, is a physical line in a source file that contains source code. 100% \nmean = 0.1867 90% median = 0.1674 stdev = 0.1088 80% correl = -0.00787 70% 60% 50% 40% 30% 20% 10% 0% \n1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 Comment Density A comment line, or CL, is a physical line in a source \nfile that represents a comment.  A line of code, or LoC, is either a source line of code or a comment \nline.  An empty line is just that. The Ohloh diff tool recognizes every comment character and characters \nrespectively that are defined and valid within one particular programming language such as the triple \nquotes in Ruby.Furthermore, it also accounts for external mark up languages such as Plain Old Documenta\u00adtion \n(POD) which is widely used in Perl. Additionally, the Ohloh diff tool recognizes comments that span multiple \nlines [11]. It does not, however, recognize whether a code line was changed; rather, it counts a changed \nline as an old line removed and a new line added. While it is not possible to determine a posteriori \nwhether a line was changed or removed and then added, heuristics exist to predict which variant was the \ncase. Most variants of the Unix tool diff, for example, implement such a heuristic by solving the Longest \nCommon Subsequence problem. We have devel\u00adoped a statistic that determines the probabilities of whether \na line was changed or removed and added [12]. Our algo\u00adrithms use this statistic to determine aggregate \nvalues like commit sizes and comment densities.  The commit size of a commit is the number of lines \nof code affected in a commit, whether added, removed, or changed. When calculating commit sizes we apply \nthe sta\u00adtistic explained above. The comment density of a file or a group of files or the whole source \ncode base of a project is defined as the number of comment lines divided by the number of lines of code \nof the same code body [4]. 1.E+05 1.E+06 1.E+07 1.E+08 1.E+09 Project Size in Lines of Code (LoC = \nCL + SLoC)  Figure 1: Comment density as a function of lines of code for a given project.   Comment \nlines Comment density Binned distribution of projects  as a function of project size as a function \nof project size as a function of comment density 100% 1.E+07 70% 90% mean = 0.1760 y = 0.1516x 1.E+06 \n60% median = 0.1652 R2 = 0.8863 0.5438 Percentage of Occurrences 80% stdev = 0.0832 1.E+05 50% 40% 30% \n20% Comment Density 70% 60% 50% 40% 30% Comment Lines Comment Lines Comment Lines Comment Lines Comment \nLines 1.E+04 1.E+03 1.E+02  C and 0.2324 0.1478 20% 1.E+01 10% C++ 10% 0.0540 0.0043 0.0012 0.0000 \n0.0000 1.E+00 0% 0% [0.0, 0.1[ [0.1, 0.2[ [0.2, 0.3[ [0.3, 0.4[ [0.4, 0.5[ [0.5, 0.6[ [0.6, 0.7[ [0.7, \n0.8[ [0.8, 0.9[ 1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 1.E+05 1.E+06 1.E+07 1.E+0 1.E+00 1.E+01 1.E+02 1.E+03 \n1.E+04 1.E+05 1.E+06 1.E+07 1.E+08 Project Size in Lines of Code (CL + SLoC) Project Size in Lines of \nCode (CL + SLoC) Comment Density y = 0.1516x; R2 = 0.8863; mean = 0.1760; median = 0.1652; stdev = 0. \n0832; population size = 1621 100% 1.E+08 70% mean = 0.2587 y = 0.2798x 90% 1.E+07 median = 0.2566 60% \nR2 = 0.9334 Percentage of Occurrences 80% stdev = 0.1111 1.E+06 1.E+05 1.E+04 1.E+03 Comment Density \n70% 60% 50% 40% 30% 1.E+02 20% 50% 40% 0.3327 30% 0.2450 0.2340 20% 0.0841 0.0841 10%  Java Python JavaSc \n1.E+01 10% 0.0165 0.0037 0.0000 0.0000 1.E+00 0% 0% 1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 1.E+05 1.E+06 \n1.E+07 1.E+0 1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 1.E+05 1.E+06 1.E+07 1.E+08 [0.0, 0.1[ [0.1, 0.2[ [0.2, \n0.3[ [0.3, 0.4[ [0.4, 0.5[ [0.5, 0.6[ [0.6, 0.7[ [0.7, 0.8[ [0.8, 0.9[ Project Size in Lines of Code \n(CL + SLoC) Project Size in Lines of Code (CL + SLoC) Comment Density y = 0.2798x; R2 = 0.9334; mean \n= 0.2587; median = 0.2566; stdev = 0.1111; population size = 1085 100% 1.E+07 70% mean = 0.1150 1.E+06 \n90% y = 0.0692x R2 = 0.5923 median = 0.1022 60% Percentage of Occurrences 80% stdev = 0.0803 0.4944 \n1.E+05 1.E+04 1.E+03 1.E+02 50% 40% Comment Density 70% 60% 50% 40% 30% 0.4052 30% 20% 20% 0.0781 1.E+01 \n10% 10% 0.0167 0.0019 0.0019 0.0019 0.0000 0.0000 1.E+00 0% 0% [0.0, 0.1[ [0.1, 0.2[ [0.2, 0.3[ [0.3, \n0.4[ [0.4, 0.5[ [0.5, 0.6[ [0.6, 0.7[ [0.7, 0.8[ [0.8, 0.9[ 1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 1.E+05 \n1.E+06 1.E+07 1.E+0 1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 1.E+05 1.E+06 1.E+07 1.E+08 Project Size in Lines \nof Code (CL + SLoC) Project Size in Lines of Code (CL + SLoC) Comment Density y = 0.0692x; R2 = 0.5923; \nmean = 0.1150; median = 0.1022; stdev = 0.0803; population size = 534 1.E+07 100% 70% mean = 0.1642 90% \ny = 0.1861x 1.E+06 median = 0.1528 60% R2 = 0.829 Percentage of Occurrences 80% stdev = 0.0935 0.5036 \n1.E+05 1.E+04 1.E+03 1.E+02 Comment Density 50% 40% 30% 0.2645 70% 60% 50% 40% 30% 20% 0.1486 20% 0.0435 \n0.0362 10%  ript 0.0036 0.0000 0.0000 0.0000 1.E+00 0% 0% 1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 1.E+05 \n1.E+06 1.E+07 1.E+0 1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 1.E+05 1.E+06 1.E+07 1.E+08 [0.0, 0.1[ [0.1, 0.2[ \n[0.2, 0.3[ [0.3, 0.4[ [0.4, 0.5[ [0.5, 0.6[ [0.6, 0.7[ [0.7, 0.8[ [0.8, 0.9[ Project Size in Lines of \nCode (CL + SLoC) Comment Density Project Size in Lines of Code (CL + SLoC) y = 0.1861x; R2 = 0.829; \nmean = 0.1642; median = 0.1528; stdev = 0.0935; population size = 276 100% 1.E+07 70% 90% mean = 0.1044 \ny = 0.1602x 0.5855 1.E+06 60% median = 0.0902 R2 = 0.9464 80% 10% 1.E+01 Percentage of Occurrences stdev \n= 0.0713 1.E+05 1.E+04 1.E+03 50% 40% 0.3382 30% 20% Comment Density 70% 60% 50% 40% 30%  Perl 1.E+02 \n20% 1.E+01 10% 0.0582 10% 0.0073 0.0109 0.0000 0.0000 0.0000 0.0000 1.E+00 0% 0% [0.0, 0.1[ [0.1, 0.2[ \n[0.2, 0.3[ [0.3, 0.4[ [0.4, 0.5[ [0.5, 0.6[ [0.6, 0.7[ [0.7, 0.8[ [0.8, 0.9[ 1.E+00 1.E+01 1.E+02 1.E+03 \n1.E+04 1.E+05 1.E+06 1.E+07 1.E+0 1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 1.E+05 1.E+06 1.E+07 1.E+08 Project \nSize in Lines of Code (CL + SLoC) Project Size in Lines of Code (CL + SLoC) Comment Density y = 0.1602x; \nR2 = 0.9464; mean = 0.1044; median = 0.0902; stdev = 0.0713; population size = 273 Figure 2: Comment \ndensity of projects with different dominant programming languages.  3. Comment density in open source \nThis Section provides an overview of comment density in open source projects, discusses how it varies \nby program\u00adming language, and investigates the practice of comment\u00ading source code. We find the commenting \ncode is a com\u00admon consistently exercised practice of open source pro\u00adjects. 3.1 Overview As we have \nalready shown in [18] and depicted in figure 1 the average comment density in our sample distribution \nis about 19% so about one line of code in five lines is a comment line varying widely per individual \nproject with a standard deviation of 10.88%. The amount of comments in a given source code body can be \ninterpreted as an indicator of its quality and maintainability [4] [5].  3.2 Influence of programming \nlanguages The comment density varies significantly by programming language. Figure 2 shows the graphs, \ntheir models, and mean, median, and standard deviation for five popular lan\u00adguages. Of the five languages, \nJava has the highest mean of comment lines per source lines at 25.87% or one com\u00adment line for three \nsource code lines. Perl has the lowest mean with 10.44% or about one comment line for nine source code \nlines. It is interesting to discuss the differences between programming languages. It appears to be less \na difference between any two particular programming languages, but rather it seems to be a difference \nbetween categories of languages. One way of categorizing the five languages is by whether they are statically \nor dynamically typed. This puts C/C++ and Java in one category and Python, JavaScript, and PERL in the \nother. All three dynamically typed lan\u00adguages have a lower average comment density than the two statically \ntyped languages. Another way of categorizing the programming lan\u00adguages is by lineage. C/C++, Java, and \nJavaScript fall into the dominant C-paradigm of programming languages, while PERL and Python do not. \nThis choice might be justi\u00adfied by the closeness of the average comment density be\u00adtween C/C++ (17.60%) \nand JavaScript (16.42%). Example factors that might influence the amount of comment lines in source code: \n Expressiveness of language (and hence the need (or lack thereof) for more documentation);  The use \nof IDEs and auto-generate comment features of such IDEs.  Without a detailed analysis of each programming \nlan\u00adguage and the dominant practices around it we cannot pre\u00addict what percentage of comment lines are \nreal content lines and which are just empty stubs. Here, we drop further investigation into the reasons \nof such variation and post\u00adpone it to future work.  3.3 The commenting practice in open source Figure \n3 shows the comment density as a function of the amount of source lines of code in a given commit. This \nFigure is rich in information. First, for those commits with zero SLoC, the comment density is naturally \n100%. Not shown in the graph, the average number of comment lines for zero-SLoC commits is 47.55 comment \nlines with a standard deviation of 570.1. Moreover, of the 6,622,901 commits in our database after the \nfilters, the zero-SLoC commits count is 164,054, repre\u00adsenting 2.477% of all commits. In other words, \nabout 2.5% of the code contributions in our sample population of open source projects, or about every \n20th commit, exclusively serve documentation purposes. Comment Density 100% 90% 80% 70% 60% 50% 40% 30% \n20% 10% 0%  Figure 3: Comment density as a function of source code lines in a given commit. Comment \nDensity 50% 45% 40% 35% 30% 25% 20% 15% 10% 5% 0% 50% 45% 40% 35% 30% 25% 20% 15% 10% 5% 0%  Figure \n4: Comment density as a function of team size of open source projects. Next, for those commits with one \nSLoC, the comment density is 62.50%. In other words, for every one-liner (of source code) contributed, \non average 1.667 comment lines are contributed. Or more poignantly, when developers are making minimal \nsource code changes, they thoroughly document them with comment lines. For commits with two SLoC, the \ncomment density falls to 48.90%, meaning that for almost every source code line there is a comment line. \nFinally, we can see that for increasing source code lines in a commit, the comment density keeps falling, \napproaching asymptotically the total average comment density of 18.67% graphed by the dashed line. The \nhigh value at 39 SLoC is caused by a single commit with 364,438 comment lines; the sample size for the \n39 SLoC commits bin is 16,534. Thus, we conclude that successful open source projects like those in our \nsample population follow a practice of on\u00adgoing and integrated documentation of their code base. This \nactivity is bipolar in that developers both perform documen\u00adtation as a separate housekeeping activity \nas well as inte\u00adgrated with regular source code lines (SLoC) contributions.  4. Functional dependencies \nThis Section discusses the influence of several variables of open source software projects on their comment \ndensity relevant to scaling up projects. Specifically, this Section looks at the relationship between \ncomment density and pro\u00adject size, team size, and age of project. 4.1 Project size and comment density \nFigure 1 already displays the comment density as a function of project size. The comment density remains \nconstant at 18.67% for most project sizes but those of the largest pro\u00adjects. Also, the correlation between \nproject size and com\u00adment density is -0.0079, suggesting they are independent of each other. For large \nprojects, the comment density appears to be decreasing. However, the data for large projects (> 10 mil\u00adlion \nSLoC) is getting sparse. We only have 18 such projects in our dataset, out of 5,229, representing 0.3% \nof the total population. Thus, variation in comment density for these few select projects may unduly \ndistort the model. Also, some of the large projects have unusual properties. For example, the Debian \ndistribution of Linux is mostly generated code, re\u00adpeating the same patterns over and over. Thus, for \nall practical purposes, we conclude that the comment density is independent of project size and that \nits average remains a constant over a wide range of project sizes.  4.2 Team size and comment density \nFigure 4 shows the comment density as a function of team size. We define team size as the number of committers \nto a given project. The committers are those people who have write access to the code repository and \nhave made a contri\u00adbution at least once. The average comment density for team sizes 1-20 is 19.14%, for \nteam sizes 1-50 is 19.22% and for team sizes 1\u00ad100 is 18.56% with standard deviations between 2.6% and \n6.4%. Of all projects, projects with team sizes 1-10 represent 80.99% and projects with team sizes 1-20 \nrepresent 89.96%. Projects with team sizes 101 and higher represent 1.32%. Thus, the bulk of projects \nare in the 1-20 people team range and the comment density of these projects dominates the average comment \ndensity.  However, despite the dominance of the smaller teams, we find little variation around the average \ncomment density of 18.67%. The mean for projects of team sizes 20-100 is 18.40%, the median is 18.55% \nand the standard deviation is 7.16%. While the variance for the comment density of pro\u00adjects run by larger \nteams is going up due to the increasing sparseness of data points, the average comment density is roughly \nstaying the same. In addition, the correlation be\u00adtween team size and comment density is -0.0550, suggesting \nindependence of the two variables. We conclude that in open source software the comment density is by \nand large independent of team size. This sug\u00adgests that successful open source projects are capable of \nmaintaining a commenting discipline as their teams grow larger.  5. Discussion of findings We summarize \nour finding and discuss potential threats to their validity. We then discuss future work. 5.1 Conclusions \nWe have found and demonstrated that commenting source code is a consistently followed practice of successful \nopen source projects. It has led to an average comment density of about 19%. This density is maintained \nby dedicated com\u00admenting activities (about 2.5% of all code contributions) as well as a regular part \nof on-going software development. We have also found that the average comment density varies by programming \nlanguage but remains constant on several other dimensions. In particular, we have found that the average \ncomment density is independent of team size and project size, suggest\u00ading that as teams and projects \nget larger, successful open source projects maintain their commenting discipline. 5.2 Threats to validity \nOur sample population represents about 30% of the total population of active open source projects. Our \ndatabase was initially seeded with popular projects by Ohloh, Inc. After this, it was opened up for community \nediting. There is no apparent bias in the selection of projects; however, Ohloh s crawler can only cope \nwith the configuration management systems CVS, Subversion, and Git. These are the most popu\u00adlar configuration \nmanagement systems, so we feel that this does not unduly bias the overall sample. We only count physical \nlines and do not analyze their contents. Thus, in terms of actual comment contents our numbers may be \nmisleading, in particular if a large number of comments in open source software was auto-generated or \nif the comments refer to the license that is used within the project for example. We do not feel that \nthis is a major issue right now, however, with features like comment stub genera\u00adtion in modern Java \nIDEs this issue may become more im\u00adportant in the future. In all analyses that rely on counting the exact \nnumber of lines affected in a commit, there is a risk of miscounting these lines because it is not possible, \na posteriori, to deter\u00admine whether a line was changed or whether it was removed and then added. Given \nour statistic over these changes and the large sample size of commits in our population, we be\u00adlieve \nthat this problem is not a serious issue [12]. 5.3 Future work Future work might include a more thorough \nanalysis of the semantic content of comment lines to see whether the differ\u00adences in comment densities \nbetween programming lan\u00adguages reflect real content or were created by auto\u00adgeneration features of IDEs. \nWe intend to compare the comment density of open source projects with those of closed source projects \nfound at SAP. We are currently preparing such a comparison. Our hope is that such comparison and the \nresulting insight can help us better define corporate code metrics that in turn aid in the management \nof software development projects. We have yet to correlate comment density with project success. We started \nout with successful projects ignoring unsuccessful projects. It would be interesting to look at the comment \ndensity of failed projects and analyze to what ex\u00adtent commenting behavior of software developers can \nbe a predictor of project success of failure.  6. Related work We did not find many studies of comment \ndensities in open source or software development at all. We found no study that assesses comment density \non the level of scale as pre\u00adsented in this paper. Prechelt reports about a controlled experiment per\u00adformed \nfrom 1997-1999 [4] [13]. 91 teams implemented the same set of requirements using different programming \nlan\u00adguages, including C, C++, Java, Perl and Python. The goal was the comparison of scripting languages \nwith non\u00adscripting languages. In contrast to our results in Section 3, Prechelt found that the scripting \nlanguage solutions were significantly better documented (had a higher comment den\u00adsity) than the non-scripting \nlanguage solutions. Values for the comment densities were in the 20-30% range. Our main explanation for \nthe differences is that the study is just too different from ours. Prechelt s subjects were students, \nand the programs were throw-away exercises. The study is over 10 years old and has a much smaller sample \nsize. May be most importantly, the implementers of the C, C++, and Java versions were paid, while the \nimplementers of the Perl and Python solutions volunteered. In his 2001 M.S. Thesis, Sundbakken assess \nthe com\u00adment density of maintenance phase code contributions to components of four open source projects \n[5]. Sundbakken observes in his data that consistent commenting correlates highly with maintainability \nof the components. The meas\u00adured comment density, however, is much lower than what we have found: It \nranges from 0.09% for poorly maintain\u00adable components to 1.22% for highly maintainable compo\u00adnents. We \nmostly attribute this discrepancy to the small sample size of his study.  In a study on the comment \ndensity of a closed-source compiler project in its maintenance phase, Siy and Votta find a consistent \ncomment density around 50% [6]. In another study of 100 Java open source classes, Elish and Offutt find \nan average comment density of 15.2% with a standard deviation of 12.2% [8]. Again, while closer to our \nnumbers, the small size makes it hard to compare this study with our work. Spinellis assesses the comment \ndensity for four operat\u00ading system kernels, namely FreeBSD, Open Solaris, Linux, and the Windows Research \nKernel [2]. His data is not com\u00adparable with our data nor the data of any of the other studies, as he \nuses a semantic (statement) based definition of com\u00adment density and not a line-based one. The comment \ndensity of the four kernels varies widely. Fluri et al. assess three open source projects (Azureus, ArgoUML \nand JDT Core) and describe how code and com\u00adments co evolve [17]. Specifically, they observe whether \nthe comment density remains stable over time and whether de\u00advelopers maintain a strong commenting discipline \nover a project s lifetime. They also find that open source develop\u00aders consistently comment their code \nbase as 97% of all common changes between source code and comments are in the same revision. Regarding \nthe comment ratio over a pro\u00adject s lifetime they find that it does not stay at a consistent value. In \none case they observe a significant upwards trend while they find a significant downwards trends in the \ntwo remaining projects. However, the small sample size of three projects makes it hard to compare this \nstudy with our work. We did not find any work that discusses how the com\u00adment density of open source \nprojects correlates to other rele\u00advant variables of the involved projects.  7. Conclusions This paper \nshows that successful open source projects are consistently well documented with an average comment density \nof 18.67%. We have found that this comment den\u00adsity varies by programming language but remains invariant \nwith respect to team size and project size (as measured in source code lines). Maybe most importantly, \nwe have found that commenting source code is an integrated activity in the development of open source \nsoftware and not a separate activity or an afterthought. These results shed further light on how open \nsource software is being developed. In future work we will relate it to closed source software development \nto improve corporate software development processes.  8. References [1] Amit Deshpande, Dirk Riehle. \nThe Total Growth of Open Source. In Proceedings of Fourth Conference on Open Source Systems. Springer \nVerlag, 2008. Page 197-209. [2] Diomidis Spinellis. A Tale of Four Kernels. In Proceedings of the 2008 \nInternational Conference on Software Engineering (ICSE 08). IEEE Press, 2008. Page 381-390. [3] Lutz \nPrechelt. Are Scripting Languages any Good? A Validation of Perl, Python, Rexx, and Tcl against C, C++, \nand Java. Advances in Computers 57 (2003). Page 207-271. [4] N. E. Fenton. Software Metrics: A Rigorous \nand Practical Approach. Thomson Computer Press, 1996. [5] Marius Sundbakken. Assessing the Maintainability \nof C++ Source Code. M.S. Thesis, Washington State University, 2001. [6] Harvey Siy, Lawrence Votta. Does \nthe Modern Code Inspection have Value? In Proceedings of the 17th IEEE International Conference on Software \nMaintenance (ICSM 01). IEEE Press, 2001. Page 281-290. [7] Carlo Daffara. How Many Stable and Active \nLibre Software Projects? See http://flossmetrics.org/news/11. [8] Mahmoud Elish, Jeff Offutt. The Adherence \nof Open Source Java Programmers to Standard Coding Practices. In Proceedings of the 6th IASTED International \nConference Software Engineering and Applications (SEA 02). Page 193\u00ad 198. [9] Ohloh, Inc. See http://www.ohloh.net. \n[10] Ohloh, Inc. Ohloh API. See http://www.ohloh.net/api. [11] Ohloh, Inc. ohcount. See http://labs.ohloh.net/ohcount. \n[12] Philipp Hofmann, Dirk Riehle. A Statistic for Calculating Commit Size Probabilities in Open Source \nProjects. Technical Report, forthcoming. [13] Lutz Prechelt. An empirical comparison of C, C++, Java, \nPerl, Python, Rexx, and Tcl for a search/string-processing program. Technical Report 2000-5, Universit\u00e4t \nKarlsruhe, Fakult\u00e4t f\u00fcr Informatik, Germany, March 2000. [14] Amit Deshpande, Dirk Riehle. Continuous \nIntegration in Open Source Software Development. In Proceedings of the Fourth Conference on Open Source \nSystems (OSS 2008). Springer Verlag, 2008. Page 273-280. [15] Barry W. Boehm. A spiral model of software \ndevelopment and enhancement. Computer vol. 21, no. 5 (May 1988). Page 61-72. [16] Kent Beck. Extreme \nProgramming Explained: Embrace Change. Addison Wesley, 1998. [17] B. Fluri, M. W\u00fcmrsch, and H.C. Gall, \n\"Do Code and Comments Co-evolve? On the Relation between Source Code and Comment Changes,\" Proc. 14th \nWorking Conf. Reverse Eng., IEEE CS Press, 2007, pp. 70 79. [18] Oliver Arafat, Dirk Riehle. In Companion \nto Proceedings of the 31st International Conference on Software Engineering (ICSE 2009). IEEE Press, \n2009. Page 195-198.  \n\t\t\t", "proc_id": "1639950", "abstract": "<p>The development processes of open source soft-ware are different from traditional closed source development processes. Still, open source software is frequently of high quality. This raises the question of how and why open source software creates high quality and whether it can maintain this quality for ever larger project sizes. In this paper, we look at one particular quality indicator, the density of comments in open source software code. We find that successful open source projects follow a consistent practice of documenting their source code, and we find that the comment density is independent of team and project size.</p>", "authors": [{"name": "Oliver Arafat", "author_profile_id": "81317490723", "affiliation": "Siemens AG, Corporate Technology, Munich, Germany", "person_id": "P1728317", "email_address": "", "orcid_id": ""}, {"name": "Dirk Riehle", "author_profile_id": "81339524672", "affiliation": "SAP Research, SAP Labs LLC, Palo Alto, CA, USA", "person_id": "P1728318", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1639950.1640047", "year": "2009", "article_id": "1640047", "conference": "OOPSLA", "title": "The commenting practice of open source", "url": "http://dl.acm.org/citation.cfm?id=1640047"}