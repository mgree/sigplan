{"article_publication_date": "10-25-2009", "fulltext": "\n Language Factories Tony Clark Thames Valley University, St. Mary s Road, Ealing, London, W5 5RF, United \nKingdom tony.clark@tvu.ac.uk Abstract Programming languages are the primary mechanism by which software \nis created, yet most of us have access to only a few, .xed, programming languages. Any problem we wish \nto express must be framed in terms of the concepts the pro\u00adgramming language provides for us, be they \nsuitable for the problem or not. Domain Speci.c Languages (DSLs) suggest an appealing escape route from \nthis fate, but since there is no real technology or theory underpinning them, new DSLs are rare. In this \npaper we present the Language Factories vision, which aims to bring together the theory and practice \nneces\u00adsary to realise DSLs in a systematic way. In so doing, we hope to lower the barrier for language \ncreation signi.cantly, ultimately allowing software creators to use the languages most suited to them \nand their needs. Categories and Subject Descriptors D.3.0 [Programming Languages]: General General Terms \nLanguages Keywords Domain speci.c languages 1. Introduction 10 years ago, in his in.uential OOPSLA talk \n[?], Guy Steele made the following statements: ...a good programmer in these times does not just write \nprograms. A good programmer builds a work\u00ading vocabulary. In other words, a good programmer does language \ndesign, though not from scratch, but by building on the frame of a base language. ...from now on, a main \ngoal in designing a language should be to plan for growth. These statements capture two notions. First, \nthat program\u00admers need more than is provided by existing programming Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA 2009, October 25 29, 2009, Orlando, \nFlorida, USA. Copyright c . 2009 ACM 978-1-60558-768-4/09/10... $10.00. Laurence Tratt Bournemouth University, \nPoole, Dorset, BH12 5BB, United Kingdom laurie@tratt.net languages. Second, that programming language \ndesign has generally made little to no attempt to cater for extensibil\u00adity or customisability. Indeed, \nfor most programmers, in most programming languages, the only language extension mechanism available \nis the library1. Libraries have allowed us to create systems of immense complexity and surprisingly high \nreliability, but have the disadvantage that they are vis\u00adibly second-class citizens to language primitives. \nFeatures such as .rst-class functions and run-time meta-programming allow programming languages to be \nbent in slightly different directions, although the room for manoeuvre is still limited [?]. Whatever \nproblem the user is trying to express must ul\u00adtimately be encoded in terms of the limited set of features \nprovided by the original language designer. While we can push at the edges of the padded cells that our \nprogramming languages provide us, the elasticity of the walls is slight and, ultimately, there is no \nway out. DSLs suggest an appealing escape route from the restric\u00adtions of programming languages, enticing \nus with the idea of languages whose syntax and semantics can be customised to our purposes. The motivation \nfor DSLs is well under\u00adstood: they are customised languages which allow classes of related problems to \nbe more quickly and precisely re\u00adalised than with traditional techniques [?]. The potential use cases \nfor DSLs are innumerable, ranging from taming the complexity of enterprise systems (such as J2EE) to \nallow\u00ading non-programmers to express tax law in a precise fashion (as in Intentional Software s tool). \nUnfortunately, in prac\u00adtice, the overhead of creating DSLs is so signi.cant that the idea is generally \nwatered down to mean the clever abuse of existing language features to make literate programming interfaces; \nHudak outlines the reasons for this [?], while the Ruby community has embraced this approach with vigorous \nenthusiasm. In other words, despite the hype, we are basi\u00adcally stuck with libraries for language extension; \nprogram\u00adming languages have restricted us to their cells, while we incorrectly assumed we had new freedoms. \nWe have two fundamental contentions. Our .rst is that DSLs, in their purest form, represent a desire \nfor customis\u00ad 1 Lisp is the obvious counter-example. However, Lisp s minimalistic syntax is core to its \napproach, which then renders it unsuitable for many DSLs which need to drastically manipulate syntax. \n able languages, where syntax is as malleable as semantics, and where we can choose the degree to which \nwe are con\u00adstrained (or not) by existing languages. Our second is that DSLs are a desire lacking a philosophy. \nIt is the latter is\u00adsue to which this paper addresses itself; until, and unless, the underlying mechanisms \nfor reasoning about and creat\u00ading DSLs are improved, their potential cannot be realised. A corollary \nof these two contentions is that, whilst DSLs are the speci.c target of current interest, there is nothing \nwhich fundamentally identi.es a DSL as being distinct from other classes of languages. The main difference \nis that few people have a need to build big languages, and those lucky few are comfortable with traditional \ntechniques; many more people have a need for the small languages that DSLs typically represent. Thus, \nwhile this paper is motivated by DSLs and we expect it to be most frequently applied to DSLs, the ap\u00adproach \nherein is applicable to languages in general, and we frame most of our discussion in terms of generic \nlanguages. 1.1 Where we are today We start this paper from the position that the status quo is not an \noption, for two reasons. First, as Hudak notes, virtually nobody builds pure DSLs because the costs are \nprohibitive [?]. Second, implicit in Steele s talk, is that languages tend to stop evolving as soon as \nthey reach a certain point (typ\u00adically a 1.0 release ). We suggest that the reason that lan\u00adguages stop \nevolving may be because: it s dif.cult to reason about the effects a change to a language will cause \nto both it and existing programs; and, there is little or no support for co-evolving programs with language \nchanges (the TXL language is a rare example of this; it was designed specif\u00adically to allow programs \nwritten in the Turing language to be automatically evolved for a new version of the language [?]). Asserting \nthat the status quo is not an option is only use\u00adful if there are signs that something better could emerge. \nIn recent years, several approaches have emerged which, while not complete in and of themselves, do provide \nsuch signs. We provide a more complete list in Section 6.2, but tech\u00adnologies such as Stratego/XT [?], \nXMF [?], and Converge [?] (the last two of these being by the authors of this pa\u00adper) have shown that \nrelatively powerful DSLs can be im\u00adplemented at relatively low cost providing that the host lan\u00adguage \noffers some key language building technologies. All of these approaches have seen some use in the real-world, \nalthough none has yet had a major impact. However none of these various emerging technologies has any \ngreat concep\u00adtual consistency, and none utilises any kind of theory about DSLs.  1.2 An outline of our \nproposal This paper outlines our vision of Language Factories. In a nut-shell, Language Factories aim \nto make DSL design sys\u00adtematic by allowing languages to be realised from compo\u00adnents which describe fragments \nof syntax, semantics, tool\u00ading capabilities, and so on. By providing a .rm base on which to build languages, \nwe believe that powerful, reli\u00adable, DSLs will be able to be built at signi.cantly lower cost than today \ns ad-hoc approaches. Furthermore, a move to component-based language design offers greater potential \nfor variable implementations of a language, and for the lan\u00adguage to evolve in a predictable manner. \nSection 2 details Language Factories in detail. We are mindful of two considerations in particular: one \nsize rarely .ts all; and jam tomorrow does not sustain life today. To address the former point, Language \nFactories is an abstract concept similar in spirit to design patterns de\u00adscribing a family of related \napproaches; each Language Fac\u00adtory must conform to the basic principles of Language Fac\u00adtories, but can \ndiffer in various aspects. To address the lat\u00adter point, it is possible to create a Language Factory \nwhich, by imposing various restrictions on the languages it can ex\u00adpress, can then realise those languages \nwithin a normal pro\u00adgramming language (Section 2.3 discusses the possible op\u00adtions, and trade-offs, in \ndetail). 2. Language Factories Language Factories are a component-based approach to the de.nition and \nconstruction of languages, as well as associ\u00adated tooling, veri.cation, and so on. Language Factories \nare, at the highest level, an abstract concept, describing a family of related approaches. An individual \nLanguage Factory is a concrete realisation of this concept which makes choices about what languages it \ncan express, how they can be im\u00adplemented, and so on. The common concept across all Lan\u00adguage Factories \nis the language component. 2.1 What is a language? At an abstract level, a language is a means of communica\u00adtion; \nin the case of computing that communication is gen\u00aderally between a human and a machine. In order to \nbe us\u00adable, a language needs to have a way that participants can share communications (syntax) and an \nagreed shared mean\u00ading (semantics). Languages may form parts of larger lan\u00adguages (e.g. the sub-part \nof English used only in computing could be detached and reattached to the main language); they may be \nparameterisable (e.g. American and British English can be seen as variations on the single, abstract, \nlanguage English); they may have variable syntaxes (e.g. Serbian is written in both the Cyrillic and \nLatin alphabets); and so on. As far as is practical, the Language Factories concept tries not to be prescriptive. \nAt a minimum, a language needs a syntax in which to express it (even if it is in a generic XML\u00adlike format) \nand an accompanying semantics of sorts (which can range from a formal mathematical de.nition, to the \ndescription of a translation into C). Exactly what form the syntax and semantics take is left to an individual \nLanguage Factory.  C Pascal Java Smalltalk XMF Converge MetaLua Stratego/XT Syntax modi.cation .... \n. Syntax extension ....  Introspection ..  n/a Self-modi.cation ...  n/a Intercession ...  n/a Compile-time \nmeta-programming Partial ... n/a Traceability ..... . n/a Table 1. A summary of some of the features \nin contemporary programming languages relevant to Language Factories. 2.2 Language Components Language \nFactories break languages down into components, including the following parts: Abstract syntax The single \nde.nition of its Abstract Syntax Tree (AST). Concrete syntax(es) and syntactic mapping A de.nition of \nits concrete syntax(es) speci.ed as e.g. a context free grammar, and a mapping from that concrete syntax \nto the abstract syntax. Semantic aspect(s) Each semantic aspect de.nes (a possi\u00adbly incomplete part of \nthe) semantics. Semantic aspects may overlap with each other (e.g. an operational and de\u00adnotational semantics) \nor describe completely different el\u00adements of the semantics (e.g. semantics of language types and semantics \nfor text editors supporting tool-tips). Constraints Describes constraints on how the language can be \ncomposed with others (both in terms of what the com\u00adponent provides, and what it requires of other compo\u00adnents). \nAn individual Language Factory can decide which of the above parts are optional or mandatory, and which \ncombi\u00adnations are illegal. For example, a Language Factory may require only the concrete syntax to be \nde.ned, in order to al\u00adlow the testing of syntactic composition; however, if a com\u00adponent wishes to de.ne \nsemantics aspects, it will have to de.ne the relevant parts of the abstract syntax. The granularity of \ncomponents is left open to users; at its crudest, a component could be an entire language. Ideally, of \ncourse, one would like language components to capture smaller, reusable, aspects of languages. For example, \nmany DSLs integrate expression languages [?]; since expression languages vary relatively little, it is \nfeasible to share a single expression language across many larger languages [?]. Lan\u00adguage components \nneed not be .xed and immutable; just as with language libraries, the designer of a language compo\u00adnent \ncan trade implementation expense with .exibility.  2.3 Realizing Language Factories We have, until this \npoint, been deliberately abstract about how Language Factories could be realised. The reason for this \nis simple: Language Factories can be realised using dif\u00adferent formalisms, tools, and with varying degrees \nof au\u00adtomation. The approach is a spectrum whose extreme posi\u00adtions can be thought of as virtual and \nidealised. At the virtual end, languages are speci.ed but not implementable; at the idealised end, they \nhave their own fully bespoke implemen\u00adtations. These two extremes also, in a sense, represent the status \nquo: specifying a language is relatively easy (a vir\u00adtual language), but providing a stand-alone implementation \nis hard (hence idealised). Fortunately, the many shades of grey between the two extremes are both meaningful \nand useful. In particular, we are keen that Language Factories can be realised using ex\u00adisting infrastructure \n(chie.y through currently available lan\u00adguages) when practical; this cuts down on implementation costs \nand also lowers the interoperability burden. Doing so inevitably involves some compromises, which depend \non the language targeted. As an example of the compromises that need to be considered, Table 1 shows \na representative se\u00adlection of languages that are compared in terms of relevant features. Each Language \nFactory needs to consider what fea\u00adtures it requires of a target language. For example, syntax extension \ndescribes whether a language can allow new syn\u00adtaxes to be naturally embedded within it; languages which \nallow this can directly express embedded languages; lan\u00adguages which do not allow this have to be translated \ninto an intermediate form without the extension. Similarly, trace\u00adability describes whether a language \ncan trace the trans\u00adlated version of an embedded language; languages which do not allow this are likely \nto present many more challenges when debugging both Language Factory implementations, and programs written \nin it. In some cases, such compromises will not be acceptable, and a bespoke implementation of the Language \nFactory may be the best route. 3. An example Language Factory and case study In order to make the description \nof Language Factories con\u00adcrete, in this section we present an imaginary Example Lan\u00adguage Factory (ELF) \nand a case study in it. ELF is a sim\u00adple Language Factory intended to specify behavioural lan\u00adguages, \nusing relatively traditional grammar speci.cations, and allowing language components to have both an \nopera\u00adtional semantics and a semantics via a translation into Java.  The case study is based on the \nlanguages needed to specify different aspects of an aircraft s systems; for obvious space reasons, we \nare only able to tackle a small part of this in detail in this paper. 3.1 ELF language de.nition ELF \nis a simple, but powerful, Language Factory for de.n\u00ading certain classes of textual languages. In particular, \nit pro\u00advides practical support for composition of components, and allows running Java implementations \nto be produced from ELF language components. ELF itself uses a simple inden\u00adtation based syntax, with \nthe general syntax of an ELF lan\u00adguage component being as follows: lang: ast: ... grammar: ... semantics \neval(env): ... semantics java: ... constraints: ... In ELF, the grammar clause is mandatory, but all \nother clauses are optional. The ast clause is typically very sim\u00adple, detailing the AST constructors \nrequired. The grammar clause allows grammars to be speci.ed via a largely stan\u00addard EBNF syntax from \nwhich ASTs are created; ELF as\u00adsumes that implementations use an Earley parser [?], so that any context \nfree grammar can be used. An ELF lan\u00adguage component may de.ne semantics either operationally (through \nthe eval clause) or via a translation to Java (the java clause). The operational semantics references \nan en\u00advironment associating variable names with values. The Java translation uses quasi-quotes [?] to \nrepresent code templates (generating Java code as an AST, not as a string). Both semantics clauses are \ndriven by pattern matching. Finally, the constraints sub-clause within the java clause allows a component \nto specify its expectations about elements in the target Java environment. 3.2 The case study Our case \nstudy involves a .ctional, large aerospace company that is working on the design and implementation of \nan air\u00adcraft. The life-cycle of an aircraft project is lengthy and com\u00adplex; many different aspects need \nto be precisely speci.ed, implemented, evaluated, and altered. Such a project ideally requires a diverse \ncollection of languages to support various parts of the life-cycle such as: planning; requirements; speci\u00ad.cation; \nimplementation; testing; deployment; manufacture; and so on. Traditionally, a handful of small languages \nare co-opted to perform a wider variety of tasks than they are ideally suited to, with many of those \nlanguages being only informally speci.ed. The fundamental question is therefore: can Language Factories \nhelp to quickly create robust lan\u00adguages that support the aircraft project life-cycle? To make this both \nconcrete, and tractable within the space con.nes of the paper, we concentrate on the speci.cation aspect \nof the aircraft life-cycle, where both the hardware and software components of the system need to be \nprecisely speci.ed. This requires a language that can specify compo\u00adnents and can specify both the differing \nstates that the com\u00adponents can be in over time, and how it moves between them. For example, the landing \ngear of a plane is a distinct compo\u00adnent that is either deployed, stowed, or moving. The speci.\u00adcation \nof a landing gear component sets an initial height and speed; as the height and speed change, or the \npilots issue new instructions, the landing gear will move through differ\u00adent states. We would therefore \nlike to specify the landing gear as follows (we have elided several transitions in the in\u00adterests of \nbrevity): component Landing_Gear(height:int, speed:float) { stm { state Moving_Up state Moving_Down state \nDeployed state Stowed transition up from Deployed to Moving_Up height_change[height>500ft and speed>100kn/s] \ntransition down from Stowed to Moving_Down deploy } } Most of the above speci.cation is fairly intuitive. \nA land\u00ading gear has an initial height and speed (both of which will change as the plane speeds up and \nslows down). Transitions have a name (e.g. moving up) and specify a move from one transition to another, \nconditional on a named event occur\u00adring, and an (optional) guard being satis.ed, with the latter two \nelements syntax being event [guard ]. There are many different ways in which we could create a language \nto implement the above. The traditional approach would be to create a single language which captures \nall of the above features, bringing all the problems and costs noted in Section 1.1. However there are \nclearly different aspects to the language which can be teased apart: a super\u00adstructure that de.nes aircraft \ncomponents; a state machine language (which has little to do with aircraft components as such); and an \nexpression language which can express lengths and measures. In the following section we show how Language \nFactories can make the process of building this sort of language systematic, reliable, and realistic \nby breaking the language down into separate components, many of which are likely to already exist when \nsuch a language is created.  3.3 A reusable expression language The .rst language component we de.ne \nis a generic expres\u00adsion language, Expr. In order that we can show a suf.cient breadth of the case study, \nwe present a simpli.ed version of the expression language, concentrating on variables, ad\u00addition arithmetic, \nand integers extrapolating the rest of the expression language from these examples is mechanical and \nlargely trivial. Expr s AST is simple, requiring little expla\u00adnation:  lang Expr: ast: Var(Str) Add(Expr, \nExpr) Num(Int) The grammar for this component is as follows: grammar: expr -> name:Id <Var(name)> | lhs:expr \n+ rhs:expr <Add(lhs, rhs)> | num:Int <Num(num)> The core of an ELF grammar is EBNF, with AST construc\u00adtors \ncontained between angled brackets. Terminals and non\u00adterminals can be pre.xed with a name, followed by \na colon, which allows that element to be referred to in the AST con\u00adstructor. We can now easily give \nan operational semantics to Expr: semantics eval(env): Var(x) -> lookup(env, x) Add(x, y) -> eval(x, \nenv) + eval(y, env) Num(x) -> x The operational semantics of expressions is de.ned with respect to an \nenvironment of variables env which maps names to values. The semantics consists of a series of de.ni\u00adtions, \nfrom AST patterns (on the LHS) to integer expressions (on the RHS). For example, the .rst rule of eval \nmatches against a variable and speci.es that its semantics are given via the pre-de.ned lookup function, \nwhich returns the value of x in the environment env. As in the above, semantics clauses can always recursively \ncall themselves via a function of the same name as the clause (i.e. eval in the above). Note that while \nELF s operational semantics uses a .xed collec\u00adtion of data values and operators (e.g. integers and addition), \n[?], [?], and others have shown how language semantics can be made modular through the use of techniques \nincluding monads and labelled natural semantics systems, all of which could be included in a Language \nFactory. Since Expr is intended to be reusable, and since Java does not allow operator over-loading, \nwe cannot translate Expr types directly into Java base types, as this would not allow new types to be \nadded to Expr. This is a standard example of the sort of real-world compromise that choosing an existing \nprogramming language as a target can impose. We are therefore forced to construct a new type hierarchy \nwhose root is ExprObj, with concrete sub-classes such as ExprInt and so on. The Java semantics therefore \nlooks as follows: semantics java: Var(x) -> [j| ${x} |] Add(x, y) -> [j| ${java(x)}.plus(${java(y)}) \n|] Num(x) -> [j| new ExprInt(${x}) |] constraints: exists_class(ExprInt) exists_class(Expr) exists_static_method(Expr,plus) \n Similarly to the operational semantics, the Java semantics is a series of de.nitions, from ELF patterns \nto Java ASTs. The latter can be built manually when necessary but, in general and as in the above example, \nbe expressed by quasi\u00adquoting. Quasi-quoting is a well understood technique (see e.g. Stratego/XT [?]) \nwhich allows abstract syntax to be expressed via concrete syntax expressed by quasi-quotes [| ... |]. \nIn the above example the j in the quasi-quotes makes explicit that the AST being built by these particular \nquasi-quotes is a Java AST. Insertions ${...} allow ASTs to be built out of smaller chunks, or for ELF \nvalues to be lifted to their Java AST equivalent (so ${2} creates a Java AST integer whose value is 2; \nsee [?] for more details of lifting). The constraints within the Java semantics are on the eventual Java \nprogram. ELF provides various prede.ned constraints: exists class(C ) asserts that the Java system in \nwhich the ELF component is translated into must have a class called C ; exists static method(C, M ) asserts \nthat the Java system in which the ELF component is translated into must have a static method M in the \nclass C . A more complete Language Factory would allow more complex constraints to be de.ned; the above \nshould however give a suf.cient .avour.  3.4 Measurement types The reusable expression language in the \nprevious section is missing one data type commonly needed in languages used in aircraft: a simple means \nof expressing measurements. In this subsection we de.ne a very simple language component which allows \nexpressions of the type 3kn/s (to be read as three knots per second ) to be de.ned. The component itself \nis very simple, using exactly the same concepts as Expr (in the interests of brevity, we elide the operational \nsemantics): lang Measurement: ast: Ft(Float) KnPerH(Float) MiPerH(Float) grammar: measure -> dst:float \nft <Ft(dst) | dst:float kn/h <KnPerH(dst)> | dst:float mph <MiPerH(dst)> semantics java: Ft(x) -> [j| \nnew ExprFeet(${x}) |] KnPerS(x) -> [j| new ExprKnPerH(${x}) |] MiPerS(x) -> [j| new ExprKnPerH(${x*0.869}) \n|] constraints: exists_class(ExprFeet) exists_class(ExprKnPerH) We can now compose Expr and Measurement \ntogether to produce a new expression language which can also express measurements. There are many different \npotential forms of composition and different Language Factories can provide composition operators which \ndiffer signi.cantly in detail; in this case we can use ELF s simple composition operator:  merge(l1, \nl2, grammar:{...}, semantics:{...}) that merges l1 and l2 to produce a new language. In essence, merge \nconstructs the union of the two languages in terms of their grammar and semantic rule-sets. The grammar \nand semantics parameters allow additional grammar and semantic rules to be added into the merged language, \ngluing the two sub-languages together. For example, grammar:{R1 -> R2} speci.es that in the merged language, \nthe grammar rule R1 should have a new alternative added that references R2. The semantics: parameter \nhas a similar effect. For an expression language with measurements, merge is used as follows: ExprMeasurement \n= merge(Expr, Measurement, grammar:{Expr::expr -> Measurement::measure}, semantics:{}) In this case the \nmerge of the two languages is simple, with only a reference needed from Expr s expr rule to the measure \nproduction. While simple conceptually, this type of composition is a fundamental part of Language Factories, \nallowing language components to be reused and customised, even in ways that their original authors might \nnot have anticipated.  3.5 A parameterisable language for statemachines Aircraft components are frequently \nspeci.ed by statema\u00adchines. In this section we show a simple example of a generic statemachine, whose \nguard language can be parametrised via the guard lang parameter. The language elements (ast, grammar, \nsemantics) of the parameter can be used in ap\u00adpropriate places within the body of StateMachine: lang \nStateMachine(guard_lang:Component): ast: STM([State | Transition]) State(Str) Transition(Str,Str,Str,Str,guard_lang.ast) \ngrammar: STM -> stm { elems:(State | Transition)* } <STM(elems)> State -> state name:Id <State(name)> \nTransition -> name:Id from:Id to:Id event:Id [ guard:guard_lang.grammar ] <Transition(name,from,to,event,guard)> \nsemantics java: STM(states, transitions) -> [j| class ${freshname()} { States state; enum States {${states}}; \n${self(transitions)}; } |] Transition(name, from, to, event, guard) -> [j| @Transition public void ${name}(Event \nev) { if (self.state == ${from} &#38;&#38; ev == ${event} &#38;&#38; ${guard_lang.semantics.java(guard)}) \n{ self.state = ${to}; return true; } return false; } |] While the above is relatively detailed, we hope \nthat most of it is, given what has come before, relatively intuitive. Note the use of the guard lang \nparameter of type Component (for the avoidance of doubt, this type denotes a Language Fac\u00adtory language \ncomponent). The StateMachine component includes the AST of the guard language as a component of the transition \nconstructor and the guard language s start non\u00adterminal is used to parse this element of a transition \ns con\u00adcrete syntax. The Java translation semantics for a transition calls the guard language s Java translation \nsemantics. The advantage of de.ning the state-machine language in this way is that, since we know that \nstatemachine languages often require subtly different expression languages, we can make that parametrisation \neasy. At its simplest, a user can pass the vanilla Expr language component as the parameter: ExprSM = \nStateMachine(Expr) In our case study however, we wish to use the expression lan\u00adguage including measurements, \nso we instantiate a statema\u00adchine language as follows: ExprMeasurementSM = StateMachine(ExprMeasurement) \nWith the ExprMeasurementSM language, we can now ex\u00adpress fairly complex state machines, and use guards \nsuch as x < 10kn/h. Merge (see Section 3.4) and parametrisation are related forms of language customization, \neach having its advan\u00adtages and disadvantages. When a very speci.c instance of variability is known in \nadvance, parametrisation is attractive as it makes the location and impact of the variability ex\u00adplicit. \nWhen a type of customisation is needed that could not have been originally envisaged or if the type \nof customi\u00adsation required is more sophisticated than parametrisation can achieve then composition comes \ninto play. There are inevitable shades of grey between the parametrisation and composition, and users \nof Language Factories will have to use their own judgement to decide when each is appropriate.  3.6 \nA language for components Finally, we de.ne a component ACComponent (AirCraft Component) which provides \na standard way of expressing an aircraft component: each has a name and is instantiated with a list of \nvariables which become the components at\u00adtributes; the body of the aircraft component is not speci.ed \nand is passed as a parameter to ACComponent. lang ACComponent(body_component:Component): ast: Component(Str,[Var],body_component.ast) \nVar(Str, Str) grammar: component -> component { name:id vars:var* body:body_component.grammar } <Component(name, \nvars, body)>  var -> name:id : type:id <Var(name, type)> semantics java: Component(name, vars, body) \n-> [j| @Component class ${name} { ${java(vars)} ${body_component.semantics.java(body)} } |] Var(name, \ntype) -> [j| ${type} ${name} |] One item of note in the above is that since ACComponent does not know \nthe name of the top-level AST element in the language component body component, it cannot be referred \nto directly; instead it makes use of the fact that each language component s AST slot refers implicitly \nto the top-level AST element. The same mechanism is used to link the grammar of the body component into \nACComponent s grammar. Finally we can instantiate a statemachine component, giv\u00ading us the language component \nwith which we can express the landing gear example of Section 3.2: AicraftDesign = ACComponent(ExprMeasurementSM) \n4. Beyond traditional syntax and semantics Traditionally we think of languages as a combination of syn\u00adtax \nand semantics and, up until this point, Language Fac\u00adtories have largely been couched in those terms. \nHowever modern software practices make use of both wider and nar\u00adrower knowledge of languages than these \nnotions capture. For example, modern IDEs can perform on-the-.y partial compilation (requiring sophisticated \nknowledge of the lan\u00adguage that a traditional semantics does not need to bother with) and perform code \ncompletion (which requires under\u00adstanding a tractable static subset of the language s seman\u00adtics). Let \nus take a simpler example: syntax colouring. It is hard for many of us now to remember the old days when \nprogramming meant looking at semi-intelligible green pix\u00adels on a charcoal grey background: syntax colouring \nhelps our brain to interpret source code more quickly than before. In order to make syntax colouring \npractical, AST elements need to be ordered into groups so that colouring can be ap\u00adplied to groups. An \nextension of ELF could easily cater for this by allowing language components to specify a colouring clause \nalong the lines of: colouring: group String: ASCIIString, UnicodeString group Number: Int, Float, Fractional \nThis information could then be used to automatically gener\u00adate the necessary .les needed to integrate \ninto an IDE. Sim\u00adilarly, clauses for any other desired tooling related require\u00adments can be de.ned by \na Language Factory as required. 5. Meta-Language Factories It is often said that the .rst test of a programming \nlanguage is whether a compiler for it can be written in the language it\u00adself (thus .nishing the bootstrapping \nof the language). Lan\u00adguage Factories do share many similarities to programming languages and compilers, \nso an important question to ask is whether a Language Factory could be used to produce other Language \nFactories. The answer is clearly yes : Language Factories can specify and implement other Language Fac\u00adtories. \nWhen a Language Factory is used to realise another Language Factory we refer to it as a meta-Language \nFac\u00adtory2. We do not envision that there will be a single meta-Language Factory, since Language Factories \nas a concept is in many ways more similar to (loose) design patterns than (strict) formal languages: \ndifferent classes of Language Fac\u00adtories will require different meta-Language Factories. 6. Discussion \nand comparison 6.1 Advantages of Language Factories There are two ways in which we imagine Language Facto\u00adries \nshaping the future. First, and most obviously, Language Factories make the design and implementation \nof new lan\u00adguages (mostly in the form of DSLs) a realistic prospect for a much greater number of people \nthan was previously the case. By making language components reusable, param\u00adeterisable, and composable, \nLanguage Factories can signi.\u00adcantly reduce the burden associated with language creation. Second, and \nthinking further ahead, Language Factories offer the potential to provide a new level of abstraction \nover libraries and frameworks, which are forced to express, often complex, domain speci.c information \nthrough the strait\u00adjacket of normal programming languages. As shown by Stratego/XT [?], adding syntax \nand semantics speci.c to a library or framework can make using it signi.cantly eas\u00adier. As shown in the \ncase study, since Language Factories can target existing programming languages, they provide all the \nnecessary tools to make this a practical reality.  6.2 Comparison to related approaches There are several \nexisting techniques, tools, and languages to which Language Factories can be compared. MDA [?] and Software \nFactories [?] both share similar\u00adities of outlook with Language Factories, being (at least in part) based \non the idea of building systems from compo\u00adnents. However neither vision has yet been realised, in part, \nwe assert because of the overly general problem they attempt to tackle: automating the process of building \narbitrary soft\u00adware systems still seems to be immensely hard. Language Factories tackle a more tractable \nproblem since, as we have shown in this paper, languages often naturally decompose into components and \nthe formalisms underlying languages are relatively well developed and understood, even if they have rarely \n(before Language Factories) been explicitly in\u00adtegrated together. 2 Note that meta is a relative term \nin this instance: there is no notion of an absolute meta-Language Factory.  Extensible programming languages \nsuch as Lisp and Converge typically use compile-time meta-programming (often called macros , although \nthat is more properly thought of as a speci.c form of compile-time meta-programming) to allow programs \nto embed different syntaxes and have them transformed into the base language. This class of lan\u00adguages \nis homogeneous in the sense that the language used to specify the transformation is the same as the language \nbeing translated into [?]. Homogeneous languages by their very nature are restricted to a single host \nlanguage; while this tight coupling can bring bene.ts (see [?] for details), it is also inherently limiting. \nIn their particular .eld, ho\u00admogeneous languages will inevitably outperform Language Factories; however, \nbecause they need not be tied to any par\u00adticular language, Language Factories .eld is so much larger \nthat the overlap is almost trivial. AST-based systems such as JetBrain s MPS3 and Inten\u00adtional s tool \n4 both work on the basis that users edit AST s, not text (i.e. both are syntax directed editors which \ndo not al\u00adlow the user to enter ill-formed ASTs). Fundamentally, both systems require programs written \nin their languages to be edited exclusively in their tools. While both go out of their way to make such \nediting more pleasant than previous gen\u00aderations of syntax directed editors, this is a serious restric\u00adtion: \nit restricts some types of additional tooling; it hampers interoperability; and quite possibly alienates \nmany potential users before they have even started. While some Language Factories may choose to use syntax \ndirected editing, with the inevitable accompanying restrictions, most Language Facto\u00adries are unlikely \nto choose to be so prescriptive. Perhaps the closest extant technology to Language Fac\u00adtories are the \nterm rewriting systems, the most advanced of which is arguably Stratego/XT [?]. Like Language Facto\u00adries, \nStratego/XT can arbitrarily compose together syntaxes, and are not restricted in the languages they compose \nor the languages they translate into (see e.g. [?] for a large scale example). Unlike Language Factories, \nStratego/XT has lit\u00adtle or no knowledge of the semantics of the languages it is expressing: it is easy \nto build nonsensical intermediate rep\u00adresentations, which can then cause chaos when debugging. Perhaps \neven more fundamentally, Language Factory lan\u00adguage components have signi.cant semantic information at\u00adtached \nto them (e.g. constraints on the components they can be composed with), making the composition of such \ncompo\u00adnents much more well-de.ned than the ad-hoc composition found in current term rewriting systems. \n7. Conclusions In this paper we presented the Language Factories vision. Language Factories can perhaps \nbest be thought of as be\u00ading similar to design patterns, describing a family of related approaches to \ncomponent-based language building. We ex\u00adplained, via a case study, how one particular Language Fac\u00adtory \nallows powerful languages to be built in a far more sys\u00adtematic, .exible way than any existing approach. \nAcknowledgments Thanks to Naveneetha Vasudevan for insightful comments on a draft of this paper. 3 http://www.jetbrains.com/mps/ \n4 http://www.intentsoft.com/    \n\t\t\t", "proc_id": "1639950", "abstract": "<p>Programming languages are the primary mechanism by which software is created, yet most of us have access to only a few, fixed, programming languages. Any problem we wish to express must be framed in terms of the concepts the programming language provides for us, be they suitable for the problem or not. Domain Specific Languages (DSLs) suggest an appealing escape route from this fate, but since there is no real technology or theory underpinning them, new DSLs are rare. In this paper we present the Language Factories vision, which aims to bring together the theory and practice necessary to realise DSLs in a systematic way. In so doing, we hope to lower the barrier for language creation significantly, ultimately allowing software creators to use the languages most suited to them and their needs.</p>", "authors": [{"name": "Tony Clark", "author_profile_id": "81100621442", "affiliation": "Thames Valley University, London, United Kingdom", "person_id": "P1728347", "email_address": "", "orcid_id": ""}, {"name": "Laurence Tratt", "author_profile_id": "81316491200", "affiliation": "Bournemouth University, Bournemouth, United Kingdom", "person_id": "P1728348", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1639950.1640062", "year": "2009", "article_id": "1640062", "conference": "OOPSLA", "title": "Language factories", "url": "http://dl.acm.org/citation.cfm?id=1640062"}