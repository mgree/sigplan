{"article_publication_date": "10-25-2009", "fulltext": "\n Towards Automation of Iteration Planning Jonas Helming Maximilian Koegel Zardosht Hodaie Technische \nUniversit\u00e4t M\u00fcnchen Technische Universit\u00e4t M\u00fcnchen Technische Universit\u00e4t M\u00fcnchen Institut f\u00fcr Informatik \nInstitut f\u00fcr Informatik Institut f\u00fcr Informatik Chair for Applied Software Engineering Chair for Applied \nSoftware Engineering Chair for Applied Software Engineering Boltzmannstrasse 3, 85748 Garching Boltzmannstrasse \n3, 85748 Garching Boltzmannstrasse 3, 85748 Garching helming@in.tum.de koegel@in.tum.de hodaie@in.tum.de \nAbstract Iterations are time-boxed periods with an intended outcome that is often a set of implemented \nrequirements. Iterations are part of most common software development lifecycle models. Planning of iterations \nis a non-trivial task due to the multi-dimensional criteria. (1) The first dimension concerns the question \nwhat shall be completed in the iteration, also referred to as release plan\u00adning . Decisions in this dimension \nare based on criteria such as dependencies and priorities of requirements. (2) The second di\u00admension \nconcerns the decision, which project participant should work on which task, also referred to as task \nassignment . Deci\u00adsions in this dimension are based on criteria such as the expertise and the workload \nof the developers. The decisions in both dimen\u00adsions are considerably complex. Therefore several approaches \nexist to semi-automatically support the decisions limited to one of the two dimensions mentioned above. \nNone of the existing ap\u00adproaches considers both dimensions at the same time. In this pa\u00adper we propose \na combination of approaches from semi-automatic release planning and from semi-automatic task assignment. \nThis results in a semi-automated two-dimensional solution for the problem of iteration planning, We suggest \nthe use of a genetic algorithm to optimize the resulting iteration plans in both dimen\u00adsions of the problem. \nCategories and Subject Descriptors D.2.9 [Management] General Terms Algorithms, Management Keywords Release \nplanning, Iteration planning, Semi\u00adautomated, Genetic algorithm, Task assignment, Unicase, unified model, \nMachine learning 1. Introduction There is an increasing trend to develop software iteratively and deliver \nit in an incremental fashion [1]. Iterations are time-boxed periods with an intended outcome that is \noften a set of require\u00adments to be implemented. If this outcome is a piece of software deliverable to \nthe customer it is called a release. Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor profit or commercial advantage and that copies bear this notice and the full cita\u00adtion on the first \npage. To copy otherwise, or republish, to post on servers or to redis\u00adtribute to lists, requires prior \nspecific permission and/or a fee. OOPSLA 2009, October 25 29, 2009, Orlando, Florida, USA. Copyright \n&#38;#169; 2009 ACM 978-1-60558-768-4/09/10 $10.00. There are several advantages of iterative development \nover a traditional sequential approach like the waterfall model ([1]). On the one hand it is possible \nto provide parts of the system to the customer early and receive feedback. On the other hand iterative \napproaches are more flexible in planning. Release planning ad\u00addresses decisions related to selecting \nand assigning features to create a sequence of consecutive product releases that satisfies important \ntechnical, resource, budget, and risk constraints ([2]). Release planning is done based on a variety \nof criteria. First, pri\u00adorities given by different stakeholders and the importance of these stakeholders \nfor the project must be considered. Second, there are several constraints like dependencies between requirements \nand the available effort for the planned iteration. In section 3 we will describe these decision criteria \nin detail. Bagnall et all ([3]) showed that the problem of release planning is NP hard even without any \ndependencies between requirements. Consequently there are several approaches, manually and semi-automatically \nsupporting the activity of release planning. Du et all ([4]) could even show in case studies that automatic \napproaches can perform better then manual ones. Section 2 gives an overview over exist\u00ading solutions. \nOne important decision criterion considered by most of the ex\u00adisting approaches is the availability of \nresources for the planned iteration. This means that the estimated effort for different re\u00adquirements \non one hand and the available manpower on the other hand constraint the selection of requirements for \nthe upcoming release. In existing approaches the available manpower is consid\u00adered as a static value, \nderived from the duration of the correspond\u00ading iteration and from the number of developers. We claim \nthat this is an inadequate simplification. It is based on the assumption that every requirement could \nbe implemented with equal effort by any participant of the developer team. But in reality the assignment \nof tasks is just another complex dimension of the iteration planning problem. It can be solved based \non crite\u00adria such as the individual workload and expertise. Consequently there are several approaches \nto semi-automatically assign given tasks to project participants (e.g. [5]). We describe related existing \nsolutions in section 2. The result of task assignment directly influ\u00adences iteration planning. For example, \nit might be better to sched\u00adule an important requirement to a later release if the most experienced developer \nis overloaded in the current iteration. In this paper we propose a concept to combine semi-automatic \nrelease planning with semi-automatic task assignment. We sug\u00adgest to apply a neural network to create \na list ordered by expertise for the assignment of every requirement. Second we apply a ge\u00adnetic algorithm \nsuch as [1] to optimize the release plan. The com\u00adbined result is a plan of iterations, including the \ninformation, which developer is working on which requirement in which itera\u00adtion. The project manager \ncan evaluate and if required manually adapt the automatically generated iteration plan. As we need to \nprocess artifacts from the system model (i.e. requirements) as well as artifacts from the project management \nmodel (i.e. tasks, stakeholders, developers and iterations), we base our approach on a unified model. \nThe unified model includes all required artifacts in one repository. The approach is currently being \nimplemented. This paper describes the underlying ideas and concepts as well as the planned evaluation. \n The paper is organized as follows: Section 2 describes existing approaches to release planning and \nto task assignment. Section 3 details the problem of iteration planning and describes the consid\u00adered \nconstraining criteria. Section 4 briefly describes the unified model our approach is based on. Section \n5 describes the concept for our proposed approach based on a genetic algorithm. Section 6 describes how \nwe plan to evaluate the proposed approach.  2. Related work There are two groups of existing approaches \nfor semi-automated planning, following its two dimensions: release planning and task assignment. None \nof the existing approaches combines these two. 2.1 Release planning Du et al. [4] compare manual and \noptimization based release planning based on three experiments. They find that optimiza\u00adtion-based approach \ncan lead (for small-scale problems han\u00addling 20 to 30 requirements) to better release plans in terms \nof time, number of violated constraints, and quality, but there is no significant difference in trust \nusers have in manual plans and optimization-based plans. Bangnal et al. [3] show that finding a provably \noptimal solution for next release problem is NP-hard. They tried to find a possibly suboptimal but good \nquality solutionusingarangeofmodernheuristicalgorithms. Greer et al. [1] introduces a new decision support \nsolution for release planning. This solution uses a genetic algorithm to map a set of requirements to \ndifferent iterations, considering priority of requirements from stakeholder's perspective and effort \nestimation to implement them. Saliu et al. [6] suggest a bi\u00adobjective optimization approach to find Pareto-optimal \nrelease plans regarding business perspective and implementation per\u00adspective. The approach proposed in \nthis paper considers the interdependencies between software components in solution domain (SD-coupling), \nwith the assumption that implementing SD-coupled component at the same release can reduce cogni\u00adtive \neffort during implementation and save development efforts. 2.2 Task assignment Most of task assignment \napproaches are based on analyzing software repositories (such as bug tracking systems or version control \nsystems) using mostly machine learning techniques. Canfora et al. [7] demonstrate how information retrieval \ntech\u00adniques can be applied on software repositories (bug repositories and CVS) to create an index of \nsource files used for impact analy\u00adsis, and an index of developers used for assignment of change requests. \nAnvik [8] investigates precision of a task assignment recommender using different machine learning algorithms \napplied to an open bug repository. Anvik et al. [9] apply a machine learn\u00ading algorithm (text categorization) \nto the open bug repository to learn the kinds of bug reports each developer resolves, and sug\u00adgests the \nappropriate developer to resolve new bugs reports. They reached precision levels of 57% and 64% on the \nEclipse and Fire\u00adfox development projects respectively, and find this result promis\u00ading for further research. \nCubranic et al. [10] describe an application of supervised machine learning using a naive Bayes classifier \nto automatically assign bug reports to developers. Mockus et al. [11] try to determine expertise about \na work product by counting related commits made by different organization units in a version control \nsystem. Yingbo et al. [12] apply a machine learning algorithm to workflow event log of a workflow system \nto learn various kinds of activities each actor undertakes and sug\u00adgesting appropriate actor to assign \nnew tasks. Wei\u00df et al. [13] apply data mining techniques to issue tracking system to predict effort estimation \nof new issues based of existing similar issues.  3. Problem description In this chapter we describe \nthe decision criteria influencing the activity of planning iterations. The criteria are derived from \nthe two dimensions of the problem: release planning and task assign\u00adment. 3.1 Requirements Considering \nthe release planning dimension, an iteration is a set of requirements which must be implemented. Requirements \nare subject to the interest of stakeholders and are prioritized by them. Stakeholders can be divided \ninto external stakeholders (such as customers) and internal stakeholders (such as developers or pro\u00adject \nmanagers) [14]. External stakeholders are mainly concerned about the application domain and hence about \nthe requirement set implemented in the iteration. On the other hand internal stakeholders are mainly \nconcerned about the solution domain and hence about analysis and implementation aspects such as the de\u00adpendency \nbetween requirements and resources consumed by the implemention. Based on these concerns every stakeholder \nassigns a priority to a requirement. A requirement can have multiple stakeholders interested in it and \nassiging different priority values to it. The priority of a requirement will the average of all priority \nvalues assigned to it by its stakeholders ([1]). Another concern about requirements is the dependency \nrela\u00adtionship between them. Dependency relationships can force one requirement to be planned for implementation \nin an earlier itera\u00adtions than another. It is also desirable that interdependent re\u00adquirements are implemented \nin same iteration to save development efforts ([1]). In this sense dependencies between requirements \nare a constraint which must be considered in a solution for release planning. 3.2 Tasks Based on the \nidentified requirements the project manager creates a set of related tasks. There are also existing tasks \nthat might be related to the requirements. Every task has an esti\u00admate, is assigned to a developer and \nis planned for an iteration. In our model an iteration is a set of tasks. The purpose of iteration planning \nis to assign each of these tasks to a developer and plan it to be implemented in a certain iteration. \nA requirement is considered fully implemented as soon as all of its related tasks are accomplished. \n 3.3 Resources The main resource considered in our approach is developer. There are two constraints on \nthis resource: Workload: In every iteration a set of tasks is assigned to each developer. The sum of \nthe estimates of these tasks will be the workload of the developer. The work load of a developer must \nbe less than or equal to the available time he/she has during each iteration.  Expertise: A developer \nshould have expertise regarding his/her assigned tasks. Expertise is measure of how familiar a developer \nis with the assigned task. This can be determined based on tasks the developer has already implemented. \nIt is assumed that a developer is more experienced to implement a task if he/she has already implemented \nother relat\u00ading/dependent tasks. The dependency and refinement relation\u00adship between requirements can \nbe used to extract related tasks within a hierarchy of requirements.  3.4 Combination The goal of semi-automated \niteration planning is to propose a optimal iteration plan based on the described criteria. The result \nwill be a plan for a pre-defined number of iterations expressing which tasks should be accomplished in \nwhich iteration and by which developer. In this sense this iteration planning is an optimi\u00adzation problem \nwith following inputs: 1. A set of tasks with effort estimates which are based on and related to a set \nof prioritized requirements 2. A set of developers with their availability estimation and expertise \nregarding tasks  3. The number of iterations to plan and subject to following constraints: 1. No solution \nshould violate the dependency relationship between requirements. 2. Requirements with higher priority \nshould be implemented in earlier iterations. 3. Tasks must be assigned to developers with higher exper\u00adtise \nregarding them 4. The developers must not be overloaded  Based on these constraints the proposed solution \nwill be evalu\u00adated. The human planner (project manager) can finally manipulate the proposed solution \nto attain the desired plan for each iteration. This feedback will also be considered during the evaluation \nof our approach.  4. The unified model For the semi-automatic support of planning iterations our ap\u00adproach \nhas to process artifacts from the system model (i.e. re\u00adquirements) as well as artifacts from the project \nmanagement model (i.e. tasks, stakeholders, developers and iterations). Some of these artifacts such \nas requirements are used as input for our approach. Others such as iterations and assigned tasks result \nfrom semi-automatic iteration planning. To avoid the complex technical problem of tool integration we \nbase our approach on a unified model. This unified model includes all required artifacts in one repository. \nIn this section we describe the unified model our ap\u00adproach is based on, as well as the part of the model, \nwhich is rele\u00advant for our approach. The unified model is implemented in a CASE-tool called UNICASE [15], \nthe successor system of Sysiphus [16]. UNI-CASE provides a unified and flexible repository, which is \nable to store arbitrary types of models. From a repository point of view any model is a graph that consists \nof a number of nodes that are connected by edges. In the following we will refer to the nodes as model \nelements and to the edges as model links. Model elements can either be part of the system model or the \nproject model ([17]). In other words system model elements such as requirements or UML elements are part \nof the same unified model. They are stored in the same repository as project model elements such as tasks, \niterations or users. Model elements from both these models can be directly linked with each other. In \nour case model elements and model links can be both, the input as well as the output of the semi-automated \niteration. Figure 1: Excerpt from the unified model of UNICASE (UML class diagram). Parts, which are \nrelevant for our approach are black colored. Figure 1 shows the part of the unified model in UNICASE, \nwhich is relevant for our approach. To describe our system from a stakeholder point of view, we use the \nmodel element Functional Requirement as part of the System Model. In UNICASE there are several other \nmodel elements like Use Cases or scenarios to de\u00adscribe requirements more in detail, but as stakeholders \ndo not prioritize them directly, we will not use them for the planning of iterations. Functional Requirements \nare described by a name and a description and can depend on each other. The depends on model link implies \nan order of precedence in the implementation be\u00adtween two Functional Requirements. The Refining model \nlink can be used to create a hierarchy of Functional Requirements. The model element Stakeholder is part \nof the project model and usu\u00adally represents a real person. Stakeholders assign individual pri\u00adorities \nto Functional Requirements. As our approach will not only assign requirements to a specific release (as \nin [1]), but also con\u00adsider the related task assignment we will use the model element Task, which can \nbe linked to Functional Requirements. Linking a Task to a Functional Requirement implies that the Task \nrepresents some work necessary to fulfill the requirement. Every Task has an estimate, defining the estimated \nnumber of hours to complete it. Our approach will semi-automatically plan iterations including the task \nassignment. To model the result, tasks can be contained by iterations and assigned to developers. Figure \n2: Instance of a planned iteration in UNICASE (UML object diagram)  Figure 2 shows an instance of an \niteration in UNICASE, which could be the result of the semi-automated planning. Functional-RequirementA \nand FunctionalRequirementB are planned in 1st Iteration. That is implicitly modeled because all tasks \n(Task1, Task2 and Task3) releated to the two requirements are contained in 1st Iteration. Task1 is assigned \nto the developer Pit, Task2 and Task3 are assigne to Bob. Aggregating the estimates of the task in 1st \nIteration Bob has a workload of 10 hours, Pit has a workload of 12 for that iteration. The unified model \nis not limited to the classes shown in Figure 1 but can contain artifacts belonging to any known software \nmod\u00adeling technique. For example, the unified model in UNICASE also includes UML classes, packages, components, \ndeployment nodes, groups, meetings and bug reports to name only a few. It can easily be extended to incorporate \neven more. Therefore our approach could be adapted to work on different types of require\u00adments specifications \nsuch as user stories used in XP or Scrum ([18], [19]).  5. Semi-automated planning of iterations Our \nproposed approach for semi-automatic planning of iterations consists of four sequential steps. In the \nfirst step preparation described in section 5.1 all required information is modeled, in\u00adcluding the requirements \nmodel itself, the prioritization of re\u00adquirements, the definition of estimated tasks and finally the \ndefinition of the available resources. In the second step described in section 5.2 we will determine \nthe expertise for every developer regarding to the identified tasks. We will need this information to \noptimize the assignment of task in the iteration planning. In the third step described in section 5.3 \nthe actual automatic iteration planning is done based on a genetic algorithm. The algorithm optimizes \nthe iteration plan based on the priorities and dependen\u00adcies of requirements as well as on the workload \nand expertise of developers. In the forth and final step the result of the automated plan can be manually \nreviewed and adapted by the project man\u00adager. 5.1 Preparation Before planning the required information \nmust be prepared. This includes information already present in a system such as UNI-CASE. As a prerequisite \nwe assume that the required artifacts, mainly requirements, are already captured. Before planning these \nartifacts and their attributes such as priorities need to be reviewed and updated. In section 5.1.1 we \ndescribed the preparation of the requirements model as well as the prioritization by stakeholders. In \nsection 5.1.2 we describe the identification and estimation of tasks and available resources. 5.1.1 Modeling \nand prioritizing requirements The first step is to model or update the functional requirements in UNICASE \naccording to the model described in section 4. That includes structuring the functional requirements \nin a refinement hierarchy as well as defining dependencies between them. The functional requirements \nare then prioritized by the corre\u00adsponding stakeholders. There is a set S of stakeholders in the pro\u00adject. \nEvery requirement ri has a set of stakeholders interested in it: stakeholder(ri) . S. Every requirement \nhas an integer value as priority on a scale from 1 to 9 assigned to it by stakeholder si: That is, prio(ri, \nsi) . {1...9}. The priority of a requirement ri is average of priorities assigned to it by its stakeholders: \nprio(ri) = avg(prio(ri, si)), si . stakeholder(ri). 5.1.2 Identifying tasks, effort estimations and \nresources Existing approaches such as [1] require estimating the effort for the implementation of every \nrequirement. As our approach should also consider assigning tasks based on the experience of developers \nwe will not estimate requirements directly, but associ\u00adate tasks to them. As described in section 4. \nThese tasks represent the work necessary to fulfill a requirement. In the example in Figure 2 Task2 and \nTask3 need to be completed to fulfill Func\u00adtionalRequirementB. We define the function tasks(ri) for re\u00adquirement \nri to represent tasks that need to be fulfilled to implement requirement ri. Subsequently the project \nmanager de\u00adfines an effort estimation (in our case in hours of work) for every task ti: estimate(ti) \n. Integer. On the other hand the project manager has to define the avail\u00adable resources for upcoming \niterations. Existing approaches con\u00adsider the available resources as one aggregated value. As our approach \nshall consider the individual workload of developers, we gather more detailed information about the availability \nof every single developer. This approach is of special importance for the common case where project participants \ndo not work full-time on one project and have fluctuating availability. The project manager selects a \nset D of developers who are participating (are available) in the planned iterations. For every developer \ndi the manager de\u00adfines his/her availability during each iteration: availability(di) . Integer.  5.2 \nDetermining Expertise In contrast to existing approaches, our semi-automated iteration planning must \nnot only optimize the selection of requirements for each release, but also optimize the assignment of \ntasks to devel\u00adopers based on their expected expertise. As a preparation for the optimization in this \nstep we determine the expertise of every available developer di regarding a task ti: expertise(ti, di) \n. Integer as the number of tasks related to ti he/she has been assigned so far. According to our evaluation \nfunction described in section 5.3.2 the raw expertise of developers will not be good enough to meas\u00adure \noverall expertise factor. For example it does not correctly represent the situation where no developer \nhas ever done tasks related to ti , that is all developers are equal in the fact that they have no experience \nabout task ti . To solve this problem we need to normalize the raw expertise to a value which indicates \na rank\u00ading of developers regarding task ti. We define the function rela\u00adtiveExpertise(ti, di) . [0, 1] \nfor every developer as expertise(ti, di) divided by maximum expertise value regarding ti between all \ndevelopers. In case that no developer has ever completed any tasks related to ti (i.e. expertise(ti, \ndi) = 0 for all developers) we set relativeExpertise(ti, di) = 1 for all developers. This is based on \nthe assumption that if no one has existing experience regarding to specific tasks any developer can work \non the corresponding tasks. Expertise of a developer regarding a task ti should also be weighted proportional \nto effort estimate of ti. The reason for this tendency is the fact that if a task with high effort estimate \nis as\u00adsigned to a developer with little or no experience regarding it, this would have a far worse impact \non feasibility of iteration than the case where a task with little effort estimate is assigned to a devel\u00adoper \nwith little or no experience regarding it. Determining the expertise of a developer regarding a task \nis based on set of tasks this developer has already done. This infor\u00admation can be obtained from records \nin a tool like UNICASE or any other task management tool like a bug repository ([10]). In this paper \nwe propose two strategies to determine expertise. The first approach we propose is to use a machine learning \ntechniques as in [20]. The second strategy is an imperative approach specific to UNICASE model.  The \nadvantage of proposing both a machine learning and an imperative algorithm is the ability to use this \napproach also with task management systems where the tasks (e.g. bug reports) do not have an exact structure \nand are not directly related to require\u00adments. For example in open bug repositories like Bugzilla the \nmain attributes of a tasks are its description and assignee, and there is no direct relationship between \ntasks and requirements [8]. On the other hand in UNICASE tasks are more structured and are directly related \nto requirements. Therefore it is possible to deter\u00admine the expertise of one developer regarding a specific \ntask di\u00adrectly based on related requirements and tasks. Section 5.2.2 and 5.2.3 describe the two proposed \napproaches to determine the expertise function expertise(ti, di). 5.2.1 Determining Expertise using machine \nlearning In the machine learning approach we will use a neuronal net\u00adwork to determine related tasks \nusing text categorization based on description and name of tasks. The training set will again be a set \nof tasks that each developer has already completed. Such an ap\u00adproach is already implemented and evaluated \nin [8], [5] and [12]. These existing approaches use bug tracking systems as an input for determining \nthe expertise. The unified model contains more relevant context information then a typical bug tracking \nsystem like functional requirements. Furthermore we have already suc\u00adcessfully applied machine learning \ntechniques to the unified model of UNICASE to classify tasks in [20]. Therefore we as\u00adsume that existing \napproaches should deliver valuable results. The description of a machine learning approach to determine \nthe ex\u00adpertise goes beyond the scope of this paper. We will focus on the imperative approach described \nin the next section. In section 6 we will describe how we plan to evaluate approach to determine the \nexpertise to find the optimal solution. 5.2.2 Determining expertise in UNICASE This imperative approach \nuses the relationship between tasks and requirements to compute the expertise(di, ti) function. In UNICASE \nmodel a task ti is related to a set of requirements. Each of these requirements has a set of refining \nrequirements, and can in turn refine a requirement. In other words there is a hierarchy of requirements \nwhich relate to each other and are also related to different tasks. Through these sets of related requirements \nand tasks, we can extract those tasks which are related to a specific task ti. The main idea of the imperative \napproach for determining expertise is to step through all related requirements for task ti, find related \ntasks and count the related task to which the developer di has been assigned or is a participant. This \nnumber will represent the raw expertise function expertise(ti, di) described previously.  5.3 Iteration \nPlanning In this section we describe the automated planning of iterations using a genetic algorithm ([21]) \nand define a solution as well as a evaluation function needed for the genetic algorithm. As a first step \nthe user defines n as the number of iterations to plan. We define one more iteration than the number \nof iterations represented with itern+1 . This iteration contains all the tasks, which will not be implemented \nin one of the proposed iterations. That means that all tasks assigned to iteration itern+1 and their \ncorresponding requirements are left to be planned in manual adap\u00adtion step (see 5.3.3) or in the future. \nThe function: iter(ti) . {1, , n +1} defines in which iteration task ti is planned. A solution to iteration \nplanning problem will be of the following form: S = {(ti, iteri, devi)} with ti . T (set of tasks to \nbe planned in iterations), iteri . {1,... n + 1}, and devi . D (set of available developers participating \nin iterations). That is, every solution will be a set of three-tuples indicating for each task ti in \nwhich itera\u00adtion iteri and by which developer di it must be accomplished. We call each of these three-tuples \n(ti , iteri , di) an assignment. 5.3.1 Genetic algorithm This section describes the general schema of \na genetic algo\u00adrithm for find a best solution S to iteration planning problem. Details and exact parameters \nof this algorithm is subject to future work as they have to be evaluated. We create a random initial \npopulation of solutions (individuals), and breed them against an evaluation function (described in 5.3.2) \nto final generation of best solutions ([21]). A solution is a set of assignments (ti, iteri, di) where \nthere is at most one triplet containing a given ti. Therefore every individual in our population (solution \nrepresentation) is a set of assignments. The variation operations of recombination and mutation will \nbe implemented as follows: recombination: to perform a recombination we select two in\u00addividuals using \na parent selection mechanism and exchange a subset of assignments in them. mutation: to perform a mutation \nwe select some individuals and change their iteration number (iteri) and assigned developer (di) within \nallowed range of values. After initial data has been gathered (section 5.1) a typical run of a genetic \nalgorithm will be applied to it. The algorithm termi\u00adnates when there are no more improvements in the \npopulation. The parameters of this genetic algorithm like population size, initialization, parent selection \nmechanism and survivor selection mechanism will be subject to future work. The following section describes \nthe evaluation function.  5.3.2 Evaluation function In this section we describe a method to evaluate \nindividuals (solutions) in every generation of the genetic algorithm. The evaluation function is a foundation \nfor the parent selection mechanism and for the survivor selection mechanism. The evalua\u00adtion is based \non the problem description (see section 3) and con\u00adsiders dependencies between requirements, requirement \npriorities, developer s expertise and the availability of resources. Every solution: S = {(ti, iteri, \ndevi)} will be evaluated by the evaluation function: eval(S) . R. For every Solution S, eval(S) first \ncalcu\u00adlates a four tuple with these elements: (dependency, priority, ex\u00adpertise, overload). This four-tuple \ndescribes a quality of a solution according to constraints specified in 3.4: Dependency: The dependency \nsatisfaction indicator: dependency .{0, 1} describes if the solution violates the dependency relation\u00adship \nbetween requirements. Sliu et al. [6] define the precedence relationship between requirements as P so \nthat (ri, rj) . P means requirement ri must be implement in an earlier iteration than rj . We calculate \ndependency factor using following rule: (ri, rj) . P => iter(ti) < iter(tj) . ti . tasks(ri) . tj . tasks(rj) \nIf a solution violates this rule then the value of dependency factor is 1 and the solution must be discarded. \nPriority: The priority factor: priority .R describes how often a solution violates the requirement priority \nconstraint. The psriority constraint implies that if a requirement ri has greater priority than requirement \nrj it should be implemented in an earlier iteration.  That is: prio(ri) = prio(rj) => iter(ti) = iter(tj) \n. ti . tasks(ri) . tj . tasks(rj) We count the number of violations of this rule in a solution and assign \nit to priority factor. This means a solution with smaller priority factor has a better quality regarding \nrequirement priority constraint than a solution with greater priority factor. Expertise: The expertise \nfactor: expertise .R describes the qual\u00adity of a solution in terms of how appropriate are the developers \nfor doing their assigned tasks. To compute the expertise factor we use relativeExpertise function defined \nin 5.2. We define the set of tasks assigned to a developer di in a solution S as tasks(di). For each \ndeveloper di we define an overall expertise as sum of her relativeExpertise for each of her assigned \ntasks. That is: overallExpertise(di) = S relativeExpertise(ti, di) ti . tasks(di) The expertise factor \nof solution will then be average over all over\u00adall expertise of developers participating in planning. \nOverload: The overload factor: overload . {0, 1} describes if a solution violates the developer workload \nconstraint. The workload of a developer must not be more than his/her availability during an iteration. \nThe workload of a developer can be calculated with the sum of estimates of all the tasks assigned to \nhim/her in a solu\u00adtion. That is: workload(di) = S estimate(ti) ti . tasks(di) If workload(di) > availability(di) \nfor each iteration, then the de\u00adveloper is overloaded (overload = 1) and solution is discarded. To evaluate \na solution using this evaluation factors, the evalua\u00adtion function performs following steps: For every \nsolution S the evaluation function eval(S) computes these four factors and then assigns a grade .R as \na combination of these factors to solution S. For the computing this combination (norm) the different \nfactors have to be weighted. The parameters for the norm function are critical to the quality of the \nproposed solutions. The optimal setting is subject to evaluation.  5.4 Manual Adaptation After termination \nof the genetic algorithm the best solution of last population is represented to the user (project planner). \nThe user can manually change the solution, i.e. assigning task to other iterations, or developers. With \nevery manipulation the its impact in terms of above constraints are shown to see the effect of changes \non quality of the plan. As we want to minimize the re\u00adquired manual changes, every manual change will \nbe captured and used to improve the evaluation function and the overall approach.  6. Evaluation In \nthis section we will describe how the evaluation of the pro\u00adposed approach is planned. There are three \nmain goals in evaluat\u00ading the concept of semi-automated planning of iterations. (1) We proposed two different \napproaches to solve the expertise determi\u00adnation. It has to be evaluated which of them works better or \nhow they should be combined. (2) Even if our approach combines existing and already evaluated solutions, \nit has to be proven that the novel combination produces valuable results. (3) The genetic algorithm used \nin our approach uses weights to calculate a com\u00adbined evaluation value for the individual solutions. \nAs there are no experiences how to set those weights we need to find out opti\u00admal values. The parameter \nimpacting genetic algorithm (like par\u00adent selection strategy and survival selection strategy) must also \nbe determined and examined. Several projects are currently running using UNICASE. We select three of \nthem for our evaluation. The first one is a student project with 25 participants and an industrial partner. \nThe second one is a small industrial project with 6 participants. As the third project we will use the \nUNICASE project itself with over 15 dis\u00adtributed participants. To evaluate the expertise determination \nwe will calculate the expertise relativeExpertise(ti, di) = 1 for a number of random un\u00adassigned tasks \nfrom the three evaluation projects. For the calcula\u00adtion we will use the imperative approach, the machine \nlearning approach and a combination. We will conduct a survey in which the project participants rank \ntheir experience for the unassigned tasks and compare these results with the calculated results. The \nevaluation of the results of iteration planning is a non\u00adtrivial task as there is no defined optimal \nsolution. Greer et al. ([1]) used surveys to evaluate the generated release plans. As our approach is \nsemi-automatic the project manager always needs to inspect the results and manually adapt and correct \nthe proposed iteration plans. For evaluation we claim that the less changes are necessary on a proposed \nplan, the better is the quality of the result. Changes can be of the following type: A task is reassigned \nto a different developer  A task is moved to a different iteration  We claim all changes to consume \nthe same amount of aver\u00adaged manual effort. Therefore the proposed iteration plan with the fewest necessary \nmanual changes is assumed to be the best. To evaluate our approach based on the number of necessary changes \nwe rely on the Version Control System (VCS) of UNI-CASE. ([22],[23]). The VCS can deliver any existing \nhistoric state of a project as well as all changes (model operations) that have been performed in-between \nthese states. The system was already used for other evaluations in a post mortem analysis. ([24]).Finally \nUNICASE offers support for tool instrumentation, e.g. to track when the feature for semi-automated iteration \nplan\u00adning was used. For our on-going evaluation projects we can easily count the number of necessary \nchanges after semi-automated iteration plan\u00adning and additionally manually interview the project participants \nabout the benefit of this approach. But this would be insufficient for an initial evaluation of parameters \nfor the genetic algorithm. The VCS of UNICASE allows us to use the history of the existing projects for \nthat task. All three evaluation projects have a number of existing manually planned iterations. We will \nrecreate the pro\u00adject states directly before these iterations were planned. Then we will apply our approach \nand compare the result with the project state after the actual iteration has been planned manually. The \nparameters for the genetic algorithm has to be set in a way, that the differences between the proposed \nsolutions and actual the manual solution from the history are minimized. This could be performed by using \nthe edit distance between the two solutions in terms of the task reassignments and task moves as a metric. \nAs all steps for this evaluation can be automated, this way of evaluation is less intrusive than the \nuser evaluation and therefore suitable for an initial exploration of the parameter setting.  7. Conclusion \nand Future work We described an approach for semi-automated planning of itera\u00adtions based on a unified \nmodel. We propose to use a genetic algo\u00adrithm to optimize the iteration plan based on two dimensions, \nfirst the priorities and dependencies of requirements, second the avail\u00adability and expertise of the \nparticipating developers. The novelty of this approach is the combination of these two dimensions. To \ndetermine the expertise of developers regarding a specific task we proposed two approaches, the use of \nmachine learning and an imperative approach. The feasibility of the proposed approach has to be shown. \nTherefore we will implement and evaluate our ap\u00adproach. We expect a high effort in finding the optimal \nsetting for the parameters of the genetic algorithm.  If the approach shows to be feasible in practice \nit can be ex\u00adtended with new criteria and dimensions of the problem of itera\u00adtion planning. As UNICASE \nalso contains artifacts from the domain of risk management, the estimated risks of certain re\u00adquirements \ncould also be considered. Furthermore the approach can be extended to different types of requirement \nspecification. Our proposal is currently based on functional requirements. As the unified model of UNICASE \nis easily modifiable the approach could be transferred iteration planning based on requirement descriptions \nsuch as features (e.g. [25]) or user stories used in agile methods ([18], [19]).  References [1] D. \nGreer und G. Ruhe, Software release planning: an evolutionary and iterative approach, Information and \nSoftware Technology, vol. 46, M\u00e4rz. 2004, S. 243-253. [2] G. Ruhe und M.O. Saliu, The Art and Science \nof Software Release Planning, IEEE Softw., vol. 22, 2005, S. 47-53. [3] A.J. Bagnall, V.J. Rayward-Smith, \nund I.M. Whittley, The next release problem, Information and Software Technology, vol. 43, Dez. 2001, \nS. 883-890. [4] G. Du, J. McElroy, und G. Ruhe, A family of empirical studies to compare informal and \noptimization-based planning of software re\u00adleases, Proceedings of the 2006 ACM/IEEE international sympo\u00adsium \non Empirical software engineering, Rio de Janeiro, Brazil: ACM, 2006, S. 212-221. [5] J. Anvik, L. Hiew, \nund G.C. Murphy, Who should fix this bug?, Proceedings of the 28th international conference on Software \nengi\u00adneering, Shanghai, China: ACM, 2006, S. 361-370. [6] M.O. Saliu und G. Ruhe, Bi-objective release \nplanning for evolving software systems, Proceedings of the the 6th joint meeting of the European software \nengineering conference and the ACM SIGSOFT symposium on The foundations of software engineering, Dubrovnik, \nCroatia: ACM, 2007, S. 105-114. [7] G. Canfora and L. Cerulo, How software repositories can help in resolving \na new change request , In Workshop on Empirical Studies in Reverse Engineering, September 2005. [8] J. \nAnvik, Automating bug report assignment, Proceeding of the 28th international conference on Software \nengineering -ICSE '06, Shanghai, China: 2006, S. 937. [9] J. Anvik, L. Hiew, und G.C. Murphy, Who should \nfix this bug?, Proceedings of the 28th international conference on Soft\u00adware engineering, Shanghai, China: \nACM, 2006, S. 361-370. [10] D. Cubranic und G. Murphy, Automatic bug triage using text cate\u00adgorization, \nProceedings of the Sixteenth International Conference on Software Engineering &#38; Knowledge Engineering, \n2004, S. 97, 92. [11] A. Mockus und J.D. Herbsleb, Expertise browser: a quantitative approach to identifying \nexpertise, Proceedings of the 24th Interna\u00adtional Conference on Software Engineering, Orlando, Florida: \nACM, 2002, S. 503-512. [12] L. Yingbo, W. Jianmin, und S. Jiaguang, A machine learning ap\u00adproach to semi-automating \nworkflow staff assignment, Proceedings of the 2007 ACM symposium on Applied computing -SAC '07, Seoul, \nKorea: 2007, S. 340. [13] C. Weiss, R. Premraj, T. Zimmermann, und A. Zeller, How Long Will It Take to \nFix This Bug?, Proceedings of the Fourth Interna\u00adtional Workshop on Mining Software Repositories, IEEE \nComputer Society, 2007, S. 1. [14] Sommerville, Ian and Sawyer, Pete. Requirements Engineering -A good \npractice guide. West Sussex : Wiley &#38; sons, 2003. 0471974447. [15] Bruegge, B., Creighton, O., Helming, \nJ., and K\u00f6gel, M. Unicase -an Ecosystem for Unified Software Engineering Research Tools. Third IEEE International \nConference on Global Software Engineering, ICGSE 2007, (2008). [16] Bruegge, B., Dutoit, A.H., and Wolf. \nSysiphus: Enabling informal collaboration in global software development. Global Software En\u00adgineering, \n2006. ICGSE '06. International Conference on, (2006), 139-148. [17] J. Helming, J. David, M. Koegel, \nH. Naughton, \"Integrating Sys\u00adtem Modeling with Project Management -a Case Study\", To appear in Proceedings \nof the International Computer Software and Applica\u00adtions Conference, COMPSAC 2009 [18] K. Schwaber, Agile \nProject Management with Scrum , Microsoft Press, 2004. [19] K. Beck, Extreme Programming Explained: Embrace \nChange , Addison-Wesley Professional, 1999. [20] B. Bruegge, J. David, J. Helming, und M. Koegel, Classification \nof tasks using machine learning, Proceedings of the 5th International Conference on Predictor Models \nin Software Engineering, Vancou\u00adver, British Columbia, Canada: ACM, 2009, S. 1-11. [21] A.E. Eiben und \nJ.E. Smith, Introduction to Evolutionary Computing, Springer, Berlin, 2003. [22] M. K\u00f6gel, Towards software \nconfiguration management for unified models. In ICSE 08, CVSM 08: Proceedings of the international workshop \non Comparison and versioning of software models (New York, 2008), ACM, pp. 19 24. [23] M. Koegel, J. \nHelming, S. Seyboth, Operation-based conflict detection and resolution , In ICSE '09, CVSM '09: Proceedings \nof the 2009 International Workshop on Comparison and Versioning of Software Models, Vancouver, Canada, \n2009, IEEE [24] M. Koegel, J. David, J. Helming, H. Naughton, Traceability Re\u00adARMed ,To appear in Proceedings \nof the International Computer Software and Applications Conference, COMPSAC 200 [25] B. Berenbach und \nT. Wolf, A unified requirements model; integrat\u00ading features, use cases, requirements, requirements analysis \nand haz\u00adard analysis, Global Software Engineering, 2007. ICGSE 2007. Second IEEE International Conference \non, 2007, S. 197-203. .  \n\t\t\t", "proc_id": "1639950", "abstract": "<p>Iterations are time-boxed periods with an intended outcome that is often a set of implemented requirements. Iterations are part of most common software development lifecycle models. Planning of iterations is a non-trivial task due to the multi-dimensional criteria. (1) The first dimension concerns the question what shall be completed in the iteration, also referred to as \"release planning\". Decisions in this dimension are based on criteria such as dependencies and priorities of requirements. (2) The second dimension concerns the decision, which project participant should work on which task, also referred to as \"task assignment\". Decisions in this dimension are based on criteria such as the expertise and the workload of the developers. The decisions in both dimensions are considerably complex. Therefore several approaches exist to semi-automatically support the decisions limited to one of the two dimensions mentioned above. None of the existing approaches considers both dimensions at the same time. In this paper we propose a combination of approaches from semi-automatic release planning and from semi-automatic task assignment. This results in a semi-automated two-dimensional solution for the problem of iteration planning, We suggest the use of a genetic algorithm to optimize the resulting iteration plans in both dimensions of the problem.</p>", "authors": [{"name": "Jonas Helming", "author_profile_id": "81436592644", "affiliation": "Technische Universit&#228;t M&#252;nchen, M&#252;nchen, Germany", "person_id": "P1728355", "email_address": "", "orcid_id": ""}, {"name": "Maximilian Koegel", "author_profile_id": "81430676121", "affiliation": "Technische Universit&#228;t M&#252;nchen, M&#252;nchen, Germany", "person_id": "P1728356", "email_address": "", "orcid_id": ""}, {"name": "Zardosht Hodaie", "author_profile_id": "81444607118", "affiliation": "Chair for Applied Software Engineering, Technische Universit&#228;t M&#252;nchen, Germany", "person_id": "P1728357", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1639950.1640065", "year": "2009", "article_id": "1640065", "conference": "OOPSLA", "title": "Towards automation of iteration planning", "url": "http://dl.acm.org/citation.cfm?id=1640065"}