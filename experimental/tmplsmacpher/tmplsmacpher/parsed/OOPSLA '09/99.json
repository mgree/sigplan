{"article_publication_date": "10-25-2009", "fulltext": "\n Concurrency by Default Using Permissions to Express Data.ow in Stateful Programs Sven Stork * Paulo \nMarques* Jonathan Aldrich Institute for Software Research Carnegie Mellon University 5000 Forbes Avenue \nPittsburgh, PA 15213, USA {svens, jonathan.aldrich}@cs.cmu.edu Abstract The rise of the multicore era \nis catapulting concurrency into mainstream programming. Current programming paradigms build in sequentiality, \nand as a result, concurrency support in those languages forces programmers into low-level reason\u00ading \nabout execution order. In this paper, we introduce a new programming paradigm in which concurrency is \nthe default. Our \u00c6MINIUM lan\u00adguage uses access permissions to express logical dependen\u00adcies in the code \nat a higher level of abstraction than sequen\u00adtial order. Therefore compiler/runtime-system can leverage \nthat dependency information to allow concurrent execution. Because in \u00c6MINIUM programmers specify dependen\u00adcies \nrather than control .ow, there is no need to engage in dif.cult, error-prone, and low-level reasoning \nabout execu\u00adtion order or thread interleavings. Developers can instead fo\u00adcus on the design of the program, \nand bene.t as the runtime automatically extracts the concurrency inherent in their de\u00adsign. Categories \nand Subject Descriptors D.3.3 [Programming Languages]; D.1.3 [Concurrent Programming] General Terms Design, \nLanguages Keywords concurrency, programming language, access permissions, data.ow 1. Introduction The \nfree lunch is over [Sutter 2005] characterizes like no other statement one of the most fundamental technol\u00adogy \nshifts in the last few decades. Because it is no longer Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for pro.t or commercial advantage and that copies bear this notice and the full \ncitation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to \nlists, requires prior speci.c permission and/or a fee. OOPSLA 2009, October 25 29, 2009, Orlando, Florida, \nUSA. Copyright c &#38;#169; 2009 ACM 978-1-60558-768-4/09/10. . . $10.00 *CISUC, Dep. Eng. Inform\u00b4 atica, \nPolo II University of Coimbra 3030-290 Coimbra, Portugal {stork, pmarques}@dei.uc.pt feasible to improve \nsingle CPU performance, hardware ven\u00addors started to integrate multiple cores into single chip. This \nmeans that programmers need to develop concurrent appli\u00adcations if they want to achieve performance improvements \non new hardware. Writing concurrent applications is notori\u00adously complicated and error prone, because \nconcurrent tasks must be coordinated to avoid problems like race conditions or deadlocks. Pure functional \nprogramming is by nature an excellent .t for concurrent programming. In functional programming there \nare no side-effects, so programs can execute concur\u00adrently to the extent permitted by data dependencies. \nAl\u00adthough functional programming can solve most problems, having explicit state, as provided by imperative \nlanguages, allows the developer to express certain problems in a more intuitive and ef.cient way. In \nan ideal world we would like to have the bene.ts of functional programming with regard to concurrent \nexecution with the expressiveness of an imper\u00adative object-oriented language. Sharing state between concurrent \ntasks immediately raises questions like: In which order should those accesses oc\u00adcur? and How to coordinate \nthose accesses to maintain a program invariants? The reason why those questions are hard to answer is \nbecause there are implicit dependencies between code and state. Methods can arbitrarily change any accessible \nstate without revealing this information to the caller. This means that two methods could be dependent \non the same state, without the caller knowing about it. Because of this lack of information, current \nprogramming languages use the order in which code is written as proxy to express those implicit dependencies. \nTherefore the compiler has to follow the given order and cannot exploit potential concur\u00adrency automatically. \nWhen the developer adds concurrency manually, it is easy for her to miss important dependencies, introducing \nrace conditions and other defects. To overcome this situation, we propose to transform im\u00adplicit dependencies \ninto explicit dependencies and then in\u00adfer the ordering constraints automatically. In our proposed system, \nby default, everything is concurrent, unless explicit dependencies imply a speci.c ordering.  We propose \nto use access permissions [Bierhoff and Aldrich 2007] to specify explicit dependencies between stateful \noperations. Access permissions are abstract capa\u00adbilities that grant or prohibit certain kinds of accesses \nto speci.c state. In our approach each method need to specify permissions to all of the state it potentially \naccesses. Looked at from a slightly different perspective, our system ensures that every method only \naccesses state for which it has ex\u00adplicit permissions. The way we use access permissions to specify state \ndependencies resembles the way Haskell [Jones 2003] uses its I/O monad1 to specify access to global state. \nBut unlike the I/O monad, which provides just one permis\u00adsion to all the state in the system, access \npermissions allow greater .exibility by supporting .ne-grained speci.cations, describing the exact state \nand permitted operations on it. Following our new programming paradigm, concurrency\u00adby-default, we are \ncurrently working on the semantics and implementation of \u00c6MINIUM. In this paper we use a Java\u00adlike syntax2 \nto explain the concepts behind \u00c6MINIUM and its features. The rest of this paper is organized as follows. \nSection 2 discusses the core language features of \u00c6MINIUM. Section 3 presents some currently open challenges. \nIn section 4 we discuss related work. Section 5 concludes the paper. 2. Concurrency by Default In \u00c6MINIUM \nevery method must explicitly mention all of its possible side effects. This allows the system to com\u00adpute \nthe data dependencies within the code, and within those constraints, execute the program with the maximum \npossi\u00adble concurrency. By following this approach our system re\u00adsembles a data.ow architecture [Rumbaugh \n1975]. But in\u00ad stead of producing and consuming data, our system supports shared objects and in-place \nupdates. To achieve scalability for upcoming massive concurrent systems, we need to use a .ne-grained \napproach for specify\u00ading side effects. To avoid overly conservative dependencies, which would limit concurrency, \nwe need a way to deal with object aliasing. In access permissions [Bierhoff and Aldrich 2007] we found \na uniform solution for both problems, the speci.cation of data accesses and the speci.cation of alias\u00ading. \nThe next sections describe the approach in more detail. 2.1 Access Permissions for Concurrency 2.1.1 \nUnique and Immutable Permissions Consider the application in Figure 1 which computes over a collection \nof data. Starting with line 20 the main func\u00ad 1 Think of it as one global permission, which grants the \nright to access or change all state in the system. 2 As everything is concurrent by default, we omit \nthe sequentializing semi\u00adcolon to emphasize this fact. 1 class Collection { ... } 2 class Dependencies \n{ ... } 3 class Statistics { ... } 4 5 Collection createRandomData() 6 : unit. unique(result) 7 8 \nvoid removeDuplicates(Collection c) 9 : unique(c). unique(c) 10 11 void printCollection(Collection \nc) 12 : immutable(c). immutable(c) 13 14 Dependencies compDeps(Connection c) 15 : immutable(c). immutable(c),unique(result) \n 16 17 Statistics compStats(Connection c) 18 : immutable(c). immutable(c),unique(result) 19 20 void \nmain() { 21 Collection c = createRandomData() 22 printCollection(c) 23 Statistics s = compStats(c) 24 \nDependencies d = compDeps(c) 25 removeDuplicates(c) 26 printCollection(c) 27 ... 28 } Figure 1. Example: \nUnique and Immutable Permissions tion creates a collection containing some randomly gener\u00adated data. \nAt line 22 we print the collection on the screen, then pass the collection into method calls to compute \nstatis\u00adtics and dependencies over the passed collection, and return corresponding objects describing \nthe statistics and depen\u00addencies. We will assume these objects are used later on in the method body, \nin line 27 and beyond. After that, we re\u00ad move existing duplicates from the collection and then print \nthe updated collection to the screen (line 26). Obviously, for concurrency purposes functions like re\u00admoveDuplicates \nrequire a permission to modify the collec\u00adtion. On the other hand, functions like printCollection, which \nonly examines the collection, only require a read-only permission. Access permissions allow us to specify \nexactly these requirements. Access permissions are abstract capabilities that grant or prohibit certain \nkinds of accesses to speci.c state. Access permissions are associated with object references and spec\u00adify \nin which way the owner of the permission is allowed to access/modify the referenced object. In our system \nwe use the following kinds of access permissions: Unique A unique permission to a reference guarantees \nthat this reference is the only reference to the object at this moment in time. Therefore the owner has \nexclusive ac\u00adcess to the object. Immutable An immutable permission to a reference pro\u00advides non-modifying \naccess to the referenced object. Ad\u00additionally a immutable permission guarantees that all other existing \nreferences to the referenced object are also immutable permissions.  Shared A shared permission to a \nreference provides mod\u00ad ifying access to the corresponding object. Additionally a shared permission indicates \nthat there are potentially other shared permissions (aliases) to the referenced ob\u00ad ject through which \nthe referenced object can be modi.ed. For brevity we write unique reference when we mean a unique permission \nto a reference , as well as for immutable and shared permissions. When specifying permissions in code \nwe write unique(X) when we mean that we have a unique permission to reference X. We use the pseudo\u00adreference \nresult to specify a permission to the return value. We use linear logic [Girard 1987] to manage the access \npermissions in our system. Linear logic is a sub-structural logic for reasoning about resources. Once \nresources have been consumed they are no longer available. We use the symbol. to separate the pre-conditions \n(the permissions a method requires and consumes) from the post conditions (the permissions a method \nreturns). Consider the follow\u00ading method signature : unique(this). unique(this) . In this case the method \nrequires that the caller must have a unique permission to the receiver object to call this method. Because \nwe use linear logic, the input permission is con\u00adsumed, and therefore the method has to produce a new \nunique permission to the receiver object upon its return. If the method did not return a permission to \nthe receiver object, the caller would not be able to access the object any more. Because access permissions \nplay such an important role in our system, we promote them to .rst-class citizens and integrate them \ninto our type system. Consider the following function that converts an Integer into its String representa\u00adtion, \nindicating the type (in this case I for Integer) and the value: String repr(Integer a){ return \"I\"+a; \n}In a standard ML-style type signature, this function would have the type Integer . String , stating \nthat the method takes an Integer as input and returns an String. In our system, the same function would \nhave the following access permis\u00adsion signature: immutable(a). immutable(a), unique(result) The access \npermission signature provides much more infor\u00admation regarding the behavior of the function. First, the \nim\u00admutable permission indicates that the function is not going to change the object we passed in. Secondly, \nindicated by the unique permission, we know that the reference to the re\u00adturned String object is not \naliased, because it is the only one in the whole system. With this information we are now able to specify \nthe exact permissions of each presented method. As shown in line 5, the createRandomData method requires \nno permis\u00adsions (we indicated the empty set of permissions with unit) and produces a unique permission \nto the returned collection. Because printCollection3 (line 11), compDeps (line 14) 3 For accessing the \noutput device our system also requires a permission. To Figure 2. Example: Unique and Immutable Permissions \nFlow and compStats (line 14) do not modify the collection, they all just require an immutable permission \nto the collection, which is returned again after their completion. Additionally, compStats and compDeps \nreturn a unique permission to their returned objects, which are later needed, but are not im\u00adportant \nin the code shown. The removeDuplicates method requires, and returns after completion, a unique permission \nto the collection, as it is going to modify the collection. Given the permission signatures and using \ntextual order, our system is able to compute the permission .ow through the program. Figure 2 shows the \npermission .ow graph for the program which captures the existing data dependencies. As speci.ed in Figure \n1, the createRandomData method generates a unique permission to the returned collection. The printCollection, \ncompStats and compDeps func\u00adtions require only an immutable permission to the collection. Therefore our \nsystem has to convert the unique permis\u00adsion into three immutable permissions, one for each func\u00adtion. \nLike in Bierhoff s system, our system performs those conversions by automatically splitting and joining \npermis\u00adsions utilizing fractions [Boyland 2003]. This means after starting out with a unique permission, \nthe system is able to split the unique permission into either multiple shared permissions or multiple \nimmutable permissions. Remember that because of linearity, the unique permission is consumed and no longer \navailable. The reverse works in a similar way. Once all shared or immutable fractional permissions have \nbeen collected, the systems is able to form a unique permis\u00adsion again. keep the example simple and because \ndata groups (explained in section 2.2) offer a better abstraction for dealing with this kind of problems, \nwe omit the I/O-related permissions in this example.  The splitting of the unique permission into three \nim\u00admutable permissions is shown in Figure 2 as split1 . Once their input requirements are ful.lled via \nan immutable per\u00admission to the collection, those three methods are eligible for execution. The system \ncan decide to execute them con\u00adcurrently or sequentially, depending on available resources and relative \nexecution costs. The removeDuplicates method requires a unique per\u00admission to the collection, and therefore \nit depends on the completion of the printCollection, compDeps and comp-Stats methods. Only when those \nmethods complete will they return the immutable permissions to the collection, which they consumed when \nstarting their execution. The system needs to collect all immutable permissions to the collection before \nit can join them back to a unique per\u00admission to the collection (see Figure 2, join1 ). Remem\u00ad ber that \nimmutable guarantees that, at this point in time, there are only immutable permissions referencing the \nob\u00adject. After the unique permission has been recovered, the input requirements for the removeDuplicates \nmethod is ful.lled and it can be executed. The second printCollec\u00adtion method (line 26) requires an immutable \npermission. Therefore, this method depends on the completion of the removeDuplicates method, before the \nsystem can split the returned unique permission to the collection into immutable permissions to the collection \n(see Figure 2, split2 ). After the completion of the second printCollection method the system will automatically \nrecover the unique permission to the collection4 (see Figure 2, join2 ). The advantage of this approach \nover explicit concurrency management is founded in the automation of dependency in\u00adference and the guarantee \nthat those dependencies are met. If the programmer manages concurrency manually he might overlook dependencies \nand create race conditions or might overlook the absence of dependencies and miss available concurrency. \nIn particular when it comes to the concurrent sharing of data, reasoning about dependencies becomes sig\u00adni.cantly \nmore complicated.  2.1.2 Shared Permissions In the previous section we saw how we can use unique and \nimmutable permissions to extract concurrency. However having only unique and immutable is of limited \nuse. Be\u00adcause there exists only one unique permission to an object at a time, there can be only one entity \nmodifying the object at a time. Shared memory and objects are in general used as communication channels \nbetween several concurrent enti\u00adties, which may modify the shared state. Therefore, we need a mechanism \nto allow concurrent execution and modifying access to a shared resource. A shared permission provides \nexactly these semantics. 4 Assuming that the statement that depends next on the collection requires unique \npermission. 1 class Queue { 2 void enqueue (Object o) 3 : unique(this), shared(o) . unique(this) 4 5 \nObject dequeue() 6 : unique(this) . unique(this), shared(result) 7 } 8 9 Queue createQueue() : unit \n. unique(result) 10 11 void disposeQueue(Queue q) : unique(q) . unit 12 13 void producer(Queue q) : shared(q) \n. shared(q) 14 { atomic { q.enqueue(...) ... }} 15 16 void consumer(Queue q) : shared(q) . shared(q) \n17 { atomic { Object o = q.deqeueu() ... }} 18 19 void main() { 20 Queue q = createQueue() 21 producer(q) \n22 consumer(q) 23 disposeQueue(q) 24 } Figure 3. Example: Producer/Consumer with Shared Per\u00admissions \nAs explained before, a shared permission allows mod\u00adifying access to the referenced object and indicates \nthat the there are potentially other shared references out there, through which the referenced object \ncould be changed. In our system, similar to immutable permissions, statements that depend on the same \nshared object can be executed con\u00adcurrently. Obviously, allowing concurrent access to the same object \nopens the window for race conditions. Therefore we require that every access through a shared reference \nmust occur inside an atomic context. We introduce the atomic\u00adblock statement into our language, atomic \n{ ... }, with the common transactional memory [Larus and Rajwar 2007] semantics. In particular this means \nthat a block of statements is completely executed, and all modi.cations become visible to the rest of \nthe system atomically. It is important to note that all code inside an atomic context is sequentially \nexe\u00adcuted in the given lexical order. If several different atomic blocks cause con.icting accesses, the \nruntime system will detect those and resolve them (in general by aborting, rolling back and retrying \nsome of the atomic blocks). Therefore, an atomic block provides the illusion of having exclusive ac\u00adcess \nto the all accessed resources. Although the placement of atomic blocks could be inferred automatically, \nfor granu\u00adlarity reasons, we require the user to explicit specify atomic regions. This approach allows \nthe user to have .ne-grain control over the size of critical sections, while our system can adapt the \napproach described in [Beckman et al. 2008] to verify and enforce the correct usage of atomic blocks. \nFigure 3 shows a simpli.ed producer/consumer example, where the producer and consumer communicate via \na queue. Beginning in line 19 main calls createQueue to obtain a new queue object. This queue is then \npassed to the pro\u00adFigure 4. Example: Producer/Consumer with Shared Per\u00admission Flow  ducer and consumer \nmethods (lines 21 + 22). Finally the program calls the disposeQueue method to free the queue. This program \ns permission .ow is shown in Figure 4. Both the consumer and producer methods require a shared permission \nto the queue. Therefore, the unique permission returned by createQueue (line 9) is automatically split \nby the system into shared permissions (Figure 4, split ). This means that both the producer and consumer \nmethods have their required input permissions and can be executed in parallel. Because the queue is shared, \nboth methods need to be in an atomic context when accessing the queue (lines 14 + 17). As shown in line \n2 and 5, both the enqueue and dequeue methods require a unique permission to the queue. Because the atomic \nblock provides an illusion of exclusive access, we can treat the shared permission to the queue as a \nunique permission, and permit the access to the queue. Because disposeQueue requires a unique permission \nto the queue, it depends on the eventual completion of producer and consumer to return the shared permissions \nto the queue and join them back to form a unique permission (Figure 4, join ).  2.2 Data Groups for \nHigher-Level Dependencies In some situations, application level dependencies exist that cannot directly \ninferred via data dependencies. As an Ex\u00adample of high-level dependencies, consider the common ob\u00adserver \npattern. It is unclear whether the observers of a sub\u00adject need to be attached to the subject before \nthe subject can be updated. In some situations it is important for observers not miss the .rst update \n(e.g., to initialize the observer cor\u00adrectly), while in other situations it does not matter if the .rst \nupdate is missed (e.g., a news feed). We propose to use data groups [Leino 1998] to allow the speci.cation \nof such high\u00ad level dependencies. Consider the simple observer example shown in Figure 5. The program \ncreates a new subject which is then passed to newly created observers and to several update method 1 \nclass Subject { 2 void add(Observer o) 3 : shared(this), shared(o) . shared(this) 4 5 void update() \n: shared(this) . shared(this) 6 } 7 8 class Observer { 9 Observer(Subject s) 10 : shared(s) . shared(s), \nshared(result) 11 { s.add(this) } 12 13 void notify(Subject s)  14 : shared(this), shared(s) . shared(this), \nshared(s) 15 } 16 17 void update(Subject s) : shared(s) . shared(s) 18 { s.update() } 19 20 void main() \n{ 21 Subject s = new Subject() 22 Observer obs1 = new Observer(s) 23 Observer obs2 = new Observer(s) \n24 update(s) 25 update(s) 26 ... 27 }  Figure 5. Example: Concurrent Observer calls. The observer constructor \nsimply adds the current ob\u00adject as subscriber to the provided subject (line 11). The up\u00ad date call triggers \nthe noti.cation of the subject (line 18). Furthermore assume we want to extract the maximum paral\u00adlelism \npossible by allowing the concurrent creating/addition of observers and concurrent updates. A .rst attempt \nwould be to use shared permissions to the subject in the Observer constructor call (line 9) and the update \ncall (line 18). Us\u00ad ing this approach leads to the dependencies shown in Fig\u00adure 6. The problem is that, \nas shown, the construction of the Observer objects and the update function only have de\u00adpendencies with \nthe Subject but not amongst each other. Therefore they can be executed concurrently in any order. This \ncould lead to the update method being called before any Observer is attached to the subject. While this \nbehavior might, in some scenarios, be acceptable (e.g., a small gadget that display the latest news), \nit can also be completely unac\u00adceptable in other situations (e.g., when the observer depends on the initial \nvalues of the subject). One way to ensure that the observers have been attached before the update calls \nget executed is to change the Observer constructor to require a unique permission to the subject. But \nthis also creates a prob\u00adlem since it would limit parallelism, as all Observer object constructions would \nbe serialized. To allow the user to specify such additional dependencies without sacri.cing concurrency, \nwe add data groups to our system. Data groups are abstract collections of objects. In particular an object \ncan be associated with exactly one data group at a time. Data groups provide a higher-level abstrac\u00adtion \nand provide information hiding with respect to what state is touched by a method.  Figure 6. Example: \nConcurrent Observer Flow In our system a data group can be seen as a container which contains all shared \npermissions to an object. Since unique permissions already provide exclusive access to the referenced \nobject and immutable permissions can safely be shared, we do not associate unique and immutable permis\u00adsion \nwith data groups. Therefore unique can be used to trans\u00adfer an object between data groups. We extend \nthe de.nition of access permissions to optionally refer to the associated data group. We write shared(REF|DG) \n, where REF is the object reference and DG speci.es the data group. Similar to access permissions for \nobjects, we introduce access permis\u00adsions to data groups: atomic An atomic permission provides exclusive \naccess to a data group. Working on an atomic data group automati\u00ad cally leads to the sequentializing \nthe corresponding code. This is similar to a unique permission for objects. Requir\u00ad ing an atomic permission \nmust be explicitly speci.ed. concurrent A concurrent permission to a data group means that multiple other \nconcurrent permissions to the data group exist. Code working on a concurrent data groups is executed \nwith concurrency by default. This is similar to a shared permission for objects. Concurrent permission \nis the default, so using the concurrent keyword is optional. Unlike with access permissions to objects, \nthe user must manually split and join permissions to data groups. To avoid tedious and error prone management \nof permissions for data groups, we propose a split block construct. A split block converts a unique permission \nto its data group into an ar\u00adbitrarily number of concurrent permissions that may be used in its body \nblock. Having concurrent permissions inside the body block of the data group allows the body to be executed \nconcurrently. After the execution of its body block, the split block will join all concurrent permissions \nback to a unique permission : split ( DataGroup grp ) { ... } Additional we propose the enhancement of \nthe atomic block construct to refer to the data group of the objects that are going to be modi.ed : atomic \n( DataGroup grp ) { ... }The explicit speci.cation of data groups is optional as it can be automatically \ninferred from the code in the atomic 1 class Subject<SG> { 2 void add(Observer<SG> o) 3 : shared(this|SG), \nshared(o|SG) . shared(this|SG) 4 5 void update() 6 : shared(this|SG) . shared(this|SG) 7 } 8 9 class \nObserver<SG> {10 Observer(Subject<SG> s) 11 : shared(s|SG) . shared(s|SG), shared(result|SG) 12 { s.add(this) \n} 13 14 void notify(Subject<SG> s) 15 : shared(this|SG), shared(s|SG) 16 . shared(this|SG), shared(s|SG) \n17 } 18 19 void update(Subject<SG> s)  20 : shared(s|SG) . shared(s|SG) 21 { s.update() } 22 23 void \nmain() { 24 group <SubG> 25 26 split (SubG) { 27 Subject<SubG> s= new Subject<SubG>() 28 Observer<SubG> \nobs1 = new Observer<SubG>(s) 29 Observer<SubG> obs2 = new Observer<SubG>(s)  30 } 31 split (SubG) { \n32 update<SubG>(s) 33 update<SubG>(s) 34 } 35 ... 36 } Figure 7. Example: Concurrent Observer with Data \nGroups block s body. Nevertheless, when present, it can be used to verify the body against the explicit \nspeci.cation. Having the explicit knowledge of which data groups are accessed inside and atomic block \ncould allow optimizations of the transactional memory system or its complete replacement via a more lightweight \napproach [Boehm 2009]. Figure 7 shows the observers example using the data group approach. We use a syntax \nsimilar to type parameters to specify and pass data groups around. A group parameter can be used at the \nclass level (line 1) or the function level (line 19). The group<Z> command creates a new group with the \nname Z. The group command always returns an atomic permission to the new group. In the enhanced example, \nin line 24, a new data group with the name SubG is created. In line 26 the split block is used to split \nthe atomic permission of the SubG data group into an arbitrary number of concurrent permissions. Having \na concurrent permission reestablishes a concurrent\u00adby-default environment. Thus, the statements in the \nbody block may be executed concurrently up to explicit data de\u00adpendencies. This is shown in Figure 8. \nThe second split block (line 31) requires an atomic permission to the SubG data group and therefore depends \non the completion of the Figure 8. Example: Concurrent Observer with Data groups Flow  .rst split block. \nAfter completion of the .rst split block s body, all the concurrent permissions to the SubG group can \nbe gathered and joined back into an atomic permission. The dependencies between data groups and data \ndepen\u00addencies are visualized in Figure 8. The atomic group per\u00ad mission, generated by the group command, \nwill be split by the .rst split block (.rst rectangle) into concurrent group permissions. The statements \ninside the corresponding block follow the normal data dependency mechanism. The system will automatically \nsplit the unique permission of the sub\u00adject into shared permissions, to allow the concurrent exe\u00adcution \nof the Observer creation. After the completion of the block, the system will join the shared permissions \nback into a unique permission and the split block will join the concurrent group permissions back into \nan atomic permis\u00adsion. The second split block (second rectangle) will take the atomic group permission \ngenerated by the .rst split block and split it again into concurrent permissions for its body. Inside \nthe body, the normal approach of automatically split\u00adting and joining object permissions is then performed. \nThe advantage of using data groups over explicit concur\u00adrency management is again based on automatic \ndependency inference and the guarantee that those dependencies are met. Data groups allow the programmer \nto explicitly model her design intent in the source code. Not only does this allow the \u00c6MINIUM system \nto infer the dependencies and correct execution, it also improves the quality of the code itself by explicit \ndocumenting those dependencies. 3. Challenges So far we have only presented a high-level overview of \n\u00c6MINIUM. Since it is at an early stage of development there are still several open issues to solve. In \nparticular, the following questions deserve closer attention: Overhead An open question is how much speci.cation \noverhead does our approach cause for the developer. Per\u00admissions are modular and should be automatically \ninfer\u00adable most of the time. But data groups model an effect system, and it may be a challenge to declare \nfunction effects without creating a blowup in speci.cation size. Granularity Since we target commodity \nhardware, we have to .nd a good trade-off between the very .ne granularity of parallelism our system \nis able to extract and the ex\u00adecution/synchronization overhead. One possible way to tackle this problem \ncould be by adapting a cost semantic model as developed by [Spoonhower 2009]. Runtime-System We need \nto .nd an ef.cient way to rep\u00adresent code along with its data dependencies in an inter\u00admediate format \nthat allows ef.cient execution. Also, tak\u00ading the granularity argument into account, we most likely need \nto develop a dynamic runtime system that automat\u00adically adapts the program to the hardware platform. \nLegacy Code When designing a new language, one cannot ignore the vast amount of legacy code that exists. \nWe pro\u00adpose to integrate legacy code, which has no permissions, by assuming the most restrictive permission \ntype. This ef\u00adfectively sequentialises the execution of those code frag\u00adments but allows a semantically \ncorrect usage of legacy code in our system. Deadlock Our system avoids race conditions, but does not \nprotect against deadlocks. For instance, it is known that using an atomic block at the wrong granularity \ncan lead to deadlock [Martin et al. 2006]. 4. Related Work As discussed in Section 1, \u00c6MINIUM was inspired \nby want\u00ading to realize the concurrency bene.ts of functional pro\u00adgramming in an imperative setting. Therefore, \nall functional programming languages can be seen as related work. In par\u00adticular Haskell [Jones 2003], \nwith is monad system, relates closely to our system. Greenhouse [Greenhouse and Scherlis 2002] describes \nan annotation and policy system for specifying relationships be\u00adtween locks and state in systems with \nexplicit concurrency. In Greenhouse s system state can be grouped into regions and locks can be associated \nwith state or regions of state. While Greenhouse uses data groups to show the absence of race conditions, \nour approach uses data groups to infer pos\u00adsible correct orders of execution. Our use of data groups \nis also similar to ownership systems [Clarke et al. 1998]. Boyland [Boyland 2003] presented a system \nthat uses read and write permissions to automatically infer depen\u00addencies between operations. Its goal \nwas to verify the cor\u00adrectness of already explicitly parallelized programs. Our ap\u00adproach reverses this \nscenario: we use permissions for ex\u00adtracting concurrency based on the inferred dependencies. Additionally, \nour system supports shared permissions.  Among recently developed programming languages, Fortress [Allen \net al. 2008] is the most comparable to our concurrency\u00ad by-default paradigm. Fortress changes the semantics \nof cer\u00adtain programming constructs, like tuple constructors or for\u00adloops, to be concurrent by default. \nLike our system, Fortress takes advantage of the high-level atomic block primitive to synchronize. Unlike \nour system, Fortress does not infer data dependencies or enforce the correct usage of atomic blocks, \nand therefore it has no built-in protection against data races. Another related concurrent programming \nlanguage is Cilk [Blumofe et al. 1995]. Cilk extends C with three addi\u00ad tional keywords: cilk, spawn \nand sync. Every method an\u00adnotated with cilk can be asynchronously spawned-off with the spawn keyword. \nThe sync keyword is used to wait for a previously started asynchronous task to complete. The Cilk runtime \nimplements a highly effective work stealing mecha\u00adnism to achieve high performance. Like Fortress, Cilk \ndoes not provide any build-in protection against race conditions or support for correct synchronization \nof shared resources like \u00c6MINIUM does. Axum (formerly known as Maestro) [Mic 2009] is an actor-based \nprogramming language. Axum comes with sev\u00aderal operators to allow the explicit construction of data.ow \ngraphs, which can hierarchically composed. For ef.ciency reasons, Axum also provides domains, containers \nfor state, which allows associated actors to access the enclosed state. Actors can either be readers \nor writers of shared state and scheduling will follow the one writer or multiple reader model. Many concepts \nin Axum and \u00c6MINIUM look sim\u00adilar, in particular the data.ow approach, and the use of data\u00adgroups/domains \ncombined with the explicit speci.cation of accesses. But \u00c6MINIUM focuses on object-oriented pro\u00adgramming, \nautomatically infers the data.ow graph and sup\u00adports true shared state between concurrent entities. 5. \nConclusion We presented \u00c6MINIUM, a novel programming language for highly concurrent systems, that uses \naccess permissions and data groups to make side effects explicit. In \u00c6MINIUM ev\u00aderything is concurrent \nby default and concurrent execution is solely limited by explicit and automatically-inferred depen\u00addencies. \n\u00c6MINIUM requires only local reasoning about side effects and handles dependency inference and concurrent \nex\u00adecution automatically. Therefore we believe that \u00c6MINIUM, by following our concurrent-by-default paradigm, \nrepresents a major step towards programming highly concurrent sys\u00adtems. Future work will focus on the \nsemantics of the system, the implementation of an ef.cient runtime system and in\u00advestigation of practical \nsolutions to the granularity problem. Acknowledgments This work was partially supported by the Portuguese \nRe\u00adsearch Agency FCT, through a scholarship (SFRH / BD / 33522 / 2008), CISUC (R&#38;D Unit 326/97), \nthe CMU Portugal program, DARPA grant #HR0011-0710019, NSF grants CCF-0546550 and CCF-0811592, and Army \nResearch Of.ce grant number DAAD19-02-1-0389 entitled Perpetually Available and Secure Information Systems. \nReferences E. Allen, D. Chase, J. Hallett, V. Luchangco, J.W. Maessen, S. Ryu, G.L. Steele Jr, and S. \nTobin-Hochstadt. The Fortress language speci.cation version 1.0. Technical report, Sun Microsystems, \nInc, 2008. N. E. Beckman, K. Bierhoff, and J. Aldrich. Verifying correct usage of atomic blocks and \ntypestate. Proc. ACM SIGPLAN conference on OOPSLA, 43(10):227 244, 2008. K. Bierhoff and J. Aldrich. \nModular typestate checking of aliased objects. In Proc. ACM SIGPLAN conference on OOPSLA, pages 301 320, \n2007. R. D. Blumofe, C. F. Joerg, B. C. Kuszmaul, C. E. Leiserson, K. H. Randall, and Y. Zhou. Cilk: \nan ef.cient multithreaded runtime system. Proc. ACM SIGPLAN symposium on PPoPP, 30(8): 207 216, 1995. \n H.-J. Boehm. Transactional Memory Should Be an Implementation Technique, Not a Programming Interface. \nTechnical Report HPL-2009-45, HP Laboratories, 2009. J. Boyland. Checking interference with fractional \npermissions. In SAS, pages 55 72. Springer, 2003. D. G. Clarke, J. M. Potter, and J. Noble. Ownership \ntypes for .exible alias protection. Proc. ACM SIGPLAN conference on OOPSLA, 33(10):48 64, 1998. J.-Y. \nGirard. Linear logic. Theor. Comput. Sci., 50(1):1 102, 1987. A. Greenhouse and W. L. Scherlis. Assuring \nand evolving con\u00adcurrent programs: annotations and policy. In Proc. ICSE, pages 453 463, New York, NY, \nUSA, 2002. ACM. S.L.P. Jones. Haskell 98 language and libraries: the revised report. Cambridge University \nPress, 2003. J. Larus and R. Rajwar. Transactional Memory. Morgan &#38; Clay\u00adpool Publishers, 1 edition, \n2007. K. Rustan M. Leino. Data groups: specifying the modi.cation of extended state. In Proc. ACM SIGPLAN \nconference on OOP-SLA, pages 144 153, New York, NY, USA, 1998. M. Martin, C. Blundell, and E. Lewis. \nSubtleties of Transactional Memory Atomicity Semantics. IEEE Computer Architecture Letters, 5(2), 2006. \n Axum Programmer s Guide. Microsoft Corporation, 2009. http: //msdn.microsoft.com/en-us/devlabs/dd795202.aspx. \nJE Rumbaugh. A parallel asynchronous computer architecture for data .ow programs. PhD thesis, Massachusetts \nInstitute of Technology, 1975. MIT-LCS-TR-150. D. J. Spoonhower. Scheduling Deterministic Parallel Programs. \nPhD thesis, Carnegie Mellon University, May 2009. H. Sutter. The Free Lunch Is Over: A Fundamental Turn \nToward Concurrency in Software. Dr. Dobb s Journal, 30(3):16 20, 2005.   \n\t\t\t", "proc_id": "1639950", "abstract": "<p>The rise of the multicore era is catapulting concurrency into mainstream programming. Current programming paradigms build in sequentiality, and as a result, concurrency support in those languages forces programmers into low-level reasoning about execution order. In this paper, we introduce a new programming paradigm in which concurrency is the default. Our Aeminium language uses access permissions to express logical dependencies in the code at a higher level of abstraction than sequential order. Therefore compiler/runtime-system can leverage that dependency information to allow concurrent execution. Because in Aeminium programmers specify dependencies rather than control flow, there is no need to engage in difficult, error-prone, and low-level reasoning about execution order or thread interleavings. Developers can instead focus on the design of the program, and benefit as the runtime automatically extracts the concurrency inherent in</p>", "authors": [{"name": "Sven Stork", "author_profile_id": "81442592591", "affiliation": "Carnegie Mellon University, Pittsburg, USA", "person_id": "P1728341", "email_address": "", "orcid_id": ""}, {"name": "Paulo Marques", "author_profile_id": "81100552548", "affiliation": "University of Coimbra, Coimbra, Portugal", "person_id": "P1728342", "email_address": "", "orcid_id": ""}, {"name": "Jonathan Aldrich", "author_profile_id": "81100454133", "affiliation": "Carnegie Mellon University, Pittsburg, USA", "person_id": "P1728343", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1639950.1640060", "year": "2009", "article_id": "1640060", "conference": "OOPSLA", "title": "Concurrency by default: using permissions to express dataflow in stateful programs", "url": "http://dl.acm.org/citation.cfm?id=1640060"}