{"article_publication_date": "10-25-2009", "fulltext": "\n The Habanero Multicore Software Research Project Rajkishore Barik, Zoran Budimli\u00b4c, Vincent Cav`e, Sanjay \nChatterjee, Yi Guo, David Peixotto, Raghavan Raman, Jun Shirako, Sa.gnak Tas\u00b8irlar, Yonghong Yan, Jisheng \nZhao, Vivek Sarkar Computer Science Department, Rice University, 6100 Main Street, Houston, TX 77005, \nUSA {rajbarik, zoran, vc8, cs20, yguo, dmp, raghav, shirako, sagnak, yanyh, jz10, vsarkar}@cs.rice.edu \nAbstract Multiple programming models are emerging to address an in\u00adcreased need for dynamic task parallelism \nin multicore shared\u00admemory multiprocessors. This poster describes the main compo\u00adnents of Rice University \ns Habanero Multicore Software Research Project, which proposes a new approach to multicore software en\u00adablement \nbased on a two-level programming model consisting of a higher-level coordination language for domain \nexperts and a lower\u00adlevel parallel language for programming experts. Categories and Subject Descriptors \nD.1.3 [Concurrent Pro\u00adgramming]: Parallel Programming General Terms Languages, Performance 1. Introduction \nThe Habanero project [14] at Rice University was initiated in Fall 2007 to address the multicore software \nchallenge by developing new programming technologies languages, compilers, man\u00adaged runtimes, concurrency \nlibraries, and tools that support portable parallel abstractions for future multicore hardware with \nhigh productivity and high performance. Our goal is to create a software platform that allows application \ndevelopers to reuse their investment across multiple generations of homogeneous and het\u00aderogeneous multicore \nhardware. A highly desirable solution to the multicore software productivity problem is to introduce \nhigh-level declarative programming models that are accessible to develop\u00aders who are experts in different \ndomains but lack deep experience with imperative parallel programming, while still enabling pro\u00adgramming \nexperts to make tuning and deployment decisions for the application. To that end, we propose a two-level \nprogramming model consisting of a higher-level coordination language for do\u00admain experts and a lower-level \nparallel language for programming experts.We use the Concurrent Collections (CnC) programming model [9, \n11, 4, 3] as the foundation for the higher-level coordina\u00adtion language in the Habanero project, and \nthe Habanero Java (HJ) language as the foundation for the lower-level parallel language1. This approach \nenables an important separation of concerns be\u00adtween domain experts who specify the inherent semantics \nof the 1 A Habanero-C language is also in development for C programmers. Data Dependence Figure 1. Data \nand Control dependences in a CnC program computation at the CnC level and programming experts who make \ndecisions on how the parallelism should be exploited on a given multicore platform. The programming expert \nis not necessarily a human it could also be a static compiler, dynamic runtime, or an auto-tuning component, \nfor example. To tie the levels together, we use an integrated runtime system that supports co-scheduling \nof CnC steps and HJ tasks (activities). An initial release of our two\u00adlevel execution model is available \nat [17]. 2. Concurrent Collections Programming Model The three constructs in the Concurrent Collections \n(CnC) model2 are computation steps, data items,and control tags. Statically, each of these constructs \nis a collection representing a set of dynamic in\u00adstances. Step, item and tag3 instances are the units \nfor scheduling parallel computations, communicating and synchronizing data ac\u00adcesses, and creating new \nstep instances, respectively. The program is represented as a graph. The computation step, data item \nand control tag collections are represented as circles, boxes and triangles respectively (see Figure \n1). We represent the graphintextual form using () for computation steps, [] for data items and <> for \ncontrol tags. The edges in the graph specify the partial ordering constraints required by the semantics. \nOne type of ordering constraint arises from a data dependence [1]. For example, in the top of Figure \n1, an instance of step (F1) produces an instance of item [X] which is consumed by an instance of step \n(F2). Clearly the producing step instance must execute before the consuming step instance. Copyright \nis held by the author/owner(s). 2 The CnC model builds on past work on TStreams [10]. OOPSLA 2009, October \n25 29, 2009, Orlando, Florida, USA. ACM 978-1-60558-768-4/09/10. 3 Any hash-able value can be used as \na tag.  Another type of ordering constraint arises from a control depen\u00addence [7], where one computation \nstep determines if another com\u00adputation step will execute. In the bottom of Figure 1, an instance of \nstep (F3) produces an instance of control tag <T> whichinturn leads to the creation of an instance of \nstep (F4). The producing step instance must execute before the newly created step instance. A step instance \nmay consume and produce data items in multi\u00adple item collections, and produce control tags in multiple \ntag col\u00adlections thereby leading to more general graph structures than the simple examples in Figure \n1. Tags play a key role in distinguishing instances of data items and computation steps. For item collections, \nthe tag is akin to a primary key used to access an item instance; the single assignment rule ensures \nthat at most one item is produced in an item collection with a given tag. For tag collections, the tag \nis akin to an iteration tuple or calling context that uniquely identi.es a step instance; again, the \nsingle assignment rule ensures that at most one step is produced with a given tag. There are a number \nof properties of the CnC model that make it attractive for use by domain experts in our two-level program\u00adming \nmodel. First, the domain expert does not have to explicitly think about sequential or parallel execution \nof steps; the ordering constraints among steps are speci.ed exactly by the control and data dependencies \nin the CnC graph. Second, all CnC programs are data-race-free i.e., the single-assignment rule ensures \nthat each read of a data item will return the same value regardless of the order in which write operations \nare performed (since there can be at most one write with a given tag value in a given item collection). \nThird, all CnC programs are deterministic i.e., all executions that read the same input from the environment \nwill result in the same output, regardless of the order in which step instances are executed. 3. Habanero \nProgramming Language Constructs The Habanero Java (HJ) language under development at Rice Uni\u00adversity \n[14] builds on past work with the X10 project at IBM [6], and proposes an execution model for multicore \nprocessors that builds on four orthogonal constructs: 1. Lightweight dynamic task creation and termination \nusing async and .nish constructs [8]. The async [(Place)] [phased(c...)] Stm statement creates a new \nchild activity that executes state\u00adment Stm, registered on all the phasers in the phased(...) list. It \nreturns immediately and may only reference .nal variables in enclosing blocks. The .nish Stm statement \nexecutes Stm and waits until all (transitively) spawned asyncs have terminated. The .nish statement has \na rooted exception model that traps all exceptions thrown by spawn activities and throws an (aggre\u00adgate) \nexception if any spawned async terminates abruptly [6]. 2. Locality control with task and data distributions \nusing the place construct [5]. Places enable co-location of async tasks and data objects.  3. Mutual \nexclusion and isolation among tasks using the iso\u00adlated construct [2]. The isolated [(Place List)] Stm \nstatement executes Stm in isolation with respect to the list of places. As advocated in [12], we use \nthe isolated keyword instead of atomic (as it is named in X10) to make explicit the fact that the construct \nsupports weak isolation rather than strong atomicity. Commutative operations, such as updates to histogram \ntables and insertions in a shared data structure, are a natural .t for isolated blocks executed by multiple \nactivities.  4. Collective and point-to-point synchronization using the phasers construct [15, 16]. \nThe phaser p = new phaser(mode) statement allocates a new phaser in a registration mode, which can be \nsignal, wait, signal-wait or single. Activities can use phasers to achieve collective barrier or point-to-point \nsynchronization.  Phasers are dynamic (number of activities using a phaser can change at runtime), deadlock-free \nin absence of explicit wait operations, and lightweight. The next statement suspends the activity until \nall phasers that it is registered with can advance. Since HJ is based on Java, the use of certain primitives \nfrom the Java Concurrency Utilities [13] is also permitted in HJ programs, most notably operations on \nJava Concurrent Collections such as ConcurrentHashMap and on Java Atomic Variables.  References [1] \nR. Allen and K. Kennedy. Optimizing Compilers for Modern Architectures. Morgan Kaufmann Publishers, 2001. \n [2] R. Barik and V. Sarkar. Interprocedural load elimination for dynamic optimization of parallel programs. \nIn The Eighteenth International Conference on Parallel Architectures and Compilation Techniques (PACT), \nSeptember 2009. (To appear). [3] Z. Budimli\u00b4c et el. Declarative aspects of memory management in the \nconcurrent collections parallel programming model. In DAMP 2009: Workshop on Declarative Aspects of Multicore \nProgramming, January 2009. [4] Z. Budimli\u00b4c et al. Multi-core implementations of the concurrent collections \nprogramming model. In CPC 09: 14th International Workshop on Compilers for Parallel Computers. Springer, \nJanuary 2009. [5] S. Chandra et al. Type inference for locality analysis of distributed data structures. \nIn PPoPP 08: Proceedings of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming, \npages 11 22, New York, NY, USA, 2008. ACM. [6] P. Charles et al. X10: an object-oriented approach to \nnon-uniform cluster computing. In OOPSLA 05: Proceedings of the 20th annual ACM SIGPLAN conference on \nObject-oriented programming, systems, languages, and applications, pages 519 538, New York, NY, USA, \n2005. ACM. [7] J. Ferrante et al. The Program Dependence Graph and its Use in Optimization. ACM Transactions \non Programming Languages and Systems, 9(3):319 349, July 1987. [8] Y. Guo et al. Work-First and Help-First \nScheduling Policies for Async-Finish Task Parallelism. In IPDPS 09: International Parallel and Distributed \nProcessing Symposium (To Appear), 2009. [9] Intel (r) concurrent collections for c/c++. http://softwarecommunity. \nintel.com/articles/eng/3862.htm. [10] K. Knobe and C. D. Offner. Tstreams: A model of parallel computation \n(preliminary report). Technical Report HPL-2004-78, HP Labs, 2004. [11] K. Knobe and V. Sarkar. The concurrent \ncollections parallel programming model -foundations and implementation challenges. PLDI 2009 tutorial. \nhttp://www.cs.virginia.edu/kim/ publicity/pldi09tutorials/CnC-tutorial.pdf. [12] J. R. Larus and R. Rajwar. \nTransactional Memory. Morgan &#38; Claypool, 2006. [13] T. Peierls et al. Java Concurrency in Practice. \nAddison-Wesley Professional, 2005. [14] Rice University. Habanero Multicore Software Research project. \n[15] J. Shirako et al. Phasers: a uni.ed deadlock-free construct for collec\u00adtive and point-to-point synchronization. \nIn ICS 08: Proceedings of the 22nd annual international conference on Supercomputing, pages 277 288, \nNew York, NY, USA, 2008. ACM. [16] J. Shirako et al. Phaser Accumulators: a New Reduction Construct for \nDynamic Parallelism. In 23rd IEEE IPDPS, 2009. [17] Habanero Team. Download site for initial release \nof Concurrent Collections (CnC) and Habanero Java (HJ) integrated runtime system. http://www.cs.rice.edu/~ \nvsarkar/downloads/ cnc_distrib_2009_07_21.zip.  \n\t\t\t", "proc_id": "1639950", "abstract": "<p>Multiple programming models are emerging to address an increased need for dynamic task parallelism in multicore shared-memory multiprocessors. This poster describes the main components of Rice University's Habanero Multicore Software Research Project, which proposes a new approach to multicore software enablement based on a two-level programming model consisting of a higher-level coordination language for domain experts and a lower-level parallel language for programming experts.</p>", "authors": [{"name": "Rajkishore Barik", "author_profile_id": "81325487459", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728527", "email_address": "", "orcid_id": ""}, {"name": "Zoran Budimlic", "author_profile_id": "81100227584", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728531", "email_address": "", "orcid_id": ""}, {"name": "Vincent Cav&#232;", "author_profile_id": "81444601805", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728532", "email_address": "", "orcid_id": ""}, {"name": "Sanjay Chatterjee", "author_profile_id": "81444603904", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728533", "email_address": "", "orcid_id": ""}, {"name": "Yi Guo", "author_profile_id": "81444594948", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728534", "email_address": "", "orcid_id": ""}, {"name": "David Peixotto", "author_profile_id": "81351607531", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728535", "email_address": "", "orcid_id": ""}, {"name": "Raghavan Raman", "author_profile_id": "81440614441", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728536", "email_address": "", "orcid_id": ""}, {"name": "Jun Shirako", "author_profile_id": "81100577078", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728537", "email_address": "", "orcid_id": ""}, {"name": "Sa&#287;nak Ta&#351;&#305;rlar", "author_profile_id": "81444608866", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728538", "email_address": "", "orcid_id": ""}, {"name": "Yonghong Yan", "author_profile_id": "81442601345", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728528", "email_address": "", "orcid_id": ""}, {"name": "Yisheng Zhao", "author_profile_id": "81444605023", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728529", "email_address": "", "orcid_id": ""}, {"name": "Vivek Sarkar", "author_profile_id": "81100597290", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1728530", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1639950.1639989", "year": "2009", "article_id": "1639989", "conference": "OOPSLA", "title": "The habanero multicore software research project", "url": "http://dl.acm.org/citation.cfm?id=1639989"}