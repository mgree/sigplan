{"article_publication_date": "10-25-2009", "fulltext": "\n Gaining inSight into Programs that Analyze Programs By Visualizing the Analyzed Program Agastya Nanda \nMangala Gowri Nanda Jaypee Institute of Information Technology IBM Research, India agastya.nanda@jiitu.org \nmgowri@in.ibm.com Abstract Visualization of a program typically entails low level views of the program \nexecution state showing, for example, method invocations or relations amongst heap objects. In most cases, \nthis would imply visualization of the executable program. However there is a certain genre of programs \nthat analyze or transform other programs. These programs could be compil\u00aders, static bug detectors, test \nsuite analyzers, model to model transformers etc. In such cases, very often, it helps to visu\u00adalize what \nis happening to the input program rather than the analyzer program. It is for such programs that we describe \na con.gurable, analysis framework. For ease of exposition, we call the analyzer program the manipulate \nprogram, and the input program the puppet program. To facilitate the visual\u00adization, we instrument the \nmanipulate program to generate a dump as it analyzes the puppet program. Using the dump , we reconstruct \nthe interprocedural control .ow graph of the puppet program and then visualize the .ow of the manip\u00adulate \nprogram over the puppet program. We use colors to highlight different events in the manipulate program. \nUsing this scheme, we are able to (1) gain insight into the manipu\u00adlate program; (2) collect useful information \n/ statistics about the puppet program. We have implemented the visualizer in a tool called INSIGHT . \nWe ran INSIGHT on a static debug\u00adging tool (the manipulate program) called XYLEM. XYLEM applies static \nanalysis to .nd potential null pointer excep\u00adtions in a puppet program, as for example, the Apache Ant \nprogram. We report the insights gained by running XYLEM through INSIGHT on ANT and other puppet programs. \nCategories and Subject Descriptors D.2.5 [Software Engi\u00adneering]: Testing and Debugging Debugging aids; \nD.1.7 [Programming Techniques]: Visual Programming Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. OOPSLA 2009, October 25 29, 2009, Orlando, Florida, USA. Copyright \nc &#38;#169; 2009 ACM 978-1-60558-768-4/09/10. . . $10.00 General Terms Algorithms, Design Keywords Visualization, \nAnalysis 1. Introduction In visualization, it is important to get the right perspective. Often there \nare several angles to be explored. Typically, visu\u00adalization of a program entails stepping through the \nprogram execution steps while examining the data structures that it manipulates [Wang et al. 2003, Ruthruff \net al. 2003, Reiss 2003, Reiss and Renieris 2005]. The visualization may be based on stored data [Ruthruff \net al. 2003] or it may be based on dynamically executing program [Reiss 2003, Reiss and Renieris 2005]. \nIt may be visualizing control .ow [Gest\u00adwicki and Jayaraman 2005] or it may be visualizing the heap [Pauw \nand Sevitsky 1999]. Either way, the visualiza\u00adtion is based on the executable program that one is trying \nto debug / understand. There exist a certain class of programs that analyze other programs. We call the \nanalyzers the manipulate programs and the analyzed the puppet programs. In such manipu\u00adlate programs, \nwe found that a different visualization per\u00adspective could help bring fresh insight into understanding \nthe working of the program. While our end goal remains the same to understand the working of a given \nmanipulate executable our approach is to visualize the analyzed pup\u00adpet program instead. Based on the \nvisualization of the puppet program, we gain a fresh new perspective on the behavior of the manipulate \nprogram. In this paper we describe a tool, INSIGHT,thatwe have built that helps visualize a puppet program \nas it is analyzed by the manipulate program. We introduce here a manipulate program, XYLEM [Nanda and \nSinha 2009] that we used to test our hypothesis against. XYLEM is a static bug detector that takes as \ninput Java byte\u00adcode and uses interprocedural analysis to .nd potential null dereferences in the input \nprogram. We instrumented XYLEM to output relevant data as it analyzes the input program. Dif\u00adferent events \nwithin XYLEM are marked with different col\u00adors. For example, when XYLEM .nds a potential source of null \ndereference, it drops a red marker and when it comes to a point where there is no possibility of a null \ndereference it drops a green marker. INSIGHT animates the .ow of XYLEM as it manipulates the analyzed \npuppet. We used several input programs to test INSIGHT on XYLEM. However, most of the examples have been \npicked up from Apache ANT.  INSIGHT helps us observe XYLEM in two different ways, (1) By observing the \nControl Flow Graph of the puppet pro\u00adgram to obtain a visual representation of the steps followed by \nXYLEM s algorithm and locate its pitfalls or any inconsis\u00adtencies, and (2) By analyzing the data collected \nat the end of the program to realize the ef.ciency, accuracy and coverage of XYLEM. Although it is not \nthe primary goal of INSIGHT, we do also analyze the data to gain knowledge of the puppet program. On \nthe graphical aspect of INSIGHT, we have a host of features, including zooming, panning, animation, slicing \netc. We have used INSIGHT on XYLEM and we found that INSIGHT gave us tremendous insight into the working \nof XYLEM. Currently, INSIGHT is tuned to the requirements of XYLEM. However, we have also designed a \ngeneric, con.g\u00adurable framework where INSIGHT can be utilized by any pro\u00adgram that manipulates another \nprogram. The main contributions of this paper are: A methodology to understand the working of a manip\u00adulator \nprogram by visualizing its working on a puppet program.  A con.gurable animation framework that can \nbe used to visualize the manipulation of a puppet program by a manipulate application.  An implementation \nthat helps us understand the program in two ways (1) By just using visual aspects and (2) By analyzing \nthe data collected.  The rest of the paper is organized as follows: Section 2 describes XYLEM, in SEction \n3, we describe a simple, yet innovative algorithm to render a control .ow graph and de\u00adscribe the features \nof INSIGHT. In section 3, we explain our insights gained by using INSIGHT on XYLEM. In section 4, we \ndescribe a generic framework for INSIGHT. Insection5, we give empirical data based on our use case study. \nSection 6gives relatedwork, andinsection7,weconclude. 2. About XYLEM XYLEM [Nanda and Sinha 2009] is \na tool that performs in\u00adterprocedural analysis on Java programs. Starting at every dereference of an \nobject, it traces backwards along the con\u00adtrol .ow graph, trying to locate potential sources of nullness. \nInstrumenting XYLEM for INSIGHT We manually instru\u00admented XYLEM to dump information as it processed paths \nin the puppet program. For every statement (or, to be more precise, every bytecode) in the puppet program \nthat XYLEM processed, the instrumented code would dump the function id, the basic block id, the instruction \nid, a text output and a color. The default color for instructions is orange. XYLEM uses a depth .rst, \nbacktracking algorithm. That is, it probes depth .rst on the reverse control .ow graph, until it reaches \n1. A point where it can categorically determine that there is no possible nullness a false path (colored \ngreen in INSIGHT) 2. A point where it .nds a potential nullness source a true path (colored red in INSIGHT) \n 3. The entry of the procedure and .nds that there may be a true path depending on the valuation of some \ninput parameter a potential interprocedural true path (no spe\u00adcial coloring) 4. A point that has already \nbeen visited with the same set of constraints and hence need not be explored any further (colored yellow \nin INSIGHT)  Capturing incompleteness of XYLEM XYLEM has many sources of incompleteness that we wished \nto observe and understand with the help of INSIGHT. Path limitation. During interprocedural analysis \na method that is invoked by another method is analyzed in the given context. Each context is de.ned by \na (set of) postconditions. For each postcondition, the analysis generates preconditions for every path \nin the method along which the nullness is not killed. However, due to memory constraints, only a lim\u00adited \nnumber of paths are collected and propagated to the next level. Any additional paths are are simply discarded \nmaking the analysis incomplete. This is the path limitation. Methods with this limitation have the entry \nnode colored pink. State space limitation. Another source of incompleteness is when the number of constraints \nat a given instruction exceeds a user de.ned limit (typically limited to 80), then no new constraints \nare generated at that point and hence no new paths are explored. This is the state space limitation and \nthe relevant node is colored pink. Time limitation. XYLEM maintains a timer for each traversal. If the \ntraversal is inconclusive at the end of the user speci.ed time (typically 2 seconds), the traversal is \naborted and a magenta event is dropped. Note that a XYLEM path stops at a magenta, green, red or yellow \nblock, but continues at a pink block. 3. INSIGHT In this section we .rst explain the algorithm for rendering \nthe Control Flow Graph of a method. We then describe the features provided by INSIGHT to visualize the \ngraph. 3.1 Rendering the CFG INSIGHT uses a simple graph drawing algorithm tuned speci.cally for single-entry \nsingle-exit graphs. The simplest unit of the graph is the BasicBlock, which represents a set of sequential \ninstructions. The basic philosophy of place\u00ad  Figure 1. Features of INSIGHT ment of BasicBlocks is \nthat, if there is an edge from one Ba\u00adsicBlock to another, the second must be placed at some po\u00adsition \nthat is vertically below the .rst except in the case of back-edges1 and that there should be no overlap \nbetween horizontal placing. This ensures a visually comprehensible graph layout. We draw all BasicBlocks \nin the same size and render the contents of the BasicBlock separately in a side pane. We do not handle \noverlapping or criss-crossing edges. However, due to the designed placement of the blocks, most edges \nbe\u00adhave very well. It is only back-edges and edges that cross several levels of vertical blocks that \ncreate problems. How\u00adever, rather than develop a complex algorithm, we came up with the following simple \nheuristic which works very well except for some pathological cases. We count the number of vertical edges \nthat cross a particular level and accordingly increase the horizontal spacing of blocks at that level. \nEdges between BasicBlocks are colored green for a true edge, red for a false edge and blue for a Back \nEdge. A structure, Chain, contains the longest non-branching sequence of BasicBlocks that are not merge \npoints. The width .eld of a Chain represents the maximum horizontal space that it requires. INSIGHT adds \nthe widths of the Chains to their parents as and when it generates them. procedure add-width ( Chain \nch, int val ) ch.width = val while ch.parents.count = 1 ch = ch.parent ch.width += val end while 1 Back \nedges are loop edges or, to put it more formally, a back edge is one where the head dominates the tail. \nThe procedure generate-chains is called with a new Chain head and the entry BasicBlock of the current \nmethod. This procedure establishes the relations between all the Chains that are formed by following \nthe successors of the BasicBlocks. All back edges are ignored during formation of chains, since they \ndon t affect the placement of the Ba\u00adsicBlocks. procedure generate-chains ( Chain ch, BasicBlock bb ) \nwhile number of successors of bb = 1 if bb has more than 1 parent then find the chain, ch-merge containing \nbb if ch-merge does not exist then ch-merge = new Chain add bb to ch-merge add ch to parents of ch-merge \nadd ch-merge to successors of ch call generate-chains ( ch-merge, bb ) return else addbbtoch bb = successor \nof bb end while width = 0 for each successor, bbs of bb do c2 = new Chain; c2.parent=ch add c2 to successors \nof ch call generateChains ( c2, bbs ) width = width + 1 end for call add-width ( ch, width ) Next, a \nprocedure calc-pos is called with the Chain head as its argument. This procedure sets the positions of \nthe var\u00adious Chains relative to each other. The depth .eld decides vertical offset of the chain and the \npos .eld represents the horizontal offset. The Chain head is initialized with a hori\u00adzontal and vertical \noffset of zero. Each Chain that is a merge point (i.e. it has more than one parent) is set at the midpoint \nof all its parents. The horizontal offsets are calculated so as to balance the successor chains to the \nleft and right of the parent, spacing them according to their widths so as to avoid overlapping. procedure \ncalc-pos ( Chain ch ) if ( ch has more than 1 parent ) set pos of ch to average pos of all parents b \n= ch.pos -ch.width/2 for each successor, chs of ch if ( chs.depth < ch.depth + length of ch ) then chs.depth \n= ch.depth + length of ch chs.pos = b b = b + chs.width call calc-pos ( chs )  Figure 2. An unsliced \ngraph and the corresponding sliced graph inset  3.2 Features Our tool INSIGHT takes as input four sets \nof data data pertaining to the call graph, the control .ow graphs (CFG) for each function, con.guration \nand animation traces. The call graph and the CFG data is used to render the graphs and con.guration data \nis used to customize the animation framework. The trace data is the data used to visualize the puppet \nprogram. The trace data may consist of several sets of traces. For example, in the case of XYLEM, there \nis one trace for each traversal from the dereference of an object. Details of the data format are given \nin Section 5. 1. Movement: Once the graph has been rendered, INSIGHT allows panning and scrolling of \nthe graph in order to view speci.c portions of the graph on the screen. 2. Zoom: The user can zoom out \nto view the structure of the CFG, and zoom in to see the details of the various components of the graph. \n 3. Animate: Animation involves picking a trace from the manipulator dump and then displaying the events \nin se\u00adquence. Each event consists of a speci.c instruction in a speci.c color. INSIGHT highlights the \nevent by .lling the relevant block in the speci.ed color. In a side pane, all the instructions in the \nblock are displayed in black and the current instruction is highlighted in blue. After a con\u00ad.gurable \ndelay, the next instruction in the trace is high\u00adlighted. The previous block retains its color, but only \nas an outline. This way we get a visual trace of the blocks that have been visited and the corresponding \ncolors.  As the animation proceeds, the display pans up, down, left or right as required if the current \nblock falls out of the current display. Animation may be performed step by step or as a simple run or \nas a run using breakpoints. The breakpoints can be speci.ed in terms of instructions or colors for exam- \n Figure 3. Tracing a path using the magenta lines. The thickness of the magenta line is poportional to \nthe number of times the edge has been visited. ple, break when you encounter a speci.c color or break \nwhen there is any change in color. Breakpoints can also be speci.ed in terms of method boundaries break \njust before or just after crossing a method boundary. Animation may proceed backwards or forwards through \nthe graph, or change direction as required. 4. Search: Two types of searches can be performed in INSIGHT \n(1) Just as we can set up breakpoints, it is also possible to jump directly to a point in the animation \nwhere the effect is identical to running the animation to the breakpoint. (2) INSIGHT can locate a fresh \ntrace to be animated based on the method signature and line number of the potential bug. 5. Trace lists: \nINSIGHT builds lists based on con.gurable input data. For example, for XYLEM, we build lists of traces \nthat represent true paths, false paths, traces that have pink nodes, traces that have magenta nodes etc. \nA given trace may be added to multiple lists. Traces can be picked from any list. 6. Flow of Path: Each \npath starts at an orange node and terminates at a red, green or yellow node. Figure 3 shows an example \nof how such a path is visualized in INSIGHT. The magenta lines overlaying the graph depict the .ow of \nthe path as a block is traversed multiple times, the magenta line also gets thicker. 7. Slicing: If \nthe graph becomes too big to visualize com\u00adfortably, INSIGHT can compress the graph to display only the \nBasicBlocks that are actually traversed. In .gure 2, the .rst image shows the colored BasicBlocksthatwere \nobtained through animating the graph. As we can see, nineteen BasicBlocks were not traversed during the \nan\u00adimation and were left black. The second image redraws   the graph, but with only the colored BasicBlocksand \nig\u00adnores the ones that were not traversed. Note, that the graph rendering algorithm may not place the \nblocks in the same manner as the unsliced program. Also currently, in the slice, all the edges are rendered \nblack. In the next ver\u00adsion, the edges in the slice will also be colored red, green and blue appropriately \nfor false, true and back edges. Fur\u00adther, the compressed graph needs to be fed back into the system to \nbe animated. This is work in progress. 8. Displaying Instructions: The instructions present in any BasicBlock \ncan be displayed by clicking on it. This is work in progress. 9. Inter-procedural .ow: Currently, each \ntime the animation crosses a method boundary, the new method is rendered and the animation continues \nat the appropriate block in the method. To this, we plan to add a display of the call graph also, so \nthat one can see at a glance, the methods that have been visited in the trace.  4. INSIGHT with XYLEM \nWhile there is a host of information that can be inferred from the data collected, this section is about \nthe information we have collected visually -by just looking at the output of INSIGHT. Inference from \ndata will be presented in Section 6. In this section we talk of our experience with XYLEM, a tool for \ntracking null dereferences in Java programs.  4.1 Insights gained through the visualization process \nInsight 1 -Observing stack over.ows Consider the exam\u00adple shown in Figure 1. The block painted pink indicates \nthat it has been visited at least 80 times with different constraints, based on the preceding path traversed. \nHowever, if we look at the blocks above the pink block in Figure 1, we observe that along all paths there \nis a green block indicating that there can be no null dereference. In order to further understand what \nis happening, it is possible to refer to the code displayed alongside (not shown in the .gure). Here \nis the pseudo-code String str = null; if ( cond1 ) str = \"abc1\"; else if ( cond2 ) str = \"abc2\"; else \nif ( cond3 ) str = \"abc3\"; else str = \"abc4\"; ... str.equals(... Clearly, str cannot be null at the \npoint of dereference at the statement str.equals(....Yet XYLEM traverses the call graph more than 80 \ntimes before coming to this conclusion. That is, XYLEM .nds at least 80 paths from the source to the \npink block along which the potential nullness of str is not known yet. This is something that is obvious \nfrom the colors in the picture but would have been very hard to detect otherwise. Figure 4. One untidy \nand three structured control .ow graphs We are now considering ways to take this into account in XYLEM \ns logic in order to make it more ef.cient. Essentially, it should be suf.cient to traverse the graph \nonce from the source to the pink block (rather than 80 times) and then from the pink block to the green \nblocks in order to determine that there is no potential null dereference. Insight 2 -Observing path over.ows \nWe mentioned in Section 2 and in [Nanda and Sinha 2009] that XYLEM anal\u00adysis continues even after a stack \nor a path over.ow. This makes perfect sense for stack over.ows that are local over.ows so there could \nbe other paths to be explored that may lead to a null dereference. However, in the case of path over.ows, \ntraversing more paths does not help since extra paths will not be recorded. This may be blindingly obvious, \nhowever programmers often overlook the obvious and this is yet another source of inef.ciency that we \ndid not catch un\u00adtil we observed visually that after a path over.ow, no more paths are accumulated. This \ninef.ciency has now been .xed in XYLEM. Insights 3 -About the structure of the input program While most \nof the procedures were well structured, there were a few that were not as can be seen in Figure 4. Visu\u00adally, \nit is easy to pick up the methods that look like good candidates for testing. For ANT in particular, \nwe looked at over 200 methods. Of theses, about 170 could be viewed in a single frame at one level of \nzoom-out (which is the size of most pictures in this paper), around 10 could be viewed in two vertical \nframes by scrolling up and down, about 20 in three to seven frames and 3 methods required more than 20 \nvertical frames to view the entire CFG. None of the meth\u00adods required horizontal scrolling, which is \nperhaps not very surprising, given the nature of a CFG.  Going through the paths that had pink nodes, \nit was clear that there were typically just 2 to 5 methods that generated these incomplete paths due \nto complex control .ow struc\u00adtures. However the effect of these methods would percolate inter-procedurally \nacross many other methods. Additionally, there was a strong correlation between these methods and the \nmethods with the untidy graphs.   5. A generic framework In the previous section, we talked of INSIGHT \nin the context of a speci.c tool XYLEM. In this section, we describe a more general framework under which \nINSIGHT could be used. Essentially, it is the owner of the manipulator tool who re\u00admains responsible \nfor deciding what data should be dumped, what should be the color scheme to be used. It is his re\u00adsponsibility \nto .gure out how to make sense of the data. So how does INSIGHT help? INSIGHT helps by rendering the \ndata, and providing a host of useful features such as a graph slicer and an unusual search mechanism \nbased on colors. Furthermore, we have designed a model wherein the graph\u00adical user interface is automatically \ncustomized based on an input model. As mentioned in Section 3.2 INSIGHT takes as input four sets of data. \nThe Call Graph and the Control Flow Graph The call graph and the control .ow graphs of each method of \nthe pup\u00adpet program need to be dumped by the manipulate program. For this the manipulate program needs \nto be instrumented. To support this function, we provide a small library of meth\u00adods that can be invoked \nby the manipulate program. This way, the manipulate program user only needs to provide the data and our \nlibrary functions will format the data and save it to the disk so as to make it usable by INSIGHT. INSIGHT \naccepts the data in an XML format. The Animate Data Here also we provide library functions that can be \ninvoked from the manipulate program to dump the animation data. Determining the points within the ma\u00adnipulate \nprogram from where to invoke these functions must be invoked remains the responsibility of the user. \nCon.guration Data The XML schema and the example XML input instance, given below indicates the type of \ncon\u00ad.guration that is possible with INSIGHT. The set of col\u00adors used is con.gurable. The set of lists \nis con.gurable. Each list has a name. The selection criteria for inclusion in the list can be a value \non a model element, typically on an attribute of the Start or End marker of each trace (e.g., select=\"End/status=TP\"). \nOr it could be based on the existence of some color (e.g., contains=\"pink\"). in the trace. The list can \nfurther be sorted on the signature (e.g., sortby=\"Start/signature,Start/lineno\"),or on the size of the \nlist (e.g., sortby=\"size,descending\"). For lack of space, we do not give details of the XML schema for \nthe call graph and the CFGs. <xs:schema xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"> <xs:elt name=\"InSight\"> \n<xs:cplexTyp> <xs:sequence> <xs:elt name=\"Colorlist\" min=\"0\"> <xs:cplexTyp> <xs:sequence> <xs:elt name=\"color\"/> \n</xs:sequence> </xs:cplexTyp> </xs:elt> <xs:elt name=\"AnimationListType\" min=\"0\"> <xs:cplexTyp> <xs:sequence> \n<xs:atribute name=\"name\"/> <xs:atribute name=\"selection\"/> <xs:atribute name=\"contains\"/> <xs:atribute \nname=\"sortby\"/> </xs:sequence> </xs:cplexTyp> </xs:elt> <xs:elt name=\"AnimateTrace\" min=\"0\"> <xs:cplexTyp> \n<xs:sequence> <xs:elt name=\"Start\" min=\"1\" max=\"1\"> <xs:cplexTyp> <xs:attrib name=\"signature\"/> <xs:attrib \nname=\"lineno\"/> </xs:cplexTyp> </xs:elt> <xs:elt name=\"Step\" min=\"1\"> <xs:cplexTyp> <xs:attrib name=\"fid\"/> \n<xs:attrib name=\"bbid\"/> <xs:attrib name=\"insid\"/> <xs:attrib name=\"info\"/> <xs:attrib name=\"color\"/> \n</xs:cplexTyp> </xs:elt> <xs:elt name=\"End\" min=\"1\" max=\"1\"> <xs:cplexTyp> <xs:attrib name=\"status\"/> \n<xs:attrib name=\"stateoverflow\"/> <xs:attrib name=\"pathoverflow\"/> <xs:attrib name=\"timeout\"/> </xs:cplexTyp> \n</xs:elt> </xs:sequence> </xs:cplexTyp> </xs:elt> </xs:sequence> </xs:cplexTyp> </xs:elt> </xs:schema> \nConfiguration Schema <InSight xsi:noNamespaceSchemaLocation=\"Insight.xsd\"> <Colorlist> <color>yellow</color> \n<color>orange</color> ... </Colorlist> -<AnimListType name=\"TruePath\" select=\"End/status=TP\" sortby=\"Start/signature,Start/lineno\"/> \n<AnimListType name=\"StackOverflow\" contains=\"pink\" sortby=\"size,descending\"/> - <AnimateTrace> <Start \nsignature=\"a.b.c()\" lineno=\"203\"/> <Step fid=\"3\" bbid=\"78\" insid=\"65\" color=\"cyan\" /> <Step fid=\"3\" bbid=\"9\" \ninsid=\"6\" color=\"red\" info=\"\"/> <End status=\"TP\" timeout=\"true\" stackoverflow=\"true\"/> </AnimateTrace> \n<AnimateTrace> ... </AnimateTrace> </InSight> Configuration Instance  (b) Colored blocks in the subject \npuppet programs. (a) Puppet programs used in the empir\u00adical studies. C is the number of classes, M is \nthe number of methods and BI is the number of bytecode instructions. . (c) Number of events of each \ncolor. Subject Total Magenta Red Pink Green Yellow Orange Ant 335882 55 814 134 3060 1949 27742 Lucene \n45926 193 1461 428 7252 2964 30837 Tomcat 81589 194 1955 235 14093 4802 55043 App A 68676 78 2121 164 \n13421 5221 47529 App B 41471 17 1849 43 7203 2375 27168 Subject C M BI Ant 667 7095 168011 Lucene 272 \n2410 58653 Tomcat 216 4223 98361 App A 204 3561 77867 App B 154 2504 46286  Subject Magenta Red Pink \nGreen Yellow Orange Ant 69 21985 26821 68181 128691 10834098 Lucene 286 83502 140782 329181 566090 38249949 \nTomcat 323 128770 178868 335614 572122 73772282 App A 121 100301 11090 88233 94405 23365462 App B 18 \n39275 7140 51263 111802 10371668 Table 1. Tables for empirical data. 6. Empirical evaluation To evaluate \nour approach, we conducted empirical studies using three open-source projects ANT, LUCENE and TOM-CAT \nand two commercial products (referred to as APP Aand APP B). Table 1(a) lists the puppet programs, along \nwith the number of classes, methods, and bytecode instructions in each subject. We ran our experiments \non an Intel-based Linux machine (1.83 GHz, dual core, 2GB RAM). The output from XYLEM was fed into the \nJava applet INSIGHT() which was used for visualization. From the raw input we computed the following \ninformation about colors in the system -in Table 1(c) we give the total number of events that were generated \nper program and the number of events of each color. In Table 1(b) we give the total number of basic blocks \nin the program and the number of blocks that underwent an event of each color. Many blocks would have \nbeen colored more than one color we count the block for each color. The red events indicate true paths \n-paths along which a null-dereference is possible. However, these events also in\u00adclude intermediate events \nof true paths computed in interme\u00addiate methods. The small ratio of red events to red blocks probably \nindicates that XYLEM s summary mechanism of reusing information across method calls is working well. \nHowever the huge ratio of orange events to orange blocks indicates that the same block is being revisited \nseveral times. This probably indicates certain inef.ciency in XYLEM s al\u00adgorithm and bears out a similar \nconclusion we came to in the visual analysis. Note however that the visual analysis gave greater insight \ninto both the source of inef.ciency as well as the possible solution.  7. Related Work Visualization \nis often broken into two camps -the one for dynamic analysis [Reiss 2003, Reiss and Renieris 2005] and \nthe other set that use trace data in a controlled environ\u00adment [Gestwicki and Jayaraman 2005, Pauw and \nSevitsky 1999]. Our tool falls into the second camp mainly because we need to collect custom data that \nmay not be possible to obtain at runtime, but also for the comparative ease of devel\u00adopment. Additionally \nthe kind of visualization we provide does not lend itself easily to dynamic analysis. The event-driven \nmethodology [Brown and Najork 1993, Stasko 1990] versus the data driven methodology [Deme\u00adtrescu and \nFinocchi 2006] raise another aspect of visual\u00adization which discusses the important triggers that drive \nthe animation. Visualizations may be triggered by events in the source code that correspond to speci.c \nactions performed by the program, or the visualization events may be by changes in data. In our tool \nthe trace data is generated by an event driven methodology but the actual visualization follows a data \ndriven approach, where, for example, a change in color implies a change in state. Often visualizatiob \nis customized to a particular require\u00adment. Shah etal [Shah et al. 2008] develop a multi-view vi\u00adsualizer \nthat is tuned towards understanding try-catch excep\u00adtion handling in Java. Jain [Jain et al. 2006] developed \na technique to automatically generate visualizations of linked list as an alternative debugging to the \nstandard debugger with breakpoints. Jones [Jones et al. 2002, Jones and Har\u00adrold 2005] came up with a \nunique visual scheme for fault localization and Lanza [Pinzger et al. 2005, Gall and Lanza 2006] came \nup with a brand new paradigm for visualizing software metrics that had no animation, Our paper also targets \na speci.c domain. We wish to visualize the .ow of analysis of a manipulator program over a puppet program, \nby animating the puppet program. The end goal is to understand the working of the manipulate program. \nTo the best of our knowledge, this is an entirely novel technique that has proved to be extremely insightful. \n  8. Conclusion In this paper we have presented a tool that helps understand the behavior of programs \n-both visually as well through analysis of data collected. We present a technique that tar\u00adgets programs \nthat analyze other programs. Our technique visualizes the manipulation of a puppet program by a ma\u00adnipulator \nprogram. We implemented this tool as an aid to understanding a tool called XYLEM, In our speci.c case \nit has given us tremendous insight into the working model and we believe we can use this insight to improve \nthe ef.ciency of XYLEM. However, we feel the tool also has the potential to be useful for any program \nthat analyzes another program. In this paper we have also presented a simple algorithm for rendering \ngraphs that generates visually pleasing graphs that utilize space ef.ciently. We have also described \na more general framework un\u00adder which INSIGHT could be used. While it remains the re\u00adsponsibility of \nthe owner of the manipulator program to de\u00adcide what data should be dumped, what should be the color \nscheme and out how to make sense of the data, INSIGHT helps by rendering and animating the data, and \nproviding a host of useful features such as a graph slicer and an un\u00adusual search mechanism based on \ncolors. INSIGHT has been designed to be con.gurable and should be able to hook up with any manipulator \nprogram.  References Marc H. Brown and Marc A. Najork. Algorithm animation using 3d interactive graphics. \nIn UIST 93: Proceedings of the 6th annual ACM symposium on User interface software and technology, pages \n93 100, New York, NY, USA, 1993. ACM. ISBN 0\u00ad89791-628-X. doi: http://doi.acm.org/10.1145/168642.168651. \nCamil Demetrescu and Irene Finocchi. A data-driven graphical toolkit for software visualization. In SoftVis \n06: Proceedings of the 2006 ACM symposium on Software visualization, pages 57 66, New York, NY, USA, \n2006. ACM. ISBN 1-59593-464\u00ad 2. doi: http://doi.acm.org/10.1145/1148493.1148502. Harald C. Gall and Michele \nLanza. Software evolution: analysis and visualization. In ICSE 06: Proceedings of the 28th interna\u00adtional \nconference on Software engineering, pages 1055 1056, New York, NY, USA, 2006. ACM. ISBN 1-59593-375-1. \ndoi: http://doi.acm.org/10.1145/1134285.1134502. Paul Gestwicki and Bharat Jayaraman. Methodology and \narchi\u00adtecture of jive. In SoftVis 05: Proceedings of the 2005 ACM symposium on Software visualization, \npages 95 104, New York, NY, USA, 2005. ACM. ISBN 1-59593-073-6. doi: http://doi. acm.org/10.1145/1056018.1056032. \nJhilmil Jain, James H. Cross, II, T. Dean Hendrix, and Larry A. Barowski. Experimental evaluation of \nanimated-verifying object viewers for java. In SoftVis 06: Proceedings of the 2006 ACM symposium on Software \nvisualization, pages 27 36, New York, NY, USA, 2006. ACM. ISBN 1-59593-464-2. doi: http://doi. acm.org/10.1145/1148493.1148497. \nJames A. Jones and Mary Jean Harrold. Empirical evaluation of the tarantula automatic fault-localization \ntechnique. In ASE 05: Proceedings of the 20th IEEE/ACM international Conference on Automated software \nengineering, pages 273 282, New York, NY, USA, 2005. ACM. ISBN 1-59593-993-4. doi: http://doi. acm.org/10.1145/1101908.1101949. \nJames A. Jones, Mary Jean Harrold, and John Stasko. Visualization of test information to assist fault \nlocalization. In ICSE 02: Proceedings of the 24th International Conference on Software Engineering, pages \n467 477, New York, NY, USA, 2002. ACM. ISBN 1-58113-472-X. doi: http://doi.acm.org/10.1145/581339. 581397. \nM. G. Nanda and S. Sinha. Accurate interprocedural null\u00addereference analysis for Java. In Proceedings \nof the 31st Intl. Conf. on Softw. Eng., May 2009. (to appear). Wim De Pauw and Gary Sevitsky. Visualizing \nreference patterns for solving memory leaks in java. In ECOOP 99: Proceed\u00adings of the 13th European Conference \non Object-Oriented Pro\u00adgramming, pages 116 134, London, UK, 1999. Springer-Verlag. ISBN 3-540-66156-5. \nMartin Pinzger, Harald Gall, Michael Fischer, and Michele Lanza. Visualizing multiple evolution metrics. \nIn SOFTVIS, pages 67 75, 2005. Steven P. Reiss. Visualizing java in action. In SoftVis 03: Pro\u00adceedings \nof the 2003 ACM symposium on Software visualization, pages 57 ff, New York, NY, USA, 2003. ACM. ISBN \n1-58113\u00ad642-0. doi: http://doi.acm.org/10.1145/774833.774842. Steven P. Reiss and Manos Renieris. Jove: \njava as it happens. In SoftVis 05: Proceedings of the 2005 ACM symposium on Software visualization, pages \n115 124, New York, NY, USA, 2005. ACM. ISBN 1-59593-073-6. doi: http://doi.acm.org/10. 1145/1056018.1056034. \nJ. Ruthruff, E. Creswick, M. Burnett, C. Cook, S. Prabhakararao, M. Fisher, II, and M. Main. End-user \nsoftware visualizations for fault localization. In SoftVis 03: Proceedings of the 2003 ACM symposium \non Software visualization, pages 123 132, New York, NY, USA, 2003. ACM. ISBN 1-58113-642-0. doi: http://doi.acm.org/10.1145/774833.774851. \nHina Shah, Carsten G\u00a8org, and Mary Jean Harrold. Visualization of exception handling constructs to support \nprogram understand\u00ading. In SoftVis 08: Proceedings of the 4th ACM symposium on Software visualization, \npages 19 28, New York, NY, USA, 2008. ACM. ISBN 978-1-60558-112-5. doi: http://doi.acm.org/ 10.1145/1409720.1409724. \nJohn T. Stasko. Tango: A framework and system for algorithm animation. SIGCHI Bull., 21(3):59 60, 1990. \nISSN 0736-6906. doi: http://doi.acm.org/10.1145/379088.1046618. Qin Wang, Wei Wang, Rhodes Brown, Karel \nDriesen, Bruno Du\u00adfour, Laurie Hendren, and Clark Verbrugge. Evolve: an open ex\u00adtensible software visualization \nframework. In SoftVis 03: Pro\u00adceedings of the 2003 ACM symposium on Software visualization, pages 37 \nff, New York, NY, USA, 2003. ACM. ISBN 1-58113\u00ad642-0. doi: http://doi.acm.org/10.1145/774833.774839. \n  \n\t\t\t", "proc_id": "1639950", "abstract": "<p>Visualization of a program typically entails low level views of the programexecution state showing, for example,method invocations or relations amongst heap objects. In most cases, this would imply visualization of the executable program. However there is a certain genre of programs that analyze or transform other programs. These programs could be compilers, static bug detectors, test suite analyzers, model to model transformers etc. In such cases, very often, it helps to visualize what is happening to the input program rather than the analyzer program. It is for such programs that we describe a configurable, analysis framework. For ease of exposition, we call the analyzer programthe \"manipulate\" program, and the input programthe \"puppet\" program. To facilitate the visualization, we instrument the manipulate program to generate a dump as it analyzes the puppet program. Using the \"dump\", we reconstruct the interprocedural control flow graph of the puppet program and then visualize the flow of the manipulate program over the puppet program. We use colors to highlight different events in the manipulate program. Using this scheme, we are able to (1) gain insight into the manipulate program; (2) collect useful information / statistics about the puppet program.We have implemented the visualizer in a tool called \"INSIGHT\". We ran INSIGHT on a static debugging tool (the manipulate program) called XYLEM. XYLEM applies static analysis to find potential null pointer exceptions in a puppet program, as for example, the Apache Ant program. We report the insights gained by running XYLEM through INSIGHT on ANT and other puppet programs.</p>", "authors": [{"name": "Agastya Nanda", "author_profile_id": "81444594920", "affiliation": "Jaypee Institute of Information Technology, Noida, India", "person_id": "P1728380", "email_address": "", "orcid_id": ""}, {"name": "Mangala Gowri Nanda", "author_profile_id": "81100183505", "affiliation": "IBM Research, India, New Delhi, India", "person_id": "P1728381", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1639950.1640074", "year": "2009", "article_id": "1640074", "conference": "OOPSLA", "title": "Gaining insight into programs that analyze programs: by visualizing the analyzed program", "url": "http://dl.acm.org/citation.cfm?id=1640074"}