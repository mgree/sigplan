{"article_publication_date": "10-25-2009", "fulltext": "\n p a Pattern Language Roman Kn\u00f6ll Mira Mezini Faculty of Computer Science Faculty of Computer Science \nTUD Technische Universit\u00e4t Darmstadt TUD Technische Universit\u00e4t Darmstadt knoell@st.informatik.tu-darmstadt.de \nmezini@informatik.tu-darmstadt.de Abstract Current programming languages and techniques realize many \nfeatures which allow their users to extend these languages on a semantic basis: classes, functions, inter\u00adfaces, \naspects and other entities can be defined. However, there is a lack of modern programming languages which \nare both semantically and syntactically extensible from within the language itself, i.e., with no additional \ntool or meta-language. In this paper we present p as an approach that aims to overcome this lack. p provides \nan abstraction mechanism based on parameterized symbols which is ca\u00adpable of semantically and syntactically \nunifying program\u00adming concepts like variables, control-structures, procedures and functions into one \nconcept: the pattern. We have evalu\u00adated the abstraction potential and the syntactic extensibility of \np by successfully creating patterns for the aforemen\u00adtioned programming concepts. p could serve as a \ntool for designing new experimental languages and might generally influence the view we have on current \nprogramming con\u00adcepts. Categories and Subject Descriptors D.1.2 [Programming Techniques]: Automatic Programming; \nD.2.10 [Software Engineering]: Design; D.3.1 [Programming Languages]: Formal Definitions and Theory; \nD.3.2 [Programming Languages]: Language Classifications -Extensible languages; D.3.3 [Programming Languages]: \nLanguage Constructs and Features -Patterns; D.3.4 [Programming Languages]: Processors -Interpreters; \nF.4.3 [Mathematical Logic and Formal Languages]: Formal Languages I.1.3 [Symbolic and Algebraic Manipula\u00adtion]: \nLanguages and Systems General Terms Design, Languages, Theory Keywords Patterns, pattern language, semiotics, \nextensi\u00adbility, language extension, language design, domain specific languages, macros Permission to \nmake digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for profit or commercial advantage and that copies \nbear this notice and the full cita\u00adtion on the first page. To copy otherwise, or republish, to post on \nservers or to redis\u00adtribute to lists, requires prior specific permission and/or a fee. OOPSLA 2009, October \n25-29, 2009, Orlando, Florida, USA. Copyright &#38;#169; 2009 ACM 978-1-60558-734-9/09/10...$10.00. \n1. Introduction 1.1. Motivation and Problem Language Design The authors were experimenting with new \nprogramming languages in the field of naturalistic design. Hereby, the overall process of creating new \nexperi\u00admental languages seemed inconvenient to us: the syntax has to be specified in a modified way fitting \nexactly the gram\u00admatical requirements of a particular parser; then, helper code has to be written to \ndissect the parse-tree. Finally, the semantics (in the form of code fragments) are added by assigning \na meaning to the nodes of the parse-tree. We found that this process is very tedious and error-prone; \nthus, we stipulate that there should be a cleaner and easier way to create new (experimental) languages. \nMacros and Notation The use of macros is popular and widespread, ranging over different languages from \nC to LISP. Macros give the programmers more control over the language. Yet, a lot of contemporary programming \nlanguages lack a syntactic macro facility. Current languages are \"given\" to us by some company, language \ndesigner or independent project group. Certainly, we would design some features different in some way \nor introduce new fea\u00adtures sooner as they would maybe happen to come with the next release. A macro facility \nwould be a way to mobilize our creativity for the overall advancement of a language. Therefore, there \nshould be a clean and easy way to syntac\u00adtically extend languages. Domain Speci.c Languages DSLs play \nan increasingly important role, in research as well as in practice. This kind of languages and especially \nthe philosophy behind ad\u00addresses the need for well adjusted notations for specific problem domains. \nFurthermore, DSLs could be a great help to find a common language with both the customers and the developers \nto specify the requirements of software. We think that domain specific modeling needs an adequate language, \ni.e., there should be a clean and easy way to de\u00adsign new domain specific languages and notations. Abstraction \nItself Certain ideas of contemporary pro \u00adgramming technologies have something very deep in com\u00admon: \nthey all are the result of (computer) scientists' drive for abstraction. Assembler programmers had to \ndeal with ever repeating tasks in their programs. They would intro\u00adduce labels so that code-fragments \ncan be reused in an ab\u00adstract way. Then, they would soon use a stack to pass \"val\u00adues\" to the labeled \ncode fragment. What followed is the birth of functions and modules (of functions). Functions in turn \nled to generic functions and classes, classes led to ge\u00adneric classes and aspects, aspects lead to... \n? This whole process is about abstraction. So, our question was: if all advancement in programming languages \nis abstraction, both semantic and syntactic, why then isn't there a language which is completely dedicated \nto that paradigm? Would current programming techniques appear as facets of some general abstraction mechanism \nbehind the scene?  1.2. The Essence: Patterns \"A pattern is a plan that has some number of parts and \nshows you how each part turns a face to the other parts, how each joins with the other parts or stands \noff [...]. A pattern should give hints or clues as to when and where it is best put to use. [...] some \nof the parts of a pattern may be holes, or slots, in which other things may be placed at a later time.\" \n Christopher Alexander What do the scenarios described so far have in common? In each scenario, a programmer \ndefines one or more code fragments, i.e. whole languages or DSLs, macros or func\u00adtions, and assigns a \ncertain syntax to them, respectively the language-or DSL-syntax, the macro-syntax or the function\u00adsyntax \n(the function signature). This syntax, having pa\u00adrameters, introduces a context that brings variability \nto the code fragment: the syntax is a parameterized symbol with an associated meaning, the code-fragment. \nThe particular motivation varies from scenario to scenario. However, the essence of this is the creation \nof a pattern1. We denote that as follows: symbol . meaning 1.2..1 The Parameterization of Symbols \"A \ngood pattern will say how changes can be made in the course of time. Thus some choices of the plan are \nbuilt in as part of the pattern [...]. In this way a pattern stands for a de\u00adsign space in which you \ncan choose, on the .y, your own path for growth and change.\" Christopher Alexander We briefly visit \nsemiotics as semiotics is the basis of our work. In our culture, symbols are combined to create more \ncomplex symbols with more complex and more concise meanings. For instance, the following sign has the \nmeaning that something is prohibited. It leaves a space to symbolize this unwanted thing or action: 1 \nOur notion of a pattern is only indirectly related to the notion of a design pattern well-known from \nthe book \"Design Patterns. Elements of Reus\u00ad able Object-Oriented Software.\" by Erich Gamma et al.; to \nsome extent those patterns could be modeled in a pattern language like p. Neither is our notion of a \npattern language related to the BETA-language [24] except for the fact that BETA uni.es classes and methods \n like p does into the concept of a \"pattern\". This symbol is a parameterized symbol (or short: syn\u00adtax). \nTogether with its meaning it establishes a pattern. Slots describe the existence of these concrete possibilities \nwithin the symbol for customizing them by other parameter symbols (or short: parameters). The slots in \nthe following mathematical sum symbol are illustrated on the right by dashed boxes: 10 a i i = 1 The \nslots at the following example from programming are underlined: while (i <= 10) { sum += a[i]; } while \n(expression) { instructions } We call the set of all symbols which could be created on the basis of \na parameterized symbol by inserting other symbols as parameters into the slots the concretization of \nthe parameterized symbol. The concretization of a pattern is then the concretization of the parameterized \nsymbol of the pattern if it has one; synonymous notions are: the sym\u00adbols realized by a pattern, the \napplications of a pattern or the symbols derived from the pattern. We say that a symbol matches a pattern \nif it is part of the concretization of the respective pattern. Given a symbol of a pattern, we call the \nsymbols that fill the slots of that pattern the sub-symbols (or primary sub-symbols) of the respective \nsymbol, the sub-symbols of the sub-symbols accordingly sub-sub-symbols (or secon\u00addary sub-symbols), and \nso on. The slot in the prohibition sign here is untyped, i.e., any symbol can be inserted here whereas \nthe slots in the while\u00adloop are typed: only expressions and instructions can be used as valid parameter \nsymbols. In general, any predicate could be used to define the type of a slot as with predicate dispatch \nin programming.  1.2..2 Programming and Semiotics Programming is a special form of communication which \naims at communicating an expected behavior from a send\u00ading system, e.g., a person, a computer or a machine, \nto a receiving system. The programming is successful when the receiving system shows the intended behavior. \nThe lan\u00adguage used to communicate the behavior is a programming language. This process is symbolic. The \nprocess of agree\u00ading on the meaning of a symbol involves making the actual link between the symbol and \nthe meaning at some time. Any parameterized entity is able to be a container for meaning.  In semiotics, \nthe relation between a symbol and \"its\" meaning is represented by the semiotic triangle:1 In this diagram, \nthe relation between a symbol (syntax) and its referent (meaning) is shown as an imputed relation which \nis created by our mind, having a thought (pattern). For instance, the sequence of Latin characters \"cow\" \n(syn\u00adtax; only for the speakers of English, of course) refers to the idea of the actual entity \"cow\" \n(meaning). This is our \"cow-pattern\" we have in mind.  1.3. The Goal: A Pattern Language \"This leads \nme to claim that, from now on, a main goal in designing a language should be to plan for growth. [...] \nLisp was designed by one man, a smart man, and it works in a way that I think he did not plan for. In \nLisp, new words de.ned by the user look like primitives and, what is more, all primitives look like words \nde.ned by the user!\"2 Guy Steele Coming back from general semiotics to programming, the important questions \nare the following: what would the es\u00ad 1 The idea of the semiotic triangle has been developed by several \nphiloso\u00adphers at different times. Therefore, the actually used notions for three constituents of the \nsemiotic triangle vary a lot, although the idea behind them is the same. Charles Kay Ogden and Ivor Armstrong \nRichards use the trinity symbol/thought/referent Charles Sanders Peirce icon/interpretant/object and \nFerdinand de Saussure (Charles Sanders Peirce and Ferdinand de Saussure are two of the founders of modern \nsemiotics) signi.ant/signi.\u00e9/chose. In other systems, the word \"meaning\" denotes what is called \"thought\" \nin the semiotic triangle as described here, since the thought is the meaning of a symbol. However, as \nin our notation the meaning of the symbol is explicitly stated by the meaning-part of the pattern we \ndecided to call this part meaning instead of denotation orreferent. Actually, the construction corresponding \nto \"thought\" in the semiotic triangle, is the whole pattern, or at least the part symbol . meaning. 2 \nThis citation and all others of Guy Steel are taken from his speech \"Growing a Language\" on the International \nConference on Object-Oriented Programming, Systems, Languages, and Applications(OOPSLA), 1998. sential \nfeatures of a pattern-language be? what should a pattern-language look like? We think that a pattern\u00adlanguage \nshould support a) full syntactical extensibility: the definition of arbi\u00adtrary new (context-free) syntax \nis possible in order to provide a mean for recording recurrent programming patterns. Speaking abstract, \nthe ideal language realiz\u00ading what we wish would have the means to associate any syntax with any given \nmeaning dynamically. Thus, it should have some facility of the form: syntax . meaning b) (syntactic) \nhomogeneity: the integration of new syn\u00adtax is seamless. The same criteria has been defined for good \nmacro languages; Brabrand and Schwartzbach say about the \"ideal macro language\" [7]: \"[it] would allow \nall nonterminals of the host language grammar to be extended with arbitrary new productions, defin\u00ading \nnew constructs that appear to the programmer as if they were part of the original language.\" c) full \nsemantical grounding: the meaning of every symbol (expression) in the language, except for a minimal \npredefined core language, is defined / definable by other expressions of the language in a non-circular \nway. This property holds for current pro\u00adgramming languages, too; however, we want to em\u00adphasize that \nthe core language, which all other patterns are defined on top, should be minimal. This property shall \nnot be mistaken for being able to prove termina\u00adtion of a program. d) re.ection completeness: every entity \nof the language and of the interpreter, for example, instructions, functions and concepts, is referenceable \nfrom within the language. e) meta-completeness: there is a meta-level to talk about the language itself \n(which is provided by reflection-completeness). This meta-level language does neither syntactically nor \nsemantically (in the way it is evaluated) differ from the rest of the language, it actually is (syntactically) \nthe same language and does not open a cascade of meta-levels; for instance, LISP is meta-complete. This \naspect is related to homogene\u00adity and includes the sub-aspect full syntactical ground\u00ading: every aspect \nof the grammar describing the lan\u00adguage is expressible in the language itself. f) full semantical extensibility: \nthis is fulfilled by nearly all programming languages, only machine code having no mean of abstraction, \ne.g. functions; we add it here for the sake of completeness.  Such a language could solve the problems \nwe have encoun\u00adtered: The design of new languages or DSLs would be eased as these languages could be \ndefined as libraries of an extensible language.  A special macro facility would not be necessary be\u00adcause \nsyntactic extensions would be available directly in the language.  A pattern-language would exactly \nmodel what abstrac\u00adtion in programming is: recognizing a repeating pat\u00adtern, naming it, declaring a symbol \nfor it and making it context-dependent by parameterization.   1.4. Our Proposal in a Nutshell A p-program \nis a sequence of instruction symbols (techni\u00adcally, sentences), each being a sequence of (Unicode) char\u00adacters. \nThe sentences are then evaluated (executed) in the respective order. There is only one language construct \nin p: the pattern. Patterns are, simply speaking, EBNF\u00adexpressions with an associated meaning; a pattern \ncan be easiest understood as a function with a syntactically com\u00adplex (context-free) \"signature\". The \nnon-terminal symbols in the signature are then the parameters of the pattern. A new parameterized symbol \n(syntax) is defined by the pattern-declaration instruction (the parameters are under\u00adlined here): declare_pattern \n. syntax . meaning; This notation reduces the pattern-definition to the abso\u00adlutely necessary: syntax \nand meaning. In addition to that, patterns can be named and in order to provide type safety, each pattern \ncan have an (explicit) type. This type defines all places where the occurrence of the respective symbol \nwill be valid in the program. So the complete pattern\u00addeclaration instruction looks as follows: declare_pattern \nname . syntax . type . meaning; An example: the following pattern declaration defines both the syntax \nand the semantics of integer-potentiation symbols like, for instance, 174^3or 2^19. All constructs used \nhere for defining the meaning of that pattern are pre\u00addefined in p and can for now be interpreted in \nan intuitive way (see below; %W-suppresses the occurrence of whitespaces): declare_pattern integer_potentiation \n. integer:i %W- \"^\" %W-integer:j . integer . { int result = i; for (int k = 1; k <= j-1; k++) result \n*= i; return result; }; After the declaration of that pattern, its applications can be immediately \nused at any place where an integer symbol may occur, e.g., in an instruction like print(174^3);. We will \nsee later that the pattern-declaration instruction and any other of the predefined instructions of p, \nthe so called \"core-pattern-set\", are patterns themselves; they are, for instance, instruction patterns \nlike the pattern-declaration instruction, the print instruction and the for-loop or data patterns like \nthe integer pattern or the pattern pattern yes, a pattern is a pattern itself, its syntax is as follows: \nname \".\" syntax \".\" type \".\" meaning Thus, the actual pattern-declaration instruction has the following \nsyntax, i.e., it takes a pattern as a parameter: \"declare_pattern\" pattern \";\" The following little \ncode-fragment is a complete p\u00adprogram consisting of two pattern-declaration instructions and two other \n(predefined) instructions, print and if, immediately making use of the just defined symbols (the operators \n\">\" and \"? :\" are predefined patterns): (1) declare_pattern maximum . \"max\" \"(\" integer:a \",\" integer:b \n\")\" . integer . ( a > b ) ? a : b; (2) print( max (13^2, 101) );  (3) declare_pattern absolute_value \n. \"|\" integer:i \"|\" . integer . ( i = 0 ) ? i : -i;  (4) if ( max (13^2, |-171|) > 169 ) print (\"yes!\"); \n  After the first pattern-declaration (line 1), the interpreter would \"know\" the pattern \"maximum\". \nTherefore the sec\u00adond instruction (line 2) is correctly interpreted. After the second pattern-declaration \n(line 3), the interpreter knows both the user-defined patterns \"maximum\" and \"absolute\u00advalue\" and can \ncorrectly interpret the last instruction\u00adsymbol (line 4) which is making use of both of them.  1.5. \nOur Contribution With this work, we contribute to the current research in two ways; the following is \nour hard contribution: Development of a Powerful Abstraction Concept Based on the conviction that the \nessence of programming is ab\u00adstraction, we created a programming language that is com\u00adpletely dedicated \nto that idea p. p integrates and abstracts ideas from several different fields such as macros and DSLs \ninto a very expressive post-paradigmatic language. Even\u00adtually, p is an approach of creating not only \na semantically but also a syntactically minimal language. Implementation of a Pattern-Language p is the \nfirst implementation of a pattern language. Technically, a pat\u00adtern language is a language in which other \nprogramming languages are both syntactically as well as semantically reproducible with additional syntactic-extensibility \nand which fulfills all the criteria defined in section 1.3.  Our soft contribution, namely the philosophy \nbehind p, will be discussed in chapter 7 of this work.  1.6. An Overview of this Work In the following \nchapter, we describe the p-language. After that, we briefly discuss our implementation of the p\u00adinterpreter. \nWe then evaluate the expressiveness of p by defining several language constructs existing in current \nprogramming languages in p. Afterwards, we provide an overview on related ideas. Finally, we conclude \nthis work with a discussion of future work and a r\u00e9sum\u00e9.  2. The Language \"But instead of designing \na thing, you need to design a way of doing.\" Guy Steele In the preceding chapter we defined the notation \nof a pat\u00adtern as a parameterized symbol with an associated meaning and we have seen a pattern-declaration \ninstruction to intro\u00ad duce new patterns to p. Now, we concretely describe how to define patterns and \nhow to use the symbols derived from these patterns. 2.1. The Syntax-Pattern First of all, p does not \nhave a syntax in a traditional sense: it is not the language which has a syntax, but each single pattern \nhas its syntax. p has predefined patterns (the core pattern set; short CPS) and user-defined-patterns; \nthe language is the set of these patterns. However, even the syntax of predefined patterns can be dynamically \nchanged thus effecting all following instructions, i.e., there is no fixed syntax in p at all. As with \ntypical grammars, the syntax of a pattern de\u00adfines the way the characters have to be assembled in order \nto represent the respective parameterized symbol of the pattern. The syntax of a pattern is defined like \nthe right side of an EBNF production rule since the latter can be seen as a parameterized symbol with \nthe nonterminal symbols repre\u00ad senting the slots of the parametrized symbol. We call our form of EBNF \np-EBNF what is something like the domain\u00adspecific syntax sub-language of p for the definition of pat\u00adterns. \nWhat follows is the definition of p-EBNF written in p-EBNF itself; this is no coincidence as all \"syntax\" \nin p is just a symbol derived from the predefined syntax pattern of the core pattern set (the non-terminals, \ni.e., the slots, are underlined in the rules): syntax . constant_syntax | slot_syntax | sequence_syntax \n| optional_syntax | or_syntax | zero_or_more_syntax | one_or_more_syntax | bracketed_syntax constant_syntax \n. \u00bb\"\u00ab { character } \u00bb\"\u00ab [\":\" name] slot_syntax . %I ( pattern_name ) [\":\" name] sequence_syntax . syntax \n. syntax . optional_syntax . \"[\" syntax \"]\" [\":\" name] or_syntax . syntax . \"|\" syntax . zero_or_more_syntax \n. \"{\" syntax \"}\" [\":\" name] one_or_more_syntax . \".\" syntax \".\" [\":\" name] bracketed_syntax . \"(\" syntax \n\")\" [\":\" name] We call the sequence-syntax, the or-syntax, the zero-or\u00admore-syntax and the one-or-more-syntax \nmulti-slots as these syntax-rules hold not only one slot but several slots. Nearly all syntax-patterns \nsupport an optional name so that they can be referenced when defining the meaning of a pattern. Names \nhave to be unique only on the same level of nesting. In p, the lexer is completely integrated into the \nparser as the p-lexer does nothing but classify the input characters into categories such as letters, \ndigits, whitespaces and the like. That way, all literal symbols, e.g., the integer or float ing-point-number \nliterals, can be defined by regular p\u00adpatterns (integer pattern and floating-point-number pattern in \nthe CPS; or short \"int\" and \"float\") and there are no name-clashes at all with \"keywords\" like it is \nthe case in a lot of current programming languages. p has a notation for different whitespaces, e.g., \n%S_ stands for a medium whitespace and %W-for no whitespace. Furthermore, p supports syntax for additional \nformatting as %I for italic font and %U for underlined text or %SUPERfor superscript characters.  2.2. \nThe Meaning-Pattern We now assign a meaning to the pattern-syntax. The mean\u00ading of new patterns in p \nis defined by making use of sym\u00adbols derived from already existing patterns, which are, after the startup \nof the interpreter, only the patterns predefined in the core pattern set (in this section, we will introduce \nsev\u00aderal core-patterns along the way). In p, the difference be\u00adtween \"language\" and \"program\" vanishes: \n\"language\" is just an alternative name for the core pattern set and \"pro\u00adgram\" denotes the actual symbolic \ninput to the interpreter including the set of user-defined patterns. Let us have a look at the following \ntwo examples: declare_pattern . \"e\" . 2.718281828459; declare_pattern . integer:i \"^2\" . i * i; The first \nof these easy pattern definitions defines the symbol \"e\" to be an approximation of Euler's number. The \nsecond pattern defines the meaning of a squared-integer symbol, i.e., an integer symbol followed by a \nconstant symbol \"^2\" meaning the product of the integer with itself. The integer-multiplication pattern \nis a pattern in the CPS: its meaning is predefined as the integer-symbol which is the \"conventional result\" \nof the integer-multiplication. Let us have a look at another example:  pattern . \"count_up_to\" \"(\" integer:i \n\")\" . { int j = 1; while (j <= i) { print (j); j++; } } This pattern-definition resembles very strong \na conven\u00adtional method declaration in C-style-languages. This is the point were semiotic theory meets \nwith programming: on the one hand, it is true, this pattern definition is like a C\u00admethod definition; \non the other hand, we do exactly the same as before: we are defining the meaning of a parame\u00adterized \nsymbol by making use of already predefined sym\u00adbols, respectively predefined patterns. So, the general \nap\u00adproach is the same, it differs only in the kind of patterns we use: before, we used a constant and \nan operator symbol, now we use \"algorithmic\" symbols like the block or the while-loop symbol; both are \nin the CPS as well as the integer-variable-declaration pattern, the smaller-comparison pattern, the increment \npattern and the print pattern: \"int\" name [\"=\" integer:initial_value] \"while\" \"(\" expression \")\" instruction \n integer \"<=\" integer integer \"++\" \"print\" \"(\" symbol \")\" As we have seen, the meaning of a pattern \ncan be de\u00adfined in two ways, we call them the \"functional\" and the \"imperative\" style. In p, this looks \nas follows: meaning . functional_meaning | imperative_meaning functional_meaning . expression imperative_meaning \n. instruction Both styles represent two sides of the same coin: what else is a \"calculation\"(-function) \nthan performing actions on symbols, i.e., symbol-manipulation? What else is an in\u00ad struction than a function \nhaving side-effects? p-symbols, as any other symbol in programming, encode behavior of a computer system. \nSo, the relevant thing is not how behavior is defined but that it is defined correctly. 2.2..1 Parameter \nBinding We now have a look at how the symbols in the slots of the patterns are made available for the \nmeaning definition, i.e., how they can be referenced in the meaning definition. In imperative languages \nthis making available is done by treating the parameters of a method like locally defined variables, \nbeing implicitly initialized on a method call. In p, explicit referencing is similar to yet not alike \n the way just described. Look at the following pattern which aims at defining a convenient lightweight \nnotation for printing a non-empty list of integers as print(3,2,8,1)(the for-loop pattern is a user-defined \npattern based on the while pattern): print_integers . \"print\" \"(\" integer:first { \",\" integer:i }:following \n\")\" . { print (first); if ( present(following) ) for (int k=0; k<=size_of(following)-1; k++) print( \nfollowing[k].i ); } The first parameter of the print-integers pattern is refer\u00adenced by \"first\". The \nname of the following zero-or-more symbol of integers, each separated by a comma, is \"following\". The \ncontent of the sequence is referenced us\u00ading the widespread array-notation: \"following[k]\". The \".\"-notation \nallows to access the sub-elements of multi\u00adslots: \"following[k].i\". The length of the sequence can be \nretrieved by the size-of pattern and the present-pattern checks the presence or absence of some optional \nsymbol (both these patterns are in the CPS). The parameters of less complex patterns can be refer\u00adenced \nby their type instead of a name whenever this is pos\u00adsible without ambiguity; we call this implicit referencing: \n\"twice\" \"(\" integer \")\" . 2 * integer We sometimes need to reference not only the parame\u00adters of the \npattern but also the sub-symbols of these pa\u00adrameters. We call this kind of referencing pass-through \nreferencing. The notation is analogous to the \".\"-notation for referencing the sub-elements of multi-slots. \nAssuming that the integer pattern is defined as follows: integer . non_zero_digit:first_digit { digit \n}:following_digits Then, a pattern to calculate the nth digit of an integer can be defined as follows: \ndeclare_pattern . \"nth_digit\" \"(\" integer:index \",\" integer:i \")\" . { if (index = 1) return i.first_digit; \nreturn i.following_digits[index-2].digit; }  2.2..2 Recursion There are two types of recursion in p \nwhich correspond to the two main parts a pattern consist of: semantic recursion and syntactic recursion. \nThe former recursion is the usage of the symbols defined by the pattern in the meaning\u00addefinition of \nthe pattern itself, the latter is the usage of the pattern in its own pattern-syntax. The following example \nfor syntactic recursion defines an array pattern which can have multi-dimensional sub-arrays (an array, \nlike all data patterns does not need a meaning as there is nothing to evaluate with pure data, e.g. all \nliterals in p are data sym\u00adbols):  array . \"[\" array | integer { \",\" array | integer }:following \"]\" \n. data  2.2..3 Reflection It is an essential part of the philosophy of p is that all enti\u00adties and all \nfunctionality of the language (technically, the interpreter) are fully accessible from within the language. \nIn the introduction, we called this property reflection com\u00adpleteness. Consequently, all actions the \ninterpreter supports and all data-types it uses are available within the language as predefined patterns, \nfor instance, there is an evaluate pattern (which is similar to the eval-command in other languages; \nthe parsed-symbol pattern is the parse-tree in p): evaluate . \"evaluate\" \"(\" parsed_symbol \")\" . symbol \n 2.3. The Name and the Type Pattern-names in p are predefined symbols as any other, even though they \nfulfill the important function of spea\u00adking in terms of the semiotic triangle making the link between \nsyntax and semantic tangible. The name of a pat\u00adtern must be unique. p has a strong, dynamic, explicit \ntype system. The type of a pattern defines both where the symbols defined by the pattern may occur in \nthe input, i.e., the replacement scheme of the grammar and the pattern of the resulting symbol pos\u00adsibly \ncalculated by the pattern. For instance, the type of the integer-sum-pattern is integer, too: integer_sum \n. integer \"+\" integer . integer The type of a symbol is the type of the corresponding pattern. The implicit \nsuper-type of all patterns is symbol. p supports \"higher-order-patterns\"; for example, the pattern-declaration \npattern takes a pattern as a parameter. Patterns in p are just all symbols that can be derived from the \npattern-pattern. 2.3..1 Type Safety and Static Semantic As in p patterns and with the patterns new symbols \n can be declared dynamically, there cannot be any static seman\u00adtic of a p-program. Nonetheless, p is \na dynamically type\u00adchecked programming language since all resulting symbols are dynamically checked (parsed) \nfor their pattern. Accord\u00ading to the philosophy of p, it is open to the programmer if she/he wants to \nestablish a static semantic or not. There are basically three approaches how one can write p-programs: \nScenario I \"bad p\" The most \"dangerous\" use of pattern-declarations is to introduce new syntax and seman\u00adtics \nbased on unpredictable user inputs or randomness: declare_pattern new_pattern . \"#\"+read(character_string) \n. integer . random_integer(); In this case, the meaning of a possibly following instruction-symbol like, \nfor instance, print(#abc) is not at all predictable. Scenario II \"better p\" Even if the language provides \nthe most freedom, a good programmer will put restrictions on herself/himself: she/he would abstain from \nusing that kind of pattern-declarations. Yet, there are still problematic cases, namely conditional pattern \ndeclarations, i.e., pattern-declarations whose execution depends on dynamic properties of the program: \nif (i > 5) { pattern signum . \"sign\" \"(\" integer \")\" . integer . r > 0 ? 1 : (r < 0 ? -1 : 0); } print \n( sign (i) ); In this case, the instruction-symbol print(sign(i)) is only interpretable if the variable \n\"i\" is greater than five. Scenario III \"good p\" Thus, an even better pro\u00adgrammer would also abstain \nfrom using conditional pattern-declarations. She/he would declare patterns in libraries (p-code-files) \nwhich would be loaded at startup and would at best use local unconditional pattern declarations like, \ne.g., in the following example: pattern divisor . integer:a \"|\" integer:b . boolean . b % a = 0; integer \nr = random_integer; if ( 3|r ) { pattern signum . \"sign\" \"(\" integer \")\" . integer . r > 0 ? 1 : (r \n< 0 ? -1 : 0); print ( sign (r) ); } In this case, the p-program has a static semantic as the set of \nactive patterns at any point in the program is fully predictable: patterns in this scenario behave like \nordinary functions with a possibly complex signature; after a \"re\u00adnaming\" from pattern-syntax to function \nnames and a flat\u00adtening of the parameter-tree, conventional static type\u00adchecking would be applicable. \n  2.4. The Interpretation Every sentence that is send to the interpreter, i.e., every symbol in form \nof a sequence of characters, will be inter\u00adpreted according to the current state of the interpreter. \nThe state is completely determined by the set of currently active patterns (we call it the context of \nthe interpreter): a symbol is accepted if it can be be recognized as the application of one or more of \nthe currently active patterns, all other sym\u00adbols are rejected as uninterpretable (meaningless). The \nin\u00adterpreter accepts only instruction-symbols (short: instruc\u00adtions). All other symbols are rejected \nas inappropriate sen\u00adtences.  2.4..1 Dispatch In general, there are two cases when an input-symbol matches \nmore than one pattern, i.e., the parse-tree is am\u00adbiguous: in the first case, the parse trees contains \nonly pat\u00adterns which are partially homonymous, i.e., basically have the same syntax but differ in the \ntypes of the slots. In this case, the dispatcher performs the selection by considering the sequence of \nslots as members of a lattice and decides according to the order defined on the lattice; this is the \nmost widespread variant of realizing symmetrical multi\u00addispatch. Since this is a partial order, only \nin the case that one interpretation of the input is more specific in every slot, this variant is selected, \nelse the input is rejected by stating an ambiguity. In the second case, when the parse-trees differ in \nother ways than just being partially homonymous patterns, the input is rejected as syntactically ambiguous \nwhich is an indication for poor pattern-design. 2.4..2 The Evaluation The evaluation of a symbol in \np means evaluating the meaning of the corresponding pattern. The meaning is looked up in the pattern-list \nof the interpreter. The actual purpose of a meaning is twofold: either the meaning\u00adsymbol causes side-effects \nor it does not; either it does calculate/create a resulting symbol (short: result) or it does not. If \nthe pattern is predefined, then its predefined meaning is realized, i.e., the respective side effects, \nfor instance, printing on the console, take place. If the pattern is user\u00addefined, then the interpreter \nwill interpret the associated user-defined meaning-symbol which in turn uses other user-defined and predefined \nsymbols. The resulting symbol of a symbol is the result of the rewriting of the respective symbol taking \nplace during the evaluation; for instance, the integer-sum symbols do re\u00adwrite themselves to the integer \nsymbol that is considered to be the \"sum\" of these two integers. A result is then inserted into the slots \nof other symbols in the further process of evaluation. The way this result is created can be different: \nthe \"functional\" way would be to \"directly\" evaluate other symbols in order to come to a result; the \n\"algorithmic\" (\"imperative\") way would be to describe a process which is creating the result. As already \nmentioned, in p, there is no difference between these approaches as \"imperative\" pat\u00adterns are evaluated \nin exactly the same way as \"functional\" patterns are, by causing side-effects and creating a resulting \nsymbol. Patterns that do not explicitly calculate a resulting sym\u00adbol, implicitly are rewritten to the \nnull-symbol (we use the Unicode no-character glyph: .). p basically cannot have a strict evaluation strategy \nas conditional instruction patterns, e.g., the if-then-else pat\u00adtern, depend on the possibility to not \nevaluate/executeparameters. Consequently, p supports lazy evaluation in the form of explicit evaluation \n(call-by-name) and implicit evaluation (call-by-need) which together are equivalent to leaving the decision \non the concrete evaluation of the pa\u00adrameters up to the programmer instead of enforcing a stan\u00addard evaluation \nstrategy. The predefined evaluate-reference(-pattern) (in the CPS) provides a mean to explicitly evaluate \nparameters: evaluate . \"evaluate\" \"(\" reference \")\" . reference It would be used in pattern-declarations \nas follows: unless . \"unless\" \"(\" expression \")\" instruction . instruction . if (!expression) evaluate(instruction); \n The expression-parameter of the unless-pattern is not explicitly evaluated but implicitly: whenever \na reference to a parameter is used without the evaluation-pattern then the evaluation will take place \nimplicitly. In this case, p uses the call-by-need strategy: once evaluated the results of the pa\u00adrameters \nare buffered in order to prevent multiple, possibly time-intensive re-evaluations of the parameters. \nThe following example uses only the implicit evaluation vari\u00adant: integer_potentiation . integer:i \"^\" \ninteger:j . integer . { int result = i; for (int k = 1; k <= j-1; k++) result *= i; return result; \n}   2.5. The Core Pattern Set \"If I want to help other persons to write all sorts of programs, should \nI design a small programming language or a large one? [...] I should not design a small language, and \nI should not design a large one. I need to design a language that can grow. I need to plan ways in which \nit might grow but I need, too, to leave some choices so that other persons can make those choices at \na later time.\" Guy Steele We have seen already a lot of the patterns built into the core pattern set. \np is a semantically and syntactically minimal language because like the .-calculus' abstraction and appli\u00adcation \nconstructs, p would as well need only these two lan\u00adguage constructs (predefined core patterns), only \nthe ab\u00adstraction would have to be extended by a possibility to de\u00adfine new parametrized symbols i.e. \nthe abstraction would be the pattern-declaration-pattern and the application  would then interpret \nsymbols in the context of these pat\u00adterns. However, as the focus of this article is to describe a pattern\u00adlanguage \nas such and not its minimality in particular, we do not argue or even prove the necessity of patterns \nto include in the CPS or not. We therefore did define the CPS in an informal way by choosing the syntax \nand the semantics that most programmers are familiar with from other program\u00adming languages (LISP-or \nPascal-style syntax could be added to p, too). There is not the one core pattern set. Sev\u00ad eral sets \nof core patterns would be adequate for a realiza\u00adtion of the p-language since patterns can be defined \non top of other patterns; the only absolutely unavoidable pattern is some pattern-declaration-pattern. \nThe CPS should be inter\u00adpreted rather as a proposal and an outline, mainly used for the definition of \nthe patterns in the evaluation of this work, than as a fix definition. We provide some examples of the \ncategories the patterns in the CPS are grouped by. Declaration (Meta-)Patterns Considering the remarks \nmade so far, it is not an exaggeration to say that the whole concept of p is based on two patterns, the \npattern-pattern and the pattern-declaration pattern which exactly reflect the philosophy of p: pattern \n. name \".\" syntax \".\" type \".\" meaning . data pattern_declaration . \"declare_pattern\" pattern . instruction \nMathematical Operator Patterns The most common mathematical operators are predefined in infix notation \nboth for integers and floats and the combinations of them: integer_multiplication . integer:a (\"*\" | \n\"\u00b7\") integer:b . integer Logical Patterns The basic logical conjunctions are pre\u00addefined, as well with \nmathematical notation: logical_and . boolean:a (\".\" | \"and\" | \"&#38;\") boolean:b . logical_operator \nlogical_operator . boolean Symbol Manipulation Patterns Patterns used for manipu\u00adlating symbols, i.e. \nin p, sequences of characters, play a crucial role in p as symbols can be seen as the \"instances\" of \npatterns. The whole language is based on the principle of symbol manipulation, or being more precisely, \nevery programming language is based on that principle, p just doesn't hide its evidence. For instance, \ncharacter-string concatenation can be done either by the \"+\"-operator or by a reduced space: character_string_concatenation \n. character_string:a (%S- | \"+\") character_string:b . character_string character_in_string . \"(\" positive_integer \n\")\" \"th_character_of\" \"(\" character_string \")\" . character The properties of a pattern can be changed \nby the prede\u00adfined rewrite pattern. The following application of the re\u00adwrite pattern, for instance, \nchanges the syntax of the print pattern; it actually performs a sort of renaming: rewrite (print.syntax, \n\"write\" \"(\" symbol \")\"); Control-Flow Patterns p provides several typical control-flow patterns, among \nthem, for instance, the if\u00adthen-else pattern: if_then_else . \"if\" \"(\" expression \")\" instruction [ \"else\" \ninstruction:else ] . control_flow_pattern Data Patterns The typical data-patterns like integer, float \nor boolean are predefined in p: boolean . \"true\" | \"false\" . data All other more complex data patterns \nlike lists, matri\u00adces, maps and tables can then be defined on top of these basic data patterns. Ontological \n(Meta-)Patterns Type hierarchies can be seen as ontologies having a type-entity and a subtype\u00adrelation. \nConsequently, all patterns, including, e.g., instruc\u00adtion patterns, can be classified by their type: \ninteger_unequality_comparison . integer:a (\".\" | \"!=\") integer:b . comparison_operator comparison_operator \n. boolean_operator The is-operator pattern can be used to find out if a pat\u00adtern is a sub-pattern of \nanother pattern: is . type \"is\" type . boolean_operator The top-pattern of the ontology in p is the symbol\u00adpattern. \nIt has two immediate children: the instruction pat\u00adtern and the expression pattern. Patterns having side-effects \nand control-flow patterns should be defined as instructions; patterns calculating a resulting symbol \nand data patterns should be defined as expressions.  Communication Patterns (I/O-Patterns) In the world \nof p, there is nothing but symbols and patterns. So, the com\u00admunication mechanism will comprise the standard \nmeans to emit and receive symbols: print . \"print\" \"(\" symbol \")\" . instruction (World-)Knowledge-Patterns \nThe world surrounding a system does contain a lot of information and knowledge that is in most cases \nrelevant to the system. Among these \"world\"-patterns are those that define the current date, time and \nlocation of the system: current_date . \"current_date\" . date Context (Meta-)Patterns We have used references \nto de\u00adfine the meaning of patterns. References, in p, like every\u00adthing else (reflection-completeness), \nare predefined pat\u00adterns: explicit_reference . name [ \"[\" integer:index \"]\" ] [ \".\" reference ] Interpreter \n(Re.ective) (Meta-)Patterns We have already mentioned some of the patterns demanded by the principle \nof reflection completeness in the section on reflection. Other patterns in the same context are, for \nexample: parse_instruction . \"parse\" \"(\" symbol \")\" . parsed_symbol A parse-tree is encoded by the parsed-symbol \npattern: a parse-tree could be seen as the original input symbol with (a lot of) additional information, \nespecially the linkage be\u00adtween the read characters and the patterns they belong to. The interpret-pattern \nis a user-defined pattern: interpret . \"interpret\" \"(\" symbol \")\" . symbol . evaluate ( parse ( symbol \n) )  3. Implementation We now describe an implementation of the p-language. We emphasize once more \nthe strict separation of the (semantics of the) p-language and the implementation of an interpreter for \nthis language. The p-language does explicitly not in\u00adclude any technical features of any underlying system, \nfor instance, something like a processor-ticks pattern or memory-management patterns; actually, it is \na pure symbol manipulation mechanism. Our interpreter is completely implemented in Java 6. Of course, \nthe central and most important element of the im\u00adplementation of a syntactically extensible language \nis the parser. For our purpose, we re-discovered a type of parsers which were used since the 70s almost \nexclusively in com\u00adputational linguistics but not in programming: the chart parsers. 3.1. The Parser \nOur parser is based on the modified Earley-parsing algo\u00adrithm [2] with several little additional improvements \nfrom our side. The Earley-parser has three main advantages in the context of using it for a pattern language: \n It updates relatively fast on a change of the grammar rules while still having acceptable parsing speed; \nthis is crucial for a syntactically extensible language.  Secondly, it can parse any context free grammar; \ntherefore programmers do not have to modify their pattern syntax in order to comply with the require\u00adments \nof a specific grammar, as, e.g., the restriction to LL-grammars concerning ANTLR.  Thirdly, the Earley-parser \nreturns all possible readings of an input sentence; thus, the dispatcher can then de\u00adcide in a later \nstage which reading is the one in the respective context (see the following section).  The algorithm \nhas a complexity of O(n3) concerning the length of the input (O(n) in case of a LR(k)-grammar). However, \na complete description of the algorithm is by far beyond the scope of this article. We have furthermore \ndeveloped an \"Earley-parser gen\u00aderator\", i.e., a small framework to instantiate a clean Earley-parser \nwith predefined rules (the ones for the prede\u00adfined patterns) written in EBNF. 3.2. Dispatch In case \nthat an input-symbol is homonymous, i.e., the parser returns several parse trees, the parse trees are \ncom\u00adpared then if they are just partially homonymous or differ in other more complex ways. In the latter \ncase, as described in the section 2.4.1, the input is rejected. In the former case, the type-distance \nof all sub-symbols to the slots is calcu\u00adlated from the parse tree and they are compared pairwise as \nif in a lattice.  3.3. Evaluation In a bootstrapping-process the predefined patterns are loaded in several \nsteps, considering the dependencies be\u00adtween them as some predefined patterns are already based on other \nmore basic predefined patterns, e.g., the prede\u00adfined integer-sum pattern uses the integer pattern which \nin turn uses the digit pattern. The evaluation of predefined patterns is straightforward: the meaning \nof these patterns is defined by pure Java-code which is then executed. The evaluation of user-defined-patterns, \non the other hand, is realized by evaluating the meaning-symbol of the respec\u00adtive pattern. For example, \nthe meaning of the following pattern is evaluated by evaluating the integer-multiplication symbol: square \n. integer:i \"^2\" . integer . i * i Of course, as p is semantically grounded, every evalua\u00adtion of a user-defined \npattern will end up in the evaluation of predefined patterns. In both cases, the evaluation of predefined \nand of user-defined patterns, the parse-tree of the symbol to evaluate is provided as a context for the \nre\u00adsolving of the parameter references. For instance, the input\u00adsymbol 3^2 would result in the following \nparse-tree pro\u00advided to the square pattern (we use an XML-style pretty\u00adprint for the parse trees):  \n<square-symbol> <integer-symbol name=\"i\"> <non-zero-digit name=\"first_digit\" literal=\"3\"> </integer-symbol> \n <literal=\"^\"> <literal=\"2\"> </square-symbol> The reference \"i\" could now be resolved by looking it \nup in the parse-tree. p provides dynamic type checking as the resulting symbols of all patterns are checked \nif they match the indicated type; for example, the p-interpreter would try to parse the result of the \nsquare-pattern as an integer symbol. If this failed, the interpreter would throw a type error.  3.4. \nImplementation Status The current implementation of the p-interpreter has some minor restrictions in \nimplementing the p-language. These are as follows: In the current implementation the reference pattern \ndiffers slightly from the way as described here; all references start with a \"$\". The usage of an ordinary \nname pattern causes the Earley-parser to generate too many possible results, which could easily be sorted \nout at a later stage, but the sheer creation of these results temporarily consumes too much memory; presently, \nwe think about working directly on the parse-chart in order to tackle that issue.  Nested pattern declarations \nas described in section  2.3.1 (\"Type Safety and Static Semantic\") are cur\u00adrently disabled since the \nparser would as well take too many resources to process these (anyway deprecated) constructions; however, \nwe think about introducing a kind of lazy parsing, i.e. a multi-stage-parsing which would then be controlled \ndirectly by the p-language, respectively by the programmer.  4. Evaluation \"It is good to design a thing, \nbut it can be far better (and far harder) to design a pattern. Best of all is to know when to use a pattern.\" \n Christopher Alexander We evaluate the expressivity of p by revisiting several con\u00adcepts of current programming \nlanguages, at the same time shedding light on these concepts from a p perspective. The evaluation is \nstructured along the level of abstraction the analyzed patterns have, starting from simple notation\u00addefinition \nand ending with full programming languages realized in p. We limit our set of examples here to a few \nrepresentative ones from each category. The interested reader can find more on our website (pi-programming.org). \n 4.1. Use-Case I: Language Constructs \"My point is that a good programmer in these times does not just \nwrite programs. A good programmer builds a working vo\u00adcabulary. In other words, a good programmer does \nlanguage design, though not from scratch, but by building on the frame of a base language.\" Guy Steele \nLanguage constructs are usually introduced by version changes of programming languages as, for example, \nthe for-each loop and variadic methods came to Java; or they are introduced by completely new languages, \nas, e.g., clo\u00ad sures came with LISP. In p, new language constructs are introduced by new patterns built \non top of the core lan\u00adguage, including expressions, instructions and data pat\u00adterns. 4.1..1 Expression \nPatterns Most contemporary programming languages lack of con\u00advenient notation for specific problem domains, \nfor instance, for mathematical or technical notations. Newer languages such as Fortress [19] address \nthis issue. The definition of symbolic aliases for functions are a major motivation for syntactic extension \n(see the related work). In p, for instance, a square-root-pattern could be defined as follows: \"v\" %W-number \n. float . square_root (number) The square-root symbol could be used then in expres\u00adsions (\"N\" is predefined \nas a synonym for the positive\u00adinteger pattern): if (n . N . n = 0) return vn; Another example: in a lot \nof programming languages, ordered sequences of numbers have to be expressed in the following bloated \nway: (i >= 10) &#38;&#38; (i <= 20) &#38;&#38; (j > 20) &#38;&#38; (j < 40) With the help of a user-defined \noperator-chain pattern the same expression can be written in the following intui\u00adtive way: 10 = i = 20 \n< j < 40  4.1..2 Control Structure Patterns Control structures such as loops can be defined as patterns: \ncontrol_structure . instruction loop . control_structure The most basic of all loop-constructs is the \none that performs a given action a fix number of times:  do { print (\"hello!\"); } (10) times The corresponding \npattern looks as follows (the execute pattern is a synonym for the evaluate pattern): do_times_loop . \n\"do\" instruction \"(\" integer:times \")\" \"times\" . loop . { for (int i = 1; i = times; i++) execute (instruction); \n}   4.2. Use-Case II: Meta-Constructs \"Meta means that you step back from your own place. What you \nused to do is now what you see. What you were is now what you act on. Verbs turn to nouns. What you used \nto think of as a pattern is now treated as a thing to put in the slot of an other pattern. A meta foo \nis a foo in whose slots you can put foos.\" Guy Steele With the term \"meta-construct\", respectively meta-pattern, \nwe denote constructs whose main purpose is in defining other patterns or helping with that. Every semantically \nex\u00adtensible programming language must have concepts for defining the entities of the language. In the \ncase of Java, for instance, these are, among others, class-and method\u00addeclarations. By now, in p we have \nseen only one construct to define other patterns: the pattern-declaration pattern. Many other constructs \ncould be defined on top of that. We can define alternative possibly reduced notations for repeating \npattern declarations, e.g., for the declaration of \"functions\" in p: declaration . instruction Functions \n being so to speak the first real abstraction in programming are an ever occurring pattern in pro\u00adgramming \nborrowed from mathematics. This kind of ab\u00ad straction can be defined in p, as well, in the following \nin the widespread C-style (we use the \"\u00bb\" and \"\u00ab\" as quotation marks (CPS) so that the upper quotation \ncharacter can be used in a readable form within the declaration-string): function_declaration . declaration \nvariable_name . name c_style_function_declaration . type name \"(\"(type variable_name):first {\",\" type \nvariable_name}:parameters \")\" block:meaning . function_declaration . { character_string pattern_string \n= \u00bb\"\u00ab + name + \u00bb\" \"(\"\u00ab; if (present (first)) pattern_string += slot(first.type) + .\":\". first.variable_name; \n if present (parameters) for (int p=0; p=size_of(parameter)-1; p++) pattern_string += .\",\". + slot(parameters[p].type) \n+ .\":\". parameters[p].variable_name; pattern_string += .\")\". \".\" type \".\" meaning; declare_pattern (pattern)pattern_string \n; } Outgoing from the function-declaration, a pattern\u00addeclaration instruction is assembled on a string-basis. \nThis looks similar to \"macro\"-programming; however, in p, there is no \"macro-expansion\" but just the \nusual evaluation of patterns: the assembled declaration string will be parsed as such and immediately \nexecuted. We can now express the simple max-operator pattern we have previously defined in a more convenient \nway (\"int\" is defined as another synonym for \"integer\"): int max(int a, int b) { return a > b ? a : \nb; }  4.3. Use-Case III: Libraries and Frameworks In p, a library or a framework we use these terms \nhere synonymously as both are extensible is a considerable set of interacting patterns serving a common \npurpose, i.e., a domain specific language. The advantage of p in library design is that the syntax of \nthe entities in the library can be developed according to the purpose of the library, for ex\u00adample, in \nthe domains of logging, error-handling, test\u00addriven-development, software metrics, GUI-design, web\u00addevelopment \nor data-access. A direct embedding of SQL-instructions would be very beneficial in a programming language \nas a lot of applica\u00adtions require persistency. We exemplary define here the sql\u00adcommand \"insert\" assuming \nthat the connection to the da\u00adtabase is realized by a pattern send_sql_command(data\u00adbase, sql_command) \nand that the patterns \"sql-value\", \"sql-column-name\" and \"sql-table-name\" are already de\u00adfined (the check-pattern \nstops the execution in case of an error; the this pattern is a reference pattern referencing the symbol \nitself, in this case, the whole sql-insert-statement): sql_instruction . instruction  sql_insert_statement \n. \"INSERT\" \"INTO\" sql_table_name \"(\" sql_column_name {\",\" sql_column_name}:column_names \")\" \"VALUES\" \n\"(\" sql_value {\",\" sql_value):values \")\" \";\" . sql_instruction . { check (size_of(column_names) = size_of(values), \n\"Wrong number of values!\"); send_sql_command (current_database(), this); } If all CRUD-sql-commands \nwere defined, we would be able to seamlessly integrate sql with p: INSERT INTO people VALUES (\"Alfred\", \n\"Wissel\"), (\"Julika\", \"H\u00e4user\"); for_each_in (SELECT * FROM people) print (current.forename); UPDATE \npeople SET surname = \"H\u00e4user\" WHERE forename = \"Alfred\" AND surname = \"Wissel\"; DELETE FROM people \nWHERE (forename =\"Alfred\"); The fact that sql-commands are elements of the lan\u00adguage might help to reduce \nproblems concerning sql\u00adinjection-attacks, too, as incoming character-strings denot\u00ading sql-commands \ncan be parsed already as specific sql\u00adcommand instead of generally interpreting the possibly harmfully \nmodified commands.  4.4. Use-Case IV: Full Languages \"A language design can no longer be a thing. It \nmust be a pat\u00adtern a pattern for growth a pattern for growing the pattern for de.ning the patterns \nthat programmers can use for their real work and their main goal.\" Guy Steele In p, the anyhow hard \nto define difference between a \"lan\u00adguage\" and a \"library\" vanishes completely. Usually, \"languages\", \nin contrast to \"libraries\", define syntax in ad\u00ad dition to the semantics they come with. As in p every \nli\u00adbrary defines syntax, as well, every library is a language. As a proof of concept of the expressiveness \nof p we define the . -calculus in a straight-forward way, both se\u00admantically and syntactically. As mentioned \nbefore, the .\u00ad calculus and p have a lot in common: the former is a se\u00admantically minimal programming \nlanguage and p is a se\u00admantically and syntactically minimal programming lan\u00adguage. . _calculus . language \nThe .-calculus has three types of expressions: . _expression . ._variable | ._abstraction | ._application \n . ._calculus A .-variable is represented by a lowercase-name: . _variable . .lowercase_letter. The abstraction \nand the application look as follows: v is a ._variable; e, e1 and e2 are ._expressions; . _abstraction: \n(.v.e); . _application: (e1 e2) . { e1 is ._abstraction : \u00df_reduction(e1.expression, e1.variable, e2), \notherwise : this; The above description is the original code-fragment in p which defines the .-calculus \nby making use of a naturalistic-slot-definition pattern (\"x, y and z are v\") and a programming-by-example-definition \npattern (\"name: ex\u00adpression\"). In addition to that, a case-pattern (user-defined) and a this-reference \n(CPS) are used. The complete imple\u00admentation of the \u00df-reduction-function can be found on our website. \nConsidering all properties of a pattern-language, we see a closer relation of p to languages like Scheme \nor Haskell. However, object-oriented languages can also be modeled with p. We currently work on a (prototypic) \nlanguage in\u00adcorporating some of the very basic features of Java, called picoJava; more information can \nbe found on our website.  4.5. Use-Case V: Meta-Languages \"In a way, a language design of the old school \nis a pattern for programs. But now we need to go meta. We should now think of a language design as a \npattern for language designs, a tool for making more tools of the same kind.\" Guy Steele The concept \nof patterns allows to interpret languages as sets of patterns. That way, with a language workbench, new \nlanguages could be created by composing features (occur\u00adring in different other languages). Languages, \nrespectively language families, could, as well, be designed in a generic way by either leaving parts \nof the syntax open for exchange or parts of the semantics, for instance, in case that different implementations \nof a language for different machines should be developed for example, one implementation for a multi-core \nsystem and another one for a micro-computer. Languages could inherit from each other by sharing a common \nset of patterns (e.g. C++ \"extends\" C), possibly with the same syntax but with rewritten pattern-semantics. \nIn this context, a whole language can be seen as a para\u00ad metrized pattern. p could be used as a super-language \nfor (some) of current programming languages and as a hyper\u00adlanguage in the sense of being a super-language \nwith the additional capability to be syntactically extensible. In this context, a pattern language behaves \nnot only like a parser-generator but like a whole integrated language generator. Product line management \ncould become a part of the language itself rather than being an outside mecha\u00adnism.   5. Related Ideas \nThe idea of a pattern language touches several fields of contemporary programming which are best captured \nby the term \"language oriented programming\". This term has been initially described in [32] by Martin \nWard. It splits the de\u00advelopment process in three stages: the design of a problem oriented very high \nlevel programming language, the im\u00adplementation of the system with this language and finally the implementation \nof a compiler for this language. This process should be performed recursively. Ward calls lan\u00adguage oriented \nprogramming \"middle out development\" in contrast to top down or bottom up development and their combination \nin outside in development. V\u00f6lter [31] adds interesting motivation for language driven development from \na practical point of view. In general, two movements can be noticed: the \"old\" movement in the 60s focussed \nmainly on macros as a mean of syntactic extension, the new movement, starting in this century is driven \nby DSLs, by providing extension tools for \"big\" languages like Java, and the desire for composing several \nlanguages in one, thereby creating a superlanguage (the term \"superlanguage\" was coined by Christopher \nDig\u00adgins [16]). Finally, term rewriting calculi and adaptive grammars, standing a bit aside, are more \nformal approaches to the same goal. However, none of the works even the closest ones about Katahdin \n[23] and XMF [22] sticking very strong to the object-oriented paradigm draw the attention on per\u00adceiving \nprogramming itself as a process of designing and using patterns. p is a new language whose goal is not \nex\u00adtension but which is built exclusively on the principle of patterns realizing all features of a pure \npattern language. p is post-paradigmatic in the sense that it does not favor any special programming \nparadigm (except for \"pattern oriented programming\" if itself interpreted as a paradigm). Only syntactic \nhomogeneity and sometimes full reflectivity seem to be a widely accepted goals in the related work. 5.1. \nSyntactically Extensible Languages Other used terms used in this field are grammar-oriented programming \nor syntax-directed languages. This kind of programming languages is closest related to the concept of \na pattern language as the goal of XMF [22] is: \"An ideal\u00adized superlanguage provides control over all \naspects of representation and execution. A superlanguage can be ex\u00adtended with new features that make \nit easy to represent concepts from the application that a customer would under\u00adstand. [...] Each new \nfeature that is added to a superlan\u00adguage has a description of how it should execute and how it integrates \nwith other features.\". Katahdin [23] is an object-oriented imperative (super\u00ad)language; it is designed \nespecially for the aspect of com\u00adbining several programming languages in one. Katahdin, like p, supports \nthe definition of syntax and semantics to\u00adgether as one unit. It hereby realizes the core of a pure pat\u00adtern \nlanguage, however, it is still attached completely to the object-oriented paradigm. Neither does it provide \nfull re\u00adflectivity or meta-completeness. Despite that, the work on Katahdin is among the most interesting \nworks in this field and the closest relative of a pattern-language. XMF [22] is a syntactically extensible \nobject-oriented language. XMF focusses very strong on the aspect of being a superlanguage for the use \nin multi-language projects. [15] describes how to syntactically extend Java on the basis of XMF. We find \nit disadvantageous that XMF forces the pro\u00adgrammer to separately define syntax and semantics: syntax \nis defined in the Grammar-construct and semantics is im\u00adplemented in a method \"desugar\" with a class \nimplement\u00ading a \"Performable\"-element. Nevertheless, XMF is one of the most advanced approaches in the \nfield of syntactically extensible languages. Logix [25] currently in alpha stadium and the eX\u00adtensible \nLanguage (XL) [35] allow for the definition of user-defined syntax for operators (XL allows for a basic \nnesting by predefined \"block\"-symbols, too). Proof assis\u00adtant systems like Isabelle [20] allow as well \nfor syntactic extensions on the operator-level.  5.2. Language Design Tools In contrast to syntactically \nextensible languages, tools for language design, mainly aim at extending existing languages with new \nsyntax. They divide in two groups: general purpose compiler-compilers provide a framework for the design \nof new languages, possibly with an already written implementation of a widespread language like Java; \nextension tools / facilities on the other hand aim at extend\u00ading a specific existing programming language. \nBoth ap\u00adproaches can be used in the context of domain specific modeling. In a pattern language, there \nis no inherent differ\u00adence between a library or a DSL as both syntax and seman\u00adtics are defined in a \nlibrary. A pattern language shares as well a common goal with model-driven development: both aim at giving \nthe programmer a powerful abstraction mechanism; however, the way, this is realized is very dif\u00adferent: \nwhereas model driven development advocated on creating a hierarchy of ever more abstract (graphical) \nmod\u00adeling languages, a pattern-language strives for meta\u00adcompleteness and primarily keeps to textual \nmodeling. 5.2..1 Extension Tools / Facilities The Java Syntactic Extender (JSE) as described by Bachrach \nand Playford in [3] is a macro-facility for the Java language. Code used in macros is quoted with a spe\u00adcial \nsyntax of an opening \"#{\"-bracket and closing \"}\"-bracket. References to code-fragments to be inserted \nare then done by the identifier of the respective fragment preceded by a question mark. Code fragments \nare then evaluated in a multi-staged way. JSE provides only a lim\u00adited syntax extension mechanism, for \ninstance, it allows to extend only a bunch of surface syntactic nodes of Java. This is intended because \nthe system focusses on the Java language and therefore considers a lot of usability issues. In [9] on \nMetaBorg / Stratego Bravenboer and Visser describe how Java can be extended by domain specific languages. \nThey provide examples for direct XML repre\u00adsentation and a GUI-language which are realized by a macro-like-rewriting \nof Java-code to Java-code. MetaBorg aims at bringing the concepts of APIs to programming languages. \n Ometa/CLOS [33] is an object-oriented language for pattern matching and is similar to executable grammars \nlike newspeak [8] which is a general purpose language sup\u00adporting the expression of parser combinators. \nLike [1] it is based on a parsing expression grammar (PEG) [18]. This is a relatively new grammar formalism \nwhich is similar to context-free grammars but supports syntax predicated and enforces by rule prioritizing \n a unique parsing result. We do not use a PEG as an ordering of patterns is not in\u00adtended in our concept \nof a pattern language, all patterns are \"equal\" by default. Besides the higher expressivity of PEGs, \nthe programmer has to take care of a lot of the syn\u00adtactic details of the rules in a skillful way in \norder to guar\u00adantee the correct ordering of the rules. [1] is the most recent work in the field and describes \nthe introduction of macros to Fortress [19]. This work has a lot in common with Katahdin [23] and XMF \n[15]. As this work concentrates on the extension of an existing language rather than the definition of \na new language it explicitly strives for syntactic homogeneity but does not aim at reflection-nor meta-completeness. \nHowever, the work describes an inter\u00adesting approach of how to organize \"grammars\" in modules which may \n(multi-)inherit from each other.  5.2..2 Compiler Compilers The Jakarta Tools Suite (JTS) [5] aims at \ncreating domain\u00adspecific languages for existing programming languages. JTS consists of the tools \"Jak\" \nand \"Bali\". The former is a meta-programming extension for Java, the latter a tool for composing grammars. \nJastAdd [21] is a compiler compiler based on aspect\u00adoriented modules. JastAdd supports as well a rewriting \nof the AST for integrating new syntax into the language. The JastAdd Extensible Java Compiler [17] is \na full implemen\u00adtation of Java in the JastAdd-framework. Theoretically, every parser is syntactically \nextendable, it just has to be regenerated every time the grammar changes. In practice, for most predictive \nparsers, for instance the LL(k)-parsers generated by ANTLR, this is not realizable; they parse very fast \nthough but take a long time for the generation of the automaton. \"Rats!\" [26] is a parser gen\u00ad erator \nfor Java which integrates, like the p-parser, lexing with parsing. It uses a parsing expression grammar. \n 5.3. Metaprogramming \"Metaprogramming\" is a very extensively used term as it comprises macro-facilities, \ngenerative programming, multi\u00adstage-programming, generic programming and meta-object\u00adprotocol implementations. \nWe focus here on macro and multi-stage-programming as generic programming is widely known. 5.3..1 Macro \nFacilities The term \"macro\" is used in various ways, as well. It mainly refers to textual macro-processors \nlike the C\u00adpreprocessors or TeX or the syntactic macro-processors like the macro-facilities of LISP, \nScheme or Dylan [4]. One of the earliest works on macros was [13] by T. E. Cheatham in 1966. Brabrand \nand Schwartzbach [7] give an excellent survey on macro languages comparing eight representative systems \nusing 32 properties. p is neither a lexical macro processor as it does not operate on a purely textual \nbasis nor is it a syntactic macro proces\u00adsor since there is no \"pre-evaluation\"-phase or \"macro ex\u00adpansion \nphase\" as it is called concerning LISP. From the point of view of p, a \"macro expansion\" is like any \nother evaluation. p does not make a difference between \"normal\" data types and data which represents \nevaluateable code: every symbol is evaluateable. However, conceptually, p has a lot in common with LISP: \nboth are minimal languages, concerning syntax and semantics and concerning its main concepts: lists and \npat\u00adterns; actually, original LISP uses trees, lists are a special data-structure defined on trees, p, \ntoo, uses trees, namely, syntax-trees; both are homoiconic programming language, i.e. \"code\" is just \na special form of data. p is a little bit like \"LISP with syntax\" but without a macro-expansion phase, \ntherefore no problems concerning hygiene occur in p. The metamorphic syntax macros [7] are designed to \nextend the syntax of a host-language, in the paper \"<big\u00adwig>\" [6], an interactive-web-service-language. \nBrabrand and Schwartzbach make a difference between normal kind of macros and metamorphic macros (hence \nthe name): the latter differ in that way from the former that they can be used in the definition of other \nmacros. In the program, the macros are identified by their identifier. Ambiguities are resolved, among \nother strategies, by declaring greedy pars\u00ading as the standard parsing rule.  5.3..2 Multi-Stage Programming \nMetaML [27] is a multi-stage programming language. MetaML supports \"higher-stage expressions\" where the \nstage of any piece of code is determined by the number of surrounding brackets. This way, code can be \ntreated as usual data, created and executed in a later stage. A pattern language is only multi-stage \nin the sense that assembled symbols can be reinterpreted as instructions an then be im\u00admediately evaluated. \nHowever, the evaluation of whole code-pieces cannot be delayed to a later stage. MetaOCaml [28, 29] is \nanother example of multi-stage programming.   5.4. Term Rewriting Calculi The \"recursive functions \nalgorithmic language\" (REFAL) described in [30] by Valentin Turchin is a functional pro\u00adgramming language \nthat directly implements term rewriting mechanisms by providing two basic mechanisms: pattern matching \nand substitution. In general, a Refal program con\u00adsists of functions in arbitrary order (the starting \nfunction is marked with the keyword $ENTRY), which in turn consist of sentences. A sentence is the combination \nof a pattern and an expression, which will be returned as the function result if the pattern matches. \nSo, a Refal function can be com\u00ad pared to a set of p-patterns. In addition to that, p is related to Refal \ninsofar that the core principle of both languages is pattern matching; however, Refal does not aim at \nsyntactic extensibility. 5.5. Adaptive Grammars Adaptive grammars also called modifiable, extensible, \ndynamic or adaptable grammars or dynamic syntax are a formalisms based on the common grammar formalism \nbut with the extension of dynamism: there are grammar rules that can change the rule set of the grammar \nduring \"pars\u00ading\". This way, adaptive grammars even become turing\u00adcomplete programming languages. Originally, \nadaptive grammars, were invented very early in 1963, see [12], af\u00adterwards reinvented several times. \n[14] gives a very good overview on these works. The Universal Syntax and Semantics Analyzer (USSA) as \ndescribed in [11] is a formalism and a parser and a more recent work in this field. The approach is based \non a bottom-up modifiable grammar as described in [10]. In USSA, rules are declared in YACC-style and \nare organized in \"clusters\". A cluster is basically a set of rules which are then at invocation of the \ncluster added or removed from the set of current rules. Clusters can be used to define whole languages. \nIn contrast to p, the semantics of USSA patterns is scattered within those patterns. It is hard to de\u00adclare \npatterns in a consistent way since potential (syntactic) sub-patterns have to implement semantics, as \nwell. Sub\u00adpatterns then communicate with their super-patterns by global attributes. The USSA stays very \ntechnical instead of exhibiting more the idea of patterns.  6. Future Work Parser Performance The mentioned \nrestrictions in the current implementation have to be relaxed and the perform\u00adance of the parser should \nbe addressed in general, we see a great potential for optimizations here. Other parser and grammar formalisms \nshould also be considered concerning their usefulness and applicability in the context of a pattern language. \nIntegration There are several ways of how p could inte\u00adgrate with existing languages: as a super-language, \nas a domain specific language for the definition of pattern within these languages or by directly importing \nsource-files of these languages into the (Java-)p-interpreter. Debugging Pattern languages require a \nspecial treatment of exceptions and errors because the parser has much more importance in a pattern language; \nhowever, it often does not provide sufficient information. So, there should be ways to generate useful \nhints from this side. Text-Formatting In order to realize the full potential of a pattern language, IDEs \nshould have an integrated support for formatted text editing like current text processors and elaborated \neditors do. In addition to that, an appropriate corresponding markup file format has to be developed. \nPattern-Sharing There should be a mechanism or a community platform to search, exchange and share pat\u00adterns. \nThis has to be done in a slightly different way than current neither optimal sharing of source code \nbecause patterns can only be identified by their name as it is hard to query on the syntax. An open pattern \nlibrary would maybe be organized in an ontological way, having patterns be tagged or provided with additional \ndescriptions.  7. R\u00e9sum\u00e9 and Conclusion \"Well there may be one other way, which is to use a large, rich \nprogramming language that has grown in the course of tens or hundreds of years, that has all we need \nto say what we want to say, that we are taught as we grow up and take for granted. [...] But that is \nnot where we are now. [...] I hope that we can, in this way or some other way, design a programming language \nwhere we don t seem to spend most of our time talk\u00ading and writing in words of just one syllable.\" Guy \nSteele p fulfills all criteria of a pattern language: p is fully seman\u00adtically and syntactically extensible \nin a syntactically homo\u00adgeneous way because there is no inherent difference in the application of predefined \nand user-defined patterns. With its minimal approach p is fully semantically grounded as every evaluation \nof a user-defined patterns ends up in the evaluation of a predefined pattern and reflection complete \nas all functionality of the interpreter is accessible from within the language. p is as well meta-complete \nas the reflection language is identical with the core language and fully syntactically grounded as even \nthe syntax of patterns is represented as syntax-patterns. This makes p post-paradigmatic in the sense \nthatp di\u00adrectly realizes the process of abstraction in a macro-like fashion: stop copy &#38; paste or \nusing IDE-source-templates. Instead, start with an example, parameterize it and give it a unique syntax \nand name. 7.1. Benefits of a Pattern-Language We think that several fields of software engineering would \nbe positively affected by such a pattern oriented design, i.e. (symbolic) abstraction as a whole as the \nmajor design prin\u00adciple thereby including other abstraction mechanisms, for example, functions:  Productivity \n/ Expressibility / Intuitiveness In general, reducing code-redundancy by patterns for repeating tasks \nleads to a significant reduction of errors. As pattern\u00adlanguage increases the possibility for abstraction, \npro\u00adgrammers are enabled to directly express their ideas with the syntax they want to use; thus, much \nfaster, direct and concise than without patterns. We think that this will com\u00adpensate the extra work \nto learn a new syntax. Understandability / Sustainability / Evolvability Most systems are designed for \na long evolutionary existence. A program written in a notation suitable for its domain of usage is easier \nto read, maintain, adapt and enhance. Structuring / Abstraction / Modularizability Patterns help in structuring \nthe program or the problem domain; the declaration of a pattern is the manifestation of a new idea. Learnability \n/ Presentability Pattern-language\u00adprogrammers would quickly learn the meaning of new fea\u00adtures as they \nare defined on the basis of the already existing features. Code can be written and read in the familiar \nway. For instance, in real mathematical notation instead of more or less convenient ASCII-mappings (as \nin the lower variant): f(x) = x2 + sinx - cos2ai f(x) = x^2 + sin(x) - cos(2*a[i]) A pattern language \ncould, as well, help in teaching pro\u00ad gramming languages theory to novice programmers as from the point \nof view of p programming languages can be re\u00adgarded as a set of (changing) features. Individuality / \nFreedom Programmers want to have freedom. This is a social argument rather than a technical one. However, \nprogramming is a social action, too. Pro\u00adgramming is a form of expressing oneself in a creative act which \nis a great stimulus for general progress and personal satisfaction. Every programming language makes \na trade\u00ad off between freedom and safety. p aims at providing as much of the former without completely \nsacrificing the lat\u00adter. Progress With a pattern-language language design be\u00adcomes a community-process \nincreasing the general pro\u00adgress in language design as syntax is then exposed to evolu\u00adtionary mechanisms. \nFrom this evolution, not only a pattern-language could directly benefit but other program\u00adming languages, \ntoo, by incorporating new constructs evolving in and from the pattern-languages.  7.2. Our Plea This \nwork wants as well to be understood as advocating: A Meta-Goal: a Renaissance of the Origins A pattern \nlanguage might do a small contribution to what we would call the \"renaissance of the origins\": coming \nback to the roots and rethink some of the decisions made on the long way from the early days of programming \nto modern con\u00adtemporary programming languages. During this long time, a lot of concessions had to be \nmade concerning the trade off between possible programming language features and tech\u00adnical feasibility. \nThese should be remembered as what they are: temporary trade-offs and by no means necessities aris\u00ading \nfrom the nature of things. Some of these decisions might not any longer be completely right, for example, \nthe decision for languages with a closed syntax. In addition to that, we would like to shed light on \nsome too familiar ideas of contemporary programming like classes, methods, aspects, control structures \nand others, thereby following the essence of science: making familiar things unfamiliar. A more fundamental \nresearch might as well reveal possibly forgotten ideas of the past still waiting for their time to come; \nsometimes one has to step back in order to jump forward. A Meta-Goal: the Democratization of Language \nDevel\u00adopment The extensions of languages are done in a half\u00adtransparent process in the sense that user-participation \nis mainly restricted to making requests but final decisions are made by a small group of people in a \nstandards committee. With a pattern language every programmer could take part in extending the language \nby the constructs she / he has in mind. The more restrictive a language / notation is, the less freedom \na language allows, the more it reduces our creativ\u00adity since right from the beginning our thoughts are \nforced into the corset of this specific notation and the less room is left for progress. Syntactic extensibility \ncould lead to an open marketplace for syntax where languages syntactically advance on need and constructs \nare in competition with each other concerning their usefulness instead of being introduced or not in \nan authoritarian way. In any case, there will automatically develop common idioms, as pro\u00adgrammers have \na natural interest in their programs being readable by others; this is the same process of competing \nexclusiveness and universality as it is happening with the individual natural language(s) each of us \nuses. A Plea for the Focus on Language Design There seems to be a trend to compensate deficiencies in \nlanguage design with ever more elaborated programming tools. This \"tool\u00aderism\" has certain drawbacks: \ntools become out of date and incompatible with the language or with other tools. Pro\u00adgrammers have to \nspend a lot of time to integrate the differ\u00adent tools and keep them up-to-date. One of the most preva\u00adlent \narguments of those advocating tools is a circular argu\u00adment: new languages would be disadvantageous as \nthey would not any longer be compatible with the existing tools! We plea for a language oriented design \ninstead of rather than subservience to tools, good tools will follow good languages automatically, we \ndon't have to worry about that. In addition to that, we plea for meta-complete languages instead of \"meta-ization\" \ncreating cascades of ever more meta-levels or languages. We think that the existence of several meta-levels \nis not a sign of quality but rather the opposite as it shows that each level seems to suffer from a lack \nof expressivity. We think that the creation of new, pure and consistently designed languages, making \na tabula rasa should be preferred over overloading the languages cur\u00adrently en vogue until they finally \ngo down with ever more features. This approach is not contradictory to a continuous evolution of languages: \nnew languages and new tools derive from the experiences we have made with the former ones: \"new\" does \nnot necessarily mean completely different but better.  A Plea for the Importance of Syntax In abstract \npro\u00adgramming language theory one could up to a certain limit (the readability for the analyst himself) \nneglect syntax and concentrate on semantics only. However, this has nothing to do with programming reality \nand leads to the widespread underestimation of the importance of syntax which is re\u00adflected in subtleties \nsuch as the emotional preference pro\u00adgrammers have for a syntax she / he is familiar with: pro\u00adgrammers \ndo not think in calculi but in symbols and they want to use symbols for real programs, especially these \nsymbols they are already used to why else would pro\u00adgramming languages syntactically refer so much to \ntheir predecessors, e.g. Java to C++/C? Why else would Micro\u00adsoft provide their .NET-framework one API, \n(semanti\u00adcally) one language in different syntaxes? It is therefore the duty of software technology \nto provide programmers especially those with customer contact the tools they need to express themselves \nin the way they want to. Syntax does matter. A Plea for more Risk and Dynamism p is a dynamic language. \nAs the syntax is subject to dynamic modifica\u00adtions, it cannot be statically proven that a program is \ncor\u00adrect. Yet, dynamic programming languages have shown to be attractive for programmers. We are aware \nthat p is a \"dangerous tool\". In practice, we think, a programmer would probably use a language (in form \nof a p-library) she/ he is familiar with and add only several new patterns. An experienced language designer \nmight use p in another, more advanced way. In our opinion, freedom in program\u00adming should not neglectfully \nsacrificed just for a higher safety. Natural language is the most powerful tool of com\u00admunication we \nknow and at the same time it is far from being open to formal proofs as ambiguities in natural lan\u00adguage \nare resolved by further inquiries of the \"pro\u00adgrammed\" person instead of using a (very restricted) un\u00adambiguous \nlanguage in the first place. In the future we will therefore concentrate our research on how to give \npro\u00adgrammers (IDE-)support and intelligent feedback for pattern-programming. Based on their experience, \npro\u00adgrammers themselves will learn how to write programs which are adequate for them. So, with minimal \npersonal insight and partial program analysis, it is possible to write type-safe p-programs. If we were \nafraid that our children died of a car accident, then we might consider to never let them drive a car, \nat all. Or we might think about giving them the best training and advice around to prepare them as good \nas we can for any eventuality. This is the concept that p follows. p does not want to put any restrictions \non the programmer by force. Our hope is that p will be used as an open artifact for studying the concept \nof patterns in programming and ex\u00adperimenting with many other new ideas and languages. In our opinion, \nthere should be a common open source stan\u00addard pattern language for the community, like, for instance, \nHaskell serves for functional programming. p could be a first source of inspiration for such a language. \nAt least, p might serve as a basis for a lot of gedankenexperiments.   Acknowledgements We are most \nindebted to Marc Wagner from Universit\u00e4t des Saarlandes who gave us the idea of using an Earley-parser \nfor the realization of p as described in the work of John Aycock and R. Nigel Horspool [2]. p would not \nexist with\u00adout the great help and technical knowledge of Felix Wolff who implemented the parser. The \narticles most inspiring to us concerning p were the works of Christopher Graham Seaton on \"Katahdin\" \n[23], of Ceteva, Inc. on \"XMF\" [22], of Jonathan Bachrach and Keith Playford on \"The Java Syntactic Extender \n(JSE)\" [3] and of Claus Brabrand and Michael I. Schwartzbach on \"Growing Languages with Metamorphic Syntax \nMacros\" [7]. Finally, we thank the members of our group, especially Andreas Sewe, Vaidas Gasunias, Tatjana \nKorbmacher and Tom Dinkelaker for their thorough feedback.  References [1] Eric Allen et al. Growing \na Syntax Sun Microsystems,FOOL, 2009 [2] John Aycock, R. Nigel Horspool Practical Earley Parsing University \nof Calgary, University of Victoria, Canada, The Computer Journal, Volume 45, Number 6, 2002 [3]Jonathan \nBachrach, Massachussetts Institute of Technology The Java Syntactic Extender (JSE) Keith Playford, Functional \nObjects, Inc., OOPSLA, 2001 [4]Jonathan Bachrach D-Expressions: Lisp Power, Dylan Style Massachusetts \nInstitute of Technology, USA, Keith Playford, Functional Objects Inc., Somerville, USA [5] Don Batory, \nBernie Lofaso, Yannis Smaragdakis JTS: Tools for Implementing Domain-Speci.c Languages The University \nof Texas at Austin, ICSR, 1998-06 [6] <Bigwig> http://www.brics.dk/bigwig, 2009-01-22 [7]Claus Brabrand, \nMichael I. Schwartzbach Growing Languages with Metamorphic Syntax Macros,PEPM, 2002 [8]Gilad Bracha Executable \nGrammars in Newspeak Cadence Design Systems, San Jose, California, USA, ENTCS, Volume 193, Pages 3-18, \n2007-11 [9] Martin Bravenboer, Eelco Visser Concrete Syntax for Objects Universiteit Utrecht, The Netherlands, \nOOPSLA, 2004 [10]Boris Burshteyn Generation and Recognition of FormalLanguages by Modi.able Grammars \nACM SIGPLAN Notices, Volume 25, Number 12, Pages 45-53, 1990-12  [11]Boris Burshteyn USSA Universal \nSyntax and SemanticsAnalyzer ACM SIGPLAN Notices, Volume 27, Number 1, Pages 42-60, 1992-01 [12]Alfonso \nCaracciolo di Forino Some Remarks on the Syntax of Symbolic Programming Languages Communication of the \nACM, Volume 6, Number 8, Pages 456-460, 1963-08 [13] T. E. Cheatham The introduction of de.nitional facilities \ninto higher level programming languages AFIPS, 1966-11 [14]Henning Christiansen A Survey of Adaptable \nGrammars Roskilde University Centre, SIGPLAN Notices,volume 25 number 11, pages 33-44, 1990-11 [15] Tony \nClark Beyond Annotations: A Proposal for Extensible Java (XJ) Thames Valley University, United Kingdom, \nPaul Sammut, James Willans, Cetava Inc. [16]Christopher Diggins Superlanguages: Syntactic andSemantic \nSupersets of other Languages 2008-03-12 [17] Torbj\u00f6rn Ekman, G\u00f6rel Hedin The JastAdd Extensible Java \nCompiler OOPSLA, 2007-10 [18]Bryan Ford Parsing Expression Grammars: A Recognition Based Syntactic Foundation \nPOPL, 2004-01 [19] The Fortress Language Speci.cation Sun Microsystems Inc., 2007 [20] Isabelle http://www.cl.cam.ac.uk/research/hvg/Isabelle \n2009-03-16 [21] JastAdd http://jastadd.org, 2009-02-25 [22] Tony Clark, Paul Sammut, James Willans Superlanguages \n Developing Languages and Applications with XMF Ceteva Inc., 2008 [23]Christopher Graham Seaton A Programming \nLanguage Where the Syntax and Semantics Are Mutable at Runtime Master's Thesis, University of Bristol, \nUnited Kingdom, 2007-05 [24]Bent Brrun Kristensen et al. Abstraction mechanisms in the BETA programming \nlanguage Aalborg University Center, Aalborg, Denmark, POPL, 1983 [25] Logix http://www.livelogix.com/logix, \n2009-03-02 [26] Rats! An Easily Extensible Parser Generator http://www.cs.nyu.edu/rgrimm/xtc/rats.html, \n2009-02-27 [27] Tim Sheard, Zino Benalssa, Matthleu Martel Introduction to multistage Programming Using \nMetaML Paci.c Software Research Center, Oregon Graduate Institute of Science and Technology, 2000-02 \n[28] Walid Taha A Gentle Introduction to Multi-stage Programming Rice University, Houston, Texas, USA, \nDSPG, 2003 [29] Walid Taha A Gentle Introduction to Multi-stage Programming, Part II Rice University, \nHouston, USA, GTTSE, 2007 [30] Valentin F. Turchin et al. .... ..... . ... ............. . ....... ............. \n................ (English: The Language REFAL and its Application in the Automation of Programming) Inter-University \nConference on the Automation of Programming of Economical Calculations, Moscow, 1967 [31] Markus V\u00f6lter \nArchitecture as Language: A story InfoQ, 2009-01-28 [32] M. P. Ward Language Oriented Programming Computer \nScience Department, Durham, 2003-01 [33] Alessandro Warth OMeta: an Object-Oriented Languagefor Pattern \nMatching University of California, Los Angeles, USA, Ian Piumarta, Viewpoints Research Institute, Glendale, \nCalifornia, USA, Dynamic LanguagesSymposium, OOPSLA, 2007-10 [34] Daniel Weise, Roger Crew Programmable \nSyntax Macros Microsoft Research Laboratory, PLDI, 1993 [35] XLR: Extensible Language and Runtime http://xlr.sourceforge.net/concept/XL.html, \n2009-02-19  \n\t\t\t", "proc_id": "1640089", "abstract": "<p>Current programming languages and techniques realize many features which allow their users to extend these languages on a semantic basis: classes, functions, interfaces, aspects and other entities can be defined. However, there is a lack of modern programming languages which are both semantically and syntactically extensible from within the language itself, i.e., with no additional tool or meta-language. In this paper we present &#960; as an approach that aims to overcome this lack. &#960; provides an abstraction mechanism based on parameterized symbols which is capable of semantically and syntactically unifying programming concepts like variables, control-structures, procedures and functions into one concept: the pattern. We have evaluated the abstraction potential and the syntactic extensibility of &#960; by successfully creating patterns for the aforementioned programming concepts. &#960; could serve as a tool for designing new experimental languages and might generally influence the view we have on current programming concepts.</p>", "authors": [{"name": "Roman Kn&#246;ll", "author_profile_id": "81319495077", "affiliation": "TUD - Technische Universit&#228;t Darmstadt, Darmstadt, Germany", "person_id": "P1728813", "email_address": "", "orcid_id": ""}, {"name": "Mira Mezini", "author_profile_id": "81100583946", "affiliation": "TUD - Technische Universit&#228;t Darmstadt, Darmstadt, Germany", "person_id": "P1728814", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1640089.1640128", "year": "2009", "article_id": "1640128", "conference": "OOPSLA", "title": "&#960;: a pattern language", "url": "http://dl.acm.org/citation.cfm?id=1640128"}