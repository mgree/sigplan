{"article_publication_date": "10-25-2009", "fulltext": "\n Inferred Call Path Pro.ling ToddMytkowicz Devin Coughlin AmerDiwan Department ofComputerScience UniversityofColorado,Boulder \n{mytkowit,coughlid,diwan}@colorado.edu Abstract Prior work has found call path pro.les to be useful for \nop\u00adtimizers and programmer-productivity tools. Unfortunately, previous approaches for collecting path \npro.les are expen\u00adsive:they needtoeitherexecuteadditionalinstructions (to track calls and returns) or \nthey need to walk the stack. The state-of-the-arttechniquesfor call path pro.ling slow down theprogramby7%(forCprograms) \nand 20%(forJavapro\u00adgrams). This paper describes an innovative technique that collectsminimalinformationfromtherunning \nprogramand later(of.ine)infersthefull callpathsfromthisinformation. Thekeyinsightbehind ourapproachisthat \nreadily avail\u00adable information during program execution the height of the call stack and the identity \nof the current executing function are good indicators of calling context. We call this pair a context \nidenti.er. Because more than one call path may have the same context identi.er, we show how to disambiguate \ncontext identi.ers by changing the sizes of function activation records. This disambiguation has no overheadinterms \nofexecutedinstructions. We evaluate our approach on the SPEC CPU 2006 C++ and C benchmarks. We show that \ncollecting context identi\u00ad.ersslows down programsby 0.17%(geometricmean).We can map these context identi.ers \nto the correct unique call path80%ofthetimeforC++programsand 95%ofthetime forCprograms. Categories and \nSubject Descriptors B.8.2 [Performance andReliability]:PerformanceAnalysis andDesignAids GeneralTerms \nMeasurement,Performance Keywords Pro.ling, Call Path, Calling Context, Calling ContextTree,Stack Permission \nto make digital or hard copies of all or part of this work for personal or classroom useisgranted without \nfeeprovided that copies are not made ordistributed forpro.tor commercial advantage andthat copiesbearthis \nnotice and thefull citation onthe .rstpage.Tocopy otherwise,torepublish,topost onserversortoredistribute \ntolists, requiresprior speci.cpermission and/or afee. OOPSLA2009, October25 29,2009,Orlando,Florida,USA. \nCopyright c &#38;#169;2009ACM978-1-60558-734-9/09/10. . .$10.00 1. Introduction Static program analyses \nhave long been the fundamental building blocks of optimizing compilers and tools for pro\u00adgrammer productivity, \ntesting, and performance analysis. However,languagefeaturessuchas dynamicdispatch,com\u00adbined with the \ngrowing complexityof programs, can cripple static analyses.For example,if a program slice[24]based on \nstaticanalysiscontainsmost ofthe programthenitis proba\u00adbly not useful.Forthisreason,researchersandpractitioners \nare turning more and more to dynamic analyses, which are burdened not by all paths and events that could \nhappen but onlybythosethat occurinpractice.Thispaperdemonstrates a nearly-zero overhead technique for \nan important dynamic analysis: collecting call paths and calling contexts. We call ourapproachInferredCallPathPro.ling, \nor ICPP forshort. Callpathpro.lescapturethe nestedsequenceofcallsen\u00adcountered at run-time; thus they \nare useful for determining which sequences of calls consume the most program exe\u00adcution time and for \nidentifying opportunities for aggressive inlining[14, 3] and code specialization[22].Calling-context \npro.les are similar to call path pro.les except that theypro\u00adduce an abstract value representing each \nsequence of calls ratherthanthecallingsequenceitself.Thisvalueis notguar\u00adanteedtobe unique,butitmaybeprobabilistically \nso[7]. Calling-contextpro.lesarealso useful,e.g.,foridentifying whenaprogramisexecutingacallpath thatithas \nnotexe\u00adcuted before,which mayindicateananomaly[11]. Unfortunately, prior approaches for call path pro.ling \nare active in that they either require program instrumenta\u00adtion[13,5, 25, 19,6,7] or needtowalkthecall \nstack[8, 12, 15] to collect data. Because active pro.ling requires signi.cant computation during program \nexecution, it may slow down or perturb the program signi.cantly. For exam\u00adple,Zhuang et al sadaptivetechnique[25]slows \ndownJava programs by an average of approximately 20% and Froyd et al sapproach[12]slows downCprogramsbyanaver\u00adage \nof 7%.If wearecollectingadditionalinformationatthe sametime(e.g., datafrom hardware-performancemonitors) \nthis slow-down may unacceptably perturb that information. This paper describes apassive schemeforcallpathpro.ling \nwhich slows down C and C++ programs by an average of 0.17%(geometricmean)andat most 2.1%.  Thekeyinsightbehind \nourapproachisthat knowingthe heightofthecall stack(in bytes) andthecurrently execut\u00ading function uniquely \nidenti.es a context most of the time. Wecallthe(stack height,currentexecutingfunction) pair the context \nidenti.er sinceit(usually)identi.esa particular context.Weshow howwecanmodifythesizesoftheactiva\u00adtionrecordssothatthecontextidenti.er \nnow uniquelyiden\u00adti.esaparticularcontext 88%ofthetime(meanacrossboth C andC++ benchmarks).Finally, weshow \nhowtocombine the context-identi.er with call graph or pro.le information (from a prior run) to infer \nthe call paths that eachcontext\u00adidenti.erstandsfor.Ourapproachis passive sinceit does not require any \nadditional instructions e.g., to keep track of the context or to traverse the call stack. We evaluated \nour approach on C++ and C benchmarks from the SPEC2006 benchmark suites and using two usage scenarios: \nof.ine and online.Intheof.inescenariowe know theinputs ofthe programinadvancesowecan do pro.ling runsinadvance \noftheactual run;thesepro.lingruns helpto produce the mapping from context identi.ers to call paths. Inthe \nonlinescenario,wedo not knowtheinputsinadvance. We show that our approach uniquely identi.es the call \npath from the context identi.er 88% of the time using the of.ine usage scenario and 74% of the time using \nthe online usage scenario.Moreover,if we are willing to tolerate some ambiguity(i.e.,acontextidenti.er \npossibly mapstomore than onecallpath), ourresultsareevenbetter:for5-precise (i.e., we map a context identi.er \nto up to .ve paths, one of which is the correct path) our scheme is correct 98% of the time for the of.ine \nscenario and 93% of the time for the online scenario. We show that the run-time cost of our approachis \nnegligible(geometricmeanof0.17%acrossall benchmarks). 2. Motivation The .rst line-of-attack when attempting \nto understand the performance of a program is to measure the end-to-end statistics about the program. \nFor example, we may use UNIX s time command to determine how long the pro\u00adgram runs for and what fraction \nof the time it spends in system versus user tasks. These measurements are cheap and easy to do; however, \ntheyprovide only a coarse-grained viewintothe program s performance. Thesecondline-of-attackisto usetoolsthatmeasuretime \nspentineachfunction.If we usesampling(insteadofinstru\u00admentation)wecandothisquitecheaply also:wecan usethe \nhardware to triggerinterrupts at regularintervals and record the currently executingfunction at eachinterrupt.If \nwe sam\u00adplefor along-enough period,thetime spentinside afunction willbeproportional tothe numberofsamplesforthatfunc\u00adtion. \nMany standard tools, such as UNIX utilities pfmon, gprof, and the Sun Hotspot JavaVM usethisapproach \ntocheaply collectdata.Whilethesemeasurementsare only slightly more expensive than the end-to-end statistics, \nthey stack grows downward SP parameters for A local variables for A parameters for B local variables \nfor B SP parameters for A local variables for A parameters for C local variables for C parameters for \nC local variables for C A\u00adB\u00adC A\u00adC Figure 1. The stackwhen A calls B calls C and when A calls C directly.Thestackpointerin \nC is different when calledvia call path A-B-C than when calledvia callpath A-C. are much richer. However, \nthey do not provide any context fora performanceanalysttointerpretthe data.Forexample, they tell the \nanalyst that function f consumes much of the program s executiontimebut f may have many callers; the \nanalystdoes notknowwhich callpathisprimarily responsi\u00adblefor the time spentin f. This paper shows how \nwe can signi.cantly enrich the aboveinformation with negligible cost.Speci.cally,itshows howwecancollect \nnotjustthetimespentineachfunction but alsothetimespentineach callpath using effectivelythe same data \ncollection mechanisms as the tools above. 3. High-level approach Prior approaches to keeping or capturing \ncalling context all do so explicitly they useinstrumentationtogatherthisin\u00adformation atruntime.Forinstance,Bond \nandMcKinleypro\u00adpose a technique that explicitly computes calling contextby addinginstrumentation to eachfunction \ncallsite[7].In con\u00ad trast, we show that explicitly computing context at runtime is not necessary insteadwecan \nusereadily availableinfor\u00admation that is a by-product of a program s computation as context.Ourtechniquerelies \nonthefactthat callingcontext is implicit in the height of the call stack. InC andC++,functionsstoretheirlocal \nvariables onthe stack, a downward-growing region of contiguous memory that serves as a scratch-pad for \ndata whose lifetime lasts no longer than that of the function invocation. In x86 64, theaddressofthe \ntop ofthestack(oftenreferred asthe stack pointer, or SP) is stored in a register dedicated to this use. \nOn every function invocation, the stack pointer is decremented to make room for the callee s activation \nrecord, which stores parameters, local variables, and other temporary items. When the function returns, \nit increments thestack back towhatit hadbeen beforeit wascalled. For example,if, asin Figure1,function \nA callsfunction B which then calls C (we will abbreviate this call path as A-B-C),thestackwill consist \noftheactivationrecordfor A,  probability of precise path 1 0.8 0.6 0.4 0.2 0  4. Step1:Constructing \napath map In order to use context identi.ers as a proxy for call paths, wemust beabletomap a(SP, PC)pair \nto the call path(s) thatlead toit.Wehaveexplored constructingthismap both statically analyzing the the \nprogram binary and source code and dynamically,byrunninganinstrumentedbinary. 4.1 Statically constructedpath \nmaps namddealIIsoplexpovrayastarperlbenchbzip2mcfmilchmmersjenglibquantumh264reflbmsphinx3average Figure \n2. Unaltered C and C++ binaries from the SPEC2006 benchmark suite. The combination of the stack heightandthecurrently \nexecutingfunction uniquelyidenti\u00ad.es a call path68% of the time. followedbythatforB,followedbythatfor \nC.If A later calls C directly, the stack will contain only the activation records for A and C:thestack \npointerwillbedifferentif C is called via A-B-C thanifitiscalledvia A-C. ICPP relies on the hypothesis \nthat the pair stack height andtheidentityofthe currently executingfunction provide a good indicator of \na program s calling context. Figure 2 teststhishypothesisusing unalteredbinariesfromtheSPEC 2006C andC++benchmark \nsuite.Thereis onebarforeach benchmark. The height of a bar gives the fraction of call paths(encountered \nduringaprogramrun) uniquelyidenti\u00ad.ed by the stack height and currently executing function. On average, \nthe CID uniquely identi.es 68% of call paths. Given this observation, a pro.le tool can record the stack \npointer(SP)andthe programcounter(PC)in a large num\u00adber ofcasesandidentify thecallingcontext,ratherthanadd \nexpensiveinstrumentation orwalk theruntimecall stack. Theapproachwe distillinthispaper, ICPP,hasfoursteps: \n1 produceamappingfrom CIDstocallpaths 2 adjust the binary to disambiguate that mapping 3 capture the \ncalling context at runtime 4 process the recorded context identi.ers to produce call paths There are \na varietyof ways to perform eachof these tasks;a clientcanmixandmatch differentimplementationsto .tits \nneedfor speed andto matchitstolerancefor ambiguity,time dilation, and other perturbations. Inthefollowingsectionswe \noutlineseveral possibleim\u00adplementations of each of the four components of ICPP, de\u00adscribe scenarios under \nwhich combinations of these imple\u00admentationswouldbe useful,andidentify situationsinwhich CID is not a \ngood indicator of the calling context and give insightintowhatwecan doaboutit. We can statically construct \na path map by (1) analyzing the binary to determine how function calls, prologues, and epilogues affectthe \nstackheight,(2) constructing a static call graph connectingfunctions by the caller-callee relationship, \nand(3)traversingthecallgraphtogeneratealistof possible paths and their stackheights. 1. Binary analysis. \nIt is relatively straight-forward to an\u00adalyze a binary to determine how the program changes the stack \nheight: adjustments to the stack are generally limited to call sites, function prologues and function \nepilogues. However, if a program allocates a dynami\u00adcally determined amount of storage on the stack, \nvia the alloca call orGCC svariable-length automaticarrays, astaticanalysismaybe unabletodeterminetheaffect \non the stack. 2. Constructingthe static callgraph. Constructing a com\u00adpletecallgraphfromabinaryis possible,butaliasanaly\u00adsis \n(for determining the targets of function pointers) is less precise at the binary level than with source \ncode [10].Instead,we usedtheCIL[17] frameworktoper\u00adform pointer analysis on C source code to determine \nthe targets of function pointers. We did not construct static callgraphsforC++,butwecouldhave usedClassHier\u00adarchyAnalysis[9]analogouslyto \nresolve virtualfunction calls. 3. Traversingthe callgraph. Given a complete callgraph, we can traverse \nit to generate a conservative set of pos\u00adsible call paths. Unfortunately, using this approach the number \nof possible call paths grows exponentially with themaximumlength ofacall path.  If we look up call paths \nlazily (that is, construct the call paths given a stack height and target function), we can work our \nway backwards from the target to main, pruning based on callheight and shortest paths, although thisis \nstill expensiveforlong call paths.To supportthis technique without added ambiguity, the CID construc\u00adtion \nmust be invertible. Our CID is invertible, since it uses only addition,butBondandMcKinley shash-based \nProbabilistic Calling Context relies on modular arith\u00admetic,soitis not. In summary, given enough time \nand space, this static ap\u00adproach can map any CID, even those that may not be exe\u00adcuted.However,thistechnique \ncannot be appliedifanyfunc\u00adtion s activation record size cannot be determined statically.  4.2 Dynamically \nconstructedpath maps Dynamically constructing path maps allows us to restrict ourselves to only those \npaths actually executed. This ap\u00adproach requires of.ine training run(s) that record paths ob\u00adservedatruntimealongwiththeircontextidenti.ers.We \nuse this information to map context identi.ers from later mea\u00adsurement runs to their callpaths. We have \nused icc s -finstrument-functions feature, which inserts hooks on each function entrance and exit,to \naddinstrumentationthat constructs path mapsforC and C++ programs. We use these hooks to build a Calling \nContextTree[2]andrecordthestack heightforevery call path observedintherunningprogram. Because function \nexit hooks are not called when func\u00adtions are exitedvia longjmp, we use a technique described by Froyd \net al. [12] that intercepts calls to longjmp and uses the stack pointer to determine where in the CCT \nexe\u00adcution will continue. This technique corrects for setjmp / longjmp whenthey are usedforexceptionhandling(asin \nthe SPEC 2006 perlbench benchmark), but does not work when these calls are used to implement a coroutine-based \nthreadingsystem,asintheSPEC2006omnetpp benchmark. Wecouldsolvethis problem(andsupport multi-threadingin \ngeneral) by keeping a separate CCT per thread, but since the rest of the SPEC 2006 benchmarks are single-threaded \nwe vechosen nottoaddressit.Asitstandsthisisacurrent limitation of our approach Dynamically constructing \npath maps is ef.cient because we include in the map only call paths that are actually ex\u00adecuted. However, \nif we conduct separate training and mea\u00adsurement runs to reduce time dilation and other perturba\u00adtions \nof the system, we must make sure that the training run covers all the paths executed during the measurement \nrun; otherwise ICPP will reportincorrect results.  4.3 Summary Weappliedthe static approachto generating \npathmapstothe SPEC 2006 C benchmarks and found that while it worked on the smaller benchmarks, our .rst \nimplementation was too slow on perlbench and gcc.For example, the perlbench static call graph consisted \nof 1,835 nodes and 39,890 edges. A traversal targeting a hot function and stack height found 7326 possible \npaths and took about 50 minutes. Although it is possible that additional program analysis would allow \nus to prune enough paths to make this approach feasible, we have instead opted to explore determining \npath maps dynamically.Wepresentresultsofthe dynamicapproachin\u00addepthinSection 9. Insummary,statically \ngenerating path mapsisconserva\u00adtivebutcomputationally expensiveandimprecise.Dynami\u00adcally generating path \nmaps is feasible but may also be im\u00adprecise.InSection5 we discussincreasing precisionby dis\u00adambiguating \ncall paths. +8 +8  +8 +8 ARR +8 +8 +8 +12 +8 +8 +8 +8 (D, 24) (D, 24) (D, 24) (D, 28) Figure 3. IncreasingthesizeofE \nsactivationrecorddisam\u00adbiguatesB-A-D andB-E-D. 5. Step2:Binarydisambiguation The mapping from context \nidenti.ers to call paths obtained in Section 4 may not be one-to-one:itis possiblethatthere are several \ndistinct call paths with the same height ending in the same function. In some cases, this ambiguity may \nbe acceptable(e.g.whendisplayinga hotpathtothe user,atool mightreporttwopossible hotpathsinstead)whileinothers \na more precise result may be needed(e.g. when helping a language runtime determine which destructors \nto call when an exceptionis thrown). We now describe several techniques for reducing/elimi\u00adnating this \nambiguity. 5.1 ActivationRecordResizing Given a call path F1-...-Fn (whereFi are functions on the call \npath),the height ofthestackforthecallpathis: n activation record size(Fi) i=1 By changing the size of \nan activation record for a function Fi (essentiallyaddingspacefor unusedlocal variables),we effectively \nchange the stack height for all call paths that include Fi. We use this mechanism to disambiguate the \nCID to call path mapping. Figure 3 shows two ambiguous call paths, B-A-D and B-E-D. Each node is annotated \nwith size of its activation record.With Active Record Resizing (ARR), we can disam\u00adbiguatethese pathsbyincreasingE \nsactivationrecord size. Changing a function s activation record size on x86 64 usually does not require \nadding any extra instructions: if theprogramiscompiledwithaframe pointer(acommon occurrenceinproductioncodeasremovingtheframe \npointer limits debugging) we can simply modify the the immediate operand oftheinstructionthat makes roomforthefunction \ns localvariables onthestack.Thismodi.cationwill,however, changetheruntimememory usageofthefunction. If \nafunctionislackingaframe pointerwe may (depend\u00ading uponthecompiler) need toinsertasuper.uous sub in\u00adstruction \nin order to affect the size of the activation record. For this reason we always compile our benchmarks \nwith the frame pointer enabled.  This method changes heights on a per function basis, so changing the \nfunction s height to disambiguate one call path may cause another path containing that function to become \nambiguous. We present an an algorithm to apply ARRgloballyinSection 5.1.1. 5.1.1 Randomsearchfordisambiguation \nIn this section we describe our search based implementa\u00adtion ofARR disambiguation.Weassumethat a priorinstru\u00admented \nrun ofthe binaryhas produced aset ofcallpathsand their associated stack depths. Disambiguating a set \nof call pathsisa non-trivialglobaloptimizationproblem.With that in mind, our search process is functional \none could take a more principled approach and add heuristics that take ad\u00advantage ofcertainaspectsofthesearch \nspaceforaparticular problem domain,howeverwehavefoundarandomsearchto work wellfor ourdisambiguation(seeSection9forresults). \nWerepeatthefollowing untilalarge numberof CIDsmap to a single call path. 1 We randomly choose two call \npaths that map to a single CID.To beconcrete,we .ndtwocallpathsthat(i) endin thesamefunctionand(ii)havethesamestack \ndepth. 2Wecreatealist ofthosefunctionsthatdiffer between the two callpaths. 3Wethen disambiguatethesetwocallpathsbyalteringthe \nsizesoftheactivationrecords ofthefunctionsinthelist fromstep(2).In ordertospeedupthesearchprocessand \naccomplish more disambiguation, with each iteration of this loop, we change the .rst function in the \nlist s acti\u00advation record by 16 bytes and check whether this dis\u00adambiguatesthecallpath.Ifit does not,thenwealterthe \nsecondfunctioninthelist sactivationrecordby 32 bytes (the third by 48, and so on), always checking if \nany of these changes disambiguate the two call paths and halt\u00ading ourdisambiguationprocesswheneverwe.ndthetwo \npaths have been disambiguated. This approach aggres\u00adsivelydisambiguates call paths at the expense of \nruntime stack utilization.Section9.1.2discussesthisfurther. Wealwaysincreasethesize ofthestackbyamultiple \nof 16 because on x86 64 thevalue of(SP -8) must be 16\u00adbyte aligned when controlis transferred to afunction \nen\u00adtrypoint.Futurearchitectures(e.g.the newIntelCorei7) may not have this requirement. 4Ifthischangeincreasedthetotalnumberof \nCIDsthatmap to a single call path, we accept the change and go to step 1.Otherwisewe undothechangeandgoback \ntostep1. If after a large number of iterations without forward progress(i.e.any changeto disambiguatecall \npathsac\u00ad tually decreases the total number of CIDs that map to a single call path), we will accept the \nchange even though +8 +8 +8 +8 +4 Callsite +8 +8 +8 +8 Wrapping +8 +8 +8 +8 (D, 24) (D, 24) (D, \n24) (D, 28) Figure 4. Wrappingthecall toBinA disambiguatesB-A-D and A-B-D by increasing the stack height \nalong the A-B edge whileleaving theB-A edge alone. itisglobally notanoptimal choice.Thisisnecessary so \nastokeep oursearchfromgettingstuckinlocaloptima. We used100forthisparameter. We repeated these sets of \nsteps until either (i) the total number of CIDs that map to a unique call path was = 97% or(ii) wemade \nnoforwardprogressafter 2000iterationsof theloop.  5.2 Callsite Wrapping CallsiteWrappingisa disambiguationtechniquethatchanges \na call path s stack height by surrounding a callsite with decrementsandincrementstothestack pointer(orequiv\u00adalently \nreplaces the call at that site with a call to a wrapper function that addsits own activation record to \nthe stack and thencallsthe originalfunction). ConsiderthetwocallpathsinFigure4,B-A-D andA-B- D. Because \nthese paths contain exactly the same functions, they will have the same height. ARR is unable to disam\u00adbiguate \nthese paths: no matter how we resize the activation records ofA,B,andD,thesizes oftheactivationrecordsin \nthesetwo pathswill alwaysadduptoidenticalheights.With CallsiteWrapping, however,wecanchangethe height \nofthe A-Bedge whileleaving theB-A edge alone. Callsite Wrapping is more .exible than ARR because it eliminates \nambiguity by changing the stack height on a per callsite, rather than a per function basis. It also allows \nus to handle the ambiguity that arises when one function calls anothertwice: wecould wrap onecallsiteandleavetheother \nalone. But since Callsite Wrapping adds instructions (and possibly newfunctions),itislikely tobemoreinvasivethan \nARR.  5.3 FunctionCloning Function Cloning replaces a call to afunction with a call to acopyofthatfunctionthat \ncontainsaddeddisambiguation. Consider the paths A-B-A-A-D and A-A-B-A-D in Fig\u00adure 5.Wecannot useCallsiteWrapping(orARR) \ntodis\u00ad  +8 +8 +8 +8 +8 +8 +8 +8 +4 Function +8 +8 +8 +8 Cloning +8 +8 +8 +8 +8 +8 +8 +8 (D, 40) \n(D, 40) (D, 40) (D, 44) Figure 5. Replacingthe calltoAinAwith a callto a clone, A ' ,that wrapsB willdisambiguateA-B-A-A-D \nandA-A-B-A-D. ambiguate these two callpaths because both contain exactly the same edges; no matter which \ncallsites we wrap, the total height ofthesecallpathsatD will always bethesame.If we create a clone of \nfunction A, A ' , that wraps its call to B in ordertochangethestack height,wethen haveA-A ' -B-A-D andA-B-A-A \n' -D.Thestack heightaddedbyA ' callingBis differentthanthat addedbyA callingB,sothesepaths now have different \nheights. This method of disambiguation requires adding new functions, and requires devirtualization[1] \noffunctionpoint\u00ad ersand dynamicdispatch,soweconsiderittobemoreinva\u00adsive thanCallsiteWrapping.  5.4 SelectiveEdgeInstrumentation \nEdgeinstrumentationinsertsinstructionstokeeparecordof when one function is called by another. Selectively \nadding instrumention along ambiguous paths to keep track of the exact path a program took along the way \nis a general tech\u00adniquethat wouldallow ICPP to differentiate between anyam\u00adbiguous call paths at the \ncost of a large perturbation in the behavior of the program.  5.5 Summary We have presented four techniques \nfor disambiguating call paths:(i)ActiveRecordResizing,which canbe used todis\u00adtinguishcallpaths ofthe \nsame heightbut withdifferentfunc\u00adtions,(ii) CallsiteWrapping,which distinguishescall paths with the same \nfunctions but different edges between them, (iii)FunctionCloning,which candifferentiate betweencall pathswith \nthesamefunctionsandedgesbutindifferent or\u00adders, and(iv)SelectiveEdgeInstrumentation, whichis ca\u00adpable \nof distinguishingarbitrary callpaths,butisexpensive. Bond and McKinley argue that the function for calculat\u00ading \nthe next context identi.er, given a call site and the cur\u00adrent identi.er, should be commutative, so that \nit is easy to distinguish between, e.g, call paths B-A-D and A-B-D. We believe that in the general case, \nthe price of commutativity istoo high.Ourresults(cf.Section 9.2)showthat,forC and C++ programs, addition \nof the activation record size to the stack pointer(acommutative operation)is goodenoughto distinguish, \nonaverage, 85%ofpathsinC++programsand 94%ofpathsinCprograms.Clientswith a needforgreater precision can \napplyCallsiteWrapping andFunctionCloning to disambiguatefurther. Inthispaperwehavechosentofocus on usingActivation \nRecord Resizing in order to demonstrate that ICPP can be preciseevenwithoutanyinstrumentationsupport.The \nother disambiguation techniques may also be bene.cial, depend\u00ading on the client of the call path pro.ling. \n6. Step3:Capturing calling context at runtime In order to use ICPP, a tool must capture the stack pointer \nandthe programcounterat runtime.It might doso viaadded instrumentation, by sampling triggered by timer, \nor with hardware performance monitors. 6.1 Sampling withinstrumentation Iftheclientisinterestedin knowingthecontextwhencertain \nsoftware events occur (such as when a particular API is called, or when a certain error occurs), instrumentation \nto capturethe CID couldbeaddedimmediatelybefore orafter the pointofinterest.Thisinstrumentationmightcausesome \nslowdown,butit would belessthaneitherwalkingthestack or collecting edge pro.les. 6.2 Samplingby timer \nIf the client is interested in observing the call paths exe\u00adcuted over period of time, it can use timer-driven \nstatisti\u00adcal samplingtocollectthis CIDs periodically.Thesampling code could be internal, delivered via \nsignals, as is the case with gprof, or in a separate program, like shark[8], that pauses the targeted \nprogram periodically and inspects its state. In either case, the sampler must be able to determine the \nSP and the PC ofthetargeted programimmediately be\u00adfore the timer was called. Since this sampling involves \nin\u00adterruptingtherunning program,it mightcausealargeslow\u00addown.  6.3 Samplingbyhardwareperformancemonitor \nModernprocessors,suchasIntel sCoreDuo, have hardware performance monitors with the ability to record \nthe state of registers whenever certaininteresting events(such as cache misses) occur. ICPP is ideal \nfor use in this case because the  Parameter Core 2 at 2.4GHz Operating System Linux 2.6.25 Tool Chain \nicc 10.1 Measurement papi-3.5.1/pfmon-3.4 memory 4G Table 1. Description of our experimental setup. \nonlyinformationit requires to capture the calling contextis the state of two registers: SP and PC.This \nsampling method isminimally invasivebecauseit does notpausetherunning program.  6.4 Summary Clients \nof ICPP are able to choose among several different ways of capturing calling context depending on the \nevents for which they require context. Sampling with instrumenta\u00adtion or a timer causes a slowdown and \nmay interfere with other measurements, but affords another opportunity to re\u00adduce ambiguity;the samplerinstrumentation \ncanlook upthe CID inthe pathmap.If the CID isambiguous,theinstrumen\u00adtation can walk the stack just enough \nto disambiguate. In this paper, however, we have chosen to use a hardware per\u00adformancemonitor,instead \nofinstrumentation,tosamplethe CID, so we do not walk the stack. 7. Step4:Producing callpaths Givenacontextidenti.er, \nICPP mustthen generallyproduce acall path(orset ofcallpaths)foraclient sconsumption. In previous sections, \nwe have discussed eagerly building afull pathmap, matching CIDs to call paths, and then query\u00ading this \nmap.However, another approachis to construct this mappinglazily.Thatis,we only attempttodiscoverthepaths \ncorresponding to a CID when we are sure that the client will have use for that information. This approach \nis partic\u00adularly usefulwhenconstructingcallpathsfromacallgraph (whetherstatic or dynamic)because doingsoisexpensive. \nICPP also has a choice in how to deal with ambiguous CIDs. Depending on the needs of the client, it could \nreport all of the possible paths, it could limit itself to the top n paths according to some heuristic \n(such as frequency of execution), orit could reportthatit was unabletodetermine theexactpath.Insomecases,itmay \nnotevenbe necessary to produce the set of call paths it might be enough to be abletotocompare onecontextidenti.erwith \nanother. The exact strategy ICPP uses to report the call paths will depend heavily on how the paths will \nbe used. 8. Experimental Methodology We now describe the platform we ran our experiments on, thebenchmarks \nusedin ourstudy,and.nally ourmethodol\u00adogyfor generatingresults. Suite Benchmark #Train Paths # RefPaths \nnamd 207 207 dealII 207317 225313 C++ soplex 7681 7804 povray 41495 43425 astar 547 547 perlbench 82441 \n125312 bzip2 210 108 mcf 49 50 milc 304 304 C hmmer 92 275 sjeng 16812 18647 libquantum 336 336 h264ref \n815 3278 lbm 17 16 sphinx3 685 703 Table 2. The number of unique call paths for the train and refinputs. \n8.1 Infrastructure We conducted our experiments on an Intel Core 2 worksta\u00adtion(Table1).We usedIntel \nsicc compiler at optimization level -O2 -fno-omit-frame-pointer -.nstrument-functions (seeSection5.1fora \ndiscussionastowhywekeeptheframe pointer). Some of our experiments require us to capture the CID of a \nrunning program. To accomplish this we made slight modi.cations to the pfmon UNIX tool so as to cap\u00adture \nboth the PC and SP registers when we sample with the precise event basedsampling(PEBS) mechanism[20].PEBS \nallows precise attribution of a certain limited set of hard\u00adware eventstoinstructions(e.g. whichinstruction \ncausedthe 1000thL1 data cachemiss).With ICPP we canmap thisin\u00adstruction directly to the current runtime \ncall path, and thus attribute hardware events to calling context. In our experiments we sample every \none million cycles. In order to interrupt on cycles, we use the PEBS enabled event instructions retired \nin conjunction with the mask and inv parameters of the hardware performance monitor. Speci.cally, we \nset mask to8 and inv to 1. This has the effect of counting cycles in which 8 or less instruc\u00adtions retire \nper cycle. An Intel Core 2 microprocessor must retireanywherefrom 0-8instructionspercycle,sothePEBS counterwith \nthese parametersiseffectively countingcycles.  8.2 Benchmarks We usedtheSPECCPU2006[21]CandC++ benchmark \nsuite to explore the effectiveness of ICPP. We were un\u00adable to get 4 of the 19 benchmarks working with \nour ap\u00adproach. xalancbmk, gcc, and gombk have too many paths for us to process with our current implementation \nof ARR disambiguation. Benchmark omnetpp uses setjmp and longjmp for co-routines that our instrumentation \nis not ableto handle.Wealso hadtomanually addinstrumentation to two methods in povray dueto abugin icc \nthat causes exits from those methods to not be properly instrumented. Table 2 presents the benchmarks \nused in our study and the total number of unique call paths for both the train and ref inputs. The number \nof paths varies greatly depending upon the benchmark and input (e.g. perlbench has almost 35%more pathsin \nref thanin train).  8.3 Implementation of ICPP For these experiments we use the dynamic call path con\u00adstruction \ndiscussed in Section 4.2. We disambiguate the bi\u00ad naries usingActiveRecordResizing(cf.Section5.1)andthe \nglobal optimization search described in Section 5.1.1. We capture the calling context using a hardware \nperformance monitor(cf.Section 6.3)and discuss producing pathsfrom aneagerly constructedpathmap as outlinedinSection7. \n 8.4 Metrics To evaluate our approach, we categorize call paths as either precise or ambiguous. We evaluate \ntwo usage scenarios of ICPP. In the .rst scenario, we use the same input to pro.le and then evaluate. \nIn the second scenario, we pro.le with onesetofinputsandevaluate ona newset. In the .rst scenario, there \nwere two possible outcomes foragivencallpath:(i) if thereare nootherpathswith thesame CID,wecall thepath \nprecise ; and(ii)if there are any additional paths with the same CID, we call the path ambiguous .  \nInthesecondscenariowecollectCIDs onthepro.leinput and then categorize call paths on the evaluation input. \nIn addition to precise and ambiguous there are two additional categorizationsfor an evaluation call path:(i) \nif there are some paths in the pro.le run with the same CID astheevaluationpath,buttheevaluationpathis \nnot amongthem,wecallthepath incorrect ; and(ii)ifthere are no paths in the pro.le run with the same CID \nas the evaluation path, we call the path missing .  We also classify paths by the total number of call \npaths that sharetheir CID.Wecall this numberapath s degreeof ambiguity. Under this classi.cation, a path \nwith degree of ambiguity 1 is precise, a path with degrees of ambiguity 2 sharesits CID with exactly \noneotherpath,andso on. Note that our de.nition of a call path functions that are active on the call stack \ndoes not consider the particular call sites within a function. This de.nition is the same as some prior \nwork(e.g. gprof[13], Spivey[19] and Zhuang et al[25]). If a particular client needs to disambiguate call \npaths based upon the speci.c call sites of a function, Sec\u00adtion5liststhreetechniquesthataccomplish this \ngoal(Call\u00adsite wrapping, Function cloning and Selective edge instru\u00admentation). 9. Results Inferredcallpathpro.lingisusefulin \nboth an of.ine as well as online scenario. In of.ine scenarios, we are often running in a controlled \nenvironment where we know all the inputs to the program and can run the program multiple times to obtain \nthe infor- Suite Benchmark Pro.le Lookup Disambiguation namd 1.2x 269cycles 1.2(sec) dealII 9.1x 2395cycles \n384(sec) C++ soplex 3.6x 497cycles 16(sec) povray 5.8x 721cycles 960(sec) astar 3.4x 331cycles 2(sec) \nperlbench 2.9x 1002cycles 196(sec) bzip2 1.4x 320cycles < 1(sec) mcf 1.6x 208cycles < 1(sec) milc 1.4x \n282cycles < 1(sec) C hmmer 1.0x 230cycles 3.1(sec) sjeng 2.0x 625cycles 5(sec) libquantum 1.1x 270cycles \n2(sec) h264ref 2.1x 342cycles 31(sec) lbm 1.1x 163cycles < 1(sec) sphinx3 1.3x 344cycles < 1(sec) Table \n3. The cost of ICPP outside program execution. mation we need. ICPP is invaluable in this case because \nit enables ustocollect contextidenti.erssimultaneously with other data without worrying about perturbingthose \nmeasure\u00adments.Moreover,sinceweareabletorunthe programmul\u00adtiple times, we can perform an instrumented \nrun (cf. Sec\u00adtion4.2) usingthesameinputsasthedatacollectionrunsin ordertotranslatethecontextidenti.erstofull \ncallpaths. In online scenarios, we do not have the luxury of rerun\u00adning the program or knowing all the \ninputs to the program before it runs. ICPP pro.ling is useful in this setting since context identi.ers \ninduce minimal overhead on the running program yet the information is rich enough that if we need thefull \ncall path,wecanlookit upinthe path map. We now evaluate ICPP with respect to the online and of.ine scenarios. \n 9.1 Cost of ICPP Broadlyspeaking ICPP has two kinds of costs. Pro.le costs: The cost associated with \nan of.ine pro.le runthatgathers data necessaryfor disambiguation.This is a three phase process each with \nassociated costs:(i) the data collection cost that collects the CID to call path mapping(Section 4.2),(ii) \nthecost of disambiguation of the binary(Section 5.1) and(iii) thecost associated with looking upthe CID \ninthecall path map(Section7).  Measurement costs: The runtime overhead of running a disambiguated binary \n(both space overhead and time overhead)whileatthesametime usingthehardwareper\u00adformancemonitorstosamplethe \nCID at regularintervals (Section 6.3).  This section reports on all of these costs. 9.1.1 Costof ICPP:Pro.lecosts \nTable 3 details the of.ine costs of ICPP. In this section We discusseachofthesecostsinturn. Cost of of.ine \npro.ling In order to build the CID to call path mapping, we employ a pro.le run that maps the CID at \neachfunctionentry tothecurrentcall path(SeeSection 4.2 for exact details of our approach). In column \nPro.le of Cost of disambiguation The Disambiguation column of Table 3 shows the of.ine runtime cost of \ndisambiguation using our ARR method described in Section 5.1. For 12 of the 14 benchmarks the amount \nof time to disambiguate each benchmark sothat either 97%ofthecallpaths uniquely map to a single CID, \nor the disambiguation process cannot make forward progress, is less than 1 minute. The two that take \nlongerthan1minute, dealII and perlbench,take onthe order of6 and3 minutes, respectively.The reasonforthisincrease \ninrunningtimeis duetothefactthatthesetwobenchmarks have the largest number of call paths. We should note \nthat thisoverhead,however,isa onetimecostthatcouldbe done, forinstance,atthetime ofthe program sinstallation. \n  9.1.2 Costof ICPP:Measurement costs In this section we measure the cost(bothin overhead and space)of \nrunning a disambiguated binary while at the same time usingthehardwareperformancemonitorstosamplethe \nCID everyonemillioncycles(seeSection8formoredetails). Our priorwork[16] showsthatmany aspects oftheex\u00adperimental \nsetupcan biasexperiments.Concretely,this bias may make our runs look slower or faster compared to a run \noftheprogramthatdoes notcollect CIDs.Toavoidsuchbias, weraneach experiment(with andwithoutthe CID collec\u00adtion)in32differentexperimental \nsetupsto obtainadistribu\u00adtion of run times and used t-test to determine if there was a statistically \nsigni.cant difference between the two distribu\u00adtions.We generatedthe 32experimental setupsbyrandomly \n(b) C Figure 6. Performance impact of recording CID for C++ andC programs. changing environment variables \nand using randomly gener\u00adatedlink orders, bothofwhichintroducebias. RuntimeOverhead Figure6plotsthe datafortheC++(a) \nandC(b) benchmarks.Each violinsummarizestheexecu\u00adtiontimes oftherunswith( original ) andwithout( collect \nCID ) collecting the CID. To enable us to present data for multiple benchmarks on the same violin, we \nnormalized the data to the median of the original runs. The white dot in eachviolingivesthemedian pointandthethicklinethrough \nthe white dot gives the inter-quartile range. The height of the violin gives the range in execution times \nwe observed asaresult ofchangingtheexperimental setup.Thewidth of the violin gives the distribution of \nthe execution times. The numbersabovethe x-axisgivethemeanoverheadof collect CID as a percentage. NC \nsays that there is no statistically signi.cant slow down (as determined by the t-test). From this data \nwe see that collecting CIDs incurs an insigni.cant slow down(median of0 acrossall benchmarks, geometric \nmean of 0.17%);itis non-trivial onlyfor perlbench at about 2.1%. Space Overhead Active Record Resizing \nadds to the size oftherun-timestack becauseit disambiguatescall pathsby increasing the size of function \nactivation records. Table 4 perlbench bzip2mcf milchmmer sjenglibquantum h264reflbm sphinx3 namd dealII \nsoplex povray astar Table3 weshowtheoverheadof ourinstrumentation onthe train inputs.We display overhead \nastheratio oftherun\u00adtime of a program before instrumentation over the runtime of the program with instrumentation. \nThe geometric mean overhead for all of the benchmarks is 2.9x. For some of the programs,theoverheadislarge(i.e. \n14timesslowerfor dealII).Weshouldnotethat(i) thisprocessisof.ineandis done onceperinputforeachprogramand(ii) \nourinstrumen\u00adtationcanbeimproved upontoreducetheoverhead. Cost of lookup in context-path map Once we \nhave the path map there is an associated cost of looking up any par\u00adticular CID inthemap.Thesize ofthe \npathmapsvarieswith (a) C++ the benchmarks in our study and thus so too does the cost. In order to investigate \nthe expense of looking up a CID in the path map we wrote a simple tool that loads each of the path-mapsinto \na balancedred-blacktree.We selectedalarge number ofrandom CID valuesandrecordedtheaveragetime amount \nof time it took to look up a particular CID in the map. The Lookup column of Table 3 details the average \nnumber ofmicroprocessorcyclesto performthislookupfor eachbenchmark.The benchmark dealII hasthelargest \nnum\u00adber ofpaths(seeTable2forfulllist) andsoitmakessense thatittoo hasthelongestlookuptimes(our red-black \ntree has O(log N ) complexity where N is the total number of entriesin the map).  Suite Benchmark Increase \nin Maximum StackUsage namd 1.00x dealII 1.16x C++ soplex 1.05x povray 1.13x astar 1.04x perlbench 2.54x \nbzip2 1.00x mcf 1.00x milc 1.02x C hmmer 1.00x sjeng 1.00x libquantum 1.61x h264ref 1.00x lbm 1.00x sphinx3 \n1.00x Geometric Mean 1.13x Table 4. Theincreaseinthemaximumsize oftherun-time stack when disambiguatingwithActiveRecordResizing. \ndemonstrates that while many programs show little to no increase in stack usage, others, such as perlbench, \nrequire an increase of more than 2.5x. perlbench is extreme in this case because it has many functions \nwith identical activa\u00adtion record sizes called via function pointers from the same callsites.ARR mustthereforeincreasetheactivationrecord \nsizes of these functions in order to distinguish call paths containing them. When disambiguated functions \nare called recursively, the stack increase can be very large. The aver\u00adage(geometricmean)stack usageincreaseacrossallbench\u00admarks,however,is \nonly1.13x.Itisworth notingthat(cf. Section 9.1.2) this moderate increase in stack usage has al\u00admost no \nperformanceimpact. OurcurrenttechniqueforARR disambiguationbalances thetimeittakesto disambiguate callpaths(cf.Section \n9.1.1) with theamount ofruntimestack utilization.Wefoundthat aggressively changing the activation record \nsizes of func\u00adtionsin ordertodisambiguatecallpaths usually spedupthe timeittakestodisambiguateabenchmark \nhoweverit does soatthecostofruntimestackutilization.Ultimately, ourap\u00adproach wasa balance betweenthesetwo \nparameters(disam\u00adbiguationspeed andstack usage) andanyfurtherimplemen\u00adtations ofARRdisambiguation arefreeto \nchoose differently.  9.2 Of.ineScenario Inthe of.inescenario,weassumethatwe havealltheinputs available \nin advance and thus we can produce the CID to call path mapping by running the program and observing \nits behavior(e.g.asinSection 10wherewemightwantto understandwhich callpathshavethe highestL1 datacache \nmiss rate). In Section 8.4 we discuss the metrics used in this study. Toremindthereader,we brie.yreiteratethem \nhere.Wecol\u00adlectedall callpaths that we encounteredduring our program run. There are two possible categorizations \nfor a given call path:(i) thereare nootherpathswiththesame CID ( pre\u00adcise ); and(ii) there areadditional \npathswith thesame CID ( ambiguous ). Even in the ambiguous case, the CID still maps to the correct call \npath but it maps to additional call pathsalso.This occurswhenthereismorethan onesequence ofcallsthatleadstoa \nprocedureandthe differentsequences yield exactly thesamestackdepth.Wecall thetotal number ofpathsthat \nshareapath s CID its degreeofambiguity .A path with degree of ambiguity 1 is precise, a path with de\u00adgrees \nof ambiguity 2 shares its CID with exactly one other path, and so on. Wecan getambiguity evenafteradjustingthesizes \nofthe activation records due to two reasons. First, our algorithm for adjusting activation record sizes \nis greedy and gives up aftera.xed numberofiterations,soit may noteliminateall ambiguity. This problem \ncan be reduced by using a smarter algorithm(thoughwebelieve,buthave notproved,thatopti\u00admally adjusting \nactivation record sizesisNP-Hard).Second, our ambiguity algorithm does not help the situation when two \ncallpathsto a procedure contain exactlythe same proce\u00addures but in a different order. This problem cannot \nbe .xed by adjusting activation record sizes; Section 5.2 describes mechanisms that can eliminate this \nproblem. On manually inspecting the output of our system we found that the sec\u00adondreasonwasthemostprominent \noneforambiguity. Figure 7 shows the results for the C++ and C bench\u00admarks.We geta precision of 0.80forC++ \nprograms(i.e., 80%oftheencountered callpathshavea CID that maps only tothatpath)and 0.95forCprograms.OneoftheC++pro\u00adgrams(povray) \ndoes suffer from signi.cant ambiguity be\u00adcause manyofits callpaths containthe exactsamefunctions, butinadifferentorder.Still, \nourapproachyieldsprecisecall paths with minimal run-time overhead for the vast majority of the cases. \nFigure8sheds morelightinto the cases that are ambigu\u00adous.Ithas onelineforeachbenchmark.Apoint (x, y) \nsays thatthe probabilitythatthe degree of ambiguityof a callpath is less than x (that is, that the call \npath s CID maps to x or fewer callpaths)isy.WeseethatfortheCprograms,the am\u00adbiguity is not serious: even \nwhen we have some ambiguity, itistypically noworsethan2.Evenfor povray most(95%) ofthetimeweget anambiguityof5 \norless.Moreover,if we consider the entire suite of benchmarks, on average 99% of call paths have CIDs \nthat map to 5 or fewer call paths. This isaparticularly usefulstatisticif aclientof ICPP istolerant to \nsome amount of ambiguity. To summarize, our approach produces precise call paths forthe of.ine scenario \nwhileincurring minimaloverheadfor the running program.  9.3 OnlineScenario In the online scenario, we \nassume that we do not have have all the inputs available for generating the CID to call path mapping. \nIn Section 8.4 we discuss the metrics used in this study. To remind the reader, we brie.y discuss them \nagain here. Weran onapro.leinput(SPEC train)and constructed a mapping from CIDs to call paths. We then \ncollected all call pathsfrom an evaluationinput(SPEC ref)and categorized   cumulative probability \n soplex povray 1 2 5 1020 degree of ambiguity (a) C++ (a) C++ 1 2 5 1020 degree of ambiguity sjenglibquantum \n(b) C Figure 7. Precision of path pro.les for C++ and C bench\u00admarks(of.ine scenario). these paths. In \naddition to the precise and ambiguous outcomes, there are two additional outcomes in the online scenario:(i) \nthere aresome pathsinthe pro.le run with the same CID as the evaluation path, but the evaluation path \nis not among them ( incorrect ); and (ii) there are no paths in the pro.le run with the same CID as the \nevaluation path ( missing ). Figure 9 shows the results for the C++ and C bench\u00admarks.Weseethat whenacall \npathfromtheevaluationrun ispresentinthepro.lerun,wearemoreoftenthan notpre\u00adcise(75%ofthetimeforC++programsand \n73%ofthetime forCprograms).However,weare unabletomapthe CID for an evaluation path to any pro.le path \n7% of the time for C++ programs and 20% of the time for C programs. These missing paths indicates that \nour pro.le run did not exercise thefull range of behaviorwesawintheevaluationruns.To alleviate this problem, \nwe could either use more inputs for trainingruns or useacallgraphanalysistocomeupwiththe mapping. Figure \n10 is similar to Figure 8 and sheds more light into the ambiguous cases. Unlike Figure 8, the curves \nin this graph may not go up to 1.0 because of the missing and incorrect cases. As with Figure 8, we see \nthat the curves (b) C Figure 8. Degree ofambiguity(of.inescenario). typically reach their asymptote early; \nin other words, even when our approachproduces ambiguous results, the amount ofambiguityissmall onaverage \n94%ofcallpathsthat are not missing or incorrect have CIDs that map to 5 or fewer call paths. To summarize, \nwhile our results are slightly inferior for the online case than the of.ine case, they are still good: \nwhen our system produces call paths, they are correct more than 74.5%ofthetime.Oursystemrarelyproducesincorrect \nresults(4% ofthetimeforC++programsand3% ofthetime forCprograms). 9.4 Bene.t of activation record resizing \nSofar,allof ourresults useactivationrecord resizing(Sec\u00adtion 5.1). Figures 11and 12 give data similartoFigure7 \nand 9 but without activation record resizing. Comparing these graphs, it is clear that activation record \nresizing greatly in\u00adcreases the number of times we provide a precise path. For ourof.inescenario,activationrecord \nresizingincreases our precisionfrom 67%to 80%forC++programsandfrom 85% to 95% for C programs. In our \nonline scenario, activation record resizingincreases ourprecisionfrom 60%to 72%for C++programsandfrom \n67%to 75%forCprograms.  1.0 missing 0.8 incorrect ambiguous precise cumulative probability cumulative \nprobability namddealIIsoplex astarpovray 1 2 510 degree of ambiguity perlbench bzip2mcfmilc hmmer sphinx3 \n (a) C++ (a) C++ 1.0 missing 0.8 incorrect ambiguous precise 0.6 0.4 0.2 0.0 sjenglibquantum h264reflbm \ndegree of ambiguity (b) C Figure 9. Precision of path pro.les for C++ and C bench\u00admarks(online scenario). \n10. UsageScenarios Inthepriorsectionweevaluatedboththecostandef.cacyof InferredCallPathPro.lingin anof.ine \nand online scenario. Now we give some insight into how clients of ICPP could use ourtechniqueintheirownenvironments. \nHardware-centric call path performance analysis: One compelling useof ICPP isattributingcertainhardwareevents \n(i.e. L1 data-cache misses, or branch-mispredicts) to the call paths that give rise to the majority of \nthose events. Traditional call path pro.lingtechniquesare suspectinthis situation because they either \nadd extensive instrumentation (e.g.gprof)orwalkthestack(e.g.Apple s shark) both of whichinterfere withthe \nhardware structures(e.g.L1data\u00adcache) we wish to measure. By splitting our measurement task into two \nruns, one in which we collect the path-map and then one that collects the CID in hardware performance \nmonitors, we reduce any perturbation in our measurements due toinstrumentation. Debugging support: If \nthe language semantics permit it, a language runtime could use ICPP to determine the call stack whenany \nkind ofexceptionisthrown(e.g. divideby zero,segfault,etc.).If thecall path mappingsarestoredina (b) C \nFigure 10. Degree ofambiguity(onlinescenario). cold area of the binary, the language runtime could simply \nlookup the set of call paths that map to the current CID whenanexceptioniscaught.Becauseanexception denotes \nanomalous behavior, a bit of ambiguity in the call paths providedtoa useris notthat muchofanissue.Justgivingthe \nusera possiblesetofcallpathscangreatly aidintheirsearch forabug.Moreover,becauseICPP does notwalktheruntime \nstack aggressiveoptimizationsdo notaffectitscorrectness. Analysis for compilation in a VM: Modern JIT \ncompil\u00aders, such as Sun s Hotspot JIT, use a sampling pro.ler to guide their decisions about which hot \nmethods to optimize. Because these pro.lers only sample the current executing function, the granularity \nof their compilation is limited to the method. IfaparticularJIT used ICPP forpro.lingitwouldhavean understanding \nnotjustofthe hotmethods,butalsothe hot paths all with negligibleamountsofextrainstrumentation. ThiswouldallowtheJIT \ncompilertoincreaseits granularity ofcompilationfromthemethodtothecall path.Becauseit is safe to compile \nmultiple paths, this application of ICPP would be tolerant of some amount of ambiguity. Anomalous Behavior \nDetection: Bond and McKinley propose usingprobabilisticcallingcontextidenti.erstode\u00adtectanomalous (andtherefore \npossiblyinsecure)callpaths   cumulative probability soplex povray sjenglibquantum h264reflbm (a) \nof.ine (a) of.ine sjenglibquantum soplex povray (b) online Figure 11. Precision of path pro.lesforC andC++ \nbench\u00admarks(of.ine without activation record sizing). inrunningprograms.OurCID couldbe usedforthis purpose \nas well. This usage would be tolerant of some amount of ambiguity because it does not require actually \nenumerating the possiblecallpathsforacontext;itisenoughtoidentify them. 10.1 Summary In this section \nwe have described several possible uses of ICPP,in both onlineandof.inescenarios. 11. RelatedWork Prior \nwork in producing either calling context or call path pro.les all effectively use an active approach \nto their mea\u00adsurement; they all add either staticinstructions(e.g. gprof addsinstructionsto capture caller/callee \nrelationships[13]) or dynamicinstructions (e.g. shark which adds dynamic instructions atruntimein ordertowalkthecall \nstack[8]). In contrast to all of these approaches and the ones we dis\u00adcussinturn, ourapproach doesaddanyinstructionstocap\u00adturecallingcontext(eitherstatic \nor dynamic).Ourinference based approach allows us, for instance, to use the precise event based sampling \nmechanism of modern hardware per\u00adformance monitorsto capture a .atpro.le oftheCIDs, which (b) online \nFigure 12. Precision of path pro.lesforC andC++ bench\u00admarks(online without activation record sizing). \nwecanthen usetoemulatethe outputofpriorwork(e.g.a set of hot callpaths ` ala shark). There is an abundance \non prior work that either intro\u00adduces novel techniques for collecting calling context or di\u00adrectly using \ncalling context (e.g. in optimizations). In the paragraphsthatfollowwereviewsome ofthat work. ExhaustiveInstrumentation \nOneofthemostpopularcall\u00ading context pro.lersis thegprof tool, whichbuilds caller/\u00adcallee relationships \nby instrumentation the epilogue of all functions in a program [13]. These caller/callee pairs are then \naggregated with some loss of precision into a dy\u00adnamiccallgraphfordigestionbya user.Thiswork waslater \nextendedtomore preciselyhandle programswith mutual re\u00adcursionand dynamicmethodbindingbySpivey[19].This \ntype of tool is arguably one of the more useful instruments that a programmer has at her disposal. Inferred \nCall Path Pro.ling can provide the same functionality without any of the onlineinstrumentationcost. BallandLarusillustratehowtoaddinstrumentation \nopti\u00admally toedgesinanintra procedural control-.ow graph[5]. Unfortunatelythisamount ofoverhead(16% onSPEC95) \nis large enough to obsfucate certain types of program un\u00adderstanding(e.g.whichpathshavethelargest numberofL1 \ndata cache misses) and our focus is on inter procedural call paths.  Selective Instrumentation Obtaining \naccurate call path pro.les usually requireshighoverheadduetothesigni.cant amount of instrumentation. \nUsually, however, programmers only care about hot call paths and can disregard any others. Thisinsightisthebasisformostpriorwork \nthat doesselec\u00adtive instrumentation via sampling, bursting or some combi\u00adnationthereof(e.g.[6, 25, 23,4,14]). \nBernatandMillerhad theinsightthat aprogrammer usu\u00adally only cares about the behavior of a few functions \nout of themanyinanapplication[6].Theirinsightallowsa pro\u00adgrammer to selectivelyinstrumentfunctions thus \nallowing the user to balance instrumentation overhead with accuracy of results. Zhuang et alintroduce \nan adaptive approach to sampling hot callpaths.They walkthe runtime call stackand are smart about how \nfar up they walk i.e. stopping the stack walk whentheyhave hit a part ofthecallingcontexttreethatthey \nalready havesampled[25].Theiroverheadissome ofthe lowestincall pathpro.ling(20%forJava programs). Stack \nWalking Walking the runtime call stack is one way to capture calling context however doing so at ev\u00adery \nentry to a function boundary is overly obtrusive. Thus, most approaches to stack walking are based upon \nsampling (e.g.[8, 12, 15]).Froydetal samplethecall stacktoproduce call paths at an overhead of 7% for \nthe SPEC2000 bench\u00admarks[12].Likewise,the Shark performancetool provides sampled stack walkingtoidentify \nhotcallpaths[8].OurIn\u00ad ferredCallPathPro.lingapproachcouldbe used asstand-in replacementsfor bothoftheseapproaches. \nUses of Calling Context There are many uses of calling contextandcall path pro.lesin priorwork(e.g. debugging \nvia stack traces or using call paths to aid in optimization decisions). For instance, Hazelwood and Grove \nuse calling context to aid inlining decisions [14] as do Arnold and Grove[3].Likewise,PettisandHansen \nusecontexttohelp with code positioning [18]. An interesting area of future work would be using these \ntechniques with ICPP as a gen\u00aderator of calling context. Probabilistic Calling Context Our work is most \nclosely related to the work of Bond and McKinley s Probabilistic Calling Context [7]. Their approach \ninstruments function epilogues and keeps a hashed value that is built from the prior functions on the \ncall stack and the current executing function. Much like our ICPP, this context information is probabilistic \nand is likely to provide a unique identi.er for context. However, unlike our approach they do not keep \ntrack of which call paths are on the current runtime stack. Moreover their approach adds instrumentation \nto compute the hash function at each function entry. Probabilistic Call Context is more likely to provide \na unique calling context, however without a signi.cant amount of modi.cation to their technique it is \nunable map their context identi.er to call paths. 12. Conclusion Thispaperintroducesa novelapproachforcapturingcalling \ncontext and then building call path pro.les, Inferred Call-Path Pro.ling. The key insight behind our \ntechnique is that readily available information during program execution the height of the call stack \nand the identity of the currently executing function can uniquely identify the sequence of function calls \nthat lead up to the currently executing func\u00adtion. Wecallthe(stack height,currentexecutingfunction) pairthe \ncontextidenti.er.Forthoseinstances wherethe con\u00adtext identi.er maps to multiple call paths, we show how \nto affectthesize offunctionactivationrecordssoastoincrease thelikelihoodthat anyparticularcontextidenti.ermapstoa \nsingle call path. Weevaluate ourapproach ontheSPECCPU2006C and C++benchmarksintwo usagescenarios: of.ine \nand online. In the of.ine scenario we know the inputs of the program in advance so we can do a pro.ling \nrun prior to the actual run.Inthe onlinescenario,wedo not knowtheinputsinad\u00advance.Weshowthat ourapproach \nallowsthecontextidenti\u00ad.erto uniquelyidentify 88%ofcallpathsintheof.inesce\u00adnarioand 74%ofcallpathsintheonlinescenario.Because \nmodern processors allow us to periodically sample both the program counter and stack pointer the constituents \nof our context identi.er in hardware performance monitors, the overheadof ourapproachis0.17%(geometricmeanacross \nall benchmarks) and at most 2.1%. References [1] GeraldAignerandUrsH\u00a8olzle. Eliminating virtualfunction \ncalls in C++ programs. In ECOOP 96: Proceedings of the 10thEuropeanConference onObject-OrientedProgramming, \npages142 166,London,UK,1996.Springer-Verlag. [2] Glenn Ammons, Thomas Ball, and James R. Larus. Exploit\u00adinghardwareperformance \ncounterswith.ow andcontextsen\u00adsitivepro.ling. SIGPLANNot.,32(5):85 96,1997. [3] M. Arnold and D. Grove. \nCollecting and exploiting high\u00adaccuracy call graph pro.les in virtual machines. In Code Generation andOptimization,2005.CGO2005.International \nSymposium on,pages51 62,March2005. [4] MatthewArnold andDavidGrove. Collecting and exploiting high-accuracycallgraphpro.lesin \nvirtual machines. In CGO 05: Proceedings of the international symposium on Code generation and optimization, \npages 51 62, Washington, DC, USA,2005.IEEEComputerSociety. [5] Thomas Ball and James R. Larus. Optimally \npro.ling and tracing programs. ACM Trans. Program. Lang. Syst., 16(4):1319 1360,1994. [6] AndrewR.BernatandBartonP.Miller. \nIncremental call-path pro.ling:Researcharticles. Concurr.Comput.:Pract.Exper., 19(11):1533 1547,2007. \n [7] Michael D. Bond and Kathryn S. McKinley. Probabilistic CallingContext. SIGPLANNot.,42(10):97 112,2007. \n[8] Apple Computer. Shark. http://developer.apple.com/performance. [9] Jeffrey Dean, David Grove, and \nCraig Chambers. Optimiza\u00adtion of object-oriented programs using static class hierarchy analysis. In ECOOP \n95: Proceedings of the 9th European Conference onObject-OrientedProgramming,pages77 101, London,UK,1995.Springer-Verlag. \n[10] Saumya Debray and Robert Muth. Alias analysis of exe\u00adcutable code. In InPOPL,pages12 24,1998. [11] \nHenry Hanping Feng, Oleg M. Kolesnikov, Prahlad Fogla, Wenke Lee, and Weibo Gong. Anomaly detection using \ncall stack information. In SP 03: Proceedings of the 2003 IEEE Symposium on Security and Privacy, page \n62, Washington, DC,USA,2003.IEEEComputerSociety. [12] NathanFroyd,JohnMellor-Crummey, andRobFowler. Low\u00adoverhead \ncall path pro.ling of unmodi.ed, optimized code. In Proceedings of the 19th annual international conference \nonSupercomputing,pages81 90,Cambridge,Massachusetts, 2005.ACM. [13] Susan L. Graham, Peter B. Kessler, \nand Marshall K. Mcku\u00adsick. gprof: A call graph execution pro.ler. In Proceedings of the 1982 SIGPLAN \nsymposium on Compiler construction, pages 120 126, Boston, Massachusetts, United States, 1982. ACM. [14] \nKim Hazelwood and David Grove. Adaptive online context\u00adsensitiveinlining. In Proceedings of theinternational \nsympo\u00adsium onCodegeneration and optimization:feedback-directed and runtime optimization,pages253 264,SanFrancisco,Cal-ifornia,2003.IEEEComputerSociety. \n[15] AllenD. Malony,Sameer Shende,RobertBell,KaiLi,LiLi, andNickTrebon. Advancesin theTAUperformance \nsystem. Performance analysis and grid computing, pages 129 144, 2004. [16] Todd Mytkowicz,Amer Diwan, \nMatthiasHauswirth, and Pe\u00adterF.Sweeney. Producing wrongdata withoutdoing anything obviously wrong! In \nASPLOS 09:Proceeding of the14thin\u00adternational conference on Architectural support forprogram\u00adming languages \nand operating systems,pages 265 276,New York,NY,USA,2009.ACM. [17] George C. Necula, Scott McPeak, Shree \nPrakash Rahul, and Westley Weimer. CIL: Intermediate language and tools for analysis and transformation \nof C programs. In CC 02: Pro\u00adceedings of the 11th International Conference on Compiler Construction, \npages 213 228, London, UK, 2002. Springer-Verlag. [18] Karl Pettis and Robert C. Hansen. Pro.le guided \ncode posi\u00adtioning. SIGPLANNot.,25(6):16 27,1990. [19] J.M.Spivey. Fast, accurate callgraphpro.ling. Softw.Pract. \nExper.,34(3):249 264,2004. [20] B. Sprunt. Pentium 4 performance-monitoring features. Mi\u00adcro,IEEE,22(4):72 \n82,Jul/Aug2002. [21] Standard Performance Evaluation Corporation. SPEC CPU2006Benchmarks. http://www.spec.org/cpu2006/. \n[22] Toshio Suganuma, Toshiaki Yasue, Motohiro Kawahito, HideakiKomatsu, andToshioNakatani. Adynamic \noptimiza\u00adtionframeworkfor aJavajust-in-time compiler. SIGPLAN Not.,36(11):180 195,2001. [23] Kapil Vaswani, \nAditya V. Nori, and Trishul M. Chilimbi. Preferential path pro.ling: compactly numbering interesting \npaths. In Proceedings of the 34th annual ACM SIGPLAN-SIGACTsymposium onPrinciples ofprogramminglanguages, \npages351 362,Nice,France,2007.ACM. [24] Mark Weiser. Program slicing. In ICSE 81: Proceedings of the \n5th international conference on Software engineering, pages439 449,Piscataway,NJ,USA,1981.IEEEPress. \n[25] Xiaotong Zhuang, Mauricio J. Serrano, Harold W. Cain, and Jong-Deok Choi. Accurate, ef.cient, and \nadaptive calling contextpro.ling. SIGPLANNot.,41(6):263 271,2006.     \n\t\t\t", "proc_id": "1640089", "abstract": "<p>Prior work has found call path profiles to be useful for optimizers and programmer-productivity tools. Unfortunately, previous approaches for collecting path profiles are expensive: they need to either execute additional instructions (to track calls and returns) or they need to walk the stack. The state-of-the-art techniques for call path profiling slow down the program by 7% (for C programs) and 20% (for Java programs). This paper describes an innovative technique that collects minimal information from the running program and later (offline) infers the full call paths from this information.</p> <p>The key insight behind our approach is that readily available information during program execution - the height of the call stack and the identity of the current executing function - are good indicators of calling context. We call this pair a <i>context identifier</i>. Because more than one call path may have the same context identifier, we show how to disambiguate context identifiers by changing the sizes of function activation records. This disambiguation has no overhead in terms of executed instructions.</p> <p>We evaluate our approach on the SPEC CPU 2006 C++ and C benchmarks. We show that collecting context identifiers slows down programs by 0.17% (geometric mean). We can map these context identifiers to the correct unique call path 80% of the time for C++ programs and 95% of the time for C programs.</p>", "authors": [{"name": "Todd Mytkowicz", "author_profile_id": "81100300026", "affiliation": "University of Colorado, Boulder, CO, USA", "person_id": "P1728752", "email_address": "", "orcid_id": ""}, {"name": "Devin Coughlin", "author_profile_id": "81442593521", "affiliation": "University of Colorado, Boulder, CO, USA", "person_id": "P1728753", "email_address": "", "orcid_id": ""}, {"name": "Amer Diwan", "author_profile_id": "81100202872", "affiliation": "University of Colorado, Boulder, CO, USA", "person_id": "P1728754", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1640089.1640102", "year": "2009", "article_id": "1640102", "conference": "OOPSLA", "title": "Inferred call path profiling", "url": "http://dl.acm.org/citation.cfm?id=1640102"}