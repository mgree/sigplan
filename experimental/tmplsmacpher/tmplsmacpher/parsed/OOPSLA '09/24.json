{"article_publication_date": "10-25-2009", "fulltext": "\n Providing Rapid Feedback in Generated Modular Language Environments Adding Error Recovery to Scannerless \nGeneralized-LR Parsing Lennart C. L. Kats Maartje de Jonge Emma Nilsson-Nyman Eelco Visser Delft University \nof Delft University of Lund University Delft University of Technology Technology emma@cs.lth.se Technology \nl.c.l.kats@tudelft.nl m.dejonge@tudelft.nl visser@acm.org Abstract Integrated development environments \n(IDEs) increase pro\u00adgrammer productivity, providing rapid, interactive feedback based on the syntax and \nsemantics of a language. A heavy burden lies on developers of new languages to provide ad\u00adequate IDE \nsupport. Code generation techniques provide a viable, ef.cient approach to semi-automatically produce \nIDE plugins. Key components for the realization of plug\u00adins are the language s grammar and parser. For \nembedded languages and language extensions, constituent IDE plu\u00adgin modules and their grammars can be \ncombined. Unlike conventional parsing algorithms, scannerless generalized-LR parsing supports the full \nset of context-free grammars, which is closed under composition, and hence can parse lan\u00adguage embeddings \nand extensions composed from separate grammar modules. To apply this algorithm in an interactive environment, \nthis paper introduces a novel error recovery mechanism, which allows it to be used with .les with syn\u00adtax \nerrors common in interactive editing. Error recovery is vital for providing rapid feedback in case of \nsyntax errors, as most IDE services depend on the parser from syntax highlighting to semantic analysis \nand cross-referencing. We base our approach on the principles of island grammars, and derive permissive \ngrammars with error recovery productions from normal SDF grammars. To cope with the added com\u00adplexity \nof these grammars, we adapt the parser to support backtracking. We evaluate the recovery quality and \nperfor\u00admance of our approach using a set of composed languages, based on Java and Stratego. Categories \nand Subject Descriptors D.2.3 [Software Engi\u00adneering]: Coding Tools and Techniques; D.3.4 [Program\u00adming \nLanguages]: Processors General Terms Languages Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. OOPSLA 2009, October 25 29, 2009, Orlando, Florida, USA. Copyright \nc &#38;#169; 2009 ACM 978-1-60558-734-9/09/10. . . $10.00 1. Introduction Integrated Development Environments \n(IDEs) increase pro\u00adgrammer productivity by combining a rich toolset of generic language development \ntools with services tailored for a spe\u00adci.c language. These services provide a programmer with rapid, \ninteractive feedback based on the syntactic structure and semantics of the language. High expectations \nwith re\u00adgard to IDE support place a heavy burden on the shoulders of developers of new languages. Language \ndevelopment en\u00advironments facilitate ef.cient development of IDE support for new languages. Notable examples \ninclude IMP [9], the Meta-Environment [37], MontiCore [24], and openArchitec\u00ad tureWare [13]. In this \npaper we focus on Spoofax/IMP [20]. Leveraging code generation and interpretation techniques, these tools \nprovide a viable, ef.cient approach to semi\u00adautomatically produce IDE plugins. Compositional Languages \nand SGLR Success of a lan\u00adguage, in part, depends on interoperability with other lan\u00adguages and systems. \nDifferent languages address different concerns. Language composition is a promising approach for providing \nintegrated support for different concerns. How\u00adever, compositional languages, such as language extensions \nand language embeddings, further increase the burden for language engineers, as they now have to provide \nIDE sup\u00adport for a combination of languages or language elements. Therefore, language development tools \nmust offer support for extensions and combinations of languages. IDE develop\u00adment for compositional languages \ngreatly bene.ts from code generation where several, independently de.ned parts can be combined. How well \na tool can support language composi\u00adtion depends on the underlying language techniques it uses. The Scannerless \nGeneralized-LR parsing parsing algo\u00adrithm (SGLR) [40] supports the modular syntax de.nition formalism \nSDF [41]. SDF is declarative yet expressive, and has been used to specify non-trivial grammars for existing \nlanguages such as Java, C, and PHP, as well as domain\u00adspeci.c languages and embeddings and extensions \nbased on these languages [7]. Unlike other parsing formalisms (par\u00ad ticularly those commonly used in \nIDEs), SDF is closed un\u00adder composition: existing grammars can be reused and com\u00adposed to form new languages. \nThis makes it a useful pars\u00ading technique to use in language tools supporting composi\u00adtion of languages. \nIntegration of SGLR into an IDE based on IMP [8] is ongoing work [20].  Parsing in IDEs Using a language \ndevelopment environ\u00adment, the grammar is the .rst artifact constructed by the developer. Traditionally, \nIDEs have often used handtailored parsers. Doing so reduces .exibility, especially with lan\u00adguage extensions \nand combinations in mind. For the ef.cient development of language tools it is essential that parser \ngen\u00aderators are used instead. The parser for a language forms the foundation of all language-speci.c \neditor services. The parser performs syn\u00adtactic analysis (parsing) to construct abstract syntax trees \n(ASTs) for user programs. These ASTs can be used for pre\u00adsentational editor services, such as syntax \nhighlighting, code folding, and outlining. They also form the basis for semantic analysis of a program, \nallowing for editor services such as cross-referencing and checking for semantic errors. To provide the \nuser with rapid syntactic and semantic feedback, programs must be interactively parsed as they are edited. \nAs the user edits a program, it is often in a syntactically invalid state. Parse error recovery techniques \ncan diagnose and report parse errors, and can construct a valid AST for syntactically invalid programs \n[10]. Thus, to successfully apply a parser in an interactive setting, proper parse error recovery is \nof paramount importance. The scannerless, generalized nature of SGLR is essen\u00adtial for parsing compositional \nlanguages, but also introduces challenges for implementing error recovery. The current SGLR implementation \nprovides no recovery of any kind, and only reports the .rst unexpected character in case of fail\u00adure. \nWe have identi.ed two main challenges. (1) Scanner\u00adless parsing: Where other parsers employ a separate \nscanner for tokenization and report errors in terms of missing (or expected) tokens, SGLR merely reports \nunexpected char\u00adacters. (2) Generalized parsing: A GLR parser processes multiple branches (representing \ndifferent interpretations of the input) in parallel. Syntax errors can only be detected at the point \nwhere the last branch failed, which may not be lo\u00adcal to the actual root cause of an error. This makes \nit dif.cult to properly identify the offending substring or character. This paper presents a novel approach \nto error recovery us\u00ading SGLR. We base our approach on the principles of island grammars [39, 26, 27], \nde.ning new production rules for a grammar that make it more permissive of its inputs. We iden\u00adti.ed \nseveral idioms for de.ning such recovery rules that either discard substrings in the input or insert \nliterals (i.e., keywords and braces) as necessary. Based on the analysis of an existing grammar, we can \nautomatically derive a set of these rules. Using the recovery rules, parse errors of various kinds can \nbe properly diagnosed and repaired, reporting any missing or inserted keywords and braces, addressing \nchal\u00adlenge (1). To cope with the added complexity of grammars with recovery rules, we adapt the parser \nimplementation to apply the recovery rules in an on-demand fashion, using a backtracking algorithm. This \nalgorithm explores an increas\u00ading, backward search space to .nd a minimal-cost solution for applying \nthe set of recovery rules. This technique allows us to identify the most likely origin of an error, thus \navoiding reports of spurious errors and addressing challenge (2). We have incorporated the approach in \nthe Spoofax/IMP IDE plugin generator [20], to obtain robust editors for com\u00ad posite languages that can \nprovide feedback to the user in the presence of syntactic errors. We have evaluated the er\u00adror recovery \napproach using a set of grammars for plain Java and for composite languages such as Stratego-Java and \nJava-SQL. Contributions -A novel approach to parse error recovery based on gram\u00admar relaxation, adding \nnew recovery productions to make a grammar more permissive. -An adaptation of the SGLR algorithm that \nef.ciently handles the increased complexity of permissive gram\u00admars. -A language (grammar) independent \napproach to error recovery using SGLR. Outline The remainder of this paper starts with a motivat\u00ading \nstudy of composite languages in Section 2. In Section 3 we discuss the requirements on error recovery. \nIn Section 4 we discuss the notion of island grammars, which provide the inspiration for our error recovery \napproach. In Section 5 we show how the ideas of island grammars can be used to make complete language \ngrammars into permissive grammars. In Section 6 we explain the adaptation of the SGLR algorithm to deal \nwith the combinatorial explosion introduced by per\u00admissive grammars. Section 7 evaluates the approach \nwhile Section 8 covers related work. Finally, the paper ends with conclusions and future work in Section \n9. 2. Composite Languages Composite languages integrate elements of different lan\u00adguage components. We \ndistinguish two classes of composite languages: language extensions and embedded languages. Language \nextensions extend a base language with new, of\u00adten domain-speci.c elements. Language embeddings com\u00adbine \ntwo or more existing languages, allowing one language to be nested in the other. Examples of language \nextensions include the addition of traits [11] or aspects [21] to object-oriented languages, en\u00ad hancing \ntheir support for adaptation and reuse of code. Other examples include new versions of a language, introducing \nnew features to an existing language, such as Java 1.5 s enum keyword for enumerated types. Examples \nof language embeddings include data base que\u00adry expressions integrated into an existing, general-purpose \n public class Authentication { public String getPasswordHash(String user) { SQL stm = <| SELECT password \nFROM Users WHERE name = ${user} |>; return database.query(stm); } } Figure 1. An extension of Java with \nSQL queries. webdsl-action-to-java-method: |[ action x_action(farg*){ stat* } ]| -> |[ public void x_action(param*){ \nbstm* } ]| with param* := <map(action-arg-to-java)> farg*; bstm* := <statements-to-java> stat* Figure \n2. Program transformation using embedded object language syntax. language such as Java. Such an embedding \nboth increases the expressivity of the host language and facilitates static checking of queries. Figure \n1 illustrates such an embedding. Using a special quotation construct, an SQL expression is embedded into \nJava. In turn, the SQL expression includes an anti-quotation of a Java local variable. By supporting \nthe notion of quotations in the language, a compiler can distin\u00adguish between the static query and the \nvariable, allowing it to safeguard against injection attacks. In contrast, when us\u00ading only a basic Java \nAPI for SQL queries constructed using strings, the programmer must take care to properly .lter any values \nprovided by the user. Language embeddings are sometimes applied in meta\u00adprogramming for quotation of \ntheir object language. Trans\u00adformation languages such as Stratego [5] and ASF+SDF [38] allow fragments \nof a language that undergoes transformation to be embedded in the speci.cation of rewrite rules. Figure \n2 shows a Stratego rewrite rule that rewrites a fragment of code from a domain-speci.c language to Java. \nThe rule uses meta\u00advariables (written in italics) to match action constructs and rewrites them to Java \nmethods with a similar signature. SDF supports meta-variables by reserving identi.er names in the context \nof an embedded code fragment. Parsing Composite Languages Key to the effective real\u00adization of composite \nlanguages are modular, reusable lan\u00adguage descriptions, which allow constituent languages to be de.ned \nindependently, and then composed to form a whole. A particularly dif.cult problem in composing language \nde.nitions is composition at the lexical level. Consider again Figure 2. In the embedded Java language, \nvoid is a reserved keyword. For the enclosing Stratego language, however, this name is a perfectly legal \nidenti.er. This difference in lexi\u00adcal syntax is essential for a clean and safe composition of languages. \nIt is undesirable that the introduction of a new language embedding or extension invalidates existing, \nvalid programs. The dif.culty in combining languages with a different lexical syntax stems from the traditional \nseparation between scanning and parsing. The scanner recognizes words either as keyword tokens or as \nidenti.ers, regardless of the con\u00adtext. In the embedding of Java in Stratego this would im\u00adply that void \nbecomes a reserved word in Stratego as well. Only using a carefully crafted lexical analysis for the \ncom\u00adbined language, introducing considerable complexity in the lexical states to be processed, can these \ndifferences be rec\u00adonciled. Using scannerless parsing [33, 32], these issues can be elegantly addressed \n[6]. The Scannerless Generalized-LR (SGLR) parsing algorithm [40] realizes scannerless parsing by incorporating \nthe generalized-LR parsing algorithm [35]. GLR supports the full class of context-free grammars, which \nis closed under composition, unlike subsets of the context\u00adfree grammars such as LL(k) or LR(k). Instead \nof rejecting grammars that give rise to shift/reduce and reduce/reduce con.icts in an LR parse table, \nthe GLR algorithm interprets these con.icts to ef.ciently try all possible parses of a string in parallel, \nthus supporting grammars with ambiguities, or grammars that require more look-ahead than incorporated \nin the parse table. Hence, the composition of independently developed grammars does not produce a grammar \nthat is not supported by the parser, as is frequently the case with LL or LR based parsers. The syntax \nde.nition formalism SDF2 [41] integrates lexical syntax and context-free syntax supported by SGLR as \nparsing algorithm. Undesired ambiguities in SDF2 def\u00adinitions can be resolved using declarative disambiguation \n.lters [3]. Implicit disambiguation mechanisms such as longest match are avoided. Other approaches, including \nPEGs [14], language inheritance in MontiCore [24], and the composite grammars of ANTLR [29], implicitly \ndisam\u00ad biguate grammars by forcing an ordering on the alterna\u00adtives of a production the .rst (or last) \nde.nition overrides the others. Enforcing explicit disambiguation allows unde\u00adsired ambiguities to be \ndetected, tested against in regression tests, and explicitly addressed by a developer. For non-trivial \ngrammars, in particular composed, independently developed grammars, this characteristic is of vital importance. \nSDF has been used to de.ne various composite lan\u00adguages, often based on mainstream languages such as \nC/C++ [42], PHP [4], and Java [7, 19]. The example grammar shown in Figure 3 extends Java with embedded \nSQL queries. It imports both the Java and SQL grammars, adding only productions that integrate the two. \nIn SDF, grammar pro\u00adductions take the form p1...pn -> s and specify that a sequence of strings matching \nsymbols p1 to pn matches the symbol s. The productions in this particular grammar spec\u00adify two productions \nto embed SQL into Java expressions and two productions to embed Java into SQL. The productions are annotated \nwith the {cons(name)} annotation, which indicates the constructor name used to label these elements when \nan abstract syntax tree is constructed.  module SQL-Java imports JavaMix[Java] SQL exports context-free \nsyntax \"<|\" Query \"|>\" -> Expr[[Java]] {cons(\"ToSQL\")} \"<|\" Expr \"|>\" -> Expr[[Java]] {cons(\"ToSQL\")} \n\"${\" Expr[[Java]] \"}\" -> Expr {cons(\"FromSQL\")} \"${\" Expr[[Java]] \"}\" -> String {cons(\"FromSQL\")} Figure \n3. A grammar extending Java with SQL queries; adapted from [4]. To avoid name collisions between the \nExpr symbol in the SQL grammar and the Expr symbol in the Java grammar, SDF uses parametrization of symbol \nnames: the [Java] parameter in the JavaMix import indicates that all Java symbols should be referenced \nusing the [[Java]] post.x. 3. Interactive Parsing and Error Recovery For all the merits of SDF and the \nSGLR parser, in the form of modularity, declarative disambiguation, and composition\u00adality, one may wonder \nwhy these technologies have not (yet) seen more widespread use. In part, this is due to a lack of publicity. \nThere are also a number of more fundamental is\u00adsues that have hindered their adoption. Recently, Bravenboer \net al [6] analyzed some of these issues. First, the syntax of productions in SDF may be awkward and unappealing \nto de\u00advelopers accustomed to BNF-style rules. Perhaps reversing the order of the production pattern and \nthe symbol would ap\u00adpeal to a broader audience. Second, [6] identi.es error han\u00ad dling as an open issue. \nThird, a lack of tool support for an\u00adalyzing ambiguities is identi.ed as an open issue. Last and perhaps \na more practical issue has been that the tools were only implemented in C, targeting the Unix/Linux platform. \nThe main obstacles for employing SDF and SGLR in an interactive environment arguably are the second issue, \na lack of error handling; and the last issue, lacking cross-platform support. This paper addresses the \nsecond issue, adding both error diagnosis and error recovery to the SGLR parser. This makes it possible \nto parse syntactically incorrect .les and use the result in the different syntactic and semantic editor \nservices of an IDE. We base our implementation on JSGLR, a Java implementation of SGLR [18]. With its \ndevelopment, although the implementation is not quite mature, the last is\u00adsue has also been effectively \nresolved. The remaining issues impact only developers of SDF grammars. Based on our own experience, and \nlooking at the large set of grammars already developed using SDF, we trust that these issues are not \na sig\u00adni.cant obstacle, and that they will be resolved in the future. Parse error handling encompasses \ntwo concerns: error re\u00adporting and error recovery. Error reporting, by itself, has an important role \nin giving feedback to the user. An error han\u00addling technique should accurately report all syntactic errors \nwithout introducing spurious errors. This requires accurate diagnosis of errors. A faulty correction \nmay leave the parser module ExtractCalls exports context-free start-symbols Module context-free syntax \nChunk* -> Module {cons(\"Module\")} WATER -> Chunk {cons(\"WATER\")} \"CALL\" Id -> Chunk {cons(\"Call\")} lexical \nsyntax [\\ \\t\\n] -> LAYOUT ~[\\ \\t\\n]+ -> WATER {avoid} [A-Z][A-Z0-9]* -> Id lexical restrictions WATER \n-/-[A-Za-z0-9] Figure 4. An island grammar for extracting calls from a legacy application; adapted from \n[26]. in a state that will cause spurious errors to be reported later. Furthermore, when an error is \nmisdiagnosed, the error mes\u00adsage issued for it tends to be misleading. An error message should indicate \nthe exact location of the error and provide a suggestion for correction. Good error messages re.ect the \nintention of the programmer. Furthermore, recovery from parse errors allows the parser to continue the \nanalysis of the source code after the detection of an error. The resulting parse tree of the analysis \nis a parse tree representing the corrected input. This parse tree allows further analysis of the source \ncode at the syntactical and se\u00admantic level even for programs that are not in a syntactically valid state \nas the programmer is editing them. 4. Island Grammars Island grammars [39, 26, 27] combine grammar production \nrules for the precise analysis of parts of a program and se\u00adlected language constructs with general rules \nfor skipping over the remainder of an input. Island grammars are com\u00admonly applied for reverse engineering \nof legacy applica\u00adtions, for which no formal grammar may be available, or for which many (vendor-speci.c) \ndialects exist [26]. Us\u00ad ing an island grammar, a parser can skip over any uninter\u00adesting bits of a .le \n( water ), including syntactic errors or constructs found only in speci.c language dialects. A small \nset of declarative context-free production rules speci.es only the interesting bits (the islands ) that \nare parsed properly . Island grammars were originally developed using SDF [39, 26]. The integration of \nlexical and context-free productions of SDF allows island grammars to be written in a single, declarative \nspeci.cation that includes both lexical syntax for the de.nition of water and context-free productions \nfor the islands. Although SGLR did not support error recovery per se, a parser using an island grammar \nbehaves similar to one that implements a noise-skipping algorithm. It can skip over any form of noise \nin an input .le. However, using an is\u00adland grammar, this logic is entirely encapsulated in the gram\u00admar \nde.nition itself.  Figure 5. The un.ltered abstract syntax tree for a COBOL statement, constructed \nusing the ExtractCalls grammar. As an example, consider Figure 4, which shows an SDF speci.cation of \nan island grammar that extracts call state\u00adments from COBOL programs. Any other statements in the program \nare skipped and parsed as water. The .rst context\u00adfree production of the grammar de.nes the Module symbol, \nwhich is the start symbol of the grammar. A Module is a series of chunks. Each Chunk, in turn, is parsed \neither as a patch of WATER or as an island, in the form of a CALL con\u00adstruct. The lexical productions \nde.ne patterns for layout, wa\u00adter, and identi.ers. The layout rule, using the special LAYOUT symbol, \nspeci.es the kind of layout (i.e., whitespace) used in the language. Layout is ignored by the context-free \nsyntax rules, since their patterns are automatically interleaved with optional layout. The WATER symbol \nis de.ned as the inverse of the layout pattern, using the ~ negation operator. Together, they can match \nany given character stream. The {avoid} an\u00adnotation on the WATER rule speci.es a disambiguation .lter \nfor these productions, indicating that the production is to be avoided: at all times, a non-water Chunk \nis to be preferred. In the lexical restrictions section, we specify a follow re\u00adstriction for the WATER \nsymbol. This rule ensures that water is always greedily matched, and never followed by any other water \ncharacter. Consider the following COBOL statement: CALL \"CKOPEN\" USING filetable, status Given our island \ngrammar, the SGLR parser can construct a parse tree or rather a parse forest that includes all possible \ninterpretations of this text.1 The parse tree includes the com\u00adplete character stream, all productions \nused, and their anno\u00adtations. In this paper, we focus on abstract syntax trees (de\u00adrived from the parse \ntrees) where only the {cons(name)} constructor labels appear in the tree. Figure 5 shows the 1 Note that \nparse forests are ef.ciently represented using the ATerm li\u00adbrary [2], which employs hash-consing to \nachieve maximal sharing of sub\u00ad trees, ensuring that any identical leaves and branches occupy the same \nspace in memory. module Java-15 exports lexical syntax [\\ \\t\\12\\r\\n] -> LAYOUT \"\\\"\" StringPart* \"\\\"\" \n-> StringLiteral \"/*\" CommentPart* \"*/\" -> Comment Comment -> LAYOUT ... context-free syntax \"if\" \"(\" \nExpr \")\" Stm -> Stm {cons(\"If\")} \"if\" \"(\" Expr \")\" Stm \"else\" Stm -> Stm {avoid, cons(\"IfElse\")} ... \nFigure 6. Part of the standard Java grammar in SDF; adapted from [6]. complete, ambiguous abstract syntax \ntree for our example input program. Note in particular the amb node, which indi\u00adcates an ambiguity in \nthe tree: CALL \"CKOPEN\" in our ex\u00adample can be parsed either as a proper Call statement or as WATER. \nSince the latter has an {avoid} annotation in its def\u00adinition, a disambiguation .lter can be applied \nto resolve the ambiguity [3]. (Normally, these .lters are applied automati\u00ad cally during or after parsing.) \n5. Permissive Grammars As we have observed in the previous section, there are many similarities between \na parser using an island grammar and a noise-skipping parser. In the former case, the water produc\u00adtions \nof the grammar are used to fall back in case an input sentence cannot be parsed, in the latter case, \nthe parser al\u00adgorithm is adapted to do so. This observation suggests that the basic principle behind \nisland grammars may be adapted for use in recovery for complete, well-de.ned grammars. In contrast, the \ntechnique of island grammars is targeted only towards partial grammar de.nitions. In the remainder of \nthis section, we illustrate how the no\u00adtion of productions for de.ning water can be used in reg\u00adular \ngrammars, and how these principles can be further ap\u00adplied to achieve alternative forms of recovery from \nsyntax errors. Without loss of generality, we focus many of our ex\u00adamples on the familiar Java language. \nFigure 6 shows a part of the SDF de.nition of the language. Indeed, Java can be parsed without the use \nof SGLR, but for extensions and em\u00adbeddings based on Java, SGLR has proved invaluable. Fur\u00adthermore, \nthe current problems with a lack of error recovery in SGLR also hold for the stand-alone Java language; \ncur\u00adrently, if any error is found in a pure Java input, the parser comes to a screeching halt and is \nunable to continue. 5.1 Chunk-Based Water Recovery Rules Whereas island grammars have an underlying \nchunk struc\u00adture, this structure is lacking in complete, well-de.ned gram\u00admars. Rather, these grammars \ntypically have a more hierar\u00adchical structure. For example, Java programs consist of a one  module Java-15-Permissive-ChunkBased \nimports Java-15 exports lexical syntax ~[\\ \\t\\12\\r\\n]+ -> WATER {recover} lexical restrictions WATER \n-/-~[\\ \\t\\12\\r\\n] context-free syntax WATER -> Stm {cons(\"WATER\")} Figure 7. Chunk-based recovery rules \nfor Java. or more classes that each contain methods, which contain statements, etc. Still, it is possible \nto impose a more chunk\u00adlike structure on existing grammars in a coarse-grained fash\u00adion: for example, \nin Java, all statements can be considered as chunks. Figure 7 extends the standard Java grammar with \na coarse-grained chunk structure at the statement level. In this grammar, every Stm symbol is considered \na chunk, which can be parsed as either a statement or as water, effec\u00adtively skipping over any noise \nthat may exist within method bodies. Note that the standard Java grammar, as shown in Figure 6, already \nuses an {avoid} annotation to explicitly avoid the dangling else problem, a notorious ambiguity that \noccurs with nested if/then/else statements. Therefore, in our recovery rules we use {recover} rather \nthan {avoid} to distinguish between the two concerns of disambiguation and recovery. We can extend the \ngrammar of Figure 7 to introduce a chunk-like structure at other levels in the hierarchical struc\u00adture \nformed by the grammar, e.g. at the method level or at the class level, in order to cope with syntax errors \nin dif\u00adferent places. However, doing so leads to a large number of possible interpretations of syntactically \ninvalid (but also syn\u00adtactically valid) programs. For example, any invalid state\u00adment that appears in \na method could then be parsed as a water statement. Alternatively, the entire method could be parsed \nas a water method. A preferred interpretation can be picked by counting all occurrences of the {recover} \nanno\u00adtation in ambiguous branches, and selecting the variant with the lowest count. The technique of \nselectively adding water recovery rules to a grammar allows any existing grammar to be adapted. It avoids \nhaving to rewrite grammars from the ground up to be more permissive in their inputs. Grammars adapted \nin this fashion produce parse trees even for inputs that contain syntax errors and cannot be parsed by \nthe original grammar. The WATER constructors in the abstract syntax trees indicate the location of errors, \nwhich can then be straightforwardly reported back to the user. While the approach we presented so far \nis already moder\u00adately effective in recovery from syntax errors, there are three disadvantages to the \nrecovery rules as presented here. Firstly, the rules are language-speci.c and are best implemented by \nan expert of a particular language and its SDF grammar spec\u00adi.cation. Secondly, the rules are rather \ncoarse-grained in na\u00adture; invalid subexpressions in a statement cause the entire statement to be parsed \nas water. Lastly, the additional pro\u00adductions alter the abstract syntax of the grammar (introduc\u00ading \nnew WATER terminals), causing the parsed result to be unusable for tools that depend on the original \nstructure.  5.2 General Water Recovery Rules Adapting a grammar to include water productions at differ\u00adent \nhierarchical levels is a relatively simple yet effective way to selectively skip over noise in an input \n.le. In the re\u00admainder of this section, we re.ne this approach and use it as a basis for our general \napproach to error recovery. Note throughout this section we use only the standard, unaltered SDF speci.cation \nlanguage, adding only the {recover} an\u00adnotation and identifying idioms for recovery rules. Most programming \nlanguages feature comments and in\u00adsigni.cant whitespace that have no impact on the logical structure \nof a program. They are generally not considered to be a logical part of the abstract syntax tree. As \ndiscussed in Section 4, any form of layout, which may include comments, is implicitly interleaved in \nthe patterns of concrete syntax productions. The parser, in a way, skips over these parts, in a similar \nfashion to the noise skipping of island grammars. However, layout and comments interleave the context-free \nsyntax of a language at a much .ner level than the recov\u00adery rules we have discussed so far. Consider \nfor example the Java statement if (temp.greaterThan(MAX)/*API change pending*/ ) fridge.startCooling(); \nin which a comment appears in the middle of the statement. Context-free syntax in SDF is a convenient \nway to de.ne context-free productions without having to worry about the interleaving of layout. Only \nin the kernel syntax that lies at the heart of SDF, does the production explicitly include the layout: \nsyntax \"if\" <LAYOUT?-CF> \"(\" <LAYOUT?-CF> <Expr-CF> <LAYOUT?-CF> \")\" <LAYOUT?-CF> <Stm-CF> -> <Stm-CF> \ncons(\"If\") The parse table generator for SDF automatically converts context-free productions to this \nform. (The production above was derived from the If production in Figure 6). Expressed in kernel syntax, \nthe symbol names in the rule above use angle brackets and explicitly state that they are related to context-free \n(CF) syntax. The optional layout symbols <LAYOUT?-CF> are not considered for the construction of the \nabstract syntax tree (and may be stored as annotated data instead). We can use the notion of interleaving \ncontext-free pro\u00adductions with optional layout in order to de.ne a new varia\u00adtion of the water-based \nrecovery rules we have shown so far. Consider Figure 8, which combines elements of the com\u00ad ment de.nition \nof Figure 6 and the chunk-based recovery rules from Figure 7. It introduces optional water into the \n module Java-15-Permissive-WaterOnly imports Java-15 exports lexical syntax [A-Za-z0-9\\_]* -> WATERWORD \n{recover} ~[A-Za-z0-9\\_\\ \\t\\12\\r\\n] -> WATERSEP {recover} WATERWORD -> WATER WATERSEP -> WATER WATER \n-> LAYOUT {cons(\"WATER\")} lexical restrictions WATERWORD -/-[A-Za-z0-9\\_] Figure 8. Water-based recovery \nrules. grammar, which interleaves the context-free syntax patterns. As such, it skips noise on a much \n.ner grained level than our previous grammar incarnation. To separate patches of water into small chunks, \neach associated with its own signi.cant {recover} annotation, we distinguish between WATERWORD and WATERSEP \ntokens. This ensures that large strings, consisting of multiple words and special characters each, are \ncounted towards a higher recovery cost. As an example input, consider a programmer who is in the process \nof introducing a conditional clause to a statement: if (temp.greaterThan(MAX) // missing ) fridge.startCooling(); \n Still missing the closing brace, the standard SGLR parser would report an error near the missing character, \nand would stop parsing. Using the adapted grammar, a parse forest is constructed that considers the different \ninterpretations, tak\u00ading into account the new water recovery rule. Based on the count of the {recover} \nannotations, the following would be the preferred interpretation: if (temp.greaterThan) fridge.startCooling(); \n In the resulting fragment both the opening ( and the identi\u00ad.er MAX are discarded, giving a total cost \nof 2 recoveries. The previous, chunk-based incarnation of our grammar would simply discard the entire \nif clause. While not yet ideal, the new version maintains a larger part of the input. Since it is based \non the LAYOUT symbol, it also does not introduce new water nodes into the abstract syntax tree. For reporting \ner\u00adrors, the original parse tree can be inspected instead. The adapted grammar of Figure 8 no longer \ndepends on hand-picking particular symbols at different granularities to introduce water recovery rules. \nTherefore, it is effectively language-independent, and can be automatically constructed using only the \nLAYOUT de.nition of the grammar.  5.3 Literal-insertion Recovery Rules So far, we have focused our efforts \non recovery by deletion of erroneous substrings. However, in an interactive environ\u00ad module Java-15-Permissive-InsertionsOnly \nimports Java-15 exports lexical syntax -> \")\" {recover, cons(\"INSERT\")} -> \"]\" {recover, cons(\"INSERT\")} \n-> \"}\" {recover, cons(\"INSERT\")} -> \">\" {recover, cons(\"INSERT\")} -> \";\" {recover, cons(\"INSERT\")} lexical \nsyntax INSERTSTARTQ StringPart* INSERTENDQ -> StringLiteral {cons(\"INSERTEND\")} \"\\\"\" -> INSERTSTARTQ \n{recover} \"\\n\" -> INSERTENDQ lexical syntax INSERTSTARTC CommentPart* INSERTENDC -> Comment {cons(\"INSERTEND\")} \n\"/*\" -> INSERTSTARTC {recover} EOF -> INSERTENDC Figure 9. Literal-insertion recovery rules. ment, most \nparsing errors may well be caused by missing substrings instead. Consider again our previous example: \nif (temp.greaterThan(MAX) // missing ) fridge.startCooling(); Our use case for this has been that the \nprogrammer was still editing the phrase, and did not yet add the missing closing brace. Discarding the \nopening ( and the MAX identi.er al\u00adlowed us to parse most of the statement and the surrounding .le, reporting \nan error near the missing brace. Still, a better recovery would be to insert the missing ). One way to \naccommodate for insertion based recovery is by the introduction of a new rule to the syntax to make the \nclosing brace optional: \"if\" \"(\" Expr Stm -> Stm {cons(\"If\"), recover} This strategy, however, is rather \nspeci.c for a single produc\u00adtion, and would greatly increase the size of the grammar if we applied it \nto all productions. A better approach would be to actually insert the particular literal into the parse \nstream. SDF actually allows us to simulate this using separate pro\u00adductions that insert literal symbols. \nWe illustrate this in Figure 9. Consider the .rst lexical syntax section, which lists a number of basic \nliteral-insertion recovery rules, each in\u00adserting a closing bracket or other literal that ends a produc\u00adtion \npattern. Literal-insertion rules have an empty pattern, indicating that they match an empty string. That \nis, for each of these literals speci.ed in the grammar, an empty string may be matched against instead. \nJust as in our previous examples, {recover} ensures these productions are deferred. The con\u00adstructor \nannotation {cons(\"INSERT\")} is used as a label\u00ading mechanism for error reporting for the inserted literals. \nAs it is de.ned in lexical syntax context, it is not used in the resulting abstract syntax tree.  Insertion \nRules for Opening Brackets In addition to in\u00adsertions of closing brackets in the grammar, we can also \nadd rules to insert opening brackets. These literals start a new scope or context. This is particularly \nimportant for com\u00adposed languages, where a single starting bracket can indicate a transition into a different \nsublanguage, such as the |[ and <| brackets of Figure 1 and Figure 2. Consider for example a syntax error \ncaused by a missing opening bracket in the SQL query of the former .gure: SQL stm = // missing <| SELECT \npassword FROM Users WHERE name = ${s} |>; Without an insertion rule for the <| opening bracket, the en\u00adtire \nSQL fragment could only be recognized as (severely syntactically incorrect) Java code. Thus, it is essential \nto have insertions for such brackets. However, for the insertion of opening brackets, the regular SGLR \nimplementation no longer suf.ces, since it could insert in.nitely many combi\u00adnations of opening and closing \nbrackets. We address this in Section 6 by adapting the parsing algorithm to consider the added recovery \ncases in an on-demand fashion. On Literals, Identi.ers, and Reserved Words Literal\u00adinsertion rules can \nalso be used for literals that are not re\u00adserved words. For example, for the combined Stratego-Java language, \na good insertion rule is: lexical syntax -> \"end\" In Java, the string end is not a reserved word and \nis a perfectly legal identi.er. In Java, identi.ers are de.ned as follows: lexical syntax [A-Za-z\\_\\$][A-Za-z0-9\\_\\$]* \n-> ID This lexical rule would match a string end. Still, the recovery rule will strictly be used to \ninsert the literal end, and never an identi.er. The reason why the parser can make this dis\u00adtinction \nis that the literal end itself is de.ned as an ordinary symbol when normalized to kernel syntax:2 syntax \n[\\e] [\\n] [\\d] -> \"end\" The literal-insertion rule simply adds an additional deriva\u00adtion for the \"end\" \nsymbol, providing the parser with an ad\u00additional way to parse it. As such, the rule does not change how \nidenti.ers (ID) are parsed. This is an important property when considering composed languages in general. \nIn many cases, some literals in one sublanguage may not be reserved words in another. With a naive recovery \nstrategy that inserts tokens into the stream, this could result in keywords being inserted in place of \nidenti.ers (e.g., end in Java). But since the insertion rules only apply when a literal is expected, \nthese effects are avoided with out approach. 2 Actually, in fully normalized kernel syntax form, the \ncharacter codes [\\101] [\\110] [\\100] are used. Insertion Rules for Lexical Symbols Insertion rules can \nalso be used to insert lexical symbols such as identi.ers. In our approach, we only focus on a very small \nset of lexical symbols; missing identi.ers generally indicate an error in the enclosing context-free \nconstruct and are not addressed separately. Still, using identi.er insertions is feasible, but adds extra \ncomplexity to the tools that process the abstract syntax tree. The lower sections of Figure 9 specify \ninsertion rules for terminating the productions of the StringLiteral and Comment symbols, .rst seen in \nFigure 6. Both rules have a {recover} annotation on their starting literal. Alternatively, the annotation \ncould be placed on the complete production, but this formulation is bene.cial for the runtime behavior \nof our adapted parser implementation, ensuring that the anno\u00adtation is considered before construction \nof the literal. The recovery rules for string literals and comments match either at the end of a line, \nor at the end of the .le as appropri\u00adate, depending on whether newline characters are allowed in the \noriginal, non-recovering productions. In contrast, an al\u00adternative approach would have been to add a \nliteral insertion production for the quote and comment terminator literals. However, by only allowing \nthe strings and comments to be terminated at the ending of lines and the .le, the number of different \npossible interpretations is severely reduced, thus reducing the overall runtime complexity of the recovery. \n 5.4 Combining Different Recovery Rules The water recovery rules of Section 5.2 and the insertion rules \nof Section 5.3 can be combined to form a uni.ed re\u00ad covery mechanism that allows both discarding and \ninsertion of substrings: module Java-15-Permissive imports Java-15-Permissive-WaterOnly Java-15-Permissive-InsertionsOnly \nTogether, the two strategies maintain a .ne balance between discarding and inserting substrings. Since \nthe water-based recovery rules incur additional cost for each water substring, insertion of literals \nwill generally be preferred over discard\u00ading multiple input strings. This ensures that most of the orig\u00adinal \n(or intended) user input is preserved.  5.5 Derivation of Permissive Grammars So far, we only focused \non a particular kind of literals for insertion into the grammar, such as brackets, keywords, and string \nliterals. Still, we need not restrict ourselves to only these particular literals. In principle, any \nliteral in the gram\u00admar is eligible for use in an insertion recovery rule. For many literals, automatic \ninsertion can lead to unintu\u00aditive results in the feedback presented for the user. For ex\u00adample, we don \nt want the editor to suggest to insert a try or synchronized keyword. In those cases, discarding some \nsubstrings instead may be a safer alternative. The decision whether to consider particular keywords for \ninsertion may depend on their semantic meaning and importance [10]. To take this into account, expert \nfeedback on a grammar is vi\u00adtal. Since we have aimed at maintaining language indepen\u00addence of the approach, \nour main focus is on more generic, structure-based properties of the grammar.  In this section we have \nidenti.ed and focused on four different distinct, general classes of literals that commonly occur in \ngrammars: Closing brackets and terminating literals for context-free productions  Opening brackets \nand starting literals for context-free productions  Closing literals that terminate lexical productions \nwhere no newlines are allowed (such as most string literals)  Closing literals that terminate lexical \nproductions where newlines are allowed (such as block comments)  Each has its own particular kind of \ninsertion rule, and each follows its own particular de.nition pattern. By analysis of a grammar, using \nheuristic rules to recognize these patterns, we derive water-based recovery rules and recovery rules \nfor insertions of the above categories. Thereby, our system maintains language independence by providing \na generic, automated approach towards the introduction of recovery rules. Automatically deriving recovery \nrules helps maintain a valid, up-to-date recovery rule set as languages evolve and are extended or embedded \ninto other languages. Particularly, as languages are changed, care must be taken to remove any recovery \nrules from the grammar that are no longer applicable. SDF speci.cations are fully declarative. It is \nthis nature that is essential for automated analysis and transformation of a grammar speci.cation. It \nis not feasible to do so for other syntax formalisms that use semantic actions to construct abstract \nsyntax trees and may maintain state or call external functions (e.g., to determine operator priorities). \nWe formulated a set of heuristic rules for the detection of different production patterns based on our \nexperience with different grammars. For instance, opening bracket and starting literal insertions are \nadded based on the following criteria. First, we only consider context-free productions. Second, the \n.rst and last symbols of the pattern of such a production must be a literal. And last, this literal is \nnot used as the starting literal of any other production. The heuristic rules for the other categories \ninvolve a larger set of conditions. The main characteristic of the sec\u00adond category is that it is based \non starting literals in context\u00adfree productions. We only consider a literal a starting literal if it \nonly ever appears as the .rst part of a production pat\u00adtern in all rules of the grammar. For the third \ncategory, we only consider productions with identical starting and end literals. Finally, for the fourth \ncategory we derive rules for matching starting and ending literals in LAYOUT productions. module Java-15 \n... context-free syntax \"{\" BlockStm* \"}\" -> Block {cons(\"Block\")} \"(\" Expr \")\" -> Expr {bracket} \"while\" \n\"(\" Expr \")\" Stm -> Stm {cons(\"While\")} context-free syntax \"void\" \".\" \"class\" -> ClassLiteral {cons(\"Void\")} \n(Anno | ClassMod)* \"class\" Id ... -> ClassHead {cons(\"ClassHead\")} Figure 10. A selection of context-free \nproductions that ap\u00adpear in the Java grammar. Note that we found that some grammars (notably the Java \ngrammar of [6]) use kernel syntax for LAYOUT productions to more precisely control how comments are parsed. \nThus, we consider both lexical and kernel syntax for the comment\u00adterminating rules. As an example, consider \nthe context-free productions of Figure 10. Looking at the .rst production, and using the heuristic rules \nabove, we can recognize that } quali.es as a closing literal. Likewise, ) satis.es the conditions we \nhave set. By programmatically analyzing the grammar in this fashion, we collected the set of closing \nliteral insertion rules of Figure 9. Note that none of the generated inserted closing literals of Figure \n9 ever occur as an opening literal in the grammar. We only derive rules from brackets that appear in \na balanced fashion with another (possibly different) literal (or a num\u00adber of other literals). Insertions \nof literals that are balanced with another literal can lead to undesired results, since such constructs \ndo not form a clear nesting structure. We make an exception for lexical productions that de.ne strings \nand comments, for which we only derive more restrictive inser\u00adtion rules. From the productions of Figure \n10 we can further derive the { and ( opening literals. In particular, the while key\u00adword is not considered \nfor deriving an opening literal inser\u00adtion rule, since it is not used in conjunction with a closing literal \nin its de.ning production. No set of heuristic rules is perfect. For any kind of heuris\u00adtic, an example \ncan be constructed where it fails. We have en\u00adcountered a number of anomalies that arose from our heuris\u00adtic \nrules. For example, based on our heuristic rules, the Java class keyword is recognized as a closing literal. \n(For nar\u00adrative reasons, we did not include it in Figure 9.) This fol\u00ad lows from the void class literal \nproduction of Figure 10. The class keyword is never used as a starting literal of any pro\u00adduction (as \nseen in the same .gure, not even so for class headings), and therefore satis.es our set of rules. In \nprac\u00adtice, we have found that these anomalies are relatively rare and harmless, or sometimes even bene.cial. \nWe evaluated our set of heuristic rules using Java, Java-SQL, Stratego and Stratego-Java grammars, as \noutlined in Section 7. For these grammars, a total number of respec\u00ad tively 33, 56, 36, and 130 insertion \nrules were generated, along with a constant number of water-based recovery rules as outlined in Figure \n8. The complete set of derived rules is available from [1].  5.6 Customization of Permissive Grammars \nA good error recovery mechanism is not only language inde\u00adpendent, but is also .exible [10]. That is, \nit allows grammar engineers to use their experience with a language to improve recovery capabilities. \nOur system, while remaining within the realm of the standard SDF grammar speci.cation for\u00admalism, delivers \nboth of these properties. Language engi\u00adneers can add their own recovery rules using SDF produc\u00adtions \nsimilar to those shown earlier in this section. Using automatically derived rules may not always lead \nto the best possible recovery for a particular language. Dif\u00adferent language constructs have different \nsemantic meanings and importance. Different languages also may have different points where programmers \noften make mistakes. For exam\u00adple, a common rookie mistake in Stratego-Java is to use [| brackets |] \ninstead of |[ brackets ]|. This may be recov\u00adered from by standard deletion and insertion rules. However, \nthe cost of such a recovery is rather high, since it would in\u00advolve four deletions and two insertions. \nOther alternatives, less close to the original intention of the programmer, might be preferred by the \nrecovery mechanism. Based on this ob\u00adservation, a grammar engineer can add substitution recovery rules \nto the grammar: lexical syntax \"[|\" -> \"|[\" {recover, cons(\"INSERT\")} \"|]\" -> \"]|\" {recover, cons(\"INSERT\")} \nThese rules substitute any occurrence of badly constructed embedding brackets with the correct alternative, \nat the cost of only a single recovery. Similarly, grammar engineers may add recovery rules for speci.c \nkeywords, operators, or even placeholder identi.ers as they see .t to further improve the result of the \nrecovery strategy. Modular De.nition of Customizations It is good practice to separate the generated \nrecovery rules from the customized recovery rules. This way, the generated grammar does not have to be \nadapted and maintained by hand. A separate grammar module can import the generated de.nitions, while \nadding new, handwritten de.nitions. Besides composition, SDF also provides a mechanism for subtraction \nof languages. The {reject} disambiguation an\u00adnotation .lters all derivations for a particular set of \nsym\u00adbols [3]. Using this .lter, it is possible to disable some of the automatically derived recovery \nrules. Consider for example the insertion rule for the class keyword, which arose as an anomaly from \nthe heuristic rules of the previous subsection. Rather than directly removing it from the generated gram\u00admar, \nwe can disable it by extending the grammar with a new rule that rejects this recovery. Figure 11 illustrates \nthis with module Java-15-Permissive-Customized imports Java-15-Permissive exports lexical syntax -> \"class\" \n{reject} ... Figure 11. A customized permissive grammar. i=f(x)+1 ; i=f(x +1); i=f(x) ; i=f( 1); i= (x)+1 \n; i= (x +1); i= x+1; i=f ; i=(x) ; i=x ; i= 1; f(x +1); f(x) ; f( 1); ; Figure 12. Many different interpretations \nof i=f(x)+1; using literal-insertion recovery rules (underlined) and water\u00adbased recovery rules. i= 2; \ni= (2); i = ((2)) ; i = (((2))) ; Figure 13. Insertion of opening brackets creates in.nitely many possible \ninterpretation of expressions. a grammar that imports the generated permissive grammar, and disables \nthe class insertion rule. 6. Parsing Permissive Grammars When all recovery rules are taken into account, \npermissive grammars provide many different interpretations of the same code fragment. As an example, \nFigure 12 shows all possi\u00ad ble interpretations of the string i=f(x)+1;. The alternate interpretations \nare obtained by applying recover productions for inserting parentheses or removing text parts. This small \ncode fragment illustrates the explosion in the number of am\u00adbiguous interpretations when using a permissive \ngrammar. As illustrated in Figure 13, the option of inserting opening brackets even results in an in.nite \nnumber of interpretations. Generalized parsers explore all possible interpretations of a string in parallel. \nAny alternative that does not lead to a valid interpretation is simply discarded, and remaining branches \nmay be .ltered by disambiguation rules. Disam\u00adbiguation can be performed during parsing, or by a post \npro\u00adcessor on the created parse tree. A disambiguation .lter for  void methodX() { if (true) // missing \n{ foo(); } int j=0; while (j < 8) methodY(j++); } Figure 14. An if statement with a missing opening \nbrace, causing the method to be closed at the end of the statement The error is detected at the while \nkeyword. permissive grammars, should prefer branches with the least number of recover productions. Theoretically, \nthe use of productions to specify how to recover from errors provides an excellent mechanism for the \nparsing of erroneous .les. However, from a practical point of view, the extra interpretations created \nby these productions negatively affect time and space requirements. As we have shown above, the combinatorial \npossibilities would grow exponentially, leading to unacceptable overhead on perfor\u00admance. Therefore, \nwe must adapt the parser strategy, to pro\u00adcess the alternatives introduced by the recovery rules. It \nis not practical to consider all recovery interpretations in parallel with the ordinary grammar productions \n(or even impossible as in the case of Figure 13). As an alternative to parsing different interpretations \nin parallel, backtracking LR parsers revisit points of the .le that allow multiple inter\u00adpretations (the \nchoice points). For normal grammars, these parsers are less practical since they exhibit exponential \nbe\u00adhavior in the worst case [17]. As such, we introduce a selec\u00ad tive form of backtracking to GLR parsing \nthat is only used for the concern of error recovery. We ignore all recovery pro\u00adductions during normal \nparsing, and employ backtracking to apply the recovery rules only once an error is detected. 6.1 Selecting \nChoice Points for Backtracking To employ backtracking for applying error recovery rules it is important \nthat the right choice point is selected. In par\u00adticular, simply trying different interpretations at the \npoint of failure is ineffective, especially when considering a scanner\u00adless parser. This is because the \npoint of failure rarely re\u00ad.ects the location of the original error, let alone the point where the error \ncan be repaired. Consider for example the code in Figure 14. Due to the missing opening brace of the \nif-block, the closing brace after the enclosed foo(); state\u00adment is misinterpreted as closing the method. \nAt that point, the parser simply continues, interpreting the remaining state\u00adments as class-body declarations. \nThis causes it to fail at the reserved while keyword, which can only occur inside a method body. More \nprecisely, our scannerless parser fails at the unexpected space after w-h-i-l-e; the character can\u00adnot \nbe shifted and all branches (interpretations at that point) are discarded. The difference between the \npoint of detection and the actual location of the error is a well-known factor that poses a challenge \nfor error recovery techniques [10]. In order to properly recover from non-local errors, they have to \nconsider the text that precedes the point of detection. Backtracking can be used to inspect this text \nin reverse order, starting at the point of detection, gradually moving backwards to the start of the \ninput .le. Using a reverse order helps maintain ef.ciency, since the actual error is most probably near \nthe failure location. As SGLR parses different interpretations in parallel, it uses a more complicated \nstack structure than normal LR parsers. Instead of a single, linear stack, it maintains a graph\u00adstructured \nstack that ef.ciently stores the different interpre\u00adtation branches. As characters are shifted, some \nof these branches may be discarded. This poses a challenge for ap\u00adplying backtracking, since all the \ndiscarded branches must be stored in case the old state is revisited. We found that it is prohibitive \n(in terms of performance) to maintain the com\u00adplete stack state for every shifted character. Therefore, \nwe only selectively record choice points to minimize the over\u00adhead introduced. In the current implementation, \nwe construct a choice point at every new line.  6.2 Applying Recovery Rules Our backtracking algorithm \niteratively explores the input stream in reverse order, starting at the nearest choice point. At each \npoint, different candidate recoveries are attempted and discarded if a valid interpretation is not possible. \nAn in\u00adterpretation is considered valid after the error detection line is parsed. Once a valid candidate \nis selected, normal parsing continues. Permissive grammars typically account for many possible interpretations, \nwhich means that the order of ex\u00adploration determines the .nal result. Generally, corrections that employ \nfewer recover productions are preferred. There\u00adfore, candidate recoveries that use fewer recovery rules \nare selected .rst. With each iteration of the algorithm, different candidate recoveries are explored \nin parallel for a restricted area of the .le and for a restricted number of recovery rule appli\u00adcations. \nFor every following iteration the size of the area and the maximum number of recovery rule applications \nare in\u00adcreased. Figure 15 illustrates a number of iterations of the algorithm for the Java method of \nFigure 14. Figure 15a shows the parse failure after the while key\u00adword. The point of failure is indicated \nby the triangle. The actual error, at the closing brace after the if-block, is shown underlined. The \n.gure shows the different choice points that have been stored during parsing using circles in the left \nmar\u00adgin. The .rst iteration of the algorithm (Figure 15b) focuses on the line where the parser failed. \nThe parser is reset to the choice point at the start of the line, and enters recovery mode. At this point, \nonly candidate recoveries that use one recovery production are considered; alternative interpretations \nformed by a second recover production are cut off. Their exploration is postponed until the next iteration. \nThe .gure visualizes the search space using boxed lines with a number indicating the amount of recovery \nrules that may be applied. In this example scenario, the .rst iteration does not lead to a valid solution. \n  For the next iteration, in Figure 15c, the search space is expanded with respect to the size of the \ninspected area and the number of recovery rules that may be applied. The new search space consist of \nthe line that precedes the point of detection, plus the error detection line where recovery candidates \nwith two rules are now also considered. For the latter, interpretations that were previously cut off \ncan now be resumed. In Figure 15d, the search space is again expanded to in\u00ad spect the line where the \nerror was detected and the two pre\u00adceding lines. This time, a valid recovery is found: discard\u00ading the \nclosing brace, by application of a water-based recov\u00adery rule, leads to a valid interpretation of the \nerroneous code fragment. Rather than a purely backtracking-based approach, we use a parallel search for \nrecovery candidates with each back\u00adtracking step. Ordering of recovery candidates is only im\u00adposed by \nthe different iterations of the backtracking algo\u00adrithm. This means that in some cases more than one \nvalid re\u00adcovery candidate is identi.ed. In this case we pick the candi\u00addate with the smallest number \nof recovery rule applications, or pick an arbitrary candidate if multiple candidates have the same number \nof applications.  6.3 Implementation The implementation of the recovery algorithm requires a number \nof (relatively minor) modi.cations of the SGLR algorithm used for normal parsing. Firstly, productions \nmarked with the {recover} attribute are ignored during normal parsing. Secondly, a choice point is stored \nfor every newline character. And thirdly, if all branches are discarded and no accepting state is reached, \nthe parser enters recov\u00adery mode. Once the recovery is successful, normal parsing resumes with a newly \nconstructed stack. Figure 16 shows pseudo code for the recovery algorithm. The Recover function controls \nthe iterative search process described in Section 6.2. The function starts with some ini\u00ad tial con.guration \n(lines 3-5): it enables the recovery produc\u00adtions that are ignored in normal parsing mode, selects the \nmost recent choice point, and initializes the candidates variable. The choice points from the point of \nfailure are then visited in reverse order (lines 6-10). Candidates for the current choice point are collected \nand explored using the RecoverParse function (line 7), until .nally a valid inter\u00adpretation is found \n(line 10). The RecoverParse function tries to construct a valid in\u00adterpretation by reparsing the area \nstarting from the choice point and revisiting recovery candidates that were previously cut off. Each \niteration resets the parser to the previous state stored for the choice point (lines 20-21). It consumes \nchar\u00adacters from the choice point location until the original point of failure is reached (lines 23-32). \nBy parsing the area again, any previously cut off candidate stacks are explored further and new candidates \ncan be collected. For each character, the stack states of candidates at that point are merged with the \ncurrent stack (line 25-27). As such, the revisited candi\u00addate recoveries are processed in parallel, using \nthe standard SGLR parser (line 28), but with the recovery rules enabled. At that point, any new stack \nbranches created using recov\u00adery rules are excluded from further exploration and stored to  RECOVER(sglr) \n1 [ Input: sglr -SGLR parser 2 3 sglr.ignoreRecoverProductions . False 4 choicePoint . Last inserted \nchoicePoint 5 candidates . Initialize list 6 do 7 candidates . RECOVERPARSE( 8 sglr, candidates, choiceP \noint) 9 choicePoint . Previous choicePoint 10 until sglr.stacks not empty 11 sglr.ignoreRecoverProductions \n. True RECOVERPARSE(sglr, candidates, choiceP oint) 12 [ Input: 13 sglr -SGLR parser 14 candidates -Unexplored \nrecover branches with 15 associated location, created on previous loop 16 choicePoint -Start location \nfor recover parse 17 [ Output: New candidates created 18 by one extra recover production 19 20 sglr.stacks \n. choicePoint.stacks 21 sglr.streamLocation . choicePoint.streamLocation 22 newCands . Initialize list \n23 while sglr.streamLocation = sglr.failureLocation 24 do 25 locCands .{ c | c in candidates and 26 c.streamLocation \n= sglr.streamLocation }27 sglr.stacks . sglr.stacks . locCands 28 sglr.parseCharacter() 29 createdCands \n. stacks created by 30 recover production 31 sglr.stacks . sglr.stacks / createdCands 32 newCands . newCands \n. createdCands 33 return newCands Figure 16. The recovery algorithm. be revisited in the next iteration \n(line 31-32). The algorithm ends once the character at the point of failure can be suc\u00adcessfully parsed. \nThe parser then resumes in normal parsing mode (line 11) using the newly constructed stack. 7. Evaluation \nWe add error recovery to a parser to improve the user expe\u00adrience. This is particularly important in \nan interactive envi\u00adronment where many editor services depend on proper parse error recovery, as opposed \nto batch use. With this in mind, we have focused the evaluation of our approach on the fol\u00adlowing criteria: \n Quality of Recovery: recovery should be as close as possible to the intention of the user. A bad recovery \nmay introduce spurious errors and lead to misleading error feedback.  Performance of the parser, with \nregards to parse time and space, is important and should not disturb the work .ow of the user. A signi.cant \nfactor in interactive scenar\u00adios is that parser input will, more often than not, contain errors.  Quality \nof Feedback: good error feedback should point out an error as accurately as possible and also give good \nsuggestions on possible corrections. Quality of feedback depends on quality of recovery.  Language Independence \nand Flexibility: the recovery solution should be independent of a particular language, yet should be \ncustomizable to the needs and insights of language designers.  Transparency: it should be clear why \na particular recov\u00adery is presented. The language designer should have in\u00adsight into how the recovery \nworks for a given grammar.  As a basis for testing we have used a set of automatically derived, permissive \ngrammar variants for Java, Java-SQL, Stratego and Stratego-Java. For each language we have tested the \nfollowing permissive variants: Water (W), Inser\u00adtion of close (C), W + C, C + Insertion of open (O) and \nW + C + O, along with standard grammars for comparison. These grammars have been tested on a set of sample \n.les taken from the following projects: The JUnit framework: A library for de.ning unit tests [15], \nproviding Java 1.5 code used to test the Java grammars.  The Dryad compiler: An open compiler for the \nJava platform [19], providing Stratego and Stratego-Java code which we use to test both the Stratego \nand Stratego-Java grammars.  The StringBorg project: A tool and grammar suite that de.nes different \nembedded languages [4], provid\u00ad ing Java-SQL code used to test the Java-SQL grammars.  Code from these \nprojects provide correct samples which we use to test the parser performance for syntactically correct \n.les. We introduced errors to the samples to simulate editing scenarios that result in syntactically \nerroneous code. These error samples are used to test performance and quality of recovery in the presence \nof syntactical errors. Both the development of a representative error sample suite and its evaluation \nhave been a challenging task. There are many factors involved: the type of error, type of gram\u00admar, locations \nof errors, etc. For example, the distribution of errors has an impact on time spent in recovery and the \nnum\u00adber of recoveries triggered. Clustered errors are expected to trigger fewer recoveries compared to \nscattered errors. Still, the actual runtime behavior of the parser remains hard to Missing Close Missing \nOpen Missing Delim predict.  100 To evaluate the recovery quality we have opted to focus 80 on single \nerrors. For error performance we also focus on 60 % of Errors % of Errors small sets of clustered errors, \nas these have a large impact on 40 the runtime behavior. All measures related to time have been 20 collected \nas averages after several runs, using a pre-heated 0 JVM. All .gures shown in this paper should be considered \nas preliminary with the purpose of showing the effectiveness W C WC CO WCO W C WC CO WCO W Changed WCWCO \nC CO Added Close Added Delim of our approach, not as a part of an in-depth study. 100 80 60 40 20 7.1 \nQuality of Recovery For the evaluation of recovery quality we .rst measure the tree alignment distance \n[16], i.e., comparing the reference AST to ASTs obtained through recovery. This is one possi\u00ad 0 W C WC \nCO WCO W C WC CO WCO W C WC CO WCO ble way to get a number on the difference of two trees as op\u00adposed \nto, e.g, running diffs on pretty printed ASTs and mea\u00adsure number of lines. The reference AST is obtained \nfrom a correct sample .le, while the recovered ASTs are created from the error samples, following [28]. \nGiven the tree distances we study recoveries in more de- Distance =0 Distance > 0 Failed to parse \nFigure 17. Distance: each diagram shows results for one error type and the following grammar variants; \nW, C, WC, tail in cases where the distance is larger than zero. We label CO and WCO. Each bar shows for \nwhat percentage the the quality of a recovery as either poor, good or excellent, as distance was equal \nto zero, larger than zero or parsing failed. suggested by Pennello and DeRemer [30], also used in the \nW -Water, C -Insertion of close, O -Insertion of open. comparative study of Degano and Priami [10]. A \ntree align\u00ad ment distance equal to zero indicates an excellent recovery while a larger distance indicates \na poor or good recovery. Poor recoveries are recoveries that introduce spurious errors (as observed through \nmanual inspection of the parse result). We study the permissive grammars for Stratego-Java in more detail \nfor sample .les containing one error. The set of error samples capture six different types of errors: \nMissing Close and Added Close: ), }, >, ], ]\\!|, or */ Missing Open: (, {, or |[  Missing Delim and \nAdded Delim: ; or ,  Changed order of symbols: [| instead of |[, or |] instead  S W C WC CO WCO Figure \n18. Quality of recovery using various grammars for Stratego-Java. Each bar shows for what percentage \nrecovery of ]| was excellent, good, poor or parsing failed. S -Standard Figure 17 shows distance results \nper error and grammar type, while Figure 18 shows the quality of recoveries as a percentage of the whole \nerror set. Figure 18 shows that the standard grammar fails to parse all inputs (as expected), and that \nmost of the permissive grammar succeed in parsing the complete set. An exception is the C variant which \nonly manages to recover form a subset of all errors. The combined variants WC, CO and WCO even get excellent \nrecoveries for a majority of cases. The diagram in Figure 17 shows the effect of using a grammar variant \non different error types. For the W variant we see that it is robust but gives large distances, with \nthe exception of the added delimiter cases. The C variant, on the other hand, is less robust but gives \nexcellent recoveries for a majority of the missing close cases. The O variant is grammar, W -Water, C \n-Insertion of close, O -Insertion of open. not tested separately, but we see that it provides excellent \nrecoveries for a majority of the missing open cases when it is included in a combination.  7.2 Parsing \nPerformance For evaluation of parsing performance we focus on parse time. Space is also of interest but \nnot addressed in this paper. As mentioned earlier, a parser used in an interactive scenario should not \nslow down the work .ow of the user. Adding recovery to a parser will potentially give overhead with regard \nto time and space.  Non-error Performance Recovery Time  One Two Three Figure 20. Recovery time for \nsamples with one, two or three errors, using the Stratego-Java W+C grammar vari\u00adant (water and closing-literal \ninsertion). Each bar shows for what percentage recovery time is less than 10 ms, 100 ms, Java-SQL, Stratego \nand Stratego-Java grammars. Values 1 s or greater than 1 s. show time percentage compared to a standard \ngrammar for each corresponding language. W -Water, C -Insertion of close and O -Insertion of open. One \nTwo Three Note that the current implementation of JSGLR is still in active development and has not been \noptimized. Particularly, algorithmic optimizations such as SRNGLR [12] have not been integrated yet, \nand an overuse of object allocations and 05 05 05 Recoveries wrapper objects currently causes a lack \nof memory locality and increase in heap usage. We are interested in the performance overhead of using \npermissive production rules on both correct and erroneous input. Figure 19 shows non-error parse time, \ni.e. the average parse time for permissive grammars in relation to the stan\u00addard grammar for each language. \nWe observe that the over\u00adhead varies between variants and languages. The W variant gives more or less \nthe same overhead independent of lan\u00adguage, while the C variant gives the best performance for all languages, \neven better performance in two cases. An important property of any parser used in an interactive environment \nis its ability to handle erroneous input. Using the WC grammar for Stratego-Java, which gives us the \nbest balance between quality and performance, we measure how much additional time that is needed to parse \n.les with one, two, or three errors. The results are shown in Figure 20. The .gure shows that the amount \nof time spent in recovery increases with the number of clustered errors. This is the expected result \nsince clustered errors are bound to trigger more recoveries. The diagram in Figure 21 shows us that the \nnumber of er\u00ad rors in a sample will result in an equal number of recoveries for a majority of the cases. \nFor occasional errors, clustered and single, recovery time can exceed 1 second. The percent\u00adage increases \nwith the number of clustered errors. There are some pathological cases for which an additional strategy \nis required to avoid overly long parse times. This is further ad\u00addressed in Section 7.3. Figure 21. Recovery \ncount for one, two and three errors using the Stratego-Java W+C grammar variant, i.e., water and insertion \nof close.  7.3 Recovery from Pathological Cases A good error recovery strategy maintains a .ne balance \nbe\u00adtween response time and the quality of a recovery. Based on our test set, we have recognized that \nthere are certain patho\u00adlogical cases where the complete recovery rule set takes too long to .nd a proper \nrecovery. Through experimentation, we found that these pathologi\u00adcal cases arise seldomly and are hard \nto predict or recognize. They only occur for particular combinations of syntax er\u00adrors and surrounding \ncontext. To avoid slow response due to long-running recovery attempts, we abort attempts that take more \nthan a set amount of time. We speculate that these cases arise from a combination of syntax errors that \ncan only be resolved by a multitude of recovery operations and the presence of particularly liberal productions \nin the base grammar. For instance, string literals in Stratego may contain any character, including newlines, \nexcept an unescaped closing quote. Any unterminated string literal, or a string literal that has been \npartially discarded by a water-based recovery rule, can greatly increase the possible number of interpretations \nof an input .le, i.e., almost any character in the remainder of the .le could be part of the string (or \nnot).  Successful error recovery typically combines multiple strategies, using a secondary strategy \nif the .rst does not suf.ce [10]. In order to still provide feedback for the patho\u00ad logical cases, such \na secondary strategy can be used. This strategy should focus purely on performance, not quality of recovery. \nWe have identi.ed three viable secondary strate\u00adgies for error recovery with SGLR. The .rst approach \nis simply to abort the current recovery attempt and report all offending characters encountered so far. \nWith this approach, it is not possible to recover a partial AST, but the user is still presented with \nfeedback of errors up to the point of where the parser is aborted. A second fall-back strategy is to \nconstruct a partial parse tree based on the reductions performed by the parser so far. This approach \nis described in [36], where a standard, unaltered SDF grammar is used. The available syntax tree at the \npoint of abortion is combined with remaining parts of the .le to create a partial parse result. Finally, \na third fall-back strategy is to con.ne errors to se\u00adlected regions of code. Each region can constrain \nthe search space used to recover from errors in that region. If recov\u00adery is not possible within a set \ntime limit, an entire region can be discarded. Regions that enclose syntax errors may be detected using \ncoarse-grained, water-based recovery gram\u00admars similar to those discussed in Section 5.1. These gram\u00ad \nmars parse any of the pathological cases almost as quickly as a non-erroneous input, identifying and \nskipping over erro\u00adneous regions of code. In ongoing experimentation we have also seen good results in \nusing indentation and the SGLR graph-structured stack to identify regions while parsing. We plan to re.ne \nthese strategies in future work.  7.4 Interactive Editing and Error Reporting A parser used in an interactive \nscenario should provide a user with good error feedback. Perhaps, just as important is the placement \nof error markers ( squiggles ) in the editor. Our current implementation does this based on the layout \nof the source code, as illustrated in Figure 22. From the screen shot we can gather that the editor shows \nseveral errors, due to successful recovery. The .rst and the second errors are recovered by a literal-insertion \nrule, while the third error has been recovered using the water-based re\u00adcovery rule. We also observe \nthat errors are detected cor\u00adrectly in both Stratego and embedded Java. Due to the different characteristics \nof the error recovery rules, described in Section 5.5, we use different error mes\u00ad sages based on the \nconstructor of the recovery rule: WATER rules: [string] not expected.  INSERT rules: [string] expected. \nThe placement of the error marker is particularly important in this case. For constructs with an opening \nand closing literal, this should be at the same level of indentation as the other literal.  INSERTEND \nrules: construct not terminated. High\u00adlights entire construct from start to end.  Syntax highlighting \nin Spoofax/IMP is implemented in a scannerless fashion [20]. This means that the parse tree is used for \ncolorization, rather than the token stream. This makes it important that a proper parse tree is available \nat all times. Our experience shows us that even when interactively editing a program, the coloring remains \nconsistent. However, since highlighting is based on successful parsing of a string, any erroneous segments \nof code that have been discarded cannot use keyword highlighting. Compared to hand-written parsers, which \nare commonly used in interactive editing, our error reports tend to be of a more generic nature. For \nexample, for an unterminated string, our editor gives a generic message construct not terminated instead \nof a language-speci.c message string literal not terminated.  7.5 Language Independence and Flexibility \nThe permissive grammars we evaluated in this section were automatically constructed using the heuristic \nrules described in Section 5.5, showing that the approach works indepen\u00ad dently of a particular language. \nYet by using derived recov\u00adery rules, speci.ed as normal SDF productions, transparency is maintained. \nIn Section 5.6 we discussed the customizability of derived grammars; additional recovery rules can be \nadded and unde\u00adsired rules can be removed to improve the recovery quality. Based on the results of a \ntest set as we constructed for our evaluation, permissive grammars can be manually tuned in order to \nimprove the results.  8. Related Work The SGLR parser, implementing the scannerless general\u00adized-LR \nalgorithm, previously lacked any form of error re\u00adcovery, limited to reporting only the character and \nlocation at the point of a parse failure. However, there has been some exploratory work on the subject \nby Valkering [36]. Valkering enhances the standard SGLR error reports with information based on the current \nstack at the point where an error occurs, reporting the set of possible strings that could be inserted \nat that point. Providing good feedback this way is non-trivial since scannerless parsing does not employ \ntokens; often it is only possible to report a set of expected characters instead. Furthermore, these \nerror reports are still biased with respect to the location of errors; because of the scannerless, general\u00adized \nnature of the parser, the point of failure rarely is a good indication of the actual location of a syntactic \nerror. In con\u00adtrast, our error reporting strategy is based on the notions of backtracking and considering \nleast-cost error recovery pro\u00adductions to determine the most likely cause of the error in the context. \nUsing arti.cial reduce actions, Valkering constructs a par\u00adtial parse tree that precedes the point of \nfailure. Furthermore, he constructs partial parse trees for the fragments that follow an error using \nsubstring parsing, introduced by Rekers and Koorn [31]. Based on these partial parsing techniques, the \nresult of the parser is a set of (often highly ambiguous) par\u00adtial parse trees. In our approach, a single, \nwell-formed parse tree is constructed instead. Lavie and Tomita developed GLR*, a noise skipping al\u00adgorithm \nfor context-free grammars [25]. Based on traditional GLR with a scanner, their parser determines the \nmaximal subset of all possible interpretations of a .le by systemat\u00adically skipping selected tokens. \nThe parse result with the fewest skipped words is then used as the preferred interpre\u00adtation. In principle, \nthe GLR* algorithm could be adapted to be scannerless, skipping characters rather than tokens. How\u00adever, \ndoing so would lead to an explosion in the number of interpretations. In our approach, we restrict these \nby using backtracking to only selectively consider the alternative in\u00adterpretations, and using water-based \nrecovery rules that skip over chunks of characters. Furthermore, our approach sup\u00adports insertions in \naddition to discarding noise and provides more extensive support for reporting errors. Island Grammars \nThe basic principles of our permissive grammars are based on the water productions from island grammars. \nIsland grammars [39, 26] have traditionally been used for different reverse and re-engineering tasks. \nFor cases where a baseline grammar is available (i.e., a complete grammar for some dialect of a legacy \nlanguage), Klusener et al [22] present an approach of deriving tolerant grammars. Based on island grammars, \nthese are partial grammars that contain only a subset of the baseline grammar s productions, and are \nmore permissive in nature. Unlike our permissive grammars, tolerant grammars are not aimed at application \nin an interactive environment. They do not support the notion of reporting errors, and, like parsing \nwith GLR*, are limited to skipping content. Our approach supports recovery rules that insert missing \nliterals and provides an extended set of error reporting capabilities. More recently, island grammars \nhave also been applied to parse composite languages. Synytskyy et al [34] composed island grammars for \nmultiple languages to parse only the in\u00adteresting bits of an HTML .le (e.g., JavaScript fragments and \nforms), while skipping over the remaining parts. In con\u00adtrast, we focus on composite languages constructed \nfrom complete constituent grammars. From these grammars we construct permissive grammars that support \ntolerant parsing for complete, composed languages. Error Handling and Recovery in Other Parsers There \nare several different forms of error recovery techniques for LR parsing [10]. These techniques can be \ndivided in correct\u00ading and non-correcting techniques. The most common non\u00adcorrecting technique is panic \nmode. On detection of an er\u00adror, the input is discarded until a synchronization token is reached. Then, \nstates are popped from the stack until the state at the top enables the resumption of the parsing pro\u00adcess. \nPanic mode does not provide a proper diagnosis of the error and may skip large fragments of an input. \nCorrecting methods try to improve on this by attempting to correct the .awed part of the input string. \nCorrecting methods for LR parsers typically attempt to insert or delete tokens nearby the location of \nan error, until parsing can resume. Successful re\u00adcovery mechanisms often combine more then one technique. \nFor example, panic mode is often used as a fall back method if the correction attempts fail. While our \napproach to error recovery follows along the same lines as is common to general correcting methods, there \nare also two signi.cant differences due to the nature of SGLR. Other error reporting methods use tokens \nfor re\u00adporting parse errors. Lacking tokens, our method is based on the identi.cation of errors such \nas missing literals through parsing with the recovery production rules. GLR parsing also introduces \nthe notion of multiple branches that are processed in parallel. Parse errors can only be identi.ed by \na failure of the last remaining branch, which may not be local to the actual root cause of an error. \nWhile other ap\u00adproaches can simply identify the offending token, we apply backtracking to track back \nto the offending point in the code. An alternative approach to scannerless parsing is used for parsing \nexpression grammars (PEGs) [14]. The class of lan\u00ad guages PEGs can express has no relation to the context-free \ngrammars supported by SDF: instead of the commutative choice (|) operator, PEGs use an ordered choice \n(/). PEGs lack the explicit disambiguation facilities [3] that SDF pro\u00ad vides for SGLR, and instead use \nordered choice to enforce an ordering of production alternatives, combined with greedy matching. To our \nknowledge, no automated form of error re\u00adcovery has been de.ned for PEGs. However, based on the ordering \nproperty, a catch all clause is sometimes added to productions, which is used if no other alternative \nsucceeds. Such a clause can be used to skip erroneous content up to a speci.c point (such as a newline) \nbut does not offer the .exibility of our approach.  IDE support for composite languages We integrated \nour recovery approach into the Spoofax/IMP [20] language de\u00ad velopment environment. A related project, \nalso based on SDF and SGLR, is the Meta-Environment [37, 38]. It cur\u00ad rently does not employ interactive \nparsing, and only parses .les after a save action from the user. Using the traditional SGLR implementation, \nit also provides no error recovery. Another language development environment is Monti-Core [23, 24]. \nBased on ANTLR [29], it uses traditional LL(k) parsing. As such, MontiCore offers only limited sup\u00adport \nfor language composition and modular de.nition of languages. Combining grammars can cause con.icts at \nthe context-free or lexical grammar level. For example, any key\u00adword introduced in one part of the language \nis automati\u00adcally recognized by the scanner as a keyword in another part. MontiCore supports a restricted \nform of embedded lan\u00adguages through run-time switching to a different scanner and parser for certain \ntokens. Using the standard error recovery mechanism of ANTLR, it can provide error recovery for the constituent \nlanguages. However, recovery from errors at the edges of the embedded fragments (such as missing quota\u00adtion \nbrackets), is more dif.cult using this approach. This is\u00adsue is not addressed in the papers on MontiCore \n[23, 24]. In contrast to MontiCore, our approach is based on scan\u00adnerless generalized-LR parsing, which \nsupports the full set of context-free grammars, and allows composition of gram\u00admars without any restrictions. \n9. Conclusion The SDF formalism allows for the speci.cation and com\u00adposition of modular, declarative \nlanguage de.nitions. Parse error recovery for parsing SDF grammars with SGLR has previously been identi.ed \nas an open issue. In this paper, we presented a .exible, language-independent approach to error recovery \nto resolve this issue. The three pillars of our work have been to use standard SDF productions to specify \nerror recovery rules; to derive such error recovery rules from SDF grammars; and to adapt the SGLR parser \nto ef.ciently cope with the added complexity of grammars with recovery rules. Using these techniques, \nwe can support rapid syntactic and semantic feedback for compositional languages as programs are edited. \nWe evaluated our approach using a set of existing, non\u00adtrivial grammars, showing a low performance overhead \nin case there are no syntax errors, and acceptable (although at times unpredictable) overhead in case \nof inputs with errors. The results also show that our approach achieves excellent recovery quality in \na majority of the cases. Our backtracking algorithm employs a growing search space and a heuristic approach \nto systematically explore dif\u00adferent possible recoveries in case of an error. We expect that in the future \nwe can further tune the weights of the different factors that play a role in this process to provide \nmore intu\u00aditive recoveries. For example, while any single insertion may be preferred to discarding a \nsubstring (as suggested in [10]), larger clusters of insertions are often less desirable and harder \nto identify in a growing search space than discard\u00ading longer substrings. Overall, we expect to improve \nboth the performance and quality through ongoing experimenta\u00adtion and evaluation. Acknowledgements This \nresearch was supported by NWO/JACQUARD projects 612.063.512, TFA: Transforma\u00adtions for Abstractions, \nand 638.001.610, MoDSE: Model-Driven Software Evolution. This work would not have been possible without \nthe efforts of Karl Trygve Kalleberg, whose Java implementation of SGLR has been invaluable for the present \nwork and the integration of SGLR into the Eclipse environment. We thank Mark van den Brand, Martin Braven\u00adboer, \nGiorgios Rob Economopoulos, Jurgen Vinju, and the rest of the SDF/SGLR team for their work on SDF. References \n[1] The permissive grammars project. http://strategoxt. org/Stratego/Permissive-Grammars, 2009. [2] M. \nG. J. van den Brand, H. de Jong, P. Klint, and P. Olivier. Ef.cient annotated terms. Software, Practice \n&#38; Experience, 30(3):259 291, 2000. [3] M. G. J. van den Brand, J. Scheerder, J. Vinju, and E. Visser. \nDisambiguation .lters for scannerless generalized LR parsers. In N. Horspool, editor, Compiler Construction \n(CC 2002), volume 2304 of Lecture Notes in Computer Science, pages 143 158. Springer-Verlag, 2002. [4] \nM. Bravenboer, E. Dolstra, and E. Visser. Preventing injection attacks with syntax embeddings. A host \nand guest language independent approach. In J. Lawall, editor, Generative Programming and Component Engineering \n(GPCE 2007), pages 3 12. ACM, 2007. [5] M. Bravenboer, K. T. Kalleberg, R. Vermaas, and E. Visser. Stratego/XT \n0.17. A language and toolset for program transformation. Science of Computer Programming, 72(1\u00ad2):52 \n70, 2008. [6] M. Bravenboer, E. Tanter, and E. Visser. Declarative, formal, and extensible syntax de.nition \nfor AspectJ. A case for scannerless generalized-LR parsing. In W. R. Cook, editor, Object-Oriented Programing, \nSystems, Languages, and Applications (OOPSLA 2006), pages 209 228. ACM, 2006. [7] M. Bravenboer and E. \nVisser. Concrete syntax for objects. Domain-speci.c language embedding and assimilation without restrictions. \nIn D. C. Schmidt, editor, Object-Oriented Programing, Systems, Languages, and Applications (OOPSLA 2004), \npages 365 383. ACM, 2004.  [8] P. Charles, R. M. Fuhrer, and S. M. Sutton, Jr. IMP: a meta-tooling platform \nfor creating language-speci.c IDEs in Eclipse. In R. E. K. Stirewalt, A. Egyed, and B. Fischer, editors, \nAutomated Software Engineering (ASE 2007), pages 485 488. ACM, 2007. [9] P. Charles, R. M. Fuhrer, S. \nM. Sutton, Jr., E. Duesterwald, and J. Vinju. Accelerating the creation of customized, language-speci.c \nIDEs in Eclipse. In G. T. Leavens, editor, Object-Oriented Programing, Systems, Languages, and Applications \n(OOPSLA 2009). ACM, 2009. [10] P. Degano and C. Priami. Comparison of syntactic error handling in LR \nparsers. Software Practice and Experience, 25(6):657 679, 1995. [11] S. Ducasse, O. Nierstrasz, N. Sch\u00a8arli, \nR. Wuyts, and A. Black. Traits: A mechanism for .ne-grained reuse. Transactions on Programming Languages \nand Systems (TOPLAS), 28(2):331 388, 2006. [12] G. Economopoulos, P. Klint, and J. Vinju. Faster scannerless \nGLR parsing. In O. de Moor and M. I. Schwartzbach, editors, Compiler Construction (CC 09), pages 126 \n141. Springer-Verlag, 2009. [13] S. Efftinge et al. openArchitectureWare User Guide. Version 4.3. Available \nfrom http://openarchitectureware. org/pub/documentation/, 2008. [14] B. Ford. Packrat parsing: Simple, \npowerful, lazy, linear time. In International Conference on Functional Programming (ICFP 02), volume \n37 of SIGPLAN Notices, pages 36 47. ACM, October 2002. [15] E. Gamma and K. Beck. JUnit: A cook s tour. \nJava Report, 4(5):27 38, 1999. [16] T. Jiang, L. Wang, and K. Zhang. Alignment of trees -an alternative \nto tree edit. In CPM 94: Proceedings of the 5th Annual Symposium on Combinatorial Pattern Matching, volume \n807 of LNCS, pages 75 86, London, UK, 1994. Springer-Verlag. [17] A. Johnstone, E. Scott, and G. Economopoulos. \nGeneralised parsing: Some costs. Lecture Notes in Computer Science, 2985:89 103, 2004. [18] K. T. Kalleberg. \nJSGLR. http://www.spoofax.org/. [19] L. C. L. Kats, M. Bravenboer, and E. Visser. Mixing source and bytecode. \nA case for compilation by normalization. In G. Kiczales, editor, Object-Oriented Programing, Systems, \nLanguages, and Applications (OOPSLA 2008), pages 91 108. ACM, 2008. [20] L. C. L. Kats, K. T. Kalleberg, \nand E. Visser. Domain\u00adspeci.c languages for composable editor plugins. In T. Ekman and J. Vinju, editors, \nLanguage Descriptions, Tools, and Applications (LDTA 2009), ENTCS. Elsevier Science Publishers, 2009. \n[21] G. Kiczales, J. Lamping, A. Menhdhekar, C. Maeda, C. Lopes, J.-M. Loingtier, and J. Irwin. Aspect-oriented \nprogramming. In M. Aks\u00b8it and S. Matsuoka, editors, Proceedings of the European Conference on Object-Oriented \nProgramming (ECOOP 07), volume 1241 of LNCS, pages 220 242. Springer, 1997. [22] S. Klusener and R. L\u00a8ammel. \nDeriving tolerant grammars from a base-line grammar. In International Conference on Software Maintenance \n(ICSM 03), pages 179 189. IEEE Computer Society, 2003. [23] H. Krahn, B. Rumpe, and S. V\u00a8olkel. Ef.cient \neditor genera\u00adtion for compositional DSLs in Eclipse. In Proceedings of the 7th OOPSLA Workshop on Domain-Speci.c \nModeling, tech\u00adnical report TR-38, pages 218 228. University of Jyv\u00a8askyl\u00a8a, 2007. [24] H. Krahn, B. \nRumpe, and S. V\u00a8olkel. Monticore: Modular de\u00advelopment of textual domain speci.c languages. In R. Paige \nand B. Meyer, editors, TOOLS EUROPE 2008, volume 11 of Lecture Notes in Business Information Processing, \npages 297 315. Springer-Verlag, June 2008. [25] A. Lavie and M. Tomita. GLR*-an ef.cient noise skipping \nparsing algorithm for context free grammars. In Third International Workshop on Parsing Technologies, \npages 123 134, 1993. [26] L. Moonen. Generating robust parsers using island grammars. In Working Conference \non Reverse Engineering (WCRE 01), pages 13 22. IEEE Computer Society Press, Oct 2001. [27] L. Moonen. \nLightweight impact analysis using island grammars. In Proceedings of the 10th IEEE International Workshop \nof Program Comprehension, pages 219 228. IEEE Computer Society, 2002. [28] E. Nilsson-Nyman, T. Ekman, \nand G. Hedin. Practical scope recovery using bridge parsing. In D. Gasevic, R. L\u00a8ammel, and E. V. Wyk, \neditors, Software Language Engineering (SLE 2008), volume 5452 of LNCS, pages 95 113. Springer, 2008. \n[29] T. Parr and R. Quong. ANTLR: A predicated-LL(k) parser generator. Software: Practice and Experience, \n25(7):789 810, 1995. [30] T. J. Pennello and F. DeRemer. A forward move algorithm for LR error recovery. \nIn Principles of programming languages (POPL 78), pages 241 254. ACM, 1978. [31] J. Rekers and W. Koorn. \nSubstring parsing for arbitrary context-free grammars. SIGPLAN Not., 26(5):59 66, 1991. [32] D. Salomon \nand G. Cormack. The disambiguation and scannerless parsing of complete character-level grammars for programming \nlanguages. Technical report, Technical Report 95/06, Department of Computer Science, University of Manitoba, \nWinnipeg, Canada, 1995. [33] D. J. Salomon and G. V. Cormack. Scannerless NSLR(1) parsing of programming \nlanguages. SIGPLAN Not., 24(7):170 178, 1989. [34] N. Synytskyy, J. Cordy, and T. Dean. Robust multilingual \nparsing using island grammars. In Proceedings of the 2003 conference of the Centre for Advanced Studies \non Collaborative research, pages 266 278. IBM Press, 2003. [35] M. Tomita. Ef.cient Parsing for Natural \nLanguage: A Fast Algorithm for Practical Systems, volume 14. Kluwer Academic Publishers, 1988.  [36] \nR. Valkering. Syntax error handling in scannerless general\u00adized LR parsers. Master s thesis, University \nof Amsterdam, 2007. [37] M. G. J. van den Brand, M. Bruntink, G. R. Economopoulos, H. A. de Jong, P. \nKlint, T. Kooiker, T. van der Storm, and J. J. Vinju. Using the Meta-Environment for maintenance and \nrenovation. In The European Conference on Software Maintenance and Reengineering (CSMR 07), pages 331 \n332. IEEE Computer Society, 2007. [38] M. G. J. van den Brand, J. Heering, P. Klint, and P. A. Olivier. \nCompiling language de.nitions: the ASF+SDF compiler. ACM Trans. Program. Lang. Syst., 24(4):334 368, \n2002. [39] A. van Deursen and T. Kuipers. Building documentation generators. In IEEE International Conference \non Software Maintenance (ICSM 99), page 40. IEEE Computer Society, 1999. [40] E. Visser. Scannerless \ngeneralized-LR parsing. Technical Report P9707, Programming Research Group, University of Amsterdam, \n1997. [41] E. Visser. Syntax De.nition for Language Prototyping. PhD thesis, University of Amsterdam, \n1997. [42] D. Waddington and B. Yao. High-.delity C/C++ code transformation. Sci. Comput. Program., 68(2):64 \n78, 2007.    \n\t\t\t", "proc_id": "1640089", "abstract": "<p>Integrated development environments (IDEs) increase programmer productivity, providing rapid, interactive feedback based on the syntax and semantics of a language. A heavy burden lies on developers of new languages to provide adequate IDE support. Code generation techniques provide a viable, efficient approach to semi-automatically produce IDE plugins. Key components for the realization of plugins are the language's grammar and parser. For embedded languages and language extensions, constituent IDE plugin modules and their grammars can be combined. Unlike conventional parsing algorithms, scannerless generalized-LR parsing supports the full set of context-free grammars, which is closed under composition, and hence can parse language embeddings and extensions composed from separate grammar modules. To apply this algorithm in an interactive environment, this paper introduces a novel error recovery mechanism, which allows it to be used with files with syntax errors -- common in interactive editing. Error recovery is vital for providing rapid feedback in case of syntax errors, as most IDE services depend on the parser from syntax highlighting to semantic analysis and cross-referencing. We base our approach on the principles of island grammars, and derive permissive grammars with error recovery productions from normal SDF grammars. To cope with the added complexity of these grammars, we adapt the parser to support backtracking. We evaluate the recovery quality and performance of our approach using a set of composed languages, based on Java and Stratego.</p>", "authors": [{"name": "Lennart C.L. Kats", "author_profile_id": "81381609357", "affiliation": "Delft University of Technology, Delft, Netherlands", "person_id": "P1728803", "email_address": "", "orcid_id": ""}, {"name": "Maartje de Jonge", "author_profile_id": "81444597572", "affiliation": "Delft University of Technology, Delft, Netherlands", "person_id": "P1728804", "email_address": "", "orcid_id": ""}, {"name": "Emma Nilsson-Nyman", "author_profile_id": "81418600185", "affiliation": "Lund University, Lund, Sweden", "person_id": "P1728805", "email_address": "", "orcid_id": ""}, {"name": "Eelco Visser", "author_profile_id": "81100561215", "affiliation": "Delft University of Technology, Delft, Netherlands", "person_id": "P1728806", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1640089.1640122", "year": "2009", "article_id": "1640122", "conference": "OOPSLA", "title": "Providing rapid feedback in generated modular language environments: adding error recovery to scannerless generalized-LR parsing", "url": "http://dl.acm.org/citation.cfm?id=1640122"}