{"article_publication_date": "10-25-2009", "fulltext": "\n Parallel Programming with Object Assemblies Roberto Lublinerman Swarat Chaudhuri Pavol .Cern\u00b4y Pennsylvania \nState University Pennsylvania State University University of Pennsylvania University Park, PA 16802, \nUSA University Park, PA 16802, USA Philadelphia, PA 19104, USA rluble@psu.edu swarat@cse.psu.edu cernyp@cis.upenn.edu \n Abstract We present Chorus, a high-level parallel programming model suitable for irregular, heap-manipulating \napplications like mesh re.nement and epidemic simulations, and JCho\u00adrus, an implementation of the model \non top of Java. One goal of Chorus is to express the dynamic and instance-dependent patterns of memory \naccess that are common in typical ir\u00adregular applications. Its other focus is locality of effects: the \nproperty that in many of the same applications, typical im\u00adperative commands only affect small, local \nregions in the shared heap. Chorus addresses dynamism and locality through the uni\u00adfying abstraction \nof an object assembly: a local region in a shared data structure equipped with a short-lived, specula\u00adtive \nthread of control. The thread of control in an assembly can only access objects within the assembly. \nWhile objects can migrate from assembly to assembly, such migration is local i.e., objects only move \nfrom one assembly to a neigh\u00adboring one and does not lead to aliasing. Programming primitives include \na merge operation, by which an assem\u00adbly merges with an adjacent assembly, and a split operation, which \nsplits an assembly into smaller ones. Our abstractions are race and deadlock-free, and inherently data-centric. \nWe demonstrate that Chorus and JChorus allow natural programming of several important applications exhibiting \nirregular data-parallelism. We also present an implementa\u00adtion of JChorus based on a many-to-one mapping \nof assem\u00adblies to lower-level threads, and report on preliminary per\u00adformance numbers. Categories and \nSubject Descriptors D.3.2 [Programming Techniques]: Concurrent Programming; D.3.2 [Program\u00adming Languages]: \nLanguage Classi.cations Concurrent, distributed, and parallel languages Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA 2009, October 25 29, 2009, Orlando, \nFlorida, USA. Copyright c &#38;#169; 2009 ACM 978-1-60558-734-9/09/10. . . $10.00 General Terms Languages, \nDesign Keywords Parallel programming, Programming abstrac\u00adtions, Irregular parallelism, Data-parallelism, \nOwnership 1. Introduction Calls for new programming models for parallelism have been heard often of late \n[29, 33]. On one hand, the demand for parallel programming is now higher than ever: inexpen\u00adsive multicore \nmachines are now near-ubiquitous, and the bottleneck in this space is now software rather than hard\u00adware. \nOn the other hand, it is increasingly clear that the cur\u00adrently popular models of parallel programming \nlocks and messages are too low-level, complex, and error-prone, and do not scale well with software complexity. \nConsequently, numerous teams of programmers and researchers are seek\u00ading high-level models of programming \nthat are intuitive as well as scalable. Not all parallel programming, of course, poses dif.cult challenges: \nembarrassingly parallel applications are easy to program ef.ciently, and for regular array-based codes, \nstatic parallelization [35] is known to work. Far more chal\u00adlenging is the problem of ef.ciently coding \napplications that combine parallelism with accesses to sparse, mutable data structures like trees and \ngraphs. Parallelism in such irregular applications [24] is highly input-dependent and prone to changes \nat runtime, with some pathological in\u00adstances exhibiting no parallelism at all. This makes compile\u00adtime \nparallelization impossible; in fact, Kulkarni et al. have noted [27] that most current implementations \nof optimistic parallelism (using transactional memory [28]) suffer in this setting as well. Vexingly, \nnumerous important scienti.c and graphical applications where parallelism is needed fall in this category \nexamples include physical [17] or epidemi\u00adological simulations [16], mesh re.nement [11], spanning tree \ncomputations [22], n-body simulation [5], social net\u00adwork analysis [21], and sparse matrix computations \n[14]. Consequently, many of these applications are perfect challenge problems for designers of new models \nof shared\u00admemory parallel programming. This understanding is re\u00ad.ected, for example, in the recently \nreleased Lonestar bench\u00admarks [2, 25], which offer code and datasets for several such  1: Mesh m = /* \nread input mesh */ 2: Worklist wl = new Worklist(m.getBad()); 3: foreach Triangle t in wl { 4: Cavity \nc = new Cavity(t); 5: c.expand(); 6: c.retriangulate(); 7: m.updateMesh(c); 8: wl.add(c.getBad()); } \nFigure 1. Delaunay mesh re.nement: sequential algorithm problems. In this paper, we present a response \nto this chal\u00adlenge: a data-centric programming model called Chorus, and a concrete language called JChorus, \nimplementing it. 1.1 Locality and dynamism The key insight behind Chorus is one also identi.ed by Pin\u00adgali, \nKulkarni et al. [24, 30]: while typical irregular appli\u00adcations require global memory access in the worst \ncase, the effects of their imperative updates are usually restricted to small, local regions in the heap. \nThis locality forms the essence of parallelism in this setting (Pingali and Kulkarni call it amorphous \nparallelism), and Chorus gives it a .rst\u00adclass treatment by exposing it at the language level. As such \nlocality is highly instance-dependent and intractable through static analysis, Chorus negotiates it dynamically \nrather than through static data partitioning. For example, consider Delaunay mesh re.nement, a clas\u00adsic \nand thoroughly studied [27] irregular application. The in\u00adput here is a triangulation of a plane viewed \nas a graph where nodes are triangles and edges represent adjacency and a subset of bad triangles that \ndo not meet certain qual\u00adity constraints. The problem is to retriangulate the mesh so that there are \nno bad triangles left. It is a property of the ap\u00adplication that such retriangulation affects a cavity \n: a local region in the mesh. A sequential algorithm (Figure 1) for De\u00adlaunay mesh re.nement uses the \nfollowing property: in each iteration of a loop, the algorithm builds a cavity c consisting of a bad \ntriangle t drawn from a worklist wl of bad triangles, expands c to the needed extent, and locally updates \nit using a retriangulation routine. In this algorithm, there is no theoretical bound on the sizes of \ncavities rewritten by c.retriangulate() at worst, they may encompass the entire mesh. Therefore, cav\u00adities \nneed to be identi.ed dynamically through the expand routine. At the same time, in practice, cavities \nare almost always small (see Figure 2), so that imperative modi.ca\u00adtions to the mesh are local. This \ncombination of locality and dynamism appears in numerous other irregular applications known to be dif.cult \nto parallelize indeed, it shows up in every irregular application that we have considered. Exploitation \nof parallelism in Delaunay re.nement and many other irregular applications is directly tied to the lo\u00adcality. \nIn parallel Delaunay re.nement, we need to guaran\u00adtee that cavities local regions are the units of space \nthat Figure 2. Snapshot of a Delaunay mesh from our experi\u00adments need to be accessed and retriangulated \natomically; cavities that do not overlap can be retriangulated in parallel. Thus, the programming pattern \nfor a thread is: Dynamically identify a region to own; establish own\u00ad ership over it. Atomically update \nthe region. Relin\u00ad quish ownership over the region. And yet, no current language for shared-memory par\u00adallelism \ncan express this combination of locality and dy\u00adnamism in a general way. In popular multithreaded lan\u00adguages \nlike Java or C#, the heap is a global pool: unless explicitly locked, a shared object can be accessed \nby any thread at any time. Locality of data structure accesses is not expressed in the program text, \nand there are no abstract prim\u00aditives capturing ownership of, and contention for, regions. This global \nnature of shared-memory accesses has a neg\u00adative effect on programmability as well as performance. In \nlock-based programming, the programmer manually man\u00adages references that can be aliased globally, leading \nto races and deadlocks. In languages using non-blocking soft\u00adware transactions, the burden of reasoning \nabout global ac\u00adcesses is passed to the transaction manager consequently, in most implementations of \nsoftware transactional memory, the transaction manager must track reads and writes to the entire memory \nto detect con.icts. As Kulkarni et al. [27, 26] point out, this makes them behave inef.ciently while \nhan\u00addling large irregular applications. Global heap-manipulation also makes precise static analysis extremely \ndif.cult. While Partitioned Global Address Space languages like X10 [10] and Chapel [8] allow language-level \npartitioning of the heap, they do not permit dynamic, lightweight cre\u00adation and recon.guration of the \npartitions. This makes them unable to grapple with the unpredictable, dynamic nature of irregular applications. \nPartitions that looked useful initially could very well turn useless during the execution, so that any \nworkable data partitioning strategy for this setting must be adaptive. At the other end of the spectrum \nare programming mod\u00adels such as Actors and Active Objects [20, 3, 32, 13], where data is encapsulated \nwithin actors, and memory accesses are modeled by message-passing. In an actor-based encod\u00ading of Delaunay \nmesh re.nement, each actor possesses a set of cavities, and cavity expansion is modeled by the passing \naround of triangles between actors. While such an imple\u00admentation captures the locality of the problem, \ncoordination in it is low-level, error-prone, and potentially expensive. For one, the simple c.expand() \nmethod is now replaced by a protocol between actors that has to be carefully coded to guarantee properties \nlike deadlock-freedom. Second, copy\u00ading and sending data involves high overheads, and if refer\u00adences \nrather than data are passed around, there is the poten\u00adtial of data races. Third, the speculative parallelism \nthat has been argued [27, 26] to be needed for irregular applications seems hard to encode within the \nactor framework.  Thus, none of these styles of programming allow for high-level expression of ownership \nof regions in the heap (cavities in case of mesh re.nement), and dynamic recon\u00ad.guration of such ownership. \nChorus, on the other hand, is designed precisely to capture these programming patterns.  1.2 Our solution \nThe Chorus programming model offers a view of concur\u00adrency that is neither as global as Java multithreading, \nnor as static as traditional data partitioning, nor based on low-level message-passing like the Actor \nmodel. The key abstraction here is an object assembly: a dynamically de.ned local re\u00adgion in the heap \nequipped with a short-lived, speculative thread of control. At any point in the execution, the assemblies \nin the sys\u00adtem form a disjoint partitioning of the heap. Typically, they are also .ne-grained in particular, \nan assembly is allowed to consist of just a single object. Thus, like the Actor model, Chorus permits \nmassive, object-level parallelism. Of course, assemblies are just programmer abstractions in any real \nimplementation, large numbers of them would be mapped to a single hardware thread. An assembly can perform \nthree kinds of actions: It can read and write objects within itself. Notably, it cannot access objects \nwithin any other assembly, which means objects within assemblies are isolated.  It can merge with an \nadjacent assembly, becoming a bigger assembly. The thread of control in the assem\u00adbly with which it merges \nis terminated. An assembly is speculative, meaning it can merge with, and terminate, a neighboring assembly \nwithout explicit consent from the latter.  It can split into a collection of smaller (disjoint) assem\u00adblies, \neach possessing a new thread of control.  All concurrency in our model is captured with these prim\u00aditives. \nThe number of assemblies is a proxy for the granular\u00adity of concurrency that the application permits \nthe greater this number, the greater the exploitable parallelism. Assem\u00adblies are of course not required \nto be bounded; in the worst case, they encompass the whole heap. Merges allow declar\u00adative and local \ncoarsening of the granularity of parallelism in the heap, while splits let parallelism be locally re.ned. \nThere is no global ordering between merges and splits e.g., merges between distinct pairs of assemblies \ncan always hap\u00adpen in parallel. For an application, consider Delaunay mesh re.nement once again. In our \napproach, each triangle in the initial mesh is an assembly. If a triangle discovers that it is bad, it \nforms a cavity (a bigger assembly) via repeated merge calls to its neighbors. The cavity retriangulates \nitself via a private up\u00addate, then splits into the new triangles (each a smaller assem\u00adbly). The expressed \nparallelism is at the .nest granularity permitted by the problem instance: all triangles and cavities \nin the heap work in parallel, and atomicity of retriangulation is guaranteed because the data in an assembly \nis isolated. Thus, it captures the pattern Own a local region, update the region, release the region, \nby rephrasing it as: Dynamically form an assembly by repeated merges, update the assembly, split the \nassembly. Our concrete contributions are the following: We introduce the Chorus programming model, present \na core language for Chorus and its operational semantics, and show it to be free of data races and deadlocks. \n We present JChorus, a programming language that em\u00adbeds our model of concurrency into the sequential \nsubset of Java.  We demonstrate the utility of JChorus in programming real-life applications via several \ncase studies. In addition to mesh re.nement, we consider the problems of Barnes-Hut n-body simulation \n[5], Focused community dis\u00adcovery in a social network [21, 4], an epidemiological simulation problem \n[16], and an algorithm for comput\u00ading minimum spanning trees [22].  We present a prototype compiler \nand runtime system for JChorus1 that use a many-to-one mapping of assemblies to low-level threads. The \nimplementation exploits local\u00adity of heap operations, uses Tarjan s Union-Find data structure to maintain \nassemblies and a token-ring-based strategy to ensure deadlock-freedom, and performs an elementary form \nof load-balancing. We report perfor\u00admance numbers for two irregular applications: Delaunay mesh re.nement \nand Boruvka s algorithm for minimum\u00adspanning-tree computation.  The paper is organized as follows. In \nSection 2, we in\u00adtroduce Chorus and study its properties. Section 3 outlines the JChorus language, and \nSection 4 demonstrates our case studies. Section 5 describes our implementation of JChorus; Section 6 \nreports on performance numbers. Related work is discussed in Section 7; we conclude with some discussion \nin Section 8. 2. Chorus Now we present the main features of the Chorus program\u00adming model. We start with \nan informal description of the 1 The prototype, as well as our encodings of these benchmark examples, \nare available at http://www.cse.psu.edu/~swarat/chorus.  Figure 3. A heap Figure 4. Control .ow in \nassemblies available programming constructs, then offer a more formal presentation using a core language. \n 2.1 Essential Chorus 2.1.1 Heaps The central structure in Chorus is the shared-memory heap, which maintains \nthe state of all shared data accessed by a parallel program. We abstractly view a heap as a directed \ngraph whose nodes are objects and edges are pointers. Point\u00aders here are labeled with .eld names.A region \nin a heap G is a graph consisting of a subset of the nodes of G, and all edges of G that connect nodes \nin this subset. For example, in Figure 3, u1, u2, u3, and v are objects, there is a pointer from u2 to \nv labeled by the .eld name f, and each shaded circle is a region. Or consider Delaunay mesh re.nement. \nThe mesh here can be modeled as a heap whose objects are triangles and whose pointers connect tri\u00adangles \nthat are neighbors in the mesh. Each cavity is a region in the heap.  2.1.2 Object assemblies An object \nassembly in G is a region of G equipped with a set of local variables and a sequential thread of control. \nThe typical execution scenario of Chorus programs has numer\u00adous assemblies executing concurrently. It \nis required that at each point in an execution, these assemblies form a disjoint partitioning of the \nheap in other words, every object in the heap belongs to (the region of) an assembly, and no object belongs \nto two distinct assemblies. While an assembly can update the heap, it embodies isolation: it has exclusive \nownership of its region and can neither read nor write objects that fall outside it. This means that \nimperative effects are local: a heap modi.cation by one assembly does not affect the data read by another. \nAn assembly is allowed to merge with adjacent assemblies and can also split into a set of smaller assemblies. \nIn typical scenarios, it is short-lived and exists to achieve a speci.c, local task e.g., the retriangulation \nof a single cavity. The active behavior of an assembly i1 is syntactically de.ned by guarded updates \nof the form :: Guard : Update where Guard is a condition that is evaluated atomically, and Update is \na statement allowing imperative modi.cation of the objects and pointers within the assembly. Control \n.ow in i1 can be abstractly captured by a state machine (Figure 4) with three control states: busy, ready, \nand terminated. A newly created assembly starts from the ready state. State transitions are as follows: \n If i1 is at the ready control state, then it nondeterministi\u00adcally chooses a guarded update, atomically \nevaluates its guard, and, if the guard is enabled, moves to the busy con\u00adtrol state to execute Update. \nAs i1 has exclusive access to its region, no extra precaution to ensure the atomicity of the update is \nneeded.  If i1 is at the busy control state and has .nished its update, then it can move back to the \nready state.  If i1 is at the ready control state, then it can be terminated.  Unlike in other guarded-command \nlanguages, a guard here can, in addition to checking local boolean conditions, merge i1 with an adjacent \nassembly i2, taking i1 to a busy control state and causing i2 to terminate. In its new state, i1 operates \non the union of the regions previously comprising i1 and i2. The heap itself is not modi.ed e.g., no \npointers are rewired. Also, the merge can happen only when i2 is in a ready state. During the merge, \ni1 can copy into its own local variables the local-variable state of i2, thus acquiring the work that \ni2 has already done. Thus, a merge is a synchronization operation in fact, it is our only synchronization \noperation. Figures 5-(a) and 5\u00ad (c) show the states of a parallel program before and after the assembly \ni1 merges with i2. Note that the operation locally coarsens the granularity of parallelism in the heap. \nAs for updates, they permit an assembly to imperatively modify its region any expression whose evaluation \nre\u00adquires accesses outside H returns an error value error. An update can also split an assembly into \nsmaller ones e.g., into assemblies containing one object each (Figures 5-(a) and 5-(b) show before-and-after \nscenarios for this opera\u00adtion). Observe that the split locally re.nes the parallelism in the system. \nImportantly, merges and splits are not globally ordered: a merge between assemblies i1 and i2 can proceed \nin parallel with a merge between j1 and j2 (where j1 and j2 are distinct from i1 and i2), or with a split \nof j1. Also, a modi.cation within i1 can run parallel to every action outside of i1. Also note that for \nan assembly i1 to merge with an as\u00adsembly i2, no explicit consent from i2 is needed. All we require is \nthat i2 is not in the middle of an update at the point when the merge happens. Thus, assemblies are spec\u00adulative \nentities that may not always .nish the task that they \n\t\t\t", "proc_id": "1640089", "abstract": "<p>We present <i>Chorus</i>, a high-level parallel programming model suitable for irregular, heap-manipulating applications like mesh refinement and epidemic simulations, and <i>JChorus</i>, an implementation of the model on top of Java. One goal of Chorus is to express the <i>dynamic</i> and instance-dependent patterns of memory access that are common in typical irregular applications. Its other focus is <i>locality of effects</i>: the property that in many of the same applications, typical imperative commands only affect small, local regions in the shared heap.</p> <p>Chorus addresses dynamism and locality through the unifying abstraction of an <i>object assembly</i>: a local region in a shared data structure equipped with a short-lived, speculative thread of control. The thread of control in an assembly can only access objects within the assembly. While objects can migrate from assembly to assembly, such migration is <i>local</i>--i.e., objects only move from one assembly to a neighboring one--and does not lead to aliasing. Programming primitives include a <i>merge</i> operation, by which an assembly merges with an adjacent assembly, and a <i>split</i> operation, which splits an assembly into smaller ones. Our abstractions are race and deadlock-free, and inherently data-centric.</p> <p>We demonstrate that Chorus and JChorus allow natural programming of several important applications exhibiting irregular data-parallelism. We also present an implementation of JChorus based on a many-to-one mapping of assemblies to lower-level threads, and report on preliminary performance numbers.</p>", "authors": [{"name": "Roberto Lublinerman", "author_profile_id": "81317497568", "affiliation": "Pennsylvania State University, University Park, PA, USA", "person_id": "P1728720", "email_address": "", "orcid_id": ""}, {"name": "Swarat Chaudhuri", "author_profile_id": "81309496839", "affiliation": "Pennsylvania State University, University Park, PA, USA", "person_id": "P1728721", "email_address": "", "orcid_id": ""}, {"name": "Pavol Cerny", "author_profile_id": "81392617758", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P1728722", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1640089.1640095", "year": "2009", "article_id": "1640095", "conference": "OOPSLA", "title": "Parallel programming with object assemblies", "url": "http://dl.acm.org/citation.cfm?id=1640095"}