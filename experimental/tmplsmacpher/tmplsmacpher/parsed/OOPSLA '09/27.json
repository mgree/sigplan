{"article_publication_date": "10-25-2009", "fulltext": "\n Writing Code for Other People Cognitive Psychology and the Fundamentals of Good Software Design Principles \n Thomas Mullen tom@tom-mullen.com Abstract This paper demonstrates how the cognitive model of the mind \ncan explain the core fundamentals behind widely ac\u00adcepted design principles. The conclusion is that software \ndesign is largely a task of chunking analogies and presents a theory that is detailed enough to be accessible \nto even the most inexperienced programmer. The corollary of which is a pedagogical approach to understanding \ndesign principles rather than the necessity of years of software development experience. Categories and \nSubject Descriptors D.2.2 [Design Tools and Techniques]: Object-oriented design methods. J.4 [So\u00adcial \nand Behavioral Sciences]: Psychology abstract data types, polymorphism, control structures. General Terms \nDesign, Human Factors, Theory. Keywords chunking analogies; 4 minus analogies 1. Introduction Making \ncode easier to understand is the primary driver be\u00adhind the phase of software design that does not change \nhow the code behaves or performs. Design principles and soft\u00adware languages have evolved over generations \nto influence code authors to produce code structures that are easy to un\u00adderstand. At the same time psychologists \nhave been unlock\u00ading the secrets of how the mind learns and understands. Later sections will illustrate \nthe many similarities between the cog\u00adnitive model and widely accepted design principles. This will serve \nas supporting evidence for the claim that code pro\u00adduced using such principles &#38; languages is a textual \nrepre\u00adsentation of the memory structures within the brain. The mapping between cognitive psychology and \nsoftware Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for profit or commercial \nadvantage and that copies bear this notice and the full citation on the first page. To copy otherwise, \nor republish, to post on servers or to redistribute to lists, requires prior specific permission and/or \na fee. OOPSLA 2009, October 25-29, 2009, Orlando, Florida, USA. Copyright &#38;#169; 2009 ACM 978-1-60558-734-9/09/10 \n$10.00. design leads us to the discovery of the importance of analo\u00adgies. If Structured Design is decomposition \nof the problem using the discipline of chunking, then Object-oriented De\u00adsign is decomposition using \nthe discipline of identifying analogies. 1.1 The Need to Learn A major portion of the time spent coding \nand designing is taken up in learning and understanding the application code. This is driven by: 1. The \nmajority of the development cost is spent maintaining and extending code. a) Software applications typically \nlast many multiples of the time it takes to develop the initial version. b) For successful applications \nit is common for team size to grow right up to the point that it becomes legacy. 2. Access to the original \ndesigner/author is uncommon. a) The lifetime of a software application will span many cycles of staff \nturnover. b) Global development of applications is becoming in\u00adcreasingly common. This includes regions \nwith little or no window of common work hours. Consequently, most software tasks are to extend/mend ex\u00adisting \nsoftware where any understanding must be gleaned directly from the code. Further (ignoring incapable \nor saboteur programmers), most bugs and deficiencies can be put down to failures in either understanding \nthe requirements or understanding the existing code. A programmer who has complete familiarity with both \nthe code and the requirement is most likely to es\u00adtablish the full extent of changes and the full extent \nof the impact of any changes on the existing behavior. There is a great cost involved in learning/understanding \nthe code and potentially further costs for fixing the issues that arise due to its misunderstanding. \nWhere we have a choice, investing in writing code that is easy to understand will produce efficiencies \nand cost savings throughout the life of the application.  1.2 Current Texts Many texts on design principles \nimplicitly require the reader to possess a certain level of experience in order to apply the principles \nappropriately. When experts pass on their design skills, it is easy to fall in the trap of using an explanation \nthat appears to them to be a natural consequence but, in fact, leans on the very same experience that \nguides them when executing that skill. Tell\u00ading a child who is unfamiliar with a keyboard layout that \nthe semicolon key is next to the L key is of limited use as a guide because finding the L key requires \nthe same search\u00ading strategy as finding the semicolon key. When the touch typist hits the L key it is \ndone automatically, with very little conscious notion of how the finger arrived at the key. The process \nseems a perfectly natural one. The guide of be\u00ading next to the L key is useful only to the expert. The \nirony is that it is the novice that has most need for a guide. In Mar\u00adtin Fowler s excellent Refactoring \nbook [9], a guide on when to employ the Extract Method rule is if the method is too long or the code \nneeds a comment to understand . The ability to recognize that the method is too long (or where it needs \ncomments) is a product of the same experience as the ability to employ the rule appropriately. To maximize \nthe value to the novice, the guide should rely solely on the limited experi\u00adence they possess (e.g. the \nsemicolon is on the middle row of letters to the right).  2. Cognitive Psychology The aspects of cognitive \npsychology that are pertinent to our cause are discussed in the following sections. The main ele\u00adments \nare as follows: 1. Chunks - Gobet et al [12] define a chunk as a collection of memory elements having \nstrong associations with one another but weak associations with elements within other chunks . 2. Short-term \nmemory (STM) - also known as working memory, STM holds the items that have current focus (e.g. when \nsolving problems) and is also responsible for the formation of chunks to be committed to long-term memory \n(via rehearsal). STM is limited by capacity [17] and time (<10secs without rehearsal). 3. Long-term \nmemory (LTM) a seemingly infinite re\u00adsource. LTM is where we store our memories and experi\u00adence ready \nfor recall into the STM when solving problems. The only known restriction to LTM is the time that it \ntakes to record (2s -8s).  4. Expert knowledge - experts and novices differ in the way they approach \nand solve problems. More crucially for de\u00adsign, a code structure that improves clarity for the novice \nmay have a detrimental effect for the expert [22]. 5. Analogical reasoning - analogies are ubiquitous \nin human intelligence [14]. Identifying and choosing analogies is driven by similarities, structure and \npurpose [15].  2.1 Chunking and Memory Mathematical analysis of memory networks has shown that searching \nis optimized when the nodes are chunked to four or five elements [8] (there is an argument that the STM \ncapacity limit is an evolutionary choice to force production of optimal long term memory networks [16]). \nOverloading STM will either necessitate dynamic chunking by the mind or will cause a sense of confusion. \nChunking our code into groups of four or fewer elements (either visually or using language structures) \nmeans that subsequent readers are less likely to suffer cognitive overload of STM and the confusion it \ncan bring. When we try to understand a concept or find a solution to delivering a requirement, the mind \nnaturally chunks related elements together. This is not necessarily immediate and may be the result of \ntrial and error. The stronger the association between two elements (e.g. two methods that use the same \nfields) the more likely they will be chunked together. This chunking characteristic has parallels in \nmany design princi\u00adples. The Data Object is a collection of fields that are related together. Data normalization \nis a process driven by the desire for chunking using classes and/or database tables to partition the \nchunks. Although it is not their sole purpose, packages can be used to chunk classes, classes can be \nused to chunk methods/fields and methods can be used to chunk statements. In advising that a class have \nno more than 2 or 3 collabora\u00adtors, Beck and Cunningham s CRC model is chunking the view of relationships \nto no more than four elements. Many of Fowler s refactoring rules are strategies to chunk elements (some \nare identified in section 4.2). The laws of Pr\u00e4gnanz, from the Gestalt branch of psy\u00adchology, identify \nhow we recognize groups of elements. Many code authors employ these laws to indicate the element chunks \nso as to pass on the knowledge of the associations (thus saving the reader from the same, potentially \ncostly, process of identifying them). For example: Chunking using the law of proximity. In the example \nbe\u00adlow, statements are visually grouped together using blank lines. Lines that are close together will \nbe chunked to\u00adgether by the reader. printHeader(); printMsg();  processNew(); update(); printFoot(); \nChunking using the law of similarity. Indented lines are associated together due to the similarity of \ntheir shape. In the example below the statements executed as part of the loop will be chunked together \nby the reader. sum=0; sumOfSquares=0; for(int I=0; I<num; I++) { sum += x[I]; sumOfSquares += x[I] * \nx[I]; } Chunking code elements can be likened to grouping mag\u00adnets that are sometimes attached by springs. \nThere is a repel\u00adling [magnetic] force between all elements to prevent them being grouped together when \nthere is no association. The associations [springs] are attractive forces (stronger associa\u00adtions are \nrepresented by stronger springs). The strong asso\u00adciations will bring some elements together and their \ncombined magnetism will repel elements that have weaker (or no) associations. For example, if a class \nevolves so that one half of the methods use one portion of the fields and the other half the remainder \nthen the stronger associations within each of the groups will lead to the pairs separating and pro\u00advide \nan argument for splitting up the class. Many texts already identify that the decomposition asso\u00adciated \nwith structured design is a reflection of the chunking process which the mind employs to understand the \nproblem. The guide that we should maximise cohesion and reduce coupling is the optimization function \nthat produces chunks as defined by psychologists ( a collection of memory elements having strong associations \nwith one another but weak asso\u00adciations with elements within other chunks ).  2.2 LTM structure and \nrelearning The storage of items in LTM has been successfully modeled as discrimination nets [11]. Discrimination \nnets have been used, among other things, to model decision making, concept formation and recognition \nprocesses. The theory proposed that elements of memory are built up into a connected net\u00adwork. For each \nelement to be added to the net, the place where it is to be incorporated is firstly identified. The net \nis then either extended or modified to allow the new data. In addition to the parent/child links of the \nnetwork, each node has an associated image (letter, word, sound, visual image, feeling, etc). Anyone \nfamiliar with mind maps will immedi\u00adately recognize this structure. Building up the networks in LTM is \nachieved by re\u00adhearsal (after they have been loaded into STM). The sole cost of LTM is purely in the \namount of time it takes to suc\u00adcessfully rehearse elements (typically of the order of sec\u00adonds). However, \nnew elements may restructure the net so as to break the links to existing elements. These existing ele\u00adments \nneed to be re-learned to allow the building of a net\u00adwork that accommodates all the learning. Naturally, \nany re\u00adlearning requires additional time costs (and sometimes frus\u00adtration on the part of the student \nwho is annoyed at them\u00adselves for seemingly going backwards). Meyer s open-closed principle is the echo \nof the mind s process to minimize re-learning costs. This makes evolution\u00adary sense. For example, if \nI see someone being violently ill after eating a black and yellow lizard I stand a better chance of survival \n(and passing on my genes) if I remember to steer clear of such reptiles. If I subsequently see someone \nfeasting heartily on a black and yellow snake with no after effects, I will want to remember that snakes \nare good to eat without modifying the knowledge that lizards are dangerous. I will want my memory to \nbe open for extension but closed for modification. Our minds have evolved so that they structure LTM \nto op\u00adtimize searching and minimize re-learning costs. If we struc\u00adture our code to mimic LTM then it \nwill be more easily and quickly absorbed (and understood) by subsequent readers. Design principles are \nsymptoms of how the mind works rather than rules based on mathematical algorithms.  2.3 Simplified Cognitive \nModel This section will detail a (very) simplified model of the cog\u00adnitive elements (see Figure 1). Without \nwishing to become involved in the vigorous debate [5] on the capacity of STM the assumption will be that \nthe limit is four chunks. The gateway to an expanse of information the size of a planet (LTM) is a four \nwindow portal (STM). Adding to, or retrieving from, LTM can only be performed through the four windows. \nIn something akin to Google Earth, the win\u00addows can contain big items (countries, states, cities) or \nzoom in to fine grain items such as words on a book. However, only one item (chunk) can be pulled in \nto each window at any time and, unless rehearsed, they will float back down to the web of LTM and soon \n(typically <10sec) disappear from our conscious. The topics we desire to learn are interconnected elements \nlike balls of spaghetti. In traditional topics, such as physics, teachers unravel and reshape the complex \nconnections and feed it to students so that it fits through STM and has a good chance of reshaping into \nsomething useful on the other side (LTM). For the software application, design principles influ\u00adence \nthe programmer to create a spaghetti ball that is already reshaped and unraveled. Indeed the ideal situation \nwould be that the application could be simply poured through the por\u00adtal, where the only limitation was \nthe flow rate (the time taken to commit to memory). The less complex the transla\u00adtion between the software \ncode and the structure of the LTM Figure 1. Simple Cognitive Model.  network, the less likelihood of \nmistakes by a new reader in formulating (i.e. understanding and learning) and therefore the less likelihood \nin needing to restructure their memory network (and the associated possibility of re-learning being necessary). \n 2.4 Evolution Fred Brooks No Silver Bullet paper [2] talks about the essential complexity of the problem \nand the accidental com\u00adplexity that we may bring to the solution by our choice of language (e.g. assembler) \nor design. Brooks surmised in 1986 that the current high-level languages have evolved to their limit. \nIf we also surmise that the evolution of languages and design principles has been driven by the desire \nto make code easier to understand (as that is where the biggest influ\u00adence of cost is), then by Darwinian \nargument: CONJECTURE Current software languages and design prin\u00adciples guide a programmer to produce \ncode that is a direct textual representation of the memory network of the solution within the brain (subject \nto the constraints of short term memory).  2.5 Cognitive Load In studies of cognitive load for the effectiveness \nof training strategies [3], two principles of note are Redundant Infor\u00admation and the Split Attention \nEffect :  If information is added that simply restates existing points and adds no extra insight, the \nconcept is more difficult to comprehend/learn. The redundant information is not neces\u00adsarily benign; \nit may take up scarce STM resources, which leaves less capacity to understand the intended concepts. \nFor example, the comments associated with a simple getter method will usually just restate the method \nsignature (there is no further insight to add). These comments can add to the complexity of the code. \nIn the split attention effect, if text that supports a picture is presented separately from the picture \nit is more difficult to comprehend/learn than if the text were displayed meaning\u00adfully upon the picture \nitself. In this instance additional items in STM are required to keep tracks of the links between the \ntext and the picture. This leaves less capacity to compre\u00adhend/learn the concepts. Adding layers of indirection \nis a tool often used by the software programmer (for example chunk\u00ading code lines into a separate method \nas in the extract method in Fowler s Refactoring ). In doing so, however, we are increasing the cognitive \nload on the code reader, as they are additionally burdened by the newly introduced links. Traversing \na layer of indirection in the code may have both time and capacity penalties for STM. For example switching \nto another class to examine the workings of a called method may take a few seconds (seconds count with \nSTM). Each level that is traversed may need to be under\u00adstood (including peripheral items), taking up \nSTM capacity and pushing the original contents out where they can no longer be rehearsed. We are remarkably \nadept at chunking all this information to keep a few levels still in STM. However, there is a limit, \nfor which there will be no warning. Just a realization that we no longer remember how/why we got to this \npart of the code. Each indirection appears not to make the code overly complex, as, when looked at in \nisolation, the additional bur\u00adden is no more than other pre-existing indirections. Unless we are frugal, \nit is all too easy to breach the limit that results in confusion when traversing the path. IDEs can help \nto re\u00adduce the cognitive overhead (e.g. quick views on methods etc) as can manual memory paging (writing \ndown). Whilst there are benefits to employing indirections (e.g. for chunk\u00ading) the cognitive model also \nidentifies a cost.  2.6 Code for Experts and Novices The more expert we are, the more we scan the code \nrather than read it. The patterns in the visual area are processed and matched with templates in memory \nthat have built up over the months and years of our experience. These templates allow the expert to immediately \nsee the structure (as well as anomalies) as if the processing was done as part of the subconscious [7]. \nFor experts it is therefore more beneficial to have as much code as possible in the field of vision (the \nsplit attention effect is also reduced). However if too much code is placed in the field of vision of \nthe novice then cogni\u00adtive overloading is possible. Novices benefit from the code being structured to \ndirect their attention to a few items at a time. Expertise of part or all of a software application is \nnot re\u00adstricted to programmers with vast experience. Certainly, a general software expert will find it \neasier than a program\u00adming novice to pick up a new software application. How\u00adever, each of us (novice \nor expert) immediately becomes an expert in any code that we write by the necessity of having to fully \nunderstand the problem and solution in order to get it to work. Also, the software application as a topic \nis small and well contained when compared against conventional topics such as Physics etc. Consequently \nit may take only a matter of months or a year before even an inexperienced program\u00admer becomes expert \nin part or most of the application. As an example, novices will typically prefer a more ag\u00adgressive normalization \nthan experts as this provides them with the chunking of the data and thus reduces cognitive overloading. \nThe expert, however, has enough knowledge templates in memory to see the chunking and will perceive such \nnormalization as a layer of indirection that serves no purpose and indeed gets in the way of understanding. \nThere will always be the contradictory aims of keeping as much in the visual field for the expert and \nformally chunking to reduce cognitive loading for the novice. There must be tolerance on both sides. \nIt won t take long for the novice to become an expert in the application when they will benefit from \nan expert layout. Conversely most teams have signifi\u00adcantly more novices than experts so the greater \ngood may mean that the expert should suffer a heavier indirection over\u00adhead attributed to chunking. When \ncoding we may start with a base that is clear and simple, but as we continue to implement the full require\u00adments \nwe will append code on to that base. Being an expert in the code that we write means that there is a \nnatural creep to make more code present in the visual field. Code reviews (in addition to other benefits) \nare useful for alerting us to complexities that as authors we become oblivious to.  2.7 Analogical Reasoning \nTo many psychologists, analogies lie at the heart of human intelligence. Some reveal new insight (e.g. \nNiels Bohr s model of the atom as a small solar system) and others allow us to transpose existing skills \nto new tasks (e.g. being able to pilot a motor boat when we have only ever been trained in driving a \ncar). In his presidential lecture [14], Hofstadter sees analogy at the core of cognition and illustrates \ntheir ubiquity. Analogies both facilitate the leaps in humankind s under\u00adstanding and are at the very \nheart of our everyday cognitive processes. They are the building blocks of how we view con\u00adcepts.  \nFigure 2. Analogy structure. Figure 3. Example Class Hierarchy to illustrate the elements of an analogy. \nHolyoak &#38; Thagard [15] identify three broad constraints in choosing analogies - Similarity, Structure \nand Purpose. For example, a games programmer may model a tiger s be\u00adhavior dependent upon its state, \ne.g. hungry, injured, cor\u00adnered etc. The tiger analogy in this case has the different states as the varieties \nand the structure elements such as movement and likelihood of attack. However, when the World Wild Fund \nfor Nature (WWF) looks into the threat of extinction to the tiger the structure elements are environment, \nbreeding cycles, current population etc. In the WWF analogy the tiger is a variety and is similar to \nother endangered spe\u00adcies such as the panda. It is purpose that determines the choice of analogy for \nthe games programmer and the WWF. In software, the same class or code element may also present different \nanalogies to separate parts of the code. For exam\u00adple, a data access object will present a read/write \nbehavior to the elements of code that need access to the data but will present a setDataSource analogy \nto the elements of code responsible for initialization. The choice of analogy by each element of code \nis driven by the purpose that element wishes to access the DAO. Presenting one analogy to the business \nfunctionality whilst hiding other aspects of the DAO may mean that cognitive load is reduced when understanding \nthe business logic. In 1983 Gentner [10] proposed an algorithm for how the structure of the analogy influences \nchoice. Analogies with similar operations are preferred to those that are simple simi\u00adlarities in attributes. \nGentner categorizes analogies by the types of mapping between the varieties. These can be mappings between \nat\u00adtributes or relations (a relation can exist between attributes and/or other relations). The categories \nare reproduced here (two of the names have been changed to avoid confusion with software terminology): \n No. Of attributes Mapped No. Of relations mapped Example Literal Similarity Many Many The K5 solar sys\u00adtem \nis like our solar system Vanilla Analogy Few Many The atom is like our solar system Rule Anal\u00adogy 1 Few \nMany The atom is a cen\u00adtral force system Anomaly Few Few Coffee is like the solar system 1 Rule Analogy \ndiffers from vanilla analogy and the other comparisons in having few object attributes in the varie\u00adties. \n For example, the instances of a class are literal similarities (the class description itself serves \nas the mapping) as are the rows of a database table (the column names serve as the mapping). Interfaces \nand abstract classes can be used to de\u00adtail the mapping for vanilla analogies. The need for late bind\u00ading \nand/or loose typing is usually associated with a rule analogy (for example, the Set class does not know \nwhat type of objects are to be placed in the set).  2.8 Analogy Patterns in Software The psychologists \nview of analogies [10] (i.e. having attrib\u00adutes and operations) is similar to to the class/interface \nstruc\u00adture evolved by software designers. This is not by coincidence if we accept the conjecture that \ndesign principles guide us to produce textual representations of the memory network. The existence of \nanalogical structures within the mind would inevitably lead to the evolution of languages and principles \nthat mimic them (although inevitability makes it a no lesser feat by the software designers). Borrowing \nheavily from the psychologists definition of the analogy and the software designers interface/class,the \nstructure for the analogy can be represented as in Figure 2. An analogy is the mapping of similar attributes, \noperations and rules between two or more varieties. Each variety speci\u00adfies a value for attributes as \nwell as an implementation for the operations. The SaleItem vanilla analogy in Figure 3 serves as a simple \nexample (the Na, Aa, Nv, Av annotations are from the analogy template in Figure 2). Of special note is \nthat the category attribute is an anology itself with varieties Electri\u00adcals , Furnishings etc. Attributes \n(Aa) reference another analogy by either the type or the name chosen to represent the attribute (in this \ncase the name category is the name of the analogy). The Value (Av) will reference a variety of that analogy. \nFor our purpose, we view the category analogy as having no attributes or operations and so it is sufficient \nto reference analogy and variety names only ( category , Elec\u00adtricals , Furnishings ). If our purpose \nchanges (either by better understanding or a change in requirement) then we would create an analogy structure \nfor category and reference that in the SaleItem analogy.  The most obvious means to implement analogies \nin soft\u00adware is to use interfaces and abstract classes but there are other structures that can deliver \nthe same. Please note, the code samples in this section are meant as examples of struc\u00adtures. They show \nhow the code could be written rather than necessarily how they should. A good guide for identifying analogies \nin software is if you can guess the code that must be written when the be\u00adhavior is to be extended for \na new variety. For example the following code presents the account type attribute for differ\u00adent varieties \nof futures exchanges (Eurex, Liffe etc) public String getAccountType(String account) { if( exchange.equals( \nEUREX ) ) return getEurexAccountType(account); if( exchange.equals( LIFFE ) ) return getLiffeAccountType(account); \nif( exchange.equals( MONEP ) ) return getMonepAccountType(account); Extending this code for the Matif \nexchange is easy to guess : if( exchange.equals( MATIF ) ) return getMatifAccountType(account); At first \nview this may seem like an implicit requirement of software development experience. However, the experience \nrequired here is one of recognizing analogies, a skill that is developed in our childhood. This implicit \nassumption of the reader being able to identify and build analogical structures (that reflect business \nrequirements) is arguably a core skill requirement for even a novice software developer. The next sections \ndetail the various Java code structures that can be used to represent analogies. Naturally, other lan\u00adguages \nshare some of these structures and most have addi\u00adtional ways of coding analogies. I propose that these \nstructures are the templates in the mind that experience builds up. For example, the Substitute Algorithm \nrefactor in Fowler s Refactoring is replacing the switch analogy with an attribute only analogy. These \nstructures have evolved using the laws of similarity and proximity to give visual clues to the reader \nso that they can easily recognize the elements of the analogy. When coding a solution to a requirement \nthe programmer will use their natural cognitive abilities to identify the analo\u00adgies of the problem (this \nwill include the simple literal simi\u00adlarities as well as the more complex vanilla analogies and rule \nanalogies). Choosing which code structure to represent the analogies will be dependent upon both the \ntype of the analogy and also the dependencies that the implementations of the varieties require. At the \nsame time the experienced programmer will be aware that the code elements need to be chunked into four \nelements or fewer. As our understanding of the requirements change (or even as the requirements themselves \nchange) the choice of code structure for the analogies may need to be revisited. The ex\u00adperienced programmer \n(with the analogy templates in their mind) finds it easier to visualize alternative analogical struc\u00adtures \nand so is more likely to deliver a well designed refac\u00adtor in a timely manner. In some cases we may change \nclasses that have been iden\u00adtified as those that should be closed for modification. This does not mean \nthat our original design failed the open-closed principle. Rather, the new requirements have changed \nthe shape of the analogies of the problem. The previous design was the correct solution for the previous \nanalogical structure, but our new requirements have changed that structure into a different problem. \nRecognizing the changes to underlying analogies will give comfort to the inexperienced coder that a redesign \nis the right choice. 2.8.1 Attribute only Analogies The simplest implementation for attribute only analogies \nis a map. In this example futures exchanges are seen as literal similarities with the only attribute \nof interest being the coun\u00adtry in which they operate. static Map exchangeCountry = new HashMap(); static \n{ exchangeCountry.put(\"EUREX\",\"Germany\"); exchangeCountry.put(\"CBOT\",\"US\"); exchangeCountry.put(\"LIFFE\",\"England\"); \n//can guess what to do //to extend for NYBOT...... } //usage public String logMessage (String exchangeName) \n{ return \"Exchange \" + exchangeName + \" is in \" +  exchangeCoun\u00adtry.get(exchangeName); }  Analogy \nName [Na] exchange is the prefix of the vari\u00adable name exchangeCountry  Attribute [Aa] country is \nthe suffix of the variable name  exchangeCountry Variety Name [Nv] the map key (e.g. \"EUREX\")  Value \n[Av] the map value (e.g. \"Germany\")   2.8.2 Statement Shape Analogies Here a statement shape is repeated \nfor different fields or ele\u00adments to provide the implementation for a behavior. The similarity of the \nstatement shape is key for the reader to be able to recognize the analogy (which is to check for a null \nvalue then check for a zero value). In this example validating a field is the analogy and each field \nof the class needs it s own variety of validation. private Date expirationDate; private Long contractNumber; \nprivate Double price; private Double quantity; private String description; private boolean isValid() \n{ if (expirationDate == null || !( expirationDate.getTime() > 0 ) ) return false; if (contractNumber \n== null || !(contractNumber.longValue() > 0) ) return false; if (price == null || !( price.doubleValue() \n> 0 )) return false; if (quantity == null || !( quantity.doubleValue() > 0 )) return false; //can guess \nwhat the code line is //for the String parameter //\"description\" ...... return true; } Analogy Name \n[Na] n/a. Operation [Oa] the method name isValid gives the single operation.  Variety Name [Nv] \nthe similarity of the statement lines (utilizing the law of similarity) will indicate that the vari\u00adety \nis defined by the field name.  Behaviour [Ov] the statement structure for each field  2.8.3 Switch \nAnalogy Similar to the Statement Shape analogy, the implementations are chunked together with a more \nformal specification of variety type. The example here returns the value for combin\u00ading two numbers with \nvarious operators (add, minus etc.) private int operand; public double calculate (double first, double \nsecond) { switch (operand) { case MULTIPLY: return first * second; case DIVIDE: return first / second; \ncase ADD : return first + second; case SUBTRACT : return first - second; } return 0; }  Analogy Name \n[Na] n/a.  Operation [Oa] the method name calculate.  Variety Name [Nv] the case values (e.g. MULTIPLY, \nDIVIDE etc.).  Behaviour [Ov] the block of the associated case.   2.8.4 Method Name Analogy Either \nthe suffix or prefix of the method is used to express the analogy. The prefix has the advantage of grouping \nto\u00adgether the methods when they are listed in alphabetical order (as with many IDEs). The prefix version \nexample is the visi\u00adtor pattern. The suffix example returns different value types from the Double object. \nThis structure is useful when all the varieties share dependencies as these can be chunked within the \nclass. //example 1 - prefix public void visitExpression(Node a){}; public void visitBlock(Node a){}; \n  public void visitFile(Node a){}; //example 2 - suffix Double doubleObj = new Double(0); double a \n= doubleObj.doubleValue(); int b = doubleObj.intValue(); long c = doubleObj.longValue(); float d = doubleObj.floatValue(); \n Analogy Name [Na] n/a.  Operation [Oa] method prefix or postfix (e.g. visit).  Variety Name [Nv] \n remainder of method name (e.g. Ex\u00adpression, Blocketc.).  Behaviour [Ov] method block.   2.8.5 Method \nParameter Analogy The type of parameter passed to a method can distinguish the variety. The example here \ngives the maximum of two num\u00adbers (using the static Math class). float f = Math.max(1.0F, 2.0F); int \ni = Math.max(1, 2); long l = Math.max(1L, 2L); double d = Math.max(1.0, 2.0); Analogy Name [Na] n/a. \n Operation [Oa] method name (max).  Variety Name [Nv] the type of the passed parameter.  Behaviour \n[Ov] method implementation.  2.8.6 Class/Interface Analogy The class/interface analogy allows for \nmultiple elements col\u00adlected (chunked) together. abstract class Shape { String name; //square, circle \netc int numSides; abstract double area(); } class Rectangle extends Shape { double length; double width \n double area() { return (length * width); } } Analogy Name [Na] abstract class name (e.g. Shape)  \nAttribute [Aa] fields (e.g. name, numSides).  Operation [Oa] abstract method area.  Variety Name \n[Nv] extended class name Rectangle.  Value [Av] values of field.  Behaviour [Ov] implementation \nof abstract method (area method in Rectangle)  2.8.7 Rule Analogy Generics in Java can be used in the \ncoding of Rule analogies. This can be to identify the operations needed by the rule and also as a way \nto formally define the type associations (e.g. the object type returned by the Iterator must be the same \ntype as that placed in the Collection class). 2.8.8 Application Level Analogy The running instances \nof an application are literal similarities of one another. Configuration files and system properties \nidentify the attributes of the analogy. IOC mechanisms allow us to define operations at the application \nlevel analogy.  2.9 Multi-Paradigm Design The approach of identifying the business analogies in the \nrequirements and choosing the pertinent code structure was identified by Coplien [4]. Coplien uses the \nterm domain for analogies and sub-domains for their varieties. Solution domains are analogy structures \nin code (although only for\u00admal structures such as interface, templates, etc. are identi\u00adfied). The commonality \nand variability analysis is the process of identifying the analogies. Both Coplien and Booch [1] explain \nobject-oriented de\u00adsign as decomposition attributed to chunking. Structured design is the discipline \nof chunking but it is my contention that object-oriented design is the discipline of identifying and \ncoding analogies. These are different but complimentary skills that must be employed to produce well \ndesigned soft\u00adware.  3. Fundamental Metric of Software Design more what you d call guidelines than actual \nrules Capt. Barbossa, Pirates of the Caribbean: The Curse of the Black Pearl  3.1 4 minus Analogies \nRule Analogies are the building blocks of cognition. Identifying the analogies of the problem is the \nfirst step to the solution. Code structures to represent analogies are part of the experi\u00adence of the \nprogrammer. Our mind has evolved to manufacture long-term memory networks that are optimized for searching \nand re-learning costs (as we extend it). The consequence of this is that we are limited to processing \nfour elements or fewer at any time (code elements include statement expression, statement groups, associations, \nmethods, classes, packages etc.). The only exception to this is the number of varieties of an anal\u00adogy. \nWe can understand a shopping list regardless of its length because we understand that all items need \nto be treated the same (i.e. find and buy). We will naturally group all the varieties as one element \nunder an analogy description. Therefore, the core fundamental metric of software design is that software \nshould be chunked in elements of four (or fewer) after allowing for any number of varieties of analo\u00adgies. \nThe psychologist s definition of a chunk is assumed here so cohesion and coupling considerations are \nimplicit in this rule. This does not mean that a class, say, should only have four methods. Rather, the \nmethods need to be chunked together in groups of four or fewer (again after allowing for any number of \nvarieties of analogies). Chunking software elements is fairly obvious and is men\u00adtioned in many texts. \nExplaining the permissible exceptions using a simple consistent rule is not. The classic exception is \nthat of a single, simple behavior based on different types, which does not warrant a class structure \nall to itself. Rather, a simple switch/case statement is more appropriate. As seen in previous sections \nthis is a structure for an analogy and so follows the rule of 4 minus analogies . Including more than \nfour elements may place a burden on the reader to employ their own chunking strategies on the code. Without \nthe guidelines that the author can give using the structures above, the reader may produce different \nparti\u00adtions and/or have difficulty doing so, leading to confusion of the code (and the greater probability \nof introducing bugs). Chunking analogies may shed some light on the artistry behind programming but not \nall. For example Bloch s builder structure owes more to making code look like written language despite \nthe tight restrictions of what has to be a very limited code vocabulary.  4. Example Companion Sections \nThe brief explanations below serve two purposes. Firstly, they provide evidence that the core principles \nabove, which have been extracted from the cognitive model, are consistent with design principles that \nare widely subscribed to. Sec\u00adondly, they show how novices can be provided with the de\u00adtails behind when \nthe rules below are appropriate to be applied. For example, the rule of 4 minus analogies serves as a \ntest for when a method or individual statement is too large or when a class has too many methods etc. \n 4.1 Design Patterns The GoF design patterns [13] show how analogies can be delivered using class level \nstructures. Single analogies are discussed in some patterns. Multiple analogies are also dis\u00adcussed, \nin some cases where one of the analogies is not under direct control (e.g. Adapter). 4.1.1 Abstract Factory \nIn most cases the elements (typically attributes and behav\u00adiors) of an analogy will be chunked together \ndue to the natu\u00adral strong associations. When there are multiple analogies influencing a behavior, the \nlayering of the analogies will largely be decided by considerations of the dependencies. In the abstract \nfactory pattern each concretion of the Widget-Factory interface creates the varieties of widgets for \na single OS. Here, the behaviors of the widgets are subject to two analogies, one that has the widget \ntype as variety, the other has the OS (that the widget is displayed upon) as the variety. An alternative \nstructure may be that the concretions create a single widget for a variety of OS s [in both cases there \nare (No. Widgets) x (No. OS) classes]. The intent of the pattern is stated as: Provide an interface for \ncreating families of related or dependent objects without specifying their concrete classes . Here the \nstronger dependencies are stated to be those within the family and so the preferred structure groups \nthe variety of widgets for a single OS. Sometimes, we may need to write the code where the analogies \noverlap to fully identify the dependencies and so decide which analogy has the stronger associations. \nIf we have prior experience then it may be possible to perform this in the mind and so visualize a design \nbefore we put fingers to keyboard. In some cases however, even the most experienced programmer will need \nto get into writing code before the design structure is finalized (especially if unfamiliar third party \ncode is being used). 4.1.2 State The state pattern reminds us that the choice of variety within an analogy \nmay be a dynamic one. It also highlights that if the associations amongst the behavior (methods) of each \nvariety are stronger than the associations amongst the varie\u00adties (i.e. common code) then it makes sense \nto chunk the varieties in their own separate classes.  4.1.3 Visitor The method name analogy as discussed \nin section 2.8.4.   4.2 Fowler Refactoring There are a number of common concepts within Martin Fowler \ns Refactoring book that can be explained with refer\u00adence to the cognitive model: a) Chunking. Code elements \nshould be chunked in ele\u00adments of 4 or fewer (allowing for analogies). b) Accurate Names. Names of variables, \nmethods etc serve as images on the LTM network. The more accurate these names are in describing what \nthey represent the more likely that the reader s mind will use the name as an image and so the closer \nthe code structure is to the structure in LTM. As a contrary example, using the same variable name to \nrepresent the value throughout the different stages of calculation must mean that it is ei\u00adther inaccurate \nfor at least one of its cases or so vague as to diminish its suitability as an image name. c) Introduce \nName. If it is difficult to determine the pur\u00adpose of the code chunk from the elements within, attach\u00ading \na name (literal description or metonymy) will serve as an image on the LTM network. In this way the author \ncan efficiently pass knowledge on to the reader. d) Remove unnecessary layers of indirection. Indirections \nthat serve no purpose have an associated cost (see sec\u00adtion 2.6 Code for Experts and Novices ). Example \nrule explanations are as follows Extract Method - The use of methods to chunk code in\u00adcluding introducing \na name.  Inline Method - If the method body is just as clear as the name then not only is this redundant \ninformation but it is also an unnecessary indirection.  Inline Temp - Unnecessary indirection  Replace \nTemp With Query -Reduces the number of ele\u00adments in the main method to ease cognitive load and also aids \nchunking.  Introduce Explaining Variable - Chunking and introduces image. A long statement (i.e. one \nthat has greater than four elements) is split into a number of statements that have four or fewer elements, \neach with their own image (variable name).  Split Temporary Variable - Accurate Names  Remove Assignments \nTo Parameters - Accurate Names  Replace Method With Method Object - Use of a class structure to allow \na long method (greater than four ele\u00adments) to be chunked.  Substitute Algorithm - Swaps one analogy \nstructure for another.  5. Conclusion This paper has Detailed the strong mapping between the cognitive \nmodel and design principles.  Identified that recognising and coding analogies is one of the two primary \ndisciplines in good software design (the other being chunking).  Used these results to discover the \n4 minus analogies rule.  Making code easier to understand is the primary driver behind the majority \nof software design principles. To define simplicity, however, we must examine the processes and limits \nwithin the mind. The cognitive model can be under\u00adstood and learned by the novice using their life experiences \nas examples and does not require any programming or design knowledge. The concepts of cognition are the \nfundamentals behind design principles. This does not obviate the necessity for learning and understanding \ndesign principles but it does help to lower the bar of experience needed for the novice to build up the \nability to differentiate when it is appropriate to apply them. The subsequent improvement in the design \nof our code will reduce the time and costs associated with sup\u00adport and mainentance. The primary proposal \nis that novice programmers follow a training program to: 1. Become familiar with the cognitive model, \nincluding: a) Chunking and the capacity limits of short-term memory. b) Analogies as the building blocks \nof cognition. c) Long term memory structures. d) Cognitive loading (e.g. split attention effect and redun\u00addant \ninformation). e) Expert versus novice behavior. 2. Identify and write Analogy &#38; Chunking structures \nin code 3. Understand how texts like Fowler s Refactoring &#38; the GoF Design Patterns provide common \nsolutions to chunking and high level structures of analogies. 4. The importance of learning IDE features \nwhich deliver an experts view on code that has been structured primarily for the novice.   6. Signoff \nIn this paper the analogy is made between the structure of memory within the brain and the structure \nof code that fol\u00adlows design principles (which have evolved over the last few decades). In this case \nthe base of the analogy is the cognitive model provided by psychologists which when mapped onto the target \nof design principles, enriches our understanding to lower the bar of experience needed to apply them. \nAt the heart of this mapping are analogies themselves. What if we were to evaluate the analogy in the \nopposite way? Could the design principles that have surfaced from the melting pot of millions of programmers \nworking on billions of lines of code be used to infer knowledge about cognition? An analogy that helps \nus to understand analogies.  Acknowledgments To Bernie Mullen, Ged Mullen and Pete Williams for the \nhelpful comments and suggestions. Thanks also to Giles Thompson, Miranda Sinclair, John Weir and Don \nRaab for their support and guidance.  References [1] G. Booch; R. A. Maksimchuk; M. W. Engle; B. J. \nYoung; J. Conallen; K. A. Houston. Object-Oriented Analysis and De\u00adsign with Applications, Third Edition \n(2007). Addison-Wesley ISBN 0-201-89551-X [2] F. Brooks. No Silver Bullet - Essence and Accidents of \nSoft\u00adware Engineering (1986). http://www.lips.utexas.edu/ee382c\u00ad15005/Readings/Readings1/05-Broo87.pdf. \n[3] G. Cooper. Research into Cognitive Load Theory and Instruc\u00adtional Design at UNSW (1998). http://education.arts.unsw.edu.au/staff/sweller/clt/index.html \n[4] J. O. Coplien. Multi-Paradigm Design for C++ (2003). Addi\u00adson-Wesley ISBN 0-201-82467-1. [5] N. Cowan. \nThe Magical Number 4 in Short-term Memory: A Reconsideration of Mental Storage Capacity. In Behavioral \nand Brain Sciences, Vol. 24, No. 1. (February 2001), pp. 87\u00ad 185. (2001) [6] O. Dahl, E. Dijkstra, C. \nA. R Hoare. Structured Programming (1972). Academic Press. [7] A. Didierjean, and F. Gobet. Sherlock \nHolmes An expert s view of expertise. In British Journal of Psychology 99: 109 125 (2087). [8] D. K. \nDirlam. Most efficient chunk sizes. In Cognitive Psy\u00adchology, 3:355 359, 1972. [9] M. Fowler, K. Beck, \nJ. Brant, and W. Opdyke. Refactoring: Improving the Design of Existing Code (1999). Addison-Wesley ISBN \n0-201-48567-2. [10] D. Gentner. Structure-mapping: A theoretical framework for analogy. In Cognitive \nScience, 7, pp 155-170 (1983). [11] F. Gobet. Discrimination Nets, Production Systems and Se\u00admantic Networks: \nElements of a Unified Framework (1996). http://people.brunel.ac.uk/~hsstffg/papers/UnifiedFramework/ \nUnifiedFramework.html. [12] F. Gobet, P. C. R. Lane, S. Croker, P. C-H. Cheng, G. Jones, I. Oliver, and \nJ. M. Pine. Chunking mechanisms in human learn\u00ading. In TRENDS in Cognitive Sciences, 5, 236-243. (2001). \n[13] Gamma, Helm, Johnson and Vlissides. Design Patterns: Ele\u00adments of Reusable Object-Oriented Software. \n(1995). Addison-Wesley ISBN 0-201-63361-2 [14] Douglas R. Hofstadter. Analogy as the Core of Cognition. \nIn Dedre Gentner, Keith Holyoak, and Boicho Kokinov (eds.) The Analogical Mind: Perspectives from Cognitive \nScience, Cam\u00adbridge, MA: The MIT Press/Bradford Book, 2001, pp. 499 538. [15] K. J. Holyoak and P. Thagard. \nThe Analogical Mind (1997). http://cogsci.uwaterloo.ca/Articles/Pages/Analog.Mind.html [16] J. N. MacGregor. \nShort-term memory capacity: Limitation or optimization? In Psychological Review, 94(1):107 108, 1987. \n[17] George A Miller. The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing \nInforma\u00adtion. In The Psychological Review, 1956, vol. 63, pp. 81-97 (1956) [18] H. Mills, R. Linger, \nA. Hevner. Principles of Information Sys\u00adtem Design and Analysis (1986). Academic Press. [19] G. Myers. \nComposite/Structured Design (1978). Van Nostrand Reinhold. [20] M. Page-Jones. The Practical Guide to \nStructured Systems Design (1988). Yourdon Press. [21] T. Stafford, M. Webb. Mind Hacks (2004). O'Reilly \nISBN 0\u00ad596-00779-5 [22] P. Van den Broek, K. Risden, Y. Tzeng, T. Trabasso, and P. Brasche. Inferential \nquestioning: Effects of comprehension of narrative texts as function of grade and timing. In Journal \nof Educational Psychology, 93(3): 521-529 (2001). [23] N. Wirth. Program Development by Stepwise Refinement \n(1983). In Communications of the ACM vol. 26(1). [24] N. Wirth. Algorithms and Data Structures (1986). \nPrentice-Hall. [25] E. Yourdon, L. Constantine. Structured Design (1979). Pren-tice-Hall.  \n\t\t\t", "proc_id": "1640089", "abstract": "<p>This paper demonstrates how the cognitive model of the mind can explain the core fundamentals behind widely accepted design principles. The conclusion is that software design is largely a task of chunking analogies and presents a theory that is detailed enough to be accessible to even the most inexperienced programmer. The corollary of which is a pedagogical approach to understanding design principles rather than the necessity of years of software development experience.</p>", "authors": [{"name": "Thomas Mullen", "author_profile_id": "81444602025", "affiliation": "Self, London, United Kingdom", "person_id": "P1728810", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1640089.1640126", "year": "2009", "article_id": "1640126", "conference": "OOPSLA", "title": "Writing code for other people: cognitive psychology and the fundamentals of good software design principles", "url": "http://dl.acm.org/citation.cfm?id=1640126"}