{"article_publication_date": "10-25-2009", "fulltext": "\n An Exploration of Program as Language Elisa Baniassad and Clayton Myers Department of Computer Science \nand Engineering Chinese University of Hong Kong {elisa, clayton}@cse.cuhk.edu.hk Abstract In this paper \nwe explore the idea that the code that consti\u00adtutes a program actually forms a higher-level, program \nspe\u00adci.c language. The symbols of the language are the abstrac\u00adtions of the program, and the grammar \nof the language is the set of (generally unwritten) rules about the allowable com\u00adbinations of those \nabstractions. As such, a program is both a language de.nition, and the only use of that language. This \nspeci.city means that reading a never-before encountered program involves learning a new natural language, \nand that porting code from one program to another requires trans\u00adlation from one natural language into \nanother. We suggest that the complexity and depth of the program language is af\u00adfected by the gap between \nthe program semantics (what the program is meant to do) and the code semantics (the way in which the \nmachine runs). We believe that in seeing that programs are languages, we gain new insight into our own \nexperience as programmers, and are able to gain new per\u00adspective on the intense complexity of code and \nits creation. Categories and Subject Descriptors D.3.2 [Programming Languages]: Language Classi.cations \nGeneral Terms Languages Keywords Program Language 1. Introduction Consider the piece of code in Figure \n1. As programmers, we have the basic skill of being able to interpret what the code is doing. It begins \nby getting a username, then it gets a password, then, if that fails, it sends an email, probably with \na password reset link. We feel we are able to do this interpretation because we know the language in \nwhich the program is written, or that Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. OOPSLA 2009, October 25 29, 2009, Orlando, Florida, USA. Copyright c \n. 2009 ACM 978-1-60558-734-9/09/10. . . $10.00 void check_account(){ string username; string password; \nstring email; username = get_username( ); if (username){ password = get_password( ); if (!password){ \nemail = get_email( ); send_reminder(email); } } } Figure 1. Simple Example we at least know one like \nit. But actually, the code does not use a tremendous number of the primitive elements of the underlying \nprogramming language. It uses its syntax, certainly, but the abstractions themselves are all formed by \nthe programmer. So while we can see at a glance what the code does, there is also higher-level information \nbeing conveyed. For instance, in this piece of code, all the variables are declared separately, and have \ntheir own names. Something as simple as this conveys that they will be altered individ\u00adually. Reorganizing \nthem into a list would give a different implication, even though logically it would be the same. A list \nimplies sweeping changes, or at least, the affordance of iteration. The original designer of this code \ndid not want to suggest that these variables were dependent on one another, or were part of a set. Therefore, \nthey are independent. Per\u00adhaps it also implies that this is a complete list of variables. Adding one \nis implicitly discouraged, or at least would re\u00adquire deeper thinking about the semantics of the program. \nAdding a phone number variable, for example, would need to be well-motivated. Placing these variables \nin a list might make it feel too easy to extend the bounds of the list, and thus add another variable \nwithout the needed thought. Such a change might cause maintenance headaches down the road, or be at odds \nwith the way another part of the program is organized. Additionally, we can see from the names of the \nsymbols that they should be processed in a particular or\u00adder. The username and password variables implicitly \ngo together. Not formally, but based on out knowledge of what this program probably does. The email variable \nis slightly separate from that pair.  So the program contains a set of instructions to the ma\u00adchine \nwritten in a programming language that a compiler un\u00adderstands, but also a set of implicit rules about \nthe usage of the abstractions that the programmer understands. That sec\u00adond set of rules and symbols \nis what we call the program language. 2. Content A programming language is a particular formalism for \ncom\u00admunicating a computation to a machine. For programmers to communicate with each other, they must \ngo outside the pro\u00adgramming language. They do this in many different ways, as we will discuss below, \nbut in each particular program, these ways must form a coherent whole that can be read by other programmers. \nIn this way, programs de.ne program languages: ways of expressing meaning to other humans, not to the \ncompiler. Humans clearly have a different relationship to code than does a compiler. Compilers only need \nto translate the code into something that runs. Programmers, however, have to be able understand the \ncode, to add new code that adheres to the requirements of stakeholders, modify existing code without \nbreaking it, and predict how future modi.cations might take shape. Thus, while programming languages \nare created for communication between the programmer and the computer, the program language captures \nall the information and convention that is needed by the programmer. 2.1 You Are Not A Compiler Consider \nthe simplest concept: the naming of the abstrac\u00adtion. We are taught to give meaningful names. Meaningful \nto whom? To ourselves, and to other programmers. This ex\u00adpression is generally thought of as a means \nto ease the task of the programmer, so that they don t have to say the same low level things over and \nover again. But this is a simpli.ca\u00adtion of what s actually happening when a new abstraction is created. \nProgrammers working on a large system communi\u00adcate with each other, and, across time, with themselves. \nThe substance of this communication may include the function or motivation behind parts of the code, \nnon-local interac\u00adtions between parts of the system, information about how the code will or may be changed, \nand so forth. In short, pre\u00adcisely those aspects of the system s description that are not obvious, through \nthe programming language, to the com\u00adpiler. In terms of semantics, code goes beyond its execu\u00adtion. It \nis far more than just what it does. The code itself is a means of communication between programmers, \nand a mechanism for a programmer to communicate with himself. quicksort [] = [] quicksort (x:xs) = quicksort \n[x | x <-xs, x < s] ++ [s] ++ quicksort [x | x <-xs, x >= s] Figure 2. Quicksort In Haskell If this weren \nt the case, wouldn t we program in 1 s and 0 s and just write notes to ourselves in comments? Even then, \nwould the comments be understandable? Not without know\u00ading the language of this particular piece of code! \nWhen programmers read code, they do not read it in the same way the machine does. To the machine, the \ncode is necessarily a formal description of a computation. To humans, though, code is text written by \nother humans. The machine view or formal semantics must be kept in mind, but frequently the reader can \ntake shortcuts or draw additional inferences based on the fact that the code was written by another person, \nand can be assumed to have meaning in the everyday informal sense as well as the strict formal sense. \nConsider the simple program in Figure 2; it is frequently presented in Haskell [7] tutorials. The reason \nthis works as an illustrative example for teaching Haskell, is that the reader already knows the quicksort \nalgorithm. A reader un\u00adfamiliar with Haskell assumes that the name quicksort is not inappropriately applied, \nthat the snippet is a function that performs a particular algorithm, and that the code performs the algorithm \nin a straightforward way. Based on these as\u00adsumptions, the reader can start to imagine what the language \nsemantics must be for this code to behave as intended. It is important to emphasize that if the reader \ntried to model the code in a strictly formal way, they would be lost without knowing the exact language \nsemantics. That examples like this work is proof that programmers read code as people, not as compilers. \nThe quicksort examples in Figure 3A and Figure 3B are the same as one another, except that the one in \nFigure 3A has meaningful names, and the code in Figure 3B has been obfuscated. The code in Figure 3A \noffers up an explanation of what it does, and is so clear that it could almost serve as a pedagogical \ntool for teaching quicksort. The code in Figure 3B, on the other hand, is almost unintelligible. The \ncompiler, however, has no problem with either Figure 3A or Figure 3B. Both are just sets of (the same) \ninstructions that can be evaluated and subsequently carried out. We believe that in many cases programmers \nread code as human communication .rst, and formal speci.cation only second. This is certainly true for \njokes and code poems like the example in Figure 4 [1]. As with any joke, it is hard to pin down precisely \nwhat is funny about it. Perhaps it is funny because it is odd to think about the concrete mechan\u00adics \nof Santa s list-separation process. But whatever it is that makes it funny, the point we would like to \nmake here is that  void quicksort(int array[], int begin, int end) { if (end > begin + 1) { int pivot \n= array[begin], l = begin + 1, r = end; while (l < r) { if (array[l] <= pivot) l++; else swap(&#38;array[l], \n&#38;array[--r]); } swap(&#38;array[--l], &#38;array[beg]); sort(array, begin, l); sort(array, r, end); \n} } A: With meaningful identi.ers void foo(int x[], int y, int z) { if (z > y + 1) { int a = x[y], b \n= y + 1, c = z; while (b < c) { if (x[b] <= a) b++; else { int d = x[b]; x[b] = x[--c]; x[c] = d; } \n} int e = x[--b]; x[b] = x[y]; x[y] = e; foo(x, y, b); foo(x, c, z); } B: Obfuscated Figure 3. Quicksort \nin C code is being used to make a joke at all. The code actu\u00adally does what Santa needs it to do: it \nseparates the list into naughty and nice. But because it does it with symbols named according to the \nnursery rhyme, the code goes from being merely practical for Santa s purposes, to being actually hu\u00admorous. \nThis humor is evidence of the use of code as beyond a communication mechanism between human and computer, \nand instead as a means of communication between program\u00admers, about concepts that have only mildly to \ndo with the functionality of the code itself. Both of these examples rely on the existence of a formal \nmeaning to the code in addition to the human meaning. In the better !pout !cry better watchout lpr why \nsanta claus <north pole >town cat /etc/passwd >list ncheck list ncheck list cat list | grep naughty >nogiftlist \ncat list | grep nice >giftlist santa claus <north pole > town who | grep sleeping who | grep awake who \n| egrep bad|good for (goodness sake) { be good } Figure 4. Santa Claus is Coming to Town Haskell example \nthis is obvious, as the code is being used to suggest the formal semantics. Even the Santa Claus example, \nthough, would be pointless if not for the suggestion that the children s song is in fact being run on \na computer. The point of all this is that programs convey meaning to programmers on two levels, the formal \n(machine) and the informal (hu\u00adman), and that communication depends on coordination of meaning between \nthose two levels.  2.2 Dealing with Design If programmers use program languages to communicate about \nabstractions, the next questions are, Why do the pro\u00adgrammers need to talk about them? and What do they \nhave to say about them? One of the goals of program de\u00adsign, after all, is to reduce the program to components \nwhose desired behavior can be speci.ed only in terms of program\u00adming language semantics, and which therefore \ncan be inde\u00adpendently implemented by programmers who do not need to understand the rest of the program. \nIf this is true and design works, why would these programmers need to talk about program abstractions \nat all? The answer is twofold: .rst, design is, in practice, not quite perfect. Programmers frequently \ndiscover that they need to know more than expected about how the rest of the program works; it is often \nuseful to know why a component must behave in a certain way, and the answer ultimately de\u00adpends on what \nprogram abstractions the component is imple\u00admenting. And information about motivation and representa\u00adtion \nis the domain of the program language, not the program\u00adming language. Second, and much more importantly, \ndesign is not static. The program will need to change, and components will need to be added and modi.ed. \nExcept in the case of true bugs, the code cannot itself describe how it needs to change. It may provide \ninformation about how it can change easily: subclasses can be substituted for superclasses, methods can \nbe added to an interface, and so on. To know how to modify the code, however, and to know how the code \nshould be written in the .rst place so it can best be modi.ed later, it is again vital to know why the \ncomponent is designed that way it is. This means knowing about the program abstractions the code is implementing, \nso that coding decisions can be avoided which make sense in terms of code but not in terms of the meaning \nof the program. For this, again, a program language is necessary.  2.3 Communication of Theories In \nProgramming as Theory Building [6], Naur argues that in building a software artifact (a program), a programmer \nmust also build a theory of how certain affairs of the world will be handled by, or supported by, a computer \nprogram . Possession of the theory is necessary for understanding and modifying the software; but signi.cantly, \nNaur asserts, the theory cannot be expressed in terms of rules nor formally communicated. While the strictly \ncognitive components of theories in Naur s sense may be impossible to communicate, we believe that theories \nare precisely the content of program language communication. A program language can suggest a partic\u00adular \nmapping between formal and human-model elements through identi.er choice, idioms for accessing data struc\u00adtures, \nand many other methods. We discuss the particulars below; here we want to point out that what program \nlan\u00adguages communicate, things like abstraction boundaries and usages and the way programming-language \nabstractions re\u00ad.ect real-world abstractions, are the essential components of Naur s theories. This leads \nto one particularly useful consequence: pro\u00adgrams with coherent theories tend to have coherent program \nlanguages, and vice versa. 3. Form Now that we have explored what is communicated by pro\u00adgram languages, \nwe can look at their form and structural fea\u00adtures. Here, we make several points: First, we note that \nthe words or individual symbols in a program language are the abstractions de.ned by the programmer. \nWe discuss that the complexity of the symbols required to make a program language word is affected by \nthe underlying language.  Second, we believe that the syntax of any one program language is generally \nnot formally de.ned, but, at a hu\u00adman level, understood.  Third, we believe that the program language \ncomprises the gap between the human-level understanding of what the program does, with the machine-level \nunderstand\u00ad  ing of how the program is carried out. We also as\u00adsert that again, programming language \ncomplexity is in\u00adversely proportional to program language complexity. Finally, we argue that each program \nde.nes distinct language; no two programs share a program language. Hence, program languages are unique \nand self-de.ning. 3.1 Words Grammatically speaking, symbols (terminal and non-terminal) are the building \nblocks of language. Through the process of software design and creation, new symbols are introduced: \nidenti.ers, abstractions, etc. Abstractions, espe\u00adcially when they are built outside the declarative \nlimits of a programming language, form the program language. This is especially true if you reject the \nidea of a single absolute taxonomy of abstraction: abstractions naturally overlap and con.ict, so the \nchoices made in one program will probably not match those made in another, even if the abstractions purport \nto be identical. Radicals in a language refer to the root concepts , and are the basic building blocks \nof words. There are two parts of the de.nition of radicals: they are language elements that correspond \nto concrete abstractions. Consider the second part, that radicals correspond to concrete abstractions. \nWhat is concrete in the context of a program language? Of the program semantics abstractions, the most \nconcrete from a linguistic point of view are those that can be most easily mapped into the programming \nlanguage abstractions. For ex\u00adample, a buffer that corresponds almost example to a queue datatype. Program \nlanguage radicals, then, are the language elements (words, graphemes) that correspond to these ab\u00adstractions. \nSince the words and graphemes of a program lan\u00adguage are the expressions of the programming language, \nthe obvious candidates for program language radicals are the ex\u00adpressions comprising the interface of \nthe concrete abstrac\u00adtions. For the very simplest abstractions, such as lists and strings, that also \ndo appear as programmer (program se\u00admantics) abstractions, the radicals themselves can serve as words. \nFor instance, we can access the simplest pro\u00adgram abstractions directly by manipulating code abstrac\u00adtions. \nFor more complicated program abstractions that are simulated by families of code abstractions (multiple \nclasses or datatypes, etc.), we need to combine the basic interface expressions to build meaningful words \nlocking and un\u00adlocking around a critical section, maintaining an invariant by removing an object from \none data structure and adding it to another. It may even be possible to distinguish between derivational \nor compound words (expressions that combine multiple interfaces into a single operation) with more com\u00adplex \ngrammatical constructs (standalone expressions appear\u00ading in sequence). The size of the word, however, \nis also affected by the un\u00adderlying language: how many separate symbols does it take make a statement \nin a program language? In Haskell, for in\u00adstance, more of the program abstractions can be expressed directly \nas code abstractions; this is even more true when combined with mathematically minded programmers. This \nmeans that the program language (for high-level program\u00adming languages) is composed more of radicals, \nand less of compound words ; this makes individual words in the lan\u00adguage more synthetic and complex, \nbut also decreases the need for complex uses of the program language. The higher\u00adlevel the concepts that \ncan be expressed in the programming language formalism, the less remains for the informal pro\u00adgram language \nto handle.  3.2 Syntax Grammar is what transforms a collection of symbols into a language. The symbols \nwork together in particular ways: one cannot arbitrarily combine symbols. We believe that program languages \nadhere to a natural language grammar, which is derived from the rules for com\u00adbining the abstractions \nthey de.ne. They might use juxtapo\u00adsition of primitive concepts in the programming language as a means \nof communication. We know that programming languages conform to context\u00adfree grammars. We know precisely \nthe syntax and semantics of the statements in a programming language. On top of the programming language \nare the programmer s abstractions. These also have syntax and semantics in terms of their com\u00adbination \nand usage, though these rules are often not de.ned anywhere, and extend beyond the abilities of the type \nsys\u00adtem to impose constraints. Instead, these rules are captured in program-speci.c idioms, and made \nclear through subtle choices for the names of abstraction and based on program organizations. Consider \nthe common pattern of lock do stuff unlock. This is an idiom that is common across all interconnected \nprograms, and hence is not an artifact speci.c language element. However, it provides an analogy by which \nto show that there exists a certain grammar in programs themselves that is at a higher level than the \nprogramming language grammar. Its basic rules are: you cannot unlock when you don t have a lock; You \nshouldn t do stuff before you have a lock; You shouldn t lock and then immediately unlock, and then do \nstuff. If we were to write this in a context-free way, it would look like: <locked-code> :-<get lock> \n<do stuff> <unlock>  3.3 The Gap between What and How Program languages bridge the gap between what \nthe pro\u00adgram does, and an explanation for how the program does it. Most programmers can look at a program \nand see what it does, and thereby understand what we will now call its code semantics, and presumably \nall programmers know what the program or is supposed to do in terms of the overriding gen\u00aderal program \nmodel. The dif.culty is connecting the two, in matching up program semantics to code semantics. We be\u00adlieve \nthat this is the content of program language communi\u00adcation: how the code implements the program semantics. \nIn some cases the program semantics abstractions have a very close .t with code semantics, and so there \nis little need for complicated program languages. Consider a mes\u00adsage buffer being implemented by a queue. \nThe important elements of the program-semantics abstraction (things go in at one end, come out at the \nother, and the things are all mes\u00adsages ) are likely all handled by the type system and data structure \nde.nition, so there is not much left to say; the rela\u00adtionship can be established quite tersely. But \nfor more complicated program-semantics abstrac\u00adtions that are not as good a match to code-semantics abstrac\u00adtions, \na lot more work and communication is necessary to show how the code implements the program. This is where \nidioms such as lock-order disciplines or related families of classes start to appear. The form of the \nprogram language, then, is the arrangement of language expressions that inter\u00adact with language expressions, \nbut the meaning of these ar\u00adrangements is in terms of program semantics. There are two interpretations. \nOne is that the content of the program language is the resulting mapping of pro\u00adgram semantics to code \nsemantics. In other words, when we read a set of language expressions, we learn how some part of the \nprogram semantics is mapped to code. In this way pro\u00adgrammers can be said to communicate with each other \nabout how to build the program. The other interpretation is that the content of the program language \nis simply the program semantics, and the program language is itself the mapping from program semantics \nto code semantics. In this interpretation, when we read a set of language expressions, we learn what \nthose expressions mean in terms of program semantics, in terms of the problem domain. This seems quite \nobvious, since we are used to thinking that way, but perhaps there really are two meanings. We are used \nto thinking that the meaning of code is obvious, that foo.beConfungedWith(bar.theOtherOne, 3, SomethingOrOther::NotThisOne) \nmeans, well, whatever it means in the same way that x+=1 means add one to x . But this is because we \nare used to knowing the program language already. This is why the experience of learning a new program \nis so strange. We see something like foo.beConfungedWith(...) above, and we think, I know what that means. \nWe are calling the method beConfungedWith on the object foo with the parameters blah blah blah. But, \nof course, although this is what the machine will do, we have no idea what any of it means in the sense \nthat we usually talk about meaning . The programming language gives us the machine mean\u00ading, but we need \nthe program language, the mapping of foo, and bar, and their relationship to meaningful concepts in the \nproblem domain, to actually understand the purpose of the code, and its human level pragmatics. In turn, \nwe need to understand the code s purpose in order to make any changes to it. For a simpler example, imagine \na line of code like num seconds += 1; . What does this mean? On the code level it means add one to the \nvariable num seconds (or, later it perhaps means increment register 9 ). But in terms of program semantics, \nit probably means something like ad\u00advance the clock . Those two meanings are fundamentally different. \nWe can learn the .rst from the programming lan\u00adguage de.nition and this line of code alone, but to learn \nthe second we have to know how num seconds will be used and interpreted elsewhere in the program.  It \nis possible that the higher-level the programming lan\u00adguage, the smaller the gap between what and how \nbecomes, and hence the less complex the program language need be. The more the high-level constraints \ncan be handled by the programs own type system, the more formally they can be encoded. This relieves \nthe programmer from having to em\u00adbed the program constraints and usage information implic\u00aditly in the \nsymbols and organization of the code.  3.4 Uniqueness A program de.nes a program language that is speci.c \nto it. Because each program is unique, each program language is also unique. The program then is both \nthe de.nition of the program language, and the sole use of that language. One of the ways we can see \nthat program languages are each distinct is through the problems of code migration between programs: \nthe semantics of migrated code tends to get lost in translation. In some cases, the same simple data \nmight just have dif\u00adferent identi.ers: currentTime, curTime, t, and so on. In other cases, with more \ncomplex classes or data structures, different versions of the same abstraction might have slightly different \ninterfaces. In natural languages, there is the con\u00adcept of false cognates: the same word appears in two \nlan\u00adguages, but means something (sometimes drastically) differ\u00adent. This might also happen when migrating \ncode: foo, or other generically named methods are likely candidates for false cognates between applications. \nTaking a method foo from one program and slotting it into another will probably result in code that, \ntechnically, runs, but that runs incorrectly due to the misinterpretation of the symbol foo. For program \nlanguage statements, constructed as se\u00adquences of programming language expressions, there are similar \ncases. We can imagine two programs maintaining local invariants in slightly different orders, remove \nfrom list A then add to list B, or add to list B, then remove from list A, or otherwise differing just \nin the arrangement of equivalent statements. At the most complex, the entire organization of a pro\u00adgram \nor subsystem might be completely different, requiring massive reorganization to any code to be migrated. \nInter\u00adparadigm translation would be the most fundamental exam\u00adple of the inability to shift code from \none context to another. Artifact-speci.c language is also found in works of art: works of art are the \nsole uses of the language they de.ne. A poem, for instance, de.nes its own language to convey meaning \nto the reader. Twas brillig, and the slithy toves Did gyre and gimble in the wabe; All mimsy were the \nborogoves, And the mome raths outgrabe. Jabberwocky, by Lewis Carroll The above verse is taken from Lewis \nCarroll s Jabber\u00adwocky [2]. Jabberwocky is written within a base language (English), but on top of that \nde.ned its own language, made up of new symbols (nonce words), and new rules for their combination. Poets \nare taught to insert into their poems the means for interpretation of those poems [3]. Certainly, Lewis \nCarroll, through design and juxtaposition of the nonce words, con\u00adveys meaning, even though most of the \nwords are new to us. And interpretation of the nonce words is only the .rst level of interpretation of \nthe poem. These words convey emotions, and context, and have historical signi.cance that have been analyzed \nfor a hundred years. No poem other than Jabberwocky can use the language of Jabberwocky. It could use \nits nonce words in the same way, but because of the shift of context, the new poem would be de.ning new \ninterpretations for these words. Hence, it would be creating a new language that, on its surface, looked \nvery much like the original. Famously, Andy Warhol made dupli\u00adcates of banana boxes, placed them in a \nmuseum, and called them art. This change of context, combined with the atten\u00adtion given to the preciseness \nof the duplication, was suf.\u00adcient to demand a new interpretation of these boxes, and in doing so, form \na new language. Programs within a particular domain often share many symbols. But because of the con\u00adtext \nof the use of these symbols, the human level interpreta\u00adtion of these symbols is program speci.c. The \ncontext of use might refer to the behavioral context of the code (the precise application), or might \nrefer to the programming conventions within which symbols are used and combined. When we look at programs \nas self-de.ning languages, we can see the activities around coding in a new light: program\u00adming is language \ncreation, program understanding is lan\u00adguage learning, and as stated above, code migration is trans\u00adlation. \nProgramming is Language Creation Designing, or creat\u00ading new code is, essentially, creating a new language: \nde.n\u00ading new abstractions, and new constraints for their combina\u00adtion. These constraints form the syntax \nof the language: the grammar. Since the language is formed implicitly, the better the programmer, the \nmore artful they will be when creating the language.  Maintaining code has a dual relationship to language: \nworking on an artifact written in an existing language, and also modifying and evolving the language \nitself. On one hand, the code maintainer has to understand the existing ab\u00adstractions in the code, and \nhas to understand the constraints in the code for how abstractions can be combined. On the other hand, \nthe code maintainer has to be able to alter the language of the code, alter its abstractions, reform \nits ab\u00adstractions, and create new rules for their combination. Program Understanding is Language Learning \nReading a new piece of code involves the same process as learning a language. The abstractions form new \nsymbols that need to be understood anew in every program. It is not prudent to assume that we know the \nmeaning of a particular abstraction because of its name. Of course, code is written in a partic\u00adular \nlanguage (the programming language), but merely un\u00adderstanding that language does not mean that a newcomer \nto a piece of code will understand it. They will need to learn about the abstractions in the code both \nby running it, but more importantly by performing an examination of the struc\u00adtures that make up the \nprogram. The task will involve ascer\u00adtaining the real boundaries of those abstractions, its compo\u00adnents, \nthe rules for combining abstractions and components, and the rules for adding new components and for \nmodifying existing components. When a programmer is faced with understanding a new piece of code, they \ngo about understanding it in a similar way to someone reading an artifact in a new language. They learn \nthe language: they start by understanding the symbols in the language, and then, they branch out to trying \nto under\u00adstand how they can .t together legally. Of course, program\u00admers understand the base language \n(or should) in which the code is written, and they understand related languages (other pieces of code). \nSo it is not hopeless for them to attempt to understand this new language. Instead, they make use of \nthe skill of learning a second, highly related, language. Similar to someone who understands Dutch trying \nto read something in Flemish. With some work, they will be able to decipher the text because the two \nlanguages are related though dis\u00adtinct, and they will learn Flemish in the process. When we arrive in \na new country, we do not immediately begin learning the entire language. We begin by learning conversational \nlanguage just enough of the language to tell a taxi driver when to turn left or right, or just enough \nto order coffee and then get the bill. Gradually we begin to branch out and learn more of the language \nso that we can say more complex things, and communicate with more people. The programming language equivalent \nof this is learning to write the hello world program in a new language. We start with something simple, \nand then branch out to more and more complicated stuff. But when the country into which we are dropped \nis actually an enormous piece of code, we follow the same routine. We start with learning only enough \nof the program to do something small, and then gradually build up our understanding of the abstractions \nto do more complex tasks. This process of program language understanding is com\u00adplex because it involves \nunderstanding the boundaries of abstraction. Abstractions are never perfectly aligned with programming \nlanguage concepts, and hence are not fully formally described. When abstractions are large, or heav\u00adily \nconnected with other abstractions, this their meaning be\u00adcomes more nuanced, and more dif.cult to ascertain. \nCode Migration is Translation As we said earlier, inter\u00adprogram code migration is an act of translation, \nbetween dis\u00adtinct, though perhaps highly related languages. The dif.culty of this activity is a symptom \nof program language unique\u00adness. This dif.culty is not felt when moving text within a program, as evidenced \nby the near pathological degree to which copying and pasting of code within an application oc\u00adcurs. Meaning \npreserving translation in natural languages is highly non-trivial. A piece of text containing both snippets \nof Chinese and English would only be understandable to those who spoke both languages. But because it \nis straightforward to visually distinguish between English and Chinese text, the translator would at \nleast be able to keep track of which por\u00adtions were left un.nished. In program languages, however, the \ntext of the source and target program languages look more or less the same. When taking a piece of code \nfrom one program to another, it is not clear which portions can be left in tact, and which need to be \nmodi.ed. Often, an it\u00aderative process of trial and error is used to test whether the migrated code has \nthe desired semantics. 4. What Program Language is Not In order to argue for the existence of program \nlanguages, we need to separate those linguistic features of programming languages that may be present. \nThe existence and meaning of program identi.ers (symbols) and programming language syntax is obvious \nand unremarkable. 4.1 Programming Languages Program languages are not equivalent to programming lan\u00adguages, \nor extensions to programming languages that in\u00adclude frameworks, API s, etc. Programming languages are \nobviously languages, with their own syntax and semantics. We re referring to the symbols that programmers \ncreate on top of the programming language, that they use to both con\u00advey information to the machine, \nbut equally importantly, to one another and themselves. Of course there are primitive symbols at the \nbottom, de.ned in a programming language, just as a programming language is operationally de.ned by its \ncompiler.  4.2 Code Semantics It is undeniable that programming languages possess more or less formally \nspeci.ed semantics, and yet, especially in early programming education, one sometimes sees asser\u00adtions \nthat programs have no meaning. How to reconcile this? For one thing, such assertions remind beginning \nprogram\u00admers that natural language references(meanings) for pro\u00adgram identi.ers, operators, and keywords \nhave no semantic signi.cance in the programming language. On another level, we can interpret this as \npointing out that programming languages are formal and arti.cial, with semantics de.ned only in terms \nof abstract formalism or machine behavior. In this regard, while language statements may be contextual \n(x+=5, for example), they do not have any pragmatics: the machine (abstract or concrete) extracts no \nmeaning from a statement beyond its formal semantics. When considering only formal semantics, the only \nway a programming language serves as a medium for human com\u00admunication is through a human modeling the \nmachine s be\u00adhavior. Here, however, we are drawing a distinction between code semantics (or language \nsemantics) vs. program seman\u00adtics. Code semantics is what code means to the machine; program semantics \nis what code means to the programmer. The difference between this is an array object and this repre\u00adsents \nthe messages to be processed, or something similar to that. 4.3 Programmer Language Programmer language \nrefers to programming approaches, idioms and patterns that are common between programs: ways in which \nprogrammers encode information that is un\u00adderstandable regardless of which program you are reading. Program \nlanguages instead refer to any code construction that s not commonly termed an idiom or a design pattern, \nbut that instead falls into that scary zone of stuff about which we can t generalize between programs, \nbut that still really really matters. 4.3.1 Code Semantics Code conventions are often held in common \nbetween fam\u00adilies of programs, and even between programs in general. Programmers, simply due to their \nshared educational back\u00adground, tend to follow some universal code conventions. The concept of meaningful \nidenti.er names is universal in all (readable) code. Names like index or validateInput are used, as opposed \nto the equally valid zX3 or ppppp. These suggest the intended use and contextual meaning of the iden\u00adti.er. \nThey can also establish a referent within the problem domain or model. We do not refer to the general \nconvention of intelligent naming itself when we put forward program language. A more program-speci.c \ntechnique is Hungarian nota\u00adtion [8]. Depending on the details of its use (Apps vs. Sys\u00adtems Hungarian), \nthis can build a system for associating meaning with identi.ers that differs from program to pro\u00adgram. \nHowever, this too is also more of a programmer lan\u00adguage than a program language, since it is a tool \nthat is used between programs in the same predictable way; only the identi.ers themselves differ. 4.3.2 \nIdioms Idioms are coding tricks that are common to many programs. Any networked program will have the \nlock dostuff unlock idiom in it. We are not talking about techniques like this that are common to many \nprograms. Instead, we refer to the combinations of concepts within a particular program that are special \nto that program. 4.3.3 Design Patterns There is de.nite overlap between design patterns and some components \nof program languages. Design patterns are, broadly speaking, higher-level abstractions than are directly \nexpressible in object-oriented languages, together with sam\u00adple implementations[4]. In that sense, design \npatterns might form a program language schemata, or possibly a sim\u00adple program language vocabulary. However, \nagain, because these structures are common to multiple programs, they are at the highest level programmer \nlanguages rather than pro\u00adgram languages. The implementations of the design patterns, and the symbols \nand conventions introduced to actually reify them in code, gets closer to program language, since it \nis program speci.c.  4.4 Domain Speci.c Languages It is particularly important to distinguish program \nlanguages from things like domain-speci.c languages that are for\u00admalisms unique to a particular program. \nThere are many ways in which programmers use abstractions to simplify the task of writing code, but at \nroot these are means of com\u00admunicating with the machine. Program languages denote precisely those aspects \nof code from which humans derive meaning differently from the machine. There are also levels of formality \nbetween programming languages and programs: domain-speci.c languages. Such programmer-de.ned abstractions \nare just as formal as under\u00adlying programming languages, though, so they too are dis\u00adtinct from program \nlanguages. In general, DSLs are created so that programmers can express their desired constraints or \nabstractions to the compiler. Once created, though, they provide another level of formalism on which \nprogram lan\u00adguages can be based. In this regard there is no distinction between domain-speci.c and general-purpose \nprogramming languages.  4.5 Literate Programming and Comments Literate Programming, as proposed by Knuth \n[5], empha\u00adsizes thinking about programs as primarily communicating their intent to humans, and only \nsecondarily specifying a computation. As such, there is a natural af.nity between the goal of literate \nprogramming and the effects of program lan\u00adguages. However, program languages are not a technique to \nbe employed, or not, in the construction of a program. The emergence of program languages is a direct \nconsequence of the fact that programs have informal bases and that program\u00admers think of their programs \nin informal ways.  For that reason, most literate programming techniques do not directly contribute \nto coherent or helpful program lan\u00adguages. Literate programming techniques tend to focus on comments \nand ease of documentation, and treat code purely as technical speci.cation. By .agging uses, conventions, \nor assumptions that are not (by implication: cannot be) ex\u00adpressed in the programming language, comments \nilluminate the model/program mapping. This helps to understand the program directly, certainly, but it \nalso functions as a sort of rosetta stone for the program language: what we see de\u00adscribed about a particular \npiece of code is probably (meant to be) communicated by that piece of code. For example, if a function \nde.nition is commented with a set of precondi\u00adtions, then we can read calls to that function as communicat\u00ading \nassertions about those preconditions. This leads to a type of common idiom: a set of operations to check \ncertain pre\u00adconditions, followed by a key call. If some of the checking operations are missing at a certain \ncall site, it communicates that some of the preconditions are already known to hold. If we encounter \nthis when reading the code, the program lan\u00adguage usage tells us something that the machine semantics \ndoesn t; if we encounter it when writing code, the program language meaning may suggest that we have \nmade an error. 5. Inline Sidebar: Programs are Works of Art, Not Works of Craft Earlier, we discussed \nthe similarity between works of art and programs, in that they both de.ne the languages in which they \nthemselves are written. Richard Stallman said: I would describe programming as a craft, which is a kind \nof art, but not a .ne art. Craft means making useful objects with perhaps decorative touches. Fine art \nmeans making things purely for their beauty. However, after examining the relationship between works \nof art and works of programming, we .nd we disagree, and in so doing propose a new boundary between art \nand craft: artifacts that comprise a unique, self de.ning lan\u00adguage are works of art; artifacts that \nare formed en\u00adtirely within an existing, externally de.ned language are works of craft. Each artistic \nartifact is its own language. An artist, in cre\u00adating a new artifact, is designing a language. The artifact \nit\u00adself contains the rules and guide for its interpretation. Every artifact must be interpreted separately. \nLooking at an artist s corpus can give clues about how to interpret each artifact within it, but it will \nnot mean that by understanding one work, you will understand all. Substitution misinterpretation is also \ntrue here. Bringing an element from one work into another will result in a misinterpretation of that \nelement. A stroke of red in one painting might symbolize blood in one painting, but love, hate, or an \nabstract representation of an emotion in another. This unique self-de.ning language mea\u00adsure can be objectively \napplied, and provides no judgement over the quality of the work of art in question. Artifacts of craft, \non the other hand, do not construct their own language. They work entirely within a language that is \nde.ned for them. They can adhere better to the language, or worse to the language, but they never add \nanything to the language (that would render the work artistic). Substitution does not result in misinterpretation. \nPerhaps some massage would be needed to integrate a symbol from one craft-work to another, but there \nwould not be a drastic failure to interpret the meaning of the transferred symbol in the new context. \nA leg of a chair will stay a leg of a chair, even if it is not a very practical one (too short; not strong \nenough; etc). It will not all of a sudden become a back of a chair, or take on new symbolic meaning. \nIn creating an artistic artifact, an artist will oscillate be\u00adtween language creation and usage, and \nhence between art and craft. In our de.nition, any artifact that comprises its new language is art, regardless \nof whether there are some portions within it that do not de.ne new language, and that instead just use \nit. So artistic artifacts will have within them elements of craft. The extent of a work of art is all \nthe arti\u00adfacts required to de.ne the language. This distinction has implications for how we view the \nact of programming. In a programming team, some program\u00admers might be crafters, while others are artists. \nSome are creating the language of the artifact (de.ning its abstrac\u00adtions, symbols, pragmatics, grammar), \nwhile others will sim\u00adply work within that. In this way we might draw a distinction between Database \nAdministrators, who design the schemas, versus Database programmers, who use them (that said, the code \nthey write might also de.ne new abstractions for their own purposes, meaning that they are creating artistic \narti\u00adfacts rather than pure craft artifacts). Programs as art not craft can explain why programs are \ndif.cult to completely quantify and thoroughly specify or model, except with themselves. It is not just \nthe fact that they are complicated, because we are able to model many complex things. It is that the \ncode does not conform to the predictability of a piece of craft, and instead contains qualities that \nare intangible, in the same way that art is intangible. 6. So? In this essay we have argued that programs \nthemselves form unique languages. We have illustrated this by examining the structures of language, and \naligning the properties of programs with those structures.  We believe that realization of program as \nlanguage is an important step forward in understanding more about our programs, and more about ourselves \nas programmers. Perhaps the view of program as language could moti\u00advate a new kind of speci.cation: showing \nthe BNF of the code itself, rather than of the programming language. This would give a new method of \ndescribing the code, rather than just looking at transactions, or structural and semantic abstraction \nrelationships. It would instead give substitution rules, and legal transformations within the code. Program\u00admers \ncould use this as a guide to understanding a new piece of code; they would have to update it once they \nhad changed the code so that it still re.ected the truth about the existing program s language. For large \npieces of code that rely on newcomers, program language could be captured in documents similar to lan\u00adguage \nlearning modules. That is not to say that good books on open source projects are not already like this: \nEclipse has several books that are somewhat like this. But authors could experiment with more intentionally \nusing language\u00adpedagogy approaches for describing the codebases. Perhaps authors could even write the \nnovice-programmer equivalent of the children s language book (La Chenille Qui Fait des Trous; La Oruga \nMuy Hambrienta, an Illustrated Guide to the Hungry Caterpillar Garbage Collector). Perhaps being more \naware of the fact that we are creating a language when we are programming could motivate a new approach \nfor design, and motivate new empirical studies efforts. It can help explain our experiences (the confounding \nexperience of trying to learn a new enormous piece of code), and may give us a new way to consider our \ntactics in future. 6.1 One Last Point Program languages highlight that program complexity is un\u00adavoidable. \nProgram languages are motivated by the same need for human-level abstraction as higher-level program\u00adming \nlanguages. (If this were not the case, would we not just program in 1s and 0s...?) But a complex, abstract \nprogram is a complex, abstract program regardless of the language in which it s written. So if the complexity \ndoes not come out in the program\u00adming language, it comes out in the program language. If we wanted to \nwrite a large, complex program directly in assem\u00adbly, it would require such a complicated program language \nfor people to understand it that it would be easier to learn and use a higher-level programming language \n(Greenspun s law!). This is not to say that program languages are undesirable! If we wanted to avoid \nprogram languages, we would have to build programming languages for every new program, and that is neither \npractical nor desirable. Instead, it seems as though the ideal may be programming languages that are \ncomplex enough to allow for reasonable program languages, without being so complex as to be over-specialized \nor im\u00adpossible to learn. Acknowledgments We would like to thank the anonymous reviewers for their in\u00adsightful \nand helpful comments. We would also like to thank Yvonne Coady and Siobh\u00b4 an Clarke for their encouragement \nin writing this essay. Finally, we would like to thank Richard P. Gabriel for shepherding the essay into \nits current form. References [1] Anonymous. The Nerd Xmas Carol, 1998. rec.humor.funny. [2] Lewis Carroll. \nAlice s Adventures in Wonderland. Oxford University Press, April 1865. ISBN 0199536341. [3] Richard P. \nGabriel. Personal communication. [4] Erich Gamma, Richard Helm, Ralph Johnson, and John Vlis\u00adsides. Design \npatterns: elements of reusable object-oriented software. Addison-Wesley Professional, 1995. [5] Donald \nE. Knuth. Literate Programming (Center for the Study of Language and Information -Lecture Notes). Center \nfor the Study of Language and Inf, June 1992. ISBN 0937073806. [6] Peter Naur. Programming as theory \nbuilding. Journal of systems architecture : JSA : the Euromicro journal, 15(5):253+, 1985. [7] Simon \nPeyton-Jones. Haskell 98 Language and Libraries. Cambridge University Press, 2003. [8] Charles Simonyi. \nHungarian Notation. November 1999.    \n\t\t\t", "proc_id": "1640089", "abstract": "<p>In this paper we explore the idea that the code that constitutes a program actually forms a higher-level, program specific language. The symbols of the language are the abstractions of the program, and the grammar of the language is the set of (generally unwritten) rules about the allowable combinations of those abstractions. As such, a program is both a language definition, and the only use of that language. This specificity means that reading a never-before encountered program involves learning a new natural language, and that porting code from one program to another requires translation from one natural language into another. We suggest that the complexity and depth of the program language is affected by the gap between the program semantics (what the program is meant to do) and the code semantics (the way in which the machine runs). We believe that in seeing that programs are languages, we gain new insight into our own experience as programmers, and are able to gain new perspective on the intense complexity of code and its creation.</p>", "authors": [{"name": "Elisa Baniassad", "author_profile_id": "81414615851", "affiliation": "Chinese University of Hong Kong, Hong Kong", "person_id": "P1728821", "email_address": "", "orcid_id": ""}, {"name": "Clayton Myers", "author_profile_id": "81414610905", "affiliation": "Chinese University of Hong Kong, Hong Kong", "person_id": "P1728822", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1640089.1640132", "year": "2009", "article_id": "1640132", "conference": "OOPSLA", "title": "An exploration of program as language", "url": "http://dl.acm.org/citation.cfm?id=1640132"}