{"article_publication_date": "10-25-2009", "fulltext": "\n The Mythical Matched Modules Overcoming the tyranny of in.exible software construction Stephen Kell \nUniversity of Cambridge Computer Laboratory 15 JJ Thomson Avenue Cambridge, CB3 0FD United Kingdom Stephen.Kell@cl.cam.ac.uk \nAbstract Conventional tools yield expensive and in.exible software. By requiring that software be structured \nas plug-compatible modules, tools preclude out-of-order development; by treat\u00ading interoperation of languages \nas rare, adoption of innova\u00adtions is inhibited. I propose that a solution must radically separate the \nconcern of integration in software: .rstly by using novel tools specialised towards integration (the \nin\u00adtegration domain ), and secondly by prohibiting use of pre\u00adexisting interfaces ( interface hiding \n) outside that domain. Categories and Subject Descriptors D.2.3 [Coding Tools and Techniques]; D.2.12 \n[Interoperability] General Terms Languages  1. Introduction Software is expensive: expensive to develop, \nand expensive to modify or change because of its inherent in.exibility.By the latter I refer both to \nthe dif.culty of maintaining software and also to software s tendency to grow in silos.Software grows \nas islands of functionality, founded on infrastructure including programming languages, UI toolkits, \ndevelopment frameworks , extensible applications (browsers like Fire\u00adfox, editors like Emacs) and so \non. The same functionality is frequently found replicated across many silos of a given class, at considerable \nexpense this is strong evidence for the underlying in.exibility of software. To .x these prob\u00adlems requires \nchanges to both tools and practices where these two are highly interdependent. Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA 2009, October 25 29, 2009, Orlando, \nFlorida, USA. Copyright c &#38;#169; 2009 ACM 978-1-60558-768-4/09/10. . . $10.00 Toolchains encompassing \ncompilers, linkers, stub gen\u00aderators and more have grown organically into a design which informs much \nof common practice. However, this de\u00adsign originates from an idealised conception of development as an \nactivity with central planning (enabling coordination of interfaces among cooperating modules), linear \nprogress (enabling depended-upon interfaces to be .nalised before their dependents are coded) and perfect \nanticipation (ensur\u00ading that earlier decisions need never be reversed). Unfortu\u00adnately, the resulting \ntools embody several false assumptions, giving them designs optimised towards building in.exible, siloed \nsoftware, and which penalise the development of .ex\u00adible and easily-interoperable software. However, \nwhen con\u00adsidered from afar, these assumptions are absurd. Speci.cally, I identify and refute the following \nlatent assumptions: that software is structured as plug-compatible modules, grown in order from low-level \ndependencies upwards;  that language interoperation is an exceptional case;  that information hiding \nis a suf.cient strategy against coupling.  I will argue that simpler and more .exible software is pos\u00adsible \nwith tools designed in conscious avoidance of these as\u00adsumptions. Speci.cally, I propose a radical two-step \nchange in tools and practices of software construction: an integration domain there is a fundamental \nneed for languages and tools specialised towards composition of software, and moreover, these should \nnot resemble con\u00adventional languages;  the practice of interface hiding information hiding should be \nextended to a new level in which components are constructed while purposely and completely ignoring the \ninterfaces of all foreign components, and where this is enforced by tools.  I begin by reviewing the \nconcept of the integration con\u00adcern, which will underpin most of the subsequent discussion.  2. The \nintegration concern All useful software has some interaction with its environ\u00adment. Even if simply printing \nout a response, returning an exit status, or adjusting some output signal, software is never an island. \nAs such, software incorporates knowledge, or as\u00adsumptions, about the nature of its environment what inter\u00adaction \nmechanisms are available, and what conventions are to be adopted in their use. Mechanisms might include \nproce\u00addure calls or byte-stream communication, and conventions include the signatures of those procedures \nor the syntax of the valid byte-stream exchanges (together with semantics in both cases). It is not possible \nto interact without some such assumptions; these are a fundamental and recurring hindrance to software, \nin that they are precisely the source of coupling. The same functionality can be useful in many different \nenvironments. For example, a spell checker might be some\u00adhow useful in a word processor, an e-mail application, \na batch document processor or a voice recognition engine. Of course, the developer must inescapably assume \nsome envi\u00adronment in order to write code. The common result is soft\u00adware that is strongly coupled to \none speci.c environment consisting of whatever pre-existing components the devel\u00adoper preferred or knew \nabout. Consequently, reimplementa\u00adtion abounds: similar functionality is replicated for each op\u00aderating \nsystem, each programming language, each desktop environment, each text editor and so on.1 I refer to \ncode s embodied knowledge or assumptions about the environment as integration details, and to their collected \nintent within a piece of software as the integra\u00adtion concern. To avoid the expense of reimplementation, \nwe would clearly like to separate the concern of integration, by modularising integration details separately \nfrom functional\u00adity as far as possible. This will lessen the problem of cou\u00adpling and improve the .exibility \nof our software. However, in common practice this has only been pursued to a limited extent (albeit an \nimportant one) in the practice of informa\u00adtion hiding [Parnas 1972]. This is a coupling minimisation \ntechnique: it limits how many decisions concerning the en\u00advironment are visible to a module. However, \nwe have es\u00adtablished that some coupling is unavoidable. There has been relatively far less progress on \nhow to mitigate, through tools and languages, whatever coupling cannot be eliminated. (As I will argue, \nwhat work does exist either provides only a clean-slate solution or presents inadequate abstractions.) \nIn domains other than software, separation of the integra\u00adtion concern is already established practice. \nFigure 1 illus\u00adtrates two of these pictorially. In circuit design, engineers do not expect that their \nintegrated circuits to be wired to\u00adgether directly with other ICs. Instead there is a whole vo\u00ad 1 Meanwhile, \nit also seems likely that a signi.cant proportion of the soft\u00adware industry is occupied by development \nof web interfaces, billing sys\u00adtems, business process models and various other common projects, each \ninstance overlapping substantially in functionality. Figure 1. Integration in circuit design and technical \nwriting cabulary of glue components, including resistors and ca\u00adpacitors and small logic arrays, constituting \na separate in\u00adtegration domain. Separating the integration concern simpli\u00ad.es the IC s design, reduces \ncost and improves .exibility with respect to other use contexts.2 As a second example, consider that \nin technical writing authors invariably de.ne their own terminology up-front without any obligation for \nconsistency with other authors.3 The primary concern is to choose a set of de.nitions convenient for \nthe author s work, meaning one which make the work precise and comprehen\u00adsible. The concern of integration \nis addressed separately the reader, when reviewing and comparing different pieces, is well accustomed \nto the need to relate differing de.nitions. Given these precedents, the ways of software seem bizarre. \nAs with separation of concerns generally, practice is highly dependent on tool support, which conventionally \nis ex\u00adtremely limited [Tarr et al. 1999]. In the following section I will examine the assumptions in \nexisting toolchains and resulting practices. (Note that I am describing assumptions latent in the design \nof tools not necessarily in the mind of any particular developer.)  3. Myths and realities 3.1 Plug-compatibility \nand in-order development Toolchains implicitly assume that software consists of mod\u00adules whose interfaces \nmatch directly and precisely. This de\u00adpends on the lemma that code providing some functionality exists \nbefore the code requiring that functionality at least to the extent that its interface is known. For \nexample, when using libraries, clients of a library are written after the in\u00adterface of that library \nis determined, so that they can tar\u00adget that interface in a plug-compatible way.4 The in-order myth is \nsubject to the classic caveat that it works only if we make correct judgements ab initio which continue \nto hold 2 It is no coincidence that with ICs there is a very tangible cost to on-chip complexity, whereas \nin software the cost of added complexity from mixing integration concerns appears more abstractly (in \npayroll, downtime, etc.). 3 Although agreement is of course helpful, writers would .nd it far too restrictive \nto be limited to preexisting de.nitions. 4 Usually interfaces change often enough through early evolution \nof a com\u00adponent s implementation that in practice, much of the target component must exist before a stable \nimplementation of any client can be produced.  time 2005 2003 2001 1996 1993 Figure 2. In-order growth \nof software stacks. over time. It is clearly falsi.ed by evolution of interfaces, by decentralised development \n(essentially evolution in parallel) and by porting or retro.tting, which inherently concern in\u00adcompatible \ninterfaces. Cost Retro.tting tasks may seem rare, but they do happen. To pick one visible example, the \nentire KDE desktop suite recently migrated from the DCOP IPC system to D-BUS5,at huge effort. DCOP details \npervaded the source code of KDE applications, entailing huge changes. (It is also interesting that the \nstandardisation effort was motivated by the desire to interoperate between previously siloed applications, \nsuch as the GNOME desktop suite.) Tellingly, the less desirable alternative to porting, namely reimplementation, \nis anecdo\u00adtally more common despite obvious disadvantages. Research perspectives Previous authors have \nnoted the in-order assumption, sometimes called provider consumer asymmetry [Reid et al. 2000, Arbab \nand Mavaddat 2002]. In-order development is common because targetting existing concrete interfaces is \nthe simplest and most expedient struc\u00adturing technique but there are others. Designs featuring intermediate \nabstraction layers are often devised, for exam\u00adple in libraries where multiple back-ends are anticipated.6 \nThese designs are inherently more resilient to changes in depended-upon code. It may therefore seem unreasonable \nto cite in-orderedness as a weakness of toolchains, when with more foresight a better design can be produced \nusing current tools. However, foresight is rare. Better tool support can enable better-abstracted designs \nnaturally, by default, rather than as a special case requiring up-front effort which is rarely made. \nThe key strategy, already proposed in prior research work [DeLine 2001] is a division of responsibility \nin toolchain design between functionality and integration. Vision Current practice is not our only concern. \nNot only might better tool support simplify existing development sce\u00adnarios, or enable more successful \ninstances of decentralised development or porting. More boldly, I claim it can also 5 http://dbus.freedesktop.org/ \n6 Textbook examples include cross-platform windowing toolkits such as wxWidgets, http://www.wxwidgets.org/ \nor Java s SWT, http://eclipse.org/swt. C ext ern i n t Foo foo ( char * ); Java foo . Foo f = new f \no o . Foo (); / / i m pl ic it Haskell import Foo ( f o o ) Python from foo import Foo Figure 3. Module \nimports implying homogeneity. cause paradigm shifts. Placing high-level tool support for in\u00adtegration \nand adaptation close to the user, for example within web application mashup platforms and browser extensions7 \nhas already led to added-value innovations8) which could not have been anticipated by the creators of \nthe underlying software. In my ultimate vision, the techniques I propose here could enable the same for \npotentially all software experienced users could straightforwardly mash together en\u00adtire applications \nor pieces thereof, to meet their desired func\u00adtionality, in a fuller realisation of the elusive Unix \nvision of user-de.ned compositions of functionality.  3.2 Homogeneity Figure 3 shows declarations of \nexternal modules in several different languages. In each case the foreign module ex\u00adposes equivalent \nfunctionality. Implicitly, that module must be written in the same language. Toolchain support when this \nis not the case comes as an ad-hoc selection of intricate and unwieldy language interoperability features. \nAs I will argue, their unwieldiness persists because of an unstated as\u00adsumption that such requirements \nare a rare exceptional case. Cost Are such requirements really rare? New program\u00adming languages continue \nto emerge, and are seen as a promising longer-term solution to the expense of software. However, adoption \nby practitioners lags far behind the state of the art. Other authors have already speculated on the rea\u00adsons \nfor this [Wadler 1998], but one key factor is the dif\u00ad.culty of incremental adoption. This is essential \nbecause it is rare to write an entire application from scratch. Unfor\u00adtunately, conventional treatments \nof inter-language linking have several weaknesses, rooted in the exceptional case assumption, which discourage \nmulti-language development. Firstly, there is no encapsulation of language decisions. If a foreign module \nis not de.ned in the same language, any import statements must betray this for example, in Java the native \nkeyword is required, in C an extern declaration, and in Haskell a foreign import declaration. This clearly \na failure of information hiding, yet is questioned little because of the exceptional case myth. Secondly, \nlanguage interoperability schemes such as Java s JNI [Liang 1999] or Haskell s FFI [Chakravarty et al. \n2002] are convoluted from the desire for a universal map\u00ad 7 e.g. Mozilla Ubiquity, http://ubiquity.mozilla.com/, \nGreasemonkey, http://www.greasespot.net/ 8 e.g. http://www.shiftspace.org/, http://www.housingmaps.com/ \n  ping between interface de.nitions in two languages that is, one de.ned for all interfaces and implementable \nfor all possible implementations allowed by those languages. This has little bene.t for the programmer, \nwho is working with speci.c interfaces and, in practice, probably interested in only a subset of conceivable \nlanguage implementations. (An interesting departure from universality is in the GNU imple\u00admentation of \nJava [Bothner 2003]. By foregoing universality, GCC provides CNI, a much more natural alternative to \nJNI.) Thirdly, C ia nearly always chosen as the unifying medium for expressing glue logic. A unifying \nmedium is clearly useful because it converts problem of size n2 mapping all languages to all other languages \ninto one apparently of size 2n. However, C is a poor uni.er: manual resource management, reliance on \nmutable storage and machine-and compiler-dictated object layout present a low-level medium for glue code, \nwhile the lack of run-time checks greatly complicates debugging. Joining two higher-level languages together \nis accordingly often special-cased (e.g. Jython9). Finally, it is telling that if some new language X \nis adopted, it is always accompanied by considerable reim\u00adplementation of tool functionality for X . \nConsider that practically every programming language has a lex-like tool. Why should this be? A lex-generated \nlexer, being a sepa\u00adrate module from its client, should be invokable from any client language, with the \nlanguage of the generated code an encapsulated concern.10 Research perspectives Much research work concentrates \non theoretical aspects of interoperability, by asking how reasoning mechanisms, such as type systems \nand run-time checks, can be extended to preserve their guarantees in the presence of foreign-language \nmodules [Wadler and Findler 2009]. This work is valuable but is not our concern here. Existing practical \napproaches are largely found in imple\u00admentations. Microsoft s CLR [Meijer 2002] de.nes an in\u00adtermediate \nabstraction, roughly par with an object-oriented garbage-collected language, and having standardised \ndata representations. This is a reasonable but clean-slate ap\u00adproach: it excludes all code lying outside \nthat standard. Generative tools are available to ease the task of creat\u00ading JNI and similar glue code. \nWrapper generators such as JunC++tion 11 generate proxies presenting a more natural in\u00adterface than that \nof the underlying interoperability interface (in this case JNI). Swig [Beazley 1996] provides an anno\u00adtation \nlanguage for customising the generated proxy s in\u00adterface, where annotations correspond to macros expanded \nwithin the C or C++ glue. These tools demonstrate the feasi\u00ad 9 http://www.jython.org/ 10 I chose lex \nnot yacc because lex has less need for semantic actions but the continued popularity of these tools designs \nis a mystery, given how they advocate such a thorough mixing of application logic with the concern of \nlanguage recognition. This contrasts with more modern approaches like Antlr [Parr and Quong 1995]). 11 \nhttp://codemesh.com/products/junction/ bility of taking code in some fairly relaxed natural style and \nthen, in a separate step, adapting that code to .t a different interface. However, both approaches are \nlimited: to speci.c languages (one side restricted C or C++) and in their .exi\u00adbility (either none, or \nin the case of Swig, to de.nition of new typemap macros a highly involved task, owing to the brittleness \nof macro expansions, the potential for feature interactions, and so on). Vision The homogeneity assumption \nmay appear unavoid\u00adable. One property of a language is that it de.nes a model of some universe. Therefore, \nperhaps by de.nition it cannot ex\u00adpress references to artifacts that lie outside that universe, in some \nother language. I call this the model problem , but it is not actually a problem. It is overcome by the \nability to in\u00adterpret one piece of code as if it were something else where de.ning interpretations of \nforeign code is a fundamental re\u00adquirement of integration. The universal mappings of in\u00adteroperability \nschemes are simply one interpretation from a wide space a space we would like to open up fully to the \nprogrammer. This concept of subjectivity [Harrison and Os\u00adsher 1993, Batory] appears throughout software.12 \nReferencing some foreign entity within code does not determine what that entity should be but only how \nit must appear. At present, toolchains13 do not support the inter\u00adposition necessary to effect this transformation \nfrom what to how compilers and linkers understand only one view of any given code, and tool support for \nde.ning and transform\u00ading views is lacking. The scope for such support is huge. Consider a command-line \ntool with its execve() interface. One interpretation of this interface shows execve() s argu\u00adments as \narrays of strings. Another shows them as a dis\u00adjoint union of options and typed arguments, re.ecting \nthe command s syntax. Tool support must permit stackable de\u00adscriptions of these interpretations, each \ndescribed in terms of lower-level conversions and rooted in primitives akin to atoi(). (As I will describe \nin Section 4, relations are one con\u00advenient abstraction for describing these and other instances of subjectivity.) \n 3.3 Doing better than information hiding Information hiding [Parnas 1972] is rightly considered a fundamental \nstrategy for reducing coupling between mod\u00adules. It is supported by all contemporary programming lan\u00adguages. \nAs described in Section 4, it minimises coupling by limiting the visibility of implementation decisions \nbetween modules. However, I have described how some coupling is inevitable. Conventional languages do \nnothing to mitigate that coupling: on whatever implementation decisions are ex\u00adposed, modules are expected \nto agree. Where incompatibili\u00ad 12 Network .lesystems are a classic example in operating systems, and \nthe adaptor pattern [Gamma et al. 1995] is well known in object-oriented programming. 13 ...and also \nruntime systems, including operating systems.  ties arise, the only recourse is to edit the code to \nregain com\u00adpatibility, or to code an adaptor.14 Cost When the plug-compatibility myth fails for exam\u00adple \nin porting tasks any coupling to an incorrect environ\u00adment must somehow be worked around. Invasive editing \nof code is common, but yields a fork or patchset which is highly syntactic and inherently fragile. Black-box \nadaptors are more modular, but are labour-intensive to create and, while less fragile, still nontrivial \nto maintain. Sometimes a mixture of both techniques is used for example in the KDE migration mentioned \nin Section 3.1, a black-box abstraction layer (QtDBus) was designed to resemble the earlier DCOP API, \nwhile still differing both abstractly in a few ways and concretely in many (including most function names). \nVision To continue the example, if KDE source code had been kept abstract and avoided embedding DCOP-speci.c \ndetails, invasive porting would have proved unnecessary. Perhaps the developers proceeded by imagining \nthat some minimally suf.cient IPC interface was available, ignoring the issue of whether any implementation \nwas available un\u00adtil later. Subsequently, a separate layer of software, mapping abstract KDE references \nto concrete DCOP or D-BUS refer\u00adences, would be required. As with information hiding, such a design requires \ndiscipline to keep the original code abstract. Just as tools enforce information hiding, so can tools \nen\u00adforce this stronger sense of modularity by preventing the import of any concrete interface, and using \nintegration tools to bridge the resulting gap between the abstract and the con\u00adcrete. The remainder of \nthis paper discusses techniques for realising this two-stage approach.  4. The integration domain what \nand why An integration domain is simply a set of languages or tools for performing integration of software. \nInformally, many ad-hoc special-purpose integration domains have emerged in conventional practice for \nexample scripting languages (like the Unix shell), patching tools (like Unix s di.)and stub generators \n(as in various RPC implementations [Birrell and Nelson 1984]). Each of these is highly specialised and \nhighly constrained, but hint at the more general and power\u00adful tools which my arguments so far have motivated. \nTwo questions remain: why are conventional programming lan\u00adguages not suf.cient for this domain, and \nwhat form should the alternative take? 4.1 An example: the Cake linking language I begin by giving an \nexample from my ongoing work of one tool, the Cake linking language compiler, which ful.ls a small part \nof the vision I have outlined. It is described more fully in an earlier short paper [Kell 2009]. Figure \n4 shows a fragment of Cake code relating function calls and the values they exchange across a mismatched \ninterface. 14 These are white-box and black-box approaches, respectively. switch . libgtk20 { /* old \ninterface . new interface */ gtk window set policy (win, shrink , grow, ) . ( if shrink then gtk window \nset size request (win, 0, 0) else void; if grow then gtk window set resizable (win, TRUE) else void ); \n(preview window ::) gtk signal connect object (i,d,c h, data) . g signal connect data ( i ,d,c h , data \n, null , {}); values { GtkWindow .GtkWindow { type as GtkWindowType .type as GtkWindowType; window has \nfocus . has focus ; auto shrink . const 0; use uposition . need default position ; use uposition . need \ndefault size ; use uposition . ( need default position || need default size ); }}}         \n         Figure 4. Relating function calls and data structures in Cake The details of the code \nare not important here, but I draw attention to several properties of the language. It is adopt\u00adable, \nlargely because it chooses a unifying abstraction al\u00adready satis.ed by substantial existing codebases \n(namely re\u00adlocatable object code). It complements component program\u00adming languages: plug-compatible compositions \ncan trivially be expressed as no-op Cake descriptions similar to linker invocations in a make.le. Once \nplug-compatiblity is violated or retro.tting is desired, Cake s adaptation features can be invoked. It \nis high-level, declarative and minimal: it simply expresses relations between runtime values, optionally \npred\u00adicated on the context in which they occur (including func\u00adtion calls, but extending to call contexts, \ncall sequences, sur\u00adrounding data structures and beyond). Why are these good properties? What makes Cake \nbetter than a conventional programming language for integration tasks? I now address these questions. \n 4.2 Why an integration domain? Glue code is different from other code. The split has been characterised \nin many ways: unstable versus stable [Nier\u00adstrasz and Achermann 2000], coordination versus compu\u00adtation \n[Arbab and Mavaddat 2002], or functionality versus packaging [DeLine 2001]. Here I argue speci.cally \nthat al\u00adternative languages are not only useful for notationally sep\u00adarating the integration concern, \nbut are essential for maxi\u00admally abstracting it. Expressivity and abstraction Component programming languages \nare a poor notation for adaptation tasks; they in\u00advariably offer the wrong abstractions or the wrong \nlevel of abstraction. Typically, adaptation logic is algorithmically simple. It de.nes few or no new \ndata types, few new func\u00adtions except for wrappers around existing ones, and likely makes relatively \nlittle use of looping or recursion. Rather, it is concerned with recognising and relating the interac\u00adFigure \n5. AST node frequencies in glue and non-glue code   tions de.ned by two existing mismatched interfaces. \nWhen written in conventional languages, it most often contains the following kinds of code: case analysis \n(pattern-matching, switch statements or if then else), data movement (by as\u00adsignment or parameter passing), \nmultiplexing and demul\u00adtiplexing, look-up tables, dynamic mappings (like dictio\u00adnaries or other key-value \nstores), simple computations (for re-encoding of messages; usually already found in libraries), simple \nbuffering, state machines, and (sometimes) concur\u00adrency control operations (like fork join patterns, \nthread wait conditions, and so on). A simple experiment lends some empirical credence to this assertion. \nFigure 5 shows relative frequencies of various syntactic features in C and C++ code from the gtk-theme\u00adswitch \nCake case study [Kell 2009]. One series measures the glue code (~8000 lines, partially autogenerated), \nthe other the main source code of the application (~1000 lines). Although the data is far from conclusive, \nnotice how loop constructs are relatively far less common in glue code, while switch and case statements \nappear more often. (The lower glue frequency of if and assignments is perhaps explained by the skewed \nnature of the adaptations required by this case study; clearly further experiments would be helpful.) \nUnfortunately, these are mostly features for which con\u00adventional languages are not optimised towards \nabstracting.15 Consider a language such as Java possibly a good choice for coding some set of components, \nbut it may be poor for adapting those same components, perhaps because it lacks pattern-matching or curried \nfunctions (for demultiplexing function calls). Meanwhile, a language such as Haskell, while having these \nfeatures, could be awkward if, say, some previously stateless adaptation logic was to be made stateful \nby addition of a state machine or dynamic map. (This is a 15 There is similarity between this set of \nprogrammatic features and the logic contained within a table-driven parser. Both are also examples of \ncode which are far more suited to being generated from a higher-level represen\u00adtation than being coded \nin a conventional language. Although recursive de\u00adscent, meanwhile, is a reasonable .t for conventional \nlanguages, choosing recursion as the means of expressing the grammar is far more constraining. complex \nchange to realise in Haskell because adding state requires profound changes to type annotations.) The \nargu\u00adment here is not that these are necessarily weaknesses in the languages, but merely that the languages \nwere designed for abstraction of algorithms and data structures, and not abstractions of relations among \nmessages or interactions. Automation and reasoning Being computationally sim\u00adpler than other code, glue \ncode is potentially more tractable for purposes of automatic reasoning and even automatic syn\u00adthesis. \nProtocol adaptation one of the most well-explored kinds of adaptation [Yellin and Strom 1997, Passerone \net al. 2002, Reussner 2003, Bracciali et al. 2005] is invariably implemented using only .nite-state abstractions \n(either in\u00adterface automata or replication-free pi calculus). This is strictly less powerful than a Turing-complete \nabstraction, but appears to be suf.ciently useful for a very wide range of tasks. Crucially, its lesser \ncomputational complexity makes it more amenable to automatic reasoning hence the auto\u00admatic or semi-automatic \nnature of the cited tools. In general this suggests that the computational power required in glue logic \nis, in a reasonable proportion of cases, likely to be less than Turing-powerful.16 Future work will no \ndoubt increase the space of synthesisable adaptation logic. Although it is likely that much of the overall \nspace will remain essentially a manual task (but still with the potential for better abstraction through \nimproved languages), keeping integration details separately modularised, and expressed in a purpose-built \nnotation, allows for constraining the computational power of the notation and increases the potential \nfor identifying and implementing synthesis and/or veri.cation techniques.  4.3 What: relations, not \nscripts or circuits Research work has proposed several new integration do\u00admains: coordination languages \n[Arbab and Mavaddat 2002], delta languages [Keller and Holzle 1998] and semantic patching tools [Padioleau \net al. 2008], linking languages [Reid et al. 2000], orchestration languages [Misra and Cook 2006] and \nformally grounded scripting languages [Acher\u00admann and Nierstrasz 2001]. Only time and experience can \ntruly prove the worth of these. However, scripting-style no\u00adtations alone are clearly limited, because \nthey are so simi\u00adlar to conventional languages. Dynamism alone cannot ab\u00adstract the integration domain; \nmeanwhile, the similarity will likely lead to leakage of application concerns into integra\u00adtion logic. \nDeltas and patches suffer from a restrictive sec\u00adond class conceptual asymmetry one cannot easily apply \na delta to a delta, say. Data-.ow networks as in Reo, while useful for scenarios where concurrency is \nparamount, are surprisingly dif.cult to design or explain17 and currently of\u00ad 16 The kinds of additional \nspeci.cations required by these techniques are already being incorporated into practical tools, and their \nbene.t is likely to outweigh any burden.[Barnett et al. 2005, Flanagan et al.] 17 Testament to this is \nthe dif.culty faced by Clarke et al [Clarke et al. 2007] in concisely explaining the operation of a very \nsimple exclusive  fer no means of expressing simple data-dependent behaviour (for example, rearranging \nthe .elds in a structured message). The choice of relations, as exempli.ed by Cake, has sev\u00aderal bene.ts. \nSimple relations on values are expressed in\u00adtuitively as pattern-matching. More complex relations can \nbe built up by incorporating contextual guards in patterns: contexts may be either spatial (e.g. relations \napplying only to values within certain function calls, or at certain points within a larger data structure) \nand temporal (relations spe\u00adcialised towards values as they occur within particular se\u00adquences of function \ncall exchanges this is protocol adap\u00adtation). Analogously with grammars, greater context depen\u00addency \ncan bring arbitrarily higher expressivity, but one hopes that a practically useful level of expressivity \ncan be reached using only a very restricted degree of context dependency.  5. Interface hiding Suppose \nan expressive integration domain is available. What strategy might best avoid coupling? My suggestion, \nstrange as it may seem, is to avoid directly importing any foreign in\u00adterface whatsoever. Similar to \nthe integrated circuits example in Section 2, each component may de.ne its own interface to the outside, \ndesigned to keep the component simple and comprehensible. It is a separate task, supported by integra\u00adtion \ntools, to glue components into a functional ensemble. 5.1 Motivational experiment complexity inheritance \nLatent in this argument is the assumption that targetting con\u00adcrete interfaces increases the complexity \nof code. Software depending on some concrete interface is clearly moulded by the details of that interface; \na more general or complex inter\u00adface may force the client to incorporate unwanted complex\u00adity, even if \nthat client exercises only a small subset of the library s functionality. If so, the client inherits \nthe complex\u00adity of the interface it targets. I conducted a small experiment to demonstrate this phenomenon. \nI used open source libraries to perform two different tasks one storage-oriented (writing a persistent \nkey-value set describing the program memory map) and one compu\u00adtational (video decoding). In each task \nthe same function\u00adality was implemented twice, using different C libraries the second chosen to be substantially \nmore complex (and more general) than the .rst, yet offering a similar level of abstraction. The library \npairs were .rstly libmpeg2 and .m\u00adpeg (comprising libavcodec and libavformat) and secondly Berkeley DB \nand sqlite s BTree interface. Table 1 presents simple summary measurements of the libraries public in\u00adterfaces, \nthe API subset (or slice ) exercised by the client, and the clients source code. The key observation \nis that the client of the more complex library is itself more complex. router circuit (page 4). The unintuitive \narrangement of channels is said to conspire to ensure exclusivity. 2 imprecise owing to undocumented \npublic private division 3 signature size =1+ number of in or out parameters 4 simple total of all public \n.elds 5 C library calls necessitated indirectly by API usage Table 1. Measurement of complexity inheritance \n 5.2 Mitigating complexity Using interface hiding, complexity inheritance clearly would not occur. Instead, \nthe additional complexity would appear in the integration domain. As I described in Section 4.3, there \nare two major reasons why this complexity can be better han\u00addled from such a domain: .rstly, the availability \nof higher\u00adlevel notations tailored to the task of relating corresponding interface elements, more suitable \nthan glue code; and sec\u00adondly, the potential for automatic or semi-automatic synthe\u00adsis of these descriptions. \n 5.3 Additional bene.ts of interface hiding A second payoff of interface hiding is in comprehensibility \nof client code. Since complexity is not inherited, substan\u00adtially more readable code may result. Separately, \ninterface hiding forces an explicit statement of requirements.Sym\u00admetric with explicit provides interfaces, \nrequires interfaces have been advocated by several component-oriented pro\u00adgramming practices [Councill \nand Heineman 2001] but have yet to appear in conventional practice. Interface hiding does not require \nextensive changes to any programming languages. Certain languages including Cand C++ already allow foreign \ninterfaces to be explicitly de.ned (e.g. by de.ning new prototypes rather than doing an #include of existing \nones). In other languages, some small changes will be necessary to separate the concepts of imports (implying \na foreign component already exists) from a declaration of a view onto the outside world. Tools also require \nthe teeth to enforce interface hiding. Analogously to the enforcement of private and protected modi.ers, \nthis requires prohibiting imports of concrete ex\u00adternal interfaces (except where explicitly overridden). \nClearly, there is a limit to how far interface hiding can be taken. Perhaps truly ubiquitous interfaces, \nlike POSIX, should not be hidden. There is also a risk that the program\u00admer will design an external interface \nwhich cannot be satis\u00ad.ed by any foreign components, or which unduly strains the expressivity of the \nintegration domain. In practice, no doubt some iteration will be required to .nd the optimal modular\u00adisation \nof logic between the integration domain and compo\u00adnent internals. These, and other practical questions, \nmust be the subject of future work.   6. Conclusions I have motivated a two-pronged redesign of software \ntools and practices with the goal of drastically improving the .ex\u00adibility of software, and ultimately \nreducing its cost. Firstly, we require an integration domain tools and languages spe\u00adcially designed \nfor integration of mismatched software, and different from conventional languages. Secondly, we require \npractices which exploit these tools to maximise separation of the integration concern interface hiding \nexploits the in\u00adtegration domain to reduce complexity of components and improve their .exibility. Acknowledgments \nI am grateful to D.J. Greaves, Andy War.eld, Yvonne Coady, Derek Murray, Alex Gurney and Alan Mycroft. \n References F Achermann and O Nierstrasz. Applications = components + scripts. In Software Architectures \nand Component Technology, pages 261 292. Kluwer, 2001. F Arbab and F Mavaddat. Coordination through channel \ncomposi\u00adtion. In Proc. Coordination, pages 21 38, 2002. M. Barnett, K.R.M. Leino, and W. Schulte. The \nSpec# program\u00adming system: An overview. Lecture Notes in Computer Science, 3362:49 69, 2005. Don Batory. \nSubjectivity and GenVoca generators. In ICSR 96. DM Beazley. Swig: An easy to use tool for integrating \nscripting languages with C and C++. In Proceedings of the 4th USENIX Tcl/Tk Workshop, pages 129 139, \n1996. AD Birrell and BJ Nelson. Implementing remote procedure calls. ACM Transactions on Computer Systems \n(TOCS), 2:39 59, 1984. P Bothner. Compiling Java with GCJ. Linux Journal, 2003. A Bracciali, A Brogi, \nand C Canal. A formal approach to compo\u00ad nent adaptation. The Journal of Systems &#38; Software, 74:45 \n54, 2005. M Chakravarty, S Finne, F Henderson, M Kowalczyk, D Leijen, S Marlow, E Meijer, and S Panne. \nThe Haskell 98 foreign func\u00adtion interface 1.0: an addendum to the Haskell 98 report, 2002. URL www.cse.unsw.edu.au/%7echak/haskell/ffi/. \nD. Clarke, D. Costa, and F. Arbab. Connector colouring I: Syn\u00adchronisation and context dependency. Science \nof Computer Pro\u00adgramming, 66(3):205 225, 2007. B Councill and GT Heineman. De.nition of a software component \nand its elements. In Component-based software engineering: putting the pieces together, pages 5 19. Addison \nWesley, 2001. R DeLine. Avoiding packaging mismatch with .exible packaging. IEEE Transactions on Software \nEngineering, 27:124 143, 2001. Cormac Flanagan, K. Rustan M. Leino, Mark Lillibridge, Greg Nelson, James \nB. Saxe, and Raymie Stata. Extended static checking for Java. SIGPLAN Not., 37(5). E Gamma, R Helm, R \nJohnson, and J Vlissides. Design patterns: elements of reusable object-oriented software. Addison-Wesley \nLongman Publishing Co., Inc. Boston, MA, USA, 1995. W Harrison and H Ossher. Subject-oriented programming: \na cri\u00adtique of pure objects. ACM SIGPLAN Notices, 28:411 428, 1993. Stephen Kell. Con.guration and adaptation \nof binary software components. In Proceedings of the 31st International Confer\u00adence in Software Engineering, \nMay 2009. R Keller and U Holzle. Binary component adaptation. In ECOOP 98, pages 307 329, 1998. S Liang. \nThe Java Native Interface: Programmer s Guide and Speci.cation. Addison-Wesley Professional, 1999. E \nMeijer. Technical overview of the common language runtime. language, 29:7, 2002. J Misra and WR Cook. \nComputation orchestration: A basis for wide-area computing. Journal of Software and Systems Model\u00ading, \n6:83 110, 2006. O Nierstrasz and F Achermann. Separation of concerns through uni.cation of concepts. \nIn ECOOP 2000 Workshop on Aspects &#38; Dimensions of Concerns, 2000. Yoann Padioleau, Julia Lawall, \nRen\u00b4e Rydhof Hansen, and Gilles Muller. Documenting and automating collateral evolutions in Linux device \ndrivers. In Proc. 3rd ACM SIGOPS/EuroSys Euro\u00adpean Conference, pages 247 260. ACM, 2008. DL Parnas. On \nthe criteria to be used in decomposing systems into modules. Communications of the ACM, 15:1053 1058, \n1972. T.J. Parr and R.W. Quong. ANTLR: A predicated-LL (k) parser generator. Software-Practice and Experience, \n25(7):789 810, 1995. R Passerone, L de Alfaro, TA Henzinger, and AL Sangiovanni-Vincentelli. Convertibility \nveri.cation and converter synthesis: Two faces of the same coin. In Proceedings of the International \nConference on Computer-Aided Design 2002, 2002. Alastair Reid, Matthew Flatt, Leigh Stoller, Jay Lepreau, \nand Eric Eide. Knit: Component composition for systems software. In Proc. of the 4th Operating Systems \nDesign and Implementation (OSDI), pages 347 360, 2000. RH Reussner. Automatic component protocol adaptation \nwith the CoConut/J tool suite. Future Generation Computer Systems, 19: 627 639, 2003. Peri Tarr, Harold \nOssher, William Harrison, and Stanley M. Sutton, Jr. N degrees of separation: multi-dimensional separation \nof concerns. In Proceedings of the 21st International Conference on Software Engineering, pages 107 119. \nACM, 1999. P Wadler. Why no one uses functional languages. ACM SIGPLAN Notices, 33:23 27, 1998. P. Wadler \nand R.B. Findler. Well-typed programs can t be blamed. In ESOP 2009, page 1. Springer-Verlag New York \nInc, 2009. DM Yellin and RE Strom. Protocol speci.cations and component adaptors. ACM Transactions on \nProgramming Languages and Systems, 19:292 333, 1997.   \n\t\t\t", "proc_id": "1639950", "abstract": "<p>Conventional tools yield expensive and inflexible software. By requiring that software be structured as plug-compatible modules, tools preclude out-of-order development; by treating interoperation of languages as rare, adoption of innovations is inhibited. I propose that a solution must radically separate the concern of integration in software: firstly by using novel tools specialised towards integration (the \"integration domain\"), and secondly by prohibiting use of pre-existing interfaces (\"interface hiding\") outside that domain.</p>", "authors": [{"name": "Stephen Kell", "author_profile_id": "81338488995", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P1728323", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1639950.1640051", "year": "2009", "article_id": "1640051", "conference": "OOPSLA", "title": "The mythical matched modules: overcoming the tyranny of inflexible software construction", "url": "http://dl.acm.org/citation.cfm?id=1640051"}