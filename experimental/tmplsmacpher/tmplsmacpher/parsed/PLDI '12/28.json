{"article_publication_date": "06-11-2012", "fulltext": "\n SuperC: Parsing All of C by Taming the Preprocessor Paul Gazzillo Robert Grimm New York University \n{gazzillo,rgrimm}@cs.nyu.edu Abstract C tools, such as source browsers, bug .nders, and automated refac\u00adtorings, \nneed to process two languages: C itself and the preproces\u00adsor. The latter improves expressivity through \n.le includes, macros, and static conditionals. But it operates only on tokens, making it hard to even \nparse both languages. This paper presents a com\u00adplete, performant solution to this problem. First, a \ncon.guration\u00adpreserving preprocessor resolves includes and macros yet leaves static conditionals intact, \nthus preserving a program s variability. To ensure completeness, we analyze all interactions between \npre\u00adprocessor features and identify techniques for correctly handling them. Second, a con.guration-preserving \nparser generates a well\u00adformed AST with static choice nodes for conditionals. It forks new subparsers \nwhen encountering static conditionals and merges them again after the conditionals. To ensure performance, \nwe present a simple algorithm for table-driven Fork-Merge LR parsing and four novel optimizations. We \ndemonstrate the e.ectiveness of our ap\u00adproach on the x86 Linux kernel. Categories and Subject Descriptors \nD.3.4 [Programming Lan\u00adguages]: Processors; D.2.3 [Software Engineering]: Coding Tools and Techniques \nGeneral Terms Languages, Algorithms Keywords C, preprocessor, LR parsing, Fork-Merge LR parsing, SuperC \n1. Introduction Large-scale software development requires e.ective tool support, such as source code \nbrowsers, bug .nders, and automated refac\u00adtorings. This need is especially pressing for C, since it is \nthe lan\u00adguage of choice for critical software infrastructure, including the Linux kernel and Apache web \nserver. However, building tools for C presents a special challenge. C is not only low-level and un\u00adsafe, \nbut source code mixes two languages: the C language proper and the preprocessor. First, the preprocessor \nadds facilities lack\u00ading from C itself. Notably, .le includes (#include) provide rudi\u00admentary modularity, \nmacros (#define) enable code transformation with a function-like syntax, and static conditionals (#if, \n#ifdef, and so on) capture variability. Second, the preprocessor is oblivious Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 12, June 11 16, 2012, Beijing, China. \nCopyright &#38;#169;c2012 ACM 978-1-4503-1205-9/12/06. . . $10.00  to C constructs and operates only \non individual tokens. Real-world C code re.ects both points: preprocessor usage is widespread and often \nviolates C syntax [14]. Existing C tools punt on the full complexity of processing both languages. They \neither process one con.guration at a time (e.g., the Cxref source browser [8], the Astr\u00b4 ee bug .nder \n[9], and Xcode refactorings [10]), rely on a single, maximal con.guration (e.g., the Coverity bug .nder \n[6]), or build on incomplete heuristics (e.g., the LXR source browser [20] and Eclipse refactorings [21]). \nPro\u00ad cessing one con.guration at a time is infeasible for large pro\u00adgrams such as Linux, which has over \n10,000 con.guration vari\u00adables [38]. Maximal con.gurations cover only part of the source code, mainly \ndue to static conditionals with more than one branch. For example, Linux allyesconfig enables less than \n80% of the code blocks contained in conditionals [37]. And heuristic algo\u00ad rithms prevent programmers \nfrom utilizing the full expressivity of C and its preprocessor. Most research focused on parsing the \ntwo languages does not fare better, again processing only some con\u00ad.gurations at a time or relying on \nincomplete algorithms [1, 3 5, 15, 19, 29, 31, 36, 41]. Only MAPR [33] and TypeChef [25, 26] come close \nto solving the problem by using a two-stage approach. First, a con.guration\u00adpreserving preprocessor resolves \n.le includes and macros yet leaves static conditionals intact. Second, a con.guration-preserving parser \nforks its state into subparsers when encountering static con\u00additionals and then merges them again after \nconditionals. The parser also normalizes the conditionals so that they bracket only complete C constructs \nand produces a well-formed AST with embedded static choice nodes. Critically, both stages preserve a \nC program s full variability and thus facilitate analysis and transformation of all source code. But \nMAPR and TypeChef still fall short. First, the MAPR preprocessor is not documented at all, making it \nimpossible to repeat that result, and the TypeChef preprocessor misses several interactions between preprocessor \nfeatures. Second, both systems parsers are limited. TypeChef s LL parser combinator library au\u00adtomates \nforking but has seven combinators to merge subparsers again. This means that developers not only need \nto reengineer their grammars with TypeChef s combinators but also have to correctly employ the various \njoin combinators. In contrast, MAPR s table\u00addriven LR parser engine automates both forking and merging. \nBut its naive forking strategy results in subparsers exponential to the number of conditional branches \nwhen a constant number of sub\u00adparsers su.ces. This paper signi.cantly improves on both systems and presents \na rigorous treatment of both con.guration-preserving preprocess\u00ading and parsing. In exploring con.guration-preserving \npreprocess\u00ading, we focus on completeness. We present a careful analysis of all interactions between preprocessor \nfeatures and identify techniques for correctly handling them. Notably, we show that a con.guration\u00adpreserving \npreprocessor needs to hoist conditionals around other preprocessor operations, since preprocessor operations \ncannot be composed with conditionals. In exploring con.guration-preserving parsing, we focus on performance. \nWe present a simple algorithm for Fork-Merge LR (FMLR) parsing, which not only subsumes MAPR s algorithm \nbut also has well-de.ned hooks for optimiza\u00adtion. We then introduce four such optimizations, which decrease \nthe number of forked subparsers (the token follow set and lazy shifts), eliminate duplicate work done \nby subparsers (shared reduces), and let subparsers merge as soon as possible (early reduces). Our op\u00adtimizations \nare not only applied automatically, they also subsume TypeChef s specialized join combinators. The result \nis compelling. SuperC, our open-source tool1 implementing these techniques, can fully parse programs \nwith high variability, notably the entire x86 Linux kernel. In contrast, TypeChef can only parse a constrained \nversion and MAPR fails for most source .les. Like MAPR, our work is inspired by GLR parsing [39], which \nalso forks and merges subparsers. But whereas GLR parsers match di.erent productions to the same input \nfragment, FMLR matches the same production to di.erent input fragments. Furthermore, unlike GLR and TypeChef, \nFMLR parsers can reuse existing LR grammars and parser table generators; only the parser engine is new. \nThis markedly decreases the engineering e.ort necessary for adapting our work. Compared to previous work, \nthis paper makes the following contributions: An analysis of the challenges involved in parsing C with \narbi\u00adtrary preprocessor usage and an empirical quanti.cation for the x86 version of the Linux kernel. \n A comprehensive treatment of techniques for con.guration\u00adpreserving preprocessing and parsing, including \nnovel perfor\u00admance optimizations.  SuperC, an open-source tool for parsing all of C, and its demon\u00adstration \non the x86 Linux kernel.  Overall, our work solves the problem of how to completely and e.ciently parse \nall of C, 40 years after invention of the language, and thus lays the foundation for building more powerful \nC analysis and transformation tools. 2. The Problem and Solution Approach C compilers such as gcc process \nonly one variant of the source code at a time. They pick the one branch of each static conditional that \nmatches the con.guration variables passed to the preprocessor, e.g., through the -D command line option. \nDi.erent con.guration variable settings, or con.gurations, result in di.erent executables, all from the \nsame C sources. In contrast, other C tools, such as source browsers, bug .nders, and automated refactorings, \nneed to be con.guration-preserving. They need to process all branches of static conditionals and, for \neach branch, track the con.gurations enabling the branch, i.e., its presence condition. This considerably \ncomplicates C tools except compilers, starting with preprocessing and parsing. Figure 1 illustrates SuperC \ns con.guration-preserving prepro\u00adcessing and parsing on a simple example from the x86 Linux kernel (version \n2.6.33.3, which is used throughout this paper). Figure 1a shows the original source code, which utilizes \nthe three main preprocessor facilities: an include directive on line 1, macro de.nitions on lines 3 and \n4, and conditional directives on lines 10 and 14. The code has two con.gurations, one when CONFIG_INPUT_MOUSEDEV_PSAUX \nis de.ned and one when it is not de.ned. After preprocessing, shown in Figure 1b, the header .le has \nbeen included (not shown) and the macros have been ex\u00adpanded on lines 6, 7, and 10, but the conditional \ndirectives remain 1 http://cs.nyu.edu/xtc/. 1 #include \"major.h\" // Defines MISC_MAJOR to be 10 2 3 \n#define MOUSEDEV_MIX 31 4 #define MOUSEDEV_MINOR_BASE 32 5 6 static int mousedev_open(struct inode *inode, \nstruct file *file) 7 { 8 int i; 9 10 #ifdef CONFIG_INPUT_MOUSEDEV_PSAUX 11 if (imajor(inode) == MISC_MAJOR) \n12 i = MOUSEDEV_MIX; 13 else 14 #endif 15 i = iminor(inode) -MOUSEDEV_MINOR_BASE; 16 17 return 0; 18 \n} (a) The unpreprocessed source. 1 static int mousedev_open(struct inode *inode, struct file *file) \n2 { 3 int i; 4 5 #ifdef CONFIG_INPUT_MOUSEDEV_PSAUX 6 if (imajor(inode) == 10) 7 i = 31; 8 else 9 #endif \n 10 i = iminor(inode) -32; 11 12 return 0; 13 } (b) The preprocessed source preserving all con.gurations. \n (c) Sketch of the AST containing all con.gurations. Figure 1. From source code to preprocessed code \nto AST. The ex\u00adample is edited down for simplicity from drivers/input/mousedev.c. on lines 5 and 9. Finally, \nin Figure 1c, the parser has generated an AST containing both con.gurations with a static choice node \ncorresponding to the static conditional on lines 5 9 in Figure 1b. 2.1 Interactions Between C and the \nPreprocessor The complexity of con.guration-preserving C processing stems from the interaction of preprocessor \nfeatures with each other and with the C language. Table 1 summarizes these interactions. Rows denote \nlanguage features and are grouped by the three steps of C processing: lexing, preprocessing, and parsing. \nThe .rst column names the feature and the second column describes the implemen\u00adtation strategy. The remaining \ncolumns capture complications aris\u00ading from the interaction of features, and the corresponding table \n Language Construct Implementation Surrounded by Conditionals Contain Conditionals Contain Multiply-De.ned \nMacros Other Lexer Layout Annotate tokens Preprocessor Macro (Un)De.nition Use conditional macro table \nAdd multiple entries to macro table Do not expand until invocation Trim infeasible entries on rede.nition \nObject-Like Expand all Ignore infeasible Expand nested Get ground truth for Macro Invocations de.nitions \nde.nitions macros built-ins from compiler Function-Like Expand all Ignore infeasible Hoist conditionals \nExpand nested Support di.ering argument Macro Invocations de.nitions de.nitions around invocations macros \nnumbers and variadics Token Pasting &#38; Stringi.cation Apply pasting &#38; stringi.cation Hoist conditionals \naround token pasting &#38; stringi.cation File Includes Include and preprocess .les Preprocess under \npresence conditions Hoist conditionals around includes Reinclude when guard macro is not false Static \nConditionals Preprocess all branches Conjoin presence conditions Ignore infeasible de.nitions Conditional \nExpressions Evaluate presence conditions Hoist conditionals around expressions Preserve order for non\u00adboolean \nexpressions Error Directives Ignore erroneous branches Line, Warning, &#38; Treat as Pragma Directives \nlayout Parser C Constructs Use FMLR Parser Fork and merge subparsers Typedef Names Use conditional symbol \ntable Add multiple entries to symbol table Fork subparsers on ambiguous names Table 1. Interactions \nbetween C preprocessor and language features. Gray entries in the last three columns are newly supported \nby SuperC. 1 #ifdef CONFIG_64BIT 2 #define BITS_PER_LONG 64 3 #else 4 #define BITS_PER_LONG 32 5 #endif \nFigure 2. A multiply-de.ned macro from include/asm-gener\u00adic/bitsperlong.h. entries indicate how to overcome \nthe complications. Blank entries indicate impossible interactions. Gray entries highlight interactions \nnot yet supported by TypeChef. In contrast, SuperC does address all interactions besides annotating tokens \nwith layout and with line, warning, and pragma directives. (We have removed a buggy implementation of \nthese annotations from SuperC for now.) Layout. The .rst step is lexing. The lexer converts raw program \ntext into tokens, stripping layout such as whitespace and comments. Since lexing is performed before \npreprocessing and parsing, it does not interact with the other two steps. However, automated refactor\u00adings, \nby de.nition, restructure source code and need to output pro\u00adgram text as originally written, modulo \nany intended changes. Con\u00adsequently, they need to annotate tokens with surrounding layout plus, keep \nsu.cient information about preprocessor operations to restore them as well. Macro (un)de.nitions. The \nsecond step is preprocessing. It col\u00adlects macro de.nitions (#define) and unde.nitions (#undef) in a \nmacro table with de.nitions being either object-like #define name body or function-like #define name(parameters) \nbody 1 // In include/linux/byteorder/little_endian.h: 2 #define __cpu_to_le32(x) ((__force __le32)(__u32)(x)) \n3 4 #ifdef __KERNEL__ 5 // Included from include/linux/byteorder/generic.h: 6 #define cpu_to_le32 __cpu_to_le32 \n7 #endif 8 9 // In drivers/pci/proc.c: 10 _put_user(cpu_to_le32(val), (__le32 __user *) buf); Figure \n3. A macro conditionally expanding to another macro. De.nitions and unde.nitions for the same macro \nmay appear in di.erent branches of static conditionals, creating a multiply\u00adde.ned macro that depends \non the con.guration. Figure 2 shows such a macro, BITS_PER_LONG, whose de.nition depends on the CONFIG_64BIT \ncon.guration variable. A con.guration-preserving preprocessor records all de.nitions in its macro table, \ntagging each entry with the presence condition of the #define directive while also removing infeasible \nentries on each update. The preprocessor also records unde.nitions, so that it can determine which macros \nare neither de.ned nor unde.ned and thus free, i.e., con.guration variables. Wherever multiply-de.ned \nmacros are used, they propa\u00adgate an implicit conditional. It is as if the programmer had written an explicit \nconditional in the .rst place an observation .rst made by Garrido and Johnson [19]. Macro invocations. \nSince macros may be nested within each other, a con.guration-preserving preprocessor, just like an ordi\u00adnary \npreprocessor, needs to recursively expand each macro. Fur\u00adthermore, since C compilers have built-in object-like \nmacros, such as __STDC_VERSION__ to indicate the version of the C standard, the preprocessor needs to \nbe con.gured with the ground truth of the targeted compiler. 1 #ifdef __KERNEL__ 2 __cpu_to_le32 3 #else \n4 cpu_to_le32 5 #endif 6 (val) (a) After expansion of cpu_to_le32. 1 #ifdef __KERNEL__ 2 __cpu_to_le32(val) \n3 #else 4 cpu_to_le32(val) 5 #endif (b) After hoisting the conditional. 1 #ifdef __KERNEL 2 ((__force \n__le32)(__u32)(val)) 3 #else 4 cpu_to_le32(val) 5 #endif (c) After expansion of __cpu_to_le32. Figure \n4. Preprocessing cpu_to_le32(val) in Fig. 3:10. Beyond these straightforward issues, a con.guration-preserving \npreprocessor needs to handle two more subtle interactions. First, a macro invocation may be surrounded \nby static conditionals. Con\u00adsequently, the preprocessor needs to ignore macro de.nitions that are infeasible \nfor the presence condition of the invocation site. Sec\u00adond, function-like macro invocations may contain \nconditionals, ei\u00adther explicitly in source code or implicitly through multiply-de.ned macros. These conditionals \ncan alter the function-like macro invo\u00adcation by changing its name or arguments, including their number \nand values. To preserve the function-like invocation while also al\u00adlowing for di.ering argument numbers \nand variadics (a gcc exten\u00adsion) in di.erent conditional branches, the preprocessor needs to hoist the \nconditionals around the invocation. Figures 3 and 4 illustrate the hoisting of conditionals. Figure 3 \ncontains a sequence of tokens on line 10, cpu_to_le32(val), which either expands to an invocation of \nthe function-like macro __cpu_to_le32, if __KERNEL__ is de.ned, or denotes the invoca\u00adtion of the C function \ncpu_to_le32, if __KERNEL__ is not de.ned. Figure 4 shows the three stages of preprocessing the sequence. \nFirst, in 4a, the preprocessor expands cpu_to_le32, which makes the conditional explicit but also breaks \nthe nested macro invocation on line 2. Second, in 4b, the preprocessor hoists the conditional around \nthe entire sequence of tokens, which duplicates (val) in each branch and thus restores the invocation \non line 2. Third, in 4c, the preprocessor recursively expands __cpu_to_le32 on line 2, which completes \npreprocessing for the sequence. Token-pasting and stringi.cation. Macros may contain two op\u00aderators that \nmodify tokens: The in.x token-pasting operator ## concatenates two tokens, and the pre.x stringi.cation \noperator # converts a sequence of tokens into a string literal. The prepro\u00adcessor simply applies these \noperators, with one complication: the operators arguments may contain conditionals, either explic\u00aditly \nin source code or implicitly via multiply-de.ned macros. As for function-like macros, a con.guration-preserving \npreprocessor needs to hoist conditionals around these operators. Figure 5 illus\u00ad trates this for token-pasting: \n5a shows the source code; 5b shows the result of expanding all macros, including BITS_PER_LONG from Figure \n2; and 5c shows the result of hoisting the conditional out of the token-pasting. File includes. To produce \ncomplete compilation units, a con.gu\u00adration-preserving preprocessor recursively resolves .le includes \n(#include). If the directive is nested in a static conditional, the 1 #define uintBPL_t uint(BITS_PER_LONG) \n2 #define uint(x) xuint(x) 3 #define xuint(x) __le ## x 4 5 uintBPL_t *p = ... ; (a) The macro de.nitions \nand invocation. 1 __le ## 2 #ifdef CONFIG_64BIT 3 64 4 #else 5 32 6 #endif 7 *p = ... ; (b) After expanding \nthe macros. 1 #ifdef CONFIG_64BIT 2 __le ## 64 3 #else 4 __le ## 32 5 #endif 6 *p = ... ; (c) After \nhoisting the conditional. Figure 5. A token-pasting example from fs/udf/balloc.c. preprocessor needs \nto process the header .le under the correspond\u00ading presence condition. Furthermore, if a guard macro, \nwhich is traditionally named FILENAME_H and protects against multiple in\u00adclusion, has been unde.ned, \nthe preprocessor needs to process the same header .le again. More interestingly, include directives may \ncontain macros that provide part of the .le name. If the macro in such a computed include is multiply-de.ned, \nthe preprocessor needs to hoist the implicit conditional out of the directive, just as for macro invocations, \ntoken-pasting, and stringi.cation. Conditionals. Static conditionals enable multiple con.gurations, so \nboth con.guration-preserving preprocessor and parser need to process all branches. The preprocessor converts \nstatic conditionals expressions into presence conditions, and when conditionals are nested within each \nother, conjoins nested conditionals presence conditions. As described for macro invocations above, this \nlets the preprocessor ignore infeasible de.nitions during expansion of multiply-de.ned macros. However, \ntwo issues complicate the conversion of conditional expressions into presence conditions. First, a conditional \nexpres\u00adsion may contain arbitrary macros, not just con.guration variables. So the preprocessor needs \nto expand the macros, which may be multiply-de.ned. When expanding a multiply-de.ned macro, the preprocessor \nneeds to convert the macro s implicit conditional into logical form and hoist it around the conditional \nexpression. For ex\u00adample, when converting the conditional expression BITS_PER_LONG == 32 from kernel/sched.c \ninto a presence condition, the preprocessor expands the de.nition of BITS_PER_LONG from Figure 2 and \nhoists it around the conditional expression, to arrive at defined(CONFIG_64BIT) &#38;&#38; 64 == 32 \\ \n|| !defined(CONFIG_64BIT) &#38;&#38; 32 == 32  which makes testing for CONFIG_64BIT explicit with the \ndefined operator and simpli.es to !defined(CONFIG_64BIT) after constant folding. Second, con.guration \nvariables may be non-boolean and condi\u00adtional expressions may contain arbitrary arithmetic subexpressions, \nsuch as NR_CPUS < 256 (from arch/x86/include/asm/spinlock.h). 1 static int (*check_part[])(struct parsed_partitions \n*) = { 2 #ifdef CONFIG_ACORN_PARTITION_ICS 3 adfspart_check_ICS, 4 #endif 5 #ifdef CONFIG_ACORN_PARTITION_POWERTEC \n6 adfspart_check_POWERTEC, 7 #endif 8 #ifdef CONFIG_ACORN_PARTITION_EESOX 9 adfspart_check_EESOX, 10 \n#endif 11 // 15 more, similar initializers 12 NULL 13 }; Figure 6. An example of a C construct containing \nan exponential number of unique con.gurations from fs/partitions/check.c. Since there is no known e.cient \nalgorithm for comparing arbi\u00adtrary polynomials [24], such subexpressions prevent the preproces\u00ad sor from \ntrimming infeasible con.gurations. Instead, it needs to treat non-boolean subexpressions as opaque text \nand preserve their branches source code ordering, i.e., never omit or combine them and never move other \nbranches across them. Other preprocessor directives. The C preprocessor supports four additional directives, \nto issue errors (#error) and warnings (#warning), to instruct compilers (#pragma), and to overwrite line \nnumbers (#line). A con.guration-preserving preprocessor simply reports errors and warnings, and also \nterminates for errors appearing outside static conditionals. More importantly, it treats conditional \nbranches containing error directives as infeasible and disables their parsing. Otherwise, it preserves \nsuch directives as token annotations to support automated refactorings. C constructs. The third and .nal \nstep is parsing. The preprocessor produces entire compilation units, which may contain static con\u00additionals \nbut no other preprocessor operations. The con.guration\u00adpreserving parser processes all branches of each \nconditional by forking its internal state into subparsers and merging the subparsers again after the \nconditional. This way, it produces an AST contain\u00ading all con.gurations, with static choice nodes for \nconditionals. One signi.cant complication is that static conditionals may still appear between arbitrary \ntokens, thus violating C syntax. However, the AST may only contain nodes representing complete C con\u00adstructs. \nTo recognize C constructs with embedded con.gurations, the parser may require a subparser per con.guration. \nFor example, the statement on lines 5 10 in Figure 1b has two con.gurations and requires two subparsers. \nThe parser may also parse tokens shared between con.gurations several times. In the example, line 10 \nis parsed twice, once as part of the if-then-else statement and once as a stand-alone expression statement. \nThis way, the parser hoists conditionals out of C constructs, much like the preprocessor hoists them \nout of preprocessor operations. Using a subparser per embedded con.guration is acceptable for most declarations, \nstatements, and expressions. They have a small number of terminals and nonterminals and thus can contain \nonly a limited number of con.gurations. However, if a C construct contains repeated nonterminals, this \ncan lead to an exponential blow-up of con.gurations and therefore subparsers. For example, the array \ninitializer in Figure 6 has 218 unique con.gurations. Using a subparser for each con.guration is clearly \ninfeasible and avoiding it requires careful optimization of the parsing algorithm. Typedef names. A .nal \ncomplication results from the fact that C syntax is context-sensitive [35]. Depending on context, names \ncan either be typedef names, i.e., type aliases, or they can be object, function, and enum constant names. \nFurthermore, the same code snippet can have fundamentally di.erent semantics, depending on names. For \nexample, T * p; is either a declaration of p as a pointer Algorithm 1 Hoisting Conditionals 1: procedure \nHoist(c, t) 2: t Initialize a new conditional with an empty branch. 3: C . [(c, )] 4: for all a . t do \n5: if a is a language token then 6: t Append a to all branches in C. 7: C . [(ci,tia) | (ci,ti) . C ] \n8: else t a is a conditional. 9: t Recursively hoist conditionals in each branch. 10: B . [ b | b . Hoist(ci,ti) \nand (ci,ti) . a ] 11: t Combine with already hoisted conditionals. 12: C . C \u00d7 B 13: end if 14: end for \n15: return C 16: end procedure to type T or an expression statement that multiplies the variables T \nand p, depending on whether T is a typedef name. C parsers usually employ a symbol table to disambiguate \nnames [22, 35]. In the presence of conditionals, however, a name may be both. Consequently, a con.guration-preserving \nparser needs to maintain con.guration-dependent symbol table entries and fork subparsers when encountering \nan implicit conditional due to an ambiguously de.ned name. 3. The Con.guration-Preserving Preprocessor \nSuperC s con.guration-preserving preprocessor accepts C .les, performs all operations while preserving \nstatic conditionals, and produces compilation units. While tedious to engineer, its function\u00adality mostly \nfollows from the discussion in the previous section. Two features, however, require further elaboration: \nthe hoisting of conditionals around preprocessor operations and the conversion of conditional expressions \ninto presence conditions. 3.1 Hoisting Static Conditionals Preprocessor directives as well as function-like \nmacro invocations, token-pasting, and stringi.cation may only contain ordinary lan\u00adguage tokens. Consequently, \nthey are ill-de.ned in the presence of implicit or explicit embedded static conditionals. To perform \nthese preprocessor operations, SuperC s con.guration-preserving preprocessor needs to hoist conditionals, \nso that only ordinary to\u00adkens appear in the branches of the innermost conditionals. Algorithm 1 formally \nde.nes Hoist. It takes a presence condi\u00adtion c and a list of ordinary tokens and entire conditionals \nt under the presence condition. Each static conditional C, in turn, is treated as a list of branches \nC := [(c1,t1),..., (cn,tn)] with each branch having a presence condition ci and a list of tokens and \nnested conditionals ti. Line 3 initializes the result C with an empty conditional branch. Lines 4 14 \niterate over the tokens and conditionals in t, updating C as necessary. And line 15 returns the result \nC. Lines 5 7 of the loop handle ordinary tokens, which are present in all embedded con.gurations and \nare appended to all branches in C, as illustrated for (val) in Figure 4b and for __le ## in Figure 5c. \nLines 8 13 of the loop handle conditionals by recursively hoisting any nested conditionals in line 10 \nand then combining the result B with C in line 12. The cross product for conditionals in line 12 is de.ned \nas C \u00d7 B := [(ci . cj,tit j) | (ci,ti) . C and (cj,tj) . B ]  and generalizes line 7 by combining every \nbranch in C with every branch in B. SuperC uses Hoist for all preprocessor operations that may contain \nconditionals except for function-like macro invocations. The problem with the latter is that, to call \nHoist, the preprocessor needs to know which tokens and conditionals belong to an oper\u00adation. But di.erent \nconditional branches of a function-like macro invocation may contain di.erent macro names and numbers \nof ar\u00adguments, and even additional, unrelated tokens. Consequently, Su\u00adperC uses a version of Hoist for \nfunction-like macro invocations that interleaves parsing with hoisting. For each conditional branch, \nit tracks parentheses and commas, which change the parsing state of the invocation. Once all variations \nof the invocation have been recognized across all conditional branches, each invocation is sep\u00adarately \nexpanded. If a variation contains an object-like or unde.ned macro, the argument list is left in place, \nas illustrated in Fig. 4c:4.  3.2 Converting Conditional Expressions To reason about presence conditions, \nSuperC converts conditional expressions into Binary Decision Diagrams (BDDs) [12, 42], which are an e.cient, \nsymbolic representation of boolean func\u00adtions. BDDs include support for boolean constants, boolean vari\u00adables, \nas well as negation, conjunction, and disjunction. On top of that, BDDs are canonical: Two boolean functions \nare the same if and only if their BDD representations are the same [12]. This makes it not only possible \nto directly combine BDDs, e.g., when tracking the presence conditions of nested or hoisted condition\u00adals, \nbut also to easily compare two BDDs for equality, e.g., when testing for an infeasible con.guration by \nevaluating c1 . c2 = false. Before converting a conditional expression into a BDD, SuperC expands any \nmacros outside invocations of the defined opera\u00adtor, hoists multiply-de.ned macros around the expression, \nand per\u00adforms constant folding. The resulting conditional expression uses negations, conjunctions, and \ndisjunctions to combine four types of subexpressions: constants, free macros, arithmetic expressions, \nand defined invocations. SuperC converts each of these subexpres\u00adsions into a BDD as follows and then \ncombines the resulting BDDs with the necessary logical operations: 1. A constant translates to false \nif zero and to true otherwise. 2. A free macro translates to a BDD variable. 3. An arithmetic subexpression \nalso translates to a BDD variable. 4. defined(M) translates into the disjunction of presence condi\u00adtions \nunder which M is de.ned. However, if M is free: (a) If M is a guard macro, defined(M) translates to \nfalse. (b) Otherwise, defined(M) translates to a BDD variable.   Just like gcc, Case 4a treats M as \na guard macro, if a header .le starts with a conditional directive that tests !defined(M) and is followed \nby #define M, and the matching #endif ends the .le. To ensure that repeated occurrences of the same free \nmacro, arithmetic expression, or defined(M) for free M translate to the same BDD variable, SuperC maintains \na mapping between these expressions and their BDD variables. In the case of arithmetic expressions, it \nnormalizes the text by removing whitespace and comments. 4. The Con.guration-Preserving Parser SuperC \ns con.guration-preserving FMLR parser builds on LR parsing [2, 28], a bottom-up parsing technique. To \nrecognize the input, LR parsers maintain an explicit parser stack, which contains terminals, i.e., tokens, \nand nonterminals. On each step, LR parsers perform one of four actions: (1) shift to copy a token from \nthe in\u00adput onto the stack and increment the parser s position in the input, (2) reduce to replace one \nor more top-most stack elements with Algorithm 2 Fork-Merge LR Parsing 1: procedure Parse(a0) 2: Q.init((true, \na0, s0)) t The initial subparser for a0. 3: while Q * \u00d8 do 4: p . Q.pull() t Step the next subparser. \n5: T . Follow(p.c, p.a) 6: if |T | = 1 then 7: t Do an LR action and reschedule the subparser. 8: Q.insert(LR(T \n(1), p)) 9: else t The follow-set contains several tokens. 10: t Fork subparsers and reschedule them. \n11: Q.insertAll(Fork(T, p)) 12: end if 13: Q . Merge(Q) 14: end while 15: end procedure a nonterminal, \n(3) accept to successfully complete parsing, and (4) reject to terminate parsing with an error. The choice \nof action depends on both the next token in the input and the parser stack. To ensure e.cient operation, \nLR parsers use a deterministic .nite control and store the state of the control with each stack element. \nCompared to top-down parsing techniques, such as LL [34] and PEG [7, 16], LR parsers are an attractive \nfoundation for con.guration-preserving parsing for three reasons. First, LR parsers make the parsing \nstate explicit, in form of the parser stack. Con\u00adsequently, it is easy to fork the parser state on a \nstatic conditional, e.g., by representing the stack as a singly-linked list and by creating new stack \nelements that point to the shared remainder. Second, LR parsers are relatively straight-forward to build, \nsince most of the complexity lies in generating the parsing tables, which determine control transitions \nand actions. In fact, SuperC uses LALR parsing tables [13] produced by an existing parser generator. \nThird, LR parsers support left-recursion in addition to right-recursion, which is helpful for writing \nprogramming language grammars. 4.1 Fork-Merge LR Parsing Algorithm 2 formalizes FMLR parsing. It uses \na queue Q of LR subparsers p. Each subparser p := (c, a, s) has a presence condi\u00adtion c, a next token \nor conditional a, which is also called the head, and an LR parser stack s. Each subparser recognizes \na distinct con\u00ad.guration, i.e., the di.erent presence conditions p.c are mutually exclusive, and all \nsubparsers together recognize all con.gurations, i.e., the disjunction of all their presence conditions \nis true. Q is a priority queue, ordered by the position of the head p.a in the input. This ensures that \nsubparsers merge at the earliest opportunity, as no subparser can outrun the other subparsers. Line 2 \ninitializes the queue Q with the subparser for the initial token or conditional a0, and lines 3 14 step \nindividual subparsers until the queue is empty, i.e., all subparsers have accepted or re\u00adjected. On each \niteration, line 4 pulls the earliest subparser p from the queue. Line 5 computes the token follow-set \nfor p.c and p.a, which contains pairs (ci, ai) of ordinary language tokens ai and their presence conditions \nci. The follow-set computation is detailed in Section 4.2. Intuitively, it captures the actual variability \nof source code and includes the .rst language token on each path through static conditionals from the \ncurrent input position. If the follow\u00adset contains a single element, e.g., p.a is an ordinary token and \nT = { (p.c, p.a) }, lines 6 8 perform an LR action on the only ele\u00adment T (1) and the subparser p. Unless \nthe LR action is accept or reject, line 8 also reschedules the subparser. Otherwise, the follow\u00adset contains \nmore than one element, e.g., p.a is a conditional. Since each subparser can only perform LR actions one \nafter another, Algorithm 3 The Token Follow-Set 1: procedure Follow(c, a) 2: T .\u00d8 t Initialize the follow-set. \n3: procedure First(c, a) 4: loop 5: if a is a language token then 6: T . T .{(c, a)} 7: return false \n8: else t a is a conditional. 9: cr . false t Initialize remaining condition. 10: for all (ci,ti) . a \ndo 11: if ti = then 12: cr . cr . c . ci 13: else 14: cr . cr . First(c . ci,ti(1)) 15: end if 16: end \nfor 17: if cr = false or a is last element in branch then 18: return cr 19: end if 20: c . cr 21: a . \nnext token or conditional after a 22: end if 23: end loop 24: end procedure 25: loop 26: c . First(c, \na) 27: if c = false then return T end if t Done. 28: a . next token or conditional after a 29: end loop \n30: end procedure lines 9 12 fork a subparser for each presence condition and token (ci, ai) . T and \nthen reschedule the subparsers. Finally, line 13 tries to merge subparsers again. Subparsers may merge \nif they have the same head and LR stack, which ensures that conditionals are hoisted out of C constructs. \n 4.2 The Token Follow-Set A critical challenge for con.guration-preserving parsing is which subparsers \nto create. The naive strategy, employed by MAPR, forks a subparser for every branch of every static conditional. \nBut condi\u00adtionals may have empty branches and even omit branches, like the implicit else branch in Figure \n1. Furthermore, they may be directly nested within conditional branches, and they may directly follow \nother conditionals. Consequently, the naive strategy forks a great many unnecessary subparsers and is \nintractable for complex C pro\u00adgrams such as Linux. Instead, FMLR relies on the token follow\u00adset to capture \nthe source code s actual variability, thus limiting the number of forked subparsers. Algorithm 3 formally \nde.nes Follow. It takes a presence con\u00addition c and a token or conditional a, and it returns the follow\u00adset \nT for a, which contains pairs (ci, ai) of ordinary tokens ai and their presence conditions ci. By construction, \neach token ai appears exactly once in T ; consequently, the follow-set is ordered by the tokens positions \nin the input. Line 2 initializes T to the empty set. Lines 3 24 de.ne the nested procedure First. It \nscans well\u00adnested conditionals and adds the .rst ordinary token and presence condition for each con.guration \nto T . It then returns the presence condition of any remaining con.guration, i.e., conditional branches \nthat are empty or implicit and thus do not contain ordinary tokens. Lines 25 29 repeatedly call First \nuntil all con.gurations have been Fork(T, p):= { (c, a, p.s) | (c, a) . T } Merge(Q):= { (p.c, a, s) \n| a = p.a and s = p.s .p . Q } (a) Basic forking and merging. Fork(T, p):= { (H, p.s) | H . Lazy(T, p) \n. Shared(T, p) } p Lazy(T, p):= {(c, a)}| Action(a, p.s) = shift .(c, a) . TShared(T, ):= p {(c, a)}| \nAction(a, p.s) = reduce n .(c, a) . T (b) Optimized forking. Figure 7. The de.nitions of fork and merge. \n covered, i.e., the remaining con.guration is false. Line 28 moves on to the next token or conditional, \nwhile also stepping out of condi\u00adtionals. In other words, if the token or conditional a is the last ele\u00adment \nin the branch of a conditional, which, in turn, may be the last element in the branch of another conditional \n(and so on), line 28 updates a with the .rst element after the conditionals. First does the brunt of \nthe work. It takes a token or conditional a and presence condition c. Lines 4 23 then iterate over the \nelements of a conditional branch or at a compilation unit s top-level, starting with a. Lines 5 7 handle \nordinary language tokens. Line 6 adds the token and presence condition to the follow-set T . Line 7 terminates \nthe loop by returning false, indicating no remaining con.guration. Lines 8 22 handle conditionals. Line \n9 initializes the remaining con.guration cr to false. Lines 10 16 then iterate over the branches of the \nconditional a, including any implicit branch. If a branch is empty, line 12 adds the conjunction of its \npresence condition ci and the overall presence condition c to the remaining con.guration cr . Otherwise, \nline 14 recurses over the branch, starting with the .rst token or conditional ti(1), and adds the result \nto the remaining con\u00ad.guration cr . If, after iterating over the branches of the conditional, the remaining \ncon.guration is false or there are no more tokens or conditionals to process, lines 17 19 terminate First \ns main loop by returning cr. Finally, lines 20 21 set up the next iteration of the loop by updating c \nwith the remaining con.guration and a with the next token or conditional. 4.3 Forking and Merging Figure \n7a shows the de.nitions of Fork and Merge. Fork creates new subparsers from a token follow-set T to replace \na subparser p. Each new subparser has a di.erent presence condition c and to\u00adken a from the follow-set \nT but the same LR stack p.s. Conse\u00adquently, it recognizes a more speci.c con.guration than the origi\u00adnal \nsubparser p. Merge has the opposite e.ect. It takes the priority queue Q and combines any subparsers \np . Q that have the same head and LR stack. Such subparsers are redundant: they will nec\u00adessarily perform \nthe same parsing actions for the rest of the input, since FMLR, like LR, is deterministic. Each merged \nsubparser re\u00adplaces the original subparsers; its presence condition is the disjunc\u00adtion of the original \nsubparsers presence conditions. Consequently, it recognizes a more general con.guration than any of the \norigi\u00adnal subparsers. Merge is similar to GLR s local ambiguity pack\u00ading [39], which also combines equivalent \nsubparsers, except that FMLR subparsers have presence conditions. 4.4 Optimizations In addition to the \ntoken follow-set, FMLR relies on three more opti\u00admizations to contain the state explosion caused by static \ncondition\u00adals: early reduces, lazy shifts, and shared reduces. Early reduces are a tie-breaker for the \npriority queue. When subparsers have the same head a, they favor subparsers that will reduce over subparsers \nthat will shift. Since reduces, unlike shifts, do not change a subparser s head, early reduces prevent \nsubparsers from outrunning each other and create more opportunities for merging subparsers. While early \nreduces seek to increase merge opportunities, lazy shifts and shared reduces seek to decrease the number \nand work of forked subparsers, respectively. First, lazy shifts delay the forking of subparsers that \nwill shift. They are based on the observation that a sequence of static conditionals with empty or implicit \nbranches, such as the array initializer in Figure 6, often results in a follow\u00ad set, whose tokens all \nrequire a shift as the next LR action. However, since FMLR steps subparsers by position of the head, \nthe subparser for the .rst such token performs its shift (plus other LR actions) and can merge again \nbefore the subparser for the second such token can even perform its shift. Consequently, it is wasteful \nto eagerly fork the subparsers. Second, shared reduces reduce a single stack for several heads at the \nsame time. They are based on the observation that conditionals often result in a follow-set, whose tokens \nall require a reduce to the same nonterminal; e.g., both tokens in the follow-set of the conditional \nin Figure 1b reduce the declaration on line 3. Consequently, it is wasteful to .rst fork the subparsers \nand then reduce their stacks in the same way. Figure 7b formally de.nes both lazy shifts and shared reduces. \nBoth optimizations result in multi-headed subparsers p := (H, s), which have more than one head and presence \ncondition H := { (c1, a1),..., (cn, an) } Just as for the follow-set, each token ai appears exactly once \nin H and the set is ordered by the tokens positions in the input. Algo\u00adrithm 2 generalizes to multi-headed \nsubparsers as follows. It pri\u00ad oritizes a multi-headed subparser by its earliest head a1. Next, by de.nition \nof optimized forking, the follow-set of a multi-headed subparser (H, s) is H. However, the optimized \nversion of the FMLR algorithm always performs an LR operation on a multi-headed subparser, i.e., treats \nit as if the follow-set contains a single ordi\u00adnary token. If the multi-headed subparser will shift, \nit forks o. a single-headed subparser p; for the earliest head, shifts p;, and then reschedules both \nsubparsers. If the multi-headed subparser will re\u00adduce, it reduces p and immediately recalculates Fork(H, \np), since the next LR action may not be the same reduce for all heads any\u00admore. Finally, it merges multi-headed \nsubparsers p if they have the same head { ( , a1),..., ( , an) } = p.H and the same LR stack s = p.s; \nit computes the merged parser s presence condi\u00adtions as the disjunction of the original subparser s corresponding \npresence conditions ci = p.H(i).c.  4.5 Putting It All Together We are now ready to illustrate FMLR \non the array initializer in Figure 6. For simplicity, we treat NULL as a token and ignore that the macro \nusually expands to ((void *)0). For concision, we subscript each subparser and set symbol with its current \nline number in Figure 6. We also use bn to denote the boolean variable representing the conditional expression \non line n, e.g., b2 ~ defined(CONFIG_ACORN_PARTITION_ICS) Finally, we refer to one iteration through \nFMLR s main loop in Algorithm 2 as a step. Since line 1 in Figure 6 contains only ordinary tokens, FMLR \nbehaves like an LR parser, stepping through the tokens with a sin\u00adgle subparser p1. Upon reaching line \n2, FMLR computes Follow for the conditional on lines 2 4. To this end, First iterates over the conditionals \nand NULL token in the initializer list by updat\u00ading a in Alg. 3:21. On each iteration besides the last, \nFirst also recurses over the branches of a conditional, including the implicit else branch. As a result, \nit updates the remaining con.guration in Alg. 3:12 with a conjunction of negated conditional expressions, \nyielding the follow-set T2 = { (b2, adfspart_check_ICS), (\u00acb2 . b5, adfspart_check_POWERTEC), ..., (\u00acb2 \n.\u00acb5 .\u00acb8 . ..., NULL) }  Since all tokens in T2 reduce the empty input to the InitializerList nonterminal, \nshared reduces turns p2 into a multi-headed subparser with H2 = T2. FMLR then steps p3. It reduces the \nsubparser, which does not change the heads, i.e., H3 = H2, but modi.es the stack to p3.s = ... { InitializerList \n It then calculates Fork(H3, p3); since all tokens in H3 now shift, lazy shifts produces the same multi-headed \nsubparser. FMLR steps p3 again. It forks o. a single-headed subparser p;3 and shifts the identi.er token \non line 3 onto its stack. Next, FMLR steps p;3. It shifts the comma token onto the stack, which yields \np;3.s = ... { InitializerList adfspart_check_ICS , and updates the head p;3.a to the conditional on \nlines 5 7. FMLR steps p;5 again, computing the subparser s follow-set as T;= { (b2 . b5, adfspart_check_POWERTEC), \n5 ..., (b2 .\u00acb5 .\u00acb8 . ..., NULL) }  Since all tokens in T5;reduce the top three stack elements to an \nIni\u00adtializerList, shared reduces turns p;5 into a multi-headed subparser with H5;= T5;. At this point, \nboth p6 and p6;are multi-headed sub\u00adparsers with the same heads, though their stacks di.er. Due to early \nreduces, FMLR steps p;6. It reduces the stack, which yields the same stack as that of p6, and calculates \nFork, which does not change p;6 due to lazy shifts. It then merges the two multi-headed subparsers, which \ndisjoins b2 with \u00acb2 for all presence conditions and thus eliminates b2 from H6. FMLR then repeats the \nprocess of forking, shifting, reducing, and merging for the remaining 17 conditionals until a single-headed \nsubparser p completes the array initializer on lines 12 13. That way, FMLR parses 218 distinct con.gurations \nwith only 2 subparsers! 5. Pragmatics Having covered the overall approach and algorithms, we now turn \nto the pragmatics of building a real-world tool. SuperC imple\u00adments the three steps of parsing all of \nC lexing, preprocessing, and parsing in Java. We engineered both preprocessor and parser from scratch, \nbut rely on JFlex [27] to generate the lexer and on Bison [17] to generate the LALR parser tables. Since \nBison gener\u00ad ates C headers, we wrote a small C program that converts them to Java. As inputs to JFlex \nand Bison, we reuse Roskind s tokeniza\u00adtion rules and grammar for C [35], respectively; we added support \nfor common gcc extensions. To parse conditional expressions, the preprocessor also reuses a C expression \ngrammar distributed with the Rats! parser generator [22]. To facilitate future retargeting to other languages, \nSuperC s preprocessor accesses tokens through an interface that hides source language aspects not relevant \nto prepro\u00adcessing. Furthermore, the preprocessor does not pass conditional directives to the parser but \nrather replaces each directive s tokens with a single special token that encodes the conditional operation \nand references the conditional expression as a BDD. Finally, the parser is not only con.gured with the \nparser tables but also with plug-ins that control AST construction (Section 5.1) and context management \n(Section 5.2). To support these plug-ins, each sub\u00ad parser stack element has a .eld for the current semantic \nvalue and each subparser has a .eld for the current context. 5.1 Building Abstract Syntax Trees To simplify \nAST construction, SuperC includes an annotation fa\u00adcility that eliminates explicit semantic actions in \nmost cases. Devel\u00adopers simply add special comments next to productions. Our AST tool then extracts these \ncomments and generates the corresponding Java plug-in code, which is invoked when reducing a subparser \ns stack. By default, SuperC creates an AST node that is an instance of a generic node class, is named \nafter the production, and has the semantic values of all terminals and nonterminals as children. Four \nannotations override this default. (1) layout omits the production s value from the AST. It is used for \npunctuation. (2) passthrough reuses a child s semantic value, if it is the only child in an alter\u00adnative. \nIt is particularly useful for expressions, whose productions tend to be deeply nested for precedence \n(17 levels for C). (3) list encodes the semantic values of a recursive production as a linear list. It \nis necessary because LR grammars typically represent repe\u00adtitions as left-recursive productions. (4) \naction executes arbitrary Java code instead of automatically generating an AST node. A .fth annotation, \ncomplete, determines which productions are complete syntactic units. SuperC merges only subparsers with \nthe same, complete nonterminal on top of their stacks; while merg\u00ading, it combines the subparsers semantic \nvalues with a static choice node. The selection of complete syntactic units requires care. Treat\u00ading \ntoo many productions as complete forces downstream tools to handle static choice nodes in too many di.erent \nlanguage con\u00adstructs. Treating too few productions as complete may result in an exponential subparser \nnumber in the presence of embedded con.g\u00adurations, e.g., the array initializer in Figure 6. SuperC s \nC grammar tries to strike a balance by treating not only declarations, de.ni\u00adtions, statements, and expressions \nas complete syntactic units, but also members in commonly con.gured lists, including function pa\u00adrameters, \nstruct and union members, as well as struct, union, and array initializers.  5.2 Managing Parser Context \nSuperC s context management plug-in enables the recognition of context-sensitive languages, including \nC, without modifying the FMLR parser. The plug-in has four callbacks: (1) reclassify modi.es the token \nfollow-set by changing or adding tokens. It is called after computing the follow-set, i.e., line 5 in \nAlgorithm 2. (2) forkContext creates a new context and is called during fork\u00ading. (3) mayMerge determines \nwhether two contexts allow merging and is called while merging subparsers. (4) mergeContexts actu\u00adally \ncombines two contexts and is also called while merging. SuperC s C plug-in works as follows. Its context \nis a symbol table that tracks which names denote values or types under which presence conditions and \nin which C language scopes. Productions that declare names and enter/exit C scopes update the symbol \ntable through helper productions that are empty but have semantic actions. reclassify checks the name \nof each identi.er, which is the only token generated for names by SuperC s lexer. If the name denotes \na type in the current scope, reclassify replaces the identi.er with a typedef name. If the name is ambiguously \nde.ned under the current presence condition, it instead adds the typedef name to the follow-set. This \ncauses the FMLR parser to fork an extra subparser on such names, even though there is no explicit conditional. \nforkContext duplicates the current symbol table scope. mayMerge allows merging only at the same scope \nnesting level. Finally, mergeContexts combines any symbol table scopes not already shared between the \ntwo contexts. 6. Evaluation To evaluate our work, we explore three questions. Section 6.1 ex\u00ad amines \nhow prevalent preprocessor usage is in real-world code. It measures preprocessor directives and feature \ninteractions in the Linux kernel. Section 6.2 examines how e.ective FMLR is at con\u00adtaining the state \nexplosion caused by static conditionals. It mea\u00adsures the number of subparsers necessary for parsing \nLinux and also compares to our reimplementation of MAPR. Section 6.3 ex- Total C Files Headers LoC 5,600,227 \n85% 15% All Directives 532,713 34% 66% #define 366,424 16% 84% #if, #ifdef, #ifndef 38,198 58% 42% #include \n86,604 85% 15% (a) Number of directives compared to lines of code (LoC). Header Name C Files That Include \nHeader include/linux/module.h 3,741 (49%) include/linux/init.h 2,841 (37%) include/linux/kernel.h 2,567 \n(33%) include/linux/slab.h 1,800 (23%) include/linux/delay.h 1,505 (20%) (b) The top .ve most frequently \nincluded headers. Table 2. A developer s view of x86 Linux preprocessor usage. amines how well SuperC \nperforms. It measures the latency for parsing Linux and also compares to TypeChef. We focus on Linux \nfor three reasons: (a) it is large and complex, (b) it has many de\u00advelopers with di.ering coding styles \nand skills, and (c) it is subject to staggering performance and variability requirements. However, since \nthe Linux build system does not use the preprocessor for set\u00adting architecture-speci.c header .les, we \nevaluate only the x86 ver\u00adsion of the kernel. In summary, our evaluation demonstrates that Linux provides \na cornucopia of preprocessor usage, that FMLR requires less than 40 subparsers for Linux whereas MAPR \nfails on most source .les, and that SuperC performs well enough, out\u00adrunning TypeChef by more than a \nfactor of four and out-scaling it for complex compilation units. 6.1 Preprocessor Usage and Interactions \nTable 2 provides a developer s view of preprocessor usage in the x86 Linux kernel. The data was collected \nby running cloc, grep, and wc on individual C and header .les. Table 2a compares the number of preprocessor \ndirectives to lines of code (LoC), exclud\u00ading comments and empty lines. Even this simple analysis demon\u00adstrates \nextensive preprocessor usage: almost 10% of all LoC are preprocessor directives. Yet, when looking at \nC .les, preprocessor usage is not nearly as evident for two reasons. First, macro invoca\u00adtions look like \nC identi.ers and C function calls; they may also be nested in other macros. Consequently, they are not \ncaptured by this analysis. Second, C programs usually rely on headers for common de.nitions, i.e., as \na poor man s module system. The data corrobo\u00adrates this. 66% of all directives and 84% of macro de.nitions \nare in header .les. Furthermore, 15% of include directives are in header .les, resulting in long chains \nof dependencies. Finally, some head\u00aders are directly included in thousands of C .les (and preprocessed \nfor each one). Table 2b shows the top .ve most frequently included headers; module.h alone is included \nin nearly half of all C .les. Table 3 provides a tool s view of preprocessor usage in the x86 Linux kernel. \nThe data was collected by instrumenting SuperC and applying our tool on compilation units, i.e., C .les \nplus the clo\u00adsure of included headers. It captures information not available in the simple counts of \nTable 2, including macro invocations. Table 3 loosely follows the organization of Table 1. Each row shows \na pre\u00ad processor or C language construct. The .rst column names the con\u00adstruct, the second column shows \nits usage, and the third and fourth columns show its interactions. Each entry is the distribution in \nthree percentiles, 50th \u00b7 90th \u00b7 100th, across compilation units. Table 3 con.rms that preprocessor usage \nis extensive. It also con.rms that most interactions identi.ed in Section 2 occur in real-world C code. \n Language Construct Total Interaction with Conditionals Other Interactions Macro De.nitions 34k \u00b7 45k \n\u00b7 122k Contained in 34k \u00b7 45k \u00b7 122k Rede.nitions 23k \u00b7 33k \u00b7 111k Macro Invocations 98k \u00b7 140k \u00b7 381k \nTrimmed Hoisted 16k \u00b7 21k \u00b7 70k 154 \u00b7 292 \u00b7 876 Nested invocations Built-in macros 64k \u00b7 97k \u00b7 258k 135 \nToken-Pasting 4k \u00b7 6k \u00b7 22k Hoisted 0 \u00b7 0 \u00b7 180 Stringi.cation 6k \u00b7 8k \u00b7 23k Hoisted 361 \u00b7 589 \u00b7 6,082 \nFile Includes 1,608 \u00b7 2,160 \u00b7 5,939 Hoisted 33 \u00b7 55 \u00b7 165 Computed includes 34 \u00b7 56 \u00b7 168 Reincluded \nheaders 1,185 \u00b7 1,743 \u00b7 5,488 Static Conditionals 8k \u00b7 10k \u00b7 29k Hoisted Max. depth 331 \u00b7 437 \u00b7 1,258 \n28 \u00b7 33 \u00b7 40 With non-boolean expressions 509 \u00b7 713 \u00b7 1,975 Error Directives 42 \u00b7 57 \u00b7 168 C Declarations \n&#38; Statements 34k \u00b7 49k \u00b7 127k Containing 722 \u00b7 896 \u00b7 2,746 Typedef Names 748 \u00b7 1,028 \u00b7 2,554 Ambiguously \nde.ned names 0 \u00b7 0 \u00b7 0 Table 3. A tool s view of x86 Linux preprocessor usage. Entries show percentiles \nacross compilation units: 50th \u00b7 90th \u00b7 100th. The vast majority of measured preprocessor interactions \ninvolve macros. First, almost all macro de.nitions are contained in static conditionals, i.e., any di.erence \nis hidden by rounding to the near\u00adest thousand. This is due to most de.nitions occurring in header .les \nand most header .les, in turn, containing a single static condi\u00adtional that protects against multiple \ninclusion. Second, over 60% of macro invocations appear from within other macros; e.g., the me\u00addian for \ntotal macro invocations is 98k, while the median for nested invocations is 64k. This makes it especially \ndi.cult to fully ana\u00adlyze macro invocations without running the preprocessor, e.g., by inspecting source \ncode. While not nearly as frequent as interactions involving macros, static conditionals do appear within \nfunction\u00adlike macro invocations, token-pasting and stringi.cation operators, .le includes, as well as \nconditional expressions. Consequently, a con.guration-preserving preprocessor must hoist such condition\u00adals. \nSimilarly, non-boolean expressions do appear in conditionals and the preprocessor must preserve them. \nHowever, two exceptions are notable. Computed includes are very rare and ambiguously\u00adde.ned names do \nnot occur at all, likely because both make it very hard to reason about source code.  6.2 Subparser \nCounts According to Table 3, most compilation units contain thousands of static conditionals. This raises \nthe question of whether recognizing C code across conditionals is even feasible. Two factors determine \nfeasibility: (1) the breadth of conditionals, which forces the fork\u00ading of subparsers, and (2) the incidence \nof partial C constructs in conditionals, which prevents the merging of subparsers. The num\u00adber of subparsers \nper iteration of FMLR s main loop in Alg. 2:3 14 precisely captures the combined e.ect of these two factors. \nFigure 8 shows the cumulative distribution of subparser counts per FMLR iteration for the x86 Linux kernel \nunder di.erent opti\u00admization levels: 8a identi.es the maxima and 8b characterizes the overall shape. \nFor comparison, the former also includes MAPR. We reimplemented MAPR by modifying SuperC to optionally \nfork a subparser for every conditional branch instead of using the token follow-set. We also reimplemented \nMAPR s tie-breaker for the pri\u00adority queue, which favors the subparser with the larger stack [33]. Figure \n8 demonstrates that MAPR is intractable for Linux, trigger\u00ad ing a kill-switch at 16,000 subparsers for \n98% of all compilation units. In contrast, the token follow-set alone makes FMLR feasi\u00adble for the entire \nx86 Linux kernel. The lazy shifts, shared reduces, and early reduces optimizations further decrease subparser \ncounts, by up to a factor of 12. They also help keep the AST smaller: fewer forked subparsers means fewer \nstatic choice nodes in the tree, and Subparsers Optimization Level 99th % Max. Shared, Lazy, &#38; Early \n21 39 Shared &#38; Lazy 22 39 Shared 21 77 Lazy 32 468 Follow-Set Only 33 468 MAPR &#38; Largest First \n>16,000 on 98% of comp. units MAPR >16,000 on 98% of comp. units (a) The maximum number across optimizations. \n (b) The cumulative distribution across optimizations.  Figure 8. Subparser counts per main FMLR loop \niteration. earlier merging means more tree fragments outside static choice nodes, i.e., shared between \ncon.gurations. 6.3 Performance Both SuperC and TypeChef run on the Java virtual machine, which enables \na direct performance comparison. All of SuperC and Type\u00adChef s preprocessor are written in Java, whereas \nTypeChef s parser is written in Scala. Running either tool on x86 Linux requires some preparation. (1) \nAs discussed in Section 2, both tools need to be con.gured with gcc s built-in macros. SuperC automates \nthis through its build system; TypeChef s distribution includes manu\u00adally generated .les for di.erent \ncompilers and versions. (2) Both tools require a list of C .les identifying the kernel s compilation \nunits. We reuse the list of 7,665 C .les distributed with Type\u00ad  Figure 9. SuperC and TypeChef latency \nper compilation unit. Chef. K\u00a8 astner et al. assembled it by analyzing Linux con.guration database [26]. \n(3) SuperC needs to be con.gured with four de.\u00adnitions of non-boolean macros. We discovered the four \nmacros by comparing the result of running gcc s preprocessor, i.e., gcc -E, under the allyesconfig con.guration \non the 7,665 C .les with the result of running it on the output of SuperC s con.guration\u00adpreserving preprocessor \nfor the same .les. With those four de.ni\u00adtions in place, the results are identical modulo whitespace. \nThis comparison also provides us with high assurance that SuperC s preprocessor is correct. (SuperC s \nparser is less rigorously vali\u00addated with hand-written regression tests.) (4) TypeChef needs to be con.gured \nwith over 300 additional macro de.nitions. It also treats macros that are not explicitly marked as con.guration \nvariables, i.e., have the CONFIG_ pre.x, as unde.ned instead of free. We refer to the experimental setup \nincluding only the .rst three steps as the unconstrained kernel and the setup including all four steps \nas the constrained kernel. As of 2/18/12, TypeChef runs only on the constrained kernel, and only on version \n2.6.33.3. To ensure that results are comparable, the examples and experiments in this paper also draw \non version 2.6.33.3 of Linux. At the same time, SuperC runs on both constrained and unconstrained kernels. \nIn fact, the data presented in Table 3 for preprocessor usage and in Figure 8 for subparser counts was \ncollected by running SuperC on the unconstrained kernel. By comparison, the constrained kernel has less \nvariability: its 99th and 100th percentile subparser counts are 12 and 32, as opposed to 21 and 39 for \nthe unconstrained kernel. SuperC also runs on other versions of Linux; we validated our tool on the latest \nstable version, 3.2.9. Figure 9 shows the cumulative latency distribution across com\u00ad pilation units \nof the constrained kernel when running SuperC or TypeChef on an o.-the-shelf PC. For each tool, it also \nidenti.es the maximum latency for a compilation unit and the total latency for the kernel. The latter \nnumber should be treated as a conve\u00adnient summary, but no more: workload and tools easily parallelize \nacross cores and machines. When considering the 50th and 80th percentiles, both tools perform reasonably \nwell. While SuperC is between 3.4 to 3.8 times faster than TypeChef, both curves show a mostly linear \nincrease, which is consistent with a normal distribu\u00adtion. However, the knee in TypeChef s curve at about \n25 seconds and the subsequent long tail, reaching over 15 minutes, indicates a serious scalability bottleneck. \nThe likely cause is the conversion of complex presence conditions into conjunctive normal form [25]; \nthis representation is required by TypeChef s SAT solver, which TypeChef uses instead of BDDs. Figure \n10 plots a breakdown of SuperC latency. It demonstrates that SuperC s performance scales roughly linearly \nwith compi\u00adlation unit size. Lexing, preprocessing, and parsing each scale roughly linearly as well, \nwith most of the total latency split be\u00adtween preprocessing and parsing. The spike at about 25 MB is \ndue to fs/xfs/ containing code with a high density of macro invocations. To provide a performance baseline, \nwe measured the cumulative latency distribution for gcc lexing, preprocessing, and parsing the 7,665 \ncompilation units under allyesconfig. We rely on gcc s -ftime-report command line option for the timing \ndata. The 50th, 90th, and 100th percentiles are 0.18, 0.24, and 0.87 seconds, i.e., a factor of 12 to \n32 speedup compared to SuperC. It re.ects that gcc does not have to preserve static conditionals and \nthat gcc s C implementation has been carefully tuned for many years. 7. Related Work Our work joins \na good many attempts at solving the problem of parsing C with arbitrary preprocessor usage [1, 3 5, 15, \n19, 25, 26, 29, 31, 33, 36, 41]. Out of these e.orts, only MAPR [33] and TypeChef [25, 26] come close \nto solving the problem. Since we already provided a detailed comparison to MAPR and TypeChef in Sections \n1, 2 and 6, we only discuss the other e.orts here. Previous, and incomplete, work on recognizing all \nof C can be classi.ed into three categories. First are tools, such as Xrefac\u00adtory [41], that process \nsource code one con.guration at a time, after full preprocessing. This approach is also taken by Apple \ns Xcode IDE [10]. However, due to the exponential explosion of the con.g\u00ad uration space, this is only \npractical for small source .les with little variability. Second are tools, such as CRefactory [19], that \nemploy a .xed but incomplete algorithm. This approach is also taken by the Eclipse CDT IDE [21]. It is \ngood enough as long as source code does not contain idioms that break the algorithm, which is a big if \nfor complex programs such as Linux. Third are tools, such as Yacfe [31], that provide a plug-in architecture \nfor heuristically recognizing additional idioms. However, this approach creates an arms race between \ntool builders and program developers, who need to push both preprocessor and C itself to wring the last \nbit of .ex\u00adibility and performance out of their code as amply demonstrated by Ernst et al. [14], Tartler \net al. [38], and this paper s Section 6. Considering parsing more generally, our work is comparable to \ne.orts that build on the basic parsing formalisms, i.e., LR [28], LL [34], and PEG [7, 16], and seek \nto improve expressiveness and/or performance. Notably, Elkhound [30] explores how to im\u00ad prove the performance \nof generalized LR (GLR) parsers by falling back on LALR for unambiguous productions. Both SDF2 [11, 40] \nand Rats! [22] explore how to make grammars modular by build\u00ad ing on formalisms that are closed under \ncomposition, GLR and PEG, respectively. Rats! also explores how to speed up PEG im\u00adplementations, which, \nby default, memoize intermediate results to support arbitrary back-tracking with linear performance. \nFinally, ANTLR [32] explores how to provide most of the expressivity of GLR and PEG, but with better \nperformance by supporting variable look-ahead for LL parsing. At a .ner level of detail, Fork-Merge \nLR parsing relies on a DAG of parser stacks, just like Elkhound, but for a substantially di.erent reason. \nElkhound forks its internal state to accept ambigu\u00adous grammars, while SuperC forks its internal state \nto accept am\u00adbiguous inputs. Next, like several other parser generators, SuperC relies on annotations \nin the grammar to control AST building. For instance, ANTLR, JavaCC/JJTree [23], Rats!, SableCC [18], \nand SDF2 provide comparable facilities. Finally, many parsers for C employ an ad-hoc technique for disambiguating \ntypedef names from other names, termed the lexer hack by Roskind [35]. In\u00ad stead, SuperC relies on a \nmore general plug-in facility for context management. Rats! has a comparable facility, though details \ndi.er signi.cantly due to the underlying parsing formalisms, i.e., LR for SuperC and PEG for Rats!. 8. \nConclusion This paper explores how to perform syntactic analysis of C code while preserving its variability, \ni.e., static conditionals. First, we identify all challenges posed by interactions between C prepro\u00adcessor \nand language proper. Our anecdotal and empirical evidence from the x86 Linux kernel demonstrates that \nmeeting these chal\u00adlenges is critical for processing real-world C programs. Second, we present novel \nalgorithms for con.guration-preserving preprocess\u00ading and parsing. Hoisting makes it possible to preprocess \nsource code while preserving static conditionals. The token follow-set as well as early reduces, lazy \nshifts, and shared reduces make it pos\u00adsible to parse the result with very few LR subparsers and to gener\u00adate \na well-formed AST. Third, we discuss the pragmatics of build\u00ading a real-world tool, SuperC, and demonstrate \nits e.ectiveness on Linux. For future work, we will extend SuperC with support for au\u00adtomated refactorings \nand explore con.guration-preserving seman\u00adtic analysis. We expect that the latter, much like our con.guration\u00adpreserving \nsyntactic analysis, will require incorporating presence conditions into all functionality, including \nby maintaining multiply\u00adde.ned symbols. In summary, forty years after C s invention, we .nally lay the \nfoundation for e.ciently processing all of C. Acknowledgements We thank Martin Hirzel, Christian K\u00a8 astner, \nJulian Rosse, and the anonymous reviewers for their helpful feedback on earlier versions of this paper. \nWe also thank Jinyang Li and Russell Power for let\u00adting us use their cluster for data collection. This \nwork is supported by NSF CNS-0448349, CNS-0615129, and CCF-1017849. References [1] B. Adams et al. Can \nwe refactor conditional compilation into aspects? In Proc. 8th AOSD, pp. 243 254, Mar. 2009. [2] A. V. \nAho et al. Compilers: Principles, Techniques, and Tools. Addison-Wesley, 2nd edition, Aug. 2006. [3] \nR. L. Akers et al. Re-engineering C++ component models via auto\u00ad matic program transformation. In Proc. \n12th WCRE, pp. 13 22, Nov. 2005. [4] G. J. Badros and D. Notkin. A framework for preprocessor-aware C \nsource code analyses. SPE, 30(8):907 924, July 2000. [5] I. D. Baxter and M. Mehlich. Preprocessor conditional \nremoval by simple partial evaluation. In Proc. 8th WCRE, pp. 281 290, Oct. 2001. [6] A. Bessey et al. \nA few billion lines of code later: Using static analysis to .nd bugs in the real world. CACM, 53(2):66 \n75, Feb. 2010. [7] A. Birman and J. D. Ullman. Parsing algorithms with backtrack. Information and Control, \n23(1):1 34, Aug. 1973. [8] A. M. Bishop. C cross referencing and documenting tool. http: //www.gedanken.demon.co.uk/cxref/. \n[9] B. Blanchet et al. A static analyzer for large safety-critical software. In Proc. PLDI, pp. 196 207, \nJune 2003. [10] R. Bowdidge. Performance trade-o.s implementing refactoring sup\u00ad port for Objective-C. \nIn Proc. 3rd WRT, Oct. 2009. [11] M. Bravenboer and E. Visser. Concrete syntax for objects. In Proc. \n19th OOPSLA, pp. 365 383, Oct. 2004. [12] R. E. Bryant. Graph-based algorithms for boolean function manipula\u00ad \ntion. TOC, C-35(8):677 691, Aug. 1986. [13] F. DeRemer and T. Pennello. E.cient computation of LALR(1) \nlook\u00ad ahead sets. TOPLAS, 4(4):615 649, Oct. 1982. [14] M. D. Ernst et al. An empirical analysis of C \npreprocessor use. TSE, 28(12):1146 1170, Dec. 2002. [15] J.-M. Favre. Understanding-in-the-large. In \nProc. 5th IWPC, pp. 29 38, Mar. 1997. [16] B. Ford. Parsing expression grammars: A recognition-based \nsyntactic foundation. In Proc. 31st POPL, pp. 111 122, Jan. 2004. [17] Free Software Foundation. Bison. \nhttp://www.gnu.org/ software/bison/. \u00b4 ter s thesis, McGill University, Mar. 1998.  [18] E. Gagnon. \nSableCC, an object-oriented compiler framework. Mas\u00ad [19] A. Garrido and R. Johnson. Analyzing multiple \ncon.gurations of a C program. In Proc. 21st ICSM, pp. 379 388, Sept. 2005. [20] A. G. Gleditsch and P. \nK. Gjermshus. The LXR project. http: //lxr.sourceforge.net/. [21] E. Graf et al. Refactoring support \nfor the C++ development tooling. In Companion 22nd OOPSLA, pp. 781 782, Oct. 2007. [22] R. Grimm. Better \nextensibility through modular syntax. In Proc. PLDI, pp. 38 51, June 2006. [23] java.net. JJTree reference \ndocumentation. http://javacc.java. net/doc/JJTree.html. [24] V. Kabanets and R. Impagliazzo. Derandomizing \npolynomial identity tests means proving circuit lower bounds. In Proc. 35th STOC, pp. 355 364, June 2003. \n[25] C. K\u00a8astner et al. Partial preprocessing C code for variability analysis. In Proc. 5th VaMoS, pp. \n127 136, Jan. 2011. [26] C. K\u00a8 astner et al. Variability-aware parsing in the presence of lexical macros \nand conditional compilation. In Proc. 26th OOPSLA, pp. 805 824, Oct. 2011. [27] G. Klein et al. JFlex: \nThe fast scanner generator for Java. http: //jflex.de/. [28] D. E. Knuth. On the translation of languages \nfrom left to right. Information and Control, 8(6):607 639, Dec. 1965. [29] B. McCloskey and E. Brewer. \nASTEC: A new approach to refactoring C. In Proc. 10th ESEC, pp. 21 30, Sept. 2005. [30] S. McPeak and \nG. C. Necula. Elkhound: A fast, practical GLR parser generator. In Proc. 13th CC, vol. 2985 of LNCS, \npp. 73 88, Mar. 2004. [31] Y. Padioleau. Parsing C/C++ code without pre-processing. In Proc. 18th CC, \nvol. 5501 of LNCS, pp. 109 125, Mar. 2009. [32] T. Parr and K. Fisher. LL(*): The foundation of the ANTLR \nparser generator. In Proc. PLDI, pp. 425 436, June 2011. [33] M. Plato. et al. An integrated program \nrepresentation and toolkit for the maintenance of C programs. In Proc. ICSM, pp. 129 137, Oct. 1991. \n[34] D. J. Rosenkrantz and R. E. Stearns. Properties of deterministic top down grammars. In Proc. 1st \nSTOC, pp. 165 180, May 1969. [35] J. Roskind. Parsing C, the last word. The comp.compilers new\u00adgroup, \nJan. 1992. http://groups.google.com/group/comp. compilers/msg/c0797b5b668605b4. [36] D. Spinellis. Global \nanalysis and transformations in preprocessed languages. TSE, 29(11):1019 1030, Nov. 2003. [37] R. Tartler \net al. Con.guration coverage in the analysis of large-scale system software. OSR, 45(3):10 14, Dec. 2011. \n[38] R. Tartler et al. Feature consistency in compile-time-con.gurable system software: Facing the Linux \n10,000 feature problem. In Proc. 6th EuroSys, pp. 47 60, Apr. 2011. [39] M. Tomita, ed. Generalized LR \nParsing. Kluwer, 1991. [40] E. Visser. Syntax De.nition for Language Prototyping. PhD thesis, University \nof Amsterdam, Sept. 1997. [41] M. Vittek. Refactoring browser with preprocessor. In Proc. 7th CSMR, pp. \n101 110, Mar. 2003. [42] J. Whaley. JavaBDD. http://javabdd.sourceforge.net/.    \n\t\t\t", "proc_id": "2254064", "abstract": "<p>C tools, such as source browsers, bug finders, and automated refactorings, need to process two languages: C itself and the preprocessor. The latter improves expressivity through file includes, macros, and static conditionals. But it operates only on tokens, making it hard to even parse both languages. This paper presents a complete, performant solution to this problem. First, a configuration-preserving preprocessor resolves includes and macros yet leaves static conditionals intact, thus preserving a program's variability. To ensure completeness, we analyze all interactions between preprocessor features and identify techniques for correctly handling them. Second, a configuration-preserving parser generates a well-formed AST with static choice nodes for conditionals. It forks new subparsers when encountering static conditionals and merges them again after the conditionals. To ensure performance, we present a simple algorithm for table-driven Fork-Merge LR parsing and four novel optimizations. We demonstrate the effectiveness of our approach on the x86 Linux kernel.</p>", "authors": [{"name": "Paul Gazzillo", "author_profile_id": "81502809215", "affiliation": "New York University, New York, NY, USA", "person_id": "P3471240", "email_address": "gazzillo@cs.nyu.edu", "orcid_id": ""}, {"name": "Robert Grimm", "author_profile_id": "81100553777", "affiliation": "New York University, New York, NY, USA", "person_id": "P3471241", "email_address": "rgrimm@cs.nyu.edu", "orcid_id": ""}], "doi_number": "10.1145/2254064.2254103", "year": "2012", "article_id": "2254103", "conference": "PLDI", "title": "SuperC: parsing all of C by taming the preprocessor", "url": "http://dl.acm.org/citation.cfm?id=2254103"}