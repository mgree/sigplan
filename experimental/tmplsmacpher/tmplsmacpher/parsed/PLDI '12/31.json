{"article_publication_date": "06-11-2012", "fulltext": "\n Speculative Separation for Privatization and Reductions Nick P. Johnson Hanjun Kim Prakash Prabhu Ayal \nZaks David I. August Princeton University, Princeton, NJ Intel Corporation, Haifa, Israel {npjohnso, \nhanjunk, pprabhu, august}@princeton.edu ayal.zaks@intel.com Abstract Automatic parallelization is a promising \nstrategy to improve appli\u00adcation performance in the multicore era. However, common pro\u00adgramming practices \nsuch as the reuse of data structures introduce arti.cial constraints that obstruct automatic parallelization. \nPrivati\u00adzation relieves these constraints by replicating data structures, thus enabling scalable parallelization. \nPrior privatization schemes are limited to arrays and scalar variables because they are sensitive to \nthe layout of dynamic data structures. This work presents Privateer, the .rst fully automatic privatization \nsystem to handle dynamic and recursive data structures, even in languages with unrestricted point\u00aders. \nTo reduce sensitivity to memory layout, Privateer speculatively separates memory objects. Privateer s \nlightweight runtime system validates speculative separation and speculative privatization to en\u00adsure \ncorrect parallel execution. Privateer enables automatic paral\u00adlelization of general-purpose C/C++ applications, \nyielding a ge\u00adomean whole-program speedup of 11.4\u00d7 over best sequential ex\u00adecution on 24 cores, while \nnon-speculative parallelization yields only 0.93\u00d7. Categories and Subject Descriptors D.1.3 [Software]: \nConcur\u00adrent Programming Parallel Programming; D.3.4 [Programming Languages]: Processors Compilers, Optimization \nGeneral Terms Languages, Performance, Design, Experimenta\u00adtion Keywords Automatic parallelization, Separation, \nSpeculation 1. Introduction The microprocessor industry has committed to multicore architec\u00adtures. These \nadditional hardware resources, however, offer no bene\u00ad.t to sequential applications. Automatic parallelization \nis a promis\u00ading approach to achieve performance on existing and new applica\u00adtions without additional \nprogrammer effort or application changes. Yet automatic parallelization is not the norm. One limiting \nfac\u00adtor is the compiler s inability to distribute work across processors due to reuse of data structures. \nThis reuse does not contribute to the constructive data .ow of the program, but creates contention that \nprevents ef.cient parallel execution. A parallelizing compiler must either respect this contention by \nenforcing exclusivity on accesses to shared data structures, or ignore it and risk data races that change \nprogram behavior. A compiler can remove contention by creating a private copy of the data structures \nfor each worker process. Privatization eliminates Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 12, June 11 16, 2012, Beijing, China. Copyright &#38;#169; \n2012 ACM 978-1-4503-1205-9/12/06. . . $10.00 c  Figure 1: Privatization Criterion and Memory Layout. \n contention and relaxes the program dependence structure by repli\u00adcating the reused storage locations, \nproducing multiple copies in memory that support independent, concurrent access. Similarly, re\u00adduction \ntechniques relax ordering constraints on associative, com\u00admutative operators by replacing (or expanding) \nstorage locations. Prior work [7, 21, 22, 29, 32] demonstrates that privatization and reductions are \nkey enablers of parallelization. The applicability of privatization systems can be understood in two \ndimensions (Figure 1). A system uses the Privatization Cri\u00adterion [21] to decide if replacing a shared \ndata structure would change program behavior. To replicate object storage, a system de\u00adtermines Memory \nLayout: the base address and size of memory ob\u00adjects. Prior work assesses the privatization criterion \nstatically [29], dynamically [21], or speculatively [7, 22]. However, prior work limits memory layout \nto arrays and scalar variables only and fails for programs that use linked or recursive data structures. \nThe prevalent use of pointers and dynamic memory allocation creates a dichotomy between static accesses \nand objects. A pointer may refer to different objects of different sizes at different times, and static \nanalysis usually fails to disambiguate these cases. As a result, it is dif.cult for a static compiler \nto decide which objects to duplicate, even when it can decide which accesses are private. Prior techniques \nare largely inapplicable to most C or C++ applications for this reason. Table 1 summarizes prior work. \nThis work proposes Privateer, the .rst fully automatic system capable of privatizing data structures \nin languages with pointers, type casts, and dynamic allocation. Instead of relying solely on static analysis \nto determine memory layout, Privateer employs pro\u00ad.ling to characterize memory accesses at the granularity \nof mem\u00adory objects. Using pro.ling information and static analysis, Priva\u00adteer identi.es accesses to \nmemory objects that are expected to be iteration-private. Such objects are speculatively privatized, \npredict\u00ading that their accesses will remain iteration-private, thereby relax\u00ading program dependence structure \nand enabling optimization and parallelization. Privateer overcomes dif.culties in memory layout while \nmini\u00admizing validation overheads. The loop s memory footprint is par\u00adtitioned into several logical heaps \naccording to observed access patterns. Privateer speculates that these heaps remain separated at runtime \nrather than speculating that individual memory access pairs are independent. Workers validate this separation \nproperty au\u00adtonomously, requiring neither a log of accesses nor communication with other workers. This \nseparation property is ef.ciently checked using compact metadata encoded in pointer addresses. Speculative \nseparation reduces sensitivity to memory layout, thus allowing Pri\u00advateer to extend an LRPD-style shadow \nmemory test [22] to ar\u00adbitrary objects. Privateer s robust, layout-insensitive privatization and reductions \nenable automatic parallelization of applications with linked and recursive data structures. This work \ncontributes:  the .rst fully automatic system to support privatization and reductions involving pointers \nand dynamic allocation;  an ef.cient, scalable validation scheme for speculative priva\u00adtization and \nreductions based on the speculative separation of logical heaps according to usage patterns; and,  an \napplication of this speculative privatization and reduction technique to the problem of automatic parallelization. \n Privateer s transformations facilitate scalable automatic paral\u00adlelization on commodity shared-memory \nmachines. No program\u00admer hints are used, nor are any hardware extensions assumed. We implement Privateer \nand evaluate it on a set of 5 programs. On a 24-core machine, results demonstrate a geomean whole-program \nspeedup of 11.4\u00d7 over best sequential execution. To achieve these results, Privateer privatized linked \nand recursive data structures which are beyond the abilities of prior work. Speculation via heap separation \nallows Privateer to extract scalable performance from general purpose, irregular applications. 2. Motivation \nAutomatic parallelization is sensitive to the dependences in a pro\u00adgram. A single dependence may prevent \na compiler from paral\u00adlelizing an entire loop. Some dependences may never manifest, yet static analysis \nis unable to prove so. Speculation allows a compiler to overcome many of the limitations of static analysis. \nInstead of optimizing for a conservative worst case, a speculative compila\u00adtion system assumes some common \ncase of program behavior and optimizes accordingly [17, 19, 30]. A speculative system inserts code to \nvalidate these assumptions at runtime and recover when they fail. Dependence speculation is the application \nof speculative methods to remove those dependences which inhibit paralleliza\u00adtion. However, dependence \nspeculation is inappropriate for depen\u00addences which occur frequently. Privatization targets false (anti-and \noutput-) dependences. Privatization succeeds even when false de\u00adpendences are frequent, where dependence \nspeculation fails. Consider the code in Figure 2a (simpli.ed from MiBench dijkstra [12]). Attempts to \nparallelize it are inhibited by frequent false dependences incident on reused data structures. The outer \nloop (Line 46) repeatedly performs Dijkstra s algorithm. However, the loop reuses two data structures \nacross iterations: Q, a linked-list work queue (Line 5), and pathcost, an array of shortest path costs \n(Line 6). Although each iteration is conceptually independent, the reuse of Q and pathcost creates false \ndependences that impose an order on outer loop iterations, preventing parallelization. These false dependences \noccur between every pair of iterations of the loop. If a na\u00a8ive compiler were to speculate that these \nfalse dependences never manifest, the program would misspeculate on every iteration, and would fail to \nachieve scalable performance. A privatization strategy is more appropriate for such cases. Pri\u00advatization \neliminates false dependences by creating a disjoint copy of the loop s memory footprint for each worker, \nenabling work\u00aders to proceed independently and without synchronization. Each worker operates on a different \nQ containing different linked list nodes and on different pathcost arrays. To prove the privatization \ncriterion, the strategy must con.rm the absence of a loop-carried .ow dependence on every pointer load \nand store. This has been addressed using static analysis [29], dynamic tests [21], and spec\u00adulation [7, \n22] in prior work. To replace these data structures, the privatization strategy must also determine the \nmemory layout. Determining the memory layout entails identifying all private objects: Q, pathcost, and \nall linked list nodes. The memory lay\u00adout enables the system to duplicate objects and re-route memory \naccesses so workers refer to their private copy. In the absence of pointers, a variable s source-level \nname uniquely identi.es a mem\u00adory object, allowing the compiler to determine the object s address and \nsize. However, languages with pointers and dynamic alloca\u00adtion allow a many-to-many relationship between \nnames and ob\u00adjects. Pointers refer to different objects at different times and al\u00adlocation sites produce \nmany objects, causing the code to exhibit different reuse patterns. Unlike related work, Privateer addresses \nthe complications of pointers, type casts, and dynamic allocation. Privateer speculatively separates \nthe program state into several logical heaps according to the reuse patterns observed during pro\u00ad.ling. \nThe compiler indicates this separation to the runtime system, which in turn privatizes without concern \nfor individual objects. By grouping objects, a logical heap can be privatized as a whole by adjusting \nvirtual page tables, neither requiring complicated book\u00adkeeping nor adjusting object addresses in a running \nprogram. All objects of each logical heap are placed within a .xed memory ad\u00address range, allowing ef.cient \nvalidation of the separation property. In the example, Q, pathcost, and all linked list nodes are accessed \nprivately whereas adj is only read; Privateer allocates them to dis\u00adtinct logical heaps of private objects \nand read-only objects at com\u00adpile time, validating this separation at runtime. Speculative separation \ngreatly simpli.es the memory layout problem, condensing unboundedly many objects into few heaps. This \nallows Privateer to apply a speculative privatization and reduc\u00adtion transformation on programs with \npointers, dynamic allocation, and type casts. This removes false dependences, relaxing program constraints, \nand enables scalable automatic parallelization. 3. Design Privateer is a combined compiler-runtime system \nthat privatizes dy\u00adnamic memory objects ef.ciently and addresses several challenges outlined in this \nsection. The compiler system acts fully automat\u00adically without any guidance from the programmer. The \ncompiler overcomes the limitations of static analysis by using pro.ling in\u00adformation to guide its transformations \nand produces code which in\u00adteracts with the runtime system. The runtime system provides ef.\u00adcient mechanisms \nfor replication of objects to support privatization and for recovery from misspeculation. Privateer s \nprivatization criterion, forbids cross-iteration .ow dependences but, unlike [22], is not limited to \narrays: Privatization Criterion: Let O be a memory object that is accessed in a loop L. O can be privatized \nif and only if no read from O returns a value written in an earlier iteration of L. Privateer also supports \na related type of privatization that in\u00advolves reduction operations with real .ow dependences. The ac\u00adcumulator \nvariable is expanded into multiple copies, each updated independently across iterations of the loop, \nafter which all copies are merged to the .nal result. We list here our reduction criterion: Reduction \nCriterion: Let O be a memory object that is accessed in a loop L. O can be reduction-privatized if and \nonly if all updates to O within L are performed by a single associative and commutative (reduction) operator, \nand no operation within L reads an intermediate value from O. The use of pointers and dynamic allocation \nin general purpose programs requires privatization and reduction systems to address: 1. Rich Heap Model: \nthe solution needs to accurately distinguish among the many and diverse objects of the program, even \nwhen several objects are created by one static instruction.  Technique Fully Automatic Supports Pointers \nand Dynamic Allocation Privatization Reductions Supported Not limited by Static Analysis Supported Not \nlimited by Static Analysis Criterion Memory Layout Criterion Memory Layout Paralax [32] \u00d7 - . - - - \n- - TL2 [8], Intel STM [18] \u00d7 - . - - - - - PD [21], LRPD [22], R-LRPD [7] . \u00d7 . . \u00d7 . . \u00d7 Hybrid Analysis \n[24] . \u00d7 . . \u00d7 . . \u00d7 Array Expansion [10], ASSA [14], DSA [31] . \u00d7 . \u00d7 \u00d7 \u00d7 - - STMLite+LLVM [17] . . \n. . - . \u00d7 \u00d7 CorD+Objects [27] . . . \u00d7 \u00d7 . \u00d7 \u00d7  Table 1: Comparison of Privateer with privatization and \nreduction schemes. 1 struct node {int vx; node *next} 1 struct node {int vx; node *next } 2 struct queue \n{node *head ,*tail} 2 struct queue {node *head ,*tail } 3 3 5 queue Q; 4 45 void hot_ loop(int K) {6 \nint pathcost[N]; 5 46 for (src=0; src < N; ++src) {7 int adj[N][N]; 6 47 8 7 48 9 void enqueueQ(int \nv) { 8 49 11 node* N = (node*)malloc( 9 50 12 sizeof ( node )); 10 // Reallocation (Section 4.4) 51 \n13 N->vx = v; 11 node* N = h alloc(sizeof(node), 52 16 N->next = Q.tail; 12 SHORTLIVED); 53 17 ... 13 \nN->vx = v; 54 20 Q.tail = N; 14 // Privacy Check (Section 4.6) 55 f o r ( i = 0 ; i < N ; + + i ) 21 \n} 15 private read(&#38;Q->tail, sizeof(node*)); 56 pathcost[i] = infinity; 22 16 N->next = Q->tail; 57 \n// Privacy Check (Section 4.6) 23 int dequeueQ(void) { 17 ... 58 private write(&#38;pathcost[src],sizeof(int)); \n24 ... 18 // Privacy Check (Section 4.6) 59 pathcost[src] = 0; 27 qKill = Q.head; 19 private write(&#38;Q->tail, \nsizeof(node*)); 60 enqueueQ ( src ); 30 v = qKill->vx; 20 Q->tail = N; 61 33 Q.head = qKill ->next; 21 \n} 62 while (!emptyQ ()) {35 free ( qKill ); 22 63 v = dequeueQ (); 36 return v; 23 int dequeueQ(void) \n{ 64 // Privacy Check (Section 4.6) 37 } 24 ... 65 private read(&#38;pathcost[v],sizeof(int)); 45 void \nhot_ loop(int K) { 25 // Privacy Check (Section 4.6) 66 d = pathcost[v]; 46 for (src= 0; src < N; ++src) \n{ 26 private read( &#38;Q->head ); 67 for (i=0; i < N; ++i) {55 for (i= 0; i < N; ++i) 27 qKill = Q->head; \n68 ncost = adj[v][i] + d;56 pathcost[i] = infinity; 28 // Separation Check (Section 4.5) 69 if (pathcost[i] \n> ncost) { 58 29 check heap( qKill, SHORTLIVED ); 70 // Privacy Check (Section 4.6) 59 pathcost[src] \n= 0; 30 v = qKill ->vx; 71 private write( &#38;pathcost[i],60 enqueueQ ( src ); 31 // Privacy Check (Section \n4.6) 72 sizeof(int) ); 61 32 private write( &#38;Q->tail ); 73 pathcost[i] = ncost; 62 while (!emptyQ \n()) { 33 Q->head = qKill ->next; 74 enqueueQ (i); 63 v = dequeueQ (); 34 // Reallocation (Section 4.4) \n75 } 66 d = pathcost[v]; 35 h dealloc(qKill, SHORTLIVED); 76 } 67 for (i= 0; i < N; ++i) { 36 return \nv; 77 } 68 ncost = adj[v][i] + d; 37 } 78 // Value prediction69 if (pathcost[i] > ncost) { 38 79 if( \nQ->head != NULL ) misspec(); 73 pathcost[i] = ncost; 39  80 if( Q->tail != NULL ) misspec(); 74 enqueueQ \n(i ); 40 81 }75 } 41 82 }76 } 42 pathcost = h alloc(N*sizeof(int),PRIVATE); 77 } 43 adj = h alloc(N*N*sizeof(int), \nREADONLY); 81 } 44 }82 } (b) Speculatively privatized code, before parallelization. Changes are in grey. \n(a) Sequential dijkstra example. Figure 2: Motivating example for Privateer. The original sequential \napplication is on the left. The right shows the code after the speculative privatization transformation, \nbefore it is automatically parallelized. Unchanged lines are consistently numbered between (a) and (b). \n2. Robust Points-to Map: Instructions manipulate pointers, yet pri-system should know how many times, \nwhere, and how large it vatization replicates memory objects. A robust mapping from allocates before \nprivatizing node N in Line 11. pointers to objects is needed to consistently update both. In Fig\u00ad 4. \nReplacement Transparency: When replacing the storage in a ure 2, the system must determine the target \nobject of pointers running system, all pointers must remain valid. The system loaded from queue and node \nobjects (Lines 27 and 33). cannot move privatized storage as it cannot guarantee that all 3. Object \nBase, Size, Count: The duplicated storage must be at references will be updated. The system cannot even \nassume that least as large as the original. This also affects the allocation of pointer values are visible \nin the IR because of the possibility of metadata at per-object or per-byte resolution. In Figure 2, the \ndisguised pointers [3]. Privateer overcomes these issues by speculating separation properties of the \nprogram. In this paper, we say that an access path is a sequence of operations which computes a pointer \naddress, and that two access paths are separated if the sets of objects they name are disjoint. Separation \nis weaker than points-to information, since it does not enumerate the objects referenced by an access \npath. Sep\u00adaration is weaker than alias information, since it says nothing about two addresses within \nthe same object. Yet separation information is strong enough to simplify memory layout. Further, separation \ncan be validated at runtime without inter-worker communication. 3.1 Analysis and Transformation The .rst \ntask of the compiler is to recognize situations where pri\u00advatization eliminates false dependences (and \n.ow dependences for reductions), thereby enabling automatic parallelization. Privateer builds a representation \nof the dependence structure of the program s hot loops, and then employs memory and control pro.ling \nto re\u00admove rare and nonexistent dependences. This representation con\u00adtains only frequently occurring \ndependences. Privateer interprets this as an optimistic view of the expected program dependences. When \nthe compiler discovers a hot loop that cannot be paral\u00adlelized due to false or .ow dependences, it investigates \nwhether the privatization and reduction criteria apply. Privateer classi.es every memory object according \nto its observed usage pattern within the loop. Based on this classi.cation, the compiler decides if privatiza\u00adtion \nis applicable and would enable parallelization. The second task of the compiler is to perform the privatization \ntransformation by inserting additional instructions to the program. These instructions interact with \nthe runtime system to control the allocation of objects in memory and to validate that memory ac\u00adcesses \nmatch the expected patterns. The resulting speculatively pri\u00advatized program is then amenable to automatic \nparallelization by parallelizing transformations such as DOALL.  3.2 Runtime Support System Traditional \nprivatization systems do not privatize many classes of dynamically allocated data structures since they \nare unable to determine the object sizes, number, and locations. Privateer takes a different approach. \nPrivateer assigns each memory object to one of several logical heaps. At runtime, those objects are allocated \nwithin a known, .xed range for each logical heap. This simpli.es the memory layout problem, since the \nruntime may treat each logical heap as a single object with known base and bound instead of many unknown \nobjects. Privateer may test whether a pointer address falls within a given heap using only a few instructions. \nThe system replaces object storage by manipulating page maps. Replacement transparency is satis.ed since \nvirtual addresses do not change. Before or after the invocation of a parallel region, these logical heaps \nbehave as normal program memory and support any form of access. During an invocation, Privateer changes \nthe process vir\u00adtual page map, thus replacing the heaps physical pages. This al\u00adlows the runtime to replicate \nthe storage for all objects in a heap, marking them with the copy-on-write page protection. Initially, \nval\u00adues within the private heap appear identical to those from the se\u00adquential region. However, the OS \ntraps updates to the private heap and silently duplicates those pages, thus isolating each worker s up\u00addates. \nThe reduction heap is replaced and bytes within those pages are initialized with the identity value for \nthe reduction operator. Privateer validates most speculative properties with instanta\u00adneous checks they \ncan be determined at a point in the code and do not rely on history of previous operations. The speculative \nmap\u00adping of pointers to a particular heap can be checked by examining only the pointer address. The speculative \nrestriction on the lifetime of short-lived objects can be checked at the end of each iteration. These \nproperties are strong enough to provide the enabling bene.ts of speculation, yet induce only minimal \nruntime overhead. Privacy validation is more complicated, requiring that we con\u00adsider all operations \nthat access a particular private object. A chal\u00adlenging aspect of privacy validation is allowing reads \nof values live\u00adin to the loop. A worker who reads a live-in value must guarantee that no worker de.ned \nthat value in an earlier iteration, requiring a .ow of information among workers. The Privateer runtime \nsys\u00adtem employs a two-phase approach to reduce the communication overhead of validation. The .rst phase \noccurs immediately, and de\u00adtects several cases of privacy violation without any communica\u00adtion among \nthe workers. The second phase completes the valida\u00adtion check by handling the cases of privacy violation \nthat require communication. The second phase occurs during a checkpoint op\u00aderation (see Section 5.2). \nUpon entering the parallel region, the runtime also creates a shadow heap for each worker which has the \nsame size as the private heap. Each byte of data within the private heap corresponds to a byte of metadata \nin the shadow heap. Privateer records metadata in the shadow heap about the history of accesses to private \nmemory. This shadow heap is analogous to the shadow arrays in the LRPD technique [22]. Each byte of metadata \ncontains a code indicating the history of that private byte given all information available to a worker. \nIn particular, metadata contains enough information to determine whether a byte of private memory may \ncontain a live-in value, or if it was necessarily de.ned during an earlier iteration of the parallel \nregion. The interpretation of these codes is discussed in Section 5.1. Since the compiler relies on pro.le \ndriven speculative paral\u00adlelization, the runtime system must support rollback and recovery in case of \nmisspeculation. Privateer provides this via checkpoint\u00ading. Speculative state is collected from all workers \nat regular inter\u00advals and validated for misspeculation. If no violations occur, then the checkpoint is \nmarked non-speculative and used as a recovery point. Checkpoints are only collected and validated after \na large number of iterations. This policy reduces checkpointing and vali\u00addation overheads in the common \ncase, but discards and recomputes a larger amount of work upon misspeculation. 4. The Privateer Analysis \nand Transformation The Privateer system provides fully automatic analyses and trans\u00adformations to privatize \nthe data structures used by general purpose C and C++ applications. Figure 3 describes the compiler compo\u00adnent. \nEach step is described in the following sections. 4.1 Pro.ling The Privateer system uses a novel pointer-to-object \npro.ler to con\u00adnect dynamic pointer addresses with a set of object names. The pro\u00ad.ler assigns static \nnames to the memory objects of global or con\u00adstant variables. The pro.ler names dynamic objects (e.g. \nmalloc or new) or stack slots according to the instruction which allocates them and a dynamic context. \nThe dynamic context distinguishes dynamic instances of a static instruction by listing the function and \nloop invocations which enclose that instruction. The pointer-to-object pro.ler instruments the program \nto main\u00adtain a interval map from ranges of memory addresses to the name of the memory object which occupies \nthat space, like [34]. This in\u00adterval map enables the pro.led program to determine the name of the object \nreferenced by any pointer during a pro.ling run. The pro\u00ad.ler instruments every pointer that cannot be \nmapped to a unique object at compile time. The pro.ler accumulates this information over program execution. \nFinally, this pro.ler tracks the allocation and deallocation of memory objects with respect to dynamic \ncontexts. This informa\u00adtion allows the compiler to characterize the lifetime of objects and  Figure \n3: Structure of the Privateer Analysis and Transformation. distinguish between short-and long-lived objects, \nsupporting ob\u00adject lifetime speculation [13]. Short-lived objects exist only within a single iteration \nof a loop. In Figure 2, the pointer-to-object map contains the following data. The pointer qKill on Line \n27 always points to objects allo\u00adcated by Line 11 in one of two contexts: either enqueueQ called at Line \n60 or enqueueQ called at Line 74. All objects allocated on Line 11 are short-lived with respect to the \nloop on Line 46. Privateer uses other pro.lers. A trip count pro.ler [15] identi\u00ad.es biased branches \nfor control speculation (`a la [5]). A memory .ow dependence pro.ler similar to [4] augments static analysis. \nA value-prediction pro.ler guides value prediction speculation (`a la [11]). Finally, an execution time \npro.ler, similar to gprof [26], .nds hot loops.  4.2 Classi.cation The hot loops access some objects \nin a restricted fashion. Using pro.le information, the system classi.es each object as one of .ve access \npatterns: private, reduction, short-lived, read-only, and unrestricted. These labels are summarized in \na heap assignment, which describes overall memory usage by mapping each object to one of the .ve heaps \nwith restricted semantics. Algorithm 1 determines a heap assignment for each loop. First, it calls getFootprint \n(Algorithm 2) to determine the read, write, and reduction footprints of the loop. These footprints are \nrepre\u00adsented as sets of memory object names and may overlap. This func\u00adtion accumulates the objects written \nby a store operation or read by a load operation. The algorithm also identi.es operation sequences which \nsyntactically resemble an associative and commutative re\u00adduction operation. Limited pro.le coverage has \nminimal effect on Privateer s analyses, since such code is likely removed via control speculation. Algorithm \n1: classify(L) let ShortLived = \u00d8; let Redux = \u00d8; let Unrestricted = \u00d8; let Private = \u00d8; let ReadOnly \n= \u00d8; let (ReadFootprint, WriteFootprint, ReduxFootprint) = getFootprint(L) ; foreach object o . WriteFootprint \n. ReadFootprint do if Pro.le.isShortLived(o, L) then ShortLived = ShortLived .{ o } ; end end foreach \nobject o . ReduxFootprint do if (o . ReadFootprint) and (o . WriteFootprint) then Redux = Redux .{ o \n} ; end end let D = All cross-iteration memory .ow dependences in L (assuming control and memory .ow \npro.les) foreach dependence (a . b) . D do let (Ra, Wa, Xa) = getFootprint(a) ; let (Rb, Wb, Xb) = getFootprint(b) \n; let F=(Wa . Xa) n (Rb . Xb); Unrestricted = Unrestricted . (F \\ ShortLived \\ Redux) ; end Private = \nWriteFootprint \\ ShortLived \\ Unrestricted \\ Redux; ReadOnly = ReadFootprint \\ ShortLived \\ Unrestricted \n\\ Redux \\ Private; return (ShortLived, Redux, Unrestricted, Private, ReadOnly); In Figure 2a, Privateer \ncomputes the footprint of the hot loop (Line 46), as follows. The read set contains the global queue \nstruc\u00adture Q, the global arrays pathcost and adj, and all linked list nodes allocated by Line 11. The \nwrite set contains Q, pathcost, and all linked list nodes. The reduction set is empty. Algorithm 2: getFootprint(S) \nlet ReadFootprint = \u00d8; let WriteFootprint = \u00d8; let ReduxFootprint = \u00d8; foreach instruction I in S do \nif I is of the form r := load p then let O = Pro.le.mapPointerToObjects(p); if (exists instruction of \nthe form store v, p ) and (exists instruction of the form v := op r, x where op is associative and commutative) \nthen ReduxFootprint = ReduxFootprint . O; else ReadFootprint = ReadFootprint . O; end end if I is of \nthe form store v, p then let O = Pro.le.mapPointerToObjects(p); if (exists instruction of the form r \n:= load p ) and (exists instruction of the form v := op r, x where op is associative and commutative) \nthen ReduxFootprint = ReduxFootprint . O; else WriteFootprint = WriteFootprint . O; end end if I is of \nthe form r := call f(...) then recur on f; end end return (ReadFootprint, WriteFootprint, ReduxFootprint) \n The classi.cation algorithm (Algorithm 1) partitions the loop s memory footprint across the .ve heaps \naccording to access pat\u00adterns. If an object is allocated and freed within an iteration, classi\u00ad.cation \nassigns it to the short-lived heap. If the compiler does not expect an object in the reduction set to \nbe accessed by loads or stores elsewhere in the loop, classi.cation assigns it to the reduc\u00adtion heap. \nThis indicates that the reduction criterion is expected to succeed, but will still be veri.ed at runtime \nvia separation checks (Section 5.1). The unrestricted heap contains objects which par\u00adtake in a loop-carried \ndependence, unless those objects were al\u00adready assigned to the short-lived or reduction heaps. The private \nFigure 4: A heap assignment for Figure 2. Privateer speculatively separates objects into several classi.cations. \nObjects are allocated from logical heaps for ef.cient validation.  heap receives all other written objects. \nThe read-only heap receives all other read objects. These .ve sets are collectively referred to as a \nheap assignment. Figure 4 shows a heap assignment for the code in Figure 2a. The short-lived set contains \nall linked list nodes allocated at Line 11. The reduction and unrestricted sets are empty (and not shown). \nThe private set contains the global queue structure Q and the global array pathcost. The read-only set \ncontains the global array adj.  4.3 Selection The compiler selects a subset of loops to parallelize \nfrom the set of hot loops with heap assignments. Program dependences are computed using static analysis \nand then re.ned according to the heap assignment: The logical heaps are separated: For a pair of operations \no and p whose footprints are assigned to sets of heaps ho and hp respectively, if ho n hp = \u00d8 then remove \nall memory dependences o . p and p . o.  The private, short-lived and reduction heaps eliminate loop\u00adcarried \ndependences: For an operation o, if the footprint of o is contained in the private, short-lived, and/or \nreduction heaps, then for all operations x in the loop, remove all loop-carried memory dependences o \n. x and x . o.  Additionally, dependences are re.ned with standard rules for value prediction, control \nspeculation, and I/O deferral. The result is an optimistic view of program behavior in the expected case. \nThis dependence structure is passed to parallelizing transformations to exclude inapplicable loops. The \ncompiler selects the largest (by ex\u00adecution time) set of parallelizable loops subject to the following \ncompatibility constraints. The compiler avoids nested parallelism: if the compiler .nds (via static analysis \nor pro.ling results) that two loops may ever be simultaneously active, it marks the two loops incompatible. \nSecond, two loops are incompatible if an object is assigned to different heaps for each loop. If two \nloops are incom\u00adpatible, the compiler selects at most one of them. This selection process yields a single \nheap assignment for the set of selected hot loops.  4.4 Replace Allocation Privateer replaces the allocation \nsite for each object from the heap assignment. Storage for global objects is allocated from the appro\u00adpriate \nheap during an initializer which runs before main (Lines 40 44), and is saved in a global variable (Lines \n5 7). All uses of the addresses of such objects are replaced with loads from said global pointer. For \nstack allocations, the operation is replaced with an allo\u00adcation from the appropriate heap and a corresponding \ndeallocation is inserted at all function exits. Similarly, heap allocations and deal\u00adlocations are replaced \nwith the routines for the appropriate heap. 4.5 Add Separation Checks The compiler inserts calls to \ntrigger validation. To validate that a pointer refers only to objects within the correct heap, the compiler \n.nds every static use of a pointer within the parallel region and traces back to the static de.nition \nof that pointer. It inserts calls to the check heap function, which performs a separation check (see \nSection 5.1). Figure 2b shows a separation check on Line 29; other checks are proved successful at compile \ntime and are elided. 4.6 Add Privacy Checks To validate that private objects never partake in loop-carried \n.ow dependences, the compiler .nds every operation within the parallel region which accesses an object \nin the private heap. It inserts a call to private read before loads, and a call to private write be\u00adfore \nstores. These calls report address and access-size information to the runtime system, causing the runtime \nto validate privacy (see Section 5.1). In Figure 2b, Lines 15, 19 and 65 show privacy checks inserted \nby Privateer. 5. The Privateer Runtime Support System The runtime support library serves several purposes. \nIt manages the logical heaps and validates their speculative separation. It provides validation of speculative \nprivacy. It coordinates periodic check\u00adpoints and initiates recovery after a misspeculation. Parallel \nexecu\u00adtion is governed by the parallelizing transformation applied to the program after privatization. \nIn this investigation, the parallelizing transformation is DOALL. Figure 5 shows a schematic time line \nof parallel execution with three workers. Speculative privatization does not add explicit com\u00admunication \nbetween the workers, but requires periodic checkpoints, marked as CHKn. Additionally, each worker performs \nsmall inline misspeculation checks, denoted by grey bars. The .gure shows a misspeculation at iteration \n2k +4, followed by sequential, non\u00adspeculative recovery. Parallel execution resumes after recovery. 5.1 \nRuntime Validation of Speculation Separate Heaps: The runtime system makes heavy use of the POSIX shared \nmemory (shm) and memory map (mmap) facilities to achieve the desired separation model. Since workers \nmust up\u00addate their virtual memory maps independently, the Privateer run\u00adtime system uses processes and \nnot threads. Heaps are created via shm open. Each process maps them into its address space via mmap with \nread-only, read-write or copy-on-write protections. The mmap facility allows the system to select a .xed, \nabsolute virtual address for these heaps. Privateer exploits this feature by Figure 5: Example showing \nthe worker processes during a parallel region. Iteration 2k +4 misspeculates, triggering a recovery. \n hiding a heap tag within the heaps virtual addresses. Bits 44 46 of the address hold a 3-bit heap tag, \nallowing the runtime to quickly determine if a pointer references an address within the correct heap. \nAs a heap is subdivided by allocations, all objects within that heap inherit its tag. This choice of \nbit location was selected for compatibility with common operating systems and hardware, and allows 16 \nterabytes of allocation within any heap. The privatizing transformation inserts a heap check at each \ninstruction which computes a pointer address in the parallel region. This check indicates an assumed \ntarget heap for that pointer. The runtime tests the pointer s heap tag via bit arithmetic, reporting \nmisspeculation upon mismatch. The bit patterns for the private and shadow heaps are chosen so they differ \nby only one bit. For a byte at address p within the private heap, the system computes the address of \nthe corresponding byte of metadata in the shadow heap with a single bit-wise OR instruction. Validating \nShort-Lived Objects: Each worker counts the number of objects allocated and not freed from its short-lived \nheap. If any of these objects is live at the end of an iteration, then lifetime speculation is violated, \nand the worker reports misspeculation [13]. Validating Privacy: Privacy is validated in two phases. First, \na worker employs a fast test upon each access to private memory. This test requires no communication \nwith other workers, but may fail to catch some violations. A thorough check will catch remain\u00ading violations \nduring the checkpoint operation (see Section 5.2). Every byte of metadata contains one of four codes: \nlive-in (0), old-write (1), read-live-in (2), or a timestamp 3+(i - i0) encod\u00ading the iteration i after \nthe most recent checkpoint i0. Initially, the shadow heap contains all zero values (live-in). Privacy \nchecks cause the runtime system to update metadata upon every private access. The transition rules for \nmetadata are shown in Table 2. The simplest cases are the most common: a write to private memory updates \nthe corresponding bytes of metadata with the current iteration times\u00adtamp; a read from private memory \nchecks that the corresponding bytes of metadata match the current iteration timestamp. If the pro\u00adgram \never reads a value that was de.ned by an earlier iteration, this can be detected by the fourth rule. \nTo support reading live-in values, the runtime marks a live-in byte with the code read-live-in. This \nindicates that a byte has been Table 2: Metadata transitions on private accesses. \u00df is the times\u00adtamp \nfor the current iteration, and a is the timestamp for an earlier iteration. Op. Metadata Comment Before \nAfter 0 2 Read a live-in value. 1 misspec Loop-carried .ow dependence. Read 2 2 Read a live-in value. \na (2 < a < \u00df) misspec Loop-carried .ow dependence. \u00df \u00df Intra-iteration (private) .ow. 0 \u00df Overwrite a \nlive-in value. 1 \u00df Overwrite an old write. Write 2 misspec Conservative false positive. a (2 < a = \u00df) \n\u00df Overwrite a recent write. read, and appears to be a live-in value, but that privacy cannot be guaranteed \nwithout communicating with other workers. Instead, this property will be checked at the next checkpoint. \nIf such a byte is overwritten before the checkpoint occurs, the system will conser\u00advatively report a \nmisspeculation. Such a misspeculation may rep\u00adresent a false-positive. We selected this design since \ntests without false positives require a separate read-iteration timestamp, doubling the size of metadata. \nWe did not observe false positives in practice. These metadata codes will eventually over.ow a byte. \nA check\u00adpoint resets the metadata range by replacing all writes before the checkpoint (metadata a = 3) \nwith old-write (1). Privateer triggers a checkpoint operation at least every 253 iterations. 5.2 Checkpoints \nTo support recovery, the speculative program periodically saves valid program state. The runtime selects \na checkpoint period k be\u00adfore the parallel invocation. After every k-th iteration, worker pro\u00adcesses \ncopy their speculative state (the private, shadow, and reduc\u00adtion heaps) into a checkpoint object, as \nin Figure 5. This object is allocated by the .rst worker to reach that iteration and retired after the \nlast worker reaches the iteration. The checkpoint system maintains an ordered list of checkpoint objects, \neach representing a distinct point in time, and allows arbitrarily many checkpoint ob\u00adjects. Workers \nacquire a lock on a single checkpoint object, not the whole checkpoint system, to avoid barrier penalties. \nThis allows a fast worker to proceed to subsequent work units without waiting for slow worker processes \nto reach the checkpoint. As mentioned in Section 5.1, privacy is validated by a two-phase approach. The \nruntime performs the second phase of validation as each worker adds its speculative state to the checkpoint \nobject, us\u00ading the same metadata transition rules as listed in Table 2. If mis\u00adspeculation is detected \nwhile a worker is performing a checkpoint, that worker signals a misspeculation and aborts. Otherwise, \nthat checkpoint object is marked non-speculative as soon as all workers have added their state to the \ncheckpoint. 5.3 Recovery If a worker detects misspeculation, it sets a global misspeculation .ag and \nrecords the misspeculated iteration number. This worker terminates immediately, squashing all its speculative \nstate created since its last checkpoint. Since workers run at different speeds, it is possible that a \nre\u00admaining worker has not yet reached the checkpoint during which misspeculation occurred. Workers consult \nthe global misspecula\u00adtion .ag after each iteration. If set, each worker compares its check\u00adpoint ID \nLi/kJ against the ID of the checkpoint which misspecu\u00adlated. If a worker has not yet reached the point \nof misspeculation, it continues execution; otherwise it terminates. This policy reduces wasted work upon \nmisspeculation, as in Figure 5. If workers dis\u00adcover an earlier misspeculation before they terminate, \nthey update the earliest iteration at which misspeculation occurs, and abort. Once all worker processes \nhave terminated, the main process begins non-speculative recovery. Using several calls to mmap, the main \nprocess replaces its heaps with those from the last valid checkpoint. The main process re-executes iterations \nnon\u00adspeculatively until it has passed the iteration at which the earliest misspeculation occurred. Unless \nthe program exits the loop during recovery, parallel execution resumes. 6. Evaluation Privateer is evaluated \non a shared-memory machine with four 6\u00adcore Intel Xeon\u00ae X7460 processors (24 cores total) running at \n2.66 GHz with 24 GB of memory. Its operating system is 64-bit Ubuntu 9.10. The compiler is built on LLVM \n[15] revision 139148. Privateer is evaluated with 5 programs that require speculative privatization for \nparallelization, as described in Table 3. Programs are selected from a set of C and C++ applications \nbecause their par\u00adallelization is limited by false dependences. We exclude many pro\u00adgrams because they \nare parallelizable without Privateer. Some other programs feature data structures that Privateer can \nsuccessfully pri\u00advatize, but whose loops cannot be parallelized with DOALL be\u00adcause of real loop-carried \n.ow dependences. We exclude those as well, since they are limited by DOALL, not by Privateer. More powerful \nparallelizing transformations, such as PS-DSWP [20] will be investigated in future work. Speci.cally, \nwe exclude 177.mesa and 462.libquantum since they can be parallelized without the aid of speculation, \nand thus we do not take credit for their performance. We exclude 164.gzip, 256.bzip2, and 456.hmmer since \nthe compiler can\u00adnot identify DOALL loops after Privateer s speculation has been applied. The compiler \ndoes not transform these codes. Each benchmark is pro.led with a training input (train). Per\u00adformance \nevaluations are measured with a different testing input (ref). When we pro.le these with a third input \n(alt), the compiler generates identical code, suggesting that Privateer s analysis is rea\u00adsonably stable \nwith respect to pro.le input. 6.1 Parallel Performance Results Figure 6 presents performance results \ngenerated by the fully auto\u00admatic privatization and parallelization transform. These measure\u00adments are \nwhole application speedups relative to the best sequen\u00adtial performance of the original application. \nThe sequential appli\u00adcations are compiled with clang -O3. These results indicate that privatization of \ndata structures un\u00adlocks parallelization opportunities in these programs. Additionally, they indicate \nthat Privateer s speculative separation is suf.ciently powerful to reason about and operate on the dynamically \nallocated and irregular data structures present in these applications. The dijkstra application from \nMiBench [12] reuses several data structures. It maintains a table of shortest paths and linked list of \nnodes whose shortest paths have changed both as global variables. Successive iterations of the hot loop \nare synchronized by false dependences on these data structures. Privateer uses value prediction to speculate \nthat the linked list is empty at the beginning of each iteration and privatizes the head node of the \nlinked list and the shortest path table. The nodes within the linked list are assigned to the short-lived \nheap. Additionally, the hot loop includes calls to printf that are deferred into the speculative system, \nso that they may issue in any order yet commit in-order. Privateer transforms the sequential version \nof the swaptions program from PARSEC [2]. It parallelizes the hot loop in the function worker by privatizing \n17 memory objects, 15 of which are short-lived. The short-lived objects include a large number of vectors \nand matrices (arrays of pointers to row vectors) which  Figure 7: Enabling effect of Privateer at 24 \nworker processes. are dynamically allocated at various points within worker and its callees, and passed \naround indirectly through other data structures. The LRPD-family techniques are inapplicable to this \nbenchmark because of the linked matrix data structures. The 052.alvinn program is from SPEC [25]. To \nenable parallelization, Privateer privatizes four stack-allocated arrays. 052.alvinn iterates over these \narrays using pointer arithmetic and passes array references to callees, making static analysis dif.cult. \nAdditionally, Privateer handles reductions on two global arrays and as well as a scalar local variable. \nAt 8 cores, Privateer achieves a speedup of 5.66\u00d7 on commodity hardware. OpenImpact [35] re\u00adports 6.44\u00d7 \nwith the help specialized hardware extensions. This compares favorably to STMLite+LLVM [17], which reports \nless than 2\u00d7 in a software-only system with 8 cores. The enc-md5 program from Trimaran [28] computes \nmessage digests for a large number of data sets and prints each to standard output. Two factors limit \nparallelization of the programs outer loop: false dependences on the MD5 state object and digest buffer, \nand calls to printf. Privateer privatizes the state object and marks the digest buffer as short-lived. \nThe side effects of stream output functions are issued through the checkpoint system and take effect \nonly when the checkpoint is marked non-speculative. Privateer transforms the sequential version of blackscholes \nfrom PARSEC [2]. In the hot loop-nest of this program, the inner loop is embarrassingly parallel. However, \nthe outer loop cannot be parallelized directly because of output dependences on the pricing array, which \nis allocated in a different function. Privateer privatizes this array, allowing for parallel execution \nof the outer loop. Figure 7 compares the performance of the DOALL transforma\u00adtion using 24 workers, with \nand without Privateer. DOALL-only refers to a non-speculative implementation which distributes loop iterations \nacross worker threads, and thus does not incur checkpoint or validation overheads. Privateer enables \nparallelization of hotter loops. For 052.alvinn, DOALL-only transforms a deeply nested inner loop. Performance \ngains do not outweigh the overhead of dis\u00adpatching worker threads, and thus DOALL-only experiences slow\u00addown. \nDOALL-only does not parallelize any loops in dijkstra or enc-md5 because of real, frequent false dependences. \nThe hot loop in swaptions is parallelizable but could not be proved paralleliz\u00adable by our static analysis. \nDOALL-only parallelizes a hot inner loop in blackscholes; however, privatization allows the compiler \nto parallelize a hotter loop. Privatization enables the compiler to parallelize a single invocation, \nthus reducing spawn/join costs. 6.2 Overhead of the Runtime System Privateer minimizes validation s \nruntime overhead. Figure 8 presents a breakdown of measured overheads for each program when using Table \n3: Details of privatized and parallelized programs, including number of invocations of the parallel region; \ntotal number of checkpoints constructed; total private bytes read and written; static number of objects \nassigned to each heap; and additional necessary transformation including value prediction speculation, \ncontrol speculation, and deferral of I/O operations. Program Dynamic Replaced Static Allocation Sites \nExtras Invoc Checkpt Priv R Priv W Private Short-Lived Read-Only Redux Unrestricted 052.alvinn 200 2,600 \n8.2 GB 300 MB 4 0 4 3 0 - dijkstra 1 5 84.9 GB 56.7 GB 10 3 11 0 0 Value, Control, I/O blackscholes 1 \n5 0 B 4.0 GB 1 0 9 0 0 Value swaptions 1 17 288 KB 169 KB 2 15 5 0 0 Value, Control enc-md5 1 5 25.5 \nGB 30.8 GB 2 1 4 0 0 Control, I/O  Figure 6: Whole program speedups of the fully automatically parallelized \ncode, measured with respect to the best running time of the unmodi.ed sequential application compiled \nwith clang -O3. Each point is the average of three trials. Figure 8: Breakdown of overheads on parallel \nperformance. 4, 8, 12, 16, 20, and 24 worker processes. These numbers are nor\u00admalized to the total computational \ncapacity (CPU-seconds) of the parallel region: the number of processor cores times the duration of the \nparallel invocation. In these units, perfect utilization would be represented as 100% useful work. Overheads \nexperienced dur\u00ading the parallel region subtract from utilization and prevent linear speedup. All times \nmeasure wall-clock time, not processor time: they include time spent blocking and context switching. \nIf the par\u00adallel region invokes more than once, these numbers are the sum over all parallel invocations. \nIn the overheads .gure, Useful Work refers to the portion of computational capacity spent executing instructions \nfrom the orig\u00adinal sequential application. Private Read refers to the capacity spent updating metadata \nin response to a read from a private object. Similarly, Private Write refers to the bookkeeping for \na write to a private object. Checkpoint refers to the capacity spent collecting, validating, and combining \ncheckpoints. Spawn refers to the unused capacity after a parallel invocation has begun, yet before the \nworker processes begin execution. This overhead is mostly determined by the latency of the operating \nsys\u00adtem s implementation of fork. Join refers to the non-useful capac\u00adity after a worker process has \n.nished its work units, yet before the parallel invocation has .nished. This overhead is caused by four \nfactors: imbalance among the workers, the latency of the worker\u00adcompleted signal, the cost of installing \nthe .nal non-committed state into the main process, and the cost of committing output oper\u00adations that \nwere issued during the parallel region. These two mea\u00adsurements are presented together as Spawn/Join. \nResults show that parallelized applications utilize most of the parallel resources for useful work. Both \n052.alvinn and dijkstra waste a signi.cant amount of time joining their workers. This is caused by an \nimbalance in the latency of each worker, and a load balancing technique such as work stealing could potentially \naddress this inef.ciency. Validation of privacy is the next largest source of overhead. Percent of computational \ncapacity used for pri\u00advacy validation remained mostly constant as the number of workers increased, suggesting \nthat the absolute amount of work for privacy validation grows with the number of workers. 6.3 Misspeculation \nAnalysis Privateer employs speculation to eliminate rare dependences and thus optimizes for the common \ncase. To reduce the risk of misspec\u00adulation, Privateer interprets pro.ling results conservatively. No \npro\u00adgrams experienced misspeculation during evaluation. To better un\u00adderstand the effect of misspeculation, \nwe inject arti.cial misspecu\u00ad  Figure 9: Performance degradation with misspeculation. lation into the \nrunning application at .xed frequencies. The results of this experiment are shown in Figure 9. We present \nmisspecula\u00adtion rates as the percentage of iterations which misspeculate as op\u00adposed to checkpoints, \nsince iterations are more standard. Privateer s recovery mechanism operates at the granularity of checkpoints \n(see Section 5.2). Thus, a misspeculation rate of 0.1% causes about one in four checkpoints to fail. \nFor blackscholes, we increased the input size so that the hot loop executed at least 1,000 iterations. \nFor most programs, these results indicate that Privateer s per\u00adformance bene.ts are sensitive to misspeculation. \nFour of .ve pro\u00adgrams lose half of their speedup with a misspeculation rate of 0.1%. This suggests that \nPrivateer requires high-con.dence speculation for performance. 7. Related Work Paralax [32] uses privatization \nto enable parallelization. The au\u00adthors note that privatization analysis is dif.cult on C programs. They \npropose KILL annotations to assert the absence of .ow de\u00adpendences through a data structure, indirectly \nanswering the priva\u00adtization criterion. These annotations are applied to named objects or object referenced \nby a single pointer indirection. This prevents the application of KILL to recursive data structures. \nEarly works on privatization [16, 29] are limited by the strength of static analysis on the privatization \ncriterion and memory layout problems. The PD Test [21] reduces reliance on static analysis by adding \ninspector loops to dynamically verify the privatization crite\u00adrion at runtime. Similarly, Hybrid Analysis \n[24] uses a generalized representation for indirect array references to statically generate predicates, \nwhich are then resolved at runtime for dynamic priva\u00adtization. The LRPD [22] and R-LRPD [7] Tests obviated \nthe need for static analysis by evaluating the privatization criterion specula\u00adtively. All of these techniques \nare evaluated on array-based codes written in FORTRAN and cannot handle pointers, linked lists, and other \ndynamic data structures. Array Static Single Assignment (ASSA) [14] extends Static Single-Assignment \nform [6] to arrays. ASSA requires that any named memory location has exactly one de.nition. Repeated \nup\u00addates are represented with new static names and joined via f-nodes. In this form, false dependences \ndo not exist, and a compiler may distribute operations across threads considering only .ow depen\u00addences. \nHowever, pointer indirection allows for ambiguous updates and foils ASSA analysis. Array Expansion [10] \nand Dynamic Sin\u00adgle Assignment (DSA) [31] are similar to ASSA. Instead of creat\u00ading new names, these \nadd a new dimension to arrays representing the new de.nition. Instead of inserting f-nodes, DSA emits \ninstruc\u00adtions to explicitly select the appropriate value at control join points. Region Array SSA [23] \nuses partial aggregation of array regions to reduce the runtime overhead of ASSA. These provide the same \nsingle-assignment semantics as ASSA, and suffer from the same applicability problems in light of unrestricted \npointers and casts. A representative DSA [31] is inapplicable to loops which contain loads or stores \nfrom pointers. Software Transactional Memory (STM) systems [8, 17, 18] pro\u00advide isolation and consequently \nprivatize data structures written during a transaction. To detect con.icts, these techniques keep a log \nof memory accesses for of.ine validation. STMLite integrates an automatic DOALL compiler featuring several \nenabling transfor\u00admations [17] and implemented in LLVM [15]. STMLite s central commit process can quickly \nbecome an execution bottleneck. The other transactional systems are not evaluated in an automatic sys\u00adtem; \nweak static analysis may cause a large volume of unnecessary validations, and it is unclear whether these \nsystems scale to that volume. None of these STMs provide speculative reduction sup\u00adport, and so a compiler \nmust rely on a static criterion. The CorD+Objects [27] compiler and STM reduce copy over\u00adheads by tracking \nspeculative state of objects. To address replace\u00adment transparency, the compiler transforms pointers \ninto double pointers and the runtime maintains a map between copies of an object. This transformation \nassumes that all accesses conform to the object s declared type, but may fail due to reinterpretation \ncasts. Static analysis cannot always determine whether an object is ever reinterpreted. The transformation \nalso assumes that all pointer val\u00adues are visible in the IR, but C s weak types allow disguised pointers, \nas discussed in [3]. Like STMs, CorD+Objects does not support speculative reductions. Since Privateer \nprovides replace\u00adment transparency using virtual page mapping, its compiler has no need to identify or \nmanipulate pointer values in the IR. Several works modify the default process memory model by manipulating \nvirtual memory maps. DoublePlay [33] employs the copy-on-write mechanism to isolate different epochs \nof a single process, providing a deterministic replay facility. Grace [1] imple\u00adments a safe multithreading \nprogramming model to reduce devel\u00adopment effort for parallel programs. Behavior oriented paralleliza\u00adtion \n[9] provides a speculative execution model that resembles an STM and features an optimized value-based \nmisspeculation detec\u00adtion system. These works are intended as programmer tools to aid the development \nof parallel applications, yet none automatically parallelize applications. 8. Conclusion Automatic parallelization \nis a promising strategy to deliver scalable application performance on parallel architectures. Privateer \nenables a compiler to extract more parallelism by selectively privatizing data structures. Privateer \ns heap separation enables greater appli\u00adcability than related techniques, and allows for ef.cient validation. \nPrivateer s fully automatic privatization and parallelization delivers a geomean whole-program speedup \nof 11.4\u00d7 over best sequential execution for 5 programs on a 24-core shared memory machine. Acknowledgments \nWe thank the entire Liberty Research Group for their support and feedback during this work. We also thank \nthe anonymous reviewers for their insightful comments. Additionally, we thank Andrew Ap\u00adpel, Gordon Stewart, \nLennart Beringer, Jude Nelson and Daya Bill for commenting on early drafts. This material is based on \nwork sup\u00adported by National Science Foundation Grant 0964328 and DARPA contract FA8750-10-2-0253. Prakash \nPrabhu thanks Google, Inc. for fellowship support. This work was carried out while Ayal Zaks was visiting \nPrinceton University, supported by the HiPEAC net\u00adwork of excellence, and on leave from IBM Haifa Research \nLab. References [1] E. D. Berger, T. Yang, T. Liu, and G. Novark. Grace: safe multithreaded programming \nfor C/C++. In Annual ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications, \n2009. [2] C. Bienia, S. Kumar, J. P. Singh, and K. Li. The PARSEC benchmark suite: Characterization and \narchitectural implications. In Proceedings of the 17th International Conference on Parallel Architectures \nand Compilation Techniques, 2008. [3] H.-J. Boehm. Simple garbage-collector-safety. In Proceedings of \nthe ACM SIGPLAN 1996 conference on Programming Language Design and Implementation, pages 89 98, New York, \nNY, 1996. ACM. [4] T. Chen, J. Lin, X. Dai, W.-C. Hsu, and P.-C. Yew. Data dependence pro.ling for speculative \noptimizations. In E. Duesterwald, editor, Compiler Construction, volume 2985 of Lecture Notes in Computer \nScience, pages 2733 2733. Springer Berlin / Heidelberg, 2004. [5] W. Y. Chen, S. A. Mahlke, and W. W. \nHwu. Tolerating .rst level memory access latency in high-performance systems. In Proceedings of the 1992 \nInternational Conference on Parallel Processing, pages 36 43, Boca Raton, Florida, 1992. CRC Press. [6] \nR. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. Ef.ciently computing static single \nassignment form and the control dependence graph. ACM Transactions on Programming Languages and Systems, \n13(4):451 490, October 1991. [7] F. H. Dang, H. Yu, and L. Rauchwerger. The R-LRPD test: Speculative \nparallelization of partially parallel loops. In Proceedings of the 16th International Parallel and Distributed \nProcessing Symposium, pages 20 29, 2002. [8] D. Dice, O. Shalev, and N. Shavit. Transactional locking \nII. In Distributed Computing, pages 194 208, 2006. [9] C. Ding, X. Shen, K. Kelsey, C. Tice, R. Huang, \nand C. Zhang. Software behavior oriented parallelization. In Proceedings of the 2007 ACM SIGPLAN Conference \non Programming Language Design and Implementation, pages 223 234, New York, NY, 2007. ACM. [10] P. Feautrier. \nArray expansion. In Proceedings of the 2nd International Conference on Supercomputing, pages 429 441. \nACM, 1988. [11] F. Gabbay and A. Mendelson. Can program pro.ling support value prediction? In Proceedings \nof the 30th annual ACM/IEEE International Symposium on Microarchitecture, pages 270 280, Washington, \nDC, 1997. IEEE Computer Society. [12] M. R. Guthaus, J. S. Ringenberg, D. Ernst, T. M. Austin, T. Mudge, \nand R. B. Brown. MiBench: A free, commercially representative embedded benchmark suite. In Proceedings \nof the Workload Characterization, 2001. WWC-4. 2001 IEEE International Workshop, pages 3 14, Washington, \nDC, 2001. IEEE Computer Society. [13] H. Kim, N. P. Johnson, J. W. Lee, S. A. Mahlke, and D. I. August. \nAutomatic speculative DOALL for clusters. Proceedings of the 10th IEEE/ACM International Symposium on \nCode Generation and Optimization, March 2012. [14] K. Knobe and V. Sarkar. Array SSA form and its use \nin parallelization. In Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages, pages 107 120, 1998. [15] C. Lattner and V. Adve. LLVM: A compilation framework for lifelong \nprogram analysis &#38; transformation. In Proceedings of the Annual International Symposium on Code Generation \nand Optimization, pages 75 86, 2004. [16] D. E. Maydan, S. P. Amarasinghe, and M. S. Lam. Array-data \n.ow analysis and its use in array privatization. In Proceedings of the 20th ACM SIGPLAN-SIGACT Symposium \non Principles of Programming Languages, pages 2 15, New York, NY, 1993. ACM. [17] M. Mehrara, J. Hao, \nP.-C. Hsu, and S. Mahlke. Parallelizing sequential applications on commodity hardware using a low-cost \nsoftware transactional memory. In Proceedings of the 2009 ACM SIGPLAN Conference on Programming Language \nDesign and Implementation, 2009. [18] Y. Ni, A. Welc, A.-R. Adl-Tabatabai, M. Bach, S. Berkowits, J. \nCownie, R. Geva, S. Kozhukow, R. Narayanaswamy, J. Olivier, S. Preis, B. Saha, A. Tal, and X. Tian. Design \nand implementation of transactional constructs for C/C++. In Annual ACM SIGPLAN Conference on Object-Oriented \nProgramming Systems Languages and Applications, pages 195 212, 2008. [19] C. G. Qui nones, C. Madriles, \nJ. S\u00b4anchez, P. Marcuello, A. Gonz\u00b4alez, and D. M. Tullsen. Mitosis compiler: an infrastructure for speculative \nthreading based on pre-computation slices. In Proceedings of the 2005 ACM SIGPLAN conference on Programming \nLanguage Design and Implementation, pages 269 279, New York, NY, 2005. ACM. [20] E. Raman, G. Ottoni, \nA. Raman, M. Bridges, and D. I. August. Parallel-stage decoupled software pipelining. In Proceedings \nof the Annual International Symposium on Code Generation and Optimization, 2008. [21] L. Rauchwerger \nand D. Padua. The Privatizing DOALL test: A run-time technique for DOALL loop identi.cation and array \nprivatization. In Proceedings of the 8th International Conference on Supercomputing, pages 33 43, New \nYork, NY, 1994. ACM. [22] L. Rauchwerger and D. Padua. The LRPD test: speculative run-time parallelization \nof loops with privatization and reduction parallelization. ACM SIGPLAN Notices, 30(6):218 232, 1995. \n[23] S. Rus, G. He, C. Alias, and L. Rauchwerger. Region Array SSA. In Proceedings of the 15th International \nConference on Parallel Architectures and Compilation Techniques, pages 43 52. ACM, 2006. [24] S. Rus, \nL. Rauchwerger, and J. Hoe.inger. Hybrid analysis: static &#38; dynamic memory reference analysis. International \nJournal of Parallel Programming, 31:251 283, August 2003. [25] Standard Performance Evaluation Corporation. \nhttp://spec.org. [26] The GNU Project. GNU Binutils. http://gnu.org/software/binutils. [27] C. Tian, \nM. Feng, and R. Gupta. Supporting Speculative Paralleliza\u00adtion in the Presence of Dynamic Data Structures. \nIn ACM SIGPLAN Conference on Programming Language Design and Implementation, 2010. [28] Trimaran. Trimaran \nBenchmarks Packages. http://trimaran.org. [29] P. Tu and D. A. Padua. Automatic array privatization. \nIn Proceedings of the 6th International Workshop on Languages and Compilers for Parallel Computing, pages \n500 521, 1994. [30] N. Vachharajani, R. Rangan, E. Raman, M. J. Bridges, G. Ottoni, and D. I. August. \nSpeculative decoupled software pipelining. In Proceedings of the 16th International Conference on Parallel \nArchitecture and Compilation Techniques, pages 49 59, Washington, DC, 2007. IEEE Computer Society. [31] \nP. Vanbroekhoven, G. Janssens, M. Bruynooghe, and F. Catthoor. A practical dynamic single assignment \ntransformation. ACM Transactions on Design Automation of Electronic Systems, 12, September 2007. [32] \nH. Vandierendonck, S. Rul, and K. De Bosschere. The Paralax infrastructure: Automatic parallelization \nwith a helping hand. In Proceedings of the 19th International Conference on Parallel Architecture and \nCompilation Techniques. [33] K. Veeraraghavan, D. Lee, B. Wester, J. Ouyang, P. M. Chen, J. Flinn, and \nS. Narayanasamy. Doubleplay: parallelizing sequential logging and replay. In Proceedings of the 16th \nInternational Conference on Architectural Support for Programming Languages and Operating Systems, pages \n15 26, New York, NY, 2011. ACM. [34] Q. Wu, A. Pyatakov, A. N. Spiridonov, E. Raman, D. W. Clark, and \nD. I. August. Exposing memory access regularities using object\u00adrelative memory pro.ling. In Proceedings \nof the International Symposium on Code Generation and Optimization. IEEE Computer Society, 2004. [35] \nH. Zhong, M. Mehrara, S. Lieberman, and S. Mahlke. Uncovering hidden loop level parallelism in sequential \napplications. In Pro\u00adceedings of the 14th International Symposium on High-Performance Computer Architecture, \n2008.    \n\t\t\t", "proc_id": "2254064", "abstract": "<p>Automatic parallelization is a promising strategy to improve application performance in the multicore era. However, common programming practices such as the reuse of data structures introduce artificial constraints that obstruct automatic parallelization. Privatization relieves these constraints by replicating data structures, thus enabling scalable parallelization. Prior privatization schemes are limited to arrays and scalar variables because they are sensitive to the layout of dynamic data structures. This work presents Privateer, the first fully automatic privatization system to handle dynamic and recursive data structures, even in languages with unrestricted pointers. To reduce sensitivity to memory layout, Privateer speculatively separates memory objects. Privateer's lightweight runtime system validates speculative separation and speculative privatization to ensure correct parallel execution. Privateer enables automatic parallelization of general-purpose C/C++ applications, yielding a geomean whole-program speedup of 11.4x over best sequential execution on 24 cores, while non-speculative parallelization yields only 0.93x.</p>", "authors": [{"name": "Nick P. Johnson", "author_profile_id": "81470644754", "affiliation": "Princeton University, Princeton, NJ, USA", "person_id": "P3471254", "email_address": "npjohnso@princeton.edu", "orcid_id": ""}, {"name": "Hanjun Kim", "author_profile_id": "81479653600", "affiliation": "Princeton University, Princeton, NJ, USA", "person_id": "P3471255", "email_address": "hanjunk@princeton.edu", "orcid_id": ""}, {"name": "Prakash Prabhu", "author_profile_id": "81464645003", "affiliation": "Princeton University, Princeton, NJ, USA", "person_id": "P3471256", "email_address": "pprabhu@princeton.edu", "orcid_id": ""}, {"name": "Ayal Zaks", "author_profile_id": "81100166351", "affiliation": "Intel Corporation, Haifa, Israel", "person_id": "P3471257", "email_address": "ayal.zaks@intel.com", "orcid_id": ""}, {"name": "David I. August", "author_profile_id": "81100388492", "affiliation": "Princeton University, Princeton, NJ, USA", "person_id": "P3471258", "email_address": "august@princeton.edu", "orcid_id": ""}], "doi_number": "10.1145/2254064.2254107", "year": "2012", "article_id": "2254107", "conference": "PLDI", "title": "Speculative separation for privatization and reductions", "url": "http://dl.acm.org/citation.cfm?id=2254107"}