{"article_publication_date": "06-11-2012", "fulltext": "\n Sound and Precise Analysis of Parallel Programs through Schedule Specialization Jingyue Wu Yang Tang \nGang Hu Heming Cui Junfeng Yang Columbia University {jingyue,ty,ganghu,heming,junfeng}@cs.columbia.edu \nAbstract Parallel programs are known to be dif.cult to analyze. A key reason is that they typically have \nan enormous number of execution inter\u00adleavings, or schedules. Static analysis over all schedules requires \nover-approximations, resulting in poor precision; dynamic analysis rarely covers more than a tiny fraction \nof all schedules. We pro\u00adpose an approach called schedule specialization to analyze a par\u00adallel program \nover only a small set of schedules for precision, and then enforce these schedules at runtime for soundness \nof the static analysis results. We build a schedule specialization framework for C/C++ multithreaded \nprograms that use Pthreads. Our framework avoids the need to modify every analysis to be schedule-aware \nby specializing a program into a simpler program based on a schedule, so that the resultant program can \nbe analyzed with stock analy\u00adses for improved precision. Moreover, our framework provides a precise schedule-aware \ndef-use analysis on memory locations, en\u00adabling us to build three highly precise analyses: an alias analyzer, \na data-race detector, and a path slicer. Evaluation on 17 programs, in\u00adcluding 2 real-world programs \nand 15 popular benchmarks, shows that analyses using our framework reduced may-aliases by 61.9%, false \nrace reports by 69%, and path slices by 48.7%; and detected 7 unknown bugs in well-checked programs. \nCategories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; D.4.5 \n[Operating Systems]: Threads General Terms Algorithms, Design, Reliability, Veri.cation Keywords Specialization, \nparallel programs, multithreading, control-.ow analysis, data-.ow analysis, constraint solving 1. Introduction \nThe computational power provided by multicore hardware and demanded by the massive number of cloud services \nhas made parallel programs increasingly pervasive and critical. Yet, these programs are known to be dif.cult \nto get right; they are often plagued with concurrency errors [25], some of which have caused critical \nfailures [23, 30, 37]. A key reason for these bugs is that parallel programs are dif\u00ad.cult to analyze \nusing automated tools. These programs typically have an enormous asymptotically exponential in the total \nexecu\u00adtion lengths number of execution interleavings, or schedules, pre\u00adsumably to react to various timing \nfactors for performance. Static analysis over all these schedules requires over-approximations, re\u00adsulting \nin poor precision and many false positives. Dynamic analy- Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 12, June 11 16, 2012, Beijing, China. \nCopyright . 2012 ACM 978-1-4503-1205-9/12/06. . . $10.00 c sis can precisely analyze the schedules that \noccur, but it rarely cov\u00aders more than a tiny fraction of all possible schedules, and the next execution \nmay well run into an unchecked schedule with errors. Our .rst contribution is a new approach we call \nschedule spe\u00adcialization that combines the soundness of static analysis and the precision of dynamic \nanalysis. Our insight is that not all of the ex\u00adponentially many schedules are necessary for good performance. \nA small set often suf.ces, as illustrated by recent work on ef.cient deterministic multithreading [16, \n17, 24, 28]. Based on this insight, our approach statically analyzes a parallel program over a small \nset of schedules, then dynamically enforces these schedules. By focus\u00ading on only a small set of schedules, \nwe vastly improve the preci\u00adsion of static analysis; by enforcing the analyzed schedules dynam\u00adically, \nwe guarantee soundness of the analysis results. Our approach is loosely analogous to previous approaches \nthat combine static analysis and dynamic checking for memory safety (e.g., [26]), but ours aims at parallel \nprograms and schedules. Schedule specialization may be implemented in many ways for many parallel programming \nmodels such as message passing and multithreading; this paper presents one such implementation for C/C++ \nprograms using Pthreads [34]. We represent a schedule as a total order of synchronizations such as lock \noperations,1 which can be ef.ciently enforced [16, 28, 32]. To ensure that schedules are feasible, we \ncollect them from real executions. To enforce sched\u00adules, we leverage our PEREGRINE [17] deterministic \nmultithread\u00ad ing system which can enforce a small set of schedules on a wide range of inputs. For instance, \nit can use about a hundred schedules to cover over 90% of requests in a real HTTP trace for Apache [7]. \nBy reusing schedules, we not only make program behaviors re\u00adpeatable across inputs, but also amortize \nthe static analysis cost in schedule specialization.2 A key challenge we face in implementing schedule \nspecializa\u00adtion is how to statically analyze a program w.r.t. a schedule. A na\u00a8ive method is to make \nevery analysis involved aware of the schedule, but this method would be quite labor-intensive and error-prone. \nIt may also be fragile: if a crucial analysis, such as alias analysis, is unaware of the schedule, it \nmay easily pollute other analyses. Solving this challenge leads to our second contribution, a pro\u00adgram \nanalysis framework with a set of sound and precise algorithms to specialize a program according to a \nschedule. The resultant pro\u00adgram has simpler control and data .ow than the original program, and can \nbe analyzed with stock analyses, such as constant fold\u00ading and dead code elimination, for improved precision. \nIn addition, our framework provides a precise def-use analysis that computes schedule-aware, must-def-use \nresults on memory locations, which can be the foundation of many other powerful analyses (\u00a77). To specialize \na program toward a schedule, our framework works in two steps. It .rst specializes the control .ow by \nrewrit\u00ading the program to map each synchronization in the schedule to a 1 Users can customize the schedule \ngranularity by selecting which synchro\u00ad nizations go into the schedules (\u00a73). 2 A set of previously \ncollected schedules may not cover all inputs. If sound\u00adness is required on inputs not covered, we may \nuse dynamic analysis (\u00a73).   unique statement. It then specializes the data .ow according to the schedule \nthrough a series of analyses and rewrites. For instance, if the program loops N (a program variable) \ntimes to spawn worker threads and the schedule dictates three worker threads, our frame\u00adwork specializes \nN, as well as the other variables where the value of N .ows to, to be three. The simpli.ed control and \ndata .ow can then greatly improve analysis precision. Our framework has broad applications. For instance, \nwe can build precise static veri.ers (e.g., to verify error-freedom) because our veri.ers need only verify \na program w.r.t. the schedules en\u00adforced. Stock compiler optimizations automatically become more effective \non a specialized program because it has simpler control and data .ow. Our framework can also bene.t read-only \nanalyses which do not require enforcing schedules at runtime. For instance, we can build precise error \ndetectors that check a program against a set of common schedules to detect errors more likely to occur, \nwhile drastically reducing false positive rates. We can perform pre\u00adcise, automated post-mortem analysis \nof a failure by analyzing only the schedule recorded in a system log to trim down possible causes. To \ndemonstrate the usefulness of schedule specialization, we have built three powerful applications with \nhigh precision, which form our third contribution of this paper. We create a schedule\u00adaware alias analyzer \nthat can distinguish array elements, leveraging the def-use analysis provided by our framework. Moreover, \nwe create a precise static race detector to detect only the data races that may occur when a given schedule \nis enforced, thus yielding few false positives. Lastly, we create a schedule-aware path slicer [21] to \nremove irrelevant statements from an execution trace. This slicer can be applied, for instance, to pinpoint \nthe root cause of a failure or generate .lters of bad inputs [15]. We have implemented our framework \nwithin the LLVM com\u00adpiler [1] and evaluated it on 17 multithreaded programs, includ\u00ad ing 2 real programs \nsuch as a popular parallel compression util\u00adity PBZip2 [3] and 15 widely used parallel benchmarks from \nSPLASH2 [4] and PARSEC [2]. Our results show that schedule specialization greatly improves precision: \non average, it reduced may aliases by 61.9%, false race reports by 69%, and path slices by 48.7%. The \nimproved precision also helped detect 7 unknown bugs in well-checked [19, 25, 29, 38, 39] programs. This \npaper is organized as follows. We .rst present relevant background on PEREGRINE (\u00a72) and an overview \nour framework (\u00a73), then present the key algorithms using an example (\u00a74) and detailed descriptions (\u00a75). \nWe then discuss implementation issues (\u00a76), describe the analyses (\u00a77) we build on top of our framework, \nand show the evaluation results (\u00a78). We .nally discuss related work (\u00a79) and conclude (\u00a710). 2. Background: \nThe PEREGRINE System Our framework leverages PEREGRINE [17] to collect and enforce schedules. This section \nbrie.y describes the relevant mechanisms in PEREGRINE; for details of PEREGRINE, please refer to [16, \n17]. Collecting schedules. To ensure that schedules are feasible, we collect them from real executions. \nTo do so, we .rst replace all synchronizations in a program with calls to our synchronization wrappers. \nAt runtime, when a synchronization wrapper is invoked, it appends an entry to a central log .le, then \ncalls the underlying synchronization. The synchronization wrappers are properly syn\u00adchronized so that \nonly one wrapper may run at any time, ensuring that all synchronizations are totally ordered. After the \nexecution .nishes, the log contains a schedule. To collect a set of schedules, we repeatedly run a program \nagainst representative workloads, and record the schedule in each execution. Although one could use clever \nheuristics to select schedules, such as iterating through many schedules to pick the fastest one, we \ncurrently do not do so. Enforcing schedules. Given a schedule, we .rst compute the pre\u00adconditions required \nfor reusing the schedule on later inputs (ex\u00adplained in the next few paragraphs). Then, if an input meeting \nthese preconditions arrives, we enforce the schedule. Speci.cally, we make all threads call synchronization \nwrappers following the total order speci.ed in the schedule, and these wrappers are again properly synchronized \nso that no two are concurrent. Prior re\u00adsults [16, 17, 24, 28] including ours [16, 17] show that enforcing \na synchronization order is ef.cient because most code is not syn\u00adchronization and can still run in parallel. \nFor instance, this overhead in PEREGRINE ranges from 68.7% faster to 46.6% slower on a di\u00adverse set of \n18 programs, including the Apache [7]. To compute preconditions for a schedule, we .rst record a de\u00adtailed \nexecution trace when recording a schedule. We then perform a modi.ed version [17] of path slicing [21] \non the trace to remove statement instances that do not affect the feasibility of the schedule, i.e., \nthe reachability of all synchronizations in the schedule. Our version of path slicing correctly tracks \ndependencies (e.g., shared data accesses) across threads. Once we compute a path slice for each thread, \nwe symbolically execute each slice, tracking the con\u00adstraints on input data, such as command line arguments \nand data read from a .le or socket. We then use the conjunction of the con\u00adstraints from each thread \nas the preconditions of the schedule. These preconditions have three properties. First, they do not guarantee \nprogram termination because we want to sidestep the dif\u00ad.cult problem of statically establishing termination. \nThis property is inherited from path slicing [21]. Second, since computing weak\u00ad est preconditions is \nundecidable, the preconditions PEREGRINE computes stay on the sound side: if an input satis.es these \nprecon\u00additions, it can be processed by the corresponding schedule (modulo termination). However, these \npreconditions may preclude inputs that can indeed be processed by the schedule. Third, these precon\u00additions \navoid data races, which may cause an execution to diverge, preventing PEREGRINE from enforcing a given \nschedule. When computing preconditions, PEREGRINE detects potential races that did not occur in a recorded \ntrace, but may occur if we reuse the schedule on different inputs. It computes preconditions suf.cient \nto avoid these races. PEREGRINE makes the races that occurred in the recorded trace deterministic using \ndynamic instrumentation. Our PEREGRINE results show that a small number of schedules can cover a wide \nrange of workloads for half of the 18 evaluated programs. We observe that the synchronizations in these \nprograms depend mostly on meta properties such as the number of pro\u00adcessor cores, and tend to be loosely \ncoupled with the inputs. For these programs, the coverage of a schedule can be extremely high. For instance, \nconsider PBZip2 which divides an input .le evenly among multiple threads to compress. Two schedules are \nsuf.cient to compress any .le for PBZip2 as long as the number of worker threads remains the same. (PBZip2 \nneeds one schedule if the .le size can be evenly divided and another otherwise.) Another data point: \nabout a hundred schedules are suf.cient to cover over 90% of requests in a real HTTP trace for Apache \n[7]. This stability [16] not only makes program behaviors repeatable across inputs, but also re\u00adduces \nthe runtime overhead of our framework (\u00a73). 3. Framework Overview This section presents an overview of \nour schedule specialization framework by presenting its key de.nitions and properties. We assign each \nstatement in a program P a unique static label lj . An execution trace, or a trace, of P , denoted by \nT , is a poten\u00adtially in.nite sequence of dynamic statement instances i0,i1,... where each ij is a tuple \n.t, l., indicating that ij is an instance of statement l executed by thread t; and if ij was completed \nbefore the start of in, then j<n (concurrently executed statements can be ordered either way). Given \ni = .t, l., we use i.label to access l.  A schedule, denoted by S, is a sequence of synchronizations \ns0,s1,...,sN where each sj is a dynamic statement instance .t, l. and l is a synchronization statement. \nWhile we anticipate our approach will work well with many parallel programming models, our current framework \ntargets C/C++ programs that use Pthreads. It includes three types of synchronizations in the sched\u00adules: \n(1) Pthread synchronizations such as pthread create and pthread mutex lock operations; (2) entries and \nexits of thread functions (functions passed to pthread create) and main be\u00adcause these events are natural \nsynchronization points; and (3) addi\u00adtional function calls to resolve ambiguity when a synchronization \nmay be invoked in different calling contexts (explained in \u00a75.1). We call the .rst two classes true synchronizations \nand the last class derived synchronizations. Unless otherwise speci.ed, we use syn\u00adchronizations to refer \nto both true and derived synchronizations. To ensure that schedules are feasible, we collect them from \nter\u00adminating execution traces. A schedule includes only totally ordered synchronizations because our \nruntime ensures that synchroniza\u00adtions are never concurrent (\u00a72). It need not contain all synchroniza\u00ad \ntions from a trace, enabling .exible tradeoffs between precision and analysis time (see the end of this \nsection). Different traces may map to the same schedule because traces are more .ne-grained than schedules. \nWe use run(P ) to denote the set of all traces of program P , including non-terminating ones. These traces \ncover all possible inputs to P . We use runS (P ) to denote the subset of traces in run(P ) with schedule \nS enforced. Traces in runS(P ) cover only inputs meeting the preconditions of S. Even though S is collected \nfrom a terminating trace, another trace with S enforced may still be non-terminating because the preconditions \nPEREGRINE computes do not guarantee termination (\u00a72). Thus, runS (P ) may include non-terminating traces \nwith a pre.x of S enforced. Without schedule specialization, a static analysis has to con\u00adsider conceptually \nall traces in run(P ) for soundness. With sched\u00adule specialization, a static analysis need consider only \ntraces in runS (P ) for each enforced schedule S, potentially computing much more precise results. One \nmethod to use this potential is to modify every analysis to be aware of the schedule and consider a set \nof executions closer to runS (P ), but this method has the draw\u00adbacks discussed in \u00a71. To avoid modifying \nevery analysis to be aware of schedules, our framework rewrites P into a specialized program PS for each \nschedule S so that run(PS) is close to runS(P ). PS can then be analyzed with many stock analyses for \nimproved precision. To analyze P over a set of schedules, we can generate a specialized program for each \nschedule, then merge the analysis results. In ad\u00addition, our framework provides a constraint-based def-use \nanalysis on PS that computes precise must-def-use chains on memory lo\u00adcations allowed only by the schedule \nS. By querying this def-use analysis, stock or slightly modi.ed advanced analyses such as alias analysis \ncan then compute schedule-aware results. Precision. Ideally for full precision, our framework should \nmake run(PS )= runS (P ), so that static analysis of PS considers only traces in runS (P ). In our current \nframework, run(PS ) may still include traces not in runS(P ) because, without enforcing S with PEREGRINE, \nan execution of PS may use a different schedule. Nonetheless, since run(PS ) is much smaller than run(P \n), stock analyses on PS should still yield more precise results than on P . Our def-use analysis excludes \ndef-use chains forbidden by the total order in S. That is, it considers traces in runS(PS ), which our \nspecialization algorithms (\u00a75) guarantee to be runS (P ). The def\u00aduse results provided by our framework \nare thus much more precise than what a stock def-use analysis can compute on PS . Soundness. Our framework \nguarantees that static analysis results on PS hold for all traces in runS (P ), i.e., whenever schedule \nS is enforced on program P , because (1) the results from a static analysis on PS should hold for all \ntraces in run(PS ); and (2) our specialization algorithms guarantee run(PS ) . runS (P ). In addition, \nour framework guarantees that the def-use results it provides hold for runS (PS ), which is runS (P ). \nAssumptions and non-assumptions. In our current framework, the soundness of static analysis results is \nconditioned on that one of the analyzed schedules is enforced. A .nite set of schedules col\u00adlected by \nPEREGRINE, however, may not cover all inputs. If an input cannot be processed by any of the schedules \n(or it can but our framework cannot determine this fact), the static analysis results may no longer hold \nfor the execution on this input. If users want to retain soundness on such inputs, they may use dynamic \nanalysis. For instance, if the analysis goal is to verify race freedom, they may use dynamic data race \ndetection on such inputs. If dynamic analy\u00adsis is used, the overall runtime overhead of our framework \nmay depend on the actual workload, or how frequently it can enforce an analyzed schedule. Fortunately, \nour PEREGRINE results show that, for many programs, a small set of schedules can cover a wide range of \nthe workloads (\u00a72). For these programs and workloads, our framework rarely needs to use dynamic analysis. \nMoreover, even if we cannot use a small set of schedules to cover a wide range of workloads, schedule \nspecialization is still useful for many applications. These applications include all read\u00adonly applications \nsuch as error detection and post-mortem analysis which do not require soundness on the inputs not covered \nby ana\u00adlyzed schedules. They also include optimizations because we can simply run the original program \non the inputs not covered. At the algorithmic level, we do not assume data-race-free pro\u00adgrams because \nwe intend to keep our framework general and ap\u00adplicable to not just optimizations, but other applications, \nsuch as veri.cation and error detection. In particular, data races cannot pre\u00advent us from enforcing \na schedule (\u00a72). Nonetheless, if optimiza\u00ad tion is the only goal, we can easily modify our algorithms \nto exploit this assumption for better results. At the implementation level, our current framework leverages \nthe LLVM compiler, which may in\u00addeed assume race freedom. This assumption may be removed by re-implementing \nthe LLVM components we leverage. Our framework does not require that a schedule collected from a trace \nincludes all synchronizations in the trace. Instead, users can customize the schedule granularity, or \nwhich synchronizations go into the schedules, by blacklisting certain synchronization state\u00adments. This \ndesign enables users to make .exible three-way trade\u00adoffs between precision, analysis time, and schedule \nreuse-rate. In general, .ne-grained schedules have lower reuse-rates and lead to larger specialized programs \nand longer analysis time, but make the analysis results more precise. One exception is that users should \ntypically blacklist synchronizations hidden behind an abstraction boundary, such as a memory allocator \ninterface, because these syn\u00adchronizations rarely improve precision but worsen analysis time and reuse-rate. \nFor instance, we blacklisted the lock operations in the custom memory allocator in cholesky (\u00a76). An \ninteresting re\u00ad search question is how to optimally make this three-way tradeoff, which we leave for \nfuture work. 4. An Example and Algorithm Overview This section illustrates how our framework operates \nusing an exam\u00adple based on two programs in our evaluation benchmarks: aget,a parallel wget-like utility; \nand fft, a parallel scienti.c benchmark. Figure 1 shows the example program. As can be seen from the \ncode, each thread accesses a disjoint partition of results. Suppose we want to build a precise alias \nanalysis to compute this fact, so that we can for example avoid wrongly .agging accesses to results \n 1 : int results[MAX]; 2 : struct {int .rst; int last;} ranges[MAX]; 3 : int global id = 0; 4 : int \nmain(int argc, char *argv[ ]) {  5 : int i; 6 : int p = atoi(argv[1]), n = atoi(argv[2]); 7 : for \n(i = 0; i < p; ++i) {  8 : ranges[i]..rst = n * i / p; 9 : ranges[i].last = n *(i + 1) / p;  10: } \n11: for (i = 0; i < p; ++i) 12: pthread create(&#38;child[i], 0, worker, 0); 13: for (i = 0; i < p; ++i) \n14: pthread join(child[i], 0); 15: return 0; 16: } 17: void *worker(void *arg) { 18: pthread mutex lock(&#38;global \nid lock); 19: int my id = global id++; 20: pthread mutex unlock(&#38;global id lock); 21: for (int i \n= ranges[my id]..rst; i < ranges[my id].last; ++i) 22: results[i]= compute(i); 23: return 0; 24: } Figure \n1: An example showing how schedule specialization works. Variable n and p are two inputs that specify \nthe size of the global array results and the number of worker threads, respectively. The code .rst partitions \nresults evenly by the number of worker threads p and saves the range of each thread to ranges (lines \n7 10); it then starts p worker threads to process the partitions (lines 11 12). Each worker enters a \ncritical section to set its instance of my id and increment global id (lines 18 20), and then computes \nand saves the results to its partition (lines 21 22). Figure 2: A possible schedule of the example in \nFigure 1 when p is 2. as races for a static race detector. Unfortunately, doing so requires solving a \nvariety of dif.cult problems. For instance, since p, the number of threads, is determined at runtime, \nstatic analysis often has to approximate these dynamic threads as one or two abstract thread instances. \nIt may thus collapse distinct accesses to results from different threads as one access, computing imprecise \nalias results. Even if an analysis can (1) distinguish the accesses to results by different threads and \n(2) infer bounds on integers such as array indices using range analysis [33], it may still fail to compute \nthat these accesses are disjoint. The reason is that the array partition each worker accesses depends \non its instance of my id, which further depends on the schedule (or the order in which worker threads \nenter the critical section at lines 18 20). In short, if a static analysis has to consider all possible \nschedules of this program, it would be very dif.cult to compute precise results. Fortunately, these dif.cult \nproblems are greatly simpli.ed by schedule specialization. Suppose whenever p is 2, we always en\u00adforce \nthe schedule shown in Figure 2. Since the number of threads is .xed, distinguishing them becomes easy. \nIn addition, since the 1 : ... // same global declarations as in Figure 1 2 : int main(int argc, char \n*argv[ ]) {  3 : int i; 4 : int p = atoi(argv[1]), n = atoi(argv[2]); 5 : for (i = 0; i < p; ++i) \n{  6 : ranges[i]..rst = n * i / p; 7 : ranges[i].last = n *(i + 1) / p; 8 : } 9 :i = 0; assume(i \n< p);  10: pthread create(&#38;child[i], 0, worker CLONE1, 0); 11: ++i; assume(i < p); 12: pthread create(&#38;child[i], \n0, worker CLONE2, 0); 13: ++i; assume(i >= p); 14:i = 0; assume(i < p); 15: pthread join(child[i], 0); \n16: ++i; assume(i < p); 17: pthread join(child[i], 0); 18: ++i; assume(i >= p); 19: return 0; 20: } 21: \nvoid *worker CLONE1(void *arg) { 22: pthread mutex lock(&#38;global id lock); 23: int my id = global \nid++; 24: pthread mutex unlock(&#38;global id lock); 25: for (int i = ranges[my id]..rst; i < ranges[my \nid].last; ++i) 26: results[i]= compute(i); 27: return 0; 28: } 29: void *worker CLONE2(void *arg) { 30: \npthread mutex lock(&#38;global id lock); 31: int my id = global id++; 32: pthread mutex unlock(&#38;global \nid lock); 33: for (int i = ranges[my id]..rst; i < ranges[my id].last; ++i) 34: results[i]= compute(i); \n35: return 0; 36: } Figure 3: The resultant program after control-.ow specialization. The loops at lines \n11 12 and lines 13 14 in Figure 1 are unrolled because they contain synchronizations in the schedule, \nwhile the other loops are not. Thread function worker is cloned twice, making it easy for an analysis \nto distinguish the two worker threads. The algorithm adds special assume calls to pass constraints on \nvariables to the data-.ow specialization step. order in which threads enter the critical section at lines \n18 20 is .xed, each worker thread always gets a .xed my id and thus ac\u00adcesses a .xed partition of results. \nTo practically take advantage of these observations, our frame\u00adwork specializes a program toward a schedule. \nIt does so in two steps. In the .rst step, it specializes the control .ow of the pro\u00adgram by straightening \nthe program so that each synchronization in the schedule maps to a unique statement, and the synchroniza\u00adtions \nwithin each thread are control-equivalent. Speci.cally, it .rst constructs a super control .ow graph \n(CFG) of the program, which includes function call and return edges. It then iterates through each pair \nof consecutive synchronizations (s1,s2) in a thread, and clones the statements between s1 and s2 in the \nCFG. Figure 3 shows the result after specializing control .ow. Loops containing syn\u00adchronizations such \nas pthread create are unrolled, and thread functions are cloned, making it easy for an analysis to distinguish \nthreads. Note that such cloning and unrolling are selectively done only to functions that may do synchronizations, \nso they would not explode the size of a specialized program. In the second step, our framework specializes \nthe data .ow through a series of analyses. For instance, it constructs an advanced def-use graph for \nvariables and memory locations according to the schedule, and replaces variables with constant values \nwhen it can.  ... // same global declarations as in Figure 1 int main(int argc, char *argv[ ]) { int \np = atoi(argv[1]), n = atoi(argv[2]); ranges[0]..rst = 0; ranges[0].last = n / 2; ranges[1]..rst = n \n/ 2; ranges[1].last = n; pthread create(&#38;child[0], 0, worker CLONE1, 0); pthread create(&#38;child[1], \n0, worker CLONE2, 0); pthread join(child[0], 0); pthread join(child[1], 0); return 0; }void *worker CLONE1(void \n*arg) { pthread mutex lock(&#38;global id lock); global id = 1; pthread mutex unlock(&#38;global id lock); \nfor (int i = 0; i < ranges[0].last; ++i) results[i]= compute(i); return 0; } void *worker CLONE2(void \n*arg) { pthread mutex lock(&#38;global id lock); global id = 2; pthread mutex unlock(&#38;global id lock); \nfor (int i = ranges[1]..rst; i < ranges[1].last; ++i) results[i]= compute(i); return 0; } Figure 4: The \nresultant program after data-.ow specialization. Variable p and my id are replaced with constants, the \nloop at lines 5 8 in Figure 3 is unrolled, and some dead code is removed. It does these analyses by collecting \nconstraints from the program and querying a constraint solver. For instance, from lines 9, 11, and 13 \nin Figure 3, it infers that p must be 2, so it replaces p with 2. Similarly, it computes a precise def-use \nchain for the accesses to global id, and infers that each my id instance has a constant value. Once variables \nare replaced with constants, we can apply techniques such as constant folding, dead code elimination, \nand loop unrolling to further specialize the program. Moreover, these stock techniques and our analyses \ncan run iteratively, until the program cannot be specialized any more. Figure 4 shows the result of specializing \ndata .ow. Bene.ts of schedule specialization. The specialized program in Figure 4 has much simpler control \nand data .ow than the original program in Figure 1, enabling stock analyses to compute more pre\u00ad cise \nresults. For instance, range analysis can now compute thread\u00adsensitive results because the worker function \nis cloned; it can also compute precise bounds for the loop index i in the worker clones because the indice \nto ranges are now constant, not my id which can have a large range if no schedule is enforced. Our framework \nguarantees that static analysis results on Fig\u00adure 4 hold for the set of all traces with the schedule \nin Figure 2 enforced. This set is fairly large because this schedule can be en\u00adforced as long as the \nnumber of threads p is 2, regardless of the data size n or the contents of other input data. A small \nset of such schedules, including one for each number of threads, can practi\u00adcally cover all inputs because \n(1) most parallel programs we evalu\u00adate achieve peak performance when the number of worker threads is \nidentical or close to the number of processor cores and (2) the number of cores a machine has is typically \nsmall (e.g., smaller than 100). This example illustrates the best case of our approach: by an\u00adalyzing \nonly a small set of schedules, we enjoy both precision and soundness for practically all inputs. (a) \nIntra-procedural ambiguity (b) Inter-procedural ambiguity Figure 5: Two types of ambiguity. The black \nnodes are synchronizations. The hatched nodes are the statements between s1 and s2 computed by the reachability \nanalysis. The gray call node is a derived synchronization marked to resolve inter-procedural ambiguity. \n5. Algorithms This section describes our algorithms to specialize the control .ow (\u00a75.1) and data .ow \n(\u00a75.2) of a program toward a schedule. 5.1 Specializing Control Flow To ease the description of our \nalgorithms, we de.ne a segment, de\u00adnoted by G, as the maximal portion of the CFG between two syn\u00adchronization \nstatements l1 and l2 that is free of other synchroniza\u00adtion statements. A segment between l1 and l2 includes \nany state\u00adment s.t. (1) l1 can reach this statement in the CFG without reach\u00ading any other synchronization \nstatements and (2) this statement can reach l2 without reaching any other synchronization statements. \nWe denote the set of statements in G by G.L, and the set of control\u00ad.ow edges in G by G.E. To specialize \nthe control .ow, we clone the segment between every two consecutive synchronizations within a thread, \nand then join all cloned segments together to form the specialized program. One dif.culty to .nd all \nstatements between two consecutive syn\u00adchronizations is ambiguity: there may be multiple ways from one \nsynchronization to another. For instance, Figure 5a shows an am\u00ad biguous case caused by multiple paths \nin the CFG. The loop body shown has two paths, only one of which contains synchronization s2. This loop \nhas to be transformed so that s1 and s2 become control-equivalent. Our algorithm to specialize control \n.ow auto\u00admatically handles this case, described later in this subsection. Figure 5b shows another ambiguous \ncase caused by multiple paths in the call graph. From s1 to s2, we can go through either call. To resolve \ncall-stack ambiguity, we instrument calls to func\u00adtions that may transitively do synchronizations, and \ninclude these derived synchronizations in the schedule as well. The result is that we can compute exactly \none call stack for each synchronization in a schedule. Our evaluation shows that the number of derived \nsyn\u00adchronizations is small, and they incur negligible overhead (\u00a78.2). Algorithm 1 shows how we specialize \nthe control .ow of a program. We .rst explain the helper function SpecializeCon\u00adtrolFlowThread, which \ntakes the original program P , a schedule S, and a thread t, and outputs a subprogram Pt . specialized \nac\u00adcording to t s synchronizations in S. For every two consecutive synchronizations of t, this function \ndoes a forward and a backward depth-.rst search to .nd the segment between the two synchroniza\u00adtions. \nIt then clones the segment, copying and renaming functions as necessary, and appends the segment clone \nto Pt . . Function DFS traverses the CFG from statement l1 to l2 and saves the visited portion of the \nCFG to output parameter Gout. It backtracks whenever it meets a synchronization. During the traver\u00adsal, \nit maintains the current call stack in cs so that it can compute where to return (lret). When it reaches \nl2, it saves the call stack to output parameter csout, which SpecializeControlFlowThread will pass to \nBackwardDFS (in the same iteration) and DFS (in the next iteration). If there are multiple paths from \nl1 to l2, DFS may reach Algorithm 1: Control-Flow Specialization  Input : the original program P and \na schedule S Output: the specialized program SpecializeControlFlow(P , S) foreach thread t do Pt . . \nSpecializeControlFlowThread(P , S, t) foreach Pt . do foreach statement l in Pt . do if l is a pthread \ncreate then ct . child thread created by l set thread function of l to P . ct return .tPt . SpecializeControlFlowThread(P \n, S, t) Pt . .\u00d8 // the specialized subprogram for thread t cs .\u00d8 // the call stack of the current synchronization \nSt . the sub-schedule of S for thread t for (si,si+1) in St do G . ({si.label}, \u00d8) // segment between \nsi &#38; si+1 // G and the second cs below are output parameters. DFS(cs, si.label, si+1.label, cs, G) \nBackwardDFS(cs, si+1.label, si.label, G) Pt . . Pt . . Clone(G) return Pt . DFS(cs, l1, l2, csout, Gout) \n// l1 and l2 may be the same if l1 is a derived synchronization then l . entry of l1 s callee function \nTryDFS(cs + l1, l1, l, l2, csout, Gout) else if l1 is a return statement then lret . the top of cs l \n. lret s intra-procedural successor TryDFS(cs -lret, l1, l, l2, csout, Gout) else foreach intra-procedural \nsuccessor l of l1 do TryDFS(cs, l1, l, l2, csout, Gout) TryDFS(cs, l1, l, l2, csout, Gout) Gout.E . \nGout.E .{(l1,l)}if l = l2 then csout . cs if l/. Gout.L then Gout.L . Gout.L .{l} if l is not a synchronization \nthen DFS(cs, l, l2, csout, Gout) l2 multiple times in one traversal, but each time the call stack must \nalways be identical because call-stack ambiguity is resolved. The results of DFS may include statements \nand CFG edges that cannot reach si+1.label. BackwardDFS prunes these state\u00adments and edges by traversing \nG, not the full CFG, backward from si+1.label to si.label. It is similar to DFS except it is backward \nand need not output a call stack, so we omit it from Algorithm 1. We now explain the main function of \nthis algorithm, Spe\u00adcializeControlFlow. It .rst invokes SpecializeControlFlowThread to compute a specialized \nprogram based on the synchroniza\u00adtions of each thread. It then replaces the thread function in each pthread \ncreate callsite with the cloned thread function. It .nally merges all the specialized programs together. \nDiscussion. We note three subtleties of Algorithm 1. First, it auto\u00ad matically handles the ambiguity \nin Figure 5a. Suppose the schedule is s1s2s3. We do not know the loop bound because one path in the loop \nbody calls s2 and the other does not. However, our algorithm can still specialize the CFG into Figure \n6. This feature is critical Figure 5a with schedule s1s2s3. the need to traverse CFG edges. in some \ncases. For example, if s2 is pthread create, this feature clones the thread functions, providing thread-sensitivity. \nSecond, DFS traverses into the body of a function only when the call to this function is a derived synchronization, \ni.e., this function may transitively do synchronization. Thus, the Gout it computes includes only CFG \nportions from such functions, and is not a full segment. The effect is that only these CFG portions are \ncloned, possibly multiple times, and each clone is unique to a segment in the resultant program; other \nfunctions are copied verbatim to the resultant program. By doing so, we capture the information from \nthe schedule without exploding the size of a specialized program. Lastly, to compute a segment, we cannot \nsimply compute only the statements in the segment and copy all edges from the original CFG. To illustrate, \nconsider Figure 7. Suppose the schedule is s1s2s3. The segment between s1 and s2 should include statements \ns1, s2, and l, but exclude the CFG edge from s2 to l.  5.2 Specializing Data Flow Given a control-.ow-specialized \nprogram, we specialize its data .ow using a series of constraint-based analyses leveraging the STP [5] \ninteger constraint solver. We collect constraints on two types of program constructs: the LLVM virtual \nregisters and mem\u00adory locations. LLVM virtual registers are already in static-single\u00adassignment (SSA) \nform, so collecting constraints on them is rel\u00adatively straightforward. Table 1 lists how we collect \nconstraints for some LLVM instructions; the remaining instructions are similar and omitted for space. \nWe handle loops by exploiting LLVM s loop structure: most of the loops in our evaluated programs are \ncanoni\u00adcalized by LLVM so that we can easily collect range constraints on the loop indices. Our algorithm \nto collect constraints on memory locations mim\u00adics classic def-use analysis. It collects two forms of \nconstraints on memory locations: (1) the value loaded by an LLVM load instruc\u00adtion is the same as the \nvalue stored by a store instruction and (2) the value loaded by a load is the same as the value loaded \nby another load. That is, we treat an LLVM load instruction as a use and an LLVM load or store instruction \nas a def. Treating loads as defs shortens the def-use chains and reduces analysis time. Collecting precise \ndef-use constraints on memory locations is challenging for multithreaded programs. Fortunately, schedule \nspe\u00adcialization enables two key re.nements over classic def-use analy\u00adsis so that our algorithm can collect \nmore precise constraints. First, we compute def-use chains spanning across threads because mul\u00adtiple \nthreads may indeed access the same shared memory location. Without schedule specialization, it would \nbe hopeless to track pre\u00adcise inter-thread def-use chains because the defs and uses may pair up in numerous \nways depending on the schedules. Second, we compute must-def-use, instead of may-def-use, re\u00adsults. Our \ninsight is that by .xing the schedule, we often .x the def-use chains of key shared data, such as the \nglobal id in Fig\u00adure 1. It is thus most cost-effective to focus on these must-def-use chains because \n(1) they essentially capture the information (and hence the precision; see results in \u00a78.1) from the \nschedule and (2) there are typically much fewer must-def-use constraints than may\u00addef-use constraints, \nso the constraint-solving cost is low.  Instruction type LLVM instruction STP constraint Note binary \na = b op c a = b op c op is a binary operator integer comparison a = icmp pred, b, c a = (b pred c) \n pred is an integer comparison predicate such as < and .= pointer arithmetic a = gep b, i1, . . ., ik \na = b + i1\u00d7 sizeof(*b) + the offset gep calculates the location of a speci.c of ik-th .eld of ik-1-th \n.eld of . . . .eld in an array/structure of i2-th .eld of b select instruction a = select b, v1, v2 b \n= 0 . a = v1 If b = 0, a = v1; otherwise a = v2 b = 1 . a = v2 F instruction a = F(v1, . . ., vk) a = \nv1 or . . . or a = vk a may have any incoming value call and return a = func(b1, . . . , bk) b1 = f1, \n. . . , bk = fk Capture the equalities between the actual func(f1, . . . , fk) {return r;} a = r and \nformal parameters/return values Table 1: Collecting constraints from LLVM instructions on virtual registers. \n To practically implement these re.nements, we compute def\u00aduse chains only on the instructions unique \nto each segment. In ad\u00addition, we look for defs of a use only from its inter-thread dom\u00adinators which \nalways execute before the use once the schedule is enforced. These dominators are dominators on the CFG \naugmented with edges representing the total order of synchronizations in a schedule. We explain our algorithm \nas well as these re.nements in the next few paragraphs. Algorithm 2 shows the pseudo code to collect \ndef-use con\u00ad straints for memory locations. It operates on a control-.ow special\u00adized program with each \nsynchronization in the schedule mapped to a unique instruction. It references several symbols de.ned \non the instructions and segments (\u00a75.1) in this program: value(l): the value loaded if l is a load instruction, \nor the value stored if l is a store;  loc(l): the memory location accessed by instruction l;  segment(l): \nthe unique (explained in the next paragraph) seg\u00adment containing instruction l, or None;  thread(G): \nthe thread containing segment G;  begin(G): the synchronization at the beginning of segment G;  end(G): \nthe synchronization at the end of segment G;  reach(l1,l2): the set of instructions on all simple paths \nfrom l1 to l2 in the CFG. A simple path has no repeated instructions. Each segment has some unique instructions \ncloned by Algo\u00ad  rithm 1; segment(l) returns the containing segment for these in\u00adstructions, or None \notherwise. We de.ne a partial order over these instructions as follows: l1 happens-before l2, or l1 . \nl2, if (1) both l1 and l2 are synchronizations, and l1 comes earlier than l2 in the schedule; (2) segment(l1)= \nsegment(l2), and l1 comes ear\u00adlier in the segment; or (3) .l3, s.t. l1 . l3 and l3 . l2. We say G1 . \nG2 if end(G1) . begin(G2). Two instructions (segments) are concurrent if there is no happens-before between \nthem. At the top level, Algorithm 2 is similar to classic def-use anal\u00ad ysis. CaptureConstraints takes \na use u, calls PotentialDefs to get a set of potential defs, and, for each live def not killed, adds \nan equality constraint between the value used and the live def. PotentialDefs illustrates how we implement \nthe re.nements enabled by schedule specialization. It processes a use u only if segment(u) is not None, \ni.e., u is unique to a segment. It searches for defs only in the instructions unique to each segment. \nTo account for shared data access, it searches each thread td for a def of u. If td is the thread containing \nu, we search backwards from u for the lat\u00adest dominator in CFG that accesses the same location. Otherwise, \nwe search backwards from the latest synchronization s in td that happens-before u, and locate the latest \ndominator of s in CFG that accesses the same location. This dominator of s is essentially an inter-thread \ndominator of u. The result of PotentialDefs contains at most one def from each thread. In addition, it \ncontains at most one store and possibly many loads (because we treat loads as defs). Algorithm 2: Capture \nConstraints on Memory Locations CaptureConstraints(u) foreach d . PotentialDefs(u) do if not MayBeKilled(d, \nu) then AddConstraint( value(u)= value(d) ) PotentialDefs(u) defs .\u00d8 Gu . segment(u) p . loc(u) if Gu \n. = None then foreach thread td do if thread(Gu) = td then defs . defs . LatestDef(u, p) else Gd . latest \nsegment of td s.t. Gd . Gu defs . defs . LatestDef(end(Gd), p) return defs LatestDef(l, p) // returns \nthe latest intra-thread de.nition d . l repeat d . ImmediateDominator(d); until d = None or MustAlias(p, \nloc(d)) if d . = None then return {d} else return \u00d8 MayBeKilled(d, u) Gd . segment(d) Gu . segment(u) \nif Gd = Gu then return MayStore(reach(d, u), u) foreach segment G s.t. begin(G) . end(Gu) and begin(Gd) \n. end(G) and G ..do = Gd and G = Gu if MayStore(G, u) then return true return MayStore(reach(d, end(Gd)), \nu) or MayStore(reach(begin(Gu),u), u) MayStore(L, u) foreach store l . L do if MayAlias(loc(l), loc(u)) \nthen return true return false Function MayBeKilled checks whether def d is killed by any in\u00adstruction \nthat may store to loc(u) and execute after d and before u. It considers all instructions, not just the \nunique ones, for soundness. If d and u are in the same segment, MayBeKilled simply checks the instructions \nbetween d and u in the CFG. Otherwise, it checks in\u00adstructions in any segment that may (1) begin no later \nthan the end of u s segment Gu and (2) end no earlier than the begin of d s segment Gd. Note that these \nsegments include not only the ones concurrent to Gu or Gd, but also any segment G s.t. Gd . G . Gu. \n The above algorithm to collect constraints on memory locations needs alias analysis to determine whether \ntwo pointers must or may alias. We answer these queries again using STP. The question whether v1 and \nv2 may alias is rephrased as whether v1 = v2 is satis.able, and whether v1 and v2 must alias is rephrased \nas whether v1 = v2 is provable. Since constraint solving may take time, we also ported bddbddb [36], \na faster but less precise alias analysis to our framework, by writing an LLVM front end to collect program \nfacts into the format bddbddb expects. We always query bddbddb .rst before STP. Once constraints are \ncaptured, we perform a series of analyses based on these constraints. One analysis infers which LLVM \nvirtual register has constant values (recall that these registers are in SSA form). It .rst queries STP \nfor an assignment of value vj to each variable aj . For each aj , it then adds aj = vj to the current \nconstraints, and checks whether STP can prove the new constraints. If so, it replaces aj with vj , such \nas replacing variable p in Figure 1 with constant 2. Once variables are replaced with constants, we perform \nstock LLVM analyses, such as constant folding, dead code elimination, and loop unrolling, which automatically \ngain precision due to schedule specialization. These analyses may further simplify a program, so we iteratively \nrun data-.ow specialization and these stock analyses until the specialized program converges. 6. Implementation \nWe implement our framework within LLVM [1]. The specialization algorithms described in the previous section \nare implemented as an LLVM pass that specializes the LLVM bitcode representation of an original program \ninto a new bitcode program. These passes are of 11,754 lines of C/C++ code, with 2,586 lines for control\u00ad.ow \nspecialization and 9,168 lines for data-.ow specialization. The remaining of this section discusses several \nimplementation issues. 6.1 Constructing Call Graph For clarity, Algorithm 1 assumes a simple call graph \nwhere each function call has a unique callee and unique return address. How\u00adever, the programs we analyze \ndo use function pointers and excep\u00adtions, invalidating this assumption. To resolve a call to a function \npointer, we query our alias analysis and call TryDFS on each possi\u00adble callee. To handle exceptions, \nwe pair up the LLVM instruction that unwinds the stack (UnwindInst) with the call instruction that sets \nan exception handler (InvokeInst). 6.2 Optimizing Constraint Solving Data-.ow specialization (\u00a75.2) \nfrequently queries STP, and these queries can be quite expensive. We thus create four optimizations to \nspeed up constraint solving. First, when identifying which variables are constants, we avoid querying \nSTP for each variable. Speci.\u00adcally, when we query STP to prove that a variable is constant, we remember \nthe value assignment STP returns even if STP cannot prove the query. If a variable has two different \nvalues in these as\u00adsignments, then this variable cannot be constant, so we do not need to query STP whether \nthis variable is constant. This optimization alone speeds up our framework by over 10 times. Second, \nwe cache extensively. Recall that data-.ow specializa\u00adtion runs Algorithm 2 and other analyses iteratively. \nWithin each iteration, we cache all alias results to avoid redundantly querying STP. Across iterations, \nwe cache must and must-not alias re\u00adsults and the def-use results because each iteration only adds more \nconstraints and does not invalidate these precise results. Third, we use a union-.nd algorithm to speed \nup equality con\u00adstraints solving. The def-use constraints we collect are all equality constraints. When \nthe number of STP variables involved in these constraints increases, the STP queries tend to run slower. \nTo reduce the number of STP variables, we put program variables that must be equal in one equivalent \nclass represented by a union-.nd data structure, and assign only one STP variable to each class. Lastly, \nwe parallelize constraint solving. The STP queries is\u00adsued by our framework are mostly independent. Speci.cally, \neach run of Algorithm 2 on a use is completely independent of another. In addition, checking whether \none variable is constant is often in\u00addependent of checking another. We have built a parallel version \nof STP that speeds up our framework by roughly 3x when running on a quad-core machine.  6.3 Manual Annotations \nOur framework supports three types of annotations to increase pre\u00adcision and reduce analysis time. First, \nusers can provide a black\u00adlist of synchronization statements to customize which synchroniza\u00adtions go \ninto the schedules (\u00a73). Second, users can write regular assertions to enable our framework to collect \nmore precise con\u00adstraints. For instance, they can write assert(lower bound <= index &#38;&#38; index \n<= upper bound) to inform our framework the range constraints on index. Third, users can provide function \nsummaries to reduce analysis time. Some functions in the evalu\u00adated programs are quite complex and contain \nmany load and store instructions, causing our framework to collect a large set of con\u00adstraints. However, \nthese functions often have simple shared mem\u00adory access patterns which users can easily summarize to \nspeed up constraint solving. These summaries can be quite coarse-grained, such as function foo writes \nan unconstrained value to variable x. Users write summaries by writing fake functions, which our frame\u00adwork \nanalyzes instead of the original functions. By supporting an\u00adnotations in forms of assertions and fake \nfunctions, we avoid the need to support an annotation language. Of the 17 programs evaluated, we annotated \nonly 4 pro\u00adgrams. We blacklisted the lock operations in the custom memory allocator in cholesky. We annotated \ntwo loops in raytrace with assertions because they are not in LLVM\u00adcanonical form. (Currently our framework \nhandles only canon\u00adical loops.) We summarized .ve functions: image segment and image extract helper in \nferret, TraverseBVH \u00adwith StandardMesh and TraverseBVH with DirectMesh in raytrace, and LogLikelihood \nin bodytrack. These summaries range from 8 to 18 lines. 7. Applications To demonstrate the precision \nof our framework, we build three powerful analyses. The .rst is a precise schedule-aware alias an\u00adalyzer, \nbuilt on top of our def-use analysis (\u00a75.2). We chose to build an alias analyzer because alias analysis \nis crucial to many pro\u00adgram analyses and optimizations. Our analyzer provides a standard MayAlias(p, \nq) query interface, making it effortless to switch ex\u00adisting analyses to our our alias analyzer. Under \nthe hood, MayAlias .rst queries a coarse-grained, existing alias analysis; if this coarse\u00adgrained analysis \nreturns true, MayAlias then queries our def-use analysis for precise answers. The existing alias analysis \nwe used is the C version3 of bddbddb ported to LLVM. The second tool is a precise static race detector \nthat detects races that may occur only when a schedule is enforced. The detection logic appears identical \nto classic race detectors: two memory ac\u00adcesses are a race if (1) they may alias, (2) at least one of \nthe ac\u00adcesses is a store, and (3) they are concurrent. There are two key differences. First, ours uses \nschedule-aware alias analysis. Second, ours detects concurrent accesses w.r.t. a total synchronization \norder (\u00a75.2), more stringent than the execution order constraints dictated by the synchronizations. These \ntwo differences enable our detector to emit no or extremely few false positives (\u00a78.1). Multiple races \n3 The alias analysis we use makes several assumptions about the C programs it analyzes for soundness; \nthese assumptions are described in [9].  .agged on a specialized program may map to the same race in \nthe original program because control-.ow specialization clones state\u00adments. Our race detector emits only \none report in this case. The third tool is a thread-sensitive path slicer. Intuitively, given a program \npath, path slicing removes from the path the statements irrelevant to reach a given target statement \n[21]. The algorithm for doing so tracks control-and data-dependencies between state\u00adments, and removes \nstatements that the target does not control\u00ador data-depend upon. As previous work describes, path slicing \ncan be applied to many problems, such as post-mortem analy\u00adsis [21], counter-example generation [21], \nand malicious-input .l\u00ad tering [15]. Our path slicer improves upon existing path slicing work [21] by \ntracking dependencies across threads. Dependencies may arise across threads due to data or control .ow. \nFor example, if thread t0 stores to pointer p, and t1 then loads from q which may alias p, then the load \nin t1 data-depends on the store in t0. Simi\u00adlarly, if different branches of a branch statement in t0 \nmay cause t1 to load different values from a shared variable, then the load in t1 control-depends on \nthe branch statement in t0. Our path slicer correctly tracks these dependencies by leveraging our precise \nalias analyzer. Another feature of our path slicer is that it can slice to\u00adward multiple targets. 8. \nEvaluation We evaluated our schedule specialization framework on a diverse set of 17 programs, including \nPBZip2 1.1.5, a parallel compression utility; aget 0.4.1, a parallel wget-like utility; parallel implemen\u00adtations \nof 15 computation-intensive algorithms, 8 in SPLASH2 and 7 in PARSEC. We excluded 4 programs from SPLASH2 \nand 6 from PARSEC because we cannot compile them down to LLVM bitcode code, they use OpenMP [13] instead \nof Pthreads [34], data-.ow specialization runs out of time on them, the compiled code does not run correctly \nin 64-bit environment, or our current prototype cannot handle them due to an implementation bug. All \nof the pro\u00adgrams were widely used in previous studies [19, 25, 29, 38, 39]. We generated schedules for \nthe programs evaluated using the following workloads: for SPLASH2 programs, we used the default arguments \nexcept that we ran them with four threads. These pro\u00adgrams .nish within 100 ms. For PBZip2, we compressed \na 10 MB randomly generated text .le. For aget, we downloaded a .le of 1 MB from the internet. Unless \notherwise speci.ed, we ran all programs using four threads. This machine is a 2.8GHz Intel 12\u00adcore machine \nwith 64 GB memory running 64-bit Linux 2.6.38. We compiled all programs using Clang and LLVM 2.9 with \nthe default optimization level (often -O2 or -O3) of each program. In the remainder of this section, \nwe .rst focus on two evaluation questions: (1) how much more precise the analyses become with schedule \nspecialization (\u00a78.1); and (2) what the overhead of our framework is (\u00a78.2). We then present the bugs \nwe detected with the precision provided by schedule specialization (\u00a78.3). 8.1 Precision We measured \nhow our framework can improve the precision on the three analyses we built, the alias analyzer, the race \ndetector, and the path slicer (\u00a77). Our methodology is to apply these analyses on an original program, \nthe control-.ow specialized program, and the data-.ow specialized program, and then compare the results. \nAlias analysis precision. We quanti.ed alias analysis precision by measuring alias percentage, the percentage \nof alias queries that return may , instead of must and must-not , responses because the latter two responses \nare precise. We selected the two pointers in each query from different threads to stress-test our alias \nanalyzer because these pointers may appear to point to the same global array or the same thread-private \nheap or stack location, but are actually not aliases because most programs we evaluated access distinct \n the percentage of alias queries that return may responses. Lower bars mean more precise results. Each \ncluster in the .gure corresponds to the results from one program. The three columns in a cluster represent \nthe alias percentage when applying our analysis on the original program, the control\u00ad.ow specialized \nprogram, and the data-.ow specialized program. memory locations in different threads. The total number \nof such queries can be large for programs that do many memory accesses, so we sampled some percentage \nof the queries to bound the total query time. The sampling ratio for aget, PBZip2 and fft is 1 ; for \n50 1 water-spatial, 5000 ; and for barnes, water-nsquared, and ocean, 1 . For all other programs, we \nprocessed all queries. 50000 Figure 8 shows the alias precision results. For 12 pro\u00adgrams (aget, PBZip2, \nfft, lu-contig, radix, blackscholes, swaptions, streamcluster, canneal, bodytrack, ferret, and raytrace), \ncontrol-.ow and data-.ow specialization com\u00adbined greatly improved precision. For instance, they reduced \nthe alias percentage down to below 0.1% for aget. For 7 (PBZip2, fft, swaptions, streamcluster, canneal, \nbodytrack, and raytrace) of these 12 programs, control-.ow specialization im\u00adproved the alias analysis \nprecision signi.cantly. For instance, it re\u00adduced the alias percentage of PBZip2 from 28.04% to 8.30%, \na 70.4% reduction. The reason is that these programs allocate a fair amount of thread-private heap or \nstack data. Since the control-.ow specialization clones thread functions and thus automatically pro\u00advides \nthread sensitivity, our alias analyzer distinguishes accesses from different threads, achieving high \nprecision. Although control\u00ad.ow specialization alone did not signi.cantly improve precision for the other \n6 programs (aget, PBZip2, lu-contig, radix, blackscholes, and ferret) of the 12 programs, it created \nop\u00adportunities for data-.ow specialization to improve precision. For the remaining 5 programs (cholesky, \nbarnes, water-spatial, water-nsquared, and ocean), the reduction was not signi.cant. This small reduction \ncould be caused by the imprecision in our an\u00adalyzer (e.g., it is not path-sensitive), or real bugs in \nthe original programs (\u00a78.3). The mean reduction over all programs is 61.9%. Race detection precision. \nWe report the precision of our race detector here, and describe the detected bugs in \u00a78.3. To evaluate \nits precision, we compared the number of false positives it emitted to a baseline race detector we built. \nThis baseline detector uses the same de.nition of concurrent accesses (\u00a77), except that it queries our \nbddbddb port instead of our alias analysis because our precise alias results can only be computed assuming \na given schedule will be enforced. Since the total number of concurrent memory access pairs may be large, \nwe used sampling for some benchmarks. The sampling ratio was 1 for PBZip2, fft, barnes, water-spatial, \n50 1 and ocean; and 5000 for water-nsquared. For all other programs, we checked all concurrent access \npairs.  specialization, and after data-.ow specialization. Program FPours FPbaseline Races aget 0 72 \n1 PBZip2 0 125 32 fft 0 96 0 lu-contig 18 18 0 cholesky 7 31 0 radix 14 53 0 barnes * water-spatial * \nwater-nsquared * ocean * 369 1799 333 292 370 2447 354 331 n/a n/a n/a n/a blackscholes 0 3 0 swaptions \n0 165 0 streamcluster 0 4 0 canneal 0 21 0 bodytrack 0 4 0 ferret 0 6 0 raytrace 0 215 0 Table 2: Precision \nof the race detector. FPours and FPbaseline show the number of false positives for our detector and the \nbaseline, respectively. Races show the true races detected. The four starred programs have a larger number \nof reports, so we conservatively treated all reports as false positives. We counted the number of false \npositives for our detector, de\u00adnoted by FPours, by inspecting its reports. Since the number of re\u00adports \nfor barnes, water-spatial, water-nsquared, and ocean is large, we inspected a random selection of 20 \nreports, and found that they were all false positives. We thus conservatively treated all reports from \nthese programs as false positives. We counted the number of false positives for the baseline detector, \ndenoted by FPbaseline, by computing Rbaseline - Rours + FPours where R is the number of reports. This \nformula works because our detector is more precise than the baseline detector, and a report .agged only \nby the baseline detector must be a false positive. Table 2 shows the false positive comparison results \nfor all 17 programs. For 10 of them, the precision of framework enabled our detector to reduce the number \nof false positives to 0. The reduction for cholesky and radix is also large. For lu-contig, barnes, water-nsquared, \nwater-spatial, and ocean, our race detector reported slightly fewer races than the baseline; some of \nthese results are expected based on our alias precision results. The mean reduction over all programs \nis 69.0%. Table 2 also shows the number of true but benign races detected. (We present the harmful races \nin \u00a78.3.) Our detector found 1 race on variable bwritten in aget and 32 races on variable AllDone, NumBlocks, \nand OutputBuffer in PBZip2. Without the precision of our framework, users may have to inspect hundreds \nof reports before .nding the true races. Program LOC Sched Cons Use CF (s) DF (s) aget 866 219 2667 720 \n1.4 1551.7 PBZip2 9869 158 1382 480 3.1 973.1 fft 877 98 1122 277 1.5 113.8 lu-contig 904 48 824 229 \n1.4 65.0 cholesky 3962 42 1550 1302 2.3 1967.9 radix 919 112 1016 330 1.5 42.5 barnes 2234 5555 1605 \n19280 5.4 1968.1 water-spatial 1958 1037 14572 5008 2.8 313.4 water-nsquared 1620 4768 48023 14530 4.1 \n468.8 ocean 2958 5709 66253 18580 6.8 1795.0 blackscholes 1264 51 482 130 1.2 38.3 swaptions 1094 15 \n215 105 1.3 9.7 streamcluster 1765 90 840 216 1.5 834.6 canneal 2794 31 535 311 5.4 96.9 bodytrack 7696 \n381 998 240 1.7 20.9 ferret 10765 153 439 118 1.0 35.3 raytrace 13226 87 13468 417 1.4 5397.8 Table 3: \nSpecialization time. LOC shows the lines of code in each program. The LOC of PBZip2 includes the bzip2 \ncompression library. We show the time spent in specializing control .ow (CF) and data .ow (DF). Since \nspecialization time are affected by the schedule, constraints, and queries, we also show the schedule \nlength (Sched), the number of constraints (Cons), and the number of uses in the def-use analysis (Use). \n Figure 10: True vs. derived synchronizations in schedules. Path slicer precision. To quantify the precision \nof our path slicer, we measured slicing ratio, the percentage of statements that remain in an execution \ntrace. Figure 9 compares the preci\u00ad sion of path slicing on the original programs and the specialized \nprograms.4 Control-.ow specialization largely reduced the slic\u00ading ratio for PBZip2, aget, swaptions, \nwater-spatial, and water-nsquared. For instance, it reduced the slicing ratio for PBZip2 from 43.84% \nto 4.40%, a 89.97% reduction. Data-.ow specialization further reduced the ratio for PBZip2, swaptions, \nblackscholes, streamcluster, fft, lu-contig and radix. For instance, it reduced the slicing ratio for \nfft from 64.25% to 8.95%, a 86.08% reduction. The ratio reduction for cholesky, barnes, and ocean was \nrelatively small because our alias anal\u00adysis sometimes reports may-alias for pointers accessed in different \nthreads, causing more instructions than necessary to be included in the slices. The mean reduction over \nall programs is 48.7%.  8.2 Overhead Table 3 shows the time specializing the control and data .ow for \neach program. Control-.ow specialization is much faster than data\u00ad.ow specialization because it does \nnot require expensive constraint\u00adbased analysis. Data-.ow specialization typically .nishes within minutes \nor hours. This time is correlated with the size of the schedule, the number of constraints collected, \nand the number of constraint-solving queries. We also measured the number of derived synchronizations, \ni.e., the calls to functions may transitively do synchronizations to re\u00ad 4 We obtained the slicing results \nfrom an earlier prototype of our framework.  Program Position Bug Effect aget Download.c: rbuf may not \nhave the byte sequence \\r\\n\\r\\n. aget needs an extra race, program crash, or large data corruption 87-95 \nbound check. aget Download.c: The bound check should be td->offset + dr -i > foffset, not race, or program \ncrash 98-99 dr -i > foffset. The size passed to pwrite should be foffset -td->offset, not foffset -i. \naget Download.c: aget should check the return value of pwrite. race, program crash, or small data corruption \n99,101,113,115 aget Download.c:111 aget should check the return value of recv. race, program crash, or \nsmall data corruption radix radix.C:148 radix should check variable radix against its upper bound 4096. \nrace, program crash. radix radix.C:159 radix should check num keys against its upper bound 262144. race, \nor program crash fft fft.C:162 fft should check log2 line size against its upper bound 4. program crash \n(before a race may occur) Table 4: Bugs found. solve call-stack ambiguity (\u00a75.1). If this number is \nlarge, the over\u00ad head to record schedules and specialize programs may increase. Figure 10 shows that, \nfor every program evaluated, the majority of the synchronizations in the schedule are still true synchroniza\u00adtions. \nTherefore, including derived synchronizations in the sched\u00adules does not incur signi.cant overhead. \n 8.3 Bugs Found The precision of our framework helped detect 7 previously un\u00adknown bugs in the evaluated \nprograms. This result is particularly interesting considering that the evaluated programs have been well \nchecked in previous work [19, 25, 29, 38, 39]. These bugs were typically detected as follows. Our analyses \n.agged two memory accesses from different threads as poten\u00adtial aliases or races, even though they should \nnot be. We initially thought these false positives were due to the imprecision of our analyses and inspected \nthem. Speci.cally, we queried STP for a solution to make the two pointers accessed identical. Surprisingly, \nmany of these false positives turned to be real bugs. A common cause is that an input variable is used \nas an array index without being checked against the upper or lower bounds of the array or the partition \nof the array assigned to a thread. Such off-bound accesses may indeed cause different threads to race, \nand our analyses thus .agged them. We detected 7 such bugs in aget, radix, and fft, which are shown in \nTable 4. These bugs may cause races, program crashes, or, worse, .le data corruption. We manually veri.ed \nthese effects by running the buggy benchmarks on the bug\u00adinducing inputs generated by STP. (The results \npresented in the previous two subsections are from the patched programs because we do not want these \nbugs to pollute our evaluation.) 9. Related Work Slicing. Slicing techniques can remove irrelevant statements \nor instructions. Program slicing [35] does so on programs, dynamic slicing [6, 40] on dynamic execution \ntraces, and path slicing [21] on (potentially infeasible) paths. Precondition slicing [15] is similar \nto path slicing with improved precision by incorporating dynamic information into the analysis. Our technique \nto specialize a program toward a schedule dif\u00adfers from these slicing techniques because it takes as \ninput both a program and a schedule, and outputs a specialized program that can actually run. Moreover, \nour technique does not merely remove statements; instead, it may transform a program by cloning state\u00adments \nwhen specializing the control .ow of the program, replacing variables with constants when specializing \nthe data .ow, etc. Deterministic multithreading. Several recent systems [8, 10 12, 16 18, 24, 28] eliminate \nnondeterminism due to thread inter\u00ad leaving; our TERN [16] and PEREGRINE [17] further reduce input nondeterminism. \nThese DMT systems are not designed to facili\u00adtate static analysis. For instance, all existing DMT systems \nexcept TERN and PEREGRINE compute schedules online without storing them explicitly, making it dif.cult \nto analyze a program w.r.t. these implicit schedules. Moreover, although several DMT systems con\u00adstrain \na program to always use the same schedule for the same in\u00adput, they may force the program to use a different \nschedule when the input changes slightly. This instability [16] not only aggra\u00ad vates input nondeterminism, \nbut also largely prevents amortizing the static analysis cost in schedule specialization. Nonetheless, \nour framework may use one of these systems to enforce schedules. Indeed, our framework leverages our \nPERE-GRINE system, which explicitly stores and reuses schedules. Al\u00adthough PEREGRINE used a technique \nsimilar to the specialization algorithms described in \u00a75, our PEREGRINE paper [17] described the technique \nmainly from a user s perspective, and presented no schedule specialization framework nor detailed algorithms. \nProgram specialization. Program specialization can specialize a program according to various goals [14, \n20, 22, 27, 31]. For in\u00ad stance, it can specialize according to common inputs [14, 27]. The specialized \nprograms can then be better optimized. Unlike previous work, our framework specializes a program toward \na set of sched\u00adules, thus allowing stock analyses and optimizations to run on the specialized programs. \nTo the best of our knowledge, we are the .rst to specialize a program toward schedules. 10. Conclusion \nand Future Work We have presented schedule specialization, an approach to analyze a multithreaded program \nover a small set of schedules for preci\u00adsion, and then enforce these schedules at runtime for soundness. \nWe have built a framework that specializes a program into a sim\u00adpler program based on a schedule, so \nthat the resultant program can be analyzed with stock analyses. Our framework provides a precise schedule-aware \ndef-use analysis, enabling many powerful applica\u00adtions. Our results show that our framework can drastically \nimprove the precision of alias analysis, path slicing, and race detection. In our future work, we plan \nto leverage the precision provided by our framework to build precise error detectors, post-mortem analyzers, \nveri.ers, and optimizers for multithreaded programs. In addition, we believe a similar specialization \napproach can improve analysis precision for sequential programs, too. In general, static analysis over \nall possible executions may be imprecise. To improve precision, we may perform static analysis over only \na small set of executions (e.g., the most common executions) and, if necessary, resort to dynamic analyses \nfor the other executions. We believe this direction will face many interesting precision, soundness, \nand overhead tradeoffs, which we will investigate. Acknowledgement Alex Aiken, Stephen Edwards, Roxana \nGeambasu, Martha Kim, Eric Powders, and the anonymous reviewers provided many helpful comments, which \nhave substantially improved the content and pre\u00adsentation of this paper. We thank Huayang Guo for LATEX \nhelp. This work was supported in part by AFRL FA8650-11-C-7190, FA8650\u00ad10-C-7024 and FA8750-10-2-0253; \nand NSF CNS-1117805, CNS\u00ad1054906 (CAREER), CNS-1012633, and CNS-0905246.  References [1] The LLVM compiler \nframework. http://llvm.org. [2] The Princeton application repository for shared-memory computers (PARSEC). \nhttp://parsec.cs.princeton.edu/. [3] Parallel BZIP2 (PBZIP2). http://compression.ca/ pbzip2/. [4] Stanford \nparallel applications for shared memory (SPLASH). http: //www-flash.stanford.edu/apps/SPLASH/. [5] STP \nConstraint Solver. https://sites.google.com/site/ stpfastprover/. [6] H. Agrawal and J. R. Horgan. Dynamic \nprogram slicing. In Proceed\u00adings of the ACM SIGPLAN 90 Conference on Programming Language Design and \nImplementation (PLDI 90), pages 246 256, 1990. [7] Apache Web Server. http://www.apache.org. [8] A. Aviram, \nS.-C. Weng, S. Hu, and B. Ford. Ef.cient system-enforced deterministic parallelism. In Proceedings of \nthe Ninth Symposium on Operating Systems Design and Implementation (OSDI 10), Oct. 2010. [9] D. Avots, \nM. Dalton, V. B. Livshits, and M. S. Lam. Improving software security with a C pointer analysis. In Proceedings \nof the 27th International Conference on Software Engineering (ICSE 05), pages 332 341, May 2005. [10] \nT. Bergan, O. Anderson, J. Devietti, L. Ceze, and D. Grossman. Core-Det: a compiler and runtime system \nfor deterministic multithreaded execution. In Fifteenth International Conference on Architecture Sup\u00adport \nfor Programming Languages and Operating Systems (ASPLOS 10), pages 53 64, Mar. 2010. [11] T. Bergan, \nN. Hunt, L. Ceze, and S. D. Gribble. Deterministic process groups in dOS. In Proceedings of the Ninth \nSymposium on Operating Systems Design and Implementation (OSDI 10), pages 1 16, Oct. 2010. [12] E. Berger, \nT. Yang, T. Liu, D. Krishnan, and A. Novark. Grace: safe and ef.cient concurrent programming. In Conference \non Object-Oriented Programming Systems, Languages, and Applications (OOP-SLA 09), pages 81 96, Oct. 2009. \n[13] O. A. R. Board. OpenMP application program interface version 3.0, May 2008. [14] C. Consel and O. \nDanvy. Tutorial notes on partial evaluation. In Pro\u00adceedings of the 20th Annual Symposium on Principles \nof Programming Languages (POPL 93), pages 493 501, 1993. [15] M. Costa, M. Castro, L. Zhou, L. Zhang, \nand M. Peinado. Bouncer: securing software by blocking bad input. In Proceedings of the 21st ACM Symposium \non Operating Systems Principles (SOSP 07), pages 117 130, Oct. 2007. [16] H. Cui, J. Wu, C.-C. Tsai, \nand J. Yang. Stable deterministic multi\u00adthreading through schedule memoization. In Proceedings of the \nNinth Symposium on Operating Systems Design and Implementation (OSDI 10), Oct. 2010. [17] H. Cui, J. \nWu, J. Gallagher, H. Guo, and J. Yang. Ef.cient determinis\u00adtic multithreading through schedule relaxation. \nIn Proceedings of the 23rd ACM Symposium on Operating Systems Principles (SOSP 11), Oct. 2011. [18] J. \nDevietti, B. Lucia, L. Ceze, and M. Oskin. DMP: deterministic shared memory multiprocessing. In Fourteenth \nInternational Confer\u00adence on Architecture Support for Programming Languages and Oper\u00adating Systems (ASPLOS \n09), pages 85 96, Mar. 2009. [19] Q. Gao, W. Zhang, Z. Chen, M. Zheng, and F. Qin. 2ndStrike: towards \nmanifesting hidden concurrency typestate bugs. In Sixteenth International Conference on Architecture \nSupport for Programming Languages and Operating Systems (ASPLOS 11), pages 239 250, Mar. 2011. [20] R. \nGl\u00a8 Ef.cient multi-level generating exten\u00ad uck and J. J\u00f8rgensen. sions for program specialization. In \nProceedings of the 7th Inter\u00adnational Symposium on Programming Languages: Implementations, Logics and \nPrograms, pages 259 278, 1995. [21] R. Jhala and R. Majumdar. Path slicing. In Proceedings of the ACM \nSIGPLAN 2005 Conference on Programming Language Design and Implementation (PLDI 05), pages 38 47, 2005. \n[22] J. J\u00f8rgensen. Generating a compiler for a lazy language by partial eval\u00aduation. In Proceedings of \nthe 19th Annual Symposium on Principles of Programming Languages (POPL 92), pages 258 268, 1992. [23] \nN. G. Leveson and C. S. Turner. An investigation of the therac-25 accidents. Computer, 26(7):18 41, 1993. \n[24] T. Liu, C. Curtsinger, and E. D. Berger. DTHREADS: ef.cient deter\u00administic multithreading. In Proceedings \nof the 23rd ACM Symposium on Operating Systems Principles (SOSP 11), Oct. 2011. [25] S. Lu, S. Park, \nE. Seo, and Y. Zhou. Learning from mistakes: a com\u00adprehensive study on real world concurrency bug characteristics. \nIn Thirteenth International Conference on Architecture Support for Pro\u00adgramming Languages and Operating \nSystems (ASPLOS 08), pages 329 339, Mar. 2008. [26] G. C. Necula, S. McPeak, and W. Weimer. CCured: type-safe \nretro.tting of legacy code. In Proceedings of the 29th Annual Sym\u00adposium on Principles of Programming \nLanguages (POPL 02), pages 128 139, 2002. [27] V. Nirkhe and W. Pugh. Partial evaluation of high-level \nimperative programming languages with applications in hard real-time systems. In Proceedings of the 19th \nAnnual Symposium on Principles of Pro\u00adgramming Languages (POPL 92), pages 269 280, 1992. [28] M. Olszewski, \nJ. Ansel, and S. Amarasinghe. Kendo: ef.cient de\u00adterministic multithreading in software. In Fourteenth \nInternational Conference on Architecture Support for Programming Languages and Operating Systems (ASPLOS \n09), pages 97 108, Mar. 2009. [29] S. Park, S. Lu, and Y. Zhou. CTrigger: exposing atomicity violation \nbugs from their hiding places. In Fourteenth International Conference on Architecture Support for Programming \nLanguages and Operating Systems (ASPLOS 09), pages 25 36, Mar. 2009. [30] K. Poulsen. Software bug contributed \nto blackout. http://www. securityfocus.com/news/8016, Feb. 2004. [31] T. Reps and T. Turnidge. Program \nspecialization via program slicing. In Proceedings of the Dagstuhl Seminar on Partial Evaluation, volume \n1101, pages 409 429. Springer-Verlag, 1996. [32] M. Ronsse and K. De Bosschere. Recplay: a fully integrated \npractical record/replay system. ACM Trans. Comput. Syst., 17(2):133 152, 1999. [33] R. Rugina and M. \nRinard. Symbolic bounds analysis of pointers, array indices, and accessed memory regions. In Proceedings \nof the ACM SIGPLAN 2000 Conference on Programming Language Design and Implementation (PLDI 00), pages \n182 195, June 2000. [34] The Open Group and the IEEE. POSIX.1-2008. http://pubs. opengroup.org/onlinepubs/9699919799/, \n2008. [35] M. D. Weiser. Program slices: formal, psychological, and practical investigations of an automatic \nprogram abstraction method. PhD thesis, 1979. [36] J. Whaley and M. S. Lam. Cloning-based context-sensitive \npointer alias analysis using binary decision diagrams. In Proceedings of the ACM SIGPLAN 2004 Conference \non Programming Language Design and Implementation (PLDI 04), pages 131 144, June 2004. [37] J. Yang, \nA. Cui, J. Gallagher, S. Stolfo, and S. Sethumadhavan. Con\u00adcurrency attacks. Technical Report CUCS-028-11, \nColumbia Univer\u00adsity. [38] W. Zhang, C. Sun, and S. Lu. ConMem: detecting severe concurrency bugs through \nan effect-oriented approach. In Fifteenth International Conference on Architecture Support for Programming \nLanguages and Operating Systems (ASPLOS 10), pages 179 192, Mar. 2010. [39] W. Zhang, J. Lim, R. Olichandran, \nJ. Scherpelz, G. Jin, S. Lu, and T. Reps. ConSeq: detecting concurrency bugs through sequential errors. \nIn Sixteenth International Conference on Architecture Support for Programming Languages and Operating \nSystems (ASPLOS 11), pages 251 264, Mar. 2011. [40] X. Zhang and R. Gupta. Cost effective dynamic program \nslicing. In Proceedings of the ACM SIGPLAN 2004 Conference on Programming Language Design and Implementation \n(PLDI 04), pages 94 106, 2004.   \n\t\t\t", "proc_id": "2254064", "abstract": "<p>Parallel programs are known to be difficult to analyze. A key reason is that they typically have an enormous number of execution interleavings, or <i>schedules</i>. Static analysis over all schedules requires over-approximations, resulting in poor precision; dynamic analysis rarely covers more than a tiny fraction of all schedules. We propose an approach called <i>schedule specialization</i> to analyze a parallel program over only a small set of schedules for precision, and then enforce these schedules at runtime for soundness of the static analysis results. We build a schedule specialization framework for C/C++ multithreaded programs that use Pthreads. Our framework avoids the need to modify every analysis to be schedule-aware by specializing a program into a simpler program based on a schedule, so that the resultant program can be analyzed with stock analyses for improved precision. Moreover, our framework provides a precise <i>schedule-aware</i> def-use analysis on memory locations, enabling us to build three highly precise analyses: an alias analyzer, a data-race detector, and a path slicer. Evaluation on 17 programs, including 2 real-world programs and 15 popular benchmarks, shows that analyses using our framework reduced may-aliases by 61.9%, false race reports by 69%, and path slices by 48.7%; and detected 7 unknown bugs in well-checked programs.</p>", "authors": [{"name": "Jingyue Wu", "author_profile_id": "81479658170", "affiliation": "Columbia University, New York, NY, USA", "person_id": "P3471197", "email_address": "jingyue@cs.columbia.edu", "orcid_id": ""}, {"name": "Yang Tang", "author_profile_id": "81548030184", "affiliation": "Columbia University, New York, NY, USA", "person_id": "P3471198", "email_address": "ty@cs.columbia.edu", "orcid_id": ""}, {"name": "Gang Hu", "author_profile_id": "81502761266", "affiliation": "Columbia University, New York, NY, USA", "person_id": "P3471199", "email_address": "ganghu@cs.columbia.edu", "orcid_id": ""}, {"name": "Heming Cui", "author_profile_id": "81479655215", "affiliation": "Columbia University, New York, NY, USA", "person_id": "P3471200", "email_address": "heming@cs.columbia.edu", "orcid_id": ""}, {"name": "Junfeng Yang", "author_profile_id": "81502714673", "affiliation": "Columbia University, NEW YORK, NY, USA", "person_id": "P3471201", "email_address": "junfeng@cs.columbia.edu", "orcid_id": ""}], "doi_number": "10.1145/2254064.2254090", "year": "2012", "article_id": "2254090", "conference": "PLDI", "title": "Sound and precise analysis of parallel programs through schedule specialization", "url": "http://dl.acm.org/citation.cfm?id=2254090"}