{"article_publication_date": "06-11-2012", "fulltext": "\n Fully Automatic and Precise Detection of Thread Safety Violations Michael Pradel Thomas R. Gross Department \nof Computer Science Department of Computer Science ETH Zurich ETH Zurich Abstract Concurrent, object-oriented \nprograms often use thread-safe library classes. Existing techniques for testing a thread-safe class either \nrely on tests using the class, on formal speci.cations, or on both. Unfortunately, these techniques often \nare not fully automatic as they involve the user in analyzing the output. This paper presents an automatic \ntesting technique that reveals concurrency bugs in sup\u00adposedly thread-safe classes. The analysis requires \nas input only the class under test and reports only true positives. The key idea is to generate tests \nin which multiple threads call methods on a shared instance of the tested class. If a concurrent test \nexhibits an excep\u00adtion or a deadlock that cannot be triggered in any linearized execu\u00adtion of the test, \nthe analysis reports a thread safety violation. The approach is easily applicable, because it is independent \nof hand\u00adwritten tests and explicit speci.cations. The analysis .nds 15 con\u00adcurrency bugs in popular Java \nlibraries, including two previously unknown bugs in the Java standard library. Categories and Subject \nDescriptors D.1.3 [Programming Tech\u00adniques]: Concurrent Programming; D.1.3 [Programming Tech\u00adniques]: \nObject-oriented Programming; D.2.5 [Software Engi\u00adneering]: Testing and Debugging General Terms Languages, \nReliability, Algorithms Keywords Thread safety, Testing, Concurrent test generation 1. Introduction Writing \ncorrect concurrent programs is hard for many reasons. Developers tend to think think sequentially, making \nconcurrent programs hard to write and understand because of their non\u00addeterministic and parallel nature. \nFurthermore, testing techniques for concurrent programs have not yet reached the sophistication of techniques \nfor sequential programs. In this paper, we address the problem of testing concurrent pro\u00adgrams. Ideally, \na testing technique requires a single input a piece of software to analyze and produces a single output \ntrue pos\u00aditive reports of concurrency bugs in the tested software. Existing techniques do not meet this \nrequirement, because they either re\u00adquire additional input, produce undesirable additional output, or \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n12, June 11 16, 2012, Beijing, China. Copyright c . 2012 ACM 978-1-4503-1205-9/12/06. . . $10.00 both. \nAs an additional input besides the software to analyze, dy\u00adnamic approaches need tests that execute the \nsoftware. Writing tests is often neglected due to time constraints. Furthermore, writing ef\u00adfective concurrent \ntests is dif.cult, because they should lead the program to sharing state between concurrently executing \nthreads and should trigger many different execution paths. Another addi\u00adtional input that many static \nand dynamic analyses rely on are ex\u00adplicit, formal speci.cations, which must be developed in addition \nto the program itself. Unfortunately, few programs provide such spec\u00adi.cations. As an additional output \nbesides true positive bug reports, many existing approaches produce false positives. They reduce the \nusability of a bug .nding technique and can even make it unusable in practice [3]. This paper presents \nan automatic testing technique to detect concurrency bugs in thread-safe classes. We consider a class \nto be thread-safe if it behaves correctly when accessed from multiple threads, regardless of the scheduling \nor interleaving of the exe\u00adcution of those threads by the runtime environment, and with no additional \nsynchronization or coordination on the part of the call\u00ading code [20]. We say that a class is thread-unsafe \notherwise. Our approach requires a single input, a program or library containing the class under test \n(CUT), possibly accompanied by third-party libraries that the program depends on, and produces a single \nout\u00adput, true positive reports about concurrency bugs in the CUT. The analysis reports problems that \nresult in an exception or a deadlock. As both are obvious signs of misbehavior, the analysis reports \nonly true positives. Each bug report contains an executable, concurrent test that exposes the problem. \nAs a motivating example, consider a previously unknown bug that our approach detected in the StringBuffer \nclass of Sun s Java standard library in versions 1.6 and 1.7.1 StringBuffer is docu\u00admented as thread-safe \nand tries to synchronize all accesses to its internal data by locking on the StringBuffer instance (Figure \n1a). Our analysis generates tests that use StringBuffers concurrently. For example, the test in Figure \n1b creates a StringBuffer and uses it in two concurrent threads. Executing the test leads to an exception \nbecause insert() retrieves the length of s, a parameter of type CharSequence, before acquiring the lock. \nThe documenta\u00adtion states: This class synchronizes only on the string buffer per\u00adforming the operation, \nnot on the source. This behavior is fatal if the passed source is the StringBuffer itself, a case the \ndevelopers of the class apparently forgot to consider. In this case, retrieving the size of the StringBuffer \nis non-atomic with the consecutive update, leading to a potential boundary error caused by an inter\u00adleaved \nupdate. Our analysis detects this bug with no input but the StringBuffer class and producing no output \nbut this bug report. 1 We reported the problem and the developers acknowledged it as a bug. See entry \n7100996 in Sun s bug database.  class StringBuffer { StringBuffer(String s) { // initialize with the \ngiven String } synchronized void deleteCharAt(int index) { // modify while holding the lock } void insert(int \ndstOffset, CharSequence s) { int l = s.length(); // BUG: l may change this.insert(dstOffset, s, 0, l); \n} synchronized void insert(int dstOffset, CharSequence s, int start, int end) { // modify while holding \nthe lock } } (a) Supposedly thread-safe class. StringBuffer sb = new StringBuffer(\"abc\"); Thread 1 Thread \n2  sb.insert(1, sb); sb.deleteCharAt(0); Result: IndexOutOfBoundsException in Thread 1 (b) Execution \nof a generated concurrent test exposing a thread-safety bug. Figure 1: StringBuffer and a test execution \nexposing a thread\u00adsafety bug. Our approach is enabled by the combination of two contribu\u00adtions. The .rst \ncontribution is a test generation technique that cre\u00adates input to exercise the methods of a CUT from \nmultiple threads. Each generated test consists of a sequential part that instantiates the CUT and a concurrent \npart in which multiple threads call sup\u00adposedly thread-safe methods on the CUT instance. The technique \nenhances existing techniques to generate sequential tests [11, 37] by adapting them to a concurrent setting. \nSimply running generated sequential tests in parallel is very unlikely to result in shared state and \nto expose concurrency bugs. Instead, our technique generates tests that share a single CUT instance between \nmultiple threads and that expose concurrency bugs by using the instance concurrently. Some existing bug \n.nding techniques use a manually written test harness that, given a set of calls with concrete parameters, \nrandomly selects and executes calls [5, 21]. Our test generation technique advances upon this approach \nin two ways. First, it re\u00adlieves developers from providing calls and from .nding appropri\u00adate parameters \nfor these calls. The test generator creates parame\u00adters by instantiating other classes and by calling \nmethods of other classes. Second, and even more important, an automated approach produces more diverse \ntests because it tries to combine many dif\u00adferent methods, parameters, and receiver objects. As a result, \ngen\u00aderated tests include usage scenarios that a human may not come up with. For example, the test in \nFigure 1b triggers a bug by pass\u00ading a StringBuffer to itself, a situation that apparently remained untested \nfor several years. The second contribution is a test oracle, called the thread safety oracle, that determines \nwhether a concurrent test execution exposes a thread safety problem. The oracle classi.es a concurrent \nexecu\u00adtion as erroneous if the execution leads to an exception or to a dead\u00adlock and if this exception \nor deadlock cannot be triggered by any linearization of the calls in the concurrent execution. A lineariza\u00adtion \nmaps all calls of a concurrent test into a single thread while preserving the order of calls made by \nindividual threads. The ora\u00adcle assumes that sequential executions are deterministic. The thread safety \noracle is generic, precise, and practical. It is generic, because it can detect different kinds of concurrency \nbugs, including data races, atomicity violations, and deadlocks, given that the bug even\u00adtually causes \nan exception or deadlock. A study of 105 real-world concurrency bugs found that 62% of all bugs lead \nto a crash or a deadlock [30], suggesting that the thread safety oracle addresses a signi.cant problem. \nThe oracle is precise, because it guarantees that each reported problem is a real bug, since exceptions \nand dead\u00adlocks are certainly undesired behavior. Finally, the oracle is practi\u00adcal, because it does not \nrequire any explicit speci.cation to come with the CUT and instead leverages generic and implicit indicators \nof incorrectness. The thread safety oracle relates to seminal work on linearizabil\u00adity as correctness \ncriterion [22] and its recent adaption to object\u00adoriented programs in Line-Up [5]. In contrast to Line-Up, \nour ora\u00adcle is more effective and more ef.cient. It is more effective, because each test execution that \nfails according to the oracle is a true posi\u00adtive. In contrast, the Line-Up oracle classi.es 426 of 1,800 \ntest exe\u00adcutions as failing, which after manual inspection contain seven bugs [5]. This high violations-to-bugs \nratio is due to benign lin\u00adearizability violations and to multiple violations caused by the same bug. \nOur oracle is more ef.cient, because it only runs linearizations of a concurrent test if the concurrent \ntest leads to an exception or a deadlock. Instead, Line-Up explores all linearizations before run\u00adning \na concurrent test.2 We implement our approach as a prototype tool for Java and ap\u00adply it to six popular \ncode bases, including the Java standard library and Apache Commons Database Connection Pools (DBCP). \nThe analysis detects six previously unknown bugs, for example, two problems in supposedly thread-safe \nclasses, ConcurrentHashMap and StringBuffer, of the most recent version of the Java standard library. \nIn total, our implementation successfully reveals 15 bugs in the analyzed code bases. Twelve of them \nare exposed through a deadlock or an exception thrown by the virtual machine or the Java standard library, \nthat is, not relying on the use of exceptions in the CUT itself. In summary, this paper makes the following \ncontributions: A technique to generate concurrent tests that exercise a CUT from multiple threads. \n A generic test oracle that .nds concurrent executions that ex\u00adpose thread safety bugs in the CUT.  \nEmpirical evidence that combining concurrent test generation with the thread safety oracle is effective \nin automatically .nding concurrency bugs.  2. Overview We presents a dynamic analysis to detect concurrency \nbugs in thread-safe classes. This section explains the key ideas of the anal\u00adysis; Sections 3 and 4 .ll \nin the details. There are three requirements for detecting a thread safety bug with a dynamic analysis. \nFirst, a test that drives the CUT to a state exposing the bug. Second, an execution environment that \nexposes the bug when executing the test. Third, an oracle that recognizes the execution as erroneous. \nVarious approaches addressing the second requirement have been proposed [6, 10, 12, 33, 43]. This work \nfocuses on the .rst and the third requirement. We address the .rst requirement by generating tests that \ndrive a CUT (Section 3). Using automatically generated tests instead of relying on existing 2 A direct \ncomparison of our results with Line-Up is not possible as the details about the classes under test [5], \nas well as the speci.c bugs found, are no longer available [4].  tests has two bene.ts: (1) it makes \nour approach easy to use and (2) it provides a large range of different inputs that can expose bugs not \ntriggered by manually written tests. We address the third requirement with an oracle that determines \nwhether a concurrent execution exposes a thread safety problem (Section 4). Our analysis consists of \nthree iteratively performed steps, which correspond to the three requirements. At .rst, a generator of \ncon\u00adcurrent tests creates a test that sets up an instance of the CUT and that calls methods on this instance \nfrom multiple threads. Next, we execute the generated test. Since the class is supposed to be thread\u00adsafe, \nit should synchronize concurrent calls on the shared instance as needed. As a result, the methods should \nbehave as if they occur in some serial order that is consistent with the order of the method calls made \nby each of the individual threads involved [1]. The third step of our analysis checks whether the CUT \nbehaves as expected. If the analysis .nds that the concurrent execution shows behav\u00adior not possible \nin any linearization of calls, it reports a bug and terminates. Otherwise, the analysis goes back to \nthe .rst step and continues until a stopping criterion, such as a timeout or a speci.ed maximum number \nof generated tests, is reached. 3. Generating Concurrent Tests This section presents a technique to generate \nconcurrent tests that exercise a CUT from multiple threads. The input to the test gener\u00adator is a class \nC and, optionally, a set of auxiliary classes A that C depends on. The generator creates call sequences. \nEach call ci in a call sequence (c1,...,cn) consists of a method signature, a possibly empty list of \ninput variables, and an optional output vari\u00adable. The input variables of a call represent parameters \npassed to the method. For an instance call, the .rst input variable is the receiver of the call. The \noutput variable of a call represents its return value. We model constructor invocations as calls where \nthe output vari\u00adable represents the new object. Similarly, we model .eld accesses as calls where the \nunderlying object is the only input variable and where the output variable represents the .eld value. \nWe say that a call sequence is well-de.ned if each input variable of a call cj is the output variable \nof a call ci with i<j, that is, if each call uses only variables de.ned on prior calls. A test consists \nof a pre.x and a set of suf.xes. The pre.x is a call sequence supposed to be executed in a single thread. \nThe pre.x instantiates the CUT and calls methods on the CUT instance to grow the object, that is, to \nbring it into a state that may allow the suf.xes to trigger a bug. A suf.x is a call sequence supposed \nto be executed concurrently with other suf.xes after executing the pre.x. All suf.xes share the output \nvariables of the pre.x and can use them as input variables for suf.x calls. In particular, all suf.xes \nshare the CUT instance created in the pre.x. While our general approach is independent of the number \nof suf.xes, we focus on two suf.xes per test, so that a test is a triple (p, s1,s2) where p is the pre.x \nand s1,s2 are suf.xes. The rationale for this choice is that most real-world concurrency bugs involve \nno more than two threads [30]. Figure 1b is a very simple example for a test. The pre.x is a single call \nto the constructor of StringBuffer, which returns the CUT instance sb. Each of the two suf.xes calls \na single method using the shared CUT instance sb as the receiver. In practice, effective concurrent tests \nare not always that simple. Calling a method often requires providing parameters of a particular type, \nwhich in turn may require calling other methods. Furthermore, triggering a bug often requires to bring \nthe CUT instance in a particular state, for example, by calling setter methods. 3.1 Tasks To automatically \ngenerate concurrent tests, we divide the genera\u00adtion of a test into simpler tasks, which build and extend \ncall se\u00adquences. Each task takes a call sequence sin =(c1,...,ci) and returns a new sequence sout =(c1,...,ci,cj \n,...,cn) that ap\u00adpends n - j +1 additional calls to sin. The additional calls can use output variables \nof previous calls as their input variables. We use three kinds of tasks: instantiateCUT T ask, which \nappends a call to create a new instance of the CUT.  callCUT T ask, which appends a call to the CUT \ninstance.  parameterT ask, which makes a parameter of a particular type available by choosing an output \nvariable of a previous call or by appending a call that returns an object of the required type.  A task \nsucceeds if it extends sin with additional calls in such a way that sout is well-de.ned and that sout \nexecutes in a single thread without throwing an uncaught exception. The latter require\u00adment adapts an \nidea from sequential test generation [37], namely to use the result of executing call sequences for selecting \nwhich se\u00adquences to extend further. Generated call sequences that result in an exception typically contain \nan illegal call, for example, a call that violates the precondition for calling the method. Although \nfocusing on non-exceptional call sequences does not guarantee that each call is legal, it ensures that \nextending a sequence will eventually lead to executing more calls without reaching an obviously illegal \nstate. To successfully accomplish a task, the test generator extends sin into candidates for sout until \na candidate is found that is well\u00adde.ned and that executes without an exception. If after creating a \nspeci.ed number of candidates no candidate has ful.lled these conditions, the test generator gives up \non this task and the task fails. For example, the callCUT T ask may fail if the CUT instance is in a \nstate that does not allow calling any of the CUT methods.  3.2 Test Generation Algorithm Algorithm 1 \ndescribes how our analysis generates a concurrent test. There are three global variables, which maintain \ntheir values over multiple invocations of the algorithm: the set P of pre.xes, the map M assigning a \npre.x to its set of suf.xes, and the set T of already generated but not yet returned tests. The algorithm \nhas three main steps. At .rst, it creates a new pre\u00ad.x or chooses a previously created pre.x (lines 6 \nto 20). Then, it creates a new suf.x for the pre.x (lines 21 to 26). Finally, the algo\u00adrithm creates \ntests by combining the new suf.x with each existing suf.x (lines 27 to 29). To create pre.xes and suf.xes, \nthe algo\u00adrithm invokes tasks. The functions randT ake and randRemove randomly select an element of a \nset with a uniform probability dis\u00adtribution, and the randRemove function also removes the selected element \nfrom the set. Creating Pre.xes During the .rst step (lines 6 to 20), the algo\u00adrithm creates a new pre.x \nunless maxP refixes (discussed in Sec\u00adtion 5) have already been created. The reason for limiting the \nnum\u00adber of pre.xes is that we require multiple suf.xes for each pre.x to test different concurrent usages \nof a CUT instance. To create a new pre.x, the algorithm invokes the instantiateCUT T ask. This task randomly \nchooses a method m from all methods in C and A that have C or a subtype of C as return type. If calling \nm requires parameters, the task invokes parameterT asks to make these parameters available. The instantiateCUT \nT ask returns a call sequence that creates all required parameters, stores them into output variables, \nand calls m. If the test generator cannot instantiate the CUT, for example, because there is no public \nconstructor, the algorithm fails. For Figure 1b, the instantiateCUT T ask chose the StringBuffer constructor \nas m and obtains a string literal as parameter from parameterT ask (literals are passed without stor\u00ading \nthem into a variable).  Algorithm 1 Returns a concurrent test (p, s1,s2) 1: P: set of pre.xes . global \nvariables 2: M: maps a pre.x to suf.xes 3: T : set of ready-to-use tests 4: if |T | > 0 then 5: return \nrandRemove(T ) 6: if |P| < maxPrefixes then . create a new pre.x 7: p . instantiateCUT T ask(empty call \nsequence) 8: if p = failed then 9: if P = \u00d8 then 10: fail( cannot instantiate CUT ) 11: else 12: p . \nrandT ake(P) 13: else 14: for i . 1, maxStateChangerT ries do 15: pext . callCUT T ask(p) 16: if pext \n=.failed then 17: p . pext 18: P .P.{p} 19: else 20: p . randT ake(P) 21: s1 . empty call sequence . \ncreate a new suf.x 22: for i . 1, maxCUT CallT ries do 23: s1,ext . callCUT T ask(s1,p) 24: if s1,ext \n. = failed then 25: s1 . s1,ext 26: M(p) .M(p) .{s1} 27: for all s2 .M(p) do . one test for each pair \nof suf.xes 28: T .T .{(p, s1,s2)} 29: return randRemove(T ) After instantiating the CUT, the algorithm \ntries to invoke meth\u00adods on the CUT instance to change the state of the CUT instance. The callCUT T ask \nrandomly chooses a method among all meth\u00adods of C and invokes the parameterT ask for each required pa\u00adrameter. \nThe pre.x in Figure 1b contains no state changing call. Alternatively to the shown pre.x, the test generator \ncould have cre\u00adated the call sequence StringBuffer sb = new StringBuffer(); sb.append(\"abc\"); where the \nsecond call is a state changing call. Creating Suf.xes During the second step (lines 21 to 26), the algorithm \ncreates a new suf.x for the pre.x p. Therefore, it repeat\u00adedly invokes the callCUT T ask. In addition \nto the suf.x, the call in line 23 passes the pre.x to the task to allow for using output variables from \nthe pre.x as input variables in the suf.x. After ap\u00adpending calls to the CUT instance, the new suf.x \nis added to the set of suf.xes for the pre.x p. All tasks that append method calls depend on the parameter-T \nask. This task uses three strategies to make a parameter of a particular type t available. If the given \ncall sequence already has one or more output variables of type t or a subtype of t, the task randomly \nchooses between reusing a variable and creating a fresh variable. The rationale for creating fresh variables \nis to diversify the generated tests instead of passing the same parameters again and again. To reuse \na variable, the task randomly chooses from all available variables with matching type. To create a fresh \nvariable, the behavior depends on the type t. If t is a primitive type or String, the task returns a \nrandomly created literal. Otherwise, the tasks randomly chooses a method from all methods in C and A \nreturning t or a subtype of t. If calling this method requires parameters, the task recursively invokes \nitself. We limit the number ArrayList l = new ArrayList(); Thread 1 Thread 2 l.add(\"a\"); l.hashCode(); \nl.add(\"b\"); Result: ConcurrentModi.cationException in Thread 2 Figure 2: Test execution using a thread-unsafe \nclass. of recursions to avoid in.nite loops and fail the task if the limit is reached. If there is no \nmethod providing t, the parameterT ask returns null. Using null as a parameter may be illegal. In this \ncase, executing the sequence can result in an exception, for example, a NullPointerException, so that \nthe candidate is rejected. Creating Tests The third step of the algorithm (lines 27 to 29) combines the \nnew suf.x with each existing suf.x for the pre.x into a test. The algorithm stores the created tests \nin T and on further invocations returns a randomly selected test from T until T becomes empty.  3.3 \nBeyond This Work The tests generated by Algorithm 1 provide input to exercise a class without any human \neffort, and hence, increase the usefulness of existing dynamic analyses. For example, executions of generated \ntests can be analyzed by existing detectors of data races [15, 32, 42, 44] or atomicity violations [16, \n21, 28, 38, 45]. Without generated tests, these analyses are limited to manually created tests and the \nbugs exposed by these tests. 4. Thread Safety Oracle This section presents an automatic technique to \ndetermine whether the execution of a concurrent test exposes a thread safety bug. 4.1 Thread Safety \nA class is said to be thread-safe if multiple threads can use it with\u00adout synchronization and if the \nbehavior observed by each thread is equivalent to a linearization of all calls that maintains the order \nof calls in each thread [1, 20]. Saying that a class is thread-safe means that all its methods are thread-safe. \nOur approach can also deal with classes that guarantee thread safety for a subset of all methods by excluding \nthe unsafe methods when generating suf.xes for a test. Figure 2 is an example for a thread-unsafe class \nand a test exe\u00adcution that exposes this property. The concurrent use of ArrayList from java.util results \nin an exception that does not occur in any of the three possible linearizations of the calls: add . add \n. hashCode add . hashCode . add hashCode . add . add Therefore, the execution in Figure 2 shows that \nArrayList is thread-unsafe, as expected. A property related to thread safety is atomicity, that is, the \nguarantee that a sequence of operations performed by a thread ap\u00adpears to execute without interleaved \noperations by other threads. One way to make a class thread-safe is to guarantee that each call to one \nof its methods appears to be atomic for the calling thread. However, a thread-safe class does not guarantee \nthat mul\u00adtiple calls to a shared instance of the class are executed atomi\u00adcally [45]. For example, consider \nthe use of the thread-safe class java.util.concurrent.CopyOnWriteArrayList in Figure 3. Exe\u00adcuting the \nconcurrent test has three possible outputs. For all three,  CopyOnWriteArrayList l = new CopyOnWriteArrayList(); \n Thread 1 Thread 2 l.add(\"a\"); l.add(\"b\"); println(l); Result: [a], [a,b], or [b,a] Figure 3: Test execution \nusing a thread-safe class. there is a linearization of calls that provides the same result, so the test \nexecution does not expose a thread safety problem: add(\"a\") . println() . add(\"b\") gives [a] add(\"a\") \n. add(\"b\") . println() gives [a,b] add(\"b\") . add(\"a\") . println() gives [b,a] 4.2 De.nitions The thread \nsafety oracle answers the question whether a concurrent test execution exposes a thread safety problem \nby comparing the concurrent execution to executions of linearizations of the test. We use . to concatenate \nsequences, and c .s c . indicates that call c comes before call c . in a call sequence s. De.nition 1 \n(Linearization). For a test (p, s1,s2), let P12 be the set of all permutations of the call sequence s1 \n. s2. The set of linearizations of the test is: L(p,s1,s2) = {p . s12 | s12 .P12 . (.c,c c c ) . (c .s1 \n. c .s12 (c .s2 c . . c .s12 c .))} That is, a linearization of a test (p, s1,s2) appends to p all calls \nfrom s1 and from s2 in a way that preserves the order of calls in s1 and s2. De.nition 2 (Execution). \nFor a test (p, s1,s2), we denote the set of all distinguishable executions of this test as E(p,s1,s2). \nEach e(p,s1,s2) .E(p,s1,s2) represents the sequential execution of p followed by a concurrent execution \nof s1 and s2. Likewise, we denote the sequential execution of a call sequence s as es. A single test \ncan have multiple distinguishable executions be\u00adcause of the non-determinism of concurrent executions. \nThe following de.nition of thread safety refers to the equiva\u00ad ~ lence e1 = e2 of two executions e1 and \ne2. We discuss in Sec\u00adtion 4.3 how our oracle decides whether two executions are equiv\u00adalent. De.nition \n3 (Thread safety). Let TC be the set of all possible tests for a class C. C is thread-safe if and only \nif: .(p, s1,s2) .TC .e(p,s1,s2) .E(p,s1,s2) ~ .l .L(p,s1,s2) so that e(p,s1,s2) = el That is, a class \nis thread-safe if each concurrent test execution has an equivalent linearization.  4.3 The Test Oracle \nShowing that a class is thread-safe according to De.nition 3 is dif.cult in practice, because all possible \ntests and all possible executions of these tests would have to be considered. However, the thread safety \noracle can show that a class C is thread-unsafe by showing: .(p, s1,s2) .TC .e(p,s1,s2) .E(p,s1,s2) so \nthat .l .L(p,s1,s2) e(p,s1,s2) . el Algorithm 2 Checks whether a test (p, s1,s2) exposes a thread safety \nbug 1: repeat 2: e(p,s1,s2) . execute(p, s1,s2) 3: if failed(e(p,s1,s2)) then 4: seqF ailed . false 5: \nfor all l .L(p, s1,s2) do 6: if seqF ailed = false then 7: el . execute(l) 8: if failed(el) . sameF ailure(e(p,s1,s2),el) \nthen 9: seqF ailed . true 10: if seqF ailed = false then 11: report bug e(p,s1,s2) and exit 12: until \nmaxConcExecs reached That is, the thread safety oracle tries to .nd a test that exposes behavior not \npossible with any linearization of the test. To decide whether two executions are equivalent, the oracle \ncompares the exceptions and deadlocks caused by the executions. De.nition 4 (Equivalence of executions). \nTwo executions e1 and e2 are equivalent if neither e1 nor e2 results in an exception or a deadlock, \nor  both e1 and e2 fail for the same reason (that is, the same type of exception is thrown or both executions \nend with a deadlock).  Although this abstraction ignores many potential differences between executions, \nsuch as different return values of method calls, it is crucial to ensure that the analysis only reports \na class as thread\u00adunsafe if this is de.nitely true. Algorithm 2 shows how the analysis checks whether \na test (p, s1,s2) exposes a thread safety problem. The algorithm repeat\u00adedly executes the test until \na maximum number of concurrent ex\u00adecutions is reached, or until a bug is found. If the test fails, that \nis, it throws an exception or results in a deadlock, the algorithm executes all linearizations of the \ntest to check whether the same failure occurs during a sequential execution of the same calls. If no \nlinearization exposes the same failure, the algorithm reports a bug because the CUT is thread-unsafe. \nThe thread safety oracle is sound but incomplete.3 Every exe\u00adcution for which the oracle reports a bug \nis guaranteed to expose a real thread safety problem according to De.nition 3, but the or\u00adacle may classify \nan execution as correct even though it exposes a thread safety problem. The soundness of the oracle ensures \nthat our approach detects concurrency bugs without reporting false pos\u00aditives. We build upon two assumptions, \nwhich we .nd true for most real-world classes during our evaluation. First, we assume that un\u00adcaught \nexceptions and deadlocks that occur in a concurrent usage of a class but not in a sequential usage are \nconsidered a problem. This assumption is in line with the commonly accepted de.nition of thread safety \n[1, 20]. Second, we assume that sequential execu\u00adtions of a call sequence behave deterministically. Sequentially \nnon\u00addeterministic methods, for example, methods that depend on the current system time, should be excluded \nfrom our analysis. Alter\u00adnatively, our analysis can be combined with a runtime environment that ensures \ndeterministic sequential execution [40]. 3 We mean soundness and completeness regarding incorrectness \n[47]. In other communities, such as type systems, the terms are typically used with respect to correctness, \nthat is, inverse to the usage here.  5. Implementation We implement the test generator and the thread \nsafety oracle into an automatic bug detection tool for thread-safe Java classes. This section presents \nseveral challenges faced by the implementation and how we address them. The test generator executes many \ncall sequences and must do so both ef.ciently and without interference between different execu\u00adtions. \nTo execute sequences ef.ciently we take a re.ection-based approach similar to the sequential test generator \nRandoop [37]. A problem not addressed by Randoop is that different call sequences may interfere because \nof static state. For example, a call sequence s1 may assign a value to a static .eld and a call sequence \ns2 may read the static .eld. As a result, the outcome of executing s2 may vary depending on whether s1 \nis executed before s2. This problem is independent of concurrency. We address the problem by reset\u00adting \nall static state to the state of the freshly loaded classes before each execution of a call sequence. \nFor this purpose, our implemen\u00adtation instruments classes so that all modi.cations of static state are \nrecorded and can be reset. Csallner and Smaragdakis describe a similar approach for a sequential test \ngenerator [11]. The test generator takes a random seed as an input, which al\u00adlows for precise replay \nof the test generation process, as long as the tested classes behave deterministically in sequential \nexecu\u00adtions. Experience with sequential, random test generation shows that short runs with many different \nseeds trigger bugs faster than few runs with a small number of seeds [9]. Our initial experi\u00adments con.rmed \nthis observation, so we run the analysis in multiple rounds that each use a different random seed. The \n.rst rounds stop after trying a small number of suf.xes (ten) for a single pre.x. Later rounds gradually \nraise the maximum number of generated pre.xes (maxP refixes) to 25 and the maximum number of generated \nsuf\u00ad.xes to 500. The values of other parameters used in Algorithm 1 are maxStateChangerT ries =5, maxConcExecs \n= 100, and maxCUT CallT ries =2. To detect deadlocks, we use the management interface for the thread \nsystem of the Java virtual machine. A daemon thread peri\u00adodically queries this interface and noti.es \nthe thread safety oracle in case of a deadlock. Although being a prototype, the performance of our tool \nis ac\u00adceptable for a testing tool (details in Section 6). The by far most important bottleneck of our \nimplementation is the repeated concur\u00adrent execution of tests. For example, for the CUT taking the longest \nto analyze, 99.5% of the time is spent with concurrent executions. We see two ways to address this issue. \nFirst, the analysis can ex\u00adploit multiple cores by exploring different concurrent executions of the same \ntest in parallel. Second, our analysis can be easily com\u00adbined with existing techniques to increase the \nprobability of hitting a bug by controlling or perturbing the scheduler [6, 10, 12, 33, 43]. Our current \nimplementation executes tests with the standard Java thread scheduler. To plug a more sophisticated scheduling \ntech\u00adnique into our approach, one can rede.ne the execute function of Algorithm 2. 6. Evaluation We evaluate \nour approach by applying the prototype implementa\u00adtion to Java classes from six popular code bases: the \nJava standard library shipped with Sun s JDK, the database connection pool li\u00adbrary Apache Commons DBCP, \nthe serialization library XStream, the text processing toolkit LingPipe, the chart library JFreeChart, \nand Joda-Time, a library to handle data and time. 6.1 Experimental Setup All experiments are done on \nan eight-core machine with 3GHz Intel Xeon processors and 8GB memory running 32-bit Ubuntu Linux class \nConcurrentHashMap { void clear() { final Segment[] segments = this.segments; for (int j = 0; j < segments.length; \n++j) { Segment s = segmentAt(segments, j); if (s != null) s.clear(); // locks the segment } } void \nputAll(Map m) { for (Map.Entry e : m.entrySet()) // BUG: m s entries may change put(e.getKey(), e.getValue()); \n} Object put(Object key, Object value) { Segment s = /* get segment in a thread-safe way */; return \ns.put(key, value); // locks the segment } } (a) Supposedly thread-safe class. ConcurrentHashMap map = \nnew ConcurrentHashMap(); map.put(\"a\", \"b\"); Thread 1 Thread 2 map.clear(); map.putAll(map); map.hashCode(); \nResult: StackOver.owError in Thread 1 (b) Execution of a generated concurrent test exposing a thread-safety \nbug. Figure 4: Concurrency bug in ConcurrentHashMap. and the Java Hotspot VM version 1.6.0 27, giving \n2GB memory to the VM. We run experiments with different CUTs in parallel but run at most four tests at \na time to reserve a core for each concurrent thread exercising the CUT. We repeat each experiment ten \ntimes with different random seeds [37]. To analyze a CUT, the test generator uses all other public classes \nfrom the code base and common classes from the Java standard library as auxiliary classes.  6.2 Bugs \nFound The analysis found 15 bugs in supposedly thread-safe classes, six of them previously unknown. Each \nbug can cause concurrency bugs in clients relying on thread-safe classes. Table 1 lists all bugs along \nwith the reason for failing. The last column indicates whether the reason is a deadlock or an exception \nthrown implicitly by the virtual machine or by the Java standard library, or if triggering the bug requires \nan explicitly thrown exception in the analyzed code base. For twelve of 15 bugs, an implicit exception \nis suf.cient to reveal the bug. That is, our approach reveals most bugs without any requirement on the \nanalyzed classes, such as throwing an exception if an unsafe state is reached. The analysis reveals two \npreviously unknown bugs in the Java standard library, one of them shown as the motivating example in \nthe introduction (Figure 1). The other new bug in the Java standard library is illustrated in Figure \n4. The class ConcurrentHashMap is part of the java.util.concurrent package, which provides thread\u00adsafe \ncollection classes. For better scalability, the class divides the map into segments that are locked independently \nof each other, in\u00adstead of relying on a single exclusion lock. Unfortunately, putAll() does not consider \nthe case where the passed map is the same as the receiver object of the call. The method retrieves the \nentries of the passed map without any synchronization and then passes each el\u00adTable 1: Summary of results. \nThe last column indicates whether the reason for failing is implicit in the Java runtime environment \nor explicitly speci.ed in the code base under test.  ID Code base Class Declared Found Reason for failing \nImplicit thread-safe unsafe Previously unknown bugs: (1) JDK 1.6.0 27 and 1.7.0 StringBuffer yes yes \nIndexOutOfBoundsException yes (2) JDK 1.6.0 27 and 1.7.0 ConcurrentHashMap yes yes StackOver.owError \nyes (3) Commons DBCP 1.4 SharedPoolDataSource yes yes ConcurrentModi.cationException yes (4) Commons \nDBCP 1.4 PerUserPoolDataSource yes yes ConcurrentModi.cationException yes (5) XStream 1.4.1 XStream yes \nyes NullPointerException yes (6) LingPipe 4.1.0 MedlineSentenceModel yes yes IllegalStateException no \nKnown bugs: (7) JDK 1.1 BufferedInputStream yes yes NullPointerException yes (8) JDK 1.4.1 Logger yes \nyes NullPointerException yes (9) JDK 1.4.2 SynchronizedMap yes yes Deadlock yes (10) JFreeChart 0.9.8 \nTimeSeries yes yes NullPointerException yes (11) JFreeChart 0.9.8 XYSeries yes yes ConcurrentModi.cationException \nyes (12) JFreeChart 0.9.12 NumberAxis yes yes IllegalArgumentException no (13) JFreeChart 1.0.1 PeriodAxis \nyes yes IllegalArgumentException no (14) JFreeChart 1.0.9 XYPlot yes yes ConcurrentModi.cationException \nyes (15) JFreeChart 1.0.13 Day yes yes NumberFormatException yes Automatic classi.cation of classes as \nthread-unsafe: (16) Joda-Time 2.0 DateTimeFormatterBuilder no yes IndexOutOfBoundsException (10x) yes \n(17) Joda-Time 2.0 DateTimeParserBucket no yes IllegalArgumentException (9x) no NullPointerException \n(1x) yes (18) Joda-Time 2.0 DateTimeZoneBuilder no yes NullPointerException (6x) yes ArrayIndexOutOfBoundsException \n(2x) yes IllegalFieldValueException (2x) yes (19) Joda-Time 2.0 MutableDateTime no yes IllegalFieldValueException \n(9x) no ArithmeticException (1x) yes (20) Joda-Time 2.0 MutableInterval no yes IllegalArgumentException \n(10x) no (21) Joda-Time 2.0 MutablePeriod no yes ArithmeticException (10x) yes (22) Joda-Time 2.0 PeriodFormatterBuilder \nno yes ConcurrentModi.cationException (5x) yes IndexOutOfBoundsException (4x) yes IllegalStateException \n(1x) no Joda-Time 2.0 ZoneInfoCompiler no no (stopped after 24h) ement to the correctly synchronized \nput(). As a result, a call to map.putAll(map) can undo changes done by a concurrently ex\u00adecuting thread \nthat also modi.es the map a clear thread safety bug. Our analysis generates the test in Figure 4b, which \nexposes the problem. Calling hashCode() results in a stack over.ow for self-referential collections, \nbecause the method recursively calls itself (this is documented behavior). If ConcurrentHashMap were \nthread-safe, this behavior should not be triggered by the test, be\u00adcause all three possible linearizations \nof the calls in Figure 4b call clear() before calling hashCode(). However, the test fails with a StackOverflowError, \nbecause putAll() undoes the effects of the concurrently executed clear(). Figure 5 is a previously unknown \nbug that our analysis detects in Apache Commons DBCP. The supposedly thread-safe class SharedPoolDataSource \nprovides two methods setDataSource-Name() and close() that register and unregister the data source via \nstatic methods of InstanceKeyObjectFactory, respectively. The factory class maintains a thread-unsafe \nHashMap assigning names to data sources. Although registering new instances is synchronized to avoid \nconcurrent accesses to the HashMap, unregistering instances is not synchronized. The generated test in \nFigure 5b shows that this lack of synchronization leads to an exception when calling setDataSourceName() \nand close() concurrently. To allow for reproducing our results, all analyzed classes, de\u00adscriptions of \nthe bugs, and a generated test to trigger each bug are available at http://mp.binaervarianz.de/pldi2012. \n 6.3 Annotating Classes as Thread-unsafe Beyond .nding bugs, our analysis can be used to analyze classes \nhaving no documentation on their thread safety and to automat\u00adically annotate these classes as thread-unsafe \nwhere appropriate. In a preliminary study for this work, we found that one of the most common concurrency-related \nquestions of Java developers is whether a particular library class is thread-safe. Few libraries come \nwith precise documentation to answer this question. To ad\u00address this lack of documentation, our analysis \ncan automatically annotate classes as thread-unsafe. Since the oracle is sound, these annotations are \nguaranteed to be correct. To evaluate this usage scenario, we run our analysis on a li\u00adbrary that speci.es \nfor each class whether it is thread-safe or not. The library (Joda-Time) contains 41 classes, of which \n33 are docu\u00admented as thread-safe and eight are documented as thread-unsafe. The lower part of Table \n1 summarizes the results. For seven of the eight thread-unsafe classes, our analysis detects a thread \nsafety problem. The missing class, ZoneInfoCompiler, reads .les from the .le system, transforms them, \nand writes other .les as output.  class SharedPoolDataSource { void setDataSourceName(String v) { key \n= InstanceKeyObjectFactory .registerNewInstance(this); } void close() { InstanceKeyObjectFactory.removeInstance(key); \n} } class InstanceKeyObjectFactory { static final Map instanceMap = new HashMap(); synchronized static \nString registerNewInstance(SharedPoolDataSource ds) { // iterate over instanceMap } static void removeInstance(String \nkey) { // BUG: unsynchronized access to instanceMap instanceMap.remove(key); } } (a) Supposedly thread-safe \nclass. SharedPoolDataSource ds1 = new SharedPoolDataSource(); ds1.setConnectionPoolDataSource(null); \n Thread 1 Thread 2  dataSource.setDataSourceName(\"a\"); dataSource.close(); Result: ConcurrentModi.cationException \nin Thread 1 (b) Execution of a generated concurrent test exposing a thread-safety bug. Figure 5: Concurrency \nbug in Apache Commons DBCP. Since the thread-safety oracle does not check the integrity of such .les, \nit cannot detect problems caused by concurrent usages of the class. For the 33 classes that are documented \nas thread-safe, no problems are found after running the analysis for 24 hours.  6.4 Effort of Using \nthe Analysis Using our approach involves minimal human effort, because the analysis requires the source \ncode or byte code of the classes under test as only input and produces true positives as only output. \nExpe\u00adrience from applying automated bug .nding techniques in industry shows that both properties are \nimportant [3]. The computational effort of our implementation is acceptable for an automatic testing \ntool. Figure 6a shows how long the analysis takes to trigger the problems from Table 1. The horizontal \naxis shows the IDs from Table 1, sorting the classes by the average time required to .nd the problem. \nThe vertical axis gives the minimum, average, and maximum time taken to .nd the problem over ten runs. \nMost of the problems are found within one hour. For several problems, the analysis takes only a few seconds. \nOther classes require several hours of computation time, with up to 8.2 hours for bug 8 (JDK s Logger). \nGiven that the bug remained unnoticed for several years in one of the most popular Java libraries, we \nconsider this time to be still acceptable. Section 5 outlines ways to reduce the running time of our \nimplementation with additional engineering effort. The approach has very moderate memory requirements. \nThe test generator selects methods randomly and therefore does not maintain signi.cant amounts of state. \nIf executing a generated call sequence exceeds the available memory, an exception is thrown and the sequence \nis not extended. (a) Time to trigger a thread-safety problem. (b) Tests generated before triggering \na thread-safety problem. Figure 6: Effort required to trigger a thread-safety problem. A question related \nto running time is how many tests the anal\u00adysis generates and executes before hitting a bug. Figure 6b \nshows the average number of generated tests for each bug, listing the bugs in the same order as in Figure \n6a. For some bugs, a small num\u00adber of tests (several hundreds or even less than hundred) suf.ces to expose \nthe problem. Other bugs require more tests, up to 17 mil\u00adlion for bug 4. A manual inspection of bugs \nrequiring many tests suggests that the task of executing a bug-exposing test with the right thread interleaving \ndominates over the task of generating a bug-exposing test. Combining our work with techniques to control \nscheduling may reduce the number of tests for hitting a bug. 7. Limitations First, the approach assumes \nthat exceptions and deadlocks are un\u00addesirable. We found this implicit speci.cation to be true in prac\u00adtice, \nbut in principle a class could throw exceptions as part of its legal, concurrent behavior. Second, the \napproach has limited sup\u00adport for multi-object bugs. Although the generated tests combine multiple classes \nand objects, they only reveal bugs triggered by concurrent calls to the same object. Third, the approach \nis limited to bugs that manifest through an exception or deadlock, and there\u00adfore it may miss more subtle \nproblems leading to incorrect but not obviously wrong results. 8. Related Work 8.1 Finding Concurrency \nBugs Table 2 compares this work with other bug .nding techniques based on four criteria: whether static \nor dynamic analysis is used, the Approach Input Output Correctness criterion  P PT PTS B BF DR Atom \nDL Crash Other [15, 32, 36, D . . . . . . . . . . 42, 49] [8] SD . . . . . . . . . . [44] D . . . . . \n. . . . . [2, 14, 21, D . . . . . . . . . . 29, 39, 48] [16, 45] D . . . . . . . . . . [28, 38] D . . \n. . . . . . . . [34] S . . . . . . . . . . [25] D . . . . . . . . . . [26] D . . . . . . . . . . [51] \nD . . . . . . . . . . [13, 18] D . . . . . . . . . . [5, 24, 31] D . . . . . . . . . . [7, 17] D . . \n. . . . . . . . [52] SD . . . . . . . . . . This work D . . . . . . . . . . Table 2: Comparison with \nexisting static (S) and dynamic (D) ap\u00adproaches. Input: program (P), program and tests (PT), or program, \ntests, and speci.cations (PTS). Output: bugs (B) or bugs and false positives (BF). Correctness criterion: \ndata race (DR), atomicity vi\u00adolations (Atom), deadlock (DL), crash, or other. input and output of the \nanalysis, and the correctness criterion. The unique feature of our work is to require only a program \nas input. Data Races Dynamic data race detectors search for unsynchro\u00adnized, con.icting accesses to shared \ndata by analyzing happens\u00adbefore relations [15, 32], by checking whether the program fol\u00adlows a locking \ndiscipline [42, 49], or by a combination of both techniques [36]. Our approach detects data races, if \nthey manifest through an exception or a deadlock. Atomicity Violations Analyses for .nding atomicity \nviolations rely on speci.cations of atomic blocks or of sets of atomic vari\u00adable accesses, provided manually \n[16, 38, 45] or inferred heuris\u00adtically [2, 14, 21]. Inference causes false positives when violat\u00ading \nsource code is not supposed to be atomic. Our analysis detects atomicity violations, if they lead to \nan exception or a deadlock. Deadlocks Naik et al. [34] search deadlocks statically but require tests. \nJoshi et al. [26] model check a reduced program and rely on annotations of condition variables. Both \nanalyses report false positives. Our analysis .nds deadlocks triggered by generated tests. Active Testing \nTo avoid false positives, active testing validates potential bugs by controlling the scheduler to provoke \nan exception or a deadlock. The approach has been applied to data races [44], atomicity violations [28, \n38], deadlocks [25], and memory-related concurrency bugs [51]. Our approach shares the idea of reporting \nproblems only if a certainly undesired situation occurs but does not rely on manually written tests. \nLinearizability Herlihy and Wing introduce linearizability as a correctness criterion for concurrent \nobjects [22]. Line-Up [5] checks the linearizability of calls but requires manually speci.ed method parameters. \nAs shown in Figure 1, unusual parameters that a human may miss can trigger long-standing bugs. Line-Up \nexe\u00adcutes all linearizations before running a concurrent test, whereas our oracle analyzes linearizations \nonly if the test fails. Elmas et al. [13] and Fonseca et al. [17] propose linearizability-based analy\u00adses \nthat require speci.cations to abstract the state of a component. Other Correctness Criteria Gao et al. \n[18] search for typestate errors in multi-threaded programs and rely on typestate speci.ca\u00adtions. Joshi \net al. [27] .lter false warnings from verifying concur\u00adrent programs by using a sequential version of \na program as an oracle for the concurrent program. The approach relies on formal speci.cations and tests. \nOther approaches check for violations of inferred invariants [24, 31, 46] or unusual orderings [52]. \nThe price paid for not relying on explicit speci.cations are false positives.  8.2 Support for Finding \nConcurrency Bugs Several techniques control the thread scheduling when running a concurrent program repeatedly, \nfor example, based on model checking [10, 33], random scheduling [6, 43], or arti.cial de\u00adlays [12]. \nThese techniques reduce the time to trigger a bug and could enhance the performance of our analysis. \nPugh and Ayewah [41] and Jagannath et al. [23] address the problem of man\u00adually writing concurrent unit \ntests. Our work is orthogonal to theirs, because we generate tests automatically.  8.3 Test Generation \nThis work is inspired by techniques to generate sequential tests, such as [11, 19, 37]. In contrast to \nthem, our test generator creates concurrent tests. Integrating more elaborate test generation tech\u00adniques, \nsuch as learning from observed call sequences [50], into our approach could help to detect complex bugs \nfaster. Ballerina [35] generates ef.cient multi-threaded tests, showing that two threads, each with a \nsingle call, can trigger many concur\u00adrency bugs. The test generator described here is directed towards \ngenerating objects of required types and aims to generate (pre.x, suf.x, suf.x) triples to expose concurrency \nproblems. In addition, Ballerina checks test executions for linearizability (similar to [5]) and therefore \nproduces false positives. 9. Conclusions We present an automatic testing technique to reveal severe bugs \nin thread-safe classes. Using our approach involves very little human effort because it requires neither \ntests nor explicit speci.cations for the classes under test, and because it produces only true positive \nbug reports. The analysis is enabled by two contributions: (1) a technique for generating tests that \nexercise a thread-safe class from multiple threads, and (2) an oracle that reports a bug when a concur\u00adrent \ntest execution results in an exception or a deadlock that cannot occur in any linearized execution of \nthe test. We validate our claims by applying the analysis to six popular Java libraries. The analysis \nreveals 15 bugs in supposedly thread-safe classes, including two previously unknown bugs in the Java \nstandard library. Our technique for generating concurrent tests provides input that can drive other dynamic \nanalyses, which traditionally rely on manually written tests. Generated tests not only add diversity \nto otherwise available tests but also allow for dynamically analyzing classes that have no tests at all. \nAcknowledgments Thanks to Zolt\u00b4an Maj\u00b4o, Albert Noll, Faheem Ullah, and the anony\u00admous reviewers for \ntheir valuable comments. The work presented in this paper was partially supported by the Swiss National \nScience Foundation under grant number 200021-134453. References [1] API documentation of java.lang.StringBuffer \n(Java platform standard edition 6), 2011. [2] C. Artho, K. Havelund, and A. Biere. High-level data races. \nSoftw Test Verif Rel, 13(4):207 227, 2003.  [3] A. Bessey, K. Block, B. Chelf, A. Chou, B. Fulton, S. \nHallem, C. Henri-Gros, A. Kamsky, S. McPeak, and D. R. Engler. A few bil\u00adlion lines of code later: Using \nstatic analysis to .nd bugs in the real world. Commun ACM, 53(2):66 75, 2010. [4] S. Burckhardt and R. \nTan. Private communication, August 2011. [5] S. Burckhardt, C. Dern, M. Musuvathi, and R. Tan. Line-Up: \na complete and automatic linearizability checker. In PLDI, pages 330 340, 2010. [6] S. Burckhardt, P. \nKothari, M. Musuvathi, and S. Nagarakatte. A randomized scheduler with probabilistic guarantees of .nding \nbugs. In ASPLOS, pages 167 178, 2010. [7] J. Burnim, T. Elmas, G. C. Necula, and K. Sen. NDSeq: runtime \nchecking for nondeterministic sequential speci.cations of parallel cor\u00adrectness. In PLDI, pages 401 414, \n2011. [8] J.-D. Choi, K. Lee, A. Loginov, R. O Callahan, V. Sarkar, and M. Srid\u00adharan. Ef.cient and precise \ndatarace detection for multithreaded object-oriented programs. In PLDI, pages 258 269, 2002. [9] I. Ciupa, \nA. Pretschner, A. Leitner, M. Oriol, and B. Meyer. On the predictability of random tests for object-oriented \nsoftware. In ICST, pages 72 81, 2008. [10] K. E. Coons, S. Burckhardt, and M. Musuvathi. GAMBIT: effective \nunit testing for concurrency libraries. In PPOPP, pages 15 24, 2010. [11] C. Csallner and Y. Smaragdakis. \nJCrasher: an automatic robustness tester for Java. Software Pract Exper, 34(11):1025 1050, Sept. 2004. \n[12] O. Edelstein, E. Farchi, Y. Nir, G. Ratsaby, and S. Ur. Multithreaded Java program test generation. \nIBM Syst J, 41(1):111 125, 2002. [13] T. Elmas, S. Tasiran, and S. Qadeer. VYRD: verifying concurrent \nprograms by runtime re.nement-violation detection. In PLDI, pages 27 37, 2005. [14] C. Flanagan and S. \nN. Freund. Atomizer: a dynamic atomicity checker for multithreaded programs. In POPL, pages 256 267, \n2004. [15] C. Flanagan and S. N. Freund. FastTrack: ef.cient and precise dy\u00adnamic race detection. In \nPLDI, pages 121 133, 2009. [16] C. Flanagan, S. N. Freund, and J. Yi. Velodrome: a sound and complete \ndynamic atomicity checker for multithreaded programs. In PLDI, pages 293 303, 2008. [17] P. Fonseca, \nC. Li, and R. Rodrigues. Finding complex concurrency bugs in large multi-threaded applications. In EuroSys, \npages 215 228, 2011. [18] Q. Gao, W. Zhang, Z. Chen, M. Zheng, and F. Qin. 2ndstrike: toward manifesting \nhidden concurrency typestate bugs. In ASPLOS, pages 239 250, 2011. [19] P. Godefroid, N. Klarlund, and \nK. Sen. DART: directed automated random testing. In PLDI, pages 213 223, 2005. [20] B. Goetz, T. Peierls, \nJ. Bloch, J. Bowbeer, D. Holmes, and D. Lea. Java Concurrency in Practice. 2006. [21] C. Hammer, J. Dolby, \nM. Vaziri, and F. Tip. Dynamic detection of atomic-set-serializability violations. In ICSE, pages 231 \n240, 2008. [22] M. Herlihy and J. M. Wing. Linearizability: A correctness condition for concurrent objects. \nACM T Progr Lang Sys, 12(3):463 492, 1990. [23] V. Jagannath, M. Gligoric, D. Jin, Q. Luo, G. Rosu, and \nD. Marinov. Improved multithreaded unit testing. In ESEC/FSE, pages 223 233, 2011. [24] G. Jin, A. V. \nThakur, B. Liblit, and S. Lu. Instrumentation and sampling strategies for cooperative concurrency bug \nisolation. In OOPSLA, pages 241 255, 2010. [25] P. Joshi, C.-S. Park, K. Sen, and M. Naik. A randomized \ndynamic program analysis technique for detecting real deadlocks. In PLDI, pages 110 120, 2009. [26] P. \nJoshi, M. Naik, K. Sen, and D. Gay. An effective dynamic analysis for detecting generalized deadlocks. \nIn FSE, pages 327 336, 2010. [27] S. Joshi, S. K. Lahiri, and A. Lal. Underspeci.ed harnesses and interleaved \nbugs. In POPL, pages 19 30, 2012. [28] Z. Lai, S.-C. Cheung, and W. K. Chan. Detecting atomic-set serial\u00adizability \nviolations in multithreaded programs through active random\u00adized testing. In ICSE, pages 235 244, 2010. \n[29] S. Lu, J. Tucek, F. Qin, and Y. Zhou. AVIO: detecting atomicity violations via access interleaving \ninvariants. In ASPLOS, pages 37 48, 2006. [30] S. Lu, S. Park, E. Seo, and Y. Zhou. Learning from mistakes: \na comprehensive study on real world concurrency bug characteristics. In ASPLOS, pages 329 339, 2008. \n[31] B. Lucia and L. Ceze. Finding concurrency bugs with context-aware communication graphs. In MICRO, \npages 553 563, 2009. [32] D. Marino, M. Musuvathi, and S. Narayanasamy. LiteRace: effective sampling \nfor lightweight data-race detection. In PLDI, pages 134 143, 2009. [33] M. Musuvathi, S. Qadeer, T. Ball, \nG. Basler, P. A. Nainar, and I. Neamtiu. Finding and reproducing Heisenbugs in concurrent pro\u00adgrams. \nIn OSDI, pages 267 280, 2008. [34] M. Naik, C.-S. Park, K. Sen, and D. Gay. Effective static deadlock \ndetection. In ICSE, pages 386 396, 2009. [35] A. Nistor, Q. Luo, M. Pradel, T. R. Gross, and D. Marinov. \nBallerina: Automatic generation and clustering of ef.cient random unit tests for multithreaded code. \nIn ICSE, 2012. [36] R. O Callahan and J.-D. Choi. Hybrid dynamic data race detection. In PPOPP, pages \n167 178, 2003. [37] C. Pacheco, S. K. Lahiri, M. D. Ernst, and T. Ball. Feedback-directed random test \ngeneration. In ICSE, pages 75 84, 2007. [38] C.-S. Park and K. Sen. Randomized active atomicity violation \ndetec\u00adtion in concurrent programs. In FSE, pages 135 145, 2008. [39] S. Park, S. Lu, and Y. Zhou. CTrigger: \nexposing atomicity violation bugs from their hiding places. In ASPLOS, pages 25 36, 2009. [40] H. Patil, \nC. Pereira, M. Stallcup, G. Lueck, and J. Cownie. PinPlay: a framework for deterministic replay and reproducible \nanalysis of parallel programs. In CGO, pages 2 11, 2010. [41] W. Pugh and N. Ayewah. Unit testing concurrent \nsoftware. In ASE, pages 513 516, 2007. [42] S. Savage, M. Burrows, G. Nelson, P. Sobalvarro, and T. E. \nAnderson. Eraser: A dynamic data race detector for multithreaded programs. ACM T Comput Syst, 15(4):391 \n411, 1997. [43] K. Sen. Effective random testing of concurrent programs. In ASE, pages 323 332, 2007. \n[44] K. Sen. Race directed random testing of concurrent programs. In PLDI, pages 11 21, 2008. [45] O. \nShacham, N. Bronson, A. Aiken, M. Sagiv, M. Vechev, and E. Ya\u00adhav. Testing atomicity of composed concurrent \noperations. In OOP-SLA, pages 51 64, 2011. [46] Y. Shi, S. Park, Z. Yin, S. Lu, Y. Zhou, W. Chen, and \nW. Zheng. Do I use the wrong de.nition?: Defuse: de.nition-use invariants for detecting concurrency and \nsequential bugs. In OOPSLA, pages 160 174, 2010. [47] Y. Smaragdakis and C. Csallner. Combining static \nand dynamic reasoning for bug detection. In TAP, pages 1 16, 2007. [48] F. Sorrentino, A. Farzan, and \nP. Madhusudan. PENELOPE: weaving threads to expose atomicity violations. In FSE, pages 37 46, 2010. [49] \nC. von Praun and T. R. Gross. Object race detection. In OOPSLA, pages 70 82, 2001. [50] S. Zhang, D. \nSaff, Y. Bu, and M. D. Ernst. Combined static and dynamic automated test generation. In ISSTA, pages \n353 363, 2011. [51] W. Zhang, C. Sun, and S. Lu. ConMem: detecting severe concurrency bugs through an \neffect-oriented approach. In ASPLOS, pages 179 192, 2010. [52] W. Zhang, J. Lim, R. Olichandran, J. Scherpelz, \nG. Jin, S. Lu, and T. W. Reps. ConSeq: detecting concurrency bugs through sequential errors. In ASPLOS, \npages 251 264, 2011.    \n\t\t\t", "proc_id": "2254064", "abstract": "<p>Concurrent, object-oriented programs often use thread-safe library classes. Existing techniques for testing a thread-safe class either rely on tests using the class, on formal specifications, or on both. Unfortunately, these techniques often are not fully automatic as they involve the user in analyzing the output. This paper presents an automatic testing technique that reveals concurrency bugs in supposedly thread-safe classes. The analysis requires as input only the class under test and reports only true positives. The key idea is to generate tests in which multiple threads call methods on a shared instance of the tested class. If a concurrent test exhibits an exception or a deadlock that cannot be triggered in any linearized execution of the test, the analysis reports a thread safety violation. The approach is easily applicable, because it is independent of hand-written tests and explicit specifications. The analysis finds 15 concurrency bugs in popular Java libraries, including two previously unknown bugs in the Java standard library.</p>", "authors": [{"name": "Michael Pradel", "author_profile_id": "81444603091", "affiliation": "ETH Zurich, Zurich, Switzerland", "person_id": "P3471314", "email_address": "michael@binaervarianz.de", "orcid_id": ""}, {"name": "Thomas R. Gross", "author_profile_id": "81332502168", "affiliation": "ETH Zurich, Zurich, Switzerland", "person_id": "P3471315", "email_address": "thomas.gross@inf.ethz.ch", "orcid_id": ""}], "doi_number": "10.1145/2254064.2254126", "year": "2012", "article_id": "2254126", "conference": "PLDI", "title": "Fully automatic and precise detection of thread safety violations", "url": "http://dl.acm.org/citation.cfm?id=2254126"}