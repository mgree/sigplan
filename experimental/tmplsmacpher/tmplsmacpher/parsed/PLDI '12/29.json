{"article_publication_date": "06-11-2012", "fulltext": "\n Test-Case Reduction for C Compiler Bugs John Regehr Yang Chen Pascal Cuoq University of Utah University \nof Utah CEA LIST regehr@cs.utah.edu chenyang@cs.utah.edu pascal.cuoq@cea.fr Eric Eide Chucky Ellison \nXuejun Yang University of Utah University of Illinois University of Utah eeide@cs.utah.edu celliso2@illinois.edu \njxyang@cs.utah.edu  Abstract To report a compiler bug, one must often .nd a small test case that triggers \nthe bug. The existing approach to automated test-case reduction, delta debugging, works by removing substrings \nof the original input; the result is a concatenation of substrings that delta cannot remove. We have \nfound this approach less than ideal for reducing C programs because it typically yields test cases that \nare too large or even invalid (relying on unde.ned behavior). To obtain small and valid test cases consistently, \nwe designed and implemented three new, domain-speci.c test-case reducers. The best of these is based \non a novel framework in which a generic .xpoint computation invokes modular transformations that perform \nreduction operations. This reducer produces outputs that are, on average, more than 25 times smaller \nthan those produced by our other reducers or by the existing reducer that is most commonly used by compiler \ndevelopers. We conclude that effective program reduction requires more than straightforward delta debugging. \nCategories and Subject Descriptors D.2.5 [Software Engineer\u00ading]: Testing and Debugging testing tools; \nD.3.2 [Programming Languages]: Language Classi.cations C; D.3.4 [Programming Languages]: Processors compilers \nKeywords compiler testing, compiler defect, automated testing, random testing, bug reporting, test-case \nminimization 1. Introduction Although many compiler bugs can be demonstrated by small test cases, bugs \nin released compilers are more typically discovered while building large projects. Before a bug can be \nreported, the circumstances leading to it must be narrowed down. The most important part of this process \nis test-case reduction: the construction of a small input that triggers the compiler bug. &#38;#169; \n2012 Association for Computing Machinery. ACM acknowledges that this con\u00adtribution was authored or co-authored \nby an employee, contractor or af.liate of the national government of France. As such, the government \nof France retains a nonexclu\u00adsive, royalty-free right to publish or reproduce this article, or to allow \nothers to do so, for Government purposes only. PLDI 12, June 11 16, 2012, Beijing, China. Copyright c \n&#38;#169; 2012 ACM 978-1-4503-1205-9/12/06. . . $10.00 The importance of test-case reduction is emphasized \nin the GCC documentation,1 which states that: Our bug reporting instructions ask for the preprocessed \nversion of the .le that triggers the bug. Often this .le is very large; there are several reasons for \nmaking it as small as possible. . . The instructions for submitting bug reports to the LLVM developers \nalso highlight the importance of test-case reduction.2 Indeed, LLVM ships with the Bugpoint tool3 that \nautomates reduction at the level of LLVM IR. The importance that compiler developers place on small test \ncases stems from the simple fact that manual test-case reduction is both dif.cult and time consuming. \nWith limited time to spend .xing bugs, compiler writers require bug reporters to undertake the effort \nof reducing large fault-causing inputs to small ones. Like debugging, distilling a bug-causing compiler \ninput to its essence is often an exercise in trial and error. One must repeatedly experiment by removing \nor simplifying pieces of the input program, compiling and running the partially reduced program, and \nbacktrack\u00ading when a change to the input causes the compiler bug to no longer be triggered. In some cases \nfor example, reducing a deterministic assertion failure in the compiler manual test-case reduction is \nte\u00addious but tractable. In other cases e.g., reducing a miscompilation bug in a large, multi-threaded \napplication manual test-case reduc\u00adtion may be so dif.cult as to be infeasible. Our belief is that many \ncompiler bugs go unreported due to the high dif.culty of isolating them. When confronted with a compiler \nbug, a reasonable compiler user might easily decide that the most economic course is to .nd a workaround, \nand not to be sidetracked by the signi.cant time and effort required to produce a small test case and \nreport the bug. Our goal in this paper is to automate most or all of the work required to reduce bug-triggering \ntest cases for C compilers. Our work is motivated by two problems that we have encountered in applying \nstate-of-the-art reducers. First, these tools get stuck at local minima that are too large. This necessitates \nsubsequent manual reduction, preventing reportable compiler bugs from being generated in an entirely \nautomated fashion. We have developed new reducers that use domain-speci.c knowledge to overcome the barriers \nthat trap previous tools. Second, existing test-case reducers often generate test cases that execute \nunde.ned behaviors. These test cases are useless because the C language standard guarantees 1 http://gcc.gnu.org/bugs/minimize.html \nhttp://gcc.gnu.org/wiki/A_guide_to_testcase_reduction 2 http://llvm.org/docs/HowToSubmitABug.html 3 http://llvm.org/docs/Bugpoint.html \n int printf (const char *, ...); union U5 { short f1; int f3:13; }; const union U5 a = { 30155 }; int \nmain () { printf (\"%d\\n\", a.f1); printf (\"%d\\n\", a.f3); return 0; } Listing 1. Test case that demonstrates \na bug in GCC 4.4.0 nothing about the behavior of such programs. For example, all C/C++ compiler teams \nwe have interacted with will ignore (in the best case) any bug report that depends upon the value of \nan uninitialized local variable. Our new reducers confront this test-case validity problem directly: \nthey avoid unde.ned test-case behaviors during reduction, thereby ensuring that the .nal reduced test \ncases are suitable for bug reporting. Our work is also motivated by Csmith, a random test-case generator \nthat has resulted in more than 400 previously unknown C compiler bugs being reported [17]. Using randomized \ndifferential testing, Csmith automates the construction of programs that trigger compiler bugs. These \nprograms are large out of necessity: we found that bug-.nding was most effective when random programs \naverage size was 81 KB [17, \u00a73.3]. In this paper, we use 98 bug-inducing programs created by Csmith as \nthe inputs to several automated program reducers, including three written by ourselves. Two of the new \nreducers are implemented as Csmith add-ons and can only reduce Csmith-generated programs. However, the \nmost effective reducer (in terms of size of output) that we developed is generic: it can reduce any C \nprogram, whether generated by Csmith or not. In the great majority of cases, one or more of our reducers \ncan distill the large (37 297 KB) test cases created by Csmith into small test cases (typically less \nthan 0.5 KB) that preserve the bug-triggering features of the original inputs. Our reducers do this automatically \nand without introducing unde.ned behavior into the reduced test cases. Our contributions are as follows: \n1. We identify existing delta-debugging algorithms as point so\u00adlutions in a more general framework. We \npresent three new, domain-speci.c test-case reducers for C code that .t into this framework. 2. We identify \nthe test-case validity problem as a crucial part of test-case reduction for compilers of programming \nlanguages that admit unde.ned and unspeci.ed behaviors. This problem has not been acknowledged or solved \nin previous work. We present various solutions to the test-case validity problem. 3. We show that our \nbest reducer produces output more than 25 times smaller than that produced by a line-based delta debugger, \non average.  2. Reporting Compiler Bugs An ideal compiler bug report is based on a small, easy-to-read, \nself-contained, and well-de.ned test program. This paper is about automatically constructing programs \nthat meet these criteria. Other elements found in a good bug report include: the identi.cation of the \nbuggy compiler: its version, its target machine and OS, how it was built, and so on;  instructions for \nreproducing the failure, including a description of how the compiler was invoked; and  the expected \nand actual outputs of the compiled test program (assuming that the compiler does not fail to compile \nthe test). For example, the following report is informative enough that it would likely be acted upon \nby compiler developers: On x86-64, the program in Listing 1 should print: 30155 -2613 However, using \nGCC 4.4.0 (built from scratch) and also GCC Ubuntu 4.4.3-4ubuntu5 (the current vendor-supplied compiler \non Ubuntu 10.04.3 LTS as of Nov 6 2011) on x86-64, we get: $ gcc -O1 small.c $ ./a.out 30155 30155 The \nprogram in Listing 1 is the verbatim output from one of our C program reducers. The underlying problem \nis an actual GCC bug that affects Ubuntu 10.04, a major and currently supported Linux distribution. The \nprogram in Listing 1 is free from unde.ned and unspeci.ed behaviors,4,5 although it does involve implementation-de.ned \nbe\u00adhavior regarding the representations of data objects. Implementation\u00adde.ned behaviors are allowed \nin test cases; indeed, in C, such basic things as the ranges of int and char are implementation-de.ned. \nAlthough the example at hand may seem to involve the technical minutiae of C, it is important for compilers \nto get these details right. Large programs such as operating systems and virtual-machine monitors depend \non subtle behaviors like those executed by Listing 1. Automated test-case reduction, when successful, \nallows one to obtain small test cases that cleanly present the essence of a problem. 3. Background In \nthis section we distinguish test-case minimization from test-case reduction. We also summarize delta \ndebugging, an existing approach to test-case reduction. 3.1 The Test-Case Minimization Problem Let I \nbe the set of all valid inputs to some system under test (SUT). For i . I, let |i| be the size of i according \nto an appropriate metric such as bytes or tokens. Let B . I be the set of inputs that trigger a particular \nfailure of interest in the SUT, e.g., a crash at a particular location in the SUT. The test-case minimization \nproblem for a SUT and a particular failure is to .nd iBmin where iBmin . B and .i . B,|i|=|iBmin|. Note \nthat iBmin may not be unique; there may be several minimum-sized inputs that result in the failure of \ninterest. For the sake of clarity, however, we describe the search for iBmin as if it were unique. 4 \nThe C99 language standard [7] identi.es many program behaviors that are unde.ned or unspeci.ed. An example \nunde.ned behavior is dereferencing a null pointer. When a C program executes an unde.ned behavior, anything \ncan happen : the C standard places no requirements on the C implementation. Unspeci.ed behaviors, on \nthe other hand, permit the compiler to choose from a variety of alternatives with no requirement for \nconsistency. An example unspeci.ed behavior is the order in which the arguments of a function call are \nevaluated. Like C programs in general, good test cases for C compilers must not execute any unde.ned \nbehaviors and must not depend on a particular choice for unspeci.ed behaviors. 5 Footnote 82 in the C99 \nlanguage standard allows a.f3 to be accessed by the second printf() call [7, \u00a76.5.2.3]. This footnote, \nintroduced in TC3, supersedes language in Annex J of the previous C99 standard which states that the \nvalue of a union member other than the last one stored into is unspeci.ed. Subtle interactions between \ndifferent parts of the standard and even outright contradictions, as we see here are not uncommon when \ninterpreting tricky C programs. Consider the task of .nding iBmin given only an initial failing test \ncase iseed . Without knowledge of the internals of the SUT, the only information that iseed provides \nis that it triggers the failure of interest and therefore de.nes a maximum value of |iBmin|. The reason \nthat iseed causes the failure of interest is unknown, and thus in principle, any input that is smaller \nthan iseed may also trigger the failure of interest. The only way to .nd iBmin, which is the absolute \nsmallest failure-inducing input, is exhaustive search. Let I<S be the set of inputs not larger than a \nsize bound S. For realistic systems under test, one can expect that |I<S| is an exponential function \nof S. Finding iBmin requires testing increasingly large members of I until a failure-inducing input is \nfound. Thus, it is easy to see that the test-case minimization problem is intractable unless |iseed | \nis quite small. Consequently, all test-case minimization work that we are aware of is heuristic. An analogy \ncan be made between test-case minimization and compiler optimization. In both situations, the problem \nis to .nd an element in a large set of programs that has a desired property while also minimizing a cost \nfunction. The major difference is that while optimization can be phrased as a relatively concise mathematical \nproblem ( .nd the cheapest machine program that is semantically equivalent to the input program ), test-case \nminimization is con\u00adducted in the absence of an effective semantics: the minimizer lacks a model for \npredicting which inputs will trigger the failure of interest in the SUT. The exact program-optimization \nproblem can be solved for small programs by encoding the meaning of the program mathe\u00admatically and then \npassing the problem to a SAT/SMT solver [8]. In contrast, an analogous solution to the test-case minimization \nprob\u00adlem would require either a brute-force search of I<|iseed | or else a mathematical encoding of the \nentire SUT. Heuristic solutions to the test-case minimization problem start with a failure-inducing input \niseed and transform it. Through repeated transformation and testing, they search for ever-smaller inputs \nthat cause the failure of interest in the SUT. We refer to this process as test-case reduction so as \nto distinguish it from absolute minimization. The goal of a reducer is to create a small test case from \na large one; a reducer R1 can be said to be better than a reducer R2 if, over a given set of test cases, \nR1 consistently produces smaller outputs than R2 does. Our focus in this paper is on high-quality test-case \nreducers for C compilers, i.e., reducing C programs. 3.2 Delta Debugging Although point solutions to \nthe test-case reduction problem have existed for some time (see Section 8), a generic solution was not \nformulated until Zeller and Hildebrandt [18] developed two delta debugging algorithms. The dd algorithm \nseeks to minimize the difference between a failure-inducing test case and a given template; the ddmin \nalgorithm is a special case of dd where the template is empty. Thus, ddmin s goal is to minimize the \nsize of a failure\u00adinducing test case. Ddmin heuristically removes contiguous regions ( chunks ) of the \ntest in order to generate a series of variants. Unsuccessful variants are those that do not trigger the \nsought-after behavior; all unsuccessful variants are discarded. Successful variants, on the other hand, \nare those that trigger the desired behavior. Each successful variant is used as the new basis for producing \nfuture variants; in other words, the search is greedy. When no successful variants can be generated from \nthe current basis, the chunk size is decreased. The algorithm terminates when the chunk size cannot be \nfurther decreased and no more successful variants can be produced. The .nal result is the last successful \nvariant that was produced; by the nature of the search, this is the smallest variant that produces the \ndesired behavior. Ddmin can be fast even for large test cases when it is successful in removing large \nchunks early in its execution. If it cannot remove large input chunks, however, ddmin can take a long \ntime to terminate especially if it is expensive to discriminate between successful and unsuccessful variants. \nDelta debugging was generalized to create hierarchical delta debugging (HDD) [13], in which chunk selection \nis guided by the hierarchical structure of the input. For several failure-inducing C and XSLT programs, \nHDD was shown to signi.cantly reduce reduction time and also produce better results, when compared with \nddmin. McPeak and Wilkerson [12] implemented a variant of ddmin which we refer to as Berkeley delta in \nthis paper that is both well\u00adknown and commonly used by compiler developers. Berkeley delta is generic \nand line-based: all variants are produced by removing one or more contiguous lines from the test input. \nWith the help of a separate utility, called topform.at, Berkeley delta can be used to perform hierarchical \ndelta debugging over program source code. The topform.at utility preprocesses an input test case and \n.attens languages with balanced delimiters, such as most common programming languages, so that all nesting \nbelow a speci.ed depth is on one line. 6 This is simple and effective. 4. Generalized Delta Debugging \nOur observation is that algorithms such as dd, ddmin, and HDD are speci.c instantiations of a simple \nand powerful framework for reducing test cases. Most of the hard-coded aspects of these existing algorithms \ncan be usefully generalized in order to more effectively reduce failure-inducing inputs, including the \nfollowing. Generalized transformations ddmin uses text-oriented chunk re\u00admoval to create variants, and \nHDD uses an AST-oriented removal strategy. The former removes a substring with each search step, and \nthe latter removes a subtree. However, our experience is that reducing a failure-triggering C program \nto a very small size requires a much richer set of transformations such as removing an argument from \na function and simultaneously all its call sites, performing inline substitution of a function body, \nreplacing an aggregate type with its constituent scalars, and so on. These transformations may operate \non many scattered program points in one step, and they cannot be described as operations that simply \ndelete a substring or subtree. Generalized search ddmin s and HDD s search strategies are greedy. This \nis simple and ef.cient but ignores a wealth of research on search that may avoid local minima by being \nnon-greedy or improve search-termination speed by not looking at alternatives that are unlikely to be \npro.table. Additionally, transformations such as inlining the body of a function or splitting up a complex \nexpression may increase code size (by adding references to temporary variables) while ultimately leading \nto better output. A greedy search rules out exploration of these variants, and thus tends to become stuck \nat a local minimum where no further substring or subtree eliminations are possible. Addressing test-case \nvalidity ddmin and related algorithms ignore the test-case validity problem: the fact that in some use \ncases, some variants will be incorrect in ways that are not or cannot be detected by the system under \ntest. This is the case when reducing C programs. For example, when a C compiler is given a program to \ncompile, the compiler cannot in general decide if the program will dereference a null pointer or perform \nan out-of-bounds array access when the program is run. Both are unde.ned behaviors and must not happen \nin a valid compiler test case. Thus, for reducing compiler test cases, a delta-based reducer cannot rely \non the compiler (the system under test) to detect when a variant is invalid. Sophisticated solutions \nare required to overcome this issue. 6 http://delta.tigris.org/using_delta.html  Generalized .tness \nfunctions The goal of ddmin, HDD, and other delta debugging algorithms is to create a minimum-sized failure\u00adinducing \ntest. In general, however, any .tness function can be used to characterize preferable test cases. For \nexample, since the eventual consumer for a reduced test case is a human being, it is undesirable to create \ntiny reduced programs if they are hard to understand. Consider these simple examples. First, almost any \nC program can be made smaller, but harder to read, by eliminating whitespace and playing preprocessor \ntricks. Second, our experience is that turning a union type into a struct can make a test case considerably \neasier to understand while also making it (at least) one byte larger. In summary, generalized delta debugging \nrefers to any iterative optimization strategy for simplifying the circumstances leading to program failure. \nA generalized delta debugger combines a search algorithm, a transformation operator, a validity-checking \nfunction, and a .tness function. 5. Test-Case Validity Ensuring that variants are valid C programs was \nthe most serious problem we faced doing this work. Beyond statically ill-formed C programs, dynamically \ninvalid programs are those that execute an operation with unde.ned behavior or rely on unspeci.ed behavior. \n5.1 The Validity Problem Consider this program: int main (void) { int x; x = 2; return x + 1; } Assume \nthat compiler A emits code that properly returns 3 while compiler B is buggy and generates code returning \na different result. The goal of a test-case reducer is to create the smallest possible program triggering \nthe bug in B. During reduction many variants will be produced, perhaps including this one where the line \nof code assigning a value to x has been removed: int main (void) { int x; return x + 1; } This variant, \nhowever, is not a valid test case. Even if this variant exhibits the desired behavior compilers A and \nB return different results the divergence is potentially due to its reliance on unde.ned behavior: reading \nuninitialized storage. In fact, on a common Linux platform, GCC and Clang emit code returning different \nresults for this variant, even when optimizations are disabled. Because delta debugging is an iterative \noptimization algorithm, once a test-case reduction goes wrong in this fashion, it is likely to remain \nstuck there, abandoning the original sense of the search. Compiler developers are typically most unhappy \nto receive a bug report whose test input relies on unde.ned or unspeci.ed behavior. This is not a hypothetical \nproblem a web page for the Keil C compiler states that Fewer than 1% of the bug reports we receive are \nactually bugs. 7 In this speci.c case we might rede.ne the test-case criterion to be: Compilers A and \nB generate code returning divergent results, and neither compiler warns about using an uninitialized \nvariable. In this case, the solution would likely be successful. On the other hand, compiler warnings \nabout uninitialized storage are typically unsound in the presence of function calls, arrays, and pointers. \nFurthermore, even after we solve this problem, the C99 7 http://www.keil.com/support/bugreport.asp standard \ndescribes 190 more kinds of unde.ned behavior that must be addressed to ensure that a test case is valid. \nAs previously noted, not all of these behaviors are statically detectable by a compiler. Beyond unde.ned \nbehavior, there are also many kinds of unspeci.ed behavior that cause similar problems. In reducing C \nprograms, we have found the most problematic behaviors to be: use before initialization of function-scoped \nstorage;  pointer and array errors;  integer over.ow and shift past bitwidth;  struct and union errors; \nand  mismatches between printf s arguments and format string.  Many languages including C, C++, C# \n(in unsafe code), and Scheme have some form of non-determinism or unspeci.ed behav\u00adior, meaning the test-case \nvalidity problem is generally applicable in other languages. (There is current work toward cataloging \nproblem\u00adatic unde.ned and unspeci.ed behaviors for many languages [14].) Providing a solution to the \ntest-case validity problem for C, with its hundreds of unde.ned and unspeci.ed behaviors, suggests that \nthis can be done for other languages as well. 5.2 Solutions There are two ways to avoid accepting variants \nthat rely on unde.ned and unspeci.ed behavior. First, the test-case reducer can avoid generating incorrect \nvariants. We do not know how to implement such a reducer for general C programs. However, we have created \ntwo reducers that rely on the fact that Csmith already knows how to create conforming C programs [17]. \nThrough extensions to Csmith, we can use Csmith to generate smaller versions of programs it has previously \noutput. The second approach is to blindly generate a mix of valid and invalid variants and then use an \nexternal tool to detect invalid code. Sound, automatic static analyzers for C code have been available \nfor some time, but we know of none that can give a large random program a clean bill of health. To reliably \navoid false positives, a semantics-checking C interpreter is needed. Two of these have recently become \navailable. 5.2.1 KCC KCC [6] is a semantics-based interpreter and analysis tool for C. In addition to \ninterpretation, it is capable of debugging, catching unde.ned behaviors, state space search, and model \nchecking. All of these modes are mechanically generated from a single formal semantics for C. KCC can \ncatch many unde.ned behaviors by virtue of the semantics getting stuck when a program is not well de.ned. \nWhile KCC does not detect all unde.ned behavior, it is capable of catching the behaviors listed in Section \n5.1. No major changes were needed in KCC to make it useful in test\u00adcase reduction. However, we added \nEnglish-language error messages for most of the common unde.ned behaviors, which made it easier to understand \nexactly how variants go wrong. Additionally, we added detectors for some previously-uncaught unde.ned \nbehaviors to the tool because those behaviors were found in variants. Any errors reported by KCC are \nguaranteed to be real errors in the program, under the assumption that the underlying semantics accurately \ncaptures C. 5.2.2 Frama-C Frama-C [5] is an open-source, extensible, static-analysis framework for C. \nIt features a value-analysis plug-in [2]: an abstract interpreter roughly comparable to Polyspace [10] \nand Astr\u00e9e [1]. The value analysis uses non-relational domains adapted to the C language; it soundly \ndetects and warns about a sizable set of C s unde.ned and unspeci.ed behaviors. At the same time, it \nis designed to avoid warning about constructs that are technically unde.ned, but that programmers use \nintentionally, for example in embedded code. Con.icts between these objectives are resolved according \nto the following principle: if a compiler implementer would use the unde.nedness of a construct as a \nreason to not .x a compiler bug, then the value analysis warns about the construct. We were able to \nleverage the fact that programs generated by Csmith are closed they take no external inputs in order \nto avoid pessimism in Frama-C. By inde.nitely deferring joins in the value analysis, Frama-C can effectively \nbe as precise as a C interpreter, propagating a singleton abstract state all the way to the end of the \nprogram. This greatly increased precision comes at a cost of extended analysis time and memory consumption. \nWe added an ef.cient interpreter mode to the value analysis, so as to diagnose terminating closed programs \nwithout the usual memory and time overhead caused by inde.nitely postponed joins. Additionally, we .xed \n[4] several Frama-C bugs that interfered with the correct interpretation of Csmith-generated programs. \n 5.2.3 A Hybrid Solution KCC and Frama-C are capable of detecting subtle dynamic viola\u00adtions of the C \nstandard. They both assume their inputs to be compil\u00adable C programs; however, some of the delta debugging \nalgorithms that we used to reduce C programs (e.g., Berkeley delta) produce variants are not even syntactically \nvalid. Therefore, in practice we employ a hybrid solution for detecting invalid code. First, we com\u00adpile \na variant using any convenient C compiler, rapidly rejecting it if it fails to compile or generates warnings \nthat reliably correspond to misbehavior. Second, we optionally examine the variant using Valgrind and/or \nthe Clang static analyzer, again looking for spe\u00adci.c warnings or errors that reliably indicate incorrect \ncode. Finally, surviving variants are tested using KCC and/or Frama-C. 5.2.4 Validity for Compiler-Crash \nInputs Test cases for compiler-crash bugs where the compiler process returns a non-zero status code to \nthe operating system may have weaker validity requirements than do the test cases for wrong-code bugs. \nAs a matter of implementation quality, a compiler vendor will usually .x a segmentation fault or similar \nproblem even if the crash\u00adinducing test case, for example, uses a variable without initialization. Relaxing \nthe correctness criterion permits crash-inducing inputs to be smaller and to be produced more rapidly. \nWe take advantage of these facts when reducing C programs that cause compiler-crash bugs. 6. New Approaches \nto Test-Case Reduction We implemented three new reducers for C programs. Two of them only work for programs \ngenerated by Csmith, while the third is general-purpose and would work in the reduction of any C program. \n(In fact, it can also be used to reduce C++ programs, though it has not yet been tuned for that purpose.) \nAll three of our reducers adopt Berkeley delta s convention of being parameterized by a test that determines \nwhether a variant is successful or unsuccessful. The test determines if the variant triggers the compiler \nbug and also, if necessary, determines whether it is statically and dynamically valid C code. 6.1 Reduction \nin Csmith by Altering the Random Number Sequence A program generated by Csmith is completely determined \nby a sequence of integers that describes a path through Csmith s decision tree. Usually this sequence \ncomes from a pseudo-random number generator (PRNG), but it does not need to. Our Seq-Reduce test\u00adcase \nreducer bypasses the PRNG in order to generate variants. The result is guaranteed to be a valid C program, \nso no external validity\u00adchecking tool is required. Seq-Reduce s implementation is split between a driver \nand two special-purpose Csmith modes. Together, these components act as a generalized delta-debugging \nloop in which Csmith produces variants and the driver determines whether they are successful or not. \nFirst, the driver launches Csmith with a command telling it to dump the speci.cation of the failure-inducing \ninput to a .le. Next, the driver repeatedly invokes Csmith using a command that tells it to load the \nsaved sequence, modify it randomly, and then dump both the new program and its speci.cation. If the new \nprogram constitutes a successful variant (i.e., it triggers the compiler failure and it is smaller than \nthe previous smallest variant), this becomes the new program speci.cation. Otherwise, Seq-Reduce rolls \nback to the previous successful variant. Seq-Reduce is the only randomized test-case reducer that we \nare aware of. Seq-Reduce has several advantages. First, it has low implemen\u00adtation complexity, adding \nabout 750 lines of code to Csmith; only 30 of these are at all entangled with Csmith s main logic. The \ndriver is 300 lines of Perl. Second, Seq-Reduce is embarrassingly parallel. For example, for the experiments \nin Section 7, we ran it on four cores. The main problem with Seq-Reduce is that it does not do a good \njob reducing programs in cases where the problematic code is generated late in Csmith s execution. Changes \nthat appear near the start of a Csmith program speci.cation tend to perturb Csmith s internal state in \nways that prevent it from emitting desirable variants later on. Additionally, Seq-Reduce has no obvious \ntermination criterion. In practice we use a timeout to terminate Seq-Reduce. 6.2 AST-Based Reduction \nin Csmith Using Run-Time Information Our next reducer, Fast-Reduce, is also based on Csmith. It explores \nthe idea that test-case reduction can bene.t from run-time infor\u00admation. As suggested by its name, Fast-Reduce \nis intended to give fairly good results in as little time as possible. It is structured as an add-on \nto Csmith that can query not only the static structure of the generated program, but also its runtime \nbehavior. Dynamic queries are implemented by instrumenting Csmith s generated code, resulting in machine-readable \noutput when the test case is executed. Fast-Reduce supports a number of transformations; we describe \nthree representative ones. Dead-code elimination Programs generated by Csmith tend to contain a lot of \ndead code. In many cases, dead code can be removed without breaking a test case; Fast-Reduce attempts \nto do so early in its execution because this tends to give good results quickly. First, Fast-Reduce issues \na static query to .nd which basic blocks are (conservatively) reachable from main. Next, it issues a \ndynamic query to discover which reachable blocks are actually executed. If removing dead code all at \nonce results in an unsuccessful variant, Fast-Reduce rolls back the change and attempts to remove dead \ncode piecewise. Exploiting path divergence Some wrong-code bugs affect control .ow: the miscompiled executable \nfollows a different execution path than does a correctly compiled executable. Fast-Reduce uses differential \ntesting to actively look for this kind of divergence while reducing programs because it provides a strong \nclue about the location of the critical piece of code in the test case that triggers miscompilation. \nEffect inlining Removing the body of a large function is one of the biggest wins available to a C program \nreducer. Fast-Reduce can attempt to remove a function even when call sites to the function exist; its \nstrategy is to render the function unnecessary by replacing each call with inline code that has the same \ndynamic effect as the current = original_test_case while (!fixpoint) { foreach t in transformations \n{ state = t::new () while (true) { variant = current result = t::transform (variant, state) if (result \n== stop) break /* variant has behavior of interest and meets validity criterion? */ if (is_successful \n(variant)) current = variant else state = t::advance (current, state) } } } Listing 2. The C-Reduce \nalgorithm function call. First, Fast-Reduce issues a static query to .nd all call sites for the target \nfunction. Second, it selects a call site and issues a dynamic query to record the values of global variables \nbefore and after each execution of that site. (This includes the values of pointer-typed variables.) \nIf the call site is executed multiple times, an arbitrary .nal effect is selected. Fast-Reduce then replaces \nthe call with its effect, generating a variant. This variant, and others generated by performing the \nsame transformation at other call sites and other target functions, are all tested. When the body of \na function .nally becomes unreferenced, Fast-Reduce attempts to remove it. The advantages of Fast-Reduce \nare that it requires no external validity-checking tool and it is very fast. Its primary disadvantage \nis that it does not always provide good results; sometimes it gets stuck quite early. Out of the 3,000 \nlines of C++ comprising Fast-Reduce, about 300 are signi.cantly entangled with Csmith. Fast-Reduce also \nincludes a driver component that orchestrates the reduction; it is about 1,700 lines of Perl. 6.3 A \nModular Reducer Our third new reducer, C-Reduce, exploits the insight that the transformations used to \nconstruct variants do not need to be hard\u00adcoded. C-Reduce invokes a collection of pluggable transformations \nuntil a global .xpoint is reached; pseudocode for C-Reduce is shown in Listing 2. A transformation that \nplugs into C-Reduce is simply an iterator that walks through a test case performing source-to-source \nalter\u00adations. A transformation must implement three functions. The .rst, new, takes no parameters and \nreturns a fresh transformation state object. The second, transform, takes a state object and a path to \na test case; it modi.es the test case in place and returns a status code that is either: ok, indicating \nthat a transformation was performed; or stop, indicating that the transformation has run out of opportu\u00adnities \nfor the test case at hand. The third, advance, takes a state object and a path to a test case; it advances \nthe iterator to the next transformation opportunity. As shown in Listing 2, C-Reduce calls advance only \nupon de\u00adtecting an unsuccessful variant. A successful variant does not require advancing the iterator \nbecause it is assumed that an opportunity for transformation has been eliminated from the transformed \ntest case. This means that for C-Reduce to terminate, it must be the case that (for any initial test \ncase, and for a fresh transformation state) each transformation eventually returns stop under non-deterministic \nchoice between (1) calling advance and leaving the current test case unchanged, and (2) not calling advance \nbut changing the cur\u00adrent test case to be the output of the transformation. Meeting this requirement \nhas been natural for each of the 50+ transformations we have implemented so far. The order in which a \ntransformation iterates through a test case is not speci.ed by C-Reduce; in practice, each transformation \nuses a convenient ordering such as preorder for tree-based passes and line-order for line-based passes. \nAt present, C-Reduce calls .ve kinds of transformations. The .rst includes peephole optimizations that \noperate on a contiguous segment of the tokens within a test case. These include changing identi.ers and \ninteger constants to 0 or 1, removing type quali.ers, removing a balanced pair of curly braces and all \ninterior text, and removing an operator and one of its operands (e.g., changing a+b into a or b). The \nsecond kind of transformation includes those that make localized but non-contiguous changes. Examples \ninclude removing balanced parentheses and curly braces without altering the text inside them, and replacing \na ternary operator (C s ?: construct) with the code from one of its branches. The third is a C-Reduce \nmodule that closely follows Berkeley delta: it removes one or more contiguous lines of text from a test \ncase. The number of lines to remove is initially the number of lines in the test case, and is successively \nhalved until it reaches one line, at which point the test case is reformatted using topform.at. This \ntransformation is 74 lines of Perl whereas Berkeley delta is 383 lines, showing that implementing a transformation \nis considerably easier than implementing an entire delta debugging loop. Fourth, C-Reduce invokes external \npretty-printing commands such as GNU indent. It is important that this kind of tool is called within \nthe delta debugging loop, as opposed to being part of a pre\u00ador post-processing step, because it is not \nunheard of for simple reformatting to turn a failure-inducing test case into one that does not trigger \na compiler bug. The .nal class of transformation was motivated by our observa\u00adtion that to create reduced \nfailure-inducing C programs nearly as small as those produced by skilled humans, a collection of compiler\u00adlike \ntransformations is needed. C-Reduce currently has 30 source\u00adto-source transformations for C code including: \n performing scalar replacement of aggregates;  removing a level of indirection from a pointer-or array-typed \nvariable;  factoring a function call out of a complex expression;  combining multiple, same-typed variable \nde.nitions into a single compound de.nition;  moving a function-scoped variable to global scope;  removing \na parameter from a function and all of its call sites, while adding a variable of the same name and type \nat function scope;  removing an unused function or variable;  giving a function, variable, or parameter \na new, shorter name;  changing a function to return void, and deleting all return statements in it; \n performing inline substitution of small function bodies;  performing copy propagation; and  turning \nunions into structs.  We implemented these using LLVM s Clang front end. We have implemented only one \nperformance optimization in C-Reduce: memoization of the (sometimes quite expensive) test for discriminating \nbetween successful and unsuccessful variants. Redundant tests occur when two or more peephole transformations \nproduce the same output, and they also occur during the .nal iteration of the .xpoint computation which, \nby necessity, performs some redundant tests. Several additional opportunities for speed-up exist, and \nwe intend to implement speed improvements in future work. As shown by the results in Section 7, however, \nautomated test-case reduction with C-Reduce already runs fast enough to be useful as part of an automated \nbug-reporting process. 7. Results This section compares our reducers against each other and against \nBerkeley delta. 7.1 Toward a Corpus of C Programs Triggering Diverse Compiler Bugs To thoroughly evaluate \ntest-case reducers for C compiler bugs, one needs a number of test inputs that trigger compiler-crash \nbugs and wrong-code bugs. Moreover, these test cases should map to a diverse collection of underlying \ndefects. We have observed that some compiler bugs (e.g., a crash while parsing a top-level pragma) lend \nthemselves to easy reduction, whereas others (e.g., a wrong\u00adcode bug in an interprocedural transformation) \nare more dif.cult. We assembled our test corpus by manufacturing a large number of bug-triggering programs \nand then selecting a subset that appear to map to diverse underlying bugs. To .nd bug-triggering programs, \nwe ran Csmith for a few days on a collection of compilers that target x86-64 on Linux. The compilers \nwe used were: LLVM/Clang 2.6 2.9, GCC 3.[2 4].0, GCC 4.[0 6].0, Intel CC 12.0.5, Open64 4.2.4, and Sun \nCC 5.11. From the set of bug-triggering inputs created by Csmith, we selected the members of our bug-triggering \ncorpus by hand. For crash bugs we chose only one test case for each distinct symptom a speci.c assertion \nviolation or similar that a compiler prints while crashing. No obvious heuristic exists for .guring out \nwhich test cases triggering wrong-code bugs map to which underlying bugs, so we simply gathered no more \nthan .ve wrong-code triggers for each compiler that we tested. In the end, we selected 98 test cases: \n57 inputs that each trigger a different compiler crash, and 41 inputs that trigger incorrect code generation. \n 7.2 Evaluating Reducers We ran Berkeley delta and our new reducers on our corpus of bug\u00adtriggering test \ninputs, using a machine with 16 GB of RAM, based on an Intel Core i7-2600 processor, running Ubuntu Linux \n11.10 in 64\u00adbit mode. For these experiments we disabled Linux s address space layout randomization (ASLR) \nfeature, which is intended to thwart certain kinds of malware. ASLR has the side effect of causing some \ncompiler bugs to occur non-deterministically. All test-case reducers that we are aware of (including \nour new ones) operate under the assumption that buggy executions can be detected deterministically. The \ninputs to each reducer Berkeley delta, Seq-Reduce, Fast-Reduce, and C-Reduce are the test case that is \nto be reduced and a shell script that determines whether a variant is successful. Berkeley delta additionally \nrequires a level parameter that speci\u00ad.es how much syntax-driven .attening of its input to perform. The \nweb page for this tool suggests running the main delta script twice at level zero, twice at level one, \ntwice at level two, and .nally twice at level ten. That is what we did. Tables 1 and 2 summarize the \nresults of our reducer experiments. For each test case we measured: The size of the original test case, \nas emitted by Csmith.  The size of the test case after being reduced by Berkeley delta, and the time \ntaken by reduction. For wrong-code bugs, we evaluated Berkeley delta using both KCC and Frama-C as checkers \nfor unde.ned behavior.  int printf (const char *, ...); struct { int f0; int f1; int f2; } a, b = { \n0, 0, 1 }; void fn1 () { a = b; a = a; } int main () { fn1 (); printf (\"%d\\n\", a.f2); return 0; } Listing \n3. The median-sized reduced test case output by C-Reduce with Frama-C for wrong-code bugs. GCC 4.3.0 \nfor x86-64 produces incorrect code with Os. This is W22 in Table 1. The size of the test case after \nbeing reduced by Seq-Reduce with a 20-minute timeout, and the time taken by reduction. (It occasionally \nruns for longer than its nominal timeout when Csmith is slow.) Because Seq-Reduce is embarrassingly parallel, \nwe ran four independent instances of it on our four-way test machine, and upon termination chose the \nbest result.  The size of the test case after being reduced by Fast-Reduce, and the time taken by reduction. \n The size of the test case after being reduced by C-Reduce and the time taken by reduction. For wrong-code \nbugs, again we used both KCC and Frama-C as checkers for unde.ned behavior.  Our choice of metrics \nthe size of the .nal output and the time taken to get it is in.uenced by our belief that these are the \nprimary metrics that people reporting compiler bugs care about. Because our results contain some signi.cant \noutliers, we report both mean and median values at the bottom of each table. 7.3 Analysis of Wrong-Code \nBug Results As Table 1 shows, reducing a test case triggering a wrong-code bug is often fast, but in \na few cases takes many hours. Berkeley delta This tool generally fails to generate test cases that we \nwould include in a compiler bug report as-is. The median run time of Berkeley delta when combined with \nFrama-C is four minutes; with KCC, the median is a little less than an hour. Seq-Reduce On average, Seq-Reduce \ncreates reduced output about twice as large as Berkeley delta s; more reduction would need to be performed \nbefore including these test cases in a compiler bug report. The primary value of Seq-Reduce lies in its \nsimplicity. Also, it serves as a proof of concept for a generalized delta debugger based on randomized \nsearch. Fast-Reduce Fast-Reduce is by far the fastest reducer. However, its .nal output is often too \nlarge to be included in compiler bug reports its median output size is almost 3 KB so further reduction \nmust be performed by hand or by a different automated reducer. C-Reduce C-Reduce is the only reducer \nwe tested that consistently produces results that we would directly copy into a bug report. Listing 3 \nshows the median-sized reduced test case out of the 41 reduced wrong-code outputs produced by C-Reduce \n(for C-Reduce paired with Frama-C). It reasonably approximates the typical Berkeley delta Berkeley delta \nC-Reduce C-Reduce Original with Frama-C with KCC Seq-Reduce Fast-Reduce with Frama-C with KCC ID Compiler \nFlags Size Size Time Size Time Size Time Size Time Size Time Size Time W1 Clang 2.7 O2 58,753 10,745 \n3 10,745 40 16,556 20 49,810 0 295 6 295 64 W2 GCC 3.2.0 O3 54,301 15,153 4 15,153 30 15,717 20 50,200 \n1 179 5 179 42 W3 GCC 3.2.0 O3 62,095 6,624 4 6,624 57 13,860 20 1,230 0 214 6 214 62 W4 GCC 3.3.0 \nO3 54,301 15,153 4 15,153 31 22,410 20 50,200 0 176 5 176 39 W5 GCC 3.3.0 O3 60,010 1,379 1 1,902 54 \n12,948 20 55,908 0 248 5 248 41 W6 GCC 3.3.0 O3 89,036 2,414 2 2,399 47 9,992 20 85,944 0 248 5 248 \n46 W7 GCC 3.4.0 O3 39,489 9,647 2 9,647 23 4,632 20 30,525 0 184 5 184 44 W8 GCC 4.0.0 O3 42,516 1,995 \n5 2,550 91 13,953 20 2,247 1 134 11 134 67 W9 GCC 4.1.0 O1 57,079 1,775 1 1,775 27 41,209 20 586 0 178 \n6 178 28 W10 GCC 4.1.0 O1 81,067 5,789 4 4,044 113 47,841 20 5,299 0 242 9 242 215 W11 GCC 4.1.0 O3 \n50,081 6,559 3 6,498 44 5,730 20 47,057 0 873 11 745 69 W12 GCC 4.1.0 O3 57,028 11,658 3 11,658 32 5,911 \n20 2,124 0 202 27 202 209 W13 GCC 4.1.0 O3 61,119 10,570 7 10,570 114 20,010 20 12,321 1 221 13 221 \n132 W14 GCC 4.2.0 O0 44,078 5,208 2 5,208 21 5,615 20 2,407 0 176 5 176 32 W15 GCC 4.2.0 O0 53,922 \n12,418 4 12,418 33 9,636 20 3,661 3 868 22 868 81 W16 GCC 4.2.0 O0 56,842 15,772 7 13,585 144 7,001 \n20 52,377 0 971 18 971 343 W17 GCC 4.2.0 O1 41,262 8,312 3 8,312 75 5,980 20 36,647 0 205 11 205 153 \nW18 GCC 4.3.0 O0 45,298 7,816 4 7,816 63 10,652 20 6,094 0 196 7 196 79 W19 GCC 4.3.0 O0 55,727 5,975 \n4 5,975 190 17,089 20 903 0 182 9 182 119 W20 GCC 4.3.0 O2 64,349 10,233 9 10,233 88 30,228 20 2,990 \n0 205 10 205 72 W21 GCC 4.3.0 O2 67,227 10,396 6 10,360 209 11,097 20 1,670 0 172 6 172 134 W22 GCC \n4.3.0 Os 96,273 10,689 7 10,814 119 37,327 20 1,961 0 192 12 199 663 W23 GCC 4.4.0 O0 43,030 859 1 \n859 14 1,216 20 384 0 179 1 179 11 W24 GCC 4.4.0 O0 52,278 1,144 1 753 130 1,103 20 393 0 182 1 182 \n73 W25 GCC 4.4.0 O0 65,597 1,108 1 1,108 46 1,119 20 397 0 179 1 179 14 W26 GCC 4.4.0 O2 40,147 4,120 \n2 4,120 13 6,805 20 36,060 0 755 5 755 30 W27 GCC 4.4.0 Os 86,103 3,537 2 3,537 60 7,257 20 801 0 245 \n4 245 53 W28 Intel CC 12.0.5 O2 42,510 13,983 6 13,983 260 18,181 20 33,530 1 187 81 317 2,312 W29 Intel \nCC 12.0.5 Os 38,232 9,756 5 9,756 55 22,635 20 3,007 0 162 12 173 59 W30 Intel CC 12.0.5 fast 48,803 \n2,967 4 2,967 28 9,242 20 2,317 0 185 7 196 31 W31 Intel CC 12.0.5 fast 81,103 6,881 8 6,881 252 56,247 \n20 7,353 1 119 10 130 268 W32 Open64 4.2.4 O2 43,176 1,428 2 1,428 28 1,259 20 376 0 218 4 218 28 W33 \nOpen64 4.2.4 O2 43,384 6,874 3 6,874 82 5,997 20 4,802 0 207 8 207 108 W34 Open64 4.2.4 O2 65,732 3,976 \n4 3,948 77 12,189 20 316 0 216 5 216 91 W35 Open64 4.2.4 O2 79,971 2,512 5 2,687 118 11,165 20 427 0 \n218 6 218 127 W36 Open64 4.2.4 O3 96,008 30,239 11 29,956 279 17,091 20 31,320 11 160 102 160 1,129 \nW37 Sun CC 5.11 xO2 41,597 1,023 1 1,023 5 1,173 20 241 0 148 4 148 11 W38 Sun CC 5.11 xO2 43,176 6,391 \n3 6,391 54 6,109 20 1,767 0 144 8 144 86 W39 Sun CC 5.11 xO2 43,384 7,090 3 7,090 77 5,744 20 2,046 \n0 145 7 145 113 W40 Sun CC 5.11 xO2 69,657 6,025 4 6,025 108 28,710 20 6,340 1 204 13 204 143 W41 Sun \nCC 5.11 xO2 70,793 1,322 1 1,322 18 14,302 20 248 0 145 3 145 21 Mean 58,208 7,256 4 7,174 82 14,462 \n20 15,470 1 258 12 259 182 Median 55,727 6,559 4 6,498 57 11,097 20 2,990 0 192 7 199 72 Table 1. Compiler \nbugs used in the wrong code part of our evaluation. Program sizes are in bytes, and reduction times are \nin minutes. C-Reduce output that might be reported to a compiler developer. The original test case emitted \nby Csmith was 94 KB clearly much too large to be included in any reasonable bug report. C-Reduce s median \nrun time when combined with Frama-C is seven minutes; with KCC it is 72 minutes. In some cases, Berkeley \ndelta or C-Reduce when combined with KCC produces different .nal output than the same tool combined with \nFrama-C. This happens when KCC and Frama-C disagree about the de.nedness of one or more variants. Often, \nthe disagreement is due to a tool timing out; we killed either tool whenever it took more than three \nseconds longer to analyze a variant than it took to analyze the original, unreduced version of the program \nbeing reduced. However, there are also real differences between the sets of programs that these tools \nconsider to be well-de.ned. We investigated these issues and found three classes of root causes. First, \ndifferential testing of KCC and Frama-C revealed a small number of bugs in the tools. (These bugs did \nnot affect the numbers that we report, because we .xed them before running our experiments.) Second, \nC is a language with many extensions and dialects, and sometimes these tools differing goals caused them \nto differently accept non-standard inputs. For example, Frama-C aims for pragmatic compatibility with \nexisting C code, and so it accepts GCC s extended ternary operator which permits the second operand to \nbe omitted: e.g., x?:y. On the other hand, KCC aims for strict standards compliance and rejects this \nconstruct. The third class of differences we found results from genuine corner cases in the standard; \nwe were not always able to resolve these issues even after talking to experts. For example, the C99 standard \nis not entirely clear about the de.nedness of the expression (s.f1=0) + (s.f2=0) when f1 and f2 are bit.elds \nthat may occupy the same byte of storage. 7.4 Analysis of Compiler-Crash Bug Results The general relationships \nbetween the reducers for wrong-code bugs (Table 1) also hold for compiler-crash bugs (Table 2). In terms \nof size of .nal output, Seq-Reduce and Fast-Reduce are worst, Berkeley delta is better, and C-Reduce \nis best. Relative to the reducers performance on test cases that trigger wrong-code bugs, test-case reduction \nfor compiler-crash bugs is faster (C-Reduce, for example, always .nished in less than 20 min\u00adutes) and \nthe reduced test cases are generally smaller. The speed-up is partly due to not having to run the expensive \nvalidity checkers for unde.ned behavior (Section 5.2.4). Also, when the requirement to have a complete \ntest case (including main) is relaxed, test cases can be made smaller, reducing the size of the search \nspace. For our corpus of test cases that trigger compiler-crash bugs, Listing 4 shows the median-sized \nreduced test case output by C-Reduce. The reduced test case is reportable as-is, whereas the corresponding \noriginal test case (C28) was 72 KB.  int **a[][0]; static int ***const b = &#38;a[0][1]; void fn1 (); \nint fn2 () { return ***b; fn1 (); } void fn1 () { **b; } Listing 4. The median-sized reduced test case \noutput by C-Reduce for compiler-crash bugs. GCC 4.0.0 for x86-64 crashes at O2. This is C28 in Table \n2. Orig. Size Reduced Test-Case Size (Tokens) File (Tokens) HDD* Berkeley delta C-Reduce bug.c 277 51 \n61 41 boom7.c 420 19 256 20 cache.c 25,011 58 124 42 Table 3. Comparing HDD*, Berkeley delta, and C-Reduce \n 7.5 Detecting Invalid Variants Our claim is that na\u00efve reducers tend to introduce problematic unde\u00ad.ned \nand unspeci.ed behaviors. In the experiments we performed with our corpus, during every wrong-code reduction \nrun using Berke\u00adley delta and C-Reduce, the reducers encountered variants with unde.ned behavior that \ncould not be detected using compiler warn\u00adings, LLVM/Clang s static analyzer, or Valgrind. However, these \nunde.ned variants were detected by KCC and Frama-C. We performed another experiment in which we reduced \nthe wrong-code test cases utilizing compiler warnings, the LLVM/Clang static analyzer, and Valgrind to \ndetect invalid variants, but not using KCC or Frama-C. In this experiment, 12 of the 41 reduced test \ncases (29%) dynamically executed an unde.ned behavior that would have rendered the test case inappropriate \nfor use in a bug report. This ratio is unacceptably high. In our experience with compiler-bug reporting, \nwe believe that a compiler team would learn to mistrust and ignore a bug submitter after fewer than 12 \ninvalid bug reports. 7.6 Comparison with Hierarchical Delta Debugging Although source code for HDD is \navailable, we were not able to obtain code for its C front end. Therefore we were not able to include \nHDD in our experiments that compare reducers over our corpus of inputs that trigger compiler-crash bugs \nand wrong-code bugs. We did, however, perform a small experiment to compare C-Reduce with previously \nreported HDD results. We compared Berkeley delta and C-Reduce with the results reported by Misherghi \nand Su [13] for reducing three test cases that cause GCC 2.95.2 to crash. (We could not .nd source code \nfor a fourth test case used in their paper.) In particular, we compared Berkeley delta and C-Reduce with \nthe results reported for HDD*, which is the particular algorithm by Misherghi and Su that yields the \nbest results for the three test cases. As in our previous experiments with crash bugs, we did not use \nKCC or Frama-C to check for unde.ned behavior in reduced test cases. This con.guration also creates a \nfair comparison, since HDD* itself does not check for unde.ned behavior in test cases. Table 3 shows \nthe results. For two of the cases, C-Reduce produces smaller output. For boom7.c, C-Reduce s output is \none token larger. A previous version of C-Reduce produced an 18-token output for this case, two smaller \nthan the current version. Our experience is that incidental phase-ordering issues in the reducer (not \nunlike similar issues seen in compilers) can easily cause the .nal reduced output to be a few tokens \nlarger or smaller. We did not compare the execution times of C-Reduce and HDD, but it is safe to assume \nthat the brute-force C-Reduce is considerably slower. 7.7 When Does Reduction Fail? Non-deterministic \nexecution of the system under test can cause test-case reduction to fail. In our experience, the most \ncommon sources of non-determinism are memory-safety bugs interacting with ASLR and resource-exhaustion \nconditions such as timeouts and memory limits. However, even deterministic bugs can be resistant to reduction, \nparticularly when these bugs stem from internal resource limits in a compiler. For example, a bug in \nregister-spilling logic may simply require a large amount of code before it is triggered. Reduction can \nfail in a different sense if the original and reduced test cases trigger different bugs. For crash bugs, \nwe robustly avoid this problem by looking for the speci.c error string that characterizes the compiler \ncrash. Examining the crash string is part of the process of disambiguating successful and unsuccessful \nvariants. In contrast to compiler-crash bugs, wrong-code bugs have no obvious .ngerprint. A pragmatic \napproach is to .x whatever bug happens to be triggered by the reduced test case, and then to check if \nthe original test case still triggers a miscompilation. 8. Related Work Previous work has sought to reduce \nC programs in order to track down compiler defects. Caron and Darnell [3] developed Bug.nd, a tool that \nnarrows wrong-code bug triggers down to a single C .le and .nds the lowest optimization level that triggers \nmiscompilation. Whalley s tool, vpoiso [15], is primarily concerned with isolating the transformation \nthat generates wrong code. However, it also includes functionality to narrow miscompilations down to \na single function in the source program. McKeeman presented a random C program generator for testing \nC compilers [11], including a test\u00ad case reduction tool that operates at a .ner granularity than Bug.nd \nor vpoiso. McKeeman s tool appears to be similar to C-Reduce s peephole passes. An important difference \nbetween previous program reducers and ours is that our reducers address the test-case validity problem. \nTo the best of our knowledge, the problem of maintaining the semantic validity of test cases during reduction \nhas not been previously identi.ed or solved. Our new C program reducers are instances of generalized \ndelta debugging algorithms. Zeller and Hildebrandt [18] developed delta debugging in 2002 and instantiated \nit in the dd and ddmin algorithms. Their main contribution was to abstract the test-case minimization \nproblem away from any speci.c domain. McPeak and Wilkerson s version of ddmin, Berkeley delta [12], reduces \ntest cases at line granularity. For appropriately structured inputs, this technique can be more ef.cient \nthan character-based ddmin. By allowing only whole-line deletions, Berkeley delta reduces the size of \nthe search space; if most lines are semantically independent from each other, variants are also likely \nto be valid test cases. Subsequently, Mish\u00aderghi and Su [13] developed Hierarchical Delta Debugging (HDD), \nwhich reduces tree-structured test cases. Berkeley delta can also reduce tree-structured inputs with \nthe help of its topform.at utility, which reformats block-structured text to match Berkeley delta s line-oriented \nstrategy for producing variants. Permitting a delta de\u00adbugger to exploit the natural hierarchical structure \nfound in some domains leads to much faster reduction times and also to better results. Our new program \nreducers embody new techniques for generating variants, including random perturbation of a program generator \ns state (Seq-Reduce), run-time feedback (Fast-Reduce), and pluggable, non-localized program transformations \n(C-Reduce). In contrast to previous delta-debugging algorithms, Fast-Reduce and C-Reduce implement transformations \nthat may increase the tex\u00adtual size of a test case (e.g., inlining), toward the goal of enabling subsequent \nreductions. Our Fast-Reduce reducer utilizes run-time feedback, whereas our Seq-Reduce and C-Reduce \nimplement brute-force techniques to generate variants. A third approach to program reduction is static \nanalysis. Leitner et al. [9] combined static backward program slicing with delta debugging to reduce \ntest cases that were randomly generated for unit testing Eiffel classes. Program slicing is used as the \n.rst step to narrow down instructions that are responsible for reaching the failure state. This greatly \nimproves the scalability and ef.ciency of subsequent delta debugging. 9. Conclusion Our goal was to take \nlarge C programs that trigger compiler bugs and automatically reduce them to test cases that are small \nenough to be directly inserted into compiler bug reports. Previous program reducers based on delta debugging \nfailed to produce suf.ciently small test cases. Moreover, they frequently produced invalid test cases \nthat rely on unde.ned or unspeci.ed behavior. We developed three new reducers based on a generalized \nnotion of delta debugging, and we evaluated them on a corpus of 98 randomly generated C programs that \ntrigger bugs in production compilers. Over this corpus, our best reduction algorithm achieves the goal \nof producing reportable and valid test cases automatically. Our future plans include the automatic production \nof additional elements of a compiler bug report. Besides the information described in Section 2, it would \nbe useful to automatically determine the .rst broken revision of the compiler and a minimized collection \nof compiler .ags triggering the problem. Better yet, fault-localization techniques could be used to give \ncompiler developers an idea about where in the compiler the bug is likely to be found. Beyond the evaluation \nof new reduction techniques for C, our work provides insights into the nature of test-case reduction. \nFirst, we observed that highly structured inputs make reduction dif.cult; we claim that navigating complex \ninput spaces requires rich and domain-speci.c transformations that are beyond the capabilities of basic \ndelta-debugging searches. Second, we showed that it can be useful to structure a test-case reducer as \na collection of modular reduction transformations whose execution is orchestrated by a .xpoint computation. \nFinally, we identi.ed the test-case validity problem, which must be addressed in testing any system that \nadmits unde.ned or unspeci.ed behaviors. Software Our new reducers are open-source software, available \nfor download at http://embed.cs.utah.edu/creduce/. Acknowledgments We thank Alastair Reid and the anonymous \nPLDI 12 reviewers for their comments on drafts of this paper. Some of our experiments were run on machines \nprovided by the Utah Emulab testbed [16]. This research was supported, in part, by an award from DARPA \ns Computer Science Study Group. Pascal Cuoq was supported in part by the ANR-funded U3CAT project. Chucky \nEllison was supported in part by NSA contract H98230 10 C 0294. References [1] Bruno Blanchet, Patrick \nCousot, Radhia Cousot, J\u00e9r\u00f4me Feret, Laurent Mauborgne, Antoine Min\u00e9, David Monniaux, and Xavier Rival. \nA static analyzer for large safety-critical software. In Proc. of the ACM SIGPLAN 2003 Conf. on Programming \nLanguage Design and Implementation (PLDI), pages 196 207, San Diego, CA, June 2003. [2] G\u00e9raud Canet, \nPascal Cuoq, and Benjamin Monate. A value analysis for C programs. In Proc. of the 9th IEEE Intl. Working \nConf. on Source Code Analysis and Manipulation, pages 123 124, Edmonton, Alberta, Canada, September 2009. \n[3] Jacqueline M. Caron and Peter A. Darnell. Bug.nd: A tool for debugging optimizing compilers. SIGPLAN \nNotices, 25(1):17 22, January 1990. [4] Pascal Cuoq, Benjamin Monate, Anne Pacalet, Virgile Prevosto, \nJohn Regehr, Boris Yakobowski, and Xuejun Yang. Testing static analyzers with randomly generated programs. \nIn Proc. of the 4th NASA Formal Methods Symposium (NFM 2012), Norfolk, VA, April 2012. [5] Pascal Cuoq, \nJulien Signoles, Patrick Baudin, Richard Bonichon, G\u00e9raud Canet, Lo\u00efc Correnson, Benjamin Monate, Virgile \nPrevosto, and Armand Puccetti. Experience report: OCaml for an industrial\u00adstrength static analysis framework. \nIn Proc. of the 14th ACM SIG-PLAN Intl. Conf. on Functional Programming (ICFP), pages 281 286, Edinburgh, \nScotland, 2009. [6] Chucky Ellison and Grigore Ro\u00b8su. An executable formal semantics of C with applications. \nIn Proc. of the 39th Symp. on Principles of Programming Languages (POPL), pages 533 544, Philadelphia, \nPA, January 2012. [7] International Organization for Standardization. ISO/IEC 9899:TC3: Programming Languages \nC, 2007. http://www.open-std.org/ jtc1/sc22/wg14/www/docs/n1256.pdf. [8] Rajeev Joshi, Greg Nelson, and \nYunhong Zhou. Denali: A practical algorithm for generating optimal code. ACM Transactions on Pro\u00adgramming \nLanguages and Systems, 28(6):967 989, November 2006. [9] Andreas Leitner, Manuel Oriol, Andreas Zeller, \nIlinca Ciupa, and Bertrand Meyer. Ef.cient unit test case minimization. In Proc. of the 22nd Intl. Conf. \non Automated Software Engineering (ASE), pages 417 420, Atlanta, GA, November 2007. [10] MathWorks. Polyspace \nserver 8.1 for C/C++, product brochure, 2010. http://www.mathworks.com/products/datasheets/ pdf/polyspace-server-for-c-c++.pdf. \n[11] William M. McKeeman. Differential testing for software. Digital Technical Journal, 10(1):100 107, \nDecember 1998. [12] Scott McPeak and Daniel S. Wilkerson. Delta, 2003. http://delta. tigris.org/. [13] \nGhassan Misherghi and Zhendong Su. HDD: Hierarchical delta debugging. In Proc. of the 28th Intl. Conf. \non Software Engineering (ICSE), pages 142 151, Shanghai, China, May 2006. [14] James W. Moore. ISO/IEC \nJTC 1/SC 22/WG 23: Programming language vulnerabilities. http://grouper.ieee.org/groups/ plv/. [15] David \nB. Whalley. Automatic isolation of compiler errors. ACM Transactions on Programming Languages and Systems, \n16(5):1648 1659, September 1994. [16] Brian White, Jay Lepreau, Leigh Stoller, Robert Ricci, Shashi Gu\u00adruprasad, \nMac Newbold, Mike Hibler, Chad Barb, and Abhijeet Joglekar. An integrated experimental environment for \ndistributed systems and networks. In Proc. of the 5th Symp. on Operating Sys\u00adtems Design and Implementation \n(OSDI), pages 255 270, Boston, MA, December 2002. [17] Xuejun Yang, Yang Chen, Eric Eide, and John Regehr. \nFinding and understanding bugs in C compilers. In Proc. of the ACM SIGPLAN 2011 Conf. on Programming \nLanguage Design and Implementation (PLDI), pages 283 294, San Jose, CA, June 2011. [18] Andreas Zeller \nand Ralf Hildebrandt. Simplifying and isolating failure-inducing input. IEEE Transactions on Software \nEngineering, 28(2):183 200, February 2002.    \n\t\t\t", "proc_id": "2254064", "abstract": "<p>To report a compiler bug, one must often find a small test case that triggers the bug. The existing approach to automated test-case reduction, delta debugging, works by removing substrings of the original input; the result is a concatenation of substrings that delta cannot remove. We have found this approach less than ideal for reducing C programs because it typically yields test cases that are too large or even invalid (relying on undefined behavior). To obtain small and valid test cases consistently, we designed and implemented three new, domain-specific test-case reducers. The best of these is based on a novel framework in which a generic fixpoint computation invokes modular transformations that perform reduction operations. This reducer produces outputs that are, on average, more than 25 times smaller than those produced by our other reducers or by the existing reducer that is most commonly used by compiler developers. We conclude that effective program reduction requires more than straightforward delta debugging.</p>", "authors": [{"name": "John Regehr", "author_profile_id": "81100459621", "affiliation": "University of Utah, Salt Lake City, UT, USA", "person_id": "P3471242", "email_address": "regehr@cs.utah.edu", "orcid_id": ""}, {"name": "Yang Chen", "author_profile_id": "81444601555", "affiliation": "University of Utah, Salt Lake City, UT, USA", "person_id": "P3471243", "email_address": "chenyang@cs.utah.edu", "orcid_id": ""}, {"name": "Pascal Cuoq", "author_profile_id": "81100049170", "affiliation": "CEA LIST, Saclay, France", "person_id": "P3471244", "email_address": "pascal.cuoq@cea.fr", "orcid_id": ""}, {"name": "Eric Eide", "author_profile_id": "81341490043", "affiliation": "University of Utah, Salt Lake City, UT, USA", "person_id": "P3471245", "email_address": "eeide@cs.utah.edu", "orcid_id": ""}, {"name": "Chucky Ellison", "author_profile_id": "81442594500", "affiliation": "University of Illinois, Urbana, IL, USA", "person_id": "P3471246", "email_address": "celliso2@illinois.edu", "orcid_id": ""}, {"name": "Xuejun Yang", "author_profile_id": "81435601120", "affiliation": "University of Utah, Salt Lake City, UT, USA", "person_id": "P3471247", "email_address": "jxyang@cs.utah.edu", "orcid_id": ""}], "doi_number": "10.1145/2254064.2254104", "year": "2012", "article_id": "2254104", "conference": "PLDI", "title": "Test-case reduction for C compiler bugs", "url": "http://dl.acm.org/citation.cfm?id=2254104"}