{"article_publication_date": "06-11-2012", "fulltext": "\n RockSalt: Better, Faster, Stronger SFI for the x86 * Greg Morrisett Gang Tan Joseph Tassarotti Harvard \nUniversity Lehigh University Harvard University greg@eecs.harvard.edu gtan@cse.lehigh.edu tassarotti@college.harvard.edu \nJean-Baptiste Tristan Harvard University tristan@seas.harvard.edu Abstract Software-based fault isolation \n(SFI), as used in Google s Native Client (NaCl), relies upon a conceptually simple machine-code analysis \nto enforce a security policy. But for complicated archi\u00adtectures such as the x86, it is all too easy \nto get the details of the analysis wrong. We have built a new checker that is smaller, faster, and has \na much reduced trusted computing base when compared to Google s original analysis. The key to our approach \nis automat\u00adically generating the bulk of the analysis from a declarative de\u00adscription which we relate \nto a formal model of a subset of the x86 instruction set architecture. The x86 model, developed in Coq, \nis of independent interest and should be usable for a wide range of machine-level veri.cation tasks. \nCategories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation General \nTerms security, veri.cation Keywords software fault isolation, domain-speci.c languages 1. Introduction \nNative Client (NaCl) is a new service provided by Google s Chrome browser that allows native executable \ncode to be run di\u00adrectly in the context of the browser [35]. To prevent buggy or ma\u00adlicious code from \ncorrupting the browser s state, leaking informa\u00adtion, or directly accessing system resources, the NaCl \nloader checks that the binary code respects a sandbox security policy. The sand\u00adbox policy is meant to \nensure that, when loaded and executed, the untrusted code (a) will only read or write data in speci.ed \nsegments of memory, (b) will only execute code from a speci.ed segment of memory, disjoint from the data \nsegments, (c) will not execute a speci.c class of instructions (e.g., system calls), and (d) will only \n* This research was sponsored in part by NSF grants CCF-0915030, CCF\u00ad0915157, CNS-0910660, CCF-1149211, \nAFOSR MURI grant FA9550-09\u00ad1-0539, and a gift from Google. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 12, June 11 16, 2012, Beijing, China. \nCopyright c &#38;#169; 2012 ACM 978-1-4503-1205-9/12/06. . . $10.00 Edward Gan Harvard University egan@college.harvard.edu \ncommunicate with the browser through a well-de.ned set of entry points. Ensuring the correctness of the \nNaCl checker is crucial for pre\u00adventing vulnerabilities, yet early versions had bugs that attackers could \nexploit, as demonstrated by a contest that Google ran [23]. A high-level goal of this work is to produce \na high-assurance checker for the NaCl sandbox policy. Thus far, we have managed to con\u00adstruct a new NaCl \nchecker for the 32-bit x86 (IA-32) processor (mi\u00adnus .oating-point) which we call RockSalt. The RockSalt \nchecker is smaller, marginally faster, and easier to modify than Google s original code. Furthermore, \nthe core of RockSalt is automatically generated from a higher-level speci.cation, and this generator \nhas been proven correct with respect to a model of the x86 using the Coq proof assistant [8]. We are \nnot the .rst to address assurance for SFI using formal methods. In particular, Zhao et al. [36] built \na provably correct ver\u00adi.er for a sandbox policy similar to NaCl s. Speci.cally, building upon a model \nof the ARM processor in HOL [11], they constructed a program logic and a provably correct veri.cation \ncondition gener\u00adator, which when coupled with an abstract interpretation, generates proofs that assembly \ncode respects the policy. Our work has two key differences: First, there is no formal model for the subset \nof x86 that NaCl supports. Consequently, we have constructed a new model for the x86 in Coq. We believe \nthat this model is an important contribution of our work, as it can be used to validate reasoning about \nthe behavior of x86 machine code in other contexts (e.g.,for veri.ed compilers). Second, Zhao et al. \ns approach takes about 2.5 hours to check a 300 instruction program, whereas RockSalt checks roughly \n1M in\u00adstructions per second. Instead of a general-purpose theorem prover, RockSalt only relies upon a \nset of tables that encode a determinis\u00adtic .nite-state automaton (DFA) and a few tens of lines of (trusted) \nC code. Consequently, the checker is extremely fast, has a much smaller run-time trusted computing base, \nand can be easily inte\u00adgrated into the NaCl runtime. 1.1 Overview This paper has two major parts: the \n.rst part describes our model of the x86 in Coq and the second describes the RockSalt NaCl checker and \nits proof of correctness with respect to the model. The x86 architecture is notoriously complicated, \nand our frag\u00adment includes a parser for over 130 different instructions with se\u00admantic de.nitions for \nover 70 instructions1. This includes support for operands that include byte and word immediates, registers, \nand complicated addressing modes (e.g., scaled index plus offset). Fur\u00adthermore, the x86 allows pre.x \nbytes, such as operand size over\u00adride, locking, and string repeat, that can be combined in many dif\u00adferent \nways to change the behavior of an instruction. Finally, the instruction set architecture is so complex, \nthat it is unlikely that we can produce a faithful model from documentation, so we must be able to validate \nour model against implementations.  To address these issues, we have constructed a pair of domain\u00adspeci.c \nlanguages (DSLs), inspired by the work on SLED [28] and .-RTL [27] (as well as more recent work [10, \n17]), for specifying the semantics of machine architectures, and have embedded those languages within \nCoq. Our DSLs are declarative and reasonably high-level, yet we can use them to generate OCaml code that \ncan be run as a simulator. Furthermore, the tools are architecture independent and can thus be re-used \nto specify the semantics of other machine architectures. For example, one of the undergraduate co-authors \nconstructed a model of the MIPS architecture using our DSLs in just a few days. The Decoder DSL provides \nsupport for specifying the transla\u00adtion from bits to abstract syntax in a declarative fashion. We were \nable to take the tables from Intel s manual [12] and use them to directly construct patterns for our \ndecoder. Our embedding of the Decoder DSL includes both a denotational and operational seman\u00adtics, and \na proof of adequacy for the two interpretations. We use the denotational semantics for proving important \nproperties about the decode stage of execution, and the operational semantics for execution validation. \nThe RTL (register transfer list) DSL is a small RISC-like core language parameterized by a notion of \nmachine state. The RTL library includes an executable, small-step operational semantics. Each step in \nthe semantics is speci.ed as a (pure) function from machine states to machine states. We give meaning \nto x86 instruc\u00adtions by translating their abstract syntax to appropriate sequences of RTL instructions, \nsimilar to the way that a modern processor works. Reasoning about RTL is much easier than x86 code, as \nthe number of instructions is smaller and orthogonal. In what follows, we describe our DSLs and how they \nwere used to construct the x86 model. We also describe our framework for validating the model against \nexisting x86 implementations. We then describe the NaCl sandbox policy in detail, and the new RockSalt \nchecker we have built to enforce it. Next, we describe the actual veri.cation code and the proof of correctness. \nFinally, we close with a discussion of related work, future directions, and lessons learned.  2. A \nCoq Model of the x86 Our Coq model of the x86 instruction set architecture has three major stages: (1) \na decoder that translates bytes into abstract syn\u00adtax for instructions, (2) a compiler that translates \nabstract syntax into sequences of RTL instructions, (3) an interpreter for RTL in\u00adstructions. The interface \nbetween the .rst two components is the de.nition of the abstract syntax, which is speci.ed using a set \nof inductive datatype de.nitions that are informally sketched in Fig\u00adure 1. 2.1 The Decoder Speci.cation \nThe job of the x86 model s decoder is to translate bytes into ab\u00adstract syntax. We specify the translation \nusing generic grammars constructed in a domain-speci.c language, which is embedded into 1 Some instructions \nhave numerous encodings. For example, there are four\u00adteen different opcode forms for the ADC instruction, \nbut we count this as a single instruction. Register reg ::= EAX | ECX | EDX | \u00b7\u00b7\u00b7 Segment Reg. sreg ::= \nES | CS | SS | \u00b7\u00b7\u00b7 Scale scale ::= 1 | 2 | 4 | 8 Operand op ::= int32 | reg int32 \u00d7 option reg \u00d7 option(scale \n\u00d7 reg) Instruction i ::= AAA | AAD | AAM | AAS | ADC(bool \u00d7 op1 \u00d7 op2) | ADD(bool \u00d7 op1 \u00d7 op2) | AND(bool \n\u00d7 op1 \u00d7 op2) | \u00b7\u00b7\u00b7 Figure 1. Some De.nitions for the x86 Abstract Syntax Definition CALL_p : grammar \ninstr := \"1110\" $$ \"1000\" $$ word @ (fun w => CALL true false (Imm_op w) None) || \"1111\" $$ \"1111\" $$ \next_op_modrm2 \"010\" @ (fun op => CALL true true op None) || \"1001\" $$ \"1010\" $$ halfword $ word @ (fun \np => CALL false false (Imm_op (snd p)) (Some (fst p))) || \"1111\" $$ \"1111\" $$ ext_op_modrm2 \"011\" @ (fun \nop => CALL false true op None). Figure 2. Parsing Speci.cation for the CALL instruction Coq. The language \nlets users specify a pattern and associated se\u00admantic actions for transforming input strings to outputs \nsuch as abstract syntax. Our pattern language is limited to regular expres\u00adsions, but the semantic actions \nare arbitrary Coq functions. Figure 2 gives an example parsing speci.cation we use for the CALL instruction. \nAt a high-level, this grammar speci.es four alter\u00adnatives that can build a CALL instruction. Each case \nincludes a pat\u00adtern specifying literal sequences of bits (e.g., 1110 ), followed by other components \nlike word or modrm2 that are themselves gram\u00admars that compute values of an appropriate type. The @ separates \nthe pattern from a Coq function that can be used to transform the values returned from the pattern match. \nFor example, in the .rst case, we take the word value and use it to build the abstract syntax for a version \nof the CALL instruction with an immediate operand. We chose to specify patterns at the bit-level, instead \nof the byte\u00adlevel, because this avoids the need to introduce or reason about shifts and masks in the \nsemantic actions. Furthermore, we were able to take the tables from the Intel IA-32 instruction manual \nand translate them directly into appropriate patterns. Our decoding speci.cations take advantage of Coq \ns notation mechanism, as well as some derived forms to make the grammar readable, but these are de.ned \nin terms of a small set of construc\u00adtors given by the following type-indexed datatype: Inductive grammar \n: Type . Type | Char: char . grammar char | Any: grammar char | Eps: grammar unit | Cat:.T1 T2,grammar \nT1 . grammar T2 . grammar (T1*T2) | Void: .T, grammar T | Alt: .T, grammar T . grammar T . grammar T \n| Star: .T, grammar T . grammar (list T) | Map: .T1 T2, (T1 . T2) . grammar T1 . grammar T2 A value of \ntype grammar T represents a relation between lists of chars2 and semantic values of type T. Alternatively, \nwe can think of the grammar as matching an input string and returning a set of associated semantic values. \nFormally, the denotation of a grammar 2 Grammars are parameterized by the type char.  is the least relation \nover strings and values satisfying the following equations: [[Char c]] = {(c :: nil,c)} [[Any]] = {(c \n:: nil,c)} c [[Eps]] = {(nil, tt)} [[Void]] = \u00d8 [[Alt g1 g2]] = [[g1]] . [[g2]] [[Cat g1 g2]] = {((s1s2), \n(v1,v2)) | (si,vi) . [[gi]]} [[Map fg]] = {(s, f(v)) | (s, v) . [[g]]} [[Star g]] = [[Map (. . nil) Eps]] \n. [[Map (::) (Cat g (Star g))]] Thus, Char c matches strings containing only the character c, and returns \nthat character as the semantic value. Similarly, Any matches a string containing any single character \nc, and returns c. Eps matches only the empty string and returns tt (Coq s unit). The grammar Void matches \nno strings and thus returns no values. When g1 and g2 are grammars that each return values of type T \n, then the grammar Alt g1 g2 matches a string s if either g1 matches s or g2 matches s. It returns the \nunion of the values that g1 and g2 associate with the string. Cat g1 g2 matches a string if it can be \nbroken into two pieces that match the sub-grammars. It returns a pair of the values computed by the grammars. \nStar matches zero or more occurrences of a pattern, returning the results as a list. The last constructor, \nMap, is our constructor for semantic ac\u00adtions. When g is a grammar that returns T1 values, and f is a \nfunc\u00adtion of type T1 . T2,then Map fg is the grammar that matches the same set of strings as g, but transforms \nthe outputs from T1 values to T2 values using f. If a grammar forgoes the use of Map,then the semantic \nvalues represent a parse tree for the input. Map makes it possible to incrementally transform the parse \ntree into alternate semantic values, such as abstract syntax. As noted above, we use Coq s notation mechanism \nto make the grammars more readable. In particular, the following table gives some de.nitions for the \nnotation used here: g1 || g2 := Alt g1 g2 g1 $ g2 := Cat g1 g2 g @ f := Map fg g1 $$ g2 := (g1 $ g2) \n@ snd We encode the denotational semantics in Coq using an induc\u00adtively de.ned predicate, which makes \nit easy to symbolically rea\u00adson about grammars. For example, one of our key theorems shows that our top-level \ngrammar, which includes all possible pre.xes and all possible integer instructions, is deterministic: \n(s, v1) .[[x86grammar]] . (s, v2) .[[x86grammar]] =.v1 = v2 This helps provide some assurance that in \ntranscribing the grammar from Intel s manual, we have not made a mistake. In fact, when we .rst tried \nto prove determinism, we failed because we had .ipped a bit in an infrequently used encoding of the MOV \ninstruction, causing it to overlap with another instruction.  2.2 The Decoder Implementation While the \ndenotational speci.cation makes it easy to reason about grammars, it cannot be directly executed. Consequently, \nwe de.ne a parsing function which, when given a record representing a ma\u00adchine state, fetches bytes from \nthe address speci.ed by the program counter and attempts to match them against the grammar and build \nthe appropriate instruction abstract syntax. Our parsing function is de.nedbytakingthe derivative of \nthe x86grammar with respect to the sequence of bits in each byte, and then checking to see if the resulting \ngrammar accepts the empty string. The notion of derivatives is based on the ideas of Brzozowski [4] and \nmore recently, Owens et al. [24] and Might et al. [22]. Reasoning about derivatives is much easier in \nCoq than attempting to transform grammars into the usual graph-based formalisms, as we need not worry \nabout issues such as naming nodes, equivalence on graphs, or induction principles for graphs. Rather, \nall of our computation and reasoning can be done directly on the algebraic datatype of grammars. Semantically, \nthe derivative of a grammar g with respect to a character c is the relation: derivc g = {(s, v) | (c \n:: s, v) . [[g]]} That is, derivc g matches the tail of any string that starts with c and matches g. \nFortunately, calculating the derivative, including the appropriate transformation on the semantic actions, \ncan be written as a straight\u00adforward function: derivc Any = Map (. .c) Eps derivc (Char c)= Map (. .c) \nEps derivc (Alt g1 g2)= Alt (derivc g1)(derivc g2) derivc (Star g)= Map (::) (Cat(derivc g)(Star g)) \nderivc (Cat g1 g2)= Alt(Cat (derivc g1) g2) (Cat (null g1)(derivc g2)) derivc (Map fg)= Map f (derivc \ng) derivc g = Void otherwise where null g is de.ned as: null Eps = Eps null (Alt g1 g2)= Alt (null g1)(null \ng2) null (Cat g1 g2)= Cat (null g1)(null g2) null (Star g)= Map (. . nil) Eps null (Map fg)= Map f (null \ng) null g = Void otherwise Effectively, deriv strips off a leading pattern that matches c,and adjusts \nthe grammar with a Map so that it continues to calculate the same set of values. If the grammar cannot \nmatch a string that starts with c, then the resulting grammar is Void.The null function returns a grammar \nequivalent to Eps when its argument accepts the empty string, and Void otherwise. It is used to calculate \nthe derivative of a Cat, which is simply the chain-rule for derivatives. Once we calculate the iterated \nderivative of the grammar with respect to a string of bits, we can extract the set of related seman\u00adtic \nvalues by running the extract function, which returns those semantic values associated with the empty \nstring: extract Eps = {tt} extract (Star g)= {nil} extract (Alt g1 g2)=(extract g1) . (extract g2) extract \n(Cat g1 g2)= {(v1,v2) | vi . extract gi} extract (Map fg)= {f(v) | v . extract g} extract g = \u00d8 otherwise \nTo be reasonably ef.cient, it is important that we optimize the grammar as we calculate derivatives. \nIn particular, when we build a grammar, we always use a set of smart constructors, which are functions \nthat perform local reductions, including: Cat g Eps . g Cat Eps g . g Cat g Void . Void Cat Void g . \nVoid Alt g Void . g Alt Void g . g Star (Star g) . Star g Alt gg . g Of course, the optimizations must \nadd appropriate Maps to adjust the semantic actions. Proving the optimizations correct is an easy exercise \nusing the denotational semantics. Unfortunately, the last of these optimizations (Alt gg . g) cannot \nbe directly implemented as it demands a decidable notion of equality for grammars, yet our grammars include \narbitrary Coq functions (and types). To work around these problems, we .rst translate grammars to an \ninternal form, where all types and functions are replaced with a name that we can easily compare. An \nenvironment is used to track the Machine locations  loc ::= PC | EAX | \u00b7\u00b7\u00b7 | CF | \u00b7\u00b7\u00b7 | SS | \u00b7\u00b7\u00b7 Local \nvariables x, y, z . identi.er Arithmetic operators op ::= add | xor | shl |\u00b7\u00b7\u00b7 Comparison operators cmp \n::= lt | eq | gt RTL instructions rt ::= x := yop z | x := ycmp z | x := imm | x := load loc | store \nloc x | x := Mem[y] | Mem[x]:= y | x := choose | \u00b7\u00b7\u00b7 Figure 3. The RTL Language mapping from names back \nto their de.nitions, and is consulted in the extract function to build appropriate semantic values. In \nthe end, we get a reasonably ef.cient parser that we can extract to executable OCaml code. Furthermore, \nwe prove that the parser, when given a grammar g and string s, produces a (.nite) set of values {v1, \n\u00b7\u00b7\u00b7 ,vn} such that (s, vi) . [[g]].Since we have proven that our instruction grammar is deterministic, \nwe know that in fact, we will get out at most one instruction for each sequence of bytes that we feed \nto the parser. Finally, we note that calculating derivatives in this fashion cor\u00adresponds to a lazy, \non-line construction of a deterministic .nite\u00adstate transducer. Our ef.cient NaCl checker, described \nin Section 3 is built from a deterministic .nite-state automaton (DFA) generated off-line, re-using the \nde.nitions for the grammars, derivatives, etc. in the parsing library.  2.3 Translation To RTL After \nparsing bytes into abstract syntax, we translate the corre\u00adsponding instruction into a sequence of RTL \n(register transfer list) operations. RTL is a small RISC-like language for computing with bit-vectors. \nThe language abstracts over an architecture s de.nition of machine state, which in the case of the x86 \nincludes the various kinds of registers shown in Figure 1 as well as a memory, repre\u00adsented as a .nite \nmap from addresses to bytes. Internally, the lan\u00adguage supports a countably in.nite supply of local variables \nthat can be used to hold intermediate bit-vector values. The RTL instruction set is sketched in Figure \n3 and includes standard arithmetic, logic, and comparison operations for bit vec\u00adtors; operations to \nsign/zero-extend and truncate bit vectors; an op\u00aderation to load an immediate value into a local variable; \noperations to load/store values in local variables from/to registers; operations to load and store bytes \ninto memory; and a special operation for non-deterministically choosing a bit-vector value of a particular \nsize. We use dependent types to embed the language into Coq and ensure that only bit-vectors of the appropriate \nsize are used in in\u00adstructions. For each x86 constructor, we de.ne a function that translates the abstract \nsyntax into a sequence of RTL instructions. The translation is encapsulated in a monad that takes care \nof allocating fresh local variables, and that allows us to build higher-level operations out of sequences \nof RTL commands. Figure 4 presents an excerpt of the translation of the ADD in\u00adstruction. The ADD constructor \nis parameterized by a pre.x record, a boolean mode, and two operands. The pre.x record records mod\u00adi.ers \nincluding any segment, operand, or address override. The boolean mode is set when the default operand \nsize is to be used Definition conv ADD prefix mode op1 op2 := let load := load op prefix mode in let \nset := set op prefix mode in let seg := get segment op2 prefix DS op1 op2 in zero . load Z size1 0; up \n. load Z size1 1; p0 . load seg op1; p1 . load seg op2; p2 . arith add p0 p1; set seg p2 op1;; b0 . \ntest lt zero p0; b1 . test lt zero p1; b2 . test lt zero p2; b3 . arith xor b0 b1; b3 . arith xor up \nb3; b4 . arith xor b0 b2; b4 . arith and b3 b4; set flag OF b4;; ... Figure 4. Translation Speci.cation \nfor the ADD instruction (i.e., 32-bits) and cleared when the operand size is set to a byte. The operands \ncan be registers, immediate values, or effective ad\u00addresses. The .rst two local de.nitions specialize \nthe load and store RTL to the given pre.x and mode. The third de.nition selects the appropriate segment. \nNext, we load constant expressions 0 and 1 (of bit-size 1) into local variables zero and up. Then we \nfetch the bit-vector values from the operands and store them in local variables p0 and p1. At this point, \nwe actually add the two bit\u00advectors and place the result in local variable p2. Then we update the machine \nstate at the location speci.ed by the .rst operand. Afterwards, we set the various .ag registers to hold \nthe appropriate 1-bit value based on the outcome of the operation. Here, we have only shown the code \nneeded to set the over.ow (OF) .ag. Occasionally, the effect of an operation, particularly on .ags, is \nunder-speci.ed or unclear. To over-approximate the set of possible behaviors, we use the choose operation, \nwhich non\u00addeterministically selects a bit-vector value and stores this value in the appropriate location. \n 2.4 The RTL Interpreter Once we have de.ned our decoder and translation to RTL, we need only give a \nsemantics to the RTL instructions to complete the x86 model. One option would be to use a small-step \noperational seman\u00adtics for modeling RTL execution, encoded as an inductive predi\u00adcate. However, this \nwould prevent us from extracting an executable interpreter which we need for validation. Instead, we \nencode a step in the semantics as a function from RTL machine states to RTL machine states. RTL machine \nstates record the values of the various x86 locations, the memory, and the values of the local variables. \nTo support the non-determinism in the choose operation, the RTL machine state includes a stream of bits \nthat serves as an oracle. Whenever we need to choose anew value, we simply pull bits from the oracle \nstream. Of course, when reasoning about the behavior of instructions, we must consider all possible oracle \nstreams. This is a standard trick for turning a non\u00addeterministic step relation into a function. Most \nof the operations are simple bit-vector computations for which we use the CompCert integer bit-vector \nlibrary [16]. Con\u00adsequently, the de.nition of the interpreter is fairly straightforward and extracts \nto reasonable OCaml code that we can use for testing.  2.5 Model Validation Any model of the x86 is \ncomplicated enough that it undoubtably has bugs. The only way we can gain any con.dence is to test it \nagainst real x86 processors (and even they have bugs!). As de\u00adscribed above, we have carefully engineered \nour model so that we can extract an executable OCaml simulator from our Coq de.ni\u00adtions. We use this \nsimulator to compare against an actual x86 pro\u00adcessor. One challenge in validating the simulator is extracting \nthe ma\u00adchine state from the real processor. We use Intel s Pin tool [18] to insert dynamic instrumentation \ninto a binary. The instrumentation dumps the values of the registers to a .le after each instruction, \nand the values in memory after each system call. We then take the original binary and run it through \nour OCaml simulator, comparing the values of the registers after the RTL sequence for an instruction \nhas been generated and interpreted. Unfortunately, this procedure sometimes generates false positives \nbecause of our occasional use of the oracle to handle unde.ned or under speci.ed behaviors. We use two \ndifferent techniques to generate test cases to exer\u00adcise the simulator. First, we generate small, random \nC programs us\u00ading Csmith [34] and compile them using GCC.In this way, we sim\u00adulated and veri.ed over \n10 million instruction instances in about 60 hours on an 8 core intel Xeon running at 2.6Ghz. However, \nthis technique does not exercise instructions that are avoided by compilers, and even some common instructions \nhave encodings that are rarely emitted by assemblers. For example, our previously discussed bug in the \nencoding of the MOV instruction was not uncovered by such testing because it falls in this category. \nA more thorough technique is to fuzz test our simulator by gen\u00aderating random sequences of bytes, which \nhas previously proved effective in debugging CPU emulators [19]. Using our generative grammar, we randomly \nproduce byte sequences that correspond to instructions we have speci.ed. This lets us exercise unusual \nforms of all the instructions we de.ne. For instance, an instruction like add with carry comes in fourteen \ndifferent .avors, depending on the width and types of the operands, whether immediates are sign\u00adextended, \netc. Fuzzing such an instruction guarantees with some probability that all of these forms will be exercised. \n 3. The RockSalt NaCl Checker Recall that our high level goal is to produce a checker for Native Client, \nwhich when given an x86 binary image, returns true only when the image respects the sandbox policy: when \nexecuted, the code will only read/write data from speci.ed contiguous segments in memory, will not directly \nexecute a particular set of instructions (e.g., system calls), and will only transfer control within \nits own image or to a speci.ed set of entry points in the NaCl run-time. The 32-bit x86 version of NaCl \ntakes advantage of the segment registers to enforce most aspects of this policy. In particular, by setting \nthe CS (code), DS (data), SS (stack), and GS (thread-local) segment registers appropriately, the machine \nitself will ensure that data reads and writes are contained in the data segments, and that jumps are \ncontained within the code segment. However, we must make sure that the untrusted instructions do not \nchange the values of the segment registers, nor override the segments inappropriately. At .rst glance, \nit appears suf.cient to simply parse the binary into a sequence of instructions, and check that each \ninstruction in the sequence preserves the values of the segment registers and does not override the segment \nregisters with a pre.x. Unfortunately, this simple strategy does not suf.ce. The problem is that, since \nthe x86 has variable length instructions, we must not only consider the parse starting at the .rst byte, \nbut all possible parses of the image. While most programs will respect the initial parse, a malicious \nor buggy program may not. For example, in a program that has a buffer overrun, a return address may be \noverwritten by a value that points into the middle of an instruction from the original parse. To avoid \nthis problem, NaCl provides a modi.ed compiler that rewrites code to respect a stronger alignment policy, \nfollowing the ideas of McCamant and Morrisett [20]. The alignment policy requires that all computed jumps \n(i.e., jumps through a register) are aligned on a 32-byte boundary. This is ensured by inserting code \nto mask the target address with an appropriate constant, and by inserting no-ops so that potential jump \ntargets are suitably aligned. In more detail, the aligned, sandbox policy requires that: 1. Starting \nwith the .rst byte, the image parses into a legal se\u00adquence of instructions that preserve the segment \nregisters; 2. Every 32nd byte is the beginning of an instruction in our parse; 3. Every indirect jump \nthrough a register r is immediately pre\u00adceded by an instruction that masks r so that it is 32-byte aligned; \n 4. The masking operation and jump are both contained within a 32-byte-aligned block of instructions; \n 5. Each direct jump targets the beginning of an instruction and that instruction is not an indirect \njump.  Requirements 4 and 5 are needed to ensure that the code cannot jump over the masking operation \nthat protects an indirect jump. 3.1 Constructing a NaCl Checker Google s NaCl checker is a hand-written \nC program that is intended to enforce the aligned, sandbox policy. Their checker partially decodes the \nbinary, looking at .elds such as the op-codes and mod/rm bits to determine whether the instruction is \nlegal, and how long it is. Two auxiliary data structures are used: One is a bit-map that records which \naddresses are the starts of instructions. Each time an instruction is parsed, the corresponding bit for \nthe address of the .rst byte is set. The other is an array of addresses for forward, direct jumps. After \nchecking that the instructions are legal, the bit\u00admap is checked to ensure that every 32nd byte is the \nstart of an instruction. Then, the array of direct jump targets is checked to make sure they are valid \naccording to the policy above. There are two disadvantages with Google s checker: it is dif.\u00adcult to \nreason about because it is somewhat large (about 600 state\u00adments of code)3 and the process of partial \ndecoding is intertwined with policy enforcement. In particular, it is dif.cult to tell what instructions \nare supported and with what pre.xes, and even more dif.cult to gain assurance that the resulting code \nenforces the ap\u00adpropriate sandbox policy. Furthermore, it is dif.cult to modify the code to e.g., add \nnew kinds of safe instructions or combinations of pre.xes. In contrast, the RockSalt checker we constructed \nand veri.ed is relatively small, consisting of only about 80 lines of Coq code. This is because the checker \nuses table-driven DFA matching to handle the aspects of decoding, following an idea .rst proposed by \nSeaborn [31]. The basic idea is to break all instructions into four categories: (1) those that perform \nno control-.ow, and are easily seen as okay; (2) those that perform a direct jump we must check that \nthe target is a valid instruction; (3) those that perform an indirect jump we must check that the destination \nis appropriately masked; and (4) those instructions that should be rejected. Each of these classes, except \nthe third one, can be described using a simple regular expression. The third class can be captured by \na regular expression if we make the restriction that the masking operation must occur directly before \nthe jump, which in practice is what the NaCl compiler does. 3 To be fair, this includes CPU identi.cation \nand support for .oating-point and other instructions that we do not yet handle.  1. Bool verifier(DFA \n*NoControlFlow, 2. DFA *DirectJump, DFA *MaskedJump, 3. uint8_t *code, uint size) 4. { 5. uint pos \n= 0, i, saved_pos; 6. Bool b = TRUE; 7. valid = (uint8_t *)calloc(size,sizeof(uint8_t)); 8. target \n= (uint8_t *)calloc(size,sizeof(uint8_t)); 9. 10. while (pos < size) { 11. valid[pos] = TRUE; 12. \nsaved_pos = pos; 13. if (match(MaskedJump,code,&#38;pos,size)) continue; 14. if (match(NoControlFlow,code,&#38;pos,size)) \ncontinue; 15. if (match(DirectJump,code,&#38;pos,size) &#38;&#38; 16. extract(code,saved_pos,pos,target)) \ncontinue; 17. free(target); free(valid); 18. return FALSE; 19. } 20. 21. for (i = 0; i < size; ++i) \n 22. b = b &#38;&#38; ( !(target[i]) || valid[i] ) &#38;&#38; 23. ( i &#38; 0x1F || valid[i] ); 24. \n 25. free(target); free(valid); 26. return b; 27. }  Figure 5. Main Routine of our NaCl Checker It \nis possible to extract OCaml code from our Coq de.nitions and use that as the core of the checker, but \nwe elected to manually translate the code into C so that it would more easily integrate into the NaCl \nrun-time. This avoids adding the OCaml compiler and run-time system to the trusted computing base, at \nthe risk that our translation to C may have introduced an error. However, at under 100 lines of C code, \nwe felt that this was a reasonable risk, since the vast majority of the information is contained in the \nDFA tables which are automatically generated and proven correct. Of course, one could try to use a veri.cation \ntool, such as Frama-C/WP [9] or VCC [7], to prove the correctness of this version, in which case the \nfunctional code in Coq could serve as a speci.cation. Figure 5 shows the C code for the high-level veri.er \nroutine. This function relies upon two sub-routines, match and extract that we will explain later, but \nintuitively handle the aspects of decoding. Like Google s checker, the routine uses two auxiliary arrays: \nthe valid array records those addresses in the code that are valid jump destinations, whereas the target \narray records those addresses that are jumped to by some direct control-.ow operation. We used byte arrays \ninstead of bit arrays to avoid having to reason about shifts and masks to read/write bits. The main loop \n(line 10) iterates through the bytes in the code starting at position 0. This position is marked as valid \nand then we attempt to match the bytes at the current position against three pat\u00adterns. The .rst pattern, \nMaskedJump, matches only when the bytes specify a mask of register r followed immediately by an indirect \njump or call through r. Note that a successful match increments the position by size which records the \nlength of the instruction(s), whereas a failure to match leaves the position unmodi.ed. The sec\u00adond pattern, \nNoControlFlow, matches only when the bytes spec\u00adify a legal NaCl instruction that does not affect control \n.ow (e.g., an arithmetic instruction). The third pattern, DirectJump matches only when the bytes specify \na direct JMP, Jcc or CALL instruction. The routine extract then extracts the destination address of the \njump, and marks that address in the target array. If none of these cases match, then the checker returns \nFALSE indicating that an ille\u00adgal sequence of bytes was found in the code. 1. Bool match(DFA *A, uint8_t \n*code, 2. uint *pos, uint size) 3. { 4. uint8_t state = A->start; 5. uint off = 0; 6. 7. while \n(*pos + off < size) { 8. state = A->table[state][code[*pos + off]]; 9. off++; 10. if (A->rejects[state]) \nbreak; 11. if (A->accepts[state]) { 12. *pos += off; 13. return TRUE; 14. } 15. } 16. return FALSE; \n 17. }  Figure 6. The DFA match routine After the main loop terminates, we must check that (a) if an \naddress is the target of a direct jump, then that address is the beginning of an instruction in our parse \n(line 22), and (b) if an address is aligned on a 32-byte boundary, then that address is the beginning \nof an instruction in our parse (line 23). The process of matching a sequence of bytes against a pattern \nis handled by the routine match which is shown in Figure 6. The function simply executes the transitions \nof a DFA using the bytes at the current position in the code. The DFA has four .elds: a starting state, \na boolean array of accepting states, a boolean array of rejecting states, and a transition table that \nmaps a state and byte to a new state.  3.2 DFA Generation What we have yet to show are the de.nitions \nof the DFAs for the MaskedJump, NoControlFlow,and DirectJump patterns, and the correctness of our checker \nhinges crucially upon these de.nitions. These are generated from within Coq using higher-level speci.ca\u00adtions. \nIn particular, for each of the patterns, we specify a gram\u00admar re-using the parsing DSL described in \nSection 2.1, and then compile that grammar to appropriate DFA tables. For example, the grammar for a \nMaskedJump is given below: Definition nacl_MASK_p (r: register) := \"1000\" $$ \"0011\" $$ \"11\" $$ \"100\" \n$$ bitslist (register_to_bools r) $ bitslist (int_to_bools safeMask). Definition nacl_JMP_p (r: register) \n:= \"1111\" $$ \"1111\" $$ \"11\" $$ \"100\" $$ bitslist (register_to_bools r). Definition nacl_CALL_p (r: register) \n:= \"1111\" $$ \"1111\" $$ \"11\" $$ \"010\" $$ bitslist (register_to_bools r). Definition nacljmp_p (r: register) \n:= nacl_MASK_p r $ (nacl_JMP_p r || nacl_CALL_p r). Definition nacljmp_mask := nacljmp_p EAX || nacljmp_p \nECX || nacljmp_p EDX || nacljmp_p EBX || nacljmp_p EBP || nacljmp_p ESI || nacljmp_p EDI. The nacl MASK \np function takes a register name and generates a pattern for an AND r, safeMask instruction. The nacl \nJMP p and nacl CALL p functions take a register and generate patterns for a jump or call instruction \n(respectively) through that register. Thus, nacljmp mask and the top-level grammar match any combination \nof a mask and jump through the same register (excluding ESP).     We compile grammars to DFAs from \nwithin Coq as follows: First, we strip off the semantic actions from the grammars so that we are left \nwith a regular expression r0. This regular expression corresponds to the starting state of the DFA. We \nuse the null rou\u00adtine to check if this is an accepting state and a similar routine to check for rejection, \nand record this in a table. We then calculate the derivative of r0 with respect to all 256 possible input \nbytes. This yields a set of regular expressions {r1,r2, \u00b7\u00b7\u00b7 ,rn}. Each ri corresponds to a state in the \nDFA that is reachable from r0.We as\u00adsign each regular expression a state, and record whether that state \nis an accepting or rejecting state. We continue calculating deriva\u00adtives of each of the ri with respect \nto all possible inputs until we no longer create a new regular expression. The fact that there are a \n.nite number of unique derivatives (up to the reductions performed by our smart constructors) was proven \nby Brzozowski [4] so we are ensured that the procedure terminates. In practice, calculating a DFA in \nthis fashion is almost as good as the usual construction [24], but avoids the need to formalize and reason \nabout graphs. The degree to which we simplify regular expressions as we calculate derivatives determines \nhow few states are left in the resulting DFA. In our case, the number of states is small enough (61 for \nthe largest DFA) that we do not need to worry about further minimization.  3.3 Testing the C Checker \nIn the following section, we discuss the formal proof of correctness for the Coq version of the RockSalt \nchecker. But as noted above, in practice we expect to use the C version, partially shown in .gures 5 \nand 6. Although this code is a rather direct translation from the Coq code, to gain further assurance, \nwe did extensive testing, comparing both positive and negative examples against Google s original checker. \nFor testing purposes, the ncval (Native Client Validator) com\u00admand line tool was modi.ed so that our \nveri.cation routine can be used instead of Google s. We ensured that both veri.ers reject a set of hand-crafted \nunsafe programs, and we also ensured that they both accept a set of benchmark programs once processed \nby the NaCl version of GCC which inserts appropriate no-ops and mask instructions. To work around the \nlack of .oating-point support in our checker, we use the -msoft-.oat .ag so that GCC avoids gen\u00aderating \n.oating-point instructions. The benchmark programs were drawn from the same set as used in CompCert [16] \nand include an implementation of AES, SHA1, a virtual machine, fractal compu\u00adtation, a Perl interpreter, \nand 16 other programs representing more than 4,000 lines of code. We also used Csmith [34] to automatically \ngenerate C programs, and compiled them with NaCl s version of GCC. We then veri.ed that our driver and \nGoogle s always agreed on a program s safety. Using this method we have veri.ed over two thousand small \nC programs. Finally, we measured the time it takes to check binaries using both our C checker and Google \ns original code. For the small benchmarks mentioned above, there was no measurable difference in checking \ntimes. However, on an arti.cially generated C program of about 200,000 lines of code, running on a 2.6 \nGHz Intel Xeon core, Google s checker took 0.90 seconds and our checker took 0.24 seconds (averaging \nover one hundred runs). Consequently, we believe that RockSalt is competitive with Google s approach. \n 4. Proof of Correctness for the Checker After building and testing the checker, we wanted to prove \nits correctness with respect to the sandbox policy. That is, we wanted a proof that if the checker returns \nTRUE for a given input binary, and if that binary is loaded and executed in an appropriate environment \n(in particular, where the code and data segments are disjoint), then executing the binary would ensure \nthat only the prescribed data segments are read and written, and control only transfers within the prescribed \ncode segment. At a high-level, our proof shows that at every step of the pro\u00adgram execution, the values \nof the segment registers are the same as those in the initial state, and furthermore, that the bytes \nthat make up the code-segment are the same bytes that were analyzed by the checker. These invariants \nare suf.cient to show NaCl s sandbox policy is not violated. Furthermore, the checker should have ruled \nout system calls and other instructions that are not allowed. But of course, formalizing this argument \nrequires a much more detailed set of invariants that connect the matching work done in the checker to \nthe semantics, along with the issues of alignment, masking, and jump-destination checks. We begin by \nde.ning the notion of an appropriate machine state: DEFINITION 1. A machine state is appropriate when: \n1. the original data and code segments are disjoint, 2. the DS, SS, and GS segment registers point to \ntheir respective original segments, 3. the CS segment registers point to the original code segment, \n 4. the program counter points within the code segment, and 5. the original bytes of the program are \nstored in the code segment.  Appropriateness captures the key data invariants that we need to maintain \nthroughout execution of the program. We augment these data invariants with a predicate on the program \ncounter to reach the de.nition of a locally-safe machine state: DEFINITION 2. A machine state is locally-safe \nwhen it is appro\u00adpriate and the program counter holds an address corresponding to the start of an instruction \nthat was matched by the verify process using one of the three generated DFAs. In other words, for a locally \nsafe state, the pc is marked as valid. We would like to argue that, starting from a locally-safe state, \nwe can always execute an instruction and end up in a locally\u00adsafe state. This would imply that the segment \nregisters have not changed, that the code has not changed, that any read or write done by the instruction \nwould be limited to the original data segments, and that control remains within the original code segment. \nAlas, we do not immediately reach a locally-safe state after ex\u00adecuting one instruction. The problem \nis that our MaskedJump DFA operates over two instructions (the mask of the register, followed by the \nindirect jump). Thus, we introduce the notion of a k-safe state: DEFINITION 3. An appropriate state s \nis k-safe when k> 0 and, for any s' such that s -. s', either s' is locally-safe or s' is (k - 1)-safe. \nWith the de.nitions given above, it suf.ces to show that if a state is locally-safe, then it is also \nk-safe for some k (and in fact, k is either 1 or 2). Indeed, each locally-safe state s should be k-safe \nfor some k:if s -. s' then either s' is locally-safe or we executed the mask of a MaskedJump and we should \nbe in an appropriate state, ready to execute a branch instruction that will target a masked (and therefore \nvalid) address. Then, assuming the computation starts in a locally-safe state (e.g., with the pc at any \nvalid address), it is easy to see that the code cannot step to a state where the segment registers have \nchanged, or the bytes in the code segment have changed. THEOREM 1. If s is locally-safe, then it is also \nk-safe for some k. Since a locally-safe instruction has a program counter drawn from the set of valid \ninstructions, and since the veri.er did not return FALSE, we can conclude that a pre.x of the bytes starting \nat this address matches one of the three DFAs. We must then argue that for each class of instructions \nthat match the DFAs, after executing the instruction, we either end up in a locally-safe state or else \nafter executing one more instruction, end up in a locally safe-state.  In the Section 4.1, we sketch \nthe connection we formalized be\u00adtween the DFAs and a set of inversion principles that characterize the \npossible instructions that they can match. These principles allow us to do a case analysis on a subset \nof the possible instructions. For example, in the case that the MaskedJump DFA matches, we know that \nthe bytes referenced by the program counter must decode into a masking operation on some register r, \nfollowed by bytes that de\u00adcode into a jump or call to register r. The proof proceeds by case analysis \nfor each of the three DFAs utilizing these inversion princi\u00adples. The easiest (though largest) case is \nwhen the NoControlFlow DFA has the successful match. We prove three properties for each non-control-.ow \ninstruction I that the inversion principle gives us: (1) executing I does not modify segment registers; \n (2) executing I modi.es only the data segments memory; (3) after executing I, the new program counter \nis equal to the old program counter plus the length of I.  For the most part, arguing these cases is \nsimple: For the .rst property, we simply iterate over the generated list of RTLsfor I and ensure there \nare no writes to the segment registers. The second property follows from the inversion principles which \nforbid the use of a segment override pre.x, and the third property follows from the semantics of non-control-.ow \ninstructions. From these three facts, it follows that after executing the instruction, we are immediately \nin a locally-safe state. That is, the original state was 1-safe. In the case where I was matched by DirectJump,we \nmust argue that the .nal loop in verify ensures that the target of the jump is valid. Of course, we must \nalso show that the segment registers are preserved, the code is preserved, etc. But then we can again \nargue that the original state was 1-safe. For the MaskedJump case, we must argue that the state is 2-safe. \nThe inversion principle for the DFA restricts the .rst instruction to an AND of a particular register \nr with a constant that ensures after the step, the value of r is aligned on a 32-byte boundary, the segments \nare preserved, and the pc points to bytes within the code segment that decode into either a jump or call \nthrough r.We then argue that this state is 1-safe. Since the destination of the jump or call is 32-byte \naligned, the .nal loop of the veri.er has checked that this address is valid. Consequently, it is easy \nto show that we end up in a locally-safe state. 4.1 Inverting the DFAs A critical piece in our proof \nof correctness is the relation\u00adship between the DFAs generated from the NoControlFlow, DirectJump,and \nMaskedJump regular expressions and our seman\u00adtics for machine instructions. We sketch the key results \nthat we have proven here. One theorem speci.es the connection between a regular expres\u00adsion, the DFA \nit generates, and the match procedure: THEOREM 2. If r is a regular expression, and D is the DFA gener\u00adated \nfrom that regular expression, then executing match on D with a sequence of bytes b1,...,bn will return \ntrue if there is some j = n such that the string b1,...,bj is in the denotation of r. The theorem requires \nproving that our DFA construction pro\u00adcess, where we iteratively calculate all derivatives, produces \na well\u00adformed DFA with respect to r. Here, a well-formed DFA basically provides a mapping from states \nto derivatives of r that respect certain closure properties. Fortunately, the algebraic construction \nof the DFA makes proving this result relatively straightforward. The theorem also requires showing that \nrunning match on D with b1,...,bn is correct which entails, among other things, showing that the array \naccesses are in bounds, and that when we return TRUE, we are in a state that corresponds to the derivative \nof the regular ex\u00adpression with respect to the string b1,...,bj . Another key set of lemmas show that \nthe languages accepted by the regular expressions are subsets of the languages accepted by our x86grammar. \nAdditionally, we must prove an inversion princi\u00adple for each regular expression that characterizes the \npossible ab\u00adstract syntax we get when we run the semantics on the bytes. For example, we must show that \nDirectJump only matches bytes that when parsed, produce either (near) JMP, Jcc,or CALL instructions with \nan immediate operand. Fortunately, proving the language con\u00adtainment property and inversion principles \nis simple to do using the denotational semantics for grammars. One of the most dif.cult properties to \nprove about the decoder was the uniqueness of parsing. In particular, we needed to show that each bit \npattern corresponded to at most one instruction, and no instruction s bit pattern was a pre.x of another \ninstruction s bit pattern i.e., that our x86grammar was unambiguous. A naive approach, where we simply \nexplore all possible bit patterns is obviously intractable, when there are instructions up to 15 bytes \nlong. Another approach is to construct a DFA for the grammar and then show that each accepting state \nhas at most one semantic value associated with it. While this is possible, the challenge is getting Coq \nto symbolically evaluate the DFA construction and reduce the semantic actions in a reasonable amount \nof time4. Consequently, we constructed a simple procedure that checks whether the intersection of two \ngrammars is empty. The procedure, which only succeeds on star-free grammars (stripped of their se\u00admantic \nactions) works by generalizing the notion of a derivative from characters to star-free regular expressions: \nDeriv g Eps = g Deriv g (Char c)= derivc g Deriv g Any = DrvAny g Deriv g Void = Void Deriv g (Alt g1 \ng2)= Alt (Deriv gg1)(Deriv gg2) Deriv g (Cat g1 g2)= Deriv (Deriv gg1) g2 where DrvAny Any = Eps DrvAny \n(Char c)= Eps DrvAny Eps = Void DrvAny Void = Void DrvAny (Alt g1 g2)= Alt (DrvAny g1)(DrvAny g2) DrvAny \n(Cat g1 g2)= Alt (Cat (DrvAny g1) g2) (Cat (null g1)(DrvAny g2)) When it is de.ned, it is easy to show \nthat: Deriv g1 g2 = {s2 |.s1.s1 . g2 . s1s2 . g1} and thus, when Deriv g1 g2 . Void, we can conclude \nthat there is no string in the intersection of the domains of g1 and g2, and furthermore, g2 s strings \nare not a pre.x of those in g1.This allowed us to easily prove (through Coq s symbolic evaluation) that \nthe x86grammar is unambiguous: We simply recursively descend into the grammar, and each time we encounter \nan Alt, check that the intersection of the two sub-grammars is empty.  5. Related Work With the growing \ninterest in veri.cation of software tools, formal models of processors that support machine-checked proofs \nhave be\u00ad 4 Recall that that the DFAs generated for the NaCl checker strip the semantic actions, so they \ndo not need to worry about reducing semantic actions.  come a hot topic. Often, these models have limitations, \nnot because of any inherent design .aw, but rather because they are meant only to prove speci.c properties. \nFor example, work on formal veri.ca\u00adtion of compilers [5, 16] only needs to consider the subset of the \ninstructions that compilers use. Moreover, these compilers emit as\u00adsembly instructions and do not prove \nsemantics preservation all the way down to machine code, so their model leaves out the tricky problem \nof decoding. The same kinds of limitations exist for the processor models used in the formal veri.cation \nof operating sys\u00adtems [6]. Some projects focus on one speci.c part of the model, for instance the media \ninstructions [14], and some others [20] model just a few instructions mostly as a proof of concept. Even \nthough we are focused here on NaCl veri.cation, our long term goal is to develop a general model of the \nx86 so we have tried hard to achieve a more open and scalable design. There are several projects focused \non the development of gen\u00aderal formal models of processors. Some projects have considered the formalizations \nof RISC processors [1, 11, 21]. As noted, de\u00adveloping a formal model for the x86 poses many new problems, \npartly because decoding is signi.cantly more complex, but also for the de.nition and validation of such \na vast number of instructions (over 1,000) with so many variations, from addressing modes to pre.xes. \nOne model close in spirit to our own is the Y86 formalization in ACL2 by Ray [29]. Like our model, Ray \ns provides an executable simulator. However, the Y86 is a much smaller fragment (about 30 instructions), \nand has a much simpler instruction encoding (e.g.,no pre.xes). Perhaps the closest related research project, \nand the one from which we took much inspiration in our design, is the work on modeling x86 multi-processor \nmemory models [25, 30, 32]. This work comes with a formal model of about 20 instructions, and we borrowed \nmany of the ideas, such as the use of high-level grammars for specifying the decoder. However, their \nfocus was on issues of non-determinism where it is seemingly more natural to use predicates to describe \nthe possible behaviors of programs. The price paid is that validation requires symbolic evaluation and \ntheorem proving to compare abstract machine states to concrete ones. Although this was largely automated, \nwe believe that our functional approach provides a more scalable way to test the model. Indeed, we have \nbeen able to run three orders of magnitude more tests. On the other hand, it remains to be seen how effective \nour approach will be when we add support for concurrency. Our decoder, formalized in Coq, uses parsers \ngenerated from regular expressions using the idea of derivatives. Others have for\u00admalized derivative-based \nregular expression matching [2] but not parsing. However, more general parser generators for algorithms \nsuch as SLR and LR have recently been formalized [3, 13]. The original idea for Software-based fault \nisolation (SFI) was introduced by Wahbe et. al. [33] in the context of a RISC ma\u00adchine. This work used \nan invariant on dedicated registers to ensure that all reads, writes, and jumps were appropriately isolated. \nOf course, parsing was not a problem because instructions had a uni\u00adform length. As noted earlier, McCamant \nand Morrisett [20] intro\u00adduced the idea of the alignment constraint to handle variable-length instruction \nsets. In that paper, they formalized a small subset of the x86 (7 instructions) using ACL2 and proved \nthat their high-level in\u00advariants were respected by those instructions, but did not prove the correctness \nof their checker. In fact, even with the small number of instructions, Kroll and Dean found a number \nof bugs in the de\u00adcoder [15], which reinforces our argument that one should be wary of a trusted decoder \nor disassembler. Pilkiewicz [26] developed a formally veri.ed SFI checker in Coq for a simple assembly \nlanguage.  6. Future work &#38; Conclusions We have presented a formal model for a signi.cant subset \nof the x86, and a new formally veri.ed checker for Native Client called RockSalt. The primary challenge \nin this work was building a model for an architecture as complicated as the x86. Although we only managed \nto model a small subset, we believe that the design is relatively robust thanks to our ability to extract \nand test executable code. The experience in using the model to reason about a simple but real policy \nsuch as NaCl s sandbox, provides some assurance that the model will be useful for reasoning in other \ncontexts. 6.1 Future Work As explained before, our x86 model is far from complete. We do not yet handle \n.oating-point instructions, system programming in\u00adstructions, nor any of the MMX, SSEn, 3dNow! or IA-64 \ninstruc\u00adtions. On the other hand, we have managed to cover enough instruc\u00adtions that we can compile real \napplications and run them through the simulator. Moving forward, we would like to extend the model to \ncover at least those instructions that are used by compilers. Our model of machine states is also overly \nsimple. For example, we do not yet model concurrency, interrupts, or page tables. How\u00adever, we believe \nthat the use of RTL as a staging language makes it easier to add support for those features. For example, \nto model multiple processors and the total-store order (TSO) memory con\u00adsistency model [32], we believe \nthat it is suf.cient to add a store buffer to the machine state for each processor. Of course, validat\u00ading \na concurrent model will present new challenges. We believe that the use of domain-speci.c languages will \nfur\u00adther facilitate re-use and help to .nd and eliminate bugs. For exam\u00adple, one could imagine embedding \nthese languages in other proof assistants (HOL, ACL2, etc.) to support portability of the speci.\u00adcation \nacross formal systems. We would also like to close the gap on RockSalt so that the C code, derived from \nour veri.ed Coq code, is itself veri.ed and compiled with a proven-correct compiler such as CompCert. \nIn fact, one fun idea is to simply bypass the compiler and write the checker directly in x86 assembly \nto see how easy it is to turn the process in on itself. Finally, there are richer classes of policies, \nsuch as XFI, for which we would like to write checkers and prove correctness.  6.2 Lessons Learned The \nbasic idea of using domain-speci.c languages to build a scal\u00adable semantics worked well for us. In our \n.rst iteration of the model, we tried to directly interpret x86 instructions, but soon real\u00adized that \nany reasoning work would be proportional to the number of distinct instructions. Compiling instructions \nto a small RISC-like core simpli.ed our reasoning, and at the same time, made it easier to factor the \nmodel into smaller, more re-usable components. One surprising aspect of the work was that the pressure \nto pro\u00advide reasoning principles for parsers forced us to treat the prob\u00adlem more algebraically than \nis typically done. In particular, the use of derivatives, which operate directly on the abstract syntax \nof grammars, made our reasoning much simpler than it would be with graphs. It goes without saying that \nconstructing machine-checked proofs is still very hard. The de.nitions for our x86 model and NaCl checker \nare about 5,000 lines of heavily commented Coq code, but the RockSalt proofs are another 10,000 lines. \nOf course, many of these proofs will be useful in other settings (e.g., that the decoder is unambiguous) \nbut the ratio is still quite large. One reason for this is that reasoning about certain theories (e.g., \nbit vectors) is still rather tedious in Coq, especially when compared to modern SAT or SMT solvers. Yet, \nthe dependent types and higher-order features of the language were crucial for constructing the model, \nmuch less proving deep properties about it.  For us, another surprising aspect of the work was the difference \nthat comes with scale. We have a fair amount of experience mod\u00adeling simple abstract machines with proof \nassistants. Doing a case split on .ve or even ten instructions and manually discharging the cases is \nreasonable. But once you have hundreds of cases, any of which may change as you validate the model, such \nan approach is no longer tenable. Consequently, many of our proofs were actually done through some form \nof re.ection. For example, to prove that the x86grammar is unambiguous, we constructed a computable function \nthat tests for ambiguity and proved its correctness. In turn, this made it easier to add new instructions \nto the grammar. Frankly, we couldn t stomach the idea of proving the correctness of a hand\u00adwritten x86 \ndecoder, and so we were forced into .nding a better solution. In short, when a mechanized development \nreaches a cer\u00adtain size, we are forced to develop more automated and robust proof techniques.   References \n[1] J. Alglave, A. C. J. Fox, S. Ishtiaq, M. O. Myreen, S. Sarkar, P. Sewell, and F. Z. Nardelli. The \nsemantics of Power and ARM multiprocessor machine code. In Proc. of the Workshop on Declarative Aspects \nof Multicore Programming, pages 13 24. ACM, 2009. [2] J. B. Almeida, N. Moreira, D. Pereira, and S. M. \nde Sousa. Partial derivative automata formalized in Coq. In Proc. of the 15th Intl. Conf. on Implementation \nand Application of Automata, number 6482 in CIAA 10, pages 59 68. Springer-Verlag, Aug. 2010. [3] A. \nBarthwal and M. Norrish. Veri.ed, executable parsing. In European Symp. on Programming, ESOP 09, pages \n160 174. LNCS, 2009. [4] J. A. Brzozowski. Derivatives of regular expressions. Journal of the ACM, 11:481 \n494, 1964. [5] A. Chlipala. A veri.ed compiler for an impure functional language. In Proc. of the 37th \nACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, pages 93 106. ACM, 2010. [6] D. Cock. \nLyrebird: assigning meanings to machines. In Proc. of the 5th Intl. Conf. on Systems Software Veri.cation, \nSSV 10, pages 6 15. USENIX Association, 2010. [7] E. Cohen, M. Dahlweid, M. Hillebrand, D. Leinenbach, \nM. Moskal, T. Santen, W. Schulte, and S. Tobies. VCC: A practical system for verifying concurrent C. \nIn Proc. of the 22nd Intl. Conf. on Theorem Proving in Higher Order Logics, TPHOLs 09, pages 23 42. Springer-Verlag, \n2009. [8] Coq development team. The Coq proof assistant. http://coq. inria.fr/, 1989 2012. [9] L. Correnson, \nZ. Dargaye, and A. Pacalet. WP plug-in manual.CEA LIST. [10] J. Dias and N. Ramsey. Automatically generating \ninstruction selectors using declarative machine descriptions. In Proc. of the 37th ACM SIGPLAN-SIGACT \nSymp. on Principles of Programming Languages, POPL 10, pages 403 416. ACM, 2010. [11] A. C. J. Fox and \nM. O. Myreen. A trustworthy monadic formalization of the ARMv7 instruction set architecture. In Interactive \nTheorem Proving, volume 6172 of LNCS, pages 243 258. Springer, 2010. [12] Intel Corporation. Pentium \nProcessor Family Developers Manual, volume 3. Intel Corporation, 1996. [13] J.-H. Jourdan, F. Pottier, \nand X. Leroy. Validating LR(1) parsers. In European Symp. on Programming, ESOP 12. Springer, 2012. To \nappear. [14] W. A. H. Jr. and S. Swords. Centaur technology media unit veri.ca\u00adtion. In Computer Aided \nVeri.cation, 21st Intl. Conf., volume 5643 of LNCS, pages 353 367. Springer, 2009. [15] J. Kroll and \nD. Dean. BakerSFIeld: Bringing software fault isola\u00adtion to x64. http://www.cs.princeton.edu/~ kroll/papers/ \nbakersfield-sfi.pdf. [16] X. Leroy. Formal veri.cation of a realistic compiler. Commun. of the ACM, 52(7):107 \n115, 2009. [17] J. Lim. Transformer Speci.cation Language: A System for Generating Analyzers and its \nApplications. PhD thesis, University of Wisconsin-Madison, May 2011. [18] C.-K. Luk, R. Cohn, R. Muth, \nH. Patil, A. Klauser, G. Lowney, S. Wal\u00adlace, V. J. Reddi, and K. Hazelwood. Pin: building customized \npro\u00adgram analysis tools with dynamic instrumentation. In Proc. of the ACM SIGPLAN Conf. on Programming \nLanguage Design and Imple\u00admentation, PLDI 05, pages 190 200. ACM, 2005. [19] L. Martignoni, R. Paleari, \nG. F. Roglia, and D. Bruschi. Testing CPU emulators. In Proc. of the 18th Intl. Symp. on Software Testing \nand Analysis, pages 261 272. ACM, 2009. [20] S. McCamant and G. Morrisett. Evaluating SFI for a CISC \narchitec\u00adture. In Proc. of the 15th Conf. on USENIX Security Symp., pages 209 224. USENIX Association, \n2006. [21] N. G. Michael and A. W. Appel. Machine instruction syntax and semantics in higher order logic. \nIn Automated Deduction -CADE\u00ad17, 17th Intl. Conf. on Automated Deduction, volume 1831 of LNCS, pages \n7 24. Springer, 2000. [22] M. Might, D. Darais, and D. Spiewak. Parsing with derivatives: a functional \npearl. In Proc. of the 16th ACM SIGPLAN Intl. Conf. on Functional Programming, ICFP 11, pages 189 195. \nACM, 2011. [23] Native Client team. Native client security contest. http: //code.google.com/contests/nativeclient-security/ \nindex.html, 2009. [24] S. Owens, J. Reppy, and A. Turon. Regular-expression derivatives re\u00adexamined. \nJ. Funct. Program., 19:173 190, March 2009. [25] S. Owens, P. B\u00a8ohm, F. Z. Nardelli, and P. Sewell. Lem: \nA lightweight tool for heavyweight semantics. In Interactive Theorem Proving, volume 6898 of LNCS, pages \n363 369. Springer, 2011. [26] A. Pilkiewicz. A proved version of the inner sandbox. In native-client\u00addiscuss \nmailing list, April 2011. [27] N. Ramsey and J. W. Davidson. Machine descriptions to build tools for \nembedded systems. In Languages, Compilers, and Tools for Embed\u00added Systems, volume 1474 of LNCS, pages \n176 192. Springer, 1998. [28] N. Ramsey and M. F. Fernandez. Specifying representations of ma\u00adchine instructions. \nACM Trans. Program. Lang. Syst., 19(3):492 524, 1997. [29] S. Ray. Towards a formalization of the X86 \ninstruction set architec\u00adture. Technical Report TR-08-15, Department of Computer Science, University \nof Texas at Austin, March 2008. [30] S. Sarkar, P. Sewell, F. Z. Nardelli, S. Owens, T. Ridge, T. Braibant, \nM. O. Myreen, and J. Alglave. The semantics of x86-CC multiproces\u00adsor machine code. In Proc. of the 36th \nACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, pages 379 391. ACM, 2009. [31] M. Seaborn. \nA DFA-based x86-32 validator for Native Client. In native-client-discuss mailing list, June 2011. [32] \nP. Sewell, S. Sarkar, S. Owens, F. Z. Nardelli, and M. O. Myreen. x86-TSO: a rigorous and usable programmer \ns model for x86 multi\u00adprocessors. Commun. ACM, 53(7):89 97, 2010. [33] R. Wahbe, S. Lucco, T. E. Anderson, \nand S. L. Graham. Ef.cient software-based fault isolation. In Proc. of the 14th ACM Symp. on Operating \nSystems Principles, SOSP 93, pages 203 216. ACM, 1993. [34] X. Yang, Y. Chen, E. Eide, and J. Regehr. \nFinding and understanding bugs in C compilers. In Proc. of the 32nd ACM SIGPLAN Conf. on Programming \nLanguage Design and Implementation, PLDI 11, pages 283 294. ACM, 2011. [35] B. Yee, D. Sehr, G. Dardyk, \nJ. B. Chen, R. Muth, T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar. Native Client: a sandbox for \nportable, untrusted x86 native code. Commun. of the ACM, 53(1): 91 99, 2010. [36] L. Zhao, G. Li, B. \nD. Sutter, and J. Regehr. Armor: Fully veri.ed software fault isolation. In 11th Intl. Conf. on Embedded \nSoftware. ACM, 2011.  \n\t\t\t", "proc_id": "2254064", "abstract": "<p>Software-based fault isolation (SFI), as used in Google's Native Client (NaCl), relies upon a conceptually simple machine-code analysis to enforce a security policy. But for complicated architectures such as the x86, it is all too easy to get the details of the analysis wrong. We have built a new checker that is smaller, faster, and has a much reduced trusted computing base when compared to Google's original analysis. The key to our approach is automatically generating the bulk of the analysis from a declarative description which we relate to a formal model of a subset of the x86 instruction set architecture. The x86 model, developed in Coq, is of independent interest and should be usable for a wide range of machine-level verification tasks.</p>", "authors": [{"name": "Greg Morrisett", "author_profile_id": "81548013278", "affiliation": "Harvard University, Cambridge, MA, USA", "person_id": "P3471273", "email_address": "greg@eecs.harvard.edu", "orcid_id": ""}, {"name": "Gang Tan", "author_profile_id": "81309504867", "affiliation": "Lehigh University, Bethlehem, PA, USA", "person_id": "P3471274", "email_address": "gtan@cse.lehigh.edu", "orcid_id": ""}, {"name": "Joseph Tassarotti", "author_profile_id": "81502806867", "affiliation": "Harvard University, Cambridge, MA, USA", "person_id": "P3471275", "email_address": "tassarotti@college.harvard.edu", "orcid_id": ""}, {"name": "Jean-Baptiste Tristan", "author_profile_id": "81342514111", "affiliation": "Harvard University, Cambridge, MA, USA", "person_id": "P3471276", "email_address": "tristan@seas.harvard.edu", "orcid_id": ""}, {"name": "Edward Gan", "author_profile_id": "81502673275", "affiliation": "Harvard University, Cambridge, MA, USA", "person_id": "P3471277", "email_address": "egan@college.harvard.edu", "orcid_id": ""}], "doi_number": "10.1145/2254064.2254111", "year": "2012", "article_id": "2254111", "conference": "PLDI", "title": "RockSalt: better, faster, stronger SFI for the x86", "url": "http://dl.acm.org/citation.cfm?id=2254111"}