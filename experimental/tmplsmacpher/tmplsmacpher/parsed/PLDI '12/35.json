{"article_publication_date": "06-11-2012", "fulltext": "\n Synthesizing Software Veri.ers from Proof Rules Sergey Grebenshchikov Nuno P. Lopes Corneliu Popeea \nTechnische Universit\u00a8at M\u00a8unchen INESC-ID / IST -TU Lisbon Technische Universit\u00a8at M\u00a8unchen grebensh@cs.tum.edu \nnuno.lopes@ist.utl.pt popeea@model.in.tum.de Andrey Rybalchenko Technische Universit\u00a8at M\u00a8unchen rybal@in.tum.de \n Abstract Automatically generated tools can signi.cantly improve program\u00admer productivity. For example, \nparsers and data.ow analyzers can be automatically generated from declarative speci.cations in the form \nof grammars, which tremendously simpli.es the task of im\u00adplementing a compiler. In this paper, we present \na method for the automatic synthesis of software veri.cation tools. Our synthe\u00adsis procedure takes as \ninput a description of the employed proof rule, e.g., program safety checking via inductive invariants, \nand produces a tool that automatically discovers the auxiliary asser\u00adtions required by the proof rule, \ne.g., inductive loop invariants and procedure summaries. We rely on a (standard) representation of proof \nrules using recursive equations over the auxiliary asser\u00adtions. The discovery of auxiliary assertions, \ni.e., solving the equa\u00adtions, is based on an iterative process that extrapolates solutions obtained for \n.nitary unrollings of equations. We show how our method synthesizes automatic safety and liveness veri.ers \nfor pro\u00adgrams with procedures, multi-threaded programs, and functional programs. Our experimental comparison \nof the resulting veri.ers with existing state-of-the-art veri.cation tools con.rms the practi\u00adcality \nof the approach. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; \nD.4.5 [Operating Systems]: Reliability Veri.cation; F.3.1 [Logics and Meanings of Pro\u00adgrams]: Specifying \nand Verifying and Reasoning about Programs Keywords Proof rules, veri.cation tool synthesis, software \nveri.\u00adcation, software model checking 1. Introduction Developing tools that deal with programs, e.g., \nparsers, compilers, analyzers, or veri.ers, is a dif.cult yet necessary task for increasing programmer \nproductivity. Programs are complex artifacts and their treatment within a tool requires careful consideration \nof various intricate aspects of program syntax and semantics. Tool synthesis offers an attractive alternative \nto manual tool development. Once a Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 12, June 11 16, 2012, Beijing, China. Copyright c . 2012 ACM 978-1-4503-1205-9/12/06. \n. . $10.00 tool generator is developed for a given problem domain, it can be used to synthesize various \ntools that deal with particular problem instances in the given domain. For example, in the problem domain \nof parsing, a parser generator allows one to synthesize parsers for particular (programming) languages \n[1]. Each parser is synthesized by the generator from a language speci.cation in the form of a grammar. \nFurthermore, static analyzers (including pointer alias analyzers) can be generated from attribute grammars \n[47], data.ow equations [29, 31], equations in the form of set constraints [2, 3, 27], or equations as \nDatalog rules [28, 34, 51]. These approaches take an analysis speci.cation as a set of equations and \nproduce an analyzer that infers program properties by solving the equations. Recently, property veri.ers \nbecame a target for automated tool construction. For example, the GETAFIX tool for checking Boolean programs \nwas synthesized from a logical formula in \u00b5-calculus using a BDD-based .xpoint solver [49]. Still, soft\u00adware \nveri.cation tools such as SLAM [4], BLAST [20, 21], FSOFT [23], IMPACT [33], TERMINATOR [11], CPACHECKER \n[7], or DSOLVE [24, 43], are developed from the ground up in a com\u00adplex manual effort that takes into \naccount particularities of domain speci.c reasoning for the applied veri.cation method. The devel\u00adopment \nefforts may need to be repeated to a large extent once a dif\u00adferent proof rule is employed, or programs \nin a different program\u00adming language are considered as input. This status quo hinders the advancement \nof the state-of-the-art in software veri.cation, makes it prohibitively expensive to develop new veri.cation \nmethods and provide veri.cation tools for the growing number of application domains. Without automatic \ntool support for the development of software veri.ers, we cannot deliver required tools for improving \nsoftware reliability and leave software developers alone in dealing with the increasing complexity of \nmodern software systems. In this paper we present a method for automating the devel\u00adopment of software \nveri.cation tools by providing the following key ingredients: a methodology for describing veri.cation \nmeth\u00adods for reachability and termination properties as constraint solv\u00ading problems, and an ef.cient \nsolver for the resulting constraints. As a result, developing a new software veri.er will become a two\u00adstep \nprocess: i) design and speci.cation of a veri.cation method in the form of constraints supported by our \nmethodology, and ii) construction of a frontend that generates constraints from software source code. \nThe main effort will be spent in the formulation of a suitable veri.cation method, which is a creative \nactivity that usu\u00adally leverages existing methods and adapts them to new applica\u00adtion domains. The frontend \nconstruction usually requires writing a translator from the compiler s intermediate representation into \nthe language of constraints, which is a well-established routine. We be\u00ad  int sum(int n) { int s; 1: \nif(n>0){ 2: s = sum(n-1); 3: return s+n; } else { 4: return 0; } 5: } V =(n, s, ret, pc) init(V )=(pc \n= .1) .(V, V .)=(n = 1 . move(.1,.2) . skip(n, s, ret)) . (ret. = s + n . move(.3,.5) . skip(n, s)) \n. (n = 0 . move(.1,.4) . skip(n, s, ret)) . (ret. =0 . move(.4,.5) . skip(n, s)) call(V, V .)=(n . = \nn - 1 . move(.2,.1)) ret(V, V .)=(s . = ret . move(.5,.3)) loc(V, V .)=(skip(n, ret) . move(.2,.3)) Figure \n1. An example program and its representation as a tran\u00adsition system. skip(v1,...,vk) abbreviates the \nconjunction v1 . = v1 . \u00b7\u00b7\u00b7 . vk . = vk . move(., ..) abbreviates the conjunction pc = . . pc . = .. \n. lieve that our method offers promising potential to boost the devel\u00adopment (and deployment) of software \nveri.ers in the same way the parser generators paved the way to modern approaches to compiler construction. \nOur method focuses on automatic construction of veri.cation tools that implement proof rules for reachability \nand termination properties in the form of Horn(-like) clauses, see e.g. [30]. Proof rules in such form \nare shown to be suf.ciently expressive and practically adequate for dealing with a wide range of program\u00adming \nlanguages (including sequential, concurrent, and functional programs), temporal speci.cations and veri.cation \ntechniques, see e.g. [13, 18, 19, 37, 42, 43]. We present an ef.cient algorithm for solving Horn-like \nclauses by generalizing state-of-the-art software veri.cation algorithms, in particular counterexample \nguided ab\u00adstraction and re.nement schemes. To demonstrate the feasibility of our approach in practice, \nwe apply our solving algorithm in combi\u00adnation with appropriate constraint generation frontends to develop \na collection of veri.ers for temporal properties of programs with procedures, multi-threaded programs, \nand functional programs. This paper makes the following contributions. Conceptually, we identify a formulation \nof proof rules for reachability and termination properties in the form of Horn-like clauses suitable \nfor automation using state-of-the-art techniques for software veri.cation.  Technically, we provide \nan algorithm for solving Horn-like clauses that is based on a generalization of the state-of-the-art \ncounterexample guided abstraction re.nement schemes.  Practically, we present an implementation of our \napproach and its evaluation on important proof rules for the veri.cation of transition systems, programs \nwith procedures, multi-threaded programs, and functional programs.  2. Illustration We illustrate our \nveri.cation approach using a simple example for which we prove a safety and a termination property. \n2.1 Verifying programs with procedures See Figure 1 for an example program implementing a sum compu\u00adtation. \nThe procedure sum takes an argument n and returns the sum of the numbers between 1 and n, or 0 if its \nargument n is not posi\u00adtive. We assume that the program state is given by a valuation of the program \nvariables V =(n, s, ret, pc) . The variable ret models return value passing, while pc is a procedure-local \nprogram counter variable that keeps track of the current control location. The initial states of the \nprogram are given as an assertion init(V ) , where .1 indicates the program line labeled 1. We use assertions \nover a tuple of variables V and its primed version V . to model program statements as binary relations \nover states. In our program, .(V, V .) represents intra-procedural statements. call(V, V .) and ret(V, \nV .) model parameter and return value passing, respectively. The last as\u00adsertion loc(V, V .) ensures \nthat the caller s local data variables are unchanged during the callee s execution, while the caller \ns program counter moves over the call site. The set of local variables that are kept unchanged by the \nassertion loc(V, V .) excludes s , which is assigned by the call statement. Proving safety We prove that \nsum always returns a non-negative value and formalize this property by the assertion error(V )= (pc = \n.5 . ret < 0) . To prove the property, we rely on a summarization proof rule for programs with procedures \n[42]. This proof rule requires the construction of an auxiliary assertion Summ(V, V .) that represents \na binary relation between entry states of a procedure and their successors on the same level of recursion. \nThe following constraints over Summ(V, V .) guarantee that all necessary pairs of states are captured. \ninit(V ) . V = V . . Summ(V, V .) Summ(V, V .) . .(V .,V ..) . Summ(V, V ..) ) . V .. Summ(V, V .) . \ncall(V .,V ..= V ... . Summ(V ..,V ...) Summ(V, V .) . call(V .,V ..) . Summ(V ..,V ...) . ,V ....,V \n.... ret(V ...) . loc(V .) . Summ(V, V ....) We obtain a correctness proof if we can .nd an instance \nof Summ that satis.es the above constraints together with the implication Summ(V, V .) . error(V .) . \nfalse . The following disjunction is a solution that is computed by our proposed Horn solving algo\u00adrithm. \nSumm(V, V .)=(pc = .1 . pc . .{.1,.4}) . (pc = .1 . pc . = .2 . n . = 1) . (pc = .1 . pc . = .3 . n . \n+ s . = 1) . (pc = .1 . pc . = .5 . ret. = 0) Note that the last disjunct ensures the non-negativeness \nof the return value. Proving termination For proving that sum terminates on every input, we require that \na so-called recursion relation between entry states of the caller and its immediate callee is well-founded, \ni.e., it does not admit in.nite chains. We obtain the recursion relation by relational composition of \nthe summary with the parameter passing relation. Hence, for proving termination, we need to .nd an asser\u00adtion \nSumm(V, V .) that satis.es the above implications ensuring the summarization property and the following \nwell-foundedness condition. well-founded(Summ(V, V .) . call(V .,V ..))  To prove termination, our previous \nsolution for Summ(V, V .) re\u00adquires a strengthening n . = n that keeps track of changes applied to n \nand guarantees that n never increases. Our solving algorithm computes the following solution. Summ(V,V \n.)=(pc = .1 . pc . = .1 . n = n .) . (pc = .1 . pc . = .2 . n . = 1 . n = n .) . (pc = .1 . pc . = .3 \n. n . + s . = 1) . (pc = .1 . pc . = .4) . (pc = .1 . pc . = .5 . ret. = 0) The composition of the strengthened \nsolution with the parameter passing relation is (move(.1,.1) . n . = 0 . n . = n - 1) . Its well-foundedness \nfollows from the decrease of n at each step and its boundedness from below by n . = 0. As our example \nillustrates, we consider proof rules that can be represented as a set of implication constraints over \nformulas repre\u00adsenting the program and unknown formulas, e.g. Summ(V,V .) . To provide a basis for ef.cient \nsolving algorithms, our implication constraints resemble Horn clauses as they may have at most one un\u00adknown \nformula in the consequent part of a clause. We refer to such implications as Horn-like clauses, since \nwe allow arbitrary disjunc\u00adtions among known formulas.  2.2 Verifying functional programs We represent \nthe program from Figure 1 as a functional program. letrecsum n= ifn >0then let s=sum(n-1) ins+n else \n0 For functional programs, typing constraints can be used to track value .ow through program expressions. \nThey relate re.nement types [14, 26] that represent assertions over values of expressions and values \nof identi.ers in scope. For example, the type of the above function sum can be represented as follows. \nsum :(n : {. : int | P1(.)}.{. : int | P2(n,.)}) Following recent work on re.nement type inference, see \ne.g., [24, 48, 50], we embed the typing constraints into logical implica\u00adtions and obtain the following \nset of Horn-like clauses over P1(.) and P2(n,.) . true . P1(.) P1(n) . n > 0 . . = n - 1 . P1(.) P1(n) \n. n > 0 . P2(n - 1,.) . .. = n + . . P2(n,..) P1(n) . n = 0 . . =0 . P2(n,.) P2(n,.) . . = 0 The .rst \nclause encodes that there is no restriction on the in\u00adputs to sum. The second and third clauses represent \ndata .ow if the branching condition succeeds. First, there is data .ow due to the parameter passing, \nwhich is represented by the second clause. Then, the result of the recursive call is represented using \nthe asser\u00adtion P2(n -1,.). The sum of . and n is the return value. The fourth clause encodes return value \npassing when the branching condition fails. The last clause represents the property that sum returns \nnon\u00adnegative values. If there is a solution to the above clauses then sum satis.es the property. Our \nsolving algorithm computes solutions for P1(.) and P2(n,.) , which yields the following type for sum. \nsum :(n : {. : int | true}.{. : int | . = 0}) . 3. Preliminaries In this section we introduce preliminary \nde.nitions. We write .x . X.e to represent a de.nition that assigns to each x . X the value obtained \nby evaluating e. Given a function f, let dom(f) denote the domain of f, i.e., the set of values for which \nf is de.ned. A binary relation is well-founded if it does not admit in.nite chains. We write well-founded(.(v, \nv .)) if .(v, v .) is a well-founded relation, i.e., there is no in.nite sequence s1,s2,... such that \n.(si,si+1) for all i = 1. Let . denote the empty tuple. A relation .(v, v .) is disjunctively well-founded \nif it is included in a .nite union of well-founded relations, i.e., if there exist well\u00adfounded .1(v, \nv .),...,.n(v, v .) such that .(v, v .) |=T .1(v, v .) .\u00b7 \u00b7\u00b7. .n(v, v .). For example, the relation x \n= 0 . x . = x - 1 is well-founded, while the relation x = 0 . x . = x - 1 . y = 0 . y . = y +1 is disjunctively \nwell-founded. Constraints Let T be a .rst-order theory in a given signature, V be a set of variables, \nand |=T be the entailment relation with respect to T . We write v to denote a non-empty tuple of variables, \ni.e., v .V+ . We refer to formulas in the given signature as constraints, and let c(v) denote a constraint \nover the variables v. Let false denote an unsatis.able constraint. For example, let x, y, and z be variables. \nThen, v =(x, y) and w =(y, z) are tuples of variables. x = 2, y = 1 . x - y = 0, and f(x)+ g(x, y) = \n3 . z = 0 are example constraints in the the\u00adory T of linear inequalities over rationals/reals and uninterpreted \nfunctions, where f and g are uninterpreted function symbols. The entailment y = 1 . x - y = 0 |=T x = \n2 is valid. Queries and dwf-predicates We assume a set of uninterpreted predicate symbols Q that we refer \nto as query symbols. The arity of a query symbol is encoded in its name. We write q to denote a query \nsymbol. Given q of a non-zero arity n and a tuple of variables v of length n, we de.ne q(v) to be a query. \nFurthermore, we introduce an interpreted predicate symbol dwf of arity one (dwf stands for disjunctive \nwell-foundedness). Given a query q(v, v .) over tuples of variables with equal length, we refer to dwf \n(q(v, v .)) as a dwf \u00adpredicate. For example, let Q = {r, s} be query symbols of arity one and two, respectively. \nThen, r(x) and s(x, y) are queries, and dwf (s(x, y)) is a dwf -predicate. Horn-like clauses Let h(v) \nrange over queries and constraints with variables in v. We de.ne a Horn-like clause to be either an implication \nc(v0) . q1(v1) .\u00b7 \u00b7\u00b7. qn(vn) . h(v) or a unit clause dwf (q(v, v .)) which consists of a dwf -predicate. \nThe left-hand side of the impli\u00adcation is called the body and the right-hand side is called the head. \nWe use cl to denote a Horn-like clause. The following set of clauses C illustrates our de.nition of Horn\u00adlike \nclauses. C = {x = y . y =-1 . r(x),y = x +1 . r(x) . s(x, y), r(x) . x = 0, dwf (s(x, y))} To support \nef.cient veri.cation, our Horn-like clauses slightly deviate from the standard notion of Horn clauses \nsince constraints occurring in our clauses can contain disjunctions and conjunctions. For example, we \nadmit clauses such as (x = 0 . y = 0) . s(x, y) . s(x, y)  and s(x, y) . (x = 0 . y = 0). While our \npresentation of the proposed method does not rely on the Boolean structure of constraints occurring in \nclauses, it is useful in practice to allow disjunction in constraints in order to keep the number of \nclauses small. (Note that the above two clauses can be translated into logically equivalent Horn clauses \nx = 0.s(x, y) . s(x, y), y = 0 . s(x, y) . s(x, y) and s(x, y) .\u00ac(x = 0) . y = 0.) In contrast, we rely \non the fact that there is at most one non-negated query in a clause. Clauses in normal form Before formalizing \nthe semantics of the clauses, we introduce assumptions on the syntax of Horn-like clauses that signi.cantly \nsimplify the presentation of the semantics without introducing any proper restrictions. First, we assume \nthat for each query symbol q there is a .xed tuple v of variables with the corresponding length and that \neach query with the symbol q is of the form q(v). That is, each query has an a priori de.ned tuple of \nvariables. Furthermore, we assume that all variables in v are pairwise distinct, i.e., for the tuple \nof variables v =(x1,...,xn) we have xi and xj are different variables for all 1 = i . = j = n. Second, \nwe assume that in each clause a query symbol can occur at most once. Formally, for each clause c(v0) \n. q1(v1) . \u00b7 \u00b7\u00b7 . qn(vn) . h(v) we assume that qi is different from qj for all 1 = i .j = n, and if the \nhead h(v) is a query q(v) then q is = different from each qi for all 1 = i = n. The .rst assumption can \nbe established by assigning tuples of variables to query symbols, and then translating queries into the \ndesired form by adding corresponding equality constraints into the constraint of a clause. For example, \nfor the query symbols r and s we assign variables vr =(xr) and vs =(xs,ys), respectively. Then, a clause \nx + y = 0 . r(x) . s(x, x) . y = 0 violates our .rst assumption but can be transformed to x = xr . x \n= xs . x = ys . x + y = 0 . r(xr) . s(xs,ys) . y = 0. The .rst conjunct corresponds to the translation \nof the query r(x), while the second and third conjuncts correspond to s(x, x). The second assumption \ncan be established by introducing aux\u00adiliary queries and clauses each time there is a clause with multiple \noccurrences of some query. The violating clause is transformed by replacing the violating query occurrences \nin the clause body by the auxiliary queries. For example, a clause r(xr) . r(xr) . r(xr) violates the \nsec\u00adond assumption due to the triple occurrence of r(xr). Hence, we in\u00adtroduce two auxiliary query symbols \nr1 and r2 of arity one together with the corresponding tuples of variables vr1 =(xr1 ) and vr2 = (xr2 \n), respectively. Then, we express the relation between r(xr) and the introduced queries using the following \nauxiliary clauses: xr = xr1 . r(xr) . r1(xr1 ) and xr = xr2 . r(xr) . r2(xr2 ). Finally, we translate \nthe original clause r(xr) . r(xr) . r(xr) to xr = xr1 . xr = xr2 . r1(xr1 ) . r2(xr2 ) . r(xr). We refer \nto a set of Horn-like clauses that satis.es the above two conditions as clauses in normal form. In the \nrest of the paper, we assume that the clauses are Horn-like and in normal form. For C de.ned above we \nobtain the following normal form CNF . {x = xr . x = y . y =-1 . r(xr), x = xr . x = xs . y = ys . y \n= x +1 . r(xr) . s(xs,ys), x = xr . r(xr) . x = 0, dwf (s(xs,ys))} Semantics of Horn-like clauses A set \nof clauses can be seen as an assertion over the queries that occur in the clauses. We consider a function \nS that maps each query q(v) occurring in a given set of clauses into a constraint over v. Such a function \nis called a solution if the following two conditions hold. First, for each clause c(v0) . q1(v1) .\u00b7\u00b7\u00b7. \nqn(vn) . h(v) from the given set we require: . .S(q) if h(v) is q(v), c(v0) . S(q1) . \u00b7 \u00b7 \u00b7 . S(qn) |=T \n.ch(v) if h(v) is ch(v). Second, for each clause dwf (q(v, v .)) in the input set we require that the \nrelation S(q) is disjunctively well-founded. Let |=Q be the corresponding satisfaction relation, i.e., \nS |=Q C if S is a solution for C. For example, the previously de.ned set of clauses CNF has a solution \nS such that S(r)= xr =-1, S(s)= xs = 0 . ys = xs +1. To check S |=Q CNF we consider the validity of the \nentailments x = xr . x = y . y =-1 |=T xr =-1, x = xr . x = xs . y = ys . y = x +1 . xr =-1 |=T xs = \n0 . ys = xs +1, x = xr . xr =-1 |=T x = 0, and the fact that S(s) is a (disjunctively) well-founded relation. \nDependency and recursion-free clauses For a clause cl such that c(v0) . q1(v1) .\u00b7 \u00b7\u00b7. qn(vn) . h(v) we \nde.ne depends(cl) to be the set of query symbols that appear in the body of cl, i.e., depends(cl)= {q1,...,qn}. \nA set of clauses de.nes a binary dependency relation on query symbols. Each clause cl that has a query \nq(v) (rather than a constraint) in its head contributes the set of pairs {(qi,q) | qi . depends(cl)} \nto the dependency relation. We say that a set of clauses is recursion\u00adfree if the corresponding dependency \nrelation is well-founded. For example, the second clause in C depends on the set of query symbols {r}, \nand the entire set of clauses C de.nes the dependency relation {(r, s)}. This dependency relation is \nwell-founded, hence C is recursion-free. Solving recursion-free clauses We assume an algorithm for solv\u00ading \nrecursion-free clauses. This algorithm takes as input recursion\u00adfree clauses in the theory T and computes \na solution S when it exists. There already exist such algorithms for the theory of lin\u00adear arithmetic \n(see [19]) and linear arithmetic with uninterpreted functions (see [17]), which are based on extensions \nof interpolation algorithms [32, 46] to tree-like structures. 4. Algorithm HSF In this section we present \nour algorithm HSF for .nding solutions to recursive Horn-like clauses. Let C be a .nite set of clauses \nthat is given as input to HSF. We partition C into inference clauses I and property clauses P. In\u00adference \nclauses contain queries in their heads, and property clauses contain the rest, i.e., I = {cl .C| cl =(... \n. q(v))}, P = C\\I. Inference clauses impose a relationship between queries, while property clauses impose \nabsolute assertions on queries. HSF .nds a solution by following an iterative, abstraction\u00adbased approach \nthat relies on (spurious) counterexample deriva\u00adtions to re.ne the abstraction in case of imprecision. \nThis approach is a generalization of the counterexample-guided abstraction re\u00ad.nement schemes for proving \nreachability and termination prop\u00aderties of software. Our generalization deals with Horn-like clauses \n(instead of transition systems/programs with procedures). Our ap\u00adproach inherits the advantages and disadvantages \nof the existing counterexample-guided abstraction re.nement schemes: a suf.\u00adciently precise yet not overly \ndetailed abstraction can be discov\u00adered automatically, however the abstraction discovery procedure may \nnot terminate. In practice, the non-terminating behavior is suf\u00ad.ciently seldom.  The iteration proceeds \nin three main steps. 1. We .nd a solution for the inference clauses I. At this step we perform logical \ninference and rely on abstraction to ensure termination in the presence of recursion and to ensure ef.ciency \nin the presence of large sets of clauses. 2. We check whether the computed solution satis.es the property \nclauses P. If some property clause, say cl, is not satis.ed then we proceed with the analysis of the \ninference tree computed in the .rst step. Otherwise, if all property clauses are satis.ed, we return \nthe solution. 3. We check whether the logical inference performed in the .rst step in the setting without \nany abstraction yields a solution that still violates the property clause cl. If the violation is present \nthen we return the inference tree as a counterexample derivation. Otherwise we use the obtained solution \nto re.ne the abstraction function and go back to the .rst step.  The .rst step is implemented using \na procedure INFERABST that applies ADDINFERRED to perform the necessary bookkeeping of the inference \ntree construction. MAKECEX extracts a relevant sub\u00adtree of the inference tree in case a solution computed \nby INFER-ABST violates some property clause. We rely on existing proce\u00addures for the analysis of the \nobtained subtree. ADDPREDS converts solutions obtained by the successful subtree analysis into a re.ne\u00adment \nof the abstraction function. The procedure HSF puts the steps together in a loop (Figure 4). Next we \npresent the procedures that implement the three steps. (Predicate) abstraction We use predicate abstraction \nas an ap\u00adproximation technique employed by HSF. Let a be a function that takes as input a constraint \n.(v) together with a .nite set {c1(v),...,cn(v)} of predicates, i.e., atomic con\u00adstraints, over v. The \noutput is an over-approximation of .(v) that is constructed from the given predicates using Boolean operators. \nWe use the following de.nition (which is called Cartesian abstraction in the literature [5]). a(.(v), \n{c1(v),...,cn(v)})= {ci(v) | i . 1..n . .(v) |=T ci(v)} For example, given the constraint x = y . y = \nz . z = 0 and the predicates {x = z, x = 0,x = 0} , the predicate abstraction function returns the conjunction \nx = z . x = 0 . We rely on two properties of the abstraction function: over-approximation and monotonicity. \nThat is, for each pair of constraints .(v), .(v) and each set of predi\u00adcates Preds we have i) .(v) entails \na(.(v), Preds) and ii) if .(v) entails .(v) then a(.(v), Preds) entails a(.(v), Preds) . The over-approximation \nwill guarantee that combining logical inference with abstraction will yield solutions to inference clauses \nand the monotonicity will guarantee that such solutions can be computed using .xpoint iteration techniques. \nInference and abstraction Before presenting the procedure IN-FERABST, which performs logical inference, \nabstraction, and c(v0) . q(v) .I RINIT a(c(v0), Preds(q)) . Inferred(q) .1(v1) . Inferred(q1) ... .n(vn) \n. Inferred(qn) . n c(v0) . qi(vi) . q(v) .I RSTEP . ni=1 a(c(v0) . i=1 .i(vi), Preds(q)) . Inferred(q) \nFigure 2. Abstract inference rules for a given set of clauses I and a predicate abstraction function \nwith the set of predicates Preds(q) for each query symbol q. bookkeeping, we .rst present a characterization \nof what it com\u00adputes in the form of inference rules. See Figure 2. The presented rules RINIT and RSTEP \nde.ne a relation between a possibly empty sequence of constraints in the premise and a constraint in \nthe consequence such that the relation satis.es some inference clause from the input set I. We keep track \nof the inferred constraints in the set Inferred that we partition according to the query symbols of these \nconstraints. The inference process applies the rules as long as the derived constraints are not subsumed \nby the previously derived ones. A constraint .(v) derived by applying a clause with the query q(v) in \nits head is subsumed if there is a constraint .(v) in Inferred(q) such that .(v) entails .(v). (This \nsubsumption de.nition is called local entailment in the literature.) We observe that the inference process \nterminates since the range of the abstraction function is .nite, i.e., there are only .nitely many different \nconstraints that can be added to Inferred, and the abstrac\u00adtion function is monotonic. Furthermore, the \nresulting constraints yield a solution for the inference clauses. Formally, we de.ne S= .q . dom(Inferred). \nInferred(q) and obtain S |=Q I. Procedure INFERABST We turn the inference rules RINIT and RSTEP into \na worklist-based iteration procedure INFERABST that also keeps track between inferred constraints and \ncorresponding clauses. See Figure 3. INFERABST takes as input the inference clauses I and a func\u00adtion \nPreds that assigns to each query symbol q (and the correspond\u00ading tuple of variables v) a .nite set of \npredicates over v. The output of INFERABST consists of the inferred constraints Inferred and a function \nParent that represent the bookkeeping results. Parent as\u00adsigns to each inferred constraint .(v) a sequence \nof constraints and a clause that were used in the rule application that produced .(v). INFERABST maintains \na worklist WL containing inference clauses that may infer new constraints. The inference starts with \napplying all clauses that do not depend on any queries, and are hence applicable when no constraints \nare yet inferred. Each clause application follows the rule RINIT and applies ADDINFERRED to process the \napplication result. Then, INFERABST iteratively applies the clauses from the worklist until no more non-subsumed \nconstraints can be computed, i.e., until the worklist becomes empty. At every iteration step, INFERABST \ntakes a clause from the worklist and exhaustively applies the clause following the rule RSTEP. Example \nFor the set of clauses CNF de.ned in the previous sec\u00adtion, we consider the predicates Preds(r)= {xr \n= 0} and Preds(s)= {xs = ys} . For brevity, we denote the four clauses from CNF as cl1 , cl2 , cl3, and \ncl4 , respectively. Our algorithm initially processes the clauses that do not depend on any queries, \n function INFERABST input I inference clauses Preds predicate table output Inferred inferred constraints \nParent parent function for inferred constraints vars WL worklist with clauses procedure ADDINFERRED \ninput .(v) abstract relation .1(v1),...,.n(vn) parent abstract relations cl =(... . q(v)) parent \nclause with head q(v) begin 1 if \u00ac(..(v) . Inferred(q): .(v) |=T .(v)) then 2 Inferred(q) := {.(v)}. \nInferred(q) 3 Parent(.(v)) := ((.1(v1),...,.n(vn)), cl) 4 WL := {cl. .I| q . depends(cl.)}. WL end begin \n 5 Inferred := .q .Q.\u00d8 6 Parent := \u00d8 7 WL := \u00d8 8 for each c(v0) . q(v) .I do 9 .(v) := a(c(v0), Preds(q)) \n10 ADDINFERRED(.(v), ., c(v0) . q(v)) 11 while WL =.\u00d8 do 12 c(v0) . q1(v1) .\u00b7 \u00b7\u00b7. qn(vn) . q(v) := take \nfrom WL 13 for each i . 1..n and .i(vi) . Inferred(qi) do 14 .(v) := a(c(v0) . .1(v1) .\u00b7 \u00b7\u00b7. .n(vn), \nPreds(q)) 15 ADDINFERRED(.(v), (.1(v1),...,.n(vn)), c(v0) . q1(v1) .\u00b7 \u00b7\u00b7. qn(vn) . q(v)) 16 return (Inferred, \nParent) end Figure 3. Abstract inference algorithm. i.e., cl1 (see lines 8 10 from Figure 3). The computation \nof a new constraint at line 9 proceeds as follows: .(xr)= a(x = xr . x = y . y =-1, {xr = 0})=(xr = 0) \n. . Procedure ADDINFERRED The procedure ADDINFERRED is shown in Figure 3. Since ADDINFERRED is de.ned \nwithin INFER-ABST, Inferred, Parent, and WL are in scope of ADDINFERRED. The input to ADDINFERRED is \nan inferred constraint .(v) that was computed by applying a clause cl with the head q(v) on the possibly \nempty sequence of constraints .1(v1),...,.n(vn), i.e., n may be equal to zero. First, ADDINFERRED checks \nif .(v) is subsumed by already inferred constraints. If no subsumption takes place then we add it to \nthe set of inferred constraints Inferred, extend Parent with a corresponding bookkeeping record, and \nadd inference clauses that depend on q to the worklist. Example (cont.) After computing the constraint \n.(xr)= xr = 0 , the inference algorithm calls ADDINFERRED(xr = 0, ., cl1) (see line 10 of Figure 3) and \nrecords the information about the newly inferred constraint as follows: Inferred(r)= {xr = 0} , Parent(xr \n= 0) = (., cl1) , WL = {cl2} . After adding the clause cl2 to the worklist, it will be processed in the \nloop at lines 11 15 and a call ADDINFERRED(xs = ys, (xr = 0), cl2) leads to a second inferred constraint \nas follows: Inferred(s)= {xs = ys} , Parent(xs = ys) = ((xr = 0), cl2) , WL = \u00d8 . For the given sets \nof predicates, i.e., Preds(r)= {xr = 0} and Preds(s)= {xs = ys} , the computation of inferred constraints \n.nishes here since the worklist is empty. . Procedure HSF The main procedure of our algorithm is HSF. \nIt is shown in Figure 4. HSF takes as input a .nite set of Horn\u00adlike clauses C = IP and iteratively computes \na solution for the inference clauses I that also satis.es the property clauses P. HSF computes solution \ncandidates from the constraints in Inferred that are inferred using INFERABST. The obtained can\u00addidate \nis guaranteed to satisfy I, while satisfaction of P requires .nding a suf.ciently precise abstraction \nfunction. The abstraction function a is determined by a set of predicates Preds that is parti\u00adtioned \nbetween query symbols. A suf.ciently precise abstraction function is computed by HSF iteratively by adding \npredicates to Preds, which is empty initially. For the given Preds, we .rst use INFERABST to compute \ninferred constraints Inferred and Parent. Then we check whether the so\u00adlution for I de.ned by Inferred \nalso satis.es P. We distinguish between violation of a clause that has a constraint in its head from \nthe violation of a clause consisting of a dwf -predicate. If a clause cl = c(v0) . q1(v1) .\u00b7 \u00b7\u00b7. qn(vn) \n. ch(v) is not satis.ed by some sequence of inferred constraints, say .1(v1) . Inferred(q1),...,.n(vn) \n. Inferred(qn), then we check if re\u00adpeating the same inference steps without applying the abstraction \nfunction computes a sequence of constraints that satis.es cl. We reconstruct the inference steps that \nproduced .1(v1),...,.n(vn) by using the procedure MAKECEX. The output of MAKECEX is a set of recursion-free \nclauses X whose queries correspond to the constraints that were involved, as recorded by Parent, in the \ncomputation of .1(v1),...,.n(vn). We record the correspondence using the function Sym that assigns query \nsymbols of the involved constraints to the fresh query symbols that represent constraints derived without \nabstraction. We also include into X a clause imposing an assertion on the queries that correspond to \n.1(v1),...,.n(vn). Now, we solve X using an existing tool for solving recursion\u00adfree clauses [17, 19]. \nIf a solution exists then we use it to extract additional predicates for Preds. The function Sym translates \nquery symbols from the domain of the solution into the query symbols in our clauses C. In this case, \nafter re.ning the abstraction we continue with another attempt to .nd a solution for C. If a solution \ndoes not exist, we return the clauses X as a witness of the property violation. Example (cont.) The set \nof clauses CNF contains the property clause cl3, i.e., x = xr . r(xr) . x = 0, which is satis.ed by the \ncandidate solution: Inferred(r)=(xr = 0) . . If a clause dwf (q(v, v .)) is not satis.ed by some of the \ninferred constraints, say .(v, v .) . Inferred(q), then we proceed in a similar way as in the above case. \nFirst, we use MAKECEX to construct a set of recursion-free clauses X that reconstructs the inference \nsteps leading to .(v, v .). Then, we rely on an existing solver for recursion-free clauses to .nd a solution \nfor X that assigns  function HSF input IP Horn-like inference and property clauses vars Preds predicate \ntable Sym de.nition of quoted query symbols function MAKECEX input .(v) inferred constraint Parent \n parent function output X set of recursion-free clauses with root .(v) begin 1 ((.1(v1),...,.n(vn)), \nc(v0) . ni=1 qi(vi) . h(v)) := Parent(.(v)) 2 Sym := { .1(v1) .. q1,..., .n(vn) .. qn}. Sym 3 return \n{c(v0) . . n .i(vi) (vi) . .(v) (v)}. i=1 n 4 i=1 MAKECEX(.i(vi), Parent) end procedure ADDPREDS input \n S solution function begin 5 for each .(v) . dom(S) do q := Sym( .(v) ) 6 Preds(q) := S( .(v) ) . Preds(q) \n7 end begin 8 Preds := .q .Q.\u00d8 9 repeat 10 (Inferred, Parent) := INFERABST(I, Preds) if exist c(v0) \n. n qi(vi) . ch(v) .P and 11 i=1 .i(vi) . Inferred(qi) for each i . 1..n such that c(v0) . n .i(vi) .|=T \nch(v) then 12 i=1 13 Sym := { .1(v1) .. q1,..., .n(vn) .. qn} X := {c(v0) . . n .i(vi) (vi) . ch(v)}. \n14 i=1 n MAKECEX(.i(vi), Parent) 15 i=1 if exists S such that S |=Q X then 16 ADDPREDS(S) 17 else 18 \nreturn error derivation X 19 else if exist dwf (q(v, v .)) .P and .(v, v .) . Inferred(q) 20 such that \n\u00acwell-founded(.(v, v .)) then Sym := { .(v, v .) .. q} 21 X := MAKECEX(.(v, v .), Parent) 22 if exists \nS such that S |=Q X and 23 well-founded(S( .(v, v .) )) then ADDPREDS(S) 24 else 25 return error derivation \nX 26 else 27 return solution .q . dom(Inferred). Inferred(q) 28 end. Figure 4. Abstract inference, checking, \nand re.nement. a well-founded relation to q(v, v .) [39]. If INFERABST infers a set of constraints Inferred \nthat de.nes a solution for P then we return this solution. Example (cont.) The set of clauses CNF contains \na second prop\u00aderty clause, i.e., dwf (s(xs,ys)) . The conditions at line 20 of Figure 4 are satis.ed \nfor the inferred constraint xs = ys : dwf (s(xs,ys)) .CNF , xs = ys . Inferred(s) and \u00acwell-founded(xs \n= ys) . In this case, the inferred constraint does not correspond to a well-founded relation. . Procedure \nMAKECEX The procedure MAKECEX is shown in Figure 4. Its scope contains Sym and Preds from HSF. MAKE-CEX \ntakes as input an inferred constraint .(v) and bookkeeping records Parent such that .(v) . dom(Parent). \nThen, MAKECEX creates a clause that records the fact that .(v) was derived using the constraints and \nthe clause in Parent(.(v)). Let Parent(.(v)) be the pair of .1(v1),...,.n(vn) and c(v0) . q1(v1) .\u00b7 \u00b7\u00b7. \nqn(vn) . h(v). This dependency is modeled by introducing auxiliary queries .1(v1) (v1),..., .n(vn) (vn). \nThese auxiliary queries stay in one-to-one correspondence with the constraints, i.e., .i(vi) (vi) corresponds \nto qi for all 1 = i = n. This correspondence is established by applying a bijective quotation function \n \u00b7 that translates a constraint into a query symbol. Finally, we recursively apply MAKECEX on the constraints \nthat produced .(v) and return all constructed clauses. Example (cont.) For the inferred constraint s \n= xs = ys, the procedure MAKECEX(xs = ys, Parent) is invoked at line 22 from Figure 4. As a result, a \nfunction Sym is constructed to keep track of the quoted query symbols: { xs = ys .. s, xr = 0 .. r}. \nFinally, the procedure MAKECEX returns the following set of recursion-free clauses: {x = xr . x = xs \n. y = ys . y = x +1 . xr = 0 (xr) . xs = ys (xs,ys), x = xr . x = y . y =-1 . xr = 0 (xr)} Procedure \nADDPREDS The procedure ADDPREDS is shown in Figure 4. It has Sym in scope and takes as input a solution \nfunction whose domain consists of quoted constraints. ADDPREDS uses Sym to translate quoted constraints \ninto original query symbols and add the solution constraints into the corresponding partitions of Preds. \nExample (cont.) Let us assume that the following solution S is returned at line 23 of Figure 4: { xr \n= 0 (xr) .. xr = 0, xs = ys (xs,ys) .. xs <ys} . The solution constraints are partitioned as follows: \nPreds(r)= {xr = 0} and Preds(s)= {xs = ys,xs <ys} . Given these predicates, the next iteration of the \nabstract inference algorithm computes abstract constraints precise enough to satisfy both property clauses \ncl3 and cl4 from our example. Inferred(r)= {xr = 0} Inferred(s)= {xs = ys . xs <ys} Correctness Upon \ntermination, the algorithm HSF computes a solution for the input clauses. The soundness of the approach \nis guaranteed by the fact that the abstraction function is over\u00adapproximating. Our abstraction re.nement \nmethod guarantees that a set of counterexample clauses X is never analyzed twice, i.e., our re.nement \nmethod satis.es the progress of re.nement property. Such soundness and progress of re.nement properties \nare standard for counterexample guided abstraction re.nement schemes.  For assertions {Tf over Vf and \nV . f | f . Procs(P )} , CP1 : init(Vmain ) . Vmain = V . main . Tmain (Vmain , V . main ) CP2 : Tf (Vf \n, V . f ) . .f (V . f , V .. f ) . Tf (Vf , V .. f ) CP3 : Tf (Vf , V . f ) . callf ,g (V . f , V .. \ng ) . V .. g = V ... g . Tg (V .. g , V ... g ) f , g . Procs(P ) such that f calls g CP4 : Tf (Vf , \nV . f ) . callf ,g (V . f , V .. g ) . Tg (V .. g , V ... g ) . retf ,g (V ... g , V .... f ) . locf \n(V . f , V .... f ) . Tf (Vf , V .... f ) f , g . Procs(P ) such that f calls g CP5 : Tf (Vf , V . f \n) . error(V . f ) . false program P is safe Figure 5. Summarization rule for programs with procedures. \nAlternative solving methods In this paper we use predicate ab\u00ad straction and re.nement to solve Horn-like \nclauses. Predicate ab\u00adstraction allows us to formulate a practical algorithm, yet the pre\u00adsented formulation \nis suf.ciently general such that a different ap\u00adproximation techniques can be employed instead without \nany sig\u00adni.cant changes to HSF. For example, abstract domains based on widening can be used to compute \na solution to inference clauses, by choosing the corresponding abstraction function for INFER-ABST. Alternatively, \nwe could use model checking techniques, e.g., bounded model checking, to explore the clauses up to a \n.nite bound. Usually, predicates are atomic constraints; however recent approaches to predicate abstraction \nshow that predicates containing Boolean operators can be useful [7]. 5. Proof rules as Horn-like clauses \nIn this section, we show a collection of proof rules that can be automated using our veri.cation approach. \n5.1 Transition systems We consider a transition system with variables V , a set of initial states init(V \n), a transition relation .(V,V .), and a standard se\u00admantics. Safety Let error(V ) represent a set of \nerror states. To verify safety the transition system, we use an invariance proof rule with conditions \nover a query R(V ) that characterizes reachable states as follows. For assertion R over V , CR1 : init(V \n) . R(V ) CR2 : R(V ) . .(V, V .) . R(V .) CR3 : R(V ) . error(V ) . false transition system P is safe \nCondition CR1 requires that all initial states are present in R(V ). Condition CR2 states that a program \ntransition starting from a state in R(V ) ends in a state that is in R(V .). Finally, CR3 states that \nthe intersection of reachable and error states is empty. Our algorithm HSF .nds a solution for the query \nR(V ). Termination To reason about termination properties of transition systems, we use a proof rule \nbased on transition invariants [37]. The assertion T represents a transition invariant, which is a superset \nof the transitive closure of the transition relation . . For assertion R over V that satis.es CR1 and \nCR2 and assertion T over V and V . , CT1 : R(V ) . .(V,V .) . T (V, V .) CT2 : T (V, V .) . .(V .,V ..) \n. T (V, V ..) CT3 : dwf (T (V, V .)) transition system P terminates We restrict the assertion T (V, V \n.) to states that are reachable using CT1, CT2 and two clauses from the invariance proof rule, CR1 and \nCR2 . The last clause, CT3, uses a predicate symbol dwf of arity one that requires a disjunctive well-founded \nargument T (V, V .) . The existence of a (disjunctive well-founded) transition invariant guarantees program \ntermination, cf. [37].  5.2 Programs with procedures We consider programs with a set of recursive proce\u00addures \nProcs(P ). Let main . Procs(P ) be the procedure that starts the program execution. For each f . Procs(P \n), let Vf the set of variables that are in scope, .f (Vf ,V f .) be the intra-procedural transition relation. \nIf f calls a procedure g . Procs(P ), then let callf ,g (Vf ,V g .) and retf ,g (Vf ,V g .) be parameter \nand return value passing relations, respectively. The relation locf (Vf ,V f .) states which local variables \nof f are not modi.ed during a call to g. Safety We prove safety properties of procedural programs using \na rule based on context-free language reachability [42]. See Figure 5 for the proof rule that consists \nof constraints over assertions Tf , one for each program procedure. A query Tf (Vf ,V f .) represents \na summary of the procedure f , which is a binary relation between entry states of f and their successors \non the same level of recur\u00adsion. For simplicity, our formulation does not adopt the common distinction \nbetween path edges and summaries, see, e.g., [42]. The .rst condition CP1 of the proof rule requires \nthat the ini\u00adtial states constraint implies the query corresponding to the entry procedure main . The \ncondition CP2 extends a query Tf (Vf ,V f .) with a transition relation from the same procedure. The \nthird and fourth conditions handle procedure calls. In CP3, given a query Tf (Vf ,V f .) of the caller \nand the calling context passed from the variables Vf . to Vg .., the result is used to seed the summary \nof the callee procedure g . The condition CP4 is the most complex clause of the proof rule and ensures \nprocedure-modular reasoning. It uses a query from the caller Tf (Vf ,V f .) , links the calling context \nwith  the parameter passing relation callf ,g (Vf .,V ..) , uses the summary g of the callee Tg (Vg \n..,V g ...), passes the return value back in the scope ,V .... of the caller with retf ,g (Vg ... f ) \nand links local variables not af\u00adf ,V .... fected by the call with locf (V . f ) . Finally, the condition \nCP5 requires that states reachable at an arbitrary location in some pro\u00adcedure f do not intersect error \nstates. Termination For proving termination properties, we use the proof rule from Figure 5 with an additional \nwell-foundedness condition that no in.nite recursion is feasible. This condition is imposed on a transition \nrelation that describes recursive descent by com\u00adposing procedure summaries with call relations following \n[12]. Let VP = Vf be the set of variables that occur f .Procs(P ) in all procedures. The technique of \n[12] constructs an assertion Descent(VP ,V P . ) such that the program P terminates if and only if Descent(VP \n,V P . ) is well-founded. By taking a transitive clo\u00adsure of Descent(VP ,V P . ) as described above, \nwe can replace well\u00adfoundedness condition by a disjunctive well-foundedness condi\u00adtion.  5.3 Multi-threaded \nprograms We consider a multi-threaded program that consists of N threads as a tuple (V, init,.1,...,.N \n), where .i is the transition relation of the thread i. The transition relation of the program . is the \ndisjoint union of the N transition relations of the threads. Owicki-Gries rule for proving safety Based \non Owicki-Gries method [36], we present the following proof rule for verifying safety of multi-threaded \nprograms. This proof rule lists conditions over N query symbols Ri that characterize reachable states \nfor each thread i . 1..N . For assertions R1,...,RN over V , CO1 : init(V ) . Ri(V ) CO2 : Ri(V ) . .i(V, \nV .) . Ri(V .) CO3 : Ri(V ) . ( . Rj (V )..j (V, V .)) . Ri(V .) i.1..N\\{j} CO4 : R1(V ) . ...RN (V \n) . error(V ) . false multi-threaded program P is safe The conditions CO1, CO2 and CO4 resemble those \nfrom the invariance proof rule, while the additional condition CO3 ensures that the query Ri(V, V .) \ncorresponding to thread i is free from interference from the transitions of other threads j . The presence \nof distinct query symbols for the reachable states of each thread allows our HSF algorithm to perform \nabstraction at the thread boundaries and leads to more scalable veri.cation compared to the monolithic \nproof rule. Rely-guarantee rule for proving safety As an alternative to the above proof rule, we can \nuse a proof rule based on rely-guarantee reasoning method [25]. The proof rule uses assertions Ri and \nEi that characterize reachable states of each thread i . 1..N and environment transitions of each thread \ni . 1..N, respectively, following [19]. Each assertion Ri(V ) includes the initial states due to CM1. \nStates reachable after executing a transition of thread i or an envi\u00adronment transition Ei(V,V .) are \nin Ri(V .) due to CM2 and CM4 , where . = i requires that the local variables of thread i do not change \nduring an environment step of thread i . CM3 requires that every step of thread i starting from a reachable \nstate is captured by the environment transitions of each other thread j. CM5 ensures that the intersection \nof reachable states and error states is empty. For assertions R1,...,RN over V and E1,...,EN over V, \nV . , CM1 : init(V ) . Ri(V ) CM2 : Ri(V ) . .i(V, V .) . Ri(V .) CM3 : ( . i.1..N\\{j} Ri(V ) . .i(V, \nV .)) . Ej (V, V .) CM4 : Ri(V ) . Ei(V, V .) . . = i (V, V .) . Ri(V .) CM5 : R1(V ) . \u00b7 \u00b7 \u00b7 . RN (V \n) . error(V ) . false multi-threaded program P is safe Rely-guarantee rule for proving termination Rely-guarantee \nreasoning [25] can be combined with the transition invariance proof rule [37] to prove termination properties \nof multi-threaded pro\u00adgrams. The proof rule uses assertions Ti for transition invariants and Ei for environment \ntransitions [39]. For assertions T1,...,TN and E1,...,EN over V, V . , CG1 : init(V ) . .i(V,V .) . Ti(V, \nV .) CG2 : Ti(V, V .) . .i(V .,V ..) . Ti(V .,V ..) CG3 : Ti(V, V .) . .i(V .,V ..) . Ti(V, V ..) CG4 \n:( . init(V ) . .j (V, V .)) . Ei(V, V .) j.1..N\\{i}CG5 :( . Ti(V,V .) . .j (V .,V ..)) . Ei(V .,V ..) \nj.1..N\\{i} ) . . = CG6 : init(V ) . Ei(V,V .i (V, V .) . Ti(V, V .) CG7 : Ti(V, V .) . Ei(V .,V ..) \n. . = i (V, V .) . Ti(V .,V ..) ) . . = CG8 : Ti(V, V .) . Ei(V .,V ..i (V, V .) . Ti(V, V ..) CG9 : \ndwf (T1(V, V .) .\u00b7 \u00b7\u00b7. TN (V, V .)) multi-threaded program P terminates The conditions CG1 and CG2 require \nthat Ti over-approximates the transition relation of the thread i restricted to initial states and to \narbitrary reachable states. The condition CG3 extends Ti with a relation from .i . The conditions CG4 \nand CG5 populate the environment transitions of thread i with steps of all threads other than i . The \nthree conditions CG6, CG7 and CG8 are similar to the .rst three conditions except local transitions from \n.i are replaced by environment transitions Ei .. = i . As before, . = i requires that the local variables \nof thread i do not change during an environment step of thread i . The .nal condition CG9 ensures that \nthe conjunction of the transition invariant queries, T1(V, V .) .\u00b7\u00b7\u00b7. TN (V, V .) , is disjunctively \nwell-founded. 6. Experiments In this section we present an experimental comparison between veri.ers developed \nusing our HSF algorithm and state-of-the-art veri.cation tools developed using traditional methods. Our \ntool HSF is implemented in Prolog and compiled with the SICStus Prolog 4.2.0 compiler. The implementation \nrelies on a built-in constraint solver for linear arithmetic. For C programs, we use the CIL library \n[35] and an additional frontend step that produces clauses for various proof rules. For verifying OCaml \nprograms, we use DSolve [43] to generate automatically subtyping constraints and then our code translates \nthese constraints to Horn\u00adlike clauses. Benchmarks We used several sets of benchmarks for our experi\u00adments. \n Program BLAST CPAchecker HSF Numerical Recipes amebsa FAIL T/O 0.2s amotsa FAIL 2.3s 0.2s bandec T/O \nT/O T/O choldc 14.1s 2.7s 2.6s crank 6.0s 1.9s 0.9s cyclic FAIL T/O 2.2s four1 FAIL T/O T/O lop FAIL \nFAIL 0.7s pzextr 11.2s FAIL 0.1s qrdcmp 75.2s T/O 12.2s qrsolv FAIL 3.3s 0.1s rsolv T/O 33.6s 0.2s spline \nFAIL 1.6s 0.3s tridag 4.1s 1.5s 0.3s ntdrivers cdaudio simpl1 64.8s 24.9s 393s diskperf simpl1 41.9s \n21.1s 213s .oppy simpl3 30.9s 10.3s 67s .oppy simpl4 50.1s 16.3s 139s kb.ltr simpl1 3.7s 2.7s 3.2s kb.ltr \nsimpl2 5.5s 4.0s 7.2s cdaudio simpl1 BUG 29.3s 12.3s 351s .oppy simpl3 BUG 1.5s 7.5s 96s .oppy simpl4 \nBUG 1.5s 12.9s 135s kb.ltr simpl2 BUG 3.1s 3.2s 14.7s ssh-simpli.ed s3 clnt 1 103s 8.0s 7.4s s3 clnt \n2 147s 59s 4.2s s3 clnt 3 FAIL 7.4s 7.3s s3 clnt 4 80s 9.7s 6.6s s3 srvr 1 FAIL 23.2s 9.8s s3 srvr 2 \nFAIL 40.0s 10.1s s3 srvr 3 FAIL 9.9s 36.1s s3 srvr 4 FAIL 11.3s 8.9s s3 srvr 6 110s 41.9s 49.5s s3 srvr \n7 FAIL 14.0s 133s s3 srvr 8 41.5s 11.1s 23.1s s3 clnt 1 BUG 4.5s 3.0s 1.3s s3 clnt 2 BUG 4.9s 2.6s 1.4s \ns3 clnt 3 BUG 4.9s 2.9s 1.3s s3 clnt 4 BUG 4.6s 3.0s 1.4s s3 srvr 1 BUG FAIL 2.6s 3.1s s3 srvr 2 BUG \n66s 2.5s 2.2s Program Threader HSF Multi-threaded programs Fig2-cex-BUG 0.2s 0.1s Fig2-.xed 0.8s 0.7s \nFig4-cex-BUG 4.5s 0.5s Fig4-.xed 1.5s 0.5s Bluetooth2 29.1s 12.9s Bluetooth2-.xed 3.7s 0.2s Bluetooth3-.xed \n135s 18.6s Scull 129s 11.6s Dekker 11.1s 4.0s Peterson 4.7s 3.7s Readers-writer-lock 0.2s 0.1s Time varying \nmutex 11.8s 9.8s Szymanski 32s 8.7s NaiveBakery 2.5s 2.6s Bakery 105s 32.4s Lamport 121s 30.5s QRCU 34.5s \n15.4s Program HMC HSF OCaml programs (correct / buggy) na dotprod-m 0.04s / 0.04s 0.11s / 0.06s na arraymax-m \n0.32s / 0.05s 0.05s / 0.07s na bcopy-m 0.09s / 5.94s 0.06s / 0.07s na bsearch-m 0.91s / 0.10s 0.03s / \n0.02s na insertsort-m 0.03s / 0.03s 1.78s / 0.04s mult-cps-m 0.03s / 0.03s 0.03s / 0.03s mult-all-m 0.03s \n/ 0.03s 0.01s / 0.01s sum-all-m 0.03s / 0.03s 0.01s / 0.01s sum-acm-m 0.04s / 0.03s 0.01s / 0.01s Program \nHSF Terminating loops broydn (33 cutpoints) 591s elmhes (9 cutpoints) 23.0s jacobi (15 cutpoints) 16.0s \nludcmp (11 cutpoints) 4.2s qrdcmp (9 cutpoints) 189s rlft3 (7 cutpoints) 16.1s spctrm (14 cutpoints) \n86s  Table 1. Timings for the benchmarks. The left-side of the page shows statistics for sequential \nprograms, with multi-threaded programs, functional programs and terminating loops on the right-side of \nthe page. T/O stands for time out after 10 minutes, while FAIL indicates that the tool failed to return \na veri.cation result. For veri.cation of sequential programs, we used a set of pro\u00adgrams from the Numerical \nRecipes book [40], with array bound checking being the safety property to verify. This set of bench\u00admarks \nincludes simulated annealing (amebsa), evaluate a trial point using simulated annealing (amotsa), fast \nfourier transform (four1), or polynomial extrapolation (pzextr). We also used two sets of benchmarks \n(ntdrivers and ssh-simpli.ed) from the test suite of CPAchecker [7]. We collected multi-threaded and \nfunctional programs from the test suites of specialized veri.cation tools, i.e., Threader [18] and HMC \n[24]. For termination checking, we used a set of programs from the Numerical Recipes book, including \na secant method pro\u00adgram (broydn), and a program to reduce a matrix to the Hessenberg form (elmhes). \nOur benchmark suite includes both safe and non-safe programs. Non-safe programs have the word BUG attached \nto their name. For termination checking, all the benchmarks are terminating and we report the number \nof cutpoints as a measure for the effort to verify program termination.  Evaluation Our experiments \nwere run on an Intel Core 2 Duo machine, clocked at 3.0 GHz, with 4 GB of RAM, and running Linux 2.6.38. \nSee Table 1 for the results. For the .rst three categories of benchmarks (Numerical Recipes, ntdrivers \nand ssh-simpli.ed), we used HSF with the summarization proof rule described in Section 2. For the veri\u00ad.cation \nof these sequential C programs, we compare HSF with BLAST [20, 21] and CPAchecker [7]. For ntdrivers \nand ssh\u00adsimpli.ed, we used BLAST 2.5 with the MathSat solver [9] and the following standard options: \n-craig 2 -dfs -predH 7 -nosimplemem -alias \"\", as suggested by the tool s authors. The use of the MathSat \nsolver led to Blast failing all the Numerical Recipes benchmarks, so instead we report statistics using \nthe lat\u00adest publicly available version of Blast that uses the Simplify solver. For CPAchecker, we used \nthe revision r3842 from the tool repos\u00aditory and used the predicate abstraction with large block encoding \ncon.guration as suggested by the tool s authors. For veri.cation of multi-threaded programs, we used \nHSF with a proof rule based on rely-guarantee reasoning [25]. We compare HSF with Threader using a reasoning \nstyle that is equivalent to the proof rule mentioned above. For the veri.cation of functional OCaml programs, \nwe compare HSF with HMC [24]. The techniques used in HMC extend a liquid type system (i.e., [43] that \nrequires user-provided logical quali.ers) to enable automatic veri.cation of OCaml programs. We used \nHSF with a termination proof rule for the programs from the last table, Terminating loops. We do not \nhave access to any public tool that can handle termination properties for these C benchmarks. In general, \nHSF is comparable and sometimes signi.cantly faster than state-of-the-art tools specialized to a particular \nveri.\u00adcation proof rule. For all our experiments, the veri.cation tools (in\u00adcluding HSF) were run starting \nwith an empty set of predicates, i.e., all predicates needed for veri.cation were discovered automat\u00adically. \nTwo limitations of our implementation lead to HSF being slower for the ntdrivers benchmarks: no direct \nsupport for equality predicates and the program representation with the transition rela\u00adtion in disjunctive \nnormal form. For example, instead of a single equality predicate (say x = y), HSF tracks two predicates, \ni.e., x = y and x = y , both during abstraction and re.nement. We plan to implement heuristics to handle \nthe high level of branching present in this set of benchmarks. On the other hand, we lever\u00adage the uniform \nrepresentation of the Horn clauses for simpli.\u00adcation and inlining steps before the start of the veri.cation \npro\u00adcess. These transformations lead to substantial savings that are par\u00adticularly effective in the Numerical \nRecipes, multi-threaded, and OCaml benchmarks. In total, HSF took approximately 48 minutes to analyze \n35 kloc (we exclude the lines of code for the two pro\u00adgrams on which HSF timed out). We applied our tool \non benchmarks from various classes of ver\u00adi.cation problems, which are usually approached using specialized \ntools. Veri.cation competition HSF(C) is a veri.er for C programs de\u00adveloped using the HSF algorithm \nand based on the summarization proof rule. HSF(C) participated in the TACAS2012 software veri.\u00adcation \ncompetition [6] and reached the 3rd place in the largest cate\u00adgory ControlFlowInteger and it competed \nwith recent implementa\u00adtions of Blast, CPAchecker and 6 more veri.cation tools. (HSF(C) did not participate \nin the other categories that required bit-precise reasoning or pointer analysis features not supported \nby our CIL frontend.) For the ControlFlowInteger category, HSF(C) analyzed 96 benchmarks from .ve groups: \nlocks, ntdrivers, ntdrivers-simpli.ed, ssh and ssh-simpli.ed. Each of these benchmarks consists of a \nC program and a safety property, which may or may not hold. HSF timed out on 2 of these programs, verifying \nand .nding counterex\u00adamples correctly for all the others, in total 207.2 kloc analyzed in 80 minutes. \nMore details about HSF(C) can be found in the related competition report [16]. 7. Related work Section \n1 points to existing approaches to generate various analyses based on data.ow domains that led to powerful \nprogram analysis frameworks [3, 27 29, 31, 34, 47, 51]. Veri.ers have also been a target for automated \ntool construc\u00adtion. XSB [41] is a programmable .xed-point engine used for im\u00adplementing model checkers \nfor a concurrent language based on CCS with properties speci.ed in a fragment of mu-calculus. Model checkers \nhave been generated from algebraic speci.cations of a source language and various fragments of temporal \nlogic [45]. More recently, veri.er generators have been developed for Boolean programs (GETAFIX [49]) \nand programs for which Datalog style bottom up inference terminates (\u00b5Z [22]). For programs with un\u00adbounded \ndata domains, MatchC [44] provides a veri.er based on matching logic speci.cations that directly build \nupon the opera\u00adtional semantics of the source language. The veri.cation is facil\u00aditated by (pattern) \nloop invariants provided by the programmer. In comparison, our approach adds an abstraction re.nement \nloop, which is crucial for handling unbounded datatypes, and allows au\u00adtomation of proof rules for termination \nand liveness properties. HSF synthesizes veri.ers that are competitive with state-of\u00adthe-art tools from \na recent veri.cation competition, while bene.t\u00ading from a series of veri.cation algorithms. We build \nupon pred\u00adicate abstraction [15], counterexample guided abstraction re.ne\u00adment [10], interpolation [32], \nranking function generation [8, 38], and constraint solvers for recursion-free Horn clauses [17, 19, \n39]. Our work provides an intermediate representation for veri.ca\u00adtion tasks in the form of Horn-like \nclauses with the support for a dwf -predicate. This representation was inspired by the usage of Horn \nclauses for the inference of environment assumptions of multi-threaded programs [19]. Boogie provides \na different interme\u00addiate representation for procedural and object-oriented programs. Boogie represents \nprograms and therefore it requires an interme\u00addiate step to generate veri.cation conditions, while Horn \nclauses encode veri.cation tasks directly as constraints. We believe that generation of Horn clauses \nfrom Boogie programs will yield yet another veri.cation tool for Boogie and all of its input languages. \n8. Conclusion We presented a next logical step towards the automatic generation of software veri.cation \ntools. Our veri.er generator takes as input a proof rule written as Horn-like clauses and produces a \nveri.er that automates the proof rule. The experimental evaluation shows that automatically generated \nveri.ers are competitive with existing state-of-the-art veri.cation tools that are manually developed \nand tuned. Acknowledgments We thank Jasmin Blanchette for comments and suggestions. References [1] A. \nV. Aho, M. S. Lam, R. Sethi, and J. D. Ullman. Compilers: Principles, Techniques, and Tools. Pearson, \n2006.  [2] A. Aiken. Introduction to set constraint-based program analysis. Sci. Comput. Program., 35(2), \n1999. [3] A. Aiken, M. F\u00a8 A toolkit for con\u00ad ahndrich, J. S. Foster, and Z. Su. structing type-and constraint-based \nprogram analyses. In Types in Compilation, 1998. [4] T. Ball and S. K. Rajamani. The SLAM project: debugging \nsystem software via static analysis. In POPL, 2002. [5] T. Ball, A. Podelski, and S. K. Rajamani. Boolean \nand cartesian abstraction for model checking C programs. In TACAS, 2001. [6] D. Beyer. Competition on \nsoftware veri.cation -(SV-COMP). In TACAS, 2012. [7] D. Beyer and M. E. Keremoglu. CPAchecker: A tool \nfor con.gurable software veri.cation. In CAV, 2011. [8] A. R. Bradley, Z. Manna, and H. B. Sipma. Linear \nranking with reachability. In CAV, 2005. [9] R. Bruttomesso, A. Cimatti, A. Franz\u00b4 en, A. Griggio, and \nR. Sebastiani. The MathSAT 4SMT solver. In CAV, 2008. [10] E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, \nand H. Veith. Counterexample-guided abstraction re.nement. In CAV, 2000. [11] B. Cook, A. Podelski, and \nA. Rybalchenko. Termination proofs for systems code. In PLDI, 2006. [12] B. Cook, A. Podelski, and A. \nRybalchenko. Summarization for termi\u00adnation: no return! Formal Methods in System Design, 35(3), 2009. \n[13] C. Flanagan and S. Qadeer. Thread-modular model checking. In SPIN, 2003. [14] T. Freeman and F. \nPfenning. Re.nement types for ML. In PLDI, 1991. [15] S. Graf and H. Sa\u00a8idi. Construction of abstract \nstate graphs with PVS. In CAV, 1997. [16] S. Grebenshchikov, A. Gupta, N. P. Lopes, C. Popeea, and A. \nRy\u00adbalchenko. HSF(C): A software veri.er based on Horn clauses -(com\u00adpetition contribution). In TACAS, \n2012. [17] A. Gupta, C. Popeea, and A. Rybalchenko. Solving recursion-free horn clauses over LI+UIF. \nIn APLAS, 2011. [18] A. Gupta, C. Popeea, and A. Rybalchenko. Threader: A constraint\u00adbased veri.er for \nmulti-threaded programs. In CAV, 2011. [19] A. Gupta, C. Popeea, and A. Rybalchenko. Predicate abstraction \nand re.nement for verifying multi-threaded programs. In POPL, 2011. [20] T. A. Henzinger, R. Jhala, R. \nMajumdar, and G. Sutre. Lazy abstrac\u00adtion. In POPL, 2002. [21] T. A. Henzinger, R. Jhala, R. Majumdar, \nand K. L. McMillan. Ab\u00adstractions from proofs. In POPL, 2004. [22] K. Hoder, N. Bj\u00f8rner, and L. de Moura. \n\u00b5Z-an ef.cient engine for .xed points with constraints. In CAV, 2011. [23] F. Ivancic, Z. Yang, M. K. \nGanai, A. Gupta, I. Shlyakhter, and P. Ashar. F-Soft: Software veri.cation platform. In CAV, 2005. [24] \nR. Jhala, R. Majumdar, and A. Rybalchenko. HMC: Verifying func\u00adtional programs using abstract interpreters. \nIn CAV, 2011. [25] C. B. Jones. Tentative steps toward a development method for inter\u00adfering programs. \nACM Trans. Program. Lang. Syst., 5(4), 1983. [26] K. W. Knowles and C. Flanagan. Type reconstruction \nfor general re.nement types. In ESOP, 2007. [27] J. Kodumal and A. Aiken. Banshee: A scalable constraint-based \nanalysis toolkit. In SAS, 2005. [28] M. S. Lam, J. Whaley, V. B. Livshits, M. C. Martin, D. Avots, M. \nCarbin, and C. Unkel. Context-sensitive program analysis as database queries. In PODS, 2005. [29] S. \nLerner, T. D. Millstein, E. Rice, and C. Chambers. Automated soundness proofs for data.ow analyses and \ntransformations via local rules. In POPL, 2005. [30] Z. Manna and A. Pnueli. Temporal veri.cation of \nreactive systems: safety. 1995. [31] F. Martin. PAG An ef.cient program analyzer generator. STTT,2 (1), \n1998. [32] K. L. McMillan. An interpolating theorem prover. TCS, 2005. [33] K. L. McMillan. Lazy abstraction \nwith interpolants. In CAV, 2006. [34] M. Naik, A. Aiken, and J. Whaley. Effective static race detection \nfor Java. In PLDI, 2006. [35] G. C. Necula, S. McPeak, S. P. Rahul, and W. Weimer. CIL: Intermedi\u00adate \nlanguage and tools for analysis and transformation of C programs. In CC, 2002. [36] S. S. Owicki and \nD. Gries. An axiomatic proof technique for parallel programs I. Acta Inf., 6, 1976. [37] A. Podelski \nand A. Rybalchenko. Transition invariants. In LICS, 2004. [38] A. Podelski and A. Rybalchenko. A complete \nmethod for the synthesis of linear ranking functions. In VMCAI, 2004. [39] C. Popeea and A. Rybalchenko. \nCompositional termination proofs for multi-threaded programs. In TACAS, 2012. [40] W. H. Press, B. P. \nFlannery, S. A. Teukolsky, and W. T. Vetterling. Numerical Recipes in C: The Art of Scienti.c Computing. \n1992. [41] Y. S. Ramakrishna, C. R. Ramakrishnan, I. V. Ramakrishnan, S. A. Smolka, T. Swift, and D. \nS. Warren. Ef.cient model checking using tabled resolution. In CAV, 1997. [42] T. W. Reps, S. Horwitz, \nand S. Sagiv. Precise interprocedural data.ow analysis via graph reachability. In POPL, 1995. [43] P. \nM. Rondon, M. Kawaguchi, and R. Jhala. Liquid types. In PLDI, 2008. [44] G. Rosu and A. Stefanescu. Matching \nlogic: a new program veri.ca\u00adtion approach. In ICSE, 2011. [45] T. Rus, E. V. Wyk, and T. Halverson. \nGenerating model checkers from algebraic speci.cations. Formal Methods in System Design, 20(3), 2002. \n[46] A. Rybalchenko and V. Sofronie-Stokkermans. Constraint solving for interpolation. In VMCAI, 2007. \n[47] M. Sagiv. High Level Formalisms for Program Flow Analysis and their use in Compiling. PhD thesis, \nTechnion, 1991. [48] T. Terauchi. Dependent types from counterexamples. In POPL, 2010. [49] S. L. Torre, \nP. Madhusudan, and G. Parlato. Analyzing recursive programs using a .xed-point calculus. In PLDI, 2009. \n[50] H. Unno and N. Kobayashi. Dependent type inference with inter\u00adpolants. In PPDP, 2009. [51] J. Whaley \nand M. S. Lam. Cloning-based context-sensitive pointer alias analysis using binary decision diagrams. \nIn PLDI, 2004.   \n\t\t\t", "proc_id": "2254064", "abstract": "<p>Automatically generated tools can significantly improve programmer productivity. For example, parsers and dataflow analyzers can be automatically generated from declarative specifications in the form of grammars, which tremendously simplifies the task of implementing a compiler. In this paper, we present a method for the automatic synthesis of software verification tools. Our synthesis procedure takes as input a description of the employed proof rule, e.g., program safety checking via inductive invariants, and produces a tool that automatically discovers the auxiliary assertions required by the proof rule, e.g., inductive loop invariants and procedure summaries. We rely on a (standard) representation of proof rules using recursive equations over the auxiliary assertions. The discovery of auxiliary assertions, i.e., solving the equations, is based on an iterative process that extrapolates solutions obtained for finitary unrollings of equations. We show how our method synthesizes automatic safety and liveness verifiers for programs with procedures, multi-threaded programs, and functional programs. Our experimental comparison of the resulting verifiers with existing state-of-the-art verification tools confirms the practicality of the approach.</p>", "authors": [{"name": "Sergey Grebenshchikov", "author_profile_id": "81502798120", "affiliation": "Technical Universit&#228;t M&#252;nchen, Munich, Germany", "person_id": "P3471278", "email_address": "grebensh@cs.tum.edu", "orcid_id": ""}, {"name": "Nuno P. Lopes", "author_profile_id": "81467640765", "affiliation": "INESC-ID / IST - TU Lisbon, Lisbon, Portugal", "person_id": "P3471279", "email_address": "nuno.lopes@ist.utl.pt", "orcid_id": ""}, {"name": "Corneliu Popeea", "author_profile_id": "81100461244", "affiliation": "Technical Universit&#228;t M&#252;nchen, Munich, Germany", "person_id": "P3471280", "email_address": "popeea@model.in.tum.de", "orcid_id": ""}, {"name": "Andrey Rybalchenko", "author_profile_id": "81442607569", "affiliation": "Technical Universit&#228;t M&#252;nchen, Germany", "person_id": "P3471281", "email_address": "rybal@in.tum.de", "orcid_id": ""}], "doi_number": "10.1145/2254064.2254112", "year": "2012", "article_id": "2254112", "conference": "PLDI", "title": "Synthesizing software verifiers from proof rules", "url": "http://dl.acm.org/citation.cfm?id=2254112"}