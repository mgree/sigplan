{"article_publication_date": "06-11-2012", "fulltext": "\n Speculative Linearizability RachidGuerraoui ViktorKuncak GiulianoLosa School ofComputer andCommunicationSciences \nSwissFederalInstitute ofTechnologyLausanne(EPFL) rachid.guerraoui@ep..ch viktor.kuncak@ep..ch giuliano.losa@ep..ch \nAbstract Linearizability is a key design methodology for reasoning about implementations of concurrent \nabstract data types in both shared memory and messagepassing systems.Itprovides theillusion that operations \nexecute sequentially and fault-free, despite the asyn\u00adchrony andfaultsinherent to a concurrent system, \nespecially adis\u00adtributed one. A key property of linearizability is inter-object com\u00adposability: a system \ncomposed of linearizable objects is itself lin\u00adearizable. However, devising linearizable objects is very \ndif.cult, requiring complex algorithms to work correctly under general cir\u00adcumstances, and often resultinginbad \naverage-casebehavior.Con\u00adcurrent algorithm designers therefore resort to speculation: opti\u00admizing algorithms \nto handle common scenarios more ef.ciently. The outcome are even more complex protocols, for which it \nis no longer tractable toprove their correctness. To simplify the design of ef.cient yet robust linearizable \npro\u00adtocols, we propose a new notion: speculative linearizability. This property is as general as linearizability, \nyet it allows intra-object composability: the correctness of independent protocolphases im\u00adplies the \ncorrectness of their composition. In particular, it allows thedesigner tofocus solely on theproof of \nan optimization andde\u00adrivethecorrectness of theoverallprotocolfromthecorrectness of the existing, non-optimized \none. Ournotion ofprotocolphases allowsprocessestoindependently switch from one phase to another, without \nrequiring them to reach agreement todetermine the change of aphase.Toillustrate the ap\u00adplicability of \nour methodology, we show how examples of spec\u00adulative algorithms for shared memory and asynchronous message \npassing naturally.tintoourframework. We rigorously de.ne speculative linearizability and prove our intra-object \ncomposition theorem in a trace-based as well as an automaton-based model. To obtain a further degree \nof con.dence, we also formalize and mechanically check the theorem in the automaton-based model,using \ntheI/O automataframework within the Isabelle interactive proof assistant. We expect our framework to \nenable, for the .rst time, scalable speci.cations and mechanical proofs ofspeculativeimplementations \noflinearizable objects. Categories and Subject Descriptors D.1.3 [Software]: Concur\u00adrentProgramming Keywords \nSpeculation,DistributedSystems,Modularity Permission to make digital or hard copies of all or part of \nthis work for personal or classroomuseisgranted withoutfeeprovided that copiesarenot madeordistributed \nforpro.tor commercial advantage andthat copiesbearthis notice andthefull citation onthe .rstpage.Tocopy \notherwise,torepublish,topostonservers ortoredistribute tolists, requiresprior speci.cpermission and/or \nafee. PLDI 12, June11 16,2012,Beijing,China. Copyright c . 2012ACM978-1-4503-1205-9/12/06. . .$10.00 \n  1. Introduction The correctness of a system of processes communicating through linearizable objects[12,17,18] \nreduces tothe correctness ofthe sequential executions of that system. In other words, linearizabil\u00adityreduces \nthedif.cultproblem of reasoning about concurrentdata types to that of reasoning about sequential ones. \nIn this sense, the use of linearizable objects greatly simpli.es the construction of concurrent systems.At \n.rstglance,thedesignandimplementation oflinearizable objectsthemselveslooks also simple.One canfocus \non each objectindependently,designthe underlyinglinearizable al\u00adgorithm,implementandtestit,andthen composeit \nwith algorithms ensuring the linearizability of the other objects of the system. In short,linearizabilityispreservedby \ninter-object composition: a set of objects is linearizable if and only if each object is linearizable \nwhen considered independently of the others. However, it is extremely dif.cult to devise ef.cient and \nrobust implementations ofalinearizable object, even when consideredin\u00addependently from the others.Thedif.culty \nstemsfrom thefollow\u00adingdilemma.Onthe onehand, achievingrobustnessin a concurrent system requires assumingthatthe \nscheduling ofprocesses, commu\u00adnication, andfaultsis completely nondeterministic.The objectdoes notknow \nwhich execution isgoing to unfoldbut needs todeliver a response to each ofits methodinvocations no matter \nthe execution. The objecthastopreparefor allscenarios, usingupitsresourcesfor thattask.This conservative \napproach typicallyyields wait-free [11] butinef.cientstrategies.Onthe otherhand, achieving ef.ciency \nre\u00adquires speculating that only a small subset of executions is likely to occur[23].Thisispractically \nappealingbecause a real system typically spends most of its time in a common case and seldom experiencesperiods \nof alternative executions.Should the objectfo\u00adcus on a very small subset of executions, it would save \nresources bypreparing onlyfor that restricted subset.Typically, the common cases that are usually considered \nin practice are those where the system is synchronous, there is no failure, contention is not very high, \na speci.c conditional branch is to be considered, etc. At a highlevel, a speculative system repeats thefollowing \nsteps: 1. Speculate about thelikelihoodof certain executions and choose a corresponding algorithm. 2. \nInitialize the chosen algorithm. 3. Monitor the algorithm to estimate if the speculation was accu\u00adrate.If \nnot, abort the algorithm and recover a consistent state.  Examples of speculation include the Ethernet \nprotocol, where processes speculatively occupy a single-user communication medium before backing off \nif collision is detected, or branch pre\u00addiction in microprocessors, where the processor speculates that \na particular branch in the code will be taken before discarding its computation if this is not the case. \nMore recent instances of spec\u00adulationinclude optimistic replication[15] or adaptive mutual ex\u00adclusion[14].Infact,mostpractical \nconcurrent systems are specu\u00adlative. In general, speculative systems may choose between many different \noptions, or speculation phases, in order to closely match a changing common case.  To illustrate the \nchallenges addressed in this work, consider a speculative algorithm that may switch between any two of \nn speculationphasesin a safe manner.Thatis, recovering a consistent state of the .rst phase and then \ninitializing the second. Doing so in an ad-hoc manner poses two major scalability problems to the designprocess.First,there \nareO(n 2 ) differentswitching casesthat need to be carefully handled in order to preserve linearizability. \nSecond, adding a new phase to an object composed of n phases built ad-hoc may require deep changes to \nall of the n existing phases. The case ofStateMachineReplication[16](abbreviatedSMR), used tobuild robustlinearizable \nobjectimplementations,illustrates thoseproblems.Non-speculativeSMR algorithmslikePaxos[7] or PBFT[6] \nare notoriouslyhard to understand.Theformal correct\u00adnessproof ofDiskPaxos[13]took about7000lines.Only \naninfor\u00admalproof,35pageslong, of a simpli.ed version ofPBFTisknown to the authors[5].SpeculativeSMRprotocols \nare even harder.For instance, the Zyzzyva [15] protocol combines PBFT with a fast pathimplementedbya \nsimple agreementprotocol.Thefastpathis more ef.cient than PBFT when there are nofailures.In the advent \nof failures, the fast path cannot make progress and Zyzzyva falls back to executing PBFT. The ad-hoc \ncomposition of the fast path with PBFT required deep changes to both algorithms and resulted in an entanglement \nthat is hardly understandable. Although PBFT hadpreviouslybeen widelytested[5],Zyzzyva sufferedfromfrag\u00adile \nimplementations and no correctness proof has ever been pro\u00adposed.Infact,Zyzzyva,beingrestrictedtotwophases,is \nveryfrag\u00adile[24].Ifthe common caseis notwhatis expectedby thefastpath one falls-back to PBFT, making \nthe optimization useless. An ad\u00adversary can easily weaken the system by always making it abort the fast \npath and go through the slow one. Introducing a new di\u00admension of speculation might make the protocol \nmore robust but would require a new ad-hoc composition, including an alternative fast-path,at a cost \ncomparabletothe effort neededtobuildZyzzyva from scratch, namely a Dantean effort. Given the diversity \nof situ\u00adations encountered in practice, we are convinced that this ad-hoc approach is simplyintractable. \nContributions. We propose in this paper a framework for de\u00advising, reasoning about, and mechanically \nverifying effective and robust linearizable implementations of concurrent data types in a scalable way. \nIn short, we show how speculative implementations oflinearizable objects canbedevised and analyzedin \nan incremen\u00adtal manner. One can focus on each dimension of speculation inde\u00adpendentlyoftheothers.Forexample,aprogrammercan \n.rstdevise an algorithm with no speculation,implement,test, andproveit cor\u00adrect, then augmentitlater \nwith an optimization that speculates that a certain subset of executionsis morelikely to occur(say thereis \nno failure). This optimization sub-algorithm is composed with the original one asis.Later, anotherprogrammer \ncan consider otherdi\u00admensions of speculations(saythereis no contention or asynchrony) and add newphases, \nstillwithout modifyingthe originalimplemen\u00adtation andproofs. At the heart of our framework lies our new \nnotion, speculative linearizability. Speculative linearizability encompasses the notion of switch actions, \nwhich makesit signi.cantly richer thanlineariz\u00adability,yet it reduces tolinearizabilityif these actions \nare ignored. Speculativelinearizability augments classicallinearizability with a new aspect of composition. \nNot only a system of concurrent ob\u00adjectscanbe considered correctifeachofthemiscorrect(inter\u00adobject composition),buta \nset of algorithmsimplementingdifferent speculation phases of the same object is correct if each of them \nis correct(intra-object composition). We express this new aspect 1: //Shared Register V ,Initially . \n2: Function propose(val): 3: if V = . then 4: V . val 5: return val 6: else 7: return V 8: endif Figure1. \nConsensusSpeci.cation through a new composition theorem which we state andprove. In\u00adtuitively, speculative \nlinearizability captures the idea of safe and live abortability. An implementation can abort if the assumptions \nbehind speculation reveals wrong.Whenitdoes abort,itdoes soin a safe manner,bypreserving the consistency(linearizability) \nofthe object state.Moreover,the abortis alsoperformedin alive manner, because a newprotocolphase can \nresume and makeprogress.Pro\u00adcesses can switchindependentlyfrom onephaseto another, without the need to \nreach agreement.Our notion of speculativelinearizabil\u00adityisitselfbased on a newde.nition oflinearizability.Thisde.ni\u00adtion \nis interesting in its own right because it enables a more local form of reasoning than the original de.nition \nand it allows for re\u00adpeatedevents, which are the norminpractice.Wehaveproved that our new de.nition of \nlinearizability is equivalent to the classical de.nition. The generality of our framework and its Isabelle/HOL \nformal\u00adization[10] setsour work apartfromstateoftheartinthearea [1,2,8]:weenableforthe .rsttimescalablemechanically-checked \ndevelopment oflinearizable objects of arbitrary abstractdatatypes. Additionalproofs andformalizations \nare availablein[9,10], as well as at http://lara.epfl.ch/w/slin.  2. PuttingSpeculativeLinearizability \ntoWork In this section we provide intuition for speculative linearizability anditskeyproperty:intra-object \ncomposability.Ourgoalis to mo\u00adtivate correct-by-construction design of objects based on specula\u00adtion \nphases. As an illustration, we present two speculative imple\u00admentationsof aconsensus object.Eachiscomposed \nof twospecu\u00adlationphases.The .rstappliestothemessage-passing computation model and the othertothe shared-memory \nmodel.We analyze each phase of those speculative implementations in isolation and con\u00adclude, using the \nintra-object composition theorem, that their com\u00adpositions are correctimplementations ofconsensus. 2.1 \nMessage-PassingConsensus Our .rst example is a consensus implementation in a system com\u00adposed of client \nand server processes which communicate by asyn\u00adchronous messagepassing and which may crash atanypoint.Our \ngoal is to implement consensus among the clients. Notable use cases of consensus in message-passing systems \ninclude Google s Chubbydistributedlockservice[4]andtheGaios reliabledata store [3]. Consensus allows \na set of clients to agree on a common value. Clients each propose a value and should receive a common \ndeci\u00adsion value taken among their proposals. We consider implemen\u00adtations that offer an invocation function \npropose(value) to each of its clients. The invocation propose(val) returns another value indicating the \ncommon decision. When a process returns from propose(value) with a value d, we say the it decides value \nd. An algorithm is linearizable with respect to the consensus data type if all calls to propose(val) \nappear as if they executed atomically the algorithminFigure1 at somepoint aftertheirinvocation(we assume \nthatproposal aredifferentfrom .).  In an asynchronous message-passing system where processes may crash, \nthere is no component which can reliably hold state. Hence,some crucialdata maybecome unavailableduetothefailure \nof a process. For example, a process may decide some value and then crash before informing any other \nprocess of its decision. In this case other processes have no way to know which value the crashed process \ndecided and they cannot decide without risking to violate consensus. Paxos[7]is an algorithm thatimplements \nconsensusiflessthan half of the servers may fail. Paxos has a minimum latency of 3 message delays. However, \nsuppose that executions are fault free and contentionfree(i.e.thetimeintervalsdelimitedby correspond\u00adinginvocations \nand responses do not overlap).Under this assump\u00adtion, very simple algorithms can solve consensus much \nfaster than Paxos, which stillhas a minimumlatency of3 messagedelays. We would like to optimize Paxos \nfor the fault-free and contention-free case. This could be done ad-hoc by adding a fast path inside Paxos. \nHowever, Paxos is a very intricate algorithm: theproof ofDiskPaxos[7],a variant ofPaxos,is7000lineslong \n[13]. Addinga fast path to Paxos would require re-examining the correctness of the entire algorithm, \nbecause the fast path is inter\u00adleaved with executions of the othersparts.The entireproof would, inprinciple, \nneed tobe rewritten. Our framework allows us to optimize Paxos without directly modifying the original \nalgorithm, and enables reasoning about the correctness ofthe optimizationindependently ofthebasicPaxosit\u00adself. \nTo use our framework, we wrap Paxos in a simple interface that allows composition with other speculation \nphases. This re\u00adquires addingatriviallevel ofindirection and makesPaxos a specu\u00adlationphaseinits own \nright.Speculativelinearizabilityensuresthat any speculatively linearizable speculation phase can be composed \nwith the Paxos speculation phase to form a correct implementa\u00adtion of consensus. Moreover, speculative \nlinearizability, instanti\u00adatedforconsensus,isaproperty independent ofPaxos.Therefore, from thepoint of \nview of algorithmdesigners, speculativelineariz\u00adabilityhides theinternal complexity ofPaxos. In this \nexample we compose Paxos with the Quorum specula\u00adtionphase,inspiredfrom[8].Quorum manages todecide on \nthe value in only 2 message delays, whenever there is neither con\u00adtention norfaults.Iffaults or contentionhappen,Quorum \ncannot decide andinsteadpasses controltoPaxos.Inthis case, we saythat Quorumswitches toPaxos.From then \non,Paxos takes over the ex\u00adecution and can decide as long as less than half of the processes are faulty. \nTo highlight that Paxos is used as a backup when opti\u00admizationbyQuorum is notpossible, we call thePaxos \nspeculation phaseBackup.Usingspeculative linearizability, we willprove that the composition ofQuorum \nandBackupislinearizableby reason\u00ading aboutQuoruminisolationandby reusing anexistingproof of Paxos. By \ncombining Quorum and Backup we obtain a system that is optimized for contention-free and fault-free loads \nwhile still re\u00admaining correct in all other conditions under which the Backup is correct.Such an approach \nhasproved empirically successful in re\u00adcent work[8];thepresentpaperprovidesthe underlying theoretical \nfoundations for such approaches. We nowdescribe morepreciselytheQuorum andBackup spec\u00adulation phases. \nTheir interface is that of a consensus object, as de.ned above, augmented with a switch-to-backup(sv) \ncall. The switch-to-backup(sv) call is used by a client to switch from the Quorum phase to Backup, i.e. \nswitch-to-backup(sv) is a proce\u00addure of Backup which may be called by a client executing Quo\u00adrum. The \nsv parameter is called a switch value. A client calling switch-to-backup(sv) transfer its pending invocation \nto Backup and provides sv as an indication to Backup on how to take over Quorum s execution. Informally, \ntheQuorum algorithm works asfollows: Uponpropose(v), a client c broadcastsitsproposalto all server processes \nandwaitsfor accept messages.It also stores v inlocal variable proposalc ofits memory and starts alocal \ntimer tc.  When a serverprocess receives aproposal v from a client c:  If it has not sent any accept \nmessage, it sends an accept message accept(v) to c.  Ifithas alreadysent an accept message accept(v \n' ),it sends accept(v ' ) to c.   Ifa client receives twodifferent accept messages,it switches to Backupby \ncalling and returning switch-to-backup(proposalc).  If a client receives the same accept messages accept(v) \nfrom all the servers, thenitdecides v.  If timer tc expires, then c waits for at least one message accept(v \n' ) from a server, or selects one v ' if it has some messages of the form accept(v ' ) already. It then \nswitches to Backupby calling switch-to-backup(v ' ).  The Backup phase is Lamport s Paxos algorithm \nwhere clients have the role ofproposers andlearners, while servershave the role of acceptors.Backuptreatsthe \nswitch callsfromQuorum as regular proposals.In other words, upon a callswitch-to-backup(v), a client \nprocessproposes the valuev to thePaxos algorithm. By composing Quorum and Backup we obtain a linearizable \nimplementation of consensus that is optimized for crash-free and contention-free workloads. This new \noptimized implementation of consensus was obtainedby composing ablack-boximplementation of Paxos with \na much simpler protocol, Quorum, which makes progress onlyunderparticular conditions. We next uncover \nthe principles behind this approach and we will show the correctness of our optimized protocol by reasoning \nabout each speculation phase in isolation, independently of each other.Thankstoourmodularapproach, wewillbeabletorely \nthe existingproof ofPaxos[13]to showthe correctness ofBackup with minor effort.  2.2 Linearizability \nBefore explaining speculative linearizability, webrie.yreviewlin\u00adearizability itself: we provide both \nits classical de.nition and our newformalization. We consider a set of concurrent clients accessing an \nobject through invocation procedures whose execution ends by returning a response, as in the consensus \nexamples above. We assume that each client is sequential. In other words, a client does not invoke the \nobjectbeforehaving returnedfromitsprecedinginvocation. An objectis accessed sequentially if every response \nto aninvo\u00adcationimmediatelyfollows theinvocation.There mustbe no other response or invocation in between \nthem. For example, the speci.\u00adcation of a consensus object statesthat allprocesses returnthe same decision \nvalue andthatthisvalue musthavebeenproposedbysome processbeforeitcanbe returned.Hence,in a sequential \nexecution, the .rstproposed value mustbe returnedto everyprocess.Notethat this corresponds to executing \nsequentially the algorithm in Figure 1:The .rstprocessexecuting willimposeitsvaluetoall others. We consider \nonly deterministic objects. Therefore, in the se\u00adquential case, the response to a given invocation is \ndetermined by the sequence ofpastinvocationsthatthe object received.Therefore, we represent a sequential \nexecution by its subsequence containing only and all invocations in the execution. We call such sequences \nofinvocations histories. When accessed concurrently, invocations and responses of dif\u00adferent processes \nmay be arbitrarily interleaved. The sequences of invocations and responses that may be observed at the \ninterface of an objectthatis accessed concurrently are called traces.The occur\u00adrence of aninvocation \nor a responsein a traceis called an event, or action.  Linearizabilityisde.ned with respect to a sequential \nspeci.ca\u00adtion, which is a description of the allowed behaviors of the object when it is accessed sequentially. \nIntuitively, a trace is linearizable ifeachinvocation appears totake effect at a singlepointintime af\u00adter \ntheinvocation call andbefore the corresponding response. This intuitivede.nition can be restated as follows:A \ntrace t islineariz\u00adable if we can associate, to each response r returned by a client c, ahistory h (calledcommithistory)such \nthat: 1. The response r is the response obtained in the sequential exe\u00adcution representedbyhistory h. \n 2. Allinvocationsin thehistoryh areinvokedin thetrace t before the response r is returned. 3. Thehistory \nh ends with thelastinvocation of client c. 4. For all commit histories h1 and h2 , either h1 is a pre.x \nof h2  or h2 is apre.x of h1 . Thisde.nition oflinearizabilityis statedprecisely inSection4.In the terminology \nofSection4, condition1 above says thathistory h explains response r.Condition 1 is speci.c to aparticular \nabstract datatype.Conditions2and3 correspond to Validity, and4to Com\u00admit Order. They do not depend on \nthe particular ADT considered. Wehaveproved[9] that thisde.nitionis equivalent to the original de.nition \noflinearizability[12]. As an example, consider a trace of a consensus object such that client c1 proposes \nvalue v1 , then client c2 proposes value v2 , then client c2 returns v2 , and .nally client c1 returns \nv2 .This execution is linearizable because the returned values are as if the invocation of client c2 \nwas executed atomicallybefore theinvocation of client c1 .To showthis, associatethehistory [propose(v2 \n)] tothe response of c2 and thehistory [propose(v2 ), propose(v1 )] to the response of c1 . It is easy \nto check that all four conditions above are satis.ed. Notably, when applied sequentially to a consensus \nobject, both histories lead to response v2 . By the de.nition above, the trace is linearizable.Examples \nof traces that are not linearizableinclude: [c1 proposes v1 , c2 proposes v2 , c1 decides v1 , c2 decides \nv2 ], as well as: [c1 proposes v1 , c1 decides v2 , c2 proposes v2 , c2 decides v2 ].  2.3 SpeculativeLinearizability \nWe now consider modularimplementations composed oftwo spec\u00adulationphases(thede.nitiongeneralizesto any \nnumber ofphases). Asinthe composition oftheQuorum andBackup algorithms, each clientprocessstartsby executing \nthe .rstphaseand may switch to the secondphase using aprocedure call,providing an argumentthat we call \na switch value along withitspending invocation.In the ex\u00adamples of this section we omit thepending invocationfrom \nswitch callsfor the sake of conciseness. We would like to reason about each speculation phase in isola\u00adtion. \nFor this purpose, we require that the switch values provided by the clients when changingphasebe the \nonlyinformationpassed from one speculation phase to the other. No side effects are per\u00admitted acrossspeculationphases.Speculationphases \narethussep\u00adarated by a clear interface: a call to the phase s switch procedure with a switch value and \napending invocation as arguments. Speculative linearizability is a property of speculation phases that \nrelates the switch events and the invocations received by the speculation phase to the responses and \nswitch events produced by the same phase. Moreover, no assumption other that trivial well\u00adformedness \nconditions is made on the received switch events and invocations. This allows us to check that a phase \nis speculatively linearizable by reasoning about the phase independently of other phasesitmightbe composed \nwith. Speculative linearizability is an extension of linearizability to traces that contain switch calls. \nIn the de.nition of linearizability stated above, we associated to each response returned by a client \na history of inputs with certain properties. In the same spirit, in addition to associating histories \nto responses returned, we now associate to each switch call in the trace a history of inputs. With respect \nto the .rst phase, we call these histories abort histories. Withrespect to the secondphase, we call them \ninithistories. Such histories associated to switch calls represent possible lin\u00adearizationsof theexecutionof \nthe .rst speculationphase.Theidea isthat,with theknowledgeofhowtheexecutionof the .rstphase waslinearized,the \nsecondphase can continue execution without vi\u00adolatinglinearizability.Inorderforaspeculationphasetodeduce \na possible currentlinearizationfrom a switchvalue, we suppose that all speculation phases agree on a \ncommon mapping from switch values tohistories.Wedenote this mappingby rinit. Depending on theparticulardata \ntypebeingimplemented, there are some sets of histories whose members all bring the system in the same \nlogical state. In other words, the response to a new invo\u00adcation is independent of which history of such \na set was executed before.We callhistoriesin such sets equivalent with respect to the data type. Consider \nour consensus example. Any set of histories whosemembers startwith thesameproposalisasetof equivalent \nhistories:becausethe .rstproposalisthedecisionvalue,any new invocationwill returnthe .rstproposed value.Processesinvoking \nthe object at a point after such a history has been executed cannot tell whichhistoryin the set actuallyhappened. \nBecause of this ob\u00adservation, we require that speculation phases agree on a mapping from switch values \nto sets of equivalent histories, as opposed to a single history. This allows us to use a compact representation \nof histories while ensuringthatenoughinformationis availableforthe secondphase to take over the execution. \nTwo otherprinciples,fault tolerance and avoidance of unneces\u00adsary synchronization,in.uenced ourde.nition.Forfault \ntolerance, wedo not rely onjust one clientpassing a single switch value.For ef.ciency reasons, we avoid \nthe requirement that all clients switch with the same value because it would imply solving a potentially \nexpensive agreement problem. Hence, the switch values of differ\u00adent clients may be different and no single \nswitch call determines the execution of the secondphase. Applied to the .rst phase, speculative linearizability \nrequires that the .rst phase be linearizable. Moreover, for all traces of the .rst phase, it must be \npossible to associate histories to the switch events so that each such history is a possible linearization \nof the trace up to the considered event and each association from switch event to history respects the \ncommon mapping that phases agree on. Finally, the longest common pre.x of all abort histories must be \na full linearization of the trace of the .rst phase. The last two requirements correspond to the AbortOrder \nproperty ofSection5. Appliedtothe secondphase,speculativelinearizability saysthat for all traces t of \nthe second phase, for all possible associations of histories to switch values that respect the common \nmapping agreed on,by concatenating t tothetrace representedbythelongest common pre.x of all init histories \nand by replacing switch calls with the pending invocation they contain, one should obtain a linearizable \ntrace. This corresponds to the Init Order property of Section5. Having de.ned the new concept of speculative \nlinearizability, we will show that the composition of any number of speculatively linearizable phases \nis a linearizable algorithm. This result is a corollary of ourintra-object compositiontheorem, which \nstatesthat the composition of two speculation phases is itself a speculation phase.  2.4 ApplyingSpeculativeLinearizabilitytoQuorum+Backup \nWe next showthat our message-passing speculationphases,Quo\u00adrum and Backup, satisfy speculative linearizability. \nAs explained above, we view the values passed when switching from Quorum to Backup as representing sets \nof histories equivalent to some lin\u00adearization of Quorum s execution. To this end we assumed that speculation \nphases agreed on a common mapping from switch events to sets ofhistories.In this example, the mapping \nof a switch event of client c with switch value v is the set of allhistories start\u00adingwithinvocation \npropose(v) from a clientc ' .= c and containing onlyinvocationsfrom clients otherthan c.Hence, aclient \nswitching toBackup with switch value v indicates toBackup that anyhistory in the set mapped to v is apossiblelinearization \nofQuorum s exe\u00adcution. Quorum is speculatively linearizable. Weprove thatQuorum is speculativelylinearizablein \ntwo steps.First, we show thatQuorum satis.es the following three invariants. Then we show that those \ninvariantsimply speculativelinearizability. I1: If some client c decides value v then all clients that \nswitch, eitherbefore or after c decides,do so withvalue v. I2: If some client c decides value v then \nall clients that decide do so with value v. I3: All clients that switch or decide do so with a value \nthat was proposed before theyswitch ordecide. InQuorum,ifthere are nofaults nor contention, a clientbroad\u00adcasting \na proposal will receive identical accept messages from all server processes and will return the value \ncontained in the accept messages. However, if contention causes proposals from different clients to be \nreceived in different orders at different servers, or if a server fails or messages are lost, clients \nwill switch to Backup because different accept messages will be received or not enough messages willbe \nreceivedbefore the timers expire. Observe that if a client returns a value v in Quorum then all servers \nwill reply with accept(v) to all the other clients. This is because a client only returns value v if \nall servers send it accept messages with value v, and a server always responds withthe same accept message.Hence,if \nsome clientdecided, all the other clients will either returnthe same value v or will switchtoBackup withthe \ninitialization value v in case message loss or server crashes cause theirtimersto expire.Fromthese observation \nwe can conclude that theinvariantsI1 andI2 are satis.edby any trace ofQuorum. Moreover, as servers respond \nwith an accept message contain\u00adingthe .rstproposalreceived, clientprocesses returnorswitchwith a value \nthat wasproposed before.Hence, theinvariantI3holds. We now prove that any trace satisfying I1, I2, and \nI3 satis.es speculativelinearizability.Consider a trace t ofQuorum that satis\u00ad.esI1,I2, andI3. According \nto the de.nition of speculative linearizability for the .rst phase, we begin by showing that t is linearizable. \nIf no client decides then the trace t is trivially linearizable. Therefore assume that some clients decide. \nThe invariant I2 implies that all decisions in the trace are the same. Let v be the common decision. \nThe invariant I3 implies that some client, noted winner, proposed v before any client decided v. Let \nthe history h be such that h starts with winner s proposal and the sub-sequence of h starting at position \n2 is equal to the subsequence of t containing all theproposals of the clientsthatdecide and thatarenot \nwinner. The history h represents a linearization of trace t. We satisfy our de.nition of linearizability \nby associating to each decision from a client c the history h truncated just after the proposal of c. \nThe linearizability ofQuorumfollows. To prove speculative linearizability, it remains to show that we \ncan associate appropriate histories to each switch event in t. We consider two cases. First, assume that \nsome clients decided. Then, by invariant I1 we know that clients decide or switch with the same value \nv. Let history h be as de.ned above. To each switch event in t we asso\u00adciate h. By de.nition of h, h \nstarts with the common decision v and all clients that switchdo so with value v.Moreover the clients \nthat switchdo notdecide; theirinvocations thusdo not appearin h. Hence, the association from switch events \ntohistories respects the common mapping.Moreover, h is alinearization of trace t.There\u00adfore, each history \nassociated to a switch event is a linearization of t. Finally, the longest common pre.x of all histories \nassociated to switch eventsis obviously h itself, and h is alinearization of trace t.We conclude that \nt satis.es speculativelinearizability. Now assume that no client decides. In this case the trace is trivially \nlinearizable. Moreover, it is easy to associate histories to switch events, so that the longest common \npre.x of all such historiesis empty.We thus triviallyhave thatt satis.es speculative linearizability. \nNote that a client that does not fail returns or switches at the latestwhenits timer expires.Quorumis \nthus wait-free. Backup is speculatively linearizable. As for Quorum, we proceed by .rst abstracting Backup \nusing simple invariants and thenproving that those invariantsimply speculativelinearizability. Since \nPaxos has been proved correct in the past [13], we can trivially abstractBackup using thefollowing twoinvariants: \nI4 Allclientsdecide the same value. I5 Allclientsdecide a switch valuepreviously submittedby some client. \nConsider a trace t satisfying invariants I4 and I5. We consider two cases. First assume that all switch \nvalues are the same and equalto v.Then,byde.nition ofthe common mappingfrom switch events tohistories,for \nall associations ofhistories to switch events respecting the common mapping, the longest common pre.x \nh of the histories associated to switch values is such that h starts with an invocation propose(v) from \na client c that doesn t execute in t and contains onlyinvocationsby clientsthatdon t executein t.Let \nth be the trace representedbyhistoryh.ByinvariantsI4 andI5 we know thatall clientsdecide value v in t.Let \nt ' be the tracet where switch calls are replaced by the pending invocation they contain. Consider the \nconcatenation th@t ' of th and t ' . Let the history h ' be the concatenation of h and some ordering \nof the proposals in t ' . Because h represents th and because all clients decide v in t, we have that \nh ' is a linearization of th@t ' . Hence, t satis.es speculativelinearizability. Now suppose that atleast \ntwo switch values aredifferent.Then for anyassociation ofhistoriesto switch events respectingthe com\u00admon \nmapping, the longest common pre.x of the histories associ\u00adated to switch events is the empty history. \nFrom invariants I4 and I5 we have that all processes decide on one of the switch values submitted before \nany decision. Hence, t is linearizable, and so is the concatenation of the empty history and t.Therefore, \nt satis.es speculativelinearizability. We have proved that Quorum and Backup satisfy speculative linearizability. \nTherefore, using the intra-object composition theo\u00adrem that we willprovebelow, we conclude that the composition \nof Quorum andBackupis alinearizableimplementation ofconsensus. Using speculative linearizability, we \nhave optimized the Paxos algorithm to obtain an algorithm thathas alatency of two message delays in the \nabsence of faults and contention. Implementing this optimization by modifying the Paxos algorithm would \nhave meant modifying a notoriouslyintricatedistributed algorithm.Instead,by using our framework, we were \nable to optimize Paxos without modifying it. Moreover, thanks to the intra-object composition theorem, \nwe easilyprovedthe optimizedprotocol correctjustby proving the optimization speculatively linearizable \nand by relying on the correctness ofPaxos.  2.5 Shared-MemoryConsensus To illustrate the broad applicability \nof our framework we now applyit to an algorithmin the shared-memory model.We consider a consensus implementation \nin an asynchronous shared-memory system. Consensus can be implemented on modern microprocessors using \nthe wait-free compare-and-swap(CAS) instruction,butthis instruction may be slower than an atomic register \naccess. It has beenproved[11] that wait-free consensus cannotbeimplemented with registers. However, assuming \nthat all executions are contentionfree(i.e. sequential), Figure 1 implements consensus using only registers. \nHence thefollowingquestion:isitpossible todevise an object that uses only registersin contention-free \nexecutionsbutthat always ex\u00adecutes correctly?We obtain such an objectby composing a register\u00adbased speculation \nphase called RCons, shown in Figure 2, and a CAS-basedspeculationphase called CASCons, showninFigure3. \nTheCAS-basedspeculationphaseis a straightforwardimplementa\u00adtion of consensus using theCAS operation.Both \nspeculationphase areinspiredby[25].It turns out that these speculationphases,like many other speculation-based \nobjects, are instances of our frame\u00adwork. The register-based consensus uses a wait-free splitter algorithm \n[19]. The splitter guarantees that at most one process returns with true and all others return withfalse.Moreover,itguarantees \nthat,in the absence of contention, exactly oneprocess returns with true.A splitter canbeimplemented using \nonly registers, asin our example implementationinFigure2. A client invokes the register-based speculation \nphase using the function propose(val), where val isthe valuethatitproposes.To simplify the notation, \nwe assume that, at the time of the call, the caller identi.er is stored in the special variable c. The \nregister\u00adbased speculation phase, RCons, can return the content of register V , orit can switch totheCAS-based \nspeculationphase, CASCons, by invoking thefunction switch-to-CASCons(V ) and returning its result. In \nthe latter case, we say that a client switches with value v, where v is the content of register V when \nit waslast read.Such switchingisthebasic mechanism of composing speculationphases in ourframework. As \nfor Quorum and Backup, we will show that the composi\u00adtion of the phases RCons and CASCons form a linearizable \nim\u00adplementation of consensus by a modular reasoning. Thanks to the intra-object composition theorem, \nwe will get the correctness of the composition of RConsand CASConsby analyzing eachiniso\u00adlation. Let \nus now show that the RCons and CASCons algorithms are speculativelylinearizable. As for Quorum and Backup, \nwe will .rst consider RCons in isolation and,given an arbitrary execution of RCons, we will show thatwe \ncan associate appropriatehistoriestothe responses returned andtothe switch calls.We willthen consider \nCASConsinisolation and show that, given an arbitrary execution of CASCons and an arbitrary association \nof histories to the switch calls of CASCons (respecting the common mapping), we can associate appropriate \nhistories to the responses appearingin the trace. We .rst showthattheinvariantsI1,I2,andI3de.nedforQuo\u00adrum \nalsohold of the traces of RCons.To establish theseinvariants, we .rst observe the following: By property \nof the splitter, at most one client executeslines15 to18.Moreover,if one client c does so and returns, \nit makes sure that other clients will either return with 1: Object RCons 2: //Shared Register V ,Initially \n.;and D,Initially . 3: //Shared Register Contention .{true, false},Initially false 4: //Shared Registers: \nY .{true, false},Initially false;and X 5: //LocalVariable v;local constant c denoting the caller s identi.er \n6: Function propose(val): 7: v . val 8: if D .. then = 9: return D 10: endif 11: if splitter() = true \nthen 12: V . v 13: if \u00acContention then 14: D . v 15: return v 16: else 17: return switch-to-CASCons(v) \n18: endif 19: else 20: Contention = true 21: if V .= . then 22: v . V 23: endif 24: return switch-to-CASCons(v) \n25: endif 26: Function splitter(): 27: X . c //Remember thatc is the caller s identi.er 28: if Y = true \nthen 29: return false 30: endif 31: Y . true 32: if X = c then 33: return true 34: else 35: return false \n36: endif Figure2. Register-Based Speculative Consensus 1: Object CASCons 2: //Shared Register D Initially \n. 3: Function switch-to-CASCons(val): 4: return CAS(D, ., val) 5: Function propose(val): 6: //Since processes \nhave to call switch-to-CASCons .rst, we know that the consensushas already been won,hencejust return \nD. 7: return D Figure3. CAS-BasedSpeculative Consensus its value atline12 or switch withits value atline27.Indeed, \nif the variable Contention isfalse atline16,it means that noprocessgot pastline23.Therefore,allprocessesthatswitch \nwill.nd c s value in variable V at line 25. We conclude that the invariants I1 and I2 hold on all executions \nof RCons. If some client c returns value v then all clients that switch, either before or after c returns, \ndo so with value v andif some client c returns value v then all clientsthat return do so with value v. \nNext, observe that all clients return or switch withtheir own value or withthe content of register V \n, which can only containproposed values.Consequently, theinvariantI3is also aninvariant on all executions \nof RCons:All clientsthat switch do so with a value that wasproposed before they switch. Similarly, the \nCASCons phase can be abstracted by the same invariants that we used to abstract the Backup speculation \nphase: Allclientsreturnthe same value andallclients return a switchvalue previously submittedby some \nclient. When we proved that Quorum and Backup are speculatively linearizable, we showed that the invariants \nI1, I2, and I3 imply speculative linearizability of the .rst phase and that the invariants I4 andI5imply \nthe speculative linearizability of the secondphase.  Since we established that the traces of RCons satisfyI1,I2, \nandI3 and that the traces of CASCons satisfy I4 and I5 we can conclude that RConsand CASConssatisfy speculativelinearizability. \nWe willnowformallyde.ne speculativelinearizability.  3. TraceProperties In this section we de.ne trace \nproperties and the operations they support.Traceproperties are our model ofdistributed systems. A trace \nproperty is a set of .nite sequences of events. We use trace properties to describe the set of all .nite \nsequences that a system can generate, as well as the desired properties of systems, such aslinearizability \nwith respectto agiven abstractdatatype.We restrict ourselves to .nite sequences because our work deals \nwith safetyproperties only. Sequences. We write [1..n] for the set {1, 2,...,n}.A se\u00adquence s of length \nn with elements from a set E is a function s : [1..n] . E. We denote n by |s|. We write E * for the set \nof all sequences of elements in E. We write [e1 ,e2,...,en] for the sequence s such that s(1) = e1, s(2) \n= e2 , ..., and s(n)= en. If s =[e1 ,e2,...,en] then s::en+1 is the se\u00adquence [e1,e2 ,...,en,en+1]. If \ns =[e1 ,e2,...,en] and s ' = '''' '' [e1 ,e 2,...,e n] then s:::s =[e1,...,en,e 1 ,...,e n] and,if m< \n|s|, we write s|m forthe the sequence [e1 ,e2,...,em].We saythat a sequence s is a pre.x of a sequence \ns ' iff there exists a sequence '' ''' ' s such that s = s:::s . We say s is a strict pre.x of s iff \nthe s '' is non-empty. Given a set of sequences P , thelongest common pre.x of set P isthelongest among \nthesequences s ' such thatfor all sequence s . P , s ' is apre.x of s. Multisets. We represent multisets \nof elements of set E by a multiplicity function E . N. Given two multisets m1 and m2 and e . E, wede.ne \n(m1 .m2 )(e)= max(m1(e),m2 (e)) and (m1 . m2)(e)= m1 (e)+ m2(e). Moreover m1 . m2 iff for all e . E, \nm1(e) = m2 (e). Let elems : . (E . N) be E * afunctionthatgivenasequence returnsamultiset representing \nall the elementsfoundinthe sequence andtheir number ofoccurences. Given a sequence s we write e . s iff \nelems(s)(e) > 0. Trace Properties. A trace is a sequence of actions which represents events happening \nat the interface between a system and its environment. An event occurs at somepoint in time and has no \nduration. We can approximate invoking a method and starting to execute it as one action. The execution \nof a method from start to .nish, however, is typically not an action because it has a positive duration \nin time. We would represent it with an invocation action and a return action. We classify actions into \ninput and output actions. This classi\u00ad.cation is especially important to de.ne composition of systems, \nbecause weneed toknowwhich actionsof acomponent affect an\u00adother component. The classi.cation is described \nby a signature.A signature sig is a pair (in, out) where in is a set of input actions and out is adisjointset \nof output actions.We require in and out to bedisjoint.Wedenotebyacts(sig) the set of all actionsin signature \nsig.When allthe actions of atrace t belongto acts(sig) we saythat t is a traceinsig. De.nition 1. A trace \nproperty is a pair P =(sig, Traces) where sig is a signature and Traces is a set of tracesin acts(sig). \nWedenote sig bysig(P ) and TracesbyTraces(P ).We allowto write in(P ) instead of in(sig(P )) and similarly \nfor the other sets of actionsde.ned above. We say that a trace property Q satis.es a trace property P \n, denoted Q |= P , if Q s signature is equal to P s signature and the set of trace of Q is a subset of \nthe set of traces of P : Q |= P . (sig(Q)= sig(P ) .Traces(Q) . Traces(P )) . Composition of Trace Properties. \nTrace properties may be composed only if their signatures are compatible. Signatures sig1 and sig2 are \ncompatibleif and onlyiftheyhave no output actionsin common, that is out(sig1 ) is disjoint from out(sig2 \n). As a result, out(sig1 ) n acts(sig2) . in(sig2) and vice versa. We de.ne the projection proj(t, A) \nof a trace t onto a set A of actions as the sequence obtained by removing all actions of t that are not \nin A. '' '''' For example, proj([x,y,x ,z,y ,z,y,z,y], {x ,y })=[x ,y ]. De.nition 2. If sig1 is compatible \nwith sig2 then the composition P = P1||P2 is such that: The signaturesig(P ) is suchthatin(P )=(in(P1 \n).in(P2 ))\\ (out(P1) .out(P2 )) and out(P )= out(P1 ) .out(P2).  The setoftraces Traces(P ) isthelargestset \noftracesin acts(P ) such thatif t . Traces(P ) then proj(t, acts(P1 )) . Traces(P1) and proj(t, acts(P2)) \n. Traces(P2 )  Intuitively, composition requires components to execute at the same time the actions \nthat appear as input of one component and outputof theother.Actionsthat appearinauniquecomponent are \nexecuted asynchronously fromthe other components.Composition has thefollowingproperty: Property1. If \nQ1 |= P1 and Q2 |= P2 then Q1||Q2 |= P1 ||P2 . Projection ofTrace Properties. De.nition 3. Given a trace \nproperty P we de.ne its projection proj(P, A) onto a set of actions A such that sig(proj(P, A)) = (in(P \n) n A, out(P ) n A) and Traces(proj(P, A)) = {t |.t ' . Traces(P ).t = proj(t ' ,A)} Applying the proj \noperator to a trace property P amounts to removing all the actions notin A from P sinterface.  4. Linearizability \nOur notion of speculative linearizability is itself based on a new de.nition oflinearizability.Thisde.nitionisinterestinginits \nown right because it enables a more local form of reasoning than the original de.nition. Moreover, it \nallows for repeated events, which arethe norminpractice.Thetechnical report[9] contains aproof that our \nnewde.nition oflinearizabilityis equivalent to the classi\u00adcalde.nition. 4.1 AbstractDataTypes AbstractData \nTypes (ADTs)formalize ourintuitive understanding ofhow sequential objects maybehave. In order to simplify \nour discussion in the rest of the paper, we deviate from the usual, state-machine based, de.nition of \nabstract data types. However we do so without loss of generality. Tradi\u00adtionally, the allowed behaviors \nare described using an ad-hoc state machine that given a state and an input transitions to a new state \nandproduces an output.Instead, wedetermine outputsfrom thein\u00adput history seen so far using an output \nfunction. Computation of the outputfunction amounts to replaying the execution of the state\u00admachinedescription. \nDe.nition 4. An ADT T is a tuple T =(IT ,OT ,fT ) where IT is a non-empty set, whose members we call \ninputs, OT is adisjoint non-empty set whose members we call outputs, and fT : IT * . OT is an outputfunction. \nIntherestof thepaper,weconsiderobjectsof some .xedADT T =(IT ,OT ,fT ). Example 1. We consider a consensus \nobject with operations of the form (p(v),d(v ' )) with v and v ' belonging to some set VCons. p(v) is \na shorthand for propose(v) and d(v) for decide(v) . The consensus object must guarantee that a unique \nvalue v may be decided and that at any point a decided value has been pro\u00adposed before. Hence, because \nwe are considering sequential ex\u00adecutions, the .rst proposed value must be decided in all subse\u00adquent \noperations. Formally, we de.ne the ADT Cons such that  ICons = {p(v) | v . VCons}, OCons = {d(v) | v \n. VCons}, fCons([p(v1),p(v2 ),...,p(vn)]) = d(v1)  4.2 ATraceModel ofConcurrentObjects We consider a \nset C of asynchronous sequential processes called clients. Clients use a concurrent object of ADT T by \ncalling the object s invocation function with one of theADT sinputs, and the invocationfunction returns \none of theADT s outputs.Wedenote a sequence ofinteractionbetween clients and object asfollows.Sup\u00adpose \nthat the following sequence of interactions between clients and object is observed: Client c1 invokes \ninput in1 ; Client c2 in\u00advokesinput in2;Clientc2 returns with output out2;Finallyclient c1 returns with \noutput out1 . This sequence of interactions is denoted by the sequence of actions [inv(c1 , in1), inv(c2 \n, in2 ), res(c2, in2, out2), res(c1, in1 , out1)] Signature of a Concurrent Object Formally, a sequence \nof interactions between a concurrent object and its clients is a trace of actionsin the signature sigT \n, where theinputs in(sigT ), called invocation actions, are of the form inv(c, n, in) and the outputs \nout(sigT ),called response actions, areoftheform res(c, n, in, out) for some client c, natural number \nn,in . IT , and out . OT . The reader willnoticethatthe secondparameter ofthe actionsis notpresentin \nourpreceding example.It willbe usedinSubsection 5 tode.ne the signature of a speculationphase. In Section \n4 we de.ne the trace property LinT such that a concurrent object described by a trace property O is linearizable \nw.r.t. T ifand onlyif O . LinT . UnderscoreNotation.Throughoutthepaper we willusethe under\u00adscoresymbol \ninmathematical expressions.Each occurrenceof thissymbolistobereplacedby a .xedfresh variable.Forexample, \nwe might say an action a is aninvocation actionif a = inv( , , ), or equivalently, thatif a = inv(c, \nn, in) for some c, n, and in, then a is aninvocation action. 4.3 ANewDe.nitionofClassicalLinearizability \nIn this section wede.ne a traceproperty calledlinearizability, and noted LinT .Informally, a tracein \nsigT is said tobelinearizableiff its actions maybe reordered toform a sequential trace that: 1. Respects \nthe semantics of theADT T . 2. Preserves the order of non-overlapping operations. Property 1 implies \nthat clients accessing a linearizable object can\u00adnottell whetherthe objectproduces sequential or concurrenttraces. \nThis is a crucial property because it hides concurrency from the view of application developers. Property \n2 makes linearizability a local property. In other words, a system composed of linearizable objectsisitselflinearizable.We \nreferthe readerto[12] for anin\u00addepthdiscussion aboutlinearizability. Instead of using the de.nition above \nwe propose a new de.ni\u00adtion of linearizability that will simplify our task when we de.ne speculation \nphases. It directly establishes a relationship between the linearizable traces and the ADT, without the \nintermediary of sequential traces. Notethat somede.nitions oflinearizability[12] assume more or less \nexplicitly that all inputs submitted are unique. This seems unwarranted as many algorithms quali.ed as \nimplementing a lin\u00adearizable object aredeemed correct without requiring this assump\u00adtion. Our de.nition \ndoes not rely on this assumption and it coin\u00ad  cides withthe otherde.nitions on traces satisfying the \nassumption. Consider a trace t in sigT . De.nition 5. Trace t is linearizable iff it is well-formed and \nit admits a linearizationfunction g : [1..|t|] . T . I * Wede.nelinearizationfunctions andwell-formedtracesbelow. \nTo ensure that our de.nition corresponds to the usual one, in the technical report[9] we alsoformalize \nthe usualde.nition of linearizability[12],by de.ning when a traceis linearizable * , even in case of \nrepeated events. We thenprove the equivalence between the twode.nitions. Theorem 1. A trace in sigis \nlinearizable if and only if it is linearizable * . T  4.4 LinearizationFunctions In the rest of the \npaper we call sequences of inputs histories. A linearizationfunction maps theindices oft tohistories \nwhich must satisfy twoproperties: First, applying theADT s outputfunction to thehistory associ\u00adated with \na response index must yield the output contained in the response.Hence alinearizationfunction maybe seenasgiving \nan explanation of the outputs observed, in term of the ADT s seman\u00adtics. Second, the history associated \nto a response index must only contain inputs invoked before index i and for all pairs of histories corresponding \nto response indices, one is a strict pre.x of the other. This second condition gives us a total order \non the response indices oft (thepre.x order onhistories)which corresponds to the reordering neededin \nthe originalde.nition. A history corresponding to some response index i in a trace t according to alinearizationfunction \nis said tobe alinearization of the(concurrent) trace t|i. We now state thisde.nitionformally: De.nition6. \nLinearization Function. Afunction g is a lineariza\u00adtionfunctionfor t iff Function g explains trace t. \n Function g and trace t satisfy the validity(t,g) and commit\u00ad  order(t,g)predicates. De.nition 7. Explains. \nWe say that function g explains trace t iff for all index i . [1..|t|], if t(i)= res( , , , out) then \nout = fT (g(i)). Consider afunction g : [1..n] . T that explains trace t. I * De.nition 8. Commit Index \nand Commit Histories. If i . [1..n] is suchthatt(i)= res( , , , ) then we saythat i is acommitindex and \nthat g(i) is a (t, g)-commithistory. De.nition 9. Sequence of Previous Inputs. We de.ne the se\u00adquence \nof previous inputs at i in t, inputs(t, i), as the se\u00adquence of all inputs submitted before index i in \ntrace t. For\u00admally, for all i . [1..|t|], |inputs(t, i)| = |proj(t|i, in(sigT )|, and for all j . [1..|inputs(t, \ni)|], proj(t|i, in(sigT ))(j)= inv( , , inputs(t, i)(j)). De.nition 10. Valid Commit Index For all index \ni . [1..|t|] such that t(i)= res( , , in, ), we say that i is (t, g)-valid iff elems(g(i)) . elems(inputs(t, \ni)) and the input in is the last element of thehistory g(i). In other words,ift(i)= res( , , in, ) theng(i) \nisapermutation of the sequence ofpreviousinputs at i and ends with theinput in. We nowde.ne validity \nand commit-order: De.nition 11. Validity(t,g). All commit indices in t are (t, g)\u00ad valid. De.nition12. \nCommit Order(t,g):For allpairs ofdistinctcommit indices (i, j), either g(i) is a strictpre.x of g(j) \nor g(j) is a strict pre.x of g(i).  Example2. Consider thefollowing trace t: '' [inv(c, in1), inv(c, \nin2 ), res(c, in2 ,fT ([in2 ])), res(c, in1 ,fT ([in2, in1 ]))]. Consider afunction g such that g(3) \n= [in2] and g(4) = [in2 , in1 ]. The function g explains t. Moreover t and g satisfy validity and commit-order.Hence \ng is alinearization functionfor t.  4.5 Well-FormedTraces The well-formedness oftracesis abasic requirement.For \nexample, it states that a response should be given to a client only if it previouslyissued aninvocation. \nGiven a clientc,let ActT (c) be the union of the sets {inv(c, , in)|in . IT }and {res(c, , in, out)|in \n. IT .out . OT }. De.nition 13. Client sub-trace. The client sub-trace sub(t, c) of trace t in sigT is \nthe trace sub(t, c)= proj(t, ActT (c)). De.nition 14. Well-formed client sub-trace. A client sub-trace \nt is well-formed iff t(1) is such that t(1) = inv( , , ) and for all i . [1..|t|-1],if t(i)= inv( , , \nin),then t(i +1) = res( , , in, ). De.nition 15. Well-formed traces. We say that trace t in sigT is well-formed \nif and onlyif allits client sub-traces are well-formed. Note that invocations with no corresponding response \nmay ap\u00adpearin a well-formedtrace.We saythatthoseinvocations arepend\u00ading. 4.6 The LinT Trace Property \nWede.nethetracepropertyLinT suchthatthe signature sig(LinT ) is sigT and the set Traces(LinT ) is the \nset of all traces satisfying linearizability. Finally, consider a system S whose behavior is denoted \nby a traceproperty P .We saythat the system S implements theADTT ifand onlyif proj(S, sigT ) |= LinT \n.  5. SpeculativeLinearizability We nextpresentour main results: aprecisede.nition of speculative linearizability, \nandtheproofthata composition ofimplementations that are speculatively linearizable implementations is \nitself specu\u00adlativelylinearizable.This sectionpresents a trace-basedformaliza\u00adtion. We summarize an alternative, \nautomata-based, formalization inSection6. 5.1 SpeculationPhases Wenow consider concurrentobjectsimplementedby \nseveral specu\u00adlationphases.Clientsuse a speculationphasebycallingthe object s invocation functions and \nthe invocationfunctions return outputs to the clients.However, a speculationphase also acceptsinitialization \ncallsfrom clients andit may switch to another speculationphase. Moreover, each speculation phases is \nidenti.ed by a natural number and a speculation phase identi.ed by n may only switch to a speculation \nphase identi.ed by n +1. Clients startby access\u00adingspeculationphase 1 and continue todo so aslong as \nthey return in thephase 1. However, speculation phase 1 may switch tophase 2.In this caseitpasses aninitialization \nvalue anditspendinginput tophase 2.A client which returnsinphase 2 stops accessing spec\u00adulationphase \n1 andinstead usesphase 2 forits nextinvocations. Let S1 and S2 be two consecutive speculationphases. \nSuppose that client c1 invokesinputin1 on S1 ;client c2 invokesinputin2 on S1 ;client c2 switches from \nS1 to S2 providing initialization value v;client c1 returns response out1 from S1 ;.nallyclient c2 returns \nresponse out2 fromS2.This sequence ofinteractionsisdenotedby this sequence of events,from now on called \nactions: [inv(c1, 1, in1 ), inv(c2 , 1, in2), swi(c2 , 2, in2,v), res(c1 , 1, in1, out1), res(c2 , 2, \nin2 , out2 )] Instead of formalizing the signature of a single speculation phaseidenti.edbya natural \nnumber wegeneralize to the signature of a composition of speculation phases. We now assume that a speculation \nphase may be composed of several other speculation phases. Let N2 = {(m, n) | (m, n) . N2 . m<n}. We \ndenote < a speculation phase by an element of N2 A speculation phase <. (m, n) . N2 describesthepossiblebehaviors \nof the composition < of speculationphasesfrom m to n. We now explain why we make thisgeneralization. \nWe would like to de.ne a property P (n) of speculation phase n,for n . N, such thatfor all m . N the \ncomposition P (1)||P (2)||... ||P (m) implements LinT .Toprove that P (1)||P (2)||... ||P (m) |= LinT \nwegeneralize P (n) to P (m, n) in order to useinduction. We wouldlike P (m, n) tobe such that: For allnatural \nnumber n> 1, P (1,n) |= LinT (1) For all(m, n) . N< 2 and (n, o) . N<2 , P (m, n)||P (n, o) |= P (m, \no) (2) Usinginduction and equation2 wehave thatfor all n> 1, P (1, 2)||P (2, 3)||... ||P (n -1,n) |= \nP (1,n). Thus, withequation1, wehave thatfor all n> 1, P (1, 2)||P (2, 3)||... ||P (n -1,n) |= LinT (3) \nNow suppose that we have a family of trace properties Q1,Q2,...,Qn, representing implementations of speculation \nphases, such that Qi |= P (i, i + 1) for all i . [1..n]. Let Comp = Q1||Q2 ||... ||Qn. By property 1 \nand equation 3, we have that Comp |= LinT . Signature of a Speculation Phase We now de.ne a signature \nsigT (m, n, Init) which models theinterface of a speculationphase (m, n) that uses initialization values \nfrom the set Init. For all m . N and any arbitrary non-empty set Initofinitialization values, we de.ne \nthe set of switch actions as formed of all actions of the form swi(c, m, in,v) where c is a client, m \n. N, in . IT , and v . Init. De.nition16. Signature of a speculation phase. For all(m, n) . N2 and any \nnon-empty set Initofinitialization values wede.ne the signature sigT (m, n, Init) as the union of the \nsets of allinvocation actions inv( , o, ), of all response actions res( ,o, , ), and of all switch actions \nswi( ,o, , ), where o . [m..n]. <  5.2 Speci.cationof aSpeculationPhase In this section we propose a \nspeci.cation for speculation phases. We consider a set of initialization values Init, and a relation \nrinit . \u00d7 I *-1 Init T such that rinit is a total onto function. The relation rinit associates a set \nof input sequences to any value in Init.Remember that the init values convey information about the execution \nof one phasetothe nextphase.Wethinkofthisinformationinterms ofin\u00adputhistories which representpossible \nlinearizations of the concur\u00adrenttraceof aphase.Wesay thesetofinput sequences associated by rinit with \navalueisthevalue spossibleinterpretations. We willnowde.ne a traceproperty SLinT (m, n), such that For \nall natural number m, proj(SLinT (1,m), acts(sigT )) |= LinT .  For all (m, n) . N2 < and (n, o) . N2 \n<,  SLinT (m, n)||SLinT (n, o) |= SLinT (m, o). Wede.ne theproperty SLinT (m, n) in the same vein as \nLinT . Consider a trace t in sigT (m, n, Init).  De.nition17. Interpretation of Init Actions. We say \nthat a func\u00adtion f : [1..|t|] . I * is an interpretation of the init actions of t iff for all index i \n. [1..|t|], if t(i)= swi( ,m, ,v) then (v, f (i)) . rinit. De.nition 18. Interpretation of Abort Actions. \nWe say that a function f : [1..|t|] . I * is an interpretation of the abort actions of t iff for all \nindex i . [1..|t|], if t(i)= swi( ,n, ,v) then (v, f (i)) . rinit. De.nition 19. Speculatively Linearizable. \nWe say that trace t is (m, n)-speculatively linearizable iff trace t is (m, n)-well-formed and for all \ninterpretation finit of the init actions of t, there exists twofunctions g : [1..|t|] . T and fabort \n: [1..|t|] . T such that: I * I * fabort is aninterpretation of the abort actions of t.  g is an (finit,fabort, \nm, n)-speculative linearization function for  t.  5.3 SpeculativeLinearizationFunctions IntuitionBehindtheDe.nitions.Consider \na speculationphaseS1 whose clients switch to speculationphase S2.We require clients to switch with a \nvalue whose set of possible interpretations includes a possible linearization of the concurrent trace \nat the point where the client switches.Note that everyhistory(1) of which all commit histories arepre.x \nand(2) that contains only values thathavebeen invoked is a possible linearization. This is the intuition \nbehind the de.nition ofAbort-Orderproperty(De.nition32). To ensure that phase S2 continues executing \nconsistently with what phase S1 did, we require all its commit histories to have as apre.xone of thepossiblelinearizationsof \nS1 s trace.Thisis the intuition behind the Init Order property(De.nition 31). However S2 receives switch \nvalues that represent sets of histories, and can\u00adnot determine which history in this set is a possible \nlinearization. Hence the quanti.er alternation in De.nition 19: for all possible interpretations of the \ninit values, phase S2 needs to ensure the ex\u00adistence of aproperlinearizationfunction. De.nition 20. Speculative \nlinearization function. A function g : [1..|t|] . T is a(finit,fabort, m, n)-speculativelinearizationfunc- \nI * tionfor t iff: Thefunction g explains trace t.  The predicates Validity(t, g, finit,fabort), Commit-Order(t, \ng),  Init-Order(t, g, finit,fabort), andAbort-Order(t, g, fabort) hold. De.nition21. Explains. We say \nthat thefunction g explains trace t iff for all index i . [1..|t|], if t(i)= res( , , , out) then out \n= fT (g(i)) Consider a function g : [1..|t|] . IT * that explains trace t and consider two functions \nfinit . rinit and fabort . rinit. In order to de.ne validity, commit-order, init-order, and abort-order \nwe need thede.nitions22 to28below. De.nition 22. Commit Indices and Commit Histories. If i . [1..n] is \nsuch that t(i)= res( , , , ) then we say that i is a (t, m, n)-commit index and that g(i) is a (t, g)-commit \nhistory. De.nition23. Init Indices and Init Histories. If i . [1..n] is such that t(i)= swi( ,m, ,v) \nwe say that i is a (t, m, n)-init index and that finit(i) is a (t, m, n, finit)-inithistory. De.nition24. \nAbort Indices and Abort Histories. If i . [1..n] is such that t(i)= swi( ,n, ,v) we say that i is a (t, \nm, n)-abort index and that fabort(i) is a (t, m, n, fabort)-aborthistory. The multiset ivi(m, t, finit,i) \ncontains all the inputs known to tohavebeeninvokedinphases (k, l), where l = m: De.nition25. Initially \nValid Inputs. ivi(m, t, finit,i)=  {elems(finit(v)) .{in}|.j < i.t(i)= swi( , m, in,v)}. Note that, \nin the previous de.nition, is the multiset union (de.ned in Section 3)and corresponds to pointwise maximum \nof representationfunctions. Now recall that inputs(t, i) is the sequence of inputs that were invokedbefore \ni in t. De.nition26. Valid Inputs. Wede.ne vi(m, t, finit,i)= ivi(m, t, finit,i) .elems(inputs(t, i)) \nDe.nition 27. Valid Commit Index. For all index i such that t(i)= res( , , in, ), we say that i is (t, \ng, finit)-valid if and only if elems(g(i)) . vi(m, t, finit,i) and the input in is the last element ofhistory \ng(i). De.nition28. Valid Abort Index. For all index i such that t(i)= swi( , n, in,v), we say that i \nis (t, finit,fabort)-valid if and only if elems(fabort(v)) .{in}. vi(m, t, finit,i). We now de.ne validity, \ncommit-order, init-order, and abort\u00adorder: De.nition 29. Validity(t, g, finit,fabort): All (t, m, n)-commit \nin\u00addices are (t, g, finit)-valid and all (t, m, n)-abort indices are (t, finit,fabort)-valid. De.nition30. \nCommit Order(t,g):For allpair ofdistinctcommit indices i, j, either g(j) is a strict pre.x of g(i) or \ng(i) is a strict pre.x of g(j). De.nition 31. Init Order(t, g, finit,fabort): The longest common pre.x \nofall (t, m, n, finit)-inithistoriesis a strictpre.x of all (t, g)\u00adcommithistories and of all (t, m, \nn, fabort)-abort histories. We assume that the longest common pre.x of an empty set of historiesis the \nemptyhistory. De.nition32. Abort Order(t, g, fabort):All (t, g)-commithistories arepre.x of all (t, m, \nn, fabort)-aborthistories. Notethatifm =1,then t has noinithistories.HenceInitOrder does not constrain \ncommit and aborthistories.  5.4 Well-FormedTraces The well-formedness condition de.nes basic requirements \non traces of a concurrent object. Given a clientc letActT (c, m, n) bethe setof actions suchthat ActT \n(c,m, n)= {inv(c, o, in)|o . [m..n] . in . IT } .{res(c, o, in,r)|o . [m..n] . in . IT . r . OT } .{swi(c, \no, in,v)|o .{m, n}. in . IT . r . OT . v . Init} Note that the switchactions whose secondparameteris \nnot m or n areprojected away. De.nition33. Client sub-trace. The(m, n)-client-sub-trace ofthe trace t \nis the trace sub(t, m, n, c)= proj(t, ActT (c, m, n)). De.nition34. Well-formed client sub-trace. A (m, \nn)-client sub\u00adtrace tc is well-formediffitis empty or: For all i . [1..|tc |- 1], if t(i)= inv( , , in) \nor t(i)= swi( , m, in, ), then t(i +1) = res( , , in, ) or t(i +1) = swi( , n, in, ).  If tc contains \nan abort action thenitis thelast element of tc.  If m =.1 then tc(1) is aninit action and there are \nno other init actionsin tc.  If m =1 then tc(1) is an invocation and there are no init actionsin tc. \n  De.nition 35. Well-formed traces. We say that the trace t is (m, n)-well-formed if and only if all \nits (m, n)-client sub-traces are well-formed.  5.5 The SLinT Trace Property Wede.ne the traceproperty \nSLinT (m, n) asfollows: De.nition36. The SLinT (m, n) is such that the signature sig(SLinT (m, n)) is \nsigT (m, n, Init) and the set Traces(SLinT (m, n)) is the set of all traces satisfying (m, n)\u00adspeculative \nlinearizability. Finally, consider a system S whose behavior is denoted by a traceproperty P .We say \nthat the system S is a(m, n)-speculation phaseifand onlyif proj(P, sig(m, n)) |= ALin(m, n). Theorem \n2. For all natural number m, any initialization set Init, and anyinitialization relation rinit, proj(SLinT \n(1,m), acts(sigT )) = LinT Proof. Compared tolinearizability, speculative linearizability only adds constraints \non the actions that are not in the signature sigT . 5.6 Intra-ObjectCompositionTheorem Our main theorem \nstates that the composition of two speculation phasesis also a speculationphase. Theorem 3. Suppose that \nS1 |= SLinT (m, n) and S2 |= SLinT (n, o), then proj(S1 ||S2 , sigT (m, o, Init)) |= SLinT (m, o). Theproof \nof this resultin the technical report[9].It consists of two pages in the current format. Among the key \nsteps is the con\u00adstruction of a speculative linearization function g that explains the traces ofthe composition \noftwophases.Thefunctionisconstructed by merging two speculative linearization functions. To show that \nit is indeed a speculative linearization function we use a form of transitive reasoning to relate commit \nhistories between different phases through abort histories. Among the properties of specula\u00adtivelinearizability,Validityis \nthe mostdif.cult to show,inpartbe\u00adcauseitis sensitive to thefact that we allowduplicate eventsin our \ntraces(something that even most existingdevelopments of classic linearizabilityignore).  6. AutomataSpeci.cationofSpeculative \nLinearizability andIsabelle/HOLProof WehavealsoformalizedinIsabelle/HOL anexecutable versionof the speci.cation \nof speculativelinearizability.Ourformalizationis based onthetheory ofI/O-automata[21], whichisformalizedin \nIsabelle sIOAframework[22].Our speci.cation automaton cor\u00adresponds to speculative linearizability instantiated \nfor State Ma\u00adchineReplication[16]protocols(abbreviated SMRprotocols).We wrote a mechanically-checked \nproof of the intra-object composi\u00adtion theorem for the automata speci.cation. Thanks to this proof, itis \nnowpossible to obtain mechanically-checked proofs of specu\u00adlativeSMRprotocolsfromthemechanically-checkedproofs \nofits speculation phases taken in isolation. Moreover, our proof of the intra-object composition theorem \nshows that re.nement proofs in ourframework arepractical. The speculative approach to SMR protocols has \nbeen shown toyield some of the most ef.cientSMRprotocolsinpractice[8]. Therefore, ourformalization andtheproof \nof theintra-object com\u00adposition theorem enable for the .rst time scalable mechanically\u00adcheckedproofs \nofpracticalSMRprotocols.Aproofdocument and the corresponding Isabelle theories are available at the Archive \nof FormalProofs[10]. Informal Description of the Automata Speci.cation. The au\u00adtomata speci.cationis \naformalization of speculativelinearizability for anADT that we call the universalADT.The outputfunction \nof the universalADTistheidentityfunction.In other words,thisADT responds to an invocation with its full \ntrace, in the form of a his\u00adtory.The universalADT canbe used as anabstractionforgeneric SMRprotocols[8]because,given \nalinearizableimplementation,it suf.ces to apply the output function of another ADT A to the re\u00adsponsesinorderobtain \nanimplementation ofA.Weformalizethe case where histories of inputs are used as initialization values \nand where the relation rinit maps a history h to the singleton set {h}. The speci.cation automaton can \nbe seen as an implementation of speculative linearizability in which all clients reside on a unique, \ncentralized,process. The automaton receives invocations and switch calls as inputs andproduces responses \nand switch call outputs. The speci.cation automaton maintains a state with the follow\u00ading components: \n Ahistory hist, representing thelongestlinearization made visi\u00adble to a client(i.e. thelongest commithistory); \n for each client c, aphase phase(c) .{ Sleep, Pending, Ready, orAborted };  for each client c,pending(c), \nthelastinput submittedby c;  a set InitHistscontaining theinithistories received;  twobooleans: aborted \nand initialized. We say that aninputispending ifitis thelast submittedinput of a client c whosephaseis \nPending andifitisnotpresentin hist. The automaton startsin a state where hist is the emptyhistory, InitHists \nis the empty set, aborted and initialized are set to false, andfor all clients c,phase(c)= Sleep . We \nnow describe how the automaton reacts to the inputs it receives, namely invocations and switch calls \nfrom the previous phase. When receiving a switch call from the previous phase by client c, if phase(c) \nequals Sleep then the automaton adds the provided init history to the set InitHists and sets pending(c) \nto the provided input. When receiving a new invocation by client c, if phase(c) equals Ready , the automaton \nsets pending(c) to the input received. In both cases phase(c) is then set to Pending . Thisdenotes thefact \nthat client c is waitingfor a response toinput pending(c).  Moreover, the automaton nondeterministically \nperforms one of thefollowing actions: A1 If initialized = false and if there is at least one client c \nsuch that phase(c) is not Sleep , then the automaton computes the longestcommonpre.x of thehistoriesin \nInitHists, assignsitto hist, and sets initializedto true. A2 It selects a pending input, say from client \nc, appends it to hist, emits an output for client c containing thenew value of hist as response, and \nsets phase(c) to Ready . A3 Itsets aborted to true. A4 If aborted = true then a client c such that phase(c) \nis not Aborted is selectedis phase(c) issetto Aborted .Moreover, the automaton emits a switch action \ncontaining an abort value h ' such that hist is apre.x of h ' and theinputs of h ' which are notin histarepending. \nThe precise de.nition of our speci.cation automaton is avail\u00adablein theALM entry[10] of theArchive ofFormalProofs. \nRelation to the Trace Based Speci.cation. The trace-based speci.cation requires associating histories \nto responses (commit histories) and switch actions(init and aborthistories).Because our ADT s outputfunctionis \ntheidentity andbecause rinit(h)= {h}, we have no choice but to associate to a response or switch action \nthe very history it contains (remember that outputs and switch values are histories in this section). \nHence commit histories are obtainedbytruncating histat apending request.Since histgrowsby appending toit, \nwehave thatCommitOrderis satis.ed.Moreover, aborthistories are obtainedby appending somepending requeststo \nhist, and at this point hist does not grow anymore. Hence Abort Order holds. Since hist is initialized \nwith the longest common pre.x of the init histories seen, Init Order also holds. Finally, hist growsbyappendingpending \nrequeststoit,Validityis also satis.ed.  To gain more insight into speculative linearizability, one may \nalso observe that any extension of history hist with some pending requestsis alinearization ofthe current \ntrace.Thanks tothis obser\u00advation, stepA2 maybeinterpreted as selecting apossiblelineariza\u00adtion and producing \nan output that realizes it. Step A4 can be seen aspassing one of thepossiblelinearizations to the next \nspeculation phase. Finally, in step A1, the automaton computes the weakest (giventheinithistoriesitreceived) \nunder-approximation of theset of possible linearizations of the previous phase and selects one of them \ntoinitializeits execution. Proof of the Intra-Object Composition Theorem. To prove the intra-object composition \ntheorem in this formulation, we con\u00adstruct a re.nement mapping[20] betweenthe composition of two speculation \nphases and a single speculation phase. We prove the re.nement mapping correct with the help of 15 state \ninvariants about the composed automaton. Using the meta-theorem about re\u00ad.nement mappings(includedintheIOA \ntheorypackaged withIs\u00adabelle/HOL), we conclude that the set of traces of the composition of two speculationphasesisincludedin \nthe set oftraces of a single speculationphase. Theproofis writtenin the structuredprooflan\u00adguageIsar[26]and \nconsists of roughly of500proof steps.Withthe speci.cation,itforms a total of1600lines ofIsabelle/HOL \ncode. Our automata speci.cation can be used as the basis for mechanically-checked re.nement proofs of \ndistributed protocols. Our proof of the composition is a good example of such a re.ne\u00admentproof and shows \nthepracticality of the approach.  7. ConcludingRemarks We have presented speculative linearizability, \nan extension of the theory of linearizability. Our extension allows us to implement linearizable objects \nby composing independently devised specula\u00adtion phases that are optimized for different situations. This \nform of intra-object composition complements the classical concept of inter-objectcomposition,inherenttolinearizabilityinitstraditional \nform.Weproposeaformalizedframeworkthatenables,forthe .rst time, scalable mechanically-checked development \nof linearizable objects of arbitrary abstractdata types. Our work canbe viewed asgeneralization of[1] \nand[2].The former work focused on contention-free executions and did not address composition: aprotocol \nthat aborts simply stops executing with nopossibility of switching. In thelatter work, a classi.cation \nof the trace properties that are switchable is proposed. A global synchronizationis requiredfor switching.In \ncontrast, our notion of speculative linearizabilitydoes not require the switchingprotocols to solve agreement \nand is, in that sense, much more general. Our work can also be viewed as a formalization of a generalized \nform of Abortable State Machine Replication(Abstract), an abstraction presentedin anintuitiveformin[8] \nto allow the construction of speculativeByzantineFaultTolerantSMRprotocolsby composing independentlydesigned \nspeculationphases.Compared to[8] ,our work concerns arbitrary abstract data types, including one-shot \nones, andgeneralizes theideatolinearizability.Being strictly more general, our framework can be used \nto reason about the fault\u00adtolerant algorithmsdevelopedfollowing those approaches[1,2,8].  References \n[1] M.K.Aguilera,S.Frolund,V.Hadzilacos,S.L.Horn, andS.Toueg. Abortableandquery-abortable objectsand \ntheiref.cientimplementa\u00adtion. In PODC,2007. [2] M. Bickford, C. Kreitz, R. v. Renesse, and X. Liu. Proving \nhybrid protocols correct. In TPHOLs 01,2001. [3] W.J.Bolosky,D.Bradshaw,R.B.Haagens,N.P.Kusters, andP.Li. \nPaxos replicated state machines as the basis of a high-performance data store. In Proc.NSDI.USENIXAssoc.,2011. \n[4] M.Burrows.TheChubbylock serviceforloosely-coupleddistributed systems. In Proc.OSDI.USENIXAssoc.,2006. \n[5] M.CastroandB.Liskov.Acorrectnessproofforapracticalbyzantine\u00adfault-tolerant replication algorithm. \nTechnical report,MIT,1999. [6] M.CastroandB.Liskov.PracticalByzantinefaulttolerance.InOSDI, 1999. [7] \nE. Gafni and L. Lamport. Disk paxos. Distributed Computing, 16(1):1 20, 2003. [8] R.Guerraoui,N.Knezevic,V.Quema,andM.Vukolic.TheNext700 \nBFTProtocols. In EUROSYS,2010. [9] R. Guerraoui, V. Kuncak, and G. Losa. Speculative Linearizability. \nTechnical Report170038,EPFL,2011. [10] R. Guerraoui, V. Kuncak, and G. Losa. Abortable linearizable modules. \nIn G. Klein, T. Nipkow, and L. Paulson, editors, The Archive of Formal Proofs. http://afp.sf.net/entries/ \nAbortable_Linearizable_Modules.shtml, March2012. Formal proofdevelopment. [11] M. Herlihy. Wait-free \nsynchronization. ACM Trans. Program. Lang. Syst.,13:124 149, January1991. [12] M.P.Herlihy andJ.M.Wing.Linearizability: \nacorrectnesscondition for concurrent objects. ACMTrans.Program.Lang.Syst.,12(3):463 492,1990. [13] M.Jaskelioff \nandS.Merz. Proving thecorrectness ofDiskPaxos. In G. Klein, T. Nipkow, and L. Paulson, editors, The Archive \nof Formal Proofs. http://afp.sf.net/entries/DiskPaxos.shtml, June 2005. Formalproofdevelopment. [14] \nP. Jayanti. Adaptive and ef.cient abortable mutual exclusion. In PODC,2003. [15] R. Kotla, L. Alvisi, \nM. Dahlin, A. Clement, and E. Wong. Zyzzyva: speculative Byzantine fault tolerance. In SOSP,2007. [16] \nL. Lamport. The implementation of reliable distributed multiprocess systems. Computer Networks,2:95 114,1978. \n[17] L.Lamport.Oninterprocess communication.partI:Basicformalism. Distributed Computing, 1(2):77 85,1986. \n[18] L. Lamport. On interprocess communication. part II: Algorithms. Distributed Computing, 1(2):86 101,1986. \n[19] L.Lamport.Afast mutual exclusion algorithm. ACMTrans.Comput. Syst.,5(1):1 11,1987. [20] N. Lynch \nand F. Vaandrager. Forward and backward simulations I: untimed systems. Inf.Comput.,121:214 233, September1995. \n[21] N. A. Lynch and M. R. Tuttle. An introduction to input/output au\u00adtomata. CWIQuarterly,2:219 246, \n1989. [22] O. M\u00a8uller. I/O automata and beyond: Temporal logic and abstraction inIsabelle. In TPHOLs,pages331 \n348,1998. [23] F. Pedone. Boosting system performance with optimistic distributed protocols. Computer,34(12):80 \n86, 2001. [24] A. Singh, T. Das, P. Maniatis, P. Druschel, and T. Roscoe. BFT protocols under .re. InNSDI,2008. \n[25] M. M. V. Luchangco and N. Shavit. On the uncontended complexity of consensus. In ICDCS,pages45 59,2003. \n[26] M.Wenzel.Isar -agenericinterpretativeapproach toreadableformal proofdocuments. InTPHOLs,pages167 \n184,1999.  \n\t\t\t", "proc_id": "2254064", "abstract": "<p>Linearizability is a key design methodology for reasoning about implementations of concurrent abstract data types in both shared memory and message passing systems. It provides the illusion that operations execute sequentially and fault-free, despite the asynchrony and faults inherent to a concurrent system, especially a distributed one. A key property of linearizability is inter-object composability: a system composed of linearizable objects is itself linearizable. However, devising linearizable objects is very difficult, requiring complex algorithms to work correctly under general circumstances, and often resulting in bad average-case behavior. Concurrent algorithm designers therefore resort to speculation: optimizing algorithms to handle common scenarios more efficiently. The outcome are even more complex protocols, for which it is no longer tractable to prove their correctness.</p> <p>To simplify the design of efficient yet robust linearizable protocols, we propose a new notion: <i>speculative linearizability</i>. This property is as general as linearizability, yet it allows intra-object composability: the correctness of independent protocol phases implies the correctness of their composition. In particular, it allows the designer to focus solely on the proof of an optimization and derive the correctness of the overall protocol from the correctness of the existing, non-optimized one.</p> <p>Our notion of protocol phases allows processes to independently switch from one phase to another, without requiring them to reach agreement to determine the change of a phase. To illustrate the applicability of our methodology, we show how examples of speculative algorithms for shared memory and asynchronous message passing naturally fit into our framework.</p> <p>We rigorously define speculative linearizability and prove our intra-object composition theorem in a trace-based as well as an automaton-based model. To obtain a further degree of confidence, we also formalize and mechanically check the theorem in the automaton-based model, using the I/O automata framework within the Isabelle interactive proof assistant. We expect our framework to enable, for the first time, scalable specifications and mechanical proofs of speculative implementations of linearizable objects.</p>", "authors": [{"name": "Rachid Guerraoui", "author_profile_id": "81100348136", "affiliation": "Swiss Federal Institute of Technology Lausanne (EPFL), Lausanne, Switzerland", "person_id": "P3471148", "email_address": "rachid.guerraoui@epfl.ch", "orcid_id": ""}, {"name": "Viktor Kuncak", "author_profile_id": "81100277693", "affiliation": "Swiss Federal Institute of Technology Lausanne (EPFL), Lausanne, Switzerland", "person_id": "P3471149", "email_address": "viktor.kuncak@epfl.ch", "orcid_id": ""}, {"name": "Giuliano Losa", "author_profile_id": "81502730363", "affiliation": "Swiss Federal Institute of Technology Lausanne (EPFL), Lausanne, Switzerland", "person_id": "P3471150", "email_address": "giuliano.losa@epfl.ch", "orcid_id": ""}], "doi_number": "10.1145/2254064.2254072", "year": "2012", "article_id": "2254072", "conference": "PLDI", "title": "Speculative linearizability", "url": "http://dl.acm.org/citation.cfm?id=2254072"}