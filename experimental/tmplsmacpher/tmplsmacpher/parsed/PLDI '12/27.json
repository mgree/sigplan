{"article_publication_date": "06-11-2012", "fulltext": "\n Synchronising C/C++ and POWER Susmit Sarkar1 Kayvan Memarian1 Scott Owens1 Mark Batty1 Peter Sewell1 \nLuc Maranget2 Jade Alglave3 DerekWilliams4 1 University ofCambridge, {first.last}@cl.cam.ac.uk 3University \nof Oxford, jade.alglave@comlab.ox.ac.uk 2 INRIA, luc.maranget@inria.fr 4IBM Austin, striker@us.ibm.com \nAbstract Shared memory concurrency relies on synchronisation primitives: compare-and-swap, load-reserve/store-conditional \n(aka LL/SC), language-level mutexes, and so on. In a sequentially consistent setting, or even in the \nTSO setting of x86 and Sparc, these have well-understood semantics. But in the very relaxed settings \nof . R IBM RPOWER , ARM, orC/C++, it remains surprisingly unclear exactly what the programmer can depend \non. This paper studies relaxed-memory synchronisation. On the hardware side, we give a clear semantic \ncharacterisation of the load-reserve/store-conditional primitives as provided by POWER multiprocessors, \nfor the .rst time since they were introduced 20 years ago; we cover their interaction with relaxed loads, \nstores, barriers, and dependencies. Our model, while not of.cially sanc\u00adtioned by the vendor, is validated \nby extensive testing, comparing actual implementation behaviour against an oracle generated from the \nmodel, and by detailed discussion with IBM staff. We believe the ARM semantics to be similar. On the \nsoftware side, we prove sound a proposed compilation scheme of the C/C++ synchronisation constructs to \nPOWER, in\u00adcluding C/C++ spinlock mutexes, fences, and read-modify-write operations, together with the \nsimpler atomic operations for which soundness is already known from our previous work; this is a .rst \nstep in verifying concurrent algorithms that use load-reserve/store\u00adconditional with respecttoa realistic \nsemantics.We alsobuild con\u00ad.dence in the C/C++ model in its own terms, .xing some omis\u00adsions and contributing \nto the C standards committee adoption of the C++11 concurrencymodel. Categories and Subject Descriptors \nC.1.2[Multiple Data Stream Architectures (Multiprocessors)]:Parallel processors; D.1.3[Con\u00adcurrent Programming]: \nParallel programming; F.3.1 [Specifying andVerifying and Reasoning about Programs] General Terms Languages, \nReliability, Standardisation, Theory, Veri.cation Keywords Relaxed Memory Models, Semantics 1. Introduction \nSynchronisation is fundamental to shared-memory concurrency, but the properties of basic real-world synchronisation \nprimitives re- Permission to make digital or hard copies of all or part of this work for personal or \nclassroomuseisgrantedwithout feeprovidedthat copies arenot madeordistributed forpro.torcommercialadvantage \nandthatcopiesbearthisnoticeandthefullcitation onthe .rstpage.To copy otherwise,to republish,topostonserversorto \nredistribute tolists, requirespriorspeci.cpermission and/ora fee. PLDI 12, June11 16,2012, Beijing, China. \nCopyright c . 2012ACM978-1-4503-1205-9/12/06. . .$10.00 main surprisingly unclear: thereisabiggap betweenthe \nusualde\u00adscriptions of their behaviour, which presuppose a sequentially con\u00adsistent (SC)[Lam79] setting, \nand their behaviour in actual multi\u00adprocessors and programming languages, which are not SC. Instead of \ninterleaving operations from different threads, all with a consis\u00adtent view of memory, real systems expose \nrelaxed memory models to the programmer, to allow for hardware and compiler optimisa\u00adtions. In such a \nsetting, even basic properties, such as locks ensur\u00ading that locations are not concurrently accessed \n, become hard to understand, as one cannot reason in simple global-time terms; the semantics of synchronisation \nprimitives are necessarily intertwined with the relaxed semantics of other code, including whatever loads, \nstores, and barriers are present. This paper addresses relaxed-memory synchronisation in hard\u00adware and \nin software, and the relationship between the two. Our .rst main contribution, on the hardware side, \nis a usable model for the synchronisation primitives, load-reserve/store-conditional pairs, of the highly \nrelaxed IBM RPower Architecture R(\u00a72). While these have been present in the architecture for 20 years, \ntheir relaxed-memory behaviour have never before been clearly ex\u00adplained (for example, confusion on this \npoint has led to a Linux kernel bug in the implementations of atomic operations [McK11], as we remark \nin \u00a72). We do so with a novel abstraction, of a write reaching coherence point, with just the properties \nthat are needed in the semantics. This removes anyneed for modelling the implemen\u00adtation detail of reservation \nregisters, which becomes very complex in a setting with speculative and out-of-order execution. We establish \ncon.dence in our model in multiple ways (\u00a73), including extensive experimental testing (comparing processor \nbe\u00adhaviour against the model), detailed discussion with IBM staff, and proofs of basic properties, about \nthe strength of load-reserve/store\u00adconditional pairs(\u00a73.2), and that a simple locking discipline guar\u00adantees \nSC for POWER programs(\u00a75). For our second main contribution, on the software side, we prove correctness \nof a mapping of the principal C/C++ synchro\u00adnisation constructs to POWER (\u00a75). We consider C/C++ locks, \natomic read-modify-write (RMW) operations, fences, and atomic loads and stores, with the various possible \nmemory-order param\u00adeters, from relaxed to SC (for locks we consider basic mutexes, not reentrant or timed, \nand just their lock and unlock interface, and we do not consider condition variables or futures). We \ntake the implementation of spinlocks from the POWER documenta\u00adtion [Pow09, p.717,718], combining that \nwith the POWER imple\u00admentation of C/C++ RMWs, fences and atomic operations pro\u00adposed by McKenney and \nSilvera [MS11]. Locks and RMWs both rely on the POWER load-reserve/store-conditional. In the processof \ndoing this proof, we identi.ed and .xed several technical issues with theC/C++11 concurrencymodel and \nwith our previous formalisation; we describe those in \u00a74, together with a brief summary of the design \nof that model and an explanation of the C/C++ fences, to make this paper as self-contained as possible. \n POWER and C/C++11 are both subtle models, though of quite different kinds, and there is an interplay \nbetween them: imple\u00admentability on POWER (and the similar ARM) had a major in.u\u00adence on the design of \nC/C++11, and, conversely, the desire to sup\u00adport ef.cient language implementation imposes constraints \non the architecture. Our work illuminates such choices by showing what is necessary for soundness; as \nwe show in \u00a72, the models are in some respects tight against each other. More generally, our correctness \nproof for this lock implementa\u00adtion is a .rst step towards reasoning about more sophisticated con\u00adcurrent \nalgorithms (using load-reserve/store-conditional synchroni\u00adsation directly, or in C/C++) with respect \nto a realistic semantics; and our models provide a basis for future work on compiler cor\u00adrectness, program \nanalysis andveri.cation, and toolbuilding. Our models and the statements of our results and key lemmas \nare expressed in the lightweight mechanised speci.cation language Lem [OBZNS11]; our proofs are rigorous \nbut non-mechanised. The details of both are available online in the supplementary mate\u00adrial [cpp], together \nwith the data from our experimental testing and our ppcmem web interface for interactively exploring \nthe model. Related Work There is surprisingly little directly related work. Webuild.rstonourown recentlineofwork,wherewehavedevel\u00adoped \na high-.delity abstract-machine model of the loads, stores and barriers of the POWER architecture, without \nload-reserve/store\u00adconditional (Sarkar et al. [SSA+11]). On the C/C++ front, Boehm and Adve describe \nthe core of the C/C++11 design [BA08]. We have provided a mathematisation of the concurrency model of \nC/C++11 (Batty et al. [BOS+11]), which we correct and use here. There, we also proved correctness of \na compilation scheme from C/C++11 nonatomic and atomic loads and stores, and fences, to x86-TSO. The \nstrength of the target memory model (and the omis\u00adsion of locks and RMWs) makes that a much simpler problem \nthan the one we address here. We previously used these two models to show correctness of compilation \nfrom C/C++11 to POWER, for the fragment ofC/C++ consisting just of nonatomic and atomic stores and loads \nof various kinds [BMO+12]. Here our extended models and proof .nally cover all of the main features of \nconcurrency in POWER and inC/C++. There have been, to the best of our knowledge, three previ\u00adous serious \nattempts at realistic relaxed-memory semantics of load\u00adreserve/store-conditional in the POWER setting, \nnone of which are satisfactory for the current architecture. Corella, Stone, and Bar\u00adton [CSB93] give \nan axiomatic model and show the correctness of an implementation of locks in terms of it. Their model \ndoes not cover the weaker lwsync barrier (which was not present in the Power Architecture of the time), \nand their lock implemen\u00adtation is therefore more conservative than the one we consider, with two syncs. \nMoreover, as Adir et al. note [AAS03], the ba\u00adsic model is .awed in that it permits the non-SC .nal state \nof a message-passing-with-syncs example. Adir et al. give a more elaborate model, with a view order per \nthread, sketching exten\u00adsions for the synchronisation instructions, but this is still for the non-cumulative \nbarriers of the time. Our previous global-time ax\u00adiomatic model (Alglave et al. [AM11]) appears reasonable \nfor load\u00adreserve/store-conditional in isolationbut too weak for the POWER lwsync barrier, permitting \nsome behaviour that the C/C++11 map\u00adping requires to be forbidden.  2. Optimistic Synchronisation on \nPOWER: Load-reserve/Store-conditional Load-reserve/store-conditional primitives were introduced by Jensen \net al. [JHB87] as a RISC-architecture alternative to the compare-and-swap (CAS) instruction; they have \nbeen used in the . R IBM RPowerPC . architecture since 1992 and are also present in ARM, MIPS, and Alpha. \nThey are also known as load-linked/store\u00adconditional (LL/SC), or, on ARM, load-exclusive/store-exclusive. \nThey provide a simple form of optimistic concurrency (very roughly, optimistic transactions on single \nlocations). Herlihy [Her93] uses load-reserve/store-conditional to imple\u00adment various wait-free and lock-free \nalgorithms, noting that (as for CAS, but unlike test-and-set and fetch-and-add) it is universal in terms \nof consensus number, and moreover that load-reserve/store\u00adconditional is practically superior to CAS \nin that it defends against the ABA problem. These results, as for almost all other work in concurrent \nalgorithms, use an underlying sequentially consistent (SC)semantics. In a sequentially consistent setting, \none can describe the be\u00adhaviour of load-reserve/store-conditional fairly simply. A load\u00adreserve does \na load from some memory address; and a subsequent store-conditional to the same address will either succeed \nor fail. It will de.nitely fail if some other thread has written to that address in the meantime (or \nfor some other reasons), otherwise (where the write read from by the load-reserve is still the most recent \nwrite to that address) it might succeed, performing a store. Moreover, the store-conditional sets a .ag \nso that later instructions can de\u00adtermine whether or not it succeeded; load-reserve/store-conditional \npairs are often repeated until success. This makes it easy to express a variety of atomic update operations, \nas in the following POWER assembly code for an atomic add (ARM code would be similar, with LDREX and \nSTREX): 1:lwarx r0,0,r2 \\\\ load-reserve from [r2] to r0 add r0,r1,r0 \\\\ add register r1 to register \nr0 stwcx. r0,0,r2 \\\\ store-conditional r0 to [r2] bne-1b \\\\ ...looping until success In an SC world, \nthe store-conditional would be guaranteed to fail if some other thread writes to [r2] since the load-reserve; \nwhich could be achieved in hardware by monitoring whether any other threadgains writeownershipof the \ncache line holding [r2] in the meantime. Note that other operations are permitted between the load-reserve \nand store-conditional, including memory reads and writes, though, unlike transactions, nothing is rolled \nback if the store-conditionalfails. However, actual POWER and ARM multiprocessors are not se\u00adquentially \nconsistent,but rather have highly relaxed memory mod\u00adels, in which program executions are not simple \ninterleavings of the instructions of each thread. A priori, it is unclear what it means to say that another \nthread has written to the relevant address between the load-reserve and store-conditional, as one has \nto understand how they interact with the thread-local out-of-order and specula\u00adtive execution, and with \nthe storage subsystem reordering, of these machines. Moreover, the vendor architecture [Pow09] does not \nre\u00adsolve these questions as clearly as one might hope. It describes the behaviour of load-reserve/store-conditional \ninformally in terms of reservations, allowing a store-conditional to succeed only if the storage location \nspeci.ed by the lwarx that established the reser\u00advation has not been stored into by another processor \nor mecha\u00adnism since the reservation was created . This is simultaneously too much and too little hardware \nimplementation detail: the since cannot refertoanSC order,butthe machineexecution orderisnot precisely \nspeci.ed. We solve these problems with an abstract-machine semantics, extending the model of Sarkar et \nal. [SSA+11] to cover load\u00adreserve/store-conditional. That model comprises a thread seman\u00adtics, with \nexplicit out-of-order and speculative execution of each hardware thread, composed with a storage subsystem \nsemantics. The latter abstracts from the cache and store-buffer hierarchy and from the cache protocol: \nfor each address it maintains just a strict partial order, the coherence order, of the ordering commitments \nthat have been made among the writes to that address, and for each thread it maintains a list of the \nwrites (and barriers) that have been propagated to that thread. For example, at a certain point in abstract-machine \nexecution, one might have established these con\u00adstraints among5 writes (by different threads) to x: \n  c:W x=4 i:W x=0 j:W x=1 a:W x=2 b:W x=3 with writes [i:W x=0, a:W x=2] propagated to some arbitrary \nthread. In that state, a read of x by that thread would see the most recent of those two, reading 2; \nor write b could be propagated to that thread, appending it to that list (as it is coherence-after the \nwrites already propagated there); or a partial coherence commit\u00adment transition could make c ordered \nbefore a, or after a but still unrelated to b, or before b but still unrelated to a, or after b.A new \nwrite by a thread is made coherence-after all writes previously propagated to that threadbut initially \ncoherence-unrelated to other writes. This machinery guarantees coherence in the normal sense, and also \nsupports a semantics for the POWER cumulative memory barriers in its non-multi-copy-atomic setting, where \nwrites to dif\u00adferent addresses can propagate to other threads in different orders. The sync and lwsync \nbarriers constrain that propagation, as we return to in \u00a75, anda sync also waits until writes that have \nprevi\u00adously been propagated to its thread (the sync s Group A), or some coherence successors thereof, \nhave been propagated to all threads. Looking at a successful load-reserve/store-conditional pair in these \nterms, we can see that for it to provide an atomic update, the write of the store-conditional must become \nan immediate coher\u00adence successor of the write read from by the load-reserve, with no other coherence-intervening \nwrite to the same address. Moreover, that property must be maintained: no other write can be allowed \nto become coherence-intervening later in the abstract-machine ex\u00adecution. To express this, the key thing \nwe need to introduce to the model is the concept of a write reaching coherence point, after which its \ncoherence-predecessors are linearly ordered and .xed (no additional write can become coherence-before \nit). Our main new rule describing how the storage subsystem (in state s)can process a successful store-conditional \nis as follows. Accept a successful write-conditional request A write\u00adconditional request w by a thread \ntid, with an accompanying wprev that was read by the program-order-previous read-reserve, can be accepted \nand succeed if: 1. the write wprev is to the same address as w ; 2. wprev has reached coherence point; \n 3. no coherence-successor of wprev by another thread has reached coherence point or has been propagated \nto thread tid ;and 4. all writes by tid to the same address as wprev (in particular, all those since \nwprev was propagated to tid) have reached coherence point.  Action: 1. add the new write w to s.writes \nseen, to record the new write as seen by the storage subsystem; 2. append the new write w to s.events \npropagated to (tid ), to record the new write as propagated to its own thread; 3. record that w has \nreached coherence point; and 4. update s.coherence by adding edges to make write w :  (a) coherence-after \nall writes to the same address that have reached coherence point (including wprev ); and (b) coherence-before \nall writes seen (except itself) to the same address that have not yet reached coherence point. Note that \na store-conditional can succeed even if there are out\u00adstanding other writes to the same address by different \nthreads (that might have been read from by yet different threads), but that any such other writes become \ncoherence-later than the store-conditional itself. For example, given the coherence order above, if only \ni has reached coherence point, and if just i has been propagated to some thread, that thread could do \nan atomic add of 5 by executing a load\u00adreserve of x=0 from i, adding 5 to that value, and doing a successful \nstore-conditional of x=5, the latter becoming an immediate coher\u00adence successor of i, and a coherence-predecessor \nof all the other writes:  c:W x=4 writes that have reached coherence point j:W x=1 a:W x=2 b:W x=3 \nAlternatively, in another execution, a could become coherence\u00adbefore c, then j and a could reach coherence \npoint, and that load\u00adreserve could read 2 from a and add 5, with the resulting store\u00adconditional of 7 \nbecoming an immediate coherence successor, coherence-before just b and c: c:W x=4 writes that have reached \ncoherence point i:W x=0 j:W x=1 a:W x=2 d:W* x=7 b:W x=3 Astore-conditionalcan nondeterministicallyfail \nat anytime, mod\u00adelling clearing of the reservation by various events, including writes to other addresses \nwithin the same cache line, hypervi\u00adsor/OS context switches, and implementation-speci.c character\u00adistics \nof the coherence mechanism [which] cause the reservation to be lost [Pow09] (moreover, the architecture \nexplicitly does not in\u00adclude a fairness guarantee). It is believed that current implementa\u00adtions do provide \nforward progress,but the architecture text does not guarantee it; without characterising those implementation-speci.c \ndetails, and making assumptions on the other events, we have to assume that arbitrary store-conditional \nfailures are possible. This effectively restricts one to reasoning about safety properties. In this paper \nwe do not model the architecture s reservation granules: the rules above consider only whether write-conditionals \nand load-reserves are to exactly the same address (which is the nor\u00admal use-case),but in the architecture \nthe signi.cantfact is whether the two addresses lie in the same reservation granule (in current implementations, \nreservation granules are the same size as cache lines). Modelling realistic (non-single-word) reservation \ngranules would require a store-conditional to fail if there is an intervening write to the same granule, \nand permit a store-conditional to succeed if the preceding load-reserve was to any address in the same \ngran\u00adule. This could be done by modifying preconditions in the above rule, to say that no write to an \naddress in the same granule as the store-conditional has been propagated to tid since wprev was read \nfrom by the load-reserve, and to say that the write wprev read from by the load-reserve was to an address \nin the same granule as the store-conditional. We also have to specify exactly when a write can reach \ncoher\u00adence point, with the rule below. Note that sync and lwsync barri\u00aders constrain the order in which \nwrites can reach coherence point, but, apart from that, barriers and load-reserve/store-conditionals \nare largely independent. Write reaches its coherence point This is an internal transition of the storage \nsubsystem, for a write it has already seen, if:  1. the write has not yet reached its coherence point; \n 2. all its coherence-predecessor writes have reached their coher\u00adence points; and 3. all writes (to \nany address, and by any thread) propagated to the writing thread before a barrier (also by the writing \nthread) before this write, have reached their coherence points.  Action: 1. add this write to s.writes \npast coherence point;and 2. update s.coherence to record that this write is coherence\u00adbefore all writes \nseen (except itself) that are to the same address and are not past their coherence points.  Turning \nnow to the thread semantics, load-reserve and store\u00adconditional instructions all commit in program order \nrelative to each other. Apart from that, load-reserves are committed just like normal loads, while store-conditionals \nare committed by a thread rule that synchronises with the storage-subsytem Accept store\u00adconditional request \nrule above, the thread commit rule additionally imposing: Commit in-.ight instruction ... if this is \na write-conditional instruction: send a write\u00adconditional request mentioning the write read from by the \nmost recent program-order-preceding load-reserve instruction with\u00adout an intervening write-conditional \n(if there is such a load\u00adreserve); receive the corresponding success/fail response; and set .ags accordingly. \nIf there is no such load-reserve, simply set .ags as forafail. Despite the commit-order constraint, a \nload-reserve can be sat\u00adis.ed (by reading a value from the storage subsystem) exactly like a normal load, \nand (like a normal load) this can be done out\u00adof-order and speculatively, long before it is committed. \nIn con\u00adtrast to normal loads, however, there is an additional restriction on load-reserve speculation, \nthat a load-reserve cannot be satis.ed un\u00adtil all program-order previous load-reserves and store-conditionals \nare committed. This models the architectural requirement of a single reservation register per thread. \nIn the model this leads to forbidding the example execution on the left below. Consistent . R with this, \nthe example is not observable on IBM RPOWER . 6 and . R IBM RPOWER . 7 implementations. Test MP+poaa+addr: \nAllowed Note also that despite the constraint on their commit order, store\u00adconditionals to different \naddresses can still propagate to other threads out-of-order, as shown on the right above. This is allowed \nin the model and observable on POWER6 and POWER 7. Each diagram shows the memory read and write events \nof a can\u00addidate execution of an assembly program running on one or more hardware threads; the assembly \nsource code is in the supplemen\u00adtary material. Events include unique ids(a, b, etc.), the addresses of \nreads and writes(x, y, etc.), and the values read and written. Load-reserve and store-conditional events \nare indicated with a star. Various edges pick outkeyrelationships between instructionsin the source, \nor more speci.cally in the particular control-.ow unfolding of the source for the execution in question: \n po edges relates events from instructions in program order (in this control-.ow unfolding);  an lwsync \nedge indicates that there is a POWER lightweight sync barrier in program order between the instructions \nthatgave rise to the two events;  a sync edge indicates a POWER heavyweight sync barrier;  an eieio \nedge indicates a POWER eieio barrier;  an addr edge indicates that the address of the second event is \ndependent (through a data.ow path via registers and computa\u00adtion) on the value read by the .rst;  a \ndata edge indicates that the data written by the second event is dependent on the value read by the .rst; \n a ctrl edge indicates there is a data.ow path from the .rst read read to the test of a conditional \nbranch that program-order\u00adprecedes the second event (branches are not shown explicitly); and  a ctrlisync \nedge indicates there is such a data.ow path from the .rst read to the test of a conditional branch that \nprogram-order\u00adprecedes an isync instruction before the second read.  Three further relations characterise \nthe remainder of the dynamics of the execution: an rf edge from a write to a read indicates that the \nread read\u00adfrom that write(rf edges from the initial state are marked with a red dot for the source); \n a co edge between writes to the same address gives the .nal coherence order between them; and  an \nrcp edge between writes indicates the order in which those writes reached coherence point (usually we \nelide these edges).  Moreover, load-reserve and store-conditional do not impose any special constraint \non normal loads and stores to different addresses: they do not act like a barrier of any kind, and so \nloads after a load-reserve/store-conditional pair might be speculated before it. If one wants to prevent \nthat, one needs to add surrounding barriers. Confusion on this point seems to have been responsible for \na Linux kernel bug [McK11] that was recently identi.ed by McKenney and con.rmed using our model: the \nLinux atomic add return implementation (from which the code above is taken), is assumed there to prevent \nspeculation, but its implementation used overly weak barriers; the same was true for other similar read-modify\u00adwrite \noperations. The example is in the supplementary material. One also has to consider whether writes can \nbe ob\u00adservably forwarded to a load-reserve or from a store\u00adconditional within a thread, on speculative \npaths before they have reached the storage subsystem. This can hap\u00adpen on POWER and ARM for normal loads \nand stores, as shown by the PPOCA example a:Wna x=1 of [SSA+11]. Interestingly, we can show that allowing \nsuch forward-sb ing in the model from a store\u00ad c:RMWrlx y=1/2 b:Wrel y=1 conditional would make the \nmap\u00ad sb dob ping of C/C++11 atomics to POWER unsound: the C/C++ candidate ex-d:Rcon y=2 ecution on the \nright (in the nota\u00ad sb,dd tion recalled in \u00a74) is forbidden in hb e:Rna x=1 C/C++11,but the correspondingexe\u00adcution \nin POWER would be allowed in our model if speculative for\u00adwarding from the store-conditional of theRMW \nwere to be permit\u00adted. The architectural intent (though this is arguably not completely clear from the \ntext) is to rule out this behaviour in a different way, allowing implementation forwarding from store-conditionals \nbut requiring that any store-conditionals must respect an implicit data dependence to the prior load-reserve \nthrough the architected reser\u00advation register, even when no actual data dependence is present;  Thread: \n0 Thread: 1 Thread: 0 Thread: 1 Thread: 2 hence preventing such forwarding until the previous load-reserve \nhas been satis.ed. An implementation of such forwarding would be extremely aggressive and complex, and \nhas not been attempted in practice. Thisisa case whereourPOWERandC/C++11 modelsaretight against each \nother: one either has to rule out such forwarding be\u00adcoming observable in the Power Architecture or permit \nthe example in C/C++ (or change the mapping,but there is no obvious alterna\u00adtive that preserves the performance \nadvantage of a consume over an acquire). It illustrates how constructing formal models at this level \nof detail can identify deep architectural and micro-architectural choices beyond current implementation \npractice, arising from the detailed interplay between the high-level language memory models and aggressively \nweakly ordered hardware models. For completeness, we also include in this paper the POWER eieio barrier, \nin addition to the previously-covered sync, lwsync, and isync, though it is not used in theC/C++ mapping. \nArchitec\u00adturally, eieio orders pairs of same-thread writes asfar as all other threads are concerned(eieio \nhas additional effects for Caching Inhibited memory, which we do not cover here), and the message\u00adpassing \ntest on the left is forbidden. However, the extension on the right, with the write to x pulled out to \na third thread, is allowed, notwithstanding the architectural mention of cumulativity, because eieio \ndoes not order reads (e.g. b)w.r.t. writes. a: W[x]=1 c: R[y]=1 a: W[x]=1 eieio addr b: W[y]=1 rf d: \nR[x]=0 c: W[y]=1 rf e: R[x]=0 Test MP+eieio+addr: Forbidden Test WRC+eieio+addr: Allowed Adding eieio \nbetween b and c of the MP+poaa+addr example above suf.ces to rule out the non-SC behaviour there. We \nmodel eieio in the storage subsystem exactly like lwsync, together with a more relaxed thread commit \nrule. Preliminary testing suggests that current implementations have considerably stronger behaviour \nthan the architecture, more like lwsync. We also remark for completeness that we have made a technical \nchange to our lwsync semantics: our [SSA+11] model let reads after lwsyncs be satis.edbut restarted them, \nwhereas now they are blocked until the lwsync commits. This has no observable effect but is simpler to \nwork with. Discussion Our semantics abstracts substantially from hardware implementation detail, focussing \non the essential properties of the store-conditional. The notion of a write reaching coherence point \nabstracts from the hardware machinery needed to maintain coher\u00adence; it captures just the minimal properties \nrequired to express the semantics. From the literature and vendor documentation, one would be tempted \nto build an operational model with explicit per\u00adthread reservation .ags, set and cleared as the abstract \nmachine executes, and indeed we did so at .rst, but that quickly becomes very complex when one considers \nreservations being set or cleared on speculative execution paths that may be rolled back. The im\u00adplicit \nreservation style that we introduce here, testing just the nec\u00adessary coherence properties at write-conditional \ncommit time, is much simpler to express and to work with.  3. Validation Our model has been validated \nin six distinct ways. First, it was developed in discussion with a senior IBM POWER de\u00adsigner/architect, \nwho has extensive experience of the POWER load\u00adreserve/store-conditional implementations. Second, webuilta \ntool, withakernel generatedfromtheLemcodeofthe model, whichal\u00adlows us to explore the behaviour of litmus-test \nexample programs, interactively via a web interface (available in the supplementary material) and in \nbatch mode (calculating all model-allowed be\u00adhaviour); this tool was used in the analysis of the Linux \nbug mentioned above. Third, using that tool for regression testing, we checked that the addition of coherence \npoints did not affect the ob\u00adservable behaviour allowed by the model for as many tests that do not involve \nload-reserve/store-conditional as we could test. Adding coherence points enlarges the search space needed \nto exhaustively explore tests,butthenewversionofthe tool terminatedin manage\u00adable memory occupancy(up \nto 10 GB)for 299 out of the 314 VAR3 tests [SSA+11], and also for approximately 450 new tests; for all \nthese, the two models allow the same outcomes.Fourth,experimen\u00adtally: we developed a large set of new \nlitmus tests, as described be\u00adlow, ran them on generations of POWER machines (PowerPC G5, POWER6 and \nPOWER 7), and compared the results against those for the model (as produced by our tool). Fifth, we proved \ntheo\u00adretical results about our POWER model on its own terms, in \u00a73.2 below. Finally, our main theoretical \nresult of this paper, proving that theC/C++11 synchronisation primitives can be correctly com\u00adpiled to \nPOWER, demonstrates that the model is strong enough for non-trivial usage. 3.1 ExperimentalValidation \nFirst, we hand-wrote tests to exercise the basic functionalities of load-reserve and store-conditional \ninstructions.Forexample,a test RSV+Fail shows that a store-conditional associated to a load\u00adreserve will \nfail if there is a load-reserve to a distinct location (on actual machines, to a distinct reservation \ngranule) in between in program order. To systematically exercise corners of the model, we de\u00adsigned several \nseries of tests, automatically generated with the diy tool [AMSS10]. The .rst and more important series \n(12499 tests) derives from the systematic tests of [SSA+11]. Assuming that mapping plain accesses to \nload-reserves or read-modify-write se\u00adquences might forbid some behaviours previously allowed by the \nmodel, but not the other way round, we selected the tests allowed by the [SSA+11] model (limited to 5 \naccesses to reduce the num\u00adber of tests to run). We call these tests plain tests, since all ac\u00adcesses \nare plain reads and writes. Then we generated all the possible atomic variations of these plain tests, \nwith a load-reserve or a load\u00adreserve/store-conditional sequence in place of some plain accesses. For \na read we usefetch and no-op (FNO), and for a write fetch and store (STA) constructs [Pow09, p.719]. \nBoth FNO and STA read a value with a load-reserve, then the FNO writes back the same value with a store-conditional, \nwhile the STA writes a prede.ned different value with its store-conditional. Note that we cannot map \na write to a store-conditional alone, because the store-conditional needs a program-order previous load-reserve \nto succeed. They are wrapped in loops, though in practice in our model tool we unroll the loops once. \nThe second series, R. (intra-thread, or internal, read-from), exercises the impact of atomic variations \non store forwarding. To do so, we generated a restricted subset of our plain tests, namely some that \nexhibit a violation of SC in the form of a critical cy\u00adcle [SS88], with at least one internal (intra-thread) \nread-from edge, and up to 3 threads; this gave a series of 1338 tests. We replaced the accesses along \nthe internal read-from edges with FNO/STAs and load-reserves, as in the .rst series. Interestingly, many \nof the R. variations that involve only load-reserves were observed on POWER 6 but not on PowerPC G5 or \nPOWER 7, e.g. a test 2+2W+lwsync+r.-data. This suggests that the implementation of load-reserve is less \nliberal on the latter two. The last series exercises in practice what we establish as a theorem about \nthe model in \u00a73.2: when all accesses of a test are replacedbyFNOorSTA,thenthe testonlyhasSCbehaviours.We \ntested this on a restricted subset of our plain tests, namely the 68 that exhibit a violation of SC via \na critical cycle, and that have up to 4 threads. Running those tests on hardware showed no non-SC behaviour, \nconsistent with the model s prediction as captured by the theorem.  Taking all these load-reserve/store-conditional \ntests together is 13963 tests. We have run all those on PowerPC G5, POWER 6 and POWER 7 machines many \ntimes at least 5 \u00b7 107 each on PowerPC G5, 8.5 \u00b7 108 on POWER 6, and 2.3 \u00b7 109 on POWER 7 and our model \nexploration tool terminated in less than 16GB memory for 10455 tests. We also have relatively thorough \ntesting of eieio, with 235 tests run on POWER6 and7and in the model. For all the above, all outcomes \nobservable on the hardware are allowed by our model; in this sense the model is experimentally sound, \nmodulo only the reservation granule issue described above. Representative data is below (with the full \ndataset online). Model Power6 Power7 MP+lwsync+porr Forbid Ok, 0/2.6G Ok, 0/6.1G MP+poaa+addr Allow Ok, \n27k/1.1G Ok, 56/1.4G 2+2W+r.pr-datarps Allow Ok, 58/545k No, 0/4.4G Allow unseen  3.2 Restoring SC \nwith FNOs and STAs Despite the relaxed nature of POWER load-reserve/store\u00adconditional (as illustrated \nby the .rst two MP examples of \u00a72), if one replaces all loads and stores by FNO and STArespectively, \none regains SC behaviour: THEOREM 1. Mapping all accesses to FNOs for loads and STAs for stores restores \nSC. Proof Outline: Note .rst that the successful store-conditionals (SSC) of an FNO or STA reach their \ncoherence points as soon as they are committed. Thus there is a total order over all SSCs of a program \n(not just a per-location order), following the abstract\u00admachine order in which the writes of this program \nreach their co\u00adherence points (we call this order rcp). Of course, this order is only over successful \nwrite-conditionals, not plain writes. Two SSCs in program order are committed in that order, thus reach \ntheir co\u00adherence point in that order, so rcp respects program order. More\u00adover, if all accesses are mapped \nto FNO and STA, we know that the threads communicate only through SSCs that are read by load\u00adreserves \nand that a load-reserve before an SSC must read the (here unique) coherence-maximal value.  4. C/C++ \nLocks, RMWs, andFences Historically, the C and C++ standards did not cover concurrency, considering it \nto be a library issue. That is not a satisfactory position, as observed by Boehm [Boe05], and the recent \nISO C11 and C++11 revisions incorporates concurrency for the .rst time [Bec11, ISO11]. The design, as \noutlined by Boehm and Adve [BA08], is based on a data-race-free (DRF) [AH90] model for normal code: for \na program written using threads, mutexes and sequentially consis\u00adtent atomic1 operations, if it has no \nraces in any execution then it is supposed to have SC semantics2; while if some execution does exhibit \na race, the program s behaviour is unde.ned (and an im\u00adplementation is entirely unconstrained). This \npermits a broad range 1In C/C++11 terminology, atomic plays a very loosely similar role to Java volatile: \nin C/C++11, for de.ning whether a program has unde.ned behaviour, atomic operations (which might be single \nloads, single stores, or read-modify-writes) are not deemed to have data races with other atomic operations, \neven if they are not separated in happens-before. 2In fact this is not quite true, as Batty et al. [BMO+12] \nobserve, due to a subtlety involving atomic initialisation. of compiler optimisations[. Sev11] and allows \nimplementation on relaxed-memory multiprocessors without requiring expensive bar\u00adriers or special load \nand store instructions for every memory ac\u00adcess. However, implementing SC atomic operations can still \nbe ex\u00adpensive, and therefore the language also includes a variety of low\u00adlevel atomics for high-performance \nconcurrent algorithms: atomic reads, writes, and read-modify-write operations with weaker prop\u00aderties \nthat are cheaper to implement. They are annotated with a memory order: either relaxed, providing no synchronisation; \nre\u00adlease (for writes and RMWs), acquire (for reads andRMWs), or re\u00adlease acquire (forRMWs), providing \nsynchronisation for message\u00adpassing idioms; or consume, a weaker variant of read-acquire that lets programmers \ntake advantageof thefact thatPOWER andARM respect data and address dependencies at little or no cost. \nSC atom\u00adics also have release/acquire semantics. The language also includes release/acquire and SC fences. \nThe standard is written in prose, subject to the usual problems of ambiguity,butwehave produceda formal \nsemanticsforthe con\u00adcurrencymodel [BOS+ 11]. In discussion with members of the ISO WG21 concurrencysubgroup, \nwe identi.edvarious issues with ear\u00adlier drafts of the standard, proposing solutions that are now incor\u00adporated \ninto the standard; there is a close correspondence between the formal semantics and the C++11 text. The \nC standard has fol\u00adlowed suit: at the time of writing, the C++11 concurrency model has been partially \nincorporated into C11, but some of the C++11 .xes are not yet incorporated.We highlighted these (together \nwith a simpli.cationtothemodel)ata recentWG14 meeting, whichhas registered them as defect reports for \na future Technical Corrigen\u00addum. In this section we explain enough of the C/C++11 memory model to support \nour discussion and proof of how it can be imple\u00admented above POWER in \u00a75.We recall the mathematical structure \nof the Batty et al. semantics and explain the lock, read-modify\u00adwrite, and fence synchronisation primitives \ninformally. The basic semantics for these is not a contribution of this paper (a version was given in \n[BOS+11]) but the explanation here is new, and we have had to make three signi.cant improvements to the \nsemantics: We place the responsibility for correctly using mutexes on the programmer, in accordance \nwith intuition and with the standard. Previous work, including [BA08, BOS+11], placed it instead on the \ncompiler, imposing unrealistic requirements, e.g. that the implementation of unlock has to check that \nthe mutex is currently held by the unlocking thread.  We carefully specify how lock and read-modify-write \nopera\u00adtions can block owing to store-conditional operations that can fail continually on the Power Architecture. \n We add two missing cases to the fence semantics.  We discuss these in more detail below, and the mathematically \nrig\u00adorous version of the improved model is available in the supplemen\u00adtary material. The C/C++11 memory \nmodel is axiomatic (quite different in style to our POWER abstract machine): presuming a threadwise operational \nsemantics that de.nes candidate executions consisting of the sets of memory read and write actions for \nthreads in isolation, it de.nes when such a candidate is consistent and whether it has a race of some \nkind. Consistency is de.ned in terms of several relations, including a happens-before (hb) relation that \nembodies the language s notion of causality. The three basic relations, sequenced-before (sb), reads-from \n(rf), and modi.cation order (mo), are closely related to our POWER abstract machine s notion of program \norder, reads-from, and coher\u00adence order, respectively. Sequenced-before is a threadwise partial order \nthat does not need to be total (for example, the operands x and y of x == y are not related by sequenced-before). \nModi.ca\u00adtion order is a per-location total order over the write operations to that location. A modi.cation \norder is only needed for atomic lo\u00adcations; it can contain atomic writes with various memory orders, \ntogether with non-atomic initialisation writes.  The synchronises-with (sw) and happens-before relations \nare calculated from sequenced-before and reads-from.A write-release synchronises with a read-acquire \nthat reads-from the write. Read\u00adacquires can also synchronise with some (but not necessarily all) write-releases \nthat appear in modi.cation order before the read\u00adfrom write; this is formalised by release sequences, \nwhich we do not detail here. Happens-beforeis thenbuilt as the transitive closure of synchronises-with \nand sequenced-before, with some exceptions relating to read-consumes which we do not detail here.Four \ncoher\u00adence axioms require that happens-before is consistent with mod\u00adi.cation order. Synchronises-with \nand happens-before have no di\u00adrect counterparts in POWER: the compilation of C/C++ to POWER must insert \nenough barriers to ensure that synchronizing write/read pairs enjoythe right ordering properties (see \n\u00a75). The sequential consistency (sc) relation is a total order on all of the SC reads and writes. It \nis required to be consistent with sequenced-before, modi.cation-order, and happens-before. A program \nhas a data race if there is some consistent execution with two happens-before unrelated reads/writes \non the same loca\u00adtion, where at least one is a write, and at least one is not atomic. 4.1 Locks To model \nmutexes, we use three kinds of additional actions: locks, unlocks, and blocks. In a consistent execution, \na total order lock order (lo) (analogous to modi.cation order) over these ensures that no mutex is acquired \nwhen already held: between any pair of locks of the same mutex, there must be an unlock of that mutex. \nFurthermore, lock order must be consistent with happens-before. Lastly, the lock order introduces synchro- \na:L m nisation from each unlock to later locks of the same mutex, ensuring that the lo sb actions in \neach critical section happen\u00ad b:Wna x=1 before the actions in subsequent ones. In sb the example execution \nhere, actions a and c:U m d:L m d lock mutex m, c and f unlock it, and the sb non-atomic writes b and \nread e are inside e:Rna x=1 critical sections. The synchronisation be-lo sb tween c and d ensures that \ne reads from f:U m b, and that e and b do not race. These C/C++ candidate execution diagrams are analogous \nto the POWER execution diagrams of \u00a72. They pick out one candidate execution of a program (the programs \nare in the supplementary material), and show the memory write and read actions and the lock and unlock \nactions of that candidate execution. Each action is annotated by the location and value, and, for memory \nreads and writes, the memory order parameter. The actions are arranged in vertical columns by thread. \nAmong these actions, we depict the keyC/C++ relations: sb edges show sequenced-before, in this control-.ow \nunfolding (recall that sequenced-before is not necessarily total over the events of a thread);  rf edges \nfrom write actions to read actions show that the read reads-from that write (as before, reads from an \ninitial state are marked with a red dot for the source);  mo edges show modi.cation order, relating \nall write actions at an atomic location;  sc edges show the SC order, a total order over all SC actions; \nand  lo edges show the lock order, a total order over all lock and unlock actions.  From these, two \nderived relations can be calculated: sw edges depict the C/C++ synchronizes-with relation; and  hb \nedges depict the C/C++ happens-before relation.  In previouswork[BA08,BOS+11], a consistent execution \nalso required that lock/unlock actions strictly alternate in lock order, and that the unlock of a mutex \nmust follow the lock that acquired it in sequenced-before. Putting this requirement on consistent execu\u00adtions \nrequires that the compiler or lock implementation enforce it, for example, by having each unlock call \ndynamically check that the mutexis heldbythe unlocking thread.To supportef.cient un\u00adlock implementations \nthat have no such check, the C/C++11 stan\u00addard places this requirement on the programmer, and so we allow \nconsistent executions with improper calls to unlock, but give such programs unde.ned behavior. Not all \nattempts to acquire a mutex eventually succeed: the pro\u00adgram could be deadlocked, or a particular acquisition \ncould be starved forever. To model this, on an attempted acquisition the threadwise operational semantics \nnon-deterministically generates either a lock action, representing success, or a block action, repre\u00adsenting \ndeadlock or starvation. In the latter case, we require that the operational semantics not produce any \nfurther actions sequenced after the block. The concept of blocked mutex acquisition does not explicitly \nappear in the standard, or in prior work; we add it to prop\u00aderly separate the axiomatic memory model \nfrom the threadwise op\u00aderational semantics. Because block actions appear in lock order, the memory model \ncan place constraints on them to specify the exact fairness or liveness guarantees enjoyed by mutex acquisition. \nThe operational semantics only needs to know whether a certain call is blocked or not. This contrasts \nwith the typical operational treatment of mutexes in which locking and unlocking operations manipulate \na piece of shared state; state which, in a relaxed memory setting, must be governed by the memory model. \nAs we discuss in \u00a72, the Power Architecture allows store\u00adconditionals to fail arbitrarily, and there \nis no simple guaran\u00adtee ruling out repeated failure (though implementations do go to great lengths to \nprovide forward progress). In \u00a75, we consider an implementation of C/C++11 mutexes based on POWER load\u00adreserve/store-conditional \ninstructions, and in this context a mutex acquisition can block inde.nitely, even in the absence of deadlock \nor contention, due to continual, spurious store-conditionalfailures. To modelthis possibilityinC/C++11,weallow \nblock actionstoap\u00adpear anywhere in the lock order, without constraint. However, if one were modelling \na particular POWER implementation that guaran\u00adteed store-conditional liveness, one could use a stronger \nC/C++11 model: in lock order, each block is either preceded by a lock which is never unlocked (the deadlock \ncase), or followed by an in.nite number of locks (the starvation case). To simplify our reasoning about \nthe connection between POWER and C/C++11 mutexes in \u00a75, we also use an alternative model that, .rst, \nuses a separate lock order for each mutex, and, second, requires that each unlock synchronise only with \nthe next lock in that order.We have proved the equivalence of the two mod\u00adels (see the supplementary \nmaterial); the equivalence relies on hav\u00ading unde.ned behaviour for programs that misuse locks.  4.2 \nRMWs C/C++11 has three kinds of atomic RMWs: fetch add and simi\u00adlar, compare exchange strong, and compare \nexchange weak. The .rst updates the value at a given address, the second is a tradi\u00adtional CAS, and the \nthird is a traditional CAS except that it can fail spuriously. The .rst two are implemented on POWER \nwith load-reserve/store-conditional pairs with loops to account for the store-conditional failing. Thus, \nlike mutex acquisition, the opera\u00adtional semantics must allow them to block. The last is implemented \nwith a simple load-reserve/store-conditional pair (which exposes the possibility of non-deterministic \nspuriousfailures).  Successful RMWs are modelled by a:Wrlx x=1 an RMW action that both reads and sb,mo \nwrites; atomicity is guaranteed by re\u00ad  rf,mo d:RMWrlx x=2/3 b:Wrlx x=2 quiring that the read reads-from \nthe im\u00ad mediate predecessor of the write in mod-sb i.cation order. Thus, in the example to c:Wrlx x=4 \nthe right, RMW-relaxed d must read from write-relaxed b, and not write-relaxed a.  4.3 Fences In C/C++11, \nfences are used to replace multiple acquire/release or SC operations with more ef.cient relaxed ones. \nThere are four kinds: acquire, release, acquire/release, and SC fences. Acquire and release fences establish \nsynchronises-with relation\u00adships, even when the reading and writing actions are relaxed. In the message-passing \nexample on the left below, the acquire fence g synchronises with write-release d even though the read \nf is relaxed; this synchronisation ensures that non-atomic write c happens be\u00adfore non-atomic read h. \nThis might help performance: for example, if f were in a loop waiting to observe d s write; we only have \nto pay for the acquire once, rather than on each iteration. In the variation on the right, a single release \nfence j ensures synchronisation based on multiple relaxed writes k and l. i:Wna a=1 c:Wna x=1 sb sb j:Frel \nd:Wrel y=1 f:Rrlx y=1 sb  sb f:Racq x=1 k:Wrlx  sw g:Facq sb sb sb g:Rna a=1 l:Wrlx y=1 p:Racq y=1 \nsb h:Rna x=1 q:Rna a=1 SC fences appear in the sc relation, and enforce a set of coherence-like axioms \nbetween it and modi.cation order. In the store-buffering (or Dekker s) example on the right, SC atomic \nreads and writes are used to ensure that at least one of the reads d c:Wsc y=1 or g reads-from one of \nthe writes c or f. sb,sc We can get the same guarantee by mak\u00ad d:Rsc x=1 ing one thread s operations \nrelaxed and putting an SC fence in between, or even sb,sc making all four operations relaxed and g:Rsc \ny=1 using two SC fences, as below. c:Wrlx y=1 c:Wrlx x=1 f:W rlx y=1 sb sb sb g:Fsc d:Fsc g:Wsc x=1 d:Fsc \n sb,sc sb sb sb e:Rrlx x=0 h:Rsc y=1 e:Rrlx y=0 h:Rrlx x=1 Despite their name,C/C++11 SC fences are \nnot designed to restore sequential consistency to programs that use low-level atomics (in part because \nin the Itanium architecture there is no implementation fence that would do so [Int02]). For example, \nthe IRIW litmus test from [BA08] with two SC fences is allowed in C/C++ (in the model, the 6 SC fence \nconditions do not impose any constraint on the sc order between two SC fences because of a non-SC-atomic \nread before one fence and a read after another). The proof of our main result in \u00a75, together with the \npreliminary results of [BMO+12], are arguably the .rst extensive validation of theC/C++11 model.To the \nbest of our knowledge, large-scale soft\u00adware development of concurrent C/C++11 code has not yet begun, \nas that practical validation requires production compilers which are only just becoming available. Even \nwhen they are, and are correct, theymayprovideover-strong models,soat presentproofistheonly way to determine \nwhether code is correct with respect to the speci\u00ad.cation rather than with respect to some particular \nimplementation.  5. Compiling Synchronisation Primitives: from C/C++ to POWER We now discuss our second \nmain contribution, the correctness proof of one mapping of the principal C/C++ synchronisation con\u00adstructs \nlocks, read-modify-writes, and fences to POWER, us\u00ading load-reserve/store-conditional and the POWER barriers. \nThe proof can be easily adapted to show related mappings, with dif\u00adferent barrier placement on C/C++ \nSC operations, or SC atomics implemented with load-reserve/store-conditional, correct as well. This subsumes \nthe result of Batty et al. [BMO+12], which just cov\u00adered C/C++ loads and stores (with their various possible \nmemory orders). The mapping we consider combines the scheme proposed by McKenney and Silvera [MS11] for \nC/C++11 atomics, fences and RMWs with the spinlock implementation given in the Power Archi\u00adtecture [Pow09, \np.717,718]. We .rst give the mapping with some informal intuition about its soundness (focussing on locks) \nbefore describing the main ideas of our proof. 5.1 Compiling from C/C++ to POWER Locks Assuming that \nregister r3 contains a lock location, r4 contains the value signifying that a lock is free and r5 the \nvalue signifying that a lock is taken, the POWER implementation of a spinlock is: loop: lwarx r6,0,r3,1 \n# load-reserve lock [r3] into r6 cmpw r4,r6 # go to wait if lock not free, bne-wait # eventually returning \nto loop stwcx. r5,0,r3 # store-cond to try to set lock bne-loop # loop if lost reservation isync # \nimport barrier The implementation of unlock is: lwsync # export barrier stw r4,0(r3) # normal store \nto release lock In the lock implementation, a load-reserve/store-conditional pair works on the lock \nlocation. The load is followed by a check on the value stored at the lock location; if the lock is not \nfree, the code branches to a waiting routine (which might be a loop doing a normal read on the lock location, \nor a backoff, and which will return to loop to try to establish a new reservation). Otherwise the code \ntries to set the lock with a store-conditional. As discussed in \u00a72, this will fail if the new value cannot \nbe made an immediate coherence successor of the write read by the load-reserve (e.g. if some other thread \nhas taken the lock in the meantime), and in that case it again returns to loop, otherwise the lock has \nbeen taken successfully and atomically. The implementation of unlock has a simple store at the lock location \nwriting the value that signi.es that the lock is free. As a result, a C/C++ unlock/lock synchronisation \nis, at the POWERISAlevel,a store-to-load communication.Forthistotruly be a synchronisation, the implementation \nalso must include addi\u00adtional protection. The unlock store is preceded by an lwsync in\u00adstruction. The \neffect of this barrier is .rst to restrict the reordering of instructions in its own thread: an lwsync \nmust be committed after anyprogram-order-preceding memory-access instruction, and before any memory-access \ninstruction following in program order is satis.ed (for reads) or committed. The second effect is an \nor\u00addering of the propagation of stores. For any lwsync barrier, our POWER model keeps track of the set \nof stores and barriers that have been done by or propagated to its thread before it was com\u00admitted. Before \nthe lwsync can be propagated to another thread tid , all the members of this set, called its Group A, \nmust .rst be prop\u00adagated to tid. In the context of the unlock/lock synchronisation, this guarantees that \nany store visible to the unlocking thread before its unlocking store (to the lock location) must also \nbe visible to the locking thread, before the load-reserve (of the successful store\u00adconditional/load-reserve \npair) on the lock location.  The propagation ordering enforced by an lwsync is transi\u00adtive, in the following \nsense. Consider a chain of unlock/lock syn\u00adchronisations, with each unlock directly following a lock \non the same thread, and each lock directly following an unlock on a different thread. This corresponds \nto a chain of thread-crossing store/load communications. In this communication, the stores come from \nthe unlocking stores to the lock location, and the success\u00adful store-conditionals of lock acquires, while \nthe loads correspond to the load-reserves at the lock location from the successful store\u00adconditional/load-reserve \npair of locks. For the communication to occur, each store must propagate to the thread of its associated \nload. If the .rst store of the chain is preceded by an lwsync, then this barrier along with its GroupAmust \npropagate to the second thread of the chain before the store it precedes. Since a load-reserve/store\u00adconditional \npair must be committed in order, the lwsync and its GroupAstores are therefore propagated to the second \nthread before the store-conditional of that second thread is committed. Hence for this second thread \ns store-conditional to propagate to the third thread of the chain, the .rst thread s barrier along with \nits GroupA must .rst propagate to that third thread. The argument continues to the rest of the chain. \nAdditionally, the last branch instruction of the lock implemen\u00adtation is followed by an isync instruction. \nAs a result of this com\u00adbination of a dependency from the result of the store-conditional to a conditional \nbranch, followed by an isync (together, a kind of ctrlisync dependency) any program-order-following loads \ncannot be speculated before the store-conditional succeeds. Hence, any program-order-following loads \nmust see the stores that were per\u00adformed by the unlocking thread, before the unlock was executed. A fully \nlocked POWER program is SC The intuition above for locks is applicable in a wider context than C/C++. \nFor a simple result along those lines, consider a POWER assembly program (not Thread: 0 Thread: 1 necessarily \ncompiled from C/C++), a: R[lx]*=0 i: R[ly]*=0 which has all competing accesses po (those accessing the \nsame location, po b: W[lx]*=1 j: W[ly]*=1 from distinct threads, at least one of them being a write) \nprotected by locks, using a distinct lock vari\u00ad k: W[y]=1 able per shared-memory variable (denoted below \nby lx, ly, etc., for l: W[ly]=0 locks protecting variables x, y, etc.). We assume all locations are disjoint \nand of the same size, and ignore the m: R[lx]*=0 case of overlapping accesses. Using the isync at the \nend of f: W[ly]*=1 n: W[lx]*=1 the lock sequence and the lwsync at the beginning of the unlock se-ssc+ctrlisync \nssc+ctrlisync quence, we get that two accesses rf g: R[y]=0 rf o: R[x]=0 in program order guarded by \nlocks lwsync lwsync follow the order in which the SSC h: W[ly]=0 p: W[lx]=0 of their lock primitives \nreach coher- Test SB+locks: Forbidden ence point. For example in the test SB+locks on the right, the \nwrite c to x on Thread 0 is committed after the SSC b to lx reaches coherence point, as depicted by the \nmagenta ssc+ctrlisync arrow. The lock write to ly on Thread0reaches coherence point before the lock write \nto ly on Thread 1, as depicted by the blue arrow rcp from Thread0 to Thread1,thus restoringSCforthis \ntest. Fleshing out this line of reasoning proves our next theorem: THEOREM 2. Protecting access to each \naddress with an associ\u00adated lock restores SC, assuming the program does not use distinct overlapping \nlocations. RMWs The implementation ofC/C++ RMWs also relies on load\u00adreserve/store-conditional pairs. \nHere, without loss of generality, we only discuss the implementation of one kind of RMW, the fetch add \noperation with an implementation as in the .rst \u00a72 example: a load-reserve/store-conditional pair surrounding \nan ad\u00addition instruction, the whole wrapped in a loop waiting for the store-conditional to succeed. The \nimplementations of other kinds ofRMWs use different instructions between the load-reserve/store\u00adconditional \npair but have essentially the same correctness argu\u00adment. RMWs are parameterised by a memory order, and \nthe mapping places POWER barriers at the beginning and dependencies at the end of the load-reserve/store-conditional \nblock, in the same style as the implementations of non-RMWC/C++ atomic accesses. The implementation of \na relaxed RMW has no additional barriers; the implementation of a release RMW is preceded by an lwsync \nbar\u00adrier; that of an acquire RMW is followed by a ctrlisync dependency; acquire/release combines both; \nand that of an SC RMW is preceded by a sync and followed by a ctrlisync dependency. Fences C/C++ fences \nare compiled to single barrier instructions: SC fences are mapped to a sync and all the others to lwsync. \nnon-RMW atomics For non-RMW atomic memory accesses the compilation maps each C/C++ read or write to corresponding \nPOWER instruction together with protecting barrier instructions, as for the RMWs above but with the addition \nof consume loads, which have no barrier but require the compiler to preserve depen\u00addencies [MS11, BMO+12]. \n 5.2 Correctness proof Our second main result is the correctness of this compilation scheme. To focus \non the concurrency issues, we abstract from the details of thread-local compilation: we consider an arbitrary \nnon\u00adoptimising compiler (preserving memory accesses, program order and thread-local dependencies) that \nuses this compilation scheme for the concurrencyprimitives. Informally, our result is as follows; the \nformal statement and proof are in the supplementary material. THEOREM 3. Consider a non-optimising compiler \nthat uses the mapping above. For any race-free C/C++ program, compile it to POWER and take any execution \ntrace of our POWER abstract ma\u00adchine. Then thereexistsaC/C++execution thatis both equivalent tothePOWERtraceand \nacceptedbytheC/C++ memory modelas a consistent execution of the original C/C++ program. This is in the \nsame style as the result ofBatty et al. [BMO+12] for the compilation mapping in the absence of locks, \nfences and RMWs. We now outline the overall proof structure, common to both works, and then show how \nto extend it to handle the synchro\u00adnisation primitives. The proof describes a procedure for constructing \na C/C++ ex\u00adecution from any POWER trace that guarantees their equivalence, and then shows the consistency \nof that C/C++ execution. But this construction does not work for racy programs. As a straightfor\u00adward \nexample, consider a C/C++ program with two threads, the .rst doing a non-atomic write at a location x, \nthe second doing a non-atomic read on x. The C/C++ memory model rules out any consistent execution with \nthe read reading from the write, because they are unrelated in C/C++ happens-before, and thus the execu\u00adtion \nwould be racy. But in the compiled POWER code, which has no direct analogue of the C/C++ happens-before, \nnothing prevents the corresponding store propagating to the second thread to be read by the load. For \nthe veri.cation of the consistency of the recon\u00adstructed C/C++ execution to succeed, the following consequence \nof race-freedom is required: in the C/C++ execution, a read can\u00adnot read-from a write that it is not \nrelated to by happens-before . The proof splits on whether this condition holds. If it does hold, consistency \nof the reconstructed execution can be directly shown, while if it does not hold, it can be shown that \nthe original C/C++ program must have been racy, thus leading to a contradiction.  The latter proof is \ntechnically involved because one needs to build a racy, consistent C/C++ execution that does not exactly \ncorrespond to the POWER trace. There are two areas where this part of Batty et al. s proof could fail \nwhen adding synchronisation constructs: in the top-level case split, and in the way that POWER\u00adlevel \nspeculation complicates the construction of the racy C/C++ execution.Infact, our alternateC/C++ formalisationof \nlocks(\u00a74.1) removes the need for modifying the case split: the new proof has a similar case split (on \nwhether unlocks are used properly), but it is simpler because the proof is about the C/C++ model only, \nnot in combination with POWER. Furthermore, careful modelling of the absence of store-conditional forwarding \n(\u00a72) means that the construction in the existing proof works unchanged. Returning to showing consistencyof \na reconstructed execution, several properties regarding the interaction of the happens-before relation \nwith other relations de.ned by the C/C++ memory model havetobeveri.edofthe constructedC/C++execution.To \ndirectly exploit our POWER model, the statements of all these properties are translated into equivalent \nstatements regarding the POWER trace from which the C/C++ execution was built: we de.ne rela\u00adtions on \nthe elements of POWER traces and show a correspondence between these and the C/C++ relations. For most \nrelations, clear counterparts exist. For example, the C/C++ sequenced-before cor\u00adresponds roughly to \nthe POWER program order (though some care needs to be taken, as sequenced-before is a partial order while \nthe program order is total). However, there is nothing that corresponds directly to the happens-before \nrelation. Instead, a more complex POWER relation isbuilt from the other POWER relations. Using this characterisation, \na propagation lemma states that for any pair of C/C++ actions a and b related by happens-before, the \ninstruction corresponding to b sees any stores that the instruction corresponding to a is able to see: \nanystore propagated to the thread of a before a is executed, is also propagated to the thread of b before \nb is executed (a read is executed at the latest abstract-machine transition in which it is satis.ed \nall previous reads having been restarted while a write is executed when it is committed). Using this \nlemma in conjunction with the preconditions and actions of the POWER model transitions, the conditions \nrequired by the C/C++ memory model can be veri.ed. For example, when the POWER storage subsystem accepts \na write request, one of its actions is to update the coherence order so that the store being accepted \nis coherence-after any store already propagated to its thread, which is needed when verifying one of \nthe coherence properties required by C/C++. Finally, a total order for SC actions must be built from \nthe POWER trace,but as for happens-before there is no direct analogue of this relation in POWER. Instead, \nwe show that the POWER sync barrier associated with SC actions by the mapping ensures that we never get \ncyclic dependencies if we take into account all the required properties of this order (e.g., a read may \nnot read from a write after in SC order). Including the synchronisation primitives The addition of the \nsynchronisation primitives affects the de.nition of the happens\u00adbefore relation. In particular, RMWs \nmake the de.nition of release\u00adsequences more complicated, and locks and fences introduce new waysfora \nsynchronises-withedgeto appear.Thisinturnaffectsthe de.nition of the POWER analogue to happens-before. \nHere is the new characterisation of the transitive part of happens-before with synchronisation primitives, \nusing relations derived from a POWER trace: )re. (synct .lwsynct ; coit re. ; rfet ; (rmwt ; rft ) * \n; .+ (ctrlisynct .ddt re. .lwsynct )re. re. + where semicolon denotes relational composition, and \u00b7 and \n\u00b7 are respectively the re.exive and transitive closures. The full poten\u00adtially non-transitive happens-before \nrelation is obtained by taking the union with program order, but that does not present any dif.\u00adculty \nfor the proof. The synct and lwsynct relations relate com\u00admit transitions of memory accesses corresponding \nto memory in\u00adstructions from a single thread which are separated in program\u00adorder by, respectively, a \nsync or lwsync. This part of the char\u00adacterisation corresponds to the barriers introduced by the compila\u00adtion \nmapping before unlocks, and release atomic-stores, fences, and RMWs. The coit relation relates commit \ntransitions of stores from the same thread which are related in the coherence order. In the ab\u00adsence \nof RMWs, this relation is the POWER analogue of the C/C++ release-sequence relation, and the rfet relation \n(relating the com\u00admit transition of a store to the commit transition of a load reading from that store \nfrom a different thread) was the next component. With RMWs, we need something more elaborate: the rmwt \nrela\u00adtion identi.es the presenceofa load-reserve/store-conditional pair. The rft relation extends rfet \nby also allowing the store and load to be on the same thread. The composition (rmwt ; rft )+ corresponds \nto a chain of RMWs ending a C/C++ release sequence. Note that theymay be RMWs anywhere in a release-sequence, \nnot only at the end,but in that case theRMW chain must come back to the thread of the release head, and \nthen the lastRMW is related to the release head by the coit relation. The last component of the characterisa\u00adtion \nis the union of ctrlisynct (the ctrlisync analogue of the synct and lwsynct relations, ddt (data dependency, \nfor C/C++ consume atomics, included in our proofbut not discussed here) and lwsynct . This corresponds \nto the barriers or dependencies placed after ac\u00adquire and consume reads or to acquire fences. The lwsynct \nhere is added, corresponding to acquire fences. Despite the expanded de.nition of the analogue of happens\u00adbefore, \nthe key abstraction of the propagation lemma still holds. Thustheproofof consistencyofthe reconstructedC/C++execution \nextends smoothly to the addition of C/C++ locks, RMWs, and fences. There is one new condition to check \nfor the consistency of a C/C++ execution: an RMW action must read from its last predecessor in the modi.cation-order. \nIn terms of the POWER implementation, this means that the load-reserve must read from the last coherence \npredecessor of the store-conditional but that is just what we are guaranteed from the rules given in \n\u00a72, fora successful store-conditional. Finally, SC fences must be a part of the sc relation, and this \ninteracts with modi.cation order to impose6additional coherence\u00adlike conditions. As before, there is \nno obvious order in the POWER machine trace with the right properties. Instead, we build the sc relation \nfrom a POWER machine trace by directly checking that these6conditionsarenot violated.Totakeoneexample,havingthe \nsc relation between the SC fences go one way in the store-buffering example of \u00a74 imposes a condition \nthat at least one read-from edge cannot be from a write that is too old in modi.cation order. Recalling \nthat SC fences are mapped to the POWER sync barrier, we use a property of this barrier (that it must \nwait for all group A writes, or coherence successors thereof, to be propagated to all threads) to guarantee \nthis condition. Indeed, the corresponding example in POWER is SB+syncs, which only has SC behaviour. \n Discussion: C/C++ and POWER Our proof establishes a close correspondence between C/C++ executions and \nPOWER abstract machine executions of the compiled program. Nevertheless, there are programs with different \nbehaviours on the two models. As noted previously, IRIW with two SC fences is allowed in C/C++, whereas \nits compilation with syncs is forbidden, and sometimes the mapping imposes stronger barriers than strictly \nnecessary. For example, consider the 2+2W test of [SSA+11]. Here the only way to regain SC behaviour \nin C/C++ is to either use SC fences or all SC accesses everywhere. The test maps to 2+2W+syncs, which \nis indeed forbidden in POWER,but infact here lwsyncs would have been enough.  6. Conclusion With this \nwork, together with [SSA+11, BOS+11, BMO+12], we .nally have a semantics for real-world concurrent programming \nin C/C++ and on POWER multiprocessors that is complete enough to support reasoning about real OS and \nVM kernel code, at least in the absence of mixed-size accesses, and that is suf.ciently well validated \nthat one can have con.dence in the results. This opens the door to future work on veri.cation techniques \nand analysis tools for such code. For example, looking informally at Michael s lock-free datastructure \nalgorithms using hazard point\u00aders [Mic04] (one of which was veri.ed in an SC setting using sep\u00adaration \nlogic [PBO07]), one can consider veri.cation of ef.cient implementations of those abstract concurrent \nalgorithms, either at the POWER ISA level, where one needs the various POWER barri\u00aders and load-reserve/store-conditional, \nor, making use of our main resulthere,attheC/C++level, whereone needstoadda particular placement of C/C++ \nfences and RMWs (interestingly, the two ap\u00adpear to coincide here: theC/C++ concurrencymodel is suf.ciently \nexpressive that one can express exactly the low-level synchronisa\u00adtion needed, as one would hope. Understanding \nhow to do such veri.cations, especially compositionally, is a major open problem, as is the question \nof how to determine the best such placement. As we have seen, our work is also identifying subtle architectural \nchoices. We believe that the ARM architecture is broadly similar to POWER in these respects (though it \nis not identical to the model we present here), and hence that it will be possible to adapt the proof \nto ARM. We are currently engaged in further testing and in discussion with ARM staff to establish con.dence \nthere. Acknowledgements We acknowledge funding from EPSRC grants EP/F036345, EP/H005633, EP/H027351, \nand EP/G026254/1, and from ANR project WMC (ANR-11-JS02-011), and thank the anonymous reviewers for their \ncomments. Legal IBM, the IBM logo, and ibm.com are trademarks or regis\u00adtered trademarks of International \nBusiness Machines Corp., reg\u00adistered in many jurisdictions worldwide. Other product and ser\u00advice names \nmight be trademarks of IBM or other companies. A current list of IBM trademarks is available on the Web \nat Copyright and trademark information at www.ibm.com/legal/ copytrade.shtml. POWER, POWER6, POWER7, \nPowerPC, and Power Architecture are registered trademarks of International Business Machines Corporation. \n References [AH90] S.V.AdveandM.D. Hill.Weak ordering anew de.nition. In Proc. ISCA, 1990. [AM11] J. \nAlglave and L. Maranget. Stability in weak memory mod\u00adels. In Proc. CAV, 2011. [AMSS10] J. Alglave, L. \nMaranget, S. Sarkar, and P. Sewell. Fences in weak memory models. In Proc. CAV, 2010. [BA08] H.-J. Boehm \nand S.V. Adve. Foundations of the C++ concur\u00adrencymemory model. In Proc. PLDI, 2008. [Bec11] P. Becker, \neditor. Programming Languages C++. 2011. ISO/IEC 14882:2011. A non-.nal but recent version is available \nat http://www.open-std.org/jtc1/sc22/ wg21/docs/papers/2011/n3242.pdf. [BMO+ 12] M. Batty, K. Memarian, \nS. Owens, S. Sarkar, and P. Sewell. Clarifying and compiling C/C++ concurrency: from C++11 to POWER. \nIn Proc. POPL, 2012. http://www.cl.cam.ac. uk/~pes20/cppppc/. [Boe05] H.-J. Boehm. Threads cannot be \nimplemented as a library. In Proc. PLDI, 2005. [BOS+ 11] M. Batty, S. Owens, S. Sarkar,P. Sewell, andT.Weber. \nMath\u00adematizing C++ concurrency. In Proc. POPL, 2011. [cpp] Supplementary material. http://www.cl.cam.ac.uk/ \nusers/pes20/cppppc-supplemental. [CSB93]F. Corella,J.M. Stone, andC.M. Barton.Aformalspeci.ca\u00adtion of \nthe PowerPC shared memory architecture. Technical Report RC18638, IBM, 1993. [Her93] M. Herlihy. A methodology \nfor implementing highly concur\u00adrent data objects. TOPLAS, 15(5):745 770, Nov 1993. [Int02] Intel.A formal \nspeci.cationof Intel Itanium processorfam\u00adily memory ordering. http://www.intel.com/design/ itanium/downloads/251429.htm, \nOctober 2002. [ISO11] Programming Languages C. 2011. ISO/IEC 9899:2011. A non-.nal but recent version \nisavailable at http://www. open-std.org/jtc1/sc22/wg14/docs/n1539.pdf. [JHB87] E. H. Jensen, G. W. Hagensen, \nand J. M. Broughton. A new approach to exclusive data access in shared memory multiprocessors. (Technical \nReport UCRL-97663), Nov 1987. [Lam79] L. Lamport. How to make a multiprocessor computer that cor\u00adrectly \nexecutes multiprocess programs. IEEETrans. Comput., C-28(9):690 691, 1979. [McK11] P. E. McKenney. [patch \nrfc tip/core/rcu 0/28] preview of rcu changes for 3.3, November 2011. https://lkml.org/ lkml/2011/11/2/363. \n[Mic04] M. M. Michael. Hazard pointers: Safe memory reclamation for lock-free objects. IEEE Trans. Parallel \nDistrib. Syst., 15:491 504,June 2004. [MS11] P. E. McKenney and R. Silvera. Example POWER implementation \nfor C/C++ memory model. http: //www.rdrop.com/users/paulmck/scalability/ paper/N2745r.2011.03.04a.html, \n2011. [OBZNS11] S. Owens,P.B\u00a8Lem:ohm, F. Zappa Nardelli, and P. Sewell. A lightweight tool for heavyweight \nsemantics. In Proc. ITP, LNCS 6898, 2011. Rough Diamond section. [PBO07] M. Parkinson, R. Bornat, and \nP. O Hearn. Modular veri.ca\u00adtion of a non-blocking stack. In Proc. POPL, 2007. [Pow09] Power ISAVersion \n2.06. IBM, 2009. [. Sev11] J. Sev..c\u00b4ik . Safe optimisations for shared-memory concurrent programs. In \nProc. PLDI, 2011. [SS88] D. Shasha and M. Snir. Ef.cient and correct execution of parallel programs that \nshare memory. TOPLAS, 10:282 312, 1988. [SSA+ 11] S. Sarkar,P.Sewell,J. Alglave,L. Maranget, andD.Williams. \nUnderstanding POWER multiprocessors. In PLDI, 2011.  \n\t\t\t", "proc_id": "2254064", "abstract": "<p>Shared memory concurrency relies on synchronisation primitives: compare-and-swap, load-reserve/store-conditional (aka LL/SC), language-level mutexes, and so on. In a sequentially consistent setting, or even in the TSO setting of x86 and Sparc, these have well-understood semantics. But in the very relaxed settings of IBM&#174;, POWER&#174;, ARM, or C/C++, it remains surprisingly unclear exactly what the programmer can depend on.</p> <p>This paper studies relaxed-memory synchronisation. On the hardware side, we give a clear semantic characterisation of the load-reserve/store-conditional primitives as provided by POWER multiprocessors, for the first time since they were introduced 20 years ago; we cover their interaction with relaxed loads, stores, barriers, and dependencies. Our model, while not officially sanctioned by the vendor, is validated by extensive testing, comparing actual implementation behaviour against an oracle generated from the model, and by detailed discussion with IBM staff. We believe the ARM semantics to be similar.</p> <p>On the software side, we prove sound a proposed compilation scheme of the C/C++ synchronisation constructs to POWER, including C/C++ spinlock mutexes, fences, and read-modify-write operations, together with the simpler atomic operations for which soundness is already known from our previous work; this is a first step in verifying concurrent algorithms that use load-reserve/store-conditional with respect to a realistic semantics. We also build confidence in the C/C++ model in its own terms, fixing some omissions and contributing to the C standards committee adoption of the C++11 concurrency model.</p>", "authors": [{"name": "Susmit Sarkar", "author_profile_id": "81392603911", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P3471232", "email_address": "Susmit.Sarkar@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Kayvan Memarian", "author_profile_id": "81496689961", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P3471233", "email_address": "Kayvan.Memarian@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Scott Owens", "author_profile_id": "81337492133", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P3471234", "email_address": "Scott.Owens@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Mark Batty", "author_profile_id": "81479651209", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P3471235", "email_address": "Mark.Batty@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Peter Sewell", "author_profile_id": "81100511814", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P3471236", "email_address": "Peter.Sewell@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Luc Maranget", "author_profile_id": "81100574739", "affiliation": "INRIA, Paris, France", "person_id": "P3471237", "email_address": "luc.maranget@inria.fr", "orcid_id": ""}, {"name": "Jade Alglave", "author_profile_id": "81392617420", "affiliation": "University of Oxford, Oxford, United Kingdom", "person_id": "P3471238", "email_address": "jade.alglave@comlab.ox.ac.uk", "orcid_id": ""}, {"name": "Derek Williams", "author_profile_id": "81485642519", "affiliation": "IBM, Austin, TX, USA", "person_id": "P3471239", "email_address": "striker@us.ibm.com", "orcid_id": ""}], "doi_number": "10.1145/2254064.2254102", "year": "2012", "article_id": "2254102", "conference": "PLDI", "title": "Synchronising C/C++ and POWER", "url": "http://dl.acm.org/citation.cfm?id=2254102"}