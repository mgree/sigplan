{"article_publication_date": "05-01-1999", "fulltext": "\n      errors (kill set = each array and pointer store, and each procedure call; see Section 5). \nExperiments: the effectiveness of profile-guided PRE. The es\u00adtimator experiment also shows the power \nof the program transfor\u00admation stage [10] of our path-sensitive optimizer [4-10]. First, the leftmost \nbar in Figure 7 shows the reuse that exists on all paths coming to a load. This full redundancy represents \nthe dynamic amount of loads that can be removed with global common subex\u00adpression elimination (CSE). \nThe second bar shows the reuse that exists on some incoming paths but is still definite. This additional \nreuse can be exploited with the standard code-motion PRE [24]. Fi\u00adnally, third bar (the lower bound) \nof the estimator gives the additional loads that can be removed with profile-guided specula\u00adtive PRE \n(Section 3.2 in [10]). On average, the standard PRE ex\u00adploits less than half of all partial redundancies; \nthe profile-guided PRE exploits nearly all (the total amount of partial redundancies lies somewhere between \nthe lower and the upper reuse bounds). 5 Experiments This section experimentally evaluates the load-store \nanalysis from Section 3 in relation to the limit study from Section 2. Because our implementation of \nthe analysis is intraprocedural, the reference point for comparison is the intraprocedurally observed \nreuse. To minimize noise in the baseline, we use the reuse collected at the ac\u00adcess history = 1. We \nanalyzed the unoptimized source programs. In summary, for each benchmark, the baseline for comparison \nis the mark in the leftmost column in Figure 2. Figure 8 plots the amount of reuse discovered by the \nanalysis. The plotted amount was computed as the mean average of the lower and upper bounds returned \nby the estimator. The load-reuse analysis was carried out under varying assumptions. The two highest \nbars in Figure 8 show the reuse detected at l-level and O-level address indirection, respectively. Our \nimplementation considered only indirect loads, not stores, which may explain the lack of indirect reuse \nin some benchmarks. To determine the reuse\u00addetection power of the analysis, these two bars assumed perfect \naliasing under which no stores along a reuse paths would kill the detected reuse. While not all of this \naggressively detected reuse can be promoted to registers, it can be exploited with alternative reuse \nmechanisms, such as data-speculative loads, as noted in Section 1. Overall, the comparison with the limit \nstudy shows that our analysis is about 80% PRE-complete. Aliasing. We also studied the killing effects \nof intervening stores and procedure calls. Because our compiler does not perform alias analysis, we considered \nthree hypothetical levels of pointer aliasing precision, specified as follows: first, we assumed that \nonly proce\u00addure calls killed the detected reuse; second, we added to the kill set all stores except for \nstores to global variables; third, all stores and procedure calls killed the reuse. Due to aggressive \ninlining, only a small amount of reuse was lost at procedure calls (the white bar segments). However, \narray and pointer stores remove almost one third of reuse (the dark, middle segments). While this pessimistic \nhypothetical aliasing gives disappointing results, other researchers showed that even a simple alias \nanalysis may produce memory dis\u00adambiguation that is near-optimal for purposes of register promo\u00adtion \n[18, 27]. Register Pressure. Besides aliasing, a lack of registers is another reason why detected reuse \nmay not lead to register promotion. The register pressure at a CFG node is the number memory locations \nwhose reuse path crosses that node; each location needs one reg\u00adister. We averaged the register pressure \nover all nodes, weighting each node by its profile frequency. For the O-level perfect aliasing analysis \nconfiguration, the highest average register pressure was 34 registers for Such an amount of registers \nwill be soon available in general-purpose processors. 6 Related Work Simulation-Based Analysis Evaluation. \nWhile in microarchi\u00adtecture the use of upper-bound limit studies has become common\u00adplace, in compiler \noptimization this trend is recent. In fact, [18] is the only simulation-based evaluation of an analysis \nknown to us. algorithm for removing heap-based loads. The ideal performance is used to determine what \nalias analysis is near-optimal for the load removal, but still not too expensive. Our work differs in \nthat we focus on load-reuse analysis, rather than on the may-alias analy\u00adsis. Lams and Chandra developed \na compiler auditor tool, which analyzes the program trace to discover limitations and bugs in the compiler \n[25]. Reinman et al developed a load-reuse profiler tech\u00adnique similar to our simulator limit-study, \nwith the primary goal to give load-reuse hints to the processor [33].  Estimators. Frequency analysis \nis the only existing systematic method for profile-weighting a data-flow solution [32]. Like our estimators, \nit is based on edge profiles. Unlike the estimators, fre\u00adquency analysis does not bound the profiling \nerror. However, con\u00adsidering that the inherent edge-profile error is small, as suggested by our experiments, \nthe maximum amount of error in the result of frequency analysis will be correspondingly small (the result \nalways falls between our lower and upper bounds). Our estimators offer an alternative to frequency data-flow \nanalysis. While frequency anal\u00adysis requires an elimination-style data-flow solver, our estimators use \nreachability or network flow algorithms, which may be easier to implement. Due to the small size of the \nCMP region, estimators are expected to run faster than a frequency data-flow solver. Load-Reuse Analysis. \nTraditionally, load removal is navigated by a lexical load-reuse analysis, in which only loads with identi\u00adcal \nnames (scalars) or identical syntax-tree structure (record fields) can be detected as equivalent [18, \n26, 26]. Techniques based on value numbering can match expressions that have different names, but their \nsymbolic interpretation power is limited to handling copy assignments [34, 37]. Therefore, they cannot \ncapture equivalences that require symbolic interpretation, such as the recurrent array ac\u00adcesses shown \nin Section 2 for which specialized techniques have been developed [6, 12, 14]. Our load-reuse analysis \nencapsulates both value numbering and symbolic capabilities. While it is less powerful that array dependence \ntechniques [13], the experiments show that our analysis uncovers about 80% of opportunities ex\u00adploitable \nby partial redundancy elimination, including array and pointer loads. Acknowledgments We are grateful \nto Brian Deitrich and John Gyllenhaal for explain\u00ading the intricacies of the IMPACT compiler. The comments \nfrom the anonymous reviewers significantly improved the presentation of the paper. This work was supported \nby NSF grants CCR\u00ad9808590 and EIA-9806525. References  \n\t\t\t", "proc_id": "301618", "abstract": "Load-reuse analysis finds instructions that repeatedly access the same memory location. This location can be promoted to a register, eliminating redundant loads by reusing the results of prior memory accesses. This paper develops a load-reuse analysis and designs a method for evaluating its precision.In designing the analysis, we aspire for <i>completeness</i>---the goal of exposing all reuse that can be harvested by a subsequent program transformation. For register promotion, a suitable transformation is partial redundancy elimination (PRE). To approach the ideal goal of PRE-completeness, the load-reuse analysis is phrased as a data-flow problem on a program representation that is <i>path-sensitive</i>, as it detects reuse even when it originates in a different instruction along each control flow path. Furthermore, the analysis is <i>comprehensive</i>, as it treats scalar, array and pointer-based loads uniformly.In evaluating the analysis, we compare it with an ideal analysis. By observing the run-time stream of memory references, we collect all PRE-exploitable reuse and treat it as the ideal analysis performance. To compare the (static) load-reuse analysis with the (dynamic) ideal reuse, we use an <i>estimator</i> algorithm that computes, given a data-flow solution and a program profile, the dynamic amount of reuse detected by the analysis. We developed a family of estimators that differ in how well they bound the profiling error inherent in the <i>edge</i> profile. By bounding the error, the estimators offer a precise and practical method for determining the run-time optimization benefit.Our experiments show that about 55% of loads executed in Spec95 exhibit reuse. Of those, our analysis exposes about 80%.", "authors": [{"name": "Rastislav Bod&#237;k", "author_profile_id": "81100033082", "affiliation": "Dept. of Computer Science, University of Pittsburgh, Pittsburgh, PA", "person_id": "P239460", "email_address": "", "orcid_id": ""}, {"name": "Rajiv Gupta", "author_profile_id": "81100027751", "affiliation": "Dept. of Computer Science, University of Pittsburgh, Pittsburgh, PA", "person_id": "PP39072720", "email_address": "", "orcid_id": ""}, {"name": "Mary Lou Soffa", "author_profile_id": "81452611636", "affiliation": "Dept. of Computer Science, University of Pittsburgh, Pittsburgh, PA", "person_id": "PP39032771", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/301618.301643", "year": "1999", "article_id": "301643", "conference": "PLDI", "title": "Load-reuse analysis: design and evaluation", "url": "http://dl.acm.org/citation.cfm?id=301643"}