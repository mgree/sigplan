{"article_publication_date": "09-17-2002", "fulltext": "\n Shortcut Fusion for Accumulating Parameters &#38; Zip-like Functions Josef Svenningsson Chalmers University \nof Technology josefs@cs.chalmers.se Abstract We present an alternative approach to shortcut fusion based \non the function unfoldr. Despite its simplicity the technique can remove intermediate lists in examples \nwhich are known to be dif.cult. We show that it can remove all lists from de.nitions involving zip-like \nfunctions and functions using accumulating parameters. Categories and Subject Descriptors D.1.1 [Programming \nTechniques]: Applicative (Functional) Pro\u00adgramming; D.3.4 [Programming Languages]: Optimization; F.3.3 \n[Studies of Program Constructs]: Program and recursion schemes; I.1.4 [Symbolic and Algebraic Manipulation]: \nAppli\u00adcations General Terms Languages, Algorithms  Keywords Deforestation, functional programming, \nintermediate data struc\u00adtures, optimisation, program transformation 1 Introduction Functional programmers \nlike to write programs by composing small, highly parameterised functions. When composed, these functions \nuse intermediate data structures to communicate with each other. These intermediate data structures are \noften lists. A standard example of such a function is the following: sumTo n = sum (map square [1..n]) \n The example is written in Haskell [JH99b]. We will use Haskell throughout this paper. This function \nproduces two intermediate Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. ICFP 02, October 4-6, 2002, Pittsburgh, Pennsylvania, USA. lists, one from the expression \n[1..n] which is immediately con\u00adsumed by map. Next, map produces a list which is immediately con\u00adsumed \nby sum. Both these lists are intermediate structures which do not form part of the result. It is by now \nwell known that many intermediate lists can be re\u00admoved automatically by using program transformations \nand a con\u00adsiderable amount of research has gone into developing more pow\u00aderful and easily applicable \ntechniques, e.g. [Wad90, Mar96, TM95, CDPR99, Ham01, Chi99]. Perhaps the most successful method for removing \nintermediate data structures is shortcut fusion [GLJ93]. It relies on writing list pro\u00adcessing functions \nusing two special functions foldr and build. Whenever a list is produced by build and consumed by foldr, \nthat list can be removed. The technique has been shown to work on many practical examples and it is very \neasy to implement. It is incorporated in the Glasgow Haskell Compiler [PJTH01]. Despite its success, \nshortcut fusion (henceforth called the foldr/build rule) has its shortcomings. Firstly, it cannot remove \nboth lists of the function zip. Secondly it cannot handle functions which consume their lists using accumulating \nparameters. In this paper we present the destroy/unfoldr rule as a new means for shortcut fusion. It \nhas the following characteristics: .The technique can remove all argument lists from a function which \nconsumes more than one list, for example the function zip. In the expression zip [1..n] [1..n] our method \nwill be able to remove all intermediate lists. The problem with zip-like functions has been one of the \nmain criticisms against the foldr/build rule. .The technique can remove intermediate lists from functions \nwhich consume their lists using accumulating parameters. For example, all intermediate lists can be removed \nfrom the func\u00adtion sumTo, even when sum is de.ned using an accumulating parameter. Accumulating parameters \nare known to be prob\u00adlematic when fusing functions and most standard techniques suffer from the inability \nto fuse functions de.ned using them.  .Like the foldr/build rule, our method is simple. It can be im\u00adplemented \nin the same manner and is therefore a good candi\u00addate for incorporating in a compiler. It should be noted \nthat the transformation itself is not new. It was noted by Takano and Meijer that the foldr/build rule \nhas a dual [TM95]. They did not, however, consider this transformation but instead focused on using hylomorphisms \nto express fusion. Copyright 2002 ACM 1-58113-487-8/02/0010 ...$5.00 In this paper we will only consider \nlists when we want to remove intermediate data structures. But most things we present generalises (like \nthe foldr/build rule) directly to other data types. The paper is organised as follows. We will begin \nby recapitulate the foldr/build rule in section 2. Section 3 explains the destroy/unfoldr rule and show \nhow list processing functions can be de.ned in terms of the functions destroy and unfoldr. In the next \ntwo sections we will show how the destroy/unfoldr rule can remove intermediate lists from de.nitions \ninvolving zip-like functions (Section 4) and accumulating parameters (Section 5). Section 6 discusses \nrelated work and Section 7 concludes. Some ef.ciency issues of shortcut fusion will be discussed in an \nappendix. 2 foldr/build The perhaps most successful technique for removing intermediate data structures \nis the foldr/build rule. But how does it work? In this section we will spend a few sentences explaining \nit as it will give us a good intuition when considering our new results and why they are important. The \nwhole story begins with two functions, foldrand build. Let s start by looking at foldr. The function \nfoldr is rather well-known to the functional pro\u00adgramming community. It has several names such as reduce \nand accumulate. It is known to be the catamorphism for lists [MFP91]. It can be de.ned as follows: foldr \nf n [] = n foldr f n (x:xs) = f x (foldr f n xs) Informally foldr goes through the list replacing, every \ncons by its .rst argument (f) and replaces nil by its second argument (n). Next, we look at the function \nbuild which is less well-known and rather speci.c to shortcut fusion. Here is how it is de.ned: build \ng = g (:) [] The important thing with build is not the function itself but its argument g. It is a function \nwhich is supposed to produce a list. But it may not do so using the list constructors (:) and [] (cons \nand nil) directly. Instead it must use whatever values are passed to it as arguments to construct the \nlist. This is because after applying the foldr/build rule, g might no longer be producing lists at all. \nWe will shortly come back to how we can ensure that g doesn t use the list constructors directly. We \nnote that build applied to foldr gives the identity function for lists, i.e.: build foldr == id The \nnext part is the actual rule which can remove intermediate data structures, the foldr/build rule. The \nbeauty is in its simplicity: foldr c n (build g) ==> g c n This rule, as it stands, is, however, not \ncorrect. The correctness of the rule relies on the fact that the function g does not use the list constructors \ninternally while producing the list. Instead it must use its arguments to construct the list. The idea \nis then that if we pass it something different than the list constructors, then another kind of value \nis produced. And this is exactly what the foldr/build rule does. So how can we make sure that g does \nnot use the list constructors to construct its result list? It can be ensured by restricting g s type. \nBut in actual implementations it turns out to be more convenient to give build a more re.ned type than \nthe inferred one: build :: (forall b. (a -> b -> b) -> b -> b) -> [a] (Haskell does not have types of \nhigher rank but several implemen\u00adtations provide support for this.) From this type we can see that g \nmust be polymorphic in its result type and the only way that it can produce it is to use its arguments. \nUsing this type we can ensure that g is suf.ciently polymorphic. Initially, work on model theory for \npolymorphic lambda calculus was used to argue for the correctness of the rule [Wad89]. Recently, a proof \nbased on operational techniques has been given [Joh01]. In order for the rule to apply the programmer \nneeds to de.ne his/her functions using foldr and build. Only then will the rule apply. This has turned \nout not to be a big burden since many functions in the standard libraries can be written in this style \nand therefore it suf.ces to use those functions to be certain that intermediate lists are removed. It \nshould be noted that the foldr/build rule is in itself rather harm\u00adless. It relies heavily on other transformations \nwhich enable the rule to apply. The most important are inlining of functions and \u00df\u00adreduction. In some \ncases it also relies on arity analysis [Gil96]. In this paper we will explicitly write out in each step \nwhat other trans\u00adformations are used to enable fusion in order to show that there is no magic going on. \nMost of the transformations that we will use are completely standard and are implemented in the Glasgow \nHaskell Compiler [PJS98]. If this is not the case we will brie.y explain them. 2.1 Good producers and \nconsumers When talking about short cut fusion it is often handy to classify functions as good producers \nand/or good consumers. This termi\u00adnology was introduced in [Gil96]. We will here de.ne what they mean \nand get some intuition about them. The idea behind good producers and consumers is the following: Whenever \na good consumer is applied to a good producer the inter\u00admediate data structure between the two can be \nremoved. This can be achieved by de.ning good producers in terms of buildand good consumers in terms \nof foldr. More formally a good producer is a function which for some expression e and arguments a1 to \nan is de.ned as follows: f a1 .. an = build e In other words a good producer must be de.ned directly \nin terms of build. Good consumers are a little trickier to de.ne. A function may take several lists as \narguments but need not be a good consumer in all of these arguments. It is therefore necessary to consider \na function to be a good consumer in certain arguments. This gives rise to the following de.nition. Consider \nthe the function f: fa1 ..ak..an = e we will say that f is a good consumer in ak if ak occurs once in \ne as the third argument to foldr. Put another way one can say that somewhere in ethere needs to be a \ncall to foldrlooking like foldr gzakfor some gand z. Furthermore this is the only place akmay occur. \nIt is actually possible to loosen the requirements on a good con\u00adsumer but the current de.nition will \nsuf.ce in this paper. Now we can see that if we have an application of a good consumer applied to a good \nproducer and we inline both function de.nitions we can directly apply the foldr/build rule and remove \nthe intermedi\u00adate list. We will see several examples of this in the coming sections. The informed reader \nnotes that these de.nitions differs somewhat from the de.nitions in [Gil96]. For the purpose of this \npaper this difference is unimportant. When we move to the next section we will revise the notion of good \nconsumers and producers to .t our purposes. 2.2 Limitations It is well known that the foldr/build rule \nis unable to handle zip-like functions and Gill describes it as a signi.cant shortcoming in his thesis \n[Gil96]. The reason is that foldr only traverses one list at a time. However, it is quite possible to \nremove one of the two lists which are fed to zip. Functions that consume lists using accumulating parameters \nalso cause problems for the foldr/build rule. The reason is again the function foldr. All good consumers \nhave to be written in terms of foldr and foldr simply doesn t handle accumulating parameters. Some readers \nmight object to this because the function foldl is de.ned using foldr and it uses accumulating parameters. \nUsing this de.nition buys us nothing however. It introduces suspended function calls isomorphic to the \nremoved list and so we have gained nothing. The foldr/build rule has other shortcomings as well but the \nones we just mentioned are the ones we will tackle in this paper.  3 destroy/unfoldr The optimisation \nthat we present in this paper has three impor\u00adtant ingredients that we will explain in this section. \nBut before we plunge into our explanation we would like to emphasise the fact that the material presented \nin this section is not new. But, although not new, many of the things we present here is not known to \na wider audience and they are vital to understand the contribution of this paper. 3.1 unfoldr Our .rst \nkey ingredient is the function unfoldr. This is a rarely used function which can be found in the Haskell \nLibrary report [JH99a]. As the name reveals it does the opposite of foldr, it con\u00adstructs lists instead \nof consuming them. unfoldr :: (b -> Maybe (a,b)) -> b -> [a] unfoldr f b = case f b of Nothing -> [] \n Just (a,b ) -> a : unfoldr f b An operational intuition of a call unfoldr f b is as follows: unfoldr \nis given an initial state b. The function f is applied to b to determine whether we shall produce more \nof the output list. If fb returns Nothing then the end of the list is returned. On the other hand if \nthe list should be longer, fb returns the value Just (a,b ) where a is the new element of the list and \nb is the next state we shall use to produce the rest of the list. In some examples we will inline unfoldr. \nBut inlining recursive functions can be problematic. When we want to use unfoldr for this purpose we \nwill use the following de.nition which is non\u00adrecursive but uses a locally de.ned recursive function \nwhich does the job: unfoldr fb=go b where go b = case f b of Nothing -> [] Just (a,b ) -> a : go b \n This version of unfoldr can easily be inlined. 3.2 destroy Our next key ingredient is also a function. \nWe have chosen to bap\u00adtise it destroy since it consumes lists 1. It does so in a fashion tai\u00adlored to \n.t together with unfoldr. Its de.nition is as follows: destroy g xs = g listpsi xs where listpsi :: \n[a] -> Maybe (a,[a]) listpsi [] = Nothing listpsi (x:xs) = Just (x,xs) The reader might wonder what \nthe type of destroy is. We will have reason to come back to this in the next subsection. Just as build \napplied to foldr yields the identity function we have a similar law for destroy and unfoldr. We have \nthat destroy composed with unfoldr yields the identity. Stated algebraically this looks like: destroy \n. unfoldr == id This follows immediately from the fact that unfoldr listpsi == id. The interesting thing \nwith destroy is, as with build, not the func\u00adtion itself but its argument. g is a function which consumes \na list, but it must not do so by pattern matching on the list. Instead it is passed a function through \nwhich it can inspect the list, thus we have created a kind of view [Wad87] of lists for g. 3.3 The destroy/unfoldr \nrule The third ingredient is a transformation rule using both destroy and unfoldr. We call it the destroy/unfoldr \nrule and it looks like this: destroy g (unfoldr psi e) ==> g psi e As with the foldr/build rule, this \nrule does not hold unconditionally but we must require that the type of g is forall a.(a -> Maybe (b,a)) \n-> a -> c)2 for some types b and c. This can be ensured by giving destroy the following type: 1In his \nthesis Gill calls this function unbuild [Gil96]. This was unknown to us at the time we (re-)discovered \nthis function and we have chosen to stick to the name we came up with. 2Some readers might be worried \nabout the use of the Maybe type. Are we removing lists just to introduce another structure? No, the Maybe \ntype is only transient and will be removed when the transformation machinery is .nished. destroy :: (forall \na. (a -> Maybe (b,a)) -> a -> c) -> [b] -> c The idea with the destroy/unfoldr rule is (as with the \nfoldr/build rule) to de.ne functions in terms of destroy and unfoldr.We can then inline these functions \nand apply the destroy/unfoldr rule to remove intermediate lists. Next, we look into the problem of de.ning \nlist processing functions using destroy and unfoldr. We believe that the destroy/unfoldr rule can be \nproved using similar techniques as in [Joh01]. This is, however, a substantial exercise and we leave \nit as future work. 3.4 Expressing list functions using unfoldr and destroy If we want to use the destroy/unfoldr \nrule to remove intermedi\u00adate lists we must express our functions in terms of unfoldr and destroy. Intuitively \nthis should be quite easy but it will soon be\u00adcome evident that there is more to it than meets the eye. \nFirst we will revise the notion of good producers and consumers. A good producer is a function which \nfor some expressions psi, e and arguments a1 to an is de.ned as follows: f a1 .. an = unfoldr psi e \nSimilarly, a function f: fa1 ..ak..an = e is a good consumer in ak if ak occurs only once in e as the \nsecond argument to a call to destroy. In order to get a feeling for how the destroy/unfoldr rule works \nlet us .rst look at some simple examples. The function enumFromTotakes two integers n and m and returns \na list of all integers between and including n and m. Since it is a list producing function we should \nde.ne it using unfoldr. This can be done as follows: enumFromTo n m = unfoldr (\\i -> if i > m then \nNothing else Just (i,succ i)) n An interesting example (at least in this context) of a function which \nconsumes a list is foldr. It can be de.ned using destroy in the following way: foldr k z xs = destroy \nfoldrDU xs where foldrDU psi xs = case psi xs of Nothing -> z Just (x,ys) -> k x (foldrDU psi ys) \n It should be noted that we can de.ne a large class of list consumers in terms of destroy. We will have \nmore to say about this in section 5. Next, we turn to the task of de.ning functions which both produce \nand consume lists, e.g. map. The function map can be de.ned using foldr and, as we saw, foldr could easily \nbe written as a good consumer. We shall therefore begin with a de.nition of map where it is only a good \nconsumer and then re.ne it: map f xs = destroy mapDU ls where mapDU psi xs = case psi xs of Nothing \n-> [] Just (x,ys) ->fx: mapDU psi ys When we want to de.ne a list producing function using unfoldr \nwe should aim at replacing [] with Nothing and : with Just. This is not always possible because the second \nargument to : needs to be a recursive call. In this case, however, it is perfectly possible and we end \nup with the following de.nition: map f xs = destroy (\\psi a -> unfoldr (mapDU psi) a) xs where mapDU \npsi xs = case psi xs of Nothing -> Nothing Just (x,ys) -> Just (f x,ys) There is a problem with this \nde.nition however. It is not a good producer since unfoldr is not at the outermost level of the function \nde.nition. There is a way to write map so that it becomes a good producer but then it is not a good consumer. \nThere doesn t seem to be a way we can de.ne map so that it is both a good producer and a good consumer. \nThere is, however, a way out of our problems. Consider what hap\u00adpens when we want to fuse two map functions \nthat sit next to each other like this: map f (map g xs) When we inline both occurrences of map and a-rename \nwe get the following expression: destroy (\\psi a -> unfoldr (mapDUf psi) a) (destroy (\\psi a -> unfoldr \n(mapDUg psi) a) xs) where mapDUf = ... mapDUg = ... We can see that the inner destroy prevents the unfoldr \nfrom con\u00adtacting the outer destroy and allowing the destroy/unfoldr rule to apply. Our solution to this \nis another rule which lets a destroy move inside another destroy and hopefully encounter an unfoldr. \nThe rule looks like this: destroy g (destroy g ls) ==> destroy (\\psi a -> destroy g (g psi a)) ls We \nwill call this rule the destroy/destroy rule. It can easily be shown correct by unfolding the de.nition \nof destroy. The idea with the rule is that if g happens to be a function de.ned using unfoldr then we \nwill bring it together with the outer destroy using the above rule. Now we can continue with our example \ninvolving the two maps. Here is what we will get if we apply our new destroy/destroy rule: destroy (\\psi1 \na1 -> destroy (\\psi a -> unfoldr (mapDUf psi) a) ((\\psi a -> unfoldr (mapDUg psi) a) psi1 a1)) xs where \nmapDUf = ... mapDUg = ... Performing two \u00df-reductions will give us a possibility to apply the destroy/unfoldr \nrule: destroy (\\psi1 a1 -> destroy (\\psi a -> unfoldr (mapDUf psi) a) (unfoldr (mapDUg psi1) a1)) xs \nwhere mapDUf = ... mapDUg = ... Applying the destroy/unfoldr rule and performing two \u00df-reductions gives \nus: destroy (\\psi1 a1 -> unfoldr (mapDUf (mapDUg psi1)) a1) xs where mapDUf = ... mapDUg = ... Inlining \nand simplifying mapDUf and mapDUg will give a map func\u00adtion which applies the function f.g to each element \nwithout creat\u00ading any intermediate data structure. We have seen how we can de.ne map in terms of destroy \nand unfoldr. Some other common list processing functions can be found in .gure 1.  4 zip fusion One \nof the criticisms that have been raised against foldr/build fu\u00adsion is the following: Suppose we have \na function f which recurses over more than one list simultaneously. We will henceforth call such functions \nzip-like. In the foldr/build framework we can make f a good producer in only one of its arguments3. In \nthis section we show how destroy/unfoldr fusion solves this problem gracefully. We do this by means of \nan example. Although we only give an ex\u00adample it should be noted that the result is completely general. \nThe .rst thing we have to do is de.ne the function zip in terms of destroy and unfoldr keeping in mind \nthat we would like zip to be a good consumer in all its arguments. This turns out to be quite easy to \nachieve. zip xs ys = destroy (\\ psi1 e1 -> destroy (\\ psi2 e2 -> unfoldr (zipDU psi1 psi2) (e1,e2) \n )ys )xs where zipDU psi1 psi2 (e1,e2) = case psi1 e1 of Nothing -> Nothing Just (x,xs) -> case \npsi2 e2 of Nothing -> Nothing Just (y,ys) -> Just ((x,y),(xs,ys)) We will now see how this de.nition \nof zip enables us to remove the intermediate lists of both arguments. Consider the following de.nition: \nascii_table = zip (enumFromTo A Z ) (enumFromTo 65 90) 3It should be noted that even though f can only \nbe a good con\u00adsumer in one of its arguments this argument need not be .xed. The important thing is that \nf can only be a good consumer for one argu\u00adment at a time. This de.nition has two intermediate lists, \none for each argument of zip. Inlining zip and enumFromTo gives us: ascii_table = destroy (\\psi1 e1 \n-> destroy (\\psi2 e2 -> unfoldr (zipDU psi1 psi2) (e1,e2)) (unfoldr (\\i -> ifi> 90 then Nothing \n else Just (i,succ i)) 65)) (unfoldr (\\i -> if i > Z then Nothing else Just (i,succ i)) A ) where \nzipDU = ... This gives us two opportunities to apply the destroy/unfoldr rule. Doing so will give: ascii_table \n= unfoldr (zipDU (\\i -> ifi> Z then Nothing else Just (i,succ i)) (\\i -> ifi>90 then Nothing else \nJust (i,succ i))) ( A ,65) where zipDU = ... Now, let us inline zipDU. After that, performing two \n\u00df-reductions, case-of-if and case-of-known will give us: ascii_table = unfoldr (\\(e1,e2) -> if e1 > \nZ then Nothing else if e2 > 90 then Nothing else Just ((e1,e2),(succ e1,succ e2))) ( A ,65) Inlining \nunfoldr (and translating the lambda-pattern to a case) will yield: ascii_table = go ( A ,65) where go \nb = case (\\a -> case a of (e1,e2) -> if e1 > Z then Nothing else if e2 > 90 then Nothing else \nJust ((e1,e2) ,(succ e1 ,succ e2))) b of Nothing -> [] Just (a,b ) -> a : go b This in turn can \nbe simpli.ed (via a \u00df-reduction and performing case-of-case and case-of-known transformations) to: map \nf xs = destroy (\\psi a -> unfoldr (mapDU psi) a) xs where mapDU psi xs = case psi xs of Nothing -> Nothing \nJust (x,ys) -> Just (f x,ys) filter p xs = destroy (\\psi a -> unfoldr (filterDU psi) a) xs where filterDU \npsi xs = case psi xs of Nothing -> Nothing Just (b,ys) -> if p b then Just (b,ys) else filterDU psi \nys foldr f z xs = destroy foldrDU xs where foldrDU psi xs = case psi xs of Nothing -> z Just (x,ys) \n-> f x (foldrDU psi ys) enumFromTo n m = unfoldr (\\i -> if i > m then Nothing else Just (i,succ i)) \nn repeat x = unfoldr (\\a -> Just (x,a)) undefined [] = unfoldr (const Nothing) undefined Figure 1. Some \nstandard list processing functions de.ned using destroyand unfoldr ascii_table = go ( A ,65) where go \nb = case b of (e1,e2) -> if e1 > Z then [] else if e2 > 90 then [] else (e1,e2) : go (succ e1,succ \ne2) As we can see both intermediate lists have been removed.  5 Fusion with accumulating parameters \nSome functions that consume lists have to be de.ned using an ac\u00adcumulating parameter. Others are de.ned \nusing an accumulating parameter for ef.ciency reasons. If we want to fuse such functions to remove intermediate \nlists we currently have to use rather sophis\u00adticated methods [CDPR99, VK01]. In this section we show \nhow de\u00adstroy/unfoldr fusion can achieve this elegantly in some cases. Again we note that even though \nwe only give an example the result is gen\u00aderally applicable. Many functions consuming lists using accumulating \nparameters can be expressed in terms of two higher order functions foldl and foldl . These functions \nare well known to the functional program\u00admer. The latter function is a strict version of the .rst which \nallows the compiler to generate code that is usually more ef.cient. We will use foldl as an example to \nshow how the destroy/unfoldr rule can deal with accumulating parameters. For our purposes we will de.ne \nfoldl in a rather roundabout way, having two locally de.ned functions foldlDU and foldlDU . Us\u00ading foldl \non this form simpli.es the transformations that we want to do. foldl f b xs = destroy (foldlDU b) xs \n where foldlDU acc psi xs = foldlDU acc xs where foldlDU acc xs = case psi xs of Nothing -> acc Just \n(a,ys) -> let acc = f acc a in seq acc (foldlDU acc ys) seq is a function which evaluates its .rst \nargument and returns its second argument after evaluating it. In this way acc will be eval\u00aduated before \nfoldlDU is called recursively. Now, to our example. Consider the following function de.nition: bar f \nbnm= foldl f b (enumFromTo n m) The function enumFromTo produces a list which is consumed by foldl . \nThe goal is to remove this intermediate list. We begin by inlining foldl and enumFromTo. This will yield: \nbar f bnm= destroy (foldlDU b) (unfoldr (\\i -> if i>m then Nothing else Just (i,succ i)) n) where \nfoldlDU acc psi xs = foldlDU acc xs where foldlDU acc xs = ... This gives us an opportunity to apply \nthe unfoldr/destroy rule. Do\u00ading so will give us: bar f bnm= foldlDU b (\\i -> ifi> m then Nothing \nelse Just (i,succ i)) n where foldlDU acc psi xs = foldlDU acc xs where foldlDU acc xs = ... The next \nthing we will do is to inline foldlDU. After applying the transformations case-of-case, case-of-known \nand \u00df-reduction we will end up with the following de.nition: bar f bnm= foldlDU b n where foldlDU acc \nxs = if xs > m then acc else let acc = f acc xs in seq acc (foldlDU acc (succ xs)) Assuming that \nthe compiler can spot that foldlDU is strict in its second argument this version of bar is as ef.cient \nas we may hope for. Most notably, all intermediate structures between foldl and enumFromTo have been \nremoved. 6 Related work Removing intermediate data structures is a popular research subject and has \nreceived quite a lot of attention e.g. [Wad84, Wad90, Chi92, GLJ93, SF93, TM95, Feg96, Chi99]. Fegaras, \nSheard and Zhou were (to our knowledge) the .rst group to attack to problem of fusing functions which \nrecurse over multi\u00adple data [FSZ94]. They extended their previous method for fusing functions [SF93] \nto handle this wider class of functions. They rely on a normalisation algorithm which transforms function \nde.nitions. Their approach is rather powerful but it is unclear how well it would work in a compiler \nwith real programs as input. Later, Takano and Meijer responded to the original shortcut fusion paper \nby generalising the fusion law using hylomorphisms [TM95]. They start by observing that the foldr/build \nrule has a dual, the de\u00adstroy/unfoldr rule we use in this paper. However, they do not study it any further \nbut instead focus on fusing functions expressed as hylomorphisms. It should be noted that although hylomorphisms \nare generalisations of both foldr-and unfoldr-like functions their transformation does not generalise \nthe corresponding transforma\u00adtions. The problem is that hylomorphisms are unable to express functions \nsuch as those using accumulating parameters, which can be expressed with destroy. In their paper they \nshow how their method can fuse all lists arguments to the function zip. This claim has, however, been \ncriticised in the paper [HIT96] which develops more theory to be able to fuse zip-like functions. Recently \nthere has been work on trying to extend the foldr/build rule to handle zip-like functions [LKS00]. This \napproach has modi.ed the foldr function to use a notion of hyperfunctions. This, how\u00adever, makes the \ninitial simplicity of the foldr/build rule disappear since the original foldr function is not usable \nany more. It also requires all list processing functions to have their types changed. Accumulating parameters \nare known to be problematic when re\u00admoving intermediate data structures and most techniques fail for \nsuch functions. Ideas which have been developed to tackle this weakness are to fuse attribute grammars \n[CDPR99] or macro tree transducers [VK01, Voi02b]. These methods can handle quite a large class of functions \nand deal easily with functions using accu\u00admulating parameters. However, these approaches are rather heavy\u00adweight. \nThe former method require that functions are rewritten into attribute grammars which are quite different \nfrom the functional language being transformed. The transformation is then applied on these intermediate \nforms and then translated back. In the latter method the transformation work on a restricted form of \nfunctions which have to be identi.ed before transforming them. In both cases the transformations involved \nare non-trivial. This is in contrast to our method which is extremely simple, although it can probably \nnot handle as large a class of functions. Recently Voigtl\u00a8ander has proposed a methodology for removing \nin\u00adtermediate data structures from programs by abstracting over these operations [Voi02a]. Using this \ntechnique makes it possible to re\u00admove intermediate structures in many cases. Although quite simple and \nelegant the technique does require the programmer to change the functions in which fusion is to take \nplace. The author suggests that this may be automated in a similar fashion as [Chi99]. We be\u00adlieve that \nit is possible to dualise his result in the same way as we have dualised shortcut fusion in this paper. \nThis paper also gives fuel to the opinion that the function unfoldr is greatly under-appreciated [GJ98]. \nGibbons and Jones note that unfoldr is useful for deforestation but only together with foldr. With our \nmethod we can remove a lot more intermediate lists since we use destroy as a good consumer and not (the \nmore restricted) foldr. 7 Conclusion and future work In this paper we have investigated an alternative, \nless well known technique for shortcut fusion which we call the destroy/unfoldr rule. We have shown that, \ndespite its simplicity, it can tackle problems which have shown to be rather dif.cult to handle. These \nproblems are fusing functions with accumulating parameters and removing all intermediate lists from zip-like \nfunctions. We have made a prototype implementation using the rules pragma of the Glasgow Haskell Compiler \n[PJTH01]. The rules pragma al\u00adlows the programmer to specify left-to-right rewrite rules which the compiler \nwill apply on the program whenever it can. This has al\u00adlowed us to verify that the transformation presented \nin this paper works for small examples. More work is needed for the implemen\u00adtation to scale up and we \nbelieve that the techniques developed for the foldr/build rule can be used for that. An interesting path \nof future work is to see how the foldr/build rule and the destroy/unfoldr rule can cohabit. One way would \nbe to let the compiler choose among several different implementations of a function in order to maximise \nfusion.  Acknowledgements I am very much indebted to J\u00a8orgen Gustavsson for suggesting many improvements \nand for helping out with the examples on the space behaviour of shortcut fusion. My supervisor David \nSands helped a lot to improve the presentation of this paper and Janis Voigl\u00a8ander supplied many insightful \ncomments. Finally I thank the referees for their many valuable comments and suggestions for improvement. \nS.D.G.  References [CDPR99] Loic Correnson, Etienne Duris, Didier Parigot, and Gilles Roussel. How to \ndeforest in accumulative pa\u00adrameters? Technical Report 3608, INRIA, January 1999. [Chi92] W. Chin. Safe \nFusion for Function Expressions. In Proceedings of the ACM Symposium on Lisp and Func\u00adtional Programming, \npages 11 20, San Francisco, Cal\u00adifornia, June 1992. [Chi99] Olaf Chitil. Type inference builds a short \ncut to defor\u00adestation. In Proceedings of the 1999 ACM SIGPLAN International Conference on Functional \nProgramming, volume 34 of ACM Sigplan Notices, pages 249 260, 1999. [Feg96] L. Fegaras. Using the parametricity \ntheorem for pro\u00adgram fusion. Technical Report 96-001, Oregon Gradu\u00adate Institute, 1996. [FSZ94] L. Fegaras, \nT. Sheard, and T. Zhou. Improving pro\u00adgrams which recurse over multiple inductive structures. In ACM \nSIGPLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation, Orlando, Florida, June \n1994. [GJ98] Jeremy Gibbons and Geraint Jones. The under\u00adappreciated unfold. In Proceedings 3rd ACM \nSIGPLAN Int. Conf. on Functional Programming, ICFP 98, Bal\u00adtimore, MD, USA, 26 29 Sept 1998, pages 273 \n279. ACM Press, New York, 1998. [GLJ93] A. Gill, J. Launchbury, and S. Peyton Jones. A Short Cut to Deforestation. \nIn Functional Programming and Computer Architecture, pages 223 232, Copenhagen, Denmark, June 1993. [GS01] \nJ\u00a8orgen Gustavsson and David Sands. Possibilities and limitations of call-by-need space improvement. \nIn Pro\u00adceeding of the Sixth ACM SIGPLAN International Con\u00adference on Functional Programming (ICFP 01), \npages 265 276. ACM Press, September 2001. [Ham01] G.W. Hamilton. Extending higher order deforestation: \nTransforming programs to eliminate even more trees. In Proceedings of the Third Scottish Functional Pro\u00adgramming \nWorkshop, Stirling, Scotland, August 2001. [HIT96] Zhenjiang Hu, Hideya Iwasaki, and Masato Takeichi. \nAn Extension of the Acid Rain Theorem. In 2nd Fuji International Workshop on Functional and Logic Programming, \npages 91 105, Shonan Village, Japan, November 1996. World Scienti.c. [JH99a] S. Peyton Jones and J. Hughes. \nHaskell 98 library re\u00adport, February 1999. [JH99b] S. Peyton Jones and J. Hughes. Haskell 98 report, \nFebruary 1999. [Joh01] Patricia Johann. Short cut fusion: Proved and im\u00adproved. In W. Taha, editor, Proceedings \nof the Sec\u00adond International Workshop on Semantics, Applica\u00adtions, and Implementation of Program Generation, \nvol\u00adume LNCS 2196 of Lecture Notes in Computer Sci\u00adence, Florence, Italy, September 6 2001. Springer. \n[LKS00] J. Launchbury, S. Krstic , and T. E. Sauerwein. Zip Fu\u00adsion with Hyperfunctions. Oregon Graduate \nInstitute, 2000. [Mar96] Simon Marlow. Deforestation for Higher-Order Func\u00adtional Programs. PhD thesis, \nUniversity of Glasgow, 1996. [MFP91] Erik Meijer, Maarten Fokkinga, and Ross Paterson. Functional Programming \nwith Bananas, Lenses, En\u00advelopes and Barbed Wire. In John Hughes, editor, Proceedings of the 5th ACM \nConference on Functional Programming Languages and Computer Architecture (FPCA), volume 523 of LNCS. \nSpringer-Verlag, 1991. [PJS98] S. Peyton Jones and A. Santos. A transformation-based optimiser for Haskell. \nScience of Computer Program\u00adming, 32(1 3):3 47, 1998. [PJTH01] S. Peyton Jones, A. Tolmach, and T. Hoare. \nPlaying by the rules: rewriting as a practical optimisation tech\u00adnique in GHC. In Haskell Workshop, 2001. \n[San98] D. Sands. Improvement theory and its applications. In A. D. Gordon and A. M. Pitts, editors, \nHigher Order Operational Techniques in Semantics, Publications of the Newton Institute, pages 275 306. \nCambridge Uni\u00adversity Press, 1998. [Gil96] A. Gill. Cheap Deforestation for Non-strict Functional Languages. \nPhD thesis, University of Glasgow, 1996. [SF93] T. Sheard and L. Fegaras. A Fold for All Seasons. In \nSixth Conference on Functional Programming Lan\u00adguages and Computer Architecture, pages 233 242, Copenhagen, \nJune 1993. [TM95] A. Takano and E. Meijer. Shortcut deforestation in cal\u00adculational form. In Simon L \nPeyton Jones, editor, Func\u00adtional Programming and Computer Architecture, San Diego, 1995. ACM. [VK01] \nJ. Voigtl\u00a8ander and A. K\u00a8uhnemann. Composition of functions with accumulating parameters. Technical Re\u00adport \nTUD-FI01-08, Dresden University of Technology, 2001. [Voi02a] J. Voigtl\u00a8ander. Concatenate, reverse and \nmap vanish for free. In Proceeding of the Seventh ACM SIGPLAN International Conference on Functional \nProgramming (ICFP 02). ACM Press, 2002. [Voi02b] J. Voigtl\u00a8ander. Using Circular Programs to Deforest \nin Accumulating Parameters. In Proceeding of the Asian Symposium on Partial Evaluation and Semantics-Based \nProgram Manipulation (ASIA-PEPM 02).ACM Press, 2002. [Wad84] P. Wadler. Listlessness is Better than Laziness: \nLazy Evaluation and Garbage Collection at Compile-time. In Proceedings of the ACM Symposium on Lisp and \nFunc\u00adtional Programming, Austin, Texas, 1984. [Wad87] Philip Wadler. Views: a way for pattern matching \nto cohabit with data abstraction. In 14 th ACM Sympo\u00adsium on Principles of Programming Languages, Mu\u00adnich, \nGermany, January 1987. [Wad89] Philip Wadler. Theorems for free! In 4 th Inter\u00adnational Conference on \nFunctional Programming and Computer Architecture, London, September 1989. [Wad90] Philip Wadler. Deforestation: \ntransforming programs to eliminate trees. Theoretical Computer Science, 73:231 248, 1990. A Shortcut \nfusion is not an improvement Using parametricity to prove the correctness of an optimisation is a rather \nweak ground since it only tells us that the expressions will compute the same values before and after \ntransformation. But when we are dealing with transformations we want to know if the trans\u00adformation actually \nimproves the program or not. A reasonable thing to expect is that the transformation improves programs \nin some improvement theory [San98]. We will here give indications that neither the foldr/build rule nor \nthe destroy/unfoldr rule are space improvements [GS01]. In the examples we will assume the seman\u00adtics \nused in the paper by Gustavsson and Sands. A.1 The foldr/build rule increases sharing First we will give \nan example showing that the foldr/build rule can increase sharing in a program. When sharing is increased, \nbits of memory is retained longer and can therefore result in higher mem\u00adory demands of the program. \nConsider the following functions: ones = build (\\c n -> let l=c1 linl) map f xs = build (\\c n -> foldr \n(\\x xs -> f x c xs) n xs) Suppose we have the following expression: map square ones Each element in \nthe resulting list will be computed separately. Now, suppose we inline the de.nitions and apply foldr/build \nfusion. After some \u00df-reductions we will then end up with the following expres\u00adsion: build(\\c n -> let \nl = c (f 1) l in l) We can now see that in the computation f1 is computed only once and shared among \nthe elements of the list. It should be noted that in the original paper on the foldr/build rule [GLJ93], \nrepeat was given a de.nition similar to ones. Using that de.nition will probably lead to increased sharing \nwhen the foldr/build rule is used. A.2 The destroy/unfoldr rule loses sharing Next, we turn to the destroy/unfoldr \nrule. Since it is the dual of the foldr/build rule we might expect examples where it can decrease the \nsharing in a program. This turns out to be the case. Consider the following functions: foo xs = destroy \nbar xs where bar psi xs = case psi xs of Just (a,ys) -> 1 Nothing -> case psi xs of Nothing -> 1 \n Just (b,zs) -> 1 traverse [] = Nothing traverse (x:xs) = traverse xs foo is a rather strange looking \nfunction but it serves its purpose in the example. The key thing to note is that it performs the call \npsi xs twice. Now, suppose we have the following expression: foo (unfoldr traverse biglist) where biglist \nis some arbitrary big list. What will happen is that foo will try to inspect its list. When doing so \nunfoldr traverse biglist will be evaluated to the empty list. This is done once and for all since it \nwill occur as the argument xs in the local function bar. Lazy evaluation will make sure that the computation \nof xs inside bar is shared with foo. Now, let us see what happens when we transform our expression. We \nbegin by inline the de.nition of foo. destroy bar (unfoldr traverse biglist) where bar = ... We have \nnow an opportunity to apply the destroy/unfoldr rule. Do\u00ading so and inlining the de.nition of bar will \nmake us end up with: case traverse biglist of Just (a,ys) -> 1 Nothing -> case traverse biglist of \n Nothing -> 1 Just (b,zs) -> 1 In this .nal expression traverse biglist is performed twice. We have \nthus lost sharing.  \n\t\t\t", "proc_id": "581478", "abstract": "We present an alternative approach to shortcut fusion based on the function <i>unfoldr,</i>. Despite its simplicity the technique can remove intermediate lists in examples which are known to be difficult. We show that it can remove all lists from definitions involving <i>zip</i>-like functions and functions using accumulating parameters.", "authors": [{"name": "Josef Svenningsson", "author_profile_id": "81100424031", "affiliation": "Chalmers University of Technology", "person_id": "P394766", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/581478.581491", "year": "2002", "article_id": "581491", "conference": "ICFP", "title": "Shortcut fusion for accumulating parameters & zip-like functions", "url": "http://dl.acm.org/citation.cfm?id=581491"}