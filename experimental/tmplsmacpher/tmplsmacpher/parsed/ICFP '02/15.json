{"article_publication_date": "09-17-2002", "fulltext": "\n Typing Dynamic Typing Arthur I. Baars S. Doaitse Swierstra arthurb@cs.uu.nl doaitse@cs.uu.nl Institute \nof Information and Computing Sciences Utrecht University P.O.Box 80.089 3508 TB Utrecht, The Netherlands \n Abstract Even when programming in a statically typed language we every now and then encounter statically \nuntypable values; such values re\u00adsult from interpreting values or from communicating with the out\u00adside \nworld. To cope with this problem most languages include some form of dynamic types. It may be that the \ncore language has been explicitly extended with such a type, or that one is allowed to live dangerously \nby using functions like unsafeCoerce. We show how, by a careful use of existentially and universally \nquanti.ed types, one may achieve the same effect, without extending the language with new or unsafe features. \nThe techniques explained are univer\u00adsally applicable, provided the core language is expressive enough; \nthis is the case for the common implementations of Haskell. The techniques are used in the description \nof a type checking compiler that, starting from an expression term, constructs a typed function representing \nthe semantics of that expression. In this function the overhead associated with the type checking is \nonly once being paid for; in this sense we have thus achieved static type checking. Categories and Subject \nDescriptors D.1.1 [Programming Techniques]: Applicative (Functional) Pro\u00adgramming; D.3.3 [Programming \nLanguages]: Language Con\u00adstructs and Features abstract data types, polymorphism, control structures; \nF.3.3 [Logics and Meanings of Programs]: Studies of Program Constructs control primitives, functional \nconstructs, type structure General Terms Languages, Theory Keywords Dynamic typing, static typing, \ntype equality, coercions, quanti.ed types, Leibnitz rule, Haskell, typed interpreters. Permission to \nmake digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 02, October \n4-6, 2002, Pittsburgh, Pennsylvania, USA. Copyright 2002 ACM 1-58113-487-8/02/0010 ...$5.00 1 Introduction \nFor a statically typed programming language the typing rules are checked at compile-time. Type violations \nare reported before pro\u00adgram execution, and ef.cient object code can be generated since no type consistency \nchecks have to be performed at run-time. Even when using statically typed languages however, the need \narises to deal with values with types that cannot be determined at compile\u00adtime. This situation occurs \nfor example in a program that interprets a (meta)language term, resulting in an object language value \nof a type that depends on the speci.c term at hand. An example of such an interpretation function is \neval which takes a string, parses it into an expression and returns the value of that expression. Other \nexam\u00adples where type information is not available until run-time are dis\u00adtributed programs, that exchange \ndata between different processes, and programs that store a value of an arbitrary type in, and retrieve \nit from stable storage. There exist several proposals[1, 2, 8] for dealing with such dynam\u00adically typed \nvalues in a statically typed language. These are all based on a similar idea: extend the language with \na universal type dynamic, and embed dynamic values in that type. This new type actually is a pair consisting \nof the value itself, together with a repre\u00adsentation of the type of that value. Before using a dynamic \nvalue its type component is inspected using a typecase or similar construct. The proposals differ in \ntheir capability to deal with polymorphic dy\u00adnamic values. In [1] dynamic polymorphism is forbidden, \nfor [8] a restricted form of dynamic polymorphism is allowed and the system described in [2] allows polymorphic \nvalues with little restrictions, and as to be expected is also the most complex one. The latest re\u00adlease \nof Clean[12] implements support for dynamic typing[11] by providing a typecase construct and allowing \npolymorphic dynamic values. A drawback noted by Shields et al. [13] is that types live in two different \nworlds, with explicit conversions between these two worlds; he views dynamic typing as staged type inference. \nSome program expressions thus have their type inference deferred until enough information is available \nat run-time. Despite ongoing research on dynamic typing, many statically typed languages such as Haskell[9] \n do not have built-in support for dynamic typing. A programmer thus must encode the dynamic type tagging \nand type checks explicitly. If the set of types is .nite and known at compile-time, one may decide to \nembed values in a user\u00adde.ned data type, and subsequently inspect the types of a values using case-analysis. \nWith this approach, however, programs are dif.cult to maintain and become verbose and messy because type\u00adchecking \ncode is intertwined with normal code.  To alleviate this problem the distributions of both Hugs and \nGHC provide a dynamic typing library. This library provides a univer\u00adsal representation Dynamic for dynamically \ntyped values. Further\u00admore it provides a function toDyn that injects a value of arbitrary type into a \ndynamically typed value and a function fromDyn that converts a dynamic value into a concrete (monomorphic) \ntype. Al\u00adthough this library cannot deal with polymorphic dynamic values, it has proven to be quite useful \nin practice. It provides a cheap way to program with dynamically typed values in Haskell. The implemen\u00adtation \nof this library is fairly simple and is based on the function unsafeCoerce which has type (.ab.a . b). \nAs the name suggests this function is not type-safe, a direct consequence of the fact that safe functions \nof type (.ab.a . b)cannot exist at all. In this paper we develop a statically typable library that provides \na form of dynamic typing, that is as powerful as Haskell s Dynamic library, but does not make use of \nunsafe functions or compiler ex\u00adtensions. The attractive aspect of this approach is that we dot not extend \nthe language itself, nor its implementation. Thus the tech\u00adnique can be universally applied, provided \nthe type system of the host language is powerful enough to type our library, as is the case for Haskell \nwith its common extensions for existentially and univer\u00adsally quanti.ed types and constructors. This \npaper is organized as follows: Section 2 introduces the con\u00adcepts of dynamic typing. In Section 3 a data \ntype is developed that serves as a witness of a proof that two types are equal. Section 4 de.nes a set \nof proof combinators to easily construct inhabitants of this data type. A key ingredient for dynamic \ntyping are run-time type tags, and thus in Section 5 a class of type representations is introduced and \na typical instance of this class is given. In Section 6 an interpreter for expression terms is described \nas an application of the techniques developed in this paper. Section 7 concludes. 2 Dynamic Typing Similar \nto Haskell s dynamic library and other approaches to dy\u00adnamic typing we take the data type Dynamic to \nbe a pair of a value together with the representation of its type. Suppose we have a type typeRep that \nis used to represent types; then the question arises how we can convince the type checker of our core \nlanguage (in our case Haskell), that a value of type typeRep corresponds to a speci.c Haskell type; i.e. \nhow can we label such a type representation with the type it represents. The answer lies in using a type \nconstructor in\u00adstead of a simple type, i.e. by passing the label type as an argument to the representation \nof the type. A dynamic value can be viewed as a box containing a value of some type and the representation \nof that type. Since we do not yet want to .x the type we use for representing types, we postpone this \ndecision by making this typeRep a parameter of the data type Dynamic. The actual type of the value injected \nin a Dynamic is hidden by existen\u00adtially quantifying1 over its type. Note that ::: is an in.x constructor \nfunction with two arguments, namely an a and a typeRep a. data Dynamic typeRep =.a.a ::: typeRep a Using \nthe ::: constructor a value can be packed as a dynamic, hiding the actual type of the value. 1The implementors \nof the Haskell extensions have chosen to de\u00adnote this existential quanti.er with a forall keyword. In \nthis presen\u00adtation we have taken the liberty to use a somewhat more intuitive notation using the . symbol \n toDynamic :: a . tpr a . Dynamic tpr toDynamic a tpr a =a ::: tpr a A value with an existential type \ncan be unpacked using a case\u00adconstruct. case dynval of a ::: tpr a . ... A skolem constant is introduced \nto serve as a placeholder for the type of a and the label of the type of the type representation tpr. \nUnfortunately, the value a cannot simply be returned, because then the skolem constant representing the \ntype of a would escape, i.e appear in a type outside the scope of the case-expression. We thus need a \npartial function fromDyn that converts a dynamic value into a value with a concrete type: fromDyn :: \ntypeRep a . Dynamic typeRep . Maybe a The function fromDyn takes two arguments, the representation of \nthe expected type and a dynamic value. Dynamic type checking now boils down to comparing the type representation \nof the ex\u00adpected type, say t1 of type tp a and the representation of the dy\u00adnamic value s type, say t2 \nof type tp b, and to make sure that the following equivalence holds: (t1 ~ t2). (a = b), i.e. structural \nequivalence of two type representations implies type equivalence of their labels and vice versa. Since \nthe right to left direction is not used we will focus on the left to right direction of this implication, \ni.e. on (t1 ~ t2). (a = b). The function fromDyn must compare the representations of the expected type \nand the dynamic s type tag. If they are equal then the value stored in the dynamic is returned as a value \nof the expected type. Unfortunately simply returning the value stored in the dynamic will not work: the \ntype of this value is unknown since it is still shielded by the existential quanti.cation. The question \nthus arises how to convince Haskell s type-checker of the fact that a successful comparison implies that \nthe hidden type equals the expected type, and hence is not unknown. 3 Type Equality In this section \nwe develop a data type that serves as evidence for the type-checker that two types are equal. In a .rst \napproach we consider two types equivalent if the .rst can be converted into the second and vice versa, \nas expressed in by the type Equal: type Equal a b =(a . b,b . a) This encoding of type equivalence is \nused among others by Yang[17] and Weirich[16]. Interestingly, this type is the encoding, according the \nCurry-Howard isomorphism of the following de.ni\u00adtion of equivalence on propositions. Note that function \narrows map to implications and pairs to conjunctions. a = b =a . b . b . a The Curry-Howard isomorphism \nconcerns the correspondence be\u00adtween logical formulas and types, in which a logical proof corre\u00adsponds \nto a computational term. The existence of a (non-diverging) term of a certain type implies the existence \nof a proof of the cor\u00adresponding logical formula, and vice versa. Hence the existence of an embedding-projection \npair of type Equal a b can be considered a proof that a and b are equivalent. Unfortunately the above \nsolution fails to enforce that the existence of a value of type Equal a b implies that a and b are truly \nequal, as can be seen in the following example: eqIntBool :: Equal Int Bool eqIntBool =(even, .x .if \nx then 1 else 0) The problem is that arbitrary functions can be chosen as conversion function. So we \nwant to restrict the type Equal in such a way that it is ensured that it can only contain conversion \nfunctions that leave the dynamic value unchanged. This can be achieved by shielding the types a and b \nusing a universally2 quanti.ed type constructor f : newtype Equal a b = Equal (.f .fa .fb) This encoding \nof type equality, in a more implicit way, also serves as a basis for the implementation of a type-safe \ncast in Weirich[16]. Interestingly, the data type Equal is actually the encoding of Leib\u00adnitz law which \nstates that if a and b are identical then they must have identical properties. Leibnitz original de.nition \nreads as fol\u00adlows a =b = .f .fa .fb and can be proven to be equivalent to: a =b = .f .fa .fb The Equal \ndata type encodes true type equality, since the identity function is the only non-diverging conversion \nfunction that can be used as argument of the Equal constructor. As the conversion func\u00adtion has to work \nfor any f , it cannot make assumptions about the structure of f , making it impossible to construct a \nvalue of type fa or to access values of type a that may be stored inside a value of type fa. Hence it \nis impossible for a conversion function to alter the value it takes as argument. Not taking into account \nthe failing functions .and .x .., the identity function is the only function that can be used to construct \na value of type Equal. The existence of a value of type Equal a b now implies that a =b, since the con\u00adversion \nfunction, that converts an a into a b, must be the identity function. In the de.nition of Equal the kinds \nof the type variables a and b can not be determined. Instead of defaulting these kinds to *,as is done \nin Haskell, we assume our language supports polymorphic kinds and assign the following kind to the type \nconstructor Equal: Equal : .k.k .k .* Kind polymorphism would make a language such as Haskell more powerful \nand .exible. Consider, for example, the following type constructors Int, [] and .which have kinds *, \n*.*, and *. *.*respectively. Because of the polymorphic kind the types Equal Int Int, Equal [][]and Equal \n(.)(.)are all valid, whereas Haskell with its defaulting rule only accepts the .rst. 4 Building Equalities \nValues of type Equal a b can be viewed as a proof that the types a and b are equal. This section introduces \na set of proof combinators that can be used to easily construct equality proofs, and thus to create inhabitants \nof the Equal type. We continue by showing that the type Equal implements an equiv\u00ad 2Note that we have \nchosen to write the Haskell keyword forall as a .. alence relation on types. The properties of an equivalence \nrelation, namely re.exivity, transitivity and symmetry, can be encoded as: Re.exivity (a =a): re.ex :: \nEqual a a re.ex = Equal id Transitivity (a =b .b =c .a =c): trans :: Equal a b .Equal b c .Equal a c \ntrans ab bc = case (ab,bc)of (Equal f ,Equal g).Equal (g.f ) The implementation of symmetry (a =b .b \n=a) is based on the following idea. If a and b are equal, we can freely substitute a s in a term by b \ns. Assuming a =b we can derive that b =a by starting with a =a (re.exivity) and applying the substitution \na .b on the .rst a. The question that arises is how to implement such a substitu\u00adtion. Recall that a \n=b is encoded by a transform function of type .f .fa .fb. It substitutes the argument a of a type constructor \nby b. In order to do a substitution on the a s in a type t, we .rst in\u00adtroduce a type constructor c, \nthat is the abstraction of t over the a s we wish to substitute. The type t is equivalent to ca, applying \nthe transformation function yields a result of type cb, which is the type t with the a s substituted \nby b s. For example we wish to apply the substitution a .b on the type (a, a). This type is equivalent \nto the application (.x.(x,x))a. Applying the transform function yields a result of type (.x.(x,x))b, \nwhich can than be reduced to (b,b) In Haskell lambda abstraction on type level can be mimicked using \ndata types. The data type corresponding to the tuple example above is: newtype Pair x = Pair{unPair :: \n(x,x)} A value of type (a,a) can be tagged with the Pair constructor to view its type as the application \nPair a. After applying the transfor\u00admation function, the reduction of the type Pair b to (b, b)is done \nby untagging the value. The function substPair is the implementation of the substitution a . .b on the \ntype (a,a)It uses the function subst, that takes care of the tagging and untagging and performs the actual \nsubstitution by applying the transformation function ab. subst :: (ta .ca) . (cb .tb) . Equal a b . \nta  . tb subst from to (Equal ab)= to.ab.from substPair :: Equal a b .(a, a).(b,b) substPair = subst \nPair unPair We will use the term type combinator for type constructors such as Pair. A type combinator \nconstructs a type (in this case (a,a)) from its components(in this case a). The last argument of a type \ncombinator is the target of the substitution. The others (if any) are unaffected by the substitution. \nConsider for example the type combinator Middle, which combines three component types into a triple: \nnewtype Middlexyz = Middle{unMiddle :: (x,z, y)} substMiddle :: Equal a b .(x,a, y).(x,b,y) substMiddle \n= subst Middle unMiddle As the middle component of the triple(z) is the last argument of the type combinator \nit is the target of the substitution, whereas the .rst and the third component are unaffected. Any substitution \ncan be expressed using the function subst and the appropriate type combi\u00adnator. Finally we have all the \ningredients to implement the symmetry property for the Equal type. The idea is that Equal b a can be \nde\u00adrived from Equal a b and re.exivity (Equal a a) by applying the substitution a Firstly we de.ne a \n.b to the .rst a in Equal a a. type combinator FlipEqual to allow a substitution on the .rst argu\u00adment \nof the Equal type constructor: newtype FlipEqual y x = Flip{unFlip :: Equal x y} The type variable x \nrepresents the target of the substitution since it is the last argument of FlipEqual. The symmetry property \ncan now straightforwardly expressed: Symmetry (a =b .b =a): symm :: Equal a b .Equal b a symm ab =(subst \nFlip unFlip ab) re.ex The functions re.ex, trans, and symm are proof combinators, they implement proof \nrules, and construct proofs out of other proofs. In the remainder of this section we extend our library \nof proof combi\u00adnators with other rules. Substitutions play a key role in the imple\u00admentation of these \nrules. We proceed by introducing the following rule: a =b ARG : fa =fb This rule is implemented by the \nfunction arg, which has the follow\u00ading type: arg :: Equal a b .Equal (fa)(fb) Notice that Equal (fa)(fb) \nis encoded as a function with the fol\u00adlowing type (.g.g (fa) .g (fb)). Thus the function arg can be implemented \nas a substitution on the a in the type g (fa). The type combinator, that is required for this substitution, \nis the following: newtype Compgf x = Comp{unComp :: g (fx)} Using this type combinator, the function \narg is now de.ned as: arg ab = Equal (subst Comp unComp ab) A very useful proof combinator derived from \narg is rewrite.It can be used to apply a substitution to the argument of a type con\u00adstructor. For example \nif we have two proofs x :: Equal a Int and list ::Equal b [a] then we can construct a proof of type Equal \nb [Int] as follows: rewrite x list. rewrite :: Equal a b . Equal c (fa) . Equal c (fb)  rewrite a bc \nfa = let fa fb = arga b in trans c fa fa fb The function rewrite can only apply a substitution to the \nlast argu\u00adment of a type constructor, such as the argument of the list type constructor or the result \npart of the function arrow. We now formu\u00adlate the corresponding rule for the function part: f =g FUNC \n: fa =ga The type of the function implementing this rule is: func :: Equal f g .Equal (fa)(ga) Note that \na value of type Equal (fa)(ga) is represented as a func\u00adtion with the following type: .h.h (fa) .h (ga). \nHence a substi\u00adtution must be applied on the f in the type h (fa). This substitution is again implemented \nusing the function subst and an appropriate type combinator. newtype Haf haf = Haf {unHaf :: h (fa)} \nfunc x = Equal (subst Haf unHaf x) Using func, it is easy to de.ne a rewrite function that applies a \nsubstitution the one but last argument of a type constructor: rewrite' :: Equal a b . Equal c (fad) . \nEqual c (fbd) rewrite' xy = trans y (func (arg x)) A rewrite function for the n but last argument of \na type construc\u00adtor can be obtained by applying func n times, as expressed in the following generic de.nition: \nrewriten xy = trans y (fun n (arg x)) For example the rewrite function for the two but last argument \nis obtained by applying func twice: rewrite2 :: Equal a b . Equal c (fade) . Equal c (fbde) rewrite2 \nxy = trans y (func (func (arg x))) Unfortunately, Haskell does not support polymorphic kinds, mak\u00ading \nthe type of func invalid. Hence the generic solution for type constructors of different arities cannot \nbe given, and instead, we must give specialized de.nitions for type constructors of different kinds. \nFor example the function rewrite' for type constructors of kind *.*.*can be de.ned as follows. Firstly, \nwe need a version of the type Equal specialized for type constructors of kind *.*: data Equal' fg = Equal' \n(.h.hf .hg) | KindInfo (f ()) (g ()) In order to prevent Haskell s kind inferencer to default the kind \nof f and g to *, a dummy alternative3 is provided, in order to force the inferencer to infer *.*instead. \nIn a similar way the composition type constructor is specialized, the dummy alternative enforces that \ng has kind *.*.*: data Comp' fgx = Comp'{unComp':: f (gx)}| KindInfo2 (g () ()) 3The latest release of \nGHC supports kind annotations. These provide a more elegant solution for assigning an explicit kind to \na type variable, than the use of dummy constructors. Using these specialized data types , specialized \nversions of the func\u00adtions arg and func can be de.ned in a similar way as before: ' arg :: Equal a b \n. Equal ' (fa)(fb) ' arg ab = Equal ' (subst Comp ' unComp ' ab) subst ' :: (ta . ca) . (cb . tb) . \nEqual ' ab . ta  . tb subst ' from to (Equal ' ab)= to.ab.from func ' :: Equal ' fg . Equal (fa)(ga) \nfunc ' fg = Equal (subst ' Haf unHaf fg) Finally, a valid de.nition for rewrite ' can be given: rewrite \n' :: Equal b d . Equal a (fbc) . Equal a (fdc) '  rewrite ' ab = trans b (func ' (arg a)) Fortunately, \nspecializations for more complex kinds are not re\u00adquired, as they are not used in the remainder of this \npaper. Using the combinators de.ned above, the law of congruence for a binary functor: a = b, c = d CONGRUENCE \n: fac = fbd can be de.ned as follows: congruence :: Equal a b . Equal c d . Equal (fac)(fbd) congruence \nab cd = rewrite cd (rewrite ' ab re.ex) Equivalence proofs can be constructed easily using the proof \ncom\u00adbinators de.ned thus far. Consider for example the following proposition and its proof: x = a . b,y \n= c . d, a = c,b = d . x = y 1 x = a . b (assumption) 2 y = c . d (assumption) 3 a = c (assumption) 4 \nb = d (assumption) 5 a . b = c . d (congruence: 3, 4) 6 c . d = y (symmetry: 2) 7 x = c . d (transitivity: \n1,5) 8 x = y (transitivity: 7,6) This proof is easily encoded using proof combinators as follows: deduce \n:: Equal x (a . b) . Equal y (c . d) . Equal a c . Equal b d . Equal x y  deduce x1 x2 x3 x4 = let \nx5 =congruence x3 x4 x6 =symm x2 x7 =trans x1 x5 x8 =trans x7 x6 in x8 5 Type Representations Thus \nfar, we have de.ned an encoding of type equivalence proofs and a set of combinators to construct such \nproofs. Since we do not want to .x the type used for type representations, we introduce the class TypeDescr, \nthat only contains the function (~)that is used for checking whether a type representation tpr a represents \nthe same type as a type representation tpr b. The Maybe data type is used to distinguish between a successful \ncomparison, in which case a witness of type Equal a b is returned, and an unsuccessful one, in which \ncase Nothing is returned. data Maybe a = Just a | Nothing class TypeRep tpr where (~):: tpr a . tpr \nb . Maybe (Equal a b) We continue by de.ning the function coerce for the Equal type, using the function \nsubst and the identity type constructor: newtype Id x = Id{unId :: x} coerce :: Equal a b . (a . b) coerce \nab = subst Id unId ab Using the operator (~)the function fromDyn, that converts a dy\u00adnamic into a normal \nvalue, can now easily be expressed: fromDyn :: TypeRep tpr . tpr a . Dynamic tpr . Maybe a fromDyn et \n(x ::: t)= case t ~ et of Just eq . Just (coerce eq x) Nothing . Nothing The function fromDyn checks \nwhether the expected type et matches the type of the value stored in its second argument. If this is \nthe case the stored value is converted , using the constructed evidence eq, into the expected type and \nreturned. Note that the only way in which this conversion can be done, is by applying the conversion \nfunction returned by the call of (~)in case the types match. We continue by de.ning a data type TpCon \nthat represents type constants, such as Int and Bool. The constructors Int and Bool, take a proof that \nthe type-label a equals the type Int respectively Bool: data TpCon a = Int (Equal a Int) | Bool (Equal \na Bool) Since we want to be able to compare such types we make it an in\u00adstance of TypeRep. The function \n(~)checks whether both its argu\u00adments are structurally equivalent and if this is the case constructs \na proof that both arguments are of the same type using the transitivity and symmetry combinators. instance \nTypeRep TpCon where (~)(Int x)(Int y)= Just (trans x (symm y)) (~)(Bool x)(Bool y)= Just (trans x (symm \ny)) (~) = Nothing Smart constructors for the type representations of the types Int and Bool are de.ned \nas inttp and booltp: inttp :: TpCon Int inttp = Int re.ex booltp :: TpCon Bool booltp = Bool re.ex Using \nthese we can easily inject values of type Int and Bool together with their type representations into \na Dynamic. true = True ::: booltp ninetythree = 93 ::: inttp Now the operation fromDyn can be used to \ntry to convert dynamic values into a concrete type. For example: fromDyn booltp true re\u00adsults in Just \nTrue and fromDyn booltp ninetythree will fail. Since we now not only want to deal with constant types \nwe intro\u00adduce a new type TpRep that extends the type representation with alternatives for list and function \ntypes, containing the representa\u00adtions of the constituting types: data TpRep tpr a = TpCon (tpr a) |.x.List \n(Equal a [x]) (TpRep tpr x) |.xy.Func (Equal a (x .y)) (TpRep tpr x) (TpRep tpr y) For the new type \ndescriptor TpRep the smart constructors of the representations of Int and Bool need to be rede.ned: type \nType = TpRep TpCon inttp :: Type Int inttp = TpCon (Int re.ex) booltp :: Type Bool booltp = TpCon (Bool \nre.ex) The smart constructor list for list types takes as an argument the representation of the component \ntype: list :: TpRep tpr a .TpRep tpr [a] list tpr a = List re.ex tpr a For function types the right-associative \noperator ... is de.ned, that constructs a function type representation out of its argument and result \ntype representation. (...) :: TpRep tpr a .TpRep tpr b .TpRep tpr (a .b) a ... r = Func re.ex a r The \nsmart constructors provide a convenient notation for construct\u00ading type representations; for example \nthe representation for [Int]. Bool can be expressed as follows: list inttp ... booltp. By now making \nTpRep an instance of the class TypeDescr it be\u00adcomes possible to cast function types and list types. \nIn order to match two type constants the function (~)on the underlying repre\u00adsentation of type constants \nis called. instance TypeRep tpr .TypeRep (TpRep tpr)where (~)(TpCon x)(TpCon y)= x ~y For list types \nthe component types are compared, resulting in an equivalence proof of both component types if the comparison \nsuc\u00adceeds. This proof is subsequently used to construct the proof that both list types match. (~)(List \nx t1)(List y t2)= case t1 ~t2 of Just eq .Just (trans (rewrite eq x)(symm y)) Nothing .Nothing The de.nition \nof (~) on two function types is quite straight\u00adforward: if we can prove that their argument types are \nequal and we can prove that their result types are equal then we may deduce that both function types \nare equal. (~)(Func x a1 r1)(Funcya2r2)= case (a1 ~a2,r1 ~r2)of (Just arg,Just res).Just (deduce x y \narg res) .Nothing Finally, if the type representations do not match then no equivalence proof can be \nconstructed, hence Nothing is returned. (~) = Nothing A function value can be cast into a dynamic value, \nand later on be down-cast to a value of its original type. During a down-cast a type\u00adcheck is performed \nonce, and afterwards we can use the function many times without again paying for type-checking. Consider \nfor example the function plus and the value one, resulting from an up\u00adcast of the operator (+)and the \ninteger 1, respectively: plus :: Dynamic Type plus =(+)::: inttp ... inttp ... inttp one :: Dynamic Type \none = 1 ::: inttp Two values can be applied, if the .rst one has a function type and the type of other \nmatches the argument type of the function: dynApply :: TypeRep tp . Dynamic (TpRep tp) . Dynamic (TpRep \ntp)  .Maybe (Dynamic (TpRep tp)) dynApply (f ::: ft)=case ft of Func eqf arg res . ' let f =coerce \neqf f in.(x ::: xt).case xt ~arg of ' Just eqa .let x =coerce eqa x '' in Just (fx ::: res) Nothing .Nothing \n .const Nothing --not a function type The value inc is the result of the application of plus to one: \ninc :: Dynamic Type inc = case dynApply plus one of Just v .v The value inc contains the function ((+)1)together \nwith a descrip\u00adtion of its type, which is (Int .Int). The function increment is the result of a down-cast \nof inc. After the down-cast we end up with a function that adds 1 to a number without performing the \ntype-check again. increment :: Int .Int increment = case fromDyn (inttp ... inttp)inc of Just f .f We \nwant to stress once more that inside the expressions that are constructed there initially live many applications \nof identity func\u00adtions to values. When our function is evaluated for the .rst time, all such applications \nof identities will be removed, and the over\u00adhead resulting from type checking the expression when building \nit is gone. 6 Interpreting Expressions In this section we show how to use the machinery from the previous \nsection in constructing ef.cient typed evaluators. We do so in the context of a syntax macro mechanism, \nin which an already existing parser for some language is dynamically extended to recognize and process \na larger language. A lot of research has been done on syntax macros and related topics[7, 10, 3, 14]. \nOur notation for syntax macros is borrowed from Cardelli et al.[3]. A syntax macro enabled compiler .rst \nreads a set of macro de.\u00adnitions and after having processed them successfully reads the actual program \nin the extended language. The semantics associated with the new language constructs is expressed in terms \nof expres\u00adsions of a base language, and are in our case built from constructors describing the abstract \nsyntax of the base language. Since these de.nitions are parsed, processed and evaluated by the existing \ncompiler we want to make sure that after successfully pro\u00adcessing the macro de.nitions, we do not pay \n(much) more than when we had added the processing of the new constructs directly to the existing compiler. \nFurthermore we want to make sure that the compiler, after having successfully processed the macro de.ni\u00adtions, \ndoes not break down due to a typing error when processing the actual program. As an example we take a \nvery simple language with the following abstract syntax: data Exp = Add Exp Exp | Sub Exp Exp | IntLit \nInt A set of syntax macros that de.nes a concrete syntax for this lan\u00adguage typically looks as follows: \nExpr, Factor :: Exp FactIter :: Exp -> Exp Oper :: Exp -> Exp -> Exp Expr ::= x=Factor fs=FactIter \n=> fs x | x=Factor => x FactIter ::= op=Oper y=Factor fs=FactIter => \\x:Exp . fs (op x y) | => \\x:Exp \n. x Oper ::= \"+\" => Add | \"-\" => Sub Factor ::= x=IntLiteral => IntLit x The macros start with the \ndeclaration of the types of new concrete nonterminals that are introduced by the macros. The constants \nin this type language are the nonterminals from the abstract syntax. The declarations are followed by \na list of production rules. The part of a production rule left of the arrow resembles a BNF production \nand de.nes the concrete syntax of the language. The right-hand side of a production rule de.nes a mapping \nto the abstract syntax of the core language. The parser constructed for the above macros recognizes expressions \ncontaining left associative +, -operators and integer literals, and constructs a parse tree of type Exp. \nOur syntax macro system constructs parsers at run-time using self\u00adoptimizing parser combinators[15] and \ncalls this parser directly on a source .le. It is not necessary to generate parse-tables off-line to \nimprove ef.ciency as is common in most other implementations. The idea behind combinator parsers is that \na parser is a function that consumes a list of symbols and produces an abstract syntax tree of some type. \nThe problem that we have to deal with now is that parsers must be well-typed just as any other function. \nThus the macro system interprets a macro and has to construct a well\u00adtyped parser. In order to achieve \nthis, run-time type-checking is re\u00adquired. Using the type-checking approach introduced before, well\u00adtyped \nparsers can be constructed in such a way that the cost of type\u00adchecking is paid for only once. To illustrate \nthe use of run-time type-checking during interpreta\u00adtion of the macros we show how the interpretation \nof the right-hand sides of the macro is done. The abstract syntax of the expressions at the right-hand \nside of a production rule is de.ned by the following data type: type Ident = String data Expression = \nVar Ident | Apply Expression Expression | Const (Dynamic Type) |.x.Lambda Ident (Type x) Expression |.x.Let \nIdent (Type x) Expression Expression Underlying the type checking is the concept of type judgments: G \n.expr : t We read this as follows: under the assumptions about the types of the variables in G, the expression \nexpr is well typed and has type t. The typing rule for constant values, like 3 and True, is trivial. \nIt states that a constant of type tp has type tp: CONSTANT : G .ctp : tp Typing an expression consisting \nof a single identi.er is described by: (id : t) .G IDENT : G .id : t The rule for function application \nis: G .expr1 : a .r,G .expr2 : a APPLY : G .expr1 expr2 : r The rule for lambda abstraction is: (G -id) \n.{id : a}.expr : b LAMBDA : G .(.id:a . expr) : a .b Finally, the rule for let expressions is: (G -id) \n.{id : a}.expr1 : a,(G -id) .{id : a}.expr2 : b LET : G .(let id:a = expr1 in expr2) : b In our compiler \nwe distinguish a compile-time and a run-time en\u00advironment. The compile-time environment is used during \ntype\u00adchecking and compilation, it is a symbol table containing the type and the location in the run-time \nenvironment for each variable. The run-time environment is used during evaluation of an expression and \ncontains the actual values for the variables in the expression. Nested pairs are a very suitable data \nstructure for the run-time en\u00advironment. They can store heterogenous data, which is important because \nthe variables in an expression may have different types. Further more selector functions to access each \nvalue can easily be constructed using the function fst and snd. Consider for example an environment containing \nthe values True, 3, and a : (True,(3, a )) The selector functions for the .rst, second and third value \nare re\u00adspectively fst, fst.snd, and snd.snd. Compiled expressions need a run-time environment to provide \nval\u00adues for their variables. Hence a compiled expression is represented as a function of type (env . \na), that computes the value of the expression of type a, given an environment of type env, contain\u00ading \na valuation for its variables. As the result type of a compiled expression is dynamic, the function representing \nthe expression is wrapped as a dynamic value. The data type DynamicF is a generalization of Dynamic. \ndata DynamicF tpr f = .x.fx :::: tpr x The functions for converting dynamic values into normal values \ncan be de.ned for the type DynamicF in a similar way as done for the type Dynamic: coerceF :: Equal a \nb . fa . fb coerceF (Equal eq)= eq fromDynF :: TypeRep tpr . tpr a . DynamicF tpr f . Maybe (fa)  \nfromDynF e (x :::: t)= case t ~ e of Just eq . Just (coerceF eq x) Nothing . Nothing The type of compiled \nexpressions is de.ned by parametrizing DynamicF with the type constructor ((.) env): type CompExp env \n= DynamicF Type ((.) env) The compile-time environment is a symbol table storing for each variable its \ntype and a the location of the variable at run-time. The type of an identi.er is encoded as a type representation \nof type Type t, and the location as a selector function of type (env . t). The identi.er information \nconsisting of a type representation and a selector function are packed as a dynamic value: type IdentInfo \nenv = DynamicF Type ((.) env) The type of the symbol table is de.ned as: type SymTable env =[(Ident,IdentInfo \nenv)] Each time a declaration of variable is introduced, a new entry with the type and selector function \nof the variable must be added to the symbol table. Futhermore, the type of the run-time environment has \nto change, since it has to store a value for the new identi.er. The function add takes a pair of an identi.er \nand the representation of its type and extends the environment with this new identi.er. add :: (Ident,Type \na) . SymTable env . SymTable (a,env)  add (x,tp) gamma =(x, fst :::: tp) : map f gamma where f (ident,get \n:::: t)=(ident,(get.snd) :::: t) In order to hold a value of type a for the new identi.er, the type of \nthe run-time environment is changed to a pair of a value of type a and the old environment. The selector \nfunction for the new identi\u00ad.er is obviously the function fst. As the type of the run-time envi\u00adronment \nchanged from env to (a,env), the selector functions for the other identi.ers must be composed with snd. \nWe proceed by developing a compiler for the simple expression language de.ned above. As the structure \nof the compiler function closely follows the typing rules, we choose it to resemble the type judgement \noperator: (|-) :: SymTable env . Expression . Maybe (CompExp env) This operator takes an environment \nand an expression as arguments; if all variables occurring in the expressions are introduced in the environment \nand there are no type errors then the compilation suc\u00adceeds and returns the value of the expression as \na compiled expres\u00adsion. The monadic do notation is used in the de.nition of (|-) to deal with the Maybe \ntype. It avoids cluttering the code with pat\u00adtern matches on Nothing and Just and makes the resemblance \nof the implementation to the typing rules more clear. The de.nition of the compile operator for constants \nis straightfor\u00adward. No environment is needed to evaluate a constant, so the en\u00advironment is discarded \nby the function const and the value of the constant is returned. gamma |- Const (c ::: tp)= return (const \nc :::: tp) The interpretation of function applications closely follows the cor\u00adresponding typing rule. \nThe .rst three lines of the do statement correspond to the three assumptions in the typing rule, whereas \nthe last line builds the conclusion. The coerce functions funEQ and argEQ are applied in order to convince \nthe type-checker that e1 is a function and the type of e2 matches the argument type of this func\u00adtion. \nIn the resulting expression the environment env is passed to both expressions. gamma |- Apply expr1 expr2 \n= do e1 ::::Func funEQ a r . gamma |- expr1 e2 :::: b . gamma |- expr2 argEQ . b ~ a let e1 ' = coerceF \nfunEQ e1 e2 ' = coerceF argEQ e2 return ((.env . e1 ' env (e2 ' env)) :::: r) For the interpretation \nof variables, the identi.er is located in the environment gamma, yielding the representation of its type \nand a function that selects its value from the run-time environment: gamma |- Var x = do var :::: tp \n. lookup x gamma return (var :::: tp) The interpretation operation for lambda-abstractions adds the iden\u00adti.er \nwith its type to the symbol table and uses the extended symbol table to compile the body of the lambda. \nAt run-time the value for the identi.er is placed into the run-time environment, which is sub\u00adsequently \nused to compute the value of the body. gamma |- Lambda x tp expr = do e :::: etp . add (x,tp) gamma |- \nexpr let mkLam env = .x . e (x,env) return (mkLam :::: tp ... etp) The compilation of a let expression \nproceeds in a similar way. Dur\u00ading compilation the symbol table is extended with the identi.er and type \nof the declaration. This symbol table is than used to compile both the declaration and the body. At run-time \nthe value of the dec\u00adlaration is put into the environment, which is used to evaluate both the declaration \nand the body of the let expression. gamma |- Let x tp expr1 expr2 = ' do let gamma = add (x,tp) gamma \ne1 :::: tp1 . gamma ' |- expr1 e2 :::: tp2 . gamma ' |- expr2 eq . tp1 ~ tp let mkLet env = let env ' \n=(decl,env) decl = coerceF eq e1 env ' in e2 env ' return (mkLet :::: tp2) Using the compiling operator \nwe can compile expression terms into their values: compile :: Expression . Type a . Maybe a compile expr \nt = do res . [] |-expr val . fromDynF t res return (val ()) The function compile takes an expression \nterm and starts with the empty environment ([]). If the resulting value matches the expected type an \nempty run-time () environment is supplied, and the value of the expression is returned. As a .nal example \nnow consider the expression corresponding to the lambda-term .x :: Int..y :: Int . x + y: expr :: Expression \nexpr =(Lambda \"x\" inttp (Lambda \"y\" inttp (Apply (Apply (Const plus) (Var \"x\") ) (Var \"y\") ) ) ) This \nterm is compiled into a function with type Int . Int . Int as follows: test :: Int . Int . Int test = \ncase compile expr (inttp ... inttp ... inttp) of Nothing . error \"type error in expression\" Just x . \nx The function test can now be applied to add two integers, without any further type checking being involved! \nThe expression compiler can also deal with recursive de.nitions as illustrated by the following example. \nConsider the following expression containing a recursive de.nition. let ones = 1: ones in ones This expression \nis encoded as a term (expr2) of type Expression, using the helper functions cons and int to wrap the \noperator (:) and the integer value, respectively. cons :: Type t . Expression cons t = Const ((:) ::: \nt ... list t ... list t) int :: Int . Expression int x = Const (x ::: inttp) expr2 :: Expression expr2 \n= Let \"ones\" (list inttp) (Apply (Apply (cons inttp)(int 1)) (Var \"ones\") ) (Var \"ones\") The expression \nexpr2 can be compiled to a Haskell value of type [Int] as follows: test2 :: [Int] test2 = case compile \nexpr2 (list inttp) of Nothing . error \"type error in expression\" Just x . x 7 Conclusions We have shown \nthat extending a language with a separate dynamic typing mechanism is not needed, provided the core language \nis suf.ciently rich. The techniques presented here can easily be in\u00adcorporated within a small module. \nOur solution does not require large compiler modi.cations or ad hoc language extensions such as unsafeCoerce. \nThe presented approach is type safe and as power\u00adful as Haskell s dynamic typing library. In contrast \nto some of the other approaches to dynamic typing, our library does not support polymorphic dynamic values. \nWhether our approach can easily be extended with dynamic polymorphism is as yet unknown and a sub\u00adject \nof further research. In order to use the dynamic typing library an instance of the class of type representations \nmust be provided. The code for these instances is completely generic and can be easily generated by a \nspecial tool; or by an extended version of the Generic Haskell compiler [4, 5]. Another solution is to \nlet the compiler construct the type represen\u00adtations as an abstract data type. This opens the way for \ndynamic linking and re.ection, e.g. by exporting from each module its envi\u00adronment in the form of a function \nof the type: environment :: FiniteMap String Dynamic In this way run-time access to the module s interface \n(.hi-.le) is obtained. Occurrences of global variables in the expression terms that are compiled by the \nexpression interpreter developed in the pre\u00advious section could in that case be linked to the corresponding \nfunc\u00adtions in the environment. We have introduced a data type Equal to represent genuine type equality. \nIt .nds its theoretical basis in Leibnitz de.nition of equal\u00adity and the Curry-Howard isomorphism. We \nhave developed a small library of proof combinators to constructs of the Equal type. Values of the type \nEqual are represented by identity functions. By com\u00adbining these with function application or composition, \nthe proof combinators construct new values of the Equal type. The proof combinators correspond to proof \nrules and make up a small proof system. A dynamic value is cast to a concrete type by comparing the type \nof the dynamic value with the expected type, resulting in a proof that they are equal if they are. This \nproof is a composition of identity functions. The identity functions are applied to the dynamic value, \ncoercing it to a value of the expected type. After the dynamic type checking overhead has been computed \nonce, the resulting value is free of typing overhead and can subsequently be used just as a nor\u00admal value. \n References [1] Mart\u00b4in Abadi, Luca Cardelli, Benjamin Pierce, and Gor\u00addon Plotkin. Dynamic typing in \na statically typed language. ACM Transactions on Programming Languages and Systems, 13(2):237 268, April \n1991. [2] Mart\u00b4in Abadi, Luca Cardelli, Benjamin Pierce, and Didier R\u00b4emy. Dynamic typing in polymorphic \nlanguages. Journal of Functional Programming, 5(1):111 130, January 1995. Sum\u00admary in ACM SIGPLAN Workshop \non ML and its Applica\u00adtions, June 1992. [3] Luca Cardelli, Florian Matthes, and Mart\u00b4in Abadi. Extensible \nsyntax with lexical scoping. Technical Report 121, Digital Systems Research Center, 1994. [4] Dave Clarke, \nRalf Hinze, Johan Jeuring, Andres L\u00a8oh, and Jan de Wit. The Generic Haskell user s guide. Technical Report \nUU-CS-2001-26, Institute of Information and Computing Sci\u00adences, Utrecht University, 2001. [5] Dave Clarke \nand Andres L\u00a8oh. Generic Haskell, speci.cally. In IFIP WG2.1 Working Conference on Generic Program\u00adming, \n2002. [6] Fritz Henglein. Dynamic typing: syntax and proof theory. Sci\u00adence of Computer Programming, \n22(3):197 230, June 1994. Selected papers of the Fourth European Symposium on Pro\u00adgramming (Rennes, 1992). \n[7] B. M. Leavenworth. Syntax macros and extended translation. CACM, 9(11):790 793, 1966. [8] Xavier \nLeroy and Michael Mauny. Dynamics in ML. In J. Hughes, editor, Functional Programming Languages and Computer \nArchitecture, 5th ACM Conference, volume 523, pages 406 426, Berlin, Heidelberg, New York, 1991. Springer-Verlag. \n[9] Simon Peyton-Jones, John Hughes, and (eds). Re\u00ad port on the programming language Haskell 98. http://www.haskell.org/report, \nFebruary 1998. [10] Simon L. Peyton Jones. Parsing dist.x operators. CACM, 29:118 122, 1986. [11] Marco \nPil. Dynamic types and type dependent functions. In Implementation of Functional Languages, 10th International \nWorkshop, IFL 98, volume 1595 of Lecture Notes in Com\u00adputer Science, pages 169 185. Springer, 1999. [12] \nRinus Plasmeijer and Marco van Eekelen. Clean language report version 2.0. http://www.cs.kun.nl/ clean/, \n2002. [13] Mark Shields, Tim Sheard, and Simon L. Peyton Jones. Dy\u00adnamic typing as staged type inference. \nIn Symposium on Prin\u00adciples of Programming Languages, pages 289 302, 1998. [14] Guy L. Steele Jr. Growing \na language. Journal of Higher-Order and Symbolic Computation, 12:221 236, 1999. [15] Doaitse Swierstra. \nCombinator parsers: From toys to tools. In Graham Hutton, editor, Electronic Notes in Theoretical Com\u00adputer \nScience, volume 41. Elsevier Science Publishers, 2001. [16] Stephanie Weirich. Type-safe cast. In Proceedings \nof the .fth ACM SIGPLAN international conference on Functional pro\u00adgramming, pages 58 67. ACM Press, \n2000. [17] Zhe Yang. Encoding types in ML-like languages. In Proceed\u00adings of the third ACM SIGPLAN international \nconference on Functional programming, pages 289 300. ACM Press, 1998.  \n\t\t\t", "proc_id": "581478", "abstract": "Even when programming in a statically typed language we every now and then encounter statically untypable values; such values result from interpreting values or from communicating with the outside world. To cope with this problem most languages include some form of <i>dynamic</i> types. It may be that the core language has been explicitly extended with such a type, or that one is allowed to live dangerously by using functions like <i>unsafeCoerce</i>. We show how, by a careful use of existentially and universally quantified types, one may achievem the same effect, without extending the language with new or unsafe features. The techniques explained are universally applicable, provided the core language is expressive enough; this is the case for the common implementations of <b>Haskell</b>. The techniques are used in the description of a type checking compiler that, starting from an expression term, constructs a typed function representing the semantics of that expression. In this function the overhead associated with the type checking is only once being paid for; in this sense we have thus achieved static type checking.", "authors": [{"name": "Arthur I. Baars", "author_profile_id": "81100553141", "affiliation": "Utrecht University, Utrecht, The Netherlands", "person_id": "P394756", "email_address": "", "orcid_id": ""}, {"name": "S. Doaitse Swierstra", "author_profile_id": "81100040645", "affiliation": "Utrecht University, Utrecht, The Netherlands", "person_id": "PP14026122", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/581478.581494", "year": "2002", "article_id": "581494", "conference": "ICFP", "title": "Typing dynamic typing", "url": "http://dl.acm.org/citation.cfm?id=581494"}