{"article_publication_date": "09-17-2002", "fulltext": "\n Compiling Scheme to JVM bytecode: a performance study Bernard Paul Serpette Inria Sophia-Antipolis \n2004 route des Lucioles B.P. 93 F-06902 Sophia-Antipolis, Cedex Bernard.Serpette@sophia.inria.fr http://www.inria.fr/oasis/Bernard.Serpette \n ABSTRACT We have added a Java virtual machine (henceforth JVM) bytecode generator to the optimizing \nScheme-to-C compiler Bigloo. We named thisnew compiler BiglooJVM. We have used this new compiler to evaluate \nhow suitable the JVM bytecode isasa target for compiling strict functional lan\u00adguagessuch asScheme. In \nthispaper, we focuson the perfor\u00admanceissue. Wehavemeasured the execution time of many Scheme programswhen \ncompiled to C and when compiled to JVM. We found that for each benchmark, at least one of our hardware \nplatformsran the BiglooJVM version in less than twice the time taken by the Bigloo version. In order \nto deliver fast programs the generated JVM bytecode must be carefully crafted in order to bene.t from \nthe speedup of just-in-time compilers. Categories and Subject Descriptors D.3.1 [Programming Languages]: \nLanguage Classi.ca\u00adtions applicative (functional) languages;D.3.4 [Program\u00adming Languages]: Processors \ncompilers; I.1.3 [Symbolic and Algebraic Manipulation]: Languages and Systems evaluation strategies \nGeneral Terms Languages, Experimentation, Measurement, Performance  Keywords Functional languages, Scheme, \nCompilation, Java virtual Machine 1. INTRODUCTION Many implementorsof high-level languageshave already \nported their compilersand interpretersto the Java Virtual Machine [21]. According to Tolksdorf s web \npage [34], there are more than 130 compilerstargeting JVM bytecode, for all kinds of languages. In the \ncase of functional languages Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. ICFP 02, October 4-6, 2002, Pittsburgh, Pennsylvania, USA. Copyright 2002 ACM \n1-58113-487-8/02/0010 ...$5.00. Manuel Serrano Inria Sophia-Antipolis 2004 route des Lucioles B.P. 93 \nF-06902 Sophia-Antipolis, Cedex Manuel.Serrano@sophia.inria.fr http://www.inria.fr/mimosa/Manuel.Serrano \n (henceforth FLs), several papers describing such systems have been published (Haskell [36], Scheme [7, \n23, 9], and SML [5]). JVM bytecode isan appealing target because: It ishighly portable. Producing JVM \nbytecode, it is possible to compile once and run everywhere . For in\u00adstance, the BiglooJVM Scheme-to-JVM \ncompiler that ispresented in thispaper isimplemented on Unix but thevery samebootstrapped vers ion als \noruns on Mi\u00adcrosoft Windows.  The standard runtime environment for Java contains a large set of libraries \nand features: widget libraries, database access, network connection, sound libraries, etc. A compiler \nwhich compilesa language to JVM bytecode could make these fancy features available to programswritten \nin that language.  A lot of programming environmentsand toolsare de\u00adsigned for theJVM.Somehave nocounterpart \nfor other languages(especially the onesthat rely on the high-level featuresof Java such asitsautomatic \nmem\u00adory management). Producing JVM bytecode allows these tools to be reused. For instance, we have al\u00adready \ncustomized the Jinsight system [8] for pro.ling Scheme compiled programs.  The JVM isdesigned for hosting \nhigh-level, object\u00adoriented languages. It providesconstructionsand facil\u00adities such as dynamic type testing, \ngarbage collection and subtype polymorphism. These runtime features are also frequently required for \nFLs.  1.1 Performance of JVM executions In spite of the previously quoted advantages, compiling to JVM \n(or to Java)raises an importantis sue: whatabout performance? Is it possible to deliver fast applications \nusing a FL-to-JVM compiler? Current Java implementationsare known not to be very fast and, in addition, \nbecause the JVM isdesigned and tuned for Java, one might wonder whether it ispossible to implement a \ncorrect mapping from a FL to JVM without an important performance penalty. The aim of thispaper isto \nprovide answersto these questions. We have added a new code generator to the existing op\u00adtimizing Scheme-to-C \ncompiler Bigloo. We call thisnew compiler BiglooJVM. Because the only di.erence between Bigloo and BiglooJVM \nis the runtime system, BiglooJVM is a precise tool to evaluate JVM performance. We have used it asa test-bed \nfor benchmarking. We have compared the performance of a wide range of Scheme programswhen com\u00adpiled to \nnative code via C and when compiled to JVM. We have used 21 Scheme benchmarks, implemented by di.er\u00adent \nauthors, in di.erent programming styles, ranging from 18 lineslong programsto 100,000 lineslong programs(see \nAppendix A for a short description). We have tested these programson three architectures(Linux/x86, Solaris/Sparc \nand Digital Unix/Alpha). We have found the ratiosBigloo\u00adJVM/Bigloo quite similar on Linux/x86 and Sparc. \nThis isnot surprising asboth con.gurationsuse the same JVM (HotSpottm 2.0). We have thusdecided not to \npresent the Sparc results in this paper. It would be pointless to measure the performance penalty imposed \nby the JVM if our compiler is a weak one. In order to validate the BiglooJVM compiler we have compared \nit to other compilers. In a .rst step, we have compared it to two other Scheme compilers: i) Kawa [7] \nbecause it is the only other Scheme compiler that producesJVM code and ii) Gambit because it is a popular, \nportable and largely used Scheme-to-C compiler. In a second step, we have compared BiglooJVM to other \ncompilersproducing JVM code: iii) MLj [5] and, iv) Sun sJava compiler. We present these comparisons in \nSection 2. 1.2 The Bigloo and BiglooJVM compilers Bigloo isan optimizing compiler for the Scheme program\u00adming \nlanguage [18]. It compiles modules into C .les. Its runtime library uses the Boehm and Weiser garbage \ncol\u00adlector [6]. Each module consists in a sequence of Scheme de.nitions and top level expressions. After \nreading and expanding a source .le, Bigloo builds an abstract syntax tree (AST) that passes from stage \nto stage. Many stages implement high-level optimizations. That is, optimizations that are hardware independent, \nsuch as source-to-source [27] transformations or data .ow reductions[29]. Other stages implement simpli.cation \nof the AST, such as the one that compiles Scheme closures [25, 30, 26]. Another stage han\u00addlespolymorphism \n[20, 28]. That is, for each variable of the source code, it selects a type that can be polymorphic, i.e., \nthetypedenoting any possible Scheme value, or monomor\u00adphic which can denote the type of primitive hardware \nvalues, such as integers or .oating point double precision.At the C code generation point, the AST isentirely \ntype-annotated and closuresare allocated asdata structures. Producing the C code requires just one additional \ntransformation: the ex\u00adpressions of the AST are turned into C statements. In the BiglooJVM, the bytecode \ngenerator takesthe place of this C statement generator (Figure 1). Reusing all the Bigloo compilation \nstagesisbene.cial for the quality of the produced JVM bytecode and for the sim\u00adplicity of the new resulting \ncompiler. The JVM bytecode only represents 12% of the code of the whole compiler (7,000 linesof Scheme \ncode for the JVM generator to be compared to the 57,700 linesof Scheme code for the whole compiler). \nThe JVM runtime system is only 5,000 lines of Java code which havetobecompared with 30,000linesof Scheme \ncode that are common to both JVM and C back-ends. This can also be compared with 33,000 lines of C code \n(including the Garbage Collector which is23,000 lineslong) of the C run\u00adtime system. The .rst versions \nof BiglooJVM, a mere 2,000 lines of Scheme code, were delivering extremely poor performance applications. \nFor instance, the JVM version of the Cgc Figure 1: The architecture of the Bigloo compiler. benchmark \n(see Appendix A), when ran on a Linux/x86 architecture wasmore than 100 timesslower than the cor\u00adresponding \nC version. Modifying the produced JVM class .les, we have been able to speed up this benchmark and it \nis now only 3 times slower than the C version. Many small problems were responsible for the initial poor \nperformance. For instance, we found that some sequences of JVM instruc\u00adtionsprevent the just-in-time \ncompiler (JIT) from compiling methods. We also found that on some 32-bit architectures, using 64-bit \nintegersisprohibitive. We found that some JIT (Sun HotSpot and others) compilers have a size limit perfunctionabove \nwhichtheystopcompiling. Finally,we found that some JIT compilers refuse to compile functions that include \nfunctional loops, that is, loops that push values on the stack. We present our experience with JVM bytecode \ngeneration in this paper. Most of the presented information is indepen\u00addent of the source language to \nbe compiled so it could be bene.cial to anyone wishing to implement a compiler pro\u00adducing JVM bytecode. \n 1.3 Overview In Section 2 we present the performance evaluation fo\u00adcusing on the di.erence between Bigloo \nand BiglooJVM. In Section 3 we present the speci.c techniques deployed in the BiglooJVM code generator \nand the BiglooJVM runtime system. In Section 4 we present the important tunings we have applied to the \ncode generator and the runtime system to tame the JIT compilers. In Section 5, we compare the BiglooJVM \ncompiler with other systems.  2. PERFORMANCE EVALUATIONS We present in this section the performance \nevaluation of BiglooJVM. In a.rst step, we compareit toBigloo(that isthe C back-end of Bigloo). Then, \nwe compare it with other Scheme implementations. Finally, we compare it with non-Scheme implementationsthat \nproduce JVM bytecode. 2.1 Settings To evaluate performance, we have used two di.erent ar\u00adchitectures: \nLinux/x86: An AMD/Thunderbird 800Mhz, 256MB, running Linux 2.2, Java HotSpottm of the JDK 1.3.0, used \nin client mode. BiglooJVM vs Bigloo (Linux/x86) 1 2 3 4 5 Bague 1.6 Beval 1.4 Bigloo 3.3 Boyer 1.9 Cgc \n3.2 Conform 4.6 Earley 3.0 Fft 2.0 Fib 0.6 Leval 2.0 Maze 3.2 Mbrot 4.1 Nucleic 1.3 Peval 4.3 Puzzle \n1.5 Queens 1.0 Qsort 1.0 Rgc 10.4 Sieve 1.4 Slatex 4.4 2.7 Traverse Figure 2: Scores are relative \nto Bigloo, which is the 1.0 mark. Lower is better. Alpha: An Alpha/21264 500Mhz, 512MB, running Dig\u00adital \nUnix 4.0F, Classic VM version 1.2.2-3. Each program wasran three timesand the minimum sum of cpu + system \ntime, asreported by the Unix times com\u00admand, wascollected. For JVM executions, the bytecode veri.er is \ndisabled (see Section 4.3). In thispaper wepresent ratiosfor which thebasevalue isthe execution time \nof the program when compiled to C by Bigloo. In consequence, when studying a con.guration K,we present \nthe ratio of K/Bigloo. The mark 1 isthe execution time of Bigloo; lower isbetter.  2.2 BiglooJVM vs \nBigloo Figures2 and 3 present the ratio of BiglooJVM/Bigloo for the Linux/x86 and Alpha platforms. The \ne.ciency of JVM executionsvary from one benchmark to another and from one platform to another. However, \nif for each bench\u00admark, we consider the con.guration with the smaller Bigloo\u00adJVM/Bigloo ratio, we found \nthat BiglooJVM measurements fall roughly between once and twice the time taken by Bigloo. The only three \nexceptionsto thisrule are: i) Fib, ii) Bigloo (the bootstrap of the Bigloo compiler) and, iii) Cgc (a \ntoy compiler that producesMipscode for a C-like language). Fib isfaster with the JVM implementation but \ntackling with C compilation options, Bigloo can reach the speed of BiglooJVM. More precisely if we prevent \nthe C compiler from using a register as frame pointer (the gcc -fomit\u00adframe-pointer option) then Bigloo \nperformsaswell asBigloo-JVM. Bigloo and Cgc benchmarksare slower when com\u00adpiled to JVM with a de.cient \nratio of 3.2. It would have been interesting to study the performance of Bigloo on the Al\u00adpha platform, \nunfortunately, the virtual machine crashes for that benchmark because of stack over.ow and we have found \nno mean to extent the stack on this platform. We are cur\u00adrently testing a new version of BiglooJVM that \nreduces the BiglooJVM vs Bigloo (Alpha) 12345 Bague Beval Boyer Cgc Conform Earley Fft Fib Leval Maze \nMbrot Nucleic Peval Puzzle Queens Qsort Rgc Sieve Slatex Traverse  Figure 3: Scores are relative to \nBigloo, which is the 1.0 mark. Lower is better. stack consumption of the produced code. On the other \nhand, we explain in Section 3.3.1 the reason why Cgc isslower when ranwiththe JVMruntime. Comparing the \nbest of all platforms (that is, considering the time gathered on the Linux platform when the ratio BiglooJVM/Bigloo \nisthe smallest, considering the Alpha platform otherwise) demon\u00adstratesthat there isno technical impos \nibility for a JVM implementation to deliver performance comparable to the one of C. The Compaq implementation \non Alpha almost achievesthislevel of performance. 2.2.1 Variations on the JVM implementation It existsmany \nimplementationsof the JVM. Some are based on pure interpretation techniques [12]. Some are based on static \ncompilation of JVM bytecode to native code [17]. Finally, some are based on just-in-time compilers [19, \n1]. Amongst the last category some use adaptive compilation [32, 31, 3] which waspioneered by the Self \nproject [14, 15]. It consists in an on-demand compilation of the hot spots of a program. Interpreterscannot \ncompete with compilersfor performance thuswe have not tested any. In addition, we have not considered \ntesting static JVM compilers because one of the most important advantage of JVM over C is the ability \nto compile once and to run everywhere. Thisprop\u00aderty doesnot hold for static native compilation. In addition, \npreviousexperimentsshow that thiscompilation technique hasa moderate impact on performance [16]. For \nthe Linux operating system alone, more than ten im\u00adplementations of the JVM exist. It is beyond the scope \nof thispaper to evaluate all of them. According to the Java performance report [22], two implementationsperform \nbest: Sun s HotSpot (JDK 1.3) [32] and IBM JDK 1.3 [31]. HotSpot seems to be the most reliable one on \nLinux so it is our base reference. In Figure 4 we present the performance evaluationsof BiglooJVM on \nLinux/x86 using the di.er\u00adent JVM implementations. Only HotSpot/client is able to JVM implementations \n HS/Client  HS/Server  IBM 12345 Bague Beval Bigloo 5.0 Boyer Cgc Conform Earley Fft Fib Leval \n 6.0 Maze Mbrot 5.0 Nucleic Peval Puzzle Queens Qsort  10.4 10.9 Rgc Sieve Slatex 5.1 Traverse \n Figure 4: BiglooJVM with Sun s JDK, with Sun s JDK/server and with IBM s JDK vs Bigloo on Linux/x86 \narchitecture. Lower is better. run all the benchmarks. Missing values denote a JVM fail\u00adure. It seems \nthat these three machines implement di.erent adaptive compilation strategies because they deliver di.er\u00adentperformance. \nWecannotconcludethatone machine always deliversthe best performance. We can thusonly use thistest to \nemphasize that: i) performance of JVM ishardly predictable and highly dependent of the hardware/software \nplatforms, and ii) comparing all the best JVM measured execution timesto the C execution times, we found \nthat only one benchmark took more than twice aslong when run on the JVM.   2.3 BiglooJVM vs Scheme \nimplementations Figure 5 presents a comparison of BiglooJVM, Kawa v1.6.7 and Gambit v3.0 (unsafe mode \nand optimizations enabled) on Linux/86. Kawa producesJVM bytecode, Gambit pro\u00adducesC code. For all tested \nbenchmarksBiglooJVM is signi.cantly faster than Kawa. One may notice that since Kawa unfortunately doesnot \nprovide specialized arithmetic operations, slow executions are therefore to be expected. The Kawa compiler \ndoesnot seem able to automatically Scheme implementations BiglooJvm  Kawa  Gambit 0 2 4 6 810 Bague \nBeval 178.2 Boyer Conform Earley 43.0 276.2 Fft 72.6 140.3 Fib Leval Maze Mbrot  589.7 25.4 \n Nucleic Peval Puzzle 329.2 46.8 Queens 341.2 Qsort 9.8 14.6 Sieve Slatex Traverse Figure 5: \nBiglooJVM, Kawa and Gambit vs Bigloo on Linux/x86 architecture. Lower is better. turn generic arithmetic \nfunction callsto specialized arith\u00admetic calls. So, Kawa programs always use generic arith\u00admetic. Thisisa \nhuge handicap. For all but two programs, BiglooJVM is faster than Gam\u00adbit. Gambit isnot mainly designed \nfor maximal e.ciency. It implementsthe exact de.nition of Scheme when Bigloo doesnot1 . In particular, \nGambit performance isa.ected by the implementation of tail recursive calls. This speed test between Gambit \nand Bigloo thusonly demonstratesthat BiglooJVM deliver programswith acceptable performance since Gambit \nis considered by the Scheme community as an e.cient enough system. In consequence, we think that if speed \nisnot an implementor shighest priority, the JVM should be considered. 2.4 BiglooJVM vs other languages \nIt isalwaysdi.cult to compare compilersfor di.erent 1Bigloo isnot fully Scheme compliant mainly because \nit is not properly tail-recursive and because it does not imple\u00adment arithmetic bound checking. programming \nlanguages. Because the programs cannot be the very same, we can fear that a small di.erence in the im\u00adplementation \ninvalidatesthe test. For instance, Scheme and SML share a lot of features and constructions: they both \nare functional languages, promoting .rst class closures and polymorphism, using garbage collection, etc. \nHowever the programming styles of these two languages di.er. It is thus to be expected that a compiler \nfor Scheme and a compiler for SML optimize di.erent patterns of source expressions. It islikely that \na Scheme program written using an SML style would not be e.ciently optimized by a Scheme com\u00adpiler and \nvice-versa. In order to avoid these pitfalls we have only tested small and simple programs that we have \ntried to implement using the natural style of each programming lan\u00adguages. In addition, we have slightly \nmodi.ed some bench\u00admarksin order to prevent the Bigloo compiler from applying too aggressive optimizations. \nFor instance, the original ver\u00adsion of the Mbrot benchmark wasrunning 40 timesfaster when compiled by \nBiglooJVM than when compiled by Javac, the Sun sstandard Java compiler. Thiswasonly due to in\u00adlining \nand constant folding. Since we do not want, in this paper, to emphasize compiler techniques and optimizations \nbut runtime system e.ciency, we have found relevant to write a neutral benchmark version that prevents \nBigloo optimizations. However, one should note that because of the Java object model and because of dynamic \nclass load\u00ading, a compiler for FLsto JVM bytecode islikely to have more opportunitiesto optimize the \nsource code than a Java compiler. We present the comparison between BiglooJVM, MLj and Javac compilersFigure \n6. On the .ve small programs we have used, we have found that BiglooJVM and MLj (version 0.2c) deliver \nprograms with comparable performance. JVM code generators BiglooJvm  MLj  Javac 1234 Bague Fib \n 4.1 Mbrot Nucleic Queens Qsort Sieve Figure 6: BiglooJVM, MLj and Javac vs Bigloo on Linux/x86 \narchitecture. Lower is better. We decided to perform these tests for Java too, even though we assumed \nthat a Java compiler would produce better code for the JVM than BiglooJVM. Surprisingly, our programsperformed \ncomparably to those produced by Sun s Javac (JDK 1.3). In fact, on the Sieve benchmark Sun s code is \neven slower. To us, this demonstrates that Bigloo-JVM makese.cient use of the JVM.  3. THE BiglooJVM \nBACK-END In this section we present the most important points of the compilation of Scheme, i.e. a functional \nprogramming language using dynamic type checking, to JVM bytecode. We start, in Section 3.1, by presenting \nthe compilation of functions. We then discuss in Section 3.2 the implementa\u00adtion of dynamic type checking. \nWe conclude in Section 3.3 with a description of data representation. 3.1 Compiling functions Bigloo \nusesthree di.erent frameworksfor compiling func\u00adtions. We .rst present in Section 3.1.1 how local functions \ncanbe compiledto loops. TheninSection 3.1.2we s how the general framework applied to functions. In Section \n3.1.3 we present how does Bigloo handle closures. Finally, in Sec\u00adtion 3.1.4 we present limitations of \nour JVM back-end. 3.1.1 Compiling functions to loops Closure analysis aims at compiling Scheme functions \ninto JVM loops. This framework applies when local Scheme functions do not escape (that is, when functions \nare not used as .rst-class values) and when these functions are always in\u00advoked tail-recursively (see \nSection 3.1.4 for a discussion of generalized tail recursion). Here is an example of two mu\u00adtually recursive \nfunctions that map to JVM loops: (definedefine (odd? x) (letrecletrec ((even? (. (m) (ifif (= m 0) #t \n(odd? (-m 1))))) (odd? (. (n) (ifif (= n 0) #f (even? (-n 1)))))) (odd? x))) iscompiled as: (method odd? \n(x) (n m) (iload x) (istore n) L1 (iload n) ;; beginning of odd? (iconst_0) (if_icmpne L2) ;; compare \nthe argument n with 0 (iconst_0) ;; return (for odd?)false (ireturn) L2 (iload n) ;; prepare the actual \nvalue for (iconst_1) ;; the even? function (isub) (istore m) (iload m) ;; even? is inlined here (iconst_0) \n(if_icmpne L3) ;; compare the argument m with 0 (iconst_1) ;; return (for even?)true (ireturn) L3 (iload \nm) ;; otherwise prepare the call to odd? (iconst_1) (isub) (istore n) (goto L1)) ;; goto odd? Asillustrated \nby the Qsort or Sieve benchmarksthat use loops extensively, this compilation framework delivers good \nperformance. 3.1.2 Compiling functions to JVM methods When the previousscheme doesnot apply, non-escaping \nn-ary functionsmap to JVM n-ary static methods. Consider the Scheme fib de.nition: (definedefine (fib \nx) (if(< 2) if x 1 (+ (fib (-x 1)) (fib (-x 2))))) It iscompiled as: 1: (method fib (x) () 11: (isub) \n2: (iload x) 12: (invokestatic fib) 3: (iconst_2) 13: (iload x) 4: ;; test with numeral 2 14: ;; second \nrecursive call 5: (if_icmpge 9) 15: (iconst_2) 6: (iconst_1) 16: (isub) 7: (ireturn) 17: (invokestatic \nfib) 8: ;; .rst recursive call 18: (iadd) 9: (iload x) 19: (ireturn)) 10: (iconst_1) The good performance \nof the Fib, Beval and other bench\u00admarks using non tail recursive calls shows the e.ciency of thiscompilation \nframework. The JVM sstatic method in\u00advocation isasfast asC sfunction invocation. 3.1.3 Higher-order and \nHeap-allocated closures Scheme isa higher-order language: functionsare .rst\u00adclass objects which can be \npassed as arguments, returned by functionsandstoredinmemory. The front-end of the com\u00adpiler resolves \nthe lexical visibility of variables inside func\u00adtionsby making explicit closureson demand. The back-end \nstill has to implement an abstract type pointer-to-function (de.ned in a straightforward manner for the \nC back end). Fortunately, thisabstract type wasdesigned to appear only in speci.c functions (closure \ncreators) and is used indirectly by speci.c special forms (funcall and apply nodes). This allowsusto \nimplement pointer-to-function asan index (in\u00adteger) into a switch tablesfor the JVM back-end. Thistech\u00adnique \nissimilar to the one deployed in Gambit to implement tail recursive calls[11]. One unique index isallocated \nfor each static closure creation on a compilation unit (a Bigloo module). Indexesmay be identical for \n2 di.erent modules (since one switch table has been allocated per module). Con\u00adsider the simple following \nBigloo module example: (moduletest export app0 app1)) module (export (define(app0 l) (f l)) define f \n(definedefine (app1 f l) (f (reverse l))) The compiler generatesa class.le similar to: publclasstest \nextends { public class extendsbigloo.procedure publicpublic staticprocedure app0 = new test( 2, 0 static \n); publicpublic staticprocedure app1 = new test( 2, 1 static ); publictest( arity, index { public int \nint ) super( arity, index ); } publicpublic Object funcall2( Object a1, Object a2 ) { switch( this.index \n) { casecase 0: retu rn this, a2 retanonymous0( a1, ); casecase 1: retu rn this, a2 retanonymous1( a1, \n); default: funcall_error2( this, a1, a2 ); } } pri atestatic Object anonymous0( priv ate static procedure \nfun, Object a1, Object a2 ) { returnreturn ((procedure) a1).funcall1( a2 ); } pri atestatic Object anonymous1( \n priv ate staticprocedure fun, Object a1, Object a2 ) { returnreturn ((procedure) a1).funcall1( reverse( \na2 ) ); } } Where procedure isa runtime Bigloo classde.ned as: package bigloo; publiabstract class procedure \n{ public class blicint arity; pu blic index, pu blicblicObject[] env; blicprocedure( arity, index { \n... }; pu blic int int ) pu blicblicabstract Object funcall1( Object a1 ); pu blicblicabstract Object \nfuncall2( Object a1, Object a2 ); } One should keep in mind that according to Sections 3.1.1 and 3.1.2, \nthisgeneric compilation framework isused only when the compiler is unable to statically discover which \nfunctionsare called at an application site. However, we found that some JITs are unable to produce code \nwith a constant complexity for the tableswitch instruction (see Section 4.4.3). An alternative compilation \nisused by Kawa [7], where each function used as value is compiled into a new JVM class. This compilation \nframework gets rid of tableswitches. Our di.erent solution is motivated by reducing the num\u00adber of generated \nclasses. For instance, the Kawa technique would yield to more than 4,000 classes to compile the clo\u00adsures \nof the Bigloo bootstrap, with each class been compiled intoaseparate .class .le! Moreover, in the current \nBigloo version, each global that is declared to be accessible from the Scheme interpreter, is associated \nwith two Bigloo functions; one to get the value of the global, one to set a new value. This would also \nincrease signi.cantly the number of generated classes. 3.1.4 Call/cc and tail recursion BiglooJVM imposes \none restriction to Bigloo: continu\u00adationscan only be invoked in the dynamic extent of the call/cc expression \nfrom which they have been rei.ed. This restriction comes from the design of the JVM instruction set and \nfrom the bytecode veri.er. The JVM doesnot provide ameantosave and restore executionstacks. The lack \nof general stack operatorsalso makesvery dif\u00ad.cult a correct JVM implementation of tail calls. In the \ncurrent BiglooJVM version, only recursive calls to local func\u00adtionsare correctly handled, i.e., without \nstack consumption (see Section 3.1.1 for an example and a previous article [29] by theauthors formoredetails). \nThesamerestriction ap\u00adpliesto the C Bigloo runtime. In addition, we think that the trampoline technique \n[4, 33, 11] isinfeasible for the current JVM implementation, as it would cause an excessive per\u00adformance \npenalty (see Section 3.1.3). Performance of JVM executionshighly depend on the performance of embedded \nJIT compilers. Because executed at application runtime, these compilers have to be extremely fast. They \nonly have the opportunity to deploy simple and local optimizations. It isthuslikely that JIT compilerswill \nfail at optimizing pure trampolined code, which isan unusual style of JVM bytecode. On the other hand, \na recent study shows a vari\u00adant of trampolined code that appearsto .t the requirement of JIT compilersand \nthat could be used to implement tail recursion under the JVM [24].  3.2 Dynamic typing TheSchemetypesystemmay \nbe viewed as ahuge, un\u00adlimited union type. Since the JVM doesnot provide union types or parametric types, \nthe usual way to mimic union types is to use subtyping. In order to specify a union type T which isa \nsum of some Ti, it is usual to declare a class T and implement all Ti as subclasses of T . Type-dependent \nbehaviors take the form of methods added to each subclass. Thisstrategy impactsearliest stagesof the \ncompiler. This wouldhave forcedwidespreadchanges to the exis ting Bigloo source code, and we decided \nnot to use this design. In\u00adstead, we have used the JVM instruction instanceof that implementsdynamic \ntype checking. Asin the case of the tableswitch instructions, we have found that some JITs fail to compile \ninstanceof e.ciently. For instance, Sun s JDK 1.3 on Linux/x86 is40 timesslower to answer no than to \nanswer yes to instanceof. Thisexplainssome distortions on the benchmarks results. As for tableswitch, \nthe Alpha implementation of the JDK doesnot seem to suf\u00adfer from thisproblem. We plan to get rid of the \ninstanceof instruction by adding a speci.c tag to all Scheme objects. The drawback of this implementation \nisthat all foreign valuesrequire wrapping in a speci.c Scheme type. We hope that the SUA optimiza\u00adtion \n[28] will do the same nice job asfor boxed integers(see Section 3.3.1).  3.3 Data representation We \npresent in this section the BiglooJVM data represen\u00adtations. We start showing in Section 3.3.1 the main \ndi.er\u00adencesin the representation of data structuresbetween the C runtime and the JVM runtime. Then, in \nSection 3.3.2, we focuson the representation of integersin the JVM runtime system. 3.3.1 Tagging, boxing \nand pointers alignment Some well-known C tricksenable faster implementations of dynamic type identi.cation \n[13]. These techniques rely on hardware alignment requirements. Because pointers are aligned on four-or \neight-byte boundaries, the two or three least signi.cant bits of values can be used to encode type information. \nIn the Bigloo C back-end we use these bits for two purposes: i) using tagged instead of boxed representa\u00adtion \nfor integers, and ii) using lightweight two-words repre\u00adsentation for pairs. Because Java is a safe high-level \nlan\u00adguage it doesnot provide operationson pointersand thus, these C tricks do not apply to the BiglooJVM \nruntime sys\u00adtem. In order to estimate the impact of these techniques, we have built two additional versions \nof the regular Scheme\u00adto-C version of Bigloo: i) the .rst one, called Bigloo32, is identical to Bigloo \nbut integersare 32 bitslong and boxed; ii) the second one, called Bigloo32+ is identical to Bigloo32 \nbut pairsare implemented using 3 memory words(one more than with Bigloo and Bigloo32). Figure 7 comparesBiglooJVM \nand these two new ver\u00adsions. We see that Cgc is highly sensitive to integer boxing. When compiled to \nC using boxed integers, this program is no longer faster than its JVM counterpart. Cgc.Most of itsexecution \ntime isspent in a library of bit-vectors. These are used for data .ow analyses such as liveness or reach\u00adability \nproperty computations. In Cgc the bit-vectorsare implemented using vectors of integers. Because of the \npro\u00adgramming style of Cgc, the Bigloo compiler isunable to demonstrate that these vectors cannot contain \nnon-integer values. Thus, it cannot optimize these vectors. That is, it cannot replace them with native \ninteger vectors. With the C tagged version of Bigloo this is not a performance problem. The main consequence \nof tagging isthat a couple of bitsis wasted for each of the word of the bit-vectors, making the vectors \nslightly larger. With the boxed version of integers, Boxed integers and 3 words-large pairs 1.1 3.3 \n 1.1 Bigloo 1.1 1.9 1.0 Boyer 1.5 3.2 3.4 Cgc 3.3 4.6 1.0 Conform 1.2 3.0 1.1 Earley \n 1.6 2.0 1.2 Fft 1.2 0.6 Fib 0.9 0.9 2.0 1.0 Leval 1.2 3.2 1.3 Maze 1.6 4.1 Mbrot 0.8 \n 0.8 1.3 1.2 Nucleic 1.2 4.3 1.0 Peval 1.5 1.5 1.1 Puzzle 1.0 1.0 1.1 Queens 1.8 1.0 \n 1.0 Qsort 1.0 10.4 1.0 Rgc 1.1 1.4 1.8 Sieve 2.9 4.4 1.0 Slatex 1.0 2.7 1.9 Traverse \n 3.1 BiglooJVM Bigloo32 Bigloo32+ 1 2 3 4 Bague 0.9 0.9 1.6 Beval 1.1 1.4        Figure 7: BiglooJVM, \nBigloo C with boxed inte\u00adgers (Bigloo32) and Bigloo C with boxed integers and 3 words long pairs (Bigloo32+) \nvs Bigloo on Linux/x86 architecture. Lower is better. bit-vector operations become expensive because \nnew inte\u00adgershave to be allocated. That is, each time a set operation iscomputed such asan union, a disjunction, \netc., new inte\u00adgersare allocated. One may argue that thisproblem isdue to the poor implementation of \nCgc.It isclear that Cgc could be easily improved. However, we wanted to use this program asis because \nthiscurrent version pointsout one real problem of the JVM version. If integers cannot be un\u00adboxed by \na compiler, the JVM runtime system performance couldbe muchslowerthanthe one ofC. 3.3.2 Integer arithmetic \nAs presented Section 3.3.1, BiglooJVM uses heap-allocated boxed integerssuch asJava Integer instances. \nBoxing in\u00adtegersisexpensive but preallocating small onesavoid mem\u00adory consumption and memory allocation \nin most cases (for example all 256 Scheme charactersare preallocated). For 32-bit integerswe have preallocated \nintegersin the range [-100...2048].For the Bigloo benchmark, only 3.8% of integersare outside thisrange. \nThanksto the SUA [28], an optimization that enablesunboxing for polymorphic lan\u00adguages, fewer than 4% \nof the static arithmetic operations (including loading constants) need boxing for this bench\u00admark. Impact \nof 64 bits arithmetic JDK 1.3  JDK 1.2  JDK 1.1 0 2 4 6 810 some JIT compilers. Since JIT compilers \nsuch as HotSpot use methodsascompilation units, it isimportant to remove such sequences; otherwise, the \nwhole function that contains it isleft uncompiled, i.e., interpreted. The Bigloo compiler already implementssome \ndata .ow analysis. However, we have added three new transformation rulesfor the JVM bytecode generator \nthat are enabled when the compiler isable to prove that expressionsare side-e.ect free: 1. Let bindingswith \nno bound variablesare removed: bague Beval Cgc Conform Earley Fft Leval Nucleic Queens Rgc  .. .. .. \nR1 (let () expr) = expr 10.9 .. .. .. 10.9 2. Let-bound variablesthat are only used in a function called \nare reduced: R2 . . . (let (... (f ... (x expr) ...) x ...)) = . . . (let (... ...) (f ... expr ...)) \n. . . . . . 3. Let-bound variables used only in a test position are re\u00adduced: Figure 8: BiglooJVM-64 \nbits/BiglooJVM-32 bits on Linux/86. Lower is better. Aside from boxing, some choices have to be made \nfor the size of basic types. These choices are directed by the target languages. For C, sizes are unspeci.ed \nbut the long type is usually large enough to contain any address. By contrast, the JVM speci.es the length \nof all basic types. In order to choose between 32-bit integers and 64-bit arithmetic inte\u00adgerswe have \ntested the two settingswith the Sun sJDK on Linux/x86. Thistest ispresented Figure 8. Because 64-bit \narithmetic in JDK1.3 hassuch a major performance penalty, we decided to use 32-bit arithmetic on all \nplatforms. Using thiscon.guration, JDK 1.3 isthe fastest JVM we have found on Linux/x86 and Solaris/Sparc. \n  4. JVM BYTECODE TUNING Because of the currently leading technology relying on dy\u00adnamic compilation \nfor executing JVM programs, special at\u00adtentionmust be paidto produce JVM bytecode thatpleas es the JIT \ncompilers. We report the most important facts we have learned during our work on BiglooJVM. 4.1 Data \n.ow optimizations Data .ow optimizationsturn out to be important. We have found that certain JVM bytecode \nsequences disable None of these rewriting rules are di.cult to implement and they are well-known [2, \n35]. However, they are important for our JVM back-end. For instance, disabling rule R2 slows down the \nBigloo benchmark by more than 20%, because the pattern reduced by rule R2 isfrequently introduced by \nearlier Bigloo compilation stages. R3 . . . (let (... (x expr) ...) (if x ...)) = . . . (let (... ...) \n(if expr ...)) . . . . . .  4.2 Functional loops On the one hand, functional languagesare expression \nori\u00adented languages. On the other hand, Java, as C, is statement\u00adoriented. Scheme loops(e.g., Scheme \ninner functions) are expressions, that is, there evaluations produces a value. This feature isdepicted \nin thisnaive example: (define(test n b) ;; compute a + b * n define a (define(mul r) define m (iif (= \nm0)r (mul (-m 1) (+b r)))) (+ a (mul n 0))) In a .rst version of the back-end we had left the value \nof a in the JVM stack. The generated bytecode was: (method test (a n b) (r m) (iload a) ;; Prepare a \nfor addition (iload n) ;; Prepare arguments for mul:m (iconst_0) ;; ...: r muls (istore r) ;; stack \nentry for mul, store in reg r (istore m) ;;... regm mul (iload m) ;; reg entry for mul (iconst_0) (if_icmpne \nl1) ;; m == 0 ? (iload r) ;; return loop with r (iadd) ;; continuation of the loop (ireturn) l1 (iload \nm) ;; Prepare arg 1 of mul:m-1 (iconst_1) (isub) (iload b) ;; Prepare arg 2 of mul:b+r (iload r) (iadd) \n(goto muls)) ;; back to stack entry of mul We have found that some JITsdo not compile thispro\u00adgramming \nstyle and we now require that all loops (back\u00adward branches)must bedonein a statement s tyle, with an \nempty stack. (One should note that such loops used as expressions cannot be produced by a Java compiler \nbecause Java is a statement-based language.) As a result, the current BiglooJVM version now produces: \n(method test (a n b) (reg1 r m save) (iload a) ;; Prepare a for addition (iload n) ;; Prepare arguments \nfor mul:n (iconst_0) ;; ...: r muls (istore r) ;; stack entry for mul: store in reg r (istore m) ;;.. \nregm (istore save) ;; SAVE THE STACK mul (iload m) ;; reg entry for mul (iconst_0) (if_icmpne l1) ;; \nm == 0 ? (iload r) ;; return loop with r (istore reg1) ;; RESTORE THE STACK (iload save) ;; RESTORE THE \nSTACK (iload reg1) ;; RESTORE THE STACK (iadd) ;; continuation of the loop (ireturn) l1 (iload m) ;; \nPrepare arg 1 of mul:m-1 (iconst_1) (isub) (iload b) ;; Prepare arg 2 of mul:b+r (iload r) (iadd) (istore \nr) ;; prepare for reg entry point of mul (istore m) (goto mul)) ;; back to reg entry of mul In order \nto perform thistransformation, the code genera\u00adtor must know the type of stack elements at each loop \nentry. The size of the stack is not enough since for each element we have to know if we have to generate \nan istore or an astore instruction. Even if more complex, this second version runs 18 timesfaster on \nSUN JDK1.3 or 1.2 than the former one!  4.3 Bytecode veri.cation Since all functions(or more generally \nmethods) must have a prototype (declaration of argumentsand return type), the JVM may be considered as \na strongly typed language. These prototypes are used for two main reasons. First, it is possi\u00adble to \nde.ne two di.erent functionswith the same name and use the prototype as an additional key for linking \npurposes. Thisisnot to be confused with Java overloading which is resolved statically at compile time. \nSecond, prototypes are used by the bytecode veri.er at runtime. Bytecode veri\u00ad.er compliant programsmust \nexplicitly, at runtime, check downward casts. Event if for instance, in order to comply to the JVM bytecode \nveri.er the following Scheme function de.nition: 1: (define(first define x) 2: (condcond 3: ((pair? x) \n(car x)) 4: ((vector? x) (vector-ref x 0)) 5: (else#f))) else mustbe compileds uchas: 1: (method first \n(x) () 10: (instanceof [jobject) 2: (aload x) 11: (ifeq 17) 3: (instanceof pair) 12: (aload x) 4: (ifeq \n9) 13: (checkcast [jobject) 5: (aload x) 14: (iconst_0) 6: (checkcast pair) 15: (aaload) 7: (getfield \ncar) 16: (areturn) 8: (areturn) 17: (getstatic bfalse) 9: (aload x) 18: (areturn)) That is, if the compiler \nis able to prove that the type of x isa pair line 3 or a vector line 4 depending on the branch of the \ncond, it still has to enforce a dynamic type test when fetch\u00ading valuesfrom the data structure, such \naslines6 and 13. One may enable or disable the bytecode veri.er when run\u00adning JVM programs. Because the \nbytecode generated pro\u00adduced by BiglooJVM isnot bytecode veri.er compliant all the previously given time \n.gures have been gathered with the bytecode veri.er disabled. BiglooJVM provides an op\u00adtion to generate \ncode that complieswith the veri.er. We have not yet implemented the optimization which removes unnecessary \ncheckcast instructions. We have noticed that the current overhead of the bytecode veri.er compliance \nrangesfrom 10% to 55%. We think that thisslowdown is acceptable, so wehavepostponed thework on this topic. \n 4.4 JVM idiosyncrasies We have noticed that current JVM implementationsare highly sensitive to the \nshape of the generated bytecode. In this section we present three JIT related problems we have encountered \nand the solution we have applied for two of them. 4.4.1 Startup time In order to gather accurate time \ninformations, we have considered long lasting benchmarks. All but Bigloo and Cgc benchmarks, when compiled \nto C, last more than 10 seconds on our AMD Athlon 800 Mhz. However, we must point out that JVM applicationshave \nlong startup times. For instance, when Bigloo isinvoked with the -help op\u00adtion which displayscommand \nline optionsand exits, the C time isabout 0.02swhile the JVM time is2.52s. That is, the startup time \nof the JVM version is 126 slower than the C one! This extremely slow startup time explains the poor result \nof the overall Bigloo benchmark for the JVM version. Prohibitive startup times are a problem for short\u00adlasting \napplications. For instance, it is currently impossible to use BiglooJVM to implement shell-like commands \nsuch as ls, cat, etc. We have no solution to this problem yet. 4.4.2 Method size considerations We have \nnoticed that the current JIT compilersuse a compilation threshold. In particular, we have experimen\u00adtally \nfound out that Sun sHotSpot stopscompiling func\u00ad tionsfor which the body islarger than 8000 JVM bytecode \ninstructions. Expectingly, some of our benchmarks su.er from this strict limitation. The most signi.cant \none is Rgc which performs miserably with HotSpot (see Figure 2). This benchmark uses Bigloo regular grammars. \nThese lex-like grammarsare compiled to deterministic .nite automata that are, in turn, compiled into \nScheme functions. Each grammar iscompiled into one global Scheme function for which the states of the \nautomaton are implemented using local func\u00adtions. Because all function calls to these local functions \nare tail calls, the Bigloo compiler is able to inline or integrate them (see Section 3.1.1). In consequence, \nfor one regular grammar, Bigloo producesexactly one JVM method. The Rgc benchmark usesa large grammar \nthat implementsa complete Scheme reader (the actual Bigloo reader). When compiled to JVM thisgrammar \nuses8252 JVM instructions. That is252 instructionsmore than the accepted number! In consequence the JVM \nmethod resulting of the compilation of the regular grammar isleft uncompiled by HotSpot. All the execution \ntime of the benchmark isspent in the com\u00adpiled regular grammar. Thisexplainswhy that benchmark performsso \nbadly with thisJava virtual machine. We hope that thisproblem will be .xed in the next HotSpot version. \nA JVM .ag enabling user customization of the compilation threshold would be a workaround to this problem. \n4.4.3 JVM compilation of tableswitch We found that someJITs areunabletoproducecode with aconstant complexity \nfor the tableswitch instruction. For example, on Linux/x86, using Sun s JIT, tableswitch im\u00adplementation \nislinear in time. More precisely, we found that the execution time of tableswitch is17.68 * index +34.39 \nnanoseconds. On the same platform, iadd wasbenchmarked around 14 nanoseconds. When index isnot in the \nspeci.ed range, the longest time isrequired. Thispoor compilation of tableswitch explains some distortions \non the benchmarks results. One should note that stable timing results were measured on the Alpha platform. \nThe e.ciency of this compilation framework isdemonstrated by the good per\u00ad formance of benchmarksusing \nhigher order functions(e.g., Queens, Leval).  5. RELATED WORK In thissection we compare BiglooJVM with \ntwo others Scheme to JVM compilers, Kawa and with a ML to JVM compiler, MLj. 5.1 The Kawa Scheme compiler \nKawa isanother Scheme compiler to JVM. Kawa imple\u00admentation techniquesdi.er from BiglooJVM in many re\u00adspects. \nFor instance, Kawa closures are implemented by the means of classes (see Section 3.1.3). Kawa strings \ndif\u00adfer from BiglooJVM strings. Kawa maps Scheme strings into Java strings, while BiglooJVM maps them \ninto array of bytes. Java strings are not suitable for implementing Scheme strings because the former \nare immutable while the later are mutable. The Kawa eq? predicate hasa di.erent meaning than the BiglooJVM \none s. Kawa eq? is false for integers, which is a correct implementation, according to the Scheme Revised5 \nReport [18]. Bigloo implementsexact eq? for integers. Thus, forthe sakeof compatibility between thetwo \nruntimesys\u00adtems, wehavedecided to providethe s amesemantics for eq? with BiglooJVM. Providing integers \neq? impactsthe perfor\u00admance of eq?. Asreported Section 3.3.2, integersare allo\u00adcated which leadsto the \nfollowing implementation of eq?: boolean EQ( Object o1, Object o2 ) { ifo1 == o2 ) returntrue; if( return \nreturnreturn( ( o1 instanceof BINT ) &#38;&#38; ( o2 instanceof BINT ) &#38;&#38; ((BINT)o1.value == \n(BINT)o2.value) ); } If equality isnot considered for integer, eq? could be: boolean EQ( Object o1, Object \no2 ) { returno1 o2; return == } When, thanksto the SUA, the Bigloo front-end succeeds in demonstrating \nthat either one of the eq? argumentsis not an integer, thisfast implementation ispreferred to the former \none. In order to minimize the performance slow down of the compatibility between Bigloo and BiglooJVM \nwe have added a compilation .ag that switches from compatible to incompatible eq?. For all benchmarks, \nwe have disable eq? compatibility. 5.2 The MLj compiler MLj isan optimizing compiler for Standard ML \nproducing JVMbytecode. BiglooJVMand MLjshare amaingoal: e.ciently compiling a strict functional language \nto JVM. The paper [5] concentrateson the front-end of that compiler and doesnot detail itsbytecode production. \nThe present paper focuses on the runtime system. The two papers are thuscomplementary. It seemsthat MLj \nusestype information to avoid boxing when Bigloo uses a global analysis. The MLj analysis is too brie.y \ndescribed. For this reason, we cannot compare the respective accuracy of the two approaches. The most \nimportant di.erence between MLj and BiglooJVM seems to be that MLj does not support separate compilation \nwhile Bigloo does[5]. The authorsof MLj state that ...the rea\u00adsonable [MLj] performance has only been \nachieved at the price of high compile timesand a limitation on the size of programswhich may reasonably \nbe compiled. Our deci\u00adsion to do whole-program optimization is certainly contro\u00adversial... . As reported \nin Figure 6 it seems that Bigloo-JVM producescomparable performance without thislimi\u00adtation. In addition, \nBiglooJVM supports separate compi\u00adlation. So, the BiglooJVM, which isa program of about 100,000 linesof \ncode (the compiler plusthe runtime system) isbootstrapped. On the other hand, the good performance of \nBiglooJVM isachieved at the price of producing code that doesnot comply with the bytecode veri.er while \nMLj does not su.er from this limitation. Using a compilation option, BiglooJVM producesbytecode veri.er \ncompliant code but thiscurrently slowsdown executions.  6. CONCLUSION We have added a new JVM bytecode \ngenerator to the Bigloo Scheme-to-C optimizing compiler. In order to esti\u00admate, from a performance point \nof view, how suitable JVM isasa target for compiling strict functional languages, we compared the applicationswhen \nrun on the C-based and the JVM-bas ed runtimesystems . Wehavetested s everal imple\u00admentationsof the JVM \non several di.erent hardware archi\u00adtectures. Given a code generator that is carefully written and aware \nof the JVM s idiosyncrasies, we found that most of the JVM compiled applicationsare no more than twice \nas slow as compiled C applications. The performance of JVM has not ceased to increase signi.cantly since \nthe .rst imple\u00admentation. If JVM implementationskeep improving at this pace, we think that in a near \nfuture, JVM bytecode may become a true performance challenger. ACKNOWLEDGMENTS Many thanksto Christian \nQueinnec, Xavier Leroy, John Clements, and to C\u00b4eline for their helpful feedbackson this work.  7. REFERENCES \n[1] A.Adl-Tabatabai,M.Cierniak, G-Y. Lueh,V.Parikh, and J. Stichnoth. Fast,E.ectiveCodeGeneration ina \nJust-In-Time Java Compiler.In Conference on Programming Language Design and Implementation,pages 280 \n190, June 1998. [2] A.Aho,R.Sethi,and J. Ullman. Compilers: Principles, Techniques and Tools. Addison-Wesley, \n1986. [3] M.Arnold, D. Fink,M.Hind, and P.Sweeney. Adaptive Optimizationinthe Jalape no JVM.In Conference \non Object-Oriented Programming, Systems, Languages, and Applications,Minneapolis,USA,October 2000. [4] \nH. Baker. CONS Should Not CONS Its Arguments, Part II: Cheney on the M.T.A <1>. Sigplan Notices, 30(9):17 \n20, September 1995. [5] N. Benton and G. Kennedy, A. Russel. Compiling Standard ML to Java Bytecodes.In \nInt l Conf. on Functional Programming,1998. [6] H.J.Boehm and M.Weiser. Garbage Collectioninan Uncooperative \nEnvironment. Software Practice and Experience, 18(9):807 820, September 1988. [7] P. Botner. Kawa: Compiling \nScheme to Java.In Lisp users conference,Berkeley, California,USA,November 1998. [8] W. De Pauw and G. \nSevitski. Visualizing Reference Patterns for Solving Memory Leaks in Java.In Proceedings ECOOP 99, pages \n116 134, Lisbon, Portugal, June 1999. [9] M. DePristo. SINTL: A Strongly-Typed Generic Intermediate \nLanguage for Scheme.Northwestern University, Computer Science Honors Thesis, 2000. [10] P. H. Hartel \net al. Pseudoknot: a Float-Intensive Benchmark for Functional Compilers. Journal of Functional Programming, \n6(4):621 655, 1996. [11] M. Feeley, J. Miller, G. Rozas, and J. Wilson. Compiling Higher-Order Languages \ninto Fully Tail-Recursive Portable C. Technical Report Rapport technique 1078, Universit\u00b4edeMontr\u00b4eal, \nD\u00b4epartement d informatique et r.o., August 1997. [12] E. Gagnon and L. Hendren. SableVM: A Research \nFramework for the E.cient Execution of Java Bytecode. Technical Report 2000-3, McGill University, School \nof Computer Science, November 2000. [13] D. Gudeman. Representing Type Information in Dynamically Typed \nLanguages. Technical report, University of Arizona, Departement of Computer Science, Gould-Simpson Building, \nThe University of Arizona, Tucson, AZ 85721, April 1993. [14] U. H\u00a8olzle. Adaptive Optimization for Self: \nReconciling High Performance with Exploratory Programming.PhD thesis,Stanford University, August 1994. \n[15] U. H\u00a8olzle and D. Ungar. Reconciling responsiveness with performance in pure object-oriented languages. \nACM Transactions on Programming Languages and Systems, 18(4):355 400, July 1996. [16] M. Honeyford. Weighing \nin on Java native compilation. Technical Report developerWorks, IBM, January 2002. [17] C.-H.Hsieh,J.Gyllenhaal, \nand W. Hwu. Java bytecode to native code translation: The Ca.eine prototype and preliminary results.In \nIEEE/ACM Int l Symposium on Microarchitecture, 1996. [18] R. Kelsey, W. Clinger, and J. Rees. The Revised(5) \nReport on the Algorithmic Language Scheme. Higher-Order and Symbolic Computation, 11(1), September 1998. \n[19] A. Krall. E.cient JavaVM Just-in-Time Compilation.In Proceedings PACT 98,Paris,France, October 1998. \n[20] X. Leroy. Unboxed objects and polymorphic typing. In Symposium on Principles of Programming Languages, \npages 177 188, Albuquerque, New Mexico, January 1992. [21] T. Lindholm and F. Yellin. The Java Virtual \nMachine. Addison-Wesley, 1996. [22] O. Pinali Doederlein. The Java Performance Report Part IIA. http://www.javalobby.org/features/jpr, \nAugust 2000. [23] C. Queinnec. The in.uence of browsers on evaluators. In Int l Conf. on Functional Programming, \npages 23 33, Montr\u00b4eal, Canada, September 2000. [24] M. Schinz and M. Odersky. Tail call elimination \nof the Java Virtual Machine.In Proceedings of Babel 01, Florence, Italy, September 2001. [25] N. S\u00b4eniak. \nTh\u00b4eorieet pratiquede Sqil: un langage interm\u00b4ediaire pour la compilation des langages fonctionnels. \nPhD thesis, Universit\u00b4ePierreetMarie Curie (Paris VI), November 1991. [26] M. Serrano. Control Flow Analysis: \na Functional Languages Compilation Paradigm.In 10th Symposium on Applied Computing, pages 118 122, Nashville, \nTennessee, USA, February 1995. [27] M. Serrano. Inline expansion: when and how? In Int. Symp. on Programming \nLanguages, Implementations, Logics, and Programs, pages 143 147, Southampton, UK, September 1997. [28] \nM. Serrano and M. Feeley. Storage Use Analysis and its Applications.In 1fst Int l Conf. on Functional \nProgramming, pages 50 61, Philadelphia, Penn, USA, May 1996. [29] M. Serrano and P. Weis. Bigloo: a portable \nand optimizing compiler for strict functional languages. In 2nd Static Analysis Symposium, Lecture Notes \non Computer Science, pages 366 381, Glasgow, Scotland, September 1995. [30] O. Shivers. Control Flow \nAnalysis in Scheme.In Proceedings of the SIGPLAN 88 Conference on Programming Language Design and Implementation, \nAtlanta, Georgia, June 1988. [31] T. Suganama, T. Ogasawara, M. Takeuchi, T. Yasue, M. Kawahito,K.Ishizaki, \nH. Komatsu, and T.Nakatani. Overview of the IBM Java Just-in-time compiler. IBM Systems Journal, 39(1), \n2000. [32] Sun Microsystems. The Java HotSpot Performance Engine, April 1999. [33] D. Tarditi, A. Acharya, \nand P. Lee. No assembly required: Compiling Standard ML to C. ACM Letters on Programming Languages and \nSystems, 2(1):161 177, 1992. [34] Tolksdorf. Compiling to JVM. http://grunge.cs.tu-berlin.de/tolk, 2000. \n~ [35] T. VanDrunen, A. Hosking, and J. Palsberg. Reducing loads and stores in stack architectures, 2000. \n[36] D. Wakeling. Compiling Lazy Functional Programs for the Java Virtual Machine. Journal of Functional \nProgramming, 9(6):579 603, November 1999.  CPU+SYS seconds Bench Bigloo C BiglooJvm Gambit Kawa MLj \nJavac   Bague 10.12 (1.00 d) 15.88 (1.56 d) 69.05 (6.82 d)  13.39 (1.32 d) Beval 10.61 (1.00 d) \n 15.30 (1.44 d) 22.18 (2.09 d) 1890.9 (178.22 d) Bigloo 3.89 (1.00 d) 12.85 (3.30 d) Boyer 12.73 (1.00 \nd)  24.28 (1.90 d) 31.82 (2.50 d) 89.17 (7.00 d) Cgc 2.35 (1.00 d) 7.43 (3.16 d) Conform 11.01 (1.00 \nd)  51.18 (4.64 d) 59.33 (5.38 d) Earley 10.51 (1.00 d) 31.81 (3.02 d) 65.75 (6.25 d) 452.08 (43.01 \nd) Fft 8.96 (1.00 d) 17.92 (2.00 d) 650.46 (72.60 d) 2474.9 (276.22 d) Fib 13.58 (1.00 d) 8.49 (0.62 \nd) 14.59 (1.07 d) 1905.4 (140.31 d) 19.65 (1.44 d) 12.03 (0.88 d) Leval 9.26 (1.00 d) 18.94 (2.04 d) \n 40.73 (4.39 d) 37.21 (4.01 d) Maze 13.87 (1.00 d) 43.74 (3.15 d) 39.58 (2.85 d) Mbrot 13.72 (1.00 \nd) 55.85 (4.07 d) 347.95 (25.36 d) 8090.0 (589.65 d) 44.98 (3.27 d) Nucleic 9.12 (1.00 d) 12.14 (1.33 \nd) 21.82 (2.39 d) 11.58 (1.27 d) Peval 14.50 (1.00 d) 62.77 (4.32 d) 36.20 (2.49 d) 89.50 (6.17 d) \nPuzzle 13.13 (1.00 d) 20.20 (1.53 d) 20.62 (1.57 d) 4322.4 (329.21 d) Queens 12.22 (1.00 d) 12.38 (1.01 \nd) 33.13 (2.71 d) 571.82 (46.79 d) 17.09 (1.39 d) Qsort 19.38 (1.00 d) 19.74 (1.01 d) 190.66 (9.83 \nd) 6611.7 (341.17 d) 36.15 (1.86 d) 18.92 (0.97 d) Rgc 10.64 (1.00 d) 110.45 (10.38 d) Sieve 11.88 (1.00 \nd) 16.06 (1.35 d) 22.05 (1.85 d) 173.34 (14.59 d) 15.76 (1.32 d) 17.61 (1.48 d) Slatex 13.91 (1.00 d) \n61.81 (4.44 d) 38.44 (2.76 d) 69.69 (5.01 d) Traverse 18.68 (1.00 d)  50.69 (2.71 d) 113.06 (6.05 \nd) 107.89 (5.77 d)        Figure 9: Benchmarks timing on an AMD Tbird 800Mhz/256MB, running Linux \n2.2.8  Appendix A: The benchmarks Here isa short description of the benchmarkswe have been using so \nfar. The numbers of lines are always given for the Bigloo version of the source .les. Figure 9 presents \nall the numerical valueson Linux/x86. Bague by P. Weis (105 lines). Tests .xnum arithmetic and vec\u00adtors. \nBeval (582 lines). The regular Bigloo Scheme evaluator.  Bigloo (99,376 lines). The bootstrap of the \nBiglooC compiler and the runtime library. Boyer (626 lines) by B. Boyer and modi.ed by B. Shaw and W. \nClinger.Tests symbols and condi\u00adtional expressions. Cgc (8,128 lines). A simple compiler for a C like \nlanguage that produces Mips assembly code. Conform (596 lines). It uses lists, vectors and numerous small \ninner functions.  Earley by M. Feeley (672 lines). An implementation of the Ear\u00adley parser. Fft (120 \nlines). Yet another Gabriel s benchmark. Fast Fourier transform ported to Scheme by Harry Barrow. Fib \n(18 lines). Fibonacci numbers. Leval by M. Feeley (555 lines). A Scheme evaluator using lambda expressions. \nMaze by O. Shivers (809 lines). Uses arrays .xnum operations and iterators.  Mbrot (47 lines). The Mandlebrot \ncurve that tests .oating point arithmetic. Nucleic (3,507 lines). Described in [10], this benchmark measures \nthe e.ciency of numerical computations.  Peval by M. Feeley (639 lines). A partial evaluator that uses \na lot of nested functions and allocates many lists and symbols.  Puzzle by F. Baskett (208 lines). Another \nGabriel s bench\u00admark. Queens by L. Augustsson (131 lines). Ported from Lml to Scheme, tests list allocations. \nQuicksort by P. Weis (124 lines). It tests arrays and .xnum arithmetic. Rgc (348 lines). The Bigloo regular \ngrammar that implements the Bigloo reader.  Sieve (53 lines) Fixnum arithmetic and list allocations. \nSlatex by D. Sitaram (2,827 lines). This is a LATEX preprocessor imple\u00admented by Rice University that \ntests Input/Output capacities.  Traverse modi.ed by J. Siskind (136 lines). It allocates and modi.es \nlists.   \n\t\t\t", "proc_id": "581478", "abstract": "We have added a Java virtual machine (henceforth JVM) bytecode generator to the optimizing Scheme-to-C compiler Bigloo. We named this new compiler BiglooJVM. We have used this new compiler to evaluate how suitable the JVM bytecode is as a target for compiling strict functional languages such as Scheme. In this paper, we focus on the performance issue. We have measured the execution time of many Scheme programs when compiled to C and when compiled to JVM. We found that for each benchmark, at least one of our hardware platforms ran the BiglooJVM version in less than twice the time taken by the Bigloo version. In order to deliver fast programs the generated JVM bytecode must be carefully crafted in order to benefit from the speedup of just-in-time compilers.", "authors": [{"name": "Bernard Paul Serpette", "author_profile_id": "81100037529", "affiliation": "Inria Sophia-Antipolis, Sophia-Antipolis, Cedex, France", "person_id": "P394758", "email_address": "", "orcid_id": ""}, {"name": "Manuel Serrano", "author_profile_id": "81100128092", "affiliation": "Inria Sophia-Antipolis, Sophia-Antipolis, Cedex, France", "person_id": "PP39028783", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/581478.581503", "year": "2002", "article_id": "581503", "conference": "ICFP", "title": "Compiling scheme to JVM bytecode:: a performance study", "url": "http://dl.acm.org/citation.cfm?id=581503"}