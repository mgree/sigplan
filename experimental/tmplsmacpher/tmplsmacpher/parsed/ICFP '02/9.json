{"article_publication_date": "09-17-2002", "fulltext": "\n Exception Analysis for Non-Strict Languages * Kevin Glynn,Peter J. Stuckey, Martin Sulzmann, Harald \nS\u00f8ndergaard Department of Computer Science and Software Engineering The University of Melbourne, Vic. \n3010, Australia {keving,pjs,sulzmann,harald}@cs.mu.oz.au Abstract In this paper we present the .rst \nexception analysis for a non-strict language. We augment a simply-typed functional language with ex\u00adceptions, \nand show that we can de.ne a type-based inference sys\u00adtem to detect uncaught exceptions. We have implemented \nthis ex\u00adception analysis in the GHC compiler for Haskell, which has been recently extended with exceptions. \nWe give empirical evidence that the analysis is practical. Categories and Subject Descriptors D.3.2 \n[Programming Languages]: Language Classi.cations Applicative (functional) languages; F.3.2 [Logics and \nMeanings of Programs]: Semantics of Programming Languages Program analysis; F.3.3 [Logics and Meanings \nof Programs]: Studies of Program Constructs Control primitives General Terms Languages, Theory  Keywords \nExceptions, non-strict functional programming languages, type in\u00adference, effect systems, Boolean constraints \n1 Introduction Ever since their introduction in PL/I and Ada, exceptions have been recognised as a useful \nmechanism for dealing with abnormal results occurring during the execution of a program. Exceptions can \nmake programs more robust, that is, able to recover from abnormal situa\u00adtions without halting, in a way \nthat preserves program modularity. *Current address: D\u00b4epartement d Ing\u00b4enierie Informatique, Univer\u00adsit\u00b4e \ncatholique de Louvain, Belgium, glynn@info.ucl.ac.be Current address: School of Computing, National University \nof Singapore, martin@comp.nus.edu.sg Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. ICFP 02, October 4-6, 2002, Pittsburgh, Pennsylvania, USA. Copyright \n2002 ACM 1-58113-487-8/02/0010 ...$5.00 Exception handling features allow a programmer to name, raise, \nand handle kinds of abnormal run-time behaviour. For example, an exception NoFile can be explicitly raised \nin a program fragment when an attempt to read from a non-existing .le is detected. In an expression-based \nlanguage, the exception can be thought of simply as an alternative value that an expression may take, \none that will propagate through enclosing expressions. To ensure that a possible exception gets dealt \nwith, a programmer can bracket an expression with exception handlers. These handlers can provide the \nmeans for recovering from the abnormal situation: the innermost handler equipped to deal with the particular \nexception will do so. Until recently only strict languages, such as the ML family [12, 11], and Java \n[1] have supported exceptions. (Haskell 98 [15] only al\u00adlows exceptions to be raised from the stateful \nIO monad.) Since the control .ow of a non-strict language is not straightforward it can be hard to predict \nwhich exception will be raised. Additionally, op\u00adtimising compilers for non-strict languages alter a \nprogram s eval\u00aduation order to achieve acceptable performance, but such transfor\u00admations can affect which \nexceptions are raised. Fortunately, Peyton Jones et al. [14] show that these problems can be overcome \nby pre\u00adtending that an expression raises a set of exceptions and the non\u00addeterministic handler (which \nmust still be in the IO monad) then selects one of the thrown exceptions. This model can be cheaply implemented \nand has no impact on most existing optimisations. In this paper we present an escaping exception analysis \nfor a non\u00adstrict functional language. The analysis discovers exceptions that could possibly be raised \nand not caught within an expression. The analysis is polyvariant and is presented for a simply-typed, \nnon\u00adstrict functional language with only base and functional types. Us\u00ading techniques we have previously \ndeveloped for a binding-time analysis [8] it is straight-forward to extend the analysis to languages \nwith Hindley-Milner style polymorphism and structured, recursive data types. We have implemented the \nanalysis in the Glasgow Haskell Compiler (GHC), and the implementation supports poly\u00admorphic programs \nand structured, recursive data types. Our exception handling constructs are based on those found in ML. \nExceptions are represented by the nullary constructors of a built-in Exception type. For example: data \nException =FileNotFound IDivideByZero IKeyNotFound IBadArgument IArrayException I In practice, the language \ndoes not need to prede.ne the possible exceptions that can be raised, for example in ML new exception \nconstructors can be introduced anywhere in a program. Since a pro\u00adgram can only raise a .nite number \nof exceptions a simple scan of the program allows an appropriate Exception type to be constructed. Our \nanalysis can do this on the .y, but to simplify the presentation we assume that the exceptions in a program \nare already known. Exception values are part of the denotation of all types (much as . is a part of the \ndenotation of all pointed types). A primitive func\u00adtion, raise, throws an exception. Since an exception \ncan be of any type, we have a family of type-indexed raise primitives: raiset :: Exception -t For simplicity, \nwe will sometimes use the unadorned raise state\u00adment instead of the appropriate type-correct instance. \nWe do not support .rst class exceptions nor exceptions with argu\u00adments. Instead, we insist that in a \nwell-formed program, the argu\u00adment to raise must be a manifest (explicit) Exception constructor. Exception \nvalued expressions can appear nowhere else. We follow [14] and accept non-determinism in the exceptions \nbe\u00ading raised. Non-determinism is a consequence of not having a .xed evaluation order throughout the \nlanguage. For example, which ex\u00adception is raised in the following expression? (raise BadArgument)(raise \nDivideByZero) Operationally, we will get the .rst exception encountered during evaluation, so the result \ndepends upon which argument is evaluated .rst. We solve this problem by allowing the denotation of an \nex\u00adpression to be a set of exceptions, and the expression above denotes the set {BadArgument,DivideByZero}. \nThis allows an implemen\u00adtation to evaluate the arguments in any order. Exceptions are caught by a new \nlanguage construct, try. try expr match excep name1 -expr1 excep name2 -expr2 excep namen -exprn Informally, \nexpr is evaluated to weak head normal form. If that raised no exceptions then the result of expr is the \nresult of the try expression as well. Otherwise one of the raised exceptions is cho\u00adsen randomly. If \nit matches one of the exception patterns then we evaluate and return that pattern s right hand side expression. \nIf the exception does not match any pattern then it is re-raised by the try expression. Operationally, \nof course, the implementation does not raise sets of exceptions. Instead, the .rst exception to be encountered \nis returned to the innermost try statement, where it is matched against the pat\u00adterns as above. However, \nthis behaviour is consistent with the above described semantics. Note that non-determinism of exceptions \ncan leak into the language proper. For example, the following expression can evaluate to either 0 or \n1, and the semantics should re.ect this. try (raise BadArgument)(raise DivideByZero) match BadArgument \n-0 DivideByZero -1 The main contribution of this paper is a novel exception analysis for a non-strict \nlanguage. It is presented as a type-based inference system which makes novel use of Boolean constraints. \nApart from suggesting well-known algorithms for implementation, the use of Boolean constraints allows \nan elegant formulation for the analysis of try expressions. It also makes the extension to a polymorphically \ntyped language easier (we do not show the extension here, but it carries over from our binding-time analysis \n[8]). We give a formal correctness result and show some empirical results of an implemen\u00adtation of our \nanalysis in GHC.  In Section 2 we introduce a simply-typed, higher-order functional language extended \nwith constructs for raising and catching excep\u00adtions. Section 3 presents our Exception Logic including \na formal correctness result. An inference algorithm is described in Section 4. In Section 5 we consider \nour implementation in the GHC compiler and present some empirical analysis results. Related work is dis\u00adcussed \ninSection6. Section7concludes. 2 Source Language Types and expressions are given by the grammar Types \nt ::=Int IBool IExn It -t Expressions e ::=x I.xe Iee I.x x in e I if e then e else e I let x =e in e \nI raiset exi I try ematch [exi -ei]iEI Exceptions ex ::=Ex1 IIExn The language has a standard syntax \nextended with primitives to raise and catch exceptions. There are a .xed number of exception constructors, \nEx1,,Exn. We denote the set of exception con\u00adstructors E. We use the notation [exi -ei]iEI to indicate \na sequence of the form [ex1 -e1,,exm -em] (I is a sequence 1 m for some positive integer m). Each exi \nis a pattern exception constructor matching an element of Ex1,,Exn. The meaning of raise and try has \nbeen discussed in the previous section. Our try statement is representative of those found in most other \nlanguages. Peyton Jones et al. [14] have a slightly different catch statement (getException), but this \nis easy to write using our try statement. The type language is also standard and the type logic is not \ngiven here. As we shall see, the standard denotation of each type is ex\u00adtended to include all possible \nexceptions. For the try expression, the type of e and all the ei s must be the same, and this is also \nthe type of the try expression. We can extend the exception escape analysis to a language with let\u00adstyle \npolymorphism using a technique from our previous work [8]. Then raise becomes a primitive in the initial \nenvironment of type Va Exn -a. Our implementation uses this approach and does han\u00addle let-polymorphism. \nHowever, in the interest of clarity we shall omit let-polymorphism in the following. The addition of \nexceptions to a non-strict language has considerable rami.cations. As noted in Section 1 determinism \nis the most promi\u00adnent victim, and we discuss other consequences in Section 6. Pey\u00adton Jones et al. [14] \nlimit the semantic impact of non-determinism by putting it in the IO monad. Although this clearly identi.es \nnon\u00addeterministic computations to the programmer (through the type system) it doesn t change the underlying \nsemantics. All the ex\u00adamples in this paper can be written (with small modi.cations) in their system and \nwill have the same behaviour. For the purposes of this paper we consider that the (entire) com\u00adputation \nis non-deterministic, not just parts in the IO monad. This simpli.es the semantics, leading to a simple \ncorrectness proof for the analysis. The meaning of a closed expression is a .nite, non-empty set of possible \nvalues. In addition to normal values we also have abnormal values. We denote by V the least solution \nof the following equation: V =B1E1V -V Base domains B, denoting values of type Int and Bool, are ordered \nby equality, function spaces have pointwise ordering, and the is coalesced sum. The partial ordering \n:thus de.ned is lifted to .nite non-empty sets by de.ning (Smyth Ordering) A .B iff Vy EB,:x EAx :y With \nthis, there is no distinction between possible and de.nite non\u00adtermination, which is adequate for our \npurpose. (On sets of func\u00adtion values, the Smyth ordering is in fact a pre-order, so strictly we should \nconsider equivalence classes with respect to the induced equivalence relation, but the details are of \nlittle interest here.) Figure 1 gives a denotational de.nition of the language. The se\u00admantics is conservative \nin the sense that it forces the normal-order evaluation of a program. An environment . maps a free variable \nto a set of possible denotations. As an example of an initial environ\u00adment, here is a suitable semantic \nequation for the built-in func\u00adtion. Note that the arguments to .init ( )are sets of denotations, as \nis the result. .init ( )=.x .y {.IE(x Uy)} U(E n(x Uy)) U{ij Ii Ex \\E !j Ey \\E} A raise expression has \nonly one (abnormal) value. A lambda ex\u00adpression is always considered a normal value, but in general, \na value of function type may have an abnormal value, witness if (raise Ex2)then else The value of this \nexpression is Ex2, and so is the result of applying the function to some argument. Similarly no distinction \nis made between and .x , although in Haskell they can be distinguished by the seq operator.  3 Exception \nLogic The structure of exception types re.ects the structure of the under\u00adlying type system. Annotations \nb ::=d Exception Types t ::=b It bt -- -  Type Schemes . ::=t IVd C t Each possible exception ex EE \nis allocated a unique variable dex. - - We write d =fv(.)to refer to the free variables in an exception \ntype .. The constraint component C will be described shortly. We are often interested in the topmost \nannotation of a type. The function I\"Ireturns a type s topmost annotation: IdI=d It btI=b - Exception \nvariable relationships are captured through Boolean con\u00adstraints. A variable d stands for a Boolean variable. \nWe denote by true the always true constraint. If variable d2 represents at least the exceptions that \nvariable d1 represents then we express that by Boolean implication d1 -d2. For example, if an expression \nof type d can raise exception Ex3, then this is expressed by a constraint of dEx3 -d. In addition to \nimplication, constraints may contain con\u00adjunction and existential quanti.cation. 2IMP C ::=true Id -d \nIC !C I:d C -- We allow :d C as shorthand for :d1 :d2 :dnC. We write C1 I= C2 to denote model-theoretic \nentailment among constraints C1 and C2. It is convenient to de.ne a structural ordering, \":s \", between \nexception types. These translate via function [[\"]]sub to a conjunction of primitive constraints: [[d1 \n:s d2]]sub =d1 -d2 d1t'd2t' - 2]]sub [[t1 1 :s t2 -=d1 -d2 ![[t2 :s t1]]sub ! [[t'1 :s t'2]]sub To relate \nan expression s valid exception type to its underlying type, we employ a shape system. This system ensures \nthat an expres\u00adsion s exception type has the same shape as its underlying type. The judgement . Is t \nstates that . is well-shaped with respect to under\u00adlying type t. A judgement . Is t is valid if it can \nbe derived by the following shape rules: (Base) d Is Bool d Is Int d Is Exn t1 Is t1 t2 Is t2 (Arrow) \nt dt'-t2 -Is t1 t Is t (V) \u00ad - Vd D t Is t We require a valid exception type to be well-shaped. 3.1 The \nLogic We now present an Exception Logic which identi.es escaping ex\u00adceptions. Note that we maintain a \nphase distinction between the process of type inference (of underlying types) and exception anal\u00adysis. \nWe will always assume that expressions are well-typed and fully type-annotated. Exception Typing judgements \nare of the form C,G I(e :: t): . where C is the global constraint, G contains the exception types of \nfree variables and primitive functions in e, (e :: t)is an expression, type-annotated with its underlying \ntype, and . is an exception type scheme. We denote by Gx the type environment obtained from G by excluding \nthe variable x. We denote by G (x :: t): . the exten\u00adsion of environment G with (x :: t): .. We will \nalways assume that ((ex :: Exn): dex)EG for each ex EE. Figure 2 de.nes the typing rules. We maintain \nthe invariant that types in the environment and types of expressions are shape cor\u00adrect. In rule (Sub) \nwe translate structural constraints into Boolean constraints via the [[\"]]sub function. Rules (VI) and \n(:I) restrict quan\u00adti.cation to the free variables. Note that dex Efv(G)for each ex EE, therefore quanti.cation \nover dEx1 ,,dExn is prohibited. In rule (App) we require that every exception arising from evaluating \nthe function component .ows to the result of the application, that is, d -It2I. Note that we do not have \nthe constraint It1I-It2I,which would be necessary for a strict language. Rule (Try) employs the power \nof Boolean constraints to catch matching exceptions by ex\u00ad istentially quantifying away (the :dex C0 \npart) information about exceptions raised in the sub-expression that would be caught by the try. Only \nexceptions that .ow to the top-most annotation of expres\u00adsion e s type will be caught. Exceptions that \n.ow to other parts of [[x]]. =.(x) [[raise ex]]. ={ex} [[.xe]]. ={.y [[e]].[x :=y]}where y fresh . \n [[ee ' ]]. ={([[e]].)r Ir E[[e ' ]]. ![[e]]. EE1}U(E1n[[e]].) .. [[try ematch [exi -ei]iEI ]]. =iEI \n{[[ei]]. Iexi E[[e]].}U([[e]]. \\iEI {exi}) [[let x =e in e ' ]]. =[[e ' ]].[x :=[[e]].] [[.x x in e]]. \n=.x(.v [[e]].[x :=v]) [[if ethen e1 else e2]]. =(E1n[[e]].) U{v1 Iv1 E[[e1]]. !True E[[e]].} U{v2 Iv2 \nE[[e2]]. !False E[[e]].} Figure 1. Semantics of the Source Language t Is tC I=dex -ItI ((x :: t): .)EG \n(Raiset ) (Var) C,G I((raiset :: Exn -t)(ex :: Exn):: t): t C,G I(x :: t): . C,Gx (x :: t): . I(e :: \nt): . C,G I(e :: t): t2 (Fix) . Is t (Sub) t1 Is tC I=[[t2 :s t1]]sub C,Gx I((.x x :: t in (e :: t)):: \nt): . C,G I(e :: t): t1 d C,G I(e1 :: t1 -t2): (t1 -t2) t1 Is t1 C,Gx (x :: t1): t1 I(e :: t2): t2(Abs) \nd (App) C,G I(e2 :: t1): t1 C I=d -It2I C,Gx I(.(x :: t1)(e :: t2):: t1 -t2): t1 -t2 C,G I((e1 :: t1 \n-t2)(e2 :: t1):: t2): t2 C,Gx I(e1 :: t1): . C,G I(e :: t): t -  (Let) C,Gx (x :: t1): . I(e2 :: t2): \nt (:I) d Sfv(C)\\fv(G,t) -  C,Gx I(let x =(e1 :: t1)in e2 :: t2): t :d C,G I(e :: t): t -  C !D,G I(e \n:: t): t C,G I(x :: t): Vd D t -  (VI) d Sfv(D,t)\\fv(G,C) (VE) C I=[d '/d ]D C !:d D,G I(e :: t): Vd \nD t C,G I(x :: t): [d '/d ]t C,G I(e1 :: Bool): d C,G I(e2 :: t): t C,G I(e3 :: t): t (If) C I=d -ItI \nC,G I((if e1 :: Bool then (e2 :: t)else (e3 :: t)):: t): t C0,G I(e :: t): t0 Ci,G I(ei :: t): ti t Is \nt (Try) Ci ' =[[ti :s t]]sub !Ci - C =C1 ' !!Cn ' !(:It0IC0)!(:dex C0)![[t0 :s t]]sub C,G I(try (e :: \nt)match [(exi :: Exn)-(ei :: t)]iEI :: t): t Figure 2. Exception Logic Example 1 Example 2 C0 =dEx1 -d0 \n!dEx2 -d0 C0,G I(raise Ex1): d0 C0,G I(raise Ex2): d0 C0,G I(if ): d0 (If)dEx3 -d1,G I(raise Ex3): d1 \nd1 -d' !dEx3 -d1 !:d0 C0 !:dEx1 C0 !d0 -d' ,G I(try ): d'(Try) :d0,d1 (d1 -d' !dEx3 -d1 !:d0 C0 !:dEx1 \nC0 !d0 -d' ),G I(try ): d'(:I) dEx2 -d' !dEx3 -d' ,G I(try ): d' C0 =dEx1 -d2 C0,G I.x raise Ex1 : d1 \nd0 -d2 true,G I.x x : d3 d4 -d3 dEx1 -d2 ![[d1 d0 -d2 :s d5 d7 -d6]]sub ![[d3 d4 -d3 :s d5 d7 -d6]]sub,G \nI(try dEx1 -d6,G I(try ): d5 d7 -d6 ): d5 d7 -d6 (Try) (:I) Figure 3. Example Type Derivations e s type \nmust be preserved. This is achieved through the constraint - (:It0IC0)!(:dex C0). Lemma 4 in the Appendix \nformally states - that this constraint only removes primitive constraints between dex and It0I. EXAMPLE \n1. Consider the expression try (if x .y then raise Ex1 else raise Ex2) match Ex1 -raise Ex3 We can show \nthat exceptions Ex2 and Ex3 can escape this expres\u00adsion, using the derivation in Figure 3. For simplicity, \nwe have omitted underlying types and uninteresting deductions. Note that :d0 C0 !:dEx1 C0 =dEx2 -d0. \nThe last step of the derivation is a simpli.cation of the constraints in the previous deduction. EXAMPLE \n2. Consider another expression try . x raise Ex1 match Ex1 -. xx Note that exception Ex1 which appears \nin the body of a func\u00adtion in the try statement won t be caught. A derivation can be found in Figure \n3. In the (Try) step we .nd that (:d0 dEx1 \u00add2)!(:dEx1 dEx1 -d2)=dEx1 -d2. Therefore, in the conclusion \nwe have that dEx1 implies d6 as desired. Our Exception Logic preserves well-shapedness. Let G be an ex\u00adception \ntype environment such that for each ((x :: t): .)EG we have that . Is t and C,G I(e :: t ' ): .'then \n.' Is t '. The Exception Logic is a conservative extension of the underlying type system. That is, all \nexpressions that can be typed in the underlying type system can be given a valid Exception Type by our \nlogic. 3.2 Correctness of Logic In this section we prove the correctness of our Exception Logic. We show \nthat any exceptions which appear in the denotation of an expression are predicted by any valid derivation \nof that expression s Exception Type in our logic. In a .rst step, we enrich the term language of annotations \nby intro\u00adducing set types: Annotations b ::=d IE where E SE. Set types represent solutions of constraints \nin 2IMP. In addition, we extend our constraint language by introducing a sub\u00adset relation among set types. \nC ::=true Id -d IC !C I:d C IE SE Let C be a constraint and let f be a closing substitution (i.e., domain(f)=fv(C)), \nmapping annotation variables to set types. Then we obtain the instantiated constraint fC by the following \ntransformation function: [[f(d1 -d2)]]con =f(d1)Sf(d2) [[f(E1 SE2)]]con =E1 SE2 [[f(C1 !C2)]]con =[[fC1]]con \n![[fC2]]con Without loss of generality we assume that constraints are free of existential quanti.ers. \nWe say a closing substitution f is a solution to a constraint C iff f is a mapping from annotation variables \nto set types, and I=[[fC]]con. We often write I=fC instead of I=[[fC]]con. We will always assume that \nsubstitutions f map variables to set types such that f(dex)= {ex}for ex EE. EXAMPLE 3. The substitution \n[{Ex1}/dE1 ,{Ex2}/dE2 ,{Ex3}/dEx3 ,0//d1,{Ex1}/d2, {Ex2,Ex3,Ex4}/d3] is a solution to the constraint \n(dEx1 -d2)!(dEx2 -d3)!(dEx3 -d3) Constraint solutions allow us to give meaning to exception types. Our \nexception types identify groups of denotations with similar ex\u00adception raising behaviour. We assume that \nsubstitutions operate on types as usual. This extends naturally to type environments. Then, d2 in the \nabove example f(d1 -d3)is the exception type of any func\u00adtional expression that can only raise exception \nEx1 and when ap\u00adplied can raise only exceptions Ex2, Ex3 and Ex4. We say a type t is a monotype iff fv(t)=0/. \nA type scheme . is closed iff fv(.)=0/. We are now in a position to give a meaning to types. The meaning \nfunction [[\"]]maps monotypes and closed type schemes to ideals, i.e., non-empty, downward-closed and \nlimit-closed subsets of V . [[E]] =E U(V \\E) E [[t1 -t2]]={v EV I(v EE)or (v [[t1]]E[[t2]])} - . [[Vd \nC t]]=f{[[ft]]I(fv(ft)=0/)and (I=[[fC]]con)} LEMMA 1. Let . be a closed exception type scheme, then [[.]]is \nan ideal. Let d beavalue in V and . a type scheme. We write d I=v . iff d E[[.]]. This relationship can \nbe extended to sets of denotations. Let ds be 2v a set of values in V . We write ds I=. iff for all d \nEds we have that d I=v .. We let . denote variable environments, mapping variables to sets of values \nin V .Let G be a type environment. We say . models G, written . I=e G,iff forall x : . EG, .(x)I=2v .. \nIn our system a program is evaluated in the context of an initial envi\u00adronment which provides implementations \nfor primitive operations which are not de.nable within the language, e.g., the addition of two integers. \nThe initial type environment describing these primi\u00adtive operations must correctly approximate the behaviour \nof the real primitives in the sense de.ned above. THEOREM 1(CORRECTNESS). Let C,G I(e :: t): . be a valid \ntyping judgement, f be a substitution and . a variable environment such that I=fC, fG is closed, and \n. I=e fG.Then [[e :: t]]. I=2v f.. A proof of this theorem is in the Appendix. We extend function I\"Iwhich \nreturns a type s topmost annotation as follows: I{Ex1,,Exn}I={Ex1,,Exn}. COROLLARY 1. Let C,G I(e :: \nt): t be a valid typing judgement, f be a substitution, ex EE be an exception and . be a variable environment \nsuch that I=fC, fG is closed, . I=e fG and ex E[[e]].. Then, we have that f(dex)SIftI.  4 Exception \nType Inference We employ a standard constraint-based type inference process [8, 7]. Constraints generated \nare in 2IMP which allows for ef.cient constraint manipulation. We assume that we are given a well-typed \nprogram where each subexpression is annotated with its underlying type. Type inference computes the missing \nexception-type information. The inference algorithm shown in Figure 4, is formulated as a deduction system \nover clauses of the form G,(e :: t) Iinf (C,t) with a type environment G and a type-annotated expression \n(e :: t) as input, and a constraint C and a type t as output. In the inference rules we use t Is t to \ndenote the creation of a fresh exception type t of shape t. All inference rules are syntax-directed except \nrule (:Intro). We assume that rule (:Intro) is applied aggressively, so that useless variables do not \nappear in the resulting constraints. In rule (Let) we integrate quanti.cation over free variables. We \nde\u00ad.ne a generalisation function giving the generalised type scheme and the generalised constraint. Let \nC be a constraint, G a type en\u00ad vironment and t a type. Then gen(C,G,t)=(:d C,Vd C t) - where d =fv(C,t)\\fv(G). \nNote that fv(G)only returns the free variables of exception types. We could be more ef.cient by push\u00ading \nin only the affected constraints. Note that we assume ((ex :: Exn): dex)EG for each ex EE. Therefore, \nquanti.cation over dEx1 ,,dExn is prohibited in rules (Let) and (:Intro). In rule (Fix) we perform a \nKleene-Mycroft iteration until a .xed point is found. We de.ne (Vd C t):(Vd 'C't' )iff C' I= - :d (C \n![[t :s t' ]]sub)where w.l.o.g. there are no name clashes be\u00ad tween d and d '. The .xed point operator \nF takes an environment and a type-annotated expression as input and returns a constraint and a type as \noutput. F (Gx (x :: t): .i,e :: t) =F (Gx (x :: t): .i+1,e :: t)if .i <.i+1 =(C,t) if .i =.i+1 where \nGx (x :: t): .i,e :: t Iinf (C,t)and (\",.i+1)=gen(C,Gx (x :: t): .i,t). Note that the sequence .0 ::.i \n:is necessarily .nite. The quanti.er is over annotation variables only, which have a .nite number of \ninstances. Soundness states that every deduction in the inference system is a valid deduction in the \nlogical system. THEOREM 2(SOUNDNESS OF INFERENCE). Let G,(e :: t)Iinf (C,t).Then C,G I(e :: t): t. Completeness \nstates that every deduction derivable in the logical system is subsumed by a deduction in the inference \nsystem. THEOREM 3(COMPLETENESS OF INFERENCE). Assume that - C,G I(e :: t): Vd 1 C1 t1, and G,(e :: t) \nIinf (C2,t2) - and let d 2 =fv(C2,t2)\\fv(G).Then - C !C1 I=:d 2 (C2 ![[t2 :s t1]]sub) It is not too \ndif.cult to perform a simplistic complexity analysis of the inference algorithm. If n is the size of \nthe (underlying) type annotated program, then the number of annotation variables is O(n), and the size \nof any constraint is O(n2). The basic con\u00adstraint operations are: conjunction, which is linear in the \nsum of its arguments hence O(n2); and projection (existential quanti.cation) which naively creates O(n2)constraints \neliminating one variable, and hence is O(n3). In any .xed point calculation there can be at most O(n2)iterations, \nsince each iteration must add one new con\u00adstraint, otherwise we have reached a .xed point. By restarting \nin\u00adtermediate .xed point calculations from the previously computed value, we can ensure that each intermediate \n.xed point calculation also involves at most O(n2)steps in its lifetime. (This is the accel\u00aderated Kleene-Mycroft \niteration of [2]). In total we have O(n)op\u00aderations (even assuming aggressive use of the (:Intro) rule), \neach at t Is tC =dex -ItI (Raiset ) G,((raiset :: Exn -t)(ex : Exn)):: t Iinf (C,t) - -  ((x :: t): \nVd C t)EGd'fresh (Var Inst) - - d' /d ]C,t) G,x :: t Iinf ([ ((x :: t): t)EG (Var .) G,x :: t Iinf \n(0/,t) t Is t d =fv(t).0 =Vd true t (Fix) F (Gxx : .0,e :: t)=(C,t) Gx,(.x x :: t in (e :: t)):: t Iinf \n(C,t) t Is t d fresh (Abs) Gx (x :: t): t,e :: t ' Iinf (C,t' ) Gx,.(x :: t)e :: t -t ' -t' ) Iinf (C,td \nG,e1 :: t2 --t1' ) t1 Iinf (C1,t1 d1 G,e2 :: t2 Iinf (C2,t2) (App) C =C1 !C2 ![[t2 :s t1]]sub !d1 -It' \n1I G,((e1 :: t2 \u00ad t1)(e2 :: t2)):: t1 Iinf (C,t' 1) Gx,e1 :: t1 Iinf (C1,t1) gen(C1,Gx,t1)=(C0,.o) Gx \n(x :: t1): .o,e2 :: t2 Iinf (C2,t2) (Let) C =C0 !C2 Gx,(let x =( e1 :: t1)in (e2 :: t2)):: t2 Iinf \n(C,t2) - d =fv(C)\\fv(G,t) G,e :: t Iinf (C,t) (:Intro) - d C,t) G,e :: t Iinf (: G,e1 :: Bool Iinf \n(C1,d1) G,e2 :: t Iinf (C2,t2)G,e3 :: t Iinf (C3,t3) (If) t Is tC =C1 !C2 !C3 !d1 -ItI![[t2 :s t]]sub \n![[t3 :s t]]sub G,(if e1 :: Bool then (e2 :: t)else (e3 :: t)):: t Iinf (C,t) G,e :: t Iinf (C0,t0) t \nIs t G,ei :: t Iinf (Ci,ti) (Try) Ci ' =[[ti :s t]]sub !Ci - C =C1 ' !!Cn ' !(:It0IC0)!(:dex C0)![[t0 \n:s t]]sub G,try (e :: t)match [(exi :: Exn)\u00ad (ei :: t)]iEI :: t Iinf (C,t) Figure 4. Exception Type \nInference Program Module Lines GHC Only Exception Analysis boyer Main 263 3.52 47% circsim Main 402 7.51 \n29% comp lab zift Main 882 6.73 31% constraints Main 163 3.43 14% eliza Main 228 3.55 28% event Main \n449 3.72 12% fft Main 410 5.16 17% .bheaps Main 116 3.39 45% .sh Main 86 3.99 23% genfft Main 500 4.48 \n16% ida Main 488 4.71 32% nucleic2 Main 650 7.97 788% RA 587 5.33 93% RC 565 5.12 100% RU 604 5.23 104% \npara Main 274 3.43 21% power Main 89 6.04 91% rewrite Main 395 6.13 160% sched Main 553 3.93 42% simple \nMain 859 24.22 142% solid Main 1242 19.94 5% sphere Main 289 6.45 55% typecheck Main 656 5.78 52% wang \nMain 355 4.16 13% wave4main Main 597 5.51 13% Figure 5. Indicative Cost of Exception Analysis worst \nO(n3), performed at most O(n2)times for a total complexity of O(n6). After exception type inference, \na compiler will need to use an entailment operation to extract information about escaping excep\u00adtions. \nHowever, entailment is O(n2), so the total cost is dominated by the cost of inference.  5 Evaluation \nResults We have an implementation of our exception analysis for GHC. GHC de-sugars a well-typed program \nto an explicitly typed, System F style functional language Core. Core is very similar to the source language \nused in this paper. In addition to the analysis described here our implementation has precise support \nfor polymorphism and structured, recursive data. We have used the constraint solver library from our \nprevious work on strictness analysis [7]. The solver is written in C and linked into the compiler. The \nconstraints are represented by a directed graph, variables are nodes and an implication is a connection \nin the graph. To evaluate the practical effectiveness of our inference algorithm we have run our analysis \non the programs in the spectral compo\u00adnent of the nofib suite. The nofib suite is available from the \nGHC implementers. Programs in the spectral component are mainly small, key components of real programs, \nand consists of almost 100 Haskell modules. The programs raise exceptions both directly by calls to the \nHaskell error function and indirectly by compiler inserted error calls for pattern-match failures. None \nof the programs catch exceptions, but we argue that the try construct can be implemented ef.ciently and \nalways reduces the - size of constraints. The constraint (:It0IC0)!(:dex C0)from the (Try) rule can \nbe implemented without copying C0 by simply re\u00ad - moving any direct connections from dex to It0I. Overall, \nfor the 100 modules in the spectral suite the average cost of our analysis was 28% of the compilation \ntime without our analysis. Figure 5 shows analysis times for the 25 spectral modules that take GHC over \n5 seconds to compile. The Lines column shows lines of code. Note the excessive time for the Main module \nin the nucleic2 program. Our analysis has a .ne-grained treatment of structured data. The data structures \nused in nucleic2 are complex, causing the constraints and ts generated for intermediate expressions to \ncontain a large number of variables. A lot of the code in nucleic2 s Main module consists of building \nand destructing data with such types. Such code can be handled ef.ciently by reducing the precision of \nthe analysis. A detailed investigation is left as future work. 6 Related Work and Discussion Previous \nwork [13, 4, 16, 9] on exception analysis for ML-style lan\u00adguages either employed a type and effect system \n[10] or an abstract interpretation based approach to approximate the set of exceptions that can be raised \nduring an expression s evaluation. They all share the assumption that the language is strict, whereas \nwe introduce for the .rst time an exception analysis for a non-strict language. The analysis of Leroy \nand Pessaux [13] uses a type and effect sys\u00adtem based on equality constraints and re.nement types. Equality \nconstraints allow for an ef.cient solving of exception constraints, but equality constraints might cause \nloss of precision in some cases. Consider the following example let id =. xx in let app0 =. f (f 0)(try \nf 0 match NotReally -0)in let res =app0 id in res In the type and effect system the try expression in \napp0 s right hand side infects the deduced type for argument f . It is given the excep\u00adtion type of a \nfunction that can raise exception NotReally.Since f is required for the result of app0, this further \ninfects app0 s type. Now any use of app0, such as the innocent application to id in the de.\u00adnition of \nres, will have exception NotReally escaping. The problem is caused by the use of uni.cation constraints \nwhich force equality. In this situation we use an inequality constraint(\":s \"). On the other hand, there \nare also examples where Leroy and Pes\u00adsaux s use of re.nement types allows for a result which is more \nprecise than that which we obtain. Moreover, they combine their analysis with a data .ow analysis, which \nallows them to give useful results for programs using .rst class exceptions and exceptions that carry \narguments. A more precise analysis based on inclusion constraints over set\u00adexpressions is considered \nby F\u00a8ahndrich and Aiken. Their approach relies on a parameterised formalism that combines inclusion con\u00adstraints \nover terms and sets [3]. Yi [16] describes an exception analysis based on abstract interpre\u00adtation. This \nanalysis is very .ne-grained and there is an associated high cost and high precision. Our development \nand implementation of this exception analysis has gained signi.cantly from previous experiences with \na binding-time analysis. Exception and binding-time analysis are essentially forms of control-.ow analysis. \nThe analyses therefore share the same con\u00adstraint domain 2IMP. In [8], we experimented with more powerful \nBoolean domains. For example, if we allow for constraints of the form (d -d' )-C we are able to give \na more precise description of the (Try) rule. C0,G I(e :: t): t0 Ci,G I(ei :: t): tit Is t Ci ' =(dexi \n-It0I)-([[ti :s t]]sub !Ci) - C =C1 ' !!Cn ' !(:It0IC0)!(:dex C0)![[t0 :s t]]sub C,G I(try (e :: t)match \n[exi -(ei :: t)]iEI::t ]:: t): t The result of the branches will affect the .nal result only if the cor\u00adresponding \nexception will actually be raised. In our experience [8], the gain of a more precise analysis does not \njustify the cost of slower analysis times. In Java, ML and Haskell, exceptions are .rst class values, \nthat is, they can be passed to and returned from functions, stored in data structures, passed to polymorphic \nfunctions and so on. Consider the following function: anyButC :: Exn -Int anyButC exn =try (raise exn) \nmatch ExC -1 We would like to give anyButC a type that says it raises any ex\u00adception in the argument \nexcept ExC. Additionally, evaluating the argument may raise an exception and ExC must be stripped from \nthis too. Brie.y, this could be supported by our constraint system if we re\u00adplace our annotation variables \nby a vector of annotation variables, one per possible exception. An exception would be represented by \nconstraining the corresponding variable to be true. When matching an exception we would use existential \nquali.cation to disconnect any constraints on matched exceptions. A more detailed, formal discussion \nof this is in the .rst author s forthcoming PhD thesis. F\u00a8ahndrich and Rehof have recently proposed a \nnew method for .ow analysis [5] for the ef.cient analysis of recursive de.nitions in the presence of \npolymorphic .ow types. In the absence of recursive types, the method offers improved worst-case time \ncomplexity for .ow analysis, namely cubic time analysis. Although our analysis has a higher worst-case \ncomplexity, our empirical results clearly show the feasibility of our approach. Our semantics differs \nin some respects from that proposed by Pey\u00adton Jones et al. [14]. Our de.nition is entirely denotational, \nwhereas [14] uses a mixture of denotational and operational semantics. More importantly, the semantics \nof [14] serves a different purpose, and is generally more slack than ours. For a function application \nee ', where both e and e 'may give abnormal results, we utilise the non-strictness of e to disregard \nthe abnormal values from e ',that is, the result is just the abnormal values of e. Similarly, for a condi\u00adtional \nexpression if e then e1 else e2, we do not care about abnormal values from e1 and e2 if it turns out \nthat e only produces abnormal results. In contrast, the semantics of [14] stipulate that the branches \nof the conditional still be scrutinised for abnormal results. The reason why Peyton Jones et al. [14] \nprefer the less precise se\u00admantics is a desire to have the semantics justify a number of pro\u00adgram transformations \nthat a compiler may try, such as strictness transformations and GHC s case-case transformation. For example, \nconsider the following function which is strict in both its arguments addPair :: (Int,Int)-(Int,Int)-(Int,Int) \naddPair xp yp =case xp of (x1,x2)-case yp of (y1,y2)-(x1 y1,x2 y2) Clearly an abnormal value Ex from \nthe .rst argument will be raised rather than one (say, Ey) from the second argument. Changing the order \nin which the arguments are scrutinised can therefore change the (abnormal) result of an application of \naddPair. Yet an optimis\u00ading Haskell compiler is in the habit of making exactly such trans\u00adformations, \nand it would be unfortunate to ban them. The answer in [14] is that in either case, Ex and Ey should \nboth be included. We make no judgement about the usefulness of this or that system of exceptions for \na non-strict functional language. The semantic issues are far from straight-forward. We saw in Section \n1 how non\u00addeterminism in exceptions can leak into the language proper, since we can use try (or any similar \nexception handling mechanism) to construct an expression amb which may evaluate to either 0 or 1. This \nraises the well-known problem that either beta reduction is lost, or else variables become inde.nite, \nas is the case for the se\u00admantics we have proposed. More speci.cally, given the semantics proposed for \n+ , the value of amb amb may be odd: it can be 0, 1, or 2. A different anomaly is that changing evaluation \norder may return a result where a non-strict language s usual order does not. The in\u00adtention with the \nmeta-language used in Figure 1 is that function ap\u00adplication is non-strict, so if loop is an expression \nwhose evaluation does not terminate, then (.x loop)(raise Ex)also fails to terminate. Hence, so does \ntry (. x loop)(raise Ex) match Ex -1 With strict function application, however, the value of(.x loop)(raise \nEx)is the exception Ex,so the try expres\u00adsion has value 1. 7Conclusion We have presented an analysis \nfor escaping exceptions in a non\u00adstrict language, and we have established its correctness. The analy\u00adsis \ndiscovers exceptions that could possibly be raised and not caught within an expression. It is formulated \nas a constrained-type infer\u00adence system, using Boolean constraints to capture the (sometimes intricate) \ndependencies that are needed to reason about control .ow. The work is part of a bigger effort to build \na general constraint\u00adbased analysis framework for non-strict functional languages with polymorphic programs \nand structured data, much in the spirit of [6]. We have found that Boolean constraints have many useful \nfeatures in the context of analysis as constrained-type inference . Boolean constraints make the formulation \nof a polyvariant analy\u00adsis easy (by polyvariance we mean property polymorphism , that is, an analyser \ns ability to infer different properties for a function f at separate applications of f , in a manner \nsimilar to type infer\u00adence for a polymorphic language). They also help achieve modu\u00adlarity of analysis, \nthat is, the ability to produce analysis results that are context-independent, so as to support separate \ncompilation. Al\u00adthough we have not described the extension to a polymorphically typed language in this \npaper, our implementation does handle this, and also structured data, and in fact the Boolean constraint \napproach supports such extensions very well. Many important subclasses of Boolean functions are closed \nunder existential quanti.cation. This is useful, since in many contexts existential quanti.cation is \nthe logical counterpart to the principle of eliminating irrelevant variables (thus restricting attention \nto relevant variables). In Section 3.1 we pointed out instances where existential quanti.cation gave \nus an elegant formulation of variable elimination, for example in the rule for try. Our evaluation results, \nfor a version of GHC with our analysis in\u00adcorporated, indicate that the analysis is practical, and a \nrough com\u00adplexity analysis shows that the analysis is O(n6), a bound which can possibly be improved. \nAcknowledgements We thank the reviewers for their helpful comments. 8 References [1] K. Arnold, J. Gosling, \nand D. Holmes. The Java Programming Language. Addison-Wesley, third edition, 2000. [2] D. Dussart, F. \nHenglein, and C. Mossin. Polymorphic re\u00adcursion and subtype quali.cations: Polymorphic binding-time analysis \nin polynomial time. In A. Mycroft, editor, Proc. Sec\u00adond Int. Symp. Static Analysis, volume 983 of Lecture \nNotes in Computer Science, pages 118 135. Springer, 1995. [3] M. F\u00a8ahndrich and A. Aiken. Program analysis \nusing mixed term and set constraints. In P. Van Hentenryck, editor, Static Analysis: Proc. Fourth Int. \nSymp., volume 1302 of LNCS, pages 114 126. Springer, 1997. [4] M. F\u00a8ahndrich and A. Aiken. Re.ned type \ninference for ML. In First International Workshop on Types in Compila\u00adtion (TIC 97), 1997. [5] M. F\u00a8ahndrich \nand J. Rehof. Type-based .ow analysis: From polymorphic subtyping to CFL reachability. In Proc. 28th \nACM Symp. Principles of Programming Languages, pages 54 66. ACM Press, 2001. [6] J. S. Foster, M. F\u00a8ahndrich, \nand A. Aiken. A theory of type quali.ers. In Proc. 1999 ACM Conf. Programming Language Design and Implementation, \npages 192 203. ACM Press, 1999. [7] K. Glynn, P. J. Stuckey, and M. Sulzmann. Effective strict\u00adness analysis \nwith Horn constraints. In P. Cousot, editor, Static Analysis: Proc. Eighth Int. Symp. Static Analysis,vol\u00adume \n2126 of Lecture Notes in Computer Science, pages 73 92. Springer, 2001. [8] K. Glynn, P. J. Stuckey, \nM. Sulzmann, and H. S\u00f8ndergaard. Boolean constraints for binding-time analysis. In O. Danvy and A. Filinsky, \neditors, Programs as Data Objects: Proceed\u00adings of the Second Symposium, volume 2053 of LNCS, pages 39 \n63. Springer, 2001. [9] J. Guzm\u00b4an and A. Su\u00b4arez. An extended type system for ex\u00adceptions. In ACM SIGPLAN \nWorkshop on ML and Its Appli\u00adcations, 1994. [10] P. Jouvelot and D. Gifford. Algebraic reconstruction \nof types and effects. In Proc. 18th ACM Symp. Principles of Program\u00adming Languages, pages 303 310. ACM \nPress, 1991. [11] X. Leroy. The Objective Caml system, 1996. http://pauillac.inria.fr/ocaml/. [12] R. \nMilner, M. Tofte, and R.W. Harper. The De.nition of Stan\u00addard ML. MIT Press, Cambridge, Massachusetts, \n1990. [13] F. Pessaux and X. Leroy. Type-based analysis of uncaught exceptions. In Proc. 26th ACM Symp. \nPrinciples of Program\u00adming Languages, pages 276 290. ACM Press, 1999. [14] S. L. Peyton Jones, A. Reid, \nT. Hoare, S. Marlow, and F. Hen\u00adderson. A semantics for imprecise exceptions. In Proc. 1999 ACM SIGPLAN \nConf. Programming Language Design and Implementation, pages 25 36. ACM Press, 1999. [15] S. Peyton Jones \net al. Report on the programming language Haskell 98. Technical report, February 1999. http:/haskell.org. \n[16] K. Yi. An abstract interpretation for estimating uncaught ex\u00adceptions in Standard ML programs. Science \nof Computer Pro\u00adgramming, 31(1):147 173, 1998. APPENDIX: CORRECTNESS PROOF First let us introduce some \nuseful lemmas. LEMMA 2. Let C I=dex -ItIand I=fC for some substitution f such that f(dex)={ex}.Then ex \nE[[ft]]. LEMMA 3. Let t1 and t2 be two monotypes such that I=[[t1 :s t2]]sub.Then [[t1]]S[[t2]]. LEMMA \n4. Let C be a constraint, d0,dex1 ,,dexn be variables such that C consists only of primitive constraints \nof the form d -d' , d0 does not appear on the left-hand side and dexi s do not appear on the right-hand \nside of an implication. Let d and d'be variables such that d differs from dex1 ,,dexn, d'differs from \nd0 and C I=d -d' . - Then (:d0 C)!(:dex C)I=d -d' . THEOREM 1(CORRECTNESS). Let C,G I(e :: t): . be \na valid typing judgement, f be a substitution and . a variable environment such that I=fC, fG is closed \nand . I=e fG.Then [[e :: t]]. I=2v f.. We prove correctness by induction over type derivations. We note \nthat applying substitutions f to type schemes . might result in type schemes of the form Vd1 {Ex1}-d1 \n. Clearly, this type scheme is not a valid member of any of the syntactic domains presented. The important \npoint is that eventually we will substitute d1 by a ground value. Therefore, the translation function \n[[\"]]con will not get stuck and will work correctly. We will also assume that the meaning function [[\"]]for \nexpressions in Figure 1 also applies to type-annotated expressions (simply by erasing the underlying \ntypes). For convenience we will sometimes omit some of the underlying type annotations. Case (Var): We \n.nd the following situation (x : .)EG. Is t C,G I(x :: t): . From the assumption . I=e fG so .(x)I=2v \nf..From the se\u00admantic equations [[x :: t]]. =.(x)so [[x :: t]]. I=2v f. as re\u00adquired. Case (Raiset ): \nWe .nd the following situation t Is tC I=dex -ItI C,G I((raiset :: Exn -t)(ex :: Exn):: t): t From the \nassumption we have that I=fC. We can immediately follow that [[(raiset :: Exn -t)(ex :: Exn):: t]]I=2v \nft. Case (Abs): We .nd the following situation t1 Is t1 C,Gx (x :: t1): t1 I(e :: t2): t2 d C,Gx I(.(x \n:: t1)(e :: t2):: t1 -t2): t1 -t2 0/ We want to show [[.xe]]. I=ft1 -ft2. Note that w.l.o.g. f(d)=0/. \nWe .nd the following equivalences. 2v 0/ [[.xe]]. I=ft1 -ft2 iff 0/ [[.xe]]. S[[ft1 -ft2]] iff [[.xe]]. \nS{v Iv [[ft1]]E[[ft2]]} iff (def. of [[.xe]].) {.y [[e]].[y/x]}S{v Iv [[ft1]]E[[ft2]]} iff [[e]].[[[ft1]]/x]S[[ft2]] \nLet .' =.[[[ft1]]/x]then application of the induction hypoth\u00adesis to the premise yields [[e]].' I=2v \nft2. The last equivalence is ful.lled. Therefore, we can establish the induction step and we are done. \nCase (App): We .nd the following situation d C,G I(e1 :: t1 -t2): (t1 -t2) C,G I(e2 :: t1): t1 C I=d \n-It2I C,G I((e1 :: t1 -t2)(e2 :: t1):: t2): t2 Applying the induction hypothesis to the two premises \n(we silently extend f such that ft1 is ground) yields [[e1 :: t1 \u00ad2v d 2v t2]]. I=f(t1 -t2)and [[e2 :: \nt1]]. I=ft1. Recall the semantic equation . [[e1 e2 :: t2]]. ={([[e1]].)r Ir E[[e2]]. ![[e1]]. EE} U(E1n[[e1]].) \nWe want to show [[e1 e2 :: t2]]. I=2v ft2,thatis, [[e1 e2 :: t2]]. S [[ft2]]. We distinguish among the \nfollowing cases: 1. ex E[[e1]].: In such a situation, we know that C I=dex -d.From C I=d -It2Iit follows \nthat C I=dex -It2I. Therefore, ex E[[ft2]](by Lemma 2). 2. is in every exception type. 3. w E[[e1 e2 \n:: t2]]. where f E([[e1]].\\E)and w E f [[e2]].: f(d) It follows that f E[[ft1 -ft2]]. By de.nition of \nf(d) [[ft1 -ft2]]we .nd that w E[[ft2]]and we are done. Case (Let): We .nd the following situation C,Gx \nI(e1 :: t1): . C,Gx (x :: t1): . I(e2 :: t2): t C,Gx I(let x =(e1 :: t1)in e2 :: t2): t We apply the \ninduction hypothesis to the .rst premise and .nd that [[e1 :: t1]]. I=2v f.. We apply the induction hypothesis \nto the second premise (there is a double induction going on and we would need to include the type environment \nin our induction argument, but the details are straight-forward and omitted here) and .nd that [[e2 :: \nt2]]. I=2v ft which establishes the induction step. Case (:I): We .nd the following situation C,G I(e \n:: t): t - d Sfv(C)\\fv(G,t) - :d C,G I(e :: t): t - By assumption I=f:d C and . I=e fG for some substitution \n- f.We .nd . such that I=.C. Note that d Efv(G,t).We apply the induction hypothesis to the premise and \n.nd that [[e :: t]]. E[[ft]]and we are done. Case (If): We .nd the following situation C,G I(e1 :: Bool): \nd C,G I(e2 :: t): t C,G I(e3 :: t): t C I=d -ItI C,G I((if e1 :: Bool then (e2 :: t)else (e3 :: t)):: \nt): t Consider the semantic equation [[if e1 then e2 else e3]]. = (E1n[[e1]].) U{v1 Iv1 E[[e2]]. !True \nE[[e1]].} U{v2 Iv2 E[[e3]]. !False E[[e1]].} We distinguish among the following cases: 1. v2 E[[e2]]. \n!True E[[e1]].: We can apply the induction to the then branch and im\u00admediately .nd that v2 I=v ft. 2. \nv3 E[[e3]]. !False E[[e1]].: Similarly, we apply the induction hypothesis to the else branch and .nd \nthat v3 I=v ft. 3. is in every exception type. 4. ex E[[e1]].: We have ex E[[ft]], by the constraint \nI=d -ItIand  Lemma 2. Case (VI): We .nd the following situation C !D,G I(e :: t): t - d Sfv(D,t)\\fv(G,C) \nC !:d D,G I(e :: t): Vd D t - By assumption I=fC !f(:d D)and . I=e fG for some sub\u00adstitution f. W.l.o.g. \nwe .nd . such that I=.D and f :. (that is, there exists f'such that f' \u00c6f =.). The induction hypothesis \napplied to the premise yields [[e :: t]]. E[[.t]].We - immediately .nd that [[e :: t]]. E[[f(Vd D t)]]and \nwe are done. Case (VE): We .nd the following situation - C,G I(x :: t): Vd D t C I=[d ' /d ]D C,G I(x \n:: t): [d ' /d ]t e By assumption wehavethat I=fC, . I=fG, fG and f[d ' /d ]t closed for some substitution \nf. The induction hy\u00ad - pothesis applied to the premise yields [[x :: t]]. E[[f(Vd D - t)]]. We note \nthat [[f(Vd D t)]]S[[f't]]where f' =f \u00c6 [d ' /d ]. This establishes the induction step. Case (Fix): We \n.nd the following situation C,Gxx : . I(e :: t): . . Is t C,Gx I((.x x :: t in e):: t): . . Note that \n[[.x x in e]]. =.x(.v [[e]].[x :=v])=fn n where f =.v [[e]].[x :=v]. We show, by induction, that fi .E[[f.]]for \nany i ;0. Case i =0: By de.nition .E[[f.]]. Case ii 1: We have that fi+1 =f (fi )=[[e]].[x := fi ]. By \ninduction fi .E[[f.]], therefore .' =.[x :=fi ] is well-de.ned. We .nd that .' I=e fG x : f.. We can \napply the induction hypothesis to the .rst premise. We .nd that [[e]].' E[[f.]], therefore fi+1 .E[[f.]]which \nconcludes the induction step. Note that ideals are limit closed, hence .x(f )E[[f.]]. Case (Try): We \n.nd the following situation: C0,G I(e :: t): t0 Ci,G I(ei :: t): ti t Is t Ci ' =[[ti :s t]]sub !Ci - \nC =C1 ' !!Cn ' !(:It0IC0)!(:dex C0)![[t0 :s t]]sub C,G I(try (e :: t)match [exi -(ei :: t)]iEI :: t): \nt By assumption, I=fC, fG closed, . I=e fG.We want to show that [[try (e :: t)match [(exi :: Exn)-(ei \n:: t)]iEI :: t]]. I=2v ft iff [[try (e :: t)match [exi :: Exn -(ei :: t)]iEI :: t]]. S[[ft]] where [[try \n(e :: t)match [(exi :: Exn)-(ei :: t)]iEI ]]. = . . iEI {[[ei]]. Iexi E[[e]].}U([[e]]. \\iEI {exi}) We \ndistinguish between the following cases: - 1. Case v E[[e]]. and v Eex: Let d0 =It0I.Let f'be a substitution \nsuch that f' (d0)= - f(d0)Uex, f' (dex)=f(dex)and f and f'agree on all - variables except those in \ndex U{d0}. We prove that I=f'C0. Assume the contrary. That is, there exists d -d' EC0 such that f' (d)Sf' \n(d' ). Con\u00adsider the following three cases. - (1) Assume d differs from dex and d'differs from d0. Note \nthat I=fC. Application of Lemma 4 leads imme\u00addiately to a contradiction. (2) Assume d' =d0 then again \nwe .nd a contradiction because f' (d0)represents the largest possible set. (3) Assume d =dexi for some \ni and d'differs from d0. Note that I=C -:It0IC0 and I=fC. Therefore, f' (d)Sf' (d' )which contradicts \nour assumption.  We conclude that I=f'C0. Application of the induc\u00adtion hypothesis to C0,G I(e :: t): \nt0 yields [[e]]. I=2v f't0.We also have that [[ft0]]S[[ft]](follows from - I=f[[t0 :s t]]sub and Lemma \n3). Note that [[f't0]]-ex = - [[ft0]]. By assumption v Eex. We can conclude v E[[ft]] and we are done. \n2. Case v E[[e ' i]]. !exi E[[e]].: Again we extend f to f'such that I=f'C0. By assump\u00adtion exi E[[e]].. \nApplication of the induction hypothesis to C0,G I(e :: t): t0 and applying the Corollary yields f' (dexi \n)SIf't0I. We know that C I=[[ti :s t]]!Ci.We .nd that I=f([[ti :s t]]!Ci). We can apply the induc\u00adtion \nhypothesis to Ci,G I(ei ' :: t): ti and obtain that 2v [[ei' ]]. I=fti. Then by Lemma 3, [[fti]]S[[ft]]. \nHence, 2v [[e ' i]]. I=ft. Finally, we can conclude that v E[[ft]], and we are done.  \n\t\t\t", "proc_id": "581478", "abstract": "In this paper we present the first exception analysis for a non-strict language. We augment a simply-typed functional language with exceptions, and show that we can define a type-based inference system to detect uncaught exceptions. We have implemented this exception analysis in the GHC compiler for Haskell, which has been recently extended with exceptions. We give empirical evidence that the analysis is practical.", "authors": [{"name": "Kevin Glynn", "author_profile_id": "81100645684", "affiliation": "Universit&#233; catholique de Louvain, Belgium", "person_id": "P394768", "email_address": "", "orcid_id": ""}, {"name": "Peter J. Stuckey", "author_profile_id": "81100133272", "affiliation": "The University of Melbourne, Vic., Australia", "person_id": "PP14057424", "email_address": "", "orcid_id": ""}, {"name": "Martin Sulzmann", "author_profile_id": "81100115708", "affiliation": "National University of Singapore", "person_id": "PP39028024", "email_address": "", "orcid_id": ""}, {"name": "Harald S&#248;ndergaard", "author_profile_id": "81100210657", "affiliation": "The University of Melbourne, Vic., Australia", "person_id": "P394763", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/581478.581488", "year": "2002", "article_id": "581488", "conference": "ICFP", "title": "Exception analysis for non-strict languages", "url": "http://dl.acm.org/citation.cfm?id=581488"}