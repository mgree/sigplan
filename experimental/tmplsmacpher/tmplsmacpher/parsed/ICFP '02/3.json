{"article_publication_date": "09-17-2002", "fulltext": "\n Monads for Incremental Computing Functional Pearl Magnus Carlsson OGI School of Science &#38; Engineering \nOregon Health &#38; Science University magnus@cse.ogi.edu Abstract This paper presents a monadic approach \nto incremental computa\u00adtion, suitable for purely functional languages such as Haskell. A program that \nuses incremental computation is able to perform an incremental amount of computation to accommodate for \nchanges in input data. Recently, Acar, Blelloch and Harper presented a small Standard ML library that \nsupports ef.cient, high-level incremental computations [1]. Here, we present a monadic variant of that \nli\u00adbrary, written in Haskell extended with .rst-class references. By using monads, not only are we able \nto provide a purely functional interface to the library, the types also enforce correct usage with\u00adout \nhaving to resort to any type-system extension. We also .nd op\u00adtimization opportunities based on standard \nmonadic combinators. This is an exercise in putting to work monad transformers with en\u00advironments, references, \nand continuations. Categories and Subject Descriptors D.1 [Software]: Programming Techniques  General \nTerms Algorithms, Design, Languages 1 Introduction It is often a tedious task to translate a library \nfrom an imperative language into a purely functional language. Types need to mir\u00adror where different \neffects may happen, and here, the standard ap\u00adproach is to use monads [16]. The reward is that the interface \nof the purely functional library is more precise about what effects differ\u00adent operations have. It can \nalso happen that monads lead us to an interface that is simpler, and more precisely captures how the \nop\u00aderations can be correctly combined. The exercise described in this paper is an example of this. Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 02, October \n4-6, 2002, Pittsburgh, Pennsylvania, USA. Copyright 2002 ACM 1-58113-487-8/02/0010 ...$5.00 Our starting \npoint is the elegant mechanism for high-level incre\u00admental computation presented in [1]. The paper comes \nwith a 69\u00adline Standard ML [11] library that under the hood maintains a dependency graph to support ef.cient \nrecomputation due to incre\u00admental changes in the input. Using this library, a programmer can develop \napplications that support incremental computing on a high level, without having to deal with the intricacies \nof checking if re\u00adcomputation is needed, or keeping the necessary data dependencies consistent. This \nis demonstrated by examples in [1] and in the fol\u00adlowing sections. We will show how the ML library can \nbe turned into a purely func\u00adtional Haskell [13] module, using .rst-class references. In the next section, \nwe give an example of incremental program\u00adming, and present the ML library, which is our starting point. \nSec\u00adtion 2 develops a monadic interface in Haskell, based on considera\u00adtions on how the interface should \nbe used, and on the ML interface. Section 3 puts the monadic interface to a more serious test by us\u00ading \nit for two larger examples: the incremental Quicksort, and a spreadsheet embryo. We describe the key \nparts of the monadic im\u00adplementation in Section 4, and Section 5 concludes. 1.1 The ML Library Using \nthe library from [1], we can express the following incremen\u00adtal computation in Standard ML: let val m \n= mod (op=) (fn d => write(d,1)) val mplus1 = mod (op=) (fn d => read(m,fn v => write(d,v+1))) in change \n(m,2); propagate() end This de.nes m to be a modi.able integer, with the value 1. It also de\u00ad.nes the \nmodi.able mplus1, to be whatever value m has, plus 1.We then change the value of m to 2, and instruct \nthe library to propagate that change to all dependent modi.ables. The incremental library uses the comparison \noperation we supplied (op=) to decide that the new value of m really is different from the old. It keeps \ntrack of the fact that mplus1 must be recomputed, since it read the value of m. The recomputation is \ndone by applying fn v => write(d,v+1) to the modi.ed value of m. As a result, mplus1 will change to 3. \nThis concludes our .rst, somewhat trivial example of an incremen\u00adtal computation. The complete signature \nof the ML library is given in Figure 1. Note that Acar et al. talks about adaptive computation, but in \nwhat signature ADAPTIVE = sig type a mod type a dest type changeable val mod: ( a * a -> bool) -> ( a \ndest -> changeable) -> a mod val read: a mod * ( a -> changeable) -> changeable val write: a dest * a \n-> changeable val change: a mod * a -> unit val propagate: unit -> unit val init: unit -> unit end Figure \n1. Interface for the SML adaptive library follows, we will mainly use the more traditional term incremental \ncomputation. The type a mod stands for a modi.able (variable) of type a. These modi.ables are de.ned \nby mod and write, changed by change and propagate, and read by read. The types prevent a user from di\u00adrectly \nreading a modi.able: since the values of modi.ables might change, it only makes sense to read them while \nde.ning values of other modi.ables.1 The vehicle here is the type changeable, which represents a computation \nthat might depend on other modi.ables, and thus might need to be recomputed. Changeables are expres\u00adsions \nthat read zero or more modi.ables in a continuation-passing style, and .nally write to the modi.able \nbeing de.ned or updated. It is the job of the destination parameter (of type a dest), pro\u00advided by mod, \nto keep track of which modi.able should be written. In the example we saw, the destination parameters \nwere called d. There is one more operation in the ML library: init. This is a meta operation used to \ninitialize the library. 1.2 Correct usage For the library to work correctly, each changeable expression \nmust use its destination exactly once, in a write operation (this is called correct usage in [1]). Unfortunately, \nthe types of the operations are not precise enough to prevent incorrect usage. Here are two examples \n(we will abstract over the comparison operations in the following as cmp, cmp etc): mod cmp (fn d => \nwrite(d,1); write(d,2)): Incorrect the destination is used in two write operations. mod cmp (fn d => \nwrite(d, mod cmp (fn d => write(d,1)))): Incorrect the desti\u00adnation d is used more than once and d is \nnot used in any write operation. The implementation of the ML library given in [1] does checks at runtime \nthat catch some incorrect uses, but not all. To ensure correct usage statically, a special-purpose functional \nlanguage with a modal type system is presented in [1]. Is it possible to design the interface of the \nlibrary so that correct us\u00adage can be statically ensured, without any type-system extensions? In what \nfollows, we will see how a monadic framework can guide us toward a solution. 1Therefore, any interesting \nadaptive program using this inter\u00adface must ultimately rely on side effects to make the values of mod\u00adi.ables \nobservable.  2 Translation into Haskell How should we approach the problem of translating the ML library \ninto the purely functional Haskell? Here, readers might stall and say that there is not much we can do \nbefore we have looked at the implementation behind the interface in Figure 1. Naturally, we will do this \nin due time. However, it is useful to start out by taking a step back and just look at the interface, \nthe types of its operations, and use patterns. 2.1 Use patterns for changeables Changeables are written \nin a continuation-passing style (CPS) in which a number of modi.ables are read, followed by a write oper\u00adation \nto a destination. Here is an example: m = mod cmp (fn d => read(m1, fn v1 => let val x= fv1 in read(m2, \nfn v2 => letvaly= gv1v2in write(d,(x,y)) end) end)) This style makes the order of the read operations \nexplicit, and the ML library observes these to build a dependency graph that de\u00adscribes the work needed \nto recompute m given changes of m1 or m2. If m1 changes, the subexpression fn v1 => ... needs to be recom\u00adputed, \nwhich involves calling f and g.If m2 changes, but not m1,we only need to recompute fn v2 =>..., which \nonly involves calling g.  2.2 The relation between CPS and monads We can easily adopt the CPS for our \nHaskell library, but we actu\u00adally bene.t from using a monadic style instead. There is a close correspondence \nbetween continuations and monads [16]. In CPS, operations take a continuation, which is of some answer \ntype A. This continuation is possibly parameterized by some value that the operations provide. Operations \nof type (a . A) . A correspond to a monadic operation C a, and we can think of these types as syn\u00adonyms. \nAs an example, assuming we have the CPS operations op1 and op2, we can de.ne an adding combinator op3 \n(from now on, we will use Haskell syntax): op3k= op1(\\a -> op2 (\\b->k (a+b))) The combinator can be expressed \nin a monadic style instead, elim\u00adinating the continuation parameter: op3 :: C Integer op3 = op1 >>= \\a \n-> op2 >>= \\b -> return (a + b) Here we have assumed the following types for the operations: op1 :: \nC Integer op2 :: C Integer (>>=) ::Ca->(a->Cb) -> Cb return :: a-> C a The last two operations are the \nbind and unit operations that ev\u00adery monad has. So far, the monadic style might seem complicated compared \nto CPS, where we didn t have to use bind and unit. But the bene.t is that we have eliminated the continuation \nparameter, thereby preventing derived operations from using non-local jumps. newtype A a newtype C a \nFor example, using CPS, nothing prevents us from de.ning an op\u00ad eration bad that ignores the continuation \nparameter and instead in\u00ad newtype Mod a vokes some other continuation that happens to be in scope: instance \nMonad A instance Monad C bad k =op1 (\\a ->op2 (\\b -> k (a + b))) class Monad m => NewMod m where By \nhiding the continuation inside the abstraction barrier of a monad, newModBy :: (a -> a -> Bool) -> C \na -> m (Mod a) we can keep better control over how it is used. Now, this is good instance NewMod A news! \nIt indicates that we are approaching a solution that prevents instance NewMod C the incorrect usage examples \ngiven in Section 1.2. A key observa\u00ad newMod :: (NewMod m, Eq a) => C a -> m (Mod a) tion is that the \ndestination parameter, in conjunction with the write readMod :: Mod a -> C a operation, plays the role \nof a continuation that can be hidden from the user. change ::Moda-> a->A() propagate :: A () 2.3 Changeables \nas monads Figure 2. Interface for the Haskell adaptive library. Let us look at the types of the operations \nfrom Figure 1 that involve changeables. We will adapt these types to Haskell by capitalizing Let us make \nthe design decision that the imperative change and type constructors and using curried functions: propagate \noperations should be prevented inside changeables. This suggests that these operations live in another \nmonad, which we can mod :: (a -> a-> Bool) -> call A for Adaptive. The monadic types for change and propagate \n (Dest a -> Changeable) -> Mod a read :: Mod a -> (a -> Changeable) -> Changeable will then be: write \n:: Dest a -> a -> Changeable change :: Moda-> a-> A() propagate :: A () From what we have learned, we \nsee that the read operation stands out as a candidate for a monadic operation that we can name How do \nwe create modi.ables to start with? The type of readMod: correctMod only allows for the creation of modi.ables \ninside other modi.ables! Why not allow creation of modi.ables in the A monad readMod ::Moda->C a too? \nHere, Ca is the monadic type that corresponds to the CPS type (a correctModA :: (a -> a -> Bool) -> C \na -> A (Mod a)-> Changeable) -> Changeable. Experienced Haskell programmers will immediately spot that \nthis What is the monadic analog to write? Answer: nothing at all! As type is a candidate for an overloaded \noperation. Let us de.ne a we already mentioned, we want the write operation to be part of the class NewMod, \nand assume we have NewMod instances for the A and Ccontinuation that we hide from the user. Another way \nof saying this monads. The overloaded operation has type is that instead of providing the write operation \nto the programmer, we put it into the mod operation itself. This makes sense, since the NewMod m =>(a \n-> a -> Bool) -> C a-> m (Mod a) write operation concludes every correct changeable. Intuitively, it \nshould be almost effortless to push it over the edge , effectively Not only does this allow us to use \nthe same name in both A and Cfactoring it out. We can try to capture the correct usage pattern by for \ncreating modi.ables, it also enables us to derive more operations providing the derived operation correctMod \ninstead of mod: that can be used in both monads. correctMod :: (a -> a -> Bool) -> C a -> C (Mod a) correctMod \ncmp c = mod cmp (\\d -> c (\\a -> write d a)) While we have our overloading hat on, our attention is drawn \nto the comparison operation of type a -> a -> Bool. In cases like this, We will re.ne this in a moment; \nby this de.nition we merely try to there is a tradition in Haskell libraries [12] to provide two opera\u00adconvey \nthe intuitive relation with the original mod operation. Note tions, one which is conveniently overloaded \nin the Eq class, and that we need a monadic type for correctMod: otherwise, the effects one which gives \nprecise control over the comparison operator. For in its argument c cannot be performed. So correctMod \nexecutes example, we have the nub and nubBy functions from the List library: c, returning a new modi.able. \nNote also that since correctMod nubBy :: (a -> a -> Bool) -> [a] -> [a] is an operation in C, it is possible \nto create modi.ables inside the nub :: (Eq a) => [a] -> [a] creation of other modi.ables. This is particularly \nuseful for de.ning nub = nubBy (==) recursive data structures that contain modi.ables, as we shall see \nin Section 3.1. We will follow this tradition, and provide the convenient operation newMod with which \nusers don t have to specify the comparison op-Now, it is time to look at the remaining operations that \nlet us change eration. Thus, we end up with a library interface that we summarize the values of a number \nof modi.ables, and then to propagate the in Figure 2. changes. These are highly imperative in nature \nand access and manipulate the underlying dependency graph. Therefore, it makes sense to look for monadic \ntypes for these operations. Should they 3 Examples in Haskell be operations in the C monad? This would \nmean that changeable ex\u00adpressions could invoke change and propagate, which could invoke Before we throw \nourselves into the implementation details behind other changeable expressions, possibly resulting in \nin.nite loops. the interface in Figure 2, let us dry run it against some examples. In an example similar \nto op3 in Section 2.2, we can de.ne a monadic operation op4: op4=op1 >>=\\a-> op2 >>= \\b -> letc =a+b \nin op3 >>= \\_ -> return c Using the do notation, the bind operation and lambda is combined into a left \narrow, and we get a shorter notation for operations for which we are only interested in their effects \n(op3): op4=doa <-op1 b<-op2 letc =a+b op3 return c datatype a list = NIL | CONS of ( a * a list mod) \n(* modl : ( a list dest -> changeable) -> a list mod *) fun modl f = mod (fn (NIL,NIL) => true | _ => \nfalse) f (* filter : ( a -> bool) -> a list mod -> a list mod *) fun filter f l = let fun filt(l,d) = \nread(l, fn l => casel of NIL => write(d, NIL) | CONS(h,r) => if f(h) then write(d, CONS(h, modl(fn d \n=> filt(r,d)))) else filt(r, d)) in modl(fn d => filt(l, d)) end Figure 3. Example of Haskell s do notation \nThis will reveal if we can combine the operations in a useful way, and we will let the examples suggest \nextensions to the interface. For our examples, we will use Haskell s do notation [13], which provides \nconvenient syntactic support for monadic programming. Figure 3 explains the do notation brie.y. A .rst \nexample immediately comes to mind: let us translate the incremental ML computation from Section 1.1. \nSince value decla\u00adrations in ML are effectful, we put them in a do command sequence: do m <-newMod (return \n1) mplus1 <-newMod (do v <-readMod m return (v+1)) change m 2 propagate Typically, Haskell programmers \navoid parentheses around a poten\u00adtially large expression that is the last argument of some function by \nusing the low-precedence operator $. Using this style, the example becomes do m <-newMod $ return 1 mplus1 \n<-newMod $ do v <-readMod m return (v+1) change m 2 propagate It is instructive to compare this with \nthe ML code in Section 1.1. Note how the destination parameters have disappeared, and that the changeables \ndon t use any write operations. It is obvious that by eliminating the write operation, changeable expressions \nget a more declarative feel. On the other side, we no longer hide the fact that the creation of modi.ables \nis an effect. Finally, the continuation passing style used in the changeables has been replaced by the \nmonadic style. Thus, monads offer the one stylistic glue that holds the Haskell example together. After \nthis example, we have enough con.dence to try some larger examples. (* qsort : int list mod -> int list \nmod *) fun qsort (l) = let fun qs(l,rest,d) = read(l, fn l => casel of NIL => write(d, rest) | CONS(h,r) \n=> let val l =filter (fn x=> x <h) r val g =filter (fn x=> x >= h) r val gs = modl(fn d => qs(g,rest,d)) \nin qs(l,CONS(h,gs),d) end) in modl(fn d => qs(l,NIL,d)) end Figure 4. Incremental Quicksort in ML. data \nList a = NIL | CONS a (Mod (List a)) deriving Eq filter :: (Eq a, NewMod m) => (a -> Bool) -> Mod (List \na) -> m (Mod (List a)) filter f l = newMod (filt l) where filt l= do l <-readMod l casel of NIL -> return \nNIL CONS h r-> if f h then CONS h liftM newMod (filt r) else filt r qsort :: (Ord a, NewMod m) => Mod \n(List a) -> m (Mod (List a)) qsort l = newMod (qs l NIL) where qs lrest =do l <-readMod l case l of \nNIL -> return rest CONShr-> do l <-filter (<h) r g <-filter (>=h) r gs <-newMod (qs g rest) qs l (CONS \nh gs)  Figure 5. Incremental Quicksort in Haskell.   3.1 The incremental Quicksort Acar et al. present \nan incremental version of Quicksort in [1], which we show in Figure 4. This version accepts as input \na variant of the standard list type that allows the tail of a list to be modi.ed (the type a list ). \nThis data structure is particularly useful for input lists to which we want to append data incrementally. \nIndeed, the authors show that the incremental Quicksort can insert a new element appended to its input \nlist of length n in expected O(log n) time. A version that uses the Haskell variant of the incremental \nlibrary is shown in Figure 5. Let us go through the principal differences between the two variants. The \nconservative comparison operation. ML-Quicksort uses a conservative comparison operation in constructing \nmodi.able lists in the modl de.nition. The comparison treats all modi.able lists as different unless \nthey are empty. Although this conservative com\u00adparison operation may trigger changeables to be recomputed \nmore often than needed, it has the bene.t of being computable in constant time. Haskell-Quicksort instead \nappeals to the overloaded equality op\u00aderation derived in the de.nition of List . This equality operation \nin turn consults underlying equality operations on the elements of the list, and on modi.ables. How do \nwe test if two modi.ables are equal? We cannot really hope for semantic equality here, since modi.ables \ndepend on the changeable computations. Moreover, semantic equality would not be a pure operation, since \nmodi.ables can be modi.ed! Let us make the design decision that we only provide the conservative equality \noperation for modi.ables, which is true if and only if the arguments are the same modi.able. This leads \nus to our .rst extension of the interface in Figure 2. We state that there is an instance declaration \nfor Mod a in Eq, which does not depend on equality for a: instance Eq (Mod a) For Haskell programmers, \nthis instance might come across as a weird member of the Eq class. Usually, Eq instances are not conser\u00advative; \nrather, they tend to lump elements together in equivalence classes. However, the most important property \nof an Eq instance is that its equality operation forms an equivalence relation, and this is indeed the \ncase with our instance for modi.ables. The comparison operation in Haskell turns out to be less conserva\u00adtive \nthan its ML counterpart. Not only does the Haskell operation identify empty lists as equal, it returns \ntrue for lists whose heads are equal and whose tails are the same modi.able. Still, it runs in constant \ntime for lists over basic types such as Int and Char. The changeable expressions. Again, we see that \nthe monadic ver\u00adsion eliminates all destination variables, continuations, and write operations. The cleanup \nis signi.cant, since filt and qs no longer need destination parameters. Monadic styles. Since newMod \nis a monadic operation (in contrast to mod), we cannot directly apply the CONS constructor to it in the \nrecursive call in filt. The standard remedy is to lift the constructor function to a monadic function \nusing liftM: liftM :: Monadm=>(a-> b)->ma ->mb liftM fma = do a<-ma return (f a) Finally, we observe \nthat the types of filter and qsort are both overloaded monadic operations in the NewMod class. Thus they \ncan be used both in the outer-level A monad, and in changeable expres\u00adsions living in the C monad. Note \nthat the newMod operation is used inside filt which in turn is inside a newMod operation in filter . \nThis is one example in which it is necessary to create modi.ables in the changeable monad C. 3.2 An \nembryonic spreadsheet A classic example of a program that bene.ts from incremental com\u00adputation is a \nspreadsheet. A large spreadsheet can have thousands of cells, containing numbers and formulas referring \nto other cells. When a user updates a cell, an ef.ciently implemented spreadsheet program only redraws \nthat cell and other cells that depend on it. Let us see how the basic mechanism behind a spreadsheet \nprogram can be implemented using the incremental library. We start by de.ning a datatype that captures \nthe abstract syntax for expressions of cells. data Expr v = Const Integer | Add (Expr v) (Expr v) | Cell \nv deriving Eq With this type, we intend to express integer constants, addition of expressions, and references \nto values of other cells. What should the type of a cell s value be? Since the content of a cell might \nbe changed by the user, it should be a modi.able: type Value = Mod Integer Now, we can write an evaluator \nfor our expressions. Since expres\u00adsions might refer to other cells, the value of an expression might \nchange. Therefore, we put the evaluator in the C monad: eval :: Expr Value -> C Integer eval (Const i) \n= return i eval (Add a b) = return (+) ap eval a ap eval b eval (Cell m) = readMod m Here, we have used \nthe left-associative in.x operator ap, which can be seen as the function application operation lifted \nto a monad: ap :: Monad m => m(a -> b) -> ma -> mb ap mf ma =do f<-mf a<-ma return (f a) By using ap \nand return, we lift the addition function to the C monad and apply it to the results of the recursive \ncalls to the evaluator. The evaluator is a straightforward example of a monadic interpreter [16]. The \ninteresting case is when we encounter a Cell, where we have to use readMod to access the value of the \ncell. We can now use the evaluator to create a cell containing a modi.\u00adable expression: type Cell = Mod \n(Expr Value) newCell :: NewMod m => m (Cell, Value) newCell = do c <-newMod $ return (Const 0) v <-newMod \n$ readMod c >>= eval return (c,v) The newCell operation creates and returns a new cell with an initial \nvalue of zero. But not only does it return the cell, it also returns its value. This value is calculated \nusing eval, and since it is modi.\u00adable, it will track future modi.cations of the cell. How can we try \nthis out? It turns out that there is a major .aw in our monadic interface: there is no way to run any \ncomputa\u00adtions in the A monad. Moreover, the modi.ables are rather useless as it stands, since they can \nonly be observed while de.ning other modi.ables. How should we allow for modi.ables to be observed? For \na fully-.edged, interactive spreadsheet program, changes to a cell will trigger rendering operations \nin the user interface. For our purposes, it will suf.ce if we can print strings to the screen. This suggests \nthat we need some means of putting I/O operations in the C and A monads, and that we need a way to invoke \nA computations from the top level in a Haskell program, that is, from the IO monad: class InIO m where \ninIO ::IO a -> ma instance InIO A instance InIO C inA::Aa -> IO a Now, we can expand our spreadsheet \nexample into a complete adap\u00adtive program. Let us .rst de.ne a cell observer that creates a cell, and \nalso observes its value by printing to the screen: newCellObserver :: NewMod m => String -> m (Cell, \nValue) newCellObserver l = do (c,v) <-newCell newMod $ do x <-readMod v inIO $ putStrLn (l ++ \" = \" ++ \nshow x) return (c,v) Here, putStrLn is a standard operation for printing a string to the screen. When \nwe create a cell with newCellObserver applied to some label, its initial value will be printed. Moreover, \nwhenever the value of the cell changes, the new value will be printed. This can happen if we change the \nexpression in the cell, or if the cell refers to some other cell value that changes. Let us use newCellObserver \nin a small program to create two cells, and then change their values to observe the effects: 1 main=inA$do \n2 (c1,v1) <\u00ad newCellObserver \"c1\" 3 (c2,v2) <\u00ad newCellObs erver \"c2\" 4 change c2 (Add (Cell v1) (Const \n40)) 5 propagate 6 change c1 (Const 2) 7 propagate The creation of the two cell/value pairs in lines \n2 and 3 result in their initial values being printed to the screen: c1 =0 c2 =0 We then change the expression \nof c2 to be the value of c1 plus 40. The propagation of this change on line 5 triggers the new value \nof c2 to be printed: c2 =40 Finally, the change of c1, once it s propagated on line 6, triggers changes \nin the values of both cells, so two more lines are being output: c1 =2 c2 =42 What happens if we introduce \na circularity in the spreadsheet? In our example, this can be done by adding the following operations: \n8 change c1 (Cell v2) 9 propagate The answer is not too surprising: the library will loop in search for \na .xpoint. In this case, there is no .xpoint, and the loop will be in.nite.  3.3 Optimizing the ap combinator \nLet us reconsider the de.nition for ap that we de.ned in conjunction with the evaluator. Suppose that \nthe expression mf reads the value of a modi.able which has changed. This triggers a recomputation of \nmf, yielding a new value for f. The library will recompute every\u00adthing that comes after the binding of \nf, in particular, ma. But this is a waste, since ma doesn t have f as a free variable! We can isolate \nthe changes in mf from ma by introducing an auxiliary modi.able: ap :: C(a->b)->C a->C b ap mf ma =do \nm <-newModBy (\\_ _ -> False) mf a<-ma f <-readMod m return (f a) The changed value from mf has now been \ncaptured inside m.We carefully avoid looking at this value until after evaluating ma. In the original \nde.nition of ap, changes inside ma did not trigger re\u00adcomputation of mf, since mf was evaluated before \nma. The optimized version is more symmetric, in that there are no dependencies in any direction between \nthe arguments. By using the optimized version in the evaluator, we achieve a .ne-grained incremental \ncomputation: a changed cell value propagates up the spine of the expression tree, but no other subtrees \nof the expression need to be recomputed. It is an interesting exercise to develop the spreadsheet example \ninto a more complete spreadsheet program, but we leave it for now. 4 Implementation Most of the implementation \nbehind the interface in Figure 2 closely follows the ML implementation in [1]. In this section, we will \ngive a short recapitulation of the mechanism implemented in the library, and then present our implementation, \nfocusing on parts that differ from the ML implementation. The complete Haskell implementa\u00adtion is available \nonline at [3]. The implementation relies on the following principal data struc\u00adtures: Dependency graph: \nEach modi.able acts as a node, and carries a list of dependent changeables (acting as edges). The edges \nare created dynamically: during evaluation of a changeable, an edge is added to the dependency list of \neach modi.able it reads. Evaluation queue: When a modi.able is changed by the change operation, all its \nedges are moved to an evaluation queue, so that dependent modi.ables can be updated. This queue is processed \nwhen the propagate operation is invoked. It can happen that the evaluation of a changeable in the queue \nresults in a change of its corresponding modi.able. In this case, the modi.able s edges are in turn added \nto the queue. Ordered list: Each edge in the dependency graph is annotated with a time interval, so that \nchangeables in the evaluation queue (which is a priority queue) can be processed in the same order they \nwere created. The evaluation queue is also pruned of edges whose time intervals are contained in those \nof other edges in the queue. The ML library uses an ef.cient implementation of ordered lists due to Dietz \nand Sleator [4] to get apt operations on time intervals. The notion of time used in the library does \nnot correspond to any\u00adthing like real time or computation time. Rather, it is used to capture the precise \norder in which modi.ables are read and written. To understand how this aspect of the library works, let \nus consider the following program fragment: m1 <-newMod $ do v <-readMod m ifv> 0 --A then do m2 <-newMod \n$ do v <-readMod m return(1/v) --B ... else ... We assume that there is already a modi.able m created. \nThe pro\u00adgram fragment will add the nodes m1 and m2 to the dependency graph. Since both the newly created \nmodi.ables read m, the library adds the changeable starting at A and the changeable at B as edges to \nthe list of dependent changeables of node m. Now, suppose that the value of m is changed to zero. The \nlibrary will move all the edges of m to the evaluation queue. This sched\u00adules recomputation of the changeables \nA and B. Now, we see that the recomputed value of m1 will follow the else branch of the con\u00additional, \nso m2 is no longer part of the value of m1. It would thus not only be a waste to recompute B; it would \nraise a division-by-zero exception! So the library needs to ensure that B does not get recomputed. We \nobserve that the B changeable is contained within the A changeable. Therefore, the library will consider \ncontaining changeables for re\u00adcomputation before contained. As it recomputes a changeable, it will prune \nall contained changeables from the evaluation queue. In our example, this ensures that A is recomputed \nand that B is pruned. The library uses the time intervals to decide when one queued changeable is contained \nwithin another. During recomputation, an arbitrary number of time stamps might need to be created within \na given time interval. Also, ef.cient deletion of time stamps within a time interval is needed. The ordered-list \ndata structure by Dietz and Sleator precisely meets these requirements. 4.1 Monad transformers and parameterized \nmodules In order to make the library as reusable as possible, we have actu\u00adally implemented a more general \ninterface than Figure 2 shows. The more general approach uses monad transformers [10], and these en\u00adable \nus to employ the incremental library not only on top of the I/O monad, but on any underlying monad that \nprovides .rst-class refer\u00adences. Therefore, we would like to parameterize the interface with respect \nto this underlying monad. Unfortunately, Haskell lacks the possibility to express modules that are parameterized \nin any way, unlike Standard ML or Cayenne [2]. Recently, a design for .rst\u00adclass modules in Haskell has \nbeen proposed [15], but it is not yet in\u00adcorporated in any of the mainstream compilers or interpreters \n[5, 6]. Without the ability to parameterize our interface over the underly\u00ading monad, what do we do? \nWe could declare a record type with .elds corresponding to the operations in the interface, along the \nlines of [14]. However, we would still need to parameterize every new type declared in the interface \nby the underlying monad. With no completely satisfying solution at hand, we resort to the traditional, \nverbose solution: to parameterize the individual de.ni\u00adtions in our interface as necessary. To make the \nimpact as small as possible, we capture the needed properties of the underlying monad in the class Ref: \nclass Monad m => Ref m r| m-> r where newRef ::a-> m(ra) readRef ::ra->ma writeRef :: r a-> a -> m () \nWith the class Ref mr, we can capture all monads m with an as\u00adsociated reference type r. In our de.nition, \nwe have used two ex\u00adtensions of Haskell: multi-parameter type classes [8], and func\u00adtional dependencies \n[7], which in conjunction have turned out to be a very versatile tool. The functional dependency m->r \ntells us that the reference type r is uniquely determined by the monad type m. This helps resolving ambiguities \nwhen we de.ne monadic oper\u00adations that need references internally. Here is a trivial example, that creates \na reference and immediately reads it: ex :: Ref mr => mInteger ex = newRef 42 >>= readRef This can be \nused in any monad which is an instance of the Ref class. Thanks to the functional dependency of r on \nm, the type of the reference can also be determined, although it is a completely internal affair to ex. \nFirst-class references are the monadic equivalent of the ML type ref, and its associated operations ref, \n!, and :=, for creating, read\u00ading and assigning references. The standard libraries of Haskell do not \nhave any instances for .rst-class references, but since the intro\u00adduction of lazy functional state threads \nand the ST monad [9], most implementations provide libraries with .rst-class references. The underlying \nmonad m, its reference type r, and the context Ref mr will show up everywhere in the interfaces that \nwe will present. Therefore, for the sake of clarity, we will take the liberty of present\u00ading elided versions \nof type de.nitions and signatures without m, r, and Ref mr. As an example, this allows us to write newtype \nOL e a newtype R e order :: Re -> Re -> OLe Ordering newtype PQ a empty :: PQ a insert ::Orda=>a-> PQ \na-> PQ a insertM :: Monad m => (a ->a->m Ordering) -> a->PQa->m (PQa) min :: PQa->Maybe (a,PQa) Figure \n6. Interface for priority queues. newtype OL e a instance Monad (OL e) newtype R e insert ::Re -> e->OLe(Re) \nspliceOut :: R e-> Re -> OL e() deleted :: R e -> OL e Bool order :: Re->Re->OLeOrdering base ::OLe(R \ne) inOL ::OLea->ma inM :: ma->OLea Figure 7. Interface for ordered lists, parameterized over Refmr. instead \nof newtype OLmr ea newtype R mr e order :: Ref mr => Rm re -> Rm re -> OL mr eOrdering 4.2 Priority \nqueues and ordered lists The ML library relies on two other libraries that implement prior\u00adity queues \nand ordered lists. We give Haskell interfaces for these interfaces in Figure 6 and 7. For ordered lists, \nwe have provided a monad-transformer based in\u00adterface, again relying on the Ref class. Operations on \nordered lists whose elements are of type e live in the monad OL e. This monad is an instance of the environment \nmonad transformer [10], modeled by parameterizing the underlying monad by the environment type. Our environment \nis a triple carrying the current size, the maximum size, and the base record of the ordered list: newtype \nOL e a = OL ((r Integer, r Integer, R e) -> m a) (Remember that we have assumed that this type is also \nparameter\u00adized over m and r.) The current size and maximum size of the or\u00addered list can change, which \nis why the environment has references to these. All records in the list have type e, and are linked together \nin a cir\u00ad newtype CL a circularList :: a -> m (CL a) next ::CLa-> m(CLa) previous :: CL a -> m (CL a) \ninsert ::CLa-> a-> m(CLa) val ::CLa ->ma update ::CLa-> a-> m() delete ::CLa-> m() Figure 8. Interface \nfor circular lists, parameterized over Refmr. cular fashion. Moreover, each record has a .ag that tells \nwhether it has been spliced out, and an integer that is used for the order comparison operation. The \ntype R captures all this information: newtype R e = R (CL (Bool,Integer,e)) This relies on yet another \nmonadic library for circular lists in Fig\u00adure 8, which also relies on our .rst-class references. The \ntype CL a represents an element which is a member in a circular list. Straight\u00adforward operations are \nprovided to create an one-element list, get to the next and previous element in the list, and to insert \nand return a new element after an element. The value of an element can be read or updated, and the element \ncan also be deleted from the list. Let us return to the operations on ordered lists in Figure 7. The \noperations allow us to create and insert a new record after an ex\u00adisting record, delete all records strictly \nbetween two records, and check if a record has been deleted. The key operation is order, that checks \nthe relative position of two records, and returns a value in the standard Haskell type Ordering: data \nOrdering = LT | EQ | GT Using this type, a record that comes before another record has the ordering LT. \nNow, why does the operation order have a monadic type? Since records never move around in the list, order \nought to be a pure function! The problem is that the ordering is determined by looking at the integer \nreferences in the records, and these might change as new records are inserted in the list. The only way \nthe integer references can be read is by the monadic readRef. The imperative signature of order contaminates \nthe otherwise monad-free interface for priority queues in Figure 6. The usual insert operation, that \nworks for the pure ordering operation in the Ord class, is useless if we want to insert elements using \nordered-list order. We therefore provide an additional insertion operation that allows the comparison \noperation to take place in a monad. The min operation returns the head and tail of a priority queue, \nor Nothing if the queue is empty. 4.3 Implementation of the A and C monads By looking inside the implementation \nof the incremental library in [1], we see that it uses references for maintaining its evaluation queue \nof edges, and for keeping track of the current time. An edge corresponds to a part of a changeable computation \nthat starts by reading an input modi.able, and ends by writing its output modi.\u00adable. That is, whenever \na changeable reads a modi.able, an edge containing the continuing changeable is inserted in the dependency \ngraph. It has a time interval which starts with the read operation of the input modi.able, and ends at \nthe .nal write operation. Time is accounted here by records in an underlying ordered list, where the \nvalues of the records are insigni.cant. To get the corresponding kind of state into the A monad, we use \nthe environment monad transformer again, this time on top of the ordered-list monad. The environment \nwill have references to the process queue and the current time: newtype Aa =A ((r (PQ Edge), r Time) \n->OL () a ) type Time = R () It turns out that the continuations that sit in the edges precisely amount \nto A-computations, which leads to the following type for propagate = do let prop = do pq <-readPq case \nmin pq of Nothing -> return () Just ((reader,start,stop),pq ) -> do writePq pq unlessM (inOL $ deleted \nstart) $do inOL $ spliceOut start stop writeCurrentTime start reader prop now <-readCurrentTime prop \nwriteCurrentTime now Figure 9. The propagate operation. Edge: type Edge = (A (), Time, Time) With these \ntypes, it is straightforward to de.ne the propagate op\u00aderation, see Figure 9, using the same algorithm \nas the ML library. It repeatedly extracts the .rst edge from the evaluation queue. If the start time \nof the edge has not been deleted from the ordered list, it deletes all edges contained in its time interval, \nand evaluates its changeable. Let us now turn to the de.nitions of the C monad and the modi.\u00adables. In \nthe ML library, a modi.able carries references to a value, a write operation, and a list of edges. Thus, \nmodi.ables form the nodes in the dependency graph. We get the corresponding type in Haskell: newtype \nMod a = Mod (r a, r (a -> A ()), r [Edge]) In the C monad, we will capture continuations of type A() \nto put in edges. This leads to the following de.nitions: newtype Ca=C((a ->A()) -> A()) deC(Cm)=m Usually, \nthe continuation monad comes with the operation call with current continuation,or callcc [10]: callcc \n:: ((a -> Cb) -> C a) -> C a callcc f =C $\\k -> deC (f (\\a -> C $\\k -> (k a))) k This operation exposes \nthe current continuation to its argument, so that one later can invoke it to jump back to the point of \ncallcc. For our purposes, the operation cont is more appropriate: it gives us the possibility to completely \nrede.ne what the continuation should be, in the underlying monad: cont :: ((a -> A()) -> A ()) -> Ca \ncont m= Cm We use cont to create the edge in readMod, de.ned in Figure 11. The locally de.ned reader, \nof type A(), has captured the con\u00adtinuation k, and forms a new continuation in terms of it. The new continuation \nreads the value of the input modi.able, and passes it to k. After k has .nished, it has written to its \noutput modi.able, so the new continuation checks the time, and forms an edge to insert in the dependency \nlist of the input modi.able. Here, and in what follows, mapRef ::(a->a)->ra->m() mapRef f r = readRef \nr >>= (writeRef r . f) inA ::Aa->Ca inC ::Ca->Aa readCurrentTime :: A Time stepTime :: A Time stepTime \n= do t < -readCurrentTime t <-inOL $ insert t () writeCurrentTime t return t Figure 10. Some auxiliary \nfunctions. readMod (Mod (v,_,es)) = do start <-stepTime cont $\\k -> do let reader = do readRef v >>= \nk now <-readCurrentTime mapRef ((reader,start,now):) es reader Figure 11. The readMod operation. we use \na couple of auxiliary functions given in Figure 10. These let us apply a function to the value of a reference, \nuse A-operations in the C monad and vice versa, and read and bump the current time. Finally, we give \nthe implementation for the A-monad instance of the newModBy operation in Figure 12. Just as its corresponding \nML operation mod, it de.nes two write operations that the changeable c will use. As the name indicates, \nwriteFirst is only used the .rst time the value of the modi.able is being computed. It will up\u00addate the \nreference changeR in the modi.able to point to writeAgain, which will be used whenever the modi.able \nneeds to be recom\u00adputed. The writeAgain operation compares the newly computed value of the modi.able \nwith the old, and if they differ, all depen\u00addent changeables are queued for recomputation by means of \nthe auxiliary insertPQ: insertPQ :: r [Edge] -> A () After the de.nition of these write operations, the \nchangeable is ex\u00adecuted to get its value v. This value is written to by using either writeFirst or writeAgain. \nThis is the point where we were able to factor out the write operation from the changeable, as promised \nin Section 2.3.  5 Conclusions We have presented an example of how a monadic framework can lead us \nto a safe interface to an imperative library for incremental computing, suitable for use in a purely \nfunctional language. After looking at some examples that use the monadic library, we found opportunities \nto optimize one of the standard monadic combinators. As a result, the library is able to remove some \narti.cial dependen\u00adcies, which in turn can result in less incremental work carried out when input changes. \nNow, our monadic library has not only paid off by ensuring correct usage. Algorithms that use the ap \ncombinator immediately bene.t instance NewMod A where newModBy :: (a -> a -> Bool) -> C a -> A (Mod \na) [3] M. Carlsson. Adaptive incremental computations in Haskell. www.cse.ogi.edu/~magnus/Adaptive/, \n2002. newModBy cmp c = do m <\u00adnewRef (error \"newMod\") changeR <\u00adnewRef (error \"changeR\") es <\u00adnewRef \n[] [4] P. F. Dietz and D. D. Sleator. Two algorithms for mainitaining order in a list. In Proceedings. \n19th ACM Symposium. Theory of Computing, 1987. let writeFirst v = do writeRef m v now <\u00adstepTime [5] \nThe Glasgow Haskell compiler. www.haskell.org/ghc/. [6] The Hugs 98 interpreter. www.haskell.org/hugs/. \nwriteRef changeR (writeAgain writeAgain t v = do v <\u00adreadRef m unless (cmp v v) $do writeRef m v now) \n[7] M. P. Jones. Type Classes with Functional Dependencies. In Proceedings of the 9th European Symposiumon \nProgram\u00adming, ESOP 2000, number 1782 in LNCS, Berlin, Germany, March 2000. Springer-Verlag. insertPQ \nes writeRef es [] writeCurrentTime t [8] S. P. Jones, M. P. Jones, and E. Meijer. Type classes: exploring \nthe design space. In Haskell Workshop, 1997. writeRef changeR writeFirst inC $ do v<\u00adc write <\u00adreadRef \nchangeR inA $ write v return (Mod (m, changeR, es)) Figure 12. The NewMod instance for A. [9] J. Launchbury \nand S. Peyton Jones. Lazy functional state threads. In ACM Programming Languages Design and Im\u00adplementation, \nOrlando, 1994. [10] S. Liang, P. Hudak, and M. P. Jones. Monad transformers and modular interpreters. \nIn Conference Record of POPL 95: 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, \npages 333 343, San Francisco, California, Jan. 1995. from the fact that the arguments are independent, \nand thus isolated in the dependency graph. From a Haskell library designer s point of view, we notice \nthat the optimized version of the ap combinator for the C monad suggests that this combinator should \nbe put in a class, and that other monads may bene.t from optimized instances. [11] R. Milner, M. Tofte, \nR. Harper, and D. MacQueen. The De.\u00adnition of Standard ML (Revised). MIT Press, 1997. [12] S. Peyton \nJones et al. The Haskell 98 libraries. haskell.org/onlinelibrary/, 1999. [13] S. Peyton Jones et al. \nReport on the programming language Haskell 98, a non-strict, purely functional language. Available from \nhttp://haskell.org, February 1999. We .nd that Haskell as a language provides good support for monadic \nprogramming, but that the lack of parameterizable mod\u00adules is a big disadvantage. Most of our interfaces \ninclude types and operations that are parameterized over an underlying monad, and the inability to capture \nthis parameter at one single point decreases the clarity of the interfaces signi.cantly. For these reasons, \nit was tempting to use Standard ML or Cayenne instead for implementa\u00adtion language. We decided to go \nfor Haskell, since it is a widely used language that is purely functional. This makes it clear that all \neffects are captured in the monadic types. We are also pleased to see that there is ongoing work on .rst-class \nmodule systems for Haskell [15]. [14] T. Sheard. Generic uni.cation via two-level types and param\u00adeterized \nmodules. In International Conference on Functional Programming, Florence, Italy, 2001. ACM. [15] M. Shields \nand S. P. Jones. First class modules for Haskell. In 9th International Conference on Foundations of Object-Oriented \nLanguages (FOOL 9), Portland, Oregon, pages 28 40, Jan. 2002. [16] P. Wadler. The essence of functional \nprogramming. In Proceedings 1992 Symposium on Principles of Programming Languages, pages 1 14, Albuquerque, \nNew Mexico, 1992. The implementation of our library is freely available for download at [3]. 6 Acknowledgments \nWe would like to thank Dick Kieburtz, Thomas Hallgren, Bill Har\u00adrison, Sylvain Conchon, Walid Taha, and \nthe anonymous referees for valuable feedback on this paper. 7 References [1] U. Acar, G. Blelloch, , \nand R. Harper. Adaptive functional programming. In Principles of Programming Languages (POPL02), Portland, \nOregon, January 2002. ACM. [2] L. Augustsson. Cayenne a language with dependent types. In Proc. of the \nInternational Conference on Functional Pro\u00adgramming (ICFP 98). ACM Press, September 1998.   \n\t\t\t", "proc_id": "581478", "abstract": "This paper presents a monadic approach to incremental computation, suitable for purely functional languages such as Haskell. A program that uses incremental computation is able to perform an incremental amount of computation to accommodate for changes in input data. Recently, Acar, Blelloch and Harper presented a small Standard ML library that supports efficient, high-level incremental computations [1]. Here, we present a monadic variant of that library, written in Haskell extended with first-class references. By using monads, not only are we able to provide a purely functional interface to the library, the types also enforce \"correct usage\" without having to resort to any type-system extension. We also find optimization opportunities based on standard monadic combinators.This is an exercise in putting to work monad transformers with environments, references, and continuations.", "authors": [{"name": "Magnus Carlsson", "author_profile_id": "81100635832", "affiliation": "Oregon Health & Science University", "person_id": "PP14218527", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/581478.581482", "year": "2002", "article_id": "581482", "conference": "ICFP", "title": "Monads for incremental computing", "url": "http://dl.acm.org/citation.cfm?id=581482"}