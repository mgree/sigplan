{"article_publication_date": "09-17-2002", "fulltext": "\n Concatenate, Reverse and Map Vanish For Free * Janis Voigtl\u00a8 ander Department of Computer Science \nDresden University of Technology 01062 Dresden, Germany voigt@tcs.inf.tu-dresden.de Abstract We introduce \na new transformation method to eliminate intermedi\u00adate data structures occurring in functional programs \ndue to repeated list concatenations and other data manipulations (additionally ex\u00adempli.ed with list \nreversal and mapping of functions over lists). The general idea is to uniformly abstract from data constructors \nand manipulating operations by means of rank-2 polymorphic combina\u00adtors that exploit algebraic properties \nof these operations to provide an optimized implementation. The correctness of transformations is proved \nby using the free theorems derivable from parametric poly\u00admorphic types. Categories and Subject Descriptors \nD.1.1 [Programming Techniques]: Applicative (Functional) Pro\u00adgramming; D.3.3 [Programming Languages]: \nLanguage Con\u00adstructs and Features abstract data types, polymorphism; D.3.4 [Programming Languages]: Processors \noptimization; F.3.1 [Logics and Meanings of Programs]: Specifying and Verifying and Reasoning about Programs; \nF.3.3 [Logics and Meanings of Programs]: Studies of Program Constructs type structure General Terms \nLanguages, Algorithms, Design  Keywords Combinators, correctness proofs, denotational semantics, list \nab\u00adstraction, parametricity, program transformation, rank-2 types, shortcut deforestation, the concatenate \nvanishes, theorems for free * Research supported by the Deutsche Forschungsgemeinschaft under grant KU \n1290/2-1 and by the Gesellschaft von Freunden und F\u00a8orderern der TU Dresden with a travel grant. Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute 1 Introduction Consider the following de.nition in the functional programming \nlanguage Haskell, implementing the partition of a list l according to some predicate p: part :: .a . \n(a . Bool) . [a] . [a] part p l = let f [] z = z f (x : xs) z = if px then x : (fxsz) else fxs (z ++[x]) \nin fl [] While serving as a good speci.cation of part, this de.nition has an inef.cient runtime behavior \ndue to repeated concatenate operations (++) on intermediate lists in the second argument position of \nf . Since + requires runtime linear in the length of its left argument, this overhead can be considerable. \nSimilar ef.ciency problems due to a modular programming style can also be caused by other data manipulating \noperations often used in speci.cations. In order to optimize function de.nitions that make extensive \nuse of + , Hughes [12] proposed an alternative list representation sup\u00adporting ef.cient concatenations. \nTherefor, a list xs is represented as the function (.ys . xs + ys). It is left to the programmer to de\u00adcide \nwhere conversion between the two representations should be performed, hence the transformation is not \nvery systematic. Wadler [27] presented an algorithmic transformation that intro\u00adduces accumulating parameters \nand can achieve many but not all of the effects of Hughes approach. For example, it is not applicable \nto the above part-function. The contribution of this paper is an optimization technique for elim\u00adinating \nconcatenate operations with the following characteristics: It is applicable to more programs than Wadler \ns method (cf. Sections 6 and 7.2).  It extends to a general methodology for eliminating also other data \nmanipulating operations than list concatenation (cf. Sections 4 and 5).  It produces function de.nitions \nthat closely resemble the orig\u00adinal speci.cations, and thus does not hamper readability and maintainability \nof transformed programs.  It has a sound semantic basis as it facilitates concise correct\u00adness proofs \nof transformations by using Wadler s free theo\u00adrems [28].  It requires no compiler modi.cation, only \nthat function def\u00ad  to lists, requires prior speci.c permission and/or a fee. initions are written \nin a special form (similarly to using build ICFP 02, October 4-6, 2002, Pittsburgh, Pennsylvania, USA. \nfor shortcut deforestation [10]). Copyright 2002 ACM 1-58113-487-8/02/0010 ...$5.00 This special form \nmoreover can be obtained automatically by using Chitil s approach of list abstraction through type in\u00adference \n[6, 7]. For example, our new method replaces the above part-function by the following: part. :: .a. (a \n. Bool) . [a] . [a] part. pl = vanish+ (.nca . let f [] z = z f (x : xs) z = if px then x c (fxsz) else \nfxs (z a (x c n)) in fln) This de.nition takes advantage of a rank-2 polymorphic function vanish+ that \nis provided in Figure 1. All the programmer needs to know in order to bene.t from our concatenate elimination \nmethod is a certain law about vanish+ that will be proved in Section 3.1. We will show in Section 4 how \nto systematically develop such reusable vanish-combinators also for other data manipulations than list \nconcatenation. vanish+ :: .a. (.\u00df. \u00df . (a . \u00df . \u00df) . (\u00df . \u00df . \u00df) . \u00df) . [a] vanish+ g = gid (.xh ys . \nx : (hys)) (.)[] Figure 1. De.nition of vanish+ . Note that the above de.nition of part. closely resembles \nthe original speci.cation of part, if we read n, c and a as [],: and + , respectively. But while the \noriginal function part has a quadratic worst-case time complexity (disregarding the time for executing \np) in the length of its input list l, the obtained part. is only of linear time complexity, as exempli.ed \nin the following measurements1: n = 3000 5000 7000 9000 11000 part even[1..n] parteven[1..n] 0.4 0.004 \n1.1 0.006 2.2 0.009 3.5 0.012 5.6 0.015 The following prerequisites are necessary to apply our method: \n1. We need a type system that supports rank-2 polymor\u00adphism [17], which is the case, e.g., for most current \nHaskell implementations, but also for MetaML [25]. 2. We have to believe in the validity of free theorems \nfor the functional language under consideration. Although the cor\u00adrectness of these free theorems relies \non relationally paramet\u00adric models [23] which are not known to exist for mod\u00adern functional languages \n Pitts recent proof [22] of the ex\u00adistence of such models for lambda calculi with higher-order polymorphic \nfunctions and .xpoint recursion justi.es this as\u00adsumption. For example, Johann [14] used Pitts result \nto jus\u00adtify shortcut deforestation the correctness of which also depends on parametricity for languages \nlike Haskell.  Although we use Haskell throughout this paper, our methodology is also applicable to \nother lazy or strict functional languages meeting the above two prerequisites. The remainder of this \npaper is organized as follows. Section 2 con\u00adsiders the used functional language and its semantics. Section \n3 1The runtimes (in seconds) shown here and in the following ta\u00adbles were measured on a SPARC workstation \nusing the pro.ling capabilities of the optimizing Glasgow Haskell Compiler. presents our technique for \neliminating concatenate operations and discusses its application on examples. Section 4 uses the elimina\u00adtion \nof list reversal to illustrate the general methodology. Section 5 presents the result of applying this \nmethodology to eliminate + , reverse and map. Section 6 shows how to eliminate concatenate operations \nalso from producers of nested lists. Section 7 compares our method with related work and Section 8 concludes. \n 2 Functional Language We use the pure and lazy functional language Haskell [2]. De.\u00adnitions of Haskell \nfunctions that we use throughout the paper are given in Figure 2. Except for swap and build, these functions \nare part of the standard Haskell prelude, though the actual de.\u00adnitions may differ between Haskell implementations. \nOur perfor\u00admance measurements will use the Glasgow Haskell Compiler s pre\u00adlude de.nitions, which might \nbe more ef.cient but are semantically equivalent to the clearer de.nitions in Figure 2. (++) :: .a. [a] \n. [a] . [a] [] + ys = ys (x : xs)++ ys = x : (xs + ys) reverse :: .a. [a] . [a] reverse l = let f [] \nys = ys f (x : xs) ys = fxs (x : ys) in fl [] map :: .a\u00df. (a . \u00df) . [a] . [\u00df] map f [] =[] map f (x : \nxs)= (fx) : (mapf xs) id :: .a. a . a id u = u (.) :: .a\u00df.. (\u00df . .) . (a . \u00df) . a . . (f1 . f2) u = \nf1 (f2 u) fst :: .a\u00df. (a,\u00df) . a fst (h1,h2)= h1 snd :: .a\u00df. (a,\u00df) . \u00df snd (h1,h2)= h2 swap :: .a\u00df. (a,\u00df) \n. (\u00df,a) swap (h1,h2)=(h2,h1) foldr :: .a\u00df. (a . \u00df . \u00df) . \u00df . [a] . \u00df foldr c n [] = n foldr c n (x : \nxs)= x c (foldr cnxs) build :: .a. (.\u00df. (a . \u00df . \u00df) . \u00df . \u00df) . [a] build g = g (:)[] Figure 2. Some Haskell \nfunctions. 2.1 Semantics Unfortunately, there is not yet a formal semantics for the whole of Haskell, \nindependent of any concrete implementation. Neverthe\u00adless, it is common practice to use a denotational \nstyle for reasoning about Haskell programs. We also follow this approach and very brie.y recall the necessary \nnotions, in particular the approximation Cbetween values of the same type, interpreted as less or equally \nde.ned as , and the value . at every type, interpreted as unde\u00ad.ned . The reader who is mainly interested \nin the development and application of our transformation method rather than in the formal proofs might \nwant to skip the rest of this section as wells as the appendices and only consider the laws in Figure \n3, where all free variables are universally quanti.ed over the appropriate types. .u =. (1) .+ xs =. \n(2) (xs + ys)++zs =xs ++(ys + zs) (3) xs ++[]=xs (4) fst (swap h)=snd h (5) snd (swap h)=fst h (6) reverse \n.=. (7) reverse (reverse xs)Cxs (8) reverse (x : xs)=(reverse xs)++[x] (9) reverse (xs + ys)C(reverse \nys)++(reverse xs) (10) map f (xs + ys)=(map f xs)++(map f ys) (11) map f (map k xs)=map (f .k)xs (12) \nreverse (mapkxs)=map k (reverse xs) (13) map f .=. (14) map id xs =xs (15) foldr (:)[]xs =xs (16) foldr \nc n (build g)=gcn (17) Figure 3. Some simple laws. In the spirit of denotational semantics [24], types \nare considered as sets equipped with the partial order C, the least element ., and limits of all non-empty \nchains. A relation between such pointed complete partial orders is called strict if it contains the pair \n(.,.). A relation is called continuous if the limits of two chains of pair\u00adwise related elements are \nagain related. A strict and continuous re\u00adlation is called admissible. A function is called monotonic \nif it pre\u00adserves the approximation order. All functions de.nable in Haskell are monotonic and continuous. \nNote that in the laws (8) and (10) from Figure 3 the approximation Cmay not be replaced by equality, \nbecause xs might be an in.nite list in both cases, giving .on the left-hand sides but not necessarily \non the right-hand sides. Further, note that law (17) which is at the heart of shortcut de\u00adforestation \nfor Haskell lists [10] does not necessarily hold if g is de.ned using strict evaluation with the polymorphic \nprimitive seq (see the counterexample in Appendix B). This is so, because seq being available at every \ntype weakens the free theorems for Haskell. For the same reason, we will for now assume that seq is \nnot used in the programs to be transformed. Since strict data types and the strict application function \n$! are de.ned in terms of seq, they will also be excluded. Then, in Appendix B, we will consider how \nthe proofs of our theorems fare in the presence of the strict evaluation primitive, and will see that \n in contrast to shortcut de\u00adforestation our optimizations are not hindered by allowing seq into the \nfunctional language.  3 More Concatenates Vanish In this section we present our technique for eliminating \ncalls to the list concatenation function. We .rst give a theorem with formal proof and then consider \nexamples to illustrate how programs are optimized by applying this theorem. 3.1 A Theorem For Free Consider \nthe rank-2 polymorphic function vanish+ as de.ned in Figure 1. In the following we present a theorem \nthat gives an al\u00adternative but equivalent semantics for vanish+ . The proof of this result exploits \nthe free theorem that comes with every poly\u00admorphic type [28], and is given in a similar style as the \ncorrectness proof for shortcut deforestation in [10]. Note that the relation cho\u00adsen in the free theorem \nmust be admissible (strict and continuous), because we consider programs in a functional language with \n.x\u00adpoint recursion and possible non-termination. THEOREM 1. For every .xed type A and function g :: .\u00df \n. \u00df . (A . \u00df . \u00df) . (\u00df . \u00df . \u00df) . \u00df holds: g [](:)(++) = vanish+ g (18) PROOF. The free theorem associated \nwith g s type is that for every choice of types B and B', values n :: B, n' :: B', c :: A .B .B, c' :: \nA .B'.B', a :: B .B .B and a' :: B'.B'.B', and an admissible relation R .B \u00d7B', the following implication \nholds: (n,n').R . (.x :: A, (l,l').R . (cxl, c' xl').R ) . (.(l1,l'1).R ,(l2,l'2).R . (al1 l2,a' l'1 \nl'2).R ) '' . (gnca,gnca').R . Here the polymorphic function g is silently instantiated at type B in \n'' the application to n, c and a, and at type B'in the application to n, cand a'. Instantiating the \nabove with B =[A], B' =[A].[A], n =[], ' n=id, c =(:), c' =(.xhys .x : (hys)), a =(++) and a' =(.), \nwe obtain: ([],id).R . (.x :: A, (l,l').R . (x : l,(.xhys .x : (hys))xl').R ) . (.(l1,l'1).R ,(l2,l'2).R \n. (l1 + l2,l'1 .l'2).R ) . (g [](:)(++),gid (.xhys .x : (hys))(.)).R . Consider the relation R ={(p,q).B \n\u00d7B'|.u :: [A]. p + u =qu}. From laws (1) and (2) follows the strictness of R . Continuity of R follows \nfrom the facts that (++) is a continuous function and that function application is also continuous. Hence, \nR is admissible and thus can be used in the above implication. Then, the three conjuncts in the precondition \nof this implication read as follows: (i). .u :: [A] . [] + u = id u (ii). for every x :: A, l :: [A] \nand l ' :: [A] . [A]: (.u :: [A] . l + u = l ' u) . (.u :: [A] . (x : l)++ u =(.xh ys . x : (hys)) xl \n' u) (iii). for every l1,l2 :: [A] and l ' 1,l ' 2 :: [A] . [A]: (.u1 :: [A] . l1 + u1 = l ' 1 u1) . \n(.u2 :: [A] . l2 + u2 = l ' 2 u2) . (.u :: [A] . (l1 + l2)++ u =(l ' 1 . l ' 2) u). Conditions (i) and \n(ii) follow from the de.nitions of (++) and id and by beta-reduction; condition (iii) follows from law \n(3) and the de.nition of (.). The instantiated free theorem thus implies .u :: [A] . (g [] (:)(++)) + \nu = gid (.xh ys . x : (hys)) (.) u, which for u =[] gives using law (4) and the de.nition of vanish+ \nthe following calculation: g [] (:)(++) =(g [] (:)(++)) ++[] = gid (.xhys . x : (hys)) (.)[] = vanish+ \ng. Note how in the above proof the relation R captures the essence of Hughes pair of functions rep and \nabs [12].  3.2 Applying the Theorem Theorem 1 can be used to optimize list producers from which all \nlist constructors and occurrences of (++) have been abstracted uni\u00adformly. This proper abstraction is \nguaranteed by the polymorphic argument type of vanish+ . Hence, if the Haskell type-checker ac\u00adcepts \nan expression vanish+ g, then this expression really has the same semantics as g [] (:)(++), but might \nbe dramatically more ef\u00ad.cient due to an optimized implementation of concatenation. We give two examples \nin the remainder of this section. Example 1. Consider the following de.nitions, implementing the recursive \nsolution to the Towers of Hanoi problem: data Pos = L | M | R hanoi :: Int . [(Pos,Pos)] hanoi t = let \nf 1 pqr =(p,q) : [] f (s + 1) pqr =(f sprq)++((p,q) : (fsrqp)) in ft LRM Abstracting from the list constructors \n[] and (:), and from (++), the function hanoi can also be written as: hanoi t =(.nca . let f 1 pqr =(p,q) \nc n f (s + 1) pqr =(fsprq) a ((p,q) c (fsrqp)) in ft LRM)[](:)(++) Using law (18) from Theorem 1, this \nis equivalent to: hanoi. :: Int . [(Pos, Pos)] hanoi. t = vanish+ (.nca . let f 1 pqr =(p,q) c n f (s \n+ 1) pqr =(fsprq) a ((p,q) c (fsrqp)) in ft LRM) The standard compiler-built-in simplifying techniques \ninlining and beta-reduction [21] are enough to automatically obtain the variant hanoi. t = (let f 1 pqr \n= .ys . (p,q) : ys f (s + 1) pqr = .ys . fsprq ((p,q) : (f srqpys)) in ft LRM)[] that closely corresponds \n by let-.oating [20] to the result of applying Wadler s introduction of accumulating parameters [27] \nto hanoi (as shown in Section 7.2) and hence enjoys the same runtime bene.ts. . As a further example \nfor our technique, we consider what we can do about a function that was termed silly in [27] and could \nnot be optimized there. Example 2. Consider the following de.nition: .atten :: .a . [[a]] . [a] .atten \nl = let silly x [] = x silly x (y : ys)= silly (x + y) ys in silly [] l If we try to use vanish+ by \nsimply abstracting from the visible list constructors [] and (++), an Inferred type is less polymorphic \nthan expected -error is produced by the type-checker. This guides us to additionally abstract from the \nlist constructors of y in the second equation of silly, by using law (16) as follows: .atten l = let \nsilly x [] = x silly x (y : ys)= silly (x ++(foldr (:)[] y)) ys in silly [] l Note that the additional \ntraversal of y with foldr (:)[] makes the de.nition less ef.cient. However, we can now use vanish+ type-correctly \nand obtain: .atten. :: .a . [[a]] . [a] .atten. l = vanish+ (.nca . let silly x [] = x silly x (y : ys)= \nsilly (x a (foldr cny)) ys in silly n l) Performance measurements show that this de.nition is not so \nsilly after all. In fact, the function .atten with a worst-case time complexity quadratic in the size \nof its argument has been transformed to .atten, which has the same semantics but only requires linear \ntime: n = 1000 3000 5000 7000 .atten [[i]|i . [1..n]] 0.18 0.003 1.6 0.008 4.5 0.014 9.0 0.019 .atten. \n[[i]|i . [1..n]] It would be interesting to make the guidance by the type-checker suggested above more \nexplicit. . So far, we have presented three examples (for part, hanoi and .atten) of applying our method \nby hand. The approach to list ab\u00adstraction was to replace some occurrences of list constructors [], (:) \nand (++) by variables, and then to use the rank-2 polymorphic type-checker for detecting whether this \nreplacement was suf.cient to express the list producer with vanish+ . Chitil [6] reduced the problem \nof list abstraction for shortcut deforestation to a decidable partial type inference problem. Thus, he \nobtained a linear-time al\u00adgorithm to derive build-forms of list producers by abstraction from [] and \n(:). By additionally treating (++) as just another list con\u00adstructor, Chitil s idea can be extended to \nautomatically derive the desired vanish+ -forms for our optimization technique. The deci\u00adsion for which \nfunctions to attempt an automatic abstraction, could come from the user via a pragma that would cause \nthe compiler to check which data manipulating operations are used inside a given de.nition and whether \na corresponding vanish-combinator exists. Alternatively, vanish+ and related combinators e.g., from \nthe next sections may be consciously used when writing new pro\u00adgrams. For example, a programmer might \nwant to implement a list producing algorithm that is most naturally expressed using repeated concatenations \nor maps. Being aware of the danger of inef.ciencies due to intermediate results, she can choose the appropriate \nvanish\u00adfunction from a pre-de.ned module containing lots of such com\u00adbinators for different data manipulations. \nNote that in order to do so, the user does not need to know the actual de.nitions of those vanish-functions, \nbut only a speci.cation of their semantics as pro\u00advided by statements like in Theorems 1, 2, 3 and 4 \nof this paper.  4 A General Methodology In this section we demonstrate that the method from the previous \nsection is an instance of a more general new methodology for sup\u00adplying data types with cheap versions \nof frequently used manipulat\u00ading operations. This will be exempli.ed by adding to the standard list data \ntype support for reversing lists without ef.ciency penalties due to repeated reversals. As an example \nwhere this is useful, con\u00adsider the following na\u00a8ive de.nition of a function for shuf.ing a list: shuf.e \n:: .a . [a] . [a] shuf.e [] =[] shuf.e (x : xs)= x : (reverse (shuf.e xs)) Since every application of \nreverse takes time linear in the length of its argument, the runtime of shuf.e is quadratic in the length \nof the input list. With the technique developed in the next three subsec\u00adtions we will obtain a version \nof shuf.e needing only linear runtime. 4.1 Freezing and Abstraction Firstly, we introduce a richer data \ntype with an additional construc\u00adtor for the additional operation that we want to support, and adapt \nshuf.e to produce a value of that richer type: data List a = Nil | Cons a (List a) | Rev (List a) shuf.e \n' :: .a . [a] . List a shuf.e ' [] = Nil shuf.e ' (x : xs)= Cons x (Rev (shuf.e ' xs)) This step of introducing \ndata constructors for external functions here: Rev for reverse is inspired by that of freezing in K\u00a8uhnemann \net al. [15]. In order to expose these constructors for later fusion, we use the following buildList-function: \nbuildList :: .a . (.\u00df . \u00df . (a . \u00df . \u00df) . (\u00df . \u00df) . \u00df) . List a buildList g = g Nil Cons Rev to uniformly \nabstract the constructors of List a, giving: shuf.e '' :: .a . [a] . List a shuf.e '' l = buildList (.ncr \n. let f [] = n f (x : xs)= cx (r (fxs)) in fl)  4.2 Ef.cient Conversion Since we are interested in a \nvalue of the original type [a] and not of the enriched data type List a, we need a conversion function \nfrom the enriched to the standard list type. Using the following function: foldList :: .a . List a . \n(.\u00df . \u00df . (a . \u00df . \u00df) . (\u00df . \u00df) . \u00df) foldList Nil ncr = n foldList (Cons xxs) ncr = cx (foldList xsncr) \nfoldList (Rev xs) ncr = r (foldList xsnc r) a trivial solution would be: convert :: .a . List a . [a] \nconvert l = foldList l [] (:) reverse However, this is clearly not a good solution, because the composed \nfunction convert . shuf.e '' will be less ef.cient than the original shuf.e, as the traversal with foldList \nonly causes additional runtime overhead while still repeated applications of reverse occur. Hence, we \nhave to improve convert by inventing a new function convert. that can perform at least the same conversions \nmore ef.\u00adciently. More precisely, we want to have the semantic property convert C convert. and convert. \nshould have a better runtime ef.ciency than convert. The solution in the particular case under consideration \nhere is to introduce two mutually recursive functions with accumulating pa\u00adrameters as follows2: convert. \n:: .a . List a . [a] convert. l = let h1 Nil ys = ys h1 (Cons xxs) ys = x : (h1 xs ys) h1 (Rev xs) ys \n= h2 xs ys h2 Nil ys = ys h2 (Cons xxs) ys = h2 xs (x : ys) h2 (Rev xs) ys = h1 xs ys in h1 l [] In \norder to be able to apply shortcut deforestation in the next sub\u00adsection, we express this as a higher-order \nand tupled foldList: convert. l = fst (foldList l (.ys . (ys,ys)) (.xhys . (x : (fst (hys)), snd (h \n(x : ys)))) (.hys . swap (hys)) [])  4.3 Fusion Following the developments from the previous two subsections, \nthe shuf.ing of a list l of the standard list type can be performed by computing convert. (shuf.e '' \nl). Now, we calculate by inlining: convert. (shuf.e '' l) = fst (foldList (shuf.e '' l) (.ys . (ys,ys)) \n(.xhys . (x : (fst (hys)),snd (h (x : ys)))) (.hys . swap (hys)) []) = fst (foldList (buildList (.ncr \n. let f [] = n f (x : xs)= cx (r (fxs)) in fl)) (.ys . (ys,ys)) (.xhys . (x : (fst (hys)),snd (h (x : \nys)))) (.hys . swap (hys)) []). 2An interesting alternative is to reuse an already existing vanish\u00adcombinator \nfor expressing a new conversion, in this case: convert. l = vanish+ (.nca . let h1 Nil = n h1 (Cons \nxxs)= x c (h1 xs) h1 (Rev xs)= h2 xs h2 Nil = n h2 (Cons xxs)=(h2 xs) a (x c n) h2 (Rev xs)= h1 xs in \nh1 l) By shortcut deforestation [14] for the List type constructor, we know that for every type A and \nfunction g with g :: (.\u00df .\u00df . (A . \u00df . \u00df) . (\u00df . \u00df) . \u00df) the following fusion law holds: foldList (buildList \ng)= g. Hence, the above calculation can be continued: = fst ((.ncr .let f [] = n f (x : xs)= cx (r (fxs)) \nin fl) (.ys .(ys,ys)) (.xhys .(x : (fst (hys)),snd (h (x : ys)))) (.hys .swap (hys)) []). In the next \nsubsection we will see that this calculated program shuf\u00ad.es the list l much more ef.ciently than the \noriginal shuf.e-function did. The reason is that the original occurrences of list reverse have been replaced \nby an optimized implementation making use of the fact that two consecutive reversals cancel each other. \n 4.4 For General Use Similarly to the development for shuf.e in the last three subsec\u00adtions we could \nalso proceed for other list producing functions that use reverse. In order to increase modularity, we \nintroduce the vanishrev-combinator in Figure 4 by generalizing the calculation result in the previous \nsubsection. vanishrev :: .a . (.\u00df . \u00df . (a . \u00df . \u00df) . (\u00df . \u00df) . \u00df) . [a] vanishrev g = fst (g (.ys .(ys,ys)) \n(.xhys .(x : (fst (hys)), snd (h (x : ys)))) (.hys .swap (hys)) []) Figure 4. De.nition of vanishrev. \nThen, we can replace shuf.e from the beginning of this section by: shuf.e. :: .a . [a] . [a] shuf.e. \nl = vanishrev (.ncr .let f [] = n f (x : xs)= cx (r (fxs)) in fl) Runtimes of shuf.e and shuf.e. are \ncompared in the following table: n = 2000 4000 6000 8000 10000 shuf.e [1..n] shuf.e. [1..n] 0.33 0.005 \n1.3 0.01 2.8 0.016 5.0 0.02 8.0 0.025 The development so far relied on the fact that indeed we have \nconvert Cconvert. (and on the correctness of shortcut deforesta\u00adtion). Instead of proving this auxiliary \nfact, we directly give a result similar to Theorem 1 that can then be used to transform shuf.e into shuf.e. \nwithout needing the calculations in the previous three sub\u00adsections. Those calculations and the List \ndata type only appeared for illustrating our general methodology (as summarized in the next subsection) \nof how to obtain optimizing vanish-combinators. THEOREM 2. For every .xed type A and function g :: .\u00df \n. \u00df . (A . \u00df . \u00df) . (\u00df . \u00df) . \u00df holds: g [] (:) reverse C vanishrev g (19) The theorem is a consequence \nof the free theorem for the type of g. Its proof using the laws (2) (9) from Figure 3 is very similar \nto but easier than the proof of Theorem 3 in Appendix A. That is why we omit it here. We only note \nthat the approximation C emerges, because in lazy functional programming languages, where in.nite data \nstructures might be present, we have reverse .reverse Cid cf. law (8) but not reverse .reverse = id. \nThis is not harmful, because we can still safely optimize (g [] (:) reverse) to (vanishrev g), which \nis at least as de.ned , whenever this replacement is type-correct. For our example this implies shuf.e \nCshuf.e, and the replacement shuf.e. is not only more ef.cient, but also has in certain contexts a better \ntermination behavior than the original speci.cation of shuf.e. For example, we have: shuf.e [1..]= 1: \n. C shuf.e. [1..]= 1: 3: 5:7: 9: 11 : \u00b7\u00b7\u00b7  4.5 The Methodology Summarized We informally summarize our \nmethodology of eliminating manip\u00adulating operations f1,...,fn for some algebraic data type D by the following \nsteps: 1. Extend D to a new data type D ' with additional construc\u00adtors for the manipulating operations \nf1,..., fn and express D\u00adproducers as builds for this extended data type D ' , freezing f1,..., fn as \nconstructors (compare Section 4.1). 2. Invent an ef.cient conversion function convert. from D '  D'.D \nto D and express it using a fold over D ' (compare Section 4.2). 3. Introduce a vanish-function that \ncomposes D '-producers with convert. : D '.D vanishf1 ,...,fn g = convert. (buildD ' g), D '.D and use \nfusion of buildD' vs. foldD' to eliminate the inter\u00admediate result of type D ' in this de.nition. Finally, \nuse the free theorem of g s type to prove that vanishf1 ,...,fn has the in\u00adtended semantics i.e., is \nsuitable as replacement of buildD' for expressing D-producers that use f1,..., fn thus justify\u00ading the \nchoice of convert. (compare Sections 4.3 and 4.4). D '.D The key step that requires ingenuity here is \nof course the invention of an ef.cient conversion function, which naturally depends on the semantics \nof the involved operations f1,...,fn. While it is unlikely that one can .nd a general strategy replacing \nthis creative step, the chance of success is rather high if f1,..., fn are related by a rich algebraic \ntheory of equations or approximations. In particular, one should consider such relationships for which \none of the two sides of an equation (or the more de.ned side of an approximation) is more favorable with \nrespect to ef.ciency. For example, the derivation of vanish+ was guided by law (3), whereas the given \nimplementation of the convert-function in Section 4.2 was motivated by law (8) in Figure 3. Law (12) \nplays a similar role for optimizing repeated applications of map in the next section.  5 The Concatenate, \nReverse and Map Vanish In this section we present the result of applying our methodology as summarized \nin Section 4.5 to the standard list data type, 3 eliminating the manipulating operations (++), reverse \nand map. We obtain the rather scary de.nition of vanish+ ,rev,map in Figure 5. However, once we have \nproved the following theorem, there is no need for the user of our combinator library [1] to be aware \nof this de.nition. THEOREM 3. For every .xed type A and function g :: .\u00df. \u00df .(A .\u00df .\u00df) .(\u00df .\u00df .\u00df) .(\u00df \n.\u00df) .((A .A) .\u00df .\u00df) .\u00df holds: g [] (:)(++) reverse map Cvanish+ ,rev,map g (20) The theorem is proved \nin Appendix A as a direct consequence of the free theorem for g s type, using de.nitions from Figure \n2 and the laws (2) (15). We show how the theorem is applied in an example that will also be used for \ncomparison with a list elimination approach by shortcut deforestation for polymorphically recursive workers \nin Section 7.1. Example 3. Consider the following speci.cation of a function inits that returns the list \nof initial segments of its argument list e.g., inits [1..4] = [[],[1],[1,2], [1,2,3], [1,2,3, 4]] : \ninits :: .a. [a] .[[a]] inits [] = [[]] inits (x : xs)= [] : (map (x :)(inits xs)) By abstracting from \nthe list constructors of the outer result list including map and using Theorem 3, inits can be replaced \nby: inits. :: .a. [a] .[[a]] inits. l = vanish+ ,rev,map (.ncarm .let f [] =[] c n f (x : xs)= [] c (m \n(x :)(fxs)) in fl) Note that abstracting also from the constructors [] and (:) of the inner lists would \nnot be type-correct4. Runtimes of inits and inits. to compute the same nested lists are compared in the \nfollowing table: n = 1000 2000 3000 4000 5000 inits [1..n] inits. [1..n] 0.35 0.08 1.3 0.3 3.2 0.7 6.0 \n1.3 9.0 2.0 These measurements show an improvement by a constant factor, because inits. avoids the repeated \nmapping of functions of the form (x :) over intermediate lists between recursive calls. Inlining the \nde.nition of vanish+ ,rev,map would show that instead the initial 3Only mapping of functions f :: A .A \nfor some type A is con\u00adsidered, because otherwise vanish+ ,rev,map would require polymor\u00adphic recursion \nand a rank-3 type with quanti.cation over type con\u00adstructors. 4Unfortunately, the messages produced by \ncurrent Haskell im\u00adplementations in case of insuf.cient polymorphism are often not very helpful in diagnosing \nsuch errors. More advanced type expla\u00adnation and correction techniques exist see, e.g., [29, 8, 18] \n but not in the presence of higher-ranked polymorphism. segments are accumulated in a functional list \nrepresentation. Since the overall number of (:)-operations required for building the nested output list \nis still quadratic in the length of the input list, the asymp\u00adtotic complexity is not changed here. . \n 6 The Concatenate Vanishes from Nested Lists Already Hughes noted that not all instances of his concatenate \nop\u00adtimization by representing lists as functions [12] can be achieved through introduction of accumulating \nparameters. As an example he considers an inef.cient function .elds for breaking up a list of characters \ninto a list of words: .elds :: [Char] .[[Char]] .elds s = let f [] =[] f (x : xs) |x == '' = fxs |otherwise \n= g [x] xs x/= '' gw (x : xs) |= g (w ++[x]) xs gw xs = w : (fxs) in fs Also our vanish+ ,rev,map-combinator \ncannot eliminate the repeated concatenations that build up the single words in the result list. The reason \nis that these concatenations take place on the inner lists of .elds result, in contrast to the example \ninits from the last section, where the maps over the outer list where eliminated. Of course, we should \nnot expect a successful optimization here, because vanish+ and vanish+ ,rev,map were developed to eliminate \nfunction calls to (++) :: [a] .[a] .[a] from a list producer with result type [a] and not from one with \nresult type [[a]]. The realization that we have to deal with this as a new data type different from [a] \npaves the way to success for optimizing also con\u00adcatenations on the inner lists. Namely, we can apply \nour methodol\u00adogy as summarized in Section 4.5 to eliminate manipulating opera\u00adtions (++) :: [a] .[a] \n.[a] and (++) :: [[a]] .[[a]] .[[a]] from producers of nested lists of the algebraic data type [[a]]. \nTherefor, we simply apply the trick of replacing lists by functions twice, once on the inner lists and \nonce on the outer list. The out\u00adcome is the combinator vanish+ ,+ in Figure 6, with semantics as given \nby the theorem below. vanish+ ,+ :: .a. (.\u00df.. \u00df .(a .\u00df .\u00df) .(\u00df .\u00df .\u00df) .. .(\u00df .. ..) .(. .. ..) ..) .[[a]] \nvanish+ ,+ g = gid (.xhys .x : (hys)) (.) id (.hhsyss .(h []) : (hs yss)) (.)[] Figure 6. De.nition of \nvanish+ ,+ . THEOREM 4. For every .xed type A and function g :: .\u00df.. \u00df .(A .\u00df .\u00df) .(\u00df .\u00df .\u00df) .. .(\u00df \n.. ..) .(. .. ..) .. holds: g [] (:)(++) [] (:)(++) = vanish+ ,+ g (21) The proof of this theorem \nusing the free theorem of g s type and the laws (1) (4) from Figure 3 is only slightly more dif.cult \nthan the proof of Theorem 1, but is omitted here due to space constraints. vanish+ ,rev,map :: .a . (.\u00df \n. \u00df .(a .\u00df .\u00df) .(\u00df .\u00df .\u00df) .(\u00df .\u00df) .((a .a) .\u00df .\u00df) .\u00df) .[a] vanish+ ,rev,map g = fst (g (.fys .(ys, ys)) \n(.xhf ys .((fx) : (fst (hf ys)),snd (hf ((fx) : ys)))) (.h1 h2 fys .(fst (h1 f (fst (h2 fys))),snd (h2 \nf (snd (h1 fys))))) (.hf ys .swap (hf ys)) (.khf ys .h (f .k) ys) id []) Figure 5. De.nition of vanish+ \n,rev,map. In order to show how vanish+ ,+ eliminates concatenate operations from producers of nested \nlists, we apply it to .elds. Example 4. Consider the function de.nition of .elds from above. Abstracting \nfrom the list constructors [], (:) and (++) type\u00adcorrectly and using law (21) from Theorem 4, this de.nition \nis equivalent to the much more ef.cient: .elds. :: [Char] .[[Char]] .elds. s = vanish+ ,+ (.ncannccaa \n. let f [] = nn f (x : xs) |= fxs x == '' |otherwise = g (x c n) xs gw (x : xs) |x/= '' = g (w a (x c \nn)) xs gw xs = w cc (fxs) in fs) By inlining the de.nition of vanish+ ,+ and performing some beta\u00adreductions \nand let-.oating, we obtain the variant .elds. s = let f [] = id f (x : xs) |= fxs x == '' |otherwise \n= g (.ys .x : ys) xs gw (x : xs) |x/= '' = g (w .(.ys .x : ys)) xs gw xs = .yss .(w []) : (f xs yss) \nin fs [] which differs from Hughes result only in that the functional repre\u00adsentation is also used for \nproduction of the outer list. .  7 Comparison with Related Work 7.1 Shortcut Deforestation Gill [9] \ngives an example of a recursive function consuming its own result via foldr and shows how a worker/wrapper \nscheme of short\u00adcut deforestation can improve the asymptotic time complexity of this function by removing \nintermediate lists between recursive calls with law (17). In a similar way, Chitil [7] uses the representation \nof map as a foldr to transform the speci.cation of inits from Exam\u00adple 3 into essentially the following: \ninits ' :: .a . [a] .[[a]] inits ' l = let fcn [] =[] c n fcn (x : xs)= [] c (f (.ys yss .(x : ys) c \nyss) nxs) in f (:)[] l This is achieved by .rstly splitting inits into a wrapper and a worker that uses \npolymorphic recursion, and then applying shortcut defor\u00adestation inside the worker. While there is no \nobvious connection between inits. and inits ' , their runtimes are comparable: However, inits. leaves \nroom for further improvement by using a more specialized vanishmap-combinator instead of the function \nvanish+ ,rev,map. Note that such a switch from using one vanish\u00adcombinator to using a more general or \na more speci.c one is usually easy, in this case by dropping a and r from the list of .-abstracted variables \nin the de.nition of inits. . On the other hand, Chitil s method does not work for functions like, e.g., \npart and .elds. Also, he discourages the use of his own ap\u00adproach (to automatically obtain inits 'by \ntype inference based de\u00adforestation) in the following words: This power is, however, a double-edged sword. \nA small syntactic change of a program [...] may cause defor\u00adestation to be no longer applicable, and \nthus change the asymptotic complexity of the program. It may hence be argued that such far-reaching modi.cations \nshould be left to the programmer. Our approach can provide the programmer with exactly this control. \nMoreover, it solves the problem in Section 3.4.3 of [7], because our method can optimize the foldr-form \nof the na\u00a8ive list reverse: rev :: .a . [a] .[a] rev l = foldr (.xh .h ++[x]) [] l by transforming it \ninto: rev. :: .a . [a] .[a] rev. l = vanish+ (.nca .foldr (.xh .h a (x c n)) nl) = foldr (.xhys .h (x \n: ys)) id l [] Thus, our method has eliminated the inef.cient concatenations without destroying the \npossibility of using shortcut deforestation with rev. as list consumer. Of course, our technique does \nnot supersede shortcut deforestation, because law (17) is also applicable to remove intermediate lists \nin a variety of cases that are not addressed by our approach of eliminat\u00ading particular data manipulating \noperations. Rather, the two tech\u00adniques complement each other quite well. Note however, that pro\u00adgrams \nusing the vanish-combinators bene.t from our optimization method without requiring any additional support \nfrom the compiler, whereas optimization by shortcut deforestation crucially depends on a compiler that \nmakes some nontrivial effort to apply law (17) or an equivalent of it at as many places as possible. \nSvenningsson [26] proposes a new destroy/unfoldr-rule that gives rise to further possibilities of intermediate \nlist removal and is in many respects a dual of law (17). Since our vanish-combinators vary the idea of \nshortcut deforestation by abstracting not only over data constructors, but also over other data manipulating \noper\u00adations it might be interesting to investigate whether a dual varia\u00adtion of the destroy/unfoldr-technique \nalso exists. 7.2 Accumulating Parameters n = 1000 2000 3000 4000 5000 inits. [1..n] inits '[1..n] 0.08 \n0.07 0.3 0.3 0.7 0.8 1.3 1.2 2.0 2.0  Wadler [27] presented a transformation that eliminates concatenate \noperations by introducing accumulating parameters. For example, the function hanoi from Example 1 is \nimproved to hanoi ' by gener\u00adalizing the local function f to f + with an additional list argument and \napplying a set of rewrite laws to the right-hand sides of a na\u00a8ive de.nition of f + , .nally yielding: \nhanoi ' :: Int . [(Pos, Pos)] hanoi ' t = let f + 1 pqr ys =(p,q) : ys f + (s + 1) pqr ys = f + sprq \n((p,q) : (f + sr qpys)) in f + t LRM [] The success of this method depends on the characterization of \nfunc\u00adtions as creative. For example, an attempted application to the in\u00adtroductory example part produces \nthe following de.nition: part ' :: .a . (a . Bool) . [a] . [a] part ' pl = let f + [] zys = z + ys f \n+ (x : xs) zys = if px then x : (f + xs z ys) else f + xs (z ++[x]) ys in f + l [] [] Note that here \nthe concatenate does not vanish. The characteriza\u00adtion of part as plagiarizing comes somewhat as a surprise, \nbecause part clearly does allocate each cons cell in its result and thus should be manageable and is \nso with our new method. On the other hand, it is easy to see that all functions ful.lling Wadler s syntactic \ntest for creativity also allow the type-correct ab\u00adstraction from list constructors [], (:) and (++), \nand can thus also be transformed by our technique. Hence, vanish+ captures the in\u00adtroduction of an accumulating \nparameter as can be seen by compar\u00ading the above function hanoi ' with the .nal de.nition obtained for \nhanoi. in Example 1. Albert et al. [3] achieve the effects of Wadler s transformation for functional \nlogic programs by temporarily introducing difference\u00adlists that are then replaced by accumulating parameters. \nTheir tech\u00adnique fails for the same examples as Wadler s, hence it would be interesting to study our \nmethod also in the more general framework of functional logic programming languages. K\u00a8uhnemann et al. \n[15] generalize list concatenation to tree sub\u00adstitution functions and eliminate such substitution functions \nfrom top-down tree transducer modules by introducing accumulating pa\u00adrameters. Their integration step \ncould also be realized in the framework of our methodology, thus generalizing their accumula\u00adtion technique \nto arbitrary functions that produce trees. Bird [4], Hu et al. [11] use calculational methods to derive \naccumu\u00adlative programs in their setting higher-order folds over algebraic data types from .rst-order \nfolds, such as transforming rev from the previous subsection into rev. (which none of the other accu\u00admulation \nmethods discussed here achieves). Their techniques have a wider scope in deriving new algorithms rather \nthan just elimi\u00adnating inef.cient function calls. On the other hand, they can only handle programs expressed \nwith a .xed set of recursion operators, and must of course fail where introduction of accumulating \nparameters cannot remove the inef.ciencies. Further approaches for deriving accumulative algorithms are \ncompared by Boiten [5].  7.3 Abstract Data Types Our steps of freezing and ef.cient conversion have \nsimilar goals as the transition from a term representation to a context\u00adpassing representation in Hughes \nmethodology for implementing domain-speci.c languages [13]. In fact, one might conceive, e.g., our developments \nin Sections 4.1 4.3 as the construction of yet an\u00adother novel representation of lists in the sense of \n[12], but this time with support for ef.cient reversal instead of concatenation. Hence, the described \nmethodology is another way to synthesize ef.cient implementations of abstract data types from the knowledge \nabout algebraic properties of the involved operations. While Hughes uses this knowledge to guide the \nchoice of the contexts from which to abstract, we employ it in the de.nition of convert-functions. The \nrank-2 polymorphic vanish-combinators encode such ef.cient implementations by introducing a form of anonymous \nabstract data types. This local encapsulation limits cross-function optimization, but is the key to proving \nthe correctness of transformations by free theorems. In particular, there are no analogues in Hughes \nmethod\u00adology to our Theorems 1 4 that embody each optimization in a sin\u00adgle rule. It is unclear how other \nencodings of abstract data types could be employed semantically to do such proofs or even to for\u00admalize \nthe essence of transformations in such a concise way. Also, the expression of optimizations by uniform \nabstraction from data constructors and manipulating functions paves the way to automa\u00adtion using Chitil \ns approach of data abstraction by type inference.  8 Conclusion In this paper we developed a combinator \nlibrary to optimize list producers involving the operations + , reverse and map. The in\u00adtroduced methodology \nis also applicable to eliminate other list ma\u00adnipulations e.g., the well-known .lter-function [1] and \nfor nested lists and other algebraic data types. We would like to further investigate the interplay between \nour tech\u00adnique and the elimination of intermediate results by shortcut defor\u00adestation. As seen in Section \n7.1, a good consumer (one consum\u00ading its argument uniformly with foldr) remains good after apply\u00ading \nour technique. Moreover, we can straightforwardly express the vanish-functions in build-form, for example: \nvanish+ g = build (.cn . gid (.xh ys . x c (hys)) (.) n) Then, every function expressed with vanish+ \nis a good producer (one producing its result uniformly with build). For example, part. becomes a good \nproducer, while part was none. Furthermore, one can dualize Chitil s approach of deforesting functions \nthat consume their own result with foldr to deforesting functions that construct their own argument with \nbuild , which is then also appli\u00adcable to the examples part and .elds. We have observed various examples \nwhere our method leads to dra\u00admatic ef.ciency improvements. However, a general statement about the relation \nbetween the runtimes of original and transformed pro\u00adgrams is hard to make. Moran &#38; Sands [19] argue \nthat Wadler s accumulation technique will never degrade ef.ciency by more than a constant factor. We \nbelieve that the same is true for our more gen\u00aderal technique of concatenate elimination and would like \nto investi\u00adgate this claim formally. For computing the asymptotic time com\u00adplexity of transformed programs \nthat use vanish+ ,rev,map, the run\u00adtime for performing the original + -, reverse-and map-operations can \nbe considered as constant rather than linear in the lengths of the lists they consume. In other applications \nof our methodology the ef.ciency of course depends on the quality of the chosen imple\u00admentation for convert. \n. 9 Acknowledgments I want to thank Claus J\u00a8urgensen and Armin K\u00a8uhnemann for com\u00adments and useful suggestions \non drafts of this paper. Discussions with Olaf Chitil and Josef Svenningsson and remarks by the ICFP \nreferees also provided interesting insights and inspiration for future research. 10 References [1] http://wwwtcs.inf.tu-dresden.de/~voigt/Vanish.lhs \n. [2] The Haskell 98 Report. http://haskell.org/onlinereport . [3] E. Albert, C. Ferri, F. Steiner, and \nG. Vidal. Improving func\u00adtional logic programs by difference-lists. In Advances in Com\u00adputing Science, \nPenang, Malaysia, Proceedings, volume 1961 of LNCS, pages 237 254. Springer-Verlag, 2000. [4] R. Bird. \nThe promotion and accumulation strategies in trans\u00adformational programming. ACM Trans. on Prog. Lang. \nand Systems, 6:487 504, 1984. Addendum Ibid., 7:490 492, 1985. [5] E. Boiten. The many disguises of accumulation. \nTechnical Report 91-26, Dept. of Informatics, University of Nijmegen, 1991. [6] O. Chitil. Type inference \nbuilds a short cut to deforestation. In International Conference on Functional Programming, Paris, France, \nProceedings, pages 249 260. ACM Press, 1999. [7] O. Chitil. Type-Inference Based Deforestation of Functional \nPrograms. PhD thesis, RWTH Aachen, 2000. [8] O. Chitil. Compositional explanation of types and algorith\u00admic \ndebugging of type errors. In International Conference on Functional Programming, Florence, Italy, Proceedings, \npages 193 204. ACM Press, 2001. [9] A. Gill. Cheap Deforestation for Non-strict Functional Lan\u00adguages. \nPhD thesis, University of Glasgow, 1996. [10] A. Gill, J. Launchbury, and S. Peyton Jones. A short cut \nto deforestation. In Functional Programming Languages and Computer Architecture, Copenhagen, Denmark, \nProceedings, pages 223 232. ACM Press, 1993. [11] Z. Hu, H. Iwasaki, and M. Takeichi. Calculating accumula\u00adtions. \nNew Generation Computing, 17:153 173, 1999. [12] J. Hughes. A novel representation of lists and its applica\u00adtion \nto the function reverse . Information Processing Letters, 22:141 144, 1986. [13] J. Hughes. The design \nof a pretty-printing library. In Advanced Functional Programming, volume 925 of LNCS, pages 53 96. Springer-Verlag, \n1995. [14] P. Johann. Short cut fusion: Proved and improved. In Se\u00admantics, Applications, and Implementation \nof Program Gen\u00aderation, Florence, Italy, Proceedings, volume 2196 of LNCS, pages 47 71. Springer-Verlag, \n2001. [15] A. K\u00a8uhnemann, R. Gl\u00a8uck, and K. Kakehi. Relating accumula\u00adtive and non-accumulative functional \nprograms. In Rewriting Techniques and Applications, Utrecht, The Netherlands, Pro\u00adceedings, volume 2051 \nof LNCS, pages 154 168. Springer-Verlag, 2001. [16] J. Launchbury and R. Paterson. Parametricity and \nunbox\u00ading with unpointed types. In European Symposium on Pro\u00adgramming, Link\u00a8oping, Sweden, Proceedings, \nvolume 1058 of LNCS, pages 204 218. Springer-Verlag, 1996. [17] D. Leivant. Polymorphic type inference. \nIn Principles of Pro\u00adgramming Languages, Austin, Texas, Proceedings, pages 88 98. ACM Press, 1983. [18] \nB. McAdam. Repairing Type Errors in Functional Programs. PhD thesis, University of Edinburgh, 2002. [19] \nA. Moran and D. Sands. Improvement in a lazy context: An operational theory for call-by-need. In Principles \nof Program\u00adming Languages, San Antonio, Texas, Proceedings, pages 43 56. ACM Press, 1999. [20] S. Peyton \nJones, W. Partain, and A. Santos. Let-.oating: Moving bindings to give faster programs. In International \nConference on Functional Programming, Philadelphia, Penn\u00adsylvania, Proceedings, pages 1 12. ACM Press, \n1996. [21] S. Peyton Jones and A. Santos. A transformation-based opti\u00admiser for Haskell. Sci. of Comput. \nProg., 32:3 47, 1998. [22] A. Pitts. Parametric polymorphism and operational equiva\u00adlence. Math. Struct. \nComput. Sci., 10:321 359, 2000. [23] J. Reynolds. Types, abstraction and parametric polymor\u00adphism. In \nInformation Processing, Paris, France, Proceed\u00adings, pages 513 523. Elsevier Science Publishers B.V., \n1983. [24] D. Schmidt. Denotational Semantics: A Methodology for Language Development. Allyn and Bacon, \n1986. [25] T. Sheard, Z. Benaissa, and M. Martel. Introduction to multi\u00adstage programming using MetaML. \nhttp://cse.ogi.edu/~sheard/papers/manual.ps . [26] J. Svenningsson. Shortcut fusion for accumulating \nparameters and zip-like functions. In International Conference on Func\u00adtional Programming, Pittsburgh, \nPennsylvania, Proceedings. ACM Press, 2002. [27] P. Wadler. The concatenate vanishes. Note, University \nof Glasgow, 1987 (revised, 1989). [28] P. Wadler. Theorems for free! In Functional Program\u00adming Languages \nand Computer Architecture, London, Eng\u00adland, Proceedings, pages 347 359. ACM Press, 1989. [29] J. Yang, \nG. Michaelson, P. Trinder, and J. Wells. Improved type error reporting. In Implementation of Functional \nLan\u00adguages, Aachen, Germany, Draft Proceedings, pages 71 86, 2000. A Proof of Theorem 3 PROOF. The free \ntheorem associated with g s type is that for every choice of types B and B ', values n :: B, n ' :: B \n' , c :: A . B . B, c ' :: A . B '. B ' , a :: B . B . B, a ' :: B '. B '. B ' , r :: B . B, r ' :: B \n'. B ' , m :: (A . A) . B . B and m ' :: (A . A) . B '. B ', and an admissible relation R . B \u00d7 B ' , \nthe following holds: (n,n ') . R . (.x :: A, (l,l ') . R . (cxl, c ' xl ') . R ) . (.(l1,l ' 1) . R ,(l2,l \n' 2) . R . (al1 l2,a ' l ' 1 l ' 2) . R ) . (.(l,l ') . R . (rl,r ' l ') . R ) . (.k :: A . A, (l,l ') \n. R . (mkl,m ' kl ') . R ) '' '' . (gncarm,gncar m ') . R . Instantiating this with B =[A], n =[], c \n=(:), a =(++), r = reverse, m = map, B ' =(A . A) . [A] . ([A],[A]) and: ' n =(.fys . (ys,ys)) ' c =(.xhf \nys . ((fx) : (fst (hf ys)),snd (hf ((fx) : ys)))) ' a =(.h1 h2 fys . (fst (h1 f (fst (h2 fys))), snd \n(h2 f (snd (h1 fys))))) ' r =(.hf ys . swap (hf ys)) ' m =(.khf ys . h (f . k) ys), we obtain (modulo \nbeta-equality): ([],(.fys .(ys,ys))) .R . (.x :: A, (l,l ') .R . (x : l, (.fys .((fx) : (fst (l ' fys)), \nsnd (l ' f ((fx) : ys))))) .R ) . (.(l1,l ' 1) .R ,(l2,l ' 2) .R . (l1 + l2,(.fys .(fst (l ' 1 f (fst \n(l ' 2 fys))), snd (l ' 2 f (snd (l ' 1 fys)))))) .R ) . (.(l,l ') .R . (reverse l,(.fys .swap (l ' fys))) \n.R ) . (.k :: A .A, (l,l ') .R . (mapkl,(.fys .l ' (f .k) ys)) .R ) '''' ' . (g [] (:)(++) reverse map, \ngncar m ) .R . If we choose the admissible relation5 R = {(p,q) |.f :: A .A,u :: [A] . (mapf p)++ u Cfst \n(qf u) . (map f (reverse p)) + u Csnd (qf u)}, then the conjuncts in the precondition of this implication \nread as follows (modulo some beta-reductions and the de.nitions of fst and snd): (i). .f :: A .A, u :: \n[A] . (map f []) + u Cu .(map f (reverse [])) + u Cu (ii). for every x :: A, l :: B and l ' :: B ' : \n(.f :: A .A,v :: [A] . (mapf l)++ v Cfst (l ' fv) . (map f (reverse l)) + v Csnd (l ' fv)) . (.f :: A \n.A,u :: [A] . (map f (x : l)) + u C(fx) : (fst (l ' fu)) . (map f (reverse (x : l))) + u Csnd (l ' f \n((fx) : u))) (iii). for every l1,l2 :: B and l ' 1,l ' 2 :: B ' : (.f :: A .A,v :: [A] . (mapf l1)++ \nv Cfst (l ' 1 fv) . (map f (reverse l1)) + v Csnd (l ' 1 fv) . (mapf l2)++ v Cfst (l ' 2 fv) . (map f \n(reverse l2)) + v Csnd (l ' 2 fv)) . (.f :: A .A,u :: [A] . (map f (l1 + l2)) + u C fst (l ' 1 f (fst \n(l ' 2 fu))) . (map f (reverse (l1 + l2))) + u C snd (l ' 2 f (snd (l ' 1 fu)))) (iv). for every l :: \nB and l ' :: B ' : (.f :: A .A,v :: [A] . (mapf l)++ v Cfst (l ' fv) . (map f (reverse l)) + v Csnd (l \n' fv)) . (.f :: A .A,u :: [A] . (map f (reverse l)) + u C fst (swap (l ' fu)) . (map f (reverse (reverse \nl))) + u C snd (swap (l ' fu))) 5Again, it is easy to see that (.,.) .R by laws (7), (14) and (2). Continuity \nof R is shown by using the facts that the re\u00adlation Cis continuous and that the involved Haskell-functions \nare monotonic and continuous. (v). for every k :: A .A, l :: B and l ' :: B ' : ' (.f :: A .A, v :: \n[A] . ' ' (mapf l)++ v Cfst (l ' fv) '' .(map f (reverse l)) + v Csnd (l ' fv)) . (.f :: A .A,u :: [A] \n. (map f (map k l)) + u Cfst (l ' (f .k) u) .(map f (reverse (map k l))) + u Csnd (l ' (f .k) u)). Using \nre.exivity and transitivity of Cand monotonicity of the in\u00advolved Haskell functions, these .ve conditions \ncan be established as follows: (i). by the de.nitions of map, (++) and reverse (ii). by the de.nitions \nof map and (++) and the laws (9), (11) and (3) (iii). by the laws (11), (3) and (10) (iv). by the laws \n(5), (8) and (6) (v). by the laws (12) and (13). As consequence of the instantiated free theorem we \nthus obtain: '''' ' (g [] (:)(++) reverse map, gncar m ) .R . Using our de.nition of R , from this follows \n.f :: A .A,u :: [A] . (map f (g [] (:)(++) reverse map)) ++ u '''' ' C fst (gncar mfu), which for f \n= id and u =[] implies using laws (4) and (15) and the de.nition of vanish+ ,rev,map the following \ncalculation: g [] (:)(++) reverse map =(map id (g [] (:)(++) reverse map)) ++[] '''' ' C fst (gncar mid \n[]) = vanish+ ,rev,map g.  B Introducing Strict Evaluation The equality stated in law (18) from Theorem \n1 does not neces\u00adsarily hold as such if g makes use of the strict evaluation primitive seq :: .a\u00df. a \n. \u00df . \u00df, de.ned in Haskell 98 by the following equations: seq .b = . seq a b = b, if a = . The reason \nis that for the relation R used in the proof we have (.,.ys ..) .R , but from (p,q) .R does not necessarily \nfol\u00adlow (seq .p,seq (.ys ..) q) .R , because seq distinguishes be\u00adtween .and (.ys ..). Hence, seq does \nnot map R -related argu\u00adments to R -related results (as it should if we want to exploit para\u00admetricity), \nand thus R is not suitable for usage in the free theorem of g s type if g may be de.ned using seq. This \nproblem can be .xed with an analogous strategy as used in Section 7 of [28] to enrich the functional \nlanguage with the .xpoint primitive while preserving parametricity, namely by imposing fur\u00adther requirements \non the relations used in free theorems. That is to say, we must restrict ourselves to relations that \nrespect seq,inthe ' sense that for such relations A and B it must follow from (a,a ) .A ' and (b,b \n') .B that also (seqab,seqa b ') .B. This can be guar\u00ad anteed if every relation X .X \u00d7X ' used in the \nproof contains all '' pairs (.,x ) with x :: X ', but no pair (x,.) with x . = . Hence, we extend the \nrelational interpretation of base types and also of the .xed type A from identity relations to the \npartial or\u00adder Cand enlarge R to R ' = {(p,q) .B \u00d7B '|.u :: [A] . p + u Cqu}, where admissibility of \nR ' follows from admissibility of C and monotonicity and continuity of (++). The instantiated free theorem \nthen reads as follows: ([],id) .R ' ' . (.x,x :: A, (l,l ') .R ' . '' x Cx .(x : l, (.xh ys .x : (hys)) \nxl ') .R ') . (.(l1,l ' 1) .R ' ,(l2,l ' 2) .R ' . (l1 + l2,l ' 1 .l ' 2) .R ') . (g [] (:)(++),gid (.xhys \n.x : (hys)) (.)) .R ' . With similar reasoning as in the proof of Theorem 1 additionally using re.exivity \nand transitivity of Cand monotonicity of (:) and (++) we can validate the three conjuncts in the precondition \nand obtain from the implied consequence the following replacement for law (18): g [] (:)(++) C vanish+ \ng (22) Likewise, the proof of Theorem 4 can be adapted to give in the presence of seq: g [] (:)(++) [] \n(:)(++) C vanish+ ,+ g (23) Hence, our concatenate elimination is still applicable, it just be\u00adcomes \nan approximation being at least as de.ned, but potentially improving termination behavior instead of \na semantic equality. Note that this is already the case for Hughes technique [12], because of: seq .b \n= .C b = seq (.ys ..+ ys) b = seq (rep .) b. The statements of Theorems 2 and 3 are not affected by \nthe presence of seq, because their proofs already use relations R that ful.ll the above restrictions \nand it is straightforward to adapt those proofs to use the partial order C instead of identity as relational \ninterpretation for base types and for A. Thus, our situation is much better than that of shortcut deforesta\u00adtion, \nwhich in the presence of unrestricted use of seq can transform terminating programs into non-terminating \nones, for example: foldr .[] (build seq)=foldr .[] (seq (:) [])=foldr .[] []=[], but after application \nof law (17) to foldr .[] (build seq) : seq .[] = .. This .aw of shortcut deforestation may be remedied \nusing more re\u00adstricted quali.ed types for build or seq, similarly to the strategy of Launchbury &#38; \nPaterson [16] for avoiding strictness side conditions on free theorems. This approach might also be applicable \nin our set\u00adting to control the use of seq and thus preserve laws (18) and (21) instead of (22) and (23). \n \n\t\t\t", "proc_id": "581478", "abstract": "We introduce a new transformation method to eliminate intermediate data structures occurring in functional programs due to repeated list concatenations and other data manipulations (additionally exemplified with list reversal and mapping of functions over lists).The general idea is to uniformly abstract from data constructors and manipulating operations by means of rank-2 polymorphic combinators that exploit algebraic properties of these operations to provide an optimized implementation. The correctness of transformations is proved by using the <i>free theorems</i> derivable from parametric polymorphic types.", "authors": [{"name": "Janis Voigtl&#228;nder", "author_profile_id": "81100011863", "affiliation": "Dresden University of Technology, Dresden, Germany", "person_id": "P394765", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/581478.581481", "year": "2002", "article_id": "581481", "conference": "ICFP", "title": "Concatenate, reverse and map vanish for free", "url": "http://dl.acm.org/citation.cfm?id=581481"}