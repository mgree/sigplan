{"article_publication_date": "09-17-2002", "fulltext": "\n An Expressive, Scalable Type Theory for Certi.ed Code Karl Crary Joseph C. Vanderwaart Carnegie Mellon \nUniversity Abstract We present the type theory LTT, intended to form a basis for typed target languages, \nproviding an internal notion of logi\u00adcal proposition and proof. The inclusion of explicit proofs al\u00adlows \nthe type system to guarantee properties that would oth\u00aderwise be incompatible with decidable type checking. \nLTT also provides linear facilities for tracking ephemeral proper\u00adties that hold only for certain program \nstates. Our type theory allows for re-use of typechecking soft\u00adware by casting a variety of type systems \nwithin a single language. We illustrate our methodology of representation by means of two examples, one \nfunctional and one state\u00adful, and describe the associated operational semantics and proofs of type safety. \nCategories and Subject Descriptors D.3[Programming Languages]: Miscellaneous; F.3.1 [Theory of Computation]: \nLogics and Meanings of Programs. General Terms Languages, Security Introduction Certi.ed code is a general \nstrategy for providing safety as\u00adsurances to extensible systems without utilizing hardware\u00adbased protection \nmechanisms. In a certi.ed code architec\u00adture, the supplier of any extension code accompanies his or her \ncode with some sort of checkable evidence that the code is safe to execute. Then the consumer of that \nextension code veri.es that safety evidence, thereby establishing the code s safety. A variety of certi.ed \ncode architectures exist, di.ering in the kind of code that is certi.ed and in the form that the safety \nevidence takes. For example, the SPIN system [2] cer\u00adti.es source-level Modula-3programs, and the Java \nVirtual This material is based on work supported in part by NSF grants CCR\u00ad9984812 and CCR-0121633. Any \nopinions, .ndings, and conclusions or recommendations in this publication are those of the authors and \ndo not re.ect the views of this agency. Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. ICFP 02, October 4 6, 2002, Pittsburgh, Pennsylvania, USA. Copyright \n2002 ACM 1-58113-487-8/02/0010 ...$5.00 Machine architecture [13] certi.es intermediate-level, byte\u00adcode \nprograms. Recently, there has been considerable inter\u00adest in certi.ed code architectures that operate \nat the level of executables, thereby eliminating the need for the code consumer either to trust the correctness \nof a just-in-time compiler, or to incur the performance cost of an interpreter. Two main directions have \nbeen explored for executable\u00adlevel certi.ed code: the proof-oriented approach exempli\u00ad.ed by Proof-Carrying \nCode (PCC) [17, 1], and the type\u00adtheoretic approach exempli.ed by Typed Assembly Lan\u00adguage (TAL) [16]. \nIn the proof-oriented approach, exe\u00adcutable programs are accompanied by explicit proofs of safety expressed \nin a formal logic. Safety is then veri.ed by checking the correctness of the proof. In the type-theoretic \napproach, executable programs are presented in a strongly typed executable language, for which a type \nsafety theorem ensures safety. Safety is then veri.ed by typechecking. In fact, the two approaches work \nout to be more simi\u00adlar than this might suggest, as the proof-oriented approach tends to be rather type-theoretic \nin practice. PCC safety proofs are usually structured using types, and existing im\u00adplementations of PCC \nall use the Edinburgh Logical Frame\u00adwork (LF) [8] as their formal logic, in which proof checking boils \ndown to type checking. Nevertheless, there is an impor\u00adtant di.erence between the extrinsic safety evidence \nof the proof-oriented approach, and the intrinsic safety evidence of the type-theoretic approach. Although \nthe proof-oriented and type-theoretic ap\u00adproaches each have various strengths and weaknesses we will \nnot discuss here, the proof-oriented approach has had two main advantages not enjoyed by the type-theoretic \nap\u00adproach: First, the proof-oriented approach has been able to pro\u00advide greater expressive power than \nhas the type-theoretic approach. This has been a direct result of the insistence in TAL on tractable \ntypechecking, which has limited the al\u00adlowable complexity of the type system. In contrast, in PCC safety \narguments can (in principle) be arbitrarily complex, because they are backed up by explicit proofs that \nthe code consumer need not be able to reproduce. Second, although both approaches have been shown to \nbe scalable to more powerful type systems [15, 26, 22, 1, 4], the proof-oriented approach enjoys much \ngreater internal scalability in the following sense: Each new extension to TAL requires a new type system, \nand therefore requires a new typechecker and a new type safety proof. In contrast, extensions to PCC \ndo not change the logic in which proofs are expressed, so the proof checker need not change. Thus, PCC \nhas been scalable from within the system, while TAL has been scaled from without. In this paper we present \na type theory devised to in\u00adcorporate these advantages of the proof-oriented approach. Our type theory \ncontains an explicit notion of logical propo\u00adsition and proof (encoded using the judgments-as-types cor\u00adrespondence) \nand allows such propositions to stand in func\u00adtion domains and codomains, thereby allowing arbitrarily \ncomplicated preconditions and postconditions. This intro\u00adduction of propositions and proofs as citizens \nof the type theory provides a natural and direct solution to the expres\u00adsiveness problem. Although our \nultimate interest is in certi.ed code, in this paper we present a high-level core language; this allows \nus to abstract from the idiosyncrasies of Typed Assembly Language that are not pertinent our present \npurposes. Our type theory, called LTT (for logical type theory ), is struc\u00adtured as a (higher-order) \npolymorphic lambda calculus, aug\u00admented with the constructs of the LF type theory. We chose LF for the \nlogical fragment of our language because it was speci.cally designed for encoding type systems; it has \nbeen used very e.ectively in certi.ed code already; excellent tools exist for constructing, manipulating \nand checking LF proofs; and it .ts very nicely into our type theory. LTT is designed in such a way that \nexisting results and tools pertaining to LF can be taken o.-the-shelf, without any substantial mod\u00adi.cation. \nJust as LF is instantiated to various di.erent logics by the choice of a signature (which provide kinds \nfor types con\u00adstants and types for term constants), LTT is instantiated to di.erent type theories by \nthe choice of a signature, speci\u00adfying ordinary types and terms as well as proof types and terms. This \nprovides internal scalability, as scaling LTT requires only changes to the signature, not changes to \nthe typechecker. Adding the logical power of LF alone provides substan\u00adtial expressive power for extensions \nto the type theory. As an example, we show how LTT can, by appropriate choice of a signature, express \na type system for arrays without auto\u00admatic bounds checking, following the ideas of Xi, Pfenning, and \nHarper [28, 27]. In this example, a well-typed array subscript operation must be supplied with a proof \nthat the subscript is within the appropriate bounds. This example is typical of functional extensions. \nIn the intuitionistic type theory of LF, once a fact holds, it holds forever. Accordingly, there is never \na need for proofs to go away. This is satisfactory for purely functional pro\u00adgramming, and it also su.ces \nfor some stateful type systems as well. For example, the references of Standard ML [14], once created, \nnever disappear. However, we can provide con\u00adsiderably more expressive power for stateful programming \nby going beyond just intuitionistic proofs and adding linear proof constructs from Linear LF [3] as well. \nThis allows the proof of facts that hold for the current state, but may later cease to hold; any operation \nthat may falsify such a fact will arrange to consume that fact s proof. As an example, we show how to \nsupport revocable capabilities in the style of Walker et al. s region type system [26]. This paper is \norganized as follows: We begin in Sec\u00adtion 2 by presenting the intuitionistic fragment of LTT. In Section \n3we give a sample application of LTT to arrays. In Section 4 we present the full language for linear, \nstateful programming and show its application to revocable capabil\u00adities. In Section 5 we give an example \nof the application of linearity to stateful programming. These sections are pri\u00admarily interested in \nthe static semantics of LTT and treat its operational semantics only informally. We then illustrate the \nmethod of de.ning operational semantics for instances of LTT in Section 6. The intuitionistic fragment \nof LTT is similar in spirit proof kinds K ::= P |.u:A.K families A ::= a |Ak |.u:A1.A2 |AM |.u:A1.A2 \nobjects M ::= u |Mk |.u:A.M |M1M2 Figure 1: Proof Language Syntax kinds k ::= T |k1 .k2 |.a:K.k |.u:A.k \ncon s c ::= a |ck |.a:k.c |c1c2 |.a:K.c |cA |.u:A.c |cM |c1 .c2 |c1 \u00d7c2 |.a:k.c |Sa:k.c |.a:K.c |Sa:K.c \n|.u:A.c |Su:A.c terms e ::= x |ek |.x:c.e |e1e2 |(e1,e2)|p1e |p2e |.a:k.e |ec |pack (c, e)as Sa:k.c |let \n(a, x)= e1 in e2 |.a:K.e |eA |pack (A, e)as Sa:K.c |let (a, x)= e1 in e2 |.u:A.e |eM |pack (M, e)as Su:A.c \n|let (u, x)= e1 in e2 contexts G ::= E |G,a:k |G,x:c |G,a:K |G,u:A Figure 2: Programming Language Syntax \nto recent work by Shao et al. [21], which was developed independently. In Section 7 we compare the two \nsystems and discuss the methodological di.erences in their use. This paper assumes familiarity with linear \nlogic [7, 24] and with the propositions-as-types correspondence [11]. Ad\u00additional familiarity with LF \nand logical frameworks in gen\u00aderal will be helpful, but is not required. 2 Intuitionistic LTT The LTT \ntype theory consists of two parts: a proof sub\u00adlanguage, and a computational programming language built \naround it. LTT is structured with a syntactic division be\u00adtween the proof language and the surrounding \nprogramming language, allowing the proof language to be precisely the LF type theory. This design allows \nus to reuse a consider\u00adable body of existing LF results particularly metatheoretic proofs and tools. \nThe surrounding programming language is in.uenced by the proof language, but not vice versa. 2.1 The \nProof Language The proof language (given in Figure 1) consists of three syn\u00adtactic classes: objects (M), \nwhich are the terms of the proof language; families (A), which are the types and type con\u00adstructors; \nand proof kinds (K), which are the types of families. As in LF (and as we illustrate by example below), \nobjects implement individuals and formulas of the logic, in\u00adference rules, and complete proofs. Families \nof kind P are the types of objects; these specify classes of individuals and logical assertions. Families \nof a higher kind .u:A.K are functions mapping objects in family A to families in kind K,where u stands \nfor the argument and may appear free in K. The family constructs are variables a, constants Ak , lambda \nabstractions .u:A1.A2, applications of functions AM, and dependent function spaces .u:A1.A2 (where u \nagain stands for the argument and is permitted to appear free in A2). When u does not appear free in \nA2, we will often write .u:A1.A2 as A1 .A2, and similarly for kinds. The object constructs are variables \nu, constants Mk, lambda abstractions .u:A.M, and function applications M1M2. Constants are drawn from \nan unspeci.ed in.nite set. As in LF, the kinds of family constants and the families of ob\u00adject constants \nare given by a signature, which is simply a mapping from constants to their kinds or families. Unlike \nLF, we permit signatures to be in.nite (and therefore we do not provide syntactic rules for them), but \nthis causes no complication to the metatheory, as only .nitely many con\u00adstants can appear in any given \nexpression. Our proof language also di.ers from the LF type the\u00adory in that it includes family variables \n(which LF omits). This di.erence also does not complicate the metatheory of the proof language since \nit provides no binding construct for family variables, and therefore the proof language may con\u00adsider \nvariables simply to be additional constants. However, family variables will be useful in the full language. \nExample To illustrate the use of the proof language, we provide the following example (abbreviated from \nHarper et al. [8]) of a fragment of .rst-order logic. Suppose we wish to reason about natural numbers \nt given by the syntax t ::= u |0 |succ (t) and .rst-order propositions over the natural numbers given \nby the syntax: . ::= t1 = t2 |.1 ..2 |.u.. We .rst implement the syntax by introducing into the sig\u00adnature \nthe constants: i : P o : P z : i eq : i .i .o s : i .i impl : o .o .o all :(i .o) .o The family i contains \nthe individuals of the logic (the nat\u00adural numbers in this case), and o contains the propositions. Note \nthat each syntactic form other than variables has its own constant to represent it. In the LF methodology, \nvari\u00adables in the logic are always represented simply by variables in the LF type theory; this allows \nfor a very elegant treat\u00adment of binding. For example, the proposition .u. u = u is represented by the \nobject all (.u:i. eq uu). With syntax taken care of, we next wish to implement judgements and proofs. \nThe relevant judgement in this case is truth of propositions, which is implemented by the con\u00adstant tr \n: o .P . For any proposition . implemented by M, tr M will be inhabited exactly when . is provable. It \nremains to give proof terms (representing inference rules of the logic) inhabiting the tr family. A few \nexamples of these are: eqrefl :.u:i. tr (eq uu) implelim :.u:o. .v:o. tr (impl uv) .tr u .tr v allintro \n:.f:i .o. (.u:i. tr (fu)) .tr (all f) For example, the judgement that .u. u = u is true is repre\u00adsented \nby the family tr (all (.u:i. eq uu)), andis provedby the object allintro (.u:i. eq uu)(.u:i. eqrefl i). \nNote that here, unlike the usual propositions-as-types correspondence, judgements are types and propositions \nare merely terms (not types). A full account of .rst-order logic in LF appears in Harper et al. [8]. \nHarper et al. also give a proof of the adequacy prop\u00aderty, which states that there is a compositional \nbijection between derivations in .rst-order logic and well-formed LF terms (with the respect to this \nsignature) of the appropriate type. A theorem of this form must be proven in order for any representation \nin LF to be considered successful, and it is essential to the appropriateness of an encoding for use \nwith LTT. It is this adequacy property of a representation that gives derivations encoded in LF the force \nof actual proofs, so it will play a critical role when we discuss type safety in LTT. We revisit this \nissue in Section 6.1.  2.2 The Programming Language The LTT programming language is the higher-order \npoly\u00admorphic lambda calculus augmented with products, and with dependent products and sums over proof \nkinds and families. The syntax appears in Figure 2 and consists of three classes: terms (e), type constructors \n(c, usually called constructors for short), and kinds (k). Constructors of kind T arethe types ofterms; \nwewill often use themetavari\u00adable t for constructors intended to be types. Contexts are used to assign \na type, kind, or family to each variable. The types are ordinary functions and products (t1 .t2 and t1 \n\u00d7t2), dependent products over kinds, proof kinds and families (.a:k.t ,.a:K.t ,and .u:A.t ), and dependent \nsums over the same classes (Sa:k.t ,Sa:K.t ,and Su:A.t ). When the variable being bound does not appear \nin the body, we will often write dependent products with an .and de\u00adpendent sums with a \u00d7.The types .a:k.t \nand Sa:k.t are also often rendered with the quanti.ers .and .in place of . and S, and we will sometimes \ndo so as well. The higher-kind constructors are lambda abstractions over kinds, proof kinds and families \nand have the usual elimination forms. Functions abstracting over proof kinds and families have the dependent \nproduct kinds .a:K.k and .u:A.k (which we write using an .when the variable does not appear free in k). \nFunctions abstracting over kinds have the usual kind (no dependency is necessary since construc\u00adtors \ncannot appear within kinds). At the term level, dependent products are introduced and eliminated using \nthe usual abstraction and application constructs. Dependent sums are introduced using pack ex\u00adpressions \n(e.g., pack (M, e)as Su:A.t ) generating the indi\u00adcated type, and eliminated through pattern matching \nusing let expressions. Functions and products are introduced and eliminated in the usual ways. As in \nthe proof language, constructor and term constants (ck and ek) are drawn from an unspeci.ed in.nite set, \nand are assigned kinds and types by a signature. Signatures are formalized in Section 2.3. An extended \nexample of the use of LTT in practice is given in Section 3.  2.3 Static Semantics To begin de.ning \nthe static semantics of LTT, we must ham\u00admer down the notion of a signature. Signatures, since they may \nbe in.nite, are not given by expressions within the type theory. They are de.ned as follows: 3 Example: \nArrays and Arithmetic Judgement Interpretation G fS k kind k is a valid kind G fS c : k c is a valid \nconstructor of kind k G fS e: t e is a valid term of type t G fS K pkind K is a valid proof kind G fS \nA: K A is a valid family of kind K G fS M : A M is a valid object of family A fS G context G is a valid \ncontext G fS k1 = k2 kind k1 and k2 are equal kinds G fS c1 = c2 : k c1 and c2 are equal constructors \nG fS K1 = K2 pkind K1 and K2 are equal proof kinds G fS A1 = A2 : K A1 and A2 are equal families G fS \nM1 = M2 : K M1 and M2 are equal objects Figure 3: Intuitionistic LTT Judgements De.nition 2.1 An (intuitionistic) \nsignature S is a map\u00adping1 of constructor constants (ck) to kinds, term constants (ek) to constructors, \nfamily constants (Ak) to proof kinds, and object constants (Mk) to families, together with a well\u00adfounded \nordering on the non-term constants in the domain of the mapping. We write <S for the ordering associated \nwith S. The judgement forms for LTT s static semantics are given in Figure 3. We follow Harper and Pfenning \ns treat\u00adment of the metatheory of LF [10], using typed equality judgements rather than \u00df.-conversion; \nequality judgements are required for all classes except terms, which alone can\u00adnot appear inside of types. \nThe typing rules for LTT are the expected ones, and are given in Appendix B (for full LTT, including \nlinearity). As usual, we consider alpha\u00adequivalent expressions to be identical. We write the si\u00admultaneous \ncapture-avoiding substitution of E1,...,En for X1,...,Xn in E as E[E1 \u00b7\u00b7\u00b7En/X1 \u00b7\u00b7\u00b7Xn]. All LTT judgements \nare predicated over a signature, and are to be considered meaningful only when that signature is well-formed. \nFor any (non-term) constant sk .Dom(S), we write S rsk for the restriction of S to constants less than \nsk (by <S). We also write TLP (S) for the termless portion of the signature S. Then we can de.ne well-formedness \nas follows: De.nition 2.2 An intuitionistic signature S is well-formed if: for all Ak .Dom(S), fSfAk \nS(Ak ) pkind,and  for all Mk .Dom(S), fSfMk S(Mk): P,and  for all ck .Dom(S), fSfck S(ck) kind,and \n for all ek .Dom(S), fTLP(S) S(ek): T.  Typechecking may be shown decidable for intuitionistic LTT, \nbut we will defer discussion of typechecking to Sec\u00adtion 4.4 where we discuss it for full LTT. We discuss \nthe operational semantics of LTT and its type safety properties in Section 6. 1We de.ne a mapping from \nB to C to be a function from some subset of B into C, and thus it may be unde.ned on some members of \nB. In this section we will develop a detailed example of an LTT signature, namely one that uses a theory \nof integer arithmetic to eliminate safely the dynamic checking of array bounds. In order to allow unchecked \narray accesses safely, we must be able to verify statically that the indices being accessed in array \noperations are within the appropriate bounds. The reason this is complicated is that the index values \nare sim\u00adply integers and may therefore be the results of arbitrarily complex arithmetic, making it impossible \nin general for a static analyzer to verify that they satisfy the appropriate constraints. Our solution \nis to use an LF representation of some theory of arithmetic any su.ciently expressive the\u00adory that may \nbe adequately encoded in LF will do and allow the program itself to construct proofs that the precon\u00additions \nof array accesses are satis.ed. The array operations themselves will be unchecked at run time but will \nrequire such proofs as arguments to ensure that the necessary con\u00additions are met when they are called. \nThe basic families and types required for this task are as follows: o : P array : Int .T .T tr : o .P \nint : T Int : P SInt : Int .T As in the shorter example given earlier, o is the family of propositions, \nwhile tr maps any proposition to the family of proofs that that proposition is true. Int is the family \nof objects that represent integer formulas in the theory of arithmetic (similar to i in the simple example), \nand for any integer object N and any type t, array Nt is thetypeof arrays of size N with elements of \ntype t.The type int clas\u00adsi.es integer values about which nothing is known integers that are computed \nbased on user input, for example. SInt is used to construct singleton types corresponding to particu\u00adlar \nobjects of family Int;if N : Int,then SInt N is a type containing exactly one value, namely the integer \nrepresented by N. Our theory of arithmetic is represented in LTT by a col\u00adlection of several object constants \nincluding: z : Int eq : Int .Int .o s : Int .Int lt : Int .Int .o  neg : Int .Int not : o .o plus : \nInt .Int .Int and : o .o .o and-i :.u:o..v:o.tr u .tr v .tr (and uv) commute :.u:Int..v:Int.tr (eq (plus \nuv)(plus vu)) As in the earlier example of our proof language, z repre\u00adsents zero, and (s M) represents \nthe successor of the inte\u00adger represented by M. The proposition eq MN states that the integers represented \nby M and N are equal, and the proposition lt MN states that M is less than N.We men\u00adtion here just two \nproof constructors (rules of inference): and-i corresponds to the and-introduction rule of proposi\u00adtional \nlogic and will appear in an example later; commute represents the commutative property of addition. All \nthe other proof-building constants are omitted to save space. Now that we can express and prove properties \nof numbers using an LF-like representation of arithmetic, the types of fun checked aget arr size index \n= checked aget = .u:Int..arr:(array u int)..size:(SInt u)..index:int. let (v, index') = focus index in \nif index < 0 then test int (lt v z)(< v z index' 0) raise Sub (.p:(tr (lt v z)).raise Sub) else (.p:(tr \n(not (lt v z))). if index < size then test int (lt vu)(< vu index' size) (.q:(tr (lt vu)). unchecked \nsub(arr,index) (* Safe? *) aget int uv (and-i ... pq) arr index') else (.q:(tr (not (lt vu))). raise \nSub raise Sub)) Figure 4: Checked subscript in SML and LTT the array operations are not surprising: \nmkarray :.a:T..u:Int. tr (not (lt uz)) . SInt u . a. array ua aget :.a:T..u:Int..v:Int. tr (and (not \n(lt vz))(lt vu)) . array ua . SInt v . a aset :.a:T..u:Int..v:Int. tr (and (not (lt vz))(lt vu)) . array \nua . SInt v . a. array u a Each operation enforces its precondition by requiring the client to pass a \nproof of the appropriate fact before the term\u00adlevel function may be applied. In particular, the mkarray \nfunction requires a proof that the size of the array to be created is non-negative, and the aget and \naset functions each require a proof that the index being accessed is at least zero but less than the \nsize of the array. This is not all we need, however, since we as yet have no way of obtaining any values \nof type SInt M for any integer expression M, and we have no mechanism allowing infor\u00admation the program \ndiscovers at run time to play a role in proving that any precondition is satis.ed. We will address these \ntwo issues one at a time. First, to link the (static) LF representation of arithmetic with the (dynamic) \ninteger values manipulated at run time, it is necessary to establish a correspondence between the singleton \ninteger types SInt M and the type int.For this purpose we include the coercions focus and blur,which \nde.ne an isomorphism between int and Su:Int.SInt u,the type of a singleton value whose identity is hidden \nby the weak dependent sum. focus : int . Su:Int.SInt u blur :(Su:Int.SInt u) . int We must also include \nsingleton-aware arithmetic operations and literal values of singleton type, for example: + :.u:Int..v:Int.SInt \nu. SInt v . SInt (plus uv) n : SInt (s n z) Note that in some cases, the programmer may wish to use ' \nsingleton-blind arithmetic operations such as +: int . int . int; these can all be de.ned using the singleton-aware \noperations, with the help of focus and blur. Now we address the problem of incorporating informa\u00adtion \ndiscovered by the program at run time into our proof system. Intuitively, we would like a program to \nbe able to use the outcome of a test as evidence in a proof: in the then\u00adbranch of a conditional it should \nbe possible to assume the guard condition to be true, and in the else-branch it should be possible to \nassume it to be false. To accomplish this, we replace ordinary boolean values with special ones whose \ntypes associate them with the proposition whose truth, or falsehood, they assert. We provide singleton-aware \ninteger comparison operations to introduce these special values, and eliminate them with a special conditional \nconstruct that al\u00adlows each of its branches to assume the truth of a proposition describing the outcome \nof the test. The constants necessary to do this are as follows: So : o . T = :.u:Int..v:Int.SInt u. SInt \nv . So (eq uv) < :.u:Int..v:Int.SInt u. SInt v . So (lt uv) test :.a:T..u:o.So u . (tr u. a) . (tr (not \nu) . a) . a The constant So is used to construct special boolean types: if P is a proposition, then at \nrun time the type So P will ef\u00adfectively contain only true if P is true, and only false if P is false. \nNotice that the type of the conditional operator test is reminiscent of an encoding of sum types in polymorphic \nlambda-calculus; in fact, if LTT had a disjoint union type we could implement the type So P as (tr P)+(tr \n(not P)), leaving only = and < as primitive constants. We illustrate this treatment of arithmetic with \nthe ex\u00adample shown in Figure 4. On the left is the implementation of a checked array subscript function \nin Standard ML; on the right is the equivalent LTT function. Both versions per\u00adform two tests on the \ngiven index value to ensure that the unchecked subscript operation will not fail; in LTT, however, the \nproof objects make it statically clear that the resulting code is safe. For clarity, we will assume the \nexistence of an SML-like exception mechanism in LTT and will raise the exception Sub if the index is \nout of range. The code on the right is well-typed, and it is therefore safe to call this function with \nany integer index. Although initially nothing is known about the value of this param\u00adeter, the focus \ncoercion attaches an object-level name to it. The use of test with the singleton-aware comparison operator \nallows the safe branch of the code to prove that, if it is reached, the subscript operation will be given \nvalid arguments. 4 Linearity and State Thus far, we have concerned ourselves with proofs of persis\u00adtent \nfacts ones that, once proved, remain true. For exam\u00ad families A ::= \u00b7\u00b7\u00b7|A1 -A2 |A1 &#38; A2 |.objects \nM ::= \u00b7\u00b7\u00b7.u:A.M |M1 M2 | |Mlk | (M1,M2)|p1M |p2M |() linear contexts . ::= E |.,u :A Figure 5: Linear \nProof Language Syntax ple, if a given integer lies between two other given integers, it will not later \n.nd itself outside that range. This is satis\u00adfactory for stateless programming, but if we introduce state \ninto our language, we will also .nd it pro.table to deal with ephemeral facts ones that hold for the \ncurrent state but perhaps not for some other state. Proof of ephemeral facts is incompatible with intuitionis\u00adtic \nLF; once a proof is constructed, there is no way to make it go away. To add support for ephemeral facts, \nwe intro\u00adduce linearity into the proof language. With linearity at our disposal, we can arrange for any \nephemeral facts on which we rely to appear as linear assumptions, and craft state\u00adful operations to ensure \nthat they consume the assumptions corresponding to any ephemeral facts that they invalidate. 4.1 Linear \nProofs In keeping with our design so far, we use the type theory of Linear LF [3] as our proof language \nin the presence of state. To obtain Linear LF, we add the additional constructs in Figure 5 to the proof \nlanguage. The principal di.erence in Linear LF is the existence of linear variables. Linear variables \nrepresent scarce resources that must be used exactly once. We do not distinguish between linear and intuitionistic \nvariables syntactically; in\u00adstead, any object variable bound by a linear context or a lin\u00adear abstraction \n(discussed below) is considered linear, while an object variable bound by an intuitionistic construct \n(such as an ordinary context) is considered intuitionistic. Intu\u00aditionistic variables are treated the \nsame as variables in LF; in particular, they may be duplicated or discarded. For con\u00advenience, we do \nnot distinguish between linear contexts that di.er only in the order variables are declared. We also \npro\u00advide linear object constants (Mlk ), whose types are given by a linear signature; these too must \nbe used exactly once. We sometimes refer to linear variables and linear object con\u00adstants jointly as \nlinear resources. Linear LF provides three new types: linear functions (A1 -A2), with (a.k.a. alternative \nor additive conjunc\u00adtion, A1 &#38;A2), and top (.). Linear functions are introduced by a linear abstraction \nform ( .u:A.M) and eliminated by a linear application form (M1 M2). The de.ning characteristic of a linear \nfunction is that it is guaranteed to use its argu\u00adment exactly once. Thus, linear functions may be applied \nto objects containing linear resources; ordinary functions make no such guarantee, so they may not be \napplied to objects containing linear resources. With types are introduced by pairs ((M1,M2)) and elim\u00adinated \nby projection (piM). The de.ning characteristic of additive conjunction is that each component consumes \nall available resources. Consequently, A1 &#38;A2 provides a choice of either A1 or A2 but not both. \nThe choice is determined by which projection operation is used. Top (.) is the unit for with; it has \nthe introduction form () and no elimination form. When () is used, it consumes all available resources. \nThis is useful in some circumstances for collecting unused resources. At .rst glance it may appear that \nthe Linear LF type theory allows intuitionistic function types to be dependent, but does not allow linear \nfunction types this generality. The reason for this di.erence is simply that it does not make sense for \nlinear variables to appear in families, since allow\u00ading this sort of thing would create a theory in which \nthe expression denoting a type or kind might contain expend\u00adable resources and therefore need to appear \nexactly once. Two types common in linear logic but not provided in the Linear LF type theory are tensor \n(a.k.a. simultaneous or multiplicative conjunction, .) and of course (!). Ten\u00adsor is provided in LTT \nin a restricted way, which we discuss below in Section 4.3. Of course, which indicates an in\u00adtuitionistic \n(and therefore duplicatable) object, is not pro\u00advided; however, as Cervesato and Pfenning point out [3], \nthe intuitionistic function type A .B inherited from the ordi\u00adnary LF type theory behaves similarly to \nthe type (!A -B) that can be expressed in logics containing of course. The argument to such a function \nmust be an object that is well\u00adtyped in an empty linear context, which ensures that it does not depend \non any linear assumptions.  4.2 Linearity in Programming The way in which linear constructs in the proof \nlanguage are intended to represent state in programs may be clari\u00ad.ed by examining how these new constructs \nare made to in\u00adteract with the programming language. Our interpretation is based on the notion that at \nany point in the execution of a program, there is a certain set of resources available; these resources \nmight be actual things, like memory loca\u00adtions, that are available for use by the program, or they may \nbe facts about the machine state of which the pro\u00adgram may take advantage. What is important is that \nsome kinds of program actions may create new resources, such as by allocating some new data structure, \nor by causing a fact to hold that did not hold before, and other actions may de\u00adstroy a resource, such \nas by destroying the data object it refers to, or by invalidating a fact . The new judgement forms in \nlinear LTT are listed in Fig\u00adure 8. To re.ect the notion of available resources in the type system, the \njudgements for objects and terms now include a linear signature R and a linear context . in addition \nto the intuitionistic signature and context. Together, these new additions represent the set of resources \navailable for use by the term(s) on the right-hand side of the turnstile; further, each item in their \ncombined domains must each be used ex\u00adactly once. (The linear signature thus resembles a linear context \nmore than it does an intuitionistic signature, as it must be divided among subterms to ensure proper \nresource use.) Our intuition is that evaluation of any program term that contains a linear constant or \na free linear variable con\u00adsumes the associated resource; thus we will often speak of a term that is \nwell-typed in an empty linear context and with R = \u00d8 as consuming no resources. It is clear that in order \nto be consistent with this under\u00adstanding of resources, syntactic values in the programming language \nmust never contain any linear constants or free linear variables: values themselves do not perform any \ncom\u00adputation and hence cannot consume anything. Thus, our typing rules must force all values to be typed \nin an empty constructors c ::= \u00b7\u00b7\u00b7|A -c terms e ::= \u00b7\u00b7\u00b7.u:A.e |e M | Figure 6: Linear Programming Language \nSyntax linear context and with an empty linear signature, for ex\u00adample: G fS t1 : T G,x:t1; E fS,\u00d8 e \n: t2 G; E fS,\u00d8 .x:t1.e : t1 .t2 On the other hand, because values never contain linear resources, they \nmay always be freely replicated without vio\u00adlating the linear typing discipline. Since our intended oper\u00adational \nsemantics is call-by-value, this means that the argu\u00adment in a function application may contain resources: \neven though the function s body may refer to its formal param\u00adeter any number of times, the term being \nreplicated is not the argument expression itself but that expression s even\u00adtual value. Thus we have \nthe following somewhat unusual typing rule for function application: G; .1 fS,R1 e1 : t1 .t2 G; .2 fS,R2 \ne2 : t1 G; (.1, .2) fS,R1lR2 e1e2 : t2 In addition to these modi.cations to the existing typ\u00ading judgements, \nthe programming language is extended to support linearity by adding one additional type. The type A -t \ncontains functions that consume the resource A (us\u00ading it exactly once), and return a value of type t.This \ntype is introduced and eliminated by similar constructs to those in the proof language, as shown in Figure \n6. The typing rule for linear functions requires that the body treat the formal parameter as a linear \nvariable, but is otherwise similar to the rule for ordinary functions over families: G fS A : P G; u \n:A fS,\u00d8 e : t G; E fS,\u00d8 .u:A.e : A -t Interestingly, the restrictions imposed by our resource interpretation \nof linear constants and variables often lead stateful programming into a closure-passing, continuation\u00adpassing \nstyle. Since functions must be closed (with respect to linear variables), they must always take resources \nas ar\u00adguments, even when those resources were actually available when the function was created, resulting \nin a closure-passing style (with respect to resources). (The desire to include multiple resources is \nwhat leads to the need for tensor (Sec\u00adtion 4.3).) Conversely, since functions can never return resources \nto do so would involve returning a value con\u00adtaining resources any function that wants to provide new \nresources must provide them as arguments to a continua\u00adtion function. Fortunately this is no hardship: \nour intended application, Typed Assembly Language, depends essentially on closure-and continuation-passing \nstyle anyway. Example Suppose A and B are ephemeral propositions, and suppose f is a stateful function \nthat requires A to be true, but then falsi.es it and causes B to be true instead. For example, A could \nsay that storage cell 1 is valid, B could say that storage cell 2 is valid, and f could deallocate 1 \nand allocate 2. Suppose further that A holds in the current state, and consequently there is a available \na linear variable u :A.Then proof kinds K ::= \u00b7\u00b7\u00b7|P+ families c ::= \u00b7\u00b7\u00b7|A1 .A2 |1 objects M ::= \u00b7\u00b7\u00b7|((M1,M2))| \n* terms e ::= \u00b7\u00b7\u00b7|let ((u1,u2))= M in e | let * = M in e G fAi : P+ G fA : P G fA1 .A2 : P+ G f1: P+ \nG fA : P+ G; .i fMi : Ai G; (.1, .2) f((M1,M2)): A1 .A2 G; E f* :1 G; .1 fM : A1 .A2 G; (.2,u1 :A1,u2 \n:A2) fe : t G; (.1, .2) flet ((u1,u2))= M in e : t G; .1 fM :1 G;.2 fe : t G; (.1, .2) flet * = M in \ne : t Figure 7: Tensor we can give f thetype(B -t) . A -t and call it with the code f (.v :B.e) u,where \ne is some continuation expression requiring a state satisfying B. The order of the arguments is signi.cant: \nbecause of our interpretation of resource consumption and the restrictions on linear variable occurrences, \nlinear arguments are generally forced to be last. Alternatively, suppose g requires A but does not invali\u00addate \nit. For example, g might read from storage cell 1. Then we can give g thetype(A -t).A -t and call it \nwith the code g ( .u:A.e) u,where e is some continuation expression requiring a state satisfying A. \n 4.3 Tensor Linear LF provides alternative conjunction, in which both conjuncts consume all available \nresources, making one or the other conjunct available to the receiver, but not both. An\u00adother useful \nform of conjunction is tensor (or simultaneous conjunction). In tensor (written A1 .A2), the available \nre\u00adsources are divided between the two conjuncts, making both of them simultaneously available to the \nreceiver. Unfortunately, Cervesato and Pfenning [3] show that in\u00adclusion of tensor would invalidate important \nmetatheoretic properties of LF and Linear LF (such as the existence of canonical forms and all known \nproofs of decidability of type\u00adchecking), and consequently tensor is omitted from Linear LF. Cervesato \nand Pfenning show that this is no major hardship for logical frameworks, one can always work around the \nabsence of tensor in a systematic way. Sadly, this is not so for LTT. Since term functions are required \nto be closed with re\u00adspect to linear variables, it is impossible for a term function to take multiple \nlinear arguments by currying. A partial so\u00adlution would be to provide multi-argument linear functions \nprimitively, with a type like A1 .\u00b7\u00b7\u00b7.An -t. This turns out to be inadequate because it provides insu.cient \nsupport for polymorphism. Consider a higher-order function such as apply : .\u00df:T...:T.(\u00df ..) \u00d7\u00df ... In \nLTT, it is essential to be able to provide linear resources to the argument function, otherwise that \nfunction is crippled for stateful computation. This can be solved using polymorphism over families: \napply : . a:P.. \u00df:T.. .:T.(\u00df . a -.) \u00d7 \u00df . a -. but this solution only works when a can be instantiated \nwith tensor. A multi-argument function would not su.ce here, because it cannot be known how many linear \narguments are to be passed to the argument function. We overcome this problem with a trick: tensor is \nadded with a typing rule that prevents it from interacting with the proof language. For convenience only, \nwe include tensor among the syntactic class of families, but we give it a new proof kind P+ . The typing \nrules for the other constructs of the proof language do not recognize families in P+,so as far as they \nare concerned tensor is ill-formed and might as well not exist. This preserves the properties of Linear \nLF. To make use of tensor, we add a construct eliminating it in the programming part of the language. \nThe construct let (( u1,u2)) = M in e decomposes an object M : A1 . A2 and adds new variables u1 :A1 \nand u2 :A2 to the linear context. Tensor objects are introduced by (( M1,M2)) .We also include a type \n1, the unit for tensor, which is eliminated by a similar term-level construct and introduced by *.In \ncontrast to () , which consumes all resources, * consumes no resources. These developments are summarized \nin Figure 7 (with signatures omitted for brevity). The apply function given above is certainly a trivial \nexample of a higher-order function. Another complication arises when a function passed as an argument \nmight have to be applied more than once, as in the familiar function map : . \u00df,.:T.(\u00df . .) . list \u00df . \nlist .. While it makes sense for the argument of map to requiresomeresources to be present, in order \nto for map to be able to apply that func\u00adtion more than once, map must require that those resources not \nbe consumed. As discussed at the end of the previous section, expressing the presence of resources in \nthe post\u00adcondition of a function requires that programs be written in continuation-passing style. Speci.cally, \nif the argument to map is intended to have the type \u00df. ., and if the variable a stands for the family \nof the resources it needs, then that ar\u00adgument must have the type . d:T.\u00df. (.. a -d). a -d in continuation-passing \nstyle. Using a similar transformation, and quantifying over the resources required by the argument function, \nwe obtain: map : . a:P+ .. \u00df,.,e:T. (. d:T.\u00df . (. . a -d) . a -d). list \u00df . (list . . a -e) . a -e  \n4.4 Static Semantics The principal change to the static semantics of LTT with the addition of linearity \nis the addition of linear contexts to the judgement forms for terms, objects, and object equality. No \nlinear context is required for the other judgements since, as discussed above, types, families, kinds, \nand proof kinds are not permitted to contain resources. The new judgements are shown in Figure 8. These \nthree judgements also add a linear signature R. A linear signature assigns families to linear object \nconstants, and is treated similarly to the linear context in that it is divided among subterms to ensure \nthat each linear object constant is used exactly once. De.nition 4.1 A linear signature R, is a mapping \nof linear object constants (Mlk ) to families. A linear signature R is Judgement Interpretation G; . \nf S,R e : t G; . f S,R M : A G; . f S,R M1 = M2 : K G f S . context e is a valid term of type t M is \na valid object of family A M1 and M2 are equal objects . is a valid linear context Figure 8: Linear \nLTT Judgements well-formed (relative to an intuitionistic signature S)if for all Mlk . Dom(R), f S R(Mlk): \nP. The full typechecking rules for LTT appear in Ap\u00adpendix B. The version of Linear LF contained within \nLTT di.ers from that of Cervesato and Pfenning in two signi.\u00adcant ways. Cervesato and Pfenning s version \nof Linear LF requires that all objects and families be written in canonical form whereas ours has no \nsuch restriction. Also, Cervesato and Pfenning omit the lambda abstraction construct at the family level. \nThose restrictions were required for their proof of decidable typechecking for Linear LF, and were rarely \na real burden in practical use. However, they do substan\u00adtially complicate the presentation of the type \nsystem, so we have removed them here. Accordingly, decidability of LTT typechecking is based on a new \nproof [23] of decidable type\u00adchecking for Linear LF. As is often the case, typechecking in LTT boils \ndown to the problem of deciding equivalence of types. In LTT this proves to be easy, provided it is possible \nto decide equiva\u00adlence of families and objects (apart from which, LTT type constructors are just terms \nof the simply typed lambda cal\u00adculus). Theorem 4.2 Suppose S and R are well-formed, f S G context,and \nG f S . context. Then it is decidable whether or not G f S A1 = A2 : K is derivable, and whether or not \nG; . f S,R M1 = M2 : A is derivable. The proof [23] is based on a logical relations argument modeled \nafter the analogous proof of Harper and Pfen\u00adning [10] for intuitionistic LF. From this it is easy to \nshow decidability of LTT typechecking: Corollary 4.3 Suppose S and R are well-formed, f S G context,and \nG f S . context. Then it is decidable whether or not G; . f S,R e : t. 5 Example: Memory Management In \nthis section we present a strategy for using the linear constructs of LTT to implement safe, explicit \nallocation and deallocation of memory. The signature we will give here is essentially a simple fragment \nof the capability calculus of Walker et al. [26]. Our simpli.ed memory management signature provides \na type of ephemeral reference cells, which resemble those of ML except that they may be explicitly deallocated. \nAllo\u00adcation of a new reference cell will result in the creation of a linear resource witnessing that \nthe cell is valid that is, that it is available to be read from, written to or destroyed. The family \nand type constants we need are these: cell : P valid : cell . P ref : T . cell . T As these declarations \nshow, reference cells are represented (n= 0) in the proof language by objects of family cell;for a cell \nC, mkarray tMM ' nv . [v,...,v] valid C is a proof family that we will arrange to be inhabited 'v-' n \ntimes when and only when there exists an actual cell associated with C. The storage cell itself will \nbe a term-level value of type ref tC,where t is the type of the cell s contents. The operations available \non reference cells have the fol\u00adlowing types: new : .a:P+ ..\u00df:T...:T. \u00df .(.c:cell.ref \u00dfc .(valid c.a) \n-.) . a-. deref : .a:P+ ..c:cell..\u00df:T...:T. ref \u00dfc .(\u00df .(valid c.a) -.) . (valid c.a) -. assign : .a:P+ \n..c:cell..\u00df:T...:T. ref \u00dfc .\u00df .((valid c.a) -.) . (valid c.a) -. free : .a:P+ ..c:cell..\u00df:T...:T. ref \n\u00dfc .(a-.) .(valid c.a) -. As these types reveal, programs that wish to use references must be written \nin continuation-passing style in order to manage their resources properly. The functions rely on ten\u00adsor \nto allow the caller to pass extra resources; these resources are then forwarded to the continuation along \nwith any others the operation makes available. This allows more than one cell to be valid at a time. \nSince the variable a in the tensor family is universally quanti.ed, these operators may be in\u00adstantiated \nand used no matter what irrelevant assumptions the linear context may contain. The e.ect of each operation \nmay be guessed by looking at the di.erence between the family of the resource passed to the function \nand the family of the resource the function passes on to its continuation. The new operation allocates \na new cell and creates a new validity resource to pass on; free destroys a cell and consumes the corresponding \nresource. The deref and assign functions require that the cell they are accessing be valid, but they \ndo not cause it to become invalid, and so the resource asserting its usability is passed on untouched \nto the continuation. The result of all this is that at any point in the program, the linear context will \ncontain validity resources in one-to-one correspondence with the cells that are available to be accessed. \nOperational Semantics De.ning an operational semantics for LTT presents a signi.\u00adcant di.culty, namely \nthe treatment of term-level constants. Logical frameworks such as LF and LLF are content to leave the \nconstants in their signatures uninterpreted in fact, the presence of uninterpreted function symbols is \nthe very basis of their ability to represent formulas and proofs. In the programming language part of \nLTT, however, it is our intention that term-level constants represent primitive val\u00adues (such as n), \noperations (such as +) and programming constructs (such as test), so they cannot meaningfully be left \nuninterpreted. It is almost certainly impossible to give a single opera\u00adtional semantics for LTT that \nproduces the correct behavior for every programming construct the language may ever be used to represent. \nInstead, a separate set of rules must be designed for each LTT signature, and any desired properties \nof the semantics (including type safety, which we will dis\u00adcuss) must be proved separately as well. We \nwill illustrate (0 = i<n) aget cM1 M2 M3 [v0,...,v(n-1)] i . vi E; Ef P : tr (lt MN) (m<n)< MNmn . tt(lt \nMN),P '' test cMttM1,M2 vv test cMffM1,M2 vv . v ' M2 . vM2 Figure 9: Selected dynamic semantic rules \nfor arrays our methodology by outlining the operational semantics for the two major examples in this \npaper: arrays and memory management. 6.1 Semantics of Arrays In order to give an operational semantics \nto our LTT signa\u00adture for arrays, we must .rst extend the language somewhat by adding array values. These \nlook like [v0,...,vn-1]where the vi are all values having the same type. We also need spe\u00adcial annotated \nboolean values to inhabit types of the form So(M); these will look like either ttM,P ,where P is a proof \nof M,or ffM,P ,where P is a refutation of M.For the purposes of our operational semantics, we will also \nconsider partial applications of term constants those whose re\u00adsult type is still a function or .-type \n to be values if the argument terms are values. Since our array signature did not contain any stateful \noperations, we may formulate our operational semantics for that signature as a reduction relation .on \nprogram terms. We take as our starting point the usual call-by-value oper\u00adational rules for the core \nconstructs of LTT which, due to lack of space, we will not reproduce here. We add to these a collection \nof rules de.ning reduction of fully-applied term constants; a few of these new rules are shown in Figure \n9. A complete set of rules for reducing fully-applied term constants, together with standard rules for \ncall-by-value beta reduction, completely de.nes the run-time behavior of our LTT array signature. The \nnext step is to prove that the language is type-safe; we do this by means of the stan\u00addard Subject Reduction \nand Progress lemmas. The proof of Subject Reduction is standard; we will show one case of Progress to \nillustrate the critical dependence of this lemma on the adequacy property (introduced in Section 2) of \nthe representation of arithmetic. Lemma 6.1 (Subject Reduction) If G fe : t and e. e ' ,then G fe ' : \nt. Lemma 6.2 (Progress) If Efe: t then either eis a value or there exists an e ' such that e ' . .e Proof \n(one case): Suppose e = mkarray tMsz Mpf vsz v. Using inversion, we can establish that Msz : Int, Mpf \n: tr (not(lt Msz z)), vsz : SInt Msz and v : t.By adequacy [8], ' the canonical form Msz of Msz must \nbe the representation of some arithmetic expression E. Again by adequacy, the ' canonical form Mpf of \nMpf must be the representation of a valid derivation of f\u00ac(E< 0). By the soundness of arith\u00admetic, it \nmust be the case that [ E]] =0. Furthermore, we can prove a canonical forms lemma that states that since \nvsz : SInt Msz, vsz = [[E]]. Thus vsz = n and n = 0, so the evaluation rule given in Figure 9 applies. \n 6.2 Semantics of References Unlike the array signature just discussed, our memory man\u00adagement signature \ncontains operations whose behavior is in\u00adtended to be stateful. Rather than attempt to formulate the \noperational semantics in terms of a reduction relation on terms, therefore, we will account for state \nby giving a tran\u00adsition relation on machine con.gurations (H,e)where H is a heap a mapping from memory \nlocations to values and e is a term. We will extend the signature such that for each closed type t that \nis well-formed under the signature s term\u00adless portion, there is a set of locations ft,i and corresponding \nobject constants locet,i : cell such that ft,i : ref tlocet,i . For each location fwe will also assume \nthe existence of a lin\u00adear constant goode, but not all of these will always be present in the linear \nsignature. Rather, we will ensure that the linear signature in which a con.guration is typed will always \ncon\u00adtain good constants for exactly those memory locations that are currently live. To this end we de.ne \na well-formedness judgement for heaps with the rule R = { goode1 :valid loce1 ,...,goodem :valid locem} \nE; Ef \u00d8 vj : tj (where fj = ftj,ij , 1 = j = m) f R { f1 . v1,...,fm . vm} Now we can write the typing \nrule for machine con.gurations as follows: f R HE; E f R e: t f (H,e): t The transition relation . on \ncon.gurations consists, as before, of the expected call-by-value rules augmented with rules for the special \nconstructs of the signature. One such new rule is H = H ' l{ f . v} (H,free Act t ' fk (( M,M ' )) ) \n. (H ' ,k M ' ) Note that the premise prevents the evaluation of an appli\u00adcation of free if the named \nlocation is not currently live in the heap in other words, attempts to free invalid locations get stuck. \nThus in order to prove the Progress part of type safety we must be able to show, among other things, \nthat this premise will be satis.ed for any well-typed application of free. Note that, according to the \ntyping rule for machine con\u00ad.gurations, the set of live locations in the heap determines the linear signature \nR in which the term e must be well\u00adtyped. Since all the resources in R must be consumed by the computation \ne, this typing rule may not apply to all the subterms of e if more than one involves stateful computa\u00adtion. \nNevertheless, we can prove both Subject Reduction and Progress by generalizing the induction hypothesis. \nAs before, we will show one case of Progress to illustrate the role of the linear signature. Lemma 6.3 \n(Subject Reduction) If H = H1 l H2 and f R1 H1 and f R2 H2 and G; Ef R1 e: t and (H,e) . (H ' ,e ' ) \n'' '' then there exist R1 and H1 such that H = H1 l H2 and f R.H ' and G; Ef R.e ' : t. 1 11 Lemma 6.4 \n(Progress) If H = H1 l H2 and f R1 H1 and f R2 H2 and E; E f R1 e : t then either e is a value or there \n'' ' exist H and e such that (H,e) . (H ,e ' ). Proof (one case): Suppose e =(free Actt ' vk) M.We can \ndetermine by inversion that c : cell , v : ref tc and M :(valid c. A). Canonical forms lemmas tell us \nthat v is some label f,that c = loce and that M is equivalent to (( M1,M2)) where M1 : valid c. But the \nonly canonical form of family valid loce is the constant goode;since the term is well-typed, the linear \nsignature R1 must include goode,so by inspection of the typing rule for heaps we conclude that a binding \nof the form f . v ' must appear in the heap H1, and therefore in H, so the above rule applies. 7 Related \nWork and Conclusion Concurrently with our work, Shao et al. [21] proposed a framework for certi.ed code \nvery similar in spirit to ours, which we refer to here as SSTP. While LTT is constructed by attaching \nLF to a typed programming language, SSTP at\u00adtaches the Calculus of Inductive Constructions [18] instead. \nLF and Inductive Constructions are similar in that both have been widely used to formalize mathematics \nand both enjoy mature, robust implementations. However, there are signi.cant di.erences between the systems \nthat result in im\u00adportant di.erences in usage and expressive power between LTT and SSTP. Regarding usage, \nLF is designed to encode logics, and emphasizes the notion of an adequacy theorem (Recall Sec\u00adtion 6) \nstating that a canonically formed proof term of ap\u00adpropriate type is (modulo encoding) a proof in the \nlogic being encoded. Inductive Constructions, on the other hand, does not support the same notion of \ncanonical forms as LF, and so the LF style of encoding does not work; instead, one implements the semantics \nof a logic. The di.erences in usage between LTT and SSTP essen\u00adtially boil down to these methodological \ndi.erences between LF and Constructions. In both cases, a logic and its encod\u00ading must be sound in order \nfor the resulting language to be type-safe. In particular, when a certain condition needs to hold in \norder for evaluation to proceed (such as, for exam\u00adple, the constraints on the subscript that must be \nsatis.ed for an array operation to make sense), it must be shown as part of the safety proof that the \nexistence of the proof ob\u00adject supplied by the program entails the required condition. In SSTP, the safety \nproof must characterize all the possi\u00adble typing derivations of all the possible terms that could be \nprovided, and demonstrate that the existence of any of these implies the desired property. The .rst of \nthese two steps corresponds roughly to the adequacy property of an LF representation, and the second \ncorresponds to soundness of the logic being encoded. As we have mentioned, adequacy proofs for LF are \nusually simple, and in some cases (such as that of arithmetic in the array example), the soundness of \nthe logic has already been established and need not be proven again. Regarding expressiveness, LTT is \nbased on Linear LF, which gives LTT the power to reason about ephemeral prop\u00aderties, an ability SSTP \ndoes not have. We conjecture that an extension of SSTP with linear typing constructs would have similar \nexpressive power, but the metatheory of the Calculus of Inductive Constructions with linearity has not \nbeen investigated and may be di.cult. On the other hand, Inductive Constructions supports primitive recursion, \nwhich LF does not (as such a construct would destroy LF s notion of canonical forms). Consequently, SSTP \ncan use primitive recursion on encoded types to support intensional type anal\u00adysis [9, 5], which LTT \ncannot. Various proposals have been made for extending LF with primitive recursion [6, 20, 19] and we \nare exploring integrating one of these into LTT. LTT provides the power for very expressive type systems \nby allowing operations to demand proofs of arbitrary propo\u00adsitions (thereby escaping the usual restrictions \nof decidable typechecking), and by allowing operations to demand linear resources, accessible only in \ncertain states. In this paper we have given some examples of how these facilities can be used separately; \nby combining them one can obtain even greater expressive power. For example, the Capability Calculus \nof Walker et al. [26] is similar to the memory management example in Section 5 in that it provides revocable \naccess to memory cells, but it goes further with an algebra over capabilities and an ability to declare \nsome constraints be\u00adtween capabilities. Those facilities can easily be encoded in LTT by an appropriate \nchoice of judgements (representing equivalences and constraints) and proof terms. One such encoding is \ngiven in Appendix A. Beyond this, we conjec\u00adture that the security automata type system of Walker [25] \nand the alias-tracking type system of Smith et al. [22] can easily be encoded in LTT as well. Although \nthese systems exist independently, LTT provides a uniform framework in which they can all be cast, and \nhas the additional bene.t that type-checking is decidable for any LTT encoding even if (as is the case \nfor the Capability Calculus) decidability for the pre-existing system has not been established. The use \nof LTT as a framework for certi.ed code type theories promotes a sort of re-use, namely that of the type\u00adchecking \nsoftware. A similar e.ort to LTT in this respect is the TinkerType meta-language of Levin and Pierce \n[12]. Unlike LTT, which casts everything in a common language, TinkerType emphasizes modular development \nof compara\u00adtively dissimilar type systems (such as F , F=, F., etc.). Like LTT, TinkerType provides for \nmodular development of typechecking software; however, its main feature is support for inheritance; for \nexample F= inherits from F and adds subtyping. LTT makes no e.ort at supporting inheritance; each LTT \nsignature, with its operational semantics, must be fully developed on its own. Adding this is an interesting \navenue for future work. Acknowledgements We would like to thank Robert Harper, Frank Pfenning and Zhong \nShao for many useful conversations and suggestions. References [1] A. W. Appel and A. P. Felty. A semantic \nmodel of types and machine instructions for proof-carrying code. In Twenty-Seventh ACM Symposium on Principles \nof Programming Languages, pages 243 253, Boston, Jan. 2000. [2] B. Bershad, S. Savage, P. Pardyak, E. \nSirer, M. Fiuczynski, D. Becker, C. Chambers, and S. Eggers. Extensibility, safety and performance in \nthe SPIN operating system. In Fifteenth ACM Symposium on Operating Systems Principles,pages 267 284, \nCopper Mountain, Dec. 1995. [3] I. Cervesato and F. Pfenning. A linear logical framework. In Eleventh \nIEEE Symposium on Logic in Computer Science, pages 264 275, New Brunswick, New Jersey, July 1996. [4] \nC. Colby, P. Lee, G. Necula, and F. Blau. A certifying com\u00adpiler for Java. In 2000 SIGPLAN Conference \non Program\u00adming Language Design and Implementation, pages 95 107, Vancouver, British Columbia, June 2000. \n[5] K. Crary and S. Weirich. Flexible type analysis. In 1999 ACM International Conference on Functional \nPro\u00adgramming, pages 233 248, Paris, Sept. 1999. [6] J. Despeyroux, F. Pfenning, and C. Sch\u00a8urmann. Primitive \nrecursion for higher-order abstract syntax. In Third Inter\u00adnational Conference on Typed Lambda Calculi \nand Applica\u00adtions, volume 1210 of Lecture Notes in Computer Science, pages 147 163, Nancy, France, Apr. \n1997. Springer-Verlag. Extended version published as CMU technical report CMU\u00adCS-96-172. [7] J.-Y. Girard. \nLinear logic. Theoretical Computer Science, 50:1 102, 1987. [8] R. Harper, F. Honsell, and G. Plotkin. \nA framework for de.ning logics. Journal of the ACM, 40(1):143 184, Jan. 1993. [9] R. Harper and G. Morrisett. \nCompiling polymorphism using intensional type analysis. In Twenty-Second ACM Sympo\u00adsium on Principles \nof Programming Languages, pages 130 141, San Francisco, Jan. 1995. [10] R. Harper and F. Pfenning. On \nequivalence and canonical forms in the LF type theory. Technical Report CMU-CS-00\u00ad148, Carnegie Mellon \nUniversity, School of Computer Sci\u00adence, July 2000. [11] W. Howard. The formulas-as-types notion of construction. \nIn J. P. Seldin and J. R. Hindley, editors, To H.B. Curry: Essays on Combinatory Logic, Lambda-Calculus \nand For\u00admalism, pages 479 490. Academic Press, 1980. [12] M. Y. Levin and B. C. Pierce. Tinkertype: A \nlanguage for playing with formal systems. Technical Report MS-CIS-99\u00ad19, Dept of CIS, University of Pennsylvania, \nJuly 1999. [13] T. Lindholm and F. Yellin. The Java Virtual Machine Spec\u00adi.cation. Addison-Wesley, 1996. \n[14] R. Milner, M. Tofte, R. Harper, and D. MacQueen. The De.nition of Standard ML (Revised). The MIT \nPress, Cam\u00adbridge, Massachusetts, 1997. [15] G. Morrisett, K. Crary, N. Glew, and D. Walker. Stack-based \ntyped assembly language. Journal of Functional Program\u00adming, 12(1):43 88, Jan. 2002. An earlier version \nappeared in the 1998 Workshop on Types in Compilation, volume 1473 of Lecture Notes in Computer Science. \n[16] G. Morrisett, D. Walker, K. Crary, and N. Glew. From Sys\u00adtem F to typed assembly language. ACM Transactions \non Programming Languages and Systems, 21(3):527 568, May 1999. An earlier version appeared in the 1998 \nSymposium on Principles of Programming Languages. [17] G. Necula and P. Lee. Safe kernel extensions without \nrun\u00adtime checking. In Second Symposium on Operating Systems Design and Implementation, pages 229 243, \nSeattle, Oct. 1996. [18] C. Paulin-Mohring. Inductive de.nitions in the system coq rules and properties. \nIn International Conference on Typed Lambda Calculi and Applications, volume 664 of Lecture Notes in \nComputer Science. Springer-Verlag, 1993. [19] C. Sch\u00a8urmann. Automating the Meta Theory of Deductive \nSystems. PhD thesis, Carnegie Mellon University, School of Computer Science, Pittsburgh, Pennsylvania, \nOct. 2000. [20] C. Sch\u00a8urmann and F. Pfenning. Automated theorem prov\u00ading in a simple meta-logic for \nLF. In Fifteenth Interna\u00adtional Conference on Automated Deduction, volume 1421 of Lecture Notes in Computer \nScience, Lindau, Germany, July 1998. Springer-Verlag. rgn : P nu1,nu2,... : rgn r ::= . cap : P null \n: cap C ::= \u00d8 one : rgn .cap plus : rgn .cap join : cap .cap .cap bar : cap .cap |{r 1}|{r +}|C .C ' \n|C Figure 10: Formulas of the capability calculus  [21] Z. Shao, B. Saha, V. Trifonov, and N. Papaspyrou. \nA type system for certi.ed binaries. In Twenty-Ninth ACM Sympo\u00adsium on Principles of Programming Languages, \npages 217 232, Portland, Oregon, Jan. 2002. [22] F. Smith, D. Walker, and G. Morrisett. Alias types. \nIn Eu\u00adropean Symposium on Programming, Berlin, Germany, Mar. 2000. [23] J. C. Vanderwaart and K. Crary. \nA simpli.ed account of the metatheory of linear LF. Technical Report CMU-CS-01\u00ad154, Carnegie Mellon University, \nSchool of Computer Sci\u00adence, 2002. [24] P. Wadler. A taste of linear logic. In Mathematical Founda\u00adtions \nof Computer Science, volume 711 of Lecture Notes in Computer Science. Springer-Verlag, 1993. [25] D. \nWalker. A type system for expressive security policies. In Twenty-Seventh ACM Symposium on Principles \nof Pro\u00adgramming Languages, Boston, Jan. 2000. [26] D. Walker, K. Crary, and G. Morrisett. Typed memory \nman\u00adagement via static capabilities. ACM Transactions on Pro\u00adgramming Languages and Systems, 22(4), July \n2000. An earlier version appeared in the 1999 Symposium on Princi\u00adples of Programming Languages. [27] \nH. Xi and R. Harper. A dependently typed assembly lan\u00adguage. In 2001 ACM International Conference on \nFunc\u00adtional Programming, pages 169 180, Florence, Italy, Sept. 2001. [28] H. Xi and F. Pfenning. Eliminating \narray bound checking through dependent types. In 1998 SIGPLAN Conference on Programming Language Design \nand Implementation, pages 249 257, Montreal, June 1998. A Representing the Capability Calculus In this \nappendix we present a representation of the Capa\u00adbility Calculus [26] in LTT. For reasons of space, we \ncannot present the Capability Calculus itself here; instead, we will assume the reader is familiar with \nit already and describe only the LTT representation. Readers not well acquainted with the Capability \nCalculus may skip this appendix. One aspect of the Capability Calculus we do not address is the storage \nof functions in the heap. Recall that func\u00adtion types in the Capability Calculus are annotated with the \nregion in which the function resides; since the functions are allowed to be polymorphic, this is di.cult \nto represent in LTT and so we will use LTT s built-in function types instead, losing the region information. \nThis would not be a problem in practice, as we would probably want to use LTT to represent programs after \nclosure conversion, when functions are represented explicitly as tuples in the dynamic heap and the polymorphic \ncode is relegated to a statically allocated text segment. eqcongnull : eqcap null null '' '' eqcongjoin \n: .c1,c2,c1,c :cap.eqcap c1 c . eqcap c2 c . 212 '' eqcap (join c1 c2)(join c1 c ) 2 '' eqcongbar : .c,c \n:cap.eqcap cc . eqcap (bar c)(bar c ' ) eqre. : .c:cap.eqcap cc '' eqsymm : .c,c ' :cap.eqcap cc . eqcap \ncc eqtrans : .c1,c2,c3:cap.eqcap c1 c2 . eqcap c2 c3 . eqcap c1 c3 eqident : .c:cap.eqcap (join null \nc) c ' ' eqcommut : .c,c :cap.eqcap (join cc ' )(join cc) eqjoinidem : .c:cap.eqcap(bar c)(join (bar \nc)(bar c)) eqbarnull : eqcap (bar null) null eqbarone : .r:rgn.eqcap (bar(one r)) (plus r) eqbarplus \n: .r:rgn.eqcap (bar(plus r)) (plus r) eqbarbar : .c:cap.eqcap (bar (bar c)) (bar c) eqbarjoin : .c,c \n' :cap. eqcap (bar (join cc ' )) (join (bar c)(bar c ' )) '' subeq : .c,c ' :cap.eqcap cc . subcap cc \nsubtrans : .c1,c2,c3:cap.subcap c1 c2 . subcap c2 c3 . subcap c1 c3 '' '' subdepth : .c1,c2,c1,c :cap.subcap \nc1 c . subcap c2 c . 212 '' subcap (join c1 c2)(join c1 c ) 2 '' subcongbar : .c,c :cap.subcap cc . subcap \n(bar c)(bar c ' ) subweakbar : .c:cap.subcap c(bar c) Figure 11: Proof constructors for the capability \ncalculus.   A.1 Formulas To begin, we must represent the syntax of capabilities and regions in the \nproof language of LTT. For regions this is easy, since all we need is a family rgn and an in.nite family \nof region literals to represent the region names (.) found in the Capability Calculus. The syntax of \ncapabilities is a bit more complex, but not di.cult to represent. The constants encoding the syntax of \ncapabilities and regions are shown in Figure 10.  A.2 Judgements The static semantics of the Capability \nCalculus explicitly de.nes two special judgements for capabilities: equality and the subcapability relation. \nFollowing the judgements-as\u00adtypes paradigm, we introduce the family constants eqcap and subcap into our \nsignature with the following kinds: eqcap : cap .cap .P subcap : cap .cap .P There is, however, a third \njudgement form that plays a crit\u00adical role in the Capability Calculus, namely the judgement that a particular \ncapability C is the one currently held by the program. There are no inference rules in the calculus for \nderiving proofs of this judgement form, but the capability that appears to the left of the turnstile \nin the term typing rules corresponds to an assumption of such a judgement, much as the variable bindings \nin the typing context repre\u00adsent assumptions that typing judgements hold for certain values. We will \nrepresent this judgement using the family constant hold : cap .P. Since some of the memory-management \noperations of the calculus replace the currently held capability with a di.er\u00adent one, assumptions of \nhold judgements will appear in the linear rather than the intuitionistic context. 0,1,... : int +,-,\u00d7: \nint .int .int if0 :.c:cap.int .(hold c-answer ) .(hold c -answer ) .hold c-answer halt :.c:cap.eqcap \ncnull .int .hold c -answer newrgn :.c:cap.(.r:rgn.hndl r .hold (join c(one r)) -answer ) .(hold c) -answer \nalloci :.c,c ' :cap ..r:rgn..a1:T.....ai:T.subcap c(join c ' (one r)) . hndl r .a1 .\u00b7\u00b7\u00b7ai .(tupi a1 \u00b7\u00b7\u00b7ai \nr .hold c-answer ) .hold c -answer :.c,c ' :cap ..r:rgn..a1:T.....ai:T.subcap c(join c ' (one r)) . \npii,j tupi a1 \u00b7\u00b7\u00b7ai r .(aj .hold c -answer ) .hold c -answer freergn :.c,c ' :cap ..r:rgn.eqcap c(join \nc ' (one r)) .hndl r .(hold c ' -answer ) .hold c-answer Figure 12: Term constants for the Capability \nCalculus. A.3 Proof Constructors The proof constructors for the capability calculus represen\u00adtation \nare shown in Figure 11. They are in direct corre\u00adspondence with the constructor equality and subcapability \nrules of the capability calculus itself. A.4 Type Constructors The constructor part of the signature \nmust provide for all the forms of types in the Capability Calculus that do not correspond directly to \nthe built-in types of LTT. In partic\u00adular, it must provide a type answer to be the return type for functions \nin continuation-passing style, a type of integers, types of region handles (which are used when allocating \nin a region and when freeing a region), and types for pointers to tuples in speci.c regions of the heap. \nSince the Capability Calculus allows tuples to be of any size, we need an in.\u00adnite family of constructor \nconstants to describe their types. Thus the constructor constants for our capability calculus representation \nare as follows: answer : T int : T hndl : rgn .T tupi : T .\u00b7\u00b7\u00b7T .rgn .T 'v ' i BTyping Rules for LTT \nfS G context  A.5 Terms The term constants for the Capability Calculus representa\u00adtion are shown in \nFigure 12. They include all of the spe\u00adcial term-level constructs of the Capability Calculus. The .rst \ngroup in the .gure are the constructs that do not deal directly with memory management: integer literals, \narith\u00admetic operations, the if0-then-else conditional construct and the primitive halt which appears \nin the top-level con\u00adtinuation of a program. The second group contains the memory-management oper\u00adations \nof the Capability Calculus: region allocation, tuple allocation, tuple element projection and region \ndeallocation. Note that since we have an in.nite family of tup construc\u00adtors with which to form tuple \ntypes, we also need an in.nite family of alloc operations (indexed by the size of the tuple being allocated) \nand an in.nite family of pi operations (in\u00addexed by both the tuple size and the position being read). \nThe types for all of these operations are determined by ex\u00adamination of the typing rules for the corresponding \nexpres\u00adsion constructs in the capability calculus; notice the use of hold on the left of each -to represent \nthe capability that appears on the left of each turnstile in the typing rules of the Capability Calculus. \n Convention In rules having an antecedent of the form (G,X1:E1,...,Xm:Em); (.,Xm+1:Em+1,...,Xn:En) fJ, \nthere is an implicit side-condition that each Xi is distinct and not contained in Dom(G) or Dom(.). A \nsimilar side-condition applies in rules with only an intuitionistic context. fS E context fS G context \nG fS k kind fS G,a:k context (a . Dom(G)) fS G context G fS t : T fS G,x:t context (x . Dom(G)) fS G \ncontext G fS K pkind fS G context G fS A : P (a (u. Dom(G)). Dom(G)) fS G,a:K context fS G,u:A context \nG fS k kind G fS k1 kind G fS k2 kind G fS K pkind G,a:K fS k kind G fS A : P G,u:A fS k kind G fS T \nkind G fS k1 . k2 kind G fS .a:K.k kind G fS .u:A.k kind G fS k1 = k2 kind G fS k kind G fS k2 = k1 kind \nG fS k1 = k2 kind G fS k2 = k3 kind G fS T = T kind G fS k = k kind G fS k1 = k2 kind G fS k1 = k3 kind \n G fS k1 = k2 kind G fS k1 = k2 kind G fS K1 = K2 pkind G fS k1 = k2 kind G fS A1 = A2 : P G,u:A1 fS \nk1 = k2 kind G fS k1 . k1 = k2 . k2 kind G fS .a:K1.k1 =.a:K2.k2 kind G fS .u:A1.k1 =.u:A2.k2 kind 13 \n G fS c : k G fS k1 kind G,a:k1 fS c : k2 G fS c1 : k1 . k2 G fS c2 : k1 (G(a)= k) (S(ck)= k) G fS a \n: k G fS ck : k G fS .a:k1.c : k1 . k2 G fS c1c2 : k2 G fS K pkind G,a:K fS c : k G fS c :.a:K.k G fS \nA : K G fS A : P G,u:A fS c : k G fS .a:K.c :.a:K.k G fS cA : k[A/a]G fS .u:A.c :.u:A.k G fS c :.u:A.k \nG; E fS,\u00d8 M : A G fS t2 : T G fS t2 : T G fS k kind G,a:k f t : T G fS t1 : T G fS t1 : T G fS cM : k[M/u]G \nfS t1 . t2 : T G fS t1 \u00d7 t2 : T G fS .a:k.t : T G fS k kind G,a:k f t : T G fS K pkind G,a:K f t : T \nG fS K pkind G,a:K f t : T G fS A : P G,u:A f t : T G fS Sa:k.t : T G fS .a:K.t : T G fS Sa:K.t : T G \nfS .u:A.t : T G fS A : P G,u:A f t : T G fS A : P + G fS t : T G fS c : k G fS k = k kind G fS Su:A.t \n: T G fS A .t : T G fS c : k G fS c1 = c2 : k (G(a)= k) G fS a = a : k G fS c1 = c2 : k1 . k2 G fS c1 \n= c2 : k1 G fS c1 c1 = c2 c2 : k2 G,u:A fS c1 = c2 : k G fS A1 = A : P G fS A2 = A : P G fS .u:A1.c1 \n= .u:A2.c2 :.u:A.k G fS t1 = t2 : T G fS t1 = t2 : T G fS t1 \u00d7 t1 = t2 \u00d7 t2 : T G fS K1 = K2 pkind G,a:K1 \nfS t1 = t2 : T G,a:k1 fS c1 = c2 : k2 G fS k1 = k1 kind G fS k1 = k1 kind (S(ck)= k) G fS ck = ck : \nk G fS .a:k1.c1 = .a:k1 .c2 : k1 . k2 G,a:K fS c1 = c2 : k G fS K1 = K pkind G fS K2 = K pkind G fS c1 \n= c2 :.a:K.k G fS A1 = A2 : K G fS .a:K1.c1 = .a:K2.c2 :.a:K.k G fS c1 A1 = c2 A2 : k[A1/a] G fS c1 = \nc2 :.u:A.k G fS M1 = M2 : A G fS t1 = t2 : T G fS t1 = t2 : T G fS c1 M1 = c2 M2 : k[M1/u]G fS t1 . t1 \n= t2 . t2 : T G fS k1 = k2 kind G,a:k1 fS t1 = t2 : T G fS k1 = k2 kind G,a:k1 fS t1 = t2 : T G fS .a:k1.t1 \n=.a:k2.t2 : T G fS Sa:k1.t1 =Sa:k2.t2 : T G fS K1 = K2 pkind G,a:K1 fS t1 = t2 : T G fS A1 = A2 : P G,u:A1 \nfS t1 = t2 : T G fS .a:K1.t1 =.a:K2.t2 : T G fS Sa:K1.t1 =Sa:K2.t2 : T G fS .u:A1.t1 =.u:A2.t2 : T G \nfS A1 = A2 : P G,u:A1 fS t1 = t2 : T G fS A1 = A2 : P + G fS t1 = t2 : T G fS c1 = c2 : k G fS k = k \nkind G fS Su:A1.t1 =Su:A2.t2 : T G fS A1 .t1 = A2 .t2 : T G fS c1 = c2 : k G,a:k1 fS c1 : k2 G fS c2 \n: k1 G,a:K fS c : k G fS A : K G fS A : P G,u:A fS c : k G fS M : A G fS (.a:k1.c1) c2 = c1[c2/a]: k2 \nG fS (.a:K.c) A = c[A/a]: k[A/a]G fS (.u:A.c) M = c[M/u]: k[M/u] G fS k1 kind G,a:k1 fS c1 a = c2 a : \nk2 G fS K pkind G,a:K fS c1 a = c2 a : k G fS A : P G,u:A fS c1 u = c2 u : k G fS c1 = c2 : k1 . k2 G \nfS c1 = c2 :.a:K.k G fS c1 = c2 :.u:A.k G fS c : k G fS c2 = c2 : k G fS c1 = c2 : k G fS c2 = c3 : k \nG fS c = c : k G fS c1 = c2 : k G fS c1 = c3 : k  G fS t1 : T G,x:t1; E fS,\u00d8 e : t2 (G(x)= t)(S(ek)= \nt)G; E fS,\u00d8 x : t G; E fS,\u00d8 ek : t G; E fS,\u00d8 .x:t1.e : t1 . t2 G; .1 fS,R1 e1 : t1 . t2 G; .2 fS,R2 e2 \n: t1 G; .1 fS,R1 e1 : t1 G; .2 fS,R2 e2 : t2 G; . fS,r e : t1 \u00d7 t2 (i =1, 2) G; (.1, .2) fS,R1lR2 e1e2 \n: t2 G; (.1, .2) fS,R1lR2 (e1,e2) : t1 \u00d7 t2 G; . fS,R pie : ti G fS k kind G,a:k; E fS,\u00d8 e : t G; . fS,R \ne :.a:k.t G fS c : k G fS c : k G,a:k fS t : T G; . fS,R e : t[c/a] G; E fS,\u00d8 .a:k.e :.a:k.t G; . fS,R \nec : t[c/a] G;. fS,R pack (c, e) as Sa:k.t :Sa:k.t G; .1 fS,R1 e1 :Sa:k.t (G,a:k, x:t); .2 fS,R2 e2 : \nt G fS K pkind G,a:K; E fS,\u00d8 e : t G; . fS,R e :.a:K.t G fS A : K G; (.1, .2) fS,R1lR2 let (a, x) = e1 \nin e2 : t G; E fS,\u00d8 .a:K.e :.a:K.t G; . fS,R eA : t[A/a] G; .1 fS,R1 e1 :Sa:K.t G,a:K fS t : T G; . fS,R \ne : t[A/a] (G,a:K, x:t); .2 fS,R2 e2 : t G fS A : P G,u:A; E fS,\u00d8 e : t G fS A : K G; . fS,R pack (A, \ne) as Sa:K.t :Sa:K.t G; (.1, .2) fS,R1lR2 let (a, x) = e1 in e2 : t G; E fS,\u00d8 .u:A.e :.u:A.t G; E fS,\u00d8 \nM : A G; .1 fS,R1 e1 :Su:A.t G; . fS,R e :.u:A.t G; E fS,\u00d8 M : A G,u:A fS t : T G; . fS,R e : t[M/u] \n(G,u:A, x:t); .2 fS,R2 e2 : t G; . fS,R eM : t[M/u] G;. fS,R pack (M, e) as Su:A.t :Su:A.t G; (.1, .2) \nfS,R1lR2 let (u, x) = e1 in e2 : t G fS A : P + G; .1 fS,R1 e : A .t G; .1 fS,R1 M : A1 . A2 G; u :A \nfS,\u00d8 e : t G; .2 fS,R2 M : A G; (.2,u1 :A1,u2 :A2) fS,R2 e : t G; E fS,\u00d8 .u:A.e : A .t G; (.1, .2) fS,R1lR2 \ne M : t G; (.1, .2) fS,R1lR2 let ((u1,u2)) = M in e : t G; .1 fS,R1 M :1 G;.2 fS,R2 e : t G; . fS,R \ne : t G fS t = t : T G; (.1, .2) fS,R1lR2 let * = M in e : t G; . fS,R e : t G fS K pkind G fS A : P \nG,u:A fS K pkind G fS P pkind G fS P + pkind G fS .u:A.K pkind G fS K1 = K2 pkind G fS K pkind G fS K2 \n= K1 pkind G fS K1 = K2 pkind G fS K2 = K3 pkind G fS K = K pkind G fS K1 = K2 pkind G fS K1 = K3 pkind \nG fS A1 = A2 : P G,u:A1 fS K1 = K2 pkind G fS .u:A1.K1 =.u:A2.K2 pkind G fS A : K G,u:A1 fS A2 : K G \nfS A :.u:A .K G; E fS,\u00d8 M : A G fS A1 : P (G(a)= K)(S(Ak )= K) G fS a : K G fS Ak : K G fS .u:A1.A2 \n:.u:A1.K G fS AM : K[M/u] G fS A1 : P G,u:A1 fS A2 : P G fS A1 : P G fS A2 : P G fS A1 : P G fS A2 : \nP G fS .u:A1.A2 : P G fS A1 .A2 : P G fS A1 &#38; A2 : P G fS . : P G fS A1 : P + G fS A2 : P + G fS \nA : P G fS A : K G fS K = K pkind G fS A1 . A2 : P + G fS 1: P + G fS A : P + G fS A : K G fS A1 = A2 \n: K G fS A1 = A2 : K G fS A2 = A3 : K (G(a)= K)(S(Ak)= K) G fS a = a : K G fS Ak = Ak : K G fS A1 = \nA3 : K G fS A1 = A2 :.u : B.K G fS M1 = M2 : B G fS A1 = A2 : P G,u:A1 fS A1 = A2 : P G fS A1 = A2 : \nP G fS A1 = A2 : P G fS A1 M1 = A2 M2 : K[M1/u]G fS .u:A1.A1 =.u:A2.A2 : P G fS A1 .A1 = A2 .A2 : P G \nfS A1 = A2 : P G fS A1 = A2 : P G fS A1 = A2 : P + G fS A1 = A2 : P + G fS A1 = A2 : P G fS A2 = A1 : \nK G fS A1 &#38; A1 = A2 &#38; A2 : P G fS A1 . A1 = A2 . A2 : P + G fS A1 = A2 : P + G fS A1 = A2 : K \nG,u:A fS A1 = A2 : K G fS B : P G fS B : P G fS A : P G fS A1 = A : P G fS A2 = A : P G,u:B fS A1 = A2 \n: K G; E fS M1 = M2 : B G,u:B fS A1 u = A2 u : K G fS .u:A1.A1 = .u:A2.A2 :.u:A.K G fS (.u:B.A1) M1 = \nA2[M2/u]: K[M1/u]G fS A1 = A2 :.u:B.K G; . fS,R M : A (G(u)= A)(S(Mk)= A)G; E fS,\u00d8 u : A :A fS,\u00d8 u : \nA G; E fS,\u00d8 Mk : A G; E fS,{Mlk:A} Mlk : AG; u G fS A1 : P G fS A2 : P G,u:A1;. fS,R M : A2 G; . fS,R \nM1 :.u:A1.A2G; E fS,\u00d8 M2 : A1 G fS A1 : P G fS A2 : P G; .,u:A1 fS,R M : A2 G; . fS,R .u:A1.M :.u:A1.A2 \nG; . fS,R M1M2 : A2[M2/u] G;. fS,R .u:A1.M : A1 .A2  G; .1 fS,R1 M1 : A1 .A2 G fS A1 : P G fS A2 : P \nG; .2 fS,R2 M2 : A1 G; . fS,R M1 : A1 G; . fS,R M2 : A2 G; . fS,R M : A1 &#38; A2 (i =1, 2) G; (.1, .2) \nfS,R1lR2 M1 M2 : A2 G; . fS,R (M1,M2) : A1 &#38; A2 G; . fS,R piM : Ai G; . fS,R M : A G fS A = A : P \nG; .1 fS,R1 M1 : A1 G; .2 fS,R2 M2 : A2 G; . fS,R () : . G; . fS,R M : A G; E fS,\u00d8 * :1 G;.1, .2 fS,R1lR2 \n(( M1,M2)) : A1 . A2 G; . fS M1 = M2 : A (G(u)= A)(S(Mk)= A) G; E fS,\u00d8 u = u : A G; u :A fS,\u00d8 u = u \n: A G; E fS,\u00d8 Mk = Mk : A G; E fS,{Mlk:A} Mlk = Mlk : A = N2 : A G; .,u :A fS,R M1 = M2 : B G,u:A fS,R \nM1 = M2 : B G; E fS,\u00d8 N1 G fS A1 = A : P G fS A2 = A : P G; . fS,R M1 = M2 :.u:A.B G fS A1 = A : P G \nfS A2 = A : P  G; . fS,R .u:A1.M1 = .u:A2.M2 :.u:A.B G; . fS,R M1 N1 = M2 N2 : B[N1/u] G;. fS,R .u:A1.M1 \n= .u:A2.M2 : A .B G; .2 fS,R2 N1 = N2 : A G; . fS,R M1 = M2 : A G; .1 fS,R1 M1 = M2 : A .B G; . fS,R \nN1 = N2 : B G; . fS,R M1 = M2 : A1 &#38; A2 (i =1, 2)G; (.1, .2) fS,R1lR2 M1 N1 = M2 N2 : B G; . fS,R \n(M1,N1) = (M2,N2) : A &#38; B G; . fS,R piM1 = piM2 : Ai G; . fS,R M1 = M2 : A G fS A = A : P G; . fS,R \nM2 = M1 : A G; . fS,R M1 = M2 : A G; . fS,R M2 = M3 : A G; . fS,R M1 = M2 : A G; . fS,R M1 = M2 : A G; \n. fS,R M1 = M3 : A = M2 : B G; .1,u :A fS,R1 M1 = M2 : B G,u:A;. fS,R M1 G fS A : P G; E fS,\u00d8 N1 = N2 \n: A G fS A : P G; .2 fS,R2 N1 = N2 : A G; . fS,R (.u:A.M1) N1 = M2[N2/u]: B[N1/u] .u:A.M1) N1 G; (.1, \n.2) fS,R1lR2 ( = M2[N2/u]: B G; . fS,R M1 = N1 : A1 G fS A : P G fS A : P G; . fS,R M2 = N2 : A2 G,u:A;. \nfS,R M1 u = M2 u : B G; .,u :B fS,R M1 u = M2 u : B G; . fS,R pi(M1,M2) = Ni : Ai G; . fS,R M1 = M2 :.u:A.B \nG; . fS,R M1 = M2 : A .B G; . fS,R p1M1 = p1M2 : A G; . fS,R p2M1 = p2M2 : B G; . fS,R M1 : . G; . fS,R \nM2 : . G; . fS,R M1 = M2 : A &#38; B G; . fS,R M1 = M2 : .  \n\t\t\t", "proc_id": "581478", "abstract": "We present the type theory LTT, intended to form a basis for typed target languages, providing an internal notion of logical proposition and proof. The inclusion of explicit proofs allows the type system to guarantee properties that would otherwise be incompatible with decidable type checking. LTT also provides linear facilities for tracking ephemeral properties that hold only for certain program states.Our type theory allows for re-use of typechecking software by casting a variety of type systems within a single language. We illustrate our methodology of representation by means of two examples, one functional and one stateful, and describe the associated operational semantics and proofs of type safety.", "authors": [{"name": "Karl Crary", "author_profile_id": "81100253026", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "P157139", "email_address": "", "orcid_id": ""}, {"name": "Joseph C. Vanderwaart", "author_profile_id": "81100511506", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "P394767", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/581478.581497", "year": "2002", "article_id": "581497", "conference": "ICFP", "title": "An expressive, scalable type theory for certified code", "url": "http://dl.acm.org/citation.cfm?id=581497"}