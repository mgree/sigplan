{"article_publication_date": "09-17-2002", "fulltext": "\n A Demand-Driven Adaptive Type Analysis Danny Dub\u00b4 e and Marc Feeley D\u00b4erationelle epartement d Informatique \net Recherche Op \u00b4Universit\u00b4\u00b4 e de Montr eal {dube,feeley}@IRO.UMontreal.CA Abstract Compilers for dynamically \nand statically typed languages ensure safe execution by verifying that all operations are performed on \nap\u00adpropriate values. An operation as simple as car in Scheme and hd in SML will include a run time check \nunless the compiler can prove that the argument is always a non-empty list using some type analysis. \nWe present a demand-driven type analysis that can adapt the precision of the analysis to various parts \nof the program being compiled. This approach has the advantage that the analysis effort can be spent \nwhere it is justi.ed by the possibility of removing a run time check, and where added precision is needed \nto accurately analyze complex parts of the program. Like the k-cfa our approach is based on abstract \ninterpretation but it can analyze some impor\u00adtant programs more accurately than the k-cfa for any value \nof k.We have built a prototype of our type analysis and tested it on various programs with higher order \nfunctions. It can remove all run time type checks in some nontrivial programs which use map and the Y \ncombinator. Categories and Subject Descriptors D.3.4 [Programming Languages]: Processors compilers, \nopti\u00admization General Terms Languages  Keywords Demand-driven analysis, static analysis, type analysis \n1 Introduction Optimizing compilers typically consist of two components: a pro\u00adgram analyzer and a program \ntransformer. The goal of the ana- Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. ICFP 02, October 4-6, 2002, Pittsburgh, Pennsylvania, USA. Copyright \n2002 ACM 1-58113-487-8/02/0010 ...$5.00 (let ((f (lambda (a b) (cons1 (car2 a) b))) (i (lambda (c) c))) \n(let ((j (lambda (d) (3 i d)))) (car4 (f (f (cons5 5 ()) (cons6 6 ())) (7 i (cons8 8(9 i ()))))))) Figure \n1. A Scheme program under analysis lyzer is to determine various attributes of the program so that the \ntransformer can decide which optimizations are possible and worth\u00adwhile. To avoid missing optimization \nopportunities the analyzer typically computes a very large set of attributes to a predetermined level \nof detail. This wastes time because the transformer only uses a small subset of these attributes and \nsome attributes are more de\u00adtailed than required. Moreover the transformer may require a level of detail \nfor some attributes which is higher than what was deter\u00admined by the analyzer. Consider a compiler for \nScheme that optimizes calls to car by re\u00admoving the run time type check when the argument is known to \nbe a pair. The compiler could use the 0-cfa analysis [8, 9] to compute for every variable of a program \nthe (conservative) set of allocation points in the program that create a value (pair, function, number, \netc) that can be bound to an instance of that variable. In the pro\u00adgram fragment shown in Figure 1 the \n0-cfa analysis computes that only pairs, created by cons1 and cons5, can be bound to instances of the \nvariable a and consequently the transformer can safely re\u00admove the run time type check in the call to \ncar2. Note that the 0-cfa analysis wasted time computing the properties of variable b which are not needed \nby the transformer. Had there been a call (car b) in f s body it would take the more complex 1\u00adcfa analysis \nto discover that only a pair created by cons6 and cons8 can be bound to an instance of variable b; the \n0-cfa does not exclude that the empty list can be bound to b because the empty list can be bound to c \nand returned by function i. The 1-cfa analysis achieves this higher precision by using an abstract execution \nmodel which partitions the instances of a particular variable on the basis of the call sites that create \nthese instances. Consequently it distinguishes the instances of variable c created by the call (7 i (cons \n...)) and those created by the call (9 i ()), allowing it to narrow the type returned by (7 i (cons ...)) \nto pairs only. If these two calls to i are replaced by calls to j then the 2-cfa analysis would be needed \nto fully remove all type checks on calls to car. By using an abstract execution model that keeps track \nof call chains up to a length of 2 the 2-cfa analysis distinguishes the instances of variable c created \nby the call chain (7 j (cons ...)) . (3 id) and the call chain (9 j ()) . (3 id). The compiler implementer \n(or user) is faced with the dif.cult task of .nding for each program Exp := #fll . Lab | xl x . Var, \nl . Lab | (le1 e2) l . Lab, e1,e2 . Exp | (.l x. e1) l . Lab, x . Var,e1 . Exp | (ifle1 e2 e3) l . Lab, \ne1,e2,e3 . Exp | (consle1 e2) l . Lab, e1,e2 . Exp | (carle1) l . Lab, e1 . Exp | (cdrle1) l . Lab, e1 \n. Exp | (pair?le1) l . Lab, e1 . Exp Lab := Labels Var := Variables Figure 2. Syntax of the Source Language \nan acceptable trade-off between the extent of optimization and the value of k and compile time. The analysis \napproach presented in this paper is a demand-driven type analysis that adapts the analysis to the source \nprogram. The work performed by the analyzer is driven by the need to deter\u00admine which run time type checks \ncan be safely removed. By be\u00ading demand-driven the analyzer avoids performing useless analysis work and \nperforms deeper analysis for speci.c parts of the program when it may result in the removal of a run \ntime type check. This is achieved by changing the abstract execution model dynamically to increase the \nprecision where it appears to be bene.cial. Like the k-cfa our analysis is based on abstract interpretation. \nAs explained in Section 4, our models use lexical contours instead of call chains. Some important programs \nanalyzed with our approach are more ac\u00adcurately analyzed than with the k-cfa for any value of k (see \nSec\u00adtion 6). In particular, some programs with higher order functions, including uses of map and the \nY combinator, are analyzed precisely. Our demand-driven analysis does not place a priori limits on the \nprecision of the analysis. This has the advantage that the analysis effort can be varied according to \nthe complexity of the source pro\u00adgram and in different parts of the same program. On the other hand, \nthe analysis may not terminate for programs where it is dif.cult or impossible to prove that a particular \ntype check can be removed. We take the pragmatic point of view that it is up to the user to de\u00adcide what \nis the maximal optimization effort (limit on the time or on some other resource) the compiler should \nexpend. The type checks that could not be removed within this time are simply kept in the generated code. \nWe think this is better than giving the user the choice of an optimization level (such as the k to use \nin a k-cfa) because there is a more direct link with compilation time. Although our motivation is the \nef.cient compilation of Scheme, the analysis is also applicable to languages such as SML and Haskell \nfor the removal of run time pattern-matching checks. Indeed the previous example can be translated directly \nin these statically typed languages, where the run time type checks are in the calls to hd. After a brief \ndescription of the source language we explain the ana\u00adlyzer, the abstract execution models and the processing \nof demands. Experimental results obtained with a prototype of our analyzer are then presented. 2 Source \nLanguage The source language of the analysis is a purely functional language similar to Scheme and with \nonly three data types: the false value, pairs and one argument functions. Each expression is uniquely \nla\u00adbeled to allow easy identi.cation in the source program. The syntax is given in Figure 2. Val. := \nErr ..Val 1 Err := Errors Val := ValB ..ValC ..ValP ValB := {#f} Booleans ValC := Val . Val. Closures \nValP := Val \u00d7 Val Pairs Env := Var . Val E : Exp . Env . Val. Evaluation function E [[#fl ]] . =#f E \n[[xl]] . = . x E [[(le1 e2)]] . = C (E [[e1]] .) (.v1. C (E [[e2]] .)(A v1)) E [[(.l x. e1)]] . = .v. \nE [[e1]] .[x. v] E [[(ifle1 e2 e3)]] . = C (E [[e1]] .) (.v. v = #f ? E [[e2]] . : E [[e3]] .) E [[(consle1 \ne2)]] . = C (E [[e1]] .) (.v1. C (E [[e2]] .)(.v2. (v1, v2))) E [[(carle1)]] . = C (E [[e1]] .) (.v. \nv =(v1, v2) ? v1 : ERROR) E [[(cdrle1)]] . = C (E [[e1]] .) (.v. v =(v1, v2) ? v2 : ERROR) E [[(pair?le1)]] \n. = C (E [[e1]] .) (.v. v . ValP ? v :#f) A :Val . Val . Val. Apply function A fv = f . ValC ? fv : ERROR \nC :Val.. (Val . Val.) . Val. Check function C vk = v . Err ? v : kv Figure 3. Semantics of the Source \nLanguage There is no built-in letrec special form. The Y combinator must be written explicitly when de.ning \nrecursive functions. Note also that cons, car, cdr and pair? are treated as special forms. The semantics \nof the language is given in Figure 3. A notable de\u00adparture from the Scheme semantics is that pair? returns \nits argu\u00adment when it is a pair. The only operations that may require a run time type check are car and \ncdr (the argument must be a pair) and function call (the function position must be a function). 3 Analysis \nFramework To be able to modify the abstract evaluation model during the anal\u00adysis of the program we use \nan analysis framework. The framework is a parameterized analysis general enough to be used for type anal\u00adysis, \nas we do here, as well as a variety of other program analyses. When the speci.cations of an abstract \nevaluation model are fed to the framework an analysis instance is obtained which can then be used to \nanalyze the program. The analysis instance is composed of a set of evaluation constraints that is produced \nfrom the framework parameters and the program. These constraints represent an abstract interpretation \nof the pro\u00adgram. The analysis of the program amounts to solving the set of constraints. The solution \nis the analysis results. From the pro\u00adgram and the framework parameters can also be produced the safety \nconstraints which indicate at which program points run time type checks may be needed. It is by confronting \nthe analysis results with the safety constraints that redundant type checks are identi.ed. If all the \nsafety constraints are satis.ed, all the type checks can be removed by the optimizer. A detailed description \nof the analysis 1The ..operator is the disjoint union, i.e. the sets to combine must be disjoint. V al \nB =0/ Abstract Booleans V al C =0/ Abstract closures V al P =0/ Abstract pairs C ont =0/ Contours k0 \n.C ont Main contour cc : Lab \u00d7C ont .V al C Abstract closure creation pc : Lab \u00d7V al \u00d7V al \u00d7C ont .V \nal P Abstract pair creation call : Lab \u00d7V al C \u00d7V al \u00d7C ont .C ont Contour selection where V al :=V al \nB ..V al C ..V al P subject to |V al |< 8 and |C ont|<8 Figure 4. Instantiation parameters of the analysis \nframework Value of el in k: al,k .V al l .Lab, k .C ont Contents of x in k: \u00dfx,k .V al x .Var, k .C ont \nReturn value of c with its body in k: .c,k .V al c .V al C , k .C ont Flag indicating evaluation of el \nin k: dl,k .V al l .Lab, k .C ont Creation circumstances of c: - .c .cc1(c) c .V al C Creation circumstances \nof p: - pp .pc1(p) p .V al P Circumstances leading to k: .k .call-1(k) k .C ont Figure 5. Matrices \ncontaining the results of an analysis framework and its implementation is given in [4]. Here we only \ngive an overview of the framework. 3.1 Framework Parameters Figure 4 presents the framework parameters \nthat specify the ab\u00adstract evaluation model. The interface is simple and .exible. Four abstract domains, \nthe main contour, and three abstract evaluation functions have to be provided to the framework. V al \nB, V al C, and V al P are the abstract domains for the Booleans, closures, and pairs. They must be non-empty \nand mutually disjoint. V al is the union of these three domains. C ont is the abstract do\u00admain of contours. \nContours are abstract versions of the evaluation contexts in which expressions of the program get concretely \nevalu\u00adated. The part of the evaluation contexts that is abstractly modeled by the contours may be the \nlexical environment, the continuation, or a combination of both. The main contour k0 indicates in which \nabstract contour the main expression of the program is to be evalu\u00adated. The abstract evaluation functions \ncc, pc, and call specify closure creation, pair creation, and how the contour is selected when a func\u00adtion \ncall occurs. cc(l,k)returns the abstract closure created when the .-expression el is evaluated in contour \nk. pc(l,v1,v2,k)returns the abstract pair created by the cons-expression labeled l evaluated in contour \nk with arguments v1 and v2. Finally, call(l,c,v,k)indi\u00adcates the contour in which the body of closure \nc is evaluated when c is called from the call-expression el in contour k and with argument v. Any group \nof modeling parameters that satis.es the constraints given in Figure 4 is a valid abstract evaluation \nmodel for the frame\u00adwork. (mPat) :=.|#f |..|.lk |(P,Pi) where l .Lab, k .(mkPat), P,Pi.(mPat) (sPat) \n:=* |.* |.lk |(P,Pi)|(Pi,P) where l .Lab, k .(skPat), P .(sPat), Pi.(mPat) (mkPat):=(P1 ...Pn) where \n.1=j=n. Pj .(mPat) (skPat) :=(P1 ...Pi ...Pn) where Pi .(sPat), .1=j=n. Pj .(mPat) j=i Figure 6. Syntax \nof patterns 3.2 Analysis Results The analysis results are returned in the seven abstract matrices shown \nin Figure 5. Matrices a, \u00df, and . indicate respectively the value of the expressions, the value of the \nvariables, and the return value of closures. The value \u00dfx,k is de.ned as follows. Assume that closure \nc was created by .-expression (.l x.eli). Then if c is called and the call function prescribes contour \nk for the evaluation of c s body, then parameter x will be bound to the abstract value \u00dfx,k. dl,k indicates \nwhether or not expression el is evaluated in contour k. el is evaluated in contour k if and only if dl,k \n=0/. Apparently, dl,k should have been de.ned as a Boolean instead of a set. However, the use of sets \nmakes the implementation of the analysis framework simpler (see [4]). Matrices ., p, and . are logs keeping \nthe circumstances prevailing when the different closures, pairs, and contours, respectively, are created. \nFor example, if during the abstract interpretation of the program a pair p is created at expression el \nwith values v1 and v2 and in contour k, then this creation of p is logged into pp. That is, (l,v1,v2,k).pp. \nMost of the time, the circumstances logged into the log variables are much fewer than what they can theoretically \n- be. In other words, pp usually contains fewer values than pc1(p). Similarly, when closure c =cc(l,k)is \ncreated by the evaluation of el in k, (l,k)is inserted in .c. And when contour ki=call(l, f ,v,k)is selected \nto be the contour in which the body of f is to be evaluated when f gets invoked on v at el in k, (l, \nf ,v, k)is inserted in .ki.  4 Pattern-Based Models In the demand-driven type analysis we use patterns \nand pattern\u00admatchers to implement abstract evaluation models. Patterns con\u00adstitute the abstract values \n(V al) and the abstract contours (C ont). Abstract values are shallow versions of the concrete values \nand ab\u00adstract contours are shallow versions of the lexical environments. These lexical contours are one \nof the features distinguishing our analysis from most type and control-.ow analyses which typically use \ncall chains. A call chain is a string of the labels of the k nearest enclosing dynamic calls. Although \nthe use of call chains guarantees polynomial-time analyses, it can also be fooled easily. We believe \nthat lexical contours provide a much more robust way to abstract concrete evaluation contexts. Figure \n6 gives the syntax of patterns. There are two kinds of pat\u00adterns: modeling patterns ((mPat)and (mkPat)) \nand split patterns ((sPat)and (skPat)). For both modeling patterns and split patterns, there is a value \nvariant ((mPat)and (sPat)) and a contour variant ((mkPat)and (skPat)). Split patterns contain a single \nsplit point that is designated by *. They are used in the demands that drive the analysis (in split demands, \nmore precisely). Modeling patterns contain no split point. They form the representation of the abstract \nvalues and contours. /.Val \u00d7(mPat)v /., if v .Val #f /#f c /.., if c .ValC c /.lk,if c .ValC, c = E [[(.l \nx.e)]] ., and . /lk (v, w) /(P1, P2), if v /P1 and w /P2 . /l (), if . is valid at label l 2 and Dom(.)= \n0/ 3 . /l (P1 P2 ... Pn), if . is valid at label l, x is the innermost variable in Dom(.), . x /P1, eli \n= (.lix.e), and .[x ..] /li (P2 ... Pn) 4 Figure 7. Formal de.nition of relation is abstracted by 4.1 \nMeaning of Patterns Modeling patterns represent abstract values, which in turn can be seen as sets of \nconcrete values. Pattern . abstracts any value, pat\u00adtern #f abstracts the Boolean value #f, pattern .. \nabstracts any clo\u00adsure, pattern .lk abstracts any closure coming from .-expression labeled l and having \na de.nition environment that can be abstracted by k .(mkPat), and pattern (P1, P2) abstracts any pair \nwhose com\u00adponents can be abstracted by P1 and P2, respectively. The difference between abstract values \nand concrete values is that an abstract value can be made imprecise by having parts of it cut off using \n.and ... Modeling contour patterns appear in the modeling patterns of clo\u00adsures. To simplify, we use \nthe term contour to mean modeling con\u00adtour pattern. Contours abstract lexical environments. A contour \nis a list with an abstract value for each variable visible from a certain label (from the innermost variable \nto the outermost). For example, the contour (.. (.,.)) indicates that the innermost variable (say y) \nis a closure and the other (say x), is a pair. It could abstract the following concrete environment:5 \n\u00b7[x .(#f,#f)] [y .E [[(.l z.#fli)]] \u00b7] A formal de.nition of what concrete values are abstracted by what \nabstract values is given in Figure 7. The relation /.Val \u00d7(mPat)relates concrete and abstract values \nsuch that v / P means that v is abstracted by P. We mention (without proof) that any concrete value obtained \nduring execution of the program can be abstracted by a modeling pattern that is perfectly accurate. That \nis, the latter abstracts only one concrete value, which is the former. The split patterns and split contour \npatterns are used to express split demands that increase the precision of the abstract evaluation model. \nTheir structure is similar to that of the modeling patterns but they include one and only one split point \n(*) that indicates exactly where in an abstract value an improvement in the precision of the model is \nrequested. Their utility will be made clearer in Section 5. Operations on split patterns are explained \nnext. 2. is valid at label l if its domain is exactly the set of variables that are visible from el . \n3Dom( f ) denotes the domain of function f . 4 . denotes an unde.ned value. Consequently, .[x ..] is \nthe same environment as . but without the binding to x. 5The empty concrete environment, \u00b7, contains \nno bindings. n: ((sPat).(mPat)) \u00d7((sPat).(mPat)) .((sPat).(mPat)) P1 nP2 is unde.ned if P1,P2 .(sPat).nP2 \n= P2 P1 n. = P1 *nP2 = * P1 n* = * #f n#f = #f ..nP2= P2,if P2 = .. or P2 = .l (P1 i ...Pi) nP1 n.. = \nP1,if P1 = .. or P1 = .l (P1 i ...Pni) .* nP2= .*,if P2 = .. or P2 = .l (P1 i ...Pi) nP1 n.* = .*,if \nP1 = .. or P1 = .l (P1 i ...Pi) n.l (P1 ...Pn) n.l (P1 i ...Pi) n = .l (Pii 1 ...Pii), n if Pi ii = Pi \nnPi i , .1 =i =n (P1,P2) n(P1i , P2i) =(P1 ii ,Pii 2 ), if Pii = P1 nP1 i and Pii = P2 nPi 1 22 Figure \n8. Algorithm for computing the intersection between two patterns 4.2 Pattern Intersection Although the \n/ relation provides a formal de.nition of when a concrete value is abstracted by an abstract value, and, \nby extension, when an abstract value is abstracted by another, it is not necessarily expressed as an \nalgorithm. Moreover, the demand-driven analysis does not manipulate concrete values, only patterns of \nall kinds. So we present a method to test whether an abstract value is abstracted by another. More generally, \nwe want to be able to test whether a (modeling or split) pattern intersects with another. Similarly for \nboth kinds of contour patterns. The intersection between patterns is de.ned in Figure 8. It is par\u00adtially \nde.ned because two patterns may be incompatible, in the sense that they do not have an intersection and \nas such, their empty intersection cannot be represented using patterns, or as the inter\u00adsection of two \nsplit patterns may create something having two split points. The equations in the .gure should be seen \nas cases to try in order from the .rst to the last until, possibly, a case applies. A pattern P intersects \nwith another pattern Pi if the intersection function is de.ned when applied to P and Pi . Moreover, when \nP intersects with Pi, the resulting intersection Pii = P nPi is charac\u00adterized by:6 {v .Val |v /Pii}= \n{v .Val |v /P . v /Pi} 4.3 Spreading on Split Patterns Another relation that is needed to perform the \ndemand-driven anal\u00adysis is the spreading test. It is useful in determining if a given split pattern will \nincrease the precision of the model if it is used in a split demand. Spreading can occur between a set \nof abstract val\u00adues (modeling patterns) and a split pattern. A split pattern can be thought of as denoting \na sub-division: the set of its abstracted con\u00adcrete value is partitioned into a number of sets corresponding \nto the different possibilities seen at the split point. Each of those sets is called a bucket. For example, \nthe pattern * abstracts all values, that is, Val. It sub-divides Val into three buckets: ValB, ValC, \nand ValP. Spreading occurs between the set of abstract values V and the split 6Provided that we consider \n* and .* to abstract all concrete values and all concrete closures, respectively. .2(mPat)\u00d7(sPat) S / \nif ..S /  P, S / if #f .S and S \\{#f}= 0/,or  *, S nT = 0/ = S \\T where T = {(P,Pi) |P,Pi.(mPat)} S \n/ if S \\T 0/ and T P = P, /where T = {Pi.S |Pi intersects with P}S / if ...S P, S / if .l (P1 ...Pm),.li \n(Pi ) .S 1 ...Pi .*, n and l = li S /  .l (P1 ...Pi ...Pn), if Pi .(sPat)and T /  Pi where T = {Pi \ni|.l (P1 i ...Pi i ...Pi) .S} n S /  (P1, P2),if P1 .(sPat)and T / P1 where T = {P1 i|(P1i ,P2i) .S} \nS / P2  (P1, P2),if P2 .(sPat)and T / where T = {P2 i|(P1i ,P2i) .S} Figure 9. Algorithm for the relation \nis spread on pattern P if some two values (or re.nements of values) in V that are abstracted by P fall \ninto different buckets. We say that V is spread on split pattern P and denote it with V /  P. Figure \n9 gives a formal de.nition of /. As with the noperator, cases should be tried in order. Mathematically, \nthe relation /  has the following meaning. The set of abstract values S is spread on the split pattern \nP, denoted S /  P, if: .P1,P2 .S. .v1,v2 .Val. .Pi.{PB ,PC ,PP }. v1 /P1 . v2 /P2 . v1 /P . v2 /P . \n(v1 /Pi.\u00ac(v2 /Pi)) where PB , PC , and PP are modeling patterns obtained by replacing * in P by #f, .., \nand (.,.), respectively. 4.4 Model Implementation An abstract value can be viewed as a concrete value \nthat has gone through a projection. Similarly, a contour can be viewed as a lexical environment that \nhas gone through a projection. If one arranges for the image of the projection to be .nite, then one \nobtains the desired abstract domains V al B, V al C , V al P , and C ont. But which projection should \nbe used? The / relation is not of much help since, generally, for a concrete value v, there may be more \nthan one abstract value v such that v /v . So a projection based on /would be ill-de.ned. The projection \nwe use is based on an exhaustive non-redundant pattern-matcher. That is, the pattern-matcher implementing \nthe pro\u00adjection of the values is a .nite set of modeling patterns. For any concrete value v, there will \nexist one and only one modeling pattern v in the set such that v /v . Such a pattern-matcher describes \na .nite partition of Val. For example, the simplest projection for the values is:7 {#f, .., (.,.)} It \nis .nite, exhaustive and non-redundant. 7This is not exactly true. The simplest pattern-matcher would \nbe the trivial one, {.}, but it would not implement a legal model for the framework since an abstract \nmodel must at least distinguish the Booleans, the closures, and the pairs. As for the projection of contours, \nwe use one pattern-matcher per .\u00adexpression. For a given .-expression el , the lexical environment in \nwhich its body is evaluated can be projected by the pattern-matcher Ml . The empty lexical environment \nis always projected onto the list of length 0, as the empty list is the only contour that abstracts the \nempty environment. The simplest contour pattern-matcher Ml for expression (.l x. eli) is {(. ... .)}, \nit is a single list having as many entries as there are visible variables in the environment in which \neli is evaluated. Having a pattern-matcher Mv that projects values and a family of pattern-matchers {Mi \n|...} that project lexical environments, and assuming that Mv projects closures coming from different \n.\u00adexpressions to different abstract closures, it is easy to create an ab\u00adstract model, i.e. to de.ne \nthe parameters of the analysis framework, as follows. V al B is {#f}  V al C is {.lk .Mv}  V al P \nis {(v1,v2) .Mv}  . C ont is () . i Mi  k0 is ()  cc(l,k) is the projection of .lk by Mv  pc(l,v1,v2,k) \nis the projection of (v1,v2) by Mv  call(l,.l (w1 ... wn),v,k) is the projection of (vw1 ...wn) by Ml \n  4.5 Maintaining Model Consistency One remaining problem that requires special attention is consis\u00adtency. \nDuring the demand-driven analysis, pattern-matchers are not used to project concrete values, but abstract \nvalues. If one of the abstract values is not precise enough the projection operation may become ill-de.ned. \nIn general, abstract values abstract a set of con\u00adcrete values. Suppose that v1 is such an imprecise \nabstract value. Now, let v2 be a modeling pattern that contains v1 as a sub-pattern. We want to project \nv2 in order to obtain the resulting abstract value. A sensible de.nition for the projection of v2 consists \nin choosing a modeling pattern w in the pattern-matcher M such that all concrete values abstracted by \nv2 are abstracted by w. Unfortunately, such a w may not exist as it may take the union of many modeling \npatterns of M to properly abstract all the concrete values abstracted by v2. Here is an example to help \nclarifying this notion. The following pattern-matcher M, intended for the projection of values, is incon\u00ad \nsistent: . . . #f, (.,#f), (.,(#f,.)), . .., (.,..), (.,(.., .)), . (.,((.,.),.)) . Note that the pattern-matcher \nis .nite, exhaustive, and non-redun\u00addant but nevertheless inconsistent. Before explaining why, let us \nsee how it models the values. First, it distinguishes the values by their (top-level) type. Second, it \ndistinguishes the pairs by the type of the value in the CDR-.eld. Finally, the pairs containing a sub\u00adpair \nin the CDR-.eld are distinguished by the type of the value in the CAR-.eld of the sub-pair. Note that \nthe CAR-.eld of the sub\u00adpairs is more precisely described than the CAR-.eld of the pairs themselves. \nThis is the inconsistency. Problems occur when we try to make a pair with another pair in the CDR-.eld. \nLet us try to make PM := PMO |PMC |PML PMO := Onode [V al .M1] |Onode [V al B .M1, V al C .M2, V al P \n.M3] where M1,M2,M3 .PM PMC := Cnode [Lab .M1] | Cnode [l1 .M1, ..., ln .Mn] where M1,...,Mn .PM and \n{l1,...,ln}={l .Lab |el is a .-expr.} PML := Leaf (mPat)|Leaf (mkPat) Figure 10. Implementation of the \npattern-matchers To project P .(mPat)with M .PM, compute pm(M,[].P), and to project (P1 ...Pn).(mkPat)with \nM .PM, compute pm(M,[].P1 .....Pn), where pm : PM \u00d7[queue of (mPat)].(mPat).(mkPat)pm(Onode [V al .M1], \nP .q) = pm(M1,q) pm(Onode [V al B .M1,...],#f .q) = pm(M1,q) pm(Onode [...,V al C .M2,...],P .q) = pm(M2,q \n.P) if P =.. or P =.l (P1 ...Pn) pm(Onode [...,V al P .M3],(P1, P2).q) = pm(M3,q .P1 .P2) pm(Cnode [Lab \n.M1],P .q) = pm(M1,q) pm(Cnode [...,li .Mi,...],.li (P1 ...Pn).q) = pm(Mi,q .P1 .....Pn) pm(Leaf P,[]) \n= P Figure 11. Pattern-matching algorithm a pair with the values #f and (.,(#f,.)). We obtain the modeling \npattern v =(#f,(.,(#f, .))) and we have to project it using M.It is clear that we cannot non-ambiguously \nchoose one of the modeling patterns of M as an abstraction of all the values abstracted by v. In order \nto avoid inconsistencies, each time an entity is re.ned in one of the pattern-matchers, we must ensure \nthat the abstract val\u00adues and the contours on which the re.ned entity depends are suf.\u00adciently precise. \nIf not, cascaded re.nements are propagated to the dependencies of the entity. This cascade terminates \nsince, for each propagation, the depth at which the extra details are required de\u00adcreases. 4.6 Pattern-Matcher \nImplementation Our implementation of the pattern-matchers is quite simple. A pattern-matcher is basically \na decision tree doing a breadth-.rst inspection of the modeling pattern or modeling contour pattern to \nproject. An internal node of the decision tree is either an O-node (object) or a C-node (closure). A \nleaf contains an abstract value or a contour which is the result of the projection. Each O-node is either \na three-way switch that depends on the type of the ob\u00adject to inspect or is a one-way catch-all that \nignores the object and continues with its single child. Each C-node is either a multi-way switch that \ndepends on the label of the closure to inspect or is a one\u00adway catch-all that ignores the closure and \ncontinues with its single child. Figure 10 presents the data structures used to implement the pattern-matchers. \n(demand):= show a .B where a .(a-var),B .(bound) | split sP where s .(splittee),P .(sPat) | show d = \n0/ where d .(d-var) | bad-call lPi Pii k where l .Lab,Pi ,Pii.(mPat),k .(mkPat) (bound) := V al B |V \nal C |V al P |V al T rues (splittee) := V al C |V al P |a |b |c where a .(a-var),b .(\u00df-var),c .(.-var) \n(a-var) := al,k where l .Lab,k .(mkPat) (\u00df-var) := \u00dfx,k,l where x .Var,k .(mkPat),l .Lab (.-var) := .c,k \nwhere c .(mPat),k .(mkPat) (d-var) := dl,k where l .Lab,k .(mkPat) Figure 12. Syntax of demands The pattern-matching \nalgorithm is presented in Figure 11. The breadth-.rst traversal is done using a queue. The contents of \nthe queue always remain synchronized with the position in the deci\u00adsion tree. That is, when a C-node \nis reached, a closure is next on the queue, and when a leaf is reached, the queue is empty. The ini\u00adtial \nqueue for an abstract value projection contains only the abstract value itself. The initial queue for \na contour projection contains all the abstract values contained in the contour, with the .rst abstract \nvalue of the contour being the .rst to be extracted from the queue. To keep the notation terse, we use \nthe view operation . both to en\u00adqueue and dequeue values. When enqueuing, the queue is on the left of \n.. When dequeuing, the queue is on the right of .. The empty queue is denoted by []. The pattern-matchers \nused in the initial abstract model are the fol\u00adlowing. Note that we describe them in terms of set theory \nand not in terms of the actual data structures. The value pattern-matcher contains one abstract Boolean, \none abstract pair, and one abstract closure for each .-expression. For each .-expression, its corre\u00adsponding \ncontour pattern-matcher is the trivial one. Note that they are consistent as the pattern-matchers are \nalmost blind to any de\u00adtail. The only inspection that is performed is the switch on the la\u00adbel when projecting \na closure. However, the projection of closures always involves closures with explicit labels since it \nonly occurs through the use of the abstract model function cc. We do not give a detailed description \nof the process of re.ning a pattern-matcher because it would be lengthy and it is not conceptu\u00adally dif.cult. \n 5 Demand Processing Figure 12 presents the syntax of demands. The syntax of the de\u00admands builds on \nthe syntax of the patterns. There are show de\u00admands, split demands, and bad call demands. 5.1 Meaning \nof Demands A show demand asks for the demonstration of a certain property. For example, it might ask \nfor demonstration that a particular ab\u00adstract variable must only contain pairs, meaning that a certain \nex\u00adpression, in a certain evaluation context, must only evaluate to pairs. Or it might ask for the demonstration \nthat a particular abstract vari\u00adable must be empty, meaning that a certain expression, in a certain evaluation \ncontext, must not get evaluated. Note that the bound V al T rues represents the values acting as true \nin the conditionals. That is, V al T rues = V al C ..V al P . A bad call demand asks for the demonstration \nthat a particular func\u00adtion call cannot happen. It speci.es where and in which contour the bad call currently \nhappens, which function is called, and which value is passed as an argument. Of course, except for the \nlabel, the parameters of the demand are abstract. A split demand asks that proper modi.cations be done \non the model in such a way that the splittee is no longer spread on the pattern. Take this demand for \nexample: split al,k *. It asks that the abstract values contained in al,k be distinguished by their type \n(because of the pattern *). If the variable al,k currently contains abstract values of different types, \nthen these values are said to be spread on the pattern *. Then the model ought to be modi.ed in such \na way that the contour k has been subdivided into a number of sub-contours k1, ..., kn, such that al,ki \ncontains only abstract values of a single type, for 1 =i =n. In case of success, one might observe that \nal,k1 contains only pairs, al,k2, only closures, al,k3, nothing, al,k4, only #f, etc. That is, the value \nof expression el in contour k would have been split according to the type. In a split demand, the splittee \ncan be an aspect of the abstract model (when it is V al C or V al P ) or an abstract variable from one \nof the a, \u00df,or . matrices. A splittee in (\u00df-var)does not denote an ordinary entry in the \u00df matrix. It \ndoes indicate the name of the source variable but it also gives a label and a contour where this variable \nis referenced (not bound). Only the values that intersect with the pattern are concerned by the split. \nFor example, if the demand is split al,k (.,*) and al,= k {#f,(#f,#f),(#f,..)}, the only thing that matters \nis that the two abstract pairs must be separated. What happens with the Boolean is not important because \nit does not intersect with the pattern (.,*). Normally, a show demand is emitted because the analysis \nhas deter\u00admined that, if the speci.ed property was false, then a type error will most plausibly happen \nin the real program. Similarly for a bad call demand. Unfortunately, split demands do not have such a \nnatural interpretation. They are a purely arti.cial creation necessary for the demand-driven analysis \nto perform its task. Moreover, during the concrete evaluation of the program, an expression, in a particular \nevaluation context, evaluates to exactly one value. So splitting in the concrete evaluation is meaningless. \n 5.2 Demand-Driven Analysis Algorithm The main algorithm of the demand-driven analysis is relatively \nsim\u00adple. It is sketched in Figure 13. Basically, it is an analysis/model\u00adupdate cycle. The analysis phase \nanalyses the program using the framework parameterized by the current abstract model. The model-update \nphase computes, when possible, a model-updating demand based on the current analysis results and applies \nit to the model. Note that the successive updates of the abstract model make it increasingly re.ned and \nthe analysis results that it helps to produce improve monotonically. Consequently, any run time type \ncheck that is proved to be redundant at some point remains as such for the rest of the cycle. The steps \nperformed during the model-update phase are: the ini\u00adtial demands are gathered; demand processing (of \nthe demands that do not modify the model) and call monitoring occur until no new demands can be generated; \nif there are model-updating demands, the best one is selected and applied on the model. The model\u00admodifying \ndemands are the split demands in which the splittee is V al C, V al P , or a member of (\u00df-var). create \ninitial model analyze program with model while there is time left set demand pool to initial demands \nmake the set of modifying demands empty repeat monitor call sites (l,k) that are marked while there is \ntime left and there are new demands in the pool do pick a new demand D in the pool if D is a modifying \ndemand then insert D in the modifying demands set else process D add the returned demands to the pool \nuntil there is no time left or there are no call sites to monitor if modifying demands set empty then \nexit else pick the best modifying demand D modify model with D re-analyze program with new model Figure \n13. Main demand-driven analysis algorithm The initial demands are those that we obtain by responding \nto the needs of the optimizer and not by demand processing. That is, if non-closures may be called or \nnon-pairs may go through a strictly pairwise operation, bound demands asking a demonstration that these \nviolations do not really occur are generated. More precisely, for a call (leli elii)and for k .C ont,if \nali k .V al C, then the initial , demand show ali k .V al C is generated. And for a pair-access , expression \n(carl eli) or (cdrl eli) and for k .C ont,if ali k . , V al P , then the initial demand show ali k .V \nal P is generated. , The criterion used to select a good model-updating demand in our implementation \nis described in Section 6. The analysis/model-update cycle continues until there is no more time left \nor no model updates have been proposed in the model\u00adupdate phase. Indeed, it is the user of a compiler \nincluding our demand-driven analysis who determines the bound on the compu\u00adtational effort invested in \nthe analysis of the program. The time is not necessarily wall clock time. It may be any measure. In our \nimplementation, a unit of time allows the algorithm to process a demand. Two reasons may cause the algorithm \nto stop by lack of model-updating demands. One is that there are no more initial de\u00admands. That means \nthat all the run time type checks of the program have been shown to be redundant. The other is that there \nremain initial demands but the current analysis results are mixed in such a way that the demand processing \ndoes not lead to the generation of a model-updating demand. 5.3 Demand Processing 5.3.1 Show In Demands \nNow, let us present the processing of demands. We begin with the processing of show (a-var).(bound)demands. \nLet us consider the demand show al,k .B. There are 3 cases. First case, if the val\u00adues in al,k all lie \ninside of the bound B, then the demand is trivially successful. Nothing has to be done in order to obtain \nthe desired demonstration. if al,k . B: . (SUCCESS) Second case, if the values in al,k all lie outside \nof the bound B, then it must be shown that the expression el does not get evaluated in the abstract contour \nk. This is a suf.cient and necessary condition because, if el is evaluated in contour k, any value it \nreturns is outside of the bound, causing the original demand to fail. And if el does not get evaluated \nin contour k, then we can conclude that any value in al,k lies inside the bound. if al,k n B = 0/: . \nshow dl,k = 0/ Last case, some values in al,k lie inside of B and some do not. The only sensible thing \nto do is to .rst split the contour k into sub\u00adcontours in such a way that it becomes clear whether the \nvalues all lie inside of B or they all lie outside of B. Since the bounds are all simple, splitting on \nthe type of the objects is suf.cient. Once (we would better say if ) the split demand is successful, \nthe original demand can be processed again. otherwise: . split al,k * 5.3.2 Show Empty Demands We continue \nwith the processing of show (d-var) = 0/ demands. Let us consider the demand show dl,k = 0/. There are \nmany cases in its processing. First, if the variable dl,k is already empty, then the demand is trivially \nsuccessful. if dl,k = 0/: . (SUCCESS) Otherwise, the fact that el does get evaluated or not in contour \nk depends a lot on its parent expression, if it has one at all. If it does not have a parent expression, \nit means that el is the main expression of the program and, consequently, there is no possibility to \nprove that el does not get evaluated in contour k.8 if el is the main expression: . (FAILURE) In case \nel does have a parent expression, let eli be that expression. Let us consider the case where eli is a \n.-expression. It implies that el is the body of eli . Note that the evaluation of el in contour k has \nno direct connection with the evaluation of eli in contour k. In fact, el gets evaluated in contour k \nif a closure c, resulting from the eval\u00aduation of eli in some contour, gets called somewhere (at expression \nelii ) in some (other) contour ki on a certain argument v in such a way that the resulting contour call(lii \n,c,v,ki) in which the body of c must be evaluated is k. So the processing of the demand consists in emitting \na bad call demand for each such abstract call. Note how the log matrices . and . are used to recover \nthe circumstances under which the contours and closures were created. 8In fact, it is a little more complicated \nthan that. We suppose here that the abstract variables contain the minimal solution for the evaluation \nconstraints generated by the analysis framework. In these conditions, for l being the label of the program \nmain expres\u00adsion, dl,k is non-empty if and only if k is the main abstract contour. For any other contour \nki , dl,ki = 0/. if eli = (.li x. el ): {} (lii bad-call lii cvki ,c,v,ki) . .k . . ,kii) . .c .kii . \nC ont. (li Now, let us consider the case where eli is a conditional. A condi\u00adtional has three sub-expressions, \nso we .rst consider the case where el is the then-branch of eli . Clearly, it is suf.cient to show that \neli is not evaluated at all in contour k. However, such a requirement is abusive. The suf.cient and necessary \ncondition for a then-branch to be evaluated (or not to be evaluated) is for the test to return (not to \nreturn, resp.) some true values. if eli = (ifli elii el eliii ): . show alii ,k . V al B The case where \nel is the else-branch of the conditional is analogous. The else-branch cannot get evaluated if the test \nalways returns true values. if eli = (ifli elii eliii el ): . show alii ,k . V al T rues The case where \nel is the test of the conditional can be treated as a default case. The default case concerns all situations \nnot explicitly treated above. In the default case, to prove that el does not get evaluated in contour \nk requires a demonstration that eli does not get evaluated in contour k either. This is obvious since \nthe evaluation of a call, cons, car, cdr,or pair? expression necessarily involves the evaluation of all \nits sub-expressions. Similarly for the test sub\u00adexpression in a conditional. otherwise: . show dli ,k \n= 0/ 5.3.3 Bad Call Demands We next describe how the bad call demands are processed. Let us consider \nthis demand: bad-call lf vk. The expression el is necessarily a call and let el = (leli elii ). There \nare two cases: either the speci.ed call does not occur, or it does. If the call does not occur, then \nthe demand is trivially successful.9 if f . ali ,k or v . alii ,k: . (SUCCESS) In the other case, the \nspeci.ed call is noted into the bad call log. Another note is kept in order to later take care of all \nthe bad calls at el in contour k. We call this operation monitoring el in contour k. More than one bad \ncall may concern the same expression and the same contour. Because the monitoring is a crucial operation, \nit should have access to bad call informations that are as accurate as possible. So, it is preferable \nto postpone the monitoring as much as possible. otherwise: . Insert (l, f ,v,k) in the bad call log. \nFlag (l,k) as a candidate for monitoring. 9Actually, in the current implementation, this case cannot \noccur. The demand is generated precisely because the speci.ed call was found in the . matrix. However, \nprevious implementations differed in the way demands were generated and bad call demands could be emitted \nthat were later proved to be trivially successful. 5.3.4 Split Demands Direct Model Split Let us now \npresent the processing of the split demands. The pro\u00adcessing differs considerably depending on the splittee. \nWe start by describing the processing of the following demands: split V al C P and split V al P P. These \nare easy to process because they explicitly prescribe a modi.cation to the abstract model. The modi.cation \ncan always be accomplished successfully. . Update Mv with P (SUCCESS) Split a-variables The most involving \npart of the demand processing is the processing of the split (a-var)(sPat) demands. Such a demand asks \nfor a splitting of the value of an expression in a certain contour, so that there is no more spreading \nof the values on the speci.ed pattern. Let us consider the demand split al,kP. The .rst possibility is \nthat there is actually no spreading. Then the demand is trivially successful. if \u00ac (al,k / P): . (SUCCESS) \nHowever, if there is spreading, then expression el has to be in\u00adspected, as the nature of the computations \nfor the different expres\u00adsions vary greatly. Let us examine each kind of expression, one by one. First, \nwe consider the false constant. Note that this expres\u00adsion can only evaluate to #f. So its value cannot \nbe spread on P,no matter which split pattern P is. For completeness, we mention the processing of the \ndemand nevertheless. if el = #fl : . (SUCCESS) Second, el may be a variable reference. Processing this \ndemand is straightforward and it translates into a split demand onto a (\u00df-var). if el = xl : . split \n\u00dfx,k,lP Third, el may be a call. Clearly, this case is the most dif.cult to deal with. This is because \nof the way a call expression is abstractly evaluated. Potentially many closures are present in the caller \nposi\u00adtion and many values are present in the argument position. It fol\u00adlows that a Cartesian product \nof all possible invocations must be done. In turn, each invocation produces a set that potentially con\u00adtains \nmany return values. So, in order to succeed with the split, each set of return values that is spread \non the pattern must be split. And the sub-expressions of the call must be split in such a way that no \ninvocation producing non-spread return values can occur in the same contour than another invocation producing \nincompatible non\u00adspread return values. This second task is done with the help of the function SC (Split \nCouples) that prescribes split patterns that sepa\u00adrate all the incompatible couples. An example follows \nthe formal description of the processing of the split demand on a call. if el = (leli elii ): . . split \n.c,ki Pc . ali ,k n V al C . . . .. v . alii ,k . . . ki = call(l,c,v,k) . . .. { .c,ki/ P } . split \nali ,kP1 P1 . B {} . split alii ,kP2 P2 . C .. .. ((c,v),.c,ki ) c . ali ,k n V al C . .. v . alii ,k \n. where A = . ki = call(l,c,v,k) . . . . \u00ac (.c,ki/ P) (B,C)= SC(A,P) The following example illustrates \nthe processing of the demand. Suppose that we want to process the demand split al,k *; that two closures \nmay result from the evaluation of eli , say, ali ,k = {c1,c2}; and that two values may be passed as arguments, \nsay, alii ,k = {v1,v2}. De.ne kij, for i, j .{1,2},as call(l,ci,vj,k). Also sup\u00adpose that \u00ac (.c1,k11 \n/ *), .c1,k12 / *, .c2,k21 / *, and \u00ac (.c2,k22 / *), that .c1,k11 . V al B, and that .c2,k22 . V al P \n. Closure c1, when called on v2, and closure c2, when called on v1, both return values that are spread \non *. It follows that their return values in those circumstances must be split. So, .c1,k12 and .c2,k21 \nmust be split by the pattern *. It is necessary for these two splits to succeed in order to make our \noriginal demand succeed. It is not suf.cient, however. We cannot allow c1 to be called on v1 and c2 to \nbe called on v2 under the same contour k. It is because the union of their return values is spread on \n*. They are incompatible. This is where the SC function comes into play and its use: SC({((c1,v1),.c1,k11 \n),((c2,v2),.c2,k22 )},*) returns either ({.*},0/) or (0/,{*}). In either case, a split according to the \nprescribed pattern, if successful, would make the two incom\u00adpatible calls occur in different contours. \nIf we suppose that the .rst case happens, the result of processing the original demand is: . split .c1,k12 \n* split .c2,k21 * split ali ,k .* Fourth, el may be a .-expression. The processing of this demand is \nsimple as it reduces to a split on the abstract model of closures. if el = (.l x. eli ): . split V al \nC P Fifth, let us consider the case where el is a conditional. Two cases are possible: the .rst case \nis that at least one of the branches is spread on the pattern; the second is that each branch causes \nno spreading on the pattern but they are incompatible and the test sub\u00adexpression evaluates to both true \nand false values. In the .rst case, a conservative approach consists in splitting the branches that cause \nthe spreading. if el = (ifl eli elii eliii ) . (alii / P . aliii / P): ,k ,k {} . split al(n),kP l(n) \n.{lii ,liii}. al(n)/ P ,k In the second case, it is suf.cient to split on the type of the test sub-expression, \nas determining the type of the test sub-expression allows one to determine which of the two branches \nis taken and consequently knowing that the value of the conditional is equal to one of the two branches. \nif el =(ifl eli elii eliii ): . split ali ,k * Sixth, our expression el may be a pair construction. The \nfact that the value of el is spread on the pattern implies .rst that the pattern has the form (Pi ,Pii)and \nsecond that the value of one of the two sub-expressions of el is spread on its corresponding sub-pattern \n(Pi or Pii). In either case, the demand is processed by splitting the appropriate sub-expression by the \nappropriate sub-pattern. if el =(consl eli elii ) . P =(Pi ,Pii) . Pi.(sPat): . split ali ,kPi ,Pii): \nif el =(consl eli elii ) . P =(Pi ,kPii . split alii Seventh, el may be a car-expression. In order to \nsplit the value of el on P, the sub-expression has to be split on (P,.). However, there is the possibility \nthat the abstract model of the pairs is not precise enough to abstract the pairs up the level of details \nrequired by (P,.). If not, the model of the pairs has to be split .rst. If it is, the split on the sub-expression \ncan proceed as planned. if el =(carl eli ) . V al P is precise enough for (P,.): . split ali ,k (P,.) \nif el =(carl eli ): . split V al P (P,.) Eighth, if el is a cdr-expression, the processing is similar \nto that of a car-expression. if el =(cdrl eli ) . V al P is precise enough for (.,P): . split ali ,k \n(.,P) if el =(cdrl eli ): . split V al P (.,P) Ninth, el must be a pair?-expression. Processing the demand \nsim\u00adply consists in doing the same split on the sub-expression. To see why, it is important to recall \nthat, if this case is currently be\u00ading considered, it is because al,k / P.If P =*, the type of the sub-expression \nmust be found in order to .nd the type of the ex\u00adpression. If P =(Pi , Pii), the same split is required \non the sub\u00adexpression since all the pairs of the pair?-expression come from its sub-expression. P cannot \nbe .* or .lii ki, for lii . Lab, ki.(mkPat), because el can only evaluate to Booleans and pairs. otherwise \nel =(pair?l eli ): . split ali ,kP Split \u00df-variables The next kind of split demands have a (\u00df-var) as \na splittee. Re\u00adcall that a (\u00df-var) indicates the name of a program variable and the label and contour \nwhere a reference to that variable occurs. Let us consider this particular demand: split \u00dfx,k,lP. Recall \nalso that the contour k is a modeling contour pattern which consists in a list of modeling patterns, \none per variable in the lexical environment visible from the expression el . Each modeling pattern represents \na kind of bound in which the value of the corresponding is guaran\u00adteed to lie. The .rst modeling pattern \ncorresponds to the innermost variable. The last corresponds to the outermost. Note that the analysis \nframework does not compute the value of variable references using these bounds. As far as the framework \nis concerned, the whole contour is just a name for a particular eval\u00aduation context. In the framework, \na reference to a variable x is computed by either inspecting the abstract variable \u00dfx,k if x is the innermost \nvariable or by translating it into a reference to x from the label li of the .-expression immediately \nsurrounding el and contour ki in which .-expression eli got evaluated, creating a closure that later \ngot invoked, leading to the evaluation of its body in contour k. For the details on variable references \nin the analysis framework, see [4]. Nonetheless, because of the way we implement the abstract model, \na reference to a variable x from a label l, and in a contour k always produces values that lie inside \nof the bound corresponding toxin k. Consequently, a split on a program variable involves a certain num\u00adber \nof splits on the abstract models of call and cc. Moreover, con\u00adsistency between abstract values also \nprescribes multiple splits on the abstract model. For example, if contour k results from the call of \nclosure .li ki on a value v at label lii, and in contour kii, that is, k =call(lii ,.li ki ,v,kii), then \ncontour k cannot be more precise than ki about the program variable bounds it shares with contour ki.In \nturn, if closure .li ki results from the evaluation of eli in contour kiii , that is, .li ki =cc(li ,kiii), \nthen contour ki cannot be more precise than kiii about the program variable bounds it shares with contour \nkiii. It follows that a split on a program variable, which can be seen as a re.ning of its bound in the \nlocal contour, requires the re.n\u00ading of a chain of contours and closure environments until a point is \nreached where the contour to re.ne does not share the variable with the closure leading to its creation. \nNow, if we come back to the processing of split \u00dfx,k,lP, the .rst thing that must be veri.ed is whether \na reference to x from el in contour k produces values that are spread on pattern P. We denote such a \nvariable reference by ref(x,k,l). If no spreading occurs,10 the demand is trivially successful, otherwise \nmodi.cations to the model must be done. if \u00ac (ref(x,k,l) / P): . (SUCCESS) otherwise: . Update Mlm with \n(Pm i Pm-1 ... P0) Update Mv with .lm+1 (Pm i Pm-1 ... P0) Update Mlm+1 with (Pm+1 Pm i Pm-1 ... P0) \n . . . Update Mv with .ln (Pn-1 ... Pm+1 Pm i Pm-1 ... P0) Update Mln with (Pn ... Pm+1 Pm i Pm-1 ... \nP0) where (.lm x. ...(.lm+1ym+1. ...(.ln yn. ...xl ...)...)...) is the .-expression binding x k =(Pn \n... Pm+1 Pm Pm-1 ... P0) Pi =Pm n P m Split .-variables The last kind of demands is the split demand \nwith a (.-var) as a splittee. The processing of such a demand is straightforward since 10Once again, \nthis case cannot occur in the current implementa\u00adtion. the return value of a closure is the result of \nthe evaluation of its body. Let us consider this particular demand: split .c,kP. In case the return value \nis not spread on the pattern, the demand in trivially successful. if \u00ac (.c,k / P): . (SUCCESS) otherwise: \n. split ali ,kP where c =.lki. el =(.l x. eli )  5.3.5 Call Site Monitoring The processing rules have \nbeen given for all the demands. However, we add here the description of the monitoring of call sites. \nThe monitoring of call sites is pretty similar to the processing of the demand split al,kP where el is \na call. The difference comes from the fact that, with the monitoring, effort is made in order to prove \nthat the bad calls do not occur. Let us consider the monitoring of call expression (leli elii ) in contour \nk. Let LBC denote the bad call log. Potentially many closures may result from the evaluation of eli and \npotentially many values may result from the evaluation of elii . Among all the possible closure-argument \npairs, a certain number may be marked as bad in the bad call log and the others not. If no pair is marked \nas bad, then the monitoring of el in k is trivially successful. () if (ali ,k n V al C)\u00d7 alii ,kn LBC(l,k)=0/: \n. (SUCCESS) On the contrary, if all the pairs are marked as bad calls, then a de\u00admand is emitted asking \nto show that the call does not get evaluated at all. () if (ali ,k n V al C)\u00d7 alii ,k. LBC(l,k): . show \ndl,k =0/ But in the general case, there are marked pairs and non-marked pairs occurring at the call site. \nIt is tempting to emit a demand D asking a proof that the call does not get evaluated at all. It would \nbe simple but it would not be a good idea. The non-marked pairs may abstract actual computations in the \nconcrete evaluation of the program and, consequently, there would be no hope of ever making D successful.11 \nWhat has to be done is to separate, using splits, the pairs that are marked and the pairs that are not. \nThe (overloaded) SC function is used once again. otherwise: {}{} . split ali ,kP1 | P1 . A. split alii \n,kP2 | P2 . B where A =(ali ,k n V al C )\u00d7 alii ,k (B,C)=SC(A,LBC(l,k))  5.3.6 The Split Couples Function \nWe conclude this section with a short description of the SC function. SC is used for two different tasks: \nsplitting closure-argument pairs 11This is because an analysis done using the framework is con\u00adservative \n(see [4]). That is, the computations made in the abstract interpretation abstract at least all the computations \nmade in the con\u00adcrete interpretation. So, it is impossible to prove that an abstract invocation does \nnot occur if it has a concrete counterpart occurring in the concrete interpretation. according to the \nbucket in which the return values fall relatively to a split pattern P; splitting closure-argument pairs \ndepending on the criterion that they are considered bad calls or not. In fact, those two tasks are very \nsimilar. In both cases, the set of pairs is partitioned into equivalence classes that are given either \nby the split pattern bucket or by the badness of the call. In order to separate two pairs (v1, v2)and \n(w1, w2)belonging to different classes, it is suf.cient to provide a split that separates v1 from w1 \nor a split that separates v2 from w2. So, what SC has to do is to prescribe a set of splits to perform \nonly on the .rst component of the pairs and another set of splits to perform only on the second component \nsuch that any two pairs from different classes would be separated. This is clearly possible since prescribing \nsplits intended to separate any .rst component from any other is a simple task. Similarly for the second \ncomponents. This way, any pair would be separated from all the others. Doing so would be overly aggressive, \nhowever, as there are usually much smaller sets of splits that are suf.cient to separate the pairs. Our \nimplementation of SC proceeds this way. It .rst computes the equivalence classes. Next, each pair is \nconverted into a genuine abstract pair (a modeling pattern). Then, by doing a breadth-.rst traversal \nof all the pairs simultaneously, splitting strategies are elab\u00adorated and compared. At the end, the strategy \nrequiring the smallest number of splits is obtained. Being as little aggressive as possible is important \nbecause each of the proposed splits will have to be ap\u00adplied on one of the two sub-expressions of a call \nexpression. And these sub-expressions may be themselves expressions that are hard to split (such as calls). \n  6 Experimental Results 6.1 Current Implementation Our current implementation of the demand-driven \nanalysis is mere\u00adly a prototype written in Scheme to experiment with the analysis approach. No effort \nhas been put into making it fast or space\u00adef.cient. For instance, abstract values are implemented with \nlists and symbols and closely resemble the syntax we gave for the mod\u00adeling patterns. Each re-analysis \nphase uses these data without con\u00adverting them into numbers nor into bit-vectors. And a projection using \nthe pattern-matchers is done for each use of the cc, pc, and call functions. Aside from the way demands \nare processed, many variants of the main algorithm have been tried. The variant that we present in Sec\u00adtion \n5 is the .rst method that provided interesting results. Previ\u00adous variants were trying to be more clever \nby doing model changes concurrently with demand processing. This lead to many compli\u00adcations: demands \ncould contain values and contours expressed in terms of an older model; a re-analysis was periodically \ndone but not necessarily following each model update, which caused some demands to not see the bene.ts \nof a split on the model that had just been done; a complex system of success and failure propaga\u00adtion, \nsequencing of processing, and periodic processing resuming was necessary; etc. The strength of the current \nvariant is that, after each model update, a re-analysis is done and the whole demand\u00adpropagation is restarted \nfrom scratch, greatly bene.tting from the new analysis results. In the current variant, we tried different \napproaches in the way the best model-updating demand is selected to be applied on the model. At .rst, \nwe applied all the model-updating demands that were pro\u00adposed by the demand processing phase. This lead \nto exaggerate (letrec1 map = (.2op.(.3l. (if4 (cons6 (7op8 (car9 )) l5 l10 (12map13 (11 op14 ) (cdr15 \n))) l16 ))) l17 (let18 op1 =(.19x. (car20 x21 )) (let22 op2 =(.23y.(24y25 #f26 )) (letrec27 loop = data. \n (.28 (let29 res1 =(30 (31map32 op133 ) (car34 data35 )) (let36 res2 =(37 (38map39 op240 )(cdr41 data42 \n)) loop44 (cons45 (cons46 (cons47 ) (43 #f48 #f49 (car50 data51 )) (cons52 w.#f54 ) (.53 (cdr55 data56 \n))))))) loop58 (cons59 #f60 #f61 )))))) (57 Figure 14. Source of the map-hardbenchmark re.ning of the \nmodel, leading to massive space use. So we decided to make a selection of one of the demands according \nto a certain criterion. The .rst criterion was to measure how much the abstract model increases in size \nif a particular demand is selected. While it helped in controlling the increase in size of the model, \nit was not choosing very wisely as for obtaining very informative analysis results. That is, the new \nresults were expressed with .ner values but the knowledge about the program data .ow was not always in\u00adcreased. \nMoreover, it did not necessarily help in controlling the increase in size of the analysis results. The \nsecond criterion, which we use now, measures how much the abstract model plus the analy\u00adsis results increase \nin size. This criterion really makes a difference, although the demand selection step involves re-analyzing \nthe pro\u00adgram for all candidate demands. 6.2 Benchmarks We experimented with a few small benchmark programs. \nMost of the benchmarks involve numeric computations using naturals. Two important remarks must be made. \nFirst, our mini-language does not include letrec-expressions. This means that recursive func\u00adtions must \nbe created using the Y combinator. Note that we wrote our benchmarks in an extended language with let-and \nletrec\u00adexpressions, and used a translator to reduce them into the base lan\u00adguage. We included two kinds \nof letrec translations: one in which Y is de.ned once globally and all recursive functions are created \nusing it; one in which a private Y combinator is generated for each letrec-expression. The .rst kind \nof translation really makes the programs more intricate as all recursive functions are closures cre\u00adated \nby Y. The second kind of translation loosely corresponds to making the analysis able to handle letrec-expressions \nas a special form. We made tests using both translation modes. Our second re\u00admark concerns numbers. Our \nmini-language does not include inte\u00adgers. Another translation step replaces integers and simple numeric \noperators by lists of Booleans and functions, respectively. Thus, in\u00adtegers are represented in unary \nas Peano numbers and operations on the numbers proceed accordingly. This adds another level of dif.\u00adculty \non top of the letrec-expression translation. For an example of translation, see Appendix A. Our benchmarks \nare the following. Cdr-safe contains the de.ni\u00adtion of a function which checks its argument to verify \nthat it is a pair before doing the access. It can be analyzed perfectly well by a 1-cfa, but not by a \n0-cfa. Loop is an in.nite loop. 2-1 computes the value of (-2 1). Map-easy uses the map function on a \nshort list of pairs using two different operators. Map-hard repetitively uses the map function on two \ndifferent lists using two different operators. The lists that are passed are growing longer and longer. \nThis use of map is mentioned in [7] as being impossible to analyze perfectly well by any k-cfa. The source \ncode of this benchmark is shown in Figure 14. Fib, gcd, tak, and ackare classical numerical computa\u00adtions. \nN-queens counts the number of solutions for 4 queens. SKI is an interpreter of expressions written with \nthe well known S, K, and I combinators. The interpreter runs an SKI program doing an in.nite loop. The \ncombinators and the calls are encoded using pairs and Booleans.  6.3 Results Figure 15 presents the \nresults of running our analysis on the bench\u00admarks. Each benchmark was analyzed when reduced with each \ntranslation method (global and private Y). A time limit of 10000 work units has been allowed for the \nanalysis of each bench\u00admark. The machine running the benchmarks is a PC with a 1.2 GHz Athlon CPU, 1 \nGByte RAM, and running RH Linux kernel 2.4.2. Gambit-C 4.0 was used to compile the demand-driven analysis. \nThe column labeled Y indicates whether the Y combinator is Global or Private. The next column indicates \nthe size of the trans\u00adlated benchmark in terms of the number of basic expressions. The columns labeled \ntotal , pre , during , and post indicate the number of run time type checks still required in the program \nat those moments, respectively: before any analysis is done, after the analysis with the initial model \nis done, during, and after the demand-driven analysis. Finally, the computation effort invested in the \nanalysis is measured both in terms of work units and CPU time. The measure in column total is a purely \nsyntactic one, it basi\u00adcally counts the number of call-, car-, and cdr-expressions in the program. The \nmeasure in pre is useful as a comparison between the 0-cfa and our analysis. Indeed, the initial abstract \nmodel used in our approach is quite similar to that implicitly used in the 0-cfa. An entry like 2@23 \nin column during indicates that 2 run time type checks are still required after having invested 23 work \nunits in the demand-driven analysis (this gives an idea of the convergence rate of the analysis). When \nwe look at Figure 15, the aspect of the results that is the most striking is the small improvements that \nthe full demand-driven analysis obtains over the results obtained by the 0-cfa. Two reasons explain this \nfact. First, many run time type checks are completely trivial to remove. For instance, every let-expression, \nonce trans\u00adlated, introduces an expression of the form ((.x. ...)...). In turn, the translation of each \nletrec-expression introduces 2 or 3 let\u00adexpressions, depending on the translation method. It is so easy \nto optimize such an expression that even a purely syntactic detection would suf.ce. Second, type checks \nare not all equally dif.cult to remove. The checks that are removed by the 0-cfa are removed be\u00adcause \nit is easy to do so. The additional checks that are removed by the demand-driven phase are more dif.cult \nones. In fact, the dif\u00ad.culty of the type checks seems to grow very rapidly as we come close to the 100% \nmark. This statement is supported by the numbers presented in [2] where a linear-time analysis, the sub-0-cfa, \nobtains analysis results that are almost as useful to the optimizer than those from the 0-cfa, despite \nits patent negligence in the manipulation of the abstract values. Note how translating with a private \nY per letrec helps both the 0-cfa and the demand-driven analysis. In fact, except for the n-queens benchmark, \nthe demand-driven analysis is able to re\u00admove all type checks when private Y combinators are used. The \nsuccess of the analysis varies considerably between benchmarks. Y size total pre during post units time(s) \ncdr-safe G P 17 17 4 4 1 1 0 0 5 5 0.02 0.02 loop G P 32 26 11 9 0 0 0 0 1 1 0.02 0.02 2-1 G P 48 42 \n15 13 2 2 1@7 1@7 0 0 47 48 0.30 0.26 map-easy G P 82 76 26 24 6 6 4@19 4@19 0 0 134 134 1.95 1.76 map-hard \nG P 96 101 33 35 9 4 6@38 5@254 3@305 1@520 2@118 0 0 1399 284 76.26 5.22 fib G P 141 168 40 50 12 5 \n4@16 3@29 2@39 1@46 12 0 10000 358 1480.57 8.77 gcd G P 257 328 77 103 8 6 7@25 6@47 5@66 4@82 3@95 2@105 \n1@112 5@19 4@35 3@48 2@58 1@65 1 0 10000 8509 7958.30 1088.58 tak G P 202 218 46 52 9 4 3@13 2@23 1@30 \n9 0 10000 240 1996.30 11.63 n-queens G P 372 454 121 151 51 11 10@34 9@65 8@93 7@118 6@140 5@1750 51 \n5 10000 10000 15899.39 1816.00 ack G P 162 189 49 59 5 3 4@16 3@29 2@39 1@46 2@10 1@17 1 0 10000 200 \n3948.32 7.97 SKI G P 285 290 46 48 19 17 15@91 13@173 11@323 9@397 7@473 6@543 5@1474 4@3584 13@52 11@98 \n9@138 8@212 5@249 4@358 3@567 1@673 4 0 10000 899 841.13 64.37 Figure 15. Experimental results  unrolling \n1248 16 units 176 280 532 1276 3724 time(s) 6.77 15.53 51.76 248.59 1592.93 Figure 16. The effect of \nthe size of a program on the analysis work Moreover, it is not closely related to the size of the program. \nIt is more in.uenced by the style of the code. In order to evaluate the performance of the analysis on \nsimilar programs, we conducted experiments on a family of such programs. We modi.ed the ack benchmark \nby unrolling the recursion a certain number of times. Translation with private Y is used. Figure 16 shows \nthe results for a range of unrolling levels. For each unrolling level i, the total number of type checks \nin the resulting program is 43 + 19i if no optimization is done, 3 checks are still required after the \nprogram is analyzed with the initial model, and all the checks are eliminated when the demand-driven \nanalysis .nishes. We observe a somewhat quadratic increase in the analysis times. This is certainly better \nthan the exponential behavior expected for a type analysis using lexical\u00adenvironment contours.  7 Conclusions \nThe type analysis presented in this paper produces high quality results through the use of an adaptable \nabstract model. During the analysis, the abstract model can be updated in response to the speci.cs of \nthe program while considering the needs of the opti\u00admizer. This adaptivity is obtained by the processing \nof demands that express, directly or indirectly, the needs of the optimizer. That is, the model updates \nare demand-driven by the optimizer. More\u00adover, the processing rules for the demands make our approach \nmore robust to differences in coding style. The approach includes a .exible analysis framework that generates \nanalyses when provided with modeling parameters. We proposed a modeling of the data that is based on \npatterns and described a method to automatically compute useful modi.cations on the ab\u00adstract model. \nWe gave a set of demands and processing rules for them to compute useful model updates. Finally, we demonstrated \nthe power of the approach with some experiments, showing that it analyzes precisely (and in relatively \nshort time) a program that is known to be impossible to analyze with the k-cfa. A complete pre\u00adsentation \nof our contribution can be found in [3]. An in-depth pre\u00adsentation of all the concepts and algorithms \nalong with the proofs behind the most important theoretical results are also found there. Except for \nthe ideas of abstract interpretation and .exible analyses, the remainder of the presented work is, to \nthe best of our knowl\u00adedge, original. Abstract interpretation is frequently used in the .eld of static \nanalysis (see [2, 7, 8, 9]). The k-cfa family of analyses (see [8, 9]) can, to some extent, be considered \nas .exible. The con.gurable analysis presented in [2] by Ashley and Dybvig can produce an extended family \nof analyses, but at compiler implemen\u00adtation time. Our analysis framework (see [4]) allows for more sub\u00adtlety \nand can be modi.ed during the analysis. We can think of many ways to continue research on this subject: \nex\u00adtended experiments on our approach in comparison to many other analyses; the speed and memory consumption \nof the analysis; in\u00adcremental re-analysis (that is, if analysis results R1 were obtained by using model \nM1, and model M2 is a re.nement of model M1, then compute new results R2 ef.ciently), better selection \nof the model-updating demands. Moreover, language extensions should be considered to handle a larger \npart of Scheme and extending our demand-driven approach to other analyses. There are also more theoretical \nquestions. We know that analyzing with the analysis framework and adequate modeling parameters is always \nat least as powerful as the k-cfa (or many other analyses). However, it requires the parameters to be \ngiven by an oracle. What we do not know is whether our current demand-driven approach is always at least \nas powerful as the k-cfa family. We think it is not, but do not yet have a proof. (letrec1 ack = (.m.(.n.(if(= \nm0) 2 3 4567 (+ n1) 8 9 10 (if(= n0) 11 121314 ((ack(-m1)) 1) 1516 17 18 1920 21 ((ack(-m1)) 2223 24 \n25 26 27 ((ackm)(-n1))))))) 2829 30 31 323334 ((ack4) 0)) 3536 37 38 39 Figure 17. The ackbenchmark, \nbefore expansion ((.Y.((.+p. 12 34 ((.+. 56 ((.-p. 78 ((.-.((.=p. 9 10 11 12 ((.=. 13 14 ((.ackp. 15 \n16 ((.ack.((ack(cons#f(cons#f(cons#f(cons#f#f)))))#f)) 17 18 192021 2223 2425 2627 282930 31 (Yackp))) \n3233 34 (.ackf.(.m.(.n.(if((=m)#f) 35 36 37 38 394041 42 43 ((+n)(cons#f#f)) 444546 47 48 49 50 (if((=n)#f) \n51 525354 55 56 ((ackf((-m)(cons#f#f)))(cons#f#f)) 5758 59 606162 63 64 65 66 67 68 69 ackf72 m)(cons77 \n#f78 #f79 ))) (70 (71 (73 (74-75 76 ((ackfm)((-n) (cons#f#f))))))))))) 8081 82 83 848586 87 88 89 90 \n(Y=p))) 9192 93 (. =f.(.x.(.y. (ifx(ify((=f(cdrx))(cdry))#f) 94 95 96 97 98 99 100 101 102 103 104 105 \n106 107 108 (ify#f(cons#f#f)))))))) 109 110 111 112 113 114 (Y-p))) 115 116 117 (.-f.(.x2.(.y2. (ify2((-f(cdrx2))(cdry2))x2)))))) \n118 119 120 121 122 123 124 125 126 127 128 129 130 (Y+p))) 131 132 133 (. +f.(.x3.(.y3.(ifx3(cons#f((+f(cdrx3)) \ny3)) y3)))))) 134 135 136 137 138 139 140 141 142 143 144 145 146 147 (. g.(gg))(.h.(.z.((f(hh))z)))))) \n(.148 f.(149 150 151 152 153 154 155 156 157 158 159 160 161 162 Figure 18. The ackbenchmark, after expansion \nOther researchers have worked on demand-driven analysis butina substantially different way (see the work \nof Duesterwald et al. [5], Agrawal [1], and Heintze and Tardieu [6]). These approaches do not have an \nabstract execution model that changes to suit the pro\u00adgram. Their goal is to adapt well-known analysis \nalgorithms into variants with which one can perform what amounts to a lazy evalu\u00adation of the analysis \nresults.  8 Acknowledgments The authors thank the anonymous referees for their careful review and the \nnumerous constructive comments. This work was supported in part by a grant from the Natural Sci\u00adences \nand Engineering Research Council of Canada. 9 References [1] G. Agrawal. Simultaneous demand-driven \ndata-.ow and call graph analysis. In Proceedings of International Conference on Software Maintenance, \npages 453 462, sep 1999. [2] J. M. Ashley and R. K. Dybvig. A practical and .exible .ow analysis for \nhigher-order languages. ACM Transactions on Pro\u00adgramming Languages and Systems, 20(4):845 868, jul 1998. \n[3] D. Dub\u00b4e. Demand-Driven Type Analysis for Dynamically-Typed Functional Languages. PhD thesis, Universit\u00b4ede \nMontr\u00b4eal, 2002. Available at: http://www.iro.umontreal.ca/ dube. [4] D. Dub\u00b4e and M. Feeley. Demand-driven \ntype analysis: an in\u00adtroduction. In Proceedings of the Workshop on Scheme and Functional Programming \n2001, pages 21 32, sep 2001. [5] E. Duesterwald, R. Gupta, and M. L. Soffa. Demand-driven computation \nof interprocedural data .ow. In Symposium of Principles of Programming Languages, pages 37 48, jan 1995. \n[6] N. Heintze and O. Tardieu. Demand-driven pointer analysis. In Proceedings of SIGPLAN 2001 Conference \non Programming Languages Design and Implementation, ACM SIGPLAN No\u00adtices. ACM Press, jun 2001. [7] S. \nJagannathan and S. Weeks. A uni.ed treatment of .ow analysis in higher-order languages. In 22nd ACM Symposium \non Principles of Programming Languages, pages 392 401, jan 1995. [8] O. Shivers. Control .ow analysis \nin Scheme. In Proceedings of the SIGPLAN 88 Conference on Programming Language Design and Implementation, \npages 164 174, jun 1988. [9] O. Shivers. The semantics of Scheme control-.ow analysis. In Proceedings \nof the Symposium on Partial Evaluation and Semantics-based Program Manipulation, pages 190 198, jun 1991. \n A Translation of a Benchmark In Section 6, we mention that letrec-expressions and numerical operations \nin the benchmarks have to be translated into the base language. We illustrate this process using the \nack benchmark. Fig\u00adure 17 shows the source code of the benchmark and Figure 18 shows the program after \ntranslation. Note that numbers have been replaced by cons-expressions and that the necessary arithmetic \noperators have been introduced as functions. Also note that the Y combi\u00adnator is bound .rst and that \nthe recursive functions ( ack and three arithmetic operators) are created using it.  \n\t\t\t", "proc_id": "581478", "abstract": "Compilers for dynamically and statically typed languages ensure safe execution by verifying that all operations are performed on appropriate values. An operation as simple as <i>car</i> in Scheme and <i>hd</i> in SML will include a run time check unless the compiler can prove that the argument is always a non-empty list using some type analysis. We present a demand-driven type analysis that can adapt the precision of the analysis to various parts of the program being compiled. This approach has the advantage that the analysis effort can be spent where it is justified by the possibility of removing a run time check, and where added precision is needed to accurately analyze complex parts of the program. Like the <i>k</i>-cfa our approach is based on abstract interpretation but it can analyze some important programs more accurately than the <i>k</i>-cfa for any value of <i>k</i>. We have built a prototype of our type analysis and tested it on various programs with higher order functions. It can remove all run time type checks in some nontrivial programs which use <i>map</i> and the Y combinator.", "authors": [{"name": "Danny Dub&#233;", "author_profile_id": "81100565940", "affiliation": "Universit&#233; de Montr&#233;al", "person_id": "P394761", "email_address": "", "orcid_id": ""}, {"name": "Marc Feeley", "author_profile_id": "81100041153", "affiliation": "Universit&#233; de Montr&#233;al", "person_id": "PP39024470", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/581478.581487", "year": "2002", "article_id": "581487", "conference": "ICFP", "title": "A demand-driven adaptive type analysis", "url": "http://dl.acm.org/citation.cfm?id=581487"}