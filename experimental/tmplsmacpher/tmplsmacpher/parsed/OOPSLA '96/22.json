{"article_publication_date": "10-01-1996", "fulltext": "\n Fast Static Analysis of C++ Virtual Function Calls David F. Bacon and Peter F. Sweeney IBM Watson Research \nCenter, P.O. Box 704, Yorktown Heights, NY, 10598 Email: {dfb,pfs}CJwatson.ibm.com Abstract Virtual functions \nmake code easier for programmers to reuse but also make it harder for compilers to analyze. We investi- \ngate the ability of three static analysis algorithms to improve C++ programs by resolving virtual function \ncalls, thereby reducing compiled code size and reducing program complex-ity so as to improve both human \nand automated program understanding and analysis. In measurements of seven pro-grams of significant size \n(5000 to 20000 lines of code each) we found that on average the most precise of the three algo-rithms \nresolved 71% of the virtual function calls and reduced compiled code size by 25%. This algorithm is very \nfast: it analyzes 3300 source lines per second on an 80 MHz Pow-erPC 601. Because of its accuracy and \nspeed, this algorithm is an excellent candidate for inclusion in production C++ compilers. Introduction \n A major advantage of object-oriented languages is ab- straction. The most important language feature \nthat supports abstraction is the dynamic dispatch of meth- ods based on the run-time type of an object. \nIn dynam- ically typed languages like Smalltalk and SELF, all dis- patches are considered dynamic, and \neliminating these dynamic dispatches has been essential to obtaining high performance [9, 14, 241. C++ \nis a more conservatively designed language. Programmers must explicitly request dynamic dispatch by declaring \na method to be virtual. C++ programs therefore suffer less of an initial performance penalty, Permission \nt0 make digit&#38;hard copy of part or all of this work for personal Or classroom Use iS granted without \nfee provided that copies are not made or distributed for profit or commercial advantage, the copyright \nnotice, the title of the publication and its date appear, and notice is given that copyrng Is by permission \nof ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires \nprior specific permission and/or a fee. OCPSIA 96 CA, USA CD 1996 ACM 0-89791-788-x/96/0010...$3.50 at \nthe cost of reduced flexibility and increased program-mer effort. However, virtual function calls still \npresent a significant source of opportunities for program opti-mization. The most obvious opportunity, \nand the one on which the most attention has been focused, is execution time overhead. Even with programmers \nspecifying virtual functions explicitly, the execution time overhead of vir- tual function calls in Ct+ \nhas been measured to be as high as 40% [16]. In addition, as programmers become familiar with the advantages \nof truly object-oriented de-sign, use of virtual functions increases. The costs as-sociated with developing \nsoftware are so high that the performance penalty of virtual functions is often not suf-ficient to deter \ntheir use. Therefore, unless compilers are improved, the overhead due to virtual function calls is likely \nto increase as programmers make more extensive use of this feature. Other researchers have shown that \nvirtual function call resolution can result in significant performance im-provements in execution time \nperformance for C++ pro-grams [6, 3, 161; in this paper we concentrate on c.ompar- ing algorithms for \nresolving virtual function calls, and investigating the reasons for their success or failure. Another \nopportunity associated with virtual func-tions is code size reduction. For a program without virtual \nfunction calls (or function pointers), a complete call graph can be constructed and only the functions \nthat are used need to be linked into the final program. With virtual functions, each virtual call site \nhas mul-tiple potential targets. Without further knowledge, all of those targets and any functions they \ncall transitively must be included in the call graph. As a result, object-code sizes for C++ programs \nhave become a major problem in some environments, par-ticularly when a small program is statically linked \nto a large object library. For instance, when a graphical hello world program is statically linked to \na GUI ob-ject library, even though only a very small number of classes are actually instantiated by the \nprogram, the entire library can be dragged in. Finally, virtual function calls present an analogous \nproblem for browsers and other program-understanding tools: if every potential target of a virtual function \ncall is included in the call graph, the user is presented with class A ( public : virtual int foo0 I \nreturn 1; 1; a vastly larger space of object types and functions that 3; must be comprehended to understand \nthe meaning of the program as a whole. In this paper, we compare three fast static analysis algorithms \nfor resolving virtual function calls and eval-uate their ability to solve the problems caused by virtual \nfunction calls in C++. We also use dynamic measure-ments to place an upper bound on the potential of \nstatic analysis methods, and compare the analysis algorithms against more sophisticated analyses like \nalias analysis. Finally, we present measurements of the speed of the analysis algorithms, which demonstrate \nthat they are fast enough to be included in commercial-quality com-pilers. 1.1 Outline Section 2 briefly \ndescribes and compares the mechanics of the three static analysis algorithms that are evalu-ated in this \npaper. Section 3 describes our benchmarks, presents the results of our measurements, and explains the \nreason behind the success or failure of the analy-sis algorithms. Section 4 describes related work, and \nSection 5 presents our conclusions.  2 Static Analysis In this paper we will be comparing three static \nanaly-sis algorithms, called Unique Name [6], Class Hierarchy Analysis [ll, 131, and Rapid Type Analysis \n[4]. We will sometimes abbreviate them as UN, CHA, and RTA, re-spectively. In this section we give a \nbrief overview of the three al-gorithms, and use a small example program to illustrate the differences \nbetween them. We then briefly compare them in power to other static analyses, and discuss the interaction \nof type safety and analysis. 2.1 Unique Name The first published study of virtual function call reso-lution \nfor C++ was by Calder and Grunwald [6]. They were attempting to optimize C++ programs at link time, and \ntherefore had to confine themselves to infor-mation available in the object files. They observed that \nin some cases there is only one implementation of a par- ticular virtual function anywhere in the program. \nThis void main0 c class B: public A { public : virtual int foo() 1 return 2; 3; virtual int foo(int i) \n{ return i+l; 3; 1. J, B* p = new B; int result1 = p->foo(l); int result2 = p-XooO; A* q = p; int result3 \n= q->fooO; 3 Figure I: Program illustrating the difference between the static analysis methods. can \nbe detected by comparing the mangled names 1 of the C++ functions in the object files. When a function \nhas a unique name (really a unique signature), the virtual call is replaced with a direct call. While \nit can be used within a compiler in the same manner as the other algorithms evaluated in this pa-per, \nUnique Name has the advantage that it does not require access to source code and can optimize virtual \ncalls in library code. However, when used at link-time, Unique Name operates on object code, which inhibits \noptimizations such as inlining. Figure 1 shows a small program which illustrates the power of the various \nstatic analyses. There are three virtual calls in main(). Unique Name is able to resolve the first call \n(that produces resultl) because there is only one virtual function called foo that takes an in-teger \nparameter -B : : f oo (int >. There are many f oo functions that take no parameters, so it can not resolve \nthe other calls.  2.2 Class Hierarchy Analysis Class Hierarchy Analysis [ll, 131 uses the combination \nof the statically declared type of an object with the class hierarchy of the program to determine the \nset of possible targets of a virtual function call. In Figure 1, p is a The mangled name of a function \nis the name used by the linker. It includes an encoding of the class and argument types to distinguish \nit from other identically named functions. pointer whose static type is B*. This means that p can point \nto objects whose type is B or any of B's derived classes. By combining this static information with the \nclass hierarchy, we can determine that there are no derived classes of B, so that the only possible \ntarget of the second call (that produces result2) is int B: :foo(). Class Hierarchy Analysis is more \npowerful than Unique Name for two reasons: it uses static informa-tion (as in Figure l), and it can ignore \nidentically-named functions in unrelated classes. Class Hierarchy Analysis must have the complete pro-gram \navailable for analysis, because if another module defines a class C derived from B that overrides f oo(), \nthen the call can not be resolved. In the process of performing Class Hierarchy Analy-sis, we build a \ncall graph for the program. The call graph includes functions reachable from main0 as well as those reachable \nfrom the constructors of global-scope objects. Note that some other researchers use the term Class Hierarchy \nAnalysis to denote only the resolu-tion of virtual calls, not the building of the call graph. 2.3 Rapid \nType Analysis Rapid Type Analysis [4] starts with a call graph gen-erated by performing Class Hierarchy \nAnalysis. It uses information about instantiated classes to further reduce the set of executable virtual \nfunctions, thereby reducing the size of the call graph. For instance, in Figure 1, the virtual call q->f \noo() (which produces results) is not resolved by Class Hi-erarchy Analysis because the static type of \nq is A*, so the dynamic type of the object could be either A or B. However, an examination of the entire \nprogram shows that no objects of type A are created, so A : : f oo (1 can be eliminated as a possible \ntarget of the call. This leaves only B: :foo(). Note that RTA must not consider instantiation of sub- \nobjects as true object instantiations: when an object of type B is created, A s constructor is called \nto initial-ize the A sub-object of B. However, the virtual function table of the contained object still \npoints to B's foo() method. Rapid Type Analysis builds the set of possible instan-tiated types optimistically: \nit initially assumes that no functions except main are called and that no objects are instantiated, and \ntherefore no virtual call sites call any of their target functions. It traverses the call graph cre-ated \nby Class Hierarchy Analysis starting at main. Vir-tual call sites are initially ignored. When a constructor \nfor an object is found to be callable, any of the virtual methods of the corresponding class that were \nleft out are then traversed as well. The live portion of the call graph and the set of instantiated classes \ngrow iteratively in an interdependent manner as the algorithm proceeds. Rapid Type Analysis inherits \nthe limitations and ben-efits of Class Hierarchy Analysis: it must analyze the complete program. Like \nCHA, RTA is flow-insensitive and does not keep per-statement information, making it very fast. Rapid \nType Analysis is designed to be most effec-tive when used in conjunction with class libraries. For instance, \na drawing library defines numerous objects derived from class shape, each with their own draw0 method. \nA program that uses the library and only ever creates (and draws) squares will never invoke any of the \nmethods of objects like circle and polygon. This will allow calls to draw0 to be resolved to calls to \nsquare : :draw(), and none of the other methods need to be linked into the final program. This leads \nto both reduced execution time and reduced code size. Another approach to customizing code that uses \nclass libraries is to use class slicing [23]. 2.4 Other Analyses There are several other levels of static \nanalysis that can be performed. First, a simple local flow-sensitive analy-sis would be able to resolve \nthis call: A* q = new B; q = new A; result = q->foo(); because it will know that q points to an object \nof type A. Rapid Type Analysis would not resolve the call because both A and B objects are created in \nthis program. An even more powerful static analysis method is alias analysis, which can resolve calls \neven when there is in- tervening code which could potentially change an ob-ject s type. Alias analysis \nis discussed more fully in Section 4.2, with related work. 2.5 Type Safety Issues An important limitation \nof CHA and RTA is that they rely on the type-safety of the programs. Continuing to use the class hierarchy \nfrom Figure 1, consider the following code fragment: void* x = (void*) new B; B* q = (B*) x; int case1 \n= q->fooO; Despite the fact that the pointer is cast to void* and then back to B+, the program is still \ntype-safe because we can see by inspection that the down-cast is actually to the correct type. However, \nif the original type is A, as in void* x = (void*) new A; B* q = (B*) x; int case2 = q->foo(); then the \nprogram is not type-safe, and the compiler would be justified in generating code that raises an ex-ception \nat the point of the virtual function call to f oo (> . However, because f oo( > is in fact defined for \nA, most existing compilers will simply generate code that calls A : : f oo ( > ; this may or may not \nbe what the program-mer intended. If the call had instead been int case3 = q->foo(666); then the program \nwill result in a undefined run-time behavior (most likely a segmentation fault) because A s virtual function \ntable (VFT) does not contain an entry for foo(int). The computation of case1 is clearly legal, and the \ncomputation of case3 is clearly illegal. In general it is not possible to distinguish the three cases \nstatically. Un-fortunately, in case2, Class Hierarchy Analysis would determine that the call was resolvable \nto B: : f oo(), which is incorrect. Rapid Type Analysis would deter-mine that there are no possible call \ntargets, which is correct according to the C++ language definition but different from what is done by \nmost compilers. Therefore, Class Hierarchy Analysis and Rapid Type Analysis either need to be disabled \nwhenever a downcast is encountered anywhere in the program, or they can be allowed to proceed despite \nthe downcast, with a warning printed to alert the programmer that optimization could change the results \nof the program if the downcasts are truly unsafe (as in case2 or case3). We favor the latter alternative \nbecause downcasting is very common in C++ programs. This can be sup-plemented by pragmas or compiler \nswitches which allow virtual function call resolution to be selectively disabled at a call site or for \nan entire module. We will discuss this issue further when we present the results for one of our benchmarks, \nlcom, which contained some unsafe code.  Experimental Results In this section we evaluate the ability \nof the three fast static analysis methods to solve the problems that were outlined in the introduction: \nexecution time perfor-mance, code size, and perceived program complexity. Where possible, we will use \ndynamic measurement in-formation to place an upper limit on what could be achieved by perfect static \nanalysis. 3.1 Methodology Our measurements were gathered by reading the C++ source code of our benchmarks \ninto a prototype C++ compiler being developed at IBM. After type analysis is complete, we build a call \ngraph and analyze the code. Since the prototype compiler is not yet generating code reliably enough to \nrun large benchmarks, we compile the programs with the existing IBM Ctt compiler on the RS/6000, xlC. \nThe b enchmarks are traced, and their executions are simulated from the instruction trace to gather relevant \nexecution-time statistics. We then use line number and type information to match up the call sites in \nthe source and object code. We used both optimized and unoptimized compiled versions of the benchmarks. \nThe unoptimized versions were necessary to match the call sites in the source code and the object code, \nbecause optimization includes in-lining, which distorts the call graph. However, existing compilers can \nnot resolve virtual function calls, so op-timization does not change the number of virtual calls, although \nit may change their location, especially when inlining is performed. Therefore, turning optimization \n(and inlining) off does not affect our results for virtual function resolution. Unoptimized code was \nonly used for matching virtual call sites. All measurements are for optimized code unless otherwise noted. \nBecause our tool analyzes source code, virtual calls in library code were not available for analysis. \nOnly one benchmark, simulate, contained virtual calls in the li-brary code. They are not counted when \nwe evaluate the efficacy of static analysis, since had they been available for analysis they might or \nmight not have been resolved. The information required by static analysis is not large, and could be \nincluded in compiled object files and libraries. This would allow virtual function calls in library code \nto be resolved, although it would not confer the additional benefits of inlining at the virtual call \nsite.  3.2 Benchmarks Table 1 describes the benchmarks we used in this study. Of the nine programs, \nwe consider seven to be real programs (sched, ixx, lcom, hotwire, simulate, id1 and taldict) which can \nbe used to draw meaningful conclusions about how the analysis algorithms will perform. id1 and taldict \nare both programs made up of production code with demo dri-vers; the rest are all programs used to solve \nreal prob-hotwire Scriptable graphical presentation builder simulate Simula-like simulation class library \nand example id1 SunSoft IDL compiler with demo back end taldict Taligent dictionarv benchmark deltablue \nIncremental dataflow constraint solver Benchmark 1 Lines Da-rint.inn---- I ---- 1 I sched Timing Simulator \nixx IDL specification to C++ stub-code translator ! lcom Compiler for the L hardware description language \n richards Simple operating system simulator r - Table 1: Benchmark Programs. Size is given in non-blank \nlines of code lems. The remaining two benchmarks, richards and deltablue, are included because they have \nbeen used in other papers and serve as a basis for comparison and validation. Table 2 provides an overview \nof the static character-istics of the programs in absolute terms. Library code is not included. The number \nof functions, call sites, and virtual call arcs gives a composite picture of the sta-tic complexity of \nthe program. Live call sites are those which were executed in our traces. Non-dead virtual call sites \nare those call sites, both resolved and unresolved, that remained in the program after our most aggressive \nanalysis (RTA) removed some of the dead functions and the virtual call sites they contained. Table 3 \nprovides an overview of the dynamic (execu-tion time) program characteristics for optimized code. Once \nagain, all numbers are for user code only. The number of instructions between virtual function calls \nis an excellent (though crude) indication of how much potential there is for speedup from virtual function \nres-olution. Under IBM s AIX operating system and C++ run-time environment a virtual function call takes \n12 in- structions, meaning that the user code of taldict could be sped up by a factor of two if all virtual \ncalls are re-solved (as they in fact are). The graphs in the paper all use percentages because the absolute \nnumbers vary so much. Tables 2 and 3 include the totals for all subsequent graphs, with the relevant \nfigure indicated in square brackets at the top of the column. Figure 2 is a bar graph showing the distribution \nof types of live call sites contained in the user code of the programs; Figure 3 shows the analogous \nfigures for the number of dynamic calls in user code. Direct (non-virtual) method calls account for an \naverage of 51% of the static call sites in the seven large applications, but only 39% of the dynamic \ncalls. Virtual method calls account for only 21% of the static call sites, but a much more significant \n36% of the total dynamic calls. Indirect function calls are used sparely except by deltablue, and pointer-to-member \ncalls are only used by ixx, and then so infrequently that they do not ap-pear on the bar chart. Since \nnon-virtual and virtual method calls are about evenly mixed, and direct (non-method) calls are less fre- \nquent, we conclude that the programs are written in a relatively object-oriented style. However, only \nsome of the classes are implemented in a highly reusable fash-ion, because half of the method calls are \nnon-virtual. The exception is taldict, with 89% of the dynamic function calls virtual: taldict uses the \nTaligent frame-works, which are designed to be highly re-usable. As use of C++ becomes more widespread \nand code reuse becomes more common, we expect that programs will become more like taldict, although probably \nnot to such an extreme. Note that we assume that trivially resolvable virtual function calls are implemented \nas direct calls, and count them accordingly throughout our measurements. That is, the call to f oo (> \nin A a; a.foo();  is considered a direct call even if f oo ( > is a virtual func-tion. This is consistent \nwith the capabilities of current production C++ compilers, but different from some re-lated work. Our \nresults differ, in some cases significantly, from those reported in two previous studies of C++ virtual \nfunction call resolution [6, 31. This would seem to indi-cate that there is considerable variation among \napplica-tions. Considerable additional work remains to be done for benchmarking of C++ programs. While \nthe SPEC benchmark suite has boiled down representative code to a small number of programs, it may well \nbe Program C ode Size ] Functions 1 Call 1 Li ve Call Virtual Non-Dead Virtual (bytes) PI [7] Sites Sites \n[2] Call Sites V-Call Sites [4] Call Arcs [8] sched 99,888 237 530 184 34 33 58 ixx 178:636 1 1.108 1 \n3,601 1 767 1 467 1 399 1.752 lcom 1641032 779 21794 1,653 458 446 1 hotwire 45,416 230 1,204 550 48 \n6 1 1. simulate 28.900 242 580 141 36 23 41 I I I I id1 1 24.1:748 1 856 1 3.671 1 882 1,248 1,198 \n3,486 I --- ---I I -1. I taldict 20.516 1 429 1 783 / 47 79 14 116 deltablue N.A. 103 372 201 3 3 11 \nrichards 9,744 78 174 68 1 1 5 Table 2: Totals for static (compile-time) quantities measured in this \npaper. All quantities are measured for user code only (libraries linked to the program are not included). \nNumbers in brackets are the numbers of subsequent figures for which the column gives the total. [Program \nInstrs. Function Virtual Instrs. per Executed Calls [3] Calls [5] Virtual Call Table 3: Totals for dynamic \n(run-time) quantities measured in this paper. All quantities are for user code only (libraries linked \nto the program are not included). Numbers in brackets are the numbers of subsequent figures for which \nthe column gives the total. Figure 2: Classification of Live User Call Sites (Static) . Virtual Method \nIII Direct Method 69 Indirect Function 0 Direct Function Figure 3: Classification of User Calls (Dynamic) \n . Virtual Method I Direct Method El Indirect Function 0 Direct Function ._ that such an approach will \nnot work with C++ because it is a more diverse language with more diverse usage patterns.  3.3 Resolution \nof Virtual Function Calls When a virtual call site always calls the same function during one or more \nruns of the program, we say that it is monomorphic. If it calls multiple functions, it, is poly- morphic. \nIf t.he optimizer can prove that a monomor-phic call will always call the same function, then it can \nbe resolved statically. Polymorphic call sites can not be resolved unless the enclosing code is cloned \nor type tests are inserted. The performance of the analyses for resolving virtual function calls is shown \nin Figures 4 (which presents the static information for the call sites) and 5 (which presents the dynamic \ninformation for the calls in our program traces). Together with the remaining graphs they compare the \nperformance of the three static analy-sis algorithms, and they all use a consistent labeling to aid in \ninterpretation. Black is always used to label the things that could not possibly be handled by static \nanalysis; in the case of virtual function resolution, black represents the call sites or calls that were \npolymorphic. White represents the region of possible opportunity for finer analysis; for virtual function \nresolution, this is the call sites or calls that were dynamically monomorphic but were not resolved by \nany of the static analysis meth-ods we implemented. For graphs of static quantities, the diagonally striped \nsection labels an additional region of opportunity in unexecuted code; for virtual function resolution, \nthis is the call sites that were not resolved and were not executed at run-time. They may be dead, monomorphic, \nor polymorphic. Since Class Hierarchy Analysis (CHA) resolves a su-perset of the virtual calls resolved \nby Unique Name (UN), and Rapid Type Analysis (RTA) resolves a super- set of the virtual calls resolved \nby CHA, we show their cumulative effect on a single bar in the chart. There-fore, to see the effect of \nRTA, the most powerful analy-sis, include all the regions labeled as resolved (they are outlined with \na thick line). If the region of opportunity is very small, then the dy-namic trace has given us a tight \nupper bound: we Icnow that no static analysis could do much better. On the other hand, if the white region \n(and for static graphs, the striped region) is large, then the dynamic trace has only given us a loose \nupper bound: more powerful static analysis might be able to do better, or it might not. Call sites identified \nas dead by Rapid Type Analysis were not counted, regardless of whether they were re-solved. This was \ndone so that the static and dynamic measurements could be more meaningfully compared, and because it \nseemed pointless to count as resolved a call site in a function that can never be executed. However, \nthis has relatively little effect on the overall percentages. Figure 5 shows that for for five out of \nseven of the large benchmarks, the most powerful static analysis, RTA, resolves all or almost all of \nthe virtual function calls. In other words, in five out of seven cases, RTA does an essentially perfect \njob. On average, RTA re-solves 71% of the dynamic virtual calls in the seven large benchmarks. CHA is \nalso quite effective, resolving an average of 51%, while UN performs relatively poorly. resolving an \naverage of 15% of the dynamic virtual calls. We were surprised by the poor performance of Unique Name, \nsince Calder and Grunwald found that Unique Name resolved an average of 32% of the virtual calls in their \nbenchmarks. We are not sure why this should be so; possibly our benchmarks, being on average of a later \nvintage, contain more complex class hierarchies. UN relies on there only being a single function in the \nentire application with a particular signature. Our benchmarks are surprisingly monomorphic; only two \nof the large applications (ixx and lcom) exhibit a significant degree of polymorphism. We do not expect \nthis to be typical of C-t+ applications, but perhaps monomorphic code is more common than is generally \nbelieved. A problem arose with one program, lcom, which is not type-safe: applying CHA or RTA generates \nsome specious call site resolutions. We examined the pro-gram and found that many virtual calls were \npoien$iaZZy unsafe, because the code used down-casts. However, most of these potentially unsafe calls \nare in fact safe, because the program uses a collection class defined to hold pointers of type void*. \nUsually, inspection of the code shows that the down-casts are simply being used to restore a void* pointer \nto the original type of the object inserted into the collection. We therefore selectively turned off \nvirtual function call resolution at the call sites that could not be de-termined to be safe; only 7% \nof the virtual calls that would have been resolved by static analysis were left unresolved because of \nthis (they are counted as unre-solved monomorphic calls). We feel that this is a rea-sonable course because \na programmer trying to opti-mize their own program might very well choose to fol-low this course rather \nthan give up on optimization al-together; readers will have to use their own judgment as to whether this \nwould be an acceptable programming practice in their environment. The only benchmark to use library code \ncontaining ;; @ P .-z = 3 1 r .- > 0 E 4 s z T @ UJ Tl 0 Figure 4: Resolution of User Virtual Call \nSites (Static) 100% 80% . Unresolved/Polymorphic . Executed Unresolved/Not 60% 0 Unresolved/Monomorphic \nH Resolved by RTA 40% . by CHA Resolved 20% . by UN Resolved 0% % .-:: E E a, .--0 z 2 2 15: -8 \n5 Tt n 7i h r3 Lz 3 E it L .-.g * -0 Programs Figure 5: Resolution of User Virtual Calls 100% 80% \n. Unresolved/Polymorphic 60% 0 Unresolved/Monomorphic 4 0 % . by RTA Resolved . by CHA Resolved . by \nUN Resolved virtual calls was simulate, which uses the task library supplied with AIX. Slightly less \nthan half of the virtual calls were made from the library code, and about half of those calls were monomorphic \n(and therefore potentially resolvable). We have not included virtual calls in library code in the graphs \nbecause the corresponding code was not available to static analysis. 3.3.1 Why Rapid Type Analysis Wins \nSince Class Hierarchy Analysis is a known and accepted method for fast virtual function resolution, it \nis impor- tant to understand why RTA is able to do better. RTA does better on four of seven programs, \nalthough for id1 the improvement is minor. For ixx, RTA re-solves a small number of additional static \ncall sites (barely visible in Figure 4), which account for almost 20% of the total dynamic virtual function \ncalls. The reason is that those calls are all to frequently exe-cuted string operations. There is a base \nclass String with a number of virtual methods, and a derived class Uniquestring, which overrides those \nmethods. RTA determines that no Uniquestring objects are created in ixx, and so it is able to resolve \nthe virtual call sites to String methods. These call sites are in inner loops, and therefore account \nfor a disproportionate number of the dynamic virtual calls. RTA also makes a significant difference for \ntaldict, resolving the remaining 19% of unresolved virtual calls. RTA is able to resolve two additional \ncall sites because they are calls where a hash table class is calling the method of an object used to \ncompare key values. The comparison object base class provides a default com-parison method, but the derived \nclass used in taldict overrides it. RTA finds that no instances of the base class are created, so it \nis able to resolve the calls. The hotwire benchmark is a perfect example of the class library scenario: \na situation in which an applica-tion is built using only a small portion of the function-ality of a class \nlibrary. The application itself is a sim-ple dynamic overhead transparency generator; it uses a library \nof window management and graphics routines. However, it only creates windows of the root type, which \ncan display text in arbitrary fonts at arbitrary locations. All of the dynamic dispatch occurs on redisplay \nof sub- windows, of which there are none in this application. Therefore, all of the live virtual call \nsites are resolved.  3.3.2 Why Fast Static Analysis Fails One benchmark, sched, stands out for the poor \nperfor-mance of all three static analysis algorithms evaluated in this paper. Only 10% of the dynamic \ncalls are resolved, even though 30% of the static. call sites are resolved, and 100% of the dynamic calls \nare monomorphic. Of course, a function may be monomorphic with one input but not with another. However, \nsched appears to actually be completely monomorphic. The unresolved monomorphic virtual call sites are \nall due to one particular programming idiom: sched de-fines a class Base and two derived classes Derived1 \nand Derived2 (not their real names). Base has no data members, and defines a number of virtual func-tions \nwhose implementation is always assert (f alse) -in other words, they will raise an exception when ex-ecuted. \nIn essence, Base is a strange sort of abstract base class. Derived1 and Derived2 each implement a mutually \nexclusive subset of the methods defined by Base, and since Base has no data members, this means that \nthese two object types are totally disjoint in functionality. It is not clear why the common base class \nis being used at all. RTA determines that no objects of type Base are ever created. However, the calls \nto the methods of Derived1 and Derived2 are always through pointers of type Base*. Therefore, there are \nalways two possi-ble implementations of each virtual function: the one defined by one of the derived \nclasses, and the one inher-ited from Base by the other derived class. Depending on your point of view, \nthis is either an example of the inability of static analysis to handle par-ticular coding styles, or \nanother excellent reason not to write strange code. The other benchmark for which none of the static \nanalyses do a very good job is Icorn: 45% of the virtual calls are monomorphic but unresolved. 40% of \nthe vir-tual calls are from a single unresolved call site. These calls are all through an object passed \nin from a single procedure, further up in the call graph. That procedure creates the object with new, \nand it is always of the same type. While it would probably not be resolved by simple flow analysis, it \ncould be resolved by alias analysis. What kinds of programming idioms are not amenable to fast static \nanalysis? CHA will resolve monomorphic virtual calls for which there is only a single possible target. \nRTA will also eliminate monomorphic calls when only one of the possible target object types is used in \nthe program. The kind of monomorphic calls that can t be resolved by RTA occur when multiple related \nobject types are used independently, for instance if Square and Circle objects were each kept on their \nown linked list, instead of being mixed together. We call this disjointed polymorphism. Disjointed polymorphism \nis what occurs in lcom and, in a degenerate fashion, in sched. While there are cer-3.5 Static Complexity \ntainly situations in which it does make sense to use disjointed polymorphism, we believe it to be relatively \nuncommon, and this is borne out by our benchmarks. Disjointed polymorphism presents the major opportu-nity \nfor alias analysis to improve upon the fast static techniques presented in this paper, since it can some-times \ndetermine that a pointer can only point to one type of object even when multiple possible object types \nhave been created.   3.4 Code Size Because they build a call graph, Class Hierarchy Analy-sis and Rapid \nType Analysis identify some functions as dead: those that are not reachable in the call graph. RTA is \nmore precise because it removes virtual call arcs to methods of uninstantiated objects from the call \ngraph. Figure 6 shows the effect of static analysis on user code size. As before, white represents the \nregion of op- portunity for finer analysis -those functions that were not live during the trace and were \nnot eliminated by static analysis. Our measurements include only first-order effects of code size reduction \ndue to the elimination of entire func-tions. There is a secondary code-size reduction caused by resolving \nvirtual call sites, since calling sequences for direct calls are shorter than for virtual calls. We also \ndid not measure potential code expansion (or contraction) caused by inlining of resolved call sites. \nFinally, due to technical problems our code size measurements are for unoptimized code, and we were not \nable to obtain measurements for deltablue. On average, 42% of the code in the seven large bench-marks \nis not executed during our traces. Class Hierar-chy Analysis eliminates an average of 24% of the code \nfrom these benchmarks, and Rapid Type Analysis gets about one percent more. CHA and RTA do very well \nat reducing code size: in five of the seven large benchmarks, less than 20% of the code is neither executed \nnor eliminated by static analysis. Only ixx and id1 contain significant portions of code that was neither \nexecuted nor eliminated (about 40%). We were surprised to find that despite the fact that RTA does substantially \nbetter than CHA at virtual function resolution, it does not make much difference in reducing code size. \nUnique Name does not remove any functions because it only resolves virtual calls; it does not build a \ncall graph. Another important advantage of static analysis is its use in programming environments and \ncompilers. For instance, in presenting a user with a program browser, the task of understanding the program \nis significantly easier if large numbers of dead functions are not in-cluded, and if virtual functions \nthat can not be reached are not included at virtual call sites. In addition, the cost and precision of \nother forms of static analysis and optimization are improved when the call graph is smaller and less \ncomplex. Figure 7 shows the effect of static analysis on elimi-nating functions from the call graph. \nThis is similar to Figure 6, except that each function is weighted equally, instead of being weighted \nby the size of the compiled code. As we stated above, since Unique Name does not build a call graph, \nit does not eliminate any functions. Once again, Class Hierarchy Analysis eliminates a large number of \nfunctions, and Rapid Type Analysis eliminates a few more. Figure 8 shows the effect of static analysis \non the number of virtual call arcs in the call graph. At a virtual call site in the call graph for a \nC++ program, there is an arc from the call site to each of the possible virtual functions that could \nbe called. Class Hierarchy Analysis removes call arcs because it eliminates functions, and so any call \narcs that they contain are also removed. Rapid Type Analysis can both remove dead functions and remove \nvirtual call arcs in live functions. For example, refer back to Figure 1 at the beginning of this paper: \neven though main0 is a live function, RTA removes the call arc to A : : f oo (> at the call that produces \nresult.3 because it. discovers that no objects of type A are ever created. Surprisingly, despite the \nlarge number of virtual call sites that are resolved in most programs, relatively few virtual call arcs \nare removed in three of the seven large benchmarks. In those programs, the virtual function resolution \nis due mostly to Class Hierarchy Analysis. CHA, by definition, resolves a function call when there is \nstatically only a single possible target function at the call site. Therefore, the call site is resolved, \nbut the call arc is not removed. On the other hand, because RTA actually removes call arcs in live functions, \nit may eliminate substantial numbers of call arcs, as is seen in the case of hotwire.  3.6 Speed of \nAnalysis We have claimed that a major advantage of the algo-rithms described in this paper is their speed. \nTable 4 shows the cost of performing the Class Hierarchy Analy- Figure 6: User Code Size Reduction \n(Static) 3 c 80% z : m 60% I Cl Not Eliminated/Unexecuted s 40% .- cn G 8 20%  Program Figure 7: Elimination \nof Functions  (Static) 80% 3 b 60% 0 Not Eliminated/Not Executed ! E _::,:I:-40% E I? 20% Program \nFigure 8: Elimination of Virtual Call Arcs (Static) Program Figure 9: Resolution of Static Call Sites \n(Alias Analysis Benchmarks) 100% 80% Unresolved/Polymorphic T . Executed Unresolved/Not @ 60% 8 Cl \nUnresolved/Monomorphic .Z m . by RTA Resolved z 40% . by CHA Resolved 0 . by UN Resolved 20% Size Analysis \nTime Compile RTA Benchmark (lines) CHA RTA Time Overhead sched 5,712 1.90 1.94 921 < 0.1% ixx 11,157 \n5.12 5.22 367 1.4% lcom 17.278 6.27 6.50 218 3.0% hotwire--- 51335 2.05 2.06 160 1.3% simulate 6,672 \n2.67 2.75 49 5.6% id1 30,288 5.71 6.42 450 1.4% taldict 11,854 1.66 1.78 45 4.0% deltablue 1,250 0.42 \n0.44 18 2.4% richards 606 0.30 0.32 9 3.6% Table 4: Compile-Time Cost of Static Analysis (timings are \nin seconds on an 80 MHz PowerPC 601). Compile time is for optimized code, and includes linking. Rightmost \ncolumn shows the overhead of adding RTA to the compilation process. sis and Rapid Type Analysis algorithms \non an 80 MHz PowerPC 601, a modest CPU by today s standards. The total time to compile and link the program \nis also included for comparison. We do not include timings for Unique Name because we implemented it \non top of CHA, which would not be done in a real compiler. Since Unique Name performed poorly compared \nto CHA and RTA, we did not feel it was worth the extra effort of a native implementation. RTA is not \nsignificantly more expensive than CHA. This is because the major cost for both algorithms is that of \ntraversing the program and identifying all the call sites. Once this has been done, the actual analysis \nproceeds very quickly. RTA analyzes an average of 3310 non-blank source lines per second, and CHA is \nonly marginally faster. The entire 17,278-line lcom benchmark was analyzed in 6.5 seconds, which is only \n3% of the time required to compile and link the code. On average, RTA took 2.4% of the total time to \ncompile and link the program. We expect that these timings could be improved upon significantly; our \nimplementation is a prototype, de-signed primarily for correctness rather than speed. No optimization \nor tuning has been performed yet. Even without improvement, 3300 lines per second is fast enough to include \nin a production compiler without significantly increasing compile times.   4 Related Work 4.1 Type \nPrediction for C++ Aigner and H6lzle [3] compared the execution time per-formance improvements due to \nelimination of virtual function calls via class hierarchy analysis and profile-based type prediction. \nOur work differs from theirs in that we compare three different static analysis tech-niques, and in that \nwe demonstrate the ability of static analysis to reduce code size and reduce program com-plexity. We \nalso use dynamic information to bound the performance of static analysis. Type prediction has advantages \nand disadvantages compared with static analysis. Its advantages are that it resolves more calls, and \ndoes not rely on the type-correctness of the program. Its disadvantages are that it requires the introduction \nof a run-time test; it requires profiling; and it is potentially dependent upon the input used during \nthe profile. Ultimately, we believe that a combination of static analysis with type prediction is likely \nto be the best solution. In Aigner and Hiilzle s study, excluding the trivial benchmarks deltablue and \nrichards and weighting each program equally, Class Hierarchy Analysis resolved an average of 27% of the \ndynamic virtual function calls (and a median of 9%). They said they were surprised by the poor performance \nof CHA on their benchmarks, since others had found it to perform well. In our mea-surements, CHA resolved \nan average of 51% of the dy-namic virtual calls, so it seems that there is considerable variation depending \nupon the benchmark suite. In fact, we got different results for the one large benchmark that we had in \ncommon, ixx, due to a different input file and possibly a different version of the program. Type prediction \ncan always resolve more virtual calls than static analysis, because it precedes a direct call with a \nrun-time test. Call sites resolved by sta-tic analysis do not need to perform this test, and one would \ntherefore expect the execution time benefit from static resolution to be greater than that from type \npre-diction. This trend is indeed evident in their execution time numbers: for only one of their benchmarks \ndoes type feedback provide more than a 3% speedup over Class Hierarchy Analysis. This is despite the \nfact that in all but one of the benchmarks, type prediction re-solves a significantly larger number of \nvirtual calls. 4.2 Alias Analysis for C++ The most precise, and also most expensive, proposed static \nmethod for resolving virtual function calls is to use interprocedural flow-sensitive alias analysis. \nPande and Ryder [19, 181 have implemented an alias analysis algorithm for C++ based on Landi et al. s \nalgorithm for C [15]. This analysis is then used to drive virtual function elimination. They give preliminary \nresults for a set of 19 benchmark programs, ranging in size from 31 to 968 lines of code. In comparison \nwith our RTA algorithm, which processes about 3300 lines of source code per second (on an 80 MHz PowerPC \n601), the speed of their al-gorithm ranges from 0.4 to 55 lines of source code per second (on a Spare-10). \nAt this speed, alias analysis will not be practical in any normal compilation path. We have obtained \ntheir benchmark suite; Figure 9 shows the performance of our static analysis algorithms on the 9 programs \nthat we could execute (since their analysis is purely static, not all programs were actu-ally executable). \nOf these 9, two are completely poly-morphic (no resolution is possible), and two were all or almost all \nresolved by Rapid Type Analysis or Class Hi-erarchy Analysis. So for four out of nine, RTA does as well \nas alias analysis. RTA resolved 33% of the virtual call sites in objects, compared to about 50% by alias \nanalysis (for compar-ative data, see their paper [19]). For the remaining four (derivi , deriv2, family, \nand off ice) fast sta-tic analysis did not resolve any virtual call sites, and significant fractions \nof the call sites were dynamically monomorphic. Alias analysis was able to resolve some of the virtual \ncall sites in derivl and deriv2, and all of the virtual call sites in family and off ice. However, the \nlatter two programs are contrived examples where aliases are deliberately introduced to objects created \nin the main routine. Because of the small size and unrealistic nature of the benchmarks used by Pande \nand Ryder, we hesitate to make any generalizations based on the results of our comparison. Two of our \nseven large benchmarks, sched and lcom, appear to be programs for which alias analy-sis could perform \nbetter than RTA. These programs make use of disjointed polymorphism, as discussed in Section 3.3.2. \nOver all, our benchmarks and Pande and Ryder s in-dicate that for most programs, there is relatively \nlittle room for improvement by alias analysis over RTA. How-ever, there are definitely cases where alias \nanalysis will make a significant difference. The ideal solution would be to use RTA first, and only employ \nalias analysis when RTA fails to resolve a large number of monomorphic calls. In a similar vein as Pande \nand Ryder, Carini et al. [7] have also devised an alias analysis algorithm for C++ based on an algorithm \nfor C and Fortran [lo, 51. We are currently collaborating with them on an implementation of their algorithm \nwithin our analysis framework. This will allow a direct comparison of both the precision and the efficiency \nof alias analysis 4.3 Other Work in C++ Porat et al. [21] implemented the Unique Name op-timization \nin combination with type prediction in the IBM xlC compiler for AIX, and evaluated the results for 3 \nbenchmark programs. Their two large benchmarks were identical to two of ours: taldict and lcom. They \nachieved a speedup of 1.25 on taldict and a speedup of 1.04 on Icorn, using a combination of Unique Name \nand type prediction. Our estimates and experiments in-dicate that a significantly higher speedup is achievable \nfor taldict using Rapid Type Analysis. Calder and Grunwald [6] implemented the first virtual function \nresolution algorithm for C++. Their Unique Name algorithm (which might more accurately be called Unique \nSignature ) is very fast, since it only requires a linear scan over the method declarations in the pro-gram. \nCalder and Grunwald implemented Unique Name as a link-time analysis, and found it to be quite effec-tive. \nWith their benchmarks, it resolved anywhere from 2.9% to 70.3% of the virtual calls executed by the pro-gram. \nWe found it to be not nearly so effective on our benchmarks, and it was significantly outperformed by \nRapid Type Analysis. Srivastava [22] developed an analysis technique with . the sole object of eliminating \nunused procedures from C++ programs. He builds a graph starting at the root of the call graph. Virtual \ncall sites are ignored; in-stead, when a constructor is reached, the referenced virtual methods of the \ncorresponding class are added to the graph. His algorithm could also be used to re-solve virtual function \ncalls by eliminating uninstanti-ated classes from consideration and then using Class Hierarchy Analysis. \nHis technique is less general than RTA because the resulting graph is not a true call graph, and can \nnot be used as a basis for further optimization. 4.4 Other Related Work Related work has been done in \nthe context of other object-oriented languages like Smalltalk, SELF, Cecil, and Modula-3. Of those, Modula-3 \nis the most similar to c++. Fernandez [ 131 implemented virtual function call elimination as part of \nher study on reducing the cost of opaque types in Modula-3. She essentially implemented Class Hierarchy \nAnalysis, although only for the purpose of resolving virtual calls, and not for eliminating dead code. \nDiwan et al. [12] have investigated a number of algorithms for Modula-3, including an interprocedural \nuni-directional flow-sensitive technique, and a name-sensitive technique. For the benchmarks they studied, \ntheir more power-ful techniques were of significant benefit for Modula-3, because they eliminated the \nNULL class as a possible tar-get. However, when NULL is ignored (as it is in C-t-t-), in all but one \ncase the more sophisticated analyses did no better than class hierarchy analysis. This is inter-esting \nbecause we found several cases in which Rapid Type Analysis was significantly better than Class Hier-archy \nAnalysis -this may indicate that class instantia-tion information is more important than the flow-based \ninformation. Because of the wide variation we have seen even among our C++ benchmarks, it seems unwise \nto ex-trapolate from Modula-3 results to C++. However, de-spite the difference between their and our \nalgorithms, the basic conclusion is the same: that fast static analy-sis is very effective for statically \ntyped object-oriented languages. Dean et al. [ll] studied virtual method call elimina-tion for the pure \nobject-oriented language Cecil, which includes support for multi-methods. They analyzed the class hierarchy \nas we do to determine the set of type-correct targets of a virtual method call, and used this information \nto drive an intraprocedural flow analysis of the methods. Their method is not directly comparable to \nRTA: it uses more precise information within proce-dures, but performs no interprocedural analysis at \nall. Measured speedups for benchmarks of significant size were on the order of 25%, and code size reduction \nwas also on the order of 25%. There has been considerable work on type inference for dynamically typed \nlanguages [20, 8, 1, 171. In a recent paper [2], Agesen and HGlzle showed that type inference can do \nas well or better than dynamic re-ceiver prediction in the SELF compiler, and proceeded to extrapolate \nfrom these results to C++ by excluding dispatches for control structures and primitive types. However, \nC++ and SELFmay not be sufficiently similar for such comparisons to be meaningful.  5 Conclusions We \nhave investigated the ability of three types of static analysis to improve C++ programs by resolving \nvirtual function calls, reducing compiled code size, and reduc-ing program complexity to improve both \nhuman and automated program understanding and analysis. We have shown that Rapid Type Analysis is highly \neffective for all of these purposes, and is also very fast. This combination of effectiveness and speed \nmake Rapid Type Analysis an excellent candidate for inclusion in production C++ compilers. RTA resolved \nan average of 71% of the virtual func-tion calls in our benchmarks, and ran at an average speed of 3300 \nnon-blank source lines per second. CHA resolved an average of 51% and UN resolved an aver-age of only \n15% of the virtual calls. CHA and RTA were essentially identical for reducing code size; UN is not designed \nto find dead code. RTA was significantly better than CHA at removing virtual call targets. Unique Name \nwas shown to be relatively ineffective, and can therefore not be recommended. Both RTA and CHA were quite \neffective. In some cases there was little difference, in other cases RTA performed substantially better. \nBecause the cost of RTA in both compile-time and implementation complexity is almost identical to that \nof CHA, RTA is clearly the best of the three algo-rithms. We have also shown, using dynamic traces, that \nthe best fast static analysis (RTA) often resolves all or al-most all of the virtual function calls (in \nfive out of the seven large benchmarks). For these programs, there is no advantage to be gained by using \nmore expensive sta-tic analysis algorithms like flow-sensitive type analysis or alias analysis. Since \nthese algorithms will invariably be at least one to two orders of magnitude more expen-sive than RTA, \nRTA should be used first to reduce the complexity of the program and to determine if there are significant \nnumbers of virtual call sites left to resolve. In some cases, this will allow the expensive analysis \nto be skipped altogether. Acknowledgements We thank Michael Burke? Susan Graham, and Jim Larus for their \nsupport of our work; Harini Srinivasan and G. Ramalingam for their assistance with the de-velopment of \nthe analyzer: Mark Wegman for his many helpful suggestions; Ravi Nair for the use of his &#38;race system, \nthe accompanying benchmarks, and for his tech- nical assistance; Vance Waddle for his NARC graph dis-play \nsystem; and Yong-Fong Lee and Mauricio Serrano for sharing their benchmark suite and their insights. \nWe thank Gerald Aigner, Urs Hclzle, Brad Calder, and Dirk Grunwald for helpful discussions and explanations \nof their work. We also thank Rob Cecco, Yee-Min Chee, Derek In-glis, Michael Karasick, Derek Lieber, \nMark Mendell, Lee Nackman, Jamie Schmeiser, and the other Montana team members for their invaluable assistance \nwith their prototype C++ compiler upon which our optimizer was built. Finally, we thank those who provided \nfeedback on earlier drafts of this paper: Michael Burke, Paul Carini, German Goldszmidt, Urs HiSlzle, \nMichael Karasick, Harini Srinivasan and Kenny Zadeck.  References AGESEN, 0. Constraint-based type inference \n PI and parametric polymorphism. In Proceedings of the First International Static Analysis Symposium \n(Namur, Belgium, Sept. 1994), B. Le Charlier, Ed., Springer-Verlag, pp. 78-100. AGESEN, O., AND H~LZLE, \nU. Type feedback PI vs. concrete type inference: A comparison of opti- mization techniques for object-oriented \nlanguages. In Proceedings of the 1995 ACM Conference on Object Oriented Programming Systems, Languages, \nand Applications (OOPSLA) (Austin, Texas, Oct. 1995), ACM Press, New York, New York, pp. 91- 107. AIGNER, \nG., AND H~LZLE, U. Eliminatingvirtual [31 function calls in C++ programs. In Proceedings of the Tenth \nEuropean Conference on Object-Oriented Programming -ECOOP 96 (Line, Austria, July 1996), vol. 1098 of \nLecture Notes in Computer Sci-ence, Springer-Verlag, pp. 142-166. BACON, D. F., WEGMAN, M., AND ZADECK, \nPI K. Rapid type analysis for C++. Tech. Rep. RC number pending, IBM Thomas J. Watson Research Center, \n1996.  BURKE, M., CARINI, P., CHOI, J.-D., AND HIND, r51 M. Flow-insensitive interprocedural alias \nanalysis in the presence of pointers. In Proceedings of the Seventh International Workshop on Languages \nand Compilers for Parallel Computing (Ithaca, New York, Aug. 1994), K. Pingali, U. Banerjee, D. Gel-ernter, \nA. Nicolau, and D. Padua, Eds., vol. 892 of Lecture Notes in Computer Science, Springer-Verlag, Berlin, \nGermany, pp. 234-250. CALDER, B., AND GRIJNWALD, D. Reducing in-direct function call overhead in C-t+ \nprograms. In Conference Record of the Twenty-First ACM Symposzum on Pranciples of Programmang Lan-guages \n(POPL) (Portland, Oregon, Jan. 1994), ACM Press, New York, New York, pp. 397-408.  CARINI, P., HIND, \nM., AND SRINIVASAN, H. Type [71 analysis algorithm for C++. Tech. Rep. RC 20267, IBM Thomas J. Watson \nResearch Center, 1995.  CHAMBERS, C., AND UNGAR, D. Iterative type PI analysis and extended message \nsplitting: optirniz-ing dynamically-typed object-oriented programs. LISP und Symbolic Computation 4, \n3 (July 1991), 283-310.  CHAMBERS, C., UNGAR, D., AND LEE, E. An PI efficient implementation of SELF, \na dynamically- typed object-oriented language based on proto- types. LISP and Symbolic Computation 4, \n3 (July 1991), 243-281.  CHOI, J.-D., BURKE, M., AND CARINI, P. Effi- PO1 cient flow-sensitive interprocedural \ncomputation of pointer-induced aliases and side effects. In Con-ference Record of the Twentieth ACM Symposium \non Principles of Programming Languages (POPL) (Charleston, South Carolina, Jan. 1993), ACM Press, New \nYork, New York, pp. 232-245.  DEAN, J., GROVE, D., AND CHAMBERS, C. Op- PI timization of object-oriented \nprograms using static class hierarchy analysis. In Proceedings of the Ninth European Conference on Object-Oriented \nProgram-ming -ECOOP 95 (Aarhus, Denmark, Aug. 1995), W. Olthoff, Ed., Springer-Verlag, pp. 77-101.  \nDIWAN, A., Moss, J. E. B., AND MCKINLEY, P21 K. S. Simple and effective analysis of statically-typed \nobject-oriented programs. Published in these proceedings, 1996. FERNANDEZ, M. F. Simple and effective \nlink-time D31 optimization of Modula-3 programs. In Proceed- ings of the SIGPLAN Conference on Programming \n Languuge Desrgn und Implementatzon (PLDI) (La Jolla, California, June 1995), ACM Press, New York, New \nYork, pp. 103-115. [!4] H~~LZLE, I;., CHAMBERS, C., AND UNGAR, D. Optimizing dynamically-types object-oriented \n[an-guages with polymorphic inline caches. In Pro-ceedings of the Eur0pea.n Conference on Oblect-Oraented \nProgramming -ECOOP 91 (Geneva, Switzerland, July 199lj, P. America, Ed., Springer-Verlag, pp. 21-38. \nj.151 LANDI, W., RYDER, B. G., AND ZHANG, S. In-terprocedural modification side effect analysis with \npointer aliasing. In Proceedings of the SIGPLAN Conference on PToymrnmzny hnguuge Desagn and Implem,entation \n(PLDI) (Albuquerque, New Mex-ico, June 1993j, ACM Press, New York, New York, pp. 56-67. [16] LEE, Y., \nAND SERRANO, M. J. Dynamic mea-surements of C++ program characteristics. Tech. Rep. ADTI-1995-001, LBM \nSanta Teresa Labora-tory, Jan. 1995. [l 71 OXHBJ, N., PALSBERG, J., AND SCHWARTZBACH, M. I. Making t,ype \ninference practical. In PTO- ceedings of the European Conference on Object-Oriented Programmzng -ECOOP \n9% (Utrecht, Netherlands, June 1992), 0. L. Madsen, Ed., Springer-Verlag, pp. 329-349. [18] PANDE, H. \nD., AND RYDER, B. G. Static type de-termination for C++. In Proceedings of the Sixth Usenix C++ Technical \nConference (Apr. 1994), pp. 85-97. [19] PANDE, H. D., AND RYDER, B. G. Data-flow-based virtual function \nresolution. In Proceed-ings of the International Static Analysis Sympo-sium (1996), Lecture Notes in \nComputer Science, Springer- Verlag [20] PLEVYAK, J., AND CHIEN, A. A. Precise con-crete type inference \nfor object-oriented languages. In Proceedings of the 1994 ACM Conference on Object Oriented Programming \nSystems, Languages, and Applications (OOPSLA) (Portland, OR, Oct. 1994), ACM Press, New York, New York, \npp. 324- 340. [21] PORAT, S., BERNSTEIN, D., FEDOROV, Y., AND RODRIGUE, J. Compiler optimizations of \nC++ vir-tual function calls. In Proceedings of the Second Conference on Object-Oriented Technologies \nand Systems (Toronto, Canada, June 1996), Usenix As-sociation, pp. 3-14. [22] SRIVASTAVA, A. Unreacha.ble \nprocedures in object- oriented programming. ACM Lettew on PTO-g7aamming Languages and Systems 1, 4 (December \n1992), 355-364. /23J TIP, F., CHOI, J.-D., FIELD, J., AND RAMA-LINGAM, G. Slicing class hierarchies in \nCt- +. Pub-lished in these proceedings, 1996. [24] UNGAR, D., SMITH, R. B., CHAMBERS, C., AND HOLZLE, \nU. Object, message, and performance: how they coexist in Self. Computer %5, 10 (Oct. 1992), 53-64. \n\t\t\t", "proc_id": "236337", "abstract": "Virtual functions make code easier for programmers to reuse but also make it harder for compilers to analyze. We investigate the ability of three static analysis algorithms to improve C++ programs by resolving virtual function calls, thereby reducing compiled code size and reducing program complexity so as to improve both human and automated program understanding and analysis. In measurements of seven programs of significant size (5000 to 20000 lines of code each) we found that on average the most precise of the three algorithms resolved 71% of the virtual function calls and reduced compiled code size by 25%. This algorithm is very fast: it analyzes 3300 source lines per second on an 80 MHz PowerPC 601. Because of its accuracy and speed, this algorithm is an excellent candidate for inclusion in production C++ compilers.", "authors": [{"name": "David F. Bacon", "author_profile_id": "81100628167", "affiliation": "IBM Watson Research Center, P.O. Box 704, Yorktown Heights, NY", "person_id": "P60470", "email_address": "", "orcid_id": ""}, {"name": "Peter F. Sweeney", "author_profile_id": "81332530743", "affiliation": "IBM Watson Research Center, P.O. Box 704, Yorktown Heights, NY", "person_id": "PP31096597", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/236337.236371", "year": "1996", "article_id": "236371", "conference": "OOPSLA", "title": "Fast static analysis of C++ virtual function calls", "url": "http://dl.acm.org/citation.cfm?id=236371"}