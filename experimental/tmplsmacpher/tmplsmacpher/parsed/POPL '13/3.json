{"article_publication_date": "01-23-2013", "fulltext": "\n Copatterns Programming In.nite Structures by Observations Andreas Abel Brigitte Pientka Anton Setzer \nDepartment of Computer Science, David Thibodeau * Computer Science, Ludwig-Maximilians-University Munich, \nSwansea University, Wales, UK School of Computer Science, Germany McGill University, Montreal, Canada \na.g.setzer@swan.ac.uk andreas.abel@i..lmu.de bpientka@cs.mcgill.ca Abstract Inductive datatypes provide \nmechanisms to de.ne .nite data such as .nite lists and trees via constructors and allow programmers to \nanalyze and manipulate .nite data via pattern matching. In this paper, we develop a dual approach for \nworking with in.nite data structures such as streams. In.nite data inhabits coinductive datatypes which \ndenote greatest .xpoints. Unlike .nite data which is de.ned by constructors we de.ne in.nite data by \nobservations. Dual to pattern matching, a tool for analyzing .nite data, we de\u00advelop the concept of copattern \nmatching, which allows us to syn\u00adthesize in.nite data. This leads to a symmetric language design where \npattern matching on .nite and in.nite data can be mixed. We present a core language for programming with \nin.nite struc\u00adtures by observations together with its operational semantics based on (co)pattern matching \nand describe coverage of copatterns. Our language naturally supports both call-by-name and call-by-value \ninterpretations and can be seamlessly integrated into existing lan\u00adguages like Haskell and ML. We prove \ntype soundness for our lan\u00adguage and sketch how copatterns open new directions for solving problems in \nthe interaction of coinductive and dependent types. Categories and Subject Descriptors D.3.3 [Programming \nLan\u00adguages]: Language Constructs and Features Data types and struc\u00adtures, Patterns, Recursion; F.3.3 \n[Logics and Meanings of Pro\u00adgrams]: Studies of Program Constructs Program and recursion schemes, Type \nstructure General Terms Languages, Theory Keywords Coinduction, Functional programming, Introduction \nvs. elimination, Message passing, Pattern matching * David Thibodeau acknowledges .nancial support by \nthe Graduiertenkol\u00adleg Programm und Modellanalyse (PUMA, 2008 ) of the Deutsche Forschungsgemeinschaft \n(DFG) and by the Undergraduate Student Re\u00adsearch Award (USRA) of the Natural Sciences and Engineering \nResearch Council of Canada (NSERC). Anton Setzer has been supported by EPSRC grant EP/G033374/1, Theory \nand applications of induction-recursion. Part of the work was done while the author was a visiting fellow \nof the Newton Institute, Cambridge. Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 13, January 23 25, 2013, Rome, Italy. Copyright c &#38;#169; 2013 \nACM 978-1-4503-1832-7/13/01. . . $10.00 1. Introduction Representing and reasoning about in.nite computation \nplays a cru\u00adcial role in our quest for designing and implementing safe soft\u00adware systems, since we often \nwant to establish behavioral proper\u00adties about our programs, reason about I/O interaction and processes, \nand establish liveness properties that eventually something good will happen. While .nite structures \nsuch as natural numbers or .\u00adnite lists are modelled by inductive types, in.nite structures such as streams \nor processes are elegantly characterized by coinductive types. Inductive types are now very well understood \nand supported by functional languages and proof assistants, whereas the theoreti\u00adcal foundations and \npractical tools for coinductive types lag behind. For example, in the Calculus of (Co)Inductive Constructions, \nthe core theory underlying Coq [INRIA 2010], coinduction is bro\u00adken, since computation does not preserve \ntypes [Gim\u00e9nez 1996; Oury 2008]. In Agda [2012], a dependently typed proof and pro\u00adgramming environment \nbased on Martin L\u00f6f type theory, inductive and coinductive types cannot be mixed in a compositional way. \nFor instance, one can encode the property in.nitely often from tem\u00adporal logic, but not its dual eventually \nforever [Altenkirch and Danielsson 2010]. Over the past decade there has been growing consensus [Set\u00adzer \n2012; McBride 2009; Granstr\u00f6m 2009] that one should distin\u00adguish between .nite, inductive data de.ned \nby constructors and in\u00ad.nite, coinductive data which is better described by observations. This view was \npioneered by Hagino [1987] who modeled .nite ob\u00adjects via initial algebras and in.nite objects via .nal \ncoalgebras in category theory. His development culminated in the design of symML, a version of ML where \none can declare codatatypes via a list of their destructors [Hagino 1989]. For example, the codatatype \nof streams is de.ned via the destructors head and tail which de\u00adscribe the observations we can make about \nstreams. Cockett and Fukushima [1992] took up his work and designed a language Char\u00adity where one programs \ndirectly with the morphisms of category theory. But while Charity was later extended with pattern match\u00ading \non (initial) data types [Tuckey 1997], no corresponding dual concept was developed for codatatypes (called \n.nal data types in Charity). In this paper, we take a .rst step towards building a type\u00adtheoretic foundation \nfor programming with in.nite structures via observations. Dual to pattern matching for analyzing .nite \ndata, we introduce copattern matching for manipulating in.nite data and describe coverage for copatterns. \nIn order to focus on the main concepts and avoid the additional complexities that come with dependent \ntypes, for instance, the need to guarantee termination or productivity, we con.ne ourselves to simple \ntypes in this article. Our theoretical treatment of patterns and copatterns takes in\u00adspiration from \nthe growing body of work which relates classical and linear logic to programming language theory via \nthe Curry\u00adHoward-Isomorphism; more precisely, we build on the duality be\u00adtween (.nite) values as right-hand \nside proof terms and continua\u00adtions or evaluation contexts as left-hand side terms of sequent cal\u00adculus \n[Curien and Herbelin 2000; Wadler 2005; Kimura and Tat\u00adsuta 2009]. Following Zeilberger s [2008b] deep \nanalysis of fo\u00adcused proofs in linear sequent calculus [Andreoli 1992] and its relationship to pattern \nmatching and evaluation order in program\u00adming languages, we distinguish between positive types which \nchar\u00adacterize .nite data and negative types which describe in.nite data. While values are matched against \npatterns, evaluation contexts are matched against copatterns. Our notion of copatterns extends pre\u00advious \nwork by Licata, Zeilberger, and Harper [2008] to treat least .xed-points as positive types and greatest \n.xed-point as negative types, and we recognize copatterns as a de.nition scheme for in.\u00adnite objects. \nMore precisely, we regard copatterns as experiments on black\u00adbox in.nite objects such as functions, streams \nand processes. In.\u00adnite objects can be de.ned by a .nite, covering set of observations, which are pairs \nof experiment (copattern) together with its outcome (de.ning term). We take the distinction between the \n.nite / initial / positive and the in.nite / .nal / negative serious and give intro\u00adduction rules and \npatterns for the former and elimination rules and copatterns for the latter. This leads to a core functional \nlanguage based on natural deduction instead of the sequent calculus formu\u00adlation explored in by Zeilberger \n[2008b] et al. [Licata et al. 2008]. Our contributions are the following: 1. We show how copatterns complement \nthe syntax of existing functional languages and enable a style of programming with in.nite objects by \nobservations (Section 2.2). There is no need to move to a different programming paradigm such as classi\u00adcal \nlogic [Curien and Herbelin 2000; Wadler 2003] or the mor\u00adphisms of category theory (Charity). 2. We \ndescribe a non-deterministic algorithm for checking copat\u00adtern coverage and prove that well-typed and \ncomplete programs do not go wrong (Section 5). The construction of a covering set of copatterns corresponds \nto the interactive construction of a program as in Agda and Epigram (Section 2.1). 3. We explain how \ncopatterns can be a fruitful paradigm in rewrit\u00ading and dependent type theory. In rewriting, de.nition \nby ob\u00adservations lead naturally to strongly normalizing rewrite rules and a semantics without in.nitary \nrewriting [Kennaway and de Vries 2003] (Section 2.3). In dependent type theory, they overcome the subject \nreduction problem of the Calculus of (Co)inductive Constructions [Gim\u00e9nez 1996] (Section 2.4).  The \nremainder of this article is structured as follows: We infor\u00admally describe copatterns in Section 2 and \nexplain in detail their bene.ts in programming, rewriting and type theory. In Section 3, we de.ne formally \nour core language with copatterns and its static semantics. We then describe its operational semantics \ntogether with copattern matching in Section 4. Coverage of copatterns together with the type safety proof \nis presented in Section 5. We brie.y de\u00adscribe a prototype implementation of copatterns for Agda in Sec\u00adtion \n6, before we conclude with a discussion of related work (Sec\u00adtion 7) and an outlook to further work (Section \n8). 2. Copatterns and Their Applications In this section we explain copatterns (Section 2.1) and .esh \nout the arguments started in the introduction. We illustrate how copat\u00adterns impact functional programming \n(Section 2.2), rewriting (Sec\u00adtion 2.3), and dependent type theory (Section 2.4). 2.1 From function \nde.nition to copatterns We introduce copatterns in the scenario of interactive program construction by \nre.ning the left hand side of a function de.nition step by step. As we will see, copatterns arise naturally \nas the generalization of de.nition by pattern matching. As an example, we construct the in.nite stream \nN, N - 1, . . . , 1, 0, N, N - 1, . . . , 1, 0, . . . of natural numbers via an auxiliary function cycleNats \n: Nat . Stream Nat such that cycleNats n = n, n - 1, . . . , 1, 0, N, N - 1, . . . , 1, 0, . . . . Before \nwe begin, let us de.ne Stream Nat as a recursive record type containing the possible observations we \ncan make about streams. These observations are also referred to as destructors, since they allow us to \ntake apart streams. record Stream A = { head : A, tail : Stream A }  Now we will construct cycleNats \nstep-by-step, similar to the interactive editing in Agda [Norell 2007] and Epigram [McBride and McKinna \n2004]. The starting point is the template: cycleNats : Nat . Stream Nat cycleNats = ? Since a function \nis an in.nite object, we de.ne it by observation rather than giving its value (a .-abstraction) directly. \nHowever, we cannot give a value of cycleNats n for every natural number n, instead, we apply cycleNats \nto a generic natural number, the pattern variable x. cycleNats x = ? Application to x, which we write \nas \u00b7 x, is our .rst instance of a copattern, an applicative copattern. It is, in this case, a generic \nex\u00adperiment on cycleNats. The observation of its outcome determines cycleNats. We are left with the task \nof constructing a Stream of natural numbers. We can make two principal experiments on a stream: we can \nobserve its head and its tail, and the outcome of these two experiments determines the stream. These \nexperiments give us two new copatterns: head \u00b7 and tail \u00b7, called destructor copatterns, and lead to \nthe next re.nement of our de.nition of cycleNats: head (cycleNats x) = ? tail (cycleNats x) = ? The \nobserved head of cycleNats x is just x. To determine the tail, we need to split on the pattern variable \nx: head (cycleNats x) = x tail (cycleNats 0) = ? tail (cycleNats (1 + x')) = ? This generalizes the \napplicative copattern form \u00b7 x to \u00b7 p where p is a pattern, as usual, a term built from constructors, \nliterals, and uniquely occurring variables only. We .nally can .ll the remaining two holes and complete \nour de.nition of cycleNats: head (cycleNats x) = x tail (cycleNats 0) = cycleNats N ' ' tail (cycleNats \n(1 + x)) = cycleNats x The in.nite object cycleNats, a function yielding streams, is de\u00ad.ned via the \ncomplete set of copatterns {head (\u00b7 x), tail (\u00b7 0), tail (\u00b7 (1 + x'))} where \u00b7, the hole, is a placeholder \nfor the function cycleNats. It is determined by the following set of observations, i. e., experiments \nmapped to their results: head (\u00b7 x) . x tail (\u00b7 0) . cycleNats N ' ' tail (\u00b7 (1 + x)) . cycleNats x \n 2.2 Copatterns in functional programming: Restoring a missing symmetry Destructor copatterns are a \nuseful addition to functional languages even if no coinduction is involved. In the following we evolve \nan implementation of the state monad typical for Haskell to demon\u00adstrate why the absence of general copatterns \nbreaks symmetry, and how copatterns restore it. A .rst implementation de.nes the type State S A of a \nstateful computation with result A just as a synonym for S . (A \u00d7 S). The monadic operations return and \n\u00bb= ( bind ) are given in an applicative style. State S A = S . A \u00d7 S return : A . State S A return a \ns = (a, s) _\u00bb=_ : State S A . (A . State S B) . State S B (m \u00bb= k) s = let (a, s ' ) = m s in k a s ' \nReturning a in state s yields the pair (a, s) of result and unchanged state, and executing the sequence \nm \u00bb= k in state s .rst executes m : State S A in state s, resulting in a value a : A and a new state \ns ', in which we run the continuation k applied to a. The code explains itself nicely if the application \nto s is read as in state s. There are reasons to move away from type synonym State S A to a bijection \nbetween the monadic type State S A and its im\u00adplementation as S . A \u00d7 S. For instance, in Haskell, type \nsyn\u00adonyms interact badly with type-class based overloading, and in\u00adstead, State S A is implemented as \na single-.eld record type with projection runState and constructor state. record State S A = state{runState \n: S . A \u00d7 S} runState : State S A . S . A \u00d7 S state : (S . A \u00d7 S) . State S A As we update our implementation \nof the monad operations, we are in for an unpleasant surprise: We can only partially keep up the applicative \nstyle, more precisely, only on the right hand side of =, the expression side. Here, we only have to pre.x \nthe monadic values m and k a with the projection runState. But on the left hand side, the pattern side, \nwe cannot do the same change, since projections are not allowed there. Instead we have to turn the l.h.s. \napplication to s to a r.h.s. .-abstraction over s, and pre.x it with constructor state. return : A . \nState S A return a = state (.s. (a, s)) _\u00bb=_ : State S A . (A . State S B) . State S B m \u00bb= k = state \n(.s. let (a, s ' ) = runState m s in runState (k a) s ' ) The projection bits are still nice to read, \ne. g., runState m s reads as run m in state s, however, the de.nition of m \u00bb= k as the stateful computation, \nthat if you pass it state s, . . . is a bit bumpy. The symmetry is broken. Copatterns, which allow projections \nalso on the l.h.s., restore the symmetry and allow a smooth de.nition of the monad operations again. \nreturn : A . State S A runState (return a) s = (a, s) _\u00bb=_ : State S A . (A . State S B) . State S B \n runState (m \u00bb= k) s = let (a, s ' ) = runState m s in runState (k a) s ' ) It reads if you run return \na in state s, you get (a, s); and to run m \u00bb= k in state s, run m in s, obtaining a value a and a new \nstate s ' in which you run k a. 2.3 Deep copatterns in rewriting: Strong normalization for corecursive \nde.nitions In the following we argue that copatterns help to integrate in.nite objects into term rewriting, \nwithout having to change the standard reduction semantics. A popular example of programming with in.nite \nobjects is the creation of the stream of Fibonacci numbers. It is concisely de.ned as .b = cons 0 (cons \n1 (zipWith _+_ .b (tail .b))) Herein, cons is the stream constructor, head and tail the projection, \nand zipWith _+_ yields a stream by applying addition pointwise to a pair of streams (here: .b and tail \n.b). Clearly, reading this equation as a rewrite rule, the computation of .b does not terminate under \nthe standard semantics, which is rewrite when the left hand side matches. Using in.nitary rewriting [Kennaway \nand de Vries 2003], .b converges to the Fibonacci stream cons 0 (cons 1 (cons 1 (cons 2 (cons 3 (cons \n5 . . . However, we are interested in the strong normalization of a term rewriting system since this \nyields a decision procedure for equality (which then implies decidability for checking dependent types). \nWe can revert to a non-standard rewriting semantics: label the de.nition of .b as corecursive and only \nunfold it when its value is demanded, e. g., by a projection. This solution, for instance taken in Coq \n[Gim\u00e9nez 1996], does not help with our particular de.nition of .b either, since tail .b appears in its \nown unfolding, leading to in.nite reduction. A workaround exists: we could introduce a mutually de.ned \nauxiliary stream .b ' which denotes the tail of .b. But copatterns provide a principled and scalable \nsolution. Me\u00adchanically, transforming the de.nition of .b into copatterns yields head .b = 0 head (tail \n.b) = 1 tail (tail .b) = zipWith _+_ .b (tail .b).  These equations are actually ful.lled by our .rst \nequation for .b, but now we take them as de.nition of .b. The rewrite system is terminating; neither \n.b nor tail .b can be reduced by itself because none of the three de.ning copatterns matches. Our syntax \nallows us to delay unfolding of corecursion until the whole copattern is matched. Copatterns, in particular, \ndeep copatterns such as nested projections tail (tail \u00b7) give us greater .exibility for corecursive de.nitions \nthan non-standard semantics. 2.4 Copatterns in dependent type theory: Reclaiming subject reduction Following \nthe lead of the functional programming language Haskell, the dependently typed language Coq introduces \nboth .nite and in\u00ad.nite trees via constructors. However, this leads to fundamental problems. For example, \nthe Calculus of (Co)Inductive Construc\u00adtions, the core theory underlying Coq [INRIA 2010], lacks sub\u00adject \nreduction. This issue is already described in Section 3.4 of Gim\u00e9nez thesis [1996]. Oury [2008] brought \nit back to the at\u00adtention of the community. A detailed analysis has been given by McBride [2009]. Let \nus recapitulate Oury s counterexample to subject reduction, as reproduced in Fig. 1: Given a coinductive \ntype U with construc\u00adtor in that takes just an argument of type U, the (extensionally) sole inhabitant \nu of U can be constructed as the .xed point of in. The de.nitions force and eq seem pointless [Chlipala \n2012, p. 91] U a codata type in : U . U its only (co)constructor u : U an inhabitant of U u = co.x in \nin.nite succession of ins force : U . U extensionally, an identity force = .x. case x of in y . in y \neq : (x : U) . x = force x eq = .x. case x of in y . re. equ : u = in u equ = eq u Figure 1. Oury s counterexample. \nbut are in fact a major tool in Coq proofs about corecursive de.\u00adnitions such as u since they wrap a \ncase-distinction around a co.x that triggers reduction: While unrestricted reduction of co.x f to f (co.x \nf) would diverge immediately, the following two rewrite equations for matching coinductive data maintain \nstrong normal\u00adization: case (in s) of in y . t = t[s/y] case (co.x f) of in y . t = case (f (co.x f)) \nof in y . t Now, the closed term eq u simpli.es via eq u = case u of in y . re. = case (co.x in) of in \ny . re. = case (in (co.x in)) of in y . re. = re. to the single constructor re. of propositional equality \n_=_ , which means that u and in u must be de.nitionally equal. Yet they are not, since u does not reduce \nto in u unless under a case distinc\u00adtion. Subject reduction is lost! As Gim\u00e9nez notes, subject reduc\u00adtion \nholds only modulo an undecidable equality on types that al\u00adlows unrestricted .xed-point unfolding, but \nthis is not what can be implemented in proof assistants for Intensional Type Theory with decidable type \nchecking. The culprit is that the rule for dependent matching is also avail\u00adable for coinductive data, \ni. e., in case of U we have the rule G f u : U G, y : U f t : C(in y) G f case u of in y . t : C(u) The \nrule substitutes a constructed term in y for term u in type C, which may trigger reduction of case expressions \nin C that are not possible without the substitution. For instance, force (in y) reduces to in y, while \nforce x does not reduce to x. This is exploited in the typing1 of eq, which leads to the loss of subject \nreduction in the end. The deeper reason for this dilemma is that coinduction is just understood as constructing \nin.nite trees; coinductive structures are just non-well-founded data structures in Coq. However, even \nin de\u00adpendent type theory, in.nite objects are better understood through their elimination rules [Granstr\u00f6m \n2009; Setzer 2012], i. e., obser\u00advations. Looking at Oury s example, it seems wrong to regard in as a \nconstructor. Rather, it should be de.ned in terms of the only 1 Since re. : in y = force (in y), by dependent \npattern matching case x of in y . re. : x = force x, thus, eq x : x = force x. observation out : U . \nU (same for the in.nite structure u : U): in : U . U u : U out (in y) = y out u = u The equations we \nhave written are now exactly the reduction rules, no restricted unfolding of co.x has to be taken into \nconsideration. This makes de.nitional equality and, thus, type checking more per\u00adspicuous, for the user \nit is a what-you-see-is-what-you-get equa\u00adtional theory. Dependent pattern matching on coinductive types \nU is no longer available and subject reduction is restored. The point\u00adless tricks like force and eq, \nnecessary to deal with edges of de\u00adpendent pattern matching, are also obsolete. While we do not develop \na dependently typed language with copatterns in this article, we have illustrated the shortcomings of \nuniformly modeling .nite and in.nite data via constructors and highlighted the potential of copatterns \nin the dependently typed setting. 3. A Core Functional Language with Copatterns In this section, we introduce \na core language with recursive data types for modeling .nite data and recursive record types2 for mod\u00adeling \nin.nite data. The term language is redex-free, which allows for a complete bidirectional type checking \nalgorithm. We then proceed to de.ne patterns and copatterns which allow us to de.ne functions, records \nand programs which can be type\u00adchecked by an extension of the algorithm. Function de.nitions will be \nmodeled as sets of rewrite rules. 3.1 Types We distinguish between positive types, 1, A \u00d7 B, and \u00b5X D, \nand negative types, A . B and . X R. This polarity assignment is inspired by focusing proofs in intuitionistic \nlinear logic [Andreoli 1992; Benton et al. 1993]. Our types 1, \u00d7, and \u00b5 correspond to the positive connectives \n1, ., and a combination of . and least .xed point, resp., and they classify .nite data. The types . and \n. correspond to the negative -and a combination of &#38; and greatest .xed point, resp., and classify \nin.nite data. Linearity will show up in the typing rules for patterns and copatterns, even though ordinary \nterms need not be linear. In terms of categorical languages [Hagino 1987; Cockett and Fukushima 1992], \npositive types are left objects or initial datatypes, and negative types are right objects or .nal datatypes. \nA, B, C ::= X Type variable | P Positive type | N Negative type P ::= 1 Unit type | A \u00d7 B Cartesian product \n| \u00b5X D Data type N ::= A . B Function type | . X R Record type D ::= (c1 A1 | \u00b7 \u00b7 \u00b7 | cn An) Variant \n(labeled sum) R ::= {d1 : A1, . . . , dn : An} Record (labeled product) Figure 2. Types. Figure 2 introduces \npositive types P , negative types N, and types A which can be either positive or negative. Variants D \nserve 2 Our terminology should not be confused with recursive records in object\u00adoriented language foundations, \ne. g., by Abadi and Cardelli [1994]. to construct possibly recursive data types \u00b5X D, and records R \nlist the .elds di of a possibly recursive record type . X R. In our non-polymorphic calculus, type variables \nX only serve to construct recursive data types and recursive record types. As usual, \u00b5X D (. X R, resp.) \nbinds type variable X in D (R, resp.). Capture-avoiding substitution of type C for variable X in type \nA is denoted by A[C/X ]. The set FTV(A) of free type variables of a type expression A is de.ned in the \nstandard way. A type is well\u00adformed if it has no free type variables; in the following, we assume that \nall types are well-formed. Datatypes Datatypes C = \u00b5X D for D = (c1 A1 | \u00b7 \u00b7 \u00b7 | cn An)are recursive \nvariant types. They could be called algebraic types. We write Dci for Ai. The constructor ci of C takes \nan arguments of type Ai[C/X ], i. e., Dci [C/X ]. Non-recursive data types can be represented by a void \n\u00b5-abstraction \u00b5_D. Like in SML, a con\u00adstructor that requires no argument formally takes an argument of \nthe unit type 1. Examples: List A = \u00b5X (nil 1 | cons (A \u00d7 X)) Nat = \u00b5X (zero 1 | suc X) Maybe A = \u00b5_ \n(nothing 1 | just A) 0 = \u00b5_ () (positive empty type) Record types Record types C = . X R with R = {d1 \n: A1, . . . , dn : An} are recursive labeled products. They could be called coalgebraic types. The destructor \ndi, if applied to a record of type C, returns the ith .eld which has type Ai[C/X ], or, with a Rd notation, \nRdi [C/X ]. The destructors are applied in post.x notation to a term t as t.di. As for data, non-recursive \nrecord types are encoded by a void .-abstraction ._R. Examples: Stream A = . X {head : A, tail : X} Colist \nA = . X {out : \u00b5_ (nil 1 | cons (A \u00d7 X))} Vector A = ._{length : Nat, elems : List A} T = ._{} (negative \nunit type) Both D and R can be seen as .nite maps from a set of labels (constructors and destructors, \nresp.) to types, with application writ\u00adten Dc and Rd. We write c . D and d . R to express that a label \nis in the domain of the corresponding .nite map. In this article, both \u00b5X D and . X R are just recursive \ntypes rather than inductive and coinductive types resp. Since D and R are not checked for functoriality \nand programs are not checked for termination or productivity, resp., there are no conditions that ensure \n\u00b5X D to be a least .xed-point inhabited only by .nite data, and . X R to be a greatest .xed-point that \nhosts in.nite objects which are productive. However, we keep the notational distinction to allude to \nthe intended interpretation as least and greatest .xed\u00adpoints in a total setting.  3.2 Terms and typing \nNext we describe terms which constitute the targets of our rewrite rules. Terms are given by the following \ngrammar: e, t, u ::= f De.ned symbol (e.g. function) | x Variable | () Unit (empty tuple) | (t1, t2) \nPair | c t Constructor application | t1 t2 Application | t.d Destructor application Terms can be identi.ers \n(variable x, de.ned symbol f ), introduc\u00adtions (tuple (), (t1, t2), constructed term c t) of positive \ntypes (1, A\u00d7B, \u00b5X D), or eliminations (application t1 t2, projection t.d) of negative types (A . B, . \nX R). Constructor applications choose a variant and fold the recursive type; destructor applications \nunfold the recursive type and select a component of the record. Missing, by intention, are eliminations \nfor positive types like tuple projec\u00adtions and case; these are replaced by pattern matching. Dually, \nwe omit introductions for negative types, such as .-abstractions and record values; instead we have de.nitions \nby copattern matching (see 3.4). . f t : A In context ., term t can be assigned type A. .(x) = A TVar \nTFun TUnit . f x : A . f f : S(f ) . f () : 1 . f t : Dc[\u00b5X D/X ] . f t : .X R TConst TDest . f c t : \n\u00b5X D . f t.d : Rd[. X R/X ] . f t1 : A1 . A2 . f t2 : A1 TApp . f t1 t2 : A2 . f t1 : A1 . f t2 : A2 \nTPair . f (t1, t2) : A1 \u00d7 A2 Figure 3. Typing rules for terms. Typing Contexts G and . denote .nite \nmaps from term variables to well-formed types. To ensure linearity in pattern typing, we write ., . ' \nfor the disjoint union of .nite maps . and . ', i. e., dom(.) n dom(. ' ) = \u00d8. We write \u00b7 or simply nothing \nfor a .nite map with empty domain, and we usually drop the braces when giving a context explicitly as \nset of pairs {x1 : A1, . . . , xn : An}. We assume a global signature S which maps de.ned symbols f to \ntheir type. The rules for the typing judgement . f t : A are given in Figure 3. Note that, since we have \nno binder on the term level no ., in particular , . remains .xed in all the rules. Assumptions in . describe \nthe type of pattern variables occurring on the left hand side of a rule and are synthesized when analyzing \ncopatterns. For each term constructor there is exactly one typing rule, so we trivially obtain the usual \ninversion lemmata. In the following, whenever we have a judgement J (e.g. a typing judgement), we write \nD :: J to indicate that D is a derivation of J using the rules for J. Usually our proof proceeds by \ninduction on a derivation of our judgement and we write in this case by induction on D . Some of our \njudgements are algorithmic, i. e., partial functional relations. Unless stated otherwise, all arguments \nto these relations are inputs. Bidirectional Type Checking Our language naturally supports overloading \nof constructors and destructors, when employing a bidirectional type checking algorithm [Pierce and Turner \n1998]. Supporting overloading is convenient in practice and leads to el\u00adegant, compact and readable code. \nWith bidirectional checking, overloading comes for free since a constructor c gets its meaning in the \ncontext of a data type to type check a constructed term c t we push its type \u00b5X D in. Dually, a destructor \nd only has a meaning in the context of a record type . X R, which is inferred from head t in the projection \nterm t.d. Overloading projections is standard in object-oriented programming (here, projections corre\u00adspond \nto method calls), and has contributed to the success of the OO paradigm. Constructor overloading is also \nemerging, e. g., in the dependently typed languages Agda [Norell 2007] and Epigram [McBride and McKinna \n2004]. Given a typing context ., we infer the type A of identi.ers and eliminations (judgement . f t \n. A), while we check introductions against a given type A (judgement . f t . A). The . f t . A In context \n., the type of term t is inferred as A. .(x) = A TCFun TCVar . f f . S(f) . f x . A . f t1 . A1 . A2 \n. f t2 . A1 TCApp . f t1 t2 . A2 . f t . . X R TCDest . f t.d . Rd[. X R/X ] . f t . A In context ., \nterm t checks against type A. . f t . Dc[\u00b5X D/X ] . f t . A A = C TCSwitch TCConstr . f t . C . f c t \n. \u00b5X D . f t1 . A1 . f t2 . A2 TCUnit TCPair . f () . 1 . f (t1, t2) . A1 \u00d7 A2 Figure 4. Type-checking \nrules for terms. rules are given in Figure 4. Type checking is trivially sound, but it is also complete \nwithout the need for any additional type annotations. TH EO R E M 1 (Soundness of type checking). 1. \nIf D :: . f t . A then . f t : A. 2. If D :: . f t . A then . f t : A.  Proof. Simultaneously by induction \non the derivation D. D For simply-typed lambda-calculus, bidirectional type checking is not complete \nand typically requires type annotations. It fails for redexes (.xt) u, since the type of a . is not inferred. \nIn our case, since for a type we have either introduction or elimination, we lack the usual redexes, \nthus, bidirectional type checking is actually complete. TH EO R E M 2 (Completeness of type checking). \nIf D :: . f t : A then . f t . A, and if A is a negative type, then . f t . A. Proof. By induction on \nD. Note that a proof of . f t . A is suf.cient, since this trivially implies . f t . A by TCSwitch. D \n 3.3 Patterns and copatterns The driving force behind computation in our language is pattern and copattern \nmatching. Pattern matching allows us to compensate for the missing eliminations for positive types, while \ncopattern matching compensates for the missing introductions for negative types. In the following, we \npresent (co)patterns and their typing. Patterns p ::= ||| x () (p1, pc p 2) Variable pattern Unit pattern \nPair pattern Constructor pattern Copatterns q ::= || \u00b7 q p q.d Hole Application copattern Destructor \ncopattern The post.x application of a projection d in q.d corresponds to the pre.x application d q we \nused in the introduction, to conform with Haskell and Agda syntax. Note that, in contrast to convention \nin the ML dialects, projection does not bind stronger than application, i. e., f x .d is to be read (f \nx).d. Our style saves parentheses when writing nested copatterns. Pattern typing is de.ned in Figure \n5. It computes a context . containing all the variables in the pattern. A (co)pattern p (or q) must be \nlinear, that is, each variable in . appears exactly once in p (or q, resp.). Again, there are two modes \nfor pattern typing. The checking mode, denoted by . f p . A, works on patterns p and follows the checking \nmode for regular typing. The inference mode, denoted by . | A f q . C works on copatterns q and additionally \ncomputes its type C from the given type A of the hole. . f p . A Pattern p checks against type A, yielding \n.. . f p . Dc[\u00b5X D/X ] PCVar PCConst x : A f x . A . f c p . \u00b5X D .1 f p1 . A1 .2 f p2 . A2 PCUnit PCPair \nf () . 1 .1, .2 f (p1, p2) . A1 \u00d7 A2 Copattern q eliminates given type A into . | A f q . C inferred \ntype C, yielding context .. . | A f q . . X R PCHead PCDest \u00b7 | A f \u00b7 . A . | A f q.d . Rd[. X R/X ] \n.1 | A f q . B . C .2 f p . B PCApp .1, .2 | A f q p . C Figure 5. Type checking for patterns and rewrite \nrules. Again, there is a one-to-one connection between pattern con\u00adstructors and pattern typing rules. \nA standard inversion lemma holds for all rules in Figure 5. 3.4 Programs A program P ::= (S, Rules) \nconsists of a signature S mapping de.ned symbols f to their types and a collection Rules of rewrite rules. \nFor each symbol f de.ned in the signature, Rules(f) gives the rewrite rules for f as a set of pairs (q \n. e), called observations, which de.ne the behavior of f. We require a dedicated symbol main . S, called \nthe entry point, that determines the value of a program. Execution of a program means rewriting main \nwith the Rules until no more rewriting is possible. The informal syntax used in the introduction can \nbe mechani\u00adcally transformed into programs of form P. For instance, the def\u00adinition .b of the stream \nof Fibonacci numbers corresponds to the following entries in S and Rules. S(.b) = . X {head : \u00b5Y (zero \n1 | suc Y ) , tail : X} 8 9 < \u00b7 .head . zero () = Rules(.b) = \u00b7 .tail .head . suc (zero ()) : ; \u00b7 .tail \n.tail . zipWith _+_ .b (.b .tail) A complete program needs also entries for zipWith and _+_, and a symbol \nmain. The type of main should be positive, otherwise the result of the program is an unprintable in.nite \nobject. Here, main could be a function listing the .rst 42 elements of the Fibonacci stream we leave \nthe details to the imagination of the reader. A program P is well-typed if f P as given in Figure 6, \nwhich in essence says that any rule (q . u) for any de.ned symbol f must be well-typed. A .rst result, \nproven in the next section, is that during the execution of a well-typed program we never encounter a \nterm which is ill-typed. 4. Evaluation and Type Preservation In this section, we de.ne program evaluation \nin terms of a small\u00adstep reduction relation. To decide whether a rewrite rule can .re, f q[f] . u Check \nrewrite rule. . | S(f) f q . C . f u . C TCRule f q[f] . u f P Check program. main . S .f . S, (q . u) \n. Rules(f). f q[f] . u TCPrg f (S, Rules) Figure 6. Well-typed rules and programs. we match evaluation \ncontexts against copatterns. We prove that reduction preserves types. 4.1 Evaluation contexts Evaluation \ncontexts E are elimination terms with a hole in head position. They generalize copatterns q in that they \nallow arbitrary terms e instead of just patterns p in argument positions. E ::= \u00b7 Hole | E e Application \n| E.d Projection The hole \u00b7 can be considered as a special variable. We write E[t] as shorthand for \nE[t/\u00b7]. Typing . | A f E : C for evaluation context E is de.ned in Figure 7. This judgement holds iff \n., x : A f E[x] : C for a fresh variable x . .. Well-typed evaluation contexts compose. LEMM A 3 (Composition \nof contexts). If D :: G | A f E1 : B and E :: G | B f E2 : C, then G | A f E2[E1[\u00b7]] : C. In context \n., evaluation context E eliminates . | A f E : C type A into type C. G | A f E : .X R ETHead ETDest G \n| A f \u00b7 : A G | A f E.d : Rd[. X R/X ] G | A f E : B . C G f e : B ETApp G | A f E e : C Figure 7. Typing \nrules for evaluation context. 4.2 Pattern matching Matching a term t against a pattern p, if successful, \nyields a sub\u00adstitution s such that p[s] = t. Pattern matching is de.ned in terms of a judgement t = ? \np s whose rules appear in Figure 8. Herein, a substitution s is a .nite map from variables to terms; \nwe write \u00b7 for the empty map, t/x for the singleton mapping x to t and s, s ' for the disjoint union \nof two maps s and s '. Substitu\u00ad tion typing G f s : . simply means that for all x . ., we have G f s(x) \n: .(x). While matching patterns p is standard, matching copatterns q is straightforward as well. The \nhole \u00b7 serves as anchor and in an implementation it seems wise to match inside-out , i. e., start at \nthe hole and proceed outwards.  4.3 Reduction and type preservation The only source of computation in \nour language is a de.ned func\u00adtion symbol f in an evaluation context E that matches the copattern t = \n? p s Term t matches with pattern p under substitution s. t = ? p s PMVar PMConstr t = ? x t/x c t = \n? c p s t1 = ? p1 s1 t2 = ? p2 s2 PMUnit PMPair () =? () \u00b7 (t1, t2) =? (p1, p2) s1, s2 Evaluation context \nE matches copattern q re- E = ? q s turning substitution s. E = ? q s PMHead PMDest \u00b7 = ? \u00b7 \u00b7 E.d = ? \nq.d s ? ? p s ' E = q s t = PMApp E t = ? q p s, s ' Figure 8. Rules for pattern matching. q of one \nof the rules (q . u) . Rules(f). Such an e = E[f] is a redex which can be contracted to another expression \ne ', written e . e ' . The precise rule for contraction is: E = ? q s (q . u) . Rules(f) E[f ] . u[s] \n One step reduction e -. e ' is de.ned as the compatible closure of contraction, i. e., e reduces to \ne ' if e ' results from contraction of one redex in e. We omit the standard inductive de.nition of e \n-. e ' . Our .rst major result is that reduction preserves types. We assume a well-typed program, i. \ne. all rewrite rules are well-typed. TH E O R E M 4 (Subject reduction). If G f e : A and e -. e ' then \nG f e ' : A Subject reduction is a consequence of the following statements: Substitution preserves types, \n(co)pattern matching yields a well\u00adtyped substitution, and contraction preserves types. LEM M A 5 (Substitution). \nIf D :: . f u : C and E :: G f s : . then F :: G f u[s] : C for some F. Proof. By induction on D. D LEM \nM A 6 (Adequacy of pattern matching). If D :: . f p . A and E :: G f e : A and F :: e = ? p s then G \nf s : .. Proof. By induction on F. D LEM M A 7 (Adequacy of copattern matching). If D :: . | A f q . \nC and E :: G | A f E : B and F :: E = ? q s then C = B and G f s : .. Proof. By induction on F. D LEM \nM A 8 (Correctness of contraction). If G | S(f) f E : C and f q[f] . u and E = ? q s then G f u[s] : \nC. Proof. By assumption, we have D1 D2 D :: . | S(f) f q . B . f u . B f q[f] . u since it is the only \nrule that could have been used. By Lemma 7, using D1 and both assumptions we have that C = B and G f \ns : .. Then, by Substitution (Lemma 5) and D2, we conclude that G f u[s] : C. D Finally, the subject \nreduction theorem follows: Proof of Theorem 4. By induction on the reduction relation, with contraction \nbeing the only interesting case: E = ? q s G f E[f] : B and (q . u) . Rules(f) E[f] . u[s] By well-typedness \nf q[f] . u, we obtain from Lemma 8 that G f u[s] : B. D 5. Copattern Coverage and Progress A fundamental \nproperty of strongly typed languages is type sound\u00adness; in the words of Milner [1978] well-typed programs \ndo not go wrong . This means that well-typed programs either produce a value or run forever, but never \nget stuck by encountering an invalid operation, like adding a function to a string or calling a number \nas one would call a function. For our language, there are three reasons why a program is stuck, i. e., \nno reduction step is possible yet we have not reached a printable value: 1. Missing rule. We might have \nde.ned a function f : Nat . A but only given a rewrite rule f zero . . . . . In this case, f (suc n) \nis stuck. In this section, we give rules for copattern coverage that ensure no rewrite rules are forgotten. \n 2. Ill-typed term. The term f nil is stuck even if we have given a complete implementation of f : Nat \n. A. However, ill-typed terms like f nil are already excluded by type checking and the type preservation \ntheorem. 3. In.nite object. The term f does not evaluate by itself; it is an un\u00adderapplied function. \nHowever, just as the typical interpreter, we consider terms of negative types as values. As a consequence, \nour notion of value is not syntactic, but type-dependent.  As main technical result of this section \nand the article, we prove type soundness, syntactically [Wright and Felleisen 1994], by showing the progress \ntheorem for a call-by-value strategy. 5.1 Values and evaluation contexts Values are de.ned using a new \njudgment . fv e : A to mean that the expression e is a value of type A under the context .. We also use \nv to denote an expression which acts as a value. Whether an expression is considered a value or not depends \nalso on its type, in particular, each expression of negative type N is considered a value the rules are \ngiven in Figure 9. . fv e : A In context ., e is a value of type A. G fv v : Dc[\u00b5XD/X] G f x : A VVar \nVConst G fv x : A G fv c v : \u00b5XD G fv v1 : A1 G fv v2 : A2 VUnit VPair G fv () : 1 G fv (v1, v2) : A1 \n\u00d7 A2 G f e : N VNeg G fv e : N Figure 9. Rules for values. LEMMA 9 (Inversion for values). The following \nhold for v = x. 1. If G fv v : 1 then v = (). 2. If G fv v : A1 \u00d7 A2 then v = (v1, v2), G fv v1 : A1 \nand G fv v2 : A2. 3. If G fv v : \u00b5XD then v = c v ' for some c . D and G f v ' : Dc[\u00b5XD/X].  We dualize \nthe notion of value for terms to evaluation contexts, introducing a judgement . | A fv E : C (see Figure \n10). It accepts those well-typed evaluation contexts E that have values in all argument positions. The \nidea is that if E is long enough , i. e., if C is a positive type, then E[f] is a redex because one of \nthe de.ning copatterns for f has to match E. This would not necessary be the case if the arguments in \nE were not values. E is an evaluation context with only values in . | A fv E : C application arguments. \nG | A fv E : .XR EVHead EVDest G | A fv \u00b7 : A G | A fv E.d : Rd[.XR/X] G | A fv E : B . C G fv v : B \nEVApp G | A fv E v : C Figure 10. Rules for value evaluation contexts. The following two propositions \nenable us to analyze non-empty value evaluation contexts from the inside out; they will be used in Theorem \n12. LEMMA 10 (Splitting a function evaluation context). If D :: G | B . C fv E : A and E = \u00b7 then E = \nE ' [\u00b7 v] with G fv v : B and G | C fv : A. E ' Proof. By induction on D. D LEMMA 11 (Splitting a record \nevaluation context). E ' G | Rd[.XR/X] fv : A. If D :: G | .XR fv E : A and E = \u00b7 then E = [\u00b7.d] with \nE ' Proof. By induction on D. D 5.2 Coverage Figure 11 de.nes a judgment to indicate that a list of \ncopatterns covers all eliminations of a given type A. The judgment is A < | (. f q . C) or, more generally, \nA < | Q where Q = (.i f qi . Ci)i=1,...,n is a set of non-overlapping copatterns qi with their type Ci \nand context .i, each satisfying .i | A f qi . Ci. The rules to construct a covering set of copatterns \nare not syntax-directed. To check whether a given set of copatterns Q for a type A is complete, we non-deterministically \nguess the derivation of A < | Q , if it exists. Although this NP-algorithm is not the best we can do, \nwe are con.dent that we can adopt existing ef.cient coverage algorithms [Norell 2007] for our language. \nThe initial covering is given by the axiom CHole. We can re.ne a covering Q by focusing on one copattern \nQ and either split the result of negative type or split one of its variables of positive type. Result \nsplitting at function type B . C applies the copattern q to a fresh variable x : B, at record type .XR \nwe take all projections (q.d)d.R. Splitting a variable x replaces it by unit (), a pair (x1, x2) or all \npossible constructors (c x ' )c.D, in accordance with the type 1, A1 \u00d7 A2, or \u00b5XD of the variable. Let \nus revisit the example of the function cycleNats from the introduction and walk through the rules for \ncoverage. With the following shorthands for types Nat = \u00b5X (zero 1 | suc X) StreamNat = .X{head : Nat, \ntail : X},  A < | QQ Typed copatterns QQcover elimination of type A. Result splitting: A < | QQ(. f \nq . B . C) CAppCHole A < | (\u00b7 f \u00b7 . A) A < | QQ(., x : B f q x . C) A < | QQ(. f q . . X R) CDest A \n< | QQ(. f q.d . Rd[. X R/X ])d.R Variable splitting: A < | QQ(., x : 1 f q . C) CUnit A < | QQ(. f q[()/x] \n. C) A < | QQ(., x : A1 \u00d7 A2 f q . C) CPair A < | QQ(., x1 : A1, x2 : A2 f q[(x1, x2)/x] . C) A < | QQ(., \nx : \u00b5X D f q . C) CConst A < | QQ(., x ' : Dc[\u00b5X D/X ] f q[c x ' /x] . C)c.D Figure 11. Rules for copattern \ncoverage. the signature entries for cycleNats are the following: S(cycleNats) = Nat . StreamNat 8 9 < \n\u00b7 x .head . x = Rules(cycleNats) = \u00b7 (zero ()) .tail . cycleNats N : ; \u00b7 (suc x) .tail . cycleNats x \nTo check coverage, we start with the trivial covering and succes\u00adsively apply the rules until we obtain \nthe copatterns of cycleNats. Since A = Nat . StreamNat stays .xed throughout the deriva\u00adtion, we omit \nit and just write the copattern list QQ. We start with CHole. (\u00b7 f \u00b7 . Nat . StreamNat) We apply x to \nthe hole by CApp. (x : Nat f \u00b7 x . StreamNat). Then we split the result by CDest. (x : Nat f \u00b7 x .head \n. Nat) (x : Nat f \u00b7 x .tail . StreamNat)  In the second copattern we split x via CConst, reusing the \nvariable name x. (x : Nat f \u00b7 x .head . Nat) (x : 1 f \u00b7 (zero x) .tail . StreamNat) (x : Nat f \u00b7 (suc \nx) .tail . StreamNat).  Finally, we apply CUnit, replacing x by (). (x : Nat f \u00b7 x .head . Nat) (\u00b7 f \n\u00b7 (zero ()) .tail . StreamNat)  (x : Nat f \u00b7 (suc x) .tail . StreamNat)  The lists of copatterns Qq \nfor type A generated by the splitting rules is complete in the sense that every closed value context \nE eliminating A into a positive type P actually matches one of the copatterns qi. TH EO R E M 12 (Matching \nwith a covering copattern). If D :: \u00b7 | A fv E : P and E :: A < | (.i f qi . Ci)i=1..n, then there are \nE1, E2 such that E = E1[E2[\u00b7]], E2 = ? qi s for some i, \u00b7 | A fv E2 : Ci and \u00b7 | Ci fv E1 : P . To prove \nthis theorem, we use the following statements. LEM M A 13 (Splitting a pattern variable). Let D :: ., \nx : A | B f q . C and E :: | B fv E : C and F :: E = ? q s. 1. Assume A = A1 \u00d7 A2 and let q ' = q[(x1, \nx2)/x]. Then ' ? ' s ' with s = s ' [x . (s ' (x1), s ' (x2))]. ., x1 : A1, x2 : A2 | B f q . C and E \n= q 2. Assume A = \u00b5X D and let q ' = q[c x ' /x] for some c . D. ' ' ? ' Then ., x : Dc[\u00b5X D/X ] f q \n. C and E = q s ' with s = s ' [x . c s ' (x ' )]. 3. Assume A = 1 and let q ' = q[()/x]. Then . f q \n' . C and ? ' s ' E = q with s = s ' [x . ()]. Proof. First, prove an adaptation of these statements \nfor patterns p and values v instead of copatterns q and evaluation contexts E. Then, prove this lemma \nby induction on F. D Proof of Theorem 12. The theorem is proved by induction on the coverage derivation \nE. The variable splitting cases CPair , CConst, and CUnit follow from Lemma 13. We consider the rules \nfor result splitting. A < | QQ(. f q . B . C) Case E :: A < | QQ(., x : B f q x . C)i=1,...,n  By induction \nhypothesis, the statement holds for one of the patterns in QQ(. f q . B . C). If the pattern has been \nchosen from QQ, we are done. Thus, without loss of generality, E = E1[E2[\u00b7]] and \u00b7 | A fv E2 : B . C \nand \u00b7 | B . C fv E1 : P and E2 = ? q s. If E1 = \u00b7 then P = B . C, which is a contradiction since P is \na positive type. If E1 = \u00b7, then E1 = E1 ' [\u00b7 v] with \u00b7 fv v : B and \u00b7 | C fv E1 ' : P by Lemma 10. Thus, \nlet E2 ' = E2 v and \u00b7 | A fv E2 ' : C by EVApp, and E2 ' = ? q x s, v/x by PMApp. A < | QQ(. f q . .X \nR) Case E :: A < | QQ(. f q.d . Rd[.X R/X ])d.R  Analogously, using Lemma 11. D 5.3 Progress We are \nready to show that evaluation of a well-typed program does not get stuck, provided that all de.nitions \ncome with a complete set of observations. First we note that closed terms are either values or eliminations \nof a de.ned symbols. Such an elimination is either a value evaluation context or contains a closed non-value. \nLEM M A 14 (Decomposition). If \u00b7 f e : A then either 1. e = (), A = 1, 2. e = (e1, e2), A = A1 \u00d7 A2, \n 3. e = c e ' , A = \u00b5X D, 4. e = E2[E1[f] e ' ] where \u00b7 | S(f) fv E1 : B . C and \u00b7 | C f E2 : A and \nfv e ' : B for some f, some evaluation contexts E1, E2, some term e ' and some types B, C . 5. e = E[f] \nfor some f, E with \u00b7 | S(f) fv E : A.  Proof. By induction on e. We only show the cases e = e1 e2 and \ne = e ' .d. The other cases are trivial. Case f e1 e2 : A. Then by inversion f e1 : B . A and f e2 : \nB. By induction hypothesis e1 = E[f] with \u00b7 | S(f) fv E : B . A for some f, E or e1 = E2[E1[f] e ' ] \nfor some f, E1, E2, ' '' and e where \u00b7 | S(f) fv E1 : B ' . C , \u00b7 | C f E2 : B . A and fv e ' : B ', \nas the 3 other cases are impossible. In the former case, if fv e2 : B, we can obtain case 4 by letting \nE2 = \u00b7, E = E1 and e2 = e '. This gives us e1 e2 = \u00b7[E[f ] e2]. If fv e2 : B, then, by EVApp, \u00b7 | S(f) \nfv E[f] e2 : A and E ' = E e2. In ' = E ' ' the latter case, we have E2[E1[f] e ] e2 2[E1[f] e ] by setting \nE2 ' = E2 e2. Case f e.d : A. Then by inversion, f e : . X R for some R. By induction hypothesis, e = \nE[f] and \u00b7 | S(f) fv E : . X R, or e = E2[E1[f] e ' ] where e ' is not a value. In the former case, e.d \n= E[f ].d = E ' [f] and \u00b7 | S(f) fv E .d : Rd[. X R/X ] by EVDest. Otherwise, e.d = E2[E1[f] e ' ].d \n= E2 ' [E1[f ] e ' ]. D Finally we prove progress under the assumption that every def\u00adinition f is complete, \nwritten S(f) < | Rules(f). TH EO R E M 15 (Progress). If D :: f e : A then either fv e : A or e -. e \n' for some e ' . Proof. The proof is done by induction on e. By Lemma 14, we have .ve possible cases. \nSince the four .rst cases follow by a simple induction argument, we only present the last case. Here \ne = E[f ] and \u00b7 | S(f) fv E : A. If A is negative, then e is already considered a value and we are done. \nOtherwise, since by assumption S(f) < | Rules(f), we can apply Theorem 12 and obtain E1, E2 such that \nE = E1[E2[\u00b7]], E2 = ? qi s for some qi . Rules(f), plus \u00b7 | S(f) f E2 : Ci and \u00b7 |Ci fv E1 : A. Thus, \nby our reduction rules E2[f] . ui[s] where (qi, ui) . Rules(f) and so E2[f] . ui[s]. We conclude that \nE1[E2[f]] . E1[ui[s]]. D 6. Extensions and Implementations Our core language misses introduction rules \nfor functions and ob\u00adjects, thus, we do not have lambda abstractions or record expres\u00adsions. However, \nwe can embed sets of behaviors {Qq . Qu} into the expression syntax and obtain anonymous objects that \nsubsume . abstractions, SML s anonymous functions de.ned by pattern matching, and record expressions: \n.xt = {\u00b7 x . t} j . fn nil . false \u00b7 nil . false = | cons x xs . true \u00b7 (cons x xs) . true j . \u00b7.fst \n. t1 record{fst = t1; snd = t2} = \u00b7.snd . t2 Of course, bidirectional type checking is no longer complete \nsince anonymous objects can only be checked against a given type, but can appear in elimination position. \nCopatterns have been added to the development version3 of Agda [Agda team 2012]. Currently, projection \ncopatterns are not part of the core of Agda, they are parsed but then translated into record expressions. \nThis does not give the full .exibility of copat\u00adterns, but allows us to experiment with them. Full copatterns \nin the core would allow us to exploit the bene.ts of deep projection co\u00adpatterns and mixed projection/application \ncopatterns, but for that, Agda s coverage checker has to be extended to copatterns. To ac\u00adcomplish this, \nfurther research is required, because dependent pat\u00adtern matching is a far from trivial enterprise [Coquand \n1992; Sch\u00fcr\u00admann and Pfenning 2003; Goguen et al. 2006; Norell 2007; Dun\u00ad.eld and Pientka 2009]. Another \nprototypical implementation of copatterns exists in MiniAgda [Abel 2012]. In MiniAgda, one can certify \ntermination and productivity using sized types [Hughes et al. 1996; Barthe et al. 2004; Abel 2007]. Copatterns \nprovide the right syntax to decorate corecursive de.nitions with size variables that witness productivity. \n3 Available from the darcs repository http://code.haskell.org/Agda. 7. Related Work Our work builds \non the insight that .nite datatypes correspond to initial algebras and in.nite datatypes correspond to \n.nal co\u00adalgebras. This was .rst observed by Hagino [1989] and was the ba\u00adsis of categorical programming \nlanguages such as symML [Hagino 1987] and Charity [Cockett and Fukushima 1992]. Categorical pro\u00adgramming \nlanguages typically support programming with the mor\u00adphisms of category theory; while they do provide \niteration, they do not support general recursion and pattern matching. In Charity, sup\u00adport for pattern \nmatching on data types was added [Tuckey 1997], but it lacks support for copattern matching. Our type \ntheoretic development of copatterns exploits the dual\u00adity of positive and negative types which is well \nknown in focused proofs [Andreoli 1992]. Previously, focusing has been applied to pattern matching [Zeilberger \n2008a; Krishnaswami 2009] and eval\u00aduation order [Zeilberger 2009; Curien and Herbelin 2000]. Clos\u00adest \nto our work from a theoretical point of view is the work by Licata, Zeilberger and Harper [2008] where \na language based on the sequent calculus is described which supports mixing LF types with computation-level \ntypes. The weak representational function space of LF is classi.ed as a positive connective and admits \npat\u00adtern matching using constructor patterns; the strong computation level function space is classi.ed \nas negative connective which is de.ned by destructor patterns. The accompanying technical report also \ndescribes brie.y how to add .-formulas to the proposed sys\u00adtem. However, in their work, (co)pattern matching \nhappens at the meta level; this is like replacing induction by an .-rule. Our work provides an object-level \nsyntax for copatterns and an algorithm for copattern coverage. Kimura and Tatsuta [2009] extend Wadler \ns [2003] Dual Cal\u00adculus to inductive and coinductive types, treating the constructor for inductive data \nas value constructor and the destructor for coin\u00adductive data as continuation constructor. However, they \ndo not in\u00adtroduce recursive values or recursive continuations nor pattern and copattern matching, but \nallow only iteration over .nite data and coiteration into in.nite data. Agda, in its currently released \nversion 2.3.0, already avoids Coq s subject reduction problem. In.nite objects are created via delay \nr and analyzed via force b, the corresponding operation on types is lifting 8. In spirit, this approach \nmimics the standard trick in call-by-value languages such as ML and Scheme to encode lazy values by suspensions, \ni. e., functions over the unit type. The two\u00adedged dependent pattern matching on in.nite objects is ruled \nout, since one cannot match on functions. Agda s coinduction is informally described by Danielsson and \nAltenkirch [2010], but it lacks solid theoretical backing. Indeed, compositionality is lost, because \nany data type that uses lifting is coinductive [Altenkirch and Danielsson 2010]. For instance, a data \ntype of trees with in.nite branching realized via streams host automatically in.nitely deep trees, even \nif that is not expressed by the data type de.nition. Our work reinterpretes lifting as the generation \nof a mutual recursive record type that contributes the coinductive part to the data type. Forcing is \ninterpreted as destructor and delaying as a mutual de.nition by destructor pattern. This way, we provide \na standard semantics for coinduction in Agda and recover compositional construction of data types. 8. \nConclusion In this paper, we have presented a type-safe foundation for pro\u00adgramming with in.nite structures \nvia observations. We model .nite data using variant types and in.nite data via record types. Pattern \nmatching of .nite data is extended with its dual notion of copattern matching on in.nite data. While \nwe do not consider termination and productivity in this paper, we guarantee that the functions are covering, \ni.e., they are de.ned on all possible inputs. Copatterns lay a foundation for .nitary rewriting with \nin.nite objects. They are also an excellent candidate for representing core\u00adcursive de.nitions in type-theoretic \nproof assistants such as Coq and dependently typed languages like Agda. In the future, we plan to extend \nthe presented work to full dependent types. There are two main theoretical issues we need to tackle: \n.rst, extension of copattern coverage to dependent types, and secondly, checking termination and productivity \nof functions to guarantee strong normalization. A candidate for the latter task are sized types [Hughes \net al. 1996; Barthe et al. 2004; Abel 2007] as already implemented in MiniAgda [Abel 2012]. Further, \nwe aim at developing a denotational model for languages with copatterns. It seems that semantics based \non orthogonality [Parigot 1997; Vouillon and Melli\u00e8s 2004] provides a good starting point for this investigation. \nFrom a practical point of view, we plan to fully integrate copat\u00adterns into Agda for a perspicuous and \nrobust foundation of coin\u00adduction. Acknowledgments The .rst author thanks Thierry Coquand and Nils Anders \nDaniels\u00adson for email exchange about copatterns and the regular partici\u00adpants of the Agda Implementor \ns Meetings from 2008 on for lively discussions on copatterns and the best way to integrate coinduction \ninto Agda. During an invitation to McGill University by the second author, much of the theory of copatterns \nwas already worked out. He is also grateful towards Tarmo Uustalu and James Chapman for an invitation \nto the Institute for Cybernetics in Tallinn in November 2011. During that visit, the implementation of \ncopatterns for Agda began. We also thank Jacques Carette and the anonymous referees for suggestions to \nimprove this paper. References M. Abadi and L. Cardelli. A theory of primitive objects. Untyped and .rst\u00adorder \nsystems. In M. Hagiya and J. Mitchell, editors, Theoretical Aspects of Computer Software, volume 789 \nof Lect. Notes in Comput. Sci., pages 296 320. Springer, 1994. A. Abel. Mixed inductive/coinductive types \nand strong normalization. In Z. Shao, editor, Proc. of the 5th Asian Symp. on Programming Lan\u00adguages \nand Systems, APLAS 2007, volume 4807 of Lect. Notes in Com\u00adput. Sci., pages 286 301. Springer, 2007. \nISBN 978-3-540-76636-0. A. Abel. Type-based termination, in.ationary .xed-points, and mixed inductive-coinductive \ntypes. Electr. Proc. in Theor. Comp. Sci., 77:1 11, 2012. Proceedings of FICS 2012. Agda team. The Agda \nWiki, 2012. T. Altenkirch and N. A. Danielsson. Termination checking in the presence of nested inductive \nand coinductive types. Short note supporting a talk given at PAR 2010, Workshop on Partiality and Recursion \nin Interactive Theorem Provers, FLoC 2010, 2010. J.-M. Andreoli. Logic programming with focusing proofs \nin linear logic. Journal of Logic and Computation, 2(3):297 347, 1992. G. Barthe, M. J. Frade, E. Gim\u00e9nez, \nL. Pinto, and T. Uustalu. Type-based termination of recursive de.nitions. Math. Struct. in Comput. Sci., \n14 (1):97 141, 2004. N. Benton, G. M. Bierman, V. de Paiva, and M. Hyland. A term calculus for intuitionistic \nlinear logic. In M. Bezem and J. F. Groote, editors, Proc. of the 1st Int. Conf. on Typed Lambda Calculi \nand Applications, TLCA 93, volume 664 of Lect. Notes in Comput. Sci., pages 75 90. Springer, 1993. ISBN \n3-540-56517-5. A. Chlipala. Certi.ed Programming with Dependent Types. MIT Press, June 2012. Unpublished \ndraft. R. Cockett and T. Fukushima. About charity. Technical report, Department of Computer Science, \nThe University of Calgary, June 1992. Yellow Series Report No. 92/480/18. T. Coquand. Pattern matching \nwith dependent types. In B. Nordstr\u00f6m, K. Pettersson, and G. Plotkin, editors, Types for Proofs and Programs \n(TYPES 92), B\u00e5stad, Sweden, pages 71 83, 1992. T. Coquand. In.nite objects in type theory. In H. Barendregt \nand T. Nipkow, editors, Types for Proofs and Programs (TYPES 93), volume 806 of Lect. Notes in Comput. \nSci., pages 62 78. Springer, 1993. P.-L. Curien and H. Herbelin. The duality of computation. In Proc. \nof the 5th ACM SIGPLAN Int. Conf. on Functional Programming (ICFP 2000), SIGPLAN Notices 35(9), pages \n233 243. ACM Press, 2000. ISBN 1\u00ad58113-202-6. N. A. Danielsson and T. Altenkirch. Subtyping, declaratively. \nIn C. Bolduc, J. Desharnais, and B. Ktari, editors, Proc. of the 10th Int. Conf. on Mathematics of Program \nConstruction, MPC 2010, volume 6120 of Lect. Notes in Comput. Sci., pages 100 118. Springer, 2010. ISBN \n978\u00ad3-642-13320-6. J. Dun.eld and B. Pientka. Case analysis of higher-order data. Electr. Notes in Theor. \nComp. Sci., 228:69 84, 2009. E. Gim\u00e9nez. Un Calcul de Constructions In.nies et son application a la v\u00e9ri.cation \nde syst\u00e8mes communicants. PhD thesis, Ecole Normale Sup\u00e9rieure de Lyon, Dec. 1996. Th\u00e8se d universit\u00e9. \nH. Goguen, C. McBride, and J. McKinna. Eliminating dependent pattern matching. In K. Futatsugi, J.-P. \nJouannaud, and J. Meseguer, editors, Algebra, Meaning, and Computation, Essays Dedicated to Joseph A. \nGoguen on the Occasion of His 65th Birthday, volume 4060 of Lect. Notes in Comput. Sci., pages 521 540. \nSpringer, 2006. ISBN 3-540\u00ad35462-X. J. Granstr\u00f6m. Reference and Computation in Intuitionistic Type Theory. \nPhD thesis, Mathematical Logic, Uppsala University, 2009. T. Hagino. A typed lambda calculus with categorical \ntype constructors. In D. H. Pitt, A. Poign\u00e9, and D. E. Rydeheard, editors, Category Theory and Computer \nScience, volume 283 of Lect. Notes in Comput. Sci., pages 140 157. Springer, 1987. T. Hagino. Codatatypes \nin ML. J. Symb. Logic, 8(6):629 650, 1989. J. Hughes, L. Pareto, and A. Sabry. Proving the correctness \nof reactive systems using sized types. In Proc. of the 23rd ACM Symp. on Principles of Programming Languages, \nPOPL 96, pages 410 423, 1996. INRIA. The Coq Proof Assistant Reference Manual. INRIA, version 8.3 edition, \n2010. J. Kennaway and F. de Vries. In.nitary Rewriting, volume 55 of Cambridge Tracts in Theoretical \nComputer Science, chapter Chapter 12 in Term Rewriting Systems, pages 668 711. Cambridge University Press, \n2003. D. Kimura and M. Tatsuta. Dual calculus with inductive and coinductive types. In R. Treinen, editor, \nRewriting Techniques and Applications (RTA 2009), Bras\u00edlia, Brazil, volume 5595 of Lect. Notes in Comput. \nSci., pages 224 238. Springer, 2009. ISBN 978-3-642-02347-7. N. R. Krishnaswami. Focusing on pattern \nmatching. In Z. Shao and B. C. Pierce, editors, Proc. of the 36th ACM Symp. on Principles of Programming \nLanguages, POPL 2009, pages 366 378. ACM Press, 2009. ISBN 978-1-60558-379-2. D. R. Licata, N. Zeilberger, \nand R. Harper. Focusing on binding and com\u00adputation. In F. Pfenning, editor, Proc. of the 23nd IEEE Symp. \non Logic in Computer Science (LICS 2008), pages 241 252. IEEE Computer Soc. Press, 2008. ISBN 978-0-7695-3183-0. \nLong version available as Tech\u00adnical Report CMU-CS-08-101. C. McBride. Let s see how things unfold: Reconciling \nthe in.nite with the intensional. In A. Kurz, M. Lenisa, and A. Tarlecki, editors, 3rd Int. Conf. on \nAlgebra and Coalgebra in Computer Science, CALCO 2009, volume 5728 of Lect. Notes in Comput. Sci., pages \n113 126. Springer, 2009. ISBN 978-3-642-03740-5. C. McBride and J. McKinna. The view from the left. J. \nFunc. Program., 14 (1):69 111, 2004. R. Milner. A theory of type polymorphism in programming. J. Comput. \nSyst. Sci., 17:348 375, Aug. 1978. U. Norell. Towards a Practical Programming Language Based on De\u00adpendent \nType Theory. PhD thesis, Dept of Comput. Sci. and Engrg., Chalmers, G\u00f6teborg, Sweden, Sept. 2007. N. \nOury. Coinductive types and type preservation. Message on the coq-club mailing list, June 2008. M. Parigot. \nProofs of strong normalization for second order classical natural deduction. J. Symb. Logic, 62(4):1461 \n1479, 1997. B. C. Pierce and D. N. Turner. Local type inference. In Proc. of the 25th ACM Symp. on Principles \nof Programming Languages, POPL 98, San Diego, California, 1998. C. Sch\u00fcrmann and F. Pfenning. A coverage \nchecking algorithm for LF. In D. Basin and B. Wolff, editors, Proceedings of the 16th International Conference \non Theorem Proving in Higher Order Logics (TPHOLs 2003), volume 2758 of Lect. Notes in Comput. Sci., \npages 120 135, Rome, Italy, September 2003. Springer. A. Setzer. Coalgebras as types determined by their \nelimination rules. In P. Dybjer, S. Lindstr\u00f6m, E. Palmgren, and G. Sundholm, editors, Epis\u00adtemology versus \nontology: Essays on the foundations of mathematics in honour of Per Martin-L\u00f6f. Springer, 2012. To appear. \nC. Tuckey. Pattern matching in Charity. Master s thesis, The University of Calgary, July 1997. J. Vouillon \nand P.-A. Melli\u00e8s. Semantic types: A fresh look at the ideal model for types. In N. D. Jones and X. Leroy, \neditors, Proc. of the 31st ACM Symp. on Principles of Programming Languages, POPL 2004, pages 52 63. \nACM Press, 2004. ISBN 1-58113-729-X. P. Wadler. Call-by-value is dual to call-by-name. In C. Runciman \nand O. Shivers, editors, Proc. of the 8th ACM SIGPLAN Int. Conf. on Func\u00adtional Programming (ICFP 2003), \npages 189 201. ACM Press, 2003. ISBN 1-58113-756-7. P. Wadler. Call-by-value is dual to call-by-name \n-reloaded. In J. Giesl, editor, Rewriting Techniques and Applications (RTA 2005), Nara, Japan, volume \n3467 of Lect. Notes in Comput. Sci., pages 185 203. Springer, 2005. ISBN 3-540-25596-6. A. K. Wright \nand M. Felleisen. A syntactic approach to type soundness. Information and Computation, 115(1):38 94, \n1994. N. Zeilberger. Focusing and higher-order abstract syntax. In G. C. Necula and P. Wadler, editors, \nProc. of the 35th ACM Symp. on Principles of Programming Languages, POPL 2008, pages 359 369. ACM Press, \n2008a. ISBN 978-1-59593-689-9. N. Zeilberger. On the unity of duality. Ann. Pure Appl. Logic, 153(1-3): \n66 96, 2008b. N. Zeilberger. The Logical Basis of Evaluation Order and Pattern-Matching. PhD thesis, \nCarnegie Mellon University, 2009. A. Agda Examples The development version of Agda has experimental support \nfor copatterns which can be turned on by option --copatterns. In the following we present a few examples \nfor copatterns in Agda syntax. Colists Colists have a coinductive type with an embedded variant type. \nIn Agda this is represented as mutual recursion between a coinductive record type and a data type. mutual \ndata \u00b5Colist (A : Set) : Set where [] : \u00b5Colist A _::_ : (x : A) (xs : .Colist A) . \u00b5Colist A record \n.Colist (A : Set) : Set where coinductive .eld out : \u00b5Colist A open .Colist Our .rst function lets us \nappend a .Colist to a List. It is de.ned by recursion on the list. open import Data.List using (List; \n[ ]; _::_; map; concatMap) append : {A : Set} . List A . .Colist A . .Colist A out (append [ ] ys) = \nout ys out (append (x :: xs) ys) = x :: append xs ys Note the overloading of constructor _::_ for lists \nand colists. We can also de.ne a zipWith function for colists de.ned as a pair of mutually recursive \nfunctions. One is acting on .Colist, the other acting on \u00b5Colist. mutual zipWith : {A B C : Set} . (A \n. B . C) . .Colist A . .Colist B . .Colist C out (zipWith f xs ys) = zipWith\u00b5 f (out xs) (out ys) zipWith\u00b5 \n: {A B C : Set} . (A . B . C) . \u00b5Colist A . \u00b5Colist B . \u00b5Colist C zipWith\u00b5 f [ ] ys = [] zipWith\u00b5 f (x \n:: xs)[] = [] zipWith\u00b5 f (x :: xs) (y :: ys) = (f x y) :: (zipWith f xs ys) Another example is an unfold \nfunction. Suppose we have a set of states S and a set of values A corresponding to the observation we \ndo at some particular state. Then, given a function taking a current state and outputting a new state \nand its value, or no state at all if it is a terminal state, and given an initial state, we can build \na colist of values of all states visited. open import Data.Maybe using (Maybe; nothing; just) open import \nData.Product using (_\u00d7_; , ) mutual unfold : {A S : Set} . (S . Maybe (A \u00d7 S)) . S . .Colist A out (unfold \nf s) = unfold\u00b5 f (f s) unfold\u00b5 : {A S : Set} . (S . Maybe (A \u00d7 S)) . Maybe (A \u00d7 S) . \u00b5Colist A unfold\u00b5 \nf (just (a, s)) = a :: unfold f s unfold\u00b5 f nothing = []  Breadth-.rst traversal of non-wellfounded \ntree Finitely branch\u00ading but potentially in.nite deep trees can be represented by a coin\u00adductive record \nwith two .elds, a label and a list subs of subtrees. record .Tree (A : Set) : Set where coinductive .eld \nlabel : A subs : List (.Tree A) open .Tree  If we have a forest List (.Tree A), we can extract the \nlabels in a breadth-.rst manner by .rst taking all the roots, then concatenating all the subtrees and \nrecurse. To ensure productivity, we distinguish the empty forest from the non-empty forest. bf : {A : \nSet} . List (.Tree A) . .Colist A out (bf [ ]) = [ ] out (bf (t :: ts)) = label t :: append (map label \nts) (bf (concatMap subs (t :: ts))) bf is productive since it is guarded-by-constructors [Coquand 1993]: \nit directly outputs either the empty colist or the non-empty colist, and since append xs ys only adds \nelements in front of ys. The latter is not yet tracked by Agda s termination and productivity checker, \nthus, the termination checker rejects this code. Productiv\u00adity checking using sized types, as realized \nin MiniAgda, does work for bf, and it is our goal to bring coinduction in Agda to the same level of expressiveness \nas in MiniAgda.    \n\t\t\t", "proc_id": "2429069", "abstract": "<p>Inductive datatypes provide mechanisms to define finite data such as finite lists and trees via constructors and allow programmers to analyze and manipulate finite data via pattern matching. In this paper, we develop a dual approach for working with infinite data structures such as streams. Infinite data inhabits coinductive datatypes which denote greatest fixpoints. Unlike finite data which is defined by constructors we define infinite data by observations. Dual to pattern matching, a tool for analyzing finite data, we develop the concept of copattern matching, which allows us to synthesize infinite data. This leads to a symmetric language design where pattern matching on finite and infinite data can be mixed.</p> <p>We present a core language for programming with infinite structures by observations together with its operational semantics based on (co)pattern matching and describe coverage of copatterns. Our language naturally supports both call-by-name and call-by-value interpretations and can be seamlessly integrated into existing languages like Haskell and ML. We prove type soundness for our language and sketch how copatterns open new directions for solving problems in the interaction of coinductive and dependent types.</p>", "authors": [{"name": "Andreas Abel", "author_profile_id": "81100320357", "affiliation": "Ludwig-Maximilians-University, Munich, Germany", "person_id": "P3977908", "email_address": "andreas.abel@ifi.lmu.de", "orcid_id": ""}, {"name": "Brigitte Pientka", "author_profile_id": "81100506891", "affiliation": "McGill University, Montreal, PQ, Canada", "person_id": "P3977909", "email_address": "bpientka@cs.mcgill.ca", "orcid_id": ""}, {"name": "David Thibodeau", "author_profile_id": "81553141656", "affiliation": "McGill University, Montreal, PQ, Canada", "person_id": "P3977910", "email_address": "david.thibodeau@mail.mcgill.ca", "orcid_id": ""}, {"name": "Anton Setzer", "author_profile_id": "81100376506", "affiliation": "Swansea University, Swansea, Wales Uk", "person_id": "P3977911", "email_address": "a.g.setzer@swan.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429075", "year": "2013", "article_id": "2429075", "conference": "POPL", "title": "Copatterns: programming infinite structures by observations", "url": "http://dl.acm.org/citation.cfm?id=2429075"}