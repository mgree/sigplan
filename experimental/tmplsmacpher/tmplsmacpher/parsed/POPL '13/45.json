{"article_publication_date": "01-23-2013", "fulltext": "\n Automatic Detection of Floating-Point Exceptions Earl T. Barr Thanh Vo Vu Le Zhendong Su Department \nof Computer Science, University of California at Davis {etbarr, vo, vmle, su}@ucdavis.edu Abstract It \nis well-known that .oating-point exceptions can be disastrous and writing exception-free numerical programs \nis very dif.cult. Thus, it is important to automatically detect such errors. In this paper, we present \nAriadne, a practical symbolic execution system speci.cally designed and implemented for detecting .oating-point \nexceptions. Ariadne systematically transforms a numerical program to explicitly check each exception \ntriggering condition. Ariadne symbolically executes the transformed program using real arithmetic to \n.nd candidate real-valued inputs that can reach and trigger an exception. Ariadne converts each candidate \ninput into a .oating-point number, then tests it against the original program. In general, approximating \n.oating-point arithmetic with real arithmetic can change paths from feasible to infeasible and vice versa. \nThe key insight of this work is that, for the problem of detecting .oating-point exceptions, this approximation \nworks well in practice because, if one input reaches an exception, many are likely to, and at least one \nof them will do so over both .oating-point and real arithmetic. To realize Ariadne, we also devised a \nnovel, practical linearization technique to solve nonlinear constraints. We extensively evaluated Ariadne \nover 467 scalar functions in the widely used GNU Scienti.c Library (GSL). Our results show that Ariadne \nis practical and identi.es a large number of real runtime exceptions in GSL. The GSL developers con.rmed \nour preliminary .ndings and look forward to Ariadne s public release, which we plan to do in the near \nfuture. Categories and Subject Descriptors D.2.3 [Software Engineer\u00ading]: Coding Tools and Techniques; \nD.2.4 [Software Engineering]: Software/Program Veri.cation Reliability, Validation; D.2.5 [Software \nEngineering]: Testing and Debugging Symbolic exe\u00adcution; F.3.1 [Logics and Meanings of Programs]: Specifying \nand Verifying and Reasoning about Programs General Terms Algorithms, Languages, Reliability, Veri.cation \nKeywords Floating-point exceptions; symbolic execution 1. Introduction On June 4, 1996, the European \nSpace Agency s Ariane 5 rocket veered off course and self-destructed because the assignment of a .oating-point \nnumber to an integer caused an over.ow [40]. The loss is estimated to have been US$370 million. Scienti.c \nresults increasingly rest on software that is usually numeric and Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 13, January 23 25, 2013, Rome, Italy. \nCopyright &#38;#169; 2013 ACM 978-1-4503-1832-7/13/01. . . $10.00 may invalidate results when buggy \n[33]. In February 2010, Toyota implicated control software in its spate of brake failures [3]. Haptic \ncontrollers are being used for remote surgery [36]. Numerical software, which uses .oating-point arithmetic, \nis prominent in critical control systems in devices in national defense, transportation, and health care. \nClearly, we are increasingly reliant on it. Floating-point numbers are a .nite precision encoding of \nreal numbers. Floating-point operations are not closed and may throw exceptions: their result may have \nan absolute value greater than the largest .oating-point number and over.ow; it may be nonzero and smaller \nthan the smallest nonzero .oating-point number and under.ow; or it may lie between two .oating-point \nnumbers, require rounding, and be inexact. Dividing-by-zero and the invalid appli\u00adcation of an operation \nto operands outside its domain, like taking the square root of a negative number, also generate exceptions. \nThe IEEE 754 standard de.nes these exceptions [24]. Writing numerical software that does not throw .oating-point \nexceptions is dif.cult [19, 22]. For example, it is easy to imagine writing if (x != y){ z = 1 / (x-y); \n} and then later con\u00adtending with the program mysteriously failing due to a spurious Divide-by-Zero [19]. \nAs another example, consider a straightfor\u00ad ward implementation to compute the 2-norm of a vector [22, \n23]: sum = 0; for (i = 0; i < N; i++) sum = sum + x[i] x[i]; * norm = sqrt(sum); For many slightly large \nor small vector components, this code may over.ow or under.ow when evaluating x[i]*x[i] or adding the \nresult to sum. In spite of exceptions during its computation, the norm itself may, nonetheless, be representable \nas an unexceptional .oating-point number. Even when some exceptions are caught and handled, others may \nnot be; these are uncaught exceptions. The Divide-by-Zero in the .rst example is an uncaught exception. \nSymbolic analysis has been successfully used to test and validate software [7, 18, 38]. However, little \nwork has considered symbolic analysis of .oating-point code, although much work has pursued formalizing \nIEEE .oating-point standards in various proof systems such as Coq, HOL, and PVS. One natural approach \nis to equip a satis.ability modulo theory (SMT) solver with a theory for .oating\u00adpoint. This has proved \nto be a challenging problem; ongoing efforts simplify and deviate from the IEEE .oating-point standard \n[37]. For detecting .oating-point exceptions, our core insight is that, if an exception can occur at \na particular operation, then that exception de.nes a neighborhood in which exception-triggering inputs \nare numerous. If one of these inputs triggers the exception over the reals, then another is likely to \ndo so over .oating-point arithmetic. Guided by this insight, we propose to symbolically execute a numeric \nprogram over the reals to search for an exception-triggering input. To this end, we transform a numeric \nprogram to explicitly check the operands of each .oating-point operation before executing it. If a check \nfails, the transformed program signals the .oating\u00adpoint exception that would have occurred if the guarded \noperation had executed, then terminates. In the transformed program, the constraints are over real, not \n.oating-point numbers, so we can directly feed them into an SMT solver equipped with the theory of reals, \nsuch as Microsoft s Z3 [9]. If we can reach any of these injected program points, we can query the SMT \nsolver for an input that triggers that exception. This input is unlikely to be a .oating\u00adpoint number, \nso we search the neighborhood of that input for a candidate .oating point number that also triggers the \nexception over real arithmetic. To undo the inaccuracy of symbolic execution over the reals, we then \ntest that candidate against the original program, concretely executed over .oating-point arithmetic. \n Our approach, which we have christened Ariadne, automatically detects .oating-point exceptions. While \nnot all exceptions are bugs, the utility of Ariadne rests on three observations: 1) over-and under\u00ad.ows \ncan be disastrous, as the loss of the Ariane 5 demonstrates; 2) the GSL developers con.rmed as bugs several \nof the exceptions Ariadne found; and 3) Invalid and Divide-by-Zero exceptions are likely to be bugs. \nAriadne reports only real exceptions: when it reports inputs that cause a program to throw a particular \n.oating\u00adpoint exception, that program run on those inputs will certainly throw that exception. When Ariadne \n.nds an exception, developers can use the inputs to .x the bug and to construct a test case to add to \ntheir test suite. To realize Ariadne, we extended the symbolic execution engine KLEE [7] to use Z3 (version \n3.1) as its SMT solver instead of STP [16], which does not support the theory of reals. Interesting numeric \ncode often results in multivariate, nonlinear constraints. In particular, the constraints we encountered \nwhile analyzing the GNU Scienti.c Library, were usually multivariate and nonlinear (Section 5). We fed \nthese constraints to iSAT, the state of the art non\u00ad linear SMT solver [13], but it only handled less \nthan 1%, rejecting most of our constraints because they contain large constant values that exceed iSAT \ns bounds. We also directly gave them to Z3, which had recently added support for multivariate, nonlinear \nconstraints but it could only handle a small percentage. These results motivated us to devise a novel, \npractical method for handling nonlinear con\u00adstraints involving rational functions (to support division), \nwhich we also incorporated into KLEE; this method works effectively over the constraints arising in our \nproblem setting. A new algorithm for solving nonlinear constraints, realized in a prototype called nlsat, \nwas developed concurrently with our work and added to Z3 [25]. We ran nlsat on 10, 000 of our constraints, \nuniformly selected at random, and compared its performance to that of our solver, Z3-AR I A DN E (Section \n5). Z 3 -A R I AD N E resolved 9,119 of the constraints (5,510 being satis.able), while nlsat resolved \n5,248 of the constraints, and returned unknown, timed out, or had parse errors on the rest. Our contributions \nfollow: The insight that, for the problem of detecting .oating-point ex\u00adceptions, real arithmetic can \neffectively model .oating-point arithmetic, since when one input triggers a .oating-point excep\u00adtion, \nmany are likely to do so and, of those, some will do so over both real and .oating-point arithmetic; \n An LLVM and KLEE-based implementation of our technique and its evaluation on the GNU Scienti.c Library \n(GSL);  A tool that automatically converts .xed precision numeric code into arbitrary precision numeric \ncode to detect potentially avoidable over.ows and under.ows; and  A practical method for handling nonlinear \nconstraints involving rational functions over the reals.  We evaluated our tool on the GNU Scienti.c \nLibrary (GSL) version 1.14. We analyzed all functions in the GSL that take scalar inputs, which include \nelementary and many differential equation 1 double av1(double x, double y) { 2 return (x+y)/2.0; 3 } \n 5 double av2(double x, double y) { 6 return x/2.0 + y/2.0; 7 } 9 double av3(double x,double y) { 10 \nreturn x + (y-x)/2.0; 11 } 13 double av4(double x, double y) { 14 return y + (x-y)/2.0; 15 } 17 double \naverage(double x, double y) { 18 int samesign; 19 if ( x >= 0 ) { 20 if (y >=0) 21 samesign = 1; 22 \nelse 23 samesign = 0; 24 } else { 25 if (y >= 0) 26 samesign = 0; 27 else 28 samesign = 1; 29 } 30 \nif ( samesign ) { 31 if ( y >= x) 32 return av3(x,y); 33 else 34 return av4(x,y); 35 } else 36 return \nav1(x,y); 37 } Figure 1: Sterbenz average function. functions. Across the 467 functions we analyzed, \nour tool discovered inputs that generated 2091 .oating-point exceptions. 91.9% of these are Under.ows \nand Over.ows, while the remainder are Divide-by-Zero and Invalid exceptions. Some of these exceptions \nare highly nontrivial, as a particular Divide-by-Zero we describe in detail in Section 5.2 illustrates. \nWe reported preliminary results to the GSL community; they con.rmed that our warnings were valid and \nlook forward to the public release of our tool. These results show that modeling .oating-point numbers \nas reals to .nd exceptions is a sweet spot in the trade-off between practicality and precision. To motivate \nand clarify our problem, Section 2 presents and explains numerical code that contains .oating-point exceptions. \nWe open Section 3 with terminology, then describe the two transfor\u00ad mations on which Ariadne rests: the \n.rst rei.es the exceptions a .oating-point operation may throw into program points and the second symbolically \nhandles external functions. We close Section 3 with the algorithms we use to solve multivariate, nonlinear \ncon\u00adstraints. Section 4 describes the realization of Ariadne. In Section 5, we present the results of \nanalyzing the GSL special functions with Ariadne. We discuss closely related work in Section 6 and conclude \nin Section 7. 2. Illustrative Example Floating-point arithmetic is unintuitive. Sterbenz [39] illustrates \nthis fact by computing x+y , the average of two numbers. Even for a 2 simple function like this, it \nrequires considerable knowledge to 1 int gsl_sf_bessel_Knu_scaled_asympx_e( 2 const double nu, const \ndouble x, 3 gsl_sf_result result * 4 ) { /* x >> nu*nu+1 */ 5 double mu = 4.0*nu*nu; 6 double mum1 = \nmu-1.0; 7 double mum9 = mu-9.0; 8 double pre = sqrt(M_PI/(2.0*x)); 9 double r = nu/x; 10 result->val \n= pre * (1.0 + mum1/(8.0*x) 11 + mum1*mum9/(128.0*x*x)); * 12 result->err = 2.0 GSL_DBL_EPSILON 13 fabs(result->val) \n * 14 + pre fabs(0.1*r*r*r); * 15 return GSL_SUCCESS; 16 } Figure 2: A function from GSL s special \nfunction collection. implement it well. The four functions av1 4 in Figure 1 are a few possible average \nformulas. They are all equivalent over the reals, but not over .oating-point numbers. For instance, av1 \nover.ows when x and y have the same sign and are suf.ciently large, and av2 is inac\u00adcurate and requires \na second expensive division. Sterbenz performs a very interesting analysis of this problem and de.nes \naverage that uses av1, av3, and av4 according to the signs of the inputs x and y. Sterbenz proved average \nto be free of over.ows. Our tool Ariadne explores all the paths in average and does not .nd any over.ows, \nas expected. To run Ariadne, we issue ariadne sterbenz.c at the command line to compile and apply the \noperand checking, explicit .oating-point exception transformation, then symbolically execute the result \nto produce sterbenz.out, which contains the analysis results. Ariadne discovers 6 under.ows, reporting, \nfor example x = -3.337611e-308 and y = 2.225074e-308, as an input pair that triggers this exception at \nline 2. We close with a function that contains each of the four .oating\u00adpoint exceptions Ariadne detects, \ndrawn from our test corpus, the GSL special functions. Figure 2 contains the GSL s implementation of \ngsl_sf_bessel_Knu_scaled _asympx_e. Run on this func\u00adtion, Ariadne reports that the square-root operation \nat line 8 throws an Invalid exception when x < 0 and a Divide-by-Zero when x = 0. When nu = -5.789604e+76 \nand x = 2.467898e+03, the evaluation of mum1*mum9 at lines 10 11 over.ows. Finally, when nu = -7.458341e-155 \nand x = 2.197413e+03, the evaluation of mu = 4.0*nu*nu at line 5 under.ows. 3. Approach Figure 3 depicts \nthe architecture of Ariadne, which has two main phases. Phase one transforms an input numeric program \ninto a form that explicitly checks for .oating-point exceptions before each .oating-point operation and, \nif one occurs, throws it and terminates execution. The transformed program contains conditionals, such \nas x > DBL_MAX, that cannot hold during concrete execution, where DBL_MAX denotes the maximum .oating-point \nvalue. The trans\u00adformed program, including its peculiar conditionals, are amenable to symbolic execution \nand any program point that symbolic execu\u00adtion reaches without throwing an exception has the property \nthat none of its .oating-point variables contain a special value, such as NaN (Not a Number) or 8. Thus, \nthe numeric constraints generated during symbolic execution involve those .oating-point values that are \na subset of Rand suitable input to an SMT solver supporting the theory of reals. During phase two, Ariadne \nsymbolically executes the transformed program, and for each path that reaches a .oating-point exception \ninjected in phase one, it attempts to solve the correspond\u00ading path constraint. If a satisfying assignment \nis found, Ariadne Exception Example Default Result Over.ow Under.ow Divide-by-Zero Invalid Inexact |x \n+ y| > O |x/y| < . x/0 0/0,0 \u00d7 8, v -1 nearest(x op y) = x op y \u00b18 Subnormals \u00b18 NaN Rounded result \nTable 1: Floating-point exceptions; x,y . F[23, \u00a72.3]. attempts to trigger the exception in the original \ncode. If it succeeds, Ariadne reports the assignment as a concrete input that triggers the exception. \nOur symbolic execution is standard; the key challenge in its realization is how to effectively solve \nthe collected numerical constraints, many of which are multivariate, nonlinear. We .rst present pertinent \nbackground in numerical analysis and introduce notation (Section 3.1), then describe our transformation \n(Section 3.2) and how we solve numerical constraints (Section 3.3). 3.1 Background and Notation Four \ninteger parameters de.ne a .oating-point number system F. R: the base (radix) \u00df , the precision t, the \nminimum exponent emin, and the maximum exponent emax. With these parameters and the mantissa m . Zand \nthe exponent e . Z, F= { \u00b1m\u00df e-t | (0 = m = \u00dft - 1 . emin = e = emax) . (0 < m < \u00dft-1 . e = emin) } The \n.oating-point numbers for which \u00dft-1 = m = \u00dft . emin = e = emax holds are normal; the numbers for which \n0 = m < \u00dft-1 . e = emin holds are subnormal [23, \u00a72.1]. O = \u00df emax (1-\u00df -t ) denotes the maximum .oating-point \nnumber; -O, the minimum. . = \u00df emin-1 is the smallest normalized .oating-point number; \u00e6 = \u00df emin -t \nis the smallest denormalized. Floating-point operations can generate exceptions shown in Table 1. Some \napplications of the operations on certain operands are unde.ned and cause the Divide-by-Zero and Invalid \nexceptions. Finite precision causes the rest. Inexact occurs frequently [19, 26] and is often an unavoidable \nconsequence of .nite precision. For example, when dividing 1.0 by 3.0, an Inexact exception occurs because \nthe ratio 1/3 cannot be exactly represented as a .oating\u00adpoint number. For this reason, Ariadne focuses \non discovering Over.ow, Under.ow, Invalid, and Divide-by-Zero exceptions. Throughout this section, we \nabuse Q to denote its arbitrary precision subset. Let fp : Q. Fconvert a rational into the nearest .oating-point \nvalue, rounding down. For next : F\u00d7F. F, next (x,y) returns the .oating-point number next to x in the \ndirection of y. To model path constraints, we consider formulas f in the theory of reals. For a formula \nf, fv(f ) = xx denotes the free variables in f . We use S to denote satis.able or SAT; S\u00afto denote unsatis.able \nor UNSAT; and U for UNKNOWN. Below, we de.ne algorithms that return satisfying bindings to variables \nor UNSAT or UNKNOWN. For this purpose, we de.ne An F = (V \u00d7 F)n { S\u00af,U} to be a disjoint union that is \neither an n length vector of simultaneous assignments over Fto the variables V , or is UNSAT or UNKNOWN. \nFor I SS AT: An F . B, I S SAT(a) returns true if a / . { S\u00af,U}.  3.2 Program Transformation We .rst \nde.ne T , the term rewriting system we use to inject explicit .oating-point exception handling into numeric \ncode. For simplicity of presentation, we assume that nested arithmetic expressions have been .attened. \nWe assume that the program terminates after throwing a .oating-point exception.  Figure 3: The architecture \nof Ariadne. 3.2.1 Basic Arithmetic Operations 1 double z = mu -1.0; The operator 8 . {+,-,*}, and variables \nx and y bind to .oating-2 double abs1 = fabs(z); point expressions. We have the following local rewriting \nrules: 3 if (DBL_MAX < abs1) { 4 perror(\"Overflow!\\n\"); T (x 8 y) = T (x / y) = . . . . . . .. . 5 exit(1); \nOver.ow if |x 8 y| > O 6 }Under.ow if 0 < |x 8 y| < . otherwise 7 if (0 < abs1 &#38;&#38; abs1 < DBL_MIN) \n{ x 8 y 8 perror(\"Underflow!\\n\"); 9 exit(1); Invalid if x = 0 . y = 0 Divide-by-Zero if x = 0 . y = 0 \n10 } 11 double mum1 = z; Over.ow if |x| > |y|O Under.ow (a) Subtraction (line 6 of example in Figure \n2). if 0 < |x| < |y|. x / y otherwise 1 if (x == 0) { // denominator is zero We also have a global contextual \nrewriting rule T (C[e]) = C[T (e)], where e denotes an expression of the form x 8 y or x / y, and C[\u00b7] \ndenotes a program context. Ignoring time-dependent behavior, it is evident that [p] = [T (p)] when the \nnumeric program p terminates without throwing a .oating-point exception, where [\u00b7] denotes the semantics \nof its operand. Figure 4a shows a concrete example of how T , specialized to C, transforms a subtraction \nexpression (line 6 of example in Figure 2). The result of the subtraction is checked and, if an exception \ncould occur, execution terminates. The division transformation, depicted in Figure 4b, is the most involved \ntransformation. The original expression is taken from line 9 of the example in Figure 2. A .oating\u00adpoint \ndivision operation can throw four distinct exceptions, each of which the transformed code explicitly \nchecks. For instance, given the inputs nu = 0.0 and x = 0.0, the original expression would have terminated \nnormally and returned NaN, but the transformed code would detect and output an Invalid exception, then \nterminate.  3.2.2 Elementary Mathematical Functions Calls into an unanalyzed library usually terminate \nsymbolic exe\u00adcution. Calls to elementary mathematical functions, such as sqrt, log, exp, cos, sin and \npow, are frequent in our constraints. These functions are often handled in hardware, like sqrt. We next \ndescribe simple, yet effective, transformations to deal with these functions. Indeed, during our experiments, \nthese transformations en\u00adabled us to .nd approximately 41% of the .oating-point exceptions we report. \nWhen all of an elementary function s operands are within its domain, these well-tested, ubiquitous functions \ndo not return specials. To handle an unanalyzed elementary function, therefore, we insert checks that \nits operands are in its domain and signal the appropriate exception if a check fails, then bind a fresh \nsymbolic variable to the call. These symbolic variables are dependent, since they depend on other symbolic \nvariables. Input symbolic variables are independent. We add the obvious constraints on the range of dependent \nvari\u00adables. For instance, we add the constraint d2 = x, for sqrt, which Figure 4: Ariadne transformations \nrealized in C: Ariadne symbol\u00adically executes this code over arbitrary precision rationals, where the \nconditionals can be tested; fabs returns the absolute value of a double. 2 if (nu == 0) { 3 perror(\"Invalid!\\n\"); \n4 } else { 5 perror(\"DivZero!\\n\"); 6 } 7 exit(1); 8 } 9 double abs1 = fabs(nu); 10 double abs2 = fabs(x); \n11 if (abs1 > abs2 * DBL_MAX) { 12 perror(\"Overflow!\\n\"); 13 exit(1); 14 } 15 if (0 < abs1 &#38;&#38; \nabs1 < abs2 * DBL_MIN) { 16 perror(\"Underflow!\\n\"); 17 exit(1); 18 } 19 double r = nu/x; (b) Division \n(line 9 of example in Figure 2). has a polynomial representation, as shown in Figure 5. On line 8 of \nthe example in Figure 2, we replace the call to sqrt with the fresh symbolic variable d and add the constraint \nd2 = M_PI/(2.0 * x). A dependent symbolic variable can depend on another dependent variable, as when \nlog(log(x)) is encountered. Dependent vari\u00adables allow us to defer a call s evaluation until that variable \nappears in a path constraint that we feed to the solver. The binding of a dependent variable to a function \ncall is recorded in a table, for use during its evaluation, when we concretize a dependent variable and \nthe variables on which it depends (Section 3.3.1). Table 2 shows the contents of the dependent symbolic \nvariable table when the  T (sqrt(x)) = Invalid d, where d \u00b7 d = x if x < 0 otherwise . . Over.ow if \nx > log(O) T (exp(x)) = . Under.ow d if x < log(. ) otherwise T (log(x)) = Invalid d if x = 0 otherwise \nT (cos(x)) = d where - 1 = d = 1 T (sin(x)) = d where - 1 = d = 1 T (pow(x,y)) = Invalid d if x = 0 \n. y = 0 otherwise Figure 5: Rewriting rules for elementary mathematical functions. Dependent variable \nExpression d0 sin( x y ) d1 log(x2 + 1 ) x Table 2: A dependent symbolic variable table. 2 1 transformation \nencounters sin( x y ) and log(x+ x ), which use the independent variables x, y. In Figure 5, we rewrite \ncalls to pow to throw Invalid if its operands are outside its domain. Our rewrit\u00ading of pow could make \nadditional checks for exceptions, such as y > 0 . ylog(x) > log(O), but we found the described handling \nof pow and the other elementary functions to be very effective over the functions we analyzed.  3.3 \nSolving Numeric Constraints Designing SMT solvers that can effectively support multivariate, nonlinear \nconstraints over the reals is an active area of research. Off\u00adthe-shelf SMT solvers focus on linear constraints \nand do not support general nonlinear constraints over the real domain because linear constraints are \nprevalent in integer programs and solving nonlinear constraints is very expensive (although decidable \nover the reals). However, real-world numeric applications contain many nonlinear constraints. In our \nexperiment over the GSL special functions, 81% of queries are nonlinear, 73% are multivariate and 62% \nare both nonlinear and multivariate. Algorithm 1 is the Ariadne solver for .oating-point exceptions. \nDuring symbolic execution, it is called to solve the numeric path constraints to the program points that \nrepresent exceptions, injected during the program transformation (Section 3.2). In addition to the path \nconstraint f, the Ariadne exception solver takes T , the depen\u00addent symbolic variable table built during \nthe transformation phase (Section 3.2.2), p, the original, untransformed numeric program itself, the \npossible exception e, and l, the location (program point) in p of the operation that may throw e. To \nsolve f, Algorithm 1 .rst checks whether f contains any multivariate numerical constraints. It it does, \nAlgorithm 1 con\u00ad cretizes f using T to convert f into a univariate formula. On line 5, it calls the C \nO N C RETIZE method, which interacts with the un\u00adderlying SMT solver to bind variables that appear in \nmultivari\u00adate numeric constraints to values in F (Section 3.3.1); it returns fc with the selected variables \nreplaced with concrete values and xac, which records those variable to value bindings. Algorithm 1 calls \nS O LVEUN I VA R I AT E (Algorithm 2) to solve a univariate for\u00ad mula. When S O LV E UNI VA R I AT E \n.nds a satisfying assignment, Al\u00ad gorithm 1 returns the bindings from the calls to both C O N C R E TI \nZ E Algorithm 1 A R I A D N E SO LVE: F \u00d7 T\u00d7 P \u00d7 E\u00d7 N . An F solves a numeric path constraint over the \nreals. This topmost algorithm handles formulae that contain multivariate numerical constraints. When \nf contains such a constraint, the solver tries various con\u00adcretizations up to its MAX_CONCRETIZATIONS \nbound. Note that n = |fv(f)|, for f . F. inputs f . F, a numeric constraint from p. T . T, a table of \ndependent symbolic variables. p . P, the numeric program under analysis. e . E, the potential exception. \nl . N, the location of e. ISMULT I VAR I AT E : F . Breturns true when passed a formula that contains \na multivariate numerical constraint. 1: if \u00acISMULTVA RI ATE(f) . |T | = 0 then 2: return S O LV E UN \nI VA RI ATE(f,(), p,e,l) // Algorithm 2 3: else 4: for 1..MAX_CONCRETIZATIONS do 5: fc,xac := C O NC \nR E T I Z E(f,T ) // Algorithm 3 6: xa := S O LV E UN IVA RI ATE(fc,xac, p,e,l) // Algorithm 2 7: if \nISSAT(xa) then 8: return xa 9: end if 10: end for 11: return U // Return UNKNOWN. 12: end if Algorithm \n2 S OLV E UN I VAR I AT E: F \u00d7 An F\u00d7 P \u00d7 E\u00d7 N. An F lin\u00adearizes nonlinear univariate constraints in f \n, .nds a .oating-point solution to the resulting constraints, then checks whether a satisfying solution \ntriggers the given exception at the speci.ed location. inputs f . F, a formula whose numeric constraints \nare univariate. xac . AFn , the concretized bindings. p . P, the numeric program under analysis. e . \nE, the potential exception. l . N, the location of e. 1: f' := LI N E A RI ZE(f ) // Algorithm 4 2: \nxa := xac + S O LV E OVERF(f') // Algorithm 5 3: if ISSAT(xa) . p(xa) does not throw e at l then 4: return \nU // Return UNKNOWN. 5: end if 6: return xa and SOLV E UNI VAR I AT E. Algorithm 1 tries different concretizations \nup to MAX_CONCRETIZATIONS times. Our experiments validate our core insight that, if an exception is reachable, \nmany inputs reach it: varying MAX_CONCRETIZATIONS did not greatly change Ariadne s detection rate (See \nSection 5.1). To convert a nonlinear univariate formula into a linear formula, Algorithm 2 applies a \nlinearization technique that .nds the roots of each nonlinear polynomial constraint, then rewrites the \nconstraints into an equivalent disjunction of interval checks (Section 3.3.2). When f is linear, f' = \nf . While f ' is univariate and linear upon input to S OLV E OV E RFon line 2, it remains a formula in \nthe theory of reals, so the underlying SMT solver, used in C O N C R E T I Z E in Algorithm 1 and here \nin the S O LV E OV E RFfunction, may return a solution in Q\\F. The SOLV E OVE RFalgorithm (Section 3.3.3) \n.nds a .oating-point solution in Fn for its input, if one exists. The S O LV E OV E RF function s solution \nreaches and triggers an exception when symbolically executed using real arithmetic, but may not when \nconcretely executed using .oating-point arithmetic. For instance, consider if(x +1 > O) Over.ow . The \nbinding x = O is valid solution in the theory of reals and S O LV E OVERFcan return it, since x . F. \nUnder concrete execution with standard .oating-point semantics, however, the difference in magnitude \nof the operands means that the result of the addition operation must be truncated to .t into the .nite \nprecision of .oating-point which absorbs the 1 into x s value of O. Under .oating-point arithmetic, this \nOver.ow is unreachable and the binding produced during symbolic execution is a false positive. Approximating \n.oating-point arithmetic with real arithmetic can also produce false negatives, again due to rounding. \n Thus, each satisfying solution S O LV EOV E RFproduces is a can\u00addidate solution that Ariadne must concretely \ncheck. In Algorithm 2, line 3 performs the requisite concrete check over .oating-point. Here, the Ariadne \nexception solver executes p on the candidate satisfying assignments both those found by SO LVEOV E RFand \nxac from concretization to determine whether p actually throws the e at l, the location of the .oating-point \noperation under scrutiny. Ariadne is certainly correct when it reports that executing a pro\u00adgram on an \ninput vector throws a particular .oating-point exception at a particular operation. However, Ariadne \ncannot guarantee that a program is exception-free, for three reasons: it 1) approximates .oating-point \nsemantics with constraints over the reals, which no\u00adtably ignore rounding (i.e. Inexact); 2) concretizes \nmultivariate into univariate constraints; and 3) rewrites loop conditions to bound the number of iterations. \nThe decision to approximate .oating-point arithmetic with real arithmetic is the core design decision \nof this work. This decision favors practicality in the trade-off between prac\u00adticality and precision; \nit allows us to use off-the-shelf SMT solvers, such as Z3. It is also what necessitates the concrete \nexecution check to con.rm that a path to an exception is indeed satis.able; it also means that we may \nfail to detect exceptions. That said, deployed numerical software is usually robust, i.e. small changes \nin its in\u00adput cause small changes in its output, so error accumulation due to rounding is typically small. \nThus, an ideal execution over the reals should closely approximate the actual execution over .oating\u00adpoint, \nespecially for invalid, over.ow and under.ow exceptions. Concretization means that Ariadne might abandon \na path as unsatis\u00ad.able, when that path is, in fact, satis.able and contains exceptions; analyzing programs \nwith externally imposed loop bounds also means that Ariadne may fail to explore paths that contain exceptions. \nAll of these cases mean that Ariadne may miss exceptions. In spite of these limitations, Ariadne is an \neffective testing technique that detects many .oating-point exceptions, as our results in Section 5 demonstrate. \nIn particular, we empirically show that concretization is quite effective in our setting (Section 5.1). \n 3.3.1 Concretization Before querying its SMT solver in Algorithm 1, Ariadne must convert multivariate \nto univariate polynomial constraints and can no longer defer the concrete evaluation of elementary functions, \nin the form of dependent symbolic variables. Algorithm 3 takes the input formula f and the analyzed program \ns dependent symbolic variable table T and handles these two problems. The algorithm .rst identi.es VT \n, the dependent variables that appear in both T and f , then the independent variables on which they \ndepend. We de.ne VT to avoid needlessly concretizing independent variables whose dependent variables \ndo not appear in f . Algorithm 3 then identi.es all the independent variables that appear in a multivariate, \nnumeric constraint in f and not in VT . Then it builds and topologically sorts the DAG G to concretize \nthe variables in G so that it has all the information it needs to evaluate the expressions in T . On \nline 8, the choose function nondeterministically selects an element from a set, but could be de.ned to \nimplement an arbitrary selection policy, such as selecting the free variable with the highest Algorithm \n3 CON C RET IZE : F \u00d7 T . F \u00d7 An-1 builds a DAG F that contains the symbolic variables that appear in \nmultivariate numeric constraints and all variables in T , then concretizes them in topological sort order. \nThe C O N C R ET I ZE function must process T , because Ariadne can no longer defer handling elementary \nfunctions, since it is about to query the underlying SMT solver. inputs f , a numeric constraint. T , \na dependent symbolic variable table. 1: xa := () contains concretized variable bindings. 2: Df = fv(f) \nn {d | (d,e) . T } is the set of dependent symbolic variables in T that appear in f . 3: VT = Df . {v \n| d . Df . (d,e) . T . v . fv(e)} is the set of dependent symbolic variables in T and the variables on \nwhich they depend that appear in f. 4: Mf = {m | m is a multivariate, numeric constraint in f . |fv(m) \n\\VT | > 1} is the set of multivariate, numeric constraints in f that will remain multivariate after T \nhas been concretized. 5: Im = fv(m) \\VT is the set of independent variables in m.Mf Mf that will remain \nafter T has been concretized. 6: Iu := 0/is the set of variables that will remain symbolic after the \nconstraints in Mf have either been converted to univariate or entirely concretized. 7: while Mf = 0/do \n// Greedily approximate the hitting set of Mf . 8: Iu := Iu . choose(fv(m) \\VT ), for some m . Mf 9: \nMf := {c | c . Mf . fv(c) n Iu = 0/} // Remove those con\u00adstraints covered by the choice made in the previous \nline. 10: end while 11: G = (V, E), where V = VT . Im \\ Iu and (u,v) . E when v depends on u, i.e. u \n. fv(T (v)). 12: .x . TO POSO RT(G) do 13: if IND EG R E E(x) = 0 then // Independent symbolic variables. \n14: c := BI N DVA R I A B LE(f,x) 15: return f ,U if c = U 16: else // Dependent symbolic variables. \n17: c := E VA L(T (x),xa) 18: end if 19: xa := xa + (x,c) 20: f := f[c/x] 21: end for 22: return f,xa \ndegree or that appears most often1 . Since Iu is a greedy over\u00adapproximation of the hitting set of variables \nin the multivariate numeric constraints in f, Algorithm 3 may over-concretize, as when f contains three \nmultivariate constraints and Algorithm 3 picks variables to concretize in the .rst two that completely \nconcretize the third constraint. When this happens, we simply hope to do better in a subsequent call \nto C O N CR ETI ZE in Algorithm 1. The fact that concretization is quite effective in our setting supports \nour core insight: in practice, our constraints either have no solution or many. Our symbolic variables \nare de.ned over intervals; if an input triggers an exception, there will almost always be many such inputs. \nAn experiment in Section 5.1 demonstrates the robustness of our concretization results. To clarify the \npresentation, we introduce the helper function C H E CK B I ND I N G: F \u00d7V \u00d7 F. B to check that a candidate \nbind\u00ading does not trivially falsify a formula. For the call C H E CK B I ND -IN G(f,x, c), we have .fi \n. f do return false if EVA L EX P R(fi[c/x]) = false 1 Preliminary experiments using degree or count \nof occurrences did not outperform uniform selection.  Algorithm 4 LIN EA R IZ E: F . F rewrites a nonlinear \npolynomial constraint into an equivalent disjunction of linear interval predicates. Here, polysolver \nis a placeholder for any polynomial solver; our implementation uses the one in the GSL-1.14 (Section \n4). _ input f = ci, a univariate numeric path constraint. .ci . f do // All constraints in f. if ci = \nR(x) -0 . degree(R(x)) > 1 then {x1,x2, \u00b7\u00b7\u00b7 ,xn} = polysolver(R(x)) I = (8, x1),\u00b7\u00b7\u00b7 ,(xn, 8), where xi \n< x j when i < j. I- is those intervals in which R(x) < 0. I+ is those intervals in which R(x) > 0. V \nn eq := i=1 x = xi V lt := i.I- x . i V gt := i.I+ x . i . := match -with = . eq | < . lt | > . gt | \n= . eq . lt | = . eq . gt f := f[./ci] end if end for return f end for return true The fi[c/x] notation \nmeans to rewrite every appearance of x in fi with c. The function E VA L EXPR walks the expression tree \nthat results from the substitution and evaluates constant expressions. It returns false if the recursive \nevaluation of constant expressions reduces the expression tree to false. For example, consider the simple \nnumeric constraint 5x > 0: E VAL EXPR would return false for any assignment to x less than or equal to \nzero and true otherwise. Its complexity is O(n), where n is the number of nodes in the expression tree. \nThe function C H EC K B I N D I N G checks a single binding; to test a bounded number of bindings, we \nde.ne B INDVA R I A B LE: F \u00d7V . F. {U}: for 1..MAX_BINDINGS do c := RAN D O M(dom(x)) return c if CHEC \nK BI N D ING(f,x,c) end for return U // Return UNKNOWN. In our setting, topological sort means that the \ncondition at line 13 will be true until all the independent symbolic variables that appear in an expression \nin T are exhausted, at which point the condition will always be false and dependent variables will be \nprocessed. At line 17, we evaluate the expression T (x) in the context of xa to .nd a 2 1 concrete binding \nfor x. For example, consider T (x) = log(y+ y ) in Table 2. When y is concretized to 1, x = log(2) = \n1. Algorithm 3 may convert f into a ground formula, i.e., a formula with no free variables. When this \nhappens, L I N E A RIZE echoes the ground formula and S O LVEOV E RF returns true or false via S\u00af. Otherwise, \nAlgorithm 3 returns a rewritten f that contains no multivariate numeric constraints. During the topological \nsort, Algorithm 3 calls E VA L E X P R for each independent symbolic variable over expression trees whose \nmaximum number of nodes is bounded by f . For each dependent variable, we must evaluate its corresponding \nexpression, at cost a. Thus, the complexity of Algorithm 3 is O(|I||f| + |D|a + |E|), where V = I . D. \n 3.3.2 Linearizing Univariate Nonlinear Constraints Given a univariate, nonlinear constraint, we transform \nit into a disjunction of linear constraints, suitable for an off-the-shelf SMT Figure 6: The roots of \nthe univariate polynomial constraint R(x) = (x - r0)(x - r1) de.ne intervals that determine its sign. \n solver. Algorithm 4 linearizes a formula in the theory of reals into an equivalent formula by replacing \neach comparison involving a nonlinear polynomial with an equivalent linear disjunction. Figure 6 gives \nthe high-level intuition that underlies this lin\u00ad earization. The roots of R(x) = (x - r0)(x - r1) de.ne \nintervals that determine its sign, as shown in the .gure. We simply need to encode the intervals that \nthe roots de.ne and the sign of R(x) when x falls into each interval into disjunctive linear constraints. \nTo form these in\u00adtervals, we must .nd the roots of a univariate polynomial constraint. Thus, the complexity \nof Algorithm 4 is quadratic. The correctness of the technical details of this rewriting rests on Lemma \n3.1, which we present next. P(x) Lemma 3.1. For a rational function f (x) = where x . R, there Q(x) exists \na polynomial R(x) of degree m whose n = m distinct real roots x1,\u00b7\u00b7\u00b7 ,xn de.ne n+1 intervals that can \nbe partitioned into I-, those intervals in which R(x) is negative, and I+, where R(x) is positive. Using \nthe roots and these intervals, we have n f (x) = 0 = x = xi i=1 f (x) < 0 =x . i i.I- f (x) > 0 =x \n. i i.I+ P(x) Proof. The rational function f (x) = , by de.nition. For -. {< Q(x) P(x) , >, =}, -0 = \nP(x)Q(x) -0 . Q(x) = 0 (multiply by Q(x)2), Q(x) so our problem reduces to that of solving the predicate \nR(x) -0 which either has the form P(x)Q(x) or Q(x). We normalize R(x) so that its leading coef.cient \nis positive. From the Fundamental Theorem of Algebra, we have R(x) = (x - x1)(x - x2)\u00b7\u00b7\u00b7(x - xm), where \nm is the degree of R(x). Complex roots with a non-zero imaginary part cannot equal zero and when a + \nbi,b = 0 is a root, its conjugate is also a root, so the product of the non-real complex factors of R(x) \nis positive, and do not determine its sign, R(x) = 0 holds whenever x equals any of the real roots of \nR(x), i.e. (x = x1) . \u00b7\u00b7\u00b7 . (x = xn). Otherwise, x falls into one of the n + 1 intervals de.ned by the \nroots of R(x). Evaluating R(x) in each of these intervals partitions them into I+, those intervals in \nwhich R(x) is positive, and I-, those intervals in which R(x) is negative. Thus, when R(x) = 0, it is \nnegative whenever x falls into any of the intervals in I- and positive whenever x is in some interval \nin I+ .  3.3.3 Finding a Floating-point Solution Given a univariate, linear constraint f , we need to \n.nd a solution over F. Algorithm 5 loops over the intervals that f de.nes. It tries to solve f at line \n2, then substitutes the nearest .oat less than or equal to the solution into f and tries to solve the \nresulting formula at line 5. If that fails, it then substitutes the nearest .oat greater than or Algorithm \n5 S O LV E OV E RF: F . An F takes a path constraint and returns a satisfying assignment over Fif one \nexists.  input f . F, a path constraint. 1: while true do 2: xa := SMT.SO LV E(f ) 3: return xa if not \nI S SAT(xa) 4: (x,v) = xa 5: xa := SMT.S O LV E(f [fp(v)/x]) 6: return xa if I S SAT(xa) 7: xa := SMT.S \nO LV E(f [next(fp(v),O)/x]) 8: return xa if I S SAT(xa) 9: f := f . (x < fp(v) . x > next(fp(v),O)) 10: \nend while equal to the solution into f and tries to solve the resulting formula at line 7. If this fails, \nit rules out the interval under consideration at line 9 and considers the next interval. The complexity \nof this step is linear in the number of intervals; we prove its correctness next. Lemma 3.2. Algorithm \n5 .nds a .oating-point solution to a uni\u00advariate linear constraint, if one exists. Proof. The solution \nfor a univariate system of linear inequalities is a set of intervals. A linear inequality has the form \nax + b > 0. Either a = 0 and b determines the truth value of the inequality, or the solution of the clause \nfalls into one of two intervals de.ned by the root of the clause. Thus, the path constraint f de.nes \na set of intervals [ai,bi]2 . For x . [ai,bi], let x f be the largest .oating-point number less than \nor equal to x. If either x f . [ai,bi] or next(x f , O) . [ai,bi] then a .oating-point value exists that \nsatis.es the path constraints. Otherwise, we have x f ./[ai,bi].next(x f ,O) ./[ai,bi].[ai,bi]n[x f ,next \n(x f ,O)] = 0/which implies x f < ai < bi < next(xf ,O). In this case, there is no .oating-point number \nin the interval [ai,bi)]. So we add the constraint x < x f . x > next(x f ,O) to rule out [ai,bi] and \nconsider a different interval. If the algorithm exhausts all the intervals without .nding a satisfying \n.oating-point value, no .oating-point value for x satis.es the path constraint. 4. Implementation In \nthis section, we present the implementation of our .oating-point exception detection tool, Ariadne. Ariadne \ns implementation mirrors its operation: it consists of transformation or analysis components. The transformation \nrests on LLVM 2.7 [29]. Its arbitrary precision transformation uses GMP [14]. Its analysis phases extends \nversion 2.7 of the KLEE symbolic execution engine [7] and uses the polynomial solver from GSL 1.14 to \nrewrite constraints [15]. We are indebted to the community for having made these tools available. To \ngive back, we will also publicly release our tool. 4.1 Transformations Our transformations are implemented \nas an LLVM analysis and transform pass and operate on LLVM IR. For this reason, our trans\u00adformations \nare language agnostic and, in particular, can handle C, C++ and Fortran, the three languages in which \nmost numerical soft\u00adware is written. The principle transformations are reify exception, loop bound, and \narbitrary precision. Reify Exception This transformation makes potential .oating\u00adpoint exceptions explicit. \nBefore each .oating-point operation, it injects operand guards to check for exceptions. The bodies of \nthese checks signal the relevant exception and contain a program point that can only be reached if the \nguarded operation can throw that 2 We consider the closed intervals; open intervals can be handled similarly. \nexception, as described in Section 3.2. It also handles elementary functions and constructs the dependent \nsymbolic variable table (Section 3.2.2). Given an input module, it iterates over every instruction, in \nevery basic block, in every function. It rewrites at the instruction-level, matching the Call instruction, \narithmetic (FAdd, FSub, FMul, FDiv) and conversion (FPToSI, FPToUI) .oating-point operations. When handling \nthe Call instruction, the transformation detects and handles elementary functions (Section 3). Loop Bound \nSymbolic execution maintains state for each path; path explosion can exhaust resources and prevent symbolic \nexecu\u00adtion from reaching interesting program points. Loops exacerbate this problem. The loop bound transformation \ntakes a bound parameter that it rewrites every loop in its input to obey. Our loop transforma\u00adtion operates \non LLVM bytecode, after loop normalization. Here, we show how it works conceptually: i n t i = 0 ; / \n/ a f r e s h v a r i a b l e w h i l e ( e x p r ) { w h i l e ( i ++ < BOUND &#38;&#38; e x p r ) { \n. b o d y b o d y } } Arbitrary Precision In Section 5.3, we propose a classi.er that separates likely \nto be avoidable over-and under-.ows from those that are likely to be unavoidable. The idea is to transform \na program that throws a .oating-point exception into an equivalent program that uses arbitrary precision \nrationals instead of .oats, then run the transformed program to check whether 1) it terminates and 2) \nthe result can be converted into .oating-point without over-or under-.owing. The arbitrary precision \ntransformation (AP), converts each .oat type annotation into mpq_t, the GMP library s arbitrary precision \nrational type. AP converts each arithmetic operation to the corresponding GMP function. AP recursively \ntraverses structures. AP rewrites internal function prototypes and de.nition and marshals and unmarshals \nthe parameters to external functions.  4.2 Analysis Concurrently and separately from KLEE-FP [4], we \nadded support for .oating point types and operations to KLEE. Our goal is not to support symbolic reasoning \non the equivalence between .oating\u00adpoint values like KLEE-FP, but to replace KLEE s underlying SMT solver, \nSTP, which does not support satis.ability reasoning over the reals. We modi.ed KLEE 1) to use version \n3.1 of the Z3 SMT solver from Microsoft, which supports the theory of real numbers, and 2) to support \n.oating-point symbolic variables, update its internal expressions when encountering .oating-point operations, \nand output those expressions, labeling the symbolic variables with type real, as input to Z3. To implement \nlinearization (Section 3.3.2) and .nd the roots of polynomials, we extended KLEE to use the GSL polynomial \nsolver package and to internally represent every expression as a rational function, i.e. a fraction of \ntwo polynomials. Limitations KLEE requires heap-allocated memory to have concrete size. Memory contents \ncan be symbolic and KLEE handles symbolic pointers by cloning. Ariadne inherits this memory handling \nstrategy from KLEE. We also restrict symbolic variables to .oating\u00adpoint parameters and assign random \nvalues to integer parameters. We do not handle parameters whose type is pointer or struct. We intend \nto support these features in the future. 5. Evaluation We .rst motivate our creation of a new multivariate, \nnonlinear solver, then present exceptions it found and discuss its performance as an automatic .oating-point \nexception detector. Ariadne .nds many over.ows and under.ows (X.ows), many of which may be an unavoidable \nconsequence of .nite precision. We close with the presentation of an X.ow classi.er that seeks to separate \navoidable from unavoidable X.ows and the F. Q type transformation on which it rests.  We ran our experiments \non a machine running Ubuntu 10.04.2 LTS (kernel 2.6.32-30-server) with 128GB RAM and 3 Intel Xeon X7542 \n6-Core 2.66GHz 18MB Cache, for a total of 18 cores. The Ariadne engine is described in Section 4. We \nchoose to analyze the special functions of the GNU scienti.c library (GSL) version gsl\u00ad1.14, because \nthe .rst phase of Ariadne focuses on scalar functions and most of GSL s special functions take and return \nscalars. We examined all the special functions in the GSL, even though some are static and others share \ntheir core implementation. The GSL is a mature, well-maintained, well-tested, widely deployed scienti.c \nlibrary [15]. It is for these reasons that we selected it for analysis: .nding nontrivial exceptions \nin it is both challenging and important. In spite of these challenges, Ariadne found nontrivial exceptions. \nSince Ariadne analyzes programs not functions, we applied a transformation to each special function in \nthe GSL library that synthesizes a main that creates symbolic variables and calls the analyzed function, \nin addition to applying the transformations described in Section 3.2 and Section 4.1. 5.1 Experimental \nSetup External functions and loops cause dif.culties for static analyzes, like the symbolic analysis \nunderlying Z3-AR I A DN E. We handle a subset of external functions as described in Section 3.2.2. For \nloops, a classic workaround tactic is to impose a timeout. Another is to bound the loops. We did both. \nWe imposed two timeouts per-query and per-run. To bound loops, we implemented a transformation that \ninjects a bound into each loop, as described in Section 4.1. Although we could have restricted the use \nof this loop bound transformation to functions whose analysis failed, we re-ran the analysis on all functions \nat each loop bound, seeking the Pareto optimal balance of loop bound and time-to-completion. The in.nity \nloop bound means that we did not apply our loop bound transformation. Concretization We performed the \nanalysis described here with maximum concretizations set to 1 (so we only tried a single con\u00adcretization \nper query), as we found that this setting effectively bal\u00adances performance and precision: higher numbers \nof concretizations had minimal impact on our results. When we uniformly sampled 1% of queries for intensive \nconcretization, our results were stable. At 1,000 concretizations, 6% of the UNSAT results at 1 concretization \nbecame SAT; at 1,000,000, 8% of the UNSAT results became SAT. These results validate our trade-off of \nperformance against precision. Z3-AR I A DN E Our goal is to build a precise and practical tool to detect \n.oating-point exceptions. To this end, we hybridized the Ariadne solver with Z3: we handed each query, \neven multivariate, nonlinear ones, to Z3 .rst, and only queried the Ariadne solver on those queries to \nwhich Z3 reported UNKNOWN. We name this hybrid solver Z3-AR IAD N E. Result Reporting Multiple paths \nor multiple inputs along a single path might reach an exception-triggering program point. If that exception \nis a bug, its .x might require a single condition, implying that all the bug-triggering inputs are in \nan equivalence class, or logic bounded by the number of distinct inputs that trigger it. Thus, we report \nexceptions as [X,Y ] where X counts unique exception locations found and Y counts the unique input to \nlocation pairs. Preconditions The public API of the GSL documents some preconditions, so do some of the \ncomments internal to its source code. To get a handle on Z3-AR I A DN E s false positive rate, we selected, \nuniformly at random, 20 of the 315 functions in which Z3-AR I AD N E reported exceptions. We manually \nexamined the public API and the source of these 20 functions to 1) identify their preconditions and 2) \ncheck whether the exception-triggering inputs Z3-A R I A D N E reported against these functions violated \nthose Figure 7: Ariadne found 2091 input-to-location pairs that trigger .oating-point exceptions in the \nGNU Scienti.c library, distributed as shown.  Figure 8: Bar plot of the number of functions (y-axis) \nwith the speci.ed number of input-to-location pairs that trigger .oating-point exceptions (x-axis). preconditions. \nTwo of the 20 functions were static; against these two functions, Z3-AR I A DN E reports 7 input to exception \npairs. Even though they had no explicit preconditions in their comments, their call sites may implicitly \nencode preconditions, so we conservatively deemed these 7 pairs to be false positives. Six functions \nhad publicly documented preconditions. Against these 6 functions, Z3 -A R I A D N E reported 16 exception \npairs, 2 of which violated the function s precondition and are false positives. Against the remaining \n12, Z3-AR I A DN E reported 64 input to exception pairs. In this experiment, 9 therefore, Z3-AR I ADN \nE s false positive rate was 77 or 12%. Path Injection For each operation, the Ariadne transforma\u00adtion \ndoubles (quadruples in the case of division) the paths to the operation. The reason is that fabs uses \na conditional to com\u00adpute the absolute value of its operand. Consider double pre = 1.0/sqrt(2.0*M_PI*x); \n. Here, the expression passed to sqrt actually contains only one multiplication because the compiler \nre\u00adplaces the constant multiplication 2.0*M_PI with a single constant. Considering only the multiplication \nin the operand of the sqrt, Ariadne injects the following pseudocode: 1 if ( x > 0 ) y = (2.0*M_PI*x) \n2 else y = -(2.0*M_PI*x) 3 if (y > DBL_MAX) Overflow 4 if (y < DBL_MIN) Underflow 5 double pre = 1.0/sqrt(y); \nIn this example, Ariadne .nds x = 2.861117e+307 that traverses 1, 3 and x = -2.861117e+307 that traverses \n1, 2, 3; both inputs satisfy the conditional and trigger Over.ow.  5.2 Analysis Performance and Results \nZ3 -A R I A DNE found a total of 2091 input-to-location pairs that trig\u00adgered exceptions, distributed \nas shown in Figure 7. Z3-AR I A D N E  Function (pre.x gsl_sf_) Line Inputs conicalP_1_e 989 2.0e+01, \n1.0e+00 bessel_Jnu_asympx_e 234 0.0, 0.0 exprel_n_CF_e 89 -1.0e+00, 1.340781e+154 bessel_Knu_scaled_asympx_e \n317 0.0, 0.0 Table 3: 4 of the 44 Divide-by-Zero exceptions Ariadne found. Function (pre.x gsl_sf_bessel_) \nLine Inputs Inu_scaled_asymp_unif_e 361 -2.225074e-308, 0.0 Knu_scaled_asympx_e 317 -7.458341e-155, -8.654053e+01 \nJnu_asympx_e 234 -5.0e-01, 0.0 Inu_scaled_asympx_e 302 -1.5e+00, -3.921032e+03 Table 4: 4 of the 125 \nInvalid exceptions Ariadne found. .nds many more X.ows than Invalid or Divide-by-Zero exceptions because \nprogrammers strive to avoid the latter and because X.ows can mask these exceptions, as when an under.ow \noccurs in the evaluation of a denominator and terminates exploration of that path before the division \nis evaluated. Figure 8 shows the distribution of functions in terms of the potential exceptions they \ncontain. As ex\u00adpected, this distribution is skewed: Given the maturity and popularity of the GSL, it \nis not surprising that most of its functions contain no latent .oating-point exceptions. Ariadne reports \nthe most excep\u00adtions, 152, in gsl_sf_bessel_Inu_scaled_asympx_e de.ned in gsl/specfunc/bessel.c: Perhaps \nthe most serious exceptions are Divide-by-Zero and Invalid exceptions. For a selection of these exceptions, \nTable 3 and Table 4 show the function in which we found this type of exceptions, the line number, and \nexception triggering inputs. For example, Ari\u00adadne found a Divide-by-Zero exception in gsl_sf_conicalP_1_e \nin gsl/specfunc/legendre_con.c. Line 989 of this .le is const int stat_V = conicalP_1_V( th, x/sh, lambda, \n1.0, &#38;V0, &#38;V1); . When lambda = 20 and x = 1, sh = sqrt(x -1.0) * sqrt(x + 1.0) = 0, so x/sh \nthrows Divide\u00adby-Zero, 122 lines and 8 control points from function entry. Table 5 shows the results \nfrom our analysis of the scalar GSL spe\u00ad cial functions. The data shows that, over the GSL special functions, \nthe loop bound (the .rst column) has little impact on the results. We believe that the reason for this \nis that the analyzed functions do not make heavy use of looping constructs. Z3-AR IA D N E attempts to \nexplore all paths within the per-run time bound it is given. When Z3-ARIAD N E does not exhaust its per-run \ntimeout when analyzing a function, we increment the No Timeout column. Z3 -A R I A DNE successfully explores \na path when it determines that the path is satis.able; when it .nds an exception, that exception is real, \ni.e. it certainly occurs with the reported inputs, even though Z3 -AR I A D N E does not model rounding, \nbecause Z3-AR I AD N E con.rms candidate input-to-exception pairs via its concrete execution check (Section \n3.3). Z3-ARI AD NE s abandonment of a path as unsatis.able is provi\u00adsional for the three reasons discussed \nin Section 3.3: it approximates .oating-point semantics with reals, which notably ignores round\u00ading; \nit concretizes multivariate into univariate constraints; and it bounds loops. Of these three, we can \nhave some con.dence when Z3 -A R I A D N E reports UNSAT due to concretization, because, as we describe \nabove, concretization is effective due to the fact that the variables in our numerical constraints in \npractice either have few or many solutions. The former case causes Z3-AR I A D N E to report unsatis.able \nconstraints. When reporting UNSAT, Z3-AR I ADNE s precision is good, so the third column reports the \ncount of functions Z3 -A R I A D N E fully explored without encountering a per-query time\u00adout, i.e. U \n. In some of the functions it fully explored, Z 3-A R I A D N E discovered no exceptions; the count of \nthese functions is in column four. The set of functions whose cardinality appears in the No Timeout column \ncontains the All Paths Explored functions which contain the No Exception Discovered functions. We note \nthat, while most of the functions in which Z3-AR I A D N E discovered no exceptions at the in.nity bound \nare loop-free, four are not. During Z 3-A RI ADNE s analysis of the GSL, Z3 handled 48% of the total \nqueries, while Ariadne handled the rest. Of the total queries made, we can guarantee the results for \n76% at the in.nity bound. The remaining 24% represent UNSAT results of which we cannot be certain, since \nthey involve concretization. That said, our intensive concretization experiment shows that 92% of them \nare likely to be UNSAT, with 1M concretizations, we found 8% additional SAT. 24% \u00b7 8% = 1.9%, so Z3-AR \nI A D N E is likely to incorrectly resolve around 2% of its constraints. The loop bound transformation \nmonotonically reduces the num\u00adber of paths in a program, so each of the function columns should be monotonically \nincreasing. This pattern does not hold over No Timeout column. There are two reasons for this variation. \nFirst, Z3 randomly hangs on some of the nonlinear, multivariate constraints Z3-ARIAD N E feeds it, in \nspite of its per-query timeout. Second, KLEE .ips coins during path scheduling to ensure better coverage. \nIn short, some of the analysis runs at certain loop bounds were simply unlucky. The three columns that \ncontain the ratios of SAT |S| , UNSAT |Q||S\u00af| , and UNKNOWN |U| queries report on Z3-ARI A DN E s overall \n|Q| |Q| effectiveness. Recall that in Z3-AR IA D N E, Ariadne only handles Z3 s unknown queries. The \nAriadne ratio column reports Ariadne effectiveness at solving Z3 s unknowns in our context. Let SA,SA \n\u00af and UA be the SAT, UNSAT and UNKNOWN queries that Ariadne |SA.S\u00afA| handles. The Ariadne ratio then \nis . In short, Ariadne |SA.S\u00afA.UA|found a substantial fraction of the exceptions and resolved 76 82% \nof the queries that Z3 was unable to handle. The Unique exception .eld shows [X,Y ], where X is the number \nof exception locations and Y is the number of unique input to exception location pairs found by Z3 -AR \nI A D N E only at the speci.ed loop bound. In the case of the number of input to location pairs, only \nthe pair is unique, not the path it take nor the exception it reaches. At loop bound 64, the unique exception \n.eld in Table 5 contains [3,145]. This means that the analysis discovered 3 exceptions that it did not \nalso .nd at another bound and 145 input to exception pairs, found only at this bound. The Shared also \nreports exceptions and paths to exceptions, but without the constraint that those exceptions and input \nto exception pairs were only discovered at the speci.ed loop bound. Our analysis is embarrassingly parallelizable, \nso the test harness partitions the functions onto available cores (in our case 18), then analyzes each \nfunction, one by one, against each loop bound. It records the analysis time per function per loop bound. \nThe sum of all the analysis times for all the functions at each loop bound is reported in the total time \ncolumn. Again, we see that, with our corpus, the loop bound does not have much impact on analysis time. \n 5.3 Classifying Over.ows and Under.ows Some over.ows and under.ows (X.ows) are an unavoidable con\u00adsequence \nof .nite precision. The addition O + O is a case in point. Some X.ows, however, may be avoided by changing \nthe order of evaluation in or outright replacing the algorithm used to compute a solution. Because a \ndeveloper s time is precious, we introduce the avoidable X.ow classi.er to distinguish potentially avoidable \nX.ows from those that are not. Let A : Fn . F be an algorithm implemented using .oating\u00adpoint and A be \nthat same algorithm implemented using arbitrary Table 5: The results of Z3 -A R I A DNE s analysis of \nthe 467 GSL special functions at the speci.ed loop bounds. Here, Q is the set of all queries issued during \nanalysis and S, S and U partition Q into its SAT, UNSAT and UNKNOWN queries.  Loop Bound No Timeout \nAll Paths Explored No Exception Discovered |S||Q| | \u00afS||Q| |U||Q| Ariadne Ratio Exceptions Unique Shared \nTotal Time (hours) in.nity 363 136 45 0.57 0.30 0.13 0.76 [20,174] [636,847] 89 64 370 149 54 0.57 0.32 \n0.11 0.80 [3,145] [658,874] 85 32 368 149 54 0.57 0.32 0.11 0.81 [1,162] [651,859] 87 16 367 149 54 0.57 \n0.32 0.11 0.81 [0,142] [652,858] 87 8 368 149 54 0.57 0.32 0.11 0.81 [3,144] [652,862] 86 4 366 149 54 \n0.58 0.32 0.10 0.82 [0,138] [644,853] 89 2 367 149 54 0.56 0.33 0.11 0.81 [4,134] [644,863] 86 1 372 \n149 54 0.56 0.33 0.11 0.81 [4,144] [655,872] 84 \u00af Over.ows Under.ows Avoidable? 98 180 Total 155 217 \nRatio 0.63 0.83 Table 6: Potentially avoidable over.ows and under.ows. x precision arithmetic over Q. \nWhen A(i) over.ows or under.ows, x we deem that exception potentially avoidable if A (i) falls within \nx the range of normal .oating-point numbers, i.e. |A (i)| . [. ,O]. This classi.er rests on the intuition \nthat, if the evaluation of a .oating-point expression over arbitrary precision arithmetic falls within \nthe range of normal .oating-point numbers, then it may be possible to .nd an alternate expression that \nevaluates to that same result over .oating-point without generating intermediate values that trigger \n.oating-point exceptions. For example, consider Sterbenz av3, where x+ y-2 x . When x = -O, y = O, the \nsubtraction over.ows under .oating-point, but the .nal result is 0, a normal .oating-point number. Further, \nwe know that av1 is the algebraically equivalent (over the reals) expression x+y that, in this case, \ngenerates the correct 2 answer without intermediate over.ow. To realize our X.ow classi.er, we wrote \na transformer that takes a numeric program and replaces its float and double types with an arbitrary \nprecision rational type, for whose implementation we use mpq_t from GMP [14]. In addition to rewriting \ntypes, our arbitrary precision transformer also rewrites .oating-point opera\u00adtions into rational operations. \nFor instance, z = x + y becomes mpq_add(z,x,y). X.ows dominated the exceptions we found, comprising 91.9% \nof all exceptions. We de.ned and realized our classi.er with the aim of .ltering these X.ows. Nonetheless, \nthe number of potentially avoidable X.ows remains high in Table 6. Note that GSL is a worst case for \nus. In a numerical library such as the GSL, these ratios are high because the range of many mathematical \nfunctions is small but their implementation relies on .oating-point operations whose operands have extremal \nmagnitude. 6. Related Work Ariadne is related to the large body of work on symbolic execu\u00adtion [27], \nsuch as recent representative work on KLEE [7] and DART [18]. Our work directly builds on KLEE and uses \nits standard symbolic exploration strategy. To the best of our knowledge, it is the .rst symbolic execution \ntechnique applied to the detection of .oating-point runtime exceptions. We have proposed a novel pro\u00adgramming \ntransformation concept to reduce .oating-point analysis to reasoning on real arithmetic and developed \npractical techniques to solve nonlinear constraints. Our work is also closely related to the static analysis \nof numerical programs. The main difference of our work from these is our focus on bug detection rather \nthan proving the absence of error every exception we detect is a real exception, but we may miss some. \nWe next brie.y discuss representative efforts in this area. Majumdar et al. extended the Splat concolic \ntesting engine to support .oating-point and nonlinear constraints, then tackled the problems of path \ncoverage, range and robustness analysis [30]. Lakhotia et al. empirically evaluated two search-based \ntechniques for solving numerical constraints alternating variable method and evolution strategies [28]. \nTheir goal was to improve the solution of numerical constraints in general, not in our speci.c context \nof de\u00adtecting .oating-point exceptions. They found that these techniques do not decisively outperform \nPex custom solvers. Godefroid and Kinder observed that numerical operations rarely appear in condi\u00adtionals \nand therefore not in the path constraint [17]. They leverage this observation to build an analysis that \naims to prove the memory safety of .oating-point operations and the non-interference of the numeric and \nnon-numeric parts of the subject program. This is in marked contrast with our work, where our transformation \nexplicitly adds numeric conditions and solves the resulting constraints in order to detect .oating-point \nexceptions. Goubault [20] developed an abstract interpretation-based static analysis [5] to analyze errors \nintroduced by the approximation of .oating-point arithmetic. Goubault and Putot later re.ned this work \nwith a more precise abstract domain [21]. Brillout et al. encode .oating-point operations as functions \non bit vectors, then succes\u00adsively both over-and under-approximate the resulting formulae [2]. Martel \n[31] presents a general concrete semantics for .oating-point operations to explain the propagation of \nroundoff errors in a compu\u00adtation. In later work [32], Martel applies this concrete semantics and designed \na static analysis for checking the stability of loops [23]. Min\u00e9 [34] proposes an abstract interpretation-based \napproach to detect .oating point errors. Under.ows and round-off errors are considered tolerable and \nthus not considered real run-time errors. Monniaux [35] summarizes the typical errors when using program \nanalysis techniques to detect bugs in or verify correctness of nu\u00admerical programs. Astree [6] statically \nanalyzes C programs and attempts to prove the absence of over.ows and other runtime errors, both over \nintegers and .oating-point numbers. Also related are different approaches to model the .oating point \ncomputation for numerical programs. Fang et al. [11, 12] propose the use of af.ne arithmetic to model \n.oating-point errors. Darulova et al. augment Scala with two new data types: Af.neFloat, which computes \nerror bounds while remaining compatible with the Double type and SmartFloat, which generalizes Af.neFloat \nto sets of inputs [8]. Two projects that address .oating-point accuracy problems are Fluctuat [10] and \na recent paper that dynamically shadows .oating-point values and operations with higher precision operands \nand operators in order to detect accuracy loss, catastrophic cancellation in particular [1]. Ariadne \ncomplements these papers, since its focus is the detection of .oating-point exceptions, not .oating-point \naccuracy.  7. Conclusion and Future Work We have presented our design and implementation of Ariadne, \na symbolic execution engine for detecting .oating-point runtime exceptions. We have also reported our \nextensive evaluation of Ariadne over a few hundred GSL scalar functions. Our results show that Ariadne \nis practical, primarily enabled by our novel combination of program rewriting to expose .oating-point \nexceptional conditions and techniques for nonlinear constraint solving. Our immediate future work is \nto publicly release the tool to bene.t numerical software developers. We would also like to investigate \napproaches to support non-scalar functions, such as those functions that accept or return vectors or \nmatrices. 8. Acknowledgments We thank Jian Zhang, Mark Gabel, David Hamilton, and the anony\u00admous reviewers \nfor constructive feedback on earlier drafts of this paper. We also thank Zhaojun Bai, William M. Kahan, \nand Ren-Cang Li for helpful discussions on this work. This research was supported in part by NSF (grants \n0702622, 0917392, and 1117603) and the US Air Force (grant FA9550-07-1-0532). The information presented \nhere does not necessarily re.ect the position or the policy of the government and no of.cial endorsement \nshould be inferred. References [1] F. Benz, A. Hildebrandt, and S. Hack. A dynamic program analysis to \n.nd .oating-point accuracy problems. In PLDI, 2012. [2] A. Brillout, D. Kroening, and T. Wahl. Mixed \nabstractions for .oating\u00adpoint arithmetic. In FMCAD, 2009. [3] CNN. Toyota: Software to blame for Prius \nbrake prob\u00adlems. http://www.cnn.com/2010/WORLD/asiapcf/02/ 04/japan.prius.complaints/index.html. [4] \nP. Collingbourne, C. Cadar, and P. H. Kelly. Symbolic crosschecking of .oating-point and SIMD code. In \nEuroSys, 2011. [5] P. Cousot and R. Cousot. Abstract interpretation: A uni.ed lattice model for static \nanalysis of programs by construction or approximation of .xpoints. In POPL, 1977. [6] P. Cousot, R. Cousot, \nJ. Feret, L. Mauborgne, A. Min\u00e9, D. Monniaux, and X. Rival. The ASTR\u00c9E analyzer. In ESOP, 2005. [7] D. \nE. Daniel Dunbar, Cristian Cadar. KLEE: Unassisted and automatic generation of high-coverage tests for \ncomplex systems programs. In OSDI, 2008. [8] E. Darulova and V. Kuncak. Trustworthy numerical computation \nin Scala. In OOPSLA, 2011. [9] L. De Moura and N. Bj\u00f8rner. Z3: An ef.cient SMT solver. In TACAS, 2008. \n[10] D. Delmas, E. Goubault, S. Putot, J. Souyris, K. Tekkal, and F. V\u00e9drine. Towards an industrial use \nof FLUCTUAT on safety-critical avionics software. In FMICS, 2009. [11] C. F. Fang, T. Chen, and R. A. \nRutenbar. Floating-point error analysis based on af.ne arithmetic. In ICASSP, 2003. [12] C. F. Fang, \nR. A. Rutenbar, M. P\u00fcschel, and T. Chen. Toward ef.cient static analysis of .nite-precision effects in \nDSP applications via af.ne arithmetic modeling. In DAC, 2003. [13] M. Fr\u00e4nzle, C. Herde, T. Teige, S. \nRatschan, and T. Schubert. Ef.cient solving of large non-linear arithmetic constraint systems with complex \nBoolean structure. JSAT, 1(3-4):209 236, 2007. [14] FSF. GMP: The GNU multiple precision arithmetic library. \n/http: //gmplib.org/. [15] FSF. GSL: GNU scienti.c library. http://www.gnu.org/s/ gsl/. [16] V. Ganesh \nand D. L. Dill. A decision procedure for bit-vectors and arrays. In CAV, 2007. [17] P. Godefroid and \nJ. Kinder. Proving memory safety of .oating-point computations by combining static and dynamic program \nanalysis. In ISSTA, 2010. [18] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed automated random \ntesting. In PLDI, 2005. [19] D. Goldberg. What every computer scientist should know about .oating-point \narithmetic. ACM Computing Surveys, 23(1), 1991. [20] E. Goubault. Static analyses of the precision of \n.oating-point opera\u00adtions. In SAS, 2001. [21] E. Goubault and S. Putot. Static analysis of numerical \nalgorithms. In SAS, 2006. [22] J. Hauser. Handling .oating-point exceptions in numeric programs. TOPLAS, \n18(2), 1996. [23] N. J. Higham. Accuracy and stability of numerical algorithms. Society for Industrial \nand Applied Mathematics, 2nd edition, 2002. [24] IEEE Computer Society. IEEE standard for .oating-point \narithmetic, 2008. [25] D. Jovanovi c and L. de Moura. \u00b4Solving non-linear arithmetic. In IJCAR, 2012. \n[26] W. Kahan. A demonstration of presubstitution for 8/8 (Grail), 2005. [27] J. C. King. Symbolic execution \nand program testing. Communications of the ACM, 19, 1976. [28] K. Lakhotia, N. Tillmann, M. Harman, and \nJ. De Halleux. FloPSy: search-based .oating point constraint solving for symbolic execution. In ICTSS, \n2010. [29] C. Lattner and V. Adve. LLVM: A compilation framework for lifelong program analysis &#38; \ntransformation. In CGO, 2004. [30] R. Majumdar, I. Saha, and Z. Wang. Systematic testing for control \napplications. In MEMOCODE, 2010. [31] M. Martel. Propagation of roundoff errors in .nite precision computa\u00adtions: \na semantics approach. In ESOP, 2002. [32] M. Martel. Static analysis of the numerical stability of loops. \nIn SAS, 2002. [33] Z. Merali. Computational science: ...error ...why scienti.c program\u00adming does not \ncompute. Nature, 467:775 777, 2010. [34] A. Min\u00e9. Relational abstract domains for the detection of .oating-point \nrun-time errors. In ESOP, 2004. [35] D. Monniaux. The pitfalls of verifying .oating-point computations. \nTOPLAS, 30(3):12:1 12:41, 2008. [36] K. L. Palmerius. Fast and high precision volume haptics. In Proceed\u00adings \nof the IEEE World Haptics Conference. IEEE, 2007. [37] P. R\u00fcmmer and T. Wahl. An SMT-LIB theory of binary \n.oating-point arithmetic. In SMT at FLoC, 2010. [38] K. Sen. CUTE: a concolic unit testing engine for \nC. In FSE, 2005. [39] P. H. Sterbenz. Floating-Point Computation. Prentice-Hall, 1974. [40] Wikipedia. \nAriane 5 .ight 501. http://en.wikipedia.org/ wiki/Ariane_5_Flight_501.    \n\t\t\t", "proc_id": "2429069", "abstract": "<p>It is well-known that floating-point exceptions can be disastrous and writing exception-free numerical programs is very difficult. Thus, it is important to automatically detect such errors. In this paper, we present Ariadne, a practical symbolic execution system specifically designed and implemented for detecting floating-point exceptions. Ariadne systematically transforms a numerical program to explicitly check each exception triggering condition. Ariadne symbolically executes the transformed program using real arithmetic to find candidate real-valued inputs that can reach and trigger an exception. Ariadne converts each candidate input into a floating-point number, then tests it against the original program. In general, approximating floating-point arithmetic with real arithmetic can change paths from feasible to infeasible and vice versa. The key insight of this work is that, for the problem of detecting floating-point exceptions, this approximation works well in practice because, if one input reaches an exception, many are likely to, and at least one of them will do so over both floating-point and real arithmetic. To realize Ariadne, we also devised a novel, practical linearization technique to solve nonlinear constraints. We extensively evaluated Ariadne over 467 scalar functions in the widely used GNU Scientific Library (GSL). Our results show that Ariadne is practical and identifies a large number of real runtime exceptions in GSL. The GSL developers confirmed our preliminary findings and look forward to Ariadne's public release, which we plan to do in the near future.</p>", "authors": [{"name": "Earl T. Barr", "author_profile_id": "81300234801", "affiliation": "University of California, Davis, Davis, CA, USA", "person_id": "P3978055", "email_address": "etbarr@ucdavis.edu", "orcid_id": ""}, {"name": "Thanh Vo", "author_profile_id": "81553065856", "affiliation": "University of California, Davis, Davis, CA, USA", "person_id": "P3978056", "email_address": "vo@ucdavis.edu", "orcid_id": ""}, {"name": "Vu Le", "author_profile_id": "81553124856", "affiliation": "University of California, Davis, Davis, CA, USA", "person_id": "P3978057", "email_address": "vmle@ucdavis.edu", "orcid_id": ""}, {"name": "Zhendong Su", "author_profile_id": "81100108298", "affiliation": "University of California, Davis, Davis, CA, USA", "person_id": "P3978058", "email_address": "su@ucdavis.edu", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429133", "year": "2013", "article_id": "2429133", "conference": "POPL", "title": "Automatic detection of floating-point exceptions", "url": "http://dl.acm.org/citation.cfm?id=2429133"}