{"article_publication_date": "01-23-2013", "fulltext": "\n A Theorem Prover for Boolean BI Jonghyun Park Jeongbong Seo Sungwoo Park Department of Computer Science \nand Engineering Pohang University of Science and Technology (POSTECH) Republic of Korea {parjong,baramseo,gla}@postech.ac.kr \nAbstract While separation logic is acknowledged as an enabling technology for large-scale program veri.cation, \nmost of the existing veri.ca\u00adtion tools use only a fragment of separation logic that excludes sep\u00adarating \nimplication. As the .rst step towards a veri.cation tool us\u00ading full separation logic, we develop a nested \nsequent calculus for Boolean BI (Bunched Implications), the underlying theory of sep\u00adaration logic, as \nwell as a theorem prover based on it. A salient fea\u00adture of our nested sequent calculus is that its sequent \nmay have not only smaller child sequents but also multiple parent sequents, thus producing a graph structure \nof sequents instead of a tree structure. Our theorem prover is based on backward search in a re.nement \nof the nested sequent calculus in which weakening and contraction are built into all the inference rules. \nWe explain the details of de\u00adsigning our theorem prover and provide empirical evidence of its practicality. \nCategories and Subject Descriptors F.4.1 [Mathematical Logic]: Mechanical theorem proving, Proof theory \nGeneral Terms Veri.cation Keywords Separation logic, Boolean BI, Theorem prover, Nested sequent calculus \n  1. Introduction 1.1 Separation logic Separation logic [36] is an extension of Hoare logic which facili\u00adtates \nreasoning about programs using mutable data structures. As it is acknowledged as an enabling technology \nfor large-scale program veri.cation [7, 31, 38], researchers have developed automated ver\u00adi.cation tools \nthat use separation logic as their foundational theory. Examples of such tools include Smallfoot [4], \nSpace Invader [15], THOR [30], SLAyer [6], HIP [33], VeriFast [26], jStar [14], and Xisa [13]. The active \ndevelopment of such tools attests to the im\u00adportance of local reasoning in program veri.cation, which \nis pre\u00adcisely the key feature that separation logic intends to support. All the aforementioned tools, \nhowever, use not full separation logic but only a decidable fragment by Berdine et al. [3] or its ex\u00adtension. \nSpeci.cally separation logic features two new logical con\u00adnectives, separating conjunction * and separating \nimplication -*, Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. POPL 13, January 23 25, 2013, Rome, Italy. Copyright c &#38;#169; 2013 ACM 978-1-4503-1832-7/13/01. \n. . $10.00 but this decidable fragment includes only separating conjunction. Lack of separating implication \nimplies that for any program per\u00adforming heap mutation or allocation, there is no support for back\u00adward \nreasoning by weakest precondition generation, an essential requirement for any complete program veri.cation \nsystem (see Ish\u00adtiaq and O Hearn [25]). Thus, while very effective in their respec\u00adtive application domains, \nthese tools allow only forward reasoning based on symbolic execution as in [5] and fail to demonstrate \nthe full potential of separation logic in program veri.cation. Omitting separating implication is not \na deliberate decision. Rather it is an inevitable decision due to the availability of no theorem prover \nfor full separation logic. Berdine et al. [5] suggest that such a theorem prover is highly desirable \nand can evolve into a complete program veri.cation system based on separation logic: This incompleteness \ncould be dealt with if we instead used the backwards-running weakest preconditions of Separation Logic. \nUnfortunately, there is no existing automatic theo\u00adrem prover which can deal with the form of these asser\u00adtions \n(which use quanti.cation and the separating implica\u00adtion -* ). If there were such a prover, we would \nbe eager consumers of it. Still, however, there is no practical theorem prover for full separa\u00adtion \nlogic. Our long-term goal is to develop a theorem prover for full sep\u00adaration logic and incorporate it \ninto a program veri.cation sys\u00adtem supporting backward reasoning. The .rst step is then to study Boolean \nBI, the underlying theory of separation logic. 1.2 Boolean BI Boolean BI is a substructural logic which \nbelongs to the family of the logic of BI (Bunched Implications) of O Hearn and Pym [34]. It inherits \nadditive connectives from classical propositional logic, thus retaining the convenience of classical \nreasoning. It is also par\u00adticularly suitable for reasoning about local resources because of multiplicative \nconnectives inherited from intuitionistic linear logic. Like other members in the family, Boolean BI \nallows us to con\u00adsider free combinations of these additive connectives and multi\u00adplicative connectives, \ngiving rise to an unusual form of contexts called bunches: trees whose internal nodes specify whether \nsub\u00adtrees are combined additively or multiplicatively. We obtain sepa\u00adration logic as a model for Boolean \nBI based on a monoid of heaps. While theoretical work on Boolean BI is maturing with recent discoveries \nof its undecidability [11, 29], there is still no practical theorem prover for Boolean BI. The display \ncalculus for Boolean BI by Brotherston [10], which draws on the framework of display logic by Belnap \n[1], has the cut elimination property and thus can be easily turned into a theorem prover, but developing \na practical proof search strategy on top of it does not seem to be easy because of the complexity due \nto its display rules [9]. In order to develop a practical theorem prover for Boolean BI and hence also \nfor full separation logic, we choose to develop another proof theory that directly re.ects the characteristics \nof Boolean BI and lends itself well to proof search. This paper presents such a proof theory for Boolean \nBI as well as a theorem prover based on it.  1.3 Contribution We present a nested sequent calculus SBBI \nfor Boolean BI. Un\u00adlike in typical nested sequent calculi [12, 22 24, 27], its sequent may have not only \nsmaller child sequents but also multiple parent sequents, thus producing a graph structure of sequents \ninstead of a tree structure. The use of nested sequents is necessary because of the presence of intuitionistic \nmultiplicative conjunction in a clas\u00adsical setting. The use of a graph structure of sequents is necessary \nbecause of the interaction between multiplicative implication and classical negation. As in typical multi-conclusioned \nsequent calculi for classical logic, we use multisets of formulas not only for an\u00adtecedents but also \nfor succedents of a sequent. Thus sequents in SBBI do not use bunches, which are supplanted by new structural \nconnectives specifying a graph structure of sequents. SBBI has the cut elimination property and is sound \nand complete with respect to the Kripke semantics for Boolean BI. Our theorem prover for Boolean BI is \nbased on backward proof search in another nested sequent calculus CSBBI which is ob\u00adtained from SBBI \nby building weakening and contraction into all the inference rules. In conjunction with a graph structure \nof se\u00adquents, the structural rules in CSBBI make it particularly challeng\u00ading to devise a practical proof \nsearch strategy, even if it is based on backward proof search. We deal with an explosion in the search \nspace due to the structural rules, which can be applied inde.nitely and exponentially increase the search \nspace, by prioritizing their applications. We .nd that our theorem prover is reasonably fast in proving \ntypical formulas of Boolean BI. To the best of our knowl\u00adedge, our theorem prover is the .rst theorem \nprover for Boolean BI. 1.4 Organization of the paper Section 2 gives preliminaries on Boolean BI. Section \n3 presents the nested sequent calculus SBBI and the satisfaction relation for its sequents. Section 4 \nproves the cut elimination property of SBBI, and Section 5 proves the soundness and completeness of SBBI \nwith respect to the satisfaction relation as well as the Kripke semantics for Boolean BI. Section 6 reviews \nthe display calculus for Boolean BI by Brotherston [10] and shows that SBBI is an optimization of the \ndisplay calculus. Section 7 presents the nested sequent calculus CSBBI. Section 8 describes the backward \nsearch strategy in our theorem prover and presents experimental results. Section 9 dis\u00adcusses related \nwork and Section 10 concludes. Our theorem prover (with an online demo) and accompanying technical report \nare avail\u00adable at http://pl.postech.ac.kr/BBI/.  2. Preliminaries on Boolean BI Formulas in Boolean \nBI extend classical propositional logic with multiplicative connectives from linear logic: formula A \n::= P |. |\u00acA | A . A | I | A* A | A -*A P denotes an atomic formula drawn from a set V . I is the multi\u00adplicative \nunit. A*B is a multiplicative conjunction and A -*B is a multiplicative implication. We de.ne T as \u00ac., \nA . B as \u00ac(\u00acA .\u00acB),and A . B as \u00acA . B. We use conventional precedence rules for logical connectives: \n\u00ac > .,* > . > ., -*. The Kripke semantics of Boolean BI [17] uses a non-deterministic commutative monoid \non a set U. Assume a binary operator w, . |= P iff. w . .(P ) w, . |= . iff. never w, . |= \u00acA iff. w, \n. |= A w, . |= A . B iff. w, . |= A or w, . |= B w, . |= I iff. w = e w, . |= A* B iff. .w1,w2 . U such \nthat w . w1 . w2 and w1,. |= A and w2,. |= B w, . |= A -*B iff. .w1 . U. w1,. |= A implies .w2 . w . \nw1.w2,. |= B Figure 1. Satisfaction relation w, . |= A for formulas (Axiom 1) f A . I *A (Axiom 2) f \nI *A . A (Axiom 3) f A* B . B* A (Axiom 4) f A* (B* C ) . (A* B ) *C f A1 . A2 f B1 . B2 *Hf (A1 *B1) \n. (A2 *B2) f (A* B ) . C f A . (B -*C) -*H1 -*H2 f A . (B -*C) f (A* B ) . C Figure 2. Axioms and inference \nrules for multiplicative connec\u00adtives in the Hilbert system for Boolean BI . : U \u00d7 U .P(U) and a unit \nelement e . U (where P(U) de\u00adnotes the power set of U). We extend . to a binary operator on P(U) such \nthat U1 . U2 = .{w1 . w2 | w1 . U1,w2 . U2}.A non-deterministic commutative monoid is a triple (U, .,e) \nwhich satis.es the following conditions: (neutrality) .w . U. w . e = {w}(commutativity) .w1,w2 . U. \nw1 . w2 = w2 . w1 (associativity) .w1,w2,w3 . U. w1 . (w2 . w3)= (w1 . w2) . w3 Given a non-deterministic \ncommutative monoid (U, .,e) and a valuation . : V .P(U) of atomic formulas, we obtain the Kripke semantics \nof Boolean BI from the satisfaction relation w, . |= A for formulas given in Figure 1. The satisfaction \nrelation w, . |= A is de.ned inductively on the structure of formula A. A formula A is valid, written \n|= A,if w, . |= A holds for any element w and valuation .. The Hilbert system for Boolean BI [35] uses \na judgment f A and is obtained by extending classical propositional logic with axioms and inference rules \nfor multiplicative connectives given in Figure 2. An induction on the structure of the proof of f A proves \nthe soundness of the Hilbert system with respect to the Kripke semantics of Boolean BI. Galmiche and \nLarchey-Wendling [17] prove that the Hilbert system is also complete with respect to the Kripke semantics \nof Boolean BI. Theorem 2.1. |= A if and only if f A. 3. Nested sequent calculus SBBI for Boolean BI \nThis section presents the nested sequent calculus SBBI for Boolean BI. We .rst explain the de.nition \nof sequents in SBBI.Then we present the satisfaction relation for sequents and the inference rules of \nSBBI. 3.1 Nested sequents A sequent in SBBI represents a graph structure whose nodes store sequents in \nclassical logic. A node can have multiple parent nodes Figure 3. An example of a graph structure of nodes \nin SBBI (p for parent, c for child, s for sibling)  as well as multiple child nodes, but the following \ntwo relations should always hold: 1. A node can have multiple parent nodes, but each parent node determines \na unique sibling node. Hence no node can have two parent nodes with the same sibling node. 2. A node \ncan have multiple child nodes, but each child node determines another unique child node. Hence we can \ndivide all child nodes into groups of two sibling nodes.  Formally a sequent W describes a graph structure \nwith respect to a certain node in it, which we refer to as the reference node. It consists of a truth \ncontext and a falsehood context. A truth context contains node states which are either true formulas \nspeci.c to the reference node or descriptions of its relation to child, sibling, and parent nodes; a \nfalsehood context contains false formulas speci.c to the reference node: sequent W = G . . truth context \nG ::= \u00b7| G; S falsehood context . ::= \u00b7| .; A node state S ::= A |\u00d8m | W, W | W ((W )) We use truth contexts \nand falsehood contexts as unordered sets and do not use an additive zero (like \u00d8a in the de.nition of \nbunches). \u00d8m is a special node state which corresponds to the unit element of the monoid in the Kripke \nsemantics of Boolean BI. A multiplicative pair W, W ' asserts the existence of a pair of child nodes \nwhich are reference nodes of W and W '.An adjoint pair W ((W ')) asserts the existence of a sibling node \nand a common parent node which are reference nodes of W and W ', respectively. Note that a sequent in \nSBBI reverts to a sequent in classical logic if we leave only true formulas in its truth context. The \nuse of adjoint pairs implies that we can describe the same graph structure of nodes using different sequents \nby changing the reference node. As an example, consider the graph structure in Figure 3 where lines denote \nparent-child relations and arcs denote sibling relations. We let G' = Ws1((Wp1));(Wc3,Wc4).Then the following \nthree sequents describe the same graph structure in Figure 3, but all use different reference nodes (top \nright, center, and bottom left): Gp2;(G;G';(Gc1 . .c1,Wc2) . .,Ws2) . .p2 G; G';(Gc1 . .c1,Wc2); Ws2((Gp2 \n. .p2)) . . Gc1; Wc2((G; G'; Ws2((Gp2 . .p2)) . .)) . .c1 SBBI provides two inference rules which convert \na sequent into another equivalent sequent by changing the reference node. Our de.nition of sequents in \nSBBI embodies the principle of proof by contradiction from classical logic: a proof of a sequent means \nthat its truth and falsehood contexts together lead to a logical contradiction. This departure from the \nstandard interpretation of se\u00adquents for classical logic (in which the conjunction of antecedents implies \nthe disjunction of succedents) is intentional, as the princi\u00adple of proof by contradiction guides the \ndevelopment of both the satisfaction relation and the rules for SBBI.  3.2 Satisfaction relation for \nsequents Given a non-deterministic commutative monoid (U, .,e) and a valuation . : V .P(U) of atomic \nformulas, we can de.ne the satisfaction relation w, . |=W W for sequents. It uses another satisfaction \nrelation w, . |=S S for node states and the satisfaction relation w, . |= A for formulas: { .S . G.w, \n. |=S S w, . |=W G . . iff. .A . ..w, . |= A The satisfaction relation w, . |=S S for node states is \nde.ned as follows: w, . |=S A iff. w, . |= A w, . |=S \u00d8m iff. w = e w, . |=S W1,W2 iff. .w1,w2 . U such \nthat w . w1 . w2 and w1,. |=W W1 and w2,. |=W W2 w, . |=S W1((W2)) iff. .w1,w2 . U such that w2 . w . \nw1 and w1,. |=W W1 and w2,. |=W W2 Note that the satisfaction relation for multiplicative formulas can \nbe rewritten in terms of the satisfaction relation for node states as follows: w, . |= I iff. w, . |=S \n\u00d8m.  w, . |= A* B iff. w, . |=S (A .\u00b7), (B .\u00b7).  w, . |= A -*B iff. w, . |=S (A .\u00b7)((\u00b7 . B)).  If \nw, . |=W W holds for any element w and valuation .,we say that W is unsatis.able and write |=W W . 3.3 \nNested sequent calculus SBBI Figure 4 shows the nested sequent calculus SBBI for Boolean BI. The inference \nrules are divided into three groups: structural rules, traverse rules, and logical rules. We read every \nrule from the conclusion to the premise. A structural rule makes a change to the sequent in the conclu\u00adsion, \nbut does not change the reference node. The rules WLS, WRS , CLS ,and CRS are weakening and contraction \nrules. The rules ECS and EAS rewrite a node state according to commutativity and as\u00adsociativity of sequents, \nrespectively. Note that associativity of se\u00adquents does not use (W1,W2),W3 and W1, (W2,W3), both of which \nare syntactically ill-formed. The rule \u00d8mUS creates a new child node with a special form of sequent \u00d8m \n.\u00b7, which can be absorbed back into the parent node by the rule \u00d8mDS . Intuitively \u00d8m .\u00b7 describes an \nempty node whose sibling node can be identi\u00ad.ed with its parent node. A traverse rule changes the reference \nnode without changing parent-child or sibling relations between nodes. The rules TCS and TPS promote \nthe left child node (corresponding to Gc1 . .c1) and the parent node (corresponding to Gp . .p), respectively, \nas the new reference node. In conjunction with the rule ECS ,the two traverse rules enable us to designate \nan arbitrary node as the reference node because every pair of nodes can be connected only via parent-child \nrelations. The following example shows how to promote the sibling node as the reference node: Gs;(G . \n.)((Gp . .p)) . .s TCS Gp;(Gs . .s), (G . .) . .p ECS Gp;(G . .), (Gs . .s) . .p TPS G; (Gs . .s)((Gp \n. .p)) . . A logical rule focuses on a principal formula in the reference node. If the sequent already \nexpresses a logical contradiction, it Structural rules: G . . G . . G; S; S . . G . .; A; A G; W ' \n,W . . WLS WRS CLS CRS ECS ' G; S . . G . .; A G; S . . G . .; A G; W, W . . G; W1, (W2,W3 .\u00b7) . . G1;(G2 \n. .2), (\u00d8m .\u00b7) . .1 G1;G2 . .1;.2EAS \u00d8mUS \u00d8mDSG; (W1,W2 .\u00b7),W3 . . G1;G2 . .1;.2 G1;(G2 . .2), (\u00d8m .\u00b7) \n. .1 Traverse rules: Gc1;(Gc2 . .c2)((G . .)) . .c1 Gp;(G . .), (Gs . .s) . .p TCS TPS G; (Gc1 . .c1), \n(Gc2 . .c2) . . G; (Gs . .s)((Gp . .p)) . . (p for parent, c for child, s for sibling) Logical rules: \nG . . G . .; A G; A . . G1; A . .1 G2; B . .2 Init S .LS .RS \u00acLS \u00acRS .LS A . A ..\u00b7 G . .; . G; \u00acA . . \nG . .; \u00acA G1;G2; A . B . .1;.2 G . .; A; B G; \u00d8m . . G; (A .\u00b7), (B .\u00b7) . . .RS ILS IRS *LS G . .; A . \nB G; I . . \u00d8m . I G; A* B . . G1 . .1; A G2 . .2; B G1 . .1; A G2; B . .2 G; (A .\u00b7)((\u00b7 . B)) . . *RS \n-*LS -*RS (G1 . .1), (G2 . .2) . A* B (G1 . .1)((G2 . .2)); A -*B .\u00b7 G . .; A -*B Figure 4. Nested sequent \ncalculus SBBI for Boolean BI completes the proof without generating a premise. All the rules from Init \nS to .RS are from classical propositional logic. The rule Init S expresses the principle of proof by \ncontradiction. The rules ILS and IRS use the fact that I is true only in an empty node which \u00d8m describes. \nThe rules *LS and *RS are based on the following interpretation of multiplicative conjunction *: w, . \n|= A*B iff. .w1,w2 . U such that w . w1 . w2 and w1,. |= A and w2,. |= B w, . |= A*B iff. .w1,w2 . U. \nw . w1 . w2 implies w1,. |= A or w2,. |= B The rule *LS creates (.) two fresh child nodes (corresponding \nto w1 and w2)where A and B are true, respectively, which explains why we need to use nested sequents. \nThe rule *RS chooses (.) two existing child nodes (corresponding to w1 and w2)which are described by \nG1 . .1 and G2 . .2.The rules -*LS and -*RS are based on the following interpretation of multiplicative \nimplication -*: w, . |= A -*B iff. .w1 . U. w1,. |= A implies .w2 . w . w1.w2,. |= B w, . |= A -*B iff. \n.w1,w2 . U such that w2 . w . w1 and w1,. |= A and w2,. |= B The rule -*LS chooses (.) existing sibling \nand parent nodes (cor\u00adresponding to w1 and w2) which are described by G1 . .1 and G2 . .2.The rule -*RS \ncreates (.) a fresh sibling node (corre\u00adsponding to w1)where A is true and a fresh parent node (corre\u00adsponding \nto w2)where B is false, which explains why we need to allow multiple parent nodes. Figure 5 shows an \nexample of proving A . (A* B) . (A* \u00acB) in SBBI. The formula means that every node can have an adjacent \nnode in which either B or \u00acB is true. First we apply the rule \u00d8mUS to create an empty node, described \nby \u00d8m .\u00b7, in which we later mix assumptions of B and \u00acB to produce a logical contradiction: (A .\u00b7), \n(\u00d8m .\u00b7) . A* B; A* \u00acB Then we extend the truth context of the empty node with a node state S describing \nthe current relation with its sibling and parent nodes: (A .\u00b7), (\u00d8m; S .\u00b7) . A* B; A* \u00acB Here we promote \nthe empty node as the reference node to generate S and apply the contraction rule CLS to duplicate S. \nAfter isolating the sequent for the empty node and adding B to its falsehood context, we consume S in \n\u00d8m; S . B (by the rule TPS )to restore Init S 15 B . B WLS 14 \u00d8m; B . B \u00acRS 13 Init S 12 A . A \u00d8m . \nB; \u00acB *RS 11 (A .\u00b7), (\u00d8m . B) . A* \u00acB WRS 10 (A .\u00b7), (\u00d8m . B) . A* B; A* \u00acB } ECS 9 (\u00d8m . B), (A .\u00b7) \n. A* B; A* \u00acB Init S 8 TPS A . A \u00d8m; S . B *RS 7 (A .\u00b7), (\u00d8m; S .\u00b7) . A* B WRS 6 (A .\u00b7), (\u00d8m; S .\u00b7) \n. A* B ; A* \u00acB } ECS (\u00d8m; S .\u00b7), (A .\u00b7) . A* B ; A* \u00acB 5 TPS \u00d8m; S; S .\u00b7 CLS 4 \u00d8m; S .\u00b7 } TCS 3 (\u00d8m \n.\u00b7), (A .\u00b7) . A* B ; A* \u00acB ECS (A .\u00b7), (\u00d8m .\u00b7) . A* B ; A* \u00acB \u00d8mUS 2 A . A* B; A* \u00acB .RS 1 A . (A* B) \n. (A* \u00acB) where S =(A .\u00b7)((\u00b7 . A* B ; A* \u00acB)) Figure 5. A proof of A . (A* B) . (A* \u00acB) in SBBI.We \nnumber all proof steps for comparison with Figure 6. the previous relation between the empty node and \nits sibling and parent nodes: (A .\u00b7), (\u00d8m . B) . A* B; A* \u00acB Finally we add B to the truth context \nand produce a logical contra\u00addiction: \u00d8m; B . B  4. Cut elimination in SBBI We state the cut elimination \nproperty of SBBI as follows:1 Theorem 4.1 (Cut elimination). If G . .; C and G ' ; C . . ' ,then G; G \n' . .; . ' . 1 Strictly speaking, Theorem 4.1 states only the admissibility of the cut rule. The cut \nelimination property, however, immediately follows as a corollary and we refer to Theorem 4.1 as the \ncut elimination theorem. Section 6 gives an indirect proof of Theorem 4.1 which exploits the cut elimination \nproperty of the display calculus for Boolean BI [10]. Here we give a sketch of a direct proof which is \ninspired by the proof of cut elimination in original display logic [1]. The main complication in proving \nTheorem 4.1 is that the two contraction rules CLS and CRS duplicate a node state or a formula in their \npremise. In conjunction with the traverse rules, these con\u00adtraction rules can produce copies of the cut \nformula C in different (smaller) sequents within the same sequent, as in: G; (G1; Cn1 . .1),W1;(G2; Cn2 \n. .2),W2 . . Here Cn means a truth context containing n copies of C.To represent such a sequent containing \nsmaller sequents with copies of the cut formula, we introduce the following de.nitions: partial sequent \n. ::= [] | [; . . ] | G; . . . partial truth context . ::= s | s; . partial node state s ::= ., W | W, \n. | ., . |.((W )) | W ((.)) | .((.)) A partial sequent is a sequent with one or more holes in it; similarly \npartial truth contexts and partial node states contain one or more holes. We write .[W1] \u00b7\u00b7\u00b7 [Wn] for \nthe sequent obtained by .lling holes in . with sequents W1, \u00b7\u00b7\u00b7 ,Wn in that order; we de.ne .[W1] \u00b7\u00b7\u00b7 \n[Wn] and s[W1] \u00b7\u00b7\u00b7 [Wn] in a similar way: .[W1] \u00b7\u00b7 \u00b7 [Wn]= . W1 where . =[],n =1 . . G1; .[W2] \u00b7\u00b7 \u00b7 [Wn] \n. .1 where . =[; . . ], . n> 1,W1 =G1 . .1 . G; .[W1] \u00b7\u00b7\u00b7 [Wn] . . where . =G; . . . Note that [; . . \n] uses the .rst sequent to describe the reference node and remaining sequents to .ll the holes in .. \nThe proof of Theorem 4.1, which is inspired by the proof of cut elimination in display logic [1], proceeds \nby proving the follow\u00ading three lemmas. Here we say that /C/ holds if G . .; A and G ' ; A . . ' implies \nG; G ' . .; . ' for any proper subformula A of C. We also write G; C . . and G . .; C to indicate that \nC is the principal formula of the last inference rule in their proofs. The proof of Lemma 4.3 uses Lemma \n4.2, and the proof of Lemma 4.4 uses Lemma 4.3. Lemma 4.2. Suppose that /C/ holds. Then G . .; C and \nG ' ; C . . ' imply G; G ' . .; . ' . Lemma 4.3. Suppose that /C/ holds. Then .[G1 . .1; Cn1 ] \u00b7\u00b7 \u00b7 [Gk \n. .k; Cnk ] and G ' ; C . . ' imply .[G1;G ' . .1;. ' ] \u00b7\u00b7\u00b7 [Gk;G ' . .k;. ' ]. Lemma 4.4. Suppose that \n/C/ holds. Then G . .; C and .[G ' 1; Cn1 . .1 ' ] \u00b7\u00b7 \u00b7 [G ' k; Cnk . .k ' ] imply .[G; G ' 1 . .; . \n1 ' ] \u00b7\u00b7\u00b7 [G; G k ' . .; . k ' ]. Then we complete the proof of Theorem 4.1 by induction on the structure \nof the cut formula C.  5. Soundness and completeness of SBBI This section proves the soundness and completeness \nof the nested sequent calculus SBBI with respect to the satisfaction relation in Section 3.2 (Theorems \n5.1 and 5.2). It means that the syntactic provability of a sequent coincides with its semantic unsatis.ability, \ncon.rming the principle of proof by contradiction embodied in the de.nition of sequents. Theorem 5.1 \n(Soundness). If G . .,then |=W G . .. Theorem 5.2 (Completeness). If |=W G . .,then G . .. The proof \nof soundness proceeds by induction on the structure of the proof of G . .. The proof of completeness \nuses a translation of a sequent W into a formula [W ]w in Boolean BI de.ned as follows: [G . .]w = [G]g \n.\u00ac[.]d [\u00b7]g = T [\u00b7]d = . [G; S]g = [G]g . [S]s [.; A]d = [.]d . A [A]s = A [\u00d8m]s = I [W1,W2]s = [W1]w \n* [W2]w [W1((W2))]s = \u00ac([W1]w -* \u00ac[W2]w) Recall that a sequent W is a description of a set of nodes \nwith respect to a reference node. [W ]w is essentially the same descrip\u00adtion as W , except that it speci.es \nthe relationship between nodes through the use of multiplicative connectives * and -* and nega\u00adtion \u00ac. \n2 The translation is characterized by Propositions 5.3 and 5.4. Proposition 5.3. |=W W if and only if \n|= \u00ac[W ]w. Proposition 5.4. If \u00b7. \u00ac[G . .]w,then G . .. Propositions 5.3 and 5.4 allow us to complete \nthe proof of completeness if we additionally show that |= A implies \u00b7. A (for A = \u00ac[G . .]w). Since |= \nA implies f A by Theorem 2.1, it suf.ces to prove the following lemma, whose proof exploits the cut elimination \nproperty of SBBI (Theorem 4.1): Lemma 5.5. If f A,then \u00b7. A. The following corollary shows that SBBI \nis sound and complete with respect to the Kripke semantics in Section 2: Corollary 5.6. \u00b7. A if and only \nif |= A. 6. Display calculus for Boolean BI This section reviews the display calculus DLBBI for Boolean \nBI (without the cut rule) by Brotherston [10]. We establish the equivalence between SBBI and DLBBI,and \nshow that SBBI is an optimization of DLBBI. 6.1 De.nition and properties of DLBBI The display calculus \nDLBBI uses a judgment X fD Y , called a consecution, in its inference rules; X is called an A-structure \nand Y a C-structure: A-structure X ::= A |\u00d8a |\u00d8m | rY | X; X | X, X C-structure Y ::= A |\u00d8a | rX | Y \n; Y | X -Y A-structures are essentially an extension of bunches in Boolean BI with negative structures \nrY . C-structures do not use the multiplica\u00adtive unit \u00d8m and the multiplicative structural connective \n,, but intro\u00adduce a negative structural connective r and a multiplicative struc\u00adtural connective -which \nis originally from the display calculus for linear logic [2]. The inference rules of DLBBI are divided \ninto three groups: structural rules, display rules, and logical rules. Structural rules deal with the \nstructural properties of consecutions. Display rules introduce or eliminate rY , rX,and X -Y as necessary \nin order to display a target A-structure or C-structure as the sole element in the left or right side \nof a consecution. A logical rule focuses on a single formula that has already been displayed in the left \nor right side of a consecution by the display rules. We refer the reader to [10] for the inference rules \nof DLBBI. Brotherston [10] presents the following results on DLBBI:3 2 The de.nition shows that W1((W2)) \nis a meta-level operator correspond\u00ad ing to the logical connective septraction in [8, 37]. 3 Similarly \nto Theorem 4.1, Theorem 6.1 states only the admissibility of the cut rule, but we refer to it as the \ncut elimination theorem.  Theorem 6.1 (Cut elimination). If X fD A and A fD Y ,then X fD Y . Theorem \n6.2 (Soundness and completeness). \u00d8a fD A if and only if |= A.  6.2 Equivalence between SBBI and DLBBI \nAlthough the equivalence between SBBI and DLBBI is obvious from Corollary 5.6 and Theorem 6.2, it does \nnot illuminate how se\u00adquents and consecutions are related. Here we present direct trans\u00adlations between \nthe two calculi and study their similarities and dif\u00adferences. Given a consecution X fD Y , we translate \nA-structure X to a sequent [X]X and C-structure Y to another sequent [Y ]Y . Then we combine [X]X and \n[Y ]Y to build a single sequent [X fD Y ]C. Let us write (G . .)(G ' . . ' ) for G; G ' . .; . ' . We \nde.ne [X fD Y ]C as follows: [X fD Y ]C = [X]X [Y ]Y [A]X = A .\u00b7 [\u00d8a]X = \u00b7. \u00b7 [\u00d8m]X = \u00d8m .\u00b7 [rY ]X = \n[Y ]Y [X1; X2]X = [X1]X [X2]X [X1,X2]X = [X1]X , [X2]X .\u00b7 [A]Y = \u00b7. A [\u00d8a]Y = \u00b7. \u00b7 [rX]Y = [X]X [Y1; \nY2]Y = [Y1]Y [Y2]Y [X -Y ]Y = [X]X (([Y ]Y )) . \u00b7 Like sequents in SBBI, both A-structure X and C-structure \nY are essentially descriptions of a set of nodes, but formulas in X are regarded as true whereas formulas \nin Y as false in the reference node. We also observe that multiplicative structures X1,X2 and X -Y correspond \nto multiplicative pairs and adjoint pairs in SBBI. Lemma 6.3 shows that SBBI is as expressive as DLBBI: \nLemma 6.3. If X fD Y holds in DLBBI,then [X fD Y ]C holds in SBBI. Given a sequent G . ., we translate \nG to an A-structure [G]G and . to a C-structure [.]D. Then we combine [G]G and [.]D to another A-structure \n[G . .]W de.ned as follows: [G . .]W = [G]G; r[.]D [\u00b7]G = \u00d8a [G; S]G = [G]G; [S]S [A]S = [\u00d8m]S = [W1,W2]S \n= [W1((W2))]S = [\u00b7]D = \u00d8a [.; A]D = [.]D; A A \u00d8m [W1]W , [W2]W r([W1]W -r[W2]W ) [W ]W is de.ned in \na similar way to [W ]w giveninSection 5. For example, [W1,W2]S coincides with [W1,W2]s if we write , \nas *,and [W1((W2))]S coincides with [W1((W2))]s if we write r as \u00ac and -as -*. The comparison between \n[W ]W and [W ]w reveals a correspondence between structural connectives in DLBBI and logical connectives \nin Boolean BI that complies with the translation from DLBBI to Boolean BI given in [10]. Lemma 6.4 shows \nthat DLBBI is as expressive as SBBI.In conjunction with Lemma 6.3, it proves the equivalence between \nSBBI and DLBBI. Lemma 6.4. If G . .,then [G . .]W fD \u00d8a. With Lemmas 6.3 and 6.4, we can now give another \nindirect proof of Theorem 4.1 by exploiting Theorem 6.1. We need an additional lemma relating the two \ntranslations: Lemma 6.5. [[G]G]X =G .\u00b7 and [[.]D]Y = \u00b7. .. Proof of Theorem 4.1. Suppose G . .; C and \nG ' ; C . . ' . [G . .; C]W fD \u00d8a and [G ' ; C . . ' ]W fD \u00d8a by Lemma 6.4 [G]G; r[.]D fD C and C fD \nr[G ' ]G; [. ' ]D by the display rules and the rule \u00d8aRD [G]G; r[.]D fD r[G ' ]G; [. ' ]D by Theorem \n6.1 [G; G ' ]G fD [.; . ' ]D by the display rules [[G; G ' ]G fD [.; . ' ]D]C in SBBI by Lemma 6.3 G; \nG ' . .; . ' by Lemma 6.5 6.3 SBBI as an optimization of DLBBI The two translations in Section 6.2 suggest \nthat sequents in SBBI essentially represent a normal form of consecutions in DLBBI.We say that a consecution \nis of the normal form if it permits a negative structure rX only in the right side of -according to the \nrevised de.nition of C-structures: C-structure Y ::= A |\u00d8a | Y ; Y | X -rX It turns out that every consecution \nX fD Y can be converted by the structural rules (for associativity and \u00d8a) and the display rules to its \nnormal form [[X fD Y ]C]W fD \u00d8a, whose formulas form the same syntactic structure as the sequent [X fD \nY ]C. Thus we may think of sequents as representing consecutions of the normal form and SBBI as a sequent \ncalculus that directly manipulates such consecutions. Note that consecutions of the normal form in DLBBI \nstill require the negative structural connective r whereas SBBI requires no such negative structural \nconnective. Hence those display rules dealing with r have no counterparts in SBBI, which implies that \nproof searches in SBBI are always simpler than in DLBBI (except in trivial cases) because of the extra \ncost of applying such display rules in DLBBI. Figure 6 shows an example of proving in DLBBI the same \nfor\u00admula as in Figure 5. The proof search proceeds in a similar man\u00adner: .rst creating \u00d8m, next applying \na contraction rule to duplicate a C-structure, then consuming the C-structure, and .nally applying the \nrule Init D. We number each proof step to mark the correspon\u00addence between proof steps in Figures 5 and \n6. Note that the display rule MD1a D expands to a pair of a traverse rule (TCS or TPS)and the rule ECS \n(at proof steps 3, 5, and 9). We observe that DLBBI takes extra six proof steps all of which apply display \nrules (marked in rectangles). This example illustrates that SBBI is a formal sys\u00adtem which can be obtained \nfrom an optimization of DLBBI that dispenses with those display rules dealing with the negative struc\u00adtural \nconnective r and revises all the logical rules accordingly.  7. Nested sequent calculus CSBBI While \nthe presence of multiplicative connectives from intuitionis\u00adtic linear logic may suggest the inverse \nmethod for implementing a theorem prover for Boolean BI, the contraction property alone makes the inverse \nmethod not so ideal as it seems, as already ob\u00adserved in previous work on intuitionistic BI by Donnelly \net al.[16]. This is especially the case for SBBI, which, unlike sequent calculi for intuitionistic BI, \nneeds to use a graph structure of sequents in\u00adstead of a tree structure. For example, it is not clear \nhow to gen\u00aderate a minimal graph structure that weakens to a given pair of graph structures (for those \ninference rules with two sequents in the premise). Thus we choose to use a backward search strategy in \nour theorem prover. As the .rst step, we obtain the nested sequent calculus CSBBI (Contraction-free SBBI), \nshown in Figure 7, by embedding the weakening and contraction rules (WLS , WRS , CLS ,and CRS)into Structural \nrules: . G; (G ' ; W1,W2 . . ' ),W3; W1 . S1, (W2 . S2,W3 . S3 .\u00b7) . . . S1 = W2((G ' ; W3((G . .)) \n. . ' )) EAC where S2 = W1((G ' ; W3((G . .)) . . ' )) G; (G ' ; W1,W2 . . ' ),W3 . . . S3 =(G ' ; W1,W2 \n. . ' )((G . .)) G; W2,W1 . . G; (G . .), (\u00d8m .\u00b7) . . ECC \u00d8mUC G; W1,W2 . . G . . G; (G1 . .1), (G2; \n\u00d8m . .2); G1; S . .; .1 \u00d8mDC where S =(G2; \u00d8m . .2)((G . .)) G; (G1 . .1), (G2; \u00d8m . .2) . . Traverse \nrules: Gc1;(Gc2 . .c2)((G . .)) . .c1 Gp;(G . .), (Gs . .s) . .p TCC TPC G; (Gc1 . .c1), (Gc2 . .c2) \n. . G; (Gs . .s)((Gp . .p)) . . (p for parent, c for child, s for sibling) Logical rules: G . .; A G; \nA . . Init C .LC \u00acLC \u00acRC G; A . .; A G; .. . G; \u00acA . . G . .; \u00acA G; A . .G; B . . G . .; A; B G; \u00d8m . \n. .LC .RC ILC IRC G; A . B . . G . .; A . B G; I . . G; \u00d8m . .; I G; (A .\u00b7), (B .\u00b7) . . G; (G1 . .1; \nA), (G2 . .2) . .; A* B G; (G1 . .1), (G2 . .2; B) . .; A* B *LC *RC G; A* B . . G; (G1 . .1), (G2 . \n.2) . .; A* B G; (G1 . .1; A)((G2 . .2)); A -*B . .G; (G1 . .1)((G2; B . .2)); A -*B . . G; (A .\u00b7)((\u00b7 \n. B)) . . -*LC -*RC G; (G1 . .1)((G2 . .2)); A -*B . . G . .; A -*B Figure 7. Nested sequent calculus \nCSBBI.We de.ne (G . .) . S as G; S . . in the rule EAC. 15 Init D B fD B WLD 14 B; \u00d8m fD B AD1aD \u00d8m \nfD B; B AD2aD \u00d8m; B fD B 12 13 Init D \u00acRD A fD A \u00d8m; B fD \u00acB *RD 11 A, (\u00d8m; B) fD A* \u00acB WLD 10 (A, (\u00d8m; \nB)); (A* B) fD A* \u00acB AD2bD A, (\u00d8m; B) fD A* B ; A* \u00acB 9 MD1a D \u00d8m; B fD A-(A* B; A* \u00acB) AD2bD \u00d8m fD \nB; A-(A* B ; A* \u00acB) 8 AD2a D Init D A fD A \u00d8m; (A-(A* B ; A* \u00acB)) fD B *RD 7 A, (\u00d8m; (A-(A* B; A* \u00acB))) \nfD A* B WRD 6 A, (\u00d8m; (A-(A* B; A* \u00acB))) fD A* B; A* \u00acB 5 MD1a D \u00d8m; (A-(A* B ; A* \u00acB)) fD A-(A* B ; \nA* \u00acB) AD2aD \u00d8m fD (A-(A* B ; A* \u00acB)); (A-(A* B ; A* \u00acB)) CRD 4 \u00d8m fD A-(A* B ; A* \u00acB) 3 MD1a D A, \u00d8m \nfD A* B ; A* \u00acB \u00d8mUD 2 A fD A* B; A* \u00acB .RD 1 A fD (A* B ) . (A* \u00acB) Figure 6. A proof of A fD (A* B) \n. (A* \u00acB) in DLBBI (adapted from Brotherston [9]) all the other rules of SBBI. Similarly to SBBI, the \ninference rules are divided into structural rules, traverse rules, and logical rules. Since contraction \nis built into all the inference rules in CSBBI, the premise of every structural rule subsumes the graph \nstructure of nodes represented by the conclusion. Except the rule ECC which rewrites a node state according \nto commutativity of sequents, every structural rule has a premise that strictly extends its conclusion \nwith new relations between nodes. Below we further describe the two structural rules EAC and \u00d8mUC, in \nwhich the premise restructures nodes by changing parent-child and sibling relations but is also able \nto recover the original structure of nodes expressed in the conclusion. In the rule EAC, each sequent \nWi . Si (i =1, 2, 3)in the premise represents the same graph structure as the conclusion, except that \nits reference node is now described by Wi. Extending Wi with Si in this way is a part of building contraction \ninto the rule EAC and is thus necessary for the completeness of CSBBI with respect to Boolean BI. As \nan example, consider the proof of a sequent (W1,W2 . B),W3 .\u00b7 where W1 = A .\u00b7 and W2 = C -* \u00ac(\u00ac(A -*B) \n*C) .\u00b7 and W3 = C .\u00b7. We apply the rule EAC to generate another sequent (W1,W2 . B),W3; W1 . S1, (W2 \n. S2,W3 . S3 .\u00b7) .\u00b7 with S1 = W2((W3((\u00b7 . \u00b7)) . B)) and S2 = W1((W3((\u00b7 . \u00b7)) . B))and S3 =(W1,W2 . B)((\u00b7 \n. \u00b7)). Eventually we reach the fol\u00adlowing sequent which is provable only because of the interaction between \nS2 and A -*B via the rule -*LC: C -* \u00ac(\u00ac(A -*B) *C); (W3 . S3)(((W1 . S1)((S1 .\u00b7)) .\u00ac(A -*B) *C)); S2; \nA -*B .\u00b7 Hence, if we omit Si in the premise of the rule EAC, welosethe completeness of CSBBI. The rule \n\u00d8mUC creates a new child node with a special form of sequent \u00d8m .\u00b7, which can be absorbed back into the \nparent node by the rule \u00d8mDC. Intuitively \u00d8m .\u00b7 describes an empty node whose sibling node can be identi.ed \nwith its parent node. Similarly to the rule EAC, the premise of the rule \u00d8mDC combines the conclu\u00adsion \nwith a new sequent G1; S . .1, which represents the same graph structure as the conclusion but has a \ndifferent reference node. Omitting S in the premise also costs the completeness of CSBBI. Forexample, \nifwe omit S in the premise of the rule \u00d8mDC,the se\u00adquent in Figure 8 is not provable because its proof \ndepends on the interaction between A -*B and S via the rule -*LC. InitC \u00d8m; A;(S1 . B)((A - +B . B)) \n. A TCC A -+B;(\u00d8m; A . A), (S1 . B) . B ECC InitC A -+B;(S1 . B), (\u00d8m; A . A) . B A - +B; B;(S1 . B), \n(\u00d8m ; A .\u00b7) . B TPC TPC S1;(\u00d8m; A . A)((A -+B . B)) . B S1;(\u00d8m; A .\u00b7)((A - +B; B . B)) . B -+LC A - +B \n;(T. \u00b7), (\u00d8m; A .\u00b7); T; S . B \u00d8mDC A - +B;(T. \u00b7), (\u00d8m; A .\u00b7) . B { S = +B . B)) (\u00d8m; A .\u00b7)((A - where \n1 S= +B;(T. \u00b7), (\u00d8m ; A .\u00b7); T A - Figure 8. A proof of A -*B;(T.\u00b7), (\u00d8m; A .\u00b7) . B in CSBBI Every inference \nrule in CSBBI is invertible, i.e., the premise implies the conclusion and vice versa. We can formally \nprove that both weakening and contraction are admissible in CSBBI. We can also prove the equivalence \nbetween SBBI and CSBBI. Theorem 7.1 (Weakening and contraction in CSBBI). If G . .,then G; S . . and \nG . .; A. If G; S; S . .,then G; S . .. If G . .; A; A,then G . .; A. Theorem 7.2 (Equivalence between \nSBBI and CSBBI). G . . in SBBI if and only if G . . in CSBBI. Figure 9 shows an example of proving in \nCSBBI the same sequent as in Figure 5. The proof tree is much smaller: the depth decreases from 16 to \n8 and the number of applications of rules decreases from 18 to 12. Besides the amount of non-determinism \nin proof search is now minimal. In Figure 5, after applying the rule \u00d8mUS (when read from the conclusion \nto the premise), we have to decide whether or not to duplicate S by applying the contraction rule CLS \n, and if we skip the rule CLS , proof search fails. In Figure 9, this form of non-determinism does not \narise because the contraction rule is embedded into the rule \u00d8mUC. As a result, except for applying the \nrule \u00d8mUC inde.nitely, the only source of non-determinism concerns which of A* B and A* \u00acB should be \nconsidered .rst by the rule *RC, which is irrelevant for the purpose of this proof anyway. Since their \nrole is to change only the reference node without changing the graph structure of nodes, the traverse \nrule TCC and the structural rule ECC in Figure 9 do not increase the complexity of proof search. For \nexample, once we decide to focus on \u00acB in A;(A . .), (\u00d8m . B; \u00acB) . ., we obtain a unique sequence of \nrules, namely ECC followed by TCC, for exposing \u00d8m . B; \u00acB in the reference node. Thus the cost of proof \nsearch is incurred mainly by various decisions on applying the structural and logical rules and not by \napplications of the traverse rules. Section 8.5 explains how to eliminate the traverse rules altogether \nin proof search.  8. Backward proof search in CSBBI This section explains the design of our theorem \nprover which uses a backward search strategy built on top of CSBBI. Because of the undecidability of \nBoolean BI [11, 29], our theorem prover implements a semi-decision algorithm. For our purpose, a semi\u00addecision \nalgorithm is still useful because in program veri.cation, we usually attempt to prove formulas that are \nbelieved to be true. Our theorem prover includes a certi.er which converts every proof in CSBBI into \nan equivalent proof in SBBI according to our proof of Theorem 7.2. In addition to automated proof search, \nit also supports an interactive mode, in which the user can issue various tactics to manually change \nthe structure of nodes. Both extensions are a preliminary step toward developing a program veri.cation \nAlgorithm ProveBBI(W, d) Input: goal sequent W , search depth d Output: true or fail 1: for each node \nw, 2: promote w as the reference node 3: if Init C, .LC,or IRC is applicable, return true 4: if \u00acLC, \n\u00acRC, .RC, ILC, *LC,or -*RC is applicable, 5: W ' . result of applying the rule 6: return ProveBBI(W ' \n,d) 7: if .LC is applicable, 8: W1 and W2 . result of applying the rule 9: return ProveBBI(W1,d) &#38;&#38; \nProveBBI(W2,d) 10: if *RC or -*LC is applicable to a fresh node state S, 11: W1 and W2 . result of applying \nthe rule to S 12: return ProveBBI(W1,d) &#38;&#38; ProveBBI(W2,d) 13: if d =0,return fail 14: for each \nnode state S in node w to which EAC or \u00d8mDC is applicable, 15: promote w as the reference node 16: W \n' . result of applying the rule to S 17: if ProveBBI(W ' ,d - 1) = true,return true 18: for each node \nw, 19: promote w as the reference node 20: W ' . result of applying \u00d8mUC 21: if ProveBBI(W ' ,d - 1) \n= true,return true 22: return fail Figure 10. Pseudocode for the proof search algorithm ProveBBI system \nbased on full separation logic. For space reasons, we do not describe these extensions. 8.1 Basic structure \nof the proof search algorithm Figure 10 shows the pseudocode for the proof search algorithm ProveBBI. \nGiven a goal sequent W and a search depth d as input, it attempts to search for a proof tree for W with \nat most d applications of the structural rules (except the rule ECC) along any search path. First it \nexamines every formula in a given sequent and applies the corresponding logical rule if possible (lines \n1 12). After checking if d =0 (line 13), it considers the structural rules EAC, \u00d8mDC,and \u00d8mUC (lines \n14 21). It returns either true or fail, depending on the result of the proof search. For the sake of \nsimplicity, the algorithm ProveBBI assumes that the rule ECC is embedded into all the other rules. For \nexample, the rule EAC in Figure 10 indeed refers to one of the four instances obtained by independently \napplying the rule ECC to node states W1,W2 and (G ' ; W1,W2 . . ' ),W3. The .rst phase of the algorithm \nProveBBI (lines 1 12) exploits the fact that all the logical rules, including *RC and -*LC,are invertible. \nHence it starts by applying the logical rules wherever possible until no more applications are left. \nFor the rules *RC and -*LC, we make sure that they do not focus more than once on the   Init C \u00d8m;(A \n. .)((A . .)); B . B \u00acRC \u00d8m;(A . .)((A . .)) . B; \u00acB TCC Init C  . B)(( A . .)) . .; A A;( \u00d8m . B; \n\u00acB ), (A . .) . . TCC ECC Init C .\u00b7)((A . .)) . .; A A;( A . .; A ), (\u00d8m . B) . . A;(A . .), ( \u00d8m . \nB; \u00acB ) . . TCC *RC  A;( A . .; A ), (\u00d8m .\u00b7) . . A;(A . .), (\u00d8m . B) . A* B ; A* \u00acB *RC A;(A . .), \n(\u00d8m .\u00b7) . A* B ; A* \u00acB \u00d8mUC where .= A* B ; A* \u00acB A . A* B; A* \u00acB .RC A . (A* B) . (A* \u00acB)  Figure \n9. A proof of A . (A* B) . (A* \u00acB) in CSBBI. Each rectangle marks a principal formula or a sequent to \nbe exposed in the reference node. same pair of a principal formula and a node state (e.g., a pair of \nA -*B and (G1 . .1), (G2 . .2) in the rule *RC), since the principal formula survives in the premise. \nAfter the .rst phase, the algorithm ProveBBI recursively in\u00advokes itself to apply the structural rules \nEAC, \u00d8mDC,and \u00d8mUC in depth-.rst order (lines 14 21). For example, with d =2, it con\u00adsiders all sequences \nof length 2 in the following order: EAC EAC, EAC \u00d8mDC, EAC \u00d8mUC, \u00d8mDC EAC, \u00d8mDC \u00d8mDC, \u00d8mDC \u00d8mUC, \u00d8mUC \nEAC, \u00d8mUC \u00d8mDC, \u00d8mUC \u00d8mUC. We choose to consider the rules EAC and \u00d8mDC before the rule \u00d8mUC, which is \nthe least re\u00adstrictive rule in the sense that it can be applied to any sequent. Note that applying a \nstructural rule does not create new formulas but only gives rise to new pairs of a formula (A* B or A \n-*B)and a node state to which the rules *RC and -*LC can be applied. A re\u00adcursive invocation of ProveBBI \nimmediately focuses on these new pairs during its .rst phase (lines 10 12).  8.2 Explosion in the search \nspace and the number of subgoals While the algorithm ProveBBI eventually .nds a proof tree for ev\u00adery \nprovable sequent if given an unlimited search depth, a naive im\u00adplementation suffers from two problems \nthat are unique to Boolean BI. The .rst is an explosion in the search space in terms of the amount of \nconjunctive non-determinism among the logical rules *RC and -*LC and the structural rules. That is, a \ntypical proof search is quickly overwhelmed with too many choices for applying these rules, which are \nall invertible and thus can be applied aggres\u00adsively. This problem is due to the structural rules EAC, \n\u00d8mDC,and \u00d8mUC, each application of which immediately doubles or quadru\u00adples the search space. The second \nproblem is an explosion in the number of subgoals due to the logical rules *RC and -*LC, each application \nof which increments the number of subgoals. These rules can be applied to each formula A* B or A -*B \nas many times as there are corresponding node states. For example, if G con\u00adtains n multiplicative pairs, \nthe rule *RC creates 2n subgoals from G . A*B during the .rst phase of the algorithm ProveBBI. The .rst \nproblem is closely related to the contraction property built into the structural rules. As an example, \nconsider the structural rule EAC in Figure 7. The graph structure of the premise has four times more \nnodes than that of the conclusion because each sequent Wi . Si (i =1, 2, 3) represents the same graph \nstructure as the conclusion, as shown in Figure 11. Consequently the premise provides four times more \nways to apply the rules of CSBBI, thus quadrupling the search space. In a similar way, each application \nof the other structural rules \u00d8mDC and \u00d8mUC doubles the search space. We remark that the .rst problem \nis not the price to pay for building contraction into the structural rules, since the same problem of \nsearch space explosion remains even if we do not build contraction into the structural rules. The second \nproblem itself is orthogonal to the .rst problem, but its effect is heavily exacerbated by the .rst problem. \nAs an exam\u00adple, consider again the structural rule EAC in Figure7 wherewe set .= A* (B* C ). After an \napplication of the rule EAC to ob\u00adtain the graph structure in Figure 11, two applications of the rule \n*RC ensue to copy A to W1, B to W2,and C to W3.Ifthese for\u00admulas happen to involve multiplicative connectives, \nwe can again apply the rules *RC and -*LC to propagate their component formu\u00adlas, which, in turn, may \ntrigger further applications of the rules *RC and -*LC, and so on. To alleviate the .rst problem, we \nneed to devise a scheme for prioritizing applications of the structural rules (Section 8.3). We can solve \nthe second problem by borrowing an idea from the inverse method (Section 8.4). In addition, we can eliminate \nthe traverse rules altogether (Section 8.5). 8.3 Prioritizing applications of the structural rules As \na solution to the .rst problem, we assign a priority, either high or low, to every sibling relation between \nnodes so as to prioritize all applications of the rules EAC and \u00d8mDC, and to every node itself so as \nto prioritize all applications of the rule \u00d8mUC.When applying a structural rule, the algorithm ProveBBI \n.rst considers sibling relations and nodes with a high priority and then those with a low priority. Below \nwe explain how to assign priorities to sibling relations and how to determine priorities for nodes. For \nthe rule EAC as shown in Figure 7, we assign priorities to sibling relations in the premise according \nto Figure 11 with the following interpretation: For a sequent inside a rectangle W , every sibling relation \nin it is assigned the same priority as in the conclusion. For a sequent inside a dashed rectangle W , \nevery sibling relation in it is assigned a low priority. A sibling relation depicted with solid lines \nis assigned a high priority. A sibling relation depicted with dashed lines is assigned a low priority. \n The rationale for this assignment is that an application of the rule EAC is primarily intended to generate \nsibling relations de\u00adscribed by W1, (W2,W3 .\u00b7), rather than S1, S2,and S3 in W1 . S1, (W2 . S2,W3 . S3 \n.\u00b7). When applying the rule EAC, the algorithm ProveBBI focuses .rst on those node states both of whose \nsibling relations have a high priority. In a similar way, we assign priorities to sibling relations in \nthe premise of the rules \u00d8mDC and \u00d8mUC according to Figure 12. We determine priorities of nodes by analyzing \npriorities of sib\u00adling relations. If a node is involved in a sibling relation with a high  W1 G . . \n G ' . . ' W3 W1 W2  After applying the rule \u00d8mDC: G . . G . . .  G2; \u00d8m . .2 G1 . .1 After applying \nthe rule \u00d8mUC: Figure 12. Assigning priorities to sibling relations after applying the rules \u00d8mDC and \n\u00d8mUC. (G . .) . (G ' . . ' ) is de.ned as G; G ' . .; . ' . priority, it is more likely to be under active \nconsideration by other structural rules than those nodes with no such involvement. Hence we assign a \nhigh priority to every node involved in at least one such sibling relation. For the logical rules *LC \nand -*RC,we reuse the priority assigned to the reference node of the conclusion for two new nodes in \nthe premise. Now we redesign the algorithm ProveBBI as a two-stage algo\u00adrithm. In the .rst stage, it \napplies the structural rules using only sibling relations and nodes with a high priority. Note that it \nstill generates every node with a low priority, which is never used by the structural rules, but may \nbe needed by the logical rules. For ex\u00adample, the two sequents discussed in Section 7 are provable in \nthe .rst stage precisely because we also generate every node with a low priority. If the proof search \nfails, it enters the second stage and re\u00adpeats the proof search without ignoring sibling relations and \nnodes with a low priority. The second stage is necessary for the complete\u00adness of proof search, since \nsome formula requires us to apply the structural rules using those with a low priority as well. In fact, \nwe can .nd even a formula whose proof tree applies the structural rules using only those with a low priority. \nSection 8.6 presents examples of such formulas.  8.4 Reusing the proof tree from the premise We solve \nthe problem of an explosion in the number of subgoals with a simple technique of reusing the proof tree \nfrom the premise. Suppose that we apply the rule *RC or -*LC to produce two sub\u00adgoals in the premise, \nwithout knowing whether this application is necessary or not. If this application is unnecessary, however, \nevery proof tree for the .rst premise must be a proof tree for the con\u00adclusion as well. Hence, upon .nding \na proof tree for the .rst sub\u00adgoal, we replay it against the conclusion, and attempt to prove the second \nsubgoal only in the case of a failure. In this way, we can aggressively apply the rules *RC and -*LC \nwithout worrying about an explosion in the number of subgoals. In essence, we partially simulate the \ninverse method with a moderate overhead of revisiting proof trees (but without entirely reformulating \nthe nested sequent calculus CSBBI).  8.5 Eliminating the traverse rules The algorithm ProveBBI invokes \nthe traverse rules to change the reference node (lines 2, 15, 19 in Figure 10), but we can eliminate \nthe traverse rules altogether with a slight change in the represen\u00adtation of sequents. The basic observation \nis that the traverse rules change only the reference node without altering the graph structure of nodes. \nHence, by rewriting every rule in such a way that it di\u00adrectly focuses on any formula or node without \nrequiring a reference node, we can discard the traverse rules. To this end, we introduce a labelled sequent \nwhich assigns a unique label w to every node and annotates all formulas and \u00d8m s in it with w: labelled \nsequent L = . f S . . graph structure . ::= \u00b7| .,w ~w1 \u00b7w2 labelled truth context S ::= \u00b7| S,A@w | S, \n\u00d8m@w labelled falsehood context . ::= \u00b7| .,A@w w ~ w1 \u00b7w2 in the graph structure speci.es that w is \na parent node of w1 and w2. Then we can convert every sequent to a unique labelled sequent modulo renaming \nlabels, since a sequent determines a unique graph structure of nodes where each node contains a unique \nset of true formulas, \u00d8m s, and false formulas. Let us write [W ] for the unique labelled sequent converted \nfrom sequent W . For a rule deducing W from W ' (and W '' )in CSBBI, we derive a new rule that deduces \n[W ] from [W ' ] (and [W '' ])in a single step; for an axiom deducing W in CSBBI, wederivea new axiom \ndeducing [W ]. We refer to the resultant system as the labelled CSBBI: W ' [W ' ] R in CSBBI -. RL in \nthe labelled CSBBI W [W ] The labelled CSBBI has no traverse rules because the premise and conclusion \nof a traverse rule in CSBBI represent the same graph structure of nodes. Still it is equivalent to CSBBI \nbecause the de.nition of labelled sequents embeds the traverse rules into all the inference rules: Proposition \n8.1. W is provable in CSBBI if and only if [W ] is provable in the labelled CSBBI. Figure 13 shows an \nexample of proving in the labelled CSBBI the same formula as in Figure 9. The depth decreases from 8 \nto Init L w ~w1 \u00b7w2 f G; B@w2 . .; .1; B@w2 Init L \u00acRL w ~w1 \u00b7w2 f G . .; .1; B@w2; A@w1 w ~w1 \u00b7w2 \nf G . .; .1; B@w2; \u00acB@w2; Init L *RL w ~w1 \u00b7w2 f G . .; .1; A@w1 w ~w1 \u00b7w2 f G . A* B @w; A* \u00acB@w ;.1; \nB@w2 *RL w ~w1 \u00b7w2 f G . A* B @w ; A* \u00acB@w;.1 . \u00d8mUL . G = A@w; A@w1; \u00d8m@w2 \u00b7f A@w . A* B @w; A* \u00acB@w \n.RL where . = A* B@w; A* \u00acB@w \u00b7f A@w . (A* B) . (A* \u00acB)@w . .1 = A* B@w1; A* \u00acB@w1 Figure 13. A proof \nof \u00b7f A@w . (A* B) . (A* \u00acB)@w in the labelled CSBBI.The rule *RL focuses on the formula inside the rectangle. \n6 and the number of applications of rules decreases from 12 to 8. The rule Init L immediately completes \nthe proof when it detects the same labelled formula in both contexts of a given labelled sequent. The \nrule \u00acRL also directly focuses on \u00acB@w2, regardless of the presence of w ~ w1 \u00b7w2 in the graph structure. \nIn this way, the labelled CSBBI dispenses with the traverse rules, yielding a smaller proof tree than \nCSBBI.  8.6 Experimental results We compare a naive implementation of the algorithm ProveBBI with an \noptimized implementation that incorporates those ideas de\u00adscribed in Sections 8.3 and 8.4. Both implementations \ninternally use the labelled CSBBI to eliminate the traverse rules, as ex\u00adplained in Section 8.5. Our \nimplementations are written in Objec\u00adtive CAML and run on Ubuntu Linux 11.10 with Intel Core i7-960 3.2GHz \nand 6 gigabytes of main memory. Figure 14 shows results of running both implementations (naive and optimized) \non 14 representative formulas. For a given formula A, we use sequent \u00b7. A and search depth d as input \nto the algorithm ProveBBI. Except for experiment (c), we set d to the minimum search depth for .nding \na proof tree. The result is either the return value of ProveBBI (true and fail)or error if the proof \nsearch does not terminate within 10 minutes. In measuring the cost in terms of the number of applications \nof the rules, we exclude the rule ECC which is already embedded into all the other rules. The elapsed \ntime is in seconds. Experiment (a) tests nine formulas (all involving multiplicative connectives) of \nincreasing complexity. The two formulas marked r require only those applications of the rule EAC in which \nsibling relations with a low priority are visited; hence the proof search .n\u00adishes in the second stage \nof the algorithm ProveBBI. Experiment (b) is designed to measure the effectiveness of the two optimiza\u00adtions \nspeci.cally against the rule EAC. Experiment (c) tests the ef\u00adfect of increasing d for a common formula \nwhich can be proven with two applications of the rule EAC followed by an application of the rule \u00d8mDC. \nWe observe that the cost of proof search is mainly driven by search depth d, i.e., the number of applications \nof the structural rules required to complete proof search. We also observe that the optimized implementation \nis much less susceptible to the expo\u00adnential growth of the search space than the naive implementation, \nthereby demonstrating that the two optimizations in Sections 8.3 and 8.4 are indeed highly effective. \nIn experiment (c), a search depth of 3 eventually produces a proof tree, but only after a number of wrong \napplications of the rule EAC. An increase of d to 4, how\u00adever, immediately incurs a wrong application \nof the rule EAC which happens to lead to the correct two applications of the rule EAC, which is why it \nproduces a proof tree at a much lower cost (from 5942 to 181). A further increase of d to 5 does not \nsigni.cantly in\u00adcrease the cost, but the elapsed time becomes much longer because of the extra overhead \nof manipulating much larger sequents. Overall we .nd that the optimized implementation is reasonably \nfast in proving typical formulas of Boolean BI.  9. Related work 9.1 Proof search in the logic of BI \nand separation logic Previous work on proof search in the logic of BI mainly focuses on intuitionistic \nBI, which is another member in the family that inher\u00adits multiplicative connectives from intuitionistic \nlinear logic (like Boolean BI), but additive connectives from intuitionistic proposi\u00adtional logic. Galmiche \nand M\u00b4ery [18, 19] present a labelled tableau calculus for a propositional fragment without . and develop \na theo\u00adrem prover, called BILL, on top of it. Their later paper [21] extends the calculus for full intuitionistic \nBI. Donnelly et al. [16] investi\u00adgate the inverse method for a propositional fragment without units (T, \n.,and I) and develop a forward theorem prover. For Boolean BI, no theorem prover has been developed yet \nbecause of the lack of a proof theory suitable for proof search. Larchey-Wendling and Gamliche [28] formulate \na labelled tableau calculus by extending the labelled tableau calculus for intuitionistic BI in [21], \nbut only in order to investigate the relation between intu\u00aditionistic BI and Boolean BI. Brotherston \n[10] shows that a modular combination of display calculi for classical logic and intuitionistic linear \nlogic gives rise to a display calculus DLBBI for Boolean BI, the .rst cut-free syntactic formulation \nof Boolean BI, and proves the cut elimination property by observing that its rules obey all the syntactic \nconstraints given in [1]. Developing a practical proof search strategy on top of it, however, is far \nfrom easy because of the complexity due to its display rules and the dif.culty in restricting applications \nof the contraction rules [9]. Galmiche and M\u00b4ery [20] present a labelled tableau calculus for separation \nlogic. It lies somewhere between syntactic (tableau) and semantic (labelled) formulations because labels \ncorrespond to heaps in separation logic. Their calculus, albeit sound and com\u00adplete, does not directly \ntranslate to a proof search strategy in its current form. It is easy to build a tableau for a given formula \nac\u00adcording to the calculus, but one needs to check if all branches in the tableau are logically or structurally \ninconsistent. This requires two semantic functions (a measure and an interpretation) for each branch, \nand the calculus does not specify how to obtain such se\u00admantic functions. For a similar reason, the labelled \ntableau calculus for Boolean BI in [28] does not directly translate to a proof search strategy. For theorem \nprovers for the decidable fragment of sepa\u00adration logic by Berdine et al. [3] (without separating implication), \nsee, for example, [4, 14, 32]. 9.2 Nested sequent calculi A nested sequent calculus is one whose sequent \nmay contain smaller sequents. It has been used as a proof-theoretic formula\u00adtion of some modal and tense \nlogics [12, 27] for which no sequent calculus of the standard form exists. SBBI is also a nested sequent \ncalculus because a sequent may contain smaller sequents. formula d naive optimized result cost result \ncost time (a) (A -+B) . (T + (I . A)) . B 1 true 9 true 9 0.001 (I -+ \u00ac(\u00acA+ I)) . A 1 true 9 true 9 0.001 \n\u00ac((A -+ \u00ac(A+B)) . ((\u00acA -+ \u00acB) . B)) 1 true 26 true 19 0.001 I . (A -+B -+C) -+A + B -+C 2 true 700 true \n76 0.021 I . A+ (B+ C ) -+ A +B +C 2 true 2606 true 263 0.051 I . A+ ((B1 -+B2) +C) -+A + (B1 -+B2) +C \n2 true 12317 true 336 0.102 . \u00ac((A -+ \u00ac(\u00ac(D -+ \u00ac(A+ (C+ B))) +A)) . C+ (D . (A+B))) 2 true 121000 true \n380 0.053 . \u00ac((C1 + (C2 +C3)). ((A -+ \u00ac(\u00ac(B -+ \u00ac(C2 + (C3 +C1))) +A)) + (B . (A+ T)))) 2 3 true error \n1614053 - true true 43 74856 0.023 128.4 \u00ac((A -+ \u00ac(\u00ac(D -+ \u00ac(C+ B2 + (B1 +A))) +A)) . C +(D . (A+ (B1 \n+B2)))) (b) A+ (B+ (C+ D)) . D+ (C+ (B+ A)) 2 true 2618 true 56 0.012 A+ (B+ (C+ D)) . D+ (B+ (C+ A)) \n3 true 15686 true 34 0.041 A+ (B+ (C+ (D+ E ))) . E+ (D+ (A+ (B+ C ))) 3 error - true 2320 2.2 A+ (B+ \n(C+ (D+ E ))) . E+ (B+ (A+ (C+ D))) 4 error - true 2921 28.2 (c) I . A+ ((B1 -+B2) + (C+ D)) -+A + D \n+ (C+ (B1 -+B2)) 2 fail 1795 fail 1837 0.438 3 error - true 5942 8.2 4 error - true 181 7.0 5 error - \ntrue 182 127.0 6 error - error - - Figure 14. Results of running two implementations (naive and optimized) \nof the algorithm ProveBBI. The elapsed time is in seconds.  A nested sequent calculus is often obtained \nas an optimization of an equivalent display calculus that is not simpli.ed to a sequent calculus of the \nstandard form. Gore et al. [22 24] propose such nested sequent calculi for bi-intuitionistic logic and \nclassical tense logic. In particular, their nested sequent calculus SKt for classical tense logic is \nsimilar to SBBI in that it has two residual rules corre\u00adsponding to the traverse rules of SBBI. The main \ndifference is that SKt uses only a tree structure of sequents and has no rule for asso\u00adciativity (which \nchanges parent-child and sibling relations between sequents). Hence it is much easier to embed contraction \nrules in SKt than in SBBI and the problem of search space explosion due to structural rules as in CSBBI \ndoes not exist in SKt.  9.3 Comparison between SBBI and DLBBI We have seen in Section 6.3 that for Boolean \nBI, sequents in SBBI essentially represent a normal form of consecutions in DLBBI.For intuitionistic \nBI, Brotherston [10] establishes a stronger result that sequents in its sequent calculus are literally \na normal form of conse\u00adcutions in its display calculus and thus belong to the same syntactic category. \nHe also conjectures that a cut-free sequent calculus for Boolean BI is unlikely to exist if it has no \nnegative structural con\u00adnective such as r in DLBBI (see Section 5 in [10]). Our discovery of SBBI does \nnot contradict his conjecture because we can think of sequents in SBBI as implicitly applying a negative \nstructural con\u00adnective to falsehood contexts. What is equally important, however, is that introducing \nonly a negative structural connective is not enough to achieve a cut-free sequent calculus for Boolean \nBI, which must use a graph structure of sequents in which a sequent may have multiple parent sequents. \nIn the case of DLBBI, the linear structural connective -allows such a graph structure of sequents, but \nthe purpose of introducing -is to obtain the display theorem which is essential to Belnap s proof of \nthe cut elimination theorem for display calculi [1]. Sim\u00adilarly, even though it does not require such \na graph structure, the display calculus for intuitionistic BI in [10] also has the same lin\u00adear structural \nconnective -. In contrast, SBBI introduces an ad\u00adjoint pair W ((W ' )) for the sole purpose of allowing \nsuch a graph structure of sequents.  10. Conclusion Despite its close connection with separation logic, \nBoolean BI has not received much attention from the proof search community. Such a lack of research, \nwhich is quite unusual considering the status of separation logic in the .eld of program veri.cation, \nis perhaps due to the dif.culty of .nding a proof theory suitable for theorem proving. Our nested sequent \ncalculus SBBI as well as a theorem prover based on it may serve as a test bed for developing proof search \nstrategies for Boolean BI. In particular, its use of nested sequents allowing multiple parent sequents \nmay shed new light on how to deal with separating implication in a theorem prover for separation logic. \n Acknowledgments We are grateful to the anonymous reviewers for their helpful com\u00adments. This work was \nsupported by the Engineering Research Cen\u00adter of Excellence Program of Korea Ministry of Education, Science \nand Technology (MEST) / National Research Foundation of Korea (NRF) (Grant 2012-0000472) and Mid-career \nResearcher Program through NRF funded by the MEST (2010-0022061). References [1] N. Belnap. Display \nlogic. Journal of Philosophical Logic, 11:375 417, 1982. [2] N. Belnap. Linear logic displayed. Notre \nDame Journal of Formal Logic, 31:14 25, 1990. [3] J. Berdine, C. Calcagno, and P. W. O Hearn. A decidable \nfragment of separation logic. In Proc. FSTTCS, pages 97 109, 2004. [4] J. Berdine, C. Calcagno, and P. \nW. O Hearn. Smallfoot: Modular automatic assertion checking with separation logic. In Proc. FMCO, pages \n115 137, 2005. [5] J. Berdine, C. Calcagno, and P. W. O Hearn. Symbolic execution with separation logic. \nIn Proc. APLAS, pages 52 68, 2005. [6] J. Berdine, C. Calcagno, B. Cook, D. Distefano, P. W. O Hearn, \nT. Wies, and H. Yang. Shape analysis for composite data structures. In Proc. CAV, pages 178 192, 2007. \n [7] L. Birkedal, N. Torp-Smith, and J. C. Reynolds. Local reasoning about a copying garbage collector. \nIn Proc. POPL, pages 220 231, 2004. [8] R. Brochenin, S. Demri, and \u00b4 E. Lozes. On the almighty wand. \nIn Proc. CSL, pages 323 338, 2008. [9] J. Brotherston. A cut-free proof theory for boolean BI (via display \nlogic). Technical Report DTR09-13, Imperial College London, 2009. [10] J. Brotherston. A uni.ed display \nproof theory for bunched logic. In Proc. MFPS, pages 197 211, 2010. [11] J. Brotherston and M. Kanovich. \nUndecidability of propositional separation logic and its neighbours. In Proc. LICS, pages 130 139, 2010. \n[12] K. Br \u00a8unnler. Deep sequent systems for modal logic. In Proc. Advances in Modal Logic, pages 107 \n119, 2006. [13] B.-Y. E. Chang and X. Rival. Relational inductive shape analysis. In Proc. POPL, pages \n247 260, 2008. [14] D. Distefano and M. J. Parkinson. jStar: towards practical veri.cation for Java. \nIn Proc. OOPSLA, pages 213 226, 2008. [15] D. Distefano, P. W. O Hearn, and H. Yang. A local shape analysis \nbased on separation logic. In Proc. TACAS, pages 287 302, 2006. [16] K. Donnelly, T. Gibson, N. Krishnaswami, \nS. Magill, and S. Park. The inverse method for the logic of bunched implications. In Proc. LPAR, pages \n466 480, 2004. [17] D. Galmiche and D. Larchey-Wendling. Expressivity properties of boolean BI through \nrelational models. In Proc. FSTTCS, pages 357 368, 2006. [18] D. Galmiche and D. M \u00b4ery. Proof-search \nand countermodel generation in propositional BI logic. In Proc. TACS, pages 263 282, 2001. [19] D. Galmiche \nand D. M \u00b4ery. Semantic labelled tableaux for proposi\u00adtional BI (without bottom). Journal of Logic and \nComputation, 13: 70 753, 2003. [20] D. Galmiche and D. M \u00b4ery. Tableaux and resource graphs for separa\u00adtion \nlogic. Journal of Logic and Computation, 20:189 231, 2010. [21] D. Galmiche, D. M \u00b4ery, and D. J. Pym. \nThe semantics of BI and resource tableaux. Mathematical Structures in Computer Science, 15: 1033 1088, \n2005. [22] R. Gor \u00b4e, L. Postniece, and A. Tiu. Cut-elimination and proof-search for bi-intuitionistic \nlogic using nested sequents. In Proc. Advances in Modal Logic, pages 43 66, 2008. [23] R. Gor \u00b4e, L. \nPostniece, and A. Tiu. Taming displayed tense logics using nested sequents with deep inference. In Proc. \nTABLEAUX, pages 189 204, 2009. [24] R. Gor \u00b4e, L. Postniece, and A. Tiu. On the correspondence between \ndisplay postulates and deep inference in nested sequent calculi for tense logics. Logical Methods in \nComputer Science, 7:1 38, 2011. [25] S. S. Ishtiaq and P. W. O Hearn. BI as an assertion language for \nmutable data structures. In Proc. POPL, pages 14 26, 2001. [26] B. Jacobs, J. Smans, and F. Piessens. \nVeriFast: Imperative programs as proofs. In Proc. VSTTE, pages 59 68, 2010. [27] R. Kashima. Cut-free \nsequent calculi for some tense logics. Studia Logica, 53(1):119 136, 1994. [28] D. Larchey-Wendling and \nD. Galmiche. Exploring the relation be\u00adtween intuitionistic BI and boolean BI: an unexpected embedding. \nMathematical Structures in Computer Science, 19:435 500, 2009. [29] D. Larchey-Wendling and D. Galmiche. \nThe undecidability of boolean BI through phase semantics. In Proc. LICS, pages 140 149, 2010. [30] S. \nMagill, J. Berdine, E. M. Clarke, and B. Cook. Arithmetic strength\u00adening for shape analysis. In Proc. \nSAS, pages 419 436, 2007. [31] N. Marti, R. Affeldt, and A. Yonezawa. Formal veri.cation of the heap \nmanager of an operating system using separation logic. In Proc. ICFEM, pages 400 419, 2006. [32] J. A. \nNavarro P \u00b4erez and A. Rybalchenko. Separation logic + superpo\u00adsition calculus = heap theorem prover. \nIn Proc. PLDI, pages 556 566. ACM, 2011. [33] H. H. Nguyen and W.-N. Chin. Enhancing program veri.cation \nwith lemmas. In Proc. CAV, pages 355 369, 2008. [34] P. W. O Hearn and D. J. Pym. The logic of bunched \nimplications. Bulletin of Symbolic Logic, 5:215 244, 1999. [35] D. J. Pym. The Semantics and Proof Theory \nof the Logic of Bunched Implications. Kluwer Academic Pub, 2002. [36] J. C. Reynolds. Separation logic: \nA logic for shared mutable data structures. In Proc. LICS, pages 55 74, 2002. [37] V. Vafeiadis and M. \nJ. Parkinson. A marriage of rely/guarantee and separation logic. In Proc. CONCUR, pages 256 271, 2007. \n[38] H. Yang. An example of local reasoning in BI pointer logic: the Schorr-Waite graph marking algorithm. \nIn Proceedings of the 1st Workshop on Semantics, Program Analysis, and Computing Environ\u00adments for Memory \nManagement, pages 41 68, 2001.  \n\t\t\t", "proc_id": "2429069", "abstract": "<p>While separation logic is acknowledged as an enabling technology for large-scale program verification, most of the existing verification tools use only a fragment of separation logic that excludes separating implication. As the first step towards a verification tool using full separation logic, we develop a nested sequent calculus for Boolean BI (Bunched Implications), the underlying theory of separation logic, as well as a theorem prover based on it. A salient feature of our nested sequent calculus is that its sequent may have not only smaller child sequents but also multiple parent sequents, thus producing a graph structure of sequents instead of a tree structure. Our theorem prover is based on backward search in a refinement of the nested sequent calculus in which weakening and contraction are built into all the inference rules. We explain the details of designing our theorem prover and provide empirical evidence of its practicality.</p>", "authors": [{"name": "Jonghyun Park", "author_profile_id": "81435595750", "affiliation": "POSTECH, Pohang, South Korea", "person_id": "P3977954", "email_address": "parjong@postech.ac.kr", "orcid_id": ""}, {"name": "Jeongbong Seo", "author_profile_id": "81553176956", "affiliation": "POSTECH, Pohang, South Korea", "person_id": "P3977955", "email_address": "baramseo@postech.ac.kr", "orcid_id": ""}, {"name": "Sungwoo Park", "author_profile_id": "81100161164", "affiliation": "POSTECH, Pohang, South Korea", "person_id": "P3977956", "email_address": "gla@postech.ac.kr", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429095", "year": "2013", "article_id": "2429095", "conference": "POPL", "title": "A theorem prover for Boolean BI", "url": "http://dl.acm.org/citation.cfm?id=2429095"}