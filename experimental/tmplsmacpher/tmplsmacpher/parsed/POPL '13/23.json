{"article_publication_date": "01-23-2013", "fulltext": "\n The Type Discipline of Behavioral Separation Lu\u00b4is Caires Jo ao C. Seco CITI and Departamento de Inform\u00b4atica \nFaculdade de Ci encias e Tecnologia, Universidade Nova de Lisboa Abstract We introduce the concept of \nbehavioral separation as a general prin\u00adciple for disciplining interference in higher-order imperative \ncon\u00adcurrent programs, and present a type-based approach that system\u00adatically develops the concept in \nthe context of an ML-like language extended with concurrency and synchronization primitives. Behav\u00adioral \nseparation builds on notions originally introduced for behav\u00adioral type systems and separation logics, \nbut shifts the focus from the separation of static program state properties towards the sep\u00adaration of \ndynamic usage behaviors of runtime values. Behavioral separation types specify how values may be safely \nused by client code, and can enforce .ne-grained interference control disciplines while preserving compositionality, \ninformation hiding, and .exi\u00adbility. We illustrate how our type system, even if based on a small set \nof general primitives, is already able to tackle fairly challenging program idioms, involving aliasing \nat various types, concurrency with .rst-class threads, manipulation of linked data structures, be\u00adhavioral \nborrowing, and invariant-based separation. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: \nLanguage Constructs and Features; F.3.3 [Logics and Meanings of Programs]: Verifying and Reasoning about \nPrograms; F.3.3 [Logics and Meanings of Programs]: Type structure Keywords Behavioral Types, Separation, \nInterference, Concur\u00adrency, Higher Order Programming  1. Introduction The purpose of this work is to \nintroduce and develop the concept of behavioral separation as a general principle for disciplining interference \nin higher-order imperative concurrent programs. Statically verifying that higher-order imperative programs \ndo not go wrong in the presence of possible interference has proven to be a challenging task, and a fertile \nground for research since the seminal work of Reynolds [36]. In general, two program fragments interfere \nwhen the effects generated by one fragment may change the state visible to the other, typically due to \naliasing or to concur\u00adrency. Some forms of interference are bad , and may cause catas\u00adtrophic failure, \nsuch as read/write races when accessing the same memory cell. Other forms of interference are good and \neven re\u00adquired, such as the interference between a producer and a consumer running concurrently, and \nsharing a thread-safe state-full queue, or Permission to make digital or hard copies of all or part of \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 13, January 23 25, 2013, Rome, Italy. Copyright c &#38;#169; 2013 \nACM 978-1-4503-1832-7/13/01. . . $15.00 the interference between the head and tail references of a linked \nlist structure. Interference is the essence of concurrency , as Cliff Jones frequently recalled [26]. \nAn ongoing issue to overcome is then to .nd techniques for disciplining interference between differ\u00adent \nusages of the same objects and ensure safety, while being able to address increasingly sophisticated \nprogramming idioms. Signi.cant advances have been achieved recently towards these general goals, in particular \nby the separation logics of O Hearn and Reynolds [33, 39] and by several substructural type and effect \nsys\u00adtems, e.g., [1, 3, 8]. Namely, separation logic supports expressive forms of local reasoning, based \non the use of the separating con\u00adjunction in combination with fractional permissions [5, 9] to char\u00adacterize \nthe .ne structure of program states. Extending such state\u00adbased techniques to tackle the sophisticated \nprogram idioms arising in modern higher-order imperative concurrent programming is thus both promising \nand challenging [40]. In this work, we radically depart from a state-based view to\u00adwards a behavioral \nview of program assertions, and introduce the notion of behavioral separation. Behavioral separation \nbuilds on concepts originating in behavioral type systems and separation log\u00adics, but shifts the focus \nfrom the separation of static program state properties towards the separation of dynamic usage behaviors \nof runtime values. More concretely, we develop a type structure that systematically explores the concept \nof behavioral separation to en\u00adforce safety of programs, ruling out bad interferences in the pres\u00adence \nof aliasing and concurrency. Our presentation is grounded on a core ML-like programming language with \nconcurrency primitives, designed as a convenient abstraction for a large family of languages supporting \nhigher-order imperative concurrent programming. Behavioral types [16, 21, 24], based on process algebras, \nchar\u00adacterize the interface of a system not just as a speci.cation of the static type of exchanged messages, \nbut more importantly as a spec\u00adi.cation of its dynamic behavior. Likewise, our behavioral sepa\u00adration \ntypes specify how program values may be safely used by client code, but, unlike pure behavioral types, \nare able to capture .ne-grained interference control disciplines. A key novelty of our approach consists \nin uniformly combining in the same type struc\u00adture temporal operations, such as sequential separation, \nimpor\u00adtant to capture constraints on traces, with spatial operations, such as parallel separation and \nisolation, important to discipline aliasing and concurrency. Remarkably, we carry out our development \nin the context of a clean substructural type theory, in which all type op\u00aderators satisfy natural algebraic \nproperties, based on a .-calculus extended with imperative references and concurrency constructs. Behavioral \nseparation types promote information hiding, com\u00adpositionality, and .exibility, since type assertions \ntalk about sepa\u00adration constraints on usage behaviors as externally perceived by the programs which use \nthem, rather than about the internal structure of program state or code. As will be clear from our examples, \nbehav\u00adioral separation types are also expressive and .exible enough for proving safety of programs combining \nfeatures still challenging for (and even out of reach of) existing proof methods, including general higher-order \nstore, aliasing / sharing at all types, linked data struc\u00adtures, borrowing of local behavior, .rst-class \nthreads, and invariant\u00adbased separation, based on typed synchronization constructs.  2. Overview In \nthis section, we motivate the general concept of behavioral sepa\u00adration, informally introducing our core \nprogramming language and the various behavioral separation type operators by going through a sequence \nof examples. Consider .rst the following implementation of a collection ADT, where we assume list elements \nto be natural numbers and the representation data structure to be a linked list. let newNode = .[].var \nnext, elt in [ setElt = .e.(elt := e), getElt = elt , setNext = .p.(next := p), getNext = next ] in let \nnewColl = .[].var hd, id in [ init = .i.(hd := NULL; id := i), getId = id, add = .e.let n =(newNode nil) \nin ((n.setElt e); (n.setNext hd); hd:=NODE(n)), scan = var s in ( s := hd; rec L.case s of NULL . nil \nNODE(n) . (s := n.getNext ; L))] We de.ne four operations on collections: the initializer init , which \nsets the collection identi.er (a string); the getId operation, which returns the collection identi.er; \nthe add operation, which adds a new element to the collection; and the scan operation, which traverses \nthe linked list, visiting each node in sequence. We model ADT objects by tuples of closures sharing memory \nlocations, and classes by object generating functions, along standard lines. In our language, tuple .elds \nare bound to expressions (quoted code), to be evaluated only after .eld selection (as e.g. in [38]). \nThe var x in e block creates a ML-style heap allocated variable, where the created cell can survive the \nlifetime of the body e, embedded in the value returned (cf. let x = ref(nil) in e in ML). In the code \nshown above, the private hd variable refers to the head of the linked list, and is shared by the add \nand scan oper\u00adations. We represent references to list elements by variant values, with options NULL(nil) \nabbreviated NULL and representing the null reference, and NODE(n), representing a list node. In NODE(n), \nn is a tuple with .elds setElt , getElt , setNext,and getNext. Notice that the latter two .elds access \nthe heap variable next, which references the next node, if any, and is local to the given node. Using \nstandard functional and product types we could assign to newC oll a type as 0.SC ,where 0 is a unit type, \nand SC a record type representing the collection objects . Such a record type would essentially specify \na .at interface, listing the signature of the operations available, each one modeled as a typed .eld. \nQuite differently, in our system types specify value usage behaviors, rather than value structure. As \na .rst example consider SC . init :str|.0 ;(getId :str &#38; add:nat|.0 &#38; scan :0) * The type SC \nspeci.es a (possible) usage behavior offered by a collection. Intuitively, the type SC says that collections \nmay be used by .rst calling the init method , and then the getId , add, and scan methods , in iterated \nchoice. First, it offers a label selection usage, denoted by the label selection type init :str|.0. The \nusage consists in selecting the init label to get a value of type str |. 0. The stop type 0 speci.es \nthat no usage is available. The operator (-)|.(-) is our primitive functional type. U |. V is a type \nfor functions which do not interfere unsafely with their argument, and speci.es a single usage of a value \nas a function, at the appropriate argument U and return type V .The U|.V does not correspond to a standard \nfunction type U.V , which can neverthe\u00adless be encoded in our system as will become clear later. It does \nneither correspond to the linear arrow, nor to the arrows of separa\u00adtion [33, 39] or bunched logic [32], \neven if it is closely connected to all of these. In a state-full, concurrent programming world, there \nare just too many ways of using a function object. In conjugation with other type operators, the functional \ntype U|.V allows much of such variety to be modularly approached. Sequencing of behaviors is expressed \nby the sequential sepa\u00adration type operator (-) ;(-). A value typed by U ; V .rst offers to clients the \nusage behavior U and only after V . In our exam\u00adple, after the init :str|.0 usage behavior, the collection \nvalue of\u00adfers a usage (getId :str &#38; add:nat|.0 &#38; scan :0) *. This last type speci.es the iterated \nchoice between the selection of .elds getId , add,and scan , each one yielding a value of respectively \ntype str, nat |. 0,and 0. Choice between alternative behaviors is expressed using intersection types. \nA value typed by U &#38; V offers to clients the choice between behaviors U and V , since it can provide \nboth U and V , alternatively. The star type U * denotes the iteration of U. Clearly, the type operators \njust described may express rich se\u00adquential protocols. Still, they are not expressive enough to express \naliased or concurrent usages, due to the strict linearity they enforce. A more .exible and still safe \nusage type for our collection would allow, after initialization, the getId operation to be always avail\u00adable, \nconcurrently with a add or a scan operation. To express this possibility we use the parallel separation \ntype operator (-) |(-). In general, a U | V type asserts that behaviors U and V may be safely used by \ncausally independent clients, either due to aliasing or to concurrency, without incurring in unsafe interference. \nSuch a parallel usage only completes when both behaviors U and V complete. Exploring parallel separation, \nwe may assign to function newColl the more .exible type 0|.CC where CC . (init :str|.0) ;(!getId :str \n|(!scan :0 ; add:nat|.0) * ) The type CC asserts that, after initialization, a collection provides two \nindependently usable behaviors, one of type !getId :str and other of type (!scan :0 ; add:nat|.0) *, \ncomposed using the paral\u00adlel separation type operator (-) |(-). The type operator !(-),used in !getId \n:str and !scan :0, spec\u00adi.es an unbounded number, possibly zero, of separated paral\u00adlel usages (parallel \nin the sense of (-) |(-)). In particular, the type !getId :str allows an unbounded number of (possibly \ncon\u00adcurrent) aliases to access the .eld getId :str. Then, the type (!scan :0 ; add:nat|.0) * speci.es \na usage consisting of the in\u00adterleaved repetition of some parallel usages of the scan :0 behavior followed \nby the add:nat|.0 behavior. Only after all the scan op\u00aderations selected in the !scan :0 phase conclude, \nwill add:nat|.0 become again available. Since there is no obligation to pick any scan :0 operation in \nthe !scan :0 phase, the type CC also allows any number of add:nat|.0 operations to be sequentially performed. \nNotice that the behavior of a newly created collection c is com\u00adpletely separated, or isolated, from \ncontext: no behavioral depen\u00addencies exist between c:CC and the behavior of other values in a program \nusing the collection. We express isolation, which plays an important role in our framework, by a speci.c \ntype operator .(-). We thus assign to the function newColl the type 0 |. .CC . Let us now consider some \ncode snippets using the collection type just de.ned, and discuss valid (and invalid) typings. let c = \nnewColl [] in (c.init my ); c.scan ;(c.add 1) let c = newColl [] in (c.init my ); (c.add 1); c.getId \n; c.scan Both code fragments are validated by our type system. In the .rst one, it is clear that the \nusage of c follows the intended type. In the second one, the intended usage type of c is also not vio\u00adlated, \neven if behaviors that appear parallel separated in the type (e.g., c:getId :str and c:scan :0) are sequentially \nused in the code. Clearly, if a value may be safely used according to U | V ,itmay also be safely used \naccording to U ; V . Subsumption principles as this one are captured by subtyping, a pre-order on types \nwritten U <: V . In particular, subtyping satis.es the exchange law [19] (A ; C) | (B ; D) <: (A | B) \n; (C | D) of which U | V <: U ; V is a special case. The next examples illustrate behavioral borrowing \n, where fragments of the behavior of c are temporarily used by some func\u00adtion, before being given back \nto the caller context. let c = newColl [] in let f = .x.(x.init your ) in (fc); (c.add 2) let c = newColl \n[] in let g = .x.(x.scan) in (c.init my ); (gc); c.scan ;(c.add 2); (gc) In the second case the borrowing \nfunction is used twice, at different places of the global behavior. The borrowed type is declared in \nthe function domain, e.g., f:(init :str |. 0) |. 0. On the other hand let c = newColl [] in let h = .x.(x.init \nyour ) in (c.add 2); (hc) attempts to use add before init , and is rejected by our type system. More \ninteresting examples illustrate borrowing of behavior through the store, which our type system is able \nto handle in a natural way, even in a higher-order setting. Consider the following code snippet. It respects \nthe expected behavioral constraints on the value c and the heap allocated variable a, even if the behavior \nof c is temporarily accessible at a, and is in fact typeable in our system. let c = newColl [] in var \na in (a := c;(a.init my ); (a.add 1); (a.add 1); c.scan )) Heap variables are assigned behavioral separation \ntypes expressed in terms of use use, read rd(U) and write wr(U) capabilities, and related by subtyping \naxioms. We show some of them here var <: use ; var use <: wr(U) ; rd(U) rd(!U) <: !rd(U) rd(U ; V ) <: \nrd(U) ; rd(V ) rd(U | V ) <: rd(U) | rd(V ) The .rst two axioms say that a single use of a variable consists \nin writing on it a value of type U, followed by a matching read phase. The following axioms specify how \nthe reading phase may be behaviorally separated, depending on the type of the stored value. The next \nexample illustrates higher-order borrowing through the store, the function attached to the add .eld is \nitself stored in memory, before being called. let c = newColl [] in ((c.init my ); var a in (a := c.add;(a \n1); c.scan )) This code does not violate any constraints imposed by the type of c, even if a collection \nmethod (a functional value) is extracted by selecting c.add and stored in the temporary heap variable \na. These last two examples get past our typing discipline, because the type system keeps track of global \nseparation constraints be\u00adtween all the values in the scope, and relies on sequential and paral\u00adlel frame \nreasoning to locally replace behaviors in behavioral sep\u00adaration type assertions. In the last example, \nthe function of type nat |. 0 is required to be used (exactly once) before scan is se\u00adlected in c, even \nif its behavior is temporarily stored in the vari\u00adable a, respecting the initial footprint of c.add of \nin the global be\u00adhavioral separation type. The type pre-condition of a := c.add is a:use |(c:add:nat \n|. 0 ; c:scan :0 ; \u00b7\u00b7\u00b7 ), and the post-condition is a:rd(add:nat |. 0) ; c:scan :0 ; \u00b7\u00b7\u00b7 . Notice that \nthis last type se\u00adquentially constrains the behaviors of a and c, forcing a to be read before using c. \nThe ability to specify global separation constraints, involving several values, seems essential for the \nexpressiveness of our system. As a further illustration of this point, consider let c = newColl [] in \nlet m = c.init in c.scan Here, the init quali.er is selected, but since the associated func\u00adtional behavior \n(bound to m) is not actually exercised, the initial\u00adization of the local hd variable is not performed, \ncausing the scan operation to crash in the case expression. Of course, this code does not type check \nunder our current assumptions, since it does not preserve the frame conditions imposed by the intended \nbehav\u00adioral separation protocols. Indeed, c.scan would need to be typed under the pre-condition (m:str \n|. 0) ; c:scan :0 ; \u00b7\u00b7\u00b7 , which states that m must be used (as a function) before progressing with the \ncontinuation behavior of collection c, which is not possible. The type system systematically uses local \nreasoning and frame principles on behavioral separation assertions to modularly com\u00adpute effects of program \nfragments. As another example, consider var s in (s := hi ; let F = .x.(let c = newColl [] in (c.init \nx; c)) in (let u =(Fs) in (s := ok ; u.add 1))) So F returns an initialized collection. The pre-condition \ntype as\u00adsertion to typing (Fs) is s:rd(str) ; var | F :(str |. .CC ).We assume that the type of strings \nstr is shareable ( str <: !str), so that reading from s does not empty the variable. To type func\u00adtion \napplication, we collect the footprints of argument and function as (s:rd(str) | F :(str |. .CC )) ; s:rd(str) \n; var. After typing let u =(Fs), the type assertion is u:.CC ; s:rd(str); var. Apparently, this says \nthat u must be fully used as .CC be\u00adfore the variable s can used again, which is not sensible. How\u00adever, \nthe behavior .CC is isolated, as expressed by .(-),so the use of s does not causally depend on it: by \nthe subtyping law (.U) ; V <: (.U) | V , we actually reach u:.CC | s:rd(str); var, and then u:.CC | s:var \n(by rd(str) <: rd(0) <: 0). Isolated types offer a safe escape from the strict locality discipline, allowing \niso\u00adlated behaviors to be fully (and soundly) separated from a global type in which they might appear \nembedded. As a further illustra\u00adtion, the following code is typeable by assigning .CC |. 0 to f so that \nit captures the argument full behavior (storing it in heap variable a) rather than borrowing it. let \nc = newColl [] in var a in let f = .x.a := x in ((fc); (a.init my )) We now consider some examples with \nconcurrency. The parallel expression (e1le2) clearly brings up the possibility of interference. The next \ncouple of examples are safe, and type-check in our system let c = newColl [] in ((c.init my ); (c.add \n1); (c.scan lc.scan )) let c = newColl [] in let f = .x.(x.scan) in ((c.init my ); ((fc)lc.scan ); (c.getI \ndl(c.add 2)); (fc)) On the other hand, the code snippets let c = newCol l [] in ((c.init my ); ((c.add \n1)l(c.scan ))) let c = newCol l [] in let f = .x.((x.add 0)l(c.add 1)) in ((c.init my ); (fc)) violate \nthe intended behavioral separation constraints, and are re\u00adjected by the type system. In the last case, \nalthough the function f may be given type (add:nat |. 0) |. 0, the application (fc) is not typeable, \nsince the type CC cannot provide footprints for sep\u00adarately typing function and argument (no parallel \nseparated add capabilities are available on c). On the other hand, the following similar looking code \nis safe and well-typed. let c = newColl [] in let f = .x.(x.scanlc.scan ) in ((c.init my ); (fc)) The \nform (e1le2) is actually derived from primitive fork and wait thread-based concurrency constructs. Thread \nreferences are .rst\u00adclass values in our language, created by the fork(e) expression. The interesting \noperation on threads is to wait for their return value. Let let c = newColl [] in ((c.init my ); var \na in (a := fork(c.scan); c.scan; wait(a); (c.add 1))) This code is well-typed under the current typing \nassumptions for c, as enforced by the parallel and sequential frame conditions, since the footprints \nof the fork and wait expressions match the expectations of the global behavioral type. On the other hand, \nlet c = newColl [] in ((c.init my ); var a in (a := fork(c.scan); (c.add 1); wait(a))) is not well-typed \nunder the same assumptions: it breaks the sep\u00adaration constraints required by the type of c. Such type \nrequires c.scan and (c.add 1) to be sequentially separated, but overlapping may occur at runtime, causing \nunsafe interference. As noticed before, it is not sound to assign to our collection a type allowing the \nadd operation to be used concurrently with scan operations. That would violate the intended usage protocol \nof the internal state, causing a write/read race on heap variable hd. However, our language allows critical \nregions in the code to be sequentialized, and eventually typed by invariant-based separation. Invariant-based \nseparation allows isolated behaviors to be repeat\u00adedly interleaved in the global behavior, as far as \nthe associated in\u00advariant conditions, expressed by a conveniently chosen type asser\u00adtion, are preserved. \nIn our example, this could be achieved, e.g., by adding a new local heap variable inv to the collection, \nand wrap\u00adping the uses of hd in add and scan as follows add = .e.sync(inv)(...) scan = var s in sync(inv)(s \n:= hd); rec L.case s of \u00b7\u00b7\u00b7 ) To type this code, we associate an assertion hd:rd(!.PNode ) ; var to the \nheap variable inv , which expresses an invariant condition protecting its footprint. Our type system \nis then able to assign to the concurrent collection the following type, which allows, after initialization, \noperations getId , add and scan to be unboundedly aliased, or shared by several active threads. (init \n:str|.0) ;(!getId :str | !scan :0 | !add:nat|.0) Of course, the main novelty to highlight here is not \nthe familiar rea\u00adsoning technique for lock invariants, but the way our type discipline elegantly captures \nit. Even if based on a few fairly general princi\u00adples, it can be effectively used to reason about safety \nproperties of higher-order concurrent programs involving dif.cult to handle scenarios of aliasing and \nconcurrency. We are not aware of related proposals, able to address the same set of (realistic) programming \nidioms, and based on a a similarly general foundation, as we have achieved here. This paper makes the \nfollowing contributions: We motivate and introduce the concept of behavioral separation as a general \nprinciple for disciplining interference in higher\u00adorder imperative concurrent programs.  We present \na behavioral separation type system for a .-calculus with imperative and concurrency constructs. We show \nsound\u00adness of the system, proving type preservation under reduction (Theorems 4.3 and 4.5) and progress \n(Theorem 4.4).  We illustrate, by means of many examples, how our type sys\u00adtem, even if based on a small \nset of very general primitives, is already able to tackle fairly challenging program idioms.  a, b, \nc, m, n, t . . . . . (Names) x, y, z . . . .V (Variables) l, s . . . .L (Labels) X, Y . . . . . (Expression \nVars) e, f ::= x (Variable) | .x.e (Abstraction) | e1e2 (Application) | let x = e1 in e2 (De.nition) \n| var a in e (Heap variable decl) | a := e (Assignment) | a (Dereference) | [l1 = e1,...] (Tupling) | \ne.l (Selection) | l(e) (Variant) | case e of li(xi) . ei (Conditional) | rec(X)e (Recursion) | X (Recursion \nvariable) | fork e (New thread) | wait e (Wait) | sync(a)e (Synchronized block) | sy(a)e (inSynchronized \nblock) | n (Thread identi.er) Figure 1. Programming Language.  3. Programming Language Our programming \nlanguage, presented in Figure 1, is a .-calculus with mutable heap allocated variables, tuples, variants, \nand concur\u00adrency primitives. To keep it close to familiar high-level languages such as Java, we consider \nunstructured (fork/join) thread-oriented concurrency primitives, and a synchronization construct. Our \nlan\u00adguage is fairly simple yet expressive enough to support challenging imperative higher-order concurrent \nprogramming idioms. To formally de.ne it, we assume given an in.nite set of names ., an in.nite set of \nvariables V, and an in.nite set of method labels L. Names in . are used to identify threads and heap \nlocations. For simplicity sake, we omit basic values, and literals for booleans or integers; their addition \nas primitives is straightforward. The functional core includes abstraction .x.e and application e1e2, \nfollowing call-by-value evaluation. The tuple expression [l1 = e1,. ..] denotes a record collecting expressions \nei, each one quali.ed by the label li. As in [37], and without any loss of gen\u00aderality, we consider lazy \ntuples, where the expression ei is only evaluated after selection of the label li. Lazy tuples allow \ndifferent quali.cations of the same entity to be subject to different interfer\u00adence constraints, both \nalong the time and space dimensions, and are convenient for encoding objects as tuples of methods . The \nempty tuple [] is also written nil. The let expression represents local de.nition and sequential composition: \nin let x = e1 in e2, the subexpression e1 is evaluated .rst, its result bound to x,and then e2 is executed \nusing the value x. We abbreviate let x = e1 in e2 by (e1; e2) if x is not free in e2. The construct l(e) \ninjects the value of expression e into the vari\u00adant label l.The case construct corresponds to a standard \ndestructor for labeled sum types. The expression case e of li(xi) . ei .rst evaluates e to a variant \nvalue li(v) (if this is not the case, execution will get stuck). Then, v is bound to xi, ei evaluated \nand its value returned as the result of the whole case expression. Variable declaration var a in e, variable \naccess a, and assign\u00adment a := e are interpreted as usual. The expression fork e spawns a new thread \ndedicated to the evaluation of expression e, and immediately returns the new thread identi.er (a name) \nto the caller (thread identi.ers are values, and do not appear in source programs). Both the calling \nthread and the newly created one proceed execution concurrently. The expression wait e suspends the caller \nuntil the thread resulting from evaluating e terminates with some result (if ever). Such result will \nthen be returned as the result of the wait expression. Our language includes a simple synchronization \nprimitive. The primitive relies on endowing each heap variable with a lock. Such locks are available \nfor .exible use in programs, pretty much as object locks are used, e.g., in Java programs (either to \nlock the variable itself, or to protect any other relevant region of the state). At each moment, a lock \nmay be either taken or free. The expression sync(n)e evaluates the expression e in exclusion, using the \nlock associated to heap variable n (cf. the Java synchronized block); only one thread may acquire the \nlock of n in linear ( write ) mode. To track entry and exit of synchronization blocks in the opera\u00adtional \nsemantics, we use the auxiliary construct sy(n)e. No occur\u00adrences of this construct, or of location or \nthread names are expected to appear in source programs, these elements belong to the runtime syntax of \nthe full language, as shown in Figure 1. The operational semantics of our programming language is de\u00ad.ned \nby a reduction system using evaluation contexts. A state con\u00adsists of a pair h; T ,where h is a heap \nand T is a set of threads. A reduction step has the form h; T . h'; T ' (h; T reduces to h'; T ') expressing \na computation step from state h; T to state h'; T '. In any such step, new heap cells may be allocated, \nthreads may be created, evolve, or terminate. Each thread in T is represented by an element of the form \nt(e),where t is the thread name (from .), and e is the runtime expression under execution by the thread. \nWe write t(e)\u00b7 T for the disjoint union of T and {t(e)}. A heap h is a mapping from heap locations (names) \nto values. Each heap binding nk . v also has an integer-valued counter k associated, to be used as a \nsemaphore, important to support the synchronization primitives. We write h(nk . v) to denote a heap such \nthat nk. v . h,and h[nk. v] to denote the heap obtained from h after storing v at location n, with lock \nvalue k. We now introduce values V and evaluation contexts E,given by  v, u .V ::= .x.e[ l1 = e1,. .. \n]l(v)tx  E ::= Dlet x = E in eE.lEevEl(E)  wait(E)sy(n)Ecase E of li(xi) . ei A value in our language \nis either an abstraction, a tuple (including the empty tuple nil), a variant value, a thread name, or \na variable. Without loss of generality, we restrict assignments in our source language to the simple \nform a := v where v is a value, and use a := e as an abbreviation for let x = e in a := x.The rules de.ning \nthe reduction relation are presented in Figure 2. We write {v/x} for the capture avoiding substitution \nof v for x, de.ned as expected. Notice that there is no order assumed between elements in a thread set \nT , so any thread t(e). T may be (non\u00addeterministically) scheduled in a reduction step. Most reduction \nrules are easy to interpret, and do not deserve much explanation. In rules (Red var) and (Red fork) the \nside condition (.n) state that name n must be fresh in the respective left hand side. Rules (Red sync*) \nrely on the integer-valued lock associated to the each heap location n. When the lock is zero, the lock \nis free. Rule (Red syncin) checks that the lock k associated to v is free, before decrementing it to \n-1, and allowing execution to enter the critical region e: the expression sy(n)e signals that the execution \nof e is taking place inside a critical region protected by the lock of n. The lock is released after \nthe body of the sy(n)e block reduces to a value u, in rule (Red syncout). (Red rec) h; t(E[ rec(X)e \n])\u00b7 T . h; t(E[ e{rec(X)e/X } ])\u00b7 T (Red let) h; t(E[ let x = v in e ])\u00b7 T . h; t(E[ e{v/x} ])\u00b7 T (Red \nbeta) h; t(E[(.x.e)v ])\u00b7 T . h; t(E[ e{v/x} ])\u00b7 T (Red sel) h; t(E[[ l = e ].li ])\u00b7 T . h; t(E[ ei ])\u00b7 \nT (Red case) h; t(E[ case li(v) of l(x) . e ])\u00b7 T . h; t(E[ ei{v/xi} ])\u00b7 T (Red var) h; t(E[ var a in \ne ])\u00b7 T . h[n .nil]; t(E[ e{n/a} ])\u00b7 T (.n) (Red assign) h(nk .v); t(E[ n := u ])\u00b7 T . h[nk .u]; t(E[ \nnil ])\u00b7 T (Red deref) h(nk .v); t(E[ n ])\u00b7 T . h(nk .v); t(E[ v ])\u00b7 T (Red fork) h; t(E[ fork e ])\u00b7 T \n. h; t(E[ n ])\u00b7 n(e)\u00b7 T (.n) (Red wait) h; t(E[ wait n ])\u00b7 n(v)\u00b7 T . h; t(E[ v ])\u00b7 T (Red syncin) h(n0 \n.v); t(E[ sync(n)e ])\u00b7 T . h[n-1 .v]; t(E[sy(n)e])\u00b7 T (Red syncout) h(n-1 .u); t(E[ sy(n)v ])\u00b7 T . h[n0.u]; \nt(E[v])\u00b7 T Figure 2. Reduction.  4. Type System In this section, we technically present our type system. \nAs already discussed, types describe behavioral usages of values. We start by systematically introducing \neach type operator, discussing on the way their basic algebraic properties and related subsumption laws. \nDE FINIT ION 4.1 (Types). Type operators are given by T, U ::= 0 (stop) | T |. V (function) | T ; U (sequential) \n| T | U (parallel) | T &#38; U (intersection) | l:T (quali.cation) | .l.I l:Tl (sum) | !T (shared) | \n.T (isolated) | t (T ) (thread) | rec(X)T (recursion) | X (recursion var) We assume some primitive type \nconstructors c, c(U),suchas str, nat, to represent basic data types, and var, rd(U),etc, to represent \nbehavioral separation types for heap allocated variables. The stop type 0 types any value exposing no \nbehavioral capability, in partic\u00adular it types nil.The sequential type T ; U asserts of a value that \nit can be safely used .rst according to type T , and only afterwards according to type U. The sequential \ntype expresses behavioral sep\u00adaration along the temporal dimension. Sequential types induce a monoid \nwith identity 0 in the type structure, expressed by U ;(V ; T ) <:> (U ; V ) ; TU ; 0<:> U 0 ; U <:> \nU The parallel type T | U asserts of a value that it can be subject to two safe independent parallel \nusages, speci.ed by type T and type U respectively. By independent parallel usage of a value we mean \nany form of sharing, arising not just in concurrent programs, but also in sequential programs, due to \naliasing. The parallel type thus expresses behavioral separation along the spatial dimension. It builds \non the fundamental idea of separation (cf. separation logic [39]), but focusing on the independence of \nusage behaviors, as perceived from a client viewpoint , rather than on the disjointness of underlying \nresources (to highlight this understanding of T | U, we refrain from using the notation T *U). A key \ninsight on (- | -) is that behaviors typed by parallel separation do not interfere in unsafe ways, even \nif they rely (and write) on shared resources (e.g., as a result of invariant based separation, developed \nin Section 4.5). An usage of type U | V only concludes when both U and V con\u00adclude: in a type such as \n(U | V ) ; T , the usage T is only available when (U | V ) conclude. So our type language provides an \nabstract way of splitting permissions , without using explicit fractions (cf. [9]). Parallel types induce \na commutative monoid with identity 0 U |(V | T ) <:> (U | V ) | TU | V <:> V | UU | 0<:> U Sequential \nand parallel composition are related by the exchange law [4, 19], the following causality preserving \ndistribution principle (A ; C) | (B ; D) <: (A | B) ; (C | D) A special case is the familiar interleaving \nlaw U | V <: V ; U. The (linear) intersection type U &#38; V asserts of a value that it may be safely \nused according to type U and according to type V . The client code using such a value can therefore freely \ndecide to pick either the U or the V behavior (but not both, since we exploit a linear interpretation \nof &#38;). The following basic laws hold. U &#38; V <: UU &#38; V <: V U <: U &#38; U Notice that (- \n| -), (- ; -) and (- &#38; -) induce a CKA [19]. The recursive type rec(X).A, with X guarded in A,is \ninter\u00adpreted co-inductively. We de.ne U * rec(X)(0 &#38;(U ; X)). The shared type !T asserts of a value \nthat it can be safely subject to an unbounded number of parallel separated usages (cf. (- | -)), each \none speci.ed by type T . In particular, it may be unboundedly aliased at type T . The following laws \nhold for the type !T !U <: U !U <: !!U 0<: !0 !U | !V <: !(U | V ) !U <: 0 !U <: !U | !U Notice that \n!(-) satis.es the fundamental co-monadic laws for the linear logic exponential; so our notation highlights \nthe connection. The function type T |.V asserts of a value that it can be safely used (once) as a function \nthat when given as argument a value of type T , exercises on it a usage of type T , and returns a result \nof type V . Type U|.V is adjoint to U|V , so that the behavioral separation interpretation ensures the \nintended safety property: no unsafe in\u00adterference can arise even if function and argument share state-full \nresources, since they are behaviorally separated. So U|.V is a type for functions that do not unsafely \ninterfere with their arguments, as in the sharing interpretation of the arrow --in [32], but does not \ncompletely forbid interference to ensure safety. Moreover, unlike in the standard linear logic interpretation \nof the arrow (U-.V ),a function of type U|.V can use its parameter more than once, as long as it globally \nrespects the behavioral type U (as in [12]). The isolated type .T asserts of a value that it may be used \nas speci.ed by the type T , but, more crucially, that such usage is fully isolated, not subject to any \nexternal (global) constraints. A value of type .T is completely separated (in terms of behavior) from \nthe rest of the world . In particular, .T says that the usage T is not borrowed from some larger computation. \nWe may see a value of type .T as offering a self-contained suspended behavior of type T , that may be \nused at any future step in the computation. No liveness commitments are imposed on client code to use \na value of type .T , unless it actually starts to use it at type T . In particular, a value of type .T \nmay be safely dropped, since nothing causally depends on it: a safe use for a value of type .T is not \nto use it at all. Moreover, since nothing can causally depend on a value of type .T , we expect the law \n(.U) ; V <: (.U) | V to hold. We also have 0<: .0 .A | .B <: .(A | B) .A <: A .A <: ..A .A <: 0 !.A \n<: .!A (.A | B) ; C <: .A |(B ; C) The .rst .ve laws express familiar algebraic principles (cf. the \nbasic laws for !(-)). The last two laws are proper to .(-).In particular, the last one expresses the \nkey property of .(-), global behavioral isolation: a behavior of type .T is isolated, and can be freely \nused anytime, concurrently with anything. No other behavior can causally depend from a behavior of type \n.T . By exchange, we may derive the postponing law (.A) ; B <: B ;(.A). The quali.ed type l:T asserts \nof a value that it offers a usage of type T under the label l. It describes a label selection capability \nof a tuple, classifying the usage type of the value in .eld l.As in[38], general tuple types may be de.ned \nby combining quali.ed types with other type constructors, e.g. (l1:T1 &#38; .. . &#38; ln:Tn) * . The \nsum type .l.ili:Ti asserts of a value that it is a labeled value that can be used according to type Ti \nif it is labeled with li. Client code using such a value must branch on the possible labels, before actually \nusing the selected behavior. The sum type thus corresponds to a standard labeled disjoint union, useful \nto describe variants or options. We abbreviate (NULL:0 . NODE:U) by Opt(U). The thread type t (T ) asserts \nof a value that it references a running thread that upon termination returns a value of type T . Types \nfor heap allocated variables are conveniently described in our system by speci.c primitives, expressing \nusage, write and read capabilities. The type of a freshly allocated heap variable is var. The type var \ndenotes the generic heap variable usage protocol, and is axiomatized by several subtyping laws, presented \nin Section 4.1. As previously discussed, a type classi.es a single value. In or\u00adder to type program expressions, \nwhich may use in general sev\u00aderal different values, we introduce a notion of type assertion.A type assertion \ncorresponds to the usual notion of type environment, assigning types to the various free identi.ers in \na program. How\u00adever, our type assertions .nely describe behavioral dependencies between the several identi.ers \nin its domain, by placing basic type assignments of the form x:T embedded in a larger global type. DE \nFINIT ION 4.2 (Type Assertion). Type assertions are given by A, B ::= x:T A ; B A|B A &#38; B !A .A X \nrec(X)A For an example, under the assumptions expressed by the type asser\u00adtion (f:U |. V ; y:U) | z:U, \nthe function f can be applied to z but not to y,so (fz) is well typed but (fy) is not, since the behavior \ny:U is only available after f:U |. V is used. We denote by Dom(A) the (.nite) set of variables appearing \nin a type assertion A.If A has a singleton domain {x} (that is, refers to a single variable x), we implicitly \nidentify it with the singular assertion x:(A)x where the type (A)x is given by (x:T )x = T (A ; B)x =(A)x \n;(B)x (A | B)x =(A)x |(B)x (A &#38; B)x =(A)x &#38;(B)x (!A)x =!(A)x (.A)x = .(A)x (X)x = X (rec(X)A)x \n= rec(X)(A)x Therefore, we identify, e.g., x:(up ; dn) with (x:up) ;(x:dn),and rec(X)((x:up | x:dn) \n; X) with x:rec(X)((up | dn) ; X). We de.ne type assertion contexts A[-] as the one hole syntactic contexts \nassociated to type assertions. We also consider active assertion contexts E[-], where the hole occurs \nunguarded, de.ned E[-] ::= D E[-] ; A E[-] | A A | E[-] 4.1 Subtyping Type assertions are related by \na subtyping relation. We write A <:B to state that A is a subtype of B, meaning that the usage behavior \n A <:> A | 0 A | B <: B | AA |(B | C) <:> (A | B) | C A <:> A ; 0 A <:>0 ; AA ;(B ; C) <:> (A ; B) ; \nC (A ; C) |(B ; D) <: (A | B) ;(C | D) A &#38; B <: AA &#38; B <: BA <: A &#38; A 0<: .0 .A <: 0 .A <: \nA .A <: ..A .A | .B <: .(A | B) !.A <: .!A (.A | B) ; C <: .A |(B ; C)!A | !B <: !(A | B) 0<: !0 !A <: \n0 !A <: A !A <: !!A !A <: !A | !A rec(X)A <:> A{rec(X)A/X } var <: use ; var use <: use ; use use <: \nwr(U) ; rd(U) wr(0) <: 0rd(0) <: 0 rd(U; V ) <: rd(U); rd(V ) rd(U | V ) <: rd(U) | rd(V ) rd(!U) <: \n!rd(!U) rd(.U) ; var <: .(rd(.U) ; var) Figure 3. Subtyping. B is subsumed by usage behavior A. Intuitively, \nA <: B means that if some value may be safely used according to A then it may also be safely used according \nto B. A <: B (A is a subtype of B) Notice that subtyping also apply to types by letting U <: V if and \nonly if x:U <: x:V . Subtyping axioms, de.ned in Figure 3, express the basic algebraic laws of the type \noperators discussed above. We abbreviate by A <:> B the fact that A <: B and B <: A.To save space, we \nabbreviate rules of the form x:U <: x:V by U <: V , and omit subtyping congruence rules. All type operators \nsatisfy the expected (covariant) subtyping congruence principles, with some exceptions, e.g., the arrow \nU |. V , which is contravariant in the domain U,and wr(V ), which is contravariant on V (see [13]). Particularly \ninteresting are the axioms de.ning the var behav\u00adior. We may derive var <: .var: clearly a fresh heap \nvariable offers an isolated behavior. The .rst axioms state that a variable can be subject to an unbounded \nnumber of uses, each use composed by a write and a read phase. Other axioms specify how the reading phase \nmay be behaviorally separated, depending on the type of the stored value. For example, the axiom for \nrd(U | V ) says that if a value of type U | V can be read from the variable, then the variable can also \nbe subject to independent reading at types U and V . This point is crucial: e.g., a heap variable may \nbe shared or aliased, only if the stored value also may be. Notice that the axiom for use, allowing a \ndifferent type U to be picked at different unfoldings of var,nat\u00adurally support strong updates [2] (updating \na heap variable to hold values of unrelated types at different points in time).  4.2 Typing Type judgments \nof our system have the form A fz e :: B (e types from A to z in B) where A and B are type assertions, \ne is an expression, and the index z is a variable. We refer to A as the pre-condition, and to B as the \npost-condition of the typing judgment. The behavioral type of (the value of) e, as determined by the \ntype system, appears embedded in assertion B.The variable z stands for such a value, and can only occur \nfree in B (not in A or e). This idea of scoping the return value z over the post-condition appears in \nthe Hoare triple types of [31], although here the type of z cannot be given apart from B.For an example, \nconsider a:use fz (.x.a := x):: z:.U|.0 ; a:rd(.U). This judgment asserts that evaluating the expression \n(.x.a := x) in a state providing a:use returns a functional value (identi.ed by z in the post-condition) \nthat must be used exactly once before the heap variable a can be read. We now progressively present the \nseveral rules of our type system, discussing each one on the way. 4.2.1 Structural Rules The identity \naxiom x:U fz x :: z:U (Id) asserts that access to the identi.er x simply returns the associated value, \nusable according to the type in the pre-condition (N.B: (Id) has the proviso that U is free from heap \nvariable types: typing rules for heap variable dereference are given below). The type system includes \nfour other structural rules. A crucial one is subtyping (Sub), which embeds into typing the basic subsumption \nprinciples. It allows assertions in type rules to be considered up to <:> ,and plays a role similar to \nthe consequence rule in Hoare logics. A <: A ' A ' fx e :: B ' B ' <: B (Sub) A fx e :: B Therulefor \nlet corresponds to cut (x not free in the conclusion) A fx e1 :: BB fy e2 :: C (Let ) A fy let x = e1 \nin e2 :: C The following parallel and sequential structural rules express basic frame principles. Rule \n(Par) allows the footprint of an expres\u00adsion to be enlarged along the spatial dimension, while rule (Seq \n) allows the footprint to be enlarged along the temporal dimension. A fx e :: B A fx e :: B (Par) (Seq \n) A | C fx e :: B | C A ; C fx e :: B ; C Given these two rules, the following deep frame rule is admissi\u00adble \nfor any active type assertion context E[-]. A fx e :: B (Frame ) E[A] fx e :: E[B]  4.2.2 Functional \nType We have the following typing rules for the .-calculus core. A|x:U fy e :: y:T (VAbs ) A fz .x.e \n:: z:U|.T A fz e1 :: z:U|.TB fx e2 :: x:U (App) A | B fy e1e2 :: y:T These rules are similar to the \narrow rules in linear or bunched [32] type systems, even if our semantics for |. is different. Given \nthe interpretation of A | B, (App) ensures that functions do not interfere with their arguments unsafely \nupon application. Notice that the type of the argument x is left 0 in the post-condition of the premise \nof (VAbs ), forcing the function body to fully exercise the behavior U of its parameter, consistently \nwith the argument-borrowing semantics of our functional type. The type of an argument-capturing function \nmay be rendered (.U) |. V , and the type of a function that can safely share the behavior of its argument \nwith its own behavior may speci.ed (!U) |. V .Be\u00adhavioral separation types allow many .ne-grained variations \nof functional behavior to be speci.ed (e.g., !(U |. V ) -a shareable function; (U |. V ) * -a non shareable \nbut repeatedly usable func\u00adtion, etc). Notice that in our typed language (as, e.g., in the monadic .-calculus) \none cannot encode let by application and abstraction. 4.2.3 Tuple Type The rules for tuples and .eld \nselection have the expected form. A fx e :: x:U A fz e :: z:l:T (Tuple ) (Sel) A fz [...l = e.. .]:: \nz:l:U A fx e.l :: x:T  Recall that .eld contents of tuples are evaluated lazily, as in [37], so (Tuple \n) allows a single .eld to be type checked.  4.2.4 Intersection Type We include as primitive the introduction \nrule And . A fy e :: BA fy e :: C A fy e :: B1 &#38; B2 (And ) (AndE ) A fy e :: B &#38; C A fy e :: \nBi Technically, we choose to absorb the elimination principles for intersection in the subtyping relation \n(e.g., A &#38; B <: A). However, familiar elimination rules AndE are admissible (using (Sub)). 4.2.5 \nBehavioral-Separation Types Structured behavioral-separation usages are assigned to basic val\u00adues (abstractions, \ntuples) by the following type rules: A fy v :: CB fy v :: D 0 fy v :: 0 (VStop ) (VSeq ) A ; B fy v :: \nC ; D !A1 | .. . | !An fx v::B A fy v::CB fy v::D (VShr) (VPar) !A1 | ... | !An fx v::!B A | B fy v :: \nC | D Rule (VShr) expresses that a value can be subject to any number of shared usages, if it only relies \non resources which may also be safely used by any number of shared usages. Interestingly, these rules \nallow values to satisfy crisper frame principles than the struc\u00adtural rules in Section 4.2.1, which apply \nto general expressions. For example, the following fat identity axiom and left-sequential frame rule \nturn out to be admissible for values, even if the corre\u00adsponding principles are not sound for arbitrary \nexpressions. B fy v :: C A fy v :: A (VId ) (VLSeq ) A ; B fy v :: A ; C 4.2.6 Isolated Type The rule \n(Iso) assigns to the post-condition of an expression an isolated type if it only depends on values of \nisolated type. .A1 | ... | .An fx e :: B (Iso) .A1 | ... | .An fx e :: .B The type rules for !A and .A \nare therefore similar, and express the basic comonadic principle associated to these type constructors \n(cf. the introduction rule for ! in intuitionistic linear logic), even if their meaning is quite different \n(sharing versus isolation). A remarkable property of any type T of the form !.U is that T <:> T | T and \nT <:> .T ,sothat T is both shared and isolated. 4.2.7 Sum Type Sum types are also handled by familiar \nlooking typing rules. A fy ec :: y : .i.I li:Ti xi:Ti | B fz ei :: C (Case ) A | B fz case ec of l(x) \n. e :: C A fz e :: z:Tj (Option ) A fz lj(e):: z: .i.I li:Ti As for function application, the type rule \nfor case ensures that the matched value is separated from the corresponding case branch, so to avoid \nunsafe interference.  4.2.8 Heap Variable Types We have already explained how heap allocated variables \nare mod\u00adeled in our system as special values, subject to a speci.c usage protocol de.ned by certain subtyping \naxioms. The type rule for a variable declaration types the body under the assumption of a sep\u00adarated \ncomplete protocol for the new variable, speci.ed by var. a:var | A fx e :: C (Var ) A fx var a in e :: \nC Rules for dereference and assignment are more interesting. We consider two typing rules for dereference, \nand two typing rules for assignment. The alternative typings express boundary cases on usage of the variable \nprotocol, which are not naturally captured by a single typing rule. We distinguish between reading just \na piece of the behavior stored in the variable (RdVB ), from reading the whole remaining stored behavior \n(RdVF ). a:rd(U) fx a :: x:U (RdVB ) a:rd(U); use fx a :: x:U | a:use (RdVF ) Rule (RdVF ) states that \neven if the precondition states that the next use of variable a is guarded by a read usage rd(U),the \nvariable content x:U is separated of the residual variable behavior a:use, specifying an empty variable. \nRule (RdVF ) expresses an important invariant ensured by the type system: the behavior stored in any \nheap variable is always separated from the continuation be\u00adhavior of the variable object itself (after \nall of its content gets read off). So the post-condition in the conclusion of (RdVF ) always holds, even \nif the type of the heap variable content is not explicitly declared as isolated (not of the form .U). \nWe also have two rules for assignment, depending on wether the behavior stored in the heap variable is \nisolated or borrowed. A fz v :: z:.U | a:wr(.U) (WrVF ) A fz a := v :: 0 A fz v :: z:U | a:use (WrVB \n) A fz a := v :: a:rd(U) In both rules, the stored value is required to be parallel separated from the \nheap variable, which must be in a ready-for-write state. Rule (WrVF) handles the case in which the value \nbehavior to be stored is isolated. Here, we only require the write capability, as the stored value may \nbe used anytime later. Rule (WrVB) handles the case in which the value behavior to be stored may be not \nisolated. In this case, one must ensure that all associated reads will happen before any sequential continuation \nof z:U, so a whole use is required in the premise, leaving the associated read usage active in the post-condition. \nIt is interesting to see why a rule as (WrVF ), but considering a non-isolated type for the stored value, \nwould not be sound. Let us consider a simple counterexample. r:U | a:wr(U) fx r :: x:U | a:wr(U) r:U \n| a:wr(U) fx a := r :: 0  r:U ; V | a:wr(U) fx a := r :: r:V r:U ; V | a:wr(U); rd(U) fx a := r :: r:V \n; a:rd(U) r:U ; V | a:use fx a := r :: r:V ; a:rd(U) This candidate derivation states that after executing \na := r the be\u00adhavior r:V is available before reading the variable a, thus violating the requirement that \nr must be used as U ; V . A correct typing is: r:U | a:use fx r :: x:U | a:use r:U | a:use fx a := r \n:: a:rd(U) r:U ; V | a:use fx a := r :: a:rd(U) ; r:V Typing rules for assignment require separation \nbetween heap vari\u00adable and stored value. This may suggest that typing of circular chains of references \nthrough the heap may be dif.cult, if not im\u00adpossible. Although it is clear that linear behaviors cannot \nrefer cir\u00adcularly to themselves, that is not the case for general behavioral separation types: some safe \ncircular chains may still support sep\u00adarated behaviors, due to the presence of quali.ed tuples, or just \nbecause of sharing (including invariant based separation). We illus\u00adtrate the point in Section 4.5, by \ntyping a version of Landin s knot. In the discussion above, we omitted recursion and recursive types. \nTo accommodate recursion typing judgements are equipped with a recursion variable environment ., which \nmaps expression variables Z to type judgments and type variables X to type asser\u00adtions (we have elided \nthe recursion environment in rules where it does not play any relevant role). This technique is inspired \nin fa\u00admiliar approaches to co-inductive types [34]), see [13] for details. We collect the rules of the \nbasic system in Figure 4. For clarity s sake, we present the type system in two steps, .rst without synchro\u00adnization \nconstructs, extended in Section 4.5 to the full language.  4.3 Typing the Collection Implementation \nWe get back to the running example in the Introduction. We claimed that a collection value may be assigned \nthe type .CC ,and the function newColl the type 0 |. .CC . We now discuss how such type is actually assigned \nby our type system. We .rst type the list nodes. Consider the following abbreviations InitNode setElt \n:(nat |. 0) ; setNext :(!.PNode |. 0) INode !getNext :PNode | !getElt :nat Node InitNode ; !.INode PNode \n!Opt(INode ) The type PNode de.nes the behavior of a pointer to a list of (initialized) nodes, as created \nby the function newNode .We use option types to type list pointers: either the null pointer, tagged NULL(-) \nor a value of type INode , tagged by NODE(-). Directed by rules VSeq , VShr and Tuple , the system assigns \ntype Node to the tuple [setElt = \u00b7\u00b7\u00b7 ] by checking that it can be subject to the given behavioral separation \nusage, while safely using its local resources (the variables next and elt ). The vari\u00adable elt gets assigned \ntype wr(nat) ; !rd(nat): it is written just once (in the operation setElt ), and available for shared \nread\u00ading from then on. Notice that var <: wr(nat) ; !rd(nat),since nat is assumed shared (nat <: !nat). \nVariable next is typed wr(.PNode ) ; !rd(PNode ) ; var. After initialization (execution of the behavior \nInitNode ), the node type evolves to !.INode ; only operations getNext and getElt are available, usable \nby an unbounded number of aliases or concurrent clients. The shared be\u00adhavior INode of the list nodes \nsupports sharing of the linked list and allows the type !scan :0 to be assigned within CC. Recall CC \n(init :str|.0) ;(!getId :str |(!scan :0 ; add:nat|.0) * ) Checking newCol lection against type 0 |. .CC \n,involves ver\u00adifying that the object tuple [init = \u00b7\u00b7\u00b7 ] representing a col\u00adlection can be safely subject \nto the behavioral separation usage speci.ed by CC .After init ,the variable hd is assigned type rd(!.PNode \n) ; var. This type is kept invariant between iterated executions of the add and scan operations. It is \nparticularly interesting to see how the scan operation is typed. The footprint precondition is hd:rd(!.PNode \n) (note that !.PNode <: !.PNode ; !.PNode ). After the assignment s := hd, the type assertion is s:rd(PNode \n) ; var. We detail the derivation of the scan loop, showing the key judgments. 1 s:use f. x nil :: s:use \n2 n:INode | s:use f. x s := n.getNext :: s:rd(PNode ) ; use 3 s:rd(PNode ) ; use f. x L :: s:use 4 n:INode \n| s:use f. x s := n.getNext ; L :: s:use 5 s:rd(PNode ) ; use fx . case s of ... :: s:use 6 s:rd(PNode \n) ; use f\u00d8 x rec L.case .. . :: s:use 7 s:rd(PNode ) ; var f\u00d8 x rec L.case .. . :: s:var Derivation of \n2 uses (WrVB). 5 is derived from 1 and 4 by (Case). 7 is derived from 6 by (Seq) and (Sub). Let .(L)= \ns:rd(PNode ) ; use fx s:use be the recursion environment intro\u00adduced by (Rec) deriving 6 from 5, and \nused by (RecVar) in 3. Fully detailed typing derivations for the collection and other examples in this \npaper are given in [13].  4.4 Type Preservation and Progress We now state the main correctness results \nfor the basic type sys\u00adtem, namely the subject reduction property and progress for well\u00adtyped programs. \nType preservation and progress ensure that in a well typed program all values are properly used according \nto their assigned behavioral-separation types. In particular, given the struc\u00adture of types assigned \nto variables, no write/write or read/write races while writing to heap variables are possible (it is \nnot the case that use <: (wr(U) | wr(V )) ; T or use <: (rd(U) | wr(V )) ; T ). We thus introduce rules \ntyping for runtime con.gurations h ; S h ; St E[C] C fx e :: x:T \u00d8 ; \u00d8 t 0 (E) (T ) h ; S \u00b7 t(e) t E[t:t \n(T )] h ; St A A <: B h ; St A A fx v :: B (S) (H ) h ; St B h, n . v ; St B{n:var/x} In rule (T ), \nE is an active type assertion context. The notation B{n:var/x} (with n fresh in B) represents the update \nof asser\u00adtion B where the behavior pieces assigned to x . Dom(B) are substituted in place by reads to \na new heap variable n: essentially, all occurrences of the form x:U in type B are replaced by n:rd(U) \nand a n:var is inserted in sequential and linear position relative to all n:rd(U) s. We can now state \nour .rst type preservation result. THE ORE M 4. 3. If h ; St A and h ; S . h ' ; S ' then h ' ; S ' tA. \nAn expression e is live, noted live(e), if it is not a value. A set S of threads is live, noted live(S) \nif there is some thread t(e) in S such that live(e). We can then prove THE ORE M 4. 4. If h ; St A and \nlive(S) then h ; S . h ' ; S ' . Detailed proofs and de.nitions are given in [13]. 4.5 Invariant-based \nSeparation We now extend the basic type system to cover the full core language with sync(a)e blocks, \nand invariant-based reasoning. As explained in Section 3, each heap variable is equipped with an associated \nlock (pretty much like a Java object is). To each lock, a resource invariant, expressed by an isolated \ntyping assertion, is associated for veri.cation purposes. We only accept for lock invariant a heap assertion \nR such that R <: .R (let us call heap assertion any type assertion that just refers to heap variable \ntypes -var, use,etc). Handling lock invariants requires some additional structure in our type system: \nwe add to typing judgments an invariant mapping ., that associates to heap location locks their invariants: \nA f. z e :: B (e types from A to z in B under .) The invariant mapping is propagated untouched by all \ntyping rules, except in the new rule for variable declaration, which may intro\u00adduce a lock invariant, \nand in the rules for sync(n)e and sy(n)e, which make use the lock invariant associated to heap location \nn: .\\a .\\a .(a) | A fx e :: .(a) | B A fx e :: .(a) | B (Sync) (Sy) A f. x sync(a)e :: B A f. x sy(a)e \n:: B .{R/a} A <: B | Ra:var | B fx e :: C (Var ) A f. x var a in e :: C Without loss of generality, \nwe assume that the invariant associated to some heap variable s lock does not talk about the variable \nitself, but only about other heap variables in scope. Interestingly, notice that the rule for sync directly \nexpresses an anti-frame principle [35]. Consider the code snippet describing an atomic variable. let \natomic = .v. var s in s := v; var lock in [ set = .x.sync(lock)s := x, get = sync(lock)s ] in ...  .A1 \n| ... | .An fx e :: B !A1 | ... | !An fx v :: B 0 fy v :: 0 (VStop ) x:U fy x :: y:U (Id) (Iso) (VShr) \n.A1 | ... | .An fx e :: .B !A1 | ... | !An fx v :: !B A <: A ' A ' fx e :: B ' B ' <: B A fy e :: BA \nfy e :: C A fx e1 :: BB fy e2 :: C (Sub) (And ) (Let ) A fx e :: B A fy e :: B &#38; C A fy let x = \ne1 in e2 :: C A fx e :: B A fx e :: B A fx e1 :: x:U |. TB fy e2 :: y:U (Seq ) (Par) (App) A ; C fx e \n:: B ; C A | C fx e :: B | C A | B fz e1e2 :: z:T A fx e :: x:U A fx e :: x:l:T A | x:U fz e :: z:T .(Z)= \n(A fx B) (Tuple ) (Sel) (VAbs ) (RecVar ) A fx [. ..l = e ...]:: x:l:U A fx e.l :: x:T A fz .x.e :: z:U \n|. T A f. x Z :: B .{Z/(AIxB)} A fy ec :: y : .i.I li:Ti xi:Ti | B fz ei :: C A fz e :: z:Tj A fx e \n:: B (Case ) (Option ) (Rec ) A | B fz case ec of l(x) . e :: C A fz lj(e):: z: .i.I li:Ti A fx . rec(Z)e \n:: B .{X/A} A fy v :: CB fy v :: D A fy v :: CB fy v :: D .(X)= A A fx v :: B (VSeq ) (VPar) (VRecVar \n) (VRec) A ; B fy v :: C ; D A | B fy v :: C | D A fx . v :: X A fx . v :: rec(X)B a:var | A fx e :: \nC A fz v :: z:U | a:use (Var ) (WrVB ) a:rd(U); use fx a :: x:U | a:use (RdVF ) A fx var a in e :: C \nA fz a := v :: a:rd(U) A fz v :: z:.U | a:wr(.U) A fx e :: x:T A fx e :: x:t (T ) (WrVF ) a:rd(U) fx \na :: x:U (RdVB ) (Fork ) (Wait ) A fz a := v :: 0 A fx fork e :: x:t (T ) A fx wait e :: x:T Figure 4. \nTyping Rules. Let U be a shared isolated type (a type such that U <: !.U,see Section 4.2.6). We can then \nderive the typing atomic :U |.(!set:(U |. 0) | !get:U) by associating to lock the invariant s:rd(U) ; \nvar. This type states that atomic is a function that returns a state-full variable object that can be \nsafely used concurrently by an arbitrary number of setters and getters. Notice that if any of the two \nsync blocks is removed, atomic would only be typed by a behavioral-separation type that sequentializes \nthe get and set operations somehow. For example, if both sync blocks are removed, a possible typing is \natomic :U |.(!get:U ; set:(U |. 0)) * which would still allow sharing (aliasing, or concurrent usage) \nof the get method but not of the set method . This example illustrates how the (concurrency control) \nmoni\u00adtor construction can be explained as a type coercion operator in our type structure, e.g., coercing \n(A ; B) &#38;(B ; A) to A | B. Recall that by the exchange law we can derive A | B <: (A ; B) &#38;(B \n; A),ex\u00adpressing the basic interleaving principle that a value of type A | B can be used according to \n(A ; B) &#38;(B ; A). Conversely, given a value providing the behavior (A ; B) &#38;(B ; A), we may in \ngeneral coerce it to the behavior A | B, by wrapping it inside a monitor en\u00adforcing the appropriate usage \nprotocol by means of locking. The monitored object then exports two behaviorally parallel separated interfaces \nA and B, even if there is potentially sharing / interference between the implementations of A and B. \nOur type system natu\u00adrally assigns A | B to the monitored object, relying on the modular type rules for \nlocking and on standard invariant-based reasoning. Invariant based reasoning is also useful in a non-concurrent \nset\u00adting, in which case we may consider the sync operator essentially as a typing device for potentially \nshared (aliased) usages. We elab\u00adorate on this point using a simple, yet non-trivial example: a FIFO \nqueue implemented with a linked list data structure with head and tail pointers (code listed in Figure \n5). We describe the type Node assigned to node value in the list: Node HeadT | TailT SHeadT Opt(HeadT \n) HeadT .unlink :.SHeadT TailT .link :.SHeadT |. 0 SQueue let new = .[].var next in next := NULL; var \nlock in [ unLink = sync(lock)let x = next in (next := NULL; x) link = .x.sync(lock)next := x ] in var \nhead , tail in ( head := NULL; tail := NULL; [ enq = let n =(new nil) in case tail of NULL . (head := \nNODE(n); tail := NODE(n)) NODE(y) . (y.link NODE(n)); tail := NODE(n)), deq = case head of NULL . head \n:= NULL NODE(y) . (head := y.unLink ; case head of NULL . tail := NULL; head := NULL NODE(y) . head := \nNODE(y)) ] Figure 5. A FIFO Queue Implemented with a Linked List Our type system assigns to function \nnew the type !(0 |. Node ). Node is a parallel separation type, exposing, on the one hand, the behavior \nto be assigned to the head pointer or to the previous node in the list, and, on the other hand, the behavior \nto be assigned to the tail pointer. The safe separation of behaviors is enforced by the use of invariant \nbased separation, associating to lock the invariant next:rd(.SHeadT ) ; var. So, for example, aliasing \nof n in (head := NODE(n); tail := NODE(n)) type checks since given n:Node we may separate and assign \ntype SHeadT to the .rst occurrence of NODE(n) and Opt(TailT ) to the second. We then derive fq SQueue \n:: SQueueI where SQueueI (q:enq:0 &#38; q:deq :0) * This type says that the declared behavioral separation \nprotocols are enforced, even in the presence of possible interference between the state accessible from \nhead and tail . Additionally, type Node clearly says that both link and unlink operation are used at \nmost once in each list node, the .rst through the tail alias, the other by the head alias, and that this \ndescribes the full behavior of a node. Type SQueueI above declares a sequential behavior for the queue, \nwhere enq and deq operations cannot be selected concurrently. A (typeable) concurrent queue can be de.ned \nby guarding the sequential implementation described with appropriate sync blocks: letCQueue = var head \n, tail in ( head := NULL; tail := NULL; var qinv in [ enq = sync(qinv)(.. .) deq = sync(qinv)(.. .)] \nFor type checking this code we associate to qinv the invariant head :rd(.SHeadT ) ; var | tail :rd(.STailT \n) ; var.We then de\u00adrive fq CQueue :: QueueCI for QueueCI !enq:0 | !q:deq :0. The QueueCI interface type \nexplicitly says that the queue can be safely used by many concurrent clients, as in. e.g., let q = C \nQueue in (q.enq; q.enqlq.deq ; q.deq ) Notice that in the assertion typing SQueue only sequential types \nappear, that is, no (- | -) or !(-). So only a single thread may be visiting the code of SQueue. This \nmeans (informal claim) that the lock lock associated to each list node will always be free. So, the sync \nblocks in Node are operationally irrelevant, and may be seen as an auxiliary device for bracketing code \nregions subject to invariant-based type checking of separation. On the other hand, sync blocks are of \ncourse essential to CQueue, if it is to be actually used according to the more permissive type QueueCI \n. As a further example, we present a code fragment tying a Landin s knot, thus creating a circular chain \nof references in the higher-order store. We may verify that it can be typed by assigning to the (operationally \nuseless) lock linv the invariant a:rd(!.(0 |. 0)) ; var, and to the function f the type !.(0 |. 0). var \na in ( a := .x.x; var linv in let f = .y.(sync(linv )(a) y) in (sync(linv )(a := f); (f nil)) ) In principle, \nour type system could be re.ned to distinguish be\u00adtween two different scenarios for invariant based reasoning, \none already useful to handle interference in sequential code, another one to handle interference in truly \nconcurrent code, only the latter would require real locks to be introduced in the code. We leave this \ndiscussion for future consideration, for the issue seems orthogonal to the main purpose of this paper. \nThe key point to highlight here is that our typing principles for the sync construct seem to capture \na useful and general form of invariant reasoning about safe interfer\u00adence in the context of a behavioral \nseparation type system. We can now state the type preservation result for the full core language. To \nthat end, typing for runtime con.gurations is gener\u00adalized to consider the declaration of invariants. \nThis is achieved by a global invariant mapping ., which assigns lock invariants to lo\u00adcations: essentially, \nthe rule (H) of Section 4.4 is replaced by the following rules, covering the two possible lock states \n(see [13]). h ; St. A | RA f. x v :: B h, n0 . v ; St.{R/n} B{n:var/x} (HU) h ; St. AA f. x v :: B h, \nn-1 . v ; St.{R/n} B{n:var/x} (HL) THE ORE M 4. 5. If h ; St. A and h ; S . h ' ; S ' then h ' ; S ' \nt. A. A progress property also holds for the full core language with con\u00adcurrency and synchronization \nprimitives, but in a slightly weaker sense, due to the possibility of deadlock on sync blocks (see [13]). \n  5. Related Work The concept of separation results from a research stream whose origins can be traced \nback to the seminal works of Reynolds on syntactic control of interference [36, 37]. Separation logics \nextend classical Hoare logic with new connectives, in particular the separa\u00adtion conjunction, which allows \nto specify the .ne-grained structure of states in programs manipulating references, and enables local \nreasoning to successfully tackle programs with references [39] and concurrency [33]. More recently, separation \nlogic has motivated the introduction of Hoare Type Theory [31], and has been extended to languages with \nhigher-order store [40]. These works focus on the identi.cation of higher-order frame principles for \nstate-based local reasoning. The idea of assigning a parallel separation type to some value, even when \nthere is (safe) interference between the imple\u00admentations of the separated behaviors, is reminiscent \nof concepts explored in .ctional separation [25], concurrent abstract predicates [17], and super.cially \nsubstructural types [28]. Again, these works are carried out within state-based separation logics. We \nhave shown how a type based approach to behavioral separation, in principle less precise for speci.cation \npurposes than a full logic, can already be used to enforce interference safety on programming languages \nidioms and features not yet in the scope of such approaches, such as higher-order store and .rst class \nconcurrency. Work on spatial log\u00adics for concurrent systems [11, 15] offered remote inspiration for our \napproach, but explored different notions of separation , useful to reasoning about distribution and mobility, \nrather than about inter\u00adference. Although the fundamental notion of separation applies to many kinds \nof computational structures [14, 20], the idea of com\u00adbining separation with behavioral types to discipline \ninterference in a realistic programming language, as we do here, does not seem to have been considered \nbefore. Various forms of behavioral types have been independently in\u00adtroduced by several authors with \nthe intent of classifying usage pat\u00adterns of computational objects [16, 21, 24]. Some of these works \nhave motivated more re.ned veri.cation techniques, for example, to check resource usage disciplines [23] \nin functional programs. A particular case of behavioral types are the so-called session types, intended \nto discipline message exchanges between partners in dis\u00adtributed systems. Although initially proposed \nfor systems with in\u00adteraction between exactly two partners [21], session types have been extended to \nsystems with an arbitrary number of partici\u00adpants [22]. Our notion of type assertion is loosely related \nwith the notion of global type introduced in [22], in the sense that it needs to talk about the joint \nbehavior of several entities. A version of ses\u00adsion types to discipline interactions between concurrent \nobjects was developed in [18], but does not attempt to deal with interference or aliasing. More recently, \nthe .rst author and Pfenning developed an interpretation of session types in linear logic [12], which \nalso inspired some aspects of the theory presented here. Connections between session types and separation \nlogic have also been investi\u00adgated in [41], but focusing on disciplining the transference of re\u00adsources \nin process communications. In prior work, we attempted a very preliminary approach to the concept of \nbehavioral separation [10]. However, the developments in this paper clarify the notion of behavioral \nseparation type in the context of a clean substructural type theory, based on a .-calculus with imperative \nand concurrency constructs, and are much more general and expressive. Several works have proposed type-based \napproaches to disci\u00adpline aliasing and concurrency control in various programming lan\u00adguages, usually \nexploiting type and effect systems [1, 8]. Owner\u00adship types have also been studied to discipline aliasing \nand con\u00adcurrency [6, 7]. Some of these works have led to the development of powerful programming tools \n[27]. Typically, these works do not focus on capturing the dynamic behavior of resources at a deeper \nlevel, as we do here, but on tracking occurrences of identi.ers, locks, permissions, regions, and data \ndependencies, essentially re\u00adsorting to linearity. An important exception is typestate, which uses a \nstate-based approach to specify resource usage protocols in ob\u00adject oriented languages [3]. A key ingredient \nof the typestate ap\u00adproach is the use of primitive permissions to capture usage idioms, rather than resource \nbehavior. In parallel research we are investi\u00adgating combinations of separation with typestate [29]. \nTechniques to support expressive borrowing idioms in the context of typestate have been recently proposed \nin [30].  6. Concluding Remarks We have introduced behavioral separation as a general principle for \ndisciplining interference, due either to aliasing or concurrency, by combining concepts from separation \nlogic and behavioral type sys\u00adtems. We have designed a behavioral separation type system that il\u00adlustrates \nthe concept using a higher-order imperative functional lan\u00adguage extended with concurrency and synchronization \nprimitives. Our type system is proven sound using proof theoretic techniques. We have also shown that \nthe expressiveness of our approach goes beyond the state of the art for type-based veri.cation of alias\u00ading \nand concurrency, and provided several challenging examples involving .ne-grained state manipulation, \nthread based concur\u00adrency, and synchronization constructs. Further examples, includ\u00ading the implementation \nof a concurrent queue based on a double linked list can be found in [13]. In ongoing work, we have already \ndesigned an algorithm that can effectively type check programs in our core language with a reasonable \nannotation burden these re\u00adsults will be reported elsewhere. We are also investigating general\u00adizations \nto invariant-based separation, along the lines suggested in Section 4.5, and the extension of our basic \nframework with depen\u00addent types, which would support more precise speci.cations. Acknowledgments. Thanks \nto Peter O Hearn for insightful remarks on safe interference, to Jorge A. Perez, Rodrigo Rodrigues, and \nto the anonymous reviewers for useful comments. Work co-supported by FCT Pest UI527 2011; PDTC/104583; \nCMU-PT NGN-44.  References [1] M. Abadi, C. Flanagan, and S. N. Freund. Types for safe locking: Static \nrace detection for Java. ACM TOPLAS, 28(2):207 255, 2006. [2] A.Ahmed,M.Fluet, and G. Morrisett. L3: \nA Linear Language with Locations. Fundam. Inform., 77(4):397 449, 2007. [3] K. Bierhoff and J. Aldrich. \nModular Typestate Checking of Aliased Objects. In OOPSLA 2007, pages 301 320, 2007. [4] S. L. Bloom and \nZ. \u00b4 Esik. Free Shuf.e Algebras in Language Varieties. Theoretical Computer Science, 163(1&#38;2):55 \n98, 1996. [5] R. Bornat, C. Calcagno, P. W. O Hearn, and M. Parkinson. Permission accounting in separation \nlogic. In POPL 2005, pages 259 270, 2005. [6] C. Boyapati, R. Lee, and M. C. Rinard. Ownership types \nfor safe programming: preventing data races and deadlocks. In OOPSLA 2002, pages 211 230. ACM, 2002. \n[7] C. Boyapati, B. Liskov, and L. Shrira. Ownership types for object encapsulation. In POPL 2003, 2003. \n[8] C. Boyapati and M. C. Rinard. A Parameterized Type System for Race-Free Java Programs. In OOPSLA \n2001, pages 56 69, 2001. [9] J. Boyland. Checking Interference with Fractional Permissions. In SAS 2003, \nvolume 2694 of LNCS, pages 55 72. Springer-Verlag, 2003. [10] L. Caires. Spatial-Behavioral Types for \nConcurrency and Resource Control in Distributed Systems. Theoretical Computer Science, 402(2\u00ad3):120 141, \n2008. [11] L. Caires and L. Cardelli. A Spatial Logic for Concurrency (Part I). Information and Computation, \n186(2):194 235, 2003. [12] L. Caires and F. Pfenning. Session Types as Intuitionistic Linear Propositions. \nIn CONCUR 10, volume 6269 of LNCS, pages 222 236. Springer-Verlag, 2010. [13] L. Caires and J. C. Seco. \nThe Type Discipline of Behavioral Separa\u00adtion. Technical report, TR-DI-FCT-UNL, 2012. [14] C. Calcagno, \nP. W. O Hearn, and H. Yang. Local Action and Abstract Separation Logic. In LICS 2007, pages 366 378, \n2007. [15] L. Cardelli and A. D. Gordon. Anytime, Anywhere. Modal Logics for Mobile Ambients. In POPL \n2000, pages 365 377. ACM, 2000. [16] S. Chaki, S. Rajamani, and J. Rehof. Types as models: Model Check\u00ading \nMessage-Passing Programs. In POPL 2002, pages 45 57, 2002. [17] T. Dinsdale-Young, M. Dodds, P. Gardner, \nM. J. Parkinson, and V. Vafeiadis. Concurrent Abstract Predicates. In ECOOP 2010,vol\u00adume 6183 of LNCS, \npages 504 528. Springer-Verlag, 2010. [18] S. J. Gay, V. Thudichum Vasconcelos, A. Ravara, N. Gesbert, \nand A. Z. Caldeira. Modular Session Types for Distributed Object-oriented Programming. In POPL 2010, \npages 299 312, 2010. [19] C. A. R. Hoare, B. M \u00a8oller, G. Struth, and I. Wehrman. Concurrent Kleene \nAlgebra. In CONCUR 09, volume 5710 of LNCS, pages 399 414. Springer-Verlag, 2009. [20] T. Hoare and \nP. W. O Hearn. Separation Logic Semantics for Com\u00admunicating Processes. EN Theo. Computer Science, 212:3 \n25, 2008. [21] K. Honda, V. T. Vasconcelos, and M. Kubo. Language Primitives and Type Discipline for \nStructured Communication-Based Programming. In ESOP 1998, volume 1381 of LNCS, pages 122 138. Springer, \n1998. [22] K. Honda, N. Yoshida, and M. Carbone. Multiparty Asynchronous Session Types. In POPL 2008, \npages 273 284. ACM, 2008. [23] A. Igarashi and N. Kobayashi. Resource Usage Analysis. In POPL 2002, pages \n331 342, 2002. [24] A. Igarashi and N. Kobayashi. A Generic Type System for the Pi-Calculus. Theoretical \nComputer Science, 311(1-3):121 163, 2004. [25] J. B. Jensen and L. Birkedal. Fictional Separation Logic. \nIn ESOP 2012, LNCS, pages 377 396. Springer-Verlag, 2012. [26] Cliff B. Jones. Splitting Atoms Safely. \nTheoretical Computer Science, 375(1-3):109 119, 2007. [27] R. Bocchino Jr., S. Heumann, N. Honarmand, \nS. Adve, V. Adve, A. Welc, and T. Shpeisman. Safe Nondeterminism in a Deterministic\u00adby-default Parallel \nLanguage. In POPL 2011, pages 535 548, 2011. [28] N. R. Krishnaswami, A. Turon, D. Dreyer, and D. Garg. \nSuper.cially Substructural Types. In ICFP 12, pages 41 54. ACM, 2012. [29] Milit ao, F. and Aldrich, \nJ. and Caires, L. Aliasing control with view\u00adbased typestate. In FTFJP 10, pages 7:1 7:7. ACM, 2010. \n[30] K. Naden, R. Bocchino, J. Aldrich, and K. Bierhoff. A Type System for Borrowing Permissions. In \nPOPL 2012, pages 557 570, 2012. [31] A. Nanevski, J. G. Morrisett, and L. Birkedal. Hoare Type Theory, \nPolymorphism and Separation. J. Fun. P., 18(5-6):865 911, 2008. [32] P. W. O Hearn. On Bunched Typing. \nJ. Fun. P., 13(4):747 796, 2003. [33] P. W. O Hearn. Resources, Concurrency, and Local Reasoning. Theor. \nComput. Sci., 375(1-3):271 307, 2007. [34] B. Pierce. Types and Programming Languages. MIT Press, 2002. \n[35] Franc\u00b8ois Pottier. Hiding local state in direct style: A higher-order anti\u00adframe rule. In LICS 08, \npages 331 340, 2008. [36] J. C. Reynolds. Syntactic Control of Interference. In POPL 78, pages 39 46, \n1978. [37] J. C. Reynolds. Syntactic Control of Interference, Part 2. In ICALP 89, volume 372 of LNCS, \npages 704 722. Springer, 1989. [38] J. C. Reynolds. Design of the programming language FORSYTHE, pages \n173 233. Birkhauser Boston Inc., Cambridge, MA, USA, 1997. [39] J. C. Reynolds. Separation Logic: A Logic \nfor Shared Mutable Data Structures. In LICS 2012, 2002. [40] J. Schwinghammer, L. Birkedal, B. Reus, \nand H. Yang. Nested Hoare Triples and Frame Rules for Higher-order Store. Logical Methods in Computer \nScience, 7(3), 2011. [41] J. Villard, E. Lozes, and C. Calcagno. Proving copyless message passing. In \nAPLAS 2009, volume 5904 of LNCS, pages 194 209. Springer-Verlag, 2009.  \n\t\t\t", "proc_id": "2429069", "abstract": "<p>We introduce the concept of behavioral separation as a general principle for disciplining interference in higher-order imperative concurrent programs, and present a type-based approach that systematically develops the concept in the context of an ML-like language extended with concurrency and synchronization primitives. Behavioral separation builds on notions originally introduced for behavioral type systems and separation logics, but shifts the focus from the separation of static program state properties towards the separation of dynamic usage behaviors of runtime values. Behavioral separation types specify how values may be safely used by client code, and can enforce fine-grained interference control disciplines while preserving compositionality, information hiding, and flexibility. We illustrate how our type system, even if based on a small set of general primitives, is already able to tackle fairly challenging program idioms, involving aliasing at various types, concurrency with first-class threads, manipulation of linked data structures, behavioral borrowing, and invariant-based separation.</p>", "authors": [{"name": "Lu&#237;s Caires", "author_profile_id": "81100101743", "affiliation": "Universidade Nova de Lisboa, Lisboa, Portugal", "person_id": "P3977965", "email_address": "luis.caires@di.fct.unl.pt", "orcid_id": ""}, {"name": "Jo&#227;o C. Seco", "author_profile_id": "81100132519", "affiliation": "Universidade Nova de Lisboa, Lisboa, Portugal", "person_id": "P3977966", "email_address": "joao.seco@di.fct.unl.pt", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429103", "year": "2013", "article_id": "2429103", "conference": "POPL", "title": "The type discipline of behavioral separation", "url": "http://dl.acm.org/citation.cfm?id=2429103"}