{"article_publication_date": "01-23-2013", "fulltext": "\n Towards Fully Automatic Placement of Security Sanitizers and Declassi.ers Benjamin Livshits Stephen \nChong Microsoft Research Harvard University livshits@microsoft.com chong@seas.harvard.edu Abstract A \ngreat deal of research on sanitizer placement, sanitizer correctness, checking path validity, and policy \ninference, has been done in the last .ve to ten years, involving type sys\u00adtems, static analysis and run-time \nmonitoring and enforce\u00adment. However, in pretty much all work thus far, the burden of sanitizer placement \nhas fallen on the developer. However, sanitizer placement in large-scale applications is di.cult, and \ndevelopers are likely to make errors, and thus create security vulnerabilities. This paper advocates \na radically di.erent approach: we aim to fully automate the placement of sanitizers by ana\u00adlyzing the \n.ow of tainted data in the program. We argue that developers are better o. leaving out sanitizers entirely \ninstead of trying to place them. This paper proposes a fully automatic technique for san\u00aditizer placement. \nPlacement is static whenever possible, switching to run time when necessary. Run-time taint track\u00ading \ntechniques can be used to track the source of a value, and thus apply appropriate sanitization. However, \ndue to the run-time overhead of run-time taint tracking, our technique avoids it wherever possible. Categories \nand Subject Descriptors D.2.4 [Software/ Program Veri.cation ]: Validation; D.3.4 [Processors ]: Com\u00adpilers; \nD.4.6 [Operating Systems ]: Security and Protection Information .ow controls General Terms Languages, \nSecurity, Veri.cation Keywords Security analysis, vulnerability prevention 1. Introduction Tracking of \nexplicit information .ow has received a great deal of attention in recent years. Two primary applications \nfor explicit information .ow tracking stand out prominently: preventing injection attacks within web \napplications such as cross-site scripting (XSS) and SQL injection; and  preventing private data leaks, \nsuch as those recently observed in a variety of popular mobile applications [10].  Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 13, January 23 25, \n2013, Rome, Italy. Copyright c &#38;#169; 2013 ACM 978-1-4503-1832-7/13/01. . . $15.00 These attacks \nhave motivated a great deal of research in the last .ve to ten years on sanitizer placement, sanitizer \ncorrectness [15, 45], checking path validity, and policy in\u00adference [23, 41], involving type systems \n[8, 32], static anal\u00adysis [17, 18, 22, 42, 43, 47], and run-time monitoring and enforcement [6, 7, 11, \n25].1 Much academic work in this space focuses on .nding missing sanitizers and is applied to relatively \nsmall appli\u00adcations. Several pro jects have explored the use of run-time techniques, motivated in part \nby the scalability and preci\u00adsion challenges that static analysis typically encounters. Ad\u00additional motivation \nfor exploring run-time techniques comes from the complexity of large-scale web applications with multiple, \npotentially nested sanitizers, which recent assess\u00adments [38, 39] suggest is well beyond the ability \nof developers to address using static reasoning and code reviews. We also feel that the run-time approach \nis most prac\u00adtical in the long run. However, the overhead of run-time approaches can be considerable. \nPrior work on sanitizer placement advocates dynamic sanitizer placement through a combination of inline \ninstrumentation [25] and library\u00adbased instrumentation [6, 7]. The main advantage of library\u00adbased instrumentation \nis reduced overhead: only library code (as opposed to application code) needs to be instrumented. However, \nlibrary-based approaches do not deal well with in\u00adformation propagated through non-library code and data \nstructures such as char[], byte[], and custom character\u00adlevel sanitizers. Custom character-level sanitizers \nare quite common, and sanitizers typically deal with string data at the level of characters [15]. The \noverhead of these approaches varies, but is generally between 1 20%, depending on the application. In \nthe case of library-based instrumentation, the depth of the data propagation path largely determines \nthe overhead. In large enterprise applications, we know that data can undergo a high number of transformations \nduring its lifetime [28], resulting in higher overhead than experi\u00adments with smaller applications would \nlead us to believe. Prior research has proposed the use of pointer analysis as a way to reduce the number \nof instrumentation points [2, 24]. However, the number of program points that are deemed to be reachable \nfrom sources and may .ow to sinks is still quite large in practice, leading to a high number of instrumenta\u00adtion \npoints. We feel that it is crucial to develop novel ways to decrease the performance penalty for inline \ninstrumentation to make it practical. 1For simplicity, in the rest of this paper, we shall talk pri\u00admarily \nabout sanitizer placement (for integrity preservation). Our techniques apply equally well to the placement \nof declassi.ers (for con.dentiality preservation).   D, D) are shown in rows and sink types ( , , ) \nare shown in columns. We use 0 as a special kind of source type and sink type, for data production or \nconsumption that is not relevant to security (such as constant strings or other trusted sources of data). \nThus, we assume that every source and sink of data has a type that appears in the table. Entries in the \ntable indicate which sanitizer should be applied to data. We use metavariable P to range over policies, \nI to range over source types, O to range over sink types, and S to range over sanitizers. We write P(I \n, O) for the entry in policy P for source I and sink O. We assume that a node cannot be both a source \nand a sink, and write t(n) for the source 0 S1 S1 S4 . S1 S2 . . S2 S1 S3 . D . . S3 . D 0 . . .. Figure \n2. Example policy. Sources shown vertically; sinks shown horizontally. . means no sanitization re\u00adquired. \ntype or sink type of node n. For example, in Figure 1, where Dand ni is the node labeled with integer \ni we have t(n3) = t(n19) = . Since n11 is neither a source nor a sink, t(n11) Figure 1. Motivating example \nof a small, but illustrative .ow graph. Sources are at the top; sinks are at the bottom. We aim to fully \nautomate the placement of sanitizers by analyzing the .ow of tainted data. A key observation is that, \ngiven a policy, sources and sinks within the application in\u00adduce restrictions on the placement of sanitizers. \nIt is di.\u00adcult for developers to place sanitizers so as to satisfy all of these restrictions, especially \nin large-scale applications [39]. In fact, we argue that developers are better o. leaving out sanitizers \nentirely, allowing them to be placed automatically. In this paper we propose a fully automatic technique \nfor sanitizer placement. The goal is to minimize both run-time overhead and code bloat due to instrumentation. \nSanitizer placement is static whenever possible, switching to run\u00adtime techniques when necessary. We \nperform analyses on the inter-procedural data.ow graph of the program to identify where sanitizers can \nbe placed, and where values must be tracked at run-time in order to determine which sanitizer to apply. \nIn order to reduce run-time overhead, we resort to run-time tracking only when necessary. 1.1 Sanitization \nPolicies Large applications come with libraries of sanitizers. Devel\u00adopers are heavily discouraged from \nwriting their own san\u00aditizers. This is in part because most of the time, they get them wrong [4, 15]. \nSince sanitizers are implemented as li\u00adbrary functions, they are typically pure functions, with type \nString . String. Policies can be given in the form of a table that for every type of data source and \ndata sink indicates the appropriate sanitizer for values that .ow from that source to that sink. Policies \nare declarative speci.cations, and can both provide developer guidance and simplify the code review process. \nSection 2 gives examples of policies. 1.2 Data.ow Graphs and Policies Figure 1 shows a simple data.ow \ngraph that will be used as an example throughout this paper. The policy for this example graph is shown \nin Figure 2. Source types (0, D, is unde.ned. For example, let P be the policy in Figure 2. Data originating \nfrom a source of type D and going to a sink of type should have sanitizer S1 applied to it. If P(I , \nO) = . then no sanitization should be applied data .owing from source type I to sink type O. This may \nindicate, for example, that constant string data should not be sanitized before being displayed to the \nuser.  1.3 Contributions This paper makes the following contributions: Fully automatic sanitizer placement. \nWe argue that sanitizer placement should be automatic, given a policy and an application, instead of \nthe current approach of the developer being responsible for getting it right.  Node-based placement. \nWe propose a simple node\u00adbased strategy for static sanitizer placement. While it is simple to implement \nand incurs no run-time overhead, it is incorrect for many data.ow graphs.  Edge-based placement. We \npropose an edge-based strategy for sanitizer placement, which attempts to place sanitizers statically \nand spills over into run time when\u00adever necessary. This strategy is appropriate to use when the simple \nnode-based strategy fails.  Correctness. We de.ne the correctness of sanitization of values in a data.ow \ngraph, and prove that our edge\u00adbased strategy for placement is correct.  Experiments. We extensively \nevaluate how our place\u00adment strategies a.ect the number of instrumentation points on both large applications \n(up to 1.8 million lines of code) and synthetically generated data.ow graphs. While the node-based approach \nonly instruments a frac\u00adtion of all nodes, in most cases it fails to provide sani\u00adtization on all paths. \nThe edge-based approach, while it requires more sophisticated analysis, provides full san\u00aditization, \nwhile reducing the number of instrumenta\u00adtion points by 6.19\u00d7 on average. Our edge-based tech\u00adnique works \neven better in the case of a precise under\u00adlying data.ow graph: for sparser synthetically generated \n  graphs, we see a reduction in the number of instrumenta\u00adtion points as high as 27\u00d7, compared to the \nna\u00a8ive version.  1.4 Paper Organization Section 2 presents examples that highlight the need for automated \nsanitizer placement. Section 3 gives an overview to our approach for automatic sanitizer placement. Section \n4 presents data.ow analyses and algorithms to implement our approach. Section 5 describes our experimental \nevaluation. Related work is discussed in Section 6. Finally, Sections 7 and 8 describe future work and \nconclude. 2. Motivating Examples Our examination of large-scale applications has shown that data processing \nis typically performed via a .xed set of sanitizers whose proper selection depends on the kind of source \nand sink and can be expressed as a table, as in Figure 2 [39]. Sanitization policies in this section \nillustrate the complexity of real-world data manipulation scenarios. 2.1 Web Applications The OWASP En\u00adterprise \nSecurity API (ESAPI) is an open-source web- URL CSS input encodeForURL encodeForCSS application security \nlibrary. Usage guidelines of ESAPI reveal that the cor\u00adrect sanitization to apply to data depends on \nhow the data will be used, that is, on the sink context. To sanitize a user-provided URL, function ESAPI.encoder(). \nencodeForURL(input ) should be used. But to sanitize user in\u00adput that will be used to construct a CSS \nattribute, function ESAPI.encoder().encodeForCSS(input ) should be used. 2.2 Web Application Roles In \nlarge-scale web applications, sanitization requirements of\u00adten vary based on who is interacting with \nthe application. This is referred to as role-based sanitization. For example, Wordpress allows authors \nto insert certain HTML tags in their blog posts that commenters may not [46]. Similar ap\u00adproaches are \ntaken by phpBB and Drupal. This complexity is re.ected in sanitization libraries such as AntiXSS [27], \nOWASP HTML Sanitizer Library [30], and HTML Puri\u00ad.er [48], where the developer can select di.erent policies \nfor sanitization of HTML. This source sensitivity arises because not all users are created equal, and \nthat authentication provides a degree of trust (and increase of capabilities) that is not warranted for \nnon-authenticated users. 2.3 Encrypted Cloud Consider a web application us\u00ading a public cloud provider \nfor storage. The web application wants to use the cloud for scal\u00adability and to reduce storage output \ncloud input . encrypt cloud decrypt . hardware costs, but does not fully trust the cloud to protect \nthe con.dentiality of its data. The application therefore will use encryption when serializ\u00ading data \nto the database, and decryption when deserializing. In this scenario, the sources are of types input \nand cloud and sinks are of types output and cloud. The policy would encrypt data before it goes into \nthe cloud and decrypt it on the way out of the cloud. The correct sanitization to apply (if any) depends \non both the source and sink of data. 2.4 Mobile App Privacy and Security Previous studies have shown \nthat applications on Android and other mobile platforms leak user data to untrusted parties. One solution \nis that the developer needs to .lter out private data before it is allowed to go outside [9, 10]. However, \nthe app often has legitimate reasons to send user input and data outside. Consider a gmail app that needs \nto communicate with its parent site, or its host, in this case, mail.google.com. It is necessary to send \ninformation to that hosting URL, including keystrokes, .les on the local system if those are to be attached \nto email, etc. There is perhaps no compelling need to send user data to AdMob.com, a third-party mobile \nadvertisement provider whose library is embedded in the app [10], and so data sent to a third-party should \nbe cleansed, i.e., should have sensitive information removed, a form of declassi.cation. This highlights \nthe need to treat the hosting site di.erently from third-party sites. Source types for this scenario \nare user input, data from host, and data from 3rd-party site. Sink types are screen output, isolated \napp storage, send to host, and send to 3rd\u00adparty site. Data sent to a third party site that does not \noriginate from the third party site should be cleansed. Also, third-party data being shown to the screen \nmight need to be pretty-printed or checked for integrity in some way, which we we refer to in the table \nbelow as ascii-sanitizer. No other sanitization or declassi.cation is required. screen isolated to to \n3rd-party output app storage host site user input . . . cleanse host . . . cleanse 3rd-party site ascii-sanitizer \n. . .  2.5 Properties of the Placement Problem Sink sensitivity: Sanitization is sink sensitive : sanitization \nto apply to data depends on how the data will be used. Source sensitivity: Sanitization is source sensitive \n: the correct sanitizer to use on data depends on where the data comes from. Source sensitivity also \nmakes full automatic sanitization (as advocated by Samuel et al. [38]) di.cult. Context-sensitivity: \nAs elaborated in ScriptGard [39] and by Weinberger et al. [46], sanitization is context-sensitive: to \nchoose the proper sanitizer, the nested context needs to be determined. Consider the following snippet \nof HTML code, which displays a comment (the value untrusted) when the element is clicked. <div class= \ncomment-box onclick= displayComment(untrusted, this) > ... hidden comment ... </div> The untrusted comment \nis in two nested contexts: it is in the onclick attribute of an HTML tag, and it is in a single\u00adquoted \nJavaScript string context. To properly sanitize the untrusted comment, we must ensure that the untrusted \ncom\u00adment does not contain either JavaScript or HTML meta\u00adcharacters. In general, more than one sanitizer \nmay be needed on a path between a given source and a sink. We model this using a single function to represent \nthe composi\u00adtion of sanitizers, as required. Not idempotent or reversible: Note that sanitizers are not \nguaranteed to be either idempotent or reversible, mean\u00ading that we cannot apply them more than once. \nA recent study [15] shows that out of 24 sanitizers considered, 19 are idempotent, and that only 2 are \nreversible. Moreover, order is important, as less than 30% of pairs of sanitizers com\u00admute. Finally, \nover-sanitization is also a signi.cant issue, which often leads to malformed double-encoded data.  3. \nOverview In this section we de.ne the problem and present an overview of two solutions: a completely \nstatic node-based solution, and an edge-based solution that uses static analysis and run-time taint tracking. \nThe static node-based solution incurs no run-time overhead, but doesn t always result in correct sanitization. \nThe edge-based solution is always cor\u00adrect, but may incur run-time overhead due to taint tracking. 3.1 \nValid Sanitizer Placement Problem A data.ow graph G = (N, E ) is a directed graph over a set of nodes \nN with edges E that describes how data .ows through a system. Nodes represent computation and/or storage \nlo\u00adcations, and edges represent the .ow of data in the system. As the program performs computation, values \ntraverse the data.ow graph, following edges in the graph, with nodes rep\u00adresenting both computation performed \non values, and where values are stored during execution. A data.ow graph may have cycles in it. This \nwork is not directly concerned with the precision or soundness of the analysis used to produce the data.ow \ngraph: improvements to the precision and sound\u00adness of analyses for data.ow graph construction will seam\u00adlessly \nimprove the quality and soundness of our results. Our focus is to ensure correct sanitization of data \nin a program, and as such we require an interprocedural data.ow graph. Suppose policy P describes which \nsanitizer should be applied to data traversing a data.ow graph. We aim to provide sanitization for values \ntraversing the data.ow graph, according to the following correctness de.nition. Possible Exclusive S1 \nS2 S3 S4 . 1, 2, 3, 6, 7, 10, 18, 19 2, 3, 6, 7, 8, 10, 11, 12, 14, 15, 17, 19, 20 3, 4, 7, 8, 11, 13, \n16, 21 5, 9, 16, 21 4, 8, 11, 12, 14, 15, 17, 20 1 13 5, 9 Figure 3. Si-possible and Si-exclusive nodes \nfor Figure 1. the absence of critical edges : edges that go from nodes with multiple successors to nodes \nwith multiple predecessors.  3.2 Node-based Formulation We say that a node n is Si-possible if it is \non a path from a source node s to a sink node t that requires sanitizer Si, that is, P(t(s), t (t)) = \nSi. Thus, if n is Si-possible, then at least some of the data passing through node n requires application \nof Si. We say a node n is Si-exclusive if it is Si-possible, and it is not Sj -posible for any j i. In \nother = words, node n is Si-exclusive if it is Si-possible, and for any source s and sink t, if n is \non a path from s to t, then that path requires sanitizer Si (i.e., P(t (s), t (t)) = Si). De.nition 2. \nNode n . N is Si-possible if there is a source node s and sink node t such that n is on a path from s \nto t and P(t (s), t (t)) = Si. De.nition 3. Node n . N is Si-exclusive if it is Si-possible and for all \nsource nodes s and sink nodes t, if n is on a path from s to t then P(t (s), t (t)) = Si. Figure 3 shows \npossible and exclusive nodes for sanitiz\u00aders S1, S2, S3, and . for the data.ow graph of Figure 1. Note \nthat while possible nodes are plentiful, exclusive nodes are rarer. In fact, S2 and . have no exclusive \nnodes at all. Note that node n13 is on a path both from n3 to n21, and from n4 to n21. However, it is \nS3-exclusive because both t(n3) = and t (n4) = D require the same sanitizer when : P(D, De.nition 1. \nGiven a data.ow graph G = (N, E), sani\u00ad going to sink ) = P(D, ) = S3. tization for the graph is valid \nfor policy P if for all source For sparser data.ow graphs, exclusive nodes will be more nodes s, and \nall sink nodes t: if P(t(s), t (t)) = S then every value that .ows from s to t has sanitizer S applied \nexactly once, and no other sanitizer is applied.  if P(t (s), t (t)) = . then every value that .ows \nfrom s to t has no sanitizer applied.  We require that a sanitizer be applied at most once on any given \npath because sanitizers are not necessarily idempotent [15]: applying it multiple times might result \nin incorrect sanitization. We require that sanitizers are not applied needlessly. We model multiple (potentially \nnested) sanitizers as a single (composite) sanitizer. We consider two strategies for sanitizer placement: \na node-based formulation (Section 3.2) that is e.cient, but may fail to produce valid sanitization; and \nan edge-based formulation (Section 3.3) that always provides correct san\u00aditization, but may require run-time \ntaint tracking in order to determine the correct sanitizer to apply. We assume that the data.ow graph \nG = (N, E ) does not contain any node that has both multiple in-coming edges and multiple out-going edges. \nThis assumption is without loss of generality, since if a graph does not satisfy this requirement, it \ncan easily be transformed to one that does by the insertion of synthetic nodes. This assumption is required \nfor the correctness of the edge-based formulation, and is analogous to assumptions in control-.ow graph \nanalysis of plentiful. Exclusive nodes are good candidates at which to apply a sanitizer to all data \npassing through the node. How\u00adever, exclusive nodes are not necessarily unique: there may be multiple \nSi-exclusive nodes on a single path from a source to a sink. If there are multiple Si-exclusive nodes \non a path, we need to choose just one of them at which to apply sani\u00adtizer Si. Since in many common applications \nof data saniti\u00adzation, a sanitized value is larger than the unsanitized value (e.g., escaping special \ncharacters in a string will increase the length of the string), we prefer to perform sanitization as \nlate as possible. We say that node n is Si-latest-exclusive if it is Si-exclusive, and for every path \ngoing through n, it is the last Si-exclusive node on that path. De.nition 4. Node n . N is Si-latest-exclusive \nif n is Si\u00adexclusive and for every source node s and sink node t, and for every path from s to t, if \nn is on that path, then n is the last Si-exclusive node on the path. By this de.nition, we see that in \nFigure 1 nodes n1, n9, and n13 are latest exclusive nodes (for sanitizers S1, S4 and S3 respectively). \nNode n5 is not an S4-latest exclusive node, since there is another S4-exclusive node later on a path \nfrom n5. It is easy to see from the de.nition that for any path from source node s to sink node t with \nP(t(s), t (t)) = Si, there is at most one Si-latest-exclusive node on that path. There may, however, \nbe no Si-latest-exclusive node on a path: if there is a path from source node s to sink node t with P(t \n(s), t (t)) = Si, but there is no Si-latest-exclusive node on that path, then node-based placement will \nnot sanitize values traveling from s to t on that path. Thus, placing sanitizers only at latest-exclusive \nnodes may fail to produce a valid placement (De.nition 1).  As will be seen in Section 5, the static \nnode-based ap\u00adproach does not produce a valid placement for all but simple and sparse data.ow graphs. \n 3.3 Edge-based Formulation We consider instead an edge-based formulation that is able to always .nd \na correct placement of sanitizers in a data.ow graph, although it may be necessary to record and track \nat run time some information about the path that a value has taken in the graph in order to determine \nthe correct sanitizer (if any) to apply to the value. Figure 4 summarizes the key concepts used in our \nedge\u00adbased solution. We provide full de.nitions and intuition for each of these terms below. We say that \nan edge e is source dependent if the sanitiza\u00adtion to apply to values traversing e depends on which source \nproduced the value. De.nition 5. An edge e is source dependent if there exist sources s0 and s1 and sinks \nt such that e is on a path from s0 to t and on a path from s1 to t and P(t (s0), t (t)) = P(t (s1), t \n(t)) (i.e, the sanitizer to use de\u00adpends on the source). Similarly, we say an edge is sink dependent \nif the sani\u00adtization to apply to values traversing it depends on which sink the value will go to. De.nition \n6. An edge e is sink dependent if there exist source s and sinks t0 and t1 such that e is on a path from \ns to t0 and on a path from s to t1 and P(t (s), t (t0)) = P(t (s), t (t1)) (i.e., the sanitizer to use \ndepends on the sink). Intuitively, if an edge is sink dependent, then when a value traverses the edge, \nwe do not yet know which sanitizer to apply. By contrast, if an edge is source dependent, we do not know \nwhich sanitizer to apply to values traversing the edge unless we know from which source the value originated. \nIf an edge is neither source dependent nor sink dependent, then all values traversing the edge are meant \nto have the same sanitizer applied. We say that edge e is source (sink) independent if it is not source \n(sink) dependent. In Figure 1, the edge from node n6 to node n10 is both source dependent and sink dependent. \nIt is sink dependent because it is on paths from n2 to both n18 and n19, but P(t (n2), t (n18)) = S1 \n= S2 = P(t (n2), t (n19)). It is source dependent since it is on paths from both n1 and n2 to n19 and \nP(t (n1), t (n19)) = S1 = S2 = P(t(n2), t (n19)). The edge from node n7 to node n8 is source indepen\u00addent \n(since only one source node can reach it), but is sink dependent. 3.3.1 Trigger Edges To apply a sanitizer \nat a source-dependent edge, we must know from which source a value originated. We can use run\u00adtime tracking \nto taint a value so that we can determine its source. However, run-time taint tracking can be expensive, \nand we do not need to track all values manipulated by the system, just those for which we need to know \nthe source in order to determine which sanitizer to apply. We identify edges where it is necessary to \nstart run-time tracking of values, and edges where, if we were tracking, it su.ces to stop tracking. \nEdge e is an in-trigger edge if it is a source-independent edge but has an edge after it that is source \ndependent. In-trigger edges are the edges where we have su.cient information to know where a value came \nfrom, and need to start run-time tracking because the origin of a value a.ects which sanitizer to apply. \nIf e is an in-trigger edge from node n1 to n2, then there must be at least one other edge going to node \nn2, since n2 is a node where paths from di.erent sources merge. De.nition 7. Edge e is an in-trigger \nedge if it is a source\u00adindependent edge from node n1 to node n2 such that there exists a source-dependent \nedge n2 . n3. Edge e is an out-trigger edge if it is a source-independent ' edge that is preceded by \na source-dependent edge e. If we ' were tracking run-time values as they traverse edge e, then we no \nlonger need to track them when they traverse edge e. If e is an out-trigger edge from node n1 to n2, \nthen there must be at least one other edge leaving n1, since n1 is a node where paths from di.erent sources \nto di.erent sinks split. De.nition 8. Edge e is an out-trigger edge if it is a source\u00adindependent edge \nfrom node n1 to node n2 such that there exists a source-dependent edge n0 . n1. Once we have sanitized \na value, we will not need to perform run-time tracking for the value. (This is an invariant that our \nrun-time discipline will enforce: only values that require sanitization and have not yet been sanitized \nwill be tagged at run time.) Because run-time tracking of values can be expensive, we typically want \nto perform sanitization as early as possible. We can only perform sanitization at sink\u00adindependent edges \n(because at sink-dependent edges, the sanitization to apply depends on the future use of the value). \nSanitization edges are the earliest possible edges at which we can perform sanitization: they are sink-independent \nedges that are the earliest sink-independent edge for some path from a source to a sink. That is, if \ne is a sanitization edge, then for at least one path from a source to a sink, it is the earliest sink-independent \nedge. De.nition 9. Edge e is a sanitization edge if it is a sink\u00adindependent edge and there is a source \nnode s and sink node t such that e is the earliest sink-independent edge on a path from s to t. Figure \n5 shows the source-dependent edge, sink-depen\u00addent edges, in-trigger edges, out-trigger edges, and saniti\u00adzation \nedges for our running example from Figure 1. For example, edge n4 . n8 is an in-trigger edge, since it \nis source independent, but has a successor edge n8 . n11 that is source dependent. Edge n10 . n19 is \na sanitization edge as it is the earliest sink-independent edge on the path from node n2 to n19. Note \nthat edge n13 . n16 is not a san\u00aditization edge, even though it is sink independent. This is because \nany path that goes through n13 . n16 must .rst go through the sink independent edge n11 . n13. In addition, \nFigure 5 shows for each edge e the policy table at e. This is simply the policy table P restricted to \nthe source types I and sink types O such that e is on a path from a source node of type I to a sink node \nof type O. Policy tables at edges are a useful concept for computing an appropriate placement, and will \nbe used in Section 4. De.nition 10. The edge policy at edge e is the restriction of the (global) policy \nP to include only source types I and  Term Brief description Source-dependent edge Sanitizer to apply \nto values traversing the edge depends on which source type the value came from. Sink-dependent edge Sanitizer \nto apply to values traversing the edge depends on which sink type the value will go to. In-trigger edge \nSource-independent edge with a source-dependent successor. Out-trigger edge Source-independent edge with \na source-dependent predecessor. Sanitization edge Earliest sink-independent edge on some path from a \nsource to a sink. Tag edge In-trigger edge that isn t dominated by sanitization edges. Start run-time \ntagging of values. Untag edge Either a sanitization edge, or an out-trigger edge that is not dominated \nby sanitization edges. Stop run-time tagging of values. Carry edge Edge that (a) is reachable from a \ntag edge without an intervening untag edge, and (b) can reach an untag edge, and (c) is neither a tag \nnor an untag edge. Instrument to propagate run-time taint values. Figure 4. Summary of terms for edge-based \nplacement. sink types O such that e is on a path from a source node of type I to a sink node of type \nO. We write Pe for the edge policy at edge e.  3.3.2 Tag, Untag, and Carry edges In-trigger edges and \nout-trigger edges help us identify where we may need to start, and can stop, run-time tracking of values. \nHowever, we can re.ne these notions to reduce the amount of run-time tracking we must perform. Intuitively, \nrun-time tracking is necessary only when a sanitization edge needs to distinguish values coming from \ndi.erent sources. These are exactly the sanitization edges that are source dependent. We need to propagate \ntaint information only along source-dependent edges, and only until we sanitize the value. This also \nmeans that we only need to start taint tracking (which we refer to as tagging data) when data values \nmove from a source-independent edge to a source-dependent edge and the data is not yet sanitized (and \nwill need sanitization in the future). Similarly, we can stop taint tracking (which we refer to as untagging \ndata) when tagged data is sanitized, or when it moves from a source-dependent edge to a source\u00adindependent \nedge. Speci.cally, a tag edge (where we tag values at run time, and start the run-time taint tracking) \nare in-trigger edges such that a value traversing the edge might be unsanitized and require sanitization \nin the future. A value is unsanitized if it has not gone through a sanitization edge, and thus the tag \nedges are in-trigger edges that are not dominated2 by a sanitization edge. Note that an edge dominates \nitself, and thus a tag edge cannot also be a sanitization edge. De.nition 11. Edge e is a tag edge if \ne is an in-trigger edge that is not dominated by sanitization edges. An untag edge is an edge such that \na tagged value can reach it (i.e., it is not dominated by sanitization edges), and we no longer need \nto track the tagged values. It is either a sanitization edge (since after sanitization we no longer need \nto track taint), or an out-trigger edge. De.nition 12. An untag edge is either (a) an out-trigger edge \nthat is not dominated by a sanitization edge; or (b) a sanitization edge. At tag edges we tag values \nand start taint tracking, and continue taint tracking the tagged value until it reaches an untag edge: \nif the untag edge is a sanitization edge, we apply the appropriate sanitizer; otherwise, the untag 2We \nde.ne domination in data.ow graphs as follows. Edge e ' is dominated by edge e if any path from any source \nthat ends ' with edge e must contain e . Figure 5. Policy tables are shown at every node and trigger \nedges are marked. edge is an out-trigger edge and we can stop taint tracking. (Note that if we stop taint-tracking \na value at an untag edge, we may potentially resume taint tracking if the value later encounters another \nin-trigger edge not dominated by sanitization edges.) Edges between tag edges and untag edges will need \nto propagate tag values. We refer to these edges as carry edges. De.nition 13. Edge e is a carry edge \nif e is on a path from a tag edge to an untag edge such that the path does not contain an untag edge. \nThat is, if edges e0, . . . , en are a path where e0 is a tag edge, en is an untag edge, and e1, . . \n. , en-1 are not tag edges, then edges e1, . . . , en-1 are carry edges. In Figure 5, edge n7 . n6 is \na tag edge: it is an in\u00adtrigger edge (since it is source independent and successor edge n6 . n10 is source \ndependent) that is not dominated by sanitizer edges. By contrast, edge n13 . n16 is an in\u00adtrigger edge, \nbut it is not a tag edge, since it is dominated by sanitizer edge n11 . n13. This means that any values \ntraversing n13 . n16 will already be sanitized, and so there is no need to track their source type in \norder to determine which sanitizer to apply. In Figure 5, all untag edges are sanitization edges.  Edge \nn6 . n10 is a carry edge, as it is on a path from tag edge n1 . n6 to untag edge n10 . n18 without an \nintervening untag edge. Edge n6 . n10 will propagate the tags that tag edges n1 . n6, n2 . n6, and n7 \n. n6 create, and enable sanitization edges n10 . n18 and n10 . n18 to apply the appropriate sanitization. \n 3.3.3 Run-Time Taint Tracking for Sanitization We have de.ned several di.erent kinds of edges that \nare relevant to the run-time discipline for applying correct sani\u00adtization to values: sanitization edges, \ntag edges, untag edges, and carry edges. We summarize what the instrumentation for these edges is required \nto do at run time: tag edge: when a value traverses a tag edge, if the value is not tagged then tag \nthe value with one of the source types reaching it. A reaching source node, and its type, can be statically \ndetermined by examining the edge policy. Multiple source types may reach the tag edge, and any can be \nused, since tag edges are source independent.  untag edge: when a tagged value traverses an untag edge, \nuntag it.  sanitization edge: If the sanitization edge is not pre\u00adceded by a carry edge, then no tagged \nvalues can reach this edge, and all values traversing this edge should have the same sanitizer applied. \nOtherwise, apply sanitization only if the value is tagged by looking up the tag (which is a source type) \nin the edge s policy table to .nd the ap\u00adpropriate sanitizer to apply (which might be ., in which case \nno sanitization is applied).  carry edge: when a value traverses a carry edge, any taint on the value \nmust be propagated.  For example, in Figure 5, consider a value .owing from source node n3 to sink node \nn20. At tag edge n7 . n8, the value will be tagged with its originating source type t(n3) = . The value \nwith its tag will be propagated over carry edge n8 . n11. Upon reaching sanitization edge n11 . n12, \nits tag will be examined, and the appropriate sanitizer (S3) applied. Note that the tag was needed for \nn11 . n12 to determine which sanitizer to apply, since a value from source node n4 could also traverse \nthat edge, requiring no sanitization (.). Note that if an edge e is not a tag edge, untag edge, sanitization \nedge, or carry edge, then e requires no instru\u00admentation, as no tagged value will traverse e, and e does \nnot need to perform any tagging, untagging, or sanitization. For example, in Figure 5, edges between \nnodes n12 and n20 require no instrumentation.  3.3.4 Correctness of Edge-based Placement The edge-based \nplacement produces a valid placement (Def\u00adinition 1). We present here the key lemma that proves this. \nLemma 1. For every path from a source node s to a sink node t, the following conditions hold for values \n.owing along that path. 1. There is at least one sanitization edge on the path. 2. If P(t(s), t (t)) \n= . then no sanitization will be applied. 3. If P(t (s), t (t)) = . then sanitizer P(t (s), t (t)) will \nbe applied at the .rst sanitization edge. 4. No sanitization will be applied at the second or subsequent \nsanitization edges.  Proof: Condition (1) holds from the de.nition of sanitization edges, and because \nan edge whose target is a sink node must be sink independent. Let e0, . . . , en be a path from a source \nnode to a sink node, and let ei be the .rst sanitization edge. Conditions (2) and (3) hold by the following \nargument. If ei is source independent then all values traversing ei will have the same sanitization applied \n(either sanitizer S if P(t (s), t (t)) = S, or no sanitization if P(t (s), t (t)) = .). Suppose that \nei is source dependent. Then there must be some other source s ' such that there is a path from s ' to \nei and some output t ' ' '' reachable from ei such that P(t (s), t (t )) = P(t (s ), t (t )). Since e0 \nis source independent and ei is source dependent and the .rst sanitizer edge, there must be some edge \nej on the path e0, . . . ei-1 such that ej is a tag edge, and all edges ej+1, . . . , ei-1 are carry \nedges. Thus, at ej , the value will be tagged with source type t(s) (or some other source type I such \nthat P(t (s), t (t)) = P(I , t (t))), the carry edges will propagate this tag, and so at sanitization \nedge ei, the correct sanitization will be applied. Suppose that condition (4) does not hold. Then there \nis some edge ek in path ei+1, . . . , en such that ek is a saniti\u00adzation edge, and ek applies sanitization \nto values traversing path eo, . . . , en. Since ek is a sanitization edge, it is the ear\u00adliest sink-independent \nedge on some path from source to a sink, and so there must be some other source node s ' that can reach \nek. Since ek is the .rst sink-independent edge on a path from s ' , there must be another edge leaving \nsource (ek) (where source (e) denotes the source node of edge e) such that on that edge, some sink node \nt ' is reachable that is ' '' not reachable from ek, and P(t (s ), t (t)) = P(t (s ), t (t )). More over, \nsince source (ek) has multiple edges coming from it, by assumption that the data.ow graph has no nodes \nwith both multiple successors and multiple predecessors, node source (ek) has a single predecessor, edge \nek-1, and so ek-1 is also on the path from s ' to ek. Therefore, edge ek-1 must be source dependent: \nsince ei can reach t ' , and ei is sink inde\u00ad ' '' pendent, it means that either P(t(s), t (t )) = P(t(s \n), t (t )) or P(t (s), t (t)) = P(t(s ' ), t (t)). Now consider whether ek-1 is a carry edge. Suppose \nek-1 is a carry edge. We will show that none of the edges on ei, ..., ek-1 can be a tag edge, and thus, \na value coming from ei cannot be tagged, and so at sanitizer ek, no sanitization will be applied. This \ncontradicts the assumption that condition (4) doesn t hold. Note that ei is not a tag edge, as it is \na sanitization edge. Then there must be some tag edge em between ei and ek-1. Since it is not dominated \nby sanitizer edges, there must be a path from a source node s0 (such that t(s0) = t (s)) to source (em) \nwithout a sanitization edge. Since em is an in\u00adtrigger edge, it is source independent. That means that \nfor all sink types O reachable from em, and all source types I that can reach em, we have Pem (t (s), \nO) = Pem (I , O). But any sink type O reachable from em is also reachable from ei, and ei is sink independent. \nThat means that for any sink types O1 and O2 we have Pem (t(s), O1) = Pem (t(s), O2). Together these \nimply that em is sink independent, since for any source I that can reach em and sinks O1 and O2 that \ncan be reached from em we have: Pem (I , O1) = Pem (t (s), O1) em is source independent = Pei (t (s), \nO1) O1 is reachable from ei = Pei (t (s), O2) ei is sink independent, and O2 is reachable from ei = Pem \n(t (s), O2)  Semi-lattice L set of source types Top T \u00d8 = Pem (I , O2) em is source independent \u00d8 . \n. Initial value init(n) But then em is the .rst sink-independent edge on the add t(n) to set if n is \na path from I0 to em, and so it is a sanitization edge. This is Transfer function T F (n) a contradiction, \nas em is a tag edge. . source identity otherwise Suppose ek-1 is not a carry edge. Edge ek is an un\u00adtag \nedge (since it is a sanitization edge). Note that ek-1 is not a tag edge, since it is source dependent. \nBut since ek-1 is source dependent, and ek is the .rst sanitization edge on the path from s ' to ek, \nthen there must be a tag edge on the path from s ' to ek without any intervening untag edges between \nit and ek. Therefore ek-1 is a carry edge, which is a contradiction. Meet operator n(x, y) union x . \ny Direction forward (a) Available source types. . . Semi-lattice L set of sink types Top T \u00d8 \u00d8 Initial \nvalue init(n) Transfer function T F (n) The correctness of the edge-based placement follows triv\u00ad add \nt(n) to set if n is a sink . identity otherwise ially from Lemma 1 and the fact that no edge other than \na sanitizer edge applies sanitization.  3.3.5 Optimizations There are several opportunities for optimization \nin the edge\u00adbased placement approach. Remove un-needed sanitization edges: For simplicity of the presentation \nand the proof, we have de.ned the behavior of tag edges and sanitization edges treating no sanitization \n. as if it were a sanitizer. If a sanitizer is not preceded by a carry edge, and the policy dictates \nthat no sanitization should be applied, then the sanitization edge does not perform any computation, \nand should not be instrumented. Similarly, if a tag edge is tagging a value with a source type that will \nnever require sanitization, then the tag edge can be removed, and the value never tagged. This optimization \nis valid because a sanitization edge that may receive tagged values will never sanitize an untagged value. \nSanitization edges preceded by carry edges: For sim\u00adplicity we required that any sanitization edge preceded \nby a carry edge needed to check the run-time tag before ap\u00adplying sanitization. There are some situations \n(statically de\u00adterminable) where a sanitization edge will be preceded by a carry edge, yet all values \ngoing through it should have the same sanitization applied. In Figure 5 edge n11 . n13 is an example \nof this: the preceding edge n8 . n11 is a carry edge, but n11 . n13 is source independent and the .rst \nsan\u00aditization edge on any path that goes through it. Thus, all values traversing n11 . n13 will have \nsanitizer S3 applied, so there is no need to examine the tag. Attaching tags to run-time values: We envision \nthe run\u00adtime taint tracking being implemented simply by attaching tags to run-time values. This is a \nstrategy that works well for dynamic languages such as Java, PHP, or JavaScript. The tags can be quite \ncompact: we have described it above as tagging a value with the source type that it originated from (or \na source type with equivalent sanitization requirements), but it would su.ce to use bit strings that \nuniquely identify a source type. The number of sources depends on the pol\u00adicy, but will typically be \nsmall, meaning that a tag of 3 4 bits would su.ce. There are opportunities for e.cient im\u00adplementation \nof taint-tracking when the tags are this small, such as placing the tag within the value header at run \ntime. With this tagging approach, instrumentation for carry edges becomes trivial, since tags will be \ncopied if they exist. Thus, the only instrumentation required will be to tag values as they traverse \ntag edges, untag them as they traverse untag edges, and apply sanitization at sanitization edges. Meet \noperator n(x, y) union x . y Direction backward (b) Anticipated sink types. Figure 6. Available source \ntypes and anticipated sink types. E.cient lookup for sanitization: Since the number of possible tags \nthat can reach a given sanitization edge is small and known statically, we can pre-compute a lookup table \nfor each sanitization edge that maps the tag number to the required sanitizer, thus minimizing run-time \ncalculations. Early vs. late sanitizer placement: The static node\u00adbased placement strategy performs sanitization \nas late as possible, at latest-exclusive nodes. The edge-based place\u00adment performs sanitization as early \nas possible, at the earli\u00adest sink-independent edges. The reason for this di.erence is that for the purely \nstatic node-based placement, it is slightly better to perform sanitization late, as many common san\u00aditizers \nincrease the size of data, and thus place additional pressure on memory. By contrast, for edge-based \nplacement, early sanitization will reduce the amount of run-time taint tracking required, and we believe \nthe cost of any run-time taint tracking outweighs the cost of increased size of data from sanitization. \n4. Placement Algorithms In this section, we propose concrete algorithms for comput\u00ading the sets and relations \ndescribed in Section 3. At the core of these computations, we have data.ow analysis, as described in \nAho et al. [1]. As we will see, we can often stage our computation and break it down into a series of \ntwo or three analyses, one after another. As Knoop et al. [20] observe, this is often advantageous compared \nto a more com\u00adplex equation-based approach, because each analysis stage completes quickly. 4.1 Node-based \nPlacement To implement the node-based placement strategy we com\u00adpute the set of nodes that are Si-possible \nand Si-exclusive for each sanitizer Si for i ranging from 1 to k. To combine the computation of these \nproperties for di.erent sanitizers Si, we use bit vectors as our representation. Generally, a 1 at position \ni for a value at node n . N means that the property (either possibility or exclusiveness) holds for Si. \nFirst, we compute available source types and anticipated sink types at every node using a data.ow analysis, \nas shown in Figure 6. We specify data.ow analyses by giving the semi\u00ad  Semi-lattice L bit vector of \nlength k Top T \u00af0 Initial value init(n) \u00af00 Transfer function T F (n) bit i = 1 identity if n is Si-exclusive \notherwise Meet operator Direction n(x, y) bitwise or x|y backward Figure 7. Computes exclusive anticipated(i). \nlattice of data.ow facts, the initial values of start nodes (source nodes for forward analyses, sink \nnodes for backwards analyses), the transfer function for nodes, and the direction of the data.ow analysis. \nThis is a complete speci.cation of the data.ow analyses. We then combine the available sources and anticipated \nsinks information as described in Algorithm 1, to determine for each node which sanitizers are possible \nat every node. This is done by projecting the policy table to only the available source types and anticipated \nsink types. We write P roject(P, S, T ) for the policy table that contains only the rows of policy table \nP for sink types S, and only the columns of P for sink types T . If at node n, sanitizer Si appears in \npolicy table P roj ect(P, available(n), anticipated(n)), then n is Si-possible. Algorithm 1. Possible \nnodes. for all n . N do for all Si . P roject(P, available(n), anticipated(n)) do possible(Si) = possible(Si) \n. {n} The nodes that are Si-exclusive are a subset of nodes that are Si-possible. Computing Si-exclusive \nnodes is a simple matter of removing from the set of Si-possible nodes any node that is Sj -possible, \nfor any i = j, as shown in Algorithm 2. Algorithm 2. Exclusive nodes. for all i . [1..k] do exclusive(Si) \n= possible(Si) for all j . [1..k] do if i = j then for all n . possible(Si) do if n . possible(Sj ) then \nexclusive(Si) = exclusive(Si) \\ {n} The last step is to compute latest-exclusive nodes: Si\u00adexclusive \nnodes that for some path from a source to a sink are the last Si-exclusive node on that path. Figure \n7 describes a backward data.ow analysis that identi.es, for each Si, which nodes can reach an Si-exclusive \nnode. We write exclusive anticipated(Si) for the set of nodes that can reach a Si-exclusive node. Latest-exclusive \nnodes are simply the set of exclusive nodes, minus the set of anticipated\u00adexclusive nodes (Algorithm \n3). Algorithm 3. Latest-exclusive nodes for all i . [1..k] do latest exclusive(Si) = exclusive(Si) for \nall n . exclusive anticipated(Si) do latest exclusive(Si) = latest exclusive(Si) \\ {n} We place sanitizer \nSi at all nodes that are Si-latest\u00adexclusive. Latest-exclusive nodes may be rare, especially in dense \ngraphs. For the graph in Figure 1, this algorithm will place sanitizers only at nodes n1, n13, and n9. \nHowever, this Semi-lattice L Bool Top T true Initial value init(n) true . . true if .Si. n . Transfer \nfunction T F (n) . identity latest exclusive(Si) otherwise Meet operator n(x, y) conjunction x . y Direction \nforward Figure 8. Detect whether static placement is valid. is clearly insu.cient, because not all values \ntraversing the graph will be sanitized, such as values .owing from source node n3 to sink node n20. Figure \n8 describes a data.ow analysis to detect whether all paths from sources to sinks go through a latest-exclusive \nnode. Data.ow facts are booleans, indicating whether all paths to the node have gone through a latest-exclusive \nnode. (By construction, a path can have at most one latest\u00adexclusive node, so there is no need to count \nthe number of latest-exclusive nodes on a path.) The static placement is valid if and only if the data.ow \nanalysis produces a value of true at all sink nodes. If the static placement is valid, then it can be \nused to correctly sanitize all values, with no run-time overhead. If the placement is not valid, then \nthe edge-based placement can be used to ensure correct sanitization, albeit with some run-time overhead. \n 4.2 Edge-based Placement To implement the edge-based solution, we must identify several di.erent sets \nof edges, summarized in Figure 4. We present algorithms to compute each of these sets of edges. Source-dependent \nedges and sink-dependent edges: First, we compute the available source types and anticipated sink types \nfor every edge, similar to the data.ow analyses in Figure 6. However, whereas Figure 6 computes data.ow \nfacts for nodes, we need to compute data.ow facts for edges. Next, for each edge e we compute edge policy \nPe: policy table P restricted to the available source types and antici\u00adpated sink types of edge e. We \nuse edge policies to identify source-dependent edges and sink-dependent edges. Edge e is source dependent \nif and only if Pe has more than one unique sanitizer in any column. Edge e is sink dependent if and only \nif Pe has more than one unique sanitizer in any row. In-trigger and out-trigger edges: Recall that in-trigger \nedges are source-independent edges with a source-dependent successor edge, and out-trigger edges are \nsource-independent edges with a source-dependent predecessor edge. We can compute these edges e.ciently \nsimply by inspection of the data.ow graph. Let in trigger denote the set of in-trigger edges, and out \ntrigger denote the set of out-trigger edges. Sanitization edges: Sanitization edges are sink-indepen\u00addent \nedges that are the earliest sink-independent edge on some path from a source to a sink. They are the \nedges at which sanitization will be performed: at sink-independent edges the sanitization to apply to \na value does not depend on which sink the value will go to. Figure 9 presents a data.ow algorithm for \ncomputing san\u00aditization edges. Note that the analysis computes data.ow facts for edges. Data.ow facts \nare pairs of boolean values. The .rst value is true for an edge if and only if all paths to the edge \ngo through a sink-independent edge. The second boolean value is true for sanitization edges: edges that \nare the .rst sink-independent edge on some path, which is ex\u00adactly the edges that are sink independent \nand have at least  Semi-lattice L Bool \u00d7 Bool Semi-lattice L Bool Top T (true, true) Top T false Initial \nvalue init(e) (false, false) Initial value init(e) Transfer function T F (e) false true if e . tag . \n. (f1(e), f2(e)) true if e is sink . . Transfer function T F (e) false if e . untag . identity otherwise \nf1(e)(a, b) = independent f2(e)(a, b) = ... . Meet operator n(x, y) x . y Direction forward a otherwise \ntrue if f1(e) =true and a = false false otherwise (a) Computes tag available: reachable from tag edge \nwithout intervening untag edge. Meet operator n(x, y) pointwise . Direction forward Semi-lattice L Bool \nTop T false 0 false true if e . untag Transfer function T F (e) identity otherwise Meet operator n(x, \ny) x . y Semi-lattice L Bool Direction backward Top T true Initial value init(e) false Figure 9. Computes \nsanitization(e). Initial value init(e) Transfer function T F (e) .. . (b) Computes untag anticipated: \ncan reach untag edge. true if e is a sanitization edge identity otherwise Meet operator n(x, y) x . y \nDirection forward Figure 10. Computes dom sani(e): whether edge e is dom\u00adinated by sanitization edges. \none path to it that does not go through a sink-independent edge. Note that the transfer function for \nedge e is given as a pair of functions, f1(e) and f2(e), each of which is a function from the input data.ow \nfact (a pair of boolean values, (a, b)) to a boolean value. Tag and untag edges: Tag and untag edges \nare where Figure 11. Data.ow analyses for carry edge computation. Benchmark DLLs DLL (KB) LOC Alias \nManagement Chat Application Bicycle Club App Software Sporting Field Management Commitment Management \nNew Hire Expense Report Approval Customer Support Portal Relationship Management 3 3 3 15 3 7 11 4 14 \n5 65 543 62 118 290 369 565 421 2,447 3,345 10,812 6,783 14,529 11,941 15,803 25,602 5,595 78,914 66,385 \n1,810,585 Figure 12. Benchmark applications, sorted by code size. we, respectively, start and stop run-time \ntracking of val\u00adues. The de.nition of both tag and untag edges relies on identifying edges that are dominated \nby a sanitization edge, for which we use the data.ow analysis in Figure 10. We write dom sani(e) if edge \ne is dominated by sanitization edges. If e is a sanitization edge, then dom sani(e) is true. The following \nalgorithm computes the set of tag and un\u00adtag edges. Tag edges are in-trigger edges that are not domi\u00adnated \nby sanitization edges. Untag edges are either sanitiza\u00adtion edges, or out-trigger edges that are not \ndominated by sanitization edges. Algorithm 4. Tag and untag edges. for all e . E do if e . in trigger \n. \u00acdom sani(e) then tag = tag . {e}if (e . out trigger.\u00acdom sani(e)).e . sanitization then untag = untag \n. {e} Carry edges: Finally, carry edges are those on a path from a tag to an untag edge that does not \npass through an untag edge. The set of carry edges can be computed by .rst performing a forward data.ow \nanalysis to com\u00adpute tag available the set of edges that are reachable from a tag edge without an intervening \nuntag edge and then performing a backward data.ow analysis to compute untag anticipated, the set of edges \nthat can reach an untag edge. These data.ow analyses are shown in Figure 11. Carry edges are the non-tag, \nnon-untag edges that are in both the tag available and untag anticipated sets, as de.ned in the following \nalgorithm. Algorithm 5. Carry edges. for all e . E do if e . tag available . e . untag anticipated then \nif e . tag . e . untag then carry = carry . {e} 5. Experimental Evaluation Our evaluation focuses on \ncomparing the number of instru\u00admentation points using our sanitizer placement algorithms compared to \na baseline implementation that performs dy\u00adnamic taint tracking between all sources and sinks. Our tar\u00adget \napplications are long-running server applications. Run\u00adtime overhead of taint tracking is typically workload \nspeci.c (e.g., [10]), so we choose not to evaluate run-time overhead directly. Reducing the number of \ninstrumentation points is a valuable goal, since long-running applications with diverse workloads have \nhigh code coverage over time, hitting increas\u00adingly many instrumentation points. Section 5.1 presents \nthe results of applying our techniques to large C# web appli\u00adcations written in ASP.NET. Section 5.2 \nevaluates our ap\u00adproach against large, synthetically constructed graphs. 5.1 Large Applications Figure \n12 contains a summary of information about our macro-benchmarks. These are relatively large business \nweb applications written on top of the ASP.NET framework, con\u00adsisting of several separate DLLs, as shown \nin column 2. Not all code contained within the application source tree is ac\u00adtually deployed to the Web \nserver. Most of the time, the number and size of deployed DLLs primarily consisting of .NET bytecode \nis a good measure of the application size, as shown in column 3. Note that in several cases, libraries \nsupplied in the form of DLLs without the source code con\u00adstitute the biggest part of an application. \nFinally, to provide another measure of the application size, column 4 shows the traditional line-of-code \nmetric for all the code within the application. Note that correct manual sanitization for these applications \nis a challenge, as explored in the Merlin project [23]; we therefore believe that fully automatic place\u00adment \nis a better alternative.  Application Graph nodes Taint sources sinks forward Tainted nodes backward \nboth ratio Exclusive nodes all l.e. ratio Sanitization coverage Terralever Alias Management Contoso \nBicycle Club Windows Experience Catalog Commitment Management New Hire Expense Report Approval Customer \nSupport Portal Relationship Management 156 59 161 204 356 502 805 3,881 3,639 64 11 50 47 135 142 214 \n967 1,054 69 12 54 83 132 183 322 1,219 982 140 22 145 186 299 401 722 3,488 3,321 140 21 133 160 296 \n409 637 3,263 3,104 76 11 87 101 183 229 408 2,266 2,241 48% 18% 54% 49% 51% 45% 50% 58% 61% 122 19 94 \n120 221 275 389 1,721 1,565 50 9 40 49 86 110 170 770 637 32% 15% 24% 24% 24% 21% 21% 19% 17% 82% 86% \n50% 93% 79% 70% 82% Figure 13. Node-based analysis and its e.ectiveness.  Application Total edges Taint \nsourcessinks Tainted forwardbackwardbothratio Dependent sourcesink Triggers inoutsanitizer Edge count \ntaguntagcarry Instr. totalratio Terralever Alias Management Contoso Bicycle Club Windows Experience \nCommitment Management New Hire Expense Report Approval Customer Support Portal Relationship Management \n142 962 182 430 461 873 1,389 8,985 17,732 96 89 11 10 80 70 68 162 177 188 258 347 367 503 1,505 2,167 \n2,376 2,594 140 137 136 13 14 13 170 174 164 386 364 358 420 409 386 680 771 652 1,286 1,296 1,208 8,534 \n8,469 8,069 17,227 17,358 16,888 95% 1% 90% 83% 83% 74% 86% 89% 95% 3 1 0 0 32 27 133 125 110 114 181 \n192 189 197 4,315 4,364 11,227 11,585 8 0 97 0 0 11 29 9 84 14 117 193 45 41 215 108 75 342 131 143 577 \n901 1,331 2,875 2,057 2,020 4,407 1 0 2 2 6 27 23 232 428 5 2 6 31 30 67 99 541 533 0 0 7 123 108 126 \n144 3,917 10,725 6 2 15 156 144 220 266 4,690 11,686 22.66 6.5 10.93 2.29 2.68 2.96 4.54 1.72 1.44 Figure \n14. Edge-based analysis and its e.ectiveness. Reduction in number of instrumented edges is shown in last \ncolumn.  Policy: There are applications ranging from tens of thou\u00adsands of lines of code to over a million \nin the case of the Relationship Management application. We classi.ed sources and sinks into the three \ncategories: nor\u00admal, .le, resource, based on their functionality (i.e., TextWriter.Write is a .le-related \nsink). We used the policy shown in the table in this paragraph for these applications. Finally, we completely \ndisregarded existing sanitizers, fully automating sanitizer placement. normal S1 S2 . resource S3 S4 \n. 0 . . .  5.1.1 Node-based Placement Figure 13 contains the results of applying the node-based placement \nstrategy. Applications are represented as graphs, some nodes of which are marked as sources or sinks. \nData.ow graphs are computed by the Cat.Net tool [26], and are fairly sparse. Nodes of the graph are parameters \nand return results of individual methods in the application or its libraries. Edges represent data .ow \nas inferred by Cat.Net. A di.erent static analysis tool could also be used to construct these graphs; \nthe precision and soundness of Cat.Net results is orthogonal to our approach. The num\u00adber of nodes (column \n2) as well as sources and sinks (3 4) ranges from dozens to lower thousands. Columns 5 8 summarize information \nabout tainted nodes in the graph. Column 5 is forward-tainted nodes (i.e., nodes that can be reached \nfrom a source node). Column 6 is backward-tainted nodes (i.e., nodes that can reach a target node). Column \n7 is both forward-and backward-tainted nodes (i.e., nodes that are on a path from a source node to a \nsink node) and column 8 is the fraction of these nodes compared to all nodes in the graph. We can see \nthat for a well-connected graph, the percentage of such nodes can be quite high, going higher than 60%. \nThe implication is that a very high fraction of nodes needs to be instrumented to propagate the taint \nforward at run time. Columns 9 11 capture our exclusive node computation. Column 9 is the number of exclusive \nnodes and column 10 is the number of latest exclusive nodes. Column 11 is the fraction of latest exclusive \nnodes within the nodes of the graph. Finally, column 12 shows the coverage, which is the fraction of \nall source-sink paths that are properly sanitized with latest exclusive nodes.3 Two key take-aways from \nthis table are as follows: the na\u00a8ive approach of taint-tracking on all nodes on a path from a source \nto a sink is very expensive, with as many as 60+% of nodes needing to be instrumented; and  while instrumenting \njust the latest exclusive nodes re\u00adquires less instrumentation, the obtained coverage is sig\u00ad  3Coverage \nnumbers are not available for the largest two ap\u00adplication; the large number of paths in the data.ow \ngraph cannot be enumerated in reasonable time.  ni.cantly less than 100%, so the static node-based ap\u00adproach \nis generally unacceptable for sanitizer placement.  5.1.2 Edge-based Placement Figure 14 shows the results \nof applying the edge-based placement strategy. Column 2 shows the number of edges in the graph. Columns \n3 4 show the number of sources and sinks, respectively; note that we use a slightly di.erent policy for \nwhich nodes as marked as sources and sinks compared to Figure 13. Columns 5 7 show the number of forward \nand backward-tainted edges and edges tainted in both directions. Column 8 shows the percentage of edges \ntainted in both directions as a fraction of the number of edges in the graph. Columns 9 10 show the number \nof source-dependent edges and sink-dependent edges. Columns 11 13 show the number of in-trigger edges, \nout-trigger edges, and sanitizer edges. Columns 14 16 show the counts for the other kinds of edges computed \nby the edge-based formulation. Finally, columns 17 and 18 show the number of edges needing instru\u00admentation \nand the savings compared to the na\u00a8ive approach of instrumenting edges that are both forward-and backward\u00adtainted. \nWe highlight particularly noticeable savings in bold. (As described in Section 3.3.5, we do not count \nunneeded sanitization edges when counting edges that require instru\u00admentation.) Three key take-aways \nfrom this table are: We see that for most applications, the percentage of edges that are forward-and \nbackward-tainted is quite high, indicating that the underlying data.ow analysis of Cat.Net is quite imprecise, \nleading to a great deal of connectivity within the data.ow graph.  Savings in terms of the number of \ninstrumentation points in the last column of Figure 14 are 6.19\u00d7 on average.  In general, our analysis \nis not as e.ective at reducing the number of instrumentation points for densely-connected graphs (the \nlast several rows) as it is for the sparser graphs (the .rst several rows).   5.2 Synthetic Graphs \nFinally, we evaluate our (edge-based) algorithm on some synthetically constructed graphs. To build such \ngraphs, we start with 100 sources, 100 sinks, and 1,000 regular nodes. We randomize the type of the sources \nwith equal probability between 0, D, 0,, and D, and the type of sinks between 0, , , and , using the \npolicy in Figure 2 for proper san\u00aditizer placement. We connect sources to sinks by performing a random \nwalk of length 10 starting at a random source and ending at a random sink through the graph, creating \nedges as we pass from node to node. We use a density parame\u00adter d to vary how many such walks we perform, \na.ecting the number of edges. Figure 15 shows the improvements with edge-based in\u00adstrumentation compared \nto na\u00a8ive, taint-based instrumenta\u00adtion as the number of edges grows. We can see that for sparse graphs, \nthe improvements are most noticeable, peaking at over 27\u00d7, gradually becoming less pronounced (only 48% \nimprovement for 550 edges). The improvements obtained with our strategy depends on the quality of the \nunderlying data.ow graph. Results in Fig\u00adure 15 suggest that our strategy performs better with sparser \ndata.ow graphs, and performs worse when the data.ow graph is more highly connected. Since more precise \nanal\u00adyses produce sparser data.ow graphs (since there are fewer conservative over-approximations of data.ow), \ninvestment in precise static data.ow graph construction may improve the results of sanitization placement. \nThis conclusion res\u00adonates with the experience of a number of projects that use static analysis to reduce \nthe number of run-time instrumen\u00adtation points: if static analysis is imprecise, the e.ect of this reduction \nis not very signi.cant. 6. Related Work The most closely-related work is that of King et al. [19], which \nconsiders the problem of resolving type errors in security-typed programs [36] by automatically placing \nme\u00addiation statements in a program (which explicitly declassify information or authorize the possibly \ndangerous information .ow). They construct a graph representation of information .ow in a program, such \nthat source nodes are high-security inputs, and sink nodes are low-security outputs. A min-cut in this \ngraph corresponds to a minimal set of program points such that insertion of mediation statements at these \nprogram points would allow the program to type check. Their problem is similar to ours, in that every \npath from a source to a sink must have a mediation statement. However, their problem is simpler than \nours, because all paths require the same kind of mediation statement. By contrast, our policies allow \ndi.erent source-sink pairs to require di.erent sanitization. As such, we are unable to use a min-cut \napproach to identify sanitization program points. Also, in our setting, it is important to prevent over\u00adsanitization: \nvalues should have the appropriate sanitization applied exactly once. By contrast, it is permissible \n(though perhaps undesirable) for a path from a source to a sink to have multiple mediation statements. \nSamuel et al. [38] share our goal of automatic sanitization, but the details are very di.erent. Our approach \nis designed to work on large legacy applications written in languages such as Java or C#, whereas they \nfocus on much smaller programs in Google Closure. Their technique is based on constraint satisfaction \nusing a custom solver, and has poten\u00adtial for scalability issues, whereas our approach uses data.ow analysis \nwith well-understood scalability properties. Graph-based analysis for information security: Sev\u00aderal \nresearchers have used program dependence graphs for analyzing information security of programs [12, 14, \n40]. Pro\u00adgram dependence graphs include both data dependencies and control dependencies, unlike the data.ow \ngraphs we use in this work, which typically contain just data depen\u00addencies. Hammer et al. [13] consider \nenforcement of declas\u00adsi.cation [37] using program dependence graphs. However, Hammer et al. require \ncertain nodes in a program depen\u00addence to be annotated as declassi.ers, whereas we seek to infer where \nto insert declassi.ers and sanitizers.  Software security analysis of web applications: Pro\u00adgram analysis \nhas a long history of being used for .nding security bugs in web applications. Static analysis has been \nadvocated for PHP, Java, and other languages [17, 18, 22, 47]. Multiple run-time analysis systems for \ninformation .ow tracking have also been proposed [11, 25, 29, 31]. Automating placement: Most recently, \nwe have seen in\u00adcreased interest in automating security-critical decisions for the developer [38, 46]. \nThe use of a security type system for enforcing correctness is another case of cooperating with the developer \nto achieve better code quality and correctness guarantees [33]. Sanitizer correctness: Balzarotti et \nal. [3] show that cus\u00adtom sanitizer routines are often incorrectly implemented. Our concerns in this \npaper are complimentary to sanitizer correctness. The Cross-Site Scripting Cheat Sheet shows over two \nhundred examples of strings that exercise com\u00admon corner cases of web sanitizers [34]. The Bek project \nproposes a systematic domain-speci.c languages for writing and checking sanitizers [15, 45]. Speci.cation \ninference: Livshits et al. [23] propose an ap\u00adproach to inferring information .ow speci.cations (sources, \nsanitizers, and sinks) using factor graphs. Kremenek et al. [21] propose belief inference as a way to \ninfer speci.cations for static analysis checkers. Vaughan and Chong [44] propose policy inference to \ndiscover correct declassi.cation policies. Graph algorithms: LCM and PRE: A range of graph\u00adtheoretical \nalgorithms from compiler literature is relevant for our work. In particular, Knoop et al. [20] describe \nlazy code motion. R\u00a8 uthing et al. describe a variant of it called sparse code motion [35]. Partial redundancy \nelimination of PRE is described by Hosking et al. [16] and Briggs and Cooper [5]. 7. Future Work The \ndesign of our placement strategies is motivated by real\u00adworld concerns (for example, in the edge-based \nstrategy, we perform sanitization as early as possible to reduce the amount of run-time taint-tracking). \nHowever, we do not of\u00adfer a formal notion of optimality of our algorithms. This is in part because it \nis unclear what we should aim to optimize. Possible candidates include reducing the number of instru\u00admentation \npoints or run-time overhead for the worst-case or average-case workloads. Exploring these di.erent notions \nof optimality in order to decide which is best requires building a more complete prototype. Our matrix-based \npolicy speci.cation allows di.erent sanitizers to be speci.ed for all source-sink pairs. However, this \nmay not be su.ciently expressive in all cases. For exam\u00adple, how do we properly sanitize the result of \nconcatenating string data from two di.erent kinds of sources? We see at least two possible solutions \nto this lack of expressiveness. One is to treat as sinks computations that combine two or more source \ntypes, e.ectively forcing proper sanitization to take place on values before computation occurs. An alter\u00adnative \nthat works for some compositional operations (e.g., string concatenation) is to perform .ner-grained \nbyte-level tagging, so that the appropriate sanitizer can be applied to the appropriate bytes of the \nvalue. Another shortcoming of our matrix-based policy speci\u00ad.cation is that we collapse a sequence of \nsanitizers into a single one. This might prove to be a disadvantage in some settings, where keeping them \nseparate would create interest\u00ading optimization opportunities. We have described our approach as working \non data.ow graphs that describe data dependencies. We believe our approach could be extended to work \non graphs that also record control dependencies. However, it may be di.cult to ensure that sanitizer \nand declassi.ers correctly account for potentially dangerous control dependencies. We also believe that \nthe approach outlined here can apply to settings other than security. Consider the challenge of manually \nplacing catch blocks in a program written in Java or C#. This problem has a similar structure to the \nsanitizer placement problem: instead of the data.ow graph we have the call graph of the program; for \nsource nodes, we have statements that can throw exceptions; instead of sanitizers we have catch blocks. \nFinally, there is only one sink, the top-most main function, by the exit of which we generally need to \ncatch all run-time-catchable exceptions. 8. Conclusions Traditionally, developers have been responsible \nfor properly dealing with the possibility of injection attacks and informa\u00adtion leaks in their code, \nleading to numerous bugs, especially in large, complex code bases. The algorithms presented in this paper \npave the way for completely automatic placement of sanitizers and declassi.ers. We proposed two strategies \nfor automatic sanitizer place\u00adment. The .rst is a node-based entirely static approach that has no run-time \noverhead, but in many settings will not correctly sanitize all values. The second strategy is an edge\u00adbased \napproach that attempts to place sanitizers statically, but uses run-time taint-tracking when necessary \nto deter\u00admine the appropriate sanitization to apply to values. The edge-based placement strategy will \nalways sanitize values correctly, and reduces the number of nodes that require in\u00adstrumentation, sometimes \nby as much as 27\u00d7, compared to na\u00a8ive taint-tracking of values between sources and sinks. Acknowledgments \nWe thank the anonymous reviewers for their helpful com\u00adments. We appreciate the helpful comments of Trent \nJaeger and Somesh Jha. This research is supported in part by the National Science Foundation under Grant \nNo. 1054172. References [1] A. V. Aho, M. Lam, R. Sethi, and J. D. Ullman. Compilers: Principles, Techniques, \nand Tools. Addison-Wesley, 2007. [2] D. Avots, M. Dalton, B. Livshits, and M. S. Lam. Improving software \nsecurity with a C pointer analysis. In Proceedings of the International Conference on Software Engineering, \nMay 2005. [3] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic, E. Kirda, C. Kruegel, and G. Vigna. \nSaner: Composing Static and Dy\u00adnamic Analysis to Validate Sanitization in Web Applications. In Proceedings \nof the IEEE Symposium on Security and Privacy, May 2008. [4] D. Bates, A. Barth, and C. Jackson. Regular \nexpressions con\u00adsidered harmful in client-side XSS .lters. In Proceedings of the International World \nWide Web Conference, 2010. [5] P. Briggs and K. D. Cooper. E.ective partial redundancy elimi\u00adnation. \nIn Proceedings of the Conference on Programming Lan\u00adguage Design and Implementation, 1994. [6] B. Chess \nand J. West. Dynamic taint propagation: Finding vul\u00adnerabilities without attacking. Information Security \nTechnical Reports, 13, January 2008. [7] E. Chin and D. Wagner. E.cient character-level taint tracking \nfor Java. In Proceedings of the Workshop on Secure Web Services, 2009.  [8] S. Chong, K. Vikram, and \nA. C. Myers. Sif: enforcing con.\u00addentiality and integrity in Web applications. In Proceedings of Usenix \nSecurity Symposium, 2007. [9] M. Egele, C. Kruegel, E. Kirda, and G. Vigna. PiOS: Detect\u00ading privacy \nleaks in iOS applications. In Proceedings of the Annual Network and Distributed System Security Symposium, \nFeb. 2011. [10] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. Mc-Daniel, and A. N. Sheth. TaintDroid: \nan information-.ow track\u00ading system for realtime privacy monitoring on smartphones. In Proceedings of \nthe Usenix Conference on Operating Systems Design and Implementation, 2010. [11] V. Haldar, D. Chandra, \nand M. Franz. Dynamic taint propaga\u00adtion for Java. In Proceedings of the Annual Computer Security Applications \nConference, Dec. 2005. [12] C. Hammer and G. Snelting. Flow-sensitive, context-sensitive, and object-sensitive \ninformation .ow control based on program dependence graphs. International Journal of Information Se\u00adcurity, \n8(6):399 422, Dec. 2009. [13] C. Hammer, J. Krinke, and F. Nodes. Intransitive noninterference in dependence \ngraphs. In 2nd International Symposium on Leveraging Application of Formal Methods, Veri.cation and Validation, \nNov. 2006. [14] C. Hammer, J. Krinke, and G. Snelting. Information .ow con\u00adtrol for java based on path \nconditions in dependence graphs. In IEEE International Symposium on Secure Software Engineer\u00ading, Mar. \n2006. [15] P. Hooimeijer, B. Livshits, D. Molnar, P. Saxena, and M. Veanes. Fast and precise sanitizer \nanalysis with BEK. In Proceedings of the Usenix Security Symposium, Aug. 2011. [16] A. L. Hosking, N. \nNystrom, D. Whitlock, Q. Cutts, and A. Di\u00adwan. Partial redundancy elimination for access path expressions. \nSoftware Practice and Experience, 31, May 2001. [17] Y.-W. Huang, F. Yu, C. Hang, C.-H. Tsai, D.-T. Lee, \nand S.-Y. Kuo. Securing Web application code by static analysis and run\u00adtime protection. In Proceedings \nof the International Conference on World Wide Web, 2004. [18] N. Jovanovic, C. Kruegel, and E. Kirda. \nPixy: A static analysis tool for detecting Web application vulnerabilities (short paper). In Proceedings \nof the IEEE Symposium on Security and Pri\u00advacy, 2006. [19] D. King, S. Jha, D. Muthukumaran, T. Jaeger, \nS. Jha, and S. A. Seshia. Automating security mediation placement. In Proceed\u00adings of the European Symposium \non Programming, 2010. [20] J. Knoop, O. uthing, and B. Ste.en. Lazy code motion. R\u00a8 SIGPLAN Notes, 39:460 \n472, April 2004. [21] T. Kremenek, P. Twohey, G. Back, A. Y. Ng, and D. R. Engler. From uncertainty \nto belief: Inferring the speci.cation within. In Symposium on Operating Systems Design and Implementation, \nNov. 2006. [22] B. Livshits and M. S. Lam. Finding security errors in Java programs with static analysis. \nIn Proceedings of the Usenix Security Symposium, 2005. [23] B. Livshits, A. V. Nori, S. K. Rajamani, \nand A. Banerjee. Merlin: Speci.cation inference for explicit information .ow problems. In Proceedings \nof the Conference on Programming Language Design and Implementation, June 2009. [24] M. Martin, B. Livshits, \nand M. S. Lam. Finding application er\u00adrors and security .aws using PQL: a program query language. In \nProceedings of the Conference on Object Oriented Pro\u00adgramming Systems Languages and Applications, pages \n365 383, 2005. [25] M. Martin, B. Livshits, and M. S. Lam. SecuriFly: runtime vulnerability protection \nfor Web applications. Technical report, Stanford University, 2006. [26] Microsoft Corporation. Microsoft \nCode Analysis Tool .NET (CAT.NET). http://www.microsoft.com/en-us/download/ details.aspx?id=19968, 3 \n2009. [27] Microsoft Corporation. Microsoft web protection library. http: //wpl.codeplex.com/, 2012. \n[28] N. Mitchell, G. Sevitsky, and H. Srinivasan. The diary of a da\u00adtum: an approach to modeling runtime \ncomplexity in framework\u00adbased applications. In Proceedings of the European Confer\u00ad ence on Object-Oriented \nProgramming, Systems, Languages, and Applications, 2005. [29] A. Nguyen-Tuong, S. Guarnieri, D. Greene, \nJ. Shirley, and D. Evans. Automatically hardening Web applications using pre\u00adcise tainting. In Proceedings \nof the IFIP International Infor\u00admation Security Conference, 2005. [30] OWASP. OWASP-Java-HTML-sanitizer. \nhttp://code.google. com/p/owasp-java-html-sanitizer/, 2011. [31] T. Pietraszek and C. V. Berghe. Defending \nagainst injection at\u00adtacks through context-sensitive string evaluation. In Proceedings of the Recent \nAdvances in Intrusion Detection, Sept. 2005. [32] W. Robertson and G. Vigna. Static enforcement of web \nappli\u00adcation integrity through strong typing. In Proceedings of the Usenix Security Symposium, 2009. \n[33] W. Robertson and G. Vigna. Static enforcement of web appli\u00adcation integrity through strong typing. \nIn Proceedings of the Usenix Security Symposium, Aug. 2009. [34] RSnake. XSS cheat sheet for .lter evasion. \nhttp://ha.ckers.org/ xss.html. [35] O. Ruthing, J. Knoop, and B. \u00a8Ste.en. Sparse code motion. In Proceedings \nof the Symposium on Principles of Programming Languages, 2000. [36] A. Sabelfeld and A. C. Myers. Language-based \ninformation-.ow security. IEEE Journal on Selected Areas in Communications, 21(1):5 19, Jan. 2003. [37] \nA. Sabelfeld and D. Sands. Dimensions and principles of declas\u00adsi.cation. In Proceedings of the 18th \nIEEE Computer Security Foundations Workshop, pages 255 269. IEEE Computer Society, June 2005. [38] M. \nSamuel, P. Saxena, and D. Song. Context-sensitive auto\u00adsanitization in web templating languages using \ntype quali.ers. In Proceedings of the Conference on Computer and Communi\u00adcations Security, Oct. 2011. \n[39] P. Saxena, D. Molnar, and B. Livshits. ScriptGard: Automatic context-sensitive sanitization for \nlarge-scale legacy web applica\u00adtions. In Proceedings of the Conference on Computer and Com\u00admunications \nSecurity, Oct. 2011. [40] B. Scholz, C. Zhang, and C. Cifuentes. User-input dependence analysis via graph \nreachability. Technical Report 2008-171, Sun Microsystems Labs, 2008. [41] V. Srivastava, M. D. Bond, \nK. S. McKinley, and V. Shmatikov. A security policy oracle: detecting security holes using multiple API \nimplementations. In Proceedings of the Conference on Programming Language Design and Implementation, \n2011. [42] Z. Su and G. Wassermann. The essence of command injection attacks in Web applications. In \nProceedings of the Symposium on Principles of Programming Languages, 2006. [43] O. Tripp, M. Pistoia, \nS. J. Fink, M. Sridharan, and O. Weisman. TAJ: e.ective taint analysis of web applications. In Proceed\u00adings \nof the Conference on Programming Language Design and Implementation, 2009. [44] J. Vaughan and S. Chong. \nInference of expressive declassi.cation policies. In Proceedings of IEEE Symposium on Security and Privacy, \nMay 2011. [45] M. Veanes, P. Hooimeijer, B. Livshits, D. Molnar, and N. Bjorner. Symbolic .nite state \ntransducers: Algorithms and applications. In Proceedings of the Sympolisium on Principles of Program\u00adming \nLanguages, Jan. 2012. [46] J. Weinberger, P. Saxena, D. Akhawe, M. Finifter, R. Shin, and D. Song. A \nsystematic analysis of XSS sanitization in web application frameworks. In Proceedings of the European \nSymposium on Research in Computer Security, Sept. 2011. [47] Y. Xie and A. Aiken. Static detection of \nsecurity vulnerabilities in scripting languages. In Proceedings of the Usenix Security Symposium, 2006. \n[48] E. Z. Yang. HTML puri.er. http://code.google.com/p/ owasp-java-html-sanitizer/, 2011.     \n\t\t\t", "proc_id": "2429069", "abstract": "<p>A great deal of research on sanitizer placement, sanitizer correctness, checking path validity, and policy inference, has been done in the last five to ten years, involving type systems, static analysis and runtime monitoring and enforcement. However, in pretty much all work thus far, the burden of sanitizer placement has fallen on the developer. However, sanitizer placement in large-scale applications is difficult, and developers are likely to make errors, and thus create security vulnerabilities.</p> <p>This paper advocates a radically different approach: we aim to fully automate the placement of sanitizers by analyzing the ow of tainted data in the program. We argue that developers are better off leaving out sanitizers entirely instead of trying to place them.</p> <p>This paper proposes a fully automatic technique for sanitizer placement. Placement is static whenever possible, switching to run time when necessary. Run-time taint tracking techniques can be used to track the source of a value, and thus apply appropriate sanitization. However, due to the runtime overhead of run-time taint tracking, our technique avoids it wherever possible.</p>", "authors": [{"name": "Benjamin Livshits", "author_profile_id": "81100637280", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P3978005", "email_address": "livshits@microsoft.com", "orcid_id": ""}, {"name": "Stephen Chong", "author_profile_id": "81548379156", "affiliation": "Harvard University, Cambridge, MA, USA", "person_id": "P3978006", "email_address": "chong@seas.harvard.edu", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429115", "year": "2013", "article_id": "2429115", "conference": "POPL", "title": "Towards fully automatic placement of security sanitizers and declassifiers", "url": "http://dl.acm.org/citation.cfm?id=2429115"}