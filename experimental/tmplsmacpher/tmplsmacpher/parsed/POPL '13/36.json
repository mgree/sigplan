{"article_publication_date": "01-23-2013", "fulltext": "\n HALO: Haskell to Logic through Denotational Semantics Dimitrios Vytiniotis Dan Ros \u00b4en Simon Peyton \nJones Koen Claessen Microsoft Research Chalmers University Abstract Even well-typed programs can go wrong \nin modern functional lan\u00adguages, by encountering a pattern-match failure, or simply return\u00ading the wrong \nanswer. An increasingly-popular response is to allow programmers to write contracts that express semantic \nproperties, such as crash-freedom or some useful post-condition. We study the static veri.cation of such \ncontracts. Our main contribution is a novel translation to .rst-order logic of both Haskell programs, \nand contracts written in Haskell, all justi.ed by denotational semantics. This translation enables us \nto prove that functions satisfy their con\u00adtracts using an off-the-shelf .rst-order logic theorem prover. \nCategories and Subject Descriptors D.3 [Software]: Applicative (functional) languages General Terms veri.cation, \nlanguages Keywords static contract checking, .rst-order logic 1. Introduction Haskell programmers enjoy \nthe bene.ts of strong static types and purity: static types eliminate many bugs early on in the develop\u00adment \ncycle, and purity simpli.es equational reasoning about pro\u00adgrams. Despite these bene.ts, however, bugs \nmay still remain in purely functional code and programs often crash if applied to the wrong arguments. \nFor example, consider these Haskell de.nitions: f xs = head (reverse (True : xs)) g xs = head (reverse \nxs) Both f and g are well typed (and hence do not go wrong in Milner s sense), but g will crash when \napplied to the empty list, whereas f cannot crash regardless of its arguments. To distinguish the two \nwe need reasoning that goes well beyond that typically embodied in a standard type system. Many variants \nof dependent type systems (Norell 2007; Swamy et al. 2011; Xi 2007) or re.nement type systems (Knowles \nand Flanagan 2010; Rondon et al. 2008) have been proposed to address this problem, each offering different \ndegrees of expressiveness or automation. Another line of work aiming to address this chal\u00adlenge, studied \nby many researchers as well (Blume and McAllester Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 13, January 23 25, 2013, Rome, Italy. Copyright &#38;#169; \n2013 ACM 978-1-4503-1832-7/13/01. . . $10.00 2006; Findler and Felleisen 2002; Knowles and Flanagan \n2010; Siek and Taha 2006; Wadler and Findler 2009), allows program\u00admers to annotate functions with contracts, \nwhich are forms of be\u00adhavioural speci.cations. For instance, we might write the following contract for \nreverse: reverse . (xs : CF) .{ys | null xs <=> null ys} This contract annotation asserts that if reverse \nis applied to a crash-free (CF) argument list xs then the result ys will be empty (null) if and only \nif xs is empty. What is a crash-free argument? Since we are using lazy semantics, a list could contain \ncons-cells that yield errors when evaluated, and the CF precondition asserts that the input list is not \none of those. Notice also that null and <=> are just ordinary Haskell functions, perhaps written by the \nprogrammer, even though they appear inside contracts. With this property of reverse in hand, we might \nhope to prove that f satis.es the contract f . CF . CF But how do we verify that reverse and f satisfy \nthe claimed con\u00adtracts? Contracts are often tested dynamically, but our plan here is different: we want \nto verify contracts statically and automatically. It should be clear that there is a good deal of logical \nreasoning to do, and a now-popular approach is to delegate the task to an off\u00adthe-shelf theorem prover \nsuch as Z3 (De Moura and Bj\u00f8rner 2008) or Vampire (Hoder et al. 2010), or search for counterexamples \nwith a .nite model .nder (Claessen and S \u00a8orensson 2003). With that in mind, we make the following new \ncontributions: We give a translation of Haskell programs to .rst-order logic (FOL) theories. It turns \nout that lazy programs have a very natural translation into .rst-order logic (Section 3).  We give a \ntranslation of contracts to FOL formulae, and an axiomatisation of the language semantics in FOL (Section \n3.5).  Our main contribution is to show that if we can prove the for\u00admula that arises from a contract \ntranslation for a given program, then the program does indeed satisfy this contract. Our proof uses the \nnovel idea of employing the denotational semantics as a .rst-order model (Section 4).  We show how to \nuse this translation in practice for static con\u00adtract checking with a FOL theorem prover (Section 4.5), \nand how to prove goals by induction (Section 5).  This work is a .rst step towards practical contract \nchecking for Haskell programs, laying out the theoretical foundations for further engineering and experimentation. \nNevertheless, we have already implemented a prototype for Haskell programs that uses GHC as a front-end. \nWe have evaluated the practicality of our approach on many examples, including lazy and higher-order \nprograms, and goals that require induction. We report this initial encouraging evaluation in Section \n6.   Programs, de.nitions, and expressions P ::= d1 ...dn d ::= f a (x : t )= u u ::= e | case e of \nK y . e  e ::= x Variables | f[t ] Function variables | K[t ](e) Data constructors | ee Applications \n| BAD Runtime error  Syntax of closed values n m<n Kn fn v, w ::= [t](e ) | [t ] e | BAD  Contracts \nC ::= {x | e} Base contracts | (x : C1) . C2 Arrow contracts | C1&#38;C2 Conjunctions | CF Crash-freedom \nTypes t, s ::= T t Datatypes | a | t . t Type environments and signatures G ::= \u00b7| G,x .::= \u00b7| .,a | \n.,x:t S ::= \u00b7| S,T :n | S,f:.a.t | S,Kn:.a.t n . T a   Auxiliary functions (\u00b7)- = \u00b7 (.,a)- =.- (., \n(x:t ))- =.- ,x Figure 1: Syntax of .HALO and its contracts To our knowledge no one has previously presented \na translation of lazy higher-order programs to .rst-order logic, in a provably sound way with respect \nto a denotational semantics. Furthermore, our ap\u00adproach to static contract checking is distinctly different \nto previ\u00adous work: instead of wrapping and symbolic execution (Xu 2012; Xu et al. 2009), we harness purity \nand laziness to directly use the denotational semantics of programs and contracts and discharge the obligations \nwith a FOL theorem prover, side-stepping the wrapping process. Instead of generating veri.cation conditions \nby pushing pre-and post-conditions through a program, we directly ask a the\u00adorem prover to prove a contract \nfor the FOL encoding of a program. We discuss related work in Section 8.  2. A higher-order lazy language \nand its contracts To formalise the ideas behind our implementation, we de.ne a tiny source language .HALO \n: a polymorphic, higher-order, call-by\u00adname .-calculus with algebraic datatypes, pattern matching, and \nrecursion. Our actual implementation treats all of Haskell, by using GHC as a front end to translate \nHaskell into language .HALO . 2.1 Syntax of .HALO Figure 1 presents the syntax of .HALO . A program P \nconsists of a set of recursive function de.nitions d1 .. .dn. Each de.nition has a left hand side that \nbinds its type-variable and term-variable parameters; if f has n term-variable parameters we say that \nit has arity n, and sometimes write it fn . The right hand side u of a de.nition is either a case expression \nor a case-free expression e. A case-free expression consists of variables x, function variables f[t ] \nfully applied to their type arguments, applications e1 e2,and data constructor applications K[t ](e). \nThe latter return values of datatypes T t . As a notation, we use x n for sequences of elements of size \nn.When n is omitted x has a size which is implied by the context or is not interesting. A program crashes \nif it evaluates the special value BAD.For exam\u00adple, we assume that the standard Haskell function error \nsimply invokes BAD, thus: error :: String -> a error s = BAD Moreover, we assume that all incomplete \npattern-matches are com\u00adpleted, with the missing case yielding BAD. For example: head :: [a] -> [a] head \n(x:xs) = x head [] = BAD In our context, BAD is our way to saying what it means for a program to go wrong \n, and veri.cation amounts to proving that a program cannot invoke BAD. Our language embodies several \nconvenient syntactic constraints: (i) .-abstractions occur only at the top-level, (ii) case-expressions \ncan only immediately follow a function de.nition, and (iii) con\u00adstructors are fully applied. Any Haskell \nprogram can be trans\u00adformed into this restricted form by lambda-lifting, case-lifting, and eta-expansion \nrespectively, and our working prototype does just this. However this simpler language is notationally \nconvenient for the translation of programs to .rst-order logic. .HALO is an explicitly-typed language, \nand we assume the existence of a typing relation S . P , which checks that a program conforms to the \nde.nitions in the signature S. A signature S (Figure 1) records the declared data types, data constructors \nand types of functions in the program P . The well-formedness of expressions is checked with a typing \nrelation S; . . u : t ,where . is a typing environment, also in Figure 1. We do not give the details \nof the typing relation since it is standard. Our technical development and analysis in the following \nsections assume that the program has been checked for type errors. The typing judgement should check \nthat all pattern matches are exhaustive; as mentioned above, missing cases should return BAD. The syntax \nof closed values is also given in Figure 1. Since we do not have arbitrary .-abstractions, values can \nonly be partial function applications fn[t] e m<n , data constructor applications K[t ](e), and the error \nterm BAD. The operational semantics of .HALO is entirely standard, and we do not give it here. We write \nP . u . v to mean in program P, right-hand side u evaluates to value v ,  2.2 Contracts We now turn \nour attention to contracts. The syntax of contracts is given in Figure 1 and includes base contracts \n{x | e}, arrow con\u00adtracts (x : C1) . C2, conjunctions C1&#38;C2 and crash-freedom CF. Previous work (Xu \net al. 2009) includes other constructs as well, but the constructs we give here are enough to verify \nmany programs and exhibit the interesting theoretical and practical problems. We write e . C to mean \nthe expression e satis.es the contract C , and similarly for functions f. We will say what contracts \nmean formally in Section 4.3. However, here is their informal meaning: Terms  s, t ::= x Variables | \nf(t) Function applications | K(t) Constructor applications | sel Ki(t) Constructor selectors | fptr | \napp(t, s) Pointers and application | unr | bad Unreachable, bad Formulae . ::= cf(t) Crash-freedom | \nt1 = t2 Equality | . . . | . . . |\u00ac. |.x.. |.x.. Abbreviations app(t, s n)=(... (app(t, s1),...sn) ...) \n.1 . .2 = \u00ac.1 . .2 Figure 2: Syntax of FOL e .{x | e'} means that e does not evaluate to a value or \ne'[e/x] evaluates to True or does not evaluate to a value. Notice that e' is an arbitrary expression \n(in our implementation, arbi\u00adtrary Haskell expressions), rather than being restricted to some well behaved \nmeta-language. This is great for the programmer because the language and its library functions are familiar, \nbut poses a challenge for veri.cation because these expressions in contracts may themselves diverge or \ncrash.  e . (x : C1) . C2 means that whenever e' satis.es C1,it is the  ' ' case that (ee) satis.es \nC2[e/x]. e . C1&#38;C2 means that e satis.es both C1 and C2.  e . CF means that e is crash free;thatis \ne does not crash regardless of what context it is plugged into (see Section 3.6).   3. Translating \n.HALO to .rst-order logic Our goal is to answer the question does expression e satisfy con\u00adtract C? . \nOur plan is to translate the expression and the contract into a .rst-order logic (FOL) term and formula \nrespectively, and get an FOL prover to do the heavy lifting. In this section we formalise our translation, \nand describe how we use it to verify contracts. 3.1 The FOL language We begin with the syntax of the \nFOL language, which is given in Figure 2. There are two syntactic forms, terms and formulae.Terms include \nsaturated function applications f(t), that is, fully applied to all the arguments that were declared \nat their de.nition. They also include saturated constructor applications K(t), variables, and, for each \ndata constructor Kn in the signature S with arity n,a setof selector functions sel Ki(t) for i . 1 ... \nn.The terms app(t, s) and fptr concern the higher-order aspects of .HALO (namely un\u00adsaturated applications), \nwhich we discuss in Section 3.3. Finally we introduce two new syntactic constructs unr and bad.As an \nabbreviation we often use app(t, s) for the sequence of applications to each si, as Figure 2 shows. Aformula \n. in Figure 2 is just a FOL formula, augmented with a predicate cf(t) for crash-freedom, which we discuss \nin Section 3.6.  3.2 Translation of expressions to FOL What exactly does it mean to translate an expression \nto .rst-order logic? We are primarily interested in reasoning about equality, so we might hope for this \ninformal guiding principle:   P{{d} = D{{d}  D{{f a (x:t)= u} = .x. U(f(x)){ u} ..x. f(x)= app(fptr, \nx) U(s){ e} =(s = E{{e} ) U(s){ case e of K y . e'} =(t = bad . s = bad) ' . (.y.t = K1(y) . s = E{{e} \n) . .. . 1 . (t bad . t=K 1(sel K1i(t)) . ... . s = unr) where t = E{{e} = E{{x} = x E{{f[ t]} = fptr \nE{{K[t](e)} = K(E{{e} ) E{{e1 e2} = app(E{{e1} , E{{e2} ) E{{BAD} = bad C{{e .{x | e'}}} = t= unr . \nt'[t/x]= unr . t'[t/x]=True where t = E{{e} and t' = E{{e'} C{{e . (x:C1) . C2} = .x.C{{x . C1}}. C{ \nex . C2} C{{e . C1&#38;C2} = C{{e . C1}}. C{ e . C2} C{{e . CF} = cf(E{{e} ) Figure 3: Translation of \nprograms and contracts to logic Axioms for bad and unr AXAPPBAD .x.app(bad, x)= bad AXAPPUNR .x.app(unr, \nx)= unr AXDISJBU bad= unr Axioms for data constructors n m AXDISJC .xy.K(x)= J(y) for every (K:.a.tn \n. T a) . S and (J:.a.tm . S a) . S and K = J n AXDISJCBU (.x.K(x) = unr . K(x) = bad) for every (K:.a.tn \n. T a) . S n AXINJ .y. sel Ki(K(y)) = yi for every Kn . S and i . 1..n Axioms for crash-freedom n AXCFC \n.x.cf(K(x)) . cf(x) for every (K:.a.tn . T a) . S AXCFBU cf(unr) .\u00accf(bad) Figure 4: Theory T : axioms \nof the FOL constants  If we can prove1 in FOL that E{{e1} = E{{e2} then e1 and e2 are semantically equivalent. \nwhere E{{e} is the translation of e to a FOL term. That is, we can reason about the equality of Haskell \nterms by translating them into FOL, and then using a FOL theorem prover. The formal statement of this \nproperty is Corollary 4.5. The translation of programs, de.nitions, and expressions to FOL is given in \nFigure 3. The function P{{P } translates a program to a conjunction of formulae, one for each de.nition \nd,using D{{d} to translate each de.nition. The .rst clause in Ds right-hand side uses U to translate \nthe right hand side u, and quanti.es over the x.We will deal with the second clause of D in Section 3.3. \nIgnoring case for now (which we discuss in Section 3.4), the formula U(f(x)){ e} simply asserts the equality \nf(x)= E{{e} . That is, we use a new function f in the logic for each function de.nition in the program, \nand assert that any application of f is equal to (the logical translation of) f s right hand side. Notice \nthat we erase type arguments in the translation since they do not affect the semantics. You might think \nthat the translation f(x)= E{{e} is entirely obvious but, surprisingly, it is only correct because we \nare in a call-by-name setting. The same equation is problematic in a call-by-value setting an issue \nwe return to towards the end of Section 4.4. Lastly E{{e} deals with expressions. We will deal with functions \nand application shortly (Section 3.3), but the other equations for E{{e} are straightforward. Notice \nthat E{{BAD} = bad, and recall that BAD is the .HALO -term used for an inexhaustive case or a call to \nerror. It follows from our guiding principle that for any e,if we manage to prove in FOL that E{{e} = \nbad, then the source program e must be semantically equivalent to BAD, meaning that it de.nitely crashes. \n 3.3 Translating higher-order functions If .HALO was a .rst-order language, the translation of function \ncalls would be easy: E{{f[t ] e} = f(E{{e} ) At .rst it might be surprising that we can also translate \na higher\u00adorder language .HALO into .rst order logic, but in fact it is easy to do so, as Figure 3 shows. \nWe introduce into the logic (a) a single new function app, and (b) a nullary constant fptr for each function \nf (see Figure 2). Then, the equations for E{{e} translate application in .HALO to a use of app in FOL, \nand any mention of function f in .HALO to a use of fptr in the logic. For example: E{{map f xs} = app(app(mapptr, \nfptr), xs) assuming that map and f are top-level functions in the .HALO \u00adprogram, and xs is a local variable. \nOnce enough app applications stack up, so that mapptr is applied to two arguments, we can invoke the \nmap function directly in the logic, an idea we express with the following axiom: .xy . app(app(mapptr,x),y)= \nmap(x, y) These axioms, one for each function f, are generated by the second clause of the rules for \nD{{d} in Figure 3. (The notation app(f, x) is de.ned in Figure 2.) You can think of mapptr as a pointer \nto , or name of of, map.The app axiom for map translates a saturated use of map s pointer into a call \nof map itself. 1 From an appropriate axiomatisation of the semantics of programs. 3.4 Data types and \ncase expressions The second equation for U(s){ u} in Figure 3 deals with case expressions, by generating \na conjunction of formulae, as follows: If the scrutinee t is bad (meaning that evaluating it invokes \nBAD) then the result s of the case expression is also bad.Thatis, case is strict in its scrutinee.  \nIf the scrutinee is an application of one of the constructors Ki mentioned in one of the case alternatives, \nthen the result s is equal to the corresponding right-hand side, ei ' , after quantifying the variables \ny bound by the case alternative.  Otherwise the result is unr. The bit before the implication . is just \nthe negation of the previous preconditions; the formula  t. =K1(sel K1(t)) is the clumsy FOL way to \nsay t is not built with constructor K1 . Why do we need the last clause? Consider the function not: not \n:: Bool -> Bool not True = False not False = True Suppose we claim that not . CF . CF, which is patently \ntrue. But if we lack the last clause above, the claim is not true in every model; for example not might \ncrash when given the (ill-typed but crash\u00adfree) argument 3. The third clause above excludes this possibility \nby asserting that the result of not is the special crash-free constant unr if the scrutinee is ill-typed \n(i.e. not bad and not built with the constructors of the type). This is the whole reason we need unr \nin the .rst place. In general, if E{{e} = unr is provable in the logic, then e is ill-typed, or divergent. \nOf course, we also need to axiomatise the behaviour of data con\u00adstructors and selectors, which is done \nin Figure 4: AXDISJCBU explains that a term headed by a data constructor cannot also be bad or unr. \n AXINJ explains how the selectors sel Ki work.  AXDISJC tells the prover that all data constructors \nare pairwise disjoint. There are a quadratic number of such axioms, which presents a scaling problem. \nFor this reason FOL provers some\u00adtimes offer a built-in notion of data constructors, so this is not a \nproblem in practice, but we ignore this pragmatic issue here.  A small point is that AXCFBU actually \nimplies AXDISJBU but for presentational reasons we keep both axioms.  3.5 Translation of contracts to \nFOL Now that we know how to translate programs to .rst order logic, we turn our attention to translating \ncontracts. We do not translate a contract per se; rather we translate the claim e . C.Once we have translated \ne . C to a .rst-order logic formula, we can ask a prover to prove it using axioms from the translation \nof the program, or axioms from Figure 4. If successful, we can claim that indeed e does satisfy C. Of \ncourse that needs proof, which we address in Section 4.4. Figure 3 presents the translation C{{e . C} \n; there are four equa\u00adtions corresponding to the syntax of contracts in Figure 1. The last three cases \nare delightfully simple and direct. Conjunction of contracts turns into conjunction in the logic; a dependent \nfunction contract turns into universal quanti.cation and implication; and the claim that e is crash-free \nturns into a use of the special term cf(t) in the logic. We discuss crash-freedom in Section 3.6. The \n.rst equation, for predicate contracts e .{x | e ' }, is sightly more complicated. The .rst clause t \n= unr, together with the ax\u00adioms for unr in Figure 4, ensures that unr satis.es every contract. The second \nand third say that the contract holds if e ' diverges or is semantically equal to True. The choices embodied \nin this rule were discussed at length in earlier work (Xu et al. 2009) and we do not repeat it here. \n  3.6 Crash-freedom The claim e . CF, pronounced e is crash-free , means that e cannot crash regardless \nof context. So, for example (BAD, True) is not crash-free because it can crash if evaluated in the context \nfst (BAD, True). Of course, the context itself should not be the source of the crash; for example (True,False) \nis crash-free even though BAD (True,False) will crash. We use the FOL term cf(t) to assert that t is \ncrash-free. The axioms for cf are given in Figure 4. AXCFC says that a data constructor application is \ncrash-free if and only iff its arguments are crash-free. AXCFBU says that unr is crash-free, and that \nbad is not. That turns out to be all that we need. 3.7 Summary That completes our formally-described \n but so far only informally\u00adjusti.ed translation from a .HALO program and a set of contract claims, \ninto .rst-order logic. To a .rst approximation, we can now hand the generated axioms from the program \nand our axiomatisa\u00adtion to an FOL theorem prover and ask it to use them to prove the translation of the \ncontract claims.  4. Soundness through denotational semantics Our account so far has been largely informal. \nHow can we be sure that if the FOL prover says Yes! This FOL formula is provable , then the corresponding \n.HALO program indeed satis.es the claimed contract? To prove this claim we take a denotational approach. \nMost of what follows is an adaptation of well-known techniques to our setting and there are no surprises \n we refer the reader to (Winskel 1993) or (Benton et al. 2009) for a short and modern exposition of the \nstandard methodology. 4.1 Technical preliminaries We will assume a program P , well-formed in a signature \nS,so that S . P . Given a signature S we de.ne a strict bi-functor F on complete partial orders (cpos), \nbelow: F (D-,D+)=( n1 D+ Kn1 . S 1 + ... ... D+ Knk + . S nk k + (D- .c D+) + 1bad ). The bi-functor \nF is the lifting of a big sum: that sum consists of (i) products, one for each possible constructor (even \nacross different data types), (ii) the continuous function space from D- to D+ , and (iii) a unit cpo \nto denote BAD values. The notation D n abbreviates n-ary products of cpos (the unit cpo 1 if n =0). The \nproduct and sum constructions are standard, but note that we use their non-strict versions. The notation \nC .c D denotes the cpo induced by the space of continuous functions from the cpo C to the cpo D. We use \nthe notation 1bad to denote a single-element cpo the bad subscript is just there for readability. The \nnotation D. is lifting. Observe that we have dropped all type information from the source language. The \nelements of the products corresponding to data con\u00adstructors are simply D+ (instead of more a precise \ndescription from [[e]](\u00b7,\u00b7) :(FunVar .c D8) \u00d7 (Var .c D8) .c D8 [[x]](s,.) = .(x) [[f [t ]]](s,.) = s(f) \n[[K [t ](e)]](s,.) = K([[e]](s,.)) [[e1 e2]](s,.) = app([[e1]](s,.), [[e2]](s,.)) [[BAD]](s,.) = Bad \n[[u]](\u00b7,\u00b7) :(FunVar .c D8) \u00d7 (Var .c D8) .c D8 [[e]](s,.) =[[e]](s,.) [[case e ofK y . eK ]](s,.) =[[eK \n]](s,.,y .d) if [[e]](s,.) = K(d) and K is a case branch = Bad if [[e]](s,.) = Bad = . otherwise [[P \n]] : (FunVar .c D8) .c (FunVar .c D8) [[P ]]s f = Fun(.d1. ... Fun(.dn.[[u]](s,x .d)) ...) if (f ax = \nu) . P = . otherwise Figure 5: Denotational semantics of .HALO type information) and the return types \nof data constructors are sim\u00adilarly ignored. This is not to say that a more type-rich denotational semantics \nis not possible (or desirable even) but this simple deno\u00adtational semantics turns out to be suf.cient \nfor formalisation and veri.cation. Now we can de.ne D8 as the solution to this recursive domain equation \nD8 F (D8,D8) We can show that D8 exists using the standard embedding\u00adprojection pairs methodology. Moreover, \nwe de.ne the value do\u00admain V8 thus: V8 = n1 D8 Kn1 . S 1 + ... ... Knk + D8 . S nk k +(D8 .c D8) + 1bad \nThe following continuous functions also exist: roll :(V8). .c D8 unroll : D8 .c (V8). However in what \nfollows we will always elide these functions to reduce clutter. To denote elements of V8 we use the following \nnotation. K(d1, ...,dn) denotes the injection of the n-ary product of D8 into the component of the sum \nV8 corresponding to the n-ary constructor K.  Fun(d) is the injection of an element of D8 .c D8 into \nthe function component of V8  Bad is the unit injection into V8.   4.2 Denotational semantics of expressions \nand programs Figure 5 gives the denotational interpretations of expressions e, right hand sides u, and \nprograms P , in terms of the domain\u00adtheoretic language and combinators we have de.ned. First, the denumerable \nset of term variable names x1,.. . induces a discrete cpo Var and the denumerable set of function variable \n names f1,... induces a discrete cpo FunVar.We de.ne, semantic term environments to be the cpo (Var \n.c D8),and semantic function environments to be the cpo (FunVar .c D8). Figure 5 de.nes the denotational \nsemantics of expressions [[e]] as a continuous map from these two environments to D8.It is entirely straightforward \nexcept for application, which depends on the continuous function app : D8 \u00d7 D8 .c D8, de.ned thus2: app(d, \na)= df (a) if d = Fun(df ) = Bad if d = Bad = . otherwise That is, application applies the payload df \nif the function d comes from the appropriate component of V8, propagates Bad, and oth\u00aderwise returns \n.. The semantics of right-hand sides [[u]] is de.ned similarly. The semantics of a case expression is \nthe semantics of the matching branch, if one exists. Otherwise, like application, it propagates Bad. \nIn all other cases we return ., not Bad; all the missing cases can only be constructors of different \ndatatypes than the datatype that K belongs to, because all case expressions are complete (Section 2.1). \nThis treatment corresponds directly to our treatment of unr in Section 3.4. Finally, Figure 5 gives the \nsemantics of a program P , which should be read recalling its syntax in Figure 1. Since [[P ]] is continuous, \nits limit exists and is an element of the cpo FunVar .c D8. De.nition 4.1. We will refer to the limit \nof the [[P ]] as [[P ]]8 in what follows. Moreover, to reduce notational overhead below, for a program \nwith no free variables we will use notation [[e]] to mean [[e]]([[P ]]8 ,\u00b7), and [[e]]. to mean [[e]]([[P \n]]8,.) Although we have not presented a formal operational semantics, we state the usual soundness and \nadequacy results: Theorem 4.1 (Soundness and adequacy). Assume S . P and u with no free term variables. \nThen (i) if P . u . v then [[u]] = [[v]]; and (ii) if [[e]] . = .,then .v such that P . e . v. The proof \nof adequacy is routine domain theory so we only sketch the high-level road-map: The proof proceeds by \nde.ning a logical relation between semantics and syntax, via the use of a bi-functor on admissible relations \nbetween elements of D8 and closed ex\u00adpressions (Pitts 1996). Adequacy then follows from the fundamen\u00adtal \ntheorem of this logical relation, which asserts that every expres\u00adsion is related to its denotation. \n 4.3 Denotational semantics of contracts Now we are ready to say formally what it means for a function \nto satisfy a contract. We de.ne the semantics of a contract as the set of denotations that satisfy it: \n[[C]]. . D8 where C is a contract with free term variables in the semantic environment .. Figure 6 gives \nthe de.nition of this function. A base contract {x | e} is satis.ed by . or or by a computation that \ncauses the predicate e to become . or return True3 . The denotation of an arrow contract, and of conjunction, \nare both straightforward. The CF contract is a little harder. Intuitively an expression is crash\u00adfree \niff it cannot crash if plugged into an arbitrary crash-free con\u00adtext. Of course this is a self-referential \nde.nition so how do we 2 A small technical remark: we write the de.nition with pattern matching notation \napp(d, a) (instead of using p1 for projecting out d and p2 for projecting out a) but that is .ne, since \n\u00d7 is not a lifted construction. 3 In previous work (Xu et al. 2009) the base contract also required crash\u00adfreedom. \nWe changed this choice only for reasons of taste; both choices are equally straightforward technically. \n[[C]]. . D8 [[x | e]]. = {d | d = .. [[e]].,x.d .{True, .}} [[(x:C1) . C2]]. = {d |.d ' .[[C1]]. . app(d, \nd ' ) . [[C2]].,x.d. } [[C1&#38;C2]]. = {d | d . [[C1]]. . d . [[C2]].} [[CF]]. = F 8 cf where F 8 = \n{.} cf .{ K(d) | Kn . S,di . F 8} cf .{ Fun(d) |.d ' . F 8 .d(d ' ) . F 8} cf cf Figure 6: Denotations \nof contracts know it makes sense? The original paper (Xu et al. 2009) speci.ed that an expression is \ncrash free iff it cannot crash when plugged into a context that syntactically does not contain the BAD \nvalue. This is a reasonable de.nition in the operational semantics world, but here we can do better because \nwe are working with elements of D8. Using techniques developed by Pitts (Pitts 1996) we can de.ne crash-freedom \ndenotationally as the greatest solution to the recursive equation for F 8 in Figure 6. Technically, since \nthe equa\u00ad cf tion involves mixed-variance recursion, to show that such a .xpoint exists we have to use \nminimal invariance. Minimal invariance can be used with strict bi-functors to show that every element \nin the negative .xpoint of a bi-functor is contained in the positive .x\u00adpoint, by constructing a sequence \nof approximations whose limit is the identity (this is the minimal invariance property), and showing \nthat every approximation of that element is contained in the positive .xpoint. Admissibility does the \nrest. Hence the de.nition F 8 is well-formed; in addition the following cf is true and will be useful \nlater on for induction: Lemma 4.2. .. F 8 and F 8 is admissible, that is, if all cf cf elements of a \nchain are in F 8 then so is its limit. cf  4.4 Soundness of the logic translation We have developed \na formal semantics for expressions as well as contracts, so it is time we see how we can use this semantics \nto show that our translation to .rst-order logic is sound with respect to this semantics. Our plan is \nto give an interpretation (in the FOL sense of the term) to our translated FOL terms, using the carrier \nset D8 as our model. Happily this is straightforward to do: I(f(t)) = app([[f]], I(t)) I(app(t1,t2)) \n= app(I(t1), I(t2)) I(fptr)=[[f]] I(K(t)) = K(I(t)) I(sel Ki(t)) = di if I(t)= K(d) = . otherwise I(unr)= \n. I(bad)= Bad The essential soundness theorem that states that our interpretation makes sense is the \nfollowing. Theorem 4.3 (Interpretation respects denotations). Assume that S . P and expression e does \nnot contain any free variables. Then, if E{{e} = t then I(t)=[[e]]. (Recall that notation [[e]] abbreviates \nthe semantics of e in the program P , see De.nition 4.1)   The proof is an easy induction on the size \nof the term e. Our soundness results are expressed with the following theorem: Theorem 4.4. If S . P \nthen (D8, I) |= T. P{ P } . As a corollary we get our guiding principle from the introduction. Corollary \n4.5. Assume that S . P and e1 and e2 contain no free term variables. The following are true: [[e1]] = \n[[e2]] iff I(E{{e1} )= I(E{{e2} ). If T. P{ P }}. E{ e1} = E{{e2} then [[e1]] = [[e2]].  Proof. The \n.rst part follows directly from Theorem 4.3. For the second part the left-hand side implies that E{{e1} \nand E{{e2} are equal in all models of T.P{ P } , in particular (using Theorem 4.4) by (D8, I) and by \nthe .rst part the case is .nished. Theorem 4.6. Assume that e and C contain no free term variables. Then \nthe FOL translation of the claim e . C holds in the model if and only if the denotation of e is in the \nsemantics of C. Formally: (D8, I) |= C{{e . C}}. [[e]] . [[C]] Completeness of axiomatisation The D8 \ndomain has a complex structure and there are many more facts that hold about elements of D8 that are \nnot re.ected in any of our axioms in T . For instance, here are some admissible axioms that are valid: \n.x n .app(fptr, x) .= unr. app(fptr, x) .= bad ..y k .app(fptr, x) =.K(y) for every (f a x m = u) . P \nand K . S with m>n These axioms assert that partial applications cannot be equated to any constructor, \n. nor Bad. If the reader is worried that without a complete formalisation of all equalities of D8 it \nis impossible to prove any programs correct, we would like to reassure them that that is not the case, \nas we shall see in the next section. The translation and lazy vs strict semantics We have mentioned previously \n(Section 3.2) that the translation that we have presented is only valid in a call-by-name setting, and \nhere we explain why. Whenever we use universal quanti.cation in the logic, we re\u00adally quantify over any \ndenotation, including . and Bad.Ina call-by-name language, given a function f x = True,the axiom .x.f(x)= \nTrue is true in the intended denotational model. How\u00adever, in a call-by-value setting, x is allowed to \nbe interpreted as .. That means that the unguarded axiom is actually not true, because f . . = True. \nInstead we need the following variation: .x.x .. = bad . x = unr . f(x)= t Moreover, the axioms for the \napp(\u00b7, \u00b7) combinator have to be mod\u00adi.ed to perform checks that the argument is not . or Bad before actually \ncalling a function. In a call-by-name language these guards are needed only for case and the function \npart of app.  4.5 Contract checking as satis.ability Having established the soundness of our translation, \nit is time we see in this section how we can use this sound translation to verify a program. The following \ntheorem is then true: Theorem 4.7 (Soundness). Assume that e and C contain only function symbols from \nP and no free term variables. Let Tall = T. P{ P } .If Tall.\u00acC{ e . C} is unsatis.able then (D8, I) |= \nC{{e . C} and consequently [[e]] . [[C]]. Proof. If there is no model for this formula then its negation \nmust be valid (true in all models), that is \u00acTall .C{ e . C} is valid. By completeness of .rst-order \nlogic Tall .C{ e . C} .This means that all models of Tall validate C{{f . C} . In particular, for the \ndenotational model we have that (D8, I) |= Tall and hence (D8, I) |= C{{e . C} . Theorem 4.6 .nishes \nthe proof. Hence, to verify a program e satis.es a contract C we need to do the following: Generate formulae \nfor the theory T. P{ P }  Generate the negation of a contract translation: \u00acC{ e . C}  Ask a FOL theorem \nprover for a model for the conjunction of the above formulae  Incremental veri.cation Theorem 4.7 gives \nus a way to check that an expression satis.es a contract. Assume that we are given a program P with a \nfunction f . dom(P ),for which we have already shown that (D8, I) |= C{{f . Cf } . Suppose next that \nwe are presented with a next goal, to prove that (D8, I) |= C{{h . Ch} . We may consider the following \nvariations of how to do this: Ask for the unsatis.ability of: T.P{ P }}. \u00acC{ h . Ch} The soundness of \nthis query follows from Theorem 4.7 above. Ask for the unsatis.ability of: T. P{ P }}. C{ f . Cf }}. \n\u00acC{ h . Ch} This query adds the already proven contract for f to the theory. If this formula is unsatis.able, \nthen its negation is valid, and we know that the denotational model is a model of the theory and of C{{f \n. Cf } and hence it must also be a model of C{{h . Ch} . Ask for the unsatis.ability of: T. P{ P \\ f}}. \nC{ f . Cf }}. \u00acC{ h . Ch} This query removes the axioms associated with the de.nition of f, leaving \nonly its contract available. This makes the proof of h s contract insensitive to changes in f s implementation. \nVia a similar reasoning as before, such an invocation is sound as well. Incremental veri.cation essentially \nimplies that our approach does not require a whole-program analysis: once a contract is proved about \na function, it can be assumed, even if the de.nition of the function is not exported, and subsequently \nused to prove contracts of other functions that may call it. Exporting only the contract but not a de.nition \nof a function can be bene.cial for ef.ciency reasons when verifying further goals; the drawback is that \nthe exported contracts might not be precise enough for proving these further goals. Our framework supports \nany of those strategies.  5. Induction An important practical extension is the ability to prove contracts \nabout recursive functions using induction. For instance, we might want to prove that length satis.es \nCF . CF. length [] = Z length (x:xs) = S (length xs) In the second case we need to show that the result \nof length xs is crash-free but we do not have this information so the proof gets stuck, often resulting \nin the FOL-solver looping. A naive approach would be to perform induction over the list argu\u00adment of \nlength however in Haskell datatypes may be lazy in.\u00adnite streams and ordinary induction is not a valid \nproof principle. Fortunately, we can still appeal to .xpoint induction. The .xpoint induction scheme \nthat we use for length above would be to as\u00adsume that the contract holds for the occurence of some function \nlength_rec inside the body of its de.nition, and then try to prove it for the function:  length [] = \nZ length (x:xs) = S (length_rec xs) Formally, our induction scheme is: De.nition 5.1 (Induction scheme). \nTo prove that [[g]] . [[C]] for a function g a x:t = e[g] (meaning e contains some occurrences of g), \nwe perform the following steps: Generate function symbols g . , g Generate the theory formula . = T. \nP{ P . g a x:t = e[g .]} Prove that the query . .C{ g . . C}}. \u00acC{ g . C} is unsatis.able. Why is \nthis approach sound? The crucial step here is the fact that contracts are admissible predicates. Theorem \n5.1 (Contract admissibility). If di . [[C]] for all elements of a chain d1 . d2 . ... then the limit \nof the chain Udi . [[C]]. Moreover, .. [[C]]. Proof. By induction on the contract C;for the CF case \nwe get the result from Lemma 4.2. For the predicate case we get the result from the fact that the denotations \nof programs are continuous in D8. The arrow case follows by induction. We can then prove the soundness \nof our induction scheme. Theorem 5.2. The induction scheme in De.nition 5.1 is correct. Proof. We need \nto show that: [[P ]]8(g) . [[C]] and hence, by admissibility it is enough to .nd a chain whose limit \nis [[P ]]8(g) and such that every element is in [[C]]. Let us consider the chain [[P ]]k (g) so that \n[[P ]]0(g)= . and [[P ]]k+1(g)= [ P ]]([[P ]]k)(g) whose limit is [[P ]]8(g). We know that .. [[C]] so, \nby using contract admissiblity, all we need to show is that if [[P ]]k(g) . [[C]] then [[P ]]k+1(g) . \n[[C]]. To show this, we can assume a model where the denotational interpretation I has been extended \nso that I(g .)= [ P ]]k(g) and I(g )=[[P ]]k+1(g). By proving that the formula . .C{ g . . C}}. \u00acC{ g \n . C} is unsatis.able, since (D8, I) |= . and (D8, I) |= C{{g . . C} , we get (D8, I) |= C{{g . C} \n, and hence [[P ]]k+1(g) . [[C]]. Note that contract admissibility is absolutely essential for the soundness \nof our induction scheme, and is not a property that holds of every predicate on denotations. For example, \nconsider the fol\u00adlowing Haskell de.nition: ones = 1 : ones f (S x)= 1: fx fZ =[0] Let us try to check \nif the .x.f(x) .ones = is true in the deno\u00adtational model, using .xpoint induction. Importanttly, by \n.here = we really mean the negation of logical equality not aHaskell function that computes a Bool. \nThe case for . holds, and so does the case for the Z constructor. For the S x case, we can assume that \nf(x) .ones = and we can easily prove that this implies that f(S x) . = ones. Nevertheless, the property \nis not true just pick a counterexample [[s]] where s =Ss. What happened here is that the property is \ndenotationally true of all the elements of the following chain .. S(.) . S(S(.)) . .. . but is false \nin the limit of this chain. In other words .is not = admissible and our induction scheme is plain nonsense \nfor non\u00adadmissible predicates. Finally, we have observed that for many practical cases, a straight\u00adforward \ngeneralization of our lemma above for mutually recursive de.nitions is required. Indeed, our tool performs \nmutual .xpoint induction when a recursive group of functions is encountered. We leave it as future work \nto develop more advanced techniques such as strengthening of induction hypotheses or identifying more \nso\u00adphisticated induction schemes.  6. Implementation and practical experience Our prototype contract \nchecker is called halo. It uses GHC to parse, typecheck, and desugar a Haskell program, translates it \ninto .rst order logic (exactly as in Section 3), and invokes a FOL theo\u00adrem prover (Equinox, Z3, Vampire, \netc) on the FOL formula. The desugared Haskell program is expressed in GHC s intermediate language called \nCore (Sulzmann et al. 2007), an explicitly-typed variant of System F. It is straightforward to translate \nCore into our language .HALO. 6.1 Expressing contracts in Haskell How does the user express contracts? \nWe write contracts in Haskell itself, using higher-order abstract syntax and a GADT, in a manner reminiscent \nof the work on typed contracts for functional program\u00adming (Hinze et al. 2006): data Contract t where \n(:->) :: Contract a -> (a -> Contract b) -> Contract (a -> b) Pred :: (a -> Bool) -> Contract a CF :: \nContract a (:&#38;:) :: Contract a -> Contract a -> Contract a A value of type Contract t is a a contract \nfor a function of type t. The connectives are :-> for dependent contract function space, CF for crash-freedom, \nPred for predication, and :&#38;: for conjunction. One advantage of writing contracts as Haskell terms \nis that we can use Haskell itself to build new contract combinators. For example, a useful derived connective \nis non-dependent function space: (-->) :: Contract a -> Contract b -> Contract (a -> b) c1 --> c2 = c1 \n:-> (\\_ -> c2) A contract is always associated with a function, so we pair the two in a Statement: data \nStatement where (:::) :: a -> Contract a -> Statement In our previous mathematical notation we might \nwrite the following contract for head: head . CF &#38; {xs | not (null xs)}. CF Here is how we express \nthe contract as a Haskell de.nition: c_head :: Statement c_head = head ::: CF :&#38;: Pred (not . null) \n--> CF If we put this de.nition in a .le Head.hs, together with the supporting de.nitions of head, not,and \nnull, then we can run halo Head.hs.The halo program translates the contract and the supporting function \nde.nitions into FOL, generates a TPTP 4 .le, and invokes a theorem prover. And indeed c_head is veri.ed \nby all theorem provers we tried. For recursive functions halo uses .xpoint induction, as described in \nSection 5. 4 A widely supported format for FOL (Sutcliffe 2009).  6.2 Practical considerations To make \nthe theorem prover work as fast as possible we trim the theories to include only what is needed to prove \na property. Unnecessary function pointers, data types and de.nitions for the current goal are not generated. \nWhen proving a series of contracts, it is natural to do so in depen\u00addency order. For example: reverse \n:: [a] -> [a] reverse [] = [] reverse (x:xs) = reverse xs ++ [x] reverse_cf :: Statement reverse_cf = \nreverse ::: CF --> CF To prove this contract we must .rst prove that (++) . CF . CF . CF; then we can \nprove reverse s contract assuming the one for (++). At the moment, halo asks the programmer to specify \nwhich auxiliary contracts are useful, via a second constructor in the Statement type: reverse_cf = reverse \n::: CF --> CF Using append_cf  6.3 Dependent contracts halo can prove dependent contracts. For example: \nfilter . (p : CF . CF) . CF . CF &#38; {ys | allpys} This contract says that under suitable assumptions \nof crash-freedom, the result of filter is both crash-free and satis.es all p.Here all is a standard Haskell \nfunction, and p is the functional argu\u00adment itself. In our source-.le syntax we use (:->) to bind p. \nfilter_all :: Statement filter_all = filter ::: (CF --> CF) :-> \\p -> CF --> (CF :&#38;: Pred (all p)) \nThe contract looks slightly confusing since it uses two arrows , one from :->, and one from the -> in \nthe lambda. This contract is proved by applying .xed point induction. 6.4 Higher order functions Our \ntool also deals with (very) higher order functions. Consider this function withMany, from library Foreign.Util.Marshal: \nwithMany :: (a -> (b -> res) -> res) -> [a] -> ([b] -> res) -> res withMany _ [] f = f [] withMany withFoo \n(x:xs) f = withFoo x (\\x -> withMany withFoo xs (\\xs -> f (x :xs ))) For withMany, our tool proves withMany \n. (CF . (CF . CF) . CF) . (CF . (CF . CF) . CF) 6.5 Experimental Results We have run halo on a collection \nof mostly-small tests, some of which can be viewed in Figure 7. Our full testsuite and tables can be \ndownloaded from http://www.cse.chalmers.se/~ koen/halo. The test cases include: Figure 7: Theorem prover \nrunning time in seconds on some of the problems in the test suite on contracts that hold, together with \nthe number of axioms the generated TPTP .les comprises. Description equinox Z3 Vampire E Axioms ack CF \n- 0.04 0.03 - 40 all CF - 0.00 3.36 0.04 39 (++) CF - 0.03 3.30 0.38 31 concatMap CF - 0.03 6.60 - 40 \nlength CF 0.87 0.00 0.80 0.01 30 (+) CF 44.33 0.00 3.32 0.10 30 (*) CF 6.44 0.03 3.36 - 36 factorial \nCF 6.69 0.02 4.18 31.04 40 exp CF - 0.03 3.36 - 41 (*) accumulator CF - 0.03 3.32 - 37 exp accumulator \nCF - 0.04 4.20 0.12 42 factorial accum. CF - 0.03 3.32 - 41 reverse CF 13.40 0.03 28.77 - 36 (++)/any \nmorphism - 0.03 - - 58 filter satis.es all - 0.03 - - 47 iterate CF 5.54 0.00 0.00 0.00 30 repeat CF \n0.06 0.00 0.00 0.01 26 foldr1 - 0.01 1.04 24.78 50 head 18.62 0.00 0.00 0.01 42 fromJust 0.05 0.00 0.00 \n0.00 36 risersBy - - 1.53 - 58 shrink - 0.04 - - 79 withMany CF - 0.00 - - 39  Crash-freedom of standard \nlibrary functions, such as (++), iterate,and concatMap.  Crash-freedom of functions with more complex \nrecursive pat\u00adterns (Ackermann s function, functions with accumulators).  Partial functions given appropriate \npreconditions (foldr1, head, fromJust).  The risers example from Catch (Mitchell and Runciman 2008). \n Some non-trivial post-conditions, such as the example above with filter and all,and also anypxs||anypys \n= any p (xs ++ ys).  We tried four theorem provers, Equinox, Z3, Vampire and E, and gave them 60 seconds \nfor each problem. For our problems, Z3 seems to be the most successful. To give an idea of the sizes \nof the FOL problems, we additionally include the number of FOL axioms that are associated with each veri.cation \ntask in Figure 7. This number ranges between 26-79 but does not appear to be directly associated to the \nrunning time.  7. Discussion Contracts that do not hold In practice, programmers will often propose \ncontracts that do not hold. For example, consider the fol\u00adlowing de.nitions: length [] = Z length (x:xs) \n= S (length xs) isZero Z = True isZero _ = False Suppose that we would like to check the (false) contract: \nlength . CF .{x | isZero x}  A satis.ability-based checker will diverge trying to construct a counter \nmodel for the negation of the above query; we have con.rmed that this is indeed the behaviour of several \ntools (Z3, Equinox, E). Why? When a counter-model exists, it will include tables for the function symbols \nin the formula. Recall that func\u00adtions in FOL are total over the domain of the terms in the model. This \nmeans that function tables may be in.nite if the terms in the model are in.nite. Several (very useful!) \naxioms, such as discrimi\u00adnation (AXDIS J C), may in fact force the models to be in.nite. In our example, \nthe table for length is indeed in.nite since [] is always disjoint from Cons x xs for any x and xs.Even \nifthere is a .nitely-representable in.nite model, the theorem prover may search forever in the wrong \ncorner of the model. From a practical point of view this is unfortunate; it is not accept\u00adable for the \nchecker to loop when the programmer writes an erro\u00adneous contract. Tantalisingly, there exists a very \nsimple counterex\u00adample, e.g. [Z], and that single small example is all the program\u00admer needs to see the \nfalsity of the contract. Addressing this problem is a challenging (but essential) direc\u00adtion for future \nwork, and we are currently working on a mod\u00adi.cation of our theory that admits the denotational model, \nbut also permits .nite models corresponding to counterexample traces. If the theory can guarantee the \nexistence of a .nite model in case of a counterexample, a .nite model .nder such as Para\u00addox (Claessen \nand S \u00a8orensson 2003) will .nd it. A tighter correspondence to operational semantics? Earlier work gave \na declarative spec.cation of contracts using operational semantics (Xu et al. 2009). In this paper we \nhave instead used a denotational semantics for contracts (Figure 6). It is natural to ask whether or \nnot the two semantics are identical. From computational adequacy, Theorem 4.1 we can easily state the \nfollowing theorem: Corollary 7.1. Assume that e and C contain no term variables and assume that C{{e \n.{x | ep}}} = .. It is the case that (D8, I) |= . if and only iff either P .. e . or P .. ep[e/x] . or \nP . ep[e/x] . True. Hence, the operational and denotational semantics of predicate contracts coincide. \nHowever, the correspondence is not precise for dependent function contracts. Recall the operational de.nition \nof contract satisfaction for a function contract: e . (x:C1) . C2 iff '' '' for all e such that (e . \nC1) it is ee . C2[e /x] The denotational speci.cation (Figure 6) says that for all denota\u00adtions d ' such \nthat d ' . [[C1]], it is the case that app([[e]],d ' ) . [[C2]]x.d. . Alas there are more denotations \nthan images of terms in D8,and we can easily show that the correspondence breaks, exploiting the infamous \nparallel-or function as a test. We omit the details due to lack of space. This is not a serious problem \nin practice. After all the two de.ni\u00adtions mostly coincide, and they precisely coincide in the base case. \nAt the end of the day, we are interested in whether main . CF,and we have proven that if is crash-free \ndenotationally, it is de.nitely crash-free in any operationally-reasonable term. Finally, is it possible \nto de.ne an operational model for our FOL theory that interpreted equality as contextual equivalence? \nProba\u00adbly this could be made to work, although we believe that the formal clutter from syntactic manipulation \nof terms could be worse than the current denotational approach. Polymorphic crash-freedom Observe that \nour axiomatisation of crash-freedom in Figure 4 includes only axioms for data construc\u00adtors. In fact, \nour denotational interpretation F 8 allows more ax\u00ad cf ioms, such as: .xy.cf(x) . cf(y) . cf(app(x, y)) \nThis axiom is useful if we wish to give directly a CF contract to a value of arrow type. For instance, \ninstead of specifying that map satis.es the contract (CF . CF) . CF . CF one may want to say that it \nsatis.es the contract CF . CF . CF. With the latter contract we need the previous axiom to be able to \napply the function argument of map to a crash-free value and get a crash-free result. In some situations, \nthe following axiom might be bene.cial as well: (.x.cf(f(x))) . cf(fptr ) If the result of applying a \nfunction to any possible argument is crash-free then so is the function pointer. This allows us to go \nin the inverse direction as before, and pass a function pointer to a function that expects a CF argument. \nHowever notice that this last axiom introduces a quanti.ed assumption, which might lead to signi.cant \nef.ciency problems. Ideally we would like to say that [[CF]] = [[CF . CF]], but that is not quite true. \nIn particular, (.x.cf(app(y, x))) . cf(y) is not valid in the denotational model. For instance consider \nthe value K(Bad) for y. The left-hand side is going to always be true, because the application is ill-typed \nand will yield .,but y is not itself crash-free.  8. Related work There are very few practical tools \nfor the automatic veri.cation of arbitrary lazy and higher-order functional programs, though the automated \nveri.cation of higher-order programs, at least for restricted strongly-normalizing languages, has been \nstudied before, for instance by the ACL2 community. Furthermore, our approach of directly translating \nthe denotational semantics of programs does not appear to be well-explored in the literature. Catch (Mitchell \nand Runciman 2008) is one of the very few tools that address the veri.cation of lazy Haskell, and have \nbeen evalu\u00adated on real programs. Using static analysis, Catch can detect pat\u00adtern match failures, and \nhence prove that a program cannot crash. Some annotations may be necessary for the analysis to succeed. \nOur aim in this paper is to achieve similar goals, and moreover to be in a position to assert functional \ncorrectness. Liquid Types (Rondon et al. 2008) is an in.uential approach to call\u00adby-value functional \nprogram veri.cation. Contracts are written as re.nements in a .xed language of predicates (which may \ninclude recursive predicates) and the extracted conditions are discharged using an SMT-solver. Because \nthe language of predicates is .xed, predicate abstraction can very effectively infer precise re.nements, \neven for recursive functions, and hence the annotation burden is very low. In our case, since the language \nof predicates is, by design, the very same programming language with the same semantics, in\u00adference of \nfunction speci.cations is harder. The other important difference is that liquid types requires all uses \nof a function to sat\u00adisfy its precondition, whereas in the semantics that we have chosen, bad uses are \nallowed but the programmer gets no guarantees back. Rather different to Liquid Types, Dminor (Bierman \net al. 2010) allows re.nements to be written in the very same programming language. Contrary to our case \nhowever, in Dminor the expres\u00adsions that re.ne types must be pure that is, terminating and have a unique \ndenotation (e.g. not depending on the store). Driven from a typing relation that includes logic entailment \njudgements, veri.cation conditions are extracted and discharged automatically using Z3. Similar in spirit, \nthe Fstar (Swamy et al. 2011) com\u00adpiler also extracts veri.cation conditions that are discharged us\u00ading \nZ3 or interactive theorem provers. Hybrid type systems such as Sage (Knowles and Flanagan 2010) attempt \nto prove as many of the goals statically, and defer the rest as runtime tests.  Boogie (Barnett et al. \n2005) is a veri.cation back end that supports procedures as well as pure functions. By using Z3, Boogie \nveri.es programs written in the BoogiePL intermediate language, which could potentially be used as the \nback end of our translation as well. Recent work on performing induction on top of an induction-free \nSMT solver proposes a tactic for encoding induction schemes as .rst-order queries, which is reminiscent \nof the way that we perform induction (Leino 2012). The recent work on the Leon system (Suter et al. 2011) \npresents an approach to the veri.cation of .rst-order and call-by-value recursive functional programs, \nwhich appears to be very ef.cient in practice. It works by extending SMT with recursive programs and \ncontrol literals that guide the pattern matching search for a counter-model, and is guaranteed to .nd \na model if one exists (whereas that is not yet the case in our system, as we discussed earlier). It does \nnot include a special treatment of the . value nor pattern match failures seem to be in the scope of \nthat project, but rather partial functional correctness. The tool Zeno (Sonnex et al. 2012) veri.es equational \nproperties of functional programs. Its proof search is based on induction, equal\u00adity reasoning and operational \nsemantics. While guaranteeing ter\u00admination, it can also start new induction proofs driven by syntactic \nheuristics. However, it only considers .nite and total subsets of val\u00adues, and we want to reason about \nHaskell programs as they appear in the wild: possibly non-terminating, with lazy in.nite values, and \nrun time crashes. First-order logic has been used as a target for higher-order lan\u00adguages in other veri.cation \ncontexts as well. Users of the inter\u00adactive theorem prover Isabelle have for many years had the op\u00adportunity \nto use automated .rst-order provers to discharge proof obligations. This work has recently culminated \nin the tool Sledge\u00adhammer (Blanchette et al. 2011), which not only uses .rst-order provers, but also \nSMT solvers as back ends. There has also been a version of the dependently typed programming language \nAgda in which proof obligations could be sent to an automatic .rst-order prover (Abel et al. 2005). Both \nof these use a translation from a typed higher-order language of well-founded de.nitions to .rst\u00adorder \nlogic. A work that comes very close to ours, in that they deal with a lazy, general recursive language \nwith partial functions, is by Bove et al. (2012), who use Agda as a logical framework to reason about \ngeneral recursive functional programs, and combine interac\u00adtion in Agda with automated proofs in FOL. \nThere exists more work on translating the semantics of programs or their properties in higher-order logics \n(e.g. CIC), for instance the work on Characteristic Formulae (Chargu\u00b4eraud 2011) and the work on Hoare-logic \nVCC-based veri.cation (Rgis-Gianas and Pottier 2008). The former is interpreting a program as a higher-order \npred\u00adicate transformer whereas the latter introduces a higher-order typed Hoare-logic and extracts veri.cation \nconditions which are proved interactively in Coq or with an automated theorem prover. We aim to stay \nwithin the realm of .rst-order logic to exploit automation of\u00adfered by the advances in FOL theorem provers \nand model .nders. At the same time we do lose expressivity, as our predicate language are only plain-old \nHaskell functions. On the other hand this gives us admissibility practically for free even in the absense \nof inductive types. But even in the case of the previous work of R \u00b4egis-Gianas and Pottier, positivity \nconditions have to be imposed on datatypes to make sure that the logical speci.cation can be embedded \nin a logic built in CIC. Like Liquid types, that work enforces contract precon\u00additions in all call sites. \nFinally, in the higher-order logic world, the recent work of Huffman (Huffman 2012) can be used to translate \nHaskell programs and reason about their semantics in HOLCF; the main application being the veri.cation \nof monad transformers. The previous work on static contract checking for Haskell (Xu et al. 2009) was \nbased on wrapping. A term was effectively wrapped with an appropriately nested contract test, and symbolic \nexecu\u00adtion or aggressive inlining was used to show that BAD values could never be reached in this wrapped \nterm. In follow-up work, Xu (Xu 2012) proposes a variation, this time for a call-by-value language, which \nperforms symbolic execution along with a logicization of the program that can be used (via a theorem \nprover) to eliminate paths that can provably not generate BAD value,. The logicization of a program has \na similar spirit to our translation to logic. Fur\u00adthermore, the logicization of programs is dependent \non whether the resulting formula is going to be used as a goal or assump\u00adtion in a proof. Improving Xu \ns work, Tobin-Hochstadt and Van Horn (Tobin-Hochstadt and Horn 2012) propose a system in the same space \nof symbolic execution but they enrich the language of contracts to handle arbitrary, potentially divergent \nor crashing functions. We believe that our approach, which is to directly en\u00adcode the semantics of programs, \nmight be simpler to specify and reason about. That said, symbolic execution has the advantage of querying \na theorem prover on many small goals, instead of a single big goal. We have some ideas about how to break \nlarge satis.abil\u00adity queries to smaller ones, guided by the symbolic evaluation of functions, and we \nconsider integrating this methodology. Finally, higher-order model checking (Kobayashi 2009a,b) aims \nat verifying properties about the execution of functional programs (for instance it can also verify temporal \nproperties of programs) based on a translation of programs to higher-order recursion schemes. Higher-order \nmodel checking is an area of active research, aiming to improve the ef.ciency and applicability of the \noriginal approach.  9. Conclusions and future work Static veri.cation for functional programming languages \nseems an under-studied (compared to the imperative world) and very promising area of research. In practical \nterms, our most immediate goal is to ensure that we can .nd .nite counter-examples quickly, and present \nthem comprehensibly to the user, rather allowing the theorem prover to diverge. As mentioned in Section \n7 we have well\u00addeveloped ideas for how to do this. It would also be interesting to see if triggers in \nSMT 2.0 could also be used to support that goal. We would like to add support for primitive data types, \nsuch as Integer, using theorem provers such as T-SPASS to deal with the tff (typed .rst-order arithmetic) \npart of TPTP. Another approach might be to generate theories in the SMT 2.0 format, understood by Z3, \nwhich has support for integer arithmetic and more. Another important direction is .nding ways to split \nour big veri.cation goals into smaller ones that can be proven signi.cantly faster. Finally, we would \nlike to investigate whether we can automatically strengthen contracts to be used as induction hypotheses \nin inductive proofs, deriving information from failed attempts. Acknowledgements Thanks to the POPL 2013 \nreviewers and Richard Eisenberg for their feedback, and to Nathan Collins for early work on a prototype \nof our translation.   References Andreas Abel, Thierry Coquand, and Ulf Norell. Connecting a logical \nframework to a .rst-order logic prover. In 5th International Workshop on Frontiers of Combining Systems \n(FroCoS), LNCS. Springer Verlag, 2005. Michael Barnett, Bor-Yuh Evan Chang, Robert DeLine, Bart Jacobs, \nand K. Rustan M. Leino. Boogie: A modular reusable veri.er for object\u00adoriented programs. In Formal methods \nfor Components and Objects, pages 364 387, 2005. Nick Benton, Andrew Kennedy, and Carsten Varming. Some \ndomain the\u00adory and denotational semantics in coq. In Proceedings of the 22nd International Conference \non Theorem Proving in Higher Order Log\u00adics, TPHOLs 09, pages 115 130, Berlin, Heidelberg, 2009. Springer-Verlag. \nGavin M. Bierman, Andrew D. Gordon, C.at .alin Hrit\u00b8cu, and David Lang\u00adworthy. Semantic subtyping with \nan SMT solver. In Proceedings of the 15th ACM SIGPLAN International Conference on Functional program\u00adming, \nICFP 10, pages 105 116, New York, NY, USA, 2010. ACM. Jasmin Blanchette, Sascha B \u00a8ohme, and Lawrence \nPaulson. Extending Sledgehammer with SMT solvers. In Conference on Automated Deduc\u00adtion (CADE), LNCS. \nSpringer Verlag, 2011. Matthias Blume and David McAllester. Sound and complete models of contracts. J. \nFunct. Program., 16(4-5):375 414, July 2006. ISSN 0956\u00ad7968. Ana Bove, Peter Dybjer, and Andr \u00b4es Sicard-Ram\u00b4irez. \nCombining inter\u00adactive and automatic reasoning in .rst order theories of functional pro\u00adgrams. In Lars \nBirkedal, editor, 15th International Conference on Foun\u00addations of Software Science and Computational \nStructures, FoSSaCS 2012, volume 7213 of LNCS, pages 104 118, March 2012. Arthur Chargu \u00b4eraud. Characteristic \nformulae for the veri.cation of imper\u00adative programs. In Proceedings of the 16th ACM SIGPLAN Interna\u00adtional \nConference on Functional Programming, ICFP 11, pages 418 430, New York, NY, USA, 2011. ACM. Koen Claessen \nand Niklas S \u00a8orensson. New techniques that improve MACE\u00adstyle model .nding. In Proc. of Workshop on \nModel Computation (MODEL), 2003. Leonardo De Moura and Nikolaj Bj\u00f8rner. Z3: an ef.cient SMT solver. In \nProceedings of the Theory and Practice of Software, 14th International Conference on Tools and Algorithms \nfor the Construction and Analysis of Systems, TACAS 08/ETAPS 08, pages 337 340, Berlin, Heidelberg, 2008. \nSpringer-Verlag. Robert Bruce Findler and Matthias Felleisen. Contracts for higher-order functions. In \nProceedings of the seventh ACM SIGPLAN International Conference on Functional programming, ICFP 02, pages \n48 59, New York, NY, USA, 2002. ACM. Ralf Hinze, Johan Jeuring, and Andres L \u00a8oh. Typed contracts for \nfunctional programming. In Proceedings of the 8th International Conference on Functional and Logic Programming, \nFLOPS 06, pages 208 225, Berlin, Heidelberg, 2006. Springer-Verlag. Kry.stof Hoder, Laura Kov \u00b4acs, and \nAndrei Voronkov. Interpolation and sym\u00adbol elimination in Vampire. In Proceedings of the 5th International \nCon\u00adference on Automated Reasoning, IJCAR 10, pages 188 195, Berlin, Heidelberg, 2010. Springer-Verlag. \nBrian Huffman. Formal veri.cation of monad transformers. In Proceedings of the 17th ACM SIGPLAN International \nConference on Functional Programming, ICFP 12, pages 15 16, New York, NY, USA, 2012. ACM. Kenneth Knowles \nand Cormac Flanagan. Hybrid type checking. ACM Trans. Program. Lang. Syst., 32(2):6:1 6:34, February \n2010. ISSN 0164-0925. Naoki Kobayashi. Types and higher-order recursion schemes for veri\u00ad.cation of higher-order \nprograms. In Proceedings of the 36th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan\u00adguages, \nPOPL 09, pages 416 428, New York, NY, USA, 2009a. ACM. Naoki Kobayashi. Model-checking higher-order functions. \nIn Proceedings of the 11th ACM SIGPLAN Conference on Principles and Practice of Declarative Programming, \nPPDP 09, pages 25 36, New York, NY, USA, 2009b. ACM. K. Rustan M. Leino. Automating induction with an \nSMT solver. In Pro\u00adceedings of the 13th International Conference on Veri.cation, Model Checking, and \nAbstract Interpretation, VMCAI 12, pages 315 331, Berlin, Heidelberg, 2012. Springer-Verlag. Neil Mitchell \nand Colin Runciman. Not all patterns, but enough: an auto\u00admatic veri.er for partial but suf.cient pattern \nmatching. In Proceedings of the 1st ACM SIGPLAN Symposium on Haskell, Haskell 08, pages 49 60, New York, \nNY, USA, 2008. ACM. Ulf Norell. Towards a practical programming language based on dependent type theory. \nPhD thesis, Chalmers University of Technology, 2007. Andrew M. Pitts. Relational properties of domains. \nInf. Comput., 127(2): 66 90, 1996. Patrick M. Rondon, Ming Kawaguci, and Ranjit Jhala. Liquid types. \nIn Proceedings of the 2008 ACM SIGPLAN Conference on Programming Language Design and Implementation, \nPLDI 08, pages 159 169, New York, NY, USA, 2008. ACM. Yann Rgis-Gianas and Franois Pottier. A Hoare logic \nfor call-by-value func\u00adtional programs. In Proceedings of the Ninth International Conference on Mathematics \nof Program Construction (MPC 08), pages 305 335, July 2008. Jeremy G. Siek and Walid Taha. Gradual typing \nfor functional languages. In IN SCHEME AND FUNCTIONAL PROGRAMMING WORKSHOP, pages 81 92, 2006. William \nSonnex, Sophia Drossopoulou, and Susan Eisenbach. Zeno: an automated prover for properties of recursive \ndata structures. In Proceed\u00adings of the 18th International Conference on Tools and Algorithms for the \nConstruction and Analysis of Systems, TACAS 12, pages 407 421, Berlin, Heidelberg, 2012. Springer-Verlag. \nMartin Sulzmann, Manuel M. T. Chakravarty, Simon Peyton Jones, and Kevin Donnelly. System F with type \nequality coercions. In Proceed\u00adings of the 2007 ACM SIGPLAN International Workshop on Types in Languages \nDesign and Implementation, TLDI 07, pages 53 66, New York, NY, USA, 2007. ACM. G. Sutcliffe. The TPTP \nProblem Library and Associated Infrastructure: The FOF and CNF Parts, v3.5.0. Journal of Automated Reasoning,43 \n(4):337 362, 2009. Philippe Suter, Ali Sinan K \u00a8oksal, and Viktor Kuncak. Satis.ability modulo recursive \nprograms. In Proceedings of the 18th International Conference on Static analysis, SAS 11, pages 298 315, \nBerlin, Heidelberg, 2011. Springer-Verlag. Nikhil Swamy, Juan Chen, C \u00b4edric Fournet, Pierre-Yves Strub, \nKarthikeyan Bhargavan, and Jean Yang. Secure distributed programming with value\u00addependent types. In International \nConference on Functional Program\u00adming, pages 266 278, 2011. Sam Tobin-Hochstadt and David Van Horn. Higher-order \nsymbolic execu\u00adtion via contracts. In Proceedings of the ACM SIGPLAN Conference on Object-Oriented Programming, \nSystems, Languages, and Applications, OOPSLA 12, 2012. Philip Wadler and Robert Bruce Findler. Well-typed \nprograms can t be blamed. In Proceedings of the 18th European Symposium on Program\u00adming Languages and \nSystems, ESOP 09, pages 1 16, Berlin, Heidel\u00adberg, 2009. Springer-Verlag. Glynn Winskel. The formal semantics \nof programming languages -an introduction. Foundation of computing series. MIT Press, 1993. Hongwei Xi. \nDependent ML: an approach to practical programming with dependent types. J. Funct. Program., 17(2):215 \n286, March 2007. ISSN 0956-7968. Dana N. Xu. Hybrid contract checking via symbolic simpli.cation. In \nPro\u00adceedings of the ACM SIGPLAN 2012 Workshop on Partial Evaluation and Program Manipulation, PEPM 12, \npages 107 116, New York, NY, USA, 2012. ACM. Dana N. Xu, Simon Peyton Jones, and Koen Claessen. Static \ncon\u00adtract checking for Haskell. In Proceedings of the 36th annual ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Lan\u00adguages, POPL 09, pages 41 52, New York, NY, USA, 2009. ACM.  \n\t\t\t", "proc_id": "2429069", "abstract": "<p>Even well-typed programs can go wrong in modern functional languages, by encountering a pattern-match failure, or simply returning the wrong answer. An increasingly-popular response is to allow programmers to write contracts that express semantic properties, such as crash-freedom or some useful post-condition. We study the static verification of such contracts. Our main contribution is a novel translation to first-order logic of both Haskell programs, and contracts written in Haskell, all justified by denotational semantics. This translation enables us to prove that functions satisfy their contracts using an off-the-shelf first-order logic theorem prover.</p>", "authors": [{"name": "Dimitrios Vytiniotis", "author_profile_id": "81100156369", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P3978020", "email_address": "dimitris@microsoft.com", "orcid_id": ""}, {"name": "Simon Peyton Jones", "author_profile_id": "81100271851", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P3978021", "email_address": "simonpj@microsoft.com", "orcid_id": ""}, {"name": "Koen Claessen", "author_profile_id": "81100206977", "affiliation": "Chalmers University of Technology, Gothenburg, Sweden", "person_id": "P3978022", "email_address": "koen@chalmers.se", "orcid_id": ""}, {"name": "Dan Ros&#233;n", "author_profile_id": "81553000356", "affiliation": "Chalmers University of Technology, Gothenburg, Sweden", "person_id": "P3978023", "email_address": "danr@student.chalmers.se", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429121", "year": "2013", "article_id": "2429121", "conference": "POPL", "title": "HALO: haskell to logic through denotational semantics", "url": "http://dl.acm.org/citation.cfm?id=2429121"}