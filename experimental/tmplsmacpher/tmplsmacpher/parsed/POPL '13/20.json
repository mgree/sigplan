{"article_publication_date": "01-23-2013", "fulltext": "\n Library Abstraction for C/C++ Concurrency Mark Batty Mike Dodds Alexey Gotsman University of Cambridge \nUniversity of York IMDEA Software Institute Abstract When constructing complex concurrent systems, abstraction \nis vi\u00adtal: programmers should be able to reason about concurrent li\u00adbraries in terms of abstract speci.cations \nthat hide the implementa\u00adtion details. Relaxed memory models present substantial challenges in this respect, \nas libraries need not provide sequentially consistent abstractions: to avoid unnecessary synchronisation, \nthey may allow clients to observe relaxed memory effects, and library speci.ca\u00adtions must capture these. \nIn this paper, we propose a criterion for sound library abstrac\u00adtion in the new C11 and C++11 memory \nmodel, generalising the standard sequentially consistent notion of linearizability. We prove that our \ncriterion soundly captures all client-library interactions, both through call and return values, and \nthrough the subtle syn\u00adchronisation effects arising from the memory model. To illustrate our approach, \nwe verify implementations against speci.cations for the lock-free Treiber stack and a producer-consumer \nqueue. Ours is the .rst approach to compositional reasoning for concurrent C11/C++11 programs. Categories \nand Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; F.3.1 [Logics and \nMeanings of Programs]: Specifying and Verifying and Reasoning about Pro\u00adgrams General Terms Languages, \nTheory, Veri.cation Keywords Veri.cation, Concurrency, Modularity, C, C++ 1. Introduction Software developers \noften encapsulate functionality in libraries, and construct complex libraries from simpler ones. The \nadvantage of this is information hiding: the developer need not understand each library s implementation, \nbut only its more abstract speci.ca\u00adtion. On a sequential system, a library s internal actions cannot \nbe observed by its client, so its speci.cation can simply be a relation from initial to .nal states of \nevery library invocation. This does not suf.ce on a concurrent system, where the invocations can overlap \nand interact with each other. Hence, a concurrent library s speci\u00ad.cation is often given as just another \nlibrary, but with a simpler (e.g., atomic) implementation; the two libraries are called concrete and \nabstract, respectively. Validating a speci.cation means show\u00ading that the simpler implementation abstracts \nthe more complex Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. POPL 13, January 23 25, 2012, Rome, Italy. Copyright c &#38;#169; 2013 ACM 978-1-4503-1832-7/13/01. \n. . $10.00 one, i.e., reproduces all its client-observable behaviours. Library abstraction has to take \ninto account a variety of ways in which a client and library can interact, including values passed at \nlibrary calls and returns, the contents of shared data structures and, in this paper, the memory model. \nThe memory model of a concurrent system governs what values can be returned when the system reads from \nshared memory. In a traditional sequentially consistent (SC) system, the memory model is straightforward: \nthere is a total order over reads and writes, and each read returns the value of the most recent write \nto the location being accessed [15]. However, modern processors and programming languages provide relaxed \nmemory models, where there is no total order of memory actions, and the order of actions observed by \na thread may not agree with program order, or with that observed by other threads. In this paper, we \npropose a criterion for library abstraction on the relaxed memory model de.ned by the new ISO C11 [12] \nand C++11 [13] standards (henceforth, the C11 model ). We handle the core of the C11 memory model, leaving \nmore esoteric features, such release-consume atomics and fences, as future work (see \u00a79). The C11 model \nis designed to support common compiler optimisa\u00adtions and ef.cient compilation to architectures such \nas x86, Power, ARM and Itanium, which themselves do not guarantee SC. It gives the programmer .ne-grained \ncontrol of relaxed behaviour for indi\u00advidual reads and writes, and is de.ned by a set of axiomatic con\u00adstraints, \nrather than operationally. Both of these properties produce subtle interactions between the client and \nthe library that must be accounted for in abstraction. Our criterion is an evolution of linearizability \n[5, 7, 10, 11], a widely-used abstraction criterion for non-relaxed systems. Like linearizability, our \napproach satis.es the Abstraction Theorem: if one library (a speci.cation) abstracts another (an implementation), \nthen the behaviours of any client using the implementation are contained in the behaviours of the client \nusing the speci.cation. This result allows complex library code to be replaced by sim\u00adpler speci.cations, \nfor veri.cation or informal reasoning. Hence, it can be viewed as giving a proof technique for contextual \nre.ne\u00adment that avoids considering all possible clients. Our criterion is compositional, meaning that \na library consisting of several smaller non-interacting libraries can be abstracted by considering each \nsub\u00adlibrary separately. When restricted to the SC fragment of C11, our criterion implies classical linearizability \n(but not vice versa). The proposed criterion for library abstraction gives the .rst sound technique for \nspecifying C11 and C++11 concurrent li\u00adbraries. To justify its practicality, we have applied it two typical \nconcurrent algorithms: a non-blocking stack and an array-based queue. To do this, we have adapted the \nstandard linearization point technique to the axiomatic structure of the C11 model. These case studies \nrepresent the .rst step towards veri.ed concurrent libraries for C11 and C++11. Technical challenges. \nApart from managing the mere complex\u00adity of the C11 model, de.ning a criterion for library abstraction \nrequires us to deal with several challenges that have not been con\u00adsidered in prior work. First, the \nC11 memory model is de.ned axiomatically, whereas existing techniques for library abstraction, such as \nlinearizability, have focused on operational trace-based models. To deal with this, we propose a novel \nnotion of a history, which records all interac\u00adtions between a client and a library. Histories in our \nwork consist of several partial orders on call and return actions. This is in contrast to variants of \nlinearizability, where histories are linear sequences (for this reason, in the following we avoid the \nterm linearizability ). We de.ne an abstraction relation on histories as inclusion over par\u00adtial orders, \nand lift this relation to give our abstraction criterion for libraries: one library abstracts another \nif any history of the former can be reproduced in abstracted form by the latter. Second, C11 offers the \nprogrammer a range of options for con\u00adcurrently accessing memory, each with different trade-offs between \nconsistency and performance. These choices can subtly affect other memory accesses across the client-library \nboundary a particular choice of consistency level inside the library might force or for\u00adbid reading certain \nvalues in the client, and vice versa. This is an intended feature: it allows C11 libraries to de.ne synchronisa\u00adtion \nconstructs that offer different levels of consistency to clients. We propose a method for constructing \nhistories that captures such client-library interactions uniformly. The Abstraction Theorem cer\u00adti.es \nthat our histories indeed soundly represent all possible inter\u00adactions. Finally, some aspects of the \nC11 model con.ict with abstrac\u00adtion. Most problematically, the model permits satisfaction cycles. In \nsatisfaction cycles, the effect of actions executed down a con\u00additional branch is what causes the branch \nto be taken in the .rst place. This breaks the straightforward assumption that faults are con.ned to \neither client or library code: a misbehaving client can cause misbehaviour in a library, which can in \nturn cause the original client misbehaviour! For these reasons, we actually de.ne two dis\u00adtinct library \nabstraction criteria: one for general C11, and one for a language without the feature leading to satisfaction \ncycles. The for\u00admer requires an a priori check that the client and the library do not access each others \ninternal memory locations, which hinders com\u00adpositionality. The latter lifts this restriction (albeit \nfor a C11 model modi.ed to admit incomplete program runs) and thus provides ev\u00adidence that satisfaction \ncycles are to blame for non-compositional behaviour. Our results thus illuminate corner cases in C11 \nthat un\u00addermine abstraction, and may inform future revisions of the model. As we argue in \u00a79, many of \nthe techniques we developed to address the above challenges should be applicable to other models similar \nto C11. Structure. In the .rst part of the paper, we describe informally how algorithms can be expressed \nand speci.ed in the C11 memory model (\u00a72), and our abstraction criteria (\u00a73). We then present the model \nformally (\u00a74 and \u00a75), followed by the criteria (\u00a76) and a method for establishing their requirements \n(\u00a77). Proofs are given in an extended version of the paper [1, \u00a7C]. 2. C11 Concurrency and Library Speci.cation \nIn this section we explain the form of our speci.cations for C11 concurrent libraries, together with \na brief introduction to program\u00adming in the C11 concurrency model itself. As a running example, we use \na version of the non-blocking Treiber stack algorithm [22] implemented using the concurrency primitives \nin the subset of C11 that we consider. Figure 1a shows its speci.cation, and Figure 1b its implementation, \nwhich we have proved to correspond (\u00a77 and [1, \u00a7E]). For readability, we present examples in a pseudocode \nin\u00adstead of the actual C/C++ syntax. Several important features are highlighted in red these are explained \nbelow. SPECIFI CATION: IMPLEMENTATION: atomic Seq S; struct Node { int data; Node *next; }; atomic Node \n*T; void init() { void init() { storeREL (&#38;S,empty); storeREL (&#38;T,NULL); } } void push(int \nv) { void push(int v) { Seq s, s2; Node *x, *t; if (nondet()) while(1); x = new Node(); atom sec { \n x->data = v; s = loadRLX (&#38;S); do { s2 = append(s,v); t = loadRLX (&#38;T); CASRLX,REL(&#38;S,s,s2); \nx->next = t; } } while } (!CASRLX,REL(&#38;T,t,x)); } int pop() { int pop() { Seq s; Node *t, *x; \nif (nondet()) while(1); do { atom_sec { t = loadACQ (&#38;T); s = loadACQ (&#38;S); if (t == NULL) \nif (s == empty) return EMPTY; return EMPTY; x = t->next; CASRLX,RLX(&#38;S,s,tail(s)); } while return \nhead(s); (!CASRLX,RLX(&#38;T,t,x)); } return t->data; } } (a) (b) Figure 1. The Treiber stack. For \nsimplicity, we let pop leak mem\u00adory. The CASes in the speci.cation always succeed. Stack speci.cation. \nAs noted in \u00a71, speci.cations are just al\u00adternative library implementations that have the advantage of \nsim\u00adplicity, in exchange for inef.ciency or nondeterminism. The spec\u00adi.cation in Figure 1a represents \nthe stack as a sequence abstract data type and provides the three expected methods: init, push and pop. \nA correct stack implementation should provide the illu\u00adsion of atomicity of operations to concurrent \nthreads. We specify this by wrapping the bodies of push and pop in atomic sections, denoted by atom_sec. \nAtomic sections are not part of the stan\u00addard C11 model for speci.cation purposes, we have extended the \nlanguage with a prototype semantics for atomic section (\u00a75). Both push and pop may non-deterministically \ndiverge, as common stack implementations allow some operations to starve (in concurrency parlance, they \nare lock-free, but not wait-free). All these are the ex\u00adpected features of a speci.cation on an SC memory \nmodel. We now explain the features speci.c to C11. The sequence S holding the abstract state is declared \natomic. In C11, programs must not have data races on normal variables; any location where races can occur \nmust be explicitly identi.ed as atomic and accessed using the special commands load, store, and CAS (compare-and-swap). \nThe latter combines a load and a store into a single operation executed atomically. A CAS takes three \narguments: a memory address, an expected value and a new value. The command atomically reads the memory \naddress and, if it contains the expected value, updates it with the new one. Due to our use of atomic \nsections, the CASes in the speci.cation always succeed. We use CASes here instead of just stores, because, \nfor subtle technical reasons, the latter have a stronger semantics in C11 than our atomic sections (see \nrelease sequences in \u00a7A). The load and store commands are annotated with a memory order that determines \nthe trade-off between consistency and per\u00adformance for the memory access; CASes are annotated with two \nmemory orders, as they perform both a load and a store. The choice of memory orders inside a library \nmethod can indirectly affect its clients, and thus, a library speci.cation must include them. In the \nstack speci.cation, several memory operations have the release\u00adacquire memory orders, denoted by the \nsubscripts REL (for stores) and ACQ (for loads). To explain its effect, consider the following client \nusing the stack according to a typical message-passing idiom: int a, b, x=0; do { x=1; a = pop(); push(&#38;x); \n} while (a==EMPTY); b=*a; The .rst thread writes 1 into x and calls push(&#38;x); the second thread \npops the address of x from the stack and then reads its con\u00adtents. In general, a relaxed memory model \nmay allow the second thread to read 0 instead of 1, e.g., because the compiler reorders x=1 and push(&#38;x). \nThe release-acquire annotations guarantee that this is not the case: when the ACQ load of S in pop reads \nthe value written by the REL store to S in push, the two commands synchro\u00adnise. We de.ne this notion \nmore precisely later, but informally, it means that the ordering between the REL store and ACQ load con\u00adstrains \nthe values fetched by reads from other locations, such as the read *a in the client. To enable this message-passing \nidiom, the speci.cation only needs to synchronise from pushes to pops; it need not synchro\u00adnise from \npops to pushes, or from pops to pops. To avoid unnec\u00adessary synchronisation, the speci.cation uses the \nrelaxed memory order (RLX). This order is weaker than release-acquire, meaning that the set of values \na relaxed load can read from memory is less constrained; additionally, relaxed loads and stores do not \nsynchro\u00adnise with each other. However, relaxed operations are very cheap, since they compile to basic \nloads and stores without any additional hardware barrier instructions. Hence, the speci.cation allows \nim\u00adplementations that are ef.cient, yet support the intended use of the stack for message passing. On \nthe other hand, as we show below, it intentionally allows non-SC stack behaviours. Stack implementation. \nFigure 1b gives our implementation of the Treiber stack. The stack is represented by a heap-allocated \nlinked list of nodes, accessed through a top-of-stack pointer T. Only the latter needs to be atomic, \nas it is the only point of contention among threads. The push function repeatedly reads from the top \npointer T, initialises a newly created node x to point to the value read, and tries to swing T to point \nto x using a CAS; pop is implemented similarly. For simplicity, we let pop leak memory. Like the speci.cation, \nthe implementation avoids unnecessary hardware synchronisation by using the relaxed memory order RLX. \nHowever, the load of T in pop is annotated ACQ, since the com\u00admand x = t->next accesses memory based \non the value read, and hence, requires it to be up to date. What does it mean for the implementation \nin Figure 1b to meet the speci.cation in Figure 1a? As well as returning the right values, it must also \nfaithfully implement the correct synchronisation. To understand how this can be formalised, we must therefore \nexplain how synchronisation works in C11 s semantics. C11 model structure. The C11 memory model is de.ned \nax\u00adiomatically. An execution of a program consists of a set of actions and several partial orders on \nit. An action describes a memory op\u00aderation, including the information about the thread that performed \nit, the address accessed and the values written and/or read. The se\u00admantics of a program is given by \nthe set of executions consistent with the program code and satisfying the axioms of the memory model \n(see Figure 4 for a .avour of these). Here is a program with one of its executions, whose outcome we \nexplain below: STORE BUFF ERING (SB): store(&#38;x,0) store(&#38;y,0) RLXRLX storeRLX(&#38;x,0); storeRLX(&#38;y,0) \nstore (&#38;x,1) store(&#38;y,1)RLXRLX storeRLX(&#38;x,1) storeRLX(&#38;y,1) sb rf rf sb loadRLX(&#38;y) \nloadRLX(&#38;x) load(&#38;y,0) load(&#38;x,0) RLXRLX Note that, in diagrams representing executions, \nwe omit thread identi.ers from actions. Several of the most important relations in an execution are: \n sequenced-before (sb), a transitive and irre.exive relation order\u00ading actions by the same thread according \nto their program order.  initialised-before (ib), ordering initial writes to memory loca\u00adtions before \nall other actions in the execution1. Above we have shown ib by a dotted line dividing the two kinds of \nactions.  reads-from (rf), relating reads r to the writes w from which they  rf take their values: \nw -. r. happens-before (hb), showing the precedence of actions in the execution. In the fragment of C11 \nthat we consider, it is transitive and irre.exive. Happens-before is the key relation, and is the closest \nthe C11 model has to the notion of a global time in an SC model: a read must not read any write to the \nsame location related to it in hb other than its immediate predecessor. Thus, for writes w1 and w2 and \na read r accessing the same location, the following shapes are forbidden: hb hb hb . w1 w2 r r w1 (RD) \n rfrf However, in contrast to an SC model, hb is partial in C11, and some rf reads can read from hb-unrelated \nwrites: we might have w -. r, hb but not w -. r. Memory orders. By default, memory reads and writes in \nC11 are non-atomic (NA). The memory model guarantees that data\u00adrace free programs with only non-atomic \nmemory accesses have SC behaviour. A data race occurs when two actions on the same memory location, at \nleast one of which is a write, and at least one of which is a non-atomic access, are unrelated in happens-before, \nand thus, intuitively, can take place at the same time . Hence, non\u00adexpert programmers who write code \nthat is free from both data races and atomic accesses need not understand the details of the relaxed \nmemory model. Data races are considered faults, resulting in unde.ned behaviour for the whole program. \nThe three main atomic memory orders, from least to most re\u00adstrictive, are relaxed, release-acquire and \nsequentially consistent2 . We have already seen the .rst two in the stack example above. The third, sequentially \nconsistent (SC), does not allow relaxed behaviour: if all actions in a race-free program are either non\u00adatomic \nor SC, the program exhibits only sequentially-consistent be\u00adhaviour [2, 4]. However, the SC memory order \nis more expensive. The weakest memory order, relaxed, exhibits a number of relax\u00adations, as the C11 model \nplaces very few restrictions on which write a relaxed read might read from. For example, consider the \n(SB) 1This is a specialisation of the additional-synchronises-with relation from the C11 model [2] to \nprograms without dynamic thread creation, to which we restrict ourselves in this paper (see \u00a74). 2Release-consume \natomics and fences [2] are left for future work (see \u00a79). We also omit some C11 subtleties that are orthogonal \nto abstraction (see \u00a74). example above. The outcome shown there is allowed by C11, but cannot be produced \nby any interleaving of the threads actions. C11 disallows it if all memory accesses are annotated as \nSC. The release-acquire memory orders allow more relaxed be\u00adhaviour than SC, while still providing some \nguarantees. Consider the following execution of the client of the stack in Figure 1a or 1b we have seen \nabove: MESSAGE PASSING (MP): store(&#38;x,0) NA ib int a, b, x=0; storeNA(&#38;x,1) sb x=1; do {a=pop();} \n call push( &#38;x) rf,hb load ACQ(&#38;S,j) push(&#38;x); while sb sb (a==EMPTY); rmw(&#38;S,i,j) \nret pop(&#38;x) RLX,REL sb rf b=*a; load(&#38;x,1) NA Here rmw (read-modify-write) is a combined load-store \naction produced by a CAS. In this case, the ACQ load in pop synchronises with the REL store part of the \nCAS in push that it reads from. This informal notion of synchronisation we mentioned above is formalised \nin the memory model by including the corresponding rf edge into hb. Then, since sb .ib . hb and hb is \ntransitive, both writes to x happen before the read. Hence, by (RD), the read from x by the second thread \nis forced to read from the most recent write, i.e., 1. If all the memory order annotations in the Treiber \nstack were re\u00adlaxed, the second thread could read 0 from x instead. Furthermore, without release-acquire \nsynchronisation, there would be a data race between the non-atomic write of x in the .rst thread and \nthe non\u00adatomic read of x in the second. The release-acquire memory orders only synchronise between pairs \nof reads and writes, but do not impose a total order over mem\u00adory accesses, and therefore allow non-SC \nbehaviour. For example, if we annotate writes in (SB) with REL, and reads with ACQ, then the outcome \nshown there will still be allowed: each load can read from the initialisation without generating a cycle \nin hb or violat\u00ading (RD). We can also get this outcome if we use push and pop operations on two instances \nof the stack from Figure 1a or 1b in\u00adstead of load and store. Thus, both the implementation and the speci.cation \nof the stack allow it to have non-SC behaviour. To summarise, very roughly, release-acquire allows writes \nto be delayed but not reordered, while relaxed allows both. Relaxed actions produce even stranger behaviour, \nincluding what we call satisfaction cycles: SATISFACTION CYCLE (SCL): load(&#38;x,8) load(&#38;y,8) a=loadRLX(&#38;x) \nb=loadRLX(&#38;y) RLX RLX sb rf rf if (a==8) if (b==8) sb store(&#38;y,8) store(&#38;x,8) storeRLX(&#38;y,a) \nstoreRLX(&#38;x,8) RLXRLX Here, each conditional satis.es its guard from a later write in the other thread. \nThis is possible because relaxed reads and writes do not create any happens-before ordering, and thus \nneither read is constrained by (RD). Unlike relaxed, release-acquire does not allow satisfaction cycles. \nIf the loads and stores in the example were annotated release-acquire, then both rf edges would also \nbe hb edges. This would produce an hb cycle, which is prohibited by the memory model. Satisfaction cycles \nare known to be a problematic aspect of the C11 model; as we show in this paper, they also create dif.culties \nfor library abstraction. 3. Library Abstraction Informally Histories. Our approach to abstraction is \nbased on the notion of a history, which concisely records all interactions between the client and the \nlibrary in a given execution. Clients and libraries can affect one another in several ways in C11. Most \nstraightforwardly, the library can observe the parameters passed by the client at calls, and the client \ncan observe the library s return values. Therefore, a history includes the set of all call and return \nactions in the execution. However, clients can also observe synchronisation and other memory-model effects \ninside a method. These more subtle interactions are recorded by two kinds of partial order: guarantees \nand denies. Synchronisation internal to the library can affect the client by forcing reads to read from \nparticular writes. For example, in (MP) from \u00a72, the client is forced to read 1 from x because the push \nand pop methods synchronise internally in a way that generates an hb ordering between the call to push \nand the return from pop. If the methods did not hb-synchronise, the client could read from either of \nthe writes to x. The client can thus observe the difference be\u00adtween two library implementations with \ndifferent internal synchro\u00adnisation, even if all call and return values are identical. To account for \nthis, the guarantee relation in a history of an execution records hb edges between library call and return \nactions. Even non-synchronising behaviour inside the library can some\u00adtimes be observed by the client. \nFor example, the C11 model re\u00adquires the existence of a total order mo over all atomic writes to a given \nlocation. This order cannot go against hb, but is not included into it, as this would make the model \nmuch stronger, and would hinder ef.cient compilation onto very weak architectures, such as Power and \nARM [21]. Now, consider the following: DENY (DN): rf,hb (forbidden!) load ACQ(&#38;x,0) sb storeREL(&#38;x,1); \ncall lib() mo lib(); library loadACQ(&#38;x); library lib(); storeREL(&#38;x,0); ret lib() sb store(&#38;x,0) \nREL In this execution, a write internal to the invocation of lib in the second thread is mo-ordered after \na write internal to the invocation of lib in the .rst thread. This forbids the client from reading 0 \nfrom x. To see this, suppose the contrary holds. Then the ACQ load synchronises with the REL store of \n0, yielding an hb edge. By transitivity with the client sb edges, which are included in hb, we get an \nhb edge from ret lib in the second thread to call lib in the .rst. Together with the library s sb edges, \nthis yields an hb edge going against the library-internal mo one, which is prohibited by the memory model. \nTo account for such interactions, the deny relations in a history of an execution record hb or other \nkinds of edges between return and call actions that the client cannot enforce due to the structure of \nthe library, e.g., the hb-edge from ret lib to call lib above. Abstraction in the presence of relaxed \natomics. As we noted in \u00a71, we actually propose two library abstraction criteria: one for the full memory \nmodel described in \u00a72, and one for programs without relaxed atomics. We discuss the former .rst. Two \nlibrary executions with the same history are observation\u00adally equivalent to clients, even if the executions \nare produced by different library implementations. By de.ning a sound abstraction relation over histories, \nwe can therefore establish abstraction be\u00adtween libraries. To this end, we need to compare the histories \nof libraries under every client context. Fortunately, we need not ex\u00adamine every possible client: it \nsuf.ces to consider behaviour un\u00adder a most general client, whose threads repeatedly invoke library methods \nin any order and with any parameters. Executions under this client generate all possible histories of \nthe library, and thus represent all client-library interactions (with an important caveat, discussed \nbelow). We write [L]I for the set of executions of the library Lunder the most general client starting \nfrom an initial state I. Initial states are de.ned formally in \u00a74, but, informally, record initialisation \nactions such as the ones shown in (SB). The set [L]I gives the denotation of the library considered in \nisolation from its clients, and in this sense, de.nes a library-local semantics of L. This library-local \nsemantics allows us to de.ne library abstrac\u00adtion. We now quote its de.nition and formulate the correspond\u00ading \nAbstraction Theorem, introducing some of the concepts used in them only informally. This lets us highlight \ntheir most important features that can be discussed independently of the formalities. We .ll in the missing \ndetails in \u00a76.1, after we have presented the C11 model more fully. For the memory model with relaxed \natomics, a history contains one guarantee and one deny relation. DEFI NITION 1. Ahistory is a triple \nH = (A, G, D), where Ais a set of call and return actions, and G, D . A\u00d7 A. Library abstraction is de.ned \non pairs of libraries Land sets of their initial states I. It relies on a function history(\u00b7) extracting \nthe history from a given execution of a library, which we lift to sets of executions pointwise. The notation \n[L, R] and the notion of safety are explained below. DEFI NITION 2. For histories (A1, G1, D1) and (A2, \nG2, D2), we let (A1, G1, D1) . (A2, G2, D2) if A1 = A2, G1 = G2 and D2 . D1. For safe (L1 ,I1) and (L2 \n,I2), (L1,I1) is abstracted by (L2,I2), written (L1 ,I1) . (L2,I2), if for any relation R con\u00adtaining \nonly edges from return actions to call actions, we have .I1 . I1, H1 . history([L1, R]I1). .I2 . I2, \nH2 . history([L2, R]I2). H1 . H2. The overall shape of the de.nition is similar to that of linearizabil\u00adity \non SC memory models [11]: any behaviour of the concrete li\u00adbrary L1 relevant to the client has to be \nreproducible by the abstract library L2. However, there are several things to note. First, we allow the \nexecution of the abstract library to deny less than the concrete one, but require it to provide the same \nguarantee. Intuitively, we can strengthen the deny, because this only allows more client behaviours. \nSecond, we do not consider raw executions of the most general client of L1 and L2, but those whose happens-before \nrelation can be extended with an arbitrary set R of edges between return and call actions without contradicting \nthe axioms of the memory model; [L1, R]I1 and [L2, R]I2 denote the sets of all such extensions. The set \nRrepresents the happens-before edges that can be enforced by the client: such happens-before edges are \nnot generated by the most general client and, in the presence of relaxed atomics, have to be considered \nexplicitly (this is the caveat to its generality referred to above). We consider only return-to-call \nedges, as these are the ones that represent synchronisation inside the client (similarly to how call-to-return \nedges in the guarantee represent synchronisation inside the library; cf. (MP)). The de.nition requires \nthat, if an extension of the concrete library is consistent with R, then so must be the matching execution \nof the abstract one. Finally, the abstraction relation is de.ned only between safe libraries that do \nnot access locations internal to the client and do not have faults, such as data races. As we show in \n\u00a77, the speci.cation of the Treiber stack in Figure 1a abstracts its implementation in Figure 1b. Abstraction \ntheorem. We now formulate a theorem that states the correctness of our library abstraction criterion. \nWe consider programs C(L) with a single client C and a library L (the case of multiple libraries is considered \nin \u00a76.1). The Abstraction Theorem states that, if we replace the (implementation) library L1 in a program \nC(L1) with another (speci.cation) library L2 abstracting L1, then the set of client behaviours can only \nincrease. Hence, when reasoning about C(L1), we can soundly replace L1 with L2 to simplify reasoning. \nIn the theorem, [C(L)]I gives the set of executions of C(L) from initial states in a set I, .combines \nthe initial states of a client and a library, and client(\u00b7) selects the parts of executions generated \nby client commands. We call (C(L),I) non-interfering, if Cand L do not access each others internal memory \nlocations in executions of C(L) from initial states in I. The notion of safety for C(L) is analogous \nto the one for libraries. THEOREM 3 (Abstraction) . Assume that (L1,I1 ), (L2,I2), (C(L2),I . I2) are \nsafe, (C(L1),I . I1) is non-interfering and (L1,I1) . (L2 ,I2). Then (C(L1 ),I . I1) is safe and client([C(L1)](I \n. I1)) . client([C(L2)](I . I2)). The requirement of non-interference is crucial, because it en\u00adsures \nthat clients can only observe library behaviour through return values and memory-model effects, rather \nthan by opening the box and observing internal states. The drawback of Theorem 3 is that it requires \nus to establish the non-interference between the client C and the concrete library L1, e.g., via a type \nsystem or a program logic proof. As we show below, we cannot weaken this condition to allow checking \nnon-interference on the client C using the ab\u00adstract library L2, as is standard in data re.nement on \nSC mem\u00adory models [8]. This makes the reasoning principle given by the theorem less compositional, since \nestablishing non-interference re\u00adquires considering the composed behaviour of the client and the concrete \nlibrary precisely what library abstraction is intended to avoid! However, this does not kill compositional \nreasoning com\u00adpletely, as non-interference is often simple to check even globally. We can also soundly \ncheck other aspects of safety, such as data-race freedom, on C(L2). Furthermore, as we show in \u00a76.1, \nthe notion of library abstraction given by De.nition 2 is compositional for non\u00adinterfering libraries. \nAs we now explain, we can get the desired theorem allowing us to check non-interference on C(L2) for \nthe fragment of the language excluding relaxed atomics. Abstraction without relaxed atomics. Restricting \nourselves to programs without the relaxed memory order (and augmenting the axiomatic memory model to \nallow incomplete program runs, as described in \u00a74) allows strengthening our result in three ways: 1. \nWe no longer need to quantify over client happens-before edges R, like in De.nition 2. Instead, we enrich \nhistories with an addi\u00adtional deny relation, which is easier to deal with in practice than the quanti.cation. \nHence, without relaxed atomics, the caveat to the generality of the most general client does not apply. \n 2. Abstraction on histories can be de.ned by inclusion on guaran\u00adtees, rather than by equality. 3. \nWe no longer need to show that the unabstracted program C(L1) is non-interfering. Rather, non-interference \nis a consequence of the safety of the abstracted program C(L2).  The .rst two differences make proofs \nof library abstraction slightly easier, but are largely incidental otherwise. In particular, quanti.cation \nover client happens-before edges in De.nition 2, al\u00adthough unpleasant, does not make library abstraction \nproofs dras\u00adtically more complicated. Requiring the guarantees of the concrete and abstract executions \nto be equal in this de.nition just results in more verbose speci.cations in certain cases. In contrast, \nthe last difference is substantial. The price of satisfaction cycles. For each of the three above dif\u00adferences \nwe have a counterexample showing that Theorem 3 will not hold if we change the corresponding condition \nto the one re\u00adquired in the case without relaxed atomics. All of these counterex\u00adamples involve satisfaction \ncycles, which can only be produced by relaxed atomics. Our results show that this language feature makes \nthe reasoning principles for C11 programs less compositional. Due to space constraints, here we present \nonly the counterexample for point 3 above; the others are given in [1, \u00a7D]. In \u00a76.3, we identify the \ncorresponding place in the proof of the Abstraction Theorem for the language without relaxed atomics \nwhere we rely on the absence of satisfaction cycles. Consider the following pair of libraries L1 and \nL2: L1 : atomic int x; L2: atomic int x; int m() { int m() { storeRLX (&#38;x,42); return 42; return \nloadRLX (&#38;x); } } Here x is a library-internal location. We have L1 . L2, since both method implementations \nbehave exactly the same, assuming that the internal location x is not modi.ed outside the library. Unsafe \nclients can distinguish between L1 and L2. For example, the client print m(); . storeRLX (&#38;x,0); \ncan print 0 when using L1 , but not L2. However, any non-trivial library behaves erratically when clients \ncorrupt its private data structures, and thus, it is reasonable for abstraction to take into account \nonly well-behaved clients that do not do this. We therefore contend that L1 should be abstracted by L2 \naccording to any sensible abstraction criterion. The above misbehaved client violates non-interference \nwhen using either L1 or L2. However, we can de.ne a more complicated client C such that C(L2 ) is non-interfering, \nbut C(L1) is not: call m() sb store(&#38;x,42) a=m() b=loadRLX(&#38;y) RLXif (a==0) if (b==0) sb load(&#38;x,0) \nload(&#38;y,0) storeRLX(&#38;y,0) storeRLX(&#38;x,0) RLX RLXsb rf rf  sb ret m(0) sb store(&#38;y,0) \nstore(&#38;x,0) RLXRLX The execution of C(L1 ) given on the right violates non-interference due to a \nsatisfaction cycle: a fault in the client causes the library to misbehave by returning 0 instead of 42, \nand the effect of this mis\u00adbehaviour is what causes the client fault in the .rst place! Since the abstract \nlibrary L2 is completely resilient to client interference, its method will always return 42, and thus, \nthe satisfaction cycle will not appear and the client will not access the variable x. Note that this \ncounterexample is not speci.c to our notion of library abstrac\u00adtion: any such notion for C11 considering \nL2 to be a speci.cation for L1 cannot allow checking non-interference using L2 . For expository reasons, \nwe have given a very simple counterex\u00adample. This program would be easy to detect and eliminate, e.g., \nusing a simple type system: one syntactic path in the client is guar\u00adanteed to result in the forbidden \naccess to the library s internal state. However, the same kind of behaviour can occur with dynamically\u00adcomputed \naddresses: the client stepping out of bounds of an array overwrites the library state, causing it to \nmisbehave, which in turn causes the original client misbehaviour. For this kind of example, proving non-interference \nbecomes non-trivial. It is unclear to us whether satisfaction cycles are observable in practice. They \nare disallowed by even the weakest C11 target ar\u00adchitectures, such as Power and ARM [21], because these \narchitec\u00adtures respect read-to-write dependencies created by control-.ow. It is also clear that the C11 \nlanguage designers would like to for\u00adbid satisfaction cycles: the C++11 standard [12, Section 29.3, Para\u00adgraph \n11] states that, although (SCL) from \u00a72 is permitted, imple\u00admentations should not allow such behaviour \n. This apparent contra\u00addiction is because certain compiler optimisations, such as common subexpression \nelimination and hoisting from loops, can potentially create satisfaction cycles (see [16] for discussion). \nSince avoiding them would require compilers to perform additional analysis and/or limit optimisations, \nthe standard does not disallow satisfaction cy\u00adcles outright. Our results provide an extra argument that \nallowing satisfaction cycles is undesirable. 4. C11: Language and Thread-Local Semantics To de.ne the \nC11 model, we use a lightly modi.ed version of its formalisation proposed by Batty et al. [2]. In the \ninterests of simplicity, we consider a simple core language, instead of the full C/C++, and omit some \nof the features of the memory model. We do not handle two categories of features: those that are orthogonal \nto abstraction, and more esoteric features that would complicate our results. In the .rst category we \nhave dynamic memory allocation, dynamic thread creation, blocked CASes and non-atomic initial\u00adisation \nof atomic locations (we also do not present the treatment of locks here, although we handle a bounded \nnumber of them in our formal development; see \u00a7A). In the second category we have memory fences and release-consume \natomics, discussed in \u00a79. The semantics of a C11 program is given by a set of executions, generated in \ntwo stages. The .rst stage, described in this section, generates a set of action structures using a sequential \nthread-local semantics which takes into account only the structure of every thread s statements, not \nthe semantics of memory operations. In particular, the values of reads are chosen arbitrarily, without \nregard for writes that have taken place. The second stage, described in \u00a75, .lters out the action structures \nthat are inconsistent with the C11 memory model. It does this by constructing additional relations and \nchecking the resulting executions against the axioms of the model. Programming language. We assume that \nthe memory consists of locations from Loc containing values in Val. We assume a function sort : Loc . \n{ATOM,NA}, showing whether memory accesses to a given location must be atomic (ATOM)or non-atomic (NA); \nsee \u00a72. The program syntax is as follows: C ::= skip |c |m |C; C |if(x) {C}else {C} | while(x) {C} | \natom sec {c} L ::= {m = Cm |m . M} C(L) ::= let Lin C1 . . . . . Cn A program consists of a library L \nimplementing methods m . Method and its client C, given by a parallel composition of threads C1,. . . \n, Cn. The commands include skip, an arbitrary set of base commands c . BComm (e.g., atomic and non-atomic \nloads and stores, and CASes), method calls m . Method, sequential compo\u00adsition, branching on the value \nof a location x . Loc and loops. Our language also includes atomic sections, ensuring that a base com\u00admand \nexecutes atomically. Atomic sections are not part of C/C++, but are used here to express library speci.cations. \nWe assume that every method called by the client is de.ned in the library, and we disallow nested method \ncalls. We assume that every method accepts a single parameter and returns a single value. Parameters \nand return values are passed by every thread via distinguished locations in memory, denoted paramt,retvalt \n. Loc for t = 1..n, such that sort(paramt) = sort(retvalt) = NA. The rest of memory locations are partitioned \ninto those owned by the client (CLoc) and the library (LLoc): Loc = CLoc .LLoc . {paramt,retvalt |t = \n1..n}. The property of non-interference introduced in \u00a73 then requires that a library or a client access \nonly the memory locations belonging to them (except the ones used for passing parameters and return \nvalues). We provide pointers on how we can relax the requirement of static address space partitioning \nin \u00a79. Actions. Executions are composed of actions, de.ned as follows: ., \u00b5 . MemOrd ::= NA |SC |ACQ \n|REL |RLX . . E.ect ::= store.(x, a) |load.(x, a) |rmw.,\u00b5(x, a, b) |call m(a) |ret m(a) u, v, w, q, r \n. Act ::= (e, g, t, .) Here e . AId is a unique action identi.er, and ., \u00b5 are memory orders (\u00a72) of \nmemory accesses. Every instance of an atomic sec\u00adtion occurring in an execution has a unique identi.er \ng . SectId. Atomic sections only have force when multiple actions have the same section identi.er, so \nactions outside any section are simply assigned a unique identi.er each. The domains of the rest of the \nvariables are as follows: t . {0,. . . , n}, x . Loc, a, b . Val. We allow actions by a dummy thread \n0 to denote memory initialisation. We only consider actions whose memory orders respect location sorts \ngiven by sort, and we do not allow rmw actions of sort NA. Loading or storing a value a at a location \nx generates the ob\u00advious action. A read-modify-write action (e, g, t, rmw.,\u00b5(x, a, b)) arises from a \nsuccessful compare-and-swap command. It corre\u00adsponds to reading the value a from the location x and atomically \noverwriting it with the value b;. and \u00b5give the memory orders of the read and the write, respectively, \nand have to be different from NA. The value a in (e, g, t, call m(a)) or (e, g, t, ret m(a)) records \nthe parameter paramt or the return value retvalt passed between the library method and its client. We \nrefer to call and return actions as interface actions. For an action u we write sec(u) for its atomic \nsection identi.er, and we denote the set of all countable sets of actions by P(Act). We omit e, g and \n. annotations from actions when they are irrelevant. We also write for an expression whose value is irrelevant. \nWe use (t, read.(x, a)) to mean any of the following: (t, load.(x, a)); (t, rmw., (x, a, )); (t, call \n(a)), if x = paramt and . = NA; (t, ret (a)), if x = retvalt and . = NA. We use (t, write.(x, a)) to \nmean (t, store.(x, a)) or (t, rmw ,.(x, , a)). We call the two classes of actions read actions and write \nactions, respectively. Thread-local semantics. The thread-local semantics generates a set of action structures \ntriples (A, sb,ib), where A . P(Act), and sb,ib . A \u00d7 A are the sequenced-before and initialised\u00adbefore \nrelations introduced in \u00a72. We assume that sb is transitive and irre.exive and relates actions by the \nsame thread; ib relates initialisation actions with thread identi.er 0 to the others. We do not require \nsb to be a total order: in C/C++, the order of executing certain program constructs is unspeci.ed. For \na base command c . BComm, we assume a set (c)t . P(P(A) \u00d7 P(A\u00d7 A)) of all pairs of action sets and sb \nrelations that c produces when executed by a thread t (the ib relations are missing, as they are relevant \nonly for a whole program). Note that base commands may include conditionals and loops, and thus can give \nrise to an arbitrary number of actions; we give a separate explicit semantics to conditionals and loops \nonly because they are used in the most general client in \u00a76.1. De.nitions of (c)t for sample base commands \nc are given in Figure 2. Note that, in the thread-local semantics, a read from memory, such as load\u00b5(y) \nin the .gure, yields an arbitrary value. A CAS command generates an rmw action, if successful, and a \nload, otherwise. We de.ne an initial state of a program C(L) by a function I . (LLoc .CLoc) ..n (Val \n\u00d7 MemOrd), giving the initial values of memory locations, together with the memory orders of initial \nwrites to them. We de.ne the set of action structures (C(L))I of a program C(L) in Figure 3. Note that \nthis set of action structures corresponds to complete runs of C(L). The clause for atom sec {c}assigns \nthe same atomic section identi.er to all actions generated by c. The clause for a call to a method m \nbrackets structures generated by its implementation Cm with call and return actions. We have omitted \nthe clause for loops [1, \u00a7B]. For simplicity, we assume that the variable in the condition of a branch \nis always non-atomic. Assumptions. We make several straightforward assumptions about the structures in \n(c)t for c . BComm: Structures in (c)t are .nite and contain only load, store and read\u00admodify-write \nactions by t with unique action identi.ers.  For any (A, sb) . (c)t, sb is transitive and irre.exive. \n Structures in (c)t are insensitive to the choice of action and atomic section identi.ers: applying \nany bijection to such iden\u00adti.ers from a structure in (c)t produces another structure in (c)t.  Atomic \nsections in every (A, sb) . (c)t are contiguous in sb:  sbsb .u, v, q. sec(u) = sec(v) .u -. q -. v \n=. sec(q) = sec(u). So as not to obfuscate presentation, we only consider programs C(L) that use paramt \nand retvalt correctly. We assume that in any action structure of a program, only library actions by tread \nparamt and write to retvalt, and only client actions by t read retvalt and write to paramt. We also require \nthat paramt and retvalt be initialised before an access: in any structure (A, sb,ib) of C(L), sb (.u \n= (t, call ) . A. .w = (t, write(paramt, )). w -. u) . sb (.u = (t, ret ) . A. .w = (t, write(retvalt, \n)). w -. u). Additional assumptions without relaxed atomics. For our re\u00adsult without relaxed atomics \n(\u00a76.2), we currently require the fol\u00adlowing additional assumptions: The structure set (c)t accounts \nfor c fetching any values from the memory locations it reads (see [1, \u00a7B] for formalisation).  Any structure \nof a base command c inside an atomic section accesses at most one atomic location. This is suf.cient \nfor our purposes, since a library speci.cation usually accesses a single such location containing the \nabstract state of the library.  We modify the standard C11 model by requiring that a program s semantics \ninclude structures corresponding to execution pre.xes. In the standard C11 model, all executions are \ncomplete (although possibly in.nite). We de.ne (Ci)p t for a thread Ci by  (Ci)p t = {(Ap,sbp) | .(A, \nsb) . (Ci)t. sb Ap . A. .u . A, v . Ap. u -. v =. u . Ap}. This is necessary due to the interaction between \nour prototype atomic section semantics and the C11 model. It weakens the no\u00adtion of atomicity: atomic \nsections at the end of a pre.x may be partially executed, and therefore more weakly ordered than their \ncompleted counterparts. Eliminating it will require a deeper un\u00adderstanding of the relationship between \natomicity and the notion of incomplete program runs. See \u00a76.3 for its use in the proof. 5. C11: Axiomatic \nMemory Model The axiomatic portion of the C11 model takes a set of action struc\u00adtures of the program, \ngenerated by the thread-local semantics in \u00a74, and .lters out those which are inconsistent with the memory \nmodel. To formulate it, we enrich action structures with extra relations. Executions. The semantics \nof a program consists of a set of ex\u00adecutions, X = (A, sb,ib,rf,sc,mo,sw,hb), where A . P(Act) and the \nrest are relations on A: sb, ib, rf and hb introduced in \u00a74; rf is such that its reverse is a partial \nfunction from read to write actions on the same location and with the same value.  sequentially consistent \norder (sc), ordering SC reads from and writes to the same location. The projection of sc to each atomic \nlocation is a transitive, irre.exive total order, while writes to distinct locations are unrelated3 . \n modi.cation order (mo), ordering writes (but not reads!) to the same atomic (i.e., of the sort ATOM) \nlocation. The projection of mo to each atomic location is a transitive, irre.exive total order.  synchronises-with \n(sw), de.ning synchronisation.  We write r(X) for the component r of the execution X. We can now de.ne \nthe denotation [C(L)] of a program and the notion of safety and non-interference introduced informally \nin \u00a73. An execution X is valid, if it satis.es the validity axioms shown in Figure 4; it is safe, if \nit satis.es the safety axioms in Figure 5, and it is non-interfering if it satis.es the N ONINTERF axiom \nfrom Figure 5. We explain the axioms shown in the rest of this section. Intuitively, validity axioms \ncorrespond to properties that are enforced by the runtime, while safety axioms correspond to properties \nthat the programmer must ensure to avoid faults. To simplify the following explanations, Figures 4 and \n5 do not show axioms dealing with CASes and locks. To keep the presentation tractable, we have also omitted \nsome corner cases from SW DEF and SCR EADS in Figure 4. The missing axioms and cases are given in \u00a7A, \nand our results are established for the memory model including these (the correctness of the stack in \nFigure 1 actually relies on a corner case in SW DEF). For a program C(L) and an initial state I, we let \n[C(L)]I be the set of valid executions X, whether safe or not, such (A, sb(X),ib(X)) . (C(L))I. We write \n[C(L)]I to stand for its obvious lifting to sets I of initial states. A program C(L) is safe when run \nfrom I if every one of its valid executions is (and similarly for non-interference and sets of initial \nstates). An unsafe program has unde.ned behaviour. The validity axioms de.ne sw and hb directly in terms \nof the other relations (SWDEF and HBDEF). The hb relation is con\u00adstructed from the sb, ib and sw, and \nas follows from ACYCLIC-ITY, has to be irre.exive. The /~operator in the de.nition of hb is needed to \nhandle atomic sections; for now the reader should ignore it. The sw relation is derived from sc and rf. \nThe rf, sc and mo re\u00adlations are only constrained by the axioms, not de.ned directly. We explain the \nvalidity axioms by .rst considering a language frag\u00adment with non-atomic memory accesses only and then \ngradually expanding it to include the other memory orders. Non-atomic memory accesses. The values read \nby non\u00adatomic reads are constrained by D ETREAD and RFN ONATOMIC. DETREAD requires every read to have \nan associated rf edge when the location read was previously initialised, i.e., when there is a write \nto it that happened before the read. Executions with reads from uninitialised locations are valid, but, \nas we explain below, un\u00adsafe. RFN ONATOMIC requires that a read only reads from the write to the same \nlocation immediately preceding it in hb; cf. (RD). In the absence of other synchronisation, this means \nthat a thread can read only from its own previous writes or initial values, since by HBDEF, sb . ib . \nhb. Threads can establish the necessary syn\u00ad 3In the original C11 model [2], sc is a total order on SC \noperations over all locations. The formulation here is is equivalent to the original one [1, \u00a7C], but \nmore convenient for de.ning library abstraction. chronisation using atomic operations (which we explain \nnow) or locks (which we elide here; see \u00a7A). SC atomics. The strong semantics of SC actions is enforced \nby organising all SC reads and writes over a single location into a total order sc, which cannot form \na cycle with hb (ACYCLICITY). According to SCR EADS, an SC read can only read from the closest sc-preceding \nwrite. Thus, if all memory accesses are annotated as SC in (SB) from \u00a72, the result shown there is forbidden. \nIndeed, by SCREADS and ACYCLICITY, the store of 1 to y has to follow the load of 0 from y in sc, and \nsimilarly for x. This yields a cycle in sb .sc, contradicting ACYCLICITY. Note that the model requires \nthe existence of sc, but does not include all of it into hb. As a consequence, one cannot use the ordering \nof, say, two SC reads in sc to constrain the values that can be read according to RFNONATOMIC. By SWDEF, \nan rf edge between an SC write and an SC read generates an sw edge, which is then included into hb by \nHBDEF. Release-acquire atomics have the same effect, as we now explain. Release-acquire atomics. By SWDEF, \nan ACQ read synchro\u00adnises with the REL write it reads from. For example, if in (SCL) we annotated all \nwrites with REL and all reads with ACQ, then the rf edges would be included into hb and the execution \nwould be prohibited by ACYCLICITY. For atomics weaker than SC, there is no total order on all operations \nover a given location analogous to sc; this is why (SB) is allowed. Instead, they satisfy a weaker property \nof coherence: all writes (but not reads) to a single atomic location are organised into a total modi.cation \norder mo, which has to be consistent with hb (HBVSMO). SC writes to the location are also included into \nmo, and in such cases the latter has to be consistent with sc (MOVSSC). Since reads are not included \ninto mo, we do not have an ana\u00adlogue of SCR EADS, and thus, a read has more freedom to choose which write \nit reads from. The only constraints on atomic accesses weaker than SC are given by coherence axioms C \nOWR, CORW and C ORR. For example, COWR says that a read r that happened after a write w2 cannot read \nfrom a write w1 earlier in mo. Relaxed atomics. Like release-acquire atomics, relaxed atomics respect \ncoherence, given by the mo order and the axioms C OWR, CORW and CORR. However, rf edges involving them \ndo not generate synchronisation edges sw. The only additional constraint on relaxed reads is given by \nRFATOMIC, which prohibits reads from the future , i.e., from writes later in hb; cf. (RD). This and the \nfact that coherence axioms enforce no constraints on actions over distinct locations allows (SCL). If \nall the loads and stores in (SCL) were to the same location, it would be forbidden by C ORW. Safety axioms. \nThe safety axioms in Figure 5 de.ne the con\u00additions under which a program is faulty. DRF constrains pairs \nof actions over the same location, with at least one write. It requires that such pairs on distinct threads, \none of which is a non-atomic access, are related by hb, and on the same thread, by sb (recall that in \nC/C++, the order of executing certain program constructs is un\u00adspeci.ed, and thus, sb is partial). SAFEREAD \nprohibits reads from uninitialised locations. The N ONINTERF axiom is not part of the C11 memory model, \nbut formalises the property of non-interference required for our results to hold (\u00a73); it is technically \nconvenient for us to consider it together with the other safety axioms. N ONINTERF requires that the \nlibrary and the client only read from and write to the locations they own, except paramt and retvalt \nused for communication (\u00a74). The axiom classi.es an action as performed by the library or the client \ndepending on its position in sb with respect to calls and returns. Atomic sections. Atomic sections are \na widespread idiom for de.ning library speci.cations. In an SC memory model, we can (store.(x, load\u00b5(y)))t \n= {({u, v},{(u, v)}) | .a ' , e1, e2, g1, g2. e1 e2 .g1 g2 . = = u = (e1, g1, t, load\u00b5(y, a ' )) .v = \n(e2, g2 , t, store.(x, a ' ))} (*y = CAS.,\u00b5(x, a, b))t = {({u, v},{(u, v)}) | .e1, e2, g1, g2 , a ' . \ne1 = e2 .g1 = g2 .a ' a . = (u = (e1, g1, t, rmw.,\u00b5(x, a, b)) .v = (e2, g2, t, storeNA(y, 1))) .(u = \n(e1, g1, t, load.(x, a ' )) .v = (e2, g2, t, storeNA(y, 0)))} Figure 2. De.nitions of (c)t for sample \nbase commands. Here x, y . Loc and a, b . Val are constants. (skip)t = {(\u00d8,\u00d8)} (C1; C2)t = {(A1 .\u00b7A2,sb1 \n.sb2 . {(u, v) |u . A1 .v . A2}) |(A1,sb1) . (C1)t .(A2,sb2) . (C2)t} (if(x) {C1}else {C2})t = {({u}.\u00b7A, \nsb . {(u, v) |v . A}) | .a. (A, sb) . (C1)t .u = ( , , t, loadNA (x, a)) .a= 0} . {({u}.\u00b7A, sb . {(u, \nv) |v . A}) |(A, sb) . (C2 )t .u = ( , , t, loadNA(x, 0))} (atom sec {C})t = {({(e, g, t, .) |(e, , t, \n.) . A},{((e1, g, t, .1),(e2 , g, t, .2)) | ((e1, , t, .1),(e2, , t, .2)) . sb}) |(A, sb) . (C)t .g . \nSectId} (m)t = {(A. {u}. {v},sb . {(u, v)}. {(u, q),(q, v) |q . A}) |(A, sb) . (Cm)t .u = ( , , t, call \nm( )) .v = ( , , t, ret m( ))} \u00b7\u00b7 { nn n (let {m = Cm |m . M}in C1 . . . . . Cn)I = (A0 .\u00b7( \u00b7 At), sbt,(A0 \n\u00d7 ( \u00b7 At))) |(.t = 1..n. (At,sbt) . (Ct)t) . t=1 t=1 t=1 } (.t = 1..n. .u. ..nitely many v. (v, u) . \nsbt) .(A0 = \u00b7 {(e, g, 0,store.(x, a)) |I(x) = (a, .) .e . AId .g . SectId}) Figure 3. Thread-local semantics. \nA.\u00b7Bis the union of the sets of actions Aand B with disjoint sets of action and atomic section identi.ers. \nHBDEF. hb = ((sb .ib .sw)/~)+, where R ''' '' R/~ = R. {(u, v) |sec(u) = sec(v) . .u , v . sec(u) = sec(u \n) .sec(v) = sec(v ) .u -. v ' } () .t1, t2 , ., \u00b5, x. t1 = t2 .. . {SC,REL} . \u00b5 . {SC,ACQ} sw SWDEF. \n.w, r. w -. r .. rfACYCLICITY. hb .sc is acyclic .w = (t1,write.(x, )) .r = (t2,read\u00b5(x, )) .w -. r hbrf \n'' ' DETREAD. .r. (.x, w . w -. r .w = ( ,write(x, )) .r = ( ,read(x, ))) .. (.w. w -. r) RFATOMIC. rfhb \nRFNONATOMIC. .w, r, x. w -. r .w = ( ,write(x, )) .r = ( ,read(x, )) .sort(x) = NA . \u00ac.r, w. r w hbhbhb \n'' ' =. w -. r .\u00ac.w . w = ( ,write(x, )) .w -. w -. r rf rfscscsc ''' SCREADS. .w, r. w -. r .r = ( ,readSC(x, \n)) .w = ( ,writeSC(x, )) =. w -. r .\u00ac.w . w = ( ,write(x, )) .w -. w -. r HBVSMO. \u00ac.w1, w2. MOVSSC. \u00ac.w1, \nw2. COWR. \u00ac.w1 , w2. CORW. \u00ac.r, w1, w2 . CORR. \u00ac.r1 , r2, w1, w2. rf mo rf \u00ad hb mo --w1 r1 w1 w2 w2 r \n. . . mo . f hb w1 w2 w1 w2 fhbmo. f hb\u00ad . rf moscr w1 w2 r2 rf momomo ASMO. .u, v. u -. v .sec(u) = \nsec(v) =. \u00ac.q. u -. q -. v .sec(u) = sec(q) scscsc ASSC. .u, v. u -v .sec(u) = sec(v) =--v .sec(u) sec(q) \n. . \u00ac.q. u . q . = Figure 4. Selected validity axioms of the C11 memory model. Axioms simpli.ed for the \npurposes of presentation are marked by . DRF. .u, v, x, t1, t2. (u, v . A.u v .u = (t1, (x, )) .v = \n(t2, (x, )) .(u = (t1,write(x, )) .v = (t2,write(x, )))) == . hbhbsbsb ((t1 t2 =-v .v -u .sort(x) = ATOM)) \n.(t1 = t2 =-v .v -. u))) = . (u .. . (u . rf SAFEREAD. .r. r . A.r = ( ,read( , )) =. .w. w -. r NONINTERF. \n.u, x, t. (u . A.t = 0 .u = (t, (x, )) .x . {paramt,retvalt |t = 1..n}) =. sbsbsb ((.v. v = ( ,call ) \n.v -. u .\u00ac.q. q = ( ,ret ) .v -. q -. u) .. (x . LLoc)) Figure 5. Selected safety axioms of the C11 memory \nmodel hbrf DETREADl. .r, t. ((.x. r = ( ,read(x, )) .x paramt . .w. w -r .w = ( ,write(x, ))) .. .w ' \n. w ' -. r) . = . sbsbsb (.a, b. r = (t, read(paramt, a)) . A.u = ( ,call (b)) .u -. r .(\u00ac.v. v = ( ,ret \n) .u -. v -. r) =. a = b) rf SAFEREADl. .r, x, t. r . A.r = (t, read(x, )) .x = paramt =. .w. w -. r \nDETREADc. .r, t. ((.x. r = ( ,read(x, )) .x retvalt . .w. w . r .w = ( ,write(x, ))) .. .w ' . w ' . \n= -hb-rfr) . sbsbsb (.a, b. r = (t, read(retvalt, a)) .u = ( ,ret (b)) .u -. r .(\u00ac.v. v = ( ,call ) .u \n-. v -. r) =. a = b) rf SAFEREADc. .r, x, t. (r . A.r = (t, read(x, )) .x = retvalt =. .w. w -. r) . \nhb (r . A.r = (t, read(retvalt, )) .r ( ,ret ) =-. r .u = (t, ret )) = . .u. u Figure 6. Axioms for library \n(\u00a76.1) and client (\u00a76.3) executions de.ne their semantics by simply requiring that no other events are \ninterleaved with actions inside an atomic section. Unfortunately, the relaxed memory model of C11 does \nnot admit such a simple de.nition. The straightforward solution of imposing a total order on all instances \nof atomic sections would rule out relaxed speci.\u00adcations that we would like to give, such as the Treiber \nspeci.cation from \u00a72. Hence, we have extended C11 with a prototype notion of atomic sections suitable \nfor its relaxed-memory setting (inspired by the semantics of transactions in [6]). This notion represents \nonly the .rst step towards a natural speci.cation language for relaxed C11, which is an interesting problem \nin itself. The axioms de.ning the semantics of atomic sections are HB-DEF, ASMO and AS SC in Figure 4 \nand ATOMAS in Figure 7 (de\u00adferred to \u00a7A for brevity). They capture the expected properties of atomicity. \nThus, in HB DEF, we factor sb .ib.sw over atomic sec\u00adtions using /~: e.g., if an action u happens-before \nanother action v, then u also happens-before any other action from the same atomic section as v. ASMO \nand AS SC require that actions from the same atomic section be contiguous in mo and sc. ATOMAS constrains \nrelaxed actions, which do not generate hb edges. AS MO, ASSC and ATOMAS are trivially satis.ed when every \naction has a unique atomic section identi.er. Additionally, in this case HBDEF simpli\u00ad.es to hb = (sb \n.ib .sw)+, which is how it is de.ned in standard C11 [2]. Thus, if every action executes in a separate \natomic section, our augmented model coincides with standard C11. 6. Library Abstraction in Detail We \n.rst de.ne formally the concepts used in the de.nition of li\u00adbrary abstraction (De.nition 2) and the \nAbstraction Theorem (The\u00adorem 3) from \u00a73 for the memory model with relaxed atomics. We then show how \nthe Abstraction Theorem can be strengthened for a fragment of the language excluding them (\u00a76.2) and \ngive the proof outlines for both theorems (\u00a76.3). 6.1 Library Abstraction in the Presence of Relaxed \nAtomics History de.nition. We formally de.ne the history function, which selects a history in the sense \nof De.nition 2 from a library execution. For an execution X, we let history(X) = (interf (X),hbL(X),scL(X)) \nand lift history to sets of executions pointwise. Here interf (X) is the projection of A(X) to interface \n(call and return) actions. The hbL selector computes the guarantee part of the history. We let hbL(X) \nbe the projection of hb(X) to pairs of actions of the form (( ,call ),( ,ret )) and pairs of calls and \nreturns (in any order) by the same thread. We record only edges of the above form, since it can be shown \nthat any happens-before edge between interface actions in a library execution under its most general \nclient can be obtained as a transitive closure of such edges. Intuitively, call-to-return edges are the \nones that represent the synchronisation between library method invocations, as illustrated by (MP) in \n\u00a72. The scL selector computes the deny part of the history. We let scL(X) be the projection of ((hb(X) \n.sc(X))+)-1 to pairs of ac\u00adtions of the form (( ,ret ),( ,call )). This component is needed, since the \nACYCLICITY axiom (Figure 4) mandates that sc cannot form a cycle with hb, but does not include sc into \nhb. Thus, when a library relates a call action u to a return action v with hb and sc, the client cannot \nrelate v to u with the same relations, as this would invalidate ACYCLICITY. We add only return-to-call \nedges into scL(X), as these are the edges that represent synchronisation inside the client (similarly \nto how call-to-return edges represent synchronisation inside the library in hbL(X)). One might think \nthat the deny component of the history should have included edges recording potential violations of other \nsimilar axioms, e.g., HB-VSMO, as suggested by (DN). However, in the case of the model with relaxed atomics, \nwe are forced to quantify over client happens\u00adbefore edges R in De.nition 2. As it happens, this makes \nit unnec\u00adessary to consider axioms other than ACYCLICITY (see the proof of the Theorem 3 in [1, \u00a7C]). \nThese axioms, however, have to be taken into account in the case without relaxed atomics (\u00a76.2). Library-local \nsemantics. We de.ne the most general client as follows. Take n = 1 and let {m1 ,. . . , ml}be the methods \nimple\u00admented by a library L. We let MGCn(L) = (let Lin C1 mgc . . . . . Cn mgc ), where Ct mgc is while(nondet()) \n{ if(nondet()) {m1} else if (nondet()) {m2} . . . else {ml} } Here we use the obvious generalisation \nof loops and conditionals to branch expressions that yield a non-deterministic value. To allow parameters \nof methods to be chosen arbitrarily, we replace the axioms D ETREAD from Figure 4 and S AFEREAD from \nFigure 5 by DETREADl and S AFEREADl from Figure 6, which mandate that reads from paramt lack associated \nrf edges, while nonetheless yielding identical values within a single method call. As part of the proof \nof the Theorem 3 (\u00a76.3), we show that this client is indeed most general in a certain formal sense (with \nthe caveat concerning the need to extend its executions with client happens-before edges mentioned in \n\u00a73). We note that some libraries require their clients to pass only certain combinations of parameters \nor issue only certain sequences of method calls. Such contracts could be accommodated in our framework \nby restricting the most general client appropriately; we do not handle them here so as not to complicate \nthe presentation. For an initial library state I . LLoc ..n Val \u00d7MemOrd, a li\u00adbrary execution of Lfrom \nI is an execution from [MGCn(L)]I for some n = 1. A library execution is valid if it satis.es the validity \naxioms with D ETREADl instead of D ETREAD; it is safe if it sat\u00adis.es the safety axioms with S AFEREADl \ninstead of S AFEREAD. We let [L]I be the set of all valid library executions of L from I and lift [L] \nto sets of initial states pointwise. We say that a library L is safe when run from I if so is every execution \nin [L]I; for a set I of initial states, (L,I) is safe if Lis safe when run from any I . I. The notion \nof a non-interfering library is de.ned similarly. Extended executions. In De.nition 2, we use library \nexecutions whose happens-before relation is extended with extra edges record\u00ading constraints enforced \nby the client. Consider an execution X and a relation Rover interface actions from A(X). The extension \nof X with R is an execution that has the same components as X, except the happens-before relation is \nreplaced by (hb(X) .R)+. An ex\u00adtension of a library execution with Ris admissible when it satis.es the \ncorresponding validity axioms, but with HBDEF replaced by EXTHBDEF. hb = ((sb .ib .sw .R)/~)+ . For an \ninitial library state I, we let [L, R]I be the set of admissi\u00adble executions of L from I extended with \nR. This completes the de.nition of components used in De.nition 2. Execution projections. Finally, we \nde.ne the client function used in Theorem 3. Consider a valid execution X of C(L). An action u . A is \na library action, if it is a call or return action, an action of the form (0,write(x, )) for x . LLo \nc, or if sb(X) .v.v = ( ,call ) .v ---. u . sb(X)sb(X) \u00ac.q.q = ( ,ret ) .v ---. q ---. u. An action u \n. A is a client action, if it is a call or return action, it is an action of the form (0,write(x, )) \nfor x . CLoc, or the nega\u00adtion of the above property holds. We de.ne the execution lib(X) by restricting \nthe action set to library actions and projecting all the re\u00adlations in X accordingly. We use a similar \nprojection client(X) to client actions and lift client and lib to sets of executions pointwise.  Properties \nof library abstraction. For the fragment of the lan\u00adguage with an SC semantics i.e., allowing only non-atomic \nmem\u00adory accesses and SC atomics De.nition 2 implies classical lin\u00adearizability. This follows from Theorem \n3 and the fact that classi\u00adcal linearizability is equivalent to observational abstraction on the SC memory \nmodel [7]. However, the converse is not true: since our notion of library abstraction validates Theorem \n3 for clients in the full C11, it distinguishes between SC libraries that classical linearizability would \nconsider equivalent (see [1, \u00a7D]). Using Theorem 3, we can obtain the expected property that, like the \nclassical notion of linearizability, our notion of library abstraction is compositional (with a caveat \nthat non-interference among libraries has to be checked globally). Formally, consider libraries L1,. \n. . , Lk with disjoint sets of declared methods and assume the splitting of the library address space \ninto regions be\u00adlonging to each library: LLoc = LLoc1 . . . . . LLock. Con\u00adsider sets of initial states \nI1 ,. . . , Ik such that .j = 1..k. .I . Ij. dom(I) . LLo cj. We adjust the notion of library safety \nso that NONINTERF for Lj is checked with respect to locations in LLocj. Let (L ' 1,I1 ' ),. . . , (Lk' \n,Ik ' ) be corresponding library speci.cations. We de.ne L, respectively, L ' as the library implementing \nall meth\u00adods of L1,. . . , Lk, respectively, L ' 1,. . . , L ' k and having the set of initial states \nI1 .. . . . Ik, respectively, I1 ' .. . . . I k' . We assume that any combination of implementations \nor speci.cations of dif\u00adferent libraries is non-interfering. The following theorem is shown by abstracting \nLj to L ' j one by one using Theorem 3. THEOREM 4. If (Lj,Ij) . (L ' j,Ij' ) for j= 1..k, then L . L \n' .  6.2 Library Abstraction without Relaxed Atomics We call an action with at least one RLX annotation \nrelaxed. In this section, we restrict ourselves to programs whose action structures do not have any relaxed \nactions, and we augment the C11 thread\u00adlocal semantics as described in the assumptions of \u00a74. Among other \nthings, these changes allow us to remove the quanti.cation over client happens-before edges Rfrom De.nition \n2, at the expense of including an additional deny relation into the history. DEFI NITION 5. An extended \nhistory is a quadruple (A, G, D, D ' ), where Ais a set of interface actions, and G, D, D ' . A\u00d7 A. For \nan execution X = (A, sb,ib,rf,sc,mo,sw,hb), we let Ehistory(X) = (interf (X),hbL(X),scL(X),denyL(X)), \nwhich we lift to sets of executions pointwise. The selectors interf , hbL and scL are de.ned as in \u00a76.1. \nThe relation denyL(X) is de.ned similarly to scL, but whereas the latter records client hb and sc edges \nthat can violate ACYCLIC-ITY, the former includes the client hb edges that can violate the axioms HB \nVSMO, COWR and SCREADS (Figure 4). We do not have to consider other similar axioms, such as RFATOMIC, \nCORW and C ORR since in any valid execution X without relaxed actions, we have rf(X) . hb(X). Due to \nthis, the hb client edges violating, HBVSMO and CORW, COWR and CORR can be covered by the same relations. \nFor the case of HB VSMO and COWR, denyL(X) includes the dashed edges of all possible instantiations of \nthe fol\u00adlowing diagrams: mo - w1 w2 w1 hb -u. mo -v hb -w2 . . . hbf rf . . . . . . . . . u f v hbf r \n where u = ( ,ret ) and v = ( ,call ). This records client hb edges that violate HB VSMO or COWR (cf. \n(DN) in \u00a73). The diagrams are thus constructed systematically by breaking the hb edge. For the case of \nSCREADS, denyL(X) includes edges corresponding to a corner case in this axiom omitted from Figure 4. \nThe full version of the axiom and the corresponding deny diagram are given in \u00a7A. DEFINITION 6. We let \n(A1, G1, D1, D 1 ' ) :(A2, G2, D2, D 2 ' ), if A1 = A2 , G2 . G1, D2 . D1 and D2 ' . D1 ' . For safe \n(L1,I1) and (L2,I2), (L1,I1) is abstracted by (L2,I2), written (L1,I1) :(L2,I2), if .I1 . I1 , H1 . Ehistory([L1]I1). \n.I2 . I2, H2 . Ehistory([L2]I2). H1 :H2. Unlike in De.nition 2, here an abstracted history can guarantee \nfewer happens-before edges to the client: without relaxed atomics, removing edges from happens-before \ncan only permit more client behaviours or make the client unsafe. We note that checking the inclusion \nbetween the components of the history given by denyL, required by De.nition 6, is simpler in practice \nthan quantifying over client happens-before edges Rin De.nition 2. For executions X and Y, we write X \n: Y when all their components except hb are equal, and hb(Y) . hb(X). THEOREM 7 (Abstraction without \nrelaxed atomics) . Assume that (L1,I1), (L2,I2) and (C(L2),I . I2) are safe and (L1,I1) : (L2,I2). Then \n(C(L1),I . I1 ) is safe and .X . client([C(L1)](I . I1)). .Y . client([C(L2)](I . I2)). X :Y. Unlike \nTheorem 3, this one allows the programmer to check non-interference on C(L2) i.e., with respect to a \nlibrary speci.cation and to conclude that C(L1) is non-interfering. Since the abstract library can have \na smaller guarantee than the con\u00adcrete one, the happens-before of the execution C(L2) may also be smaller \nthan that of the execution C(L1). Like the notion of library abstraction from \u00a76.1, the one pro\u00adposed \nhere implies classical linearizability for the SC fragment of the language (but not vice versa) and is \ncompositional [1, \u00a7C]. However, here the latter property does not require us to check non\u00adinterference \nglobally: a composition of several non-interfering li\u00adbraries is non-interfering. 6.3 Proof Outlines \nClient-local semantics. We start by de.ning the client-local se\u00admantics of a client C = C1 . . . . . \nCn, which is a counterpart of the library-local semantics de.ned in \u00a76.1. Let M be the set of methods \nthat can be called by C. Consider the program C(\u00b7) = (let {m = skip |m . M}in C1 . . . . . Cn), where \nevery method is implemented by a stub that returns im\u00admediately after having been called. Moreover, we \nallow meth\u00adods to return arbitrary values by replacing the axioms DETREAD from Figure 4 and S AFEREAD \nfrom Figure 5 by D ETREADc and SAFEREADc from Figure 6. We call executions of the above pro\u00adgram client \nexecutions of C. A client execution is valid, if it sat\u00adis.es the validity axioms with D ETREADc instead \nof D ETREAD; it is safe, if it satis.es the safety axioms with SAFEREADc in\u00adstead of S AFEREAD. For an \ninitial client state I . CLoc ..n (Val \u00d7 MemOrd), let [C]I be the set of all valid client executions \nof C from I; for a set I of initial states we de.ne [C]I as expected. The notion of an extended client \nexecution is similar to the one of an extended library execution from \u00a76.1. For an extended execution \nX we let core(X) be the execution obtained from X by recomput\u00ading hb(X) from sb(X), ib(X) and sw(X) according \nto HB DEF.  Client-side history selectors. Consider a client execution X. We de.ne hbC(X),scC(X) . interf \n(X) \u00d7 interf (X), which are analogous to hbL and scL from \u00a76.1, but select the information about the \nclient part of the execution that is relevant to the library. We let hbC(X) be the projection of hb(X) \nto pairs of actions of the form (( ,ret ),( ,call )) and pairs of calls and returns (in any order) by \nthe same thread. We select edges of this form as they are the ones that record synchronisation enforced \nby the client. We let )-1 scC(X) be the projection of ((hb(X) . sc(X))+ to pairs of actions of the form \n(( ,call ),( ,ret )). Proof outline for Theorem 3. Consider an execution X of C(L1) from the initial \nstate I . I1, where I . I and I1 . I1 . We start by decomposing X into a client execution client(X) and \na library execution lib(X) and showing that client(X) . [C, hbL(core(lib(X)))]I; lib(X) . [L1, hbC(core(client(X)))]I1. \nThe second inclusion justi.es that the most general client of the library de.ned in \u00a76.1 is indeed most \ngeneral, as it can reproduce the behaviour of L1 under any client C. This comes with the caveat that \nan execution of the most general client of L1 has to be extended with hbL(core(lib(X))) to obtain lib(X), \nas the library\u00adlocal semantics does not generate happens-before edges enforced by client synchronisation \n(and similarly for client(X) in the .rst inclusion). The above decomposition step relies on X being non\u00adinterfering. \nUsing the fact that (L1,I1) . (L2,I2), we prove that there exist I2 . I2 and Y . [L2 ,hbC(core(client(X)))]I2 \nsuch that history(lib(X)) . history(Y). Here we use the quanti.cation of client happens-before edges \nR in De.nition 2 to handle the extension of the library execution with hbC(core(client(X))). We then \ncompose the executions X and Y into the desired execution of C(L2). This step uses the fact that the \ndeny component of history(Y) is smaller than that of history(lib(X)). .. Proof outline for Theorem 7. \nUnlike in Theorem 3, here we need to consider the case when an execution X of C(L1) has ac\u00adtions violating \nnon-interference. In this case, we identify an earli\u00adest faulting action u and construct a valid execution \nthat is a pre.x of X ending just before u and is thus non-interfering. This is only possible because, \nwithout relaxed atomics, we do not have satisfac\u00adtion cycles, and because the theorem is stated over \nan augmented thread-local semantics (\u00a74), with pre.x executions added to the se\u00admantics. We convert the \nresulting execution into one of C(L2) as in the proof of Theorem 3 and conjoin the action the action \nu to it. This yields an execution of C(L2) violating non-interference and contradicting the assumption \nabout its safety. In the case when X is non-interfering, the proof is similar to that of Theorem 3. Some \nadditional work is needed to deal with the fact that De.nition 6 does not have a quanti.cation over client \nhappens\u00adbefore edges and allows the abstract guarantee to be smaller than the concrete one. .. 7. Establishing \nLibrary Abstraction In this section, we discuss the proof process for establishing ab\u00adstraction between \nlibraries in the sense of De.nitions 2 and 6. To reason about programs on the C11 memory model, we use \naxioma\u00adtisations of the action structures generated by them, which give a simple mathematical interface \nto the program semantics. To prove library safety, required by De.nitions 2 and 6, we consider all the \nexecution shapes of the most general client, and check these against the C11 safety axioms. We now explain \nhow we prove the correspondence between the executions of concrete and abstract li\u00adbraries, using De.nition \n2 for illustration. Effect points. Consider an execution X1 . [L1 , R]I1. We con\u00adstruct an execution \nX2 . [L2, R]I2 whose history witnesses the existential in De.nition 2 using an adapted version of the \nlin\u00adearization point method for proving linearizability. The method constructs the abstract execution \nby calling a method speci.ca\u00adtion at a .xed linearization point in every method invocation of the concrete \nexecution; intuitively, it is at this point that the concrete method takes effect . In our adaptation, \nwe construct X2 by sub\u00adstituting calls to library method implementations in X1 for the cor\u00adresponding \ncalls to speci.cations, and choosing appropriate values for reads and different orders between actions. \nThese values and orders are chosen based on the orders over actions we call effect points, picked for \neach concrete method invocation in X1 . Thus, the various partial orders over the effect points in the \nconcrete ex\u00adecution dictate the order of precedence for the effects of method invocations in the abstract \nexecution. In contrast with the original linearization point method, the latter order does not have to \nbe lin\u00adear. We now explain this technique in more detail on an example. Example: Treiber stack. We have \nproved the correctness of the stack in Figure 1b with respect to its speci.cation in Figure 1a ac\u00adcording \nto De.nition 2 (full details are given in [1, \u00a7E]). As ef\u00adfect points in X1, we pick the rmw actions \nmodifying the stack s top pointer T, which correspond to successful CASes (this is the same choice as \nthe that of linearization points when proving the linearizability of Treiber s stack on an SC memory \nmodel). The order mo(X1) over these actions de.nes a total order over success\u00adful push and pop invocations. \nWhen substituting invocations of method implementations for invocations of speci.cations, we use mo(X1) \nto decide rf(X2) and mo(X2 ) for the abstract location S. Namely, suppose we have two method invocations \nU and V in X1 , such that the rmw of U is the immediate predecessor to the rmw of V in mo(X1). When substituting \ncorresponding invocations of speci.cation methods U ' and V ' , we set up rf(X2) and mo(X2) so that the \nload from S in V ' reads from the rmw in U ' , and mo(X2) orders the rmw on S in U ' right before rmw \non it in V ' . Fixing rf(X2 ) and mo(X2) in the abstract execution immediately .xes the values of reads, \nwhich .nishes the construction of X2. Example: producer-consumer queue. We have similarly veri\u00ad.ed a \nnon-blocking producer-consumer queue according to De.\u00adnition 6 (see [1, \u00a7E]). The queue is intended for \ncommunication between a single producer thread and a single consumer thread and provides three methods: \ninit, enq and deq. The implementation stores values in a .nite cyclic array, while the speci.cation stores \nthem using the abstract data type of a sequence. To ensure that the consumer calling deq observes up-to-date \nvalues, it must synchro\u00adnise with the producer calling enq using release-acquire atomics. 8. Related \nWork Relaxed-memory behaviour has become widespread in real con\u00adcurrent systems. As a result, some algorithm \ndesigners have be\u00adgun to publish algorithms with memory-model annotations such as fences [3, 17, 18]. \nHowever, the corresponding formulations of cor\u00adrectness properties and their proofs are generally informal. \nWhile there has been some work on formally verifying programs on weak memory models [14, 20, 23], none \nhas proposed a compositional reasoning method, like we do. Ours is the .rst approach that for\u00admulates \nthe notion of a correct library speci.cation and provides a method for establishing it on C11, or any \nsimilarly relaxed model. Our work is an evolution of linearizability [11], a correctness criterion that \nhas been widely adopted in the concurrent algorithms community. In the SC fragment of C11, our de.nition \nof library abstraction implies classical linearizability. History abstraction in classical linearizability \nis de.ned by linearization of the partial order over non-overlapping methods invocations, and the guarantee \nportion in our histories can be seen as lifting this to the C11 setting. Classical linearizability has \nno equivalent to our deny relation; the con.icts between relations that are captured by deny do not occur \nin an SC setting where all events are totally ordered.  Recent work has formalised the intuition that \nlinearizability cor\u00adresponds to observational abstraction [7] and has extended it to han\u00addle liveness \n[9], resource-transferring programs [10] and the x86 memory model [5]. The latter work is the closest \nto this paper; in particular, we borrow the decompose-compose approach in the proof of the Abstraction \nTheorem (\u00a76.3) from it. However, while its objective is the same as ours abstraction for relaxed-memory \ncon\u00adcurrent libraries the technical challenges and the machinery de\u00adveloped to address them are very \ndifferent. The x86 memory model can be de.ned by a small-step operational semantics, which has an underlying \ntotal order on abstract machine memory events [19]. Linearizability for x86 is therefore a relatively \nmild extension to classical linearizability, which simply represents some of these events in (linear) \nhistories. In contrast, C11 constrains relaxed be\u00adhaviour through partial ordering, controlled by an \naxiomatic se\u00admantics. There are no abstract machine events to linearize, which motivates our novel de.nition \nof a history as a set of partial orders and history abstraction as inclusion over them. Furthermore, \nx86 is a substantially stronger model than C11, with (SB) from \u00a72 be\u00ading the only signi.cant relaxation \n[19]. Our approach is the .rst technique for specifying client-visible effects of relaxations inside \nlibraries on weaker memory models. 9. Conclusion and Future Work We have proposed the .rst sound criterion \nfor library abstraction suitable for the C11 memory model and demonstrated its practi\u00adcality on two small, \nbut typical, relaxed libraries. Our criterion is certainly complex, but much of this complexity arises \nfrom the real\u00adworld intricacies of the C11 memory model. In turn, the complex\u00adity of the model arises \nfrom a multitude of target platforms of C and C++ two of the world s most widely-used programming lan\u00adguages. \nDespite this complexity, the criterion allows developers to establish that C11 libraries satisfy simple, \nreusable speci.cations that precisely describe the level of consistency guaranteed. This is an essential \ningredient for supporting modular development of complex software on relaxed memory models. In addition, \nour approach is the .rst compositional reasoning technique for an axiomatically de.ned relaxed memory \nmodel, and highlights general principles for abstraction on such models. We have good reason to believe \nthat our techniques can be reused for other memory models, as the conditions for library abstraction \nfall out naturally from obligations arising when trying to prove the Ab\u00adstraction Theorem according to \nthe approach in \u00a76.3. In particular, the histories in our approach are constructed uniformly, with deny \nrelations obtained straightforwardly from axioms by breaking hb edges (\u00a76.2). In particular, our preliminary \ninvestigations show that these techniques can be used to de.ne a notion of library abstrac\u00adtion for an \naxiomatic formulation of the x86 memory model [19]. Our speci.cations describe precisely the level of \nsynchronisa\u00adtion provided by the library, although in some cases this makes them more verbose. This is \nmotivated by the fact that libraries on C11 can offer relaxed interfaces to clients, without either giving \nup all synchronisation guarantees or enforcing sequential consistency. If information about the internal \nsynchronisation used to ensure library correctness were not described in these interfaces, clients would \nhave to duplicate it, thereby decreasing performance. On the other hand, requiring library interfaces \nto be SC would rule out li\u00adbraries that use weaker memory orders to achieve ef.ciency while preserving \nbasic correctness properties, again decreasing perfor\u00admance. Our prototype atomic section semantics represents \na .rst attempt at a syntactic speci.cation idiom for relaxed algorithms, albeit with limitations as described \nin \u00a74. We leave a more compre\u00adhensive treatment of relaxed atomic sections to future work. Our two formulations \nof library abstraction (De.nitions 2 and 6) and the Abstraction Theorem (Theorems 3 and 7) identify the \nfeature of the current C/C++ memory model that does not allow fully compositional reasoning about libraries. \nAs we argued in \u00a73, this de.ciency is not speci.c to our de.nition of library abstraction, but would \nbe inherent to any sensible one. We hope that these insights will inform future revisions of the C/C++ \nmemory model. Our development omits memory fences and release-consume atomics, which are the more advanced \nfeatures of the C11 memory model. A memory fence is a synchronisation construct that affects many memory \nactions, rather than just one. Release-consume is a special-purpose memory order which compiles more \nef.ciently to Power and ARM processors. We conjecture that our methods can be used to handle these features. \nAs both of them generate more possible client-library interactions, this will require adding additional \nrelations to histories. To concentrate on the core challenges of library abstraction in C11, we assumed \nthat the data structures of the client and its li\u00adbraries are completely disjoint (\u00a74). We hope to lift \nthis restriction by combining our results with a recent generalisation of classical linearizability allowing \ntransfers of memory ownership [10]. Simi\u00adlarly, a previous generalisation of linearizability to handle \nliveness properties [9] could be used to strengthen speci.cations of the kind shown in Figure 1a to guarantee \nproperties such as lock-freedom. Acknowledgements. We would like to thank Hans Boehm, Richard Bornat, \nPaul McKenney, Robin Morisset, Madan Musu\u00ad . vathi, Peter Sewell, Jaroslav Sevc.\u00b4ik, Hongseok Yang and \nJohn Wickerson for helpful comments. We acknowledge funding from EPSRC grants EP/F036345 and EP/H005633. \nReferences [1] M. Batty, M. Dodds, and A. Gotsman. Library abstraction for C/C++ concurrency (extended \nversion). University of York Technical Report YCS-2012-479, 2012. [2] M. Batty, S. Owens, S. Sarkar, \nP. Sewell, and T. Weber. Mathematizing C++ concurrency. In POPL, 2011. [3] H.-J. Boehm. Can seqlocks \nget along with programming language memory models? In MSPC, 2012. [4] H.-J. Boehm and S. V. Adve. Foundations \nof the C++ concurrency memory model. In PLDI, 2008. [5] S. Burckhardt, A. Gotsman, M. Musuvathi, and \nH. Yang. Concurrent library correctness on the TSO memory model. In ESOP, 2012. [6] S. Burckhardt, D. \nLeijen, M. F\u00a8ahndrich, and M. Sagiv. Eventually consistent transactions. In ESOP, 2012. [7] I. Filipovi\u00b4c, \nP. O Hearn, N. Rinetzky, and H. Yang. Abstraction for concurrent objects. In ESOP, 2009. [8] I. Filipovi \n\u00b4 c, P. O Hearn, N. Torp-Smith, and H. Yang. Blaiming the client: On data re.nement in the presence of \npointers. FAC, 22, 2010. [9] A. Gotsman and H. Yang. Liveness-preserving atomicity abstraction. In ICALP, \n2011. [10] A. Gotsman and H. Yang. Linearizability with ownership transfer. In CONCUR, 2012. [11] M. \nP. Herlihy and J. M. Wing. Linearizability: a correctness condition for concurrent objects. TOPLAS, 12, \n1990. [12] ISO/IEC. Programming Languages C++, 14882:2011. [13] ISO/IEC. Programming Languages C, 9899:2011. \n[14] M. Kuperstein, M. T. Vechev, and E. Yahav. Partial-coherence abstrac\u00adtions for relaxed memory models. \nIn PLDI, 2011. [15] L. Lamport. How to make a multiprocessor computer that correctly executes multiprocess \nprograms. IEEE Trans. Comp., 28, 1979. [16] J. Manson. The Java memory model. PhD Thesis. Department \nof Computer Science, University of Maryland, 2004.  Action structures for locks (lock(l))t = {({(e, \ng, t, lock(l))},\u00d8),({(e, g, t, block(l))},\u00d8) |e . AId .g . SectId} (unlock(l))t = {({(e, g, t, unlock(l))},\u00d8) \n|e . AId .g . SectId} { nn n (let {m = Cm |m . M}in C1 . . . . . Cn)I = (A0 .\u00b7( \u00b7 At), sbt,(A0 \u00d7 ( \u00b7 \nAt))) | t=1 t=1 t=1 (.t = 1..n. (At,sbt) . (Ct)t) .(.t = 1..n. .u. ..nitely many v. (v, u) . sbt) . } \n(\u00ac.u, v, t. (u, v) . sbt .u = ( , , ,block( ))) .(A0 = \u00b7 {(e, g, 0,store.(x, a)) |I(x) = (a, .) .e . \nAId .g . SectId}) Additional validity axioms rf momomo ATOMRMW. .w, u. w -. u .u = ( ,rmw( )) =. w -. \nu .\u00ac.w ' . w -. w ' -. u rf mo ATOMAS. .w, w ' , r, u, v, x. w -. r .sec(u) = sec(r) = sec(w) = sec(v) \n.r = ( ,read(x, )) .sort(x) = ATOM =. \u00ac(w -. v) mo momo '' '' ) '' .(u = ( ,write(x, )) =. w -. u .\u00ac.w \n. sec(w = sec(u) .w -. w -. u) rf .(u = ( ,read(x, )) .w ' -. r .sec(w ' ) = sec(r) =. w '' = w) sc \nscsc LOCKS. .u, v. u = ( ,lock(l)) .v = ( ,lock(l)) .u -. v =. .q. q = ( ,unlock(l)) .u -. q -. v swsc \n SWDEF. .w, r. w -. r .. (.l. w -. r .w = ( ,unlock(l)) .r = ( ,lock(l))) . rsrf (.t1, t2, ., \u00b5, x, \nw ' . t1 = t2 .. . {SC,REL} . \u00b5 . {SC,ACQ} . w = (t1,write.(x, )) .r = (t2,read\u00b5(x, )) .w -.t1 w ' -. \nr), rsdefmomomo where w -.t w ' .. .w1 . w -.* w1 .(.w2. w -.* w2 -.* w ' =. (w2 = (t, ) .w2 = ( ,rmw( \n)))) SCREADS. rf .w, r, x. w -. r .r = ( ,readSC(x, )) =. sc scsc '' ' ((w = ( ,writeSC(x, )) .w -. \nr .\u00ac.w . w = ( ,write(x, )) .w -. w -. r) . sc scsc (... w = ( ,write.(x, )) .. = SC . .w1. (w1 = ( \n,write(x, )) .w1 -. r .\u00ac.w2. w2 = ( ,write(x, )) .w1 -. w2 -. r) =. hb \u00ac(w -. w1))) Additional safety \naxiom sb scsc SAFELOCK. (.v, t, l. v . A.v = (t, unlock(l)) =. .u. u = (t, lock(l)) .u -. v .\u00ac.q. q \n= ( , (l)) .u -. q -. v) . sb scsc (\u00ac.u, v, t, l. u = (t, lock(l)) .v = (t, block(l)) .u -. v .\u00ac.q. \nq = ( , (l)) .u -. q -. v) Figure 7. Action structures for locks and additional C11 memory model axioms \n[17] M. M. Michael. Scalable lock-free dynamic memory allocation. In PLDI, 2004. [18] M. M. Michael, \nM. T. Vechev, and V. A. Saraswat. Idempotent work stealing. In PPOPP, 2009. [19] S. Owens, S. Sarkar, \nand P. Sewell. A better x86 memory model: x86-TSO. In TPHOLs, 2009. [20] T. Ridge. A rely-guarantee proof \nsystem for x86-TSO. In VSTTE, 2010. [21] S. Sarkar, P. Sewell, J. Alglave, L. Maranget, and D. Williams. \nUnder\u00adstanding POWER multiprocessors. In PLDI, 2011. [22] R. K. Treiber. Systems programming: Coping \nwith parallelism. Tech\u00adnical Report RJ 5118, IBM Almaden Research Center, 1986. [23] I. Wehrman and J. \nBerdine. A proposal for weak-memory local reasoning. In LOLA, 2011. A. Additional De.nitions for the \nC11 Model In \u00a74 5, we omitted the treatment of locks and CASes from the description of the memory model \nand simpli.ed some of the ax\u00adioms, even though the proofs of our theorems do not make such simpli.cations. \nHere we provide the missing de.nitions. We handle programs with bounded numbers of locks l . Lock, acquired \nand released using commands lock(l) and unlock(l), respectively. We thus extend the set of actions as \nfollows: . ::= . . . | lock(l) | unlock(l) | block(l), where l . Lock. An action (e, g, t, block(l)) \nrepresents a deadlocked attempt to acquire a lock l. We split the set of locks into client and library \nones (Lock = CLock .LLock) and consider only programs where the client and the library use locks from \nCLock and LLock, respectively. In Figure 7, we give the actions structures for lock operations, omitted \nfrom Figure 3, and the C11 axioms omitted from Figures 4 and 5. Note that the action structures of a \nwhole program do not include those where a thread executes actions after blocking. To adjust the axioms \nto the model with locks, we require that the sc re\u00adlation totally orders actions of the form ( ,lock( \n)), ( ,block( )) or ( ,unlock( )) for each lock, in addition to SC actions. The axioms ATOMRMW and LOCKS \nde.ne the behaviour of CAS commands and locks. ATOMAS is an additional axiom for atomic sections, in \nthe spirit of ATOMRMW. SWDEF and SCR EADS are full ver\u00adsions of the axioms presented in a simpli.ed form \nin Figure 4. The former adds synchronisation via release sequences [2] (de.ned by the rs relation), and \nthe latter allows SC reads from non-SC writes. SAFELOCK is an additional safety axiom, .agging a double \nunlock or a double lock in the same thread as a fault. All the theorems stated in the paper stay valid \nfor this ex\u00adtension of the model. To account for the full version of the SCREADS axiom, we add additional \nedges to denyL(X). For X = (A, sb,ib,rf,sc,mo,sw,hb), denyL(X) includes the dashed edges of all possible \ninstantiations of the following diagram: rf . . . w = ( ,write.(x, )) .. r = ( ,readSC(x, )) . = SC .. \n. . r . . . . . . w hbf u . . . w1 = ( ,write(x, )) . (\u00ac.w2. w2 = ( ,write(x, )) . . . . . sc. . . . \n. f v w1 sc-. w2 sc-. r) . . f hb w1 where u is a return, and v is a call. Its counterpart denyC(X) \ncontains the dashed edges assuming u is a call, and v is a return.  \n\t\t\t", "proc_id": "2429069", "abstract": "<p>When constructing complex concurrent systems, abstraction is vital: programmers should be able to reason about concurrent libraries in terms of abstract specifications that hide the implementation details. Relaxed memory models present substantial challenges in this respect, as libraries need not provide sequentially consistent abstractions: to avoid unnecessary synchronisation, they may allow clients to observe relaxed memory effects, and library specifications must capture these.</p> <p>In this paper, we propose a criterion for sound library abstraction in the new C11 and C++11 memory model, generalising the standard sequentially consistent notion of linearizability. We prove that our criterion soundly captures all client-library interactions, both through call and return values, and through the subtle synchronisation effects arising from the memory model. To illustrate our approach, we verify implementations against specifications for the lock-free Treiber stack and a producer-consumer queue. Ours is the first approach to compositional reasoning for concurrent C11/C++11 programs.</p>", "authors": [{"name": "Mark Batty", "author_profile_id": "81479651209", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P3977957", "email_address": "mark.batty@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Mike Dodds", "author_profile_id": "81418593776", "affiliation": "University of York, York, United Kingdom", "person_id": "P3977958", "email_address": "mike.dodds@york.ac.uk", "orcid_id": ""}, {"name": "Alexey Gotsman", "author_profile_id": "81322494535", "affiliation": "IMDEA, Madrid, Spain", "person_id": "P3977959", "email_address": "Alexey.Gotsman@imdea.org", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429099", "year": "2013", "article_id": "2429099", "conference": "POPL", "title": "Library abstraction for C/C++ concurrency", "url": "http://dl.acm.org/citation.cfm?id=2429099"}