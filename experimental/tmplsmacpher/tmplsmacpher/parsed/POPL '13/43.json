{"article_publication_date": "01-23-2013", "fulltext": "\n The Rami.cations of Sharing in Data Structures Aquinas Hobor Jules Villard National University of Singapore \nUniversity College London hobor@comp.nus.edu.sg j.villard@cs.ucl.ac.uk Abstract Programs manipulating \nmutable data structures with intrinsic shar\u00ading present a challenge for modular veri.cation. Deep aliasing \ninside data structures dramatically complicates reasoning in isolation over parts of these objects because \nchanges to one part of the structure (say, the left child of a dag node) can affect other parts (the \nright child or some of its descendants) that may point into it. The result is that .nding intuitive and \ncompositional proofs of correctness is usually a struggle. We propose a compositional proof system that \nenables local reasoning in the presence of sharing. While the AI frame problem elegantly captures the \nreasoning required to verify programs without sharing, we contend that natural reasoning about programs \nwith sharing instead requires an answer to a different and more challenging AI problem, the rami.cation \nproblem : reasoning about the indirect consequences of actions. Accordingly, we present a RAMIFY proof \nrule that attacks the rami.cation problem head-on and show how to reason with it. Our framework is valid \nin any separation logic and permits sound compositional and local reasoning in the context of both speci.ed \nand unspeci.ed sharing. We verify the correctness of a number of examples, including programs that manipulate \ndags, graphs, and overlaid data structures in nontrivial ways. Categories and Subject Descriptors F.3.1 \n[Specifying and Veri\u00adfying and Reasoning about Programs]: Logics of programs; D.2.4 [Software/Program \nVeri.cation]: Correctness proofs, Formal meth\u00adods General Terms Languages, Theory, Veri.cation. Keywords \nAliasing, Heap/Shape, Modularity, Separation logic. 1. Introduction Data structures with intrinsic sharing, \nsuch as acyclic and unre\u00adstricted graphs as well as various kinds of overlaid data structures, are pervasive \nin computing. An example of an overlaid data structure can be found in the Linux deadline I/O scheduler, \nin which the set of events forms both a singly linked list and a binary sorted tree, depending on which \nlinks one follows. Programs manipulating data structures with sharing are often short, but the reason \nthat they are correct can be subtle, and previous work has not come up with gen\u00aderal, intuitive and compositional \nprinciples for reasoning about such programs. The key dif.culty is that deep aliasing dramatically com\u00adplicates \nreasoning in isolation over parts of these objects: changes Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 13 January 23 25, 2013, Rome, Italy. Copyright \nc &#38;#169; 2013 ACM 978-1-4503-1832-7/13/01. . . $10.00 to one part of the structure (say, the left \nchild of a dag) can affect other parts (the right child or its descendants) that may point into it. We \npropose a compositional proof system for programs manip\u00adulating shared data structures. Our framework \ndirectly addresses the intrinsic sharing present in the data structures and achieves compositionality \nvia applications of the following ramify rule: RAMIFY tP u c tQu ramifypR, P, Q, R1 q 1 tRu c tRu At \n.rst glance there seems to be no connection between the known spec tP u c tQu and the desired spec tRu \nc tR1u. The connection is given by the rami.cation, indicated by the ramifypR, P, Q, R1qpremise, which \nasserts (semantically, although this paper also provides ways to reason syntactically about it) that \nthe global assertion R becomes R1 after a local transformation from P to Q. The term rami.cation comes \nfrom arti.cial intelligence [Fin87, Thi01] and refers to the problem of understanding the indirect (global) \nconsequences of (local) actions (e.g. relocating a bookcase might reduce the ambient light by blocking \nthe window). Rami.ca\u00adtion is contrasted with the simpler frame problem, which centers on maintaining \nknowledge after unrelated actions (e.g., relocating the bookcase does not change the number of moons \nof Jupiter). Program veri.cation has had signi.cant success handling the frame problem, especially with \nthe frame rule of separation logic [Rey02]: FRAME tP u c tQu tP F u c tQ F u Here the separating conjunction \n ensures that P and F cover disjoint pieces of heap, allowing the frame rule to guarantee that F is unchanged \nunder the action of c. The frame rule buys us compositionality in the presence of the heap: we can reason \nabout the effect a program has on the portions of heap it accesses, and reuse that spec in any bigger \nheap. This has given rise to concise, compositional proofs of programs, even in the presence of some \n forms of sharing where one knows what is shared by whom. Unfortunately, we usually cannot use the frame \nrule directly when verifying programs that manipulate data structures with unre\u00adstricted sharing because \nsuch structures cannot easily be massaged into the form P F : for example, the left and right descendants \nof a dag node are not usually disjoint. The reason to focus on rami.ca\u00adtion rather than frame is that \nthe former allows us to reuse specs for c in far more diverse settings than the latter permits. Of course, \nwith great power comes great responsibility: having isolated the parts of the proof that require careful \nexamination of indirect effects on the global structure, we are left with rami.cation obligations to \nprove. As it turns out, rami.cations are expressible as separation logic def R1 entailments: ramifypR, \nP, Q, R1q R $ P pQ \u00b4 q. These entailments feature the magic wand connective of separation logic ( for \nall states s1 satisfying Q and disjoint from the current state s2, the combination of both states s1 \n s2 satis.es R1 ), which is notor\u00adiously hard to reason about in general given the universal quanti.\u00adcation \nover states. However, appearances of \u00b4 in rami.cations are restricted to a particular idiom that, together \nwith , denotes an up\u00addate to the state. Guided by this intuition, we are able to reduce these spatial \nentailments to more abstract reasoning about the nature of the update on the structure s mathematical \nrepresentation (e.g., graphs as sets of nodes and edges and transformations on said graphs). The veri.cation \nprocess thus divides into two parts: .rst, showing that a concrete program correctly implements some \ntransformation on an abstract mathematical structure; and second, showing that those mathematical transformations \nproduce the desired speci.cation. This division gives us the freedom to describe data structures with \nintrinsic sharing in the most natural way. We will present examples that use the separating conjunction \n of separation logic to reason about genuine disjointness (e.g., between the parent of a dag node and \nits children), the overlapping conjunction Y to reason about unspeci.ed sharing (e.g., between the left \nand right children of a dag node), and the classical conjunction to reason about complete sharing (e.g., \nan overlaid data structure). In contrast to previous work, we achieve compositional reason\u00ading and embrace \nthe sharing. Approaches based on separation logic favored convoluted invariants that hacked the state \ninto the disjoint pieces required by the frame rule. Often the predicate de.nitions de\u00adpended heavily \non the program at hand (e.g. the dag de.nition used could depend on the order of traversal in the algorithm \n[BCO04]). In other words, previous attempts to reason about shared data struc\u00adtures with separation logic \nhave stood on their head to avoid the sharing. Other approaches suffered from these problems at least \nas much and often gave up compositionality altogether [Bor00]. Our key contributions are as follows: \n We present the RAMIFY rule which enables local reasoning while accounting for global effects precisely \nwhen they are re\u00adquired. Rami.cation can reason about programs that manipulate data structures with unrestricted \nsharing while enabling the small speci.cations, compositionality, and expressiveness that have led to \nseparation logic s success.  Although the ramify rule leads to more natural Hoare proofs, the entailment \nchecks can be nontrivial. We have developed a rami\u00ad.cation library of lemmas that help simplify the rami.cation \nconditions. Crucially, we also show how to prove rami.cations concerned with certain general graph and \ndag updates in a way that enables a separation of concern between heap manipulations and mathematical \nreasoning about graphs.  We have applied the ramify rule to a variety of algorithms that manipulate \ndata structures with nontrivial sharing. Although some of the examples are not long, all involve intricate \nreasoning due to the heavy use of sharing. We think that a strength of our approach is that the Hoare \ninvariants at each program point are natural and seem to follow our programmer s intuition much more \nclosely than traditional proofs.  We give a semantic account of rami.cation, and show that RAM-IFY and \nFRAME are each derivable from the other, meaning that our framework is applicable in any separation logic. \nMoreover, we identify the precise constraints on the underlying model that enable the overlapping conjunction \nY , and show that most sepa\u00adration logics in the literature can therefore follow our recipe and use it \nto reason about unspeci.ed sharing.  The rest of the paper is organized as follows: we .rst recall some \nimportant concepts from separation logic (\u00a72). We then motivate and present the ramify rule (\u00a73), and \nshow how to reason about it (\u00a74). Based on this, we provide proof sketches for three examples that showcase \ndifferent aspects of rami.cation: marking a dag (\u00a75), removing from an overlaid data structure (\u00a76), \nand Cheney s garbage collector (\u00a77). Finally, we show how rami.cation is applicable in virtually any \nseparation logic (\u00a78), compare to related works, and conclude. 2. Separation Logic and Trees Recall \nthe framework of separation logic [IO01, Rey02] while con\u00adsidering the following mark procedure, written \nin C, that recursively marks binary trees, dags, or graphs: 1 struct node {int m; struct node *l,*r;}; \n2 void mark(struct node *x) { 3 if (!x || x->m) return; 4 struct node *l = x->l, *r = x->r; 5 x->m = \n1; mark(l); mark(r); } Separation logic allows straightforward inductive de.nitions of predicates to \ndescribe tree-like data structures in the heap. The following de.nition disregards the actual contents \nand location of each node, but does make sure that the structure is acyclic (thanks to the between the \nroot and the subtrees) and that no sharing occurs between subtrees (thanks to the between the children): \ndef treepxq px 0 ^ empq_Dd, l, r. x \u00de\u00d1 d, l, r treeplq treeprqThe de.nition of tree uses the standard \nclassical separation logic operators. A heaplet h satis.es the points-to predicate x \u00de\u00d1 y when h contains \nonly the location x, whose value is y, and the separating conjunction P Q asserts that P and Q hold \non disjoint subheaps. We use x \u00de\u00d1 d, l, r as a shorthand for px ` 0q \u00de\u00d1 d px ` 1q \u00de\u00d1 l px ` 2q \u00de\u00d1 r (simplifying \nthe memory model so that e.g., each datum occupies one unit of space). It is well-known how to use separation \nlogic to prove the mark procedure memory safe for trees. Moreover, the separation logic proof mirrors \nthe programmer s intuitions beautifully. The crux of the veri.cation is to handle the recursive calls \nvia the frame rule, e.g., at line 5, taking the spec of mark as a premise: ttreeplqu mark(l) ttreeplqu \nFRAME tt \u00de\u00d1 1, l, r treeplq treeprqu mark(l) tt \u00de\u00d1 1, l, r treeplq treeprqu (1)  This is a canonical \nexample of how inductive predicates, the separat\u00ading conjunction, and the frame rule .t together to produce \nconcise proofs. Unrolling the tree predicate yields -conjoined formulas, so the proof system, via its \nframe rule, is able to perform surgery on the symbolic state and work on each sub-state independently. \n3. Rami.cations for Sharing We now turn to the case of data structures with sharing, and introduce our \nRAMIFY rule. We begin by de.ning inductive predicates for dags and graphs before presenting the proof \nsketch that we aspire to for the mark procedure when applied to dags. 3.1 Dag and Graph Predicates Our \n.rst task is to de.ne a dag predicate. Since the separating conjunction prevents sharing, our .rst attempt \nupdates tree to utilize regular conjunction ^ between the children instead: def dag0pxq px 0 ^ empq_Dl, \nr. x \u00de\u00d1 l, r pdag0plq^ dag0prqqUnfortunately, in classical separation logic, dag0pxq actually de\u00adscribes \na linked list because the conjunction forces the two sub-dags to occupy exactly the same space in memory \n(h ( P ^ Q if h ( P and h ( Q). However, Reynolds points out that dag0 is correct in in\u00adtuitionistic \nseparation logic, in which x \u00de\u00d1 y holds on any heap that contains at least x, rather than only x [Rey02, \n\u00a76]. Translated into our classical setting this is equivalent to de.ning dags as follows: def dag1pxq \npx 0 ^ empq_Dl, r. x \u00de\u00d1 l, r ppdag1plq trueq^pdag1prq trueqq  If our .rst attempt was in some sense \ntoo small , then our second is too big : dag1pxq holds on any heap that contains at least a dag rooted \nat x. As usual in intuitionistic separation logic, it is impossible to fully verify certain algorithms \n(e.g. showing that dag disposal completely frees the structure) using dag1. What we want is a way to \nget the overlapping features of the intuitionistic conjunction without actually becoming intuitionistic. \nWe turn to another connective, scarcely studied in the published literature, which we dub the overlapping \nconjunction and write Y , and which precisely characterizes the desired sharing: def h |\u00f9 P Y Q Dh1,h2,h3. \nph1 h2 h3 hq^ph1 h2 ( P q^ph2 h3 ( QqThe is the combination operator on the underlying separation \nalgebra [COY07] (often some kind of disjoint union). Contrast the de.nition of Y with the standard de.nition \nof : def h |\u00f9 P Q Dh1,h2. ph1 h2 hq^ph1 ( P q^ph2 ( QqHere are some properties of Y for reference \nand to aid intuition. Lemma 3.1 P Y emp %$ P (2) P ^ Q $ P Y Q (3) P Q $ P Y Q (4) P Y Q $ P true (5) \nP Y Q P Y Q %$ %$ DR. pR \u00b4 P q pR \u00b4 Qq R Q Y P (6) (7) P Y pQ Y Rq%$pP Y QqY R (8) covarpF1q\u00f1 covarpF2q\u00f1 \ncovarp.P. F1pP qY F2pP qq (9) Equations (2), (3), (4) and (5) are immediate from the de.nition of Y . \nWe use quanti.cation over predicates in (6). Commutativity (7) is direct from (6) and the commutativity \nof . In contrast, associativity (8) is trickier and requires cross split (see \u00a78.3). Finally, Lem. (9) \nenables Y to be used in covariant1 recursive predicates, just like and ^. Whenever we write recursive \nde.nitions using Y , including dag and graph below, we are implicitly using (9). The key point to Y is \nthat we can use it in exactly the same places that feature the kinds of sharing that the intuitionistic \n^ captures, but it does not over-approximate the resulting structure. That is, it allows us to de.ne \na classical dag (with a data .eld) as: def dagpxq px 0 ^ empq_ Dd, l, r. x \u00de\u00d1 d, l, r pdagplqY dagprqq \n(10) The separating conjunction between the root x and its children prevents cycles in the data structure. \nPleasingly, the de.nition for graphs simply replaces this remaining with another Y : def graphpxq px \n 0 ^ empq_Dd, l, r. x \u00de\u00d1 d, l, r Y graphplqY graphprq (11) We will equip dag and graph with mathematical \ndags d and graphs . to enable proofs of functional correctness, writing dagpx, dq and graphpx, .q respectively; \nd and . need not be tight and so can include vertices that are unreachable from x. Mathemat\u00adical trees \nlack sharing and are hence directly de.nable as terms; mathematical dags d and graphs . are more complicated \nand so we defer the associated formal de.nitions until \u00a74.2; one key notation is dpxq pd, l, rq, which \nindicates that the mathematical node x is associated with data d and successors l and r. Unspeci.ed Sharing \nObserve that Y models unspeci.ed sharing: i.e., the dag predicate does not say which parts of a dag are \nshared. In contrast, speci.ed sharing requires the precise identi.cation of the shared part, e.g. on \na dag identifying which nodes are shared between the left and right children; often this is very dif.cult. \n1 def covarpF q pP $ Qq\u00f1 F pP q$ F pQq 1 void mark(struct node *x) { // tdagpx,dqu 2 struct node *l,*r; \n3 if (x == 0|| x->m== 1) return; 4 l = x->l; r = x->r; 5 // tx \u00de\u00d1 0, l, r pdagpl,dqY dagpr,dqq ^ dpxq \np0, l, rqu 6 x->m = 1; 7 // tx \u00de\u00d1 1, l, r pdagpl,dqY dagpr,dqq ^ dpxq p0, l, rqu 8 mark(l); \" * x \u00de\u00d1 \n1, l, r pdagpl,mpd, lqq Y dagpr,mpd, lqqq ^ 9 //lp23q dpxq p0, l, rq10 mark(r); \" * x \u00de\u00d1 1, l, r pdagpl,d1qY \ndagpr,d1qq ^ 11 //lp24q dpxq p0, l, rq^ d1 mpmpd, lq, rq12 } // tdagpx,mpd, xqqu Figure 1: Proof sketch \nfor marking a binary dag. The steps that induce rami.cations are indicated with ii, where the associated \nrami.cation entailment is equation number i. On the other hand, sometimes speci.ed sharing is exactly \nwhat the doctor ordered. Although the overlapping conjunction is ex\u00adtremely useful, our framework is \nnot based around it, and one of our key contributions is that RAMIFY can handle both speci.ed and unspeci.ed \nsharing. For an example of speci.ed sharing, see \u00a76, which uses ^ instead of Y ; moreover, see \u00a78.3 for \nhow we can use the explicit overlapping conjunction of Cherini and Blanco [CB09]. 3.2 Rami.cations of \nManipulating Dags Fig. 1 presents the annotated2 proof sketch of the functional correctness of mark when \napplied to dags using the small spec tdagpl,dqu mark(l) tdagpl,mpd, lqqu. The function mpd, xq, whose \nformal de.nition is deferred until \u00a75, indicates the mathemat\u00adical dag derived from d via marking starting \nfrom node x. Notice that this speci.cation immediately implies that if the initial dag is unmarked then \nthe .nal dag is completely marked. As is the case for many recursive programs on graph-like data structures, \npart of the state tracking the recursive exploration of the graph resides in the call stack, which remembers \nwhich states have been only partially processed. Our spec accounts for this complexity while remaining \nlocal (i.e., it only describes the portion of memory accessed by mark), enabling compositional reasoning. \nMoreover, we enjoy straightforward invariants at each program point. Although the invariants are natural, \nthe proof in separation logic is far from obvious. Things are straightforward enough until we reach the \n.rst recursive call at line 8. For tree we applied the frame rule in equation 1, which worked very well. \nWhile we can easily frame away the x \u00de\u00d1 1, l, r from the precondition (line 7), disentangling the two \ndag predicates into dagpl,dq on the one hand and a -disjoint frame on the other would necessitate describing \nthe shape of the right child once everything that is shared with the left child has been removed, which \nis exactly what we wish to avoid. The second recursive call, in line 10, presents exactly the same problem: \nwe wish to frame but cannot. These two recursive calls require a new proof pattern that we call rami.cation. \n 3.3 The RAMIFY Rule While the proof outline of Fig. 1 provides all the invariants needed to prove mark \non dags, FRAME cannot be applied directly to reason about the effect of applying the mark spec on the \nleft child because the left and right child are not disjoint. To solve this issue, we introduce the rami.cation \nrule, which allows the reasoning to 2 We often write e.g. dpxq ... when what we really mean is x \u00f3 v \n^ dpvq ..., where x \u00f3v means that the variable x evaluates to the value v in the current state, because \nmathematical graphs take values rather than variables. We elide these kinds of details for the presentation. \n progress through commands that have indirect global effects: RAMIFY tP u c tQu R $ P pQ \u00b4 R1 q fvpQ \n\u00b4 R1qX 1 modif pcq H tRu c tRu RAMIFY isolates the complicated leap in reasoning at each recursive call \nsite so that the assertions at each program point remain natural, such as in Fig. 1 (e.g., the assertions \nare free from \u00b4 ). No free variables of Q \u00b4 R1 may be modi.ed by c. As usual, magic wand (separating \nimplication) is the adjunct3 of : def1 1 h ( P \u00b4 Q @h.hKh\u00f1 h1 ( P \u00f1 h h1 ( Q Here hKh1 asserts the compatibility \nof h and h1 (Dh2.h h1 h2). Informally, ramify can be read as the result of applying c in a state R \nis R1 if replacing P inside R with Q yields R1 . Magic wand binds more loosely than any other operator. \nRamify is suf.ciently abstract that it can be hard to appreciate. As an initial demonstration of its \npower, observe that the frame rule (modulo some restrictions on free variables as discussed below) is \na direct consequence because P F $ P pQ \u00b4 Q F q. Next, let us apply rami.cation to verify the following \nspec, in which x \u00de1 . x \u00de\u00d1 x 1 \u00d1\u00b4 is the standard notation for Dx . tx \u00de y \u00d1\u00b4u *x=a tx \u00de\u00d1 a Y\u00de \u00d1\u00b4Y\u00de y \n\u00d1\u00b4u RAMIFY emits two subgoals. The .rst precisely matches the stan\u00addard small axiom for store update \nin separation logic: tx \u00de \u00d1\u00b4u *x=a tx \u00de\u00d1 au The second is the following rami.cation entailment, whose \nproof is direct from the associated de.nitions: x \u00de y \u00d1\u00b4$ x \u00d1\u00b4 px \u00de\u00d1 a x \u00de\u00d1 a Y\u00de \u00d1\u00b4Y\u00de\u00de\u00b4 y \u00d1\u00b4q (12) \nFree variables Notice that RAMIFY has a side condition to pacify the usual free variable bugaboo. Usually \nthis is no big deal, but it causes trouble when we want to use rami.cation to verify commands of the \nform x=fp...q, since x is modi.ed and we may want to refer to it in the postcondition. One suf.cient \nsolution, which pleasingly removes all free variable side conditions, is to use variables as resource \n[BCY06], but this introduces other complications. Another solution is to use the following variant of \nthe ramify rule: RAMIFYASSIGN 1 11 tP u x f p...qtQu R $ P pQ \u00b4 rx \u00de\u00d1 x sRq : tRu x fp...qtR1 u : x \n1 R fvpR, R1,P qYvarspfq^ fvpQ \u00b4 R1qXmodif pfq H RAMIFYASSIGN is a consequence of RAMIFY and the usual \nrules for assignment and sequence if we are allowed to make the local pro\u00adgram transformation from x=fp...q \nto x 1 =fp...q;x= x 1 in which x 1 is always chosen fresh. From now on we will sweep free variable issues \nunder the rug, silently using RAMIFYASSIGN when needed. Lookup Because points-to facts may be buried \ninside shared parts of the state, we .nd it convenient to use the global rule for lookup [Rey02] instead \nof the standard local one of separation logic: LOOKUP x 1 R fvpP, yq 11 1 tDx . py \u00de\u00d1 x trueq^rx \u00de\u00d1 \nx sP u x=*y tP u In fact, RAMIFYASSIGN is able to derive LOOKUP from the standard local separation logic \naxiom. 4. Reasoning about Rami.cations To set the stage for the veri.cation of our examples, we now present \ntechniques for general reasoning about rami.cations and link ab\u00adstract mathematical reasoning about graphs \nto spatial rami.cations. 3 That is, and \u00b4 are related by P Q $ R \u00f4 P $ Q \u00b4 R. 4.1 Rami.cation Library \nOur rami.cation library is a collection of lemmas that help reduce complicated rami.cations and related \nentailments. Some of the more general-purpose lemmas, which can handle simpli.cations such as removing \nframes that occur within rami.cations, are grouped in Fig. 2. Other lemmas in our library are speci.c \nto certain data structures such as graphs; we will meet some of these in \u00a74.3. Some of the lemmas in \nFig. 2 require that various predicates be precise, which means that whenever P is satis.ed on a sub-state \ndef (h1 d h3 Dh2.h1 h2 h3), that sub-state must be unique: def precisepP q @h1,h2,h3.h1 d h3 \u00f1 h2 \nd h3 \u00f1 h1 ( P \u00f1 h2 ( P \u00f1 h1 h2 All the predicates we consider here are indeed precise, so this is never \na concern in this paper. Lemmas 4.3 and 4.4 use \u00b4 - , the existential magic wand: def1 h ( P \u00b4 - Q Dh.hKh1 \n^ h1 ( P ^ h h1 ( Q This operator can be tricky because one does not know which copy of P has been \npulled out of Q, but is handy sometimes. Lem. 4.1 allows one to frame away F within an overlapping conjunction \nin order to focus on an easier entailment. Perhaps surprisingly, both P and Q need to be precise for \nit to hold. Lem. 4.2 and 4.3 are analogues of Lem. 4.1 for classical con\u00adjunctions. Although Lem. 4.2 \nis more immediate, the premise R $ P pQ \u00b4 R1q may sometimes be dif.cult to establish. In particular, \none would need to show that P can always be found in a state satisfying R, which is not necessarily the \ncase; it is true in the original rami.cation because the state satis.es pP F q^ R. Lem. 4.3 remedies \nthis by requiring the subtler condition that if P may be found in R, then any way of adding Q instead \nof P yields R1 . We use this lemma to prove the pop program in \u00a76. Lem. 4.4 allows one to ignore parts \nof the state that remain invariant during an update. For instance, a procedure may require some piece \nof state in its precondition that is not modi.ed and thus percolates unchanged to its postcondition. \nFor the lemma to apply, that piece has to be described precisely enough by F that R1 is invariant under \nswapping it for any other satisfying F (third premise). Precision of P is required to force the same \nsub-state of R to satisfy both F true and Q \u00b4 R1 (second and last premises), and R $ P F true makes \nsure that R always contains P F . Finally, Lem. 4.5 and 4.6 allow one to split a rami.cation over either \ndisjoint or overlapping pieces of states into independant rami.cations over each of these states. This \nis crucial to make the proof of some rami.cation entailments modular, for instance when reasoning about \nthe effects of an update on both a global graph and a set of overlapping pointers as in our proof of \nCheney s algorithm (see \u00a77), or when proving the dag copying program of \u00a7A. This rami.cation library \nis by no means exhaustive, nor do we use all of it in the examples presented here. Rather, we think that \nthese lemmas demonstrate that rami.cation entailments can be reasoned about using the intuition that \nthey represent updates to the state. The lemmas we will present in \u00a74.3 for rami.cations on graphs and \ndags further reinforce that claim. 4.2 Exact Graph and Dag Predicates In this section, we de.ne mathematical \ngraphs . and dags d; we will provide ways to reason about rami.cations which involve them in the next \nsection. Before we do so, however, let us consider whether our job would be any easier if we were only \nworried about shape instead of functional correctness, e.g. if we tried to verify mark with the spec \ntdagpxqu mark(x) tdagpxqu. As in Fig. 1, the proof is straightforward until the .rst recursive call on \nline 8. After framing away the root pointer x \u00de\u00d1 1, l, r,we apply RAMIFY, which emits the following entailment, \nin which P 4.1: Frame within Y Rami.cation 4.2: Frame within ^ Rami.cation 1 precisepP, Qq P Y R $ P \npQ \u00b4 Q Y R1 q precisepP q R $ P pQ \u00b4 R1 q pP F qY R $ P pQ \u00b4 pQ F qY R1q pP F q^ R $ P pQ \u00b4 pQ F \nq^ R1q 4.3: Frame within ^ Rami.cation 2 4.4: Exact Frame within Rami.cation P \u00b4 - R $ Q \u00b4 R1 precisepP \nq R $ P F true F \u00b4 - R1 $ F \u00b4 R1 R $ P pQ \u00b4 R1 q pP F q^ R $ P pQ \u00b4 pQ F q^ R1 q R $ P F pQ F \u00b4 \nR1 q 4.5: Disjoint Rami.cation 4.6: Y -piecewise Rami.cation 1111 1 11 R $ P pP \u00b4 Rq S $ Q pQ\u00b4 Sq precisepP, \nP q @i. P Y Qi $ P pP \u00b4 P 1 Y Qiq 1111 1 11 R S $ P Q pP Q\u00b4 R Sq P Y Q1 Y Q2 $ P pP \u00b4 P 1 Y Q1 Y Q2q \nFigure 2: Some general-purpose lemmas from our rami.cation library. and Q are the pre-and postconditions \nfrom the recursive call: R PQR1 hkkkkkkkkkikkkkkkkkkj hkkikkj hkkikkj hkkkkkkkkikkkkkkkkj dagplqY dagprq$ \ndagplq pdagplq\u00b4\u00b4 dagplqY dagprqq Unfortunately, this entailment turns out to be invalid. Recall that \nour rami.cation P pQ \u00b4 R1q idiom represents a state update, in which P is substituted for Q in R to yield \nR1 . Here this means substituting one dagplq for another dagplq, which on its surface seems reasonable. \nThe problem is that the rami.ed away state pQ \u00b4 R1q can have dangling pointers into the local state P \n;if P is mangled too badly as it is transformed into Q then those pointers break in the recombined state \nR1 (here dagplqY dagprq): lr lr  1l2 1 l1 s l1 r r In this example, the update on dag l has freed node \ns and allocated a fresh node l2 instead. Although l is still a dag afterwards, r is not, so we will not \nbe able to prove dagplqY dagprq. This is not an arti.cial problem stemming from our approach. In fact, \nthe failure of the rami.cation entailment indicates that tdagplqu mark(l) tdagplqu is too weak of an \ninductive speci.\u00adcation: overly aggressive changes to the pointer structure of the left sub-dag could \nmake the recursive call to the right sub-dag crash, and we must re.ect that reality in the speci.cation \nfor mark. There are several solutions to this problem, but for this paper choose the most powerful: proving \nfunctional correctness. In \u00a78.3 we will discuss some other possibilities that can yield more lightweight \nshape proofs at the cost of some additional formalism. Mathematical graphs We de.ne the mathematical \nrepresentation of a directed binary graph as a quadruple pV, D, L, Eq, where V is a .nite set of vertices, \nD is some set of data, L : V \u00d1 D is a labeling function associating each vertex v with some data d, and \nE : V \u00d1pV Zt0uq pV Zt0uq associates each vertex with up to two successors. To ease the matching between \na mathematical graph and its heap representation we usually take V A Loc and D D Val. Given a mathematical \ngraph . pV, D, L, Eq, we often write x P . for x P V Zt0u, S D . for S D V Zt0u, and .pxqfor pLpxq,Epxq.1,Epxq.2q. \nWe de.ne the update of . at node v, written rv \u00de \u00d1pd, l, rqs., where l, r P V YtvuZt0u and d P D, as: \nrv \u00de \u00d1pd, l, rqspV, D, L, Eq defpV Ytvu,D, rv \u00de\u00d1 dsL, rv \u00de \u00d1pl, rqsV q . A node y is the successor of \na node x P ., written x y, or simply x y when . is clear from context, if either Epxq py, zq or Epxq \npz, yq for some z. A node y is reachable from x, written . x \u00b0 y or x \u00b0 y,if px, yq is in the re.exive \ntransitive closure . The reachability set of x P ., written reachp., xq, is de.ned as: def. reachp., \nxq ty | x \u00b0 yu We also lift reachability to sets of vertices S tv1,...,vnuD V : def reachp., Sq reachp., \nv1q Y \u00a8\u00a8\u00a8 Y reachp., vnqGiven a graph . pV, D, L, Eq and a set of vertices S D V , it is often useful \nto restrict . to those vertices reachable from (respectively not reachable from) the vertices in S, written \n. \u00d3 S (and respectively . \u00d2 S). Accordingly, we de.ne (where f \u00e7 S is the function obtained from f by \nrestricting the domain to the set S): def . \u00d3 S pV 1 reachp., Sq ,D,L \u00e7 V 1,E \u00e7 V 1q def . \u00d2 S pV 1 \n V zpreachp., Sqq,D,L \u00e7 V 1,E \u00e7 V 1q The quadruple pV 1,D1,L1,E1q . \u00d2 S is not necessarily a graph, \nsince the edge function E1 may point outside of the new set of edges V 1 . However, . \u00d3 S is always a \ngraph: the subgraph of . reachable from S. We sometimes write . \u00d3 x and . \u00d2 x for . \u00d3txu and . \u00d2txu. \nBy convention, if S E V then pV, D, L, Eq\u00d3 S is the empty graph. Spatial graphs We tie a mathematical \ngraph . to a spatial (in\u00adheap) graph by adding . as a parameter to graph: defpx 0 ^ empq_Dd, l, r. .pxq \npd, l, rq^ graphpx, .q x \u00de\u00d1 d, l, r Y graphpl, .qY graphpr, .qNote that graphpx, .q owns only the spatial \nrepresentation of the portion of . that is reachable from x; . may contain other nodes. This is expressed \nby the following lemma, that explodes a graph into its individual nodes. We use the iterative star notation, \nde.ned as emp if the set that is being iterated over is empty and as follows otherwise, given a predicate \nP pxq on x: def xPtx1,...,xnuP pxq P px1q \u00a8\u00a8\u00a8 P pxnq Lemma 4.7 For every graph . pV, Eq and node \nx P ., graphpx, .q%$ vPreachp.,xqv \u00de\u00d1 .pvq Generally speaking, reasoning at this level is undesirable \nin program proofs, and rami.cation crucially allows us to remain at the level of graph instead. However, \nthis lemma is useful both as a sanity check and to prove the general lemmas about ramifying graphs given \nin the next section. We likewise enrich dag with a mathematical graph d: defpx 0 ^ empq_Dd, l, r. dpxq \npd, l, rq^ dagpx, dq x \u00de\u00d1 d, l, r pdagpl, dqY dagpr, dqqMoreover, the predicate dagpx, dq is satis.able \nif and only if d \u00d3 x is indeed a dag, as enforced by the in the spatial predicate: Lemma 4.8 For every \ngraph d and variable x, dagpx, dq%$ graphpx, dq^pd \u00d3 x is acyclicq Finally, we de.ne the following shorthand \nfor describing multi\u00adple sub-graphs of the same graph from a root set S tv1,...,vnu: def graphspS, .q \n graphpv1,.qY \u00a8\u00a8\u00a8 Y graphpvn,.q def dagspS, dq dagpv1,dqY \u00a8\u00a8\u00a8 Y dagpvn,dqIf S H then both predicates \ndenote emp.  4.3 Reasoning about Graph and Dag Rami.cations One advantage of proving functional correctness \nis that we can tightly connect our mathematical reasoning with our spatial reason\u00ading. Here we state \nlemmas that do just that. First, the spatial graph (and thus dag) predicates are precise. Lemma 4.9 For \nall S and ., precisepgraphspS, .qq. Our next lemma lets us reroot collections of sub-graphs provided \nthat we preserve the set of reachable nodes: Lemma 4.10 If reachp., Sq reachp., S1q, then graphspS, .q%$ \ngraphspS1,.q Our third lemma helps us extend a graph with fresh nodes. Lemma 4.11 (Graph Growth) x \u00de\u00d1 \nd, x, x $ graphpx, rx \u00de \u00d1pd, x, xqsq (13) x \u00de\u00d1 d, x, r graphpr, .q$ graphpx, rx \u00de \u00d1pd, x, rqs.q (14) \nx \u00de\u00d1 d, l, r graphsptl, ru,.q$ graphpx, rx \u00de\u00d1pd, l, rqs.q (15) x \u00de\u00d1 d, l, r dagsptl, ru,dq$ dagpx, \nrx \u00de(16) \u00d1pd, l, rqsdq First, (13) a graph cell x whose successors are both itself corre\u00adsponds to a \nsingleton graph rx \u00de4 Second, (14) if a node \u00d1pd, x, xqs. x has a loop to itself on the left and a pointer \nto an existing graph on the right,5 then we can add x to the graph; not shown is the mirrored case when \nthe loop is on the right. Third, (15) if x links to two (possibly equal) graph nodes then we can again \nadd x to the graph. The .rst two cases need to be stated separately because x R . means that graphpx, \n.q is K. Finally, (16) is the analogue of (15) for dags; we do not need analogues for (13) and (14) because \ndags must be acyclic. The frame rule, combined with the between a parent and its descendants and equation \n(16), is enough to mutate the root of a dag. However, an unrestricted graph has Y between the parent \nand its successors, so we need to use RAMIFY to update the root. The following lemma helps discharge \nthe associated rami.cations: Lemma 4.12 (Single Graph Node Update) 11 1 .pxq pd, l, rq .1 rx \u00de,l,r qs. \n\u00d1pd graphsptx, l1 ,r 1uY S, .q$ x \u00de\u00d1 d, l, r 111 1 px \u00de\u00d1 d,l,r \u00b4 graphsptx, l, ruY S, .qq (17) .pxq \npd, l, rq .1 rx \u00de1,l,rqs. \u00d1pd graphpx, .q$ x \u00de\u00d1 d, l, r px \u00de\u00d1 d1,l,r \u00b4 graphpx, .1 qq (18) Lem. 4.11 \nhandles the cases in which we are adding a fresh node, so in (17)-(18) we need only consider the case \nin which tx, l, r, l1 ,r 1uD .. The case of interest is (17), a full update to node x, where we are updating \nnot only the data d to d1 but also the pointers l and r to l1 and r 1 respectively. The precondition \nis a Y -joined set of subgraphs of ., including x, l1 , and r 1 , as well as arbitrary others S. After \nthe update, the state contains subgraphs at x (which now contains l1 and r 1) and S, as well as the old \nl and r (previously contained in the old x), which may now be disconnected from txuY S. In practice we \noften care about far simpler updates; (18) is a direct consequence of (17), and handles the case in which \nwe only wish to update the data .eld. Next, we observe that an update that preserves the set of reach\u00adable \nnodes cannot remove any overlapping points-to fact. The same remark is true of dags as well, replacing \ngraphs with dags every\u00adwhere in the lemma below. 4 rx \u00de ptxu,D, rx \u00de\u00d1 ds, rx \u00d1px, xqsq\u00d1pd, x, xqs def\u00de \n5 Observe that r can be equal to 0, in which case graphpr, .q is just emp. Lemma 4.13 (Points-to preservation) \nreachp.1,S1qE reachp., SqgraphspS, .qY x \u00d1\u00b4$\u00degraphspS, .q pgraphspS1,.1q\u00b4\u00b4 graphspS1,.1qY x \u00de\u00d1\u00b4q Our \n.nal lemma applies when we wish to update an entire subgraph (typically with a function call) rather \nthan a single node. Lemma 4.14 (Subgraph Update) 11 1 reachp.,S1qE reachp., S1q .1 \u00d2 S1 . \u00d2 S1 graphspS1,.qY \ngraphspS2,.q$ graphspS1,.q 11 1 pgraphspS1,.1q\u00b4\u00b4 graphspS1,.1qY graphspS2,.qq (19) 11 1 reachpd,S1qE \nreachpd, S1q d1 \u00d2 S1 d \u00d2 S1 dagspS1,dqY dagspS2,dq$ dagspS1,dq 11 1 pdagspS1,d1q\u00b4\u00b4 dagspS1,d1qY dagspS2,dqq \n(20) First, (19) lets us ramify an update to a subgraph (or set of subgraphs) as long as all previously \nreachable nodes are still reachable (to prevent e.g. the dangling pointer problem outlined in \u00a73.3) and \nthe mathematical update is local. Second, (20) gives us the same property for dags (if our newly substituted \nsub-dag does not contain a cycle then our whole dag will not suddenly become cyclic). 5. Proving mark \non Dags We are ready at last to polish off the proof of mark from Fig. 1. Mathematical marking One of \nour goals is to translate mathe\u00admatical reasoning into spatial reasoning. De.ne the mathematical marking \nmp., rq of a graph . pV, D, L, Eq starting from the vertex r P V as marking all nodes reachable via unmarked \nnodes from r. Formally, de.ne a new relation . 0 as follows: x . 0 y iff Dz. .pxq p0,y,zq_ .pxq p0,z,yqAs \nbefore, we omit the subscript . when it is clear from context and write . \u00b0 for the re.exive transitive \nclosure. The marking mp., rqof . from 0 r is then pV, D, L1,Eq where, for all x P V , # \u00b0 1 1 if r 0 \nx Lpxq Lpxq otherwise We also need to describe the effect of marking a single node in ., accomplished \nwith m1p., xq, that sets the marked bit of node x in . to 1. The following lemma about mathematical markings \nnow becomes crucial to prove the functional correctness of mark. Lemma 5.1 For all graphs . and nodes \nx, y P ., mpmp., xq,yq mpmp., yq,xq (21) Moreover, if .pxq pd, l, rq, then mpmpm1p., xq,lq,rq mpm1pmp., \nlq,xq,rq m1pmpmp., lq,rq,xq mpm1pmp., rq,xq,lq mp., xq (22) That is, (21) we can swap the order of two \nmathematical markings, and (22) regardless of which order we mark the root and children (either child \n.rst by equation 21), at the end we are fully marked. Spatial marking Our .rst remaining tasks are the \nrami.cations on lines 9 and 11. In both cases we frame away the root node and then apply RAMIFY, yielding \nthe following entailments: dagpl,dqY dagpr,dq$ dagpl,dq pdagpl,mpd, lqq \u00b4 (23) dagpl,mpd, lqq Y dagpr,mpd, \nlqqqdagpl,mpd, lqq Y dagpr,mpd, lqq $ dagpr,mpd, lqq pdagpr,mpmpd, lq, rqq \u00b4 (24) dagpl,mpmpd, lq, rqq \nY dagpr,mpmpd, lq, rqqq Observe that the .rst rami.cation directly implies the second by instantiating \nd with mpd, lq in the .rst entailment and using the commutativity of Y to swap the roles of l and r. \nTo prove (23),we apply Lem. 4.14 to reduce the spatial rami.cation entailment to a pair of mathematical \nsubgoals. The .rst mathematical subgoal, reachpmpd, lq, lqE reachpd, lq, i.e., that every vertex reachable \nfrom l in the old dag d is still reachable from l in the new dag mpd, lq, is immediate because the mathematical \nmarking function m changes neither the vertices nor the edges of the dag d. The second mathematical subgoal, \nmpd, lq\u00d2 l d \u00d2 l, i.e., that the part of d that is not reachable from l is identical to the part of \nmpd, lq that is not reachable l, is almost as simple. By the de.nition of m, we know that the only difference \nbetween d and mpd, lq is that the new labeling function has marked vertices reachable via unmarked paths \nin d from l; all other labels are maintained. Since the second mathematical subgoal only cares about \nchanges to the portion of the mathematical graph that is not reachable from l, and those labels are unchanged, \nwe are done. Finally, to establish the postcondition in line 12 from line 11, apply Lem. 4.11 to derive \ndagpx,m1pmpmpd, lq, rq, xqq, which by Lem. 5.1 is equivalent to our postcondition. 5.1 Observations \nOur proof of mark (i.e., Fig. 1 and \u00a75) is short and our invariants at each program point are straightforward. \nWe were able to reuse our initial rami.cation (23) to prove our second (24). Essentially all of the spatial \ndif.culties were handled by our rami.cation library. Moreover, by Lem. 5.1 our proof is easy to modify \nto accommodate trivial changes in the program like moving the update in line 6 to after one or both of \nthe recursive calls in lines 8 and 10, swapping the order of the recursive calls, etc. Our ability to \naccommodate these kinds of changes is an indication of the power of using rami.cation to separate mathematical \nand spatial reasoning from each other. In contrast, previous work on verifying these kinds of algorithms \nused complex and brittle invariants so that they could always apply the frame rule. For example, consider \nBornat et al. [BCO04], which is the progenitor of most previous work in applying separation logic to \nreason about data structures with intrinsic sharing. Bornat et al. de.ne mathematical dags as tree-shaped \nterms whose nodes are either labeled proper nodes (written x : Node dl dr) or references to a label elsewhere \nin the dag (written Ptr x)toex\u00adpress sharing. Their spatial pdag predicate grants ownership of a node \nat the point that corresponds to where it is declared in the math\u00ad def ematical de.nition (roughly speaking, \npdag x px : Node dl drq x \u00de\u00d1 v, l, r pdag ldl pdag rdr), but not when it is referenced def again (similarly, \npdag x pPtr xq emp). Each node can only be declared once (although it may be referenced many times), \nand the order in which they are declared must match the order in which the program traverses the dag, \nas the authors note [BCO04, \u00a78, p. 7]: This predicate is speci.cally designed to support a left to right \nscan, as are the formulae on which it is based. It seems dif.cult to avoid this complication. Unfortunately, \nthe consequences of this style of de.nition ricochet to many other parts of the associated veri.cation, \nincluding the statement of the speci.cation of mark and its exact implementation. Changes in one part \nof the system (e.g., swapping the order of traversal) required changes to other parts of the system (i.e., \nthe de.nition of pdag, the speci.cation of mark, and the invariants at each program point). Altogether, \nthe style of hacking the state into many disjoint pieces to reason about data structures with intrinsic \nsharing pays a heavy price to enable the frame rule, resulting in dauntingly subtle [BCO04, \u00a78.4, p. \n9] de.nitions and veri.cations. In contrast, our de.nition of mathematical graphs is traditional, our \ndag predicate is natural, and our speci.cation for mark is straight\u00adforward. None of these depend on \ninternal implementation speci.cs of the algorithm such as traversal orders. Moreover, our program invariants \nare easy to understand, easy to update to accommodate minor changes in the algorithm, and easy to verify \nusing rami.cation and our rami.cation library. Veri.cations utilizing rami.cations are both more natural \nand more robust than those in previous work. Marking possibly cyclic graphs The mark function can also \nmark unrestricted graphs. Because Lemmas 4.14 and 5.1 both apply to graphs as well as dags, the only \nsubstantial change to the the proof in Fig. 1 is for line 6. Here dags only require the frame rule due \nto the between a parent and its children but unrestricted graphs require an additional rami.cation due \nto the additional Y : x \u00de\u00d1 0, l, r Y graphsptl, ru,.q$ x \u00de\u00d1 0, l, r px \u00de\u00d1 1, l, r \u00b4 x \u00de\u00d1 1, l, r Y graphsptl, \nru,m1p., xqqq This rami.cation follows directly from Lem. 4.12. Termination Our work here is primarily \nconcerned with partial correctness, but suppose we were interested in total correctness as well. The \ndag argument is simpler: each recursive call is on a strictly smaller subheap thanks to the between \na parent and its children; notice that this argument is valid regardless of whether we mark the root \n.rst, at line 6, or after one or both recursive calls. In contrast, the termination argument on unrestricted \ngraphs is more complicated because the Y between root and successors means that the subheap may not be \nany smaller at the recursive calls. Instead, each recursive call must be on a graph with fewer unmarked \nnodes; if we recurse before coloring the root then we may not terminate. 5.2 Other Graph Algorithms \nTo prove that rami.cation can apply equally well to programs that, unlike mark, mutate the link structure \nof the graph, we also veri.ed copy_dag and dispose_graph. The full details are in Appendices A and B \nrespectively; here we give only the key insights. Copying dags The goal of the copy_dag function is to \nmake a deep (structure-preserving) copy of its argument. It uses a data .eld in each original node to \nrecord the location of its corresponding copy (or 0 if the node has not yet been copied). Just as with \nmark, a straightforward recursive implementation is compact and works as follows. If the root is already \ncopied then return immediately; otherwise, recursively copy the left and right children, allocate a new \nnode to be the root s copy, and set its .elds as appropriate. To make the veri.cation hang together, \nwe need to add a new fea\u00adture to our separation logic: regions [LG88]. Brie.y, regions indicate disjoint \nzones in the heap, and a spatial predicate P can be tagged with a region identi.er a to become Pa, indicating \nthat P is entirely contained in region a. Predicates in different regions are always disjoint, even when \nconnected by sharing operators such as Y . Regions are useful when we are faced with the following prob\u00adlem, \nin which 7 is some sharing operator such as ^ or Y : ? pP Qq7pR Sq %$ pP 7Rq pQ7Sq That is, we have \nsome disjoint formulas P and Q, which overlap with two additional disjoint formulas R and S, and we wish \nto shuf.e resources around until the P and Q are overlapping with each other and are disjoint from the \noverlapping Q and S. The % direction is immediate. Unfortunately, verifying copy_dag requires the $ direction \nafter making both recursive calls and reaching the following invariant, in which l and r are the left \nand right children of the root and ll and rr are their respective copies: pdagpl,dq dagpll,d1 qq Y pdagpr,dq \ndagprr,d1 qq Now we need to apply the rule of consequence to disentangle the original children from \ntheir overlapping copies: pdagpl,dqY dagpr,dqq pdagpll,d1qY dagprr,d1 qq  1 struct node { struct node \n*next ,*l,*r; }; 2 void pop(void){ //tlistpsq^ treeptqu 3 if (!s) return; 4 struct node *c = s; 5 // \ntps \u00de\u00d1 n, l, r listpnqq ^ treeptq^ c su 6 s = c->next; 7 // tpc \u00de\u00d1 s,l,r listpsqq ^ treeptqu 8 // \ntpc \u00de\u00d1 s,l,r listpsqq ^ psktreept,p Ztcuq ptrspp Ztcuqqu 9 t = tree_del(t,c); 10 //ltpc \u00de\u00d1 s, \u00b4, \u00b4 \nlistpsqq ^ psktreept,pq c \u00d1\u00b4\u00de, \u00b4, \u00b4 ptrsppqqu11 // tplistpsq^ treeptqq c \u00d1\u00b4\u00de, \u00b4, \u00b4u 12 free(c); 13 } \n// tlistpsqq ^ treeptqu Figure 3: Removal from a threaded tree. The problem is that the implication is \njust not true without carrying around some additional information via regions: speci.cally, that the \noriginal dag is in region a while the copy is being created in region \u00df. In general regions help because \nthey ensure that P does not have any overlap with S despite the intermediate sharing operator 7: pPa \n Q\u00df q7pRa S\u00df q%$pP 7Rqa pQ7Sq\u00df (25) Others have run across the same problem in diverse contexts including \nRGSep [Vaf07] and shape analysis for overlaid lists and trees [LYP11] and have turned to regions for \nsimilar reasons. Interestingly, our veri.cation also uses regions in an novel way to split one large \nrami.cation entailment (equation 35) into two smaller entailments via Lem. 4.5 from our rami.cation library. \nThis second use of regions is not vital to verify copy_dag, but it does simplify things nicely. Other \nthan the use of regions, the veri.cation proceeds straightforwardly. Disposing graphs Disposing a graph \nis usually done in two steps: .rst, suppress all sharing between nodes of the graph, so that each node \nhas at most one predecessor, thus computing a spanning tree of the graph; and then dispose the tree. \nApx. B contains the novel veri.cation for the .rst step; verifying the second is standard. The real proof \neffort is on the mathematical side; the spatial aspects of the veri.cation are no more complicated than \nmark and copy_dag, and do not require regions. Because our de.nition for graph uses Y , we are able to \nestablish emp at the end, indicating that we have completely freed the structure. 6. Overlaid Data Structures \n Reasoning about threaded trees Our examples so far have fo\u00adcused on graph manipulations. Rami.cation \nis also applicable in other interesting contexts, including overlaid data structures. Here we focus on \none kind of overlaid structure: threaded trees, which overlay lists and trees. Each node has three links \nto other nodes of the data structure: a next pointer of a singly-linked list, and the left and right \n.elds of a binary tree. This is a popular type of overlaid data structure: the linked list may record \nthe set of elements some order of particular interest (e.g., .rst-inserted to most recent), while the \ntree provides ef.cient out-of-order lookup. Our case study is a procedure that removes the .rst element \nof the linked list from the data structure, inspired by what can be found in the Linux deadline I/O scheduler \n[LYP11]. The code and annotations are shown in Fig. 3. It assumes two global variables s and t that point \nrespectively to the head of the linked list and the root of the tree. The precondition states that the \ntwo shapes span exactly the same memory cells, enforced by the conjunction ^. Removing from the list \n(line 6) merely advances the head pointer, but we cannot stop there because it leaves the overlaid structure \nin an inconsistent state (the items in the list and the tree must be identical). Removing from the tree \nis likely to be operationally complex, potentially involving operations to rebalance, reroot, or otherwise \nrotate parts of the tree. Thus, we abstract this operation and assume that it is performed by a function \ntree_del(t,c). Its spec has to express two particular facts to ensure that it is well-behaved w.r.t. \nthe overlaid list structure: it must not tamper with the list .elds, and the resulting new tree should \ncover the same nodes as before except for c. We enforce the .rst constraint by not giving any access \nrights on the list .elds to the procedure, i.e. by restricting its precondition to the skeleton of the \ntree, and the second constraint by recording the set of nodes encompassed in the tree shape. We therefore \nde.ne the following predicate that skips the list .elds of each node: def sktreepx, pq px 0 ^ emp ^ \np Hq _ Dl, r, pl,pr. x ` 1 \u00de\u00d1 l, r sktreepl, plq sktreepr, prq^p txuZ pl Z pr The tree predicate can \nbe split into a skeleton and a bag of points-to predicates, using the pointers predicate ptrs: ptrsptx1,...,xnuq \n \u00de\u00de defx1 \u00d1\u00b4 \u00a8\u00a8\u00a8 xn \u00d1\u00b4 treeptq\u00f4Dp. sktreept, pq ptrsppq (26) The list predicate is de.ned in the standard \nway for nil-terminated acyclic lists with two data .elds: def11 1 listplq pl 0 ^ empq_Dl,x,y.l \u00de\u00d1 l,x,y \n listplq We moreover assume that each address is aligned as a multiple of 3, to prevent skewing, in \nwhich a node in the tree might overlap two nodes in the list in a state satisfying listpsq^ treeptq. \nA general observation about how overlaid data structures are manipulated is that changes to .elds of \nonly one structure do not affect the other, e.g., list induction easily proves that x \u00de\u00d1 n, l, r \u00b4 - \nlistpsq$ x \u00de\u00d1 n, l1 ,r 1 \u00b4 listpsq This reads as: if a state may be completed by a node to form a linked \nlist, then completing it by any other node at the same location and with the same next .eld also yields \na list. The same property for skeleton trees follows by induction on the size of the tree: sktreept, \npq\u00b4\u00b4- listpsq$ sktreept 1,pq\u00b4\u00b4 listpsq (27) Veri.cation The spec of tree_del follows the discussion above: \ntsktreept, pZtcuquu=tree_del(t,c)tsktreepu, pq c`1 \u00de \u00d1\u00b4, \u00b4u The proof sketched in Fig. 3 is mostly straightforward: \nif s is nil then the list is empty, hence so is the tree and the postcondition is trivially satis.ed; \notherwise, we unfold the list predicate, which enables the lookup at line 6. After that, we split the \ntree according to (26) and apply the following rami.cation: pc \u00de\u00d1 s,l,r listpsqq ^ psktreept,p Ztcuq \n ptrspp Ztcuqq$ sktreept,p Ztcuq `c ` 1 \u00de\u00d1\u00b4, \u00b4 sktreept1,pq\u00b4\u00b4 pc \u00de\u00d1 s, \u00b4, \u00b4 listpsqq ^ pc ` 1 \u00de1,pq \nptrspp Ztcuqq . \u00d1\u00b4, \u00b4 sktreept This rami.cation follows a general pattern, and we can reduce it to a \nmuch simpler one by noticing that the right-hand side conjunct is automatically handled by Lem. 4.3 from \nour rami.cation library, which can remove frames that occur within ^ rami.cations. This yields the following \nsimpler proof obligation: sktreept, p Ztcuq \u00b4 - c \u00de\u00d1 x, y, z listpsq$ c ` 1 \u00de1,pq\u00b4 c \u00de\u00d1 x, \u00b4, \u00b4 listpsq \n\u00d1\u00b4, \u00b4 sktreept\u00b4 This entailment is similar to (27). The rest of the proof is immediate. 7. Cheney s \nGarbage Collector It is time for the acid test: verifying the functional correctness of Cheney s garbage \ncollector [Che70]. The general setting is as follows. There are two disjoint, equally large regions of \nmemory, the from-space and the to-space, starting respectively at the address pointed to by from and \nto. Programs manipulate objects in the from\u00adspace. When the program wishes to allocate but the from-space \nhas run out of room, we garbage collect by copying the entire graph of reachable objects into the to-space \nbefore swapping from and to and resuming normal execution. If the former from-space had any unreachable \nobjects then the new from-space has some free space. In the tradition of previous work, we make a number \nof simpli.\u00adcations. We assume that there is a single root from which all active objects are reachable, \ni.e. any object not reachable from that root can be safely reclaimed. We also restrict our study to even-aligned \ntwo\u00ad.eld objects that contain only pointers (including the null pointer) rather than arbitrary integers. \nOur proof can be modi.ed to verify the unsimpli.ed algorithm; e.g., we can allow data by the usual systems \nhack of requiring that data be odd and pointers be even. Remarkably, Cheney s algorithm migrates the \ngraph from one space to the other using only a constant amount of extra memory, which is in short supply \nduring garbage collection. Contrast this with our dag-copying example of \u00a7A that required linear additional \nspace (in both the data .elds and the function stack). The cost is that we mangle the original graph, \nwhich we can live with because afterwards it will be garbage. The trick is that Cheney rewires the .rst \n.eld in each already-copied object in the from-space to point to its copy in the to-space. The collector \ncan determine whether an object has already been copied, and moreover discover the copy s address, by \nchecking if its .rst .eld points into the to-space. Following [Gas11], we implement the algorithm as \ntwo func\u00adtions: collect and copy_ref, shown in Fig. 4. In addition to the to and from pointers (.xed \nfor the duration of the collection), they maintain two additional pointers into the to-space. First, \nthe scan pointer separates the fully-processed scanned objects, whose point\u00aders point into the to-space, \nfrom the partially-processed queued objects, whose pointers point into the from-space. Second, the free \npointer distinguishes the .rst unused address in the to-space. Initially (line 3), scan free to, meaning \nthat no objects have been copied and the entire to-space is free. The process is initiated by copying \nthe object pointed to by the root r (line 4), which allocates two cells of memory at the beginning of \nthe to-space by increasing free and .lls them with the values in the original object, now enqueued. After \nthat the program loops (lines 5 12) until no queued objects remain, calling copy_ref on both object .elds \n(lines 8 and 11) before incrementing scan to indicate that the object has been scanned. Each call to \ncopy_ref swings the from-space pointers into the to-space, queuing newly encountered nodes as necessary. \nFig. 5 presents an intermediate state in the execution, with one node copied and scanned and one node \nqueued for scanning. Formal speci.cation To represent states of the execution we use the following de.nitions. \nMathematical graphs are pairs pV, Eq, i.e. we remove D and L, and the spatial predicate is accordingly \ndefpx 0 ^ empq_Dl, r. .pxq pl, rq^ graphpx, .q x \u00de\u00d1 l, r Y graphpl, .qY graphpr, . q We de.ne shorthand \nto express whether a node is in the from-or to-space and whether it has been copied (recall that to, \nfrom and size are constant throughout the execution): def from pxq x 0 _ from d x a from ` size def \ntopxq x 0 _ to d x a to ` size def copied p., xq x 0 ^ from pxq^ top.pxq.1q We write from p.q for \n@v P .. from pvq and similarly for top.q. The memory also contains a pool of free addresses, starting \nat some x, and the whole from-space, which we use to collect nodes that the algorithm disconnects (i.e., \nfrom-space objects that are no longer reachable from the to-space and are therefore fresh garbage): def \npoolpxq ptrsptx,..., to ` size \u00b4 1uq def fromsp ptrsptfrom,..., from ` size \u00b4 1uq The main end-to-end \nproperty of a garbage collector is that the .nal graph is isomorphic to the original one. In the middle \nof a 1 void collect ( void ** r ) { 2 // tpr \u00de\u00d1 r0 graphpr0,.0qY fromspq poolptoq^ from p.0qu 3 scan \n= free = t o ; 4 copy_ref ( r ); 5 while ( scan ! = free ) \" * r \u00de\u00d1 to pgraphpto,.qY fromspq poolpfreeq^6 \n// .@to \u00ab .0@r0 ^ cheneyp., scan, freeq $ , &#38;r \u00de\u00d1 to pgraphpto,.qY scan \u00de\u00d1 q0,q1 Y graphpq0,.qY \n. 7 { // graphpq1,.qY fromspq poolpfreeq^ .@to \u00ab .0@r0 ^ %cheneyp., scan, freeq^ scan d free \u00b4 2 \u00ad8 c \no p y _r e f ( scan ) ; $ , r \u00de\u00d1 to pgraphpto,.1qY scan \u00de\u00d1 q0 1 ,q1 Y graphpq0 1 ,.1qY / &#38; . graphpq0,.1qY \ngraphpq1,.1qY fromspq poolpfreeq^ 9 //l .@to \u00ab .0@r0 ^ scan d free \u00b4 2 ^ $ % cheneyp.1 , scan ` 1, freeq^ \n.1@to \u00ab .@to ,/\u00ad&#38;r \u00de\u00d1 to pgraphpto,.1qY fromspq poolpfreeq^ . 10 // % .1@to \u00ab .0@r0 ^ cheneyp.1 , \nscan ` 1, freeq^ \u00ad scan d free \u00b4 2 11 c o p y _r e f ( scan + 1); 12 scan = scan + 2 ; } \" * r \u00de\u00d1 to \n graphpto,.q fromsp poolpfreeq^ 13 } // top.q^ .@to \u00ab .0@r0 14 15 void copy_ref ( void ** p ) { 16 \n// pp \u00de\u00d1 q Y graphpq, .qq poolpfq^ cheneyp., p,fq^ free f 17 if (* p ) { \" * pp \u00de\u00d1 q Y q \u00de\u00d1 a, b Y \ngraphpa, . qY graphpb, . qq 18 // poolpfq^ cheneyp., p,fq^ free f 19 void * obj = * p ; 20 void * \nfwd = * obj ; \" * pp \u00de\u00d1 obj Y obj \u00de\u00d1 fwd,b Y graphpfwd,.qY graphpb, . qq 21 // poolpfq^ cheneyp., p,fq^ \nfree f 22 if ( t o <= f wd &#38; &#38; f w d < t o + size ) { \" * pp \u00de\u00d1 obj Y obj \u00de\u00d1 fwd,b Y graphpfwd,.qY \ngraphpb, . qq 23 // poolpfq^ cheneyp., p,fq^ free f ^ topfwdq24 $ *p = f w d ; ,&#38;pp \u00de\u00d1 fwd Y obj \n\u00de\u00d1 fwd,b Y graphpfwd,.1qY graphpb, . 1qq . 25 //l poolpfq^ cheneyp., p,fq^ free f ^ topfwdq^%cheneyp.1 \n, p ` 1,fq^ .1 rp \u00de\u00d1 fwds. \u00ad 26 } else { \" * pp \u00de\u00d1 obj Y obj \u00de\u00d1 fwd,b Y graphpfwd,.qY graphpb, . qq \n27 // poolpfq^ cheneyp., p,fq^ free f ^ from pfwdq28 void * new = free ; 29 free = free + 2 ; 30 *n \ne w = *o b j; 31 $ * ( new + 1) = * ( obj + 1); ,&#38;pp \u00de\u00d1 obj Y obj \u00de\u00d1 fwd,b Y graphpfwd,.qY graphpb, \n. qq . 32 // % new \u00de\u00d1 fwd,b poolpfreeq^ free f ` 2 ^ \u00adcheneyp., p,fq^ from pfwdq^ new f $ , pp \u00de\u00d1 \nobj Y obj \u00de\u00d1 fwd,b Y new \u00de\u00d1 fwd,b Y / &#38; . graphpfwd,.1qY graphpb, .1qq poolpfreeq^ 33 // free \nf ` 2 ^ cheneyp., p,fq^ from pfwdq^ % /\u00ad new f ^ .1 rnew \u00de\u00d1 fwd,bs. 34 * o bj = new ; $ , pp \u00de\u00d1 obj \nY obj \u00de\u00d1 new,b Y new \u00de\u00d1 fwd,b Y / &#38; . graphpfwd,.2qY graphpb, .2qq poolpfreeq^ 35 //l cheneyp., \np,fq^ free f ` 2 ^ from pfwdq^ /\u00ad % new f ^ .2 robj \u00de\u00d1 newsrnew \u00de\u00d1 fwd,bs. 36 *p = n e w ; $ , pp \n\u00de\u00d1 new Y obj \u00de\u00d1 new,b Y new \u00de\u00d1 fwd,b Y / &#38; . graphpfwd,.1qY graphpb, . 1qq poolpfreeq^ 37 //l cheneyp., \np,fq^ free f ` 2 ^ from pfwdq^ % /\u00ad new $ f ^ .1 rp \u00de\u00d1 newsrobj \u00de\u00d1 newsrnew \u00de\u00d1 fwd,bs. ,&#38;pp \u00de\u00d1 \nq1 Y graphpq1,.1qY graphpq, . 1qq poolpfreeq^ . 38 }}} // % cheneyp.1 , p ` 1, freeq^ .@to \u00ab .1@to^ \n\u00ad.1 \u00d2tp,q,q1u . \u00d2tp,qu^ free e f Figure 4: Proof sketch of Cheney s garbage collector.  to scan free \nFigure 5: Transient state of the memory during garbage collection. Previous .eld values are indicated \nby 0 or dotted pointer arrows. def cheneyp., s, f q topsq^ topf q^ |tv | copied p., vqu| pf \u00b4 toq{2 \n^ (28) tto,...,f \u00b4 2uD . \u00d3 to ^ (29) @v P .. @a, b. .pvq pa, bq\u00f1 . topvq^ppv a s ^ topaqq _ pv e s ^ \nfrom paqqq^ _ (30) ppv`1 a s ^ topbqq _ pv`1 e s ^ from pbqqq `. from pvq^ from pbq^ptopaq\u00f1 .@b \u00ab .@p.paq.2qq \n(31) Figure 6: Cheney graphs. Parameter s is the .rst unscanned address and f is the beginning of the \nfree space. There are as many nodes in the to-space as there are copied nodes (28), which ensures that \nwe never exhaust our free space at line 29. Every cell in the to-space is reachable (29). For each object, \neither (30) it is in the to-space and either scanned with .elds pointing to the to-space, or queued with \n.elds pointing to the from-space; or (31) it is in the from-space, with .elds either entirely pointing \nto the from-space or with .rst .eld pointing to its copy in the to-space, in which case the second .elds \nof the object and its copy point to isomorphic sub-graphs. collection, the loop invariant is more complex; \nfor Cheney it is that the graph rooted at to is isomorphic to the original one up-to a canonicalization \nfunction, canon p.q. The canonicalization of a graph . pV, Eq skips already copied nodes by following \ntheir .rst .eld (which points to their copies). Formally, canon p.q is the graph pV 1,E1q where V 1 tv \nP V |.copied p., vqu and, if Epxq pv1,v2q, then E1pxq pv1 1 ,v2 1 q with # 1 Epviq.1 if copied p., viq \nv i vi otherwise We write .@x \u00ab .1@x 1 to denote graph isomorphism between canon p.q\u00d3 x and canon p.1q\u00d3 \nx 1. Both from p.q and top.q imply canon p.q ., so at the end of garbage collection, when the entire \ngraph has been moved into the to-space, we will have standard isomorphism between the old graph and the \nnew. The main constraints satis.ed by the graph are enforced in the mathematical world by the cheney \npredicate shown in Fig. 6. Additionally, the following invariant is implicit throughout the proof: to \nd scan d free a to`size ^ evenpfrom, to, scan, free,.q Here even forces all objects and global pointers \nto be aligned on even boundaries. Notice that a graph entirely in the from-space is automatically a Cheney \ngraph: from p.q\u00f1 cheneyp., to, toq. Similarly, if to P . and s f then cheneyp., s, f q\u00f1 top.q. These \nobservations are enough to go from the precondition to the loop invariant, and from the loop invariant \nto the postcondition. Veri.cation of copy_ref We omit the (simpler) spec of copy_ref that applies the \n.rst time it is called in collect (line 4) and focus instead on the calls made from the main loop (lines \n8 and 11). copy_ref swings one .eld of a queued object from its original target in the from-space to \nits target s copy in the to-space. If the target is 0 then no action is required and the post is direct \nfrom the pre. Otherwise, we can unfold the graph (line 16) to expose the target object in the from-space. \nWe then examine its .rst .eld, fwd. If fwd is in the to-space, then the target object has a copy located \nthere and we swing the pointer to it. The rami.cation immediately follows from Lem. 4.12, slightly modi.ed \nto handle single-.eld updates, and updates the graph to .1 rp \u00de\u00d1 fwds. (where a single .eld update rx \n\u00de\u00d1 ys. corresponds to rx \u00de\u00d1 y, .pxq.2s. if x is even and to rx \u00b4 1 \u00de\u00d1 .pxq.1,ys. if x is odd). The actual \nproof effort at that point is to mathematically establish cheneyp.1 , p`1, freeq and .@to \u00ab .1@to. The \nformer holds because the only update is that p changed from queued in . to scanned in .1 (p a p ` 1) \nand from pointing to the from-space to the to-space. For the latter, notice that canon p.qppq fwd, so \nswinging p to point to fwd gives the same canonical graph: canon p.q canon p.1q, hence .@to \u00ab .1@to. \nIf the object has not been copied yet, we reserve two units of space at the position of the free pointer \n(by advancing it, line 27), and .ll them with the object s .elds. Since the pool of free space is kept \n-separated from the current graph of objects, F RAME is able to deal nicely with the heap mutations up \nto the assignment at line 35. Now we rewrite the state to integrate the new object into the main graph \n(Lem. 4.11), then swing both the current .eld p and the .rst .eld of the target object obj to point to \nthe copy new, yielding two successive rami.cations that update the global graph accordingly, which we \ncan discharge with Lem. 4.12. Once again, RAMIFY and our library allow us to progress past updates to \nthe shared state; the actual complexity resides in establishing mathematical facts about graphs in the \npostcondition. Their proof is similar to the case in which fwd was in the to-space to begin with. We \nhave to prove that new is reachable from to, as required by 29, which holds because p is reachable from \nto and points to it. The isomorphism holds because new and obj have identical contents. Veri.cation of \ncollect The main function .rst copies the root node in the graph using an alternative (simpler) spec \nfor copy_ref to establish the loop invariant (line 6, in which we leave out the case r0 0 of an empty \ngraph). It then enters a loop that updates both .elds of the .rst unscanned object in succession (which \nmay queue up new objects), repeating until all objects have been scanned. The looping condition allow \nus to go from the invariant at line 6 to the assertion at line 7 (in particular, to \u00b0 scan by (29) so \nLem. 4.10 applies). The rami.cation at line 9 makes interesting use of our rami.cation library. Lem. \n4.13 tells us that each individual pointer in fromsp (as well as the other .eld of scan) is preserved. \nCombining this with Lem. 4.6 yields that the whole of fromsp is preserved. The graphs are updated thanks \nto Lem. 4.14. We .nally combine both our conclusions with another application of Lem. 4.6. To deduce \nline 10, we fold back the sub-graph rooted at scan into the main one rooted at to, which leaves the following \nspatial deduction, which holds because, together, graphpto,.1q and fromsp contain the whole allocated \nheap: graphpto,.1qY graphpq0,.1qY fromsp $ graphpto,.1qY fromsp The second call to copy_ref is analogous \nto the .rst, and after we advance scan we reach the loop invariant.6 Related work Cheney s garbage collector \nhas been a bench\u00admark of sorts for heap-aware veri.cation, especially in separation logic [MAY06, TSBR08, \nGas11]. Previous veri.cations worked by exploding the spatial graph into its individual nodes, and grouping \nthose into several disjoint groups corresponding to the intersections of various heap regions (from and \nto-space, scanned and unscanned, 6 In the above proof, the global variable free is modi.ed by copy_ref,but \nappears in our rami.ed assertions. We circumvent this issue by treating free as a resource: we remove \nour knowledge about free when copy_ref is called, and only get to assume what is in copy_ref s post-condition \nin the post-rami.ed state (e.g. line 9). Hyp. tP u c tQu Hyp. modif pcqX fvpQ \u00b4 R1q H Hyp. Frame Modus \nPonens 111 1 R $ P pQ \u00b4 Rq tP pQ \u00b4 Rqu c tQ pQ \u00b4 Rqu Q pQ \u00b4 R1q$ R 1 Consequence tRu c tRu Figure 7: \nProof of RAMIFY. etc.). Our approach uses a single, generic inductive graph predicate, and the intricacies \nof reasoning about those regions is handled at the level of mathematical graphs. This division of labor \nyields, in our opinion, a much more pleasant and concise proof, which enjoys relatively intuitive and \nnatural invariants. 8. Universality, Strongest Posts, and Extensions Here we discuss the general applicability \nof the ramify rule as well as an alternative form of the rule. We also discuss a number of extensions \nto apply rami.cations to more examples, including the overlapping conjunction Y , regions, and higher-order \nsettings. 8.1 Universality of Rami.cation In \u00a73.3 we showed that the frame rule was a consequence of \nthe ramify rule. Somewhat surprisingly, the converse is also true. Theorem 8.1 (RAMIFY) tP u c tQu R \n$ P pQ \u00b4 R1 q fvpQ \u00b4 R1qX 1 modif pcq H tRu c tRu Proof By the short derivation given in Fig. 7. . Because \ntheorem 8.1 only requires frame and consequence, ramify is valid in any separation logic. This is very \nhandy, because it means that we do not need to modify the numerous .avors of separation logic in previous \nwork to incorporate rami.cation: it has been there all along, just waiting for its importance to be recognized. \n 8.2 Weakest preconditions and strongest postconditions In fact, our ramify rule appears in the separation \nlogic folklore as a weakest precondition rule, codi.ed as follows: Lemma 8.1 (Weakest Pre) Given a postcondition \nR1 and a speci\u00ad.cation tP u c tQu, then P pQ \u00b4 R1q is the weakest precondition, i.e., given any speci.cation \ntRu c tR1u, then R $ P pQ \u00b4 R1q. Our examples demonstrate that we can successfully ramify with weakest \nprecondition. Can we also succeed with strongest postcondition, i.e., with the following forward ramify \nrule: FWRAMIFY tP u c tQu R $ P true pP \u00b4 - Rq Q $ R1 1 tRu c tRu The pP \u00b4 - Rq Q $ R1 pattern is reminiscent \nof a pattern used in RGSep [VP07] to characterize stability by setting R1 to R.In RGSep the focus is \non concurrency, and a thread s collaborators may take an unknown number of actions. In our setting we \nknow that a given speci.cation will execute exactly once, which we leverage by allowing the consequent \nto be the more general R1 rather than R. When P is precise, FWRAMIFY gives the strongest postcondition: \nLemma 8.2 (Strongest Post) Given precondition R and tP u c tQu, if P is precise then pP \u00b4 - Rq Q is the \nstrongest postcondition. As it happens, whenever P is precise, RAMIFY and FWRAMIFY are each derivable \nfrom the other. However, precision is actually only needed when starting from FWRAMIFY, and so we consider \nRAMIFY to be fundamental. Moreover, although we were able to prove some of the examples using FWRAMIFY, \nwe found its \u00b4 - idiom to be harder to reason about than the \u00b4 idiom in RAMIFY.  8.3 Extensions supporting \nrami.cation We can ramify in any separation logic, but verifying certain pro\u00adgrams can require various \nextensions, such as regions in \u00a7A. Here we detail other extensions, starting with a more careful look \nat Y . The overlapping conjunction Y Although the overlapping con\u00adjunction Y appears occasionally in \nthe literature (under such names as fusion , relevance conjunction , and sepish ), its properties are \nnot well-understood for abstract separation logics. A separation algebra [COY07] is a partial commutative \nmonoid with cancellation pS, q that provides an abstract model for separa\u00adtion logic. Although the overlapping \nconjunction Y can be de.ned in any separation algebra, it is not necessarily easy to use: in fact, several \ncritical properties require stronger separation algebra axioms. We propose using a variant described \nby Dockins et al. [DHA09] that has multiple units, disjointness (i.e., x x y \u00f1 x y), and a kind of \ndistributivity property called cross split : a b z ^ c d z \u00f1Dac, ad, bc, bd. ac ad a ^ bc bd \nb ^ ac bc c ^ ad bd d  That is, if an element (e.g., a heaplet) can be split in two different ways, \nthen there are four subobjects which partition the original and respect the original splittings. Cross \nsplit is not discussed much in the literature, but we discovered that it is vital for reasoning about \nthe overlapping conjunction Y , which is not even associative without it. In fact, virtually all of our \nproofs that use Y assume cross split. Many but by no means all separation algebras used in prac\u00adtice \nsatisfy cross split, including the canonical model of heaplets as partial maps from addresses to values \n(quarters are found by set intersection on the domain). Users of our theory must therefore verify that \nthe separation algebras they care about satisfy cross split. Explicit overlapping conjunction Cherini \nand Blanco proposed a generalization of P Y Q that tagged the shared core with an explicit description \nC [CB09], de.ned as follows: def h ( P xY : CyQ Dh1,h2,h3. ph1 h2 h3 sq^ph1 h2 ( P q^ph2 ( Cq^ph2 \n h3 ( QqThis explicit overlapping conjunction is more expressive than Y : P xY : trueyQ %$ P Y Q Moreover, \nCherini and Blanco developed the following proof rule: EXPRAMIFY tP u c tQu pC \u00b4 - Rq C1 $ R1 Q $ C1 \n true tP xY : CyRu c tQxY : C1 yR1 u Unfortunately, EXPRAMIFY is not useful to verify any of our examples \nbecause we focus on unspeci.ed sharing that is, we do not know exactly what the overlap is (e.g., the \nprecise nodes shared between the children of a dag node), and hence cannot pick C or C1 other than true. \nIn general unspeci.ed sharing is more dif.cult to verify than speci.ed sharing, which is apparent when \none tries to apply EXPRAMIFY: ptrue \u00b4 - Rq true $ R1 In other words, start from R, remove an unrestricted \nsubheap, replace it with a second unrestricted heap, and now prove R1 . Yikes! Conversely, EXPRAMIFY \ncannot verify our overlaid example (\u00a76) because instead of C and C1 being too weak, they represent the \nentire structure (i.e., P C R and Q C1 R1). Applying EXPRAMIFY then makes no progress because the \nsimpler Hoare subproof tP u c tQu is actually identical to the goal. All of that said, Cherini and Blanco \ndemonstrate how to use EXPRAMIFY to verify programs that operate in the special case of speci.ed partial \nsharing i.e., when nontrivial C and C1 are known and not the entire P , Q, R,or R1. Happily, E XPRAMIFY \nis derivable from RAMIFY, so we can reuse all of their veri.cations. Fractional shares, actions, and \ntight regions In \u00a74.2 we pointed out that na\u00efve attempts to verify mark using the shape-only dagpxqpredicate \nwere unsound. In this paper we focused on functional correctness instead, but we also experimented various \nother methods for guaranteeing that the graph is not overly mangled, including fractional shares [DHA09], \nactions in the style of RGSep [Vaf07], and a variant of regions that could prevent memory deallocation. \nEach method had some bene.ts but also required some additional formalism; the tradeoffs were unclear. \nHigher-order settings In recent years there have been several .avors of separation logic to reason about \nhigher-order state such as the resource invariants of concurrent separation logic with .rst\u00adclass locks \n[HAZ08]. Although we did not do any rami.cations for genuine higher-order settings (which are often very \ncomplicated in ways unrelated to their higher-orderness), we did check a few of the rami.cations from \nthis paper in Coq within the framework of approximating separation algebras [HDA10], and believe that \nthe higher-orderness by itself poses no fundamental dif.culties. 9. Related Work There is a large body \nof work, orthogonal to ours, tackling the design and proof of algorithms for data structures with sharing. \nIts counterpart in program veri.cation spans a range of domains, and we begin this section with other \nseparation logic based analyses. Our reasoning about graphs owes a lot to the overlapping conjunction \nY , which has roots in relevant logic [Urq72]. Many people have rediscovered it in the context of separation \nlogic [Rey03, GMS12], who de.ned inductive graphs and dags as we did, but did not provide a means to \nreason about them. Cherini and Blanco were able to reason about a speci.ed version of Y using a more \ndomain-speci.c framework than ours, as discussed in \u00a78.3. More recently, Mehnert et al. and Krishnaswami \net al. have used some form of rami.cation to verify respectively implementations of snapshottable trees \n[MSBS12] and programs that follow the subject\u00adobserver pattern [KBA10], both of which involved unspeci.ed \nsharing. Their rami.cations are restricted to ad-hoc rami.cation operators tailored for each example, \nand the logic itself is domain\u00adspeci.c and done modulo a predicate on the global heap. It would be interesting \nto try and recast their proofs in our setting. Lee et al. devised an automatic analysis for threaded \ntrees that instruments the results of separate analyses for lists and for trees [LYP11]. Moreover, several \nworks have dealt with de.nite sharing in sep\u00adaration logic, e.g. doubly linked lists [Rey00], trees with \nparent pointers, skip or cyclic lists, etc. In these cases, one always knows what is shared and by whom. \nOn the other hand, handling inde.\u00adnite sharing, such as in this paper, was achieved only by resorting \nto tricks that speci.ed or avoided the sharing. Yang s proof of the Schorr-Waite graph marking algorithm \n[Yan01, \u00a77] (later mech\u00adanized in Isabelle/HOL [MN05]) does not de.ne a spatial graph predicate, but \nrather describes the graph by its spanning tree. At\u00adtempts to lift this kind of reasoning to other algorithms \non dags and graphs has led to convoluted predicates that explicitly deal with sharing and hack data structures \ninto -conjoined pieces, often in ways tied to the behavior of the program at hand [BCO04]. Several other \nframeworks have dealt with sharing in pro\u00adgrams. In shape analysis, Hob can prove data structure consistency \nwhen one can expose a backbone into which objects ultimately point [WKL ` 06], and TVLA has been used \nto prove partial correct\u00adness of a mark-and-sweep garbage collector and the Schorr-Waite algorithm [MSRF04]. \nHawblitzel and Petrank have used Boogie to automatically verify garbage collectors [HP09]. However, these \nworks do not provide compositional reasoning for sharing. It would be interesting to see if we can import \nrami.cation into other frameworks, such as Dafny [Lei10], whose reasoning about the heap is based on \ndynamic frames (a cousin of separation logic). 10. Conclusion We have presented a new paradigm, rami.cation, \nvalid in any sep\u00adaration logic, for the compositional veri.cation of programs that manipulate data structures \nwith both speci.ed and unspeci.ed shar\u00ading. We gave a rami.cation library that helps simplify rami.cation \nentailments in general and reduces local spatial updates to abstract mathematical reasoning. We have \ndemonstrated the applicability of our framework by providing concise, local speci.cations for a range \nof examples and data structures, including Cheney s garbage collector. These initial successes lead us \nto believe that rami.cation provides a robust basis for elegant, compositional reasoning about sharing \nin data structures. Acknowledgments We deeply thank Peter O Hearn for his continuous help and encour\u00adagement. \nWe also bene.ted from discussions with Josh Berdine, Richard Bornat, Gareth Smitch, David Walker, Hongseok \nYang, and especially with Matthew Parkinson, who .rst suggested that our ini\u00adtial semantic account of \nrami.cation was expressible as a separation logic entailment. Finally, we thank the anonymous reviewers \nfor their suggestions and enthusiasm. This research was supported by a Lee Kuan Yew Postdoctoral Fellowship \nand EPSRC Programme Grant Resource Reasoning . References [BCO04] R. Bornat, C. Calcagno, and P. O Hearn. \nLocal reasoning, separation and aliasing. In SPACE, 2004. [BCY06] R. Bornat, C. Calcagno, and H. Yang. \nVariables as resource inseparation logic. ENTCS, 155, 2006. [Bor00] R. Bornat. Proving pointer programs \nin Hoare logic. In MPC, 2000. [CB09] R. Cherini and J. O. Blanco. Local reasoning for abstractionand \nsharing. In SAC, 2009. [Che70] C. J. Cheney. A nonrecursive list compacting algorithm. C. ACM, 13(11), \n1970. [COY07] C. Calcagno, P. W. O Hearn, and H. Yang. Local action andabstract separation logic. In \nLICS, 2007. [DHA09] R. Dockins, A. Hobor, and A. W. Appel. A fresh look at separation algebras and share \naccounting. In APLAS, 2009. [Fin87] J. Finger. Exploiting constraints in design synthesis. PhD thesis, \nStanford University, 1987. [Gas11] H. Gast. Developer-oriented correctness proofs -a case studyof Cheney \ns algorithm. In ICFEM, 2011. [GMS12] P. Gardner, S. Maffeis, and G. D. Smith. Towards a programlogic \nfor JavaScript. In POPL, 2012. [HAZ08] A. Hobor, A. W. Appel, and F. Zappa Nardelli. Oracle semanticsfor \nconcurrent separation logic. In ESOP, 2008. [HDA10] A. Hobor, R. Dockins, and A. W. Appel. A logical \nmix of approximation and separation. In APLAS, ENTCS, 2010. [HP09] C. Hawblitzel and E. Petrank. Automated \nveri.cation of practical garbage collectors. In POPL, 2009. [IO01] S. S. Ishtiaq and P. W. O Hearn. BI \nas an assertion languagefor mutable data structures. In POPL, 2001. [KBA10] N. Krishnaswami, L. Birkedal, \nand J. Aldrich. Verifying event\u00addriven programs using rami.ed frame properties. In TLDI, 2010.  [Lei10] \nK. R. M. Leino. Dafny: An automatic program veri.er forfunctional correctness. In LPAR, 2010. [LG88] \nJ. M. Lucassen and D. K. Gifford. Polymorphic effect systems.In POPL, 1988. [LYP11] O. Lee, H. Yang, \nand R. Petersen. Program analysis for overlaiddata structures. In CAV, 2011. [MAY06] N. Marti, R. Affeldt, \nand A. Yonezawa. Formal veri.cation of the heap manager of an operating system using separation logic.In \nICFEM, 2006. [MN05] F. Mehta and T. Nipkow. Proving pointer programs in higher\u00adorder logic. Inf. Comput., \n199(1-2), 2005. [MSBS12] H. Mehnert, F. Sieczkowski, L. Birkedal, and P. Sestoft. Formal\u00adized veri.cation \nof snapshotable trees: Separation and sharing.In VSTTE, 2012. [MSRF04] R. Manevich, S. Sagiv, G. Ramalingam, \nand J. Field. Partiallydisjunctive heap abstraction. In SAS, 2004. [Rey00] J. C. Reynolds. Intuitionistic \nreasoning about shared mutabledata structure. In Millennial Perspectives in Computer Science, Cornerstones \nof Computing, 2000. [Rey02] J. C. Reynolds. Separation logic: A logic for shared mutabledata structures. \nIn LICS, 2002. [Rey03] J. C. Reynolds. A short course on separation logic. http://www.cs.cmu.edu/afs/cs.cmu.edu/project/fox-19/member/jcr/wwwaac2003/notes7.ps, \n2003. [Thi01] M. Thielscher. The quali.cation problem: A solution to theproblem of anomalous models. \nArti.cial Intelligence, 131(1), 2001. [TSBR08] N. Torp-Smith, L. Birkedal, and J. C. Reynolds. Local \nreasoningabout a copying garbage collector. ACM TOPLAS, 30(4), 2008. [Urq72] A. Urquhart. Semantics for \nrelevant logics. J. Symb. Log., 37(1), 1972. [Vaf07] V. Vafeiadis. Modular .ne-grained concurrency veri.cation. \nPhD thesis, University of Cambridge, 2007. [VP07] V. Vafeiadis and M. J. Parkinson. A marriage of rely/guaranteeand \nseparation logic. In CONCUR, 2007. [WKL ` 06] T. Wies, V. Kuncak, P. Lam, A. Podelski, and M. C. Rinard. \nField constraint analysis. In VMCAI, 2006. [Yan01] H. Yang. Local Reasoning for Stateful Programs. PhD \nthesis, University of Illinois, 2001. A. Copying Dags The program in Fig. 8 makes a deep (structure-preserving) \ncopy of a dag, using a data .eld in each original node to record the location of its copy when it exists \n(or 0 otherwise). Initially, all the copy .elds of dagpxq must be set to 0, and at the end all the nodes \nreachable from x will have been copied into a new dag whose root is returned by copy_dag. In the intermediate \nrecursive calls, parts of the dag rooted at the argument will have already been copied. To cut down on \nthe amount of formalism we must present to verify a reasonable-looking speci.cation for copy_dag, we \nwill utilize regions in the following ad-hoc way. We assume two regions, a and \u00df, bound at the top level \n, in the meta context. The initial dag must come in region a, and malloc always allocates in region \u00df; \nafterwards the new copy will be in \u00df and the original will remain in a. This speci.cation is not as general \nas one would want, since e.g. it prevents us from verifying the copying of a copy; a far better speci.cation \nwould take the regions as parameters, but all of the extra wizardry would be in the (orthogonal) region \nmanagement system rather than in the rami.cations. Ideally, such a system would have features such as \ngeneral-purpose region creation, destruction, and merging, as well as a good handle on region variable \nscoping. Describing completed and in-process dag copies We represent an entirely copied dag d pV, D, \nL, Eq rooted at x and its copy rooted at y by the predicate ddagpx, y, dq (or double dag): defpx y \n0 ^ empq_pdagapx, dq ddagpx, y, dq dag\u00df py, copy pdqq ^ Lpxq y ^ y 0qThe nodes in the .rst dag are described \nby the graph d. Because we store the addresses of the copy in the data .elds, d is also enough to 1 \nstruct node {struct node *c , * l , * r ;}; 2 struct node * 3 copy_dag ( struct node * x ) { // ticdagpx,dqu \n4 struct node *l , * r , * ll , * rr , * y ; 5 if (! x ) return 0; 6 if ( x ->c) return x-> c ; 7 l = \nx-> l ; r = x-> r ; 8 y = malloc ( sizeof(struct node )) ; 9 x-> c=y ; \" x \u00de\u00d1a y, l, r picdagpl,dqY \nicdagpr,dqq y \u00de\u00d1\u00df 10 // dpxq p0, l, rq11 ll = c opy_dag ( l ) ; \" * \u00b4, \u00b4, \u00b4^ * x \u00de\u00d1a y, l, r pddagpl, \nll,d1qY icdagpr,d1qq 12 //lp35q y \u00de\u00d1\u00df \u00b4, \u00b4, \u00b4^ dpxq p0, l, rq^ d1 el d 13 rr = c opy_dag ( r ) ; \" * \nx \u00de\u00d1a 0, l, r pddagpl, ll,d2qY ddagpr, rr,d2qq 14 //lp36q d1 y \u00de\u00d1\u00df \u00b4, \u00b4, \u00b4^ dpxq p0, l, rq^ d1 el d \n^ d2 er 15 y ->c = 0; y ->l = l l ; y ->r = rr ; $ , &#38; x \u00de\u00d1a y, l, r y \u00de\u00d1\u00df 0, ll, rr . 16 // % \npddagpl, ll,d2qY ddagpr, rr,d2qq ^ \u00addpxq p0, l, rq^ d1 el d ^ d2 er d1 17 return y; 18 } // tddagpx, \ny,d3q^ d3 ex du Figure 8: Proof sketch of dag copy. describe the copy via copy pdq pV 1,D,L1,E1q, where \nV 1 tv 1 |Dv P V. Lpvq v 1 ^ v 1 0u L1 pvq 0 $ &#38;Dv 1 P V. dpv 1q pv, l, rq^ 1 11 Epvq pl,r q if \npl l1 0 _ Lplq l1q^ % pr r 1 0 _ Lprq r 1q The predicate ddag describes the postcondition for copy_dag; \nour next task is to de.ne the precondition. Because some parts of the dag may have already been copied, \nthe in-copy dag predicate icdagpx, dq describes a single dag in region a and a set of dags in region \n\u00df corresponding to any previously copied sub-dags. def icdagpx, dq dagapx, dq dags\u00dfpprpx, dq, copy pdqq \n prpx, dq (processed roots) .nds the roots of the copied sub-dags: $  &#38; H if x 0 def prpx, dq \nprpl, dqY prpr, dq if dpxq p0,l,rq (32) % txu otherwise Observe that when x is copied, i.e. dpxq py, \nl, rq and y 0, then icdagspx, dq%$ ddagspx, y, dq (33) We will use this equivalence to move between \nthe precondition and the postcondition when we discover that the dag is already copied. When we wish \nto reason entirely about the copies we write cdagspx, dq (i.e., copy dags) for dagspprpx, dq, copy pdqq. \nNote that if x is not yet copied, i.e. dpxq p0,l,rq, then, using the second case in the de.nition of \npr, we deduce that cdagspx, dq%$ cdagspl, dqY cdagspr, dq, and thus icdagspx, dq%$ x \u00de\u00d1a 0,l,r picdagspl, \ndqY icdagspr, dqq (34) Finally, to re.ect the fact that already copied parts of the dag will not be \nchanged by copy_dag, we de.ne the relation d1 ex d between two dags d pV, D, L, Eq and d1 pV, D, L1,Eq, \ntrue when d1 \u00d2 x d \u00d2 x and d1 \u00d3 x is more copied than d \u00d3 x: pLpvq 0 \u00f1 L1pvq Lpvqq ^ @v P reach pd, \nxq. pL1pvq 0 \u00f1 Lpvq 0q We will write d1 e d when Dx. d1 ex d. Veri.cation of copy_dag Now we annotate \nthe program in Fig. 8 with the key assertions to prove the following speci.cation: ticdagpx, dqu y = \ncopy_dag(x) tddagpx, y, d1q^ d1 ex du If the dag is empty then the postcondition is trivially satis.ed \n(line 5); if the node has already been copied (line 6) then equation 33 yields the postcondition. The \nreal meat of the algorithm is in the rami.cations from the two recursive call sites and the entailment \nof the postcondition from line 16. The two rami.cations are as follows: icdagpl,dqY icdagpr,dq$ icdagpl,dq \npddagpl, ll,d1q^ d1 el d \u00b4 (35) ddagpl, ll,d1qY icdagpr,d1q^ d1 el dq ddagpl,d1qY icdagpr,d1q$ icdagpr,d1q \npddagpr, rr,d2q^ d2 er d1 \u00b4 (36) ddagpl, ll,d2qY ddagpr, rr,d2q^ d2 er d1q As with mark, the second rami.cation \nfollows from the .rst by swapping the roles of r and l and observing that when d1 e d ddagpx, y, dq$ \nicdagpx, d1q\u00f4 ddagpx, y, d1q\u00f4 ddagpx, y, dq Regions let us split the .rst rami.cation (35) using the \nLem. 4.5 from our rami.cation library, yielding two simpler rami.cations in which d1 el d, and, by the \nde.nition of ddag, l ll 0 _ d1plq pll, \u00b4, \u00b4q. The .rst half of (35), in region a, dagpl,dqY dagpr,dq$ \ndagpl,dq pdagpl,d1q\u00b4\u00b4 (37) dagpl,d1qY dagpr,d1qq, is direct from Lem. 4.14. The second half of (35), \nin region \u00df,is cdagspl,dqY cdagspr,dq$ cdagspl,dq pdagpll,dc 1 q\u00b4\u00b4 (38) dagpll,dc 1 qY cdagspr,d1qqwhere \ndc 1 copypd1q. This rami.cation is more involved because the copied roots of d1 starting from r may \ndiffer from the previous ones in d. Instantiating Lem. 4.14 with S1 prpd, lq, S2 prpd, rq and S1 1 \ntllu yields this entailment, which is only halfway there, because it features the sub-dags rooted at \nprpd, rq, whereas we want those rooted at prpd1 , rq: cdagspl,dqY cdagspr,dq$ cdagspl,dq pdagpll,dc 1 \nq\u00b4\u00b4 dagpll,dc 1 qY dagspprpd, rq,dc 1 qqTo complete this proof, we remark that the copied roots of r \nin d1 and in d satisfy the following relations, hence Lem. 4.10 applies: prpd, rqD reachpdc 1 , prpd1 \n, rqq pd1 e dqprpd1 , rqD prpd, rqY reachpdc 1 , llq pd1 el dq To reach the postcondition from line 16, \nthe sub-copies on each side of the overlapping conjunction need to be disentangled from the original \nsub-dags using regions and equation 25 in the following derivations, where dpxq p0, l, rq, d1 el d, and \nd2 er d1: x \u00de\u00d1a y, l, r y \u00de\u00d1\u00df 0, ll, rr pdagapl,d2q dag\u00dfpll, copypd2qqq Y pdagapr,d2q dag\u00dfprr, copypd2qqq \n(39) $ dagapx,d3q dag\u00df py, copypd3qq ^ d3 rx \u00d1p\u00dey, l, rqsd2 $ ddagpx, y,d3q^ d3 ex d The last deduction \nstep uses this mathematical fact: dpxq p0,l,rq^d1 pxq py, l, rq^d1 el d ^d1 er d \u00f1 d1 ex d B. Disposing \na Graph Let us show how to verify the depth-.rst search spanning tree procedure for binary graphs, as \npresented in Fig. 9. The desired top-level speci.cation for spanning is that, starting from an unmarked \ngraph ., we remove some edges (indicated by the predicate D) and get a tree t that covers the same set \nof nodes: tgraphpx, .q^ unmarkedp.qu spanning(x) ttreepx, tq^ t D . ^ reachpt, xq reachp., xquThe predicate \npV, D, L, Eq D pV 1,D1,L1,E1q is true when pV 1,D1,L1q pV, D, Lq, and E has fewer edges than E1: 11 11 \n@v P V. Epvq pl,r 1q\u00f1 Epvq pl, rq^l Ptl, 0u^r Ptr , 0u 1 void spanning(struct node *x) { 2 // tgraphpx,.q^ \n.pxq p0, \u00b4, \u00b4qu 3 struct node *l,*r; 4 l = x->l; r = x->r; 5 // tx \u00de\u00d1 0, l, r Y graphpl,.qY graphpr,.q^ \n.pxq p0, l, rqu 6 x->m = 1; \" * x \u00de\u00d1 1, l, r Y graphpl,.1qY graphpr,.1q^ 7 //l .pxq p0, l, rq^ .1 \nm1p., xq 8 if (l &#38;&#38; !l->m) \" * x \u00de\u00d1 1, l, r Y graphpl,.1qY graphpr,.1q^ 9 // .pxq p0, l, rq^ \n.1 m1p., xq^ .1plq p0, \u00b4, \u00b4q10 spanning(l); 11 else x->l = 0; ` $ , x \u00de\u00d1 1, l, r Y treepl,.2qY graphspprpl,.1q,.2qY \n/ &#38; . graphpr,.2q^ .pxq p0, l, rq^ .1 m1p., xq^ 12 //l % .1plq p0, \u00b4, \u00b4q ^ /\u00ad . .2 D mp.1, lq^ \nreachp.2, lq reach0p.1, lq _ \u00a8\u00a8\u00a8 13 if (r &#38;&#38; !r->m) spanning(r); 14 else x->r = 0; $ \u00a8 . , x \n\u00de\u00d1 1, l, r Y treepl,.3qY graphspprpl,.1q,.3qY  \u00b0treepr,.3qY graphspprpr,.2q,.3q^ .pxq p0, l, rq^ \u00b0 \n\u00b0 .1 m1p., xq^ .1plq p0, \u00b4, \u00b4q ^ .2prq p0, \u00b4, \u00b4q ^  . .2 D mp.1, lq^ reachp.2, lq reach0p.1, lq^  \n/ &#38; .3 D mp.2, rq^ reachp.3, rq reach0p.2, rq . \u00a8 . 15 //l x \u00de\u00d1 1, l, 0 Y treepl,.1 qY graphspprpl,.1q,.1 \nqY 3 3 \u00b0graphpr,.1 q^ .pxq p0, l, rq^ .1 m1p., xq^ 3 \u00b0 _\u00b0 .1plq p0, \u00b4, \u00b4q ^ p.2prq p1, \u00b4, \u00b4q _ r \n0q^ . .2 D mp.1, lq^ reachp.2, lq reach0p.1, lq^  .1 rx \u00de\u00d1p1, l, 0qs.2 % 3 / \u00ad _ \u00a8\u00a8\u00a8 \" * treepx,.1qY \ngraphspprpx,.q,.1q^ 16 } // .1 D mp., xq^ reach0p., xq reachp.1 , xq Figure 9: Spanning tree of a binary \ngraph. During the execution, the graph will be partially marked, and the effect of spanning on such \ngraphs is thus subtler. Assuming that the root x of the graph . has not been marked yet, it transforms \nthe unmarked part of . that is reachable from x (it was not apparent in the top-level speci.cation, wherein \nreach0p., xq reachp., xq) into a tree covering the same nodes, overlapped with some subgraphs. As seen \nin Fig. 9, these extra subgraphs are precisely those that start at a marked node reachable from x via \nunmarked nodes in the original graph, using the pr predicate (32) from Apx. A. The proof of spanning \nhas four main branches, corresponding to whether each of the left and right sub-graphs has to be examined \nor not (notice that spanning assumes a non-empty graph as a precondi\u00adtion). In Fig. 9, we only show the \nproof sketch corresponding to the case where the left sub-graph was non-empty and unmarked. Mark\u00ading \nthe root x is done as in mark for graphs. To handle the recursive call of line 10, we have to prove the \nfollowing rami.cation: graphpl,.1qY graphpx,.1q$ graphpl,.1q ptreepl,.2qY graphspprpl,.1q,.2q\u00b4\u00b4 treepl,.2qY \ngraphspprpl,.1q,.2qY graphpx,.2qq Rewriting treepl,.2q as graphpl,.2q^p.2 \u00d3 l is a treeq, using an analogue \nof Lem. 4.8 for trees turns this rami.cation into an applica\u00adtion of Lem. 4.14. The same trick can be \nused to obtain the .rst dis\u00adjunct of line 15 (corresponding to the case where spanning(r) was applied), \nwhile the second disjunct is an application of Lem. 4.12. Because the nodes covered by the sub-trees \nat l and r are marked and form the same set as the nodes reachable via unmarked paths in the graphs before \neach recursive call, we can disentangle both trees and the roots in the .rst disjunct of line 15 to form \nthe spatial part px \u00de\u00d1 1, l, r treepl,.3q treepr,.3qqY graphspprpl,.1q,.3qY graphspprpr,.2q,.3q The \npost follows from the pure facts. The other disjuncts are similar.   \n\t\t\t", "proc_id": "2429069", "abstract": "<p>Programs manipulating mutable data structures with intrinsic sharing present a challenge for modular verification. Deep aliasing inside data structures dramatically complicates reasoning in isolation over parts of these objects because changes to one part of the structure (say, the left child of a dag node) can affect other parts (the right child or some of its descendants) that may point into it. The result is that finding intuitive and compositional proofs of correctness is usually a struggle. We propose a compositional proof system that enables local reasoning in the presence of sharing.</p> <p>While the AI \"frame problem\" elegantly captures the reasoning required to verify programs without sharing, we contend that natural reasoning about programs with sharing instead requires an answer to a different and more challenging AI problem, the \"ramification problem\": reasoning about the indirect consequences of actions. Accordingly, we present a RAMIFY proof rule that attacks the ramification problem head-on and show how to reason with it. Our framework is valid in any separation logic and permits sound compositional and local reasoning in the context of both specified and unspecified sharing. We verify the correctness of a number of examples, including programs that manipulate dags, graphs, and overlaid data structures in nontrivial ways.</p>", "authors": [{"name": "Aquinas Hobor", "author_profile_id": "81388591155", "affiliation": "National University of Singapore, Singapore, Singapore", "person_id": "P3978051", "email_address": "hobor@comp.nus.edu.sg", "orcid_id": ""}, {"name": "Jules Villard", "author_profile_id": "81384606967", "affiliation": "University College London, London, United Kingdom", "person_id": "P3978052", "email_address": "j.villard@cs.ucl.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429131", "year": "2013", "article_id": "2429131", "conference": "POPL", "title": "The ramifications of sharing in data structures", "url": "http://dl.acm.org/citation.cfm?id=2429131"}