{"article_publication_date": "01-23-2013", "fulltext": "\n Sigma*: Symbolic Learning of Input-Output Speci.cations Matko Botin .can Domagoj Babi \u00b4c * University \nof Cambridge Facebook, Inc. matko.botincan@cl.cam.ac.uk babic@eecs.berkeley.edu Abstract We present \nSigma*, a novel technique for learning symbolic mod\u00adels of software behavior. Sigma* addresses the challenge \nof synthe\u00adsizing models of software by using symbolic conjectures and ab\u00adstraction. By combining dynamic \nsymbolic execution to discover symbolic input-output steps of the programs and counterexam\u00adple guided \nabstraction re.nement to over-approximate program behavior, Sigma* transforms arbitrary source representation \nof programs into faithful input-output models. We de.ne a class of stream .lters programs that process \nstreams of data items for which Sigma* converges to a complete model if abstraction re.ne\u00adment eventually \nbuilds up a suf.ciently strong abstraction. In other words, Sigma* is complete relative to abstraction. \nTo represent in\u00adferred symbolic models, we use a variant of symbolic transducers that can be effectively \ncomposed and equivalence checked. Thus, Sigma* enables fully automatic analysis of behavioral properties \nsuch as commutativity, reversibility and idempotence, which is useful for web sanitizer veri.cation and \nstream programs compiler optimizations, as we show experimentally. We also show how mod\u00adels inferred \nby Sigma* can boost performance of stream programs by parallelized code generation. Categories and Subject \nDescriptors D.2.4 [Software Engineer\u00ading]: Software Veri.cation Formal methods; D.3.4 [Program\u00adming Languages]: \nProcessors Optimization General Terms Languages, Theory, Veri.cation Keywords Inductive learning, Speci.cation \nsynthesis, Behavioral properties, Equivalence checking, Stream programs, Compiler op\u00adtimization, Parallelization \n1. Introduction Modern software systems often process large amounts of data in a stream-like fashion. \nBy streams, we mean sequences of data items, processed in some order. Such stream processing is inherent \nto many domains such as digital signal processing, embedded applica\u00adtions, network event processing, \n.nancial applications, web appli\u00adcations, and even to common desktop software. Likewise, big-data services \nrunning on a cloud often continuously process streams of moving data and batches of past data. * This \nwork was done while the second author was with UC Berkeley. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 13, January 23 25, 2013, Rome, Italy. \nCopyright c &#38;#169; 2013 ACM 978-1-4503-1832-7/13/01. . . $10.00 We focus on a simple notion of programs \nthat applies to many of these systems, called a .lter. Filters are typically small fragments of code, \nbut they facilitate large scale stream-processing [15, 18, 23, 26, 29, 32, 54]. A .lter iteratively reads \na bounded number of items from an input stream at once, performs some computation on those items, and \nwrites the results to an output stream. Filters exchange data via stream(s) with other parts of the program, \nand can also be glued together into more complex structures. Unfortu\u00adnately, reasoning about even these \nrelatively simplistic programs is dif.cult as their low-level implementation details often obscure the \nhigh-level input-output behavior that we want to reason about. Our aim is to provide ways for automated \nanalysis of the input\u00adoutput behavior of programs such as stream .lters. Although the internal implementation \nof such programs may be rather delicate, many of their properties rely solely on their input-output behavior. \nTo exemplify a couple of such properties, let us consider intention\u00adally simple .lters P and P ' (coming \nfrom, say, two revisions of the code or from two different vendors), that implement a difference encoder \n(used in, e.g., JPEG compression [53]):1 out(peek(0)); state = 0; P while ( true ) {out(peek(1)-peek(0)); \nP ' while ( true ) {out(peek(0)-state); in (); state = in(); } } P and P ' are syntactically different \nand have different operational semantics but they exhibit the same input-output behavior. Behav\u00adioral \nequivalence of P and P ' ensures that the two implementations can be used interchangeably for instance, \na behaviorally equiva\u00adlent stateless (or with few states) implementation might be prefer\u00adable over a \nstateful (or with many states) one, as the former can be made amenable to data-parallel execution by \na simple replication. For another property, consider a .lter Q that looks like P but in\u00adstead of the \ndifference calculates the sum of the two consecutive values. If we connect P s output stream to Q s input \nstream in a pipeline then the resulting composition will have the same behav\u00adior as if we were to connect \nQ s output to P s input. Knowing that P and Q are commutative with respect to each other we can reorder \nthem (e.g., for performance reasons) without affecting the behavior of the pipeline. In this paper, we \npresent a technique called S * that enables au\u00adtomated analyses of input-output properties of programs \nby learn\u00ading. S * uses dynamic symbolic execution [16, 28, 49] to dis\u00adcover symbolic input-output steps \nof a program, and counterex\u00adample guided abstraction re.nement [7, 20] to over-approximate program behavior, \nand combines the two techniques into a sound and complete (relative to abstraction) symbolic learning \nalgorithm. S * works on the control-.ow graph without assuming any speci.c 1 In these code snippets, \nfunction out() writes a data item to the output stream, peek() returns the item at the given offset in \nthe input stream without consuming it, and in () consumes and returns the current item from the input \nstream.  Figure 1: The Design of S *. Arrows indicate the data .ow. syntactic structure of the program \nand, by learning, synthesizes a faithful symbolic model of program behavior. It represents the models \nusing a variant of symbolic transducers (STs) [14], which generalize classical .nite-state machines by \nallowing transitions la\u00adbeled with arbitrary predicates as input guards and terms as out\u00adput. Assuming \nformulae from a decidable theory, STs can be ef\u00adfectively composed and equivalence-checked, enabling \nanalysis of various behavioral properties such as commutativity, reversibility, and idempotence. S * \ntargets applications beyond just veri.cation. As we show, S * enables domain-speci.c compiler optimizations \n(e.g., .lter fu\u00adsion and reordering [2, 45]) for a wider class of stream programs than currently possible. \nAlso, STs inferred by S * lend themselves to vectorized implementation (e.g., by utilising SIMD instruc\u00adtions \n[57], GPU architecture [15, 56] or .eld-programmable gate arrays [35, 39]) and data-parallel execution \n(e.g., by replication or using speculative techniques such as [48]). Overview of S * . In a nutshell, \nS * can be seen as an extension of Angluin s L * automata-learning algorithm [5] to learning models of \nprograms. L *, designed to learn regular languages in a black\u00adbox manner, is not applicable to the general \nsoftware setting for two reasons. Firstly, L * requires a priori knowledge of the concrete alphabet of \nthe language. While that .ts certain scenarios (such as inference of component interfaces [4, 27, 51], \nwhere the alphabet corresponds to the set of component s methods), the exact alpha\u00adbet of software internals \n(including, for instance, all values that arise during the execution) is hard to specify in advance. \nEven if known, such alphabets are typically large (or practically in.nite), so treating them concretely \nas in L * hinders scalability. Secondly, L * merely conjectures the inferred model and to check the conjec\u00adture \nrelies upon an oracle (a teacher) that can answer equivalence queries. An omniscient oracle for equivalence \nchecking against software artifacts is, however, computationally intractable. Therefore, S * is built \naround two key ideas: 1. S * uses dynamic symbolic execution to discover constraints on input values \n(path predicates) and terms generating output values, and builds symbolic alphabet out of these. By using \nsymbolic alphabets to represent equivalence classes of input\u00adoutput steps, S * enables discovery of complete \ninput-output behavior independently of the concrete alphabet size. 2. Instead of equivalence checking \nagainst the program, S * builds an abstraction that is a .nite-state symbolic over-approximation of program \nbehavior that we wish to learn. Checking equiva\u00adlence of (deterministic) symbolic conjectures and such \n(possi\u00adbly non-deterministic) over-approximations can be done algo\u00adrithmically. S * implements an algorithm \nthat either generates a separating sequence (counterexample) showing how the con\u00adjecture and abstraction \ndiffer, or proves they are equivalent.  Starting with the trivial symbolic conjecture and the coarsest \nabstraction, S * iteratively re.nes the conjecture or the abstraction until the two become equivalent \n(see Figure 1). If the counterexam\u00adple returned by the equivalence checking algorithm is spurious (i.e., \nthe program does not produce the same sequence of outputs as the abstraction), we re.ne the abstraction. \nOtherwise, the counterex\u00adample represents a behavior that the conjecture failed to capture, and we re.ne \nthe conjecture. Upon termination, the .nal conjec\u00adture is in a certain sense minimal behaviorally equivalent \nmodel of the program. The symbolic conjecture maintained by S * is a variant of sym\u00adbolic .nite-state \ntransducers [14] that we call symbolic lookback transducers (SLTs). To generate outputs, SLTs use a sliding \nwin\u00addow over a bounded number of past inputs (SLTs can also be augmented with lookahead to allow peeking \nof incoming inputs). Along with conjectures, we also synthesize over-approximations of program behavior \nin the form of SLTs. We use predicate abstrac\u00adtion [7, 30] to abstract away the internal control .ow \nof a program, however, in doing so we keep the input-output data .ow intact. We then transform the obtained \nabstraction into an equivalent non\u00addeterministic SLT. To check equivalence of the conjecture and the \nover-approximation, we use our algorithm for equivalence check\u00ading of a deterministic and non-deterministic \nSLT. The main technical result of the paper is that S * is relatively complete with respect to the abstraction. \nAssuming that the pro\u00adgram behavior can be represented with an SLT, S * terminates with an SLT behaviorally \nequivalent to the program if the overapproxi\u00admation scheme eventually produces an inductive invariant \nimplying the program s input-output relation. Since synthesis of the overap\u00adproximating SLT is guided \nby abstraction re.nement, relative com\u00adpleteness of S * is conditioned by completeness of the predicate \nselection method in re.nement of the predicate abstraction [9, 42]. Other classes of program behavior \ncould be learned by varying the type of symbolic conjectures. For programs whose behavior cannot be represented \nwithin the given class of symbolic models, S * will end up conjecturing more re.ned models ad in.nitum. \nHowever, if S * is interrupted before convergence, the conjecture is guaranteed to be correct up to the \nexplored depth. Applications. To demonstrate practical utility of S * , we report three experimental \nstudies conducted with our implementation: Web Sanitizers Veri.cation. We analyzed sanitizers from Google \nAutoEscape web sanitization framework and found out that 86% of them (12 out of 14) can be represented \nas SLTs. S * successfully inferred all 12 sanitizers fully automatically, en\u00adabling their further analysis \nwith systems such as Bek [37].  Stream Filter Optimization. We applied S * to infer .lters from various \nstream processing applications [18, 23, 33, 45, 54]. We show how S * enables optimizations such as reordering \nand fusion that are not possible with the current state-of-the-art.  Parallelization. We show how SLT \nmodels of .lters enable au\u00adtomated parallelization. From a variety of SLTs, we generated SIMD implementations \nusing Intel SSE intrinsics and GPU im\u00adplementations using NVIDIA CUDA, and obtained speedups of up to \n3.89 against the most optimized gcc code.  Contributions. We claim the following contributions. Symbolic \nLearning Framework S * . We present an automated learning framework S * for learning symbolic models \nof pro\u00adgrams s input-output behavior. The key insight behind S *, be\u00adsides use of symbolic alphabets \nto represent program steps, is use of over-approximation to detect convergence.  Symbolic Lookback Transducers. \nWe introduce a carefully lim\u00adited variant of symbolic transducers that is amenable to learning   prev \n= 0; cur = 0; i = 0; while (true) {cur = peek(0); if ( i < 2) out(cur ); else if (cur < prev) out(cur \n+ prev); else out(cur - prev); prev = in(); i++; } Figure 2: Code Snippet for the Running Example in \n\u00a72. true/.0 true/.0 .0 = .-1/.0 - .-1 .0 < .-1/.0 + .-1 (a) C1 (b) C2 true/.0 true/.0 true/.0 + .-1 \ntrue/.0 - .-1 true/.0 + .-1 true/.0 - .-1  (c) A1 (d) A2 Figure 3: Conjectures and Abstractions for \nthe Example in Figure 2. and develop an equivalence checking algorithm. We experimen\u00adtally show that \nSLTs are useful in practice through three case studies, two of which demonstrate novel use of transducers. \n Synthesis of Over-approximations. We show how to transform predicate abstraction of a program into an \nSLT over-approxi\u00admating the program behavior, and how to re.ne it. The key step of the synthesis is .nitization \nof the unabstracted components of states that correspond to the input-output .ow.  Relative Completeness. \nOur main technical result is that S * converges to a sound and complete model of SLT programs, as long \nas the abstraction re.nement eventually builds a strong enough set of predicates. Effectively, this result \nreduces the completeness of learning to the completeness of abstraction.  2. S* Illustrated by Example \nWe begin by showing how S * works on the example given in Fig\u00adure 2. The program reads input in an in.nite \nloop using commands peek() and in (); peek(0) reads the current input symbol and leaves it in the input \nstream, while in() reads the current input symbol and moves onto the next one. Both commands halt if \nthere is no more input to read. In the .rst two iterations, the program prints the last read symbol (using \ncommand out), and in every subsequent iteration it outputs the sum or difference of the last two symbols, \ndepending on their relative ordering. We represent learned conjectures and synthesized abstractions in \nthe example as SLTs with lookback 1. Each transition is labeled by a symbolic predicate-term pair of \nthe form p/t. The transition is taken when the predicate p evaluates to true for a given sequence of \nconcrete input symbols. The term t describes the computed output. Predicates and terms are expressions \nover input symbols and constants. We use .0 to denote the current symbol and .-i to denote symbols read \ni transitions before. SLTs with lookback k are allowed to read only the current and the last k symbols. \nWe use (dynamic) symbolic execution [16, 28, 49] to gather sequences of predicates and output terms occurring \nalong the paths in the program execution. For instance, given an input of length four, a possible execution \nmight take twice the then branch of the .rst if, then the else branch of the second if, and .nally the \nthen branch of the second if. For that execution we would obtain a predicate sequence (the path condition) \npp = true \u00b7 true \u00b7 (cur3 = prev2) \u00b7 (cur4 < prev3), and an output sequence pt = cur1 \u00b7 cur2 \u00b7 (cur3 - \nprev2) \u00b7 (cur4 + prev3). In sequences such as pp and pt, we use \u00b7 to denote the concatenation operator. \nTo obtain predicates and output terms formulated with regard to the input, we relativize all references \nof variables in pp and pt so that they become expressed with respect to the current position in the input \nstream. For instance, the relativized version of pp would be the sequence true \u00b7 true \u00b7 (.0 = .-1) \u00b7 \n(.0 < .-1), and of pt, the sequence .0 \u00b7 .0 \u00b7 (.0 - .-1) \u00b7 (.0 + .1). As for SLTs, the variable .-j in \neach element p |i of the sequences above corresponds to the input symbol j positions before the current \nposition (i) in the input stream. Thus, e.g., .0 in the third and fourth element of the sequences correspond \nto the last two symbols read by the program. To generate a concrete input from relativized path conditions, \nwe need to derelativize them and pass the derelativized formula to an SMT solver. In the case above, \nthe solver might return a concrete sequence 0 \u00b7 1 \u00b7 3 \u00b7 2 satisfying the relativized path condition. \nS * begins processing the example by learning the .rst conjec\u00adture C1 (Figure 3a), and compares it against \npredicate abstraction A1 of the program with respect to an empty set of predicates (Fig\u00adure 3c). Note \nthat, unlike in the classic predicate abstraction, we keep the input-output data .ow intact. Equivalence \nchecking of C1 and A1 produces the .rst symbolic counterexample, say a predi\u00adcate pp1 = true and output \np= t1 (.0 + .-1), which is a behavior captured by the abstraction, but not the conjecture. Any concrete \nsequence satisfying those two formulae is a concrete counterexam\u00adple. For example, take input .-1 = 1, \n.0 = 1. The program will produce output .0 for that input without reading .-1, showing that p 1/pt1 is \nspurious because symbolic outputs do not match. We re\u00ad.ne the abstraction with respect to a new set of \npredicates, obtained by some predicate selection method (e.g., by taking atomic predi\u00adcates in the weakest \nprecondition computed along the path [6]). Suppose such method returns {i = 0, i = 2} at this instance. \nThe re.ned abstraction A2 is shown in Figure 3d. Equivalence checking of A2 and C1 produces the second \nsymbolic counterexample, say pp2 = true\u00b7true\u00b7true and pt2 = .0 \u00b7.0 \u00b7(.0 -.-1). Any sequence of three \nsymbols will satisfy p 2 and it turns out that counterexample is not spurious. Thus, we have to re.ne \nthe conjecture. After processing the counterexample, S * learns conjecture C2 shown in Figure 3b. C2 \nis correct, but S * does not know that yet, because equivalence checking of C2 and A2 returns the third \ncounterexample, say pp3 = true \u00b7 true \u00b7 (.0 < .-1) and pt3 = .0 \u00b7 .0 \u00b7 (.0 + .1). The third counterexample \nis not spurious either. Thus, once again, we need to re.ne the abstraction. Using the same method for \nre.nement as above, we extend the set of predicates with .0 < .-1. Predicate abstraction computes A3, \nwhich is equivalent to C2, and the process terminates, faithfully inferring the program s input-output \nrelation, i.e., the speci.cation of program s input-output behavior.  For the following example with \nnested loops, S * terminates inferring a SLT with lookback 0, shown on the right. while (true) { .0 = \na/e .0= a/.0 x = in(); while (x != a ) { .0 = a/.0 x = in(); out(x); } } .0= a/e 3. Transductive Programs \nWe now turn to the formal development of S * . In this section, we formalize the syntax and semantics \nof programs that transform an input stream into an output stream of symbols. Behavior of cer\u00adtain such \nprograms can be represented by SLTs (\u00a74). We also for\u00admally de.ne concepts associated with the dynamic \nsymbolic exe\u00adcution, which we use in development of over-approximations (\u00a75) and learning (\u00a76). To simplify \nexposition, henceforth we assume programs working with streams of integers. 3.1 Preliminaries Let Z be \nthe set of integers, N = {i . Z | i > 0} the set of naturals, and B = {false, true} the set of booleans. \nFor a set D, we denote by D * the free monoid generated by D with concatenation as the operation and \nthe empty word e as identity. We refer to words in D * as sequences. Sequences of predicates (resp. terms) \nwe denote by p = p1 \u00b7 \u00b7 \u00b7 pm (resp. t = t1 \u00b7 \u00b7 \u00b7 tn). For sequences of sequences of terms, we write pt. \nWe denote the length of p by |p |, the i-th element of p by p |i and the subsequence pi \u00b7 \u00b7 \u00b7 pi+k by \np |[i,i+k]. For f : D . C and D ' . D, we write f|DI to denote the restriction of f on D ' . For pa andpb \nsuch that n . |pa| = |pb|, we write f[pa . pb] to denote the function f ' such that for all i . {1, . \n. . , n}, f ' (pa|i) b|i and for all x . {pa|1, . . . ,pa|n}, f ' (x) = f(x). We = p/use t[x . y] to \ndenote the term obtained from t by simultaneously replacing all free occurrences of x with y. Vars(t) \ndenotes the set of all free variables in t. 3.2 Syntactic Representation We .rst de.ne syntactic representation \nof programs. Let V be the set of program variables. Expressions (terms) Exp[V], predicates BExp[V], and \natomic commands Cmd[V] over V are given by: e ::= k | x | f(e) | . . . . Exp[V] b ::= false | true | \n\u00acb | b . b | b . b |e = e | e . BExp[V] = e | R(e) | . . . c ::= assume(b) | x := e | x := peek(k) |x \n:= in() | out(e) . Cmd[V] where k . Z, x . V, while f and R are constructors for terms and predicates. \nAs long as the quanti.er-free theory of Exp[V] with equality and satis.ability of BExp[V] are decidable, \npar\u00adticular details of the grammar are not important. The command x := peek(k) reads a data item at offset \nk from the current symbol in the input stream and stores the item to x if the input is avail\u00adable, otherwise \nit causes the program to halt. The in() command works like peek(0) but in addition consumes the item \nfrom the in\u00adput stream and moves onto the next input symbol. The command out(e) writes the value of e \nto the output stream. We represent programs using control-.ow automata [36] over the language of atomic \ncommands. The control-.ow automaton is determined by a set of control nodes N containing a distinguished \nnode sN . N representing the starting point of the program and a function succ: N \u00d7 Cmd[V] -N representing \nlabeled edges. All nodes either have a single successor or have all outgoing edges labeled with a label \nof the form assume(b). In the latter case, we = k [k]s . . s(x) if x . V, . = x if x . VI, [x]s . unde.ned \notherwise . [f(e)]s = f([e1]s, . . . , [en]s) Figure 4: Symbolic Evaluation of Expressions. assume(b) \n' (n, s, ., i, j) p (n , s, ., i, j) xp:=e ' (n, s, ., i, j) (n , s[x . [e]s], ., i, j) x:=peek(k) ' \n(n, s, ., i, j) p (n , s[x . [ini+k]s], ., i, j) x:=pin() (n, s, ., i, j) (n ' , s[x . [ini]s], ., i \n+ 1, j) outp(e) (n, s, ., i, j) (n ' , s, .[outj . [e]s], i, j + 1) Figure 5: Symbolic Semantics of Commands. \nassume that all corresponding predicates b are mutually exclusive and that their disjunction is a tautology. \n 3.3 Symbolic Semantics Given a program P we now de.ne its symbolic semantics. We formalize the contents \nof the input and the output stream with sets of variables VI . {in1, in2, . . .} (in-variables) and VO \n. {out1, out2, . . .} (out-variables), respectively. On a particular run of P, all except .nitely many \nof these variables are unde.ned, and for those which are de.ned, ini corresponds to the i-th element \nof the input stream, and outj to the j-th element of the output stream. By p in we refer to the sequence \nof in-variables in1in2 . . . and we use gin to denote the length of the data sequence in the input stream. \nWe evaluate expressions on a memory s . Mem . V -Exp[VI] as indicated in Figure 4. We execute commands \non states of the form State . N \u00d7 Mem \u00d7 OutStr \u00d7 N \u00d7 N. The third component, OutStr . VO -Exp[VI], represents \nthe symbols in the output stream. The last two components of the state, the in\u00adindex and the out-index, \nstore indices of the current element in the input stream and the output stream, respectively. We denote \nthe components of a state s . State by s.n, s.s, s.., s.i, and s.j, respectively. The initial state is \ns0 = (sN, \u00d8, \u00d8, 1, 1). We represent the symbolic semantics of P by a labeled tran\u00adsition system (LTS) \nT = (State, C, p) with State as the set of states, C . Cmd[V] as the .nite set of labels, and p as the \nla\u00adbeled transition relation. The relation p . State \u00d7 C \u00d7 State is de.ned by the rules given in Figure \n5, showing the effect of each command on a state. In each rule we have n ' = succ(n, c). We c ' write \ns p s to denote the transition (s, c, s ' ) . p.  3.4 Dynamic Symbolic Traces, Path Predicates and Outputs \nThe LTS T encodes the symbolic semantics of P with respect to any input. Given a concrete input pa . \nZ* , we can construct a sequence of states in T representing the (dynamic) symbolic trace of P driven \nby pa, as in [16, 28, 49]. We start with the initial state c s0 and at each step we follow the transition \nsi p si+1, such that if c is of the form assume(b) then b is true in si.s[ pa]. We stop in . p if we \never reach a state sf , which we call ending, such that the in\u00ad :=peek(k) index sf .i equals gin + 1 \nor sf has an outgoing p -transition with k such that sf .i + k > gin. We de.ne the symbolic trace of \n P on input pa, denoted tP (pa), as the .nite sequence s0s1 . . . sf .0 stands for the current symbol \nin the input stream, .-i for the if an ending state is reached, or as the in.nite sequence s0s1 . . . \nsymbol i positions back and .i for the symbol i positions ahead. .i. denote a variable substitution that \nmaps each in\u00ad - otherwise. Let p in We refer to a state si as in-state if si = s0, si = sf or the variable \ninj to .-variable .j-i. We de.ne relativization of a state :=in()ii -. .], .[ p. -.], j). In\u00ad pp p (n, \ns, ., i, j) by .(s) incoming transition reads an input symbol, i.e., si-1 si. Let s = (n, s[ p in in \ntuitively, .(s) relativizes symbolic expressions in s with respect to the current in-index. For general \ntransductive programs, expres\u00ad sions in s-and .-components of .(s) may use unboundedly many .-variables \nas the expressions can refer to inputs from arbitrary p tin P (pa) s 0s 1 . . . s n be the sequence of \nin-states from tP (pa). We de.ne big-step transition as a transition between two successive states in \ntP in(pa). For 1 = i = n, let pi be the conjunction of predicates b of the form assume(b) encountered \non all transitions far in the past. However, k-lookback programs use only up to k .-variables with negative \nindex, namely, .-k, . . . , .-1. assume( ) between s i-1 and s i. In case no p -transitions exist between \nsi we set pi to true. Furthermore, for 1 = i = n, let ti s i-1 and be the sequence of symbolic outputs \n(as written to out-variables by out( ) p -transitions) between s i-1 and s i. If no output is generated \nwe set ti to e. We de.ne path predicates of P on input pa as the sequence pP (pa) p1 \u00b7 \u00b7 \u00b7 pn. Analogously, \nwe de.ne the symbolic output of P on pa by .P (pa) t1 \u00b7 \u00b7 \u00b7 tn. The concrete output of P on pa is de.ned \nby .P (pa) a)[ pa]. .P (pin . p  3.5 Transductive and k-lookback Programs In order to be able to learn \nprogram behavior, we have to make some assumptions about programs. Firstly, when considering the input-output \nbehavior of a program, no path in a program should end up in a loop without reading an input, i.e., we \nwill not allow in\u00ad.nite periods of silence during which the program would not read any input. This .rst \nassumption will allow us to extend incomplete conjectures of program behavior with new big-step transitions. \nSec\u00adondly, we will assume that programs produce uniformly bounded number of output symbols per each big-step \ntransition. This second assumption is inherent to symbolic transducers [14], on which we base SLTs (\u00a74), \nthe model of program behaviour used in S * . More formally, let T be the LTS of P and . any symbolic \ntrace in T starting with s0 and ending with an in-state. Let us denote :=in() by #in(.) the number of \np -transitions in . and by #out(.) out( ) the number of p -transitions in .. We say that P is transductive \nif there are no in.nite symbolic traces in T with only .nitely many in-states, and there exists M . N \nsuch that for every . as above we have #out(.) < M \u00b7 #in(.). As a consequence, if P is transductive then \nfor every input pa, tP (pa) is .nite and |.P (pa)| = |.P (pa)| < M \u00b7 |pa|. Besides transductiveness, \nwe impose an additional require\u00adment that is speci.c to the type of transducers that we use to represent \nprogram behavior in S *, but that could be relaxed if we would use more expressive models (such as, e.g., \ntransduc\u00aders with registers [3, 14]). This additional requirement asks that transductive programs produce \noutputs from a bounded number of inputs in the past. More formally, we say that P is k-lookback if out(e) \nP is transductive and for every . as above, each p -transition out(e) in . depends only on previous k \ninputs, i.e., if s p s ' then Vars([e]s.s) . {ins.i-k, . . . , ins.i}. In \u00a75 and \u00a76 we focus on a class \nof k-lookback programs whose behavior can be represented with SLTs.  3.6 Input Relativization In development \nof over-approximations (\u00a75) and the learning algo\u00adrithm (\u00a76), we will need to rephrase symbolic expressions \npertain\u00ading to program states so that they use the offset from the current position in the input stream \nrather than from the beginning. We show how to relativize these expressions so that the offset becomes \nrelative to the current in-index. Let V. {. . . , .-1, .0, .1, . . .} be an in.nite set of .\u00advariables, \nindexed by a relative offset. We use .-variables so that 4. Symbolic Transducers with Lookback In the \nlast section, we formalized the syntax and semantics of pro\u00adgrams. In this section, we introduce symbolic \nlookback transducers (SLTs) with a constructive equivalence checking algorithm. We use SLTs to represent \nsynthesized over-approximations (\u00a75) and sym\u00adbolic conjectures in the learning algorithm (\u00a76). 4.1 Background \nFinite-state transducers are an extension of classic .nite-state au\u00adtomata obtained by allowing output \non transitions (see [46]). Sym\u00adbolic .nite-state transducers [14] extend .nite-state transducers by symbolic \ntransitions, which are de.ned using predicates for input guards and symbolic terms for output. Our notion \nof SLTs extends symbolic .nite-state transducers with a sliding window over input, which allows a transducer \nto generate outputs based on a bounded number of inputs from the past.  4.2 De.nitions We now formally \nde.ne symbolic .nite-state transducers with k\u00adlookback k-SLTs. We specialize our exposition for the \ncase when the alphabet of input and output symbols is Z, but gener\u00adalization is easy. We omit k, when \nit is not important. Instead of reading a single symbol from the input tape at a time, the tape head \nof a k-SLT is effectively a window of size k + 1, reading the current and the last k symbols. Equivalently, \nsuch a transducer can be seen as a transducer with k registers updated in a FIFO manner on each transition \nthe newly read symbol is inserted, while the oldest is removed from the queue. Rather than using registers, \nwe use the set of .-variables V. k := {.-k, . . . , .-1, .0} so that .0 is the current symbol and .-i \nis the symbol i positions back. De.nition 1. A symbolic .nite transducer with lookback k (k-SLT) is a \ntuple A = (Q, q0, .) where Q is a .nite set of states, q0 . Q is the initial state and . . Q \u00d7 BExp[V. \nk ] \u00d7 Q \u00d7 Exp[Vk .] * is a .nite transition relation. In other words, SLT is a variant of a symbolic \nsequential e\u00adinput-free (i.e., real-time) transducer having only .nal states,2 and in general can be \nnon-deterministic and does not have to be bounded-valued. We say that SLT A is deterministic if for every \ntwo transitions I ./t .I/t q --. r and q ---. r ' if . . . ' is satis.able then r = r ' and (. . . ' \n) . t = t ' is valid. SLTs that are inferred by the S * s learning algorithm will always be deterministic \nand even more, transitions from every state will have mutually disjoint guards. We next formally de.ne \nhow SLTs produce output. Before de.ning a run of an SLT, we introduce some convenient notation. 2 It \nis unclear how to learn transducers with non-.nal states, as such trans\u00adducers allow inherent ambiguity \nin where the output is produced. Indeed, existing algorithms for learning concrete transducers (e.g., \n[50, 58]) require all states to be .nal.  For brevity, we refer to the sequence .-k . . . .0 as .. To \nprocess the input, k-SLT prepends it with k dummy symbols . ./Z. Any operation with . yields . and every \ncomparison with . (except . .k . = .) is false. For a sequence pa, let us denote pa \u00b7 pa. A run of k-SLT \nA = (Q, q0, .) on pa . Zn is a .nite sequence of states q0 . . . qn such that there exists a sequence \nof transitions .1/t1.2/t2.n/tn q0 - --. q1 - --. q2 \u00b7 \u00b7 \u00b7 qn-1 ----. qn, where .1, . . . , .n . BExp[Vk \n. Exp[Vk .] and t1, . . . , tn .] * such that for all 1 = i = n, pa .|[i,i+k] satis.es .i. We say that \nA on the input pa produces the output po . Z* and write pa -A po if for all e p  4.5 Extension with \nLookahead SLTs can be straightforwardly extended to incorporate lookahead. In our model of SLTs, the \nsliding window begins at the current input tape head position and covers k last symbols. Such window \ncan also be made to cover symbols ahead of the current head position by using additional .-variables \n.1, . . . , .l such that .i stands for the symbol i positions ahead. A k-SLT with a lookahead l can be \nreduced to a (k + l)-SLT, so equivalence checking of SLTs with lookahead can be reduced to equivalence \nchecking of SLTs. 5. Synthesis of Over-Approximations .|[i,i+k], where po|i If A is deterministic, the \nrun is uniquely determined by the input 1 = i = n, oi sequence. For a deterministic A and pa . Z* , let \nus denote by pA(pa), .A(pa) and .A(pa) the corresponding sequences .1 \u00b7 \u00b7 \u00b7 .n, t1 \u00b7 \u00b7 \u00b7 tn, and o1 \u00b7 \n\u00b7 \u00b7 on, respectively. We de.ne the transduction of (a possibly nondeterministic) A as a function TA : \nZ* . 2Z* de.ned by TA(pa) {po | pa -A po}. We say that A is single-valued if for all pa, |TA(pa)| = 1. \n4.3 Composition of SLTs SLTs are closed under composition. Given a k-SLT A and a l-SLT B, their composition \nis a (k + l)-SLT A . B such that TA.B(pa) = {TB(po) | po . TA(pa)}. The composition of SLTs can be con\u00adstructed \nsimilarly as the composition of symbolic .nite-state trans\u00adducers [14].  4.4 Equivalence Checking Unfortunately, \ngeneral equivalence checking of SLTs is undecid\u00adable as it is already undecidable to check equivalence \nof con\u00adcrete non-deterministic e-free .nite-state transducers [41]. While the technique of Bj\u00f8rner et \nal. [14] could be adapted to SLTs to decide the single-valued case, that would not suf.ce in our case \nas over-approximations of programs (\u00a75) need not to be bounded\u00advalued. Fortunately, our learning conjectures \nare always determin\u00adistic, so in fact we only need to check equivalence between a deter\u00administic and \na (possibly) non-deterministic SLT. We present an ef.cient algorithm for equivalence checking be\u00adtween \ndeterministic and non-deterministic SLTs, which is a sym\u00adbolic adaptation of the algorithm from Demers \net al. [22] for decid\u00ading single-valuedness of .nite-state transducers. To check whether a deterministic \nand non-deterministic SLT are equivalent, it suf\u00ad.ces to check whether their union (which is a non-deterministic \nSLT) is single-valued. Checking whether a non-deterministic SLT A = (Q, q0, .) is single-valued is ef.ciently \ndecidable in O(|Q|2) time [22] by checking whether a linear grammar generated from A generates a language \nof palindromes [38]. Let (N, T, P, S) be a linear context-free grammar, with a .\u00adnite set of non-terminals \n(resp. terminals) N (resp. T ), a .nite set of productions P of the form N ::= T NT | e, and the start \nsymbol S . N. From a k-SLT A, generate a grammar G = p (Q\u00d7Q, BExp[Vk .] * .]\u00d7Exp[Vk , P, [q0, q0]), where \nP is de.ned as '' ' [s1, s2] ::= (.1, t1)[s1, s2](.2, t2), such that (si, .i, ti, si) . ., c i .i is \nsatis.able, and ti = .. By ., our learning algorithm de\u00adnotes outputs on transitions that are either \ninfeasible because of the constraints on the path condition, or subsumed by other predicates. A is single-valued \niff G generates a set of palindromes. Checking whether the outputs match under the guards reduces to \nchecking c the validity of formula ( i .i) . t1 = t2, which can be done with O(|Q|2) calls to the prover. \nIf A is not single valued then we construct a witness for disequality between the deterministic and the \nnon-deterministic SLT called separating sequence by .nding the shortest path from the start symbol to \nthe .rst reachable rule = ti . . pa = oi. that does not generate a palindrome. We now show how to synthesize \nsound program over-approxima\u00ad tions for a class of programs with .nite lookback. Overapproxi\u00ad iii mations \nare computed in two steps. In the .rst step, we construct an over-approximation of the program that is \nbased on predicate abstraction [8, 30]. In the second step, we transform the obtained abstraction to \nan equivalent non-deterministic SLT. We re.ne such an SLT by augmenting the set of predicates in predicate \nabstraction. 5.1 Abstraction of Transductive Programs The goal of the abstraction is to abstract away \nthe internal com\u00adputation of the program but in doing so to keep all of its original input-output behavior. \nLet us consider the LTS T = (State, C, p) of a transductive program P as de.ned in \u00a73.3. We parameterize \nour abstraction by a set of predicates F over program variables, in\u00adterpreted over V -Z. Let us denote \nby Pred(F) the set of boolean combinations over predicates from F (i.e., all minterms). We de.ne 4 4 \nthe abstraction of T as the LTS T= (State4, C, p) constructed as follows. The set of abstract states \nState4 is given by 4 StateN \u00d7 Pred(F) \u00d7 (VD -Exp[VI]) \u00d7 OutStr \u00d7 N\u00d7 N where the valuations of program \nvariables are mapped to predi\u00adcates in Pred(F) satis.ed by the valuation, while the data variables VD \n. V that are live (i.e., for which there exists data .ow to output terms), are kept intact along with \nother components of the state. Using the approximate post operator on Pred(F) computed with predicate \nabstraction we obtain the transition relation p4 on ab\u00adstract states. We rely on the soundness of the \npredicate abstraction to obtain the following. Proposition 2. For every input pa, if tP (pa) = s0 . . \n. sn is a trace in 4' ' T , then there exists a trace tP (pa) = s0 . . . sn in T4 such that for ' ''' \nevery 0 = i = n, si.n = si.n, si.. = si.. si.i = si.i, si.j = si.j, si.s|VD = si ' .s and si.s satis.es \nsi ' ... Consequently, the output 44.P (pa) corresponding to the trace tP (pa) is equal to .P (pa). \n 5.2 Translation to SLTs We now translate the abstract LTS T 4 = (State4, C, p4) into an equivalent (possibly \nnon-deterministic) SLT. We de.ne an equiv\u00ad ' alence relation ~ on State4 as follows. For s, s . State4, \nwe ' ' let s ~ s iff3 for .(s) = (n, .., s., .., j) and .(s ) = '' ' (n , . ' ., . ' ) we have n = n \n. and s. = s ' ., s ' ., j , .. . . ' .. Relation ~ can have in.nitely many equivalence classes in general, \nhowever, we focus on programs having .nite-index ~, as we can represent such programs with SLTs and learn \nwith S * . De.nition 3. We say that P is SLT-representable if for any choice of F, the corresponding \nrelation ~ is of .nite index. SLT-representable programs necessary have a bounded lookback. 4 Let us \nde.ne paths(s, t) as the set of all p4-sequences of in states between s and t such that there is a single \ninput transition 3 We extend the de.nition of input-relativization to s = (n, ., s, ., i, j) . iii -.], \ns[i. -.], j). . -.], .[i. State4 by .(s) (n, .[i in in in  between states on the path from s to t. For \n. . paths4 (s, t), in let us denote by p4(.) the conjunction of assumed predicates on transitions in \n. and let .4(.) be the produced symbolic output. We need the following lemma for our translation to an \nSLT to be well\u00adde.ned. Lemma 4. If s ~ s ' and t ~ t ' then for every path . . ' ' paths4 (s, t), there \nexists an equivalent path . ' . paths4 (s , t ) in in such that p4(.) = p4(. ' ) and .4(.) = .4(. ' ). \nWe de.ne AF to be the SLT (Q, q0, .) with Q {[s]~ |s is in-state} as the set of states, q0 [s0]~ as the \ninitial state ./t and . as the transition relation such that [s] --. [s ' ] . . iff there exist . . paths4 \n(s, s ' ), such that p4(.) = . and .4(.) = in t. Intuitively, AF represents all isomorphism classes of \nbig-step transitions between the abstracted in-states. Lemma 5. If P is SLT-representable then AF is \nan SLT. We can now show that AF captures exactly the behavior of T 4 thus AF soundly over-approximates \nthe behavior of P. Proposition 6. For all pa, .4 (pa) = po iff pa . po. P -AF Corollary 7. For all pa, \nif .P (pa) = po then pa . -AF po.  5.3 Re.nement Suppose that AF strictly over-approximates the behavior \nof an SLT-representable P on some input pa, i.e., there exist po and po ' , po = po ' , such that .P \n(pa) = po and pa -AF po ' . Then we need to re.ne the abstraction AF. We do so by adding enough predicates \nto F to evidence infeasibility of the spurious run in AF that generates po ' . Our approach to .nding \na new set of predicates for re.ning AF is based on standard counterexample feasibility analysis with \nweakest preconditions [6]. The basic idea is to build a predicate a from the spurious trace in AF generating \npo ' so that a is unsatis.\u00adable if and only if the given trace is infeasible in P. Starting with false, \na is obtained by applying the weakest precondition of com\u00admands in P along the trace, until the beginning \nof the trace. To maintain the syntactic form of assume-predicates collected along the trace, we keep \nall substitutions in a explicitly. The set of all atomic predicates in a is then used to augment F. 4 \nAlthough more involved methods (e.g., based on Craig interpolation) are possi\u00adble, our empirical evaluation \nshows that this heuristic works well in practice for our target classes of programs. Completeness of \nthe predicate selection method. Since our ab\u00adstraction is based on predicate abstraction and fully precise \nisomor\u00adphic representation of other components of the state, AF in fact de\u00ad.nes the strongest inductive \ninvariant containing the reachable set of states of P that is expressible as a Boolean combination of \nthe given set of predicates, while faithfully preserving the input-output relation in the relativized \nform. If there exists a quanti.er-free in\u00adductive invariant . which can be built using some set of predicates \nF such that . uniquely identi.es the reachable states of P, then the other transducers up to n states. \nTo abstract away the complexity of such construction, we assume existence of a predicate selection method \nthat eventually yields a set F resulting in an abstraction AF equivalent to P. We will say that a predicate \nselection method is complete if it is guaranteed to eventually generate a suf.cient set of predicates \nto construct AF equivalent to P. Our main result expresses completeness of our learning algorithm relative \nto exis\u00adtence of such a complete predicate selection method. However, we emphasize that the predicate \nselection mechanism does not affect the soundness of S * , nor the quality of inferred models, only the \neventual convergence. pp 6. Learning In this section, we describe S * s learning algorithm and prove \nits main properties. Our algorithm iteratively builds conjectures simi\u00adlarly as L * . To make the presentation \nreasonably self-contained, we .rst give a brief overview of L * (\u00a76.1). We then de.ne the represen\u00adtation \nof conjectures (\u00a76.2), followed by the detailed presentation of the learning algorithm (\u00a76.3) and its \nproperties (\u00a76.4). 6.1 Background: Overview of L * Here we give an informal overview of the classic L \n* . See the paper of Angluin [5] for a more detailed description (or Shahbaz and Groz [50] for the Mealy \nmachines version of L *). The goal of L * is to learn an unknown regular language D by generating a deterministic \n.nite automaton (DFA) that accepts D. L * starts by asking a teacher, who knows D, membership queries \nover a known concrete alphabet to check whether certain words are in D. The results of these queries \nare recorded in a so-called obser\u00advation table. Membership queries are iteratively asked until certain \ntechnical conditions are met, upon which L * conjectures an au\u00adtomaton. L * asks the teacher an equivalence \nquery to check if the conjectured language is equivalent to D. The teacher either con\u00ad.rms the equivalence \nor returns a counterexample, which is a word that distinguishes D from the conjecture. L * uses the counterex\u00adample \nto devise new membership queries, re.ning the conjecture. This procedure is repeated until the conjecture \nbecomes equivalent to D. If D is indeed a regular language then L * is guaranteed to .nd a (minimal) \nDFA for D after at most a polynomial number of membership and equivalence queries. In S * , we answer \nthe membership queries by using a combi\u00adnation of concrete and symbolic execution [16, 28, 49], and the \nequivalence queries by equivalence checking learned conjectures and increasingly re.ned abstractions, \nusing the equivalence check\u00ading algorithm for SLTs (\u00a74.4).  6.2 De.nitions We proceed by giving notational \nconveniences used in the section and de.ning S * s representation of the observation table. We .rst de.ne \na relativization function for path predicates and 1n symbolic outputs by .(s1 . . . sn) s1[ p -.] . . \n. sn[ p. in . -.], in i - . construction of abstraction would converge. Assuming a complete where p \nin p . is the variable substitution de.ned in \u00a73.6 and pdecision procedure for the underlying theory \nand a predicate se-either a path predicate or symbolic output. If ps is a symbolic out\u00adlection method \nthat would eventually build such F, by the relative put pt, the same relativization function is applied \nto each individual s is completeness of predicate abstraction [9, 42], we could generate an term in the \nsubsequence, i.e., if t = then t[ p -i t1 . . . tm in . p p .] .]. We next de.ne witness as a function \nthat takes a sequence of relativized predicates, derelativizes them = invariant as strong as .. Although \nit is not clear how to construct such . directly from p ii -. - . t1[ p in .] . . . tm[ pin P, we can \nconstruct it if the number of states n of an SLT AP that by applying the inverse of the . substitution, \ncomputes a conjunc\u00ad co u is behaviorally equivalent to P is known a priori by explicitly en\u00ad coding a \nchecking sequence [46] that distinguishes AP from all .-1 tion of derelativized predicates (p ) |i, passes \nthe conjunction to an SMT solver, and returns a concrete sequence 1=i=|p?| 4 In some examples we employ \nadditional heuristic that uses templates built of input symbols of length |p | satisfying the conjunction, \nor . if from syntactic predicates in the code. the conjunction is infeasible. Finally, we point out that \nall equality (resp. inequality) checks = (resp. =) over predicates and terms in this section are syntactic \nequality (resp. inequality) checks.5 S * constructs symbolic observation table similarly as L * , but \ntable entries are path predicates and symbolic outputs (\u00a73.4), rather than concrete words. The .nished \ntable can be easily translated into an SLT, representing a conjecture. As in L * , such conjecture will \nalways be deterministic. De.nition 8. Symbolic observation table is a quadruple (R, S, E, T ) . (BExp[V.] \n* , BExp[V.] * , BExp[V.] * , BExp[V.] * \u00d7 BExp[V.] * . (Exp[V.] . {., e}) * ), where -R . S represents \na set of identi.ed states, -S (resp. E) is a pre.x-(resp. suf.x-) closed set of relativized path predicates, \nand -T is a map indexed by p p . S, p s . E, containing the suf.x of the relativized symbolic output \ngenerated when processing p s immediately after p p, i.e., if pa = witness(p p \u00b7 p s) and pt = .(.P (pa)) \nthen T [p p, p s] = pts, where pts is a suf.x of pt such that |pts| = |p s|. For p . S, we de.ne a p \n-row in the observation table as an E-indexed set, denoted p -row. We denote outputs generated by infeasible \ntransitions in the table by .. Intuitively, R represents a set of shortest paths leading to dis\u00adcovered \nstates, S . R contains exactly path predicates from R and additionally all the sequences that extend \nsequences from R by exactly one big-step transition. The role of S is to exercise all the transitions \nin the inferred SLT. Finally, E is the set of distinguish\u00ading tests that distinguish different states. \nThe classic L * makes a conjecture when the table is closed, which means that every sequence in S has \na representative in R, i.e., .p . S . .pr . R . p -row = pr-row. We de.ne closedness in the same way \nas L * . From a closed table, we can easily construct a complete (for all states and input symbols, all \ntransitions are de.ned) SLT using standard techniques (e.g., see [5, 50]).6  6.3 The Learning Algorithm \nWe begin by describing the FILLROWS algorithm that computes the missing entries of the observation table, \ncontinue with the EXTENDTABLE algorithm that explores the successor states of all states discovered at \ncertain step, and end with the S * s learning algorithm. Algorithm 1 computes the missing entries in \nthe observation table. If the entry is missing for some pre.x p p . S and suf.x p s . E, we .rst try \nto compute a concrete witness pa by splicing together the pre.x and the suf.x (Line 2). While the sets \nS (and R) contain path predicates that are collected along pre.xes of some feasible paths in P starting \nfrom the initial state, the set E contains suf.xes of feasible paths. Naturally, when we arbitrarily \nsplice pre.xes and suf.xes of different paths, the resulting formula might be infeasible. If feasible, \nwe execute pa on P using concolic execution (Line 4) and collect the predicates (pr) and output terms \n(pt) from big-step transitions. Note that the collected predicates might differ from p p \u00b7 p s, but at \nleast the pre.x (corresponding to p p) will always match. The outputs corresponding to mismatched 5 At \nthe cost of more complex exposition, we could use semantic equality and check that output terms are equal \nunder the guard restrictions. Such an approach might allow us to learn more compact SLTs. 6 In L* , one \nalso de.nes the consistency property, which would in our setting say that if two sequences pi1, ip2 from \nR are equivalent, then both states reached by .P (witness(pi1)) and .P (witness(pi2)) must produce the \nsame output in the next big-step transition given the same input symbol. We maintain the consistency \nof our symbolic observation table by always assuring that each state has only one representative in the \nR set. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 input and output : Observation table OT forall the p p \n. S, p s . E such that T [p p, p s] is unde.ned do pa := witness(p p \u00b7 p s) if pa = . then (pr,pt) := \n(.(pP (pa)), .(.P (pa))) // assert(|pr| = |pt|) p ts := e forall the 1 = i = |pt| do if i > |p p| then \nif (p p \u00b7 p s)|i = pr|i then pts := pts \u00b7 pt|i else pts := pts \u00b7 . else // assert(p p|i = pr|i) T [p \np, p s] := pts else T [p p, p s] := . // Close the table forall the p . S s.t. \u00ac.pr . R . p -row = pr-row \ndo R := R . p // New state Return OT Algorithm 1: The FILLROWS Algorithm. predicates and infeasible path \nconditions are marked .. Lines 6 9 replace the output terms at positions where the p p \u00b7 p s and pr sequences \ndiffer syntactically. Finally, lines 14 15 close the table. Algorithm 2 takes a state representative \npr, i.e., a path predicate that holds on the shortest path to the identi.ed state, and .nds all the outgoing \nbig-step transitions from that state, adding the predicates from those transitions to E and the entire \nsequence (pr extended by one transition) to S. The only interesting part of the algorithm is the discovery \nof new transitions and the corresponding predicates. In the .rst iteration, Line 6 extends the representative \nsequence pr with predicate true, effectively allowing the solver to produce an arbitrary value for the \nlast element of the concrete input sequence. Executing the obtained concrete sequence and collecting \npredicates along the path, we identify the .rst big-step transition guard pred\u00adicate (rs). In every following \niteration, we negate a disjunction of the predicates discovered so far, until the disjunction becomes \nvalid (test at Line 4). All infeasible traces lead to a ghost state that has one self-loop transition \nlabeled true/.. The algorithm creates such a state automatically, if needed, by .lling the corresponding \nrow with ., as even the pre.x to the ghost state is infeasible. Finally, Algorithm 3 infers a symbolic \ntransducer. Lines 1 9 discover all the big-step transitions from the initial state and the corresponding \npredicates. All the discovered predicates are added to the set E. In the next three lines, we extend \nand close the table, producing the .rst AC conjecture and the .rst abstraction AF of P. The loop beginning \non Line 15 checks the equivalence between the conjecture and abstraction. If they are equivalent, the \nalgorithm terminates returning the exact transducer implemented by P. Oth\u00aderwise, the counterexample \nis checked against P. If it is spurious, we re.ne the abstraction, otherwise, we re.ne the conjecture. \nWe use Shahbaz and Groz s [50] technique for processing the coun\u00adterexamples adapted for our symbolic \nsetting. First, we collect the predicates from P along the path determined by the counterexam\u00adple and \ndiscard the longest pre.x that is already in S. We denote the remaining suf.x by p s. We add all suf.xes \nof p s to E (Line 24), to assure that E remains suf.x closed.  6.4 Properties First, we state the main \nproperties of S * , and then proceed with the proof of relative completeness and a discussion of computational \ncomplexity.  input and output : Observation table OT 1 forall the pr . R do // Extend all sequences \nfrom R 2 3 if \u00ac.p s . E . |p s| = 1 . pr \u00b7 p s . S then s := false 4 while s . true do 5 rs := e 6 pa \n:= witness(pr \u00b7 \u00acs) 7 if a = . then 8 rs := \u00acs 9 s := true 10 else 11 p := .(pP (pa)) 12 // assert(|p \n| = |pr| + 1) rs := p ||?r|+1 s := s . rs 13 14 15 E := E . {rs}S := S . {pr \u00b7 rs}OT :=FILLROWS(OT ) \n 16 Return OT Algorithm 2: The EXTENDTABLE Algorithm. init : R = {e}, S = {e}, E = \u00d8, T = \u00d8, i = 0, s \n= false result : k-SLT AC  1 repeat // Fill 1st row 2 if s . false then 3 a := randomly generated array \nof type Z[1] 4 else 5 a := witness(\u00acs) 6 p := . (pP (a)|1) // 1st pred. from path predicate 7 E := E \n. p 8 T [e, p] := . (.P (a)|1) 9 s := s . p 10 until s . true 11 (R, S, E, T ) :=EXTENDTABLE(FILLROWS(R, \nS, E, T )) 12 Compute AC from (R, S, E, T ) 13 Compute initial AF of P 14 while true do 15 Let (pa, po) \nbe a separating sequence between AC and AF 16 if pa = e then 17 Return AC 18 if .P (pa) = po then \n// Spurious counterexample? 19 Re.ne AF of P on (pa, po) 20 else 21 p := .(pP (pa)) 22 Let p p be \nthe longest pre.x of p s.t. p p . S 23 Let p s be s.t. p = p p \u00b7 p s 24 E := E . Su.x (p s) 25 (R, \nS, E, T ) :=EXTENDTABLE(FILLROWS(R, S, E, T )) 26 Compute AC from (R, S, E, T ) Algorithm 3: The S * \ns Learning Algorithm. Lemma 9. Let T = (R, S, E, T ) be a symbolic observation table. Then S * preserves \nthe following invariants: 1. R and S (resp. E) are always pre.x-(resp. suf.x-) closed. 2. For every \np . S there is a unique pr . R such that p -row =  pr-row. 1 n ni 3. For every pr . R, there are rs \n, . . . , rs such thati=1 rs . true and for all i, it holds that pr \u00b7 rs i . S. 4. The conjecture AC \nis closed at the end of each step.  Correctness. R represents the part of the symbolic execution tree \nof P on which the conjecture faithfully represents the behavior of P, which is stated with the following \nproposition. Proposition 10 (Bounded correctness). After each step, for all pr . R and pa such that pa \n= witness(pr), .P (pa) = .AC (pa) holds. One can rephrase bounded correctness as a guarantee given by \nS * in case S * is interrupted before reaching a convergence. In other words, we can consider S * as \nperforming bounded model checking of the program with a state-space exploration strategy guided by the \nlearned model. Completeness. The following lemma ensures that a progress is made after each conjecture \nre.nement. Lemma 11. If at some step of S * , (pa, po) is a separating sequence such that .P (pa) = po, \nthen at the end of the step, for all pa ' such that pa ' = witness(pP (pa)), .AC (pa ' ) = .P (pa ' ) \nholds. We state the completeness of S * relative to the completeness of the predicate selection method. \nTheorem 12 (Relative completeness). If P is SLT-representable and the predicate selection method for \nre.nement is complete, then S * terminates with AC being behaviorally equivalent to P. Proof. First note \nthat when AF is single-valued, then by the sound\u00adness of abstraction, AF is in fact behaviorally equivalent \nto P. As the predicate selection method is assumed to be complete, we will eventually obtain a single-valued \nAF. The equivalence check of AF and AC always returns the short\u00adest separating sequence (if one exists). \nThere can be only .nitely many shortest separating sequences of a given length, and at each step such \na sequence is used either to re.ne the conjecture or to re.ne the abstraction. Therefore, the number \nof conjecture re.ne\u00adments must also be .nite. Computational complexity. Next, we analyze the complexity \nof S * . Let n be the number of states of the inferred SLT, k the maximal number of outgoing big-step \ntransitions from any state, m the maximal length of any counterexample, and c the number of counterexamples. \nThere can be at most n - 1 counterexamples, as each counterexample distinguishes at least one state. \nSince we initialize E with k predicates, |E| can grow to at most k+m(n-1). The size of S is at most n \n\u00b7 k. Thus, the table can contain at most \u00b7 k2 2 n \u00b7 k \u00b7 (k + m \u00b7 n - m) = O(n + m \u00b7 n \u00b7 k) entries. The \nk factor is likely to be small in practice, and our equivalence checking algorithm .nds the minimal counterexample. \nThe SMT solver is called once per each state (i.e., representative in R) and for each outgoing transition. \nFor each equivalence check, we might need to call the solver n 2 times. Thus, the total worst-case number \nof calls to the solver is O(n \u00b7 k + n 2), not including the number of calls required for abstraction \nre.nement, which depends on the abstraction technique used. 7. Applications In this section, we demonstrate \npractical utility of S * by applying it in three different application domains and reporting experimental \nresults obtained with our prototype implementation. We built our implementation on top of KLEE [17] with \nSTP [25] and CPAchecker [13]. We patched KLEE to generate relativized symbolic traces and answer membership \nqueries for the learning al\u00adgorithm (\u00a76), and used STP in the equivalence checking algorithm (\u00a74.4). \nWe used CPAchecker for counterexample-guided predicate abstraction re.nement (\u00a75). All experiments were \nrun on a machine with Intel Core2 Quad 2.8 GHz CPU and NVIDIA GeForce GTX 460 GPU (with 7 Table 1: Experimental \nResults. The benchmarks that S * successfully learned are denoted by .. The last benchmark could be learned \nif S * were extended to handle subsequential transducers. Int. bits is the size of the internal control \nand data state in bits, #States the number of states in the .nal SLT, #Transitions the number of transitions \nin the .nal SLT, #AC re.nements the number of re.nements of the conjecture, #AF re.nements the number \nof re.nements of the abstraction, and |F| the size of the set of predicates in the .nal abstraction. \nIn each of the four benchmarks whose rows contain symbolic expressions dependent on L, the particular \nL denotes the bound on the size of the buffer internally used by the benchmark. The value of L depends \non the characteristics of the input language of the benchmark and is a priori .xed in our four benchmarks \n(e.g., for HtmlEscape, it is bounded by the maximal length of tag names, attribute names and special \nsymbols).  Benchmark Learned Int. bits #States #Transitions Lookback #AC re.nements #AF re.nements |F| \nEncodeHtml [37] . 8 1 2 0 0 1 10 GetTags [14] . 48 3 7 1 4 5 6 CleanseAttribute . 40 2 4 1 0 3 14 CleanseCss \n. 40 1 2 0 0 2 16 CssUrlEscape . 40 1 11 0 0 1 12 HtmlEscape . 8 L + 1 7 \u00b7 L L L L + 3 L + 11 JavascriptEscape \n. 16 3 16 2 2 6 20 JavascriptNumber . 41 17 19 16 17 23 41 JsonEscape . 8 L + 1 11 \u00b7 L L L L + 3 L + \n12 PreEscape . 8 L + 1 5 \u00b7 L L L L + 3 L + 6 UrlQueryEscape . 8 2 11 0 2 5 19 XMLEscape . 8 L + 1 7 \u00b7 \nL L L - 1 L + 2 L + 11 PrefixLine - 8 SnippetEscape - 8 1.42 GHz multiprocessors, 48 cores each). The \nlearning algorithm inferred all learnable benchmarks described below in less than three seconds. 7.1 \nWeb Sanitizers Veri.cation To make web applications more secure, sanitization is used to remove possibly \nmalicious elements from user s input. Although small in numbers of lines of code, sanitizers in real-world \nappli\u00adcations are surprisingly dif.cult to implement correctly [10, 37], often because low-level implementation \ntricks are obscuring the intended input-output behavior. By automatically inferring input\u00adoutput models \nof sanitizers, we can automatically check their prop\u00aderties such as commutativity, reversibility, and \nidempotence using tool such as Bek [37]. We evaluated S * on the sanitizers from Google AutoEscape (GA) \nweb sanitization framework, the same benchmarks used by Hooimeijer et al. [37]. We dropped the ValidateUrl \nsanitizer, as it is effectively just a wrapper for calling other sanitizers. In addition to GA sanitizers, \nwe added to our benchmark suite the sanitizers EncodeHtml [37] and GetTags [14]. We found out that 86% \nof GA sanitizers (12 out of 14) along with EncodeHtml and GetTags are SLT-representable and were successfully \nlearned by S * (Table 1). In comparison, the authors of [37] had to invest several hours of a human expert \ns time into manual synthesis of each transducer from the source code. Only two sanitizers could not be \ninferred by S * . PrefixLine is effec\u00adtively a 0-SLT, but it is implemented by calling the memchr function \nin guards, which could only be represented by nondeterminism, as memchr s return value could be arbitrarily \nfar ahead from the start of the input string. SnippetEscape generates output from a pre\u00adde.ned set of \nsymbols only at the end of the input, but it could be learned if S * were extended to subsequential transducers \nby gener\u00adalizing Vilar s algorithm [58] to the symbolic setting. 7.2 Stream Filter Optimization Stream \nprograms often consist of many interacting .lters that have to be optimized against various goals (e.g., \nspeed, latency, through\u00adput, . . . ). Two vital .lter optimizations are reordering and fusion. For instance, \nreordering might be pro.table when it would place a .lter that is selective (i.e., drops some data) before \na costly .l\u00adter that does some processing. However, we must ensure that the Table 2: Properties of Eight \nFilters Inferred by S *. First four .l\u00adters are linear and can be optimized with existing techniques. \nS * enables fusion and reordering optimizations for all eight .lters. By stateless, we mean single-state \ntransducers. Benchmark Linear Stateless Saxpy kernel [56] Radix-2 complex FFT .lter [43] FIR .lter [45] \nZig-zag descrambling .lter in MPEG-2 [23] + + + + + + + + Clsfr in L3-Switch bridge [18] FM demodulator \nin StreamIt [54] MPEG-2 internal parser in StreamIt [54] GSM encoder/decoder in MiBench [33] - - - - \n+ + - - two .lters are commutative in order for reordering to be safe. Filter fusion is used when it \nwould be pro.table to trade pipeline paral\u00adlelism for lower communication cost. We conducted a set of \nexperiments to explore ability of S * to enable stream .lter optimizations such as reordering and fusion. \nTable 2 shows eight .lters inferred by S * indicating their two key properties: whether they encode a \nlinear or non-linear output function, and whether they are stateless (i.e., have a single state) or stateful \n(i.e., have more then one state). First four .lters can be optimized with existing techniques for optimizing \nlinear .lters [2, 45]. To our knowledge, no optimization techniques used in existing stream program compilers \ncan optimize the remaining .lters in Table 2. On the other hand, S * enables fusion and reordering optimizations \nfor all eight .lters.  7.3 Parallelization Finally, we show how SLT models of .lters enable automated \nparal\u00adlelization. We consider two approaches to improving utilization of hardware concurrency by mapping \n.lters to (1) multiple cores and (2) SIMD instructions. Stateless .lters are inherently data-parallel \nand lend themselves naturally to both multi-core and vectorized im\u00adplementations by simple replication. \nStateful .lters normally can\u00adnot be parallelized this way as their next invocation depends on the previous \ninvocation. However, SLT .lters have usually small, a pri\u00adori known, number of states, so we can run \neach replica of an SLT .lter from each state in parallel and merge suitable outputs.  To provide some \ninsight into possible practical speedups, we generated SIMD implementations using Intel SSE4 intrinsics \nand GPU implementations using NVIDIA CUDA 4.2 of 11 single-state SLTs (3 from Table 1, 6 from Table 2, \nand 2 hand-crafted) and one three-state SLT inferred by S *. Original source code repre\u00adsentations of \nall SLTs are stateful and some of them are with non\u00adaf.ne loop nests. For the stateless SLTs, we obtained \nspeedups in the range of 1.72 to 3.89 for the SSE versions, and 1.5 to 2.7 for the CUDA versions. For \nthe 3-state SLT, the speedup of the CUDA version was 2.3. CUDA versions were run using 1024 threads (resp. \n1024 threads in 3 blocks) for the single-state (resp. three\u00adstate) SLTs. We established the baseline \nby running the sequential version of SLTs compiled with gcc with all optimizations (-O3) and SSE .ags \nturned on. 8. Discussion Predicate abstraction. To obtain complete models, S * relies on convergence \nof the abstraction. One could rightfully ask why we need the whole learning machinery of S * as we presume \nthe ab\u00adstraction eventually becoming equivalent (although, in a possibly non-deterministic form) to the \nbehavioral model. Our program is deterministic, so as long as the abstraction is not single-valued it \nmust contain infeasible behavior. Therefore, we could consider a procedure that just iteratively re.nes \nthe abstraction until the ab\u00adstraction becomes single-valued. Setting aside how to ef.ciently re.ne abstractions \nalone, an abstraction-only approach suffers from a fundamental limitation: models generated by the abstraction \ncan be unboundedly larger than the ones learned by S *. For instance, consider the program from Figure \n1 in [31], which is considered as an example on which predicate abstraction does not work well. Let us \nadapt the example by adding reading an input and writing some output in the loop, and enclosing it with \nan outer while( true )-loop to become a transductive program. Then S * infers a single-state SLT, while \nby using predicate abstraction alone we would obtain an SLT with 1000 states. SLT limitations. Along \nwith the dependency on the abstraction, ability of S * to infer complete models of program behavior is \nlimited by the expressive power of symbolic conjectures. We have judiciously restricted SLTs so as to \nbe able to represent interesting real-world examples while still being able to learn and equivalence \ncheck them ef.ciently. However, there are still other interesting classes of programs that are not SLT-representable. \nAt the cost of additional complexity, we believe it would be possible to extend S * to work with symbolic \nversions of more expressive transducers such as subsequential [58] and streaming transducers [3] and \nin this way enable learning of larger classes of programs. Incomplete models. While the main concern \nof this paper is learning of exact behavioral models, incomplete models inferred by S * could also be \nuseful, e.g., for automated testing based on dynamic symbolic execution [16, 28, 49]. The learning component \nof S * can be seen as systematically exploring all paths in the exe\u00adcution tree of a program, but in \naddition conjecturing the behavior of not yet explored branches. Conjectures could be used to guide the \nexploration strategy, similarly as in MACE [19], which showed how concrete transducer conjectures enable \nmore effective testing of protocol implementations. 9. Other Related Work Learning of symbolic transducers. \nPrevious work on learning some notion of symbolic transducers [1, 12, 40] focuses on lim\u00adited variations \nthat a priori .x the shape of predicates and generate concrete values. Learning algorithms for these \ntransducers postu\u00adlate existence of an equivalence checking oracle and work over concrete alphabets, \nrelying on the shape restrictions to translate the L *-inferred concrete transducer to a symbolic one. \nAs software artefacts feature predicates that are unknown prior to the analysis, if techniques [1, 12, \n40] were to be applied in the software setting, they would need to exhaustively enumerate predicates, \nwhose set is unbounded. Learning in veri.cation. Techniques for learning various types of automata have \nbeen applied in a wide variety of veri.cation set\u00adtings: inference of interface invariants [4, 27, 51], \nlearning-guided concolic execution [19], compositional veri.cation [21], and regu\u00adlar model checking \n[34]. In those settings, except for [27], learning is performed using concrete alphabets in a black-box \nmanner, even though source code is usually available. Independently to us, Gi\u00adannakopoulou et al. [27] \nhave recently developed a technique for learning component interfaces that combines L * with symbolic \nex\u00adecution to discover method input guards. However, their approach treats method invocations as a single \ninput step with no output, and, unlike S *, assumes that each method has a .nite number of paths. Under \nthis later constraint, equivalence checking can be done by merely executing a suf.ciently large number \nof member\u00adship queries. Alur and .y s approach to synthesis of interface Cern \u00b4speci.cations with JIST \n[4] also uses predicate abstraction as S * . However, predicate abstraction in JIST is used to check \nwhether the synthesized interfaces are safe for a given safety property. In general, such interfaces \nare approximate and may incorporate in\u00adfeasible behavior. In addition, the paper [4] does not demonstrate \nthat the technique can be fully automated. In contrast, S * is fully automated and infers faithful models \nupon termination. Property checking. Although the goal of S * is different, it resem\u00adbles some ideas \nused in property checking. Most closely related, collecting predicates on conditional statements as in \nautomated testing [16, 28, 49] has been previously combined with predicate abstraction in the SYNERGY \nalgorithm [31]. While SYNERGY uses a combination of must and may analyses to check safety prop\u00aderties \nfaster, S * uses must (learning) and may (abstraction) to infer a more compact input-output relation. \nOptimizations of .lters. The closest work to our application of S * for stream compiler optimizations \nis on optimizations of linear .lters [45] and (slightly more general) linear state space systems [2] \nin StreamIt. In another line of work [47], fusion of .lters for Brook has been developed using an af.ne \nmodel. Soul\u00b4 e et al. [52] developed a proof calculus that allows analysis of non\u00adlinear .lters, but \nthey can perform reordering optimizations only if .lters are stateless. In contrast, S * allows fusion \nand reordering of stateful .lters with non-linear input-output relations. Approaches for numerical static \nanalysis of linear .lters (e.g., [24]) do not relate directly to ours as their goal is to obtain deep \nnumerical properties of .lters (such as numerical bounds) for safety-critical applications. Automated \nparallelization. Thies et al. [55] extract pipeline par\u00adtitions from legacy streaming applications written \nin C by relying on programmer-provided annotations indicating pipeline bound\u00adaries. In contrast, our \napproach does not require any annotations. For synchronous data.ow streaming applications, parallelism \nhas been exploited either by replicating stateless .lters [15, 29, 44], or by using af.ne partitioning \nof loop nests [47]. In contrast, S * enables parallelization of non-linear stateful .lters with non-af.ne \nloop bounds. There is a massive amount of work on general cross\u00adloop iteration dependence scheduling \n(e.g., see [11]). S * is aimed at complementing such advanced techniques by enabling na\u00a8ive par\u00adallelization \nof behaviorally simple loop nests that are not necessary polyhedral, disjoint or with a clear pipeline \nstructure.  Acknowledgments This work was supported by the Gates trust, the Lawrence Liver\u00admore National \nLab grant B597718, and by the NSERC PDF fel\u00adlowship. Thanks to Mike Dodds, Eric Koskinen, Matthew Parkin\u00adson, \nDawn Song, John Wickerson and the anonymous reviewers for comments and suggestions. References [1] F. \nAarts, B. Jonsson, and J. Uijen. Generating models of in.nite-state communication protocols using regular \ninference with abstraction. In Proc. of the 22nd IFIP WG 6.1 Int. Conf. on Testing Software and Systems, \npages 188 204, 2010. [2] S. Agrawal, W. Thies, and S. P. Amarasinghe. Optimizing stream programs using \nlinear state space analysis. In Proc. of the 2005 Int. Conf. on Compilers, Architecture, and Synthesis \nfor Embedded Systems, pages 126 136, 2005. [3] R. Alur and P. .y. Streaming transducers for algorithmic \nveri.ca- Cern \u00b4tion of single-pass list-processing programs. In Proc. of the 38th ACM SIGPLAN-SIGACT \nSymp. on Principles of Programming Languages, pages 599 610, 2011. [4] R. Alur, P. .y, P. Madhusudan, \nand W. Nam. Synthesis of interface Cern\u00b4speci.cations for Java classes. In Proc. of the 32nd ACM SIGPLAN-SIGACT \nSymp. on Principles of Programming Languages, pages 98 109, 2005. [5] D. Angluin. Learning regular sets \nfrom queries and counterexamples. Information and Computation, 75(2):87 106, 1987. [6] T. Ball. Formalizing \ncounterexample-driven re.nement with weakest preconditions. In Engineering Theories of Software Intensive \nSystems, volume 195 of NATO Science Series, pages 121 139. 2005. [7] T. Ball, R. Majumdar, T. Millstein, \nand S. Rajamani. Automatic pred\u00adicate abstraction of C programs. In Proc. of the 2001 ACM SIGPLAN Conference \non Programming Language Design and Implementation, pages 203 213, 2001. [8] T. Ball, A. Podelski, and \nS. K. Rajamani. Boolean and cartesian abstraction for model checking C programs. In Proc. of the 7th \nInt. Conf. on Tools and Algorithms for the Construction and Analysis of Systems, pages 268 283, 2001. \n[9] T. Ball, A. Podelski, and S. K. Rajamani. Relative completeness of abstraction re.nement for software \nmodel checking. In Proc. of the 8th Int. Conf. on Tools and Algorithms for the Construction and Analysis \nof Systems, pages 158 172, 2002. [10] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic, E. Kirda, \nC. Kruegel, and G. Vigna. Saner: Composing static and dynamic anal\u00adysis to validate sanitization in web \napplications. In IEEE Symposium on Security and Privacy, pages 387 401, 2008. [11] M. M. Baskaran, N. \nVydyanathan, U. Bondhugula, J. Ramanujam, A. Rountev, and P. Sadayappan. Compiler-assisted dynamic schedul\u00ading \nfor effective parallelization of loop nests on multicore processors. In Proc. of the 14th ACM SIGPLAN \nSymp. on Principles and Practice of Parallel Programming, pages 219 228, 2009. [12] T. Berg, B. Jonsson, \nand H. Raffelt. Regular inference for state machines using domains with equality tests. In Proc. of the \nTheory and practice of software, 11th Int. Conf. on Fundamental approaches to software engineering, pages \n317 331, 2008. [13] D. Beyer and M. E. Keremoglu. Cpachecker: A tool for con.gurable software veri.cation. \nIn Proc. of the 23rd Int. Conf. on Computer Aided Veri.cation, pages 184 190, 2011. [14] N. Bj\u00f8rner, \nP. Hooimeijer, B. Livshits, D. Molnar, and M. Veanes. Symbolic .nite state transducers: Algorithms and \napplications. In Proc.of the 39th ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, 2012. \n[15] I. Buck, T. Foley, D. R. Horn, J. Sugerman, K. Fatahalian, M. Houston, and P. Hanrahan. Brook for \nGPUs: stream computing on graphics hardware. ACM Trans. Graph., 23(3):777 786, 2004. [16] C. Cadar and \nD. R. Engler. Execution generated test cases: How to make systems code crash itself. In Proc. of the \n12th Int. SPIN Workshop on Model Checking Software, pages 2 23, 2005. [17] C. Cadar, D. Dunbar, and D. \nEngler. KLEE: Unassisted and automatic generation of high-coverage tests for complex systems programs. \nIn Proc. of the 8th USENIX Symp. on Operating Systems Design and Implementation, pages 209 224, 2008. \n[18] M. K. Chen, X.-F. Li, R. Lian, J. H. Lin, L. Liu, T. Liu, and R. Ju. Shangri-La: achieving high \nperformance from compiled network ap\u00adplications while enabling ease of programming. In Proc. of the ACM \nSIGPLAN 2005 Conference on Programming Language Design and Implementation, pages 224 236, 2005. [19] \nC. Y. Cho, D. Babi \u00b4c, P. Poosankam, K. Z. Chen, E. X. Wu, and D. Song. MACE: Model-inference-assisted \nconcolic exploration for protocol and vulnerability discovery. In USENIX Security Symposium, 2011. [20] \nE. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith. Counterexample-guided abstraction re.nement. \nIn Proc. of the 12th Int. Conf. on Computer Aided Veri.cation, pages 154 169, 2000. [21] J. M. Cobleigh, \nD. Giannakopoulou, and C. S. P.as .areanu. Learn\u00ading assumptions for compositional veri.cation. In Proc. \nof the 9th Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems, volume 2619, \npages 331 346, 2003. [22] A. J. Demers, C. Keleman, and B. Reusch. On some decidable properties of .nite \nstate translations. Acta Informatica, 17:349 364, 1982. [23] M. Drake, H. Hoffmann, R. M. Rabbah, and \nS. P. Amarasinghe. MPEG-2 decoding in a stream programming language. In Proc. of the 20th International \nParallel and Distributed Processing Symposium, 2006. [24] J. Feret. Static analysis of digital .lters. \nIn Programming Languages and Systems, 13th European Symposium on Programming, pages 33 48, 2004. [25] \nV. Ganesh and D. L. Dill. A decision procedure for bit-vectors and arrays. In Proc. of the 19th Int. \nConf. on Computer Aided Veri.cation, pages 519 531, 2007. [26] B. Gedik, H. Andrade, K.-L. Wu, P. S. \nYu, and M. Doo. Spade: the System S declarative stream processing engine. In SIGMOD Conference, pages \n1123 1134, 2008. [27] D. Giannakopoulou, Z. Rakamaric, and V. Raman. Symbolic learning of component interfaces. \nIn 19th Int. Symp. on Static Analysis, pages 248 264, 2012. [28] P. Godefroid, N. Klarlund, and K. Sen. \nDART: directed automated ran\u00addom testing. In Proc. of the ACM SIGPLAN 2005 Conf. on Program\u00adming Language \nDesign and Implementation, pages 213 223, 2005. [29] M. I. Gordon, W. Thies, and S. P. Amarasinghe. Exploiting \ncoarse\u00adgrained task, data, and pipeline parallelism in stream programs. In Proc. of the 12th Int. Conf. \non Architectural Support for Programming Languages and Operating Systems, pages 151 162, 2006. [30] S. \nGraf and H. Saidi. Construction of abstract state graphs with PVS. In Proc. of the 9th Int. Conf. on \nComputer Aided Veri.cation, pages 72 83, 1997. [31] B. S. Gulavani, T. A. Henzinger, Y. Kannan, A. V. \nNori, and S. K. Rajamani. SYNERGY: a new algorithm for property checking. In Proc. of the 14th ACM SIGSOFT \nInt. Symp. on Foundations of Soft\u00adware Engineering, pages 117 127, 2006. [32] J. Gummaraju, J. Coburn, \nY. Turner, and M. Rosenblum. Streamware: programming general-purpose multicore processors using streams. \nIn Proc. of the 13th Int. Conf. on Architectural Support for Programming Languages and Operating Systems, \npages 297 307, 2008. [33] M. R. Guthaus, J. S. Ringenberg, D. Ernst, T. M. Austin, T. Mudge, and R. B. \nBrown. MiBench: A free, commercially representative em\u00adbedded benchmark suite. In Proc. of the Workload \nCharacterization. WWC-4 IEEE Int. Workshop, pages 3 14, 2001.  [34] P. Habermehl and T. Vojnar. Regular \nmodel checking using inference of regular languages. Electr. Notes Theor. Comput. Sci., 138:21 36, 2005. \n[35] A. Hagiescu, W.-F. Wong, D. F. Bacon, and R. M. Rabbah. A comput\u00ading origami: folding streams in \nFPGAs. In Proc. of the 46th Design Automation Conference, pages 282 287, 2009. [36] T. A. Henzinger, \nR. Jhala, R. Majumdar, and G. Sutre. Lazy abstrac\u00adtion. In Proc. of the 29th ACM SIGPLAN-SIGACT Symp. \non Principles of Programming Languages, pages 58 70, 2002. [37] P. Hooimeijer, B. Livshits, D. Molnar, \nP. Saxena, and M. Veanes. Fast and precise sanitizer analysis with BEK. In USENIX Security Symposium, \n2011. [38] J. E. Hopcroft. On the equivalence and containment problems for context-free languages. Theory \nof Computing Systems, 3:119 124, 1969. [39] A. Hormati, M. Kudlur, S. A. Mahlke, D. F. Bacon, and R. \nM. Rabbah. Optimus: ef.cient realization of streaming applications on FPGAs. In Proc. of the 2008 Int. \nConf. on Compilers, Architecture, and Synthesis for Embedded Systems, pages 41 50, 2008. [40] F. Howar, \nB. Steffen, B. Jonsson, and S. Cassel. Inferring canonical register automata. In Proc. of the 13th Int. \nConf. on Veri.cation, Model Checking, and Abstract Interpretation, pages 251 266, 2012. [41] O. H. Ibarra. \nThe unsolvability of the equivalence problem for E\u00adfree NGSM s with unary input (output) alphabet and \napplications. In Proc. of the 18th Annual Symp. on Foundations of Computer Science, pages 74 81, 1977. \n[42] R. Jhala and K. L. McMillan. A practical and complete approach to predicate re.nement. In Proc. \nof the 12th Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems, pages 459 \n473, 2006. [43] U. J. Kapasi, W. J. Dally, S. Rixner, J. D. Owens, and B. Khailany. The imagine stream \nprocessor. In Proc. of the 20th Int. Conf. on Computer Design, VLSI in Computers and Processors, pages \n282 288, 2002. [44] M. Kudlur and S. A. Mahlke. Orchestrating the execution of stream programs on multicore \nplatforms. In Proc. of the ACM SIGPLAN 2008 Conference on Programming Language Design and Implementation, \npages 114 124, 2008. [45] A. A. Lamb, W. Thies, and S. P. Amarasinghe. Linear analysis and optimization \nof stream programs. In Proc. of the ACM SIGPLAN 2003 Conference on Programming Language Design and Implementation, \npages 12 25, 2003. [46] D. Lee and M. Yannakakis. Principles and methods of testing .nite state machines-a \nsurvey. In Proc. of the IEEE, volume 84, pages 1090 1123, 1996. [47] S.-W. Liao, Z. Du, G. Wu, and G.-Y. \nLueh. Data and computation transformations for Brook streaming applications on multiprocessors. In Proc. \nof the 4th IEEE/ACM Int. Symp. on Code Generation and Optimization, pages 196 207, 2006. [48] P. Prabhu, \nG. Ramalingam, and K. Vaswani. Safe programmable speculative parallelism. In Proc. of the 2010 ACM SIGPLAN \nConf. on Programming Language Design and Implementation, pages 50 61, 2010. [49] K. Sen, D. Marinov, \nand G. Agha. CUTE: a concolic unit testing engine for C. In Proc. of the 10th European Software Engineering \nConf. held jointly with 13th ACM SIGSOFT Int. Symp. on Foundations of Software Engineering, pages 263 \n272, 2005. [50] M. Shahbaz and R. Groz. Inferring Mealy machines. In Proc. of the 2nd World Congress \non Formal Methods, pages 207 222, 2009. [51] R. Singh, D. Giannakopoulou, and C. S. Pasareanu. Learning \ncompo\u00adnent interfaces with may and must abstractions. In Proc. of the 22nd Int. Conf. on Computer Aided \nVeri.cation, pages 527 542, 2010. [52] R. Soul\u00b4e, M. Hirzel, R. Grimm, B. Gedik, H. Andrade, V. Kumar, \nand K.-L. Wu. A universal calculus for stream processing languages. In Programming Languages and Systems, \n19th European Symposium on Programming, pages 507 528, 2010. [53] W. Thies and S. P. Amarasinghe. An \nempirical characterization of stream programs and its implications for language and compiler de\u00adsign. \nIn Proc. of the 19th International Conference on Parallel Archi\u00adtecture and Compilation Techniques, pages \n365 376, 2010. [54] W. Thies, M. Karczmarek, and S. P. Amarasinghe. StreamIt: A lan\u00adguage for streaming \napplications. In Proc. of the 11th International Conference on Compiler Construction, pages 179 196, \n2002. [55] W. Thies, V. Chandrasekhar, and S. P. Amarasinghe. A practical approach to exploiting coarse-grained \npipeline parallelism in C pro\u00adgrams. In 40th Annual IEEE/ACM Int. Symp. on Microarchitecture, pages 356 \n369, 2007. [56] A. Udupa, R. Govindarajan, and M. J. Thazhuthaveetil. Software pipelined execution of \nstream programs on GPUs. In Proc. of the 7th Int. Symp. on Code Generation and Optimization, pages 200 \n209, 2009. [57] M. Veanes, D. Molnar, B. Livshits, and L. Litchev. Generating fast string manipulating \ncode through transducer exploration and SIMD in\u00adtegration. Technical Report MSR-TR-2011 124, Microsoft \nResearch, 2011. [58] J. M. Vilar. Query learning of subsequential transducers. In Proc. of the 3rd Int. \nColloquium on Grammatical Inference: Learning Syntax from Sentences, pages 72 83, 1996.     \n\t\t\t", "proc_id": "2429069", "abstract": "<p>We present Sigma*, a novel technique for learning symbolic models of software behavior. Sigma* addresses the challenge of synthesizing models of software by using symbolic conjectures and abstraction. By combining dynamic symbolic execution to discover symbolic input-output steps of the programs and counterexample guided abstraction refinement to over-approximate program behavior, Sigma* transforms arbitrary source representation of programs into faithful input-output models. We define a class of stream filters---programs that process streams of data items---for which Sigma* converges to a complete model if abstraction refinement eventually builds up a sufficiently strong abstraction. In other words, Sigma* is complete relative to abstraction. To represent inferred symbolic models, we use a variant of symbolic transducers that can be effectively composed and equivalence checked. Thus, Sigma* enables fully automatic analysis of behavioral properties such as commutativity, reversibility and idempotence, which is useful for web sanitizer verification and stream programs compiler optimizations, as we show experimentally. We also show how models inferred by Sigma* can boost performance of stream programs by parallelized code generation.</p>", "authors": [{"name": "Matko Botin&#269;an", "author_profile_id": "81444607580", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P3978027", "email_address": "matko.botincan@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Domagoj Babi&#263;", "author_profile_id": "81339489035", "affiliation": "Facebook, Inc., Menlo Park, CA, USA", "person_id": "P3978028", "email_address": "babic@eecs.berkeley.edu", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429123", "year": "2013", "article_id": "2429123", "conference": "POPL", "title": "Sigma*: symbolic learning of input-output specifications", "url": "http://dl.acm.org/citation.cfm?id=2429123"}