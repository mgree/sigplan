{"article_publication_date": "01-23-2013", "fulltext": "\n Complete Instantiation-Based Interpolation Nishant Totla Thomas Wies Indian Institute of Technology \nBombay New York University nishant.totla@gmail.com wies@cs.nyu.edu Abstract Craig interpolation has \nbeen a valuable tool for formal methods with interesting applications in program analysis and veri.cation. \nModern SMT solvers implement interpolation procedures for the theories that are most commonly used in \nthese applications. How\u00adever, many application-speci.c theories remain unsupported, which limits the \nclass of problems to which interpolation-based tech\u00adniques apply. In this paper, we present a generic \nframework to build new interpolation procedures via reduction to existing interpolation procedures. We \nconsider the case where an application-speci.c the\u00adory can be formalized as an extension of a base theory \nwith addi\u00adtional symbols and axioms. Our technique uses .nite instantiation of the extension axioms to \nreduce an interpolation problem in the theory extension to one in the base theory. We identify a model\u00adtheoretic \ncriterion that allows us to detect the cases where our tech\u00adnique is complete. We discuss speci.c theories \nthat are relevant in program veri.cation and that satisfy this criterion. In particular, we obtain complete \ninterpolation procedures for theories of arrays and linked lists. The latter is the .rst complete interpolation \nprocedure for a theory that supports reasoning about complex shape properties of heap-allocated data \nstructures. We have implemented this proce\u00addure in a prototype on top of existing SMT solvers and used \nit to automatically infer loop invariants of list-manipulating programs. Categories and Subject Descriptors \nD.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; F.3.1 [Logics and Mean\u00ading of Programs]: \nSpecifying and Verifying and Reasoning about Programs; I.2.3 [Arti.cial Intelligence]: Deduction and \nTheorem Proving General Terms Algorithms, Theory, Reliability, Veri.cation Keywords Craig Interpolants, \nDecision Procedures, Satis.ability Module Theories, Program Analysis, Data Structures 1. Introduction \nIn his pioneering work [37], McMillan recognized the usefulness of Craig interpolants [13] for the automated \nconstruction of ab\u00ad stractions of systems. Since then, interpolation-based algorithms have been developed \nfor a number of problems in program anal\u00adysis and veri.cation [1, 15, 17, 24, 25, 31, 34, 39]. An impor\u00ad \ntant requirement for most of these algorithms is that interpolants are ground (i.e., quanti.er-free). \nThis is because the computed in- Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 13, January 23 25, 2013, Rome, Italy. Copyright c &#38;#169; 2013 \nACM 978-1-4503-1832-7/13/01. . . $15.00 terpolants again serve as input to decision procedures that only \nsupport quanti.er-free formulas. Modern SMT solvers implement ground interpolation procedures for the \ntheories that are most com\u00admonly used in program veri.cation. This includes theories such as linear arithmetic \n[8, 9, 23, 38], the theory of uninterpreted func\u00ad tion symbols with equality [19, 38, 50], and combinations \nof such theories [11, 21, 38, 50]. However, many application-speci.c the\u00ad ories remain unsupported. This \nlimits the class of problems and programs to which interpolation-based algorithms can be applied. In \nthis paper, we present a generic framework that enables the modular construction of ground interpolation \nprocedures for application-speci.c theories via a reduction to existing interpola\u00adtion procedures. We \nfocus on cases where an application-speci.c theory can be formalized as an extension of a base theory \nwith addi\u00adtional symbols and universally quanti.ed axioms. As an example of such a theory extension, \nconsider the theory of arrays over integers. Here, the base theory is the theory of linear integer arithmetic, \nthe extension symbols are the array selection and update functions, and the extension axioms are McCarthy \ns read over write axioms [36], which give meaning to the extension symbols. Theory extensions often appear \nin practice, e.g., as part of the background theories of veri.cation systems such as BO O GI E [3] and \nWH Y [18], and the tools that are built on top of these systems. Our starting point is the approach to \ninstantiation-based inter\u00adpolation for local theory extension presented in [47]. Local theory extensions \n[46] are extensions for which satis.ability of ground formulas can be decided via a reduction to satis.ability \nin the base theory. The reduction works by instantiating the extension axioms only with terms that already \nappear in the input formula. In [47], this instantiation-based reduction approach is applied to the prob\u00adlem \nof computing ground interpolants in local theory extensions. This technique is used, e.g., in the interpolation \nprocedures un\u00adderlying the software model checker ARMC [44] and the interpo\u00ad lating prover CSIsat [6]. \nIn [47], the instantiation-based interpola\u00adtion approach was shown to be complete for a syntactically \nde.ned class of local theory extensions. Unfortunately, many interesting application-speci.c theories \ndo not fall into this class. Instead of imposing syntactic restrictions, we identify a stronger condition \non the theory extension than just locality to ensure com\u00adpleteness of instantiation-based interpolation. \nWe then relate this condition to a semantic property of the models of the theory exten\u00adsion. We refer \nto this property as the partial amalgamation prop\u00aderty. This property allows us to systematically construct \ntheory extensions for which the instantiation-based approach produces a complete ground interpolation \nprocedure. The resulting framework then applies to a more general class of theory extensions than [47]. \nWe discuss several non-trivial examples of theories that are rel\u00adevant in program veri.cation and to \nwhich our framework applies. In particular, we consider the theory of arrays with difference func\u00adtion \n[10]. Using our approach we obtain an alternative ground inter\u00ad polation procedure for this theory. Unlike \nthe procedure presented in [10], our procedure does not require a dedicated decision proce\u00ad dure for \nthis speci.c array theory. Instead, it reduces the interpola\u00adtion problem to existing interpolation procedures \nfor uninterpreted functions and linear arithmetic.  The second example that we discuss in detail is \na variation of Nelson s theory of linked lists with reachability predicates [41], which was studied more \nrecently in [35]. We show that this theory does not admit ground interpolation, unless it is extended \n(among others) with an additional join function. Given two heap nodes, the join function returns the \njoin point of the two list segments that start in the given nodes (if such a join point exists). Incidentally, \nthe join function is not just of theoretical interest, but is also useful to express properties about \nthe heap that are important for verifying frame conditions. We prove that our extended theory of linked \nlists with reachability has partial amalgamation. Using our approach we then obtain the .rst ground interpolation \nprocedure for a theory that supports reasoning about complex shape properties of heap\u00adallocated data \nstructures. This interpolation procedure has promis\u00ading applications in CEGAR-based shape analysis [5, \n42] and may also provide a new perspective on the construction of shape do\u00admains in parametric shape \nanalysis [45]. To show the feasibility of our approach, we have implemented a prototype of our interpolation \nframework and instantiated it for the theory of linked lists presented in this paper. We have successfully \napplied the resulting interpolation procedure to automatically infer loop invariants for the veri.cation \nof list-manipulating programs. Summary. The main contributions of this paper can be summa\u00adrized as follows: \n We present a new framework to modularly construct interpola\u00adtion procedures for application-speci.c \ntheories.  We present a model-theoretic criterion that allows us to identify the theories for which \nour interpolation framework is complete.  We present examples of theories that are important for program \nveri.cation and to which our framework applies. In particular, we present the .rst decidable theory for \nreasoning about com\u00adplex shape properties of heap-allocated data structures that ad\u00admits ground interpolation. \n We report on our experience with a prototype implementation of our framework, which we have successfully \nused to infer loop invariants of simple list-manipulating programs.  An extended version of this paper \nincluding proofs of key lemmas and theorems is available as a technical report [48]. 2. Motivation and \nOverview We motivate our approach using the concrete application of inter\u00adpolation to the problem of \ninferring invariants for program veri.ca\u00adtion. Consider the reverse function given in Figure 1. This \nfunction takes a pointer x to a singly-linked list as input, reverses the list, and then returns a pointer \nto the head of the reversed list. Our goal is to verify that the reverse function preserves acyclic\u00adity, \ni.e., if the input list is acyclic, then so is the output list. We can express acyclicity of list x by \nsaying that null is reachable from x by following the n pointer .elds in the heap. Using the notation \nthat we formally introduce in Section 5.2, this is denoted by the reachability predicate x -n . null. \nHence, the property we want to verify is that if the pre-condition x -n . null holds at the entry point \nof function reverse, then the same formula holds again at the return point.  The graph in Figure 1 depicts \nan intermediate state of the heap that is observed during the execution of reverse when the function \nis applied to an acyclic list of length six. This state is observed at the entry point of the while loop, \nafter the .rst three iterations of the loop. An appropriate inductive loop invariant for a Hoare proof \nof typedef struct Node { List reverse ( List x) {struct node* n; List prev , curr , succ ; int data ; \ncurr = x; } * List ; prev = null ; while ( curr != null ) {succ = curr . n; n n curr . n = prev; prev \n= curr ; n curr = succ; null } n x = prev; return x ; n n } Figure 1. C code for in-place reversal of \na linked list. The graph depicts a reachable program state at the entry point of the while loop in function \nreverse. our veri.cation goal must capture the situation depicted in Figure 1, but abstract from the \nconcrete length of the list segments. That is, the loop invariant must express that the list segments \npointed to by prev and curr are acyclic (in fact, only the former is strictly necessary for the proof), \nand that the two list segments are disjoint. An appropriate inductive loop invariant is given by the \nfollowing formula: nn prev --.ncurr) = null (1) . null . curr . null . (prev The term (prev .ncurr) denotes \nthe join point of the list segments starting from prev and curr, i.e., (prev .ncurr) is the .rst node \nthat is reachable from both prev and curr by following n pointer .elds in the heap, unless such a node \ndoes not exist, in which case its value is prev. The formula (prev .ncurr) = null, thus, implies the \ndisjointness of the two list segments. Note that this formula cannot be expressed in terms of the reachability \npredicate, unless we allow universal quanti.cation over heap nodes. We next describe how to compute inductive \nloop invariants such as (1) using our instantiation-based interpolation approach. 2.1 Interpolation-Based \nProgram Veri.cation Given an unsatis.able conjunction of formulas A . B, an inter\u00adpolant for A . B is \na formula I such that I is implied by A, the conjunction I.B is unsatis.able, and I only speaks about \ncommon symbols of A and B. A popular approach to interpolation-based veri.cation uses bounded model checking \nto generate infeasible error traces of the analyzed program. These infeasible error traces are then translated \ninto unsatis.able formulas A . B, where A and B encode a partition of the trace into a pre.x and suf.x \ntrace. An interpolant I for A . B then describes a set of program states that (1) includes all states \nthat are reachable by executing the pre.x of the trace and (2) only includes states from which no feasible \nexe\u00adcution of the suf.x is possible. The interpolant I is then used as a candidate invariant to re.ne \nthe search for additional infeasible er\u00adror traces. This process is continued until a .xed point is reached, \ni.e., until an inductive invariant has been computed that proves the program correct. We illustrated \nthis approach through an example. The left-hand side of Figure 2 shows an error trace of function reverse \nthat is obtained by unrolling the while loop three times. The .rst and last assume statements correspond \nto the pre-condition, respectively, the negated post-condition of reverse. This error trace is infeasible, \ni.e., there is no execution that reaches the end of the trace (note that a failing assume statement blocks \nan execution). The right-hand side of Figure 2 shows an encoding of this error trace into a .rst-order \nformula using static single assignments. Note that the symbols - . , . , and [ := ] are interpreted. \nThat  assume x -n . null; curr = x; prev = null; . . . . . . . . . . . . f n0a that does not go through \nc. In particular, a -. b is simply a -. null .x0 f/b . shorthand for a --. b. The meaning of the extension \nsymbols is curr0 = x0 given by the extension axioms shown in Figure 6 of Section 5.2. prev0 = null . \nAll free variables appearing in these axioms are implicitly univer\u00ad assume curr != null; curr0 . = null \nA . sally quanti.ed. Note in particular how the constrained reachability succ = curr.n; curr.n = prev; \nprev = curr; curr = succ; assume curr != null; succ = curr.n; curr.n = prev; prev = curr; curr = succ; \nassume curr != null; .. . . . . . . . . . . . . . .. . . . . . . . . . . . . . succ1 = curr0.n0 = n0[curr0 \n:= prev0] . predicate is used to de.ne reachability with respect to an updated n1 . .eld f [u := v] \nin terms of reachability with respect to .eld f. In prev1 = curr0 . the following, we denote this set \nof extension axioms by K. curr1 = succ1 . Instantiation-based interpolation reduces the computation \nof in\u00ad = null curr1 succ2 = curr1.n1 . terpolants in the theory extension to the problem of computing \nin\u00ad = n1[curr1 := prev1] . terpolants in the base theory, thus, effectively building new interpo\u00ad n2 \n . lation procedures by reusing existing ones. The reduction works by prev2 = curr1 . turning the interpreted \nextension symbols into uninterpreted ones. curr2 = succ2 . This is accomplished by generating .nitely \nmany ground instances = null curr2 succ = curr.n; B succ3 = curr2.n2 . K[T ] of the extension axioms \nK for a .nite set of terms T that is = n2[curr2 := prev2] . computed from the input formula A . B. The \nset of terms T is curr.n = prev; prev = curr; curr = succ; assume curr == null; x = prev; assume !(x \n-n . null); . . . . . . . . . . . . . . . . . . n3 . chosen such that the formula K[T ] . A . B is already \nunsatis.able prev3 = curr2 . in the base theory. If in addition, the set K[T ] does not contain in\u00ad \ncurr3 = succ3 = null . stances that mix non-shared symbols of A and B, then K[T ] can curr3 x1 = prev3 \n . be divided into K[T ] = K[TA] . K[TB ] where K[TA] contains n3 only symbols of A and K[TB] only symbols \nof B. That is, we ob\u00ad -. null) \u00ac(x1 tain an instance A0 . B0 of an interpolation problem for the base \ntheory (modulo uninterpreted functions) where A0 = K[TA] . AFigure 2. Spurious error trace of function \nreverse and its encoding as a trace formula is, they are given meaning by a speci.c .rst-order theory, \nhere the theory of linked lists with reachability that we introduce in and B0 = K[TB] . B. We then compute \na ground interpolant I0 for A0 . B0 using the interpolation procedure for the base theory. Finally, from \nI0 we reconstruct a ground interpolant I for A . B. We illustrate this approach by computing an interpolant \nfor the following formula A . B: Section 5.2. The symbol - f . is interpreted as described above. \nf f The symbol . denotes .eld dereference and the symbol [ := ] .eld update. The remaining symbols such \nas curr0 and n1 are uninterpreted. We call this formula the trace formula of the error trace because \nthe valuations of uninterpreted symbols that make the trace formula true exactly correspond to the feasible \nexecutions of the trace. Since the error trace is infeasible, its trace formula is unsatis.able. We can \nnow split the trace formula into two parts A and B, say, where A corresponds to the pre.x of the trace \nup to the end of the .rst iteration of the while loop and B to the remainder of the trace. This is depicted \nin Figure 2. Since A . B is unsatis.able, we can interpolate the two formulas. A possible ground interpolant \nfor this choice of A and B is: n1n1 prev1 -. null . curr1 -. null . prev1 n1 curr1 = null (2) Note that \nthis is a valid interpolant for A and B. In particular, it only speaks about uninterpreted symbols that \nare common to both A and B. Further note that (modulo renaming of variables) for\u00admula (2) exactly corresponds \nto the inductive loop invariant (1) of reverse. Formula (2) is also the exact interpolant that the prototype \nimplementation of our interpolation framework produces for this particular conjunction A . B. We next \ndescribe through an exam\u00adple how our interpolation framework works in detail.  2.2 Instantiation-Based \nInterpolation through an Example Our interpolation framework is parameterized by a theory exten\u00adsion. \nThis theory extension consists of the base theory, for which we assume that a ground interpolation procedure \nexists, and the symbols and axioms that extend the base theory. In our example, we consider the theory \nof linked lists with reachability, where the base theory is the empty theory. That is, the base theory \nonly sup\u00adports uninterpreted constants and equality. The extension symbols are the symbols , . , and \n[ := ], which we described / earlier, as well as the constrained reachability predicate --. . f/c Intuitively, \na --. b means that b is reachable via an f-path from (3) c . c BA Note that this conjunction is unsatis.able \nin the theory of linked lists with reachability because A implies that c lies on an f cycle, while B \nimplies that this is not the case. From the formula A . B we compute the sets of terms TA and TB that \nwe use to instantiate the extension axioms. In our example, we use TA = {a, c, c.f} and TB = {b, c, c.f}. \nFigure 3 then shows the resulting sets of ground clauses A0 = A . K[TA] and B0 = B . K[TB]. Note that \nwe omit all instances of extension axioms that are not needed to prove unsatis.ability of A0 . B0. To \nsee why the conjunction A0 . B0 is unsatis.able, suppose that a = c. Then clause 2 in A0 implies c.f \n= c. If on the other hand a -f = c, then clauses 4 and 2 imply a . c. Hence together with f/af f 8 and \n6 this implies a --. c.f . c.f -. a. If c.f -. a, then 3 f f/af implies c.f -. c. If a --. c.f then from \n7 follows again c.f -. c because otherwise clause 5 gives a = c, which contradicts the f assumption. \nThus, A0 implies the formula I = c = f.c . c.f -. c. Using similar reasoning we can show that I . B0 \nis unsatis.able. Since I only speaks about common symbols of A0 and B0, it is an interpolant for A0 . \nB0 and hence also for A . B. Note that in the above derivation of the interpolant I, all func\u00adtion and \npredicate symbols in A0 and B0 where treated as uninter\u00adpreted symbols, i.e., we can compute I by applying \nan interpolation procedure for the theory of uninterpreted functions with equality to the formula A0 \n. B0. We thus reduced the problem of computing ground interpolants in the theory of linked lists with \nreachability to computing ground interpolants in the combination of the base the\u00adory (which is empty \nin our case) with the theory of uninterpreted functions and equality. The crux of this instantiation-based \nreduction approach is whether it is indeed always possible to compute sets of terms TA and TB from A.B \nsuch that the reduced formula A0 .B0 is an in\u00adterpolation problem for the base theory. That is, to .nd \nTA and TB -. a . a.f c -. b . \u00acb -. c c = c c c  A0 B0 cc cc f f 1 : c -. a 1 : c -. b f 2 : a.f = \nc 2 : \u00acb -. c f f f /bf /b 3 : c.f -. a . a -. c . 3 : c --. c.f . c.f --. c . f f /c c.f -. c f c.f \n-. b . c --. c.f f /c 4 : a --. a.f . a = c f f 4 : c.f -. c . c -. b . f /a 5 : a --. c . a = c f c.f \n-. b f /a f /c 6 : c --. c.f . c = a 5 : c --. f.c . c = c.f f f /a f /b 7 : a -. c . a --. c.f . 6 : \nc --. f.c . c = b f /cf a --. c.f . c.f -. c . f 7 : c.f = c . c -. b . c = b f /af /a f f a --. c . \nc --. c.f 8 : c.f -. c . c.f -. b . f /af f /cf 8 : c --. c.f . c -. a . c.f --. b . b -. c . f /af f \n/bf a --. c.f . c.f -. a c.f --. c . c -. b 9 : . . . 9 : . . . Figure 3. Interpolation problem A0 . \nB0 that is obtained from (3) after instantiation of the extension axioms. All function and predicate \nsymbols are uninterpreted. such that (1) A0 . B0 is unsatis.able and (2) A0, B0 do not share terms that \nare not already shared by A, B. It is here where our se\u00admantic completeness criterion of partial amalgamation \ncomes into play. It allows us to systematically construct these sets of terms. 3. Preliminaries In the \nfollowing, we de.ne the syntax and semantics of formulas. We further recall the notions of partial structures \nand (.-)local theory extensions as de.ned in [28, 46]. Finally, we de.ne the problem that interpolation \nproblems we are considering. Sorted .rst-order logic. We present our problem in sorted .rst\u00adorder logic \nwith equality. A signature S is a tuple (S, O), where S is a countable set of sorts and O is a countable \nset of function symbols f with associated arity n = 0 and associated sort s1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 sn . s0 with si \n. S for all i = n. Function symbols of arity 0 are called constant symbols. We assume that all signatures \ncontain a dedicated sort bool . S and dedicated equality symbols = s . O of sort s\u00d7s . bool for all sorts \ns . S \\ {bool}. Note that we generally treat predicate symbols of sort s1, . . . , sn as function symbols \nof sort s1 \u00d7 . . . \u00d7 sn . bool and we typically drop sort annotations from equality symbols. Terms are \nbuilt as usual from the function symbols in O and (sorted) variables taken from a countably in.nite set \nX that is disjoint from O. A term t is said to be ground, if no variable appears in t. A S-atom A is \na S-term of sort bool. We use in.x notation for atoms built from the equality symbol. A S-formula F is \nde.ned via structural recursion as either one of A, \u00acF1, F1 . F2, or .x : s.F1, where A is a S-atom, \nF1 and F2 are S-formulas, and x . X is a variable of sort s . S. We typically omit sort annotations from \nquanti.ers if this causes no confusion. We use syntactic sugar for Boolean constants (T, .), disjunctions \n(F1 . F2), implications (F1 . F2), and existential quanti.cation (.x.F1). Total and partial structures. \nGiven a signature S = (S, O), a partial S-structure M is a function that maps each sort s . S to a non-empty \nset M(s) and each function symbol f . O of sort s1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 sn . s0 to a partial function M(f) : M(s1) \n\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 M(sn) -M (s0). We denote by [M] the support of M which is the non-disjoint union of the interpretation \nof all sorts in M. We assume that all partial structures interpret the sort bool by the two-element set \nof Booleans {0, 1}. We further assume that all structures M interpret each symbol = s by the equality \nrelation on M(s). A partial structure M is called total structure or simply structure if it interprets \nall function symbols by total functions. For a S-structure M where S extends a signature S0 with additional \nsorts and function symbols, we write M|S0 for the S0-structure obtained by restricting M to S0. Given \npartial S\u00adstructures M and N, a weak embedding of M into N is a total injective function h : [M] . [N] \nsuch that for all f . S, and a1, . . . , an . M, if M(f ) is de.ned on (a1, . . . , an) then N(f) is \nde.ned on (h(a1), . . . , h(an)) and h(M(f)(a1, . . . , an)) = N(f )(h(a1), . . . , h(an)). If h is a \nweak embedding between M and N, then we denote this by h : M . N. We say that M weakly embeds into N \nif a weak embedding of M into N exists. A weak embedding between total structures is simply called embedding. \nIf M weakly embeds into N and [M] . [N], we call M a (partial) substructure of N, which (abusing notation) \nis denoted by M . N. Given a total structure M and a variable assignment \u00df : X . M, the evaluation tM,\u00df \nof a term t in M, \u00df is de.ned as usual. For the evaluation of a ground term t in M we write just M(t). \nA quanti.ed variable of sort s ranges over all elements of M(s). From the interpretation of terms the \nnotions of satis.ability, validity, and entailment of atoms, formulas, clauses, and sets of clauses in \ntotal structures are derived as usual. In particular, we use the standard interpretation of propositional \nconnectives in classical logic. We write M, \u00df |= F if M satis.es F under \u00df where F is a formula, a clause, \nor a set of clauses. We write M |= F if F is valid in M. In this case we also call M a model of F . The \ninterpretation tM,\u00df of a term t in a partial structure M is as for total structures, except that if t \n= f(t1, . . . , tn) for f . O then tM,\u00df is unde.ned if either tiM,\u00df is unde.ned for some i, or (t1M,\u00df \n, . . . , tnM,\u00df ) is not in the domain of M (f). We say that a partial structure M weakly satis.es a \nliteral L under \u00df, written M, \u00df |= w L, if (i) L is an atom A and either AM,\u00df = 1 or AM,\u00df is unde.ned, \nor (ii) L is a negated atom \u00acA and either AM,\u00df = 0 or AM,\u00df is unde.ned. The notion of weak satis.ability \nis extended to (sets of) clauses as for total structures. A clause C (respectively, a set of clauses) \nis weakly valid in a partial structure M if M weakly satis.es C for all assignments \u00df. We then call M \na weak partial model of C. Theories and theory extensions. A theory T over signature S is simply a set \nof S-formulas. We consider theories T de.ned as a set of S-formulas that are consequences of a given \nset of clauses K. We call K the axioms of the theory T and we often identify K and T . For a theory T \nand formulas (clauses, sets of clauses) F and G, we use F |=T G as a short-hand for T . F |= G. Let S0 \n= (S0, O0) be a signature and assume that signature S1 = (S0 .Se, O0 .Oe) extends S0 by new sorts Se \nand function symbols Oe. We call the elements of Oe extension symbols and terms starting with extension \nsymbols extension terms. A theory T1 over S1 is an extension of a theory T0 over S0, if T1 is obtained \nfrom T0 by adding a set of (universally quanti.ed) S1-clauses K. .-local theory extensions. The following \nde.nition captures one speci.c variant of (.-)local theory extensions that is discussed together with \nother variants of this notion in [46] and [28]. Let T be a theory over signature S0 = (S0, O0) and T1 \n= T0 . K a theory extension of T0 with .nite K and signature S1 = (S0 . Se, O0 . Oe). In the following, \nwhen we refer to a set of ground clauses G, we assume they are over the signature Sc 1 which extends \nS1 with a set of new constant symbols Oc. For a set of clauses K, we denote by st(K) the set of all ground \nsubterms that appear in K. An embedding closure for T1 is a function . associating with a set of (universally \nquanti.ed) clauses K and a .nite set of ground terms T a .nite set .(T ) of ground terms such that (i) \nall ground subterms in K and T are in .(T ); (ii) . is monotone, i.e., for all sets of ground terms T \n, T ' if T . T ' then .(T ) . .(T '); (iii) . is idempotent, i.e., for all sets of ground terms T , .(.(T \n)) . .(T ). (iv) . is compatible with any map h between constants, i.e., .(h(T )) = h(.(T )) where h \nis homomorphically extended to terms. For a set of ground clauses G, we denote by .(G) the set .(st(G)). \nLet K[.(G)] be the set of instances of K in which all extension terms are in .(G). We say that T1 = T0 \n. K is a .-local theory extension if there exists an embedding closure . such that for every .nite set \nof ground clauses G, T1 . G |= . iff T0 . K[.(G)] . G |= .. Theory extension T1 = T0 . K is a local theory \nextension, if it is a .-local extension, where . is de.ned as .(T ) = st(K) . st(T ).  Craig interpolation \nmodulo theories. We use a notion of Craig interpolation modulo theories where interpreted symbols are \ncon\u00adsidered to be shared between formulas. Let S be a signature and T a S-theory. Let further Sc be the \nsignature S extended with fresh constant symbols Oc. We say that a Sc-term t is shared between two sets \nof Sc-terms TA and TB , if all constants from Oc in t ap\u00adpear in both TA and TB , i.e., st(t)nOc . st(TA)nst(TB). \nWe say that t is TA-pure if st(t) n Oc . st(TA), respectively, t is TB-pure if st(t) n Oc . st(TB ). \nWe extend these notions from sets of terms TA and TB to clauses and sets of clauses, as expected. Given \na conjunction A . B of Sc-formulas A, B that is unsat\u00adis.able in T , a Craig interpolant for A . B is \na Sc-formula I such that: (a) I is a consequence of A in T : A |=T I, (b) the conjunction of I and B \nis unsatis.able in T : I . B |=T ., and (c) all terms in st(I) are shared between A and B. We say that \nT admits ground interpolation if for all .nite sets of Sc-ground clauses A and B with A . B |=T ., there \nexists a .nite set of Sc-ground clauses I that is a Craig interpolant for A . B. 4. Instantiation-Based \nInterpolation We now present our framework for instantiation-based interpola\u00adtion. In the following, \nwhen we refer to a theory extension T1 = T0 . K, we denote by S0 the signature of T0 and by S1 = S0 . \nSe the signature of T1, where Se = (Se, Oe) are the extension sym\u00adbols and sorts. In the case of local \ntheories, the instantiation-based reduction approach to interpolation works as follows [47]. Suppose \nwe are given sets of ground clauses A and B over S1, whose conjunction is unsatis.able in T1. The goal \nis to compute a ground interpolant I for A.B. Locality tells us that we can reduce the problem of check\u00ading \n(un)satis.ability of A . B in T1 to checking (un)satis.ability of K[A . B] . A . B in T0. Here, K[A . \nB] is the (.nite) set of in\u00adstances of clauses in K that are obtained by replacing the free vari\u00adables \nappearing below extension terms in K with ground subterms appearing in K . A . B, such that all resulting \nground extension terms in K[A.B] already appear in A.B. The instances K[A.B] can be partitioned into \nA-pure instances KA (obtained by instanti\u00adating clauses in K with terms from A only), B-pure instances \nKB (obtained by instantiating clauses in K with terms from B only), and mixed instances KC (obtained \nby instantiating clauses in K with terms from both A and B). If it is possible to .nd a .nite set of \nnon-mixed terms that separates the mixed instances KC into sets of A-pure instances KC,A and B-pure instances \nKC,B , then we ob\u00adtain an interpolation problem for the base theory A0 . B0 |=T0 .. Here, A0 and B0 are \nthe results of applying Ackermann s expan\u00adsion to eliminate the extension symbols from the sets of clauses \nKA . KC,A . A, respectively, KB . KC,B . B. From a ground interpolant I0 for A0 . B0 one can then easily \nreconstruct a ground interpolant I for A . B. The question is whether it is indeed possible to separate \nthe in\u00adstances KC into A-pure and B-pure parts. The result in [47] iden\u00ad proc Interpolate input T1 = \nT0 . K : theory extension Interpolate0 : ground interpolation procedure for T0 . TEUF W : amalgamation \nclosure for T1 A, B : sets of ground Sc 1-clauses with A . B |=T1 . begin A0 := A . K[W (A, B)] B0 := \nB . K[W (B, A)] I := Interpolate0(A0, B0) return I end Figure 4. Generic instantiation-based interpolation \nprocedure. ti.es suf.cient conditions on the theory extension to ensure this. Unfortunately, these restrictions \nare quite severe. In particular, the axioms in K are required to be Horn clauses of a speci.c form, which \nrules out many interesting applications. Instead of impos\u00ading such syntactic restrictions on the theory, \nwe .rst identify a stronger completeness condition on the theory extension than just (.-)locality and \nthen relate this condition to a semantic condition on the models of the theory. By combining these two \nresults, we obtain a framework of complete instantiation-based ground inter\u00adpolation procedures for a \nmore general class of theory extensions. 4.1 W -Separable Theories To formalize the set of terms that \nis required to separate the mixed instances of A and B, we introduce the notion of an amalgamation closure. \nAn amalgamation closure for a theory extension T1 = T0 . K is a function W associating with .\u00adnite sets \nof ground terms TA and TB , a .nite set W (TA, TB) of ground terms such that (i) all ground subterms \nin K and TA are in W (TA, TB ); (ii) W is monotone, i.e., for all TA . T' A, TB . T'W (TA, TB ) . W (T'B \n); (iii) W is a clo- B, A, T'sure, i.e., W (W (TA, TB ), W (TB, TA)) . W (TA, TB); (iv) W is compatible \nwith any map h between constants satisfying h(c1) = h(c2), for all constants c1 . st(TA), c2 . st(TB) \nthat are not shared between TA and TB, i.e., for any such h we require W (h(TA), h(TB )) = h(W (TA, TB \n)); and (v) W (TA, TB ) only contains TA-pure terms. For sets of ground clauses A, B we write W (A, B) \nas a shorthand for W (st(A), st(B)). For the remainder of this section W always refers to an amalgamation \nclosure. We next identify the cases where the instances of extension axioms can be separated. De.nition \n1. We say that a theory extension T1 = T0 . K is W \u00adseparable if for all sets of ground clauses A and \nB, T1 .A.B |= . iff T0 . K[W (A, B)] . A . K[W (B, A)] . B |= .. From this de.nition we directly obtain \nthe following theorem. Theorem 2. If T1 = T0 . K is W -separable, then it is .-local where . is de.ned \nby .(T ) = W (T , T ), for all sets of ground terms T . Our generic instantiation-based interpolation \nprocedure is de\u00adscribed in Figure 4. Procedure Interpolate reduces the given inter\u00adpolation problem A \n. B for the theory extension T1 = T0 . K, to an interpolation problem A0 . B0 in T0 . TEUF, where TEUF \nis the theory of uninterpreted function symbols with equality. For W \u00adseparable theory extensions, procedure \nInterpolate is sound and complete, provided that a complete ground interpolation procedure Interpolate0 \nfor T0 . TEUF exists: Theorem 3. Let T1 = T0 . K be a theory extension such that:  1. T0 . TEUF has \na ground interpolation procedure Interpolate0, 2. all free variables in K appear below extension symbols, \nand 3. T1 . T0 is W -separable.  Then Interpolate is a ground interpolation procedure for T1.  4.2 \nIdentifying W -Separable Theories We now present our semantic criterion to identify W -separable theories. \nLet us begin by recalling the model theoretic notion of amalgamation [32]. An amalgam for a theory T \nis a tuple (MA, MB, MC ) where MA, MB , MC are models of T with MA . MC . MB and [MC ] = [MA] n [MB]. \nTheory T has the amalgamation property if for every amalgam (MA, MB, MC ) of T , there exists a model \nMD of T , and embeddings hA : MA . MD and hB : MB . MD such that hA|[MC ] = hB|[MC ]. If in addition \nhA[MA] n hB[MB] = hA[MC ] = hB[MC ] where for any sets X . Y and function f with domain Y , f X = { f(x) \n| x . X }, then T is said to have the strong amal\u00adgamation property. Note that T has the strong amalgamation \nprop\u00aderty iff for all models MA, MB, MC of T with MA . MC . MB and [MC ] = [MA] n [MB ] there exists \na model MD of T with MA . MD . MB . It is well-known that amalgamation and ground interpolation are strongly \nrelated: Theorem 4 ([2]). A theory T has ground interpolation iff T has the amalgamation property. Theorem \n4 provides an effective tool to check whether a given theory admits ground interpolation. Unfortunately, \nthe amalgama\u00adtion property only tells us that ground interpolants exist, not how to compute them (other \nthan by brute-force enumeration). To rem\u00adedy this fact, we de.ne a related notion of partial amalgamation \nthat refers to partial instead of total models and weak embeddings instead of embeddings. This notion \nallows us to characterize W \u00adseparable theories. Together with Theorem 3, we then obtain a pow\u00ad erful \nmodel theoretic criterion that does not just allow us to prove the existence of ground interpolants, \nbut also tells us how to gener\u00adically construct the accompanying interpolation procedure by ap\u00adplying \nTheorem 3. For a weak partial model M of a theory extension T1 = T0 . K, we denote by T (Oe, M ) the \nset of terms T (M) = { f (a1, . . . , an) | ai . [M], f . Oe, M (f)(a1, . . . , an) de.ned }where we \ntreat the elements of the support [M] as constant sym\u00adbols that are interpreted by themselves. Further, \nwe denote by PMod(T1) the set of all weak partial S1-models M of T1 in which all symbols in S0 are totally \nde.ned and T (M) is .nite. Let W be an amalgamation closure for theory extension T1 = T0 . K. A partial \nW -amalgam for T1 = T0 . K is a tuple (MA, MB , MC ) where (i) MA, MB, MC . PMod(T1); (ii) MC is a substructure \nof both MA and MB ; (iii) [MC ] = [MA] n [MB ]; (vi) both T (MA) and T (MB ) are closed under W , i.e., \nW (T (MA), T (MB )) . T (MA) and W (T (MB), T (MA)) . T (MB); and (v) T (MA) n T (MB) . T (MC ). De.nition \n5. A theory extension T1 = T0 . K is said to have the partial amalgamation property with respect to W \nif for all partial W -amalgams (MA, MB, MC ) there exists a model MD of T1, and weak embeddings hA : \nMA . MD and hB : MB . MD such that hA|[MC ] = hB|[MC ]. To simplify matters, we assume that the extension \naxioms K are in a speci.c normal form: a clause C is called S1-.at if no term that occurs in C below \na predicate symbol or the symbol = contains nested function symbols. A clause C is called S1-linear if \n(i) whenever a variable occurs in two non-variable terms in C that do not start with a predicate or the \nequality symbol, the two terms are identical, and if (ii) no such term contains two occurrences of the \nsame variable. Note that every set of extension axioms can be syntactically transformed into one that \nis S1-.at and S1-linear. Intuitively, a weak partial model M of A0 . B0 corresponds to a partial W -amalgam \n(MA, MB , MC ) where MA is obtained from M by restricting M to the terms in A0, MB is obtained by restricting \nM to the terms in B0, and MC is obtained by restricting M to the common terms of A0 and B0. Partial amalgamation \nthen tells us that we can always obtain a total model of A0 . B0 from M. This is what the following theorem \nsays: Theorem 6. Let T1 = T0 . K be a theory extension with K S1 \u00adlinear and S1-.at. If T1 has the partial \namalgamation property with respect to W , then T1 is W -separable. Finally, in order to apply Theorem \n3, we need to be able to iden\u00ad tify the cases where a ground interpolation procedure Interpolate0 for \nthe theory T0 . TEUF exists. One possibility is that we view T0 . TEUF as the disjoint combination of \nthe theories T0 and TEUF. In this case, we require that T0 is decidable, has the strong amalga\u00admation \nproperty, and is stably in.nite. Since TEUF satis.es the same properties, a ground interpolation procedure \nfor the disjoint com\u00adbination of the theories T0 and TEUF exists, as follows from [11, Corollary 1]. \nCorollary 7. Let T1 = T0 . K be a theory extension such that: 1. satis.ability of sets of ground clauses \nis decidable for T0, 2. T0 is stably in.nite 3. T0 has the strong amalgamation property, 4. all free \nvariables in K appear below extension symbols, and 5. T1 . T0 is W -separable.  Then Interpolate is \na ground interpolation procedure for T1 where Interpolate0 is the ground interpolation procedure for \nthe disjoint theory combination T0 . TEUF. Alternatively, we can view T0 . TEUF as a local extension \nof T0 and use results from [47] to obtain the procedure Interpolate0. This yields different requirements \non the base theory than the ones stated in Corollary 7. See the technical report [48] for further details. \n5. Examples Our framework of complete instantiation-based interpolation ap\u00adplies to many known local \ntheory extensions, including those de\u00adscribed in [47]. In the following, we discuss two non-trivial exam\u00ad \nples that go beyond the theories considered in [47]. 5.1 Theory of Arrays with Difference Function Our \n.rst example is the theory of arrays with difference function that has been recently investigated in \n[10]. We de.ne this theory of arrays as a theory extension Tarr = T0 . Karr that is parametric in its \nbase theory T0. For this purpose, we assume that the base theory T0 is over signature S0 = (S0, O0) with \nsorts index and elem in S0, and that T0 satis.es the assumptions of Corollary 7. Examples of appropriate \nbase theories are the empty theory (in which case O0 contains only equality predicates), the theory of \nuninterpreted function symbols with equality, and the theory of linear arithmetic, interpreting the sort \nindex as integers. The theory Tarr extends T0 with a fresh sort array and extension symbols rd : array \n\u00d7 index . elem, wr : array \u00d7 index \u00d7 elem . array, and di. : array \u00d7 array . index. The function symbols \nrd and wr stand for the usual array selection and update function whose meaning is given by McCarthy \ns read over write axioms [36]: rd (wr(a, i, e), i) = e, (4) i = j . rd (wr(a, i, e), j) = rd (a, j) (5) \n The function di. is de.ned as follows: for any two distinct arrays a and b, the term di. (a, b) denotes \nan index at which a and b differ. This is formalized by the following axiom: a = b . rd (a, di. (a, b)) \n= rd (b, di. (a, b)) (6) Note that this axiom is obtained by skolemizing the extensionality axiom for \narrays .ab. a = b . .i. rd (a, i) = rd (b, i) where di. is the introduced Skolem function for the existentially \nquanti.ed variable i. The set of extension axioms Karr of our theory of arrays consists of the .attened \nand linearized versions of the axioms (4), (5), and (6) where a, b, i, j and e are implicitly universally \nquanti.ed variables. For instance, the linearized and .attened version of axiom (4) is b = wr(a, i, e) \n. i = j . rd (b, j) = e It is well-known that the standard theory of arrays (i.e., the one given by axioms \n(4) and (5)) does not admit ground in\u00adterpolation. We illustrate this through an example due to Ranjit \nJhala: consider the ground formulas A = b = wr(a, i, e) and B = j = k . rd (a, j) = rd (b, j) . rd (a, \nk) = rd (b, k) whose conjunction is unsatis.able. There exists no ground inter\u00adpolant for (A, B) that \nonly contains the shared constants a, b and the theory symbols wr and rd . However, as has been observed \nin [10], such a ground interpolant can be constructed if one in\u00ad cludes the difference function di. in \nthe theory. An appropriate ground interpolant for (A, B) in the extended theory is given by b = wr(a, \ndi. (a, b), rd (b, di. (a, b))). In fact, the authors of [10] have shown that including the di. function \nis suf.cient for ground interpolation. We now give an alternative proof of this result by showing that \nTarr has the partial amalgamation property. This leads to an alternative interpolation procedure for \ntheory Tarr that can be easily implemented on top of an existing interpolation procedure for the base \ntheory. In order to de.ne an appropriate amalgamation closure Warr , we need to generalize the example \nabove. That is, we have to de.ne Warr in such a way that there exists no partial Warr -amalgams (MA, \nMB, MC ) with arrays a and b that are shared between MA and MB, and MA, MB disagree on the number of \nindices at which a and b differ. To this end, inductively de.ne for any terms a and b k of sort array \nand k = 0 the term a b as follows: k a b = a if k = 0 and kk-1k-1k-1 a b = wr(a b, di. (a b, b), rd (b, \ndi. (a b, b))) for all k > 0. Note that if in some Tarr -model two arrays a and b k differ in exactly \nk positions, then b = a b. Now de.ne Warr as follows: Warr (TA, TB) = k let T0 = st(TA . { a b | a, b \n. st(TA n TB ) }) in let T1 = st(T0 . { rd (a, di. (a, b)) | a, b . st(TA) }) in T1 . { rd (a, i) | a, \ni . st(T1), rd (b, i) . T1 . st(TB ) } where k is the number of non-shared terms of the form wr(a, i, \ne) in TA . TB . Note that Warr (TA, TB) can be represented in space that is polynomial in the size of \nTA . TB . Hence, also Karr [W (A, B)] . Karr [W (B, A)] is polynomial in A, B for .nite sets of ground \nclauses A, B. Clearly Warr satis.es properties (i), (ii), (iv), and (v) of amal\u00adgamation closures. To \nsee that it also satis.es (iii), note that Warr does not increase the number of non-shared terms of the \nform wr(a, i, e). Lemma 8. Warr is an amalgamation closure. Theorem 9. The theory Tarr = T0 . Karr has \nthe partial amalga\u00admation property with respect to Warr .  5.2 Theory of Linked Lists with Reachability \nOur second example is an extension of Nelson s theory of linked lists with reachability [41], which is \nalso at the core of the LISBQ logic studied in [35]. This theory is useful for reasoning about the correctness \nof programs that manipulate list-like heap-allocated data structures. We show that neither Nelson s original \ntheory, nor its variation in [35] admit ground interpolation. Using counterex\u00ad amples to the partial \namalgamation property for Nelson s theory, we then systematically develop an extension of the theory, \nwhich admits ground interpolation. As a result, we obtain the .rst com\u00adplete ground interpolation procedure \nfor a non-trivial theory of linked data structures. As in the previous example, we de.ne our theory of \nlists with reachability as a theory extension Tllr = T0 . Kllr that is parametric in its base theory \nT0. We require that the base theory is over the signature S0 = (S0, O0) with a dedicated sort addr in \nS0 and that T0 satis.es the assumptions of Corollary 7. Theory Tllr extends the base theory with an additional \nsort .eld and extension symbols rd , wr, df , jp, lb, and R. The associated sorts are as follows: rd \n: .eld \u00d7 addr . addr wr : .eld \u00d7 addr \u00d7 addr . .eld df : .eld \u00d7 .eld . addr jp, lb : .eld \u00d7 addr \u00d7 addr \n. addr R : .eld \u00d7 addr \u00d7 addr \u00d7 addr . bool Before we present the axioms of the theory extension, we \nde.ne the meaning of the extension symbols in terms of a set of struc\u00adtures Mllr in which the interpretation \nof extension symbols is de\u00adtermined by the interpretation of the sorts addr and .eld. We call the structures \nin Mllr heap models. In a heap model M . Mllr, the sort addr represents a set of memory addresses and \nthe sort .eld a set of address-valued pointer .elds. We use a Bornat/Burstall-style memory model [7], \ni.e., each .eld is represented as a function from addresses to addresses. The base theory may, e.g., \ninterpret the sort addr as integers to model pointer arithmetic, or it may leave this sort uninterpreted \nto obtain a more abstract memory model. In a heap model, the extension symbols rd and wr are inter\u00adpreted \nas function application and function update, respectively. For notational convenience, we write x.f and \nf[x := y] in for\u00admulas for terms of the form rd (f, x), respectively, wr(f, x, y). An atom R(f, a, b, \nc) holds in a heap model M, if there exists a path in the function graph spanned by .eld f that connects \naddresses a and b, and the shortest such path does not visit address c. In formulas, f /uf we write x \n--. y instead of R(f, x, y, u) and we write x -. y as f /yf a short-hand for x --. y. Note that a -. \nb holds in a heap model M iff a and b are related by the re.exive transitive closure of f. The function \nsymbol jp is interpreted such that jp(f, a, b) denotes the join point of addresses a and b, i.e., jp(f, \na, b) is the .rst ad\u00address on the f-path starting in a that is also on the f-path starting in b, unless \nthese paths are disjoint. In the latter case, we de.ne jp(f, a, b) = a. Note that even if the f-paths \nstarting in a and b are not disjoint, we might still have jp(f, a, b) = jp(f, b, a) if the two f paths \nform a cycle. In formulas, we write x y as a shorthand for jp(f, x, y). The function symbol lb is interpreted \nsuch that if b is reachable from a via f, then lb(f, a, b) is the last address before b on the shortest \nf-path from a to b. The function symbol df is inter\u00adpreted as in the theory of arrays, i.e., df (f, g) \ndenotes an address for which f and g take different values in case f and g are not the same functions. \n M(rd)(f, a) = f(a) M(wr)(f, a, b) = f[a . b] M(R)(f, a, b, c) = 1 iff (a, b) . { (d, f(d)) | d . M(addr) \n. d = c } * M(df )(f, g) . { a . M(addr) | f (a) = g(a) } if f = g M(jp)(f, a, b) = c iff (a, c) . { \n(d, f(d)) | (b, d) ./f * } * . ((b, c) . f * . a = c) M(lb)(f, a, f(b)) = b if M(R)(f, a, b, f(b)) = \n1 Figure 5. Restrictions on the interpretation of extension symbols in a heap model M Formally, for a \nbinary relation P over a set X (respectively, a unary function P : X . X), we denote by P * the re.exive \ntran\u00adsitive closure of P . The set of heap models Mllr is then de.ned as the set of all structures M \nsuch that (i) M|S0 is a model of T0, (ii) M(.eld) is the set of all functions M(addr) . M(addr), (iii) \nthe interpretation of the extension symbols in M satis.es the restric\u00adtions speci.ed in Figure 5, and \n(iv) for every a . M(addr), f . f f M(.eld), the set { b . M(addr) | a -. b . b -. a } is .nite. Con\u00addition \n(iv) is not strictly necessary, but it provides a more precise characterization of the models that we \nobtain from partial amal\u00adgams of Tllr. We make the following simplifying assumption, which restricts \nthe set of input formulas that we consider. Assumption 10. The set of uninterpreted constants Oc contains \nat most one constant of sort .eld. Assumption 10 means that we will only consider input formulas A.B \nin which all terms of sort .eld are related by a .nite sequence of .eld writes. That is, there will be \nno models of such formulas in which the interpretation of two terms of sort .eld appearing in A . B differ \nat more than n addresses, where n is the number of .eld writes in A . B. The extension axioms Kllr are \nthe set of clauses that is obtained by computing the conjunctive normal form of the axioms given in Figure \n6, and linearizing and .attening the resulting set of clauses. The following lemma states that the resulting \ntheory extension Tllr is a sound axiomatization of heap models. Lemma 11. All heap models are models \nof Tllr. As we shall see later, the extension axioms are also suf.cient to fully characterize heap models, \ni.e., every ground formula that is satis.able modulo Tllr is also satis.able in some heap model. However, \nlet us .rst explain why the theory without the function jp does not have ground interpolation. To this \nend, consider the situation illustrated in Figure 7. The graphs MA, MB, and MC depict (partial) heap \nmodels where the dashed edges denote binary f reachability x -. y. Transitive and re.exive edges are \nomitted for readability. The structures MA and MB are almost identical. They only differ in the order \nin which the list segments starting in c1 and c2 join the list segment starting in c0. In MA the segment \nof c1 joins before the one of c2 and in MB it is the other way around. We express MA and MB in terms \nof formulas A and B as follows: f/c1f/c0f f/a0 A = c0 - -. a0 . c1 - -. a0 . a0 -. a1 . c2 ---. a1 . \nf a1 -. c3 . a0 = a1 f/c2f/c0f f/b0 B = c0 - -. b0 . c2 - -. b0 . b0 -. b1 . c1 - -. b1 . f b1 -. c3 \n. b0 = b1 f/u Re.exive x --. x f/u Step x --. x.f . x = u f SelfLoop x.f = x . x -. y . x = y f/x Sandwich \nx --. y . x = y f/uf Reach x --. y . x -. y f f/yf/u Linear1 x -. y . x --. u . x --. y f/uf/v Linear2 \nx --. y . x --. z . f/uf/uf/vf/v x --. z . z --. y . x --. y . y --. z f/uf/uf/u Transitive1 x --. y \n. y --. z . x --. z f/zf/zf f/u Transitive2 x --. y . y --. u . y -. z . x --. y ff Join1 x -. (x y) \nfff f Join2 x -. z . y -. z . y -. (x y) ff f f/z Join3 x -. z . y -. z . x --. (x y) f ff Join4 y -. \n(x y) . (x y) = x f/y.f LastBefore x - --. y . lb(f, x, y.f) = y f[u:=v]/w ReachWrite x ------. y . f/wf/u \nx - -. y . x --. y . f/wf/wf/u x - -. u . v - -. y . v --. y . u = w ReadWrite1 x.(f[x := y]) = y ReadWrite2 \nx = y . y.(f [x := z]) = y.f Di. f = g . df (f, g).f = df (f, g).g Figure 6. Axioms of theory extension \nTllr The conjunction A . B is unsatis.able because A and B do not agree on the order of the join points \nof the list segments. An appropriate ground interpolant for A . B is given by f f f \u00ac(c0 c2) -. (c0 c1) \nAll other ground interpolants for A . B also rely on the join function. Hence, if we drop the join function \nfrom the theory Tllr, we lose ground interpolation. This is also re.ected in a violation of the amalgamation \nproperty. If we drop joins, the models MA and MB have a common substructure MC , which we also depict \nin Figure 7. There is no model MD in which both MA and MB can be embedded while preserving the common \nsubstructure MC . The function lb plays a similar role than jp in that it is also needed for the completeness \nof ground interpolation. A correspond\u00ading counterexample to partial amalgamation can be found in the \nextended version of this paper [48]. We omit further details here because the function lb appears to \nbe of less practical importance than the join function. Although the full theory Tllr admits ground interpolation, \nit is still dif.cult to devise an amalgamation closure Wllr that allows us to prove partial amalgamation \nfor this theory. We illustrate this using the unsatis.able formula (3) in Section 2.2. One ground f interpolant \nfor A . B is c.f -. c, which expresses that c lies on   f f f f f f  f f f f f f f f  MA MC MB \nFigure 7. An amalgam (MA, MC , MB ) of the theory of linked lists without join that witnesses a violation \nof amalgamation a cycle. In order to prove the partial amalgamation property for theory Tllr, we have \nto ensure that the shared substructure of every partial amalgam already contains all information about \nwhich of the shared terms c lie on a cycle. Since we can express this using f the formula c.f -. c we \nmay attempt to de.ne the amalgamation closure Wllr such that for every shared .eld f and every shared \naddress c de.ned in the common substructure, also c.f is de.ned. However, since c.f is again shared, \nsuch an operator Wllr would inevitably fail to satisfy condition (iii) of amalgamation closures. We can \navoid this problem by further extending Tllr with an additional predicate symbol Cy : .eld \u00d7 addr . bool \nsuch that f Cy(f, c) holds iff c.f -. c. The corresponding extension axioms de.ning Cy are as follows \nf f Cycle1 x -. y . y -. x . Cy(f, x) . x = y f f Cycle2 Cy(f, x) . x -. y . y -. x Note that in these \naxioms we do not use c.f to de.ne Cy(f, c), which avoids the problem with the de.nition of the amalgamation \nclosure mentioned above. We denote by Kllrc the set of extension axioms obtained by adding these axioms \nto Kllr and we denote by Tllrc the resulting theory extension Tllrc = T0 . Kllrc. To de.ne the amalgamation \nclosure for Tllrc, we .rst de.ne the terms f k g for all terms f, g of sort .eld and k = 0, as in the \ncase of the array theory, except that we replace array reads by .eld reads and array writes by .eld writes. \nThe amalgamation closure for Tllrc is then de.ned as follows: Wllrc(TA, TB) = let T0 = st(TA . { f k \ng | f, g . st(TA n TB) }) in let T1 = st(T0 . { df (f, g).f | f, g . st(TA) }) in let T2 = T1 . { a.f \n| f, a . st(T1), a.g . T1 . st(TB) } in let T3 = T2 . { lb1(f, a, b.f ) | a, b.f . T2 } in let T4 = T3 \n. { (a f b)1 | a, b, f . T3 shared with TB } in f /c let T5 = T4 . { a --. b | a, b, c, f . T4 } in let \nT6 = T5 . { Cy(f, a) | f, a . T5 shared with TB } in T6 where k is the number of non-shared terms of \nthe form f[a := b] in TA.TB , lb1(f, a, b.f ) denotes lb(f, a, b.f ) if lb does not appear in a or else \nit denotes a, and similarly (a f b)1 denotes a f b if no join appears in a and b, or else a. The intermediate \nset of terms T2 in the de.nition of Wllrc(TA, TB ) is similar to the set of terms computed by Warr for \nthe theory of arrays. The set of terms T4 ensures that the joins of all shared terms are de.ned. Note \nthat in models of Tllrc we ff f fff have for all a, b, c and f, (a b) c = a c or (a b) c = b c, ff fff \nf and similarly a (b c) = a b or a (b c) = a c. Because of this property and Assumption 10, we can avoid \nthe construction of terms with nested occurrences of joins. The set T5 ensures that the reachability \npredicate is fully de.ned in all partial models. Finally, T6 ensures that the predicate Cy is de.ned \nfor all shared terms. Lemma 12. Wllrc is an amalgamation closure. We can now prove that theory Tllrc \nhas the partial amalgamation property. In fact, we can prove a slightly stronger statement: Lemma 13. \nFor every partial Wllrc-amalgam (MA, MB, MC ) of Tllrc there exists a total model MD of Tllrc, and weak \nembeddings hA : MA . MD and hB : MB . MD such that hA|[MC ] = hB |[MC ]. Moreover, MD|Sllr is isomorphic \nto a heap model. Theorem 14. The theory Tllrc = T0 . Kllrc has the partial amalga\u00admation property with \nrespect to Wllrc. Theorem 14 does not just give us a complete ground interpo\u00adlation procedure for Tllrc, \nbut also for Tllr. This is because we can always rewrite atoms of the form Cy(f, c) in interpolants for \nthe\u00ad f ory Tllrc into atoms c.f -. c, obtaining an interpolant for Tllr. Corollary 15. Theory Tllr admits \nground interpolation. Finally, we can show that satis.ability of ground formulas mod\u00adulo Tllr is equivalent \nto satis.ability of ground formulas modulo heap models. This is a consequence of Lemma 13 and Lemma 11. \nTheorem 16. Let G be a .nite set of ground Sc -clauses. Then llr Tllr . G |= . iff M |= G for all M . \nMllr. Note that the number of terms in Wllrc(TA, TB ) is polynomial in the size of TA . TB and, hence, \nso is the number of generated instances of extension axioms. Together with Theorem 14 this im\u00adplies that \nsatis.ability of ground formulas modulo Tllr is decidable in NP, provided T0 . TEUF is also decidable \nin NP. 6. Combining Interpolation and Abstraction We now turn towards more practical concerns. A common \nproblem in interpolation-based algorithms is that interpolants are not unique. Often the interpolation \nprocedure produces interpolants that are not useful for a speci.c application. This may cause, e.g., \nthat the re.nement loop of a software model checker diverges because the generated interpolants do not \nsuf.ciently abstract from the infeasible error traces. To illustrate this problem, consider the program \nshown in Fig\u00adure 8. The function concat takes two lists x and y as input and con\u00adcatenates them by .rst \ntraversing x and then swinging the pointer of the last node of x to y. A second while loop then traverses \nx again to check whether y is reachable after the concatenation. Suppose we want to use interpolation-based \nveri.cation to check that the assert statement in concat never fails. The right-hand side of Figure 8 \nshows the trace formula for a spurious error trace of concat, which is obtained by unrolling both loops \ntwice. The trace formula is un\u00adsatis.able, hence we can compute an interpolant for the indicated choice \nof A . B. One valid interpolant is as follows: x.n1.n1 = null . y = null This interpolant is rather useless \nfor obtaining an inductive invari\u00adant that allows us to prove our veri.cation goal. The interpolant only \nrules out the one given error trace and fails to abstract from its speci.cs, i.e., the length of the \ntraversed list. We would rather like n1 to obtain the alternative interpolant x -. y, which is the induc\u00adtive \nloop invariant we are seeking. But how can we ensure that the  = null . proc InterpolateWithAbstraction \nvoid concat ( List x, List y) { prev0 List . input curr , prev ; curr0 = x prev = null ; curr0 = null \n. T1 = T0 . K : theory extension Interpolate0 : ground interpolation procedure for T0 . TEUF curr = x; \nprev1 = curr0 . . . . . . . . . . . . . . . . . .. . . . .. . . . . . . while (curr != null ) {prev = \ncurr; curr1 = curr0.n0 . GetModel0 : model generation procedure for T0 . TEUF . curr = curr.n; A curr1 \n= null . W : amalgamation closure for T1 } if prev2 = curr1 . a : abstraction function for weak partial \nmodels PMod(T1) (prev == null) x = y; curr2 = curr1.n0 else prev.n = y; curr = x; while (curr != null \n&#38;&#38; = null . A, B : sets of ground Sc 1-clauses with A . B |=T1 curr2 . = null . begin prev2 n1 \n= n0[prev2 := y] . I := . curr3 = x . curr3 = null . != y) {curr.n while \u00acI . A . K[W (A, B)] |. do =T0.TEUF \nMA := GetModel0(\u00acI . A . K[W (A, B)]) curr curr = . } assert curr3 = y . A0 := a(MA) . K[W (a(MA), B)] \n(curr == y); curr4 = curr3.n1 = null . B0 := B . K[W (B, a(MA))] } curr4 B curr4 = y . if A0 . B0 |. \nthen =T0.TEUF curr5 = curr4.n1 . A0 := MA . K[W (MA, B)] (curr5 = null . B0 := B . K[W (B, MA)] curr5 \n= y) . I := I . Interpolate0(A0, B0) curr5 = y return I Figure 8. C code for concatenation of two lists. \nThe second while loop checks whether y is reachable from x after the concatenation. The right-hand side \nshows the trace formula for an infeasible error trace that is obtained by unfolding both while loops \ntwice. interpolation procedure .nds the right interpolant? What accounts for a good interpolant often \ndepends on the concrete application. It is therefore dif.cult to devise generic strategies that can be \nhard\u00adwired into the interpolation procedure. Our approach enables the user of the interpolation procedure \nto inject domain-speci.c knowledge that helps to guide the proof search and improves the quality of the \nproduced interpolants. This can be done as follows. Note that a partial model M can be thought of as \na symbolic representation of a set of total models, namely the set of all models into which M weakly \nembeds. In fact, for many local theory extensions we can represent a ground formula A as a .nite set \nof partial models each of which is represented as a .nite set of ground unit clauses. We can then guide \nthe interpolation procedure as follows: instead of interpolating A . B directly, we enumerate partial \nmodels MA of A, which we interpolate one by one with B. However, before we compute the interpolant of \nMA . B for a given partial model MA, we .rst apply a user\u00adde.ned abstraction function a that widens MA \nby dropping certain clauses. For instance, in the case of the theory of linked-lists we may want to drop \nall clauses containing the function symbol for .eld dereference from partial models and only keep information \nabout reachability and joins. This idea of combining interpolation and abstraction is re\u00adalized in procedure \nInterpolateWithAbstraction given in Fig\u00adure 9, which re.nes our earlier procedure in Figure 4. Procedure \nInterpolateWithAbstraction takes as additional arguments the user-de.ned abstraction function a and a \nprocedure GetModel0 that is able to generate partial models for satis.able formulas in the theory T0 \n. TEUF. The while loop enumerates the partial models of A. In each iteration, we only consider partial \nmodels that are not yet subsumed by the already computed interpolants I. This ensures that only few partial \nmodels have to be considered in practice. The conditional statement in the body of the while loop guarantees \nthat the interpolation procedure falls back to the full partial model MA in the cases where the abstraction \nfunction is too coarse and does not preserve unsatis.ability of MA . B. Procedure InterpolateWithAbstraction \nenables us to easily incorporate domain-speci.c abstraction and widening techniques end Figure 9. Instantiation-based \ninterpolation procedure with user\u00adde.ned abstraction of partial models. into the interpolation procedure \nwhile still treating the underlying interpolation procedure for the base theory as a black box. The ability \nof modern SMT solvers to generate models for satis.able formulas makes it easy to implement this approach. \n7. Implementation and Evaluation We have implemented our framework in a prototype tool and in\u00adstantiated \nit for the theory of linked lists with reachability that we presented in Section 5.2. The prototype is \nwritten in OCaml. It im\u00adplements a variation of the algorithm presented in Figure 9. We use the SMT solver \nZ3 v.4.0 [14] for the generation of partial mod\u00adels and MathSAT 5 [22] for interpolation of formulas \nin the base theory. Communication with both provers is done via their SMT-LIB 2 [4] interfaces. The difference \nbetween the implementation and the vanilla algorithm in Figure 9 is that we use the incremen\u00adtal solving \ncapability of the SMT solver to get a more .ne-grained abstraction of partial models. Instead of falling \nimmediately back to the full partial model MA whenever the abstract partial model is too weak to prove \nunsatis.ability, we sort the clauses of MA in a particular order and then push them one by one on the \nas\u00adsertion stack of the solver. Each time we push a new clause onto the stack, we check whether the conjunction \nof the stack with B is still satis.able. Once it becomes unsatis.able, we compute the interpolant. The \norder in which the clauses of the partial model are pushed is determined by a weight associated with \neach clause, where lighter clauses are considered .rst. The weight function en\u00adcodes the domain-speci.c \nknowledge that guides the proof search of the solver. In our implementation we have chosen the weight \nfunction such that highest weight is given to clauses that contain dereferences of pointer .elds. This \nmakes it more likely that the computed interpolants abstract from the length of the lists. The number \nof generated instances of extension axioms is poly\u00adnomial in the size of the input formulas, which means \nthat the un\u00adderlying decision problem remains in NP. However, in practice the eager instantiation approach \ncan still be a performance bottle neck with thousands of clauses generated even for small examples. We \ntherefore implemented several optimizations to reduce the number Table 1. Summary of experiments. The \ncolumns list the bench\u00admark name, the number of loop unrollings in the error trace, the number of generated \npartial models for A, the number of generated instances of extension axioms, and the total computation \ntime.  benchmark #unroll. #MA #inst. time (s) reverse 3 1 5,003 0.4 concat 2-2 1 9,953 0.6 delete 2 \n2 27,934 2.3 insertBefore 2 2 28,176 2.3 splice 2 4 135,446 12.1 of instances of axioms that we generate. \nFirst, we compute the con\u00adgruence closure for the terms appearing in the original input for\u00admula and \nthen only instantiate axioms by selecting one representa\u00adtive term per congruence class. We have found \nthis to work partic\u00adularly well for trace formulas, which typically contain many equal\u00adities. Second, \nwe use a more lazy instantiation approach where we .rst compute a subset of the terms in the amalgamation \nclosure that is likely to be suf.cient for proving unsatis.ability. For example, in our experiments we \nnever needed to generate instances with terms that contain the df function. Apart from these obvious \noptimiza\u00adtions, our instance generation procedure is still rather naive. To evaluate the feasibility \nof our approach, we have used our implementation to automatically infer loop invariants for verify\u00ading \nproperties of simple list-manipulating programs. In particular, we checked functional correctness properties \nand whether certain shape invariants are preserved. For this purpose, we manually gen\u00aderated spurious \nerror traces from the considered programs by un\u00adrolling their loops a few times. Our prototype accepts \nsuch error traces as input and converts them into trace formulas which are then interpolated. Our experiments \nwhere conducted on a Linux laptop with a dual-core processor and 4GB RAM. Table 1 shows the sum\u00admary \nof our experiments. In all cases, the obtained interpolant was an inductive loop invariant of the program \nand strong enough to prove the program correct. Roughly 40% of the running time is spent on I/O with \nthe provers. However, the main bottle neck of the implementation is the eager instantiation of extension \naxioms. We believe that the running times can be signi.cantly improved by us\u00ading more sophisticated model-driven \ninstantiation approaches such as [20, 29], which instantiate axioms incrementally. 8. Related Work Our \nnotion of partial amalgamation is closely related to the (strong) amalgamation property [32], whose role \nin ground interpolation for disjoint theory combinations has been recently studied [11]. Our use of amalgamation \nproperties is orthogonal to [11], as we con\u00ad sider (non-disjoint) theory extensions rather than disjoint \ntheory combinations. In a sense, partial amalgamation is the adaptation of the weak embedability condition \nin [46] to the case of inter\u00ad polation. Our approach can thus be thought of as the symbioses of the two \northogonal approaches described in [46, 47] and [11]. Note that neither of the interpolation techniques \npresented in [47] and [11] can be applied directly to the theory of lists considered in this paper. The \napproach in [47] is restricted to extension axioms of a very speci.c syntactic form: Horn clauses in \nwhich all predicate symbols are binary and where additional guard constraints on the quanti.ed variables \napply. All three restrictions are violated by the axioms of the list theory. The approach in [11] could \nbe used, in principle, to obtain an interpolation procedure for the combination of a theory of lists \nwith uninterpreted heap nodes and, e.g., the the\u00adory of linear integer arithmetic (for interpreting heap \nnodes as ad\u00addresses). However, the technique in [11] assumes that interpolation procedures for the component \ntheories already exist. There is no interpolation procedure for the list theory component to start with. \nHence, the combination technique of [11] cannot be applied. Other reduction-based approaches to interpolation \nthat are less closely re\u00adlated include [33], which is based on quanti.er elimination. Ground interpolation \nprocedures for speci.c theories have been developed, e.g., for linear arithmetic over reals [23, 38] \nand inte\u00ad gers [8, 9], uninterpreted functions with equality [19, 38, 50], func\u00ad tional lists [50], as \nwell as, combinations of these theories [11, 21, 38, 50]. These are the procedures that our approach \nbuilds on. We discussed two speci.c theories for which ground interpolation re\u00adduces to these existing \nprocedures: the theory of arrays with dif\u00adference functions [10], and the theory of linked-lists with \nreach\u00ad ability [35, 41] extended with join. We believe that our approach applies to many other theory \nextensions that are of importance in program veri.cation, such as our theory of imperative trees [49]. \nInterpolation approaches that use resolution-based automated theorem provers have been studied, e.g., \nin [26, 40]. Unlike our ap\u00ad proach, these methods target undecidable fragments of .rst-order logic and \ninfer quanti.ed interpolants. Sometimes, such quanti\u00ad.ed interpolants are needed to obtain inductive \ninvariants. We can use our approach to infer quanti.ed interpolants by applying tech\u00adniques explored \nin [1]. One interesting observation is that these quanti.ed interpolants themselves often constitute \nlocal theory ex\u00adtensions and can therefore be treated systematically by our frame\u00adwork, if they become \npart of subsequent interpolation problems. To out knowledge, McMillan s [40] interpolating version of \nthe the\u00ad orem prover SPASS, is the only other interpolation-based system that has been used to infer \nshape invariants of heap-allocated data structures. Unlike our theory of linked-lists, McMillan s axiomati\u00adzation \nof reachability predicates is incomplete. Recent works have explored techniques to in.uence the quality \nof computed interpolants, e.g., by reducing the size of unsatis.a\u00adbility proofs from which interpolants \nare generated [27], restricting the language in which interpolants can be expressed [1, 30], or by controlling \nthe interpolant strength [16]. Our technique of guiding the proof search of the interpolation procedure \nthrough user-de.ned abstraction functions is orthogonal to these approaches. In spirit, it is most closely \nrelated to [30]. The key difference is that we do not need to modify the underlying interpolation procedure, \nwhich would contradict our modular approach to interpolation. The idea of using the ability of SMT solvers \nto generate models for abstrac\u00adtion has been previously explored, e.g., in [43]. Whether the ap\u00ad proach \nof combining interpolation and abstraction can be explained more concisely in terms of abstract interpretation, \ne.g., in the spirit of [12], remains a question for future research. 9. Conclusion We have presented \na new instantiation-based interpolation frame\u00adwork that enables the modular construction of ground interpolation \nprocedures for application-speci.c theories. We introduced the se\u00admantic notion of partial amalgamation \nto systematically identify and construct theories for which our framework yields complete interpolation \nprocedures. We gave examples of both new and ex\u00adisting theories to which our framework applies. Using \na prototype implementation we demonstrated that our framework enables new applications of interpolation-based \nalgorithms in program veri.ca\u00adtion. Therefore, we see this work as a starting point for a new line of \nresearch that studies ef.cient instantiation-based interpolation procedures for applications in program \nveri.cation. Acknowledgments This work was supported in part by the European Research Council (ERC) Advanced \nInvestigator Grant QUAREM and by the Austrian Science Fund (FWF) project S11402-N23.  References [1] \nF. Alberti, R. Bruttomesso, S. Ghilardi, S. Ranise, and N. Sharygina. Lazy abstraction with interpolants \nfor arrays. In LPAR, volume 7180 of LNCS, pages 46 61. Springer, 2012. [2] P. Bacsich. Amalgamation properties \nand interpolation theorems for equational theories. Algebra Universalis, 5:45 55, 1975. [3] M. Barnett \nand K. R. M. Leino. To goto where no statement has gone before. In VSTTE, volume 6217 of LNCS, pages \n157 168, 2010. [4] C. Barrett, A. Stump, and C. Tinelli. The SMT-LIB Standard: Version 2.0, 2010. [5] \nD. Beyer, T. A. Henzinger, and G. Th\u00b4eoduloz. Lazy shape analysis. In CAV, volume 4144 of LNCS, pages \n532 546. Springer, 2006. [6] D. Beyer, D. Zufferey, and R. Majumdar. CSIsat: Interpolation for LA+EUF. \nIn CAV, volume 5123 of LNCS, pages 304 308, 2008. [7] R. Bornat. Proving Pointer Programs in Hoare Logic. \nIn MPC, volume 1837 of LNCS, pages 102 126. Springer, 2000. [8] A. Brillout, D. Kroening, P. R \u00a8ummer, \nand T. Wahl. An Interpolating Sequent Calculus for Quanti.er-Free Presburger Arithmetic. J. Autom. Reasoning, \n47(4):341 367, 2011. [9] A. Brillout, D. Kroening, P. R \u00a8ummer, and T. Wahl. Beyond Quanti.er-Free Interpolation \nin Extensions of Presburger Arithmetic. In VMCAI, volume 6538 of LNCS, pages 88 102. Springer, 2011. \n[10] R. Bruttomesso, S. Ghilardi, and S. Ranise. Rewriting-based quanti.er-free interpolation for a theory \nof arrays. In RTA, volume 10 of LIPIcs, pages 171 186, 2011. [11] R. Bruttomesso, S. Ghilardi, and S. \nRanise. From strong amalgama\u00adbility to modularity of quanti.er-free interpolation. In IJCAR, volume 7364 \nof LNCS, pages 118 133. Springer, 2012. [12] P. Cousot, R. Cousot, and L. Mauborgne. The reduced product \nof abstract domains and the combination of decision procedures. In FOSSACS, volume 6604 of LNCS, pages \n456 472. Springer, 2011. [13] W. Craig. Three uses of the Herbrand-Gentzen theorem in relating model \ntheory and proof theory. The Journal of Symbolic Logic, 22(3):269 285, 1957. [14] L. de Moura and N. \nBj\u00f8rner. Z3: An ef.cient SMT solver. In TACAS, pages 337 340, 2008. [15] K. Dr \u00a8ager, A. Kupriyanov, \nB. Finkbeiner, and H. Wehrheim. SLAB: A Certifying Model Checker for In.nite-State Concurrent Systems. \nIn TACAS, volume 6015 of LNCS, pages 271 274. Springer, 2010. [16] V. D Silva, D. Kroening, M. Purandare, \nand G. Weissenbacher. Inter\u00adpolant strength. In VMCAI, volume 5944 of LNCS, pages 129 145. Springer, \n2010. [17] E. Ermis, M. Sch \u00a8af, and T. Wies. Error invariants. In FM, volume 7436 of LNCS, pages 187 \n201. Springer, 2012. [18] J.-C. Filli atre and C. March \u00b4e. The Why/Krakatoa/Caduceus Platform for Deductive \nProgram Veri.cation. In CAV, volume 4590 of LNCS, pages 173 177. Springer, 2007. [19] A. Fuchs, A. Goel, \nJ. Grundy, S. Krstic, and C. Tinelli. Ground interpolation for the theory of equality. In TACAS, volume \n5505 of LNCS, pages 413 427. Springer, 2009. [20] Y. Ge and L. M. de Moura. Complete instantiation for \nquanti.ed formulas in satis.abiliby modulo theories. In CAV, volume 5643 of LNCS, pages 306 320. Springer, \n2009. [21] A. Goel, S. Krstic, and C. Tinelli. Ground interpolation for combined theories. In CADE, volume \n5663 of Lecture Notes in Computer Science, pages 183 198. Springer, 2009. [22] A. Griggio. A Practical \nApproach to Satis.ability Modulo Linear Integer Arithmetic. JSAT, 8:1 27, January 2012. [23] A. Griggio, \nT. T. H. Le, and R. Sebastiani. Ef.cient interpolant generation in satis.ability modulo linear integer \narithmetic. In TACAS, volume 6605 of LNCS, pages 143 157. Springer, 2011. [24] M. Heizmann, J. Hoenicke, \nand A. Podelski. Nested interpolants. In POPL, pages 471 482. ACM, 2010. [25] T. A. Henzinger, R. Jhala, \nR. Majumdar, and K. L. McMillan. Ab\u00adstractions from proofs. In 31st POPL, 2004. [26] K. Hoder, L. Kov \n\u00b4acs, and A. Voronkov. Interpolation and symbol elimination in vampire. In IJCAR, volume 6173 of LNCS, \npages 188 195. Springer, 2010. [27] K. Hoder, L. Kov \u00b4acs, and A. Voronkov. Playing in the grey area \nof proofs. In POPL, pages 259 272. ACM, 2012. [28] C. Ihlemann, S. Jacobs, and V. Sofronie-Stokkermans. \nOn local reasoning in veri.cation. In TACAS, pages 265 281, 2008. [29] S. Jacobs. Incremental instance \ngeneration in local reasoning. In CAV, volume 5643 of LNCS, pages 368 382. Springer, 2009. [30] R. Jhala \nand K. L. McMillan. A practical and complete approach to predicate re.nement. In TACAS, volume 3920 of \nLNCS, pages 459 473. Springer, 2006. [31] R. Jhala and K. L. McMillan. Interpolant-based transition relation \napproximation. Logical Methods in Computer Science, 3(4), 2007. [32] B. J \u00b4onsson. Universal relational \nsystems. Math. Scand., 4:193 208, 1956. [33] D. Kapur, R. Majumdar, and C. G. Zarba. Interpolation for \ndata structures. In SIGSOFT FSE, pages 105 116. ACM, 2006. [34] D. Kroening and G. Weissenbacher. Interpolation-Based \nSoftware Veri.cation with Wolverine. In CAV, volume 6806 of LNCS, pages 573 578. Springer, 2011. [35] \nS. K. Lahiri and S. Qadeer. Back to the future: revisiting precise program veri.cation using SMT solvers. \nIn POPL, pages 171 182. ACM, 2008. [36] J. McCarthy. Towards a mathematical science of computation. In \nIFIP Congress, pages 21 28, 1962. [37] K. L. McMillan. Interpolation and SAT-Based Model Checking. In \nCAV, volume 2725 of LNCS, pages 1 13. Springer, 2003. [38] K. L. McMillan. An interpolating theorem prover. \nTheor. Comput. Sci., 345(1):101 121, 2005. [39] K. L. McMillan. Lazy abstraction with interpolants. In \nCAV, volume 4144 of LNCS, pages 123 136. Springer, 2006. [40] K. L. McMillan. Quanti.ed invariant generation \nusing an interpolating saturation prover. In TACAS, volume 4963 of LNCS, pages 413 427. Springer, 2008. \n[41] G. Nelson. Verifying reachability invariants of linked structures. In POPL, pages 38 47. ACM, 1983. \n[42] A. Podelski and T. Wies. Counterexample-guided focus. In POPL, pages 249 260. ACM, 2010. [43] T. \nW. Reps, S. Sagiv, and G. Yorsh. Symbolic implementation of the best transformer. In VMCAI, volume 2937 \nof LNCS, pages 252 266. Springer, 2004. [44] A. Rybalchenko and V. Sofronie-Stokkermans. Constraint solving \nfor interpolation. In VMCAI, volume 4349 of LNCS, pages 346 362. Springer, 2007. [45] M. Sagiv, T. Reps, \nand R. Wilhelm. Parametric shape analysis via 3-valued logic. ACM TOPLAS, 24(3):217 298, 2002. [46] V. \nSofronie-Stokkermans. Hierarchic reasoning in local theory exten\u00adsions. In CADE, pages 219 234, 2005. \n[47] V. Sofronie-Stokkermans. Interpolation in local theory extensions. Logical Methods in Computer Science, \n4(4), 2008. [48] N. Totla and T. Wies. Complete instantiation-based interpolation. Technical Report TR2012-950, \nNew York University, 2012. [49] T. Wies, M. Mu niz, and V. Kuncak. An ef.cient decision procedure for \nimperative tree data structures. In CADE, volume 6803 of LNCS, pages 476 491. Springer, 2011. [50] G. \nYorsh and M. Musuvathi. A combination method for generating interpolants. In CADE, volume 3632 of LNCS, \npages 353 368, 2005.   \n\t\t\t", "proc_id": "2429069", "abstract": "<p>Craig interpolation has been a valuable tool for formal methods with interesting applications in program analysis and verification. Modern SMT solvers implement interpolation procedures for the theories that are most commonly used in these applications. However, many application-specific theories remain unsupported, which limits the class of problems to which interpolation-based techniques apply. In this paper, we present a generic framework to build new interpolation procedures via reduction to existing interpolation procedures. We consider the case where an application-specific theory can be formalized as an extension of a base theory with additional symbols and axioms. Our technique uses finite instantiation of the extension axioms to reduce an interpolation problem in the theory extension to one in the base theory. We identify a model-theoretic criterion that allows us to detect the cases where our technique is complete. We discuss specific theories that are relevant in program verification and that satisfy this criterion. In particular, we obtain complete interpolation procedures for theories of arrays and linked lists. The latter is the first complete interpolation procedure for a theory that supports reasoning about complex shape properties of heap-allocated data structures. We have implemented this procedure in a prototype on top of existing SMT solvers and used it to automatically infer loop invariants of list-manipulating programs.</p>", "authors": [{"name": "Nishant Totla", "author_profile_id": "81549167756", "affiliation": "Indian Institute of Technology Bombay, Bombay, India", "person_id": "P3978053", "email_address": "nishant.totla@gmail.com", "orcid_id": ""}, {"name": "Thomas Wies", "author_profile_id": "81384598627", "affiliation": "New York University, New York, NY, USA", "person_id": "P3978054", "email_address": "wies@cs.nyu.edu", "orcid_id": ""}], "doi_number": "10.1145/2429069.2429132", "year": "2013", "article_id": "2429132", "conference": "POPL", "title": "Complete instantiation-based interpolation", "url": "http://dl.acm.org/citation.cfm?id=2429132"}