{"article_publication_date": "01-01-2001", "fulltext": "\n Programming language methods in computer security John C. Mitchell Department of Computer Science Stanford \nUniversity http://www.sta nford.edu/'jcm Abstract This invited talk will give a personal view of the \nfield of computer security and summarize some ways that methods from the study of programming language \nprinciples can be applied to problems in computer security. Some background information is provided here \nin this short document.  Security and correctness Computer security is concerned with detection and \npreven- tion of unauthorized use of computational resources. Com-puter security problems range from detecting \npotentially malicious network traffic to password systems and other ac- cess control mechanisms to mechanisms \ndesigned to prevent installed code from corrupting a computing environment. There is some overlap between \ncomputer security and methods for ensuring software correctness. For example, web browser code that contains \na Trojan (functionality to allow unauthorized access) is simply an incorrect browser implementation: \nthe specification of a web browser does not include functionality for providing remote access to the \ncom- puter on which the browser is installed. Therefore, an inse- cure browser could be considered an \nincorrect browser. For this reason, many basic security concerns can be addressed using methods designed \nfor software assurance. At the same time, however, security properties tend to have a different flavor \nfrom other correctness properties. One qualitative difference between security properties and other correctness \nproperties lies in way that system in- put is considered. Although the following characterizations are \napproximate and must be taken with a grain of salt, the difference may be illustrated as follows: Correctness: \nA software system is correct if correct system input results in correct system output. To give a simple \nexample, the specification for a function f : A ~ B generally says that for all inputs x E A, the output \nf(x) E B has a certain property. Permission to make digital or hard copies of all or pert of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor profit or commercial advan- tage and that copies beer this notice and the full citation on the first \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspecific permission and/or a fee. POPL '01 1/01 London, UK &#38;#169; 2001 ACM ISBN 1-58113-336-710110001 \n.,. $5.00 Security: A software system is secure if arbitrary input does not have undesired consequences, \nsuch as release of private information or corruption of the state of the system. To continue the function \nexample above, the implementation of a function .f : A ~ B is insecure if the computation of f(y), for \nsome y ~ A, causes overflow of some buffer allocated on the run-time stack and therefore results in some \nsystem call not related to the correct calculation of function f. In general terms, computer security \nis concerned with behavior in arbitrary environments while correctness is often stated using some restrictions \non the environment. Security analysis In general, it is only possible to prove that a system or mech- \nanism is secure in a relative sense. More specifically, a proof of security involves some model of the \nbehavior of the system in question and, at least as importantly, some model of the set of actions available \nto an attacker. This reliance on mod- els leads to one fundamental connection between program- ming language \nmethods and computer security: the kinds of programming language and system models often studied at POPL \ncan be used to characterize the behavior of a system for the purpose of security analysis. A promising \ndirection for POPL-style research is to characterize the actions avail- able to an attacker within these \nmodels, and devise methods for reasoning about the possible effects of an attacker on a system. One computer \nsecurity topic that has received consider- able attention in recent years is security analysis of net- \nwork protocols. A number of methods have been de-veloped, ranging from BAN logic and related approaches \n[BAN89, GNY90] to finite-state analysis [Ros95, MMS97] and proof methods based on higher-order logic \n[Pau97]. Most approaches in current use are based on enumeration or reasoning about a set of protocol \ntraces, each trace obtained by combining protocol actions with actions of a malicious in- truder. There \nare several reasons why protocol analysis has at- tracted so much attention. One is the importance of \nthe problem. To give one example, the Secure Sockets Layer (SSL) protocol (analyzed in [MSS9S]) is used \nin a huge num- ber of Internet purchases every minute. The purpose of the protocol is to establish a \nsecret key, shared between client and server, that can be used to send a credit card number or other \ndata under encryption. If this protocol were sus- ceptible to practical attack, millions of Internet \ncustomers could have their credit card numbers stolen. Another rea- son that protocol analysis has been \npopular in recent years is the relative tractability of the problem. Security protocols are typically \nsimple distributed programs that run for three to seven communication steps and halt. Relative to other \nsoftware systems, they are therefore very simple programs. Moreover, there is a standard idealized intruder \nmodel, com- monly referred to as the \"Dolev-Yao model,\" which appear to have developed from positions \ntaken by Needham and Schroeder [NS78] and a model presented by Dolev and Yao [DY83]. In this model, the \nattacker can intercept messages sent on the network but cannot interfere with local proto- col calculations \ncarried out by parties to the protocol. The attacker may block network messages, decompose them into \nparts, remember all of the parts, decrypt parts if the key is known, and send messages composed from \nprevious message parts to protocol participants. More generally, there are many ways that methods from \nprogramming language analysis have been used in security protocol analysis: Use of process calculi and \nrelated formalisms to repre- sent protocols in a form amenable to analysis.  Model checking techniques \nto find flaws in protocols.  Theorem proving methods to prove correctness of pro- tocols.  Use of concepts \nfrom logics of programs to develop spe- cialized logics for proving protocol correctness.  In addition \nto protocol analysis, here are some other com- puter security topics can be addressed using techniques \nde- veloped or used in POPL-style research: Information flow and noninterference: the study of how information \nmay be transferred from one user (or process) to another in a multi-user system and how such transfer \nof information can be prevented.  System security flaws. An astonishing number of com- puter security \nadvisories stem from buffer-overflow er- rors in system programs. Such flaws are amenable to source-code \nstatic analysis methods and dynamic program-monitoring methods.  Mobile code security: When code is \ntransferred and ex- ecuted dynamically, program analysis methods (such as Java bytecode verification) \ncan be used to examine code before it is installed. Proof-carrying code [NL96] is a popular approach \nthat has received significant at- tention at POPL and related conferences.  There are many additional \ntopics represented in current se- curity conferences such the IEEE Symposium on Security and Privacy \nand the IEEE Computer Security Foundations Workshop, both listed at http://www.ieee-security.org/, the \nACM Conference on Computer and Communications Secu- rity, listed at http://www.acrn.org/sigsac/, and \nthe Crypto and Eurocrypt conferences organized by the International Association for Cryptologic Research, \nwww.iacr.org. Compositionality and observational congruence One particular folk belief that may interest \nthe POPL au-dience is the belief in the security community that security properties do not compose. A \ngeneral problem with com-position is that when two mechanisms are combined, one may inadvertently reveal \ninformation related to the security of the other. Here is a simplified example to illustrate the point. \n Specification: Any party Alice must be able to send any message m to any other party Bob in such a way \nthat no passive eavesdropper listening on the network can determine the identity of message m.  Implementation: \nWe assume a public key infrastruc- ture so that Alice knows the public encryption key KB of Bob, Bob \nknows Alice's public key KA, and the cor- responding decryption keys KB -1 and KA -1 are ini- tially \nknown only to Bob and Alice, respectively.  To send message m, Alice computes the encryption ~m~gS of \nmessage m with Bob's public key and sends two values to Bob: the encrypted message ~m~KS and Alice's \nprivate decryption key KA -1. Assuming that a good encryption function is used, the implementation above \nmeets its specification. A passive eavesdropper will obtain two values from the network: the encryption \nof m and a private decryption key not related to the encryption of m. Since the private decryption key \nis not related to the encryption of m, the eavesdropper cannot learn the message m. Consider what happens \nif we compose the secure proto- col above with the same protocol used in reverse to send a message from \nBob to Alice. Using the notation commonly found in the literature, here is the resulting protocol: Alice \n~ Bob : ~m~KB,KA -1 Bob ---. Alice : ~m'~KA,KB -1 The symbols mean that Alice sends the first pair of \nvalues to Bob and Bob sends the second pair of values to Alice. This protocol clearly does not satisfy \nthe composition of the two specifications: after seeing both messages, a passive eavesdropper can learn \nboth messages, m and m I, since each transmission contains the decryption key needed to decrypt the message \ncontained in the other transmission. A promising approach for developing compositional se- curity properties \nis to use observational equivalence, a stan- dard and well-studied relation in programming language and \nconcurrency theory. For those not familiar with the con-cept, two programs or systems, P and Q, are observationally \nequivalent if they give rise to the same observable behavior in all contexts. In symbols, P '~ Q iff \nfor all contexts C[] we have C[P] = C[Q] where C[P] is the result of placing P in context C[ ] and = \nis some basic equality defined using some primitive form of ob- servations, such as printing a number \nor sending a boolean value on some predetermined channel. The important fact about observational equivalence \nis that it is provably a con- gruence relation. Therefore, if we specify security proper- ties as equivalences \nbetween systems and their specifications, compositionality will follow. To the best of my knowledge, \nthe potential for using observational equivalence in security specifications was first realized by Abadi \nand Gordon and described in their paper on the Spi-calculus lAG99]. The idea is very general and seems \npromising for a variety of formalisms, including some simpler that Spi-calculus and some that are more \ncomplex (e.g., [LMMS98] and related papers). References and further information Copies of the slides \nfor this talk and additional references will be available at the web site listed below the author's address \nabove. References [AG99] M. Abadi and A. Gordon. A calculus for crypto- graphic protocols: the spi calculus. \nInformation and Computation, 148(1):1-70, 1999. [BAN89] M. Burrows, M. Abadi, and It. Needham. A logic \nof authentication. Proceedings of the Royal Society, Series A, 426(1871):233-271, 1989. Also appeared \nas SRC Research Report 39 and, in a shortened form, in ACM Transactions on Computer Systems 8, 1 (Febru- \nary 1990), 18-36. [DY83] D. Dolev and A. Yao. On the security of public-key protocols. IEEE Transactions \non Information The- ory, 2(29), 1983. [GNY90] L. Gong, R. Needham, and R. Yahalom. Reasoning About Belief \nin Cryptographic Protocols. In Deborah Cooper and Teresa Lunt, editors, Proceedings 1990 IEEE Symposium \non Research in Security and Pri- vacy, pages 234-248. IEEE Computer Society, 1990. [LMMS98] P.D. Lincoln, \nJ.C. Mitchell, M. Mitchell, and A. Sce- drov. A probabilistic poly-time framework for. proto- col analysis. \nIn ACM Conf. Computer and Commu- nication Security, 1998. [MMS97] J.C. Mitchell, M. Mitchell, and U. \nStern. Automated analysis of cryptographic protocols using Murk. In Proc. IEEE Syrup. Security and Privacy, \npages 141- 151, 1997. [MSS98] John C. Mitchell, VitMy Shmatikov, and Ulrich Stern. Finite-state analysis \nof SSL 3.0. In Proceedings of the 7th USENIX Security Symposium, pages 201-216, San Antonio, TX, 1998. \n[NL96] G. Necula and P. Lee. Safe kernel extensions without run-time checking. In Second Symposium on \nOperat- ing Systems Design and Implementation, 1996. [NS78] R.M. Needham and M.D. Schroeder. Using encryp- \ntion for authentication in large networks of comput- ers. Communications of the ACM, 21(12):993-999, \n1978. [Pau97] L.C. Paulson. Proving properties of security proto- cols by induction. In lOth IEEE Computer \nSecurity Foundations Workshop, pages 70-83, 1997. [Ros95] A.W. Roscoe. Modelling and verifying key-exchange \nprotocols using CSP and FDR. In 8th IEEE Com- puter Security Foundations Workshop, pages 98-107. IEEE \nComputer Soc Press, 1995.   \n\t\t\t", "proc_id": "360204", "abstract": "This invited talk will give a personal view of the field of computer security and summarize some ways that methods from the study of programming language principles can be applied to problems in computer security. Some background information is provided here in this short document.", "authors": [{"name": "John C. Mitchell", "author_profile_id": "81338490160", "affiliation": "Department of Computer Science, Stanford University", "person_id": "PP43125642", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/360204.360205", "year": "2001", "article_id": "360205", "conference": "POPL", "title": "Programming language methods in computer security", "url": "http://dl.acm.org/citation.cfm?id=360205"}