{"article_publication_date": "01-01-2001", "fulltext": "\n Secure Safe Ambients Michele Bugliesi Giuseppe Castagna Universitd \"Ca' Foscari\", Venice C.N.R.S, Ecole \nNormale Sup~rieure, Paris michele@ dsi.unive.it Giuseppe.Castagna@ens.fr Abstract. Secure Safe Ambients \n(SSA ) are a typed variant of Safe Ambients [9], whose type system allows behavioral invariants of ambients \nto be expressed and verified. The most significant aspect of the type system is its ability to capture \nboth explicit and implicit process and ambient behavior: process types account not only for immediate \nbehavior, but also for the behavior resulting from ca- pabilities a process acquires during its evolution \nin a given con- text. Based on that, the type system provides for static detection of security attacks \nsuch as Trojan Horses and other combinations of malicious agents. We study the type system of SSA, define \nalgorithms for type check- ing and type reconstruction, define powerful languages for express- ing security \nproperties, and study a distributed version of SSA and its type system. For the latter, we show that \ndistributed type check- ing ensures security even in ill-typed contexts, and discuss how it relates to \nthe security architecture of the Java Virtual Machine. 1. INTRODUCTION Mobile Ambients [5] are named \nagents or locations that enclose collections of running processes, possibly including nested sub- arnbients. \nSafe Ambients [9] are a variant of Mobile Ambients. The two calculi differ in the underlying notion of \ninteraction: in Mobile Ambients, interaction is \"one-sided\", in that one of the two partners in a move \nor open action simply undergoes the action. In Safe Ambients, instead, the reduction relation requires \nactions to synchronize with corresponding co-actions. To exemplify, consider the ambients a and b described \nbelow: Mobile Ambients a[openban c] I b[in a.in d]. The brackets [... ] represent ambient boundaries, \n\" I \"denotes par- allel composition, and \".\" enforces sequential execution. Given the above configuration, \nthe ambient b may enter a, by exercising the capability in a, and reduce to a[open b.in c I b[in d]]. \nThen a may dissolve the boundary provided by b by exercising open b, and reduce to a[in e I in d]. Neither \nof the two reductions is legal in Safe Ambients. To obtain Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for profit or commercial advan-tage and that copies bear this notice and \nthe full citation on the first page. To copy otherwise, to republish, to po~ on servers or to redistribute \nto lists, requires prior specific permission and/or a fee. POPL'01 1101 London, UK &#38;#169; 2001 ACM \nISBN 1-58113-336-7/01/0001 ...$5.00 the behavior we just described, the two ambients a and b should be \nwritten as follows: Safe Ambients ale a.open b.in e][ b[in a.'Sffd'~ b.in d]. Now the move of b into \na arises as the result of a mutual agreement between the two partners: b exercising the capability in \na, and a exercising the co-capability ~ a. The resulting configuration, a[open b.in c [ b[o~ b.in d]], \nreduces to a[in c [ in d], again as the result of the synchronization between open b and o~ b. Secure \nSafe Ambients (SSA) are a typed variant of Safe Ambients whose type system is so defined as to allow \nbehavioral invariants of ambients to be expressed and verified. The most significant aspect of the type \nsystem is its ability to trace both explicit and implicit process behavior and ambient mobility: the \ntype assigned to a pro- cess accounts not only for the behavior resulting from the capabil- ities that \nprocess possesses in isolation, but also from the capabil- ities the process may acquire by interacting \nwith the surrounding environment. This degree of accuracy is essential for a sound ver- ification of \nsecurity policies, as implicit (i.e., acquired) mobility is at the core of a number of security attacks \nsuch as Trojan Horses or other combinations of malicious agents. EXAMPLE 1.1. Consider again the two \n(safe) ambients a and b in- troduced above, now running in parallel with a third ambient c as in the \nfollowing configuration, where P and Q are arbitrary pro- cesses: a[i~ a.open b.in c] l b[in a.o-p-~ \nb.in d]  I c[i~e.eld[igd.Q]] For the purpose of the example, assume that d contains confidential data, \nwhich should be made available to ambients running within c (which may enter, as signaled by the co-capability \n~ d), but not to ambients entering e. Given this security policy, the question is whether e should let \na in without fear that a may access the confidential data in d. If we only look at explicit mobility, \nthat is at the capabilities available for a, then the move of a into c seems safe, as a does not make \nany direct attempt to move into d. However, a can be used as a Trojan Horse for b: a can let b in, then \nenter e and, once inside c, open b to gain access to d. [] EXAMPLE 1.2. A different way that a may attack \nc is by letting b out after having entered c. The two ambients a and b would then be written as shown \nbelow: a[T~a.ine.o~a]l b[ina.ou~a.ind] I c[~c.PId[~d.Q]] Again, if we only look at the capabilities available \nfor a, we are  above are detected by the type system of [4]. A further difference is the presence in \n[4] of a novel (and quite interesting) construct for dynamic group creation, a primitive that is not \navailable for our version of mobile ambients. While we believe that this construct could be included \nin our type system, it would certainly compli- cate type reconstruction. Besides our specific interests \nin security issues, that are somewhat disregarded in [4], type reconstruction and the distributed version \nof the system (neither of which is dis- cussed in [4]) represent further important differences between \nthe two papers. Further related work includes E and H.R. Nielson's framework for control and data flow \nanalysis for Mobile Ambients [12, 13]: in fact, our type reconstruction algorithm may be seen as an abstract \ncontrol flow analysis where ambient behavior is abstracted upon in terms of domain behavior. Plan of \nthe paper. Section 2 reviews the syntax and reduction semantics of (Secure) Safe Ambients. Section 3 \ndefines the type system, while Section 4 focuses on type soundness and safety. Sec- tion 5 introduces \nthe algorithmic systems, and proves them sound and complete. Section 6 shows how to define a security \nlayer on top of the type system, and how the type system may be used enforce and verify security properties. \nIn Section 7 we define a distributed version of SSA, and discuss how it relates to the security architec- \nture of the JVM. A short section concludes the presentation. Proofs of the main results are given in \na separate appendix. 2. THE LANGUAGE The terms of our language are those of Safe Ambients with the only \ndifference that the types of (ambient) names are (protection) Do- mains. These are type-level constants \nused to identify ambients that satisfy the same behavioral invariants and share common se- curity policies: \ninstead of associating such invariants and policies to each ambient we rather define them for domains, \nand then group ambients in domains. Processes  P ::= 0 I .m I (.a:D)e I Pip I <m] lip Capabilities \n ::= ina lea I ou a [o a I opena [ opena Besides being a design choice, the introduction of domains \nis mo- tivated by technical reasons. An alternative, and more informative, notion of ambient type could \nbe defined by associating each am- bient with the set of term-level capabilities that ambient may ex- \nercise. The resulting type system would certainly provide a more accurate characterization of process \nand ambient behavior, but it would also incur into a number of technical problems arising from the dependency \nof these types on terms 1. On the other hand, our use of protection domains is well motivated and justified \nby what is nowadays common practice for languages and systems supporting code mobility [8]. Reduction \ni One problem with that solution is that types are not preserved by structural congru- ence. For instance, \nthe term (t.,a:A) (vb: B) a [in b] ] b [~n b] would not be typeable, as the type A should contain all \nthe capabilities a can exercise: yet .,4 cannot contain in b, as b is in the scope of a nested binder. \nIf we exchange the position of the two binders, as in (tsb:B)(L,a:A)a[inb] [ b[~b] the term becomes typeable. \nThe use of domains resolves the problem: both terms are well-typed when A and B are domains (thus type \nconstants rather than sets of term-level capabilities). The reduction relation for SSA derives from the \none defined for Safe Ambients. (in) b[\u00b1n a.P I Q] I ale a.R I S] ~ a[R I S I b[P [ Q]] (out) a[ b[outa.P \n[ Q] I o~a.R I 51 ~ b[P I Q] I a[n I s] (open) open a.P I a[o~ a.Q I R] -~ P I Q I R (context) P--~Q \n~ #[P]-*#[Q] (struct) 2 P' = p.-~Q =~ p'-.~Q where @[] denotes an evaluation context defined as follows: \nEvaluation Contexts g[]::=[] I (~,a:D)g[] I PI g[] I gg[] I P I a[~[]] and =-- is the standard structural \nequivalence relation for ambients, that is the least congruence relation that is a commutative monoid \nfor 0 and [ and closed under the following rules: !P _=!P I P (va:D)0 = 0 (ua:A)(vb:B)P =_=_ (ub:B)(ua:A)P \nfor a # b (va:D)(P I Q) = P l(ua:D)Q fora efn(P) (ua:D)b[P] = b[(ua:D)P] for a ~ b 3. TYPE SYSTEM Ambient \ndomains, ranged over by A, B, C, and D, provide the type-level unit of abstraction: in the type system, \nthe effect of ex- ercising a capability is observed on domains rather than ambients. We define process \ntypes in terms of type-level capabilities as fol- lows: Type Capabilities M ::= in D [ ~ D [ out D [ \no~ D I open D [ o~ D Process 7)/pes P ::= (L,M,N) (L,M,N E 2 M) Notation. The following conventions are \nused throughout. We often write cap D (resp. cap a) to denote an arbitrary type-level (resp. term-level) \ncapability. If P = (L, M, N), we write P-r for L, P= for M, and P* for N, and often abuse this notation \nusing p'r, p= and P* both as projections of the type P, and directly as sets, as in P : (per p= p*). \nAlso, we use set-theoretic notation for various operations on process types: if P and Q are process types \nP c Q denotes component-wise inclusion. Similarly P U Q denotes component-wise union. Given a set M of \ntype capabilities and a process type P, we define P U* M (respectively, P U = M and P U t M) as the process \ntype resulting from the union of M and p,t (respectively, P= and pt): p U* M ~ (P-r, P=, P'~ U M),  \n PU=M ~ (P-r, P= UM, P*) and PU-rM &#38; (Pl\" UM, P=, P*). Finally, given a type-level capability M, \na type-level co-capability M, and two sets of type capabilities L and M, we write M E sync(L, M) as a \nshorthand for M E L and M E M. Process types describe the capabilities that processes may exercise, and \ntrace the nesting level at which the effect of exercising a ca- pability may be observed. The three components \nof process types identify those levels: pt describes the effects that can be observed at the level of \nthe ambient enclosing P, P= describes the capa- bilities observed at the level of P, and finally, P* \nrepresents the capabilities that are exercised within P, whenever P is an ambient 2We use this definition \nof structm'al reduction instead of the more standard definition P' ~P ~ Q~Q~ =~ P' ~ Q' to ease the proof \nof type safety (see Section 4). of the form alP']. To exemplify, given a : A: e in a.P : P ~ in A E \nPt, since the effect of exercising in a is observed at the level of the ambient (if any) enclosing P \nb[in a.P] : P ~ in A 6 P=, since now it is b[in a.P] that exercises in a open a.P : P :=~ open A 6 P=, \nsince open a is exercised (and its effect observed) at the level of the processes running in parallel \nwith open a.P b[open a.P] : P ~ open A E P~, since open a is exercised within b.  3.1 Environments \nand Type Rules We define two classes of environments, namely 7~/pe Environments, denoted by E, and Domain \nEnvironments, denoted by II: ~pe Envs E : Ambient Names ~ Ambient Domains 7~ype Envs II : Ambient Domains \n~ Process 7)~pes Type environments associate with each ambient name the domain it belongs to, while \ndomain environments associate with each domain the type that is shared by all its ambients. Thus, while \ntype environ- ments partition ambients into domains, domain environments con- vey information about potential \ninteractions among domains, and enforce behavioral invariants for processes enclosed in ambients in each \ndomain. Definition 3.1 (Closure and Boundeduess). Let H be a domain environment, P a process type, and \nD and H be ambient domains. We define the following notation: H t- P closed open H 6 sync(P =, II(H) \n=) ~ II(H) C_ P II ~ D bounds P __a p'r C II(D) = A P= C II(D)* A (~ D 6 II(D) = ~ P C II(D))  H h \nD closed .~- in H 6 sync(II(D) =, II(H) =) ~ II I-- H bounds [I(D) out H 6 sync(H(D) =, H(H)*) ~ H(D) \nC_ H(H) [] The closure condition on process types formalizes the intuition that processes may exercise \nall the capabilities of the ambients they may open. The boundedness of P by D ensures that the process \ntype II(D) provides a sound approximation of the type P of any process enclosed in (ambients of) domain \nD. This is expressed by the first two inclusions, which reflect the different nesting level at which \none may observe the behavior of ambients and their en- closed processes. The last inclusion handles the \ncase of domains whose ambients may be opened: in that case ambient boundaries are dissolved, and consequently \nthe behavior of the processes un- leashed as a result of the open may be observed at the nesting level \nof the ambients where they were originally enclosed. Finally, the closure condition for domains enforces \nthe previous invariants in the presence of mobility: the behavior of an ambient a of domain D must account \nfor the behavior of ambients entering a, as well as for the behavior of ambients exiting a (since a lets \nthese ambients out, then it is virtually responsible for their behavior). Definition 3.2 (Coherence). \nLet II be a domain environment. We define the notation IIh o (read II is coherent) as follows: H I-- \no &#38;fn(H) C_ Oom(H) A  VD e Dom(II). (II l- D closed A IIh H(D) closed) where, with an abuse of notation, \nwe use fn(H) to denote the set {D I cap D 6 ling(H)}. [] The typing rules are given in Figure 1. They \nderive judgments of the form II, E F- P:P, where E is a type environment, H is a domain environment, \nand ling(E) C_ Dom(II) (that is, the image of E is contained in the domain of H). The rules (DEAD), (PAR), \n(REPL), and (RESTR) are standard. The typing of prefixes (in the (ACTION) rules) is motivated by the \nob- servations we made earlier: the effect of exercising the capabilities in a, out a, i'-~ a and open \na may be observed at the level of the enclosing ambient. Dually, open a, and out a may be observed at \nthe level of the continuation process. As for (AtvIB), the rule stipulates that an ambient alP] has the \ntype that II associates with the domain D of a, provided that D bounds the type of P in II. The (AMB) \nrule is technically interesting, as, unlike its companion rule in previous type systems for Mobile (and \nSafe) Ambients, it establishes a precise relationship between the type of an ambient and the process \nrunning inside it. This rela- tionship, which is essential for tracing implicit behavior, can be expressed \nin our type system thanks to the three-level structure of our process types. Theorem 3.3 (Subject Reduction). \nIf H, E ~- P : P and P~Q, thenH, EF- Q: P. [] 3.2 Examples We illustrate the behavior of the typing \nrules with the two systems of Exarnples 1.1 and 1.2. Assume E _= a:A,b:B, c:C,d:D, and consider the attack \nale a.open b.in el [ b[in a.o~ b.in all. Let Pb be the type of the process enclosed in b: it is easy \nto ver- ify that {o~ B, in D} C Pb~. From H h B bounds Pb, one has o~ B 6 II(B) =, and hence in D 6 II(B) \nt. Let now P, be the type of the process enclosed in a. Since open B E sync(P~, II(B)=), then a consequence \nof the closure of Pa is that II(B) t _C Pat C II(A) = (the last inclusion holds because 17 b A bounds \nOn). Hence in D E H(A) = and the attack is detected. A similar analysis applies to the attack ale a.in \ne.o~ a] I b[in a.out a.in d]. Here in D q II(A) = results from oul; A E sync(II(B)=, II(A)*), which \nimplies II(B) C II(A) by closure. 4. TYPE SAFETY The operational significance of the type system is \nestablished by showing that process types provide a safe approximation of process behavior. In that direction, \nwe introduce the relation P ~ a n that defines the behavior of a process P in terms of the capabilities \nthat P may exercise (at nesting level r/6 {~, =, $}) while evolving in a context. Then we connect the \ntype system with this notion of process behavior by means of a safety result stating that, given a well-typed \nprocess P in a well-typed context, for every c~ such that P ~ c~ n, the type capability corresponding \nto c~ is traced by the type of P: in other words, no action goes untraced by the type system. Below, \nwe focus on a simplified case of type safety, one that as- sumes that processes are \"normalized\" to the \nform (u~:/9)P where 225 (TYPE PROC) (ENV) (NAME) lil-~ fn(P) CDom(II) IIl-Pclosed lifo Img(E) C_Dom(li) \nli, E~o aEDom(E) li I- P II, E l- o li, E I\"- a : E(a) (DEAD) (PAR) (REPL) II, EF-o II, E I-- P : P \nII, EFQ: P li, EI- P : P II, E I-0 : (O,O,O) H, Et- PIQ: P II, EHP : P (ACTION t ) (ACTION = ) lik-P:P \nli, Ek-a:D capDEP* II, EI-P:P li, Ek-a:D capDEP = cap E {in, ~, oat, o~ } cap E {5\"~, open }H, E I- cap \na.P : P li, E I- cap a.P : P (RESTR) (AMB) li, E,a:Dk-P:P aCDom(E) li, Ek-P:P li, Ek-a:D liI--DboundsP \n li, E I-- (va:D)P: P li, E I- a[P]: II(D) (SUBSUMPTION) lli, Et- P: P li t'- Q PC_Q H,E~P:Q Figure 1: \nTyping Rules P contains no restriction v. This assumption simplifies the state- our assumption that processes \nare in \"normal\" form, structural con- ment and the proof of the type safety theorem: in Appendix D we \ngruence is extended to tagged processes by simply adding the fol- show how the result can be generalized \nto arbitrary processes. lowing additional clauses3: S0 ~ 0 fi(PI Q) -= ~PI ~Q ~ !P-=!~P We start by introducing \na relation of \"immediate exhibition\", noted P $ cz'7: the relation is defined in Figure 2 by induction \non the Second, we define the reduction rules for all possible cases that structure of the process P. \nNext we define a tagging mech- result from whether the processes involved in a reduction step are anism \nfor processes, by a technique similar to the one in [14]. tagged or not. To ease the definition, we indicate \nwith l~ \u00b0 a possibly Given a process P, we consider its syntax tree and tag some of absent tag, and with \n1ti the i-th occurrence of the tag ~. With this its nodes with the symbol ~. So for example, if P is \nthe process notation, the tagged version of reduction is defined by the rules in P1 ] a[P2 I (vb:B)Pa] \nthen, say, P1 I ~a[P2 I (vb:B)~Ps] denotes Figure 3. the process P in which we tagged the ambient a and \nthe subprocess P3 occurring therein. Now we can give a precise definition of the residuals of a process \nevolving in a context: intuitively these are all the tagged processes Having tagged a particular occurrence \nof P, we instrument re- that result from tagging the process in question, and reducing it in duction \nso that every process interacting with this occurrence gets the given context. The definition relies \non the following notion of tagged: if the tag is initially applied to an ambient, this technique (restriction-free) \ncontext: allows us to trace the interactions considered in the Chinese Wall Security Policy [1]: in particular \nwe can trace all the processes that 5[] ::= [] I PLY[] I ~[] I e I a[~[]] I c~.~[] \"got in touch\" with \nthat ambient. Tags are propagated based on Definition 4.1 (Residuals). Let (v~:/9)P be a process, with \nP the idea of an ambient as a paint pot: any ambient exiting a tagged containing no restrictions. ambient \nis tagged: 1. An occurrence of P is a path A in the syntax tree of P. We ~a[ b[out a.P [ Q] I o~ a.R \nI S ] ~ ~b[P I Q] I ~a[R I denote with Pa the subprocess of P occurring at A, and with and so is every \nprocess unleashed by opening a tagged ambient: ~ [ ] the context obtained from P by substituting a hole \nfor the subprocess occurring at A. Hence P = cc~ [Pa]. opena.P l ~a[o~a.Q I R ] ~ P I~(QIR). 2. Given \na tagged process P, we denote by IPI the process ob- tained by erasing 4 all tags occurring in P. Following \nthe intuition that a process exercises all the capabilities 3. Let A be an occurrence of an untagged \nprocess P. The set of the processes it opens, we also have: of residuals of A in P is defined as follows: \nllopen a.P I a[bSffd~ a.Q I R] ~ II(P I Q [ R). 3In Appendix D the definition is refined to handle restrictions \nand scope extrusion. 4Technically, tags are annotations on the syntax tree and are not part of the syntax. \nTechnically, the definition is only slightly more complex. First, we Thus the notion of occurrence is \npreserved by tagging/untagging, that is, for every need to extend structural congruence to tagged processes. \nGiven tagged P and occurrence A, IPzx [ = IP[~. oz E (\u00b1na, outa,~a, opena} oz E {open a,o-~a} a.P $ a \n~ a.P ,l, a = P -1- ca p b n P ,1- a* a~b (~,a:D)P $ cap b n a[P] $ a = P Sa n Pi 4a n !P $ a ~ Pl l \nP~ .~ a n (i = 1,2) P.~a = a[P] ,I. a* Figure 2: Exhibiting a capability (in) (out) a[ fl~b[ l~out \na.P I Q] I tl~o~ (open) ~open a.P I a[ fl~o~ (out tag) ~a[ ~?b[ ~iout a PI Q]I ~o~ (open tag) ~open a.P \nI ~a[ ~o~  a.Rl~ ~ o o .obr.o P l~aa[~4RlSI,1 t,2 IQ]] a.R I 8] ~ ~b[ fl~P I Q] I a[lt~R I S] a.QIR] \n~ ~(PI~QIR) a.RIS] ~ ~b[II~PIQ]I~a[~RIS] a.QIR] ~ fl~elfl(QIR) Figure 3: Tag Propagation via Reduction \n(1) P&#38; is a residual of A in P (2) If ~AP[I~Pzx] ~ Q and Qzx' is tagged (that is, QLx, = fiR for \nsome R), then every residual of A' in IQI is also a residual of A in P. []  We can finally generalize \nthe notion of capability exhibition to pro- cess occurrences. Definition 4.2 (Residual Behavior). Let \n(v~:/))P be a process, with P containing no restriction, and A be an occurrence of P. Then, A ~ c~ n \nif and only if there exists a residual R of A in P such that R .1. a T. [] Theorem 4.3 (Type Safety). \nLet (u~:D)P be a process, with P containing no restriction, A be an occurrence of P and let E = E', ~:19 \nfor a type environment E'. Assume that II, E S- P : P' and II, E P PA : P. If A .IJ. (cap a) n, then \ncap E(a) 6 pn. [] To exemplify, consider the ambient a [~ a.open b]. If taken in iso- lation, this ambient \nonly exhibits the capabilities ~ a and open b. If, instead, we take the parallel composition a~ a.open \nb] I b[\u00b1n a.o~b.in c] (1) then the ambient a[... ] also exhibits in e as a result of the interac- tion \nwith the context. In fact, if we start tagging a[... ] in (I) above, the result of tagged reduction is \nas follows: ~a~ a.open b] I b[ia a.o~ ban e]  ~a[open b l b[o~ b.in c]] Now, Theorem 4.3 ensures that \nif we type the process (1), the fact that the residual a[\u00b1n c] of a exhibits in c is traced by the type \nas- sociated to the domain of a. In fact, the result is even stronger, as it ensures that the type system \ntraces the behavior of any process that interacts with the process occurrence of interest. For example, \nif we take the composition ~a[~ a.o~ b] I b[in a.out a.in c], the re- sult of tagged reduction is IRa[] \nI l~b[ in c], and Theorem 4.3 ensures that the type of (the domain of) a traces the type-level capability \ncorresponding to in c, since it is exhibited by the residual b[in c]. 5. ALGORITHMIC SYSTEMS As it is \nusual in the presence of subsumption, the type system given in Figure 1 is not algorithmic: however, \nit is easy to state the type rules so that they form a syntax-directed system. 5.1 Typing Algorithm \nThe algorithmic type system finds the minimal type of a term under a given set of domain assumptions \nII and type assumptions E. The system results from the type system of Figure 1 by erasing the rule of \nsubsurnption, and replacing the (ACTION) and (PAR) rules with the rules in Figure 4: the only subtlety \nis the side condition to the rule (ACTION~), which defines P' as the minimum P' that contains P and is \nclosed in II (i.e. such that II ~-P' is derivable). These roles constitute the core of an algorithm that \ngiven II, E, and P as input, returns the type P as output. Theorem 5.1 (Soundness and completeness). \nIf H, E i-a, P : P, then II, E I-- P : P. Conversely, If II, E I-- P : P, then II, E I--~ P : P' and \nP' C P [] Corollary 5.2 (Minimal typing). II, E ~-d P : min{P [II, E H P: P} if this set is non-empty. \n13 The existenee of minimum types and of an algorithm computing them are interesting and useful properties. \nYet, leaving a program- mer with the task of providing a domain environment II as input to the type checking \nalgorithm is a very strong requirement. Below, we show that this task can be dispensed with, as domain \nenviron- ments can be reconstructed automatically. In principle, providing a coherent II for which the \ntyping algorithm does not fail is straight- forward. Given a process P, let ~ be the set of domain names \noccurring in P, and let E be a type environment that assigns a do- main in ~ to every name in P. Now, \ndenote by W\" the process type whose com~nents contain all the possible type capabilities over ~, and \nlet II ~ be the saturated type environment such that Dom(II) = ~ and II~(D) = W at for all D E Dom(II). \nIt is easy to verify that there always exists a process type P such that Fi~ b- P : P is derivable: to \nsee that, observe that II~(D) pro- vides a sound approximation the behavior of every ambient (and (PAR) \n(ACTION~) II, Et-~cP:P H, EF-~cQ:Q iII, E~-~cP:P E(a)=A II, EI--~P[Q: PuQ II, EI-~ a.P: P U= {~ ' A} \n(ACTION~) II, E~-~t P:P E(a)=A P'&#38;PU ={openA}U[ If(A) ifSffCff A 6 FI(A) = otherwise If,E I-~ open \na.P : pt L (ACTION t) II, EFa. P:P E(a)=A cap E {in, i-n, 0111; , 5~ } II, E F-~ cap a.P : P U t {cap \nA} Figure 4: Algorithmic Typing process) occurring in P (indeed, II sat I- P : psat holds). On the other \nhand, it is also clear that IY at is not very useful as a domain environment, as it provides the coarsest \npossible approximation of behavior: this is problematic in view of our prospective use of types to check \nand enforce security, as the coarser the approximation of a process' behavior, the less likely is that \nprocess to pass the security checks imposed by its environment.    5.2 Type Reconstruction Type reconstruction \ncomputes the minimum coherent domain envi- ronment II such that a given term type checks. The ordering \nover environments derives by extending the containment relation to en- vironments, using point-wise ordering \nas follows: II C II' if and only if Dora(H) = Dorn(II') and for all D E Dora(H), II(D) C II (D). We use \n~{a [ ~(a)} as a shorthand for N~e{~l~(~)} ' and similarly for the union. Then we have the following-definition. \nDefinition 5.3 (Closure). Let II be a domain environment such thatfn(II) C Dom(II). Then define: EnvCIosure(H) \n,~. N{II' I II' D l-I, II' F- o} ProcCIosure(P, II) A p U U{II(A)lopenA6sync(P =, Yi(A)=)} DomClosure(P, \nA, II) N{II' [ II' DII ,II'(A) D (~,Pt, P=) U P'} whereP'=~F P if o~A6II'(A) = O otherwise [] t It is \neasy to see that all these operators are well-defined and mono- tone: furthermore they can be effectively \ncomputed by (always ter- rninating) algorithms: an example is given in Figure 7. The system for type \nreconstruction is defined in Figure 5: the (R- ACTION) rules are the same as the corresponding algorithmic \n(Ac- TION) rules, (R-REeL) and (R-RESTR) are defined as their corre- sponding rules in Figure 1. In all \nthe rules, the subscript 9 in-dicates a finite set of ambient domains: in (R-DEAD), O9 is the domain \nenvironment defined by Zm(D) = (O, O, 0) for every D 6 9. The rules describe an algorithm that, given \na process P and a type environment E such thatfn(P) C Dora(E) returns a process type P and a domain environment \nII. More precisely, given a process P and a type environment E, let ~ be the set of ambient domains occurring \nin the type assumptions of E and in the typed restrictions of P. Then, there exists one and only one \nprocess type P and environment II such that II, E ~ P : P: we denote this process type and domain environment \nrespectively with ~,~oo(E, P) and ~env(E, P). Theorem 5.4 (Soundness and Completeness). Let P be a process \nand E a type environment such that fn(P) C Dora(E). Then ~.env(E, P), E F-~ P : ~type(E, P). Furthermore, \nfor any II and P such that 17i, E I-a, P : P, one has ~P, env(E, P) C II and ~o(E, P) C P. [] Corollary \n5.5 (Minimality). Let P be a process and E a type en- vironment such that fn(P) C Dora(E). Then (~e.~(E,P),~o(E, \nP)) = min{(II, P) l II, E I- P: P} [] Accordingly, in the typed syntax it is enough to specify the do- \nmains of the ambients occurring in P, and the associated security constraints: the type checker will \nthen generate the minimal types for each domain and for P.  6. SECURITY Security policies are expressed \nby means of security constraints, and new environments help associate security constraints with am- bient \ndomains: Security Envs ~ : Ambient Domains ~ SecmJty Constraints A security environment establishes the \nsecurity structure for a given system of processes and ambients. Given domain and type environ- ments \nII and E, and a well-typed process P, we may then verify that P is secure in ~ by checking that II satisfies \n~2. The definition of satisfaction, denoted II ~ ~, requires Dora(E) = Dora(H) and depends on the structure \nof the security constraints, which in turn depend on the sort of security policy one wishes to express. \nWe discuss three options below. Domain Constraints yield rather coarse security policies whereby one \ncan identify trusted and untrusted domains and, for each do- main, allow interactions only with trusted \ndomains. These security constraints may be expressed by tables of the form S = (in = ~,, out = ~.ut). \nIf D is a domain and ~(D) = S, then ~, (re-spectively, ~out) is the set of trusted domains whose ambients \ncan enter (respectively, exit) the ambients of D. In this option II ~ if and only if, for all D in Dom(II), \none has (i) {A [ in D E sync(II(A) =, II(D)=)} C_ ~(D).in, and (ii) {A [ out D E sync(II(A) =, II(D)'~)} \nC ~(D).out.  (R-DEAD) (R-PAR) H1,EI-~ P1 : P1 H2,E I-~ P2 : P2 II ~ EnvClosure(II1 U H2), oa,, E F-~ \n0 : (0, g, o) H,E ~-~ P11P2 : P P ,~- ProcCIosure((P1 U P2), H) (R-AMB) II, E t-~ P : P E(a)=A  IX* \n~ n{n\" I n- ~_n, H\" = EnvCIosure(II'), II' = DomCIosure(P', A, II), P' = ProcCIosure(P, H\")} II*,E ~-m \na[P]: II*(A) Figure 5: Type Reconstruction Algorithm The security model arising from domain constraints \nis related to security policy of the JDK 1.1.x. In JDK 1.0.x all non local def- initions are considered \nas insecure. The same applies under JDK 1.1.x with the difference that a class loaded from the network \ncan become trusted if it is digitally signed by a party the user has de- cided to trust (in our case \na domain in ~,,). Capability Constraints lead to finer protection policies that iden- tify the type-level \ncapabilities that entering and exiting ambients may exercise ~. These constraints may be expressed by \ntables of the form S = (in = Pin, out = Pout), whose entries are process types. If D is a domain, and \nE(D) = S then: Pin defines the only capabilities that processes entering am- bients of domain D have \npermission to exercise: the three sets Pi~, P~, and P~ specify the capabilities that can be ex- ercised, \nrespectively, at the level of the entering process, at the level of the enclosing ambient, and inside \nthe entering process. The first specification is useful to prevent informa- tion leakage, the second \nto control the local interactions of the entering ambient, and the third is useful when opening (or entering) \nthe entered process.  Pout is the table defining the capabilities that are granted to processes exiting \nout of ambients of domain D, with the three entries t =  Pout, Pout, and Pout defined as above. In \nthis option II ~ E if and only if, for all A, B in Dom(II), in A e sync(II(B)=,II(A) =) implies II(B) \nC_ E(A).in, and, out A E sync(II(B) =, II(A) $) implies II(B) C ~(A).outCapa-bility constraints are loosely \nrelated to the permission collections used in the the JDK 1.2 architecture (a.k.a Java 2) to enforce \nsecu- rity policies based on access control and stack inspection. Constraint Formulas. More refined policies \ncan be expressed by resorting to a fragment of first order logic. The fragment is given below, where \nM ranges over type capabilities, D over ambient do- main names (and domain variables), and ~ over T, \n=, and $. Syntax \u00a2 ::= MeD\" I ~\u00a2 I \u00a2A\u00a2 I \u00a2V\u00a2 I VD:\u00a2 Semantics II~M6D '7 ~ MEH(D) n H~-~\u00a2 ~ II~\u00a2doesnothold \nII~\u00a21A\u00a22 ~ II~\u00a2landII~\u00a22 II~\u00a21V\u00a22 ~ II~\u00a2xorII~\u00a22 II~VD:\u00a2 ~ II~\u00a2{D:----A}forallAeDom(II) 5 Alternatively, \nwe could define what arnbients should not be allowed to do, but our choice complies with well-established \nsecurity principles [7]. The notion of formula satisfiability is easily extended to security environments, \nnamely II ~ E if an only if for all D in Dom(II), II ~ E(D). Since we work on finite models, satisfiability \nis always decidable. Note that the first-order fragment is powerful enough to encode quantification on \nactions as well as formulas such as capD E sync(L, M). Based on that, we can express refined security \nproperties: for example, the formula VB, C : in D E synch(B=,D =) Ain B E synch(C=,B =) ~ in D E C = \nallows one to prevent arbitrary nested Trojan Horses (an ambient entering a second ambient that enters \na third ambient that can enter D), since it requires that all ambients that are granted the right to \nenter domain D may only be entered by ambients that already have the right to enter D. Independently \nof the structure of constraints, given a process P and a type environment E for the names occurring free \nin P, we say that E and P satisfy a security policy E if and only if ~eav(E, P) E. As a corollary of \nTheorem 4.3 we have that ,~env(E, P) implies that no ambient occurring in P can violate the security \npolicies defined in E. 7. DISTRIBUTED SSA The type systems presented in the previous sections have interest- \ning properties and significant operational impact. Yet, there is also a fundamental weakness to them, \nin that they rely on the assump- tion that global information is available on ambient domains, and their \ntypes: a derivation for a typing judgment 1FI, E &#38; P : P re- quires that the environments II and \nE contain assumptions for all the ambients occurring in P, and for all those ambients' domains. This \nis clearly unrealistic for a foundational calculus for wide-area distributed computations and systems. \nIn this section we address the problem by presenting a distributed variant of SSA. In the distributed \nversion, which we call DSSA, each ambient (i.e. each \"location\" in the system of processes) car- ties \na type and a domain environment. The syntax of DSSA pro- cesses is defined by the following productions: \nDistributed Processes P::=O I a.P I (va:D)P ] PIP I a[p]Sn,E ] !P where c~, II, and E are defined as \nin the previous sections, and S is a capability constraint. To get an intuition of DSSA ambients, it \nis useful to think of Java class files. Class files include applet bytecode together with type and security \ninformation used for bytecode verification and dynamic linking. In particular a class file declares the \ntypes of all methods and fields the associated class defines (the type asser- tions), and the types of \nall the identifiers the class refers to (type as- sumptions) [ 10]. When downloading a class file, the \nverifier checks (among other properties) that the bytecode satisfies the type asser- tions under the \ntype assumptions. A DSSA ambient a[P]~,E can be understood as a class file, where a[P] represents the \nbytecode, and the pair 17, E corresponds to the type assertions and assump- tions. Intuitively, for any \nname b occurring in a[P], the process type II(E(b)) may be thought of as a type assertion, if b = a or \nb is the name of an ambient of P, or else as a type assumption if b occurs in a capability of P but P \ncontains no ambient named b.   7.1 Typed Reduction The type system for DSSA is the same as that defined \nfor SSA. DSSA ambients are typed, statically, by simply disregarding their associated environments: the \nlatter are used in the dynamic type- checks performed upon reduction. The new reduction relation is based \non structural congruence, which is defined as in Section 2 with the only exception of the following rule: \n(z'a:D)b[P]Sn,E,a:D ~ b[(va:D)p]Sn,E a ~ b that replaces the corresponding rule for SSA. Typed reduction \nis then defined by the (open), (struct), and (context) rules of Sec- tion 2, plus the rules in Figure \n6. The notation II IY indicates the environment that results from appending H ~ to H so that assumptions \nin II' hide corresponding assumptions in H. Hence, in the rules of Figure 6: (H.n')(D) ~ H'(D) /fD E \nDom(II') = H(D) otherwise (E.E')(a) ~ E'(a) ira E Dom(E') = E(a) otherwise The rule (in) extends the \ncorresponding rule for SSA with addi- tional conditions ensuring that the reduction takes place only \nwhen the local environments of the two ambients involved in the move are mutually compatible and the \nsecurity constraints fulfilled. First, the rule requires the environment of a to be extended by the en- \nviroument of b (in the reductum a carries the environment 17, E that extends Ha, Ea). Second, the reduction \nrequires the entering ambient b to (i) be well-typed in the extended environments, and (ii) to satisfy \nthe security constraints of a. Finally, the condition H ~-E(a) bounds H(E(b)) requires that the entering \nambient b does not modify the external behavior of a: a lets new ambients in only if they comply with \nits own local behavior discipline. 6 The rule (out) performs similar type and security checks: note, \nin particular, that if a were well typed then the type check on b would be unnecessary. Yet, we cannot \nmake any apriori assumption about a and its type, and therefore we must check that the exiting ambient \nhas the type it is supposed to have (otherwise the security check would be of no use). A closer look \nat the rule (in) shows an interesting correspondence between the constraints enforced by the target of \nthe move and the functions implemented by the three component of the JVM security system: the Class Loader, \nthe Bytecode Verifier, and the Security Manager [10]. 6 .... In the rules we constdered that ambmnts \nare indexed by Capability Constraints. If S's were instead Domain Constraints the security requirements \n1H(E(b)) C_ S~ .in and IFI(E(b)) C_ S.out in (in) and (out) would change respectively to E(b) E So.in \nand E(b) E S.out. If instead, the constraints were expressed by formulas, we could consider free-graded \nsecurity constraints of the form S ::= (in = \u00a2, out = ~b), and the security conditions in (in) and (ou0 \nwould change to H ~ Sa .in and FI ~ S.out, respectively. H, E = IIb.II~, Eb.E~ : Local (to a) assumptions \non the type of each name hide remote assumptions for that name. As a consequence, the entering agent \nb cannot spoof a definition of the target host a. This is the security policy implemented by the JVM \nClass Loader, which provides name-space sepa- ration and prevents type-confusion attacks for spoofing. \nb[in a.P [ Q]Snb ,Eb : II(E(b)) : The target of the move, ambient a, checks that the entering agent b \nhas the type it declares to have, in case b \u00a2 Dom(E~), or that a expects it to have, when b E Dom(E~). \nThis is the security policy enforced by the bytecode verifier. H(E(b)) C Sa.in : The ambient a checks \nthat the entering agent performs only actions that are explicitly permitted by the se- curity constraints \ndefined by Sa.in. This is essentially the security policy enforced by the Security Manager: the dif- \nference is that the Security Manager performs these checks dynamically (when the agent is already entered \nand requires to perform the action), whereas in our system they are per- formed at load time. Note that, \nintuitively, all the above checks are performed by a, the ambient whose boundary is crossed. That ambient \ndoes not trust foreign code, it just trusts, of course, its own implementation of the type checking algorithm \nwhich is used to dynamically verify forcing code: verification is based on the (type) information for- \neing code carries along with it, according to the common proof- carrying-code practice [ 11].  7.2 Type \nSafety Most of the properties relating the type system and reduction carry over from SSA to DSSA. However \nthe key property of DSSA, where the essence of distribution resides, is the following, stronger, version \nof Theorem 4.3. Again, the theorem is stated for the simpli- fied case of \"normalized\" distributed processes, \ni.e. for processes with all restrictions extruded to the outermost scope. It is based on the same definitions \nof residual and exhibition of the previous section: the additional information attached to ambients is \nsimply disregarded. Theorem 7.1 (Local Type Safety). Let (v~:/9)P be a DSSA pro- cess, with P containing \nno restriction, and A be an occurrence of = arQ1 s Jn,E\" Assume II, E t- PA : P is derivable. 19 such \nthat PA t /f P~ ~ (capb) n, then capE(b) E pn. [] The difference from Theorem 4.3 is that the new statement \ndoes not require the context P to be well typed, but just that the ambient occurrence can be typed under \nthe assumptions it comes with. Ac- cordingly, every ambient that type-checks under the environment it \ncarries along with it will only exhibit capabilities that are already in its static type, even though \nthe context it interacts with is not well-typed 7 . This is an interesting result for wide-area distributed \nsystems, where global typing may not be possible: for example, distinct subsys- tems may have incompatible \ntype assumptions. Even then, typed reduction allows secure interactions provided that local type safety \n7This property does not hold for the non-distribnted calculus: the proof fails in the case for (in) as \nit is not possible to deduce the well-typing of the ambient b. , \"-~ QISb ISa (,) (in) b[ina.PIO]~bE~la[~a.RlS]Sn~,E~ \na[al SI b[Pl Jn~,E~Jn.E (.) provided that, given II, E = IIb.IIa, Eb.Ea, one has II, E I- b[:i.n a.P \nI Q]: II(E(b)), II(E(b)) C Sa.in and II I-- E(a) bounds II(E(b)) (out) ale a.P J Q J b[out a.R J s'IS~.IHb,EEt, \nJH,EE'IS ~ b[R J S]~bb,Eb J a[P J Q]Sn, E (**) (**) provided that YI, E F b[out a.R J S']: H(E(b)), and \nII(S(b)) C S.out Figure 6: New reduction rules for DSSA exists or can be ensured. Hence, an agent can \nconfidently let an- other ambient in or out even if the former is evolving in a possibly ill-typed context: \nas long as typed reduction is respected, the se- curity constraints that agent defines are never violated. \nThe dual view holds as well: an agent can confidently enter or exit another ambient even if the latter \nis ill-typed: the reduction semantics en- sures that the security constraints defined by the former are \nnever violated. 8. CONCLUSIONS We have showed that classical type theoretic techniques provide effective \ntools for characterizing behavioral properties of mobile agents. We hope to have convinced the reader \nthat capturing im- plicit behavior is essential to ensure secure agent interactions: to our knowledge, \nour type system is the first among type systems for Mobile Ambients to have this property. Also, we have \nshowed that in the design of a distributed implementation for the calculus, one finds back features distinctive \nof real systems. There are several directions for future work. A first, obvious exten- sion is to study \nwhether and how our techniques scale to a calculus with communications. A second interesting subject \nof study is the use of multi-sets (or even lxaces) in place of sets as basic compo- nents of process \ntypes: this would allow us to refine the analysis of process behavior and, consequently, to enforce more \npowerful se- curity policies. Also interesting would be to apply these techniques to the Seal Calculus \n[15]. A further subject of future research is the study of a notion of \"sub- typing\" on ambient domains. \nThis would allow us to introduce in the system a notion of security levels and perform static analyses \nsuch as those described in [2]. Acknowledgments Work partially supported by Franco-Italian Action \"Galileo\" \n1999- 2000. Support was also provided by the Italian MURST Project 9901403824_003 \"Automatic Program \nCertification by Abstract In- terpretation\" and by the French CNRS Program Telecommunica-tions: \"Collaborative, \ndistributed, and secure programming for In- teract\". 9. REFERENCES [1] D. Brewer and M. Nash. The chinese \nwall security policy. In Proc. of lEEE Symposium on Security and Privacy, pages 206--214, 1982. [2] H. \nR. N. C. Bodei, E Degano and E Nielson. Static analysis of processes for no read-up and no write-down. \nIn Porceedins of FoSSaCS'99. 1999. [3] L. Cardelli, G. Ghelli, and A. Gordon. Mobility types for mobile \nambients. In Proceedings oflCALP'99, LNCS 1644, pages 230-239. 1999. [4] L. Cardelli, G. Ghelli, and \nA. D. Gordon. Ambient groups and mobility types. In Int. Conf. IFIP TCS, LNCS 1872, pages 333-347. 2000. \n [5] L. Cardelli and A. Gordon. Mobile ambients. In Proceedings ofPOPL'98. ACM Press, 1998. [6] L. Cardelli \nand A. Gordon. Types for mobile ambients. In Proceedings of POPL'99, pages 79-92. ACM Press, 1999. [7] \nP. J. Denning. Fault tolerant operating systems. ACM Computing Surveys, 8(4):359-389, Dec. 1976. [8] \nL. Gong. Inside Java 2 Platform Security. Addison-Wesley, 1999. [9] E Levi and D. Sangiorgi. Controlling \ninterference in ambients. In POPL '00, pages 352-364. ACM Press, 2000. [10] T. Lindholm and E Yellin. \nThe Java Virtual Machine Specification. Java series. Addison-Wesley, 1997. [11] G. Necula. Proof carrying \ncode. In A. Press, editor, POPL '97, 1997. [12] E Nielson, H. R. Nielson, R. R. Hansen, and J. G. Jensen. \nValidating firewalls in mobile ambients. In Proc. CONCUR'99, LNCS 1664, pages 463--477. 1999. [13] H. \nR. Nielson and F. Nielson. Shape analysis for mobile ambients. In POPL'O0,pages 135-148. ACM Press, 2000. \n[14] P. Sewell and J. Vitek. Secure composition of untrusted code: Wrappers and causality types. In 13th \nIEEE Computer Security Foundations Workshop, 2000. [15] J. Vitek and G. Castagna. Seal: A framework for \nsecure mobile computations. In Internet Programming Languages, LNCS 1686, 1999.  APPENDIX A. SUBJECT \nREDUCTION We first prove a few simple and useful properties for domain en- vironments and process types. \nIn that direction, we extend the set-theoretic notation used on processes to domain environments as follows. \nGiven two domain environments II2 and II2 such that Dom(II1) = Dora (II2), we define II1 nit2 (respectively, \nII10112) to be the domain environment that maps every D E Dom(II~) into the process type II1 (D) f3 II2 \n(D) (respectively, II1 (D) U II2 (D)). Proposition A.1 (Boundedness and Closedness). Let II and H' be \ndomain environments, D an ambient domain, and P, P' two pro- cess types. 1. If H t-D bounds P andYi ~ \nD bounds P', then II ~-D bounds (P OP') 2. If H F D bounds P and P' C P, then II ~- D bounds P'. 3. \nIf II ~-D bounds P and II' ~-D bounds P, then also II ~ II' ~ D bounds P.  4. If II ~- D closed and \nII' ~ D closed, then also II fq II' D closed. 5. If II t- P closed and IIt-- P' closed, then also II \n}- P U P' closed. Proof In all cases, the proof is by a direct application of the defi- nitions. Corollary \nA.2 (Coherence). Let H, H' be domain environments. If II ~-o and II' I-- o, thenII~II' b o. [] Lemma \nA.3 (Process Types). Let H be a domain environment, and Pz, P2 be twoprocess types such that II ~- P~ \nandII l- P2. Then TIF P~UP~ Proof By Proposition A.1. [] Lemma A.4 (Type Formation). If II, E F P : P, \nthen H ~-o and II F P. Proof By induction on the derivation ofII, E F P : P. [] Lemma A.5 (Generation). \n1. If II, E b a : D, then D = E(a). 2. If II, E ~- P [ Q : P, then there exist P1, P2 C_ P such that \nII, E I- P : P1 and Yi, E ~ Q : P2; 3. If II, E HP : P, then there exists P' C_ P such that H, E  P \n: P'; 4. If H, E ~ cap a.P : P, then there exists P' C_ P such that H, E }- P : P', and II, E b a : A \nfor some ambient domain A. Furthermore, either (i) cap E {in, ~, out, o~ } and cap A E P'\u00a2, or (ii) cap \nE {out, open } and cap A E P'= 5. If Yi, E b- (b,a:D)P : P, then there exists P' C P such that II, E, \na:D ~ P : P' 6. Assume II, E ~-a[P] : P. Then II, E F a[P]: II(E(a)), II(E(a)) C P, and there exists \nP' such that II, E F- P: P', andII F E(a) bounds P'.  Proof In each case, directly by induction on \nthe derivation of the judgment in the hypothesis. [] Lemma A.6 (Subject Congruence). 1. lf II, E ~ P \n: P and P _=_ Q, then II, E }- Q : P. 2. If II, E ~- P : P and Q ~ P, then II, E k- Q : P.  Proof By \nsimultaneous induction on the derivations of P ----Q and Q ~ P. [] Theorem A.7 (Subject Reduction). If \nII, E ~ P : P and P'-~Q, then II, E ~ Q : P. Proof The proof is by induction on the depth of the derivation \nof the reduction, and by a case analysis on the last rule in the deriva- tion. Case (open): open a.P1 \nI a[o~ a.P2 I P3] ~ P1 ] P2 [ P3 From II, E ~ open a.P1 I a[o~ a.P2 I Pal : P, by repeated applications \nof Lemma A.5:2, A.5:4, and A.5:6, there exist an am- bient domain D E Dom(YI) with H(D) C P, and process \ntypes P1 C_ P, and P2, P3, P2a with P2, Pa C P23 such that the follow- ing are all verified: lII, E I- \nP1 : P1 (2) II, E [- o~ a.P2 I P3 : P~3 (3) H,E}-P~:P2 and H,E~P3:Pa (4) H, Eba:D and Ht-DboundsP2a (5) \nFrom the first judgment in (4), by Lernma A.5:4, we know that o~ D E P2t3. From this, and from (5), we \nknow that o~ D E II(D) =, and hence P23 C_ III(D) again from (5). Then P2a C P since II(D) C_ P. By subsumption \nfrom (2) and the two judgments in (4), we then derive H, E J- P~ : P for i = 1, 2, 3. Then lII, E I- \nP1 [ P2 I P3 : P derives by two applications of (PAR). Case (in): a[~ a.P1 ] P2] l b[in a.Q1 I Q2] ~ \na[P1 I P21b[Q1 I Q2]] From II, E F- a[~ a.P1 [ P2] [ b[in a.Q1 [ Q2] : P, by Lemma A.4 we know that II \nF o. By repeated applications of Lernma A.5:2, A.5:4, and A.5:6 there exist ambient domains A, B E Dom(II), \nwith II(A),II(B) _C P, process types Pl, P2, P12 with P1, P2 C P12, and Q1, Q2, Q12 with Q1, Q2 C Q12 \nsuch that the following are all verified: II, E l- in a.Q1 I Q2 : Q12 (1) II, EI-Q1 :Q1 and YI, E~Q~:Q2 \n(2) III, EFb:B and Ht--BboundsQ12 (3) II, E t- ~ a.P1 [ P2 : P12 (4) II, EI--P1 :Pl and II, EJ-P2:P2 \n(5) H, EFa:A and HF-AboundsPx2 (6) From the left judgments of (2) and (6), by Lernma A.5:4, we know \nthat in A E Q~2\" From this and from (3), in A e II(B) =. From the left judgment of (5), we also know \nthat i--~ A E P~2- From this and from (6), ~ A E II(A) =. Summarizing we have, in A E sync(H(B) =, H(A)=). \nFrom this, and from H F o, we know that II ~- A bounds II(B). From this, and from the right judgment \nof (6), by Proposition A. 1.1, we have H F A bounds(H(B) U el2) (7) From the two judgments in (2), by \nsubsumption (that can be applied by Lemma A.3) and (PAR), lII, E b Q1 I Q2 : Q12. From this, and (3), \nby (AMB) II, E ~- b[Q1 [ Q2] : II(B) (8) From the two judgments in (5), by subsumption and (PAR), II, \nE F P1 [ P2 : P12. From (8) and the last judgment, by subsumption and (PAR), H, E ~- P~ [ P1 [ b[Q~ [ \nQ2] : II(B) U P12 (9) Now, the type of the reduct derives from (9), (7), and the left judg- ment of (6) \nby (AMB) and subsumption. 232  EnvCIosure(II : DomEnv):DomEnv := 1 ~ := Dom(II); 2 while .~ ~ do 2 \nchoose D in ~; ~ := ~ \\ {D} 3 for M in II(D) = do 4 II' := II 5 case Mof  6 owe H: 7 if~ H 6 II(H)* \nthen II(H) := II(H) U rI(D) 8 in H: 9 if~ H 6 II(H) = men 10 begin n n(n) = := n(H) = u n(m)*; n(n)* \n:= n(H)+ U II(A)= 12 froth 6 iH(H) = men H(H) := If(H) U II(D) 13 end 14 open H: 15 ifo~ H 6 If(H) = \nthen If(D) := II(D) t3 If(H) 16 esac 17 lfII # If' then 9 := ~ U {H} 18 done 19 done 20 return(H) Figure \n7: A closure algorithm The definition of i~[ ] must be extended to include restrictions: [] I el~\u00a2[] \nI ~e[lle [ a[~'[]] I a.f\u00a2[] I (ua:D)~[] Given a context ~[ ] we denote by Efe the type environment formed \nby all the declarations introduced in the context by u's that have the context's hole in their scope. \nFor brevity we use E~ P to denote We can now state the new definition of set of residuals, which is modified \nso that type-environments annotations are traced during the reduction. For this reasons residuals will \nbe tagged processes rather than processes: Definition D.1 (Residuals). Let P be a process. 1. Let ~ be \nan occurrence of an untagged process P and E a type environment. The set of E-residuals ofA.in P is defined \nas follows: (1) ~EP~ is an E-residual of A in P (2) If ~[~Pzx] ~ Q and Q,a, = ~IE,R for some R, then \nevery E'-residual of ~' in ]Q] is also an E-residual of A in P.  2. Let A be an occurrence of an untagged \nprocess P. The set of residuals of A is the set of G-residuals of A in P. [] We extend the type system \nwith an additional type rule for tagged processes and define the $ relation also for tagged processes: \n(TYPE TAG) II, E t- P : P P ,1, cap a n a \u00a2 Dom(E) H,E 1\" ~E'P : P ~EP $ cap a n The way capability exhibition \nis defined for tagged processes jus- tifies why residuals are now defined as tagged processes and why \ntags have to store environments: if we did not, then by the rule (15) a residual could exercise a capability \nthat in the original occurrence would have been blocked by a restriction. Finally, the definition of \n-0- is as before, but now it uses the new definitions of exhibition and residual. Definition D.2 (Residual \nBehavior). Let P be a process, A and an occurrence of P. A -O- an if and only if Q -1- a n, for some \nresidual Q of A. [] The general version of Theorem 4.3 stated for generic processes holds for this new \ndefinition of ~. Theorem D.3 (General Type Safety). Let P be a process and A be an occurrence of P. Assume \nthat II, E ~-P : P' and II, E E~x F- Pa : P. If A ~ (cap a) ~, then cap E(a) E p.. [] To prove it we \nshould first lift the subject reduction theorem to tagged processes and tagged reduction. Theorem D.4 \n(Tagged Subject Reduction). Let P be a tagged pro cess. If II, E ~- P : P and P ~ Q, then II, E b- Q \n: P. [] Then the General Type Safety theorem follows from an analogue of Lemma Lemma B.2 on tagged processes, \nand the following version of Lemma B. 1. Lemma D.5. Let P be an untagged process and A an occurrence \nofP. AssumethatII, E I- P: P andII,(E. Effx) I- P,a : Pl. If ~[I~ExPA] ~ ~l[~E2P2], for some context \n~, then H, (E . E~) I-~2P2 : Pi. Proof. (Sketch) The proof is in two steps. First we prove that the \nclaim holds for structural congruence, i.e. that if ~[~E1Pzx] ~';[~EsP3], then II,(E E~el) I- ~aPs : \nP1. This follows by a case analysis on the possible occurrences of ~E, Ptx: the proof makes a crucial \nuse of the assumption that P is untagged and that therefore ~Ex Pzx is the only tagged occurrence of \nthe starting pro- cesses (if we had several tags then the statement would not hold because of the rule \nlIP I I~Q --- ~(P I Q)). Then, we observe all possible one step reductions starting from ~[~EsPs] and \nending into ~l[~E2P2]. This part of the proof is very much the same as the corresponding part in the \nproof of Lemma B.1, once we note that if ~a Pz is directly issued from ~E2 P2, then E~g x = E~. []  \n  \n\t\t\t", "proc_id": "360204", "abstract": "<i>Secure Safe Ambients</i> (SSA) are a typed variant of <i>Safe Ambients</i> [9], whose type system allows behavioral invariants of ambients to be expressed and verified. The most significant aspect of the type system is its ability to capture <i>both</i> explicit <i>and</i> implicit process and ambient behavior: process types account not only for immediate behavior, but also for the behavior resulting from capabilities a process acquires during its evolution in a given context. Based on that, the type system provides for static detection of security attacks such as <i>Trojan Horses</i> and other combinations of malicious agents.We study the type system of SSA, define algorithms for type checking and type reconstruction, define powerful languages for expressing security properties, and study a distributed version of SSA and its type system. For the latter, we show that distributed type checking ensures security even in ill-typed contexts, and discuss how it relates to the security architecture of the Java Virtual Machine.", "authors": [{"name": "Michele Bugliesi", "author_profile_id": "81100363070", "affiliation": "Universit&#225; \"Ca' Foscari\", Venice", "person_id": "PP14129639", "email_address": "", "orcid_id": ""}, {"name": "Giuseppe Castagna", "author_profile_id": "81100388576", "affiliation": "C. N. R. S. &#201;cole Normale Sup&#233;rieure, Paris", "person_id": "PP31040104", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/360204.360223", "year": "2001", "article_id": "360223", "conference": "POPL", "title": "Secure safe ambients", "url": "http://dl.acm.org/citation.cfm?id=360223"}