{"article_publication_date": "01-01-2001", "fulltext": "\n Mobile Values, New Names, and Secure Communication Mart\u00b4in Abadi C\u00b4edric Fournet Bell Labs Research \nMicrosoft Research Lucent Technologies Abstract We study the interaction of the new construct with a \nrich but common form of (.rst-order) communication. This in\u00adteraction is crucial in security protocols, \nwhich are the main motivating examples for our work; it also appears in other programming-language contexts. \nSpeci.cally, we introduce a simple, general extension of the pi calculus with value pass\u00ading, primitive \nfunctions, and equations among terms. We develop semantics and proof techniques for this extended language \nand apply them in reasoning about some security protocols. A case for impurity Purity often comes before \nconvenience and even before faithfulness in the lambda calculus, the pi calculus, and other foundational \nprogramming languages. For example, in the standard pi calculus, the only messages are atomic names [32]. \nThis simplicity is extremely appealing from a foundational viewpoint, and helps in developing the theory \nof the pi calculus. Furthermore, ingenious encodings demon\u00adstrate that it may not entail a loss of generality: \nin partic\u00adular, integers, objects, and even higher-order processes can be represented in the pure pi \ncalculus. On the other hand, this purity has a price. In applica\u00adtions, the encodings can be futile, \ncumbersome, and even misleading. For example, in the study of programming lan\u00adguages based on the pi \ncalculus (such as Pict [37] or Jo\u00adcaml [14]), there is little point in pretending that integers are not \nprimitive. The encodings may also complicate static analysis and preclude careful thinking about the \nimplemen\u00adtations of communication. Moreover, it is not clear that satisfactory encodings can always be \nfound. We may ask, for instance, whether there is a good representation of the spi calculus [5] (a calculus \nwith cryptographic operations) in the standard pi calculus; we are not aware of any such representation \nthat preserves security properties without a trusted central process. These di.culties are often circumvented \nthrough on-the\u00ad.y extensions. The extensions range from quick punts ( for the next example, let s pretend \nthat we have a datatype of integers ) to the laborious development of new calculi, such as the spi calculus \nand its variants. Generally, the exten\u00adsions bring us closer to a realistic programming language or modeling \nlanguage that is not always a bad thing. Although many of the resulting calculi are ad hoc and poorly \nunderstood, others are robust and uniform enough to have a rich theory and a variety of applications. \nIn particular, impure extensions of the lambda calculus with function symbols and with equations among \nterms ( delta rules ) have been developed systematically, with consider\u00adable success. Similarly, impure \nversions of CCS and CSP with value-passing are not always deep but often neat and convenient [31]. In \nthis paper, we introduce, study, and use an analo\u00adgous uniform extension of the pi calculus, which we \ncall the applied pi calculus (by analogy with applied lambda calcu\u00adlus ). From the pure pi calculus, \nwe inherit constructs for communication and concurrency, and for generating stati\u00adcally scoped new names \n( new ). We add functions and equations, much as is done in the lambda calculus. Messages may then consist \nnot only of atomic names but also of val\u00adues constructed from names and functions. This embedding of \nnames into the space of values gives rise to an important interaction between the new construct and value-passing \ncommunication, which appears in neither the pure pi cal\u00adculus nor value-passing CCS and CSP. Further, \nwe add an auxiliary substitution construct, roughly similar to a .oat\u00ading let ; this construct is helpful \nin programming examples and especially in semantics and proofs, and serves to cap\u00adture the partial knowledge \nthat an environment may have of some values. The applied pi calculus builds on the pure pi calculus and \nits substantial theory, but it shifts the focus away from en\u00adcodings. In comparison with ad hoc approaches, \nit permits a general, systematic development of syntax, operational se\u00admantics, equivalences, and proof \ntechniques. Using the calculus, we can write and reason about pro\u00adgramming examples where new and value-passing \nappear. First, we can easily treat standard datatypes (integers, pairs, arrays, etc.). We can also model \nunforgeable capabilities as new names, then model the application of certain func\u00adtions to those capabilities. \nFor instance, we may construct a pair of capabilities. More delicately, the capabilities may be pointers \nto composite structures, and then adding an o.\u00adset to a pointer to a pair may yield a pointer to its \nsecond Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for profit or commercial \nadvantage and that copies bear this notice and the full citation on the first page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior specific permission and/or \na fee. POPL '01 1/01 Londo, UK Copyright 2001 ACM 1-58113-336-7/01/0001 ... $5.00 component (e.g., as \nin [27]). Furthermore, we can study a variety of security protocols. For this purpose, we repre\u00adsent \nfresh channels, nonces, and keys as new names, and primitive cryptographic operations as functions, obtaining \na simple but useful programming-language perspective on security protocols (much as in the spi calculus). \nA distin\u00adguishing characteristic of the present approach is that we need not craft a special calculus \nand develop its proof tech\u00adniques for each choice of cryptographic operations. Thus, we can express and \nanalyze fairly sophisticated protocols that combine several cryptographic primitives (encryptions, hashes, \nsignatures, XORs, ... ). We can also describe at\u00adtacks against the protocols that rely on (equational) \nproper\u00adties of some of those primitives. In our work to date, security protocols are our main source \nof examples. The next section de.nes the applied pi calculus. Sec\u00adtion 3 introduces some small, informal \nexamples. Section 4 de.nes semantic concepts, such as process equivalence, and develops proof techniques. \nSections 5 and 6 treat two larger examples; they concern a Di.e-Hellman key exchange and message authentication \ncodes, respectively. (The two ex\u00adamples are independent.) Section 7 discusses some related work and concludes. \n2 The applied pi calculus In this section we de.ne the applied pi calculus: its syntax and informal semantics, \nthen its operational semantics (in the now customary chemical style). 2.1 Syntax and informal semantics \nA signature S consists of a .nite set of function symbols, such as f, encrypt, and pair, each with an \narity. A function symbol with arity 0 is a constant symbol. Given a signature S, an in.nite set of names, \nand an in.nite set of variables, the set of terms is de.ned by the grammar: L, M, N, T, U, V ::= terms \na, b, c, . . . , k, . . . , m, n, . . . , s name x, y, z variable f (M1,...,Ml) function application \nwhere f ranges over the functions of S and l matches the arity of f. Although names, variables, and constant \nsymbols have similarities, we .nd it clearer to keep them separate. A term is ground when it does not \nhave free variables (but it may contain names and constant symbols). We use meta\u00advariables u, v, w to \nrange over both names and variables. We also use standard conventional notations for function appli\u00adcations. \nWe abbreviate tuples u1,...,ul and M1,...,Ml to u1and M , respectively. We rely on a sort system for \nterms. It includes a set of base types, such as Integer, Key, or simply a universal base type Data. In \naddition, if t is a sort, then Channel(t ) is a sort too (intuitively, the sort of those channels that \nconvey messages of sort t). A variable can have any sort. A name can have any sort or, in a more re.ned \nversion of the sort system, any sort in a distinguished class of sorts. We typically use a, b, and c \nas channel names, s and k as names of some base type (e.g., Data), and m and n as names of any sort. \nFor simplicity, function symbols take arguments and produce results of the base types only. (This separation \nof channels from other values is convenient but not essential to our approach.) We omit the unimportant \ndetails of this sort system, and leave it mostly implicit in the rest of the paper. We always assume \nthat terms are well-sorted and that substitutions preserve sorts. The grammar for processes is similar \nto the one in the pi calculus, except that here messages can contain terms (rather than only names) and \nthat names need not be just channel names: P, Q, R ::= processes (or plain processes) 0 null process \nP | Q parallel composition !P replication .n.P name restriction ( new ) if M = N then P else Q conditional \nu(x).P message input u(N).P message output The null process 0 does nothing; P | Q is the parallel com\u00adposition \nof P and Q; the replication !P behaves as an in.nite number of copies of P running in parallel. The process \n.n.P makes a new, private name n then behaves as P . The condi\u00adtional construct if M = N then P else \nQ is standard, but we should stress that M = N represents equality, rather than strict syntactic identity. \nWe abbreviate it if M = N then P when Q is 0. Finally, u(x).P is ready to input from channel u, then \nto run P with the actual message replaced for the formal parameter x, while u(N).P is ready to output \nN on channel u, then to run P . In both of these, we may omit P when it is 0. Further, we extend processes \nwith active substitutions: A, B, C ::= extended processes P plain process A | B parallel composition \n.n.A name restriction .x.A variable restriction {Mx} /active substitution We write {M/x} for the substitution \nthat replaces the vari\u00adable x with the term M. Considered as a process, {M/x} is like let x = M in ... \n, and is similarly useful. However, un\u00adlike a let de.nition, {M/x} .oats and applies to any process that \ncomes into contact with it. To control this contact, we may add a restriction: .x.({M/x}| P ) corresponds \nexactly to let x = M in P . The substitution {M/x} typically appears when the term M has been sent to \nthe environment, but the environment may not have the atomic names that ap\u00adpear in M; the variable x \nis just a way to refer to M in this situation. Although the substitution {M/x} concerns only one variable, \nwe can build bigger substitutions by parallel composition, and may write {M1/x1 ,..., Ml /} for {M1/x1 \n}| ... |{Ml/} xl xl ' We write s, {M/x}, {M/xI} for substitutions, xs for the image of x by s, and Ts \nfor the result of applying s to the free variables of T . We identify the empty substitution and the \nnull process 0. We always assume that our substitutions are cycle-free. We also assume that, in an extended \nprocess, there is at most one substitution for each variable, and there is exactly one when the variable \nis restricted. Extending the sort system for terms, we rely on a sort system for extended processes. \nIt enforces that M and N are of the same sort in the conditional expression, that u has sort Channel(t \n) for some t in the input and output expressions, and that x and N have the corresponding sort t in those \nexpressions. Again, we omit the unimportant details of this sort system, but assume that extended processes \nare well\u00adsorted. As usual, names and variables have scopes, which are delimited by restrictions and by \ninputs. We write fv(A), bv(A), fn(A), and bn(A) for the sets of free and bound vari\u00adables and free and \nbound names of A, respectively. These sets are inductively de.ned, using the same clauses for pro\u00adcesses \nas in the pure pi calculus, and using: def fv({M/x})= fv(M) .{x} def fn({M/x})= fn(M) for active substitutions. \nAn extended process is closed when every variable is either bound or de.ned by an active substi\u00adtution. \nWe use the abbreviation .u1for the (possibly empty) series of pairwise-distinct binders .u1..u2.....ul. \nA frame is an extended process built up from 0 and active substitutions of the form {M/x} by parallel \ncomposition and restriction. We let . and . range over frames. The domain dom(.) of a frame . is the \nset of the variables that . exports (those variables x for which . contains a substitution {M/x}not under \na restriction on x). Every extended process A can be mapped to a frame .(A) by replacing every plain \nprocess embedded in A with 0. The frame .(A) can be viewed as an approximation of A that accounts for \nthe static knowledge exposed by A to its environment, but not for A s dynamic behavior. The domain dom(A) \nof A is the domain of .(A).  2.2 Operational semantics Given a signature S, we equip it with an equational \ntheory, that is, with an equivalence relation on terms that is closed under substitutions of terms for \nvariables. (See for exam\u00adple [33, chapter 3] and its references for background on uni\u00adversal algebra \nand algebraic data types from a programming\u00adlanguage perspective.) We further require that this equa\u00adtional \ntheory be closed under one-to-one renamings, but not necessarily closed under substitutions of arbitrary \nterms for names. We write S f M = N when the equation M = N is in the theory associated with S. Here \nwe keep the theory implicit, and we may even abbreviate S f M = N to M = N when S is clear from context \nor unimportant. We write S f M = N for the negation of S f M = N. An equational theory may be generated \nfrom a .nite set of equational axioms, or even from rewrite rules, but this property is not essential \nfor us. We tend to ignore the me\u00adchanics of specifying equational theories. As usual, a context is an \nexpression (a process or ex\u00adtended process) with a hole. An evaluation context is a con\u00adtext whose hole \nis not under a replication, a conditional, an input, or an output. A context C[] closes A when C[A] is \nclosed. Structural equivalence = is the smallest equivalence re\u00adlation on extended processes that is \nclosed by a-conversion on both names and variables, by application of evaluation contexts, and such that: \nPar-0 A = A | 0 Par-A A | (B | C) = (A | B) | C Par-C A | B = B | A Repl !P = P |!P New-0 .n.0 = 0 New-C \n.u..v.A = .v..u.A New-Par A | .u.B = .u.(A | B) when u . fv(A) . fn(A) Alias .x.{M/x}= 0 Subst {M/x}| \nA ={M/x}| A{M/x} Rewrite {M/x}={N/x} when S f M = N The rules for parallel composition and restriction \nare stan\u00addard. Alias enables the introduction of an arbitrary active substitution. Subst describes the \napplication of an active substitution to a process that is in contact with it. Rewrite deals with equational \nrewriting. In combination, Alias and Subst yield A{M/x}= .x.({M/x}| A) for x/. fv(M): A{M/x}= A{M/x}| \n0 by Par-0 = 0 | A{M/x} by Par-C = (.x.{M/x}) | A{M/x} by Alias = .x.({M/x}| A{M/x}) by New-Par = .x.({M/x}| \nA) by Subst Using structural equivalence, every closed extended proc\u00adess A can be rewritten to consist \nof a substitution and a closed plain process with some restricted names: A = n.{ ' x .1M/I}| P where \nfv(P )= M) \u00d8, and {n1}. fn(MM). In partic\u00ad \u00d8, fv( M= ular, every closed frame . can be rewritten to consist \nof a substitution with some restricted names: . = n.{ ' x .1M/I} \u00d8 and {1M).where fv(MM)= n}. fn( MThe \nset {x1} is the domain of .. Internal reduction . is the smallest relation on extended processes closed \nby structural equivalence and application of evaluation contexts such that: Comm a(x).P | a(x).Q . P \n| Q Then if M = M then P else Q . P Else if M = N then P else Q . Q for any ground terms M and N such \nthat S f M = N Communication (Comm) is remarkably simple because the message concerned is a variable; \nthis simplicity entails no loss of generality because Alias and Subst can introduce a variable to stand \nfor a term: a(M).P | a(x).Q = .x.({M/x}| a(x).P | a(x).Q) . .x.({M/x}| P | Q) by Comm = P | Q{M/x} (This \nderivation assumes that x/. fv(M) .fv(P ), which can be established by a-conversion as needed.) Comparisons \n(Then and Else) directly depend on the underlying equational theory; using Else sometimes re\u00adquires that \nactive substitutions in the context be applied .rst, to yield ground terms M and N. This use of the equational \ntheory may be reminiscent of initial algebras. In an initial algebra, the principle of no confusion dictates \nthat two elements are equal only if this is required by the corresponding equational theory. Similarly, \nif M = N then P else Q reduces to P only if this is required by the equational theory, and reduces to \nQ otherwise. Initial algebras also obey the principle of no junk , which says that all elements correspond \nto terms built exclusively from function symbols of the signature. In contrast, a fresh name need not \nequal any such term in the applied pi calculus. Brief examples This section collects several examples, \nfocusing on signa\u00adtures, equations, and some simple processes. We start with pairs; this trivial example \nserves to introduce some nota\u00adtions and issues. We then discuss one-way hash functions, encryption functions, \ndigital signatures, and the XOR func\u00adtion [30, 40]. Further examples appear in sections 5 and 6. Of course, \nat least some of these functions appear in most formalizations of cryptography and security protocols. \nIn comparison with the spi calculus, the applied pi calculus permits a more uniform and versatile treatment \nof these functions, their variants, and their properties. Like the spi calculus, however, the applied \npi calculus takes advantage of notations, concepts, and techniques from programming languages. Pairs \nand other data structures Algebraic datatypes such as pairs, tuples, arrays, and lists occur in many \nexamples. Encoding them in the pure pi calculus is not hard, but nei\u00adther is representing them as primitive. \nFor instance, the signature S may contain the binary function symbol pair and the unary function symbols \nfst and snd, with the abbre\u00adviation (M, N) for pair(M, N), and the evident equations: fst((x, y)) = x \nsnd((x, y)) = y (So the equational theory consists of these equations, and all obtained by re.exivity, \nsymmetry, and transitivity and by substituting terms for variables.) The sort system may enforce that \nfst and snd are applied only to pairs. Alterna\u00adtively, we may add a boolean function that recognizes \npairs. We may also add equations that describe the behavior of fst and snd on other values (e.g., adding \na constant symbol wrong, and equations fst(M)= snd(M )= wrong for all ap\u00adpropriate ground terms M). We \nusually omit such standard variants in other examples. Using pairs, we may for instance write the process: \n .s.a((M, s))| a(x).if snd(x)= s then b(fst(x)) One of its components sends a pair consisting of a term \nM and a fresh name s on a channel a. The other receives a message on a and, if its second component is \ns, it forwards the .rst component on a channel b. Thus, we may say that s serves as a capability (or \npassword) for the forwarding. However, this capability is not protected from eavesdroppers when it travels \non a. Any other process can listen on a and can apply snd, thus learning s. We can represent such an \nattacker within the calculus, for example by the following process: a(x).a((N, snd(x))) which may receive \n(M, s) on a and send (N, s) on a. Com\u00adposing this attacker with the program, we may obtain N instead \nof M on b. One-way hash functions In contrast, we represent a one\u00adway hash function as a unary function \nsymbol h with no equations. The absence of an inverse for h models the one\u00adwayness of h. The fact that \nh(M )= h(N) only when M = N models that h is collision-free. Modifying our .rst example, we may now write: \n a((M, h(s, M)))| .s. a(x).if h(s, fst(x)) = snd(x) then b(fst(x)) Here the value M is signed by hashing \nit with the fresh name s. Although (M, h(s, M)) travels on the public chan\u00adnel a, no other process can \nextract s from this, or produce (N, h(s, N)) for some other N using the available functions. Therefore, \nwe may reason that only the intended term M will be forwarded on channel b. This example is a typical \ncryptographic application of one-way hash functions. In light of the practical impor\u00adtance of those applications, \nour treatment of one-way hash functions is attractively straightforward. Still, we may ques\u00adtion whether \nour formal model of these functions is not too strong and simplistic in comparison with the properties \nof actual implementations based on algorithms such as MD5 and SHA. In section 6, we consider a somewhat \nweaker, subtler model for keyed hash functions. Symmetric encryption In order to model symmetric cryp\u00adtography \n(that is, shared-key cryptography), we take binary function symbols enc and dec for encryption and decryption, \nrespectively, with the equation: dec(enc(x, y),y)= x Here x represents the plaintext and y the key. We \noften use fresh names as keys in examples; for instance, the (useless) process: .k.a(enc(M, k)) sends \nthe term M encrypted under a fresh key k. In applications of encryption, it is frequent to assume that \neach encrypted message comes with su.cient redun\u00addancy so that decryption with the wrong key is evident. \nWe could consider incorporating this property for example by adding the equation dec(M, N)= wrong whenever \nM and N are two ground terms and M = enc(L, N) for all L. On the other hand, in modern cryptology, such \nredundancy is not usually viewed as part of the encryption function proper, but rather an addition. The \nredundancy can be im\u00adplemented with message authentication codes. Accordingly, we do not build it in. \nAsymmetric encryption It is only slightly harder to model asymmetric (public-key) cryptography, where \nthe keys for encryption and decryption are di.erent. We introduce two new unary function symbols pk and \nsk for generating public and secret keys from a seed, and the equation: dec(enc(x, pk(y)), sk(y)) = x \nWe may now write the process: .s.a(pk(s))| b(x).c(dec(x, sk(s))) The .rst component publishes the public \nkey pk(s) by send\u00ading it on a. The second receives a message on b, uses the corresponding secret key \nsk(s) to decrypt it, and forwards the resulting plaintext on c. As this example indicates, we essentially \nview . as a generator of unguessable seeds. In some cases, those seeds may be directly used as passwords \nor keys; in others, some transformations are needed. Some encryption schemes have additional properties. \nIn particular, enc and dec may be the same function. This property matters in implementations, and sometimes \nper\u00admits attacks. Moreover, certain encryptions and decryp\u00adtions commute in some schemes. For example, \nwe have dec(enc(x, y),z)= enc(dec(x, z),y) if the encryptions and decryptions are performed using RSA \nwith the same modu\u00adlus. The treatment of such properties is left open in [5]. In contrast, it is easy \nto express the properties in the applied pi calculus, and to study the protocols and attacks that depend \non them. Non-deterministic ( probabilistic ) encryption Going fur\u00adther, we may add a third argument to \nenc, so that the en\u00adcryption of a plaintext with a key is not unique. This non\u00addeterminism is an essential \nproperty of probabilistic encryp\u00adtion systems [23]. The equation for decryption becomes: dec(enc(x, pk(y),z), \nsk(y)) = x With this variant, we may write the process: a(x). .m.b(enc(M, x, m))| .n.c(enc(N, x, n)) \nwhich receives a message x and uses it as an encryption key for two messages, enc(M, x, m) and enc(N, \nx, n). An ob\u00adserver who does not have the corresponding decryption key cannot tell whether the underlying \nplaintexts M and N are identical by comparing the ciphertexts, because the cipher\u00adtexts rely on di.erent \nfresh names m and n. Moreover, even if the observer learns x, M, and N (but not the decryption key), \nit cannot verify that the messages contain M and N because it does not know m and n. Public-key digital \nsignatures Like public-key encryption schemes, digital-signature schemes rely on pairs of public and \nsecret keys. In each pair, the secret key serves for computing signatures and the public key for verifying \nthose signatures. In order to model digital signatures and their checking, we use again the two unary \nfunction symbols pk and sk for generating public and secret keys from a seed. We also use the new binary \nfunction symbol sign, the ternary function symbol check, and the constant symbol ok, with the equation: \ncheck(x, sign(x, sk(y)), pk(y)) = ok (Several variants are possible.) Modifying again our .rst example, \nwe may now write: .s.{pk(s)/y}| a((M, sign(M, sk(s))))| a(x).if check(fst(x), snd(x),y)= ok then b(fst(x)) \nHere the value M is signed using the secret key sk(s). Al\u00adthough M and its signature travel on the public \nchannel a, no other process can produce N and its signature for some other N. Therefore, again, we may \nreason that only the in\u00adtended term M will be forwarded on channel b. This prop\u00aderty holds despite the \npublication of pk(s) (but not sk(s)), which is represented by the active substitution that maps y to \npk(s). Despite the restriction on s, processes outside the restriction can use pk(s) through y. In particular, \ny refers to pk(s) in the process that checks the signature on M. XOR Finally, we may model the XOR function, \nsome of its uses in cryptography, and some of the protocol .aws con\u00adnected with it. Some of these .aws \nstem from the intrinsic equational properties of XOR, such as cancellation property that we may write: \nxor(xor(x, y),y)= x Others arise because of the interactions between XOR and other operations (e.g., \n[41, 15]). For example, CRCs (cyclic redundancy codes) can be poor proofs of integrity, partly because \nof the equation: crc(xor(x, y)) = xor(crc(x), crc(y)) 4 Equivalences and proof techniques In examples, \nwe frequently argue that two given processes cannot be distinguished by any context, that is, that the \nprocesses are observationally equivalent. The spi calculus developed the idea that the context represents \nan active at\u00adtacker, and equivalences capture authenticity and secrecy properties in the presence of \nthe attacker. In this section we de.ne observational equivalence for the applied pi calculus. We also \nintroduce a notion of static equivalence for frames, a labeled semantics for processes, and a labeled \nequivalence relation. We prove that labeled equivalence and observational equivalence coincide, obtain\u00ading \na convenient proof technique for observational equiva\u00adlence. 4.1 Observational equivalence We write A \n. a when A can send a message on a, that is, when A . * C[a(M ).P ] for some evaluation context C[] that \ndoes not bind a. De.nition 1 Observational equivalence ( ) is the largest symmetric relation R between \nclosed extended processes with the same domain such that A R B implies: 1. if A . a, then B . a; 2. \nif A . * A', then B . * B' and A' R B' for some B'; 3. C[A] R C[B] for all closing evaluation contexts \nC[].  These de.nitions are standard in the pi calculus, where . a is called a barb on a, and where \nis one of the two usual notions of barbed bisimulation congruence. (See [20] for details.) For example, \nwhen h is a unary function symbol with no equations, we obtain that .s.a(s) .s.a(h(s)).  4.2 Static \nequivalence Two substitutions may be seen as equivalent when they be\u00adhave equivalently when applied to \nterms. We write s for this notion of equivalence, and call it static equivalence. In the presence of \nthe new construct, de.ning s is some\u00adwhat delicate and interesting. For instance, consider two functions \nf and g with no equations (intuitively, two inde\u00adpendent one-way hash functions), and the three frames: \ndef .0 = .k.{k/x}| .s.{s/y} def g(k) .1 = .k.{f(k)/x,/y} def f(k) .2 = .k.{k/x,/y} .x.a.x. .k.a(enc(M, \nk)).a(k).a(z).if z = M then c( oops ! ) - ---. .k. {enc(M,k)/x}| a(k).a(z).if z = M then c( oops ! ) \n.y.a.y. - ---. .k. {enc(M,k)/x}|{k/y}| a(z).if z = M then c( oops ! ) a(dec(x,y)) - -----. .k. {enc(M,k)/x}|{k/y}| \nif dec(x, y)= M then c( oops ! ) . .k. {enc(M,k)/x}|{k/y}| c( oops ! ) Figure 1: Example transitions \nIn .0, the variables x and y are mapped to two unrelated values that are di.erent from any value that \nthe context may build (since k and s are new). These properties also hold, but more subtly, for .1; although \nf(k) and g(k) are based on the same underlying fresh name, they look unre\u00adlated. (Analogously, it is \ncommon to construct apparently unrelated keys by hashing from a single underlying secret, as in SSL [21].) \nHence, a context that obtains the values for x and y cannot distinguish .0 and .1. On the other hand, \nthe context can discriminate .2 by testing the pred\u00adicate f(x)= y. Therefore, we would like to de.ne \nstatic equivalence so that .0 s .1 s .2. This example relies on a concept of equality of terms in a frame, \nwhich the following de.nition captures. De.nition 2 We say that two terms M and N are equal in the frame \n., and write (M = N)., if and only if . = .1 n.s, Ms = Ns, and {n1}n (fn(M) . fn(N)) = \u00d8 for some names \nn1and substitution s. For instance, in our example, we have (f(x)= y).2 but not (f(x)= y).1, hence .1 \ns .2. De.nition 3 We say that two closed frames . and . are statically equivalent, and write . s ., when \ndom(.)= dom(.) and when, for all terms M and N, we have (M = N). if and only if (M = N).. We say that \ntwo closed extended processes are statically equivalent, and write A s B, when their frames are stati\u00adcally \nequivalent. Depending on S, static equivalence can be quite hard to check, but at least it does not depend \non the dynamics of processes. Some simpli.cations are possible in common cases, for example when terms \ncan be put in normal forms. The next two lemmas state several basic, important properties of s: Lemma \n1 Static equivalence is closed by structural equiva\u00adlence, by reduction, and by application of closing \nevaluation contexts. Lemma 2 Observational equivalence and static equivalence coincide on frames. Observational \nequivalence is strictly .ner than static equivalence on extended processes: . s. To see that observational \nequivalence implies static equiv\u00adalence, note that if A and B are observationally equivalent then A | \nC and B | C have the same barbs for every C, and that they are statically equivalent when A | C and B \n| C have the same barb . a for every C of the special form if M = N then a(s), where a does not occur \nin A or B.  4.3 Labeled operational semantics and equivalence A labeled operational semantics extends \nthe chemical se\u00admantics of section 2, enabling us to reason about processes that interact with their \nenvironment. The labeled semantics a de.nes a relation A -. A ' , where a is a label of one of the following \nforms: a label a(M), where M is a term that may contain names and variables, which corresponds to an \ninput of M on a;  a label a(u) or .u.a(u), where u is either a channel name or a variable of base type, \nwhich corresponds to an output of u on a.  In addition to the rules for structural equivalence and re\u00adduction \nof section 2, we adopt the following rules: a(M) In a(x).P ---. P {M/x} a.u. Out-Atom a(u).P - -. P a.u. \nA - -. A ' u = a Open-Atom .u.a.u. .u.A - ---. A ' a A -. A ' u does not occur in a Scope a .u.A -. .u.A \n' . A ' A -abv(a) n fv(B)= bn(a) n fn(B)= \u00d8 Par a A | B -. A ' | B a A = BB -. B ' B ' = A ' Struct a \nA -. A ' According to In, a term M may be input. On the other hand, Out-Atom permits output only for \nchannel names and for variables of base type. Other terms can be output only by reference : a variable \ncan be associated with the term in question and output. For example, using the signature and equations \nfor sym\u00admetric encryption, and the new constant symbol oops !, we have the sequence of transitions of \nFigure 1. The .rst two transitions do not directly reveal the term M. However, they give enough information \nto the environment to compute M as dec(x, y), and to input it in the third transition. The labeled operational \nsemantics leads to an equiva\u00adlence relation: De.nition 4 Labeled bisimilarity ( l) is the largest sym\u00admetric \nrelation R on closed extended processes such that A R B implies: 1. A s B; 2. if A . A ' , then B . \n* B ' and A ' R B ' for some B ' ; . A ' aB ' R B '  3. if A -aand fv(a) . dom(A) and bn(a)nfn(B)= \n\u00d8,  then B . * -.. * and A ' for some B ' . Conditions 2 and 3 are standard; condition 1, which requires \nthat bisimilar processes be statically equivalent, is necessary for example in order to distinguish the \nframes .0 and .2 of section 4.2. Our main result is that this relation coincides with obser\u00advational \nequivalence. Although such results are fairly com\u00admon in process calculi, they are important and non-trivial. \nTheorem 1 Observational equivalence is labeled bisimilar\u00adity: = l. One of the lemmas in the proof of \nthis theorem says that l is closed by application of closing evaluation contexts. However, unlike the \nde.nition of , the de.nition of l does not include a condition about contexts. It therefore permits simpler \nproofs. In addition, labeled bisimilarity can be established via standard bisimulation up to context \ntechniques [38], which enable useful on-the-.y simpli.cations in frames after out\u00adput steps. The following \nlemmas provide methods for sim\u00adplifying frames: Lemma 3 (Alias elimination) Let A and B be closed ex\u00adtended \nprocesses. If {M/x}| A l {M/x}| B, then A l B. Lemma 4 (Name disclosure) Let A and B be closed ex\u00adtended \nprocesses. If .s.({s/x}| A) l .s.({s/x}| B), then A l B. In Lemma 3, the substitution {M/x} can a.ect \nonly the con\u00adtext, since A and B are closed. However, the lemma implies that the substitution does not \ngive or mask any information about A and B to the context. In Lemma 4, the restriction on s and the substitution \n{s/x} mean that the context can access s only indirectly, through the free variable x. Cru\u00adcially, s \nis a name of base type. Intuitively, the lemma says that indirect access is equivalent to direct access \nin this case. This labeled operational semantics contrasts with a more naive semantics carried over from \nthe pure pi calculus, with output labels .1 u.a(M) and rules that permit direct output of any term, such \nas: a.M. Out-Term a(M).P ---. P . I u.a.M. A -----. A ' v . fv(M) . fn(M) \\{a, u1} Open-All .v,Iu.a.M. \n.v.A - -----. A ' These rules lead to a di.erent, .ner equivalence relation, which for example would \ndistinguish .k, s.a((k, s)) and .k.a((f(k), g(k))). This equivalence relation is often inad\u00adequate in \napplications (as in [5, section 5.2.1]), hence our de.nitions. We have also studied intermediately liberal \nrules for out\u00adput, which permit direct output of certain terms. We ex\u00adplain those rules next.  4.4 Re.ning \nthe labeled operational semantics In the labeled operational semantics of section 4.3, the la\u00adbels for \noutputs do not reveal much about the terms being output. Except for channel names, those terms are repre\u00adsented \nby variables. Often, however, more explicit labels can be convenient in reasoning about protocols, and \nthey do not cause harm as long as they only make explicit in\u00adformation that is immediately available \nto the environment. For instance, for the process .k.a((Header, enc(M, k))), the label .y.a((Header,y)) \nis more informative than .x.a(x). In this example, the environment could anyway derive that fst(x)= Header. \nMore generally, we rely on the following de.nition to characterize the information that the environ\u00adment \ncan derive. De.nition 5 A variable x can be derived from the extended process A when, for some term M \nand extended process A ' , we have A ={M/x}| A ' . In general, when x . dom(A), there exist n1, M, and \nA ' such that A = .n.1{M/x}| A ' . If x can be derived from A, then n1can be chosen empty, so that M \nis not under restrictions. Intuitively, if x can be derived from A, then A does not reveal more information \nthan .x.A, because the context can build the term M and use it instead of x. For example, using function \nsymbols for pairs and symmetric encryption, we let: def enc(x,k)(y,N) . = .k.{M/x,/y,/z} The variable \ny can be derived from . using fst(z). Formally, we have: {fst(z)(enc(x,k),N) . = /y}| .k.{M/x,/z } In \ncontrast, x and z cannot be derived from . in general. However, if k does not occur in N, then z can \nbe derived from . using (y, N): {(y,N)enc(x,k) . = /z}| .k.{M/x,/y} Conversely, if N = k, then x can \nbe derived from . using dec(y, snd(z)), even if k occurs in M: {dec(y,snd(z))(y,k) . = /x}| .k.{enc(M,k)/y,/z} \nRelying on De.nition 5, we de.ne rules for output that permit composite terms in labels but require that \nevery re\u00adstricted variable that is exported can be derived by the en\u00ad a vironment. In the relation A \n-. A ' , the label a now ranges over the same labels a(M) for input and generalized labels for output \nof the form .1 u.a(M), where M is a term that may contain variables and where {u1}. fv(M).fn(M). The \nlabel .1on a that reveals u.a(M) corresponds to an output of M the names and variables u1. We retain \nthe rules for structural equivalence and reduc\u00adtion, and rules In, Par, and Struct. We also keep rule \nScope, but only for labels with no extrusion, that is, for labels a(M) and a(M). As a replacement for \nthe rules Out-Atom and Open-Atom, we use the rules Out-Term and: a.b. A --. A ' b = a Open-Channel .b.a.b. \n.b.A ----. A ' . I u.a.M. A -----. A ' x . fv(M) \\{u1}x can be derived from .u.1{M/z}| A ' Open-Variable \n.x,Iu.a.M. .x.A - -----. A ' Rule Open-Channel is the special of Open-Atom for chan\u00adnel names. Rule Open-Variable \n.lters output transitions whose contents may reveal restricted variables. Only non\u00adderivable subterms \nhave to be replaced with variables before the output. Thus, these rules are more liberal than those of \nsection 4.3. In fact, it is easy to check that the rules of section 4.3 are special cases of these ones. \nFor instance, consider A1 = .k.a((f(k), g(k))) and A2 = .k.a((k, f(k))). With the rules of section 4.3, \nwe have: .z.a.z. Ai ----. .x, y.{(x,y)/z }| .i where x, y can be eliminated and .i is as in section 4.2. \nWith the new rules, we also have: .x,y.a.(x,y). Ai --------. .i This transition is adequate for A1 since \nx and y behave like fresh, independent values. For A2, we also have the more informative transition: \n.x.a.(x,f(x)). A2 - -------. .k.{k/x} that reveals the link between x and y, but not that x is a name. \nIn general, for a given message, we may have several output transitions. Each of these transitions may \nlead to a process with a di.erent frame. However, it su.ces to con\u00adsider any one of the transitions in \norder to prove that a rela\u00adtion is included in labeled bisimilarity. Hence, a particular label can be \nchosen to re.ect the structure of the protocol at hand, and to limit the complexity of the resulting \nframe. The next theorem states that the two semantics yield the same notion of equivalence. Thus, making \nthe labels more explicit only makes apparent some of the information that is otherwise kept in the static, \nequational part of l. Theorem 2 Let L be the relation of labeled bisimilarity obtained by applying De.nition \n4 to the semantics of this section. We have l = L. In another direction, we can re.ne the semantics to \nper\u00admit functions that take channels as arguments or produce them as results (which are excluded in section \n2). For ex\u00adample, we can permit a pairing function for channels. Thus, although the separation of channels \nfrom other values is fre\u00adquent in examples and convenient, it is not essential. For this purpose, we \nwould allow the use of the rule Open-All in the case where v is a channel b. The dis\u00adadvantages of this \nrule (indicated above) do not arise if two reasonable constraints are met: (1) channel sorts contain \nonly pairwise-distinct names up to term rewriting; (2) for every term M with a channel variable x, there \nis a channel term N with free variable y and no free names such that x = N{M/y}. Di.e-Hellman key agreement \n(example) The fundamental Di.e-Hellman protocol allows two prin\u00adcipals to establish a shared secret by \nexchanging messages over public channels [17]. The principals need not have any shared secrets in advance. \nThe basic protocol, on which we focus here, does not provide authentication; therefore, a bad principal \nmay play the role of either principal in the protocol. On the other hand, the two principals that follow \nthe protocol will communicate securely with one an\u00adother afterwards, even in the presence of active attackers. \nIn extended protocols, such as the Station-to-Station pro\u00adtocol [18] and SKEME [26], additional messages \nperform authentication. We program the basic protocol in terms of the binary function symbol f and the \nunary function symbol g, with the equation: f(x, g(y)) = f(y, g(x)) (1) Concretely, the functions are \nf(x, y)= y x mod p and g(x)= ax mod p for a prime p and a generator a of Zp * , ay\u00d7x and we have the \nequation f(x, g(y)) = (ay)x == ax\u00d7y =(ax)y = f(y, g(x)). However, we ignore the under\u00adlying number theory, \nworking abstractly with f and g. The protocol has two symmetric participants, which we represent by the \nprocesses A0 and A1. The protocol estab\u00adlishes a shared key, then the participants respectively run P0 \nand P1 using the key. We use the public channel c01 for messages from A0 to A1 and the public channel \nc10 for communication in the opposite direction. We assume that none of the values introduced in the \nprotocol appears in P0 and P1, except for the key. In order to establish the key, A0 invents a name n0, \nsends g(n0) to A1, and A1 proceeds symmetrically. Then A0 computes the key as f(n0, g(n1)) and A1 computes \nit as f(n1, g(n0)), with the same result. We .nd it convenient to use the following substitutions for \nA0 s message and key: def s0 = {g(n0)/x0 } def {f(n0,x1) f0 = /y} and the corresponding substitutions \ns1 and f1, as well as the frame: def . =(.n0. (f0 | s0)) | (.n1.s1) With these notations, A0 is: def \nA0 = .n0.(c01(x0s0)| c10(x1).P0f0) and A1 is analogous. Two reductions represent a normal run of the \nprotocol: A0 | A1 .. .x0,x1,n0,n1. (P0f0 | P1f1 | s0 | s1) (2) = .x0,x1,n0,n1, y. (P0 | P1 | f0 | s0 \n| s1) (3) = .y.(P0 | P1 | .x0,x1..) (4) The two communication steps (2) use structural equivalence to \nactivate the substitutions s0 and s1 and extend the scope of the secret values n0 and n1. The structural \nequivalence (3) crucially relies on equation (1) in order to reuse the active substitution f0 instead \nof f1 after the reception of x0 in A1. The next structural equivalence (4) tightens the scope for restricted \nnames and variables, then uses the de.nition of .. We model an eavesdropper as a process that intercepts \nmessages on c01 and c10, remembers them, but forwards them unmodi.ed. In the presence of this passive \nattacker, the operational semantics says that A0 | A1 yields instead: .y.(P0 | P1 | .) The sequence of \nsteps that leads to this result is similar to the one above. The absence of the restrictions on x0 and \nx1 corresponds to the fact that the eavesdropper has obtained the values of these variables. The following \ntheorem relates this process to .k.(P0 | P1){k/y} which represents the bodies P0 and P1 of A0 and A1 \nshar\u00ading a key k. This key appears as a simple shared name, rather than as the result of communication \nand computa\u00adtion. Intuitively, we may read .k.(P0 | P1){k/y} as the ideal outcome of the protocol: P0 \nand P1 execute using a shared key, without concern for how the key was established, and without any side-e.ects \nfrom weaknesses in the establish\u00adment of the key. The theorem says that this ideal outcome is essentially \nachieved, up to some noise . This noise is a substitution that maps x0 and x1 to unrelated, fresh names. \nIt accounts for the fact that an attacker may have the key\u00adexchange messages, and that they look just \nlike unrelated values to the attacker. In particular, the key in use between P0 and P1 has no observable \nrelation to those messages, or to any other left-over secrets. We view this independence of the shared \nkey as an important forward-secrecy property. Theorem 3 Let P0 and P1 be processes with free variable \ny where the name k does not appear. We have: .y.(P0 | P1 | .) .k.(P0 | P1){k/y}| .s0.{s0/x0 }| .s1.{s1/x1 \n} The theorem follows from Lemma 2 and the static equiva\u00adlence . s .s0,s1, k.{s0/x0 , s1 /x1 , k/y}, \nwhich says that the frame . generated by the protocol execution is equivalent to one that maps variables \nto fresh names. Extensions of the basic protocol add rounds of communi\u00adcation that con.rm the key and \nauthenticate the principals. We have studied one such extension with key con.rmation. There, the shared \nsecret f(n0, g(n1)) is used in con.rma\u00adtion messages. Because of these messages, the shared secret can \nno longer be equated with a virgin key for P0 and P1. Instead, the .nal key is computed by hashing the \nshared se\u00adcret. This hashing guarantees the independence of the .nal key. 6 Message authentication codes \nand hashing (another example) Message authentication codes (MACs) are common crypto\u00adgraphic operations. \nIn this section we treat MACs and their constructions from one-way hash functions. This example provides \na further illustration of the usefulness of equations in the applied pi calculus. On the other hand, \nsome aspects of MAC constructions are rather low-level, and we would not expect to account for all their \ncombinatorial details (e.g., the birthday attacks ). A higher-level task is to express and reason about \nprotocols treating MACs as primitive; this is squarely within the scope of our approach. 6.1 Using MACs \nMACs serve to authenticate messages using shared keys. When k is a key and M is a message, and k is known \nonly to a certain principal A and to the recipient B of the mes\u00adsage, B may take mac(k, M) as proof that \nM comes from A. More precisely, B can check mac(k, M) by recomputing it upon receipt of M and mac(k, \nM), and reason that A must be the sender of M. This property should hold even if A generates MACs for \nother messages as well; those MACs should not permit forging a MAC for M. In the worst case, it should \nhold even if A generates MACs for other messages on demand. Using a new binary function symbol mac, we \nmay de\u00adscribe this scenario by the following processes: def A =!a(x).b((x, mac(k, x))) def B = b(y).if \nmac(k, fst(y)) = snd(y) then c(fst(y)) def S = .k.(A | B) The process S represents the complete system, \ncomposed of A and B; the restriction on k means that k is private to A and B. The process A receives \nmessages on a public channel a and returns them MACed on the public channel b. When B receives a message \non b, it checks its MAC and acts upon it, here simply by forwarding on a channel c. Intuitively, we would \nexpect that B forwards on c only a message that A has MACed. In other words, although an attacker may \nintercept, modify, and inject messages on b, it should not be able to forge a MAC and trick B into forwarding \nsome other message. This property can be expressed precisely in terms of the labeled semantics and it \ncan be checked without too much di.culty when mac is a primitive function symbol with no equations. The \nproperty remains true even if there is a func\u00adtion extract that maps a MAC mac(x, y) to the underlying \ncleartext y, with the equation extract(mac(x, y)) = y. Since MACs are not supposed to guarantee secrecy, \nsuch a func\u00adtion may well exist, so it is safer to assume that it is available to the attacker. The property \nis more delicate if mac is de.ned from other operations, as it invariably is in practice. In that case, \nthe property may even be taken as the speci.cation of MACs [22]. Thus, a MAC implementation may be deemed \ncorrect if and only if the process S works as expected when mac is instantiated with that implementation. \nMore specif\u00adically, the next section deals with the question of whether the property remains true when \nmac is de.ned from hash functions.  6.2 Constructing MACs In section 3, we give no equations for one-way \nhash func\u00adtions. In practice, one-way hash functions are commonly de.ned by iterating a basic binary \ncompression function, which maps two input blocks to one output block. Fur\u00adthermore, keyed one-way hash \nfunctions include a key as an additional argument. Thus, we may have: f(x, y + z)= h(f(x, y),z) where \nf is the keyed one-way hash function, h is the com\u00adpression function, x is a key, and y + z represents \nthe con\u00adcatenation of block z to y. Concatenation (+) associates to the left. We also assume other standard \noperations on sequences and the corresponding equations. In this equation we are rather abstract in our \ntreatment of blocks, their sizes, and therefore of padding and other related issues. We also ignore two \ncommon twists: some functions use initialization vectors to start the iteration, and some append a length \nblock to the input. Nevertheless, we can explain various MAC constructions, describing .aws in some and \nreasoning about the properties of others. a(M) .k.(A | B) ---. .x.b.x. ----. b((M+N,h(snd(x),N))) --------------.. \n.y.c.y. ----. .k.(A | B | b((M, mac(k, M)))) .k.(A | B |{(M,mac(k,M))/x}) .k.(A | c(M + N)|{(M,mac(k,M))/x}) \n.k.(A |{(M,mac(k,M))/x, M+N /y}) Figure 2: An attack scenario .k.(A | B) a(M) ---. .x.b.(M,x). -------. \nb((M+N,h(x,N))) -----------.. c.M+N. -----. .k.(A | B | b((M, mac(k, M)))) .k.(A | B |{mac(k,M)/x}) \n.k.(A | c(M + N)|{mac(k,M)/x}) .k.(A |{mac(k,M)/x}) Figure 3: An attack scenario (with re.ned labels) \nA .rst, classical de.nition of a MAC from a keyed one\u00adway hash function f is: def mac(x, y)= f(x, y) \nFor instance, the MAC of a three-block message M = M0 + M1 + M2 with key k is mac(k, M)= h(h(f(k, M0),M1),M2). \nThis implementation is subject to a well-known extension attack. Given the MAC of M, an attacker can \ncompute the MAC of any extension M + N without knowing the MAC key, since mac(k, M + N)= h(mac(k, M),N). \nWe can describe the attack formally through the operational semantics, as done in Figure 2 and in Figure \n3, which use the semantics of sections 4.3 and 4.4 respectively. We assume k . fn(M) . fn(N). In those \ndescriptions, we see that the message M that the system MACs di.ers from the message M + N that it forwards \non c. There are several ways to address extension attacks, and indeed the literature contains many MAC \nconstructions that are not subject to these attacks. We have considered some of them. Here we describe \na construction that uses the MAC key twice: def mac(x, y)= f(x, f(x, y)) Under this de.nition, the process \nS forwards on c only a message that it has previously MACed, as desired. Looking beyond the case of S, \nwe can prove a more general result by comparing the situation where mac is primitive (and has no special \nequations) and one with the de.nition of mac(x, y) as f(x, f(x, y)). Given a tuple of names 1k and an \nextended proc\u00adess C that uses the symbol mac, we write [ C] for the trans\u00adlation of C in which the de.nition \nof mac is expanded wher\u00ad ever a key ki in 1k is used, with f(ki, f(ki,M)) replaced for mac(ki,M). The \ntheorem says that this translation yields an equivalent process (so, intuitively, the constructed MACs \nwork as well as the primitive ones): Theorem 4 Suppose that the names 1k appear only as MAC keys in C. \nTake no equations for mac and the equation f(x, y + z)= h(f(x, y),z) for f. Then .1k.C .k.1[ C] . 7 \nRelated work and conclusions In this paper, we describe a uniform extension of the pi calculus, the applied \npi calculus, in which messages may be compound values, not just channel names. We study its theory, developing \nits semantics and proof techniques. Although the calculus has no special, built-in features to deal with \nsecurity, we .nd it useful in the analysis of security protocols. Other techniques have been employed \nfor the analysis of these protocols. Some are based on complexity theory; there, principals are basically \nTuring machines that com\u00adpute on bitstrings, and security depends on the computa\u00adtional limitations of \nattackers (e.g., [44, 23, 24, 8, 22]). Oth\u00aders rely on higher-level, formal representations where issues \nof computational complexity can be conveniently avoided (e.g., [19, 25, 29, 39, 35, 34, 42, 5, 16, 7]). \nAlthough some recent work [28, 36, 6] starts to relate these two schools (for example, justifying the \nsoundness of the second with respect to the .rst), they remain rather distinct. Our use of the ap\u00adplied \npi calculus clearly belongs in the second. Within this school, many recent approaches work essentially \nby reason\u00ading about all possible traces of a security protocol. However, the ways of talking about the \ntraces and their properties vary greatly. We use a process calculus. Its semantics pro\u00advides a detailed \nspeci.cation for sets of traces. Because the process calculus has a proper new construct (like the pi \ncalculus but unlike CSP), it provides a direct account of the generation of new keys and other fresh \nquantities. It also enables reasoning with equivalence and implementation re\u00adlations. Furthermore, the \nprocess calculus permits treating security protocols as programs written in a programming notation subject \nto typing, to other static analyses, and to translations [1, 3, 4, 2, 10, 11, 9, 13]. The applied pi \ncalculus has many commonalities with the original pi calculus and its relatives, such as the spi calculus \n(discussed above). In particular, the model of communica\u00adtion adopted in the applied pi calculus is deliberately \nclas\u00adsical: communication is through named channels, and value computation is rather separate from communication. \nFur\u00adther, active substitutions are reminiscent of the constraints of the fusion calculus [43]. They are \nespecially close to the substitution environments that Boreale et al. employ in their proof techniques \nfor a variant of the spi calculus with a sym\u00admetric cryptosystem [12]; we incorporate substitutions into \nprocesses, systematize them, and generalize from symmetric cryptosystems to arbitrary operations and \nequations. Famously, the pi calculus is the language of those lively social occasions where all conversations \nare exchanges of names. The applied pi calculus opens the possibility of more substantial, structured \nconversations; the cryptic character of some of these conversations can only add to their charm and to \ntheir tedium. Acknowledgements We thank Rocco De Nicola, Andy Gordon, Tony Hoare, and Phil Rogaway for \ndiscussions that contributed to this work. Georges Gonthier and Jan J\u00a8urjens suggested improvements in \nits presentation. References [1] Mart\u00b4in Abadi. Protection in programming-language translations. In Kim \nG. Larsen, Sven Skyum, and Glynn Winskel, editors, Proceedings of the 25th Inter\u00adnational Colloquium \non Automata, Languages and Pro\u00adgramming, volume 1443 of Lecture Notes in Computer Science, pages 868 \n883. Springer, July 1998. Also Dig\u00adital Equipment Corporation Systems Research Center report No. 154, \nApril 1998. [2] Mart\u00b4in Abadi. Secrecy by typing in security protocols. Journal of the ACM, 46(5):749 \n786, September 1999. [3] Mart\u00b4in Abadi, C\u00b4edric Fournet, and Georges Gonthier. Secure implementation \nof channel abstractions. In Pro\u00adceedings of the Thirteenth Annual IEEE Symposium on Logic in Computer \nScience, pages 105 116, June 1998. [4] Mart\u00b4in Abadi, C\u00b4edric Fournet, and Georges Gonthier. Authentication \nprimitives and their compilation. In Proceedings of the 27th ACM Symposium on Princi\u00adples of Programming \nLanguages, pages 302 315, Jan\u00aduary 2000. [5] Mart\u00b4in Abadi and Andrew D. Gordon. A calculus for cryptographic \nprotocols: The spi calculus. Informa\u00adtion and Computation, 148(1):1 70, January 1999. An extended version \nappeared as Digital Equipment Cor\u00adporation Systems Research Center report No. 149, Jan\u00aduary 1998. [6] \nMart\u00b4in Abadi and Phillip Rogaway. Reconciling two views of cryptography (The computational soundness \nof formal encryption). In Proceedings of the First IFIP International Conference on Theoretical Computer \nSci\u00adence, volume 1872 of Lecture Notes in Computer Sci\u00adence, pages 3 22. Springer-Verlag, August 2000. \n[7] Roberto M. Amadio and Denis Lugiez. On the reach\u00adability problem in cryptographic protocols. In Catus\u00adcia \nPalamidessi, editor, CONCUR 2000: Concurrency Theory (11th International Conference), volume 1877 of \nLecture Notes in Computer Science, pages 380 394. Springer-Verlag, August 2000. [8] Mihir Bellare and \nPhillip Rogaway. Entity authentica\u00adtion and key distribution. In Advances in Cryptology CRYPTO 94, volume \n773 of Lecture Notes in Com\u00adputer Science, pages 232 249. Springer-Verlag, 1993. [9] Chiara Bodei. Security \nIssues in Process Calculi. PhD thesis, Universit`a di Pisa, January 2000. [10] Chiara Bodei, Pierpaolo \nDegano, Flemming Nielson, and Hanne Riis Nielson. Control .ow analysis for the pi-calculus. In Davide \nSangiorgi and Robert de Simone, editors, CONCUR 98: Concurrency Theory (9th Inter\u00adnational Conference), \nvolume 1466 of Lecture Notes in Computer Science, pages 84 98. Springer, September 1998. [11] Chiara \nBodei, Pierpaolo Degano, Flemming Nielson, and Hanne Riis Nielson. Static analysis of processes for no \nread-up and no write-down. In Wolfgang Thomas, editor, Proceedings of the Second International Confer\u00adence \non Foundations of Software Science and Computa\u00adtion Structures (FoSSaCS 99), volume 1578 of Lecture Notes \nin Computer Science, pages 120 134. Springer, 1999. [12] Michele Boreale, Rocco De Nicola, and Rosario \nPugliese. Proof techniques for cryptographic processes. In Proceedings of the Fourteenth Annual IEEE \nSym\u00adposium on Logic in Computer Science, pages 157 166, July 1999. [13] Luca Cardelli. Mobility and security. \nIn F. L. Bauer and R. Steinbrueggen, editors, Foundations of Secure Computation, NATO Science Series, \npages 3 37. IOS Press, 2000. [14] Sylvain Conchon and Fabrice Le Fessant. Jocaml: Mobile agents for Objective-Caml. \nIn First Interna\u00adtional Symposium on Agent Systems and Applications (ASA 99)/Third International Symposium \non Mobile Agents (MA 99), pages 22 29, October 1999. [15] Core SDI S.A. ssh insertion attack. Available \nat http://www.core-sdi.com/soft/ssh/attack.txt, July 1998. [16] Mads Dam. Proving trust in systems of \nsecond-order processes. In Proceedings of the 31th Hawaii Inter\u00adnational Conference on System Sciences, \nvolume VII, pages 255 264, 1998. [17] W. Di.e and M. Hellman. New directions in cryp\u00adtography. IEEE Transactions \non Information Theory, IT-22(6):644 654, November 1976. [18] Whit.eld Di.e, Paul C. van Oorschot, and \nMichael J. Wiener. Authentication and authenticated key ex\u00adchanges. Designs, Codes and Cryptography, \n2:107 125, 1992. [19] Danny Dolev and Andrew C. Yao. On the security of public key protocols. IEEE Transactions \non Informa\u00adtion Theory, IT-29(12):198 208, March 1983. [20] C\u00b4edric Fournet and Georges Gonthier. A hierarchy \nof equivalences for asynchronous calculi. In Kim G. Larsen, Sven Skyum, and Glynn Winskel, editors, Pro\u00adceedings \nof the 25th International Colloquium on Au\u00adtomata, Languages and Programming, volume 1443 of Lecture \nNotes in Computer Science, pages 844 855. Springer, July 1998. [21] Alan O. Freier, Philip Karlton, and \nPaul C. Kocher. The SSL protocol: Version 3.0. Available at http:// home.netscape.com/eng/ssl3/draft302.txt, \nNovem\u00adber 1996. [22] Sha. Goldwasser and Mihir Bellare. Lecture notes on cryptography. Summer Course \nCryptography and Computer Security at MIT, 1996 1999, August 1999. [23] Sha. Goldwasser and Silvio Micali. \nProbabilistic en\u00adcryption. Journal of Computer and System Sciences, 28:270 299, April 1984. [24] Sha. \nGoldwasser, Silvio Micali, and Ronald Rivest. A digital signature scheme secure against adaptive chosen-message \nattack. SIAM Journal on Computing, 17:281 308, 1988. [25] R. Kemmerer, C. Meadows, and J. Millen. Three \nsys\u00adtem for cryptographic protocol analysis. Journal of Cryptology, 7(2):79 130, Spring 1994. [26] Hugo \nKrawczyk. SKEME: A versatile secure key ex\u00adchange mechanism for internet. In Proceedings of the Internet \nSociety Symposium on Network and Dis\u00adtributed Systems Security, February 1996. Available at http://bilbo.isu.edu/sndss/sndss96.html. \n[27] Ben Liblit and Alexander Aiken. Type systems for dis\u00adtributed data structures. In Proceedings of \nthe 27th ACM Symposium on Principles of Programming Lan\u00adguages, pages 199 213, January 2000. [28] P. \nLincoln, J. Mitchell, M. Mitchell, and A. Scedrov. A probabilistic poly-time framework for protocol anal\u00adysis. \nIn Proceedings of the Fifth ACM Conference on Computer and Communications Security, pages 112 121, 1998. \n[29] Gavin Lowe. Breaking and .xing the Needham-Schroeder public-key protocol using FDR. In Tools and \nAlgorithms for the Construction and Analysis of Systems, volume 1055 of Lecture Notes in Computer Science, \npages 147 166. Springer Verlag, 1996. [30] Alfred J. Menezes, Paul C. van Oorschot, and Scott A. Vanstone. \nHandbook of Applied Cryptography. CRC Press, 1996. [31] Robin Milner. Communication and Concurrency. \nIn\u00adternational Series in Computer Science. Prentice Hall, 1989. [32] Robin Milner. Communicating and \nMobile Systems: the p-Calculus. Cambridge University Press, 1999. [33] John C. Mitchell. Foundations \nfor Programming Lan\u00adguages. MIT Press, 1996. [34] John C. Mitchell, Mark Mitchell, and Ulrich Stern. \nAutomated analysis of cryptographic protocols using Murf. In Proceedings of the 1997 IEEE Symposium on \nSecurity and Privacy, pages 141 151, 1997. [35] Lawrence C. Paulson. The inductive approach to ver\u00adifying \ncryptographic protocols. Journal of Computer Security, 6(1 2):85 128, 1998. [36] Birgit P.tzmann, Matthias \nSchunter, and Michael Waidner. Cryptographic security of reactive systems (extended abstract). Electronic \nNotes in Theoretical Computer Science, 32, April 2000. [37] Benjamin C. Pierce and David N. Turner. Pict: \nA pro\u00adgramming language based on the pi-calculus. In Gordon Plotkin, Colin Stirling, and Mads Tofte, \neditors, Proof, Language and Interaction: Essays in Honour of Robin Milner, Foundations of Computing. \nMIT Press, May 2000. [38] D. Sangiorgi. On the bisimulation proof method. Jour\u00adnal of Mathematical Structures \nin Computer Science, 8:447 479, 1998. [39] Steve Schneider. Security properties and CSP. In Pro\u00adceedings \nof the 1996 IEEE Symposium on Security and Privacy, pages 174 187, 1996. [40] Bruce Schneier. Applied \nCryptography: Protocols, Al\u00adgorithms, and Source Code in C. John Wiley &#38; Sons, Inc., second edition, \n1996. [41] Stuart G. Stubblebine and Virgil D. Gligor. On message integrity in cryptographic protocols. \nIn Proceedings of the 1992 IEEE Symposium on Research in Security and Privacy, pages 85 104, 1992. [42] \nF. Javier Thayer F\u00b4abrega, Jonathan C. Herzog, and Joshua D. Guttman. Strand spaces: Why is a security \nprotocol correct? In Proceedings of the 1998 IEEE Symposium on Security and Privacy, pages 160 171, May \n1998. [43] Bj\u00a8orn Victor. The Fusion Calculus: Expressiveness and Symmetry in Mobile Processes. PhD thesis, \nDept. of Computer Systems, Uppsala University, Sweden, June 1998. [44] Andrew C. Yao. Theory and applications \nof trapdoor functions. In Proceedings of the 23rd Annual Sympo\u00adsium on Foundations of Computer Science \n(FOCS 82), pages 80 91, 1982.   \n\t\t\t", "proc_id": "360204", "abstract": "We study the interaction of the \"new\" construct with a rich but common form of (first-order) communication. This interaction is crucial in security protocols, which are the main motivating examples for our work; it also appears in other programming-language contexts. Specifically, we introduce a simple, general extension of the pi calculus with value passing, primitive functions, and equations among terms. We develop semantics and proof techniques for this extended language and apply them in reasoning about some security protocols.", "authors": [{"name": "Mart&#237;n Abadi", "author_profile_id": "81100547147", "affiliation": "Bell Labs Research, Lucent Technologies", "person_id": "PP39047996", "email_address": "", "orcid_id": ""}, {"name": "C&#233;dric Fournet", "author_profile_id": "81100547450", "affiliation": "Microsoft Research", "person_id": "PP14190246", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/360204.360213", "year": "2001", "article_id": "360213", "conference": "POPL", "title": "Mobile values, new names, and secure communication", "url": "http://dl.acm.org/citation.cfm?id=360213"}