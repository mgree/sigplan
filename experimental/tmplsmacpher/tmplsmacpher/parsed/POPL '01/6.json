{"article_publication_date": "01-01-2001", "fulltext": "\n Regular Expression Pattern Matching for XML Haruo Hosoya Benjamin Pierce Department of Computer and \nInformation Science University of Pennsylvania {haho soya, bcpierce }@c i s. upenn, edu Abstract We \npropose regular expression pattern matching as a core feature for programming languages for manipulating \nXML (and similar tree-structured data formats). We extend con- ventional pattern-matching facilities \nwith regular expression operators such as repetition (*), alternation (I), etc., that can match arbitrarily \nlong sequences of subtrees, allowing a compact pattern to extract data from the middle of a com- plex \nsequence. We show how to check standard notions of exhaustiveness and redundancy for these patterns. \nRegular expression patterns are intended to be used in languages whose type systems are also based on \nthe regular expression types. To avoid excessive type annotations, we develop a type inference scheme \nthat propagates type con- straints to pattern variables from the surrounding context. The type inference \nalgorithm translates types and patterns into regular tree automata and then works in terms of stan- dard \nclosure operations (union, intersection, and difference) on tree automata. The main technical challenge \nis dealing with the interaction of repetition and alternation patterns with the first-match policy, which \ngives rise to subtleties concerning both the termination and the precision of the analysis. We address \nthese issues by introducing a data structure representing closure operations lazily.  Introduction XML \n[XML] is a simple format for tree-structured data. As its popularity increases, a need is emerging for \nbetter pro- gramming language support for XML processing--in par- ticular, for (1) static analyses capable \nof guaranteeing that generated trees conform to an appropriate Document Type Definition (DTD) [XML] or \nto a schema in a richer language such as XML-Schema [XS00], DSD [KMS], or l~elax [Rel]; and (2) convenient \nprogramming constructs for tree manip- ulation. In previous work [HVP00], we proposed regular expres- \nsion types as a basis for static typechecking in a language for processing XML. Regular expression types \ncapture (and Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for profit or commercial \nadvan- tage and that copies bear this notice and the full citation on the first page. To copy otherwise, \n10republish, to post on servers or to redistribute to lists, requires prior specific permission and/or \na fee. POPL '01 1/O1 London, UK &#38;#169; 2001 ACM ISBN 1-58113-336-7/0110001 .-$5.00 generalize) the \nregular expression notations commonly found in schema languages for XML, and support a natural \"se-mantic\" \nnotion of subtyping. We argued that this flexibility was necessary to support smooth evolution of XML-based \nsystems and showed that subtype checking, though expo- nential in general (it reduces to checking language \ninclusion between tree automata), can be computed with acceptable efficiency for a range of practical \nexamples. In the present paper, we pursue the second question-- developing convenient programming constructs \nfor tree ma- nipulation in a statically typed setting. We propose regular expression pattern matching \nfor this purpose. Regular expression pattern matching is similar in spirit to the pattern matching facilities \nfound in languages of the ML family [BMS80, MTH90, LVD+96, etc.]. Its extra ex- pressiveness comes from \nthe use of regular expression types to dynamically match values. We illustrate this by an ex-ample. The \nfollowing declarations introduce a collection of reg- ular expression types describing records in a simple \naddress database. type Person = person[Name,~ail*,Tel?] type Name = name[String] type Email = email[String] \ntype Tel = tel[String] Type constructors of the form label[...] classify tree nodes with the label label \n(i.e., XML structures of the form <label>...</label>). Thus, the inhabitants of the types Name, F~ail, \nand Tel are all strings with an appropriate identifying label. Type constructors of the form T* denote \na sequence of arbitrarily many Ts, while T? denotes an op- tional T. Thus, the inhabitants of the type \nPerson are nodes labeled person whose content is a sequence consisting of a name, zero or more email \naddresses, and an optional tele- phone number. Using these types, we can write a regular expression pat- \ntern match that, given a value p of type Person, checks whether p contains a zel field, and if so, extracts \nthe con- tents of name and tel. match p with person[name[n], Email*, tel[t]] --~ (* do some stuff involvin \nE n and t *)  person[p] --~ (* do other stuff *) The first case of the match expression matches a \nnode la- beled person whose content is a sequence of a name, zero or more emails, and a tel. In this \ncase, we bind the variable n to the name's content and t to the tel's content. The second case matches \na label person with any content and binds p to the content. The second case is invoked only when the \nfirst case fails, i.e., when there is no Tel compo- nent. Note how the first pattern uses the regular \nexpression type Email* to \"jump over\" an arbitrary-length sequence and extract the tel node following \nit. This style of match- ing (which goes beyond ML's capabilities) is often useful in XML processing, \nsince XML data structures often con- tain sequences where repetitive, optional, and fixed parts are mixed \ntogether; regular expression pattern matching allows direct access to the parts of such sequences. We \nconcentrate in this paper on pattern matching with a \"single-match\" semantics, which yields just one \nbinding for a given pattern match. We also follow ML in adopting a \"first- match\" policy, which allows \nambiguous patterns and gives higher priority to patterns appearing earlier. A different alternative that \nis arguably more natural in the setting of query languages and document processing languages [DFF +, \nAQM+97, CS98, CG00a, NS00, NS98, Mur97] is an \"all-matches\" style, where each pattern match yields a \nset of bindings. We will compare the two styles at several points in what follows. To support regular \nexpression pattern matching in a stat- ically typed programming language, it is important that the compiler \nbe able to infer the types of most variable bindings in patterns (otherwise, the type annotations tend \nto become quite heavy). We propose a type inference scheme that au-tomatically computes types for pattern \nvariables. The type inference scheme is \"local\" in the sense that it focuses only on pattern matches; \nit takes a pattern match and a type for the values being matched against, and propagates the type constraints \nthrough the patterns to the pattern variables. For example, in the pattern match above, given the input \ntype Person, type inference computes the type String for the variables n and t and the type (Name,Eraail*) \nfor the variable p. The intuition behind the type for p is that, since all persons with tel are captured \nby the first pattern, only persons with no tel can be matched by the second pattern. Our type inference \nalgorithm represents both types and patterns in the form of regular tree automata and propagates type \ninformation through patterns in a top-down manner (i.e., it starts with a given type and pattern, calculates \ntypes for the immediate substructures of the pattern, and repeats this recursively). The technical difficulties \nin the develop- ment of the algorithm arise from the interaction between the first-match policy and the \nrepetition operator. The first- match policy implies that, in order to maintain the precision of our \nanalysis, we need to be able to reason about the types of values that did not match preceding patterns. \nTo this end, we exploit the closure properties of tree automata--in par- ticular, the (language-)di~erence \noperation. However, since repetition patterns are translated to tree automata whose state transition \nfunctions contain loops, the algorithm re-quires some care to ensure termination of the algorithm. A \nnaively constructed algorithm might infinitely traverse the patterns; more seriously, if the algorithm \nuses the closure operations each time it encounters the same state, an un-bounded number of types may \nbe propagated to the same state (this is discussed further in Section 4.2). We address this problem by \nintroducing a data structure representing closure operations lazily. As a result, we achieve exact type \ninference: it predicts a value for a bound variable if and only if the variable can actually be bound \nto this value as a result of a successful match of a value from the input type. Previous papers on type \ninference for pattern match- ing have considered either recursion [MS99, PV00, Mur97] or the first-matching \npolicy [WC94, PS90], but, as far as we know, no papers have treated both. In summary, the main contributions \nof this work are: (1) the motivation and design of regular expression pattern matching; and (2) the \nalgorithm for propagating types to pattern variables from the surrounding context. The rest of the paper \nis organized as follows. In the following section, we illustrate regular expression pattern matching \nby several examples. Section 3 gives basic defi- nitions of types and patterns and sketches the translation \nfrom the user-level external syntax to the tree-antomata-based internal representation. Section 4 develops \nthe type inference algorithm and proves its correctness. Section 5 discusses the relationship of our \nwork with other work. Sec- tion 6 concludes and suggests some possible directions for future research. \nAppendix A gives some technical details omitted from the earlier discussion of the closure opera- tions. \nFor brevity, proofs are omitted in this summary. They can be found in an expanded version, available \nelectroni- cally [HPOOa]. We have used regular expression pattern matching (and regular expression types) \nin the design of a statically typed XML processing language called XDuce (\"transduce\") [HP00b]. Interested \nreaders are invited to visit the XDuce home page http://www. cis. upenn, edu/~hahos oya/xduce  for more \ninformation on the language as a whole. 2 Examples We give a series of examples motivating our design \nof pat- tern matching and illustrating the associated algorithmic problems. 2.1 Regular Expression Types \nEach type in our language denotes a set of sequences. Types like String and tel[String] denote singleton \nsequences; the type Tel* denotes sequences formed by repeating the singleton sequence Tel any finite \nnumber of times. So each element of the type person [Tel*] is a singleton sequence la- beled with person, \ncontaining an arbitrary-length sequence of Tels. If S and T are types, then the type S,T denotes all \nthe sequences formed by concatenating a sequence from S and a sequence from T. The comma operator is \nassociative: the types (Name,Tel*) ,Addr and Name, (Tel*,Addr) have exactly the same set of elements. \n(Comma is not commuta-tive, however: we consider only ordered sequences.) As the unit element for the \ncomma operator, we have the empty sequence type, written (). Thus, Name, () and () ,Name are equivalent \nto Name. The subtype relation between two types is simply inclu- sion between the sets of sequences that \nthey denote. (See Section 3.3 for a formal presentation of this definition.) For example, (Name*,Tel*) \nis a subtype of (Name iTel)* since the first one is more restrictive than the second. That is, Names \nmust appear before any Tel in the first type, while Names and Tels can appear in any order in the second \ntype. 58 2.2 Regular Expression Pattern Matching As in ML, a regular expression pattern match consists \nof one or more clauses, each of which is a pair of a pattern and a body. The pattern describes the shape \nof input values that we want to identify, and may contain bound variables for extracting subcomponents \nof the input value. The body is an expression in some term language (whose details we do not need to \nbe precise about, for purposes of this paper) that is executed when a match against the pattern succeeds. \nTo introduce the notation, consider the following simple pattern match expression, which analyzes a value \nof type Person. match p with person[name[n], tel[ill I person [name [n], rest] --~ ..\u00b0 The first case \nmatches a label person whose content is a se- quence of a name node and a tel node. It binds the variable \nn to the name's content and t to the name's content while evaluating the body. The second case is similar \nexcept that it binds the variable rest to the (possibly empty) sequence follows the name node. Patterns \ncan contain regular expression types. For exam- ple, the following pattern match contains the type Email*. \nmatch p with person[name[n], e as Email*, tel[ill I person[name[n], e as Email*] --~ ... This example \nis similar to the previous one except that the variable e is bound to the intermediate sequence of zero \nor more emails between name and tel. (In general, an \"as\" pattern \"x as P\" performs matching with p as \nwell as bind- ing x to the whole sequence that matches P. Notice also that we treat types in the same \ncategory as patterns.) The use of the repetition operator * yields an iterative behavior dur- ing pattern \nmatching. That is, when the pattern matcher looks at the pattern (e as F~nail*), no hint is available \nabout how many emails there are. Therefore the marcher must walk through the input value until it finds \nthe end of the chain of emails. This matching of arbitrary length se- quences is beyond ML pattern matching, \nand is often quite useful in programming with XML. For example, the pattern above is substantially more \ncompact than explicitly writ- ing a recursive function that traverses the sequence, as we would need \nto do if only ML-style matching of fixed-length sequences were supported. The usefulness of matching \nagainst regular expression types is yet more evident in the following complex pattern, which extracts \nthe subcomponents of an HTML table.  match t with table[cap as Caption?, col as (Col*IColgroup*), \nhd as Thead, ft as Tfoot?, bd as (Tbody+ITr\u00f7)] An HTML table consists of several optional fields (Caption? \nand Tfoot?) and repetitive fields (Co1., Colgroup*, Tbody+, and Tr+). (We assume the types Caption, Col, \netc., to be defined elsewhere.) Again, by matching against regular ex- pression types, we can directly \npick out each subcomponent, whose position in the input sequence is statically unknown. Imagine equivalent \ncode written only with simpler ML-like pattern matching.  2.3 Ambiguous Patterns Regular expression \npattern matches can have two kinds of ambiguity. The first kind of ambiguity occurs when multiple pat- \nterns match the same input value. For example, the pat- terns in the first example above are ambiguous, \nsince any value that matches the first pattern also matches the sec- ond pattern. In such a case, we \nsimply take the first match- ing pattern (\"first-match policy\"). The reason why we take this policy rather \nthan simply disallowing ambiguity is the same as in ML: it makes it easy to write a \"default case\" at \nthe end of a pattern match, whereas restricting to non- ambiguous sets of patterns would force us to \nwrite a cum- bersome final pattern explicitly matching the \"negation\" of the other cases. The second \nform of ambiguity occurs when a single pat- tern can match a given value in different ways, giving rise \nto different bindings for the pattern variables. This possibil- ity is intrinsic to regular expression \npattern matching. For example, in the pattern match e with el as Email*, e2 as Email* which splits a \nsequence of emails into two, it is ambiguous how many amails the variable el should take. We resolve \nthis ambiguity by adopting a \"longest match\" policy where patterns appearing earlier have higher priority \n(as in most implementations of regular expression pattern matching on strings). In the example, el is \nbound to the whole input sequence, e2 to the empty sequence. Again, an alternative design choice would \nbe to disal- low such ambiguity. However, the longest-match policy can make patterns more concise. Consider \nthe contents of an HTML description, which is a sequence of type (Dr [Dd)*, where Dt (term) and Dd (description) \nare defined as dt [... ] and dd[...], respectively (the content types.., are not im- portant here). Suppose \nwe want to format this sequence in such a way that each term is associated with all the follow- ing descriptions \nbefore the next term (if any). We may write an iteration for scanning the sequence where, at each step, \nthe following pattern match analyzes cases on the current sequence. match I with dt[t], d as Dd*, rest \n--~ (* display term t with d, and do rest *) I () --~ (* finish *) Here, the first case matches a sequence \nbeginning with dr, where we extract the content of the dt and take the following dds as many as possible, \nusing the longest match. Note that, without the longest match, it is ambiguous how many dds are taken \nby each of the consecutive patterns (d as Dd*) and rest. If we rewrite this pattern to an unambiguous \none, the variable rest must be restricted not to match a sequence that begins with dd, resulting in a \nsomewhat more cumbersome pattern: dt[t], d as Dd*, rest as ((Dt,(DdlDt)*) I O) The longest-match and \nfirst-match policies turn out to fit cleanly together in the same framework, as we shall see in Section \n3.1. 2.4 Exhaustiveness and Redundancy Checks We support the usual checks for exhaustiveness and redun- \ndancy of pattern matches. For these checks, we assume that the \"domain\" type (i.e., the type of the input \nvalues) is known from the context. A pattern match is then exhaus- tive iff every value from the domain \ntype can be matched by at least one of the patterns. Likewise, a clause in a pat- tern match is redundant \niff all the input values that can be matched by the pattern are covered by the preceding pat- terns. \n Although these definitions themselves are the same as usual (cf., for example, [MTHg0, page 30]), checking \nthem is somewhat more demanding. Consider the following pattern match, which, given a sequence of persons, \nfinds the first person node with a tel field and extracts the name and tel fields from this person. match \np with person[Name, Email*]*, person[name[n], Email*, tel[I;]], rest; o.. I person[Name, Email*]* This \npattern match is \"obviously\" exhaustive--the first clause captures the sequences containing at least \none person with tel and the second captures the sequences containing no such person. But how can a machine \nfigure this out? Sec- tion 3 describes our approach, which is based on language inclusion between regular \ntree automata. 2.5 Type Inference Since we intend regular expression pattern matching to be used in \na typed language, we need a mechanism for infer- ring types for variables in patterns, to avoid excessive \ntype annotations. The type inference algorithm assumes that a domain type T for the pattern match is \ngiven by the context. It then infers an exact type U for each pattern variable x. That is, the type U \ncontains all and only the values v such that x can be bound to v as a result of successful match of the \nwhole pattern against a value from T. Since the semantics of pattern matching uses a first-match policy, \nobtaining this degree of precision re-quires some care. For example, consider the follow-ing pattern \nmatch, where the domain type is Person = person [Name, FJnail*, Tel?] match p with person [name [n], \ntel [t] ] I person[name[n], rest] o.o We can easily see that n and t should be given String. But what \ntype should be given to the variable rest? At first glance, the answer may appear to be (gmail*,'rel?), \nbecause the content type of person is (Name ,Emil* ,Tel?), according to the definition of the type Person. \nBut in fact, the precise type for rest is (Email+,Tel?) [ O. To see why, recall that the second case \nmatches values that are not matched by the first case. This means that, if a value falls in the first \ncase, the name in the value is not immediately followed by a tel. Therefore what follows after the name \nshould be either one or more emails or nothing at all. How do we calculate this type? The trick is to \ncal-culate a set-difference between types. In the above ex-ample, the type of the values that are not \nmatched by the first case is computed by the difference between person [Name, Email*, Tel?] and person \n[Name, Tell, which is person [Name, ( (Email+, Tel?) J ()) ]. The computation of difference is feasible \nbecause types are equivalent to tree au- tomata and tree automata are closed under difference (Sec- tion \n3.4). The type person[Name, ((Email+,Tel?) I O)] is then propagated to the rest variable by simply checking \nthe matching of the label person of the type and the pat- tern, and similarly for the label name. However, \nwe have to carefully propagate types through repetition patterns (*) so that the algorithm terminates. \nFurther, the combination of repetition patterns and choice patterns with the first-match policy requires \na delicate construction of the inference algo- rithm, as we will explain in Section 4. So far, we have \nseen inference for \"bare\" variable pat- terns (which match any values). The type inference can also compute \na type for an \"as-ed\" variable of the form (x as P). The inferred type can be more refined than the type \nthat can be formed from the associated pattern P. For example, con- sider the following pattern match \n(where the domain type is Person): match p with person[Name, x as (EmailITel)+] --~ ... .\u00b0.  Here, the \npattern (Email I Tel) + imposes the restriction that x can be bound to sequences of length one or more. \nHowever, we know from the domain type that at most one tel may follow smalls. Thus, type inference computes \na more precise type: (Email+, Tel?) ] Tel  This refinement is useful since the body of the pattern match \nmay actually depend on the fact that there is at most one tel and type inference alleviates the burden \nof writing the more verbose annotation. Our type inference method works only for variables that appear \nin the tail position in a sequence (we call such vari- ables \"tall variables.\"), for a technical reason \nexplained in Section 3.2. We require each non-tail pattern variable to be supplied with an as pattern, \nso that we can construct a type for the variable from the supplied pattern in a straight- forward way. \nFortunately, this limitation turns out not to be too annoying in practice: in our experience, the most \ncommon uses of pattern variables are (1) binding the whole contents of a label (as in the examples in \nSection 2.2), and (2) binding the \"rest\" of a sequence during iteration over a repetitive sequence (as \nin the example in Section 2.4). Both of these uses occur in tail positions. 3 Syntax and Semantics For \npurposes of formalization (and implementation), it is useful to distinguish two forms of types--external \nand internal--and two corresponding forms of patterns. The ex- ternal form is the one that the user actually \nreads and writes; all the examples in the previous sections are in this form. Internally, however, the \ntype inference algorithm uses a sim- pler representation to streamline both the implementation and its \naccompanying correctness proofs. Below, we give the syntax of each form and the semantics of the internal \nform, and sketch the translation from external to internal form. Then we define inclusion relations and \nclosure operations on the internal form, and give simple methods for checking exhaustiveness and redundancy \nof patterns. 3.1 External Form For brevity, we omit base values (like strings) and the cor- responding \ntypes and patterns from our formalization. We assume a countably infinite set of labels, ranged over \nby 1, and a countably infinite set of type names, ranged over by X. Type expressions are then defined \nas follows. T ::= () empty sequence X type name 1 IT] label T, T concatenation T J T union The bindings \nof type names are given by a single, global set E of type definitions of the following form. type X = \nT The body of each definition may mention any of the defined type names (in particular, definitions may \nbe recursive). We regard E as a mapping from type names to their bodies. We represent the Kleene closure \nT* of a type T by a type X that is recursively defined as follows. type X = T,X I 0 The other regular \nexpression constructors are defined as fol- lows. T+ ~ T , T* T? .~ T [ () As we have defined them so \nfar,types correspond to ar- bitrary context-free grammars. Since we instead want types to correspond \nto regular tree languages, we impose a syntac- tic restriction, called well-formedness, on types. (The \nreason why we want to restrict attention to regular tree languages is that the inclusion problem for \ncontext-free grammars is undecidable [HU79].) Intuitively, well-formedness requires unguarded (i.e., \nnot enclosed by a label) recursive uses of type names to occur only in tail positions. See [HVP00] for \nthe formal definition. We assume a countably infinite set of pattern names, ranged over by Y, and a countably \ninfinite set of variables, ranged over by x. Pattern expressions are then defined as follows. x bare \nvariable x as P as-ed variable 0 empty sequence Y pattern name 1 [P] label P, P concatenation P \n]P choice (Notice that the syntax of pattern expressions differs from that of type expressions only in \nvariable patterns.) The bindings of pattern names are given by a single, global, mu- tually recursive \nset F of pattern definitions of the following form. pat Y = P For convenience, we assume that F includes \nall the type definitions in E where the type expressions appearing in E are considered as pattern expressions \nin the evident way. Pattern expressions must obey the same well-formedness re- striction as types. In \nwriting pattern expressions, we use the same abbreviations for regular expression operators (*, +, and \n7). We write BV(P) for bound variables appearing in P and FN(P) for free pattern names appearing P. The \nlongest-match policy mentioned in Section 2.3 ac- tually arises from these abbreviations and the first-match \npolicy. That is, Email* is defined as a variable Y that is recursively defined as pat Y = Email,Y [ () \n and, with the first-match policy, the first branch (Email, Y) is taken as often as possible, which accounts \nfor the longest- match policy. The same argument is applied to the other operator + and ?. Notice that \nthe order of union clauses in the definitions of the abbreviations matters for the semantics of pattern \nmatching. We impose an additional syntactic restriction lineari~y on patterns in order to make sure that \npattern matching always yields environments with no missing bindings and no multiple bindings for the \nsame variable. For simple ML- style patterns, linearity is just a check that each variable appears in \na pattern just once. In the present setting, we need to extend this notion to patterns with choices and \nre- cursion. Intuitively, a linear variable must occur exactly once in each branch of a choice, and must \nbe unreachable from itself. The formal definition is given in the full version of the paper [HP00a]. \nNotice that, in the above definition of patterns, nothing prevents us from writing a single pattern that \ntraverses a tree to an arbitrary depth. For example, consider the fol- lowing recursively defined type \nfor binary trees, with two forms of leaves, b[] and c[], and internal nodes labeled a, type T = a[T],T \n[ b[] [ c[] and the match expression  match t with P -4 ... where P is recursively defined as follows: \n  pat P = a[P],T [ a[T],P [ x as b[] The pattern P matches a tree that has at least one b [], and yields \nexactly one binding of the variable x. Since P has the choice of patterns alP] ,T and a[T] ,P in this \norder, the first- match policy ensures that the variable x is bound to the first b [] in depth-first \norder. Although this \"deep\" matching is somewhat attractive, we are not sure about its usefulness, because, \nafter obtaining the first b [] as above, it is not clear what to do to get the next one, or more generally \nto iterate through all the b[]s in the input tree. (By contrast, this sort of deep matching would be \nmore clearly useful if we had chosen the \"all-matches\" semantics instead.)  3.2 Internal Form Values, \ntypes, and patterns in the external form are labeled trees of arbitrary arity (i.e., any node can have \nan arbitrary number of children). In the internal form, we consider only binary trees. The labels I in \nthe internal form are the same as labels in the external form. Internal (binary) tree values are defined \nby the following syntax. t ::= e leaf l(t,t) label There is an isomorphism between binary trees and \nsequences of arbitrary-arity trees. That is, e corresponds to the empty sequence, while l(t, t') corresponds \nto a sequence whose head is a label 1 where t corresponds to the content of 1 and t' corresponds to the \nremainder of the sequence. For example, from the arbitrary-arity tree    person[name[I, email[]] \n we can read off the binary tree person(narae(e, email (e, e)), e), and vice versa. For types, we begin \nas before by assuming a countably infinite set of (internal) type states, ranged over by X. A binary \ntree automaton M is a finite mapping from states to (internal) type expressions, where type expressions \nT are defined as follows: T ::= 0 empty set e leaf T ] T union l(z,x) label There is an one-to-one correspondence \nbetween external and internal types, following the same intuition as for values. For example, the external \ntype person[narae [], ema\u00b1l []*] corresponds to the internal type person(X1, X0) where the states X1 \nand Xo are defined by the corresponding automa- ton M as follows. M(Xo) = e M(X~) = name(Xo, X2) M(X2) \n= email(Xo, X2) I e The formalization of the translation from external types to internal types can be \nfound in [HVP00]. We use the metavariable A to range over both type states and type expressions--jointly \ncalled types---since it is often convenient to treat them uniformly. The free states FS(T) of a type \nexpression T are the states appearing in T. This is extended to the free states of an automaton M by \nFS(M) = U {FS(M(X)) I X E dom(M)}. We assume that every automaton M satisfies FS(M) C_ dora(M). The semantics \nof types is given by the acceptance re- lation t E A (relative to some tree automaton M), which is read \n\"tree t has type A\" or \"t is accepted by A.\" (We usually elide M, to lighten the notation.) The rules \nfor the acceptance relation are as follows. t E M(X) (Acc-ST) tEX e E e (Aco-EPS) teT~ (Acc-OR1) t e \nTl l T2 t eT2 (Acc-OR2) t ~ Tx l T2 tl E Xl t2 E X2 (Acc-LAB) l(t~, t2) e l(x~, x~) The definition of \npatterns is similar to that of types. We assume a countably infinite set of pattern states, ranged over \nby Y. Pattern variables x are the same as in the external form. A pattern automaton is a finite mapping \nfrom states to (internal) pattern expressions, which are defined as follows. P ::= x : P variable 0 failure \nT wild-card e leaf P [ P choice l(V, Y) label Note that, in the internal form, we drop bare variable \npat- terns, but introduce the wild-card pattern T. A bare ex- ternal variable pattern x is encoded as \nan internal pattern x : T. We use the metavariable D to range over both pat- tern states and pattern \nexpressions, jointly called patterns. We write B V(P) for the variables occurring in P. The semantics \nof patterns is given by the matching rela- tion t E D ~ V (relative to a pattern automaton N, which we \nnormally elide), where an environment V is a finite map- ping from variables to trees. This relation \nis read \"tree t is matched by pattern D, yielding environment V.\" The rules for the matching relation \nare as follows. t E N(Y) ~ V (MAT-ST) tEY=~V t E P =t~ V (MAT-BIND) t e x : P =~ VU{(z~ t)} t E T ~ 0 \n(MAT-ANY) e E e ~ 0 (MAT-EPs) tEP~V (MAT-OR1) t e P~ I P2 =~ v t\u00a2P~ t~P2~ V (MAT-OR2)  P11v2~v t~ E \nY~ ~ Vx t2 E Y2 =~ V2 (MAT-LAB)  t(tl, t2) ~ l(Y1, Y2) ~ v~ u v~ We write t E D to mean t E D =~ V for \nsome V. Also, we writetED~(x~-+u) whentED~VandV(x)=ufor some V. Note that the matching relation is based \non a \"first-match\" policy, as in ML: when a tree matches both branches of a choice pattern, we take the \nfirst one. This follows from the fact that the rule MAT-OR2 is applicable only when MAT-OR1 is not. The \ncorrespondence between external patterns and inter- nal patterns is similar to what we have seen for \ntypes, except for the treatment of variable patterns. External patterns can contain variable patterns \nthat are not in tail positions. For example, the following pattern contains a non-tail variable pattern \nlabeled with the variable x: (X as (name[],email[])),tel[] Such a pattern cannot be directly translated \nto an internal pattern because a variable pattern in the internal form can only be bound to a whole subtree, \nwhich, in the external form, corresponds to a sub-sequence from some point to the tail. To deal with \nthis discrepancy, we transform each non- tail variable pattern labeled with a variable x to a pair of \ntail variable patterns labeled with new variables Xb and x~. The scope of the variable pattern labeled \nXb opens at the beginning of the original x pattern and closes at the tail; the scope of the variable \nx~ opens at right after the end of the original x pattern and closed at the tail. Thus, we transform \nthe above pattern to (Xb as (name[],email[],(xe as tel[l))). Now, since the newly introduced variable \npatterns both ex- tend all the way to the end of the sequence, we can translate the whole pattern to \nthe internal pattern  Xb : name (Xo, Xi) where Xo and Xi are defined by the automaton N as follows: \n N(Xo) = e g(xl) = email(Xo, X2) N(X2) = xo : tel(Xo, Xo) Finally, since the body of the pattern match \nactually wants to use the original variable x instead of the new variables Xb and xe, we insert a bit \nof extra code, at the beginning of the body, that recovers the original behavior. This extra code \"trims \noff\" the sequence assigned to xe from the se-quence assigned to Xb (note that the former is a suffix \nof the latter), and binds the original variable x to the result. The formalization of the translation \nof patterns can be found in [HP00a]. As we mentioned in Section 2.5, our type inference method cannot \ncompute exact types for non-tail variables. To see why, consider the following pattern with the domain \ntype (T,T?). (x as T), T? This pattern is encoded as X b as (T, (xe as T?)) by the translation described \nabove. From the type inference algorithm described later (in Section 4), we will obtain the type (T,T?) \nfor Xb and T? for x\u00a2. But it is not immediately clear how to obtain the desired type T for x from these \ntwo. Naively, it seems we want to compute a type such that each inhabitant t is obtained by taking some \ntree tb from (T,T?) and some tree t~ from T? and then cutting off the suffix Ce from tb. But the type \nwe get by this calculation is (T,T I T I ()), which is bigger than we want. How to infer exact types \nfor non-tail variables is still an open question. In what follows, all the definitions are implicitly \nparam- eterized on the tree automaton and the pattern automaton that define the types and patterns appearing \nthere. In places where we are talking about only a single tree automaton and a single pattern automaton, \nwe simply assume a \"global\" tree automaton M and a global pattern automaton N. In a few cases, where \nwe are dealing with operations that cre= ate new types, we will need to talk explicitly about the tree \nautomaton before the creation and the one after. Finally, whenever we talk about a type A and a pat-tern \nD at the same time, we assume either that they are both states or that they are a type expression and \na pattern expression. 3.3 Inclusion We define subtyping as inclusion between the sets of trees in the \ntwo given types. Since types are represented as tree automata, subtyping can be decided by an algorithm \nfor checking inclusion of regular tree languages [Sei90]. (The complexity of this decision problem is \nexponential in the worse case, but algorithms are known that appear to behave well on practical examples \n[HVP00].) For what follows, we must also define an inclusion relation between types and patterns. 3.3.1 \nDefinition [Subtyping and Inclusion]: A type A is a subtype of a type B, written A <: B, if t C A implies \nt 6 B for all t. A type A is included in a pattern D, written A <: D, if t 6 A implies t E D for all \nt. Using the inclusion relation between types and patterns, exhaustiveness of pattern matches can be \ndefined as follows: 3.3.2 Definition [Exhaustiveness]: A pattern match P1 ---+ el [ ... [ Pn ~ e~ is \nezhaustive with respect to a type T if T<: PiI...IP..  3.4 Closure Operations The check for redundancy \nof pattern matches uses an inter- section operation that takes a type and a pattern as inputs and returns \na type representing their intersection: 3.4.1 Definition [Intersection]: A type B is an intersec- tion \nof a type A and a pattern D, written A N D =~ B, if t 6 B ifft 6 A and t 6 D. That is, an intersection \nof A and D represents the set of trees that are in the type A and also match the pattern D. The redundancy \ncondition can now be expressed as follows: 3.4.2 Definition [Redundancy]: In a pattern match Pl \"-~ et \nI \"\" I P~ \"-~ e~, a pattern Pi is redundant with respect to a type T if, for some U, T n P~ ~ U A U <: \nPi I . . . I Pi- i . That is, a pattern is redundant if it can match only trees already matched by the \npreceding patterns. 3.4.3 Proposition: For all types A defined under a tree automaton M and patterns \nD defined under a pattern au- tomaton N, we can effectively calculate a type B defined under a tree automaton \nM' D M such that A N D ~ B. The actual algorithm for the intersection operation can be found in Appendix \nA. Our type inference algorithm needs to calculate not only intersections of types and patterns, but \nalso differences be- tween types and patterns. If T is the type of the input trees to a pattern P1 I \nP2, we can infer that the type for the trees that can be matched by P1 is the intersection of T and P1, \nwhile the type for the trees matched by P2 is the differ- ence between T and P1 (i.e., those trees not \nmatched by the preceding pattern). One might now expect to define a difference operation just as we did \nfor the intersection operation and to use these operations in building the type inference algorithm. \nHow-ever, this approach turns out to be problematic. To see why, notice that the above proposition tells \nthat the types re- turned by the intersection operation may in general contain freshly generated states \nthat were not in the input types or patterns (and the same holds for the difference operation). This \nbecomes an issue in our type inference algorithm. If one step of the algorithm uses the results of the \noperations in cal- culating partial results that become inputs to the next step, then it becomes difficult \nto place a bound on the number of \"distinct states\" encountered by the algorithm, making it difficult \nto guarantee termination. We will come back to this point in Section 4.2, where we define a data structure \nfor representing intersections and differences of types and patterns without actually calculating them. \n4 Type Inference for Pattern Matching We now consider the problem of inferring types for the vari- ables \nbound by a pattern, given the domain type of the whole pattern. 4.1 Specification We assume that a domain \ntype T and a pattern P are given. We want to know the \"range\" of each variable ~--the set of all and \nonly the trees that x can be bound to as a result of a successful match of a tree from T against P. 4.1.1 \nDefinition [Range]: The range of P with respect to T, written pT,P, is the function mapping each variable \nx that is reachable from P to the set {u I 3t. t E T ^ t E P ~ (x ~ u)}. A type environment P (mapping \nvariables to types) represents pT, P if U E F(x) implies u E pT'P(x), and vice versa, for all x. Given \na type T and a pattern P, the result of type infer- ence should be a type environment P representing \nthe range of P with respect to T.  4.2 Highlights of the Algorithm Given a pattern P and its domain \ntype T, the goal of our type inference algorithm is to obtain a domain type T' for each subpattern P' \nof P, where T' represents the set of trees that are matched by P' as a result of a successful match of \na tree from T against P. Having computed domain types for all subpatterns, the range of P can be obtained \nas a mapping from each variable x to the union of the domain types for all the variable patterns binding \nx. The algorithm proceeds by a top-down propagation of type information through subpatterns. We begin \nwith the domain type T for the whole pattern P. For each immediate subpattern P' of P, we compute its \ndomain type T' from T and P, and recursively apply the same operation to all the subpatterns. For example, \nconsider the labeled type T --l(X1, X2) where the global tree automaton M defines M(X1) = ~ I I(X2,X2) \nM(X2) = and the labeled pattern P = I(Y1,Y2) where the pattern automaton N defines N(Y1) = yl : T N(Y2) \n= y2 : T. We compute a domain type for each subcomponent of P by taking the corresponding subcomponent \nof T. For the first subcomponent Y1 of P (which expands to yl : Y), we obtain the domain type e ] l(X2, \nX2) from the first subcomponent of T; similarly, for the second subcomponent Y1 of P (which expands to \ny2 : 7\"~, we obtain the domain type e from the second subcomponent of T. From these domain types, we \ncan calculate the type environment {yl : (e I l(X2, X2)), y2 : e} as the result of the whole type inference. \nChoice patterns need careful treatment because their first-match policy gives rise to complex control \nflows. Sup-pose T is a domain type for the choice pattern P1 I P2. We want to obtain a domain type for \neach of the subpatterns P1 and P2. Since the domain type T1 for P1 should denote the set of trees from \nT that are matched by P1, the type T1 can be characterized by the intersection of T and P1. On the other \nhand, since the domain type T2 for P2 should denote the set of trees from T that are not matched by the \nfirst pattern, the type T2 can be characterized by the difference between T and P1. Since patterns can \nbe recursive, we need to do some extra work to make sure that the propagation described above will always \nterminate. We apply a standard technique used in many type-related analyses, keeping track of all the \ninputs to recursive calls to the algorithm and immediately return- ing when the same input appears for \nthe second time (the intuition being that processing the same input again will not change the final result). \nThe termination of the algorithm then follows from the fact that there are only finitely many possible \ninputs. Typical uses of this technique can be found in recursive subtyping algorithms [GLP00, HVP00]. \nIn the present setting, since each input to the algorithm is a pair of a type and a pattern, we keep \ntrack of such pairs. (It is not sufficient to keep to track of only the patterns we have already seen. \nSuppose that we have already seen a pattern P with a domain type T~ but encounter the same pattern P \nwith a different domain type T', in particular, larger than T. Since the pattern P may match more trees \nthan those from T, we need to go through P again with the new domain type T'.) We need one additional \ntrick, however, to ensure termi- nation. In the propagation of types for choice patterns, if we simply \ncompute the intersection of T and P1 and the difference between T and P1, we can create \"new\" states \nin the resulting types (cf. Proposition 3.4.3). This means that eration isect is defined as follows. \nwe cannot guarantee that there are only finitely many types encountered by the algorithm, which makes \nit difficult to ensure termination. Instead, our algorithm delays actually calculating intersections \nand differences by explicitly ma- nipulating expressions containing what we call \"compound states,\" which \nare a form composed of intersections, differ- ences, and the states appearing in the input type and pat- \ntern. Because there are only a finite number of such states, only finitely many compound states can be \ngenerated, en-suring termination. 4.3 Preliminaries A compound state X consists of a single type state, \na set of \"intersecting\" pattern states, and a set of \"sub-tracting\" pattern states. Intuitively, X denotes \nthe set of trees that are in the type state and also in each in- tersecting pattern state, but not in \nany s_ubtracting pat- tern state. Formally, a compound state X has the form X N {Y1 ... Ym}\\{Z1 ... Zn}, \nwhere X is a state and all the Ys and Zs are pattern states. We write XnW for the com- pound state X \nn {Y1 .. Ym, W}\\{Z1... Z,~} and X\\W for X n {rl... Y,~}\\{Z1... Z., W}. Further, we adapt several definitions \non types given in Section 3.2 to handle compound states. Compound type ex- pressions T are just like \ntype expressions except that they contain compound states instead of type states: 7::=\u00a2 TIT l(X,X) We \nuse the metavariable A to range over both compound states and compound type expressions, jointly__ known \nas compound types. The acceptance relation t E A is defined for compound types just as it is for types, \nplus the following cases: tEx tEY (DAcc-IsEcT) t ~ xnY rEX q t Y m (DAcc-DIFF) t e X\\Y Inclusion A <: \nD means that t E A implies t E D for all t. Using compound types, we can now define intersection and \ndifference operations that do not introduce new states (unlike the intersection operation defined previously). \nThese operations take a compound type expression and a pattern expression and returns a compound type \nrepresenting their intersection or difference. The \"compound\" intersection op- T isect 0 = 0 0 isect \nP = 0 'Tisectx:P = 7isectP isect 7- = e isect e = e isectl(Y1,Y2) = (_~1 I T2) isect P = (71 isect P) \nI (T2 isect P) T isect (P1 I P2) = (T isect P1) ] (T isect P2) l(Xl,X2) isect e = 0 l('Xl,'X2) isect \nI'(Y1,Y2) = 0 l # l' I(X1,X2) isect I(Y1,Y2) = I(Xlf'IY1,X2OY2) Similarly, the following defines the \n\"compound\" difference operation diff. d~ff 0 = Tdiff x : P = T diff P {~ diff P = 0 TdiffT = 0 e diff \ne = 0 e diff l(Y1, Y2) = e (71 172) diffP = (T~diffP) l(72diffP) 7diff (P~ ]P2) = (TdiffPi) diffP2 l(Xl,X2) \ndiff e = I(X1,X2) i(Xl,X2) diff l'(Y1,Y2) = l(Xl,X2) l # l' t(xl,x~) cliff t(Yl,Y2) = *(Xi\\Y1,X~) I z(X1,X~\\Y~) \nThe last case means that if a tree l(tl,t2) is in I(X1,X2) but not in I(Y1,Y2), then either tl is not \nin Y1 or t2 is not in Y2. Note that the above operations never unfold a state. When the type inference \nalgorithm needs to proceed to the \"unfolding\" of a compound state, we use the following unf function: \nunf(X) = M(X) unf(X-'2\"~Y) = unf(X) isect N(Y) unf(X\\Y) = un](X) difff N(Y) The type inference algorithm \nmainly manipulates com- pound types, but, for calculating the final results, it uses a \"conversion\" operation \nfrom compound types to their equiv- alent non-compound types. Formally, a compound type A is convertible \nto B, written A ~ B, if t E A if[ t E B, for all t. The actual algorithm for the conversion operation \ncan be found in Section A. Finally, we need several definitions on type environ-ments. We write {~ : \nT} for the type environment that maps x to T and any other variables to the empty-set type 0; the empty \nenvironment 0 maps all variables to the empty set type @. We define r <: r' as r(x) <: r'(z) for all \nvari- ables x, and define F I F' as (F I r')(x) = r(x) I r'(x). We can easily see that u E (F1 I F2)(x) \niffu E Fi(z) or u e r~(x). 4.4 Inference Algorithm The type inference algorithm is presented as a set \nof syntax- directed rules defining a relation of the form H ~-A t> D => Ht; F, where II ranges over sets \nof pairs of a compound state and a pattern state, written in the form (XI>Y). The algo- rithm computes, \nfrom a (compound) domain type A for a pattern D, a type environment F that represents the range of D \nwith respect to A. To detect termination, the algo- rithm takes as input the set H of already-encountered \npairs of compound states and pattern states, and returns as out- put a set H' containing all the pairs \nin the input set H plus the additional pairs encountered during the processing of A and D. This output \nset becomes the input to the next step in the algorithm. The whole type inference takes as inputs a \ndomain type T and a target pattern P. We assume that T is included in P. (In general, T may not be included \nin P. But because only trees matched by P contribute to the ranges, we can take the intersection T N \nP for the the starting type, which is automatically included in P.) We start the type inference by calling \nthe general inference relation with 0 ~-T ~ P =~ II~; F. The output F is the final result of type inference. \n(The other output H ~ is thrown away.) We now give the rules for the type inference relation H b- A > \nD =*- H'; F. For a variable pattern, we add the domain type 7 to the range of x. (INFA-BIND) n~7~ : P \n~ n';(r I {~ : T}) The second premise converts the compound type T to a non- compound type T so that \nit can be added to the output type environment. If the type 7 is less than the empty type (and therefore \ncontains no trees), we return the empty type environment since no successful matches are possible. If \nthe pattern is either a leaf or a wild-card, we return the empty type en- vironment since matching against \nthe pattern will yield no bindings. T<: 0 (INFA-EMP)H~7~P=~H;O H I-\" e > e ~ II; 0 (INFA-EPS) H I- 7 \n> T =~ H; 0 (INFA-ANY) For a choice pattern, we compute a domain type for each choice by the compound \nintersection operation isect and the compound difference operation diff. H I- (T isect P1) t> P1 =-~ \nH1;F1 H1 ~ (T diff P1) ~ Pa :=~ Ha; Fa (INFA-ORI) HeT~ P~ I P~ ~ H2;(F1 Ira) If the type is a union, \nwe simply generate a subgoal for each component. H I\" 71 ~ P :=.~ H1; F1 H1 ~ 72 ~ P => H2;F2 H I-- T1 \nI T2 t> P =~ Ha; (F1 I F2) (INFA-OR2) If the type and the pattern are both labels, we propagate each \ncomponent of the type to the corresponding component of the pattern. l(x,x') \u00a2. 0 H F I(X,X') ~ I(Y,Y') \n~ Ha;(rl I ra) (INFA-LAB)  The side-condition I(X,X') ~. 0 is necessary for the preci- sion of the type \ninference. Suppose that I(X,X') <: 0. Then this means that one of X and X' is empty, but the other may \nnot necessarily be empty. If such a non-empty type is propagated to the corresponding component of the \npattern I(Y,Y'), this may augment the range of the pattern. But this augmentation is unnecessary because \nthe type l(X, X') contains no trees and there can therefore be no successful matches against the pattern. \nFinally, we have two rules for type and pattern states. (INFA-ST)HI- X~ Y =~ H;0 (Xt>Y) \u00a2 H H U { (X>Y)} \n~- unf (X) > N(Y) =-~II';F H~X~Y =~H';F (INFA-UNF) That is, if we have already seen the pair (Xr, Y), \nwe simply return the emp.ty type environment since proceeding to the unfoldings of X and Y again will \nnot add anything to the final type environment. If we have not seen the pair, we add it to H (so that \nwe will be able to tell if we encounter it again) and proceed with the unfoldings. The worst-case complexity \nof this algorithm is double- exponential. The rule INFA-UNF may be applied at most ~_.many times as the \nnumber of possibilities for the form (X>Y), which is exponential in the size of the input types and patterns. \nIn addition, each time the rule is applied, we may convert compound types to non-compound types the same \nnumber of times as variable patterns appear, which is linear. The conversion takes exponential time in \nthe worst case (cf. Appendix A). However, despite these frighten- ing possibilities, in our experience \nusing type inference with several small applications in XDuce, the performance of the algorithm is quite \nacceptable. The reason is that the pat- terns used in these applications are \"almost\" non-recursive (in \nthe case of completely non-recursive patterns, the rule INFA-UNF is applied only a linear number of times \nin the size of the pattern), and that the optimization techniques used in our implementation (cf., Appendix \nA) make the conversion operation quick for these examples. The algorithm is sound, that is, all trees \nin the predicted range of x are also in the actual range of x. 4.4.1 Theorem [Soundness]: Suppose 0 I- \nA ~> D => H; P and A <: D. Then, u E F(9) implies u E pA'D(9). The (routine) proof can be found in the \nfull version [HP00a]. Conversely, all trees in the actual range of x are also in the predicted range \nof x. 4.4.2 Theorem [Completeness]: Suppose 0 ~ A ~ D =~ II;F. Then, u E pA,D(y) implies u E F(y). The \nkey to the proof of completeness lies in characteriz- ing the partial results II ~ and F in an intermediate \nstate of the algorithm expressed by the form II K A v. D :=~ II'; F. That is, when the algorithm is given \nH, A, and D, what will it return in II ~ and F? To see the intuition, first observe that the algorithm \nwill behave as follows. (1) The algorithm performs type propagation from the pair of the compound type \nA and pattern D. (2) When the algorithm sees a pair of a compound state and a pattern state that is not \nin II, it will proceed to their unfoldings and record the pair in II'. (3) When the algorithm sees a \npair that is already in II, then it will skip this pair. From these, we can expect that F contains partial \nresults collected by type propagation from the pair of A and D and from the unfoldings of each pair in \nII' \\II. To capture the above intuition precisely, we introduce a partial validation relation. Partial \nvalidation can be seen as a \"checking\" version of the type inference algorithm. That is, it performs \ntype propagation similarly to the inference algorithm but, rather than computing a type environment, \nit checks whether a given type environment is big enough. We check \"big enough\" because our purpose here \nis to show completeness (i.e., the predicted range F is bigger than the actual range). In addition, partial \nvalidation checks the type environment with types and patterns only \"shallowly,\" with- out unfolding \nany definitions. This is because we want to characterize each individual pair that the algorithm went \nthrough (and avoid wrongly including the pairs that were skipped). Formally, we first define the relation \nYI ~-A ~ D F, which is read \"the type environment F is partially valid under II w.r.t A and D.\" This \nrelation is defined by the following set of rules: (X~,Y) e II (INF-ST) II ~-X ~ Y =~ F HF-T~P~F TaT \n{x:T}<: F (INF-BIND) 7<: 0 m (INF-EMP) IIF-T~P=~F II ~ e ~ e ~ I\" (INF-EPS) II ~- T ~ T ~ F (INF-ANY) \nIIb (T isect P1) ~ P1 :=~ F II K (T dif[ P1) ~ P2 ~ F (INF-OR1) H I- 71 ~ P ::::~ F HK72~P=~F (INF-Oa2) \nIIb Ti [T2~ P ~ F t(X,X') \u00a2 0 II F- X D. Y :=~ F H K X' ~ Y' =-~ F (INF-LAB) n ~-t(X,X') ~ s(Y,r') =~ \nr Each rule is similar to one of the algorithmic rules, with the following differences. First, the validation \nrules do not re-turn an output II'. Second, the input II from the conclusion is directly passed to each \npremise. Third, the type environ- ment F is passed through all of the rules, and, each time we reach \na variable pattern, we check that the passed type en- vironment contains sufficient type information \nfor the range at the variable. And fourth, the validation relation has no rule corresponding to INF-UNF: \nvalidation stops at states. We additionally define the relation II K II' =:~ F (which is read \"F is partially \nvalid under II w.r.t 1Yff\") as follows: V(X~Y) E H'. H F- unf(X) ~ N(Y) ~ F rl ~ YIt ~ r (INF-CONS) \n That is, it checks if, for each (Xv, Y) in H', the type envi- ronment F is partially valid under II \nw.r.t, the unfoldings of X and Y. Finally, F is ~lly valid w.r.t A and D, written ~ D :=~ F, iff both \nH K A ~ D ~ F and H ~-H :=~ F hold for some lII. The completeness of type inference is now proved in \ntwo steps. First, we show that the final result F of the algo- rithm is fully valid w.r.t. A and D (Lemma \n4.4.3). Then we show that a type environment F that is fully valid w.r.t. A and D is big enough for the \nactual range of D w.r.t A (Lemma 4.4.4). 4.4.3 Lemma: If 0 F- A ~ D ~ H;F, then A ~ D ~ FF. 4.4.4 Lemma: \nSuppose A ~ D ~ F. Then, t E pA,D(y) implies u E F(y). In the proof of Lemma 4.4.3, we use the above \nintuition for the characterization of partial results by partial validation. Finally, the type inference \nalgorithm constructed as above is guaranteed to terminate. 4.4.5 Theorem [Termination]: For all types \nA defined under a tree automaton M and patterns D defined under a pattern automaton N, we can effectively \ncalculate a type environment F defined under a tree automaton M' D M such that 0 K A ~ D =:~ II; F for \nsome II. 5 Related Work Pattern matching is found in a wide variety of languages, and in a variety of \nstyles. One axis for categorization that we have discussed already is how many bindings a pattern match \nyields. In all-matches style, a pattern match yields a set of bindings corresponding to all possible \nmatches. This style is often used in query languages [DFF +, AQM+97, CS98, CG00a, NS00] and document \nprocessing languages [NS98, Mur97]. In the single-match style, a successful match yields just one binding. \nThis style is usually taken in pro- gramming languages [MTH90, LVD+96, JHH+93]. In par- ticular, most \nfunctional programming languages allow am- biguous patterns with a first-match policy. Our design fol- \nlows this tradition. Another axis is the expressiveness of the underlying \"pat- tern logic.\" Some query \nlanguages and document process- ing languages use pattern matching mechanisms based on tree automata \n[NS98, Mur97] or monadic second-order logic (which is equivalent to tree automata) [NS00], and therefore \nthey have a similar expressiveness to our pattern matching. TQL [CG00a] is based on Ambient Logic [CG00b], \nwhich ap- pears to be at least as expressive as tree automata. On the other hand, pattern matching based \non regular path expres- sions, popular in query languages for semistructured data [DFF +, AQM+97, CS98], \nis less expressive than tree au-tomata. In particular, these patterns usually cannot ex-press patterns \nlike \"subtrees that contain exactly these la- bels.\" Both tree automata and regular path expressions \ncan express extraction of data from an arbitrarily nested tree structure (although, with the single-match \nstyle, the useful- ness of such deep matching is questionable, as we discussed in Section 3.1). Type \ninference with tree-automata-based types has been studied both in query languages for semistructured \ndata [MS99, PV00] and in the setting of a document transfor- mation framework [Mur97]. The target languages \nin these studies have both matching of inputs and reconstruction of outputs (while we consider only matching \nhere). Their pattern matches choose the all-matches style--in particu- lar, an input tree is matched \nsymmetrically against all the patterns in a choice pattern. Consequently, these inference algorithms \ndo not involve a difference operation. Milo, Suciu, and Vianu have studied a typechecking problem for \nthe general framework of k-pebble tree trans-ducers, which can capture a wide range of query languages \nfor XML [MSV00]. They use types based on tree automata and build an inverse type inference to compute \nthe type for inputs from a given type for outputs (which is the opposite direction to ours). Another \narea related to our type inference method is set-constraint solving [AW92] (also known as tree set automata \n[GTT96]). This framework takes a system of inclusion con- straints among types with free variables and \nchecks the sat- isfiability of the constraints [AW92] or finds a least solution if it exists [GTT96]. \nSince they allow intersection and dif- ference operations on types, it seems possible to encode our problem \ninto their framework and obtain the solutions by their algorithm. If we used this encoding, we would \nneed to do some work (similar to what we have done here) to prove the existence of least solutions for \nthe sets of constraints we generate, because least solutions do not exist in general in their setting. \nWright and Cartwright incorporate in their soft type sys- tem a type inference technique for pattern \nmatching [WC94]. Their type system uses a restricted form of union types and their patterns do not involve \nrecursion. (A more precise comparison with our scheme is difficult, since the details of their handling \nof pattern matching are not presented in their paper.) Puel and Sukrez [PSg0] develop a technique for \npattern match compilation using what they call term decomposition. Although their goal is different from \nours, the technique it- self resembles our type propagation scheme. Their term de- composition calculates \na precise representation of the set of input values that match each pattern, and their calculation of \nthe \"values not covered by the preceding patterns\" is sim- ilar to our Use of difference operations. \nThey do not treat recursive patterns. Future Work Some important extensions are left as future work. \nThe most important is that we would like to support an Any type, denoting all sequences of trees, as \nwell as patterns including the Any type. Any is useful for encoding object- style \"extension subtyping\" \n[HVP00], and also for writing patterns that extract parts of sequences (we can use Any to match the parts \nwe do not care about). We have not included Any in the present treatment, because adding it in a naive \nway destroys the property of closure under difference (see Appendix A for a related discussion), which \nmakes exact type inference impossible. Another extension is the inference of types for pattern variables \nin non-tail positions. We have some preliminary ideas for addressing these issues. Acknowledgments Our \nmain collaborator in the XDuce project, J~r6me Vouil- Ion, contributed a number of ideas, both in the \ntechniques presented here artd in their implementation. We are also grateful to the other XDuce team \nmembers (Peter Bune- man and Phil Wadler) and to Sanjeev Khanna for pro-ductive discussions, to Xavier \nLeroy and David MacQueen for help with references to related work, to the anonymous POPL'01 referees \nfor comments and suggestions that sub- stantially improved the paper, and to the database group and the \nprogramming language club at Penn and the mem- bers of Prof. Yonezawa's group at Tokyo for a great working \nenvironment. This work was supported by the Japan Society for the Promotion of Science and the National \nScience Foundation under NSF Career grant CCR-9701826 and IIS-9977408. References [AQM+97] Serge Abiteboul, \nDallan Quass, Jason McHugh, Jen- nifer Widom, and Janet L. Wiener. The Lorel query language for semistructured \ndata. Interna-tional Journal on Digital Libraries, 1(1):68-88, 1997. lAW92] Alexander Aiken and Edward \nL. Wimmers. Solv-ing systems of set constraints (extended abstract). In Proceedings, Seventh Annual IEEE \nSymposium on Logic in Computer Science, pages 329-340, June 1992. [BMS80] R. Burstall, David MacQueen, \nand Donald Sannella. HOPE: an experimental applicative language. In Pro- ceedings of the 1980 LISP Conference, \npages 136- 143, Stanford, California, 1980. Stanford University. [CG00a] Luca Cardelli and Giorgio Ghelli. \nA query language for semistructured data based on the ambient logic. Manuscript, April 2000. [CG00b] \nLuca Cardelli and Andrew D. Gordon. Anytime, any- where. Modal logics for mobile ambients. In Proceed-ings \nof the 27th ACM Symposium on Principles of Programming Languages, pages 365-377, 2000. [CS98] Sophie \nCluet and J~rSme Simeon. Using YAT to build a web server. In Intl. Workshop on the Web and Databases \n(WebDB), 1998. [DFF +] Alin Deutsch, Mary Fernandez, Daniela Florescu, Alon Levy, and Dan Suciu. XML-QL: \nA Query Language for XML. http : llwww, w3. orglTRINOTE-xml-ql. [GLP00] Vladimir Gapeyev, Michael Levin, \nand Benjamin Pierce. Recursive subtyping revealed. In Proceed-ings of the International Conference on \nl~unctional Programming (ICFP), pages 221-232, 2000. [GTT96] R. Gilleron, S. Tison, and M. Tommasi. Set \ncon- straints and automata. Technical Report it-292, Lab- oratoire d'Informatique fondamentale de Lille, \nUni- versitLille 1, 1996. [HP00a] [HP00b] [HU79] [HVP00] [JHH+93] [KMS] [LVD+96] [MS99] [MSV00] [MTHg0] \n[Mur97] [NS98] [NS00] [PS90] [PVOO] [Rel] Haruo Hosoya and Benjamin Pierce. Regular expression pattern \nmatching for XML. Available through ht'ep://w~tw, cis. upemx, edu/'hahos oya/ papers/tapat-full.ps, November \n2000. Haruo Hosoya and Benjamin C. Pierce. XDuce: A typed XML processing language. In Proceedings of \nThird International Workshop on the Web and Databases (WebDB2000), May 2000. John E. Hopcroft and Jeffrey \nD. Ullman. Introduction to Automata Theory, Languages, and Computation. Addison-Wesley, 1979. Haruo \nHosoya, Jarfme Vouillon, and Benjamin C. Pierce. Regular expression types for XML. In Pro- ceedings of \nthe International Conference on Func-tional Programming (ICFP), pages 11-22, September 2000. Simon L. \nPeyton Jones, Cordelia V. Hall, Kevin Hammond, Will Partain, and Philip Wadler. The Glasgow Haskell compiler: \na technical overview. In Prec. UK Joint Framework for Information Technol- ogy (JFIT) Technical Conference, \nJuly 93. Nils Klarlund, Anders M\u00a2ller, and Michael I. Schwartzbach. DSD: A schema language for XML. htCp \n:/lw~,n~. brics, dk/DSD/. Xavier Leroy, J~r6me Vouillon, Damien Doligez, et al. The Objective Carol system. \nSoftware and documentation available on the Web, http:// pauillac, inria, fr/ocaml/, 1996. Tova Milo \nand Dan Suciu. Type inference for queries on semistructured data. In Proceedings of Symposium on Principles \nof Database Systems, pages 215-226, Philadelphia, May 1999. Tova Milo, Dan Suciu, and Victor Vianu. Type-checking \nfor XML transformers. In Proceedings of the Nineteenth A CM SIGMOD-SIGA CT-SIGART Sym- posium on Principles \nof Database Systems, pages 11- 22. ACM, May 2000. Robin Milner, Mads Tofte, and Robert Harper. The Definition \nof Standard ML. The MIT Press, 1990. Makoto Murata. Transformation of documents and schemas by patterns \nand contextual conditions. In Principles of Document Processing '96, volume 1293 of Lecture Notes in \nComputer Science, pages 153- 169. Springer-Verlag, 1997. Andreas Neumann and Helmut Seidl. Locating \nmatches of tree patterns in forests. In 18th FSTTCS, volume 1530 of LNCS, pages 134-145, 1998. Frank \nNeven and Thomas Schwentick. Expressive and efficient pattern languages for tree-structured data. In \nProceedings of the Nineteenth ACM SIGMOD-SIGACT-SIGART Symposium on Prin-ciples of Database Systems, \npages 145-156. ACM, 2000. Laurence Puel and Asc\u00a3nder Suhrez. Compiling pat- tern matching by term decomposition. \nIn 1990 ACM Conference on Lisp and Functional Programming, pages 272-281, June 1990. Yannis Papakonstantinou \nand Victor Vianu. DTD Inference for Views of XML Data. In Proceedings of the Nineteenth A CM SIGMOD-SIGA \nCT-SIGART Symposium on Principles of Database Systems, pages 35-46, Dallas, Texas, May 2000. RELAX (REgular \nLAnguage description for XML). ht~p ://www. xml. gr. jp/relax/.  [Sei90] Hermut Seidl. Deciding equivalence \nof finite tree au- tomata. SIAM Journal of Computing, 19(3):424-437, June 1990. [wc94] Andrew K. Wright \nand Robert Cartwright. A practi- cal soft type system for scheme. In In Proceedings of A CM Conference \non Lisp and Functional Program- ming, pages 250-262, 1994. [XML] Extensible markup language (XMLTM). \nhttp:// ~n~. w3. org/XML/. [XS00] XML Schema Part O: Primer, W3C Working Draft. h~l;p ://~w. w3. org/TR/xmlschema-0/, \n2000. A Closure Algorithms This a2.pendix defines an algorithm for the conversion oper- ation A ::~ \nB introduced in Section 4.3, which computes a non-compound type equivalent to a given compound type. \nFrom this, we can derive, as a special case, an algorithm for the intersection operation introduced in \nSection 3.4. The formalization here depends on the definitions given in Section 4.3. We use the definitions \nof compound t~pe ex- pressions T, compound states X, compound types A, their acceptance relations, the \nintersection operation isect and dif- ference operation diff for compound types, and the unfolding function \nunf for compound states. We first give a characterization of the conversion oper- ation A =~ B. We define \ntwo relations IIk A =~ B and F- II, where H maps compound~tates to type states, and we claim that a~ompound \ntype A is convertible to a type B iff both II I- A ~ B and I- H hold, for some II. Intuitively, IIk A \n~ B means that A is \"immediately\" (without un- folding) convertible to B, assuming that the X is convert- \nible to Z for each X ~ Z in II. Similarly, k 17 means that the assumptions in YI are consistent--that \nis, that, for each X ~ Z in II, the unfolding of X is indeed convertible to the unfolding of Z. The following \nrules define these relations. X ~--r Z E II (E-ST) HkX~Z YI I- I~ ~ @ (E-EMP) IIk e =~. e (E-EPs) (E-OrO \nII h\" T1 IT2 ~ U1 ]U2 II ~- Xi ~ Z1 II ~-X2 ~ Z2 (E-LAB) rI ~- t(X1,X2) ~ t(Zl, z2) vX~ z ell. rIF ~nf(X) \n~ M(Z) (E-CoNs) t-II The only essential work is done in the rule E-CoNS, which computes the unfolding \nof X (which involves consecutive ap- plications of isect and diff operations), and confirms that the \nresult is convertible to the unfolding of Z. The other rules simply replace each compound state with \nthe corresponding state according to the mapping II. A.1 Lemma: II I- A ~ B and I-- II iff A :=~ B. \nFrom the above characterization, we can read off an ac- tual algorithm for the conversion as follows. \nWe start by setting H to the empty mapping and apply the rules to the given type and pattern in a goal-directed \nmanner. When we reach the rule E-ST, we may not find the compound state X in the domain of H. In this \ncase, we generate a fresh state Z and add a mapping X ~ Z to H. We then ]2ro- ceed to convert the unfolding \nof the compound state X to a non-compound type and \"back-patch\" the result as the unfolding of Z in the \ntree automaton. This algorithm even- tually terminates because only a finite number of compound states \ncan be constructed from the states in the given type and pattern. Also, notice that newly created states \nappear only in the output type and never in the input type, so there is no danger of trying to unfold \none of them before it has been back-patched with its definition. A.2 Lemma: For all compound types A \ndefined with re- spect to a tree automaton M and pattern automaton N, we can effectively calculate a \nt~pe B defined under a tree automaton M' _D M such that A =.~ B. The algorithm for the conversion operation \ntakes expo- nential time in the worst case because an exponential num- ber of compound states can be \ngenerated from the states in the given type and pattern. However, the algorithm has several opportunities \nfor optimization. Suppose that a com- pound state has the form X N {Y1... Yrn)\\{Z1 ... Zn). We can remove \nYi from the compound state if X <: Y~. Like- wise, when X <: Zi, we can replace the whole compound state \nby a state associated with the empty set type 0. Fur- thermore, when X and Zi denote disjoint sets, we \ncan re- move Zi from the compound state. (The disjointness can be checked by first calculating the intersection \nof X and Zi and then testing the emptiness of the result. Note that if we simply use the conversion operation \nfor calculating the inter- section, this introduces circularity. But we can avoid it by specializing \nthe conversion operation for intersection where no subtracting states appear in compound states. See \nthe next paragraph.) Although the inclusion tests in these opti- mizations are themselves potentially \nexpensive (exponential in the worst-case), these checks turn out usually to be rela- tively cheap, in \nour experience [HVP00]. The intersection of a (non-compound) type and a pat- tern is a special case of \nthe above operation. To compute an intersection of T and P, we can first calculate (T isect P) and then \nconvert the resulting compound type to a non- compound type. Proposition 3.4.3 can be derived as a corol- \nlary of Lemma A.2. The worst-case complexity of the inter- section operation is quadratic. To see why, \nobserve that, from the definition of isect, the compound types obtained by (A isect D) contain only compound \nstates of the form X A {Y}. Moreover, the unfolding of the compound state X N {Y} is also a compound \ntype that contains only com- pound states of this form. Since only a quadratic number of such compound \nstates can be generated from the states in the given type and pattern, the intersection operation completes \nin quadratic time. Although the operations we have defined are all we need in our framework, one may \nwonder which others can be de- fined. Indeed, it is possible to compute an intersection of two patterns \n(since types can be treated as a special case of patterns, intersections on other combinations are also \npos- sible). On the other hand, we cannot compute differences between patterns and patterns in general. \nFor example, to compute the difference T \\ I(X,X), we would need to enu- merate all the labels except \nl, an infinite set. For the same reason, neither types nor patterns are closed under negation.    \n \n\t\t\t", "proc_id": "360204", "abstract": "We propose <i>regular expression pattern matching</i> as a core feature for programming languages for manipulating XML (and similar tree-structured data formats). We extend conventional pattern-matching facilities with regular expression operators such as repetition (*), alternation (I), etc., that can match arbitrarily long <i>sequences</i> of subtrees, allowing a compact pattern to extract data from the middle of a complex sequence. We show how to check standard notions of exhaustiveness and redundancy for these patterns.Regular expression patterns are intended to be used in languages whose type systems are also based on the <i>regular expression types</i>. To avoid excessive type annotations, we develop a type inference scheme that propagates type constraints to pattern variables from the surrounding context. The type inference algorithm translates types and patterns into regular tree automata and then works in terms of standard closure operations (union, intersection, and difference) on tree automata. The main technical challenge is dealing with the interaction of repetition and alternation patterns with the <i>first-match</i> policy, which gives rise to subtleties concerning both the termination and the precision of the analysis. We address these issues by introducing a data structure representing closure operations lazily.", "authors": [{"name": "Haruo Hosoya", "author_profile_id": "81100504076", "affiliation": "Department of Computer and Information Science, University of Pennsylvania", "person_id": "PP37037779", "email_address": "", "orcid_id": ""}, {"name": "Benjamin Pierce", "author_profile_id": "81100303310", "affiliation": "Department of Computer and Information Science, University of Pennsylvania", "person_id": "P28925", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/360204.360209", "year": "2001", "article_id": "360209", "conference": "POPL", "title": "Regular expression pattern matching for XML", "url": "http://dl.acm.org/citation.cfm?id=360209"}