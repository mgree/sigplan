{"article_publication_date": "01-01-2001", "fulltext": "\n Colored Local Type Inference Martin Odersky Christoph Zenger Matthias Zenger \u00b4 Ecole Polytechnique F\u00b4ed\u00b4erale \nde Lausanne {odersky,czenger,zenger}@di.epfl.ch Abstract We present a type system for a language based \non F=, which allows certain type annotations to be elided in actual pro\u00adgrams. Local type inference determines \ntypes by a com\u00adbination of type propagation and local constraint solving, rather than by global constraint \nsolving. We re.ne the pre\u00adviously existing local type inference system of Pierce and Turner[PT98] by \nallowing partial type information to be propagated. This is expressed by coloring types to indicate propagation \ndirections. Propagating partial type informa\u00adtion allows us to omit type annotations for the visitor \npat\u00adtern, the analogue of pattern matching in languages without sum types. Introduction Many modern programming \nlanguages are based on type systems which combine a notion of objects and subtyp\u00ading with parametric \npolymorphism [Str91, Mey92, CDG+92, NC97, OW97, PT98, BOSW98]. A popular basis for such type systems \nis F=, the second-order lambda calculus with subtyping. While F= is an excellent basis for explaining \nthe abstract type structure of programs, it is less suitable as a kernel language for concrete source \nprograms, because of the excessive amount of type information that needs to be written by the programmer. \nMost programmers would agree that some kinds of type an\u00adnotations are useful as a vehicle for program \ndocumentation whereas others are annoying because they only repeat in\u00adformation that can easily be deduced \nfrom the context. For instance, a type signature for a globally de.ned function is generally useful, \nwhile an explicit type parameter in a function application is often annoying, in particular when the \nsame information can be deduced from the types of the function s actual value parameters. Local type \ninference [PT98] aims at eliminating the need for annoying explicit type information. It does this with \ntwo techniques. First, type parameters in a function appli\u00adcation are inferred from the function s value \nparameters by solving a constraint system which relates formal with actual argument types. Second, it \npropagates known types down the syntax tree in order to infer some types of formal value parameters and \nprovide additional guidance to type param\u00adeter inference. For instance, if function f is known to have \ntype (Int . Int) . Int, then f(fun (x) x + 1) would be well-typed, since the type of parameter x can \nbe inferred to be Int by propagating the known type Int . Int down the tree. This bidirectional local \ntype inference can be formalized in a type system where every type rule of F= is split into two rules, \none for the case where the result type is known, the other for the case where it is unknown. Compared \nto a type inference algorithm, a formalization of a type system in terms of typing rules is attractive \nbecause it provides a contract which can be understood by both users and im\u00adplementers of a programming \nlanguage. For this reason, bidirectional local type inference is put forward as the type inference technology \nof the ML2000 draft proposal [ACF+]. The downward type propagation in bidirectional local type inference \nworks only if the propagated type is completely known. If only some part of a type is known, downward \npropagation is disabled and types are instead inferred by propagating information from the leaves of \nthe tree upwards. For instance, if g is known to have type .a.(Int . a) . a, then g(fun (x) x + 1) would \nnot be well-typed since the type information known from the outside about the anonymous function is only \npar\u00adtial. The outside type information is Int . a where the instance type of the type variable a has \nyet to be deter\u00admined. In this paper we study a re.nement of bidirectional local type inference, where \npartial as well as total type informa\u00adtion can be propagated down the tree. Our approach types essentially \nall programs which are typable under bidirec\u00adtional local type inference as well as other programs. For \ninstance, it can type the function application of g above. Idioms like the one of g above arise naturally \nin Church encodings of parameterized types. Consider for instance the implementation of lists in a language \nwith recursive records, but without sum types. Taking the Church encoding of sum types as a guide, we \ncan implement pattern matching on lists with visitor records [GHJV94]. That is, the list type can be \nrepresented as a record with a single method, match, which takes a list visitor as argument: Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for profit or commercial advantage and that copies \nbear this notice and the full citation on the first page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior specific permission and/or a fee. POPL '01 1/01 Londo, \nUK Copyright 2001 ACM 1-58113-336-7/01/0001 ... $5.00 type List[a] = { match [b] (v: ListVisitor[a, \nb]): b } A list visitor is a record which contains two function-valued .elds, which are here called \ncaseNil and caseCons. The .rst function is invoked when the encountered list is Nil, the sec\u00adond when \nit is not. type ListVisitor[a,b] = { caseNil (): b, caseCons (x: a, xs: List[a]): b } The implementations \nof the list constructors Nil and Cons are then evident: Nil [a] (): List[a] = { match v = v.caseNil () \n} Cons [a] (x: a, xs: List[a]): List[a] = { match v = v.caseCons (x, xs) } As an example of a client \nusing lists and list visitors, consider the standard implementation of the append function. append [c] \n(xs: List[c], ys: List[c]): List[c] = xs.match { caseNil () = ys, caseCons (x, xs1) = Cons (x, append \n(xs1, ys)) } Note the close correspondence between the application of match and a pattern matching case \nexpression in a language with algebraic data types. The methods of the list visitor correspond one-to-one \nto the branches of a case expression. The same principle can be applied to represent systemati\u00adcally \nevery sum type in a language which has only product types. Most object-oriented languages fall into this \ncategory. A systematic application of the visitor pattern can obviate the need for a complication of \nthe type structure in these languages. That this representation is feasible in practice has been demonstrated \nin the case of the Pizza [OW97] and GJ [BOSW98] compilers. The Pizza compiler, written in Pizza, made \nheavy use of algebraic data types and pattern matching. The GJ compiler was derived from the Pizza compiler, \nbut it was written in GJ, which does not have al\u00adgebraic data types. Most pattern matching expressions \nin the Pizza compiler were represented by applications of the visitor pattern in the GJ compiler. The \nswitch did not lead to a signi.cant decrease in readability. Unfortunately, bidirectional local type \ninference cannot type the body of append above. It requires the parameter types of the caseCons to be \ngiven explicitly: append [c] (xs: List[c], ys: List[c]): List[c] = xs.match { caseNil () = ys, caseCons \n(x : c, xs1 : List[c])= Cons (x, append (xs1, ys)) } The reason is that the match method of lists is \npolymorphic. Hence, no type information is propagated into the argument of match and we have to write \nthe parameter types of all methods in the visitor explicitly. This type information is redundant, since \nit can easily be derived from the type of xs, the receiver of the match application. Most program\u00admers \nwould therefore classify the added type annotations as annoying rather than helpful. What s required \nhere is that we propagate the knowledge that we are dealing with a ListVisitor into the body of the list \nvisitor record. This knowledge is only partial, since we do not know yet the return type b of the type \nListVisitor[a,b] to be propagated. The inference system presented here can deal with such partial type \ninformation and can therefore type the .rst de.nition of append without auxiliary type annotations in \nvisitor methods. A type which is completely known from the context of the term to be typed and which \nis propagated inwards (down the tree) is called inherited , in analogy to inherited at\u00adtributes in attribute \ngrammars [Knu68]. By contrast, a type which is propagated outwards (up the tree) is called syn\u00adthesized \n. We write .T for inherited types and .T for syn\u00adthesized types. In general, a type can have both inherited \nand synthesized parts. For instance, the list visitor argu\u00adment for the match method in the code of append \nwould be inferred to have type .ListVisitor[c, .List[c]]. This indicates that we expect from the outside \na ListVisitor with .rst type parameter c, and that the second type parameter is found to be List[c] by \ntyping the visitor record itself. A type without pre.x is allowed to consist of arbitrary in\u00adherited \nor synthesized parts. To embed such a type T in an inherited or synthesized context, we use a . pre.x. \nFor example .(.T ..U) represents a function type where the function type construc\u00adtor is inherited, its \nargument type T is synthesized, and its result type U is arbitrary. The inherited and synthesized parts \nof a type can alter\u00adnatively and more concisely be characterized by coloring them. A second version of \nthis paper intended for color output [OZZ00] uses a red font for inherited parts of a type and a blue \nfont for synthesized parts. Black color is reserved for types with arbitrary inherited or synthesized \nparts. In the rest of this paper we develop these ideas in a type system for second order lambda calculus \nwith records and subtyping. We .rst de.ne a subtyping relation between col\u00adored types which re.ects the \ninformation given in the colors. The subtyping relation is designed such that it allows the de.nition \nof a subsumption rule. For instance, an inher\u00adited record type .{x : a, y : b} cannot be a subtype of \nthe smaller inherited record type .{x : a}, because this would mean that type information about y is \nguessed at a sub\u00adsumption step in the proof rather than being propagated from further up the tree. On \nthe other hand, it is true that .{x : a, y : b}= .{x : a} . We next de.ne a type system that assigns \ncolored types to terms and show how it can be used to infer missing type information for explicitly typed \nF=. This type system es\u00adsentially subsumes the bidirectional local type inference sys\u00adtem of Pierce and \nTurner. A minor deviation is presented at the end of section 6. We .nally present a local type infer\u00adence \nalgorithm which can propagate partial type information down the tree. The algorithm is not formulated \nwith col\u00adored types. Instead, we split a colored type into a prototype that contains the information \nwhich is propagated down the tree, and a type, which represents the completely computed type of a term. \nMissing information in the prototype is ex\u00adpressed by the special symbol ? . We have shown that the algorithm \nis sound and complete with respect to the type system. The type system is presented here with second \norder lambda calculus as the source language, but its ideas have much wider applicability. For instance, \nwe have used it in the design and implementation of the type system for the func\u00adtional net language \nFunnel [Ode00], which is based on join calculus [FG96]. Colored types are useful in general for de\u00adscribing \ninformation .ow in polymorphic type systems with propagation-based type inference. Related Work There \nis a long thread of research on type inference for extensions of the Hindley/Milner system or for higher-order \nlambda calculus. A particularly large body of work is concerned with the extensions we deal with, .rst\u00adclass \npolymorphism and subtyping. Typically, type infer\u00adence algorithms for extensions of the Hindley/Milner \nsys\u00adtem are complete, whereas algorithms for variants of second order lambda calculus are incomplete, \nsince the basic type inference problem for F2 is known to be undecidable [Wel94]. Extensions of the Hindley/Milner \nsystem with .rst class polymorphism [OL96, Jon97, GR99] distinguish between polymorphic type schemes \nand monomorphic types. They di.er in the methods how to convert from one to the other. Their type inference \nalgorithm is always based on some form of .rst-order uni.cation. Similar in motivation to these is Pfenning \ns work on type inference for F2 [Pfe88], which uses higher-order uni.cation. Extensions of the Hind\u00adley/Milner \nsystem with subtyping have also been stud\u00adied [AW93, TS96, EST95, Pot96, Nor98, Pot98]. They are usually \nbased on constrained types [OSW99], which include a set of subtype constraints as part of a type. A problem \nin practice is that constraint sets can become very large. Trifonov and Smith [TS96] as well as Pottier \n[Pot98] have proposed schemes to address the problem. A more radical al\u00adternative has been proposed by \nNordlander [Nor98] and Pey\u00adton Jones and Wansbrough [WJ00]. They approximate con\u00adstrained types with \nunconstrained types in the generaliza\u00adtion step. Nordlander s system [Nor98] heuristically uni.es type \nvariables with their bounds. He uses a scheme similar to ours to pass partial type information, treating \nwildcards (that correspond to our ? ) as unique fresh type variables. Roughly similar to subtype polymorphism, \nbut incompara\u00adble in expressive power, are R\u00b4emy s row variables [R\u00b4em89]. A system which combines .rst-class \npolymorphism with row variables, as studied in [GR99], can express many aspects of F=, and admits a complete \nand decidable type inference al\u00adgorithm based on uni.cation. But the resulting type system tends to become \nfragile and complex and the necessary en\u00adcodings in user programs can be a bit roundabout. The type inference \nproblem for F=, which combines subtyp\u00ading with .rst-class polymorphism, has been addressed by Cardelli \ns [Car93] greedy algorithm, which uni.es type vari\u00adables with their bounds, as soon as these are encountered \nin a subtype constraint. This usually works well in practice, but it does not admit an independent characterization \nof the output in a type system. Clearly closest to our work is Pierce and Turner s work on local type \ninference [PT98]. The main extension over their work is our re.nement of type propagation. Whereas their \npropagation of type information is all or nothing , we also admit propagation of partial information \nvia colored types. Both forms of type inference rely largely on propagation instead of (global) constraint \nsolving. A form of local type inference is also used in GJ [BOSW98]. In fact, GJ does not even have a \ntype parameter construct for polymorphic method applications. It relies totally on local type inference \nfor this task. Like Java, GJ requires complete type signatures for all variables and parameters to be \ngiven. The techniques discussed here are therefore not directly relevant for type inference in GJ. Propagation \nof information along the edges of a syntax tree is also the idea underlying attribute grammars [Knu68]. \nOur synthesized types correspond to synthesized attributes whereas inherited types correspond to inherited \nattributes. Attribute grammars cannot express attributes that have in\u00adherited as well as synthesized \ncomponents. Litvinov [Lit98] develops a type system for Cecil [CT98], which is comparable to ours. Cecil \nhas both structural sub\u00adtyping and subtyping by name and it can deal with recursive bounds. However, \nthe type inference is heuristic, with no decidability result. Xi and Pfenning [XP99] also use an all \nor nothing bidi\u00adrectional algorithm for type-checking. Their setting is an extension of the Hindley-Milner \ntype system by dependent types. They use bidirectionality to infer quanti.er elimina\u00adtion and introduction \nplaces. The rest of this paper is structured as follows. Section 2 and 3 present the internal and external \nlanguage of our calculus. Section 4 presents an example, section 5 and 6 discuss the subtype relation \nand the type system using colors. Section 7 outlines the local constraint resolution and section 8 the \ntype inference algorithm. Section 9 concludes. 2 Internal Language We have an internal and an external \nlanguage. The internal language is essentially the fully typed second order lambda calculus with records \nand subtyping. The external language additionally provides constructs to elide some of the explicit type \ninformation needed in the internal language, thus re\u00adducing clutter in source programs. The task of type \ninfer\u00adence is to map the external into the internal language by reconstructing the elided type information. \nThe internal language is based on F= and is almost the same as the one of Pierce and Turner. The one \nextension with respect to their system is the introduction of record values and types, which help to \nstreamline the encoding of object-oriented programs. The terms, types, and type environments of the internal \nlanguage are given by the following grammar (VAR) G . x : G(x) Terms E, F = x | fun[a](x : T )E Types \nT, S, R | | = F [T ](E) | E.x {x1 = E1, . . . , xn = En} a | T | . Environments G | | = T a. S {x1 : \nT1, . . . , xn : Tn} x : T | E | a | G, G'  G, a, x : T . E : S . <: T (BOT) (ABS) a G . fun[a](x : \nT )E : T . S aT<: T (TOP) G . F : S . T G . E : S ' S ' <:[R/a]S (APP) G . F [R](E):[R/a]T a<: a (VAR) \n G . F : . G . E : R ''(APP.) T1 <: T1 ... Tn <: Tn G . F [T ](E): . {x1 : T1,...,xn : Tn,xn+1 : Tn+1,...,xm \n: Tm} (REC) G . F : {x1 : T1,...,xn : Tn}(SEL) <: {x1 : T1' ,...,xn : Tn' } G . F.xi : Ti G . F : . \n (SEL.) T1 <: T1 ' T2 <: T2 ' G . F.xi : . aa(FUN)T1 ' . T2 <: T1 . T2 ' G . F1 : T1 ... G . Fn : Tn \n(REC) G f{x1 = F1,...,xn = Fn} : {x1 : T1,...,xn : Tn} Figure 1: G . E : T and T<: S A term is a variable \nx, a function abstraction fun[a](x : T ) with formal type parameters a and value parameter x : T , a \nfunction application F [T ](E), a record constructor {x1 = E1,...,xn = En} or a record selector E.x. \nThe overbar sig\u00adni.es tupling, with a equivalent to a1, ..., an for an unspec\u00adi.ed n. The presence of \nrecords allows us to restrict our lan\u00adguage to single-argument functions since polyadic functions can \nbe straightforwardly encoded: fun[a](x : T,y : T ' )E is encoded as fun[a](r : {x : T,y : T ' })[r.x/x, \nr.y/y]E and f[R](E,F ) is encoded as f[R]({x = E,y = F }). A type is either a type variable a, a record \ntype a {x1 : T1,...,xn : Tn} or a function type T . S. Only func\u00adtion types are polymorphic, and we write \nthe polymorphic a type variables over the function arrow; e.g. T . S instead of the more customary .a.T \n. S. We also have two types ., T which are the least, respectively greatest type. Prim\u00aditive types like \nInt are treated as free type variables. We identify types that are equivalent up to a-renaming as well \nas record types with the same .elds, possibly occurring in di.erent order. tv(E) and tv(T ) are the free \ntype variables of the term E and the type T respectively. The type system for the internal language and \nthe corre\u00adsponding subtype relation are presented in Figure 1. As in bidirectional local type inference, \nthe type system for the internal language has no subsumption rule. This is only a matter of presentation, \nsince at the point where we have to match types, in the application rule, we explicitly allow that the \nargument s type is a subtype of the formal argu\u00adment type. External Language The external language is \na superset of the internal language. There are two additional syntactic constructs, which let one omit \ntype annotations. E, F = ... | | fun(x)E F (E) lightweight abstraction lightweight application Our abstractions \nare even a bit more lightweight than the ones studied by Pierce and Turner [PT98], since we elide formal \ntype variables as well as argument types, whereas they elide only argument types. We say, a term E is \na partial erasure of F , if it can be obtained from F by erasing type information, i.e. replacing abstractions \nby lightweight abstractions and applications by lightweight applications. We use colors in types to represent \nthe direction from where type information is propagated. Red color indicates a part of the type which \nis known from the context (inherited), blue color indicates a part of the type which is known from the \nterm itself (synthesized). In black-and-white versions of the paper, colors are represented by up ticks \n. and down ticks . . The syntax of synthesized types .T is: .T, .S, .R = .a | .T| .. a | .{x1 : .T1,...,xn \n: .Tn}| .(.T . .S) Types which are propagated down the tree are called inher\u00adited types. They are written \n.T and their syntax is the dual of synthesized types. .T, .S, .R = . a | .T| .. ...a | .{x1 : T1,...,xn \n: Tn}| (.T . .S) Synthesized and inherited types are special cases of general types which can have arbitrary \ninherited and synthesized parts. They are pre.xed with . (In the colored version, they are black). The \nsyntax of general types is: .T, .S, .R = . a | .T| .. .a | .{x1 : .T1,...,xn : .Tn}| (.T ..S) | .a | \n.T| .. a | .{x1 : .T1,...,xn : .Tn}| .(.T ..S) Although we will use the adjectives synthesized and in\u00adherited \nin the following, we will often refer to the type s annotation as its color . To prevent too many annotations, \nthe pre.xes . , ., and . a are interpreted structurally on the type. So .(T . S) is actually identical \nto .(.T . .S) and in the following we will always use the former. Also, if we do not annotate the outermost \ntype constructor, we assume it to be .. Type constructors are always inherited or synthesized. A constructor \nannotated with . means that it is either in\u00adherited or synthesized. If we write the types .T , .T , .T \nwithin a single statement, they are assumed to be all struc\u00adturally equivalent, di.ering only in color. \nIf the same con\u00adstructor occurs more than once annotated with ., as in '' a .{x1 : T1,...,xn : Tn} = \n.{x1 : T rences of the constructor are assumed to have the same color. 1,...,xn : T n }, all occur- \nSubstitutions [T/a]S on types are de.ned to be color pre\u00adserving: [T/a].a = .T and [T/a]. a = .T . Types \nin type environments are always synthesized. This ensures that the type of a variable is always determined \nby its de.nition and not in.uenced by the context of its usage. G= x : .T | E | .a | G, G ' Example We \ndemonstrate the application of colored local type infer\u00adence by means of an example, which details the \nde.nition of a map function over the type Option[a] using the visitor technique. The example is analogous \nto the list and list visitor example presented in the introduction, except that it avoids the use of \nrecursive types (which are not covered here). The types Option[a] and OptionVisitor[a,r] are de.ned as \nfollows: map = fun[c,d](f: c . d) fun(x: Option[c]) r .match):(.{ }. .r) caseSome : c . r r.{.}((xmatchOptionVisitor[]:: \nc,rr..{}. caseNone : r..{}.(None())(Option[]): t.. { caseNone = (fun() t .)Option[]: ..{}. .(Option[]): \n., t caseSome = (fun(y: .c) (Some: .(.t . .Option[t]) (f:.(.c . .d)(y:. c)):.d) : .Option[d]) : .(c . \n.Option[d]) caseNone : {} . .Option[.] } : .{ }) caseSome : c . .Option[d] : .Option[d] c,d : .((c . \nd) . Option[c] . Option[d]) Figure 2: map type Option[a] = { match [r] (v: OptionVisitor[a,r]): r } \ntype OptionVisitor[a,r] = { caseNone (): r, caseSome (y: a): r } Constructors for Option[a] are as follows: \nNone = fun[s](): Option[s] { match = fun(v) v.caseNone() } Some = fun[t](y: t): Option[t] { match = \nfun(v) v.caseSome(y) } To make presentation easier, we have added some syntactic sugar to our formal \nlanguage de.nition. Type declarations introduce abbreviations for record types. A function ab\u00adstraction \nwith a return type fun (x: T ): T ' (E) is considered equivalent to a function with an explicity typed \nbody fun (x: T ): (E: T ' ). An explicitly typed expression such as E: T is in turn con\u00adsidered equivalent \nto (fun (x: T ) x) E. Consider now a map function over optional values, which is written in the external \nlanguage as follows. map = fun[c,d](f: c . d) fun(x:Option[c]) x.match { caseNone = fun() None(), caseSome \n= fun(y) Some(f(y)) } Figure 2 presents the same function together with internally computed type information \nfor terms and formal parame\u00adters. Note that: In applications, we use the function s argument type for \ntyping the actual argument. Here, the formal pa\u00adrameter of function x.match has the synthesized type \n.OptionV isitor[c, r], which expands to .{caseNone : {} . r, caseSome : c . r}. So for the actual argument, \nthe visitor record, every\u00adthing is given from outside, except for the second pa\u00adrameter type r of OptionVisitor, \nwhich still needs to be instantiated. Therefore, function caseSome has type .(c . .Option[d]). The argument \ntype . c of the function is given from the outside. Therefore, the type of the formal parameter x of \ncaseSome can be reconstructed; no explicit type an\u00adnotation needs to be given. 5 Subtyping Subtyping \ns role is to mediate di.erences when type infor\u00admation about a term is propagated both from the inside \nand T1 = T2 T2 = T3T = T T1 = T3 .a = . a ..= .. .T= .T ..= .T aa .{x1 : .T1,...,xn : .Tn,xn+1 : .T,...,xm \n: .T} = .{x1 : .T1,...,xn : .Tn} .(.T ..S) = .(.T ..S) a ..= . a ..= .{x1 : ..,...,xn : ..} ..= .(.T. \n..) a .a = .T .{x1 : .T,...,xn : .T} = .T .(... .T) = .T T1 = T1 ' ... Tn = Tn ' T1<T 1 ' T2 = T2 ' \n'' aa {x1 : T1,...,xn : Tn}={x1 : T1,...,xn : Tn} T1 ' . T2 = T1 . T2 ' Figure 3: T = S G(x)= .T G fc \nE : TT = T ' (VAR) (SUB) G fc x : .T G fc E : T ' fc fc (ABStp) a(ABS) .aG fun[a](x : T )E : .(T ..S)G \nfun(x)E :(T ..S) G, .a, x : .TE : S G, .a, x : .TE : Sa .. tv(E) fc fc .a G fc F :(.S . .T )G fc E :[R/a].S \n(APPtp) G F [R](E):[R/a].T fc a G fc F : .(.S . .T )G fc E : S ' S ' . a .S S ' = [R/a].S [R/a].T = \nT ' (APP) ''' ' '' ''' .R,T .(S ' = [R /a].S . [R /a].T = T ~ T . [R/a].T = [R /a].T ) G fc F (E): T \n' G E : .{x : .T } G E1 : .T1 ... G En : .Tn fc fc fc (SEL) (REC) fc fc G E.x : T G {x1 = E1,...,xn \n= En} : .{x1 : .T1,...,xn : .Tn} fc Figure 4: G E : T from the outside. A synthesized type constructor \nof a given type matches with an inherited constructor of that same type, or of a supertype. The subtype \nrelation = for colored types is shown in Figure 3. Since subtyping is contravariant in the argument type \nbut colors are covariant, we have a second relation <, which is the same as = but with reversed colors. \nIn this subtype relation a structural change in the type al\u00adways implies that the di.erent constructors \ndi.er also in color. Going from the subtype to the supertype, we always change from synthesized to inherited. \nThe synthesized type .(Int . Int) for example is a subtype of .(Int . .T) and .(Int . Int) = .(... .T) \n= .T. But .(Int . Int) is not a subtype of .T. Here, the topmost constructors di.er, but they have the \nsame color. This ensures that we never guess types. Synthesized infor\u00admation is really coming from inside, \nit cannot be constructed a using subsumption. A rule relating e.g. ..= .(S . T ) ing subsumption. The \nsubtype rules in Figure 3 are designed such that they derive smallest possible steps. Therefore we often \nrely on transitivity for deriving subtype judgements. For instance, ..= .(Int .{x : ..}) via ..= .(.T. \n..) = .(Int .{x : ..}). The subtype relations <: for uncolored types of the internal language and = for \ncolored types have the following relationship: Lemma 5.1 (Subtyping). 1. T = S implies T<: S. 2. T<: \nS implies .T = .S,  would destroy this property, because it would synthesize a function type which was \nguessed rather than propagated. Similarly, inherited information must really be given from the outside, \nit cannot be discarded by subsumption: If a type constructor is inherited at a certain point in the term, \ngoing outward we can discard the inherited constructor only explicitly in a rule (the origin of the information), \nnot by us-The .rst statement says that = is a restriction of <:; i.e. subsumption is sound in the internal \nlanguage, where we disregard colors when using <: on colored types. The sec\u00adond statement together with \nsubsumption guarantees that a term of type .T will typecheck against each supertype of T given completely \nfrom outside. As an example consider the typing of map. In the selection x.match we know from outside \nthat x has to have a type of the form .r' {match : .T . .T }. If we look up x in the type environment, \nwe .nd the synthe\u00adsized type r .{match : OptionV isitor[a, r] . r}. Subsumption gives us that x also \nhas type .r {match : .OptionV isitor[a, r] . .r} which is of the required form. Colored Type System The \ntype system for the external language is formulated in terms of colored types. Typing rules for that \nsystem are given in Figure 4. They include a subsumption rule (SUB) which makes use of the subtpying \nrelation de.ned in section 3. Most rules are straightforward. Rule (VAR) is the usual tautology rule \nfor variables. Vari\u00adables in environments are always synthesized; i.e. their type has been completely \nde.ned at the point of their de.nition. Therefore, the (VAR) rule can be restricted to synthesized types \n.T without loss of generality. There are two rules for function abstraction. The rule (ABStp) for function \nabstraction with an explicit argument type produces a type with a synthesized arrow as top\u00adlevel constructor, \nwhereas the rule (ABS) for lightweight abstractions produces an inherited arrow. In other words, lightweight \nabstractions require a function type to be passed from the outside into the abstraction. The function \ns result type is in each case pre.xed with a ., which tells us that this type can be propagated in either \ndirection. In the untyped abstraction (ABS), the type T of the func\u00adtion s argument is inherited. So \nit has to be known from the context. Here is an example for this: fun(x) x + 1 : .(Int . .Int). This \nfunction type indicates that the argument type must be known from the context, whereas the result type \nis de\u00adtermined by the function itself. Because formal type parameters are not explicitly mentioned in \nthe term, we disallow their use in the function body (see the side condition of rule (ABS)). Pierce and \nTurner do not require this side condition since their system never elides formal type parameters. If \nthe context does not provide the required information on the argument type, we have to annotate it in \nthe function de.nition. Example: fun(x : Int) x + 1 : .(Int . Int) As a consequence, that function has \na purely synthesized type. There are also two rules for function application. The rule (APPtp) for typed \nfunction application is straightforward. The expression s function part F needs to have a function type. \nThis is the only requirement propagated into the func\u00adtion expression; the rest of the function type \nhas to be syn\u00adthesized. With this information we also know the type of the argument E, so it gets a purely \ninherited type, which just needs to be checked. For example, a function f of type .((Int . Int) . Int) \ncan be applied to the term fun(x) x + 1, yielding f (fun(x) x + 1): .Int. The type derivation of this \njudgement uses the subsumption step .(Int . .Int) = .(Int . Int) for typing the function argument. This \nstep weakens the synthesized result type .Int of the argument to the same type .Int in inherited form. \nRule (APPtp) is formulated in a way, which makes a separate rule for the case where the function s type \nis . super.uous: Assume that the expression F has type ... By subsumption a it also has type .(.T. ..). \nNow if the argument E is typable with .T, we can conclude with (APPtp) that F (E) has the expected type \n... By far the most complicated rule in our system is rule (APP) for function application without explicit \ntype parameters. This is not surprising, since this rule plays the role of four di.erent rules in Pierce \nand Turner s system. The premise of the rule requires again the function part F of the expression to \nhave a function type. The argument expression is then checked to have a type which coincides with the \nfunction s (inherited) argument type, except for occurrences of type parameters ai, where an arbitrary \nsynthesized type is required. This is expressed by the condition S ' . a .S in the premise. The auxiliary \nrelation . a expresses a replacement of every occurrence of a variable in a by an arbitrary type. We \ndo not try to take account of sharing at this point. Therefore di.erent occurrences of the same type \nvariable can be associated with di.erent types. The relation is de.ned as follows. .T. a .T .T. a . ai \nT1. aT1 ' ... Tn. aTn ' .{x1 : .T1,...,xn : .Tn}. a .{x1 : .T1' ,...,xn : .Tn' } T. aT ' S. aS ' .a.' \na (.T ..S). a (.T ..S ' ) In other words, when type checking function arguments, we use a weaker constraint \nthan the one implied by the function type, since di.erent occurrences of the same type variable can be \nmatched with di.erent types. The next two con\u00additions in the premise of rule (APP) tighten the constraint. \nThey require the existence of a tuple of types R, which, when substituted for the type variables a in \nthe formal argument type .S, yield a type which is a supertype of the actual argument type S ' . Furthermore, \nwhen substituted for a in the function s result type .T , we require a type which is a subtype of the \nwhole rule s result type T ' . The .nal premise of rule (APP) requires that the tuple of types R minimizes \nthe function s result type when compared to any other solution which satis.es the same constraints. The \npremise makes use of the auxiliary relation S ~ T , which states that S and T coincide on their inherited \nparts. ~ is de.ned as follows: .T ~ .S .T ~ .T T1 ~ T1 ' ... Tn ~ Tn ' .{x1 : .T1,...,xn : .Tn}~ .{x1 \n: .T1' ,...,xn : .Tn' } T ~ T ' S ~ S ' .aa (.T ..S) ~ .(.T ' ..S ' ) For example, suppose we have a \nfunction g of type a .((Int . a) . a) which is again applied to our term fun(x) x + 1. To show that g \n(fun(x) x + 1): .Int, we choose R = Int in the rule (APP). .(Int . .Int). a .(Int . a) shows that the \ntype of g provides enough information to type the argument, .(Int . .Int) = .(Int . Int) shows that actual \nand formal argument type match, and trivially [Int/a].a = .Int turns .Int into an appropriate result \ntype. Clearly, Int is also the optimal choice here. a However, with a function h:(a . a) . a we cannot \n.nd a type for h(fun(x) x + 1). The condition S ' . a .(a . a), which requires that argument and result \ntype of S ' are syn\u00adthesized, fails for S ' = .(Int . .Int) and all its supertypes, since they are all \nof the form .(Int . S '' ), where the argu\u00adment type is inherited. This is not unexpected, since neither \nh nor fun(x) x + 1 have information on the type of x. As a further example for the use of the lightweight \nappli\u00adcation rule (APP), consider the function application f(x), where f has the synthesized type a .(a \n. (a . a)) and x has type .Int. Since .Int. a . a, x is a matching ar\u00adgument. But f(x) fails to have \na purely synthesized type. The high level reason for this is that a occurs co-and con\u00adtravariantly in \nthe result type and thus we cannot make an optimal choice for R. If we try to give f(x) the synthesized \ntype .(Int . Int), we have to choose R = Int. The subtype requirements of the rule (APP) are ful.lled, \nbut R ' = T and T '' = .(T.T) ~ .(Int . Int) provide an alternative which also ful.lls the requirements. \nThis falsi.es the optimality constraint .(T.T) = .(Int . Int), and therefore does not yield a valid typing. \nOther choices for synthesized types fail for similar reasons. On the other hand, we can verify that f(x) \ndoes have the inherited type .(Int . Int). The choice R = Int is the same, but here the requirement T \n'' ~ .(Int . Int) on T '' is stronger, and the only choice left for R ' is Int. Indeed, [Int/a].(a . \na) = [Int/a].(a . a) holds and the optimality constraint is satis.ed. By analo\u00adgous reasoning, f(x) also \nhas the inherited type .(...). Rule (SEL) speci.es the typing of record selection. The premise of this \nrule uses an inherited record type construc\u00adtor, which re.ects the fact that when typing expression E \nin a selection E.x, we know that E must be a record with an x .eld. The .eld s type can be propagated \nin either direction. Subsumption allows that the argument may have additional .elds. However, all these \nadditional .elds have to have syn\u00adthesized types. Allowing inherited types would enable us to guess them. \nFinally, rule (REC) speci.es the typing of record construc\u00adtion. The record type constructor appears \nin synthesized form in the conclusion of the rule, re.ecting the fact that in a record formation {x1 \n= E1,...,xn = En} we know the shape of the constructed record without further context in\u00adformation. The \ntypes of the .elds x1,...,xn, on the other hand, can again be propagated in either direction. For example, \nassume we want to type { u = fun(x) x + 1, v = 3 }.u The record expression itself has type .{u : .(Int \n. .Int),v : .Int}. The selection rule expects that the quali.er has a record type with one u component. \nWe apply the subsumption rule to get the record type into the proper form .{u : Int . .Int}. Here it \nwas essential that the v component had a synthesized type, because for subsumption we needed .Int = .T. \nWe would not have been able to type { u = fun(x) x + 1, v = 3 }.v since the type s u component is not \npurely synthesized and .(Int . .Int) .= .T. Soundness and Completeness We have shown, that the type system \nis sound and complete with respect to the internal language. fc Theorem 6.1 (Soundness) If G E : T then \nthere exists a term F such that E is a partial erasure of F with G . F : S and S<: T . Theorem 6.2 (Completeness). \nIfG . E : T then G E : .T fc Completeness is easy to show, as the rules for the lightweight terms need \nnot be considered. For soundness we insert the derived argument types, formal type parameters, and actual \ntype parameters into E and show that the resulting term F always has a unique type which is a subtype \nof T . Note that the external language does not have a subject reduction property. For instance (fun(x: \nInt.Int) x) (fun(y) y + 1) 3 has type .Int. But, assuming standard reduction semantics, this expression \nreduces to (fun(y) y + 1) 3 which does not have a type. One can still show type soundness of the external \nlanguage by using type soundness for the internal language F= to\u00adgether with the soundness theorem 6.1, \nwhich relates the two languages. Variants The optimality constraint in rule (APP) minimizes the in\u00adstantiated \nversion of the function s result type. Several other variants of this constraint are also possible. 1. \nTaking account of inherited information. There is one kind of term that bidirectional local type inference \ncan type in checking mode, but colored local type inference cannot. To see this, consider again f(x) \nwith f of type a .(a . (a . a)) and x of type .Int. We saw that we can infer the types .(...) and .(Int \n. Int), but we will explain now that we cannot infer .(.. Int). If we try to give f the type .(.. Int), \nwe .nd with R = Int and R = . two solutions for the substitution [R/a], none of which is better than \nthe other. Bidirectional local type inference infers .. Int in checking mode. This case can only appear \nin a polymorphic application where a type variable occurs co-and contravariantly in the function s result \ntype (a in the example),  this type variable can be chosen in di.erent ways (. and Int), and  the type \nis given completely from outside.  The last two points mean in particular that the type given from outside \nreplaces co-and contravariant occurrences of the type variable with di.erent types (. and Int in the \nex\u00adample). We could solve this problem by using another optimality criterion for (APP): '. '''' = .'' \nS = [R ' /a]S . [R ' /a].T = T ~ T . .T T. Using this criterion, one could infer the type .(.. Int) for \nf(x). But implementing the new criterion comes at a considerable cost in algorithmic complexity. 2. Extending \noptimality for function arguments. In prac\u00adtice, one might often want to restrict (APP) further instead \nof generalizing it. The problem is that rule (APP) as well as bidirectional local type inference do not \nalways instantiate all type variables to unique types. The case of f(x) above is one where bidirectional \nlocal type inference succeeds, but does not instantiate the type variable a. Another case is the a application \ng(x) where g has type .(a . {}) and x has type .Int. Here, both colored and bidirectional local type \ninfer\u00adence would succeed without determining an instance type for a. In fact, both Int and T would be \npossible instantiations. This indeterminacy is not a problem for languages which are parametric [Wad89], \nbecause in these languages the partic\u00adular instantiation of a type variable cannot a.ect the result of \na computation. But most real world languages are not parametric over\u00adloading, dynamic type casts, or \ninheritance with overriding all destroy parametricity. If parametricity does not hold, it is mandatory \nthat all type variables are instantiated to unique types. In our case, this could be achieved by a strengthened \noptimality constraint in rule (APP), which re\u00adquires that the argument type as well as the result type \nis minimized: '' ' S ' = [R ' /a].S . [R ' /a].T = T ~ T . [R/a].T = [R ' /a].T . [R/a].S = [R ' /a].S \nThis variation requires only minimal changes to the inference algorithm. 3. Dealing gracefully with non-variant \nresult types. The optimality criteria given so far rely on a minimization of a function s result type. \nHence, if the function s result type is non-variant in the type variable(s) to be instantiated, a best \nsolution often does not exist and type parameters have to be given explicitly. As an example, consider \na version of the List type augmented by an append function: type List[a] = { match [b] (v: ListVisitor[a, \nb]): b append (ys: List[a]): List[a] } This type is non-variant in the type variable a, since a ap\u00adpears \ncovariantly and contravariantly in the type of append. 1 Consider now a function singleton which creates \na one\u00adelement list. singleton [a] (x: a): List[a] = Cons (x, Nil[a]()) Intutitively, one would expect \nsingleton( abc ): List[String] but with the optimality criteria given so far we get instead an ambiguity \ntype error. The problem is that both [String/a] and [T/a] are legal instantiations of singleton s type \nparam\u00adeter, a. The two instantiations lead to two result types List[String] and List[T], with neither \nof the two being better than the other. Ambiguities like these can be avoided by arbitrarily picking \none instantiation over the others. Our current implementa\u00adtion always picks minimal instance types. That \nis, it instan\u00adtiates type variables which are non-variant in the function result type to the smallest \ntype which is consistent with the local constraints. With this modi.cation, we get the ex\u00adpected type \nList[String] for singleton( abc ). Our experience indicates that the modi.cation greatly reduces the \nnumber of required type annotations in programs which deal with non-variant types. Even after the modi.cation, \nthere is in practice one more rough edge in the treatment of non-variant types. Con\u00adsider an occurrence \nof a parameter-less constructor of a non-variant type, such as Nil for non-variant List, and as\u00adsume \nthat there is no inherited type information. With our original optimality constraint, Nil() is ambiguous, \nsince it has types List[String] and List[T], among others. With our modi.ed optimality constraint, we \nget instead 1A purely co-variant version of append could be writ\u00adten if type variables with lower bounds \nwere permitted: append[b >: a](ys: List[b]): List[b]. But a type system with bounds like these is beyond \nthe scope of the present paper. Nil(): List[.]. The problem is that List[.] is not a very useful type \nfor Nil(), because it is not a subtype of any other list type (assuming that lists are non-variant). \nIf one wanted a list of String, one would need either a type parameter as in Nil[String](), or an explicit \ntype annotation, such as Nil(): List[String]. The lo\u00adcal type inference algorithm for GJ has a neat solution \nto this problem by adding an unknown type * to the internal type language. Types with *-parameters can \nbe implicitly widened to types with arbitrary types at corresponding po\u00adsitions. Some syntactic restrictions \nprevent duplication of *-types and thus guarantee the soundness of the widening rule. It is not clear \nyet, whether the GJ solution can be generalized to the setting considered here. Constraint Resolution \nIn the type inference we need to .nd the locally best solu\u00adtion for actual type parameters of polymorphic \nfunctions in lightweight applications. This requires solving a set of sub\u00adtype constraints. We can use \nthe techniques introduced in bidirectional local type inference. An a-constraint set C is a set of inequations \nT<: a<: T ' , where (tv(T ) . tv(T ' )) n a = \u00d8. We abbreviate T<: a<: T by T<: a and . <: a<: T ' by \na<: T ' . An a-substitution s is an idempotent substitution with dom(s)= a. An a-substitution s is a \nsolution for an a-constraint set C if we have T<: sa <: T ' for each T<: a<: T ' in C. During type inference \nwe generate a-constraint sets from subtype constraints containing a. Given types T and S where only one \nof them contains a, the constraint generation algorithm algorithm computes the minimal a-constraint set \nC which guarantees S<: T . The judgement fa S<: T . C which describes this is directly taken from [PT98]. \nWe have for example: fa,b Int . Int <: a . b .{a<: Int, Int <: b} The soundness and completeness properties \nshown by Pierce and Turner [PT98] carry over to our system with records. Theorem 7.1 (Soundness). Suppose \nthat either tv(S) n a = \u00d8 or tv(T ) n a = \u00d8. If fa S<: T . C and s is a solution of C, then sS <: sT \n. Theorem 7.2 (Completeness). Let s be an a\u00adsubstitution and let S and T be types such that either tv(S) \nn a = \u00d8 or tv(T ) n a = \u00d8. If sS = sT then fa S<: T . C for some C. Now, given a constraint set C and \na type R, sC,R is a so\u00adlution of C, which makes the type sC,RR minimal, i.e. for each solution s of C: \nsC,RR<: sR. sC,R is unde.ned, if such a solution does not exist. For the example above we get s{a<:Int,Int<:b}{x \n: a, y : b} = {x : .,y : Int}. The algorithm of Pierce and Turner [PT98] to compute sC,R also works for \nour system with records. 8 Type Inference Type inference is organized as a recursive algorithm, which \ndoes a depth-.rst traversal of the syntax-tree. The parame\u00adters of the inference algorithm are the term \nE that we want to type, a type environment G, and a prototype P , which contains partial information \non the type of E. The algorithm .lls in the information that P was lacking and returns the complete type \nT . The type inference algorithm is given as a deduction system for judgements of the form P, G E : T \nfw (see Figure 5). Prototypes P are regular types except that they may con\u00adtain an additional type constant \n? which indicates that information about a part of the type is lacking. We say a type T matches a prototype \nP if T is obtained from P by replacing ? s with arbitrary types. For example in the judgement Int . ?,E \nfw fun(x)x : Int . Int the prototype Int . ? indicates that only the argument type Int of the function \nis known from outside. But from this argument type we conclude that x is of type Int and .ll it in as \na result type. For each inference judgement we can .nd a corresponding judgement in the colored system \nby combining the informa\u00adtion of P and T into a single colored type. For instance, the above judgement \ncorresponds to fc . E fun(x)x :(Int . .Int) in the colored system. The parts present in the prototype \nare now inherited, the rest is synthesized. To reconstruct the colored type from the prototype P and \nthe type T in general, we use the operation T /P . If T matches P , then T /P is structurally equal to \nT . It is in\u00adherited on the parts given in P , and it is synthesized, where P hasa?. If T does not match \nthe prototype P , we use the smallest supertype of T which does. If such a type does not exist, T /P \nis unde.ned. Dually, T .P is the greatest sub\u00adtype of T which matches P , is inherited on the parts given \nin P , and is synthesized elsewhere. For instance Int . Int/Int . ?= .(Int . .Int) and Int . ./? . ? \n. ?= .(.Int . .T. ..). It is crucial for the inference to keep the rule system deter\u00administic. Therefore \nthere must not be a subsumption rule in the inference system. Since for the inference the proto\u00adtype \nis given and since there can be at most one supertype of T which matches a given prototype P , namely \nT /P , we can always choose this one. Consequently, every derivable inference judgement P, G E : T satis.es \nthe invariant fw that T matches P . Most of the rules in Figure 5 are now straightforward to derive. \nWhere above we combined the prototype P and the type T into a single colored type, we now have to do \nit the other way and split a colored type into a prototype and a regular type. For instance, in the rule \n(sel) we split the colored type T from the (SEL) rule into P and T ' . Then .{x : .T } splits into {x \n: P } and {x : T ' }. (var) P, G fw x : G(x)/P fw ?, G, a, x : TE : S T, G, a, x : T fw E : S (abstp,?) \n(abstp,T) fwafw ?, G fun[a](x : T )E : T . S T, G fun[a](x : T )E : T fw fw (abstp) (abs) P ' , G, a, \nx : TE : S P, G, a, x : TE : S aaaaa P . P ' , G fw fun[a](x : T )E : T . S/P . P ' T . P, G fw fun(x)E \n: T . S afw fw ?, G fw F : S . T [R/a]S, G fw E :[R/a]S ?, G F : .T, G E : S (apptp) (apptp,.) P, G fw \nF [R](E):[R/a]T /P P, G fw F [R](E): ./P a ?, G fw F : S . T [?/a]S, G fw E : S ' fw fw (app) fa S ' \n<: S . C1 fa T<: T.P . C2 (app.) ?, G F : .T, G E : S P, G fw F (E): ./P P, G fw F (E): sC1.C2,T T /P \n fw fw fw {x : P }, G F : {x : T } ?, G F1 : T1 ... ?, G Fn : Tn (sel) (rec?) fw fw P, G F.x : T ?, \nG {x1 = F1,...,xn = Fn} : {x1 : T1,...,xn : Tn} fw fw T, G F1 : T1 ... T, G Fn : Tn (recT) fw T, G {x1 \n= F1,...,xn = Fn} : T fw fw fw fw (P1, G F1 : T1) ... (Pm, G Fm : Tm)(T, G Fm+1 : Tm+1) ... (T, G Fn \n: Tn) (rec) fw {x1 : P1,...,xm : Pm}, G {x1 = F1,...,xn = Fn} : {x1 : T1,...,xm : Tm} fw Figure 5: \nP, G E : T The resulting rule (sel) illustrates the information .ow used in the type checking of (SEL). \nFrom outside we get infor\u00admation about the type in P . From this we conclude that the type of the record \nmust match {x : P }. The type inference for the record will tell us that its .nal type is {x : T }. From \nthat we know that the .nal type for the selection expression is T . For the record introduction we need \nthree separate rules, (rec), (rec?), and (recT), because we have to consider three di.erent kinds of \nprototypes, {x1 : P1,...,xm : Pm}, ?, and T. The reason is that in rule (REC) the types Ti may be inherited \nor may have inherited components, although the record type constructor is synthesized. Similarly, we \nhave to construct three rules (abstp), (abstp,?) and (abstp,T) for (ABStp). The most important case is \nagain the untyped application rule (app), where we have to infer type parameters. Here, the descriptive \npremises in the type system are replaced by local constraint resolution. First of all, passing [?/a]S \nas a prototype for the actual argument guarantees S ' < a .S. Then we generate two constraint sets C1 \nand C2 from the two subtype requirements. C1 guarantees that a solution s ful.lls S ' <: sS, which ensures \nthat the type of the actual argument is a subtype of the function s argument type. C2 ensures sT <: T.P \n, so that a solution will always have a supertype matching P . Each solution of C1 . C2 satis.es both \nconstraints. Choosing sC1.C2,T guarantees that we have a solution also satisfying the optimality constraint. \nIn the map example of Figure 2 x.match has type r {caseNone : {} . r, caseSome : c . r}. r. The type \ninference checks the actual visitor argument of x.match with prototype {caseNone : {} . ?, caseSome : \nc . ?}. This yields the .nal type {caseNone : {} . Option[.], caseSome : c . Option[d]}. Thus, the resulting \nconstraint system is {Option[.] <: r, Option[d] <: r}. The second constraint implies the .rst, so the \noptimal solu\u00adtion for result type r is sC,r =[Option[d]/r]. Therefore, Option[d] is the complete type \nfor the visitor ap\u00adplication. We have shown soundness and completeness of the type inference with respect \nto the colored type system. fw Theorem 8.1 (Soundness). If P, G E : T then G fc E : T /P . fc Theorem \n8.2 (Completeness). IfG E : T and T = T /P then P, G fw E : T /P . The condition T = T /P in the completeness \ntheorem requires that the prototype P contains at least the infor\u00admation which is present in the inherited \npart of T . For the special case that T is purely inherited or purely synthesized, completeness simpli.es \nto the following corollary. fc Corollary 8.3 (Completeness). IfG E : .T then ?, G fw E : T . IfG fc E \n: .T then T, G fw E : T . The proofs for soundness and completeness proceed by in\u00adduction on the derivation. \nIn the proof for completeness we always regard the last non-subsumption step together with all following \nsubsumption steps. Conclusion When designing the type system for the functional net lan\u00adguage Funnel \n[Ode00], we were looking for a type system with deep subtyping and polymorphic records. Further, we wanted \nto have a source language that avoided unnecessary clutter due to type annotations. First, we were looking \ninto type systems with uni.cation\u00adbased type inference. Since deep subtyping and polymorphic records \ntogether do not allow complete type inference, one has to .nd restrictions on these two properties. The \nproblem with this approach is that every new language construct, or even just a slight change of an existing \nlanguage construct is a possible threat to the decidability or tractability of the type inference. It \nis even often di.cult to see whether a speci.c change leads to undecidability. Using F= and a local type \ninference scheme proved to be more robust and .exible in this respect. Here, we always have the internal \nlanguage as a starting point and fallback. On top of this we can introduce lightweight versions of our \nsyntactic constructs that obviate the need for many type annotations. Since in Funnel programs the visitor \npattern is used per\u00advasively, it is important to be able to express visitors with lightweight abstractions. \nThe .rst main contribution of this paper is a local type inference algorithm that is able to prop\u00adagate \npartial type information. This is essential for visitors, but it is also helpful in eliding type information \nfor other language constructs. Although our type inference algorithm can type the visitor pattern, the \nlocal constraint resolution algorithm is the same as the one by Pierce and Turner [PT98] and the complexity \nof the algorithm is similar. The added power of our infer\u00adence is hence solely derived from a more re.ned \npropagation scheme. The second main contribution of this paper is the presen\u00adtation of the type system \nas a colored deduction system. Information .ow during type inference is no longer explicit, it is encoded \nas the color of the types. This yields a very compact notation with little redundancy. Looking at the \ndiscussion at the end of chapter 6, we can see that we often have to change very little when regarding \ndi.erent versions of the type system. References [ACF+] Andrew Appel, Luca Cardelli, Kathleen Fisher, \nCarl Gunter, Robert Harper, Xavier Leroy, Mark Lillib\u00ad ridge, David B. MacQueen, John Mitchell, Greg \nMor\u00ad risett, John H. Reppy, Jon G. Riecke, Zhong Shao, and Christopher A. Stone. Principles and prelimi\u00ad \nnary design for ML 2000. [AW93] Alexander Aiken and Edward L. Wimmers. Type in\u00ad clusion constraints and \ntype inference. In FPCA 93: Conference on Functional Programming Languages and Computer Architecture, \nCopenhagen, Denmark, pages 31 41, New York, June 1993. ACM Press. [BOSW98] Gilad Bracha, Martin Odersky, \nDavid Stoutamire, and Philip Wadler. Making the future safe for the past: Adding genericity to the java \nprogramming lan\u00adguage. In Proc. OPPSLA 98, October 1998. [Car93] Luca Cardelli. An implementation of \nF<:. Technical Report 97, DEC Systems Research Center, February 1993. [CDG+92] Luca Cardelli, James Donahue, \nLucille Glassman, Mick Jordan, Bill Kalsow, and Greg Nelson. Modula\u00ad3 language de.nition. ACM SIGPLAN \nNotices, 27(8):15 42, August 1992. [CT98] Craig Chambers and Cecil Team. The Cecil language, speci.cation \nand rationale, December 1998. [EST95] Jonathan Eifrig, Scott Smith, and Valery Trifonov. Type inference \nfor recursively constrained types and its application to OOP. In Proc. MFPS 95, Eleventh Conference on \nthe Mathematical Foundations of Pro\u00adgramming Semantics, March 1995. [FG96] C\u00b4edric Fournet and Georges \nGonthier. The re.exive chemical abstract machine and the join-calculus. In Proc. 23rd ACM Symposium on \nPrinciples of Pro\u00adgramming Languages, pages 372 385, January 1996. [GHJV94] Erich Gamma, Richard Helm, \nRalph Johnson, and John Vlissides. Design Patterns : Elements of Reusable Object-Oriented Software. Addison-Wesley, \n1994. [GR99] Jacques Garrigue and Didier R\u00b4emy. Semi-explicit .rst-class polymorphism for ML. Information \nand Computation, 155:134 171, 1999. [Jon97] Mark P. Jones. First-class polymorphism with type inference. \nIn Proc. 24th ACM Symposium on Prin\u00adciples of Programming Languages, pages 483 496, Paris, Jan 1997. \nACM Press. [Knu68] Donald E. Knuth. Semantics of context-free lan\u00adguages. Mathematical Systems Theory, \n2(2):127 145, February 1968. [Lit98] Vassily Litvinov. Constraint-based polymorphism in Cecil: Towards \na practical and static type system. In Proceedings of the 13th ACM Conference on Object-Oriented Programming \nSystems, languages and ap\u00adplications, October 1998. [Mey92] Bertrand Meyer. Ei.el, The Language. Object \nOri\u00adented Series. Prentice Hall, Engelwood Cli.s, 1992. [NC97] Johan Nordlander and Magnus Carlsson. \nReactive objects in a functional language -an escape from the evil I. In Proceedings of the Haskell Workshop, \nJune 1997. [Nor98] Johan Nordlander. Pragmatic subtyping in polymor\u00adphic languages. In Proceedings of \nthe third ACM SIG-PLAN International Conference on Functional Pro\u00adgramming (ICFP 98), September 1998. \n[Ode00] Martin Odersky. Functional nets. In European Sym\u00adposium on Programming, Lecture Notes in Computer \nScience. Springer Verlag, 2000. Invited Paper. [OL96] Martin Odersky and Konstantin L\u00a8aufer. Putting \ntype annotations to work. In Proc. 23rd ACM Symposium on Principles of Programming Languages, pages 54 \n67, January 1996. [OSW99] Martin Odersky, Martin Sulzmann, and Martin Wehr. Type inference with constrained \ntypes. TAPOS, 5(1), 1999. [OW97] Martin Odersky and Philip Wadler. Pizza into Java: Translating theory \ninto practice. In Proc. 24th ACM Symposium on Principles of Programming Languages, pages 146 159, January \n1997. [OZZ00] Martin Odersky, Christoph Zenger, and Matthias Zenger. Colored local type inference. http://lampwww.epfl.ch/papers/clti-color.ps.gz, \n2000. [Pfe88] Frank Pfenning. Partial polymorphic type inference and higher-order uni.cation. In Proceedings \nof the 1988 ACM Conference on Lisp and Functional Pro\u00adgramming, pages 153 163, July 1988. [Pot96] Fran\u00b8cois \nPottier. Simplifying subtyping constraints. In Proceedings of the 1996 ACM SIGPLAN In\u00adternational Conference \non Functional Programming (ICFP 96), pages 122 133, January 1996. [Pot98] Fran\u00b8cois Pottier. A framework \nfor type inference with subtyping. In Proceedings of the third ACM SIGPLAN International Conference on \nFunctional Programming (ICFP 98), pages 228 238, September 1998. [PT98] Benjamin C. Pierce and David \nN. Turner. Local type inference. In Proc. 25th ACM Symposium on Princi\u00adples of Programming Languages, \npages 252 265, Jan\u00aduary 1998. [R\u00b4em89] Didier R\u00b4emy. Typechecking records and variants in a natural extension \nof ML. In Proc. 16th ACM Sympo\u00adsium on Principles of Programming Languages, 1989. [Str91] Bjarne Stroustrup. \nThe C++ Programming guage, Second Edition. Addison-Wesley, 1991. Lan\u00ad [TS96] Valery Trifonov and Scott \nSmith. Subtyping con\u00adstraint types. In International Static Analysis Symposium, volume 1145 of LNCS, \npages 349 365. Springer, September 1996. [Wad89] Philip Wadler. Theorems for free! In Fourth Symposium \non Functional Programming Languages and Computer Architecture, pages 347 359. ACM, September 1989. London. \n[Wel94] J.B. Wells. Typability and type checking in the sec\u00adond order .-calculus are equivalent and undecidable. \nIn Proc. 9th IEEE Symposium on Logic in Computer Science, pages 176 185, July 1994. [WJ00] Keith Wansbrough \nand Simon Peyton Jones. Sim\u00adple usage polymorphism. In Proceedings of the Third ACM SIGPLAN Workshop \non Types in Compilation, September 2000. [XP99] Hongwei Xi and Frank Pfenning. Dependent types in practical \nprogramming. In A. Aiken, editor, Confer\u00adence Record of the 26th Symposium on Principles of Programming \nLanguages (POPL 99), pages 214 227. ACM Press, January 1999.  \n\t\t\t", "proc_id": "360204", "abstract": "We present a type system for a language based on <i>F</i>&amp;le;, which allows certain type annotations to be elided in actual programs. Local type inference determines types by a combination of type propagation and local constraint solving, rather than by global constraint solving. We re ne the previously existing local type inference system of Pierce and Turner[PT98] by allowing partial type information to be propagated. This is expressed by coloring types to indicate propagation directions. Propagating partial type information allows us to omit type annotations for the visitor pattern, the analogue of pattern matching in languages without sum types.", "authors": [{"name": "Martin Odersky", "author_profile_id": "81100056476", "affiliation": "&#201;cole Polytechnique F&#233;d&#233;rale de Lausanne", "person_id": "PP14030830", "email_address": "", "orcid_id": ""}, {"name": "Christoph Zenger", "author_profile_id": "81545025056", "affiliation": "&#201;cole Polytechnique F&#233;d&#233;rale de Lausanne", "person_id": "PP31102401", "email_address": "", "orcid_id": ""}, {"name": "Matthias Zenger", "author_profile_id": "81100449273", "affiliation": "", "person_id": "PP31102329", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/360204.360207", "year": "2001", "article_id": "360207", "conference": "POPL", "title": "Colored local type inference", "url": "http://dl.acm.org/citation.cfm?id=360207"}