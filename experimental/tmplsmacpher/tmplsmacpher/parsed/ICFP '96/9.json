{"article_publication_date": "06-15-1996", "fulltext": "\n Optimality and inefficiency : what isn t a cost model of the lambda calculus? Julia L. Lawall IIarry \nG. Mairsont IRISA Computer Science Department Campus Universitaire de Beaulieu Brandeis University 35042 \nRennes Cedex Waltham, Massachusetts 02254 France Abstract We investigate the computational efficiency \nof the sharing graphs of Lamping [Lam90], Gonthier, Abadi, and L6vy [GAL92], and Asperti [Asp94], designed \nto effect so-called optimal evaluation, with the goal of reconciling optimdity, efficiency, and the clarification \nof reasonable cost models for the A-calculus. Do these graphs suggest reasonable cost models for the \nA-calculus? If they are optimal, are they efficient? We present a brief survey of these optimal evaluators, \nidentifying their common characteristics, as well as their shared failures. We give a lower bound on \nthe efficiency of sharing graphs by identifying a class of A-terms that are formalizable in @(n) time, \nand require ~(n) fan interac\u00adtions, but require Q(2n) bookkeeping steps. For [GAL92], we analyze this \nanomaly in terms of the dynamic mainte\u00adnance of deBruijn indices for intermediate terms. We give another \nlower bound showing that sharing graphs can do f2(2n) work (via fan interactions) on graphs that have \nno /?-redexes. Finally, we criticize a proposed cost model for ~-calculus given by Frandsen and Sturtivant \n[FS91], show\u00ading by example that the model does not take account of the size of intermediate forms. Our \nexample is a term requiring @(2n) steps while having proposed cost @(n). We propose some cost models \nthat both reflect this pa\u00adrameter, and simultaneously reconcile key concepts from optimal reduction. \nIntroduction The dual fields of idgorithrnics and semantics have ma\u00adtured with very little intercommunication, \nalthough both are devoted to the foundations of computation. Universal computation, as developed by Turing, \nChurch, Herbrand, Godel, Post, among others, divides naturally into those models of computation that \nare machine based (Turing machines, register machines, and their variants), and those Work petiormed \nat Brandeis Umversity, supported by ONR Grant Nooo14-931-1o15 and NSF Grant CDA-9504288. tSuPPOrtedby \nOplR Grant NOOO14-93-1-1O15, NSF Grant ccFl\u00ad92161S5,and the Tyson Foundation. Permission @ make digitslhard \ncopy of part or all of this work for personal or classroom use is ranted without fee provided that copies \nare not made or distributed for pro 1!t or commercial advantage, the copyright notice, the title of the \nublication and its date appear, and nOti03 is 9h@n that copying is t y penniesion of ACfvl, Inc. To copy \notherwise, to republish, to post on xrvers, or to redistribute to lists, requires prior specific perrnieeion \nandlor a fee. ICFP 98 5/96 PA. USA CJ 1996 ACM 0-89791 -771 -5/96/0005... $3.50 that are language based \n(A-calculus, computing with equa\u00adtions d la Herbrand-Godel, etc.). From this fundamental division one \nsees the algorithmic focus on machines, aa well as the semantic focus on languages. Optimal evaluation: \nOptimal reduction [L&#38;y 78, L4wy80], the idea of evaluating programs correctly (pro\u00adducing a normal \nform if there is one) while not duplicat\u00ading work, attempted to simultaneously achieve the goals of \ncomputational efficiency and semantic clarity. These goals sit squarely between the two cultures of algorithmic \nand semanticg. But how efficient is optimal reduction? To understand its efficiency, we also need to \nconsider reason\u00adable cost models for A-calculus. It was an open question for some fifteen years whether \noptimal reduction strategies exist, answered affirmatively by Lamping [Lam90], Kathail [Kat90], and in \na simplified way by Gonthier, Abadi, and L6vy [GAL92] (henceforth, GAL), as well aa Asperti [AsP94]. \nThe solution of GAL was appealing because it also gave a static semantics to A-calculus in the spirit \nof Girard s geometry of interaction [Gir88]; this semantics has also been recently investigated as an \nimplementation technique by Mackie [Mac95]. All these ,solutions are contributions to compiler technology \nsince they are just rarefied forms of graph reduction. In this paper, we compare and analyze the computational \nfeatures of proposed optimal evaluators, explaining what design features are common, and what computational \nre\u00adsources are required to realize these design features. While these schemes are optimal, we show that \nthey are all inef\u00adficient. Machine models: Compiler and interpreter technol\u00adogy relate the two cultures \nof machines and language5 at a theoretical level as well as at a practical one. There is a substantial \ntheory literature on machine simulations (see, e.g., the survey paper [vEB90]), founded on the in\u00advariance \nThesis, the modern-day version of Church s The\u00adsis: Reasonable universal machines can simutate each other \nwithin a polynomially-bounded overhead in time and a constant-factor overhead M space. Machine simulation \nis just the theorist s version of hardware emulation, not really different from compiler and interpreter \ntechnology except in the complexity of the source language. How ef\u00adficient are optimal evaluators-do \nthey simulate machine models well? What are the relevant cost models? More generally, can we speak of \nthe complexity of a functional program in a machine-independent way? These kinds of questions were asked \nin a provocative paper by Frandsen and Sturtivant [FS91], who proposed various implementation-independent \ncost models for the J-calculus, and showed that several well-known implemen\u00adt ation techniques (Turner \ncombinators [Tur79], Hughes supercombinators [Hug82]) are too inefficient to satisfy these cost models. \nThey leave as an open question whether their cost models, while conscientiously justified, are in\u00addeed \nattainable. This paper continues their work by an\u00adalyzing optimal evaluators in the same vein. We discover \nthat optimal reduction fails to be efficient in the sense of Frandsen and Sturtivant, even though their \ncost models are based on the idea of parallel reduction, borrowed from the optimal evacuation literature. \nWhile [FS91] implicitly endorses parallel reduction as a good idea with respect to efficiency, it does \nnot analyze whether any additional computation (for example, bookkeeping to facilitate par\u00adallel reductions) \nis computationally prohibitive. Rather than dispense with optimrd reduction as hopelessly ineffi\u00adcient, \nwe propose modifications to their cost model that we believe to be more realistic. Furthermore, we argue \nthat realizing this revised model is intimately related to the bookkeeping problems inherent in lproposed \noptimal reduction schemes. Technical contributions: We present optimal reduc\u00adtion d la Lamping, GAL, \nand Asperti, making the follow\u00ading observations: We present a taxonomy of operators from each scheme, \nindicating which of myriad interactions are computationally explosive. We link the problematic form of \nbracket interaction to deBruijn indices (i.e., lexical addresses), and to a beginning analysis of the \ncost of substitution in optimal reduction.  We present a lower bound on the efficiency of Lamp\u00ading, \nGAL, and Asperti, by identifying classes of terms requiring Q(2n) graph reduction steps, with only @(n) \ninteractions of so-called fan nodes, where we regard such fan interactions, which include ~\u00adreduction, \nas the essential work being performed. The acklitional required bookkeeping overhead re\u00adquired swamps \nthe real work, and for an infinite class of terms approaches the efficiency of normal order evaluation. \nWhether such bookkeeping can be made efficient remains the biggest open question in this area.  If we \nfurther divide the real work done by optimal reduction strategies into parallel @-steps and comple\u00admentary \nfan interactions, we present another lower bound on efficiency, showing that /such fan interac\u00adtions \nmay grow exponentially in the number of par\u00adallel /3-steps, even when the corresponding term is in normal \nform. Knowing whether a graph-encoded term is in normal form requires a global analysis that local reduction \nrules seem N-equipped to provide. Sharing is undone via duplication in optimal reduc\u00adtion to facilitate \n~-reduction: how can this duplica\u00adtion be controlled?  We analyze the cost model of Frandsen and Sturtivant \nbased on parallel reduction, and provide concrete evidence that it is not met by any of the oP\u00ad  timal \nreduction schemes. We further answer a con\u00adjecture of Frandsen and Sturtivant concerning the polynomial \nrelatedness of two of their proposed cost models, showing they are not so related. The essence of these \nanalyses is the identification of a class of terms that require @(2n) fan interactions to reduce the \ncorresponding term to normal form, while requir\u00ading only @(n) parallel /?-steps. A very similar result \nwas recently and independently derived by Asperti [AsP96] in his analysis of the inherent Complexity \nof ~-reduction. We observe that normal order evaluation is an ac\u00adceptable machine model in the sense \nof the ortho\u00addox Invariance Thesis. Thus the debate over cost models is largely fine structure, or the \nthesis is too crude. The key observation is that sharing and ma\u00adchine simulation have little in common. \nb We propose two cost models for the A-calculus based on t-he jabelled A-calculus, and we use them to \nmoti\u00advate further work in this area. While there is a developing literature on implementa\u00adtions of optimal \nevaluation based on graph reduction, we explore its finitary dynamics from an algorithmic perspec\u00adtive. \nBecause a lot of this literature is technical, we also provide a gentle introduction to optimal reduction \nthat we hope is digestible to the general reader. While [GAL92] parodied Lamping as TV Digest, we found \ntheir presen\u00adt ation, however brilliant, an impenetrable synthesis of the traditions of Bourbaki and \nHunter Thompson. As much as possible, we return to the TV Digest vernacular. 2 Sharing graphs for A-calculus \nTraditional technology for evaluating functional programs can be categorized according to the eficien \ncy and safety of ,8-reduction. When the value of an expression is multiply used, efficiency requires \nthat it not be evaluated more than once. When the value of an expression is never used, safety requires \nthat it not be evaluated. Graph reduction (see, e.g., [P J87]), used to implement lazy functional languages, \ncompromises between these two goals: /3-reduction binds all occurrences of the parameter to a single \nshared graph representing the argument. When the value of some oc\u00adcurrence of the parameter is requested, \nthe argument is evaluated. Sharing causes all other occurrences of the pa\u00adrameter to return a result \nimmediately. This strategy works well until the shared value is a A-abstraction and is applied. Since \neach use of the A-Abstraction may apply it to a different argument, the body of the A-abstraction cannot \nbe shared after /3-reduction. When a A-abstraction is applied, a new copy of its body is instantiated \nwith the argument. This copying may be excessive, since other computations in the A-body not de\u00adpending \non the argument could still be shared. Lamping [Lam90] had the great idea of economizing via partial \nsharing of the body. In other words, instead of copying the whole body, just copy the J-node at the top \nof the graph representing the function, and continue to share the body of the function. This scheme introduces \nthe sharing of evaluation contests (multiple vaJues evalu\u00adated concisely in the same shared context) \nas well as the more obvious sharing of values (one value evaluated con\u00adcisely in multiple contexts), \nand makes these two kinds of sharing dually complementary to effect duplication. Since no redex is ever \nduplicated, Lamping s evaluator is thus ef\u00adficient in the number of /3-reductions and safe, or optimal. \nThe algorithmic variations on his fundament al observation (e.g, [GAL92, Asp94]) consist of alternative \nlow-level im\u00adplement ations of his sharing nodes. We now briefly sketch Lamping s basic idea, and variations \non its implementa\u00adtion. 2.1 First version: no sharing allowed For a moment, forget about sharing, and \nconsider a first version that implements a A-calculus where bound vari\u00adables occur at most once. We see \ntwo kinds of ternary nodes: J nodes and @ nodes.1 A value is given by a wire. The terms kc.E, EF, and \n(kc.E)F are represented by the following graphs, where graphs for E and F are similarly defined: Ax.E \nEF (Ax.E)F E @ E +-Y EF E F bF?@ ! F yx a yx The bound variable wire for x in Ax .E wraps around to \nthe right side of the J node in the graph; a free variable wire to y also appears. This wrap around feature \nal\u00adlows @-reduction to be defined by a simple rewrite rule, as shown by example in the reduction (kc..E)F \n+ E[F/z], where the A and @ nodes annihilate, and their wires are fused. The rule is shown below:  % \nII 2.2 Second version: sharing with omniscient fan nodes Now let s add fan nodes to implement sharing, \nfor example the term A s kz.xx that has two references to x. Figure 1 shows the reduction of AA. After \nstep 1, the value of the second A is shared by a fan node. A new graph rule is introduced to push the \nsharing node past the J node, partialig sharing the A-body (value sharing) as well as the context of \nits bound variable wire (context sharing). (Dually, one can partially share an ap\u00adplacation. ) In thus \nunsharing the A node, we create two A nodes one for each use and two sharing nodes. The left positive \nnode shares the body of the k-expression; the right negative node shares the context provided by the \nbody with two uses (step 2). The pair of nodes serves as a kind of switch, where setting both to left \ngives F(M), and setting both right gives F(N). The context semantics given in [GAL 92] is an elaborate \nmechanism for iteratively setting these switches. 1 We annotate A-nodes with the name of the bound variable \nfor clarity m@ @ ill4. @@ t w@ 4 Figure 1. The reduction of AA Next, we consider the interaction of \nfan nodes (p) and (q) above. When fan nodes interact that are (omni\u00adsciently) the same, they annihilate \neach other, while when diflerent, they duplicate each other: X+\u00ad same different In this case, they are \ndifferent (step 3). The fan node under the @ then duplicates the application, and its copies annihilate \nthe fan nodes on the other side (steps 4 and 5). How do fan nodes facing each other know if they are \nthe same or diflerent ? This question is the key technicfl implementation issue to be resolved in optimzd \nreduction. Its answer is what makes optimal reduction schemes so hard to understand: the respective tours \nde force of Lamp\u00ading, GAL, and Asperti each resolve it differently. They cdl agree which fans are the \nsame and diflerent; they only dis\u00adagree in how this information is determined. The different solutions \nare all variations on the same theme: a numeri\u00adcal indez is maintained by each fan node, and two nodes \nare the same if they have the same index. In each im\u00adplementation, new graph operators are introduced \nwhose sole purpose is bookkeeping the dynamic mutation of fan node indices. 2.3 Third version: sharing \nwith bookkeeping nodes In the bus system, the single wires of the previous dia\u00adgrams are replaced by \na bus of wires, where graph oper\u00adators travel on particular wires of a bus. The bus gives a physical \ninterpretation to the idea of indez mentioned above the index is just the position of the operator on \n the bus. Additionally, new graph operators, called crois\u00adsant and bracket, are introduced to mutate \nindices of other operators. Croissant and bracket nodes mark the bound\u00adary ports of regions of the sharing \ngraph. As a sharing node enters such a region, they modify its index appro\u00adpriately. Each of the different \nimplementations GAL, Asperti, Lamping chooses particular kinds of regions to be annotated with croissant \nand bracket nodes at port positions. Now for the fine print: A fan node joins two buses. Fan nodes implement \nsharing, as well as ~ and Cl. A bracket combines two wires into one, A croissant creates a new wire. \n11 Nodes can appear in any orientation. In each case we have drawn the node with its interaction port \nfacing downwards. Two nodes only interact if their interaction ports are facing each other. The rules \nfor their interaction are shown in Figure 2. By annotating each node with an index, indicating the number \nof wires to its right, we can abbreviate the multi\u00adwire bus using a single wire. The rules for the one-wire \nbus can be derived from the rules for the multi-wire bus. In particular, the index of a node is incremented \nwhen it passes to the left of a bracket, and decremented when it passes to the left of a croissant. We \nrefer to interactions involving brackets and crois\u00adsants as bookkeeping. The complementary fan interactions \ncontain a subset consisting of parallel /3-steps, since fan nodes can be used to implement ~ and @ as \nwell as shar\u00ading. 2.3.1 GAL GAL s translation of lambda terms into graphs is as fol\u00adlows: Ax.M MN \\ 42 \n n MN node is nested. Asperti s algorithm begins by assigning an index to each sub term. The index of \nthe entire term is O. The indices of the subterms are calculated as follows: \\ \\\\\\ //  !7-7J x Y / \n(EF) = (J2X.+1 ). / \\\\-$+(k.E) = (Xc.&#38;)n v Vn = This encoding uses brackets in three wavs. Stack \nbrackets sulit the leftmost . not affect the index of any sharing node; sider them further. Redex brackets \ntravel C.! nodes like pilot fish on a shark. Free-variable brackets, which are the most problematic, \nmanipulate an analogue of deBruijn indices. In the initial graph, the number of free-variable brackets \nequals the deBruijn index of the oc\u00adcurrence of the identifier. In GAL, the index of a sharing node is \nthe number of nested A-bodies the sharing node has begun to copy. This index is maintained by the inward-facing \nredex and free\u00advariable brackets surrounding all entrances to a A-body, as shown by the translation of \na A-abstraction above. En\u00adtrance is via one of the extremal ports of the graph, located at the root, \nthe bound variable, and any free variables. At the root and the bound-variable ports the redex brackets \nincrement the index of an entering sharing node. When a sharing node enters at a free-variable port, \nits index is incremented by the free-variable bracket. The graph simulation of /3-reduction must (1) \nsub\u00adstitute the argument for the parameter, and (2) adjust the deBruijn indices of variables, represented \nin unary as stacks of free-variable brackets. During ,8-reduction in graphs, redex brackets at the A-node \nand @ node annihi\u00adlate each other, connecting root to J-body, and parameter to argument, achieving the \nsubstitution. In the A-calculus, ,f?-reduction of (kr..E)F affects deBruijn indices as follows: the index \nof every free variable in E is reduced by 1, and for each occurrence of z with index k in k .E, the index \nof every free variable in the substituted .F is incremented by k 1. In GAL, the brackets on the free-variable \nports of the A-body are not eliminated during ~-reduction, nor does the Xnode have direct access to them; \nthus, the body is delineated even after annihilation. To adjust the de-Bruijn indices, a croissant node \nintroduced at the applica\u00adtion migrates lazily to the free variable ports, decreasing all deBruijn indices \nby 1. Brackets at the parameter port migrate lazily to the free-variables ports of the substituted argument, \nand are appended to the brackets found there. In the bureaucracy of index management, the 1-1 of a croissant \nhitting a bracket is not reduced to zero, even though it has zero effect on the index of passing nodes, \nsince such bureaucratic junk may need to annihilate with other nodes. This anomaly is the essential bottleneck \nof GAL, and of optimal reduction schemes more generally: details vary with respect to Lamping and Asperti, \nbut the essential problem is the same. 2.3.2 Asperti In GAL, the index of a sharing node is the number \nof J-bodies in which the sharing node is nested. Asperti counts applications instead: the index of a \nsharing node is the number of argument positions in which the sharing -n quite different wire. These \ndo we do not con\u00ad next to J and / ,/\\/ m Figure 2. The translation of an indexed term into a graph is \nshown below. Ax.En En Fn.+1 fJn ?Lr+  h:? a< En Fw, n En n+ nn If an occurrence of identifier v has \nindex k, and the A-abstraction binding v has index 1, then the wire cod\u00ading the occurrence holds a sequence \nof k 1 brackets. When the identifier is bound, these brackets propagate over the value, incrementing \nthe indices to reflect the new argument-nesting depth of each occurrence. The sequence of brackets representing \nan identifier ends in a croissant. GAL uses a croissant in an appli\u00adcation because a /3-reduction causes \none J-abstraction to disappear. Here the croissant reflects the fact that a @\u00adreduction causes one application \nto disappear. The crois\u00adsant is directly part of the translation of an identifier, rather than being \nintroduced by an application. It has no effect, however, until the identifier is bound by an ap\u00adplication. \nLower bounds The exponential lower bounds we present on the efficiency of optimal reduction are all based \non application of the term C~ -k.~(~(. . . (;z). . .)) to different arguments, where the n applications \nof ~ s Js. h.s(sz) refer to the familiar Church numeral. We use C. to construct a term that normalizes \nin ~(n) ~-steps, but requires Q(2 ) book\u00adkeeping steps, mostly involving bracket and croissant in\u00adteractions. \nWe then use Cn to construct another term that contains no further ~-redexes after ~(n), but the graph \nrepresent ation requires Q (2n ) further fan interactions to normalize. These examples show that the \nbookkeeping overhead needed to implement fan interactions (including parallel ,6steps) can grow exponentially \nin the number of m Interaction rules 3.1 Computing an exponential iterator Consider the reduction, in \nthe l-wire bus with omniscient fan nodes, of (As. Jz.s(sz))(Az.E), where kz.E is closed and normalized: \n + @@@ E   $9ii! &#38; HB E =+ 4 E E We use ~ to denote a sequence of reductions. In this last sequence, \nthe linked fan nodes duplicate the graph E between them; the boldface wire linking the fan nodes says \nto connect the z port of the first copy to the root of the second copy. This configuration of fan nodes \nis a key succinctness primitive: for example, here is how to code 2n applications of ~ to z in a graph \nof size @(n): /8 x \\ n L [m @ such interactions, and that the local reduction rules are v f not sufficient \nto efficiently detect normal form. 3.2 First analysis: bookkeeping overwhelms fan interaction Consider \nthe term E = Cm(Jz.Ag.xy). Since a sim\u00adple calculation shows (~s.~z.s(sz))(~z.~y.zy) D A.z.)iy.zy, clearly \nE normalizes in ~(n) @steps. The initial graph quickly gets rewritten to: Via the reduction sequence \nwe see that the graph normalizes in ~(n) parallel /3-steps as well. The duplicated term has a constant \nnumber of Cl, ~, and fan nodes, suggesting that a constant amount of copying work is done at each of \nn iterations. This is not the case! The pairs of fans duplicate whatever is between them, including bookkeeping \nnodes. If the duplicates do not annihilate, the copying work doubles on each iteration. The first iteration \nof-GA~looks like this: *a f!! The kth iteration looks like: { U@ @ * 4 translation of Xz .s) the \nreduction in Asperti s system be\u00adhaves similarly. Theorem 1. GAL and Asperti take Q(2n) bookkeeping steps \nto eflect n parallel ~-steps. In the reduction of the term Cn (kc. ~y.sg), there are complexes of brackets \nand croissants of size Q(2n) that travel through the graph, even though their effect on wire indices \nis 0(1). The complexes are designed to readjust deBruijn indices; they form a kind of base 1 with no \nsub\u00adtraction, where + is a bracket and is a croissant. We can write, say, 2, as ++, or + ++, or as \nany string with two more + than , without a simplification rule that rewrites substrings + and + to e. \nThis redundancy has sug\u00adgested various optimizations, which we assess in Section 4. 3.3 Second application: \nlocality and unnecessary fan interaction Consider the difference between putting the pair of fans around \nthe ports of ~y.zy and Ay. yz. The first case is the basis of Section 3.2, and causes the construction \nof a j?\u00adredex. The second case causes duplication, but no ,&#38;redex is made: $ri J$i--2b @@ K ti \nTo iterate this peculiarity, we reduce C~(Xz.Ay.yZ). The compact encoding we really want is given by \nthe first intermediate form below. This graph represents the term ~y.y(~g.y(~y.y( ...))), which is in \nnormal form. To normal\u00adize the graph, the sharing nodes need to be propagated, with an exponential explosion \nin graph size: $?  P@ 4- The point of unsharing by propagating fan nodes is to partially duplicate \nA and @ nodes in order to create /3\u00adredexes. One then needs a global strategy for propagating the right \nfan nodes. The beauty of graph reduction lies in its dependence on local rewrite rules, but therein lies \na limitation, since it is insufficient to identify useful work. Because Asperti also uses brackets andl \ncroissants in the Detecting redexes seems to require a static analysis like translation of Xz.Ay.zy (and \nindeed, unlike GAL, in the GAL s context semantics, which can be very expensive. Theorem 2. Optimal evaluators \nallow Q(2n) useless fan interactions where there are no /3-r-edexes to reduce. Asperti has suggested \nthat we avoid this anomaly by considering only terms that normalize to constants [Asp96]. In this case, \nall functions are used, and all ap\u00adplications become redexes. But what if we remove this assumption can \nsharing be implemented with minimal overhead and no implicit foreknowledge that all functions will be \napplied? Optimizations The inefficiency in the reduction of C. (k .Jv.*Y) comes from the duplication \nof the brackets and croissants intro\u00adduced in the translation of Jz. Jg. zy. Brackets and crois\u00adsants \nare only useful to adjust the indices of sharing nodes. Because /lx. Jy.zy contains no sharing nodes, \nthe book\u00adkeeping nodes serve no purpose. Asperti and Lamping have each proposed rules to eliminate these \nnodes. While their approaches improve performance for Ax .Jy.z~, they do not eliminate the problem of \nexcess duplication in gen\u00ad eral. 4.1 Asperti Asperti [AsP95] observed, by way of category theory, that \nwe can replace a croissant atop a bracket by a single wire, when we can guarantee that neither the bracket \nnor the croissant ever annihilate with any node in the graph. Such brackets and croissants are called \nsafe. In the initial graph, every bracket and croissant is safe. A bracket or croissant becomes unsafe \nwhen it propagates over a lambda node. It becomes safe again when it reaches a safe node of lower index. \nSo that unsafe nodes can reach safe nodes, new rules should be introduced allow brackets and croissants \nto move from the root of an application to the function and argument positions (such rules are not mentioned \nby Asperti). If these optimization rules are applied when\u00adever possible, this system can reduce C&#38;( \nid) in ~(n) steps, where id is any q-expansion of AZ. x. 4.2 Lamping Although Lamping s algorithm [Lam90] \npreceeded both GAL and Asperti, it can be seen as a variant of GAL with Asperti s optimization rules \nbuilt in. Like GAL, Lamping uses brackets to mark free-variable ports, and croissants to cancel free-variable \nbrackets when a A abstraction is ap\u00adplied. Lamping uses two kinds of brackets: round brackets that are \nsafe, and square brackets that are not safe. Lamp\u00ading s algorithm does contain the rules to allow croissants \nand unsafe brackets to move from the root of an appli\u00adcation to the function and argument positions. \nWhile at first glance, the number of Lamping s rules seems daunt\u00ading, most follow the bus-oriented rules \ndescribed in Section 2.3, with additional rules for manipulating and optimiz\u00ading safe brackets. Like \nAsperti, if the rules are applied in the right order, Lamping can reduce Cn (id) in @(n) steps, where \nid is any V-expansion of Ax .x. 4.3 GAL Although GAL is based on Lamping, it is not clear how to extend \nthe optimization to GAL. In the Lamping t ransla\u00adtion of source terms, a croissant is placed over the \nroot of any lambda abstraction containing a free variable. This croissant does not move until the lambda \nabstraction is applied. If there is no sharing, it is then free to move through the term to annihilate \nthe free-variable brackets. In GAL the croissant is introduced by the translation of an application. \nIf in the source term the function position is a free variable, the croissant gets stuck on top of these \nfree-variable brackets. In our example we wind up with the following (omitting some of the bookkeeping \nnodes). l I @@ ,1 1,  ?(iT Uu The boldface croissant should cancel the boldface free\u00ad variable bracket, \nbut the free-variable bracket below the croissant is perpetually in the way.  4.4 More trouble The efficacy \nof the optimization relies on the ability of the croissant to reach the corresponding free-variable bracket \nso they can annihilate before being duplicated. However, the optimization, and any sophisticated variant \nof it (e.g., making the rules for safety more complex), is useless if the croissant cannot reach the \nbracket. For example, in the term C~(Az.Ag. (Aa.aa)(Az.(zy) z)), after ~(n) fan re\u00adductions there are \nno more ~ steps. Because the croissant representing the application of (~g ....) gets stuck on the sharing \nnode of (Au. au), it cannot cancel with the free\u00advariable brackets, and exponential duplication is required. \nThus Theorem 3. GAL, Lanaping, and Asperti, with and with\u00adout optimization, take fl(2n) bookkeeping to \ne~ect n par\u00adallel ~-steps. 4.5 Guerrini Guerrini [Gue95] shows how Asperti s stacks of brackets and \ncroissants can be represented as integers. Rather than canceling croissants against brackets, he shows \nthat at the bound variable port of a lambda node it is safe to combine these integers using addition. \nUnfortunately, as shown by the example in Section 3.2, by the time the brackets and croissants reach \na bound variable port of a lambda node, the exponential duplication has already taken place. 5 Cost models \nA cost model for the A-calculus should be implementation independent, so it can be used as a metric to \nmeasure the efficiency of different implementations. Taste and aes\u00adthetics govern choice of a model, \nwith a sanity check given by the Invariance Thesis: Reasonable universal seem likely that sharing graphs \ncan improve measurably machines can simulate each other within a polynomially\u00ad bounded overhead in time \nand a constant-factor overhead in space [vEB90]. This sanity check has two basic components: (1) if reducing \nE requires time tand space s, then there must be an implementation (say, on a Turing machine) using P(t) \ntime and cs space, for some fixed polynomial P and constant c; (2) there must be a coding of Turing machine \ncomputations as A-terms, with accompanying reduction strategy, such that given any Turing machine requiring \nT(n) time and S(n) space to accept or reject an input of length n, the A-calculus simulation of that \nTuring machine computation can be so effected in P(Z (n)) time and cS(n) space. While the sanity check \nrules out the truly unrealistic cost models the unattainable ones, as well as the overly costly there \nis a large enough slop factor that cost models and strategies, typically regarded as inefficient, nonetheless \nbecome admissible. For example, we have the following, disconcerting claim: Theorem 4. The cost of normal \norder evaluation, naively implemented, satisfies the invariance thesis. Namely, to reduce a term, write \nit down on a piece of paper. Write down successive terms derived from ,B\u00adreduction, using a leftmost-outermost \nstrategy: total ink (or paper area) used is the time cost, and maximum ink (or paper) used for any term \nis the space cost. This metric can be realized (with polynomial slowdlown for time, and constant expansion \nfor space) on a Turing machine. More surprisingly, an arbitrary Turing machine can be simu\u00adlated efficiently, \nusing your favorite coding [FS91 ] essen\u00adtially gives one; [HM94] gives another. The explanation of the \nefficiency of the simulation is simple: the simulation does not depend in any profound way on sharing. \nIn an attempt to define a more parsimonious cost model, Frandsen and Sturtivant [F S9111proposed the \nfol\u00adlowing: the cost of a reduction to normal form is the length of the the initial and final term, plus \nthe number of parallel /3-steps. They point out that several standard combinator\u00adbased implementations \n(e.g., [Tur79, Hug82]) require time exponential in the cost model. We observe that optimal reduction \nstrategies, even without counting bookkeeping, fail to run polynomially in the Frandsen-Sturtivant cost \nmet ric. 5.1 Optimal evaluators fail the Frandsen-Sturtivant test Our evidence against the Frandsen-Sturtivant \nmodel is the reduction of the term F ~ E(Az. z), where E s C~(Js.,lz.s(sz)). Since F has length El(n), \nreduces to the term Jz.z of length ~(l), and can be SC,reduced in 5n + 1 parallel /3-steps, its Frandsen-Sturtivant \ncost is @(n). To reduce F to normal form, an optimal evaluator must normalize E to the Church numeral \nfor 22 . Dur\u00ading this reduction, the fan sharing the two occurrences of s in As. XZ .S(SZ) is duplicated \nexponentially. This dupli\u00adcation follows the pattern of the exponential free-variable bracket duplication \nin Section 3.2. This work seems to be essential, since a @(2m)-node graph (hence El(n2n) bits) is being \nused to represent the numeral for 22 . It does not on binary representations of integers. Theorem 5. \nIf v(E) is the Frandsen-Sturtivant cost met\u00ad ric for evaluating a A-term E, then the number of fan in\u00ad \nteractions required by existing optimal evaluators grows as Q(2@). This result was derived independently \nby Asperti [AsP96], using a more complicated term having similar consequences. The reduction of E to \nnormal form also answers a con\u00ad jecture posed by Frandsen and Sturtivant [FS91]. In their paper, they \nidentify a family of terms requiring at least 5n /3-steps to normalize, but only n parallel /3-steps. \nThey conjectured that the ratio of ordinary to parallel /?-steps could be exponential. The reduction \nof E shows that the ratio can in fact be doubly exponential. Observe that the Church numeral for 22 is \ncomputed by iterating squaring n times: 22n = (.. . (22)2 . . .)2. l o square k, we reduce ~~, where \n17i is the Church numeral for m. This reduction requires Q(k) ordinary /3-steps. In reducing E, then, \nthe final squaring requires at least 22*\u00ad ordinary ~-steps. As a consequence, we derive the follow\u00ad ing: \nTheorem 6. There exists a family of A-terms that nor\u00admalizes in 2Q(2 ) ordinary /3-steps, but only @(n) \nparallel fl-steps and @(2n) fan interactions. Theorem 5 implies that optimal evaluators are ineffi\u00adcient: \ndo we discard the message and look for a better cost metric, or do we kill the messenger and look for \na better evaluation algorithm? We think both are necessary. Not only are efficiency improvements needed \nfor optimal re\u00adduction at the bureaucratic level, we also need a more realistic cost model. The lesson \nof this example is very clear: the model of [FS91] does not take into account the size of intermediate \nterms. Furthermore, we consider the work of the sharing nodes, even if their work is indepen\u00addent from \n/3-reduction, to be essential. By contrast, the work of brackets and croissants seems more bureaucratic. \n5.2 Cost models based on fan interaction In his recent paper, Asperti has proposed a cost metric where \nthe intrinsic complexity of a A-term is the number of fan interactions incurred in the normalization \nof the term [Asp96]. Intuitively, he writes, Lamping s abstract al\u00adgorithm does not seem to perform any \nuseless operation. We comment briefly on this proposal First, it seems undesirable to base the inherent \ndiffi\u00adculty of reducing a term on an implementation. Denota\u00adtional semantics was invented, in part, to \nliberate meaning from implementation; the same ought to be true of cost. In this case, there would be \nnothing left to prove: Lamp\u00ading s abstract algorithm is certainly optimal in the cost model. Do we as \na consequence know anything new? Second, the proposal seems premature in the face of the research community \ns considerable lack of insight into optimaJ evaluation. Imagine that the subject was instead sorting, \nand the best proposed algorithm was insertion sort. Surely we would not want to declare insertion sort \noptimal by fiat-we would be better off learning more about sorting. n Last, the proposal ignores the \nrole of brackets and croissants. W bile these operators seem to cause needless bureaucracy, they do play \na crucial role in demarcating the boundaries of regions, e.g., in GAL, the bodies of J-terms. If Asperti \ns proposal is to be taken seriously, it implies that this concept of boundary is not essential. 5.3 \nCost models based on labelled A-calculus A more realistic, implementation independent cost model is immediately \nsuggested by the (L6vy)-iabeiled A-calcuius, of which there are many flavors: we have relied on the ver\u00adsion \nin [Fie90]. Briefly, each subterm of the initial J-term is initially annotated with a unique kzbel. As \nreduction occurs, labels are concatenated according to certain rules, so that the labels encode the history \nof the computation. When (Az .E)F is reduced, the label on each free z in E is (reverse) concatenated \nwith a unique new label associ\u00adated 1-1 with the label of the function, and the label of the argument; \nthe label of E is concatenated with the new label, and the label of the redex: (Xr.E)gF ~ E~[z H Fg] \n For example, ((AX . (r? z ) ) (Ax. ($ z ) ) ) + ((k.( $ Z- ) ) -+ (Ax.($ z ) ) + ) : L&#38;y s original \nidea of optirnality is that all redexes in the entire computation having identical labels on the (func\u00adtion \npart are reduced in one parallel ,B-step. The first cost model we propose, providing more money) than \nthat of Frandsen and Sturtivant, though not at initiaJ glance realizable, is that the cost of reducing \na term is the number of unique labels generated in the re\u00adduction. A second, more liberal cost metric \nis one where we sum the length of the labels generated. We conjecture that the number of fan interactions \nis polynomial in the number of labels, and that the total number of interac\u00adtions, including bureaucratic \nones, is polynomial in the sum of the lengths of the labels. Frandsen and Sturtivant showed Turner combinators \nand Hughes supercombinators to be inefficient in terms of their proposed cost model, identifying a family \nof terms involving sharing that require Q ( 2n ) combinator reduction steps, while normalizing in only \nEl(n) ~-steps. Optimal evaluators can reduce this family oft erms with only ~(n) fan interactions because \ndifferent sharing nodes do not duplicate each other. As a consequence, combinators are not efficient \neven under these more liberal cost models. 6 Summary; open questions Many important questions concerning \nthe computational efficiency of optimal reduction remain unanswered, includ\u00ading several we have considered \nin some detail. They in\u00adclude: 1. Can the exponential lower bounds of Section 3 be made stronger? Are \nthere examples that require, say, Q (22 ) bookkeeping interactions to effect n fan node interactions? \nWe conjecture no: sharing nodes copy the body and then come to rest at free-variable ports. Thus corresponding \nto each fan interaction, there is at most a doubling of the size of some graph. The question is, though, \nwhat graph: reducing a ,f?\u00adredex in the body of a A-abstraction can allow a sharing node duplicating \nthe ~-abstraction to also duplicate other nodes. 2. Can the cost models we have proposed be realized \nby implementations? Such a demonstration is non\u00adtrivial. 3. Can the bookkeeping interactions that update \nde-Bruijn indices be related in a more precise, natural way to the cost of substitution? 4. Can similarity \nof fan nodes be dynamically main\u00adtained using altogether different methods, perhaps relying on more sophisticated \ndata structures with\u00adout all the pitfalls of current methods? 5. Can completeness bounds be proven on \nthe difficulty of optimal evaluation? For instance, given a A-term E and a constant k where log k is \npolynomial in the length of E, can E be normalized in no more than k parallel steps? Were such a question \ncomplete for, say, exponential time, this would be a coup de grcice to the entire idea of efficient optimal \nevaluation. 6. Similarlv, .,-might efficient imdementation of o~timal evaluation imply unlikely hierarchy \nrelations, e.g., if k parallel f?-steps can be implemented with overhead polynomial in k, then P = NP \n(or something like that). Such an approach would involve clever and nontrivial coding of generic problems \n(time bounded computation, satisfiabilit y, etc. ).  After having spent tremendous time and effort \nunder\u00adstanding optimal reduction mechanisms and their efficien\u00adcies, we are left with an overriding impression: \nfew al\u00adgorithmic insights have followed Lamping s breakthrough. Progress has been made in identifying \na static (context) se\u00admantics, in understanding how L6vy labels identify paths in the graphs, and in \nalternate mechanisms for hacking the indices of sharing nodes. However, nobody can do it with appreciably \nless bookkeeping overhead than Lamp\u00ading, including us. Further progress in developing these algorithms \nmust come from a better global understanding of the dynamics of the bookkeeping nodes, so that redun\u00addant \nnodes can be eliminated. Acknowledgments. Thanks to Paris Kanellakis, John Field, Doaitse Swierstra, \nand Georges Gonthier for several very helpful discussions on complexity aspects of the A- Calculus. \nReferences [Asp94] Andrea Asperti. Linear logic, comonads, and op \u00adt%mal rea!u cti om. Unpublished manuscript. \n[Asp95] Andrea Asperti. 60!c = 1: optimizing optimal A-calculus implementations. Proceedings, RTA, 1995. \n [Asp96] [Bar84] [VEB90] [Chu41] [Fie90] [FS91] [Gir88] [GAL92] [Gue95] [Hug82] [Kat90] [Lam90] [L6vy78] \n[L6vy80] [HM94] [Mac95] Andrea Asperti. On the complexity oj beta. reduction. 1996 ACM Symposium on Prin\u00adciples \nof Programming Languages, pp. 110 118. Henchik Barendregt. The Lambda Calculus: Its Syntax and Semantics. \nNorth Holland, 1984. Peter van Erode Boas. Machine models and sim\u00ad ulation. Handbook of Theoretical Computer \nScience, volume A, pp. 1 66. North Holland, 1990. Alonzo Church. The Calculi of Lambda\u00adconversion. Princeton \nUniversity Press, 1941. John Field. On laziness and optima[ity in lambda interpreters: tools for specification \nand analy\u00adsis, 1990 ACM Symposium on Principles of Programming Languages, pp. 1 15. Guchnund S. Frandsen \nand Carl Sturtivant. What is an ef/icient implementation of the A-calculus? 1991 ACM Conference on Functional \nPro\u00adgramming and Computer Architecture (J. Hughes, cd.), pp. 289 312. Jean-Yves Girard. Geometry oj interaction \nI: interpretation of System F. Logic Colloquim 1988, pp. 221-260. Elsevier (North Holland), 1989. Georges \nGonthier, Martin Abadi, and Jean-Jacques L&#38;y. The geometTy of optimal lambda reduction. 1992 ACM \nSymposium on Princi\u00adples of Programming Languages, pp. 15 26. Stefano Guerrini. Sharing-graphs, sharing\u00admorphisms, \nand (optimal) i-graph reductions (draft). Unpublished mmmscript. June 16,1995. John Hughes. ,$upercombinators: \na new imple\u00admentation method foT applicative languages. 1982 ACM Symposium on Lisp and Functional Programming, \npp. 1 10. Vinod Kathail. Optimal inte?pretem for lambda\u00adcalculus based functional languages. Ph.D. Thesis, \nMIT, May 1990. John Lamping. An a/goTithm for optimal lambda calculus reduction. 1990 ACM Symposium on \nPrinciples of Programming Languages, pp. 16 30. Jean-Jacques L6vy. Reductions come.tes et opti\u00admales \nclans /e lambda-calcul. Th%e d Etat, Uni\u00adversit6 Paris 7, 1978. Jean-Jacques L6vy. Optima/ reductions \nin the lambda-calculus. To H. B. Curry: Essays in Combinatory Logic, Lambda Calculus and Formalism, (Jonathan \nP. %ldin and J. Roger Hindley, editors), pp. 159 191. Academic Press, 1980. Harry G. Mairson and Fritz \nHenglein. The com\u00adplexity of type inference for higher-oTde? typed lambda calculi. Journal of Functional \nPro\u00adgramming 4:4 (October 1994), pp. 435-478. Ian Mackie. The geometTy of interaction ma\u00adchine. 1995 \nACM Symposium on Principles of Programming Languages, pp. 198 208. [PJ87] Simon Peyton-Jones. The of \nFunctional Programming Prentice-Hall, 1987. Implementation Languages. [Tur79] David A. Turner. New implementation \nfor applicative languages. Software and Experience 9 (1979), pp. 31 49. techniques Practice   \n\t\t\t", "proc_id": "232627", "abstract": "We investigate the computational efficiency of the <i>sharing graphs</i> of Lamping [Lam90], Gonthier, Abadi, and L&amp;eacute;vy [GAL92], and Asperti [Asp94], designed to effect so-called <i>optimal evaluation</i>, with the goal of reconciling optimality, efficiency, and the clarification of reasonable cost models for the &amp;lambda;-calculus. Do these graphs suggest reasonable cost models for the &amp;lambda;-calculus? If they are optimal, are they efficient?We present a brief survey of these optimal evaluators, identifying their common characteristics, as well as their shared failures. We give a lower bound on the efficiency of sharing graphs by identifying a class of &amp;lambda;-terms that are normalizable in &amp;Theta;(<i>n</i>) time, and require &amp;Theta;(<i>n</i>) \"fan interactions,\" but require &amp;Omega;(2<sup><i>n</i></sup>) bookkeeping steps. For [GAL92], we analyze this anomaly in terms of the dynamic maintenance of deBruijn indices for intermediate terms. We give another lower bound showing that sharing graphs can do &amp;Omega;(2<sup><i>n</i></sup>) work (via fan interactions) on graphs that have no &amp;beta;-redexes. Finally, we criticize a proposed cost model for &amp;lambda;-calculus given by Frandsen and Sturtivant [FS91], showing by example that the model does not take account of the size of intermediate forms. Our example is a term requiring &amp;Theta;(2<sup><i>n</i></sup>) steps while having proposed cost &amp;Theta;(<i>n</i>). We propose some cost models that both reflect this parameter, and simultaneously reconcile key concepts from optimal reduction.", "authors": [{"name": "Julia L. Lawall", "author_profile_id": "81100529486", "affiliation": "IRISA, Campus Universitaire de Beaulieu, 35042 Rennes Cedex, France", "person_id": "PP15035219", "email_address": "", "orcid_id": ""}, {"name": "Harry G. Mairson", "author_profile_id": "81100061196", "affiliation": "Computer Science Department, Brandeis University, Waltham, Massachusetts", "person_id": "P107959", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/232627.232639", "year": "1996", "article_id": "232639", "conference": "ICFP", "title": "Optimality and inefficiency: what isn't a cost model of the lambda calculus?", "url": "http://dl.acm.org/citation.cfm?id=232639"}