{"article_publication_date": "06-15-1996", "fulltext": "\n The Semantics of Scheme with Future Luc Moreau* University of Southampton L .Moreau@ecs. soton. ac .uk \nAbstract We present the formal semantics of future in a Scheme-like language which has both side-effects \nand first-class continu\u00ad ations. Correctness is established by proving that programs annotated by future \nhave the same observable behaviour as their non-annotated counterparts, even though evaluation may be \nparallel. 1 Introduction MultiLisp future [1, 8] is an annotation by which the pro\u00ad grammer indicates \nthat some expression maybe evaluated in parallel. By definition, future-based programs have the same \nobservable behaviour as their non-annotated counter\u00ad parts, i.e. annotated programs return the same result \nas in the absence of annotations, even though evaluation maybe parallel. It is a delicate matter to design \na language with futures and effects, i.e. with side-effects and first-class continua\u00adtions: as the values \nof some programs using effects may depend on the evaluation order, incautiously adding par\u00adallelism would \nmake them non-deterministic, which would contradict the idea that future is an annotation. So far, implementation \nand efficiency questions [13, 25, 8, 12, 10, 11, 3] have mainly motivated research on annota\u00adtions for \nparallelism in Lisp-like languages. Recently only, two semantics of parallelism by annotations were proposed. \nThe author of this paper defined a semantic framework for functional programs with first-class continuations \nand pca II annot at ions [15, 16, 17]. Flanagan and Felleisen [7] formu\u00adlated the semantics of futu re \nin a purely functional language. However, the issue of future in a language that has side\u00adeffects and \nfirst-class continuations remains unaddressed. *This research was supported in part by the Engineering \nand Physical Sciences Research Council, grant GR/K30773. Author s ad\u00address: Department of Electronics \nand Computer Science, University of Southampton, Southampton S017 lBJ. United Kingdom.  Permission to \nmake digitalhrd copy of part or all of thk work for personal or classruom use is granted without fee \nprovided that copies ara not made or distributed for profit or commercial advantage, the copyright notice, \nthe title of the ublication and its date appear, and notice is given that copying is Ey permission of \nACM, Inc. To mpy otherwise, to ~publish, to post on servers, or to redistribute to lists, requires prior \nspecific permission andfor a fae. ICFP 966f96 PA, USA 01996 ACM 0-69791-771 -5/96/0005 ...$3.50 The goal \nof this paper is to formalise the semantics of future in a Scheme-like [22] language with side-effects \nand first-class continuations. More generally the motivation of our research is to design a distributed \nimplementation of Scheme based on a future-like annotation to create remote computations. This paper \npresents the semantic foundation of our language, which serves as a guideline to build our distributed \nsystem. Distribution considerations are beyond the scope of this paper and will be covered in a forthcoming \nreport. The major contributions of this paper are three opera\u00adtional semantics which highlight different \naspects of a pro\u00adgramming language with future. The first semantics is the sequential semantics of the \nlanguage which regards future as a transparent annotation without parallelism-related mean\u00ading. By transparent, \nwe mean that the value of future is the value of its argument. The second semantics interprets future \nas a construct that indicates that some expression may be evaluated in parallel; it embodies the technique \nto coordinate effects in a semantically sound way. The first two semantics are context-rewriting machines \n[4, 7], which are advantageously high-level and concise. The third se\u00admantics is a lower-level refinement \nof the second semantics. It features an explicit shared memory h la MultiLisp [8], placeholdeT data-structures, \nand a notion of legitimacy [12] to assess the validity of results and the soundness of side\u00adeffects. \nAll semantics are proved to be equivalent; proofs can be found in [18]. This paper is organised as follows. \nThe three semantics are presented in Sections 2, 3, and 4, respectively. Section 5 discusses related \nwork, and is followed by a conclusion. 2 The CS-Machine The syntax of our idealised Scheme-like language \nis shown in Figure 1: Af is an applied call-by-value lambda calculus extended with primitives for manipulating \nfirst-class boxes and continuations. In addition, Af has a future construct writ ten as (future A/f). \nIn the sequel, we adopt Barendregt s [2] definitions and conventions on the lambda-calculus; we shall \nuse ilf [z + V] to denote the substitution of V for the free occurrences of x in ilf. Furthermore, as \nthe seman\u00adtics that we propose generalise Flanagan and Felleisen s [7] semantics of future, we try to \nuse their notations and termi\u00adnology wherever possible. PEA? iVf~Af V G Valuef a c BConst f E FConst \nx C Vars ::= ::= = = = V / (M M) I (if M a I f [ z I (kz.A4) {true, false, nil, O, 1,. ..} {cons, car, \ncdr, makeref, {Z, y,.z...} M M) [ (future M) deref, setref !, callcc} (Program) (Term) (Value) (Basic \nConstant) (Functional Constant) (User Variable) Figure 1: Syntax of A f The first operational semantics \nis given by the CS-machi\u00adne, derived from Felleisen, Friedman, Hieb, and Sabry s [4, 6, 23] Ju-CS-calculi. \nIts state space and evaluator specification are displayed in Figures 2 and 3, respectively. The Cs\u00admachine \nis a context-rewriting machine that uses the notion of evaluation context [4]: an evaluation context \n&#38; is a term with a hole , [ ], in place of the next subterm to evaluate. The transition relation \n*CS maps states onto states. Sta\u00adtes are expressions of the type (Ietref 8 M). The construct (Ietref \nO [ ]) corresponds to Felleisen and Hieb s [6] p-notat,ion, where the store 6 , a finite function represented \nas a set, maps box variables to values. The reader should observe right here and now that the store 0 \nis local to a state. This detail will turn out to be essential, when pwallelism is added to the machine. \nThe Ietref construct accepts mutually referent boxes, which correspond to circular data-structures in \na, real memory. The semantics is defined by a total evaluation function evalC8, which associates terminating \nprograms with Answers and non-t erminat ing ones with L. An Answer is a closed value where A-abstractions, \nboxes and continuations are re\u00adplaced by tags. The first four rules of Figure 3 deal with the purely \nfunctional subset of the language in a traditional way. When the functional constant caIIce, which stands \nfor Scheme call-with-current-continuation, is applied on a value, rule (capture ) creates a first-class \ncontinuation rep\u00adresented as an abortive abstraction AW.A5[V], with &#38; the current evaluation context. \nA term A Al, called an abort\u00adapplication [4], is meant to terminate the computation and to return the \nvalue of A/f; its behaviour is rnodelled by (abort) which discards its evaluation context. According \nto rule (makere/), the effect of applying makeref on a value V is to extend the local store with an association \nbetween a new box variable and the value V. This box can be accessed by deref and modified by setref \n!. As we wish to define a total evaluation function, error situations are detected, for inst ante in \n((30) when a non-applicable value occurs in op\u00aderator position. Error situations are reported by using \nthe abort operator A, which will end the computation with the distinguished constant error. Rule (future \nid) [7] gUarMIlt1312S that future is an annotation by requiring the value of futu re to be the value \nof its body. We shall consider the CS-machine as the sequential se\u00admantics of the language Af. Its correctness \nis established by the fact that its reduction rules are derived from the &#38; CS-calculi [4, 6, 23]. \nThe CS-machine defines future as a transparent operator because the value of future is the value of its \nargument. Hence, annotated programs have the same observable behaviour as their non-annotated counterparts. \n3 The P(CS)-Machine In the CS-machine, future is regarded as a transparent an\u00adnotation, but the real \npurpose of future is to indicate that an expression may be evaluated in parallel. This section presents \nthe P(CS)-machine in which future is a construct that can create parallelism. Figure 4 displays the state \nspace of the P(CS)-machine. We introduce a new kind of value, called placeholder variable, which represents \nthe result of a computation that is in progress [7] . We also distinguish proper values from runtime \nvalues: the former are like the runtime values of the CS-machine, while the latter include placeholder \nvariables as well. Whenever the P(CS)-machine interprets future as a con\u00adstruct for parallelism, it creates \na new state with its own local store. Each state of the P(CS)-machine can be viewed as a task that may \nbe evaluated in parallel with other states. Newly created states appear inside a construct f-let of the \nform (f-let (p M) S). Like a let, f-let binds a placeholder vari\u00adable p to the value of M in S; its intension \nis to model the potential evaluation of S in pzmallel with the state in which f-let occurs. The term \nM is called the primary term and S is the secondary state. The computations that S generates are speculative \nbecause they are not known to be needed before M returns a value; they may even be useless if M escapes \nby a continuation invocation. On the other hand, the evaluation of M is mandatory because it contributes \nto the value of the state in which f-let occurs. The evaluator specification of the P(CS)-machine is \ndis\u00adplayed in Figure 5. The meaning of SI ~~~~ S2 is that n steps are required in the transition from \nS1 to Sz, and among them m < n steps are mandatory, As indicated by rule (/ork), the primary term of \na f-let construct is initially the future body, whose value will be bound to a new placeholder variable \np. The secondary state evaluates a term composed of the cent ext of future, i.e. its continuation, to \nwhich the placeholder p was passed; the secondary statel haa its own local store (initially empty). As \nfar as the secondary state is concerned, the store 0 of the mandatory term is regarded as a remote store. \nAccording to rule (speculative), the P(CS)-machine has the potential to perform speculative computations: \nif a state 1The definition of the evaluation context 2 is explained by the fact that a f-let created \nby (fork) always appears in the body of a Ietref. Ae rule (capture) is the only rule to create abort-applications, \nand as evaluation is not allowed inside abort-applications, the argument of A is always of the form &#38;[ \nV]. .. .. (Ietref O M) (State) Unload function: Unload., : Value., G Answer .. ., v (Term) I (MM) Unloadcs \n[c] = c (if M MM) Untoadc, [(cons VI Vz)] = (cons Unloadc~ [Vi] (future M) Unloadcs [V,]) (AM) Unloads \n[Ax. M] = procedure .. .. Clx (Runtime Value) Unloadc, [b] = box I fc[b Unload.. [fc] = procedure (Az.M) \nI (cons V V) c E Const .. .. ald[f (Constant) f. e PApp .. .. (cons V) (Partial Application) Free variables \n(additional rule): g c AValue .. .. I (setref ! 1 ) ~Ax.M) (Applicable Value) m (b) = {b} &#38; G EvCon \n.. .. I flfc (Evaluation Context) Set of closed terms: (t i) (if &#38; MM) XO = {M c X, F V(M) =0} (future \n&#38;) O E StorePC A G Answer .. .. .. .. (... c (bt u)...) (Store) (Answer) Store update: (cons AA) \n0 = O[b := V] is defined if procedure 3 (b V ) E 0 and 8 = (O\\ {(b V )}) U {(b V)} box b E box-Vars \n {be, bl,...} (Box Variable) Store domain: d E DConst . {error, void} (Distinguished Constant) DOM((... \n(b~ K))..)) = {... b}...} Figure 2: State space of the CS-machine Transition rules: HC,: Statecs ~ Statecs \n(Ietref O &#38;[M[z -v,]]) if VI = (ku.M) (Ietref (3 &#38;[(VI Vz)]) E+C. (Ietref O E[(A error)]) if \n~ @ AValue (A) { (Ietref O &#38;[Vl]) if V = (cons VI Vz) (Ietref 0 &#38;[(car V)]) (car) (Ietref 6 S[(d \nerror)]) if V # (cons VI Vz) { (Ietref (3 &#38;[W]) if V = (cons V1 Vz) (Ietref O &#38;[(cdr V)]) ++=. \n(cdr) (Ietref (3 &#38;[(.4 error)]) if V # (cons V1 Vz) { (Ietref @L9[M1]) if V # false(Ietref .9 ~[(if \nV Ml Mz)]) (Ietref 6 &#38;[M2]) if V = false (if) { (Ietref O &#38;[(callcc V)]) (Ietref O &#38;[v (Jv.d \n&#38;[v])]) (capture) (Ietref O t[(d M)]) (Ietref O M) (abort) (Ietref @&#38;[(makeref V)]) (Ietref 8 \n&#38;[b]) with b @DOM(8), 19 = 8 U {(b V)} (makeref) (Ietref 6 &#38;[V ]) if V= b,(b V )~t9 (Ietref O \n&#38;[(deref V)]) (deref) (Ietref O t[(~ error)]) if V # b { (Ietref 0 &#38;[void]) if V1 = b, b E DOM(0), \n6 = @[b := Vz] (Ietref O &#38;[(setref! VI W)]) E+C. (setref) (Ietref 6 t[(d error)]) if ~ # b { (Ietref \nO &#38;[(future V)]) +.s (Ietref O &#38;[V]) (future zd) Evaluator specification: evalcs : A; + Answer \nU {J_} Unloadcs [V] if (Ietref () P) s;, (Ietref 6 V) evalc. (P) = 1 if Vi ~ N, 3Si G StateC~ such that \n{ (Ietref () P) = SO and S, +.. S,+l Figure 3: Evaluator specification of the Cs.machine S can be reduced \nto a state S , these reductions can also be performed if S appears inside the body of a f-let, without \nwaiting for the value of the placeholder. The only rules that introduce speculative computations are \n(fork) and (specu\u00adlative), as indicated by the explicit zero for the number of mandatory transitions. \nWe can see that future, interpreted as a task-creation mechanism, offers a possible concurrent evaluation \nbetiween a mandatory term computing the value of a placeholder, and a speculative state using this value; \nthis clearly refers to a producer-consumer type of parallelism. In the consumer, strict operations, i.e. \nthe operations that need the aLctual value being computed by the producer, introduce synchroni\u00adsations. \nStrict primitives, like car, cd r, deref, and set ref ! re\u00adquire their arguments to be pairs or boxes. \nSimilarly, strict positions like the operator position of an application or the predicate position of \na conditional demand values diflerent from placeholders. For this reason, all strict operations ver\u00adify \nthat their argument is not a placeholder as indicated in rules (@V), (car), (ca%), (if), (O!eref), (setref). \nIf a primary term has produced a value V, rule (join) substitutes V for the free occurrences of the placeholder \nvari\u00adable in the secondary state. In order to preserve the states organisation, the stores of the speculative \nand mandatory states are merged together, after having substituted V for the free occurrences of p across \nthe whole speculative store. In the perspective of a distributed implementation, this rule may be interpreted \nas follows: mutable objects allocated by a mandatory task in its local store can be remotely accessed \nby a speculative task, only when the mandatory task has completed its execution. By the non-determinism \nwhich stems from rules (jerk) and (speculative ), the evaluator can elect to perform slpecu-Iative transitions \ninstead of mandatory ones. As speculative computations may be infinite, while mandatory ones remain finite, \ndivergence should be defined with the greatest care. In the following example, (callcc Nc. ((future (k \n1)) Q)) the final result is 1, but an unbounded number of specu\u00adlative transitions can be performed \nto evaluate the diverg\u00ading term Q. Therefore, we say that the evaluator diverges for a program P, if \nP leads to an infinite transition se\u00adquence that includes mandatory computations regularly of\u00adten. Even \nthough the evaluation order can be non-determi\u00ad nistic, evalpc. defines a total function. Based on a \nmodified Diamond technique [7, 18], the following theorem states that the observable behaviors of programs \nare the same in the CS-and P(CS)-machines. Theorem 1 eual~, = evalP~. 0 As a corollary of Theorem 1, \nfuture interpreted as a task\u00adcreation operator is a transparent annot at ion, i.e. future does not change \nthe final answer of programs with effects despite parallel evaluation. Two different techniques are used \nto ensure that future remains an annotation in the presence of first-class cent inua\u00adtions and side-effects. \nOn the one hand, rule (capture) pack\u00adages up the whole continuation &#38; into a first-class abortive \nabstraction which computes a terminal value when applied. The value will be considered as a final answer \nif it is pro\u00adduced by a mandatory state. On the other hand, consis\u00adtency of side-effects is enforced \nby prohibiting a speculative state from accessing the local store of a mandatory one; in other words, \naccess to a remote store requires synchroni\u00adsations. This semantics ensures that parallelism can exist \nbetween states that perform effects locally. Practically, it means that two programs written by two programmers \ncan run in parallel if each program uses its own boxes locally. This is precisely the programming style \noffered by mostly\u00adfunctional languages like Scheme. Our semantics does not enforce the scheduling strategy, \nexcept that it demands to perform mandatory transitions regularly often. The rule (fork) models task \ncreation in the machine, but it is the implementor s responsibility to choose the characteristics of \nthe scheduling strategy that suit best his goal, like for instance eager or lazy task creation [14, 3], \ndata-centric or task-centrm task allocation [21]. 4 The F-PCKS-Machine In MultiLisp [8], an expression \n(future M) also offers a po\u00adtential concurrent evaluation between the task computing the value of M and \nthe task using it. In order to syn\u00adchronise these producer and consumer tasks, MultiLisp uses placeholder \ndata-structures that can be assigned at most one value. The process that obtains the value of III stores \nthis value in the placeholder. Assigning a value to a place\u00adholder is usually referred to as determining \nthe placeholder to the value. In the presence of first-class continuations, the expression A4 could return \nmultiple values , i.e. the cent inuat ion of 14 could be passed several values, succes\u00adsively. In order \nto preserve the determine once paradigm of placeholders, the first value passed to the continuation of \nM is stored in the placeholder, while the subsequent ones re-evaluate the continuation, as if futu re \nhad not existed [12]. On the contrary, the P(C S)-machine implements place\u00adholders as vmiables. By definition \nof substitution, variables receive at most one value, but rule (capture) can duplicate their binders. \nAs a result, the P(GS)-machine is unsatisfac\u00adtory in a number of respects: 1. In the state S1 = (Ietref \n0 (f-let (p &#38;[calicc V]) S)), the continuation to be captured is of the form Av.A(f-let (p &#38;[w]) \nS). Each invocation of this continuation reinstates the f-let construct, and possibly gives each instance \nof p a new value. 2. In the same state S1, if speculative computations S + S are performed afier the \ncontinuation is captured, the invocation of the continuation will restore the state S and not S . More \ngenerally, rule (abort) erases any speculative computation that was performed in the context of .4. \n3. Even though rule ( captu~e) and the rules that imple\u00adment the invocation of continuations (,BU followed \nby  S C StatePC. ::= (Ietref O M) (State) I $jetref O (f-let (p M) S)) M E AP., ::= (Term) 1 (MM) I \n(if MMM) ) fclb (Proper Value) (cons V V) (Runtime Value) (Sequential Evaluation Context) I (if D~M) \nI (future D) &#38; G EvConPC8 ::= (Evaluation Context) I ~-let (p D) S) p = p-Vars = {PO) Pi,...} (Placeholder \nVariable) Unload function: UnloadPcs : PValuePca -+ Answer Unload,., [W] = Unloadcs [W] Substitution \nfor p variable: p~+v] = v p~-V] = pifp#p (f-let (p M) S)~ + V] = (f-let (p Mb ~ V])S) if p = p (f-let \n(p M) S)~ < V] = (f-let (p Mb +-V])S~ +-V]) if p # p Free placeholder: FP(p) = {p} FP((f-let (p M) S)) \n= FP(M) u (FP(S) \\ {p})  Figure 4: State space of the P(CS)-machine (Differences with Figure 2) Transition \nRules: (Ietref O &#38;[M[z +-W]]) if VI = (kc.M) (Ietref e &#38;[(V, w)]) (P.) (Ietref 8 &#38;[(A error)]) \nif VI @ AValue, VI # p { (Ietref d &#38;[W]) if V = (cons VI VZ) (Ietref O &#38;[(car V)]) (car) (Ietref \nO ~[(.xt error)]) if V # (cons W Vz), V # p { (Ietref O &#38;[VZ]) if V = (cons VI V2) (Ietref O S[(cdr \nV)]) (cdr) (Ietref 19&#38;[(.4 error)]) if V # (cons W V,), V # p { (Ietref b &#38;[Ml]) if V # false, \nV #p(Ietref O &#38;[(if V Ml M,)]) (if) (Ietref O i$[Mz]) if V = false { (Ietref 0 &#38;[(callcc V)]) \n(Ietref 6 &#38;[V (Jv.AE[v])]) (capture) (Ietref 8 S[(A &#38;l[v])]) (Ietref 0 ~l[V]) (abort) (Ietref \nO S[(makeref V)]) (Ietref O f[b]) with b @ DOM(0), 0 = 0 U {(b V)} (makeref) (Ietref 6 &#38;[V ]) if \nV= b,(b V )et9 (Ietref O t[(deref V)]) (deref) (Ietref O &#38;[(A error)]) if V # b, V # p { (Ietref \n0 &#38;[void]) if VI = b, b c DOM(0), 0 = 6 [b := V2](Ietref 0 S[(setref! V1 VZ)]) (setref) { (Ietref \n8 $[(future V)]) (Ietref 19&#38;[V]) (future id) (Ietref .9 t?[(future M)]) (Ietref O (f-let (p M) (Ietref \n() &#38;~]))) with p @ FP(&#38;) (fork) (Ietref d &#38;[(.4 error)]) if V1 #b, V1 # p (Ietref O (f-let \n(j M) S)) (Ietref 6 (f-let (y M) S )) if S ti~~ S (speculative) (Ietref 191(f-let (p V) (Ietref L9Z&#38;[M]))) \n(Ietref 03 S[M] ~ -V]) with DOM(191) n DOM(19Z) = 0, (join) 6$=~1 U04, and Oj= {(b V;) I3 (bVZ)E82, V; \n= VZ~~ V]} s s (rejiexive) s S if S s~~ S and S s~~$ S . (transitive) Evaluator Specification: eva!pcs \n: A; + Answer U {1} Unloadpc. [W] if (Ietref () P) s~c. (Ietref 0 W) evalp.. (P) = 1 if Vi ~ N, 39, \nc Statepc., ni, m, E N such that { (Ietref () P) = SO and S, s~~~~ S,+l with m, >0. Figure 5: Evaluator \nspecification of the P(CS)-machine abort) are simple and faithful to the semantics of con\u00adtinuations \n[4, 6, 23], they are expensive and difficult to implement. Indeed, rule (capture) takes a snap\u00adshot of \nall speculative states running in parallell with the current state, whereas rule (znvoke) restores this \nsnapshot. 4. When a primary term provides a value V, rule (join) substitutes V for the free occurrences \nof the place\u00adholder variable in the f-let body, which involves sub\u00ad ii stitution across the whole speculative \nstore. This sub\u00adstitution fundamentally differs from the one in the ~u\u00adreduction: the latter corresponds \nto an environment extension, while the former is comparable to a side\u00adeffect. Besides the fact that \nthe P(CS)-machine does not con\u00adsider placeholders as mutable data-structures, there is an\u00adother reason \nthat exdains its distinct behaviour with re\u00adgard to MultiLisp implementations: context-rewriting ma\u00adchines \ndo not distinguish the continuation of a future from its speculative evaluation, because both are represented \nby the same evaluation context. Consequently, rule (capture) has no other choice but to take snapshots \nof running states. Taking these observations into account, we have designed a lower-level refinement \nof the P(CS)-machine, which incor\u00adporates MultiLisp-like solutions. The F-PCKS-machine ab\u00adstracts a MIMD \narchitecture with a shared memory in the tradition of MultiLisp systems [8]. The F-PCKS-machine generalises \nthe CK and CKS machines [4, 5], by providing a parallel evaluation mechanism based on a notion of task. \nEach task is represented by a CK-configuration (composed of a control string and a continuation), and \nhas access to a shared memory. The state space of the F-PCKS-machine appears in Fig\u00adure 6 and its evaluator \nspecification in Figure 7. The set of values contains a new kind of object (ph o), called place\u00adholder, \nwhich refers to a location a in the shared store. A placeholder is undetermined if its associated location \nis empty; it gets determined to a value V by storing V in its location. In the F-PCKS-machine, care is \ntaken not to determine a placeholder more than once. As in the PI(CS)\u00admachine, a strict operation must \nensure that its argument is not an undetermined placeholder. The action of obtaining the value of a placeholder, \ncalled touching the placeholder, is implemented by the function touch.. Let us notice that this function \nis recursive because placeholders can be deter\u00admined by other placeholders. Active tasks are quadruples \nformed of a term, a continu\u00adation code, a legitimacy [12], used to coordinate effects and validate final \nvalues, and a name. A legitimacy (leg a), like a placeholder2, is a data-structure that refers to a location \nin the shared store, but unlike a placeholder, it is not consid\u00adered as a value because there exists \nno primitive to reify it to the status of value. We shall also use the terms undeter\u00admined and determined \nfor legitimacies. In the P(CS)\u00admachine, f-let is the construct that distinguishes mandatory Katz, Weise, \nand Feeley [12, 3] suggest to implement legiti\u00admacy by placeholders. However, as placeholders and legitimacy \nhave different semantic purposes, we decided to give them different representations. from speculative \nevaluations; legitimacy plays a similar role in the F-PCKS-machine. When starting the execution of a \nprogram, the initial task is given the initial legitimacy 1~. Whenever a task r evaluates a future, rule \n(jerk) creates a task #, and allocates a new placeholder ph and a new legitimacy /1 (both initially undetermined). \nAfter transition (\\ork), task ~ still has the same legitimacy, but is now evaluating the future body \nwith a continuation (~ det (ph, 11)), where ph is the placeholder to determine and /1 the legitimacy \nof #. Meanwhile, the task # begins to evaluate the continuation of future with the new placeholder ph. \nWe know that task # performs a speculative computation on behalf of ~ because the legiti\u00ad macy of r \nis /1, and the continuation of task r contains a code (~ det (ph, 11)), whe re 11 is explicit. Rule (determine) \nhas two roles. First, it ensures that a placeholder is given at most one value: regardless of its le\u00adgitimacy, \nthe first task producing a value for a given place\u00adholder has the right to determine the placeholder \nto that value, while the other ones continue the evaluation as if no future had existed. Second, it keeps \ntrack of legitimacy as follows. If the placeholder (ph a) gets determined to a value V, the task that \nconsumes this placeholder speculatively be\u00adcomes dependent on the value V. This dependency is made explicit \nby giving the consuming task the legitimacy of the producing task. More precisely, the legitimacy of \nthe con\u00adsumer task is determined to the legitimacy of the producer task. So, legitimacy is passed between \ntasks as a token, whenever a placeholder gets determined. When a legitimacy (leg a) gets determined, \nlocation a re\u00adceives a legitimacy, which might also be determined. Hence, as evaluation proceeds, chains \nof Iegitimacies get formed in memory. We define a relation /1 +. tz stating that there is a path from \nlegitimacy 11 to legitimacy 12, which means that control has flowed from a task with legitimacy .!?Zto \na task with legitimacy /1. Intuitively, legitimacy models the fact that a sequential implementation would \nhave performed the evaluation done by the tasks with legitimacies tz to 11. The relation + is used to \ndetermine whether a final value, i.e. a value returned to the (init ) continuation, is a valid answer. \nA valid answer is produced by the task whose le\u00adgitimacy .2 is such that 1 +C 1~. The initial legitimacy \n&#38; is a pre-allocated legitimacy which serves as a marker for the end of legitimacy chains. This legitimacy \nalways remains undetermined because the initial program does not depend on any placeholder. A first-class \ncontinuation (co K) is a pair composed of tag co and a continuation code n. A box (bx a,/) is a triple \ncomposed of a tag bx, a location, and the legitimacy of the task which performed the transition (makeref). \nAs legiti\u00admacy represents the sequential flow of control, it is used to coordinate side-effects soundly. \nRead and write operations on boxes are allowed if they are performed in the same order as a sequential \nimplementation would have done them; i.e., the task that wishes to access a box should have a legitimacy \ndetermined (possibly through a chain) to the legitimacy of the task that created it. Said differently, \na task is not al\u00adlowed to access a box if it is more speculative than the one that created it, as in \nthe P(CS)-machine. W ~ PValUefPcks ph E Placeholder ! E Legitimacy u E Store fPCkS O E Contents a E Loc \nT E Tid ..= (T. u) (State) .. .. .. .. ., I (if h A4 iwj (future M) .. .. c [ x I (Jz.kf) (Proper \nValue) (COK) I (bx a,~) I (consV V) Ij, ,. .. Wl ph. (Runtime Value) .. ,, (init) (Continuation code) \n(K fun V) (K arg AI) (K cond(~, &#38;f)) (~ det (ph,l)) .. .. (ph a) (Placeholder) .. .. yo: ~ ~ontents \n(Legitimacy) (Store) .. .. Vllll (Store Content)  {ao, cl,,. .} (Location)  {70,7,,. ..} (Taak Identifier) \nMandatory descendant: en-+. .!l if eo=el, or U(cro) +. /1 if 10 = (leg ao) and a(ao) # 1 { Touch function: \ntouch : ValUefpcks x StOTef~cka ~ PValuefPck. U {-L} toucha(V) = V if V#ph touchc ((ph a)) = touch. (u(a)) \nif u(a) # 1 toucho ((ph a)) = Lifa(cr)=l Initial Legitimacy: L = (leg a,) Initial Store: ai = Aa.1 Unload \nfunction (differences): Un~oadfPck,[(bx a, L)] = box Unloadfp&#38; [(co K)] = procedure  Figure 6: State \nspace of the F-PCKS-machine The correctness of the third semantics comes from Theo\u00adrem 2 which states \nthat the evaluators of the F-PCKS-and P(CS)-machines define identical functions. The proof of Theorem \n2 [18] involves a translation of any F-PCKS-state into the P(CS) state space. A Lemma establishes that \nany reachable state of the F-PCKS-machine corresponds to a state that the P(CS)-machine can reach. Theorem \n2 Wdfpcks = evalP~, 0 The F-PCKS-machine is a formalisation of Katz and Weise s implementation schema \n[12]. If we consider the func\u00adtional subset with first-class continuations, it avoids syn\u00adchronisations \nand resorts to speculative computations as much as possible. It is well-known that speculative com\u00adputations \nmay lead to unintended computations, and a pro\u00adgrammer might wish to have more control on their genera\u00adtion. \nThere exist two opposite views concerning this prob\u00adlem: we can restrict either futures or continuations. \nBoth approaches can be easily described from the current seman\u00adtic framework. Figure 8 displays two proposed \nvariants; in contrast, the semantics of Figures 6 and 7 will be referred to as the unrestrtct~ve semantics \n. The essence of future is to initiate a computation that speculatively uses a placeholder while its \nactual value is be\u00ading computed. The future -restrictive solution authorises a task r to determine a \nplaceholder allocated when evalu\u00adating an expression (future M), only if ~ is the mandatory task that \nevaluated kf. This approach restricts speculation because it forbids a task speculatively spawned by \ne to take advantage of the speculative computation performed with the placeholder. We implement this \nsolution by adding a le\u00adgitimacy to placeholders, and by modifying rules (fork) and (determine). Every \nnewly allocated placeholder receives the legitimacy of the task that executes (jerk). Rule (deter\u00admine \n) is added a new side-condition so that placeholders can now be determined only when the legitimacy chain \nguaran\u00adtees that the current task is not more speculative that the one that created the placeholder. \nThough placeholders look very similar to boxes, they remain different from them, be\u00adcause they can be \nmutated at most once, and because read\u00ading their content is not conditioned by the speculativeness of \nthe task. The continuation-restrictive solution, proposed in [16, 18], allows a task r to invoke a continuation, \nif ~ is not more speculative than the task that created the first-class cent inuation. As far as the \nimplementation is concerned, a legitimacy is added to each first-class continuation; the legit\u00adimacy \nof a continuation is the one of the task that executes (capture). Similarly, rule (revoke) can be fired \naccording to the legitimacy added to continuation points. The continuation-restrictive solution bears \na strong re\u00adsemblance to the technique that coordinates side-effects in the F-PCKS-machine. Parallelism \nis stall allowed between modules that do not share cent inuat ions or boxes, which is a reasonable assumption \nfor mostly-functional languages like Scheme. The future-restrictive solution is more permissive because \nit still allows speculative invocations of continua\u00adtions. The following example illustrates how it differs \nfrom the unrestricted semantics of the F-PCKS-machine: &#38;l[future (callcc M. (cons (future(k 1)) (future(k \n2))))] In the unrestricted semantics, the outermost future allocates a placeholder phl, and creates a \ntask to evaluate ~1 ~hl] speculatively. The innermost futures allocate two placehold\u00aders phz, phs, and \ncreate two additional tasks, so that (k 1), ~ansith rUkS: tic~~: (~USk x $%O?YfP.ks) ~ (~@?kS* x SkJ?WfPc$) \n{(A4 N), ~,1)7 +ck~ (M, (K arg N),l). if (M IV) @ PApp (operator) (V, (K arg N),l). +C~8 (N, (K fun V), \n/)T (operand) (V, (K fun AZ. M),4)T +C~, (A4[z + V], K.,l)T (PIJ) (V, (K fun Vl),l)~ +Ck. ((VI V), rs,t). \nif (Vl V) c PApp (partial apply) (V, (K fun (cons VI)), l?)r +,-k. ((cons VI V), K, I!)r (cons) (vi, \nK,e)T if toucha (V) = (cons VI V2) (car){ v K Un Car) t)r k (error, (K fun (co (init))), 1)7 if touchm(V) \n# (cons Vl VZ), touchm(V)#L ((if M M M ), K,t)r +,+8 (M, (K cond (M , M )),t). (predicate) (M , ~,l?)~ \nif toucho(V) = false (if) (v (K cond (M )) 1) k (M, K,t?)T if toucho (V) # false, toucha(V)#l { (future \nM, K,l), ~Ck~ {(M, (K det (ph, t,)), t)~, (ph, K,ll)rl }; a[al + -1-][a +-~] (fork-) with 11= (leg al), \nph = (ph a), afresh al E Lot, afresh a ~ Lot, anew # ~ Tzd (V, (K fun Vi),.t)T if toucha ((ph a)) = V1, \nV1 ~ AValue v K Un Ph )) )T k (error, (K fun (co (init))), 1)~ if touchm((ph a)) = V1, V1@AValue, Vl#l \napp ouch) { ($, (stop), $).;a[~l + t21[@ -VI if o(~) = J. (V, (K det ((ph a), (leg m))), ~2)T ck. (v, \n~,tz)~ (determine) ifa(a) # 1 { (v, (fC fun cdlcc), t)r +Ck. ((co /$), ( C fun v), /)T (capture) (V, \n(K fun (co K)), k?)T +Ck$ (v, K,f?)r (invoke) (V, (~ fun makeref),l)~ +Ck, ((bx a,l), K,l)T; u[a +-V] \n(rnakerefi with a fresh a (S Loc (C7(a),fc,t?)r if toucha(v) = (bx @, LI), t +~ 11 (deref) { v x Un \neref) ~)r __ cks (error, (N fun (co (init))), L)T if toucha(V) # (bx a, 11), toucha(V)#l (void, .d, t?)~; \nu[a +-V] if toucha(Vl) = (bx a,tl), f +6 41 (v, (K fUn (Set ef! Vi)), ~)r ~cks (setrej) (error, (K fun \n(co (init))),l)~ if touche(Vl) # (bx a,ll), touchc(Vl)#J_ { Conventions: (~, U) -Ck$ ({~ }, U) k written \n~@c~s t (t, u) -Cks ({t }, u ) is written t+ckst ;,7 + ~ (t,U)-k. ({t ,/) t };U ~ (7 t },k writtent~.k.{t \n,  (T, a) +~$ks (T , a ) if 3t = (M, K, l). 6; T, such that (t,a)+.k.(T ,c ), (base) T = (T\\ {t}) U \n{T }, a = 1 if 1-~ L, and a = Ootherwise. S +~~c~~bwb S if S +~~ck~ S and S b~~~~, S . (tr-ansitwre) \nEvaluator Specification: evalfpck, : A; -) Ansurer U {1} Unzoadfp.k, [touch~ (V)] if ( { (P, (init), \nli)~~ } , ~i) +~P.k~ (T, ~), with (V, (init ), t?)r E T, such that I +~ L evazfpcks(p) = L if Vi E N, \n3S; ~ Statefpcks, n,, m; G N, such that so = ( { (p, (init), &#38;)TO } ,at), t ~$j i+ljmi >0 { Figure \n7: Evaluator specification of the F-PCKS-machine future-restrictive solution: ph E Placeholder ::= (Ph \n~, 1) (Placeholder) (future M, K, Z)T HCk. { (M, (K det (ph,l~)),~)~, (p&#38; K,~I).I };~[QI + J-IIcI+ \nJ-1 (fork) with II = (leg al), ph = (ph cYl), a fresh al G Lot, a fresh a E Lot, a new r 6 Tid (+, (stop), \n*) T;a[m +-12][a +-V] if u(a) = 1,1,-01 (V, (K det ((ph crl), (leg cII))), &#38;)7 ++Ck, (determine) \n(v, K,12)7 if a(a) # 1\u00ad { continuation-restrictive solution: W c PValuefpCk8 ::= . . . I (co K, t) I \n. (Proper Value) (V, (J%fun callcc), $~ ~ck~ ((co&#38; /), (~ fun V), /)r (capture) (v, (K fUn (CO K,t?l)), \n/)T ++ .k. (v,fi,~)~ if ltir /1 (znvoke) Figure 8: Speculation controlling variants (k 2), and (cons \nph~ phs) are all returning values for the out-eralises the PCKS-machine by the language accepted and \nermost future body, in parallel. Regardless of its legitimacy, simplifies the architecture. the first \ntask that returns a value (1, 2, or (cons pZ PS)) stores According to the nomenclature proposed in this \npaper, it in phl, and dies; the following ones keep on evaluating the the semantics of pcall [15, 16, \n17, 18] can be categorised as context &#38;l. continuation-restrictive . This means that a notation pcall \nOn the contrary, the future-restricted semantics allows based on the unrestricted future would be more \nspeculative the placeholder phl to be determined by 1 only; the other re-than in [15, 16, 17, 18]. sults, \nwhich are more speculative than 1, requires re-evalua- The only other work concerning the formal semantics \nof ting the context S1. This implementation of future favours annotation-based parallelism is Flanagan \nand Felleisen s [7] programs using continuations in a downward way, by avoid\u00adsemantics of future in a \npurely functional language. They ing the speculative computation performed on ~1 ~hl] being proposed \nseveral abstract machines with varying degrees of stolen by a non-legitimate result (2 or (cons p, ps) \n). This intensionality. Our CS-and P(CS)-machines extend their solution particularly makes sense when \nside-effects should be C-and P(C)-machines with side-effects and first-class con\u00ad performed in S1. Indeed, \nas side-effects appearing in &#38;l can tinuations. Interestingly, no extra constraint is added to the \nonly be performed by the legitimate task, it is a reasonable functional core in order to support effects. \nassumption to only let the mandatory task take advantage Our F-PCKS-machine is a lower-level refinement \nof their of the speculative computation already performed. CPh-machine. Indeed, as continuations were \npart of the lan\u00adguage, we considered that it was crucial to understand when 5 Related Work and Discussion \nplaceholders were allocated and determined. To that end, we have provided the F-PCKS-machine with an \nexplicit shared Previously, the author [15, 16, 17, 19] studied the semantics memory a la MultiLisp [8]. \nThe F-PCKS-machine is still of a functional language extended with first-class continu-too abstract to \nbe considered as a real implementation. We ations, side-effects, and pca II annotations. The annotation \ncould easily get rid of the substitution model by introduc\u00adpca II indicates that subexpressions of an \napplication may be ing an environment [4]. Furthermore, the level of atomicity evaluated in parallel \nbefore applying the value of the oper-assumed by transitions is still too high; a solution based on ator \non the values of the arguments. Parallelism generated explicit critical sections could be derived from \n[16]. by peal I is said to be of the type fork and join , while the In addition, in order to keep the \nsemantics as simple as one generated by future, more speculative, is of the type possible, we have not \nincluded queues in the representation producer consumer . The following translation suffices to of placeholders. \nAs a result, a task which touches an un\u00ad define pcall in terms of future: determined placeholder is \nnot allowed to fire a transition rule. In order to avoid busy-waiting, it is common practice (pcall M \nN) = ((future M) N) [12, 3, 8] to suspend such a task, to put it in a queue asso-In [17, 18], the semantics \nproposed for peal l-based programs ciated with the placeholder, and to resume it as soon as the relied \non the PCKS-machine. The F-PCKS-machine gen\u00ad placeholder gets determined. The collection of tasks is \nan issue that can have a seri\u00adous impact on the practicality and performance of a parallel implementation. \nHalstead s MultiLisp [8] does not reclaim any runnable task. The collection of tasks in Miller s Mul\u00ad \ntiScheme [13] is solved during garbage collection: incleed, a task can be collected if the placeholder \nthat it determines is accessible from the gc roots. From their semantics of future, Flanagan and Felleisen \nderive a set-baaed analysis [9] to perform a touch optimi\u00adsation , removing provably-unnecessary touch \noperations. There is no doubt that such an analysis would be useful for our language. However, we feel \nthat a major dMiculty is to design an analysis which provides safe and accurate ap\u00adproximations of expressions, \nwhen side-effects and continua\u00adtions are used. Other analysis and associated optimisations are conceivable \nto improve evaluation. For instance, every access to a box (read or write) requires to check the legiti\u00admacy \nof the running task. A static analysis and a program transformation, in the spirit of the touch optimisation, \ncould reduce the costs of theses checks; set-based analysis [9] or inference of regions and effects [24] \nwould be two interesting approaches to design the analysis. The annotation future had never been studied \nin the pres\u00adence of both side-effects and first-class continuations. Katz and Weise [12, 3] described \nan implementation for future and continuations, and Tinker and Katz [25] designed Paratran to deal with \nfutures and side-effects. Our unrestricted se\u00admantics is based on Katz and Weise s solution. However, \nwe are much more conservative than Paratran for side-effects. Indeed, in Paratran, side-effects are performed \noptimisti\u00adcally: a run-time system detects data dependency violations and is able to correct them by \nrestoring a previous state by a roll-back mechanism. Unfortunately, the run-time system is so expensive \nthat it penalises sequential programs too much. Katz and Weise also suggest a synchronizing vari\u00adant \nof future, which seems closer to our future-restrictive semantics; however, it permits less speculation \nbecause it requires killing illegitimate tasks. Feeley s thesis [3] is a deep study of the performance \nof Katz and Weise s implementation schema. He observes that the implementation of this semantics of future \nrequires cap\u00adturing the continuation of each future, so that it can be called when multiple returns occur. \nFeeley shows that by using a lazy task creation mechanism [14], i.e. delaying the creation of the task \nuntil it needs to be transferred to another proces\u00adsor, the capture of continuations can be postponed \nuntil the time of steal, where it has to be done anyway. Hence, good performance can be achieved by combining \nthe semantics with lazy task creation. Feeley discusses the cost of supporting legitimacy. He distinguishes \nlegitimacy propagation (rule determine) and legitimacy testing (/ + 1,), and proposes techniques to re\u00adduce \ntheir costs. He also addresses the issue of the runtime cost of touching placeholders; variants that \navoid recursive touching are proposed. 6 Conclusion The design of a parallel language based on future \nwith side\u00adeffects and first-class continuations has been a long-standing open problem. We present the \nfirst semantics of such a lan\u00adguage and prove its correctness. Such a semantics is useful for the derivation \nof a proven-correct compiler and for static analysis of parallel programs. The lower-lever framework \npresented is also suitable to express less speculative variants of the semant its. A distributed implementation \nof Scheme baaed on the proposed semantics is being developed using Queinnec s DMe\u00adroon [20], a library \noffering facilities to distribute objects, and to maintain their coherency over the network. 7 Acknowledgement \nThanks to David De Roure, David Barron, and the anony\u00admous referees for their comments. References [1] \nHenry Baker and Carl Hewitt. The Incremental Garbage Collection of Processes. Technical Report AI Memo \n454, M. I. T., Cambridge, Massachussets, March 1977. [2] Henk P. Barendregt. The Lambda Calculus: Its \nSyntax and Semantics, volume 103 of Studies in Logic and the Foundations of Mathematics. North-Holland, \nsecond edition, 1984. [3] Marc Feeley. An E@cient and General Implementation of Futures on Large Scale \nShared-Memory Multiproces\u00adsors. PhD thesis, Brandeis University, 1993.  [4] Matthias Felleisen and Daniel \nP. Friedman. Control Operators, the SECD-Machine and the A-Calculus. In M. Wksing, editor, Formal Description \nof Program\u00adming Concepts 111, pages 193 217, Amsterdam, 1986. Elsevier Science Publishers B.V. (North-Holland). \n [5] Matthias Felleisen and Daniel P. Friedman. A Reduc\u00adtion Semantics for Imperative Higher-Order Languages. \nIn Proc. Conf. on Parallel Architecture and Languages Europe, number 259 in Lecture Notes in Computer \nSci\u00adence, pages 206 223. Springer-Verlag, 1987. [6] Matthiaa Felleisen and Robert Hieb. The Revised Re\u00adport \non the Syntactic Theories of Sequential Control and State. Theoretical Computer Science, 2(4):235 271, \n1992. Technical Report 100, Rice University, June 1989. [7] Cormac Flanagan and Matthias Felleisen. \nThe Se\u00admantics of Future and Its Use in Program Optimiza\u00adtion. In Proceedings of the Twenty Second Annual \nACM SIGA CT-SIGPLAN Symposium on Principles of Pro\u00adgramming Languages, January 1995. Technical Reports \n238, 239, Rice University, 1994. [8] Robert H. Halstead, Jr. New Ideas in Parallel Lisp : Language Design, \nImplementation. In T. Ito and Robert H. Halstead, editors, Parallel Lisp : Languages and Systems. USjJapan \nWorkshop on Parallel Lisp. Japan., number 441 in Lecture Notes in Computer Sci\u00ad ence, pages 2 57. Springer-Verlag, \n1990. [9] Nevin Heintze. Set-Based Analysis of ML Programs. In Proceedings of the 1994 ACM Conference \non Lisp and Functional Programming, pages 306 317, Orlando, Florida, June 1994. [10] Takayasu Ito and \nManabu Matsui. A Parallel Lisp Lan\u00adguage Pailisp and its Kernel Specification. In T. Ito and Robert H. \nHalstead, editors, Parallel Lisp : Lan\u00adguages and Systems. US/Japan Workshop on Parallel Lisp. Japan., \nnumber 441 in Lecture Notes in Computer Science, pages 58-100. Springer-Verlag, 1990. [11] Takayaeu Ito \nand Tomohiro Seino. On Pailisp Con\u00adtinuation and its Implementation. In Proceedings of the ACM SIGPLAN \nworkshop on Continuations CW92, pages 73-90, San Francisco, June 1992. [12] Merry Katz and Daniel Weise. \nContinuing Into the Future: On the Interaction of Futures and First-Class Continuations. In Proceedings \nof the 1990 ACM Confer\u00adence on Lisp and Functional Programming, pages 176 184, June 1990. [13] James \nS. Miller. MultiScheme : A Parallel Processing System Based on MIT Scheme. PhD thesis, MIT, 1987. [14] \nEric Mohr, David A. Kranz, and Robert H. Halstead. Lazy Task Creation : a Technique for Increasing the \nGranularity of Parallel Programs. In Proceedings of the 1990 ACM Conference on Lisp and Functional Pro\u00adgramming, \npages 185 197, June 1990. [15] Luc Moreau. The PCKS-machine. An Abstract Ma\u00adchine for Sound Evaluation \nof Parallel Functional Pro\u00adgrams with First-Class Continuations. In European Symposium on Programming \n(ESOP 94), number 788 in Lecture Notes in Computer Science, pages 424-438, Edinburgh, Scotland, April \n1994. Springer-Verlag. [16] Luc Moreau. Sound Evaluation of Parallel Functional Programs with First-Class \nContinuations. PhD the\u00adsis, University of Libge, Service d Informatique, In\u00adstitut Montefiore B28, 4000 \nLi&#38;ge, Belgium, June 1994. Also available by anonymous ftp from f tp. montef i ore. ulg. ac. be in \ndirectory pub/more au. [17] Luc Moreau. Non-speculative and Upward Invocation of Continuations in a Parallel \nLanguage. In Interna\u00adtional Joint Conference on Theory and Practice of Soft\u00adware Development (TAPSOFT/FASE \n95), number 915 in Lecture Notes in Computer Science, pages 726 740, Aarhus, Denmark, May 1995. [18] \nLuc Moreau. The Semantics of Scheme with Future. Technical report, University of Southampton, 1995. [19] \nLuc Moreau and Daniel Rlbbens. The Semantics of pcall and fork. In R. Halstead, T. Ito, and C. Quein\u00adnec, \neditors, PSLS 95 Parallel Symbolic Langages and Systems, Beaune, France, October 1995. [20] Christian \nQueinnec. DMEROON: a Distributed Class\u00adbased Causally-coherent Data Model: Preliminary Re\u00adport. In Parallel \nSymbolic Languages and Systems., Beaune, France, October 1995. [21] Mukund Raghavachari and Anne Rogers. \nA Case Study in Language Support for Irregular Parallelism: Blocked Sparsed Cholesky. In Parallel Symbolic \nLanguages and Systems., Beaune, France, October 1995. [22] Jonathan Rees and William Clinger, editors. \nRevised Report on the Algorithmic Language Scheme. Lisp Pointers, 4(3) :1-55, July-September 1991. [23] \nAmr Sabry and Matthias Felleisen. Reasoning about Programs in Continuation-Passing Style. Lisp and Symbolic \nand Computation, Special Issue on Contin\u00aduations, 6(3/4) :289 360, November 1993. [24] Jean-Pierre Talpin \nand Pierre Jouvelot. Polymorphic Type, Region and Effect Inference. Journal of Func\u00adtional Programming, \n2(2), 1992. [25] Pete Tinker and Merry Katz. Parallel Execution of Sequential Scheme with ParaTYan. In \nProceedings of the 1988 ACM Conference on Lisp and Functional Pro\u00adgramming, pages 28-39, Snowbird, Utah, \nJuly 1988. 156 \n\t\t\t", "proc_id": "232627", "abstract": "We present the formal semantics of future in a Scheme-like language which has both side-effects and first-class continuations. Correctness is established by proving that programs annotated by future have the same observable behaviour as their non-annotated counterparts, even though evaluation may be parallel.", "authors": [{"name": "Luc Moreau", "author_profile_id": "81100006426", "affiliation": "Department of Electronics and Computer Science, University of Southampton, Southampton SO17 1BJ United Kingdom", "person_id": "PP14015069", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/232627.232644", "year": "1996", "article_id": "232644", "conference": "ICFP", "title": "The semantics of Scheme with future", "url": "http://dl.acm.org/citation.cfm?id=232644"}