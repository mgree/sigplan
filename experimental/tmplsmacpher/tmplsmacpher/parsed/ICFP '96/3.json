{"article_publication_date": "06-15-1996", "fulltext": "\n Lag, drag, void and use heap profiling and space-efficient compilation revisited Niklas Rojemo and Colin \nRunciman Department of Computer Science, University of York, Heslington, York, YOI 5DD, UK (e-mail: {rojemo, \ncolin}@cs. york. ac. uk) Abstract The context for this paper is functional computation by graph reduction. \nOur overall aim is more efficient use of memory. The specific topic is the detection of dormant cells \nin the live graph those retained in heap memory though not actually playing a useful role in computation. \nWe de\u00ad scribe a profiler that can identify heap consumption by such useless cells. Unlike heap profilers \nbased on traversals of the live heap, this profiler works by examining cells post\u00ad mortem. The new profiler \nhas revealed a surprisingly large proportion of useless cells, even in some programs that previously \nseemed space-efficient such as the boot-strapping Haskell compiler nhc. Introduction A typical computation \nby graph reduction involves a large and changing population of heap-memory cells. Taking a census of \nthis population at regular intervals can be very instructive, both for functional programmers and for \nfunctional-language implementors. A heap profiler [RW93] records population counts for different classes \nof cells at each census. A producer profile classifies cells by the program components that crest ed \nthem; a constructor projile classi\u00ad fies cells according to the kinds of values they represent. A post-processor \ngenerates a graphical summary of heap con\u00ad tents throughout the computation. Census information can be \nextended to include the active components that retain access to cells (retainer proj-ile) and the cells \neventual life\u00ad times (lifetime profile) [RR95]. Such heap profiling is a surprisingly effective tool \nfor dis\u00adcovering space faults. We say surprisingly because there is nothing in a who-produces-what profile \n(nor even in the deeper structural information of something like a retainer profile) that directly points \nto some part of heap usage as a likely fault. It is up to the programmer to assess features such as sudden \nspikes of growth or steadily widening bands. Do these represent behaviour only to be expected of their \nprogram? Or do they represent the anomalous behaviour of a space fault? Permission to make cfigitalhird \ncopy of part or all of this work for personal or classroom use is ranted without fee provided that mpies \nare not made or distributed for pro i t or commercial advantage, the copyright notice, the title of the \npublication and its date appear, and notice is given that copying is by permission of ACM, Ino. To @py \notherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission \nandlor a fee. ICFP 86 !Y86 PA, USA @ 1886 ACM O-89791 -771 -WWOO05...$505O In other lines of work on \nmemory management, research\u00aders are questioning the conventional acceptance of safe over\u00adestimates of \ngarbage in memory management see for ex\u00adample [MFH95]. There is an important difference in prin\u00adciple \nbetween (a) the time for which a cell is retained simply because it is attached to a live graph , and \n(b) the inter\u00adval over which the cell is actually needed because it plays a useful role in the computation. \nThese observations together motivate our goal to identify live but useless memory cells directly in some \nform of heap profile. We want to discover how great the difference is in practice between the traditional \nover-estimate of needed cells (i.e. as used for garbage collection) and a true measure of need (i.e. \nas defined by full knowledge of how and when cells are used). The main application so far is to halve \nthe memory de\u00admands for nhc a boot strapping Haskell compiler. This is not the first time a heap profiler \nhas been used to improve a compiler for a lazy functional language [RW92]. So what s new? The compiler \nin the 92 paper was not designed with space efficiency in mind. The initial version needed 2Mb of live \nheap data at peak for a 280-line module. It was not too surprising that by constructing a profiling tool \nwe were able to uncover space faults and make significant gains. Overall space x time cost was halved, \nand peak heap-memory demand was reduced by about 30%. The compiler examined in this paper, however, w \na.s de\u00adsigned for space-efficiency right from the start. Indeed, the profiling tools from 92 were available \nto help in this. Des\u00adpite a more complex language (Haakell 1.2 [Hud92] rather than Lazy ML [AJ93, Aug84, \nAJ89]) compilation of a com\u00adparably sized source file (280 lines + 1400 lines of interface files) at \nthe startof our profiling exercise in this paper uses only 800kb. 1 So one might not expect substantial \nreduc\u00adtions in heap space. Yet not only do we again improve the overall space x time cost by nearly a \nfactor of two; the peak memory demand is also reduced by up to 5070. We achieve the factor of two result \nin a tougher context because we have developed more powerful tools for heap-profiling. By slicing the \nheap in more ways than just the two-dimensional who produces what , many more questions can be answered \nabout the way heap memory is used. Our latest profiler spe\u00adcifically directs attention to apparently \nwasted heap space. The remainder of the paper is as follows. $2 makes more lThe actual module we shall \nuse as a running example is smaller SO Iines + 634 lines of interface files requiring only 400kb at \nthe outset. 34 precise what we mean by the distinction between live cells and useful ones, concluding \nwith the definitions of terms such as heap lag and heap drag. $3 explains both in principle and in practice \nhow the techniques of heap profiling can be adapted to obtain a profiler for measuring lag and drag. \n$4 describes how the space-efficiency of nhc was improved with the aid of the new profiler. $5 discuss \nthe meaning of useful heap . $6 concludes with a discussion of current limitations and future potential. \n2 Definitions of terms 2.1 The individual cell The bzog~aphy of a typical cell in heap memory includes \nfour important events: 1.the cell is created it is born as one small piece of the live graph; 2. the \ncell is used for the jirst txme it is employed in the computation; 3. the cell is used for the last \ntime it goes into retire\u00adment ; 4. the cell is destroyed it dies , ceasing to be part of the live \ngraph.  The intervals between these successive events correspond to three phases for the cell: lag, \nuse and drag. lag use drag I t created first used last used t destroyed In this paper, we are concerned \nwith whether and when cells are used at all, not with the details of how frequent the uses are. So we \nchoose to ignore the fact that the first and last uses of one cell may be its only uses, while those \nof another cell may be the first and last of many. We make the simplifying assumption that the first \nand last uses mark the beginning and end of an undivided phase during which the cell is useful. We are \nmost interested in the lag and drag phases. A cell is in the lag phase from its creation to its first \nuse, and in the drag phase from its last use to its destruction. For the most effective use of memory, \nboth lag and drag phases should be as short as possible. That is, most cells should be useful for most \nof their lifetime. Often one or more of the three phases of lag, use and drag will in fact be so short \nas to be virtually instantaneous. Under a call-by-need regime, we should not be surprised to find that \nmany cells are used as soon as they are created zero lag. For any cell that is used exactly once, the \nevents of first and last use coincide. And many cells are destroyed as an immediate consequence of their \nlast use zero drag even if the memory they occupy is not recycled until the next garbage collection. \nWhat if a cell is never used? Then we refer to the interval between its creation and its destruction \nas void. I void I t created t destroyed 2.2 Cell populations These biographical terms applied to individual \ncells can be extended to collections of cells. In particular, we can ap\u00adply them to the complete population \nof cells maintained in heap memory. At any given moment during a computa\u00adtion we can divide cells into \nfour classes: lag, use, drag or void. Hence we can define the instantaneous heap lag as the amount of \nheap memory occupied by cells in their lag phase; and similarly for the other cell phases. The same sort \nof classification can be applied across the entire period of a computation. Since we can label all of \nheap memory at any given instant with one of the four phases, we can integrate across all such instants \nto obtain total space x time cost (e.g. expressed in byte x seconds) for each of the phases. This gives \na measure of the overall pro\u00adportions of heap use in comparison with any heap lag, heap drag or heap \nvoid. 3 Profiling method Earlier heap profilers [RW93, San94, SP95, RR95] collected their information \nby traversing the live heap. This is not possible when collecting biographical data. There is no way \nto determine the phase of all cells on-the-fly in the middle of the computation, without knowledge of \nhow they will be used in the future. The alternative is to record the timing of important events in the \ncell, and retrieve this information when the cell is eventually removed from the live graph. 3.1 Practical \nimplement ation We now outline an implementation of our biographical pro\u00adfiler, using nhc [Roj95a, Roj95b] \nas the host compiler. Every heap cell is enlarged to accommodate three addi\u00adtional pieces of information: \n(1) creation time; (2) time of first use, if any so far; and (3) time of most recent use, if any. As \nin some previous heap profilers, time is reckoned by the number of heap censuses that have occurred. \nSo the time of the final event for a cell, its destruction, need not be stored in the (now dead) cell. \nIt is implicit at the next census, when the information is required. Setting the first time-stamp is \neasy. To maintain the other two, we must agree what constitutes a use of a cell. In the unoptimised G-machine \n[Joh84, PJL92] setting of nhc the broad rule is that use means evaluation. This includes: (1) case analysis \nof a data construction; (2) application of a function closure; (3) evaluation as argument in a primitive \noperation. In addition, a functional closure is also deemed to be used when it is updated with its result. \nThis choice is open to debate. It was not the rule we implemented at first, but we found it unhelpful \nto have function closures awaiting update labelled as heap drag. The previous section explained the need \nto examine cells post mortem. At each census, a summary of all cells des\u00adtroyed since the last census \nis written to a log file. The summary comprises a time-stamp for the census, followed by a series of \npopulation counts for each distinct triple of time-stamps occurring in the dead cells. There are two \nways that cells can be destroyed: they can be overwritten or they can be disconnected from the graph. \nInformation about overwritten cells is collected just before the update is done; the data is later merged \ninto the next census. Disconnected cells are processed during the census 35 00 200 400 6 30 ,D=a d Figure \n1. A profile showing the lag, drag, void and use components of heap memory when the original version \nof nhc compiles a small part of itself an 80-line module. itself. First all live cells are marked (using \nthe mark phase of the garbage collector) and then the heap is scanned. All unmarked cells have been disconnected \nand are therefore included in this census. Afterwards the heap is compacted to prevent the unmarked cells \nfrom being counted at the next census. Theuseof variable-sized cells innhcis a problem when scanning \nfor disconnected cells. For an ordinary garbage collection only marked cells are of interest, and they \ncan be found bysearching forset mark-bits. Butduringa censuswe must locate the unmarked cells. Oursolution \nis to guarantee that there is no empty space between cells: the next cell always starts immediately after \nits predecessor. This is true when cells are allocated, but ceases to be the case when a cell is updated \nwith a smaller cell. If this happens a filler cell of the appropriate size must be inserted in the vacant \nspace. The census then finds all dead cells by scanning from the start of the heap, ignoring filler cells \nand cells with their mark-bits set. The time needed for censuses is not included in the heap profile, \nbut the overhead when overwriting cells is. This is not a serious problem as our main concern is space. \nTimes shown in different heap profiles can still be compared to see whether a space optimisation slows \ndown the program or speeds it up. After the computation is over, a post-processor derives population \ncounts for cells in different phases at each census point. The derived census data is plotted graphically \nin the time-honoured way To increase the accuracy of the ap\u00adprox~mation one simply increases the frequency \nwith which censuses are taken. 3.2 Profiling restricted parts of the heap The heap profiler must also \nbe able to answer questions like What is producing the heap drag? , using biographical in\u00adformation to \nrestrict the scope of a producer profile. Our implementation of a biographical profiler can only be combined \nwith invm-mnt profiles, i.e. those where cells never change their attributes. The current implementation \ncan : u 35% Lox,ca om% IEx,ma sm. . ,0!4 P,m,L,b ~ 6% L-,r. E m. Par-l-.x m. . 2% F4, WL.W W ,% 1,-234 \n253k. o 2% F r@n!.aL8st5 o 2% Pralu&#38;Lt$,7 . 2% Iwo xok. o 2% TransMam o ,% Prel daL,s!l 1$5k H 1% \nP@.&#38;2T.Ple o ,% ,rel ?a, n, Im !$$ !% LmtLM o ,% L-Low o ,% ,a.ec.r.  SW o 0%,.,.., o 0% ,,s1 \n,s1,,s,  m 00 200 400 m, smmd Figure 2. A producer profile showing which modules produce the void cells \nin Figure 1. not combine retainers and biographical profiles. There 1s not enough space to record in \neach cell the different retainer sets it has during its lifetime, and as we have already observed there \nis in general no way to obtain the biographical state of a cell in mid-computation. Future work may remove \nsome of these restrictions: see ~6. 4 Example application nhc The bootstrapping Haskell compiler nhc \nwas written with space-efficiency as the main objective [Roj95a, Roj95b]. In\u00addeed, it can compile itself \nin well under 3 Mb which compares favorably with other compilers. Yet, as Figure 1 shows, ap\u00adproximately \n88% of nhc s heap memory is lag, drag or void! 4.1 Symbol tables in nhc As we shall see some of this \nwasted memory is due to the symbol table. A short description of how identifiers are treated in nhc is \ntherefore necessary. After a source module is parsed, but before scope is de\u00adtermined, all interface \nfiles are read and checked for consist\u00adency. Identifiers are entered into a symbol table sorted by their \nreal names (the names used when the identifiers were defined). Each identifier is given a unzque number \nwhen it is inserted in this table. After the consistency check, the symbol table is re -ordered by visible \nnames (after any re\u00adnaming done during import, see [Hud92] section 5.2.2), and all identifiers in the \nparse-tree are replaced by their unique numbers. The symbol table is then re-ordered once more, this \ntime by the unique numbers, after which all needed in\u00adformation about identifiers (e.g. arity, type, \nname) is fetched from the symbol table using the unique number as key. Once entered in the symbol table \nan identifier and all its associated information is kept until the compiler terminates.  4.2 Laziness \nmay keep redundant closures The heap void is a large part of both the peaks in nhc s heap profile (see \nFigure 1). A profile of only the heap void (Figure 2) shows that most of the first peak is produced in \n 36 35Qk. . 24% la, m. Wx. 1 32% v.d m 24% VO!d J ! xc+. Ig 22%... ,5W 1COk o 23%.. 5m ok Figure 3. \nThe heap profile after strictify\u00ading the parser combinators and promoting the filtering of hidden identifiers. \n the module ParseLib, and most of the second in the module IExtract. Let us start by trying to remove \nthe first peak. A constructor profile restricted to the heap void pro\u00adduced by ParseLib shows that all \nthese cells are binary ap\u00adplication nodes! It is the parser combinators in ParseLib that create these \nbinary application nodes. These combin\u00adators are written in a continuation-based style with two con\u00adtinuations: \none (good) is used if the parser succeeds, and the other (bad) in case of failure. possible to build \nlarger parsers longer description is available for example the ap combinator. as: Using these combinators \nit is by combining simpler ones (a in [Roj95a] chapter 4). Take This combinator is defined :: Parser \n(a->b) i c -> Parser ai c-> Parser bi c apxy=\\good bad -> x (\\u -> y (\\v -> good (u v)) bad) bad ap In \nshort aptakes two parsers (xand y), applies the first (x), and if it succeeds, then applies the second \n(y) with the rest of the input. The result of the combined parser is the result from the first parser \n(u) applied to the result of the second parser (v). But this application (u v) is not eval\u00aduated at this \npoint. It will not be evaluated until some function needs the return value of the whole parser later \nin the compilation. That would account for some lag of ap\u00adplication cells, but the problem is void. We \nconclude that not all parts of syntax trees that represent interface files are actually needed. The reason \ncan be found in the source module being compiled. The programmer used selective import from the Prelude, \ni.e. all identifiers defined in the Prelude that are used in the code are mentioned in the import declaration. \nThe compiler can therefore remove all other definitions from the syntax tree of the interface file. The \nnecessary compar\u00adisons make use of removed identifiers, but not of their as\u00adsociated type and arity information. \nIt is this information that amounts for much of the heap void. Since the com\u00adpiler knows which identifiers \nwill be needed before it starts reading the interface files, this filtering can be done earlier. H 24% \n*,, o 26% .ss 00 200 400 m o ,.mnd Figure 4. Memoriz ation remo ves a large part of the peak at the \nend of evaluation. Moving the filter function into the parser solves this prob\u00adlem t~~nlythe parser \ncombinators evaluate the applications in their return values. By forcing evaluation of the application \n(u v) inap and promoting the filter into the pamer, we flatten the first peak (see Figure 3). To make \nthis change straightforwardly it is essential that functional values can be forced, as the parser combinator \nhas nowayof knowing the result type of the application (u V).2 4.3 Sharing can reduce memory usage The \nnatural next step is to obtain a constructor profile of cells created in IExtract and never used. However \nthis does not give any useful information: memory is more or less evenly divided among a dozen types. \nBut a producer profile with the same restrictions reveals that 61% of the memory in the profile is produced \nby the function uniqueType. This function checks that all type constructors and type classes used ina \ntype are imported.3 Ifsothen uniqueType returns the type with all identifiers replaced by their unique \nnum\u00adbers. A biographical profile of cells produced by uniqueType reveals that no less than 81~0 of the \nheap occupied by these cells are heap void, and only 1% is heap use! The large heap void is because many \ndefined in PreludeCore. ers in PreludeCore to way to import from it Making uniqueType is already evaluated \nof these types belong to class methods Haskell 1.2 does not allow identifi\u00adbe hidden, so the programmer \nhas no selectively. more lazy does not help: too much due to the check for undefined type constructors \nor classes. Introducing a memo table as an auxiliary argument to uniqueType is far more effective as \nIt increases sharing. The void percentage becomes even higher than before (91%), but the total amount \nof memory used by uniqueType is now only one tenth of the amount needed before. The one drawback of this \nmodification is that it slows down the compiler by 4~o. If it is not possible to force evaluation of \nfunctional values then two different types of ap are needed. It is then up to the programmer to choose \nthe correct one depending on the type of the returned value, This check is required by the Haskell 1.2 \nstandard 37 350k . 28% lag 3CW 1 2&#38;lk n 23% V.,, W3k pg# 22% *?., ,50k , cm o 27% US. %k ok 00 \n200 400 000 second Figure 5. Not creating symbol-table entries for instance definitions of class methods \nremoves the narrow plateau left at the end of evaluation in Figure 4. Most of the bands are even and \nno obvious point of attack is available. (The bump in the heap drag is due to circular dependencies and \nnot easily removed).  4.4 Sometimes sharing increases memory usage After two attacks on heap void, \nit is time to tackle the heap drag. Part of the second of the two peaks of heap drag in Figure 4 is a \nconsequence of using a symbol table. The symbol table turns into heap drag as each entry is used for \nits last time. But the jirst peak has no obvious explanation. By fur\u00adther profiling it is easy to find \nout that the module Import creates most of the cells that are dragged, with the function process Interfacel \nas its main producer. However, look\u00ading at the code for processInterfacel does not explain the large \namount of memory produced, or why it is dragged. The function processes the header part of interface \nfiles, extracting renammg and jixity information, and returning mappings from visible names to fixit \ny and real name. We should like to see why these mappings are retained, but we cannot obtain a retainer \nprofile restricted by biographical information as explained in $3.2. Since the definition of processInterfacel \nitself looks innocent enough, we suspect a problem in the code that uses its return value. We manually \ntrack the values that process Interf ace 1 returns until the problem is finally found in IExtract. This \nmodule re-orders the symbol table from using real names as keys to using visible names instead. It does \nso by flattening the original symbol table into a list and then rebuilding it with the new sorting order. \nHowever, the work done by uniqueType happens at the same time, and uniqueType needs the table sorted \nby real names to decide which type constructors and type classes are available, and to find their unique \nnumbers. This sharing means that the original symbol table (sorted by real name) is kept until the new \none is completely built! The parts of the symbol table created by the functions that process Interfacel \nreturns are not used by unique Type, and hence show up as drag in the heap profile. By building a small \ntable with only the mapping needed for uniqueType, at the same time as the Figure 6. A constructor profile \nof the void band from Figure 5. new svmbol table is built, the . memorv usage can -\u00ad . . peak ho reduced \nby approximate ely 30kb. This solution depends on la,wness as uniqueType needs the mapping to build the \nnew symbol table a circular dependency that makes it difficult to remove the rest of the first drag \npeak. 4.5 Eagerness may build redundant structures There is just one unexplained peak left. This is \nthe narrow plateau of heap void created shortly before the end of the execution (again see Figure 4). \nOur usual tactic of doing a module profile restricted to the biographical data of interest draws our \nattention to two modules, NameLow and Trans-Name. Profiling producers in these two modules, we find the \nfunction trenslat e accounts for 40% of the memory. This function does a fix-and-clean job on the symbol \ntable as part of the final preparations before code generation. One of these fixes is to create entries \nfor instance definitions of class methods (e.g. the equality function in the Int instance of the class \nEq). These definitions have not had their own entries before. Their unique numbers have been kept in \na list in the entry for the class they belong to. Entries are now needed as the type checker may insert \ntheir unique numbers in the syntax tree, and these numbers must be translated into real names before \ncode generation. But the compiled module might only use a few, if any, of these methods. The others are \nvoid. Knowledge about which methods are ac\u00adtually used is not available at this point in the compiler. \nOur remedy is to store both the number of the class and the number of the class method in the syntax \ntree, instead of the number of the instance method. Then no entries are needed in the symbol table for \ninstance methods.4 We have now reached the heap profile shown in Figure 5.  4.6 The final(?) squeeze \n trading words for bits Most of the peaks are gone, and those remaining can be explained. However, it \nwould be nice to remove the void band completely. The constructor profile restricted to heap void in \nFig\u00adure 6 clearly illustrates the problem: 56% of the heap void 4For other reasons, instance definitions \nin the compiled module itself must have symbol-table entries 38 mk~ . 32% Ikn I ?COk 250k z 20% w m \nE 16% *W ,50k ,W . 32% m ,Ok % 00 zoo ,00 600 sad Figure 7. The full profile when position information \nis encoded in an Int. is used by Pos constructions, representing lexical position information! This \nis very depressing as-the info~mation is only used if an error message is generated. It is fairly easy \nto change the coding of position information from the naive data Pos = Pos PackedString Int Int5 to a \nmore compact type Pos = Int. File names are encoded as small numbers which are combined with line and \ncolumn numbers into a 32 bit integer. This limits the number of files, and the maximum line and column \nnumbers, but the pay-off is very good a 1570 reduction in overall cost (see Figure 7). There is also \na reduction in heap drag because many integers were previously used only once, to calculate the next \ncolumn or line position. 4.7 Have we specialised for one test file? The previous sections have all used \nthe same test file. However, we obtain a similar overall improvement for every source file in the compiler \nas shown in Figure 8. The curves are very rough but at least two trends are clear. The im\u00adprovement in \ntime is larger for larger source files, but the fall in maximum heap size is smaller. One explanation \nof the smaller percentage reduction in maximum heap size for larger files is that our improvements mostly \naffect the processing of interface files. When the source module is small the processing of the (very \nlarge) interface file for the standard prelude accounts for a large part of the maximum peak in heap \nspace. But for larger source files, type checking creates most of the maximum peak in heap size, and \nno improvements have been made to the type checker as a result of the profiling described in this paper. \nThe reason for the greater improvements in time for lar\u00adger modules is less clear. A reduction in live \nheap does mean fewer and cheaper garbage collections, especially if the live heap originally used most \nof the available memory. But we suspect that this is only a partial explanation. The two curves for time \nand maximum heap size more or less cancel each other when costs in byte x seconds are considered. The \noverall improvement in cost is about 50~o 5The shared packed string is used to store the file name for \nthe position. 100 9C) time maximum heapsize overall cost + --+---B-\u00ad 80 7C) 60 50 40 0 50 100 150 200 \n250 300 350 400 450 500 Figure 8. The graph shows what per\u00adcentages of the maximum heap size, exe\u00adcution \ntime and overall space x time cost of the original compiler are needed by the improved one. The x-axis \nshows the num\u00adber of source lines in the compiled mod\u00adules. for nearly all modules. This is the factor \nof two improvement promised at the start of the paper. A 115-line module dealing with flag decoding shows \nthe greatest improvement. The main reason is an abnormally large speed-up in the compilation. The code \nin this mod\u00adule is not typical: one large function (50 lines) that builds a tuple, and 45 selector functions \nfor this tuple.6 This is very easy code to compile: almost no type checking and no complicated mutually \nrecursive structures. An unusu\u00adally large part of the time is spent processing interface files. And since \nour improvements mostly affect the parts of the compiler dealing with interfaces we get a larger than \nusual speecl-up. The module with the smallest improvement in cost is PPSyntax. This 170-line module is \na pretty-printer for the syntax tree. The module consist of many mutually recursive functions with high \norder arguments. Over 2/3 of the time and more than half of the maximum heap usage is due to type checking. \nIn our running example type checking was never a problem, and hence no improvements were tried. But when \nnhc compiles PPSyntax, a biographical profile shows that nearly half of the memory is drag (49~0 !) even \nafter our space-saving modifications. One immediate conclusion is that our choice of source file did \naffect our improvements. If we had chosen PPSyn\u00adtax instead then it is likely that something would have \nbeen done about the type checker. Nevertheless, the modifica\u00adtions prompted by profiling the compilation \nof a single mod\u00adule did result in improvements for all other compilations. It is only that some are less \nimproved than others. If records had existed in Haskell 1.2 then this module would not have been necessary. \n 39 5 Discussion It was an (unpleasant!) surprise to discover that only 12% of the live heap structure \nin nhc supposed to be a space\u00adefficient compiler represented cells currently in use for computational \npurposes. Even in the final compiler with improved space-efficiency the figure only rises to 32~0. Of \ncourse this depends on our definition of use. Perhaps this definition is too harsh or restrictive? Yes \nand no! One the one hand, classifying lag cells as useless is in\u00addeed rather harsh. They are not useless \nin the same sense that drag and void cells are. Drag and void cells are truly redundant, though not yet \nidentifiable as garbage: they will never (again) be used in the computation, so they could in principle \nbereallocated for other purposes. Butlag cells are not redundant: they will be needed eventually. Lag \ncells are identified as possible indicators of memory inefficiency only because it might be possible \nto save memory by delaying their creation. So a more generous assessment of the useful part of the heap \nmight include both use and lag cells: 48% for the initial version of nhc compiling our running example, \nand 64% for the final version. On the other hand, one could argue that our figure for use is an over-estimate. \nThis is because a cell is regarded as useful throughout the period between its first and last uses, no \nmatter how infrequently it is used in between or even whether there are any other uses at all. A fundamental \nquestion is if all these problems are due to the use of a lazy language. Maybe we could get rid of our \nspace problems just by using a strict language instead? We don t think so. Although the problem in 54.2 \nwas solved by increasing strictness, all other problems were removed by other means. Increasing sharing \n($4.3) or decreasing it ($4.4) could be just as useful in a strict language. By us\u00ading heap profiles \non a lazy language we find problems with lazy languages. Using it on a strict language we would find \nproblems with strict languages too. 6 Conclusions and future work To aim for negligible amounts of lag, \ndrag and void in heap memory is quite an exacting requirement, especially for large and complex applications. \nBut it could be another useful target as functional languages gradually migrate from large research machines \nto miniaturised systems. To work towards such a target it is essential to have the tools to measure and \nassist progress. In $2 we noted the simplifying abstraction of an undi\u00advided phase of use for a cell, \nregardless of the actual fre\u00adquency with which it is used. We d like to remove this abstraction, to give \na fuller picture of how heap cells are used. One method is to add bit strings to cells. Each bit represents \none interval between censuses, and is set if the cell is used in that interval. If one can afford the \nspace, such bit strings could provide a rich source of information. The main problem might be presenting \nthis information in an accessible way. Another thing on our to-do list is a proper integration of post-mortem \nand live-heap techniques. Programmers ques\u00adtions are often qualified by restrictions specifying cells \nin terms of several different categories: e.g. (What s the bio\u00adgraphical profile of cells retained by \nthis function? or So what s retaining these cons cells being dragged for the latter part of the computation? \n. Bit strings make it possible to answer the first of these questions, using a bit to represent each \ncensus interval, set if the cell was retained by the function in question. We have not found any method \n(short of brute force enumera\u00adtion) to implement the more specific restriction in the second quest ion. \nUnfortunately this is the question we would have liked to ask in ~4.4! Others concerned with efficient \nimplementation of lazy functional languages have developed the use of unboxed val\u00adues [P L91]. Eliminating \nthe box of a cell reference around basic values such as integers can result in marked savings of both \nspace and time. In the case of lexical position in\u00adformation the total space xtime cost of our example \ncould be reduced by another 1070.8 It is therefore important to note that nhc does not (as yet) make \nuse of unboxed values, with the exception of literal strings that are held packed rather than as ordinary \nlists of characters. It is possible to program in the spirit of unboxed values: for example, the explicit \nchange of representation for lexical position inform\u00adat ion can be viewed as a form of box-avoidance; \nin effect, three numeric indices are made to share the same box. But the introduction of true unboxed \nvalues can be expected to yield further reductions in the amount of heap space needed. It is unsatisfactory \nthat the programmer must make ex\u00adplicit use of selective imports to reduce memory consump\u00adtion in the \ncompiler. Selective imports are mainly intended as an aid to help a human reader of the program, not \nas a tool to tune memory consumption. We are therefore im\u00adplementing lazy loading in nhc: the compiler \nwill only load information about identifiers that are needed in the com\u00adpiled module. Selective imports \nare still checked, as hiding a needed identifier is an error. Acknowledgement Niklas Rojemo is supported \nby a post-doctoral scholarship from the Swedish Research Council for Engineering Sciences. We also acknowledge \nthe financial support of Canon Re\u00adsearch Europe. References [AJ89] L. Augustsson and T, Johnsson. The \nChalmers Lazy-ML Compiler, The Computer Journal, 32(2):127-141, 1989. [AJ93] L. Augustsson and T. Johnsson. \nLazy ML User s Manual. Programming Methodology Group, De\u00adpartment of Computer Sciences, Chalmers, S-412 \n96 Goteborg, Sweden, 1993. Distributed with the LML compiler. [Aug84] L. Augustsson. A Compiler for Lazy \nML. In Pro\u00adceedings of the 1984 ACM Symposium on Lisp and Functional Programming, pages 218 227, Austin, \nTexas, 1984. ACM Press. [Hud92] Paul Hudak et al. Report on the Programming Language Haskell: A Non-Strict, \nPurely Functional Language. SIGPLAN Notices, 27(5), May 1992, The less precise restrictions drag or use \nor lag or void are however easy to implement. Unboxed integers were simulated by the unit type to obtain \nthis estimate. 40  [Joh84] T. Johnsson. Efficient Compilation of Lazy Evalu\u00adation. In Proceedings of \nthe SIGPLAN 84 Sym\u00adposium on Compiler-Construction, pages 58 69, Montreal, 1984. [MFH95] G. Morrisett, \nM. Felleisen, and R. Harper. Ab\u00adstract models of memory management. In Proc. 7th Intl. Conf. on Functional \nProgramming Lan\u00adguages and Computer Architecture, pages 66-77. ACM Press, June 1995. [PJL92] S. L. Peyton \nJones and D. Lester. Implementing Functional Languages: A Tutorial. Prentice Hall, 1992. [PL91] Simon \nL. Peyton Jones and John Launchbury. Un\u00adboxed values as first class citizens in a non-strict functional \nlanguage. In Proc. 5th Intl. Conf. on Functional Programming Languages and Computer Architecture, pages \n636-666. ACM Press, August 1991. [RR95] Colin Runciman and Niklas Rojemo. New dimen\u00adsions in heap profiling. \nTechnical Report YCS 256, Department of Computer Science, University of York, 1995. (Revised version \nto appear in Journal of Functional Programming). [RW92] Colin Runciman and David Wakeling. Heap profil\u00ading \nof a lazy functional compiler. In John Launch\u00adbury and Patrick Sansom, editors, Proc. 1992 Glas\u00adgow Workshop \non Functional Programming, pages 203-214. Springer Verlag, 1992. [RW93] Colin Runciman and David Wakeling. \nHeap profil\u00ading of lazy functional programs. Journal of Func\u00adtional Programming, 3(2):217-245, 1993. \n[Roj95a] Niklas Rojemo. Garbage Collection, and Memory Efficiency, m Lazy Fkctional Languages. PhD thesis, \nDepartment of Computer Sciences, Chalmers University of Technology, S-412 96 Goteborg, Sweden, May 1995. \n[Roj95b] Niklas Rojemo. Highlights from nhc: a space\u00adefficient Haskell compiler. In Proc. 7th Ml. Conf. \non Functional Programming Languages and Com\u00adputer Architecture, pages 282 292. ACM Press, June 1995. \n[San94] Patrick M. Sansom. Execution profiling for non\u00adstrict functional languages. PhD thesis, Depart\u00adment \nof Computing Science, University of Glasgow, 1994. [SP95] Patrick M. Sansom and Simon L. Peyton Jones. \nTime and space profiling for non-strict higher-order functional languages. In 22nd ACM Symposium on Principles \nof Programming Languages, pages 355 366, San Francisco, CA, January 1995. ACM Press.  \n\t\t\t", "proc_id": "232627", "abstract": "The context for this paper is functional computation by graph reduction. Our overall aim is more efficient use of memory. The specific topic is the detection of dormant cells in the live graph --- those retained in heap memory though not actually playing a useful role in computation. We describe a profiler that can identify heap consumption by such 'useless' cells. Unlike heap profilers based on traversals of the live heap, this profiler works by examining cells <i>postmortem</i>. The new profiler has revealed a surprisingly large proportion of 'useless' cells, even in some programs that previously seemed space-efficient such as the boot-strapping Haskell compiler nhc.", "authors": [{"name": "Niklas R&#246;jemo", "author_profile_id": "81100401642", "affiliation": "Department of Computer Science, University of York, Heslington, York, YO1 5DD, UK", "person_id": "P209185", "email_address": "", "orcid_id": ""}, {"name": "Colin Runciman", "author_profile_id": "81100654458", "affiliation": "Department of Computer Science, University of York, Heslington, York, YO1 5DD, UK", "person_id": "P49752", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/232627.232633", "year": "1996", "article_id": "232633", "conference": "ICFP", "title": "Lag, drag, void and use&#8212;heap profiling and space-efficient compilation revisited", "url": "http://dl.acm.org/citation.cfm?id=232633"}