{"article_publication_date": "10-01-1994", "fulltext": "\n Object Persistence in Heterogeneous Databases Workshop Addendum Paul J. Richards Electronic Data Systems \npricha0 l@ddex.etsgmeds.com As the second in a continuing series, the Object Persistence in Heterogeneous \nDatabase Workshop commenced at the OOPSLA 94 conference in Portland Oregon on Monday, October 24, 1994. \nThis years persistence workshop consisted of more than 20 participants with representation from both \nIndustry and Academic arenas. Several position papers reflected functional architectures and systems \nutilizing home-grown database interfaces while others reflected heavy leveraging upon industry standard \nor proprietary products for effecting their object persistence. This years workshop participation and \nquality of output was a great success. 1.0 Workshop Participation 1.3 Participants Workshop participation \nfrom the various Jim Augins Augins Defense companies and Universities included: John Baker Adv. Boolean \nCncpts Joe Kinsella Easel Corporation 1.1 Chairpersons &#38; Organizers Mike Menn Christopher Reedy QSYS \nMitre Lougie Anderson Johnny Martin Sequent Versant Rick Russell Ashutosh Tiwary Burlington N. RR Boeing \nComp. Srvcs Allen Otis Servio Logic Paul Richards EDS, OOAIS 1.2 Authors and Speakers 2.0 Introductions: \nPaul Richards George Copeland IBM, Austin Texas Mr. Paul Richards identified this years Christina Lau \nIBM, Canada workshop goals. The workshop this year Taejae Lee IBM, Santa Teresa was to focus on products, \nstandards and Bob Nemec EDS, OOAIS architectures which help in realizing this Juraj (George) Petras BNR, \nCanada goal. To do this, the 1994 workshop will Richard Sargent QSYS utilize the results of last years \ndiscoveries by Wonhee Sull University of Miami building upon the issues sighted and generate Bhavani \nThuraisingham Mitre a working set of requirements envisioned to Jane Xu IBM, Santa Teresa support heterogeneous \nobject persistence. Ralph Stout Information Builders Lougie Anderson and Paul Richards introduced the \nauthor of each accepted paper for the workshop. Each author presented their paper and the most outstanding \nhot topics they felt were pertinent 2.1 Persistent Object Services for Heterogeneous Datastore: Taejae \nLee (Co-authors include Daniel Chang, Christina Lau and Jane Xu) Mr. Lee described his paper which includes \nthe Common Object Datastore Adapters (CODA) based on the OMG Persistent Object Service Specification. \nCODA defines a set of tools for 00 access to data. CODA is middleware with client/server architecture \nand provides object-oriented access to data residing in conventional datastores, such as hierarchical \ndatabase, relational database and record file system as well as ODBMS. The design of CODA is based on \nthe OMG Persistent Object Service Specification providing a common interface to various datastores. CODA \nsupports a client-server architecture, where the data is cached in a user s environment. CODA consists \nof four components, the function of each is as follows: o Smart Schema: Framework for mapping an object \nschema to a datastore schema 0 Schema Mapping Engine: Conversion to/from a Schema Mapping Definition \nLanguage o Datastore Manager: Provides add, change, update and deletion of objects o Smart Access: Allows \nan end user to access data without programming  Hottest Topics Identified by Mr. Lee: 1) Pre-fetch hints, \n2) Single level storage and 3) Automation of new database adapters. 2.2 Framework for Internal Object \nManagement for Real-Time Systems: Juraj Petras (Co-authors Richard Lemieux, Robert Lowe) Mr. Petras described \nthis framework which is the building block for distribution of real-time objects. The application of \n00 technology in real-time critical systems, such as a telephone switch, is a challenging goal. BNR advocates \nbuilding a central framework which provides fast creation, destruction, and association capabilities. \nThe framework also provides building blocks for distribution of real-time objects between different processors \nalong with incremental upgrades of object clusters while the system is running. The framework plays the \nrole of an 00 database system and its performance is critical. As the number of services required on \neach switch increases, the management of the software running on those switches becomes more complex. \nUsing OOT enables a faster delivery of those services. Overall system requirements include: 1) non interruptable \nservice (DMS switch cannot be shut down but still needs updates) 2) fast transfer between nodes 3) incremental \nupdates and 3) consistency issue and replication. Hottest Topics Identified by Mr. Petras: 1) No downtime \nfor software upgrade, 2) Fast object transfer between systems and 3) Consistency of replicates.  2.3 \nArchitecture and Aspects for Persistent Objects: Richard Sargent Mr. Sargent described the architecture \nand persistent data aspects of an application developed for a specific. The system developed reflects \nmany of the actual issues we discussed in the 93 workshop. In this system, the application required an \n00 interface to AS/400 keyed files. A custom interface was written to support the application for effecting \npersistence. The interface designed supported the following features: Caching: The cache management functions \nof the interface manage small static data sets. These are the instances of classes which do not need \nrefreshing on the clients. Large static data sets are not cached. Other objects are cached if they fulfill \na LRU profile, but these are still for small relatively static data sets. Transactions: Implements a \nlogical Unit Of Work. This model collects changes to objects in one set and set the updates. Updates \nare verified with a timestamp to make sure no one else has updated the record. Object Identify Maintenance: \nObject identify was maintained through encoding of class, unique identifier and version information. \nReferences to object were managed. Relationship Management: Relationships were managed by modeling and \nformally supporting the notion of collections. Hottest Topics Identified by Mr. Sargent: 1) Cache management, \n2) Database support for garbage collection and 3) Versioning of objects. 2.4 00 Approach to Integrating \nPersistent Heterogeneous Database Systems: Bhavani Thuraisingham / Bob Nemec Mr. Nemec spoke to the role \nof the object- oriented approach and how it can facilitate the interconnection of multiple database systems \nusing schema integration distributed object management. As DBMSs are being used increasingly in many \norganizations, the interoperability of these DBMSs within heterogeneous and autonomous environments will \nbe required. An 00 approach can be utilized both for schema integration as well as interconnections between \nthe various DBMSs. Theoretically, a generic 00 representation can be used to support the transformations \nbetween a relational model and an 00 data model. A specific concern with a generic 00 representation \nof heterogeneous databases is performance. In actual applications, it has been found that orders of magnitude \nperformance improvements can be achieved if the 00 representation is bypassed. Hottest Topics Identified \nby Mr. Nemec: 1) How to automate generation of complex queries for specific databases and 2) Database-independent \nlanguage for object queries ?  2.5 System Services for SOM Objects: George Copeland The goal of IBM \ns System Object Model (SOM) is to provide the underlying technology to support large-scale code reuse. \nThis involves addressing several problems, including binary-code re-use across compilers and languages, \nlocal-remote transparency, automatically inserting object services (e.g. , persistency, concurrency, \nrecoverability, security and distribution) into binary classes and datastore independence. The importance \nof binary code reuse was cited including the facts that source code must be made available, the code \nis usually poorly tested, changes are difficult to detect, compilation is resource intensive and software \npiracy is a problem. SOM supports binary re-use by offering the compiler and language independence. Here \na class compiled with one compiler can be subclassed using another compiler. Additionally, these compilers \ncan be of different language types. Programming using SOM library technology involves defining a class \nin OMG CORBA IDL. The methods can be written in any language and are supported by adding adequate method \nresolution techniques. Several significant issues surfaced during Mr. Copelands presentation. Foremost, \nperformance for transporting objects between different address spaces was a concern. There are certain \nlevels of non-transparency bought into using this architecture. In particular different network calls \nhave October 23-27,1994 different failure modes and must be programmed for. Additionally, utilizing this \napproach assumes the existence of global variables. Advantages pointed out (beyond the stated benefits) \nis that just-in-time creation of classes can decrease the amount of coding necessary where classes are \nbuilt for persistency and recoverability. Hottest Topics Identified by Mr. Copeland: 1) Reuse of classes \nshould be possible using binary code, without source code and 2) Do object services such as persistence, \netc, limit reuse ? 2.6 Heterogeneous Databases in Medical Environments: Wonhee Sull Mr. Sull described \nhis experiences with an object oriented information infrastructure he is currently developing for Health \nCare Information Systems. The goal of this architecture is to support medical information stored across \ndiverse databases. The approach is to achieve integration of PACS and HIS using the 00 data model. Since \nthere are large amount of data in current medical relational databases they will derive their 00 data \nschema from the relational schema. Additionally, their approach supports the autonomic and dynamic creation \nof an integrated view of the data. In this environment, they have a very heterogeneous network. In addition \nto dealing with connections between nodes they must deal with political and security issues. Hottest \nTopics Identified by Mr. Sull: 1) How much automation of interfacing is possible and 2) How to compare, \nintegrate objects from different class libraries. 2.7 Information Builders Query Representation: Ralph \nStout Information builders brought to the table a unique approach for accessing multiple databases from \na single front-end client. As Mr. Stout explained, in the architecture of IB, their database access mechanisms \nproduce iSQL for a Data Access Engine to process. IB supports access to over 50 database types across \n35 platforms. To date, this approach is one of the most flexible data access architectures found. The \nsteps in query decomposition, representation and regeneration are: 1) SQL sent from client, 2) Parsed \nthrough parser, 3)Decomposed into Abstract Syntax Tree, 4) Checks semantics using me&#38;data, 5) Other \n(type) information added, 6) Run through SQL generator. Hottest Topics Identified by Mr. Stout: 1) Transaction \nprocessing, 2) Data migration and 3) Caching  3.0 Workmow Topics: Johnny Martin and Allen Otis The \nworkshop participants reconciled the hottest topics and divided into two workgroups to discuss a subset \nof the hottest topics. 3.1 Workgroup ONE Topics and Findings (Performance) 3.1.1 Pre-fetching Pre-fetching \nis required to reduce trips to the persistence mechanism. If everything is pre-fetched this could cause \ninefficient overloading though. Hints based on work flow of the application must be used to optimize \npre-fetching. Pre-fetching subsets would be roughly equivalent of 00 views. Adaptive learning approaches \nmay be appropriate for implementing pre-fetching techniques. Who provides the pre-fetching hints? The \nprogrammer could add me&#38;data to the system, the database administrator could do the same, possibly \non a per class basis. The application workflow would have to be deterministic. It would be best to separate \nthe definition of the pre-fetching hints from the application logic. Monitoring and measurement tools \nwould be used to gather summarized states of caching and performance analysis. 3.1.2 Caching, LRU and \nGarbage Collection Motivations for caching include the ability for object access to be as transparent \nas possible. Differences between the 00 and Relational (and other) models requires GC or LRU techniques \nin the cache manager. There is a need to be able to deal with object proxies alone, not just data. Tools \nand techniques are needed for getting rid of object proxies. There will be a high degree of handshaking \nbetween client and server for cache coherency. There are also timing considerations regarding the caching \nof objects. The timing mechanism should be independent of the data itself but will be driven by the frequency \nof access to that data. Several requirements surfaced. The user should be able to identify perm space \nhints so the GC doesn t waist cycles for cached persistent data which is known to not be garbage. The \nuser should be able to identify what portions of memory are used for cache. The possibility of an intermediary \nlevel for caching (in synchronization with the client or server) exists and the requirement for managing \nfailure modes for such an approach. Caching policies are required and the possibility of a knowledge-based \napproach may be appropriate. Thus the cache management solutions range from hints to rules to intelligence. \nRDBMS server caching can give some ideas for what to look at for optimal caching: LRU on the data pages \nor other schemes. LRU could be dangerous for collections vs. atomic data. LRU assumes a uniform unit \nof allocation. What is needed is a hinting mechanism which is more complicated than LRU because of the \nvariations in data size and data usage. Considerations must be made for flushing the cache at commit \ntime. The cache should be independent of commit with features made available to synchronize them if required. \nFlushing would be ignored for implementations with automatic caching.  3.2 Workgroup TWO Topics and \nFindings (Schemas) 3.2.1 Translation of schemas How to translate classes between different systems or \nidentity domains was the key issue here. A common object language needs to be able to specify both structure \nand behavior . IDL is used for just such a definition. Disparate databases can be brought together using \nan IDL approach. Other considerations were made for the meta-model approach and mapping each schema into \na single meta-model. Objects would have to be mapped into and out of the various persistent representations. \nThis approach is very performance poor and it is resource intensive to build and maintain the meta-model. \n 3.2.2 Instance creation and equivalence The difficulty in comparing objects from different identity \ndomains was pointed out. Loading data into an object system and/or other persistency mechanism requires \nthe firing of rules for maintaining object and data integrity. When creating objects in the object persistence \nenvironment a behavioral interface is needed to support the instance creation semantics and the rules \nenforcing such. Special consideration must be made for distributed data across the multiple heterogeneous \ndatabases where the rules must be forwarded to each of the persistence mechanisms. Each rule would have \nto be expressed appropriately for the various database types.  3.2.3 Runtime access to classes Lack \nof runtime access to classes will limit the ability to interface one object domain to another domain. \nIn contrasting C++ with Smalltalk, many of the reflective properties of Smalltalk are not available to \nC++. Unfortunately, it may be necessary to disallow use of certain features from within each language \njust to enable integration of various domains. Incongruencies between the languages may force a least \ncommon denominator approach. 3.2.4 Dynamic creation of classes and sustaining complex relationships \nIs this possible within the respective database persistence mechanisms? If not, then a domain may have \ntrouble importing classes and instances from another domain. Just as an RDBMS can dynamically generate \nviews, it may be necessary for the various persistence mechanisms to generate views or generate classes \ndynamically. Several of the object databases support this capability, others do not. This also depends \non the language interface in which to access the database.  3.2.5 Transaction support When does an RDBMS \nfail to support an application built using object programming? It was pointed out that an RDBMS fails \n(performance wise) with more than 4 or 5 joins compared to object traversal in an ODBMS. An RDBMS fails \nif the database must provide garbage collection of persistent objects with complicated connectivity. \nThe threshold of acceptable performance depends on table sizes and frequency of joins. Recent standardization \nof query capability like SQL3 and/or the ODMG OQL will narrow the gap between the various RDBMS and ODBMS \ns for eventual query propagation across both of these environments.   4.0 Worbrour, Summarization There \nare various products, architectures and standards required to realize the aforementioned challenges. \nThe following lists identifies some of the requirements derived from the Workgroup discussions: 4.1 Asynchronous \nrequests for caching data and Multi-threaded clients. 4.2 ANSI X3J20 (Smalltalk) should adopt a weak \narray and weak pointer finalization hooks to provide callbacks before an object is Garbage Collected. \n4.3 Support memory management and a standard interface to the memory manager for memory I manage in all \nobject oriented languages. 4.4 Support me&#38;level programming capabilities for languages such as C++ \nand others that do not currently allow access to information about the classes at runtime. 4.5 Expand \nCORBA specification to define a common object identifier scheme to allow multi-vendor ORB interoperability. \n\t\t\t", "proc_id": "260028", "abstract": "", "authors": [{"name": "Paul J. Richards", "author_profile_id": "81100451719", "affiliation": "Electronic Data Systems, OOAIS", "person_id": "P222073", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/260028.260133", "year": "1994", "article_id": "260133", "conference": "OOPSLA", "title": "Object persistence in heterogeneous databases: workshop addendum", "url": "http://dl.acm.org/citation.cfm?id=260133"}