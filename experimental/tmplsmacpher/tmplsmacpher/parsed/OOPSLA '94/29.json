{"article_publication_date": "10-01-1994", "fulltext": "\n Persistent Storage for a Workflow Tool Implemented in Smalltalk Bob Beck and Steve Hartley Sequent \nComputer Systems, Inc. 15450 SW Koll Parkway Beaverton, Oregon 97006-6063 rbk@sequent.com (503)578-9809 \nsteveh@sequent.com (503)578-4139 Experience Paper: Database and Persistence. Abstract: This paper describes \na new workflow model and its implementation in Smalltalk. The paper also details problems with using \na RDBMS as the persistent store for the workflow tool and the subsequent experiences in using an ODBMS \nfor this purpose. The final solution was a coexistence approach, using the RDBMS for legacy corporate \ndata and the ODBMS for the process description and workflow status data. 1.0 Introduction Workflow is \nubiquitous in corporate life; it is the value chain that makes things happen. Workflow occurs whenever \none individual passes something to be done along to another individual. Workflow goes by many names: \ndelegation, corporate process, paper- shuffling, how things get done, the way we do things here . In \ncompanies today, workflow proceeds primarily with the flow of paper from individual to individual, though \nE-Mail is becoming a common vehicle for the flow of work. Though this flow of work is the lifeblood of \nmost companies, rarely is it automated, controlled, or even explicitly defined. As an example, at Sequent \nwe have a well- defined process for creating new part numbers for our products. There are several steps \nto part number creation and each step can be done by one or more individuals. Each individual is typically \nworking on several different part numbers simultaneously and Permission to copy without fee all or part \nof this material is granted provided that the copies are not made or distributed for direct commercial \nadvantage, the ACM copyright notice and the title of the publication and its date appear, and notice \nis given that copying is by permission of the Association of Computing Machinery. To copy otherwise, \nor to republish, requires a fee and/or s ecific permission. OOPS LI 94- 10194 Portland, Ore on USA Q \n1994 ACM P O-89791 -688-3194 0010..$3.50 wants some on-line control of their work queue. There is a \npartial ordering among the steps, but some sequences of steps can be done in parallel. There are usually \nseveral part numbers being created at the same time (instances of the part number creation process), \nand there is a need to determine status for each instance at any point in time. Also, part number creation \nisn t always as easy as it sounds, and process instances (part numbers being created) must sometimes \nbe sent back to earlier steps for rework or clarification; we want to track these exceptions to the normal \nflow of work. We also want to predict the expected time for each step in the part creation process as \nwell as the overall expected time for the process to execute and to track deviations from these expected \ntimes. Finally, the part number creation process is a component of other (larger) processes at Sequent. \nLike most companies, we at Sequent are trying to understand our workflow; the processes by which things \nget done, and to provide tools that will help US to understand and automate these processes. To this \nend, we began an investigation of workflow products with the following requirements in mind. We wanted \na generic workflow tool that would be relatively easy to understand and use (e.g., using a graphical \ninterface), that could be applied to a variety of corporate processes, and that would minimize the impact \nof process changes while allowing for systematic process revision and improvement. It was important that \nthe tool enable us to track multiple instances of workflow within a given process, and would handle exception \nconditions (when something went wrong and a given instance had to be sent back to an earlier step in \nthe process). The tool needed to provide access to corporate data stored in relational database systems, \nand would ideally store the state of processes and related data in relational databases. The tool needed \nto allow for reuse of process descriptions, since simpler business processes are replicated in move involved \nprocesses. Similarly, data access components should be reusable and customizable by end users (rather \nthan involving IS professionals). Finally, the tools needed to allow for after-the-fact analysis of process \nexecution, and provide critical path analysis. Unfortunately, we were unable to find a workflow product \nthat met our requirements. This led to the decision to implement our own workflow tool, the Process Quality \nManagement System (PQMS). Additional requirements for sophisticated GUI capability and portability led \nto the decision to use Smalltalk in the PQMS implementation. Original plans also called for the use of \na Relational Data Base Management System (RDBMS) for both access to corporate data (Sequent runs its \ncompany on RDBMSs) and for persistent storage of process descriptions and process instance data. However, \nour initial plans to use an RDBMS ran into intractable technical problems, resulting in the decision \nto use an Object Data Base Management System (ODBMS) as a persistent store for parts of PQMS. These intractable \nproblems were not related to the classical impedance mismatch problem between the object model and the \nrelational model but rather to issues of garbage collection and identity maintenance. This paper discusses \nthe object-oriented design and implementation of PQMS, a generic workflow tool. It also discusses the \nproblems encountered in using an RDBMS as a persistent store for the object- oriented implementation, \nand the move to an ODBMS to solve this problem. Our final solution incorporates both an ODBMS and an \nRDBMS, using the strengths of each to achieve a workable solution to PQMS s persistent storage problem. \nThus this paper is the actual experience of a coexistence approach in a production application. 2.0 \nThe PQMS Process Model The goal of supporting time-based statistics is fundamental to the overall theme \nof empowerment and process improvement. In our research we found nothing providing these essential characteristics \nfor workflow design and management other than Critical Path Method (CPM) and Program Evaluation and Review \nTechnique (PERT) which do not support the concept of multiple instances of workflow, alternate paths \n(decision points), or reuse of process components. Petri-nets, flow charts and data flow diagrams were \nall considered but did not meet our needs. As a result, for PQMS we developed a new workflow process \nmodel. This model defines a process graph, an extension of a PERT-chart model, as follows: A PQMS process \ngraph consists of a collection of nodes. Nodes may be connected from their out- side to the in-side of \nother nodes. The graph must have a unique start node (a node with no incoming arcs), and a unique end \nnode (no outgoing arcs). Work flows left -to- right in the graphical representation. A process graph \nmay not contain loops (i.e., a circular path along the arcs connecting nodes). An example of a PQMS process \ngraph under design is shown in Figure 1; the graph represents a prototypical expense report process. \n . A process graph may contain 4 different kinds of nodes in the current implementation. These are Activity \nnode, Or-Emit node, Or-Collect node, and Sub-Process node. An Activity node represents some particular \ntask that one or more people must accomplish. Node properties include a description of the task, the \nnames of one or more people who must do the task, and can include a description of (and contextual information \nfor) a data accessing form, typically used to access corporate data relevant to the process at this node. \nAn Activity node has a property (any/all) which determines, for multiple users assigned work at the node, \nif all the users (aZZ) or just one of the users (any) must complete the task. An all node is used when \nit is important for multiple people to bless a change or decision. An any node is used when any one of \nseveral people can perform the same task, and it s desirable to let the first available person Edit Nodes \nLayout Select Exit Figure 1 complete the task. Activity nodes are . graphically displayed as rectangles \n(e.g., the node labeled Expense in figure 1). Or-Emit and Or-Collect nodes are placed in properly nested \npairs (they act as parenthesis). At an Or-Emit node, a choice must be made about which single output \narc to take. This allows the expression of macro choices in the process, for example, a make vs. buy \ndecision. Like Activity nodes, Or- Emit nodes can contain names of one or more people involved with the \ndecision. Or-Emit nodes are graphically displayed as triangles . 375 larger on the right, Or-Collect \nnodes as triangles larger on the left (see figure 1). A Sub-Process node references another PQMS process \nby name. At this node, work can be started in the named process, and either explicitly waited for (afork) \nor just started and not waited for (a spawn). Using Sub-Process nodes, a collection of smaller processes \ncan be assembled into larger processes without replicating the definitions of the sub-processes. Similar \nto an Activity node, multiple user names can be associated with a Sub-Process node, as well as the any/all \nchoice. Sub-Process nodes are graphically displayed as oval shapes (e.g., the node labeled Notify in \nfigure 1). MiSc Multiple instances of workflow can exist in the process graph at any point in time, each \ncalled a PQMS-instance. Each PQMS-instance maintains its own state, independent of other PQMS- instances. \nThe state of a PQMS-instance includes the set of nodes at which work needs to be completed (active nodes), \nthose arcs on which work has flowed from a node but not yet consumed by the next node, and an audit-trail \nof information about the execution of this particular PQMS-instance (e.g., time stamps of when work arrived \nat and left nodes). A PQMS-instance starts executing at the unique start node. When work completes at \na node, it flows out all output arcs (except for an Or-Emit example, if changes that cannot be undone \nwere made node, which flows out exactly one output arc). to a corporate database. When this occurs, it \nis possible for nodes later in Close Instances Fmcesses User Exit Mist Instances Figure 2 the graph \nto become active. A node becomes Figure 2 illustrates the graphical execution view active when all its \nincoming arcs havefired; that is, all nodes connected to its in-side have completed. When work flows \nfrom the end node, execution of the PQMS-instance is finished. Note that connecting the out-side of one \nnode to the in-side of another makes the fust node a prerequisite for execution of the second (there \nis an execution order dependency between the first and second nodes). There are times in the execution \nof a PQMS- instance where work already completed or previous decisions must be revisited. In PQMS, these \nsituations are called exceptions. For any execution state of a PQMS-instance in any process graph, restart \nrules determine appropriate nodes at which execution can be restarted (e.g., unwound), and the PQMS-instance \ns execution state can be appropriately reset. An audit trail keeps track of which decisions were made \nat Or-Emit nodes, to allow restarting on an or-branch. It is application dependent which nodes may be \nrestarted (i.e., execution that has passed through them may be re-done). The application can add an audit \ntrail entry in a PQMS-instance asserting execution must not be restarted across given nodes. It might \nbe impossible to cleanly restart over a node, for and a given PQMS-instance (OOPSLA conference) in execution. \nActive nodes are displayed darker (in red on color displays); inactive nodes are displayed lighter (in \ngreen). At the Or-Emit node, the choice to take the V.P. branch was made. The PQMS-instance is active \nat nodes V.P. and Logistics. Nodes V.P., Notify, and Logistics are done concurrently, based on the structure \nof the graph. The larger dot on the arc between nodes NotiJs,and Pay represents work that has left node \nNotify (node Notify has completed), but not yet been consumed by node Pay (since nodes V.P. and Logistics \naren t yet complete). Figure 3 gives an example of a simple form associated with node Logistics. 3.0 \nPQMS Implementation 3.1 Interactive Graphical Editing and Execution A major goal of the PQMS project \nwas to provide users with interactive graphical editing of process graphs, and a graphical view of executing \nPQMS- instances. These were provided by several classes that implement PQMS processes and instances, \nand several views in the Smalltalk Model-View- Controller paradigm. These classes are: Class PqmsProcess \n(a Smalltalk Model subclass) holds the process graph and collection of PQMS instances running in the \nprocess. PqmsProcess includes protocol to allow PQMS-instances to be started and terminated. nstance \nName: OOPSLA conference Node Description File vendor receipts. Note: This activity occurs in parallel \nwith V.P. approval and the automatic Notify sub process. Figure 3 Class Pqmslnstance holds the execution \nstate of a PQMS-instance and a reference to the process it s executing in. All execution state changes \nare made by sending messages to PqmsInstance objects. Class ProcessDesignView (and controller) implements \nthe view used to interactively edit a PQMS process graph (figure 1). Typical graphical editing functions \nare provided, such as adding and deleting nodes, connecting and disconnecting nodes (via click and drag \nof a line), selection of one or more nodes (selected nodes are displayed in a different color), moving \nselected nodes by click and drag with the mouse (this includes rubber-banding connection lines as the \nnodes move), copy/cut/paste nodes, alignment and distribution of nodes, and undoing editing operations. \nIn addition, the design view allows editing node properties (e.g., name of the node, time estimates for \nthe task at the node, list of names assigned to the node, description of task to be performed at the \nnode, selection and customization of the data access form to be used at the node; see figure 4). A subclass \nof this view, ProcessPERTView, adds the ability to statically compute critical paths in the graph based \non time estimates at each node. Class ProcessExecuteView (and controller) implements a graphical interface \nfor executing PQMS-instances in a process (figure 2). This view allows the selection of any PQMS-instance \ncurrently active in the process, displaying active nodes in a different color (by default, red). Clicking \non an active node launches the form associated with the node. The forms typically include a button to \ndeclare the users work complete at the node, allowing execution to proceed further in the graph (figure \n3). PqmsExecuteView affects execution state changes by using the protocol in class PqmsInstance. Other \nexecution views are possible; for example, a view could provide a list of PQMS-instances where a given \nuser has work, and once a PQMS-instance was selected a list of named active nodes could be presented; \nselecting an active node launches the form. Another interface to PQMS-instance execution might be command-line \nbased, running a headless version of the PQMS application driven from shell scripts. There are many other \nclasses involved in building the graphical part of the PQMS application. These include classes for each \nkind of node, classes to implement property editing dialogs, and utility classes.  3.2 Application Independence \nof Process Framework Throughout the design and implementation of PQMS, the process description and basic \nworkflow execution of the application have been kept carefully independent of the particular initial \napplication (set of forms and semantics). It was felt this would lead to a cleaner design, and the possible \napplication of the process part of PQMS to other applications at Sequent. The result is the specification \nand implementation of well-defined boundaries between the lower-level process and workflow framework \nand the application running on the process framework. For example, a process graph will store the name \nof a form class at a node, and an arbitrary context object of individually prepared and executed SQL \nfor that form. The process framework has no expressions. knowledge of the particular form, nor knowledge \nof Class AbstractTable, an abstract class supporting the context object. However, the framework ensures \nmapping of RDBMS tables to concrete Smalltalk the context object is made persistent, by sending it subclasses. \nIt holds row instances resulting from the markDirty message at appropriate times. messages to TableAccessor \nand provides protocol Although the process framework can be used to access table attributes and produces \nattribute independently as a tool to guide and track workflow, default values for new row insertion. \ndirect access to corporate data was also a goal. This Class AbstructCDAT, an abstract class capability \nis implemented through a set of classes supporting display and control of both the data representing \nCorporate Data Access Tools (CDAT). and the activity node from which it can be These tools are bound \nto an activity node during the requested. During design this class supports the design process where \nthe CDAT class name is held capture of customized view-behavior. Duringby each node. The process framework \nprovides process execution it presents a view of default dialogs for each node type. CDAT tools AbstructTuble \ndata to the user with both generic extend the scope and capability of those dialogs controls and any \ncustom behavior. through subclasses providing access to corporate RDBMS s. The following systems of \nclasses provide Class AbstractRow holds the table-specific CDAT canabilities: single-row view that can \nbe a component of any of the variety of views supported by concrete lode Name: Assignment List I Forms \nActivityNodeDialog CDAT Manager approves all expenses. ControlledDistributIon EMPLOYEE INSTANCES INSTANCESQueue \n PNRDual PNRlnstanceName PNRNew bptlmistic Estimate: 0 Auto Launch  lost Likely Estimate: Figure 4 subclasses \nof AbstructCDAT. It also holds a row Class TubZeAccessor holds database connection state, acting as \na row buffer, and provides state and protocol for transaction management. It methods to manage form field \nvalidation, lookup- provides transient access to results (rows, errors) and-selection, and specialized \nbehavior. During design, each node in a process may be perform restart operations on PQMS-instances. \nassigned one of these CDAT forms, and the behavior Those with execution privileges may execute process \nof a form may be customized as required by that activities only if their name appears in the activities \nparticular activity. The specification of that behavior assignment-list. They may not perform process \nis recorded in the nodes context object. The process restarts. designer may specify the following features: \nthe Data Resources Instance Help Inspect Exit Expense Approval Request 1 50069 Description Figure Menu-bar, \nwhich may be selected from a list of available menus (a menu may provide functions for process control, \ndata storage, query, print and other actions); Button-state which enables/disables buttons on the view; \nQuery-characteristics such as Query- only, Query-on-startup and custom SQL-clause; Confirm-characteristic, \nwhich controls the use of a confirmation dialog box when execution at a node has completed. Each field \non the form may also enabled or disabled: enterable, mandatory, queriable and visible characteristics. \nThe basic PQMS process framework is extended via subclasses to add general system-wide roles that limit \naccess and functional capabilities. Four roles provide access authorization: administration, design, \nmanagement and execution. Administrators control the release of processes into the production environment \nand may perform all design, management and execution functions. Designers may create new processes but \nmay not modify released processes nor release a process into production. Managers may execute any process \nactivities and Originator 1 rbk 5 Figure 5 shows the Expense activity s view of an expense report form, \nand figure 6 shows the V.P. activity s view of the same form. Each form shows adaptive behavior where \nenterable form fields are highlighted.  3.3 Development Process The initial analysis and design were \ndone using the Responsibility Driven Design methodology [Wirfs-Brock et.al., Designing Object Oriented \nSo@are]. This phase was very valuable to get all team members using common terminology to talk about \nthe application and its requirements (this was particularly useful given the diverse backgrounds of the \nproject members). This produced an understanding of basic requirements and structure of the application. \nAs a result of the inexperience of the developers with object design methods, the initial analysis and \ndesign provided good direction but insufficient specification of requirements. This resulted in a number \nof re-factorings of large pieces of the system as newly understood requirements PQMS-instance state \nwere being stored in an emerged. RDBMS. As more functionality was added to PQMS, however, it became clear \nthere were The PQMS source code was stored in a source- significant problems in continuing to store the \ncode management system on a per-class basis. Some process component of PQMS in an RDBMS. Thishome-grown \ntools made this a reasonable approach section discusses what was successfully storedfor a small number \nof developers. These tools use the relationally, the problems encountered, what was change set maintained \nby Smalltalk to know what done to convert to an ODBMS, and some of the classes have been modified, allowing \nfileout of only problems presented by the ODBMS. A brief modified classes. The tools also implement treatment \nof these issues has been previously automatic generation of accessing methods, class described in [Loomis, \nHitting the Relational Wd]. )ata Resoumes Instance Hel Expense Approval Request 71 Originator Irbk Description \n Requestto attend OOPSLA conference to presentpaper on the use ofSmalItaIk,OODBMS and RDBMStechnol'ogiesto \nManager Vice President Approved @ Y l!!Eiia Figure 6 comment templates, version methods (to encode class \nversion information in the source and binary image), 4.1 Use of Relational Database Management and automatic \ngeneration of an installation script System (makefile). The tools are in the public domain, in the PQMS \nwas able to store processes and a subset of Manchester/U1 Smalltalk goodies archive PQMS-instance state \nin an RDBMS and rematerialize (mushroom.cs.man.ac.uk (130.88.13.70) or this state from the RDBMS for \nuse in the application. st.cs.uiuc.edu (128.174.241.10), file This included storing all four kinds of \ngraph nodes /pub/MANCHESTEWmisc/development-launcher.st) with all their state, the connections between \ngraph nodes, and enough state information to persistently store PQMS-instances in arbitrary states of \nexecution 4.0 PQMS Persistent Data Issues in a process graph. Audit record data, assignment of forms \nto nodes, and context objects were never stored An initial goal of the PQMS project was to store relationally. \nAlthough transactions were used in the all data in an RDBMS. This was primarily due to RDBMS, no support \nfor concurrency control existing corporate data stored in relational databases was implemented in the \nrelational model (i.e., there was at Sequent, which PQMS needed to access. The relational database approach \nwas used for a while, to no use of select for update), and therefore safe multi-user access was not implemented. \nthe point where PQMS processes and a subset of Processes were stored in 9 tables: a table to map process \nname and date/time stamp into process identifier (a number unique across all processes); one table for \neach kind of graph node (including all properties particular to the kind of node); a table to list the \nkinds of graph nodes contained in a given process (this limited the number of selects necessary to read \nthe graph, and allowed the kinds of nodes to be extensible); a table to encode the connections between \nnodes (this table stored, for each process, the in-and out-side node numbers for each connection between \nnodes); a table to store the user names assigned at each node; and a table to store the names and unique \nidentifiers for the PQMS-instances currently active in the process. PQMS-instances were stored in 6 tables \nto keep track of: unique identifier of the parent PQMS- instance (if any); child PQMS-instances of subprocess \nnodes; the set of arcs on which work is waiting; the set of nodes that are currently active; the names \nof users yet to complete work in each active node; and a unique application key value. In addition, there \nwere two sequence number tables, to create unique identifiers for PQMS processes and instances. These \ntables were each represented in Smalltalk as concrete classes, subclasses of more abstract classes that \nprovided RDBMS functions. The root of this hierarchy was class DbmsTable, which provided class methods \nfor basic selects, joins, deletes, and inserts. This class was abstracted via subclasses to support the \nabsence of identity in the RDBMS; for example, use of unique sequence numbers as identities for PQMS-Processes, \nPQMS-Instances, and for numbering nodes within the graph. The graph node tables were also represented \nby concrete classes with abstract superclasses supporting common sub-structure. In all, about 25% of \nthe classes in the application provided the RDBMS abstractions. At least 25% of the design time was spent \nbuilding the RDBMS abstractions. For both PQMS processes and instances, state is represented both by \nthe presence and absence of rows in relevant tables. For example, a connection exists between nodes A \nand B if there is a row in the connections table for these nodes; otherwise, no such connection exists. \nAs a result of this, updating a process definition or PQMS-instance required deleting all rows concerning \nthe PQMS process or instance in all relevant tables and then inserting new rows to represent the new \ndata structure. In order to use SQL updates, it would have been necessary to keep a copy of the state \nknown to exist in the database (to avoid fetching it again), compute the difference between the currently \nstored state and the new state, then using SQL updates, deletes, and inserts where appropriate. This \nwas viewed as too much complexity in the early phases of PQMS and wasn t attempted. 4.2 Problems With \nthe RDBMS The extent to which PQMS stored state relationally was not without problems. Among the first \nproblems noticed was that storing a well understood, interrelated, set of Smalltalk data into relational \ntables was awkward. In particular, the Smalltalk objects referred to each other via Smalltalk object \nreferences, or via identity. An RDBMS only supports storing and comparing values; there is no support \nfor storing references to anything. As a result, it was necessary to generate unique identifiers to provide \na form of identity in the otherwise value based relational model. This is not difficult, but introduces \nadditional data into the application that has nothing to do with the data abstraction of the application. \nStoring objects in relational tables effectively requires taking the objects apart and storing a representation \nin a set of flat tables. Reconstructing the objects involves a series of selects from the RDBMS and reassembling \nthe objects. During this process, previously existing identity relationships must be preserved. For example, \nif one node in a graph refers to another (e.g., since they are connected), when the process graph is \nstored and later retrieved this same reference must exist. It is not acceptable to refer to a copy of \nthe node. The schema design and code to read and write objects must be very careful here. In PQMS this \ninvolved assigning numeric indices to nodes (corresponding to their position in an OrderedCollection) \nand storing connection information based on these indices. After the nodes have been read from the database \n(and ordered in the same order they were in when written), the connections table is read and the nodes \nare literally reconnected. This imposed a constraint on how the nodes were stored in Smalltalk (in an \nOrderedCollection of nodes) that was otherwise irrelevant to the application. A related problem, although \nmore subtle and difficult to handle, is that objects can be reached via multiple paths. For example, \na PQMS-instance object might be reached from the process it is executing in, while a user is manipulating \nit in a user interface. It might also be reached from another PQMS-instance object if it is the child \nor parent of that object (the result of a fork operation in a Sub- Process node) as part of a change \nof execution state. Similarly, process objects can be reached by multiple paths via the user interface, \nor references in PQMS- instance objects. It is imperative that regardless of which path is used to reach \nan object, a unique object is found. The application will fail if multiple copies of an object (or objects) \nare materialized from the database. This was handled in PQMS via a caching technique; all process and \nPQMS-instance objects were fetched (ultimately) through a lazily evaluated dictionary that materialized \nobjects from the database if they weren t already in memory. This dictionary was keyed using the unique \nprocess or PQMS- instance identifier. Another problem was the parallel hierarchy of classes providing \nthe relational abstraction. As noted above, approximately 25% of the classes in the application were \nthere to enable RDBMS storage and retrieval of PQMS processes and instances. This hierarchy necessarily \nhad to reflect the hierarchy of classes actually used within the application. Designing these extra classes \nand keeping them up to date was additional development overhead, and required developers to keep two \nlargely orthogonal hierarchies of classes in mind when only one was semantically important to the application. \nFinally, there is a surprising restriction in the use of SQL that limits text strings to 255 characters \nin insert statements; inserting longer strings requires use of bind variables in the Smalltalk interface \nto SQL. This was discovered after several design and implementation iterations of the RDBMS abstraction \nclasses and would have required yet another overhaul of these classes. 4.3 Hitting the Relational Wall \nThe problems noted in the previous section were painful and consumed time, but surmountable. While trying \nto work out how to support some additional features in PQMS, some additional, more difficult problems \nwere uncovered that led to the use of an ODBMS. In particular, there was a significant issue in storing \nordered collections of objects, while allowing flexible subclassing. Also, the lack of garbage collection \nsupport in the RDBMS was at odds with the garbage collection semantics of Smalltalk. This section will \nmotivate these problems. Of note is that the application only had one or two simple joins expressed in \nSQL; join complexity was not the real problem (join complexity is often a good reason to move to an ODBMS, \nhowever). The ordered collection problem involved storing audit records. An audit trail was to be kept \nfor each PQMS-instance object, including timestamps on when this PQMS-instance entered and left each \nnode, information about when PQMS-instances were forked and joined in Sub-Process nodes, timestamps when \neach user declared their work done at each node, annotations added by the application (e.g., comments), \nand assertions (e.g., this node must not be restarted over). The audit trail entries were each instances \nof concrete audit trail classes, with a common root superclass. The issues in storing this structure \nin an RDBMS included: how to represent a number of different subclasses, and how to store what is really \nan ordered collection of these records. Ideally, this sort of ordered collection would be abstracted \nand reusable, not just a special case for PQMS-instance objects. To deal with multiple kinds of audit \ntrail objects, the multiple subclasses might have been stored using a technique similar to how the graph \nnode classes were stored, to allow for extensibility (a table, mapping PQMS-instance identifier to collection \nof audit record tables, requiring multiple selects and reassembly to build the audit trail). Keeping \nthe ordered collection might involve storing an index with each audit record, and carefully maintaining \na maximum index for the PQMS-instance (requiring a table to keep the maximum index, storing a per record \nindex with each audit trail record, carefully reassembling these when reading the table, and storing \nthem carefully when writing new entries). Fortunately, the audit trail was append only, simplifying this \nsomewhat. The more difficult garbage collection problem involved the need to store a reference to a form \nclass at most nodes, and in particular storing a context object with the form (a form class is used to \nassociate a process execution-time data access form with a node). The context object allowed a common \nclass of form to be customized at the node. For example, some fields might be visible or not depending \non context and the role of the user. The form of the context object was to be completely arbitrary; i.e., \nthe process management part of PQMS had no knowledge of the form or structure of the object, but would \njust store it at the right place and at the right times. Since the forms could be complex, the context \nobject could also be complex in order to customize the form. The problem was deciding how and (more importantly) \nwhen to save and delete a given context object, without doing redundant saves to the database or leaving \ngarbage in the database (unused context object data). This is complicated by the semantics of editing \na process definition: until the user actually accepts the definition, the old definition must persist. \nIn Smalltalk, this is not an issue since assigning a new context object implicitly makes the old one \ngarbage (since it is no longer referenced) and the garbage collector will (eventually) collect the memory. \nHowever, when trying to store this relationally, since there is no garbage collection in the database, \nthe application must explicitly add support for this. An overkill solution would be to save all context \nobjects whenever the process definition was saved; however, this would redundantly save most of the context \nobjects (e.g., in nodes that hadn t been edited), leading to performance impact. Alternately, the application \nwould need to keep track of just what had been modified in the context object(s) and save as appropriate. \nEither case adds complexity to the application. Since context objects could have complex structure (e.g., \ndictionaries of dictionaries), for each kind of context object, additional schema design would be necessary \nand more complex code required to store and retrieve the objects properly. Given prior experience with \nthe difficulty in doing this for process graph and PQMS-instance objects, the above problems led the \nproject to seriously consider the use of an ODBMS. Every time a new application issue was considered, \nmuch too much time was being spent worrying about how to store this relationally.  4.4 Use of Object \nDatabase Management System Because of the problems outlined above, PQMS was rehosted to store process \nand PQMS-instance data in an ODBMS (corporate legacy data was still accessed from the RDBMS). After a \ncursory review of documentation, the conversion took approximately one half day, by someone not previously \nfamiliar with the ODBMS. This initial conversion required a handful of methods that sent markDirty messages \nat appropriate times (so the database software knows which objects are dirty and need to be updated). \nThis was a dramatic decrease in complexity from what it took to do the same in the RDBMS. This initial \nresult was encouraging. It was clear it would be much simpler to store the process components in the \nODBMS, allowing the project to concentrate on application design and implementation rather than the complexities \nof the persistent store. It was also clear that the harder problems with the RDBMS (e.g., audit trail \nand form context objects) were trivial to deal with. However, the initial port to the ODBMS missed a \nfew issues: a few markllirty s were missing or in the wrong place, and nothing was done about concurrency \ncontrol. Three new persistent collection classes were created: PersistentSet, PersistentOrderedCollection, \nand PersistentDictionary. These collections, subclasses of respective collection classes, overrode sufficient \nbehavior to add ma&#38;Dirty sends when appropriate. The application was restructured slightly to use \nthese collections where it was previously using Set, OrderedCollection, and Dictionary in PQMS process \nand instance objects (minor alterations to initialization methods). As a result, the persistence of PQMS \nprocess and instance data became transparent to most of the application. The ODBMS used in PQMS supports \ntwo forms of concurrency control: optimistic (by default), and pessimistic. Pessimistic concurrency control \nrequires the application to explicitly lock and unlock objects. Optimistic concurrency control keeps \ntrack of objects read and written by each transaction. When a transaction attempts to commit, a coordinating \nprocess checks this read/write set against that of other transactions committed since this transaction \nstarted, allowing the commit only if there is no conflict. Optimistic concurrency control is guaranteed \nsafe, but can be too restrictive (i.e., not allowing transactions to commit that really should be allowed). \nThis proved to be the case with PQMS: although PQMS would work safely with multiple users (something \nnever attempted with the RDBMS), it would not allow multiple users to be viewing and executing the same \nor different PQMS-instances in the same PQMS process. PQMS had problems with the default optimistic concurrency \ncontrol settings primarily due to read/write conflicts that really didn t matter. For example, a PQMS \nprocess object holds a dictionary of PQMS-instances (mapping a name to a PQMS- instance object). If one \nuser was executing a PQMS- instance in a process and another user either creating or destroying a PQMS-instance \nobject in that same process, there would be a conflict causing one of the transactions to fail (both \ntransactions read the PQMS- instance dictionary in the process, and one of them modified it). In this \ncase, the application wants both transactions to commit. This can be dealt with by altering the optimistic \nconcurrency control policy to ignore read/write conflicts, if this is known safe for the application. \nA more difficult issue with concurrency control occurs when multiple users are attempting to cause execution \nstate changes in the same PQMS-instance in a process. This must be allowed when it doesn t conflict, \nand handled transparently to the user. However, relaxing read/write conflict checking doesn t cover this \ncase, since this case involves a write/write conflict (both users will modify the PQMS-instance). The \nsolution was to raise a Smalltalk exception when a commit fails. The exception is handled by aborting \nthe current transaction (to refresh object state) and retry the operation the user attempted. Class methods \nto do this were added to keep the exception handling code in one place; the methods take an action block \nand a retry block, so they are quite general. These methods were used by user interface components when \nattempting to cause execution state changes. The result is that one of the users transactions will commit; \nthe others will transparently abort and retry, providing the new object state to the other users. Users \ndon t know the abort/retry has occurred. A related issue is visibility of newly created PQMS-instances \nin a process. There might be users who spend all their time executing PQMS-instances in one (or a few) \nPQMS processes. These users need to see new PQMS-instances when they are created. An additional capability \nwas added that causes a transaction abort and redisplay of the interface, which shows newly created PQMS-instances. \nPessimistic concurrency control is used in PQMS to prevent multiple users from making changes to a process \ngraph at the same time. When a process design view is opened, the process is first locked for write access. \nConcurrent users attempting to do the same will be informed the object is busy. To avoid modifying a \nprocess graph that has PQMS-instances in execution, PQMS adds state to the process object that declares \nthe process executable. Once set, the process many have PQMS-instances created in it to execute, but \nmay not be modified. The process may be copied, allowing for revisions of the process to be created. \n 4.5 What s Good About an Object Database The experience with PQMS suggests there are many attractive \nthings about the use of an ODBMS. For example, with appropriate supporting classes, a great deal of the \npersistence issue can be completely transparent to the application, resulting in much less code to implement \npersistence. As this is complex code for an RDBMS, this is a significant benefit. As noted earlier, to \nimplement a subset of PQMS persistent in an RDBMS required about 25% of the classes of the entire application. \nMoving this to an ODBMS reduced this to less than 10% of the classes (including reusable persistent collections \nand database session logon/off abstractions). Much of this reduction is due to the ODBMS data model matching \nthat of the Smalltalk language closely: there is no need to disassemble and reassemble objects. This \nreduction removed the (redundant) mirrored class hierarchy used to abstract relational tables. Further, \nthe ODBMS version of PQMS implemented multi-user concurrency control, which was not included in the original \nRDBMS implementation. In the ODBMS, since the data model matches that of the Smalltalk language closely, \nit implements the notion of identity. As such, there is no need to design and implement unique identifiers \nand caching of objects from the database (LazyDictionary and indirect fetching) to simulate identity, \nsince the database already does this. In other words, to use an RDBMS it was necessary to implement functions \nin the application that already exist in an ODBMS. Since the ODBMS supports the same garbage collection \nsemantics as that of the implementation language (Smalltalk), the application need not concern itself \nwith deletion semantics. This allowed form context objects to have arbitrary complexity without worrying \nabout relational schema to store them, and to completely ignore issue of deleting the objects since that \nwas handed by the database. Finally, abstractions such as the audit trail (an ordered collection of different \nobject types) which is trivially implemented in the ODBMS, needed considerable design and implementation \nin an RDBMS.  4.6 Problems with the Object Database Although the ODBMS used by PQMS alleviated most \nof the problems with the RDBMS, there were a few problems introduced. Probably the most difficult problem \nfor a new ODBMS user was getting the markDirty s right. In earlier revisions of PQMS, before the use \nof persistent collections, the authors understanding of commit, abort, and markDirty semantics in this \nparticular database was lacking. There were cases where aborting a transaction left some modified state \n(since not all the right objects had been marked dirty). When re-fetching objects from the database after \nthe abort, existing state could be used that should have been reread from the database (e.g., partially \nmodified execution state in PQMS-instance objects). This lead to strange bugs that cleared up after logging \nout and back in to the database (which cleared all state). When trying to understand these problems, \nit became clear a more formal abstraction (persistent collection classes) would not only solve the problem, \nbut make it much more transparent and far less error prone. Persistent collections should be provided \nby the database vendor, as many customers will likely have similar problems. Another aspect of the database \nthat was initially difficult to understand was the need to abort a transaction to see changes made by \nother users. In the case of PQMS, for example, it was difficult to see how a user viewing an execution \nview of a PQMS process would see new PQMS-instances when they were created, or how the view would stop \nshowing PQMS-instances that had completed execution. Once it was understood an abort was necessary, the \nsolution was reasonably clear (but, this also requires previously completed work to be committed first, \nor it will be lost). This problem is probably solved by experience, but additional documentation would \nhave helped. The default optimistic concurrency control provided by the database has the pleasant feature \nthat it s safe: with no forethought by application designers, the application will be concurrency safe. \nThis is not true for relational systems. However, the default optimistic concurrency control is in some \nsense too pessimistic for many applications. Read/write conflicts that don t matter to the application \ncan effectively make desired concurrent access semantics impossible. The application designer must become \nknowledgeable with the concurrency control semantics and accommodate them appropriately. In the case \nof PQMS, this involved relaxing the default conflict checking policy, and aborting and retrying transactions \ntransparently to the user. 5.0 Results To date we have achieved significant progress on all the stated \ngoals. Simple processes are now in production. The data access and presentation classes achieve the goals \nof reuse based on the context of process-activity and fully support the design goals. The designer may \nspecify display and control characteristics on an activity by activity basis thus reusing the form and \ncontrolling its behavior for each activity in which it is used (Figures 5 and 6). End- user designers \nare modifying form behavior, exercising this aspect of reuse among various activities using the same \nform. Process reuse is also fully supported through the sub-process node providing a high degree of modularity. \nThe goal of minimizing the impact of process change by cleanly segregating process from data access has \nbeen achieved. For the developer, correcting base-form defects has been simplified since global features \nlike RDBMS integrity constraints, default values, default field characteristics and button behavior are \nconsolidated in one form object. Since the base form-object is identical wherever used, the impact of \ncorrecting such defects is minimized. By contrast, it is the authors experience that RDBMS vendor-specific \ntools require varying degrees of form and integrity- constraint-code replication to achieve our results. \nThis replication increases the overall impact of defects as well as the opportunity for introducing new \ndefects during their resolution. The process graphing tools are fully functional. The classes are well \ndesigned for reuse and have been subclassed to add late-breaking features and extensions specific to \nthe system as a whole without impact on the base classes. These classes offer high potential for reuse \nand are not essentially limited to depicting the particular graph semantics used for this system. Access \nto RDBMS data is well supported. Developer overhead is required to map each relational table or view \nto corresponding classes for both access to data and for views on data, but work has progressed to the \npoint that about 80% of these classes and methods are now automatically generated. We do not expect more \nthan about a 90% solution based on code generation due to the particulars of implementing RDBMS data \nintegrity and related constraints and form specific controls such as pick- lists to fill in field values. \nClasses supporting these special functions comprise a reusable and growing set of tools for the developer. \nProcess analysis is supported through graph syntax checking and clear error dialogs. Execution views \nsupport process flow simulation and testing for the process designer. An audit trail of PQMS- instance \nmovement through a process is maintained, including time stamps on activity entry and exit, backtracking \nactivities (flow restart) and ad-hoc user comments. A PQMS-instance-flow audit trail provides information \nthat can also be translated into Pareto charts depicting the frequency of exceptional events, including \nactivities exceeding their expected duration or activities where restarts were initiated. PQMS-instance-flow \ndata for a single PQMS- instance is useful, but a historical view of multiple PQMS-instances broadens \nthe prospect of process- flow analysis and improvement. Generic Pareto-chart views are available to \nsupport such analysis but are not actively used in production today. Process change control is not fully \nimplemented, but capabilities exist to copy, cut, paste, export and import process graphs. These features \nare currently used to control change in a more manual manner than was originally planned. Storage of \nthe process model in a relational database was abandoned fairly early in the project when it became evident \nthat our complex process objects would be extremely difficult to manage under circumstances of concurrent \nprocess state change. This issue was elegantly and simply solved by changing the process store to an \nODBMS. Use of the ODBMS significantly simplifies the chore of making objects persistent when compared \nto the mapping and concurrency control required when using relational technology to achieve similar results. \nThis is also opening tempting possibilities for the migration of legacy data into the ODBMS environment. \n 5.1 Future Plans Having demonstrated major progress on all of the stated goals, we are anxiously proceeding. \nBeyond the work of maintaining and improving existing capabilities, several avenues for further exploration \nand implementation have arisen. The benefit of data-access-tool reuse is expected to expand as more of \nthese components are added to the CDAT. Overall we expect to enhance the system to provide more comprehensive \nquality metrics and capabilities for process improvement. We will turn on the Pareto graphing capacity \nalready in hand, applying it to a broad range of process design statistics (duration estimates, probabilities, \netc.) and PQMS-instance-flow history. We will also add enhanced simulation and historical replay capability \nso that a designer can compare and contrast process refinement options based on factual historical data. \nWe plan to extend the concept of CDAT tools into classes that support a variety of resources other than \nbasic data access forms. An early prototype spawned terminal windows on one of our database vendors forms, \nadding pull down menus to trigger vendor specific form functions. We envision encapsulating other point \nsolution products in CDAT. An area where design automation is needed is in Or-Emit nodes (decision nodes). \nAt the moment decisions may be made through a default manual- node-selection dialog, or as single-case \nautomated dialogs implemented by development staff. In practice, these decisions can often be derived \nfrom the state of the data and would therefore be more useful if their actions were specifiable by the \nprocess designer.   References 1. Gene Honbo, D. Appleton, LAB SESSION: Process and Data Modeling for \nEngineering/Manufacturing Information Systems (see also supplement Ford Assembly Models Discussion of \nDifferences ), Proceedings of the Eighth Annual Congress on CIM Databases: Controlling Data for Concurrent \nEngineering, April 26-28, 1992. 2. Box and Bisgaard, The Scientific Context of Quality Improvement , \nQuality Progress, June 1987. 3. Mary E.S. Loomis, Hitting the Relational Wall , Journal of Object Oriented \nProgramming, January 1994, Vol. 6 No. 8. 4. Wirfs-Brock, Wilkerson, Wiener, Designing Object Oriented \nSoftware, Prentice Hall, 1990, ISBN O-13-629825-7   \n\t\t\t", "proc_id": "191080", "abstract": "<p>This paper describes a new workflow model and its implementation in Smalltalk. The paper also details problems with using a RDBMS as the persistent store for the workflow tool and the subsequent experiences in using an ODBMS for this purpose. The final solution was a <italic>coexistence approach</italic>, using the RDBMS for legacy corporate data and the ODBMS for the process description and workflow status data.</p>", "authors": [{"name": "Bob Beck", "author_profile_id": "81100558195", "affiliation": "Sequent Computer Systems, Inc., 15450 SW Koll Parkway, Beaverton, Oregon", "person_id": "PP14193878", "email_address": "", "orcid_id": ""}, {"name": "Steve Hartley", "author_profile_id": "81502680371", "affiliation": "Sequent Computer Systems, Inc., 15450 SW Koll Parkway, Beaverton, Oregon", "person_id": "P269273", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/191080.191140", "year": "1994", "article_id": "191140", "conference": "OOPSLA", "title": "Persistent storage for a workflow tool implemented in Smalltalk", "url": "http://dl.acm.org/citation.cfm?id=191140"}