{"article_publication_date": "10-01-1994", "fulltext": "\n Experiences Building Large 00 Frameworks at BNR Gerard Meszaros and associates Bell-Northern Research \nLtd. Ottawa, Ontario, Canada E-mail: gerard@ bnr.ca Abstract This experience report describes the ex-perien \nces we have had at BNR building large Object Oriented frameworks to support telephony applications. It \nfocuses on a few key areas: How to determine what functionality a framework should provide. How to validate \nan architecture before it is built through architectural prototyping and continuous inte-gration . Other \nbenefits of using Object Technology on large projects. This report was based on four experience reports \nsubmitted to OOPSLA-94; the other authors were: Richard Wardle. Neil Thomson, Brent Sprinkle, Sky Matthews, \nMalgosia Plucinska, Todd Hansen, Dennis Leung, Paul Winterhalder, Marnie Beaubien, Ron Hough and Bill \nShanahan. Background About BNR and Northern Telecom Northern Telecom (NT) is a leading supplier of digital \ntelecommunication equipment. BNR is its Research and Development subsidiary. In this role, BNR develops \nthe hardware and software for most of NT s products, including the central office telephone exchange \nknown as DMS- 100. Telephone exchanges, also known as switches , are very large specialized embedded \nreal-time systems. The DMS:lOOF family of systems comprises eight products ranging from Local Access \ntelephone switch to Signal Transfer Point and consists of over 25 (twenty five) million lines of source \ncode written in Protel, an object-based Pascal-like language. About the Generic Service Framework (GSF) \nProject DMS-100 is a highly featured Local Access telephone switch delivered to North American and Global \nmarkets. Each market has specific requirements for a multitude of services (e.g. Call Waiting, 3-Way \nCalling). These requirements vary from market to market requiring extensive customization or parallel \nimplementations. The GSF project was launched to establish leadership in switching software archi-tecture \nto enable responsiveness to our customers requirements in global markets. The decision was made to design \nthe call processing software using Object Oriented technology (OOT) to enable faster delivery of the \nmany variations of services to global markets. We plan to have the bulk of the developers of DMS-100 \ntransitioned to OOT by the end of 1995; about one third have al- Portland, OR October 23-27,1994 ready \nmade the transition.   Discovering Framework Requirements The goal of the GSF project is to build an \nobject-oriented framework for call pro-cessing applications enabling faster de-livery of the many variations \nof services to global markets. The project involves a large number of teams developing generic framework(s) \nas well as developing a number of applications. Historically the call processing software has been developed \none application at a time, and the software reworked to meet the needs of each particular application \nas it came along. The primary drive for the GSF project was to create a flexible software architecture \ncapable of meeting current and future requirements of our customers. As the project was forming, a number \nof application teams expressed a strong interest in becoming the first customers of the framework. In \nthe spirit of our decision to use an object-oriented design process, we asked for requirements to be \ndelivered to us in the form of Use Cases. Our initial pass resulted in the creation of several hundred \nUse Cases, in part because groups new to OOT were attempting to do all their Use Case modelling before \nbuilding Domain or Analysis models. Problems encountered The task of requirements capture and analysis \nturned out to be difficult for the following reasons: Requirements were captured in a variety of formats \nand levels of detail -some were extremely detailed, others too abstract to be useful. There was a lot \nrepetition of the same capabilities described by different appli-cations. Also, in the telecommunications \ndomain, requirements are often derived from external specifications which can be inconsistent and ambiguous. \nMany of the requirements were provided to us in terms of design solutions based on the previous software \nimple- mentation. The sheer number of Use Cases received made the task of analysis impossible given \nlimited time and resources. Most of the requirements were written without a common vocabulary. This makes \nit difficult to communicate concepts between individuals and groups on a large project. For example, \nthe same concept may be referred to by different names even within the same requirement specification. \nInformation sharing and discovery of system wide commonality was extremely difficult due the lack of \nconsistency of the requirement specifications. It quickly became apparent that the way we were doing \nrequirements capture was not productive, and that our initial process would not work. A new approach \nhad to be put in place to better focus our efforts .  Strategy for success The strategy we finally adopted \nfor re-quirements gathering and analysis in-cluded the following steps: An initial object model was developed \nbefore the requirements were examined in great detail. The model was verified by testing it against known \nhigh-level requirements and applying it in various scenarios. This was made possible by drawing on extensive \nexperience of telecommunications domain experts. The scope of the initial requirements gathering was \nlimited to two applica-tions. This prevent the analysis paralysis that can be caused by too much information. \nTwo detailed scenarios were developed jointly with application primes therefore establishing a template \nfor future scenarios. This ensured a uniform level of understanding between the framework developers \nand application experts. Based on the provided scenarios, the re-quired system capabilities were derived \nand mapped onto the framework components as a set of framework capabilities. The request to provide the \nspecified framework capabilities was made to the owners of the particular component. The owners would \ndetermine how the requested capability was going to be provided internally by their design. The object \nmodels were refined to show the newly added framework capabilities.  Validating an Architecture through \nPrototyping On a large project (hundreds of devel-opers), the discovery of architectural problems after \ncoding can result in large amounts of rework. Just finding and in-forming all the affected developers \ncan take many weeks. This is probably one of the key causes of the software crisis. It is crucial that \nthe software integration occurs smoothly; this requires advance preparation during the architecture and \ndesign phases of the project. Initial Approach: Our first attempt at integrating the work of the various \nframework design teams was to have each team identify the services they needed from classes owned by \nother teams. These were captured in an N by N team interaction matrix (where N is the number of teams.) \nFor each identified interaction, the two teams were to meet and agree on an in-terface between their \nclasses. This agreement was to be documented and any changes to the agreed upon interface needed to be \ncommunicated to everyone involved in the agreement. Initial Results: This process seemed to work well \nfor the early part of the integration; during the dependency discovery phase, it seemed to be sufficient \nand appropriate in detail. During the fleshing out phase, however, some of it s weaknesses started to \nbecome apparent. The accuracy and completeness of the result was impossible to verify. How can one be \nsure that what s documented is current and sufficient? How can one tell that a dependency wasn t captured \nor docu-mented? In the longer term, it turned out to be too cumbersome and hard to manage. It required \ntoo much discipline to implement manually and was completely separate from the design work products. \nThe cost of keeping the agreements up to date as the design evolved was prohibitive, and the value of \ndoing it was insufficient to warrant the cost. Our conclusion was that this was a step in the right direction, \nbut it wasn t sufficient. Recipe for Success: The frustrations of dealing with tracking the team interactions \nlead us to create a prototyping team to pick up where the paper exercise left off. The first step after \nidentifying and agreeing upon the Portland, OR October 23-27, 1994 interfaces was to capture them in \na smalltalk prototype. This was done by the Prototyping Team on behalf of the supplier team. They would \nimplement at least a bare bones success path emulation of the agreed upon functionality. Next, the \nconsumer teams would start fleshing out the implementations of their classes including instantiation \nof (and method calls on the interfaces of) the supplier teams objects. The code could be tested by executing \nthe Use Cases, but usually just fleshing out the methods was enough to discover missing functionality, \neither missing Methods or missing Classes. As issues were found, interface changes were agreed upon and \nthe prototype was updated. It (the prototype) became the specification of the class interfaces. The Protel \nimplementation was based on these interfaces. The integration of the Protel modules was done in a similar, \niterative fashion (interfaces first, followed by users and then implementations fleshed out.)  Results: \nProblems with interfaces were found more quickly because people were writing code to use them. This essentially \ntested the interfaces for completeness (at least w.r.t. the use cases being tested.) This also resulted \nin a more iterative design approach by allowing the teams to get something in place quickly and then \nevolve it, rather than discussing things forever. The overhead of following the process was reduced and \nmore value was gained from it. People who best learn things by reading code were able to understand the \ndesign earlier. It also helped establish prototyping as an integral part of the design process. While \nteams were only required to prototype their dependencies, many teams extended their prototyping efforts \nto their detailed designs.  Benefits of Using Object Technology: The final section of this paper describes \nsome other ways one can take advantage of the object oriented nature of a project. How do you organize \nyour peo-ple? Initially, we chose to organize our teams based on clusters of related use cases. This \nallowed them to define classes without developing any attachment to them. Once the classes had been defined, \nwe switched to a class-based organization. For example, we had a Connections Team which owned all the \nframework classes related to making connections. This maximized the communication between closely coupled \nclasses while reinforcing the minimal coupling between different parts of our system. Organizing in this \nfashion did result in one problem: adding new functionality to the framework was difficult because it \nspanned many teams. This made it hard to determine whether new classes should be introduced or existing \nones extended. We solved this by creating joint design teams (JDTs) with representation from the application \nteams and the affected framework teams. These JDTs owned and analysed the new requirements (Use Cases) \nand proposed changes to the architecture. This approach made it easier to make necessary changes to the \nclass hierarchy and associations by avoiding the not in my class syndrome.  Continuous Integration: \nThe continuous integration previously discussed under the topic of Architecture Validation continues \nright into the final product integration and assembly. Just as the Prototyping was centered around specific \nUse Cases, the assembly of the Protel implmentation was based on sets of Use Cases. The development project \nwas divided into major iterations each defined in terms of a set of key Use Cases. The component development \nteams planned their own iterations based on the need to deliver functionality required to support the \nkey Use Cases. This ensured that all the pieces need to satisfy the Use Cases were developed at the same \ntime. As with the Prototype integration, the Protel interfaces were coded first to allow other teams \nto compile their client against the real interfaces. The success paths were filled in next, allowing \nclients to try out success path Use Cases. Finally, the error paths were coded and test. When the time \ncame to integrate all the software, there were very few surprises. The system integrated very quickly \nand smoothly. This allowed us to fullfil our first call milestone right on schedule. This would not have \nbeen possible with the traditional big bang approach.  Common Design Vocabulary: Another key benefit \nof using OOT was the use of common vocabulary to describe design before we had any code. Traditional \nprogramming terminology doesn t describe design separate from implementation. OOT has given us a starter \nset of basic terms, and Design Patterns as described in [GHJV94] has added another set of terms describing \ncommonly occuring designs. We have augmented this through a set of domain-specific design patterns describing \ncommonly encountered arrangements of objects in telephony services. We are in the process of evolving \nthis into a complete Pattern Language describing the methodology for transforming service specifications \ninto executable code. We expect this language to contain several hundred patterns when complete.  Conclusions: \nDesigning Frameworks is hard work but the payoff can be significant in saved effort and system consistency \nif YOU anticipate significant numbers of framework users. The development of frameworks needs to be \ndone iteratively; choose incremental chunks of functionality as the basis of your iterations. Continuous \nIntegration is crucial to suc-cessful integration of applications and your framework. Architectural proto-typing \nis a key part of this. In making the transition to 00, cultural change is a significant obstacle. Learning \nto communicate requirements in terms of problems rather than solutions is key to application and framework \nteam harmony. The high cohesion and low coupling of objects can be used to one s advantage in organizing \nthe people as well as the software but care needs to be exercised to ensure that the organization mimics \nthe architecture rather than vice versa.  References [GHJV94] Design Patterns: Elements of Reusable \nObject-Oriented Software. Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides published by Addison-Wesley. \nISBN o-201-63361-2. Portland, OR October 23-27,1994 \n\t\t\t", "proc_id": "260028", "abstract": "", "authors": [{"name": "Gerard Meszaros", "author_profile_id": "81100335374", "affiliation": "Bell-Northern Research Ltd., Ottawa, Ontario, Canada", "person_id": "PP31086675", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/260028.260085", "year": "1994", "article_id": "260085", "conference": "OOPSLA", "title": "Experiences building large OO frameworks at BNR", "url": "http://dl.acm.org/citation.cfm?id=260085"}