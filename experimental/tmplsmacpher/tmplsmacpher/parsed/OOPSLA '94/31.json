{"article_publication_date": "10-01-1994", "fulltext": "\n Experience with Representing C++ Program Information in an Object-Oriented Database Tamiya Onodera IBM \nReseamh, Tokyo Research Laboratory 1623-14, Shimo-tsuruma, Yamato-shi, Kanagawa-ken 2@ Japan Abstract \nTwo major issues related to storing program in-formation in an OODB are sharing and cluster-ing. The \nformer is important since it prevents the database from consuming excessive disk space, while the latter \nis crucial, since it keeps clients running without thrashing. In our database, ob-jects are shared across \nmultiple programs trans-lation units, and are clustered by combining three techniques, namely, birth-order, \ndeath-order, and sharing-oriented clusterings. An initial experi-ment shows that, for a medium-size application, \nthe database consumes 3.5 times less disk space than in a conventional environment, and that the invocation \nof a client is almost instantaneous. 1 Introduction The growing size and complexity of software has intensified \nthe need for advanced programming environments that can reduce the burden on soft-ware developers. Such \nan environment should in-tegrate tools, including a compiler, a debugger, a source-code browser, and \na builder. Tool integra- tion, in this narrow context of lower CASE, means integration of presentation, \ncontrol, and data [l]. To build such an integrated environment, it is be- lieved, the correct strategy \nis to use a database management system. Permission to copy without fee all or part of this material is \ngranted provided ?hat the copies are not made or distributed for direct commercial advantage, the ACM \ncopyright notice and the title of the publication and its date appear, and notice is given fhat copying \nis by permission of the Association of Computing Machinery. To copy otherwise, or to republish, requires \na fee and/or specific permission. OOPSIA 94- 1 O/94 Portland, Ore on USA Q 1994 O-89791 -688-3194 0010..$3.50 \nACM 7 Our attempt to represent C++ program infor-mation by using an object-oriented database fol-lows \nthese lines, but at the same time we have aimed to alleviate two serious and pervasive prob-lems in the \ndevelopment of programs: bloated working storage and stalled invocation. In the first, a tremendously \nlarge amount of disk space is used to store information for tools, and in the second, an intolerably \nlong time is spent before a tool is ready to accept user interaction. As an example, we present statistics \non a Motif application that is being developed at our labora tory by using IBM C Set ++ for AIX/6000. \nThe numbers given below were all obtained under AIX 3.2.4 on a RISC System/6000 Model 560. When compiled \nand linked without any specific option-s, the library, which consists of 300 source files and contains \na total of 15,541 lines, consumes 3.03 megabytes of disk space, including source files, ob- ject files, \nand an executable. To use a debugger, we must build the executable with the debugger option specified. \nThis requires 16.86 megabytes more disk space. When we invoked the dbx de-bugger against the executable, \nit took 479 seconds of real time for the debugger process to show its first prompt. To allow use of a \nbrowser, we must build the executable with the browser option spec-ified. This, surprisingly, requires \n76.92 megabytes more disk space. Moreover, the system configu-ration did not allow us to use the source \ncode browser; the initialization of the browser process failed, because of the heavy demand on paging \nspace. The reason for bloated working storage is as fol- lows. The use of a library in a C/C++ program \nresults in one or more header files being included, and the inclusion of a header file contributes to \nincreased consumption of disk space; information on types defined in the header file is generated if \nthe program is compiled with the debugger op-tion, while information on cross-references that originate \nin the header file is produced if the pro-gram is compiled with the browser option. When a header file \nis included in many source files, the same number of duplicates result, and are sim-ply left to occupy \ndisk space. What really ag-gravates the duplication is that modern software tends to or is encouraged \nto rely on more and more libraries, some of which are very large. For instance, the source file in the \nMotif application contains only 51.8 lines on average. However, af- ter the file has been preprocessed, \nthe average number of lines rises to as many as 9,153, since all the source files but one include Xm.h \ndirectly or indirectly. On the other hand, the reason for stalling invocation is simply that the dbx \ndebug ger and the source code browser eagerly attempt to initialize a large number of objects before \nthey accept user interaction. We can amend bloated working storage by enhancing the compiler to allow \nit to populate a database with objects, sharing as many objects as possible. When the compiler is about \nto store an object in a database, it first checks whether the database already contains any equivalent \nob-ject and, if not, adds it to the database. On the other hand, we can solve stalled invocation by somehow \nrealizing lazy evaluation. For instance, it may be promising to use memory mapping fa-cilities if they \nare available; actually, there is a debugger that does not suffer from the problem. However, a much simpler \nand cleaner way of re-alizing lazy evaluation is to rely on a DBMS that allows objects to be fetched \non demand from the persistent storage. Fortunately, the OODBMS used in our project, ObjectStore, is known \nfor its notable use of virtual memory mapping architec-ture [2, 31; when a client accesses a database \nob-ject for the first time, the OODBMS brings the entire page containing the object into the client s \nvirtual memory. The following sections are organized as fol-lows. Section 2 overviews C++ program databas-es. \nSection 3 describes how and what objects are shared, primarily to solve bloated working stor-age. Section \n4 is on clustering, which is crucial to the database performance, even if objects are fetched on demand. \nSection 5 gives initial perfor-mance measurements, while Section 6 deals with related work. Finally, \nSection 7 presents our con-clusions and discusses future work. 2 C++ Program Database The program database \nwe are attempting to build stores static information on C++ programs. This includes build relationships \nof programs and cross-references of symbols appearing in program- s. An important feature is that a single \ndatabase holds information on multiple programs. This is essential to eliminate the problem of bloated \nworking storage; if we built a database for each program, it would prevent information originating in \nXm. h from being shared among different Motif applications. 2.1 Basic Structure Static information on \nC + + programs is represent- ed as graphs of objects, which are grouped into four categories: files, \ncross-references (abbreviat-ed below as xrefs), symbols, and types. A file ob- ject is constructed for \neach of the operating sys-tem s files that have participated in building C-t + programs. File objects \nform graphs to represent build dependency, or relationships showing which files are linked into which \nfile and which file in-cludes which files. A primary ingredient of the program database is an zrefgraph, \nnamely an xref object pointing to a symbol object that may point to a type graph; the symbol points to \na type graph only if it has a type. This xref graph denotes which symbol op-tionally having which type \nis defined or declared or used in which location; logically, the location is a triple of file object \n, line number, and column number, but physically, it is squeezed into a pair, // a.C int x; class A ( \nchar x; unsigned y; 1; double foo(float a)< return x+a; I Figure 1: A Sample Program to Show the Basic \nStructure of the Program Database as we will see in Section 3. These xref graphs are then organized according \nto the block structure of a C++ program. Consider the following source file as an exam-ple. Its compilation \nresults in the population of objects shown in Figure 2. The block structure of the translation unit is \nrepresented as a graph formed by three objects: a file object correspond-ing to a. o, an xref object \ncorresponding to the class definition, and an xref object correspond-ing to the function definition. \nEach of these has a pointer member to an array of the pointers to the xref graphs. All the xrefs of the \ntranslation unit, including those for the class and function definitions, are organized into the arrays. \nNote that not alI the objects are shown in the fig-ure; the database is also populated with special cross-references, \nwhich are introduced below. Not all the pointers are drawn in the figure, either; backward pointers, \nwhich ahow fast climbing-up traversal, are also present.  2.2 Intended Clients The intended tools are \ninitially a debugger, a source-code browser, a builder, which is similar to the make utility, and a profiler. \nActually, the information we stored in a database reflects this. First, the database stores code-static \ninformation as used by a debugger. Symbol objects have mem-bers for relative addresses, offsets within \nstack frames, or offsets within data layouts of classes. Special xrefs are provided for storing information \non breakpoints. Second, the database does not Since an xref essentially carries information on its lo- \ncation, this scheme can accommodate breakpoints at inter- vals with a finer granularity than lines. contain \nparse trees, such as those generated by a compiler s front-end, since it is not intended for code generation \nand program transformation. Note, however, that enough information is stored for incremental compilation \nor program slicing. Finally, although the database contains sufficient information to instrument code \nfor execution pro-filing, it is not supposed to contain the results of profiling per se. This does not \nnecessarily exclude the population of such profiling results; we believe that static and dynamic program \ninformation can be separate islands in a database, and this paper simply focuses on the population of \nstatic infor- mation. The only intended populator is a compiler. To facilitate turning a conventional \ncompiler into a populating compiler, we define a population inter-face, or a collection of methods encapsulated \ninto a class. Following the definition of the interface, calls to the methods are inserted at appropriate \nlocations in an existing compiler s source code. Linked with an implementation of the interface class, \nit is made a populating compiler.  3 Sharing One purpose of sharing is to alleviate the prob-lem of \nbloated working space, and xrefs from commonly included header files must be shared. Sharing xrefs implies \nsharing symbols pointed to by them. Putting it another way, sharing symbols is considered to facilitate \nthe sharing of xrefs. Ob-viously, sharing symbols can and should be based on the C++ semantics of linkage. \nHowever, s-toring multiple programs information in a single database presents a significant challenge \nto this, as we will discuss. 3.1 Objects Shared The entities that can be shared among translation units \nin our program database are global symbols, global types, and global zrefs. A symbol is said to be global \nif it is not a member or local. For a glob- al symbol to be shared, it must represent what is common \nacross translation units. For compari-son, assume that the data structure of a function Figure 2: Basic \nStructure of the Program Database: only the relevant values are shown within the objects. 0 meobjeas \n0 xrcfobjects [7 symbolobjects 0 typcdd-  symbol is defined to have a member that points to a graph \nrepresenting its definition. This is of- ten the case in internal data structures of a con-ventional \ncompiler, since at most one definition is legally given to a function symbol in a translation unit. However, \nthis is no longer allowed in our database setting, and thus the function symbol shown in Figure 2 results. \nAn alternative would be to have a function symbol s member point not to a definition but to a list of \ndefinitions. Howev-er, doing so might slightly degrade performance, since inserting a new definition \nresults in the up-dating of an existing object , such as a list node; in general, modifying existing \nobjects is more costly than simply constructing new objects. A type is said to be global if it is not \nlocally de-fined or a derived type constructed from a locally defined type. We attempt to share derived \ntypes as well as fundamental types. Thus, only a sin-gle representation exists in a database for each \nof int, char*, double (float), int (*n)(int, char*), and so forth. An xref is said to be global if it \noccurs with file scope. Xrefs are our primary targets for shar- ing, since this eliminates duplicated \nobjects due to commonly included header files. Though the preprocessor s conditional commands might cause \n the compiler to attempt to store different sets of objects for different inclusions of a header file, \non-ly objects corresponding to the delta are added. Note, however, that the granularity of sharing is \na global xref; when a conditional compilation e-liminates the text of a declaration of a member, the \nxref graph representing the definition of the member s class is newly stored in its entirety. The compilations \nof two translation units in Figure 3 populate a database with objects, as in Figure 4. We assume that \na. o and b. o are com-piled in this order. 3.2 Computing the Hash Values of Graphs Whenever the compiler \nis about to add an objec-t, it looks for any structurally equivalent objec- t. Obviously, the database \nmaintains hash tables // a.h class A ( char x; unsigned J; 3; // a.C extern int x ; #include a .h\" double \nfoo(float); // b.C extexn int x; #include a. h double hoo(float); Figure 3: A Sample Program to Show \nObject Sharing for these lookups. Precisely, the population of an object involves the following steps. \nThe compil-er first constructs an object in the transient heap. For each of the candidate persistent \nobjects in the hash table, the compiler performs the structural equivalence test. If this succeeds for \nsome can-didate, the compiler subsequently uses the per-sistent object and discards the transient object. \nOtherwise, it makes a persistent copy of the tran-sient object, inserts it into the hash table, and discards \nthe transient object. It might be interesting to compute a hash val-ue for a graph. To facilitate this, \nthe compiler maintains an invariant specifying that, when it attempts to store an object, only the root \nof that object is transient and its siblings or subgraphs have already been made persistent, or stored \ninto a database. The hash value of a graph is comput- ed by using one or more values of fundamental types \nin the root object and one or more direct siblings persistent addresses.2 The computation is very fast, \nsince it does not involve traversal of the graph, but it still effectively takes into account all the \nobjects contained in the entire graph. 2The persistent address of an object within a database is a pair \nof segment identifier and offset in ObjectStore. Since these values are stored in the protected members \nof a class ObjectStore supplies, we need a hacking method for deriving a class to breach the access control. \n 3.3 Overlinking The object files resulting from the compilation of two translation units, shown in \nFigure 4, are not necessarily linked into the same program. If they are not, the symbol object for int \nx actual- ly represents two different symbolic entities; this is inevitable, since it is not necessarily \nknown in advance which executable a particular object file is eventually linked into, especially if it \nis a mem- ber of an archive. Similarly, even within a single program a single symbol for a class may \nbe used to represent different C++ classic entities of the same name, since they may have internal linkages. \nIn short, ouerla nlca ng occurs. Overlinking is much easier to cope with than underlinking. For this \npurpose, the coverage of an object is defined to be a subset of database objects that can be reached \nfrom the object by tracing pointers. Though a symbol object does not necessarily uniquely identify a \nC+ + symbolic entity, it really does if paired with an appropriate coverage. For instance, a pair of \nthe symbol de-noting int x and the coverage of the file object into which the file a. o is linked uniquely \nidentifies the symbolic entity declared in a.c. This pairing effectively means that a database client \nlimits it-s interest to the specified coverage when dealing with queries.  4 Clustering Clustetings \nis a technique of populating together objects that are referenced together, thereby im-proving reference \nlocality. The client of a poorly clustered database is very likely to cause thrash-ing, which effectively \nprevents it from running any further. Reference locality, however, totally de-pends on clients access \npatterns. In particular, burst access made by clients is of great concern. Obviously, we cannot list \nall the clients in ad- 30bjectStore allows two levels of clustering, by what are called segments and \nobject clusters. What we have used for clustering the program database are segments. However, in this \npaper we consistently use the term clus-ter, which means a segment in ObjectStore terminology. Figure \n4: Sharing of Objects Vance, and access patterns of clients may impose conflicting demands on clustering. \nWhat we can do at best is to prepare for major, known clients. This section first considers burst access \nthat ex-pected clients are likely to make. It then sum-marizes three methods of clustering applicable \nto our program database, and describes the cluster-ing actually used. Finally, it presents further ef-fects \nof the clustering, one of which contributes to a substantial reduction in the size of a database. 4.1 \nBurst Access Expected clients that heavily access a program database are a compiler, a scavenger, a source-code \nbrowser, and a debugger. Though a compiler is primarily considered as a populator, it is also a heavy \naccessor; it does a large number of lookups for sharing, which is likely to cause burst access. A scavenger \nis a tool for reclaiming database objects that are no longer referenced; this tool is needed because \nObjectStore leaves it up to user-s to garbage-collect database objects. Since the C-t-t convention is \nto call the delete operator for each unused object, burst access is likely to result. between Translation \nUnits A browser does not madly access a database as long as it is processing such requests as show members \nof a class and show all the break-pointable locations of a function. However, burst access may happen \nwhen it attempts to show the entire inheritance graph, the entire call graph, all the cross-references \nof a symbol, or all the func-tions and global variables defined in a program. A debuggei is also a modest \nclient as long as it handles such requests as set a breakpoint here and print an automatic variable \ns value. Burst access may result for a request such as show the call stack s contents for a long stack \nand Ushow all the values of global variables. Our observation is that coping with burst ac- cess by \na compiler and a scavenger should have top priority. The reason is that both lookups and deletes may \ntouch pages in the persistent storage scattered in the database-wide, while access by a browser or a \ndebugger is limited to pages that contain objects representing a program. 4.2 Methods for Clustering \nThree methods of clustering are considered promising for CT++ program databases. First, birth-order clustering \nsimply stores objects in the order in which they are created. Since a popula-tor can easily follow this \norder, it is used wide-ly, even unconsciously. Not surprisingly, it can be observed that the birth order \nis respected by many access patterns; objects are never created in a random order, and the order reflects \nthe logical structure of a program. Death-order clustering stores together object-s that die more or \nless at the same time. This method of clustering is very beneficial for a s-cavenger or, more generally, \nin terms of memo-ry management, although we cannot always know the death times of objects. Furthermore, \nif a database management system allows us to delete a cluster, we can delete a bunch of database ob-jects \nat the cost of a single function call, as is often done in implementing a customized memo-ry management \nsystem for C and C++. Finally, sharing-oriented clustering stores to-gether objects that are shared among \ntranslation units, in order to prepare for lookup operations. As mentioned earlier, what are shared in \na pro-gram database are global objects. If we simply fol-low the birth-order clustering, lookups may \ncause thrashing, since the method interleaves global ob-jects with objects from inner blocks. In short, \nwhere there is sharing, there must be clustering. 4.3 Our Clustering Objects are clustered in a C++ program \ndatabase, as shown in Figure 5. First, we apply sharing-oriented clustering, following the prioriti-zation \nmentioned earlier. Global symbols are clus-tered together with the hash table, as are global types. As \ncan be seen in the figure, objects that orig-inate in the same file form a cluster, or what we call a \nfire cluster. This file-based clustering is a combination of sharing-oriented and death-order clusterings. \nIt is sharing-oriented because it clus-ters globals xrefs, which come from the same file, together with \nthe hash table. It is not accept-able to put all the global xrefs into a single clus-ter, since the cluster \nwould grow gigantic; divid-ing them among files prevents this. On the oth-er hand, file-based clustering \nis also a death-order clustering, since objects from the same file tend to become unused simultaneously; \nthis demographic fact reflects the current way of developing a C++ program, namely, on a file basis. \nTo add an object to a file cluster, the compiler must first look for the cluster corresponding to the \noperating system s file in which the object origi-nates. It does so by using not only the file s name \nbut also the file s timestamp. In this way, a file cluster is created for each version of an operating \nsystem s file. Finally, birth-order clustering is applied with-in each cluster, and file objects form \ntheir own cluster.  4.4 Further Effects File-based clustering also helps to reduce the size of a database. \nIt allows us to squeeze the location of an xref object into a pair, instead of a triple of the source \nfile, linenumber, and column num-ber, by cluster-tagging,which is very similar to the page-tagging used \nin many Lisp interpreters. Given a virtual address of an xref, ObjectStore al-lows us to obtain the persistent \naddress. In other words, we can find out which cluster (or segment in ObjectStore terminology) the xref \nis allocat-ed to. If we build a table that maps clusters to files, we can eventually obtain the file \nin which the xref originates. The source file of an xref s loca-tion thus becomes a computable attribute. \nNotice that xref objects are by far the most dominant objects in a program database; squeezing a word \nfrom an xref leads to a substantial reduction in the database size. Finally, we touch on the garbage \ncollection of database objects. Owing to death-order clus-tering, individual objects do not have to be \ndeleted; we simply delete a cluster. File clus-ters themselves are maintained by applying the reference-counting \ntechnique; we believe that ref-erence counting on the granularity of clusters is quite acceptable. The \nclusters for shared sym-bols and types are never reclaimed by using ref-erence counting. However, shared \nobjects with-in the clusters are garbage-collected by using the ah share4l xrefs the hash table xrefs \nsymbols types IC  Figure 5: Clustering in the C-+-t Program Database mark-and-sweep technique, which \nis much less fre- quently invoked. Note that the abovementioned arrangement of a file cluster for a version \nallows the reference count to be zero soon enough; if a file cluster contained objects from all the versions \nof an operating system s file, the reference count could not reach zero. However, it would be rather \nexpensive to create a cluster each time a source file is modified and compiled; a good trade-off is to \nlet a file cluster hold program information across a few versions of a source file.  Performance Measurements \n We have implemented three important compo-nents, and built two clients with them. The first component, \ncalled pd, defines the scheme of the C++ program database, and must be linked into every client. It is \nalso responsible for sharing and clustering, though such functions are only used by a populator. Another \ncomponent, dop, defines the population methods mentioned in Section 2. We have built a populating version \nof the C++ compiler with dop and pd. Lastly, the pq compo-nent implements basic queries on top of pd; \namong them are collective queries such as show all the classes and navigational queries such as find \nthe definition of a function. We have built a simple source code browser with pq and pd. The pd, dop, \nand pq components are all written in C++, using ObjectStore Release 2.0, and contain 9053, 8575, and \n1808 lines, respectively. We have run two clients against three programs: these are a Lisp interpreter; \na simple X applica- tion, which bounces balls in a window; and a GUI library, which is used for building \nGUI on Motif. The applicatien mentioned in Section 1 was built by using the library. Table 1 summarizes \nthe char-acteristics of these programs. We have performed measurements under AIX 3.2.4 on a RISC Sys-tem/6000 \nModel 560 with 384 megabytes of main memory. We set the size of the client cache at 8 megabytes, which \nis one of the parameters for the client environment in ObjectStore. 5.1 Database Sizes We first compiled \nthese programs using the pop-ulating compiler, and built a database for each program; it is worth emphasizing \nthat we were successful in populating a database even for the GUI library. The last column of Table 1 \nshows the sizes of the resulting databases. The levels of disk consumption are very much lower than in \na conventional approach. Taking the GUI library as an example, the additional disk space needed to do \nbrowsing and debugging is 68.47 megabytes in the conventional system in Section 1, while the size of \nthe database covering such information is much smaller, as shown in the table. Program Number of Translation \nUnits Before Total Number Preprocessing Average of Lines After Preprocessing Total Average Size of Database \n(kilobytes) Interpreter Bouncing Ball GUI Library 3 46 294 673 4,018 15,071 224.3 87.3 51.3 4,695 361,924 \n2,686,647 1,565 7,868 9,138 761 5,881 32,498 Table 1: Characteristics of Measured Programs and Database \nSizes Though we constructed a database for each pro-gram in this measurement, our database can ac-commodate \ninformation on multiple programs, as mentioned earlier. This turns out to be a cru-cial advantage when, \nfor instance, we are using the library to build multiple applications simulta-neously; otherwise, we \nwould have to create as many databases containing at least about 32.5 megabytes of objects as the number \nof the ap- plications.  5.2 Browsing Times Next, we invoked the simple browser against the above databases, \nand issued typical collective queries. The invocations were instantaneous, and it did not take long to \nretrieve necessary informa-tion from the databases. Table 2 lists the result in detail. It shows the \namounts of time taken to retrieve objects necessary for building inheri-tance graphs and call graphs; \nthe amounts of time measured do not include those spent on actually drawing graphs. We have measured \nthem both in cold and warm ways. Since the times are proportional to the numbers of objects to be re-trieved, \nthe table also shows the numbers of nodes and arcs in the graphs. In the measurements, we prepared the \ndatabas-es for these queries by building appropriate tables; this is a common tactic in database application- \ns. Had we not done so, we would have had to traverse the entire database. In general, the time needed \nto traverse a database gives a good indi-cation of the performance in processing a query for which the \ndatabase is not prepared. The table therefore includes the amounts of time needed for hot and cold traversals, \nalong with the numbers of objects to be visited. Notice that the database size for the GUI li-brary exceeds \nthe cache size we set in the mea-surements; we suspect that this caused the times to increase irregularly \nfor the GUI library.  5.3 Discussion Though we found that our approach is promis-ing in terms of disk \nconsumption and client invo-cation, a severe problem, is the large amount of extra compilation time, \nthat is, the time needed to construct a database. The populating compiler currently takes 4 to 5 times \nlonger on average than the original compiler does when invoked with the debugger and browser options \nturned on. This is not due to database operations such as trans-actions and persistent allocations; the \nunderlying database per se performs well enough as long as we create an appropriate clustering. At any \nrate, we are now working to resolve this problem. In addition, we are not necessarily satisfied with \nthe current sizes of program databases. Actually, more space can be squeezed. In many OODBMSs, including \nObjectStore, objects are stored in per-sistent storage in almost the same formats as in virtual memory; \nthey are still objects in persistent storage. However, objects are not a compact way of representing \ninformation. For instance, the x-coff format encodes the pointer type to the integer type as *-1, taking \na mere three bytes, while the corresponding type graph in our scheme consist-s of two type objects, taking \na total of 16 bytes. Database Inheritance Graph I Call Graph Entire Traversal Time set Size 1 Time (set) \nSize Time set #Objects Cold Warm #Nodes Cold Warm #Nodes Cold Warm Visited + + WI #Arcs #Arcs Interpreter \n0.0983 0.00773 105+41 11 0.100 0.0339 501+451 0.0310 0.0107 10.1 Bouncing Ball 1.39 0.0211 293+38 110.820 \n0.146 2,001+1,193 4.10 0.483 463 GUI Library 4.68 0.0613 517+165 1 13.5 0.749 7,600+6.988 51.4 37.8 3,492 \n Table 2: Performance of Browser s Typical Queries Even the compress command in AIX attains 49% to 63% \nreductions for the databases in Table 1. More reduction can definitely be expected if we extensively \nuse type information, which is also s-tored in the databases. Obviously, we should per-form compression \npage-wise, thereby allowing on-demand compression. We are now designing the details of this procedure, \nwhich we call type-dtiuen compression.  Related Work It is well known that the C++ programming environment \nformerly named Cadillac [4] stores C++ program information in an object-oriented database. It too uses \nObjectStore. However, as far as we know, no paper describes the database organization in enough detail \nfor us to compare it with our work. CIA++ [5] is a tool that stores a C++ pro-gram information in a database. \nThe information covered is largely the same as in our scheme, but does not include code-static information. \nIn ad- dition, the database is relational. We are curious to learn how sharing and clustering are dealt \nwith in relational setting. Reprise [6] is a graph representation of C++ programs. It represents source-static \ninformation in much more detail than our scheme, but does not give any code-static information. Though \nthe paper describes how such representations are gen-erated, it does not say how or where they are s-tored. \nKendall and Allin [7] discuss how the size of a program database can be reduced. They propose eliding \nunused declarations and combining objects among translation units, which can be performed in two ways, \nby sharing and by linking. They also present detailed measurements of the degree of effectiveness of \nthese methods in reducing the database size. One difference from our work is that their database is main-memory \nand contains only a single program. Databases accommodating multiple programs are very different and \nrequire the notion of overlinking. Another difference is that they attempt to reduce the database size \nby varying the requirements imposed on the program database; that is why elision becomes applicable, \nalthough the resulting database is not suitable for source code browsing. Our requirement is that the \nprogram database must be used for the browser, debugger, and builder. 7 Concluding Remarks We have described \nhow objects are shared and clustered in an object-oriented C++ program database. Sharing is important \nto prevent a program database from occupying too much sec-ondary storage. Our initial experiment showed \nthat the database occupies much less space than is required in a conventional file-based environ-ment \n. Clustering is crucial to keep clients running without thrashing. Though we have prepared for major \nexpected clients, we have already found a client that has a conflicting demand on clustering. An instance \ntmnsformer, which supports schema evolution, turns instances of updated classes into new versions, accessing \nall the instances of each class. The best clustering for this is a class-based clustering, which allocates \ninstances of a class to-gether. However, it obviously conflicts with the sharing-oriented and death-order \nclustering. Dy-namic reorganization of a database might be pur- sued in this case. As we have seen, \npopulating objects involves linking symbolic entities. We expect to be able to completely eliminate the \nphase of batch linking in the not-sodistant future; this will considerably accelerate the development \ncycle. In addition, it is believed that C++ program databases can au-tomate a complicated process of \ntemplate instan-tiations [8]. We believe that the evolution from separate compilation to populating compilation \nwill have a significant impact on C++ program development.  Acknowledgments We thank the members of \nthe Compiler Tool-s Group at IBM Canada s Language Technology Centre and of the Programming Languages \nGroup at IBM Japan s Tokyo Research Laboratory for their detailed discussions, which very much im-proved \nthis work. Ed Merks and Kazu Yasuda defined the population interface, and Shoichi Ni-nomiya implemented \nthe dop component. Trademarks ObjectStore is a trademark of Object Design, In- c. AIX, RISC System/6000, \nand C Set ++ are trademarks of IBM. References [l] Thomas, I. and B. A. Nejmeh. Definitions of Tool \nIntegration for Environments. IEEE Software 9(2), 29-35 (1992). [2] Lamb, C. et al. The ObjectStore Database \nSystem. Communications of the ACM 34(10), 50-63 (1991). [3] ObjectStore User Guide, Object Design, Inc., \n1992. [4] Gabriel, R. P. et al. Foundation for a C-t-l-Programming Environment. Pvxeedings of C++ At \nWork 1990, pp. 85-102. [5] Grass, J. E. and Y. Chen. The C++ Infor-mation Abstractor. Proceedings of \nthe 1990 USENIX C++ Conference 1990, pp. 265- 277. [6] Rosenblum, D. S. and A. L. Wolf. Represent-ing \nSemantically Analyzed C++ Code with Reprise. Proceedings of the 1991 USENIX C++ Conference 1991, pp. \n119-134. [7] Kendall, S. C. and G. Allin. Sharing Between Translation Units in C++ Program Databas-es. \nProceedings of the 1994 USENIX C++ Conference 1994, pp. 247-263. [8] McCluskey, G. Template Instantiation \nFor C++. ACM SIGPLAN Notices 37(12), 47-56 (1992). \n\t\t\t", "proc_id": "191080", "abstract": "<p>Two major issues related to storing program information in an OODB are sharing and clustering. The former is important since it prevents the database from consuming excessive disk space, while the latter is crucial, since it keeps clients running without thrashing. In our database, objects are shared across multiple programs' translation units, and are clustered by combining three techniques, namely, birth-order, death-order, and sharing-oriented clusterings. An initial experiment shows that, for a medium-size application, the database consumes 3.5 times less disk space than in a conventional environment, and that the invocation of a client is almost instantaneous.</p>", "authors": [{"name": "Tamiya Onodera", "author_profile_id": "81100474003", "affiliation": "IBM Research, Tokyo Research Laboratory, 1623-14, Shimo-tsuruma, Yamato-shi, Kanagawa-ken 242 Japan", "person_id": "PP31089269", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/191080.191146", "year": "1994", "article_id": "191146", "conference": "OOPSLA", "title": "Experience with representing C++ program information in an object-oriented database", "url": "http://dl.acm.org/citation.cfm?id=191146"}