{"article_publication_date": "06-01-1993", "fulltext": "\n Load/Store Range Analysis for Global Register Allocation* Priyadarshan Koltetand Mary Jean Harrold Department \nof Computer Science Clemson University Clemson, SC 29634-1906 harrold@cs.clemson. edu Abstract Live range \nsplitting techniques improve global register allocation by splitting the live ranges of vari\u00adables into \nsegments that are individually allocated reg\u00adisters. Load/store range analysis is a new technique for \nlive range splitting that is based on reaching def\u00adinition and live variable analyses. Our analysis local\u00adizes \nthe profits and the register requirements of every access to every variable to provide a fine granular\u00adityy \nof candidates for register allocation. Experiments on a suite of C and FORTRAN benchmark programs show \nthat a graph coloring register allocator operating on load/store ranges often provides better allocations \nthan the same allocator operating on live ranges. Ex\u00adperimental results also show that the computational \ncost of using load/store ranges for register allocation is moderately more than the cost of using live \nranges . 1 Introduction Register allocation maps variables in an inter\u00admediate language program to either \nregisters or mem\u00adory locations in order to minimize the number of ac\u00adcesses to memory during program \nexecution. Due to the significant difference between access times of reg\u00adisters and memory, a good register \nallocation scheme *This work was partially supported by NSF under grant CCR-910953I to Clemson University. \nt Cm-rent address: Department of CS&#38;E, Oregon Graduate Institute, Beaverton, OR 97006. Email: pkolte@cse.ogi.edu \nPermission to copy without fee all or part of this material is granted provided that the copias are not \nmade or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication \nand its date appear, and notice is given that copying is by permission of the Association for Computing \nMachinery. To copy otherwise, or to republish, requirea a fee and/or specific permission. ACM-S IGPLAN-PLDl-6/93 \n/Albuquerque, N.M. 01993 ACM O-8979 J-598 .4/93 jO006/0268... $505O can produce appreciable speedup in \nprogram execu\u00adtion time[14]. Various compiler optimizations such ss procedure inlining and code scheduling \nfurther in\u00adcrease the demand for good register allocation. Register allocation is divided into two subprob\u00adlems: \nregwier spdling and register assignment[l]. First, register spilling determines which live ranges will \nbe assigned to registers (allocated live ranges) and which live ranges will be assigned to memory (spilled \nltve ranges). Then, register assignment maps allocated live ranges to registers so that no register contains \nmore than one live range at each program statement. Graph coloring on interference graphs of live ranges \nis an established paradigm for register allocation [6, 7]. The nodes of an interference graph are live \nranges, and there are edges bet ween nodes that are simultaneously live at any statement in the program. \nColors represent physical registers, and the nodes of the graph are assigned colors such that neigh\u00adboring \nnodes do not share a color. Nodes that cannot be colored have to be spilled. Thus, under the graph coloring \nparadigm, the register assignment problem becomes the the coioring problem, which determines whether \nall nodes of a given interference graph can be colored with a given number of colors. Similarly, the \nspilling problem becomes the node deletion problem which finds the minimum number of nodes to spill such \nthat the resulting interference graph can be colored. Since both the coloring and the spilling problems \nare NP-complete[12], heuristic algorithms are employed to obtain a good register allocation. Register \nallocation requires a weaker constraint than that imposed by interference graphs of live ranges, namely, \ntwo variables cannot share a regis\u00adter at any particular statement in the program. Thus, segments or \npartitions of a live range of a variable may be assigned different registers or even spilled to memory \nin different regions of the program. These 268 partitions are connected to one another by register\u00adregister \nor register memory transfer instructions, amd the resulting allocation is valid even though it may not \ncorrespond to a valid coloring of the interferelmce graph. To produce better register allocations, live \nrange splitting techniques that partition live ranges have been implemented to solve both the spilling \nproblem[5, 8, 18] and the assignment problem[8, 9]. Although live range splitting is promising, there \nis no theoretical or empirical evidence that these techniques provide better allocations than the graph \ncoloring al\u00adgorithm using live ranges. Further, there is no gu~ar\u00adantee that the improvement in register \nallocation cut\u00adweighs the connection costs, where connection costs represent the execution cost of the \ninstructions that are inserted to connect the split live range segments of a variable that are assigned \ndifferent registers. In this paper, we present a new techniclue, load/store range analysis, that addresses \nthe register spilling problem by splitting live ranges into partitions that can be independently and \nprofitably allocated (or spilled). Load/store ranges are computed using a stan\u00addard iterative data flow \nanalysis algorithm that is sim\u00adilar to live variable analysis[l]. We construct the inter\u00adference graph \nof a program using load/store ranges in\u00adstead of live ranges, and use existing heuristics to spill and \ncolor the nodes of this graph. We incorporated our load/store range analysis into a register allocator \nthat uses Chaitin s graph coloring scheme[7] with delayed spilling[3] and the Haifa suite of spill heuristics[2], \nland compared it to a similar register allocator that used live range interference graphs. Experiments \non a snnall suite of well known C and FORTRAN benchmark pro\u00adgrams show that the allocator operating on \nload/store ranges often produces better spilling than the one op\u00aderating on live ranges. The main benefit \nof our approach is that, un\u00adlike live ranges that are coarse and do not adequately account for clustered \naccesses of variables[8, 15], our technique provides a fine granularity of candidates for register allocation \nthat are based on the access pat\u00adterns of variables. Additionally, our load/store ranges can be used \ninstead of live ranges with any existing graph coloring algorithms, and our technique can even complement \nother live range splitting schemes. In the next section, we give background informat\u00adion. Section 3 describes \nthe load/store range anal\u00adysis technique. In Section 4, we discuss the use of load/store ranges with \nan existing register allocation scheme. Section 5 presents our experimental results. Related work is \nbriefly discussed in Section 6. Finally, section 7 presents conclusions and future work. BO x:= : Lil \nT B1 B4 \\ II B6 I I Figure 1: For variable X, Namel contains {BO,B1}, and Name2 contains {B2,B3,B4,B5}. \n2 Background A controljlow graph is a directed graph in which nodes represent program statements and \nedges repre\u00adsent flow of control between statements. A subpath in a control flow graph is a finite sequence \nof nodes (nl, n2,...,n~) such that for i = 1,2, . . . . k-l, there is an edge from n$ to ni+l. A subpath \n(i, nl, .... n~, j) is dejlnition-free with respect to a variable v from nodes i to j if there is no \ndefinition of v in any of the ni on the path. A use U of variable v is reachable from statement S if \nthere is at least one definition-free subpath with respect to v from S to U. A variable v is live at \nprogram statement S if there is a use of v that is reachable from S. The live range of variable v is \nthe set of all statements over which v is live[l]. The live range of a variable may contain a number \nof non-contiguous regions, called names[6], where each name is a set of connected statements. For example, \nFigure 1 shows a program with variable X defined in BO, B2 and B3, and used in B1, B4 and B5. Live range \nanalysis reveals that X is live in all basic blocks except B6, and hence the live range of X is Li(X)={B0,Bl,B2, \nB3,B4,B5}. However, since X is not live on the edges (B1,B2) and (B1,B3), the live range Li contains \ntwo non-contiguous regions (names). These two names are Namel={BO,Bl} and Name2={B2,B3,B4, B5}, and they \nare shown in Fig\u00adure 1. Although names are not identical to live ranges, we traditionally use the two \nterms synonymously. Two live ranges interfere with each other if they are simultaneously live at any \nstatement. The degree of live range Li is the number of live ranges that in\u00adterfere with Li. If we assume \nthat a memory access (load or store) takes one CPU clock cycle, the cost or profit associated with a \nlive range is the weighted sum of the number of definitions and uses of the variable, where the weights \nare the the execution frequencies of the definitions and uses. Chaitin s heuristic for deciding which \nlive ranges to spill [7] chooses the candidate with the lowest profit/degree ratio. Briggs, et al.[3] \nintroduced the idea of delayed spilling, which always produces allo\u00adcations that are at least as good \nas those produced by Chaitin. Bernstein, et al. [2] developed the Haifa register allocator and refined \nChaitin s spilling heuris\u00adtic to produce a set of three complementary heuris\u00adtic functions: cost/degree2, \ncost/(areax degree), and cost/(area x degreez). Their experiments showed that although none of these \nthree heuristic functions con\u00adsistently dominated one another, the best-of-three always outperformed \nChaitin s heuristic for spilling. Load/Store Range Analysis The goal of load/store range analysis is \nto achieve better spilling by localizing profits and register requirements of the accesses to variables. \nRegister re\u00adquirements are the statements over which a register is required. Accesses are the definitions \nand uses of the variable. The store range of a definition is the set of statements over which the variable \nmust be allocated a register to avoid a store at the definition. The load range of a use is the set of \nstatements over which the variable must be allocated a register to-avoid a load at the use. A store range \nmay contain a number of load ranges, and there is at least one load range for every use in the store \nrange. Store ranges are based on the observation that, in order to avoid a store at a definition, it \nis necessary and sufficient to allocate a register only to those statements in the live range of a variable \nwhere the definition reaches. The main observation used to construct load ranges is that allo\u00adcating \na register over all statements between the use of a variable and the most recent accesses of the variable \nis necessary and sufficient to avoid a load at the use. Load ranges and store ranges are partitions of \nlive ranges that can be independently and profitably allocated or spilled. Independent allocation means \nthat the allocation, including the computation of the heuristic function for spilling costs, of a partition \nof a live range is independent of all other partitions of that live range. Profitable allocation means \nthat ev\u00adery live range segment has a positive savings in pr~ gram execution time if it is allocated. \nAn additional desirable property for a live range splitting scheme is that it produce minimum size partitions. \nMinimum size partitions are the smallest sets of statements that are profit able and independent, and \nhence every live range results in the maximum number of such parti\u00adtions. Although load and store ranges \nusually satisfy the requirement of minimum size partitions, it maybe possible to obtain finer partitions \nbased on the sub\u00ad paths within the ranges. 3.1 Examples of load and store ranges Example of load ranges: \nFigure 2 illustrates the usefulness of load ranges of a variable. There is a definition of X at statement \nS1, and uses of X at statements S2, S3, and S4. X is live between S1 and S4, and hence, the live range \nof X is Lil:{Sl,.. .,S4}. Assuming that the basic block is executed once, the profit of allocating Lil \nis 4 because it has 1 defini\u00adtion and 3 uses. Store range analysis produces the store range St 1:{S1 \n,.. .,S4} that also has a profit of 4. Load-range analysis produces the load ranges Lo1:{S1,.. .,S2}, \nL02:{S2,.. .,S3} and L03:{S3,.. .,S4}. The profit of allocating Lol to a register is 1 because a load \nis saved at S2. The profit of allocating L02 is 1 because we assume that a load is used to access X at \nS2 and a register is used to access X at S3 and thus, we save a load at S3. Similarly the profit of L03 \nis 1. Lil Lol Sl: x:=... ... 1IL02 S2: ....= x ... 1IS3:... :=x ... S4: ....= x ... Basic Block Live \nRange Load Ranges Figure 2: Load ranges Lol, L02 and L03 are profitable and independent of one another. \nStore range St 1 is not shown, 1 SO: if (...) SO: if(...) I Sl: x:=... else Sl: x := ...1 S2:x := ... \n endif S3: =x I t Program Fragment Control Flow Graph Figure 3: Store ranges St 1 and St2 are If there \nis a sufficient number of registers avail\u00adable in the basic block, allocating store range St 1 is the \nsame as allocating live range Lil and yields a profit of 4. On the other hand, suppose there are too \nmany live variables in the region between statements S2 and S3, and variable X must be spilled. If we \nspill the live range of X, Lil, there is no profit, but if we spill load ranges, we may be able to allocate \nthe load ranges Lol and L03 to obtain a profit of 2. Load ranges Lol, L02 and L03 are independent partitions \nbecause the allocation as well as the computation of the profit for any one of them does not depend on \nthat of the others. When the entire live range lies within a single basic block, load ranges are minimum \nsize partitions because it is not possible to find smaller partitions that yield any profit. Example \nof store ranges: The program frag\u00adment shown in Figure 3 illustrates the usefulness of store ranges. \nVariable X is defined at statements S1 and S2, and is used at statement S3. The live range of X is Lil:{Sl,.. \n.,S2,. . .,S3}. Assuming that S1 and S2 are each executed once and S3 is executed twice, the profit of \nLil is 4. Store range analysis produces two store ranges: Stl:{Sl,. . .,S3} and St2:{S2,.. .,S3} each \nwith a profit of 2. Suppose a register is not avail\u00adable in the region S1,.. .,S3, but a register is \navailable in the region S2 ,.. .,S3. Then, considering store ranges as candidates for spilling is beneficial \nbecause only St 1 is spilled while St2 is allocated a register. The load X for St 1 can be placed on \nthe edge between blocks B1 and B2. It is clear that Stl and St2 are the minimum size partitions that \nare independent and profitable. Lil St1 st2 22 v4 \\/ Live Range Store Ranges profitable and independent \nof each other. 3.2 Computation of load and store ranges The store range (St) of definition D of variable \nv is the set of all statements S that D reaches such that there exists a reachable use U of v at S. St(D) \n= {S I D reaches S A 3 U reachable from S } We introduce additional terminology to define a load range. \nAn access of a variable v is either a defini\u00adtion or a use of v. An access-free subpath with respect \nto variable v and two statements Si and Sj k a Subpath from statement Si to the statement Sj that contains \nno accesses of the variable v. An access of variable v at statement Si arrives at statement Sj if there \nis at least one access-free subpath with respect to v from Si to Sj. Use U of variable v is exposed at \nstatement S if there is at least one access-free subpath with respect to v from S to U. A definition \nof a variable is never exposed. The load range (Lo) of two accesses ai and aj in a store range is the \nset of statements between ai and aj. Lo(~,aj)={ S I % arrives at S A aj is exposed at S } Computing store \nranges requires reaching def\u00adinition and reachable use analyses, which are per\u00adformed using standard \niterative data flow analy\u00adsis algorithms[l]. After store ranges are computed, we assign unique subscripts \nto the definitions and uses of the variables in order to identify the ac\u00adcesses within store ranges, \nThen we use algorithm Comput eLoadRanges, given in Figure 4, to compute load ranges. slgorithm input: \noutput: declare: ComputeLoadRsnges store range G with set of statements S and edge set load ranges Lo \nof store range G A_I1, ARUT, E-IE, E-OUT, GEli, USE and KILL are sets such that there is one such set \nfor each statement E of accesses s 6 S; begin /* step 1 : initialization of sets */ forse Sdo GEE [s] \n:={alais an accessing}; USE [s] :={alaisa use ins}; KILL [s] := { a I a is an access of A.Ill [s] := \n~; A-OUT [s] := GEM [s] ; E-IE [s] := USE [s] ; E-OUT [s] := # ; endfor a variable that occurs in s }; \n/* A-II! is set of arriving /* A.(NJT is set of arriving /* E-IM is set of exposed /* E-OUT is set of \nexposed accesses accesses accesses accesses at a point at a point at a point at a point just just just \njust before after before after s s s s */ */ */ */ /* step 2 : A-Ii [s] AJJUT [s] compute arriving accesses \nby iterating := P-asa?rede.A-&#38;T p]; -Cessor0} .9 := GEE [s1 u (A.lB [s1 -KILL [s1 ); until - a steady \nstate */ I+ step 3 : E-OUT [s] E-IB [s] compute exposed uses by iterating := u E-II [t] ; t is a suc\u00adcessor \nof s := usE [s] u (E.OUT [s1 -KILL [s]); until a steady state */ I* step 4 : compute Lo (a, , aj) := \n{ load s / ranges for all pairs a; E AJE [s1 A aj C of accesses EJM [s1 } in S */ end Comput eLoadSanges \nFigure 4: Algorithm to compute load ranges. In step 1, Comput eLoadRanges initializes the sets for the \ndata flow analysis. For program statement s, GEE[s] is the set of accesses in s, and USE [s] is the set \nof uses in s. KILL [s] is the set of accesses that, if exposed at the point after s will not be exposed \nat the point before s. The GEli [s1, USE [s1, and KILL [s1 are computed locally for each statement s. \nA_IIJ [s] is the set of arriving accesses that reach the point just before s, and A_OUT[s] is the set \nof arriving accesses that reach point just after s, A-IN [s] is initially empty and A-OUT [s] is initially \nGEI?[s]. Similarly, E-Iii [s] is the set of exposed accesses at the point just before s and E_OUT[s] \nis the set of exposed accesses at the point just after s. E_IIJ [s1 is initially USE [s1 and E-OUT [s] \nis initially empty. In step 2 of Comput eLoadRanges, the arriving accesses are computed using forward \ndata flow anal\u00adysis and solving the data flow equations by iterating over the statements until a steady \nstate is reached. Similarly, in step 3 of Comput eLoadRanges, the ex\u00adposed uses are computed by iterating \nover the state\u00adments and solving the equations until a steady state is reached, except that flow is in \na backward direction. Finally, in step 4, the arriving accesses and the exposed uses are considered for \neach pair of accesses to determine the load ranges. 4 Register Allocation with Load/Store Ranges Register \nallocation using graph coloring involves constructing the interference graph of the program, applying \nthe spilling and coloring heuristics to the in\u00adterference graph, and assigning registers to the allo\u00adcated \nranges. Constructing the interference graph of a program using load/store ranges requires the usual three \nsteps: Step 1: compute the nodes Step 2: compute the weights of nodes Step 3: compute the edges between \nthe nodes The first step of constructing an interference graph computes the nodes representing sets of \nstate\u00ad ments in the load/store ranges using the techniques described in section 3.2. The second step \nattaches weights to the nodes that represents the profits of allocating the nodes. To compute the profits \nof the ranges, we estimate that each access is executed 10* times where d is the loop-nesting depth at \nwhich the access occurs, The profit associated with a store range is the sum of the number of definitions \nand uses in the store range that have been weighted by the execution frequencies of the definitions and \nuses, The profit as\u00ad sociated with load range Lo(%, aj ) is the number of times that an access-free subpath \nfrom ~ to aj is ex\u00ad ecuted. We statically estimate the profit of Lo(%, aj ) as the quotient of the execution \nfrequency of aj and the number of accesses that statically reach aj. The third step of constructing interference \ngraphs determines the edges between nodes by cc)m\u00ad puting the interferences among the load and store \nranges as follows. Load and store ranges of the same variable do not interfere with one another. The \nload and store ranges of distinct variables interfere with one another if they intersect at some statement. \nThus, the degree of a range of a variable is the number of ot her variables with which the range interferes. \nFor a graph coloring register allocator, the cc}m\u00adputational expense of using load/store ranges instead \nof live ranges is the additional time required to cc~m\u00adpute the load/store ranges and the increase in \nalloca tion time due to the increased number of nodes han\u00addled by the allocator. If we assume that each \nstake\u00adment of the program defines one result and uses at most two operands, then the number of accesses \nin the program is at most three times the number of clef\u00adinitions in the program (and at most one and \na half times the number of uses in the program). Since the time required by the iterative data flow analysis \nalgo\u00adrithm is linear in the size of the set of values being propagated, the times required for computing \nreach\u00ading definitions, reachable uses, arriving accesses amd exposed accesses are roughly similar. Thus, \nthe time required for computing store ranges is close to that for live ranges. Although computing arriving \naccesses amd exposed uses with the method given in steps 2 and 3 of Figure 4 is efficient, the execution \ntime of algorithm Comput eLoadRanges is dominated by step 4 where all possible pairs of accesses are \nexamined, An enhance\u00ad ment to Comput eLoadRanges is to perform step 4 in a lazy manner in which we compute \nthe load ranges of only those store ranges that might be spilled by the coloring/spilling heuristics \nof the register allocator. The number of store ranges in a program is roughly equal to the number of \nlive ranges in the pro\u00ad gram, but the number of load ranges in a store range can be as large as the square \nof the number of accesses of the variable in the store range. Though the total number of load ranges \nin the program is potentially large, in our experiments, we found that the num\u00ad ber of load ranges is \nbetween two and three times the number of live ranges. Thus, the increase in register allocation time \ndue to the use of load or store ranges is not prohibitive. 5 Experimental Results We implemented two \nregister allocators that are based on Chaitin s graph coloring scheme[7] with the delayed spilling enhancement \n[3] and the Haifa spill heuristics[2]. One allocator uses live ranges as the nodes of its interference \ngraph and the other uses load/store ranges. We experimented with a few well known C and FORTRAN programs \nin order to com\u00adpare the two allocators, and give our results in Tables 1 and 2. The C programs that \nwe considered include linpack, which is a linear algebra kernel, hoops, which is a kernel containing \nthe 14 Lawrence Liver\u00admore loops, ns i eve, which is the sieve of Eratosthenes. We also examined the \ndhryst one, whet st one and dhampst one synthetic benchmarks, but ,do not report the results because \nboth allocators produced nearly identical allocations. The FORTRAN programs that we considered are the \nt omcatv mesh generation pro\u00adgram and the matrixsoo matrix multiplication pro\u00adgram from the SPEC benchmarks \nsuite. Further de\u00adtails of our experiments can be found elsewhere[16], The live ranges and load/store \nranges of the C programs are computed from the definition/use infor\u00admation obtained from a modified version[13] \nof the GNU C compiler gcc[19]. The definition/use inform~ tion of the FORTRAN programs is obtained by \nusing f 2c to translate the programs into C[l 1], and then compiling the resulting C programs with the \nmodified gcc compiler. Table 1 compares the two allocators for both C and FORTRAN programs. The first \nand second columns contain the names of the program and its procedure respectively. The third column \nlists the weighted number of loads and stores in the procedure 97 2 ,GI-1 Program Procedure Total Loads/ \nNumber of Using Live Using Lo,/St. Gain (~)0 Stores Registers Ranges Ranges C Programs nsieve main 328 \n1 156 136 I 20 12,8% 2 I 91 I 86 I 5 5.5% 4 40 36 4 10.0% 8 0 0 0 0% sieve 12042 1 4696 4384 312 6.6% \n2 3491 3447 44 1.3% 4 1087 809 278 25.6 % 8 26 35 9 34.6% Hoops main 190057 1 2 108547 68866 105814 \n64010 2733 4856 2.5% 7.1% 4 34138 34822 684 2.0% 8 8247 6841 1406 17.0% init 98290 1 55988 54380 1608 \n2.9% 2 35847 33445 2402 6.7% 4 10262 8986 1276 12.470 8 0 0 0 0% linpack main 2191 1 744 722 22 3.0% \n2 305 278 27 8.9~o 4 26 29 3 11.570 8 0 0 0 070 mat gen 10290 1 5249 4879 370 7.070 2 3719 3158 561 \n15.1% 4 2178 1934 244 11.2% 8 642 305 337 52.5% dgefa 9567 1 4665 4310 355 7.6% 2 3728 3296 432 11.6% \n4 2156 1923 233 10.8~o 8 464 224 240 51.7% daxpy 2090 1 1169 1070 99 8.5% 2 786 684 102 13.0% 4 442 377 \n 65 14.7% 8 75 78 3 4.0% ddot 1940 1 1070 1003 67 6.3% 2 699 615 84 12.0% 4 389 335 54 13.9% 8 54 27 \n27 50.0% dscal 1579 1 797 714 83 10.4% 2 515 464 51 9.9% 4 203 155 48 23.6% 8 0 0 0 o% FORTRAN Programs \ntomcatv main 162852 1 63876 62390 1486 2.3% 2 38620 36646 1974 5.1% 4 19726 15745 3981 20.2% 8 6629 4766 \n1863 28.1% matrix300 main 6828 1 2632 2503 129 4.9% 2 1798 1621 177 9.8% 4 517 505 12 2.3% 8 50.09% prnt \n1688 1 98; 76: 22: 22.5% 2 550 465 85 15.5% 4 257 266 9 3.5% 8 11 11 0 o% sgemv 1252 1 618 555 63 10.2% \n2 470 409 61 9.9% 4 293 274 19 6.5% 8 156 157 -1 -0.1% Table 1, Allocations for C and FORTRAN programs. \nProgram Procedure Stare Ranges nsieve main 24 sieve 34 hoops main 1261 init 163 linpack main 376 matgen \n51 dgefa 91 daxpy 101 ddot 96 dscal 67 tomcatv main 1037 matrix300 main 203 prnt 25 sgemv 93 Table2. \nNumber ofnodes and the fourth column gives the number of general purpose registers available for allocation, \nWe expler\u00adimented with 1, 2, 4 and 8 registers to get our re\u00adsults, The fifth column contains the weighted \nnumber of loads and stores obtained after allocating R reg\u00adisters to the live ranges of the procedure; \nthe sixth column shows the corresponding number for the al\u00adlocation of load/store ranges, The last two \ncolumns show the absolute difference and the percentage differe\u00adnce between the two allocations respectively. \nIn cases where the resulting number of loads/stores is small, such as ns i eve with 8 registers, linpack, \nmatgen with 8 registers, matrix300, main with 8 registers and matrix300, saxpy with 8 registers, the \npercent\u00adage gains appear extreme. However, even for other cases, the allocations with the load/store \nranges usu\u00adally results in a reduction in the number of loads and stores in the program. To determine \nthe growth in the size of the inter\u00adference graph using load/store ranges, we recorded the number of \nnodes produced in each allocator. Table 2 compares the number of nodes in the load/store inter\u00adference \ngraphs of our test programs with the number of nodes in the live range interference graphs of the same \nprograms. The third column in Table 2 lists the number of store ranges and the fourth lists the number \nof load ranges. The fifth column gives the number of store ranges that contained only one load range. \nWe optimized the number of load/store ranges by elimin\u00adating the load ranges that were the only member~~ \nof their store ranges from the interference graph. The Load Single Loads/ Live Ranges Ranges Stores \nRanges 30 19 35 21 80 18 96 28 1964 1116 2109 1219 335 130 368 147 430 353 453 368 136 33 154 43 250 \n79 262 89 210 81 230 93 189 74 211 86 142 55 154 64 1645 944 1738 1013 229 192 240 204 56 14 67 23 174 \n68 199 85 inthe interference graphs. resulting number of load/store ranges is shown in the sixth column. \nThe last column in Table 2 shows the number of live ranges of the procedure. Comparing the last two columns \nof this table reveals that the number of load/store ranges is generally less than three times the number \nof live ranges. Although there are a few programs where the ratio of the number of load/store ranges \nto the number of live ranges is higher, these are small programs with few live ranges. These re\u00adsults \nlead us to believe that, in practice, the cost of allocating load/store ranges is much less than the \nthe\u00adoretical worst case estimates. 6 Related Work Bernstein et al,[2] proposed that spilling of live \nranges be performed only in the busy regions instead of over the entire program as in Chaitin s implement \na\u00adtion. Callahan and Koblenz[5] proposed a scheme that computes the spill costs of variables based on \nvariable usage patterns between spills and reloads rather than the usage over the entire program. Their \nhierarchical graph coloring scheme first covers the program with a set of tiles ) that reflect the control \nflow of the pro\u00adgram, then computes the interferences and allocates registers in the tiles in a depth \nfirst manner, and fi\u00adnally assigns registers in a top-down manner in the tile tree. Although this scheme \nis intuitively appealing, it is much more complex than Chaitin s original scheme, and there are no theoretical \nor empirical results to demonstrate its effectiveness. Chow and Hennessy presented an alternate graph \ncoloring scheme called priority-based coioring[8, 17]. Nodes of the interference graph are assigned pri\u00ad \norities using a costj.size function that is similsr to Chaitin s cost/degree heuristic. Nodes are colored \nin order of decreasing priority, and anode that cannot be colored is split into partitions that can be \ncolored. Al\u00adthough the live range splitting can produce colorings where Chaitin fails, the greedy coloring \napproach may split live ranges that might have been assigned a single color by Chaitin s coloring heuristic. \nThus, it may in\u00adtroduce unnecessary register register transfer instruc\u00ad tions. Further, it is not clear \nwhether the priority\u00ad based coloring produces any improvement in spilling over Chaitin s heuristic. Bernstein \ns team reports [2] that their modification to Chaitin s spilling heuris\u00ad tic universally outperforms \nthe priority-based coloring approach, but they do not provide any statistics. Cytron and Ferrante[9] \npresented an algorithm for live range splitting to improve the colorability of interference graphs. They \ndescribed an algorithm that guarantees a coloring using MAXLIVE colors, where MAXLIVE is the maximum \nnumber of variables that are simultaneously live at any program state\u00adment. If the number of available \nregisters, is less than MAXLIVE, the assignment pass is preceded by an al\u00adlocation pass which uses weights \non the nodes such as Chow and Hennessy s priorities, However, the tech\u00adnique for determining such an \nallocation is not de\u00adscribed. Like the priority-based coloring, this algo\u00adrithm can produce colorings \nwhere Chaitin fails, but it may also split live ranges where Chaitin s coloring heuristic would have \nworked. Proebsting and Fischer[18] presented a global register allocation technique called probabilistic \nregis\u00adter allocation in which the spilling heuristic uses prob\u00adabilities that estimate the chances of \nlive ranges being spilled. These probabilities serve the same purpose as the l/degree2, I/(area x degree) \nand I/(area x degree2) components of the Haifa spilling heuristics. They con\u00adcentrated on reducing the \nnumber of loads by split\u00adting live ranges in a manner that is equivalent to our computation of load ranges. \nUnlike our scheme, their heuristic further splits load ranges at loop boundaries. After load ranges are \nallocated registers, they allocate registers to store ranges which have no spilled load ranges. It would \nbe interesting to compare the allo\u00adcations produced by their probability based heuristic for spilling \nwith those produced by the Haifa spilling heuristics operating on load/store ranges. Briggs et al.[4] \nsuggested various schemes for splitting live ranges such as splitting live ranges around loops and splitting \nat forward and reverse dominance frontiers[lO]. They report that in spite of comprehensive experiment \nation, they were unable to find a live range splitting scheme that consistently pro\u00adduced better allocations \nthan using live ranges. 7 Conclusions and Future Work We have presented a new technique to split live \nranges into load/store ranges that provide a finer gran\u00adularity of candidates for register allocation \nthan using live ranges. Our algorithms to compute load/store ranges are standard iterative data flow \nalgorithms. Our experiments show that the computational cost of our technique is only moderately more \nthat the cost of using live ranges but we get a better allocation in most cases. In this paper, we concentrate \non using live range splitting to improve the spilling of variables in regions of high register pressure. \nThe problem of assigning registers to the live range segments and inserting the minimum possible connection \nstatements still remains. Two possible approaches to solving this problem are to use conservative coalescing \nin which the connected segments of a live range that can be coalesced without spilling are coalesced[4], \nand biased coloring in which, when possible, a live range segment is assigned the same color as its connected \nsegments[4]. Load subpaths are sets of statements within load ranges such that each statement (except \nthe last one) contains exactly one control flow successor in the load subpath. Load subpaths cent ain \nstatements between a use and a most recent access, instead of all most recent accesses as in the case \nof load ranges. Thus, load subpaths represent an even finer granularity than load ranges, and we plan \nto experiment with register allocators that use these. It is well known[4, 5, 18] that moving loads and \n stores out of loops is beneficial. At present, load/store range analysis implicitly assumes that the \nloads are avoided only at uses and stores are avoided only at def\u00ad initions, and hence it does not take \nloops into account when constructing the ranges. We plan to extend our analysis to initially assume that \nall live variables are used (with execution frequency O) at all loop bound\u00ad aries, and study the effects \nof this extension on register allocation. Acknowledgements We wish to thank Preston Briggs, Jeff Offutt, \nTodd Proebsting and Mark Smotherman for their valuable comments on various drafts of this paper. References \n[1] A. V. Aho, R, Sethi and J. D. Unman, Compil\u00aders, Principles, Techniques, and Tools, Addison-Wesley \nPublishing Company, 1986. [2] D. Bernstein, D. Q. Goldin, M. C. Golumbic, H. Krawczyk, Y. Mansour, I. \nNahshon and IR. Y. Pinter, Spill code minimization techniques for optimizing compilers , Proceedings \nof the ACM SIGPLAN 89 Conference on Programming Language Design and Implementation, Sigplan Notices, \nvol. 24, no. 6, pp. 258 263, June, 198$1. [3] P. Briggs, K. D. Cooper, K. Kennedy and L. Torc\u00adzon, Coloring \nheuristics for register allocation , Proceedings of the ACM SIGPLAN 89 Confer\u00adence on Programming Language \nDesign and Ina\u00adpiementation, Sigplan Notices, vol. 24, no. 6, pp. 275-284, June, 1989. [4] P. Briggs, \nK. D. Cooper and L. Torczon, Re\u00admaterialization , Proceedings of the ACM SIG-PLAN 92 Conference on Programming \nLa:n\u00adguage Design and Implementation, Sigplan No\u00adtices, vol. 27, no. 7, pp. 311-321, June, 1992. [5] \nD. Callahan and B. Koblenz, Register alloclw tion via hierarchical graph coloring , Proceedings of the \nACM SIGPLAN 91 Conference on Prog\u00ad ramming Language Design and Implementation, Sigplan Noticesj vol. \n26, no. 6, pp. 192-203, June, 1991. [6] G. J. Chaitin, M. A. Auslander, A. K. Chandr;a, J. Cocke and \nP. W. Markstein, Register alloci~ tion via coloring , Computer Languages, vol. 15, pp. 47-57, January, \n1981. [7] G. J. Chaitin, Register allocation and spilling via coloring , Proceedings of the A CM SIGPLAN \n82 Symposium on Compiler Construction, Sig\u00adplan Notices, vol. 17, no. 6, pp. 98 105, June, 1982. [8] \nF. Chow and J. Hennessy, The priority-based coloring approach to register allocation , ACM Transactions \non Programming Languages and Systems, vol. 12, no. 4, pp. 501 536, October, 1990. [9] R. Cytron and J. \nFerrante, What s in a name? The value of renaming for parallelism detection and storage allocation , \nProceedings of the 198 7 International Conference on Parallel Processing, pp. 19-27, August, 1987. [10] \nR. Cytron, J. Ferrante, B. K. Rosen, M. N. Weg\u00adman and F. K. Zadeck, Efficiently computing static single \nassignment form and the control dependence graph , ACM Transactions on Pro\u00adgramming Languages and Systems, \nvol. 13, no. 4, pp. 451-490, October, 1991. [11] S. I. Feldman, D. M. Gay, M. W. Maimone and N. L. Schryer, \nA Fortran-to-C converter, Computing Science Technical Report No. 149, AT&#38;T Bell Laboratories, Murray \nHill NJ, November, 1990. [12] M. R. Garey and D. S. Johnson, Computers and Intractability: A Guide to \nthe Theory of NP-Completeness, W .H. Freeman and Company, New York, 1989. [13] M. J. Harrold and P. Kolte, \nCombat: A com\u00adpiler based data flow testing system , Proceedings of the It?h Pacific Northwest Sofiware \nQuality Conference, October, 1992. [14] J. L. Hennessy and D. A. Patterson, Computer Architecture: A \nQuantitative Approach, Morgan Kaufmann Publishers, Inc., 1990, 15] W. -C. Hsu, C. N. Fischer and J, R, \nGoodman, On the minimization of loads/stores in local reg\u00adister allocation , IEEE Transactions on Software \nEngineering, vol. 15, no. 10, pp. 1252-1260, Oc\u00adtober, 1989. 16] P. Kolte, Load/store range analysis \nfor global register allocation, Masters Paper, Clemson University, August, 1992. [17] J. R. Larus and \nP. N. Hilfinger, Register alloca\u00adtion in the SPUR Lisp compiler , Proceedings of the ACM Symposium on \nCompiler Construction, Sigplan Notices, vol. 21, no. 6, pp. 255 263, June, 1986. [18] T. A. Proebsting \nand C. N. Fischer, Probabilis\u00adtic register allocation , Proceedings of the ACM SIGPLAN 92 Conference \non Programming Lan\u00adguage Design and Implementation, Sigplan No\u00adtices, vol. 27, no. 7, pp. 300-310, June, \n1992. [19] R. M. Stallman, Using and porting GNU CC (version 1.37.1), Free Software Foundation, Inc., \nCambridge MA, February, 1990.  \n\t\t\t", "proc_id": "155090", "abstract": "<p>Live range splitting techniques improve global register allocation by splitting the live ranges of variables into segments that are individually allocated registers. Load/store range analysis is a new technique for live range splitting that is based on reaching definition and live variable analyses. Our analysis localizes the profits and the register requirements of every access to every variable to provide a fine granularity of candidates for register allocation. Experiments on a suite of C and FORTRAN benchmark programs show that a graph coloring register allocator operating on load/store ranges often provides better allocations than the same allocator operating on live ranges. Experimental results also show that the computational cost of using load/store ranges for register allocation is moderately more than the cost of using live ranges.</p>", "authors": [{"name": "Priyadarshan Kolte", "author_profile_id": "81100298774", "affiliation": "", "person_id": "P228361", "email_address": "", "orcid_id": ""}, {"name": "Mary Jean Harrold", "author_profile_id": "81100639551", "affiliation": "", "person_id": "PP14219545", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/155090.155116", "year": "1993", "article_id": "155116", "conference": "PLDI", "title": "Load/store range analysis for global register allocation", "url": "http://dl.acm.org/citation.cfm?id=155116"}