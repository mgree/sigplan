{"article_publication_date": "06-01-1993", "fulltext": "\n HandDing Control Dorai Sitaram Department of Computer Science Rice University Houston, TX 77251-1892 \nAbstract Non-local control transfer and exception handling have a long tradition in higher-order programming \nlanguages such as Common Lisp, Scheme and ML. However, each language stops short of providing a full \nand comple\u00admentary approach control handling is provided only if the corresponding control operator \nis first-order. In this work, we describe handlers in a higher-order con\u00adtrol setting. We invoke our \nearlier theoretical result that all denotational models of control languages invariably include capabilities \nthat handle control. These capa\u00adbilities, when incorporated into the language, form an elegant and powerful \nhigher-order generalization of the first-order exception-handling mechanism. Introduction Control manipulation \nin applicative programming lan\u00adguages comes in two flavors. First-order control op\u00aderators allow computations \nto abort to a dynamicidly enclosing control context, e.g., Common Lisp s [22, 23] throw and ML s [8, \n16] raise. They are invariably accompanied by forms that delimit and handle the aborted value, e.g., \ncat ch in Common Lisp and handle in ML. In contrast, htgher-order operators such as call\u00adwith-current-continuation \nin Scheme [26, 27] and ML [3] allow unrestricted transfers of control without regard to dynamic scope. \nIn pre-Common Lisp [15], the operators error iand errorset, intended to respectively signal and handle \nerrors, work equally well for exits. The form errorset simply returns the value of its subexpression \nif the latter has no calls to error. If the subexpression does generate a call to error whether due \nto a miscornputation or an explicit call to error there is a non-local exit Permission to copy without \nfee all or part of this materiall is granted provided that the copies are not made or distributed for \ndirect commercial advantage, the ACM copyright notice and ithe title of the publication and its data \nappear, and notice is givan that copying is by permission of the Association for Computing Machinery. \nTo copy otherwisa, or to republish, requires a fee and/or spacific permission. ACM-SlGPLAN-PLDl-6 /93/Albuquerque, \nN.M. a 1993 ACM 0-89791 -598 -4/93 /0006 /0147 ...$1 .50 or abort to errorset. Using lists or other records \nto pack the error return value and placing a dispatching wrapper around errorset provides a rudimentary \nbut effective form of control handling. We next have the catch and throw pair of Com\u00admon Lisp, where \nnon-local exits are caused ( thrown ) by throw and delimited ( caught ) by catch. These operators are \ntagged, i.e., a tagged throw can only be caught by a catch with an identical tag. In other words, a throw \ncan pick its destination, and not restrict itself to the closest catch. (In contrast, error and errorset \nsaddle the user with the chore of writing special dis\u00adpatching routines to distinguish between different \nexit destinations.) Because of the explicit throw operator, there is no reliance on errors for obtaining \njumps. In fact, it is possible to view error as a specially tagged throw, and errorset as its corresponding \ncatch. ML s exception-handling system, where raise causes a first\u00adorder jump and handle delimits it, \nmatches this view. In contrast to the first-order operators described above, a higher-order control operator \nsuch as Scheme s and ML s call-with-current-continuationl can transfer control to arbitrary points in \nthe program, not just to dynamically enclosing contexts. Like its historical fore\u00adrunners J [14] and \nescape [18], call/cc provides the user with a representation of the current control context: the (rest \nof the program or the continuation . Invoking this continuation at any point in the program causes the \nprogram s current context to be replaced by the contin\u00aduation s context. This ability to substitute the \ncurrent program context by a previously stored snapshot of a program context is simple and powerful. \nIt allows a wide range of programming paradigms [9, 10, 11, 12] not possible with catch and throw. However, \nthere is no analog to delimiting or han\u00ad dling a control action, as with errorset, or to distin\u00ad guishing \nbetween different varieties of control actions, as with catch. Methods of handling and distinguish\u00ad ing \ncontrol actions are left to user programs. Typically, 1Abbreviated call/cc in Scheme and Catrcc in ML. \n the user stores the context where a continuation should be handled as yet another call/cc-continuation, \nso that control can be transferred to it after the jump to the first continuation has accomplished its \npurpose. In the presence of several continuations with their respective quasi-handlers, keeping track \nof the various jump-off points and avoiding clashes between them requires so\u00adphisticated bookkeeping \nstrategies [4, 11]. It is there\u00adfore useful to explore options that tackle this problem wtthout sacrificing \nthe programming power of higher\u00adorder control. Here we show that the historical dualit y of first-order \nthrowing and handling is useful even for higher-order control. In earlier work [20, 21], we showed that \nall con\u00adventional models for non-local control include a control\u00adhandling capability. In other words, \nif the relationship between the model meanings and the observable behav\u00adior of language terms is to match, \nthe language, like the model, must include handlers. In light of this theo\u00adretical result, efforts to \nconstrain tail/cc are simply attempts to simulate a handler in a handler-less lan\u00adguage. Such attempts \nare not only complicated but also ultimately unsatisfactory, since the original opera\u00adtor has to be disabled \nin the process. A control handler in the language cleanly solves these issues. Indeed, it enriches higher-order \ncontrol, opening the way to novel and elegant control paradigms. Section 2 introduces the higher-order \ncontrol opera\u00ad tors run and fcontrol in a Scheme setting, with simple illustrations. Sections 3 and 4 \ndescribe two familiar but larger examples where control handlers prove use\u00adful. Section 5 summarizes \nthe results. 2 Manipulating control using handlers A control operator such as cal!/cc that captures contin\u00aduations \nis a control reafier: it retjies the continuation of the program and provides this to the user. However, \na closer look shows that call/cc combines two actions: not only does it capture the current continuation, \nit also invokes its argument procedure on this continuation. In other words, the handling of the continuation \ntakes place at the identical site as the creation of the continu\u00adation, in contrast to errorset/ error \nand catch/t brow. Control-handling constructs in traditional Lisp de\u00adlimit the context that can be erased \nby their control operators. Extrapolating from the relationship between errorset and error or catch and \nthrow, a control de\u00adlimiter for call/cc would control the extent of the con\u00adtext captured by call/cc \nor erased by its continuations. This operator, proposed by Felleisen [7], is called the prompt , since \nit annotates its subexpression as an independent program, in so far as control actions are concerned, \nmuch like the prompt sign in a read-eval\u00adprint loop. The procedural variant of the prompt is called run, \nto borrow a term used for an operator that runs programs [25]. The prompt and run are equiv\u00adalent: either \ncan be seen as syntactic sugar for the other. Together with higher-order control reifiers like call/cc, \nthe prompt supports powerful programming id\u00adioms [6, 19]. It has several successors specially suited \nto various practical settings, e.g., spawn [13], reset [2], and splitter [17]. However, none of these \nconstructs bandies control objects the corresponding control reifier continues to double as handler. \nIn this work, we continue the process of extrapola\u00adtion identified above by adding control-handling capa\u00adbilities \nto the delimiter. In other words, we shift the site of continuation handling from the control reifier \nto the control delimiter. This drastically changes the aspect of both delimiter and reifier. The new \ncontrol-capturing operator is a stripped down version of call/cc it needs no procedural argument to \nreceive its continuation, since the delimiter takes care of control handling and is therefore given \na new name: fcontrol. The new delim\u00aditer takes two sub expressions: (1) a computation that runs as a \ncontrol-independent program, and (2) a pro\u00adcedure that will handle any control actions performed by the \nfirst subexpression.z There is one notable difference between the current system and the historical errorset \nthat it resembles: It is a much more versatile control mechanism the continuations manipulated are higher-order, \nand not just aborts. The control system is identical to the one suggested by a different, theoretical \nroute, viz., the control-handling prompts that we showed to be im\u00adplicitly present in all the traditional \ndenotational mod\u00adels [20, 21]. 2.1 Run and fcontroi The control delimiter is called run. It takes two \nar\u00adguments, a thunk3 and a binary procedure called the handler: (run (thunk) (handjer)) The procedure \nrun calls the thunk as an control\u00adindependent program. If the thunk returns normally, the call to run \nreturns the result of the thunk. If, on the other hand, there is a control action inside the thunk, the \nhandler is invoked on the objects produced by the control action. The prompt, ZO, is a convenient synt \nattic variant4 of run: 2 Bruce Duba first suggested the prompt with a handler . 3 I.e., a procedure of \nzero arguments. 4 The symbol YO is chosen for its similarity to an operating sys\u00adt em prompt. Lisp s \nown prompt sign is usually >; unfortunately, that symbol is taken. (% exp handler) = (run (lambda () \nezp) handler) A control action is caused by invoking the control reifer fcontrol on a single argument: \n(fcontrol (object)) This sends a signal to the dynamically nearest surround\u00ad ing run, much like the first-order \nthrow to catch. The important difference is that the signal contains bclth the argument object and the \nretjied context or the con\u00adtinuation. Run processes this signal by invoking the handler on these two \nvalues. Since we want run to be the sole arbiter of control handling, the continuatic)ns produced by \nfcontrol are functional . I.e., fcontroi\u00ad continuations, unlike call/cc-continuations, will not au\u00ad \ntomatically erase existing context when invoked.  2.2 Simple exits As a simple illustration, a prompt \nwith a handler that ignores the continuation provides an abort, i.e., the common paradigm for procedure \nand loop exits. The prompt marks the entry point; an fcontrol-application within the prompt s first subexpression \nexits to the en\u00adtry point with an aborted value. E.g., the following procedure for multiplying the elements \nof a list exits immediately on encountering a zero element: (define product (lambda (s) (% (let loop \n([s s]) (if (null? s) 1 (let ([a (car s)]) (if (= a O) (fcontrol O) (* a (loop (cdr s))))))) (lambda \n(r k) r)))) 2.3 Tree-mat thing A canonical example of the use of continuations is to find if two trees \nhave the same frz nge5. The purely functional approach flattens both trees and checks if the results \nmatch. However, this would traverse the trees once completely to flatten them, and then again till it \nfinds non-matching elements. Furthermore, even the best flattening operations require conses equal to \nthe total number of leaves. The Scheme solution enlists both tail/cc and assignm\u00adent to avoid needless \nconsing. Each tree is mappedl to a generator, a procedure with internal state that suc\u00adcessively produces \nthe leaves of the tree: 51n our example ((1 . 2) . 3) and (1 . (2 . 3)) are considered to have the same \nfringe, as also ((1 2) 3), (1(2 3)) and ((:1 2) (3)) the empty list (), wherever it occurs in the tree, \ndoes not contribute any leaves. (define make-generator (lambda (tree) (letrec ([cailer *] [generate-leaves \n(lambda () (let ioop ([tree tree]) (cond [(pair? tree) (loop (car tree)) (loop (cdr tree))] [(nuil? tree) \nskip] [else (call/cc (lambda (rest-of-tree) (set! generate-leaves (lambda () (rest-of-tree *))) (caller \ntree)))])) (caller ()))]) (lambda () (call/cc (lambda (k) (set! caiier k) (generate-ieaves) )))))) The \ngenerator returns the empty list (which cannot be a leaf) when all the leaves have been accounted for. \nA simple loop alternately calls each generator, matches the leaves thus obtained, and stops immediately \nupon finding a mismatch: (define same-fringe? (lambda (treel treel?) (let ([genl (make-generator treel)] \n[gen~ (make-generator tree2)]) (let loop () (let ([leafl (genl)] [leaf2 (gen2)]) (if (eqv? leafl Ieafi?) \n(if (null? leafl ) #t (ioop)) #f)))))) The generator procedure uses call/cc to keep track of two continuations: \n(1) the continuation of each call to the generator so the result can be returned to it, and (2) the continuation \nmarking each break in the traversal of the tree, so that the next call to the generator can resume where \nthe previous call left off. Assignment is used to store both continuations in the internal state of the \ngenerator. The crucial continuation is (2), the rest of the com\u00adputation in the generator. The continuation \n(1) merely handles the interface with the generator. In the call/cc solution, each cent inuation represents \na different in\u00adstance of the entire program context. In fact, con\u00ad tinuation (1) is used to remember \nthat point in the continuation (2) where control needs to be transferred back to the caller. In the presence \nof the continuation\u00addelimiting handler, continuation (1) need not be cap\u00ad tured at all, and furthermore, \ncontinuation (2) need (fcontrol-tagged (tag) (object)) only be the partial continuation within the generator. \nAs a side benefit, the entire bookkeeping using assign\u00adment can be wholly avoided. We now present the \nScheme solution that uses prompt and fcontrol rather than call/cc and set!. Here too, the program checks \nthe leaves alternately, using generators that successively throw leaves: (define make-frznge (lambda \n(tree) (lambda (any) (let loop ([tree tree]) (cond [(pair? tree) (ioop (car tree)) (loop (cdr tree))] \n[(nuii? tree) *] [else (fcontroi ~ree)])) (fcontrol ())))) A loop catches leaves alternately from each \nfringe, and compares them: a mismatch immediately stops the pro\u00adcess: (define same-fringe ? (lambda (treel \ntree2) (let loop (~ringel (rnake-frtnge treel )] (jiwige2 (make-fringe tree2)]) (% (frtngel *) (lambda \n(leafl rest-of-fringel ) (% (fr2nge2 *) (lambda (ieaf2 res&#38;of-fringe2) (if (egv? leafl leaf2) (if \n(nuli? leafl ) #t (loop rest-o f-fringel rest-of-frmge2)) #f)))))))) Each time the rest of a fringe is \nprobed, a handler is used to collect a leaf (or the empty list signaling end of fringe) and the remaining \nfringe computation. If the leaves from the two fringes match, more leaves are ordered. If the leaves \nare different, the rest of the fringes are ignored, and the predicate returns false.  2.4 Tagged run \nand fcontrol To avoid interference between control actions arising from logically different uses of run/fcontroi, \nwe should identify matching pairs of these control operators. In an earlier approach, we suggested a \nhierarchically ordered set of delimiters [19]. For prompts with handlers, it is natural to continue our \nextrapolation from Lisp s catch and throw, giving tagged versions of run and fcontrol, invoked respectively \nas: (run-fagged (tag) (thunkj (handier)) and One tagging protocol others are possible is to have an \nfcontrol tagged X jump to the dynami\u00adcally closest prompt tagged X. Not only are interven\u00ading prompts \nof other tags ignored, but the continuation thrown to the X-prompt will be the complete continu\u00adation \nextending from the X-prompt to the X-fcontrol\u00adapplication. Different tags govern different logical uses \nof run/fcontrol without fear of interference. Further\u00admore, since a tag is any object, we can choose \nunforge\u00adable tag values and hide their use within a textual region using lexical hiding. We can define \nthe tagged versions using the raw primitives and a strategy whereby fcontrol-tagged uses fcontrol to \nsend a structure consisting of both its tag and its thrown value. However, it is preferable to avoid \nthe data-structure overhead and provide the tagged op\u00aderators as primitives. We shall henceforth usurp \nthe name run and fcontrol for the tagged operators. The previous untagged uses can be considered as having \nei\u00adther a default or catch-all tag, say false. 3 Nestable engines Our first larger example involving \nintensive control ma\u00adnipulation is the engine. An engine [4, 10] is an ab\u00adstraction of computation subject \nto timed preemption. It forms a tractable building block for realizing a variety of communicating concurrent \nprocesses. An engine s underlying computation is a thunk that can be run as a preemptable process. The \nengine is ap\u00adplied to three arguments: (1) a number of time units or tacks, (2) a success procedure, \nand (3) a failure procedure. If the engine computation finishes within the allotted time, the success \nprocedure is applied to the result of the computation and the remaining ticks; otherwise, the failure \nprocedure is applied to a thunk that represents the rest of the interrupted computation. This thunk, \nwhen called, resumes the interrupted engine comput ation.6 Haynes and Friedman [10] distinguish two varieties \n of engines: flat (untestable) and nestable. Flat engines cannot run other engines, but as the authors \nsay, this re\u00ad striction considerably simplifies the implementation of engines , where the implementation \nuses Scheme-style continuations. The more general nestable engines, or nesters, can be called at arbitrary \nsites, but are more difficult to implement in Scheme. An engine that invokes ( (nests ) GTraditionally, \nthe value supplied to the jai(tire procedure is a new engine representing the remaining computation of \nthe old engine rather than just its underlying thunk. Our version is no less general, and further allows \nenhancements that directly access the engine s underlying thunk. another engine is called its parent. \nNesters require some user-specified notion of fatrness governing the way time is spent among the nested \ninvocations.7 For instance, the nestable variety described here lets each engine use ticks only from \nthe amount allotted to its ancestors. Otherwise, an engine could cheat by performing its work through \nits offspring. The call/cc implementation of flat engines involves capture of continuations at both the \nstarting (or resum\u00ading) and returning points of an engine. Extending it to allow nestable engines entails \nmore than adding code for tick management, since the continuations to be cap\u00adtured while transferring \ncontrol across the generations of engines need involved bookkeeping [4]. We show here an implementation \nof nestable engines using control handlers. There is a clean separation be\u00adtween the segment for transferring \ncontrol and the seg\u00adment for managing time units.s Indeed, modifying just the time management strategy \nyields different kinds (of fairness, including flat engines. 3.1 The clock The implementation presupposes \na global clock or hn\u00adterruptable timer that consumes ticks while a program executes. The following describes \nthe type of clock we shall use: it may be defined using either natively pro\u00advided alarms or through syntactic \nextensions [4] that simulate tick consumption. The internal state of the clock contains: 1. the number \nof remaining ticks; and 2. an interrupt handler to be invoked when the clock runs out of ticks.  The \nuser can perform the following clock operations: 1. (clock set-handler (h)) sets the interrupt handler \ntO (h); 2. (clock set (n)) sets the ticks for countdown to (n); and 3. (clock stop) stops the clock \n(without setting off tlhe interrupt handler), returning the remaining ticks.  The number of ticks ranges \nover the natural num\u00adbers and an atom called infi nity.g A clock with an in\u00adfinite number of ticks cannot \nrun out of time, i.e., it 7Indeed, the flat engine could be considered a variant of the nester where \nfairness means the prohibition of children! 8 Given a module-based Scheme, the code can be written as \nan engine module that abstracts over a fairness module. 9Some Scheme dialects provide an atom for an \ninfinitely large number, on which the numerical procedures produce the expected results. In other dialects, \nany non-numerical atom may be chosen, with the procedures rnin, and = redefined (in the lexical sco,pe \nof the engine definition) to admit infinity as a possible argument. is quiescent or already stopped . \nStopping an already stopped clock returns infinity. Setting the clock s ticks to infinity stops the clock, \ni.e., ( ciock stop) is shorthand for (clock set infinity). The clock s handler is set to throw an interrupt \nsig\u00adnal, say interrupt, to an engine prompt: (cJock set-handler (lambda () (fcontrol engine interrupt))) \n 3.2 The engine core code The procedure make-engine takes a thunk and produces an engine, a procedure \nof three arguments: ticks, suc\u00adcess and failure. Assume for the moment that the tick management is accomplished \nby code segments named (ticks-preiude) and (tacks-postlude). The variable true-ticks intro\u00adduced in \n(tacks-prelude) shows the actual number of ticks given to the current engine. This may be less than \nthe argument ticks, owing to fairness considerations. When invoked, the engine runs its thunk as an in\u00addependent \npiece of computation, in so far as control is concerned. We therefore depict the engine compu\u00adtation \nas the engine s thunk invoked within a prompt tagged engine. The computation uses the flag engine\u00adsucceeded? \nto record whether the engine succeeded, and if so, the variable ticks-lefl denotes the ticks to spare. \nIn our first outline, the prompt surrounds code that in\u00adcludes both the initial setting of the clock \nto the allotted ticks, and the stopping of the clock if the thunk returns successfully. If the engine \nfails because of a clock interrupt the handler returns a thunk representing the rest of the engine. \n(If the handler was invoked for some reason other than an interrupt, we simply let it pass on the value.) \nAfter the postlude timer code (ticks-postiude) which may modify ticks-iefi either the success or fail\u00ad \nure action is taken, depending on the result of running the engine thunk: (define make-engine;; *** first \noutline *** (lambda (thunk) (lambda (ticks success failure) (ticks-prelude) (let* ([engine-succeeded? \n#fl [ticks-iefi O] [result;; . . . (1) (% engine (begin (ciock set true-tzcks) (let ([result (thunk)]) \n(set ! ticks-iefi (ciock stop)) ;; ... (II) (set ! engzne-succeeded? #t) result)) (lambda (r k) (if \n(eq? r interrupt) (lambda () (k #f)) r)))]) (ticks-postlude) ;; ... (III) (cond [engine-succeeded? (success \nresult ticks-lefl)] [else (faiture result)]))))) When the prompt returns, the variable resu!t con\u00adtains \neither the rest of the failed engine or a success\u00adful result, and the flag engine-succeeded? tells which \nof these is the case. Unfortunately, the code gives in\u00adcorrect failed engines: the continuation denoting \nthe interrupted engine includes the actions for setting the flag engine-succeeded? and stopping the clock. \nThis will yield spurious results when the engine is resumed, whether as a plain thunk or as a fresh engine. \nTo avoid this, we use two prompts. The outer prompt encloses all the computation as before, includ\u00ading \nthe thunk and the clock and flag operations. The new inner prompt surrounds only the setting of the clock \nand the call to the engine s thunk. The inner handler reacts to interrupts by throwing the rest of the \nengine to the outer prompt, thereby avoiding including the flag and clock operations in the thrown thunk. \nThe outer handler disables interrupts that occur after the inner prompt has exited this is done by resuming \nthe interrupted computation: *** first modification, for (I) above *** !)> (let* (.. . [result (% engine \n(let ([resuit (% engine (begin (ciock set true-ticks) (thunk)) (lambda (r k) (if (eq? r interrupt) (~cont~oi \nengine (lambda () (k #f))) r)))]) (set! tz cks-lefi (ciock stop)) ;; ... (II) (set! engine-succeeded? \n#t) result) (lambda (r k) (if (eg? r interrupt) (k #f) r)))]) ... ) A successful engine that finishes \nwith no ticks to spare and suffers an interrupt between the two prompts could stop the clock twice. To \navoid the second stop from setting the number of ticks left to infinity, the latter value must be coerced \nto zero: ... 1)) *** second modification, for (II) above *** (set! tzcks-lefl (zmfinity+O (clock stop))) \n. . . where mfindy+O is the function (lambda (n) (if (= n infinity) O n)). The engine currently run may \nbe a child engine, in which case care is needed when invoking the faziure op\u00aderations. If the child has \nno ticks left, the parent may resume with the ~aihtre action on the rest of the child. If the child does \nhave some ticks left, the child s fail\u00adure was not because the ticks supplied by the user were insufficient, \nbut because the fairness strategy curtailed its ticks. In the latter case, the parent must resume the \nchild when the parent runs again: .. . *** third modification, for (III) above *** ))> (cond [engme-sticceeded? \n(success resuit ttcks-lefi)] [(= tzcks-lefl O) (~ailure resuit)] [else ((make-engine result) ticks-lefi \nsuccess fazlure)]) . Engines can be forced to stop immediately, either with a success value or as a failure. \nFor a successful exit, use fcontrol tagged engine to transfer control and a success value to the engine \nprompt: (define engine-return (lambda (v) (fcontro~ engine v))) To block an engine, i.e., compel it to \nfail, use fcontrol to force an interrupt: (define engine-block (lambda () (fcontrol engine interrupt))) \n 3.3 The code for managing ticks A flat engine needs very little tick management. The variable true-ticks, \nintroduced in (ticks-prelude), is set to exactly the ticks argument supplied to the engine, since there \nare no parent engines. Some error-checking to ensure that there is no engine already running may be added: \n*** (tacks-prelude)flat engines ***for ~1~ (if (not (= (ciock stop) infinity)) (error engine Trying to \nnest engines! )) (let ([true-ticks ticks]) ... ) The (ticks-postlude) for flat engines is empty. For \nnestable engines, both the prelude and postlude codes are more elaborate. The algorithm first stops the \ncurrently active parent engine, if any, before running the new child engine. This yields the ticks left \nfor the parent infinity if there is no parent engine. For fair nesting, the child cannot be run beyond \nthe parent s remaining ticks, regardless of the ticks allotted to the child in the program. Thus the \nchild should be run for a number of ticks, true-tzcks, that is the minimum of the parent s remaining \nticks and the child s speciiied ticks. The variable chzld-ttcks-lefi is that part of the child s ticks \nnot accounted for by true-ticks, and should be remembered should the child be continued at sc,me later \ntime. Further, the time taken by the child is also counted against the parent thus, parent-ticks-le}t \nis the parent s ticks less the child s true ticks. ,,, *** (ticks-P~e/~de) for nestable engines *** (let \n([parent-ticks (clock stop)] [true-ticks (mtn parent-ticks tzcks)] [parent-tzcks-lefi (\u00ad parent-ttcks \ntrue-ttcks)] [chdd-tzcks-tefl (\u00ad ticks tr-ue-tzcks)]) . . . ) In the postlude, both the parent s and \nthe child s re\u00ad maining ticks are updated to include ttcks-lefl, a non\u00adzero number if the child finished \nsuccessfully before true-tacks ran out. The clock is reset to parent-t~cks\u00ad lefi, thereby restarting \nthe parent engine computation: ... *** (tzcks-Post/ude) for nestable engines *** )1) (set! parent-ticks-left \n(+ parent-tacks-left tzcks-lefi)) (set! ticks-lefi (+ ch~ld-ticks-lefl ticks-lefi)) (clock set parent-ticks-lefl) \n ... Backtracking through handling Control handling provides an accessible approach to Prolog-style \nbacktracking [1, 24]. Backtracking sol[ves a problem or goal by trying to solve its subgoals. If the \ngoal is a simple or atomzc goal, it is solved by matching it with statements or facts in a database. \nA goal that is solved is said to succeed. Given a query goal that is a conjunction of subgoals, the backtracker \nchecks if each subgoal succeeds. If the query is a disjunction, the backtracker checks if at least one \nof the subgoals succeeds, keeping track of the rest of the subgoals with a backtrack point. Should a \nsub\u00adgoal fail, the backtracker goes back to the dynamically closest backtrack point to try the next subgoal \nin that disjunction. If all such retries fail, the query as a whole fails. Implementing backtracking \nin Scheme provides an apt use of continuations. While purely functional solutions with goals returning \nboolean values are pos\u00adsible, such methods require that goals explicitly call success and failure procedures \nto allow resumption of subgoals at backtrack points. In contrast, Scheme approaches [5, 9] aim for more \nconcise and readable code using tail/cc-continuations to identify and jump to backtrack points. Control \nhandlers continue this tra\u00addition by simply using prompts to mark subgoals. 4.1 Unification and logic \nvariables An atomic goal is simply a predicate on terms, where terms are structured objects built from \nlogic variables, numbers, lists and other datatypes. An atomic goal is solved by unifying the term structures \ncomposing the goal against facts in the database. (The unification pro\u00adcess itself is a predicate: thus, \nthe unification of two terms is an example of an atomic goal. ) In this treat\u00adment, since our purpose \nis to study the backtracking capabilities provided by control handlers, we will not go into the details \nof implementing logic variables and unification in Scheme (refer [5, 9]). 4.2 Goals In this treatment, \na goal is a Scheme expression that throws (instead of just returning) the boolean jalse if it fails and \na true value if it succeeds. In addition, in the latter case, the continuation of the throw represents \na backtrack point if the goal is to be retried for an alter\u00adnate solution. Thus, the fail goal is simply \n(~controi goal #f). The true goal is not (~controi goal #t) but (begin (~contro~ goal #t) (~control goal \n#f)), since it should fail when retried. A goal is evaluated by running it in a prompt: the handler handles \nthe thrown continuation depending on whether the goal succeeded or failed. The thrown con\u00adtinuation is \nexactly the rest of the computation of the goal, in other words a representation of the backtrack point \nin the goal. A user query is evaluated like any other goal, viz., inside a prompt: if it succeeds, its \nlogic variables can be examined to see how the query was solved. 4.3 Disjunction and conjunction of \ngoals We now define10 disjunctions (or!) and conjunctions (and!) as syntactic extensions that take an \narbitrary sequence of goals as subexpressions. First, the disjunc\u00ad tion: (or! g...)= (% goal (begin (% \ngoal g (ret h (lambda (r k) (if T (begin 10The s~ntax rec helps define recursive functions: (rec f Z) \n= (let (~ *]) (set! j z) f). (fconhol goal #t) (% goal (k *) h)))))) (jcontrol goal #f)) (ret h (lambda \n(r k) (if r (begin (fconiroi goal #t) (% goal (k *) h)) (~control goal #f))))) Each subgoal g is tried \nsuccessively in a separate prompt. If g fails, its successor is tried, and so on. If, on the other hand, \ng succeeds, its handler sends a signal of success to the caller of the disjunctive goal. However, g s \nhandler notes that the disjunction should backtrack at g s own backtrack point before trying g s successors. \nIf all the subgoals fail, the disjunction itself fails. This is accomplished by throwing false after \ntrying all the goals. Conjunctions follow a related outline: (and!) E (begin (fcontrol goal #t) (~control \ngoal #f)) (and! gg2 . ..)\u00ad (% goal g (ret h (lambda (r k) (if r (% goal (and! g2 . ..) (ret h2 (lambda \n(r2 k2) (if r2 (begin (fcontroi goal #t) (% goal (k2 *) h2))) (% goal (k *) h)))) (fcontro/ goal #f))))) \nThe first clause of the definition of and! shows that a vacuous conjunction is synonymous with a true \ngoal. If subgoals are present, all of them should succeed for the conjunction to succeed. Each subgoal \ndecides whether the subgoals following it should be tried or not. If a subgoal g succeeds, its handier \ntries the conjunction of the remaining goals, g2, etc., but after noting that if these fail, g s own \nbacktrack point should be retried. If g fails, its handler should signal overall failure, without trying \ng s successors.  4.4 The cut The above implements pure Prolog. Often, either for efficiency or a procedural \nstyle, we need to prune the backtracking possibilities: Prolog s method is the cut ( ! ). The cut is \na goal that succeeds but has the side\u00adeffect of committing all the goal choices made from a certain cut \nentry point to the point of the cut. In Prolog, the cut entry is always the immediately enclos\u00ading disjunction, \nbut we can relax this restriction here. The syntax or! ! stands for disjunctions with a cut entry point. \n In our implementation, we simply add a handler tagged cut at the cut entry point. The cut itself is \na goal that succeeds at first, but on backtracking, jumps to the cut entry point with a failure signal. \n(or!! 9)= (let ([cut (lambda () (fcontrol goal #t) (fconfrol cut *))]) (% cut (or! g . ..) (lambda (r \nk) (jconirol goal #f)))) 5 Conclusion We have described a versatile control mechanism for programming \nlanguages that manipulate higher-order control. Control handling has been traditionally suc\u00adcessful in \nfirst-order control arenas. When extrapolated appropriately to languages with higher-order control, it \nis an important programming tool, affording clean and easy solutions for a wide range of control tasks. \nThus, this work bolsters our conclusion from studying denota\u00adtional models that control handling is an \nindispensable addition to any programming language with control op\u00aderators. Acknowledgment. I thank Matthias \nFelleisen and Bruce Duba for helpful discussions. References [1] W.F. Clocksin and C.S. Mellish. Programming \nin Pro\u00adlog. Springer-Verlag, 1981. [2] 0. Danvy and A. FilinskL Abstracting control. In Proc. 1990 ACM \nConference on Lisp and Functional Programming, pages 151-160, 1990. [3] B.F. Dubs, R. Harper, and D. \nMacQueen. Typing first\u00adclass continuations in ML. In Proc. 18th ACM Sympo\u00adsium on Principles of Programming \nLanguages, pages 163-173, 1991. [4] R.K. Dybvig and R. Hieb, Engines from Continu\u00adations. Journal of \nComputer Languages (Pergamon Press), 14(2):109-124, 1989. [5] M. Felleisen. Translit crating Prolog into \nScheme. Tech\u00adnical Report 182, Indiana University Computer Science Department, 1985. [6] M. Felleisen. \nA-v-CS: An Extended A-Calculus for Scheme. In Proc. 1988 Conference on Lisp and Func\u00adtional Programming, \npages 72-84, 1988. [7] M, Felleisen, The Theory and Practice of First-Class Prompts. In Proc. 15th ACM \nSyrnposZum on Principles of Programming Languages, pages 180 190, 1988. [8] R. Harper. Introduction \nto Standard ML. LFCS Re\u00adport Series ECS-LFCS-86-14, University of Edinburgh, 1986. [9] C.T. Haynes. Logic \nContinuations. J. Logic Program., 4:157-176, 1987. Preliminary version: In Proc, of the Third International \nConference on Logic Programming, July 1985, London, England, Lecture Notes in Com\u00adputer Science, Vol. \n225, Springer-Verlag, Berlin, 6i l\u00ad 685. [10] C.T. Haynes and D.P. Friedman. Abstracting Timed Preemption \nwith Engines. Jozwnai of Computer Lan\u00adguages (Pergamon Press), 12(2):109-121, 1987. Pre\u00adliminary version: \nEngines Build Process Abstractions. In Proc. Conference on Lisp and Functional Program\u00adming, 1985, 18 \n24. [11] C.T. Haynes and D.P. Friedman. Embedding Con\u00adtinuations in Procedural Objects. ACM Transactions \non Programming Languages and Systems, 9(4):245 254, 1987. [12] C.T. Haynes, D.P. Friedman, and M. Wand. \nObtaining Coroutines from Continuations. Journal of Computer Languages (Pergamon Press), 11(3/4):109 \n1 21, 1986. [13] R, Hieb and R.K. Dybvig. Continuations and Con\u00adcurrency. In Second ACM SIGPLAN Symposium \non Principles and Pract~ce of Para!iei Programming, pages 128-136, 1990. [14] P.J. Lanolin, A Correspondence \nbetween Algol 60 and Church s Lambda Notation. Commun. ACM, 8(2):89\u00ad101; 158-165, 1965. [15] J. McCarthy \net al. Lisp 1.5 Programmer s Manual. The MIT Press, 2nd edition, 1965. [16] R. Milner, M. Tofte, and \nR. Harper. The Definition of Standard ML. The MIT Press, Cambridge, Mas\u00adsachusetts and London, England, \n1990. [17] C. Queinnec and B. Serpette. A Dynamic Extent Con\u00adtrol Operator for Partial Continuations. \nIn Proc. 18th ACM Symposium on Principles of Programming Lan\u00adguages, pages 174-184, 1991. [18] J.C. Reynolds. \nDefinitional interpreters for higher\u00adorder programming languages. In Proc. ACM Confere\u00adnce, pages 717 \n740, 1972. [19] D. Sitaram and M. Felleisen. Control Delimiters and Their Hierarchies. Lisp and Symbolic \nComputation, 3(1):67 99, 1990. [20] D. Sitaram and M. Felleisen. Reasoning with Contin\u00aduations II: How \nto Get Full Abstraction for Models of Control. In Proc. 1990 Conference on Lisp and Ftmc\u00ad tioncd Programming, \npages 161 175, 1990. [21] D. Sitaram and M. Felleisen. Modeling Continuations without Continuations. \nIn Proc. 18th ACM Symposium on Principles of Programming Languages, pages 185 196, 1991. [22] G.L. Steele \nJr. Common Lisp: the Language. DigitaJ Press, 1984. [23] G.L. Steele Jr. Common Lisp: the Language. Digital \nPress, second edition, 1990. [24] L. Sterling and E. Shapiro. The Art of Prolog. The MIT Press, 1986. \n[25] J.E. Stoy and C. Strachey. 0S6: An Operating System for a Small Computer. Comp. J., 15(2):117-124, \n195\u00ad203, 1972. [26] G.J. Sussman and G.L. Steele Jr. Scheme: An inter\u00adpreter for extended lambda calculus. \nMemo 349, MIT AI Lab, 1975. [27] J. Rees W. Clinger et al. Revised Report on the Al\u00adgorithmic Language \nScheme, November 1991.  \n\t\t\t", "proc_id": "155090", "abstract": "<p>Non-local control transfer and exception handling have a long tradition in higher-order programming languages such as Common Lisp, Scheme and ML. However, each language stops short of providing a full and complementary approach&#8212;control handling is provided <italic>only</italic> if the corresponding control operator is first-order. In this work, we describe handlers in a higher-order control setting. We invoke our earlier theoretical result that all denotational models of control languages invariably include capabilities that handle control. These capabilities, when incorporated into the language, form an elegant and powerful higher-order generalization of the first-order exception-handling mechanism.</p>", "authors": [{"name": "Dorai Sitaram", "author_profile_id": "81100164410", "affiliation": "", "person_id": "PP31097001", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/155090.155104", "year": "1993", "article_id": "155104", "conference": "PLDI", "title": "Handling control", "url": "http://dl.acm.org/citation.cfm?id=155104"}