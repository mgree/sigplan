{"article_publication_date": "06-01-1993", "fulltext": "\n Real-Time Replication Garbage Collection Scott Nettlles and James O Toole Abstract We have implemented \nthe first copying garbage collector that permits continuous unimpeded mutator access to the original \nobjects during copying. The garbage collector incrementally replicates all accessible objects and uses \na mutation log to bring the replicas up-to-date with changes made by the mu\u00adtator. An experimental implementation \ndemonstrates that the costs of using our algorithm are small and that bounded pause times of 50 milliseconds \ncan be readily achieved. Keywords: real-time garbage collection, copying garbage collection, incremental \ncollection, concurrent collection, replication. 1 Introduction Garbage collector pauses are always annoying, \nbut for many applications they are intolerable. For example, smocthly Authors addresses: nettles@ cs.cmrr.edu, \nSchool of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, Pennsylvania \n15213. (412)268-3617 otoole@lcs.mit. edu, Laboratory for Computer Science, Massachusetts In\u00adstitute of \nTechnology, Cambridge, Massachusetts 02139. 617-253 -601[8 This research was sponsored by the Avionics \nLab, Wright Research and Development Center, Aeronautical Systems Division (AFSC), U. S. Air Force, Wnght-Patterson \nAl%, OH 45433-6543 under Contract F33615-90\u00adC-1465, Arpa Order No. 7597, by the Alr Force Systems Cornmamd \nand the Defense Advrmced Research Projects Agency (DARPA) under Contract F19628-9 1-C-0128, and by the \nDepartment of the Army under Contract DABT63-92-C-O012. The views and conclusions contained in this document \nare those of the authors and should not be interpreted as representing the official policies, either \nexpressed or implied, of the Defense Advanced Research Projects Agency or the U.S. Government. Permission \nto copy without fee all or part of this materiall is granted provided that the copies are not made or \ndistributed for direct commercial advantage, the ACM copyright notica and itha title of the publication \nand its date appear, and notice is given that copying is by permission of the Association for Computing \nMachinery. To copy otherwisa, or to republish, raquires a faa and/or specific permission. ACM-SlGPLAN-PLDl-6 \n/93/Albuquerque, N.M. e 1993 ACM 0-89791 -598 -41931000610217 . ..$1 .50 tracking a mouse in an interactive \ngraphics application re\u00adquires pause times of 50 milliseconds or less[5]. For garbage collection to be \nuseful in applications with real-time con\u00adstraints, pause times must be bounded. We have implemented \na garbage collector which provides real-time collection using anew technique. This technique is efficient \nand can provide such short bounded pause times. The key method used by real-time collectors is incremental \ncollection, in which garbage collection work is interleaved with mutation. For incremental collection \nto be possible, the garbage collector must sometimes suspend its work and per\u00admit the mutator to run, \neven though the collection algorithm has not completed. Previous work on incremental collection has focused \non techniques that required either special hardware or operating system support [12, 1], or in which \nthe extra overhead for the mutator was potentially very high [4, 16]. These algorithms are variants of \nBaker s algorithm [2] which uses a to-space invariant. The to-space invariant requires that the mutator \nuse only pointers into to-space. The cost of enforcing this restriction leads to the need for special \nhardware or operating system support. Instead of a to-space invariant, our method uses a from\u00adspace invariant \nwhich requires that the mutator use only the original from-space objects. The garbage collector incremen\u00adtally \nbuilds a consistent replica of the accessible objects. The modified colleetor invariant decouples the \nexeetttion of the garbage collector from the mutator, and permits the collector great flexibility in \nscheduling its replication activity. An early prototype of our implementation[14] demon\u00adstrated that \nreplication can be used for incremental collec\u00adtion but did not provide real-time response. It also did \nnot allow for a careful comparison of performance with stop\u00adand-copy collection. To demonstrate that \nour technique is practical and feasible for real-time collection, we have im\u00adplemented several variants \nof this technique for Standard ML of New Jersey (SMJJNJ). Our experimental collectors pro\u00advide excellent \nperformance with little runtime overhead. The real-time collector provides bounded pause times within \nthe limits needed by interactive applications. In the sections that follow, we introduce our general \nap\u00adproach, based on the new invariant. We provide a high-level explanation of our method and its fundamental \ncorrectness conditions. We then discuss the details of our experimen\u00adtal implementation and its real-time \nperformance goals. We present experimental results that show that the cost of the technique is low in \npractice and that pause times are well controlled. Finally, we discuss possible improvements to the implementation \nand suggest areas for further work. We as\u00adsume that the reader is familiar with the basics of copying \nand generational garbage collection, a survey may be found in Wilson [20], 2 Real-Time Replication Garbage \nCol\u00adlection Incremental collectors permit the mutator to resume execu\u00adtion before the collection has \ncompleted. The operations of the collector and the mutator may be interleaved. Thus the effects of the \ngarbage collector must not be observable by the language primitives used by the mutator. The standard \ntechnique used by copying garbage collectors to copy an object destroys the original object by overwriting \nit with a forwarding pointer. Therefore, incremental collectors that use the standard copying technique \nrequire the muta\u00adtor to use only the relocated copy of an object. Enforcing this to-space invariant typically \nrequires a read-barrier , as shown in figure 1. The implementation of read-barriers has consequently \nbeen the focus of much effort in incremental garbage collection work. barrier I I Fromspaca Tospaca , \n 1 read GC 1 t trap / Figure 1: A Read Barrier Protecting Tospace In contrast, our technique requires \nthe collector to replicate live objects without destroying the original objects. The mutator is able \nto continue accessing the original objects. This allows us to eliminate the read-barrier and modify the \nto-space invariant. However, our method requires a write\u00adbarrier because the mutator may continue to \nmodify objects after they have been replicated, A write-banier is much less costly to implement than \na read-bamier[lO]. Conceptually, the standard Copy operation can be made non-destructive by reserving \nan extra word in the object which is not observable by the mutator and which is used to store the forwarding \npointer. In our algorithm, the goal of the collector is to successfully replicate all live objects which \nare present in from-space by creating corresponding ~ read e Mutator write GC Log t I Figure 2: Replication \nand The Mutation Log objects in to-space . When this task is complete, the col\u00adlector replaces the roots \nof the mutator with pointers to their corresponding replicas in to-space, discards from-space, and terminates. \n2.1 Mutations are Logged After the collector has replicated an object, the original object may be modified \nby the mutator. If this happens, then the same modification must also be made to the replica before the \nmutator switches to using the replica. Therefore, our algorithm requires the mutator to record all mutations \nin a mutation log , as shown in figure 2. The collector must use the mutation log to ensure that all \nreplicas reach a consistent state by the time the collection terminates, The collector does this by processing \nthe log entries and applying mutations to the replicas. When the collector modifies a replica which has \nalready been scanned, it rescans the replica to ensure that any object referenced as a result of the \nmutation is also replicated in to-space. After a log entry has been processed in this way it may be discarded. \nThe cost of logging and of processing the mutation log depends on the application, and also the im\u00adplementation \nof logging. Mutation logging works best when mutations are infrequent or can be recorded without mutator \ncooperation. Mutation logging is also attractive whenever writes are already expensive or a mutation \nlog is required for other reasons. For example, generational collectors, per\u00adsistent data, and distributed \nsystems uswdly make mutation operations more expensive[13].  2.2 The Collector Invariant The invariant \nmaintained by the replication-based garbage collector is that the mutator can only access from-space \nob\u00adjects, that all previously scanned objects in to-space contain only to-space pointers, and that all \nto-space replicas are up-to\u00addate with respect to their original from-space objects, unless a corresponding \nmutation is recorded in the mutation log. This from-space invariant differs from standard collector invariants \nbecause it requires the mutator to continue using the original from-space objects. The from-space invariant \npermits the replicated objects to be in an inconsistent state, as long as the inconsistencies are recorded \nin the mutation log. It is because of these inconsistencies that the mutator must continue to use only \nthe from-space objects until the collection algorithm completes.  2.3 The Completion Condition The collector \nhas completed a collection when the mutation log is empty, the mutator s roots have been scanned, and \nall of the objects in to-space have been scanned. When these conditions have been met, the invariant \nensures that all objects reachable from the roots have been replicated in to-space, are up-to-date, and \ncontain only to-space pointers. When the collector has established this completion condition, it atomically \nupdates all roots of the mutator to point at their corresponding to-space replicas, discards the from-space, \nand renames to-space as from-space. 2.4 Limiting Pause Times In order to guarantee that the garbage \ncollector will only pause the mutator for a bounded time, the collection algo\u00adrithm must somehow limit \nits execution. If the algorithm has not completed when the maximum pause time has passed, the collector \nmust stop work and permit the mutator to conti]nue executing. The replication-based algorithm described \nhere can sus\u00adpend execution at any time, and is suitable for concurrent implementation (see section 6). \nHowever, the actual mech\u00adanisms that can be used to control the duration of garbage collection pauses \nare implementation dependent, and are dis\u00adcussed in section 3.3. 2.5 Optimization Opportunities The \nfrom-space invariant used by this algorithm is very weak, in the sense that the collector never needs \nto work on any particular task in order to allow the application to execute. The collector only needs \nto replicate all the live data soon enough to terminate and reuse the memory in from-space before the \napplication runs out of memory. In the algorithm of Appel, Ellis, and Li[l], the application may frequently \nbe blocked waiting for the collector to copy the objects that it must use. We believe that the flexibil\u00ad \nity of our invariant offers potentially important optimization opportunities to any replication-based \nimplementation. For example, the collector can copy objects in essentially any desired order. This freedom \nin copying order could be used to increase locality of reference or to change the representation of \nobjects stored in a cache[17]. Another way that copying order free\u00ad dom can be exploited is by concentrating \nearly replication work on objects reachable from particular roots. Particular roots may be more likely \nto change than others, so copying them later could reduce the amount of latent garbage copied by the \ncollector. Also, if no mutable objects have been replicated then the collector need not apply mutations \nto replicas. The collector could choose to concentrate early replication effort on only immutable objects, \nand thereby delay the need to process the log until the last possible moment. The actual copying of an \nobject can be delayed until the object is scanned using an optimization suggested by Ellis[9]. The collector \ncould replicate mutable objects into a segregated portion of the to\u00adspace, and delay copying and scanning \nmutable objects as long as possible. Mutation log entries created before the first mutable object was \nactually copied could be discarded.  3 Implementation To test the practicality of our new approach, \nwe implemented a real-time garbage collector using the replication-based al\u00adgorithm, The collector is \ndesigned to show that pause times can be limited and to permit accurate comparison with an existing stop-and-copy \ncollector. The experimental collector operates in the runtime system of Standard ML of New Jersey, which \nuses a two-level generational heap design. The collec\u00adtor uses the replication algorithm for both minor-incremental \nand major-incremental collections, which share the imple\u00admentation of object replication and mutation \nlogging. The major and minor collectors differ in when collections are initiated and how their execution \nis controlled. The real\u00adtime collector can be operated with the incremental algorithm enabled for one \nor both of the two generations present in the original SML/NJ collector. The experimental results pre\u00adsented \nin section 4 use results from various configurations to quantify the costs of the replication method \nand the pause time behavior for several benchmarks. 3.1 The SML/NJ Runtime System We chose SML/NJ (version \n0.75) for our work primarily because it has a good compiler and a simple generational garbage collector. \nSince the runtime system has no stack, heavy demands areplaced on the storage allocation and recla\u00admation \nsystem. Providing real-time garbage collection is therefore challenging. However, the SML language encour\u00adages \na mostly functional programming style, so mutations are rare. This is advantageous to our technique. \nIn the SML/NJ collector, there are two generations, old and new. Objects are allocated in new-space. \nWhen new-space fills, a minor collection is initiated which copies the live data into old-space. The \nsize of the new-space is controlled by the runtime parameter N. Another parameter, O, controls the initiation \nof a major collection. When the amount of memory copied into the old space by minor collections exceeds \nO, a major collection occurs, copying all live data into to-space and then exchanging the roles of to-space \nand old-space. 3.2 Replication and Logging Generational collectors must identify mutations that might \ncreate pointers from old-space into new-space. The SML/NJ 219 Figure 3: SML/NJ Heaps with GC Parameters \ncollector uses a log called the storelist to track such mu\u00adtations. The replication-based algorithm needs \nto log all mutations to the contents of a previously replicated object. We modified the SMUNJ compiler \nso that all mutations are recorded in its storelist. The most straightforward implementation of non\u00addestructive \ncopying is to store a forwarding pointer to the replica in an extra word in each object. However, measure\u00adments \nof the SML/NJ system suggest that most objects are only three words long, including the object header \nword used to store certain type and length information. This means that the overhead of allocating an \nextra word per object would be prohibitive. Therefore in our implementation we overwrite the object header \nword with the forwarding pointer. Fromspace Tospace Figure 4: Getheader Operations Follow the Forwarding \nWord Our implementation must ensure that the replacement of the objeet header word is not observable \nby the mutator. The mutator accesses the object header word only during the polymorphic equality operator \nand certain type-specific length operations. We modified the compiler to implement these operations by \nchecking for the forwarding pointer and reading the object header word from the replica when nec\u00adessary. \nThis slows down these operations without imposing an overhead on normat read access to object contents. \nWe also modified all runtime system call operations which mod\u00adify ML data (e.g. 1/0 primitives) to perform \nappropriate logging. 3.3 Controlling Pause Duration In SML/NJ the pauses due to major collections are \nthe longest and most disruptive. The real-time collector uses the incre\u00admental algorithm to eliminate \nthese pauses. The incremental algorithm is enabled when the O parameter tirst triggers a major collection. \nEach time a minor generation collection occurs, the major-incremental collector performs some work after \nthe minor collector terminates. This approach slightly increases the pause times for minor collections \nand com\u00adpletely eliminates the more disruptive major pause times. In order to control the total pause \ntime caused by the com\u00adbined minor and major collections, the incremental algorithm restricts the amount \nof work it does using a parameter, L. The L parameter limits the total amount of memory copied by the \ncollections during a single pause. However, only the incre\u00admental algorithm respects the work limit L. \nIf the minor collection has exceeded the copy limit L, then the major-incremental algorithm processes \nthe mutation log, but does not perform any additional replication work. There\u00adfore, when L is very small, \nthe major-incremental collection may not terminate. There is an implementation-dependent lower bound \nfor L that will guarantee termination, but such a conservative completion strategy increases the total \ncost of garbage collection [14]. 3.4 The Real-Time Collector Minor collection pauses are usually short, \nbut may not be bounded by L. Therefore, to bound these collection pauses, the real-time collector uses \nthe incremental algorithm for mi\u00adnor collections as well as for major collections. When the work limit \nL is exceeded during a minor collection, the col\u00adlector suspends execution and returns control to the \nmutator. In this case, new-space must be expanded in order for the mutator to allocate more objects. \nCurrently the implemen\u00adtation expands new-space by a parameter A, whenever any incremental collection \nis awaiting completion. For a minor collection the log contains pointers into the old heap which are \nroots. Our technique requires that all roots be atomically updated at the time of a flip. For minor flips \nthis requires an additional traversal of the log to update the roots in the old heap. At this point the \nlog has been filtered so that it includes only the pointer related mutations as only these entries are \nroots. Our real-time collector does not yet offer an absolute guar\u00adantee of bounded pause times. First, \nthe implementation makes no attempt to shield the mutator from page faults, 1/0, swapping, and other \nsystem effects. Second, the current implementation does not incrementally copy a single large object. \nnor does it incrementally process the mutation log. Therefore, these operations can exceed the work limit \nL. If necessary, these operations can easily be implemented so that they are performed incrementally \nand respect the work limit.   4 Performance The goals of the performance study were to demonstrate \nthat pause times are bounded and to measure the overheads im\u00adposed by our technique. The measured performance \nis good; the real-time collector achieves short pause times with an acceptable overhead. In addition \nto the basic measurements of pause and execution times, we also undertook a series of experiments to \nquantify the contributions of various factors to the overhead. 4.1 Benchmarks Three benchmmks were used \nto test our implementation. Each was chosen because it stressed the memory manage\u00adment system in a different \nway. All benchmarks require several minutes to execute and require many major and mi\u00adnor garbage collections \nduring execution. See [6] for more details about these benchmarks. Primes is a prime number sieve implemented \nin a simple lazy language which is in turn interpreted by an SML program. It allocates memory at a very \nhigh rate (ap\u00adproximately 10Mb/see), but few objects survive garbage collection. It is typical of compute-bound \nprograms in SMLiNJ, Comp is the SML/NJ compiler compiling a portion of itself. This is the most realistic \nbenchmark; the SML/NJ compiler is a large optimizing compiler and is in daily, production use. Comp does \nnot allocate as much data as Primes, but more of it survives collections. The amount of live data fluctuates \ndepending on the phase of the compilation. Sort is a sorting program based on futures which are in turn \nimplemen&#38;l u~ing SML threads. Sort does more mutation than a typical SML program and it creates a \nlarge amount of live data. Both the large mutation rate and the substantial survival rate make this a \nchallenging example for our technique. All benchmarks were executed on a Decstation 50001200 with 64 \nMb of physical memory running the Mach 2.5 oper\u00adating system. The system has a 25 MHz clock and separate \n64Kb instruction and data caches. For the pause time meas\u00adurements the system clock resolution was set \nto 4ms. 4.2 Parameter Settings To test our system we chose values for the parameters N, O, L and A. For \nOwe used the values 5Mb and lMb. The larger value is typical for running SML/NJ in our environment, while \nthe lower setting was chosen to emphasize overheads present in major collections. For N we chose lMb \nand 0.21Vfb. Again, the larger value is typical for use with the stop-amd\u00adcopy collector. The lower setting \nwas chosen because it atlowed us to achieve pause times of 50 milliseconds yet still have the collector \nterminate. We chose 50 milliseconds as our target pause time because this is the maximum pause time which \nwill allow an interactive program to smoothly track a mouse[5]. When N is 0.2Mb we set L to O.lMb and \nwhen N is lMb we set L to 0.5 Mb. The value of O.lMb was chosen because that is approximately how much \ndata the collector can copy in 50 milliseconds, while the value of 0.5Mb was chosen somewhat arbitrarily. \nA was chosen to be L/2. This guarantees that the collector will make progress when an incremental collection \nis active. We also ran our benchmarks with other values of L but those results are not particularly illuminating \nand have been omitted due to lack of space (see [19] for more details). In general, as L increases, pause \ntimes increase and duration of collections decrease. Any overheads that are related to collection duration \ndecrease. In this study we are concerned with quantifying the over\u00adheads of adding replication-based \ncollection to the system, rather that studying what polices should be used to control such a collector. \nSince the choice of policy can strongly influence performance we controlled for it in the following way. \nUsing the parameters above, the real-time collector was run in such a way as to produce a script of exactly \nwhen it flipped and how much new allocation space it returned. These scripts were then used to replay \nthese policy decisions for all benchmark runs. This ensures that the differences we measured were those \nimposed by our mechanism rather than variations caused by different policy decisions. We measured the \noverhead caused by this replay method and found it to be smaller than the margins of error (approximately \n270) typical in our benchmark runtimes.  4.3 Pause Times The primary motivation for using a real-time \ngarbage collec\u00adtor is to provide bounded collector pause times. In this section we present the measurement \nresults for our benchmarks. Short GC Pauses dumg Comp Benchnwk 2500 - 1 ! I I Stop and COPy (S+C) 4- \nReal-Time (RT) -t-\u00ad 2000 / <, : 1000 Figure 5: Compiler Benchmark (N=O.2Mb, O=lMb) Figure 5 shows \na plot of pause times for both the stop\u00adand-copy collector and the real-time collector running Comp with \nO= lMb and N=200Kb. The real-time collector has a maximum pause of 84ms and the peak at 50ms represents \n991 ,2/2. Long GC Pauses dumg ComF Benchrmmk 5 1 I 1 1 1 1 1 1 Stop and COpy (S+C) 4 1 t 100 200 300 \n400 50 3 600 700 S00 900 10@3 Pause Tme (mlhseconds) Figure 6: Compiler Benchmark (N=O.2Mb, O=lMb) the \nresult of truncating the longer stop-and-copy pauses to that value. Figure 6 shows the longer pauses \nof the stop-and\u00adcopy collector which our technique eliminated. Note that during this 245 second long \nrun the stop-and-copy collector causes a pause longer than 0.5 seconds approximately every 20 seconds. \nTable 1 summarizes the rest of the pause time data. The table shows the the median pause time, the 99% \npercentile pause time, and the maximum pause time. These measures show that the real-time collector is \nsuccessful at bounding the pauses, and that in exchange the duration of many shorter pauses increase \nslightly. 4.4 Elapsed Times l%e real-time collector is clearly successful at providing bounded pause \ntime, but at what cost in performance? A diagram of the component costs of elapsed time in our imple\u00admentation \nis shown in figure 7. Several of the costs, such as latent garbage and the generational scan of pointer \nmutations, are shared by any incremental and/or generational collector, and are not peculiar to replication \ngc. These overheads will be explored in some detail in the following section. To determine total overhead, \nwe measured our benchmarks using a variety of configurations: the full real-time collec\u00adtor, the real-time \ncollector with only minor collections done incrementally, the real-time collector with only major collec\u00adtions \ndone incrementally, the stop-and-copy collector with the compiler changes for real-time collection and \nthe stop\u00adand-copy collector without those modifications. Figures 8, 9, and 10 summarize this data. In \ngeneral the overhead for the most realistic benchmzwk, Comp, is under 10%. We consider this overhead \nacceptable. Even Sort, the most demanding benchmark, shows overheads under 2570. Note that the cost of \ndoing minor-only incremental is essen\u00adtially the full cost of real-time collection. We do not have a \ngood explanation of why in some cases this cost is larger than for the full real-time collector, but \nin later sections we Primes ON Stop+copy Real-Time Mb Mb 50% 99% Max 50% 99% Max Comu.. 1 ON Stop+copy \nReal-Time Mb Mb soy. 99% Max 50% 99% Max L 10.2 8 36990 12 64 86 1 1.0 28 148 934 36 292 314 5 0.2 12 \n36 778 12 60 74 5 1.0 32 120 450 36 260 294  sort ON Stop+copy Real-Time Mb Mb 50% 99% Max 50% 99% \nMax Table 1: Garbage Collection Pause Times (msec) Elapsed Time A *A    I @ a . ..-.-.. .. Gener&#38; \nional Logging Scan Pointer Mutations Reapply Mutations Figure 7: Components of Execution Time will \nsee why it should be essentially the same. Real-Time o Minor-Incremental Major-Inerementat Stop + COpy \nw/Mods + 0 X 4.5 Overheads Due to Compiler Modifications 25% II 20% 15% ++ 10% 5% o% Figure 8: Primes \nBenchmark 25% I, 20% 15% + 10%-e $ 5%-x x ()% ~ Elapsed the 176 199 N 130 0.2 05 Figure 9: Compiler \nBenchmark: 25% 1 1 $ 20% $ + g z 15% ~ VY E 8 tt!2, 10% 0 5% - El x x o%~ Elapsed Time 206 233 N 1.0 \nLo o 5 1 Figure 10: Sort Benchmark 1r Primes + ? Elapsed Times t 1 Comp 0+ : x x 209 245 secmds 1.0 \n0.2 Mb 1 1 Mb Elapsed Times 1f sort ?: EI 0 x 235 270 x seconds 0.2 0.2 Mb 5 1Mb Elapsed Times The compiler \nmodifications which were needed to support our technique impose two overheads on the compile~ testing \nheaders for forwarding words and adding extra records to the log. The extra log records also impose an \noverhead on the garbage colleetor. To measure these overheads we ran the stop-and-copy collector with \neach of these modifications enabled separately, We were unable to measure the cost of testing for the \npresence of forwarding pointers, leading us to conclude that it is negligible, or at most a few percent. \nThe cost of the extra log entries accounted for essentially all of the overhead due to the compiler modifications. \n Examining the entries in figures 8, 9,and 10, we see that the overhead of these additional records is \nessentially O% for Primes and near 5% for Comp and Sort. This is easily explained by following observations. \nPrimes does almost no mutations and so should see no overhead. Sort mostly mutates integer references \nwhich the compiler normally does not place on the log, while Comp contains many mutations to byte data \nwhich is likewise normally not logged. Perhaps the overhead due to these non-pointer mutations could \nbe reduced either by forwarding them to to-space during mutation instead of logging, or by using other \nlogging techniques. We have not yet made separate measurements of the mutator and garbage colleetor costs. \nPrimes [ ON CR %CR CF %CF (Mb) (Mb) II (sees) (sees) 1 0.2 II 7,0 2.3 14.1 4.7 I 1 1.0 6.4 2.7 21.2 9.0 \n 5 0.2 5.7 2.0 14.7 5,1 5 1.0 II 6.1 2.6 21.4 9.2  Comp ON CR %CR CF %CF (Mb) (Mb) (sees) (sees) 1 \n0.2 3.3 1.3 3.7 1.4 1 1.0 3.0 1.3 4.6 2.0 5 0.2 3.1 1.4 3.9 1.8 5 1.0 2.5 1.3 4.7 2.4  sort ON CR \n%CR CF %CF (Mb) (Mb) (sees) (sees) 1 0.2 5.3 1.7 10.2 3.2 1 1.0 4.8 1.7 14.2 5.0 3.6 5 0.2 4.3 1.6 \n10.0 5 1.0 4.6 1.8 13.9 5.6  Table 2: Log processing costs 4.5.1 Processing the Mutation Log Two costs \nof our technique which are not shared by other incremental or generational collectors are the costs of \nreap\u00adplying mutations to to-space and of atomically updating roots found in the log during a minor flip. \nTo measure this cost we repeatedly processed the mutation log in order to increase the overhead to a \nmeasurable level, both with and without the reapplication of mutations enabled. This allowed us to distinguished \nthe two cases described above. Figure 2 presents these results. CR is the cost of reapply\u00ading the mutations \nin seconds and %CR is the percentage cost relative to that of the real-time collector. CF is the cost \nof atomically flipping the roots in seconds and 9ZOCFis percent relative to real-time collection. The \ncost of actually forward\u00ading the stores is generally small and is always smaller than the cost of the \natomic flip. If the minor collection need not be incremental then the flip cost may be avoided. It is \nalso possible that improving the data structures used to represent the mutation log would reduce this \ncost. This data, along with the measurements of overheads due to compiler modifi\u00adcations also reveals \nwhy the minor-incremental collector has essentially the same performance as the real-time collector. \nThe minor-incremental collector shares all these costs with the real-time collector, and these costs \ndominate. 4.5.2 Latent garbage One potential overhead for any incremental collection algo\u00adrithm is that \ndata considered live by the collector may die before the collector terminates. This latent garbage increases \nthe overhead of collection since it must be copied and it leaves less free memory to be used by the allocator. \nTo measure this effect we compared the amounts of data copied by the stop\u00ad and-copy collector and the \nreal-time collector. Because the flips and allocation amounts were exactly synchronized the difference \nbetween the two is the latent garbage. Table 3 shows our measurements of latent garbage both in Kb (G) \nand as percentage of the true live data (% G). We also estimate the cost of copying this much data in \nseconds (CG). Our cost estimates are based on measurements of the rate at which the collector copied \ndata. These measurements show atypical copying rate of approximately 2Mb/sec. This corre\u00adlates well with \nthe fact that L = 100Kb gives 50 millisecond pause times. We see that the amount of latent garbage is \ngeneratly a small fraction of the total amount of data copied. The abso\u00adlute amount of latent garbage \ngoes down both with increasing N and O. For O this is because there are fewer collections to create latent \ngarbage. For N it is because for these mea\u00adsurements increasing N increases L. When L increases the incremental \nalgorithm terminates more quickly and there is less latent garbage. These measurements suggest that latent \ngarbage is not an important contributor to the overheads in our current tests. However, different policies \nwith respect to when to begin collection and how rapidly to complete it may Primes G %G CG (M; (M; (Kb) \n(sees) 1 0.2 739 0.5 0.4 1 1.0 0 0.0 0.0 5 0.2 159 0.1 0.1 5 1.0 0 0.0 0.0  Comp G %G CG (M: (M; \n(Kb) (sees) 1 0.2 7556 3.6 3.9 1 1.0 6247 4.1 3.2 5 0.2 5561 1.6 2.8 5 1.0 1723 1.9 0.9  sort G %G \nCG (M: (M; (Kb) (sees) 1 0.2 5561 1.6 2.8 1 1.0 4115 1.5 2.1 5 0.2 1237 0.4 0.6 5 1.0 998 0.4 0.5 \n Table 3: Latent garbage amounts make this effect more important.  5 Related Work The real-time copying \ncollector by Baker[2] first proposed the condition that object accesses somehow be redirected to the \nrelocated copy of the object. The work of Ellis, Li, and Appel[l] exemplifies the use of virtual memory \ntraps and other operating system support to implement similar condi\u00adtions. A method due to Brooks[4], \nand later implemented by North [161, requires the mutator to follow a forward\u00ading pointer which leads \nto the relocated object. Nilsen[15] describes a software implementation of Baker s algorithm which is \ndesigned for an environment in which strings are heavily used. The overhead of his technique seems to \nbe prohibitive in a more general context. Recent work by Boehm, Demers and Shenker [3] on a con\u00adcurrent \nmark-and-sweep collector promises real-time perfor\u00admance. As in our algorithm, a form of mutation logging \nis used by the collector to track changes made by the mutator. The mutation log is implemented by periodically \nsampling the dirty page bits maintained by the virtual memory sys\u00adtem. Live objects are not relocated, \nbut rather are marked non-destructively. Therefore, GC efforts can be interleaved freely with mutator \noperations, but the compaction possible in copying collectors is unavailable. The authors observed the \npossibility of using a from-space invariant for a copying collector. Two recent collectors for ML are \nquite closely related to ours. However, both depend on the semantics of ML mc~re closely than our work. \nDoligez and Leroy [8] have implemented a concurrent col\u00adlector which uses a mixed strategy to provide \ncollection for a multithreaded version of CAML. Immutable objects are al\u00adlocated in private heaps which \nare collected by a replicaticm\u00adbased stop-and-copy collector. This collector copies vatues into a shared \nheap which is collected using a concurrent mark-and-sweep algorithm based on Dijkstra[7]. To avoid the \nissue of inconsistent mutable values all such objects are allocated in the shared heap. If mutations \nto such a value cause other values which currently reside in a private heap to become reachable from \nthe shared heap, these values are copied into the shared heap at the time of mutation. IIe use of replication-copying \nallows the original owner of these values to continue to access the copy in the private heap. Huelsbergen \nand Larus[l 1] have recently built a concur\u00adrent collector for SML/NJ which uses replication-based copy\u00ading. \nThey use a to-space invariant and a consistency protocol which requires that the mutator read and write \nthe to-space version if it exists. Our previous work[14] considers this pro\u00adtocol, the from-space invariant \nand other consistency options for replication garbage collection. In addition to maintaining a to-space \ninvariant, their collector has a number of otlher differences from our own, Their collector is not generational \nwhich leads to a slow down relative to the original SML/NJ collector (despite the use of multiple processors) \nand makes it difficult to directly assess the overhead of their technique. Less important their implementation \ndoes not merge forward\u00ading pointers with header words and thus has a substantial space penalty. Also \ntheir implementation is more closely tied to the semantics of mutable vatues in SML and to the de\u00adtails \nof their processor memory consistency model. We hope to implement their technique along with others from[141 \nin the context of a concurrent version of the collector described here. This will allow a quantitative \ncomparison of these options. 6 Future Work and Conclusions We are actively extending the current work \nin severat dire\u00adctions. Our experimental implementation is perfectly suited for use as a concurrent collector. \nThe replication primitive can be interleaved freely with mutator activity, as long as the memory system \nprovides single-word memory atonnic\u00adity. Synchronization between the collector and the mutator is only \nrequired for transferring the mutation log and updating the roots. The concurrent version of this implementation \nis working and initial performance measurements can be found in [18]. Replication-based copying is also \na promising apprcnch for use in heap based transaction systems. In addition to the advantages concurrent \ncollection has for such systems a fur\u00ad ther advantage is that such systems also must log all mutation \nto transactional data. Replication-copying is thus even more attractive. We are currently working on \nextending the con\u00adcurrent collector implementation to support a transactional persistent heap[13]. An \narea which we have not yet explored is what policies are best suited for use with our collector. For \nexample in an interactive system, our technique would allow collection to proceed while the system was \nwaiting for input. If such pauses are long enough or frequent enough collection may become essentially \nfree. On the other hand when running compute bound jobs it may make no sense to pay even the small cost \nof incremental collection since such jobs already introduce lengthy pauses. Conclusions We have designed \nand implemented a real-time garbage col\u00adlector using anew replication-based invariant. This invariant \neliminates the need for a read-barrier, and therefore enables real-time garbage collection on stock hardware \nwith low mu\u00adtator overhead. We have examined various overhead costs in an implementation that relies \non mutator cooperation for logging. Our experimental implementations show that con\u00adtrolled pause times \nof 50 milliseconds can be readily achieved in practice this satisfies the requirements for most interactive \napplications. Acknowledgments Thanksto the DEC Systems Research Center for support as summer interns \nin 1990,at which time this idea was originally conceived, to David Pierce and Nicholas Haines for their \ncon\u00adtributions to the original implementation, and to John Reppy for his suggestion to merge the forwarding \npointer and header word. Plenty of thanks goes to the facilities staff at CMU, in particular Alessandro \nForin and Dale Moore, for provid\u00ading timely assistance adjusting the clock resolution. Thanks also to \nour readers: Andrew Myers, Mark Day, Greg Mor\u00adrisett, Nicholas Haines, Richard Lethin, John Keen, Amer \nDiwan, David Tarditi, Brian Milnes, Ali-Reza Adl-Tabatabai and David Gifford. References [1] Andrew \nW. Appel, John R. 1311is,and Kai Li. Real-time Con\u00adcurrent Garbage Collection on Stock Multiprocessors. \nIn SIG-PL4N Symposium on Programming Language Design and Implementation, pages 11-20,1988. [2] H. G. \nBaker. List Processing in Real Time on a Serial Com\u00adputer. Communications of the ACM, 21(4):280-294, \n1978. [3] Hans-Juergen Boehm, Atan J. Demers, and Scott Shenker. Mostly Parallel Garbage Collection. \nIn SIGPLAN Sympo\u00adsium on Programming Language Design and Implementation, pages 157-164,1991. [4] Rodney \nA. Brooks. Trading Data Space for Reduced Time and Code Space in Real-Time Garbage Collection. In SIGPLAN \nSymposium on LISP and Functional Programming, 1984. [5] Stuart K. Card, Thomas P. Moran, and Allen Newell. \nThe Psy\u00adchology of Human-Computer Interaction. Lawrence Erlbaum Associates, Hillsdale, NJ, 1983. [6] \nEric Cooper, Scott Nettles, and Indira Subramanian. Im\u00adproving the Performance of SML Garbage Collection \nusing Application-Specific Virtual Memory Management. In Pro\u00adceedings of the ACM Conference on Lisp and \nFunctional Pro\u00adgraming, pages 43 52, June 1992. [7] E. Dijkstra, L. Lampo@ A. Martin, C. Scholten, and \nE. Stef\u00adfens. On-the-fly Garbage Collection:An Exercise in Coopera\u00adtion. Communications of the ACM, 21(11 \n):966 975, Novem\u00adber 1978. [8] D. Doligez and X. Leroy. A concurrent generational garbage collector for \na multi-threaded implementation of ml. In Pro\u00adceedings of the 1993 ACM Symposium on Principles of Pro\u00adgramming \nLanguages, pages 113 123, January 1993. [9] John R. Ellis, Kai Li, and Andrew W. Appel. Real-time Con\u00adcurrent \nGarbage Collection on Stock Multiprocessors. Techni\u00adcal Report DEC-SRC-TR-25, DEC Systems Research Center, \nFebruary 1988. [10] Antony L. Hosking, J. Eliot B. Moss, and Darko Stefanovic. A comparative performance \nevaluation of write barrier im\u00adplementations. In Proceedings of the 1992 Conference on Object-Oriented \nProgramming Systems, Languages, and Ap\u00adplications, 1992. [11]Lorenz Huelsbergen and James R. Larus. A \nconcurrent copying garbage collector for languages that distinguish (immutable data. In Proceedings of \nthe 1993 ACM Sym\u00adposiym on Principles and Practice of Parallel Programing, 1993. To appear. [12] David \nA. Moon. Garbage Collection in a Large Lisp Sys\u00adtem. In Proceedings of the 1984 ACM Symposium on Lisp \nand Functional Programming, pages 235 246. ACM, August 1984. [13] Scott M. Nettles, James W. O Toole, \nand David K. Gifford. Concurrent garbage collection of persistent heaps. Tech\u00adnical Report MIT-LCS-TR-569 \nand CMU-CS-93-137, Mas\u00adsachusetts Institute of Technology and Carnegie Mellon Uni\u00adversity, 1993. Submitted \nto 14th Symposium on Operating Systems Principles. [14] Scott M. Nettles, James W. O Toole, David Pierce, \nand Nicholas Haines. Replication-Based Incremental Copying Collection. In Proceedings of the SIGPLAN \nInternational Workshop on Memory Management, pages 357 364. ACM, Springer-Verlag, September 1992. Also \navailable as Carnegie Mellon University Technical Report CMU-CS-93-135. [15] K. Nilsen. Garbage Collection \nof Strings and Linked Data Structures in Real-time. Software-Practice and Experience, 18(7):613-640, \nJuly 1988. [16] S. C. North and J.H. Reppy. Concurrent Garbage Collec\u00adtion on Stock Hardware. In Gilles \nKahn, editor, Func~ional Programming Languages and Computer Architecture (LNCS 274), pages 113 133. Springer-Verlag, \n1987. [17] James W. O Toole. Garbage Collecting an Object Cache. Technical Report MIT/LCSnM-485, Massachusetts \nInstitute of Technology, April 1993. To appear. [18] James W. O Toole and Scott M. Nettles. Concurrent \nReplica\u00adtion Garbage Collection. Technical Report MlT-LCS-TR-570 and CMU-CS-93 -138, Massachusetts Institute \nof Technology and Carnegie Mellon University, 1993. [19] James W. O Toole and Scott M. Neffles. Real-Time \nReplica\u00adtion GC: An Implementation Report, Technical Report MIT\u00adLCS-TR-568 and CMU-CS-93-136, Massachusetts \nJ.nstitute of Technology and Carnegie Mellon University, 1993. [20] PaulR. Wilson. Uniprocessor Garbage \nCollection Techniques. In Proceedings of the 1992 SIGPLAN Interna~ional Workshop on Memory Managemen~, \npages 142. ACM, Springer-Verlag, September 1992.  \n\t\t\t", "proc_id": "155090", "abstract": "<p>We have implemented the first copying garbage collector that permits continuous unimpeded mutator access to the original objects during copying. The garbage collector incrementally replicates all accessible objects and uses a mutation log to bring the replicas up-to-date with changes made by the mutator. An experimental implementation demonstrates that the costs of using our algorithm are small and that bounded pause times of 50 milliseconds can be readily achieved.</p>", "authors": [{"name": "Scott Nettles", "author_profile_id": "81100150673", "affiliation": "", "person_id": "PP14062810", "email_address": "", "orcid_id": ""}, {"name": "James O'Toole", "author_profile_id": "81100388575", "affiliation": "", "person_id": "P133165", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/155090.155111", "year": "1993", "article_id": "155111", "conference": "PLDI", "title": "Real-time replication garbage collection", "url": "http://dl.acm.org/citation.cfm?id=155111"}