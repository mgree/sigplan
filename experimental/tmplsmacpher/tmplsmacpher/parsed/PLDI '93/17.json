{"article_publication_date": "06-01-1993", "fulltext": "\n Using Lifetime Predictors to Improve Memory Allocation Performance David A. Barrett and Benjamin G, \nZorn Department of Computer Science Campus Box #430 University of Colorado, Boulder 80309-0430 Abstract \nDynamic storage allocation is used heavily in many application sr\u00adeas including interpreters, simulators, \noptimizers, and translators. We describe research that can improve all aspects of the perfor\u00admance of \ndynamic storage allocation by predicting the lifetimes of short-lived objects when they are allocated. \nUsing five significant allocation-intensive C programs, we show that a great fraction of all bytes rdlocated \nare short-lived (> 90% in all cases). Furthermore, we describe an algorithm for lifetime prediction that \naccurately pre\u00addicts the lifetimes of 42-99% of rdl objects allocated. We describe and simulate a storage \nallocator that takes advantage of lifetime prediction of short-lived objects and show that it can significantly \nimprove a program s memory overhead and reference locality, and even, at times, improve CPU performance \naswell. 1 Introduction Dynamic storage allocation (DSA) is used heavily in many ap\u00adplication areas including \ninterpreters, simulators, optimizers, and translators. Furthermore, object-oriented programming languages, \nsuch as C++, encourage a programming style that uses more dy\u00adnamic memory allocation than their predecessors. \nBut dynamic storage allocation has been criticized because it is not as efficient as static allocation \n[17, p. 465]. Indeed, programmers frequently write their own domain-specific allocation routines to attempt \nto increase the performance of their programs [22]. In this paper we describe and investigate a method \nfor improving the performance of dynamic storage allocation that automates the process that pro\u00adgrammers \ncurrently use to increase allocation performance: tune the allocation strategy to the behavior of the \nprogram. Programmers often use runtime profiles to snrdyze the behavior of atypical execution of their \nprogram. This snalysisreveals perfor\u00admance bottlenecks that include calls to a dynamic storage allocator \n(e.g., the malloc function in C, or the new operator in C++). The programmer then snalyzeswhich calls \nto the memory sllocatormay be customized by a special purpose routine and writes one that is specifically \ntuned for these allocation events. In sho~ our research is an exercise in automating this process using \nthe general technique of projile-based optimization. With profile-based opdmization, programs areexecutedwith \ntraining sets oftestdatasndbehaviorrd aspectsoftheprogramsarerecorded.Af- Permission to copy without \nfee all or part of this material is granted provided that the copies ara not made or distributed for \ndirect commercial advantage, the ACM copyright notica and the title of tha publication and its date appear, \nand notice is given that copying is by permission of the Association for Computing Machinery. To copy \notherwisa, or to republish, requires a fea and/or specific permission. ACM-SlGPLAN-PLDl-6 /93/Albuquerque, \nN.M. g 1993 ACM 0-89791-598-419310006101 87...$1.50 terthesetraining sessions,aDSA implementation isgeneratedthat \noptimizes the DSA rdgorithm for the observed program behavior. In this paper we describe a system of \nprofile-based optimizat\u00adion that accurately predicts the objects that will be short-lived at the time \nthey are allocated and segregates these objects from the longer-lived ones, In related work, Hanson describes \nthe advsrt\u00adtages of segregating short-lived objects, in his case by having the programmer explicitly \nspecify what is short-lived [10]. Our work automates Hanson s algorithm by using the allocation site \n(an abstraction of the call-stack) and object size to identify and segregate short-lived objects. Using \nfive significant, allocation\u00adintensive C programs, we show that a great fraction of all bytes allocated \nare short-lived. Furthermore, we describe an algorithm for lifetime prediction that accurately predicts \nthe lifetimes of 42\u00ad99% of all objects allocated. We also describe an algorithm that uses this information \nto increase the performance of dynamic storage allocation. In our algorithrnj objects that are predicted \nto be short-lived are rapidly allocated in small spacesby incrementing a pointer and deallocated together \nwhen they are all dead. With this algorithm, CPU per\u00adformance may be improved because allocation is cheap \nand the. deallocation are done in batches. Memory fragmentation is re\u00adduced becausethe many small short-lived \nobjects arenot polluting the addressspaceoccupied by long-lived objects. Finally, program reference locsJity \nis increased because the short-lived objects (a large fraction of the total objects allocated) are allocated \nin a smrdl part of the heap, less than 100 kilobytes in all the programs we measured. 1.1 Relatad Work \nOur researchcombines two active fields of researchin programming languages: dynamic storage allocation \nand profile-based optimiza\u00adtion, Other researchers have designed memory allocation systems based upon \nvarious characteristics of object allocation behavior. For example, generational garbage collectors exploit \nthe general observation that objects tend to be short-lived [15, 18, 16]. Our approach can improve the \nperformance of generational collectors by predicting object lifetimes when they are born. Object size \ninformation has also been used to improve alloca\u00adtor performance. The conservative garbage collector \ndescribed by Boehm and Weiser [2] uses size to segregate objects but does not attempt to predict object \nlifetimes. They mention, however, that memory overhead would be improved if living objects were seg\u00adregated \nfrom dead objects. In later related work, Demers et al [4] use an object s allocation site (based on \nthe current stack pointer) to predict object lifetimes. Our work expands upon theirs and presents detailed \nmeasurements of the effectiveness of the lifetime prediction approach. In work that is closely related \nto ours, Hanson [10] describes how segregating objects by lifetime improves the performance of DSA algorithms. \nHis results show that segregation can dramatically reduce the cost of allocation and deallocation of \nshort-lived objects. His work differs from ours because he requires the programmer to indicate how long \nobjects will live, while we predict object life\u00adtimes automatically. We enhance Hanson s algorithm by \nusing the behavior of previous program executions to automatically generate an allocator customized for \nshort-lived objects. Our work uses the state of the dynamic call-stack to predict object lifetimes. Other \nresearchers have used the call-stack as a predictor as well, In particular, Hayes [11] and Wilson [21] \nuse stack deallocation events to detect clustering of object deaths and trigger garbage collections. \nTheir work uses the heuristic that a small call-stack predicts there will be more garbage available for \ncollection and hence collection algorithms should be invoked if possible when the stack is low. Like \nHayes and Wilson, we use program measurements to derive useful heuristics, However, we use the contents \nof the stack and not just the size. There has also been a recent flurry of researchin the area of profile-based \noptimization. Wall hasinvestigated the problem of de\u00adtermining how well execution profiles predict actual \nbehavior [20], He concludes that profile-based optimization is more accurate than static attempts to \ndetermine where programs spend time and what global variables are used most often. Most recently, Fisher \nand Freudenberger report considerable success in using previous runs of a program to perform branch-prediction \noptimization in large C and Fortran programs [7]. Grunwald and Zom [9] describe a tool called CUSTOIVLAWOC \nthat performs profile-based optimization of DSA algorithms. In their work, information collected from \nprevious program execu\u00adtions is used to automatically generate high-speed explicit alloca\u00adtors, However, \nno optimization based upon predicted lifetimes is performed in their work. Thispaperhasthefollowing organization, \nFirst,wedescribethe goals of our approach, define the important terms, and discuss the methods used to \nperform our measurements. Next we present mea\u00adsurements that show lifetime prediction can be used to \naccurately predict the lifetimes of short-lived objects. Finally, we present the results of simulating \nDSA algorithms both with and without lifetime prediction. Predictors Our goal is to implement high-performance \ndynamic storage al\u00adlocation algorithms by successfully predicting an object s lifetime when it is allocated. \nThe successof our approach depends on the following hypotheses: 1, One execution of a program will provide \nuseful information about other runs of that program. 2, Information available at the time of obiect birth \ncan uredict that object s lifetime. While the first hypothesis is generally accepted in the domain of \nof execution profiles, it has yet to be thoroughly investigated with respect to other aspectsof program \nbehavior. In this paper, we present evidence that supports the first hypothesis with respect to program \nallocation behavior and we illustrate how such information can be used to optimize allocator implementations. \nSpecifically, we use the allocation site and the object sue to predict object lifetimes. The allocation \nsite specifies where the object was created in the control sequence of the program and the size specifies \nhow much memory is required by that object. When available, the object s type or class can also be used \n[5, 6], but we chose to only use the allocation site and size because the type of an object is not directly \navailable at C birth events. Extensions of lifetime prediction algorithms that use type information, \nwhich is available in languages such as C++, Modula-2, and Modula-3, are the subject of future research. \n3 Methods 3.1 Sample Programs Since our system makes use of a heuristic and a hypothesis con\u00adcerning \nempirical program behavior, our evaluation is based on measurements of actual programs. We selected a \nrepresentative sample of programs, observed their memory allocation behavior, and designed a system to \nexploit that behavior. To show that the technique is widely applicable, we selected programs from a va\u00adriety \nof application areas that require intensive dynamic storage allocation, Our measurements are based on \nfive application programs: CFRAC,which factors large integers; ESPRESSO,a PLA logic opti\u00admize~ GAWK,the \nGNU implementation of the AWK programming language; GHOSTor GhostScript, a publically available PostScript \ninterprete~ and PERL,a report extraction language commonly used in UNIX systems. We measured the allocation \nbehavior of each of these programs by instrumenting them with Larus AE trace gen\u00aderation tool [14]. Table \n1 describes the programs and their input sets and Table 2 summarizes the execution behavior of these \npro\u00adgrams. Multiple input datasets were measured; the performance results presented apply to the largest \nof the input sets in all cases. 3,2 Lifetimes and the Allocation Site We seek to find a correlation between \nthe l~etime of an object and the allocatwn site andfor size of that object. To understand the measurement \nresults, the following terms must be defined in more detail. We define object lifetime to be the total \nnumber of bytes al\u00adlocated between the time the object is allocated and when it is deallocated, While \nbytes allocated may seem an odd measure of time, it is completely appropriate. Time can be measured in \nmany ways but one of the most natural measures, CPU instructions, is not particularly suitable for our \npurposes. To understand why this is true, consider the point of view of the memory allocation sys\u00adtem. \nTo it, the only interesting events are object allocations and deallocation, The demands placed upon the \nallocator are directly proportional totherateoftheseeventsratherthanelapsedtime. Two time measurements \nbased on allocations are easily available: the number of allocation events or the number of bytes allocated \n[1l], We chose the latter because it more closely reflects the demands placed upon the memory system, \nThe call-chain of an event corresponds to an abstraction of the program s call-stack at the time that \nthe event occurred. In particular, we define the call-chain to be the ordered list of functions present \non the runtime stack at any particular program event with cycles of recursive function invocations removed. \nWe chose the entire call-chain because it contains a significant amount of state information about the \ndynamic context of an event. WRAc ClracMaprogramthatfactorslargeintegersusingthecontinuedfractionmethod.Theinputsincluded \n20-40 digit numbers that were the product of two primes. ESPN?.SSOEspresso,version2,3,isalogic optimization \nprogram. Theinputsusedwereexamplesprovided with the release code. GHOST GhostScript, version 2.1, is \na publicly-available interpreter for the PostScript page-description lan\u00ad guage, The inputs used include \na large reference manual and a masters thesis. These executions of GhostScript did not run as interactive \napplications as it is often used, but instead were executed with the NODISPLAY option that simply forces \nthe interpretation of the PostScript program without displaying the results. GAWK GNu AWK, version 2.11, \nis a publicly-available interpreter for the AWK report and extraction language. The inputs used an AWK \nscript to format the words of several dictionaries into filled paragraphs. PERL Perl 4.10, is a publicly-available \nreport extraction and printing language commonly used on UNIX systems, The input scripts sorted the contents \nof a file and formated the words in a dictionary into filled paragraphs. Tablel: General information \nabout thetest programs. Source Instructions Function Total Total Maximum Maximum Program Lines Executed \nCalls Bytes Objects Bytes Objects of c (xlO ) (xlO ) (X1 O ) (xlO ) (x 103) CFRAC 6000 1490 18,4 65.0 \n3.8 83 5236 ESPRESSO 15500 2419 9.55 105 1.7 254 4387 GAWK 8500 2072 28,7 167 4.3 35 1384 GHOST 29500 \n1035 1,21 89.7 0.9 2113 26467 Pm 34500 894 23.4 33.5 1.5 62 1826 Table2 Pefiormance kformation about \ntiememo~aUmation behavior foreach of thetest programa. Total Bytes and Total Objects refer tothetotsl \nbytes andobjects allocated by eachprogram. Maximum Bytes and M~tium Objects showthe maximum number of \nbytes and objects, respectively, thatwere allocated byeachprogram atany onetime. Heap Refsshows thepercentage \nofallmemoV references that were made to objects in the heap (on a SPARC architecture), As an alternative, \nwe could have simply used the last element of the call-chain (e.g., the function calling malloc) but \nwe felt that a single caller doesnotprovide enough information. Because recursive calls add no additional \ninformation, we chose to prune out all recursive loopsinthedefinition ofthecall-chain. Usersofthegpro~execution \nprofiler will be familiar with this approach of collapsing cycles in the dynamic call graph [8]. In our \nstudies, we consider the entire call-chain to seehow much information would be available in the ideal \ncase, and sub-chains of thecomplete call-chain aswell. Inpractice, thesequence of calls inthecall-chain \nmay be very deep. Thus, wedefine thelengtk-N sub-chubrto be the last N callersin thecomplete call-chain. \nFor example, the length-l sub-chain of a particular complete call-chain is another way to describe the \nfunction that directly calls malloc. We distinguish between two types of call-chains: one consisting \nof the chain of functions and the other consisting of the chain of return addresses, Our tools made it \neasy to use the former, so we don t distinguish between two calls within the same function, although \nwe will in future work. We define the allocation site (or simply site) to be the call-chain to the allocation \nroutine at each object birth event. Because the size is always available at the time of allocation, we \nassume that the object size is part of the allocation site unless mentioned otherwise. Thus, the same \ncall-chain allocating 8 bytes at one time and 16 bytes another corresponds to 2 distinct allocation sites. \n4 The Effectiveness of Lifetime Prediction In this section, we describe the methods used to perform lifetime \nprediction and present measures of the effectiveness of this tech\u00adnique, 4.1 Lifetime Quantile Histograms \nOur goal is to determine how well the allocation site and size pre\u00addict the lifetime of the objects created. \nA given allocation site creates many objects of varying lifetimes. We measure the associ\u00adated lifetime \ndistribution of each allocation site using Jain s quantile histogram algorithm [12], which generates \napproximations of a set of quantiles for a distribution. We use Jain s algorithm because it allows us \nto compute the quantiles with minimal storage require\u00adments. To collect the quantile histograms at each \nallocation site, we instrument each program with AE, which allows us to maintain the current call-chain \nand associate each object with its allocation site. When an object is allocated, we enter the object \nand its site into a database, When the object is later freed, we add its observed lifetime to the quantile \nhistogram associatedwith its allocation site. When the instrumented program finishes, we are left with \na mapping of allocation sites to quantile histograms for each allocation site in the program. Table 3 \nillustrates the quartiles of the object lifetime distribu\u00adtions in each of the five applications. The \ntable shows that most objects in all of the applications are very short-lived, with over half of the \nobjects in each program living less than 10,000 bytes. We also see in the table that the oldest objects \nin a program live orders of magnitude longer than the median age. Table 3 illustrates the kind of data \nwe collect for each allocation site in the programs we measured. For the purpose of improving a memory \nallocation system, we would like to group objects with similar lifetimes together. One method is to find \nespecially short-lived objects and place them into a segregatedareaof memory or arena (after Hanson [10]). \nTo predict that a particular allocation site will allocate short-lived objects, we look at the quantile \nhistogram for that site, If a large percentage of the objects allocated at that site are short-lived, \nwe consider that site to be an excellent predictor of short-lived objects, If a collection of such sites \npredicts the lifetimes of a large fraction of all objects allocated, we say that the predictor is successful. \nHow short is short-lived? The answer to this question depends on several factors. First, we must realize \nthat the longer we consider short-lived to be, the more objects we will be able to predict as short-lived \n(consider the degenerate case of the maximum object lifetime). On the other hand, the shorter we predict \nshort-lived objects to live, the smaller the region of memory (arena) we need to set aside to store them. \nMaking this region as small as possible has two advantages. First, it decreasesthe total heap size, reducing \nthe memory overhead of storage allocation. Second, it localizes the references to short-lived objects, \nreducing the cache and page miss rates. In addition to balancing these concerns, we must also consider \nthat eachprogram will havedifferent lifetime distributions. For the rest of this paper, we choose short-lived \nto mean less than 32 kilobytes. We felt this size does not adversely increase the heap size and at the \nsame time (as we will see) it allows us to effectively predict a large fraction of objects as being short\u00adlived. \nWe have investigated other values for this parameter, and the correct choice of value is clearly application \ndependent. In general, this value would be determined automatically by the tool that analyses the program \nbehavior, Our arbitrary choice of 32 kilobytes simplifies the descriptions in this paper and also shows \ngood performance in our particular applications. Another point relating to lifetime quantile histograms \nmust also be considered. Earlier, we said that we chose allocation sites that allocate a large percentage \nof short-lived objects. How large should this percentage be? The answer to this question is related to \nthe cost of incorrect prediction: the cheaper incorrect prediction is, the more sites that allocate non-short-lived \nobjects we can allow. In our case, the algorithm that takes advantage of lifetime prediction will not \nwork well if incorrect prediction is frequent. Therefore, we only consider allocation sites in which \nall of the objects allocated lived less than 32 kilobytes. That is, our algorithm predicts that an allocation \nsite will allocate short-lived objects if all objects allocated at that site in the training inputs were \nshort-lived objects. Table 4 shows the fraction of total bytes allocated in the five test programs that \nwere predicted as short-lived based on their al\u00adlocation sites. This table shows what is possible based \nentirely on examining allocation sites and does not present a measurement of an actual simulation. In \na later section, we present simulation re\u00adsults. Throughout this paper we distinguish between self and \ntrue prediction. By self predictwn, we mean prediction in which the same input is used for both the training \nand test executions of a program. True predictwn implies that different inputs are used in the training \nand test executions, To perform true prediction, we must map the allocation sites from the training inputs \ninto allocation sites in the test execution. We found that requiring an exact mapping of allocation sites \nsome\u00adtimes prevented corresponding sites from correctly mapping be\u00adtween runs. By rounding the object \nsize to a multiple of four bytes, we found the corresponding sites were more likely to map cor\u00adrectly. \nRounding to a larger multiple of two reduced the mapping effectiveness because too much size information \nwas eliminated. In understanding the results using true prediction, it is also important toknowhowtheinputsusedfortraining \nandmeasurement differed, Table 4 illustrates some of the important aspects of how Object Lifetime Quantiles \nProgram OYo 259 0 50% I 75% 10070 I (rein) I I (median) I (max) CFRAc 10 1 32 48 849 i 64.994.593 ESPRESSO \n4 I 196 ] 2.379 I 25,530 I 104,88i.499 I GAWK 2 29 257 li92 167:322:377 GHOST 16 4330 8,052 393,531 89,669,104 \nPm 1 64 887 1306 33,528,692 Table 3: Quantile histogram of object lifetimes in five programs, The table \npresents quartiles of the distributions of object lifetimes (in bytes) in each program, illustrating \nhow object lifetimes are distributed. To read the table, each column gives the lifetime for which that \npercentage of bytes is alive. For example, 75% of the bytes allocated in GAWKlive less than 1192 bytes, \nNote that the quantile histograms presented here are approximations of the true quantiles. For example, \nactual measurements show that the true 75% quantile for GHOSTshould be less than 32,000, but the quantile \nhistogram approximates this value as 393,531. Self Predlctlon True Predlctlon Totsl Actual Predicted \nError Predicted Error Program Sites Short-lived Sites Short-lived Bytes Sites Short-lived Bytes Bytes \n(%) Used Bytes (%) (%) Used Bytes (%) (%) 134 100 110 79.0 0.00 77 47,3 3.65 so 2854 91 2291 41.8 0.00 \n855 18,1 0006 GAWK 171 98 93 99,3 0.00 91 99.3 0!00 GHOST 634 97 256 80.9 0,00 211 71.8 0,00 PERL 305 \n99 74 91.4 0.00 29 20.4 1.11 Table 4: Fraction of total bytes predicted asbeing short-lived based upon \nallocation site and size in each of five programs, Total Sites indicates the total allocation sites in \nthe program while the Actual column shows the true percentage of short-lived bytes. The Sites Used columns \nindicate how many distinct allocation sites were used to identify the short-lived objects. The Predicted \nBytes columns show what percentage of total bytes allocated are correctly predicted as short-lived based \nupon their allocation site and size. Objects are considered short-lived if they are deallocated (die) \nbefore 32 kilobytes of new data are allocated. The Error Bytes columns indicate what fraction of total \nbytes were predicted as short-lived by the predictor but were actually long-lived, the input setsdiffered \nin the programs measured. For example, the two PERL inputs represent two distinct PERL programs operating \non distinct inputs, As such, we expect to see less effective true prediction in PERL. By contrast, the \ntwo GAWK inputs use the same gawk program and only differ in what data the gawk program is fed. In this \ncase,we expect to seevery effective true prediction. We see in Table 4 that the generational hypothesis \n(most ob\u00adjects die young) used in garbage collection was valid for all our programs. Short-lived objects \naccounted for more than 90% of all bytes allocated in every program. Furthermore, in most cases,the allocation \nsites identified many of the short-lived objects. This re\u00adsult suggests that lifetime prediction based \non allocation site and size is possible and potentially very effective. Table 4 also shows that the training \nsets do not always exhibit the samebehavior as the test inputs. That is, sometimes predictors will incorrectly \nidentify long-lived objects asbeing short-lived. In the case of self prediction, errors do not occur \nbecause sites that only allocate short-lived objects are selected. Whh true prediction, those same sites \nmay occasionally allocate long-lived objects. The table shows that incorrect prediction is usually a \nvery small per\u00adcentage and only potentially a problem with the CFRACand PERL applications. After showing \nthat prediction is possible, we sought to deter\u00admine if the size and complete allocation site are both \nneeded for effective prediction. We first examined the effect of using only the size to predict the lifetime \nas shown in Table 5. The table shows that, while in some casessize can be slightly effective, in every \ncase the effectiveness is much less than that of using both the alloca\u00adtion site and size, This result \nconfirms a similar observation made by Ungar and Jackson about the correlation of size and lifetime in \nSmalltalk programs [19]. Another way to reduce the cost of lifetime prediction is to use less than the \ncomplete call-chain to predict lifetimes, To determine the effect of reduced information, we examined \nwhat happened to the predictions if the complete call-chain in the allocation site length was restricted \nto a length-N sub-chain. Table 6 presents the relationship between call-chain length and the effectiveness \nof lifetime prediction. The table shows that as site length increases, a larger percentage of short-lived \nobjects is identified. Furthermore, for each application there was a length at which this percentage \nabruptly increases, We seefrom the table that this abrupt increase occurs at a relatively short length, \nalways length-4 or less in the programs measured. The intuitive explanation for this behavior is that \nprograms use a layered design, Until enough layers are resolved, the different actual allocators of objects \nare indistirrguish\u00adable. For example, many programmers perform memory allocation by calling a function \nxmalloc which then calls malloc. The xmalloc layer provides greater security by checking that the value \nreturned from malloc is not NULL. In such a design, the length-l call-chain information would be an ineffective \npredictor. Table 6 also suggests how effective lifetime prediction can be at improving the reference \nlocality of programs. The New Ref column for each application shows the predicted fraction of total heap \nreferences that are made to short-lived objects (i.e,, the objects that will be highly-localized using \nlifetime prediction). We see from that table that heap references to short-lived objects account for \n8 70% of all references, typically accounting for around 40%. From Table 6, we see that the length-4 \ncall-chain effectively predicts a large fraction (> 90%) of the short-lived bytes predicted by the complete \ncall chain. We conclude from this measurement that in practice, length-4 call chains can be very effective \nat predicting short-lived object lifetimes. 5 Simulation Results Measurements in the previous section \nshow that allocation sites effectively predict the allocation of short-lived objects. In this section \nwe explore the performance benefits and costs of lifetime prediction. In particular, we describe an algorithm \nthat segregates short-lived objects and we show, through simulation, that all aspects of performance \nof this algorithm may be improved when lifetime prediction is employed. 5.1 The Algorithm Using the \ntechniques described in the previous section, training executions of a program are used to generate a \nset of allocation sites that predict only short-lived objects. This set of sites is stored in a databasethat \nis incorporated into an allocation system that is then linked to the program. When an object is allocated, \nthe allocation system uses this database of allocation sites to select one of two strategies: one specific \nto the short-lived allocation sites, and a general one for all others. The short-lived objects are allocated \nusing an algorithm very similar toHanson s[10], Eachshort-lived arenahasafixedsizethat is relatively \nsmall (8-32 kilobytes)l, In addition to the objects, each arena contains one pointer (allot) and a count \nfield that identifies how many objects in the arena are currently alive. Objects in the arena have no \nper-object overhead for tags, sizes, allocated/free bits, etc, Allocation in a short-lived arena proceeds \nas follows. When a new arena is selected, the count field is set to zero and the allot pointer is set \nto the base of the arena. Each time an object is allocated, the following events occur, First, the allot \npointer is checked to seeif the arena contains enough spacefor the request. If it does, the count field \nis incremented, the allot pointer is incremented, and the associated space is returned. If there is not \nenough space,the algorithm scansall short-lived arenasattempting to find one with a zero count field \n(indicating no live objects). If one is found, its allot pointer to reset to the base of the arena and \nallocation proceeds. If one cannot be found, the object is allocated as if it were long-lived, To perform \na free, this algorithm simply decrements the count field in the object s arena. The algorithm requires \nthat we distinguish allocations and deal\u00adlocation of arena objects and objects in the general heap. For \ndeallocation, the address of the object gives this information (and which arena)becausearenasarecontiguous \nandnotpartofthegen\u00aderal allocation heap. For allocations, the presence of the allocation site in the \nshort-lived site database indicates an arena allocation. Because the number of short-lived allocation \nsites is small, the database may be maintained as a small hash-table. The allocation siteisencodedasaninteger \nthatisusedtoindex into thehash-table, We propose two alternatives to determining the allocation site. \nThe measurements in Table 6 suggest that exck.rsive-ORing the size with the last four return addressesshould \nyield results comparable to using the entire call-chain. As an alternative to calculating the callersateachallocation, \nCarter[3] suggeststhefollowing approach that we call call-chain encryptwn, For each function in a program, \nassign a 16-bit id2. At each function call, create an new key by XORing the current function s id with \nthe key of the caller, The function ids should be selected so that the resulting keys being generated \nby call-chains are likely to be unique; static call-graph analysis may be used to determine the best \nids. The overhead of this 10bjecta larger than a specific size are allocated by the general purpose allocator. \n2Weuse16-bit idsbecauseexisting hardware, suchaathe MIPSR3000architecture, supports 16-bit immediate \nconstants. rT I Actual Predicted Sites Program Short-lived Short-lived Used To Bytea (%) Bytes (%) Predict \nCFRAC 100 0 5 ESPIWSSO 91 19 177 GAWK 98 564 GHOST 36 106 pERL ;; 29 26 Table 5: Fraction of total bytes \npredicted as being short-lived based only upon object size in each of five programs. Self prediction \nis used in this table. The Actual, Predicted, and Sites columns are as in Table 4. As the table shows, \nsize information alone predicts only a small fraction of the objects as being short-lived. Call CPRAC \nESPRESSO GAWK GHOST PERL Chain Pred.I New Pd N Pd Pd N Pd N L&#38;ngth (f6 Ref.(%) &#38; Re;~.) (;) \nRe/&#38;o) &#38; Re;&#38;) &#38;) Ref!(?o) 1 52(::) ; ;; ;; :; ;; :: ;: 2 (g) 66 3 7041 8(g) : 14 33 \n4 827042 8 (;) 31;) : 5 827042 8 9943 37 6 827043 9 994380379445 7 82 I 70 44 9 99143181138195/45 m I \n82 70 42 8 99]43181 [38192144 I I Table 6: Effect of call-chain length on short-lived object prediction. \nThis table shows how the fraction of total bytes predicted as being short-lived changes as more callers \nin the call-chain are considered. Self prediction is used in this table, The predictive ability of the \ncall-chain increases with the number of callers. The numbers in parentheses indicate the length at which \nan abrupt improvement in prediction occurred. The New Ref columns indicate the predicted fraction of \ntotal heap references to the short-lived objects. Them case corresponds to using the complete call-chain, \nNote that in some cases, the oo case predicts less than the length-7 chain (e.g., ESPmSSO). This occurs \nbecause we perform recursive loop elimination in the complete site case and not in the length-N case. \napproach is distributed over all function calls, but would result in a small number of additional instructions \nper function call (load from caller s stack, XOR with the function s id, and store into callee s stack). \nWe modeled the CPU cost of each of these methods by multiply\u00ading the instruction count for each by the \nnumber of allocations and function calls respectively. On a RISC-style architecture, such as SPARC, we \nestimate that the length-4 call-chain can be computed in 10 instructions. Tlvo assumptions are necessary \nto achieve this count. First, we assume that a pointer to the previous stack frame is stored in every \nframe. Compiler optimization that eliminate this frame-pointer will increase the cost of determining \na function s callers. Fortunately, the SPARC architecture, with built-in regis\u00adter windows, eliminates \nthis problem. The second assumption we make is that the C crt O routine pushes three dummy stack frames \non the stack so that the last four callers are always available. This optimization eliminates checks \nfor the bottom of the stack, We further estimate that the determination of whether an allo\u00adcation is \nshort-lived takes approximately 18 instructions, including the 10 to determine the length-4 call-chain. \nIn contrast, to compute the per-allocation cost of call-chain en\u00adcryption, we take the total number of \nfunction calls in a program execution and multiply by the cost per call (we estimate 3 instruc\u00adtions) \nand then divide by the total number of allocations. While this cost is program dependent, we observe \nit to range from 9 instruc\u00adtions to 94 instructions per allocation in the programs measured. A complete \ncomparison of the CPU overhead of this algorithm is presented in Table 9. 5.2 The Simulation We measured \nthe performance of the test programs with the lifetime prediction algorithm using trace-driven simulation. \nTo measure the performance of a program, we fed a trace of the program s allocation events and a list \nof short-lived sites into a simulator of the prediction algorithm, The allocation event included the \nlifetime, size, and an identifier corresponding to the complete call-chain and size of that allocation. \nThe output of the simulator gives operation counts, information about the fraction of objects and bytes \nallocated in arenas, heap size, and fragmentation measurements. In our experiments, we compare the performance \nof a lifetime predicting arena-allocator with a relatively simple first-fit algorithm with enhancements \ndescribed by Knuth [13]. We chose to compare the arena allocator with the first-fit algorithm for two \nreasons. First, the first-fit allocator often has relatively good memory utilization characteristics, \nand as such serves as a fair baseline for comparing the memory usage of the arena allocator. Second, \nthe first-fit algo\u00adrithm is used by the arena allocator for non-arena objects. In this way, the first-fit \nalgorithm becomes the degenerate case of an arena allocator that allocates no objects in arenas. In all \nsimulations, we present the results of true prediction, Table 7 shows how effectively the algorithm was \nable to rec\u00adognize short-lived objects. In all cases, the total space devoted to arenas was 64 kilobytes, \ntwice the age of the objects predicted as short-lived by the pfe~ictor. This size was chosen with the \nintu\u00adition that by the time the last half of the 64 kilobytes are filled, we are confident that objects \nin the first half of the arena are dead, and thus the space in the first half can be re-used. Furthermore, \nthe 64-kilobyte arena area was divided into 16 distinct 4-kilobyte arenas. This blocking reduces the \nspace consumed by erroneously predicted long-lived objects that tie up the entire arena in which they \nare allocated. Table 7 should be compared directly with Table 4, The frac\u00adtion of bytes allocated in \narenas corresponds very closely with the predicted short-lived bytes shown in Table 4. There are two \nno\u00adtable exceptions, namely GHOST and CFRAC. In GHOST, we see that while the fraction of arena objects \nis high (80Yo), the fraction of arena bytes is much smaller (only 3870). This occurs because GHOST allocates \nabout 5000 6-kilobyte short-lived objects. These objects cannotbe allocated in the 4-kilobyte arenas \nand are allocated in the general heap instead. CFRAC shows what happens to this algorithm if too many \nlong\u00adlived objects are erroneously predicted to be short-lived. Recall that 3.65% of the objects in CFRAC \nwere incorrectly predicted as short-lived. Furthermore, empirical measurements of CFRAC show that the \nobject lifetime distribution is very highly skewed [23]. That is, while the vast majority of objects \nallocated by CFRAC are very short-lived, some objects it allocates are extremely long-lived, Therefore, \nobjects incorrectly predicted as short-lived may actually be very long-lived. These objects then tie \nup all the arenas @ol\u00adhdng the arenas), forcing the arena allocator to degenerate to a general-purpose \nallocator. We speculate that this is what happened in CFRAC, although its poor performance requires more \ninvestiga\u00adtion. High error rates degrade performance dramatically and it will be important to identify \nprograms that exhibit them, such as CFRAC, during training. Lifespan prediction may be inappropriate \nfor such programs. Table 8 shows the effect of arena allocation upon the total mem\u00adory consumedly each \nprogram. For programs that use only a small amount of memory, the arena algorithm consumed more space. \nFor GHOST, which uses much more memory than the other programs, a savings of ZW8V0 was realized. Table \n8 also compares the effec\u00adtiveness of true prediction with self prediction. In most cases, true prediction \nresults in the same heap size as self prediction. In the GHOST program however, true prediction increased \nheap size rela\u00adtive to self prediction, but still reduced heap size by 28% over the standard first-fit \nalgorithm. We feel confident that in programs with large heaps, lifetime prediction will be very effective \nin reducing total heap size, Table 9 shows the average number of instructions to allocate and free objects \nin four allocation algorithms. The numbers for the first two algorithms (BSD and First-fit) were computed \ndirectly from actual implementations using the QP [1] instruction profiling tool. The numbers for the \nArena algorithms were computed using operation counts (e.g., allocations, frees, etc), multiplying them \nby the estimated cost per operation. In general, even though an esti\u00admated 18 instructions are expended \nto predict object lifetime, this overhead is a relatively small fraction of the total cost of allocation \nplus deallocation in the BSD and First-fit allocators. We see from the table that the effectiveness of \nlifetime prediction translates directly into increased CPU performance. For example, GAWK, in which lifetime \nprediction was highly successful, shows very low CPU overheads. CFRAC, on the other hand, which suf\u00adfers \nfrom significant prediction errors resulting in arena pollution, shows the poorest CPU performance, It \nis clear from the table that lifetime prediction has a mixed effect on CPU performance; it can improve \nCPU performance significantly and it can also degrade it significantly. Based on these results, we conclude \nthat improved CPU performance is not the primary advantage of this approach. In comparing the different \ncall-chain identification strategies, we see that the length-4 arena algorithm was usually slightly faster \nthan the call-chain encryption arena strategy, and in one case twice as fast. This suggests that a space-speed \ntradeoff may be possible by selecting one or another of the algorithms depending upon how True Predlctlon \nProgram Total Arena Non-arena Total Arena Non-arena Allots Allots Allots Bytes Bytes Bytes (1000 s) ~%) \n(%) @bytes) (%) (%) CPRAC 3809.2 97.4 63472 1.8 98.2 ESPRESSO 1654.2 19s 80.9 102423 18.2 81.8 GAWK 4273.0 \n98.2 1.8 163401 99.3 GHOST 924.1 81.3 18,7 87567 37.7 :2?3 PERL 1466.8 18.0 82.0 32743 20.5 79.5 Table \n7: Fraction of total objects and bytes allocated in the arena and the non-arena part of the heap in a \nlifetime predicting arena allocator. Self Predlctlon True Predlctlon First-fit Arena Allot Arena Allot \nArena Allot Arena Allot Program Heap Heap Heap/ Heap Heap/ Size Size First-fit Size First-fit I (Kbytes) \nI (Kb&#38;;s) Heap (%) (Kbytes) Heap (%) CFRAC 144 I I 144.4 I 208 I 144.4 =PRESSO 280 344 122,9 344 \n122.9 GAWK 56 112 200.0 112 200.0 GHOST 5584 2896 51!9 4048 72.5 PERL 80 144 180,0 144 180.0 Table 8: \nMaximum heap sizes allocated by a first-fit allocator and a lifetime predicting arena allocator, The \narena heap sizes include the 64-kilobyte arena area in the total. I True Predlctlon I First-fit Arena \n(len-4) Arena (ccc) Program CPRAC (instr per) allot I free ] a+f 52 ] 17 I 69 (instr per) allot I free \n66 I 64 I a+f 130 (instr per) allot ] free 134 I 62 \\ a+f 196 m ESPRESSO 55 17 72 65 65 130 76 55 130 \n84 55 139 GAWK 54 17 71 56 64 120 29 11 40 29 11 39 GHOST 61 17 78 165 57 222 58 18 76 142 18 160 PERL \n51 17 68 70 I 6511361 82[ 551 137 1201 551 175 \\ Table 9: Average number of instructions for calls to \nallocate and free in the application programs using different allocation algorithms. The numbers for \nBSD and First-fit were measured counting instructions in actual implementations with the QP tool. Arena \n(len-4) indicates the cost of lifetime prediction using the last 4 callers, The determination of the \nlength-4 caller costs 10 instructions per allocation. Arena (ccc) indicates the pe~ allocation ove~head \nusing call-chain encryption and factoring {he per-call call-chain encryption as a per-allocation cost. \nIn this case, the encryption key costs from 9 to 94 instructions per allocation in the programs measured. \neffective the length-4 algorithm was in finding short-lived allocation sites. Conclusions Our goal is \nto improve all aspects of the performance of dynamic storage allocation. In this paper, we have investigated \nusing infor\u00admation present at the allocation of an object to predict its lifetime. We have measured five \nsignificant allocation-intensive C programs to determine the effectiveness of this approach. Our results \nshow that segregation of short-lived objects into small contiguous areas of memory can improve the reference \nlocal\u00adity and total memory requirements of memory allocation, In one program, where lifetime prediction \nwas particularly effective, the CPU overhead of storage allocation was also significantly reduced. We \nhave seen that the allocation site (intuitively, an abstraction of the call-stack at the point of allocation) \nreliably predicts short-lived objects for a broad range of programs; 40-10O% of all bytes allo\u00adcated \nby a program are predicted to be short-lived by the allocation site. By allocating short-lived objects, \nwhich represent a large frac\u00adtion of the total bytes allocated, in a small arena area (64 kilobytes), \nreference locality is improved. Because these objects are not com\u00adpeting for space in the heap, heap \nfragmentation and size is reduced for programs with large heaps. Lifetime prediction does not come without \nCOSGon the SPARC architecture, we estimate 18 instruc\u00adtions per allocation are required to attempt to \npredict if an object is short-lived. Our measurements show that the CPU overhead of a lifetime predicting \nallocator is often comparable to that of a first-fit allocator, This paper has explored the possibility \nof lifetime prediction and simulated the performance of one algorithm based on this idea. Further exploration \nof algorithms based on this idea are required to fully understand its performance implications. In future \nwork, we will build a prototype implementation of the most promising algorithms and measure the performance \nof lifetime predicting al\u00ad locators directly. Acknowledgements We would like to thank John Ellis, Rod \nOldehoeft, and the anonymous comments. This material is based National Science Foundation under by a \nDigital Equipment Corporation References [1] Thomas Ball and James R. Larus. Kinson Ho, Dirk Grunwald, \nreviewers for their insightful upon work supported by the Grant No. CCR-9121269 and External Research \nGrant. Optimally protiling and tracing programs. In Conference Record of the Nineteenth ACM Symposium \non PrrirciplesofProgramming Languages, pages 59-70, January 1992. [2] H. Boehm and M. Weiaer. Garbage \ncollection in an uncooperative environment. Software-Practice and Experience, pages 807-820, September \n1988. [3] Larry Carter. Discussion of efficient encoding of call-chain informa\u00adtion. Personal communication, \nSeptember 1992. [4] Alan Demers, Mark Weiser, Barry Hayes, Hana Boehm, Daniel Bo\u00adbrow, and Scott Shenker. \nCombining generational and conservative garbage collection: Framework and implementationa. In Conference \nRecord of the Seventeen thACM Symposium on Prtkciples of Program\u00adming Languages, pagea 261-269, January \n1990. [5] John DeTreville. Experience with concurrent garbage collectors for modula-2+. Technical Report \n64, Digital Equipment Corporation Sys\u00adtem Research Center, Palo Alto, CA, November 1990. [6] A. Diwan, \nE. Moss, and R. Hudson. Compiler support for garbage collection in a statically typed language. In Proceedings \nof the ACM SIGPLAN 92 Conference on Pro~ramminz Larwuaee Desizn and lmplementatwn, vo~ume27, pages~73-282,>an \nF;an;isco, C~ June 1992. [7] Joseph A. Fisher and Stefan M.Freudenberger. Predicting conditional branch \ndirections from previous runs of a program. In Proceedings of the Fijlh Intern atwnal Conference on Architectural \nSupport for Programming Languages and Operating Systems (ASPLOS-~, pages 85-95, Boaton, MA October 1992. \n[8] Susan L. Graham, Peter B. Kessler, and Marshall K. McKuaick. An execution profiler for modular programs. \nSo@are Practice and .Ec\u00adperience, 13:671-685,1983. [9] Dirk Grunwald and Benjamin Zorn. CUSTOMAIWC Efficient \nsynthe\u00adsized memory allocators. Technical Report CU-CS-602-92, Depart\u00adment of Computer Science, University \nof Colorado, Boulder, Boulder, CO, July 1992. [10] David R. Hanson. Fast allocation and deallcoation \nof memory based on object lifetimes. Sofhvare<ractice and Experience, 20(1):5-12, January 1990. [11] \nBarry Hayea. Using key object opportunism to collect old objects. IrI 00PSLA 91 Conference Proceedings, \npages 33-46, Phoenix, AZ, November 1991. [12] Raj Jain and Imrich CMamtac. The P-2 algorithm for dynamic \ncalcu\u00adlation of quantiles and histograms without storing observations. Com\u00admunications of the ACM, 28(10): \n1076-1085, October 1985. [13] Donald E. Knuth. Fundamental Algorithms, volume 1 of The Art of Computer \nProgramming, chapter 2, pages 435-451. Addison Wesley, Reading, MA 2nd edition, 1973. [14] James R. Lams. \nAbstract execution: A technique for efficiently trac\u00ading programs. Software Practice and Experience, \n20(12):1241-1258, December 1990. [15] Henry Lieberman and Carl Hewitt. A real-time garbage collector \nbased on the lifetimes of objects. Communications of the ACM, 26(6):419\u00ad429, June 1983. [16] David A. \nMoon. Garbage collection in a large Lisp system. In Con\u00adference Record of the 1984 ACM Symposium on LISP \nand Functional Programming, pages 235-246, Austin, Texas, August 1984. [17] Bjarne Stroustrup. The C++ \nProgramming Language. Addison-Wesley Series in Computer Science. Addison-Wesley, Reading, M&#38; 2nd \nedition, 1991. [18] David Ungar. Generation scavenging: A non-disruptive high perfor\u00ad mance storage reclamation \nalgorithm. In SIGSOFT/SIGPLAN Prac\u00adtical Programming Environments Conference, pages 157-167, April 1984. \n [19] David Ungar and Frank Jackson. AU adaptive tenuring policy for gen\u00aderation scavenger. ACM Transactions \non Programming Languages and Systems, 14(1):1-27, January 1992. [20] David W. Wall. Predicting program \nbehavior using real or estimated profilea. In Proceedirrgsof theACMSIGPL4N 91 Conference on Pro\u00adgramming \nLanguage Design and Implementation, volume 26, pages 59-70, Toronto, Ontario, Canada, June 1991. [21] \nPaul R. Wkon. Opportunistic garbage collection. SIGPLANNotices, 23(12):98-102, December 1988. [22] Benjamin \nZom. The measured cost of conservative garbage collection. Software-practice and Experience, 1993. To \nappear. [23] Benjamin Zom and Dirk Grunwald. Empirical measurements of aix allocation-intensive C programs. \nSIGPLAN Notices, 27(12):71-80, December 1992.  \n\t\t\t", "proc_id": "155090", "abstract": "<p>Dynamic storage allocation is used heavily in many application areas including interpreters, simulators, optimizers, and translators. We describe research that can improve all aspects of the performance of dynamic storage allocation by predicting the lifetimes of short-lived objects when they are allocated. Using five significant, allocation-intensive C programs, we show that a great fraction of all bytes allocated are short-lived (&gt; 90% in all cases). Furthermore, we describe an algorithm for liftetime prediction that accurately predicts the lifetimes of 42&#8211;99% of all objects allocated. We describe and simulate a storage allocator that takes adavantage of lifetime prediction of short-lived objects and show that it can significantly improve a program's memory overhead and reference locality, and even, at times, improve CPU performance as well.</p>", "authors": [{"name": "David A. Barrett", "author_profile_id": "81392612783", "affiliation": "", "person_id": "PP39069323", "email_address": "", "orcid_id": ""}, {"name": "Benjamin G. Zorn", "author_profile_id": "81100190820", "affiliation": "", "person_id": "P28972", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/155090.155108", "year": "1993", "article_id": "155108", "conference": "PLDI", "title": "Using lifetime predictors to improve memory allocation performance", "url": "http://dl.acm.org/citation.cfm?id=155108"}