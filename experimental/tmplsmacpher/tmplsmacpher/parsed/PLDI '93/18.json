{"article_publication_date": "06-01-1993", "fulltext": "\n Space Efficient Conservative Garbage Collection Hans-Juergen Boehm Xerox PARC boehmQparc.xerox. com \n Abstract We call a garbage collector conservative if it has only partial information about the location \nof pointers, and is thus forced to treat arbitrary bit patterns as though they might be pointers, in \nat least some cases. We show that some very inexpensive, but previously unused tech\u00adniques can have dramatic \nimpact on the effectiveness of conservative garbage collectors in reclaiming mem\u00adory. Our most significant \nobservation is that static data that appears to point to the heap should not result in misidentified \nreferences to the heap. The garbage collec\u00adtor has enough information to allocate around such ref\u00aderences. \nWe also observe that programming style has a significant impact on the amount of spuriously retained \nstorage, typically even if the collector is not terribly conservative. Some fairly common C and C++ pro\u00ad \ngramming styles significantly decrease the effectiveness of any garbage collector. These observations \nsuffice to explain some of the different assessments of conservative collection that have appeared in \nthe literature. Introduction 6 aTbage collectors reclaim storage that has been allo\u00adcated by a client \nprogram, but is no longer accessible by following pointers from program variables. For a re\u00adcent survey \nof the problem and of garbage collection techniques see [24]. Permission to copy without fee all or part \nof this material is granted provided that the copies are not made or distributed for di reot commercial \nadvantage, the ACM copyright notice and the title of the publication and its date appear, and notice \nis given that copying is by permission of the Association for Computing Machinery. To copy otherwise, \nor to republish, requires a fee ar)d/or specific peMIiSSiOt7. ASM-SIGPLAN-PLDl-6 /93/Albuquerque, N.M. \n@ 1993 ACM O-89791 -598 -41931000610 ~97... $~0~O Conservative garbage collectors [9] can operate with \nonly minimal information about the layout of the client program s data. Instead of relying on compiler \nprovided information on the location of pointers, they assume that any bit pattern that could be a valid \npointer in fact is a valid pointer. Generally, this is safe only under the assumption that objects do \nnot move. However, hybrids that rely on some exact pointer information to move some objects are both \npossible and often used [3, 13]. It is possible to construct conservative garbage col\u00adlectors that utilize \nmany of the same performance im\u00adprovement techniques as conventional collectors. Gener\u00adational conservative \ncollectors have been const ructed[5, 12] as have concurrent collectors that greatly reduce client pause \ntimes[8]. Conservative collectors have been used successfully, even with fairly large conventional C \nprograms [9, 18, 25]. 1 Such collectors have also been used as a debugging tool for programs that explicitly \ndeallocate atorage[9, 16]. Conservative garbage collection also makes it possible to easily compile other \nprogramming languages that re\u00adquire garbage collection into efficient C, thus providing a portable implementation \nthat can take advantage of the manufacturers C compilers to obtain competitive performance. Programming \nlanguage implementations that rely on conservative collection in this manner in\u00adclude the only commonly \navailable implementations of Modula-3 (SRC Modula-3) and Sather[17], as well as portable implementationa \nof Scheme[4, 18], ML[l 1, 10], Common Lisp (AKCL[21]), Mesa [19, 2], and CLU, among others. These vary \ngreatly in their degree of con\u00adservativism, i.e. in how much information about data structure layout \nthey maintain. Some maintain comp\u00adlete information on the location of pointers in the heap, and only \nscan the stack conaervatively[4, 19, 21]. Oth\u00aders also treat the heap conservatively [18, 2, 17]. Thus \n1The correctness of such an approach can be guaranteed with minimal restrictions on C compiler optimization. \n[ ?l In fact, most current systems use standard C compilers and ignore any possi\u00adbility of unsafe compiler \noptirnkations.  the following observations apply to different degrees. Most applications of such collectors \nhave encountered few peoblems. In particular, the Xerox Portable Com\u00ad mon Runtime system [22] is used \nroutinely to run more than a million lines of Cedar/Mesa code that have been compiled to C. Nonetheless, \na few negative results have been reported in the literature. In particular, several authors[14, 23] have \nreported significant memory leak\u00ad age under some circumstances, i.e. significant amounts of inaccessible \nmemory were not reclaimed. The nega\u00ad tive performance results of [11] are probably partially attributable \nto such leakage. Other papers (cf. [16]) point to the dangers of such leakage, but do not cite specific \nempirical results. We note that garbage collection with minimal leak\u00adage is fundamentally an optimization \nproblem, and not an absolute issue of correctness. The notion of a zero\u00adleakage garbage collector is \nill-defined. As pointed out in, for example, [9], programming language definitions rarely (never?) define \na notion of accessible memory. In\u00addeed, it is hard to see how to do so without disallowing essential \ncompiler optimization. Thus the not ion of re\u00adclaiming all inaccessible storage is ill-defined. Indeed \nthe traditional interpretation as pointer reachability in a given implementation is both dependent on \nthe imple\u00admentation and not optimal in any real sense. There are many cases in which pointer accessible \nstructures can be safely discarded cf. [6, 15]. (This is not an indictment of automatic garbage collection; \nC malloc implementa\u00adtions usually provide no useful bound on space usage, either. In the worst case they \nare subject to disastrous fragmentation overhead.) Thus the goal of any garbage collector has to be to \nre\u00adtain as little memory as it can, subject to the constraint that all memory that will be accessed in \nthe future must be retained. Like many compiler optimization, a fail\u00adure by the run-time system to solve \nthis problem well is likely to lead to unacceptable results. Also like many compiler optimization, it \nis important to give the pro\u00adgrammer a reasonable idea of what programming styles are likely to result \nin unacceptable performance. The remainder of this paper addresses these two is\u00adsues. First, the next \ntwo sections present some empirical results on the causes of spurious memory retention by conservative \ncollectors, and discuss refinements for such collectors that can greatly reduce such retention. Our approach \nwill be to reduce the probability that non\u00adpointer data will be mistakenly identified as pointers. We \nthen conclude with a discussion of programming techniques that can greatly alter the amount of memory \nretained as the result of a misidentification. The only detailed previously published discussion of these \nissues appears to be by Wentworth [23]. He dis\u00adcusses the circumstances under which spurious retention \nis likely to be unacceptable. Some minimal empirical re\u00adsults also appear in [9]. Some measurements of \noverall space usage are given by Zorn [25], but he does not an\u00ad alyze the causes of excess space consumption. \nHe does not specifically discuss techniques for reducing such re\u00ad tention.  2 Pointer Misidentification \nThe most apparent potential source of excess memory retention by conservative collectors is the misidentifica\u00adtion \nof, for example, integers, as pointers. If the collec\u00adtor finds an integer variable that happens to contain \nthe address of a valid but inaccessible object, and the run\u00adtime system has no way to determine that \nit is indeed an integer, then that object, and other garbage objects referenced by it, will be retained. \nThis can easily hap\u00adpen while, for example, trying to garbage collect C data structures. The probability \nof such misidentification in\u00adcreases if more of the address space is occupied by the heap, since this \nincreases the probability that a ran\u00addom piece of data will happen to be the address of an object. In \nsome environments, it is essential to recognize a pointer to the interior of an object as valid, forcing \nthe containing object to be retained. This is often required if the source language requires that array \nelements can be passed by reference. It potentially allows arbitrary portable, fully ANSI conforming \nC programs [1] to be garbage collected.2 This requirement greatly increases the chance of misidentification. \nSome simple ad hoc techniques can often greatly de\u00adc~ease the misidentification probability. It is desirable \nto design the allocator to avoid allocating objects at ad\u00addresses that are likely to collide with other \ndata. On a machine that ensures that pointers are stored at word boundaries in memory (where a pointer \nis a word long), an adequate solution sometimes consists of properly po\u00adsitioning the heap in the address \nspace. If the high or\u00adder bits of addresses are neither all zeros or all ones, then conflicts with integer \ndata are unlikely. Similarly, likely character codes and floating point values can be avoided. If pointers \nare not guaranteed to be properly aligned then all possible alignments must be considered by the collector, \nthus greatly increasing the number of false point ers, This situation is particularly unpleasant since \nthe concatenation of the low order half word of an inte\u00adger with the high order half word of the next \ninteger can 2This also requires some minimal additional constraints on compiler optimizations. [7] Note \nthat the standard does not de\u00adfine, and hence renders unportable, the results of many kinds of commonly \nused pointer arithmetic (e.g. pointer hashing), many of which are actually benign for conservative garbage \ncollection. Interestingly, interior pointers rarely need to be recognized if old C programs are run with \ngarbage collection; such programs normally also maintain a pointer to the base of the object, in anticipation \nof having to explicitly deallocate it. easily be a valid heap address (see figure 1), even if small \nintegers by themselves are not valid heap addresses, as on most machines. Experience with the collector \nof [9] indicates that the impact of this problem can be greatly reduced if objects are not allocated \nat addresses con\u00adtaining a large number of trailing zeroes. 00000009 0000 000a Figure 1: Two small integers \nturn into the address (hex) 00090000 Nonetheless, unaligned pointers are problematic. With old versions \nof our collectors, we have sometimes observed unreasonable garbage retention in environ\u00adments requiring \nboth unaligned pointers and pointers to object interiors to be recognized. Fortunately, mod\u00adern machines \ntypically impose substantial penalties on unaligned data references. Thus newer compilers almost always \nguarantee adequate alignment. For garbage collectors that scan the heap conserva\u00adtively, it is essential \nto provide some way to commu\u00adnicate to the collector at least the fact that an entire large object contains \nno pointers. Otherwise certain kinds of objects (most notably large amounts of com\u00adpressed data, such \nas compressed bitmaps) introduce false pointers with excessively high probability. The col\u00adlectors discussed \nin the following sections provide this alternative. Similarly, it is useful, though sometimes more difficult, \nto avoid scanning large static data areas that contain seemingly random, nonpointer areas (e.g. IO buffers). \n  Systematic Techniques A much less ad hoc, and more flexible technique for avoiding false references \nis the following. First, we en\u00adsure that garbage collections take place at regular in\u00adtervals, with at \nleast one (normally very fast) garbage collection occurring just after system start up before any allocation \nhas taken place. For collectors such as that described in [8] this is quite natural in any case. Second, \nwe keep a record of invalid pointers discov\u00adered during a garbage collection that could conceivably become \nvalid object addresses as a result of later alloca\u00adtion. Such addresses are effectively blacklisted. \n(Black\u00adlisted values that are no longer found by a later collec\u00adtion may be removed from the list.) A \nmodification of a rather naive marking algorithm to accomplish this is given in figure 2. The only additions \nrequired for black\u00adlisting are in bold face. In a realistic implementation, mark(p) { if p is not a valid \nobject address if p is in the vicinity of the heap add p to blacklist return if p is marked return set \nmark bit for p for each field q in the object referenced by p mark(q) } Figure 2: Marking with blacklisting \n the heap proximity check is likely to overlap substan\u00ad tially with the immediately preceding pointer \nvalidity check. Finally we ensure that we do not allocate objects at blacklisted addresses, unless it \nis known that very little memory will ever be reachable from these objects ( e.g because the objects \nare small and known not to contain pointers). If pointers to the interiors of objects force objects to \nbe retained, then we do not allocate objects that span blacklisted addresses. This scheme is likely to \nblacklist addresses that corre\u00adspond to long-lived data values before these values be\u00adcome false references. \nShort-lived false references are not of interest in any case, since they do not cause garbage to be retained \nindefinitely, In our experience, the most troublesome false references (e.g. the one lead\u00ading to the \nproblem described in [14]) originate from stat\u00adically allocated constant data that is scanned for roots \nby the collector. Such false references are gua? anteed to be eliminated. We have implemented variants \nof the above approach in recent versions of the PCR[22] garbage collector and in more recent versions \nof the collector described in [9]. Both collectors scan the stack(s), registers, static data, as well \nas the heap conservatively. For reasons of performance and simplicity, we black\u00adlist entire pages rather \nthan individual addresses. The blacklist can be implemented as a bit array, indexed by page numbers. \nIf the heap is discontinuous, as for the second of the above collectors, it makes sense to imple\u00adment \nit as a hash table with one bit per entry. If a false reference is seen to any of the pages with a given \nhash address, all of them are effectively blacklisted. Since collisions can easily be made rare, this \ndoes not result in much lost precision. In our collectors, the blacklist is only examined when allocation \nfrom a new page is begun. Since false references during marking are also relatively rare, the total additional \noverhead introduced by blacklisting is usually less than 1%.3 Results have been encouraging. We ran the \nprogram T given in appendix A on a SPARCStation, using both the statically linked and dynamically linked \nversions of the SunOS 4.1.1 C library, on an SGI workstation, and under 0S/2 on an 80486-based PC. We \nalso ran a modi\u00ad fied version of the program on the SPARCstation under PCR, as part of the Cedar programming \nenvironment. More detailed descriptions of these environments, neces\u00ad sary program adaptations, and explanations \nof platform specific anomalies, are given in appendix B. The program T allocates 200 circular linked \nlists con\u00ad taining 100 Kbytes each. The collector is configured so that if any data points to any of \nthe 100,000 addresses corresponding to objects in the list, then the entire list is retained. We ask \nwhat fraction of these linked lists fail to be collected after the program drops the last in\u00ad tentional \nreference to any of them. We measured this value both for a collector that blacklists pages, and for \nthe same collector with blacklisting disabled. In the PCR case, some of the experiments were performed \nwith much more substantial client code running concurrently with program T. The results are given in \ntable 1. Several observations are in order: 1.The executable program is not as trivial as it sounds, \nsince it includes the garbage collector itself, as well as large fractions of the C library. (We refer\u00adence \nsprintf and use it to print collector statistics. ) The resulting program and static data areas for the \noptimized SPARC(static) versions of the program total more than 140 Kbytes, out of which more than 60 \nKbytes are scanned by the collector as potential roots. (The time overhead involved in this could be \nlargely eliminated by the techniques in [8], but that is not relevant here.) In the PCR case, much larger \ndata areas are included. 2. Based on the results from PCR, the approximate amount of retention appears \nrobust across a variety of client programs. See appendix B for details. 3. The numbers in the table \nshould be interpreted as approximate. None of the results are completely reproducible, since the scanned \npart of the address space is polluted with UNIX environment vari\u00adables, and in some cases apparently \nregister values left over from kernel calls and/or context switches.  3The stand-alone collector can \nstill allocate and collect an 8 byte object in around 2 microseconds under optimal conditions (no accessible \nheap data) on a SPARCStation 2, which is much faster than malloc/free round-trip times for most malloc \nimple\u00ad ment ations. For the test program of appendix A, version 2.5 of the collector spends approximately \n0.2 ?4 of its time dealing with blacklisting related bookkeeping. In earlier versions of the collec\u00ad \ntor, this overhead was about an order of magnitude greater, since blacklisted blocks were kept on a list \nof free pages indefinitely, increasing the overhead of page-level allocation. Where we observed different \nresults, we specified ranges. 4. Large numbers usually do not mean that collected programs exhibit continuous \nstorage leaks, though occasionally this might be the case [23]. Usually false references will render \na section of memory un\u00adusable, and the program will then continue to run out of a section of memory that \nhas no false refer\u00adences to it. Thus some blacklisting occurs implic\u00aditly, after the fact. The problem \nis that a false ref\u00aderence may decommission much more than a page or, in some cases, introduce a growing \nleak. 5. It is likely that the references that remain even with blacklisting are not truly permanent, \nand instead originated from a portion of the stack where they would be eventually overwritten in a longer \nrunning program with more varied stack frames. Whenever we have managed to track down similar references, \nthis has been the case. 6. The additional heap size needed to make up for black listed pages in the \nabove environment was negligible, and not easily measurable, since it is dominated by the heap expansion \nincrement. In the PCedar environment, there are enough alloca\u00adtions of small objects known to be pointer-free \nthat blacklisted pages can still be allocated, and thus the loss is usually zero. 7. A quick examination \nof the blacklist in a stati\u00adcally linked SPARC executable suggests that if all interior pointers are \nconsidered valid, it becomes difficult to allocate individual objects larger than about 100 Kbytes without \nviolating the blacklist constraint, or requesting memory from the operat\u00ading system at a garbage-collector \nspecified location. This is never a problem if addresses that do not point to the first page of an object \ncan be consid\u00adered invalid. Statically linked code for the SPARC architecture also probably represents \na worst case among modern architectures. And, as described in appendix B, the problem could be greatly \nreduced with trivial changes to the compiler and libraries.  The main conclusion to be drawn is that \nblacklist. ing is often an effective technique for nearly eliminating accidental retention caused by \ncollector conservativism, Under most conditions it should be sufficient to allow conservative collectors \nthat recognize arbitrary interior pointers to objects, with minimal or no changes to com\u00adpilers and libraries. \nIt can often be incorporated into a garbage collecting allocator at almost no performance cost.4 And \nit is, of course, completely invisible to client programs. 4More accurate techruques are possible at \nsubstantial perfor\u00admance cost, even for unmodified C code. For example, under suit\u00ad Machine Optimized? \nNo Blacklisting Blacklisting SPARC(static) no 79-79.5% 0-.5% SPARC(static) yes 78-78.5% .5-1% SPARC(dynamic) \nno 8-9.5% .5% SPARC(dynamic) yes 9-11.5% o-.5% SGI(static) no 1.5-8% o% SGI(static) yes 1-4% o% OS/2( \nstatic) no 28% 3% OS;2~staticj yes 26% 1% PCR mixed 44.5-55% 1.5-3.5% Table 1: Storage retention wit \nh and without blacklisting 3.1 Other Sources of Excess Retention A second, more subtle source of excess \nmemory reten\u00adtion is the fact that conservative collectors tend to have even less information about variable \nliveness than con\u00adventional collectors. A global variable may contain a valid pointer which is known \nto the programmer to no longer be useful, If the program had been written with garbage collection in \nmind, that variable might have been cleared. If the program was written in C for ex\u00adplicit deallocation, \nthen this is unlikely. Another form of this phenomenon occurs on many modern RISC ar\u00adchitectures. For \nreasons motivated either by efficient calling conventional by the existence of register win\u00addows, or \nby cache alignment considerations, these ar\u00adchitectures tend to encourage unnecessarily large stack frames, \nparts of which are never written, As a conse\u00adquence, a pointer a may be written to a stack location, \nthe stack may be popped to well below that pointer s location, the stack may grow again, and the garbage \ncollector may be invoked, with a again appearing live, since it failed to be overwritten during the second \nstack expansion. We observed this to be a significant effect, especially for small benchmark programs, \nwhich often make un\u00adrealistically heavy use of the stack. For example, this appears to have been a significant \nfactor for the perfor\u00admance problems reported in [11]. This part of the problem is not difficult to address \nin the garbage collector. We found two techniques to be useful: Often the initial pointer value that \nis then acciden\u00adtally preserved is stored by the allocator or collector itself. The client program may \nhave a very regular execution, ensuring that the same stack locations are always overwritten. But out-of-line \nallocation able conditions, we could run two copies of the same program with heap starting addresses \nthat differ by n. Any two corresponding locations whose vslues do not differ by n are then known not \nto be pointers. code and garbage collector code is triggered irregu\u00adlarly and relatively rarely. Thus \nit may pay to have the allocator and collector carefully clean up after themselves, clearing local variables \nbefore function exit. (Dead variable elimination in the compiler s optimizer may make it difficult to \nwrite such code for the garbage collector.) The allocator should occasionally try to clear ar\u00adeas in \nthe stack beyond the most recently activated frame. This is particularly useful when the allo\u00adcator is \ninvoked on a stack that is much shorter than the largest one encountered so far. A simple program (compiled \nunoptimized on a SPARC) that recursively and nondestructively reverses a 1000 el\u00adement list 1000 times \nresulted in a maximum of between 40,000 and 100,000 apparently accessible cons-cells at one point. With \na very cheap stack\u00adclearing algorithm added, we never saw the maxi\u00admum exceed 18,000 apparently live \ncons-cells. (The optimized version of the program never resulted in many more than 2000 cons-cells reported \nas acces\u00adsible, for either version of this particular program. The list reversal routine is tail recursive, \nand was optimized to a loop, thus eliminating the problem.) In the Cedar environment, we also observed \nthat stray stack pointers can significantly lengthen the lifetime of some objects, thus placing a ceiling \non the effectiveness of generational collection (cf. [20, 8]).  4 Consequences of Misidentifi\u00adcation \nThe impact of an individual false reference is greatly dependent on the data structures involved [23]. \nThe expected number of vertices retained as a result of a false reference to a balanced binary tree with \nchild links is approximately equal to the height of the tree. Thus a large number of false references \nto such structures can usually be tolerated. As Wentworth also points out [23], other data struc\u00ad tures \nexhibit much worse behavior. Queues and lazy lists in particular have the problem that they grow without \nbound, but typically only a section of bounded length is accessible at any point. A false reference can \nresult in retention of all the inaccessible elements, and thus unbounded heap growth. Fortunately, at \nleast in traditional imperative programs, such problems are usu\u00ad ally avoidable.5 In our experience, \na more common, but less well rec\u00adognized problem is the construction of large strongly connected data \nstructures. This can result in an un\u00adbounded memory leak only if the structures are large enough that \nthe probability of a false reference to a given structure is essentially one, which is unlikely with \nthe techniques of the previous section. Nonetheless, sub\u00adstantial leaks can result as in [14].6 A particularly \nproblematic programming practice is the use of linked list representations that involve pointer fields \nin the objects themselves, instead of separate lisp\u00adstyle cons -cells. If objects appear on more than \none list, this can greatly increase the connectivity of data structures, in ways that are not actually \nutilized by the program. As an example, consider a rectangular array of ver\u00adtices, which are linked both \nhorizontally and vertically. The structure is accessed either by traversing a row, or by traversing a \ncolumn, starting from the appropriate row or column header. An embedded link representation of the structure \nis shown in figure 3, and a separate link representation, with cons -cells represented by ovals, is given \nin figure 4. (The reader should imagine these as representative of a much larger grid. ) In the former \ncase, a false reference can be expected to result in the reten\u00adtion of a large fraction of the structure. \nIn the latter case, at most a single row or column is affected. When it is possible, the introduction \nof explicit cons \u00adcells conveys more information to the garbage collector than the use of embedded link \nfields, and should be encouraged, in the presence of any garbage collector. In the presence of a nonconservative \ncollector, there are no false references in our sense. But accidentally uncleared pointer variables (user \nor compiler introduced) or an inopportune promotion by a generational collector can have similar effects. \ns Queues no longer grow without bound if the queue link field is cleared when an item is removed. Note \nthat clearing links is much safer than explicit deallocation, since an error cannot result in random \noverwrites of unrelated modules data. In this case, it is also easy to decide when it is safe to clear \nlinks based on very local information. 6 Edelson s data structures exhibited this problem, essentially \nas described in figure 3, but with the addition of some cycles. He was using a version of our collector \nthat predated the addition of blacklisting. II Ii  [1J t+J  Figure 3: Rectangular grid with embedded \nlinks III III Figure 4: Rectangular grid with separate link cells Even with explicit deallocation, explicit \ncons -cells potentially allow much more prompt deallocation of parts of the data structure, and greatly \nreduce the prob\u00ad ability y of int reducing cycles. This may more than com\u00ad pensate for the small amount \nof additional storage re\u00ad quired. Thus this style may be preferable even with, ex\u00ad plicit storage management. \nIt is unfortunately at c)dds with some common C and C++ programming styks. Conclusions It is worth emphasizing \nthat at least on machines with sparse address spaces, the above considerations are im\u00adportant only on \nrare occasions. Data structures w;hich become unbounded with the addition of a stray refer\u00adence should \nbe avoided in very long-running applicat\u00adions, or when this data structure constitutes a signif\u00adicant \nfraction of the allocated storage. Circular clata structures are usually an issue only if they are huge \n(at least several megabytes), especially if blacklisting is used by the collector. Even before the addition \nof blacklisting, the large majority of observed instances of memory leakage in the Cedar environment \nwere caused by programmer errors resulting in genuine unbounded growth of data structures and not by \nfalse references. And even such errors are much less frequent (and gen\u00aderally have much more local repairs) \nthan similar errors in programs that use explicit deallocation. The addition of blacklisting appears \nto reduce the probability of longterm accidental storage retention through misidentified pointers to \nvery near zero. In combination with very mildly defensive programming, garbage-collector induced storage \nleaks should not be a problem with conservative collectors. As measured in [25], simply replacing explicit \ndealloc\u00adation in a leak-free program with conservative garbage collection is still likely to increase \nmemory consump\u00adtion. There are at least two reasons to expect this. First, programs that are written \nfor explicit deallc)ca\u00adtion are likely to keep deallocated memory accessible through program variables, \nHence some explicitly deal\u00adlocated memory will appear accessible to any collector, This phenomenon is \nclearly avoidable in code written for automatic garbage collection. Second, any tracing garbage collector \nwill require some fraction of the heap to be empty in order to avoid excessively frequent collections. \nThis appears unavoid\u00adable without resorting to reference counting. On the other side, even a completely \nnonmoving con\u00ad servative collector should gain a slight advantage over a malloc/free implementation, \nin that it is usually much less expensive to keep free lists sorted by address. I his increases the probability \ny that related objects are allo\u00adcated together, and thus increases the probability of large chunks of \nadjacent space becoming available in the future, decreasing fragmentation. A partially conserva\u00ad tive \ncollector can in addition compact some memory.7 Acknowledgements The idea of tracking previously encountered \nstray point\u00ad ers to minimize future retention of nongarbage grew out of a discussion with Barry Hayes. \nBarry was also the primary implementor of a refinement of the generational collector in PCR that eventually \nmade the effect of bo\u00ad gus stack references on generational collection painfully obvious. Daniel Edelson \nand Regis Cridlig helped to track down the performance problems they observed. Several program committee \nmembers provided useful suggestions. 0S/2 and C Set/2 are trademarks of IBM Corpora\u00ad tion. SPARC is a \ntrademark of SPARC International, Inc. SunOS is a trademark of Sun Microsystems, Inc. SPARCStation 2 \nis a trademark of SPARC Interna\u00ad tional, Inc. 80486 is a trademark of Intel Corporation, IRIX is a trademark \nof Silicon Graphics, Inc. References [1]Standard X3.159-1989, American National Stan\u00addard foT Information \nSystems -Programming Lan\u00adguage -C, American National Standards Institute, Inc. [2] Atkinson, Russ, Alan \nDemers, Carl Hauser, Chris\u00adtian Jacobi, Peter Kessler, and Mark Weiser, Ex\u00adperiences Creating a Portable \nCedar , Proceedings of-the ACM SIGPLAN 89 Conference on Program\u00adming Language Design and Implementation, \nSIG-PLAN Notices 24, 7 (July 1989), pp. 322-329. [3] Bartlett, Joel F. Compacting garbage collection \nwith ambiguous roots , Lisp Pointers 1, 6 (April-June 1988), pp. 3-12. [4] Bartlett, Joel F., Scheme \n-> C a Po? tab/e Scheme\u00adto-C Compiler, WRL Research Report 89/1, Digi\u00adtal Equipment Corporation Western \nResearch Lab\u00adoratory, January 1989. [5] Bartlett, Joel F., Mostly Copying Garbage Collec\u00adtion Picks Up \nGenerations and C++, Technical Re\u00adport TN-12, Digital Equipment Corporation West\u00adern Research Laboratory, \nOctober 1989. [6] Bekkers, Y,, 0. Ridoux, and L. Ungaro, Dy\u00adnamic Memory Management for Sequential Logic \nTE~pcrience with PCR suggests that traditiOn~ cOPYing strategies are unlikely to gain enough in compaction \nto make up for the extra space needed for copying. PCR heaps are often at least 70% full. Sliding compaction \navoids this limitation at some cost in time. [17] Omohundro, Stephen M., The Sather Language, ICSI, Berkeley, \n1991. [18] Rose, John R., and Hans Muller, Integrating the Scheme and C languages , P? oceedings of the \n1992 ACM Conference on Lisp and Functional PFogFam\u00adming, pp. 247-259. [19] Rovner, Paul, On Adding Garbage \nCollection and Runtime Types to a Strongly-Typed Statically Checked, Concurrent Language , Technical \nReport CSL-84-7, Xerox Palo Alto Research Center, Palo Alto, CA, July 1985. [20] Ungar, David M., Generation \nScavenging: A Non-Disruptive High Performance Storage Reclamation Algorithm , ACM SIGSOFT/SIGPLAN Software \nEngznee?zng Symposium on Practical Sofiwa? e De\u00advelopment Environments, SIGPLAN Notices 19, 5 (May 1984), \npp. 157-167. [21] Schelter, W. F., and M. Ballantine, Kyoto Com\u00admon Lisp , AI Expert 33 (1988), pp. 75-77. \n[22] Weiser, Mark, Alan Demers, and Carl Hauser, The Portable Common Runtime Approach to In\u00adteroperabilit \ny , Proceedings 13th ACM Symposium on Operating Systems Principles, December 1989. [23] Wentworth, E. \nP., Pitfalls of Conservative Garbage Collection , Soflwar e Practice 8 Expe? i\u00adence 20, 7 (July 1990) \npp. 719-727. [24] Wilson, Paul R., Uniprocessor Garbage Collec\u00ad tion Techniques , Proceedings of the \nInternational Workshop on Memo? y Management, St. Male, F~ance, Septembe? 1992, Springer LNCS 637, pp. \n1-42. [25] Zorn, Benjamin, The Measured Cost of Conserva\u00adtive Garbage Collection , University of Colorado \nat Boulder, Department of Computer Science Techni\u00adcal Report CU-CS-573-92. [7] [8] [9] [10] [11] [12] \n[13] [14] [15] [16] Programming Languages, national Workshop on Male, France, September pp. 82-102. Boehm, \nHans-J., and for Garbage-Collector-Safe Journal of C Language ber 1992), pp. 126-141, Boehm, H., A. Demers, \nProceedings of the Inter\u00ad.Mernory ikfanagement, St. 1992?, Springer LNCS 637, David Chase, A Proposal \nC Compilation , The Translation ~, 2 (Decem\u00ad and S. Shenker, Mostly Parallel Garbage Collection , Proceedings \nof the ACM SIGPLAN 91 Conference on Programming Language Design and Implementation, SIGPLAN Notices 26, \n6 (June 1991), pp. 157-164. Boehm, Hans-J. and Mark Weiser, Garbage col\u00adlection in an uncooperative environment \n, Softwa?e PTactice &#38; likpe?ience 18, 9 (Sept. 1988), pp. 807\u00ad 820. Chailloux, Emmanuel, A Conservative \nGarbage Collector with Ambiguous Roots for Static Type\u00adchecking Languages , Proceedings of the Inter\u00adnational \nWorkshop on Memory Management, St. Male, France, September 1992, Springer LNCS 637, pp. 218-229. Cridlig, \nRegis, An Optimizing ML to C Com\u00adpiler , ACM SIGPLAN Wod%hop on ML and its Applications, San Francisco, \nJune 1992, David MacQueen, chair. A. Demers, M. Weiser, B. Hayes, H. Boehm, D. Bobrow, S. Shenker, Combining \nGenerational and Conservative Garbage Collection: Framework and Implementations , Proceedings of the \nSeventeenth Annual ACM Symposium on Principles of Pro\u00adgramming Languages, January 1990, pp. 261-269. \nDetlefs, David L., Concurrent Garbage Collec\u00adtion for C++ , in Advanced Programming Lan\u00adguage Implementation, \nPeter Lee, ed,, MIT Press, 1991, Edelson, Daniel, A Mark-and-Sweep Collec\u00adtor for C++ , Conference Record \nof the Nine\u00ad teenth Annual ACM SIGPLAN-SIGA sium on Principles of Programming buquerque, New Mexico, \nJanuary Goldberg, Benjamin, and Michael morphic Type Reconstruction for tion without Tags , Proceedings \nof Conference on Lisp and Functional pp. 53-65. CT Sympo-Languages, Al\u00ad1992, pp. 51-58. Gloger, Poly-Garbage \nCollec\u00adthe 1992 A Clkf Programming, Hastings, Reed, and Bob Joyce, Fast Detection of Memory Leaks and \nAccess Errors , Proceedings of the Winter 92 USENIX conference, pp. 125-136. Appendix A: Program T vary \nmainly in the platforms they support. Most of the experiments were performed with multiple collec\u00ad/* \ntor versions, All the results were includedin the spec\u00ad * Allocate a cycle of n 4 byte objects. ified \nranges, The most recent version of this collec\u00ad * Iteturn a pointer into it. tor is currently availableby \nanonymous ftp from par\u00ad  */ cftp.xerox.com:pub/russell/gc.tar.Z, The collector uses char * allot-cycle(n) \nthetechniques of section 3.1 whether or not blacklisting . . . was enabled. SPARC A SPARCstation 2 running \nSunOS4.1.l us\u00ad# define li 200 /* number of lists *I ingthe bundled C compiler and the bundled C li\u00ad# \ndefine S 25000 /* nodes per list */ braries. The static version of the of the C library contains several \nlarge arrays (totalling more than 35K) of seemingly random integer values, appar\u00adchar * a[N]; ently used \nfor base conversion in the 10 library. void test(n) Contents of unused registers appear tobe nonde\u00adterministic, \nsince newly allocated register windows register int n; { register int i; are not cleared. This presumably \naccounts for the nonrepeatability of the results. for (i =O; i<N; i++){ The large number of false references \nin the static li\u00ada[i] = allot.cycle(n); brary case without blacklisting areprimarily dueto } the arrays \nmentioned above. Asecond majorsource for (i =O; i <N; i++) { of false references is that character strings \nare not a[i] = O; word-aligned by the compiler we used. A trailing } NUL character of one string, followed \nby the first } three characters of the next may appear to be a pointer. (This is easily avoidable on \nbig-endian maino machines, such as this one. A corresponding prob\u00ad{ lemwith the endofa stringis harder \nto avoidon register int i; little-endian machines.) /* Force recomition of interior nointe:rs */ . . \n. SGI An SGI 4D/35 running IRIX 4.0.1. Some tests test(S); were repeated under 4.0.5. The machine uses \na GC-gcollecto; MIPS R3000 processor in big-endian mode. The /* high variation in retained storage is \nnot entirely * Simulate further program understood, but is presumably also due to varying * execution \nto clear stack garbage register contents after system call or trap returns. * This is not terribly effective. \n  0S/2 An80486-basedPCrunningOS/2 2.0 with the*/ IBMC/Set2compilerandlibraries. Except forop\u00adtest(2); \ntimization and debugging switches, another com\u00adGC_gcollecto; pilation switches had default settings. \nprogram T /* was modified to only allocate 100 lists totalling 10* The statistics reported by MB, due \nto memory constraints on the machine* this collection are used in used for the measurement. This probably \nresulted* table 1 in slightly inflated fractions of retained objects,*/ since certain stack locations \nare likely to always return(0); . contain pointers togarbageobj ects, independentof the heap size. Measurements \nappeared completely reproducible, though probably not across compiler versions. This test used a collector \nsimilar to ver\u00adsion 2.5. (Earlier versions didn t support OS/2 cor- Appendix B: Platforms tested rectly. \n) facility, which allows selected otherwise unreach\u00adable heap cells to be enqueued for further action. \nThis required a few cells in each list to be allocated slightly differently. All interior pointers into \nthe 8-byte cells were considered valid by the collector. Measurements should be comparable to the above. \n With the exception of the PCR data, the experiments PCR A different version of program Twas run inside \nwere performed with versions 2.3 through 2.5 of our the Cedar programming environment on a SPARC\u00ad conservative \ngarbage collector. The different versions station 2. The program differed in that each list consisted \nof 12500 8-byte cells, instead of twice as benign; if they pin a large data structure, the many objects \nof half the size. (The second word heap will grow, changing the variable values, contained a magic number \nthat was used to help unpinning the structure. trace false references into the list. ) Furthermore, 2. \nGarbage left by the allocator itself on other statistics were gathered using the PCR finalization thread \nstacks. The test program was dynamically loaded into the Cedar world and invoked using the PCR inter\u00adpreter. \nThe test program was run in its own thread. The garbage collector was manually invoked until no more \nlists were finalized as the result of further invocations. (Once was usually enough.) The experiments \nwere run with very different sized Cedar address spaces, ranging from 1.5 to about 13 MB of other live \ndata at the beginning of the experiment. (In the 1.5 MB case, only the Cedar command interpreter and \nsome basic packages were loaded. In the 13 MB case, many other packages, including a window system, editor, \nand mailer were also loaded in the same address space. ) Interest\u00adingly, the number of loaded packages \nhad minimal effect on the amount of retained storage, and all numbers were included in the specified \nranges. The larger address spaces included more background threads that woke up regularly during the \nexper\u00adiment. This seemed to have a beneficial effect of clearing out thread stacks, and thus tended to \nre\u00adduce apparent leakage. The runs without blacklisting were made in an otherwise quiet Cedar world. \nSome of the runs with blacklisting were made in the same manner, while others were made with concurrently \nrunning Cedar clients. In one case, the concurrently run\u00adning Cedar code accounted for an additional \nexpan\u00adsion of 13 MB in live data during the test. Again, this seemed to produce minimal variation, and \nall results are included. We identified three sources of leakage that per\u00adsisted with blacklisting. All \nseemed to occur with comparable frequency, though the second seemed more common in smaller worlds, and \nthe third was slightly more noticeable in runs that occurred con\u00adcurrently with other allocation clients. \n1. Statically allocated variables that changed oc\u00adcasionally, but not frequently. Interestingly, in several \nruns the only variables responsible for such leakage basically contained the heap size, but were maintained \nby parts of PCR outside the collector, These are in a sense guaranteed 3. Occasional heap-resident pointers \ninto the lists. These p~obably resulted either from pages dedicated to 8 byte objects during PCR startup, \nbefore the blacklisting mechanism had a chance to see the source of the refer\u00adences, or as a result of \nfalse references created while the test program was running. PCR includes only small fractions of the \nSunOS C library. Most of the arrays mentioned under the SPARC description above are excluded. This ex\u00adplains \nthe improved numbers even without black\u00adlisting. The PCR collector does not attempt to clear t bread \nstacks, perhaps explaining some in\u00adcrease in remaining stack references. The PCR version was essentially \nidentical to PCR4-9. Results should be similar with the most recent version available by anonymous ftp \nfrom parcftp.xerox.com: pub/per (though the Cedar code is proprietary). The C code, including the test \nprogram itself was compiled unoptimized with the same compiler as above, The Cedar code was com\u00adpiled \nwith C optimization on the target code en\u00adabled. \n\t\t\t", "proc_id": "155090", "abstract": "<p>We call a garbage collector conservative if it has only partial information about the location of pointers, and is thus forced to treat arbitrary bit patterns as though they might be pointers, in at least some cases. We show that some very inexpensive, but previously unused techniques can have dramatic impact on the effectiveness of conservative garbage collectors in reclaiming memory. Our most significant observation is that static data that appears to point to the heap should not result in misidentified references to the heap. The garbage collector has enough information to allocate around such references. We also observe that programming style has a significant impact on the amount of spuriously retained storage, typically even if the collector is not terribly conservative. Some fairly common C and C++ programming style significantly decrease the effectiveness of any garbage collector. These observations suffice to explain some of the different assessments of conservative collection that have appeared in the literature.</p>", "authors": [{"name": "Hans-Juergen Boehm", "author_profile_id": "81423595101", "affiliation": "", "person_id": "PP31072798", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/155090.155109", "year": "1993", "article_id": "155109", "conference": "PLDI", "title": "Space efficient conservative garbage collection", "url": "http://dl.acm.org/citation.cfm?id=155109"}