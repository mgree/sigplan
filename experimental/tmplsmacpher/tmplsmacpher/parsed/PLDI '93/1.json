{"article_publication_date": "06-01-1993", "fulltext": "\n Detection and Recovery of Endangered Variables Caused by Instruction Scheduling Ali-Reza Adl-Tabatabai \nand Thomas Gross School of Computer Science Carnegie Mellon University Pittsburgh, Pennsylvania 15213 \nAbstract Instruction scheduling re-orders and interleaves instruction sequences from different source \nstatements, This impacts the task of a symbolic debugger, which attempts to present the user a picture \nof program execution that matches the source program. At a breakpoint l?, if the value in the run-time \nlocation of a variable V may not correspond to the value the user expects V to have, then this variable \nis endangered at B. This paper describes an approach to detecting and recovering endangered variables \ncaused by instruction scheduling. We measure the effects of in\u00adstruction scheduling on a symbolic debugger \ns ability to recover source values at a breakpoint. This paper reports measurements for three C programs \nfrom the SPEC suite and a collection of programs from the Numerical Recipes, which have been compiled \nwith a variant of a commercial C compiler. 1 Introduction A debugger allows a user to control the execution \nof a program (e.g., to set breakpoints) and to inspect the state of the execution (e.g., to print the \ncurrent value of a variable). To qualify as a symbolic debugger, all interactions must be Supported in \npart by the Defense Advanced Research Projects Agency, Information Science and Technology Office, under \nthe title Research on Parallel Computing, ARPA Order No. 7330. Work fnrnished in connection with thk \nresearch is provided under prime contract MDA972\u00ad90-C-0035 issued by DARPPJCMO to Carnegie Mellon University. \nThe views and conclusions contained in this document are those of the authors and should not be interpreted \nas representing the official policies, either expressed or implied, of the U.S, Government. Permission \nto copy without fee all or part of this material is granted provided that the copiee are not made or \ndistributed for direct commercial advantage, the ACM copyright notice and the title of the publication \nand its date appear, and notice is given that copying is by permission cf the Association for Computing \nMachinery. To copy otherwise, or to republish, requires iB fee and/or specific permission. ACM-SlGPLAN-PLDl-6 \n/93/Albuquerque, N.M. @ 1993 A(JM 0.89791 -598-4/93 /0006 /0013 . ..$1 .50 in terms of the high-level \nlanguage program that is the source for the object program. Optimizing compilers impact the task of the \nsymbolic debugger by complicating the correspondence between the source code and object code. By re-ordering \nor eliminat\u00ading the execution of source level expressions, optimizing compiler transformations complicate \nthe mapping of break\u00adpoints and values in the source code to those in the object code. One important \ntransformation that affects symbolic de\u00adbugging is instruction scheduling. Instruction schedul\u00ading can \nincrease the efficiency of modern processors with instruction-level parallelism by statically scheduling \ninde\u00adpendent instructions for concurrent execution. However, scheduling changes the sequence in which \nsource level expressions are computed by reordering or interleaving in\u00adstruction sequences from different \nsource statements. Con\u00adsequently, at a breakpoint, the run-time value of an in\u00adspected variable may not \ncorrespond to the value expected in the source. Consider the source and object codes shown in Figure \n1. Variable a has been assigned register R3, while variables b and p have both been assigned register \nR4. Variables c and d have been assigned registers R5 and R6 respec\u00adtively, and variables f and g both \nreside in memory. s,: d = f+g; 11: load RI, f S2: b = c*a; 12: load R2, g S3: *p = a; 13: store (R4) \n,R3 14: fpmul R4, R5, R3 Is: fpadd R6, RI, R2 Source code Object code (a) (b) Figure 1: Example The first \nthree columns of Table 1 show the correspon\u00addence between instructions and source expressions; it is \neasy to see how the instruction scheduler has interleaved and reordered the execution of instruction \nsequences from Breakpoint Source Expression Nonresident Endangered Variables Evaluated Variables Noncurrent \nSuspect Object Source by Instruction Roll Forward Roll Back 11S1f b 12SI CT b 13S3*pa b d 145 2 b=C*a \nb d *P 15SI d=f+g P b f,g Table 1: Endangered variables at breakpoints in the code of Figure 1 different \nstatements. For example, the assignment to d from statement S1 occurs at instruction 15, while the as\u00adsignments \nto b and *p of statements S2 and S3 occur at instructions 14 and 13 respectively. If a breakpoint occurs \nat instruction 14 (e.g., due to a floating point exception), the debugger will report that ex\u00adecution \nhas halted within statement S2. At this breakpoint, the user expects d to have the value assigned by \nstatement S1. However, this assignment to d has not yet executed (it is executed at 15), and the value \nin d s run-time location (i.e., the value in R6) is the value from the last executed assignment to d \nprior to this block. Therefore, the value in d s run-time location does not correspond to the value that \nthe user expects d to have in the source, and d is said to be noncurrent at this breakpoint [8]. If there \nis a breakpoint at 14, the assignment to *p of S3 has executed prematurely at instruction 13. Therefore, \nthe memory location M, pointed to by p, is also noncurrent since the value in M is not the value expected \nby the user. M maybe the home location of a variable, or it may be part of a dynamically allocated heap \nobject. The debugger can determine exactly which location M is noncurrent, since the value of p that \nwas used by the prematurely executed assignment of S3 is available in R4. However, consider a breakpoint \nat instruction 15, reported at statement S1. At this breakpoint, the assignment of S3 has again been \nexecuted prematurely, but the value of p used by S3 is un\u00adavailable because p s register (R4) is holding \nsome other variable s value (the value of b assigned at 14). There\u00adfore, the debugger cannot determine \nthe memory location M that is noncurrent and must conservatively assume any variable with a home locations \nin memory, i.e., f or g, may be noncurrent at this breakpoint. In this situation, f and g are said to \nbe suspect variables because the debugger can\u00adnot determine with certainty whether these variables are \nnoncurrent. In general, noncurrent and suspect variables are referred to as endangered variables; i.e., \nan endangered variable is a variable whose run-time value may not correspond to the variable s expected \nsource value. If a variable is not endangered, then it is current. The debuggers for most systems in \nuse today usually punt the issue of optimized code, by either turning opti\u00admization off whenever the \nuser asks for source level de\u00adbugging, or displaying the value in an inspected variable s assigned location \nwithout attempting to detect and warn the user that the variable is endangered. These approaches are \nunsatisfactory because: 1. The ability to debug optimized code is desirable and sometimes necessary \nand therefore should not be compromised [8,4,5]. 2. Displaying values without detecting and warning \nthe user of the effects of optimizations can mislead the user [5].  In this paper we present and evaluate \nan approach to de\u00adtecting endangered variables caused by instruction schedul\u00ading. We also consider a \nsimple but effective recovery scheme that improves the precision of the debugger in re\u00adtrieving source \nvalues at a breakpoint. We present data measuring the effects of instruction scheduling on a sym\u00adbolic \ndebugger s ability to retrieve source level values at breakpoints. We also present data showing that \nour recov\u00adery strategy can be effective. The data have been gathered for a collection of C programs fi-om \nthe SPEC suite and the Numerical Recipes, which have been compiled with a variant of a commercial C compiler. \nThe rest of this paper is organized as follows. Section 2 describes our debugger model and approach to \ndebug\u00adging optimized code. Section 3 presents our approach to detecting and recovering endangered variables \ncaused by instruction scheduling. Section 4 presents experimental results, and Section 5 presents our \nconclusions. 2 Debugger model The debugger can be invoked as a result of two types of breaks; synchronous \nand asynchronous. A synchronous break occurs when control reaches a control breakpoint that was set at \na source statement by the user. When a synchronous break invokes the debugger, the debugger re\u00adports \nthat execution has stopped at the statement S where the user has set a breakpoint. An asynchronous break \noc\u00adcurs when an instruction raises an exception, or when the user interrupts program execution. The debugger \nmaps the instruction I, at which execution is halted, to the source statement S, for which 1 was generated, \nand reports that execution has stopped due to an exception within source statement S, A data break occurs \nwhen the program writes to a stor\u00adage location that is monitored by a data breakpoint set by the user. \nA source statement may contain several as\u00adsignment expressions that may each cause a data break. Therefore, \nsince a data break can occur within a source statement, as opposed to at a statement boundary, a data \nbreak isconsidered to be an asynchronous break. Wedo not discuss the mechanics of how control or data \nbreak\u00adpoints are implemented [10, 13]. When a break occurs, the point in the object at which execution \nhas halted is called the object breakpoint, and the source statement where the breakpoint is reported \nis called the source breakpoint. A breakpoint refers to a pair < S, I >, where S is the source breakpoint \nand I the object breakpoint. The debugger can change the object code to implement control or data breakpoints, \ne.g., by using the techniques described in [10] and [13], but the compiler is not allowed to insert extra \ncode to make debugging easier. The debug\u00adger is also not allowed to modify the object code to ease retrieval \nof values, e.g., by saving values before they are lost or re-ordering code back to the original source \norder. Any change to the object code must be limited to the im\u00adplementation of breakpoints, i.e., the \ncode generated by the compiler for debugging is the same as the code generated otherwise so that debugging \nis non-invasive. There are many problems with allowing data modifica\u00adtion by a debugger s user in the \npresence of optimizations [8]. We do not address this problem in this paper, and data modification by \nthe user is not supported in our debugger model. 2.1 Retrieving source values We define the canonical \nexecution order of source expres\u00adsions to be the order in which expressions in the source program are \nsupposed to execute according to the semant\u00adics of the source language. During symbolic debugging, the \nuser expects source expressions to execute in canonical execution order. At a breakpoint < S, J >, the \nvalue that a user expects a variable V to have, relative to the source breakpoint S, is V s expected \nvalue, while the value in V s run-time location at 1 is V s actual value. In the example of Figure 1, \nat breakpoint < S3, 13> the expected value of d is the value assigned by statement S1. However, the actual \nvalue of d, i.e., the value in register R6, is the value assigned by the last assignment to d before \nthis block of code. Sometimes there may be no location holding a variable V s value at a breakpoint, \nand consequently no actual value of V may exist. For example, if a variable V has been assigned a register \nR, and the breakpoint lies outside of V s live range, then R may be holding the value of some other variable \nat the breakpoint. In the example of Figure 1, p has no actual value at < S1, 15> since p s assigned \nregister R4 k holding the value of b (assigned at 14) at this breakpoint. If, at a breakpoint B, the \ndebugger determines that the register assigned to a variable V is holding the value of some other variable, \nthen V is nonresident at B [1]. The fourth column of Table 1 lists the nonresident variables at breakpoints \nin the code of Figure 1. If the actual value of a variable V at a breakpoint B is identical to the expected \nvalue of V relative to the corre\u00adsponding source breakpoint, then V is current at B. Oth\u00aderwise, if the \nactual value of V may not correspond to the expected value of V, then V is endangered at the break\u00adpoint. \nEndangerment does not pertain to a nonresident variable, since such a variable does not have an actual \nvalue. This implies that if V is a register assigned vari\u00adable, then only after determining that V is \nresident can the debugger determine whether V is endangered. If the debugger can determine with certainty \nthat the actual value of V does not correspond to the expected value of V, then V is noncurrent at B. \nHowever, if a function call or indirect assignment operation is executed out of sequence, the debugger \nmay not be able to determine the operation s side effects on the memory state. As a result, if a variable \nV has a home location in memory (rather than assigned a register), the debugger is not able to determine \nwhether the actual value of V corresponds to the expected value of V at the breakpoint, and V is suspect \nat B. Objects allocated in the heap and referenced via pointers can also be endangered, noncurrent or \nsuspect. There are two ways in which a variable V may be non\u00adcurrent at a breakpoint B. Either an assignment \nto V has prematurely overwritten V s expected value, in which case V is a roll back variable, or the \nassignment that updates the expected value of V has been delayed until after the breakpoint, in which \ncase V is a roll forward variable [8]. For example, at breakpoint < S2, 14 > in Figure 1, d is a roll \nforward variable because the instruction correspond\u00ading to S1 s assignment (15) has not yet executed, \nwhile the object pointed to by p is a roll back variable because S3 has been executed prematurely at \nthis breakpoint. The last three columns of Table 1 list the roll forward, roll back and suspect variables \nat breakpoints in the code of Figure 1. To provide the expected value of a noncurrent vari\u00adable V, the \ndebugger may attempt to construct V s ex\u00adpected value from other run-time values. At breakpoint < SZ, \n14 > in Figure 1, the expected value of d is the a valid expected value. value assigned by S1, and computed \nby 15, The values of 15 s source registers (RI and R2) are computed at instruc\u00adticms 11 and 12, and are \nthus available at 14. Therefore the debugger can provide the expected value of d by interpret\u00ading 15. \nThis process is called recovery. When attempting recovery, the debugger must be prepared to handle the \ncase where the interpreted instructions cause an exception. To simplify execution resumption from a breakpoint, \nwe as\u00adsume that the debugger buffers recovered values into its own data structures rather than modifying \nthe halted pro\u00adgram s run-time state.  2.2 Evaluation order The expected value of a variable relative \nto a source break\u00adpoint is not always well defined because the evaluation or\u00adder may not be precisely \ndefined by the source language semantics. To determine expected source values at break\u00adpoints, the debugger \nmust accurately model the canonical execution order of expressions that have side effects. Usu\u00adally, \nthe canonical execution order of side effects from dif\u00adferent source statements is well defined, i.e., \nthe semantics specify that statements execute in sequence. However, in a C language expression containing \nmultiple side effecting expressions, the compiler is free to choose the evaluation order of the side \neffecting expressions. For example, in the code fragment of Figure 2, the assignment in state\u00adment S1 \nmust execute before the assignments in S2, and all assignments in SZ must execute before the assignment \nin S3, but the compiler is free to choose the evaluation order of the three assignments within statement \nS2. Thus, at an asynchronous break occurring during the execution of expression y++ within S2, the expected \nvalue of x is not uniquely defined since this value can be assigned by either S1 or by the expression \nx++ of S2. I.e., if the actual value of x corresponds to either of these two values, then x is current. \nIn practice most compilers impose an evaluation order during the translation from source to intermediate \nform. The debugger should not consider the compiler defined evaluation order as the canonical execution \norder, other\u00adwise the debugger will produce conservative and possibly misleading responses to the user. \nConsidering again the example of Figure 2, the compiler may impose a left to right evaluation order so \nthat x++ is evaluated before y++ at the intermediate representation level (i.e., before code generation). \nHowever, if the code generator delays the evaluation of x++ until after the evaluation of y++, and the \ndebugger uses the compiler defined evaluation order as the canonical execution order, then the debugger \nwill report x as noncurrent at a break occurring within y++. If the actual value of x is the value assigned \nby S1, then this response is not accurate since the actual value of x is SI: x=y +2; S2,: z = xi-+ + \ny++; S3: y=x+y; Figure 2: Undefined evaluation order in C  2.3 Approaches to debugging optimized code \nThere are several approaches that a debugger can take to handle code that has been optimized. The debugger \ncan try to completely hide the effect of optimizations, i.e., the de\u00adbugger presents the expected behavior \n[14,5]. To provide expected behavior non-invasively, the debugger must de\u00adtect all nonresident and endangered \nvariables and recover their expected values. Recovering the expected values is not always possible [2], \ntherefore like most other debuggers for optimized code we settle for trz@ul behavior [14,5] : the debugger \ndetects the set of variables that are nonresident or endangered, and either reports them as such in response \nto a user query, or attempts to recover their values, although recovery may not always be successful. \nThe recovery strategy has an influence on how often the debugger is able to present the expected value \nto a user, but in either case, the debug\u00adger is never allowed to present erroneous data to the user. \nIf an expected value cannot be presented, the debugger may provide additional guidance to the user by \nconvey\u00ading how optimizations have affected source values, For example, the debugger may tell the user \nat which source assignment(s) an endangered variable s actual value was (or may have been) assigned [2,5]. \nPrior work on debugging optimized code has made sim\u00adplifying assumptions for either the language model, \nthe debugger model, or both. For example, [8] considers only a subset of Pascal without pointers, while \n[5] does not con\u00adsider practical language aspects such as undefined evalu\u00adation order of assignment expressions \n[6]. Realistic lan\u00adguages like C do not completely specify the order of eval\u00aduation and allow aliasing, \nand the design of a debugger for optimized code must consider these language proper\u00adties. Another frequent \nsimplification is to allow break\u00adpoints only at pre-determined statement boundaries (e.g., [7] and [5]), \nbut in practice, debuggers are used for post\u00admortem analysis of programs, or can be invoked as a result \nof run-time faults, data breaks or user interrupts such as Control-C. Therefore, a debugger for optimized \ncode must provide accurate information at breakpoints occurring any\u00adwhere in the object code. Our work \nfocuses on using C as the source language, and our debugger model is gen\u00aderal, allowing breakpoints at \narbitrary points in the object code. No prior work has dealt with these issues in a single framework. \nSome debugger systems try to avoid the problem of deal\u00ading with optimized code by leaving it to the user \nto sort things out. Instead of trying to present the user with a view of the data space that matches \nthe source code, these systems provide either raw information (e.g., the current machine state) to the \nuser or convey the results of optimiza\u00adtion (e.g., statements eliminated), CXdb [4] is a recent example \nof such a debugger. It animates the execution of a source program by highlighting the source expression(s) \nthat is (are) being executed at each breakpoint. Basedl on this information, the user can determine how \nsource vallues are affected by optimizations. Such a visual annotation is useful if the user single-steps \nthrough the code; for each step, the source expression being executed is illuminated. However, if the \nprogram is run until a break occurs, CXdb tells the user at which source expression the break occurred \nbut fails to provide any history or context.  3 Detection and recovery Detecting and recovering endangered \nvariables at all possi\u00adble object breakpoints requires analysis of both the source and object programs \nto accurately determine expected and actual variable values. Hence language features and se\u00admantics (e.g., \npointers and evaluation order), effects of compiler transformations (e.g., re-ordering of operations \nand re-use of storage locations), as well as target machine features (e.g., concurrent execution of multiple \ninstruc\u00adtions), must be precisely modelled. In this section, we describe a model for detecting and recovering \nendangered variables. 3.1 Execution order To detect endangered variables, the debugger must first determine \nwhich source expressions have executed out of order at a breakpoint. Thus it is necessary to capture \nthe canonical execution order of source expressions and link this to the expressions object execution \norder. Like all optimizing compilers we are aware of, our compiler first maps source expressions to an \nintermediate representation (IR), and then the code generator maps the IR into machine instructions. \nSo our model must link source expressions with instructions in the object code via the IR. The canonical \nexecution order of IR operations is cap\u00adtured by annotating each expression A in the IR with a sequence \nnumber Seq(A). Given two IR operations A and B in the same basic block, Seq(A) < Seq(B) implies that \nA executes before B in canonical execution order, while Seq(A) = Seq(B) implies that the canonical execution \norder of A and B is undefined. In the example of Figure 2 the three assignment expressions of statement \nS2 will all have the same sequence number. The target machine model for our compiler and debugger is \na processor with a precise interrupt model; i.e., at an object breakpoint O, all instructions scheduled \nprior to O have executed, while no instructions scheduled at O or after O have completed execution or \ncaused side effects on the run-time state. Either an instruction at O raised an exception, a user interrupt \nhalted execution at O, or a breakpoint was reached at O. The order in which IR operations are executed \nin the object is determined by the code scheduler, and the code scheduler must pass this information \nto the debugger. Each IR operation may translate into multiple instructions, which are placed by the \nscheduler at different positions in the basic block schedule. Therefore, each IR operation N is annotated \nwith the list of instructions generated for N. The position of the last instruction (the one with the \nhigh\u00adest offset in the basic block schedule) generated for an IR operation N is denoted by Sched(N). \nSched(N) captures the relative order in which IR operations complete exe\u00adcution in the object: given \ntwo IR operations N and ill, Meal(N) < Sched(M) implies that N completes execu\u00adtion before M in the object, \nwhile Sched(N) = Sched(M) implies that N and M complete execution concurrently. For an IR operation A, \nsuch that A assigns to a variable V, Sclzed(A) is the basic block position of the instruction 1 that \nperforms the assignment. If V has been assigned a register, then 1 targets the register assigned to V, \noth\u00aderwise 1 stores to V s home location. Thus, the order in which assignments are executed is recorded. \nFor each instruction I, we record its position in the basic block schedule, denoted Offset(I). Since \nour code generator performs local instruction scheduling only, it is sufficient to record 1 s offset \nfrom the start of the basic block. Each instruction I is also annotated with the position (in the basic \nblock) of the last and next local definitions of its source and destination registers, denoted LastDefl \n(R) and NextDefI(R), where R is a source or destination register of 1. If no local last definition of \nR exists, then LastDefl(R) is 1. Similarly, if no local next definition of R exists, then NextDefl (R) \nis set to a value beyond the last position in 1 s basic block. The set of source registers of an instruction \n1 is de\u00adnoted by SourceRegs(I), and the destination register of an instruction 1 is denoted by DestReg(I). \nIf I is a load or store instruction, then 1 s set of address registers (e.g., base and index registers) \nis denoted by AddressRegs(I). I ~i~ definition covers statically scheduled machines that cm execute multiple \ninstructions (or machine operations) concurrently. Hence the need for the case where two instructions \nare scheduled at the same block offset. 3.2 Out-of-order operations When a break occurs at an instruction \nI, the object break\u00adpoint is mapped to the IR operation N for which 1 was generated, denoted IR(I), and \nreferred to as the IR break\u00adpoint operation. The annotated IR is then examined to detect which IR operations \nhave executed out of sequence with respect to the IR breakpoint operation. This approach is similar to \nHennessy s [8], however, our model considers values held in the physical registers of the machine as \nwell as individual instructions generated for each IR operation. Given an object breakpoint O and the \nIR breakpoint operation M, we call an IR operation N that is performed out of source order with respect \nto M an out-of-order IR operation at breakpoint O. There are two types of out-of\u00adorder IR operations: \no If N occurs before M in the canonical execution or\u00adder but is scheduled to complete after O, then N \nis a roll forward operation at breakpoint O, denoted RFOP(N, O). If N occurs after M in the canonical \nexecution or\u00adder but is scheduled to complete before O, then N is a roll back operation at breakpoint \nO, denoted RBOP(N, O). Using the IR annotations, the debugger can determine which operations are executed \nout of order. Let I be the instruction causing a break, M = IR(I) be the IR breakpoint operation, O = \nOffset(I) be the position of I in the basic block (the object breakpoint), and N an IR operation in the \nsame block as M: . [( Seq(N) < Seq(M)) A (Sched(N) z O)] * RFOP(N, O) [( Seq(N) > Seq(M)) A (Sched(N) \n< O)] =+ RBOp(N, O) We extend the above terminology to instructions. An instruction I that was generated \nfor an out-of-order IR operation IR(I) is an out-of-order instruction. If IR(I) is a roll forward (roll \nback) operation at an object breakpoint O, then I is a roll forward (roll back) instruction at breakpoint \no. 3.3 Noncurrent and suspect variables Having discovered which operations are out-of-order, the debugger \nmust then determine how the expected source state has been affected by such operations. If an IR oper\u00adation \nA is out-of-order at a breakpoint B, and A assigns to a variable V, then V is noncurrent at B. However, \nif the debugger cannot determine the side effects of A, e.g., a function call, then all variables that \nare potentially af\u00adfected by A are suspect at B. Operations that affect the source state are assignments \nand function calls. Therefore, only out-of-order assignment and function call operations are relevant \nto the detection of endangered variables. We distinguish between two forms of IR assignments: 1. Direct \nassignments. Assignments with Ivalue expres\u00adsions that are identifiers [9]; e.g., the assignment ex\u00adpressions \nat S l and S2 in Figure 1. 2. Indirect assignments. Assignments with lvalues that are of the form *E \nwhere E is an expression of pointer type; e.g., the assignment expression at S3 in Figure  1. Assignments \nto array elements (e.g., a [ i ] ) and assignments through structure pointers (e.g., p >x), also fall \ninto this category since the lvalue expressions of such assignments are transformed by the compiler into \nequivalent expressions of the form *E. If A is an assignment of the form *El = E2, we call El the address \nexpression of A. Out-of-order direct assignments cause noncurrent vari\u00adables, since the debugger can \ndetermine from the lvalue identifier exactly which variable is being assigned to. In the case of an out-of-order \nindirect assignment A of the form *El = E2, the debugger must retrieve the value of the address expression \nE 1 to determine which mem\u00adory location is affected by A. If the value of El can\u00adnot be retrieved, the \ndebugger must conservatively assume that all objects in memory may have been affected by A. Similarly, \nif a function call is out-of-order, the debugger cannot determine which memory locations may have been \naffected by the call. Thus, out-of-order function calls and indirect assignments (with non-recoverable \naddress expres\u00adsions) cause suspect variables. In the example of Figure 1, at breakpoint < S1, 15>, the \nassignments of S2 and S3 are both roll back operations. The assignment of S2 is a direct assignment to \nb, thus the debugger can determine that b is noncurrent. The assignment of S3 is an indirect assignment \nwith the address expression p. The value of p, however, cannot be recovered and the debugger cannot determine \nwhich memory location has been prematurely assigned by this assignment. Therefore, all variables in memory, \nin this case f and g, are reported as suspect. Note that variables that have been assigned registers \ncan\u00adnot be suspect since such variables are not affected by indirect assignments or function calls. \n 3.4 Recovery The IR annotations provide a correspondence between run\u00adtime values and IR expressions. \nThis correspondence al\u00adlows the debugger to recover values of IR expressions from the run-time state, \nthus providing more precise information to the user in two ways: 1 Recovering the values assigned by \nroll forwardl as\u00adsignments allows the debugger to provide the ex\u00adpected values of some roll forward variables, \nIf a roll forward assignment A assigns a variable V s expected value, and the value assigned by A is \nrecoverable, then the debugger can provide V s expected value. In Figure 1, the assignment of S l is \na roll-forward assignment that assigns the expected value of d at breakpoint <S2,14>. Thedebugger canrecover \nthe expected value of dby interpreting 15, the instruction that computes the value assigned by S1. Recovery \nof values assigned by assignment operations is called assignment recovery. 2. Recovering address expressions \nof indirect assign\u00adments allows the debugger to refine the set of suspect variables, since it allows \nthe debugger to determine precisely which memory location is affected by an out-of-order indirect assignment. \nFor instance, inl the example of Figure 1, at breakpoint < Sz, 11>, Is is a roll-back store instruction, \ncorresponding to an indi\u00adrect assignment, The value of 13 s address expression is available in R4 and \ncan be recovered, thus alllow\u00ading the debugger to determine which memory location was affected by the \nstore. The debugger then reports this location as noncurrent. At breakpoint < S1, 15>, 13 is again a \nroll-back store instruction, but 13 s ad\u00address expression value cannot be recovered because it was overwritten \nat 14. Recovery of address expres\u00adsion values is called address recovery. Both recovery strategies use \nthe same techniques but have different objectives. Address recovery attempts to provide a more precise \npicture of the current run-time state to the debugger, while assignment recovery provides the user with \nthe expected values of variables relative to the current breakpoint. Since assignment recovery is only \nuse\u00adful if the variable is not suspect, the debugger first attempts address recovery of roll forward \nand roll back indirect as\u00adsignments, and then attempts assignment recovery of roll forward assignments \n(either direct assignments or indirect assignments with recoverable address expressions). As has been \nnoted in earlier work [8], roll forward variables are easier to recover than roll back variables. Therefore, \nwe do not attempt recovery of roll back variables. 3.4.1 Address recovery Let Abe an indirect assignment \nexpression, and let 1 be the store instruction generated for A. A s address expression is recoverable \nat an object breakpoint O if the values in 1 s address registers have been computed but not subsequently \noverwritten: VR E AddressRegs(I) : (LasLDefl(R) < O) A (NextDefl(R) ~ O)  3.4.2 Assignment recovery \nLet A be a direct assignment of the form z = N, where z is an identifier. Let B be a breakpoint that \noccurs in the same block as A. If ~ is a register assigned variable, the compiler generates either a \nregister move operation that copies the value computed by N into the register assigned to z, or the last \ninstruction generated for N targets the register assigned to z. If z is a memory variable the in\u00adstruction \ngenerated for A is a store instruction that stores the value computed by N. In both cases, the value \nas\u00adsigned by A is recoverable if the value computed by N is recoverable. If A assigns x s expected value \nrelative to breakpoint 1?, and N s value is recoverable, then the debugger can provide Z S expected value. \nOn the other hand, if A is an indirect assignment of the form *E = N, in addition to N being recoverable, \naddress recovery must also recover the address expression E for A to be recoverable. We take a simple \napproach to recovering the value gen\u00aderated by an IR operation N. Let 1 be the last instruction generated \nfor N, and let O be the object breakpoint. N s value is available in the run-time state if either 1. \n(Offset(Z) < O) A (NextDefl(.DestReg( I)) ~ O) or 2. VR E SourceRegs(I) : (LustDefl(R) < O) A (NextDefl(R) \n~ O) and I is safe to execute.  In the first case, IR operation N has executed and its re\u00adsult is available \nin a register. In the second case, the last instruction of N has not executed but can be executed (actually \ninterpreted by the debugger) since its source reg\u00adisters are available. Hence we can compute 1 s value \nfrom 1 s source registers and obtain N s value. However, the debugger must be prepared to handle the \ncase that 1 may fault. The debugger cannot perform this computation if 1 is a function call instruction, \nor if 1 is a load instruction and memory locations are endangered. We do not inter\u00adpret function calls \nsince they transfer control out of the current basic block; such interpretation is difficult. Also, we \ndo not interpret loads since the values ,in memory may be endangered. Note that we can extend the above \nscheme to recover values from more than one instruction by tracing instruc\u00adtion dependence further. However, \nwe are interested in how well we can do with a simple scheme.   Experimental results Program I I I \nII We have implemented detection and recovery of endan\u00adgered variables as described above in a variant \nof acom\u00admercial C compiler: the iWarp C compiler pre-release ver\u00adsion 2.7. This compiler is based on \nthe PCC2 compiler from AT&#38;T that has been enhanced with global optimiza\u00adtion. The target machine \nis the iWarp microprocessor, a Long Instruction Word (LISV) machine with 128 registers, of which 94 are \navailable to the compiler. In a single cycle, the iWarp can execute a floating point multiplication, \na floating point addition, 2 integer operations or memory accesses, as well as a loop termination test \n[3]. The compiler performs global register allocation and as\u00adsignment, branch optimizations, unreachable \ncode elimina\u00adtion, and constant folding. Common subexpression elim\u00adination, value propagation, and instruction \nscheduling are performed at the basic block level. Function calls do not delimit basic blocks, and scheduling \nmay cause function calls to be reordered with respect to other operations. The code generator was modified \nto emit the informa\u00adtion and IR annotations described in Section 3; the object code is identical to the \ndefault code produced. Debugging is totally non-intrusive and the compiler does not effect any changes \nin the code, the memory layout, or any other aspect of the object program. For our experiments, the algorithms \nfor detecting and recovering endangered vari\u00adables are implemented in a separate program that analyzes \nthe object code and the annotated IR. This program also computes the statistics presented in this section. \nThe set of programs for this evaluation consists of three C programs from the SPEC integer suite (ii, \nespresso and eqntott)[ 12], and twelve programs from the Numerical Recipes collection (balanc, bessi, \nbessj, elmhes, fft, gaussj, hqr, jacobi, ludcmp, meo, svdcmp, and tred2)[l 1]. Each program from the \nlatter set consists of a small number of functions, and the results do not vary significantly between \nthe individual programs. Therefore, we average the results from the Numerical Recipes programs. Each \nfigure in this section contains four charts, one for each SPEC program, and one for the averaged results \nof the Numerical Recipes programs, referred to in the figures as recipes . The information presented \nin this section is collected by analyzing the code generator output for all possible break\u00adpoints and \naveraging the results by the number of break\u00adpoints. Since we are considering asynchronous break\u00adpoints, \nthe analysis is done for each instruction and the results averaged by the number of instruction. Since \nthe number of endangered variables at a break\u00adpoint is a function of the program and the code generator, \nwe measured how often instructions from different state\u00adments are being interleaved. The second column \nof Table 2 shows the average number of out-of-order instructions m Table 2: Effect of scheduling: Average \nnumber of out-of\u00adorder instructions per breakpoint (I), and average number of statements per basic block \n(II). at each breakpoint. For comparison, the average number of statements per basic block in the source \nprograms is shown in the third column. Although there are on the av\u00aderage only a few statements per basic \nblock, the compiler interleaves code quite frequently when the opportunity ex\u00adists. Basic blocks with \njust a single statements contain no out-of-order operations, and therefore no endangered variables. For \nli, only 1/5 of the basic blocks contains more than one statement on average, but nevertheless, on average, \n0.8 operations are out-of-order. The first column of the charts in Figure 3 shows the number of breakpoints \nthat contain endangered variables as a percentage of the total number of possible breakpoints in each \nbenchmark program. These are breakpoints with out-of-order assignment or function call operations. The \npercentage of such breakpoints ranges from approximately 9% (ii) to 21% (recipes). Operations that can \ncause endangered variables are clas\u00adsified into five categories: 1. Direct assignments to local variables \nthat have been assigned registers. 2. Direct assignments to local variables with home loca\u00adtions in \nmemory. 3. Direct assignments to global variables with home lo\u00adcations in memory. 4. Indirect assignments. \n 5. Function calls.  Columns 2 to 6 of Figure 3 show the percentage of break\u00adpoints with endangered \nvariables caused by each of these different kinds of operations. At a breakpoint there can be more than \none out-of-order operation, therefore the sum of the percentages of these columns may be more than the \ntotal shown by the first column. At the majority of breakpoints with endangered variables, an assignment \nto a register assigned variable is out-of-order and causes this variable to be noncurrent. The exception \nto this is li, which contains a large number of function calls, and where out\u00adof-order function calls \nare the main cause of endangered variables. The low number of out-of-order assignments to local variables \nin memory is due to the success of the register allocator in assigning registers to local variables. \nOut-of-order function calls are the second largest contrib\u00adutor for the other SPEC benchmarks. This shows \nthat if a scheduler operates on basic blocks that are not delim\u00adited by function calls, a significant \nnumber of function calls may be out-of-order at a breakpoint. The numeri\u00adcal recipes benchmark consists \nmainly of computations on arrays, with relatively few function calls. Therefore this benchmark has a \nhigher percentage of breakpoints with endangered variables caused by out-of-order pointer as\u00adsignments \n(4 %o) and a low percentage of breakpoints with out-of-order function calls. In the SPEC programs, out \nof order indirect assignments occur at about 270 of all break\u00adpoints. Out-of-order function calls are \nproblematic in that the debugger cannot determine a function call s effect on the program state in memory. \nThus a debugger must report a memory variable as suspect at a breakpoint B, if there exists an out-of-order \nfunction call at B. Out-of-order in\u00addirect assignments are similarly problematic if the debug\u00adger cannot \nrecover the address of the assigned memory location. The variables affected by direct assignments can \nbe precisely determined by the debugger, and hence these types of assignments do not cause suspect variables. \nFigure 4 depicts the effect of address recovery. Since we may not be able to count the number of variables \nthat are suspect (all variables on the heap may be included, and their number can only be determined \nat run-time), we have to use the number of breakpoints with suspect (or noncurrent) variables to illustrate \nthe effect of recovery. The first column in the charts of Figure 4 shows the number of breakpoints with \nendangered variables (from Figure 3) and is repeated here for reference. The second column of the charts \nshows the percentage of breakpoints with noncurrent variables, i.e., breakpoints with out-of\u00adorder direct \nassignments. The third column shows the per\u00adcentage of breakpoints with suspect variables, i.e., break\u00adpoints \nwith out-of-order indirect assignments or function calls. This data indicates that there are more breakpoints \nwith noncurrent variables than there are breakpoints with suspect variables. However, there are still \na significant number of breakpoints with suspect variables. In the case of li there are almost as many \nbreakpoints with suspect variables as there are breakpoints with noncurrent vari\u00adables. When a function \ncall or indirect assignment is out-of\u00adorder at a breakpoint, the number of suspect variables can be quite \nlarge since all memory variables and objects will be suspect. Any success in identifying the effect of \nthe in\u00addirect assignments allows the debugger to provide the user with more precise information, and \nthus improves the qual\u00adity of the debugger. The last two columns in the graphs of Figure 4 show the effects \nof recovering addresses of clut\u00adof-order indirect assignments. As expected, the number of breakpoints \nwith suspect variables variables decreases while the number of breakpoints with noncurrent variables \nincreases. Address recovery reduces the number of break\u00adpoints with suspect variables to approximately \nthe number of breakpoints with out-of-order function calls, which is the limit on how well address recovery \ncan do. Figure 5 breaks down the percentage of breakpoints with out-of-order assignments and function \ncalls into break\u00adpoints with roll forward and roll back operations. Again, the first column is repeated \nfrom Figure 3. We see that there are more breakpoints with roll forward operations (Column 2) than ones \nwith roll back operations (Column 3). This is good news for the user interested in obtaining the expected \nvalue of a variable: for a roll forward oper\u00adation M, either the debugger may attempt to recover the \nvalue using the approach described in Section 3.4, or the user may set a breakpoint at the point where \nM is even\u00adtually computed to recover the value computed by M. This figure also breaks down the breakpoints \nwith roll forwardlroll back operations according to whether they cause suspect or noncurrent variables. \nAlmost all roll back operations are direct assignment operations (Columns 3 and 5); roll back function \ncalls or indirect assignments are very rare (Column 7). That is, almost all suspect variables are caused \nby roll forward operations, and those can be potentially recovered by the debugger. A user of a debugger \nmay want to know how many vari\u00adables are suspect or noncurrent at the average breakpoint. As explained \nabove, this number cannot be obtained us\u00ading the static analysis tools developed, since the number of \nsuspect memory variables is dynamic (and may differ from one run of a program to another). However, for \nother out-of-order operations, a better breakdown is pos\u00adsible and is presented in Figure 6. This figure \nshows the average number of roll forward operations per breakpoints with noncurrent or suspect variables, \nfor the different types of assignments and for function calls. Columns 1, 3, 5, 7, and 10 show the average \nnumber of roll forward direct assignments to register assigned variables, local variables in memory, \nand global variables in memory, of indirect assignments, and of roll forward function calls, respec\u00adtively. \nAlso shown is the average number of roll-forward assignments whose values are recoverable using our sim\u00adple \napproach to assignment recovery (Columns 2,4, 6, 9). In many of the cases, most of the roll forward assignments \nare recoverable. Note that to recover an out-of-order in\u00addirect assignment, both the address expression \nas well as the assigned value must be recoverable. We see that ad\u00address recovery is successful in recovering \nthe addresses of most roll forward indirect assignments (compare Column 7 with Column 8), but there are \nsome for which only the the address expressions can be recovered (compare Column 8 with Column 9). Benchmark \nI I II Ii 8.8 6.1 espresso 12.9 9.0 eqntott 14.5 10.7 recipes 20.8 16.2 Table 3: Effects of recovery: \nBreakpoints with out-of\u00adorder function calls or assignments total (I) and after re\u00adcovery (II). Address \nrecovery is also successful in recovering the addresses of the majority of roll back indirect assignments. \nHowever, these results were not shown because rollback indirect assignments are so rare that their effects \ndo not show in the graph (see Figure 5 for the overall frequency). In the case of roll forward operations \nthat are direct assignments or indirect assignments with recoverable ad\u00addresses, the numbers in this \ngraph are also upper bounds on the number of roll forward variables that are caused by these assignments, \nsince each assignment can assign to only one variable (but more than one may assign to the same variable). \nIn summary, there exist a noticeable number of static breakpoints with endangered variables (between \n9% and 219. in our suite). A simple recovery scheme as described in this paper reduces the number of \nbreakpoints with en\u00addangered variables. Table 3 presents the bottom line and shows how recovery affects \nthe number of breakpoints where the debugger can provide the expected values of source variables.  Conclusions \nInstruction scheduling is an important aspect of code gen\u00aderation, and a large number of modern compilers \ninclude some form of instruction scheduling. This optimization causes endangered variables by re-ordering \nthe execution of source expressions. There exist two mutually exclusive classes of endangered variables: \nthose for which the de\u00adbugger can deduce that the actual value is not the expected value, and those for \nwhich the debugger is not sure. A de\u00adbugger that wants to exhibit truthful behavior must detect all such \nvariables and warn the user if such a variable is queried. Detecting noncurrent variables caused by instruction \nscheduling requires accurate modelling of source and ob\u00adject execution orders. When debugging a realistic \nlanguage such as C, out-of-order pointer assignments and function calls may inhibit the debugger from \nprecisely detecting which variables are noncurrent. Our results show that the impact of out-of-order \nfunction calls can be significant. A simple recovery scheme that rolls forward a sin\u00adgle instruction \nis effective for recovering the values as\u00adsigned by out-of-order assignments and can reduce the number \nof variables for which the debugger cannot re\u00adport the expected value. Further work is ongoing to in\u00advestigate \nwhether better results can be obtained by rolling forward through more instructions. Recovering address \nvalues from the physical registers can reduce the number of out-of-order assignments that cause suspect \nvariables. By recovering the address, the debugger can determine the effect of the indirect assignment \non the programmer-visible state of the machine. Both techniques are effective and re\u00adduce the number \nof breakpoints with endangered variables. Acknowledgements We thank Amer Diwan, Scott Nettles, David \nTarditi, Bob Wheeler, and Po-Jen Yang for helpful comments on an earlier draft of this paper.  References \n[1] A. Adl-Tabatabai and T. Gross. Evicted variables and symbolic debugging of optimized code. In Proc. \n20th POPL Corf, pages 371-383. ACM, January 1993. [2] Ali-Reza Adl-Tabatabai. Nonresident and endan\u00adgered \nvariables: The effects of code generation opti\u00admization on symbolic debugging. Technical Report CMU-CS-92-221, \nCMU, December 1992. [3] S. Borkar, R. Cohn, G. Cox, S. Gleason, T. Gross, H. T. Kung, M. Lam, B. Moore, \nC. Peterson, J. Pieper, L. Rankin, P. S. Tseng, J. Sutton, J. Urban\u00adski, and J. Webb. iwarp: An integrated \nsolution to high-speed parallel computing. In Proceedings of Su\u00adpercomputing 88, pages 330 339, Orlando, \nFlorida, November 1988. IEEE Computer Society and ACM SIGARCH. [4] G. Brooks, G. Hansen, and S. Simmons. \nA new ap\u00adproach to debugging optimized code. In Proc. SIG-PLAN 92 Con$ on PLDI, pages 1 11. ACM SIG-PLAN, \nJune 1992. [5] M. Copperman. Debugging optimized code without being misled. Technical Report 92-01, UC \nSanta Cruz, May 1992. [6] M. Copperman. Personal communication. 1992. [7] D. S. Coutant, S. Meloy, and \nM. Ruscetta. Dot: A practical approach to source-level debugging of globally optimized code. In Proc. \nSIGPLAN 1988 Con. on PLDI, pages 125-134. ACM, June 1988. [8] J. L. Hennessy. Symbolic debugging of \noptimized code. ACM Trans. on Programming Languages and Systems, 4(3):323 344, July 1982. [9] B. W. \nKernighan and D. M. Ritchie. The C Pro\u00adgramming Language. Prentice-Hall, Inc., Englewood Cliffs, New \nJersey, 1978. [10] P. Kessler. Fast breakpoints: Design and implemen\u00adtation. In Proc. ACM SIGPLAN 90 \nCon$ on PLDI, pages 78 84. ACM, June 1990. [11] W. H. Press, B. P. Flannery, S. A Teukolsky, and W. \nT. Vetterling. Numerical Recipes in C. Cambridge University Press, 1991.  [12] J. Uniejewski. Spec \nbenchmark suite: Designed for today s advanced systems. SPEC Newsletter, l(l), Fall 1989. [13] R. Wahbe. \nEfficient data breakpoints. In Proc. Fijlh Intl. Con~ on Architectural Support for Progratn\u00adming Languages \nand Operating Systems (ASPLOS V), pages 200-212, Boston, October 1992. ACWIEEE. [14] P. Zellweger. An \ninteractive high-level debugger for control-flow optimized programs. In Proc. of the ACM SIGSOFT/SIGPL4N \nSo@vare Engineering Symposium on High-Level Debugging, pages 159 171. ACM, 1983. eqntott recir)es I Breakpoints \nwith noncurrent or suspect variables o Breakpomta with out-of-order assignments to register assigned \nIkxala o Breakpoints w,th out-of-order ass,gnmenta to memory Iocala o Breakpoints with out-of-order \nasalgnmenta to memory globals o Breakpoint with out-of-order md,rect assignments m Breakpoints with \nout-of-order functmn calls   Figure 3: Breakpoints with operations causing endangered variables I \nII espresso -, espresso I 20 i eqntott eqntott reccpes recipes o Breakpoints withnoncurrent ors.spectvanables \n o Breakpoints with noncurrent or suspect variables  o Breakpoints wlthroll fomardass,gnments or function \ncalls f J Breakpointa with noncurrent variablea ~ Breakpoints withroll backaas!gnments or f.nctlon calls \n~ Breakpoints w,th suspect variables &#38; Breakpoints w!throll forward direct assignmenta o Breakpoints \nw,th hO.C.rrent variables after addresa recovery o Breakpoints wlthroll backdire.t assignments o Breakpoints \nwith suspect variables after address recovery o Breakwlnts w]throll fowardlndlrect assignments or function \ncalls ~ Breakpoints w,throll backlndrect asa,gnments or funct!on calls  Figure 4: Breakpoints with suspect \nand noncurrent vari-Figure5: Breakpoints with roll forward androllbackop\u00adables, with and without address \nrecovery erations 24 0.6 0.5 0.4 0.3 0.2 0.1 0 0.8 0.7 06 1 0.5\u00ad0.4\u00ad0.3\u00ad 0.1\u00ad0 0.9 0.8\u00ad0.7\u00ad0.6\u00ad0.5\u00ad0.4\u00ad0.3\u00ad0.2\u00ad \n0 Roll forward Recoverable Roll forward Recoverable Roll foward Recoverable o Roll forward El Roll forward \no Recoverable Ezl Roll forward o L assignment roll forward assignments roll forward assignments roll \nforward espresso eqntott recives to register assignments to memory asaignmenta to memory aasignmenta \nasaigned locals to register bcals to memory globals to memory indirect assignments indirect assignments \nwith recoverable roll forward indirect assignments funct!on cane asaigned locals locals globals addresses \n Figure6: Average number ofrollforward and recoverable operations \n\t\t\t", "proc_id": "155090", "abstract": "<p>Instruction scheduling re-orders and interleaves instruction sequences from different source statements. This impacts the task of a symbolic debugger, which attempts to present the user a picture of program execution that matches the source program. At a breakpoint <italic>B</italic>, if the value in the run-time location of a variable <italic>V</italic> may not correspond to the value the user expects <italic>V</italic> to have, then this variable is <italic>endangered</italic> at <italic>B</italic>. This paper describes an approach to detecting and recovering endangered variables caused by instruction scheduling. We measure the effects of instruction scheduling on a symbolic debugger's ability to recover source values at a breakpoint. This paper reports measurements for three C programs from the SPEC suite and a collection of programs from the Numerical Recipes, which have been compiled with a variant of a commercial C compiler.</p>", "authors": [{"name": "Ali-Reza Adl-Tabatabai", "author_profile_id": "81100032153", "affiliation": "", "person_id": "PP14023844", "email_address": "", "orcid_id": ""}, {"name": "Thomas Gross", "author_profile_id": "81332502168", "affiliation": "", "person_id": "PP39077266", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/155090.155092", "year": "1993", "article_id": "155092", "conference": "PLDI", "title": "Detection and recovery of endangered variables caused by instruction scheduling", "url": "http://dl.acm.org/citation.cfm?id=155092"}