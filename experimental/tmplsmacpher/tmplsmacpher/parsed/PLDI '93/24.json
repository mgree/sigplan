{"article_publication_date": "06-01-1993", "fulltext": "\n Lifetime-Sensitive Modulo Scheduling Richard A. Huff* Department of Computer Science Cornell University \nIthaca, NY 14853 (607) 254-8830 huff@cs . cornell .edu Abstract This paper shows how to software pipeline \na loop for mini\u00admal register pressure without sacrificing the loop s minimum execution time. This novel \nbidirectional slack-scheduling method has been implemented in a FORTRAN compiler and tested on many scientific \nbenchmarks. The empirical results when measured against an absolute lower bound on execution time, and \nagainst a novel schedule-independent absolute lower bound on register pressure indicate near\u00adoptimal \nperformance.  Introduction Software pipelining increases a loop s throughput by over\u00adlapping the loop \ns iterations; that is, by initiating successive iterations before prior iterations complete. Whh sufficient \noverlap, a functional unit can be saturated, at which point the loop initiates iterations at the maximum \npossible rate. To find an overlapped schedule, a compiler must represent the complex resource constraints \nthat can arise. Efficiently representing these constraints is especially difficult when ad\u00adjacent iterations \ndo not follow a common schedule but instead follow a pattern that repeats only after several iterations. \nThe problem is greatly simplified by restricting the search to a common schedule that initiates successive \niterations at a constant rate. This restriction leads to the modulo constraint no resource may be used \nmore than once at the same time modulo the initiation interval of II cycles. The resulting re\u00adsource \nconstraints are easily represented in a modulo resource table with II entries: each entry keeps track \nof the various machine resources that can be reserved during a cycle. The *Partof thisresearchwasperformedasanemployw \nof Hewlett-Packrrd Laboratories. The work at Cornell was supportedby NSF Presidential YoungInvestigatorawardCCR-8958543,by \nNSF grant CCR-9008526, and by ONR gmnt NOOO14-93-1-O1O3. Permission to copy without fee all or part of \nthis material is granted provided that the copies ere not made or distributed for direct commercial advantage, \nthe ACM copyright notice and the title of the publication and its date appear, and notice is given that \ncopying is by permission of tha Association for Computing Machinery. To copy otherwise, or to republish, \nrequires a fee and/or specific permission. ACM-S lGPLAN-PLDl-6/93 /Albuquerque, N.M. @ J993 ACM O-8979 \nJ-598-4/93/0006 /0258 .,. $J.50 compiler s primary task is to schedule the loop at a minimal II, thereby \nmaximizing the loop s throughput. The overall discipline is called modulo scheduling [17]; for a detailed \nintroduction, consult [14]. Prior scheduling research has focussed on achieving mini\u00admal execution time, \nwithout regard for whether the heuristics unnecessarily inflate register pressure. Ever since the studies \nof the late 1970 s [10, 16], most people have advocated using list scheduling, in either a top-down or \nbottom-up fashion. Consequently, most schedulers consider each cycle in turn, packing it full of operations \nbefore considering the next cycle [7, 24, 12]. e For software pipelining loops with recurrences, where \na cycle-by-cycle approach is inherently inadequate, com\u00adpilers have considered each operation in turn, \nalways placing an operation as early as possible in the partial schedule constructed thus far [9, 6]. \nAlthough the first approach can avoid excessive pressure at some cost in execution time [8, 3], neither \napproach schedules for minimal register pressure. In general, uni\u00addirectional strategies (top-down or \nbottom-up) unnecessarily stretch operand lifetimes; for example, by scheduling loads too early or stores \ntoo late. This paper presents a novel bidirectional strategy that si\u00admultaneously schedules some operations \nlate and other oper\u00adations early. The resulting slack-scheduling framework mod-U1Oschedules a loop for \nminimal register pressurel with an in\u00adcreased likelihood of achieving a minimal II. This framework has \nbeen integrated into Cydrome s FORTRAN77 compiler [6] and tested on all eligible DO loops in the Lawrence \nLivermore Loops, the SPEC89 FORTRAN benchmarks, and the Perfect Club codes-a total of 1,525 loops. The \nscheduler s perfor\u00admance on these loops when measured against an absolute lower bound on II, and against \na novel schedule-independent absolute lower bound on register pressure indicates near\u00adoptimal performance. \nThe next section describes the compiler s target machine, Section 3 defines the schedule-independent \nlower bounds 1An intinita supply of registers is assumed, in order to measure register pressure rather \nthan what can be done when spitl code is allowed. Besides, no one as yet has a good strategy for spilling \nregisters in a software pipeline. Pipeline No. Operations Latency n Memory Port 2 load 13 store 1 Address \nALU 2 addr add/sub/mult 1 Adder 1 int add/sub/logical 1 float addjsub 1 Multiplier 1 int/float multiply \n2 Divider 1 int/float div/mod 17 float sqrt 21 Branch Unit 1 brt op 2 Table 1: Functional Unit Latencies \non II and register pressure. Section 4 presents the slack\u00adscheduling framework. Section 5 presenta a \nbidirectional scheduling heuristic that adds lifetime sensitivity to the slack\u00adscheduling framework. \nThe scheduler s execution time is analyzed in Section 6. Performance measurements are shown in Section \n7. Finally, Section 8 offers some comparisons with related work. 2 Target Machine The target machine \nis a hypothetical VLIW processor similar to Cydrome s Cydra 5 [20, 2], including architectural support \nfor overlapping loops without using code duplication [5]. Nevertheless, the scheduling techniques shown \nin this paper can be directly applied to conventional RISC machines [14, 23], albeit at the expense of \ncode expansion [19]. 2.1 Functional Units Functional-unit latencies are given in Table 1. The com\u00adpiler \nassumes the responsibili~ for honoring these lakm\u00adcies, scheduling no-ops wherever necessary, All functicmal \nunits are fully pipelined; except for the divider, which is not pipelined at all. The b rt op conditional \nbranch conve\u00adniently combines several loop-management duties into one instruction [5]. The load latency \nof 13 cycles was chosen to represent the cost of bypassing a first-level cache and hitting a large Ioff\u00adchip \nsecond-level cache a reasonable choice for a compliler that does not perform any loop-tiling transformations \nE25]. A memory latency register specifies the load latency that the compiler has chosen to schedule for. \nThe hardware honors tlds load latency by freezing instruction issue whenever a load does not complete \nin time. 2.2 Predicated Execution Every operation has a l-bit predicate input. If the predicate is false, \nthen the hardware treats the operation as a no-op, else it executes the operation as usual. Predicated \nexecution often eliminates the need for a condi\u00adtional branch, as operations from both sides of the conditional \nsubroutine sample (n, x, y) real*4 x(n) , y(n) do 2i=3, n x(i) = x(i 1) + y(i 2) y(i) = y(i 1) + x(i-2) \n2 continue return end Figure 1: A Sample Loop may be issued with the unwanted results being safely no\u00adop \nd, This optimization generalizes to if-conversion [1, 13], which transforms unstructured acyclic code \ninto branch-free predicated code. Since modulo scheduling is applicable only to loops with branch-flee \nbodies, if-conversion allows more loops to be modulo scheduled. Finally, predicated execution greatly \nsimplifies code generation after modulo scheduling a loop; see [19] for details. To address the problem \nof modulo scheduling loops-with\u00adbranches on machines without predicated execution, two ex\u00adtensions to \nmodulo scheduling have been developed; namely, hierarchical reduction [9], and enhanced modulo schedul\u00ading \n[23]. In essence, each approach reduces the problem to scheduling branch-free loop bodies, at the cost \nof code expansion.  2.3 Rotating Register Files When modulo scheduling a loop, it k quite common for \nan operation s result to be live for more than II cycles, thus preventing the operation from targeting \nthe same register in adjacent iterations. For example, consider the loop shown in Figure 1. Each iteration \ngenerates a pair of values (z(z) and Y(z)) that are used two iterations later. Dataflow analysis can \ndetect that the values may be passed from iteration to iteration within registers rather than main memory. \nPerforming this load/store elimination [15, 6] leaves the resulting registers live for more than II cycles, \nas will be illustrated shortly. The compiler must ensure that the successive outputs of an operation \ncan be kept in distinct registers. In the absence of hardware support, the loop may be unrolled and the \nduplicate register specifiers renamed appropriately [9]. However, this modulo variable expansion technique \ncan result in a large amount of code expansion [18]. A rotating register file can solve this problem \nwithout du\u00adplicating code. Consider saving the series of values generated by an operation in its own \ninfinite pushdown stack. O!d val\u00adues can be read out of anywhere in the stack, and new values can be \npushed on top, but a value cannot be modified once it has been pushed onto the stack, that is, the stack \nenforces a dynamic single assignment discipline [15]. Since each value pushed onto the stack has the \nsame lifetime, only a constant portion of the stack is live at any given moment. In par\u00ad with the maximum \nsuch ratio determines a lower bound on II-call it ResMII. Consider recurrence circuits. A recurrence \ncircuit from an operation to an instance of itself Omega (Q iterations   r-+==+ later, must have a \ntotal latency L of no more than the Q x II Figure 2: Concatenating Shifters titular, once the software \npipeline reaches its steady state, each stack acts like a finite shifter that shifts its values once \nevery II cycles. A rotating register file can be thought of as a concatenation of these shifters-end \nto end into a finite circular queue, as illustrated in Figure 2. The implementation of a rotating register \nfile is quite sim\u00adple. Consider a file of 2m registers. The illusion of rotation is created by adding \n(modulo 2 ) each n-bit register specifier to a dedicated n-bit iteration control pointer (ICP). The ICP \nis decremented every II cycles by the loop s brt op condi\u00adtional branch instruction. Thus rotation is \nsimply a stylized mechanism for indirectly addressing a register file. As an illustration of rotation \nat work, consider Figure 3, which shows a naive allocation of the values for z(i) and y(i) within a rotating \nfile of six registers. (Other loop variants have been omitted for clarity.) The values generated by the \ntirst iteration are shown in bold face. Lifetimes are outlined with ovals. When the figure says that \nz(i) has a lifetime of [0,5), it means that the first iteration of the loop reserves a register for z(3) \nat cycle O, and that this register may not be overwritten until its last use at cycle 5. At each cycle \nin the space-time diagram, the ICP points to the register directly above the solid bar. At cycle O, the \nrotating register file contains the initial live-in values for each recurrence. Unlike the Cydra 5, the \ntarget machine has only three register files, two of which rotate: the ICR file contains ro\u00adtating predicates, \nused for iteration control and if-converted code; the RR file contains rotating addresses, ints, and \nfloats; and the GPR file contains loop-invariant addresses, ints, and floats. In order to measure register \npressure, the compiler assumes that each register file is infinite. 3 Absolute Lower Bounds 3.1 Lower \nBounds on II A loop s minimum II is bounded below by two factors: re\u00adsource contention and recurrence \ncircuits. Consider resource contention. If each iteration of the loop requires N units of a resource \n(e.g., integer adders), and the machine can supply at most R units of the resource per cycle, then II \nmust be at least [N/Rl. Therefore the resource An optirnaf allocation would use onfy four rotating registers, \ncycles that separate the two operations. Hence a feasible schedule must have II > [L/Ql. Therefore the \nelementary recurrence circuit with the maximum such ratio determines a lower bound on II call it RecMII. \nTo enable the scheduler to compute the Q for a recur\u00adrence circuit, the dependence analyzer labels each \ndepen\u00addence arc with its omega (w), which is the minimum number of iterations that must separate the \noperations of the depen\u00addence. The compiler s front-end performs important code optimization, such as \nloadlstore elimination, when a depen\u00addence s w is the exact number of iterations spanned by the dependence. \nNevertheless, even conservative lower bounds on w can lessen scheduling constraints significantly. Although \na graph can contain exponentially many ele\u00admentary recurrence circuits, most loop bodies have very few. \nSo the compiler computes RecMII by simply scan\u00adning each circuit [21]. In any case, RecMII can be computed \nin O (V x E x log V) time by indirectly finding a circuit with the minimum cost-to-time ratio, where \n,a dependence arc is viewed as having a cost of latency, and a time of w [11]. IfR is the minimum cost-to-time \nratio, then RecMII = [ R1. The ResMII and RecMII lower bounds are defined using the ceiling function \nbecause it does not make sense to talk about a non-integral II. However, if a compiler performs loop \nunrolling, then it can take advantage of fractional lower bounds. For instance, if a loop had an exact \nminimum II of 3/2, then the compiler could unroll the loop once and attempt to schedule for an II of \n3. Unfortunately, the current compiler does not perform any such loop transformations. In practice, almost \nall loops can achieve their absolute lower bound of MII = max(ResMII, RecMII). But for some loops, the \nminimum feasible II is more than MII.  3.2 Lower Bounds on Register Pressure First a few miscellaneous \ndetails: Some machines need two registers to hold a 64-bit scalar; other machines need only one. To \nnormalize the results in this paper, all programs were compiled so that a scalar used only one register. \n This paper concentrates on register pressure arising from loop variants. So registers will henceforth \nrefer solely to the RR file.  Operations that execute under mutually exclusive predi\u00adcates may use the \nsame destination register without inter\u00adfering with each other. Unfortunately, the compiler does  3The \nliterature on vectoriziig and psralletiiing compilers would CSUan exact w the dependence s distance. \n 5 f\u00adY(3) Y(3) > Y(3) C(6) x(6) x(6) x(6) 4 cx(1) x(l) ((4) y(4) Y(4> / Z(7) X(7) Lifetimes - Physical \nStorage Cells 3 2 cx(2) X(2) / X(3) %(2) X(3) > Z(2) X(3) X(3) ((5) > X(3) y(5) Y(5) % Y(6) Y(6) Allocation \nz(i 2) I ICP+5 1 0 cy(1) cy(2) y(2) Y(2> C(4) Z(4) Z(4) / X(:5) Z(4) Z(5) X(47 Z(5) X(5) 7 X(5) % l$(i-l~lICP+41 \nIX(2) y(i 2) y(i 1) y(i) ICP + ICP + ICP+ ICP + 1 3 2 1 O Overlapping yl y2 Xoxl x2 x3 x4 Zo21 x2 \n 01234567 Time in Cycles (II= Figure 3: A Naive Allocation Lifetimes y3 yl y2y3 x3 x4 Xoxl x2x3 X4 Time \nModulo II: 01 2 3 ... LiveVector = (4, 4) Figure 4: Computing the Sample LiveVector not perform the requisite \nanalysis. Therefore the compiler allocates registers, and computes lower bounds, as if all predicates \nmay be true. Once a loop has been scheduled, an absolute lower bcnrnd on the schedule s register pressure \ncan be found by computing the maximum number of values that are live at any cyclle of the schedule. Figure \n4 illustrates this computation for the sample loop of Figure 1. (Values for address arithmetic have been \nomitted for clarity.) The lifetimes generated by one iteration are shown in bold face. Since 11 = 2, \nlifetimes from adjacent iterations overlap each other as shown in the diagram. Summing the number of \nlive values in each of the II columns gives a loop s LiveVector. Due to the moclulo constraint, a faster \nalgorithm is possible: simply wrap the lifetimes generated by the first iteration around a vector of \nlength II. In any case, the LiveVector s maximum, MaxLive, is the desired lower bound. Allocating registers \nfor a modulo-scheduled loop is beyond the scope of this paper. For an extensive discussion of the 89 \n 2) for the Sample Loop problem, including heuristic solutions and empirical results, consult [18]. One \nof the most remarkable results reported in that paper is the ability of their allocation strategies to \nalmost always achieve the MaxLive lower bound on a schedule s reg\u00adister pressure4. Due to that result, \nthis paper approximates a schedule s register pressurewith its MaxLive lower bound. Three observations \nlead to a novel schedule-independent lower bound on a loop s final register pressure: 1. MaxLive is usually \nvery close to the LiveVector s av\u00aderage, AvgLive, especially when a long schedule is wrapped around a \nsmall 115. 2, AvgLive can be expressed as the total length of all life\u00adtimes divided by II. 3, Given \na fixed II, a schedule-independent lower bound on the length of a value s lifetime, MinLT, can be cal\u00adculated. \n(Section 5.1 shows how.) Therefore MinAvg = ~~~ MinLT(v)@l is a useful lower bound. In particular, MaxLive \n-MinAvg provides an abso\u00adlute measure of how well the scheduler minimizes register pressure. 41nparticular, \nthe wands-only strategy using end-fit with adjacency order\u00ading never needed more than MaxLive + 1 registers, \nand the blades-allocation strategy using best-fit with adjacency and start-time orderingsneverneeded \nmore than MaxLive + 5 registers. The paper did not explicitly state these facts. Instead, I had the privilege \nof directly ex anrining the paper s raw data. 5ova 97% of me rjm, Mml,ive is no morethan&#38;Wve +s. \n  4 Slack Scheduling Slack scheduling focuses on each operation s scheduling freedom-or skzck, which \nis precisely defined in the next subsection, after a little motivation. To schedule straight-line code, \n(instead of a loop), a list\u00adscheduling compiler can simply consider each cycle in turn, packing it full \nof operations before considering the next cycle. After all, an operation that cannot fit in the current \ncycle can always find room in a later cycle. To software pipeline a loop, a scheduler must handle cyclic \n data dependencies, which arise from the loop s non-trivial recurrence circuits. A trivial recurrence \ncircuit, which is a dependence arc from an operation to itself, imposes no scheduling constraints, as \nthe compiler previously ensured that II a RecMII. Henceforth, recurrence circuit implic\u00aditly signifies \nnon-trivial , unless explicitly stated otherwise. As mentioned in Section 3.1, a scheduler must not stretch \na recurrence circuit s length beyond Q x II cycles. In addition, placing an operation at a cycle t commits \nresources for cycles t+ k x II, for all k. So an operation that cannot fit in one cycle might not fit \nin any later cycles. Therefore a list-scheduling compiler is not likely to find a feasible schedule at \nMII when recurrence circuits are present. Slack scheduling solves this problem by integrating re\u00ad currence \nconstraints and critical-path considerations into an operation-driven tkamework with limited backtracking. \n4.1 Computing Estart and Lstart Bounds When an operation is placed into a partial schedule, it will in \ngeneral have an earliest start time (Estart) and a latest start time (Lstart), due to predecessors and \nsuccessors that have already been placed. For operations on recurrence circuits, these constraints cannot \nbe avoided. The difference between these bounds is the operation s Slack. To ensure that Estart and Lstart \nare well defined for all operations, the compiler adds two pseudo-operations to the loop body: Start \nand Stop. Start is a predecessor of each operation; Stop is a successor of each operation. Start is fixed \nat cycle O; Stop is scheduled just like any other operation. The scheduler maintains Estart and Lstart \nbounds with the aid of a minimum distance relation. For each pair of operations z and y, MinDist(z, \ny) is the minimum number of cycles (possibly negative) by which x must precede y in any feasible schedule, \nor co if there is no path in the dependency graph from z to y. Computing MinDist is an all-pairs longest-paths \nproblem, Simply assign each dependence arc a cost of latency w x IL Since II > RecMH, all cycles have \nnon-positive costs. Hence the problem can be reduced to a fast all-pairs shortest\u00adpaths calculation by \nnegating each arc s weight. Finally, set MinDist(z, z) = O for each operation z. Although MinDist must \nbe recomputed for each attempted II, the overhead is reasonable since most loops achieve MD. GNen the \nMinDist relation, the scheduler initializes Estart(z) = MhDist(Start, z), and Lstart(z) = Lstart(Stop) \n MinDist(x, Stop), where Lstart(Stop) is judiciously set to equal or exceed Estart(Stop). When an operation \ny is placed at a time t, the scheduler updates the bounds to: Estart(x) = max (Estart(z), t + MinDist(y, \nz)) , and Lstart(z) = min (Lstart(z), t-MinDist(z, y)) . 4.2 An Operation-Driven Framework Once a compiler \ncan compute both Estart and Lstart bounds, it can add critical-path considerations by control\u00adling Lstart(Stop) \n. If a loop has no resource contention (ResMII = 1), then it can always be scheduled to meet its critical \npath. Otherwise the scheduler sets Lstart(Stop) = [Estart(StOp)/ III X II. Thk provision of extra slack \nlessens the overall amount of backtracking and improves the final schedule. Once set, Lstart(Stop) is \nreset only when Estmt(Stop) is pushed out beyond either Lstart(Stop) or Stop s current placement in the \nschedule. The scheduler places operations one by one until either a feasible schedule is found or the \nheuristics give up. The central loop comprises the following 6 steps: 1. Choose a good operation to place \ninto the current partial schedule. (Section 4.3) 2. Search for a good issue cycle within the operation \ns Estart and Lstart bounds. (Section 5.2) 3. If no contlict-free issue cycle exists, then create room \nfor the operation by ejecting one or more operations from the schedule. (Section 4.4) 4. Place the operation, \nand update the modulo resource table. 5. Update the Estart and Lstart bounds for all unplaced op\u00aderations \nto reflect the new partial schedule. (Section 4,1 ) 6. If operations are ejected too many times, then \nremove all operations from the schedule, increment II, and start all over again.  In practice, almost \nall loops succeed at MU. Even so, in Step 6 the compiler increments II by max ( 10.04 x II], 1), rather \nthan by 1, in order to avoid spending an excessive amount of time compiling large complex loops6. d~wemntig \nII by 1 lowered the total II by 45 at the eqmse of 29% more time spent in the scheduler.  4.3 Choosing \na Good Operation to Place schedule. Slack scheduling is characterized by its attempt to always choose \nan operation with the minimum number of issue slots available to it. An issue slot for an operation is \na conflict-free potential placement of the operation into the current partial schedule. The number of \nissue slots for an operation can be approximated by its slack, which is an upper bound on the number \nof issue cycles available to it. Each issue cycle may hold multiple issue slots for the operation; for \ninstance, the hypothetical target machine can issue two address-add operations per cycle. Unfortunately, \nthe compiler assigns operations to functional units before scheduling commences, thereby restricting \nan operation to one issue slot per cycle. If a loop has no resource contention (ResMII = 1), then an \noperation has precisely as many issue cycles as its slack predicts. Otherwise the scheduler tries to \nestimate rescmrce contention by dividing a critical operation s slack value in half. An operation is \ncritical if it uses a critical resource. A resource is critical if one iteration uses the resource for \nat least 0.90 x II cycles. Critical operations are marked just before attempting each new value of II. \nFurthermore, divisions and square roots tend to have very few issue slots, due to the complex non-pipelined \nresource patterns they employ. The compiler primitively takes this into account by halving an operation \ns slack value (yet again) if it uses the divider. The final slack value is the operation s dynamic priority. \n At each iteration of its central loop, the scheduler chooses an operation with minimum dynamic priority, \nwhich determ\u00adines a unique operation 48% of the time. Ties are broken by choosing the operation with \nthe smallest Lstart, as this top-down bias interacts well with the scheduler s backtracki\u00adng policy. \nIn practice, this dynamic priority scheme cleanly integrates recurrence constraints and critical-path \nconsidera\u00adtions. Section 8 gives an intuitive explanation for this empir\u00adical result. 4.4 Limited Backtracking \nEjecting operations out of the schedule is a form of back\u00adpacking, which must be controlled. To that \nend, when the scheduler cannot place an operation z due to a lack of conflict-free issue slots, it forces \nthe operation into cycle max (Estart(&#38;), 1 + last placement of z) by ejecting a117op\u00aderations that \nconflict with its resource needs. This heuristic avoids Iivelock by forcing z into successively later \ncycles. If operation z is forced into a cycle beyond Lstart(z), then other operations may conflict with \nz due to dependency con\u00adstraints. These operations need not m immediate successors of x, as MinDist reflects \nthe transitive closure of the success\u00ador relation. Nevertheless, ejecting all of these operatialns rather \nthan just the immediate successors tends to reduce the overall amount of backtracking and improve the \nfinal TWi~ one ~xmption: The loop s brt op conditionalbranclrCmmot~ ejected,asits placementdeterminesthe \nschedule sII. Hencean operation mustsearchsuccessivecyclesto avoidcontlictswith brt op. Ejecting an operation \nmay loosen the Lstart bounds of an\u00adcestors and the Estart bounds of descendants. The scheduler recursively \nmarks these bounds as invalid, pruning its depth\u00adfirst search whenever it encounters a placed operation. \nIf p operations are placed and u operations are unplaced, then the bounds for all unplaced operations \ncan be recomputed in O (p x u) time. In practice, only a couple operations get ejected at a time, hence \nfew of the bounds need to be recom\u00adputed. So the update takes only linear time on average.  5 Lifetime \nSensitivity Prior scheduling algorithms have always placed an operation as early as possible within the \npartial schedule constructed thus far. This unidirectional strategy unnecessarily stretches operand \nlifetimes; for example, by scheduling loads too early. In general, unidirectional approaches are a legacy \nfrom an over-reliance on the methods and intuition underlying list scheduling. In contrast, slack scheduling \ncan accommodate a novel bidirectional approach that attempts to place an operation either as early as \npossible or as late as possible, depending on a sophisticated heuristic. The heuristic s primary goal \nis to minimize each value s lifetime, in the hope that this will minimize the overall peak register pressure. \n5.1 Computing MinLT The compiler eases the scheduler s task by putting the loop body into static single \nassignment (SSA) form [4], thereby giving each value a unique defining operation and a precise set of \nflow dependencies. In that setting, a value s lifetime is merely the length of its longest flow dependence \nin the final schedule. A novel schedule-independent lower bound, MinLT, on the length of a lifetime can \nbe calculated with the aid of the MinDist relation. Suppose a value v has a defining operation d and \na set S of flow dependencies. For each flow dependence f e S, let u denote the corresponding operation \nthat uses v. Then MinLT(v) = maxf~s (W x II+ MinDist(d, u)) . This lower bound plays a key role in the \nfollowing bidirectional heuristic.  5.2 Choosing a Good Issue Cycle To find an issue cycle for an operation, \nthe scheduler linearly scans between the operation s Estart and Lstart bounds; the seaming stops as soon \nas an available issue cycle is found. Due to the modulo constraint, at most II consecutive cycles need \nto be scanned. 46 ZOof the time, the operation has no slack. Otherwise the key decision is whether to \nscan from Estart to Lstart, or from Lstart to Estart. Empirically, the following heuristics tend to favor \nan early placement twice as often as a late placement. When deciding whether to favor placing the operation \nearly or late, the scheduler considers only flow dependencies whose lengths can be stretched. Thus the \nfollowing are ignored: o loop invariants, which are stored in the GPR file. o duplicate inputs, in order \nto not count a lifetime twice.  self-recurrences, as their lengths are fixed. Henceforth, inputs and \noutputa refer to stretchable flow dependencies. If an operation has neither inputa nor outputs, (for \nexample, an accumulator that is not referenced until the loop exits), then it should be placed early \nin the schedule to minimize the overall schedule length. Otherwise, the scheduler tries to estimate-given \nthe current partial schedule how many of the operation s inputs and outputs are stretchable Since the \nloop body is in SSA form, placing the oper\u00adation early will stretch its outputs. But placing the op\u00aderation \nlate might not stretch an input, since some other operation may stretch the input farther than this operation \ncould. In particular, suppose that an operation d defines a value v that is used w iterations later by \nan operation u. If Estart(d) + MinLT(v) ~ w x II+ Lstart(u), then operation u cannot stretch v s lifetime. \nEmpirically, the operation has more stretchable inputs than outputs 30% of the time, and fewer stretchable \ninputs than outputs 470 of the time, with ties occurring the remaining 20% of the time. In the first \ncase, the operation should be placed early in the schedule; in the second case, it should be placed late. \nIn case of a time, the operation s placement cannot affect the final register pressure, but it might \naffect the likelihood of finding a feasible schedule. To minimize backtracking, the scheduler attempts \nto place the operation near whichever group of operations is less likely to be ejected: the operation \ns immediate predecessors or successors. The scheduler predicts that whichever group has a larger fraction \nof operations placed is less likely to be ejected. In case of a tie, the scheduler places an operation \nearly if and only if no predecessor or successor has yet been placed.  6 Compilation Time The bidirectional \nslack-scheduling framework has been inte\u00adgrated into Cydrome s ImRTRAN77 compiler. The compiler is capable \nof modulo scheduling arbitrary DO loops with un\u00adstructured bodies, so long as the loop bodies are acyclic, \nhave no assigned or computed gotos, and make no procedure calls. Even loops with early exits can be modulo \nscheduled [22], al\u00adthough that experimental feature was not employed for these experiments. Nevertheless, \nthe compiler does not attempt to modulo schedule loops with less than 5 iterations, or more than 30 basic \nblocks before if-conversion, or which have ResMII >500, as the benefits would be minimal. The scheduler \nhas been tested on all eligible DO loops in the Lawrence Livermore Loops, the SPEC89 FORTRAN Metric Min \n50% 90% Max # Basic Blocks 1 1 1 15 # Operations 2 11 48 556 # Critic~l Ops at MII o 2 16 323 # Ops on \nRecurrences o 0 8 198 # Div/Mod/Sqrt Ops o 0 1 11 RecMII 1 1 17 206 ResMII 1 3 19 323 MII 1 3 31 323 \nMinAvg at MII 1 13 28 57 # GPRs 1 2 8 65 Table 2: Measurements horn all 1525 Loops benchmarks, and \nthe Perfect Club codes-a total of 1,525 loops. Table 2 characterizes the complexity of these loops. Scheduling \nthe loops consumed 3.96 minutes of the com\u00adpilation time on an HP 9000/730 workstation. For 889 of the \nloops, totaling 7,278 operations, no backtracking was re\u00adquired. For the other 636 loops, the scheduler \nplaced 23,603 operations in 306,860 iterations of its central loop (see Sec\u00adtion 4.2). Step 3 had to \nbe invoked 157,694 times, thereby ejecting 282,130 operations. Step 6 was invoked a mere 139 times. Overall, \nbacktracking consumed 65% of the sched\u00aduler s execution time. In contrast, computing RecMII took only \n670 of the time, and computing MinDist took 10%. Cydrome s scheduler took 6.5x longer to schedule the \nloops, primarily because it backtracked 3.7x as much. 7 Performance The scheduler achieved optimal execution \ntime (II = MI) for 96% of the loops. Overall, the loops would execute in 1.01x their minimum time, which \nrepresents a 1.11x speedup over Cydrome s scheduler. Tables 3 and 4 charac\u00adterize this performances. \nThe final figures compare the register pressure generated by the bidirectional slack scheduler (denoted \nNew Sched\u00aduler ) and Cydrome s scheduler (denoted Old Scheduler ). e Figure 5 graphs the MaxLive MinAvg \nmetric. Notice how close MaxLive can get to MinAvg: - 46% of the loops achieve optimality. - 93% of the \nloops are within 10 RRs of ideal. Figure 6 shows the overall pressure for the RR file. No\u00adtice that modulo \nscheduling does not require excessively many rotating registers: - 92 % of the loops use no more than \n32 RRs. - Only 5 loops use more than 64 RRs. 8Cydrome s scheduler failed to pipeline 14 of the loops. \nEach faiture is represented in Table 4 by the last II that was attempted. Loop Class opt All % Has Conditional \n56 Has Recurrence 305 Has Both 43 Has Neither 1,059 :1,068 ;99 ii m *I All LOOpS 1,463 1,525 96 17:517 \n*] Table 3: Slack Scheduling Performance Loop Class opt All % II ~ For the 132 Loops with Has Conditional \n47 59 80 1,515 1,447 1.05 Metric Min 5070 Has Recurrence 272 344 78 8,896 7,775 1.14 II 3 29 Has Both \n32 54 59 2,403 1,585 1.52 MII 2 20 Has Neither 1,042 1,068 98 6,579 =,6,501 1.01  II MII 1 2 All LOOpS \n1,393 1,525 91 19,393 17,308 I 1.12 11/MII 1.02 1.11 Table 4: Cydrome s Figure 7 displays the number \nof loop invariant kept in the GPR file. It is possible to trade off GPRs for RRs under certain circumstances, \nso their combined pressure is also of interest. -97% of the loops use no more than 16 GPRs. -Only 3 \nloops use more than 32 GPRs. -82% of the loops keep RRs + GPRs <32. -Only 16 loops have RRs + GPRs >64. \n Figure 8 shows why ICR pressure is of no real concern: only one loop uses more than 32 ICR predicates. \n(The  schedulers This performance tion 5.2; without the same register In summary, generate very similar \nICR pressure.) is due to the bidirectional heuristics of Sec\u00ad them, the slack scheduler generates nearly \npressure as Cydrome s scheduler. these measurements show that the absolute lower bounds on II and register \npressure can usually be achieved by the bidirectional slack-scheduling framework. In addition, the scheduler \nappears quite robust, as other ex\u00adperiments with different Iatencies for the functional units give very \nsimilar performance results and compilation times. Related Work By using a dynamic priority scheme, \nslack scheduling provides a novel integration of recurrence constraints and critical-path considerations. \nThe intuition underlying this in\u00adtegration is that the operations on a recurrence circuit can have a \nlot of slack until one of them gets placed, at which point the slack can sharply converge nearly to zero. \nIn some sense, the recurrence gets jixed at this point, as the other operations now have an anchor around \nwhich they must be placed. The dynamic-priority scheme can detect this transit\u00adion because the scheduler \nmaintains precise Estart and Lsmrt Scheduling Performance II >MII 90% Max 104 618 68 323 45 412 3.22 \n4.5  bounds for all operations at all times. Even in the absence of recurrence circuits, the dynamic-priority \nscheme is an im\u00adportant refinement to the critical-path method [10]. Cydrome s scheduler has a similar \nbacktracking operation\u00addriven framework, with very difYerent heuristics [6]. In par\u00adticular, it does \nnot employ a dynamic priority scheme; in\u00adstead, it relies on a static priority that favors those operations \nwhose initial slack is minimal. Thus the scheduler cannot de\u00adtect when a recurrence circuit becomes fixed. \nTo be safe, the scheduler places all operations that are on recurrence circuits, before placing any other \noperations. In order to dispense with backtracking altogether, the Warp compiler special-cases recurrence \ncircuits within a list\u00adscheduling framework [9]. In essence, the compiler fixes the relative timing of \nthe operations on a recurrence circuit before scheduling the overall loop body. By thus reducing each \nrecurrence circuit to a complex pseudo-operation, only acyclic dependencies remain, which are easily \ndealt with. However, neither of the two prior approaches is totally satisfactory because the early placement \nof all operations ftom a recurrence circuit can be an unnecessary constraint on the schedule~ after all, \nthe minimum schedule length of a recurrence circuit need not be anywhere near ita limit of Q x II cycles. \nThe empirical results in [9] and Section 7 support this intuition. The hardware timing constraints that \narise when locally compacting microcode are similar to recurrence constraints. Prior work in this area \nrefers to an operation s Estart and Lstart bounds as ita absolute timing, while the MinDist re\u00adlation \nencodes the operations extended timings [24]. The slack scheduling framework handles these timing constraint \nmore naturally than prior methods. Prior efforts at lifetime-sensitive scheduling have been in the context \nof straight-line code for conventional RISC pro\u00adcessors [8, 3]. This work has advocated Integrated Prepass \nScheduling (IPS) within a list-scheduling framework. IPS Percent of All Loops 0 0 :,, . .. . ,,, :-------.--.-:--: \n,, , , ,, :... :,  ,, ~ . . ... :.. 4 :: r , . >... ,, : ,, .. .. ... .: .; .. ...... .... . -, ,, \n---,----,... .... {,  tILIIIIIIt --(I I I11I II8I , ..,. ,, :, :, , : .----,... --, ... .... ........ \n  w ,, ,.--. ..y.>.... ! {. ;.. ,,, [ : ...... ,------:\u00ad  : ,,: .: . .. .. ...... ... ...... .. ,, \n.... .. . .. ..... .... . . ,. -.- ---\u00ad ., ,-, ,----.,.. .. ,. , ,.. .. .,. . . 1 q :. .. i..: . g \n----- ,, .. E ,-~ g g ~~ .. . . . . . .... ..... ,, I . I ........ I . I I ( . I ._ I I 266 switches \nbetween a heuristic for avoiding pipeline interlock and a heuristic for reducing register pressure, based \non how close the partial schedule is to a register pressure limit. ltet the heuristic for avoiding interlock \ndoes not attempt to take register pressure into account it can squander registers just as freely as previous \nschedulers, In contrast, the bidirec\u00adtional slack-scheduling framework, which can be applied to straight-line \ncode as well as loops, attempts to integrate lifetime sensitivity into the placement of each operation. \nFu\u00adture experimentation may assess how well slack-scheduliiig would work in the context where IPS has \nbeen studied. Acknowledgments My advisor, Keshav Pingali, for his patience. Bob Rau, Mike Schlrmsker, \nand Viiod Ksthail, for giving me an interesting pro\u00adblem,Cydrome s source code, and many discussions \nduring my stay at HP Labs. Mayan Moudgill, an early drdlt for proofreading of this paper. Paul Stodghill, \nWei Li, Mark Chsrney, and anonymous referees, for their comments. References [1] J. R. Allen, K. Kennedy, \nC. Porterfield, and J. Warren. Con\u00adversion of control dependence to data dependence. In Pro\u00adceedings \nof the Tenth Annual ACM Symposium on Principles of Programming Languages, pages 177-189, Jan. 1983. [2] \nG. R. Beck, D. W. L. Yen, and T. L. Anderson. The Cydra-5 mini-supercomputer: kchitecture and implementation. \nJour\u00adnal of Supercomputing, 7( 1/2), Jan. 1993. [3] D. G. Bradlee, S. J. Eggers, and R. R. Henry. Jntegmting \nregister allocation and instruction scheduling for RISCS. In Proceedings of the Fourth International \nConference on Archi\u00adtectural Support for Programming Languages and Operating Systems, pages 122-131, \nApr. 1991. [4] R. Cytron, J. Fwmnte, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. Au efficient method \nof computing static single assignment form. In Proceedings of the Sixteenth AnnualAC&#38;l Symposium \non Principles of Programming Languages, pages 25-35, Jan. 1989. [5] J. C. Dehnert, P. Y.-T. Hsu, and \nJ. P. Bratt. Overlapped loop support in the Cydra 5. Jn Proceedings of the Third Interna\u00adtional Conference \non Architectural Support for Programming Languages and Operating Systems, pages 26-38, Apr. 1989. [6] \nJ. C. Dehnert and R. A. Towle. Compiling for the Cydra 5. Journal of Supercomputing, 7(1/2), Jan. 1993. \n[7] P. B. Gibbons and S. S. Muchnick. Efficient instruction scheduling for a pipeliued architecture. \nIn Proceedings oj?he ACM SIGPLAN 86 Symposium on Compiler Construction, pages 11-16,1986, [8] J. R. Goodman \nand W.-C. Hsu. Code scheduling and register allocation in large basic blocks. In Proceedings of the 1988 \nInternational Conference on Supercomputing, pages442-452, June 1988. [9] M. S. Lam. A Systolic Array \nOptimizing Compiler. Kluwer Academic Publishers, 1989. [10] D. Lsndskov, S. Davidson, B. Shriver, and \nP.W. Mallet. Local microcode compaction techniques. ACM Computing Surveys, pages 261-294, Sept. 1980. \n[11] E, L. Lawler. Combinatorial Optimization: Networks and Matroids. Saunders College Publishing, 1976. \n[12] P.G. Lowney, S. M. Freudenberger, T. J. Karzes, W. D. Liech\u00adtenstein,R. P. Nix, J. S. O Donnell, \nand J. C. Ruttenberg. The Multiflow trace scheduling compiler. Journal of Supercom\u00adputing, 7(1/2), Jan. \n1993. [13] J. C. H. Park and M. S. Schlansker. On predicated execution. Technical Report HPL-91-58, Hewlett-Packard \nLaboratories, May 1991. [14] S. Ramakrishnrm. Software pipelining in PA-RISC compilers. Hewlett-Packard \nJournal, pages 39-45, June 1992. [15] B, R. Rau, Data flow and dependence analysis for instruc\u00adtion level \nparallelism. In Fourth Workshop on Languages and Compilers for Parallel Computing, pages 236-250, Aug. \n1991. [16] B. R, Rau and J. A. Fisher. Instruction-level parallel process\u00ading History, overview and perspective. \nJournal of Supercom\u00adputing, 7(1/2), Jan. 1993. [17] B. R. Rau and C. D. Glseser. Some scheduling techniques \nand an easily schedulable horizontal architecture for high per\u00adformance scientific computing. In Proceedings \nof the 14th Annual Microprogramming Workshop, pages 183-197, Oct. 1981. [18] B. R. Rau, M. Lee, P.Tmmalai, \nsndM. S. Schlsnsker. Register allocation for software pipelined loops. In Proceedings of the ACM SIGPLAN \n 92 Conference on Programming Language Design and Implementation, pages 283-299, June 1992. [19] B. R. \nRau, M. S. Schlansker, sndP. Tnmalai. Code generation schemasfor modulo scheduled loops. Jn Proceedings \nof the 25th Annual International Symposium on Microarchitecture, pages 158-169, Dec. 1992. [20] B. R. \nRau, D. W. L. Yen, W. Yen, and R. A, Towle. The Cydra 5 departmental supercomputec Design philosophies, \ndecisions, and trade-offs. IEEE Computer, pages 12-35, Jau. 1989. [21] J.C.Tleman. Anefficient searchalgorithm \ntofindtheelemen\u00adtary circuits of a graph. Communications of the ACM, pages 722-726, Dec. 1970. [22] P.Tmmalsi, \nM. Lee, and M. S. Schlansker. Parallelization of loops with exits on pipelined architectures. LnIEEE \nProceed\u00adings of Supercomputing 90, pages 200-212, Nov. 1990. [23] N. J. Wsrter, J. W. Bockhaus, G. E. \nHaab, and K. Subrama\u00adnian. Bnhanced modulo scheduling for loops with conditional branches. In Proceedings \nof the 25th Annual International Symposium on Microarchitecture, pages 170-179, Dec. 1992. [24] P.Wijaya \nand V. H. Allsn. Incremental foresighted local com\u00adpaction. In Proceedings of the 22nd Annual International \nSymposium on Microarchitecture, pages 163-171, Aug. 1989. [25] M. E. Wolf and M. S. Lam. A data locality \noptimizing al\u00adgorithm. In Proceedings of the ACM SIGPLAN 91 Confer\u00adence on Programming Language Design \nand Implementation, pages 30-44, June 1991.  \n\t\t\t", "proc_id": "155090", "abstract": "<p>This paper shows how to software pipeline a loop for minimal register pressure without sacrificing the loop's minimum execution time. This novel <italic>bidirectional slack-scheduling</italic> method has been implemented in a FORTRAN compiler and tested on many scientific benchmarks. The empirical results&#8212;when measured against an absolute lower bound on execution time, and against a novel <italic>schedule-independent</italic> absolute lower bound on register pressure&#8212;indicate near-optimal performance.</p>", "authors": [{"name": "Richard A. Huff", "author_profile_id": "81546207656", "affiliation": "Cornell Univ., Ithaca, NY", "person_id": "PP31080447", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/155090.155115", "year": "1993", "article_id": "155115", "conference": "PLDI", "title": "Lifetime-sensitive modulo scheduling", "url": "http://dl.acm.org/citation.cfm?id=155115"}