{"article_publication_date": "10-01-2001", "fulltext": "\n On Regions and Linear Types* (Extended Abstract) David Walker and Kevin Watkins Carnegie Mellon University \nSchool of Computer Science ABSTRACT We explore how two di.erent mechanisms for reasoning about state, \nlinear typing and the type, region and e.ect disci\u00adpline, complement one another in the design of a strongly \ntyped functional programming language. The basis for our language is a simple lambda calculus containing \n.rst-class memory regions, which are explicitly passed as arguments to functions, returned as results \nand stored in user-de.ned data structures. In order to ensure appropriate memory safety properties, we \ndraw upon the literature on linear type systems to help control access to and deallocation of re\u00adgions. \nIn fact, we use two di.erent interpretations of linear types, one in which multiple-use values are freely \ncopied and discarded and one in which multiple-use values are explic\u00aditly reference-counted, and show \nthat both interpretations give rise to interesting invariants for manipulating regions. We also explore \nnew programming paradigms that arise by mixing .rst-class regions and conventional linear data struc\u00adtures. \n1. INTRODUCTION One of the classic challenges in programming languages research is to design mechanisms \nthat help programmers reason about the behavior of their code in the presence of imperative operations \nsuch as update and deallocation of memory. Over the past 15 years, two techniques for solving * This \nresearch was sponsored in part by the Advanced Re\u00adsearch Projects Agency CSTO under the title The Fox \nProject: Advanced Languages for System Software, ARPA Order No. C533, issued by ESC/ENS under Contract \nNo. F19628-95-C-0050 and by ONR grant number 1140015, Ef\u00ad.cient Logics for Reasoning about Network Security. \nThe views and conclusions contained in this document are those of the authors and should not be interpreted \nas representing o.cial policies, either expressed or implied, of the Defense Advanced Research Projects \nAgency, ONR, or the U.S. gov\u00adernment. This material is based upon work supported under a National Science \nFoundation Graduate Research Fellow\u00adship. Permission to make digital or hard copies of all or part of \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. ICFP 01, September 3-5, 2001, Florence, Italy. Copyright 2001 ACM 1-58113-415-0/01/0009 \n...$5.00. this problem have repeatedly found success: Linear type systems, which have been derived from \nGi\u00adrard s linear logic [11] and Reynolds syntactic control of interference [24], and  The type, region \nand e.ect discipline developed by Gif\u00adford and Lucassen [10] and re.ned by Jouvelot, Talpin and Tofte \n[17, 26, 28].  Despite the individual successes of these techniques, there has been little research \nthat attempts to understand the re\u00adlationships between the two or how to unify them in a single language. \nHence, in this paper, we investigate how they may be fruitfully used together in the domain of memory \nman\u00adagement. 1.1 Regions The starting point for our development is a simple func\u00adtional programming language \nthat contains programmer\u00adcontrolled regions. A region is simply an unbounded area of memory or address \nspace where values such as function closures, lists or pairs may be allocated. The sole purpose of these \nregions is to group objects with similar lifetimes. When no object in a region is needed to complete \nthe rest of the computation, the region (and all of the objects con\u00adtained therein) may be deallocated. \nExperimental results indicate that this batch-style deallocation can be very e.\u00adcient in practice, rivaling \nor exceeding memory management via malloc and free or garbage collection in many situations [8, 12]. \nAs an example, consider the function Pair:1 .(x, gen, r). let r = gen () in let y = x \u00d7 x at r in r \u00d7 \ny at r Pair has three arguments: a value x that will be duplicated and returned in a pair (call it y), \na .rst-class function gen that returns the region r used to hold the pair and .nally, aregion r that \nwill hold the ultimate result (the pair y and the region r that it was allocated in). The expression \nx \u00d7 x at r allocates a pair of x s in the region r . The function Pair has many of the features that \nmake our language interesting. Most importantly, regions, like 1Normally, function closures, like other \nstorage objects, are allocated in regions, but we will ignore this detail in our informal introduction. \nother values, are ordinary .rst-class programming objects. They can be passed as arguments to functions, \nreturned as results and stored in data structures. In order to program with regions, we must also be \nable to allocate new ones, and we do this using the alloc primitive. When a region is no longer needed, \nit can be deallocated using the free primitive. Given these two primitives and the expression let x \u00d7 \nx = e in e ', which projects the two components x and x from the pair e for use in the expression e . \n,we can write the following code, which uses the Pair function. let gen = .() . alloc () in let r = alloc \n() in let r \u00d7 y = Pair (17,gen,r) in free(r); let x \u00d7 x = y in free(r ); x + x Of course, programming \nwith regions, like other forms of explicit memory management, is fraught with danger. If a programmer \naccidentally deallocates a region too early, then chaos ensues as his or her program chases dangling \npoint\u00aders. Forgetting to deallocate a region is almost as bad since it causes a memory leak. Tofte and \nTalpin [28] solved this problem by developing a type-and-e.ect system to check the safety of programs \nthat use regions. Unfortunately, their type system is based on the notion that regions must be used in \na .rst-allocated/last-deallocated, stack-like fashion and moreover, that regions are intrinsically second-class \nob\u00adjects. Other proposals for static region-based memory man\u00adagement [31, 14] and optimizations of Tofte \nand Talpin s original model [4, 2] helped to alleviate some of the expres\u00adsiveness problems, but these \nproposals are often very com\u00adplex. Moreover, none of these e.orts consider regions to be .rst-class programming \nobjects. As a result, the simple Pair function will not type check in previous systems. 1.2 Safety through \nLinear Types Linear type systems have been used many times before to guarantee safety in the presence \nof explicit memory manage\u00adment operations for individual objects. These type systems provide information \nabout the last use of a data structure, and clearly, if we are guaranteed that a data structure has been \nused for the last time, we can safely deallocate it. The simplest linear type systems [19, 1] actually \nguarantee that linear data structures are used exactly once. After this one use, the data structure is \na deallocated. More sophisticated type systems [30, 6, 18, 15] make it possible to use linear objects \nseveral times, but still provide support for detect\u00ading the last use of such objects. The main disadvantage \nof memory management through linear type systems is that they restrict the amount of sharing/aliasing \nthat can occur in linear data structures. As a result, programs are often forced to copy entire data \nstructures or to maintain reference counts on every object, both of which can lead to excessive time \nand space overhead. In this work, we take a new approach to the problem of safe, explicit memory management. \nIn order to avoid restric\u00adtions on sharing between individual data structures and to avoid maintaining \nper-object reference counts, we group ob\u00adjects into regions. However, rather than attempting to craft \nour own custom region-based type system from scratch, we will take advantage of a large body of pre-existing \nliterature designed speci.cally for controlling volatile resources the literature on linear type systems. \nThe combination of both regions and linear types has never been studied before and it is highly e.ective, \nyielding much more than the straight\u00adforward sum of the individual systems. 1.3 Contributions The main \ncontribution of this paper is to explore the syn\u00adergy between linear type systems and region-based mem\u00adory \nmanagement. To this end, we have designed a simple lambda calculus of .rst-class regions in which a linear \ntype system controls the use, reuse and deallocation of regions as well as other objects such as pairs \nor closures. Because regions are, for the most part, ordinary .rst-class programming objects, it is relatively \nstraightforward for us to adopt existing ideas from the literature on linear type sys\u00adtems. In this paper, \nwe will actually study two such systems although we believe there are several more related type sys\u00adtems \nthat can be combined e.ectively with regions. The .rst is a purely static system derived from Wadler \ns early work on linear type systems [30]. The derived rules for manipu\u00adlating regions easily capture \nthe e.ect of Tofte and Talpin s letregion construct. The second type system has a very di.erent behavior \nfrom the .rst as it is derived from the reference-counting interpretation of linear types discovered \nby Chirimar, Gunter and Riecke [6]. Reference-counting adds a dynamic component to the language that \nincreases the .exibility of the system but gives fewer static guarantees. Finally, by combining ideas \nfrom Wadler with the reference counting interpretation, we obtain new invariants that make it possible \nto manage deferred reference counts. Another important component of our system is that no\u00adtions of linearity \nare applied uniformly across our language: any storage object can be linear or not. This helps to con\u00adtribute \nto the simplicity of our language. It also implies that programmers can freely mix ordinary linear data \nstructures with regions, which gives rise to additional new memory management invariants. For example, \nprogrammers will be able to de.ne heterogeneous linear lists in which every ele\u00adment of the list inhabits \nits own region and therefore may be deallocated independently of any other elements in the list. In contrast, \nprevious region-based type systems could only represent homogeneous lists, where every element inhabited \nthe same region and therefore no list elements could be deal\u00adlocated until the entire list was dead. \nPrevious region-based type systems have also had di.culty dealing with muta\u00adble data structures. Related \ntechniques make it possible to handle mutable data structures more e.ectively than before. Unfortunately, \ndue to space considerations we are unable to explain them here (See a preliminary version of this work \n[32] for details). One important problem that we make no attempt to solve in this report is the issue \nof type inference. As a result, the current work could be viewed as a speci.cation for an ide\u00adalistic \ncompiler intermediate language, rather than a source programming language. In the remainder of this paper, \nwe present a language of regions and linear types in more detail. Section 2 describes a core calculus \nincluding features for allocating and deallocat\u00ading linear regions, pairs and functions. Section 3 describes \nthe execution model for the language. Sections 4 and 5 ex\u00adtend the language with reference-counted regions \nand lists respectively. The latter demonstrates how to de.ne hetero\u00adgeneous data structures. Finally, \nsection 6 discusses related work.  2. THE CORE LANGUAGE Our core language arises by layering ideas \ndrawn from Wadler s linear type system [30] on top of a call-by-value lambda calculus with .rst-class \nregions. 2.1 The Types We .rst explain our choice of linear type system and then proceed to augment the \nlanguage of types with types for regions. 2.1.1 Linear Types Our linear type system includes two di.erent \nvariants of every storage object: there are two forms of closure, two forms of pairs and later there \nwill be two forms of regions. The linear variant classi.es objects that are referenced by exactly one \npointer and are used exactly once.2 Linear objects are deallocated after they are used. The intuition\u00adistic \nvariant classi.es objects that can be used an unlimited number of times (including not at all). In this \nsystem, by contrast with linear logic, linearity is inherent in the types themselves, rather than in \nthe context in which they appear. f We write t1 .t2 for generic functions where the quali\u00ad.er f is either \n\u00b7, indicating an intuitionistic function that maybe usedmanytimes, or 1, indicating a linear function \nthat must be used exactly once.3 After its single use, the closure containing the function s free variables \nwill be deal\u00ad f located. Likewise, we write t1 \u00d7t2 for generic pair types. A linear pair is deallocated \nafter its components have been projected. Normally, we will suppress the \u00b7 annotation above the intuitionistic \ntypes. Hence, we write t1 \u00d7t2 for an intuitionistic pair. In our formal work, we will use ( ) as a base \ntype and as\u00adsume it may be used many times. We could have introduced two variants of ( ) just as we have \ntwo variants of the other types, but instead we will assume that there is no cost to using ( ) (an actual \nimplementation need not allocate it in the store) and therefore no need to de.ne the linear vari\u00adant. \nIn our examples, we will use other base types, such as integers, assuming they may be freely copied. \nFor simplicity, we did not include multi-argument func\u00adtions in our language. However, we can simulate \nthem easily using single-argument functions that accept linear pairs as arguments. Therefore, in our \nexamples, rather than write 1 int \u00d7int .int we will often write (int, int) .int. In order to preserve \nthe single-use invariant of linear ob\u00adjects, it is necessary to ensure that intuitionistic objects do \nnot contain linear objects. The term formation rules help maintain this invariant by preventing linear \nassump\u00adtions from being captured in intuitionistic closures. These rules are discussed in more detail \nin section 2.2. In addition, we consider intuitionistic pairs with linear component types, 1 such as \n(t1 \u00d7t2) \u00d7t3 to be syntactically ill-formed. 2Beware, we will later introduce an operator that temporar\u00ad \nily converts a single-use object into a multi-use object. 3Notice that the function is used once or many \ntimes. Unlike type systems based directly on linear logic, these function types say nothing about how \noften their arguments are used. The number of uses of an argument is determined exclusively by the argument \ns type. 2.1.2 Regions Regions are unbounded extents of memory that hold groups of objects. Every region \nhas a unique name, denoted using the meta-variable ., that can be used to identify the region and the \nobjects it contains. For most purposes, regions are just like any other storage objects. In particular, \na region with name . has a type that may be quali.ed as either linear f or intuitionistic: rgn(.). When \na region has linear type, it may be deallocated. When a value is allocated in a region with name .,the \ntype of the value is tagged with .. For example, a closure in f . has type t1 .t2 at . and similarly \nwith pairs. For the sake of uniformity in our formal language we will assume that all stored objects \nare allocated in some region and therefore that all function and product types are annotated at ., for \nsome region .. However, in our examples we will assume there is some global top-level region named that \nisal\u00adways accessible and is never deallocated. This convention allows us to simulate an ordinary linear \ntype system simply by allocating all objects in . Whenever we omit a region annotation at . or (see the \nnext section) at r, assume the data structure lives in the region . In order to use functions in many \ncontexts, they must be polymorphic with respect to the names of their region arguments. A polymorphic \nfunction is considered linear (in\u00adtuitionistic), if the underlying monomorphic function is lin\u00adear (intuitionistic). \nFor example, the intuitionistic function TwoInts, which returns a pair of integers in its argument region \n., could be given the type .[.].rgn(.) .(int \u00d7int at .) Sometimes, we will wish to de.ne functions that \nreturn new regions they have allocated. For this purpose, we will use an existential type. The simplest \nsuch function is the gen function de.ned in the introduction. It takes no arguments and returns some \nnew region ., so it is assigned the type 1 () ....rgn(.). Traditional region-based type systems disallow \nobjects of existential type, as existentials allow regions to escape the scope of their de.nition, and, \nnormally, deallocation is linked to the scope of region de.nition. Our system is similar in that if we \nwant to be able to deallocate intuitionistic regions, we must place some constraints on the way they \n.ow through programs. However, we do not have to restrict the .ow of linear regions linear typing will \nensure that deallocation is safe. Therefore, an existential type is permitted to hide the name of a linear \nregion but is not permitted to hide the name of an intuitionistic region. Moreover, existential types \nare themselves linear, meaning that they may be opened exactly once. We will explain the rules for manipulating \nexistentials in more detail in section 2.2. 2.1.3 Summary of Type Syntax Figure 1summarizes the syntax \nof the type language. It also documents a subset of the types, ranged over by the meta-variable I, that \nwe refer to as intuitionistic and a disjoint subset, the linear types, ranged over by the meta\u00advariable \nL. Types (and later terms) are considered equiv\u00adalent up to renaming of bound variables. We implicitly \nassume that type contexts, ., contain no repeated region names. We concatenate two type contexts using \nthe nota\u00adtion ., .'.If.and.. have any region names in common . ::= \u00b7|.,. f ::= \u00b7|1 t ::= L |I 1 1 1 L \n::= rgn(.) |t1 \u00d7t2 at . |.[.].t1 .t2 at . |...t I ::= () |rgn(.) |I1 \u00d7I2 at . |.[.].t1 .t2 at . Figure \n1: Syntax: Types G ::= \u00b7|G,x:t e ::= x |() |e1; e2 f |e1 \u00d7e2 at e3 |let x1 \u00d7x2 = e1 in e2 f |.[.]x:t \n.e1 at e2 |e1[.] e2 |pack[., e] as ...t |unpack ., x = e1 in e2 |alloc e |free e |let x = e1 in e2 |let!(y) \nx = e1 in e2 Figure 2: Syntax: Expressions then the notation is unde.ned. The judgment . ft states that \nthe free variables in t are contained in . and that intuitionistic types do not contain linear component \ntypes.  2.2 Expressions Figure 2 presents the expression syntax. As usual, the syntax includes variables \nas well as introduction and elim\u00adination forms for each type of object. Each of the intro\u00adduction forms \n(aside from alloc, the introduction form for regions, which always introduces linear regions) uses a \nqual\u00adi.er to indicate whether a linear or non-linear value is intro\u00adduced. We also include two forms \nof let-expression. The .rst is standard; it binds the variable x to the value computed by expression \ne1 and then continues to compute the result of e2. The second let-expression has the same e.ect as the \n.rst at run time. However, the static semantics are derived from Wadler s let! construct[30]. At compile \ntime, the input region y, which must initially have linear type, is given intuitionistic type in the \nexpression e1 andthenlinear type again in e2. 4 Through this device, we can use a linear region y multiple \ntimes and later recover its linear type, which allows us to deallocate the region. In the following informal \nexample, we allocate a linear region, use it twice to allocate two pairs and then delete it. let y = \nalloc () in let!(y) x =(3 \u00d75 at y) \u00d77 at y in free(y) In order to use let! safely, it is necessary to \nensure that no references to y escape from e1 and into e2. In the example above, only pairs allocated \nin y escape, not references to y itself, for if a reference did escape, we could not justify y s linear \ntype in e2. The type system will prevent references to y from escaping by performing an analysis of the \ntype of e1. We will explain these operations more fully in conjunction with their typing rules, but before \nwe can proceed with the formal semantics we must present a few auxiliary de.nitions. 4Note that the variable \ny is free, not bound in this expres\u00adsion. 2.2.1 Notation The typing rules for expressions have the form \n.; G fe : t where G is a .nite map from variables to types. The domain of G will include all the free \nvariables in e. We assume bound variables are appropriately alpha-converted before being en\u00adtered into \nthe context. As for type contexts, the notation G, G' is unde.ned unless the domains of G and G' are \ndis\u00adjoint. Our type system relies upon a nondeterministic oper\u00adation G = G1 M G2 that splits the linear \nassumptions in G between the contexts G1 and G2. The intuitionistic assump\u00adtions in G appear in both \nG1 and G2. We will often write G=G1 M G2 M G3 as an abbreviation for G = G1 M G' and G' =G2 M G3. f We \nalso use the notation G. When f is \u00b7,all the types in G must be intuitionistic. When f is 1, G is unrestricted. \nThis notation is used to prevent intuitionistic objects from containing linear objects. Since G is just \na .nite map, we implicitly allow exchange of any two assumptions in the con\u00adtext. Weakening and contraction \nwill be admissible on intu\u00aditionistic components of the context, but not on linear ones. We use the notation \ne[x1/x2]and e[.1/.2]to denote stan\u00addard capture-avoiding substitution of expression variables and regions \ninto expressions.5 The notation e[.1/.2]ex\u00adtends region substitution pointwise to region contexts, and \nis only de.ned if .1 and .2 have the same number of ele\u00adments.  2.2.2 Typing Rules for Expressions The \ntyping rules for expressions are derived from consid\u00aderation of three main invariants: 1. An object of \nlinear type must be used exactly once. 2. Any access to a region (i.e. allocation within a region or \nuse of an object within a region) must be accompa\u00adnied by proof that the region is still live. 3. If \nan object contains a reference to an intuitionistic region, the region must appear in its type.  The \n.rst invariant is enforced mainly through careful ma\u00adnipulation of the type checking context and the \nuse of the nondeterministic splitting operator. The second invariant is enforced by requiring that the \nprogram present a reference to a region every time the region is accessed. We subse\u00adquently ensure that \nthere is a reference to a region if and only if the region is still live. The third invariant is enforced \nby conditions on the formation of closures and existential packages, which otherwise could capture references \nto an in\u00adtuitionistic region without its being mentioned in the type. This .nal invariant ensures it \nis possible to perform a type\u00adbased analysis to prevent stored intuitionistic regions from escaping the \nscope of a let! expression. Figure 3 presents the typing rules for expressions. The .rst three rules \ndo not involve regions so they are the nor\u00admal typing rules for a linear lambda calculus. The rule for \nvariables requires that the context G contain only intuition\u00adistic variables we must not let linear \nvariables go unused. The rule for unit is similar. The last of the three is the rule for sequencing. \nIt uses the context splitting operator 5Because of the way we have de.ned our operational se\u00admantics \n(see section 3), only variables are subsituted into expressions arbitrary expressions are never substituted. \nto divide the linear variables between the .rst and second expressions in the sequence. The rules for \npairs and functions are more complex since we must worry about accessing regions. Pairs are allocated \n.; G f e : t f .. .; G,x:t f x : t .; G f () : () G=G1 M G2 .; G1 f e1 :() .;G2 f e2 : t .; G f e1; e2 \n: t f G=G1 M G2 M G3 . f t1 \u00d7 t2 at . using the expression e1 \u00d7 e2 at e3 where e1 and e2 com\u00adpute values \nthat form the components of the pair. The pair is allocated into the region denoted by expression e3.As \nin the typing rule for sequencing, the splitting operator divides the linear variables between the three \nexpressions. There are two further details to notice in this rule. First, the third expression should \nhave type rgn(.), the type of an intuition\u00adistic region. We do not allow allocation into a linear region \nbecause we do not want an allocation to be the single use of .; G1 f e1 : t1 .; G2 f e2 : t2 .; G3 f \ne3 : rgn(.) a linear region. What would be the point of allocating an f f object in a region that could \nnot be used in the future? It would be impossible to use the object itself.6 In a moment, .; G f e1 \u00d7 \ne2 at e3 : t1 \u00d7 t2 at . we will de.ne an operation that temporarily converts linear f G=G1 M G2 M G3 \n.; G1 f e1 : t1 \u00d7 t2 at . .; G2,x1:t1,x2:t2 f e2 : t3 regions into intuitionistic regions in order to \nallow access to linear regions without having to deallocate them. A second subtle but important aspect \nto this rule is that .; G3 f y : rgn(.) (for some y) .; G f let x1 \u00d7 x2 = e1 in e2 : t2 it explicitly \nmaintains the invariant that intuitionistic ob\u00ad jects (in this case intuitionistic pairs) do not contain \nlinear . G2) M G3 ., . ' f t objects. It does so through the well-formedness judgment f G= ( G1, on \nthe result type of the expression. If the pair s quali.er f f ., . ' ;G1,x:t f e1 : t1 is \u00b7 then this \nconstraint speci.es that the component types .; G3 f e2 : rgn(.) must not be linear. . e1 at . t1 at \nf f (closed(G1)) The elimination form for pairs, let x1 \u00d7 x2 = e1 in .; G f .[. ' ]x:t e2 : .[. ' ].t \ne2,. projects the two components of the pair e1 and binds them to x1 and x2 before continuing with the \nexpression e2.If e1 inhabits region . then we must ensure that this region is still live. Otherwise, \nthis access is a memory error. A reference G=G1 M G2 M G3 .; G1 f e1 : .[.2].t1 . t2 at .; G2 f e2 : \nt1[.1/.2] f . y to the region is extracted from the context to witness that .; G3 f x : rgn(.) (for some \nx) the region is still live. (.1 . .) .; G f e1[.1] e2 : t2[.1/.2] .; G f e : t[.0/.] (closed.(t),.0 \n. .) .; G f pack[.0,e] as ...t : ...t G=G1 M G2 .; G1 f e1 : ...t .,.;G2,x:t f e2 : t2 (. .. FV(t2)) \n.; G f unpack ., x = e1 in e2 : t2 .; G f e :() 1 .; G f alloc e : ...rgn(.) 1 .; G f e : rgn(.) .; \nG f free e :() G=G1 M G2 .; G1 f e1 : t1 .; G2,x:t1 f e2 : t2  2.2.3 Escaping Regions, Function Closures \nand Ex\u00adistential Packages Unless we are careful, function closures will be able to capture references \nto intuitionistic regions without revealing these references in the type of the closure, breaking invariant \n3 listed above. Therefore, we require all functions to be closed with respect to intuitionistic regions. \nIf a function wants to access a value in an intuitionistic region, that region must be explicitly passed \nas an argument to the function. Hence, the latent e.ect of the function, a concept found in standard \ne.ect systems [17, 28], is represented as part of the type of the function argument. The closure requirement \nis enforced by the predicate closed.(t) (pronounced t is region-closed with respect to . ). closed.(rgn(.)) \n= false f . ' )=.; G f let x = e1 in e2 : t2 closed.(t1 \u00d7 t2 at closed.(t1) . closed.(t2) 1 G=G1 M G2 \nM G3 .; G1 f y : rgn(.) .; G2,y:rgn(.) f e1 : t1 1 .; G3,y:rgn(.),x:t1 f e2 : t2 (closed.(t1)) .; G f \nlet!(y) x = e1 in e2 : t2 Figure 3: Well-formed Expressions closed.(.. ' .t)= . closed.(t)(if . ' = .) \nclosed.(t) = true (otherwise) In clause two above, . ' may or may not be equal to . and the pair is still \nclosed if its components are. The predicate is used to rule out references to intuitionistic regions \n(with 6There are other ways we could organize our language so that access to linear regions is allowed \nand yet access does not constitute the single use of a linear region. For example, an allocation operation \ncould return a pair of the allocated object and the reference to the region. This would essen\u00adtially \nrequire that programs be written in A-normal form. type rgn(.)) which carry with them the privilege to \naccess a region, but it does not rule out references to objects (such as pairs or closures) within an \nintuitionistic region. Notice that linear regions are always closed. We use the notation closed(t) (pronounced \nt is region-closed ) when closed.(t) for all regions .. We lift the de.nition of region-closed point\u00adwise \nto contexts G. Given these de.nitions we can now interpret the typing rules for functions (see Figure \n3). As before, the splitting op\u00aderator partitions the linear assumptions between the context used to \ncheck the function body and the computation that generates the region into which the closure is allocated. \nIf the closure is an intuitionistic object then following our rule about no linear objects inside intuitionistic \nobjects, the con\u00adtext used to check the function body can contain no linear variables. Finally, this \ncontext must also be region-closed. Therefore, the function closure cannot contain references to intuitionistic \nregions (although it can contain pairs and other functions that inhabit intuitionistic regions). Section \n2.3 explains how to lift the region-closed restriction. The rule for function application ensures the \nregion name arguments (. ' ) match the expected region name parameters and that the argument has the \nexpected type. As in the elimination form for pairs, the existence of a reference to the region containing \nthe function (x) serves as proof that the region is still live. Existential types pose di.culties similar \nto those already described for function closures, and the solution we have adopted is the same. In fact, \ngiven Minamide, Morrisett and Harper s interpretation of function closures as existen\u00adtial packages [20], \nexistential types may be viewed as the real source of the problem. To ensure that intuitionistic regions \ncan be restricted to a particular program scope, we require the type t to be closed with respect to intuitionistic \nregions named . when we form an existential of type ...t using the pack expression. The elimination form \nfor existentials is the standard unpack expression.  2.2.4 Region Allocation and Deallocation The alloc \nprimitive returns a new, linear region. It natu\u00ad 1 rally has type ( )....rgn(.). The free primitive consumes \n1 a linear region and has the type ...rgn(.).( ). However, we do not treat these primitives as constants \nwith these types because our operational semantics is slightly more elegant if we treat them as expressions \nwith their own typing rules (see Figure 3). For programmer convenience, it is unnec\u00adessary to pack the \nargument to free as an existential (the region name in the premiss of the typing rule for free may be \nviewed as implicitly existentially quanti.ed). Intuitionistic regions are introduced and eliminated using \nlet! as explained earlier. One of the key constraints in the typing rule is that the type of e1 should \nbe region-closed with respect to .. This prevents intuitionistic references to . from escaping from e1 \ninto e2. We have introduced let! as an orthogonal programming construct so that the central concept may \nbe understood in isolation from other expressions in the language. However, it is useful to be able to \nmake a linear region temporarily in\u00adtuitionistic in many di.erent program scopes, not just those connected \nwith a let! expression. A more general treatment would permit expressions of the form let!(y) pattern \n= e1 in e2. We use the following instance of the more general construct in the example we are about to \npresent:7 G=G1 M G2 M G3 M G4 1 .; G1 fy : rgn(.1) f .; G2,y:rgn(.1) fe1 : t1 \u00d7t2 at .2 1 .; G3,y:rgn(.1),x1:t1,x2:t2 \nfe2 : t2 .; G4,y:rgn(.1) fz : rgn(.2)(for some z) (closed.1 (t1,t2)) .; G flet!(y) x1 \u00d7x2 = e1 in e2 \n: t3 Example. Now we can look at how to type the example given in the introduction. The text of the example \nhas only been changed to add typing annotations, pack and unpack instructions, and linearity annotations \n(! and \u00b7). 1 .[.](x:int, gen:( ) ... ' .rgn(. ' ),r:rgn(.)) . unpack . ' ,r ' = gen () in let!(r ' ) \ny = x \u00d7x at r ' in 1 pack[. ' ,r ' \u00d7y at r] as tres The function gen generates fresh linear regions, \nand there\u00ad 1 fore it has type () ... ' .rgn(. ' ). The region argument r is given intuitionistic type \nbecause it is used by Pair, but is not deallocated by it. Therefore, the context calling Pair must retain \nan alias to r in order to deallocate it. The function re\u00ad 1 1 turns a value of type tres = .. ' .rgn(. \n' )\u00d7(int\u00d7intat . ' )at .. The calling context may be typed as follows. let gen =(.() .alloc ()) in unpack \n., r = alloc () in let!(r) xres = Pair[.](17, gen,r) in unpack . ' ,z = xres in let!(r) r ' \u00d7y = z in \nfree(r); let!(r ' ) x \u00d7x ' = y in free(r ' ); x + x ' 2.3 Relation to the Tofte-Talpin Language There \nare close connections between our let!and Tofte and Talpin s letregion. Both constructs use a type-based \nescape analysis to ensure safety. When Wadler .rst intro\u00adduced let! into his linear lambda calculus, \nhe had no notion of a region name, so his analysis was very imprecise. Since a region type contains a \nunique region name, it is a form of singleton type, a very precise classi.er that makes the mod\u00adi.ed \nconstruct much more e.ective. In fact, it is possible to de.ne a letregion construct in our calculus: \ndef letregion ., x in e = unpack ., x = alloc () in let!(x) y = e in free x; y A general translation \nof the Tofte-Talpin language into our calculus is not possible without signi.cant run-time over\u00adhead. \nThe primary barrier is that (simpli.ed) Tofte-Talpin 7This construct can be de.ned within the language \nwithout overhead if the pair that is accessed is allocated in some region other than y. Otherwise, we \nmust incur the cost of an allocation and immediate deallocation of a linear pair: 1 let!(y) z =(let x1 \n\u00d7x2 = e1 in x1 \u00d7x2 at ) in let x1 \u00d7x2 = z in e2. .; G fs : t .; G fS : t1 .t2 .; . G f() : ( ) G= G1 \nM G2 .; G1 fx1 : t1 G= G1 M .; . G f\u00b7: t .t G2 .; G1,x:t1 fE[x]: t2 f .; G2 fx2 : t2 . ft1 \u00d7t2 at . \n.; G2 fS : t2 .t3 .; G fE, S : t1 .t3 f f .; G f(x1 \u00d7x2). : t1 \u00d7t2 at . . G=G1 M (G2, G3).;G1 fy : rgn(.) \nf 1 ., . ' ft ., . ' ;G1,x:t fe : t ' .e) f (. .., .; G2,x:rgn(.) fS : t1 .t2 (closed.(t1), closed(G1)) \n.;G flet! x = y in S : t1 .t2 closed.(G2)) f . ].t .t at . f G2 f(.[. ' ]x:t . : .[. ' ' .; G1, .; G \nfx : t[.0/.](.0 .., closed.(t)) Figure 5: Well-Formed Stacks .; G fpack[.0,x] as ...t : ...t (. ..) . \nf f cated in region ., an existential package, or the data struc\u00ad f .; G fdata(.): rgn(.) Figure 4: Well-Formed \nStored Values . closures have type t1 .t2 at . where . is the set of regions {.1,... ,.n}that the function \naccesses. Equality on these types is modulo equality of sets of regions. One might try to translate Tofte-Talpin \nclosures into closures with the form ture associated with a region ( data(.)).8 The stack contains a \nlist of evaluation contexts E, which are expressions with ahole .. The notation E[e] denotes the expression \nformed by .lling the hole in E with e. A stack can also contain the special instruction let! x = y in \nS, which is used to repre\u00adsent the action of the let! expression in the static language. We will discuss \nthis construct in further detail in the next section. f f|.|[.,x] ..t data(.)packas ff f . |(.[.]x : \nt .e) \u00b7|H, x .s \u00b7|E, S |let! x = y in S () |(x1 \u00d7x2) rgn(.1) \u00d7\u00b7\u00b7\u00b7\u00d7rgn(.n) \u00d7((rgn(.1) \u00d7\u00b7\u00b7\u00b7\u00d7rgn(.n),t1) \n. s ::= t2 at .) at ., but such a translation does not preserve equal\u00ad . ity (pairs are not associative, \ncommutative, etc.). Therefore, H ::=if a translation from Tofte-Talpin is desired one must gen-S ::=eralize \nour function types to include an e.ect on the arrow f and use the following rule where closed(G) requires \nG be E ::= .; e |.\u00d7e1 at . e2 |x \u00d7. at e closed with respect to all regions other than those in .: .|let \nx1 \u00d7x2 = .in e2 .e at |x1 \u00d7x2 at f |.[.]x:t .|.[.] e |x[.] . |pack[., .] as ...t |unpack ., x = .in e \n|alloc .|free .|let x = .in e f . G= ( G1, G2) M G3 ., . ' ft. .. f ., . ' ;G1,x:t fe1 : t1 .; G3 fe2 \n: rgn(.) f,. f,. .; G f.[. ' ]x:t . e1 at e2 : .[. ' ].t . t1 at . (closed.(G1)) S ::= (.; H; S; e) \nIn addition, the de.nition of closed.(t)mustaccountfor the new closure types: f,.. ' closed.(.[. ' ].t \n. t1 at ) = false (if . ..) With these modi.cations we can capture the simple Tofte-Talpin closures. \nHowever, capturing the Tofte-Talpin notion of e.ect polymorphism is not trivial and we di.er it to future \nwork. For the remainder of this paper, we concentrate on the closure types de.ned earlier in the paper, \nas they are all we need to explore the relationship between regions and linear types. 3. THE ABSTRACT \nMACHINE Programs in our language execute on an abstract machine. An abstract machine state (S) includes \nthe list of live regions (.), a description of the store (H), a stack (S)representing the current continuation \nand, .nally, the expression to be evaluated. The store maps variables to stored values (s), which may \nbe unit, a function closure allocated in region ., a pair allo- In order to facilitate the proof that \nour type system is sound, we extend the source language type system to the abstract machine, giving well-formedness \nconditions for ma\u00adchine states, the store, stored values and stacks. These rules is to guarantee the \nfollowing simple facts: There is exactly one region data structure in the store for each live region. \n All stored values are well-formed with appropriate types.  The expression to be executed and the stack \nare well\u00adformed with respect to the current store.  Aside from the typing rule for the special let!, \nwhich is discussed in more detail below, the typing rules for the abstract machine are quite intuitive. \nThe rules are shown in Figures 4 through 6. 8In the ML Kit, the data associated with a region includes \na pointer to the beginning of the region in memory and a pointer to the current allocation point within \nthe region [27]. fS: t program . fH live . ' fH : G store (for some . ' ..) G=G1 M G2 . ' ;G1 fe : t1 \n. ' ;G2 fS : t1 .t f(.; H; S; e): t program . fH live \u00b7f\u00b7live .1, .2 fH live f .1,., .2 fH,x .data(.) \nlive . fH live f (s .data(.)) = . fH,x .s live . fH :G store . f\u00b7: \u00b7store . fH :Gstore G=G1 M G2 .; G1 \nfs : t . f(H, x .s): (G2,x : t)store Figure 6: Well-Formed Machine States 3.1 Operational Semantics \nIn order to de.ne the operational semantics, we will need to de.ne some additional notation. We require \nthat no vari\u00adable appear more than once in the domain of the store. Thus, the notation H, x .s implicitly \nrequires that x not be in the domain of H. Similarly, the notation H1,H2 for the concatenation of two \nstores is unde.ned unless the do\u00admains of H1 and H2 are disjoint. The operation H(x) selects the object \nat address x from store H.If x does not appear in the store then the operation is unde.ned. When an intuitionistic \nobject is used, it remains in the store. However, when a linear object is used, it is deallo\u00ad . cated. \nThe following two operations (- for intuitionistic 1 objects and -for linear objects) implement this \nbehavior. . H -x = H 1 (H, x .s,H ' ) -x = H,H ' The operational semantics for the language is given \nby a mapping from machine states to machine states. This map\u00adping is presented in Figure 7. In general, \nan introduction form is evaluated by choosing a fresh address9 and extending the store with the appropriate \nvalue allocated at that ad\u00address. When allocating in a region, the operational seman\u00adtics veri.es that \nthere exists a live region with that name. An elimination form such as a projection or function call \nis evaluated by looking the pair or function up in the store, ensuring that the region inhabited by the \npair or function is 9By fresh address, we mean an address that does not already appear in the domain \nof the store. The freshness constraint is implicit in the formal rules. still alive and .nally taking \nthe appropriate action. The penultimate rule in Figure 7 explains how to evalu\u00adate a let! expression. \nIt removes the linear copy of the data structure associated with region . from the store and replaces \nit with an intuitionistic copy at a fresh address z. At thesametime, the current stack S is extended \nwith the evaluation context for a let expression, and this new stack is wrapped with the special let! \nstack form. In summary, the .nal stack is: let! y = z in (let x = .in e2,S) The purpose of this construction \nis to preserve the infor\u00admation that intuitionistic references to . do not appear in the stack (let x \n= .in e2,S). The special let!construct does this by preserving the information that the stack is well-formed \nin a context that is region-closed with respect to .. The typing rule for the let!stack form makes this \nidea precise. The closure condition on the stack justi.es the removal of the intuitionistic region data \nstructure from the store once the current expression has been evaluated. The last operational rule eliminates \nthe intuitionistic re\u00adgion . from the store. It replaces the reference to . with a dummy value (we use \nunit) and extends the store with a fresh reference to a linear copy of .: (.; H1,z .data(.),H2; let! \ny = z in S; x) -. 1 (.; H1,z .(),H2,y .data(.); S; x) Ordinarily, if we were to replace an intuitionistic \nvalue with another value of a di.erent type (say, if we replaced a func\u00adtion value with unit), there \nwould be no guarantee that the resulting store would be well-formed. However, due to the closure conditions \non the formation of function values and existential types, we can guarantee that this replacement is \nsound. The resulting store type is related to the original store type through the erasure function: erase.(rgn(.)) \n=() ff erase.(t1 \u00d7t2 at . ' )= erase.(t1) \u00d7erase.(t2) at . ' erase.(.. ' .t)= .. ' .erase.(t)(if . ' \n=..) erase.(t)= t (otherwise) Notice that the structure of erase.(t) follows the struc\u00adture of closed.(t) \nexactly and that neither need recurse into the structure of function types (due to the closure require\u00adments \non function formation). We lift the de.nition of era\u00adsure pointwise to contexts G. Now we can prove that \nthe potentially dangerous replacement of rgn(.)by ( )does lead to a well-formed store, albeit one with \ntype erase.(G): Lemma 1. If . ' f (H, y . data(.),H ' ): G store and . f (H,y . data(.),H ' ) live and \n. ' . . then . ' f (H, y .(),H ' ): erase.(G) store. This lemma allows us to show that the store remains \nwell\u00adformed when the operational rule for let!is executed. How\u00adever, we must also show that the stack \nand variable x remain well-formed. The key to this proof is that when a type t (or context G) is region-closed, \nit is equal to its erasure: Lemma 2. If closed.(t) then erase.(t)= t. Therefore, using the closure conditions \non the stack S and the variable x implied by the typing rule for let!we S -. S ' (.; H; S; E[e]) -. (.; \nH; E, S; e) if e not a variable (.; H; E, S; x) -. (.; H; S; E[x]) (.; H; S;()) -. (.; H,x . (); S; x) \n(.; H; S;(x; e)) -. (.; H; S; e) if H(x)= () areabletoprove that S and x are still well-typed in the \nnew machine state, and equally importantly, have the same type. Thus, the well-formedness of the abstract \nmachine is preserved during this operational step. 3.2 Properties of the Core Language We have proven \na type soundness theorem for our core language. Given the recent research on proving soundness of Tofte \nand Talpin s region calculus [31, 13, 5] it should come as no surprise that we were able to apply syntactic \ntechniques to the problem. To state our Type Soundness theorem, we will de.ne the stuck states.A state \nS is stuck if S is not a terminal state of the form (.; H; \u00b7 ; x) and there is no state S ' such that \nS ' * S -. . We also use the notation -. to denote the f f (.; H; S; x1 \u00d7 x2 at x3) -. (.; H, y .(x1 \n\u00d7 x2).; S; y) if H(x3)= data(.)and . . . re.exive and transitive closure of -.. Theorem 3 (Type Soundness). \nIf f S: t program * and S -. S ' then S ' is not stuck. (.; H; S; let x1 \u00d7 x2 = y in e) -. f '' (.; H \n- y; S; e[x1,x2/x1,x2]) f 4. REFERENCE COUNTING ' ' if H(y)= (x \u00d7 x2). and . . . 1 So far, our implementation \nof the intuitionistic linear type (.; H; S; .[. ' ]x:t (.; H, z .(.[. ' ]x:t . e).; S; z) . ate f f \ny) -. system allows objects of intuitionistic type to be shared (i.e.there may be many pointers to these \nobjects). Objects of linear type, on the other hand, are always unshared and therefore they may be collected \nimmediately after they are used. These decisions lead to a completely static memory if H(y)= data(.)and \n. . . f (.; H; S; x[.a] xa) -. (.; H - x; S; e[.a/.f ][xa/xf ]) f management discipline. Unfortunately, \nthe lack of aliasing if H(x)= (.[.f ]xf :t . e). and . . . (.; H; S; pack[.,x] as ...t) -. (.; H, y . \npack[., x] as ...t; S; y) (.; H; S; unpack ., y = x in e) -. (.; H - 1 x; S; e[. ' /.][y ' /y]) if H(x)= \npack[. ' ,y ' ] as ...t (.; H; S; alloc x) -. 1 1 (.,.; H, y . data(.),z . pack[., y] as ...rgn(.); S; \nz) if H(x)= () and ./. . . FV(H) . FV(S) 1 (.1,., .2; H; S; free x) -. (.1, .2; H - x, y . (); S; y) \n1 if H(x)= data(.) (.; H; S; let x = x ' in e) -. (.; H; S; e[x ' /x]) (.; H; S; let!(y) x = e1 in e2) \n-. 1 (.; H - y, z . data(.); let! y = z in (let x = .in e2,S); e1[z/y]) 1 if H(y)= data(.) (.; H1,z \n. data(.),H2; let! y = z in S; x) -. 1 (.; H1,z . (),H2,y . data(.); S; x) Figure 7: Operational Semantics \nfor reusable (linear) objects has its disadvantages: it is nec\u00ad essary to copy linear objects in some \nsituations to preserve the single pointer invariant and this copying can lead to unnecessary memory use. \nAlternatively, it is necessary to convert linear regions into intuitionistic regions for signi.\u00ad cant \nportions of a program and to delay region deallocation beyond the point at which a region is semantically \ndead. Chirimar, Gunter and Riecke [6] proposed an entirely dif\u00ad ferent model of linear logic. They used \nreference counting to keep track of the number of pointers to an object. The lin\u00ad ear type system ensures \nthat reference counts are maintained accurately. Reference counts add a dynamic component to the memory \nmanagement system that complements a purely static approach. Rather than having to copy objects or con\u00ad \nvert linear regions into intuitionistic regions, it is possible to manipulate reference counts. In general, \none can augment the calculus of previous sec\u00ad tions with a third quali.er (#) and manage regions, pairs, \nclosures or other heap-allocated objects by reference count\u00ad ing.10 Here, for simplicity, we concentrate \nexclusively on # reference-counted regions, which we give type rgn(.). The new type of reference-counted \nregions belongs to the class L of linear objects implicit contraction or weakening of assumptions with \nthis type is not admissible. We extend the language of expressions with operations to allocate reference-counted \nregions, explicitly increment reference counts, and explicitly decrement the count (and 10Onedoeshaveto \nbecareful to ensure that reference\u00adcounted objects contain intuitionistic objects only, not lin\u00adear objects \nor other reference counted objects. This may be accomplished using techniques similar to those of previous \nsections which ensure that only intuitionistic objects appear inside of intuitionistic objects. .; G \nfe : t .; G fe :() # # .; G falloc e : ...rgn(.) G=G1 M G2 # ## .; G1 fe : rgn(.).;G2,x:rgn(.),y:rgn(.) \nf e ' : t ' .; G flet x, y = inc e in e ' : t ' # .; G fe : rgn(.) .; G fdec e :() G=G1 M G2 M G3 # .; \nG1 fy : rgn(.) .; G2,y:rgn(.) fe1 : t1 # .; G3,y:rgn(.),x:t1 fe2 : t2 (closed.(t1)) .; G flet!(y) x \n= e1 in e2 : t2 Figure 8: Reference Counting Constructs deallocate the region when the count reaches \nzero): # e ::= \u00b7\u00b7\u00b7|alloc e |let x, y = inc e in e ' | dec e Figure 8 de.nes additional rules for type \nchecking expres\u00adsions. In the previous sections, the let! operator made it possi\u00adble to temporarily treat \nlinear regions as intuitionistic ones to avoid costly copying. Here, we can use the same con\u00adstruct to \ntemporarily increase reference counts without the runtime cost of having to do the actual increment opera\u00adtion. \nThis trick also conveniently allows us to reuse all the allocation and access rules for pairs and closures \nfor both reference-counted regions and other sorts of regions. Example. To demonstrate our new reference \ncounting op\u00aderations, we will reuse our previous Pair example, but this time rather than allocating two \nlinear regions, we will only allocate a single reference-counted region. The Pair func\u00adtion itself is \nunchanged, except for its type, which speci.es that it expects the gen function to be linear and to return \na reference-counted region. The code for the function follows. # We use the abbreviation t# for the type \n.. ' .rgn(. ' )and tres 1# for .. ' .rgn(. ' ) \u00d7(int \u00d7int at . ' ) at .. 1 .[.](x:int, gen:( ) .t#,r:rgn(.)) \n. unpack . ' ,r ' = gen () in let!(r ' ) y = x \u00d7x at r ' in 1 pack[. ' ,r ' \u00d7y at r] as tres Thecodethat \ncalls the Pair function allocates a reference\u00adcounted region r and then increments the reference count, \ncreating a second reference r ' . This second reference is stored in gen s closure. When the Pair function \nis called, we use the let! operator to temporarily allow more refer\u00adences to r then there are reference \ncounts. At this point, there is a reference count of two (due to the single inc in\u00adstruction), but three \nreferences to r: one reference to r is in gen s closure, a second reference is an argument to Pair and \na third reference is retained by the calling context. When Pair returns, the reference count is decremented \nto 0 and the region is deallocated. # unpack ., r = alloc () in let r, r ' = inc (r) in 1 let gen =(.() \n.pack[., r ' ] as t#) in let!(r) xres = Pair[.](17, gen,r) in unpack . ' ,z = xres in 1 let!(r) r ' \u00d7y \n= z in let!(r ' ) x \u00d7x ' = y in dec (r ' ); dec (r); x + x ' 5. CONTAINER DATA STRUCTURES One of the \nprimary weaknesses of region based memory management on its own is that all container data structures \nare homogeneous with respect to the regions that their ele\u00adments inhabit. In other words, all elements \nof a list, tree, or other recursive datatype are required to inhabit the same region. Consequently, all \nelements of any given list or tree must have the same lifetime. For long-lived containers for which both \ninsertions and deletions are common, this strat\u00adegy can incur quite a cost as none of the objects that \nare removed from the collection can be deallocated until the en\u00adtire collection is deallocated. Tofte \nand others [27] have developed clever programming techniques to avoid this problem in many cases. In \nessence, they manually mimic the action of the copying garbage col\u00adlector. More speci.cally, they periodically \ncopy the con\u00adtainer data structure from one region to another. After the copy, they cease to use the \ndata in the old region so it may safely be deallocated. Dan Wang and Andrew Appel [33] have exploited \nsimilar ideas to write a complete copy\u00ading garbage collector in a type safe language that uses the regions. \nAlthough copying is highly e.ective solution in many sit\u00aduations, it is not without its own overhead. \nIf the container data structure is large, the extra space and time required to copy the live data from \none region to another may not be acceptable. In our language, programmers have many more choices. On \nthe one hand, they may employ the copying solution that we have just discussed. On the other hand, programmers \ncan mix linear types with regions to solve this problem in new ways. In particular, programmers can de.ne \nheterogeneous data structures. In other words, containers may hold elements stored in di.erent regions \nand therefore individual objects may be deallocated independently of the other objects in the container. \nTo demonstrate these ideas, we introduce a type for lists: f t list at .. Like other data structures \nsuch as pairs and closures, intuitionistic lists are constrained so that they do not contain linear objects. \nf There are three lists expressions. The expression []t at e introduces an empty list with type t in \nthe region designated f by e. The expression cons(e1,e2) at e3 prepends e1 to the list e2, in the region \ndesignated by e3. The case construct case e1 of [] .e2 | (x, y) .e3 follows the .rst branch if e1 .; \nG f e : t f .; G f e : rgn(.). f t list at . ff .; G f []at e : t list at . t G= G1 M G2 M G3 .; G1 f \ne1 : t f .; G2 f e2 : t list at . .; G3 f e3 : rgn(.) ff .; G f cons(e1,e2) at e3 : t list at . G=G1 \nM G2 M G3 f f .; G1 f e1 : t ' list at . .; G2 f z : rgn(.) f .; G3 f e2 : t .; G3,x:t ' ,y:t ' list \nf e3 : t .; G f case e1 of [] . e2 | (x, y) . e3 : t Figure 9: Well-Formed List Constructs is the empty \nlist and the second branch otherwise. Figure 9 presents the well-formedness rules for list expressions. \nThese typing rules (in particular, the rule for cons) require that the spine of the list inhabits a single \nregion.However, the elements of the list may inhabit di.erent regions. For example, a linear list of \nlists might be given the following type: There are close connections between this work and Walker, Crary \nand Morrisett s capability calculus [31]. The capa\u00adbility calculus used a notion of linearity to control \nregion aliasing. Our current work has the advantage of being more expressive in a number of ways (it \naccommodates .rst-class regions, heterogeneous data structures and reference count\u00ading). However, the \nbounded quanti.ers of the capability calculus make it possible to write continuation-passing pro\u00adgrams \nthat we cannot write with the lexically-scoped let! operator (see [31] for a detailed explanation). It \nseems likely that there is a way to combine the two approaches. Makholm, Niss and Henglein [14] have \nhad similar in\u00adsights with respect to reference-counted regions as we have and are developing successful \ntype inference techniques for a language with (second-class) reference-counted regions. Gay and Aiken \n[8, 9] have developed run-time libraries and language support for reference-counted regions in C. Their \nreference-counting scheme is somewhat di.erent than the one we have introduced here as they count the \nnumber of pointers that cross region boundaries rather than the num\u00adber of pointers to the region data \nstructure itself. Dealloca\u00adtion is allowed when there are no more pointers to values in a particular \nregion and safety is checked mainly at run time. DeLine and F\u00a8ahndrich [7] are developing a new type-safe \nvariant of C called Vault. They use a form of the capabilities mentioned above to control access to all \nsorts of program re\u00adsources including memory regions. They have also developed e.ective local type inference \ntechniques and have experience using their type system to enforce safety properties in device drivers. \nCurrently, Vault tracks linear resources only and it might bene.t from our let! operation to temporarily \nmake 1 1 . ...rgn(.) \u00d7 (( ) list at .) 1 list linear resources intuitionistic. In this case, each element \nof the list is an existential pack\u00ad age containing a pair of a reference to a region and a list inhabiting \nthat region. Each of these inner lists may be processed and deallocated independently of any of the other \ninner lists. However, since the regions are linear they can not alias one other. If a programmer requires \na data struc\u00adture that involves aliasing between the lists then a reference counting solution could be \nused: Dan Grossman, Trevor Jim and Greg Morrisett are cur\u00adrently developing a second type-safe variant \nof C, called Cy\u00adclone. Currently, Cyclone relies upon a conservative garbage collector. However, together \nwith Grossman et al.,we are exploring ways to incorporate some of the ideas described here into Cyclone. \nAcknowledgments Many of the ideas in this paper arose from discussions with 1 # . 1 ...rgn(.) \u00d7 (( ) \nlist at .) list Greg Morrisett. We would like to thank Manuel F\u00a8ahndrich, 6. RELATED AND FUTURE WORK \nThis paper draws together two di.erent branches of type theory designed for managing computer resources. \nResearch on linear types originated with Girard s linear logic [11] and Reynolds syntactic control of \ninterference [24]. Linear type systems were later studied by many researchers [19, 30, 1, 3, 6, 29, 34, \n15]. Type and e.ect systems were introduced by Gi.ord and Lucassen [10] and they too have been explored \nby many others [17, 26, 28, 21]. More recently, a number of new linear type systems, or more generally, \nsubstructural type theories, have been developed such as Kobayashi s quasi-linear types [18], Po\u00adlakow \nand Pfenning s ordered type theory [22, 23]. There is also renewed interest in developing new logics \nthat facilitate Hoare-style reasoning about heap-allocated data structures. Reynolds [25] and Ishtiaq \nand O Hearn [16] have developed substructural logics for just this purpose. An interesting line of research \nis to investigate how these other systems for alias control interact with region-based memory management. \nDan Grossman and the anonymous reviewers for their com\u00adments on earlier versions of this work. 7. REFERENCES \n[1] Samson Abramsky. Computational interpretations of linear logic. Theoretical Computer Science, 111:3 \n57, 1993. [2] Alexander Aiken, Manuel F\u00a8ahndrich, and Raph Levien. Better static memory management: Improving \nregion-based analysis of higher-order languages. In ACM Conference on Programming Language Design and \nImplementation, pages 174 185, La Jolla, California, 1995. [3] Erik Barendsen and Sjaak Smetsers. Conventional \nand uniqueness typing in graph rewrite systems (extended abstract). In Shyamasundar, editor, Thirteenth \nConference on the Foundations of Software Technology and Theoretical Computer Science, volume 761of Lecture \nNotes in Computer Science, pages 41 51, Bombay, 1993. Springer-Verlag. [4] Lars Birkedal, Mads Tofte, \nand Magnus Vejlstrup. From region inference to von Neumann machines via region representation inference. \nIn Twenty-Third ACM Symposium on Principles of Programming Languages, pages 171 183, St. Petersburg, \nJanuary 1996. [5] Cristiano Calcagno. Strati.ed operational semantics for safety and correctness of region \ncalculus. In Twenty-Eighth ACM Symposium on Principles of Programming Languages, pages 155 165, London, \nUK, January 2001. [6] Jawahar Chirimar, Carl A. Gunter, and Jon G. Riecke. Reference counting as a computational \ninterpretation of linear logic. Journal of Functional Programming, 6(2):195 244, March 1996. [7] Rob \nDeLine and Manuel F\u00a8ahndrich. Enforcing high-level protocols in low-level software. In ACM Conference \non Programming Language Design and Implementation, 2001. To appear. [8] David Gay and Alex Aiken. Memory \nmanagement with explicit regions. In ACM Conference on Programming Language Design and Implementation, \npages 313 323, Montreal, June 1998. [9] David Gay and Alex Aiken. Language support for regions. In Workshop \non semantics, program analysis and computing environments for memory management (SPACE 2001), London, \nUK, January 2001. [10] D. K. Gi.ord and J. M. Lucassen. Integrating functional and imperative programming. \nIn ACM Conference on Lisp and Functional Programming, Cambridge, Massachusetts, August 1986. [11] Jean-Yves \nGirard. Linear logic. Theoretical Computer Science, 50:1 102, 1987. [12] Niels Hallenberg. Combining \ngarbage collection and region inference in the ML Kit. Master s thesis, Department of Computer Science, \nUniversity of Copenhagen, 1999. [13] Simon Helsen and Peter Thiemann. Syntactic type soundness for the \nregion calculus. In workshop on higher order operational techniques in semantics, pages 1 19, September \n2000. [14] Fritz Henglein, Henning Makholm, and Henning Niss. A direct approach to control-.ow sensitive \nregion-based memory management. In ACM Conference on Principles and Practice of Declarative Programming, \nFirenze, Italy, September 2001. [15] Martin Hofmann. A type system for bounded space and functional in-place \nupdate extended abstract. In Gert Smolka, editor, European Symposium on Programming, volume 1782 of Lecture \nNotes in Computer Science, pages 165 179, Berlin, March 2000. [16] Samin Ishtiaq and Peter O Hearn. BI \nas an assertion language for mutable data structures. In Twenty-Eighth ACM Symposium on Principles of \nProgramming Languages, pages 14 26, London, UK, January 2001. [17] Pierre Jouvelot and D. K. Gi.ord. \nAlgebraic reconstruction of types and e.ects. In Eighteenth ACM Symposium on Principles of Programming \nLanguages, pages 303 310, January 1991. [18] Naoki Kobayashi. Quasi-linear types. In Twenty-Sixth ACM \nSymposium on Principles of Programming Languages, pages 29 42, San Antonio, January 1999. [19] Yves Lafont. \nThe linear abstract machine. Theoretical Computer Science, 59:157 180, 1988. [20] Y. Minamide, G. Morrisett, \nand R. Harper. Typed closure conversion. In Twenty-Third ACM Symposium on Principles of Programming Languages, \npages 271 283, St. Petersburg, January 1996. [21] Hanne Riis Nielson and Flemming Nielson. Higher-order \nconcurrent programs with .nite communication topology. In Twenty-First ACM Symposium on Principles of \nProgramming Languages, pages 84 97, January 1994. [22] Je. Polakow. Logic programming with an ordered \ncontext. In Conference on Principles and Practice of Declarative Programming, Montreal, September 2000. \n[23] Je. Polakow and Frank Pfenning. Properties of terms in continuation-passing style in an ordered \nlogical framework. In Workshop on Logical Frameworks and Meta-Languages, Santa Barbara, June 2000. [24] \nJohn C. Reynolds. Syntactic control of interference. In Fifth ACM Symposium on Principles of Programming \nLanguages, pages 39 46, Tucson, 1978. [25] John C. Reynolds. Intuitionistic reasoning about shared mutable \ndata structure. In Millennial perspectives in computer science, Palgrove, 2000. [26] J.-P. Talpin and \nP. Jouvelot. Polymorphic type, region, and e.ect inference. Journal of Functional Programming, 2(3):245 \n271, July 1992. [27] Mads Tofte, Lars Birkedal, Martin Elsman, Niels Hallenberg, Tommy H\u00f8jfeld Olesen, \nPeter Sestoft, and Peter Bertelsen. Programming with regions in the ML Kit (for version 3). Technical \nReport 98/25, Computer Science Department, University of Copenhagen, 1998. [28] Mads Tofte and Jean-Pierre \nTalpin. Region-based memory management. Information and Computation, 132(2):109 176, 1997. [29] David \nN. Turner, Philip Wadler, and Christian Mossin. Once upon a type. In ACM International Conference on \nFunctional Programming and Computer Architecture, San Diego, CA, June 1995. [30] Philip Wadler. Linear \ntypes can change the world! In M. Broy and C. Jones, editors, Progarmming Concepts and Methods, Sea of \nGalilee, Israel, April 1990. North Holland. IFIP TC 2 Working Conference. [31] David Walker, Karl Crary, \nand Greg Morrisett. Typed memory management via static capabilities. ACM Transactions on Programming \nLanguages and Systems, 22(4):701 771, July 2000. [32] David Walker and Kevin Watkins. On linear types \nand regions. In Workshop on Semantics, Program Analysis and Computing Environments For Memory Management \n(SPACE 2001), London, UK, January 2001. Available at http://www.cs.cmu.edu/-dpw/papers/. [33] Daniel \nC. Wang and Andrew Appel. Type-preserving garbage collectors. In Twenty-Eighth ACM Symposium on Principles \nof Programming Languages, pages 166 178, London, UK, January 2001. [34] Keith Wansbrough and Simon Peyton \nJones. Once upon a polymorphic type. In Twenty-Sixth ACM Symposium on Principles of Programming Languages, \npages 15 28, San Antonio, January 1999.   \n\t\t\t", "proc_id": "507635", "abstract": "We explore how two different mechanisms for reasoning about state,linear typing and the type, region and effect discipline,complement one another in the design of a strongly typed functionalprogramming language. The basis for our language is a simple lambdacalculus containing first-class memory regions, which areexplicitly passed as arguments to functions, returned as resultsand stored in user-defined data structures. In order to ensureappropriate memory safety properties, we draw upon the literatureon linear type systems to help control access to and deallocationof regions. In fact, we use two different interpretations of lineartypes, one in which multiple-use values are freely copied anddiscarded and one in which multiple-use values are explicitlyreference-counted, and show that both interpretations give rise tointeresting invariants for manipulating regions. We also explorenew programming paradigms that arise by mixing first-class regionsand conventional linear data structures.", "authors": [{"name": "David Walker", "author_profile_id": "81100426485", "affiliation": "Carnegie Mellon Univ.", "person_id": "PP18001632", "email_address": "", "orcid_id": ""}, {"name": "Kevin Watkins", "author_profile_id": "81100079094", "affiliation": "Carnegie Mellon Univ.", "person_id": "PP14038202", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/507635.507658", "year": "2001", "article_id": "507658", "conference": "ICFP", "title": "On regions and linear types (extended abstract)", "url": "http://dl.acm.org/citation.cfm?id=507658"}