{"article_publication_date": "10-01-2001", "fulltext": "\n Compositional Explanation of Types and Algorithmic Debugging of Type Errors Olaf Chitil University \nof York, UK olaf@cs.york.ac.uk ABSTRACT The type systems of most typed functional programming languages \nare based on the Hindley-Milner type system. A practical problem with these type systems is that it is \nof\u00adten hard to understand why a program is not type correct or a function does not have the intended \ntype. We suggest that at the core of this problem is the di.culty of explain\u00ading why a given expression \nhas a certain type. The type system is not de.ned compositionally. We propose to ex\u00adplain types using \na variant of the Hindley-Milner type sys\u00adtem that de.nes a compositional type explanation graph of principal \ntypings. We describe how the programmer un\u00adderstands types by interactive navigation through the ex\u00adplanation \ngraph. Furthermore, the explanation graph can be the foundation for algorithmic debugging of type errors, \nthat is, semi-automatic localisation of the source of a type error without even having to understand \nthe type inference steps. We implemented a prototype of a tool to explore the usefulness of the proposed \nmethods. 1. INTRODUCTION The type systems of most typed functional programming languages are based on \nthe Hindley-Milner type system [11]. It combines the unobtrusiveness of not requiring any type annotations \nin the program with the .exibility of polymor\u00adphism. The basic ideas of the type system are intuitive: \nA function can have many types. The type of a polymorphic function represents all types that can be gained \nby instan\u00adtiation of its type variables. Every function has a principal, that is, most general, type \nwhich represents all of its types. Practical experience shows that the type checker catches many errors, \nfrom trivial oversights to sometimes even deep logical errors. But experience also shows that from a \ntype error message it is often hard to deduce the actual cause of the error and understand it [1, 2, \n3, 4, 9, 10, 17, 19, 20, 21, 22, 23, 24, 25, 26]. Consider the following tiny Haskell program [16]: f \nxs ys = ((map toUpper) . (++)) xs ys Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro\u00a3t or commercial advantage and that copies bear this notice and the full citation on the \u00a3rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci\u00a3c permission and/or a fee. ICFP 01, September 3-5, 2001, Florence, Italy. Copyright 2001 ACM 1-58113-415-0/01/0009 \n...$5.00. The function map toUpper mapsalistofcharacterstoa list of (uppercase) characters, (++) concatenates \ntwo lists, and the in.x operator . composes the two functions. The programmer thinks that the composition \nis a function map\u00adping two lists of characters to a list of characters. However, the Haskell system Hugs1 \ngives the following error message: ERROR (line 1): Type error in application *** Expression : (map toUpper \n. (++)) xs ys *** Term : map toUpper *** Type : [Char]-> [Char] *** Does not match : ([a]-> [a]) -> b \n-> c So the program is not typable and hence the program\u00admer s reasoning must be faulty. But what is \nwrong with the subexpression map toUpper? Why should its type match the type ([a]-> [a]) -> b -> c? The \nGlasgow Haskell compiler2 generally gives more detailed type error messages than Hugs, but here it is \nnot better: Couldn t match [Char] against [a] -> [a] Expected type: [a]-> [Char] Inferred type: [a]-> \n[a]-> [a] In the second argument of . , namely ++ In the right-hand side of an equation for f : ((map \ntoUpper) . ++) xs ys This message reports a type con.ict for a di.erent subex\u00adpression. The function \n(++) certainly has type [a]-> [a] -> [a], but why should it also have type [a]-> [Char]? We analyse why \ntype error messages of current interpreters and compilers are unsatisfactory. The meaning of current \ntype error messages, the meaning of the reported types and their relation to the program, is not well-de.ned. \nFurther\u00admore, the program position given in an error message is often far from the source of the error. \nWe argue that this lack of precise error location is unavoidable for a Hindley-Milner based type system. \nBecause of this lack of precision, theprogrammermustbeabletoexplore howanunexpected type was inferred \nto locate the source of the error. So the main component of a type error explanation system has to be \nan explanation system for types. We argue that neither a Hindley-Milner type inference tree nor Milner \ns type check\u00ading algorithm W [11] are suitable for explaining types. We claim that a type explanation \nmust be compositional to be comprehensible. That is, the whole explanation must have a tree structure \nwhere the types at each node are deter\u00admined uniquely by the types of the node s children. A tree of \nprincipal types is not compositional, but a tree of principal 1http://haskell.org/hugs 2http://haskell.org/ghc \ntypings is. Unfortunately the Hindley-Milner type system only has principal types, but not principal \ntypings. How\u00adever, in [12] John Mitchell de.nes a type checking algorithm that implicitly de.nes a type \nsystem which is closely related to the Hindley-Milner type system and which has what we call a principal \nmonomorphic typing property. The type system of principal monomorphic typings is our basis. The type \nchecking algorithm can produce a compositional type explanation tree. In fact, to avoid duplication of \nsubtrees, we actually construct an acyclic type explanation graph. We show how the programmer can understand \ntypes by in\u00adteractive navigation through the type explanation tree. Nav\u00adigation at di.erent levels enables \nthe programmer to avoid useless information without losing important details. Just as type inconsistencies \nare reported far from the actual error, run-time errors are usually observed far from their source. For \ndeclarative languages algorithmic debugging has been used successfully to locate run-time errors. The \ntype ex\u00adplanation graph is a good basis for algorithmic debugging of type errors. To algorithmically \nlocate type errors, the programmer does not even have to follow type explanations but only needs to know \nwhich types he/she intends variables and expressions to have. We implemented a prototype type explanation \nand debugging tool to explore our ideas. The prototype produced the examples shown in this paper. Although \nwe use Haskell in examples, our analysis is valid and the proposed method is applicable to all Hindley-Milner \nbased programming languages such as ML and Clean. In Section 2 we analyse the problems with the type \ner\u00adror messages of current systems and argue that neither a Hindley-Milner type derivation tree nor Milner \ns type check\u00ading algorithm W are a suitable basis for explaining types and type errors. In Section 3 \nwe informally describe our idea of compositional type explanations. In Section 4 we formalise the type \nsystem of principal monomorphic typings and in Section 5 we de.ne the construction of the type explana\u00adtion \ngraph. In Section 6 we discuss navigation through the explanation graph and in Section 7 we demonstrate \nhow al\u00adgorithmic debugging of type errors works. In Section 8 we brie.y discuss the implementation of \nan explanation and debugging tool. In Section 9 we discuss related work. We conclude in Section 10. \n 2. THE PROBLEMS To provide better support for a programmer with an un\u00adtypable program, we .rst have \nto analyse why current type error messages are unsatisfactory and what makes giving more helpful information \nso hard. The Meaning of Type Error Messages. The type check\u00aders of most systems for Hindley-Milner based \nprogramming languages report a type error in the form of an expression and two contradictory types for \nit. Hugs reports a type and another type which does not match the .rst. GHC reports an expected type \nand an inferred type. It is unclear what these descriptions mean and how the types relate to the ex\u00adpression \nand each other. The types in the error messages contain type variables. They do not mean that the given \nexpressions are or should be polymorphic but that their types are or should be in\u00adstances of the given \ntypes. The occurrence of the same type variable in several types means that this type variable has to \nbe replaced by the same type in all these types. These type variables introduced by the type checker \nare so called non\u00adgeneric type variables that scope over the whole program in contrast to the generic \ntype variables occurring in type annotations in a program. These two sorts of type variables are rather \nconfusing. The Error Location. The following program highlights part of the problem: reverse []= [] \nreverse (x:xs) = reverse xs ++ x last xs = head (reverse xs) init = reverse . tail . reverse rotateR \nxs = last xs : init xs Hugs gives the following error message: ERROR (line 7): Type error in application \n*** Expression : last xs : init xs *** Term : last xs *** Type : [a] *** Does not match : a *** Because \n: unification would give infinite type The Glasgow Haskell compiler says: Occurs check: cannot construct \nthe infinite type: a = [a] Expected type: [[[a]]] Inferred type: [[a]] In the first argument of init \n, namely xs In the second argument of : , namely init xs The two Haskell systems give di.erent expressions \nat which type checking fails. Unfortunately both expressions are far away from the source of the error: \nThe right hand side of the second equation of reverse must be reverse xs ++ [x] to de.ne the desired \nfunction that reverses the order of the el\u00adements of a list. The example highlights a problem of poly\u00admorphism: \nBecause of the .exibility of polymorphism an erroneous expression is often still well-typed. Fortunately, \nthe type of the erroneous expression is usually di.erent from the type intended for this part by the \nprogrammer. Thus the usage of the expression usually leads to a type error in its context.3 The reverse \nexample is contrived. If we had written the intended type of reverse in the program, then we would have \nobtained a more precise error message. However, too many type annotations are practically undesirable \nand the Hindley-Milner type system was designed to make them un\u00adnecessary. The right-hand side of a function \nde.nition usu\u00adally does not contain type annotations and is often large enough to su.er from the polymorphism \nproblem. So, be\u00adcause of the sparseness of type annotations, the type checker seldom knows the intended \ntype for an expression which it could compare with the inferred type. We conclude that in general a type \nchecker cannot pin\u00adpoint exactly the source of a type error but only report an inconsistency of types \nat some program location. 3The two occurrences of the word usually in the two last sentences indicate \nthat an erroneous program may be well\u00adtyped. This limitation of type systems is not the subject of this \npaper. Explanation of Types. Of the types reported in an error message at least one does not agree with \nthe type intended by the programmer. Hugs reports that in the de.nition of rotateR the expression last \nxs has type [a] which does not match the type a. The programmer intends xs to be a list, so the reported \ntype [a] seems reasonable. But why should its type also be an instance of the type a? Similarly, the \nGlasgow Haskell compiler reports for the last occurrence of xs in the de.nition of rotateR the types \n[[[a]]] and [[a]]. The programmer actually intends xs to be a list of arbitrary elements. So how did \nthe type checker obtain the types [[[a]]] and [[a]]? At the heart of a tool for explaining type errors \nmust be a tool for explaining the types of program fragments. However, already for a well-typed expression \nit is rather di.cult to explain its type. The Type Inference Tree. A type system is formally de\u00ad.ned \nthrough type rules. These de.ne the valid type judge\u00adments. A type judgement . fM :: t consists of an \nexpres\u00adsion M, an environment . that associates each free variable of M with a type, and the type t the \nexpression M has in .. A type judgement is valid i. there exists a type infer\u00adence tree for it. Figure \n1 shows such a tree. (We assume the literal 3 not to be overloaded but to be just of type Int.) The fact \nthat we have to split the tree into subtrees to .t it onto the page underlines that it is impossible \nto un\u00adderstand the tree as a whole. We can only look at a small part at a time. We can verify the correctness \nof the tree by verifying that each inference step is an instance of a type rule. However, an inference \nstep does not provide an expla\u00adnation. For simplicity we assume that the types of null and (:) are globally \nknown, but consider the tree leaves with the judgements for xs and ys. Why are both of type [Int]? Why \nnot any other type and why the same? Furthermore, the programmer may intend the expression .xs..ys. ... \nto have a more general type, for example the type [a]->[Int]->([Int],[a]). He wants to apply the ex\u00adpression \nto a list of Chars and a list of Ints. Only for the more general type this would be well-typed. However, \na Hindley-Milner proof tree cannot prove that there exists no more general type. Algorithm W. Most type \nexplanation systems that have been proposed are based on Milner s type checking algo\u00adrithm W. The algorithm \nrecursively traverses an expression to determine its principal type. It implicitly constructs an inference \ntree. Figure 2 visualises some intermediate states of W s construction of an inference tree for our example. \nWe do not discuss the details here but note that for each as yet unknown type the algorithm introduces \na new type variable. For example, before state A it introduces the variables b and c. When subtrees are \ncombined, type variables may have to be substituted. For example, to reach state F the type [Int] has \nto be substituted for d to make the type of the function and the type of the argument equal. So type \nvariables scope over the whole tree that has yet been constructed and the algorithm may modify the tree \nthat has already been con\u00adstructed at any later time. Furthermore, at state C the al\u00adgorithm uses the \ntype that was already inferred for xs when traversing another subtree. These global modi.cations and \n.ow of information between subtrees make it very hard to follow algorithm W. Wcan be e.ciently implemented \nbut is not suitable for explaining types.  3. COMPOSITIONAL EXPLANATIONS In the previous section we \nargued that a type explana\u00adtion cannot be based on an inference tree with global de\u00adpendencies or a type \nchecking algorithm that modi.es type variables with global scope. To be comprehensible, an ex\u00adplanation \nmust consist of small manageable units, each of which is meaningful on its own. Hence we claim that a \ntype explanation must be compositional. That is, the whole ex\u00adplanation must have a tree structure where \nthe types at each node are determined uniquely by the types of the node s chil\u00addren. Such an inference \nstep is a small explanation unit and only refers to the explanations of the child nodes. Principal Typings. \nLet us consider the expression fxy. Without knowing anything else about the variables f, x and y we can \ninfer that f must be a function which takes two arguments, the types of these arguments must equal the \ntypes of x and y, and the type of the whole expression is the result type of the function f. We can express \nthis concisely as follows: Expression: f x y Type :a with f:: b-> c-> a x::b y::c Let us do the same \nfor the expression null xs appearing in the example of the last section. We know that the prede.ned function \nnull has type [a] .Bool. Hence we can infer Expression: null xs Type : Bool with xs :: [a] Similarly \nfor the subexpression (xs, ys): Expression: (xs,ys) Type : (a,b) with xs::a ys :: b Type variables \nexpress dependencies between types. The type of an expression and the types of its variables belong together, \nseparately they are meaningless. De.nition 1. A type environment . plus a type t is a typing, written \n. ft.A type judgement . fM :: t states that M has type t in ., that is, . ft is a typing for the expression \nM. We just inferred typings of expressions: fxy has typing {f :: b .c .a, x :: b, y :: c}fa null xs has \ntyping {xs :: [a]}fBool (xs, ys) has typing {xs :: a, ys :: b}f(a, b) Note, however, that the type inference \ntree of Figure 1 uses a di.erent typing for the expression (xs, ys). But that typing is an instance of \nthe typing which we inferred. We in\u00adferred the principal, that is, most general, typing for (xs, ys). \nDe.nition 2. A typing .' ft ' is an instance of a typing . ft i. there is a type substitution s with \n.' =.s and t' = ts.A typing . ft is principal for an expression M i. it is a typing for M and all typings \nfor M are instances of . f t. For comparison, a type t is principal for an expression M and a type environment \n.i. M has type t in .and alltypes t' with . fM :: t ' are instances of t . {}fnull :: .a. [a] .Bool (i) \n{}fnull :: [Int] .Bool {xs :: [Int]}fxs :: [Int] {xs :: [Int] fnull xs :: Bool (ii) {xs :: [Int]}fxs \n:: [Int] {ys :: [Int]}fys :: [Int] {xs :: [Int],ys :: [Int]}f(xs, ys)::([Int], [Int]) {}f(:) :: .a. a \n.[a] .[a] {}f3::Int {}f(:) :: Int .[Int] .[Int] (iii) {}f(3 :) :: [Int] .[Int] {ys :: [Int]}fys :: [Int] \n{ys :: [Int]}f3: ys :: [Int] {xs :: [Int]}fxs :: [Int] {xs :: [Int],ys :: [Int]}f(3 : ys, xs)::([Int], \n[Int]) {xs :: [Int],ys :: [Int]}fif null xs then (xs, ys)else(3 : ys, xs)::([Int], [Int]) (i) (ii) (iii) \n. . . . . . . . . {xs :: [Int]}fnull xs :: Bool {xs :: [Int],ys :: [Int]}f(xs, ys)::([Int], [Int]) {xs \n:: [Int],ys :: [Int]}f(3 : ys, xs)::([Int], [Int]) {xs :: [Int]}f.ys. if null xs then (xs, ys)else(3 \n: ys, xs)::[Int] .([Int], [Int]) {}f.xs. .ys. if null xs then (xs, ys)else(3 : ys, xs)::[Int] .[Int] \n.([Int], [Int]) For space reasons the subtrees (i), (ii) and (iii) are displayed separately above the \ntree. Figure 1: A Hindley-Milner Type Inference Tree {}fnull :: .a. [a] .Bool {}fnull :: .a. [a] .Bool \n{}fnull :: [b] .Bool {xs :: [b]}fxs :: [b] {}fnull :: [b] .Bool {xs :: c}fxs :: c {xs :: [b]}fnull xs \n:: Bool State A: Introduction of b and c State B: Substitution [[b]/c] {xs :: [b]}fxs :: [b] {ys :: \nd}fys :: d {}f(:) :: .a. a .[a] .[a] {xs :: [b],ys :: d}f(xs, ys)::([b],d) {}f3::Int {}f(:) :: e .[e] \n.[e] State C: Introduction of d State D: Introduction of e {}f(:) :: .a. a .[a] .[a] {}f3::Int {}f(:) \n:: Int .[Int] .[Int] {}f(3 :) :: [Int] .[Int] {ys :: d}fys :: d State E: Substitution [[Int]/e] {}f(:) \n:: .a. a .[a] .[a] {xs :: [b]}fxs :: [b] {ys :: [Int]}fys :: [Int] {}f3::Int {}f(:) :: Int .[Int] .[Int] \n{xs :: [b],ys :: [Int]}f(xs, ys)::([b], [Int]) {}f(3 :) :: [Int] .[Int] {ys :: [Int]}fys :: [Int] {ys \n:: [Int]}f3: ys :: [Int] State F: Substitution [[Int]/d] .. .. .. {ys :: [Int]}f3: ys :: [Int] {xs :: \n[b]}fxs :: [b] {xs :: [b],ys :: [Int]}f(3 : ys, xs)::([Int], [b]) State G Figure 2: Some Intermediate \nSteps of Type Inference Tree Construction by Algorithm W A principal type is meaningless without a .xed \ntype en\u00advironment. In contrast, an expression determines its princi\u00adpal typing uniquely up to type variable \nrenaming. Hence a principal typing is a meaningful unit of information about an expression. An Inference \nStep. We have principal typings for null xs and (xs, ys) The following typing is also principal: Expression: \n(3:ys,xs) Type : ([Int],a) with xs::a ys :: [Int] How do we determine from these principal typings the \nprincipal typing for if null xs then (xs, ys) else (3 : ys, xs)? First, we arrange the three typings \nin three columns side by side: ExpresTypes with sionxs ys s: : null Bool [a xs ]b (xs,ys) (b,c) c (3:ys,xs) \n([Int],d) d [Int] We renamed the type variables of the second and third typing (the last two columns). \nThe type variables express dependencies within a typing, but they are unrelated to type variables in \nother typings. For the if-then-else construct the type of the .rst argument must be Bool and the types \nof the second and third argument must be equal. We substitute [Int] for b, and c for d: Expressions: \nnull xs (xs,ys) (3:ys,xs) Types : Bool ([Int],c) ([Int],c) with xs c [a][Int]ys c [Int] Also the types \nof the variables xs and ys have to agree. Hence we substitute [Int] for c and Int for a: Expressions: \nnull xs (xs,ys) (3:ys,xs) Types : Bool ([Int],[Int]) ([Int],[Int]) with xs [Int][Int] [Int] ys [Int][Int] \nIn short, we applied the most general substitution that gives the required type equalities. We obtain \nthe principal typing: Expression: if null xs then (xs,ys) else (3:ys,xs) Type : ([Int],[Int]) with xs \n:: [Int] ys :: [Int] Figure 3 shows the whole type inference tree of principal typings for our example. \nType variables are local to a single principal typing. The typings at the leaves of the derivation tree \nare trivial and independent of the remaining tree. The conclusion of an inference step is uniquely determined \nby its premises. In a nutshell: the tree is compositionally de.ned. A Type Error. For an untypable expression \na type inference step will fail. In that case an error message can report the con.icting typings: Type \nerror in: (map toUpper) . (++) because Expressions: (.) (map toUpper) (++) Types: (a->[Char])->a->[Char] \n[b]->[b]->[b] This error message is surprisingly similar to the one given by the Glasgow Haskell compiler. \nHowever, all the infor\u00admation in our error message has a well-de.ned meaning. The function (.) (map toUpper) \nhas the principal typing {} f (a . [Char]) . a . [Char] and its argument (++) has the principal typing \n{} f [b] . [b] . [b] (here we assume the types of map, toUpper etc. as given). The underlining of types \nemphasises that the type of function and argument do not .t together. The remaining parts of the example, \nespecially the arguments xs and ys, do not contribute to the error. If the programmer does not understand \nthe principal typing for an expression, he/she can ask for more explana\u00adtions as we will discuss in subsequent \nsections. Polymorphic and Monomorphic Variables. Type infer\u00adence for the Hindley-Milner system is in \ngeneral not as easy as we have so far suggested. Consider the expression xx. According to the previous \nexposition it gives a type error: Type error in: x x because Expressions: x x Types :a b withx a b The \ntype of the .rst x needs to be a function, that is c . d. The type of the second x must be equal to the \nargument type of the function. On the other hand both occurrences of x must have thesametype. However, \nthere exists in.nitely many typings for xx, for example: {x :: .a.a}fxx :: .a.a {x :: .a.a . a}fxx :: \n.a.a . a  The point is that x can be a polymorphic variable. Then it can be used at di.erent occurrences \nwith di.erent types. In the previous section we actually used the polymorphic variable null but we did \nnot consider the possibility that any of the variables we listed in the type environments of the typings \nis polymorphic. The expression xx is given in [6] as an example for an ex\u00adpression for which no principal \ntyping exists in the Hindley-Milner type system. The Hindley-Milner type system only has principal types, \nwhich are not su.cient for a compo\u00adsitional type explanation. So how can we get around this problem? \nThe Hindley-Milner type system clearly distin\u00adguishes between polymorphic variables and monomorphic variables. \nVariables de.ned on the top-level of a program or within a let are polymorphic. The type of a polymorphic \nvariable may contain .-quanti.ers and then the variable may be used with di.erent types. All other variables, \nbasically those representing function arguments, are monomorphic. The type of a monomorphic variable \nmay contain type vari\u00adables, but the monomorphic variable may only be used with thesametypeateachoccurrence. \nPrincipal Monomorphic Typings. The type environments in all our previous examples contain only monomorphic \nvari\u00adables. We assumed that the types of the polymorphic vari\u00adables and data constructors such as null \nand (:) were im\u00adplicitly globally known. Because new polymorphic variables can be de.ned in a program, \npossibly even within a let with only a limited scope, we need to make the types of polymorphic variables \nexplicit in a formal type system. We (i) {}fnull :: [a] .Bool {xs :: b}fxs :: b [[a]/b]{xs :: [a] fnull \nxs :: Bool (ii) {xs :: a}fxs :: a {ys :: b}fys :: b {xs :: a, ys :: b}f(xs, ys)::(a, b) (iii) {}f3::Int \n{}f(:) :: a .[a] .[a] {}f(3 :) :: [Int] .[Int] [[Int]/a] {ys :: a}fys :: a {ys :: [Int]}f3: ys :: [Int] \n[[Int]/a] {xs :: a, ys :: [Int]}f(3 : ys, xs)::([Int],a) {xs :: a}fxs :: a (i) (ii) (iii) . . . . . . \n. . . {xs :: [a]}fnull xs :: Bool {xs :: b, ys :: c}f(xs, ys)::(b, c) {xs :: d, ys :: [Int]}f(3 : ys, \nxs)::([Int],d) [Int/a, [Int]/b {xs :: [Int],ys :: [Int]}fif null xs then (xs, ys)else(3 : ys, xs)::([Int], \n[Int]) , [Int]/c, [Int]/d] {xs :: [Int]}f.ys. if null xs then (xs, ys) else (3 : ys, xs)::[Int] .([Int], \n[Int]) {}f.xs. .ys. if null xs then (xs, ys)else(3 : ys, xs)::[Int] .[Int] .([Int], [Int]) Figure 3: \nA Type Inference Tree of Principal Local Typings introduce a second, separate environment for the types \nof polymorphic variables. The idea is that the type checker takes as input an expression together with \nan environment for the polymorphic variables. If the types are not inconsis\u00adtent, then the type checker \nproduces as output a type for the expression and a type environment for the monomorphic variables which \noccur freely in the expression. This type and type environment will be the most general of all types \nand type environments that give a valid type judgement, that is, it is a principal monomorphic typing. \n 4. THE TYPE SYSTEM Following the preceding informal introduction we now de\u00ad.ne our type system of principal \nmonomorphic typings. The Language. Because we aim for a tool for real programs we do not use the classical \n.-calculus plus let. Instead, our language uses the main features of functional languages. All subsequent \nexamples are written in the language. The syntax is given in Figure 4. For type checking pur\u00adposes we \ncan de.ne patterns to be equal to expressions, but they shall not contain the let construct and in practice \nthey will have to meet more restrictions. An equation consists of a left-hand side expression and a right-hand \nside expression, where the de.ned variable appears .rst on the left-hand side. A de.nition consists of \none or more equations for the same variable. A program is a sequence of de.nitions. A de.\u00adnition may \nbe recursive, but for simplicity we do not allow mutual recursion. Hence a polymorphic variable can only \nbe used in its own and subsequent de.nitions. . is Super\u00a4uous. The Hindley-Milner type system uses the \n.-quanti.er in types of polymorphic variables. For ex\u00adample, the variable null has type .a.[a] . Bool. \nIn our type system we always regard typings instead of types. We can express polymorphism in a typing, \nwithout using the .\u00adquanti.er. The polymorphic variable null has the principal typing {}f[a] .Bool. The \nfact that null does not occur in the domain of the type environment {}indicates that null is polymorphic. \nIn contrast, a principal typing {ys :: a}fa for a variable ys indicates that ys is monomorphic. We will \nsee that ys cannot have several di.erent types in an expres\u00adsion, because at each inference step the \ntypes of all variables in the type environments are uni.ed. So in our type system we do not use the \n.-quanti.er at all. This keeps the type system simple. In particular, a type variable always scopes over \nthe typing in which it appears. It is furthermore useful in practice, because no functional lan\u00adguages \nbased on the Hindley-Milner type system uses the .-quanti.er for types of polymorphic variables. A type \nsig\u00adnature null :: [a]-> Bool in a functional language can simply be interpreted as speci\u00adfying for null \nthe typing {}f[a] .Bool For every polymorphic variables with a type signature the type environment of \nthe typing is empty. However, not for every polymorphic variables is this type environment empty, as \nwe will demonstrate later in a discussion of restricted polymorphism. Type Judgements. The environments \nfor monomorphic and polymorphic variables are separate. Whereas the former as\u00adsociate monomorphic variables \nwith types, the latter asso\u00adciate polymorphic variables with typings(!). A monomor\u00adphic (type) environment \n. is a mapping from variables to types. A (monomorphic) typing . ft is a pair of a mono\u00admorphic type \nenvironment and a type. A polymorphic (typ\u00ading) environment G is a mapping from variables to typings. \nWe often write an environment as a set of pairs. dom(G) denotes the domain of the environment G. The \n+ operator combines two environments such that the right supersedes the left. The .operator combines \ntwo environments under the assumption that they agree on the common domain. Let V be a set of variables. \nG \\V denotes the environment that variable x,y,f Int literal n:= ... |-2 |-1 |0 |1 |2 |... data constructor \nc:= (:) |[] |True |False |... expression M,N:= n|c |x|MN |let bind in M pattern P := M equation for variable \nf eq(f):= fP1 ... Pi = M; de.nition of variable f def (f):= eq1(f) ...eqi(f); program prog:= def 1(f1) \n...def i(fi); type variable a type constructor T := Int |Bool |[] |... type t:= a|t1 .t2 |Tt1 ...ti \n Figure 4: Syntax of the Language monomorphic (type) environment . := {x1 :: t1,... ,xi :: ti} (monomorphic) \ntyping . ft polymorphic (type) environment G := {.. x1 .(.1 ft1),... ,xi .(.i fti)}type judgements G; \n. fM :: t, G; . feq(f), G1;G2;. fdef (f), G; . fprog Figure 5: Type Judgements and their Components G(c)= \n{}ft G(x)=. ft x/.dom(G) a new Int Constructor PolyVar MonoVar G; {}fn :: Int G; {}fc:: t G; . fx :: \nt G; {x :: a}fx :: a G; .1 fM :: t1 G; .2 fN :: t2 Application (.,t3 .t4)= U({.1,.2},{t1,t2 .a}) a new \nG; . fMN :: t4 G; G ' ;.1 fdef (f) G+G ' ;.2 fM :: t ' Let (.,t)= U({.1,.2},{t ' }) G; . flet def (f)in \nM :: t G \\vars({P1,... ,Pi}); .1 ffP1 ...Pi :: t1 G \\vars({P1,... ,Pi}); .2 fM :: t2 Equation (.,t)= \nU({.1,.2},{t1,t2}) G; . \\vars({P1,... ,Pi}) ffP1 ...Pi = M G \\{f};.1 feq1(f) ... G \\{f};.i feqi(f) .= \nU({.1,... ,.i}) Definition G; {f .f.(f))};.' feq1(f) ...eqi(f); . ' =. \\{f} .reduce(.' G; G1;.1 fdef \n1(f1)G .G1;G2;.2 fdef 2(f2) ... G .G1 .....Gi-1;Gi;.i fdef i(fi) Program .= U({.1,... ,.i}) G .G1 .....Gi;. \nfdef 1(f1) ...def i(fi); Figure 6: The Type System of Principal Monomorphic Typings U({.1,... ,.i})=let \nax new with x .dom(.1) .....dom(.i) s =mgu({ax =.(x) |. .{.1,... ,.i},x.dom(.)}) in .1s......is U({.1,... \n,.i},{t1,... ,tj})=let a new and ax new with x .dom(.1) .....dom(.i) s =mgu({ax =.(x) |. .{.1,... ,.i},x.dom(.)}.{a= \nt |t .{t1,... ,tj }}) in (.1s......is,t1s) Figure 7: Uni.cation of Type Environments and Types reduce(. \nft)=(. \\{x .dom(.) |tyVars(.(x)) ntyVars(t)= \u00d8}ft Figure 8: Reduction of a Typing agrees with G except \nthat it is not de.ned for the variables in V . Figure 5 shows the syntax of typings, type environments \nand the four sorts of type judgements for the various pro\u00adgram fragments. The type judgements for equations, \nde.ni\u00adtions and programs do not have a type, only environments and a program fragment. The type judgement \nfor de.nitions has two polymorphic environments. The .rst is for the poly\u00admorphic variables that can \nbe used within the group and the second is for the polymorphic variable de.ned by the group. Type Rules. \nThe type rules of our type system of princi\u00adpal monomorphic typings are given in Figure 6. Variables \nin the domain of the polymorphic environment are poly\u00admorphic, all other variables are monomorphic. Note \nthat within its own de.nition a variable is monomorphic. In rule Equation the variables occurring in \nthe patterns have to be removed from environments to achieve correct variable scop\u00ading, similarly the \nde.ned variable has to be removed in rule Definition. In rules Let and Program the combination of environments \nwith + assures correct variable scoping. In rule Program G assigns typings to data constructors. Uni\u00a3cation \nof Environments and Types. The uni.cation of monomorphic environments and types is de.ned in Fig\u00adure \n7. The function Uuses a function mgu which determines the most general uni.er of a set of type equations. \nSuch a uni.cation function is de.ned in Section 11.2.2 of [12]. Envi\u00adronments are uni.ed by unifying \nthe types for each variable. The uni.ed environment has types for all variables that oc\u00adcur in any of \nthe input environments. Type Variables. Type variables always scope over a typing, no matter if the typing \nis within a polymorphic environment or part of a type judgement. For uni.cation typings are split apart \ninto monomorphic environments and types. Be\u00adcause type variables from di.erent typings are unrelated, \nthe type variables of typings that are uni.ed have to be disjoint. To ensure disjointness we demand by \nthe common informal statement a new in the type rules that every such type vari\u00adable a is distinct from \nall other type variables introduced in the type inference tree. This requirement of globally unique type \nvariables is easy to implement e.ciently. Alternatively, we could require disjointness in the premises \nof rules and add a rule for renaming type variables in typ\u00adings. This approach makes the scope of type \nvariables ex\u00adplicit in the type system, but it also leads to a larger type system that is further away \nfrom an e.cient implementa\u00adtion. Restricted Polymorphism. Consider the program: fxs=letgy=y:xs ing1++gTrue \nFor the local de.nition we obtain the type judgement: {(++) ..xs :: [a]}fa .[a])} .... }; {g .({ fg y \n= y : xs Although g is a polymorphic variable after the in, it can\u00adnot be instantiated to di.erent types \nthere. We can infer {(++) ..xs :: [a]}fa .[a])}; {xs :: [Int]} .... , g .({ fg 1::[Int]  and {(++) ..xs \n:: [a]}fa .[a])}; {xs :: [Bool]} .... , g .({ fg True :: [Bool]  but the type inference step for g 1 \n++ g True requires uni.cation of the types of xs and hence fails. The program is rightly not typable. \nThe monomorphic variable xs in the monomorphic envi\u00adronment of g expresses that the type of the variable \ng is not polymorphic in a. For programs such as this example a poly\u00admorphic environment must associate \npolymorphic variables with typings, not just types. There is however no point for such a typing to contain \na monomorphic variable whose type does not contain any type variable of the type of the typ\u00ading. Such \nsuper.uous monomorphic variables are removed by the function reduce de.ned in Figure 8 and used in rule \nDefinition. Type Inference and the Hindley-Milner system. We ob\u00adtained our type system of principal monomorphic \ntypings by rewriting John Mitchell s type checking algorithm PTL ([12], Section 11.3.3) as a type inference \nsystem and extending it to our language. Mitchell uses PTL to expose the strong relationship between \ntype checking for the simply typed .\u00adcalculus and for the Hindley-Milner type system. Our type rules \ncan be read as a type checking algorithm. The (.rst) polymorphic environment and the program frag\u00adment \nare the input. The remaining components of a type judgement, which may be a second polymorphic environ\u00adment, \nthe monomorphic environment and a type, are the output. For example, for a polymorphic environment G \nand an application MN the algorithm recursively calls itself twice. One call with G and M as input determines \nthe principal monomorphic typing .1 ft1, and the other call with G and N as input determines the principal \nmonomorphic typing .2 ft2. The two calls are independent. Finally, the uni\u00ad.cation function U combines \nthe two typings to obtain the principal monomorphic typing . ft4 for MN and G. De.nition 3. A (monomorphic) \ntyping . ft is principal for an expression M and a polymorphic environment G i. G; . fM :: t and all \n(monomorphic) typings . ' ft ' with (G ' ). .. ' fHM M :: t ' are instances of . ft . The second type \njudgement is a judgement of the Hindley-Milner type system and (\u00b7). translates a polymorphic environment \ninto an environment with .-quanti.ed types. We claim that if (G). .. ' fHM M :: t ' ,then a type judgement \nG; . f M :: t is provable in our type system and . f t is principal for M and G. Theorems 11.3.5, 11.3.9, \n11.3.10 and 11.3.13 of [12] prove similar properties for algorithm PTL. An adaption of Mitchell s proofs \nshould be routine but is outside the scope of this paper. 5. THE EXPLANATION GRAPH Our type system has \nprincipal monomorphic typings, but the polymorphic environment still creates global dependen\u00adcies in \na type inference tree. The typing for the use of a polymorphic variable is a leaf in the inference tree. \nTo un\u00adderstand why the polymorphic variable has the given typing we have to search the inference tree \nfor the place where the typing is added to the polymorphic typing environment. So the inference tree \nis not compositional. The solution is simple: We copy the whole inference tree of the de.nition of a \npolymorphic variable to every use oc\u00adcurrence of this variable in the tree, so that the typing for a \nused polymorphic variable is no longer a leaf in the tree. Consider the expression id 3 where idx=x From \nthe non-compositional derivation tree G; {} f id :: a . a G; {} f 3::Int G; {} f id 3::Int we construct \nthe tree {id :: b}f id :: b {x :: a}f x :: a {id :: a . a, x :: a}f id x :: a {x :: a}f x :: a {id :: \na . a}f id x = x {} f id :: a . a {} f 3::Int {} f id 3::Int This explanation tree is not completely \nsyntax directed as the type inference tree, but it is compositional. The poly\u00admorphic environment is \nno longer needed. We also collapse trivial inference steps for de.nitions with a single equation. The \ntyping for a data constructor is still a leaf of the tree, but it may be useful to put the de.nition \nof the data type above the typing in the tree, because it implicitly declares the type of the data constructor. \nCopying the tree for every de.nition of a polymorphic variable to every use of it is a waste of space. \nSo we share such subtrees and construct an acyclic explanation graph instead of an explanation tree. \nSharing is also useful to tell a programmer who is navigating through the explanation graph that he/she \nalready visited a certain subgraph, even if he/she did so by coming from a di.erent use point of a polymorphic \nvariable.  6. NAVIGATION THROUGH THE GRAPH We de.ned the graph to be compositional so that each inference \nstep is meaningful on its own. In practice the pro\u00adgrammer will only be interested in a fraction of the \ninference steps of the explanation graph. The programmer under\u00adstands typings best by interactively navigating \nthrough the graph. At the Level of Program Fragments. Type checking our example program from Section \n2 gives the following error message: Type error in: (last xs) : (init xs) because Expressions: (:) (last \nxs) init xs Types : [a]->[a] [b] with xs [[a]] [[[b]]] The typings of both subexpressions are surprising. \nWhy is xs a list of lists in the left subexpression and even a three times nested list in the right one? \nIt should just be a list with arbitrary elements. The central point in locating errors is that the type \nof xs in the typings of the subexpressions (:) (last xs) and init xs maywellbemoregeneral than thetypeweintend \nxs to have. However, our intended types should be an in\u00adstance of the types given in the typings. The \nfact that this is not the case is a clear indication of an error. Hence we ask for an explanation of \nthe .rst typing: Expression: (:) (last xs) Type : [a]->[a] with xs [[a]] because Expressions: (:) last \nxs Types: a->[a]->[a] b with xs [[b]] Here the typing for (:) is as intended, but not that of xs in the \ntyping for last xs. So we demand an explanation: Expression: last xs Type :b with xs [[b]] because Expressions: \nlast xs Types : [[b]]->b a with xs a We intend the function last to have type [b]->b,which is not an \ninstance of [[b]]->b. We enquire further: Function : last Type : [[a]]->a because of its definition Lhs/Rhs \n: last xs head (reverse xs) Types :c a with last b->c xs b [[a]] The left-hand side of the equation \nof last is correct, but thetypeof xs in the typing for the right-hand side contra\u00addicts our intentions. \nAt the Level of Polymorphic Variables. Asking for more explanations will .nally lead us to the source \nof the error. Unfortunately this search process is long. We can speed up the search. We only ask for \ntype explanations in terms of used polymorphic variables, that is, when traversing the explanation graph \nwe skip the inference steps for all program fragments but polymorphic variables. Thus we can quickly \nlocate the erroneous de.nition. We start again at the type error: Type error in: (last xs) : (init xs) \nbecause last :: [[a]]->a init :: [[[a]]]->[a] We intend the types of both polymorphic functions to be \nmore general. We ask for an explanation of the .rst one: last :: [[a]]->a because head :: [a]->a reverse \n:: [[a]]->[a] Here thetypeof head is as intended, but not the type of reverse. So we ask for an explanation \nof its type: reverse :: [[a]]->[a] because (++) :: [a]-> [a]-> [a] The type of the only polymorphic variable \nthat is used is correct. Hence the error must be in the de.nition of reverse. To determine the exact \nlocation of the error we now switch to explanations at the level of program fragments: reverse :: [[a]]->[a] \nbecause Equation: .. []= [] .. (x:xs) = .. with reverse [b]->[c] [[a]]->[a] The expected type of reverse, \n[a]->[a] is an instance of the type given in the typing for the .rst equation, but not an instance of \nthe type given in the typing for the second equation. Hence we ask about the second typing: Equation \n: .. (x:xs) = .. with reverse [[a]]->[a] because Lhs/Rhs : reverse (x:xs) (reverse xs) ++ x Types : b \n[a] with reverse [c]->b d->[a] x c [a] xs [c]d In the second typing x is a list. Because that is not \nour intention, we ask further: Expression : (reverse xs) ++ x Type : [a] with reverse d->[a] x [a] xs \nd because Expressions : (++) (reverse xs) x Types : [b]->[b] c with reverse a->[b] xc xs a Here both \ntypings are reasonable. Hence we have located the error: The expression (reverse xs) ++ x is wrong. By \ncomparing our intentions with the de.nition of reverse and the given typings we realise that the correct \nexpression is (reverse xs) ++ [x]. Navigation at di.erent levels enables us to avoid unneces\u00adsary detail \nand to quickly reach the source of a type error. We usually start at the high level, regarding only polymor\u00adphic \nfunctions, and later move to individual inference steps at program fragment level. It is also conceivable \nto have an even .ner level, which shows the uni.cation process of a type inference step in several stages. \n 7. ALGORITHMIC DEBUGGING The problem that a type checker notices type inconsis\u00adtencies often far from \nthe sources of the errors reminds of the similar problem for run-time errors, which also usually are \nobserved far from the source. Algorithmic debugging was introduced by Shapiro to diagnose wrong and missing \nanswers in Prolog [18]. Later algorithmic debugging was successfully applied to locate the sources of \nrun-time errors in functional and other languages [15, 5]. The principle of algorithmic debugging is \nnot linked to run-time errors. It is quite clear from [13] that algorithmic debugging can be applied \nto any propositions such as evaluation judgements or type judgements which are de.ned by a compositional \ntree (or acyclic graph). At every tree node is a proposition which can be correct or erroneous. A node \nis the source of an error, if its proposition is erroneous but the propositions of all its children are \ncorrect. Algorithmic debugging con\u00adsistsofconstructingatreewithanerroneousrootwhenwe observe erroneous \nbehaviour and then locating in the tree a source of this error. To determine if a node proposition is \nerroneous, an oracle is used. Usually the oracle is the programmer, who is asked questions about the \nvalidity of propositions. Here is an example session with user input (y/n) in italics: Type error in: \n(last xs) : (init xs) last :: [[a]]->a Is intended type an instance? (y/n) n head :: [a]->a Is intended \ntype an instance? (y/n) y reverse :: [[a]]->[a] Is intended type an instance? (y/n) n (++) :: [a]-> \n[a]-> [a] Is intended type an instance? (y/n) y At this point the system knows that the source of the \nerror is in the de.nition of reverse andstartsaskingabout typings of fragments of the de.nition. reverse \n:: [b]->[c] Is intended type an instance? (y/n) y reverse :: [[a]]->[a] Is intended type an instance? \n(y/n) n The system could actually know the answer to this ques\u00adtion from the third question. reverse \n(x:xs) :: b reverse :: [c]->b x :: c xs :: [c] Are intended types an instance? (y/n) y Note that equal \ntype variables of separate types must be instantiated equally to obtain the intended types. (reverse \nxs) ++ x :: [a] reverse :: d->[a] x :: [a] xs ::d Are intended types an instance? (y/n) n (++) (reverse \nxs) :: [b]->[b] reverse :: a->[b] xs ::a Are intended types an instance? (y/n) y Error located. Wrong \nexpression: (reverse xs) ++ x The system assumes that the typing for a single variable such as x is \ncorrect. It probably should also never ask about the types of data constructors such as (:), assuming \nthat type de.nitions are correct. It is useful and common practice in algorithmic debugging that the \nprogrammer can declare a set of variables as correct, as trusted; for example all vari\u00adables de.ned in \nsome standard libraries. This reduces the number of questions. To reduce the number of questions further, \nit is feasible that the programmer, instead of just answering no,alsoin\u00addicates which part of which type \ndoes not meet his/her in\u00adtentions. As answer to the question reverse :: [[a]]->[a] Are intended types \nan instance? the programmer may indicate, that the inner list of the argument type is erroneous. Hence \nthe second equation of the de.nition of reverse must be erroneous and the system can skip the question \nreverse :: [b]->[c] Is intended type an instance? (y/n) Similarly, the programmer could indicate that \ntwo occur\u00adrences of the same type variable con.ict with his/her inten\u00adtions of instantiating these occurrences \ndi.erently. The questions of algorithmic debugging are shorter than explanations of typings. Also algorithmic \ndebugging leads to the source of the error without the programmer having to understand how typings were \ninferred. On the other hand the programmer might want to understand typings. Fur\u00adthermore, it is in practice \nmuch easier to locate an erroneous typing in a set of typings than to state whether a typing is an instance \nof the intended one. We believe that a combination of algorithmic debugging together with free navigation \nthrough explanations of type inference steps is desirable. Practical experience is needed to determine \nhow exactly the programmer can use the ex\u00adplanation tree most e.ectively.  8. IMPLEMENTATION We built \na prototype type explanation and debugging tool. For a program in the language de.ned in Section 6 it \nconstructs the type explanation graph; in case of an unty\u00adpable program the root of the graph is a type \nerror message. The tool only has a simple textual user interface but enables navigation through the explanation \ngraph in various ways. With the prototype we tested many examples and re.ned our ideas. All the examples \nin this paper were obtained from the output of the prototype. The prototype is written in Haskell, based \non Mark Jones type checker for core Haskell [7]. Although we had to replace the actual type checking \nalgorithm by our own type checking algorithm, Jones type checker provides a framework and will be even \nmore useful when we extend the prototype to handle the Haskell class system. In the development of our \nprototype we concentrated on quick development and ease of modi.cation to explore our ideas. In return \nit is not e.cient at all. The main e.\u00adciency issue for a practical tool is the space required for the \nexplanation graph. The graph is huge. However, it does not need to be constructed in full but can be \nconstructed in smallpiecesasneeded. Thetypechecker may.rstonly store the typings of polymorphic variables. \nThen, when the programmer requires an explanation of some program frag\u00adment, this fragment is type checked \nagain and its part of the explanation graph constructed. Note that the type checking algorithm of principal \nmonomorphic typings only requires the typings of all polymorphic variables in scope to type check a program \nfragment. Even an improved implementation of our type checking algorithm is probably less e.cient than \na good implemen\u00adtation of Milner s W algorithm. Our algorithm introduces more type variables and performs \nmore uni.cations. Fur\u00adthermore, during the construction of the explanation tree type variables cannot \nbe implemented as mutable variables for e.cient substitution, because all type variables appear in the \nexplanation graph. However, a combination of our al\u00adgorithm with algorithm W is possible. Both stop at \na type con.ict in the same top-level de.nition. So W may be used .rst and only the erroneous de.nition \nhas to be type checked again with our algorithm. 9. RELATED WORK Many people have investigated methods \nfor improving the understanding of type errors. Several of these also saw the need for a type checking \nalgorithm di.erent from W.Bern\u00adstein and Stark use a type checking algorithm similar to ours that de.nes \ntype inference trees that are compositional without any post-processing [2]. Basically, the algorithm \ndetermines a type for each occurrence of a variable. These types are uni.ed (or matched in the case of \na polymorphic variable) at the binding occurrence of the variable. The sys\u00adtem enables the programmer \nto obtain the types of subex\u00adpressions; the authors do not take advantage of the compo\u00adsitionality. The \nlarge number of types for a single variable make types and especially typings hard to understand. To\u00adgether \nwith Simon and Huch we developed a variation of this type checking algorithm that reduces the problem \n[19]: the algorithm collects several types only for monomorphic variables. However, we had not yet realised \nthe importance of compositionality and typings. Yang also outlines a similar algorithm [24]. He suggests \ncombining it with algorithm M. M passes more type information downward than W when traversing an expression. \nLee and Yi show that M .nds type con.icts earlier than W [8]. McAdam de.nes uni.cation of substitutions \nto avoid the left-to-right bias of W [9]. Walz and Johnson apply a maximum .ow technique to the set of \ntype equations to determine the most likely source of an error [21]. Wand [22] modi.es the uni.cation \nalgorithm used by W to keep track for every type variable which pro\u00adgram fragment forces its instantiation. \nBeaven and Stansifer [1] and later Duggan and Bent [4] improve Wand s method. Choppella and Haynes present \na related method [3]. It might be possible to transfer some of these approaches to our type system to \nguide and reduce the number of questions in al\u00adgorithmic debugging. Several people note the importance \nof an interactive tool. Soosaipillai developed a tool for a small functional language that interactively \nexplains each step of algorithm W [20]. Rittri outlines the design of an interactive type error ex\u00adplanation \nsystem based on Wand s method [17]. Together with Simon and Huch we developed a tool for interactively \nviewing the types of subexpressions in their context [19]. McAdam de.nes a graph with type information \nto gen\u00aderalises the approaches of Wand and Bernstein and Stark [10] Yang and Michaelson investigate psychological \naspects of explaining type errors [25, 26]. Yang, Michaelson, Trinder and Wells present a manifesto of \nproperties a good type er\u00adror reporting system should have [23]. We think our system has all seven properties. \n10. SUMMARY AND FUTURE WORK We analysed the problem of understanding types and type errors and identi.ed \ncompositionality as a key to generating good explanations. A tree of principal types is not compo\u00adsitional. \nA tree of principal typings is compositional. In the Hindley-Milner type system not every expression \nhas a principal typing, but we noticed that Mitchell s type al\u00adgorithm PTL implicitly de.nes a type system \nof principal monomorphic typings. From the type inference tree of this type system we construct a compositional \nacyclic type expla\u00adnation graph. Each inference step of the graph is uniquely determined by the premises \nand can hence be understood on its own. An explicit .-quanti.er or generic and non-generic type variables \nare unnecessary. We demonstrated how in\u00adteractive navigation of the explanation graph assists under\u00adstanding \ntypes and type errors and how algorithmic debug\u00adging based on the explanation graph can semi-automatically \nlocate the source of type errors. Experiments with our prototype tool are encouraging. The tool needs \na better user interface. To improve orientation in the explanation graph, we envision the tool to show \nex\u00adplanations of typings in one window and the source program with the relevant program fragments highlighted \nin a second window. The programmer should also be free to mark any program fragment and ask for its typing. \nA mouse pointer would ease marking erroneous parts of types. The polymorphism of the Haskell class system \nmakes type errors even worse. Just view Hugs error message for the tiny expression (print . div) 42: \nERROR: Illegal Haskell 98 class constraint in inferred type * Expression : (print . div) 42 * Type : \n(Show (a -> a), Integral a) => IO ()  We are currently working on extending our prototype to handle \nthe Haskell class system. The extension of the ex\u00adplanation graph by classes appears to be straightforward. \nType systems for various kinds of program analysis have been developed [14]. We speculate that explanation \ngraphs similar to ours can be constructed for many of these sys\u00adtems. Such a graph may be a good basis \nfor showing the inferred information to the developer of the analysis or even the programmer. A navigation \nand algorithmic debugging tool based on the type explanation graph is no magic wand which turns all problems \nwith types into wisps of white smoke. But we claim that it substantially helps to understand types and \nto .nd the cause of most type errors. Acknowledgements I thank Simon Thompson, Axel Simon, Frank Huch, \nColin Runciman and the anonymous referees.  11. REFERENCES [1] M. Beaven and R. Stansifer. Explaining \ntype errors in polymorphic languages. ACM LOPLAS, 2(4):17 30, 1993. [2] K. Bernstein and E. Stark. Debugging \ntype errors. Technical report, Stony Brook, 1995. [3] V. Choppella and C. T. Haynes. Diagnosis of ill-typed \nprograms. TR426, Indiana University, 1995. [4] D. Duggan and F. Bent. Explaining type inference. Science \nof Computer Programming, 27(1):37 83, 1996. [5] P.Fritzson,N.Shahmehri,M.Kamkar, and T. Gyimothy. Generalized \nalgorithmic debugging and testing. ACM LOPLAS, 1(4):303 322, Dec. 1992. [6] T. Jim. What are principal \ntypings and what are they good for? In POPL 96, pages 42 53. ACM, 1996. [7] M. P. Jones. Typing Haskell \nin Haskell. In Proceedings of the 1999 Haskell Workshop, pages 1 14. Universiteit Utrecht, UU-CS-1999-28, \n1999. [8] O. Lee and K. Yi. Proofs about a folklore let-polymorphic type inference algorithm. ACM TOPLAS, \n20(4):707 723, July 1998. [9] B. J. McAdam. On the uni.cation of substitutions in type inference. In \nIFL 98, LNCS 1595, pages 137 152, 1999. [10] B. J. McAdam. Generalising techniques for type debugging. \nIn Trends in Functional Programming, chapter 6. Intellect, 2000. [11] R. Milner. A theory of type polymorphism \nin programming. Journal of Computer and System Sciences, 17:348 375, Dec. 1978. [12] J. C. Mitchell. \nFoundations for Programming Languages. MIT Press, 1996. [13] L. Naish. A declarative debugging scheme. \nJournal of Functional and Logic Programming, 1997(3), 1997. [14] F. Nielson, H. R. Nielson, and C. Hankin. \nPrinciples of Program Analysis. Springer, 1999. [15] H. Nilsson. Declarative Debugging for Lazy Functional \nLanguages. PhD thesis, Link\u00a8oping, Sweden, May 1998. [16] S. L. Peyton Jones, J. Hughes, et al. Haskell \n98: A non-strict, purely functional language. http://www.haskell.org, Feb. 1999. [17] M. Rittri. Finding \nthe source of type errors interactively. In Proceedings of El Winterm\u00a8ote,pages 273 276. University of \nG\u00a8oteborg and Chalmers University of Technology, 1993. PMG report 73. [18] E. Y. Shapiro. Algorithmic \nProgram Debugging.MIT Press, 1983. [19] A. Simon, O. Chitil, and F. Huch. Typeview: A tool for understanding \ntype errors. In Draft Proc. of IFL 2000, pages 63 69. RWTH Aachen, 2000. AIB 00-7. [20] H. Soosaipillai. \nAn explanation based polymorphic type checker for Standard ML. Master s thesis, Heriot Watt University, \nEdinburgh, Scotland, 1990. [21] J. A. Walz and G. F. Johnson. A maximum .ow approach to anomaly isolation \nin uni.cation-based incremental type inference. In POPL 86, pages 44 57. ACM, 1986. [22] M. Wand. Finding \nthe source of type errors. In POPL 86, pages 38 43. ACM, 1986. [23] J. Yan, G. Michaelson, P. Trinder, \nand J. B. Wells. Improved type error reporting. In Draf Proc. of IFL 2000, pages 71 86. RWTH Aachen, \n2000. AIB 00-7. [24] J. Yang. Explaining type errors by .nding the source of a type con.ict. In Trends \nin Functional Programming, chapter 7. Intellect, 2000. [25] J. Yang and G. Michaelson. A visualisation \nof polymorphic type checking. Journal of Functional Programming, 10(1):57 75, 2000. [26] J. Yang, G. \nMichaelson, and P. Trinder. How do people check polymorphic types? In Proceedings of 12th Workshop on \nPsychology of Programming,pages 67 77. Edizioni Memoria, 2000.  \n\t\t\t", "proc_id": "507635", "abstract": "The type systems of most typed functional programming languages arebased on the Hindley-Milner type system. A practical problem withthese type systems is that it is often hard to understand why aprogram is not type correct or a function does not have theintended type. We suggest that at the core of this problem is thedifficulty of explaining why a given expression has a certain type.The type system is not defined compositionally. We propose toexplain types using a variant of the Hindley-Milner type systemthat defines a compositional type explanation graph of principaltyping. We describe how the programmer understands types byinteractive navigation through the explanation graph. Furthermore,the explanation graph can be the foundation for algorithmicdebugging of type errors, that is, semi-automatic localisation ofthe source of a type error without even having to understand thetype inference steps. We implemented a prototype of a tool toexplore the usefulness of the proposed methods.", "authors": [{"name": "Olaf Chitil", "author_profile_id": "81100243192", "affiliation": "Univ. of York, York, UK", "person_id": "PP14093711", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/507635.507659", "year": "2001", "article_id": "507659", "conference": "ICFP", "title": "Compositional explanation of types and algorithmic debugging of type errors", "url": "http://dl.acm.org/citation.cfm?id=507659"}