{"article_publication_date": "10-01-2001", "fulltext": "\n Down with Emacs Lisp: Dynamic Scope Analysis Matthias Neubauer Michael Sperber Institut fur Informatik \n\u00a8Wilhelm-Schickard-Institut f\u00a8 ur Informatik Universit\u00a8Universit\u00a8ubingen at Freiburg at T\u00a8 neubauer@informatik.uni-freiburg.de \nsperber@informatik.uni-tuebingen.de ABSTRACT It is possible to translate code written in Emacs Lisp \nor an\u00adother Lisp dialect which uses dynamic scoping to a more modern programming language with lexical \nscoping while largely preserving structure and readability of the code. The biggest obstacle to such \nan idiomatic translation from Emacs Lisp is the translation of dynamic binding into suitable in\u00adstances \nof lexical binding: Many binding constructs in real programs in fact exhibit identical behavior under \nboth dy\u00adnamic and lexical binding. An idiomatic translation needs to detect as many of these binding \nconstructs as possible and convert them into lexical binding constructs in the target language to achieve \nreadability and e.ciency of the target code. The basic prerequisite for such an idiomatic translation \nis thus a dynamic scope analysis which associates variable occurrences with binding constructs. We present \nsuch an analysis. It is an application of the Nielson/Nielson frame\u00adwork for .ow analysis to a semantics \nfor dynamic binding akin to Moreau s. Its implementation handles a substantial portion of Emacs Lisp, \nhas been applied to realistic Emacs Lisp code, and is highly accurate and reasonably e.cient in practice. \n 1. MIGRATING EMACS LISP Emacs Lisp [16, 29] is a popular programming language for a considerable number \nof desktop applications which run within the Emacs editor or one of its variants. The actively maintained \ncode base measures at around 1,000,000 loc1 . As the Emacs Lisp code base is growing, the language is \nshowing its age: It lacks important concepts from modern functional programming practice as well as provisions \nfor large-scale modularity. Its implementations are slow com\u00adpared to mainstream implementations of other \nLisp dialects. Moreover, the development of both Emacs dialects places 1The XEmacs package collection \nwhich includes many pop\u00adular add-ons and applications currently contains more than 700,000 loc. Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro\u00a3t or commercial advantage and that copies \nbear this notice and the full citation on the \u00a3rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci\u00a3c permission and/or a fee. ICFP 01, September \n3-5, 2001, Florence, Italy. Copyright 2001 ACM 1-58113-415-0/01/0009 ...$5.00. comparatively little focus \non signi.cant improvements of the Emacs Lisp interpreter. On the other hand, recent years have seen the \nadvent of a large number of extension language implementations of full programming languages suitable \nfor the inclusion in application software. Speci.cally, several current Scheme implementations are technologically \nmuch better suited as an extension language for Emacs than Emacs Lisp itself. In fact, the o.cial long-range \nplan for GNU Emacs is to replace the Emacs Lisp substrate with Guile, also a Scheme implementation [28]. \nThe work presented here is part of a di.erent, independent e.ort to do the same for XEmacs, a variant \nof GNU Emacs which also uses Emacs Lisp as its extension language. Replacing such a central part of an \napplication like XEmacs presents di.cult pragmatic problems: It is not feasible to re\u00adimplement the entire \nEmacs Lisp code base by hand. Thus, a successful migration requires at least the following ingre\u00addients: \n Emacs Lisp code must continue to run unchanged for a transitory period.  An automatic tool translates \nEmacs Lisp code into the language of the new substrate, and it must produce maintainable code.  Whereas \nthe .rst of these ingredients is not particularly hard to implement (either by keeping the old Emacs \nLisp imple\u00admentation around or by re-implementing an Emacs Lisp en\u00adgine in the new substrate), the second \nis more di.cult. Even though a direct one-to-one translation of Emacs Lisp into a modern latently-typed \nfunctional language is straightfor\u00adward by using dynamic assignment or dynamic-environment passing to \nimplement dynamic scoping, it does not result in maintainable output code: Users of modern functional \nlan\u00adguages use dynamic binding only in very limited contexts such as exception handling or parameterization. \nAs it turns out, the situation is not much di.erent for Emacs Lisp users: For many lets and other binding \nconstructs in real Emacs Lisp code, dynamic scope and lexical scope are identical! Consequently, a good \nidiomatic translation of Emacs Lisp into, say, Scheme, should convert these binding constructs into the \ncorresponding lexical binding constructs of the tar\u00adget substrate. The only problem is to recognize these \nbinding constructs, or rather, distinguish those where the programmer meant dynamic scope from those \nwhere she meant lexical scope. Since with dynamic scope, bindings travel through the pro\u00adgram execution \nmuch as values do, this requires a proper (let* ((filename (expand-file-name filename)) (file (file-name-nondirectory \nfilename)) (dir (file-name-directory filename)) (comp (file-name-all-completions file dir)) newest) (while \ncomp (setq file (concat dir (car comp)) comp (cdr comp)) (if (and (backup-file-name-p file) (or (null \nnewest) (file-newer-than-file-p file newest))) (setq newest file))) newest)) Figure 1: Typical usage \nof let in Emacs Lisp. .ow analysis. This paper presents such an analysis called dynamic scope analysis. \nSpeci.cally, our contributions are the following: We have formulated a semantics for a subset of Emacs \nLisp, called Mini Emacs Lisp, similar to the sequential evaluation function for .d by Moreau [20].  \nWe have applied the .ow analysis framework of Niel\u00adson and Nielson [22] to the semantics, resulting in \nan acceptability relation for .ow analyses of Mini Emacs Lisp programs.  We have used the acceptability \nrelation to formulate and implement a .ow analysis for Emacs Lisp which tracks the .ow of bindings in \naddition to the .ow of values.  We have applied the analysis to real Emacs Lisp code. More speci.cally, \nthe analysis is able to handle medium\u00adsized real-world examples with high accuracy and rea\u00adsonable e.ciency. \n The work presented here is a part of the el2scm project that works on the migration from Emacs Lisp \nto Scheme. How\u00adever, the other aspects of the translation (such as front-end issues, correct handling \nof symbols, the code-data duality, treatment of primitives and so on) are outside the (lexical) scope \nof this paper. Indeed, the analysis could be used for a number of other purposes, among them the development \nof an e.cient compiler for Emacs Lisp, or the translation to a di.erent substrate such as Common Lisp. \nOverview. The next section presents some code examples which show the need for a dynamic scope analysis. \nSec\u00adtion 3 de.nes the syntax of Mini Emacs Lisp. Section 4 develops an operational semantics with evaluation \ncontexts. Based on the semantics, Section 5 presents a speci.cation of a correct .ow analysis. The next \nsection sketches a cor\u00adrectness proof. Our implementation approach is described in Section 7. Section \n8 describes some experimental results gained with our implementation prototype. We end with a discussion \nof related work and a conclusion.  2. EXAMPLES Consider the Emacs Lisp code shown in Figure 1, taken \nliterally from files.el in the current XEmacs core. It (let ((file-name-handler-alist nil) (format-alist \nnil) (after-insert-file-functions nil) (coding-system-for-read binary) (coding-system-for-write binary) \n(find-buffer-file-type-function (if (fboundp find-buffer-file-type) (symbol-function find-buffer-file-type) \nnil))) (unwind-protect (progn (fset find-buffer-file-type (lambda (filename) t)) (insert-file-contents \nfilename visit start end replace)) (if find-buffer-file-type-function (fset find-buffer-file-type find-buffer-file-type-function) \n(fmakunbound find-buffer-file-type)))) Figure 2: Parameterizations via dynamic let in Emacs Lisp. contains \n.ve variable bindings, all introducing temporary names for intermediate values. The bindings of the vari\u00adables \nfilename, file, dir, comp,and newest are all visible in the other functions reachable from the body of \nthe let, yet none of them contain occurrences of these names. The only variable occurrences which access \nthe bindings are in the body of the let* itself, and all are within the lexical scope of the bindings. \nHence, translating the let* into a lexically-scoped counterpart in the target language would preserve \nthe behavior of this function. Figure 2 shows an example for idiomatic use of dynamic binding (also taken \nfrom files.el): It is part of the im\u00adplementation of insert-file-contents-literally which calls insert-file-contents \nin thebodyofthe let.The de.nition of insert-file-contents indeed contains occur\u00adrences of the variables \nbound in the let with the exception of find-buffer-file-type-function. Therefore, it is not permissible \nto translate the let with a lexically-scoped bind\u00ading construct. For the vast majority of binding constructs \nin real Emacs Lisp code, dynamic scope and lexical scope coincide. Thus, the ultimate goal of the analysis \nis to detect as many of these bindings constructs as possible. In general however, value .ow and the \n.ow of bindings in\u00adteract during the evaluation of Emacs Lisp programs. Hence, it is not possible to \napply standard .ow analyses based on lexical-binding semantics to solve the problem; a new anal\u00adysis \nis necessary. 3. SYNTAX OF MINI EMACS LISP For the sake of simplicity, we concentrate on a subset of \nEmacs Lisp called Mini Emacs Lisp in the paper. We omit multi-parameter (and variable-parameter) functions, \ncatch/throw, dual name spaces for functions and ordinary values, the resulting gratuitous split between \nfuncall and regular application as well as the data/code duality which appears in various contexts in \nEmacs Lisp. Adding these features to the analysis is straightforward and does not re\u00adquire signi.cant \nnew insights, which is why we omit it here. Our implementation of the analysis does treat all of these \nfeatures. Here is the syntax for Mini Emacs Lisp: l .Lab ::= ... s,x .SymVar ::= fritz |franz |... c \n.Lit ::= 0 |1 |2 |... b .Prim ::= cons |car |... t .Term ::= c | (quote s) | (lambda (x) e) | x | (setq \nxe) | (e0 e1) | (let xe1 e2) | (if e0 e1 e2) | (be1 ...en) e .Exp ::= tl d .Def ::= (defvar xe) | (defun \nx0 (x1) e) p .Prg ::= d * e All expressions carry unique labels which the analysis uses for identifying \nlocations in the program source. The set of literals is trivially extensible. Note that Emacs Lisp uses \nthe nil symbol for boolean false, and everything else for true. An Emacs Lisp program consists of a sequence \nof de.ni\u00adtions followed by a single expression the entry point of the program.  4. A SEMANTICS FOR MINI \nEMACS LISP We present a structural operational or small-step seman\u00adtics [23] for Mini Emacs Lisp. We \nuse evaluation contexts and syntactic rewriting as developed by Felleisen and Fried\u00adman [6]. 4.1 Values \nand Intermediate Terms We use separate syntactic categories for intermediate ex\u00adpressions and values. \nHere is the syntax for literals and abstractions: f .Fun ::= (func (x) e) v .Val ::= (prim c) | (sym \ns) | f l1 l2 | (pair vv ) 12 it .ITerm ::= (bind xve) e .Exp ::= v l |itl The elements of Val, called \nvalues, are results from success\u00adful computations. They represent primitive values, symbols and functions, \nand correspond to the the expressions of Exp which produce them. The semantics uses intermediate bind \nterms to handle dy\u00adnamic binding: They result from reducing let expressions with the value to be bound \nto the variable already evaluated. Expressions attach labels to values and intermediate terms. Only the \nvalue bound to a variable by a bind term does not carry a label because bind expressions only show up \nduring evaluation, but not in the analysis which only looks at the source code. 4.2 Environments Environments \n.are .nite mapping from symbols to values and contain bindings: . .Env = SymVar ..n Val. The notation \nfor the empty environment is []. The modi.\u00adcation of an existing environment through the new mapping \nof a symbol x toavalue v is written as .[x v]. . 4.3 Evaluation Contexts Here are the evaluation contexts \nfor Mini Emacs Lisp: E.EvalContext ::= [-] | (Ee2)l | (if Ee1 e2)l | (let x Ee2)l | (bind xv E)l | (setq \nx E)l | (pv * Ee * )l Vx0 .VarContext(x0) ::= [-] | (Ee2)l | (if Vx0 e1 e2)l | (let x Vx0 e2)l | (bind \nx1 v Vx0 )l if x0 = x1 | (setq x V)l x0 | (bv * Vx0 e * )l The rules for EvalContext describes all contexts \nin which a reduction step in Mini Emacs Lisp can occur. Variable ac\u00adcess needs the most recent dynamic \nbinding of the variable. The variable contexts in VarContext(x0) help accomplish this; they describe \nall contexts that do not contain any bind\u00adings associated with the symbol x0.  4.4 Reductions An evaluation \nstate consists of a partially evaluated ex\u00adpression and a global environment. Thus, a con.guration . \nof Conf is a tuple consisting of an environment and a current expression: . .Conf = Env \u00d7Exp. The primitive \nsteps of the evaluation process are reduction rules. Some expressions immediately reduce to a value: \n[c] .,E[c l] ..,E[(prim c)l] [quote] .,E[(quote s)l] ..,E[(sym s)l] [lambda] .,E[(lambda (x) e)l] ..,E[(func \n(x) e)l] Note that in Emacs Lisp, abstractions do not evaluate to closures this is dynamic scope, after \nall. Here are the semantic mechanics for dealing with variable A variable may have either a local or \na global binding. The let and lambda constructs introduce local bindings. For a variable occurrence, \nthe closest bind context for that vari\u00adable holds its value. The [var] rule expresses this behavior; \nthe context Vx guarantees that there is no other binding closer to the variable. Lacking a local binding, \na global one must apply; the [varglob]ruletakes over. access: [var] ., E[(bind xv Vx [x l])l0 ] . ., \nE[(bind xv Vx [v l])l0 ] [varglob] ., Vx [x l] .., Vx [v l]if x .dom(.),.(x)= v The machinery for mutating \nbindings by setq is analogous to the one for referencing variables: [setq] ., E[(bind xv Vx [(setq xv0 \nl0 )l])l1 ] . ., E[(bind xv0 Vx [v0l ])l1 ] [setqglobal] ., Vx [(setq xv0 l0 )l] ..[x .v0], Vx [v0l ] \nIn the case of a local binding, the [setq] rule changes the value in the corresponding bind context. \nAssignments to global variables mutate the global environment. Here are the reductions for function applications \nand local variable bindings: [app] ., E[((func (x1) e2)l0 e1)l] .., E[(let x1 e1 e2)l] l1 e2)l] [let] \n., E[(let xv1 e2)l] .., E[(bind xv1 [bind] ., E[(bind xv0 v1 l1 )l] .., E[v1l ] The [app] rule reduces \na function application to a binding of the function parameter wrapped around the function body and the \nenvironment. The [let]ruleof EvalContext turns a let expression into a corresponding bind expression. \nEvaluation continues with the body e2 until it becomes a value. Then, the [bind]rule removes the obsolete \ncontext. Note that the distinction between let expressions and bind expressions is unnecessary when considering \nonly the semantics, but the formulation of the .ow analysis requires their separation. The [if1]and [if2] \nrules handle conditionals: l0 l1 l [if1] ., E[(if vt1 e2)l] .., E[t1]if v = (sym nil) l0 l2 )l [if2] \n., E[(if ve1 t2 ] .., E[t2l ]if v = (sym nil) Here are reduction rules for selected primitives, namely \nthose dealing with pairs: l1 l2 )ll1 l2 )l [cons] ., E[(cons vv ] .., E[(pair vv ] 12 12 l1 l2 l [car] \n., E[(car (pair v1 v2 )l0 )l] .., E[v1] l1 l2 l [cdr] ., E[(cdr (pair v1 v2 )l0 )l] .., E[v2] The [cons] \nrule produces a pair value from two argument values. Car selects the .rst component of pairs by rule \n[car], the [cdr] rule handles cdr. The combination of the reduction rules de.nes the reduc\u00adtion relation \n..Conf \u00d7Conf putting all possible con.gurations before and after a reduc\u00adtion step during evaluation \nin relation. Its re.exive transi\u00adtive closure is written .*.  4.5 Expression Contexts So far, only the \nmeaning of expression is de.ned by the . relation. For programs, we de.ne another kind of context, the \nexpression contexts of ExpContext: X. ExpContext ::= (defvar x [-]) p | [-] 4.6 Reductions for Programs \nEquipped with the notion of program con.gurations d .PConf = Env \u00d7Prg, as well as contexts for programs \nX and the reduction relation . for expressions, it is possible to state the rewriting rules . d for \nprograms:  [defvar] ., (defvar xv0 l0 ) p .d .[x .v0],p if x .dom(.) [defun] ., (defun x0 (x1) e) p \n.d .[x0 .(func (x1) e)],p if x0 .dom(.) ., e ..' ,e ' [exp] ' ., X[e] .d .', X[e] The [defvar]and [defun] \nrules satisfy top-level de.nitions. The [defvar] rule inserts the new global binding in the vari\u00adable \nenvironment .. The condition x . dom(.) guarantees that there is only one global variable for every name. \nThe [defun] rule does the equivalent for procedures. The [exp] rule allows the use of all the reductions \nfor expressions at the places de.ned using the contexts ExpContext. Again .d * is the re.exive transitive \nclosure of .d. 4.7 The Evaluation Function of Programs The reduction relation .d rewrites the program \nuntil it gets a .nal answer. This does not always happen: the pro\u00adgram may loop in which case the reduction \nsequence is in\u00ad.nite, or evaluation may get stuck at a con.guration with no matching reduction rule. \nThus, the reduction relation induces a partial evaluation function eval: eval : Prg --+Val v if [],p \n.d * ., v for some . eval(p)=unde.ned otherwise  5. SPECIFICATION OF THE ANALYSIS This section speci.es \na .ow analysis for Mini Emacs Lisp. With the help of the de.nitions for the abstract domains of the analysis \nwe de.ne an acceptability relation for correct .ow analyses which employ these domains. The actual anal\u00adysis \nresults directly from the de.nition of the acceptability relation. 5.1 Abstract Domains Here are the \nabstract domains of the analysis: V bp . BP = Lab .{o} bpe . BPEnv SymVar .V P= BP PP p . Cons = Lab \n\u00d7Lab \u00d7BPEnv V v . Val = P(SymVar .{.}.Fun .PCons) . Env BP) .V . V=(SymVar \u00d7VVal PP C . Cache =(Lab \n\u00d7 Val BPEnv) .V V Birthplaces BP for short denote syntactic locations of variable bindings. The ostands \nfor top-level bindings. The label of the body of a function or of a let expression serves as the birthplace \nfor the binding it creates. Birthplace environments BPEnv are abstractions over P regular variable environments; \nthey map variables to birth\u00adplaces instead of regular values. P Cons is one part of the abstract value \ndomain; it is the set of all possible abstract pairs and contains all triples of two labels and a birthplace \nenvironment. The two labels are the labels of these two argument subexpressions of the cons expression \nwhich created the pair. The birthplace en\u00advironment registers the abstract bindings active at the time \nof creation of the pair. Registering the birthplace environ\u00adment is necessary because we di.erentiate \nprogram points depending on the birthplace environments they occur under. V Val is the set of all possible \nabstract values v. An abstract value represents a set of run-time values. Not every run-time value is \nrelevant to the analysis: the single symbol . repre\u00adsents all primitive values except for symbols. The \nanalysis tracks symbols needed (eventually) for variable names, func\u00adtions, primitive values, and abstract \npairs. P An abstract cache C of Cache is an abstract pro.le of all values which occur during a program \nrun. It tracks the abstract values of program subexpressions, di.erentiated by birthplace environment. \nAn abstract environment Env is a union of the en\u00ad . of Vvironments that occur during the evaluation of \na program. It associates a variable name and one of its birthplaces with an abstract value. 5.2 Acceptability \nfor Programs We de.ne an acceptability relation for programs |=: |= Cache \u00d7VBPEnv \u00d7Prg. . PEnv \u00d7 P The \n|= relation de.nes the validity of analyses (C ,. )with regard to a program p and a current birthplace \nenvironment bpe. From now on, the notation is (C ,. ) |= bpe p. 5.2.1 Value Expressions [c](C ,. ) |= \nbpe c l i. . .C (l, bpe) [quote](C ,. ) |= bpe (quote s)l i. s .C (l, bpe) [lam](C ,. ) |= bpe (lambda \n(x) e0)l i. (func (x) e0) .C (l, bpe) The [c], [quote], and[lam] clauses register their abstract counterpart \nin the abstract cache under the program point l and the current birthplace environment bpe.Note that \n[lam] does not require that the analysis is also valid for the body of each lambda term, because an acceptable \nanalysis must only treat the reachable functions correctly. 5.2.2 Expressions Occurrences of variable \nreferences and mutations induce further validity constraints. The [var] rule for variable ref\u00aderences \nenforces that the abstract value for the variable x and its current birthplace bpe(x), held in the abstract \nenvi\u00adronment, must be a subset of the abstract value that linked it to its label and birthplace environment \nin the abstract cache: [var](C ,. ) |= bpe x l i. . (x, bpe(x)) .C (l, bpe) The [setq] clause enforces \nthat the analysis for the right\u00adhand side is also valid. Moreover, a valid analysis allows values that \nresult from the subexpression t0 to be possible values for the variable x under the current bindings \nbpe and also for the whole expression: [setq](C ,. ) |= bpe (setq xtl0 )l 0 i. (C ,. ) |= bpe tl0 . 0 \n C(l0, bpe) .. (x, bpe(x)) . C (l0, bpe) .C (l, bpe) The [app] clause speci.es the constraints for procedure \ncalls. Its .rst and second condition, (C ,. ) |= bpe t l0 0 and (C ,. ) |=bpe t l1 , guarantee that the \nanalysis is also valid un\u00ad 1 der the same birthplace environment for the operator t0 and the operand \nt1: l0 l1 [app](C ,. ) |= bpe (t0 t1 )l i. (C ,. ) |= bpe tl0 . 0 (C ,. ) |= bpe tl1 . 1 (.(func (x1) \nt lb b ) .C (l0, bpe). (C ,. ) |= bpe0 t lb . b C(l1, bpe) .. (x1,lb) . C (lb, bpe0) .C (l, bpe) . where \nbpe0 = bpe[x1 .lb]) lb Every function (func (x1) tb ) which might occur in the operator position t0 of \na procedure call under bpe must have a valid analysis for its body as well, under an expanded birthplace \nenvironment bpe0 which contains a binding for the function parameter x1. Moreover, the analysis must \nlink the abstract values of the argument with those of the formal parameter x1 as well as the possible \nresults of the body with the those of the whole expression. The [let] clause works analogously to function \napplication: l1 l2 [let](C ,. ) |= bpe (let xtt)l 12 i. (C ,. ) |= bpe tl1 1 . (C ,. ) |= bpe0 t2 l2 \n. C(l1, bpe) .. (x, l2) . C (l2, bpe0) .C (l, bpe) where bpe0 = bpe[x .l2] In the [if] clause, each \nbranch contributes to a valid analysis: l0 l1 l2 [if](C ,. ) |=bpe (if t0 t1 t2 )l i. (C ,. ) |= bpe \ntl0 . 0 (C ,. ) |= bpe tl1 . 1 C (l1, bpe) .C (l, bpe) . (C ,. ) |=bpe t l2 2 . C (l2, bpe) .C (l, bpe) \n 5.2.3 Primitives Each primitive has its own associated .ow behavior. Pair construction and selection \nserve as examples. The [cons] rule for the pair constructor is straightforward: A cons produces an abstract \npair from abstract values with the labels of its arguments, under the original birthplace environment: \nl1 l2 [cons](C ,. ) |= bpe (cons tt)l 1 2 i. (C ,. ) |= bpe tl1 . 1 (C ,. ) |= bpe t l2 . 2 (l1,l2, bpe) \n.C (l, bpe) The [car]and [cdr] clauses are also straightforward: They induce validity constraints on \nthe argument, and then sim\u00adply pick the .rst or second component respectively of the abstract pairs .owing \ninto it: [car](C ,. ) |= bpe (car tl0 )l 0 i. (C ,. ) |= bpe tl0 . 0 (.(l1,l2, bpe0) .C (l0, bpe). C \n(l1, bpe0) .C (l, bpe)) [cdr](C ,. ) |= bpe (cdr tl0 )l 0 i. (C ,. ) |= bpe t0 l0 . (.(l1,l2, bpe0) .C \n(l0, bpe). C (l2, bpe0) .C (l, bpe)) 5.2.4 De\u00a3nitions The [defvar]and [defun] clauses extend the notion \nof valid scope analyses to entire programs. The [defvar]clause handles variable de.nitions: [defvar](C \n,. ) |= bpe (defvar xtl0 ) p 0 i. (C ,. ) |= bpe t l0 0 . C(l0, bpe) .. (x, bpe(x)) . (C ,. ) |= bpe \np A valid analysis must re.ect the value initially bound to the variable. It must also associate the \nvariable x with its ab\u00adstract values under the current binding bpe(x). Moreover, a valid analysis must \ntake into account the rest of the program p,too. The [defun] clause registers the procedure in the abstract \nenvironment. As in the [defvar] clause, the rest of the pro\u00adgram p must be valid as well. [defun](C ,. \n) |= bpe (defun x0 (x1) e) p i. (func (x1) e) .. (x0, o) . (C ,. ) |= bpe p 5.2.5 Values So far, the \nde.nition of the relation |= for all possible expressions and programs checks whether a certain analysis \nfor a program is valid or not. Now, the next goal is to show that valid analyses agree with the semantics \nthat is, that they are semantically correct. However, the reduction rules generate intermediate terms \nnot covered by the rules so far. Here they are: [const](C ,. ) |= bpe (prim c)l i. . .C (l, bpe) [sym](C \n,. ) |=bpe (sym s)l i. s .C (l, bpe) [proc](C ,. ) |= bpe (func (x) e0)l i. (func (x) e0) .C (l, bpe) \nThe [const], [sym], and [proc] clauses are identical to their equivalents [c], [quote], and [lam] because \ntheir semantics are identical. The [pair] clause is a simpler version of the [cons] clause. The only \ndi.erence is since a pair already carries two val\u00adues in it that it is unknown under which prior birthplace \nenvironment the evaluation took place. The only require\u00adment is that a suitable birthplace environment \nbpe0 exists: l1 l2 [pair](C ,. ) |= bpe (pair vv )l 1 2 i. .bpe0.(C ,. ) |= bpe0 v l1 . 1 (C ,. ) |= \nbpe0 v2 l2 . (l1,l2, bpe0) .C (l, bpe) 5.2.6 Intermediate Expressions The .nal clause in the de.nition \nof acceptability handles intermediate bind expressions. A bind expression binds a variable x to a value \nv1 during the evaluation of the body t2: [bind](C ,. ) |=bpe (bind xv1 t l2 )l 2 i. (C ,. ) |= bpe0 t2 \nl2 . C (l2, bpe0) .C (l, bpe) . v1 A( .(x, l2), C) where bpe0 = bpe[x .l2] The [bind] rule requires a \nvalid analysis for the body un\u00adder a suitably extended birthplace environment bpe0.More\u00adover, the value \nof the body becomes the value of the bind expression. The supplementary constraint v1 A( .(x, l2), C) \nre.ects that the actual new binding also has to show up in the abstract variable environment under the \nthe relevant birthplace l2;the Arelation is explained in the next section. 5.3 The Approximation Relation \nA Intuitively, the |= relation determines if a dynamic scope analysis (C ,. ) correctly re.ects the evaluation \nprocess of a program a in an abstract sense. The formulation of |=uses the approximation relation Athat \nregulates the approxima\u00ad tion of values Val with abstract equivalents. Here is its formal de.nition: \nA.Val \u00d7VCache Val \u00d7 P v A( v, C) i. .c .s .f .v1 .v2. ((v = c .. . v) . (v = s .s . v) . (v = f .f . \nv) . l1 l2 (v = (pair v1 v2 ) . .bpe. (l1,l2, bpe) . v . v1 A(C (l1, bpe), C ) . v2 A(C (l2, bpe), C \n))) A holds between a value v and its correct representation as a set of abstract values and an abstract \ncache. This is straightforward except for the treatment of pairs: The rep\u00adresentation of a pair consists \nof its components creation points and a birthplace environment. An abstract repre\u00adsentation however must \nalso map to abstract values for its components. Thisiswhy avalue cache C participates in the de.nition \nof A. 5.4 The Well-De\u00a3nedness of |= It is not immediately clear that the acceptability relation |= from \nSubsection 5.2 is unambiguous. Structural induction by itself is not su.cient because the [app]clauseisnot \ncompositional. On the other hand, the speci.cations of |=can be consid\u00adered as a functional P Q: P( PEnv \n\u00d7 Cache \u00d7 VBPEnv \u00d7Exp) . P( PEnv \u00d7BPEnv P\u00d7Exp)Cache \u00d7 V with l1 l2 (C , xt )l) .Q(R) i. ., bpe, (let \n1 t2 R(C , ., bpe,t1 l1 ) . R(C , ., bpe[x .l2],tl2 2 ) . C(l1, bpe) .. (x, l2) . C (l2, bpe[x .l2]) \n.C (l, bpe) (C , ... ., bpe,...) .Q(R) i. This change in perspective leads to a speci.cation of |=using \nsound mathematical means. Q is a monotone function on the complete lattice (P( PEnv \u00d7 P Cache \u00d7 VBPEnv \n\u00d7Exp), .) because (P( PEnv \u00d7 P Cache \u00d7 VBPEnv \u00d7Exp), .)isacom\u00adplete lattice with respect to the partial \norder R1 . R2 i. .t.t .R1 .t .R2,and Q is a monotone function on this complete lattice that is, .R1,R2.R1 \n.R2 .Q(R1) .Q(R2). Consequently, Q has a greatest .xed point. Thus, a well\u00adde.ned de.nition of |= works \nby coinduction as |=:= gfp(Q).  5.5 Acceptability for Environments Since dynamic scope analysis is ultimately \nconcerned with scope and hence with environments, it is necessary to extend the notion of acceptability \nto environments: P |= Cache \u00d7 VBPEnv \u00d7Env . PEnv \u00d7 (C ,. ) |= bpe . i. .x .dom(.)..(x) A( .(x, bpe(x)), \nC) This acceptability relation for environments examines ev\u00adery binding in an actual environment which \noccurs during evaluation and relates it to its abstract counterpart for cor\u00adrectness. 5.6 Acceptability \nfor Con\u00a3gurations The combination of the acceptability relation for programs with that for environments \nproduces an acceptability rela\u00adtion for con.gurations combinations of environments and expressions: |= \nCache \u00d7 VBPEnv \u00d7Conf . PEnv \u00d7 P (C ,. ) |= bpe ., e i. (C ,. ) |= bpe . . (C ,. ) |= bpe e Furthermore, \nit is possible to de.ne an acceptability relation for program con.gurations combinations of programs \nand environments: |= Cache \u00d7 VBPEnv \u00d7PConf . PEnv \u00d7 P (C ,. ) |= bpe ., p i. (C ,. ) |= bpe . . (C ,. \n) |= bpe p  6. SEMANTIC CORRECTNESS The semantics developed in Section 4 employs evaluation contexts \nand rewriting rules. Hence, the speci.cation of the semantics uses almost exclusively syntactical means \nwith the exception of the notion of environments: a program tran\u00adsitions through a sequence of con.gurations \nwhich include valid programs or expressions until it reaches a .nal value, gets stuck or loops forever. \nThe de.nition of the acceptability relation in the previ\u00adous section was derived intuitively. A correctness \nproof is necessary which must show that every valid analysis stays valid under the evaluation process. \nThis section summarizes the most import lemmas and theorems involved in the proof. For details, the reader \nis referred to Neubauer s thesis dissertation [21]. The .rst lemma states that a dynamic scope analysis \nis valid for a value if and only if the value is part of the abstract cache at its label and the given \nbpe: Lemma 1 (C ,. ) |= bpe v l i. v A(C (l, bpe), C) Proof. By structural induction over v. Another \nlemma states the obvious assumption, that if an abstract value v1 is a correct approximation of a true \nvalue v, it is also a correct approximation of another abstract value v2 which includes the former one: \n Lemma 2 If v A( v1, C) and also v1 . v2 then v A( v2, C). Proof. By structural induction over v.Each \ncase of the proof is obtained individually by inspecting the de.nition of A. The speci.cation of the \nacceptability relation has the im\u00adportant property stated by the following lemma: if an anal\u00adysis is \nvalid for a term t at label t1, and the abstract values .owing through it are all contained in the values \n.owing through label l2, the analysis is also valid at label l2: Lemma 3 If (C ,. ) |= bpe tl1 and C \n(l1, bpe) .C (l2, bpe) then also (C ,. ) |= bpe tl2 . Proof. by case analysis over the rules of Term.As \nan example, here is the case for setq expressions: From the .rst premise l0 l1 (C ,. ) |= bpe (setq xt0 \n) follows (C ,. ) |=bpe t l0 (1) 0 C(l0, bpe) .. (x, bpe(x)) (2) C (l0, bpe) .C (l1, bpe) (3) by the \n[setq]clauseof |=. The assumption together with (3) yields C (l0, bpe) .C (l2, bpe). (4) The backwards \napplication of the [setq] clause together with (1) and (2) yields the proposition. The other cases work \nanalogously. Another central insight is that the validity of the dynamic scope analysis of an expression \ncarries over those subexpres\u00adsions which are in an evaluation context. Even stronger, such a subexpression \ncan be replaced by another valid one without violating its validity. With this result, the further proof \nof the correctness of a reduction step can concen\u00adtrate on the possible redexes of all expressions; the \nfollowing lemma then allows us to generalize the result to the big pic\u00adture. This facility is known as \nreplacement lemma in the realm of combinatory logic [13]: l1 l1 Lemma 4 If (C ,. ) |=bpe E[t1 ] where \nE[t1 ] is carrying the label l, then there exists bpe0 such that a) (C ,. ) |= bpe0 tl1 holds. 1 l1 l1 \nb) If also (C ,. ) |= bpe0 tthen (C ,. ) |= bpe E[t]. 22 c) If also E.VarContext(x) then bpe0(x)= bpe(x). \nProof. Structural induction over E. The .rst main theorem is subject reduction for expressions under \nthe reduction relation .. A valid dynamic scope analysis for an expression e and a correct approximation \nof the environment stay valid after one step with . for the resulting expression e ' and the modi.ed \nenvironment: Theorem 1 If (C ,. ) |=bpe ., e and ., e . . ' ,e ' then also (C ,. ) |= bpe . ' ,e ' . \nProof. By case analysis over the reduction relation .. The second theorem formulates subject reduction \nfor entire programs, adapting the previous theorem one to the reduc\u00adtion relation .p: . '' Theorem 2 \nIf (C ,. ) |= bpe ., p and ., p .d ,p then also (C ,. ) |= bpe . ' ,p ' . Proof. By case analysis over \n.d.  7. IMPLEMENTATION The de.nition of the acceptability relation presented in Section 5.2 is a blueprint \nfor a practical implementation of a dynamic scope analysis. Our own analysis is constraint\u00adbased [1]; \nit uses a set of syntactic entities to represent appli\u00adcations of the rules generated by the acceptability \nrelation. The analysis, just like every other constraint-based program analysis, consists of two phases: \nconstraint generation and constraint simpli.cation. In the following we consider a .xed program p* and \nde\u00adscribe how to compute the least dynamic .ow analysis for p* which is acceptable with respect to the \nacceptability relation |=. Since the program p* is .nite, it is possible to enumerate all its occurring \nlabels, symbol, and functions. We call these .nite sets Lab*, SymVar* and Fun*, respectively. Simi\u00adlarly, \nthe sets of possibly occurring birthplace environments P BPEnv* and possibly occurring abstract pairs \nPare Cons* also identi.able and .nite. Accordingly, the .nite set of all abstract values that are conceivable \nfor all possible program runs of p* is a .Abs* = SymVar* Cons*. .{.}.Fun* .P The .nite sets serve as \nbasis for the speci.cation of the dy\u00adnamic scope analysis for a program p*. 7.1 Generating Constraints \nIn the constraints generated by the analysis, .ow vari\u00adables V stand for sets of abstract values. A .ow \nvariable Cl,bpe stands for the set of abstract values in the abstract cache at label l and birthplace \nenvironment bpe. A .ow variable rx,l stands for a set of abstract values in the ab\u00adstract environment. \nA constraint co in our analysis belongs to one of three di.erent kinds. A simple constraint of the form \n{a}.V, where a is an abstract value of Abs*, states that a certain abstract value a must be member of \nthe set of abstract values A.A variable constraint V0 .V1 says that the abstract values of V0 are all \ncontained in those of V1.A conditional constraint {a}.V =. co where a is an abstract value of Abs* and \nco is another constraint, states that the constraint co must hold if the abstract value a is a member \nof the set of abstract values denoted by V. By inspecting the rules of the acceptability relation, we \nde.ne the function G[p]bpe M that constructs the set of con\u00adstraints to be solved, as shown in Figure \n3. Its .rst pa\u00adrameter is the program or expression for which constraints are generated. The second one, \nbpe, is the birthplace envi\u00adronment, relative to which the generation of the constraints takes place. \nThe third parameter, M, is a set of pairs of a label of a body of a procedure lb and a birthplace envi\u00adronment \nbpe each. This set memoizes instances of pairs of procedures and birthplace environments already handled \nby the constraint generation. The analysis uses it to prevent generating duplicate constraints. G[c \nl]bpe M = {{.}.Cl,bpe} G[(quote s)l]bpe M = {{s}.Cl,bpe } G[(lambda (x) e0)l]bpe M = {{(func (x) e0)}.Cl,bpe \n} G[x l]bpe M = {rx,bpe(x) .Cl,bpe } l0 l0 G[(setq xt )l]bpe M = G[t ]bpe M .{Cl0,bpe .rx,bpe(x)} 00 \n .{Cl0,bpe .Cl,bpe} l0 l1 l0 l1 G[(tt)l]bpe M = G[t]bpe M .G[t]bpe M 01 01 .{{(func (x1) t lb )}.Cl0,bpe \n=. co b |(func t lb ) .Fun*,(x1) b bpe0 = bpe[x1 .lb], (lb,bpe0) .M, M ' = M.{(lb,bpe0)}, co .G[tblb \n]bpe0 M' } .{{(func (x1) t lb )}.Cl0,bpe =. Cl1,bpe .rx1,lb b |(func t lb ) .Fun*}(x1) b lb .{{(func \n(x1) t )}.Cl0,bpe =. Clb,bpe[x11. lb] .Cl,bpe b |(func (x1) t lb ) .Fun*} b l1 l2 l1 G[(let xt t )l]bpe \nM = G[t ]bpe M .G[t l2 ]bpe M 12 12 .{Cl1,bpe .rx,l2 } .l2] .Cl,bpe} l0 l1 l2 l0 l1 .{Cl2,bpe[x G[(if \nttt)l]bpe M = G[t]bpe M .G[t]bpe M} 012 01 .{Cl1,bpe .Cl,bpe}.G[t2 l2 ]bpe M} .{Cl2,bpe .Cl,bpe} l1 l2 \nl1 l2 G[(cons tt )l]bpe M = G[t ]bpe M .G[t ]bpe M 12 12 .{{(l1,l2,bpe)}.Cl,bpe } l0 l0 G[(car t)l]bpe \nM = G[t]bpe M .{{(l1,l2,bpe0)}.Cl0,bpe =. Cl1,bpe0 .Cl,bpe 00 |(l1,l2,bpe0) .Cons*} l0 )ll0 G[(cdr t]bpe \nM = G[t]bpe M .{{(l1,l2,bpe0)}.Cl0,bpe =. Cl2,bpe0 .Cl,bpe 00 |(l1,l2,bpe0) .Cons*} l0 l0 G[(defvar \nxt0 p)]bpe M = G[t0 ]bpe M .{Cl0,bpe .rx,bpe(x)} .G[p]bpe M G[(defun x0 (x1) e) p]bpe M = {{(func (x1) \ne)}.rx0,o}.G[p]bpe M Figure 3: Generating Constraints. The constraint generation rules in Figure 3 are \nmostly 7.2 Solving the Constraints straightforward translations of the corresponding rules of The generated \nset of constraints express the behavior of the acceptability relation. all valid dynamic scope analyses. \nTo get the least dynamic The most involved case is the treatment of procedure ap\u00ad scope analysis, we \nclose the generated constraints under the plications. In addition to the generation of constraints for \nfollowing inference rules S: the terms at the operator position and the parameter po\u00adsition, every procedure \n.owing into the operator triggers [VarProp] {a}.V0 V0 .V1 the generation of constraints for its body \nunder the current {a}.V1 birthplace environment via a conditional constraint. The treatment of the primitives \ncar and cdr worksina [CondProp] {a}.V {a}.V =. co similar way: we do not know, which abstract pairs could \nco occur at the operator position. Therefore, the anaylsis gen\u00aderates conditional constraints for all \nabstract pairs. and write S(CO) for the closure of a set of constraints CO The well-de.nedness and the \ntermination of the algorithm under S. follow by simple .x-point arguments on a underlying .nite The actual \ndynamic scope analysis results from the solv\u00adcomplete lattice. ing phase as all abstract values associated \nwith a variable G[p]bpe M as speci.ed generates a large number of condi-V after generating the initial \nconstraints and closing those tional constraints in the application and car and cdr rules, constraints \nunder S: many of which are never triggered during the constraint\u00ad dsa(p)(V)= {a|{a}.V .S(G[p]bpe0 \u00d8)} \n solving phase. Therefore, our implementation defers the generation of their right-hand sides until constraint \nsolv-where bpeo denotes the top-level birthplace environment. ing. It would have been possible to specify \nthe analysis this For our implementation, we employ the standard tech\u00ad way from the beginning, but this \nwould mean having to nique of using a graph representation for the constraint set mix the constraint-generation \nand constraint-solving phase, and apply a worklist algorithm on the graph to compute the which would \nobscure the presentation. least solution of the original constraints [2, 14, 32]. Package Lines Prims \nBps Dynamic Bps Iters Analysis Time (sec) mail-utils.el 355 51 63 0 4159 0.96 rfc822.el 378 48 56 1 89428 \n81.84 add-log.el 718 74 67 1 22284 8.32 pop3.el 839 67 169 5 93640 130.49 footnote.el 975 47 153 0 115930 \n73.86 Figure 4: Analyzed Emacs Lisp packages, their size in lines of code after macro expansion, the \nnumber of additionally used primitives, the number of birthplaces, the number of birthplaces recognized \nas dynamic binding, the number of iterations the worklist algorithm used, and the analysis time. The \nworklist algorithm always terminates. Every program induces only a .nite set of abstract values (Abs*)and \nthere is only a .nite number of potential nodes since there is only a .nite number of program points, \nvariables, and birthplace environments. Hence, the analysis propagates a .nite num\u00adber of data objects \nover a .nite number of nodes. The pro\u00adcess ends after a .nite number of steps: at the latest when every \ndatum has arrived at every node. The algorithm has exponential worst-case complexity with respect to \nthe size of the analyzed program: the number of all possible birthplace environments is already exponen\u00adtial. \nHowever, the next section shows that our prototype implementation is already practical for medium-sized \nreal\u00adworld examples. Also, since the translation of Emacs Lisp programs into a new substrate ideally \nhappens only once, speed is not quite as important as, say, in compilers which run often. Instead, precision \nis at a premium.  8. MEETING THE REAL WORLD Our prototype implementation of the algorithm is in about \n5500 lines of Scheme code and runs atop Scheme 48 [15], a byte-code implementation of Scheme. It handles \na large sub\u00adset of Emacs Lisp programs. Speci.cally, it correctly deals with a number of aspects of the \nlanguage not treated in this paper including the following: multi-parameter functions and optional arguments, \n catch and throw,  funcall and the duality between functions and their names, and  separation of function \nand value components of bind\u00adings.  In this section, we present the results of the analysis run on various \npackages taken directly from the XEmacs package collection. To receive accurate information from real \npack\u00adages, the implementation must know the .ow behavior of a substantial number of used XEmacs s primitives. \nThe implementation contains a small macro language to describe the .ow behavior of basic primitives for \nwhich no implementation in Emacs Lisp exists. Using those macros simpli.es the description of the primitives \ntremendously. For instance, the three lines (primitive-flow (FILENAME) ((const) (union (symbol t) (symbol \nnil)))) describes the constraint generation for the built-in primitive file-exists-p that checks for \nthe existence of a .le with a given name. Currently, the system emits an annotated version of the input \nprogram, marking those bindings which would have to stay dynamic under lexical binding. The binding-type \ncondition which we use to decide to which type a variable reference belongs, is the following: Binding-type \ncondition A variable is used dynamically i. the abstract cache registers some abstract object for the \nvariable under its label for a di.erent birthplace than the static one, that is i. x l0 with static birthplace \nl1 is dynamic i. .bpe.bpe(x)= l1 . C (l0, bpe)= \u00d8. Further conditions exist for our implementation to \nrecog\u00adnize Emacs Lisp letsusedinthe .avorofstatically scoped let* s or letrec s in Scheme. The results \nin this section were obtained by running the implementation under the Scheme system Scheme 48 0.53 on \nan Athlon 1 GHz system with 256 kByte second-level cache and 256 MByte of physical memory. We did not \nput any e.ort to highly optimize or to compile our implementation to native code; feasibility was our \nmain concern. Figure 4 lists the packages used for the experimental re\u00adsults. They are all part of the \nregular XEmacs distribu\u00adtion. Mail-utils contains utility functions used both by the other packages rmail \nand rnews. Rfc822 implements a parser for the standard internet messages. Pop3 provides POP3 functionality \nfor email clients. Add-log lets a pro\u00adgrammer manage .les of changes for programs. Footnote o.ers the \nfunctionality to add footnotes to XEmacs bu.ers. Figure 4 shows that the analysis is highly accurate: \nit only leaves behind a small number of dynamic binding constructs. 9. LIMITATIONS While the analysis \ndescribed here solves some of the hard\u00adest problems associated with translating Emacs Lisp pro\u00adgrams \nto readable Scheme programs, a few remain: eval Emacs Lisp has an eval function which interprets a piece \nof data as an Emacs Lisp expression. Its seman\u00adtics is naturally quite unde.ned in a Scheme environ\u00adment. \nExcept for simple cases (for example, where the expression to be evaluated is a symbol), there is no \nidiomatic translation for eval forms. Programmers must transform the Emacs Lisp code not to use eval \nbefore attempting translation. Dynamic generation of symbols as well as some introspection capabilities \nof the language also belong in this category. bu.er-local variables EmacsLispfeatures bu.er-local variables \nwhich implicitly change value according to the current bu.er. This an unfortunate con.ation of the language \nsemantics and the application domain, and often yields to unexpected and hard-to-track be\u00adhavior of Emacs \nLisp code. However, bu.er local\u00adity is usually a global property of variables programs rarely use the \nsame variable both bu.er-locally and bu.er-globally. Hence, a feasible approach is to trans\u00adlate bu.er-local \nvariables into special designated data structures and access them via special constructs rather than \npreserving their implicit nature. No special anal\u00adysis is required as long as the calls to make-variable\u00adbuffer-local \nare close to their variable declarations. Note that these kinds of problems are inherent in almost any \ntranslation from one programming language to another, if maintainability is to be preserved. 10. RELATED \nWORK 10.1 Dynamic Binding Despite the fact that languages with dynamic variable binding have existed \nfor a long time, formulations of se\u00admantics for these languages are quite rare. On the other hand, it \nis folklore that dynamic binding can be eliminated by a dynamic-environment passing translation that \nmakes the dynamic bindings explicit [24]. Gordon [9] initially formalized dynamic binding in the context \nof early Lisp dialects and studied their metacircular interpreters, using denotational semantics. Moreau \n[20] rounded up the view on dynamic binding by introducing a syntactic theory of dynamic binding with \na calculus allowing equational reasoning. From this theory, he also derived a small-step semantics using \nevaluation con\u00adtexts and syntactic rewriting as developed by Felleisen and Friedman [6]. Wright and Felleisen \n[30, 31] and Harper and Stone [11] formulated semantics for exception mechanisms which also employ a \nkind of dynamic binding. Lewis at al. [17] introduce a language feature called im\u00adplicit parameters that \nprovides dynamically scoped variables for languages with Hindley-Milner type systems, and formal\u00adize \nit with an axiomatic semantics. However, functions with implicit parameters are not .rst-class values \nin their setting. 10.2 Flow Analysis Most realistic implementations of .ow analysis for func\u00adtional programming \nlanguages are simple monovariant (or 0-CFA) .ow analyses [12, 7, 8, 26], that is, the analysis looks \nat every program point independent of context. Shivers [27] proposed the splitting of the analysis at \na function call sites depending on the context of the last recent k procedure calls (called k-CFA). Other \nsplittings, also de\u00adpending on procedure calls, were proposed by Jagannathan and Weeks [14] as poly-k-CFA \nand by Wright and Jagan\u00adnathan [32] as polymorphic splitting. The concept of coinduction arose from Milner \nand Tofte s works [18] on semantics and type systems of an extended .\u00adcalculus with references. Nielson \nand Nielson were the .rst to use coinduction as a means for specifying a static analysis [22]. Their \nwork provides the theoretical framework for the speci.cation of our analysis. 10.3 Subject reduction \nThe notion of correctness we used is generally called a sub\u00adject reduction result. Curry and Feys [5] \nintroduced subject reduction to show the correctness of predicates in the lan\u00adguages of combinatory logic. \nMitchell and Plotkin [19] used the idea to show a type correctness result for a .-calculus like language, \nwhereas Wright and Felleisen [30, 31] adapted it to the more .exible concept of operational semantics \nwith reduction rules and evaluation contexts. Wright and Jagan\u00adnathan [32] used the same technique for \ntheir polymorphic splitting .ow analysis. 10.4 Emacs Lisp and Scheme A number of other projects have \nbuilt or are currently building Scheme-based variants of Emacs. The oldest is Matt Birkholz s Emacs Lisp \ninterpreter which allows run\u00adning Emacs Lisp programs on top of MIT Scheme s Edwin editor. Current e.orts \ninclude Ken Raeburn s work on creat\u00ading a Guile-based Emacs [25], the Guile Emacs project [10] as well \nas Per Bothner s JEmacs [3, 4] which aims at re\u00adimplementing Emacs atop Java bytecodes, leveraging Both\u00adner \ns Kawa compiler for Scheme. As far as Emacs Lisp is concerned, only JEmacs seems to have seen signi.cant \nwork as far as making Emacs Lisp programs run. None of these projects address permanently translating \nEmacs Lisp code to Scheme while retaining maintainability. 11. CONCLUSION AND FUTURE WORK We have speci.ed, \nproved correct and implemented a .ow analysis for Emacs Lisp whose distinguishing feature is its correct \nhandling of dynamic binding. The primary purpose of the analysis is to aid translation of Emacs Lisp \nprograms into more modern language substrates with lexical scoping since most binding in real Emacs Lisp \nprograms behaves identically under lexical and dynamic scoping. Our analysis is highly accurate in practice. \nOur prototype implementa\u00adtion is reasonably e.cient. We have two main directions for future research: \n Improving the e.ciency of the analysis by ordinary optimization, compilation code and modularization \nof the constraints [8], and  integration of the analysis into a translation suite from Emacs Lisp to \nScheme.  Acknowledgments. We would like to thank the initial mem\u00adbers of the el2scm project: Martin \nGasbichler, Johannes Hirche, and Peter Biber. Speci.cally, Peter Biber devel\u00adoped a precursor to the \nanalysis presented here, demonstrat\u00ading the feasibility of the project. Peter Thiemann provided valuable \nsuggestions for the paper. We also thank the ICFP referees for valuable comments. 12. REFERENCES [1] \nA. Aiken. Set constraints: Results, applications and future directions. Lecture Notes in Computer Science, \n874:326 335, 1994. [2] A. Aiken and E. Wimmers. Type inclusion constraints and type inference. In Proceedings \nof the FPCA 1993, pages 31 41, 1993. [3] P. Bothner. JEmacs-the java/scheme-based emacs. In Proceedings \nof the FREENIX Track: 2000 USENIX Annual Technical Conference (FREENIX-00), pages 271 278, Berkeley, \nCA, June 18 23 2000. USENIX Ass. [4] P. Bothner. JEmacs the Java/Scheme-based Emacs text editor. http://jemacs.sourceforge.net/,Feb. \n2001. [5] H. B. Curry and R. Feys. Combinatory Logic, volume I. North-Holland, Amsterdam, 1958. [6] \nM. Felleisen and D. P. Friedman. Control operators, the SECD-machine, and the .-calculus. In M. Wirsing, \neditor, Formal Description of Programming Concepts III, pages 193 217. North-Holland, 1986. [7] C. Flanagan \nand M. Felleisen. Set-based analysis for full scheme and its use in soft-typing. Technical Report TR95-254, \nRice University, Oct., 1995. [8] C. Flanagan and M. Felleisen. Componential set-based analysis. ACM Transactions \non Programming Languages and Systems, 21(2):370 416, Mar. 1999. [9] M. J. C. Gordon. Programming Language \nTheory and its Implementation. Prentice-Hall, 1988. [10] Guile Emacs. http://gemacs.sourceforge.net/,July \n2000. [11] R. Harper and C. Stone. An interpretation of Standard ML in type theory. Technical Report \nCMU-CS-97-147, Carnegie Mellon University, Pittsburgh, PA, June 1997. (Also published as Fox Memorandum \nCMU-CS-FOX-97-01.). [12] N. Heintze. Set-based analysis of ML programs. In ACM Conference on Lisp and \nFunctional Programming, pages 306 317, 1994. [13] R. Hindley and J. Seldin. Introduction to Combinators \nand .-Calculus, volume 1 of London Mathematical Society Student Texts. Cambridge University Press, 1986. \n[14] S. Jagannathan and S. Weeks. A Uni.ed Treatment of Flow Analysis in Higher-Order Languages. In POPL, \n1995. [15] R. A. Kelsey and J. A. Rees. A tractable Scheme implementation. Lisp and Symbolic Computation, \n7(4):315 335, 1995. [16] B. Lewis, D. LaLiberte, R. Stallman, and the GNU Manual Group. GNU Emacs Lisp \nreference manual. http://www.gnu.org/manual/elisp-manual-20-2.5/ elisp.html, 1785. [17] J. Lewis, M. \nShields, E. Meijer, and J. Launchbury. Implicit parameters: Dynamic scoping with static types. In Proceedings \nof the 27th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, Boston, Massachusetts, \npages 108 118, Jan 2000. [18] R. Milner and M. Tofte. Co-induction in relational semantics. Theoretical \nComputer Science, 87:209 220, 1991. [19] J. C. Mitchell and G. D. Plotkin. Abstact types have existantial \ntype. In ACM Transcations on Programmin Languages and Systems, volume 10, pages 470 502, July 1988. [20] \nL. Moreau. A Syntactic Theory of Dynamic Binding. Higher-Order and Symbolic Computation, 11(3):233 279, \nDec. 1998. [21] M. Neubauer. Dynamic scope analysis for Emacs Lisp. Master s thesis, Eberhard-Karls-Universit\u00a8ubingen, \nat T\u00a8Dec. 2000. http://www.informatik.uni-freiburg. de/~neubauer/diplom.ps.gz. [22] F. Nielson and H. \nR. Nielson. In.nitary control .ow analysis: a collecting semantics for closure analysis. In Proc. POPL \n97, pages 332 345. ACM Press, 1997. [23] G. D. Plotkin. A structural approach to operational semantics. \nTechnical Report DAIMI FN-19, Computer Science Department, Aarhus University, Aarhus, Denmark, Sept. \n1981. [24] C. Queinnec. Lisp in Small Pieces. Cambridge University Press, 1996. [25] K. Raeburn. Guile-based \nEmacs. http://www.mit.edu/~raeburn/guilemacs/,July 1999. [26] M. Serrano and M. Feeley. Storage use analysis \nand its applications. In Proceedings of the 1fst International Conference on Functional Programming,page12, \nPhiladelphia, June 1996. [27] O. Shivers. Control-FlowAnalysis of Higher-Order Languages. PhD thesis, \nCarnegie-Mellon University, May 1991. [28] R. Stallman. GNU extension language plans. Usenet article, \nOct. 1994. [29] B. Wing. XEmacs Lisp Reference Manual. ftp://ftp.xemacs.org/pub/xemacs/docs/a4/ lispref-a4.pdf.gz, \nMay 1999. Version 3.4. [30] A. K. Wright and M. Felleisen. A syntactic approach to type soundness. Technical \nReport 91-160, Rice University, Apr. 1991. Final version in Information and Computation 115 (1), 1994, \n38 94. [31] A. K. Wright and M. Felleisen. A syntactic approach to type soundness. Information and Computation, \n115(1):38 94, 1994. Preliminary version in Rice TR 91-160. [32] A. K. Wright and S. Jagannathan. Polymorphic \nsplitting: an e.ective polyvariant .ow analysis. ACM Transactions on Programming Languages and Systems, \n20(1):166 207, Jan. 1998.  \n\t\t\t", "proc_id": "507635", "abstract": "It is possible to translate code written in Emacs Lisp or another Lisp dialect which uses dynamic scoping to a more modern programming language with lexical scoping while largely preserving structure and readability of the code. The biggest obstacle to such an idiomatic translation from Emacs Lisp is the translation of dynamic binding into suitable instances of lexical binding: Many binding constructs in real programs in fact exhibit identical behavior under both dynamic and lexical binding. An idiomatic translation needs to detect as many of these binding constructs as possible and convert them into lexical binding constructs in the target language to achieve readability and efficiency of the target code. The basic prerequisite for such an idiomatic translation is thus a dynamic scope analysis which associates variable occurrences with binding constructs. We present such an analysis. It is an application of the Nielson/Nielson framework for flow analysis to a semantics for dynamic binding akin to Moreau's. Its implementation handles a substantial portion of Emacs Lisp, has been applied to realistic Emacs Lisp code, and is highly accurate and reasonably efficient in practice.", "authors": [{"name": "Matthias Neubauer", "author_profile_id": "81100042558", "affiliation": "Univ. Freiburg", "person_id": "P343130", "email_address": "", "orcid_id": ""}, {"name": "Michael Sperber", "author_profile_id": "81100100127", "affiliation": "Univ. T&#252;bingen", "person_id": "PP14044834", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/507635.507642", "year": "2001", "article_id": "507642", "conference": "ICFP", "title": "Down with Emacs Lisp: dynamic scope analysis", "url": "http://dl.acm.org/citation.cfm?id=507642"}