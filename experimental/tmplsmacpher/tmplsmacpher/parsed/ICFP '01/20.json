{"article_publication_date": "10-01-2001", "fulltext": "\n A New Notation for Arrows Ross Paterson Department of Computing, City University, London ABSTRACT \nThe categorical notion of monad, used by Moggi to structure denotational descriptions, has proved to \nbe a powerful tool for structuring combinator libraries. Moreover, the monadic programming style provides \na convenient syntax for many kinds of computation, so that each library de.nes a new sublanguage. Recently, \nseveral workers have proposed a generalization of monads, called variously arrows or Freyd-categories. \nThe extra generality promises to increase the power, ex\u00adpressiveness and e.ciency of the embedded approach, \nbut does not mesh as well with the native abstraction and appli\u00adcation. De.nitions are typically given \nin a point-free style, which is useful for proving general properties, but can be awkward for programming \nspeci.c instances. In this paper we de.ne a simple extension to the functional language Haskell that \nmakes these new notions of computa\u00adtion more convenient to use. Our language is similar to the monadic \nstyle, and has similar reasoning properties. More\u00adover, it is extensible, in the sense that new combining \nforms can be de.ned as expressions in the host language. 1. INTRODUCTION A useful method for implementing \nof domain-speci.c lan\u00adguages (DSLs) is to embed them in a general-purpose lan\u00adguage. Functional languages \nare particularly suitable, as originally noted by Landin [19] and widely exploited since. Hudak [11] \ngives a recent account. Many of these libraries or sublanguages have a common structure; they involve \na monad, a categorical structure that Moggi applied to the structuring of denotational descrip\u00adtions \n[22] and Wadler subsequently applied to functional programming [30]. Much useful code can be written \nto the monad abstraction, and is thus useful with each such library. In the monad-based view of computation \n[22], we move from expressions yielding values of type Ato computations of type MA,where Mis a functor \nwith certain operations. A simple example of the monadic style of programming is Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 01, September 3 5, 2001, Florence, Italy. \nCopyright 2001 ACM 1-58113-415-0/01/0009 ...$5.00. the following Haskell [24] function that adds the \nresults of two computations: addM :: Monad m . mInt . mInt . mInt u addM v = u > = .x . v > = .y . return \n(x + y) Though the setting is more general, variables like x and y still denote values, and may be bound \nusing Haskell s .\u00adabstraction. A neat example of a monad-based library is provided by recursive-descent \nparsers [13]. One can write a set of mu\u00adtually recursive computations that closely mirror the origi\u00adnal \ngrammar, subject to the usual limitations of top-down parsing. However such parsers have a major .aw: \nthey are typically designed to backtrack on error, which is both ine.cient and makes useful error reporting \nvery di.cult. The deterministic parsing library designed by Swierstra and Duponcheel [28] solves these \nproblems, but steps beyond the world of monads. The reason is the same as the source of the e.ciency \nof this technique: the parser has a static component that is independent of the input, and this would \nbe lost in any de.nition of the > = combinator. Moreover, as they noted, this optimization technique \nis applicable in many other contexts, but the resulting libraries would not be monadic. Hughes [12] showed \nthat monads could be generalized to arrows relating inputs and outputs. Workers in denota\u00adtional semantics \nhave proposed similar frameworks [4, 26, 27]. Such arrows may represent procedures that have a static \ncomponent independent of the input, or other kinds of procedure that accept multiple inputs, as well \nas monadic computations. The added generality is useful, but comes at a cost: since procedures are no \nlonger functions, they cannot be manipulated using the abstraction and application fea\u00adtures of the underlying \nlanguage. One can use a point-free style resembling category theory, which is very convenient for proving \ngeneral properties, but can be awkward for pro\u00adgramming speci.c instances. The contribution of this paper \nis to de.ne a convenient notation for computation corresponding to these semantic notions, designed as \nan extension to the functional language Haskell [24]. Although arrows cannot in general be factored as \nfunctions, we are able to de.ne limited forms of applica\u00adtion and abstraction, as well as a notion of \ncontrol operator for combining arrow-based computations. We also extend a notion of feedback to arrows \nto support recursion. The new constructs are de.ned by translation to standard Haskell. The rest of the \npaper is organized as follows. In the next arr id \u00bb f = f f \u00bb arr id = f (f \u00bb g) \u00bb h = f \u00bb (g \u00bb h) arr \n(g \u00b7 f )= arr f \u00bb arr g .rst (arr f )= arr (f \u00d7 id) .rst (f \u00bb g)= .rst f \u00bb .rst g .rst f \u00bb arr (id \u00d7 \ng)= arr (id \u00d7 g) \u00bb .rst f .rst f \u00bb arr fst = arr fst \u00bb f .rst (.rst f ) \u00bb arr assoc = arr assoc \u00bb .rst \nf Figure 1: Arrow equations section we brie.y review Hughes s arrows. Section 3 presents our proposed \nextension to Haskell, illustrated using an ex\u00adample from [12]. A larger example, an embedded language \nfor regular data parallel algorithms, is described in Section 4. In Section 5 we consider how arrows \nmay be extended to al\u00adlow recursive de.nition of values, and similarly extend our syntax. This extension \nis applied in our .nal example, an embedded language for circuit description, in Section 6. Although \nour focus is on programming, many of the con\u00adcepts here are inspired by category theory. Short discussions \nof the connections are given in subsections entitled Theoret\u00adical Aside. These maybeusefultoreaders with \ntheappro\u00adpriate theoretical background, but they are not essential to the main development. The extension \nto Haskell described here has been imple\u00admented by a preprocessor that produces Haskell 98. The preprocessor \nis itself written in Haskell 98, as an extension of a Haskell parser and pretty printer written by Sven \nPanne, Simon Marlow and Keith Wansborough. This paper was for\u00admatted from a literate script which has \nalso been fed to the preprocessor, and thence to Haskell implementations. 2. ARROWS We brie.y recall \nHughes s de.nitions from [12]. De.nition 1. An arrow type is a binary type constructor a with the following \ndata: class Arrow a where arr :: (b . c) . abc (\u00bb):: abc . acd . abd .rst :: abc . a (b, d)(c, d) satisfying \nthe equations of Figure 1. The functions (\u00d7)and assoc used there are de.ned as follows: (\u00d7)::(a . a ) \n. (b . b) . (a, b) . (a . , b) (f \u00d7 g)(a, b)=(fa, gb) assoc :: ((a, b), c) . (a, (b, c)) assoc ((a, b), \nc)=(a, (b, c)) There is no need to require a second function, as it is de.ned in terms of .rst: second \n:: Arrow a . abc . a (d, b)(d, c) second f = arr swap \u00bb .rst f \u00bb arr swap swap :: (a, b) . (b, a) swap \n(x, y)=(y, x) The following de.nitions will also be useful: (* ):: Arrow a . abc . ab. c . . a (b, b)(c, \nc ) f * g = .rst f \u00bb second g (&#38;&#38;&#38;) :: Arrow a . abc . abc. . ab (c, c ) f &#38; g = arr \n(.b . (b, b)) \u00bb f * g Note that * does not in general preserve composition; for example, the order in \nwhich e.ects occur is signi.cant. Ordinary functions are a special case instance Arrow (.) where arr \nf = f f \u00bb g = g \u00b7 f .rst f = f \u00d7 id The Kleisli arrows of a monad may also be cast as an arrow type. \nnewtype Kleisli m a b = K (a . mb) instance Monad m . Arrow (Kleisli m) where arr f = K (return \u00b7 f ) \nKf \u00bb Kg = K (.b . fb > = g) .rst (Kf )= K (.(b, d) . fb > = .c . return (c, d)) However, there are other \nimportant examples, as we shall see later. Some arrow types have additional constants. Hughes gave a \nclass specifying an application operator class Arrow a . ArrowApply a where app :: a (abc, b) c which \nis required to satisfy certain conditions [12]. The triv\u00adial arrow type . and Kleisli arrow types satisfy \nthese con\u00additions, and indeed any such arrow type is equivalent to a Kleisli arrow type [12, 27]. Hughes \nalso de.ned structures on sum types dualizing those on product types: class Arrow a . ArrowChoice a where \nleft :: abc . a (Either b d)(Either c d) right :: ArrowChoice a . abc . a (Either d b)(Either d c) right \nf = arr mirror \u00bb left f \u00bb arr mirror where mirror (Left x )= Right x mirror (Right y)= Left y (+++) :: \nArrowChoice a . abc . ab. c . . a (Either b b)(Either c c) f +++ g = left f \u00bb right g (|||):: ArrowChoice \na . abd . acd . a (Either b c) d f ||| g = f +++ g \u00bb arr untag where untag (Left x )= x untag (Right \ny)= y As an illustration of the programming style used with ar\u00adrows, here is an arrow operation corresponding \nto addM from the previous section: addA :: Arrow a . ab Int . ab Int . ab Int addAf g = f &#38; g \u00bb arr \n(.(x, y) . x + y) 2.1 Theoretical Aside Similar structures have been independently proposed by workers \nin denotational semantics. We give here a simpli\u00ad.ed (but equivalent) version of a de.nition of Power \nand Thielecke [27]. De.nition 2. A Freyd-category consists of a category Vwith .nite products (the value \ncategory),  a category C with the same objects as V (the compu\u00adtation category),  a functor inc : V.Cthat \nis the identity on objects,  a functor K : C\u00d7V.Csuch that inc xK y = inc (x\u00d7y)  and the following \nnatural isomorphisms in V assoc\u00d7 :(A\u00d7B) \u00d7C ~ = A\u00d7(B\u00d7C) unitr\u00d7 := A A\u00d71 ~ extend to natural isomorphisms \nin C: inc assoc\u00d7 :(AK B) K C ~ = AK (B\u00d7C) inc unitr\u00d7 := A AK 1 ~ The .rst four of Hughes s axioms correspond \nto the re\u00adquirements of a category Cand an object-preserving functor inc (corresponding to arr). Hughes \ns .rst corresponds to the family of functors -K C for each object C, with the last two of his axioms \ncorresponding to the naturality requirements above. In this form, the de.nition is easily generalized \nto any symmetric monoidal category. Nor is the assumption of symmetry required; one merely assumes two \nbifunctors and additional axioms, obtaining what Power and Robinson call a notion of computation [26]. \nEven more general structures have been explored by Blute, Cockett and Seely [4]. Hughes [12] showed that \nthe stream processors of the Fud\u00adgets library [5] comprised an arrow type, but were more often used as \na dual arrow type. In Power and Robinson s terms, stream processors comprise a notion of computation \nwhere the underlying monoidal structure is that of sums rather than products. A Freyd-category is said \nto be closed [27] if each functor inc -K A : V.C has a right adjoint; this is equivalent to Hughes s \nArrowApply class. 2.2 Deterministic Parsing Hughes showed how Swierstra and Duponcheel s parser li\u00adbrary \nmay be recast using an arrow type, say ParseArrow, with composition corresponding to grammatical concatena\u00adtion. \nFor the empty language and union, we use the classes class Arrow a .ArrowZero a where zeroArrow :: abc \n class ArrowZero a .ArrowPlus a where (<+>):: abc .abc .abc which make sense for many kinds of arrow. \nAn extra prim\u00aditive is supplied for terminal symbols. symbol :: Sym .ParseArrow () () data Expr = Plus \nExpr Expr |Minus Expr Expr |\u00b7\u00b7\u00b7 expr :: ParseArrow () Expr expr = term \u00bb exprTail exprTail :: ParseArrow \nExpr Expr exprTail =( arr (.e .(e,())) \u00bb second (symbol PLUS) \u00bb second term \u00bb arr (.(e,t) .Plus e t) \n\u00bb exprTail ) <+> ( arr (.e .(e,())) \u00bb second (symbol MINUS) \u00bb second term \u00bb arr (.(e,t) .Minus e t) \u00bb \nexprTail ) <+> arr id term :: ParseArrow () Expr term = ... Figure 2: Expression parser using arrows \nNow we can write parsers using arrow combinators. For example, the parser in Figure 2 expresses the common \nex\u00ad ample grammar expr ::= term exprTail exprTail ::= PLUS term exprTail || MINUS term exprTail E In \nthis program the underlying grammar is obscured by all the plumbing required to pass the results of earlier \ncomputa\u00adtions past later ones. (Indeed this is the reason for requiring .rst in the arrow de.nition.) \nThis point-free style is typical of arrow-based programs. While convenient when de.ning general combinators \nand laws, it can be very cumbersome for speci.c de.nitions.  3. ARROW-BASED SUBLANGUAGES We propose \nto address this problem by de.ning an ex\u00adtension to Haskell, with the meaning of new forms given by translation \nrules from the new expressions back into Haskell. This will be done in two stages. Firstly we de.ne a \nsyntax for arrow expressions, which will enable us to write programs re\u00adsembling the raw monadic syntax \n(using > =and > ). Then on top of this we will de.ne an analogue of Haskell s do\u00adnotation. The new syntax \nfor arrow expressions, with associated translation rules, is given in Figure 3. An arrow expression is \nde.ned by a new binding operator proc. The body of such an expression is a new form, which we call a \ncommand. 3.1 Arrow Application The simplest kind of command is the arrow application e1 -. e2,where e2 \nis a Haskell expression to be input to the arrow described by the Haskell expression e1.As noted above, \nthere is in general no notion of application of arrows, Syntax exp ::= ... | proc pat . cmd cmd ::= exp \n-. exp |||| form exp cmd1 ...cmdn cmd1 op cmd2 .pat . cmd (cmd) Translation rules . . arr (.p . e2) \n\u00bb e1 proc p . e1 -. e2 = . . . . . if Vars(p) n Vars(e1)= \u00d8 arr (.p . (e1,e2)) \u00bb app otherwise proc \np . form ec1 ...cn = e (proc p . c1) ...(proc p . cn) proc p . c1 op c2 = proc p . form (op) c1 c2 proc \np . .p . . c = proc (p,p ) . c Figure 3: Arrow expressions but the rule allows two useful special cases. \nThe .rst is proc p . e1 -. e2 = arr (.p . e2) \u00bb e1 Clearly this is meaningful only if e1 contains no \nvariables de.ned in p. A simple example of an expression for e1 is the identity arrow returnA :: Arrow \na . abb returnA = arr id Then we have proc p . returnA -. e = arr (.p . e) This arrow returnA will play \na role analogous to return in monad notation. The second translation is proc p . e1 -. e2 = arr (.p . \n(e1,e2)) \u00bb app This version has no such syntactic restriction, but it does require that the arrow in \nuse belong to the class ArrowApply, and thus be equivalent to a monad. Thus both rules are needed. The \nrules overlap, but from the axioms of app it is possible to show that in that case they produce equivalent \ntranslations. Hence we must distinguish two kinds of variables: local variables de.ned in the current \narrow expression. external variables de.ned outside. In this paper we shall focus on arrows that are \nnot equiv\u00adalent to monads, so we shall use only the .rst form of arrow application. Nevertheless, the \nnotation may be used with a variety of arrows, some of which are equivalent to monads. 3.2 Control Operators \nNext we need a means to combine commands to make new ones. In the monad setting, we have operators like \nmplus :: MonadPlus m . ma . ma . ma This works well, because in an expression like e1 mplus e2 the two \nexpressions may take inputs from environment vari\u00adables bound in ordinary ways. However, we cannot in \ngen\u00aderal factor an arrow type as a function from inputs, so an arrow combinator must route the inputs \nof the composite ex\u00adpression to each of the arguments. Hence the corresponding arrow operator has the \nsignature (<+>):: ArrowPlus a . abc . abc . abc In the arrow notation, a command describes an arrow from \nthe local environment. We can use operators to combine commands by combining the resulting arrows, so \nfor example we have proc p . c1 <+>c2 =(proc p . c1) <+>(proc p . c2) In general an operator may be an \narbitrarily complex Haskell expression meeting certain conditions (to be given below). The syntax requires \na keyword form to distinguish these from commands. However in the special case of in.x oper\u00adatorswecan \nuseanabbreviatedsyntaxasabove. Parameter Passing. Some operators pass data to their ar\u00adguments. For example, \nthe monadic operator for exception handling has the form handle :: MonadHandle ex m . ma . (ex . ma) \n. ma If the second argument (the handler) is called, it is passed the exception raised. The arrow form \nwill also have two arguments. Each will be passed the input, with the second also being given the exception: \nhandleA :: ArrowHandle ex a . abc . a (b,ex) c . abc We shall adopt the convention of adding argument \ndata by pairing in this way. In general the input of an arrow will have the form ((...(v,v1),...),vn) \nwhere v is the original input, named by the proc pattern p,and the vi are additional arguments, as yet \nunnamed. The next form, the . quanti.er, applies another pattern to the innermost argument v1 within \na sub-command. A similar quanti.er occurs in the abstract machine framework of Douence and Fradet [7], \ntransferring a value from the argument stack to the environment. Thus we can write a command like c1 \nhandleA .ex . c2 This may be read just like the corresponding monadic form: the body c1 is executed, \nand if it raises an exception then the handler c2 is called, with ex bound to the exception raised. However, \nthe arrow version of the operator passes the original environment to both commands, as we can see from \nthe translation: proc p . c1 handleA .ex . c2 =(proc p . c1) handleA (proc p . .ex . c2) =(proc p . c1) \nhandleA (proc (p,ex) . c2) An operator may also accept an argument from its caller in a similar way, \nas in the following operator to encapsulate state-transforming arrows: runWithState :: ... . abc . a \n. (b,s) c Naturality. We stated above that an operator delivers in\u00adputs of the composite arrow to its \ncomponents. We can formalize this with a naturality condition for each opera\u00adtor. For example, the handleA \noperator will be required to satisfy arr k \u00bb (f handleA g)= (arr k \u00bb f ) handleA (arr (k \u00d7id) \u00bb g) This \nensures that inputs delivered by the operator to f or g were inputs to the whole expression. In general, \nan input to the whole expression need not be delivered to each argu\u00adment; in the above example g is called \nonly if an exception occurs in f . But any input that is delivered must have been an input to the whole \narrow. In the special case of a Kleisli arrow of a monad m,this naturality condition ensures that the \noperator is equivalent to a monadic operator. In this case, the type of handleA is equivalent to (b .mc) \n.((b,ex) .mc) .b .mc Currying the second argument gives the type (b .mc) .(b .ex .mc) .b .mc Since this \nis natural in b (and the Kleisli arrows factor as functions) it is equivalent to the type of the corresponding \nmonad operator mc .(ex .mc) .mc Many monadic operators have similar generalizations in the arrow setting. \nFormal De.nition of a Control Operator. In order to specify which Haskell expressions may serve as control \nop\u00aderators, we need a preliminary de.nition: De.nition 3. Let t stand for a Haskell value type. We introduce \na new sort of types Command types . ::= a\\t | t.. For each Haskell type t and command type ., we de.ne \na Haskell type t . . as follows t . a\\t. = att. t . (t. ..)=(t,t) . . If k :: t1 .t2, we can de.ne a \nfunction k . . :: (t2 . .) . (t1 . .)by k . a\\t =(arr k \u00bb) k . (t..)=(k \u00d7id) . . De.nition 4. A Haskell \nexpression e is a control operator of signature .1 .\u00b7\u00b7\u00b7.n .. if 1. No local variables occur free in e, \n 2. e has type .b. (b. .1) .\u00b7\u00b7\u00b7(b . .n) .(b. .) where b does not occur free in any of the .s, and 3. \ne satis.es a corresponding naturality property  e ((k . .1) x1) ... ((k . .n) xn)= (k . .)(ex1 ... xn) \nexpr :: ParseArrow () Expr expr = proc () . (term -.()) bind .t . exprTail -.t exprTail :: ParseArrow \nExpr Expr exprTail = proc e .( (symbol PLUS -.()) bind (term -.()) bind .t . exprTail -.Plus e t ) <+> \n( (symbol MINUS -.()) bind (term -.()) bind .t . exprTail -.Minus e t ) <+> (returnA -.e) Figure 4: \nExpression parser in arrow notation The .rst two conditions would be checked by the imple\u00admentation. \nIt may be that the naturality property can be obtained automatically from parametricity results. For \nexample, the control operator handleA has signature a\\c .(ex .a\\c) .a\\c. Examples. Some functions we \nhave already seen are also examples of control operators: (&#38;&#38;&#38;) :: Arrow a .abc .abd .ab \n(c,d) (<+>):: ArrowPlus a .abc .abc .abc zeroArrow :: ArrowZero a .abc Others may be de.ned using the \nfeatures of Haskell. For example, the arrow counterpart of the monadic binding op\u00aderator > = may be de.ned \nas bind :: Arrow a .abc .a (b,c) d .abd u bind f = arr id &#38; u \u00bb f Using this operator, we can rede.ne \naddA (which is also an operator): addA :: Arrow a .ab Int .ab Int .ab Int addAf g = proc z . (f -.z) \nbind .x . (g -.z) bind .y . returnA -.x + y Another useful operator is the special case of bind where \nthe result of the .rst computation is ignored, corresponding to the monadic > combinator: bind :: Arrow \na .abc .abd .abd u bind v = u bind (arr fst \u00bb v) Now we can rewrite the arrow parser of Figure 2, obtaining \nthe version of Figure 4. As promised, the form of this pro\u00adgram is very similar to what we would write \nwith monadic parser combinators [13]. The point is that this program works not merely for monadic parsers \nbut also for any parser that can be cast in the more general arrow form, including the optimized ones \nof Swierstra and Duponcheel [28]. All the plumbing of the previous version is hidden. 3.3 Theoretical \nAside Power and Thielecke [27] showed that each Freyd-category is equivalent to a kind of indexed category \ncalled a .-category. Each category HA models computations in a context A,and has the same objects as \nC, with morphism sets HA(B, C)= C(A \u00d7B, C) Our command sublanguage could be viewed as a language for \nsuch indexed categories, with A corresponding to the in\u00adput context and B to additional arguments. The \n. quanti.er then corresponds to the obvious isomorphism HA(B \u00d7C, D) ~= HA\u00d7B (C, D) as in Hasegawa s .-calculus \n[9]. A control operator de.nes a natural family of functions, one for each category HA.These generalize \nthe controls of elementary control structures [25], which are used to model concurrency. Our de.nition \nsug\u00adgests a higher-order generalization, although such operators appear to be less useful. 3.4 Type-checking \nof Commands One could use the equations of Figure 3 to transform any arrow expression into ordinary Haskell, \nwhere it will be type\u00adchecked, but it would obviously be easier for users to deal with a type system \nfor the command sublanguage. There is not room here for a formal treatment, not least because there is \nno complete de.nition of Haskell s type system to refer to, but the basic ideas are simple. Each command \nis assigned a command type as follows: If e1 :: at t . and e2 :: t,then e1 -.e2 has type a\\t. .  If \nc has type . assuming p :: t ,then . p .c has type t...  If each ci has type .i and e is a control operator \nof signature .1 . \u00b7\u00b7\u00b7.n . .,then form ec1 ... cn has type ..  Syntax cmd ::= ... | do {stmt1; ...stmtn; \ncmd } stmt ::= cmd || pat .cmd rec {stmt1; ...; stmtn } Translation rules do {c }= c do {p .c; A}= c \nbind . p .do {A} do {c; A}= c bind do {A} do {rec A; B } (see Section 5.3) Figure 5: do-notation for \narrows expr :: ParseArrow () Expr expr = proc () .do t .term -.() exprTail -.t exprTail :: ParseArrow \nExpr Expr exprTail = proc e .do symbol PLUS -.() t .term -.() exprTail -.Plus e t <+> do symbol MINUS \n-.() t .term -.() exprTail -.Minus e t <+> do returnA -.e Figure 6: Expression parser using do-notation \nIt follows (by induction on c)thatif c has type . assuming p :: t ,then proc p .c :: t . .,and ((.p . \n.e) . .)(proc p .c)= proc p . .[e/p]c This equation expresses the naturality of commands with respect \nto the environment, allowing us to change the rep\u00adresentation of the environment, for example to improve \ne.\u00adciency. We shall return to this point in Section 3.7. 3.5 Equivalences It is also useful to reason \ndirectly with commands. De.nition 5. We write c1 =p c2 for proc p .c1 = proc p .c2 and c1 =c2 to mean \nc1 =p c2 for all legal p. Then we have the following equivalences for returnA and bind, corresponding \nto the familiar monad laws: (returnA -.e) bind . x .c = [e/x]c c bind . x .returnA -.x = c c1 bind . \nx1 .(c2 bind . x2 .c3) = (c1 bind . x1 .c2) bind . x2 .c3 An arrow library would typically supply a collection \nof ar\u00adrows and operators with associated laws, ideally expressed as equivalences between commands. 3.6 \ndo-notation for Arrows We can take the correspondence further, by de.ning a do-notation for commands \nin a similar fashion to Haskell s monadic do-notation. The syntax and translation rules are given in \nFigure 5. The rec construct, which allows recursive bindings, will be discussed in Section 5.3. Then \nthe above operator addA could be rewritten as addA :: Arrow a .ab Int .ab Int .ab Int addAf g = proc \nz .do x .f -.z y .g -.z returnA -.x + y Similarly, the parser example of Figures 2 and 4 may be rewritten \nas in Figure 6, which is similar to the monadic version, though it works for a wider variety of parsers. \n 3.7 Improving the Translation The rules of Figures 3 and 5 de.ne the meaning of the new constructs in \nclear way, but may produce less e.cient pro\u00adgrams than one might have written by hand. For example, the \narrow addA above would be translated to addAf g = arr id &#38; f \u00bb arr id &#38; &#38;(arr (.(z , x) .z) \n\u00bb g) \u00bb arr (.((z, x), y) .x + y) Note that both the original input z and the .rst result x are held during \nthe computation of g, even though z is not required. We can project out z when it is no longer needed, \nobtaining the improved version addAf g = arr id &#38; f \u00bb arr (.(z,x) .(x,z)) \u00bb second g \u00bb arr (.(x,y) \n.x + y) which is essentially equivalent to what we would write by hand. These projections may also be \nmoved through oper\u00adators, thanks to their naturality property. The prototype implementation incorporates \nmany such improvements.  4. EXAMPLE: DATA PARALLELISM S . bS For each set S,the type a de.nes an arrow. \nSuch arrows may be used to model data parallel computation; here S represents the set of processors, \nand the arr oper\u00adation executes the same function on each processor. Addi\u00adtional combinators will be \nrequired for the various opera\u00adtions supported by a particular model. Here we shall focus on a special \ncase: algorithms operat\u00ading on 2n elements, whose behaviour is de.ned by induction on n. These arise \nin circuit design (cf. Ruby [15]), and de\u00adscriptions of parallel algorithms (cf. Misra s powerlists [21]). \nThe objects of interest then consist of in.nite sequences of functions on arrays of increasing size 8 \n 2n 2n a .b n=0 We can model a 2n as Pairn a,where type Pair a =(a,a) Thus the elements are organized \nas a perfectly balanced bi\u00adnary tree of depth n, and we are interested in functions that preserve this \ndepth. We call them homogeneous functions and model them with the following Haskell datatype: data Hom \na b =(a .b) :&#38;: Hom (Pair a)(Pair b) Elements of this type have the form f0 :&#38;: f1 :&#38;: f2 \n:&#38;: ... where fn :: Pairn a .Pairn b. Before writing programs with this datatype, we need a framework \nfor executing them. We will de.ne a type for perfectly balanced binary trees: data BalTree a = Zero a \n|Succ (BalTree (Pair a)) deriving Show Here are some example elements: tree0 = Zero 1 tree1 = Succ (Zero \n(1,2)) tree2 = Succ (Succ (Zero ((1,2),(3,4)))) tree3 = Succ (Succ (Succ (Zero (((1,2),(3,4)), ((5,6),(7,8)))))) \nThe elements of this type have a string of constructors ex\u00adpressing a depth n as a Peano numeral, enclosing \na nested pair tree of 2n elements. The following function applies a homogeneous function to a perfectly \nbalanced tree, yielding another perfectly bal\u00adanced tree of the same depth: apply :: Hom a b .BalTree \na .BalTree b apply (f :&#38;: fs)(Zero x)= Zero (fx) apply (f :&#38;: fs)(Succ t)= Succ (apply fs t) \nFew other operations can be expressed in terms of the bal\u00adanced tree type. Typically one wants to split \na tree into two subtrees, do some processing on the subtrees and combine the results. But the type system \ncannot discover that the two results are of the same depth (and thus combinable). Of course, this is \nexactly what homogeneous functions can do, so we shall focus on them; the balanced tree type is used \nonly for test runs of our algorithms. Firstly, Hom is an arrow: instance Arrow Hom where arr f = f :&#38;: \narr (f \u00d7f ) (f :&#38;: fs) \u00bb (g :&#38;: gs)=(g \u00b7f ) :&#38;:(fs \u00bb gs) .rst (f :&#38;: fs)= .rst f :&#38;: \n(arr transpose \u00bb .rst fs \u00bb arr transpose) transpose :: ((a,b),(c,d)) .((a,c),(b,d)) transpose ((a,b),(c,d)) \n= ((a,c),(b,d)) The function arr maps a function over the leaves of the tree. The composition \u00bb composes \nsequences of functions pairwise. The * operator unri.es a tree of pairs (a,b)into atreeof asand atreeof \nbs, applies the appropriate function to each tree and ri.es the results. When describing algorithms, \none often provides a pure function for the base case (trees of one element) and a ex\u00adpression for trees \nof pairs, usually invoking the same algo\u00adrithm on smaller trees. Parallel Pre.x. This operation (also \ncalled scan)mapsthe sequence x0,x1,x2,...,x2n-1 to the sequence x0,x0 .x1,x0 .x1 .x2,...,x0 .x1 .\u00b7\u00b7\u00b7.x2n-1 \nfor some associative operation .. If there is only one element (i.e. the tree has zero depth) then obviously \nthe scan should be the identity function. Otherwise, we need to deal with a tree of pairs, so the gen\u00aderal \nscan operation will have the form scan :: (a .a .a) .a .Hom a a scan (.) b = id :&#38;: proc (x,y) .... \nwhere b is the identity of the .operation1 . The missing part will be de.ned using recursive calls of \nscan, but operating on smaller trees. An e.cient scheme, devised by Ladner and Fischer [18], is .rst \nto sum the elements pairwise: x0 .x1,x2 .x3,x4 .x5,... and then to compute the scan of this list (which \nis half the length of the original), yielding x0 .x1,x0 .x1 .x2 .x3,x0 .x1 .x2 .x3 .x4 .x5,... This listishalfofthe \ndesiredanswer; theother elements are x0,x0 .x1 .x2,x0 .x1 .x2 .x3 .x4,... 1It is possible to do without \nthe identity, at the cost of slightly complicating the code. which can be obtained by shifting our partial \nanswer one place to the right and adding x0,x2,x4,....We can express this idea directly in our notation: \nscan :: (a .a .a) .a .Hom a a scan (.) b = id :&#38;: proc (x,y) .do y . .scan (.) b -.x .y yl .rsh b \n-.y . returnA -.(yl .x,y ) The auxiliary arrow rsh b shifts each element in the tree one place to the \nright, placing b in the now-vacant leftmost position, and discarding the old rightmost element. This \ncould be supplied as a primitive, but it is also possible to code it directly: rsh :: a .Hom a a rsh \nb = const b :&#38;: proc (x,y) .do yl .rsh b -.y returnA -.(yl,x) Butter.y Circuits. In many divide-and-conquer \nschemes, one recursive call processes the odd-numbered elements and the other processes the even ones \n[14]: butter.y :: (Pair a .Pair a) .Hom a a butter.y f = id :&#38;: proc (x,y) .do x . .butter.y f -.x \ny . .butter.y f -.y returnA -.f (x . ,y ) The recursive calls operate on halves of the original tree, \nso the recursion is well-de.ned. (The Fast Fourier Transform has a similar structure.) Some examples \nof butter.ies: rev :: Hom a a rev = butter.y swap unri.e :: Hom (Pair a)(Pair a) unri.e = butter.y transpose \nBatcher s ingenious sorter for bitonic sequences [1] is another example of a butter.y circuit: bisort \n:: Ord a .Hom a a bisort = butter.y cmp where cmp (x,y)=(min x y,maxxy) This canbeused(with rev) as the \nmerge phase of a sorting function.  5. RECURSION Since arrows are Haskell values, they may be recursively \nde.ned in the usual way, as we have seen. A di.erent kind of recursion involves recursive de.nition of \nvalues within a computation, where an output is used as an input. To ex\u00adpress this, we will de.ne a feedback \noperator on arrows, though not all arrows will have such an operator. We ex\u00adpect that it would generalize \nthe .xed point operator on monads, which has signature class Monad m .MonadFix m where m.x :: (a .ma) \n.ma An axiomatization of this operator is given by Erk\u00a8ok and Launchbury [8]. Not all monads have such \nan operator, but several important ones do, including state transformers, readers, writers and Haskell \ns built-in monads ST and IO. The straightforward generalization of m.x would be the class class Arrow \na .ArrowFix a where .xA :: a (b,c) c .abc This could work, but it is neater to separate the output from \nthe feedback data, giving the more symmetrical de.nition class Arrow a .ArrowLoop a where loop :: a (b,d)(c,d) \n.abc The trivial arrow type has such an operator: instance ArrowLoop (.) where loop = simple loop simple \nloop :: ((b,d) .(c,d)) .b .c simple loop f b = c where (c,d)= f (b,d) Monads with m.x give rise to Kleisli \narrows with a loop operator: instance MonadFix m . ArrowLoop (Kleisli m) where loop (Kf )= K (liftM fst \n\u00b7m.x \u00b7f ) where f . xy = f (x,snd y) We shall require that the loop operator satisfy the equa\u00adtions of \nFigure 7. These axioms are also presented in a graphical form in Figure 8. Here the ovals represent loop \noperators, which feed part of the output of the arrow inside back to its input. Our intent, as with m.x, \nis that a value is recursively de.ned, but the computation is executed only once. Thus computations at \nthe start or end that are independent of the recursively de.ned value can by moved out of loop,us\u00ading \nthe tightening rules. On the other hand, the sliding rule can move only pure computations on the recursively \nde.ned value from the end of the loop to the start; moving gen\u00aderal computations would change the order \nof computational e.ects. The vanishing rule states that nested recursive de.\u00adnitions are equivalent to \nsimultaneous recursive de.nitions. Superposing adds unrelated data to the recursion. Finally, we require \nthat loop should extend simple loop. Instances of loop for speci.c arrows may well satisfy ad\u00additional \naxioms. For example, e.ect-free synchronous cir\u00adcuits would satisfy a stronger version of the sliding \naxiom, in which arbitrary circuits could be moved around the loop. 5.1 Theoretical Aside The simple \nloop operator is an example of a trace oper\u00adator, as de.ned by Joyal, Street and Verity [16, 10]. Their \nde.nition assumed a braided monoidal category (a relax\u00adation of a symmetric monoidal category). The equations \nof Figure 7 generalize their axioms to Freyd-categories, and the names of all but the last are taken \nfrom the corresponding trace axioms. In this setting, loop de.nes a family of functions C(BK D,C K D) \n.C(B,C) Then the tightening rules amount to naturality in B and C, while sliding speci.es dinaturality \nin D. Left tightening loop (.rst h \u00bb f )= h \u00bb loop f Right tightening loop (f \u00bb .rst h)= loop f \u00bb h \nSliding loop (f \u00bb arr (id \u00d7k)) = loop (arr (id \u00d7k) \u00bb f ) Vanishing loop (loop f )= loop (arr assoc -1 \n\u00bb f \u00bb arr assoc) -1) Superposing second (loop f )= loop (arr assoc \u00bb second f \u00bb arr assoc Extension \nloop (arr f )= arr (simple loop f ) Figure 7: Loop equations . .. . .. .. Left tightening f = f . . \n.. . . h h . . . . . .. . .. .. Right tightening f = f . . . . . . h h . .. . . .. . .. . . .. arr \nk arr k Sliding = f f . . . . . .. . . .. . . . .. .. Vanishing . . = f . . . . . f . . .  . \n.. . . .. . .. .. . f .  . f . Superposing = . . . . . . Figure 8: Loop equations in graphical \nform It is straightforward to further generalize the signature of loop and these axioms to any symmetric \nnotion of compu\u00adtation. Indeed the Fudgets stream processor library [5] al\u00adready includes a version of \nloop based on sums rather than products.  5.2 Comparison with m.x Our axioms, restricted to the special \ncase of Kleisli ar\u00adrows, may be compared to the axiomatization of m.x given by Erk\u00a8ok and Launchbury \n[8]. The three axioms they pos\u00adtulate correspond to our extension, left tightening and van\u00adishing axioms \nrespectively. They reject a possible law cor\u00adresponding to right tightening, because it fails for certain \nmonads, the most important of which are those involving exceptions. Parametricity of m.x implies a weaker \nform of the sliding law, in which k must be strict, and this proves to be necessary for the exception \nmonads. They suggest that a slightly stronger version of parametricity holds for all monads of interest; \nthis would imply a counterpart of the superposing law. It may be that a similar relaxation would be desirable \nin the arrow context. For example, a loop operator on parser arrows could be used to pass attributes \nbetween parsers in either direction. (The parsers themselves are values of arrow type, and would be recursively \nde.ned using the ordinary recursion of Haskell.) However, such a loop operator would not satisfy the \nright tightening axiom, because the compu\u00adtation h might cause the parse to fail, which would make the \nattributes unde.ned if h were inside the loop. Similarly the sliding axiom would fail for non-strict \nk, if the parse inside the loop were to fail. 5.3 Extending the do-notation We could use the loop operator \ndirectly, but is is more convenient to add recursive bindings to our do-notation, as foreshadowed in \nFigure 5. We use a form modelled on the recursive let (O Haskell [23] has a similar notation for monadic \ndo), rather than the recursive do of Erk\u00a8ok and Launchbury. This form is more .exible, and has a simple \ncorrespondence to loop, given by the following translation rule: do {rec A; B }=do pB .form loop (. pA \n.do A returnA -.(pA, pB)) B where pA is a pattern containing those variables de.ned in A that are required \nin A,and pB is a pattern containing those variables de.ned in A that are required in B.  6. EXAMPLE: \nSYNCHRONOUS CIRCUITS A synchronous circuit receives an input and produces an output on each tick of some \nglobal clock. The output for a given tick may depend on the input for that tick, as well as previous \ninputs. Such circuits .t well with the data-.ow model of computation, and several languages of that type \nhave been used to model them [2, 6, 29]. Consider the following simple circuit (taken from [20]): reset \n.. . . . . out CONST 0 .. . COND . . .. . . INCR .. .. next DELAY 0 . .. This circuit represents a resettable \ncounter, taking a Boolean input and producing an integer output, which will be the number of clock ticks \nsince the input was last True.To achieve this, the output is incremented and fed back, delayed by one \nclock cycle. The .rst output of the delay component is its argument, here 0; its second output is its \n.rst input, and so on. Hardware description languages embedded in Haskell can achieve considerable .exibility \nby parameterizing descrip\u00adtions over type classes. The microarchitecture design lan\u00adguage Hawk [20] abstracts \nover the type of values that may pass through wires. Low-level descriptions deal with bits (Bool), but \nany Haskell type may be used, allowing Hawk to scale to much more abstract descriptions, and also allow\u00ading \nthe same circuit description to be simulated or symboli\u00adcally executed. Further interpretations are possible \nwith the hardware description language Lava [3], where circuits have the form Value . Monad V alue. where \nboth value and monad types are parameters described by Haskell classes. By selecting appropriate instances, \na single description may be simulated, symbolically executed or presented in a variety of styles2 . 6.1 \nA Circuit Class We propose to generalize, treating circuits as arrows, so that a wider range of interpretations \nwill be possible. It su.ces to consider circuits with a single input and output, because multiple inputs \nmay be treated as input of a tuple, and similarly for output. The arr operation de.nes circuits where \neach output is a pure function of the corresponding input (e.g. cond and incr in the above circuit). \n Composition connects the output of the .rst circuit to the input of the second.  The .rst operation \nchannels part of the input to a subcircuit, with the rest copied directly to the output.  As usual, \nwe shall require additional operations. We de.ne circuits as arrows that support cycles and a delay arrow: \nclass ArrowLoop a . ArrowCircuit a where delay :: b . abb The argument supplies the initial output; \nsubsequent out\u00adputs are copied from the input of the previous tick. A circuit built with loop must include \na delay somewhere on its second input before using it, as in the example above. One could 2 The most \nrecent release of Lava has however removed mon\u00adads from the language, partly by pushing impure features \ninto their variant of Haskell. newtype SeqMap b c = SM (Seq b . Seq c) instance Arrow SeqMap where arr \nf = SM (mapSeq f ) SM f \u00bb SM g = SM (g \u00b7 f ) .rst (SM f )= SM (zipSeq \u00b7 (f \u00d7 id) \u00b7 zipSeq-1) instance \nArrowLoop SeqMap where loop (SM f )= SM (simple loop (zipSeq-1 \u00b7 f \u00b7 zipSeq)) instance ArrowCircuit SeqMap \nwhere delay x = SM (Cons x) Figure 9: A circuit arrow type enforce this by combining the two in a single \nconstruct, but the present formulation is better suited to algebraic manip\u00adulation. Here is the resettable \ncounter circuit in arrow notation: counter :: ArrowCircuit a . aBool Int counter = proc reset . do rec \nnext . delay 0 -. out +1 out . returnA -. if reset then 0 else next returnA -. out This corresponds rather \ndirectly to the graphical presenta\u00adtion given earlier. The variables denote the values passing through \nwires on a particular clock tick.  6.2 Interpretations One implementation uses an idea introduced by \nKahn [17]: components de.ne functions from in.nite sequences of in\u00adputs to in.nite sequences of outputs. \nThis idea is the basis for several data-.ow languages [2, 6, 29], for which hardware simulation is just \none application, as well as the microarchi\u00adtecture design language Hawk mentioned above. In.nite sequences \nmay be modelled in Haskell by de.ning data Seq a = Cons a (Seq a) A circuit description in Hawk consists \nof a simultaneous re\u00adcursive de.nition of several such sequences (there called sig\u00adnals), each representing \nthe entire sequence of values that pass through a particular wire over time. We can use this idea to \nde.ne a circuit arrow type as in Figure 9. The de.\u00adnitions use the obvious functions mapSeq :: (a . b) \n. Seq a . Seq b zipSeq :: (Seq a, Seq b) . Seq (a, b) zipSeq-1 :: Seq (a, b) . (Seq a, Seq b) The underlying \nmodel is the same as in Hawk, but program\u00adming with arrows has a di.erent feel. In Hawk one works with \ncircuits and wires, with variables denoting the entire history of wires. Each primitive operation on \nvalues must be lifted to an operation on sequences, and one often has to convert back and forth between \ntuples of sequences and se\u00adquences of tuples. In the arrow formulation, one works with circuits and values. \nThe conversions are still happening, but they are built into the arrow combinators, and thus hidden \nnewtype Writer a bc = W (ab (c, ShowS)) by the arrow notation. Other implementations of the ArrowCircuit \nclass are pos\u00ad instance Arrow a . Arrow (Writer a) where sible. Instead of maps of sequences, we could \nuse automata arr f = W (arr (.x . (fx, id))) that map an input to an output and a new circuit, as follows: \nWf \u00bb Wg = W (proc x . do (y, s1 ) . f -. x newtype Autob c = A (b . (c, Auto b c)) (z, s2 ) . g -. y \nThe external behaviour is the same, but this interpretation returnA -. (z , s1 \u00b7 s2 )) may have di.erent \noperational characteristics. .rst (Wf )= W (proc (x, y) . do We can de.ne further implementations, and \nthus addi\u00ad (x . , s) . f -. x tional interpretations, by two strategies. returnA -. ((x . , y), s)) 1. \nWe can generalize the types SeqMap and Auto,replac\u00ad instance ArrowLoop a . ing the function type with \nan arrow parameter, so that ArrowLoop (Writer a) where they become arrow transformers that may be applied \nloop (Wf )= W (proc b . do to any arrow type that provides loop, such as state rec ( (c, d), s) . f -. \n(b, d)transformers. returnA -. (c, s)) 2. Alternatively, we can apply other arrow transformers to an \nexisting circuit arrow type to create a new one instance ArrowCircuit a . ArrowCircuit (Writer a) where \ndelay x = W (delay x &#38; arr (const id)) with additional features. For example, to add debugging probes \nto circuits, we de.ne a class write :: Arrow a . Writer a ShowS () class ArrowCircuit a . ProbedCircuit \na where write = W (arr (.s . ((), s))) probe :: Show b . String . ab () instance ArrowCircuit a . so \nwe can extend the counter example ProbedCircuit (Writer a) where counter :: ProbedCircuit a . aBool \nInt probe label = proc x . counter = proc reset . do write -. showString label\u00b7 rec probe \"Reset\" -. \nreset showString \"=\"\u00b7 next . delay 0 -. out +1 shows x \u00b7 showChar \\n out . returnA -. if reset then 0 \nelse next Figure 10: Adding output to an arrow probe \"Output\" -. out returnA -. out The intention is \nthat when this circuit is run, the sequence The subsequence of inputs tagged with Left is extracted by \nof values passing through the named wires will be recorded. getLeft and fed to the subcircuit f. The \noutputs of f are Achieving this in Hawk seems to require non-declarative ex\u00adthen tagged with Left and \nmerged with the original sequence tensions to Haskell [20]. by replace, replacing the corresponding inputs. \nThe e.ect is In the arrow setting, we can use the second technique to conditionally propagate the clock \nto subcircuits, as with above, de.ning a Writer arrow transformer that adds out\u00adthe when construct of \nLustre [6]. put to any arrow, and indeed preserves all the ArrowCircuit For arrows in ArrowChoice, we \ncan de.ne conditional structure, as in Figure 10. (We have used the Haskell string commands as follows \n(case commands may be de.ned sim\u00ad output type ShowS, but this is easily generalized to any ilarly): \nmonoid). The simulator may then pick o. the probe output from the circuit outputs. proc p . if e then \nc1 else c2 = arr (.p . if e then Left p else Right p) \u00bb 6.3 Conditionals (proc p . c1) ||| (proc p \n. c2) All the interpretations considered above are also instances A circuit inside an if-then-else command \nonly takes an of ArrowChoice. For example, here is an instance for the input and produces an output on \nclock ticks for which the SeqMap type: condition is true. For example, the command instance ArrowChoice \nSeqMap where if b then counter -. reset left (SM f )= else counter -. reset SM (.xs . replace xs (f (getLeft \nxs))) getLeft :: Seq (Either a b) . Seq a is not equivalent to counter -. reset, because it maintains \ngetLeft (Cons (Left x ) xs)= Cons x (getLeft xs) two counters, only one of which is reset or incremented \non getLeft (Cons (Right ) xs)= getLeft xs each clock tick (depending on the value of b on that tick). \nreplace :: Seq (Either a b) . Seq c . Seq (Either c b)  7. CONCLUSION replace (Cons (Left ) xs) (Cons \ny ys)= Cons (Left y)(replace xs ys) Arrow types, as de.ned by Hughes, or the equivalent replace (Cons \n(Right x ) xs) ys = Freyd-categories de.ned by Power and Thielecke, provide Cons (Right x)(replace xs \nys) useful expressiveness beyond that of monads. We have shown how a simple and useful arrow-based sublanguage \nmay be embedded in the functional language Haskell. As with the monadic style, we can use the full machinery \nof the host language in de.ning new operators, and thus de.ning new sublanguages. We have explored three \nexamples here, but expect that many existing DSLs could be simpli.ed and strengthened by being recast \nin this form.  8. ACKNOWLEDGEMENTS I am indebted to John Hughes, Levent Erk\u00a8ok and John Launchbury for \ndiscussions on parts of this work. Sven Panne, Simon Marlow and Keith Wansborough wrote the Haskell parser \nand pretty-printer on which I based the prototype preprocessor. The preparation of this paper was greatly \neased by Ralf Hinze s lhs2TEX program. 9. REFERENCES [1] K. Batcher. Sorting networks and their applications. \nIn AFIPS Spring Joint Conference, pages 307 314, 1968. [2] G. Berry and G. Gonthier. The Esterel synchronous \nprogramming language: Design, semantics, implementation. Science of Computer Programming, 19(2):87 152, \n1992. [3] P. Bjesse, K. Claessen, M. Sheeran, and S. Singh. Lava: Hardware design in Haskell. In International \nConference on Functional Programming. ACM, 1998. [4] R. Blute, J. Cockett, and R. Seely. Categories for \ncomputation in context and uni.ed logic. Journal of Pure and Applied Algebra, 116:49 98, 1997. [5] M. \nCarlsson and T. Hallgren. Fudgets a graphical user interface in a lazy functional language. In FPCA, \npages 321 330. ACM Press, 1993. [6] P. Caspi, D. Pilaud, N. Halbwachs, and J. Plaice. LUSTRE: A declarative \nlanguage for programming synchronous systems. In 14th ACM Symposium on Principles of Programming Languages, \npages 178 188, Munich, 1987. [7] R. Douence and P. Fradet. Towards a taxonomy of functional language \nimplementations. In Programming Languages: Implementations, Logics and Programs, volume 982 of Lecture \nNotes in Computer Science, pages 34 45, 1995. [8] L. Erk\u00a8ok and J. Launchbury. Recursive monadic bindings. \nIn ICFP, 2000. [9] M. Hasegawa. Decomposing typed lambda calculus into a couple of categorical programming \nlanguages. In CTCS, volume 953 of Lecture Notes in Computer Science. Springer, 1995. [10] M. Hasegawa. \nRecursion from cyclic sharing: Traced monoidal categories and models of cyclic lambda calculi. In Proceedings, \nThird International Conference on Typed Lambda Calculi and Applications (TLCA 97), volume 1210 of Lecture \nNotes in Computer Science. Springer, 1997. [11] P. Hudak. Modular domain speci.c languages and tools. \nIn International Conference on Software Reuse, 1998. [12] J. Hughes. Generalising monads to arrows. Science \nof Computer Programming, 37:67 111, May 2000. [13] G. Hutton and E. Meijer. Monadic parsing in Haskell. \nJournal of Functional Programming, 8(4):437 444, 1998. [14] G. Jones and M. Sheeran. Collecting butter.ies. \nTechnical Monograph PRG-91, Oxford University Computing Laboratory, Programming Research Group, Feb. \n1991. [15] G. Jones and M. Sheeran. Designing arithmetic circuits by re.nement in Ruby. In R. Bird, C. \nMorgan, and J. Woodcock, editors, Mathematics of Program Construction, volume 669 of Lecture Notes in \nComputer Science, pages 208 232. Springer, 1993. [16] A. Joyal, R. Street, and D. Verity. Traced monoidal \ncategories. Mathematical Proceedings of the Cambridge Philosophical Society, 119(3):447 468, 1996. [17] \nG. Kahn. The semantics of a simple language for parallel programming. In IFIP 74. North Holland, 1974. \n[18] R. Ladner and M. Fischer. Parallel pre.x computation. J. ACM, 27:831 838, 1980. [19] P. J. Landin. \nThe next 700 programming languages. Communications of the ACM, 9(3):157 164, 1966. [20] J. Launchbury, \nJ. Lewis, and B. Cook. On embedding a microarchitecture design language within Haskell. In International \nConference on Functional Programming. ACM, 1999. [21] J. Misra. Powerlist: A structure for parallel recursion. \nACM Trans. Prog. Lang. Syst., 16(6):1737 1767, Nov. 1994. [22] E. Moggi. Computational lambda-calculus \nand monads. In Logic in Computer Science. IEEE, 1989. [23] J. Nordlander. Reactive Objects and Functional \nProgramming. PhD thesis, Dept. of Computing Science, Chalmers University of Technology, 1999. [24] S. \nPeyton Jones, J. Hughes, et al. Haskell 98: A non-strict, purely functional language, Feb. 1999. [25] \nA. Power. Elementary control structures. In CONCUR 96: Concurrency Theory, volume 1119 of Lecture Notes \nin Computer Science, pages 115 130. Springer, 1996. [26] J. Power and E. Robinson. Premonoidal categories \nand notions of computation. Mathematical Structures in Computer Science, 7(5):453 468, Oct. 1997. [27] \nJ. Power and H. Thielecke. Closed Freyd-and kappa-categories. In ICALP, volume 1644 of LNCS. Springer, \n1999. [28] S. D. Swierstra and L. Duponcheel. Deterministic, error-correcting combinator parsers. In \nJ. Launchbury, E. Meijer, and T. Sheard, editors, Advanced Functional Programming, volume 1129 of Lecture \nNotes in Computer Science, pages 184 207. Springer, 1996. [29] W. Wadge and E. Ashcroft. Lucid, the Data.ow \nProgramming Language. Academic Press, 1985. [30] P. Wadler. The essence of functional programming. In \n19th ACM Symposium on Principles of Programming Languages, pages 1 14, Albuquerque, NM, Jan. 1992.  \n \n\t\t\t", "proc_id": "507635", "abstract": "The categorical notion of monad, used by Moggi to structure denotational descriptions, has proved to be a powerful tool for structuring combinator libraries. Moreover, the monadic programming style provides a convenient syntax for many kinds of computation, so that each library defines a new sublanguage. Recently, several workers have proposed a generalization of monads, called variously \"arrows\" or Freyd-categories. The extra generality promises to increase the power, expressiveness and efficiency of the embedded approach, but does not mesh as well with the native abstraction and application. Definitions are typically given in a point-free style, which is useful for proving general properties, but can be awkward for programming specific instances. In this paper we define a simple extension to the functional language Haskell that makes these new notions of computation more convenient to use. Our language is similar to the monadic style, and has similar reasoning properties. Moreover, it is extensible, in the sense that new combining forms can be defined as expressions in the host language.", "authors": [{"name": "Ross Paterson", "author_profile_id": "81100274068", "affiliation": "City Univ., London, UK", "person_id": "PP14103160", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/507635.507664", "year": "2001", "article_id": "507664", "conference": "ICFP", "title": "A new notation for arrows", "url": "http://dl.acm.org/citation.cfm?id=507664"}