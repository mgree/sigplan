{"article_publication_date": "10-01-2001", "fulltext": "\n A Simple Implementation Technique for Priority Search Queues Ralf Hinze Institute of Information and \nComputing Sciences, Utrecht University P.O.Box 80.089, 3508 TB Utrecht, The Netherlands ralf@cs.uu.nl \nABSTRACT This paper presents a new implementation technique for pri\u00adority search queues. This abstract \ndata type is an amazing blend of .nite maps and priority queues. Our implementa\u00adtion supports logarithmic \naccess to a binding with a given key and constant access to a binding with the minimum value. Priority \nsearch queues can be used, for instance, to give a simple, purely functional implementation of Dijkstra \ns single-source shortest-paths algorithm. A non-technical concern of the paper is to foster abstract \ndata types and views. Priority search queues have been largely ignored by the functional programming \ncommunity and we believe that they deserve to be known better. Views prove their worth both in de.ning \na convenient interface to the abstract data type and in providing a readable imple\u00admentation.  Categories \nand Subject Descriptors D.1.1 [Programming Techniques]: Applicative (Func\u00adtional) Programming; D.3.2 \n[Programming Languages]: Language Classi.cations applicative (functional) languages; D.3.3 [Programming \nLanguages]: Language Constructs and Features abstract data types; E.1 [Data]: Data Struc\u00adtures trees; \nF.2.2 [Analysis of Algorithms and Prob\u00adlem Complexity]: Nonnumerical Algorithms and Prob\u00adlems sorting \nand searching; I.1.2 [Computing Method\u00adologies]: Algorithms analysis of algorithms General Terms Algorithms, \ndesign, performance  Keywords Priority search queues, views, Haskell, tournament 1. INTRODUCTION The \naim of this paper is threefold: Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. ICFP 01, September 3 5, 2001, Florence, Italy. Copyright 2001 ACM 1-58113-415-0/01/0009 \n...$5.00. First, we would like to advertise priority search queues, a useful abstract data type that \nhas been largely ignored by the functional programming community and that de\u00adserves to be known better. \nPriority search queues are an amazing blend of .nite maps (or dictionaries) and priority queues, that \nis, they support both dictionary operations (for instance, accessing a binding with a given key) and \nprior\u00adity queue operations (for instance, accessing a binding with the minimum value). We give two simple \napplications that demonstrate their usefulness: a purely functional implemen\u00adtation of Dijkstra s single-source \nshortest-paths algorithm and an e.cient implementation of the .rst-.t heuristics for the bin packing \nproblem. Second, we describe a simple implementation technique for the abstract data type. The standard \nimplementation of priority search queues, McCreight s priority search trees [14], combines binary search \ntrees and heaps. Unfortunately, balanced search trees and heaps do not go well together. Ro\u00adtations that \nare typically used to maintain balance destroy the heap property and restoring the property takes T(h) \ntime where h is the height of the tree. Consequently, in order to attain overall logarithmic time bounds \nthe under\u00adlying balancing scheme must guarantee that the number of rotations per update is bounded by \na constant. We show that it is possible to weaken the heap property so that ro\u00adtations become constant \ntime operations without sacri.cing the running time of the priority queue methods. Thus, we can freely \nchoose an underlying balancing scheme we illus\u00adtrate our approach using weight-balanced trees [1]. Third, \nwe would like to promote the use of views. Views have been introduced by Wadler [23] to relieve the tension \nbetween pattern matching and abstraction. Brie.y, views allow any type (in particular, any abstract data \ntype) to be viewed as a free data type. We have found views not only useful for providing a convenient \ninterface to an abstract data type but also extremely helpful in the implementation itself. The use of \nviews made the code substantially clearer. The remainder of this paper is structured as follows. Sec\u00adtion \n2 brie.y reviews the concept of views. Section 3 in\u00adtroduces the abstract data type priority search queue \nand Section 4 illustrates its use. Section 5 provides a simple implementation based on unbalanced trees. \nSection 6 then shows how to augment the basic implementation by a bal\u00adancing scheme. Section 7 analyses \nthe running time of so\u00adcalled range queries. Finally, Section 8 reviews related work and Section 9 concludes. \n 2. PRELIMINARIES: VIEWS The code in this paper is given in Haskell 98 [19] aug\u00admented by the concept \nof views [4, 16]. This section brie.y reviews Okasaki s proposal for views [16]. A view allows any type \nto be viewed as a free data type. A view declaration for a type T consists of an anonymous data type, \nthe view type, and an anonymous function, the view transformation, that shows how to map elements of \nT to the view type. Here is a simple example that de.nes a minimum view on lists: view (Ord a) . [a ]= \nEmpty | Min a [a ] where [] . Empty a1 : Empty . Min a1 [] a1 : Min a2 as | a1 .a2 . Min a1 (a2 : as) \n| otherwise . Min a2 (a1 : as). This declaration introduces two constructors, Empty and Min, that henceforth \ncan be used to pattern match elements of type [a ], where the context (Ord a) . restricts a to instances \nof Ord. The minimum view allows any list to be viewed as an ordered list. The following de.nition of \nselection sort nicely illustrates the use of views: selection-sort :: (Ord a) . [a ] . [a ] selection-sort \nEmpty = [] selection-sort (Min a as)= a : selection-sort as. The view constructors can be freely mixed \nwith ordinary data type constructors. In fact, the view transformation of the minimum view already illustrates \nnested patterns. A type can even have multiple views. However, view construc\u00adtors may only appear in \npatterns with the notable excep\u00adtion of the view transformation itself. View declarations can be implemented \nby a simple source to source translation: each view is expanded into a data type and a function. For \nthe minimum view we obtain: data Min-View a = Empty | Min a [a ] min-view :: (Ord a) . [a ] . Min-View \na min-view x1 = case x1 of [] . Empty a1 : x2 . case min-view x2 of Empty . Min a1 [] Min a2 as | a1 \n.a2 . Min a1 (a2 : as) | otherwise . Min a2 (a1 : as). The function is invoked whenever constructors \nof the view appear in patterns. In our example, the view constructors appear in the view transformation \nitself. Consequently, it is expanded into a recursive function. Selection sort becomes: selection-sort \nx = case minView x of Empty . [] Min a as . a : selection-sort as. For a precise de.nition of the semantics \nwe refer the in\u00adterested reader to Okasaki s paper [16] the proposal is for Standard ML but it can be \neasily adapted to Haskell 98. 3. PRIORITY SEARCH QUEUES The abstract data type priority search queue \nis conceptu\u00adally a .nite map that supports e.cient access to the binding with the minimum value, where \na binding is an argument\u00advalue pair and a .nite map is a .nite set of bindings. For emphasis, we call \nthe arguments keys and the associated values priorities. The functions key and prio are used to access \nthe key and the priority of a binding. key (k, p)= k prio (k, p)= p. The abstract data type of priority \nsearch queues is paramet\u00adric in the types of keys and priorities: data PSQ k p. Most operations on priority \nsearch queues require that both k and p are totally ordered. This condition is expressed in Haskell by \nthe context (Ord k, Ord p) . . However, in the rest of this paper we will omit the context to reduce \nclutter. Priority search queues support both .nite map and prior\u00adity queue operations plus so-called \nrange queries. Constructors and insertion. \u00d8 :: PSQ k p {\u00b7} :: (k, p) . PSQ k p insert :: (k, p) . PSQ \nk p . PSQ k p from-ord-list :: [(k, p)] . PSQ k p The constructor \u00d8 represents the empty queue; {b} creates \na queue that contains b as the single binding; insert b q inserts binding b into q (if the queue contains \na binding with the same key, then the old binding is overwritten); and from-ord-list converts a list \nof bindings into a queue with the precondition that the list is sorted into increasing order by key. \nDestructors and deletion. view PSQ k p = Empty | Min (k, p)(PSQ k p) delete :: k . PSQ k p . PSQ k p \nA queue is destructed using the patterns Empty and Min bq introduced by the view declaration. The function \ndelete re\u00admoves a binding with the given key (the queue is left un\u00adchanged if it does not contain a binding \nwith the key). The constructors of the minimum view have the following mean\u00ading: if a queue pattern matches \nEmpty, then it is empty; otherwise it matches Min bq where b is the binding with the minimum priority \nand q is the remaining queue. Thus, us\u00ading the view we can e.ectively treat a priority search queue as \na list of bindings ordered by priority. Observers. lookup :: k . PSQ k p . Maybe p to-ord-list :: PSQ \nk p . [(k, p)] at-most :: p . PSQ k p . [(k, p)] The function lookup .nds the priority associated with \na given key: the call lookup k q returns Nothing if the queue does not contain the key k; otherwise it \nyields Just p where p is the priority associated with k. The function to-ord-list converts a queue into \na list of bindings ordered by key. Pri\u00adority search queues not only support dictionary and priority queue \noperations. As a little extra they also allow for so\u00adcalled range queries: at-most pt q returns a list \nof bindings ordered by key whose priorities are at most pt . In the full version of the paper [9] we \nalso discuss range queries that additionally take a key range into account. Modi.er. adjust :: (p . p) \n. k . PSQ k p . PSQ k p The function adjust changes a binding for the given key by applying the function \nto its priority (the queue is left unchanged if it does not contain a binding with the key). 4. APPLICATIONS \n4.1 Single-source shortest-paths problem Dijkstra s algorithm for the single-source shortest-paths problem \nserves as a nice example for the use of priority search queues. The algorithm maintains a queue that \nmaps each vertex to its estimated distance from the source. The algorithm works by repeatedly removing \nthe vertex with minimal distance and updating the distances of its adja\u00adcent vertices. Priority search \nqueues support both opera\u00adtions equally well. The update operation is typically called decrease: decrease \n:: (k, p) . PSQ k p . PSQ k p decrease (k, p) q = adjust (min p) kq decrease-list :: [(k, p)] . PSQ k \np . PSQ k p decrease-list bs q = foldr decrease q bs. Note that decrease (k, p) q has no e.ect if k s \npriority in q is less than p. To keep the presentation terse we assume that the follow\u00ading functions \non graphs are provided from somewhere. vertices :: Graph . [Vertex ] adjacent :: Graph . Vertex . [Vertex \n] The function vertices returns an ordered list of all vertices of a graph; adjacent produces a list \nof vertices adjacent to the given one. The function dijkstra de.ned below takes three arguments: a directed \ngraph, a weight function, and a source vertex. It returns a list of vertex-distance bindings that determine \nthe minimal distance of each vertex from the source. type Weight = Vertex . Vertex . Double dijkstra \n:: Graph . Weight . Vertex . [(Vertex, Double)] dijkstra g w s = loop (decrease (s, 0) q0) where q0 = \nfrom-ord-list [(v, +8) | v . vertices g ] loop Empty = [] loop (Min (u, d) q) =(u, d): loop (decrease-list \nbs q) where bs = [(v, d + wuv) | v . adjacent g u ] The helper function loop uses the minimum view to \nprocess the queue. Note that the computed list of vertex-distance bindings may contain bindings with \npriority +8, which in\u00addicates that the given graph was not strongly connected. Now, if we assume that \nthe computation of the view and the decrease operation each take T(log V ) time, then the algo\u00adrithm \nhas a worst-case running time of T((V + E) log V ), which is the best known running time for purely functional \nimplementations. Remark 1. If we modify the computation of the new dis\u00adtances as follows ... where bs \n= [(v, wuv) | v . adjacent g u ], we obtain Prim s algorithm for computing a minimum span\u00adning tree. \n 4.2 One-dimensional bin packing As the second example we employ priority search queues to implement \nthe .rst-.t heuristics for the bin packing prob\u00adlem. Recall that the standard list-based implementation \nshown below has a worst-case running time of T(n 2) where n is the number of items. pack-.rst-.t :: [Item \n] . [Bin ] pack-.rst-.t = foldl .rst-.t [] .rst-.t :: [Bin ] . Item . [Bin ] .rst-.t [] i =[i ] .rst-.t \n(b : bs) i | b + i .1= b + i : bs | otherwise = b : .rst-.t bs i The function pack-.rst-.t takes a list \nof items, each of a certain size, and returns a list of bins that contain the input items. For simplicity, \nwe represent an item by its size and a bin by its total size (each bin has a capacity of 1). Using priority \nsearch queues we can improve the running time of the na\u00a8ive implementation to T(n log n). The central \nidea is to use the function at-most to quickly determine the .rst bin that can accommodate a given item \n(the bins are numbered consecutively). type No = Int pack-.rst-.t :: [Item ] . [Bin ] pack-.rst-.t is \n=[prio b | b . to-ord-list q ] where (q, )= foldl .rst-.t (\u00d8, 0) is .rst-.t :: (PSQ No Bin, No) . Item \n . (PSQ No Bin, No) .rst-.t (q, n) i = case at-most (1 - i) q of [] . (insert (n, i) q, n + 1) (k, ): \n. (adjust (+i) kq, n) This is the only place where essential use is made of Haskell s non-strict semantics \nas we merely require the .rst element of the list returned by at-most. In a strict language, we would \nbe forced to de.ne a specialized version of at-most that computes the .rst binding only (if any).  \n5. PRIORITY SEARCH PENNANTS This section describes an implementation of priority search queues based \non unbalanced search trees. Great care has been taken to modularize the code so that a balancing scheme \ncan be added later with ease (Section 6 discusses the nec\u00adessary amendments). It should be noted, however, \nthat the implementation in this section is perfectly suitable for Dijk\u00adstra s or Prim s algorithm since \nboth do not require inser\u00adtions. The underlying idea of the implementation is best ex\u00adplained using the \nmetaphor of a knockout tournament. Con\u00adsider the tournament depicted in Figure 1. We have eight participants, \nso the course of matches forms a complete bi\u00adnary tree. Each external node corresponds to a participant; \neach internal node corresponds to a winner of a match. To facilitate searching the participants are arranged \nfrom left  Lennart 1 Phil 3  Erik 2 Lennart 1  Phil 3 Simon 5 Charles 4 Erik 2 Lennart 1 Mary 6 Phil \n3 Richard 7 Simon 5 Warren 8 Figure 1: A tournament tree. to right in increasing order by name. Tournament \ntrees are almost a suitable data structure for priority search queues if it were not for the many repeated \nentries. The champion, for instance, appears on every level of the tree. Now, there are at least two \nways to repair this defect. One possibility is to promote losers up the tree turning the tournament tree \nof Figure 1 into the heap-structured tree of Figure 2. This transformation usually involves ad\u00additional \nmatches. In our example, Erik has to play with Mary to determine the second-best player of the .rst half \nof the tournament. Pursuing this idea further leads to a data structure known as a priority search tree \n[14]. We will come back to this data structure in Sections 7 and 8. An alternative possibility, which \nwe will investigate in this section, is to label each internal node with the loser of the match, instead \nof the winner, and to drop the external nodes altogether. If we additionally place the champion on top \nof the tree, we obtain the topped loser tree of Figure 3. We call the resulting data structure priority \nsearch pennant. Since every participant with the notable exception of the champion loses exactly one \nmatch, the pennant does not contain repeated entries. It is important to note, however, that the loser \ntree is not heap-structured. Since the nodes are labelled with losers, they dominate, in general, only \none subtree. The node labelled Phil, for instance, dominates its right but not its left subtree. Thus \nthe loser tree constitutes only a so-called semi-heap. The Haskell data type for priority search pennants \nis a direct implementation of the above ideas except that we additionally introduce split keys (or search \nkeys) to support searching. Here,Void represents the empty tournament; Winner bt m represents a tournament \nthat b has won, t is the associated loser tree and m is the maximum key. Likewise, Start is the empty \nloser tree; Loser b tl ktr represents a subtournament that b has lost, tl is the left subtree, k is the \nsplit key, and tr is the right subtree. The maximum key is usually accessed using the function max-key. \nmax-key :: PSQ k p . k max-key (Winner bt m)= m We will see in Section 5.1 why it is useful to keep track \nof the maximum key. Priority search pennants combine the features of search trees and semi-heaps. To \nformulate the invariants, it is convenient to view the top node Winner b t m as a bi\u00adnary node with an \nempty right subtree so that the maxi\u00admum key becomes an ordinary split key (Winner b t m ~ = Loser b \nt m Start). Semi-heap conditions: 1) Every priority in the pennant must be greater than or equal to the \npriority of the winner. 2) For all nodes in the loser tree, the priority of the loser s binding must \nbe less than or equal to the priorities of the bindings of the subtree from which the loser originates. \nThe loser originates from the left subtree if its key is less than or equal to the split key, otherwise \nit originates from the right subtree. Search-tree condition: For all nodes, the keys in the left subtree \nmust be less than or equal to the split key and the keys in the right subtree must be greater than the \nsplit key. Key condition: The maximum key and the split keys must data PSQ k p = Void also occur as keys \nof bindings. | Winner (k, p)(LTree k p) k data LTree k p = Start Finite map condition: The pennant must \nnot contain two | Loser (k, p)(LTree k p) k (LTree k p) bindings with the same key. Lennart 1 Erik \n2  Phil 3  Charles 4 Mary 6 Richard 7 Simon 5 Warren 8 Figure 2: The heap corresponding to the tournament \nof Figure 1. Lennart 1 Phil 3 Erik 2  Simon 5 Charles 4 Mary 6 Richard 7 Warren 8 Figure 3: The semi-heap \ncorresponding to the tournament of Figure 1. Figure 4: The priority search pennant correspond\u00ading to \nthe tree of Figure 3. Two remarks are in order. First, the second semi-heap con\u00addition shows that a priority \nsearch pennant contains enough information to reconstruct the original tournament tree. This ability \nis crucial for implementing the priority queue opera\u00adtions. Second, the key condition ensures that every \nsearch key originates from a binding in the tree. This means, in particular, that if we delete a binding \nfrom a tree, we must also delete the key s second occurrence as a search key. We will see that it is \nrelatively easy to maintain this invariant. Let us consider an example. If we augment the tree of Figure \n3 by split keys, we obtain the priority search pen\u00adnant depicted in Figure 4. Note that the dotted lines \nmark the subtrees that are not dominated by the loser. As we have remarked before, the semi-heap structure \ncan also be determined by comparing the loser s key to the split key: the node labelled Phil, for instance, \ndominates its right sub\u00adtree since P >M; the node labelled Erik on the other hand dominates its left \nsubtree since E . E. The pennant can quite easily be expressed as a Haskell term: Winner (L, 1) ( Loser \n(P, 3) ( Loser (E, 2) ( Loser (C, 4) Start C Start) E ( Loser (M, 6) Start L Start)) M ( Loser (S, 5) \n( Loser (R, 7) Start P Start) R ( Loser (W, 8) Start S Start))) W. Note that if we list the search keys \nfrom left to right, we obtain the keys of the participants in increasing order. Remark 2. The nodes are \ndecorated with bindings of type (k, p). While this is convenient for the presentation, it comes at a \nsmall run-time cost since every access involves one extra level of indirection. In the production code, \nwhich is avail\u00adable from http://www.cs.uu.nl/~ralf/software, we speed up the access by storing the keys \nand the priorities directly in the nodes. 5.1 Constructors The empty queue and the singleton queue are \nde.ned as follows: \u00d8 :: PSQ k p \u00d8 = Void {\u00b7} :: (k, p) . PSQ k p {b} = Winner b Start (key b). The data \ntypes PSQ and LTree have been designed to e.\u00adciently support the binary operation (J), which corresponds \nto playing a match. This operation, which is used by most of the remaining functions, takes two pennants \nand returns a new pennant that is the union of the two with the precon\u00addition that the keys in the .rst \ntree are strictly smaller than the keys in the second tree. The operation is illustrated in Figure 5. \n(J) :: PSQ k p . PSQ k p . PSQ k p Void J t' = t' t J Void = t '' Winner bt m J Winner b' tm | prio \nb .prio b' = Winner b (Loser b' tmt') m' | otherwise = Winner b' (Loser bt m t') m' Note that in order \nto construct the loser tree we require a split key, which is why we keep track of the maximum key in \nthe top node. This makes J a constant-time operation. It is not hard to see that J preserves the invariants \nof priority search pennants. Using J we can easily de.ne from-ord-list. from-ord-list :: [(k, p)] . PSQ \nk p from-ord-list = foldm (J) \u00d8\u00b7 map (.b .{b}) The helper function foldm, which is listed in the full \nversion of this paper [9], folds a list in a binary-sub-division fashion. For instance, from-ord-list \n[(A, 4), (D, 2), (E, 1), (J , 6), (L, 3), (N , 7), (P, 5), (V , 8)] reduces to (({A, 4} J {D, 2}) J ({E, \n1} J {J , 6})) J (({L, 3} J {N , 7}) J ({P, 5} J {V , 8})), which in turn evaluates to the tree of Figure \n4. In general, the expression tree generated by foldm takes the form of a leaf-oriented Braun tree [3]. \nSince J preserves the shape of the expression tree, the priority search pennant produced by from-ord-list \ncorresponds to a topped Braun tree. This means, in particular, that the shape is solely determined by \nthe total number of participants (and not by their priorities).  5.2 Destructors The minimum view is \nimplemented as follows: view PSQ k p = Empty | Min (k, p)(PSQ k p) where Void . Empty Winner bt m . Min \nb (second-best t m). The function second-best used in the second clause deter\u00admines the second-best player \nby replaying the tournament without the champion. second-best :: LTree k p . k . PSQ k p second-best \nStart m = Void second-best (Loser bt k u) m | key b .k = Winner bt k J second-best u m | otherwise = \nsecond-best t k J Winner bu m Note that only those players who lost to the champion are taken into account. \nThe origin of the champion is deter\u00admined by comparing the loser s key to the split key. Again, it is \nstraightforward to see that second-best pre\u00adserves the invariants except perhaps for the key condition: \ndoes second-best also remove the search key of the cham\u00adpion? This is most easily shown if we de.ne second-best \non Figure 5: Playing a match (b1 b2 is shorthand for prio b1 prio b2). pennants instead of loser trees \n(we call this variant del-min): del-min :: PSQ k p . PSQ k p del-min Void = Void del-min (Winner b Start \nm) = Void del-min (Winner b (Loser b ' tku) m) | key b ' k = Winner b ' tk J del-min (Winner bu m) | \notherwise = del-min (Winner bt k) J Winner b ' um. Since the argument of del-min is always a legal pennant, \nm must equal key b in the second equation by virtue of the key condition. Furthermore, we know that b \nis the champion, since the champion is passed unchanged to the recursive calls. The function second-best \ncan now be seen as a simple optimization: we have del-min (Winner b t m)= second-best t m. Remark 3. \nWhen we replay a tournament we determine the origin of a loser by comparing the loser s key to the split \nkey (key b k). Instead of using this perhaps costly com\u00adparison, we can alternatively code the information \ninto the constructors when building the tree: data LTree k p = Start | LLoser (k, p)(LTree k p) k (LTree \nk p) | RLoser (k, p)(LTree k p) k (LTree k p). This is, in fact, the representation we use in the production \ncode. The original representation, however, is slightly easier to augment by a balancing scheme.  5.3 \nObservers Views are not only convenient for the client of an abstract data type. They can also be tremendously \nhelpful when im\u00adplementing an abstract data type. The following declaration allows us to view a pennant \nas a tournament tree. view PSQ k p = \u00d8|{k, p}| PSQ k p J PSQ k p where Void .\u00d8 Winner b Start m .{b} \nWinner b (Loser b ' tl ktr ) m | key b ' k . Winner b ' tl k J Winner b tr m | otherwise . Winner b tl \nk J Winner b ' tr m Note that we have taken the liberty of using \u00d8, {\u00b7} and J also as constructors. There \nis little danger of confu\u00adsion since the constructors of the view may only appear in patterns with the \nnotable exception of the view transfor\u00admation itself while the functions of the same name may only appear \nin expressions. The view transformation is es\u00adsentially the inverse of the J operation. In particular, \nif a winner tree matches tl J tr , then it is guaranteed that the keys in tl are strictly smaller than \nthe keys in tr . Further\u00admore, both tl and tr are non-empty. The function to-ord-list, which converts \na queue into a list of bindings ordered by key, nicely illustrates the use of the tournament view.1 to-ord-list \n:: PSQ k p . [(k, p)] to-ord-list \u00d8 = [] to-ord-list {b} =[b ] to-ord-list (tl J tr )= to-ord-list tl \n+ to-ord-list tr In the last clause we rely on the fact that the keys in tl precede the keys in tr . \nIt is instructive to rewrite the de.nition of to-ord-list into a form that does not make use of views. \nWe will see that the resulting code is much harder to read. On the other hand, the rewrite opens the \npossibility of small improve\u00adments (which a good optimizing compiler might be able to perform automatically). \nAs the .rst step, we fuse the view transformation and the original function: to-ord-list :: PSQ k p . \n[(k, p)] to-ord-list Void = [] to-ord-list (Winner b Start m) =[b ] to-ord-list (Winner b (Loser b ' \ntl ktr ) m) | key b ' k = to-ord-list (Winner b ' tl k) + to-ord-list (Winner b tr m) | otherwise = to-ord-list \n(Winner b tl k) + to-ord-list (Winner b ' tr m). Note that in each of the recursive calls to-ord-list \nis passed a non-empty winner tree. Furthermore, the maximum key and the split keys are never used. This \nsuggests specializing to-ord-list (Winner bt m) to traverse b t: to-ord-list :: PSQ k p . [(k, p)] to-ord-list \nVoid = [] to-ord-list (Winner bt m)= traverse b t traverse :: (k, p) . LTree k p . [(k, p)] traverse \nb Start =[b ] traverse b (Loser b ' tl ktr ) | key b ' k = traverse b ' tl + traverse b tr | otherwise \n= traverse b tl + traverse b ' tr . Most of the following functions can be optimized along these lines. \n1Due to the use of (++) the de.nition of to-ord-list exhibits T(n 2) worst-case behaviour. This is, however, \neasily reme\u00addied using standard techniques. The look-up function is very similar to the look-up func\u00adtion \nfor binary search trees. Again, the tournament view allows for a very natural implementation. lookup \n:: k . PSQ k p . Maybe p lookup k \u00d8 = Nothing lookup k {b} | k key b = Just (prio b) | otherwise = Nothing \n lookup k (tl J tr ) | k max-key tl = lookup k tl | otherwise = lookup k tr The running time of lookup \nis proportional to the height of the tree even if we search for a binding that is high up in the tree. \nThis observation suggests to additionally test the bindings on the search path at the cost of one additional \ncomparison per recursive call. Of course, this change neither a.ects the worst-case nor the average-case \nrunning time. lookup ' :: k . PSQ k p . Maybe p lookup ' k (Min bq) | k key b = Just (prio b) lookup \n' k \u00d8 = Nothing lookup ' k {b} = Nothing --we know that k . key b lookup ' k (tl J tr ) | k max-key tl \n= lookup ' ktl | otherwise = lookup ' ktr Note that this version of the look-up function uses both the \nminimum and the tournament view. 5.4 Modi.er, insertion, and deletion The dictionary functions adjust, \ninsert, and delete can be most easily implemented using the tournament view. adjust :: (p . p) . k . \nPSQ k p . PSQ k p adjust f k \u00d8 = \u00d8 adjust f k {b} | k key b = {k, f (prio b)} | otherwise = {b} adjust \nf k (tl J tr ) | k max-key tl = adjustf ktl J tr | otherwise = tl J adjustf ktr The modi.er adjust nant. \nBy contrast, insert degenerated tree. insert :: (k, p) . PSQ k p . insert b \u00d8 = {b} insert b {b ' } \n| key b < key b ' = {b} J {b ' } | keyb keyb ' = {b} --update | key b > key b ' = {b ' } J {b} insert \nb (tl J tr ) | key b max-key tl = insert b tl J tr | otherwise = tl J insert b tr In the case of search \ntrees deletion is notoriously more di.\u00adcult to handle than insertion. Perhaps surprisingly, this does \nnot hold for priority search pennants. The reason is simply that using the tournament view all modi.cations \ntake place at the fringe of the tree: delete :: k . PSQ k p . PSQ k p delete k \u00d8 = \u00d8 delete k {b} | k \nkey b = \u00d8 | otherwise = {b} delete k (tl J tr ) | k max-key tl = delete k tl J tr | otherwise = tl J \ndelete k tr . Given the hybrid nature of priority search pennants the def\u00adinition of delete is surprisingly \nattractive. 5.5 Range queries Like the second version of the look-up function, the query function at-most \nemploys two views simultaneously. The minimum view is used to prune the search if a node is en\u00adcountered \nwhose priority is greater than the given one. at-most :: p . PSQ k p . [(k, p)] at-most pt (Min bq) | \nprio b > pt = [] at-most pt \u00d8 = [] at-most pt {b} =[b ] --we know that priob pt at-most pt (tl J tr )= \nat-most pt tl + at-most pt tr The query function is analysed in Section 7.  6. A BALANCED SCHEME One \nof the strengths of priority search pennants as com\u00adpared to priority search trees is that the basic \nimplementa\u00adtion can be easily extended by a balancing scheme. Most schemes use rotations to restore balancing \ninvariants. Now, while rotations preserve the search-tree property, they do not preserve the semi-heap \nproperty as the following exam\u00adple shows. In the original tree, both losers, D and F , dominate their \nright subtree. This implies that they have not played against each other and that the winner stems from \nthe leftmost sub\u00adtree t1. Now, if we rotate the loser tree to the right, the new root should dominate \nits right subtree but it does not. To restore the semi-heap property we have to exchange D5 and F 2. \nWe will see that, in general, at most one exchange at the cost of at most one additional comparison is \nrequired. In other words, rotations are constant time operations for priority search pennants. By contrast, \nin the case of priority search trees we have to preserve the heap property, which takes T(h) time where \nh is the height of the tree. This means, in particular, that in order to ensure an overall logarithmic \ntime bound, the num\u00adber of rotations per update must be bounded by a constant. Red-black trees [6] or \n2-3-4 trees [10] satisfy this constraint. On the other hand, AVL trees [2] or weight-balanced trees [1] \ndo not guarantee such a bound. Ironically, Okasaki s el\u00adegant functional implementation of red-black \ntrees [17] also fails to meet this condition. However, for priority search pennants we can freely choose \nan underlying balancing scheme. We pick Adams s weight\u00adbalanced trees [1] since they support insertions \nand deletions equally well. A tree is weight-balanced if for all nodes either both subtrees have at most \none element or one subtree does not have more than . times as many elements as the op\u00adposite subtree, \nwhere . is some constant > 3.75. To check and to maintain the invariant, each node in a loser tree is \naugmented by a size .eld: type Size = Int data Tree k p = Lf | Nd Size (k, p)(Treek p) k (Tree k p). \n Using views and smart constructors we can make the com\u00adputation of the size .eld totally transparent. \nleaf = Lf node bl k r = Nd (1 + size l + size r) blkr view Treek p = Leaf | Node (k, p)(Tree k p) k (Tree \nk p) where Lf . Leaf Nd blkr . Node bl k r size :: Tree k p . Size size Lf =0 size (Nd s )= s In the \nsequel we will use the smart constructors leaf and node to construct weight-balanced trees, the view \nconstruc\u00adtors Leaf and Node to pattern match weight-balanced trees, and the function size to query the \nsize .eld. The balance function de.ned below maintains weight-bal\u00adance using single and double rotations \nunder the precondi\u00adtion that at most one subtree has changed size by at most one element and the original \ntree was in balance. The algo\u00adrithm is described in more detail in Adams [1]. balance bl k r | size l \n+ size r < 2= node bl k r | size r >. * size l = balance-left b l k r | size l >. * size r = balance-right \nb l k r | otherwise = node bl k r balance-left b l k r@(Node rl rr) | size rl < size rr = single-left \nb l k r | otherwise = double-left b l k r balance-right b l@(Node ll lr) kr | size lr < size ll = single-right \nb l k r | otherwise = double-right b l k r The balance operation is essentially the same as for search \ntrees. Only the implementation of the rotations is more elab\u00adorate since they have to maintain the semi-heap \nproperty. Figure 6 displays the possible cases for a single rotation to the right. Since a single rotation \ninvolves two nodes and since each node may dominate one of two subtrees, we must distinguish four di.erent \ncases. The only problematic case is the last one, where we have to perform one additional match to determine \nthe top binding. In general, b1 is the new top binding i. key b2 > k1 and prio b1 prio b2. The four cases \nfor the left rotation are symmetric: single-left b1 t1 k1 (Node b2 t2 k2 t3) | key b2 k2 . prio b1 prio \nb2 = node b1 (node b2 t1 k1 t2) k2 t3 | otherwise = node b2 (node b1 t1 k1 t2) k2 t3 single-right b1 \n(Node b2 t1 k1 t2) k2 t3 | key b2 > k1 . prio b1 prio b2 = node b1 t1 k1 (node b2 t2 k2 t3) | otherwise \n= node b2 t1 k1 (node b1 t2 k2 t3). Double rotations are implemented in terms of single rota\u00adtions. double-left \nb1 t1 k1 (Node b2 t2 k2 t3) = single-left b1 t1 k1 (single-right b2 t2 k2 t3) double-right b1 (Node b2 \nt1 k1 t2) k2 t3 = single-right b1 (single-left b2 t1 k1 t2) k2 t3 Remark 4. Since a double rotation is \nde.ned in terms of two single rotations, at most two additional matches are required. Perhaps surprisingly, \none can show that only one additional match su.ces. A direct implementation of the double rotations is \nleft as an exercise to the reader. It remains to adapt the implementation of Section 5 to balanced trees. \nThis can be done by a simple renaming: occurrences of the constructors Start and Loser in patterns must \nbe replaced by Leaf and Node; occurrences in expres\u00adsions must be replaced by leaf and balance. The smart \ncon\u00adstructor node can be used instead of balance if the shape of the tree has not changed (as in the \ncase of adjust) or if the tree is known to be balanced (as in the case of from-ord-list). Let us conclude \nthe section with a brief discussion of the running times of the various operations. For simplicity, we \nassume that we are working in a strict setting. Weight\u00adbalanced trees have a height that is logarithmic \nin the num\u00adber of elements. Consequently, the dictionary operations (lookup, insert, and delete) and \nthe priority queue opera\u00adtions (Min) have a worst-case running time of T(log n). The conversion functions \nfrom-ord-list and to-ord-list are both linear in the number of bindings. Finally, the range query at-most \ntakes T(r(log n - log r + 1)) time where r is the length of the output list the next section contains \na de\u00adtailed analysis. The following table summarizes the running times: Constructors and insertion Destructors \nand deletion \u00d8 T(1) Empty T(1) {\u00b7} T(1) Min T(log n) insert T(log n) delete T(log n) from-ord-list T(n) \nObservers Modi.er lookup T(log n) adjust T(log n) to-ord-list T(n) at-most T(r(log n - log r + 1)). \n 7. ANALYSIS OF RANGE QUERIES The range query at-most is a so-called output-sensitive al\u00adgorithm, that \nis, its running time is not only governed by the total number of bindings in the tree but also by the \nnumber of bindings it returns as a result. To estimate its running time we have to determine the number \nof nodes that must be inspected to return r outputs. A general observation is Figure 6: A single rotation \nto the right (-8 represents the winner; b1 b2 is shorthand for prio b1 prio b2). that whenever a player \nenters the output list, we must addi\u00adtionally check all the players who have lost to this particular \nplayer. Consider the pennant of Figure 3. If Lennart is se\u00adlected, we must check Phil, Erik, and Mary. \nIf Phil is also selected, we must additionally check Simon and Richard. The structure becomes more apparent \nif we turn the bi\u00adnary semi-heap into a multiway heap. The dominated sub\u00adtrees become children and the \nnon-dominated subtrees be\u00adcome siblings. Figure 7 displays the tree thus obtained. This transformation \nis an instance of what is known as the nat\u00adural correspondence between binary trees and forests, see \nKnuth [12]. To simplify the analysis let us assume that the original trees are perfectly balanced as \nin our example, so that we have a total number of n =2h bindings. In this special case we obtain as the \nresult of the transformation a so-called binomial heap [21]. Now, in a binomial heap with n = 2h elements, \nwe have one node with h subtrees (namely the root), 20 nodes with h - 1 subtrees, 21 nodes with h - 2 \nsubtrees, ..., 2h-2 nodes with 1 subtree, and 2h-1 nodes with 0 subtrees. Summing up and adding one for \nthe root we obtain a total of n nodes: 01 h-2 h-1 n = 1+ h +2\u00b7 (h - 1) + 2\u00b7 (h - 2) + \u00b7\u00b7\u00b7 +2\u00b7 1+2\u00b7 0. \nUsing the binary logarithm we can rewrite the above identity into the following form: n-1 n =1+ h +(h \n- 1 -Llg kJ). k=1 On the right-hand side we have a sum with n +1 summands. Now, if we only sum up the \n.rst r + 1 summands, we ob\u00adtain the desired maximum number of successors of r nodes. Consequently, the \nworst-case running time of at-most is pro\u00adportional to r-1 1+ h +(h - 1 -Llg kJ), k=1 for 1 <r n. To \nestimate the asymptotic growth of this function we use the formula m Llg(m+1)J+1 Llg kJ =(m + 1)Llg(m \n+ 1)J- 2+2 k=1 and calculate r-1 1+ h +(h - 1 -Llg kJ) k=1 Llg rJ+1 = 1+ h +(r - 1)(h - 1) - (rLlg rJ- \n2+2) Llg rJ+1 = r lg n - r - rLlg rJ +2 = r(lg n - lg r) + T(r). Thus, if r is small, we have a logarithmic \nrunning time. The running time eventually becomes linear as r approaches n. Let us conclude the section \nby noting that priority search pennants answer range queries less e.ciently than priority search trees, \nwhich support them in T(log n + r) time [5]. The reason is simply that the heap property is stronger \nthan the semi-heap property: in the case of binary heaps at most two additional elements must be checked \nfor every element that enters the output list. As an aside, this also shows that binomial heaps, which \nare essentially sequences of semi\u00adheaps [8], are less well-suited for answering range queries.  8. RELATED \nWORK Priority search queues. We have already commented on the relationship between priority search pennants \nand Mc\u00adCreight s priority search trees [14]. Let us brie.y summarize the main points. Priority search \ntrees are restricted to bal\u00adancing schemes where the number of rotations per update is bounded by a constant. \nBy contrast, our methods works with arbitrary balancing schemes. The asymptotic running times of the \n.nite map and the priority queue operations are the same for both approaches. However, priority search \ntrees support range queries more e.ciently. As an aside, priority search trees should not be confused \nwith cartesian trees or treaps, which are also a combination of search trees and priority queues [22]. \nIn a priority search tree each node is labelled with two keys, the key of the binding and an additional \nsplit key, whereas in a treap the key of the binding serves as the split key, which completely determines \nthe structure of the treap. Tournament trees and pennants. Tournament trees and loser trees already appear \nin Knuth s TAOCP series [13]. The term pennant was coined by Sack and Strothotte [20] to denote topped, \nperfectly balanced trees (we do not require the trees to be perfectly balanced though). Pennants are \nwidespread: Sack and Strothotte employ them to design algorithms for splitting and merging heaps in the \nform of left-complete binary trees, Okasaki [15] uses pennants as a fundamental building block for data \nstructures modelled after number systems, pennants underly binomial heaps [8], and they are useful for \nanalysing red-black trees [7]. Dijkstra s algorithm. Using priority search queues we were able to implement \nDijkstra s single-source shortest-paths al\u00adgorithm in a purely functional way. Previous formulations \nlike that of King [11] relied in an essential way on stateful computations. King writes: . . . if a purely \nfunction solution exists for these algorithms [Dijkstra s and Kruskal s] it will prob\u00adably involve using \na state-encapsulating combi\u00adnator. Perhaps surprisingly, by using a di.erent abstract data type priority \nsearch queues instead of priority queues we obviate the need for state. We feel that the resulting code \nis much clearer than the state-based formulation. Views. Views have originally been introduced by Wadler \n[23]. Later the idea was .eshed out into a proposal for an extension to Haskell [4]. Okasaki slightly \nsimpli.ed the pro\u00adposal and adapted it to Standard ML [16]. A recent paper by the same author [18], where \nOkasaki strongly advocates the use of views, revived my interest in this language feature. 9. CONCLUSION \nPriority search queues are an amazing combination of .\u00adnite maps and priority queues in that they support \nboth dictionary and priority queue operations. Building upon the metaphor of a knockout tournament we \nhave developed a simple, yet e.cient implementation technique for this ab\u00adstract data type. In developing \nthe code the concept of views was tremendously helpful: views enhanced both the read\u00adability and the \nmodularity of the code. We have presented   Erik 2 Mary 6 Simon 5 Richard 7 Charles 4 Warren 8 Figure \n7: The multi-way heap corresponding to the binary semi-heap of Figure 3. two applications of priority \nsearch queues: a purely func\u00adtional implementation of Dijkstra s single-source shortest\u00adpaths algorithm \nand an e.cient implementation of the .rst\u00ad.t heuristics for the bin packing problem. We hope to see further \napplications in the future. 10. REFERENCES [1] S. Adams. Functional Pearls: E.cient sets a balancing \nact. J. Functional Programming, 3(4):553 561, October 1993. [2] G. Adel son-Vel ski.i and Y. Landis. \nAn algorithm for the organization of information. Doklady Akademiia Nauk SSSR, 146:263 266, 1962. English \ntranslation in Soviet Math. Dokl. 3, pp. 1259 1263. [3] W. Braun and M. Rem. A logarithmic implementation \nof .exible arrays. Memorandum MR83/4, Eindhoven University of Technology, 1983. [4] W. Burton, E. Meijer, \nP. Sansom, S. Thompson, and P. Wadler. Views: An extension to Haskell pattern matching. Available from \nhttp://www.haskell.org/development/views.html, 1996. [5] O. Fries, K. Mehlhorn, S. N\u00a8aher, and A. Tsakalidis. \nA log log n data structure for three-sided range queries. Information Processing Letters, 25(4):269 273, \nJune 1987. [6] L. J. Guibas and R. Sedgewick. A dichromatic framework for balanced trees. In Proceedings \nof the 19th Annual Symposium on Foundations of Computer Science, pages 8 21. IEEE Computer Society, 1978. \n[7] R. Hinze. Constructing red-black trees. In C. Okasaki, editor, Proceedings of the Workshop on Algorithmic \nAspects of Advanced Programming Languages, WAAAPL 99, Paris, France, pages 89 99, September 1999. The \nproceedings appeared as a technical report of Columbia University, CUCS-023-99, also available from http://www.cs.columbia.edu/~cdo/waaapl.html. \n [8] R. Hinze. Functional Pearl: Explaining binomial heaps. J. Functional Programming, 9(1):93 104, January \n1999. [9] R. Hinze. A simple implementation technique for priority search queues. Technical report, UU-CS-2001-09, \nUniversiteit Utrecht, March 2001. [10] S. Huddleston and K. Mehlhorn. A new data structure for representing \nsorted lists. Acta Informatica, 17:157 184, 1982. [11] D. King. Functional Programming and Graph Algorithms. \nPh.d. thesis, Department of Computer Science, University of Glasgow, March 1996. [12] D. E. Knuth. The \nArt of Computer Programming, Volume 1: Fundamental Algorithms. Addison-Wesley Publishing Company, 3rd \nedition, 1997. [13] D. E. Knuth. The Art of Computer Programming, Volume 3: Sorting and Searching. Addison-Wesley \nPublishing Company, 2nd edition, 1998. [14] E. M. McCreight. Priority search trees. SIAM Journal on Computing, \n14(2):257 276, May 1985. [15] C. Okasaki. Purely Functional Data Structures. Cambridge University Press, \n1998. [16] C. Okasaki. Views for Standard ML. In The 1998 ACM SIGPLAN Workshop on ML, Baltimore, Maryland, \npages 14 23, September 1998. [17] C. Okasaki. Functional Pearl: Red-Black trees in a functional setting. \nJ. Functional Programming, 9(4):471 477, July 1999. [18] C. Okasaki. Breadth-.rst numbering: lessons \nfrom a small exercise in algorithm design. ACM SIGPLAN Notices, 35(9):131 136, September 2000. [19] S. \nPeyton Jones and J. Hughes, editors. Haskell 98 A Non-strict, Purely Functional Language, February 1999. \nAvailable from http://www.haskell.org/definition/. [20] J.-R. Sack and T. Strothotte. A characterization \nof heaps and its applications. Information and Computation, 86(1):69 86, May 1990. [21] J. Vuillemin. \nA data structure for manipulating priority queues. Communications of the ACM, 21(4):309 315, 1978. [22] \nJ. Vuillemin. A unifying look at data structures. Communications of the ACM, 23:229 239, 1980. [23] P. \nWadler. Views: a way for pattern matching to cohabit with data abstraction. In Fourteenth Annual ACM \nSIGACT-SIGPLAN Symposium on Principles of programming languages, 1987, pages 307 313. ACM Press.   \n\t\t\t", "proc_id": "507635", "abstract": "This paper presents a new implementation technique for priority search queues. This abstract data type is an amazing blend of finite maps and priority queues. Our implementation supports logarithmic access to a binding with a given key and constant access to a binding with the minimum value. Priority search queues can be used, for instance, to give a simple, purely functional implementation of Dijkstra's single-source shortest-paths algorithm. A non-technical concern of the paper is to foster abstract data types and views. Priority search queues have been largely ignored by the functional programming community and we believe that they deserve to be known better. Views prove their worth both in defining a convenient interface to the abstract data type and in providing a readable implementation.", "authors": [{"name": "Ralf Hinze", "author_profile_id": "81332504302", "affiliation": "Utrecht Univ., Utrecht, The Netherlands", "person_id": "PP43126402", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/507635.507650", "year": "2001", "article_id": "507650", "conference": "ICFP", "title": "A simple implementation technique for priority search queues", "url": "http://dl.acm.org/citation.cfm?id=507650"}