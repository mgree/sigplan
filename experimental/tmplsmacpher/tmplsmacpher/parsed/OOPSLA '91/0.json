{"article_publication_date": "09-01-1991", "fulltext": "\n KEYNOTE Phoenix, Arizona 6-77 October 7997 Object Orientation and Transaction Processing: Where Do \nThey Meet? Keynote speaker: John Tibbetts, Kinexis This is my first time speaking at OOPSLA and I must \nconfess to some apprehension. I m not apprehensive about giving a speech; I do that all the time. Usually, \nhowever, I get up in front of transaction-oriented crowds and tell them about objects. My basic message \nto them is Speed up. Here I have a different challenge. I m talking to object-oriented people about transactions, \nand my message, at least in part, is going to be Slow down. And that s a message I m not used to delivering. \nMy goal is to try to make the transaction world and object world a little less like strangers to each \nother. And strangers they are. They dress differently, come into work at different times, go to different \nrestaurants for lunch, have different ideas about what business is, and very different ideas about the \nroles of computers in business. But it s becoming quite apparent that, especially in the last year, there \nis increasing interest within the object community to begin participating in commercial-grade software. \nThe object journals <are filled with articles about objects being applied to real-world applications. \nWhy is that? Because there s a lot of commercial-grade, real-world money out there that s going to be \nneeded to fuel the continued growth of this technology. So our first part of this talk will be trying \nto get a handle on what real- world software is all about. The body of the talk will be a detailed discussion \nof exactly where I believe that objects fit into this definition of real-world software. And finally \nwe ll take a pass at guessing at what the future will bring. REAL WORLD SOFTWARE Real World Software \n Figure 1 Perhaps real-world software is too imprecise a term. For this group, real-world software would \ncertainly include things like compilers, environments and tools. But for the purposes of this talk I \nm referring to the other real world: the world of applications software that provides business solutions. \nFigure 1 shows estimated 1990 US software vendors worldwide solution sales, broken out by solution category. \nNotice the tick marks on the x- axis: Each tick represents 200 million dollars. Those two largest bars \non the top, Accounting and Manufacturing, contribute sales of 1.1 billion dollars apiece. The total solutio~~s \nmarket is about 12.7 billion dollars. Let s stop for a moment and imagine a similar chart for object \ntools and languages. I don t have numbers for that. But I do know that, at the most optimistic, the \ntick marks on an object tool market might be 10 million dollars. So right off the bat we can get some \nappreciation for why we want to talk about real- world software. We want to tap into those 200 million \ndollar ticks! Now let s return to the chart again for a moment. I ve darkly shaded some of the bars which \nI m going to refer to as core software. The lightly shaded bars I ll call support software. Core software \nis software that directly models the life of a company. It is the life blood of a company: virtually \nall businesses need Accounting software to manage their money and Human Resource software to manage their \npersonnel, benefits, etc. And Manufacturing, Banking, Insurance manage the basic entities that are the \nlivelihood of those respective businesses. On the other hand, support software, like Word Processing \nand Project Management, is not not exactly the company s life blood, though it does enhance the productivity \nof individuals or groups performing their various activities. For the purposes of this talk, I mean by \nreal world software that subset of solution software that I ve called core software. Core software represents \nabout 90% of solution software, or about 11.3 billion dollars. Incidentally, this is only vendor-supplied \nsolution software. A great deal more software investment is in internally-developed solution software. \nWhen we examine the requirements of core software, we find that there are several: This software must \nbe commercial-grade, industrial strength software. After all, the data that it manages-and, less recognized-the \nfunction it provides, are primary corporate assets. It must have high durability and availability, often \nneeding to support 24-by-7 (24 hour per day by 7 day per week) operation. An industry analyst recently \nreported that when the reservation system for a major airline went down for 18 hours, the airline suffered \na loss of 5% of market share for 6 months. He added that this equalled a 5 JJE (jmnbo-jet-equivalent) \nin revenue. Core software needs to be rugged. It also needs to provide very robust access to large shared \ndutabases. In case you assume that this is no big deal with modern database technology, let s look at \nthe scale we re talking about. Large commercial TP systems may support disk farms of tens of terabytes, \nsupporting tens of thousands of users (Sabre supports 160,000 users), and processing hundreds of transactions \nper seconds. A State of California systems administrator complained to me last month that she couldn \nt figure how to satisfy her manager s downsizing edict when just one of 9-l 1 October 14 I her system \ntables spanned nineteen 3390 disk drives. Core software needs to support jumbo applications. Finally-and \nthis is the key to the $11.3 billion dollar core software market-such large concurrent applications need \nto be maintained by transactions to keep the system resources in synch. Since many people in this audience \nmay not develop commercial applications let me dwell briefly on transaction management. A transaction, \nalso called a unit-of- work, is a program that either executes or it doesn t. You might be saying, I \nve got lots of programs that do that, but transactions are more disciplined than your average program \nthat sometimes bombs. If a transaction succeeds, all system resources that the transaction may have touched \nare updated to new states. If it fails (a rollback), no resources are updated. A transaction never appears \nto execute half-way. This all-or-nothing property of an operation is Maintained with Transactions Figure \n2 called integrity. Many people seem to confuse integrity with security but they are totally different \nattributes. Figure 2 shows a transaction processing environment. Three different users (or processes) \nare executing their transactions. A transaction manager provides an environment in which these transaction \nexecute. Typical transaction managers are IBM s IMS/TM, IBM s CICS, DEC s DECtp, NCR Top- End, and in \nnewer operating system design, such as the AS/400, in the operating system itself. The transaction manager \nmight be updating shared main-memory (storage), a database manager, some shared transaction queue, and \nperhaps even be communicating to a remote computer with its own transaction manager. If the transaction \nfails, all of 1991 Phoenix, Arizona these resources are left unaffected. If it succeeds all of the resources \nare updated. Commercial-grade systems need ruggedized two-phase commit procedures between remote resource \nmanagers to ensure that these resource updates happen correctly even if system components on either side \nfail during operation. I should point out that in simpler applications, this picture trivializes to an \napplication performing operations on only one resource manager, the database manager. But in richer environments, \nespecially those with distributed resources, you will find more comprehensive transaction management \nessential. WHERE DO OBJECTS FIT IN? Cross-Section of Information System Business Database Logic Figure \n3 To figure out where objects fit into this scheme, let s frost lay out a general road map of an information \nsystem. Figure 3 depicts a model of an information system. There s nothing revolutionary about this diagram. \nIn fact, it represents the ways we ve thought about these systems since their inception. At the back-end \nwe have some magnetic or optical surface that stores raw data and a layer of database software whose \njob it is to access that data and communicate with the applications s business logic.  Various Implementation \nTopologies Mainframe + Terminals Msinfrsmc + Fronlwarc / \\ Figure 4 At the front-end we have some form \nof display and a layer of software whose job it is to render the application activity for the display. \nThe business logic layer is where the real application work is done. Of course, real world systems are \nmuch more complex, with these layers recursing or being split among multiple processes. Nevertheless, \nthis diagram will serve as an analytic model to think through some interesting aspects of these systems. \nFigure 4 depicts some of the common topologies for an information system and how they relate to our road \nmap. The first segment shows a mainframe and its terminals. In this case all three software layers exist \nin a single environment. Another topology used increasingly in commercial systems offloads the user interface \ncomponents onto an intelligent front-end-PC or workstation. But probably the fastest evolving technology \nputs LANs on the front- end of corporate mainframes to act as enterprise servers. Notice that I show \nthe business logic split among different server levels. The actual placement of function is a crucially \nimportant issue in these emerging architectures, but it is outside of the scope of what we ll be addressing \ntoday. My fundamental beliefs about where objects fit in are expressed in Figure 5. The horizontal axis \nis the architectural cross-section that we ve already seen. The vertical axis represents the value of \nthe 00 paradigm. I believe that the value of 00 in the front- end is extremely high. In fact I consider \nit to be so high that it can be said to have unfair advantage Addendum to the Proceedings OOPSLA 91 \n UI Progression Towards Objects Object Paradigm Value Across Architecture Figure 5 over any other technique. \nOn the back-end, however, I believe the value of 00 in the database itself to be very low. And in the \nbusiness logic, it s something of a mixed bag. This hysteresis-looking curve in the middle indicates \nthat there are multiple approaches for building business logic that entail greater or lesser exploitation \nof object technology. I m going to spend most of the rest of this talk trying to justify what I ve set \nout on this chart.  USER INTERFACE You d expect little controversy in this group about object-oriented \nuser interfaces in 1991, what with Windows, Motif, OS/ZPM, etc. But this isn t quite the case. I say \nthat the 00 community is not being aggressive enough in how it exploits-even what it means by- object-oriented \nuser interfaces, or OOUIs. This goes double for OOUIs as they being applied in transaction processing. \nToo many people are confusing OOUIs with something much less: GUIs that are programmed with 00 languages. \nFigure 6 is a brief history of user interface technology and helps to position the difference between \nGUIs and OOUIs. Most of the history of human experience has involved users directly experiencing and \nmanipulating the constellation of physical objects that surround us. When computers came along, the first \ninterfaces were teletypes exploiting a command-line interface: user gives command, system responds. Most \nbusiness applications built in the last two decades have used Figure 6 formatted screen technology. \nThese applications use the terminal s rectangle of glass to create a form similar to the paper business \ndocuments that we have used for generations. Notice though that these are profoundly computer-driven \napplications that only periodically invoke the user for input. Character User Interfaces, or CUIs, have \nbeen pioneered by the spreadsheet companies. These still feature some aspects of formatted screens but \nintroduce menu bars, pull-downs and some windowing. GUIs are the state-of-the-practice interfaces. Some \npeople call them the WIMP interface: Windows, Icons, Menus, Pointers. We see them everywhere we look, \nbut in some senses they are just multiplexing traditional interfaces, not really presenting objects. \nIn a GUI, a window is viewer into an application. An icon is just a shrunken window; a double-click on \nan icon means to run the underlying application. There is no explicit contact with objects, except for \nthe fact that the developer is aware that the scrollbars, pushbuttons, etc are implemented as objects. \nAn OOUI, on the other hand, invites the user to explicitly recognize and manipulate the objects on the \nglass. In effect, it extends the world of objects all the way out to the user. An OOUI appears to be \na simulation, not a representation, of reality. We see OOUIs in many video games: My daughter plays King \ns Quest and points at a coin on the ground, picks it up and puts it in her pouch. We see them in draw \nprograms and in systems like Metaphor that support visual programming. The recently released SAA CUA \n9 1 manuals clearly document a UI architecture for OOUIs. The example I ll use is based on CUA 9 1. 9-l \n1 October 1991 Phoenix, Arizona In an OOUI, an icon is an object. Windows are simply viewers into the \nobject. A double-click tells the object to open itself. Note that there don t seem to be identifiable \napplications in an OOUI; there is merely a constellation of objects that a user can consider and mruiipulate. \nIn a very real sense, the user is the application. OOUIs are not GUIs, as I ve said, but there is a relationship \nbetween them. A GUI is a low-level UI abstraction; it s like GUI assembler. An OOUI utilizes a GUI for \nits set of componentry but adds to it a significant semantic content on the meaning of objects and user \ngestures. Formsets If OOUIs me new, applying them to transactional applications is even newer. Early \nwork was done by a group of CUA beta testers who got together to generalize some of the concepts associated \nwith database- and transaction-oriented applications. The basic problem they addressed was this: although \nthere are high-level UI controls for text (for example, a multi-line edit control is a full editor in \na window), there are no controls for representing databases or transactions. One proposal that has emerged \nis the notion of Fomisets. A formset is a high-level UI control used for transaction processing applications. \nNow, while the vrast majority of UI objects for a TP system represent sets of business documents (such \nas are used for order-entry, time cards, hiring an employee, docking a ship, or filing a tax return), \nthe job of a formset is not just to enter this type of data. The formset supports the creation, maintenance \nand handling of a simple or complex document during the entire life-cycle of that document. The first \nimplementation of a formset I m aw are is in a human resource system developed by a client of mine: Tesseract \nCorporation s HRMS Intuition. In this system formsets have been used to implement a vast number of business \ndocuments including personnel, payroll and benefits. Be w arned: don t confuse formsets with forms. Figure \n7 shows the relationship between the two. A form system is one in which the developer can implement a \nformatted screen interface by some process and then invoke that form definition from an application program. \nA great many systems have implemented forms over the years, ranging from Formsets Are More Than Forms \nFigure 7 rather clumsy coded forms of mainframe systems like CICS to very powerful paint-the-form systems \nthat we find by the dozens on PCs. The problem here is this: businesses don t process fomis, they process \ntransactions. A form is just a part of the entire transaction process. The standard application for a \nform system needs to deal with both the transaction processing logic and the substantial logic that controls \nwhich fomi is currently displayed, how we page through multi-page forms, what data edits are perfomied \nwhen all the forms have been entered, etc. By contrast, formsets sep arate transaction processing logic \nfrom all the form navigation and other multi- form activities. Formsets also encapsulate knowledge that \nrelates to the various stages in the transaction life-cycle; for example, error messages that some process \nmay have assigned to errors in the data and even notes that have been affixed to the formset by some \nreviewer of the data.  SAMPLE APPLICATION Let s walk through a sample application that uses an OOUI \nand formset. The application we ll describe is an order-entry and catalog system for a hypothetical video-cassette \ndistributor. The system is called VIDOR. The Ul architecture is based on the new CUA 91 Workplace Model. \nFigure A shows an OOUI with various objects on the screen. Around the edges <are objects for mail (Inbox, \nOutbox), trash, a printer, some general tiles, a three workareas. Think of a workarea as a part of your \n Open the Formset  Figure A Figure B desktop devoted to objects for a particular task. We see a workarea \nfor accessories, one for personal stuff, and the open workarea VIDOR. The VIDOR workarea, in turn, contains \nvarious objects: a pad of blank order-forms labelled Blank Formset, post-it notes, some pending documents, \na returned formset, and two output bins. In Figure B we tear off an order-form so that we can fill it \nout. Note that just as in the real world we could also have filled out the order form completely or only \npartially, and torn it off at a later period. In Figure C Figure C Filling Out the Item Page  Figure \nD we double-click on the formset icon to open it. We start filling it out. When the customer code field \nis set to Kinexis, it sets the formset object title (below the icon) to Kinexis. Note that, unlike in \nmany GUIs, the icon is still present (and highlighted with diagonal stripes) when we open it. That s \nbecause the icon represents the object and the open window is just one of possibly many simultaneous \nviews into that object. This particular object is a formset that contains three forms: an order header \nform, a repeating item form, and an optional instructions form. 9-11 October 1991 Phoenix, Arizona In \nFigure D we ve started filling out the item form and have opened another viewer; this time a catalog \nof available videos. After searching for a suitable movie (and watching the trailer for the movie, thanks \nto our multimedia attachment) we grab the film reel icon for Kiss Me Deadly from a list of films, drag \nit to the item form and drop it on the form. This operation drains the corresponding fields (video code \nand unit price) into the item form. (In smarter implementations this behavior can be implemented even \nby dragged objects that haven t explicitly known about each other in their development process. This \nrequires late binding, some method naming conventions, and optimally the ability to ask a flier icon \nwhat methods it supports (eg. Smalltalk #respondsTo:)). When we ve finished filling out the order, we \nSubmit the Trausaction  Figure E submit the formset. In Figure E we do this by grabbing the title-b&#38;u \nicon (TBI) that sits right next to the system icon. The TBI is new to CUA 91 and means self. Another \nway of thinking about it is that it is a synonym for the underlying formset object icon (which may be \ncovered up by other windows). The TBI is then dragged over and dropped on one of the output binds labelled \na Hold Bin. The difference between Hold Bin and the Priority Bin is that in one case a set of formsets \nare collected for subsequent processing, in the other it is submitted immediately. In either case, the \noutput bin first sends a message back to the formset to tell it to conduct any final cross-form semantic \ndata checking it may Sometime Later...lncoming Mail Figure F Handle Errors  Figure G wish to, then \nrender itself in its output message form, and finally return this message to the bin. The Hold Bin is \na container that can be inspected later and its alarm clock can be set to submit its documents at some \nspecific time. This might have been the end of this particular activity except a while later we get some \nmail. In our inbox (Figure F) we find the Kinexis formset returned to us. Upon opening it in Figure G \nwe find an Errors window informing us that the Kinexis credit limit has been exceeded and that we must \neither refuse the order to get management approval to proceed. In Figures H and I we open up a Stickum \nnote, write a message, glue it to the formset, and Stick On A Note  Figure H Then Send to Fred Form&#38;-Kinexia \n-c-n  Figure I mail it off to our boss, Fred. Note how much this entire process has simulated the \nphysical behavior of order processing, with a few electronic boosts like the catalog support. We ve found \nthat this physical-world paradigm is easy to learn. In addition some very difficult activities, like \npending a transaction in process and transferring it to another user, are made simple by the ability \nto stick things on these formsets and mail them off. Also note that when looking at the objects on the \nOOUI it s hard to distinguish where one application stops and another begins. As we le arn how to build \nthese systems more and more efficiently, that will be a measure of success. In a full workplace simulation \nthere is no application. The user is the application that directly manipulates the objects in the display \nuniverse to accomplish a business goJ. Now that we ve got an idea what it s like to use a formset, let \ns look at what is needed to create a formset definition. Four basic items need to be sent to a formset \ncontrol to define it for a particular use (Figure 8). An entity-relationship diagram, readily created \nby many CASE tools, is needed to train the formset as to what fields are in each form and what the relationships \nof the forms are to each other. ER diagrams readily handle the mapping and cardinality issues needed \nfor any business document that I ve seen, whether it is a three field timecard or a 50 page tax form. \nA field dictionary of some type is needed to provide more detailed behavior for each field. Is it numeric? \nhave a range? in a table? contain a check digit? etc. Another input item is a descriptor of the message \nformat that is created by the formset to be How To Define A Formset Figure 8 sent to the output bin \nwhen it is actually submitted for processing. Finally, some optional descriptors can make the formset \nformatting beautiful so that the document set looks just like the paper documents. Once the formset definition \nis complete this object can create instances of itself for use. These formset instances need to reference \nthe formset definition, contain the formset data, and possible contain error messages or notes. 00 AND \nDATABASE I ve asserted that the 00 community has undervalued 00 techniques at the front end by still \nSomething Wrong With This Picture OODBMS Rdati0lld Network Hierarchical  File Systems Figure 9 The \nReal Evolution Hierarchical High Bias Low Complexily High Performance Network Tuneable Bias High Complexity \nTuneable Performance  RA3tiOtlPl Low Bias Low Complexity Low Performance Figure 10 thinking GUI rather \nOOUI. On the other hand, they may be overvaluing objects as they relate to today s databases. Something \nis wrong with database evolution described in Figure 9. I see this diagram in virtually every article \nand every piece of promotional material I read on 00 databases. It shows a progression in data from tile \nsystems, through hierarchical, network, and relational, heading straight for the replacement paradigm: \nOODBMS. I do not believe this interpretation of database evolution. Figure 10 shows database evolution \nas I understand it. The earliest real databases-that is, systems for storing data that includes a data \nmodel-were based on the hierarchical model. The hierarchical model, as implemented in products such as \nDL/l and System 2000, allows data to be stored in fixed tree structures in the database. Since tree structures \noccur very frequently in nature, these structures are quite handy. Imagine a typical inventory application \n(and one that is used frequently in the database literature): a database with parts data and supplier \ndata. The stock room sees this data very naturally as a tree. There are Parts on top and for each Part \nthere may be one or many Suppliers. This perspective can be modelled beautifully and simply in hierarchical \ndatabase. Unfortunately, the purchasing department sees this data in quite a different natural way; they \nsee Suppliers 011top with each supplying one or many Parts. Both views are natural but don t match each \nother. Hierarchical databases have a high bias towards accessing the data along the lines that it has \nbeen placed in the tree. If you go with the flow tree-wise, you will find these databases to be simplest \nand fastest (because the trees can use pointers and clustering for very fast, single view accessing). \nIf you fight the flow, this model becomes almost worthless. To fix the problem so that both departments \ncould see their data naturally, database vendors came up with the network model. This model, which was \nrepresented in the Codasyl standard, allowed for network data structures to be created with multiple \nlinkages and allowed pointing in any desired direction. Many structures and linkages were provided for. \nI believe at last count, for example, there were six different linkage types between database segments. \nThe network model gave tuneable bias (you could implement whichever access paths you wanted) and got \ntuneable performance in turn. But it required high complexity to describe and use the database. The relational \nmodel solved the problem of linkages by simply throwing them away. Parts and suppliers became simple \ntables. If you wanted to view parts over suppliers the relational user would just join them that way \nat run time. The resulting characteristics have been very low bias (you could support any possible connection \nthat the data could support) and low complexity. However, it cost a lot because of all the runtirne work \nthat needs to be done. So the industry decided a long time ago now that they were willing to sacrifice \nperformance to get Addendum to the Proceedings OOPSLA 91 The Forgotten Feature Figure 11 But Databases \nNeed Objects Too. Rckenlial surkicnt Intcgli1y &#38; for Shed Procs Dumb Programs Figure 12 low bias. \nLow bias not only means that relational can support multiple conceptual views (as shown in Figure 11). \nLow bias environments also are simple to understand, especially for non-programming systems analysts. \nThis technology has driven functional analysis out of the systems analyst business. Systems analysis \nis now settled on data-oriented analysis which is compatible with this relational model. So ease of analysis \nis another critical feature. Finally, since relational databases are based on a formal model, formal \ntechniques have been used to optimize database access. The result is that the low performance has improved \nto the point of adequate performance. Now let s look at OODBMS. These databases <are based on the notion \nof object persistence. The structure of objects is shaped by their class hierarchies. These databases \nare a return to the hierarchical model (except now with stored procedures). In the marketing literature \nwe see claims of much higher performance over relational (100 times). But that is consistent with using \na hierarchy for its single conceptual view.  Where OODBMS Belongs I am not against OODBMS technology. \nQuite the contrary. The technology is not only good, it is essential for the object portions of commercial \napplications. To build an OOUI like the one I just showed you, you will absolutely need some rich object \npersistence. But I do believe this technology is being mis-positioned. Perhaps it is even mis-named. \nIts role is object persistence, not enterprise data. To that end I continue to see great applicability \nin its traditionally strong areas of CAD/CAM, repository management and multi-media. These tend to have \na single conceptual view: the object view. This is where OODBMS belongs. Does all this mean that we don \nt need the basic object insights at the back-end of a core application? I don t think so. I believe that \ndata needs objects too. Let s look at the trends in data. Figure 12 shows the evolution of the relationship \nof application and data. In early tile systems, we found smart programs and dumb data. Dumb data means \nthat the data in files knew absolutely nothing about themselves except for their content (that is, no \nmetadata). To counterbalance this, applications had to know everything about the data, including its \nformat, position, type, validity . . everything. As we moved into database systems, some metadata went \ninto the database. And what went into the database came out of the applications. Applications got mercifully \ndumber; data got smarter. Then databases got smarter yet: referential integrity checks that a foreign \nkey has a reference, stored procedures can validate field values. Every successive step added to the \ndatabase is pulled out of the application. Where does this lead? It leads to very smart data and very \ndumb programs. (Perhaps the end will be fully smart data and programs so dumb they disappear . . . or, \nas we said in the OOUI section, becorlze rhe user). How do we view this apparent contradiction between \nsticking to relational databases but needing smart data. For 199 1, use object wrappers around a relational \ndatabase (we ll see more about this in the next section). This preserves the simplicity and low bias \nof relational. Use OODBMS for object persistence for the object portion of the application (more to come \non this too). Where will the sm art-data controversy land? I don t know. There are two possibilities: \nsmartening up relational databases until they start behaving like objects, or formalizing object database \nso they become more malleable.  00 AND BUSINESS LOGIC As you can tell from my graph of 00 value (Figure \n5), the business logic section is indeteninate. We see a couple of approaches suggested: a conservative \napproach that doesn t derive much object value and an aggressive approach that does. We ll examine these \ndifferent approaches in this next section. But first, here at the premier object conference, you ve got \nto be asking: If we ve already got some 00 on the front-end, why use a non-00 approach at all? Why not \njust keep using the object paradigm until we hit the relational database?  Barriers to Using Objects \nWell, maybe you could do that. But let s look at some of the reasons you might not. The simplest reason \nis incredible predominance of traditional languages and techniques for building core applications. There \nare 3 million COBOL programmers. Something like 98% of the programmers in commercial I/S are COBOL programmers. \nThere are 90 billion lines of COBOL code. (Here s a depressing thought: that means about 500 million \nlines of Identification Divisions.) I have three clients who are large insurance companies. On average \nthey have 150 million lines of COBOL apiece, about 3500 COBOL programmers apiece (a few dozen C programmers), \nand productivity below the national average of 2000 lines of COBOL per programmer per year. (One of the \nthree had formed a Productivity Committee to remedy this but were having trouble meeting because of the \nscheduling conflicts of the committee s 92 members). These somewhat grim numbers mean that the vast majority \nof people who know how to write commercial applications (and want to write them) are trained in traditional \nlanguages and techniques. This in turn leads to a fundamental point. Integration of object techniques \ninto the commercial marketplace will be limited more by training and migration issues than any other \nsingle issue. There are more concrete problems than training. We have seen earlier the importance of \ntransaction managers iu core applications. These transaction managers act, in effect, as sub-operating \nsystems. In 1991 they still impose a functional view of applications and have major limitations on languages \nthat can interface to their special runtime systems. They always support COBOL, a few support PL/l, and \nthey re just starting to support C. Another reason to consider a non-00 approach has to do with the increasing \nemphasis on distributed and cooperative systems. These environments may span PC, LAN server, to Enterprise \nserver; each with a different operating system and language support. The one language that you can be \nsure to bind to any of them will be COBOL. This is a good reason to write the vanilla business logic \nin COBOL...so that it can port. Finally, there are all the other infrastructure issues. In Figure 13 \nI show AD/Cycle s famous Eight Blocks of Granite diagram. This diagram represents a pretty comprehensive \nlist of all the components that go into the application development lifecycle. Application Development \nInfrastructure Figure 13 In other words, it is a good diagram of the software construction infrastructure. \nNow, the dark dots I ve put on languages and generators (it really should be called environments) mean \nthat 00 has made strong penetration in these areas. The medium gray dots on Analysis &#38; Design, and \nApplication Development Platform mean that, despite the great strides in these areas the last few years, \nI question whether there is enough consensus and tool support for these components in the commercial \nenvironment. Tlie light gray dots on Knowledge-based Systems, Enterprise Modelling (requirements gathering), \nCross Lifecycle (project &#38; process management), and Testing and Maintenance, mean that I think these \nblocks are far from acceptable on commercial systems. Addendum to the Proceedings OOPSLA 91 [I31 Certainly \na few of these evaluations are arguable by one shading value. But my basic point is this: The infrastructure \nfor 00 development in commercial core applications is far from done. Is infrastructure that important? \nQuestion: how much infrastructure would you be willing to forego on the airline that brought you here? \nSome companies view their core applications as every bit as crucial to survival as you might consider \na well-maintained airplane. The Split-Paradigm World What do we do until we ve got infrastructure and \ntraining and integration to transaction managers and platform portability? Answer: we live in a split- \nparadigm world. Figure 14 shows that in this split world we exploit the object world near the front of \nApplication in Two Parts I A Object Environment A Transaction Services A Object Persislence A Database \nServices A Back-end Wrappers A Systems Management Figure 14 the system. This world gives us pure software \npower. It supports an object environment with persistence. This is where the OODB tits in. Toward the \nback of the object world are some wrappers to the other world that lies behind. Then at some (hopefully \nwell-defined) point we switch into the transaction world that gives us certifiable, industrial-strength, \ncommercial-grade integrity, security, and reliability. This world supports transactions, corporate data, \nand the sophisticated systems management required to support these systems. These two worlds communicate \nvia messages. I usually gives these messages a special name: PUOWs. This stands for proposed-unit-of-work. \nIts the job of the object world to give users great power and freedom and periodically to propose to \nthe backend that a corporate resource be changed. The transactional back-end disposes of the request \nbased on enterprise policy. What do the development teams on each side of the split need to learn to \nbuild these kinds of systems? The object developers need to learn how to view transactions and the elements \nof databases as objects. These protocols they will view as the wrappers that will do the direct communication \nto the transaction world. Transaction developers need to learn something too. Although they can continue, \nunder this model, to use their traditional language and transaction manager, they need to le arn how \nto write programs that handle messages, not screens. This is a tall order. For years, application programmers \nhave viewed their consumer as a human. Vast amounts of their code deals with screen formatting, paging, \nand keyboard watching. Now they have a machine as their user. They will eventually figure out that it \nis easier to write message-based programs. But it will take a while to readjust. On the way, they will \nstart realizing how profoundly our transaction definitions have beeu shaped by the 1920-character rectangle \nof a terminal screen. Notice what we have just done. By getting core application programmers to write \nmessage-based systems, we have started them on the path towards objects. Message-based systems implement \nthe encapsulation that is the real essence of object-based systems.  A More Aggressive Stance We have \nbeen focussing on the conservative side of the 00 value chart, where the value line drops fast. Once \non the path, most organizations will have (perhaps unwittingly) set the concepts on the path of more \naggressive object development. The steps that I see causing the application to move more towards the \nright <are the following: 00 extensions to traditional languages will start getting the programners to \nreap some of the pure programming benefit of 00. Properly implemented, these can do a nice job of wrappering \nthe application code for the object world 011 the front. 00 analysis and design will become a natural \nway of thinking once the developers are thinking in terms of objects. These techniques will become even \nmore accepted as CASE tools for these disciplines become more available. . Even further down the path \nis actually starting the process of classification of transactions and database elements within the transactional \nenvironment. I ve thought that this might be too aggressive for business developers, but then I saw the \nsystem build at Brooklyn Union Gas. Here is a case where very aggressive object classification and implementation \nhas taken place with very positive results. I m not sure this aggressive path is for everyone; it is \nmore risky but brings more reward. I believe that it takes some extraordinary talent and vision in the \ndevelopment shop plus plenty of management support. I spend most of my time getting companies to take \nthe conservative approach and to start down the path. Once objects are in there, they will grow.  THE \nFUTURE Is this split paradigm that I have laid out permanent or temporary? I tend to believe that it \nis temporary, but it may persist for the next half decade. Some of the forces that will drive to thoroughbred-00 \nare familiar to people here: increasing software complexity and the strong desire to recycle software. \nAnother reason may be less apparent but, I believe, even more compelling. The needs for a model for highly \ndistributed, even parallel computing will eventually drive the entire computing world to objects. This \nis the only software paradigm I know that can address the incredible complexity of these emerging environments. \nSo I believe the value chart will change to look like Figure 15. Ultimately the object paradigm will \noffer end-to-end unfair advantage over any other. But to get there we have yet to solve some problems. \nWe need full lifecycle support for the 00 paradigm. Eventual Thoroughbred 00 Environments Figure 15 And \nwe need not only the pieces but an end-to-end methodology that will support it. We need widespread training \nand migration strategies. And finally, we need transaction-aware, distributed, 00 operating systems. \nI know of projects like this well along the way at IBM, DEC, and NCR. I also know that they have years \nto go before completion. In the meantime, we need to acknowledge and to accept the split paradigm. Despite \nthe fact that it lacks the kind of aesthetic completeness we like, it works. And it works right now. \nWe can get the best tools on each side of the split to help us do our jobs. We can glue the sides together \nwith architected interfaces like SQL and some of the RPC initiatives now being standardized. This will \nhelp us to roll with some of the blows as these dividing lines inevitably change. And finally we can \nplan for-perchance dream of-a unified environment in the future.  \n\t\t\t", "proc_id": "143773", "abstract": "", "authors": [{"name": "John Tibbetts", "author_profile_id": "81100298725", "affiliation": "", "person_id": "PP39084571", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143773.143779", "year": "1991", "article_id": "143779", "conference": "OOPSLA", "title": "Object orientation and transaction processing: where do they meet?", "url": "http://dl.acm.org/citation.cfm?id=143779"}