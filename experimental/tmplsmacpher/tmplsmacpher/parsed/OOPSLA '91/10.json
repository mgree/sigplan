{"article_publication_date": "09-01-1991", "fulltext": "\n Phoenix, Arizona 6 -11 October 1991 Object Oriented (Domain) Analysis Authors: John Burnham Demlis \nde Champeaux This report describes the papers presented and the highlights of the two panels of the OO(D)A \nworkshop that was held in conjunction with OOPSLA 9 1. This workshop was organized by John Bumham, HP- \nSESD, Rebecca Wirfs-Brock, Tektronix and by Dennis de Champeaux, HP-Labs. We had the following submissions, \nwhere the indicates that this submission was chosen for a presentation: Alexander, R., OOA Clemenson, \nG. &#38; M. Williams, Integrated Object Analysis in ProKappa Cummins, F.A. &#38; C. Mullins, A Brkness \nOriented Approach to OOA Duke, R., 00 Domain Analysis Using Object-Z Fayad, M.E., Shlaer-Mellor s 00 \nMethod, Lessons Learned Firesmith, D.G., {Contributiort too long} Kerth, N., OOA, DA arzd the Whole Topic \nof Getting Prodrrcts Out the Door Kilov, H., Contracts in OOA: Precise Declarative Specifications of \nBehavior Lubars, M.D., C. Potts &#38; C. Richter, Domain Modeling for Evolutionary Requirements Formtlation \nMorris, R., OO(D)A Murphy, G., OO(D)A Nerson, J-M., OOA and OOD in the Bl4siness Class Project Seidewitz, \nE., OODA for Parametrized Software in Ada Sun, W., R. Ege &#38; C. Yu, Inheritance Constraints: Another \ninterpretation of Specialization . Tidwell, B.K., OO(D)A . Ward, E.S., OO(D)A A copy of the proceedings \nis available upon request (Dennis de Champeaux, HP-Labs, MS lU-14, 1501 Page Mill Rd, Palo Alto, Ca 94303.) \nTwo panels on respectively 00 analysis and 00 domain analysis complemented the program. We describe briefly \ntwo of the presentations.  0 Cummins, F.A. &#38; C. Mullins, A Business Oriented Approach to OOA They \ndescribe a large scale development effort of an unspecified business application. After reviewing the \nliterature (early Rumbaugh et al, Boo&#38;, Coad-Yourdon and Wirfs-Brock et al) they felt most comfortable \nwith the responsibility way of looking at objects. (Because of the business nature of the application?) \nSince this a large effort and they apparently have deep pockets-EDS-they decided to go into a little \ndetour and they developed their own 00 analysis tool!! Their way of doing analysis is decidedly driven \nby focusing first on system functionality and more specifically on business processes, business events \nand business functions. From there they identify entities, classes and relationships. The output of the \nanalysis is more than all these notions. They emphasize the construction of a consistent model using \nthe defined ingredients. They appear to be satisfied 00 (analysis) users: From a business standpoint, \nthe approach described here has been key to achieving an orderly approach on a major project. It allowed \na large development team to allocate the work among its members and avoid the possibility of much overlap \nand inconsistency in the development of system requirements.  Tidwell, B.K., OO(D)A He reported actual \nexperience on an approach to 00 design (which I have been pondering for a while). The output of an 00 \nanalysis is nearly executable, except for the actions specified in transition networks (and a few other \ndetails). Using this observation he had built an interpreter for families of transition networks. Thus \nafter replacing action specifications in transition networks by actual algorithms/ code, he can execute \nsuch a high level design. His next observation was that this execution often satisfied the performance \nrequirements. Consequently, there was no further need for a low level design and a subsequent implementation. \n The 00 Analysis panel The members of the panel: Don Firesmith, Advanced Software Technology Specialists, \nmoderator Fred Cummins, EDS AI Services Moh amed Fayad, McDonnell Douglas Missile Systems Company J-M \nNerson, Societe des Outils du Logiciel Boyd Tidwell, Software Technology and Tools This panel addressed \nthe following topics: *There are different recipes for doing OOA:- static first: objects, relations, \nobject behavior, object interaction-dynamic first: object behavior, object interaction, objects, relations-system \nfirst: context-system prototypical interaction sequences (Use Cases), . . . -system decomposition first: \nensemble, ensemble interaction, ensemble expansion, . . . Are there preferences? What are criteria for \nchoosing a recipe? . SA has a natural approach to large system decomposition: decompose high level processes \ninto smaller and smaller processes. What is the equivalent trick in OOA? . What can you say about the \ntransformation of the OOA output into the design phase? Phrased differently: Is there a process for turning \nformal specifications into design/implementations? And again: What does it mean to prototype an analysis \nmodel? Where does analysis stop and design begin. . The output of the OOA goes in two different directions: \n184 1 9-11 October - to the customer, to obtain a sign/off, an agreement that the specs correspond with \nthe requirements/ the envisioned system - to the designer, as a precise description of the intended \nsystem.  How does your approach meet their needs? . Any experience with OOA tools? What is the significance/ \ncrucialness of tool support for OOA? . Anything to say about tracing analysis results throughout the \ndesign and implementation? Responses: 1. First Speaker: Fred Cummins Many of these questions were covered \nin my talk. The first question: should static or dynamic analysis be first? Static first, looking at \nattributes first in preference to operations. But there is also the aspect of understanding the paradigm. \nPrototyping will aid in understanding the basic concepts of the problem. Question #2: Large system decomposition. \nStarting with business events and propagating them into entities using the responsibility/collaboration \napproach addresses the top-down nature of problems. At the low level you have trivial kinds of elements \nof responsibilities and collaborations which are the highly shared ones. I define generic interface definitions \nin terms of behaviors. As I propagate the collaboration/responsibility into the system, I either identify \nentities that I have already assigned that behavior to or I have to create it. When that behavior is \nalready in the system that gives me the low level sharing. Question #3: Transforming OOA to Design. Transformation \nof OOA to design phase is a natural transition from the responsibility/collaboration model to assigning \nmethods on classes. There is detail that we do not deal with at the analysis(logicaI) phase that we do \ndeal with in design. For example in the analysis phase we describe one to many relationships. In the \ndesign phase we have to create mechanisms such as indexes or collections that represent the relationship. \nI may go from simple entities to more complex structures in design. Question #4: Who gets the output \nof the analysis? What the customer sees is our understanding what the business is, what the entities \nare, what the events are and what the impact of these are on his business. The responsibility/collaboration \nmodel is not necessarily seen by the customer but it does provide rigor for design. Question #5: What \nexperience do you have with tools? My tool, OA Tool had to be database based. The meta model was simpler \nthan the thing we were trying to describe so the database was not difficult to implement as a relational \nmodel. Question #6: Any comments on traceability? Tracing analysis through out the system using our method \nis based on m aintaining the logical system which is generalizable across many implementations, while \nthe design is specific to each implementation. So we go back to the logical model if we are going lo \nm ake extension or changes. Our strategy would be to bring the logical model up to the level of new specification \nand let that drive the physical model again. Panel member #2. J-M Nerson Going from the bottom of the \nlist. Question #6. I would like to talk about the importance of tracing components. We feel that it is \nimportant to have some kind of tool to manage components. We are working on a librarian that would manage \nthe way we would enter and retrieve a component from the library of classes. Early in the development \nprocess it is important to keep track of every thing entered. To describe the components and have them \nentered into the database is the only solution to traceability. Question #4. Where does the notation \nof the method go to? It should go to the designer and the architect of the system. The end-user non-technical \nperson and/or manager should not receive models. It is too hard to train them in the notation. There \nshould be the capabilily to render the model in plain text. This is a feature we are working on. We failed \nin our attempt at trainiog the end user in our notation. Question # 1. Static or dynamic model first \nis a matter of taste. It also depends on the way the problem is phrased. (At the point slides were presented \nto explain these points. He used the Rumbaugh example of move a goose, fox, and bag of corn across a \nriver.) By its nature the problem is a dynamic one. There would be a tendency to define the protocol \nand the way information moves in the system before you would define classes. Looking at this problem \nand using my notation outlined in the position paper, we would focus on the primary objects and model \nthe communication channels used to send information to solve this problem. We favor the dynamic model \nfirst here because we know what the solution will be. If you don t known the solution ahead of time, \nyou should create the static model first. You would in this example define a freight class as an abstraction \nof boat, goose, grain etc. statically first specifying pre and post conditions and invariants that mapped \nthe constraints posed in the problem. An obvious invariant is that you don t want the corn to be eaten. \nThe invariant is not eaten . Starting from that point you would give the model to the implementor who \nwould then try to solve the problem coming up with a dynamic model. What we should start with first depends \non the problem and the ability that you have to solve the problem. I would like lo pose a question. Is \nit easier to manage static information in the model than the dynamic information in the model? I have \nfound it easier to manage static data, but I would like more information about this.  Panel speaker \n#3. Mohamed Fayad I will take the questions in order. Question # 1: Must of the people in the Object \nOriented market are not really software engineers. In software engineering we would start with the problem. \nTo start with static or dynamic model is not really the issue. What we are trying to do with the requirements? \nRamamoorthy has defined the requirements to be in two categories: functional and non-functional. Most \nof the 00 models do not address the functional model. Other people divide the requirement into a system \nrequirement and an environment requirement. Most of the 00 methods on the market deal with the system \nrequirement not with the problem requirement. This is a very important issue. I found that Zukerman(?) \ndivides requirements into a problem and system analysis requirement. The point I am trying to make is \nthat most people only focus on the system requirement. The 00 methods do not deal with problem analysis. \nInstead of defining the problem you get a lot of objects which is not really a problem definition analysis. \nThis is not a formal analysis. I have defined several criteria that when applied will yield a complete \nproblem analysis. Representation criteria, requirement analysis criteria, 00 criteria, Software Engineering \ncriteria, and project need criteria. For example, the 00 representation has to have descriptive adequacy \ni.e. there should be only one way to describe a concept. It has to have an expressive power i.e. it has \nto be able to express the problem in that representation without ambiguity. It h,as to have procedure \nadequacy, i.e. the ability to divide the problem into subproblems. The notation has to be very efficient. \nThere is lots of notation which is very confusing in the market place. One methodologist completely changed \nthe meaning of dat tilow diagrams. He put control flow in it. What is going on here? I would like to \nshare this criteria with you. Question 5. We have experience with Teamwork. It works great with Shlaer-Mellor. \nWe have experience with Adagen but it did not have a database and could not do consistency checking. \n(Note from the audience: that has been corrected).  Panel speaker #4 Tidwell Question 1. I use Shlaer-Mellor \nand so naturally I do static first. I have tried both ways. The rational that I come up with for doing \nstatic first is that 00 should really be called data oriented. In the system it really is the data that \nyou build your objects around. OOA is really a solution in data. That is the way they bill it, and I \nreally believe that. In an OOA system, you have very little compared to a traditional system delinition. \nAll the information is in the data and in tables of data. The problem then becomes to manages all that \ndata which is an easily solvable problem, of course. The idea is to get all the data right early in the \nsystem definition. You avoid the problem of creating processing based on incorrect data and the vicious \ncycle the results form iterating over incorrect processes and incorrect data. Also, the more you understand \nthe problem the more the data is reduced in size and complexity. 00 can be thought of as a general table \ndriven approach to solving a problem. Question 2. The decomposition of large problem into smaller manageable \nproblems is a real concern with OOA. We have carried out an informal decomposition based on Structured \nAnalysis Techniques. That seems to work for us. We break up our system functionally, [86 1 9-11 October \ni.e. the system is broken into subsystems which have the property of high cohesion internally, and low \ncoupling to other subsystems. One client has come up with high level OOA models. They view subsystems \nas objects. It is not rigorous. Attributes turn out to be objects. Looking at the system as flat and \nall mapped out makes sense to me. I don t really understand it. It is not worked out but I think it is \nworth pursuing. Question 4. Finally, I would like to discuss the training of managers and customers to \nunderstand what you are doing and how that relates lo the programmers. To really do the method requires \nformal training. But to just understand the model and to see how it maps to requirements does not require \ntraining. But as they ask questions about the functions, they learn the concepts and can be intuitively \nunderstood, and the end-user can tell you where your model is wrong. General discussion. Question: For \nthe Shlaer-Mellor method, a superclass where the common attributes are factored out, how do you factor \nout common processing and common life cycle specification i.e. inheritance? Is that important or necessary? \nBoyd Tidwell responds: Where you find that is in the supertype, subtype, superclass, subclass definition. \nIn the information model you put in the attributes accordingly. In the state model, you have to look \nat each supertype, subtype model and you have to decide at what level you are going to model it at. In \nmost cases the super type has most of the processing. In that case the state model models the super type. \nConversely, when the processing is mostly in the subtype the factoring is done that way so that the state \nmodel works for the subtype. For that case, we develop two sets of state models with an external event \nto the subtypes. Because of the way the model works it makes a determination based on type where to send \nthe event. You always send the event. And it is only the problem of finding out where the event goes. \nThere is no auswer for the question about the superclass, subclass issue except that the object needs \nto find out information from itself. This is a little strange but using the modeling techniques it still \nworks out. Question: What the previous question was really addressing was the issue of reusability. Shlaer- \nMellor really don t address that issue. It is not easy to do that common state. We have redundancy that \nis hard to eliminate. There are so many dataflows that it is hard to identify common processes. It I \nhad a karge project, I would create a subtype etc. But this is not problem analysis. Shlaer-Mellor does \nnot handle that. Question: I was disappointed in two aspects of the Shlaer-Mellor method. Inheritance \nand polymorphism are not really defined. These concepts are not exploited. They encourage you to m ake \nflat models. But these concepts need support not discouragement. Question: With OOA/D we are moving towards \na seamless approach. Incremental recursive life-cycles are in vogue. But what is the optimum overall \nlife- cycle? If we are not using the water fall life cycle with its built in bottle-neck review cycles, \nwhat ought we be using instead? Response: Boyd Tidwell On a typical project, we start with the infonnation \nmodels before we do the state models. (interruption: do you really do all of the infonnation models before \nyou do any of the state models?) Really, it is per information model. It is not the typical water- fall \napproach. All the models are highly modifiable. For example, I had left out an object. I fixed all of \nthe models and put it into the implementation all within two or three hours. Most of the work is done \nat the information model level. At least 50% of the effort is in that phrtse. Question: What is the affect \nof incomplete requirements? Response: Boyd Tidwell We get to ask better questions. Some problems are \nuncovered just by completing the information model. By the time all of the models are complete most of \nthe requirements are nailed down. Just follow the Shlaer-Mellor method, and the issues will work out. \nIf you break the rules, it fails. What we like about the method is that if you follow it by the book, \nit works and it does not depend on our individual talent. Response to the seamless nature of the paradigm \nquestion. There is really strong contention between what should be se amless and what should not. Steve \nMellor is very strong in his support of there being a very different notation for design separate from \nanalysis. However, Boyd got around this by basing his implementation strongly on OOA. This is not being \ndone at Prqject Technology in the same way. Peter Coad and Ed Yourdon argue that you just expand and \nextend the object models to design and implementation. That is really an opposite view Addendum to the \nProceedings OOPSLA 91 points. Now I believe there is a strong distinction between analysis and design \nas best expressed in McMenamin and Palmer in Essential System Analysis . During analysis you trying to \nfind what the problem is and what your system is trying to do with regard to implementation technology. \nDuring design you have to put in implementation concerns. The main goal of Object Oriented is to have \nyour resulting code reflect your problem domain as closely as possible. We should let analysis impinge \non design as much as possible. But you need to play freely with the analysis components to achieve performance \netc. But there should be a common mind set and strong connection especially as you go on to Domain Analysis. \nResponse #2 Firesmith. I backed off from separating Analysis and Design. During implementation design \nI would add on help classes to the logical design. I do not make a strong barrier between analysis and \nlogical design. I make a stronger barrier between logical design and implementation design. And now I \nget a good traceability using this model. Response #3 You are making a fundamental hypothesis here. The \nstructure of the problem is a good structure to implement a solution. This has to be examined. Response#4 \nIn water fall, all analysis is done first. In 00 we would like to do a little of analysis and then a \nlittle design. But if you don t do all of the analysis first, you will not get the scope of the problem. \nFor example in modeling a company there is a real shift in what is an association. At first the model \nsays that employee is an association. But in the department, the employee is an object. And even further \nchanges when addressing employees as customers etc. Question: In the ATM example we are exposed to cooperation \nobjects that affect the users account. My question is how do you use pre and post conditions to deal \nwith the locality of the dam? How do predicates play in this model? Response: Pre and post conditions \nare not enough. You need a class invariant. They check that when a message is sent and executed it will \nconform to certain conditions. But the real ability for distributed systems to to be able to define invariants \non attributes that are maintained across various actions of the system. The class invariant is the only \nway to [ 971 maintain this consistency. Since it is inherited it cannot be violated by using inheritance. \nThere could be a static checker to check for a consistent system. Q: How can class invariance solve the \ndistributed system. R: But the predicate can relate to distant objects. R: In last years proceedings \nthere is a paper on contracts by Richard Hillman, et al. It is different from what Bertrand Meyer or \nI (Rebecca Wirfs- Brock) have talked about. It describes invariants that accomplish this for a set of \ncollaborating objects using pre and post conditions and invariants.   0 The 00 Domain Analysis panel \nThe members of the panel: Don Firesmith, Advanced Software Technology Specialists, moderator Haim Kilov, \nBellcore Gail Murphy, MPR Teltech Ltd Edward Seidewitz, Goddard Space Flight Center Elaine Ward, Mitre \nCorp This panel addressed the following topics: . Domain analysis, DA, is an evolving discipline. OODA \nis still in statu nascendi . Can you propose a definition? -input = ? -output = ? -process = ? -goals \n= ? What are the communalities and differences between OOA and OODA? How does OODA impact OOA, OOD? . \nHow do you know when you are done with OODA? Who are the consumers of OODA? 0 Any ideas for a tool that \nsupports OODA? . Can you share any experience about OODA? First question Panel member #l. My definition \nis simple and radical. An application system is a computer system in support of one activity. A parameterized \nsystem is a set of independent components that can be configured in some framework to produce many application \nsystems. Systems analysis is coming up with a specification for an application system. Domain analysis \nis the specification for a parameterized system. This parameterized system can cover a wide domain. This \nis naturally object oriented. You are trying to specify a wide ranging domain rather than the functionality \nof some specific domain. Just classifying and organizing this knowledge has defied any other approach. \n Panel member #2 Haim Kilov My definition is controversial. On input you have the slippery real world. \nHere is an example. In your implementation use a master file . But what is this master file . So the \ninput is this mess and the output is a set of interrelated object classes. The goal is to understand \nthe input, clean up the mess and get a reasonable output that can be understood by the developers and \nthe subject matter experts who understand what they want to do. There exists a very serious medicine, \ngive the customer exactly what they said, not what they ment. This medicine can only be used once. Panel \nmember #3 Gail Murphy The goal of domain analysis is to find reusable components that can be used, and \nthat encapsulate the domain knowledge that exists. From the view point of standards used to build these \ninteroperable systems, there has to be some understanding at a formal level of what the domain is. The \nprocess is iterative. It never ends. There has to be a way to manage the versions of the domain analysis \nthat exist. The input will be information that you can extract from your domain experts, the background \nthat you can find, user modeling, what exists in the minds of the experts. The output will consists of \nclass descriptions, relationship diagrams, structure analysis and some executable form.  Panel member \n#4 Elaine Ward Our definition: the act of studying data and functionality, functional requirements for \na well defined problem area without paying attention to the specific application detail. Some examples: \nnaval planing, army info systems. Input: From people well versed in the functional area. Project artifacts, \nfunctional descriptions, prototypes. Output: The domain model. Process: Looked at in two ways. From \ngeneral to specific and from specific to general. In the first, requires a lot of money before the specific \napplication takes place. Management is not willing to put money first. In the second case Domain Analysis \nw<as done after the fact, which management was willing to pay for. The go al was reusability and a lower \noverall cost to system development. second part- If reuse is the prime driver of domain analysis, naturally \nif you do DA across app boundaries you get more benefit. With a large project you should do some just \nto get cost saving. But often this is not funded. People use DA to identify reusable objects. Second \nquestion: How do you know that you are done? Who is the consumer? How do you know that you did it right? \n Panel member #I. In our project, we set down high level requirements for our division and then asked \nwhich of these should our project handle. This was interesting because it was the first time that the \ndivision had a stated set of requirements. We were done when we have enough functionality to support \nthe different activities that our division was supporting. We were helped in that our activities are \nwell defined and we have a history of these kinds of activities. In the short term as we plan our releases, \nwe must complete enough functionality to support these releases. These constraints drove the scope of \nour process. Panel member #2 The consumer is the developer and the subject matter experts. The process \nis probably never done but at least there is a simple criteria that says when most of it is done. There \ncomes a time when you don t have many more questions to ask the subject matter experts. At tirst we know \nnothing, then we ask stupid questions, then we ask sm arter questions until finally the subject matter \nexperts cannot answer our questions any more. This is the critical point. It means that they don t know \nwhat they are doing. Things start going very quickly. Everyone starts to talk in the same language. Then \nwe start a new application. This is where reuse comes in. Things should work better and better. We are \ngetting there, but we are not there yet. Panel member #3 From our view point, OODA analysts and librarians \nare the consumer. In our case since management does not have a business plan, they can also be a consumer. \nThey can use an OODA model as input to a business plan. Funding is done on a project basis. It might \nbe a year in advance when you know that you will have to produce a product in a certain area. It is at \nthat time that you can seek funding to do the domain analysis.  Panel member #4 In my current assignment, \nmoving from the specific to the general we will look at all of the information systems that are already \nout there and derive our domain model from that. All the info model artifacts, behavior components and \nput that into the repository. Right now there is only source code in there and no body uses it. We put \nour Domain Analysis in there and in such a way that it will be used. Panel member #l clarification: To \nget really reusable components, they must be developed outside the framework of a specific project even \nthough that concept is not supported by our current funding model i.e. only specific projects are funded. \nThere are too many project specific concerns. Project money needs to be allocated to generalized software. \nBut you still have to convince the management that it will support the project. Panel member #2 My project \ncrosses project and its funding has been from differeut orgauizatious. Now all of the organizations want \nthe results of all of the effort, not just the part they financed. Third question:  Panel member 1 I \nwould like to have a tool to get my specs on-line, organize how the analyst look at those specs. This \nshould be tied to a configuration mechanism. All is connected together. Everyone gets a consistent view. \nIn our domain there are thousands of components. I don t need a library management system. What I do \nneed is the above described system one component of which is a library search and retrieval system. Because \nof my domain, the application design has been fixed and what I want is a system that guides me through \nmy design giving me library components to choose from and library component parameters to specify. This \nguide through the library is much more than a keyword or other simple search a retrieve mechanism for \nthe library. This is manageable task because there are IO s of design components. Each design cUmpoueu1 \ncould have several library components that could satisfy it.  Panel member 2 Two answers. The simple \nanswer: use your brain. The second answer: if you have to struggle with a tool that hinders your thoughts, \nit has a negative value. Even more so than using an awkward language will hinder programmers. Panel \nmember 3 Graphical pictures, data dictionary and support for the whole life cycle. The tool must support \nlocation, understanding, and adaptability of the artifacts that you have. The tool needs a way to store \nexample instances to show how the artifacts work together and in what context they work together since \nthere may be operation artifacts that effect behavior. View points <arue important to capture. Panel \nmember 4 Nice to have tool support. There are no tools now to support us. We evaluated many tools, but \nthey did not support the methods they claimed to support. The graphical support might be there but the \nconsistency checking wasn t. The library needs links to look at models that are representative of certain \nfunctions in the applications. Last question: experiences in OODA. The moderator had an experience with \na very library of code and OODA. There are very many issues with this. Panel member 1 Even though OODA \nis tough, it is tougher when you are defining the procedures for the method at the same time as you are \nusing it. Subject matter experts are doing the domain analysis. This is a great advantage. The domain \nexperts know more about programming than the programmers know about the domain. Panel member 2 People \ndon t like to be trained in a new approach. But in the end they accepted it. Here, our subject matter \nexperts are different from the analyst. The negative aspects is the 5 inch thick book is a problem if \nit contains a few pictures and long lists of entities and relationships. There needs to be a top/down \nlayered presentation of the material. Panel member 3 Using domain entities and integrating them into \nthe the DA has been a very positive result. This effort yields a common language across different functional \nareas. The caution is that you do not take weight the behavioral aspects. It should be given the same \nweight as the entity model otherwise significant gaps can occur in the Domain Analysis. Panel member \n4 Money was not provided for DA. But I worked on lots of similar applications were the same. So DA happened \nby experience and a model was built on the side without our management team. Panel member 2 Behavior \nand information models are really the same. There should not be a special object model. There should \nnot be two models, one for objects and one for behavior. The information model is both a behavioral model \nand an entity model. a  Final remark The attendees of this workshop were strongly encouraged to submit \npapers to OOPSLA 92. The widespread adoption of the 00 paradigm hinges on well defined methods (and tools) \nthat cover the entire development lifecycle. 00 analysis and 00 design are still in catch up mode for \nthe development of medium to large size systems.  \n\t\t\t", "proc_id": "143773", "abstract": "", "authors": [{"name": "John Burnham", "author_profile_id": "81100305108", "affiliation": "", "person_id": "PP31073633", "email_address": "", "orcid_id": ""}, {"name": "Dennis de Champeaux", "author_profile_id": "81100265123", "affiliation": "", "person_id": "PP31034638", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143773.143798", "year": "1991", "article_id": "143798", "conference": "OOPSLA", "title": "Object oriented (domain) analysis", "url": "http://dl.acm.org/citation.cfm?id=143798"}