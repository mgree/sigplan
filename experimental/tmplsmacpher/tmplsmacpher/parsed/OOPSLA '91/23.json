{"article_publication_date": "11-01-1991", "fulltext": "\n Experiences in DBMS Implementation Using an Object-oriented Persistent Programming Language and a Database \nToolkit Eric N. Hanson+ Tina M. Harveyj Mark A. Roths Abstract The EXODUS database toolkit, and in particular \nthe E persistent programming language, have been used in two substantial database system implemen-tation \nefforts by the authors (the Ariel database rule system and the Triton nested relation DBMS). Observed \nadvantages of using a persistent pro-gramming language for database system implemen-tation include ease \nof implementation of special-purpose persistent objects used by the DBMS such as catalogs, data indexes, \nrule indexes, and nested relational structures. Other advantages of using E (a persistent version of \nC++) that are independent of the persistence issue are the usefulness of object- oriented programming \nin developing large software systems, and the utility of the Collection abstrac-tion in E. Observed disadvantages \ninclude (1) the inability to map the type system of the DBMS to the type system of the underlying programming \nlanguage while still retaining good performance for tEric Hanson is with the Artificial Intelligence \nTech-nology Office (WL/AAA-l), Air Force Wright Laboratory, Wright-Patterson AFB, OH 45433, and with \nWright State University. His work was supported in part by the Air Force Office of Scientific Research \nunder grant number AFOSR-89-0286. *Tina Harvey s work was done while with the Department of Electrical \nand Computer Engineering Air Force Institute of Technology. She is currently with the 7th Communica-tions \nGroup/DOWI, The Pentagon, Washington DC 20330. \u00a7Mark Roth is with the Department of Electrical and Computer \nEngineering (AFIT/ENG), Air Force Institute of Technology, Wright-Patterson AFB, OH 45433. ad-hoc queries, \nand (2) software engineering diffi-culties due to the distinction in E between database types and main-memory \ntypes. 1 Introduction It is well-known in the database community that implementing DBMS code is difficult \nand time-consuming. Recent research on persistent pro-gramming languages and other tools to support database \nimplementation has given hope that the burden of implementing DBMS code could be sub- stantially reduced. \nIn an attempt to simplify the implementation of two different prototype database systems (the Ariel database \nrule system [13, 141 and the Triton nested relational database system [15, 271) we have used the EXODUS \ndatabase toolkit extensively [7]. In particular, we have made significant use of the E programming language \nof EXODUS [24], a version of C++ [32] extended with persistent objects. This paper reviews the advan-tages \nand disadvantages of using a database toolkit and a persistent programming language (E) that we observed \nwhile implementing non-trivial DBMS soft ware. The next section describes the EXODUS toolkit. Section \n3 discusses the impact of persistence on our implementations, as well as issues related to the type systems \nof the DBMS and the underlying pro-gramming language. Section 4 discusses the impact of features of the \nlanguage and toolkit unrelated to persistence, including the impact of object-oriented programming, collections, \nand the EXODUS opti-mizer generator [12]. Section 5 covers issues related to performance, Section G briefly \nreviews related research, and Section 7 summarizes and presents OOPSLA 91, pp. 314-328 conclusions. \nWe now turn to the discussion of EX- ODUS.  Overview of EXODUS EXODUS provides some powerful tools \nto help automate the generation of application-specific database systems, including a storage manager, \nthe persistent programming language E, a rule-based query optimizer generator and a B+tree class generator. \nOne possible architectural framework for using EXODUS to build a database system is shown in Figure 1. \nThe EXODUS storage manager is accessed via procedural calls which allow creation and destruc-tion of \ndatabase files containing sets of objects, and iteration through the contents of files. Objects can be \ninserted in and deleted from a file at any off-set in the file, and explicit clustering of objects on \ndisk can be specified. The storage manager pro-vides procedures for transaction and version man-agement \n. The E programming language provided by the EXODUS toolkit is an extension of C++ with per-sistent objects. \nPersistence in E is implemented on top of the EXODUS storage manager. E extends C++ types and defines \na corresponding db type (database type) for each C++ and user defined type. These db types are used to \ndefine objects in the database. There are four kinds of db types in E: . fundamental db types -dbshort, \ndbint, db-long, dbfloat, dbdouble, dbcha.r, and dbvoid . dbclass, dbstruct and dbunion (every sub com-ponent \nof a dbclass must be of a db type) . pointer to a db type object . arrays of db type objects If the persistent \nkeyword is used before the dec- laration of a db type, EXODUS will map the persis- tent db variables \nto a permanent storage location. In E, a collection is an unordered set of objects. E also has a feature \ncalled generator classes which allows defining a generic template for a Q-+-style class. Customized classes \ncan then be declared us-ing the generator class name plus additional pa-rameters for customization. Collections \nare sup-ported in E using a built-in generator class called collection, which is invoked by collection \n[T] where T is any db type. A collection must be instantiated for a specific type before it can be used \nto declare collection objects. EXODUS provides a generator class for B+trees to allow straightforward \ncreation of indexes for different data types. A typical way to create an indexed data set is to create \na collec-tion, and then create a B+tree as an index on the objects in that collection. In E, iterutors \nare controlled looping functions that are used to step through a sequence of values such as collections. \nAn iterator is made up of an iterator function and an interate loop. The iter-ate loop consumes values \nthat the iterator function produces. The iterator function yields values to the iterate loop. The EXODUS \noptimizer generator takes as in- put (1) a set of operators, (2) a set of methods that implement the \noperators, (3) transformation rules that describe equivalence-preserving transfor-mations of query trees, \nand (4) implementation rules that describe how to replace an operator with a specific method. Using these \nrules, a specific op-timizer is generated for the particular application. Neither the Ariel nor Triton \ndevelopers made use of the optimizer generator, so we are not able to comment extensively on it. The \ndevelopers of Ariel made the decision to implement a custom optimizer rather than use the optimizer generator. \nOne rea-son for this is that the original optimizer generator required use of C functions and structures, \nand we were committed to using object-oriented program-ming in C++. The latest version of the optimizer \ngenerator now also handles C++ and E objects, so we would no longer object to using the optimizer generator \non these grounds. Another reason we decided against using the optimizer generator was the need to be \nable to optimize a set of commands in the action of an Ariel rule. We felt it might be difficult to implement \nspecial-purpose optimization PARSER QUERY + OPTIMIZER 8.5 COMPILER > E COMPILER COMPILED QUERY CATALOG \nMANAGER v 1: OPERATOR METHODS ACCESS METHODS STORAGE f] F Figure 1: An architecture for a DBMS based \non EXODUS routines for rule actions using the optimizer gener-the storage manager that frees the programmer \nator. The Triton optimizer has not been developed, from most of the details of mapping data between but \nthe intent is to use the optimizer generator. A disk and main-memory data structures. The pri-more thorough \ndiscussion of the merits of the op-mary disappointment with persistence in E is re-timizer generator \nawaits more experience using it. lated to issues of interaction between the database In the next section \nwe comment on the impact type system and E language type system, which of persistence in the programming \nlanguage based will be discussed later in Section 4. Also, our expe-on our experiences with E. riences \nreinforce the belief that persistence should be a property of data independent of type. This property \nwas defined as persistence data type or-3 The Impact of Persistence thogonality, in the design of PS-algol \n[4], and is also sometimes called simply persistence orthogonality. The availability of persistent objects \nand collec-tions in E has definitely proved worthwhile to use, 3.1 Catalogs significantly simplifying \nimplementation of system catalogs, data indexes, rule indexes, and data stor-The catalogs in Ariel have \nbeen implemented using age structures. Having persistent objects in the persistent E objects. The Relation \ncatalog consists programming language is a convenient interface to of a collection of objects of type \nRelation. The Relation object has methods on it to set and get information about attributes, presence \nof indexes, statistics about relation size, number of unique val-ues per attribute and so on. Instance \nvariables of the Relation object include a list of Attribute ob-jects to describe the attribute names, \ndata types, and other information about each attribute. Using E provided high-performance access to the \ncatalog data without the need to implement any code for mapping the catalog information into special \ninter-nal data structures. Typically, relational database systems store catalog information in relations, \nand map data about a recently-accessed set of relations into a main-memory cntulog cache (this is the \nap- proach used in POSTGRES [31]). Using persistent objects for the catalogs freed us from having to \nim- plement a catalog cache. The only drawback to our approach was that it is not possible to use the \nquery language to query our catalogs. Special-purpose commands have been provided to get information \nfrom the catalogs to make up for this, but these commands do not give access in as flexible a manner \nas a general-purpose query language. Similar advantages to using per-sistent data for the catalogs have \nbeen realized in the Triton project.  3.2 Indexes Using persistent objects definitely simplifies the \nim- plementation of complex permanent storage struc-tures such as data indexes and other special pur-pose \nindexes such as rule indexes. As with the cat-alogs, the primary simplification is that the pro-grammer \ndoes not need to be concerned with map-ping data between the disk and main-memory data structures. Hence, \nit becomes essentially no more difficult to implement a persistent index structure such as a B+-tree \nthan it would be to implement a main-memory index structure, except that per-formance artifacts such \nas node size and clustering must be addressed more carefully in the persistent implementation. The amount \nof code saved by using a persistent language to implement indexes depends on a num- ber of factors including \nthe complexity of the index being implemented, the programming language fea-tures available independent \nof persistence, etc. Re-search prototypes using PS-algol have shown that code size can be reduced by \na factor of 3 in some cases [18]. The Ariel implementors are using per-sistent objects to implement a \nfairly complex rule index [14]. We believe that this rule index would have been infeasible to implement \nwithout the aid of a persistent programming language. 3.3 Data Storage Structures and Lan- guage and \nDatabase Type System Issues Implementation of data storage structures for rela- tions and nested relations \nwas made simpler than it would have been otherwise by the availability of persistent collections provided \nin E. There are two main approaches to building database stor-age structures using E, and using them \nto process database queries (these approaches also apply for other persistent programming languages that \ndo all type checking at compile time and use conven-tional compiler and linker technology). The first \napproach, which we call the compiled approach, is to compile database type definitions and object (e.g., \nrelation) creation commands into E code, and compile this code into object files using the E com-piler. \nTo compile a query, the system generates an-other file of E code, which is compiled and linked with the \nobject files containing the compiled type definitions. The resulting executable is then run to process \nthe query. This approach has the ap-pealing property that database types are mapped directly into types \nin the underlying programming language. It can also provide fast query execution since queries are compiled \ndirectly into machine code. Unfortunately, it results in a severe perfor-mance problem for query compilation \nif a conven-tional compiler and linker are used by the persis-tent programming language, as they are \nin E (we will discuss performance figures later). The second approach, which we call the inter-preted \napproach, does not use the persistent pro-gramming language at all for compiling types and queries. Instead, \ntype definitions and queries are interpreted directly by the DBMS. Data is stored in persistent collections \nof generic storage objects (e.g., byte strings) for which one type (e.g., Tu-pIeCollection in Ariel) \nis defined when the database system itself is compiled. Implementing code to in- terpret the format of \nthese generic objects stored in the persistent collections of data is left to the DBMS implementor. Execution \nof queries is done by compiling a query into an execution plan, which is then interpreted. A drawback \nof this approach is that interpreted queries will run slower than the compiled queries in the first approach, \ngiven that the same query plan is used in both approaches. However, response time for any query generated \nin text form and sent to the DBMS for execution is dramatically better in the second approach (a fraction \nof a second vs. many seconds). Such long response time for ad-hoc queries is not tolerable. We chose \nto implement the interpreted approach in Ariel since we felt the response time of the compiled approach \nwas unacceptable. Relations in Ariel are persistent collections of byte strings. Tu-ples are mapped onto \nthese byte strings explicitly. A TupleDescriptor object describes how tuple fields are arranged in the \nbyte strings in a collec-tion representing a relation. An alternative to this approach would have been \nto map a relation defini-tion directly into E language constructs, and then compile the resulting E code \nwith the E compiler. The Ariel type system allows separate commands for defining relation types and constructing \nin-stances of relations with those types, similar to the mechanism provided in the EXCESS query lan-guage \n[8]. Th e fo 11 owing is an example definition of a relation type and a relation in Ariel: define relation \ntype emp_type(name=c20, age=int, salary=float, dept,no= int) create relation emp : emp,type The E code \nthat would be generated to represent the same information is: dbclass emp-type < dbchar name [20] ; dbint \nage; dbfloat salary; dbint dept,no; 1; dbclass emp,Collection : collection[emp,typel ; persistent emp_Collection \nemp;  Compiling a source file containing the E code above into an object file takes 3 seconds on a Sun \nSPARCstation 1 computer. Compiling an E source file containing a trivial one-relation selection query \nand linking that file with the appropriate object file for the relation and the E library to create an \nexecutable file takes more than 15 seconds. An alternative approach to implementing a per- sistent language \nto support DBMS development would be to start with a language supporting in-cremental compilation of \nboth types and program code, such as Smalltalk [ll] or Lisp and CLOS [17]. This would allow direct mapping \nof database types into language types, and fast compilation of both types and queries, making the compiled \nap-proach discussed earlier practical. However, this approach would bring with it the larger run-time \noverhead associated with Smalltalk or Lisp. 3.4 Type System Mapping Example As another more sophisticated \nexample of a trans- lation from a database type to underlying E types, in Triton, a nested relation definition \nis mapped directly into a persistent collection of E objects, which in turn have fields which contain \ncollections of objects. Figure 2 shows a nested relation that holds information on VHSIC Hardware Description \nLanguage (VHDL) systems[3]. Figure 3 gives the E code representation of the Systems relation. This implementation \nillustrates the ease with which nested relation types can be mapped into E and also allows compilation \nof Triton queries into machine code. However, it suffers from the performance problem mentioned above \nfor ad hoc queries and thus an interpreted implementation of the Triton type system and query processor \nis be- ing considered for use by Triton application devel-opers. On the other hand, Since the Triton \nsystem is targeted for use by embedded database appli-cations (such as CAD or CASE tools), extended SQL \ncommands [25] will be embedded in a host programming language and compiled as part of the application. \nThus, ad hoc queries will not normally be performed. camps ports number name cov# name mode type start-bit \nstop-bit STRT in BIT 0 0 15899 STROBE in BIT 0 0 43191 COUNTER CON in BIT-V 0 1 30018 DATA-BUS in BIT-V \n0 3 14701 FULL-ADDER I Figure 2: The Systems Relation It is unfortunate that the difficulty in making \nuse of the E compiler to compile database types and queries negates some of the advantages of using a \npersistent programming language. Essentially the only language feature necessary to support stored data \nusing the interpreted approach to DBMS implementation is the persistent collection of byte strings. It \nwould thus be about the same amount of work to implement stored relations using a direct interface to \nthe storage manager (e.g., a C+ l- class called PersistentCollection with the same meth-ods provided \nby E collections, including get-first, getnext, getlast and get-prev). This would not require extensions \nto the C-l-+ compiler on the part of the EXODUS implementors. Moreover, it would have allowed use of \na standard C-l-+ programming environment including code inspectors, debuggers, etc., without modification. \nIt would also be pos-sible to build on the PersistentCollection class by creating subclasses. The E language \ndoes not allow subclasses to be derived from the built-in collection classes of E, although there appears \nto be noth- ing preventing this. Although object persistence in E was not especially useful for storing \nrelations in Ariel, we still believe persistence is worthwhile in a database implementation language \nbecause of its usefulness for implementing indexes, catalogs, and any other data structures with object \ntypes that cannot change at run time. Another difficulty we have faced implementing Ariel is a distinction \nin E between database classes defined using the dbclass notation, and normal classes. There is a slight \noverhead to accessing a dbclass object compared to a normal object since dbclass objects reside in the \nstorage manager, and a pointer to a dbclass object is a 16-byte record, compared to a 4-byte word for \na main-memory pointer. The designers of E wanted to give the im-plementor a choice whether or not to \nuse classes or dbclasses to have more control over performance. Objects that needed to be persistent \nwould be de-fined using dbclasses, and the rest of the objects would be defined using classes. This design \nchoice in E violates the principle of persistence orthogonality, which states that all data objects should \nbe allowed the full range of persistence. Our experience in implementing Ariel reveals that the lack \nof persistence orthogonal- ity causes software engineering difficulties since a dbstruct port f DBMS \nimplementor does not know in advance all dbchar nameC121; dbchar modeC41; the types for which he or she \nwould like to cre- dbchar typeC61; ate persistent instances. For example, at first we dbint start-bit; \ndid not intend to store query plan operator objects dbint stop-bit; in the Ariel database, but now we \nhave decided public: port (char *, char *, char *, int, int); that it would be natural to store compiled \nqueries char * get-nameo; as persistent plan objects. Accomplishing this will void change-name (char \n*I; involve a significant modification to our code. In E char * get_modeO; void change-mode (char *I; \nchar * get-typeo; it is not trivial to simply classes since all subobjects change all classes to db-of \na db-object must also void change-type (char *>; be db-objects, which can cause a single change to int \nget-start-bit0; propagate through many objects. Also, some basic void change-start-bit (int); int get-stop-bit0; \nvoid change-stop-bit (int); library routines tions are not the such as string manipulation same for db-objects \nas they func-are for void print (port *I; main-memory objects. This mismatch can result in I; dbstruct \ncamp 1 the need to extensively modify a class definition in dbint camp-num; order to make it into a dbclass, \ncreating an inor- public: dinate workload on the programmer. This extra camp (int); int get-comp_numO; \nvoid change,camp-num (int); work inhibits the software system. process of prototyping a complex void \nprint (camp *I; In the design of persistent programming lan- I; guages, we thus feel that it is very \nimportant to dbstruct system c dbchar namecl21; make no distinction main-memory types, between database \neven if it involves types a small and sac- dbint number; rifice in performance. It will be a challenge \nto dbclass compRVA:collectionCcompl; compRVA camps; dbclass portRVA:collection[portl; the language implementors \nto make access kinds of objects as efficient as possible. to both Investi- portRVA ports; gation of efficient \nways to implement a persistent public: language in this manner is worthy of continued re- system (char \n*, int); char * get-nameo; void change-name (char *I; search. in the We are encouraged by recent developments \narea of transaction-based virtual memory int get-numbero; storage systems, including work on Cricket \n[29], void change-number (int>; ObjectStore [21] and Bubba [6, lo], which poten- void print (system 8); \nI; tially can provide access to persistent no overhead beyond that needed for objects with concurrency \ndbclass systemRVA:collectionCsystem]; control and recovery. In these systems, once a per- persistent \nsystemRVA systems; sistent object is in memory, it can be accessed at Figure 3: The E Code Representation \nof the Sys- the speed of a main-memory object. tems Relation In summary, the main area where we felt \nthat the persistent programming language features of E were the most useful was in creating special- \npurpose persistent data structures, such as cata- logs, data indexes, and rule indexes. If good ad-hoc \nquery response time is required, the persistent fea-tures of the language have approximately the same \nutility for actually storing database data as a direct interface to a storage manager providing transac-tion \nsupport would have. Finally, it is best to make no distinction between database and main-memory types. \n 4 The Impact of Object-Oriented Programming In this section we discuss the impact of the W-t-derived \nfeatures of E that support object-oriented programming, as well as E s extensions to C-l-t including \ngenerator classes and collections. The implementations of Ariel and Triton have derived substantial benefits \nfrom using the C++ object-oriented programming features of E. In Ariel, we have implemented a terminal \nmonitor, lexer, parser, semantic analyzer, system catalogs, query optimizer and query executor, and system \nutili-ties in about 16000 lines of code written using E and the Unix compiler generation tools LEX and \nYACC [20, 161. A system of similar, or slightly greater complexity is the terminal monitor, front-end, \nquery executor, and utilities of the university INGRES system [30], which contain approximately 32000 \nlines of C code. It is hard to make a pre-cise comparison, but it appears that a savings of somewhere \nbetween 25 to 50% in the amount of code written can be achieved using object-oriented programming in \nE (or C++) relative to using C to implement a DBMS. Moreover, object-oriented im-plementation has provided \nus with some reusable code which will facilitate extensions as Ariel grows. Object-oriented programming \nfeatures including classes, polymorphism, and inheritance are used throughout Ariel. Use of inheritance \nand polymor-phism has been particularly beneficial in the design of the Ariel syntax tree structure generated \nby the parser, the internal representation of built-in data types, and the query plan operator tree represen-tation. \nAs an example, the class hierarchy for the QueryPlaIlOp scan RelationScan SequentialScan IndexScan StoreTemporary \nJoin NestedLoopJoin NestedLoopJoinIndexInner SortMergeJoin Project Figure 4: Class hierarchy for query \nplan operators in Ariel. query plan operators in Ariel is shown in Figure 4. Methods on these object \ntypes include those for accessing result tuples, getting statistics on the expected cost of execution, \nand constructors and destructors. Ct-t virtual functions are used so that methods are inherited from \nabove unless they are reimplemented in a subclass. Polymor-phism proved useful -for example, every object \nin the class hierarchy shown responds to the get-next method. It is not necessary to know the type of \nthe node to get the next tuple from it. A substantial number of instance variables and some methods are \ninherited by the subclasses of Scan and Join. There is an inherent benefit from the organiza-tion enforced \non the code by designing the code using C-l-+ classes. Subjectively, the code seems easier to understand \nand modify than a C program accomplishing a similar task with which the au-thors are familiar (e.g., \nthe front-end of university INGRES). Another object-oriented feature of E is genera-tor classes, a mechanism \nfor creating parameterized types. For example, EXODUS provides a genera-tor class for building B-l--trees \nfor different data types [35]. A simplified and shortened version of dbclass BplusTree [ // keys for \nentities stored in the tree dbstruct key-type I void print(); 1, // key comparison function int compare(const \nkey-type 8, const key-type k), // entities to be stored in the tree  dbstruct entity-type <), I< // \nDefinitions of instance variables for // BplusTree . . .  public: // Constructors, destructors, functions \nfor // building an index, inserting and deleting // records etc. Figure 5: Sketch of B+-tree class \ngenerator in E. the definition of this generator class is shown in Figure 5. Users of this class generator \ncreate a new class by specifying parameters for the items in the square brackets (key-type, compare, \nand entity-type). For example, this piece of code defines an instance of BplusTree for keys of type integer \nand entities of type Tuple (IntKey is a structure type containing an integer, and IntKeyCompare is a \nfunction that takes two IntKeys and compares them): dbclass IntBtreeIndex : BplusTree LIntKey, IntKeyCompare \n, Tuple] ; The ability to derive classes using a generator can be useful, significantly reducing the \namount of code that needs to be written to implement closely related types. However, one difficulty with \nthe E implementation of generator classes is that classes created with a generator class cannot be made \nsub-morphism with types derived from BplusTree. types of another type. In Ariel, this made imple- menting \nthe IndexScan query plan operator more complex than necessary by not allowing use of poly- In object-oriented \nprogramming, a commonly used, powerful technique is to define a base class B and subclasses of B, say \n61, bz, . . . , bk. Each of the subclasses responds to the same set of messages. Then, another class \nC can be implemented gener-ically, storing one of B s subtypes in a variable of type B. Messages can \nbe sent to the object con-tained in that variable, and the object will respond correctly, regardless \nof its type. This generic im-plementation, which makes use of polymorphism, can save a substantial amount \nof code in the im-plementation of C, by letting a single line of the form object->message(parameters...) \n replace a multi-line SWITCH statement with one CASE for each of B s subclasses bl-bk. We be-lieve that \nan implementation of generator classes should provide a way to create a hierarchy of types, with virtual \n(inheritable, polymorphic) methods, so that the object-oriented programming technique described above \ncan be used when working with classes derived from a generator class. The exper-imental parameterized \nclass facility for C++ de-scribed in [33] appears to support the desired fea-tures, although it is not \nyet part of the C++ stan-dard. An alternative to using generator classes that allows object-oriented \nimplementation style is to provide base classes from which sub-classes can be derived. This sub-classing \napproach to generic-ity does not require any extensions to an object-oriented programming language (no \ngenerator class facility is needed). For example, the BplusTree class in EXODUS could have been implemented \nas a standard E class with virtual functions. A guideline could have been written for deriving sub-classes \nfrom BplusTree by re-implementing a very small amount of code in each subclass (e.g., the key-comparison \nfunction). The vast majority of the complex code for implementing BplusTree would be inherited by the \nsubclasses. This approach does not completely eliminate the need for a genera-tor class facility (e.g., \nthe key-comparison function would have to be re-implemented for each type), but it provides a workable \nalternative in many cases, and it does not interfere with object-oriented programming style. The collection \ngenerator class available in E proved very useful in implementing data storage structures. The Triton \nsystem is built on the nested relational data model, which allows relation-valued attributes in relations. \nThe nested rela-tional data model is mapped very nicely using E collections. Nested relational attributes \nare rep-resented by using collections of collections. The EXODUS storage manager automatically uses near \nhints to group collections and sub-collections to-gether on disk to increase efficiency. Unfortunately, \nEXODUS only provides the capability for sequen-tial scanning of collections, making access via a search \nkey slow for large relations. The only way around this shortcoming is to build indexes on ev-ery frequently \naccessed or sufficiently large relation. One way we feel EXODUS could be improved to simplify the programmer \ns task would be to pro-vide a library of additional types of collections in-cluding ordered and hashed \ncollections. This would be somewhat simpler to use than a separate index mechanism. Performance Issues \n Obtaining good performance from a DBMS imple-mented with a persistent programming language is crucial, \nas it is in any DBMS implementation. We currently do not have a great deal of information on performance \nof our database implementations based on E -no extensive application benchmarks have been done. However, \nsubjectively we feel that the speed at which individual persistent objects can be accessed using the \nE language, which has a built- in interface to the EXODUS storage system, is ex- cellent. For example, \naccess to Ariel catalog infor-mation stored in a persistent data structure made up of a hash table and \nlinked lists is extremely fast. A performance study done on the EXODUS stor-age system shows that the \noverhead for accessing an E persistent object that is already in the buffer pool is about 47 MIPS RISC \narchitecture machine cycles greater than the overhead to access a C-l--i-main-memory object [28]. Our \nexperience suggests that this level of performance is adequate for im-plementing system catalogs without \nthe need for a special cache. Performance is also good for scan-ning persistent collections of objects \nor collections of collections as in the Triton system. The abil-ity to map nested relations directly \nto nested col-lections of tuples in the EXODUS storage system allows us to directly benefit from the \nnearness of nested tuples to decrease object access time. A comparison of a relational and nested relation \ndatabase design for a software engineering CASE tool, using the Triton system on a Sun 3 computer, showed \ncode generation and compilation times in the range of 2 to 3 seconds for relational queries and 3 to \n7 seconds for more complex nested rela-tional queries. Query execution times were about 0.1 seconds for \nthe relational queries and about 0.5 seconds for more complex nested relational queries. Given an equivalent \nset of relational queries and a single nested relational query, code generation and compilation times \nwere 70 to 80% faster and query execution times were 10 to 75% faster for the nested relational query \n[15]. In summary, the speed of object access in E, or any similarly im-plemented persistent language, \ndoes not seem to be an impediment to implementing a DBMS using the language. Transaction throughput is \nanother performance issue. An important question is whether a DBMS implemented with a persistent language \ncan achieve high transaction rates (e.g., greater than 100 transactions per second). Currently, we have \nno data on transaction rates using E since a multi- user version of EXODUS is not yet available. How-ever, \na DBMS implemented using a persistent pro-gramming language will clearly be limited to a transaction \nrate no greater than that which can be supported by the storage system underlying the language. We see \nno fundamental reason why such a storage system cannot be performance-tuned to provide high transaction \nthroughput, using tech-niques similar to those used in other DBMS im-plementations such as splitting \nthe log tail, group commit, etc. [22]. Th us, in the long run, the native transaction rate of the persistent \nlanguage s stor-age system should not hinder DBMS implementors using the language. Variables related \nto throughput which the DBMS implementor can control include the CPU utilization per transaction, and \ncontention for system-wide shared resources such as catalogs and indexes. The majority of CPU cycles \nutilized by the DBMS will probably be outside the storage system of the persistent language, and it is \nthe DBMS implementor s responsibility to keep it to a minimum to achieve high transaction rates. As in \nany DBMS implementation, when using a per- sistent programming language, care must be taken to avoid \ncreating concurrency control bottlenecks around hot-spots such as a tuple-count field in the system \ncatalogs and other meta-data. If handled improperly, hot spot bottlenecks can drastically re-duce concurrency \nand hence transaction through-put. For example, having each transaction set a write-lock on tuple count \nand hold it until the end of the transaction will severly limit throughput. This is exactly what will \nhappen if the tuple count is treated as ordinary data by a concurrency con-trol system based on two-phase \nlocking. In most DBMS implementations, hot-spots such as tuple-count are handled as special cases. In \nthe case of tuple-count, updates to it are normally not logged, and write locks are held only while physi-cally \nupdating the tuple count, not until the end of the transaction. Given a persistent programming language \nsuch as E, it would be difficult or impos-sible to implement special-case treatment of hot-spots in a \nDBMS based on the language if the hot-spot data was implemented using persistent lan-guage objects. We \nfeel that persistent program-ming language implementors should give more at-tention to this issue, perhaps \nproviding an inter-face to their storage systems designed to handle hot-spots in a way which will allow \nhigh transac-tion rates to be achieved.7 If they don t, then DBMS implementors using the persistent language \nwho want to achieve high transaction throughput will have to resort to ad-hoc approaches to storing hot-spot \ndata such as using data files directly to by-pass the persistent programming language. 6 Review of Related \nResearch In this section we compare and contrast EXODUS to three other extensible systems, GENESIS, DAS-DBS, \nand POSTGRES, and discuss the relation-ship of E with four other persistent programming languages, Ott, \nVbase, 02, and Object Design s ObjectStore that are all based on C or C++. Then we discuss other efforts \nto implement database sys-tems using database toolkits or persistent program-ming languages. 6.1 Database \nToolkits and Extensible Databases GENESIS [5], like EXODUS, provides a modular approach to extensibility. \nThis approach is sup-ported by providing a library of modules with com-pletely compatible interfaces. \nGENESIS provides a data definition language to define the schema of relations, as well as a data manipulation \nlan-guage that provides access to the basic objects in the database (which are records, files, and links). \nThe lowest layer of GENESIS is the file manage- ment system, JUPITER. Like the EXODUS stor-age manager, \nJUPITER provides buffer and re-covery management; unlike EXODUS, JUPITER is extensible in that different \nbuffer and recovery management schemes can be supported by replac- ing the appropriate module in JUPITER \nwith a new one. JUPITER supports both single-keyed and multi-keyed file structures, such as index-ing, \nB+-trees, heap structures, and multi-key hash structures. The Darmstadt Database System (DAS-DBS) [26]supports \nextensibility through the use (IThe need to support special protocols for handling meta-data was briefly \nmentioned in [23]. of a kernel storage component that allows flexible, application-specific front ends. \nThe DASDBS ker-nel provides access (such as reading, insertion, and deletion) to sets of complex objects \nas opposed to a one-record-at-a-time interface by fetching or stor-ing lists of pages via a variable \nsize buffer. Thus, a single scan of a complex object retrieves all of the values of its sub-objects, \nwhich limits the number of disk accesses. This is very similar to the way the EXODUS storage manager \nworks. The kernel provides operations to read, insert, and delete an object. Like the EXODUS storage \nmanager, the DASDBS kernel provides concurrency control ca-pabilities. Instead of using tuple indices, \nthe kernel appends a virtual address attribute to each tuple which can be used in the application layers \nto build access paths (e.g., B+-index trees) and provides di- rect access to the tuple. To enhance performance, \nthe DASDBS kernel attempts to group pages rep- resenting a complex object together on disk. POSTGRES \n[31] supports extensibility by al-lowing users to define new data types, operators, built-in functions, \nand access methods. Like EXO-DUS, built-in types support both scalar type fields and variable length \nrecords. However, unlike EXO-DUS, POSTGRES supports two interesting built-in types, which are POSTQUEL \nand procedure types. POSTQUEL types are data manipulation commands, while procedure types are program-ming \nlanguage procedures with embedded data ma-nipulation commands. POSTGRES provides these two types to allow \nusers to represent and manipu-late complex objects.  6.2 Persistent Programming Languages Database programming \nlanguages are unique in that they should not only support strong typing of objects, but must allow the \nspecification of per- sistent objects that can last beyond the programs that created them. These two \nobjectives can ei-ther be met by providing a single language that does both (as does the E programming \nlanguage of EXODUS), or providing a separate data definition language and data manipulation language. \nOtt [l] is implemented as an extension of C++ with persistent objects, and is thus closely related to \nE. In addition, O-t-t also provides additional language statements for defining queries. The main difference \nbetween 0+-l-and E is that in O++ there is no distinction between database classes and in-memory classes, \nbut there is a distinction between database pointers and in-memory point-ers (there is also a third pointer \ntype called a dual pointer that can point to a persistent of volatile object). The O++ approach to persistence \nis es-sentially the dual of the E approach. Neither O-t-t nor E completely separates the issue of persistence \nfrom the definition of types. Vbase [2] and 02 [19] are database systems that support a separate data \ndefinition language and data manipulation language. In both systems, the data manipulation language is \nbased on an exten-sion of C. In Vbase, the data definition language, called TDL, allows strong typing \nand inheritance. All objects are persistent until they are explic-itly deleted, which is good in that \npersistent and volatile object interaction is not an issue. However, explicit deletion of objects can \nbe tedious. The Data Definition Language of 02 is also strongly typed and supports inheritance. Persis-tent \nobjects are declared from a persistent super object called tuple. All objects of type tuple or de-clared \nfrom a subtype of tuple are persistent, and sets of tuple objects can be identified. Methods for types \nare specified when the type is declared, and types are inherited down the type hierarchy unless they \nare redefined for a specific subtype. Methods are first order functions and are implemented in C. The \nObjectStore system [21] treats persistent data and persistent data access the same way as conventional \nvirtual memory access. During Ob-jectstore application sessions, referenced persistent data is dynamically \nmapped into the workstation s virtual address space. If persistent data is called for and it not in memory, \na memory fault occurs and the missing data is retrieved from the database. ObjectStore also supports \ndata caching, concur-rency control and restart/recovery. The program-mer can create persistent data via \nseveral methods: a variant of the C-i-+ new operator which also al-lows clustering hints, use of a persistent \nkeyword, or use of a library call. Any C or C++ type can be made persistent; in addition, ObjectStore \nincludes a collection class, and the Set, Bag, and List sub-class of collection, and iterator functions \nover these classes.  6.3 Use of Database Toolkits and Per-sistent Languages Relatively little has been \npublished on experiences using database toolkits to implement a DBMS. Cooper et al. [9] discuss three \nsystems imple-mented using PS-algol [4], a persistent version of Algol with the property of persistence \northogonal-ity. One of the systems covered used PS-algol to implement a DBMS based on an extended func-tional \ndata model (EFDM) [18]. The benefits of using PS-algol cited in the EFDM implementation were (1) automatic \nmovement of persistent data to/from memory, (2) reduction in misuse of data due to strong typing, (3) \nusefulness of a universal pointer type, (4) fast access to persistent language objects. Our findings \ncorroborate theirs, particu-larly (1) and (4) above.  7 Conclusions The EXODUS system has proven to \nbe a powerful tool for implementing a database system, although it is by no means an antidote for the \nall the com-plexities of DBMS implementation. At a minimum, DBMS designers still have to specify a data \nmodel, query language parser, catalogs, index and data storage structures, a query optimization strategy \n(with or without using the optimizer generator), and a query execution strategy. Using a persistent programming \nlanguage to im-plement a DBMS has proven very useful for imple-menting special-purpose persistent structures \nsuch as catalogs, data indexes, and rule indexes, and somewhat less useful for storing the data itself. \nThe problem with using persistent collections in E to store data is due to the fact that one must resort \nto using persistent collections of generic objects (byte strings) to hold data in order to get adequate \nre-sponse time for ad hoc queries. In systems where ad hoc query capability is not necessary (as in Tri- \nton), or where all persistent types can be specified at compile time (e.g., in a computer-aided design \ndatabase) this is not a major problem. A diffi-culty we experienced with the E implementation of persistence \nis the lack of persistence orthogonality in E, which led to software engineering problems in the implementation \nof Ariel. We assert that it is impossible for the designer of complex software system to know at the \noutset what data types will need to be persistent. Research on virtual-memory based storage systems (e.g., \nCricket) may eliminate the incentive to distinguish between database and main-memory types. We highly \nencourage this and other research on ways to improve the speed of stor- age systems for persistent languages. \nLanguage features of E independent of persis-tence, especially object-oriented programming ca-pability, \nclearly helped simplify our systems. Ariel shows a significant reduction in code size relative to parts \nof university INGRES with comparable com-plexity. E generator classes were useful, but the in-ability \nto use polymorphism and inheritance with generated classes is a problem. Generator class fa-cilities \nin an object-oriented language need to allow use of object-oriented style with generated classes. We \nwere not able to adequately evaluate the useful-ness of the optimizer generator. A useful evaluation \nof the optimizer generator would be to implement an optimizer with the generator and also code the optimizer \nby hand, and compare the resulting op-timizers. In terms of performance, we are pleased with the speed \nof access to persistent objects in E. Perfor-mance seems adequate for catalogs, indexes, and data storage \nstructures. Any improvements in speed of persistent object access would, however, be welcome. The speed \nof the underlying stor-age system does not appear to stand in the way of achieving high transaction throughput. \nHow-ever, we are concerned about having the persistent language storage system handle meta-data such \nas catalogs and indexes. Since the storage system will and David Maier, editors, Readings in Object- \nuse a standard two-phase locking, write-ahead log Oriented Database Systems, pages 500-518. strategy \nfor all data, it almost certainly will cause a Morgan Kaufmann, San Mateo, CA, 1990. transaction throughput \nbottleneck around the sys- H. Boral. Prototyping Bubba, a higly parrallel tem catalogs. Database toolkit \ndesigners need to PI database system. IEEE Transactions on Data provide some sort of support for meta-data \nto avoid and Knowledge Engineering, 2(l), May 1990. the creation of a transaction bottleneck. Using EXODUS \nhas been a worthwhile experi- PI M. Carey, D. Dewitt, D. Frank, G. Graefe, ence for us. We encourage \ncontinued research on J. Richardson, E. Shekita, and M. Muralikr-ways to improve database toolkits and \npersistent ishna. The architecture of the EXODUS ex-programming languages so that the job of DBMS tensible \nDBMS. In Procedings of the Interna-implementors who follow in our footsteps might be tional Workshop \non Object-Oriented Database simpler. Systems, September 1986. M. J. Carey, D. J. Dewitt, and Scott L. \nVan- PI denberg. A data model and query language for References EXODUS. In Proceedings of the 1988 ACM \nSIGMOD InternationaE Conference on Man- Ill R. Agrawal and N. H. Gehani. Rationale for agement of Data, \nJune 1988. the design of persistence and query process-ing facilities in the database programming lan-PI \nR. L. Cooper, M. P. Atkinson, A. Dearle, and guage, Ott. In Richard Hull, Ron Morrison, D. Abderrahmane. \nConstructing database sys- and David Stemple, editors, Proceedings of the tems in a persistent environment. \nIn Proceed-Second International Workshop on Database ings of the 19th VLDB Conference, 1987. Programming \nLanguages, pages 25-40, Glene- G. Copeland. Uniform object management. den Beach, Oregon, June 1989. \nPO1 In Proceedings of the Intl. Conf. on Extending Database Technology, March 1990. Timothy Andrews. \nThe Vbase object PI database environment. In Alfonso F. Car-Adele Goldberg and David Robson. Smalltalk- \n  IllI denas and Dennis McLeod, editors, Research 80: The Language. Addison Wesley, 1989. Foundations \nin Object-Oriented and Semantic Database Systems, pages 221-240. Prentice- G. Graefe and D. J. Dewitt. \nThe EXO- WI Hall, Englewood Cliffs, NJ, 1990. DUS optimizer generator. In Proceedings of the 1987 ACM \nSIGMOD International Con-James R. Armstrong. Chip-Level Modeling PI ference on Management of Data, May \n1987. with VBDL. Prentice-Hall, Englewood Cliffs, NJ, 1989. Eric N. Hanson. An initial report on the \nde- Ml sign of Ariel: a DBMS with an integrated pro- M. P. Atkinson, P. J. Bailey, K. J. Chisholm, duction \nrule system. SIGMOD Record, 18(3), PI P. W. Cockshott, and R. Morrison. An ap-September 1989. proach \nto persistent programming. The Com-puter Journal, 26(4), 1983. (reprinted in [34]). PI Eric N. Hanson, \nMoez Chaabouni, Chang-ho Kim, and Yu-Wang Wang. A predicate match- D. S. Batory, J. R. Barnett, J. F. \nGarza, ing algorithm for database rule systems. In PI K.P. Smith, K. Tsukuda, B. C. Twichell, and Proceedings \nof the 1990 ACM SIGMOD Inter- T. E. Wise. GENESIS: An extensible database national Conference on Management \nof Data, management system. In Stanley B. Zdonik May 1990.  Capt Tina M. Harvey. Access and opera- WI \ntor methods for the Triton nested relational database system. Master s thesis, School of Engineering, \nAir Force Institute of Technology (AU), Wright-Patterson AFB, OH, December 1990. S. C. Johnson. YACC \n-yet another compiler PI compiler. Technical Report CSTR-32, Bell Laboratories, Murray Hill, NJ, 1975. \nSonya E. Keene. Object-Oriented Program- WI ming in Common Lisp. Addision-Wesley, 1989. K. G. Kulkarni \nand M. P. Atkinson. Imple- WI menting an extended functional data model using PS-algol. Software Practice \nand Expe- rience, 17(3):171-185, Marche 1987. Christophe Lkcluse, Philippe Richard, and WY Fernando Velez. \n02, an object-oriented data model. In Stanley B. Zdonik and David Maier, editors, Readings in Object-Oriented \nDatabase Systems, pages 227-241. Morgan Kaufmann, San Mateo, CA, 1990. M. E. Lesk. LEX -a lexical analyzer \ngenera- WI tor. Technical Report CSTR-39, Bell Labora- tories, Murray Hill, NJ, 1975. WI Object Design, \nInc. ObjectStore technical overview, release 1.0, August 1990. PI Andreas Reuters, editor. Proceedings \nof the 2nd International Workshop on High Perfor- mance Transaction Systems. Springer Verlag, 1987. \nWI Joel E. Richardson and Michael J. Carey. Pro-gramming constructs for database system im-plementation \nin EXODUS. In Proceedings of the 1987 ACM SZGMOD International Con-ference on Management of Data, May \n1987. Joel E. Richardson, Michael J. Carey, and WI Daniel T. Schuh. The design of the E program- ming \nlanguage. Technical report, University of Wisconsin, 1989. Mark A. Roth, Henry F. Korth, and Don S. P51 \nBatory. SQL/NF: A query language for 11NF relational databases. Information Systems, 12(1):99-114,1987. \nHans-Jeorg Schek et al. The DASDBS project: P61 Objectives, experiences, and future prospects. IEEE Transactions \non Knowledge and Data Engineering, 2(7):25-43, March 1990. Capt Craig W. Schnepf. SQL/NF transla- PI \ntor for the Triton nested relational database system. Master s thesis, School of Engineer- ing, Air Force \nInstitute of Technology (AU), Wright-Patterson AFB, OH, December 1990. Dan Schuh, Michael Carey, and \nDavid Dewitt. WI Persistence in E revisited -implementation experiences. In Proceedings of the 1990 Per-sistent \nObject Systems Workshop, Fall 1990. Eugene Shekita and Michael Zwilling. Cricket: PI A mapped, persistent \nobject store. Technical report, University of Wisconsin, Fall 1990. M. Stonebraker, E. Wong, P. Kreps, \nand WI G. Held. The design and implementation of INGRES. ACM Transactions on Database Systems, 1976. \nWI Michael Stonebraker, Lawrence Rowe, and Michael Hirohama. The implementation of POSTGRES. IEEE Transactions \non Knowl-edge and Data Engineering, 2(7):125-142, March 1990. WI Bjarne Stroustrup. The C++ Programming \nLanguage. Addision Wesley, 1986. WI Bjarne Stroustrup. Parameterized types for Ct t. In Proceedings of \nthe Usenix C++ Con-ference, 1988. WI Stanley B. Zdonik and David Maier, editors. Readings in Object-Oriented \nDatabases. Mor-gan Kaufmann, 1990. WI Michael Zwilling. B-l--tree external documen-tation, 1989. EXODUS \nProject Documenta-tion. \n\t\t\t", "proc_id": "117954", "abstract": "", "authors": [{"name": "Eric N. Hanson", "author_profile_id": "81100646269", "affiliation": "Artificial Intelligence Technology Office (WL/AAA-1), Air Force Wright Laboratory, Wright-Patterson AFB, OH and Wright State University", "person_id": "P78138", "email_address": "", "orcid_id": ""}, {"name": "Tina M. Harvey", "author_profile_id": "81100589542", "affiliation": "7th Communications Group/DOWI, The Pentagon, Washington DC and Department of Electrical and Computer Engineering, Air Force Institute of Technology", "person_id": "P282914", "email_address": "", "orcid_id": ""}, {"name": "Mark A. Roth", "author_profile_id": "81339525495", "affiliation": "Department of Electrical and Computer Engineering (AFIT/ENG), Air Force Institute of Technology, Wright-Patterson AFB, OH", "person_id": "PP42050369", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/117954.117978", "year": "1991", "article_id": "117978", "conference": "OOPSLA", "title": "Experiences in DBMS implementation using an object-oriented persistent programming language and a database toolkit", "url": "http://dl.acm.org/citation.cfm?id=117978"}