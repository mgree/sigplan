{"article_publication_date": "06-15-2009", "fulltext": "\n A Study of Memory Management for Web-based Applications on Multicore Processors Hiroshi Inoue, Hideaki \nKomatsu, and Toshio Nakatani IBM Tokyo Research Laboratory 1623-14, Shimo-tsuruma, Yamato-shi, Kanagawa-ken, \n242-8502, Japan {inouehrs, komatsu, nakatani}@jp.ibm.com 0.6 Keywords Dynamic memory management, Region-based \nmem\u00ad ory management, Scripting Language, Web-based applications. 0.4 0.2 0 Abstract More and more server \nworkloads are becoming Web-based. In these Web-based workloads, most of the memory objects are used only \nduring one transaction. We study the effect of the memory management approaches on the performance of \nsuch Web-based applications on two modern multicore processors. In particular, using six PHP applications, \nwe compare a general-purpose alloca\u00adtor (the default allocator of the PHP runtime) and a region-based \nallocator, which can reduce the cost of memory management by not supporting per-object free. The region-based \nallocator achieves better performance for all workloads on one processor core due to its smaller memory \nmanagement cost. However, when using eight cores, the region-based allocator suffers from hidden costs \nof increased bus traffics and the performance is reduced for many workloads by as much as 27.2% compared \nto the default allocator. This is because the memory bandwidth tends to become a bottleneck in systems \nwith multicore processors. We propose a new memory management approach, defrag\u00addodging, to maximize the \nperformance of the Web-based work\u00adloads on multicore processors. In our approach, we reduce the memory \nmanagement cost by avoiding defragmentation overhead in the malloc and free functions during a transaction. \nWe found that the transactions in Web-based applications are short enough to ignore heap fragmentation, \nand hence the costs of the defrag\u00admentation activities in existing general-purpose allocators out\u00adweigh \ntheir benefits. By comparing our approach against the region-based approach, we show that a per-object \nfree capability can reduce bus traffic and achieve higher performance on multi\u00adcore processors. We demonstrate \nthat our defrag-dodging ap\u00adproach improves the performance of all the evaluated applications on both \nprocessors by up to 11.4% and 51.5% over the default allocator and the region-based allocator, respectively. \nCategories and Subject Descriptors D.3.3 [Programming Lan\u00ad guages]: Language Constructs and Features \n Dynamic storage management. General Terms Performance, Languages.  1. Introduction Emerging Web-based \nworkloads are demanding much higher throughputs to support ever-increasing client requests. When a next-generation \nserver system is designed, it is important to be able to run such Web-based applications efficiently \non multicore processors. One important characteristic of those Web-based ap\u00adplications is that most memory \nobjects allocated during a transac\u00adtion are transaction scoped, living only during that transaction. \nTherefore the runtime systems can discard these objects at once when a transaction ends. Region-based \nmemory management [1-4] is a well-known technique to reduce the cost of memory management by discard\u00ading \nmany objects at once. Typically, a region-based allocator does not provide a per-object free and hence \ndoes not reuse the mem\u00adory area allocated for dead objects. Instead, it discards the whole region at \nonce to reclaim all the objects allocated in that region. For example, the Apache HTTP server uses a \nregion-based cus\u00adtom allocator [5] that deallocates all of the objects allocated to serve an HTTP connection \nwhen that connection terminates. Although the region-based memory management looks ideal for managing \ntransaction-scoped objects in Web-based applica\u00adtions, it does not improve, or in some cases even degrades, \nthe performance of Web-based applications on systems with multi\u00adcore processors compared to a general-purpose \nallocator. For example, our results showed that performance of Web-based ap\u00adplications written in PHP \nsignificantly degraded on a system with eight cores of Intel\u00ae Xeon\u00ae (Clovertown) processors, while it \nimproved the performance of the same applications on one or few processor cores. Figure 1 shows an example \nof the degradation in throughput. Although the region-based allocator significantly sho r te r is fa \nst er 1.4 normalized CPU timeper transaction 1.2 1 0.8 Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for profit or commercial advantage and that copies bear this notice and the full \ncitation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to \nlists, requires prior specific permission and/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. Copyright \n&#38;#169; 2009 ACM 978-1-60558-392-1/09/06 $5.00. default allocator region-based allocator of the PHP \nruntime Figure 1. Performance of a region-based allocator on multi-core processors (for MediaWiki on \n8 Xeon cores). Table 1. Summary of three allocation approaches for transaction-scoped objects including \nour proposed defrag-dodging approach. type of allocators bulk free per-object free defrag mentation cost \nof malloc / free bandwidth requirement examples of the approach general purpose allocators supporting \nbulk freeing Yes Yes Yes high low default allocator of the PHP runtime [8], amalloc (arena malloc) in \nlibc, Reaps [9] region-based allocators Yes No No lowest high Apache pool allocator [5], GNU obstack \n[10] our defrag-dodging allocator Yes Yes No low low our DDmalloc speeds up the memory management functions, \nit degraded the performance of the rest of the program. This degradation is due to longer access latency \nfor system memory caused by the increased bus traffics. The region-based allocator does not support per\u00adobject \nfree and hence cannot reuse the memory locations of dead objects. Therefore many dead objects are left \nin cache memory and cache pressure is increased, resulting in increased cache misses and bus traffics. \nThe system memory bandwidth tends to become a bottleneck in systems with multicore processors [6, 7], \nbecause the rate of improvement in processing power with such multicore processors exceeds the rate of \nimprovement in system memory bandwidth. Hence the increase in bus traffic may limit the performance of \nthe region-based allocator on multicore proc\u00adessors. Based on our learning, we present a new memory management \napproach for transaction-scoped objects, called defrag-dodging. With this approach, we aim to find a \nsweet spot between the gen\u00aderal-purpose memory management and the region-based memory management. As \ndiscussed above, the region-based memory man\u00adagement is not an optimal way to reduce the memory manage\u00adment \ncost on multicore processors. Unlike the general-purpose memory allocators such as the de\u00adfault allocator \nof the PHP runtime, our approach reduces the memory management cost by skipping those defragmentation \nactivities in malloc and free, which take a non-negligible CPU time. We found that the transactions of \nWeb-based applications are short enough to ignore the harmful effects of gradual heap fragmentation even \nin large Web-based applications, and hence the cost of the defragmentation activities outweighs the benefit. \nFor example, the default allocator of the PHP runtime supports both per-object and bulk freeing and it \nclean up the heap at the end of each transaction by bulk freeing. In spite of cleaning up the heap every \ntransaction, the default allocator pays a cost for de\u00adfragmentation activities in malloc and per-object \nfree functions to avoid gradual performance degradation and the cost matters for the overall performance \nof the workloads. Unlike the region-based memory management, our approach retains its per-object free \ncapability even though all of the mem\u00adory objects are freed at the end of a transaction. This per-object \nfree capability, which enables fine-grained memory reuse, is im\u00adportant to avoid the performance degradation \nwith multicore processors. Table 1 contrasts those three approaches. By avoiding defragmentation activities, \nwe can use a very simple data struc\u00adture for the heap and we do not have to add per-object header for \neach memory object in our new allocator. Such simpler data struc\u00adture can give further improvements in \nthe overall performance by reducing memory pressure in addition to the reduced allocator cost. To evaluate \nour defrag-dodging approach, we implemented a new memory allocator, called DDmalloc, in the PHP runtime \nand compared the performance of three allocators, our DDmalloc, a region-based allocator, and the default \nallocator of the PHP run\u00adtime, using six Web-based applications. All three allocators sup\u00adport bulk freeing \n(with the function freeAll) for transaction\u00adscoped objects at the end of each transaction. In addition \nto the freeAll, the default allocator and our DDmalloc support per-object free during a transaction. \nOur DDmalloc avoids defragmenting the heap in malloc and per-object free functions to reduce costs but \nstill maintains a free list to keep track of freed objects and reuse them in future allocations. This \nconfiguration gives the highest performance on multicore processors. We conducted ex\u00adperiments on two \nsystems, one with eight Intel Xeon cores and the other with eight Sun Niagara cores. By reducing the \nCPU time used for memory management our DDmalloc showed improve\u00adments in throughput by up to 11.1% on \nXeon and 11.4% on Niag\u00adara compared to the default allocator of the PHP runtime using eight cores. Meanwhile, \ndue to the increased bus traffic the re\u00adgion-based allocator did not improve the throughput when using \neight cores. To compare our DDmalloc against well known general\u00adpurpose allocators that do not support \nbulk freeing, we also exam\u00adined the performance of the Ruby runtime for a Web-based appli\u00adcation. We \nused Hoard [11] and TCmalloc [12] for the comparisons. The results showed that the cost of the defragmenta\u00adtion \nactivities exceeds the benefit even in those sophisticated memory allocators. Our DDmalloc achieved higher \nperformance than these high-performance allocators. In this paper, we examined our defrag-dodging approach \nfor transaction-scoped objects in Web-based applications, since mul\u00adticore processors have already become \nso common for servers that efficient execution of Web-based server applications on multicore processors \nis important. However our defrag-dodging approach is applicable to other applications that deallocate \nmany objects in groups and where the lifetimes of those objects are short enough to ignore gradual fragmentation. \nAlthough it has received little study to date, our results show that the limited bandwidth in mul\u00adticore \nenvironments is another important problem for memory allocators, in addition to such problems as lock \ncontention and false sharing. The main contribution of this paper is two-fold. 1) We demon\u00adstrate that \nthe advance of multicore processors is significantly changing the requirements for memory allocators. \nFor example, our experiments show that region-based memory management may degrade the performance of \napplications on multicore envi\u00adronments, while it improves the performance on systems with only one or \na few cores. 2) We propose and evaluate a new mem\u00adory management approach for transaction-scoped objects, \ncalled defrag-dodging, based on our observation that the cost of the defragmentation activities outweighs \nthe benefit in Web-based workloads. The defrag-dodging approach can achieve higher per\u00adformance in Web-based \napplications on multicore processors by reducing the cost of memory management.  The rest of the paper \nis organized as follows. Section 2 gives an overview of existing memory management techniques. Section \n3 describes our new defragment-dodging approach and our im\u00adplementation of the new approach. Section \n4 shows the experi\u00admental environment and gives a summary of our results. Section 5 discusses how our \nobservations affect runtime systems of GC\u00adbased languages. Section 6 covers related work. Finally, Section \n7 reports our conclusions.  2. Existing Memory Management Approaches This section gives an overview \nof existing memory management approaches as a background of our proposed one. 2.1 Region-based memory \nmanagement Region-based memory management [1-4] is a well-known tech\u00adnique to reduce the cost of memory \nmanagement using knowledge of the object lifetimes. The region-based allocators obtain a large block \nof memory from an underlying allocator, such as operating systems, and the allocation is done by simply \nincrementing a pointer that tracks the current location to allocate in the block. The programmer can \ndelete all the allocated objects merely by discarding the entire block. Thus the costs of both allocation \nand deallocation are almost negligible. The region-based memory management, however, may suffer from \nperformance degradation with Web-based applications on multicore processors due to in\u00adcreased bus traffic, \nas shown in Figure 1. 2.2 General-purpose malloc-free General-purpose memory allocators have to perform \nmany activi\u00adties to avoid excess fragmentation of the free memory chunks in the heap. How to avoid fragmentation \ndepends on the implemen\u00adtation of the memory allocator and is a major area of innovation. One typical \napproach is used in a well known memory allocator developed by Doug Lea [13], which sorts all of the \nobjects in the free lists in order of their size to easily find the best object to allo\u00adcate for a request, \ncoalesces multiple small objects into large ob\u00adjects, and splits large objects into small objects in \nresponse to requests. The default allocator of the current PHP runtime devel\u00adoped by Zend Technologies \n[8] also does coalescing and splitting of objects. Memory allocators often spent a large amount of CPU \ntime for such defragmentation activities, which are necessary for general-purpose allocators to avoid \ngradual performance degrada\u00adtions of the applications, both in execution time and memory con\u00adsumption. \n  3. Our Defrag-dodging Approach 3.1 Basic concept Our defrag-dodging approach eliminates the overhead \nof the costly defragmentation activities in malloc and free by introduc\u00ading a freeAll function for initializing \nthe heap. The freeAll func\u00adtion is called from an application when all of the objects in the heap can \nbe deallocated, such as at the end of each transaction in Web-based applications. In the defrag-dodging \napproach, alloca\u00adtors still retain the per-object free capability. Our approach re\u00adplaces the defragmentation \nactivities in malloc and free by a freeAll that cleans up the heap including the metadata, such as the \nfree lists of unallocated objects. Therefore applications need to call freeAll even if all of the objects \nin the heap have already been freed by per-object free. The defrag-dodging approach can reduce the overhead \nof memory management because the cost to initial\u00adize the metadata in the heap is much smaller than the \ncost of maintenance for the heap with many live objects. We can skip defragmentation activities in malloc \nand free because each trans\u00adaction in most Web-based applications is short enough to ignore the gradual \nperformance degradations due to the fragmentation of the heap. Both our defrag-dodging approach and the \nregion-based mem\u00adory management can reduce the cost of memory management compared to general-purpose \nmalloc-free. Comparing the defrag\u00addodging approach to the region-based memory management, the cost is \nslightly higher for the defrag-dodging approach, because it still needs to maintain the free lists to \nsupport per-object free se\u00admantics. This per-object free capability is the key not only to reduce the \namount of memory used but also to improve the over\u00adall performance of the applications by avoiding increases \nin bus traffic. Without reusing the freed objects, many already-dead objects remain on the cache memory \nand hence waste the cache capacity. As with the region-based memory management, the defrag\u00addodging approach \nrequires modifications to applications written with general malloc-free semantics, because our defrag-dodging \nallocator depends on invocations of freeAll to avoid fragmenta\u00adtion in the heap. Also, it requires the \nallocations to be aware of the objects lifetimes. For example, the current PHP runtime uses its custom \nmemory allocator to allocate transaction-scoped ob\u00adjects and an allocator in the standard library to \nallocate persistent objects. The PHP runtime calls freeAll for the heap of its custom allocator at the \nend of the lifetime of transaction-scoped objects. Thus it is easy to apply the defrag-dodging approach \nor the re\u00adgion-based memory management to the PHP runtime by replacing only the memory allocator. The \nmodification to apply the defrag\u00addodging approach for other applications written for general mal\u00adloc-free \nsemantics is similar to that for the region-based memory management [3]. The steps for modification are: \n1) identify memory objects that can be discarded at once (such as transaction-scoped objects in the Web-based \nworkloads), 2) replace malloc and (per-object) free for those identified objects with the allocation \nfunction for our allocator, and 3) add freeAll function calls in appropriate places (such as at the ends \nof transactions in the PHP runtime). In the modification for the region-based management, all invoca\u00adtions \nof per-object free for the objects identified in Step 1 have to be removed in addition to these three \nsteps, but those free calls must be retained for ours.  3.2 Implementation of DDmalloc In this section, \nwe describe the details of an implementation of our defrag-dodging allocator, which we call DDmalloc. \nDDmal\u00adloc is based on a segregated storage [14] similar to other high\u00adperformance allocators. We carefully \nimplemented the malloc and free functions to be as efficient as possible by avoiding activities other \nthan maintenance of the free lists. Though we describe the free list of each size class size class for \neach segment class 1 segment 1 class 2 segment 2 class 3 segment 3 segment 1 segment 2 segment 3 \n Figure 2. A heap structure. (a) after first malloc for a small object (b) after second malloc for a \nsmall object (c) after free the object s1  segment 1 segment 2 free list of each size class NULL class \n1 class 2 class 3 size class for each segment NULL 2 unused segment 1 segment 2 segment 3 unused segment \n3 s1 5 number of unallocated objects in this segment segment 1 segment 2 free list of each size class \nNULL class 1 class 2 class 3 NULL segment 3 s1 s2 size class for each segment 2 unused segment 1 segment \n2 segment 3 unused 4 segment 1 segment 2 free list of each size class NULL class 1 class 2 class 3 NULL \nsegment 3 s2 size class for each segment 2 unused segment 1 segment 2 segment 3 unused 4 Figure 3. Steps \nof malloc and free operations for small objects. details of DDmalloc in this section, the method of free \nlist man\u00adagements in DDmalloc is not new. The novelty of our DDmalloc is that we totally eliminate, not \njust delay, the defragmentation activities. TCmalloc [12], for example, reduces the overhead by delaying \nthe defragmentation activities until the total size of the memory objects in the free lists exceeds a \nthreshold. However TCmalloc still has costs for the delayed defragmentation activities and the costs \nmatter for the overall performance, as shown in Section 4.4. Figure 2 shows the heap structure with DDmalloc. \nA heap consists of fixed-size memory chunks, each called a segment, and metadata. Each segment must start \nfrom an address of a multiple of the size of a segment. Due to this alignment restriction, DDmalloc can \nefficiently determine to which segment an object belongs from the address of the object. DDmalloc divides \neach segment into multiple objects of the same size and uses the seg\u00adment as an array of those objects. \nThere is no per-object metadata between objects. This results in both high space efficiency and better \ncache utilization. Like many other high-performance mem\u00adory allocators, DDmalloc maintains a free list \nfor each size-class. It maps all allocation requests into the corresponding size-class and allocates \nmemory from the free list for the size-class. The metadata includes an array of pointers for the head \nof a single\u00adlinked free list for each size-class and an array of 1-byte integers that track the size-classes \nfor each segment. DDmalloc classifies objects into two categories, large objects (larger than half the \nsize of a segment) and small objects. Figure 3 presents examples of malloc and free calls for a small \nobject cor\u00adresponding to the size-class 2. To handle the malloc request, DDmalloc first determines the \nsize-class for the requested size. Then it checks a free list for that size-class. In this example, it \nfinds that the free list is empty because it is the first invocation of malloc. DDmalloc generates new \nfree objects for this size-class by obtaining an unused segment and dividing the segments into fixed-sized \nobjects corresponding to the size-class. It returns the top of newly generated objects to the caller \nand uses a pointer to the second object as the head of the free list. The size-class is recorded in the \nmetadata. In order to track the number of unallo\u00adcated objects within the segments, DDmalloc stores the \nnumber of unallocated objects (5 in this example) at the top of the unallo\u00adcated objects. Figure 3(a) \nshows a snapshot of the heap after the first call to malloc. Figure 3(b) shows an example of a subsequent \ncall to malloc with the same size request. Now the free list for the size-class 2 is not empty and DDmalloc \nimmediately returns the object at the top of the free list and updates the free list. Figure 3(c) illustrates \nan example of a call for free for the object allo\u00adcated by the first malloc. DDmalloc chains the freed \nobject to the top of the corresponding free list. Thus the freed objects are re\u00adused in LIFO order. For \nlarge objects requests, DDmalloc directly allocates and re\u00adclaims the segments without using the free \nlists. It marks the seg\u00adments as used for the large object in the size-class array when it allocates \nthe segments. To free the large objects, it simply marks the segment as unused. When freeAll is called, \nDDmalloc clears only the metadata in the heap. The metadata is much smaller than the entire heap. Hence \nthe overhead of freeAll is almost negligible. As a result of the freeAll call, the heap returns to the \ninitial state shown in Fig\u00adure 2. How to map the requested sizes of small objects onto each size-class \nis an important tunable parameter. Our current imple\u00admentation 1) rounds up the requested size to a multiple \nof 8 bytes if the size is smaller than 128 bytes, 2) rounds up to a multiple of 32 bytes if the size \nis smaller than 512 bytes, and 3) rounds up to the nearest power of two for larger sizes. The size of \na segment is another important parameter, which affects both the amount of memory consumed and the allocation \nspeed. We used 32 KB as the size of a segment. We chose these parameters based on our measurements. For \nexample, using larger segment size tended to increase memory footprint and cache misses while it reduced \nthe number of instructions to manage each segment. We chose the parameters based on such tradeoffs to \nprovide the best throughput in PHP applications  3.3 Optimizations In addition to the basic memory management \nmechanisms, we tuned our implementation for the following traits: 1. DDmalloc frequently accesses the \nmetadata in the heap. Thus accesses to the metadata may often incur cache misses due to associativity \noverflows if they are located at the same location in the heap. We change the position of the metadata \nin the heaps using the process ids to cut down on cache misses. The effect of this optimization is significant \non Niagara where multiple hardware threads share a small L1 cache. 2. DDmalloc uses large page memory \nfor the heap to reduce the overhead of TLB handling. Using larger size page for the heap results in notable \nperformance improvements on some processors, such as Niagara, because of the high overhead of TLB handling \nin software. However we disabled this large\u00adpage optimization in our evaluations on Xeon to allow fair \ncomparisons to the default allocator of the PHP runtime. 3. The default configuration of the current \nPHP runtime is a single-threaded application. However it can be configured as a multi-threaded application \nto run as plug-ins for multi\u00adthreaded HTTP servers. Even in the multi-threaded configura\u00adtion, the threads \nserve independent transactions and they do not communicate with each other. Thus DDmalloc provides a \nseparate heap for each thread and does not need locks for each heap. For our evaluations, we configured \nthe PHP runtime as a single-threaded application and hence each runtime process owns only one heap. \n   4. Experimental Results This section focuses on the performance comparisons of the Web\u00adbased applications \nwritten in PHP using the default memory allo\u00adcator of the PHP runtime, a region-based allocator, and \nour DDmalloc for managing transaction-scoped objects. 4.1 Platforms and implementations We implemented \nDDmalloc and a region-based allocator for two platforms, Intel's quad-core Xeon (Clovertown) processors \nrun\u00adning Linux and Sun's UltraSPARC T1 (Niagara) processors run\u00adning Solaris. The Xeon system used for \nour evaluation was equipped with two 1.86 GHz quad-core Xeon E5320 processors for a total of eight cores \nand 8 GB of system memory. Red Hat Enterprise Linux 5 was running on the system. The PHP runtime was \ncompiled as a 64-bit binary with gcc-4.1.2. The Niagara sys\u00adtem used for our evaluation was equipped \nwith a 1.2 GHz eight\u00adcore Niagara processor and 16 GB of system memory. Solaris 10 was running on the \nsystem. The PHP runtime was compiled with the C compiler included in Sun Studio 11. None of the experi\u00adments \nused the large pages on Xeon, but they did use the 4-MB pages on Niagara. This was because Linux could \nnot use the large pages without modifying the applications, while Solaris supports them. Although both \nsystems have a total of eight cores, the Ni\u00adagara system provides 32 hardware threads with 4-way multi\u00adthreading \nfor each core, while the Xeon system provides only 8 hardware threads. We selected these two platforms \nto study the performance of the allocators on multicore processors with different focuses. The Xeon processor \nfocuses on fast single-thread performance. Thus the processor has a higher frequency, larger cache memories, \na hardware memory prefetcher, and out-of-order cores. In contrast, the Niagara processor focuses on total \nthroughput by aggregating many simple cores in one chip. Thus the processor has a lower frequency, smaller \ncache memories, no hardware memory pre\u00adfetcher, and in-order cores with 4-way multi-threading. To modify \nthe memory allocator for transaction-scoped ob\u00adjects in the PHP runtime, we simply replaced the custom \nmemory allocator of the PHP runtime with our DDmalloc or the region\u00adbased allocator. We did not need \nto modify other parts of the run\u00adtime for our experiment. Also, we did not need to modify the PHP applications. \nOur region-based allocator obtains a 256 MB chunk of mem\u00adory from the operating system at startup time \nand allocates mem\u00adory objects from the top of the chunk by simply incrementing a pointer showing the \nnext position to allocate. It rounds up the requested size to a multiple of 8 bytes when it allocates \nan object. When the pointer reaches the end of the chunk, the allocator ob\u00adtains the next 256 MB chunk. \nOne 256 MB chunk was large enough for most of the PHP transactions and additional chunks were rarely \nneeded, so the overhead of system calls to obtain additional chunks was negligible here. We also evaluated \nthe GNU obstack [10] as another region-based allocator. However our own region-based allocator outperformed \nthe obstack for the PHP applications. Therefore we used only our own region-based allocator in this paper. \n 4.2 Workloads and configurations We used PHP-5.2.1 for the runtime, lighttpd-1.4.13 for the HTTP server, \nand mysql-4.1.20 for the database server. We also installed the APC-3.0.14 extension to the PHP runtime, \nwhich enhances the performance of PHP applications by caching the compiled intermediate code. Figure \n4 is an overview of the system configu\u00ad database client application server server number of runtimes \n= 16 (Xeon) or 48 (Niagara) Figure 4. System configuration for the measurements. Table 2. Workloads used \nin our measurements  workload version descriptions of the workload MediaWiki 1.9.3 A wiki server program \nSugarCRM 4.5.1 A customer relationship management system eZ Publish 4.0.0 A content management system \nphpBB 3.0.1 A Web-based forum program CakePHP 1.2.0.7296 A Web application framework SPECweb 2005 1.10 \nAn industry-standard benchmark for Web servers with dynamic pages Table 3. Statistics on average number \nof malloc and free calls per transaction and average size of memory allocation per malloc workload numbers \nof calls per transaction allocation size (byte) malloc free realloc MediaWiki (read only) 151770 129141 \n6147 62.1 MediaWiki (read/write) 404983 354775 22371 66.7 SugarCRM 276853 225800 3120 49.3 eZ Publish \n123019 109856 4646 78.6 phpBB 46965 43267 1003 56.3 CakePHP 99195 82645 3574 68.6 SPECweb 3277 2383 106 \n175.6 ration for the measurements. The database server and the client emulator ran on separate machines. \nThe number of PHP runtime processes was 16 for Xeon and 48 for Niagara. We selected a variety of Web \napplications written in PHP and evaluated their performances. Table 2 summarizes these workloads. MediaWiki \n[15] is a wiki server program developed by the WikiMedia foundation for the Wikipedia online encyclopedia. \nWe imported 1,000 articles from a Wikipedia database dump (http://download.wikimedia.org/). We configured \nMediaWiki to use memcached-1.2.1 running on the same machine to cache the results of the database queries. \nWe measured two user scenarios with the MediaWiki: a read-only scenario and a read-write sce\u00adnario. For \nthe read-only scenario, we measured the throughput for reading randomly selected articles. In the read-write \nscenario, the clients opened randomly selected articles for editing and then updated the article instead \nof just reading it in 20% of the total transactions. The emulated clients introduced three seconds of \nthink time between each request. The number of emulated clients was set for the highest throughput that \nallowed the average re\u00adsponse time to stay under 2.0 seconds.  1.2 1.2 on Xeon ter on Niagara ster \n1 rntime 0.8 higher is fasput ovePHP ru higher is fa ve through0.6 relatidefault allocator of 0.4 default \nallocator of PHP runtime 0.2 region-based allocator our DDmalloc 0 aMediade(r CRMi kike)iy) iWWtnliawrrodiaead/SugMeeZr \nbB P Nh eBHisACwphpPbl MEeuECakPSP.Geo 160 ( 140 %) memory management others aster 120 ction (ansa shorter \nis f 100er tr 80mes p 60 allocatorallocatorallocator allocatorallocatorallocatorallocatorallocator normalized \nCPU ti40 allocatorallocatorallocatorbased mallocbased mallocbased allocatorallocatorallocatorallocatorallocatormallocbased \nmallocbased mallocbased mallocbased mallocbased malloc 20 default region\u00adour DDdefault region\u00adour DDdefault \nregion\u00ad our DDdefault region\u00adour DDdefault region\u00adour DDdefault region\u00adour DDdefault region\u00adour DDdefault \nregion\u00adour DD 1 0.8 relative throughput overdefault allocator of PHP runtime 0.6 0.4 default allocator \nof PHP runtime 0.2 region-based allocator our DDmalloc 0 Figure 5. Relative throughput over the default \nallocator of the PHP runtime on 8cores of Xeon and Niagara. For SugarCRM [16], we set up a database with \n512 user ac\u00ad counts and 10 customers for each user. Each emulated client logged into SugarCRM using a \nunique user-id and then repeatedly issued AJAX-style requests to obtain information on a customer assigned \nto that user. For eZ Publish [17], we built a website using the setup wizard included in the distribution. \nWe imported 1,000 articles from an actual blog server as blog posts into the website. Each emulated client \nkept its own session and read randomly selected articles. The phpBB [18] is a popular Internet forum \nsoftware package. We generated 1,000 posts in a database and measured the throughput to read randomly \nselected articles. CakePHP [19] is a framework for developing Web applica\u00ad 0 tions. We built a simple \ntelephone-directory application on top of the framework to focus on the performance of the framework. \nWe generated 100 records in the database and measured the through\u00adput for the following scenario: reading \na table of all of the records, Figure 6. Breakdown of CPU time per transaction on 8 Xeon selecting one \nrecord randomly, and then updating that record. cores. SPECweb2005 [20] is an industry-standard benchmark \nfor Web servers with dynamic pages. We selected the eCommerce 4.3 Performance results scenario of the \nbenchmark, because the other two scenarios em-Figure 5 shows comparisons of the throughput of the applications \nphasize SSL performance (in the Banking scenario) or large file on Xeon and Niagara. Our DDmalloc had \nthe best performance transfers (in the Support scenario) and thus were not suitable for for all applications \non both platforms. The maximum performance evaluating the performance of the PHP runtime itself. Even \nin the advantages over the default allocator of the PHP runtime were eCommerce scenario, the PHP program \nis much simpler than the 11.1% (7.7% on average) on Xeon and 11.4% (8.3% on average)other test applications \nand large amount of CPU time were con\u00adon Niagara. When we enabled the optimization using large pagessumed \nin static file serving. on Xeon, the improvement increased to 11.7% (9.0% on average). Table 3 shows \nthe average sizes of memory allocations per In contrast, the region-based allocator significantly degraded \nthe malloc call and average numbers of calls for malloc, per-object average performance by as much as \n27.2% on Xeon. On Niagara, free, and realloc per transaction for each workload. We include the region-based \nallocator improved the performance of four the number of calls for calloc, a variation of malloc function, \nin workloads, while degrading the other three. As a result, the re\u00adthe number of malloc calls. The number \nof free calls is 7.9% to gion-based allocator average almost matched the default allocator.  27.3% (15.3% \non average) less than that of malloc. This means The maximum performance advantages of our DDmalloc over \nthe some allocated memory objects are not deallocated by per-object region-based memory allocator were \nup to 51.5% (24.2% on av\u00adfree and remain alive until the end of the transaction. Those ob\u00aderage) on Xeon \nand 17.4% (7.0% on average) on Niagara. jects are freed by the freeAll at the end of the transaction. \nMore To examine the differences due to the memory allocators, Fig\u00adthan 80% of the total objects are deallocated \nby per-object free ure 6 compares breakdowns of the system-wide CPU time per and thus the performance \nof the per-object free is still very impor\u00adtransaction as measured on Xeon. In the figure, memory opera\u00adtant, \neven with the runtime calls to freeAll at the ends of the tions include only those for transaction-scoped \nobjects in the PHP transactions. The statistics for SPECweb2005 are slightly differ\u00adruntime and do not \ninclude other memory operations, such as ent from the other applications. The number of malloc and free \nmemory management functions in the operating system. We used calls are significantly smaller than in \nother workloads and the a sampling profiler (Oprofile [21]), which uses a hardware per\u00adaverage size of \nmemory allocation is larger than any other work\u00adformance monitor, and did not insert instrumentation \ncode in the load. As a result, the performance of SPECweb2005 was not sen\u00admemory management functions \nto obtain the execution time of sitive to the memory allocator, as shown later. each call to the allocator. \nAs discussed in Section 1, the region\u00adbased allocator reduced the CPU time used for memory opera\u00ad  \n140 120 140 120 100 throughput (transactions / sec) on Niagara higher is faster throughput (transactions \n/ sec) higher is faster 100 80 80 60 60 40 our DDmalloc region-based allocator dafult allocator of PHP \nruntime 0 02468 02468 number of cores number of cores 0 Figure 7. Throughput of MediaWiki (read-only \nscenario) with increasing numbers of cores on Xeon and Niagara. Table 4. Speedups with 8 cores for each \nworkload our DDmalloc 40 20 20 region-based allocator dafult allocator of PHP runtime workload memory \nallo\u00adcator on Xeon on Niagara throughput with 1 core (transactions/sec) throughput with 8 cores (transactions/sec) \nspeedupwith 8 cores throughput with 1 core (transactions/sec) throughput with 8 cores (transactions/sec) \nspeedupwith 8 cores MediaWiki (read only) default region-based DDmalloc 25.3 26.4 (+4.0%) 26.4 (+4.1%) \n156.6 145.7 (-7.0%) 167.9 (+7.2%) 6.2x 5.5x 6.4x 14.9 16.5 (+11.3%) 16.5 (+11.3%) 111.0 113.3 (+2.1%) \n122.2 (+10.1%) 7.5x 6.9x 7.4x MediaWiki (read/write) default region-based DDmalloc 11.7 12.5 (+6.6%) \n12.7 (+7.9%) 79.6 59.7 (-24.9%) 85.5 (+7.4%) 6.8x 4.8x 6.8x 5.2 5.5 (+5.4%) 5.6 (+7.0%) 40.0 39.6 (-1.1%) \n43.5 (+8.8%) 7.7x 7.2x 7.8x SugarCRM default region-based DDmalloc 19.4 20.8 (+7.2%) 21.1 (+8.9%) 134.6 \n98.0 (-27.2%) 148.4 (+10.2%) 6.9x 4.7x 7.0x 8.1 9.2 (+13.4%) 8.8 (+8.3%) 64.4 62.3 (-3.4%) 69.7 (+8.3%) \n7.9x 6.8x 7.9x eZ Publish default region-based DDmalloc 28.5 31.8 (+11.6%) 32.2 (+12.9%) 178.6 138.3 \n(-22.6%) 196.3 (+9.9%) 6.3x 4.3x 6.1x 13.6 16.5 (+21.1%) 15.8 (+15.9%) 99.4 94.4 (-5.1%) 110.8 (+11.4%) \n7.3x 5.7x 7.0x phpBB default region-based DDmalloc 62.6 69.2 (+10.6%) 69.5 (+11.0%) 402.4 393.5 (-2.2%) \n447.2 (+11.1%) 6.4x 5.7x 6.4x 30.5 35.9 (+17.7%) 34.0 (+11.2%) 234.0 259.1 (+10.8%) 259.8 (+11.0%) 7.7x \n7.2x 7.7x CakePHP default region-based DDmalloc 28.3 31.6 (+11.4%) 30.8 (+8.8%) 191.6 185.7 (-3.1%) 206.6 \n(+7.8%) 6.8x 5.9x 6.7x 12.6 13.8 (+9.3%) 13.6 (+7.7%) 96.7 101.6 (+5.1%) 103.8 (+7.3%) 7.7x 7.4x 7.7x \nSPECweb 2005 default region-based DDmalloc 188.6 197.3 (+4.6%) 194.3 (+3.0%) 970.0 960.4 (-1.0%) 977.3 \n(+0.8%) 5.1x 4.9x 5.0x 115.5 118.3 (+2.4%) 118.4 (+2.5%) 699.3 705.4 (+0.9%) 709.2 (+1.4%) 6.1x 6.0x \n6.0x The ratios in parenthesis show the relative throughputs over the default allocator. tions by 85% \non average compared to the default allocator. Other parts of the programs, however, were slowed down. \nOur DDmal\u00adloc also reduced the overhead for memory management functions by 56% on average and up to 65%. \nThe performance of other parts was unchanged or slightly improved. Comparing the break\u00addown for all workloads, \nSPECweb2005 consumed the least time for memory management. As a result, the effect of memory allo\u00adcators \nwas also least significant. To see the effects of memory allocators on the scalability with increasing \nnumber of cores, Figure 7 compares the throughput of MediaWiki for the read-only scenario with various \nnumbers of cores. DDmalloc consistently outperformed the default allocator. It almost tied the region-based \nallocator for small numbers of cores (up to 2 cores on Xeon and 4 cores on Niagara). However, DDmalloc \ndemonstrated much better scalability with increased numbers of cores compared to the region-based allocator, \nand hence it achieved the best performance among the three allocators when using eight cores on both \nplatforms, as shown in Figure 5. Table 4 summarizes the speedups using eight cores for all work\u00adloads. \nBoth DDmalloc and the region-based allocator improved the performance of every workload when using only \none core on both platforms. However the region-based allocator showed much poorer scalability compared \nto the other two allocators while DDmalloc and the default allocator of the PHP runtime achieved almost \ncomparable speedups for all workloads. Figures 8 shows the changes in the numbers of instructions, cache \nmisses, and bus transactions per Web transaction from the default allocator. On both platforms, DDmalloc \nreduced both L1 and L2 cache misses and bus transactions while the region-based allocator significantly \nincreased the numbers of L2 cache misses and bus transactions. The reduction in instructions and L1 instruc\u00adtion \ncache misses for DDmalloc and the region-based allocator were because of the smaller size of the allocator \ncode. The reduc\u00adtion in L1 data cache misses was mainly because they do not use   change in number \nof events per transaction.change in number of events per transaction.over default allocator of PHP runtime \n(%)over default allocator of PHP runtime (%) lower is better lower is better 60 50 40 30 20 10 0 -10 \n-20 -30 -40  60 50 40 30 20 10 0 -10 -20 -30 total instruction L1I cache miss L1D cache miss D-TLB \nmiss L2 cache miss bus transaction Figure 8. Comparisons of changes in the numbers of instructions, cache \nmisses, and bus transactions per web transaction with our DDmalloc and the region-based allocator on \n8 cores of Xeon and Niagara. the per-object metadata that increases the size of the objects and ference \nwas reduced by disabling the prefetcher. The inferior reduces the cache locality. Both DDmalloc and the \nregion-based scalability of the region-based allocator was unaffected, even allocator increased the D-TLB \nmisses for two or three workloads without the prefetcher. and reduced them for the others. The number \nof TLB misses was These cache miss trends were consistent when we changed the sensitive to the allocator \nand its parameters, such as the size of a numbers of cores used. Our DDmalloc achieved better perform\u00adsegment \nin DDmalloc, because the number of TLB entries is very ance with the PHP runtime because of these improvements \nin the small. For DDmalloc, we chose the parameter values that pro-cache misses in addition to the smaller \nmemory management duced the highest throughput rather than the fewest TLB or cache overhead. In contrast, \nthe region-based allocator was slowed misses. If we enable the large page optimization on Xeon, the down \nby the increases in bus transactions when using large num-TLB misses were reduced by more than 60% compared \nto the ber of cores as shown in Figure 7 and Table 4. Those performance default allocator. The increase \nin L2 cache misses and subsequent degradations for the region-based allocator were less significant bus \ntransactions for the region-based allocator was because it does on Niagara because Niagara provides relatively \nhigher memory not support per-object free and thus cannot reuse the dead objects bandwidth than Xeon. \nresiding in the L2 cache. The increased cache pressure did not Figure 9 shows the average memory consumptions \nduring significantly increase the L1 data cache misses, because only the transactions. We defined memory \nconsumption for each allocator most frequently used data objects were residing in the small L1 as follows: \nthe amount of memory allocated from the underlying cache and the dead objects were quickly spilled out \nof it. On memory allocator for the default allocator, the total amount of Xeon, the increases in bus \ntransactions were much larger than the memory used for allocated segments and the metadata for increases \nin the L2 cache misses. This difference mainly came DDmalloc, and the total amount of memory allocated \nduring a from the hardware memory prefetcher. We observed that the dif-transaction for the region-based \nallocator. DDmalloc consumed  glibc Hoard TCmalloc our DDmalloc 2.5 on 8 Xeon cores. Figure 9. Comparison \nof the amount of memory consumed. 24% more memory on average compared to the default allocator. This \nwas because the segregated heap management, which is the basis of DDmalloc, tends to consume more memory \narea as a trade-off for faster allocation and deallocation. Using a smaller size for segments can reduce \nthe memory consumptions while it often increases the CPU time used for malloc and free. The re\u00ad gion-based \nallocator consumed almost 3 times as much memory on average and more than 7 times more in the worst case. \n  4.4 Performance comparisons with high-performance general-purpose allocators glibc Hoard TCmalloc \nour DDmalloc This section compares the performance of our DDmalloc against the well known general-purpose \nallocators, hoard-3.7 [11] and Figure 11. Breakdown of CPU time per transaction for Ruby TCmalloc [12] \nincluded in the google-perf-tools-0.9.1. Those on Rails on 8 Xeon cores with various allocators. general-purpose \nallocators support only the malloc-free interface, and thus they are not applicable to the PHP runtime. \nTherefore we used the Ruby runtime for this comparison. The Ruby runtime does not call freeAll at the \nend of each Web transaction and does not distinguish between the allocations for transaction-scoped objects \nand other objects. To compare the performance of DDmalloc to the general-purpose allocators, we did not \nmodify the runtime to call freeAll. Instead, we configured the runtime to restart periodically (once \nper 500 transactions) to clean up the entire heap without calling freeAll. This allows direct compari\u00ad \nsons with these general-purpose allocators supporting only malloc and free, though this is not the best \nway to clean up the heap for DDmalloc because restarting process incurs more overhead than (non-zero \n20 100 500 2500 no restart origin) lifetime of one process (number of transactions) the freeAll function \nand once per 500 transactions is not short enough to totally ignore the gradual degradations due to heap \nfragmentation. Restarting the processes of scripting language runtimes is a common practice to avoid \nperformance degradations even with standard memory allocators. Thereby we configured the runtime to restart \nevery 500 transactions for all of the alloca\u00adtors because it was beneficial for all of the allocators. \nWe selected Ruby on Rails-1.2.3 [22] as a workload for the evaluation. Ruby on Rails is a framework for \ndeveloping Web applications. We followed the evaluation for CakePHP, building a similar application on \ntop of Ruby on Rails and evaluating it us\u00ading the same scenario. We used the prebuilt binary of the ruby\u00ad \n1.8.5 included in the OS distribution and dynamically linked each memory allocator at runtime. The other \nserver configurations were unchanged from the measurements for PHP. Figure 10 shows the comparisons for \nthe throughput with various memory allocators on all eight cores of Xeon. Our DDmalloc again achieved \nthe best performance. The performance advantage over Figure 12. Performance improvements by restarting \nRuby processes for various periods of restart on 8 Xeon cores. the default allocator, glibc-2.5, was \n13.6%. Hoard and TCmalloc also outperformed glibc. DDmalloc outperformed the next best allocator, TCmalloc, \nby 5.3%. Figure 11 compares the breakdowns of CPU cycles per trans\u00adaction. All of the results are normalized \nagainst the results for glibc, the default allocator for the platform. DDmalloc obviously spent the least \ntime on memory operations among the tested allo\u00adcators by avoiding the costs for defragmentation activities \nin mal\u00adloc and free. The results show that the costs of the defragmentation activities exceed the benefits \nin Web-based ap\u00adplications even in those sophisticated memory allocators, and the costs matter for the \noverall performance of the workloads.  In our DDmalloc, objects in the free lists are chained in ran\u00addom \norder after a long run without defragmentation activities. Hence DDmalloc starts to allocating separated \nobjects for succes\u00adsive allocation requests. Such allocations tend to decrease the cache locality. To \nsee this degradation more quantitatively, Figure 12 depicts the performance improvements from restarting \nthe processes of the Ruby runtime to clean up the heap. From this figure, restarting a process after \nevery 500 transactions improved throughput by 4.0% compared to no restarts for our DDmalloc while the \nimprovement was only 1.1% for glibc. We observed that restarting a process after every 500 transactions \nreduced the number of L2 cache misses per transaction by 8.0% for DDmalloc while it was 2.5% for glibc. \nThe reductions in the L1 cache misses by restarting the process were only 0.3% and 0.8% for DDmalloc \nand glibc respectively. These results show that, even without restarting, DDmalloc was almost as fast \nas the TCmalloc and still faster than glibc or Hoard. This was because the benefit of efficient malloc \nand free of DDmalloc due to no defragmentation outweighed the cost of increased L2 cache misses due to \nfragmentations for this particu\u00adlar workload. We have evaluated only one application in this sec\u00adtion \nand more extensive study on the benefit and cost of defragmentation is an interesting future work.  \n 5. Discussions In this section, we consider how important our observations are for systems other than \nWeb application servers. The language runtime systems supporting garbage collection for memory management, \nsuch as JavaTM VMs and .net runtimes, are widely used today. Many of these virtual machines, especially \nthose using copying garbage collectors, allocate heap memory for newly created objects in a similar way \nto the region-based alloca\u00adtors, in which the allocation is done by simply incrementing a pointer that \ntracks the current location to allocate. This allocation mechanism is widely used because of the virtue \nof small alloca\u00adtion overhead. In those virtual machines, however, allocated ob\u00adjects are not freed until \nthe heap becomes full and the virtual machines execute garbage collection. Hence the virtual machines \nmay suffer from the increased bus traffic on multicore processors, just as the region-based allocator \nsuffers in the PHP runtime, be\u00adcause they cannot reuse the memory locations used by already\u00addead objects. \nIn the GC-based languages, programmers do not free objects explicitly and hence reusing the memory locations \nquickly is not a trivial task. However techniques to quickly reclaim short-lived objects are quite important \nto reduce the hidden costs of the in\u00adcreased bus traffic and to achieve high performance on multicore \nprocessors. For example, the advanced escape analysis of Shankar et al. [23] is a good way to quickly \nreuse the short-lived objects by allocating them on a stack. For another example, MicroPhase of Xian \net al. [24] can improve the memory locality by aggres\u00adsively invoking a garbage collection before the \nJava heap be\u00adcomes full. 6. Related Work Memory management consumes a considerable fraction of CPU time \nin applications [25]. Therefore many designs of dynamic memory management have been proposed in the past \n[26]. For general purpose use, an allocator by Doug Lea [13] is known as one of the most advanced designs \nof dynamic memory manage\u00adment, which balances several goals, including speed, space, and portability. \nRecent advances in multicore processors require good scalability for every application. Hence currently \nmany memory allocators focus on scalability for multi-threaded applications. Hoard [11], TCmalloc (included \nin google-perf-tools) [12] are such examples. Many of them achieve good scalability of multi\u00adthreaded \napplications by avoiding lock contentions for heap ac\u00adcesses and false sharing. In this paper, we focus \non poor scalabil\u00adity caused by the limited bus bandwidth on multicore processors as another reason for \npoor scalability. There have been many efforts to exploit knowledge about the characteristics of the \napplications, such as the lifetimes or sizes of the objects, to improve the performance of memory management \n[1-4, 27, 28]. Region-based memory management [1-4], which allows fast allocation by simply incrementing \na pointer and free\u00ading multiple objects at once, is one of the most attractive ways to exploit the knowledge \nof the lifetimes of the objects. As already discussed in this paper, the region-based memory management \nis very effective in reducing the overhead of memory management. However, it may suffer from poor scalability \non multicore proces\u00adsors. Our proposed defrag-dodging approach can also exploit the knowledge of the \nobject lifetimes to reduce the overhead of mem\u00adory management, but it yields higher scalability than \nthe region\u00adbased memory management. Berger et al. [9] proposed an allocator, called Reaps, that com\u00adbines \nthe conventional malloc/free and the region-based memory management. Like our defrag-dodging approach \nor the custom allocator in the PHP runtime, it supports both per-object free and bulk free for all of \nthe objects in a region. In contrast to ours, their allocator acts in almost the same way as Doug Lea's \nallocator [13] for per-object free and does not focus on improving the perform\u00adances of the per-object \nfree. Thus the Reaps also pays cost of the defragmentation activities, which is excessive for short-lived \ntransactions in Web-based applications, like the default allocator of the PHP runtime.  7. Conclusions \nIn this paper, we examine the performance of a general-purpose allocator and a non-freeing region-based \nallocator using Web\u00adbased workloads on two platforms with multicore processors. Our results show that \nthe region-based allocator achieves much better performance for all workloads on one or a few processor \ncores due to its smaller memory management costs. However the re\u00adgion-based allocators suffer from hidden \ncosts of increased bus traffic on multicore environments and the performance is reduced by as much as \n27.2% compared to the default allocator when using eight cores. This is because the system memory bandwidth \ntends to become a bottleneck in systems with multicore proces\u00adsors. This paper describes a new memory \nmanagement approach, called defrag-dodging, for transaction-scoped objects in Web\u00adbased applications. \nThe approach can improve the performance of Web-based applications on multicore processors by reducing \nthe total costs of memory management without increasing the bus traffic. The key to the reduced costs \nfor memory management in the defrag-dodging allocator is that it avoids the defragmentation activities \nin the malloc and free invocations during transactions. In Web-based applications, the costs of the defragmentation \nac\u00adtivities in existing general-purpose allocators outweigh their bene\u00adfits. We show that the throughput \nwith our new approach is higher than with the other two allocators for all of the applications when using \neight cores. The improvements are up to 11.4% and 51.5% over the default allocator and the region-based \nallocator, respec\u00adtively. Our results show that the increasing use of multicore proc\u00adessors is significantly \nchanging the requirements for memory allocators to fully benefit from the large amounts of computing \nresources provided by such multicore processors.  We are grateful to the anonymous reviewers for their \nthoughtful comments and suggestions. We thank Tamiya Onodera, Rei Odaira, and Kazunori Ogata for their \nuseful feedback on earlier drafts on this work. We also thank Shannon Jacobs for his edito\u00adrial assistance \nand valuable suggestions including the name de\u00adfrag-dodging.  References [1] D. R. Hanson. Fast allocation \nand deallocation of memory based on object lifetimes. Software Practice &#38; Experience, 20(1), pp. \n5 12, 1990. [2] D. A. Barrett and B. G. Zorn. Using Lifetime Predictors to Improve Memory Allocation \nPerformance. In Proceedings of the ACM Con\u00adference on Programming Language Design and Implementation, \npp. 187 196, 1993. [3] D. Gay and A Aiken. Memory management with explicit regions. In Proceedings of \nthe ACM Conference on Programming Language Design and Implementation, pp. 313 323, 1998 [4] D. Grossman, \nG. Morrisett, T. Jim, M. Hicks, Y. Wang, and J. Che\u00adney. Region-Based Memory Management in Cyclone. In \nProceed\u00adings of the ACM Conference on Programming Language Design and Implementation, pp. 282 293, 2002. \n[5] Apache Software Foundation. The Apache Portable Runtime Project. http://apr.apache.org/ . [6] R. \nIyer, M. Bhat, L. Zhao, R. Illikkal, S. Makineni, M. Jones, K. Shiv, and D. Newell. Exploring Small-Scale \nand Large-Scale CMP Archi\u00adtectures for Commercial Java Servers. In Proceedings of the IEEE In\u00adternational \nSymposium on Workload Characterization, pp. 191 200, 2006. [7] Y. Chen, E. Li, W. Li, T. Wang, J. Li, \nX. Tong, P. P. Wang, W. Hu, Y. Zhang, Y. Chen. Media mining emerging tera-scale computing applications. \nIntel Technology Journal, 11(3), pp 239 250, 2007. [8] The PHP Group. PHP: Hypertext Preprocessor. http://www.php.net/ \n. [9] E. D. Berger, B. G. Zorn, and K. S. McKinley. Reconsidering custom memory allocation. In Proceedings \nof the ACM Conference on Ob\u00adject Oriented Programming, Systems, Languages, and Applications, pp. 1 12, \n2002. [10] Free Software Foundation, Inc. GNU C Library obstack. http://www.gnu.org/software/libc/manual/html_node/Obstacks.html. \n[11] E. D. Berger, K. S. McKinley, R. D. Blumofe, and P. R. Wilson. Hoard: A Scalable Memory Allocator \nfor Multithreaded Applications. In Proceedings of the International Conference on Architectural Support \nfor Programming Languages and Operating Systems, pp. 117 128, 2000. [12] S. Ghemawat and P. Menage. TCMalloc \n: Thread-Caching Malloc. http://goog-perftools.sourceforge.net/doc/tcmalloc.html . [13] Doug Lea. A Memory \nAllocator. http://g.oswego.edu/dl/html/malloc.html . [14] M. S. Johnstone and P. R. Wilson. The memory \nfragmentation prob\u00adlem: Solved. In Proceedings of the International Symposium on Memory Management, pp. \n26 36, 1998. [15] Wikimedia Foundation. MediaWiki. http://www.mediawiki.org . [16] SugarCRM Inc. SugarCRM. \nhttp://www.sugarcrm.com . [17] eZ Systems. eZ Publish. http://ez.no . [18] The phpBB Group. phpBB. http://www.phpbb.com/ \n. [19] Cake Software Foundation, Inc. CakePHP. http://www.cakephp.org/ . [20] Standard Performance Evaluation \nCorporation. SPECweb2005. http://www.spec.org/web2005/ . [21] OProfile - A System Profiler for Linux. \nhttp://oprofile.sourceforge.net/news/ . [22] D. H. Hansson. Ruby on Rails. http://www.rubyonrails.org \n. [23] A. Shankar, M. Arnold, and R. Bodik. Jolt: lightweight dynamic analysis and removal of object \nchurn. In Proceedings of the ACM Conference on Object Oriented Programming Systems Languages and Applications, \npp. 127 142, 2008. [24] F. Xian, W. Srisa-an, and, H. Jiang. Microphase: an approach to proactively invoking \ngarbage collection for improved performance. In Proceedings of the ACM Conference on Object Oriented \nPro\u00adgramming Systems Languages and Applications, pp. 77 96, 2007. [25] D. Detlefs, A. Dosser, and B. \nZorn. Memory allocation costs in large C and C++ programs. Software Practice &#38; Experience, 24(6), \npp. 527 542, 1994. [26] P. R. Wilson, M. S. Johnstone, M. Neely, and D. Boles. Dynamic Storage Allocation: \nA Survey and Critical Review. In Proceedings of the International Workshop on Memory Management, pp. \n1 116, 1995. [27] M. L. Seidl, and B. G. Zorn. Segregating heap objects by reference behavior and lifetime. \nIn Proceedings of the International Confer\u00adence on Architectural Support for Programming Languages and \nOp\u00aderating Systems, pp. 12 23, 1998. [28] Y. Shuf, M. Gupta, R. Bordawekar, and J. P. Singh. Exploiting \npro\u00adlific types for memory management and optimizations. In Proceed\u00adings of the ACM Symposium on Principles \nof Programming Languages, pp. 295 306, 2002. Java is a trademark of Sun Microsystems, Inc. Intel and \nXeon are registered trademarks of Intel Corporation. Other company, prod\u00aduct, and service names may be \ntrademarks or service marks of others.  \n\t\t\t", "proc_id": "1542476", "abstract": "<p>More and more server workloads are becoming Web-based. In these Web-based workloads, most of the memory objects are used only during one transaction. We study the effect of the memory management approaches on the performance of such Web-based applications on two modern multicore processors. In particular, using six PHP applications, we compare a general-purpose allocator (the default allocator of the PHP runtime) and a region-based allocator, which can reduce the cost of memory management by not supporting per-object free. The region-based allocator achieves better performance for all workloads on one processor core due to its smaller memory management cost. However, when using eight cores, the region-based allocator suffers from hidden costs of increased bus traffics and the performance is reduced for many workloads by as much as 27.2% compared to the default allocator. This is because the memory bandwidth tends to become a bottleneck in systems with multicore processors.</p> <p>We propose a new memory management approach, <i>defrag-dodging</i>, to maximize the performance of the Web-based workloads on multicore processors. In our approach, we reduce the memory management cost by avoiding defragmentation overhead in the malloc and free functions during a transaction. We found that the transactions in Web-based applications are short enough to ignore heap fragmentation, and hence the costs of the defrag-mentation activities in existing general-purpose allocators outweigh their benefits. By comparing our approach against the region-based approach, we show that a per-object free capability can reduce bus traffic and achieve higher performance on multicore processors. We demonstrate that our defrag-dodging approach improves the performance of all the evaluated applications on both processors by up to 11.4% and 51.5% over the default allocator and the region-based allocator, respectively.</p>", "authors": [{"name": "Hiroshi Inoue", "author_profile_id": "81100619710", "affiliation": "IBM, Kanagawa, Japan", "person_id": "P1464326", "email_address": "", "orcid_id": ""}, {"name": "Hideaki Komatsu", "author_profile_id": "81100557247", "affiliation": "IBM, Kanagawa, Japan", "person_id": "P1464327", "email_address": "", "orcid_id": ""}, {"name": "Toshio Nakatani", "author_profile_id": "81100311827", "affiliation": "IBM , Kanagawa, Japan", "person_id": "P1464328", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542520", "year": "2009", "article_id": "1542520", "conference": "PLDI", "title": "A study of memory management for web-based applications on multicore processors", "url": "http://dl.acm.org/citation.cfm?id=1542520"}