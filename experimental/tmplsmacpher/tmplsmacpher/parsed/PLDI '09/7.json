{"article_publication_date": "06-15-2009", "fulltext": "\n TAJ: Effective Taint Analysis of Web Applications Omer Tripp Marco Pistoia Stephen Fink Manu Sridharan \nOmri Weisman IBM Software Group IBM T. J. Watson Research Center IBM Software Group omert@il.ibm.com \n{pistoia,sj.nk,msridhar}@us.ibm.com weisman@il.ibm.com Abstract Taint analysis, a form of information-.ow \nanalysis, establishes whether values from untrusted methods and parameters may .ow into security-sensitive \noperations. Taint analysis can detect many common vulnerabilities in Web applications, and so has attracted \nmuch attention from both the research community and industry. However, most static taint-analysis tools \ndo not address criti\u00adcal requirements for an industrial-strength tool. Speci.cally, an industrial-strength \ntool must scale to large industrial Web applica\u00adtions, model essential Web-application code artifacts, \nand generate consumable reports for a wide range of attack vectors. We have designed and implemented \na static Taint Analysis for Java (TAJ) that meets the requirements of industry-level applica\u00adtions. TAJ \ncan analyze applications of virtually any size, as it em\u00adploys a set of techniques designed to produce \nuseful answers given limited time and space. TAJ addresses a wide variety of attack vec\u00adtors, with techniques \nto handle re.ective calls, .ow through con\u00adtainers, nested taint, and issues in generating useful reports. \nThis paper provides a description of the algorithms comprising TAJ, evaluates TAJ against production-level \nbenchmarks, and compares it with alternative solutions. Categories and Subject Descriptors D.2.4 [Software \nEngineer\u00ading]: Software/Program Veri.cation; D.2.5 [Software Engineer\u00ading]: Testing and Debugging General \nTerms Static Analysis, Web Applications, Security Keywords Security, Static Analysis, Taint Analysis, \nInformation Flow, Integrity, Web Applications 1. Introduction Information-.ow violations [8] comprise \nthe most serious security vulnerabilities in today s Web applications. In fact, according to the Open \nWeb Application Security Project (OWASP) [26], they constitute the top six security problems. Automatically \ndetecting such vulnerabilities in real-world Web applications may be dif.cult due to their size and complexity. \nManual code inspection is often ineffective for such complex programs, and security testing may remain \ninconclusive due to insuf.cient coverage. This paper proposes a static-analysis solution that detects \nfour of the aforementioned top six security vulnerabilities [26]: Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. \nCopyright c &#38;#169; 2009 ACM 978-1-60558-392-1/09/06. . . $5.00 Cross-site scripting (XSS) attacks \n(the most common vulnera\u00adbility) may occur when a Web application accepts data originat\u00ading from a user \nand sends it to another user s browser without .rst validating or encoding it. For example, suppose an \nattacker embeds malicious JavaScript code into his or her pro.le on a social Web site. If the site fails \nto validate such input, that code may execute in the browser of any other user who visits that pro.le. \n Injection .aws (the second most frequent vulnerability) arise when a Web application accepts input \nfrom a user and sends it to an interpreter as part of a command or query, without .rst validating it. \nVia this vulnerability, an attacker can trick the interpreter into executing unintended commands or changing \ndata. The most common attack of this type is Structured Query Language injection (SQLi).  Malicious \n.le executions (the third most common vulnerability) happen when a Web application improperly trusts \ninput .les or uses unveri.ed user data in stream functions, thereby allowing hostile content to be executed \non the server.  Information leakage and improper error-handling attacks (the sixth most common vulnerability) \ntake place when a Web ap\u00adplication leaks information about its own con.guration, mech\u00adanisms, and internal \nproblems. Attackers use this weakness to steal sensitive data or re.ne their attacks.  Each of these \nvulnerabilities can be cast as a problem in which tainted information from an untrusted source propagates, \nthrough data and/or control .ow, to a high-integrity sink without being properly endorsed (i.e., corrected \nor validated) by a sanitizer . To address these vulnerabilities, the research community has fo\u00adcused \nmuch attention on static analysis for information-.ow secu\u00adrity of Web applications. Unfortunately, many \nof the published ap\u00adproaches do not immediately apply to industrial Web applications. Many existing solutions \nrequire use of complex, non-standard type systems, which are unlikely to enjoy broad adoption [36; 24; \n30]. Other solutions, based on precise program slicing [16], have not been shown to be suf.ciently scalable \n[31; 13]. In this paper, we present Taint Analysis for Java (TAJ), a tool designed to be precise enough \nto produce a low false-positive rate, yet scalable enough to allow the analysis of large applications. \nTAJ incorporates a number of techniques to produce useful results on extremely large applications, even \nwhen constrained to a given time or memory budget. Furthermore, TAJ supports many complex fea\u00adtures of \nJava Platform, Enterprise Edition (Java EE) Web applica\u00adtions that were often omitted from discussion \nin previous work. In addition to a general overview of TAJ, this paper makes the following speci.c contributions: \nHybrid thin slicing. We present a novel thin-slicing algo\u00adrithm [33] that combines .ow-insensitive data-.ow \npropaga\u00adtion through the heap with .ow-and context-sensitive data-.ow propagation through local variables. \n An effective model for static analysis of Web applications. TAJ models re.ective calls, tainted .ows \nthrough containers, detection of taint in the internal state of objects, the JavaServer Pages (JSP), \nEnterprise JavaBeans (EJB), the Struts and Spring frameworks, and many other challenging features that \nhave largely been ignored in the literature but are essential for ef\u00adfective analysis of Web applications. \n A set of bounded analysis techniques. When applications are extremely large and the end user still requires \nthe analysis to terminate in a short time or stay below a given memory\u00adconsumption level, TAJ supports \na prioritization policy that focuses the analysis on portions of the Web application that are likely \nto participate in taint propagation.  Implementation and evaluation. We have implemented TAJ on top \nof the T. J. Watson Libraries for Analysis (WALA) [35] and shipped it as part of a commercial product \n[17]. We present implementation details of TAJ and experimental results ob\u00adtained by running TAJ on industrial \ncodes. These results in\u00adclude comparisons between our techniques and alternative ap\u00adproaches.  The remainder \nof this paper proceeds as follows: Section 2 presents a code sample demonstrating the challenges faced \nby taint analysis. Section 3 details the TAJ framework and underlying algorithms. In Section 4, we discuss \ncode-modeling techniques to boost the accuracy and scalability of TAJ, and in Section 5, we present a \ntechnique that reduces the number of redundant reports presented to the user. Techniques for bounded \nanalysis appear in Section 6. TAJ is evaluated in Section 7. Related work is described in Section 8. \nWe conclude and discuss future work in Section 9. 2. Motivating Example The example in Figure 1 shows \nsome of the challenges faced by static taint-analysis tools.1 Designed for expository purposes, the example \nshows a Java Web application reading untrusted data from servlet parameters. The example also shows some \nmanipulation of data via re.ection, which often occurs in the implementation of Web frameworks such as \nStruts or Spring. Since a practical tool cannot anticipate all Web frameworks that customer code may \nrely on, the tool is often forced to analyzed framework implementata\u00adtions directly, including re.ective \ncalls. In the code sample, the tainted strings t1 and t2 get their val\u00adues from the calls to getParameter \nat lines 13 and 14, respec\u00adtively. Next, a series of re.ective calls acquire a reference to class Motivating \nat line 18, gain access to method id at lines 19-26, and invoke it at lines 31-36. Speci.cally, id is \ninvoked (re.ectively) three times: .rst with a tainted argument (the value corresponding to key \"fName\" \nin map m) at lines 31-32, then with a sanitized argument (the value corresponding to key \"lName\", sanitized \nby a call to URLEncoder.encode) at lines 33-34, and .nally with a non-tainted argument (the value corresponding \nto key \"date\")at lines 35-36. Since only the .rst call to id involves a tainted value, string s1 which \n.ows into the constructor of object i1 at line 37 is tainted, whereas s2 and s3 which .ow to the constructors \nof objects i2 and i3 at lines 38 and 39, respectively are not. Method println is considered an XSS sink \nbecause it renders the string value of its input to the screen. Thus, the call to println with argument \ni1 at line 40 poses a security issue. The other two calls to println at lines 41 and 42 are benign. 1 \nThe example is partially inspired by the Refl1 case in Stanford Se\u00adcuriBench Micro [34]. This example \nillustrates many of the challenges posed by static taint analysis of real programs. To analyze this code \nprecisely, the analysis must track .ow through re.ective calls [19] as well as through containers (the \nmap m) and object .elds (the objects .owing into println are i1, i2 and i3, rather than s1, s2 and s3). \nStatic-analysis algorithms that cannot disambiguate the three calls to invoke on idMethod, as well as \nthe three instances of Motivating$Internal, will fail to distinguish between the vul\u00adnerable and benign \ncalls to println. Similar problems would arise from an inability to distinguish the results of the three \ncalls to method get on map m, based on the key provided as an argument. 1: 2: 3: 4: 5: 6: 7: 8: 9: 10: \n11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 29: 30: 31: 32: 33: 34: 35: 36: \n37: 38: 39: 40: 41: 42: 43: 44: 45: 46: 47: 48: 49: 50: public class Motivating { private static class \nInternal { private String s; public Internal(String s) { this.s = s; } public String toString() { return \ns; } } protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws IOException {String \nt1 = req.getParameter(\"fName\"); String t2 = req.getParameter(\"lName\"); PrintWriter writer = resp.getWriter(); \nMethod idMethod = null; try { Class k = Class.forName(\"Motivating\"); Method methods[] = k.getMethods(); \nfor (int i = 0; i < methods.length; i++) { Method method = methods[i]; if (method.getName().equals(\"id\")) \n{ idMethod = method; break; } } Map m = new HashMap(); m.put(\"fName\", t1); m.put(\"lName\", t2); m.put(\"date\", \nnew String(Date.getDate())); String s1 = (String) idMethod.invoke(this, new Object[] {m.get(\"fName\")}); \nString s2 = (String) idMethod.invoke(this, new Object[] {URLEncoder.encode(m.get(\"lName\"))}); String \ns3 = (String) idMethod.invoke(this, new Object[] {m.get(\"date\")}); Internal i1 = new Internal(s1); Internal \ni2 = new Internal(s2); Internal i3 = new Internal(s3); writer.println(i1); // BAD writer.println(i2); \n// OK writer.println(i3); // OK } catch(Exception e) { e.printStackTrace(); } } public String id(String \nstring) { return string; }} Figure 1. Motivating Program 3. Core Taint Analysis TAJ takes a Web application \nand its supporting libraries, and checks it with respect to a set of security rules . Each security rule \nis of the form (S1,S2,S3), where S1 is a set of sources , S2 is a set of sanitizers , and S3 is a set \nof sinks . A source is a method whose return value is considered tainted, or untrusted.2 A sanitizer \nis a method that manipulates its input to produce taint-free output. A sink is a pair (m, P ), where \nm is a method that performs security\u00adsensitive computations and P contains those parameters of m that \nare vulnerable to attack via tainted data. TAJ statically checks that no value derived from a source \nis passed as an input to a sink unless it .rst undergoes appropriate sanitization.  TAJ consists of \ntwo stages. The .rst phase performs pointer analysis and builds a call graph. The second phase runs a \nnovel slicing algorithm to track tainted data. 3.1 Pointer Analysis and Call-graph Construction The TAJ \narchitecture supports any preliminary pointer analysis and call graph construction algorithm. The current \nimplementation relies on a context-sensitive variant of Andersen s analysis [1] with on-the-.y call graph \nconstruction. TAJ employs a custom context-sensitivity policy tuned to ad\u00address precision and performance \nissues that arise when analyzing real codes. Most methods are analyzed with one level of object sensitivity \n[18; 22], in which the context of a method invocation consists of the invoked method and the object abstraction \nrepresent\u00ading the receiver. The policy also includes careful treatment of col\u00adlections and security-related \nApplication Programming Interfaces (APIs). In particular: Java collection classes are treated with unlimited-depth \n(up to recursion) object-sensitivity. This means that all internal objects of a collection are cloned \nfor each collection instance. As a result, the contents of Java collections from different allocation \nsites are fully disambiguated, eliminating a major source of pointer-analysis pollution.  The pointer \nanalysis adds one level of call-string context to calls to library factory methods. These methods tend \nto pollute pointer-.ow precision if handled without context sensitivity, because all the objects created \nby a factory method share the same allocation site.  Taint-speci.c APIs, such as sources and sinks, \nare also analyzed with one level of call-string context. This is necessary due to the special role these \nAPIs play in taint propagation. In the example given in Figure 1, this context allows TAJ to disambiguate \nthe two calls to source method getParameter at lines 13 and 14, even though they are performed on the \nsame receiver object.  As for other dimensions of precision, the pointer analysis of TAJ is .eld-sensitive \n[29]. Furthermore, it relies on a Static-Single As\u00adsignment (SSA) register-transfer language representation \nof each method [6], which gives a measure of .ow sensitivity for points-to sets of local variables [14]. \n 3.2 Hybrid Thin Slicing Using the preliminary pointer analysis and call graph, the second phase of \nTAJ tracks data .ow from tainted sources using hybrid thin slicing, a novel thin-slicing algorithm [33]. \nHybrid thin slicing combines .ow-insensitive reasoning about .ow through the heap with .ow-and context-sensitive \ntracking of .ow through local variables. Thin slicing [33] is a good basis for taint analysis since a \nthin slice typically captures the statements most relevant to a tainted .ow. A forward thin slice from \na statement t consists of those state\u00adments that are data-dependent on t [16], excluding base-pointer \nde\u00adpendencies: for a store statement x.f=y, dependencies due to 2 Some methods, such as RandomAccessFile.readFully \nin package java.io, receive parameters by reference and taint their internal state. TAJ also supports \nthe speci.cation of such methods as sources. uses of the base pointer x are ignored; loads are handled \nsimilarly. Thin slices are typically much smaller and more understandable than program slices. Note that \nin [33], the term thin slice refers to a backward thin slice, in which data dependencies are consid\u00adered \nin the opposite direction, while here we use this term to mean a forward thin slice. Thin slices do not \ninclude control dependencies, and hence TAJ does not track the corresponding indirect information .ow. \nExperience shows that attacks based on control dependence are rare and complex, and thus less important \nthan direct vulnerabilities. Hybrid thin slicing combines aspects of the previously proposed context-sensitive \n(CS) and context-insensitive (CI) thin slicing al\u00adgorithms [33], achieving a better tradeoff between \nscalability and precision for taint analysis. Like CS thin slicing, hybrid thin slicing tracks .ow through \nlocal variables with .ow and context sensitiv\u00adity. However, unlike CS thin slicing, the hybrid technique \ndoes not track heap data dependencies via additional method parameters and return values, as this treatment \nis a scalability bottleneck [33]. This handling of heap dependencies by CS thin slicing is also unsound \nfor multi-threaded programs since it is partially .ow-sensitive, and many of our target Web applications \nare multi-threaded. Instead, hybrid thin slicing tracks heap data dependencies via direct edges from \nstores to loads. Such edges are added based on the prelim\u00adinary pointer analysis, as in CI thin slicing. \nAs we shall show in Section 7, the hybrid approach yields better scalability than CS thin slicing and \nbetter precision than CI thin slicing (with better perfor\u00admance than CI in some cases). Hybrid thin slicing \nperforms a demand-driven traversal over a special System Dependence Graph (SDG) [16] called the Hybrid \nSDG (HSDG). Nodes in an HSDG correspond to load and store statements in the program, as well as call \nstatements representing source and sink methods. An HSDG has two types of edges representing data dependence: \ndirect edges and summary edges . A direct edge connects a store to a load and represents a data dependence \ncomputed by a preliminary pointer analysis (as in CI thin slicing [33]). A sum\u00admary edge can connect \ns to t if t is transitively data-dependent on s purely via .ow through local variables; .ow through the \nheap is excluded. Summary edges are obtained on demand by comput\u00ading context-sensitive reachability over \na no-heap SDG an SDG that elides all control-and data-dependence edges re.ecting .ow through heap locations. \nNote that the no-heap SDG includes no successor edges for sanitizer return and sink call statements, \nsince we need not track .ow beyond these statements. TAJ computes the successors of a statement x in \nthe HSDG on demand, as follows: If x = st is a store statement, then precomputed points-to information \nis used to connect st to all load statements l such that the base pointers of st and l are may-aliased. \n Otherwise, a context-sensitive slice is computed from program point x on the no-heap SDG using the \nReps-Horwitz-Sagiv (RHS) tabulation algorithm [28]. All the statements in the slice corresponding to \nstore instructions and sink invocations are registered as the successors of x.  Figure 2 shows an example, \nwhich displays the slice computed on the no-heap SDG corresponding to a load-to-store summary edge in \nthe HSDG. To .nd tainted .ows, we compute reachability in the HSDG from each source-call statement s, \nadding the necessary direct and summary edges on demand. The nodes reachable from s represent the load, \nstore, and sink statements directly data-dependent on s (ignoring base-pointer data dependencies). Our \n.nal output recon\u00adstructs thin slices from s to sensitive sinks via the HSDG and rele\u00advant no-heap SDGs. \n  Store statement Load statement Sink-dispatch statement Call statement Return statement Other statement \nStore-to-load direct edge Load-to-store or load\u00adto-sink summary edge No-heap SDG edge Figure 2. Fragment \nof the HSDG Comparison to Re.nement-Based Pointer Analysis The hybrid thin-slicing algorithm can be described \nin terms of Re.nement-Based Pointer Analysis (RBPA) [32]. Our direct edges from stores to loads correspond \nto match edges in RBPA. However, whereas the initial match edges in RBPA are based solely on .eld types, \nour algorithm computes initial match edges more precisely with a preliminary pointer analysis. Thus, \nwhile RBPA starts with a relatively imprecise solution and tries to recover precision through re.nement, \nour approach starts with a relatively precise solution and does not re.ne. A second difference between \nhybrid thin-slicing and RBPA is that the latter is forced to collapse strongly-connected call-graph components \ndiscovered during analysis. In contrast, since hybrid thin slicing does not re.ne match edges, it can \nalso handle method recursion on match-edge-free subpaths precisely. We studied the re.nement-based approach \nand found that it introduces additional false positives compared to our approach, which we wished to \navoid. 4. Code-modeling Techniques In this section, we detail modeling techniques used to deal with code \nthat TAJ either (1) cannot analyze (for example, native code) or (2) does not analyze directly for ef.ciency. \nIn Section 4.1, we describe modeling speci.c to checking security properties, and in Section 4.2 we discuss \nmore generally-applicable modeling tech\u00adniques. 4.1 Security-speci.c Modeling This section presents \nthe code-modeling techniques employed by TAJ to effectively capture taint .ows due to objects that carry \ntainted data as part of their internal states. It also shows how code modeling can be used to detect \ninformation leakage and improper error handling, a vulnerability de.ned in Section 1. 4.1.1 Taint Carriers \nTAJ must handle cases where tainted data is passed to a sensitive sink via the internal state of a parameter, \nrather than the param\u00adeter itself. For example, in line 40 of Figure 1, a tainted String is passed to \nthe println sink method indirectly, wrapped in an Internal object. This constitutes a security vulnerability \nwhich must be .agged by TAJ. We use the term taint carrier to refer to an object whose internal state \ncontains tainted data. TAJ handles taint carriers by reporting an issue whenever a taint carrier is passed \nas a sensitive parameter to a sink. Ideally, speci.cations would indicate precisely which access paths \nof sink parameters must not hold sensitive data, in which case the analysis could check these access \npaths directly. However, in many cases such speci.cations would be dif.cult or impossible to write, e.g., \nwhen a sink uses native code or when it takes a parameter of interface type. To avoid missing issues, \nwe treat any passing of a taint carrier to a sink as a possible bug. Our implementation handles taint \ncarriers by using the prelimi\u00adnary pointer analysis to augment the HSDG with additional edges. We consider \na pointer-analysis solution as a heap graph [10] a bipartite graph whose nodes represent abstract objects \n(henceforth, instance keys) and abstract pointers (henceforth, pointer keys). Given pointer key P and \ninstance key I, an edge P . I indi\u00adcates that P may point to I. An edge I . P indicates that P represents \neither a .eld of an object instance modeled by I, or the array contents of array instance I. Based on \nthe heap graph, our algorithm employs the following logic to supplement the HSDG with data-.ow edges \nfrom store statements to sink calls: 1. For any store statement st, let pk be the pointer key correspond\u00ading \nto the base pointer for the store. Let Ist be the points-to set of pk. Similarly, for any sink invocation \nsk, let Isk denote the union of the points-to sets for the sensitive formal parameters of sk. 2. For \neach sink invocation sk, let I * be the set of instance keys sk reachable in the heap graph from the \ninstance keys in Isk. 3. Add edge st . sk to the HSDG if and only if Ist n Isk*  = \u00d8. For example, \non the code of Figure 1, the taint-carrier-detection algorithm synthesizes the HSDG edge from the store \nat line 5 (in the clone of the Internal constructor corresponding to the allocation at line 37) to the \nsink call at line 40. With this edge, TAJ discovers the tainted .ow that from line 13 reaches line 40 \ngoing through lines 37 and 5. Step 2 of this algorithm may introduce false positives due to pointer analysis \nimprecision; we address this concern in Sec\u00adtion 6.2.  4.1.2 Handling Exceptions TAJ employs special-case \nmodelling for vulnerabilities from ex\u00adceptions. Consider, for example, the following block of code, which \nexempli.es the (unfortunately) common practice of ren\u00addering caught exceptions to the screen: protected \nvoid doGet(HttpServletRequest req, HttpServletResponse resp) throws IOException { try { ... } catch (Exception \ne) { resp.getWriter().println(e); } } This code may leak sensitive information concerning the in\u00adternal \nmakeup of the application, as the default implementa\u00adtion of Exception.toString includes the result of \nthe call to Exception.getMessage in its return value. As mentioned in Sec\u00adtion 1, exposing this information \nto unauthorized observers cur\u00adrently constitutes the sixth most common security vulnerability in today \ns Web applications. To account for this type of .ow where it is not clear which source should be de.ned \nTAJ synthesizes code that calls getMessage on a caught Exception object, and marks this synthetic code \nas a source of tainted data. Similar tech\u00adniques model taint .ow in certain JSP tags.   4.2 General \nModels A basic approach to static analysis would model all available pro\u00adgram and library code directly. \nHowever, to improve performance and precision, we tune the analysis with various higher-level mod\u00adels. \nThese models are general purpose and may be useful for other static analyses. Our models serve several \nfunctions in the analysis. First, code that cannot affect the .ow of taint through the program can be \nig\u00adnored. Second, certain library methods can be summarized, creat\u00ading models that provide a succinct \nyet sound description of the rel\u00adevant behavior. Finally, models can compensate for cases in Web\u00adframework \nclients where data .ow is not clear from the code alone. We next discuss speci.c examples of how TAJ \nemploys synthetic models of code. 4.2.1 Code-reduction Techniques A simple, yet effective, code-reduction \noptimization is to exclude benign library classes, packages, and subpackages based on a whitelist generated \nby hand. A more interesting type of modeling can simplify data-.ow propagation by substituting simpler \nmodels for library meth\u00adods, where the simpler model encodes the behavior with re\u00adspect to .ow of taint. \nFor example, taint analysis does not need to analyze the complex manipulations in the implementation \nof URLEncoder.encode; it suf.ces to observe that this method re\u00adturns some string that is sanitized according \nto the relevant rules. Using this insight, TAJ gives special treatment to String op\u00aderations, which arise \nfrequently in tainted .ows, have relatively simple semantics, but are often dif.cult to analyze precisely. \nWe de.ne the family of string carriers to include classes String, StringBuffer and StringBuilder in package \njava.lang. String-carrier instances are handled as if they were primitive values by inserting appropriate \noperations into the SSA representation for each method that manipulates string carriers and modeling \ntheir public APIs. With this treatment, the analysis need not track the contents of string carriers through \nthe heap during pointer analysis, and loses no precision. TAJ also applies special treatment to dictionaries \nfrom the stan\u00addard libraries. Clearly, the general problem of tracking data .ow through a hash set is \ndif.cult. However, we observe that many Web applications access hash structures with keys that can be \nresolved as constants. Exploiting this observation, TAJ applies special logic to track data .ow between \nstatements making read or write access to hash structures, whenever the key can be statically resolved \nas a constant. For example, in the following code, TAJ will determine that o1 cannot .ow to o2 based \non the keys used to access s: HttpSession s; Object o1; ... // Initialization code here. s.setAttribute(\"a\", \no1); Object o2 = s.getAttribute(\"b\"); Precise handling of this special case dramatically improves preci\u00adsion, \nas this idiom appears often in Web applications.  4.2.2 Approximating the Behavior of Web Frameworks \nIn many Web applications, precise analysis requires information that is external to the program s code \n(e.g. con.guration .les). In these cases, TAJ often uses models that provide a conservative approximation \nof possible behavior. For example, TAJ uses this type of modeling to support the Apache Struts framework. \nStruts is an implementation of the Model View Controller (MVC) pattern, where the controller is con.gured \nbased on an eXtensible Markup Language (XML) .le, the model consists of the business logic and the model \nstate (which are repre\u00adsented by the Action and ActionForm classes respectively), and the view is a JSP \n.le. The dispatch logic coded into the XML guides the framework when invoking business-logic elements, \nin the form of Action classes, by invoking the execute method on them. This method takes as a parameter \nan ActionForm instance, whose .elds are populated by the framework based on user input (and should thus \nbe considered tainted). The fact that Action classes are dispatched by the Struts frame\u00adwork is modeled \nby treating them as entrypoints; the analysis be\u00adgins at their implementation of execute, and synthesizes \nan ap\u00adpropriate program state. When ActionForms are passed as argu\u00adments in calls to Action.execute, \nthe analysis .rst checks which constraints the concrete implementation of execute places on its ActionForm \nparameter in the form of cast operations and then simulates the passing of all compatible subtypes of \nActionForm as parameters to execute. For each of these subtypes, the system generates a synthetic constructor \nwhich assigns tainted values to all its .elds (this is done recursively, as .elds may be of compound \ntypes). Another crucial challenge for Java EE applications concerns ac\u00adcounting for EJB calls. Consider \nan enterprise bean having remote interface EB2, home interface EB2Home and bean class EB2Bean. Assume \nthat a method m2 is declared in EB2 and implemented in EB2Bean. To call m2 remotely, a method m1 in bean \nEB1Bean would perform the following: Context initial = new InitialContext(); Object objRef = initial.lookup(\"java:comp/env/ejb/EB2\"); \nEB2Home eb2Home = (EB2Home) PortableRemoteObject.narrow( objRef, EB2Home.class); EB2 eb2Obj = eb2Home.create(); \neb2Obj.m2(); At the bytecode level, the call to eb2Obj.m2 delegates to an im\u00adplementation generated automatically \nby the Java EE deployment tool. The Java EE container consults run-time registries and a back\u00ading persistence \nmanager (usually a database) to map the remote m2 method call to the actual method implementation, and \nthen passes a message to the process hosting the home container for EB2Bean using Remote Method Invocation \nover Internet Inter-ORB Proto\u00adcol (RMI-IIOP). The receiving process unmarshalls the RMI-IIOP message, \nactivates the relevant component through the bean life\u00adcycle implementation, and .nally delegates to \na re.ective call to complete the remote invocation. Analyzing bytecode alone, it would be impossible \nto resolve this remote method invocation, since the relevant dispatch tables are en\u00adcoded in the XML \ndeployment descriptor, and read by the container at run-time. To guarantee soundness, it would then be \nnecessary to analyze the container code, but given its complexity and size, this would limit the scalability \nand precision of the analysis. TAJ does not analyze the thousands of methods in the container implementa\u00adtion \nthat perform the remote invocation of m2; instead, it bypasses the container and recognizes special semantics \nfor the call to m2.To achieve this result, TAJ consults the deployment descriptor, gener\u00adates an analyzable \nartifact representing the semantics of a call to m2, and models the call as dispatching to this artifact.3 \nThe simple semantics there suf.ce to construct a correct call graph incorpo\u00adrating the call to m2, independent \nof the container implementation. Effectively, TAJ ignores the generated deployed code, and mod\u00adels the \napplication-level semantics of EJB calls directly, based on direct analysis of the deployment descriptor. \nThis functionality is essential for accurate analysis of EJB calls in Java EE, and to our knowledge is \nnot supported by any other static-analysis imple\u00admentation. 3 Details on the construction of this analyzable \nartifact are given in [9].  Our choice to model EJB calls in this way has three advantages. First, it \nallows scalability, as the body of code to analyze is dramat\u00adically reduced. Second, it enhances precision, \nas mapping an EJB remote method to its actual implementation in the corresponding EJB class without analyzing \na container s RMI-IIOP implementa\u00adtion minimizes the risk of data-.ow pollution. Finally, portability \nis accomplished by virtue of the fact that the analysis results are not dependent on the container implementation. \n 4.2.3 Re.ection APIs and Native Methods TAJ includes signi.cant machinery to approximate the behavior \nof Java re.ection APIs, such as Class.forName and Method.invoke. When the value of an argument to a re.ection \nAPI can be inferred (for example, when it is constant), the system synthesizes a relevant abstraction \nin place of the re.ective call. Finally, the system relies on hand-coded synthetic models for native \nmethods in the standard Java library. This is essential not only for tracking data-and control-.ow information, \nbut also because native calls .gure prominently in security-related oper\u00adations. For example, Thread.start \nand the four overloads of AccessController.doPrivileged are all based on native APIs. Failure to analyze \nthese methods would render the analysis useless for many real-world Web vulnerabilities. 5. Eliminating \nRedundant Reports Some tainted .ows reported by the analysis may be redundant to a user. The analysis \ncan compute all .ows of the form sr . sk, where sr is a source, sk is a sink, and no sanitizer is present \nalong the path from sr to sk. However, from a user s perspective, this may be too much information, since \nmany of these .ows might redundantly expose a single logical .aw. We now describe an approach to address \nthis potential redun\u00addancy. Considering the insertion of a sanitizer invocation into the path as a remediation \naction, we propose an approach whereby .ows are grouped together according to the remediation actions \nthey map to. TAJ reports one representative per group, rather than all the .ows. Formally, we de.ne a \nlibrary call point (LCP) to be the last statement along a .ow from a source to a sink where data .ows \nfrom application code (i.e., the project s source code) to library code (i.e., libraries referenced by \nthe project). Data can .ow from application to library in one of three ways: (1) a library method is \ninvoked from application code, (2) a library memory location is written from application code, or (3) \nan application memory location is read from library code. With this de.nition at our disposal, we can \nintroduce an equiv\u00adalence relation ~, as follows: Let U and V be two .ows. Then U ~ V , if and only if \n(1) U|LCP = V |LCP (where X|LCP is the part of .ow X extending from the source to the LCP inclusive), \nand (2) U and V require the same remediation action. The equiv\u00adalence classes induced by ~ are the sets \nof .ows into which .ows are classi.ed. For example, considering the call graph illustrated in Figure \n3, we can de.ne U as the .ow along path p1 and V as the .ow through p2. We note that nodes n10 and n11 \nare both sinks with the same issue type (for example, XSS or SQLi), and so they both require the same \nremediation action, or sanitation logic. Since U and V both transition from application code to library \ncode at the same point (n4), it follows that U ~ V . If we instead de.ne U as the .ow along p3 and V \nas the .ow through p4, then U and V do not share the same LCP, and thus belong in different equivalence \nclasses, despite .owing from the same source to the same sink. The justi.cation for this is that, po\u00adtentially, \nthe remediation action introduced for U will not remove the security threat exposed in V (e.g., if a \nsanitizer is called from node n3). Similarly, the .ows through p4 and p5 are both reported, although \nthey originate from the same source and pass through the same LCP, since they end at sinks corresponding \nto different issue types, and may therefore require different remediation actions.  Node with LCP p1= \n(n1, n2, n4, n7, n10) p2= (n1, n2, n4, n7, n11) p3= (n1, n2, n4, n9) p4= (n1, n2, n3, n6, n9) p5= (n1, \nn2, n3, n5, n8) Sinks with same issue type Figure 3. Call Graph Illustrating the LCP Concept Our analysis \nof the example in Figure 3 demonstrates the twofold advantage of the LCP-based method of classi.cation: \n(1) the part of .ow X that is under the developer s control is precisely X|LCP ,4 and (2) if .ow X is \na representative of equivalence class [X]~, then, once the vulnerability exposed in X is remedied, all \nthe other .ows in [X]~ will be remedied as well. This compact, action-oriented report greatly improves \nuser experience. TAJ uses the following algorithm to generate minimal reports according to this property: \n1. After hybrid thin slicing, a view of the HSDG restricted to state\u00adments in the slice is produced. \nThis view is then traversed back\u00adwards starting from sinks, and LCPs are identi.ed as transitions from \nlibrary to application code. This step outputs a relation mapping sinks to LCPs. 2. For each LCP lcp, \nthe associated sinks are grouped into equiv\u00adalence classes according to the indicated remediation logic. \nLet Slcp be the set of sink-equivalence-class representatives for an LCP lcp. 3. We identify every source/LCP \npair (sr, lcp) for which there is a data-.ow path from sr to lcp, traversing the hybrid thin slice. For \neach such pair (sr, lcp), for each sk . Slcp, report sr . lcp . sk as a potential vulnerability, if so \nindicated by the security rules.  6. Bounded Analysis Techniques When analyzing large applications, \na user may decide to constrain the analysis to a speci.c time and memory budget. This section presents \na set of techniques for customizing the analysis to produce satisfactory results within a .xed budget. \n 6.1 Priority-driven Call-graph Construction Under a .xed time and memory budget, TAJ may terminate pointer \nanalysis and call-graph construction early, yielding an underap\u00adproximate result. The result is underapproximate \nsince the points\u00adto relation computed by Andersen s analysis grows monotonically. While the underapproximate \ncall graph and points-to relation may not be sound, they are often suf.cient for .nding many bugs. When \nterminated early, the order in which the pointer analysis adds and solves constraints can have a strong \nimpact on the number of bugs discovered in taint analysis. TAJ uses priority-driven call\u00adgraph construction \nto heuristically improve pointer analysis quality 4 Note, however, that X|LCP may transition between \napplication and li\u00adbrary code multiple times, which implies that parts of this sub-.ow may not be accessible \nto the developer.  within a .xed budget. The priority heuristic favors the analysis of methods that \nare more likely to generate and propagate taint. Our experiments show that it enables the detection of \na signi.cantly larger number of taint vulnerabilities than chaotic iteration when TAJ runs in a constrained \ntime or memory budget. Priority-driven call-graph construction forces the pointer anal\u00adysis to add constraints \n.rst from higher-priority methods in this case, those methods likely to be more relevant to taint analysis. \nOur pointer analysis iterates between two key phases: (1) con\u00adstraint solving, which computes points-to \nrelationships and notes newly discovered targets for virtual calls, and (2) constraint adding, which \nadds constraints for new methods found to be reachable by constraint solving.5 Priority-driven call-graph \nconstruction changes phase (2); it assigns a priority to pending methods and ensures that in each pass, \nconstraints are only added for the highest-priority method. In this manner, methods more relevant to \ntaint analysis are processed earlier by the pointer analysis. More formally, let G =(N, E) be the call \ngraph under con\u00adstruction. We assume that the budget takes the form of a bound on the number of call \ngraph nodes, i.e., a number maxNodes such that |N|= maxNodes. The construction of G is governed by a \npriority policy .: N . N, where smaller numbers mean higher priority. Upon creation of a new call-graph \nnode n,6 . uses the following initial-assignment rule to assign n a priority: if n is a source node, \nthen .(n):=0; otherwise, .(n):= maxNodes. The idea behind this rule is that source nodes represent taint \ngeneration and so should be given the lowest priority value (corresponding to the highest importance) \nin the construction of G. Pointer analysis and call-graph construction begins by instan\u00adtiating call-graph \nnodes that represent invocations of application entrypoints and adding them to a priority queue Q. Then \nwhile Q = \u00d8 and the analysis budget has not been met the following steps are run in a loop: 1. A node \nn with the lowest priority value in Q is dequeued. 2. Aset Tn . N is constructed as follows: Tn contains \n(1) all the predecessors and successors of n in G, and (2) all the existing nodes that represent methods \ncontaining a load statement that, according to the pointer analysis, matches a store statement in the \nmethod represented by n (in which case, there will be a direct edge from the store to the load in the \nHSDG). Any node t . Tn with no priority assigned yet is given priority .(t) according to the initial-assignment \nrule. 3. The priorities of all nodes t . Tn are updated according to the following update rule: .(t):=min{.(t), \n.(n)+1}. 4. Nodes in Tn are added to Q if necessary. 5. Any node t . Tn whose priority changed in Step \n3 propagates its priority to all the nodes in Tt. This propagation process runs to a .xed point. 6. \nConstraints for n are added to the pointer-analysis-constraint system, and constraint solving runs to \na .xed point.  The reasoning behind steps 2 and 3 above is based on the locality\u00adof-taint principle, \nwhich is an observation to the effect that if taint .ows through a particular code location, then nearby \ncode locations (those in the Tn set above) are also likely to be relevant to taint propagation. In Step \n2, methods containing load statements matching the stores in n are considered near n due to the possible \n5 For context-sensitive analysis, constraints are added separately for each method clone. 6 A call-graph \nnode represents a method in some calling context, as deter\u00admined by the context-sensitivity policy. \ncorresponding .ow through the heap. Step 3 ensures that all nearby methods for n have a priority close \nto that of n since n has been deemed relevant to taint, nearby methods are also likely to be relevant. \nAnother important aspect of the technique is the role played by .. Since . assigns the maximal possible \npriority as the initial priority for source nodes, the algorithm favors nodes closer to the sources of \ntaint. This bias leads to the discovery of more taint\u00adrelated bugs in practice.  6.2 Useful Bounds on \nAnalysis Dimensions The call-graph construction process is not the only aspect of our algorithm that \ncan be bounded. Limits can also be set on the slic\u00ading process, the algorithm searching for nested taint \nunder object abstractions, and many other components of the framework. The choice of which dimensions \nto bound, and how to bound them, is crucial for an analysis to yield satisfying results under constraints. \nIn what follows, we discuss bounds we found to be useful when running TAJ in environments with limited \nresources. 6.2.1 Slice Size There are two ways to constrain the size of a slice, when computed through \nhybrid thin slicing. One is to limit the number of heap store-to-load transitions, and another is to \ncast constraints on the slice sizes through the no-heap SDG. Our experience suggests that limiting the \nnumber of heap transitions yields better overall results. The main reason for this is the loss of precision \nentailed by data .ow through the heap, which relies on a .ow-insensitive pointer analysis. It is straightforward \nto constrain the size of the slice in this manner during hybrid thin slicing by keeping track of store-to\u00adload \nexpansions of the slice. 6.2.2 Flow Length The loss in precision entailed by long series of heap transitions, \nalong with other over-approximations that are required for sound analysis (such as the static resolution \nof re.ective and virtual calls), account for a strong correlation between the length of a reported .ow \nand its classi.cation as a true positive. Our empirical studies suggest that the longer a .ow is, the \nless likely it is to be a true positive. The theoretical justi.cation for this is that the longer a .ow \nis, the more opportunities the analysis has to err on the conservative side. Section 7 presents further \ncon.rmation for this claim, in the form of empirical evidence.  6.2.3 Nested-taint Depth Using the algorithm \ndescribed in Section 4.1.1 to compute the set of objects reachable from a given object abstraction, without \nplac\u00ading any restriction on the length of .eld-dereference sequences, can lead to an overly conservative \nanalysis. This can happen, for exam\u00adple, if a data-structure reference is stored as the .eld of an object, \nthereby bridging between that object and the transitive .elds of all the objects stored in the data structure. \nWhile dismissal of long .eld-dereference sequences from consideration (by introducing a bound) is theoretically \nunsound, our experience suggests that it is highly unlikely for a sink to consume data that is stored \ndeep in\u00adside the state of its arguments. Empirically, we found 2 levels of .eld dereference to be suf.cient, \nas will be discussed in Section 7. 7. Experimental Results Since TAJ was designed to support a commercial \nproduct [17], it has undergone extensive evaluation on a large set of large industrial benchmarks. In \nthis section, we present and discuss results from the main experiments, run on 22 benchmarks.  7.1 Experimental \nSetup TAJ is a WALA client [35] written in Java and implemented as an Eclipse V3.4 plug-in. Its testing \nenvironment comprised an IBM desktop running Microsoft Windows XP Service Pack 3, with a 1.86 GHz Intel \nCore 2 processor and 3GB of RAM. TAJ was run on top of Sun Microsystems Java Standard Edition Runtime \nEnvironment (JRE) V1.6.0 06, using 1 GB of heap space. Hybrid Unbounded . Prioritized . . Optimized \n. . . . . CS . CI . Table 1. Settings Used for the Evaluated Algorithms Five different algorithms were \nevaluated: CS thin slicing [33], CI thin slicing [33], and three variants of hybrid thin slicing an unbounded \nversion running to completion, a prioritized ver\u00adsion running under a call-graph size bound with the \npriority-driven scheme, and a fully optimized version running with all the optimiza\u00adtions and bounds \ndescribed above. Details concerning the settings we used are provided in Table 1. A call-graph bound \nof 20,000 nodes was used for the prioritized and fully optimized versions of the hybrid algorithm. The \nfully optimized variant also restricts heap transitions (during slicing) to 20,000, .lters out .ows whose \nlength is greater than 14, and allows no more than 2 .eld dereferences when running the taint-carrier \ndetection algorithm. Table 2 lists information about the applications used for the evaluation, including \nsupporting libraries. The identi.ers A, B, I, S and ST are used instead of the actual names of the corresponding \napplications for anonymity. Together, the 22 benchmarks included in our experiments capture all the challenges \ndiscussed in earlier sections. Most of the benchmarks make heavy use of Web frame\u00adworks and re.ection, \nand as con.rmed by manual inspection all of the selected benchmarks expose non-trivial taint .ows. The \nlarger benchmarks also pose scalability challenges. Some of the ap\u00adplications in the list have been included \nin previous studies on taint analysis [20].  7.2 Discussion Results concerning the performance of each \nof the algorithms are detailed in Table 3. For nine of the applications, we manually classi.ed the reported \nissues into true and false positives. The distribution of reports between these two categories appears \nin Figure 4.7 The following trends are apparent from the gathered data: The unbounded hybrid algorithm \noffers a compelling tradeoff be\u00adtween performance and accuracy, when compared to the CI and CS con.gurations. \nTable 3 presents the running times for all con.gurations on all benchmarks. The average running time \nfor the unbounded hybrid con.guration was 1051 seconds, which is a factor of 2.65X slower than the CI \ncon.guration. The CS con.guration only completed on six of the smaller benchmarks. (On the remaining \nbenchmarks, the CS analysis ran out of memory.) On these six benchmarks, the average running time for \nthe unbounded hybrid con.guration was 19.3 seconds, which is a factor of 29X faster than the CS con.gura\u00adtion. \nNote from Table 1 that all con.gurations use synthetic models, which are key to good performance. 7 Empty \nentries in Table 3, as well as missing columns in Figure 4, represent instances where the relevant algorithm \nfailed to complete its run on the input program. The only algorithm for which such cases were registered \nis CS thin slicing. Turning to accuracy, we examine the data breaking down false positives, as reported \nin Figure 4. We de.ne the accuracy score for an analysis as the ratio between the number of true positives \nand the number of true and false positives combined, which cor\u00adresponds to the total number of reported \nissues; a higher accuracy score indicates better accuracy. The respective accuracy scores of the unbounded \nhybrid, CS and CI algorithms are 0.35, 0.54 and 0.22. Note that the CS algorithm completed only on four \nof the benchmarks for which we manually evaluated accuracy. On these four benchmarks, the unbounded hybrid \nand CI algorithms had ac\u00adcuracy scores of 0.54 and 0.34, respectively. In the worst case (A), the unbounded \nhybrid algorithm is only 1.05 times less accurate than CS. An interesting observation is that the unbounded \nhybrid and CI algorithms agree on the number of true positives for all the nine benchmarks for which \nwe manually evaluated accuracy, which is expected given that both these algorithms are sound, while the \nCS algorithm has false negatives on BlueBlog, I and SBM; the numbers of false negatives are 2, 1 and \n2, respectively. This re.ects the fact that the CS algorithm is unsound with respect to multi-threaded \napplications, as we observed in Section 3. We conclude that the unbounded hybrid algorithm represents \nan attractive tradeoff between performance and accuracy. The prioritized hybrid algorithm offers superior \naccuracy and performance tradeoffs than the CI and unbounded hybrid con\u00ad.gurations. On the 9 benchmarks \nevaluated manually, the unbounded hybrid algorithm reports 556 false positives, while the prioritized \nversion reports only 146 false positives. The 20,000-node call-graph bound did not lead to any missed \ntrue positives on 8 of the 9 benchmarks, with Webgoat as the only exception. Compared to CI (which is \nthe most conservative algorithm), the prioritized hybrid algorithm in\u00adtroduces only 1 more false negative \non A and 3 more false negatives on BlueBlog. The prioritized hybrid algorithm runs on average in 215 \nseconds, a factor of 1.8X faster than CI. We conclude that the prioritized hybrid algorithm offers a \ncom\u00adpelling tradeoff between performance gain and accuracy loss com\u00adpared to the unbounded alternatives. \nThe fully optimized version of the hybrid algorithm is more ac\u00adcurate than the prioritized variant and \nmore ef.cient than the CI algorithm. Compared to the prioritized hybrid algorithm, the fully optimized \nvariant introduces only 1 new false negative (on BlueBlog). It .nds, however, 14 more true positives \n(on Webgoat), and reports an overall of 74 false positives, compared to 146 false positives re\u00adported \nby the unoptimized prioritized hybrid con.guration. Intuitively, the fully optimized version recovers \nissues lost by the prioritized algorithm since the optimizations lead to a more ef.cient use of the limited \nanalysis budget. The fully optimized version generates fewer false positives due mainly to restrictions \non .ow lengths and heap transitions in tainted .ows. The average running time of the fully optimized \nalgorithm is 325 seconds, 21% faster than the CI algorithm. Overall, the fully optimized version is 1.5X \nslower than the unoptimized hybrid vari\u00adant. On 13 out of the 22 benchmarks, the fully optimized algorithm \nis faster than the prioritized algorithm; its higher average running time is mainly due to degraded performance \non GridSphere. Taken together, these trends point to the fully optimized hybrid algorithm as the most \nattractive compromise between accuracy and scalability, among the con.gurations evaluated. 8. Related \nWork In this section, we compare TAJ with other work in the area of static taint analysis. Related work \non dynamic taint analysis is discussed  Application Version File Count Line Count Class Count Method \nCount App. Total App. Total A 1.0 121 746 43 2057 4272 150339 B - 314 1680 246 9252 14552 328941 Blojsom \n3.1 225 19984 254 7216 10688 354114 BlueBlog 1.0 32 650 38 1044 7628 269056 Dlog 3.0-BETA-2 240 17229 \n268 12957 7790 284808 Friki 2.1.1-58 40 2339 35 1133 3848 116480 GestCV 1.0 159 107494 124 5139 13673 \n473574 Ginp 1.0 121 387 73 2941 8076 277680 GridSphere 2.2.10 698 44767 676 32134 10671 385609 I 1.0 \n30 281 25 996 4254 149278 JSPWiki 2.6 724 27000 429 13087 9863 335828 Lutece 1.0 1039 3065 467 12398 \n7606 237137 MVNForum 1.0.2 969 8860 608 19722 8979 315527 PersonalBlog 1.2.6 135 47007 38 1644 4951 157794 \nRoller 0.9.9 325 4865 251 9786 7200 246390 S - 168 2064 100 10965 6219 393204 SBM 1.08 125 5165 143 6506 \n8047 283069 SnipSnap 1.0-BETA-1 828 85325 571 17960 12493 455410 SPLC 1.0 106 12447 69 3526 6538 229417 \nST - 1451 594 5956 31309 24221 822362 VQWiki 1.0 280 31325 185 6164 4803 152341 Webgoat 5.1-20080213 \n245 17656 192 14309 6663 254726 Table 2. Statistics on the Applications Used in the Experiments Application \nHybrid CS CI Unbounded Prioritized Fully Optimized Issues Time(s) Issues Time(s) Issues Time(s) Issues \nTime(s) Issues Time(s) A 54 43 33 54 37 23 51 554 73 88 B 25 1160 7 242 1 217 - - 67 564 Blojsom 238 \n783 162 222 123 207 - - 504 275 BlueBlog 19 5 19 5 12 6 14 376 30 7 Dlog 21 873 11 243 6 221 - - 168 \n602 Friki 60 11 60 10 7 9 14 1392 125 11 GestCV 21 2461 20 182 7 209 - - 255 760 Ginp 67 40 67 45 49 \n28 43 1028 309 75 GridSphere 803 6505 116 735 261 2467 - - 853 1281 I 3 8 3 8 3 8 2 16 17 15 JSPWiki \n68 159 67 270 26 118 - - 381 192 Lutece 3 824 2 28 4 59 - - 41 99 MVNForum 260 313 100 228 293 205 - \n- 374 213 PersonalBlog 454 3708 108 386 48 740 - - 1854 604 Roller 650 1495 87 175 230 268 - - 3171 794 \nS 395 602 25 398 24 263 - - 697 729 SBM 154 9 154 7 159 6 125 26 161 10 SnipSnap 91 279 89 167 94 153 \n- - 397 291 SPLC 40 188 37 279 36 116 - - 103 272 ST 731 933 369 207 347 277 - - 1830 565 VQWiki 888 \n2450 303 383 545 565 - - 2284 784 Webgoat 48 276 27 180 39 193 - - 102 485 Table 3. Experimental Results \nComparing between Hybrid Variants and Other Algorithms in [4]. Works related to our contributions in \nthe area of program slicing are surveyed in [33] and references therein. Of notable importance is the \nfact that while program slicing has been applied to taint analysis in the past, none of the proposed \nalgorithms has been shown to scale to applications whose size is comparable to that of the large benchmarks \nagainst which we evaluate TAJ. The notion of tainted variables as variables in security-sensitive code \nwhere untrusted values can .ow became known with the Perl language. In Perl, using the -T option allows \ndetecting tainted vari\u00adables [37]. Typically, the data manipulated by a program can be tagged with security \nlevels [8], which naturally assume the struc\u00adture of a partially ordered set. Under certain conditions, \nthis par\u00adtially ordered set is a lattice [7]. In the simplest example, this lattice only contains two \nelements, indicated by high and low. Given a pro\u00adgram, the principle of non-interference dictates that \nlow-security behavior of the program be not affected by any high-security data, unless that high-security \ndata has been previously veri.ed and downgraded. [12]. The taint analysis problem described in this pa\u00adper \nis an information-.ow problem in which high data is the un\u00adtrusted output of a source, low-security operations \nare those per\u00adformed by sinks, and untrusted data is downgraded by sanitizers.  A B BlueBlog 10 20 30 \n40 50 60 70 80   10 20 30 40 50 60 70  5 10 15 20 25 30   0 Unbounded Prioritized Fully Optimized \nCS CI 0 Unbounded Prioritized Fully Optimized CS CI 0 Unbounded Prioritized Fully Optimized CS CI 0 20 \n40 60 80 100 120 140 Unbounded Prioritized Fully Optimized Friki CS CI 0 50 100 150 200 250 300 Unbounded \nPrioritized Fully Optimized GestCV CS CI 0 2 4 6 8 10 12 14 16 18 Unbounded Prioritized Fully Optimized \nI CS CI 0 100 200 300 400 500 600 700 Unbounded Prioritized Fully Optimized S CS CI 0 20 40 60 80 100 \n120 140 160 180 Unbounded Prioritized Fully Optimized SBM CS CI 0 20 40 60 80 100 120 Unbounded Prioritized \nFully Optimized Webgoat CS CI  Figure 4. Classi.cation of Reported Issues into True and False Positives \non Key Benchmarks Volpano, et al. [36] have shown a type-based algorithm that certi.es implicit and explicit \n.ows and also guarantees non\u00adinterference. Shankar, et al. present a taint analysis for C using a constraint-based \ntype-inference engine based on cqual [30]. To .nd format string bugs, cqual uses a type-quali.er system \n[11] with two quali.ers: tainted and untainted. The types of values that can be controlled by an untrusted \nadversary are quali.ed as being tainted, and the rest of the variables are quali.ed as untainted. A constraint \ngraph is constructed for a cqual program. If there is a path from a tainted node to an untainted node \nin the graph, an error is .agged. Myers Java Information Flow (Jif) [24] uses type-based static analysis \nto track information .ow. Jif is based on the Decen\u00adtralized Label Model [25], and considers all memory \nas a channel of information, which requires that every variable, .eld, and pa\u00adrameter used in the program \nbe statically labeled. Labels can either be declared or inferred. Ashcraft and Engler [2] also use taint \nanalysis to detect soft\u00adware attacks due to tainted variables. Their approach provides user\u00adde.ned sanity \nchecks to untaint potentially tainted variables. Pis\u00adtoia, et al. [27] present a static analysis explicitly \ndesigned to de\u00adtect tainted variables in privilege-asserting code in access-control systems based on \nstack inspection. They also perform a backward call-graph traversal starting at security-sensitive calls \nuntil a bound\u00adary edge between application code and library code is encountered. Boundary edges indicate \nto the user the optimal code locations where calls to privilege-asserting APIs should be inserted. This \nis similar to the LCP algorithm discussed in Section 5. Snelting, et al. [31] make the observation that \nProgram De\u00adpendence Graphs (PDGs) and non-interference are related in the following manner. Consider \nstatements s1 and s2.If dom(s1) dom(s2) then, in a security-correct program, it must be the case that \ns1 ./backslice(s2). Here, backslice is the function that maps each statement s to its static backwards \nslice, consisting of all the (transitive) predecessors of s along control-and data-dependence edges in \nthe PDG. Based on this observation, Hammer, et al. [13] present an algorithm for checking for non-interference: \nfor any out\u00adput statement s, it must be the case that backslice(s) contains only statements that have \na lower security label than s. Though promis\u00ading, their approach has not been shown to scale. Livshits \nand Lam [20] present an elegant approach for taint analysis for Java EE applications that is engineered \nto track taint .owing through heap-allocated objects. Their analysis requires prior computation of Whaley \nand Lam s .ow-insensitive, context\u00adsensitive may-points-to analysis, based on Binary Decision Di\u00adagrams \n(BDDs) [40]. The points-to relation is the same for the entire program, ignoring the program s control \n.ow. By contrast, the PDG-based algorithm in [13] handles heap objects in a .ow\u00adsensitive manner, albeit \nat a much higher cost. Livshits and Lam s taint analysis requires the presence of programmer-supplied \nde\u00adscriptors for sources and sinks, as well as for library methods that handle objects through which \ntaint may .ow. This is reminiscent of our source and sink speci.cation, as well as of our special treat\u00adment \nof string carriers. Their approach does not cover all the attack vectors addressed by TAJ, and does not \ndeal with challenges such as .ow through containers, nested taint and accurate handling of Web frameworks, \nwhich are essential for precise and comprehen\u00adsive analysis of industrial applications. Furthermore, \nit is unclear whether BDD-based static analysis can scale to large applications when using object sensitivity \n[18]. Customization of the BDD\u00adbased approach (e.g. by .xing analysis budget and enhancing the analysis \nwith a priority-driven scheme) also appears to be problem\u00adatic.  Wassermann and Su extend Minamide s \nstring-analysis algo\u00adrithm [23] to syntactically isolate tainted substrings from untainted substrings \nin PHP applications. They label non-terminals in a Context-Free Grammar (CFG) with annotations re.ecting \ntaint\u00adedness and untaintedness. Their expensive, yet elegant, mechanism is applied to detect both SQLi \n[38] and XSS [39] vulnerabilities. McCamant and Ernst [21] take a quantitative approach in infor\u00admation \n.ow: instead of using taint analysis, they cast information\u00ad.ow security to a network-.ow-capacity problem, \nand describe a dynamic technique for measuring the amount of secret data that leaks to public observers. \n9. Conclusion and Future Work We have presented TAJ, an approach to taint analysis suitable for industrial \napplications. An experimental evaluation indicates that the hybrid algorithm TAJ uses for slice construction \nis an attrac\u00adtive compromise between context-sensitive and context-insensitive thin slicing. We also \ndemonstrated priority heuristics to perform effective taint analysis in a limited budget, improving performance \nwithout signi.cantly degrading accuracy. In future research, we intend to introduce modular as well as \nin\u00adcremental analysis capabilities into TAJ [5]. Also, we plan to inves\u00adtigate techniques from demand-driven \npointer analysis [15] as an alternative to the priority heuristics presented here. Since string car\u00adriers \nare the most common taint mediators in Web applications, we are currently in the process of enhancing \nour analysis with string\u00adspeci.c taint-detection capabilities, in the spirit of [23]. Finally, we plan \nto extend our coverage of security rules, by investigating ways for statically identifying cross site-request \nforgery and client-side vulnerabilities [26]. References [1] L. O. Andersen. Program Analysis and Specialization \nfor the C Programming Language. PhD thesis, University of Copenhagen, Denmark, 1994. [2] K. Ashcraft \nand D. Engler. Using Programmer-Written Compiler Extensions to Catch Security Holes. In S&#38;P 2002. \n[3] R. Bod\u00b4ik, R. Gupta, and V. Sarkar. ABCD: Eliminating Array Bounds Checks on Demand. In PLDI 2000. \n[4] W. Chang, B. Streiff, and C. Lin. Ef.cient and Extensible Security Enforcement Using Dynamic Data \nFlow Analysis. In CCS 2008. [5] P. Cousot and R. Cousot. Modular Static Program Analysis. In CC 2002. \n[6] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. Ef.ciently Computing Static \nSingle Assignment Form and the Control Dependence Graph. TOPLAS, 13(4), 1991. [7] D. E. Denning. A Lattice \nModel of Secure Information Flow. CACM, 19(5), 1976. [8] D. E. Denning and P. J. Denning. Certi.cation \nof Programs for Secure Information Flow. CACM, 20(7), 1977. [9] S. Fink, J. Dolby, and L. Colby. Semi-Automatic \nJ2EE Transaction Con.guration. IBM Research Report RC23326, 2004. [10] S. Fink, E. Yahav, N. Dor, G. \nRamalingam, and E. Geay. Effective Typestate Veri.cation in the Presence of Aliasing. In ISSTA 2006. \n[11] J. S. Foster, T. Terauchi, and A. Aiken. Flow-Sensitive Type Quali.ers. In PLDI 2002. [12] J. A. \nGoguen and J. Meseguer. Security Policies and Security Models. In S&#38;P 1982. [13] C. Hammer, J. Krinke, \nand G. Snelting. Information Flow Control for Java Based on Path Conditions in Dependence Graphs. In \nISSSE 2006. [14] R. Hasti and S. Horwitz. Using Static Single Assignment Form to Improve Flow-insensitive \nPointer Analysis. In PLDI 1998. [15] N. Heintze and O. Tardieu. Demand-Driven Pointer Analysis. In PLDI \n2001. [16] S. Horwitz, T. W. Reps, and D. Binkley. Interprocedural Slicing Using Dependence Graphs. In \nPLDI 1988. [17] IBM Rational AppScan Developer Edition (AppScan DE), http: //www.ibm.com/software/awdtools/appscan/developer \n[18] O. Lhot\u00b4ak and L. J. Hendren. Context-Sensitive Points-to Analysis: Is It Worth It? In CC 2006. \n[19] B. Livshits, J. Whaley, and M. S. Lam. Re.ection Analysis for Java. In ASPLAS 2005. [20] V. B. Livshits \nand M. S. Lam. Finding Security Vulnerabilities in Java Applications with Static Analysis. In USENIX \nSecurity 2005. [21] S. McCamant and M. D. Ernst. Quantitative Information Flow as Network Flow Capacity. \nIn PLDI 2008. [22] A. Milanova, A. Rountev, and B. G. Ryder. Parameterized Object Sensitivity for Points-to \nAnalysis for Java. TOSEM, 14(1), 2005. [23] Y. Minamide. Static Approximation of Dynamically Generated \nWeb Pages. In WWW 2005. [24] A. C. Myers. JFlow: Practical Mostly-static Information Flow Control. In \nPOPL 1999. [25] A. C. Myers and B. Liskov. A Decentralized Model for Information Flow Control. In SOSP \n1997. [26] OWASP, http://www.owasp.org. [27] M. Pistoia, R. J. Flynn, L. Koved, and V. C. Sreedhar. Interprocedural \nAnalysis for Privileged Code Placement and Tainted Variable Detec\u00adtion. In ECOOP 2005. [28] T. Reps, \nS. Horwitz, and M. Sagiv. Precise Interprocedural Data.ow Analysis via Graph Reachability. In POPL 1995. \n[29] B. G. Ryder. Dimensions of Precision in Reference Analysis of Object-Oriented Languages. In CC 2003. \nInvited Paper. [30] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting Format String Vulnerabilities \nwith Type Quali.ers. In USENIX Security 2001. [31] G. Snelting, T. Robschink, and J. Krinke. Ef.cent \nPath Conditions in Dependence Graphs for Software Safety Analysis. TOSEM, 15(4), 2006. [32] M. Sridharan \nand R. Bod\u00b4ik. Re.nement-based Context-sensitive Points-to Analysis for Java. In PLDI 2006. [33] M. Sridharan, \nS. J. Fink, and R. Bod\u00b4ik. Thin Slicing. In PLDI 2007. [34] Stanford SecuriBench Micro, http://suif.stanford.edu/ \n~livshits/work/securibench-micro. [35] T. J. Watson Libraries for Analysis (WALA), http://wala.sf.net. \n[36] D. Volpano, C. Irvine, and G. Smith. A Sound Type System for Secure Flow Analysis. JCS, 4(2-3), \n1996. [37] L. Wall, T. Christiansen, and J. Orwant. Programming Perl. O Reilly &#38; Associates, Inc., \n3rd edition, 2000. [38] G. Wassermann and Z. Su. Sound and Precise Analysis of Web Applications for Injection \nVulnerabilities. In PLDI 2007. [39] G. Wassermann and Z. Su. Static Detection of Cross-site Scripting \nVulnerabilities. In ICSE 2008. [40] J. Whaley and M. S. Lam. Cloning Based Context-Sensitive Pointer \nAlias Analysis Using Binary Decision Diagrams. In PLDI 2004.     \n\t\t\t", "proc_id": "1542476", "abstract": "<p>Taint analysis, a form of information-flow analysis, establishes whether values from untrusted methods and parameters may flow into security-sensitive operations. Taint analysis can detect many common vulnerabilities in Web applications, and so has attracted much attention from both the research community and industry. However, most static taint-analysis tools do not address critical requirements for an industrial-strength tool. Specifically, an industrial-strength tool must scale to large industrial Web applications, model essential Web-application code artifacts, and generate consumable reports for a wide range of attack vectors.</p> <p>We have designed and implemented a static Taint Analysis for Java (TAJ) that meets the requirements of industry-level applications. TAJ can analyze applications of virtually any size, as it employs a set of techniques designed to produce useful answers given limited time and space. TAJ addresses a wide variety of attack vectors, with techniques to handle reflective calls, flow through containers, nested taint, and issues in generating useful reports. This paper provides a description of the algorithms comprising TAJ, evaluates TAJ against production-level benchmarks, and compares it with alternative solutions.</p>", "authors": [{"name": "Omer Tripp", "author_profile_id": "81435610768", "affiliation": "IBM, Herzlyia, Israel", "person_id": "P1464240", "email_address": "", "orcid_id": ""}, {"name": "Marco Pistoia", "author_profile_id": "81100510307", "affiliation": "IBM, Hawthorne, NY, USA", "person_id": "P1464241", "email_address": "", "orcid_id": ""}, {"name": "Stephen J. Fink", "author_profile_id": "81100118324", "affiliation": "IBM, Hawthorne, NY, USA", "person_id": "P1464242", "email_address": "", "orcid_id": ""}, {"name": "Manu Sridharan", "author_profile_id": "81100641428", "affiliation": "IBM, Hawthorne, NY, USA", "person_id": "P1464243", "email_address": "", "orcid_id": ""}, {"name": "Omri Weisman", "author_profile_id": "81435607604", "affiliation": "IBM, Herzlyia, Israel", "person_id": "P1464244", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542486", "year": "2009", "article_id": "1542486", "conference": "PLDI", "title": "TAJ: effective taint analysis of web applications", "url": "http://dl.acm.org/citation.cfm?id=1542486"}