{"article_publication_date": "06-15-2009", "fulltext": "\n Merlin: Speci.cation Inferencefor Explicit Information Flow Problems BenjaminLivshits, AdityaV. Nori, \nSriramK. Rajamani Anindya Banerjee * Microsoft Research IMDEA Software, Madrid, Spain Abstract The last \nseveral years have seen a proliferation of static and run\u00adtime analysis tools for .nding security violations \nthat are caused by explicit information .ow in programs. Much of this interest has been causedbythe increaseinthe \nnumberof vulnerabilitiessuchas cross-site scriptingandSQL injection.Infact, theseexplicit infor\u00admation \n.ow vulnerabilities commonly found inWeb applications now outnumber vulnerabilities such asbufferoverruns \ncommonin type-unsafe languages such asCand C++.Tools checking for these vulnerabilities require a speci.cation \nto operate. In most cases the taskofprovidingsuchaspeci.cationisdelegatedtotheuser.More\u00adover, the ef.cacy \nof these tools is only as good as the speci.ca\u00adtion. Unfortunately, writing a comprehensive speci.cation \npresents a major challenge: parts of the speci.cation are easy to miss, lead\u00ading to missed vulnerabilities; \nsimilarly,incorrect speci.cations may lead tofalse positives. This paper proposes MERLIN, a new approach \nfor automati\u00adcally inferring explicit information .ow speci.cations from pro\u00adgram code. Such speci.cations \ngreatly reduce manual labor, and enhance the quality of results, while using tools that check for secu\u00adrity \nviolations caused by explicit information .ow. Beginning with a data propagation graph, which represents \ninterprocedural .ow of information in the program, MERLIN aims to automatically in\u00adfer an information \n.ow speci.cation.MERLIN models information .ow paths in the propagation graph using probabilistic constraints. \nA na\u00a8ive modeling requires an exponential number of constraints, one per path in the propagation graph.For \nscalability, we approx\u00adimate these path constraints using constraints on chosen triples of nodes, resultingina \ncubic numberof constraints.We characterize this approximation as a probabilistic abstraction, using the \ntheory of probabilistic re.nementdevelopedby McIver and Morgan.We solve the resulting system of probabilistic \nconstraints usingfactor graphs, which are a well-known structure for performing proba\u00adbilistic inference. \nWe experimentally validate the MERLIN approach by applying it to 10 large business-critical Web applications \nthat have been Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page.To copyotherwise, to \nrepublish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or a \nfee. PLDI 09, June 15 20, 2009, Dublin, Ireland. Copyright c &#38;#169; 2009ACM 978-1-60558-392-1/09/06... \n$5.00 *Partially supported at Kansas State University by NSF grants ITR\u00ad0326577 and CNS-0627748 andby \nMicrosoft Research, Redmond,byway of a sabbatical visit. analyzed with CAT.NET, a state-of-the-art static \nanalysis tool for .NET.We.nda totalof167new con.rmed speci.cations, which result in a total of 322 additional \nvulnerabilities across the 10 benchmarks. More accurate speci.cations also reduce the false positive \nrate:in ourexperiments,MERLIN-inferred speci.cations resultin13false positives being removed; this constitutes \na 15% reductionin theC AT.NET false positive rate on these10 programs. The .nalfalse positive rate forCAT.NET \nafter applying MERLIN in our experiments drops to under 1%. Categories and Subject Descriptors D.3.4[Processors]: \nCom\u00adpilers; D.4.6 [Operating Systems]: Security and Protection Information .owcontrols; D.2.4[Software/ProgramVeri.cation]: \nStatistical methods General Terms Languages, Security,Veri.cation Keywords Security analysis tools, Speci.cation \ninference 1. Introduction Constraining information .ow is fundamental to security: we do notwant secret \ninformationto reach untrusted principals (con.den\u00adtiality), and we do not want untrusted principals to \ncorrupt trusted information (integrity). If we take con.dentiality and integrity to the extreme, then \nprincipals from different levels of trust can never interact, and the resulting system becomes unusable.For \ninstance, such a draconian system would never allow a trusted user to view untrusted content from the \nInternet. Thus, practical systems compromise on such extremes, and al\u00adlow .ow of sanitized information \nacross trust boundaries.For in\u00adstance, it is unacceptable to take a string from untrusted user input, \nand use it as part of a SQL query, since it leads to SQL injection attacks. However, it is acceptable \nto .rst pass the untrusted user input through a trusted sanitization function, and then use the san\u00aditized \ninput to construct a SQL query. Similarly, con.dential data needstobe cleansedtoavoid information leaks. \nPractical checking tools thathave emergedin recent years[4,21,24] typicallyaimto ensure that all explicit \n.ows of information across trust boundaries are sanitized. The fundamental program abstraction used in \nthe sequel (as well as by existing tools) is what we term the propagation graph a directed graph that \nmodels all interprocedural explicit information .owina program.1 The nodesofa propagation graph are methods, \nand edges represent explicit information .ow between methods. There is an edge from node m1 . m2 whenever \nthere is a .ow of information from method m1 to method m2, through a method 1We do not focus onimplicit \ninformation .ows [27] in this paper: dis\u00adcussions withC AT.NET [21]developers reveal that detectingexplicit \ninfor\u00admation .ow vulnerabilities is a more urgent concern. Existing commercial tools in this space exclusively \nfocus on explicit information .ow.  1. void ProcessRequest(HttpRequest request, 2. HttpResponse response) \n 3. { 4. string s1 = request.GetParameter(\"name\"); 5. string s2 = request.GetHeader(\"encoding\"); 6. \n 7. response.WriteLine(\"Parameter \" + s1); 8. response.WriteLine(\"Header \" + s2); 9. }  Figure 1. \nSimple cross-site scripting example parameter,orthroughareturnvalue,orbywayofanindirectupdate through \na pointer. Following the widely accepted Perl taint terminology conven\u00adtions [30] more precisely de.ned \nin [14] nodes of the prop\u00adagation graph are classi.ed as sources, sinks, and sanitizers;nodes not falling \nin the above categories are termed regular nodes. A source node returns tainted data whereas it is an \nerror to pass tainted datatoasinknode. Sanitizernodes cleanseor untaintor endorsein\u00adformation to mediate \nacross different levels of trust. Regular nodes do not taint data, and it is not an error to pass tainted \ndata to reg\u00adular nodes. If tainted data is passed to regular nodes, theymerely propagate it to their \nsuccessors without any mediation. A classi.cationof nodesina propagation graph into sources, sinks and \nsanitizers is called an information .ow speci.cation or, just speci.cation for brevity. Given a propagation \ngraph and a speci.cation, one can easily run a reachability algorithm to check ifallpathsfrom sourcesto \nsinkspass througha sanitizer.Infact, this is precisely what manycommercial analysis tools in everyday \nuse do [4, 24]. User-provided speci.cations, however, lead to bothfalse posi\u00adtives andfalse negativesin \npractice.False positives arise becausea .ow from source to sink classi.ed as offending by the tool could \nhavea sanitizer that the toolwas unaware of.False negatives arise because of incomplete information about \nsources and sinks. This paper presents MERLIN, a tool that automatically infers information .ow speci.cations \nfor programs. Our inference algo\u00adrithm uses the intuition that most paths in a propagation graph are \nsecure. That is, most paths in the propagation graph that start from a source and end in a sink pass \nthrough some sanitizer. Example 1 Consider a Web application code snippet written in C# shown in Figure \n1. While method GetParameter, the method returning arguments of an HTTP request, is highly likely to \nbe part of the default speci.cation that comes with a sta\u00adtic analysis tool and classi.ed as a source, \nthe method retriev\u00ading an HTTP header GetHeader may easily be missed. Be\u00adcause response.WriteLine sends \ninformation to the browser, there are two possibilities of cross-site scripting vulnerabilities on line \n7 and line 8. The vulnerability in line 7 (namely, passing a tainted value returned by GetParameter into \nWriteLine with\u00adout saniziting it .rst) will be reported,but the similar vulnerabil\u00adity on line8may be \nmissed due to an incomplete speci.cation. In fact, in both .NET and J2EE there exist a number of source \nmeth\u00adods that return various parts of an HTTP request. When we run MERLIN on larger bodies of code, even \nwithin the HttpRequest class alone, MERLIN correctly determines that getQueryString, getMethod, getEncoding, \nand others are sources missing from the default speci.cation that already contains 111 elements. While \nthis example is small, it is meant to conveythe challenge involved in identifying appropriate APIs for \nan arbitrary application. D Our approach. MERLINinfers information .ow speci.cations us\u00ading probabilistic \ninference. By using a random variable for each node in the propagation graph to denote whether the node \nis a source, sink or sanitizer, the intuition that most paths in a prop\u00adagation graph are secure can \nbe modeled using one probabilistic constraint for each path in the propagation graph. Aprobabilistic \nconstraint is a path constraint parameterized by the probability that the constraint is true. By solving \nthese con\u00adstraints, we can get assignments to values of these random vari\u00adables, which yields an information \n.ow speci.cation. In other words, we use probabilistic reasoning and the intuition we have about the \noutcome of the constraints (i.e, the probability of each constraint being true) to calculate values for \nthe inputs to the con\u00adstraints. Since there can be an exponential number of paths, us\u00ading one constraint \nper path does not scale. In order to scale, we approximate the constraints using a different set of constraints \non chosen triples of nodes in the graph.We show that the constraints on triples are a probabilistic abstraction \nof the constraints on paths (see Section 5) according to the theory developed by McIver and Morgan [19, \n20]. As a consequence, we can show that approximation using con\u00adstraints on triples does not introducefalse \npositives when compared with the constraints on paths. After studying large applications, we found that \nwe need additional constraints to reducefalse positives, such as constraints to minimize the number of \ninferred sanitizers, and constraintstoavoid inferringwrappersas sourcesor sinks.Sec\u00adtion 2 describes \nthese observations and constraints in detail. We show how to model these observations as additional probabilistic \nconstraints. Once we have modeled the problem as a set of proba\u00adbilistic constraints, speci.cation inference \nreduces to probabilistic inference.To perform probabilistic inferenceina scalable manner, MERLIN uses \nfactor graphs, which have been used in a variety of applications [12, 35]. While we can use the above \napproach to infer speci.cations without any prior speci.cation, we .nd that the quality of infer\u00adence \nis signi.cantly higher if we use the default speci.cation that comes with the static analysis tool as \nthe initial speci.cation, us\u00adingMERLINto complete this partial speci.cation. Our empirical results in \nSection6demonstrate that our tool provides signi.cant valueinboth situations.Inourexperiments,weuseCAT.NET[21], \nastate-of-the-art static analysis tool for .ndingWeb application se\u00adcurity .aws that works on .NET bytecode. \nThe initial speci.cation providedbyCAT.NET is modeled asextra probabilistic constraints on the random \nvariables associated with nodes of the propagation graph.To show theef.cacyofMERLIN, we show empirical \nresults for10 largeWeb applications. Contributions. Our paper makes the following contributions: MERLIN \nis the .rst practical approach to inferring speci.ca\u00adtions for explicit information .ow analysis tools, \na problem made important in recent years by the proliferation of infor\u00admation .ow vulnerabilitiesinWeb \napplications.  Asalient feature of our method is that our approximation (us\u00ading triples instead of paths) \ncan be characterized formally we makeaconnection between probabilistic constraints and proba\u00adbilistic \nprograms, and use the theory of probabilistic re.nement developed by McIver and Morgan [19, 20] to show \nre.nement relationships between setsof probabilistic constraints.Asa re\u00adsult, our approximation does \nnot introducefalse positives.  MERLINis able to successfully and ef.ciently infer information .owspeci.cationsinlargecode \nbases.Weprovidea compre\u00adhensive evaluation of the ef.cacyand practicality of MERLIN using10Web application \nbenchmarks.We .nda totalof 167 new con.rmed speci.cations, which resultina totalof322vul\u00adnerabilities \nacross the 10 benchmarks that were previously un\u00addetected.M ERLIN-inferred speci.cations also resultin13false \npositives being removed.   Figure 2. MERLIN system architecture. Outline. The rest of the paper is \norganized as follows. Section2 givesmotivationforthe speci.cation inference techniquesMERLIN uses. Section \n3 provides background on factor graphs. Section 4 describes our algorithm indetail. Section5proves that \nthe system of triple constraintsisa probabilistic abstractionoverthe systemof path constraints. Section6describes \nourexperimentalevaluation. Finally, Sections7and8describe relatedwork and conclude. 2. Overview Figure \n2 shows an architectural diagram of MERLIN. MERLIN starts with an initial, potentially incomplete speci.cation \nof the ap\u00adplication to produce a more complete speci.cation. Returning to Example 1, suppose we start \nMERLIN with an initial speci.cation that classi.es GetParameter asasource and WriteLine asasink. Then, \nthe speci.cation outputbyMERLIN would additionally con\u00adtain GetHeader as a source. In addition to the \ninitial speci.cation, MERLIN also consumes a propagation graph, a representation of the interprocedural \ndata .ow. Nodes of the propagation graph are methods in the program, and edges represent explicit .ow \nof data. De.nition 1. A propagation graph is a directed graph G = (NG,EG), where nodes NG are methods \nand an edge (n1 . n2) . Eg indicates that there is a .ow of information from method n1 to method n2 through \nmethod arguments, or return values, or indirectly through pointers. The propagation graph is a representation \nof the interprocedural data .ow produced by static analysis of the program. Due to the presence of virtual \nfunctions, and information .ow through refer\u00adences, a pointer analysis is needed to produce a propagation \ngraph. Since pointer analyses are imprecise, edges of a propagation graph approximate information .ows. \nImproving the accuracy of prop\u00adagation graph involves improving the precision of pointer analy\u00adsis, and \nis beyond the scope of this paper. In our implementation, CAT.NETuses an unsound pointer analysis, so \nthere could be .ows of data that our propagation graph does not represent. Even though propagation graphs \ncan have cycles, MERLIN performs a breadth\u00ad.rst search and deletes the edges that close cycles, resulting \nin an acyclic propagation graph. Removing cycles greatly simpli.es the subsequent phases of MERLIN. As \nour empirical results show, even with such approximations in the propagation graph, MERLIN is able to \ninfer useful speci.cations. Example2 We illustrate propagation graphs with an example. public void TestMethod1() \n{ string a = ReadData1(); string b = Prop1(a); string c = Cleanse(b); WriteData(c); } public void TestMethod2() \n{ string d = ReadData2(); string e = Prop2(d); string f = Cleanse(e); WriteData(f); }  In addition to \ntwo top-level driver methods, TestMethod1 and TestMethod2, this code uses six methods: ReadData1, ReadData2, \nProp1, Prop2, Cleanse, and WriteData. This pro\u00adgram gives rise to the propagation graph shown on the \nright. An edge in the propagation graphrepresents explicit .ow of data; i.g., the value returned by Prop1 \nis passed into Cleanse as an argu\u00adment. The edge from Prop1 to Cleanse represents this .ow. D 2.1 Assumptions \nand Probabilistic Inference The crux of our approach is probabilistic inference: we .rst use the propagation \ngraph to generate a set of probabilistic constraints and then use probabilistic inference to solve them. \nMERLIN uses factor graphs (see Section 3) to perform probabilistic inference ef.ciently. As shown in \nFigure 2, MERLIN performs the following steps: 1) constructafactor graph based on the propagation graph; \n2) perform probabilistic inference on thefactor graph to derive the likely speci.cation. MERLIN relies \non the assumption that most paths in the propa\u00adgation graph are secure. That is, most paths that go from \na source to a sink pass through a sanitizer. The assumption that errors are rare has been used before \nin other speci.cation inference tech\u00adniques [3, 10]. Further, we assume that the number of sanitizers \nis small, relative to the number of regular nodes. Indeed, develop\u00aders typically de.ne a small number \nof sanitization functions or use ones suppliedin libraries,and call themextensively.For instance, the \nout-of-box speci.cation that comes withCAT.NETsummarized in Figure12 containsonly7sanitizers. However, \nas we show later in this section, applying these as\u00adsumptions along various paths individually can lead \nto inconsis\u00adtencies, since the constraints inferred from different paths can be mutually contradictory. \nThus, we need to represent and analyze eachpath withina constraint system that tolerates uncertainty \nand contradictions. Therefore, we parameterize each constraint with the probabilityofits satisfaction. \nThese probabilisticconstraints model the relative positions of sources, sinks, and sanitizers in the \nprop\u00adagation graph. Our goal is to classify each node as a source, sink,  A1 For every acyclic pathm1,m2,...,mk-1,mk, \nwhere m1 is a potential source and mk is a potential sink, the joint probability of classifying m1 as \na source, mk as a sink and all of m2,...,mk-1 as regular nodes is low. B1 For everytriple of nodes(m1,m2,m3), \nwhere m1 is a potential source, m3 isapotential sink, and m1 and m3 are connected by a path through m2 \nin the propagation graph, the joint probability that m1 is a source, m2 is not a sanitizer, and m3 isa \nsinkis low. B2 For every pair of nodes (m1,m2) such that both m1 and m2 lie on the same path from a potential \nsource to a potential sink, the probability of both m1 and m2 being sanitizers is low. B3 Each node m \nis classi.ed asa sanitizer with probability s(m) (see De.nition3for de.nitionof s). B4 For every pair \nof nodes (m1,m2) such that both m1 and m2 are potential sources, and there is a path from m1 to m2 the \nprobability that m1 is a source and m2 is not a source is high. B5 For every pair of nodes (m1,m2) such \nthat both m1 and m2 are potential sinks, and there is a path from m1 to m2 the probability that m2 is \na sink and m1 is nota sink is high. Figure 3. Constraint formulation. Probabilities in italics are para\u00admeters \nof the constraints. sanitizer, or a regular node, so as to optimize satisfaction of these probabilistic \nconstraints.  2.2 Potential Sources, Sinks and Sanitizers The goal of speci.cation inference is to classify \nnodes of the prop\u00adagation graph into sources, sinks, sanitizers, and regular nodes. Since we are interested \nin string-related vulnerabilities, we .rst generate a set ofpotential sources, potential sanitizers, \nand poten\u00adtial sinks based on method signatures, as de.ned below: Methods that produce strings as output \nare classi.ed as poten\u00adtial sources.  Methods that take a string as input, and produce a string as output \nare classi.ed as potential sanitizers.  Methods that take a string as input, and do not produce a string \nas output are classi.ed as potential sinks.  Next, we perform probabilistic inference to infer a subset \nof poten\u00adtial sources, potential sanitizers, and potential sinks that form the inferred speci.cation. \n 2.3 Core Constraints Figure 3summarizes the constraints that MERLIN uses for proba\u00adbilistic inference.We \ndescribe eachofthe constraints below refer\u00adringto Example2where appropriate.We alsoexpressthe number \nof constraintsofeachtypeasa functionof N, the number of nodes in the propagation graph. A1: Path safety. \nWe assume that most paths from a source to a sink pass through at least one sanitizer. For example, we \nbelieve that if ReadData1 is a source, and WriteData is a sink, at least one of Prop1 or Cleanse is a \nsanitizer. This is stated using the set of constraints A1 shown in Figure 3. While constraints A1 model \nour core beliefs accurately, they are inef.cient if used directly: A1 requires one constraint per path, \nand the number of acyclic paths couldbeexponentialin the numberofpropagation graph nodes. B1:Triple safety. \nIn order to abstract the constraint set A1 with a polynomial number of constraints, we add a safety constraint \nB1 for each triple of nodes as shown in Figure 3. The number of B1 constraints is O(N3). In Section 5 \nwe prove that the constraints B1 are a probabilistic abstraction of constraints A1 under suitable choices \nof parameters.  2.4 Auxiliary Constraints In practice, the set of constraints B1 does not limit the \nsolution space enough.We have found empirically that just using this set of constraints allows too many \npossibilities, several of which are incorrect classi.cations. By looking at results over several large \nbenchmarks we havecome up with four sets of auxiliary constraints B2, B3, B4, and B5, which greatly enhance \nthe precision. B2:Pairwise Minimization. The set of constraints B1 allows the solver .exibility to consider \nmultiple sanitizers along a path. In general, we want to minimize the number of sanitizers we infer. \nThus, if there are several solutions to the set of constraints B1, we want to favor solutions that infer \nfewer sanitizers, while satisfy\u00ading B1, with higher probability. For instance, consider the path ReadData1, \nProp1, Cleanse, WriteData in Example 2. Suppose ReadData1 is a source and WriteData is a sink. B1 constrains \nthe triple (ReadData1, Prop1, WriteData) so that the probability of Prop1 not being a sanitizer is low; \nB1 also constrains the triple (ReadData1, Cleanse, WriteData) such that the probability of Cleanse not \nbeing a sanitizer is low. One solution to these constraints is to infer that both Prop1 and Cleanse are \nsanitizers. In reality,programmers do not add multiple sanitizers on a path and we believe that only \none of Prop1 or Cleanse is a sanitizer. Thus, we add a constraint B2 that for each pair of potential \nsanitizers it is unlikely that both are sanitizers, as shown in Figure 3. The number of B2 constraints \nis O(N2). Need for probabilistic constraints. Note that constraints B1 and B2 can be mutually contradictory, \nif they are modeled as non-probabilistic boolean constraints. For example, consider the propagation graph \nof Example 2. With each of the nodes ReadData1, WriteData, Prop1, Cleanse let us associate boolean variables \nr1, w, p1 and c respectively. The interpretation is that r1 is true iff ReadData1 is source, w is true \niff WriteData is a sink, p1 is true iff Prop1 is a sanitizer, and c is true iff Cleanse is a sanitizer. \nThen, constraint B1 for the triple (ReadData1, Prop1, WriteData) is given by the boolean for\u00admula r1 \n. w =. p1, and the constraint B1 for the triple (ReadData1, Cleanse, WriteData) isgivenbythe formula \nr1 . w =. c. Constraint B2 for the pair (Prop1, Cleanse) states that both Prop1 and Cleanse cannotbe \nsanitizers, andisgivenby the formula \u00ac(p1 . c). In addition, suppose we have additional in\u00adformation \n(say, from a partial speci.cation given by the user) that ReadData1 is indeed a source, and WriteData \nisa sink.We can conjoin all the above constraints to get theboolean formula: (r1 . w =. p1) . (r1 . w \n=. c) .\u00ac(p1 . c) . r1 . w This formula is unsatis.able and these constraints are mutually contradictory. \nViewing them as probabilistic constraints gives us the .exibility to add such con.icting constraints; \nthe probabilistic inference resolves such con.ictsbyfavoring satisfactionof those constraints with higher \nprobabilities attached to them. B3: Sanitizer Prioritization. We wish to bias the selection of sanitizers \nto favor those nodes that have a lot of source-to-sink paths going through them.We formalizethis below. \n De.nition 2. For eachnodem de.ne weight W (m) to be the total numberofpathsfrom sourcestosinksthatpassthrough \nm. Suppose we know that ReadData1 is a source, ReadData2 is not a source, and WriteData is a sink. Then \nW (Prop1)= W (Cleanse)=1, since there is only one source-to-sink path that goes through each ofthem. \nHowever, in this case, we believe that Prop1 is more likely to be a sanitizer than Cleanse since all \npaths going through Prop1 are source-to-sink paths and only some paths going through Cleanse are source-to-sink \npaths. De.nition 3. For each node m de.ne Wtotal (m) to be the total number of paths in the propagation \ngraph that pass through the node m (this includes both source-to-sink paths, as well as other paths). \nLet us de.ne s(m) for eachnode m as follows: W (m) s(m)= Wtotal (m) We add a constraint B3 that prioritizes \neach potential sanitizer n based on its s(n) value, as shown in Figure 3. The number of B3 constraints \nis O(N). B4: Source WrapperAvoidance. Similar to avoiding inference of multiple sanitizers on a path, \nwe also wish to avoid inferring mul\u00adtiple sources ona path.A prominent issue with inferring sources is \nthe issue of having wrappers, i.e. functions that return the result producedbythe source.For instance,ifan \napplication de.nes their own series of wrappers around system APIs, which is not uncom\u00admon, there is \nno need to .ag those as sources because that will actually not affect the set of detected vulnerabilities. \nIn such cases, wewantMERLINto infer the actual source rather than the wrapper function around it. We \nadd a constraint B4 for each pair of potential sources as shown in Figure 3. The number of B4 constraints \nis O(N2). B5: Sink WrapperAvoidance. Wrappers on sinks can be handled similarly, with the variation that \nin the case of sinks the data ac\u00adtually.owsfromthe wrappertothe sink.Weadda constraint B5 for each pair \nof potential sinks as shown in Figure 3. The number of B5 constraints is O(N2). Given a propagation graph \nwith N nodes, we can generate the constraints B1 through B5 in O(N3) time. Next, we present some background \non factor graphs, an approach to ef.ciently solving probabilistic constraints. 3. Factor Graph Primer \nIn the previous section, we have described a set of probabilistic constraints that are generated from \nan input propagation graph. The conjunction of these constraints can be looked upon as a joint probability \ndistribution over random variables that measure the odds of propagation graph nodes being sources, sanitizers, \nor sinks. Let p(x1,...,xN ) be a joint probability distribution over boolean variables x1,...,xN .We \nare interested in computing the marginal probabilities pi(xi) de.ned as: pi(xi)=\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7p(x1,...,xN ) \n(1) x1 xi-1xi+1 xN where xi .{true, false} for i . [1,...,N]. Since there are an exponential number of \nterms in Equation 1, a na\u00a8ive algorithm for computing pi(xi) will not work in practice. An abbreviated \nnotation for Equation1is pi(xi)=p(x1,...,xN ) (2) ~{xi} where the sum is over all variables except xi. \nThe marginal prob\u00adability for each variable de.nes the solution that we are interested in computing. \nIntuitively, these marginals correspond to the likeli\u00adhood of each boolean variable being equalto true \nor false. Factor graphs [35] are graphical models that are used for computing marginal probabilities \nef.ciently. These graphs take advantage of their structure in order to speed Figure 4. Factor graph \nfor (3). up the marginal probability computation (known as probabilistic inference).There area wide variety \nof techniques for performing probabilistic inference on a factor graph and the sum-product algorithm \n[35] is the most practical algorithm among these. Let the jointprobability distribution p(x1,...,xN ) \nbeaproduct offactors as follows: p(x1,...,xN )=fs(xs) (3) s where xs isthe setofvariablesinvolvedinthefactor \nfs.A factor graph isabipartite graph that represents thisfactorization.Afactor graph has two types of \nnodes: Variable nodes:one node for every variable xi.  Function nodes: one node for every function \nfs.  Example3 As an example, consider the following formula (x1 . x2) . (x1 .\u00acx3) (4)  'v-'' v-' C1 \nC2 Equation4canbe rewritten as: f(x1,x2,x3)= fC1 (x1,x2) . fC2 (x1,x3) (5) where 1 if x1 . x2 = true \nfC1 =(6) 0 otherwise 1 if x1 .\u00acx3 = true fC2 =(7) 0 otherwise ThefactorgraphforthisformulaisshowninFig.4. \nThere are three variable nodes for each variable xi, 1 = i = 3 and a function node fCj for each clause \nCj ,j .{1, 2}. Equations6and7 can also be de.ned probabilistically thus al\u00adlowing for solutions thatdo \nnot satisfy formula4;but such solu\u00adtions are usually set up such that theyoccur with low probability \nas shown below: 0.9 if x1 . x2 = true fC1 =(8) 0.1 otherwise 0.9 if x1 .\u00acx3 = true fC2 =(9)  0.1 otherwise \nIf we use this interpretation of fC1 and fC2 , then we can interpret formula5 asa probabilistic constraint. \nfC1 (x1,x2) \u00d7 fC2 (x1,x3) p(x1,x2,x3)= (10) Z where Z =(fC1 (x1,x2) \u00d7 fC2 (x1,x3)) (11) x1,x2,x3 is \nthe normalization constant. The marginal probabilities are de\u00ad.ned as pi(xi)=p(xx), 1 = i = 3 (12) ~{xi} \n GenFactorGraph Inputs: (G = (V, E) : P ropagationGraph), parameters low1, low2, high1, high2, high3, \nhigh4 . [0..1] Returns: afactor graph F for the propagation graph G 1: G' = MakeAcyclic(G) 2: (Xsrc \n,Xsan ,Xsnk ) = ComputePotentialSrcSanSnk(G) 3: (Triples, Pairssrc , Pairssan , Pairssnk )= ComputePairsAndTriples(G',Xsrc \n,Xsan ,Xsnk ) 4: s = ComputeWAndSValues(G') 5: for each triple (a, b, c). Triples do 6: Createafactor \nfB1(xa,xb,xc) in thefactor graph 7: Let fB1(xa,xb,xc)= xa .\u00acxb . xc 8: Let probability Pr(fB1(xa,xb,xc)= \ntrue)= low1 9: end for 10: for each pair (b1,b2). Pairssan do 11: Createafactor fB2(xb1 ,xb2 ) in thefactor \ngraph 12: Let fB2(xb1 ,xb2 )= xb1 . xb2 13: Let probability Pr(fB2(xb1 ,xb2 )= true)= low2 14: end for \n15: for each n . Xsan do 16: Createafactor fB3(xn) in thefactor graph 17: Let fB3(xn)= xn 18: Let Pr(fB3(xn)= \ntrue)= s(n) 19: end for 20: for each pair (xa1 ,xa2 ). Pairssrc do 21: Createafactor fB4(xa1 ,xa2 ) in \nthefactor graph 22: Let fB4(xa1 ,xa2 )= xa1 .\u00acxa2 23: Let probability Pr(fB4(xa1 ,xa2 )= true)= high3 \n24: end for 25: for each pair (xc1 ,xc2 ). Pairssnk do 26: Createafactor fB5(xc1 ,xc2 ) in thefactor \ngraph 27: Let fB5(xc1 ,xc2 )= \u00acxc1 . xc2 28: Let probability Pr(fB5(xc1 ,xc2 )= true)= high4 29: end \nfor Figure 5. Generatingafactor graph froma propagation graph. Here, pi(xi = true) denotes the fraction \nof solutions where the variable xi has value true. These marginal probabilities can be usedto computeasolutiontotheSATinstancein \nEquation4asfol\u00adlows:(1) chooseavariable xi with the highest marginal probability pi(xi) and set xi = \ntrue,ifpi(xi) is greater thanathresholdvalue, otherwise, set xi = false. (2) recompute the marginal probabili\u00adties \nand repeat Step (1) until all variables have been assigned (this is a satisfying assignment with high \nprobability). Iterative message passing algorithms [12,35] onfactor graphs perform Steps (1) and (2) \nas well as compute marginal probabilities ef.ciently. D 4. Constructing theFactor Graph Given a propagation \ngraph G, we describe how to build a fac\u00adtor graph F to represent the constraints B1 through B5 associ\u00adated \nwith G. Figure5 shows the algorithm GenFactorGraph that we use to generate thefactorgraph from the propagation \ngraph. The construction of the factor graph proceeds as follows. First, in line 1, the procedure MakeAcyclic \nconverts the input prop\u00adagation graph into a DAG G', by doing a breadth .rst search, and deleting edges \nthat close cycles. Next, in line 2, the proce\u00addure ComputePotentialSrcSanSnk computes the sets of potential \nsources, potential sanitizers, and potential sinks, and stores the re\u00adsults in Xsrc, Xsan , and Xsnk \n, respectively. On line 3, procedure ComputePairsAndTriples computes four sets de.ned in Figure 7. These \nsets can be computed by .rst doing a topological sort of G' (the acyclic graph), making one pass over \nthe graph in topo\u00adlogical order, and recording for each potential sanitizer the set of potential sources \nand potential sinks that can be reached from that node. Potential sources, sanitizers, and sinks are \ndeterminedby an\u00adalyzing type signatures of eachmethod, as described in Section 2.2. ComputeWAndSValues(G:Propagation \nGraph, Xsrc ,Xsan ,Xsnk :Set of Nodes) Precondition: Inputs: Acyclic propagation graph G,sets of nodesXsrc \n,Xsan ,Xsnk representing potential sources, potential sanitizers and potential sinks respectively Returns: \nW (n) and s(n) for each potential sanitizer n in G 1: for each potential source n . Xsrc do 2: F (n) \n:= initial probability of n being a source node 3: Ftotal (n) :=1 4: end for 5: for each potential sanitizer \nn . Xsan in topological order do 6: F (n) :=0 7: Ftotal (n) :=0 8: for each m . V such that (m, n) . \nE do 9: F (n) := F (n)+ F (m) 10: Ftotal (n) := Ftotal (n)+ Ftotal (m) 11: end for 12: end for 13: for \neach potential sink n . Xsnk do 14: B(n) := initial probability of n being a sink node 15: Btotal (n) \n:=1 16: end for 17: for each potential sanitizer n . Xsan in reverse topological order do 18: B(n) :=0 \n19: Btotal (n) :=0 20: for each m . V such that (n, m) . E do 21: B(n) := B(n)+ B(m) 22: Btotal (n) := \nBtotal (n)+ Btotal (m) 23: end for 24: end for 25: for each potential sanitizer n . Xsan do 26: W (n) \n:= F (n) * B(n) W (n) 27: s(n) := Ftotal (n)*Btotal (n) 28: end for 29: return s Figure 6. Computing \nW (n) and s(n). These sets can be computed in O(N3) time, where N is the number of nodes in the propagation \ngraph. Next in line 4, the function ComputeWAndSValues is in\u00advoked to compute W (n) and s(n) for every \npotential sanitizer n. The function ComputeWAndSValues is described in Figure 6. In lines 5 9, the algorithm \ncreates a factor node for the constraints B1. In lines 10 14, the algorithm iterates through all pairs \n(b1,b2)of potential sanitizers (that is, actual sanitizers as well as regular nodes)suchthatthereisapathinthe \npropagationgraphfrom b1 to b2 and addsfactors for constraints B2. In lines 15 19, the algorithm iterates \nthrough all potential sanitizers and adds factors for con\u00adstraints B3. In lines 20 24, the algorithm \niterates through all pairs (a1,a2) of potential sources such that there is a path in the prop\u00adagation \ngraph from a1 to a2 and addsfactors for constraints B4. Similarly, in lines 25 29, the algorithm iterates \nthrough all pairs (c1,c2) of potential sinks such that there is a path from c1 to c2 and addsfactors \nfor constraints B5. 4.1 Computing s() and W () Recall values s() and W () de.ned in Section 2.4. Figure \n6 de\u00adscribes ComputeWAndSValues, which computes s(n) for each potential sanitizer node, given input probabilities \nfor each poten\u00adtial source and each potential sink. The value s(n) for each potential sanitizer n is \nthe ratio of the sum of weighted source-sink paths that go through n and the total number of paths that \ngo through n. The algorithm computes W (n) and s(n) by computing four numbers F (n), Ftotal (n), B(n), \nand Btotal (n). F (n) denotes the total number of sources that can reach n, and Ftotal (n) denotes the \ntotal number of paths that can reach n. B(n) denotes the total number of sinks that can be reached from \n SET DEFINITION . Triples {(xsrc,xsan ,xsnk | xsrc . Xsrc, xsan . Xsan , xsnk . Xsnk , xsrc is connected \nto xsnk via xsan in p} p.paths(G ' ) . ' '' Pairssrc {(xsrc,x | xsrc . Xsrc, x . Xsrc, xsrc is connected \nto x in p} srcsrc src p.paths(G ' ) . ' '' Pairssan {(xsan ,x | xsan . Xsan , x . Xsan , xsan is connected \nto x in p} sansan san p.paths(G ' ) . '' ' Pairssnk {(xsnk ,x | xsnk . Xsnk , x . Xsnk , xsnk is connected \nto x in p} snksnk snk p.paths(G ' ) Figure 7. Set de.nitions for algorithm in Figure 5. Path(G = (V, \nE)) Returns: Mapping m from V to the set {0, 1} 1: for all paths p = s, . . . , n from potential sources \nto sinks in G do 2: assume(m(p) . 10 * 1).cp assume(m(p) . 10 * 1) 3: end for Post expectation:[. paths \np in G, m(p) . 10 * 1]. Figure 9. Algorithm Path n. Finally, Btotal (n) denotes the total number of \npaths that can be reached from n. For each potential sourcen, we set F (n) to an initial value in line2(in \nour implementation, wepickedan initialvalueof0.5), and we set Ftotal (n) to1in line 3.For each potential \nsink, we set B(n) to some initial value in line 14 (in our implementation, we picked this initial value \nto be 0.5), and we set Btotal (n) to1 in line 15. Since the graph G ' is a DAG, F (n) and Ftotal (n) \ncan be computed by traversing potential sanitizers in topological sorted order, and B(n) and Btotal (n) \ncan be computed by traversing potential sanitizers in reverse topological order. The computation of F \n(n) and Ftotal (n) in forward topological order is done in lines 5 12 and the computation of B(n) and \nBtotal (n) in reverse topological order is done in lines 17 24. Once F (n) and B(n) are computed, W (n) \nis set to F (n) \u00d7 B(n) and s(n) is set to W (n) W (n) = Ftotal (n) \u00d7 Btotal (n) Wtotal(n) as shown in \nline 26. Parameter tuning. The parameters low1, low2, high1, high2, high3, and high4 all need to be instantiated \nwith any values be\u00adtween0.0and1.0.In Section5weshowhowto compute parameter values for low1 associated \nwith the constraints B1 from the para\u00admeter values for the constraints A1. We have experimented with \nvarying the values of high1, high2, high3 and high4 from 0.8 to 0.95, and the low1, low2, values from \n0.05 to 0.2 in increments as small as .01.Fortunately, our inferenceis quite robust: these pa\u00adrameter \nvariations do not signi.cantly affect the quality of results produced by the inference in the applications \nwe have tried. Example4 Figure8shows thefactor graph obtainedby applying algorithm FactorGraphto thepropagation \ngraph in Figure 2. The marginal probabilitiesforallvariable nodes are computedbyprob\u00adabilistic inference \non thefactor graph and these are used to classify sources, sanitizers, and sinks in the propagation graph. \nD 5. Relationship betweenTriples andPaths In this section, wegivea formal relationship between theexponen\u00adtial \nnumber of constraints A1 and the cubic number of constraints Triple(G = (V, E)) Returns: Mapping m from \nV to the set {0, 1} 1: for all triples t = (s, w, n) such that s isa potential source, n is a potential \nsink and w lies on some path from s to n in G do 2: assume( assume(m((s, w, n)) = 101) m((s, w, n))= \n101).ct 3: end for Post expectation:[. paths p in G, m(p) . 10 * 1]. Figure 10. Algorithm Triple B1 \nin Section2.We use the theoryof probabilistic abstraction and re.nementdevelopedby McIverandMorgan[19,20]to \nderiveap\u00adpropriate bounds on probabilities associated with constraints A1 and B1 so that B1 is a probabilistic \nabstraction of the speci.cation A1 (or, equivalently, A1 is a probabilistic re.nement of B1). We .rst \nintroduce some terminology and basic concepts from [20]. Probabilistic re.nement primer. Non-probabilistic \nprograms can be reasoned with assertions in the style of Floydand Hoare [7]. The following formula in \nHoare logic: {Pre} Prog {Post} is valid if for every state s satisfying the assertion Pre, if the program \nProg is started at s, then the resulting state s ' satis.es the assertion Post.We assume Prog always \nterminates, and thus we do not distinguish between partial and total correctness. McIver and Morgan extend \nsuch reasoning to probabilistic pro\u00adgrams [19, 20]. In order to reason about probabilistic programs, \ntheygeneralize assertionstoexpectations.An expectationisafunc\u00adtion that maps each state to a positive \nreal number. If Prog is a probabilistic program, and PreE and PostE are expectations, then the probabilistic \nHoare-triple {PreE } Prog {PostE} is interpreted to mean the following: If the program Prog is started \nwith an initial expectation PreE , then it results in the expectation PostE after execution. Assertions \nare ordered by implication ordering. Expectations are ordered by the partial order =. Given two expectations \nAE and BE , we say that AE = BE holds if for all states s, we have that AE (s) = BE (s). Given an assertion \nA the expectation [A] is de.nedtomapevery state s to 1 if s satis.es A and to 0 otherwise. Suppose AE \n= BE . Consider a sampler that samples states using the expectations as a probability measure. Then, \nfor any threshold t and state s, if AE (s) >t, then it is the case that BE (s) >t. In other words, for \nanysampler with anythreshold t, sampling over AE results in a subset of states than those obtained by \nsampling over BE . Traditional axiomatic proofs are done using weakest precondi\u00adtions. The weakest precondition \noperator is denoted by WP. By  Figure 8. Factor graph for the propagation graphin Example 2. de.nition, \nfor any program Prog and assertion A, we have that WP(Prog,A) to be the weakest assertion B (weakest \nis de.ned with respect to the implication ordering between assertions) such that the Hoare triple {B}Prog{A} \nholds. McIver and Morgan extend weakest preconditions to expecta\u00adtions, and de.ne for an expectation \nAE , and a probabilistic pro\u00adgram Prog, WP(Prog, AE ) is the weakest expectation BE (weak\u00adest is de.ned \nwith respect to the ordering = between expecta\u00adtions) such that the probabilistic Hoare triple {BE }Prog{AE \n}holds. Given two probabilistic programs Spec and Impl with re\u00adspect to a post expectation PostE, we \nsay that Impl re.nes Spec if WP(Spec, PostE ) = WP(Impl, PostE ). Re.nement between constraint systems. \nWe now model con\u00adstraints A1 and B1 from Section2 as probabilistic programs with an appropriate post \nexpectation, and derive relationships between the parameters of A1 and B1 such that A1 re.nes B1. Consider \nanydirected acyclic graph G = (V, E), where E . V \u00d7 V .In this simple setting, nodes with in-degree0 \nare potential sources, nodes with out-degree 0 are potential sinks, and other nodes (internal nodes with \nboth in-degree and out-degree greater than 0) are potential sanitizers. We want to classify every node \nin V with a boolean value 0 or 1. That is, we want a mapping m : V .{0, 1}, with the interpretation that \nfor a potential source s . V , m(s)=1 means that s is classi.ed as a source, and that for a potential \nsink n . V , m(n)=1 means that n is classi.ed as a sink, and that for a potential sanitizer w . V , m(w)=1 \nmeans that w is classi.ed asa sanitizer.Weextend the mapping m to operate on paths (triples) over G by \napplying m to every vertex along the path (triple). Wewant mappingsm that satisfy the constraint that \nfor anypath p = s, w1,w2,...,wm,n that starts at a potential source s and endsina potential sink, the \nstring m(p) . 10 * 1, where 10 * 1 is the languageof strings thatbegin and end with1andhavea sequence \nof 0 s of arbitrary length in between. The constraint set A1 from Section2is equivalent in this set\u00adting \nto the probabilistic program Path given in Figure 9, and the constraint set B1 from Section 2 is equivalent \nin this setting to the probabilistic program Triple given in Figure 10. The statement assume(e)isano-opife \nholdsand silentlystopsexecutionif e does not hold. The probabilistic statement S1 .q S2 executes statement \nS1 with probability q and statement S2 with probability 1-q. Note that both programs Path and Triple \nhave the same postexpectation [. paths p in G, m(p) . 10 * 1]. Further, note that bothprograms are parameterized. \nThe Path program has a parameter cp associ\u00adated with each path p in G, and the Triple program hasa parameter \nct associated with each triple t in G. The following theorem states that the probabilistic program Path \nre.nes program Triple under appropriate choices of proba\u00adbilities as parameters. Furthermore, given a \nprogram Path with ar\u00adbitraryvalues for the parameters cp for each path p, it is possible to choose parameter \nvalues ct for each triple t in the program Triple such that Path re.nes Triple. Theorem. Consider any \ndirected acyclic graph G = (V, E) and probabilistic programs Path (Figure 9) and Triple (Figure 10) with \nstated post expectations. Let the program Path have a pa\u00adrameter cp for each path p. For any such valuations \nto the cp s there exist parameter values for the Triple program, namely a pa\u00adrameter ct for each triple \nt such that the program Path re.nes the program Triple with respect to the post expectation PostE = [. \npaths p in G, m(p) . 10 * 1]. Proof: Consider anytriple t = (s, w, n). Choose the parameter ct for the \ntriple t to be equal to the product of the parameters cp of all paths p in G that start at s, end at \nn and go through w. That is, ct = cp (13) p such that t is a subsequence of p. To show that Path re.nes \nTriple with respect to the post expectation PostE stated in the theorem, we need to show that WP(Triple, \nPostE ) = WP(Path, PostE ). That is, for each state s, we need to show that WP(Triple, PostE )(s) = WP(Path, \nPostE )(s). Note that WP(assume(e), [A]) = [e . A], and WP(S1 .q S2, [A]) = q \u00d7 WP(S1, [A]) + (1 - q) \n\u00d7 WP(S2, [A]) [20]. Using these two rules, we can compute WP(Triple, PostE ) and WP(Path, PostE ) as \nan expression tree which is a sum of product of expressions, where each product corresponds to a combination \nof probabilistic choices made in the program. First, consider any state s that does not satisfy PostE. \nFor this state, WP(Triple, PostE )(s)= WP(Path, PostE )(s) = 0, and the theorem follows trivially. Next, \nconsider a state . that satis.es PostE . In this case, WP(Path, PostE )(.) is the product of probabilities \ncp for each path p in G. Also, in this case WP(Triple, PostE )(.) is the product of two quantities X(.) \nand Y (.), where X(.) is equal to the product of probabilities ct for each triple t = (s, w, n) such \nthat m((s, w, n)) = 101, and Y (.) is equal to the product of ' ''' probabilities (1 - ct ' ) for each \ntriple t = (s ,w ,n ) such that m((s ' ,w ' ,n ' )) = 101. Since ct s have been carefully chosen according \nto Equation 13 and Y (.) . [0, 1], it follows that X(.) is less than or equal to the product of the probabilities \ncp for each path p. Therefore, it is indeed the case that for each state ., WP(Triple, PostE )(.) = WP(Path, \nPostE)(.). Any solver for a probabilistic constraint system C with post expectation PostE chooses states \ns such that WP(C, PostE )(s) is greater than some threshold t. Since we have proved that Path re.nes \nTriple, we know that every solution state for the Triple system,isalsoa solution stateforthe Path system. \nThus, the set of states that are chosenbysolver for the Triple system is contained in  Benchmark DLLs \nDLL size LOC (kilobytes) Alias ManagementTool 3 65 10,812 Chat Application 3 543 6,783 Bicycle Club App \n3 62 14,529 Software Catalog 15 118 11,941 Sporting Field ManagementTool 3 290 15,803 Commitment ManagementTool \n7 369 25,602 New HireTool 11 565 5,595 Expense Report ApprovalTool 4 421 78,914 Relationship Management \n5 3,345 1,810,585 Customer Support Portal 14 2,447 66,385 Figure 11. Benchmark application sizes. Type \nCount Revisions Sources Sinks Sanitizers 27 77 7 16 8 2 Figure 12. Statistics for the out-of-the box \nspeci.cation that comes withC AT.NET. the set of states that are chosen by the solver for the Path system. \nThis has the desirable property that the Triple system will not introduce more false positives than the \nPath system. Note that the Path system itself can result in false positives, since it requires at least \none sanitizer on each source-sink path, and does not require minimizationof sanitizers.In orderto removefalse \npositives due to redundant sanitizers, we add the constraints B2 and B3 to the Triple system. Further, \nthe path system does not distin\u00adguish wrappers of sources or sinks, so we add additional constraints \nB4 and B5 to avoid classifying these wrappers as sources or sinks. Using all these extra constraints, \nwe .nd that the Triple system performs very well on several large benchmarks and infers speci.\u00adcations \nwithveryfewfalse positives.We describe these resultsin the next section. 6. Experimental Evaluation CAT.NET, \na publicly available state-of-the-art static analysis tool forWeb applicationisthe platformforourexperiments[21].MER-LIN \nis implemented as anadd-on on top ofCAT.NET, usingIN-FER.NET, a library [22] that provides an interface \nto probabilistic inference algorithms. This section presents the results of evaluat\u00adingMERLIN on10 large \n.NETWeb applications. All these bench\u00admarks are security-critical enterprise line-of-business applications \ncurrently in production written in C# on top of ASP.NET. Theyare also subject of periodic security audits. \nBenchmark G Nodes Edges F Vars Nodes Alias Management Tool Chat Application Bicycle Club App Software \nCatalog Sporting Field Management Tool Commitment Management Tool New Hire Tool Expense Report Approval \nTool Relationship Management Customer Support Portal 59 1,209 156 187 176 246 190 455 268 320 356 563 \n502 1,101 811 1,753 3,639 22,188 3,881 11,196 3 3 25 33 70 317 73 484 50 50 107 1,781 116 1,917 252 2,592 \n874 391,221 942 181,943 Figure 13. Size statistics for the propagation graph G andfactor graph F used \nbyMERLIN.  6.1 Experimental Setup Figure 11 summarizes information about our benchmarks. As we discovered, \nnot all code contained within the application source tree is actually deployed to theWeb server. Most \nof the time, the number and size of deployed DLLs primarily consisting of .NET bytecode is a good measure \nof the application size, as shown in columns 2 3. Note that in a several cases, libraries supplied in \nthe form of DLLs without the source code constitute the biggest part of an application. Finally, to provide \nanother measure of the application size, column4shows the traditional line-of-code metric for all the \ncode within the application. To put our results on speci.cation discovery in perspective, Fig\u00adure 12 \nprovides information about the out-of-the box speci.cation for CAT.NET, the static analysis tool that \nwe used for our experi\u00adments [21]. The second column shows the number of speci.cations for each speci.cation \ntype. The last column shows the number of revisions each portion of the speci.cation has gone through, \nas ex\u00adtractedfromthecoderevision repository.Wehavemanuallyexam\u00adined the revisions to only count substantial \nones (i.e. just adding comments or changing whitespace was disregarded). It is clear from the table that \neven arriving at the default speci.cation for CAT.NET, as incomplete as it is, took a pretty signi.cant \nnumber of source revisions.We found that most commonly revised spec\u00adi.cation correspond to most commonly \nfound vulnerabilities. In particular, speci.cations for SQL injection and cross-site scripting attackshave \nbeen revisedbyfar the most. Moreover, after all these revisions, the ultimate initial speci.cationis \nalsofairly large, con\u00adsisting of a total of 111 methods. To provide a metric for the scale of the benchmarks \nrelevant for CAT.NET and MERLIN analyses, Figure 13 provides statistics on the sizes of the propagation \ngraph G computed by MERLIN, and the factor graph F constructed in the process of constraint generation.We \nsort our benchmarksby the numberof nodesin G. With propagation graphs containing thousands of nodes, \nit is not surprising that we had to develop a polynomial approximation in order forMERLIN to scale, as \nSection5describes.  6.2 Merlin Findings Figure 14 provides information about the speci.cations discov\u00adered \nby MERLIN. Columns 2 16 provide information about how many correct and false positive items in each speci.cation \ncate\u00adgory has been found. Note that in addition to good and bad speci.cations, as indicated by ,and X, \nwe also have a maybe column denoted by ?. This is because often what constitutes a good speci.cation \nis open to interpretation. Even in consultations with CAT.NET developers we found many cases where the \nclassi\u00ad.cation of a particular piece of the speci.cation is not clear-cut. The column labeled Rate gives \nthefalse positive rate forMERLIN: the percentage of bad speci.cations that were inferred. Overall, MERLIN \ninfers 381 speci.cations, out of which 167 are con.rmed and 127 more are potential speci.cations. TheMERLIN \nfalse pos\u00aditive rate, looking at the discovered speci.cations is 22%, com\u00adputed as (7+31+49)/381. This \nis decidedly better than the aver\u00adage state of the art false positive rate of over 90% [5]. The area \nin which MERLIN does the worst is identifying sanitizers (with a38%falsepositive rate). Thisis because \ndespite theextra con\u00adstraints described in Section 2.4, MERLIN still .ags some poly\u00admorphic functions \nas sanitizers. An example of this is the method NameValueCollection.get Item in the standard class library. \nDepending on what is stored in the collection, either the return re\u00adsult will be tainted or not. However, \nthisfunction clearly does not untaint its argument and so is not a good sanitizer. Figure 15 summarizes \ninformation about the security vulner\u00adabilities we .nd based on both the initial and the post-MERLIN \nspeci.cations.For the purpose of .nding vulnerabilities, the post\u00ad  SOURCES SANITIZERS SINKS Benchmark \nAll . ? X Rate All . ? X Rate All . ? X Rate Alias Management Tool 0 0 0 0 N/A 0 0 0 0 N/A 0 0 0 0 N/A \nChat Application 1 1 0 0 0% 0 0 0 0 N/A 2 2 0 0 0% Bicycle Club App 11 11 0 0 0% 3 2 0 1 33% 7 4 0 3 \n42% Software Catalog 1 1 0 0 0% 8 3 0 5 62% 6 3 2 1 16% Sporting Field Management Tool 0 0 0 0 N/A 0 \n0 0 0 N/A 1 0 1 0 0% Commitment Management Tool 20 19 0 1 5% 9 1 2 6 66% 11 8 1 2 18% New Hire Tool 3 \n3 0 0 0% 1 1 0 0 0% 17 14 0 3 17% Expense Report Approval Tool 8 8 0 0 0% 20 2 13 5 25% 20 14 0 6 30% \nRelationship Management 44 3 36 5 11% 1 0 0 1 100% 4 0 3 1 25% Customer Support Portal 26 21 4 1 3% 39 \n16 10 13 33% 118 30 55 33 27% Total 114 67 40 7 6% 81 25 25 31 38% 186 75 62 49 26% Figure 14. New speci.cations \ndiscovered withMERLIN.  BEFORE AFTER Benchmark All . ? X All . ? X - Alias Management Tool Chat Application \nBicycle Club App Software Catalog Sporting Field Management Commitment Management Tool New Hire Tool \nExpense Report Approval Tool Relationship Management Customer Support Portal 2 0 0 14 0 1 4 0 9 59 2 \n0 0 0 0 0 0 0 0 8 0 6 0 0 0 1 0 0 4 0 0 0 0 0 6 3 0 19 3 37 2 1 4 8 0 22 3 2 10 290 2 0 0 1 0 0 3 1 0 \n8 0 0 0 0 0 16 3 3 3 0 0 2 0 0 10 0 0 277 13 0 0 0 0 6 0 0 1 0 3 3 Total 89 40 6 43 342 322 17 3 13 Figure \n15. Vulnerabilities before and afterMERLIN.  MERLIN speci.cations we used are the good speci.cations \nde\u00adnoted by the ,columns in Figure 14. Columns 2 10 in Figure 15 show the number of vulnerabilities based \non the original speci\u00ad.cation and the number of newly found vulnerabilities. Just like with speci.cations, \nwe break down vulnerabilities into good , maybe , and bad categories denoted by ,, ?, and X. The very \nlast column reports 13former false positives eliminated with the MERLIN speci.cation because of newly \ndiscovered sanitizers. As with manyother static analysis tools,false positives is one ofthe primary complaints \naboutCAT.NET inpractice.As canbe seen from Figure 15 (thecolumn marked with - ),MERLINhelps reducethefalsepositiveratefrom48%to33%(thelatter \ncomputed as (43-13)/89). Furthermore, if we takeinto account all the 322 new (and con.rmed) vulnerabilities \ninto account, thefalse positive rate drops to 1% (computed as 3/342). Example 5 Function CreateQueryLink \nin Figure 16 is taken from the Software Catalog benchmark2. The return result of this function is passed \ninto a known cross-site redirection sink not shown here for brevity. The paths that go through request.Url.AbsolutePath \nand request.QueryString on lines6and 15 are correctly identi\u00ad.ed as new, not previously .agged vulnerabilities. \n CAT.NET .ags the path that passes through function QueryStringParser.Parse on line 18 as a vulnerability. \nHowever, with MERLIN, AntiXss.UrlEncode is correctly de\u00adterminedtobea sanitizer, eliminating thisfalse \npositive.With MERLIN, we eliminate all6false positivesin this benchmark.  2CAT.NET addresses explicit \ninformation .ow only and does not .ag thefact that thereisa control dependency on line13 because taintedvalue \nrequest.QueryString is used within a conditional. 1 public static string CreateQueryLink( 2 HttpRequest \nrequest, string key, string value, 3 List<string> keysToOmit, bool ignoreKey) 4 { 5 StringBuilder builder \n= new StringBuilder( 6 request.Url.AbsolutePath); 7 if (keysToOmit == null) { 8 keysToOmit = new List<string>(); \n9 } 10 builder.Append(\"?\"); 11 for (int i = 0; i < request.QueryString.Count; i++) { 12 if ((request.QueryString.GetKey(i) \n!= key) &#38;&#38; 13 !keysToOmit.Contains(request.QueryString.GetKey(i))) 14 { 15 builder.Append(request.QueryString.GetKey(i \n)); 16 builder.Append(\"=\"); 17 builder.Append(AntiXss.UrlEncode( 18 QueryStringParser.Parse( 19 request.QueryString.GetKey(i)))); \n20 builder.Append(\"&#38;\"); 21 } 22 } 23 if (!ignoreKey) { 24 builder.Append(key); 25 builder.Append(\"=\"); \n26 builder.Append(AntiXss.UrlEncode(value)); 27 } 28 return builder.ToString().TrimEnd(new char[] { \n&#38; }); 29 } Figure 16. Function CreateQueryLink for Example 5.  This short function illustrates \nmanytrickyissues with explicit in\u00adformation .ow analyses as well as the danger of unrestricted ma\u00adnipulation \nof tainted data as strings. D Note that while we start with theCAT.NETspeci.cation charac\u00adterized in \nFigure 12, M ERLIN can even infer speci.cation entirely without an initial speci.cation purely based \non the structure of the propagation graph. Example 6 Consider a short program fragment written in C# \nconsisting of two event handlers shown in Figure 17. When run 1 protected void TextChanged(object sender, \nEventArgs e) { 2 string str = Request.QueryString[\"name\"]; 3 string str2 = HttpUtility.HtmlEncode(str); \n4 Response.Write(str2); 5 } 6 7 protected void ButtonClicked(object sender, EventArgs e) { 8 string str \n= Request.UrlReferrer.AbsolutePath; 9 string str2 = HttpUtility.UrlEncode(str); 10 Response.Redirect(str2); \n11 } Figure 17. Program for Example 6.  Sources (1): string System.Web.HttpUtility+UrlDecoder.Getstring() \nSanitizers (8): string System.Web.HttpUtility.HtmlEncode(string) string System.Web.HttpUtility.UrlEncodeSpaces(string) \nstring System.Web.HttpServerUtility.UrlDecode(string) string System.Web.HttpUtility.UrlEncode(string, \nEncoding) string System.Web.HttpUtility.UrlEncode(string) string System.Web.HttpServerUtility.UrlEncode(string) \nstring System.Web.HttpUtility.UrlDecodestringFrom... string System.Web.HttpUtility.UrlDecode(string, \nEncoding) Sinks (4): void System.Web.HttpResponse.WriteFile(string) void System.Web.HttpRequest.set_QuerystringText(string) \nvoid System.IO.TextWriter.Write(string) void System.Web.HttpResponse.Redirect(string) Figure 18. Speci.cation \ninferred for Example 6. Benchmark CAT.NET P MERLIN G F Total time Alias Management Tool Chat Application \nBicycle Club App Software Catalog Sporting Field Management Tool Commitment Management Tool New Hire \nTool Expense Report Approval Tool Relationship Management Customer Support Portal 2.64 4.61 2.81 3.94 \n5.97 6.41 7.84 7.27 55.38 89.75 4.59 .81 .53 1.02 2.22 18.84 2.98 3.59 87.63 29.75 2.63 2.67 2.72 2.73 \n2.69 2.91 3.44 3.05 66.45 31.55 9.86 8.09 6.06 7.69 10.88 28.16 14.27 13.91 209.45 151.05 Figure 19. \nStatic analysis and speci.cation inference running time, in seconds. with no intial speci.cation at all, \nMERLIN is able to infer a small, but absolutely correct speci.cation consisting of 13 elements, as shown \nin Figure 18. Starting with even a small speci.cation such as the one above, MERLIN is able to succesfully \ninfer increasingly larger speci.cations that .ll many gaps in the original CAT.NET speci.cation. D  \n6.3 RunningTimes Finally, Figure 19 provides information about running time of the various MERLIN components, \nmeasured in seconds. Columns 2 4 show theCAT.NET running time, the time tobuild the propagation graph, \nand the inference time. The experiments were conducted on a3GHz Pentium Dual CoreWindows XP SP2 machine \nequipped with4 GB of memory. Overall, in part due to the approximation described in Section 5, our analysis \nscales quite well, with none of the benchmarks taking over four minutes to analyze. Given that CAT.NET \nis generally run once a day or less frequently, these running times are more than acceptable. 7. RelatedWork \nRelatedworkfalls into the broad categoriesof securingWeb appli\u00adcations and speci.cation mining . 7.1 \nSecuringWebApplications There has been much interest in static and runtime protection tech\u00adniquestoimprovethesecurityofWeb \napplications. Static analysis allows the developer to avoid issues such as cross-site scripting be\u00adfore \nthe application goes into operation. Runtime analysis allows exploit prevention and recovery during the \noperation of an applica\u00adtion.TheWebSSARIproject pioneeredthislineof research[8],by combining static and \ndynamic analysis for PHP programs. Several projectsthat cameafterWebSSARIimproveonthequalityof static \nanalysis for PHP [9, 33]. The Grif.n project proposes scalable and precise static and runtime analysis \ntechniques for .nding security vulnerabilities in large Java applications [15, 18]. Several other runtime \nsystems for taint tracking have been proposed as well, including Haldar et al. [6] and Chandra et al. \n[1] for Java, Pietraszek et al. [25], and Nguyen-Tuong et al.for PHP [23]. Several commercial tools have \nbeenbuiltto detect information.ow vulnerabilitiesin programs[4, 24]. All these tools without exception \nrequire a speci.cation of information .ow. Our work infers such speci.cations.  7.2 Mining Speci.cations \nAnumber of projects have addressed inferring speci.cations out\u00adside the contextof security.Fora generaloverviewof \nspeci.cation mining techniques, the reader is referred to Perracotta [34], Dy\u00adnaMine [16], andWeimer \net al. [31]. In particular, Engler et al. [3] infer speci.cations from code by seeking rules that involve \naction pairs: malloc paired with free, lock paired with unlock, etc. Li and Zhou [13] and Livshits and \nZimmerman [16] look at more gen\u00aderal patternsinvolving action pairsby combining data mining tech\u00adniques \nas well as sophisticated pointer analyses. Whaley et al. [32] considers inference of interface speci.cations \nfor Javamethod calls using static analysis. Jagannathan et al. [26] use data mining tech\u00adniques for inference \nof method preconditions in complex software systems. The preconditions might incorporate data-.ow as \nwell as control-.ow properties. Kremenek et al. [10] use probabilistic inference to classify func\u00adtions \nthat allocate and deallocate resources in programs. While sim\u00adilar in spirit to our work, inference of \ninformation .ow speci.ca\u00adtions appears to be a more complex problem than inference of allo\u00adcation and \ndeallocation routines in C code in part because there are more classes classi.cations sources, sinks, \nand sanitizers at play. Furthermore, the wrapper avoidance and sanitizer mini\u00admization constraints do \nnot have direct analogs in the allocator\u00addeallocator inference. Unlike Kremenek et al. [10] we use the \nthe\u00adory of probabilistic re.nement to formally characterize the triple approximation we have implemented \nfor the purposes of scaling. 8. Conclusions The growing importance of explicit information .ow is evidenced \nby the abundance of analysis tools for information .ow tracking and violation detection at the level \nof the language, runtime, oper\u00adating system, and hardware[1,2,6,8 11,15,17,18,23,28,29,33, 36]. Ultimately, \nall these approaches require speci.cations. In this paper we have presented MERLIN, a novel algorithm \nthat infers explicit information .ow speci.cations from programs. MERLIN derives a system of probabilistic \nconstraints based on in\u00adterprocedural data .owin the program, and computes speci.cations using probabilistic \ninference. In orderto scaletolarge programs,weapproximateanexponen\u00adtial number of probabilistic constraints \nby a cubic number of triple constraints, showing that the path-based constraint system is a re\u00ad.nement \nof the triple-based constraint system. This ensures that, for any given threshold, every solution admitted \nby the approxi\u00admated triple system is also admitted by the path system (for the same threshold). Though \nthis connectiongives formal groundingto our approximation, it does not say anything about the precision \nof the results that can be obtained; such an assessment is obtained em\u00adpiricallybyevaluating thequalityof \nthe speci.cation inferred for large applications, the number of new vulnerabilities discovered, and the \nnumber offalse positives removed. Based on our observa\u00adtions about largeWeb applications, we addedextra \nconstraints to the triple system (constraints B2, B3, B4, and B5 in Figure 3) to enhance the quality \nof the results.  With these extra constraints, our empirical results convincingly demonstrate that our \nmodel indeed achieves goodprecision. In our experimentswith10largeWeb applications writtenin.NET,MER-LIN \n.nds a total of 167 new con.rmed speci.cations, which re\u00adsult in a total of 322 newly discoveredvulnerabilities \nacross the 10 benchmarks. Equally importantly,M ERLIN-inferred speci.cations also resultin13false positivesbeing \nremoved.Asa resultofnew .ndings and eliminatingfalse positives, the .nal false positive rate forCAT.NETafter \nMERLINin ourexperimentsdropstoabout1%. Acknowledgments We thank Carroll Morgan forexplaining his insights \nabout abstrac\u00adtion and re.nement between probabilistic systems. We want to thankTed Kremenek, G. Ramalingam, \nKapilVaswani, andWest\u00adleyWeimer for their insightful comments on earlier drafts.We are indebted to Mark \nCurphey, Hassan Khan, DonWillits, andothers behind CAT.NET for their unwavering assistance throughout \nthe project.Wealso thank JohnWinn for help with usingINFER.NET. References [1] D. Chandra and M. Franz. \nFine-grained information .ow analysis and enforcement in a java virtual machine. In Annual Computer Security \nApplications Conference, pages 463 475, 2007. [2] M. Dalton, H. Kannan, and C. Kozyrakis. Raksha: a .exible \ninformation .ow architecture for software security. In Proceedings of the International Symposium on \nComputer Architecture, pages 482 493, 2007. [3] D. R. Engler, D. Y. Chen, and A. Chou. Bugs as inconsistent \nbehavior:Ageneral approach to inferring errors in systems code. In In Proceedings ofACM Symposium on \nOperating Systems Principles, pages 57 72, 2001. [4]Fortify.Fortify code analyzer. http://www.ouncelabs.com/,2008. \n[5]C.L. Goues andW.Weimer. Speci.cation mining withfewfalse positives. In Tools and Algorithms for the \nConstruction and Analysis of Systems, 2009. [6] V. Haldar, D. Chandra, and M. Franz. Dynamic taint propagation \nfor Java. In Proceedings of the Annual Computer Security Applications Conference, pages 303 311, Dec. \n2005. [7] C. A. R. Hoare. An axiomatic basis for computer programming. Communicationsof theACM, 12:576 \n583, October 1969. [8] Y.-W. Huang, F. Yu, C. Hang, C.-H. Tsai, D.-T. Lee, and S.-Y. Kuo. Securing Web \napplication code by static analysis and runtime protection. In Proceedings of the Conference onWorldWideWeb, \npages 40 52, May 2004. [9] N. Jovanovic, C. Kruegel, and E. Kirda. Pixy: a static analysis tool for detecting \nWeb application vulnerabilities (short paper). In Proceedings of the Symposium on Security and Privacy, \nMay 2006. [10]T. Kremenek,P.Twohey,G. Back,A.Y.Ng,andD.R. Engler. From uncertainty to belief: Inferring \nthe speci.cation within. In Symposium on Operating Systems Design and Implementation, pages 161 176, \nNov. 2006. [11] M. Krohn,A.Yip,M. Brodsky,N. Cliffer,M.F. Kaashoek,E.Kohler, and R. Morris. Information \n.ow control for standard os abstractions. In Proceedings of Symposium on Operating Systems Principles, \npages 321 334, 2007. [12] F. R. Kschischang, B. J. Frey, and H. A. Loeliger. Factor graphs and the sum-product \nalgorithm. IEEETransactions on Information Theory, 47(2):498 519, 2001. [13] Z. Li and Y. Zhou. Pr-miner: \nAutomatically extracting implicit programming rules and detecting violations in large software code. \nIn Proceedings of the European Software Engineering Conference, 2005. [14] B. Livshits. Improving Software \nSecurity with Precise Static and Runtime Analysis. PhD thesis, Stanford University, Stanford, California, \n2006. [15] B. Livshits and M. S. Lam. Finding security errors in Java programs with static analysis. \nIn Proceedings of the Usenix Security Symposium, pages 271 286, Aug. 2005. [16] B. Livshits andT. Zimmermann. \nDynaMine: Finding common error patterns by mining software revision histories. In Proceedings of the \nInternational SymposiumontheFoundationsof Software Engineering, pages 296 305, Sept. 2005. [17] M. Martin, \nB. Livshits, and M. S. Lam. Finding application errors and security vulnerabilities using PQL: a program \nquery language. In Proceedings of the Conference on Object-Oriented Programming, Systems, Languages, \nand Applications, Oct. 2005. [18] M. Martin, B. Livshits, and M. S. Lam. SecuriFly: Runtime vulnerability \nprotection for Web applications. Technical report, Stanford University, Oct. 2006. [19] A. McIver and \nC. Morgan. Abstraction, Re.nement and Proof of Probabilistic Systems. Springer, 2004. [20] A. McIver \nand C. Morgan. Abstraction and re.nement in probabilistic systems. SIGMETRICSPerformance Evaluation Review, \n32:41 47, March 2005. [21] Microsoft Corporation. Microsoft Code Analysis Tool .NET (CAT.NET). http://www.microsoft. \ncom/downloads/details.aspx?FamilyId= 0178e2ef-9da8-445e-9348-c93f24cc9f9d&#38;displaylang=en, 32009. \n[22]T.Minka,J.Winn,J.Guiver,andA. Kannan.Infer.NET2.2,2009.Mi\u00adcrosoft Research Cambridge. http://research.microsoft.com/infernet. \n[23] A. Nguyen-Tuong, S. Guarnieri, D. Greene, J. Shirley, and D. Evans. Automatically hardening Web \napplications using precise tainting. In Proceedings of the IFIP International Information Security Conference, \nJune 2005. [24] OunceLabs, Inc. Ounce. http://www.ouncelabs.com/, 2008. [25]T. Pietraszek andC.V. Berghe. \nDefendingagainst injection attacks through context-sensitive string evaluation. In Proceedings of the \nRecent Advances in Intrusion Detection, Sept. 2005. [26] M. K. Ramanathan, A. Grama, and S. Jagannathan. \nStatic speci.cation inference using predicate mining. In PLDI, 2007. [27] A. Sabelfeld and A. Myers. \nLanguage-based information-.ow security. IEEEJournalon SelectedAreasin Communications,21(1):5 19, January \n2003. [28] Z.Su andG.Wassermann. The essenceof command injection attacks in web applications. In Proceedings \nof POPL, 2006. [29] S. Vandebogart, P. Efstathopoulos, E. Kohler, M. Krohn, C. Frey, D. Ziegler,F. Kaashoek,R. \nMorris, andD. Mazi`eres. Labels andevent processes in the Asbestos operating system. ACMTrans. Comput. \nSyst., 25(4):11, 2007. [30] L.Wall. Perl security. http://search.cpan.org/dist/perl/ pod/perlsec.pod. \n[31]W.WeimerandG.C. Necula. Mining temporal speci.cationsfor error detection. In Proceedings of the International \nConference onTools and Algorithms for the Construction and Analysis of Systems, pages 461 476, 2005. \n[32] J. Whaley, M. Martin, and M. Lam. Automatic extraction of object\u00adoriented component interfaces. \nIn Proceedings of the International Symposium on SoftwareTesting and Analysis, pages 218 228, 2002. [33] \nY. Xie and A. Aiken. Static detection of security vulnerabilities in scripting languages. In Proceedings \nof the Usenix SecuritySymposium, pages 271 286, Aug. 2006. [34] J.Yang and D. Evans. Perracotta: mining \ntemporal API rules from imperfect traces. In Proceedings of the International Conference on Software \nEngineering, pages 282 291, 2006. [35] J. S.Yedidia,W.T. Freeman, andY.Weiss. Understanding belief propagation \nand its generalizations. Exploring Arti.cial Intelligence in the New Millennium, pages 239 269, 2003. \n[36]N. Zeldovich,S.Boyd-Wickizer,E.Kohler,andD. Mazires. Making information .ow explicit in HiStar. In \nProceedings of the Symposium on Operating Systems Design and Implementation, pages 263 278, 2006.  \n  \n\t\t\t", "proc_id": "1542476", "abstract": "<p>The last several years have seen a proliferation of static and runtime analysis tools for finding security violations that are caused by <i>explicit information flow</i> in programs. Much of this interest has been caused by the increase in the number of vulnerabilities such as cross-site scripting and SQL injection. In fact, these explicit information flow vulnerabilities commonly found in Web applications now outnumber vulnerabilities such as buffer overruns common in type-unsafe languages such as C and C++. Tools checking for these vulnerabilities require a specification to operate. In most cases the task of providing such a specification is delegated to the user. Moreover, the efficacy of these tools is only as good as the specification. Unfortunately, writing a comprehensive specification presents a major challenge: parts of the specification are easy to miss, leading to missed vulnerabilities; similarly, incorrect specifications may lead to false positives.</p> <p>This paper proposes Merlin, a new approach for automatically inferring explicit information flow specifications from program code. Such specifications greatly reduce manual labor, and enhance the quality of results, while using tools that check for security violations caused by explicit information flow. Beginning with a data propagation graph, which represents interprocedural flow of information in the program, Merlin aims to automatically infer an information flow specification. Merlin models information flow paths in the propagation graph using probabilistic constraints. A naive modeling requires an exponential number of constraints, one per path in the propagation graph. For scalability, we approximate these path constraints using constraints on chosen triples of nodes, resulting in a cubic number of constraints. We characterize this approximation as a probabilistic abstraction, using the theory of probabilistic refinement developed by McIver and Morgan. We solve the resulting system of probabilistic constraints using factor graphs, which are a well-known structure for performing probabilistic inference.</p> <p>We experimentally validate the Merlin approach by applying it to 10 large business-critical Web applications that have been analyzed with CAT.NET, a state-of-the-art static analysis tool for .NET. We find a total of 167 new confirmed specifications, which result in a total of 322 <i>additional</i> vulnerabilities across the 10 benchmarks. More accurate specifications also reduce the false positive rate: in our experiments, Merlin-inferred specifications result in 13 false positives being removed; this constitutes a 15% reduction in the CAT.NET false positive rate on these 10 programs. The final false positive rate for CAT.NET after applying Merlin in our experiments drops to under 1%.</p>", "authors": [{"name": "Benjamin Livshits", "author_profile_id": "81100637280", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1464236", "email_address": "", "orcid_id": ""}, {"name": "Aditya V. Nori", "author_profile_id": "81320493380", "affiliation": "Microsoft Research, Bangalore, India", "person_id": "P1464237", "email_address": "", "orcid_id": ""}, {"name": "Sriram K. Rajamani", "author_profile_id": "81100468626", "affiliation": "Microsoft Research, Bangalore, India", "person_id": "P1464238", "email_address": "", "orcid_id": ""}, {"name": "Anindya Banerjee", "author_profile_id": "81100144615", "affiliation": "IMDEA Software, Madrid, Spain", "person_id": "P1464239", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542485", "year": "2009", "article_id": "1542485", "conference": "PLDI", "title": "Merlin: specification inference for explicit information flow problems", "url": "http://dl.acm.org/citation.cfm?id=1542485"}