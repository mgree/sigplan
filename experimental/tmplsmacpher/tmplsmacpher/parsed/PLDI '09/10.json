{"article_publication_date": "06-15-2009", "fulltext": "\n FastTrack: Ef.cient and Precise Dynamic Race Detection Cormac Flanagan Stephen N. Freund Computer Science \nDepartment Computer Science Department University of California at Santa Cruz Williams College Santa \nCruz, CA 95064 Williamstown, MA 01267 Abstract Multithreaded programs are notoriously prone to race conditions. \nPrior work on dynamic race detectors includes fast but imprecise race detectors that report false alarms, \nas well as slow but precise race detectors that never report false alarms. The latter typically use expensive \nvector clock operations that require time linear in the number of program threads. This paper exploits \nthe insight that the full generality of vec\u00adtor clocks is unnecessary in most cases. That is, we can \nreplace heavyweight vector clocks with an adaptive lightweight represen\u00adtation that, for almost all operations \nof the target program, requires only constant space and supports constant-time operations. This representation \nchange signi.cantly improves time and space per\u00adformance, with no loss in precision. Experimental results \non Java benchmarks including the Eclipse development environment show that our FASTTRACK race detector \nis an order of magnitude faster than a traditional vector-clock race detector, and roughly twice as fast \nas the high-performance DJIT+ algorithm. FASTTRACK is even comparable in speed to ERASER on our Java \nbenchmarks, while never reporting false alarms. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: \nSoftware/Program Veri.cation reliability; D.2.5 [Software Engineering]: Testing and Debugging monitors, \ntesting tools; F.3.1 [Logics and Meanings of Programs]: Specifying and Veri\u00adfying and Reasoning about \nPrograms General Terms Languages, Algorithms, Veri.cation Keywords Race conditions, concurrency, dynamic \nanalysis 1. Introduction Multithreaded programs are notoriously prone to race conditions and other concurrency \nerrors, such as deadlocks and atomicity vi\u00adolations. The widespread adoption of multi-core processors \nonly exacerbates these problems, both by driving the development of increasingly-multithreaded software \nand by increasing the inter\u00adleaving of threads in existing multithreaded systems. A race condition occurs \nwhen a program s execution contains two accesses to the same memory location that are not ordered by \nthe happens-before relation [21], where at least one of the accesses is a write. Race conditions are \nparticularly problematic because they typically cause problems only on certain rare interleavings, Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 09, June 15 \n20, 2009, Dublin, Ireland. Copyright c . 2009 ACM 978-1-60558-392-1/09/06. . . $5.00 making them extremely \ndif.cult to detect, reproduce, and elimi\u00adnate. Consequently, much prior work has focused on static [1, \n5, 3, 19, 4, 12, 15, 26, 40] and dynamic [33, 38, 27, 42, 30, 11, 34, 42, 30] analysis tools for detecting \nrace conditions. In general, dynamic race detectors fall into two categories, de\u00adpending on whether they \nreport false alarms. Precise race detectors never produce false alarms. Instead, they compute a precise \nrepre\u00adsentation of the happens-before relation for the observed trace and report an error if and only \nif the observed trace has a race con\u00addition. Typically, the happens-before relation is represented using \nvector clocks (VCs) [23], as in the DJIT+ race detector [29, 30]. Vector clocks are expensive, however, \nbecause they record infor\u00admation about each thread in a system. Thus, if the target program has n threads, \nthen each VC requires O(n) storage space and each VC operation requires O(n) time. Motivated in part \nby the performance limitations of vector clocks, a variety of alternative imprecise race detectors have \nbeen developed, which may provide better coverage but can report false alarms on race-free programs. \nFor example, Eraser s LockSet al\u00adgorithm [33] enforces a lock-based synchronization discipline and reports \nan error if no lock is consistently held on each access to a particular memory location. Eraser may report \nfalse alarms, how\u00adever, on programs that use alternative synchronization idioms such as fork-join or \nbarrier synchronization. Some LockSet-based race detectors include happens-before reasoning to improve \nprecision in such situations [42, 28]. MultiRace [29, 30] leveraged this combi\u00adnation of techniques to \nimprove performance as well. That analysis, and others [42], also group multiple memory locations into \nmini\u00adpages to improve performance, again at some cost in precision. A primary limitation of both static \nrace detectors and impre\u00adcise dynamic race detectors is the potential for a large number of false alarms. \nIndeed, it has proven surprisingly dif.cult and time consuming to identify the real errors among the \nspurious warnings produced by some tools. Even if a code block looks suspicious, it may still be race-free \ndue to some subtle synchronization dis\u00adcipline that is not (yet) understood by the current programmer \nor code maintainer. Even worse, additional real bugs (e.g., deadlocks) could be added while attempting \nto .x a spurious warning pro\u00adduced by these tools. Conversely, real race conditions could be ignored \nbecause they appear to be false alarms. Precise (albeit in\u00adcomplete) race detectors avoid these issues, \nbut such detectors are limited by the performance overhead of vector clocks. This paper exploits the \ninsight that, while vector clocks provide a general mechanism for representing the happens-before relation, \ntheir full generality is not actually necessary in most cases. Indeed, the vast majority of data in multithreaded \nprograms is either thread local, lock protected, or read shared. Our FASTTRACK analysis uses an adaptive \nrepresentation for the happens-before relation to provide constant-time fast paths for these common cases, \nwithout any loss of precision or correctness in the general case. Figure 1: Multithreaded Program Traces \na . Trace = Operation* a, b . Operation = rd(t, x) | wr(t, x) | acq(t, m) | rel(t, m) | fork(t, u) | \njoin(t, u) s, u, t . Tid x, y . Var m . Lock In more detail, a VC-based race detector such as DJIT+ records \nthe clock of the most recent write to each variable x by each thread t. By comparison, FASTTRACK exploits \nthe observation that all writes to x are totally ordered by the happens-before relation (assuming no \nraces detected so far), and so it records information only about the very last write to x, speci.cally, \nthe clock and thread identi.er of that write. We refer to this pair of a clock and a thread identi.er \nas an epoch. Read operations on thread-local and lock-protected data are also totally ordered (assuming \nno races have been detected) and so FASTTRACK records only the epoch of the last read to such data. FASTTRACK \nadaptively switches from epochs to vector clocks where necessary (for example, when data becomes read-shared) \nin order to guarantee no loss of precision. It also switches from vector clocks back to lightweight epochs \nwhere possible (for example, when read-shared data is subsequently updated). Using these adaptive representation \ntechniques, FASTTRACK reduces the analysis overhead of almost all monitored operations from O(n)-time \n(where n is the number of threads in the target program) to O(1)-time, via lightweight, constant-time \nfast paths. Note that this performance improvement involves no precision loss. In addition to improving \nperformance, our epoch representation also reduces space overhead. A VC-based race detector requires \nan O(n) space overhead for each memory location of the target pro\u00adgram and can quickly exhaust memory \nresources. By comparison, FASTTRACK reduces the space overhead for thread-local and lock\u00adprotected data \nfrom O(n) to O(1). For comparison purposes, we have developed implementations of six different dynamic \nrace detectors: -ERASER [33], a well-known imprecise race detector. -GOLDILOCKS, a precise race detector \nbased on an extended notion of LockSets [14]. -BASICVC, a traditional VC-based race detector. -DJIT+, \na high-performance VC-based race detector [30]. -MULTIRACE, a hybrid LockSet/DJIT+ race detector [30]. \n-FASTTRACK, the algorithm presented in this paper. These tools are all implemented on top of the same \nframework for dynamic analysis of multithreaded Java software, and the VC\u00adbased tools use the same optimized \nvector clock primitives, thus providing a true apples-to-apples comparison. Our experimental results \non several Java benchmarks including the Eclipse develop\u00adment environment [13] show that FASTTRACK outperforms \nthese other tools. For example, it provides almost a 10x speedup over BA-SICVC and a 2.3x speedup even \nover the DJIT+ algorithm. It also provides a substantial increase in precision over ERASER, with no loss \nin performance. In summary, the main contributions of FASTTRACK are: It provides a signi.cant improvement \nin precision over earlier, imprecise race detectors such as Eraser [33], while providing comparable performance. \n Despite its ef.ciency, it is still a comparatively simple algorithm that is straightforward to implement, \nas illustrated in Figure 5.  It uses an adaptive lightweight representation for the happens\u00adbefore relation \nthat reduces both time and space overheads.  It contains optimized constant-time fast paths that handle \nup\u00adwards of 96% of the operations in benchmark programs.  It provides a 2.3x performance improvement \nover the prior DJIT+ algorithm, and typically incurs less than half the mem\u00adory overhead of DJIT+ . \n FASTTRACK also improves the performance of more heavy\u00adweight dynamic analysis tools by identifying millions \nof irrel\u00adevant, race-free memory accesses that can be ignored. It pro\u00advides a 5x speedup for the VELODROME \ndynamic atomicity checker [17] and an 8x speedup for the SINGLETRACK deter\u00adminism checker [32].  The \npresentation of our results proceeds as follows. The fol\u00adlowing section reviews preliminary concepts \nand notation, as well as the DJIT+ algorithm. Section 3 presents the FASTTRACK algo\u00adrithm. Section 4 \ndescribes our prototype implementation of this al\u00adgorithm, and Section 5 presents our experimental results. \nSection 6 concludes with a discussion of related work. 2. Preliminaries 2.1 Multithreaded Program Traces \nWe begin by formalizing the notions of execution traces and race conditions. A program consists of a \nnumber of concurrently exe\u00adcuting threads, each with a thread identi.er t . Tid, and these threads manipulate \nvariables x . Var and locks m . Lock. (See Figure 1.) A trace a captures an execution of a multithreaded \npro\u00adgram by listing the sequence of operations performed by the various threads. The set of operations \nthat a thread t can perform include: rd(t, x) and wr(t, x), which read and write a value from x;  acq(t, \nm) and rel(t, m), which acquire and release a lock m;  fork(t, u), which forks a new thread u; and \n join(t, u), which blocks until thread u terminates.  The happens-before relation <a for a trace a \nis the smallest transitively-closed relation over the operations1 in a such that the relation a<a b holds \nwhenever a occurs before b in a and one of the following holds: Program order: The two operations are \nperformed by the same thread.  Locking: The two operations acquire or release the same lock.  Fork-join: \nOne operation is fork(t, u) or join(t, u) and the other operation is by thread u.  If a happens before \nb, then it is also the case that b happens after a. If two operations in a trace are not related by \nthe happens-before relation, then they are considered concurrent. Two memory access con.ict if they both \naccess (read or write) the same variable, and at least one of the operations is a write. Using this terminology, \na trace has a race condition if it has two concurrent con.icting accesses. We restrict our attention \nto traces that are feasible and which re\u00adspect the usual constraints on forks, joins, and locking operations, \ni.e., (1) no thread acquires a lock previously acquired but not re\u00adleased by a thread, (2) no thread \nreleases a lock it did not previ\u00ad 1 In theory, a particular operation a could occur multiple times in \na trace. We avoid this complication by assuming that each operation includes a unique identi.er, but, \nto avoid clutter, we do not include this unique identi.er in the concrete syntax of operations. ously \nacquire, (3) there are no instructions of a thread u preceding an instruction fork(t, u) or following \nan instruction join(t, u), and (4) there is at least one instruction of thread u between fork(t, u) and \njoin(v, u).  2.2 Review: Vector Clocks and the DJIT+ Algorithm Before presenting the FASTTRACK algorithm, \nwe brie.y review the DJIT+ race detection algorithm [30], which is based on vector clocks [23]. A vector \nclock VC : Tid . Nat records a clock for each thread in the system. Vector clocks are partially-ordered \n(.) in a point-wise manner, with an associated join operation () and minimal element (.V ). In addition, \nthe helper function inct increments the t-component of a vector clock: V1 . V2 iff .t. V1(t) = V2(t) \nV1 . V2 = .t. max(V1(t), V2(t)) .V = .t. 0 inct(V )= .u. if u = t then V (u)+1 else V (u) In DJIT+, each \nthread has its own clock that is incremented at each lock release operation. Each thread t also keeps \na vector clock Ct such that, for any thread u, the clock entry Ct(u) records the clock for the last operation \nof thread u that happens before the current operation of thread t. In addition, the algorithm maintains \na vector clock Lm for each lock m. These vector clocks are updated on synchronization operations that \nimpose a happens-before order between operations of different threads. For example, when thread u releases \nlock m, the DJIT+ algorithm updates Lm to be Cu. If a thread t subsequently acquires m, the algorithm \nupdates Ct to be Ct . Lm, since subsequent operations of thread t now happen after that release operation. \nTo identify con.icting accesses, the DJIT+ algorithm keeps two vector clocks, Rx and Wx, for each variable \nx. For any thread t, Rx(t) and Wx(t) record the clock of the last read and write to x by thread t. A \nread from x by thread u is race-free provided it happens after the last write of each thread, that is, \nWx . Cu. A write to x by thread u is race-free provided that the write happens after all previous accesses \nto that variable, that is, Wx . Cu and Rx . Cu. As an example, consider the following fragment from an \nexe\u00adcution trace, where we include the relevant portion of the DJIT+ instrumentation state: the vector \nclocks C0 and C1 for threads 0 and 1; and the vector clocks Lm and Wx for the last release of lock m \nand the last write to variable x, respectively. We show two com\u00adponents for each vector clock, but the \ntarget program may of course contain additional threads.2 2 For clarity, we present a variant of the \nDJIT+ algorithm where some clocks are one less than in the original formulation [29]. This revised algorithm \nhas the same performance as the original but is slightly simpler and more directly comparable to FASTTRACK. \n At the write wr(0,x), DJIT+ updates Wx with current clock of thread 0. At the release rel(0,m), Lm is \nupdated with C0. At the acquire acq(1,m), C1 is joined with Lm, thus capturing the dashed release-acquire \nhappens-before edge shown above. At the second write, DJIT+ compares the vector clocks Wx = .4, 0,......4, \n8,.... = C1 Since this check passes, the two writes are not concurrent, and no race condition is reported. \n3. The FASTTRACK Algorithm A limitation of VC-based race detectors such as DJIT+ is their performance. \nIf a target program has n threads, then each vector clock requires O(n) storage space and each vector \nclock operation (copying, comparing, joining, etc) requires O(n) time. Empirical data gathered from a \nvariety of Java programs indi\u00adcates that synchronization operations (lock acquires and releases, forks, \njoins, waits, noti.es, etc) account for a very small fraction of the operations that must be monitored \nby a race detector. Reads and writes to object .elds and arrays, on the other hand, account for over \n96% of monitored operations. The key insight behind FAST-TRACK is that the full generality of vector \nclocks is not necessary in over 99% of these read and write operations: a more lightweight representation \nof the happens-before information can be used in\u00adstead. Only a small fraction of operations performed \nby the target program necessitate expensive vector clock operations. We begin by providing an overview \nof how our analysis catches each type of race condition. Each race condition is either: a read\u00adwrite \nrace condition (where the trace contains a read that is con\u00adcurrent with a later write to the same variable); \na write-read race condition (a write concurrent with a later read); or a write-write race condition (involving \ntwo concurrent writes). Detecting Write-Write Races. We .rst consider how to ef.ciently analyze write \noperations. At the second write operation in the trace discussed in the previous section, DJIT+ compares \nthe vector clocks Wx . C1 to determine whether there is a race. A careful inspection reveals, however, \nthat it is not necessary to record the entire vector clock .4, 0,.... from the .rst write to x. Assuming \nno races have been detected on x so far,3 then all writes to x are totally ordered by the happens-before \nrelation, and so the only critical information that needs to be recorded is the clock (4) and identity \n(thread 0) of the thread performing the last write. This information (clock 4 of thread 0) is then suf.cient \nto determine if a subsequent write to x is in a race with any preceding write. We refer to a pair of \na clock c and a thread t as an epoch, denoted c@t. Although rather simple, epochs provide the cru\u00adcial \nlightweight representation for recording suf.ciently-precise aspects of the happens-before relation ef.ciently. \nUnlike vector clocks, an epoch requires only constant space, independent of the number of threads in \nthe program, and copying an epoch is a constant-time operation. An epoch c@t happens before a vector \nclock V (c@t . V ) if and only if the clock of the epoch is less than or equal to the corresponding clock \nin the vector. c@t . V iff c = V (t) Comparing an epoch to a vector clock (.) requires only O(1) time, \nunlike vector clock comparisons (.), which require O(n) time. We use .e to denote a minimal epoch 0@0. \n(This minimal epoch is not unique; for example, another minimal epoch is 0@1.) Using this optimized representation, \nFASTTRACK analyzes the above trace using a compact instrumentation state that records only 3 FASTTRACK \nguarantees to detect at least the .rst race on each variable. a write epoch Wx for variable x, rather \nthan the entire vector clock Wx, reducing space overhead. (C and L record the same information as Cand \nLin DJIT+.) At the .rst write to x, FASTTRACK performs an O(1)-time epoch write Wx := 4@0. FASTTRACK \nsubsequently ensures that the second write is not concurrent with the preceding write via the O(1)-time \ncomparison: Wx = 4@0 ..4, 8, .... = C1 To summarize, epochs reduce the space overhead for detecting write-write \ncon.icts from O(n) to O(1) per allocated memory location, and replaces the O(n)-time vector clock comparison \n. with the O(1)-time comparison operation . . Detecting Write-Read Races. Detecting write-read races \nunder the new representation is also straightforward. On each read from x with current vector clock Ct, \nwe check that the read happens after the last write via the same O(1)-time comparison Wx . Ct. Detecting \nRead-Write Races. Detecting read-write race condi\u00adtions is somewhat more dif.cult. Unlike write operations, \nwhich are totally ordered (assuming no race conditions detected so far), reads are not totally ordered \neven in race-free programs. Thus, a write to a variable x could potentially con.ict with the last read \nof x performed by any other thread, not just the last read in the entire trace seen so far. Hence, we \nmay need to record an entire vector clock Rx, in which Rx(t) records the clock of the last read from \nx by thread t. However, we can avoid keeping a complete vector clock in many cases. Our examination of \ndata access patterns across a va\u00adriety of multithreaded Java programs indicate that variable reads are \noften totally ordered in practice, particularly in the following common situations: Thread-local data, \nwhere only one thread accesses a variable, and hence these accesses are totally ordered by program-order. \n Lock-protected data, where a protecting lock is held on each access to a variable, and hence all access \nare totally ordered, either by program order (for accesses by the same thread) or by synchronization \norder (for accesses by different threads).  Reads are typically unordered only when data is read-shared, \nthat is, when the data is .rst initialized by one thread and then shared between multiple threads in \na read-only manner. FASTTRACK uses an adaptive representation for tracking the read history of each variable \nthat is tuned to optimize the common case of totally-ordered reads, while still retaining the full precision \nof vector clocks when necessary. In particular, if the last read to a variable happens after all pre\u00adceding \nreads, then FASTTRACK records only the epoch of this last read, which is suf.cient to precisely detect \nwhether a subsequent access to that variable con.icts with any preceding read in the entire program history. \nThus, for thread-local and lock-protected data(whichdoexhibittotally-orderedreads), FASTTRACK requires \nonly O(1) space for each allocated memory location and only O(1) time per memory access. In the less \ncommon case where reads are not totally ordered, FASTTRACK stores theentirevectorclock. However, itstill \nhandles read operations in O(1) time, via an epoch-VC comparison (.). In addition, since such data is \ntypically read-shared, writes to such variables are rare, and so their analysis overhead is negligible. \nAnalysis Details. Based on the above intuition, we now describe the FASTTRACK algorithm in detail. Our \nanalysis is an online algo\u00adrithm that maintains an analysis state s; when the target program performs \nan operation a, the analysis updates its state via the rela\u00adtion s .a s.. The instrumentation state s \n=(C, L, R, W ) is a tuple of four components, where: Ct identi.es the current vector clock of thread \nt.  Lm identi.es the vector clock of the last release of lock m.  Rx identi.es either the epoch of \nthe last read from x, if all other reads happened-before that read, or else records a vector clock that \nis the join of all reads of x.  Wx identi.es the epoch of the last write to x.  The initial analysis \nstate is: s0 =(.t.inct(.V ), .m..V , .x..e, .x..e) Figure 2 presents the key details of how FASTTRACK \n(left col\u00adumn) and DJIT+ (right column) handle read and write operations of the target program. Expensive \nO(n)-time operations are high\u00adlighted in grey. That table also shows the instruction frequencies observed \nin our program traces, as well as how frequently each rule was applied. For example, 82.3% of all memory \nand synchroniza\u00adtion operations performed by our benchmarks were reads, and rule [FT READ SAME EPOCH] \nwas used to check 63.4% of those reads. Read Operations. The .rst four rules provide various alternatives \nfor analyzing a read operation rd(t, x). Rule [FT READ SAME EPOCH] optimizes the case where x was already \nread in this epoch. This fast path requires only a single epoch comparison and handles over 60% of all \nreads. We use E(t) to denote the current epoch c@t of thread t, where c = Ct(t) is t s current clock. \nDJIT+ incorporates a comparable rule [DJIT+ READ SAME EPOCH]. The remaining three read rules all check \nfor write-read con.icts via the fast epoch-VC comparison Wx . Ct, and then update Rx appropriately. Here, \nR is a function, Rx abbreviates the function application R(x), and R[x := V ] denotes the function that \nis iden\u00adtical to R except that it maps x to V . Changes to the instrumen\u00adtation state are expressed as \nfunctional updates for clarity in the transition rules, but they are implemented as constant-time in-place \nupdates in our implementation. If Rx is already a vector clock, then [FT READ SHARED] simply updates \nthe appropriate component of that vector. Note that multi\u00adple reads of read-shared data from the same \nepoch are all covered by this rule. We could extend rule [FT READ SAME EPOCH] to han\u00addle same-epoch reads \nof read-shared data by matching the case that Rx . VC and Rx(t)= Ct(t). The extended rule would cover \n78% of all reads (the same as [DJIT+ READ SAME EPOCH]) but does not improve performance of our prototype \nperceptibly. If the current read happens after the previous read epoch (where that previous read may \nbe either by the same thread or by a different thread, presumably with interleaved synchroniza\u00adtion), \n[FT READ EXCLUSIVE] simply updates Rx with the access\u00ading threads current epoch. For the more general \nsituation where the current read may be concurrent with the previous read epoch, Figure 2: FASTTRACK \nRace Detection Algorithm and its Comparison to DJIT+ . FASTTRACK State: C : Tid . VC L : Lock . VC W \n: Var . Epoch R : Var . (Epoch . VC ) Reads: 82.3% of all Operations  [FT READ SAME EPOCH] Rx = E(t) \n(C, L, R, W ) .rd(t,x) (C, L, R, W ) [FT READ SHARED] Rx . VC Wx . Ct R. = R[x := Rx[t := Ct(t)]] (C, \nL, R, W ) .rd(t,x) (C, L, R.,W ) [FT READ EXCLUSIVE] Rx . Epoch Rx . Ct Wx . Ct R. = R[x := E(t)] (C, \nL, R, W ) .rd(t,x) (C, L, R.,W ) [FT READ SHARE] Rx = c@u Wx . Ct V = .V [t := Ct(t),u := c] R. = R[x \n:= V ] (C, L, R, W ) .rd(t,x) (C, L, R.,W ) 63.4% of reads 20.8% of reads 15.7% of reads 0.1% of reads \nWrites:  14.5% of all Operations [FT WRITE SAME EPOCH] Wx = E(t) (C, L, R, W ) .wr(t,x) (C, L, R, W \n) [FT WRITE EXCLUSIVE] Rx . Epoch Rx . Ct Wx . Ct W . = W [x := E(t)] (C, L, R, W ) .wr(t,x) (C, L, \nR, W .) [FT WRITE SHARED] Rx . VC Rx Wx . Ct W . = W [x := E(t)] R. = R[x := .e] (C, L, R, W ) .wr(t,x) \n(C, L, R.,W .) 71.0% of writes 28.9% of writes 0.1% of writes DJIT+ State: C : Tid . VC L : Lock . \nVC W : Var . VC R : Var . VC  [DJIT+ READ SAME EPOCH] 78.0% of reads Rx(t)= Ct(t) (C, L, R, W) .rd(t,x) \n(C, L, R, W) [DJIT+ READ] 22.0% of reads Wx R. = R[x := Rx[t := Ct(t)]] (C, L, R, W) .rd(t,x) (C, L, \nR. , W) [DJIT+ WRITE SAME EPOCH]  71.0% of writes Wx(t)= Ct(t) (C, L, R, W) .wr(t,x) (C, L, R, W) [DJIT+ \nWRITE] 29.0% of writes Wx Rx W. = W[x := Wx[t := Ct(t)]] (C, L, R, W) .wr(t,x) (C, L, R, W.)  [FT READ \nSHARE] allocates a vector clock to record the epochs of both reads, since either read could subsequently \nparticipate in a read-write race. Of these three rules, the last rule is the most expensive but is rarely \nneeded (0.1% of reads) and the .rst three rules provide commonly-executed, constant-time fast paths. \nIn contrast, the cor\u00adresponding DJIT+ rule [DJIT+ READ] always executes an O(n)\u00adtime vector clock comparison \nfor these cases. Write Operations. The next three FASTTRACK rules handle a write operation wr(t, x). \nRule [FT WRITE SAME EPOCH] optimizes the case where x was already written in this epoch, which applies \nto 71.0% of write operations, and DJIT+ incorporates a comparable rule. [FT WRITE EXCLUSIVE] provides \na fast path for the 28.9% of writes for which Rx is an epoch, and this rule checks that the write happens \nafter all previous accesses. In the case where Rx is a vector clock, [FT WRITE SHARED] requires a full \n(slow) VC comparison, but this rule applies only to a tiny fraction (0.1%) of writes. In contrast, the \ncorresponding DJIT+ rule [DJIT+ WRITE] requires slow VC comparisons on 29.0% of writes. Other Operations. \nFigure 3 shows how FASTTRACK handles all other operations (acquire, release, fork, and join). These operations \nare rare, so the traditional analysis for these operations in terms of expensive VC operations is perfectly \nadequate. Thus, these FAST-TRACK rules are similar to those of DJIT+ and other VC-based analyses. Example. \nThe execution trace in Figure 4 illustrates how FAST-TRACK dynamically adapts the representation for \nthe read history Rx of a variable x. Initially, Rx is .e, indicating that x has not yet been read. After \nthe .rst read operation rd(1,x), Rx becomes the epoch 1@1 recording both the clock and the thread identi.er \nof that read. The second read rd(0,x) at clock 8 is concurrent with the .rst read, and so FASTTRACK switches \nto the vector clock rep\u00adresentation .8, 1,.... for Rx, recording the clocks of the last reads from x \nby both threads 0 and 1. After the two threads join, the write operation wr(0,x) happens after all reads. \nHence, any later opera\u00adtion cannot be in a race with either read without also being in a race on that \nwrite operation, and so the rule [FT WRITE SHARED] discards the read history of x by resetting Rx to \n.e, which also switches x back into epoch mode and so optimizes later accesses to x. The last read in \nthe trace then sets Rx to a non-minimal epoch. Correctness. FASTTRACK is precise and reports data races \nif and only if the observed trace contains concurrent con.icting accesses, as characterized by the following \ntheorem. THEOREM 1 (Correctness). Suppose a is a feasible trace. Then a is race-free if and only if .s \nsuch that s0 .a s. PROOF The two directions of this theorem follow from Theo\u00adrems 2 and 3, respectively. \nSee Appendix. . 4. Implementation ROADRUNNER. We have developed a prototype implementa\u00adtion of FASTTRACK \nas a component of ROADRUNNER, a frame\u00adwork we have designed for developing dynamic analyses for mul\u00adtithreaded \nsoftware. ROADRUNNER is written entirely in Java and runs on any JVM. ROADRUNNER inserts instrumentation \ncode into the target bytecode program at load time. This instrumentation code generates a stream of events \nfor lock acquires and releases, .eld and array accesses, method entries and exits, etc. Back-end tools, \nsuch as FASTTRACK, process this event stream as it is generated. Re-entrant lock acquires and releases \n(which are redundant) are .l\u00adtered out by ROADRUNNER to simplify these analyses. Figure 3: Synchronization \nand Threading Operations Other:  3.3% of all Operations [FT ACQUIRE] C. = C[t := (Ct . Lm)] (C, L, \nR, W ) .acq(t,m) (C., L, R, W ) [FT RELEASE] L. = L[m := Ct] C. = C[t := inct(Ct)] (C, L, R, W ) .rel(t,m) \n(C.,L., R, W ) [FT FORK] C. = C[u := Cu . Ct,t := inct(Ct)] (C, L, R, W ) .fork(t,u) (C., L, R, W ) [FT \nJOIN] C. = C[t := Ct . Cu,u := incu(Cu)] (C, L, R, W ) .join(t,u) (C., L, R, W ) ROADRUNNER enables \nback-end tools to attach instrumenta\u00adtion state to each thread, lock object, and data memory location \nused by the target program. Tool-speci.c event handlers update the instrumentation state for each operation \nin the observed trace and report errors when appropriate. The ROADRUNNER framework provides several bene.ts. \nBy working exclusively at the bytecode level, ROADRUNNER tools can check any Java program regardless \nof whether source code is available. Moreover, tools only need to reason about the relatively simple \nbytecode language. In addition, ROADRUNNER s compo\u00adnent architecture facilitates reliable comparisons \nbetween different back-end checking tools. FastTrack Instrumentation State and Code. FASTTRACK repre\u00adsents \nan epoch c@t as a 32-bit integer, where the top eight bits store the thread identi.er t and the bottom \ntwenty-four bits store the clock c. Two epochs for the same thread can be directly compared as integers, \nsince the thread identi.er bits in each integer are iden\u00adtical. FASTTRACK represents a vector clock as \nan array of epochs, even though the thread identi.er bits in these epochs are redun\u00addant, since this \nrepresentation optimizes the epoch-VC comparison operation (.). We use the function TID(e) to extract \nthe thread identi.er of an epoch. While 32-bit epochs has been suf.cient for all programs tested, switching \nto 64-bit epochs would enable the FASTTRACK to handle large thread identi.ers or clock values. In addition, \nexisting tech\u00adniques to reduce the size of vector clocks [10] could also be em\u00adployed to save space. \nFASTTRACK associates with each thread a ThreadState ob\u00adject (see Figure 5) containing a unique thread \nidenti.er tid and a vector clock C. The current epoch for thread t can be expressed as t.C[t.tid], and \nwe cache that value in the epoch .eld. Each memory location (object .eld or array element) has an as\u00adsociated \nVarState object containing epochs W and R and a vector clock Rvc. These represent the W and R components \nof the analy\u00adsis state. Setting R to the special epoch READ SHARED indicates that the location is in \nread-shared mode, and hence Rvc is in use. FAST-TRACK also maintains a LockState containing a vector \nclock for each object used as a lock. Figure 5 shows FASTTRACK event handling pseudocode for read and \nwrite operations. The code includes the name of the corre\u00adsponding FASTTRACK analysis rule for each code \nbranch, as well Figure 4: Example Trace. as the percentage of time that the branch is taken. Note that \nthe two slow operations in these event handlers (vector clock allocation and comparison) are executed \nextremely rarely, on 0.1% of reads and 0.1% of writes. Despite its performance, the FASTTRACK al\u00adgorithm \nis surprisingly straightforward to implement. Event han\u00addlers for other operations are also simple but \nless interesting. Our actual implementation introduces some additional features, such as more precise \nerror reporting, and it replaces the .. check x.W > t.C[TID(x.W)] with the equivalent but slightly faster \ncondition TID(x.W) != t.tid &#38;&#38; x.W > t.C[TID(x.W)] , eliminates obvious common subexpressions, \netc. Granularity. ROADRUNNER supports two levels of granularity for analyzing memory locations. The default \n.ne-grain analysis treats each .eld of an object as a distinct entity that has its own VarState. The \ncoarse-grain analysis treats all .elds of an object as a single entity with a single VarState. The coarse-grain \nanaly\u00adsis signi.cantly reduces the memory footprint for VarStates, but may produce false alarms if, for \nexamples, two .elds of an ob\u00adject are protected by different locks. However, as others have ob\u00adserved \n[38, 42], object-oriented programs most often use the same synchronization discipline for all .elds of \nan object. ROADRUN-NER also supports .ne and coarse grain analyses for arrays. Extensions. The FASTTRACK \nimplementation extends our anal\u00adysis in several straightforward ways. Most importantly, it supports additional \nsynchronization primitives, including wait and notify, volatile variables, and barriers. FASTTRACK models \na wait operation on lock m in terms of the underlying release and subsequent acquisition of m. Thus, \nno additional analysis rules are necessary. A notify operation can be ignored by FASTTRACK. It affects \nscheduling of threads but does not induce any happens-before edges between them. The Java Memory Model \n[22] guarantees that a write to a volatile variable vx . VolatileVar happens before every subse\u00adquent \nread of vx. To handle volatiles, FASTTRACK extends the L Figure 5: FastTrack Instrumentation State and \nCode class ThreadState { int tid; int C[]; int epoch; // invariant: epoch == C[tid] } class VarState \n{ int W, R; int Rvc[]; // used iff R == READ_SHARED } class LockState { int L[]; } void read(VarState \nx, ThreadState t) if (x.R == t.epoch) return; // Same Epoch 63.4% // write-read race? if (x.W > t.C[TID(x.W)]) \nerror; // update read state if (x.R == READ_SHARED) { // Shared 20.8% x.Rvc[t.tid] = t.epoch; } else \n{ if (x.R <= t.C[TID(x.R)]) { // Exclusive 15.7% x.R = t.epoch; } else { // Share 0.1% if (x.Rvc == null) \n x.Rvc = newClockVector(); // (SLOW PATH) x.Rvc[TID(x.R)] = x.R; x.Rvc[t.tid] = t.epoch; x.R = READ_SHARED; \n}   } } void write(VarState x, ThreadState t) if (x.W == t.epoch) return; // Same Epoch 71.0% // write-write \nrace? if (x.W > t.C[TID(x.W)]) error; // read-write race? if (x.R != READ_SHARED) { // Shared 28.9% \nif (x.R > t.C[TID(x.R)]) error; } else { // Exclusive 0.1% if (x.Rvc[u] > t.C[u] for any u) error; // \n(SLOW PATH) } x.W = t.epoch; // update write state } component of the analysis state to map volatile \nvariables to the vec\u00adtor clock of the last write: L :(Lock . VolatileVar) . VC Volatile reads and writes \nthen modify the instrumentation state in much the same way as lock acquire and release. [FT READ VOLATILE] \nC. = C[t := Ct . Lvx ] (C, L, R, W ) .vol rd(t,vx) (C., L, R, W ) [FT WRITE VOLATILE] L. = L[vx := (Ct \n. Lvx )] C. = C[t := inct(Ct)] (C, L, R, W ) .vol rd(t,vx) (C.,L., R, W )  We also add a new type of \nevent to indicate when threads are released from a barrier. While strictly not necessary since FAST-TRACK \ncan precisely handle the synchronization primitives upon which barriers are built, the barrier implementations \nused in many benchmarks and libraries contain benign race conditions that would cause spurious warnings \nif not handled specially. The operation barrier rel(T ) indicates that the set of threads T are simultane\u00adously \nreleased from a barrier. (We do not need to track entries to barriers.) [FT BARRIER RELEASE] F C. = \n.t.. if t . T then inct( Cu) else C(t) u.T (C, L, R, W ) .barrier rel(T ) (C., L, R, W ) Thus, the .rst \npost-barrier step by any thread t . T happens after all pre-barrier steps by threads in T and is unordered \nwith respect to the next steps taken by other threads in T . Con.guration options enable FASTTRACK to \nuse this rule for any barrier implementation identi.ed by the user. Although FASTTRACK does not currently \nsupport the full set of concurrency primitives available in the Java concurrency li\u00adbrary [37], we believe \ntheir effects on a program s happens-before graph can all be modeled in our representation. 5. Evaluation \nWe validate the effectiveness of FASTTRACK with three sets of ex\u00adperiments. We .rst compare FASTTRACK \ns performance and pre\u00adcision to other dynamic race detectors when checking a variety of benchmarks. Second, \nwe demonstrate how to use FASTTRACK to improve the performance of checkers for more complex con\u00adcurrency \nproperties. Finally, we describe our experience of using FASTTRACK to check the Eclipse development environment \n[13]. 5.1 Precision and Performance This section compares the precision and performance of seven dynamic \nanalyses: EMPTY (which performs no analysis and is used to measure the overhead of ROADRUNNER); FASTTRACK; \nERASER [33], extended to handle barrier synchronization [29]; DJIT+ [30]; MULTIRACE [30]; GOLDILOCKS \n[14]; and BA-SICVC. BASICVC is a simple VC-based race detector that main\u00adtains a read and a write VC \nfor each memory location and performs at least one VC comparison on every memory access. To ensure reliable \ncomparisons, all tools were implemented on top of ROAD-RUNNER as similarly as possible. For example, \nBASICVC, DJIT+ , MULTIRACE, and FASTTRACK use the same vector clock imple\u00admentation, and all checkers \nwere pro.led and tuned to eliminate unnecessary bottlenecks. We note that several additional techniques \ncould be used to im\u00adprove the performance of all these checkers. For example, we could (1) include a \nseparate static analysis to reduce the need for run-time checks; (2) include a separate dynamic escape \nanalysis; (3) add un\u00adsound optimizations; (4) tune ROADRUNNER to better support one particular kind of \nanalysis; (5) implement these checkers directly on a JVM rather than on top of ROADRUNNER; (6) implement \nthe checkers inside the JVM itself (sacri.cing portability, maintainabil\u00adity, etc); or (7) at the extreme, \nimplement the checkers directly in hardware. These techniques would improve performance in ways that \nare orthogonal to the central contributions of this paper, and at the cost of additional complexity. \nIn order to present our results n the most consistent manner, we do not report on these complemen\u00adtary \noptimizations. Benchmark Con.guration. We performed experiments on 16 benchmarks: elevator, a discrete \nevent simulator for eleva\u00adtors [39]; hedc, a tool to access astrophysics data from Web sources [39]; \ntsp, a Traveling Salesman Problem solver [39]; mtrt, a multithreaded ray-tracing program from the SPEC \nJVM98 benchmark suite [35]; jbb, the SPEC JBB2000 business object simulator [35]; crypt, lufact, sparse, \nseries, sor, moldyn, montecarlo, and raytracer from the Java Grande benchmark suite [20]; the colt scienti.c \ncomputing library [6]; the raja ray tracer [18]; and philo, a dining philosophers simulation [14]. The \nJava Grande benchmarks were con.gured to use four worker threads and the largest data set provided (except \ncrypt, for which weusedthesmallestdatasetbecause BASICVC, DJIT+,and MUL-TIRACE ran out of memory on the \nlarger sizes). All experiments were performed on an Apple Mac Pro with dual 3GHz quad-core Pentium Xeon \nprocessors and 12GB of memory, running OS X 10.5.6 and Sun s Java HotSpot 64-bit Server VM version 1.6.0. \nAll classes loaded by the benchmark programs were instrumented, except those from the standard Java libraries. \nThe timing measurements include the time to load, instrument, and execute the target program, but it \nexcludes JVM startup time to reduce noise. The tools report at most one race for each .eld of each class, \nand at most one race for each array access in the program source code. Summary of Results. Table 1 lists \nthe size, number of threads, and uninstrumented running times for each program examined. All timing measurements \nare the average of 10 test runs. Variability across consecutive runs was typically less than 10%. The \nfour programs marked with * are not compute-bound, and we exclude these programs when computing average \nslowdowns. The Instrumented Time columns show the running times of each program under each of the tools, \nreported as the ratio to the uninstrumented running time. Thus, target programs ran 4.1 times slower, \non average, under the EMPTY tool. Most of this overhead is due to communicating all target program operations \nto the back\u00adend checker. For GOLDILOCKS, we include both measurements for ourownimplementationontopof \nROADRUNNER andperformance estimates for the original implementation [14], as discussed below. The variations \nin slowdowns for different programs that we ob\u00adserved in our experiments are not uncommon for dynamic \nrace con\u00addition checkers. Different programs exhibit different memory ac\u00adcess and synchronization patterns, \nsome of which will impact anal\u00adysis performance more than others. In addition, instrumentation can impact \ncache performance, class loading time, and other low-level JVM operations. These differences can sometimes \neven make an instrumented program run slightly faster than the uninstrumented (as in colt). The last \nsix columns show the number of warnings produced by each checker using the .ne grain analysis. All eight \nwarnings from FASTTRACK re.ect real race conditions. As reported pre\u00adviously [16, 28, 38, 39], some of \nthese are benign (as in tsp, mtrt, and jbb) but others can impact program behavior (as on the checksum \n.eld in raytracer and races on several .elds related to a thread pool in hedc). ERASER Comparison. The \nperformance results show that our re-implementation of ERASER incurs an overhead of 8.7x, which is competitive \nwith similar Eraser implementations built on top of unmodi.ed JVMs, such as [28]. Surprisingly, FASTTRACK \nis slightly faster than ERASER on some programs, even though it performs a precise analysis that traditionally \nhas been considered more expensive. More signi.cantly, ERASER reported many spurious warnings that do \nnot correspond to actual races.4 Augmenting our ERASER implementation to reason about additional synchronization \ncon\u00adstructs [30, 42] would eliminate some of these spurious warnings, but not all. On hedc, ERASER reported \na spurious warning and also missed two of the real race conditions reported by FASTTRACK, 4The total \nnumber of warnings is about three times higher if ERASER does not reason about barriers. Program Size \n(loc) Thread Count Base Time (sec) Instrumented Time (slowdown) Warnings EMPTY ERASER MULTIRACE GOLDILOCKSRRGOLDILOCKSKAFFE \nBASICVC DJIT+ FASTTRACK ERASER MULTIRACE GOLDILOCKS BASICVC DJIT+ FASTTRACK colt 111,421 11 16.1 0.9 \n0.9 0.9 1.8 2 0.9 0.9 0.9 3 0 0 0 0 0 crypt 1,241 7 0.2 7.6 14.7 54.8 77.4 84.4 54.0 14.3 0 0 0 0 0 \n0 lufact 1,627 4 4.5 2.6 8.1 42.5 8.5 95.1 36.3 13.5 4 0  0 0 0 moldyn 1,402 4 8.5 5.6 9.1 45.0 17.5 \n28.5 111.7 39.6 10.6 0 0 0 0 0 0 montecarlo 3,669 4 5.0 4.2 8.5 32.8 6.3 2.2 49.4 30.5 6.4 0 0 0 0 0 \n0 mtrt 11,317 5 0.5 5.7 6.5 7.1 6.7 8.3 7.1 6.0 1 1 1 1 1 1 raja 12,028 2 0.7 2.8 3.0 3.2 2.7 3.5 3.4 \n2.8 0 0 0 0 0 0 raytracer 1,970 4 6.8 4.6 6.7 17.9 32.8 146.8 250.2 18.1 13.1 1 1 1 1 1 1 sparse 868 \n4 8.5 5.4 11.3 29.8 64.1 57.5 27.8 14.8 0 0 0 0 0 0 series 967 4 175.1 1.0 1.0 1.0 1.0 1.1 1.0 1.0 1.0 \n1 0 0 0 0 0 sor 1,005 4 0.2 4.4 9.1 16.9 63.2 1.4 24.6 15.8 9.3 3 0 0 0 0 0 tsp 706 5 0.4 4.4 24.9 8.5 \n74.2 2.9 390.7 8.2 8.9 9 1 1 1 1 1 elevator* 1,447 5 5.0 1.1 1.1 1.1 1.1 1.1 1.1 1.1 0 0 0 0 0 0 philo* \n86 6 7.4 1.1 1.0 1.1 7.2 1 1.1 1.1 1.1 0 0 0 0 0 0 hedc* 24,937 6 5.9 1.1 0.9 1.1 1.1 3.3 1.1 1.1 1.1 \n2 1 0 3 3 3 jbb* 30,491 5 72.9 1.3 1.5 1.6 2.1 1.6 1.6 1.4 3 1  2 2 2 Average 4.1 8.6 21.7 31.6 24.2 \n89.8 20.2 8.5 27 5 3 8 8 8 Table 1: Benchmark Results. Programs marked with * are not compute-bound \nand are excluded when computing average slowdowns. Program Vector Clocks Allocated Vector Clock Operations \nDJIT+ FAST TRACK DJIT+ FAST TRACK colt 849,765 76,209 5,792,894 1,266,599 crypt 17,332,725 119 28,198,821 \n18 lufact 8,024,779 2,715,630 3,849,393,222 3,721,749 moldyn 849,397 26,787 69,519,902 1,320,613 montecarlo \n457,647,007 25 519,064,435 25 mtrt 2,763,373 40 2,735,380 402 raja 1,498,557 3 760,008 1 raytracer 160,035,820 \n14 212,451,330 36 sparse 31,957,471 456,779 56,553,011 15 series 3,997,307 13 3,999,080 16 sor 2,002,115 \n5,975 26,331,880 54,907 tsp 311,273 397 829,091 1,210 elevator 1,678 207 14,209 5,662 philo 56 12 472 \n120 hedc 886 82 1,982 365 jbb 109,544,709 1,859,828 327,947,241 64,912,863 Total 796,816,918 5,142,120 \n5,103,592,958 71,284,601 Table 2: Vector Clock Allocation and Usage. due to an (intentional) unsoundness \nin how the Eraser algorithm reasons about thread-local and read-shared data [33]. BASICVC and DJIT+ Comparison. \nDJIT+ and BASICVC re\u00adported exactly the same race conditions as FASTTRACK. That is, the three checkers \nall yield identical precision. In terms of perfor\u00admance, however, the results show that FASTTRACK signi.cantly \noutperforms the other checkers. In particular, it is roughly 10x faster than BASICVC and 2.3x faster \nthan DJIT+. These perfor\u00admance improvements are due primarily to the reduction in the allo\u00adcation and \nuse of vector clocks, as shown in Table 2. Over all the benchmarks, DJIT+ allocated more over 790 million \nvector clocks, whereas FASTTRACK allocated only 5.1 million. DJIT+ performed over 5.1 billion O(n)-time \nvector clock operations, while FAST-TRACK performed only 17 million. The memory overhead for stor\u00ading \nthe extra vector clocks leads to signi.cant cache performance degradation in some programs, particularly \nthose that perform ran\u00addom accesses to large arrays. MULTIRACE Comparison. MULTIRACE maintains DJIT+ \ns in\u00adstrumentation state, as well as a lock set for each memory loca\u00adtion [29]. The checker updates the \nlock set for a location on the .rst access in an epoch, and full vector clock comparisons are performed \nafter this lock set becomes empty. This synthesis sub\u00adstantially reduces the number of vector clock operations, \nbut in\u00adtroduces the overhead of storing and updating lock sets. In addi\u00adtion, the use of ERASER s unsound \nstate machine for thread-local and read-shared data leads to imprecision. In combination with a coarse-grain \nanalysis, this approach produced substantial perfor\u00admance improvement [29]. Our re-implementation of \nthe MULTIRACE algorithm in ROAD-RUNNER used .ne-grain analysis and exhibited performance com\u00adparable \nto DJIT+. Interestingly, over all benchmarks MULTIRACE performed less than half the number of VC operations \nas FAST-TRACK. However, this did not lead to speed-ups over DJIT+, be\u00adcause the memory footprint was \neven larger than DJIT+, leading to substantial cache performance degradation. Additionally, on aver\u00adage \nroughly 10% of all operations required an ERASER operation that also imposed some additional overhead. \nGOLDILOCKS Comparison. GOLDILOCKS [14] is a precise race detector that does not use vector clocks to \ncapture the happens\u00adbefore relation. Instead, it maintains, for each memory location, a set of synchronization \ndevices and threads. A thread in that set can safely access the memory location, and a thread can add \nitself to the set (and possibly remove others) by performing any of the operations described by the synchronization \ndevices in the set. GOLDILOCKS is a complicated algorithm that required 1,900 linesofcodetoimplementin \nROADRUNNER,ascomparedtofewer than 1,000 lines for each other tool. GOLDILOCKS also ideally re\u00adquires \ntight integration with the underlying virtual machine and, in particular, with the garbage collector, \nwhich is not possible un\u00adder ROADRUNNER. Both of these factors cause GOLDILOCKS to incur a high slowdown. \nAs shown in Table 1, GOLDILOCKS imple\u00admented in ROADRUNNER incurred a slowdown of 31.6x across our benchmarks \n(but ran out of memory on lufact), even when utilizing an unsound extension to handle thread-local data \nef.ciently. (This extension caused it to miss the three races in hedc found by other tools.) We believe \nsome performance improvements are possible, for both GOLDILOCKS and the other tools, by integration into \nthe virtual machine. As another data point, the original GOLDILOCKS study reported its slowdown for the \ncompute-intensive benchmarks in common Program Memory (MB) Memory Overhead Slowdown Fine Coarse Fine \nCoarse DJIT+ FAST TRACK DJIT+ FAST TRACK DJIT+ FAST TRACK DJIT+ FAST TRACK colt 36 4.3 2.4 2.0 1.8 0.9 \n0.9 0.9 0.8 crypta 41 44.3 10.5 1.2 1.2 54.0 14.3 6.6 6.6 lufactc 80 9.8 4.1 1.1 1.1 36.3 13.5 5.4 6.6 \nmoldynb 37 3.3 1.7 1.3 1.2 39.6 10.6 11.9 8.3 montecarlob 595 6.1 2.1 1.1 1.1 30.5 6.4 3.4 2.8 mtrt 51 \n3.9 2.2 2.6 1.9 7.1 6.0 8.3 7.0 raja 35 1.3 1.3 1.2 1.3 3.4 2.8 3.1 2.7 raytracerb 36 6.2 1.9 1.4 1.2 \n18.1 13.1 14.5 10.6 sparsec 131 23.3 6.1 1.0 1.0 27.8 14.8 3.9 4.1 seriesc 51 8.5 3.1 1.1 1.1 1.0 1.0 \n1.0 1.0 sorc 40 5.3 2.1 1.1 1.1 15.8 9.3 5.8 6.3 tsp 33 1.7 1.3 1.2 1.2 8.2 8.9 7.6 7.3 elevator* 32 \n1.2 1.2 1.2 1.2 1.1 1.1 1.1 1.1 philo* 32 1.2 1.2 1.2 1.2 1.1 1.1 1.1 1.1 hedc* 33 1.4 1.4 1.3 1.3 1.1 \n1.1 0.9 0.9 jbb* 236 4.1 2.4 2.3 1.9 1.6 1.4 1.3 1.3 Average 7.9 2.8 1.4 1.3 20.2 8.5 6.0 5.3 Table \n3: Comparison of Fine and Coarse Granularities. with this paper to be roughly 4.5x [14]. However, those \nresults are for a GOLDILOCKS implementation written in compiled C code inside the Kaffe Virtual Machine, \nand target programs were in\u00adterpreted by this modi.ed JVM.5 If GOLDILOCKS were imple\u00admented inside a \nJIT, then target programs would run signi.cantly faster, and so the GOLDILOCKS slowdown would appear \nlarger but would be more directly comparable to ROADRUNNER tools (in which both the target program and \nchecker are optimized by the JIT). To compensate for this effect, we estimated the corresponding GOLDILOCKS-JIT \nslowdown from the experimental results of [14] as: (Goldilocks-Time - Interpreted-Time)+ JIT-Time JIT-Time \nThat is, we compute the cost of the Goldilocks analysis based on the running times of the unmodi.ed Kaffe \ninterpreter and the Goldilocks-aware Kaffe interpreter, and then estimate the slow\u00addown that this overhead \nwould have on the running time of the tar\u00adget program in the Kaffe JIT. We include these estimates in \nTable 1 in the Kaffe column. They suggest the GOLDILOCKS slowdown on a JIT could be as high as 25x, which \nis close to our implemen\u00ad tation. In summary, GOLDILOCKS is an interesting algorithm but its complexity \nand JVM-integration issues make it dif.cult to imple\u00adment ef.ciently, and so GOLDILOCKS may not provide \nsigni.cant performance bene.ts over FASTTRACK. Analysis Granularity. Next, we investigate the effect \nof analy\u00adsis granularity on space and time overheads. Table 3 shows the memory requirements for each \nuninstrumented program, and the memory overhead factor and slowdown factor for DJIT+ and FASTTRACK, using \nboth .ne and course grain analyses. Mem\u00adory overhead is reported as the ratio of the maximum heap space \nused during analysis to the maximum heap space used under unin\u00adstrumented execution. The overall increase \nin heap usage can be smaller than the total size of allocated vector clocks because the garbage collector \ncollects vector clocks belonging to reclaimed objects. The memory overhead for the .ne-grain analysis \nis substantial (columns 3 and 4), since every .eld and array element requires a its own VarState object. \nHowever, FASTTRACK s memory requirements are substantially better than DJIT+ s because many 5 Some of \nthe JavaGrande benchmark programs were run on smaller data sets than we used, which could also impact \nrelative performance. fewer vector clocks are allocated. The coarse-grain analysis (col\u00adumn 5 and 6) \nreduces the memory overhead by roughly half for both checkers, and results in a roughly 50% speedup. \nThecoarse-grainanalysisdoescause FASTTRACK andtheother analyses to report spurious warnings on most of \nthe benchmarks. We could adaptively re.ne the granularity of the analysis for those objects for which \nthe coarse analysis generates warnings, either by iteratively running the checker under different levels \nof granular\u00adity [30] or by performing on-line adaptation [42] with some loss of precision. Our estimates \nsuggest that performing on-line adaptation in ROADRUNNER would yield performance close to the coarse\u00adgrain \nanalysis, but with some improvement in precision. 5.2 Analysis Composition Precise race condition information \ncan also signi.cantly improve the performance of other dynamic analyses. For example, atomicity checkers, \nsuch as ATOMIZER [16] and VELODROME [17], and determinism checkers, such as SINGLETRACK [32], can ignore \nrace-free memory accesses. To compose independent analyses, the ROADRUNNER com\u00admand line option: -tool \nFastTrack:Velodrome con.gures ROADRUNNER to feed the event stream from the target program to FASTTRACK, \nwhich .lters out race-free memory accesses from the event stream and passes all other events on to VELODROME.6 \nThe following table illustrates the improvement of ATOM-IZER, VELODROME and SINGLETRACK under .ve different \n.lters: NONE, which shows the slowdown of these tools over the original, uninstrumented benchmark programs; \nTL, which .lters out only accesses to thread-local data; ERASER; DJIT+; and FASTTRACK. FASTTRACK signi.cantly \nimproves the performance of these tools, because their rather complex analyses can avoid analyzing poten\u00adtially \nmillions of uninteresting, race-free data accesses. The slow\u00addowns reported are the average slowdown \nfor our compute-bound benchmarks. Checker Slowdown for Pre.lters NONE TL ERASER DJIT+ FAST TRACK ATOMIZER \nVELODROME SINGLETRACK 57.2 57.9 104.1 16.8 27.1 55.4 7 14.9 32.7 17.5 19.6 19.7 12.6 11.3 11.7  6Note \nthat FASTTRACK (and other tools) may .lter out a memory access that is later determined to be involved \nin a race condition; thus this opti\u00admization may involve some small reduction in coverage.  5.3 Checking \nEclipse for Race Conditions To validate FASTTRACK in a more realistic setting, we applied it to the Eclipse \ndevelopment environment, version 3.4.0 [13]. We modi.ed two lines of source code to report the time to \nperform each user-initiated operation but made no other modi.cations. We used Sun s Java 1.5.0 HotSpot \nClient VM because our test platform must run Eclipse as a 32-bit application with a maximum heap size \nof 2GB. We performed experiments with the following .ve Eclipse op\u00aderations: Startup: Launch Eclipse \nand load a workspace containing four projects with 65,000 lines of code. Import: Import and perform an \ninitial build on a project containing 23,000 lines of code. Clean Small: Rebuild a workspace with four \nprojects containing a total of 65,000 lines of code. Clean Large: Rebuild a workspace with one project \ncontaining 290,000 lines of code. Debug: Launch the debugger and run a small program that imme\u00addiately \nthrows an exception. Operation Base Time (sec) Instrumented Time (Slowdown) EMPTY ERASER DJIT+ FAST TRACK \nStartup Import Clean Small Clean Large Debug 6.0 2.5 2.7 6.5 1.1 13.0 7.6 14.1 17.1 1.6 16.0 14.9 16.7 \n17.9 1.7 17.3 17.1 24.4 38.5 1.7 16.0 13.1 15.2 15.4 1.6 For these tests, FASTTRACK loaded and instrumented \nroughly 6,000 classes corresponding to over 140,000 lines of source code. Several classes using re.ection \nwere not instrumented to avoid current limitations of ROADRUNNER, but these classes did not involve interesting \nconcurrency. Native methods were also not in\u00adstrumented. Eclipse used up to 24 concurrent threads during \nthese tests. Eclipse startup time was heavily impacted by the bytecode in\u00adstrumentation process, which \naccounted for about 75% of the ob\u00adserved slowdowns. While ROADRUNNER does not currently sup\u00adport off-line \nbytecode instrumentation, that feature would remove a substantial part of startup time. FASTTRACK performed \nquite well on the three most compute-intensive tests (Import, Clean Small, and Clean Large), exhibiting \nperformance better than DJIT+ and comparable to ERASER. Monitoring the Debug test incurred less overhead \nfor all tools because that test spent much of its time start\u00ading up the target VM and switching views \non the screen. ERASER reported potential races on 960 distinct .eld and ar\u00adray accesses for these .ve \ntests, largely because Eclipse uses many synchronization idioms, such as wait/notify, semaphores, readers\u00adwriter \nlocks, etc. that ERASER cannot handle. Additional exten\u00adsions [42] could handle some of these cases. \nFASTTRACK reported 30 distinct warnings. While we have not been able to fully verify the correctness \nof all code involved in these races, none caused major failures or data corruption during our tests. \nThey include: Races on an array of nodes in a tree data structure implemen\u00adtation. We believe these races \ncan cause null pointer exceptions under Java s non-sequentially consistent memory model. 7Since ATOMIZER \nalready uses ERASER to identify potential races inter\u00adnally, it would not be meaningful to add it as \na pre.lter. Races on .elds related to progress meters that may cause incor\u00adrect information to be displayed \nbrie.y.  An instance of double-checked locking in the code to read .les for compilation units from disk \nthat, while benign, adds signi.cant complexity to the code.  Benign races on array entries used to communicate \nvalues from helper threads back to their parents, and in the initialization code in the debugger for \nmonitoring input and output streams.  DJIT+ reported 28 warnings. These overlapped heavily with those \nreported by FASTTRACK, but scheduling differences led to several being missed and several new (benign) \nraces being identi.ed. The items listed above were reported by both tools. Although our exploration of \nEclipse is far from complete, these preliminary observations are quite promising. FASTTRACK is able to \nscale to precisely check large applications with lower run-time and memory overheads than existing tools. \n6. Related Work Much prior work has focused on dynamic analyses to detect race conditions. In addition \nto the dynamic race detectors discussed earlier, a variety of alternative approaches have been explored. \nEraser s LockSet algorithm [33] has been re.ned to eliminate false positives, reduce overhead, and handle \nadditional synchronization idioms, as in [38, 27]. Some race detectors have combined Eraser s LockSet \nalgo\u00adrithm with happens-before reasoning (e.g., for analyzing barriers and fork-join synchronization), \nwith good results. RaceTrack [42], for example, uses happens-before information to approximate the set \nof threads concurrently accessing memory locations. An empty lock set is only considered to re.ect a \npotential race if the happens\u00adbefore analysis indicates that the corresponding location is ac\u00adcessed \nconcurrently by multiple threads. MultiRace [30], as de\u00adscribed above, also falls into this category. \nWhile these analyses reduce the number of false alarms, they cannot eliminate them com\u00adpletely. Other \napproaches have combined dynamic analysis with a global static analysis to improve precision and performance \n[8, 14, 39]. TRaDE [11] is a precise race detector based on a dynamic es\u00adcape analysis and accordion \nclocks [10], a technique that reduces the space overhead of vector clocks for applications with many \nshort-lived threads. Unlike FASTTRACK, TRaDE is implemented inside the HotSpot virtual machine interpreter, \nand so the target program is interpreted while the instrumentation code is compiled, making it dif.cult \nto compare results directly. However, for the two benchmarks (colt and raja) common to both papers, FAST-TRACK \nis several times faster. We expect the TRaDE innovations (dynamic escape analysis and accordion clocks) \nto further improve FASTTRACK s performance. In addition to on-the-.y analyses that monitor and report \nraces as a program runs, other techniques record program events for post\u00admortem race identi.cation (see, \nfor example, [9, 2, 31]). These approaches, however, might be dif.cult to use for long-running programs. \nDynamic race detectors have also been developed for other settings, including for nested fork-join parallelism \n[24]. Many static analysis techniques for identifying races have also been explored. While static race \ndetection provides the potential to detect all race conditions over all program paths, decidability limitations \nimply that, for all realistic programming languages, any sound static race detector is incomplete and \nmay produce false alarms. Warlock [36] was an early static race detector system for ANSI C programs for \nreasoning about lock-based synchronization. Type systems for identifying race conditions have been developed \nfor various languages, including Java [1, 5, 3] and Cyclone, a statically safe variant of C [19]. Aiken \nand Gay [4] investigate static race detection in the context of SPMD programs. A variety of other approaches \nhave also been developed, including model checking [7, 41, 25] and data.ow analysis [12, 15], as well \nas scalable whole-program analyses [26, 40]. 7. Conclusions Race conditions are notoriously dif.cult \nto debug. Precise race de\u00adtectors avoid the programmer-overhead of identifying and elimi\u00adnating spurious \nwarnings, which are particularly problematic on large programs with complex synchronization. FASTTRACK \nis a new precise race detection algorithm that achieves better perfor\u00admance than existing algorithms \nby tracking less information and dynamically adapting its representation of the happens-before re\u00adlation \nbased on memory access patterns. The FASTTRACK algo\u00adrithm and adaptive epoch representation is also straightforward \nto implement, and may be useful in other dynamic analyses for mul\u00adtithreaded software. Acknowledgments \nThis work was supported in part by NSF Grants 0341179, 0341387, 0644130, and 0707885. We thank Ben Wood \nfor comments on a draft of this paper. We also thank Tayfun Elmas, Shaz Qadeer, and Serdar Tasiran for \nhelping us to understand the performance of Goldilocks. The proof structure in the Appendix was adapted \nfrom techniques developed by Caitlin Sadowski for the SINGLETRACK determinism checker [32]. References \n[1] M. Abadi, C. Flanagan, and S. N. Freund. Types for safe locking: Static race detection for Java. \nTOPLAS, 28(2):207 255, 2006. [2] S. V. Adve, M. D. Hill, B. P. Miller, and R. H. B. Netzer. Detecting \ndata races on weak memory systems. In ISCA, pages 234 243, 1991. [3] R. Agarwal and S. D. Stoller. Type \ninference for parameterized race-free Java. In VMCAI, pages 149 160, 2004. [4] A. Aiken and D. Gay. Barrier \ninference. In POPL, pages 243 354, 1998. [5] C. Boyapati and M. Rinard. A parameterized type system for \nrace-free Java programs. In OOPSLA, pages 56 69, 2001. [6] CERN. Colt 1.2.0. Available at http://dsd.lbl.gov/\u00ad~hoschek/colt/, \n2007. [7] A. T. Chamillard, L. A. Clarke, and G. S. Avrunin. An empirical comparison of static concurrency \nanalysis techniques. Technical Report 96-084, Department of Computer Science, University of Massachusetts \nat Amherst, 1996. [8] J.-D. Choi, K. Lee, A. Loginov, R. O Callahan, V. Sarkar, and M. Sridhara. Ef.cient \nand precise datarace detection for multi\u00adthreaded object-oriented programs. In PLDI, pages 258 269, 2002. \n[9] J.-D. Choi, B. P. Miller, and R. H. B. Netzer. Techniques for debugging parallel programs with .owback \nanalysis. TOPLAS, 13(4):491 530, 1991. [10] M. Christiaens and K. D. Bosschere. Accordion clocks: Logical \nclocks for data race detection. In Euro-Par, pages 494 503, 2001. [11] M. Christiaens and K. D. Bosschere. \nTRaDe: Data Race Detection for Java. In International Conference on Computational Science, pages 761 \n770, 2001. [12] M. B. Dwyer and L. A. Clarke. Data .ow analysis for verifying properties of concurrent \nprograms. Technical Report 94-045, Department of Computer Science, University of Massachusetts at Amherst, \n1994. [13] The Eclipse programming environment, version 3.4.0. Available at http://www.eclipse.org, 2009. \n[14] T. Elmas, S. Qadeer, and S. Tasiran. Goldilocks: A race and transaction-aware Java runtime. In PLDI, \npages 245 255, 2007. [15] D. R. Engler and K. Ashcraft. RacerX: Effective, static detection of race conditions \nand deadlocks. In SOSP, pages 237 252, 2003. [16] C. Flanagan and S. N. Freund. Atomizer: A dynamic atomicity \nchecker for multithreaded programs. Sci. Comput. Program., 71(2):89 109, 2008. [17] C. Flanagan, S. N. \nFreund, and J. Yi. Velodrome: A sound and complete dynamic atomicity checker for multithreaded programs. \nIn PLDI, pages 293 303, 2008. [18] E. Fleury and G. Sutre. Raja, version 0.4.0-pre4. Available at http://raja.sourceforge.net/, \n2007. [19] D. Grossman. Type-safe multithreading in Cyclone. In TLDI, pages 13 25, 2003. [20] Java Grande \nForum. Java Grande benchmark suite. Available at http://www.javagrande.org/, 2008. [21] L. Lamport. Time, \nclocks, and the ordering of events in a distributed system. Commun. ACM, 21(7):558 565, 1978. [22] J. \nManson, W. Pugh, and S. V. Adve. The Java memory model. In POPL, pages 378 391, 2005. [23] F. Mattern. \nVirtual time and global states of distributed systems. In Workshop on Parallel and Distributed Algorithms, \n1988. [24] J. M. Mellor-Crummey. On-the-.y detection of data races for programs with nested fork-join \nparallelism. In Supercomputing, pages 24 33, 1991. [25] M. Musuvathi, S. Qadeer, T. Ball, G. Basler, \nP. A. Nainar, and I. Neamtiu. Finding and reproducing heisenbugs in concurrent programs. In OSDI, 2008. \n[26] M. Naik, A. Aiken, and J. Whaley. Effective static race detection for Java. In PLDI, pages 308 319, \n2006. [27] H. Nishiyama. Detecting data races using dynamic escape analysis based on read barrier. In \nVirtual Machine Research and Technology Symposium, pages 127 138, 2004. [28] R. O Callahan and J.-D. \nChoi. Hybrid dynamic data race detection. In PPOPP, pages 167 178, 2003. [29] E. Pozniansky and A. Schuster. \nEf.cient on-the-.y data race detection in multihreaded C++ programs. In Proceedings of the ACM Symposium \non Principles and Practice of Parallel Programming, pages 179 190, 2003. [30] E. Pozniansky and A. Schuster. \nMultiRace: Ef.cient on-the-.y data race detection in multithreaded C++ programs. Concurrency and Computation: \nPractice and Experience, 19(3):327 340, 2007. [31] M. Ronsse and K. D. Bosschere. RecPlay: A fully integrated \npractical record/replay system. TCS, 17(2):133 152, 1999. [32] C. Sadowski, S. N. Freund, and C. Flanagan. \nSingleTrack: A dynamic determinism checker for multithreaded programs. In ESOP, 2009. [33] S. Savage, \nM. Burrows, G. Nelson, P. Sobalvarro, and T. E. Anderson. Eraser: A dynamic data race detector for multi-threaded \nprograms. TOCS, 15(4):391 411, 1997. [34] E. Schonberg. On-the-.y detection of access anomalies. In PLDI, \npages 285 297, 1989. [35] Standard Performance Evaluation Corporation. SPEC benchmarks. http://www.spec.org/, \n2003. [36] N. Sterling. Warlock: A static data race analysis tool. In USENIX Winter Technical Conference, \npages 97 106, 1993. [37] Sun Microsystems. The java.util.concurrent package. Available at http://java.sun.com/javase/6/docs/api/, \n2008. [38] C. von Praun and T. Gross. Object race detection. In OOPSLA, pages 70 82, 2001.  [39] C. \nvon Praun and T. Gross. Static con.ict analysis for multi-threaded object-oriented programs. In PLDI, \npages 115 128, 2003. [40] J. W. Voung, R. Jhala, and S. Lerner. Relay: static race detection on millions \nof lines of code. In FSE, pages 205 214, 2007. [41] E. Yahav. Verifying safety properties of concurrent \nJava programs using 3-valued logic. In POPL, pages 27 40, 2001. [42] Y. Yu, T. Rodeheffer, and W. Chen. \nRaceTrack: Ef.cient detection of data race conditions via adaptive tracking. In SOSP, pages 221 234, \n2005. A. FastTrack Correctness Proofs For a transition sa .a sa. , by convention the elements in state \nsa are named Ca , La , Ra, and W a, and the elements in state sa . are C\u00b4a L\u00b4a \u00b4\u00b4 named , , Ra, and W \na. We interpret each epoch as a function from threads to clocks: c@t . (.u. if t = u then c else 0) This \ninterpretation allows us to overload the function application operator to also apply to the W and R components \nof the state. DEFINITION 1 (Well-Formed States). A state s = .C, L, R, W . is well-formed if 1. for all \nu, t . Tid, if t . = u then Cu(t) <Ct(t), 2. for all m . Lock,t . Tid, Lm(t) <Ct(t), 3. for all x . \nVar,t . Tid, Rx(t) = Ct(t), 4. for all x . Var,t . Tid, Wx(t) = Ct(t).  LEMMA 1. s0 is well-formed. \nLEMMA 2 (Preservation of Well-Formedness). If s is well-formed and s .a s. then s. is well-formed. LEMMA \n3 (Clocks Imply Happens-Before). Suppose sa is well\u00ad .a.a formed and sa sb .b sb. . Let t = tid(a) and \nu = tid(b). If Cta(t) = Cub (t) then a<a.a.b b. PROOF If t = u then a<a.a.b b by program order. Otherwise \nassume t .u, and the proof proceeds by induction on the length = of a. Since sa is well-formed, Cua(t) \n<Cta(t) = Cub (t) (Here, Cua denotes the clock vector for the thread u in the pre-state of operation \na.) Hence there must be some operation d . a.a that increases the Cu(t) component of the analysis state. \nThus: d db Ca \u00b4 u (t) = Cu(t) <Cta(t) = Cu(t) = Cu(t) Since d increases the Cu(t) component of the analysis \nstate, it must be one of fork(v, u), join(u, v), or acq(u, m). We illustrate the case for d = join(u, \nv). In this case: Cta(t) = C\u00b4 ud(t) from above = max(Cud(t),Cvd(t)) by [FT JOIN] = Cvd(t) as Cud(t) <Cta(t) \nIf e is the last operation by v that appears before d in a.a, then Cvd(t)= Cve(t), and so a<a.a.b e<a.a.b \nd<a.a.b b by induction, fork-join order, and program order, respectively. Note that if there is no v-operation \nbefore d in a.a then no operation increases the Cv(t) component of the state, and so we obtain the contradiction \nthat Cva(t) .<Cta(t). THEOREM 2 (Soundness). If s0 .a s. then a is race-free. PROOF Suppose a has a \nrace condition, and thus contains an operation a followed by a later operation b where a con.icts with \nb and a . <a b. The proof proceeds by lexicographic induction on the length of a, and on the number of \nintervening operations between a and b. Without loss of generality, we assume the pre.x of a before b \nis race-free, and that b is not in a race with any operation in a before a. Let t = tid(a) and u = tid(b). \nClearly t .u. By = Lemma 3, Cta(t) >Cub (t). We illustrate the argument for a = wr(t, x) and b = rd(u, \nx). If the rule for b is [FT READ SAME EPOCH], then there must have been a preceding read d = rd(u, x). \nIf d is after a, then by induction a<a d<a b. If d is before a, then since d and b are in the same epoch, \nthere can be no intervening fork or release operations by thread u (as those increase Cu(u) and so change \nthe epoch) and hence d . <a a, and so there is an earlier race condition in this trace. Otherwise, if \nthe rule for b is not [FT READ SAME EPOCH], then W \u00b4 a (Cta(t))@t = by [FT WRITE ... ] = W b as no intervening \nwrites to x . Cb by [FT READ ... ] Hence Cta(t) = Cub (t), and so we have a contradiction. We introduce \nthe abbreviation: j C\u00b4a if a a join or acquire operation Ka = Ca otherwise LEMMA 4. Suppose s is well-formed \nand s .a s. and a, b . a. Let t = tid(a) and u = tid(b). If a<a b then Ka(t) . Kb(u). PROOF By induction \non the derivation of a<a b. We choose to use a happens-before derivation that applies program-order in \npreference to other rules wherever possible. . THEOREM 3 (Completeness). If a is race-free then s0 .a \ns. PROOF Suppose a = \u00df.a.. such that operation a is stuck, that is: s0 .\u00df s. ..a \u00b7\u00b7\u00b7 We consider all \npossible operations for a that could get stuck, and illustrate the argument for a = rd(t, x). If this \nread is stuck, then Wxa .. Cta. We consider the last write b = wr(u, x) preceding a. In all cases, b \n\u00b4 b (Cu(u))@u = Wx = Wxa .. Cta Hence Kub (u)= Cub (u) .= Cta(u)= Kta(u) By Lemma 4, b .<a a, and so \na has a write-read race condition.  \n\t\t\t", "proc_id": "1542476", "abstract": "<p>\\begin{abstract}</p> <p>Multithreaded programs are notoriously prone to race conditions. Prior work on dynamic race detectors includes fast but imprecise race detectors that report false alarms, as well as slow but precise race detectors that never report false alarms. The latter typically use expensive vector clock operations that require time linear in the number of program threads.</p> <p>This paper exploits the insight that the full generality of vector clocks is unnecessary in most cases. That is, we can replace heavyweight vector clocks with an adaptive lightweight representation that, for almost all operations of the target program, requires only constant space and supports constant-time operations. This representation change significantly improves time and space performance, with no loss in precision.</p> <p>Experimental results on Java benchmarks including the Eclipse development environment show that our <sc>FastTrack</sc> race detector is an order of magnitude faster than a traditional vector-clock race detector, and roughly twice as fast as the high-performance DJIT+ algorithm. <sc>FastTrack</sc> is even comparable in speed to <sc>Eraser</sc> on our Java benchmarks, while never reporting false alarms.</p>", "authors": [{"name": "Cormac Flanagan", "author_profile_id": "81100538763", "affiliation": "University of California at Santa Cruz, Santa Cruz, CA, USA", "person_id": "P1464253", "email_address": "", "orcid_id": ""}, {"name": "Stephen N. Freund", "author_profile_id": "81100165065", "affiliation": "Williams College, WIlliamstown, MA, USA", "person_id": "P1464254", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542490", "year": "2009", "article_id": "1542490", "conference": "PLDI", "title": "FastTrack: efficient and precise dynamic race detection", "url": "http://dl.acm.org/citation.cfm?id=1542490"}