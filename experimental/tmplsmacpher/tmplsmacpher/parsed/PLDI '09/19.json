{"article_publication_date": "06-15-2009", "fulltext": "\n ProgramVeri.cation usingTemplatesoverPredicate Abstraction * Saurabh Srivastava Sumit Gulwani Universityof \nMaryland, CollegePark Microsoft Research, Redmond saurabhs@cs.umd.edu sumitg@microsoft.com Abstract We \naddress the problem of automatically generating invariants with quanti.ed and boolean structure for proving \nthe validity of given assertions or generating pre-conditions under which the as\u00adsertions arevalid.We \npresent three novel algorithms,having dif\u00adferent strengths, that combine template and predicate abstraction \nbased formalisms to discover required sophisticated program in\u00advariants using SMT solvers. Two of these \nalgorithms use an iterative approach to compute .xed-points (one computes a least .xed-point and the \nother com\u00adputes a greatest .xed-point), while the third algorithm uses a con\u00adstraintbased approachto \nencodethe.xed-point.Thekeyideainall these algorithms is to reduce the problem of invariant discovery \nto that of .nding optimal solutions for unknowns (over conjunctions of some predicatesfromagivenset)inatemplate \nformulasuchthat the formula is valid. Preliminary experiments using our implementation of these al\u00adgorithmsshow \nencouraging resultsovera benchmarkof smallbut complicated programs. Our algorithms can verify program \nproper\u00adties that, to our knowledge, have not been automatically veri.ed before. In particular, our algorithms \ncan generate full correctness proofs for sorting algorithms (which requires nested universally\u00adexistentially \nquanti.ed invariants) and can also generate precondi\u00adtions requiredto establishworst-case upper boundsof \nsorting algo\u00adrithms. Furthermore, for the case of previously considered proper\u00adties, in particular sortedness \nin sorting algorithms, our algorithms take less time than reported by previous techniques. Categories \nand Subject Descriptors F.3.1[Logics and Mean\u00adings of Programs]: Specifying andVerifying and Reasoning \nabout Programs Invariants, Logics of Programs, Mechanical Veri.ca\u00adtion, Pre-and Post-conditions; F.3.2[Logics \nand Meanings of Pro\u00adgrams]: Semantics of Programming Languages Program Analy\u00adsis; D.2.4[SoftwareEngineering]:Software/ProgramVeri.cation \nCorrectness Proofs,Formal Methods General Terms Languages,Veri.cation, Theory, Algorithms Keywords Predicate \nabstraction, Quanti.ed Invariants,Template Invariants, Iterative Fixed-point, Constraint-based Fixed-point, \nWeakest Preconditions, SMT Solvers. * Theworkwas supportedin partby CCF-0430118 andin part done during \nan internship at Microsoft Research. Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage.To copyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. Copyright c &#38;#169; 2009ACM 978-1-60558-392-1/09/06... \n$5.00. 1. Introduction There has been a traditional trade-offbetween automation and pre\u00adcision for the \ntask of program veri.cation. At one end of the spec\u00adtrum, we have fully automated techniques like data-.ow \nanaly\u00adsis [19], abstract interpretation [5] and model checking [8] that can perform iterative .xed-point \ncomputationover loops,but are lim\u00adited in the kind of invariants that theycan discover. At the other \nend, wehave approaches basedonveri.cation condition generationthat can be used to establish sophisticated \nproperties of a program us\u00ading SMT solvers [25, 32],but require the programmer to provide all the sophisticated \nproperties along with loop invariants, which are usually even more sophisticated. The former approach \nenjoys the bene.t of complete automation, while the latter approach en\u00adjoys the bene.t of leveraging \nthe engineering and state-of-the-art advances that are continually being made in SMT solvers. In this \npaper, we explore the middle ground, wherein we show how to use SMT solvers as black-boxes to discover \nsophisticated induc\u00adtiveloopinvariants,usingonlya littlehelpfromthe programmerin the form of templates \nand predicates. We take inspiration from recent work on template-based pro\u00adgram analysis [26, 27, 4, \n18, 1, 13, 12, 14] that has shown promise in discovering invariants that are beyond the reach of fully\u00adautomated \ntechniques. The programmer provides hints in the form of a set of invariant templates with holes/unknowns \nthat are then automatically .lled in by the analysis. However, most of existing work in this area has \nfocused on quanti.er-free numerical invari\u00adants and depends on specialized non-linear solvers to .nd \nsolutions to the unknowns. In contrast, we focus on invariants that are useful for a more general class \nof programs. In particular, we consider in\u00advariants with arbitrarybut pre-speci.ed logical structure(involving \ndisjunctions and universal and existential quanti.ers) over a given set of predicates. One of the key \nfeatures of our template-based approach is that it uses the standard interface to an SMT solver, al\u00adlowing \nit to go beyond numerical properties and leverage ongoing advances in SMT solving. Our templates consist \nof formulas with arbitrarylogical struc\u00adture (quanti.ers, boolean connectives) and unknowns that take \nval\u00adues over some conjunction of a given set of predicates (Section 2). Such a choice of templates puts \nour work in an unexplored space in the area of predicate abstraction, which has been highly success\u00adful \nin expressing useful non-numerical and disjunctive properties of programs. The area was pioneered by \nGraf and Se\u00a8idi [10], who showed how to compute quanti.er-free invariants (over a given set of predicates). \nLater, strategies were proposed to discover univer\u00adsally quanti.ed invariants [9, 21, 17] and disjunctions \nof univer\u00adsally quanti.ed invariants in the context of shape analysis [22]. Our work extends the .eld \nby discovering invariants that involve an ar\u00adbitrary (but pre-speci.ed) quanti.ed structure over a given \nset of predicates. Since the domain is .nite, one can potentially search over all possible solutions,but \nthis naive approachwouldbe infea\u00adsible.  (a) InsertionSort(Array A, int n) 1 i := 1; 2 while (i<n) 3 \nj := i - 1; val := A[i]; 4 while (j = 0 . A[j] > val) 5 A[j + 1] := A[j]; 6 j := j - 1; 7 A[j + 1] := \nval; 8 i := i +1; 9 Assert(.y.x : (0 = y<n) 10 . (A [y]= A[x] . 0 = x<n)) User Input: InvariantTemplate: \nv1 . (.y : v2 . v3) . (.y.x : v4 . v5) Predicate Set: AllPreds({x, y, i, j, n}, {0, \u00b11}, {=, =, . =}) \nAllPreds({val,A[t],A[t] | t .{i, j, x, y, n}}, {0}, {=})  Tool Output:Proof of validity of assertion: \nOuter Loop Invariant: .y :(i = y<n) . (A [y]= A[y]) . .y.x : (0 = y<i) . (A [y]= A[x] . 0 = x<i) Inner \nLoop Invariant: val = A[i] .-1 = j<i . .y :(i<y<n) . A [y]= A[y] . .y.x : (0 = y<i) . (A [y]= A[x] . \n0 = x = i . x= j + 1)  (b) SelectionSort(Array A, int n) 1 i := 0; 2 while (i<n - 1) 3 min := i; j := \ni +1; 4 while (j<n) 5 if (A[j] <A[min]) min := j; 6 j := j +1; 7 Assert(i= min); 8 if A[i] and A[min]; \n(i= min) swap 9 i := i +1;  User Input: InvariantTemplate: v0 . (.k : v1 . v2) . (.k : v3 . v4) . (.k1,k2 \n: v5 . v6) Predicate Set: AllPreds({k, k1,k2, i, j, min,n}, {0, 1}, {=, =,>}) . AllPreds({A[t] | t .{k, \nk1,k2, i, j, min,n}}, {0, 1}, {=, =}) Tool Output:Assertion valid under following precondition. Precondition \nRequired: .k : (0 = k<n - 1) . A[n - 1] <A[k] .k1,k2 : (0 = k1 <k2 <n - 1) . A[k1] <A[k2] Outer Loop \nInvariant: .k1,k2 :(i = k1 <k2 <n - 1) . A[k1] <A[k2] .k : i = k<n - 1 . A[n - 1] <A[k] Inner Loop Invariant: \n.k1,k2 :(i = k1 <k2 <n - 1) . A[k1] <A[k2] .k :(i = k<n - 1) . A[n - 1] <A[k] j>i . i<n - 1 ..k :(i = \nk<j) . A[min] = A[k] Figure 1. (a)Verifying that Insertion Sort preserves all its input elements(b) \nGeneratinga precondition under which Selection Sortexhibits its worst-case number of swaps. (For anyset \nof program variables Z, any constants C and anyrelational operators R, we use the notation AllPreds(Z, \nC, R) to denote the set of predicates {z - z' op c, z op c | z, z' . Z, c . C, op . R}.) We therefore \npresent three novel algorithms for ef.ciently dis\u00adcovering inductive loop invariants that prove the validity \nof asser\u00adtions in a program, given a suitable set of invariant templates and a set of predicates. Two \nof these algorithms use standard iterative techniques for computing .xed-point as in data-.owanalysis \nor ab\u00adstract interpretation. One of them performs a forward propagation offacts and computesa least .xed-point, \nand then checks whether thefacts discovered imply the assertion or not (Section 4.1). The other algorithm \nperformsa backward propagationoffacts starting from the given assertion and checks whether the precondition \ndis\u00adcovered is true or not (Section 4.2). The third algorithm uses a constraint-based approach to encode \nthe .xed-point as a SATfor\u00admula such that a satisfying assignment to the SAT formula maps back to a proof \nof validity for the assertion (Section 5). The worst\u00adcase complexityof these algorithmsisexponentialonlyinthe \nmax\u00adimum number of unknowns at twoneighboring points as opposed to being exponential in the total number \nof unknowns at all program points for the naive approach. Additionally, in practice we have found them \nto be ef.cient and having complementary strengths (Section 7). Thekeyoperationin these algorithmsis thatof \n.nding optimal solutions for unknownsina template formulasuchthatthe formula is valid (Section 3). The \nunknowns take values that are conjunc\u00adtions of some predicates from a given set of predicates, and can \nbe classi.ed as either positive or negative depending on whether re\u00adplacing them by a stronger or weaker \nset of predicates makes the formula stronger or weaker respectively. We describe an ef.cient, systematic, \nsearch process for .nding optimal solutions to these un\u00adknowns. Our search process uses the observation \nthata solution for a positive (or negative) unknown remains a solution upon addition (or deletion) of \nmore predicates. Oneofthekeyaspectsof our algorithmsisthattheycanbe eas\u00adilyextendedto discover maximally-weak \npreconditions1 that ensure 1Aprecondition is maximally-weak if no other strictly weaker precondition \nexists in the template that also ensures the validity of the assertions. validity of given assertions. \nThis is unlike most invariant gener\u00adation tools that cannot be easily extended to generate (weak) pre\u00adconditions. \nAutomatic precondition generation not only reduces the annotationburdenonthe programmerintheusualcase,butcanalso \nhelp identify preconditions that are not otherwise intuitive. This paper makes the following contributions: \n We present a template based formalism to discover invariants with arbitrary (but pre-speci.ed) logical \nstructure over a given set of predicates.  We present three novel .xed-point computation algorithms, \neach having different strengths, given a set of templates and predicates.Two iteratively propagatefacts \nand one encodes the .xed-point as a constraint.  We show how to generate maximally-weak preconditions \nfor ensuring the validity of assertions that hold only under certain preconditions.  We present preliminary \nexperimental evidence that these algo\u00adrithms can verify (using off-the-shelf SMT solvers) program properties \nnot automatically veri.ed before. Theyalso take less time than previously reported for properties analyzed \nbeforeby alternate techniques.We also compare the propertiesof our al\u00adgorithms against each other.  \n 1.1 Motivating Examples Checking Validity of Assertions Consider, for example, the in\u00adplace InsertionSort \nroutine in Figure 1(a) that sorts an array A of length n. The assertion at Line 9 asserts that no elements \nin array A are lost, i.e., the array A at the end of the procedure contains all elements from array A \n, where A refers to the state of array A at the beginning of the procedure. The assertion as well as \nthe loop invariants required to prove it are .. quanti.ed, and we do not know of anyautomated tool that \ncan automatically discover such invariants for array programs. In this case, the user can easily guess \nthat the loop invariants would require a .. structure to prove the assertion on Line 9. Ad\u00additionally, \nthe user needs to guess that an inductive loop invariant may requirea . fact(to capture somefact about \narray elements)and a quanti.ed-free fact relating non-array variables. The quanti.ed facts contain an \nimplication as is there in the .nal assertion. The user also needs to provide the set of predicates. \nIn this case, the set consisting of inequality and disequality comparisons between terms (variablesandarray \nelementsthatareindexedbysomevariable)of appropriatetypessuf.ces.This choiceof predicatesisquite natural \nand has been used in several works based on predicate abstraction. Given these user inputs, our tool \nthen automatically discovers the non-trivial loop invariants mentioned in the .gure.  Our tool eases \nthe task of validating the assertion by requiring the user to only provide a template in which the logical \nstructure has been made explicit, and provide some over-approximation of the set of predicates. Guessing \nthe template is a much easier task than providing the precise loop invariants, primarily because these \ntemplates are usually uniform across the program and depend on the kind of properties to be proved. Precondition \nGeneration Consider, for example, the in-place SelectionSort routine in Figure 1(b) that sorts an array \nA of length n. Using bound analysis [11], it is possible to prove that the worst-case numberof arrayswapsforthisexampleis \nn - 1. On the other hand, suppose we want to verify that the worst-case number of swaps, n - 1, canindeedbe \nachievedby some input instance. This problem can be reduced to the problem of validating the as\u00adsertion \nat Line 7. If the assertion holds then the swap on Line8is always executed, which is n - 1 times. However, \nthis assertion is not valid without an appropriate precondition (e.g., consider a fully sorted array \nwhen the swap happensin no iteration).Wewant to generate a precondition that does not impose anyconstraints \non n while allowing the assertion to be valid this would provide a proof that SelectionSort indeed admits \na worst-case of n - 1 array swaps. In this case, the user can easily guess that a quanti.ed fact (.k1,k2 \nthat compares the elements at locations k1 and k2)cap\u00adturing some sortedness property will be required. \nHowever, this alone is not suf.cient. The user can then iteratively guess and add templates until a precondition \nis found. (The process can probably be automated.)Two additional quanti.edfacts and an unquanti.ed fact \nsuf.ce in this case. The user also supplies a predicate set con\u00adsisting of inequality and disequality \ncomparisons between terms of appropriate type. The non-trivial outputof ourtoolis shownin the .gure. \nOur tool automatically infers the maximally-weak precondition that the input array should be sorted from \nA[0] to A[n - 2], while the last entry A[n - 1] contains the smallest element. Other sorting programs \nexhibit their worst-case behaviors usually when the arrayisreverse-sorted(For selection sort,areverse \nsorted array is not the worst case; it incurs only n 2 swaps!). By automatically generating this non-intuitivemaximally-weak \nprecondition our tool provides a signi.cant insight about the algorithm and reduces the programmer sburden. \n2. Notation We often use a set of predicates in place of a formula to mean the conjunction of the predicates \nin the set. In our examples, we often use predicates that are inequalities between a given set of variables \nor constants.For some subset V of the variables, we use the notation QV to denote the set of predicates \n{v1 = v2 | v1,v2 . V }. Also, for any subset V of variables, and any variable j, we use the notation \nQj,V to denote the set of predicates {j < v,j = v,j > v,j = v | v . V }. 2.1 Templates A template t \nis a formula over unknown variables vi that take values over (conjunctions of predicates in) some subset \nof a given setof predicates.We considerthe following languageof templates: t ::= v |\u00act | t1 . t2 | t1 \n. t2 |.x : t |.x : t We denote the set of unknown variables in a templatet by U(t ). We say that an unknown \nv . U(t) in template t is a positive (or negative) unknown if t is monotonically stronger (or weaker \nrespectively) in v. More formally, let v be some unknown variable in U(t ). Let sv be anysubstitution \nthat maps all unknownvariables v ' in U(t ) that are different from v to some set of predicates. Let \nQ1,Q2 . Q(v). Then, v is a positive unknown if .sv,Q1,Q2 :(Q1 . Q2) . (tsv[v . Q2] . tsv[v . Q1]) Similarly, \nv is a negative unknown if .sv,Q1,Q2 :(Q1 . Q2) . (tsv[v . Q1] . tsv[v . Q2]) We use the notation U+(t \n) and U-(t) to denote the set of all positive unknowns and negative unknowns respectively in t . If each \nunknown variable in a template/formula occurs only once, then it can be shown that each unknown is either \npositive or negative. In that case, the sets U+(t ) and U-(t ) can be computed using structural decomposition \nof t as follows: + - U(v)= {v} U(v)= \u00d8 U+(\u00act)= U-(t) U-(\u00act)= U+(t) --- U+(t1 . t2)= U+(t1) . U+(t2) \nU(t1 . t2)= U(t1) . U(t2) --- U+(t1 . t2)= U+(t1) . U+(t2) U(t1 . t2)= U(t1) . U(t2) -- U+(.X : t)= \nU+(t) U(.X : t)= U(t) -- U+(.X : t)= U+(t) U(.X : t)= U(t) EXAMPLE 1. Consider the following template \nt with unknown variables v1,..,v5. (v1 . (.j : v2 . sel(A, j) = sel(B, j)) . (.j : v3 . sel(B, j) = sel(C, \nj))) . (v4 . (.j : v5 . sel(A, j) = sel(C, j))) Then, U+(t )= {v2,v3,v4} and U-(t )= {v1,v5}.  2.2 Program \nModel We assume that a programProg consists of the following kind of statements s (besides the control-.ow). \ns ::= x := e | assert(f) | assume(f) In the above, x denotes a variable and e denotes some expres\u00adsion.Memoryreadsand \nwritescanbe modeledusing memoryvari\u00adables and select/update expressions. Since we allow assume state\u00adments, \nwithout loss of anygenerality, we can treat all conditionals in the program as non-deterministic. We \nnow set up a formalism in which different templates can be associated with different program points, \nand different unknowns in templates can take values from different sets of predicates. Let C be some \ncut-set of the program Prog. (A cut-set of a program is a set of program points, called cut-points, such \nthat any cyclic path in Prog passes through some cut-point.) Every cut-point in C is labeled with an \ninvariant template. For simplicity, we assume that C also consists of program entry and exit locations, \nwhich are labeled with an invariant template that is simply true. Let Paths(Prog) denote the set of all \ntuples (d, t1,t2,st), where d is some straight-line path between two cut-points from C that are labeled \nwith invariant templates t1 and t2 respectively. Without loss of any generality, we assume that each \nprogram path d is in static single assignment (SSA) form, and the variables that are live at start of \npath d are the originalprogram variables, and the SSA versions of the variables that are live at the \nend of d are given by the mapping st, while st -1 denotes the reverse mapping.  We use the notation \nU(Prog) to denote the set of unknown variables in the invariant templates at all cut-points of Prog. \nEXAMPLE 2. Consider the following program ArrayInit (used as a running example) that initializes all \narray elements to 0. ArrayInit(Array A, int n) 1 i := 0; 2 while (i<n) 3 A[i] := 0; 4 i := i +1; 5 Assert(.j \n:0 = j<n . sel(A, j) = 0); Consider the cut-set C for program ArrayInit that consists of only the program \nlocation 2 besides the entry and exit locations. Let the program location 2 be labeled with the invariant \ntemplate .j : v . sel(A, j)=0, which has one negative unknown v. Then, Paths(ArrayInit) consists of the \nfollowing tuples. Entry Case (i := 0, true, .j : v . sel(A, j)=0,st), where st is the identity map. Exit \nCase (assume(i = n), .j : v . sel(A, j)=0, .j :0 = j<n . sel(A, j)=0,st), where st is the identity map. \nInductive Case (assume(i<n); A ' := upd(A, i, 0); i ' := i +1, .j : v . sel(A, j)=0, .j : v . sel(A ' \n,j)=0,st), where st(i)= i ' ,st(A)= A ' .  2.3 Invariant Solution The veri.cation condition of any straight-line \npath d (a sequence of statements s)in SSA form between two program points labeled with invariant templates \nt1 and t2 isgiven by VC((t1, d, t2))= t1 . WP(d, t2) where the weakest precondition WP(d, f) of formula \nf with respect to path d is as follows: WP(skip,f)= f WP(s1; s2,f)= WP(s1, WP(s2,f)) WP(assert(f ' ),f)= \nf ' . f WP(assume(f ' ),f)= f ' . f WP(x := e, f)=(x = e) . f (1) Observethatthe correctnessofEq.1inthe \nde.nitionoftheweakest precondition above relies on thefact that the statements on path d are in SSA form. \n(Note that it is important for the path d to be in SSA form since otherwise we will have to address the \nissue of substitution in templates, as the only choice for WP(x := e, f) when the path d is in non-SSA \nform would be f[e/x]. DEFINITION 1 (Invariant Solution). Let Q be a predicate-map that maps each unknown \nv in any template invariant in program Prog to some set of predicates Q(v).Let s map eachunknown v in \nany template invariant in program Prog to some subset of Q(v). Wesay thats is an invariant solution for \nProg overQ if thefollow\u00ading formula VC(Prog,s), whichdenotes the veri.cation condition of the program \nProg w.r.t. s, is valid. def VC(Prog,s)=VC((t1s, d, t2sst)) (d,t1,t2,st).Paths(Prog) EXAMPLE 3. Consider \nthe program ArrayInit described in Ex\u00adample 2. Let Q map unknown v in the invariant template at cut\u00adpoint \nlocation 2 to Qj,{0,i,j}. Let s map v to Q0 = {0 = j,j <i}. Then, s is an invariant solution for ArrayInit \nover Q since the veri.cation condition VC(ArrayInit,s) of the program ArrayInit,whichisgivenbythe conjunctionofthe \nfollowingfor\u00admulas, is valid. i =0 . (.j : Q0 . sel(A, j) = 0)  (i = n . (.j : Q0 . sel(A, j) = 0)) \n. (.j :0 = j = n . sel(A, j) = 0)  (i<n . A ' = upd(A, i, 0) . i ' = i +1 . (.j : Q0 . sel(A, j) = \n0)) .  (.j : Q0st . sel(A ' ,j) = 0) where st(i)= i ' and st(A)= A ' . Sections4and5describe algorithmsfor \ngeneratinganinvariant solutiongiven program Prog and an appropriate predicate-map Q. 3. Optimal Solutions \nIn this section, we present the core operation of generating an optimal solution that is used by our \nalgorithm to perform local reasoning about program paths (which are encoded as formulae). Separating \nlocal reasoning from .xed-point computation (that we address later) is essential because it is not possible, \nin general, to encode a program with loops as a single SMT constraint. DEFINITION 2 (Optimal Solution). \nLet f be a formula with un\u00adknowns {vi}i where each vi is either positive or negative. Let Q map each \nunknown vi to some set of predicates Q(vi). A map {vi . Qi}i is a solution (for f over domain Q)if the \nformula f is valid after each vi isreplacedby Qi, and Qi . Q(vi).Asolu\u00adtion {vi . Qi}i is optimal if \nreplacing Qi by a strictly weaker or stronger subset of predicates from Q(vi), depending on whether vi \nisnegativeor positive,resultsinamapthatisnolongera solution. EXAMPLE 4. Consider the following formula \nf with one negative unknown .. i =0 . (.j : . . sel(A, j) = 0) Let Q(.) be Qj,{0,i,n}. There are four \noptimal solutions for f over Q. These map the negative unknown variable . to {0 <j = i}, {0 = j<i}, {i<j \n= 0}, and {i = j< 0} respectively. Since the naive exponential search for optimal solutions to a formula \nwould be too expensive, here we present a systematic search, that we found to be ef.cient in practice. \nThe procedure described in Figure2returns the set of all opti\u00admal solutions for an input formula f over \ndomain Q. It makes use of an operation OptimalNegativeSolutions(f, Q) (discussed later) that returns \nthe set of all optimal solutions for the special case when f consists of only negative unknowns. To understand \nhow the procedure OptimalSolutions operates, it is illustrative to think of the simple case when there \nis only one positive variable ..In this case, the algorithm simply returns the conjunction of all those \npredicates q . Q(.) such that f[. .{q}] is valid. Observe that such a solution is an optimal solution, \nand this procedure is much more ef.cient than naively trying out all possible subsets and picking the \nmaximal ones. EXAMPLE 5. Consider the following formula f with one positive unknown .. (i = n) . (.j \n: . . sel(A, j) = 0)) . (.j :0 = j<n . sel(A, j) = 0) Let Q(.) be Qj,{0,i,n}. There is one optimal solution \nfor f over Q, namely  OptimalSolutions(f, Q) 1 Let U+(f) be {.1,..,.a}. 2 Let U-(f) be {.1,..,.b}. 3 \nS := \u00d8; 4 foreach (q1,..,qa). Q(.1) \u00d7 .. \u00d7 Q(.a): 5 f ' := f[.i .{qi}]i; 6 T := OptimalNegativeSolutions(f \n' ,Q); 7 S := S .{s | s(.i)= {qi},s(.i)= t(.i),t . T }; 8 R := {MakeOptimal(s, S) | s . S}; 9 while any \nchange in R:  10 foreach s1,s2 . R 11 s := Merge(s1,s2,S); if (s = .) continue; ab bb 12 if .s ' . \nR : s ' (.i) . s(.i) . s(.i) . s ' (.i) i=1 i=1 13 R := R .{MakeOptimal(s, S)}; 14 return R; MakeOptimal(s, \nS) b b 1 T := {s ' | s ' . S . s(.i) . s ' (.i)} i=1 2 foreach s ' . T : s '' 3 := Merge(s, s ' ,S) (s \n'' = .) s := s '' 4 if ; 5 return s Merge(s1,s2,S) 1 Let s be s.t. s(.i)= s1(.i) . s2(.i) for i = 1 to \na 2 and s(.i)= s1(.i) . s2(.i) for i = 1 to b b b 3 T := {s ' | s ' . S . s(.i) . s ' (.i)} i=1 a bb \n4 if .s ' . T s.t. s ' (.i)= {qi} return s q1.s(.1),..,qa.s(.a) i=1 5 else return . Figure 2. Procedure \nfor generating optimal solutionsgivena template formula f and a predicate-map Q. Thisiscomputedbythe \nalgorithminFigure2as follows.Attheend of the .rst loop (Lines 4-7), the set S contains three solutions: \n1: . .{0 = j} 2: . .{j<n} 3: . .{j<i} The set R at the endof line8contains only one optimal solution: \n. .{0 = j,j <n,j <i} The set R is unchanged by second loop (Lines 9-13), simply be\u00adcause it contains \nonly one optimal solution, while any change to R would require R to contain at least two optimal solutions. \nNow, consider the case, of one positive and one negative vari\u00adable. In this case, the algorithm invokes \nOptimalNegativeSolut\u00adions to .nd an optimal set of negative solutions for the negative variable ., for \neach choice of predicate q . Q(.) for the posi\u00adtive variable . and stores these solutions in set S (Lines \n4-7). After this, it groups together all those solutions in S that match on the negative variable to \ngenerate a set R of optimal solutions (Line 8). (Recall, from Defn 2, that in an optimal solution a positive \nvariable is mapped to a maximal set of predicates, while a negative variable ismappedtoa minimalset.)Itthen \nattemptsto generate moreop\u00adtimal solutions by merging the solutions for both the positive and negative \nvariables of the optimal solutions in R (Lines 9-13). EXAMPLE 6. Consider the following formula f with \none positive unknown . and one negative unknown .. (. . (i = n) . (.j : . . sel(A, j) = 0)) . (.j : j \n= m . sel(A, j) = 0) Let Q(.) and Q(.) both be Q{i,j,n,m}. There are three optimal solutions for f over \nQ, namely 1: . .{j = m} , . .\u00d8 2: . .{j = n, j = m, j = i}, . .{m = n} 3: . .{j = i, j = m} , . .{m = \ni} These are computedby the algorithminFigure2 as follows.At the end of the .rst loop (Lines 4-7), the \nset S contains the following four solutions: 1: . .{j = m}, . .\u00d8 2: . .{j = n} , . .{m = n} 3: . .{j \n= i} , . .{m = i} 4: . .{j = i} , . .{m = n} The set R at the end of line8contains the following three \noptimal solutions: 1: . .{j = m} , . .\u00d8 2: . .{j = n, j = m, j = i}, . .{m = n} 3: . .{j = i, j = m} \n, . .{m = i} The set R is unchanged by second loop (Lines 9-13). The extension to multiple positive variables \ninvolves considering a choice of all tuples of predicates of appropriate size (Line 4), while the extension \nto multiple negative variables is not very different. OptimalNegativeSolutions This operation requires \nperform\u00ading theory based reasoning over predicates, for which we use an SMT solver as a black box. Of \nseveral ways to implement OptimalNegativeSolutions,we found it effectiveto implement OptimalNegativeSolutions(f, \nQ) as a breadth .rst search on the lattice of subsets ordered by implication with T and . being \u00d8 andthesetofall \npredicates, respectively.Westartat T andkeep deleting the subtree of every solution discovered until \nno more el\u00adements remain to be searched. Furthermore, to achieve ef.ciency, onecan truncatethe searchatacertaindepth.(Weobservedthatthe \nnumber of predicates mapped to a negative variable in anyoptimal solution in our experiments was never \ngreater than 4.)To achieve completeness, the bounding depth can be increased iteratively after afailed \nattempt. 4. Iterative Propagation Based Algorithms In this section, we present two iterative propagation \nbased algo\u00adrithms for discovering an inductive invariant that establishes the validity of assertions \nin a given program. Thekeyinsight behind these algorithms is as follows. Observe that the set of elements \nthat are instantiations of a given template with respect to a given set of predicates, ordered by implication, \nforms a pre-order, but not a lattice. Our algorithms performs a standard data-.ow analysis over the powerset \nextension of this abstract domain (which forms a lattice) to ensure that it does not miss any solution. \nExperimental evidence shows that the number of elements in this powerset extension never gets beyond \n6. Each step involves updating a fact at a cut-point by using the facts at the neighboring cut-points \n(preceding/succeeding cut-points in case of forward/backward data-.ow respectively). The update is doneby \ngenerating theveri.cation condition that relates thefacts at the neighboring cut-points with the template \nat the current cut\u00adpoint, and updating using the solutions obtained from a call to OptimalSolutions. \nThe two algorithms differ in whether they perform a forward or backward data.ow and accordingly end up \ncomputing a least or greatest .xed point respectively,but theyboth have the following property. THEOREM \n1. Given a program Prog and a predicate map Q, the algorithmsinFigure3output aninvariant solution,if \nthereexists one.  LeastFixedPoint(Prog,Q) 1 Let s0 be s.t. s0(v) . \u00d8, if v is negative s0(v) . Q(v), \nif v is positive 2 3 S := {s0}; while S = \u00d8 . .s . S : \u00acValid(VC(Prog, s)) 4 Choose s . S, (d, t1, t2, \nst) . Paths(Prog) s.t. 5 6 7 8 \u00acValid(VC((t1s, d, t2sst))) S := S - {s}; Let sp = s | U(Prog)-U(t2) and \n. := t2s . t2. S := S . {s ' s-1 t . sp |s ' . OptimalSolutions(VC((t1s, d, t2)) . ., Qst)}if S = \u00d8 return \n No solution 9 else return s . S s.t. Valid(VC(Prog, s)) (a) Least Fixed Point Computation GreatestFixedPoint(Prog) \n1 Let s0 be s.t. s0(v) . Q(v), if v is negative s0(v) . \u00d8, if v is positive 2 3 S := {s0}; while S = \n\u00d8 . .s . S : \u00acValid(VC(Prog, s)) 4 Choose s . S, (d, t1, t2, st) . Paths(Prog) s.t. 5 6 7 8 \u00acValid(VC((t1s, \nd, t2sst))) S := S - {s}; Let sp = s | U(Prog)-U(t1) and . := t1 . t1s. S := S . {s ' . sp |s ' . OptimalSolutions(VC((t1, \nd, t2sst)) . ., Q)}if S = \u00d8 return No solution 9 else return s . S s.t. Valid(VC(Prog, s)) (b) Greatest \nFixed Point Computation  Figure 3. Iterative Algorithms for generating aninvariant solutiongiven program \nProg and predicate-map Q. For notational convenience, we present the algorithms slightly differently. \nEach of these algorithms (described in Figure 3) in\u00advolve maintaining a set of candidate-solutions at \neach step. A candidate-solution s is a map of the unknowns v in all tem\u00adplates to some subset of Q(v), \nwhere Q is the given predicate\u00admap. The algorithms make progress by choosing a candidate\u00adsolution, and \nreplacing it by a set of weaker or stronger candidate\u00adsolutions (depending on whether a forward/least \n.xed-point or backward/greatest .xed-point technique is used) using the oper\u00adation OptimalSolutions de.ned \nin Section 3. The algorithms return an invariant solution whenever any candidate solution s becomes one \n(i.e., Valid(VC(Prog,s))), or fail when the set of candidate-solutions becomes empty.We next discuss \nthe two spe\u00adci.c variants along with an example. 4.1 Least Fixed-point This algorithm (Figure 3(a)) starts \nwith the singleton set contain\u00ading the candidate solution that maps each negative unknown to the empty \nset (i.e., true)and each positive unknown to the set of all predicates. In each step, the algorithm chooses \na s, which is not an invariant solution. It must be the case that there exists (d, t1,t2,st) . Paths(Prog) \nsuch that VC((t1s, d, t2sst)) is not valid. Furthermore, this is because t2s is a too strong instantiation \nfor t2. The algorithm replaces the candidate solution s by the so\u00adlutions {s ' s-1 . sp |s ' .OptimalSolutions(VC((t1s, \nd, t2)) . t ., Qst)}, where sp is the projection of the map s onto the un\u00adknowns in the set U(Prog) - \nU(t2) and . (de.ned as t2s . t2) ensures that only stronger solutions are considered. EXAMPLE 7. Consider \nthe ArrayInit program from Example 2. Let Q(v)= Qj,{0,i,n}. In the .rst iteration of the while loop, \nS is initialized to s0, and in Line 4 there is only one triple in Paths(ArrayInit) whose corresponding \nveri.cation condition is inconsistent, namely (i := 0, true, .j : v . sel(A, j)= 0,st), where st is the \nidentity map. Line 7 results in a call to OptimalSolutions on the formula f =(i = 0) . (.j : v . sel(A, \nj) = 0), the result of whichhas already been shown in Example 4. The set S now contains the following \ncandidate solutions after the .rst iteration of the while loop. 1: v .{0 <j = i} 2: v .{0 = j<i} 3: v \n.{i<j = 0} 4: v .{i = j< 0} Of these, the candidate-solution v .{0 = j<i} is a valid solution and hence \nthe while loop terminates after one iteration.  4.2 Greatest Fixed-point This algorithm (Figure 3(b)) \nstarts with the singleton set contain\u00ading the candidate solution that maps each positive unknown to the \nempty set (i.e., true)and each negative unknown to the set of all predicates. In each step, the algorithm \nchooses a s, which is not an invariant solution. It must be the case that there exists (d, t1,t2,st) \n. Paths(Prog) such that VC((t1s, d, t2sst)) is not valid. Furthermore, this is because t1s is a too weak \ninstantiation for t1. The algorithm replaces the candidate solution s by the so\u00adlutions {s ' . sp | s \n' . OptimalSolutions(VC((t1, d, t2sst)) . ., Q)}, where sp is the projection of the map s onto the unknowns \nin the set U(Prog) - U(t1) and . (de.ned as t1 . t1s)ensures that only weaker solutions are considered. \nEXAMPLE 8. Consider the ArrayInit program from Example 2. Let Q(v)= Qj,{0,i,n}. In the .rst iteration \nof the while loop, S is initialized to s0, and in Line 4 there is only one triple in Paths(ArrayInit) \nwhose corresponding veri.cation condition is inconsistent, namely (assume(i = n), .j : v . sel(A, j)= \n0, .j :0 = j<n . sel(A, j)=0,st), where st is the identity map. Line7resultsina callto OptimalSolutions \non the formula f =(i = n) . (.j : v . sel(A, j) = 0) . (.j :0 = j<n . sel(A, j) = 0), whose output is \nshown in Example 5. This results in S containing only the following candidate-solution after the .rst \niteration of the while loop. v .{0 = j,j <n,j <i} The candidate-solution v .{0 = j,j <n,j <i} is a valid \nsolution and hence the while loop terminates after one iteration. 5. Constraint Based Algorithm Inthis \nsection,weshowhowto encodetheveri.cation conditionof the program asa boolean formula such thata satisfying \nassignment to the boolean formula corresponds to an inductive invariant that establishes thevalidityof \nassertionsinagiven program. For every unknown variablev and anypredicate q . Q(v), we introduce a boolean \nvariable bvq to denote whether or not the predi\u00adcate q is present in the solution for v.We show how to \nencode the veri.cation condition of the programProg usingaboolean formula .Prog over the boolean variables \nbvq . The boolean formula .Prog is constructed by making calls to the theorem proving interface OptimalNegativeSolutions \nand has the following property. THEOREM 2. The boolean formula .Prog (Eq. 2) is satis.able iff thereexistsaninvariant \nsolutionforprogram Prog over predicate\u00admap Q. 5.1 Notation Given a mapping {vi . Qi}i (where Qi . Q(vi)), \nlet BC({vi . Qi}i) denote the boolean formula that constrains the unknown variable vi to contain all \npredicates from Qi. bvi  5.2 Boolean Constraint EncodingforVeri.cation Condition We .rst show how to \ngenerate the boolean constraint .d,t1,t2 that encodes the veri.cation condition corresponding to anytuple \n(d, t1,t2,st) . Paths(Prog). Let t2 ' be the template that is ob\u00adtained from t2 as follows. If t2 is \ndifferent from t1, then t2 ' is same as t2, otherwise t2 ' is obtained from t2 by renaming all the un\u00adknownvariablesto \nfresh unknownvariables with orig denoting the reverse mapping that maps the fresh unknownvariables back \nto the original.(Werenameto ensurethateach occurrenceofanunknown variable in the formula VC((t1, d, t \n2' )) is unique. Note that each oc\u00adcurrence of an unknown variable in the formula VC((t1, d, t2)) is \nnot unique when t1 and t2 refer to the same template, which is the case when the path d goes around a \nloop). A simple approach would be to use OptimalSolutions to compute allvalid solutions for VC((t1, d, \nt 2' )) and encode their dis\u00adjunction. But because both t1,t 2 ' are uninstantiated unknowns, the numberof \noptimal solutionsexplodes.We describe belowanef.\u00adcient construction that involves only invoking OptimalNegative-Solutions \nover formulaewithasmallernumberofunknowns(the negative) for a small choice of predicates for the positive \nvariables. Let .1,..,.a be the set of positive variables and let .1,..,.b be the set of negative variables \nin VC((t1, d, t 2' )). Consider any positive variable .i and any qj . Q ' (.i), where Q ' is the map \nthat maps an unknown v that occurs in t1 to Q(v) and an un\u00adknown v that occurs in t2 to Q(v)st. Consider \nthe partial map s.i,qj that maps .i to {qj } and .k to \u00d8 for any k = i. Let .i,qj S be the set of optimal \nsolutions returned after invok\u00ad d,t1,t2 ing the procedure OptimalNegativeSolutions on the formula VC((t1, \nd, t 2' ))s.i,qj as below: .i,qj '' S = OptimalNegativeSolutions(VC((t1, d, t 2))s.i,qj ,Q ) d,t1,t2 \nSimilarly, let Sd,t1,t2 denote the set of optimal solutions returned after invoking the procedure OptimalNegativeSolutions \non the formula VC((t1, d, t 2' ))s, where s is the partial map that maps .k to \u00d8 for all 1 = k = a. Sd,t1,t2 \n= OptimalNegativeSolutions(VC((t1, d, t 2' ))s, Q ' ) The following Boolean formula .d,t1,t2,st encodes \nthe veri.\u00adcation condition corresponding to (d, t1,t2,st). .. .-1 .d,t1,t2,st = BC({orig(.k) . Qkst \n}k). . {.k\".Qk}k.Sd,t1,t2 .. . orig(.i) -1 . .b-1 .BC({orig(.k) . Qkst }k). qj s t .i,qj .i,qj .Q'(.i) \n{.k\".Qk}k.S d,t1,t2 Theveri.cation conditionofthe entire programisnowgivenby the following boolean formula \n.Prog that is the conjunction of the veri.cation condition of all tuples (d, t1,t2,st) . Paths(Prog). \n.Prog = .d,t1,t2,st (2) (d,t1,t2,st).Paths(Prog) EXAMPLE 9. Consider the ArrayInit program from Example \n2. Let Q(v)= Qj,{0,i,n}. The above procedure leads togeneration of the following constraints. Entry Case \nThe veri.cation condition corresponding to this case contains one negative variable v and no positive \nvariable. The set Sd,t1,t2 is same as the set S in Example7,whichcontains 4 optimal solutions. The following \nboolean formula encodes this veri.cation condition. (bv 0=j . bvj=i) . (bvi=j . bv (3) j<i) . (bv 0<j \n. bv j<0) . (bvi<j . bjv =0) Exit Case The veri.cation condition corresponding to this case contains \none positive variable v and no negative variable.We now consider the set Sv,q for each q . Q(v). Let \nP = {0 = j,j < d,t1,t2 i, j = i,j < n,j = n}. If v . P , the set Sv,q contains the d,t1,t2 empty mapping \n(i.e., the resultant formula when v is replaced by q is valid). If v . Q(v) - P , the set Sv,q is the \nempty-set (i.e., d,t1,t2 the resultant formula when v is replaced by q is not valid). The following boolean \nformula encodes this veri.cation condition. (bvq . true) . (bvq . false) q.Pq.Q(v)-P whichis equivalent \nto the following formula \u00acbv 0<j .\u00acbvi=j .\u00acbvn=j .\u00acbv (4) i<j .\u00acbv n<j .\u00acbv j<0 .\u00acbjv =0 Inductive Case \nThe veri.cation condition corresponding to this case contains one positive variable v and one negative \nvariable v ' obtained by renaming one of the occurrences of v. Note that Sd,t1,t2 contains a singleton \nmapping that maps v ' to the empty\u00adset. Also, note that Sv,j=i is the empty-set, and for any q . d,t1,t2 \nQ(v ' ) -{j = i}, Sv,q contains at least one mapping that maps d,t1,t2 v ' to the singleton {qst}. Hence, \nthe following boolean formula encodes this veri.cation condition. (bvj=i . false) . bvq . (bvq . ...) \nq.Q(v')-{j=i} whichis equivalent to the formula \u00acbvj=i (5) The boolean assignment where bv 0=j and bv \nj<i are set to true, and all other boolean variables are set to false satis.es the conjunction of the \nboolean constraints in Eq. 3,4, and 5. This implies the solution {0 = j,j <i} for the unknown v in the \ninvariant template. 6. Maximally-Weak Precondition Inference In this section, we address the problem \nof discovering maximally\u00adweak preconditions that .t a given template and ensure that all assertions in \na program are valid. DEFINITION 3. (Maximally-Weak Precondition)Given a program Prog with assertions, \ninvariant templates at eachcutpoint, and a template te at the program entry, a solution s for the unknowns \nin the templates assigns a maximally-weak precondition to te if s is a valid solution, i.e. Valid(VC(Prog,s)). \n For any solutions ',it is not the case thatte s ' is strictly weaker  than te s, i.e., .s ' :(te s \n. te s ' . te s ' . te s) . \u00acValid(VC(Prog,s ' )). The greatest .xed-point algorithm described in Section \n4.2 already computes one such maximally-weak precondition. If we change the condition of the while loop \nin line3in Figure 3(b) to S \u00d8..s . S : = \u00acValid(VC(Prog,s ' )), then S at the end of the loop contains \nall maximally-weak preconditions. The constraint based algorithm described in Section 5 is ex\u00adtended \nto generate maximally-weak preconditions using an itera\u00adtive process by .rst generating anyprecondition, \nand then encod\u00ading an additional constraint that the precondition should be strictly weaker than the \nprecondition that was last generated, until any such precondition can be found. The process is repeated \nto gener\u00adate other maximally-weak preconditionsby encoding an additional constraint that the precondition \nshould not be stronger than anypre\u00adviously found maximally-weak precondition. See [30] for details. A \ndual notion can be de.ned for maximally-strong postcondi\u00adtions, which is motivated by the need to discover \ninvariants as op\u00ad  Benchmark Merge Sort (inner) Other Sorting Assertion proved .y.x :0 = y<m . A[y]= \nC[x] . 0 = x<t .y.x :0 = y<n . B[y]= C[x] . 0 = x<t .y.x :0 = y<n . A [y]= A[x] . 0 = x<n Table 1. The \nassertions proved for verifying that sorting programs preserve the elements of the input. A is the array \nA at the input. Benchmark Precondition inferred Selection Sort .k : 0 = k < n-1 . A[n-1] < A[k] .k1, \nk2 : 0=k1 <k2 <n-1 . A[k1] < A[k2] Insertion Sort .k : 0 = k < n-1 . A[k] > A[k+1] Bubble Sort (.ag) \n.k : 0 = k < n-1 . A[k] > A[k+1] Quick Sort (inner) .k1, k2 : 0 = k1 < k2 = n . A[k1] = A[k2] Table \n2. The preconditions inferredby our algorithms resultinginthe worst case upper bounds runs for sorting \nprograms. Benchmark Partial Init Init Synthesis Binary Search Merge Preconditions inferred under given \npostcondition (a) m = n pre: (b) .k : n = k<m . A[k]=0 post: .k :0 = k<m . A[k]=0 (a) i =1 . max =0 pre: \n(b) i =0 post: .k :0 = k<n . A[max] = A[k] pre: .k1,k2 :0 = k1 <k2 <n . A[k1] = A[k2] post: .k :0 = k<n \n. A[k]= e .k :0 = k<n . A[k] = A[k+1] pre: .k :0 = k<m . B[k] = B[k+1] post: .k :0 = k<t . C[k] = C[k+1] \n Table 3. Given a functional speci.cation (post), the maximally-weak preconditions (pre) inferred by \nour algorithms for functional correct\u00adness. The code for these examples is listed in Figure 10. posed \nto verifying given assertions. It can be shown that the least .xed-point based algorithm in Section 4.1 \nalready computes one such maximally-strong solution. Furthermore, the constraint based algorithm can \nbe extended to generate maximally-strong postcon\u00additions. See [30] for details. 7. Evaluation Wehavebuilta \nprototype implementation using the Phoenix com\u00ad piler framework [24] as the frontend parser for ANSI-C \nprograms and Z3 [25, 7] as our SMT solver. Our implementation is approxi\u00ad mately 15K lines of non-blank, \nnon-comment, C# code. Since quanti.cation makes reasoning undecidable, SMT solvers require additional \nhelp in the presence of quanti.ed facts. We have developed a wrapper interface that automatically constructs \npatterns for quanti.er instantiation (used for E-matching [6]) and introducesexplicitskolemization functions. \nAlso,to support linked lists, we augment Z3 s support for select/update with axioms for reachability. \nSee [31, 30] for details. We evaluated the performance of our algorithms, using a 2.5GHz Intel Core2Duo \nmachine with 4GBof memory. 7.1 Templates and Predicates Our tool takes as input a program and a global \nset of templates and predicates. The global template is associated with each loop header (cut-point) \nand the global set of predicates with each unknown in the templates.We usea global setto reduce annotationburdenbut \npossiblyatthecostofef.ciency.Foreach benchmark program,we supplied the tool with a set of templates, \nwhose structure is very similar to the program assertions (usually containing one unquanti\u00ad.ed unknownandafew \nquanti.ed unknowns,asinFigure1)anda set of predicates consisting of inequality relations between relevant \nprogram and bound variables. 7.2 Verifying standard benchmarks Simple array/list manipulation: We present \nthe performance of our algorithms on simplebut dif.cult programs manipulating ar\u00adrays and lists that \nhave been previously considered by alternative techniques. By adding axiomatic support for reachability, \nwe were able toverify simple list programs illustrating ourextensibility.Ta\u00adble4presentsthe benchmarkexamples,the \ntimein secondstaken by each of our algorithm (least .xed-point, greatest .xed-point and constraint-based) \nand the time reported by previous techniques2. For the appropriately named Consumer Producer [17], weverify \nthat only values produced are consumed. For the appropriately namedPartitionArray[2,17],weverifythattheoutput \narraysare partitionsofthe input.ForListInit[12],weverifythatthe output list is initialized and for List \nInsert/Delete [12] that theymaintain the initialization. Sortedness property: We choose sorting for our \nbenchmark com\u00adparisons because these are some of the hardest veri.cation in\u00adstances for array programs \nand have been attempted by previous techniques.Weverify sortedness for all major sorting procedures. \nTable 6, columns 1 5, presents the benchmark examples, the time taken in seconds by our algorithms (least \n.xed-point, greatest .xed-point and constraint-based) to verify that theyindeed output a sorted array \nand previously reported timings2.Weevaluateover selection, insertion andbubble sort (one that iterates \nn 2 times irre\u00adspective of array contents, and one that maintains a .ag checking if the array is already \nsorted). For quick sort and merge sort we consider their partitioning and merge steps, respectively. \nWe do not know of a single technique that can uniformly ver\u00adify all sorting benchmarks as is possible \nhere. Infact, the missing results indicate that previous techniques are not robust and are spe\u00adcialized \nto the reasoning required for particular programs. In con\u00adtrast, our tool successfully veri.ed all programs \nthat we attempted. Also, on time, we outperform the current state-of-the-art.  7.3 Proving ..,worst-case \nbounds and functional correctness We now present analyses for which no previous techniques are known.We \nhandle three new analyses: .. properties for verifying that sorting programs preserve elements, maximally-weak \nprecon\u00additions for worst case upper bounds and functional correctness. .. properties: Weprovethat the \nsorting programs do not lose any elements of the input3. The proof requires discovering .. invariants \n(Table1).The runtimes areshowninTable6, columns 6 8. Except for two runs that timeout, all three algorithms \nef.ciently verify all instances. 2We warn the reader that the numbers for previous techniques are poten\u00adtially \nincomparable because of the differences in experimental setups and because some techniques infer predicates, \npossibly using templates. 3Similar .. invariants can be used to prove that no elements aregained. Together, \nthese invariants prove that the output array is a permutation of the input for the case when the elements \nin the input array are distinct.  Benchmark LFP GFP CFP Previous Consumer Producer 0.45 2.27 4.54 45.00 \n[17] Partition Array 2.28 0.15 0.76 7.96 [17], 2.4 [2] List Init 0.15 0.06 0.15 24.5 [12] List Delete \n0.10 0.03 0.19 20.5 [12] List Insert 0.12 0.30 0.25 23.9 [12] Benchmark GFP Partial Init 0.50 Init Synthesis \n0.72 Binary Search 13.48 Merge 3.37  Table 5. Time (secs) for pre-Table 4. Time(secs)forveri.cationof \ndata-sensitivearray/list conditionsfor functionalcor\u00adprograms. rectness. Sortedness .. Upper Benchmark \nLFP GFP CFP Previous LFP GFP CFP Bound Selection Sort 1.32 6.79 12.66 na4 22.69 17.02 timeout 16.62 Insertion \nSort 14.16 2.90 6.82 5.38 [15]4 2.62 94.42 19.66 39.59 Bubble Sort (n2) 0.47 0.78 1.21 na 5.49 1.10 13.74 \n0.00 Bubble Sort (.ag) 0.22 0.16 0.55 na 1.98 1.56 10.44 9.04 Quick Sort (inner) 0.43 4.28 1.10 42.2 \n[12] 1.89 4.36 1.83 1.68 Merge Sort (inner) 2.91 2.19 4.92 334.1 [12] timeout 7.00 23.75 0.00 Table \n6. Time (secs) for sorting programs.Weverify sortedness, preservation(..)and infer preconditions for \nthe worst case upper bounds. Figure 5. LFP and CFP remain rela\u00adtively robust to irrelevant predicates. \nWorst case upper bounds: We have already seen that the worst case input for Selection Sort involves a \nnon-trivial precondition that ensures that a swap occurs every time it is possible (line 7 of Figure \n1).For Insertion Sort we assert that the copy operation inthe innerloopisalwaysexecuted.Forthe termination \nchecking version of Bubble Sort we assert that after the inner loop concludes the swapped .ag is always \nset. For the partitioning procedure in Quick Sort (that deterministically chooses the leftmost element \nas thepivot),we assertthatthepivotendsupatthe rightmost location. All of these assertions ensure the \nrespective worst case runs occur. We generate the maximally-weak preconditions for each of the sortingexamples \nas showninTable2. Notice that the inner loop of merge sort and the n 2 version of bubble sort always \nperform the same number of writes and therefore no assertions are present and the precondition is true.The \ntimetakenisshowninTable6, column 9, and is reasonable for all instances. Functional correctness: Often, \nprocedures expect conditions to hold on the input for functional correctness. These can be met by initialization, \nor by just assuming facts at entry. We consider the synthesis of the maximally-weakest such conditions. \nTable 3 lists our benchmarks and the interesting non-trivial5 preconditions (pre)we compute under the \nfunctional speci.cation(post)supplied as postconditions. Table 5 lists the time taken to compute the \npreconditions. Partial Init initializes the locations 0 ...n while the func\u00adtional speci.cation expects \ninitialization from 0 ...m. Our algo\u00adrithms, interestingly, generate two alternative preconditions, one \nthat makes the speci.cationexpect less, while the otherexpects lo\u00adcations outside the range to be pre-initialized. \nInit Synthesis com\u00adputestheindexofthe maximumarrayvalue. Restrictingto equality predicates we compute \ntwo orthogonal preconditions6 that corre\u00ad 4[12] and [17] present timing numbers for the inner loops that \nare incom\u00adparable to the numbers for the entire sorting procedure that we report here. For the inner \nloops of selection sort and insertion sort, our algorithms run in time 0.34(LFP), 0.16(GFP), 0.37(CFP) \nfor selection sort compared to 59.2 [12] and in time 0.51(LFP), 1.96(GFP), 1.04(CFP) for insertion sort \n compared to 35.9 [12] and 91.22 [17]. 5We omit other non-interesting trivial preconditions for lack \nof space. spond to the missing initializers. Binary Search is the standard binary search for the element \ne with the correctness speci.cation that if the element was not found in the array, then the array does \nnot containthe element.We generate the intuitive precondition that the input array must have been sorted. \nMerge Sort (inner) outputs a sorted array.We infer that the input arrays musthave been sorted for the \nprocedure to be functionally correct.  7.4 Properties of our algorithms Statistical properties: We statistically \nexamined the practical be\u00adhavior our algorithms to explain why they work well despite the theoretical \nbottlenecks.We accumulatedthe statisticsoverall anal\u00adyses and for all relevant modes (iterative and constraint-based). \nFirst, we measuredif the SMT queries generatedby our system were ef.ciently decidable. Figure 4 shows \nthat almost all of our queries take less than 10ms.By separating .xed-point computation from reasoning \nabout localveri.cation conditions,wehavebrought the theoremprovingburdendowntotherealmof currentsolvers. \nSecond, because our algorithms rely on OptimalNegative-Solutions and OptimalSolutions, it is therefore \nimportant that in practice theyreturna small numberof optimal solutions.Infact, we found that on most \ncalls they return a single optimal solution (Figure6and7) and never more than6. Therefore there are indeed \na small number of possibilities to consider when they are called (in Figures2and3andin the constraint \nencoding). Thisexplains the ef.ciencyof our local reasoning in computing the best abstract transformer. \nThird,weexaminetheef.ciencyofthe.xed-point computation (iterative) or encoding (constraint-based)built \nfrom the core pro\u00adcedures.For the iterative approaches, we reacheda .xed-pointina median of4steps withthe \nnumber of candidates remaining small, at around8(Figure 8). This indicates that our algorithms perform \navery directed search for the .xed-point.For the constraint-based approach, the number of clauses in \nthe SATformula never exceeds 500 (Figure9) witha median sizeof5 variables. Thisexplains the ef.ciencyof \nour .xed-point computation. 6Notice that the second precondition is indeed the maximally-weakest for \nthe speci.cation, even though max could be initialized out of bounds. If we expected to strictly output \nan array index and not just the location of the maximum, then the speci.cation should have contained, \n0 = max < n.  Figure 6. OptimalNegative-Figure 7. Solutions mostly returns so-OptimalSolutions mostly \nlutions with one predicate. returns a single solution. Robustness: Our algorithms use a global set of \nuser speci.ed predicates.Weevaluated the robustnessof our algorithmsover the sortedness analysisby adding \nirrelevant predicates. Figure5shows how the performancedegrades, asafactorof the base performance and \naveraged over all sorting examples, as irrelevant predicates are introduced. The constraint-based approach \nis much more robust than the iterativeschemes and, remarkably,only shows degradation past 35 irrelevant \npredicates. On the other hand, greatest .xed-point cannot handle more than 15 and least .xed-point shows \nsteady decrease in performance.  7.5 Discussion Our benchmark programs pose a spectrum of analysis challenges. \nThe experiments corroborate the intuition that a universal panacea capable of addressing all these challenges \nprobably does not ex\u00adist. No single technique (forward or backward iterative or bi\u00addirectional constraint-based) \naddresses all the challenges,but be\u00adtween them they cover the space of reasoning required. Therefore \nin practice, a combination will probably be required for handling real world instances. We have also \nidenti.ed the different strengths that each algo\u00adrithm demonstratesin practice.We found that for maximally-weak \nprecondition inference, the iterative greatest .xed-point approach is more ef.cient than the constraint-based \napproach. In a similar setting of computing maximally-strong postcondition, the iterative least .xed-point \nis expected to be more ef.cient, as is indicated by its performancein ourexperiments.Aconstraint-based \nencodingis not suitable in an unconstrained problem where the number of pos\u00adsibilities grows uncontrollably. \nOn the other hand, when the system is suf.ciently constrained, for example when verifying sortedness \nor preservation, the constraint-based approach is signi.cantly more robust to irrelevant predicates, \nfollowed by least .xed-point and lastly greatest .xed-point. 8. RelatedWork Template-based analyses The \ntemplate-based approach used in this work is motivated by recent work on using templates to dis\u00adcover \nprecise program properties, such as numerical invariants [26, 27, 4, 18, 1, 13], quanti.er-free invariants \nover predicate abstrac\u00adtion [14], and universally quanti.ed invariants (over arrays) [12]. All these \ntechniques differ in expressivity of the templates, as well as the algorithm and underlying technology \nused to solve for the unknowns in the templates. In terms of expressivity, our templates, which are based \non logical structure over predicate abstraction, are more precise than the quanti.er-free templates of \n[14], and orthog\u00adonal to the templates used in anyother approach. All techniques,withtheexceptionof[12],employa \nconstraint\u00adbased approach to encode .xed point, reducing invariant gener\u00adation to the task of solving \na constraint. In particular, [14] uses the notion of predicate cover of a quanti.er-free formula to re\u00adduce \nthe problem to SATsolving, while the remaining techniques Figure 8. The number of can-Figure 9. The number \nof didates in iterative schemes re-clauses in the SAT formulae mains mostly below 8. are always less \nthan 500. use Farkas lemma to reduce the problem to solving non-linear constraints, which are then solved \nby either SATsolvers after bit\u00adblasting [13] or by using specialized non-linear solvers [26, 27, 4, 18, \n1]. On the other hand, [12] uses an iterative least-.xed point approach; however it requires non-standard \nunder-approximation analyses. In contrast, we present both iterativeand constraint-based algorithmsbuilt \non thepowerof SMT solvers, and preliminaryex\u00adperimental results indicate that each has its own strengths. \nPredicate Abstraction The form of our templates (in which un\u00adknowns rangeover conjunctionsof predicatesas \nopposedto numer\u00adical templatesin which unknowns rangeover constant coef.cients) is motivated by recent \nadvances in using predicate abstraction to express and discover disjunctive properties of programs. The \nim\u00adportant body of work [10, 9, 21, 17, 22] leading up to our work has been discussed earlier (Section \n1). In that dimension, we extend the.eldtodiscoveringinvariantsthatinvolvean arbitrary(butpre\u00adspeci.ed) \nquanti.ed structure over a given set of predicates. An\u00adother signi.cant difference is thatour technique \n(the iterativegreat\u00adest .xed-point version, which works in a backward direction) gen\u00aderate maximally-weak \npreconditions, while the other predicate ab\u00adstraction techniquesthatweknowof,withtheexceptionof[14],do \nnot generate preconditions, primarily because most of them work in the forward direction. [14] presents \na constraint based approach to generating preconditions for quanti.er-free templates. In con\u00adtrast, our \nquanti.ed templates are not only more expressive, but our experimental results show that the constraint-based \napproach does not lend itself well to generating preconditions because of too manychoices that become \npossible in an unconstrained system. We do not consider the orthogonal problem of computing the rightsetof \npredicates(e.g.,[3,16])andleavethe interestingavenue of combining our work with predicate discovery for \nfuture work. Sketching In the domain of program synthesis, combinatorial search based algorithms [29, \n28] are distantly related. They also use templates,but for program statements. It will be interesting \nto apply the ideas presented here to template based program synthesis. Others [23] describes how to use \ndecision procedures to com\u00adpute best abstract transformers over domains other than predicate\u00adabstraction \ndomains. Our iterative algorithms accomplish this for arbitrary logical structure over predicate abstraction. \nKov\u00b4 acs andVoronkov [20] describea technique for generating invariants with quanti.er alternations using \na saturation-based the\u00adorem prover. Their technique relies on an underlying procedure for generating \ninvariants over scalar loop variables and an instru\u00admented loop counter. Any skolemizations functions \nare removed by the introduction of quanti.er alternations. Theydiscover quan\u00adti.ed invariants for a couple \nof examples, e.g., array partitioning and initialization,but the completeness of the approachis unclear \nanditis unclear whetherit canbe adaptedtoprovegiven assertions as opposed to generating arbitrary invariants. \n Partial Init(Array A, int m) 1 i := 0; Merge(Array A, int n) 2 while (i < n) 3 A[i] := 0; 4 i++; 5 \nAssert(.k : 0 = k < m . 6 A[k] = 0) Init Synthesis(Array A, int n) 1 while (i < n) 2 if (A[max] < A[i]) \n3 max := i; 4 i++; Binary Search(Array A, int n) 1 low := 0; high := n - 1; 2 while (low = high 3 Assume(low \n= mid = high) 4 if (A[mid] < e) 5 low := mid + 1; 6 else if (A[mid] > e) 7 high := mid - 1; 8 else return; \n9 Assert(.k : 0 = k < n : A[k] = e) 1 2 3 4 5 6 7 8 9 10 11 i := j := t := 0; while (i < n . j < m) if \n(A[i] = B[j]) C[t++] := A[i++]; else C[t++] := B[j++]; while (i < n) C[t++] := A[i++]; while (j < m) \nC[t++] := B[j++]; Assert(.k : 0 = k < t - 1 . 5 Assert(.k : 0 = k < n . 12 C[k] = C[k + 1]) 6 A[max] \n= A[k]) Figure 10. Benchmark examples for weakest preconditions for functional correctness.  9. Conclusions \nand FutureWork In this paper, we address the problem of inferring expressive pro\u00adgram invariants over \npredicate abstraction for veri.cation and also for inferring maximally-weak preconditions. We present \nthe .rst technique that infers ./..-quanti.ed invariants for proving the full functional correctness \nof all major sorting algorithms. Additionally, we present the .rst technique that infers maximally-weak \nprecon\u00additions for worst case upper bounds and functional correctness. We present three .xed-point computing \nalgorithms (two itera\u00adtive and one constraint-based) that use a common interface to SMT solvers to construct \ninvariants as instantiations of templates with arbitrary quanti.cation and boolean structure. Our algorithms \ncom\u00adpute greatest and least .xed-point solutions that induce maximally\u00adweak precondition and maximally-strong \npostcondition analyses. We have implemented our algorithms in a tool that uses off\u00adthe-shelf SMT solvers. \nOur tool uniformly and ef.ciently veri.es (sortedness and preservation) properties of all major sorting \nalgo\u00adrithms and we have also used it for establishing worst case bounds and maximally-weak preconditions \nfor functional correctness.We are unaware of anyother technique that performs these analyses. Today, \nSMT solvers support a variety of theories, and we have veri.ed simple linked list programs. Next, we \nintend to use our algorithmstoverifyfull functional correctnessof list/treeandother data structure operations \n(e.g. insertion inAVL/Red-Black trees). Future work includes integrating our algorithms with predicate\u00addiscovery \ntechniques, and extending ideas to program synthesis. A. Code listingfor example benchmarks Figure 10 \nshows the benchmark examples for which we generate the weakest preconditions (Table 3) for functional \ncorrectness. Acknowledgments The authors would like to thank Bor-Yuh Evan Chang, Jeff Fos\u00adter, Aswin \nSankaranarayanan and the other anonymous reviewers for their insightful comments and suggestions for \nimprovements to earlier versions of the paper. Also, we greatly appreciate the con\u00adtinued support by \nthe Z3 team at Microsoft Research, speci.cally Nikolaj Bj\u00f8rner and Leonardo de Moura, for their help \nin interfac\u00ading with their solver. References [1] Dirk Beyer, Thomas Henzinger, Rupak Majumdar, and Andrey \nRybalchenko. Invariant synthesis for combined theories. In VMCAI, volume 4349 of LNCS, pages 378 394, \n2007. [2] Dirk Beyer, Tom Henzinger, Rupak Majumdar, and Andrey Ry\u00adbalchenko. Path invariants. In PLDI, \npages 300 309, 2007. [3] Edmund M. Clarke, Orna Grumberg, Somesh Jha, Yuan Lu, and HelmutVeith. Counterexample-guided \nabstraction re.nement. In CAV, pages 154 169, 2000. [4] Michael Col\u00b4on, Sriram Sankaranarayanan, and \nHennySipma. Linear invariant generation using non-linear constraint solving. In CAV, pages 420 432, 2003. \n[5]Patrick Cousot and Radhia Cousot. Abstract interpretation:Auni.ed lattice model for static analysis \nof programs by construction or approximation of .xpoints. In POPL, pages 238 252, 1977. [6] Leonardo \nde Moura and Nikolaj Bj\u00f8rner. Ef.cient E-matching for smt solvers. In CADE, pages 183 198, 2007. [7] \nLeonardo de Moura and Nikolaj Bj\u00f8rner. Z3: Ef.cient SMT solver. In TACAS, volume 4963 of LNCS, pages \n337 340, April 2008. [8] Jr. Edmund M. Clarke, Orna Grumberg, and Doron A. Peled. Model checking. MIT \nPress, Cambridge, MA, USA, 1999. [9] Cormac Flanagan and Shaz Qadeer. Predicate abstraction for software \nveri.cation. In POPL, pages 191 202, 2002. [10] Susanne Graf and Hassen Sa\u00a8idi. Construction of abstract \nstate graphs with PVS. In Computer AidedVeri.cation, pages 72 83, 1997. [11] Sumit Gulwani, Sagar Jain, \nand EricKoskinen. Control-.ow re.nement and progress invariants for bound analysis. In PLDI, 2009. [12] \nSumit Gulwani, Bill McCloskey, and AshishTiwari. Lifting abstract interpreters to quanti.edlogical domains. \nIn POPL, pages 235 246, 2008. [13] Sumit Gulwani, Saurabh Srivastava, and RamarathnamVenkatesan. Program \nanalysis as constraint solving. In PLDI, pages 281 292, 2008. [14] Sumit Gulwani, Saurabh Srivastava, \nand RamarathnamVenkatesan. Constraint-based invariant inference over predicate abstraction. In VMCAI, \npages 120 135, 2009. [15] Nicolas Halbwachs and MathiasP\u00b4eron. Discovering properties about arrays in \nsimple programs. In PLDI, pages 339 348, 2008. [16] ThomasA. Henzinger,RanjitJhala,Rupak Majumdar,andKennethL. \nMcMillan. Abstractions from proofs. In POPL,pages 232 244, 2004. [17] Ranjit Jhala andKen McMillan. Array \nabstraction from proofs. In CAV, 2007. [18] Deepak Kapur. Automatically generating loop invariants using \nquanti.er elimination. In Deduction and Applications, 2005. [19] Gary A. Kildall. Auni.ed approach to \nglobal program optimization. In POPL, pages 194 206, 1973. [20] LauraKov\u00b4acs and AndreiVoronkov. Finding \nloop invariants for programs over arrays using a theorem prover. In FASE, 2009. [21] Shuvendu K. Lahiri \nand Randal E. Bryant. Predicate abstraction with indexed predicates. ACMTrans. on ComputationalLogic, \n9(1), 2007.  [22] Andreas Podelski and ThomasWies. Boolean heaps. In SAS, 2005. [23] ThomasW. Reps, \nShmuel Sagiv, and GretaYorsh. Symbolic impl.of the best transformer. In VMCAI, pages 252 266, 2004. [24] \nMicrosoft Research. Phoenix. http://research.microsoft. com/Phoenix/. [25] Microsoft Research. Z3. http://research.microsoft.com/ \nprojects/Z3/. [26] Sriram Sankaranarayanan, HennySipma, and Zohar Manna. Non\u00adlinearloopinvariant generationusinggr\u00a8obner \nbases.In POPL, pages 318 329, 2004. [27] Sriram Sankaranarayanan, Henny B. Sipma, and Zohar Manna. Constraint-based \nlinear-relations analysis. In SAS, pages 53 68, 2004. [28] Armando Solar-Lezama, Gilad Arnold, Liviu \nTancau, Rastislav Bodik, Vijay Saraswat, and Sanjit A. Seshia. Sketching stencils. In PLDI, pages 167 \n178, June 2007. [29] Armando Solar-Lezama, Liviu Tancau, Rastislav Bodik, Vijay Saraswat, and Sanjit \nA. Seshia. Combinatorial sketching for .nite programs. In ASPLOS, pages 404 415, Oct 2006. [30] Saurabh \nSrivastava and Sumit Gulwani. Programveri.cation using templates over predicate abstraction. Technical \nReport MSR-TR\u00ad2008-173, Nov 2008. [31] Saurabh Srivastava, Sumit Gulwani, and JeffreyFoster. VS3: SMT\u00adsolvers \nfor programveri.cation. In CAV, 2009. [32] Karen Zee,ViktorKuncak, and Martin C. Rinard. Full functional \nveri.cationof linked data structures. In PLDI, pages 349 361, 2008.    \n\t\t\t", "proc_id": "1542476", "abstract": "<p>We address the problem of automatically generating invariants with quantified and boolean structure for proving the validity of given assertions or generating pre-conditions under which the assertions are valid. We present three novel algorithms, having different strengths, that combine template and predicate abstraction based formalisms to discover required sophisticated program invariants using SMT solvers.</p> <p>Two of these algorithms use an iterative approach to compute fixed-points (one computes a least fixed-point and the other computes a greatest fixed-point), while the third algorithm uses a constraint based approach to encode the fixed-point. The key idea in all these algorithms is to reduce the problem of invariant discovery to that of finding <i>optimal</i> solutions for unknowns (over conjunctions of some predicates from a given set) in a template formula such that the formula is valid.</p> <p>Preliminary experiments using our implementation of these algorithms show encouraging results over a benchmark of small but complicated programs. Our algorithms can verify program properties that, to our knowledge, have not been automatically verified before. In particular, our algorithms can generate full correctness proofs for sorting algorithms (which requires nested universally-existentially quantified invariants) and can also generate preconditions required to establish worst-case upper bounds of sorting algorithms. Furthermore, for the case of previously considered properties, in particular sortedness in sorting algorithms, our algorithms take less time than reported by previous techniques.</p>", "authors": [{"name": "Saurabh Srivastava", "author_profile_id": "81100062128", "affiliation": "University of Maryland, College Park, College Park, MD, USA", "person_id": "P1464281", "email_address": "", "orcid_id": ""}, {"name": "Sumit Gulwani", "author_profile_id": "81100315615", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1464282", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542501", "year": "2009", "article_id": "1542501", "conference": "PLDI", "title": "Program verification using templates over predicate abstraction", "url": "http://dl.acm.org/citation.cfm?id=1542501"}