{"article_publication_date": "06-15-2009", "fulltext": "\n Binary Analysis for Measurement and Attribution of Program Performance Nathan R. Tallent John M. Mellor-Crummey \nMichael W. Fagan Rice University {tallent,johnmc,mfagan}@rice.edu Abstract Modern programs frequently \nemploy sophisticated modular de\u00adsigns. As a result, performance problems cannot be identi.ed from costs \nattributed to routines in isolation; understanding code perfor\u00admance requires information about a routine \ns calling context. Ex\u00adisting performance tools fall short in this respect. Prior strategies for attributing \ncontext-sensitive performance at the source level ei\u00adther compromise measurement accuracy, remain too \nclose to the bi\u00adnary, or require custom compilers. To understand the performance of fully optimized modular \ncode, we developed two novel binary analysis techniques: 1) on-the-.y analysis of optimized machine code \nto enable minimally intrusive and accurate attribution of costs to dynamic calling contexts; and 2) post-mortem \nanalysis of op\u00adtimized machine code and its debugging sections to recover its program structure and reconstruct \na mapping back to its source code. By combining the recovered static program structure with dynamic calling \ncontext information, we can accurately attribute performance metrics to calling contexts, procedures, \nloops, and in\u00adlined instances of procedures. We demonstrate that the fusion of this information provides \nunique insight into the performance of complex modular codes. This work is implemented in the HPC-TOOLKIT1 \nperformance tools. Categories and Subject Descriptors C.4 [Performance of sys\u00adtems]: Measurement techniques, \nPerformance attributes. General Terms Performance, Measurement, Algorithms. Keywords Binary analysis, \nCall path pro.ling, Static analysis, Performance tools, HPCTOOLKIT. 1. Introduction Modern programs frequently \nemploy sophisticated modular de\u00adsigns that exploit object-oriented abstractions and generics. Com\u00adposition \nof C++ algorithm and data structure templates typically yields loop nests spread across multiple levels \nof routines. To im\u00adprove the performance of such codes, compilers inline routines and optimize loops. \nHowever, careful hand-tuning is often necessary to 1 HPCTOOLKIT is an open-source suite of performance \ntools available from http://hpctoolkit.org. Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. Copyright &#38;#169; \n2009 ACM 978-1-60558-392-1/09/06. . . $5.00 obtain top performance. To support tuning of such code, \nperfor\u00admance analysis tools must pinpoint context-sensitive inef.ciencies in fully optimized applications. \nSeveral contemporary performance tools measure and attribute execution costs to calling context in some \nform. However, when applied to fully optimized applications, existing tools fall short for two reasons. \nFirst, current calling context measurement tech\u00adniques are unacceptable because they either signi.cantly \nperturb program optimization and execution with instrumentation, or rely on compiler-based information \nthat is sometimes inaccurate or un\u00adavailable, which causes failures while gathering certain calling con\u00adtexts. \nSecond, by inlining procedures and transforming loops, op\u00adtimizing compilers introduce a signi.cant semantic \ngap between the binary and source code. Thus, prior strategies for attributing context-sensitive performance \nat the source level either compro\u00admise measurement accuracy or remain too close to the object code. To \nclarify, we consider the capabilities of some popular tools using three related categories: calling context \nrepresentation, mea\u00adsurement technique and attribution technique. Calling context representation. Performance \ntools typically attribute performance metrics to calling context using a call graph or call path pro.le. \nTwo widely-used tools that collect call graph pro.les are gprof [11] and Intel s VTune [15]. A call graph \npro.le consists of a node for each procedure and a set of directed edges between nodes. An edge exists \nfrom node p to node q if p calls q. To represent performance measurements, edges and nodes are weighted \nwith metrics. Call graph pro.les are often insuf.cient for modular applications because a procedure p \nthat appears on multiple distinct paths is represented with one node, resulting in shared paths and cycles. \nConsequently, with a call graph pro.le it is in general not possible to assign costs to p s full calling \ncontext, or even to long portions of it. To remove this imprecision, a call path pro.le [12] represents \nthe full calling context of p as the path of calls from the program s entry point to p. Call path pro.ling \nis necessary to fully understand the performance of modular codes. Measurement technique. There are two \nbasic approaches for obtaining calling context pro.les: instrumentation and statistical sampling. Instrumentation-based \ntools use one of three principal instrumentation techniques. Tools such as Tau [26] use source code instrumentation \nto insert special pro.ling code into the source pro\u00adgram before compilation. In contrast, VTune [15] \nuses static bi\u00adnary instrumentation to augment application binaries with pro.ling code. (gprof s [11] \ninstrumentation, though traditionally inserted by a compiler, is effectively in this category.) The third \ntechnique is dynamic binary instrumentation. While source-level instrumentors collect measurements that \nare easily mapped to source code, their instrumentation can interfere with compiler optimizations such \nas inlining and loop transforma\u00adtions. As a result, measurements using source-level instrumenta\u00adtion \nmay not accurately re.ect the performance of fully optimized code [28]. Binary instrumentors may also \ncompromise optimiza\u00ad tion. For example, in some compilers gprof-instrumented code cannot be fully optimized. \n An important problem with both source and static binary in\u00adstrumentation is that they require recompilation \nor binary rewriting of a program and all its libraries. This requirement poses a sig\u00adni.cant inconvenience \nfor large, complex applications. More criti\u00adcally, the need to see the whole program before run time \ncan lead to blind spots, i.e., portions of the execution that are systematically excluded from measurement. \nFor instance, source instrumentation fails to measure any portion of the application for which source \ncode is unavailable; this frequently includes critical system, math and communication libraries. For \nFortran programs, this approach can also fail to associate costs with intrinsic functions or compiler\u00adinserted \narray copies. Static binary instrumentation is unable to cope with shared libraries dynamically loaded \nduring execution. The third approach, dynamic binary instrumentation, supports fully optimized binaries \nand avoids blind spots by inserting instru\u00admentation in the executing application [4]. Intel s recently-released \nPerformance Tuning Utility (PTU) [14], includes a call graph pro\u00ad .ler that adopts this approach by using \nPin [18]. However, dynamic instrumentation remains susceptible to systematic measurement er\u00adror because \nof instrumentation overhead. Indeed, all three instrumentation approaches suffer in two dis\u00adtinct ways \nfrom overhead. First, instrumentation dilates total execu\u00adtion time, sometimes enough to preclude analysis \nof large produc\u00adtion runs or force users to a priori introduce blind spots via selec\u00adtive instrumentation. \nFor example, because of an average slowdown factor of 8, VTune requires users to limit measurement to \nso-called modules of interest [15]. Moreover, overhead is even more acute if loops are instrumented. \nA recent Pin-based loop pro.ler in\u00adcurred an average slowdown factor of 22 [22]. Second, instrumen\u00ad tation \ndilates the total measured cost of each procedure, dispropor\u00adtionately in.ating costs attributed to small \nprocedures and thereby introducing a systematic measurement error. The alternative to instrumentation \nis statistical sampling. Since sampling periods can easily be adjusted (even dynamically), this approach \nnaturally permits low, controllable overhead. Sampling\u00adbased call path pro.lers, such as the one with \nIntel s PTU [14], use call stack unwinding to gather calling contexts. Stack unwinding re\u00adquires either \nthe presence of frame pointers or correct and complete unwind information for every point in an executable \nbecause an asynchronous sample event may occur anywhere. However, fully optimized code often omits frame \npointers. Moreover, unwind in\u00adformation is often incomplete (for epilogues), missing (for hand\u00adcoded \nassembly or partially stripped libraries) or simply erroneous (optimizers often fail to update unwind \ninformation as they trans\u00adform the code). In particular, optimized math and communication libraries frequently \napply every trick in the book to critical proce\u00addures (e.g., hot-cold path splitting [6]) just those \nprocedures that are likely to be near the innermost frame of an unwind. Attribution technique. By inlining \nprocedures and transform\u00ading loops, optimizing compilers introduce a semantic gap between the object \nand source code, making it dif.cult to reconcile binary\u00adlevel measurements with source-level constructs. \nCompiler trans\u00adformations such as inlining and tail call optimization cause call paths during execution \nto differ from source-level call paths. Af\u00adter compilers inline procedures and apply loop transformations, \nexecution-level performance data does not correlate well with source code. Since application developers \nwish to understand per\u00adformance at the source code level, it is necessary for tools to collect measurements \non fully optimized binaries and then translate those measurements into source-level insight. Since loops \nare critical to performance, but are often dynamically nested across procedure calls, it is important \nto understand loops in their calling context. Much prior work on loop attribution either compromises \nmea\u00adsurement accuracy by relying on instrumentation [22, 26] or is based on context-less measurement \n[19]. A few sampling-based call path pro.lers [2, 14, 22] identify loops, but at the binary level. Moseley \net al. [22] describe a sampling-based pro.ler (relying on unwind information) that additionally constructs \na dynamic loop/call graph by placing loops within a call graph. However, by not accounting for loop or \nprocedure transformations, this tool attributes performance only to binary-level loops and procedures. \nAlso, by using a dynamic loop/call graph, it is not possible to un\u00adderstand the performance of procedures \nand loops in their full call\u00ading context. To understand the performance of modular programs, as part \nof the HPCTOOLKIT performance tools we built hpcrun, a call path pro.ler that measures and attributes \nexecution costs of unmodi.ed, fully optimized executables to their full calling context, as well as loops \nand inlined code. Achieving this result required novel solutions to three problems: 1. To measure dynamic \ncalling contexts, we developed a context\u00adfree on-line binary analysis for locating procedure bounds and \ncomputing unwind information. We show its effectiveness on applications in the SPEC CPU2006 suite compiled \nwith Intel, Portland Group and PathScale compilers using peak optimiza\u00adtion. 2. To attribute performance \nto user-level source code, we devel\u00adoped a novel post-mortem analysis of the optimized object code and \nits debugging sections to recover its program structure and reconstruct a mapping back to its source \ncode. The ability to expose inlined code and its relation to source-level loop nests without a special-purpose \ncompiler and without any additional measurement overhead is unique. 3. To compellingly present performance \ndata, we combine (post\u00admortem) the recovered static program structure with dynamic call paths to expose \ninlined frames and loop nests. No other sampling-based tool attributes the performance of transformed \nloops in the full calling context of transformed routines for fully optimized binaries to source code. \n In this paper, we describe our solutions to these problems. The major bene.t of our approach is that \nhpcrun is minimally invasive, yet accurately attributes performance to both static and dynamic context, \nproviding unique insight into program performance. Our results are summarized by Figure 1. As shown in \nFig\u00ad ure 1(a), let p . q . r . s be a user-level call chain of four procedures. Procedure p contains \na call site cp (that calls q) em\u00adbedded in loop lp; procedures q and r contain analogous call sites. \nAssume that a compiler inlines call site cq so that code for proce\u00addure r appears within loop lq. Consequently, \nat run time cq is not executed and therefore a procedure frame for r is absent. Using call stack unwinding \nand line map information recorded by com\u00adpilers yields the reconstruction of context shown in Figure \n1(c). By combining dynamic context obtained by call stack unwinding with static information about inlined \ncode and loops gleaned us\u00ading binary analysis, our tools obtain the reconstruction shown in Figure 1(b). \nSpeci.cally, our tools 1) identify that cp and cr are located within loops; 2) detect the inlining; and \n3) nest cr within both its original procedure context r and its new host procedure q. Most importantly, \nreconstructed procedures, loops and inlined frames can be treated as .rst-class entities for the purpose \nof as\u00adsigning performance metrics. The rest of the paper is as follows. Section 2 describes our use of \nbinary analysis to support call path pro.ling of optimized code and evaluates its effectiveness (contribution \n1). Section 3 describes  Figure 1. Correlating call paths with program structure. our binary analysis \nto support accurate correlation of performance measurements to optimized code (contribution 2). Section \n4 high\u00ad lights the rich performance data we obtain by fusing dynamic call paths and static structure \n(contribution 3). Finally, Section 5 dis\u00ad cusses related work; and Section 6 summarizes our conclusions. \n2. Binary Analysis for Call Path Pro.ling Sampling-based call path pro.lers use call stack unwinding \nto gather calling contexts. For such pro.lers to be accurate, they must be able to unwind the call stack \nat any point in a program s execution. A stack unwind, which forms the calling context for a sample point, \nis represented by the program counter for the innermost procedure frame and a list of return addresses \n one for each of the other active procedure frames. Successfully unwinding the call stack requires determining \nthe return address for each frame and moving up the call chain to the frame s parent. Obtaining the return \naddress for a procedure frame without a frame pointer is non-trivial since the procedure s frame can \ndynamically grow (as space is reserved for the caller s registers and local variables, or supplemented \nwith calls to alloca) and shrink (as space for the aforementioned purposes is deallocated) as the procedure \nexecutes. If the return address is kept in the stack (as is typical for non-leaf procedures), the offset \nfrom the stack pointer at which the return address may be obtained often changes as a procedure executes. \nFinding the return address for a procedure frame is simple with correct and complete compiler-generated \nunwind information [10]. Unfortunately, compilers routinely omit unwind information for procedure epilogues \nbecause it is not needed for exception han\u00addling. However, even if compilers generate complete unwind \nin\u00adformation, fully optimized applications often link with vendor li\u00adbraries (e.g., math or OpenMP) that \nhave incomplete unwind tables due to hand-coded assembly or partial stripping. Since codes may spend \na signi.cant fraction of time in procedures that lack proper unwind information,2 dropping or mis-attributing \nsamples that oc\u00adcur in such procedures could produce serious measurement error. To enable accurate unwinding \nof all code, even code lacking compiler-based unwind information, we developed two binary an\u00adalyzers \n one to determine where a procedure begins and ends in partially-stripped code, and a second to compute \nhow to unwind to 2 For example, the S3D turbulent combustion code described in Section 4.2 spends nearly \n20% of its total execution time in the math library s exponen\u00adtiation routine as it computes reaction \nrates. Algorithm 1: High-level sketch of using on-the-.y binary analysis to support call stack unwinding \nof optimized code. Input: B, procedure bounds for each load module Input: U, unwind recipes for procedure \nintervals (splay tree) let F = (PC , FP, SP) be the frame of the sample point (consisting of program \ncounter, frame and stack pointer) while F is not the outermost frame do if U has no unwind recipe for \nPC then let \u00b5 be the load module containing PC if B has no bounds for \u00b5 then Compute bounds for all procedures \nin \u00b5 let p be the procedure (from B) with bounds \u00df containing PC Scan the object code of p, 1) tracking \nthe locations of its caller s program counter, frame and stack pointer; and 2) creating an unwind recipe \nfor each distinct interval let . be the unwind recipe (from U) for PC let F' = (PC ', FP', SP') be the \ncaller s frame, computed using . F.F' a caller s frame from any address within a procedure. At any in\u00adstant, \na frame s return address (which also serves as the program counter for the calling frame) may be located \neither 1) in a register, 2) in a location relative to the stack pointer, or 3) in a location rela\u00adtive \nto the frame pointer (which the frame must have initialized be\u00adfore using). The value of the frame pointer \nfor a caller s frame may be found similarly. To recover the program counter, stack pointer and frame \npointer values for a caller s frame, we compute a se\u00adquence of unwind recipes for a procedure. Each unwind \nrecipe cor\u00adresponds to an interval of code that ends in a frame-relevant instruc\u00adtion. A frame-relevant \ninstruction is one that changes the machine state (e.g., by moving the stack pointer, saving the frame \npointer value inherited from the caller, or initializing the frame pointer for the current frame) in \nsuch a way that a different unwind recipe is needed for instructions that follow. Although procedure \nbounds and unwind recipes could be com\u00adputed off-line, we perform both analyses on demand at run time. \nWe perform binary analysis on each load module to recover the bounds of all of its procedures. This analysis \nis triggered at program launch for the executable and all shared libraries loaded at launch and whenever \na new shared library is loaded with dlopen. The computed procedure-bounds information for a module is \ncached in a table that is queried using binary search. We perform binary anal\u00adysis to compute unwind \nintervals for a procedure lazily the .rst time that the procedure appears on the call stack when a sample \nevent occurs. This approach elegantly handles dynamically loaded shared libraries and avoids wasting \nspace and time computing un\u00adwind recipes for procedures that may never be used. To support fast queries, \nwe memoize unwind recipes in a splay tree indexed by intervals of code addresses. Algorithm 1 shows a \nhigh-level overview of the process of performing on-the-.y binary analysis to support call path pro.ling. \nBecause dynamic analysis must be ef.cient, we prefer fast linear-time heuristics that may occasion\u00adally \nfail over slower fully general methods.3 (An evaluation of our approach in Section 2.3 shows that our \nmethods almost never fail in practice.) In the next two sections, we describe how we infer procedure \nbounds and compute unwind recipes. 3 For example, Rosenblaum et al. [24] developed an off-line analyzer \nto recover procedure bounds in fully stripped code. However, the focus of this work was on thorough analysis \nfor security.  2.1 Inferring Procedure Bounds To compute unwind recipes for a procedure based on its \ninstruction sequence, one must know the procedure s bounds, namely where the procedure begins and ends. \nIn many cases, complete informa\u00adtion about procedure bounds is not readily available. For instance, stripped \nshared libraries have only a dynamic symbol table that contains only information about global procedure \nsymbols; all in\u00adformation about local symbols is missing. Often, libraries are par\u00adtially stripped. For \ninstance, the OpenMP run time library for ver\u00adsion 3.1 of PathScale s x86-64 compiler only has symbol \ninforma\u00adtion for OpenMP API procedures; all information about other pro\u00adcedures is missing. For this \nreason, inferring procedure bounds for stripped or partially stripped code is an important precursor \nto com\u00adputing unwind intervals. Our approach for inferring procedure bounds is based on the following \nobservations. We expect each load module to provide information about at least some procedure entry points. \nPerformance analysis of a stripped executable is typically unproductive. Interpreting measurement results \nis dif.cult without procedure names. For this reason, entry points for user procedures will generally \nbe available for an executable. Dynamically-linked shared libraries have (at a minimum) pro\u00adcedure entry \npoints for externally-visible library procedures. We must perform procedure discovery on all load modules. \nPartially-stripped libraries are not uncommon. There is no a pri\u00adori way to distinguish between a partially-stripped \nload mod\u00adule and one that has full symbol information. We have also encountered (non-stripped) executables \nthat lack information about some procedures. For instance, the SPEC benchmark xalanbmk, when compiled \nwith the PathScale C++ compiler (version 3.1, using -O3) contains small anonymous procedures. Having \nthe proper address for a procedure start is more impor\u00adtant than having the proper address for a procedure \nend. For a procedure with the interval [s, e), incorrectly inferring the procedure end at address e ' \n>e will not change the unwind recipes that we compute for the interval [s, e). We assume all procedures \nare contiguous In other words, we assume a single procedure is not divided into disjoint code segments. \nFor the most part, this assumption holds. We have, however, encountered compilers that employ hot-cold \noptimization [6]. This optimization sometimes splits the procedure into disjoint segments. Furthermore, \nan unrelated procedure may be placed between the disparate parts of the hot\u00adcold-optimized procedure. \nOur treatment of a divided procedure is to treat each part as a separate procedure. Our treatment sim\u00adpli.es \nprocedure discovery, but requires additional considera\u00ad tion when determining the unwind recipe for \nthe various seg\u00adments of a divided procedure. See \u00a72.2 for more information.  Not all false positives \nare equally problematic. We classify false procedures starts into two categories: malig\u00adnant and benign. \nIf we infer a false procedure start in a gap between two real procedures that contains data (e.g., a \njump ta\u00adble for a switch statement), this will not affect the bounds of any real procedures for which \nwe need to compute unwind intervals. For this reason, we call such a false procedure start benign. On \nthe other hand, if we infer a false procedure start s ' in the mid\u00addle of a real procedure ranging from \n[s, e), this may cause us to  compute incorrect unwind information for the interval [s ' ,e). We call \nsuch a false procedure start malignant. 2.1.1 Approach We take an aggressive approach to procedure discovery. \nWithout evidence to the contrary, we assume that the instruction following an unconditional jump or a \nreturn is the start of a new procedure. In optimized code, we have also seen procedures that end with \na call to a procedure that doesn t return (e.g., exit or abort). To handle this case, we infer a function \nstart after a call if we immediately encounter code that is obviously a function prologue. We use the \nfollowing collection of heuristics to avoid inferring a procedure start within a procedure (a malignant \nfalse positive). We call the interval between a conditional branch at an address a and its target at \naddress t a protected interval. No procedure start will be inferred in a protected interval. If a<t, \nthis yields a protected interval [a, t ' ), where t ' is the end of the instruction at address t; otherwise, \nthis yields a protected interval [t, a ' ), where a ' is the end of the instruction at address a. (Conditional \njumps are almost always within procedures. While we have found one or two conditional forward branches \nused as tail calls in libc, other heuristics prevent us from missing procedure starts in this rare case.) \n A backward unconditional jump at address a into a protected interval that extends from [s, e) extends \nthe protected interval to cover the range [s, a ' ), where a ' is the end of the instruc\u00adtion at address \na. (Such jumps often arise at the end of cold path prefetching code that has been outlined from loops \nand deposited after what would have been the end of the procedure.)  Moving the stack pointer upward \nat address a in a procedure prologue (to allocate stack space for local variables ) must be followed \nby a compensating adjustment of the stack pointer in each of the procedure s n epilogues, at addresses \ne1,...,en. Let en be the epilogue with the largest address. We treat the interval [a, e n' ) as a protected. \n Let the interval between initializing the frame pointer register with the value of the stack pointer \nand restoring the value of the frame pointer be a protected interval. Similarly, let the interval between \na store and load of the frame pointer be a protected interval.  A global symbol in the symbol table \nor the dynamic symbol table is always considered a procedure start, even if it lies within a protected \ninterval. In contrast, a local symbol only considered a procedure start if it does not fall within a \nprotected interval.   2.2 Computing Unwind Recipes Because dynamic analysis must be ef.cient, we prefer \nfast linear\u00adtime heuristics that are typically accurate over slower fully general methods. Experiments \ndescribed in Section 2.3 show that our ap\u00ad proach is nearly perfect in practice. Although we initially \ndevel\u00adoped our strategy for computing unwind recipes for x86-64 bina\u00adries, the general approach is architecture \nindependent. We recently adapted it to compute unwind recipes for MIPS and PowerPC bi\u00adnaries to support \ncall path pro.ling on SiCortex clusters and Blue Gene/P, respectively. Our binary analyzer creates an \nunwind recipe for each distinct interval within a procedure. An interval is of the form [s, e) and its \nunwind recipe describes where to .nd the caller s program counter, frame pointer (FP) register value, \nand stack pointer (SP). For example, the caller s program counter (the current frame s return address) \ncan be in a register, at an offset relative to SP or at an offset relative to FP; the value of the caller \ns FP register, which may or may not be used by the caller as a frame pointer, is analogous. The initial \ninterval begins with (and includes) the .rst instruc\u00adtion. The recipe for this interval describes the \nframe s state immedi\u00adately after a call. For example, on x86-64, a procedure frame begins with its return \naddress on the top of stack, the caller s value of FP in register FP, and the caller s value of SP at \nSP-8, just below the return address. In contrast, on MIPS, the return address is in regis\u00adter RA and \nthe caller s value of FP and SP are in registers FP and SP, respectively.  The analyzer then computes \nunwind recipes for each interval in the procedure by determining where each interval ends. (Intervals \nare contiguous and cannot overlap.) To do this, it performs a linear scan of each instruction in the \nprocedure. For each instruction, the analyzer determines whether that instruction affects the frame. \n(For x86-64, where instruction decoding is challenging, we use Intel s XED tool [5].) If so, the analyzer \nends the current interval and creates a new interval at the next instruction. The unwind recipe for the \nnew interval is typically created by applying the instruction s effects to the previous interval s recipe. \nAn interval ends when an instruction: 1. modi.es the stack pointer (pushing registers on the stack, sub\u00adtracting \na .xed offset from SP to reserve space for a procedure s local variables, subtracting a variable offset \nfrom SP to support alloca, restoring SP with a frame pointer from FP, popping a saved register), 2. \nassigns the value of SP to FP to set up a frame pointer, 3. jumps using a constant displacement to an \naddress outside the bounds of the current procedure (performing a tail call), 4. jumps to an address \nin a register when SP points to the return address, 5. returns to the caller, 6. stores the caller \ns FP value to an address in the stack, or 7. restores the caller s FP value from a location in the stack. \n There are several subtleties to the process sketched above: fol\u00adlowing a return or a tail call (items \n4 and 5 above), a new interval begins. What recipe should the new interval have? We initialize the interval \nfollowing a tail call or a return with the recipe for the inter\u00adval that we identify as the canonical \nframe. We use the following heuristic to determine the canonical frame C. If a frame pointer rel\u00adative \n(FP) interval was found in the procedure (FP was saved to the stack and later initialized to SP), let \nC be the .rst FP interval. Oth\u00aderwise, we continue to advance C along the chain of intervals while the \nframe size (the offset to the return address from the SP) is non\u00addecreasing, and the interval does not \ncontain a branch, jump, or call. We use such an interval as a signal that the prologue is complete and \nthe current frame is the canonical frame. In addition, whenever a return instruction is encountered during \ninstruction stream pro\u00adcessing, we check to make sure that the interval has the expected state: e.g., \nfor x86-64, the return address should be on top of the stack, and the FP should have been restored. If \nthe interval for the return instruction is not in the expected state, then the interval that was most \nrecently initialized from the canonical frame is at fault. When a return instruction interval anomaly \nis detected, we adjust all of the intervals from the interval reaching the return back to the interval \nthat was most recently initialized from the canonical frame. To handle procedures that have been split \nvia hot-cold optimiza\u00adtion, we check the end of the current procedure p for a pattern that indicates \nthat p is not an independent procedure, but rather part of another one. The pattern has two parts: 1. \np ends with an unconditional branch to an address a that is in the interior of another procedure q. \n2. The instruction preceding a is conditional branch to the begin\u00adning of p.  When the hot-cold pattern \nis detected, all intervals in p are adjusted according to the interval computed for a. Integer programs \nOverhead (percent) Unwind Failures hpc PTU- PTU\u00ad hpc PTU-smpl Benchmark run smpl Pin run Intel Others \nperlbench 1.3 0.9 1043.3 0.0 4.5% 87.5% bzip2 2.9 0.9 197.1 0.0 0.8% 52.2% gcc 3.2 1.3 300.9 15.1 4.5% \n70.7% mcf 1.3 2.6 8.5 0.0 0.1% 60.4% gobmk 1.7 1.3 481.3 0.1 2.4% 71.6% hmmer 0.4 1.0 36.4 0.0 0.1% 74.4% \nsjeng 0.3 1.6 694.4 0.0 19.2% 100.0% libquantum -0.2 -0.2 16.3 0.0 0.1% 99.9% h264ref 0.1 0.0 784.2 0.6 \n21.9% 69.7% omnetpp 1.6 1.7 701.2 0.0 1.4% 49.4% astar 1.6 1.7 184.1 0.0 0.5% 57.6% xalancbmk 9.5 10.8 \n732.0 0.0 1.0% 0.4% Average* 2.0 1.9 431.6 1.3 4.7% 66.1% Std. Dev. 2.6 2.8 353.4 4.3 7.6% 26.6% Floating-point \nprograms bwaves 1.7 1.9 9.9 0.0 0.0% 66.6% gamess 0.8 0.1  0.0 0.3% 99.7% milc 0.6 0.4 61.0 0.0 0.0% \n99.9% zeusmp 2.1 2.0  0.0 0.0% 99.7% gromacs 0.6 0.4 57.3 0.0 0.1% 100.0% cactusADM 1.6 1.5 6.7 0.0 \n0.0% 100.0% leslie3d 2.0 1.7 2.5 0.0 0.0% 93.5% namd 0.2 1.5 5.1 0.0 0.0% 42.0% dealII 0.5 0.7 1746.4 \n0.0 2.7% 83.8% soplex 1.6 1.8 19.3 0.0 2.0% 54.3% povray 0.1 0.3 1732.8 0.0 6.5% 49.8% calculix -0.5 \n0.9 62.5 0.0 0.2% 99.5% GemsFDTD -0.8 -1.2 45.3 0.0 0.1% 74.9% tonto 0.3 1.3 287.4 0.0 11.1% 98.0% lbm \n0.9 1.2 10.2 0.0 0.0% 13.5% wrf 3.0 1.5 59.5 0.5 0.0% 98.2% sphinx3 0.4 2.4 84.7 0.0 1.9% 48.0% Average* \nStd. Dev. 0.9 1.0 1.1 0.9 279.4 566.0 0.0 0.1 1.5% 3.0% 77.7% 27.1% * Neither the arithmetic nor geometric \nmean summarizes these values well. PTU-Pin failed to execute any version of these benchmarks. Table 1. \nComparing hpcrun and PTU on SPEC CPU2006. In the linear scan between the start and end address of a pro\u00adcedure, \nthe analyzer may encounter embedded data such as jump tables. This may cause decoding to fail or lead \nto corrupt intervals that would leave us unable to unwind. Although such corrupt in\u00adtervals could cause \nunwind failures (we note such failures in a log .le), we have not found them to be a problem in practice. \n 2.3 Evaluation To evaluate the ef.ciency and effectiveness of our binary analyses for unwinding against \ncontemporary tools, we compared hpcrun with two of the tools from Intel s Performance Tuning Utility \n(PTU) [14] PTU s call stack sampling pro.ler (PTU-smpl) and PTU s Pin-based call graph pro.ler (PTU-Pin) \n using the SPEC CPU2006 benchmarks [27]. Since PTU is designed for Intel archi\u00ad tectures, this evaluation \nfocuses on analysis of x86-64 binaries. We compiled two versions of each benchmark, distinguished by \nbase or peak optimization, using the Intel 10.1 (20080312), PathScale 3.1 and Portland Group (PGI) 7.1-6 \ncompilers; this resulted in six versions of each benchmark. We used the following base and peak optimization \n.ags: for Intel, -O3 and -fast (but with static linking disabled); for PathScale, -O3 and -Ofast; for \nPGI, -fast -Mipa=fast, inline. To permit high-throughput testing, experi\u00adments were performed on a cluster \nwhere each node is a dual-socket Intel Xeon Harpertown (E5440) with 16 GB memory running Red Hat Enterprise \nLinux 5.2. Table 1 summarizes our results.  2.3.1 Ef.ciency The .rst multi-column of Table 1 compares \nthe average overhead of hpcrun with PTU-smpl and PTU-Pin. We .rst observe that despite PTU-Pin s sophistication, \ndynamic binary instrumentation is not an acceptable measurement technique for two reasons. First, compared \nto a worst case sampling overhead of about 10% (average of 1-2%), instrumentation can introduce slowdown \nfactors of 10\u00ad 18. Second, the drastic variation in overheads strongly suggests that Pin s instrumentation \ndilates the execution of small procedures and introduces systematic distortion. Because of the extremely \nlong run times and the clear advantage of sampling, we chose not to collect PTU-Pin results on executables \ngenerated by non-Intel compilers, assuming that an Intel tool used with an Intel-generated executable \nrepresents a best-case usage. Both hpcrun s and PTU-smpl s results are averaged over all six versions \nof the benchmarks; each tool used a 5 ms sampling period, yielding approximately 200 samples/second. \nBecause of hpcrun s additional dynamic binary analysis, one might expect it to incur more overhead. However, \nour results show that a reasonable execu\u00adtion time and sampling rate quickly amortizes the binary analysis \noverhead over thousands of samples and makes it negligible.4 In fact, the overhead differences between \nhpcrun and PTU are sta\u00adtistically insigni.cant. This is seen in two ways. First, the average overheads \nfor each set of benchmarks are very similar; and given the high standard deviations, a statistical test \nwould not meaning\u00adfully distinguish between the two. Second, average overheads for the individual benchmarks \nare within within 1-2% of each other, but no tool consistently performs better. Moreover, these small \ndif\u00adferences are well within the natural execution-time variability for a standard operating system (especially \nwhen using shared I/O) [23]; this fact accounts for the small negative overheads. The one benchmark for \nwhich both hpcrun and PTU incur meaningful overhead is xalancbmk, at around 10%. The reason is that xalancbmk \nhas many call paths that are 1000-2000 invocations long. An earlier version of hpcrun for the Alpha platform \nused a technique of inserting an active return on a sample to memoize stack unwinds and collect return \ncounts [9]. We plan to implement this technique and expect that it will signi.cantly reduce hpcrun s \noverhead in such cases. 2.3.2 Effectiveness Given that hpcrun and PTU-smpl incur comparably low over\u00adheads, \nmulti-column two of Table 1 assesses the quality of their call path pro.les in terms of unwind failures. \nAn unwind failure is de.ned as the inability to collect a complete calling context. Note that for hpcrun, \nthis metric directly assesses the quality of unwind recipes and indirectly re.ects the accuracy of procedure \nbounds. This is a reasonable metric because we have designed hpcrun s binary analyses to cooperate for \nthe purpose of obtaining accurate unwinds. There are two ways to directly measure unwind failures. The \nmost comprehensive method uses binary analysis to attempt to verify each link in the recovered call chain. \nFor each each step in the unwind, we have a segment p . q and a return address (RA) within p. The analysis \ncan then certify the unwind from q to p as (almost certainly) valid, likely, or (provably) invalid: valid, \nif a statically-linked call to q immediately precedes RA 4 Although it is more dif.cult to amortize the \noverhead of our binary anal\u00adyses for very short executions, this does not imply that for such executions \ntools like PTU-smpl that use statically-computed unwind information in\u00adduce signi.cantly less overhead. \nBecause typical compiler-generated un\u00adwind information is stored sparsely, a tool like PTU-smpl must \ninvest some effort to read and interpret it. valid, if a dynamically-linked call to q immediately precedes \nRA (via inspection of the procedure linkage table)  likely, if a dynamically-dispatched call immediately \nprecedes RA  likely, if a call to procedure r immediately precedes RA, and r is known to have tail calls \n invalid, if none of the above apply  Two details are worth noting. First, for architectures with variable\u00adwidth \ninstructions, it is reasonable to simply test offsets from RA that correspond to possible call or jump \ninstructions rather than disassembling from the beginning of the procedure. Second, delay slots will \noffset the location of the call site. The second way to measure unwind failures is based on the observation \nthat, in practice, if an unwinder attempts to use an incorrect frame or stack pointer, errors very quickly \naccumulate and result in return addresses that are provably wrong in that they do not correspond to mapped \ncode segments. Also, hpcrun s program monitoring technology is able to intercept a process s or thread \ns entry point (for both statically and dynamically linked binaries). Thus, this second method classi.es \nan unwind as invalid if it .nds a provably wrong return address or if the unwind is not rooted in the \nprocess s or thread s entry point. hpcrun currently implements the second method and discards all invalid \nunwinds. We are in the process of implementing the .rst, stronger version. In contrast, for PTU-smpl, \nwe measured unwind failures indi\u00adrectly. PTU-smpl does retain partial unwinds; and if it performs any \nsort of veri.cation, that information is not exported. Therefore, we wrote a script to analyze the results \nof PTU-smpl s hot path listing. The script classi.es a path as valid if it is rooted at some variant \nof main or any ancestor frame. Observe that this require\u00adment is more relaxed than hpcrun s. It is also \nworth noting that this requirement does not not penalize PTU-smpl for skipping a frame by incorrectly \nfollowing its parent s frame pointer rather than its own an easy mistake for an x86-64 tool that is \nunwinding from an epilogue or frame-less procedure and that relies on compiler\u00adgenerated unwind information. \nOur results showed radically different failure rates for PTU\u00adsmpl on Intel-generated code (5%) versus \nPathScale and PGI code (65-75%). Since PTU-smpl is dependent upon frame pointers and unwind information, \nand since frame pointers are not reliably main\u00adtained in these binaries, the results strongly suggest \nthat, compared to PathScale and PGI, the Intel compiler places a much higher pri\u00adority on consistently \nrecording correct unwind information. How\u00adever, even on Intel-generated binaries, PTU-smpl can have high \nenough failure rates as high as 5-20% that it risks introducing systematic distortion by failing to \nunwind through a commonly ap\u00adpearing procedure instance. On the non-Intel benchmark versions, PTU-smpl \ns failure rate is so high that it essentially becomes a call path fragment pro.ler. In contrast, the \nnumber of unwind failures for hpcrun is vanish\u00adingly small. hpcrun s failures are reported as the average \nnumber (not percent) of failures over all six benchmark versions. Its worst performance was on the gcc \nbenchmark. The benchmark averages on the order of 100K samples. Across the six versions of the bench\u00admark \nthat we studied, hpcrun failed to gather a full call path for 16 of those samples on average.  2.3.3 \nSummary Despite the fact that hpcrun s binary analysis for unwind recipes is a) context insensitive, \nb) operates without a control .ow graph, c) does not formally track register values, and d) cannot treat \nembedded data as such, these results show that the cost of our  (LM /mypath/hmc load module (File /mypath/hmc.cc \nsource .le (Proc doHMC 257-449 {[0xabe-0xfeed)} procedure (Stmt 309-309 {[bab1-0xbabe)} ) statement (Loop \n311-435 {[0xdad-0xfad)} loop (Stmt 313-313 {[0xdaf-0xea1), [ee1-0xeef)} ) )))) Figure 2. An object to \nsource-code-structure map. analysis is very modest and its results are very effective. Given that hpcrun \nalmost always collects a full call path and that PTU-smpl much more frequently fails, we can say that \non average hpcrun performs more useful work per sample than PTU-smpl at the same overhead. The clearest \ndownside to our approach is the effort we have invested in developing these heuristics. The x86 unwinder \nwas the most dif.cult to write, in large part because of its irregular architecture and variable-sized \ninstructions. Nevertheless, once we arrived at the general approach we were able to relatively quickly \ndevelop MIPS and PowerPC unwinders. For example, we wrote the PowerPC unwinder for use on Blue Gene/P \n and resolved some OS-speci.c issues in about a week and a half. During our .rst major test, we collected \nperformance data for an 8192-core execution of the FLASH astrophysics code [7] compiled with the IBM \nXL Fortran and C compilers for BG/P (versions 11.1 and 9.0, respectively) using options -O4 -qinline \n-qnoipa.5 Out of approximately 1 billion total samples, hpcrun failed to unwind approximately 13,000 \ntimes a failure rate of .0013%. 3. Binary Analysis for Source-Level Attribution To combine dynamic call \npath pro.les with the static structure of fully optimized binaries, we need a mapping between object \ncode and its associated source code structure. An example of what this mapping might look like is shown \nin Figure 2. The mapping is represented as a scope tree, where a load module (a binary) contains source \n.les; .les contain procedures; procedures contain loops; procedures and loops contain statements; and \nscopes such as procedures, loops and statements can be annotated with object code address interval sets. \nThere are two ways to obtain the desired mapping: use a sum\u00admary of transformations recorded by the compiler \nor reconstruct it through analysis. Because debuggers must associate the execu\u00adtion of object code with \nsource code, one would expect debugging information to provide the former. In 1992, Brooks et al. [3] \ndevel\u00ad oped debugging extensions for mapping object code to a scope tree of procedures, loops, blocks, \nstatements and expressions. While they left to future work a solution for the inlining problem, nei\u00adther \ncompilers nor debugging formats followed their lead. Although DWARF [8], the de facto standard on Linux, \ncan represent inlin\u00ading, it cannot describe loops or loop transformations. Even worse, all x86 Linux \ncompilers that we have used generate only limited DWARF, often failing to record inlining decisions. \nIntel s com\u00adpiler (10.x) retains line-level information in the presence of inlin\u00ading, but the information \nis incomplete (e.g., there is no association between inlined code and object code) and sometimes erroneous. \nThus, however easy the problem of creating the object to source code mapping could have been, the fact \nremains that vendor com\u00adpilers do not provide what we desire. Consequently, we wrote the hpcstruct tool \nto reconstruct the mapping through binary analy\u00adsis, using only a lowest common denominator set of debugging \ninformation. We focus on programs written in C++, C, and Fortran. 5 We were forced to disable inter-procedural \nanalysis because of an incom\u00adpatibility between IBM s compiler and our tool for inserting hpcrun in statically-linked \nbinaries. Address File Line Procedure 0x...15550 hmc.cc 499 main 0x...15570 hmc.cc 14 main 0x...17030 \nqdp multi.h 35 main 0x...172c0 stl tree.h 1110 main Figure 3. Typical line map information. An obvious \nstarting point is to consult an executable s line map, which maps an object address to its corresponding \nsource .le, line number and procedure name for use by a debugger. However, the line map is insuf.cient \nfor detecting inlined, or more generally, alien code, i.e., code that originates outside of a given procedure. \nTo see this, consider the unexceptional line map excerpt from a quantum chromodynamics code shown in \nFigure 3. Given that the .rst entry maps to native (as opposed to alien) code, what is the .rst line \nof procedure main? Although one is tempted to answer 14, it turns out that the second line is actually \nalien; this is not detectable because the line map retains the original .le and line in\u00adformation (from \nbefore inlining) but assumes the name of the host procedure (after inlining). Even worse, because optimizing \ncom\u00adpilers reorder the native and alien instructions (including prologues and epilogues), no particular \nentry is guaranteed to map to native code, much less the procedure s begin or end line. Consequently, \nto reconstruct the desired mapping we must supplement the line map with a lowest common denominator set \nof DWARF-speci.c information. 3.1 Recovering the Procedure Hierarchy Compilers perform several procedure \ntransformations such as .attening nested procedures, inlining, and cloning for special\u00adization. Recovering \nthe procedure hierarchy involves re-nesting source code procedure representations, determining their \nsource line bounds and identifying alien code. It turns out that by combining standard DWARF information \nwith certain procedure invariants, recovering the procedure hierar\u00adchy is less dif.cult than it .rst \nappears. A load module s DWARF contains procedure descriptors for each object procedure in the load module \nand the nesting relationship between the descriptors. Each descriptor includes 1) the procedure s name, \n2) the de.ning source .le and begin line, and 3) its object address ranges. The key miss\u00ading piece of \ninformation is the procedure s end line. Observe how\u00adever, that two source procedures do not have overlapping \nsource lines unless they are the same procedure or one is nested inside the other. Intuitively, in block \nstructured languages, source code does not overlap. More formally: Non-overlapping Principle. Let scopes \nx1 and x2 have source line intervals s1 and s2 within the same .le. Then, either x1 and x2 are the same, \ndisjoint or nested, but not overlapping:6 (x1 = x2) . (s1 = s2)  (x1 = \u00d8) . (s1 . s2) . (s2 . s1)) \n = x2) . ((s1 n s2 We can also say (where x2 8-x1 means x1 is nested in x2): (s1 n s2 = \u00d8) . ((x1 = \nx2) .\u00ac(x1 8-x2) .\u00ac(x2 8-x1))  (s2 . s1) . (x1 8-x2)  The implication of this principle is that given \nDWARF nesting information, we can infer end line bounds for procedures, resulting in the following invariants: \nProcedure Invariant 1. A procedure s bounds are constrained by any (parent) procedures that contain it. \n6 Unstructured programming constructs may give rise to irreducible loops or alternate procedure entries. \nWhile the former is not strictly an exception (no block of source code actually overlaps), the latter \nis. However, Fortran s alternate entry statement is deprecated and used very infrequently.  Figure \n4. Bounding procedure end lines. Procedure Invariant 2. Let procedure y have sibling procedures x and \nz before and after it, respectively. Then, y s begin line is greater than x s end line and its end line \nis less than z s begin line.7 Figure 4a graphically depicts application of this invariant. Neither C++ \nnor C permits procedure nesting. To handle For\u00adtran, which places strict limits on where a procedure \ncan be nested, we derive a special invariant (depicted graphically in Figure 4b):8 Procedure Invariant \n3. Let procedure Y have nested procedures x1 ...xn, in that order. Then Fortran nesting implies that \nthe exe\u00adcutable code of Y and x1 ...xn forms n +1 ordered, contiguous source code regions. These invariants \nenable hpcstruct to infer an upper bound on all procedure end lines except for the last top-level procedure \nof a source .le, whose upper bound is 8. Moreover, accurate procedure bounds information is suf.cient \nfor detecting all alien code within a procedure (assuming two restrictions discussed below). There are \ntwo complications with this strategy. First, it is often the case that a load module s DWARF does not \ncontain a DWARF descriptor for every source level procedure, creating gaps in the procedure hierarchy. \nFor example, no descriptor is generated for a C++ static procedure inlined at every call site. Although \nthis knowl\u00adedge can never be fully recovered, we have developed a simple and effective heuristic to close \nmost of the important gaps [28]. Second, C++ permits classes to be declared within the scope of a procedure, \nthereby allowing class member functions to be transitively nested within that procedure. Consider a procedure\u00adscoped \nC++ class with n member functions. The nth member function may be inlined into the procedure but because \nthe only end line bound we can establish on the nth member function is the end line bound of the containing \nprocedure itself, we will not be able to detect it. This means that in the presence of procedure\u00adscoped \nclasses, even with DWARF descriptors for every procedure we may not be able to detect all alien code. \nHowever, this issue is of little practical concern: procedure-scoped classes are rare; and we have developed \na strategy for detecting the presence of most procedure-scoped classes [28]. A high-level sketch of hpcstruct \nis shown in Algorithm 2. It consists of two parts: recovering the procedure hierarchy and recovering \nloop nests for each procedure. This section has covered the .rst part; the second part is covered below. \n 3.2 Recovering Alien Contexts Before discussing loops, we note three important aspects of detect\u00ading \nalien code. Figure 5a shows an example of two alien scopes, A1 and A2, representing the presence of alien \ncode within procedure zoo. Con\u00adsider the task of identifying the alien code within zoo. In general, 7 \nWe can ignore the case where two procedures are de.ned on the same source line; column information would \nmake this precise. 8 Because DWARF contains a language identi.er, this nesting rule can be applied only \nwhen appropriate. (File main.cpp (Proc ... (Proc zoo 10-100 (Alien1 ... (Loop1 ... ... A1 (Alien zoo \nmoo.cpp:10-13 ... ) (Alienm ... L1 (Loop 20-50 (Loop... m A2 (Alien zoo moo.cpp:10-15 (Alienm+1 ... ... \n) (Stmt ...) Figure 5. (a) Alien context ambiguity; (b) Maximum procedure context nesting for scope s. \ngiven an object code instruction, its corresponding source level statement is classi.ed as alien if its \nsource .le is different than the enclosing procedure s or if its source line is outside the line bounds \nof the enclosing procedure s. However, as an instruction is processed, adjacent instructions may belong \nto different alien contexts (i.e., different inlined procedures). Since inlining can be nested, it is \nnatural to ask how to distinguish between nested and non-nested inlining. The short answer is that without \nDWARF in\u00adlining or source-level call graph information, we cannot. Therefore, we choose to .atten alien \nscopes with respect to their enclosing loop or procedure. This implies that for a loop nest of depth \nm, there can be at most m +2 parent contexts (procedure or alien scopes), as illustrated in Figure 5b. \nReturn again to Figure 5a. Observe that A1 and A2 have over\u00adlapping bounds, where A2 is embedded within \nloop L1. Without call site information, it is not possible to distinguish between 1) one distinct call \nsite within the loop, where some of the inlined code was was loop invariant; or 2) two distinct call \nsites where some of the code from the .rst call site (A1) was entirely eliminated. Finally, the number \nand bounds of alien scopes can be re.ned using the Non-overlapping Principle [28].  3.3 Recovering Loop \nNests Having an outline of the procedure hierarchy, hpcstruct recovers the loop nesting structure for \neach procedure. As shown in Algo\u00adrithm 2, this task can be broadly divided into two components: 1) analyzing \nobject code to .nd loops (line 7) and 2) inferring a source code representation from them (line 9). To \n.nd loop nests within the object code, hpcstruct .rst decodes the machine instructions in a procedure \nto compute the control .ow graph (CFG) and then uses Havlak s algorithm [13] to recover the tree of loop \nnests [19]. Given this tree of object code loops, hpcstruct then recovers a source code representation \nfor them. This is a challenging problem be\u00adcause with fundamentally line-based information hpcstruct \nmust distinguish between 1) loops that contain inlined code, 2) loops that may themselves be inlined, \nand 3) loops that may be inlined and contain inlined code. Finally, hpcstruct must account for loop transformations \nsuch as software pipelining. Because loops also obey the Non-overlapping Principle, there are analogous \nloop invariants for Procedure Invariants 1 and 2. However, without symbolic loop information, these invariants \nare of little value. Consequently, hpcstruct s strategy is to initially assume that the source loop nesting \ntree mirrors the object code loop tree, and then look for exceptions. Speci.cally, hpcstruct performs \na preorder traversal of the object loop tree, recursively visiting outer loops before inner loops. The \nchallenge we now discuss is reconstructing a source representation for every loop during this traversal. \nAs a starting point, we observe that loop invariant code motion implies that a computation at loop level \nl will (usually) not be moved into a loop that is at a nesting level deeper than l. Coupling this observation \nwith accurate procedure bounds, we could scan through all the non-alien statements within a particular \nloop and compute a minimum and maximum line number, which we call the min-max heuristic.  Algorithm \n2: High-level sketch of recovering a binary s static source code structure. Input: A load module lm (with \nDWARF information) Result: S, lm s object to source code structure map let D, dwarf map : object-procedure \n. DWARF-descriptor let L, line map : address .(.le-name, proc-name, line) // Recover procedure hierarchy \n(\u00a73.1) Create a source procedure pS for each DWARF descriptor in D with no object code Create a source \nprocedure pS for each object-procedure pO using D(pO) or L(pO). // Recover loop nests (\u00a73.3) foreach \nprocedure pS in S with object-procedure pO do 7 Form pO s loop nests by creating the strongly connected \nregions tree T induced by pO s control .ow graph 9 foreach basic block b in T (preorder traversal) do \nif b is a loop header then let s .L(i) for backward-branch i let esS . determine-context(s) Create a \nsource code loop lS located within esS foreach instruction i in b do let s .L(i) let esS . determine-context(s) \nCreate a statement scope sS for s within esS Normalize each procedure p in S (\u00a73.4) (File main.cpp Steps \n(Proc init 145-199 A1 (Alien ... Array.cpp:82-83 1. Find alien context S1 (Stmt 82-82) L2 (Loop 83-83 \n2. Locate loop (incorrectly) S2 (Stmt 83-83) (Alien ... main.cpp (Stmt 158-158)  :158-158 A3 3. Self \nnesting! S3 Figure 6. Detecting incorrect loop placement via nesting cycles. One complication for the \nmin-max heuristic is Fortran s use of statement functions, which are single-statement functions nested \nwithin a procedure. Statement functions have no associated DWARF descriptors. Code for statement functions \nis forward substituted wherever they are used. Applying the min-max heuristic to the .rst loop of a procedure \nthat uses a statement function will result in a loop begin line that erroneously includes all executable \nstatements prior to the loop. To prevent this problem, we would like some mechanism for estimating the \nbegin line of a loop. When loops are compiled to object code, the loop header s continuation test is \ntypically translated into a conditional backward branch that, based on the result of the continuation \ntest, returns to the top of the loop or falls through to the next instruction. Moreover, most compil\u00aders \nassociate the loop s backward branch with the source line of the continuation test, and therefore the \nloop header. We therefore modify the simple min-max heuristic to form the bbranch-max heuristic for computing \nloop begin and end lines: the loop begin line can be approximated using information from the backward \nbranch; and the best loop end line is the maximum line after all alien lines have been removed. Although \nthe bbranch-max heuristic can be thwarted by un\u00adstructured control .ow, it suffers from a more serious \ndefect. The dif.culty is that when estimating a loop s begin line from that loop s continuation test, \nthe heuristic implicitly determines the loop s procedure context, i.e., the loop s enclosing alien or \nproce- Before After (File main.cpp (File main.cpp (Proc init 145-199 (Proc init 145-199 A1 (Alien Array.cpp:82-83> \n(Alien Array.cpp:82-83 (Stmt 82-82) (Stmt 82-82) ) L1 (Loop 83-83) (Loop 158-158 (Alien Array.cpp:82-83 \nS2 (Stmt 83-83) (Stmt 83-83) ) (Alien main.cpp:158-158 S3 (Stmt 158-158 ) (Stmt 158-158) Figure 7. Correcting \nnesting cycles. dure scope. Speci.cally, bbranch-max assumes that the procedure context for that instruction \nis the same context as other instructions within the (object) loop body. This results in a severe problem \nif the loop s condition test derives from inlined code, something that is very common within object-oriented \nC++. Therefore, it is neces\u00adsary to somehow distinguish between a loop deriving from an alien context \n(and which itself may have alien loops) and one that only contains alien contexts within its header or \nbody. As previously suggested, our solution to this problem, is to guess and correct. In brief, hpcstruct \nprocesses instructions within a loop one-by-one (Algorithm 2, line 9); and for each instruction it determines \nthat instruction s procedure context, its source line location within that context, and its enclosing \nloop (if any). Figure 6 shows a partially reconstructed procedure where alien scope A1 has been identi.ed \n(Step 1) by using the source line information for the instruction cor\u00adresponding to S1. When hpcstruct \nprocesses the loop header (S2) for L2 using bbranch-max (Step 2), it must determine whether the source \nline loop should be located in the current procedure context, a prior context (which would imply the \ncurrent context is alien), or a new alien context. In this case, because of the presence of state\u00adment \nS2, hpcstruct guesses that the loop header should be lo\u00adcated within the current alien procedure context \nA1. hpcstruct next processes S3 (Step 3), which it determines must be alien to the current procedure \ncontext A1, resulting in the new alien con\u00adtext A3. However, because A3 s bounds are within init s bounds, \nthis implies that init is inlined inside of itself, which is a contra\u00addiction. This shows that the guess \nat Step 2 was wrong. This observation, which is another implication of the Non\u00adoverlapping Principle, \ncan be formally stated as follows: Procedure Invariant 4. Let L be a loop nest rooted in an alien scope \nCa. Furthermore, let L have loop levels 1 ...n. Now, let s be a statement at level n that clearly belongs \nin a shallower procedure context C '. Since C ' is a shallower procedure context, it must be a parent \nof Ca which implies that C ' is nested within itself, which is impossible. When an impossibility such \nas this is found, hpcstruct, knowing that L was mislocated, corrects the situation by relocating all \nlevels of L from Ca to within C '. Figure 7 shows how we correct the loop nesting cycle shown in Figure \n6. In this case, L1 is un-nested one level, which places it within the correct procedure context and \nits bounds are updated to include S3. S2 remains nested in L1, but A1 s context must be replicated to \ncorrectly represent it. (The fact that a loop nest of depth m can have at most m +2 parent contexts bounds \nthe cost of this correction process in practice.) Observe that to properly recover the corrected L1, \nit is critical to appropriately expand its begin line so that statements that should belong in the loop \nare not ejected. To do this, we use a tolerance factor when testing for a statement s inclusion within \nthe current loop. If the current begin line minus the tolerance factor would include the statement within \nthe bounds, the statement is deemed to be within the loop and the bounds grow accordingly; the loop s \nend line can thought of having a tolerance of 8 to assign the maximum line within the loop as the end \nline. The effects of fuzzy matching can be complex, because a loop may initially appear to be within \nan alien context (by backward branch information) but later emerge as a native loop. To account for this, \nhpcstruct uses different tolerances based on context [28].  3.4 Normalization Because of loop transformations \nsuch as invariant code motion and software pipelining, the same line instance may be found both within \nand outside of a loop or there may be duplicate nests that appear to be siblings. To account for such \ntransformations, we developed normalization passes based on the observation that a particular source \nline (statement) appears uniquely with a source .le (an application of the Non-overlapping Principle). \nFor its most important normalization passes, hpcstruct repeatedly applies the following rules until a \n.xed point is reached: Whenever a statement instance (line) appears in two or more disjoint loop nests, \nfuse the nests but only within the same procedure context. (Correct for loop splitting.)  Whenever a \nstatement instance (line) appears at multiple dis\u00adtinct levels of the same loop nest (i.e., not crossing \nprocedure contexts), elide all instances other than the most deeply nested one. (Correct for loop-invariant \ncode motion.)   3.5 Summary Thorough application of a small set of invariants enables hpcstruct to \nrecover very accurate program structure even in the presence of complex inlining and loop transformations. \nImportantly, in the (rare) worst case, while the effects of an incorrect inference may be compounded, \nthey are limited to at most one procedure. Fur\u00adther details, including discussions of macros, procedure \ngroups and algorithms can be found in [28]. We have tested hpcstruct on the GCC, Intel, PathScale, Port\u00adland \nGroup and IBM XL compilers (among others). When debug\u00adging information is accurate, hpcstruct produces \nvery good re\u00adsults. However, we have observed that debugging information from certain compilers is sometimes \nerroneous and even violates the DWARF standard. We have hardened hpcstruct to handle certain errors, \nbut it cannot psychoanalyze. While compilers may opt to generate incomplete information, the information \nthat they do gen\u00aderate should be correct. 4. Putting It All Together By combining hpcrun s minimally \nintrusive call path pro.les and hpcstruct s program structure, we relate execution costs for a fully \noptimized executable back to static and dynamic contexts overlaid on its source code. To demonstrate \nour tools capabilities for analyzing the performance of modular applications, we present screen shots \nof HPCTOOLKIT s hpcviewer browser displaying performance data collected for two modern scienti.c codes. \n4.1 MOAB We .rst show the detailed attribution of performance data for MOAB, a C++ library for ef.ciently \nrepresenting and evaluat\u00ading mesh data [29]. MOAB implements the ITAPS iMesh inter\u00ad face [16], a uniform \ninterface to scienti.c mesh data. We compiled MOAB on an AMD Opteron (Barcelona) based system using the \nIntel 10.1 compiler with -O3. (We could not use -fast because of a compiler error.) We pro.led a serial \nexecution the mbperf performance test using a 200 \u00d7 200 \u00d7 200 brick mesh and the array-based/bulk interface. \nFigure 8(a) shows a calling context tree view of a call path pro.le of MOAB. The navigation pane (lower \nleft sub-pane) shows a partial expansion of the calling context tree. The infor\u00admation presented in this \npane is a fusion of hpcrun s dynamic and hpcstruct s static context information. The selected line in \nthe navigation pane (at the bottom) corresponds to the highlight in the source pane (top sub-pane). The \nnavigation pane focuses on the hottest call path (auto\u00admatically expanded by hpcviewer with respect to \nL1 data cache misses). A closer look reveals that the path contains six loops dynamically nested within \ninlined and non-inlined procedure ac\u00adtivations. The root of the path begins prosaically with main . testB \nbut then encounters an inlined procedure and loop from mbperf_iMesh.cpp. The inlined loop makes a (non-inlined) \ncall to imesh_getentadj which descends through several layers of mesh iteration abstractions. Near the \nend of the hot call path, AEntityFactory::get_adjacencies contains an inlined code fragment from the \nC++ Standard Template Library (STL), which itself contains a loop over code inlined from the MOAB appli\u00adcation \n(TypeSequenceManager.hpp). Closer inspection of the call path con.rms that get_adjacencies calls an (inlined) \nprocedure that calls the STL set::find function which makes a call back to a user-supplied comparison \nfunctor in TypeSequenceM\u00adanager.hpp. In this context, the comparison functor incurs 21.3% of all L1 data \ncache misses, suggesting that objects in the STL set should be allocated to exploit locality. Our tools \nare uniquely able to attribute performance data at the source level with exquisite de\u00adtail, even in the \npresence inlining.  4.2 S3D The second application we discuss is S3D, a Fortran 90 code for high .delity \nsimulation of turbulent reacting .ows [20]. We compiled S3D on a Cray XD1 (AMD Opteron 275) using Portland \nGroup s 6.1.2 compiler with the -fast option. Figure 8(b) shows part of a loop-level .at view for a call \npath pro.le of a single-core execution. The .at view organizes perfor\u00admance data according to an application \ns static structure. All costs incurred in any calling context by a procedure are aggregated to\u00adgether \nin the .at view. This particular view was obtained by .atten\u00ading away the procedures normally shown at \nthe outermost level of the .at view to show outer-level loops. This enables us to view the performance \nof all loop nests in the application as peers. We focus on the second loop on lines 209-210 of .le rhsf.90. \nNotice that this loop contains a loop at line 210 that does not appear explicitly in the code. This loop \nconsumes 5.5% of the total execution time. This is a compiler-generated loop for copying a non-contiguous \n4\u00addimensional slice of array grad_Ys into a contiguous array tempo\u00adrary before passing it to computeScalarGradient. \nThe ability to explicitly discover and attribute costs to such compiler-generated loops is a unique strength \nof our tools. 5. Considering Other Contemporary Tools There is a large body of prior work on call path \npro.ling, but its focus has not been on using binary analysis to enable sampling\u00adbased measurement and \nattribution of performance metrics for fully optimized code. For this this reason we focus on comparing \nwith contemporary tools with the most closely related capabilities for measurement and attribution. To \nour knowledge, no other sampling based pro.ler is capa\u00adble of collecting full call path pro.les for fully \noptimized code. Any tool based on libunwind [21] such as LoopSampler [22] re\u00ad quires frame pointers or \nunwind information. OPro.le [17] and Sysprof [25], two well-known Linux system-wide call stack pro.l\u00ad \ners require frame pointers. Since the x86-64 ABI does not require frame pointers, this restriction requires \nrecompilation of any appli\u00ad  (a) A calling context view for MOAB (C++). (b) A .at view exposing loops \nfor S3D (Fortran 90). Figure 8. hpcviewer presenting different views of call path pro.les for two applications. \ncation and system library of interest. Apple s Shark [2], one of the nicer tools, also fails to correctly \nunwind optimized code. On a sim\u00adple test, we observed it incorrectly unwinding calls from the sinh math \nlibrary procedure. Sampling-based call path pro.lers naturally fail to record a complete calling context \ntree. However, they also naturally high\u00adlight the most important paths, which comports well with perfor\u00admance \nanalysis. Zhuang et al. develop bursty call path pro.ling for Java [31] a combination of sampling and \nadaptive, time\u00adlimited dynamic instrumentation that more accurately approx\u00adimates the complete CCT with \nan average overhead of 20%. For performance tuning, it is no bargain to pay such overhead to in\u00adcrease \nthe knowledge of infrequently executed paths. The importance of correlating performance measurements \nwith source code has been widely acknowledged. The task of correla\u00adtion is easy with custom-generated \ncompiler information [1, 30]. Unfortunately, this solution is impractical. Typically, open systems supply \nmultiple compilers. Consequently, current sampling-based call path pro.lers trivially correlate dynamic \ndata with source code using the binary s line map. In the presence of inlining and loop transformations, \nthis approach results in confusing correlations that attribute costs of inlined code back to their source \n.les rather than where they were incurred. 6. Conclusions We have designed methods of binary analysis \nfor 1) minimally intrusive call path pro.ling of fully optimized code and 2) effec\u00adtive attribution and \ninterpretation of performance measurements of fully optimized code. Our evaluation of hpcrun using the \nSPEC benchmarks on executables optimized by several different compil\u00aders shows that we can attribute \ncosts incurred by fully optimized code to full calling context with low run-time overhead. The ex\u00adamples \nin Figure 8 highlight the unique contextual information we obtain by combining hpcrun s dynamic call \npath information with hpcstruct s static program structure. They show both how we at\u00adtribute costs to \ninlined frames and loop nests and how this informa\u00adtion yields insight into the performance of complex \ncodes. When compared with instrumentation-based techniques, our measurement and analysis methods have \nseveral advantages. First, sampling-based call path pro.lers do not interfere with compiler optimization \nand introduce minimal distortion during pro.ling. On many operating systems, they can even be invoked \non un\u00admodi.ed dynamically linked binaries. Second, using binary anal\u00adysis to recover source code structure \nis uniquely complementary to sampling-based pro.ling. hpcrun samples the whole calling context in the \npresence of optimized libraries and even threads. hpcstruct recovers the source code structure, by using \nonly min\u00adimal symbolic information, for any portion of the calling context even without the source code \nitself. Using binary analysis to recover source code structure addresses the complexity of real sys\u00adtems \nin which source code for libraries is often missing. Third, binary analysis is an effective means of \nrecovering the source code structure of fully optimized binaries. When source code is avail\u00adable, we \nhave seen that hpcstruct s object to source code struc\u00adture mapping accurately correlates highly optimized \nbinaries with procedures and loops. Among other things, it accounts for inlined routines, inlined loops, \nfused loops, and compiler generated loops. In effect, our binary analysis methods have enabled us to \nobserve both what the compiler did and did not do to improve performance. We conclude that our binary \nanalyses enable a unique combination of call path data and static source code structure; and this com\u00adbination \nprovides unique insight into the performance of modular applications that have been subjected to complex \ncompiler trans\u00adformations. Both of our analyses have been motivated, in part, by a lack of compiler information. \nWhile we would welcome improved com\u00adpiler support, it seems unlikely any will be forthcoming. Although \ncompiler vendors have been sympathetic to our requests to .x or improve their symbolic information, they \nhave been clear that their highest priority is highly ef.cient and correct code. Improving line maps \nor debugging information in binaries is at the bottom of their list of tasks. We have shown that accurate \nand rich contextual in\u00adformation can be obtained with only minimal compiler information and we believe \nthat the utility of our results justify our effort. Acknowledgments Development of HPCTOOLKIT is supported \nby the Department of Energy s Of.ce of Science under cooperative agreements DE-FC02-07ER25800 and DE-FC02-06ER25762. \nHPCTOOLKIT would not exist without the contributions of the other project mem\u00adbers: Laksono Adhianto, \nMark Krentel, and Gabriel Marin. Mark Krentel s efforts have vastly improved hpcrun s ability to dynami\u00adcally \nand statically monitor processes and threads. HPCTOOLKIT s hpcviewer interface is primarily the work \nof Laksono Adhianto.  We are grateful to Mark Charney and Robert Cohn at Intel for assis\u00adtance with \nXED [5]. This work used equipment purchased in part with funds from NSF Grant CNS-0421109. References \n[1] V. S. Adve, J. Mellor-Crummey, M. Anderson, J.-C. Wang, D. A. Reed, and K. Kennedy. An integrated \ncompilation and performance analysis environment for data parallel programs. In Supercomputing 95: Proceedings \nof the 1995 ACM/IEEE conference on Supercom\u00adputing (CDROM), page 50, New York, NY, USA, 1995. ACM Press. \n[2] Apple Computer. Shark. http://developer.apple.com/tools/ sharkoptimize.html. [3] G. Brooks, G. J. \nHansen, and S. Simmons. A new approach to debugging optimized code. In PLDI 92: Proceedings of the ACM \nSIGPLAN 1992 conference on Programming language design and implementation, pages 1 11, New York, NY, \nUSA, 1992. ACM Press. [4] B. Buck and J. K. Hollingsworth. An API for runtime code patching. The International \nJournal of High Performance Computing Applications, 14(4):317 329, Winter 2000. [5] M. Charney. XED2 \nuser guide. http://www.pintool.org/docs/ 24110/Xed/html. [6] R. Cohn and P. G. Lowney. Hot cold optimization \nof large Windows/NT applications. In MICRO 29: Proceedings of the 29th Annual ACM/IEEE International \nSymposium on Microarchitecture, pages 80 89, Washington, DC, USA, 1996. IEEE Computer Society. [7] A. \nDubey, L. Reid, and R. Fisher. Introduction to FLASH 3.0, with application to supersonic turbulence. \nPhysica Scripta, 132:014046, 2008. [8] Free Standards Group. DWARF debugging information format, version \n3. http://dwarf.freestandards.org. 20 December, 2005. [9] N. Froyd, J. Mellor-Crummey, and R. Fowler. \nLow-overhead call path pro.ling of unmodi.ed, optimized code. In ICS 05: Proceedings of the 19th annual \nInternational Conference on Supercomputing, pages 81 90, New York, NY, USA, 2005. ACM Press. [10] N. \nFroyd, N. Tallent, J. Mellor-Crummey, and R. Fowler. Call path pro.ling for unmodi.ed, optimized binaries. \nIn GCC Summit 06: Proceedings of the GCC Developers Summit, 2006, pages 21 36, 2006. [11] S. L. Graham, \nP. B. Kessler, and M. K. McKusick. Gprof: A call graph execution pro.ler. In SIGPLAN 82: Proceedings \nof the 1982 SIGPLAN Symposium on Compiler Construction, pages 120 126, New York, NY, USA, 1982. ACM Press. \n[12] R. J. Hall. Call path pro.ling. In ICSE 92: Proceedings of the 14th international conference on \nSoftware engineering, pages 296 306, New York, NY, USA, 1992. ACM Press. [13] P. Havlak. Nesting of reducible \nand irreducible loops. ACM Trans. Program. Lang. Syst., 19(4):557 567, 1997. [14] Intel Corporation. \nIntel performance tuning utility. http:// software.intel.com/en-us/articles/intel-performance\u00ad tuning-utility. \n[15] Intel Corporation. Intel VTune performance analyzer. http: //www.intel.com/software/products/vtune. \n[16] ITAPS working group. The ITAPS iMesh interface. http: //www.tstt-scidac.org/software/documentation/iMesh_ \nuserguide.pdf. [17] J. Levon et al. OPro.le. http://oprofile.sourceforge.net. [18] C.-K. Luk, R. Cohn, \nR. Muth, H. Patil, A. Klauser, G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood. Pin: building customized \nprogram analysis tools with dynamic instrumentation. In PLDI 05: Proceedings of the 2005 ACM SIGPLAN \nconference on programming language design and implementation, pages 190 200, New York, NY, USA, 2005. \nACM Press. [19] J. Mellor-Crummey, R. Fowler, G. Marin, and N. Tallent. HPCView: A tool for top-down \nanalysis of node performance. The Journal of Supercomputing, 23(1):81 104, 2002. [20] D. Monroe. ENERGY \nScience with DIGITAL Combustors. http: //www.scidacreview.org/0602/html/combustion.html. [21] D. Mosberger-Tang. \nlibunwind. http://www.nongnu.org/ libunwind. [22] T. Moseley, D. A. Connors, D. Grunwald, and R. Peri. \nIdentifying po\u00adtential parallelism via loop-centric pro.ling. In CF 07: Proceedings of the 4th international \nconference on Computing frontiers, pages 143 152, New York, NY, USA, 2007. ACM. [23] T. Mytkowicz, A. \nDiwan, M. Hauswirth, and P. Sweeney. Producing wrong data without doing anything obviously wrong! In \nFourteenth International Conference on Architectural Support for Programming Languages and Operating \nSystems (ASPLOS 09), 2009. [24] N. Rosenblum, X. Zhu, B. Miller, and K. Hunt. Learning to analyze binary \ncomputer code. In Proceedings of the Twenty-Third AAAI Conference on Arti.cial Intelligence (2008), pages \n798 804, 2008. [25] S. Sandmann. Sysprof. http://www.daimi.au.dk/~sandmann/ sysprof. 21 October 2007. \n[26] S. S. Shende and A. D. Malony. The Tau parallel performance system. Int. J. High Perform. Comput. \nAppl., 20(2):287 311, 2006. [27] SPEC Corporation. SPEC CPU2006 benchmark suite. http: //www.spec.org/cpu2006. \n3 November 2007. [28] N. R. Tallent. Binary analysis for attribution and interpretation of performance \nmeasurements on fully-optimized code. M.S. thesis, Department of Computer Science, Rice University, May \n2007. [29] T. J. Tautges. MOAB-SD: integrated structured and unstructured mesh representation. Eng. Comput. \n(Lond.), 20(3):286 293, 2004. [30] O. Waddell and J. M. Ashley. Visualizing the performance of higher-order \nprograms. In Proceedings of the 1998 ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools \nand Engineering, pages 75 82. ACM Press, 1998. [31] X. Zhuang, M. J. Serrano, H. W. Cain, and J.-D. Choi. \nAccurate, ef.cient, and adaptive calling context pro.ling. In PLDI 06: Proceedings of the 2006 ACM SIGPLAN \nconference on Programming language design and implementation, pages 263 271, New York, NY, USA, 2006. \nACM.    \n\t\t\t", "proc_id": "1542476", "abstract": "<p>Modern programs frequently employ sophisticated modular designs. As a result, performance problems cannot be identified from costs attributed to routines in isolation; understanding code performance requires information about a routine's calling context. Existing performance tools fall short in this respect. Prior strategies for attributing context-sensitive performance at the source level either compromise measurement accuracy, remain too close to the binary, or require custom compilers. To understand the performance of fully optimized modular code, we developed two novel binary analysis techniques: 1) <i>on-the-fly</i> analysis of optimized machine code to enable minimally intrusive and accurate attribution of costs to dynamic calling contexts; and 2) post-mortem analysis of optimized machine code and its debugging sections to recover its program structure and reconstruct a mapping back to its source code. By combining the recovered static program structure with dynamic calling context information, we can accurately attribute performance metrics to calling contexts, procedures, loops, and inlined instances of procedures. We demonstrate that the fusion of this information provides unique insight into the performance of complex modular codes. This work is implemented in the HPCToolkit performance tools (http://hpctoolkit.org).</p>", "authors": [{"name": "Nathan R. Tallent", "author_profile_id": "81100138644", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1464351", "email_address": "", "orcid_id": ""}, {"name": "John M. Mellor-Crummey", "author_profile_id": "81100196441", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1464352", "email_address": "", "orcid_id": ""}, {"name": "Michael W. Fagan", "author_profile_id": "81100015595", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P1464353", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542526", "year": "2009", "article_id": "1542526", "conference": "PLDI", "title": "Binary analysis for measurement and attribution of program performance", "url": "http://dl.acm.org/citation.cfm?id=1542526"}