{"article_publication_date": "06-15-2009", "fulltext": "\n Ef.ciently and Precisely Locating Memory Leaks and Bloat Gene Novark Emery D. Berger Department of \nComputer Science University of Massachusetts, Amherst Amherst, MA 01003 gnovark@cs.umass.edu, emery@cs.umass.edu \nAbstract Inef.cient use of memory, including leaks and bloat, remain a signi.cant challenge for C and \nC++ developers. Applications with these problems become slower over time as their working set grows and \ncan become unresponsive. At the same time, memory leaks and bloat remain notoriously dif.cult to debug, \nand comprise a large number of reported bugs in mature applications. Previous tools for diagnosing memory \ninef.ciencies based on garbage collection, binary rewriting, or code sampling impose high overheads (up \nto 100X) or generate many false alarms. This paper presents Hound, a runtime system that helps track \ndown the sources of memory leaks and bloat in C and C++ applica\u00adtions. Hound employs data sampling, a \nstaleness-tracking approach based on a novel heap organization, to make it both precise and ef.cient. \nHound has no false positives, and its runtime and space overhead are low enough that it can be used in \ndeployed applica\u00adtions. We demonstrate Hound s ef.cacy across a suite of synthetic benchmarks and real \napplications. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Reliability; D.2.5 [Software \nEngineering]: Debugging aids; D.3.3 [Programming Languages]: Dynamic storage management General Terms \nAlgorithms, Languages, Reliability Keywords Hound, virtual compaction, dynamic memory alloca\u00adtion, memory \nleak detection, heap pro.ling 1. Introduction Memory management is a notorious source of problems in \nC and C++. Even when programmers manage memory correctly avoiding potentially catastrophic errors like \ndouble or invalid frees and dangling pointer errors it remains challenging for them to use this memory \nef.ciently. Memory inef.ciency occurs whenever a program consumes more memory than it actually needs. \nWhen a program has unnecessary excess memory consumption, the pro\u00adgram exhibits bloat. If a program has \nunneeded memory memory that it will never use again and never reclaims it, the program has a leak. Inef.cient \nuse of memory reduces both performance and avail\u00adability. Bloated applications limit the number of applications \na user Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n09, June 15 20, 2009, Dublin, Ireland. Copyright c &#38;#169; 2009 ACM 978-1-60558-392-1/09/06. . . $5.00. \nBenjamin G. Zorn Microsoft Research One Microsoft Way Redmond, WA 98052 zorn@microsoft.com can run or \ndegrade responsiveness by forcing other applications to be paged out. Memory leaks cause an application \ns memory image to grow over time, eventually triggering paging. Leaky applications thus become slower \nand slower, eventually becoming unresponsive or exhausting available address or swap space. Perhaps because \nof their impact on usability, memory inef.cien\u00adcies continue to be one of the most common classes of \nreported bugs. Both memory leaks and bloat are notoriously dif.cult to de\u00adtect and debug in long-running \napplications, such as servers or web browsers. For example, in the .rst two months of 2008, over 150 \nmemory leak bugs were reported in the Firefox browser [20]. Debugging memory inef.ciencies is dif.cult \nfor several rea\u00adsons. First, some existing tools do not provide enough information or cannot be used \nin deployment. Existing tracing-based tools like Purify [7] and Valgrind [21] cannot locate reachable \nleaks or identify bloat. Worse, their high overheads (up to 100X) prevents their use in deployed applications. \nBecause leaks often manifest over long periods of time and in response to exceptional events, it can \nbe extremely dif.cult for developers to reproduce them in\u00adhouse. Second, while newer tools both can be \nused in deployment and detect all forms of memory inef.ciency, they can produce too many false alarms. \nThese staleness-based tools track the amount of elapsed time since the last access to each object [3, \n8], al\u00ad lowing them to identify both bloat and leaks,whether reachable or not. However, because exact \nstaleness tracking would be pro\u00adhibitively expensive (requiring instrumentation of every memory access), \nthese tools use adaptive code-based sampling techniques: the more frequently a code path is executed, \nthe lower the chance it will update access information. However, code sampling can over\u00adestimate object \nstaleness and thus generate many false alarms. Be\u00adcause programmer intervention is required to separate \nreal errors from false positives, a high false alarm rate can make these tools unusable. Contributions \nThis paper presents Hound, a runtime system for C/C++ that lo\u00adcates both leaks and bloat without any \nfalse alarms. Hound uses data sampling instead of code sampling to track object staleness with high precision \nwhile maintaining suf.ciently low runtime and memory overhead for production use. To accomplish this, \nHound relies on a combination of virtual memory primitives and novel memory management techniques: context-sensitive \nmemory allo\u00adcation and age-segregated memory allocation, which enable track\u00ading and isolation of stale \nobjects, and virtual compaction, which reduces Hound s memory consumption by compacting objects in physical \nbut not virtual memory, making it suitable for C and C++. We demonstrate Hound s low overhead across \na suite of stan\u00addard benchmarks and applications with real memory leaks. For non-allocation-intensive \nworkloads, Hound imposes low runtime overheads, averaging less than 5% across a suite of server applica\u00adtions, \nall of SPECint2000, and all but two of the benchmarks from SPECint2006. We show that, despite this low \noverhead, Hound generates precise leak reports (i.e., with no false positives) that can point directly \nto the source of memory inef.ciencies in both syn\u00adthetic and real applications.  Outline The rest of \nthis paper is organized as follows. Section 2 .rst pro\u00ad vides an overview of Hound s key algorithms. \nSection 3 contrasts code sampling, used in previous tools, with Hound s data sampling. Section 4 describes \nHound s segregating allocator in detail, and Section 5 describes how Hound tracks object staleness. Section \n6 describes the virtual compaction mechanism Hound uses to reduce memory overhead. Section 7 describes \nhow Hound generates its reports. Section 8 empirically evaluates Hound s overhead and its precision at \nlocating memory inef.ciencies. Section 9 presents an overview of related work, and Section 10 concludes. \n2. Overview Hound relies on memory protection to detect object accesses and estimate staleness. This \nmechanism works at a page granularity, meaning Hound either enables or disables tracking for all objects \non a page as a group. In order to accurately estimate staleness with low overhead, Hound collocates objects \nwith similar predicted be\u00adhavior on the same page. This segregation allows constant protec\u00adtion and monitoring \nof rarely-used objects, while hot objects are grouped together on the same pages and can be left unprotected. \nHound s allocator segregates objects along two different axes. First, Hound uses a context-sensitive \nallocation strategy: it uses the calling context of malloc calls known to be an effective pre\u00addictor \nof object lifetime [27] to segregate objects from different allocation sites onto different pages. This \npolicy groups similarly behaved objects onto a small number of pages and prevents dis\u00adsimilar objects \nfrom being allocated into those pages. While the ef\u00adfectiveness of this policy depends on program behavior, \nour results show the approach is effective in real programs. Hound combines this context-sensitive allocation \nwith an age\u00adsegregated memory allocator. Age segregation ensures that all ob\u00adjects on the same page are \nof similar age, as measured by allocation time. Eventually, as the program frees non-leaked objects, \nleaked objects and bloat will be isolated on their own pages. Hound further re.nes these algorithms to \nreduce the risk of excessive fragmentation. First, Hound performs per-allocation site segregation only \nfor sites that are the source of a large number of objects. This approach prevents the worst case of \nhaving each call site with only a single live object holding down an entire page. Notice that this policy \ndoes not impair Hound s precision: by de.nition, sites that allocate few objects cannot be the source \nof signi.cant memory leaks. Second, Hound performs virtual compaction, a novel tech\u00adnique that compacts \nmemory without the need to move objects (something C and C++ do not permit). Virtual compaction retains \nsegregation within the virtual address space, while signi.cantly re\u00adducing the physical fragmentation \nof the heap by merging sparsely\u00adpopulated virtual pages onto the same physical page frame. Thus, virtual \ncompaction can reclaim a substantial amount of physical memory when live objects are sparsely spread \nacross many pages. This technique reduces the amount of physical memory required for age-segregation \nwithout sacri.cing the precision of Hound s object tracking. 3. Code vs. Data Sampling In contrast to \nleak detection tools that use code-based sampling, Hound uses a data-based sampling technique. Data sampling \npre\u00advents overestimating object staleness, a source of false positives in tools based on code sampling. \nThis section explains the problems inherent in using code sampling for leak detection and presents Hound \ns solution. State-of-the-art leak detection tools such as SWAT [8] and Sleigh [3] use a code sampling \ntechnique called adaptive bursty tracing (ABT). This technique samples code inversely proportional to \nits execution frequency. Thus, infrequently-executed code is traced nearly all the time, while frequently-executed \ncode is rarely sampled. This strategy allows thorough tracing of code where bugs may lie, while avoiding \nthe overhead of tracing well-tested hot code paths. Using ABT to sample object accesses for staleness \nestimation relies on the assumption that hot code paths access hot objects, and that cold code paths \naccess cold objects. Accesses to objects during hot code execution will be frequently missed due to sampling. \nIf a program accesses the same object frequently, then sampling will detect some references to it, correctly \nestimating staleness. However, if a hot code path accesses many different objects, most of the objects \nwill have greatly overestimated staleness values. For example, consider a large hash table accessed only \nthrough a single hot code path. If ABT uses a minimum 0.1% sampling rate (as in the experiments in the \nSWAT paper), then it will miss all but 1 reference out of every 1,000. Assuming a random distribution \nof accesses, each individual object in the hash table is accessed only a small fraction of the total \naccesses to the table. As a result, most objects in the table appear far staler (1,000X) than they actually \nare, even though they are live and referenced relatively often. Instead of code sampling, Hound uses \na data sampling approach which avoids overestimating staleness. Hound periodically protects every page \nand updates the last access time of all objects on that page to the current allocation time. When a protected \npage is ac\u00adcessed, Hound unprotects it and places it on an active list. Protected pages cannot have been \naccessed since their most-recent protection time, providing a strict lower bound on the staleness of \nall objects on the page. Hound s sampling policy cannot result in false positives. How\u00adever, it may result \nin false negatives when a hot object is collocated on a page with stale objects. Hound uses an aggressive \nsegrega\u00adtion policy to reduce the frequency of these situations, as the next section describes. 4. Hound \nHeap Structure Hound relies on object segregation to achieve low-overhead stale\u00adness detection using \nmemory protection. Without segregation, stale objects would often be on the same page as frequently-accessed \nobjects. Thus, Hound could not protect stale objects without pro\u00adtecting hot objects, and would thus \nincur a high page-fault rate, causing unacceptable performance degradation. While garbage-collected languages \nlike Java support moving garbage collection [10] and can thus segregate objects at GC time, C s and C++ \ns direct access to memory addresses precludes object relocation. Thus, the only way for Hound to segregate \nobjects is to separate them at allocation time. To achieve this separation, Hound uses a novel memory \nman\u00adager that segregates objects a priori. Figure 1 presents an overview of Hound s memory manager, which \nsegregates objects along two dimensions: allocation sites (the calling context that ends in malloc or \nnew) and age (in allocation time).   Figure 1. Hound s context-sensitive heap structure, which segre\u00ad \ngates allocation requests by allocation site once the number of live objects exceeds a .xed threshold \n(see Section 4.1). 1 void * houndmalloc (size_t size) { 2 // compute hash of calling context. 3 int context \n= getContextHash(); 4 Metadata * m = getMetadata(context); 5 // one more object allocated. 6 m->liveCount++; \n7 // use the age-segregated heap to 8 // satisfy the request, if possible. 9 if (m->getAgeHeap() != NULL) \n{ 10 return m->getAgeHeap()->malloc (size); 11 } else if (m->getLiveCount() >= 64) { 12 // make a new \nheap. 13 m->initAgeHeap(); 14 return m->getAgeHeap()->malloc (size); 15 } else { 16 // still below threshold: \n17 // get memory from standard allocator. 18 return phkmalloc_with_header (size, 19 context); 20 } 21 \n} Figure 2. Pseudo-code for Hound s allocation-site segregated malloc. 1 void houndfree (void * ptr) \n{ 2 // check pointer validity. 3 if (!isFromHoundHeap(ptr)) { 4 // return to standard allocator 5 // \nafter updating metadata. 6 int context = getHeader(ptr); 7 Metadata * m = getMetadata(context); 8 m->liveCount--; \n9 phkfree_with_header (ptr); 10 } else { 11 // locate the page via ptr masking 12 // and free the object. \n13 void * page = ptr &#38; (PAGE_SIZE-1); 14 PageEntry * entry = pageMap(page); 15 entry->free (ptr); \n16 } 17 } Figure 3. Pseudo-code for Hound s allocation-site segregated free. 4.1 Allocation-Site Segregation \nPrevious research has shown that objects allocated from the same call site tend to exhibit similar behavior \nand lifetime patterns [27]. To isolate leaks and bloat, Hound segregates objects by associating a separate \nheap with each allocation site. Hound identi.es these sites with bounded context sensitivity (the last \nfour return addresses on the call stack). Each heap then uses a distinct set of pages to satisfy allocation \nrequests from that site. This segregation helps prevent the intermin\u00adgling of objects from sites that \nproduce hot objects with those that produce cold or leaked objects. The result is that pages tend to \nfall into two classes: those that contain all cold objects, which can be constantly protected without \nincurring page faults, or mostly hot objects, which are left unprotected, and may increase the page-level \nspatial locality of the heap. Contrast this separation with the behavior of conventional memory allocators, \nwhich do not perform per-call site segregation and thus can end up with a single hot object on a page \n.lled with cold or leaked objects. Limiting Memory Overhead Most applications have a large number of \ndynamic allocation sites. For example, Firefox allocates from approximately 14,000 sites during a typical \ninteraction. However, most of those sites create relatively few objects, especially those sites that \ncorrespond to its initialization phase. Allocating an entire page to hold a few small objects wastes \nmemory. To reduce this memory overhead, Hound instantiates a new heap for a site only when the number \nof live objects from that site reaches some threshold (currently 64). To track the count for each site, \nHound adds an extra header word to each object containing the hash of the allocation site of each object. \nWhen an object is freed, Hound decrements the live count for its allocation site. At allocation time, \nHound uses a hash table to map each allo\u00adcation site to a metadata entry (line 4 of Figure 2), which \ntracks statistics including the total allocation count for the site. As long as the total live count \nfor that site remains below 64, Hound allocates object requests directly from a conventional heap (line \n18); Hound currently uses PHKmalloc [12] as its allocation substrate. Other\u00ad wise, it instantiates a \nseparate heap for that site (line 13), using it for all subsequent allocations from that site. This approach \n.lters out sites that only produce a small number of objects, since these sites cannot be sources of \nsubstantial memory leaks or bloat. To further reduce memory overhead, we modi.ed PHKmal\u00adloc slightly. \nPHKmalloc normally uses sbrk to allocate mem\u00adory, but this approach can prevent reclamation of freed \nobjects if subsequently-allocated objects remain live. We changed PHKmal\u00adloc to allocate large objects \n(at least 64K) directly from the system via mmap, allowing their space to be returned to the system as \nsoon as they are freed. This hybrid allocation strategy is used by many memory allocators, including \nDLmalloc and Hoard. 4.2 Age-Based Segregation While call site segregation is a heuristic that can help \nseparate ob\u00adjects with similar behavior, some sites may still be heterogeneous. For example, a site may \ngenerate objects that eventually become stale as well as short-lived objects. Allocating a short-lived \nobject onto a page with stale objects would cause Hound to underestimate the staleness of the other objects \non that page. To avoid this scenario, Hound departs further from conventional heap layouts by segregating \nobjects by age, as measured in alloca\u00adtion time. The key insight is the following: objects that are leaks \nor bloat by de.nition are not reclaimed for a long time, and thus become older and older as program execution \ncontinues. Keeping old objects separate from newer objects thus prevents stale objects from intermingling \nwith newer, potentially hot objects. While age segregation can ensure accurate staleness informa\u00adtion \nin the case of some anomalous sites, other pathologies may lead to incorrect staleness information. For \nexample, if a site pro\u00adduces many stale objects and some long-lived hot objects, the hot  1 2 3 4 5 \n6 7 8 9 10 11 12 13 Figure 4. Hound s age-segregated heap (see Section 4.2). 14 15 16 17 objects will \ncause Hound to incorrectly record that many of the 18 stale objects are active due to page-level false \nsharing. Note that 19 this inaccuracy only underestimates staleness, and thus cannot lead 20 to false \nalarms. 21 Hound separates young from old objects in an age-segregated 22 heap. Each age-segregated heap \nis itself a segregated-.ts alloca-23 tor [35] organized as a collection of pages. Each page is an array \nof 24 25 .xed-sized object slots (see Figure 4). Each heap contains a list of 26 pages for each size \nclass (powers of two, ranging from 16 to 2048 27 bytes), plus a special bin for larger objects. 28 Hound \nsatis.es allocation requests by bumping a pointer through 29 the currently active page for the appropriate \nsize class (line 26 30 of Figure 5). When an active page is .lled, Hound maps a fresh (empty) page and \nuses it for subsequent allocations (lines 11 18). Free operations decrement the population count for \nthe appropriate page (line 3 of Figure 6). Hound only reuses memory on a page when the population count \nfor a page drops to zero and the bump pointer has reached the end of the page (lines 5 8). Hound adds \n1 .lled pages to the aging queue, where they will eventually be pro-2 3 tected for staleness tracking, \nand also become candidates for virtual 4 compaction, described in Section 6 (lines 9 12). 5 Hound assigns \none metadata structure for each allocated page. 6 This structure contains three elements: (1) the bump \npointer, used 7 for allocation from non-full pages; (2) the total number of live 8 objects, which lets \nHound free pages when their population drops 9 to zero; and (3) a bitmap that tracks which slots contain \nlive objects, 10 used by Hound s virtual compaction algorithm. Hound uses a two-11 12 level page table \nstructure to map page addresses to metadata. 13 14 5. Tracking Staleness Hound keeps all .lled pages \n(those that will not be used for subse\u00adquent allocations) on its aging queue. This aging queue is organized \nin order of staleness, measured as the time since the application last accessed some object on the page. \nHound protects pages on the queue from direct read and write access using the mprotect sys\u00adtem call. \nObjects on the page cannot have been accessed since the last time the page was protected. Hound estimates \nstaleness using the formula currentTime - protectionTime, which provides a strict lower bound on true \nstaleness. When the application accesses an object on the page, Hound handles the page fault (SIGSEGV) \nand unprotects the pages. While unprotected, all objects on the page are considered to have a staleness \nvalue of 0. Protecting all pages on the aging queue would be prohibitively expensive, since some pages \nwill contain frequently-used objects. Hound thus segregates the aging queue into active and inactive \nlists. Pages on the inactive list are page-protected and managed in LRU order, while pages on the active \nlist are unprotected and managed using a FIFO queue. When the program accesses a page on the inactive \nlist, a page fault occurs and Hound unprotects and void * AgeHeap::malloc (size_t size) { if(size > PAGE_SIZE/2) \nreturn allocWithMmap(size); int c = computeSizeClass (size); Heap * h = getHeapFromClass (c); if (!h->activePage \n|| h->activePage->bump == h->activePage->endOfPage) { void * page = getNewPage(); PageEntry e *= createPageEntry \n(page); e->bump = page; e->endOfPage = page + PAGE_SIZE; e->inUse = 0; e->heap = h; h->activePage = e; \n} return h->activePage->malloc(); } void * PageEntry::malloc(size_t size) { void * ptr = bump; bump \n+= roundUp(size); inUse++; bitmap.set(indexOf(ptr)); return ptr; } Figure 5. Pseudo-code for Hound s \nage-segregated malloc. void PageEntry::free (void * ptr) { // find originating page. inUse--; bitmap.clear(indexOf(ptr)); \nif ((inUse == 0) &#38;&#38; (bump == endOfPage)) { // free the page for re-use. recyclePage (page); \nclearPageEntry (page); } else if ((inUse < NUM_ENTRIES/2) &#38;&#38; (bump == endOfPage)) { // check \nvirtual compaction queue AgingQueue.addOrUpdate(this); } } Figure 6. Pseudo-code for Hound s age-segregated \nfree. moves the page to the head of the active list. Hound periodically moves pages from the end of the \nactive list onto the inactive list to maintain the latter s target size. 5.1 Adapting the Inactive List \nThe size of the inactive list is controlled adaptively to achieve both acceptable runtime overhead and \nto maximize the useful informa\u00adtion acquired. Since each page on the inactive list is protected, a larger \ninactive list gathers more useful data about page staleness, but results in more runtime overhead due \nto page faults. Hound s heuristics for controlling the list sizes and moving objects from the active \nto inactive list are based on those used in CRAMM [37] and shown as pseudocode in Figure 7. Each time \na page is added to the aging queue, Hound checks whether it should adjust the sizes of the queues. If \n1/8 second of CPU time has passed (or 10 page faults), Hound reevaluates the Figure 8. An example pair \nof pages that share no common live indices. The virtual compactor can merge these pages in physical memory \nwhile not actually relocating objects in virtual memory (see Section 6).  that truly inactive pages \nnever move from the inactive to the active list, and thus have accurate staleness information. 6. Virtual \nCompaction Hound recycles memory from age-segregated heaps only when pages become completely empty. This \nstrategy could potentially lead to high fragmentation. In the worst case, a single live object could \nprevent the reclamation of an entire page. To mitigate this problem, Hound uses a novel scheme we call \nvirtual compaction that leverages Linux s virtual memory remap\u00adping capability to permit compaction of \nmultiple virtual pages onto the same physical page, without moving objects in virtual address space. \nWhile we limit our discussion here to its use in Hound, we believe that virtual compaction may enable \na new class of compact\u00ading memory managers for C and C++ applications. Virtual compaction merges virtual \npages with no overlapping objects into a single physical page. This process is facilitated by Hound s \nage-segregated heaps, which use a segregated .ts structure in which each page is an array of identically-sized \nobjects. For each page, Hound maintains a bitmap indicating which positions within the page are occupied \nby live objects. If a pair of pages contain live objects only at different positions (i.e., there is \nno offset containing a live object on both pages), then the pages can be overlaid on top of each other \nwith no collisions between live objects (see Figure 8). Our current implementation only considers merging \npages within the same size class for simplicity. Merging pages with different\u00adsized objects would enable \nmore virtual compaction, but require tracking more metadata. Using the Linux mremap call, Hound merges \nsuch pairs of pages onto a single physical frame and maps that frame to the vir\u00adtual addresses of both \noriginal pages. Thus, while virtual memory remains highly fragmented (because virtual memory is only \nrecy\u00adcled at page-granularity), virtual compaction signi.cantly increases the occupancy of physical pages, \nreducing the footprint of the ap\u00adplication. Virtual compaction can be implemented in many ways. This \nsection describes when and how Hound identi.es pairs of pages to compact, as well as the virtual memory-based \nmechanism for merging pages. 6.1 Finding Candidate Pairs At runtime, Hound s heap can contain many low-occupancy \npages. Pages in the heap may be modeled as a graph, where each page is a node. Edges exist between two \npages when they share a com\u00admon live object index, and thus cannot be merged via virtual com\u00adpaction. \nIn this model, .nding an optimal compaction strategy (fewest physical pages) is equivalent to graph coloring, \nand thus NP-complete. Hound therefore makes no attempt to optimally com\u00adpact pages, and instead relies \non heuristics that are effective in prac\u00adtice (see Section 8.3).  1 //calledwhenapageisadded2 //tothefragmanageroranobject3 \n//isfreedonthepage4 voidFragManager::checkMerge(PageEntry*p)5 {6 foreach(PageEntry*qinpageList){7 if(!p.conflicts(q)){8 \n//virtuallycompactpwithq.9 p.mergeWith(q);10 return;11 }12 }13 }Figure 9. Pseudo-code for Hound s .rst-.t \nvirtual compaction al-gorithm (see Section 6). In fact, Hound faces a more dif.cult problem than ordinary \ngraph coloring, because the graph constantly changes as objects are deallocated. Our current system uses \na simple .rst-.t strategy to identify pairs of pages to compact. Hound considers compaction only for \npages which have less than 50% occupancy. It tracks these pages using its fragmentation manager which \nkeeps a linked list of low-occupancy pages per size class. Figure 9 shows pseudocode of the fragmentation \nmanager s compaction algorithm. When a deallocation occurs on a page man-aged by the fragmentation manager, \nit scans its list to .nd another page which has no con.icts. If it .nds a compatible target, then it \neagerly merges the two pages. Pages can be tested for compatibility quickly by performing a bitwise AND \nof their live object bitmaps. If any bit in the result is set, then the pages con.ict. 6.2 Merging Pages \nWhen merging pages, Hound .rst iterates through the liveness bitmap of one page, copying the live objects \nonto the target page. It then remaps the target physical page to both virtual addresses. This is done \nusing the mremapsystem call and specifying a size of 0 [32]. The virtual pages thus share a single physical \nframe, reducing memory overhead. Virtual compaction is not limited to pairs of pages. Any number of virtual \npages may be combined onto a single physical frame as long as they do not con.ict.1 Thus, merged pages \nare put back onto the candidate list for further compaction. A merged page contains a bitmap representing \nthe combined live object information for the corresponding virtual pages, enabling fast con.ict checking. \n7. Reporting While Hound s staleness tracking operates on the page level, it pro-duces reports that summarize \nstaleness information per allocation site. These reports present each allocation site, ranked by the \nsever-ity of their memory consumption, and provide information the pro-grammer can use to diagnose leaks \nor other inef.cient usage of memory. Figure 10 shows two allocation sites from Hound s report for the \nSquid web cache. The report produces 7 total sites, but the remaining 5 have few live objects. The .rst \nreported site is a true memory leak, while the second is caused by data structures which are eagerly \nallocated at the start of the program and never used, and may thus be unneeded bloat. Hound ranks allocation \nsites by their total drag, the sum of object size (in bytes) times staleness (in 1 Kernel limitations \nrestrict the maximum number to 128, which is not a problem in practice. Figure 10. Hound s report for \nSquid allocation time) for each unreclaimed object from that site [26]. It also reports the total number \nof objects and blocks and the maximum staleness of any object from the site. It also shows the calling \ncontext of the site as well as the last-reported touch sites of the pages (the calling context of the \ninstruction which caused a protection fault on the page). The graph presented with each allocation site \npresents a cumula\u00ad tive distribution function (CDF) of the staleness of the pages from the site. These \ngraphs provide a visual representation of how the staleness behavior of objects from the callsite. A \npoint on the curve at (x, y), considering the axes ranging from 0 100%, means that y% of pages have staleness \nx% of the maximum for that site. Intu\u00ad itively, a line close to diagonal, such as the .rst site in Figure \n10 (a real leak), represents a leak that increases steadily over time. The second site shows a large \nfraction of objects (around a third) that are not stale (the plateau in the lower left), and then that \nmost of the rest of the objects are quite stale (the sudden jump in the center). Hound produces detailed \ninformation on every block in heap. The reporting tool uses these raw dumps to generate the summary information. \nHowever, the programmer may .nd the raw dumps to be useful, as they present exact information on the \nnumber of objects surviving on every page and the individual staleness estimates. The raw information \nis produced as an XML .le, making it easy to use existing tools to mine the data. The tool that produces \nour visual reports is written in the XQuery language and transforms the raw XML into an XHTML/SVG report. \n8. Experimental Results Our evaluation answers the following questions: 1. What is Hound s runtime overhead? \n2. What is Hound s memory space overhead, and how effectively does virtual compaction reduce its physical \nmemory consump\u00ad tion? Figure 12. Memory overhead for Hound across the SPECint2000 and SPECint2006 suite \nof benchmarks, normalized to the consumption of the DLmalloc allocator (see Section 8.2). Hound incurs \nminimal memory overhead for most of the benchmarks. 3. How precisely does Hound compute object staleness \nwhile avoiding false positives? 4. How well does Hound identify callsites corresponding to leaks, and \nwhat is its false positive rate?  8.1 Runtime Overhead We evaluate Hound s runtime performance on several \nbenchmark suites. The .rst is a range of highly allocation-intensive bench\u00admarks. These benchmarks allocate \nand deallocate objects at unusu\u00adally high rates, and as such stress Hound s allocation mechanisms. While \nthese applications are not generally representative of typical workloads due to their high allocation \nrates, we include them here because they have been widely used in previous memory manage\u00adment studies. \nThe second set of benchmark suites is the SPECint2006 and SPECint2000 suites of CPU-intensive benchmarks \n[30], which we run using their reference workloads.2. We also evaluate Hound s performance with three \ndifferent server applications: the thttpd web server, the bftpd ftp server, and the OpenSSH server. For \nthe .rst two, we record total throughput 2 471.omnetpp from SPECint2006 times out, 252.eon from SPECint2000 \nfails on both GNU libc and Hound, and the perl benchmarks from both suites fail to run with our current \nimplementation of Hound.  achieved with 50 simultaneous clients issuing 100 requests each. For OpenSSH, \nwe record the time it takes to perform authentica\u00adtion, spawn a shell, and disconnect. Our experimental \nmachine is a single-core, hyperthreaded Pen\u00adtium 4 with 1GB of physical memory. For each benchmark, we \nreport the average result of .ve runs; the observed variance was un\u00adder 1%. We compare runtime overhead \nagainst to the baseline GNU libc allocator, which is based on DLmalloc [14] and is among the fastest \ngeneral-purpose allocators [2]. Figure 11 shows Hound s overhead across the benchmark suites. Hound s \noverhead is substantial on the allocation-intensive bench\u00admarks (from 7.9% to 102%, with a geometric \nmean of 54%), be\u00adcause the cost of each allocation and deallocation is higher than in GNU libc. However, \nHound s runtime overhead is generally far lower for the other benchmark suites. On SPECint2006, except \nfor omnetpp and xalancbmk, Hound s overhead ranges from -9% to 15%, with a geometric mean of 4%. The \nallocation patterns of omnetpp and xalancbmk heavily stress Hound s virtual compaction mech\u00adanism by \nhaving many sparsely-populated pages during most of the benchmark run. The simple matching algorithm \nused in the current implementation results in signi.cant overhead while scanning the list of pages. More \nrobust algorithms for .nding candidate pairs is an area for future work. The omnetpp benchmark has a \ntimeout mechanism that causes premature termination due to the overhead imposed by Hound. On SPECint2000, \nHound s overhead ranges from 0% to 15%, with a geometric mean of 3%. On the server benchmarks, the overhead \nranges from -1% to 8%, with a geometric mean overhead of 4%. We believe that these ranges are likely \nto be typical of long\u00adrunning applications, which allocate memory at a far lower rate than the allocation-intensive \nbenchmarks. 8.2 Memory Overhead We evaluate Hound s memory overhead compared to DLmal\u00adloc [14], the basis \nfor the GNU libc allocator. We measure total virtual memory consumption of the heap using a tool that \nob\u00adserves all calls to mmap and sbrk and accounts for Hound s use of mremap. It reports the maximum virtual \nmemory consumption (high water mark). We use the DLmalloc itself rather than GNU libc in this experiment \nbecause libc appears to call internal ver\u00adsions of sbrk which cannot be shimmed by standard methods (e.g. \nLD PRELOAD). Figure 12 shows relative memory consumption for SPECint2006. The other benchmark suites \n(allocation-intensive and server) con\u00adsist of applications with very small heap footprints, at most 2MB \nunder Hound. Hound requires several hundred kB of memory for global metadata regardless of actual application \nmemory us\u00adage, making relative comparison misleading for small programs. The SPEC benchmarks require \nmuch more heap memory (mean: 250MB), though most have lower allocation rates in terms of malloc calls \nper second. Because some benchmarks consist of multiple executions on different inputs, we measure the \noverhead required for the largest input. For most benchmarks, Hound imposes minimal memory overhead: \n7 of 10 SPECint2006 benchmarks need less than 5% more heap space when running under Hound than with DLmalloc. \nOf the remainder, xalancbmk requires 34% more, libquantum 25%, and h264ref 13%. SPECint2000 shows similar \noverheads, with most benchmarks requiring less than 15% more memory. The sole exception is twolf, which \nhas a small heap footprint of only 3.4 MB under DLmalloc. Under Hound, it requires 4.6 MB, an increase \nof 36%. 8.3 Virtual Compaction We evaluate Hound s ability to limit fragmentation via its virtual compaction \nmechanism on the Firefox browser as well as on the small, allocation-intensive benchmark, cfrac. Firefox \nMemory Overhead To measure the effectiveness of virtual compaction on large pro\u00adgrams, we compare the \nmemory requirements of Firefox (version 2.0.0.9) running under DLmalloc to Hound, con.gured both with \nand without virtual compaction enabled. We measure both the total virtual memory consumption of the entire \nprocess, and the physical memory required by the heap alone. For each experiment, we loaded the same \nseries of 25 pages dur\u00ading a single browsing session. We then measured virtual memory consumption using \ntop and heap usage using the tool described in Section 8.2. Under DLmalloc, Firefox s heap requires 239 \nMB of memory. Under Hound, it rises to 267 MB, an increase of 11%. Virtual compaction saves over 4,000 \npages (16 MB), about 5% of total physical memory. Of the 267 MB used by Hound, 73 MB (27%) is used by \nage-ordered heaps. Virtual Compaction in Small Programs The bulk of the allocation-intensive benchmarks \nprimarily allo\u00adcate short-lived objects, so few age-segregated heaps are created, and the lifetimes of \nthese objects tend to be short. However, vir\u00adtual compaction has a signi.cant effect on the memory usage \nof cfrac. While cfrac is short-running (around 5 seconds), vir\u00adtual compaction reduces the total number \nof physical heap pages by 47% (from 2726 pages to 1425 pages). 8.4 Staleness Computation We evaluate \nHound s data sampling technique for determining ob\u00adject staleness and compare it to the state-of-the-art \ncode sampling technique used in SWAT. Hound and SWAT have opposing limi\u00adtations: while SWAT can overestimate \nobject staleness due to its sampling technique, it never underestimates staleness. Hound can underestimate \nobject staleness since it tracks staleness at a page granularity, but it never overestimates staleness. \n8.4.1 Accuracy Metrics To quantitatively compare SWAT and Hound, we use several met\u00adrics. First, we use \nprecision and recall, two metrics commonly used to measure the quality of classi.ers in the information \nretrieval community. Precision is the ratio of true positives to all positives (true and false), while \nrecall is the ratio of true positives to the sum of true positives and false negatives. Intuitively, \nclassi.ers with high precision (near 1.0) produce few false positives, and similarly, classi.ers with \nhigh recall have low false negative rates. The re\u00adported precision and recall metrics are on a per-object \nbasis, show\u00ading the accuracy of each approach at estimating individual object staleness. However, leak \ndetection tools generally do not report individual objects but rather aggregate them by their allocation \ncallsite. In this context, object-based metrics can be misleading. Consider a report that identi.es one \nallocation site as the source of stale data. If that report failed to identify nine other sites that \nalso had stale data, the recall would be 0.1 (1/10). However, those nine unreported sites could have \nbeen responsible for only a tiny number of stale objects. For example, the reported site could be the \nsource of 10,000,000 objects, and the nine unreported sites together might only comprise 100,000 objects. \nTo capture this effect, we introduce weighted metrics based on callsites rather than individual objects. \nWeighted recall weighs each callsite by its true drag, summed over all objects allocated from that callsite. \nThis weighting emphasizes the importance of false negatives that miss a signi.cant volume of leaks or \nbloat. Similarly, weighted precision weighs callsites by their reported drag, emphasizing false positives \nthat report larger amounts of (false) bloat.  8.4.2 Methodology To compare Hound s precision and recall \nto SWAT, we imple\u00admented SWAT s Adaptive Bursty Tracing framework in PIN, a dynamic binary instrumentation \nsystem [15]. Our implementation instruments every memory reference and checks a .ag to deter\u00admine whether \nsampling is enabled. This approach sacri.ces per\u00adformance, but generates the same information as SWAT \ns adaptive sampling. We also use PIN to compute perfect staleness informa\u00adtion which we use as ground \ntruth when computing the precision and recall metrics for both Hound and SWAT. For our results, we con.gure \nSWAT with a 0.1% sampling rate, as used in the original paper. While our experiments show the qual\u00aditative \ndifference between SWAT and Hound with respect to accu\u00adrate staleness information, computing precision \nand recall requires a binary classi.er. We use SWAT s Greater50M predicate (stale for more than 50 million \nsampled memory references) to classify objects as leaks or non-leaks based on the staleness information \nfrom Hound, SWAT, or the oracle. Note that for this experiment, an object is considered leaked if it \nsatis.es this predicate, regardless of whether or not it would be subjectively considered to be a leak. \n8.4.3 Accuracy Results Tables 1 and 2 present precision, recall, and weighted recall results for both \nHound and SWAT across several benchmark programs. Note that in every case, Hound has a precision of 1.0 \n(no false positives), while SWAT has a recall of 1.0 (no false negatives). HashTable is a microbenchmark \nthat builds a hash table of two million objects and then executes 4,000 random probes. The hash table \nquery code is hot, so it is rarely sampled. However, each individual data item is cold, since the table \nis large. Two allocation sites are hot: the one that produces objects stored in the table, and a site \nproducing internal nodes. Note that none of these objects would be considered real leaks by a human, \nsince each has an equal, non-zero probability of being accessed on the next query. SWAT s precision here \nis 50%, meaning that half of the objects it classi.es as leaks are incorrect, because it overestimates \nstaleness. Hound s recall is only 57% on this benchmark, meaning that it underreports staleness for 43% \nof individual objects. These results highlight the key difference between the two staleness tracking \nmethods. However, weighting reveals the qualitative difference between SWAT and Hound. Hound s weighted \nrecall is 100%, meaning that it reports only the allocation site producing truly stale objects. By contrast, \nSWAT s weighted precision is 50%, because it reports both sites as stale. Squid is a web cache application \nthat acts as an HTTP proxy. Client web browsers request pages from Squid, which it fetches from its in-memory \ncache or its local disk cache, if available. On every request, Squid consults the indices of these caches \nto see whether it can satisfy the request locally, or must fetch the data from the hosting server. Squid \n2.4STABLE3 and earlier suffer a memory leak when handling SNMP requests. We test Hound against this leak \nby sending a sequence of 20,000 requests with a mix of SNMP requests (leaks) and standard HTTP requests. \nSWAT s precision here is fairly high (88%), but that corresponds to 33 false alarms out of 549 allocation \nsites. Its weighted precision is 94%, in part because the heap has little false drag to report. The GIMP \nis a graphic editor similar to Photoshop. We drive it with a script that automatically generates several \nimages and Hound HashTable Squid Gimp Precision (objects) 1.0 1.0 1.0 Weighted Precision (sites) 1.0 \n1.0 1.0 Recall (objects) 0.59 0.57 0.53 Weighted Recall (sites) 1.0 0.81 0.73 Table 1. Precision and \nrecall metrics for Hound. SWAT HashTable Squid Gimp Precision (objects) 0.50 0.88 0.93 Weighted Precision \n(sites) 0.50 0.94 0.98 Recall (objects) 1.0 1.0 1.0 Weighted Recall (sites) 1.0 1.0 1.0 Table 2. Precision \nand recall metrics for SWAT. then runs a series of effects and .lters on them. SWAT s precision appears \nhigh (94%), but here, this value translates to 887 false positives out of 6,887 call sites. For this \nbenchmark, Hound has a relatively low weighted recall (57%). We attribute this to the fact that the GIMP \nhas many allocation sites with only a small number of objects per site, too few to cross Hound s tracking \nthreshold. 8.5 Leak Identi.cation and Ranking We evaluated Hound s usefulness at isolating leaks and \nbloat qualitiatively by running it on Squid with the leak scenario de\u00adscribed above. Figure 10 presents \nHound s report. The report shows two callsites. The .rst is the true leaky allocation site in the snmp \nparse function. Notice that its reported drag is an or\u00adder of magnitude larger than the second site. \nThis latter site eagerly creates data structures related to MIME type handling when the program starts. \nThese data structures are never used during our test workload. The information for the .rst site points \nthe programmer directly to the exact source of the leaked objects. The second site indicates a possibly \ninef.cient use of memory (i.e., bloat), which the program\u00admer can use to determine the severity of the \nproblem and make a subjective decision of whether to change the program s allocation behavior (e.g., \nby allocating this memory only when needed). 9. Related Work Memory leaks and memory bloat have been \nthe target of much pre\u00advious work. Leak detection tools generally focus on two classes of errors: unreachable \nleaks that can be found by GC-based tech\u00adniques, and staleness leaks which are reachable from live objects \nin the heap. Because Hound focuses on detecting staleness leaks, we focus our discussion of prior work \non this area. Dynamic leak detection The prior work most closely related to Hound is SWAT [8], Sleigh \n[3], and SafeMem [24]. The relationship between SWAT and Hound has already been discussed. Sleigh is \na leak detector for Java similar to SWAT. Sleigh also uses adaptive bursty tracing to reduce the overhead \nof staleness detection, and the authors report an increase in false positives as a result, although they \nstill are able to detect a true leak amid noisy data. SafeMem uses ECC memory instead of program instrumentation \nto detect stale objects. It tracks allocation sites that appear to be leaking objects and uses ECC to \nreduce false positive rate for those sites. Unlike Hound, SafeMem cannot run on systems without ECC memory. \nOther prior work focuses more on the issue of reachability. Conservative garbage collection techniques \ncan be used to .nd unreachable objects. Several tools use this approach, including Purify [7], Valgrind \n[21], and RADAR [18]. While these tools are useful for diagnosing a large class of leaks, they cannot \n.nd leaked objects that are still reachable.  Several papers focus on providing more detailed information \nabout the causes of leaks to make debugging and correcting them easier. LeakBot automatically identi.es \nJava data structures that are potential leaks by evaluating the evolving structure of the heap graph \n[19]. Jump and McKinley describe a low-overhead approach to inferring sources of leaks by examining dynamic \ncharacteris\u00adtics of the points-from graph in Java programs [11]. Maebe et al. describe a high-overhead \nleak detector that identi.es the spe\u00adci.c program statement responsible for removing the last refer\u00adence \nfor reachability leaks [17]. Rayside and Mendel describe ob\u00ad ject ownership pro.ling, a high-overhead, \ntrace-based dynamic technique that incorporates structural information when report\u00ading leaks in object-oriented \nprograms [25]. MemTracker provides state-tracking hardware support for individual memory locations, allowing \nlow-overhead staleness detection [34]. Static leak detection Static analysis can detect certain types \nof memory leaks, but suf\u00adfer from false positives due to analysis imprecision. Clouseau in\u00adfers ownership \nconstraints and .nds violations that may indicate leaks [9]. Xie and Aiken use boolean constraints to \n.nd leaks based on escape analysis [36]. Cherem et al. propose an analysis that con\u00ad siders .ows through \nthe program graph from allocation points to deallocation points to identify possible leaks [5]. Orlovich \nand Rug\u00ad ina s analysis proves the absence of leaks, but can be used to detect leaks when the proof fails \n[23]. Leak tolerance Several recent papers propose methods for leak tolerance, both in C/C++ and in garbage \ncollected languages. For C applications, Cyclic Memory Allocation (CMA) [22] tolerates leaks by replacing \ndynamically-allocated memory with .xed-size buffers based on pro.ling runs. CMA can only eliminate leaks \nfrom sites which it identi.es as bounded and can erroneously overwrite live data when pro.ling is incorrect. \nIt has not escaped our attention that Hound s virtual compaction scheme could be used to provide leak \ntolerance. Garbage collection tolerates unreachable leaks by automatically reclaiming leaked objects, \nbut does not address staleness leaks. Both Melt [4] and LeakSurvivor [31] augment a relocating garbage \ncollector in Java with techniques to isolate and compress stale objects. Melt identi.es staleness with \na lightweight read barrier, while LeakSurvivor uses Sleigh s sampling mechanism. Tsai et al. combine \nstatistical techniques with conservative garbage collec\u00adtion to detect and tolerate unreachable memory \nleaks in C appli\u00adcations [33]. Static analysis can also eliminate memory leaks by program transformation. \nShaham et al. present two analyses that can elimi\u00adnate memory leaks in Java: the .rst detects dead entries \nin arrays that will never be read in the future [28], while the second uses shape analysis to detect \ndead references [29]. Lattner and Adve pro\u00ad pose pool allocation, a transformation that can statically \neliminate some leaks in C/C++ applications via points-to set liveness [13]. VM-techniques for memory \nmanagement Appel and Li describe a number of primitives and algorithms for exploiting virtual memory \nin user-mode [1], including the prim\u00ad itives used by Hound. Dhurjati and Adve introduce a technique that \nuses virtual memory remapping to detect dangling pointer er\u00adrors [6]. Each object is allocated on a new \nvirtual page, with mul\u00ad tiple virtual pages mapped to the same physical page. Their sys\u00adtem detects dangling \npointers by protecting the virtual pages hold\u00ading freed objects. By contrast, virtual compaction starts \nwith many objects mapped to individual virtual pages, and combines virtual pages (holding multiple objects) \nonto one physical page. Recent cooperative systems exploit communication between the OS virtual memory \nmanager (VMM) and the garbage collector to reduce paging due to garbage collection. CRAMM is a virtual \nmemory manager that provides detailed reference information, al\u00adlowing it to dynamically adapt GC heap \nsizes in order to maximize performance [37]. Hound uses a derivative of CRAMM s mecha\u00ad nism to control \nthe size of its aging queues. Hertz et al. present the bookmarking collector, a cooperative system where \nthe OS informs the runtime system of impending page eviction, and the garbage collector summarizes information \non the pages ( book\u00admarks ) that allow it to avoid traversing paged-out memory dur\u00ading garbage collection. \nArchipelago [16] uses an object-per-page allocator to improve resilience against buffer over.ow errors \nand uses virtual memory protection to compact cold pages and reduce physical memory overhead. 10. Conclusion \nThis paper presents Hound, a runtime system that precisely locates both memory leaks and sources of bloat. \nHound s key contribution is its hybrid memory management scheme, which both segregates objects at allocation \ntime with a context-sensitive allocator and sep\u00adarates leaked from non-leaked objects with an age-segregated \nal\u00adlocator. A novel virtual compaction mechanism allows Hound to compact memory without the need to move \nobjects, reducing frag\u00admentation due to segregation without degrading Hound s ability to locate leaks. \nHound operates on unaltered binaries, making deployment sim\u00adple. Hound locates both reachable and unreachable \nleaks without generating any false positives, and with extremely low overhead. For a range of applications, \nincluding servers and applications with low allocation-intensity, Hound incurs minimal runtime and mem\u00adory \noverhead, making it practical for use even for large deployed applications where performance is a key \nconcern. 11. Acknowledgments The authors would like to thank Ting Yang and Scott Kaplan for valuable \ndiscussions about Hound and Linux virtual memory man\u00adagement, Ted Hart for his feedback during the development \nof Hound, and Shan Lu, Martin Rinard, and Huu Hai Nguyen for pro\u00adviding us the leaky inputs for squid. \nThis material is based upon work supported by Intel, Microsoft Research, and the National Sci\u00adence Foundation \nunder CAREER Award CNS-0347339 and CNS\u00ad0615211. Any opinions, .ndings, and conclusions or recommenda\u00adtions \nexpressed in this material are those of the author(s) and do not necessarily re.ect the views of the \nNational Science Foundation. References [1] A. W. Appel and K. Li. Virtual memory primitives for user \nprograms. In Proceedings of the Fourth International Conference on Architectural Support for Programming \nLanguages and Operating Systems (ASPLOS 91), pages 96 107, 1991. [2] E. D. Berger, B. G. Zorn, and K. \nS. McKinley. Reconsidering custom memory allocation. In Proceedings of the 2002 ACM SIGPLAN Conference \non Object-Oriented Programming Systems, Languages and Applications (OOPSLA 02), pages 1 12, 2002. [3] \nM. D. Bond and K. S. McKinley. Bell: bit-encoding online memory leak detection. In Proceedings of the \n12th International Conference on Architectural Support for Programming Languages and Operating Systems \n(ASPLOS 06), pages 61 72, San Jose, CA, Oct. 2006. [4] M. D. Bond and K. S. McKinley. Tolerating memory \nleaks. In Proceedings of the 23rd Annual ACM SIGPLAN Conference on  Object-Oriented Programming, Systems, \nLanguages, and Applica\u00adtions (OOPSLA 2008), pages 109 126, Nashville, TN, Oct. 2008. ACM. [5] S. Cherem, \nL. Princehouse, and R. Rugina. Practical memory leak detection using guarded value-.ow analysis. In Proceedings \nof the 2007 ACM SIGPLAN Conference on Programming language design and implementation (PLDI 07), pages \n480 491, 2007. [6] D. Dhurjati and V. Adve. Ef.ciently detecting all dangling pointer uses in production \nservers. In Proceedings of the International Conference on Dependable Systems and Networks (DSN 06), \npages 269 280, Washington, DC, USA, 2006. IEEE Computer Society. [7] R. Hastings and B. Joyce. Fast detection \nof memory leaks and access errors. In Proceedings of the Winter 92 USENIX conference, pages 125 136. \nUSENIX Association, 1992. [8] M. Hauswirth and T. M. Chilimbi. Low-overhead memory leak detection using \nadaptive statistical pro.ling. In ASPLOS, pages 156 164, Boston, MA, Apr. 2004. ACM. [9] D. L. Heine \nand M. S. Lam. A practical .ow-sensitive and context\u00adsensitive C and C++ memory leak detector. In Proceedings \nof the ACM SIGPLAN 2003 conference on Programming Language Design and Implementation (PLDI 03), pages \n168 181, 2003. [10] R. E. Jones and R. Lins. Garbage Collection: Algorithms for Automatic Dynamic Memory \nManagement. Wiley, Chichester, July 1996. [11] M. Jump and K. S. McKinley. Cork: Dynamic memory leak \ndetection for garbage-collected languages. In Proceedings of the 34th annual ACM SIGPLAN-SIGACT symposium \non Principles of Programming Languages (POPL 07), pages 31 38, 2007. [12] P.-H. Kamp. Malloc(3) revisited. \nhttp://phk.freebsd.dk/pubs/malloc. pdf. [13] C. Lattner and V. Adve. Automatic pool allocation: improving \nperformance by controlling data structure layout in the heap. In PLDI 05: Proceedings of the 2005 ACM \nSIGPLAN conference on Programming language design and implementation, pages 129 142, 2005. [14] D. Lea. \nA memory allocator. http://gee.cs.oswego.edu/dl/html/ malloc.html, 1997. [15] C.-K. Luk, R. Cohn, R. \nMuth, H. Patil, A. Klauser, G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood. Pin: building customized \nprogram analysis tools with dynamic instrumentation. In Proceedings of the 2005 ACM SIGPLAN conference \non Programming language design and implementation (PLDI 05), pages 190 200, 2005. [16] V. B. Lvin, G. \nNovark, E. D. Berger, and B. G. Zorn. Archipelago: trading address space for reliability and security. \nIn Proceedings of the 13th International Conference on Architectural Support for Programming Languages \nand Operating Systems, (ASPLOS 08), pages 115 124, Mar. 2008. [17] J. Maebe, M. Ronsse, and K. D. Bosschere. \nPrecise detection of memory leaks. In Workshop on Dynamic Analysis (WODA 04), pages 25 31, 2004. [18] \nMicrosoft TechNet, Microsoft Corporation. Memory Leak Diagnoser, Dec. 2007. [19] N. Mitchell and G. Sevitsky. \nLeakBot: An automated and lightweight tool for diagnosing memory leaks in large Java applications. In \nEuropean Conference on Object-Oriented Programming (ECOOP), 2003. [20] Mozilla.org. Bugzilla@mozilla, \n2008. [Online; accessed 12-March\u00ad2008]. [21] N. Nethercote and J. Seward. Valgrind: a framework for heavyweight \ndynamic binary instrumentation. In Proceedings of the ACM SIGPLAN 2007 Conference on Programming Language \nDesign and Implementation (PLDI 07), pages 89 100, June 2007. [22] H. H. Nguyen and M. Rinard. Detecting \nand eliminating memory leaks using cyclic memory allocation. In Proceedings of the 6th International \nSymposium on Memory Management (ISMM 07), pages 15 30, 2007. [23] M. Orlovich and R. Rugina. Memory leak \nanalysis by contradiction. In Proceedings of the 13th Annual Static Analysis Symposium (SAS 06), pages \n405 424, 2006. [24] F. Qin, S. Lu, and Y. Zhou. SafeMem: Exploiting ECC-memory for detecting memory leaks \nand memory corruption during production runs. In Proceedings of the 11th International Symposium on High-Performance \nComputer Architecture (HPCA 05), volume 00, pages 291 302. IEEE Computer Society, 2005. [25] D. Rayside \nand L. Mendel. Object ownership pro.ling: a technique for .nding and .xing memory leaks. In Proceedings \nof the 22nd IEEE/ACM international conference on Automated software engineering (ASE 07), pages 194 203, \n2007. [26] N. R\u00a8ojemo and C. Runciman. Lag, drag, void, and use: Heap pro.ling and space-ef.cient compilation \nrevisited. In Proceedings of First International Conference on Functional Programming, pages 34 41, Philadelphia, \nPA, May 1996. ACM Press. [27] M. L. Seidl and B. G. Zorn. Segregating heap objects by reference behavior \nand lifetime. In Proceedings of the Eighth International Conference on Architectural Support for Programming \nLanguages and Operating Systems (ASPLOS 98), pages 12 23, San Jose, CA, Oct. 1998. [28] R. Shaham, E. \nK. Kolodner, and S. Sagiv. Automatic removal of array memory leaks in Java. In Proceedings of the 9th \nInternational Conference on Compiler Construction (CC 00), pages 50 66, London, UK, 2000. Springer. [29] \nR. Shaham, E. Yahav, E. Kolodner, and M. Sagiv. Establishing local temporal heap safety properties with \napplications to compile-time memory management. In SAS 03: Proceedings of the 10th Annual Static Analysis \nSymposium, 2003. [30] Standard Performance Evaluation Corporation. SPEC2006. http://www.spec.org. [31] \nY. Tang, Q. Gao, and F. Qin. LeakSurvivor: Towards safely tolerating memory leaks for garbage-collected \nlanguages. In Proceedings of the 2008 USENIX Annual Technical Conference (USENIX 08), pages 307 320, \nBoston, MA, June 2008. [32] L. Torvalds. Linux kernel mailing list post. http://lkml.org/lkml/ 2004/1/12/265, \nJanuary 2004. [33] T. Tsai, K. Vaidyanathan, and K. C. Gross. Low-overhead run\u00adtime memory leak detection \nand recovery. In Proceedings of the 12th Pac.c Rim International Symposium on Dependable Computing (PRDC \n06), pages 329 340. IEEE Computer Society, 2006. [34] G. Venkataramani, B. Roemer, Y. Solihin, and M. \nPrvulovic. Memtracker: Ef.cient and programmable support for memory access monitoring and debugging. \nIn Proceedings of the 13th International Symposium on High-Performance Computer Architecture (HPCA 07), \npages 273 284. IEEE Computer Society, 2007. [35] P. R. Wilson, M. S. Johnstone, M. Neely, and D. Boles. \nDynamic storage allocation: A survey and critical review. In Proceedings of the International Workshop \non Memory Management, volume 986, pages 1 116, Kinross, Scotland, Sept. 1995. Springer. [36] Y. Xie and \nA. Aiken. Context-and path-sensitive memory leak detection. In Proceedings of the 5th Joint Meeting of \nthe European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software \nEngineering (ESAC/FSE 05), pages 115 125, 2005. [37] T. Yang, E. D. Berger, S. F. Kaplan, and J. E. B. \nMoss. CRAMM: Virtual memory support for garbage-collected applications. In 7th Symposium on Operating \nSystems Design and Implementation (OSDI 06), pages 103 116. USENIX Association, 2006.   \n\t\t\t", "proc_id": "1542476", "abstract": "<p>Inefficient use of memory, including leaks and bloat, remain a significant challenge for C and C++ developers. Applications with these problems become slower over time as their working set grows and can become unresponsive. At the same time, memory leaks and bloat remain notoriously difficult to debug, and comprise a large number of reported bugs in mature applications. Previous tools for diagnosing memory inefficiencies-based on garbage collection, binary rewriting, or code sampling-impose high overheads (up to 100X) or generate many false alarms.</p> <p>This paper presents Hound, a runtime system that helps track down the sources of memory leaks and bloat in C and C++ applications. Hound employs <i>data sampling</i>, a staleness-tracking approach based on a novel heap organization, to make it both precise and efficient. Hound has no false positives, and its runtime and space overhead are low enough that it can be used in deployed applications. We demonstrate Hound's efficacy across a suite of synthetic benchmarks and real applications.</p>", "authors": [{"name": "Gene Novark", "author_profile_id": "81350568767", "affiliation": "University of Massachusetts, Amherst, Amherst, MA, USA", "person_id": "P1464329", "email_address": "", "orcid_id": ""}, {"name": "Emery D. Berger", "author_profile_id": "81100228645", "affiliation": "University of Massachusetts, Amherst, Amherst, MA, USA", "person_id": "P1464330", "email_address": "", "orcid_id": ""}, {"name": "Benjamin G. Zorn", "author_profile_id": "81100190820", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P1464331", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542521", "year": "2009", "article_id": "1542521", "conference": "PLDI", "title": "Efficiently and precisely locating memory leaks and bloat", "url": "http://dl.acm.org/citation.cfm?id=1542521"}