{"article_publication_date": "06-15-2009", "fulltext": "\n Analyzing Recursive Programs using a Fixed-point Calculus * SalvatoreLaTorre P. Madhusudan Gennaro \nParlato Dipartimento Informatica e Applicazioni, Departhment of Computer Science, Department of Computer \nScience, Universit`a degli Studi di Salerno, Italia. Univ. of Illinois at Urbana-Champaign, Univ. of \nIllinois at Urbana-Champaign, latorre@dia.unisa.it Illinois, USA. Illinois, USA. madhu@illinois.edu Universit`a \ndegli Studi di Salerno, Italia. parlato@illinois.edu Abstract We show that recursive programs where \nvariables range over .\u00adnite domains can be effectively and ef.ciently analyzed by describ\u00ading the analysis \nalgorithm using a formula in a .xed-point calcu\u00adlus. In contrast with programming in traditional languages, \na .xed\u00adpoint calculus serves as a high-level programming language to eas\u00adily, correctly, and succinctly \ndescribe model-checking algorithms. While there have been declarative high-level formalisms that have \nbeen proposed earlier for analysis problems (e.g., Datalog), the .xed-point calculus we propose has the \nsalient feature that it also allows algorithmic aspects to be speci.ed. We exhibit two classes of algorithms \nof symbolic (BDD-based) algorithms written using this framework one for checking for errors in sequential \nrecursive Boolean programs, and the other to check for errors reachable within a bounded number of context\u00adswitches \nin a concurrent recursive Boolean program. Our formal\u00adization of these otherwise complex algorithms is \nextremely simple, and spans just a page of .xed-point formulae. Moreover, we imple\u00adment these algorithms \nin a tool called GETAFIX which expresses algorithms as .xed-point formulae and evaluates them ef.ciently \nusing a symbolic .xed-point solver called MUCKE. The resulting model-checking tools are surprisingly \nef.cient and are competitive in performance with mature existing tools that have been .ne-tuned for these \nproblems. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cationModel \nchecking; F.3.1 [The\u00adory of Computation]: Specifying and Verifying and Reasoning about Programs; F.4.1 \n[Theory of Computation]: Mathematical LogicTemporal logic. General Terms Algorithms, Experimentation, \nVeri.cation. Keywords Software veri.cation, abstraction, logic, \u00b5-calculus, model-checking, recursive \nsystems. * This work was partially funded by NSF CAREER Award CCF 0747041, by the Universal Parallel \nComputing Research Center at the University of Illinois at Urbana-Champaign (a center sponsored by Intel \nCorporation and Microsoft Corporation), and the MIUR grants ex-60% 2007-2008 and FARB 2009 Universit`a \ndegli Studi di Salerno (Italy). Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. Copyright c &#38;#169; 2009 \nACM 978-1-60558-392-1/09/06. . . $5.00 1. Introduction Abstraction is a key concept in veri.cation. \nAnalyzing complex programs against relatively simple properties has become practical in recent years \nprimarily due to abstraction based techniques, which include type-checking, static-analysis, and abstract-interpretation. \nAbstraction-based veri.cation is often composed of two distinct methods the abstraction engine that simpli.es \na complex pro\u00adgram into a tractable model and an analysis engine that, using .xed\u00adpoint computations, \ndeduces properties of the model. This paper is devoted to the key analysis component in the second phase \nof veri.cation model-checking the state-spaces of recursive Boolean models of imperative programs. A \nBoolean program is a recursive imperative program where all variables range over the Boolean domain only. \nBoolean pro\u00adgrams are a standard model used in abstraction based veri.cation. The fairly successful paradigm \nof verifying control-intensive prop\u00aderties using predicate abstraction, for instance, generates Boolean \nprogram models. Microsoft Research s SLAM engine [5], its com\u00admercial developer-kit cousin SDV (Static \nDriver Veri.er [3]), the checker BLAST [6], and the tool Terminator [10] that checks ter\u00admination for \nprograms, are all prominent artifacts that construct Boolean models whose analysis leads to .nding errors \nor proving programs correct. Several model-checkers for Boolean programs exist, and many of the ef.cient \ncheckers use symbolic techniques that represent sets of states using Boolean Decision Diagrams (BDDs). \nThe SLAM tool utilizes the reachability solver BEBOP [4] that computes pro\u00adcedure summaries using BDDs \n(see [21, 18] for the traditional al\u00adgorithms for reachability). The MOPED tool is a very ef.cient and \nmature checker: one of its versions computes the reachable set by computing the .nite automaton that \nrepresents the set of all reach\u00adable con.gurations (including the stack), while the other two ver\u00adsions \nuse a weighted pushdown system library [11]. Implementing symbolic model-checking algorithms is, in gen\u00aderal, \na complex task. A researcher who comes up with a new al\u00adgorithm to model-check a system often implements \nin a traditional programming languages like C or Java, utilizing a BDD-library to perform the symbolic \noperations. Myriad heuristics needs to be put in place, including decisions on ordering of variables, \nmanaging memory and caching, deciding order of evaluations, when to reset temporary terms, and a host \nof other tricks, to obtain a reasonably ef.cient implementation. Moreover, small changes to the algorithm \nmay require considerable change in the design of the program, dis\u00adcouraging the testing of new ideas, \nand severely affecting the pro\u00adductivity of the programmer. In this paper, we propose that most symbolic \nmodel-checking algorithms are essentially .xed-point computations that can be compactly described in \na high-level .xed-point calculus. Our main thesis is that model-checking algorithms for Boolean programs \ncan be described easily using a .xed-point calculus, and by utiliz\u00ading a symbolic .xed-point solver, \nwe can obtain ef.cient model\u00adcheckers, without resorting to low-level programming.  Our main contribution \nis to substantiate the above thesis by building ef.cient symbolic model-checking algorithms for solving \nthe reachability problem for sequential and concurrent recursive Boolean programs, writing the algorithms \nin a .xed-point calculus. We show that by using a .xed-point solver, we can automatically obtain an ef.cient \nimplementation of these algorithms. We have im\u00adplemented our ideas in a new tool, GETAFIX ( get a .x \nusing .xed\u00adpoints ), which take as input sequential and concurrent Boolean programs, and model-checks \nthem against reachability speci.ca\u00adtions. A detailed experimental evaluation shows that our solvers are \ncompetitive with sophisticated mature checkers that have been engineered for these problems. For sequential \nBoolean programs, we show that we can en\u00adcode the traditional algorithm for reachability using simple \n.xed\u00adpoint formulae. We adapt the traditional algorithm into two algo\u00adrithms, which ensure better performance \nby restricting themselves to searching using only the reachable parts of the search-space. The formulae \ndepicting the two algorithms are very readable small for\u00admulae, one of 40 lines and the other of 50 lines! \nConcurrent recursive Boolean programs with shared memory do not have a decidable reachability problem. \nSince concurrency bugs are notoriously hard to .nd, and since abstracting a program natu\u00adrally yields \na recursive model, the problem of checking reachability in concurrent programs is an important one. A \nrecent proposal [16] is to search the space reached by a concurrent program using at most k context switches, \nwhere k is a .xed bound. Intuitively, ex\u00adploring a few number of context-switches exhaustively searches \na very interesting space for concurrency errors, and studies have shown that a few context-switches give \nvery high coverability of the entire search space, and that many concurrency errors manifest within a \nsmall context-switch bound [15]. Bounded context-switching reachability for concurrent recur\u00adsive programs \n(with a .xed number of threads) was shown to be decidable by Qadeer and Rehof in 2005 [16]. The .rst \nalgorithms proposed to solve this problem involved, unfortunately, keeping the entire description of \nstack contents reached by each individual pro\u00adcess using .nite automata (similar to the way BEBOP computes \nreachability). A model-checker for bounded context-switching was not implemented until recently as it \ninvolved a complex algo\u00adrithm involving automata represented as BDDs. Recently, Lal and Reps [12] have \nshown how to reduce the context-bounded reacha\u00adbility problem to the reachability problem for sequential \nrecursive programs. However, this conversion and the implementation are algorithms that search using \neven unreachable parts of the search space (called the eager approach in their paper). They also propose \na set of rules for computing the reachable states lazily, exploring only the reachable parts of the search \nspace, but this has not been implemented. Also, very recently, there has been an implemen\u00adtation of context-bounded \nreachability in an extension of Moped (called JMoped) that solves the problem by iteratively computing \nthe automata representing reachable con.gurations. In this paper, we show a new (and simple) .xed-point \nformu\u00adlation of the algorithm to solve bounded context-switching reacha\u00adbility of concurrent recursive \nprograms. Our algorithm is described using a formula that adds a couple of clauses to the sequential \nreachability algorithm, and computes only using the reachable states of the concurrent program. While \nour .xed-point formu\u00adlation is similar to the set of rules for lazy evaluation described in [12], it \nis new and more ef.cient. In particular, the rules pre\u00adsented in [12] involve keeping tuples, where the \ntuple contains as many as 3k global variables, where k is the context-switching bound. Ours, in contrast, \ninvolves a .xed-point computation of tu\u00adples that keep track of at most k +1 copies of global variables \nonly. As k increases, this tuple s length depicts the precise space increase in model-checking, and hence \nwe believe that our formulation is signi.cantly more ef.cient. It is worth mentioning that in [12] the \nauthors assume that along any computation the control switches happen according to a round-robin scheduling. \nThus, for computa\u00adtions allowing up to r round-switches (which, for 2 threads, means 2r context switches), \nthey can implement their rules by using just 3r global variables. We observe that this improvement is \northogo\u00adnal to what we propose in this paper, and our ideas are applicable in their setting too, thus \nreducing the number of global variables required. Turning to the implementation, we encode our algorithm \nfor bounded-context switching reachability as a .xed-point formula, and obtain an ef.cient symbolic model-checking \nalgorithm. The .xed-point formulation is quite simple, and in fact it took us only a couple of days to \nwrite the formula (algorithm), and rearrange terms to get ef.ciency! This algorithm is also incorporated \nin our implementation, and we show that it works well in practice on a class of Bluetooth examples. Our \nproposal of using a high-level .xed-point calculus as a pro\u00adgramming language to easily write symbolic \nmodel-checking algo\u00adrithms has several advantages. First, it eases the effort in building model-checking \ntools considerably. We have implemented scores of variants of the model-checking algorithm, using a simple \nrewrit\u00ading of the formula, and evaluated the results. If we had implemented our checker using a language \nsuch as C, we would have certainly not have tried these many variants, nor would we have implemented \nthe concurrent program checker (let alone implementing it two days). We believe that our approach greatly \neases programming, letting novice programmers and theoreticians implement their al\u00adgorithmic ideas with \nlittle effort, while not sacri.cing ef.ciency. Secondly, we believe that our framework aids building \nof cor\u00adrect correctness tools. Most model-checking tools have bugs, pri\u00admarily due to the hard task of \nmanaging computations and algo\u00adrithms natively in a traditional programming language. During our experiments, \nwe found errors in MOPED, which were duly cor\u00adrected by its authors. Seeing our entire algorithm on one \npage aided us greatly in reviewing the code (formula) and arguing its correct\u00adness. We found the transformation \nfrom the mathematical formula\u00adtion of the algorithm on paper to the .xed-point formula easy and intuitive. \nThe .xed-point calculus that we propose to use is a quanti.ed Boolean logic with least-.xed point operators \n(more precisely, we use .rst-order logic on the domain {true, false} with an additional least .xed-point \noperator). While this calculus has a natural seman\u00adtics based on least-.xed points, we also endow it \nwith an opera\u00adtional semantics that precisely describes how the .xed point will be computed. This operational \nsemantics is the natural Tarskian it\u00aderative computation, and is intuitive and natural. Furthermore, \neven if the formulae we write are not monotonic (and hence least-.xed points may not exist), the operational \nsemantics gives precise al\u00adgorithmic meaning to our formulae. In fact, in one of our algo\u00adrithms (the \noptimized entry-forward algorithm), it becomes essen\u00adtial to use a non-monotonic operator. In this case, \nthe operational semantics is what gives us algorithmic control over the way the .xed-points are computed. \nDeclarative approaches to building analysis tools have been pro\u00adposed earlier. Notably, Lam et al [13] \npropose to reduce context\u00adsensitive static analysis questions to answering queries in Data\u00adlog. Using \nan ef.cient BDD-based solver for Datalog (bddbddb), the authors obtain automatic implementation for program \nanalysis problems. They too argue that using an intermediate high-level lan\u00adguage to state analysis problems \ngreatly eases the engineering of an ef.cient static analysis tool.  It is in fact well known that reachability \nof recursive programs reduces to querying Datalog (see [1] for a precise reduction). How\u00adever, though \nDatalog is a convenient way to declaratively state the reachability problem, Datalog is too weak to express \nthe algorith\u00admic control that we desire in guiding the search. One may of course wonder whether a clever \nDatalog solver like bddbddb may outper\u00adform the algorithms that we wish to encode. We actually did try \nthis idea, and in fact built an automatic transformation of Boolean pro\u00adgrams to Datalog. However, the \ninitial experimental results were poor, and we abandoned this approach. The programmer has very little \ncontrol on how the Datalog queries are computed; heuris\u00adtics like magic-set transformations and other \noptimizations are of\u00adten implemented and discourage control by the programmer. We believe that some control \non how exactly the algorithm searches the state-space (like the control required to describe the optimized \nentry-forward algorithm we formulate in this paper) is required to build an ef.cient reachability solver. \nIn summary, this paper makes the following contributions: The thesis that symbolic model-checking algorithms \ncan be easily, correctly, and ef.ciently engineered by expressing the model-checking algorithm as a formula \nin a .xed-point calculus over the Boolean domain.  The formulation of three algorithms for checking \nreachability in recursive Boolean programs as .xed-point formulae. The algo\u00adrithms get increasingly complex \nto describe but are increasingly ef.cient, and the .nal one is competitive with existing mature solvers. \n A new .xed-point formulation of the reachability problem for concurrent recursive Boolean programs \nunder a context\u00adswitching bound. Our formulation involves a .xed-point over a tuple that is considerably \nshorter than previous formulations.  The implementation of a model-checker, called GETAFIX,that automatically \ntranslates Boolean programs to Boolean formu\u00adlae that capture its behavior, and by incorporating the \nabove mentioned algorithms written using .xed-point formulae, im\u00adplements them using the symbolic .xed-point \nsolver MUCKE.  An extensive evaluation of GETAFIX on sequential programs, derived from SLAM device-driver \nbenchmarks and TERMINA-TOR benchmarks that show that GETAFIX is extremely compet\u00aditive with existing \ntools.  An evaluation of the GETAFIX for reachability in concurrent programs on a class of BlueTooth \nbenchmarks, where it per\u00adforms well, competitive with existing prototype tools that have been developed \nto solve this problem.  Related work The BEBOP tool implements reachability in recursive Boolean pro\u00adgrams \nusing summaries, similar to the algorithms proposed in this paper. The tool MOPED [11, 20] implements \nboth forward and backward symbolic reachability algorithms for Boolean programs. The tool is built for \npushdown systems with local and global vari\u00adables ranging over .nite domains, and the implemented algorithms \nconstruct a .nite automaton accepting the set of reachable con.g\u00adurations (correctness relies on the \nfact that this set is regular [8]). The algorithms proceed by growing the automaton until saturation. \nEach edge added to the automaton in this process corresponds to adding a pair to the summary of a procedure, \nand in these regards, the forward algorithm builds the summary by taking the entry for\u00adward (E-edges \nsummarize the entry-to-exit reachability relation) and the backward algorithm by taking the exit backward. \nWeighted pushdown systems, where edges of the pushdown graph are endowed with weights, have been used \nto analyze in\u00adterprocedural data.ow analysis problems [19]. A new version of MOPED has been built using \nthe weighted pushdown system library to compute reachability of Boolean programs as well. In [1], the \nmodel-checking of recursive state machines (a for\u00admalism equivalent to Boolean programs) is studied. \nThere, the au\u00adthors propose a reachability algorithm that computes the summary for each procedure going \neither forward or backward depending on whether the number of entries and the number of exits is smaller. \nThis yields an O(n.2) bound on the time complexity for solving reachability, where n is the number of \nvertices and . is the maxi\u00admum over all procedures of the minimum between the number of entries and the \nnumber of exits. Though the algorithm can be imple\u00admented symbolically via Datalog rules, the backward-computation \nutilized in this can discover unreachable states. Recently, a sub\u00adcubic algorithm for recursive state \nmachines was given in [9], though it is not clear how to implement it symbolically. Symbolic reachability \nhas been implemented for hierarchic reactive modules (no recursion) in the tool HERMES [2]. The idea \nof studying context-bounded reachability stems from a paper by Qadeer and Wu [17] where the authors study \nthe problem for two context-switches. In [16], it was shown that the bounded context-switching problem \nfor recursive concurrent programs is de\u00adcidable for any bound. In a recent paper, Lal and Reps propose \na constructive reduction of the bounded context-switching reachabil\u00adity problem to reachability on sequential \nrecursive programs. They also provide an eager implementation of their algorithm. More re\u00adcently, the \npaper [22] describes an implementation of the original algorithm by Qadeer and Rehof [16] that checks \nbounded context\u00adswitching reachability using a tuple of automata that represent the con.gurations of \nthe individual threads. As mentioned earlier, Datalog has also been successfully used as a high-level \nlanguage to express context-sensitive analysis of recursive programs, by using a BDD-based solver (bddbddb) \nfor Datalog [24, 13]. A convenient intermediate level between using high-level spec\u00adi.cations and programming \ndirectly with BDDs in order to imple\u00adment program analysis tools is given by JEDD [14], where BDDs are \nabstracted as database-style relations and operations on rela\u00adtions. Jedd, however, does not provide \n.xed-point operators that we need to express algorithms.  2. Recursive Boolean programs Let us .x the \nsyntax of a simple sequential programming language with variables ranging only over the Boolean domain, \nand with explicit syntax for nondeterminism, (recursive) function calls, and tuples of return values. \nLet us .x a set of variable names Var . Programs are described by the following grammar: (pgm) ::= (gvar-decl)(proc-list) \n(gvar-decl)::= decl x; |(gvar-decl)(gvar-decl) (proc-list) ::= (proc)(proc-list)|(proc) (proc) ::= fh,k \n(x1,...,xh) begin (lvar-decl)(stmt) end (lvar-decl) ::= decl x ; |(lvar-decl)(lvar-decl) (stmt) ::= (stmt) \n; (stmt)| skip |(assign)| call fh,0( (expr1),...,(exprh)) | return (expr1),...,(exprk)| if ((expr)) \nthen (stmt) else (stmt) . | while ((expr)) do (stmt) od (assign) ::= x1,...,xm := (expr1),...,(exprm)| \nx1,...,xk := fh,k((expr1),...,(exprh)) (expr) ::= T | F |*| x |\u00ac(expr)|(expr).(expr)| (expr).(expr) \n In the above, xi are variables in Var,and fh,k denotes a procedure with h formal parameters and k return \nvalues. A program has a global variable declaration followed by a list of procedures. Each procedure \nis a declaration of local variables followed by a sequence of statements, where statements can be simultaneous \nassignments, calls to functions (call-by-value) that take in multiple parameters and return multiple \nvalues, conditional statements, while-loops, or return statements. Boolean expressions can be true, false, \nor non-deterministically true or false (*), and can be combined using standard Boolean operations. Functions \nthat do not return any values are called using the call statement. We will assume several obvious restrictions \non the above syn\u00adtax: global variables and local variables are assumed to be dis\u00adjoint; formal parameters \nare local variables; the body of a function fh,k has only variables that are either globally declared, \nlocally declared, or a formal parameter; a return statement in the body of fh,k returns exactly k values. \nLet us also assume that there is a procedure main, which is the procedure where the program starts, and \nthat there are no calls to this procedure in the code of P . The semantics is the obvious one: a con.guration \nof a program consists of a stack which stores the history of positions at which calls were made, along \nwith valuations for local variables and formal parameters, and the top of the stack contains the local \nand global valuations, and a pointer to the current statement being executed. Let us .x a program P , \nand let the set of formal parameters, local variables and global variables in P be respectively Par, \nL and G. As we observed above Par . L.A global valuation is a function vG : G .{T,F } that assigns true \nor false to every variable in G. Analogously, a local valuation is a function vL : L .{T,F } that assigns \ntrue or false to every variable in L.Let VG and VL denote the set of all global and local valuations, \nrespectively. Let us assume that each individual statement in each procedure in P is labeled uniquely \nby an element from a set PC (called program counter). A state of the program P is given by a program \ncounter, a local valuation and a global valuation. We will denote with u the state de.ned by the tuple \n(u.pc, u.Local, u.Global). The con.guration of the program P is a call-stack a stack of elements, each \nelement being a pair containing a program counter and a local valuation, except the top of the stack \nwhich is the current state of P (i.e. the stack is a word in (PC \u00d7 VL \u00d7 VG).(PC \u00d7 VL) *). The reachability \nproblem asks whether a particular statement in the program marked using a special label Goal is reachable. \nMore precisely, given a program counter pc, the problem is to determine if there is a reachable con.guration \nwhere pc is the program counter of the current state.  3. Fixed-point calculus over Boolean domains \nIn this paper, we will use a basic .rst-order logic along with a .xed\u00adpoint formula to represent model-checking \nalgorithms for both sequential and concurrent recursive Boolean programs. Intuitively, a symbolic model-checking \nalgorithm takes a set of input relations, typically describing the model that is being checked (for example, \nthe transition relation and the set of initial states are input relations). Using these relations, the \nalgorithm proceeds to compute several sets in order to check the problem at hand for instance, a model\u00adchecker \nfor non-recursive Boolean programs will start from a set of initial states, and compute the set of all \nreachable states. The central theme of this paper is that a high-level .xed-point calculus serves as \nan adequate programming language to describe typical model-checking algorithms, and moreover, using an \nef.\u00adcient underlying platform to execute these formulae, we can obtain fast and ef.cient veri.cation \ntools. Most importantly, the formulae are very easy to write, follows the mathematical algorithm a pro\u00adgrammer \nintends to write, and leads often to bug-free implementa\u00adtions. We believe that this programming paradigm \nwill make novice programmers quickly implement their ideas, without the need to learn the (often undocumented) \nheuristics and yet obtain ef.cient implementations. The .xed-point calculus we use in this paper is a \n.rst-order variant of the \u00b5-calculus (more precisely, .rst-order logic with a least-.xed point operator \nsuf.ces) that has operators Boolean combinations of sets, existential quanti.cation over the Boolean \ndomain, and least .xed-point operators. Let us .x some notation. A Boolean relation Rk(x1,...,xk) is \nany k-ary relation over the Boolean domain B = {true, false},for some k . N.I.e. Rk . Bk . Fix a set \nof variables Var. A Boolean expression over Var is given by the following syntax: BoolExp ::= T | F | \nRk(x1,...,xk) |\u00acBoolExp | BoolExp . BoolExp | BoolExp . BoolExp | .x.(BoolExp) |.x.(BoolExp) In the above, \nx1,...,xk range over variables in Var and Rk denotes any k-ary Boolean relation. The semantics of Boolean \nexpressions is the standard one, and an expression de.nes some m-ary relation (where m is the number \nof free variables in the expression). We say that a boolean expression is positive if the relations Rk \nused in the expression do not occur within an odd number of nega\u00adtions. (Intuitively, the formula is \nallowed to test membership of tuples in Rk, but not test non-membership.) In this case, the rela\u00adtion \nde.ned by the expression is monotonic, in the sense that when the relations Rk are interpreted as larger \nrelations, the expression also relates a (not-strictly) larger relation as well. An equation over R is \nan equation of the form R = BoolExp. Note that R may appear also in BoolExp and thus this depicts a recursive \nde.nition of R. By Tarski s .xed-point theorem, it follows that any positive equation system (set of \nequations) has a unique least .xed-point (and unique greatest .xed-point). That is, there is a unique \nleast interpretation for the relation that satisfy the equations. Algorithmic semantics of a .xed-point \nformula Consider a system of equations (not necessarily positive): Eq = {R1 = B1,R2 = B2,...Rk = Bk}. \nThen we de.ne a precise algorithmic computation of a particu\u00adlar relation, say R1, as follows: Evaluate(R,Eq):- \nLet (R = B) occur in Eq; Set S := Emptyset; while (S does not stabilize) { -Eq. := Eq \\ R = B; -Replace \nR in each expression of Eq. with S to get Eq''; -for every relation Ri that occurs in B { Si := Evaluate(Ri \n,Eq'); } -Substitute each Ri in B with Si, replace R in B with S, and evaluate B to obtain the new value \nof S; } return S; While the above may look daunting, it is actually quite intuitive. The algorithm above, \nin order to compute a relation R in an equa\u00adtion system with R = B in it, essentially tries to .nd a \n.xed-point by starting with interpreting R as the empty set, and in each round replacing R with its current \ninterpretation, evaluating the remain\u00ading equation system, and substituting those relations in B to obtain \nthe next interpretation of R.  The Tarski-Knaster theorem says that the above iterative algo\u00adrithm will \nalways converge to the least .xed-point of the relations, when all the expressions are positive. In other \nwords, there is a smallest interpretation for each of the Ri s that satis.es all the equations in the \nsystem, and the above algorithm computes it. In this paper, we will con.ne ourselves to algorithms that \ncan be described as a least .xed-point of a set of equations. While most of our algorithms will use only \npositive expressions, there are certain situations when we may want to use expressions negatively (for \ninstance, to compute on a set smaller than the current set of reach\u00adable states, in order to speed up \ncomputation). When non-positive expressions are used, the above algorithm need not terminate (the interpretation \nfor a relation may never stabilize), but we will ensure that the particular algorithms we write do indeed \nterminate. Let s give an example of an algorithm written as a formula. Consider a transition system, \nwhere states are valuations over the Boolean variables v\u00af= v1,...vk, let the transition relation be Trans(\u00afv, \nv\u00af') and let Init(\u00afv) the set of initial states, both expresses as Boolean formulae. Then the least .xed-point \nof the equation system with a single equation Reach(\u00afu)= Init(\u00afx.(Reach(\u00afx, \u00af u) ..\u00afx) . Trans(\u00afu)) is \nthe set of all states reachable in the transition system. Also, the above formula gives a concrete way \nof computing it: we start with the Reach set empty, and evaluate the expression, to get the initial states. \nWe then substitute it back in the formula, and obtain the set of states reachable from the initial states \nin zero or one steps. We continue this till we reach a .xed-point, and stop. The above formula is in \nfact all that we need to write an al\u00adgorithm that symbolically model-checks a (non-recursive) transi\u00adtion \nsystem. We will have an underlying .xed-point calculus solver that will perform the iterations ef.ciently \nusing BDDs, employing heuristics to order variables, evaluate sub-expressions, project away variables \nthat are existentially/universally quanti.ed, etc. The aim of this paper is to show that ef.cient model-checking \nalgorithms for recursive sequential and concurrent programs can be obtained by simply writing such formulae. \n 4. The entry-forward summary-based algorithm In this section, we show how to implement a symbolic reachabil\u00adity \nalgorithm for recursive Boolean programs. Note that a recursive Boolean program has, in general, an in.nite \nnumber of states it can reach (due to the unbounded stack). Traditional algorithms for reachability (which \nare sound and complete) compute the reacha\u00adbility sets using summaries. Our aim in this section is to \ngently introduce the primary ideas in model-checking recursive programs, and encode the algorithms using \n.xed-point formulae. We will .rst recall the most simple of the sound and complete summary-based algorithms, \nand show how to express it as a .xed-point formula. This algorithm, however, is not ef.cient, as it can \ncompute the reachable states using interme\u00addiate sets that are not reachable. As we progress, we will \nintroduce better algorithms that are competitive with existing tools. In order to describe the algorithms \nfor solving reachability of Boolean programs, let us assume the following template formulae that describe \nthe semantics of a program. Let us also assume that the Goal program counter that we test reachability \nfor is in the main module (we can easily transform a general reachability problem to such a one). Internal \nTransitions: Transitions that happen within a module (that is, those that are neither a call nor a return) \nare described by a formula ProgramInt(u, v). For instance, an assignment will compute the variables of \nthe next state v depending on those of the current state u, and update the program counter. Transitions \ninto a Call: Transitions that take the program from a call in a procedure to the beginning of the procedure \nbeing called are described by a formula IntoCall(u, v). This formula ensures that v.Global = u.Global \n(global variables are pre\u00adserved) and that v.Local initializes the local variables of the called module \n(in particular, it sets the value for the formal pa\u00adrameters). Entry, Exit: Let us assume formulae Entry(u.pc) \nand Exit(u.pc) that capture the entry and exit labels of all procedures in the program. Entries correspond \nto labels of the .rst statement in all procedures. Exits are labels of return statements or after the \nlast line of a procedure. Initial states: The formula Init(u.pc) captures the constraints on the initial \nprogram counter, i.e. states that u.pc is the label that precedes the .rst statement of main. Across \na call: Let us assume a formula Across(u.pc, v.pc) that captures the pairs of program counters denoting \nfrom where a call occurs to where the call returns to (both program counters in the same procedure). \nReturn from a call: Let us assume a formula Return(u, v, w) that captures the update of variables according \nto the values com\u00adputed in a procedure call. In this formula, u refers to the state at the procedure \ncall, v to the state on exiting from the called pro\u00adcedure, and w to the state of the calling procedure \non returning from the call. Formula Return ensures that Across(u.pc, w.pc) holds, and also that w.Global \nmatches v.Global and w.Local matches u.Local except for those variables that are assigned with return \nvalues (in particular, if the called procedure does not return values, we have w.Global = v.Global and \nw.Local = u.Local). 4.1 A simple summary-based algorithm We are now ready to write a summary-based least-.xed \npoint def\u00ad inition of the reachable states according to a classical summary\u00ad based algorithm. A summary \ncaptures the set of all pair of states (u, v),where u is an entry to a procedure and v is a state of \nthe same procedure that is reachable from u. We can easily write a recursive de.nition of the summary \nrela\u00ad tion, using the following three clauses: If u is an entry, then Summary(u, u) holds.  If Summary(u, \nx) holds and there is an internal move from x to v,then Summary(u, v) holds.  If Summary(u, x) holds, \nx is a call, y is the entry x leads to, v is a return matching the call x and further Summary(y, z) holds \nwhere z is an exit, then Summary(u, v) holds provided v matches x on the local variables and matches \nz on the global variables modulo the assignment of the returned values.  More succinctly, Summary is \nthe least .xed-point of the follow\u00ading equation: Summary(u, v)= (Entry(u.pc) . u = v) . (.x.(Summary(u, \nx) . ProgramInt(x, v))) . (.x, y, z.(Summary(u, x) . IntoCall(x, y) . Summary(y, z) . Exit(z.pc) . Return(x, \nz, v)))  THEOREM 1. Let P be a program. Let u be an entry of procedure main. The least .xed-point of \nthe equation for Summary given above relates u and a state v if and only if v is a state of main that \nis reachable in P . The above formula, surprisingly, can be immediately written us\u00ading a mu-calculus \nformula, and using a tool like MUCKE, we would obtain a symbolic model-checker for recursive Boolean \nprograms! The standard approach to evaluate a .xed-point formula, when ap\u00adplied to the above, will result \nin an algorithm that starts with sum\u00admaries capturing all entries of all modules (whether they are reach\u00adable \nor not) and compute the set of all reachable states in each pro\u00adcess, utilizing summaries of called procedures. \nSymbolic model\u00adchecking algorithms that search spaces that are not reachable often do much worse than \nthose explore forward from the initial state, ensuring that only reachable states are discovered. We \nwill modify the above scheme into one that computes only the reachable states.  4.2 The entry-forward \nsummary-based algorithm Let us now re.ne the scheme above so that, at any point of the computation of \nthe set of reachable states, we keep only states that are reachable. In other words, if Summary(u, v) \nholds, we insist that u and v are reachable (with some stack content) from the entry of the main-procedure. \nIntuitively, we start with the set of only the entry summary of the main procedure. At a call to a procedure, \nwe allow the entry\u00adsummary of the called procedure to be discovered. Computation proceeds otherwise in \na similar manner as above. Let us call this relation SummaryEF (for Entry-forward , as we are intuitively \ntak\u00ading the entry forward to compute the summary). SummaryEF(u, v)= (Entry(u.pc) . u=v . Init(u.pc)) \n. (.x.(SummaryEF(u, x) . ProgramInt(x, v))) . (.x, y.(SummaryEF(x, y) . IntoCall(y, u) . u=v)) .(.x, \ny, z.(SummaryEF(u, x).IntoCall(x, y).SummaryEF(y, z) . Exit(z.pc) . Return(x, z, v))) The third clause \nabove, which has been added new, generates the pair of identical entries of a module that is reachable. \nIt is easy to see that SummaryEF computes reachability, and any two states related by summary must be \nindividually reachable from the initial state of the program. The above formula (algorithm) can be optimized \nfurther. Notice that the .xed-point computation will, in each round, evaluate the formula inside out, \nrepresenting each set using a BDD. Now let us look closely at the last disjunctive clause which computes \nthe discovery of a return (SummaryEF(\u00afu, v\u00af)) to a module, from the caller (SummaryEF(\u00afu, x\u00af)) and a \nsummary of a called procedure (SummaryEF(\u00afy, z\u00af)). This clause has two SummaryEF relations that are combined \nconjunctively, and given that this set gets very large, and the conjunction of two BDDs takes time product \nof their sizes, this is a serious bottle-neck in the computation. We aim to rewrite this clause such \nthat the two summary sets are .rst combined with other sets with a presumably small BDD representation \nand then their conjunction is computed. We start by arranging the constraints into two groups: (A) the \nconstraints in\u00advolving the caller (x\u00af) and the return (v\u00af), and (B) the constraints involving the exit \n(z\u00af), the entry (y\u00af) and the return (v\u00af). For this pur\u00adpose, we split the predicate Return into two parts, \ncalled respec\u00adtively ReturnA and ReturnB, each restricted to state constraints only on a subset of the \nvariables. Recall that formula IntoCall(x, y) captures the transitions from a call x to an entry y. In \nparticular, it ensures x.Global = y.Global and that y.Local is consistent with the parameters passed \nto the module of y when called from x. Thus, to express such constraints, y.pc is not really needed provided \nthat we can refer to the module of y. Therefore, instead of IntoCall(x, y) we can use an equivalent formula \nIntoCall1(x, pc, y.Local, y.Global) where pc is a program counter of the same module as y.pc.    \n                     Thus, we quantify over x\u00afthe constraints (A), and extract the \nvariables in x\u00afthat are required in (B). Then, we quantify over y\u00afand z\u00afthe constraints (B) and extract \nthe variables of y\u00afand z\u00afwhich are in use in (A). Rewriting the algorithm as a formula, we replace the \nlast dis\u00adjunctive clause of the above formula with: . (. xpc, zpc, yLocal , yGlobal. (.x.(SummaryEF(u, \nx) . ReturnA(x, zpc,v) . IntoCall1(x, zpc, yLocal , yGlobal) . xpc = x.pc)) . (.y, z.(SummaryEF(y, z) \n. (yGlobal = y.Global . yLocal = y.Local) . (zpc = z.pc . Exit(z.pc)) . ReturnB(y, z, xpc,v))) ) The \nabove formula, except for some implementation details, is exactly the formula for one of the algorithms \nthat we report in the implementation (see the Appendix for the exact implemented formula). The following \ntheorem holds. THEOREM 2. Let P be a program. The least .xed-point of the equation for SummaryEF given \nabove relates a state u and a state v if and only if u is an entry of a procedure that is reachable in \nP and v is a state in the same procedure reachable from the entry u using a run that returns from all \ncalls. In particular, SummaryEF(u, v) holds when u is an entry of main iff v is a state of main that \nis reachable in P .  4.3 An optimized entry-forward algorithm We now present a high-level description \nof an optimization of the entry-forward algorithm. This algorithm involves several issues that we will \nhighlight. We compute the set SummaryEFopt as described by the following iterative algorithm. SummaryEFopt \nis initialized with the initial con\u00ad.gurations. Now, let X be the con.gurations discovered in the last \niteration, and Relevant be set of all SummaryEFopt con.gurations that have as a program counter the program \ncounter of a con.gura\u00adtion of X.We de.ne New1 to be the the image-closure of Relevant on internal transitions, \nand de.ne New2 as the image of Relevant on transitions that call a module or skip a called module using \na summary. Thus, SummaryEFopt is the union of SummaryEFopt in the previous round, New1,and New2. The \nalgorithm terminates when SummaryEFopt stabilizes. Two aspects are relevant in the algorithm described \nabove. Typ\u00adically, programs exhibit many more internal transitions than calls and/or returns, and the \ncomputation of calls and returns are quite expensive compared to internal transitions a call or a return \nin\u00advolves at least two con.gurations of different modules and the pa\u00adrameter/return values are typically \nset in a non-trivial way. Thus, the .rst idea is to compute, in one iteration, only one set of new calls \nand returns, but compute the internal moves to completion (ignoring calls and the returns that may become \nactive). Another important intuition is that we would compute only starting from con.gurations that are \nnewly discovered in the previous round. Un\u00adfortunately, the BDD representing such a set can be quite \ncomplex and completely different from the one for SummaryEFopt. A better solution is to take the con.gurations \nto process by considering only the pc. Thus, at a given iteration, a con.guration is processed if its \nprogram counter is the same as that of a state newly discovered in the previous iteration. Usually the \nBDD con.guration for it is less complex of the one for SummaryEFopt, resulting in faster computa\u00adtion. \n                   In the following equations, we use a new bit fr; fr =1 is used to \nmark each pair of states (u, v) whichis addedto SummaryEFopt, and fr =0 to mark all such pairs that have \nbeen added in any of the previous iterations but the last one. According to this mark\u00ading, we can determine \nthe set of pairs (u, v) which have been added to SummaryEFopt for the .rst time in the last iteration \nthe tuple (1, u, v) must be in SummaryEFopt while the tuple (0, u, v) should not. This is used to compute \nthe relevant set of program counters Relevant which the next iteration works on. Formally, SummaryEFopt \nis de.ned as the least .xed-point of the relation SummaryEFopt(fr, u, v) in the system of equations below: \nSummaryEFopt(fr, u, v)= (fr=1 . Entry(u.pc) . u=v . Init(u.pc)) [1] . SummaryEFopt(1, u, v) [2] . (fr=1 \n. (New1(u, v) . New2(u, v)) ) [3] Relevant(pc)= .u, v.(SummaryEFopt(1, u, v) .\u00acSummaryEFopt(0, u, v) \n. v.pc = pc) [4] New1(u, v)= (SummaryEFopt(1, u, v) . Relevant(v.pc)) [5] . (.x.(New1(u, x) . ProgramInt(x, \nv))) [6] New2(u, v)= (.x.(Relevant(x.pc) . SummaryEFopt(1, u, x) . IntoCall(x, v))) [7] . (.x, y, z.(SummaryEFopt(u, \nx) [8] . IntoCall(x, y) . SummaryEFopt(y, z) [9] . Exit(z.pc) . Return(x, z, v) [10] . (Relevant(x.pc) \n. Relevant(z.pc)))) [11] All the above equations are interpreted as least-.xed-point equations, with \nthe main computation being that of SummaryEFopt (note that this is important as some of the equations, \nsuch as Relevant employs negation see Section 3 for the precise algo\u00adrithmic semantics of evaluation). \nBy clause 1, the initial states are added to the current set in each iteration. Note that they will contribute \nto determining the set of relevant program counters only once (when they are .rst inserted). By clause \n2, for each tuple (1, u, v), the tuple (0, u, v) is added to SummaryEFopt, i.e., all the pairs (u, v) \nalready discov\u00adered so far are marked as not newly discovered. Clause 3 adds to SummaryEFopt the tuples \nbelonging to either one of the sets New1 and New2, and mark them with fr =1. Equation 4 computes the \nset Relevant of all program counters pc such that there are pairs of states (u, v) in SummaryEFopt which \nare marked with fr=1 but not fr=0,and pc is the program counter of the newly discovered states v. In \nthe equation de.ning New1, clause 5 adds to New1 each pair (u, v) which has been already discovered and \nsuch that v.pc is in the set Relevant, and clause 6 allows us to discover new states by taking internal \ntransitions. The least .xed-point of New1 com\u00adputes the set of all pairs (u, v) such that v can be reached \nwithin any number of internal transitions from a state w such that w.pc is in Relevant and (1, u, w) \nis in SummaryEFopt. The above equation for New2 de.nes New2 as the set of all pairs (u, v) such that \nv is either reachable by a call from a reachable relevant state (clause 7) or by a transition across \na call to a module (clauses 8 11). Notice that for the correctness of the algorithm in this second case \nit is crucial to require just that for either one among the caller state and the exit state involved \nin the transition to be in the relevant set, and not both (clause 11). In fact, such caller and exit \nstates could be discovered in different times and thus it might be the case that they never happen to \nbe in the relevant set at the same time. The following that captures the correctness of the above .xed\u00adpoint \nalgorithm: THEOREM 3. Let P be a program. Consider the least .xed\u00adpoint of the equation for SummaryEFopt \ngiven above. Then SummaryEFopt(1, u, v) holds if and only if u is an entry of a proce\u00addure that is reachable \nin P and v is a state in the same procedure reachable from the entry u using a run that returns from \nall calls. In particular, SummaryEFopt(1, u, v) holds when u is an entry of main iff v is a state of \nmain that is reachable in P . The above algorithm is similar to frontier-set simpli.cation or incrementalization \ntechniques often implemented in solvers. How\u00adever, we emphasize that they are not the same. In frontier-set \nsim\u00adpli.cation, the precise set of states discovered in the previous round are used to compute the image. \nHowever, in many situations, the BDD for the frontier-set can be much larger than the BDD for all reachable \nstates. In our algorithm, we wish to take the set of all reachable nodes whose pc-value was part of some \nstate on the frontier-set. This is a restriction of the reachable set to a particu\u00adlar set of program-counter \nvalues, and hence does not blow up in practice.  5. Bounded-context reachability in concurrent programs \nA concurrent Boolean program is a set of boolean recursive pro\u00adgrams running in parallel and sharing \nsome (global) variables. For\u00admally, the syntax of concurrent boolean programs is de.ned by ex\u00adtending \nthe syntax of boolean recursive programs (Section 2) with the following rules: (conc-pgm) ::= (gvar-decl)(pgm-list) \n(pgm-list) ::= (pgm)(pgm-list)|(pgm) Let P be a concurrent program formed by the sequential pro\u00adgrams \nP1,...,Pn (where n> 0). Each program Pi has its own global and local variables, and can access also to \nother variables which are shared with the other component programs. We denote with S the set of the shared \nvariables and with VS the set of their valuations. We give the semantics of P using interleaved the behaviors \nof P1,...,Pn. At any point of a computation, only one of the programs is active. Therefore, a con.guration \nof P is denoted by a tuple (i, uS ,u1,...,un) where Pi is the currently active program, uS . VS and uj \nis a con.guration of Pj (valuation of global and local variables and stack) for j =1,...,n.From the con.guration \n(i, uS ,u1,...,un) the computation of P can evolve either according to the local behavior of Pi or by \nswitching to another program Pj , which then becomes the new active program. The consecutive portion \nof a run that executing only program Pi is called a context. Given a program counter pc (of any component \nprogram), the reachability problem for concurrent programs asks whether a state containing pc can be \nreached in a computation of P. It is well\u00adknown that the reachability problem for concurrent recursive \npro\u00adgrams is undecidable. For model-checking such programs sev\u00aderal authors have considered a simpler \nreachability problem, the bounded context-switch reachability. Given a program counter pc andaninteger \nk,the k-bounded context-switch reachability prob\u00adlem asks whether a state containing pc can be reached \nin a compu\u00adtation where the active program has changed at most k times (i.e.,  at most k context-switches \nhappened). In the following, we refer to a component program of a concurrent program also as a thread. \n5.1 An algorithm for bounded context-switching reachability in concurrent programs Our .xed-point algorithm \nfor computing the set of states reachable by a concurrent Boolean program in k context-switches is a \nbit involved we will give here the main intuition of the construction of the .xed-point equations, and \nskip formal proofs of correctness. Fix a bound k on the number of context-switches and .x n the number \nof threads in the program. Our .xed-point formula is parameterized over k and n. Assume, for simplicity, \nthat each thread of the concurrent program is over the same set of local and global variables, and further, \nthat all global variables are shared by the threads. Let L denote the local variables and G the global \n(and shared) variables. We compute a predicate Reach(u, v, ecs, cs, {gi}ki=1, {ti}ki=0), where both u \nand v represent valuations of L . G, cs and ecs are variables ranging over {0, 1,...,k}, each gi is a \nvaluation of the global shared variables G, and each ti is a variable over {1,...,n}. Intuitively, the \npair (u, v) captures a summary relation of one particular thread, where u represents the point of entry \ninto the current procedure of the thread and v represents the current state of the thread. The variable \ncs denotes the current context\u00adswitch number (i.e. the number of context-switches that have taken place) \nwhile ecs represents the number of context-switches that had happened at the point of entry into the \ncurrent procedure (and hence ecs = cs). The variable ti (i =0,... cs) represents the thread that is active \nat the i th context. The variable gi represents the valuation of the shared global variables at the point \nat which the i th context\u00adswitch happened. More formally, Reach(u, v, ecs, cs, {gi}ki=1, {ti}ik =0) holds \niff there is a global execution . that switches contexts cs times, the i th context-switch happening \nat global valuation gi (for each i . {1, ...,cs}), and reaches a global state where thread T = tcs is \nin the state v, and furthermore, the valuation of the global variables at the entry to the procedure \nin thread T was u.Global, and the num\u00adber of context-switches done before the last entry to the procedure \nwas ecs. This is the precise semantics of Reach, and is essential to understand the .xed-point formulation \nthat we provide below. No\u00adtice that the values of gj and tj,where j>cs, are not relevant at all, and \ndo not contribute to the semantics of Reach. Note that a program counter pc is reachable by the concurrent \nprogram within k context-switches iff Reach(u, v, cs, {gi}ki=1, {ti}ki=0) holds for some tuple with v.pc \n= pc. Hence computation of Reach suf.ces to solve the reachability problem. One property of our formulation \nof the .xed-point greatly simpli.es understanding it and hence is worth noting. When inferring that Reach(u, \nv, ecs, cs, {gi}ki=1, {ti}ki=0) holds, we will use the fact that other tuples of the form '''''' Reach(u,v, \necs, cs, {gi}ki=1, {ti}ki=0) hold. However, these '' tuples will always be such that gi = gi and ti = \nti.In other words, when we infer tuples in Reach using other tuples, we will ensure that the gi and ti \ntuples are precisely the same, for all values of i. Furthermore, cs' = cs also will always hold. We are \nnow ready to de.ne the .xed-point. In the following, let g denote {gi}ki=1 and let t denote {ti}ki=0. \n Reach(u, v, ecs, cs, g, t)= .init . .int . .call . .ret . .1st-switch . .switch where the sub-formulae \nare de.ned as follows: [Initial tuples:] .init =(cs= ecs=0 . Entry(u.pc) . u=v . Init(t0, u.pc)) This \nis similar to the initial clause we had for sequential summaries, except that we set the number of context-switches \nthat have hap\u00adpened to 0 and make sure u.pc is the initial program-counter for thread t0, the thread \nactive in the .rst context. [Internal transitions:] ( ) .int = .x. Reach(u, x, ecs, cs, g, t) . ProgramInt(x, \nv) [Call transitions:] '' .call = .x, y, ecs.( Reach(x, y, ecs, cs, g, t) . IntoCall(y, u) . ecs = \ncs . u = v ) [Return transitions:] ' ' .ret = .x, y, z, cs.( Reach(u, x, ecs, cs, g, t). IntoCall(x, \ny) ' ' .Reach(y, z, cs, cs, g, t).Exit(z.pc).Return(x, z, v). cs=cs) The above three clauses explore \nstates reached using internal transitions, call transitions, and return transitions of the current thread, \nand are very similar to the corresponding clauses we had for sequential summaries. Note that taking these \ntransitions preserves the value of cs. However, there are some subtleties to note regarding the formula \nfor return transitions. The state of the caller of the current module, x, could have been reached using \na different number of context\u00adswitches cs'; but we must then insist that cs' is not larger than cs. The \nsoundness argument for this last rule is subtle. Since ' ' Reach(u, x, ecs, cs, g, t), there is a run \n. that reaches x using cs ' context-switches. From the fact that Reach(y, z, cs, cs, g, t) holds, it \nfollows that there is a run .' that reaches z using cs context\u00adswitches. The crucial argument is that \nwe can construct from . and .' a run that reaches v using cs context-switches. This run .'' is obtained \nas follows: from ., we take the portions of the run in the current thread that reaches the caller x in \ncs' context-switches, and stitch it with the local run of the current thread in .' within the cur\u00adrent \nprocedure from entry y to exit z, and then proceed to v.More\u00adover, the runs in the other threads are \nobtained by using appropriate portions in the run .'. The fact that this results in a valid global run \n.'' depends crucially on the fact that the two Reach-tuples are over the same vectors g and t. In particular, \nthe local run which we pull out from . assumes context-switches to other threads that result in changes \nto global variables, and cannot be invalidated when we substitute the runs in other threads using different \nruns (from .') that result in the same changes to global variables.  [Context-switching to a thread \nfor the .rst time:] '''' .1st-switch = .x, y, cs, ecs. ( Reach(x, y, ecs, cs, g, t). ' (cs = cs+1) \n. First(tcs , cs,t) . (v.Global = gcs = y.Global). (u = v) . (ecs = cs) . Init(tcs , v.pc)) In the above, \nFirst(t, s, t) is a predicate that is true iff ts = t and there is no r<s such that tr = t.In other words, \nFirst(tcs , cs,t) checks whether cs is the .rst context the thread we are switching to (tcs ) is active \nin. This clause deals with the .rst time we switch to a thread, andallows atupletobeadded to Reach provided \nthere was some state reachable in a different thread with the same global variables and one less context-switch; \nwe record the globals in gcs (i.e., the component of g at index cs).  [Context-switching back to a thread:] \n.switch =  '' '' (.x, y, cs , ecs . (Reach(x, y, ecs , cs , g, t ) .(cs = cs ' +1) . \u00acFirst(tcs , cs,t) \n. (v.Global = gcs = y.Global))) . '' '' (.v ' , cs .(Reach(u, v ' , ecs, cs , g, t ) . (cs '' <cs) . \nConsecutive(cs '' , cs,t ) . v.Local = v ' .Local )) This case handles the scenario when we switch to \na thread we had executed previously at some point. The .rst conjunct above checks whether a state is \nreachable in another thread, and imbibes the global valuation from there (similar to the previous case). \nThe second conjunct is more involved as it retrieves the local valuation of the thread we are context-switching \nto. The predicate Consecutive(r, s, t) checks whether ts = tr and further that there is no r<i<s such \nthat ts = ti. Hence Consecutive(cs '' ,cs, t ) checks whether cs '' was the last context the thread we \nare switching to was last active in. We recover the local state of the thread by checking for a compatible \ntuple in Reach with cs '' context-switches. The soundness of this rule also involves stitching runs. \nGiven two runs that witness the two tuples in Reach in the above clause, we can stitch them into a single \nrun that witnesses the new tuple we are adding to Reach. The crucial condition that helps in showing \nthis is again that the runs in other threads can be freely substituted using runs that effect the same \nchange in global variables. We can now check whether pc is reachable using the following predicate: \nReachable(pc)= .u, v, ecs, cs, g, t. ( Reach(u, v, ecs, cs, g, t) .v.pc = pc ) The following theorem \nstates the correctness of the above .xed\u00adpoint formulation: THEOREM 4. Fix an integer k> 0.Let P be a \nconcurrent Boolean program with n threads, and let Goal be a program counter of P. Let Reach and Reachable \nbe the predicates as de.ned above. Then a state with program counter Goal is reachable in P within k \ncontext-switches iff Reachable(Goal) holds. One of the salient features of the above formulation is the \neconomic use of copies of global variables. A natural formulation would keep track of the g and t vectors \nat the entry to a called procedure; however, since these vectors never really change, we can do away \nwith keeping these vectors at the entry to a procedure. In other words, summaries do not involve two \ncopies of the k-tuple of global variables. Hence the number of global variables we use in the .xed-point \nformulation in k \u00b7|G| +2|G| only (we can in fact reduce this even to k \u00b7|G| + |G| by getting rid of the \nv.Global variables, and instead use gcs ). Previous formulations of capturing the reachable states using \n.xed points required more copies of global variables [12]. A nice feature of the formulation presented \nin [12] is that the authors show how to handle k round-robin schedules (not context\u00adswitches) using O(k) \ncopies of global variables only. We have ex\u00adtended our formulation above to rounds as well, and can capture \na k round-robin schedule using 2k copies of global variables. However, this is considerably more complex, \nand is out of the scope of this paper. We do emphasize that this formulation too can be captured using \nour .xed-point calculus.  6. Implementation and experiments In this section, we describe the implementation \nof the ideas pre\u00adsented in this paper in a new tool GETAFIX ( get-a-.x using .xed\u00adpoints ), and is available \nat the website below: http://www.cs.uiuc.edu/~madhu/getafix . 6.1 GETAFIX on sequential recursive programs \nGETAFIX is a BDD-based symbolic veri.er for Boolean programs which answers reachability queries. The \ntool takes as an input a Boolean program and a statement label, and gives as an output a YES/NO answer \nto the question is the statement at the input label reachable in the input program? . The answer can \nbe computed using one of the algorithms presented in the previous sections, which have all been implemented \nin the tool. The model-checking engine of the tool is the mu-calculus symbolic model checker MUCKE [7]: \nthe input program and the reachability algorithm are all translated into a mu-calculus formula which \nis fed to MUCKE for evaluation. The high level architecture of the tool is shown in Figure 1. GETAFIX \ntakes the input Boolean program and a target program la\u00adbel, and generates Boolean formulae (without \n.xed-points) that de\u00adscribe the various predicates in the Boolean program. These are the template formulae \ndescribed in Section 4, and includes predicates that capture the internal transition relation, the transition \nrelation on calls, etc. These templates are succinctly described as Boolean formulae. GETAFIX also computes \na fairly simple BDD-ordering suggestion to MUCKE, encoding it as allocation constraints. This BDD ordering \nis based on a simple algorithm which looks at the assignments in the program, and tries to allocate the \nvariables in\u00advolved in the assignment together. This algorithm is essentially the same algorithm followed \nby both MOPED VERSION 1and BEBOP (the Boolean program checker used in SLAM). The formulae resulting from \nthe translation step has a .rst part that concerns the encoding of the input program and a second part \nthat concerns the encoding of the chosen reachability algorithm. The two parts have a clear interface \nrepresented by the formulae ProgramInt, IntoCall, Entry, Exit, Init, Across and Return that have been \ndescribed in Section 4. Therefore, each of the parts can be implemented independently of the other as \nlong as the program translation will de.ne those formulae and the algorithm will use only those abstractions \nof the program. The table in Figure 2 summarizes our experimental results. For each analyzed program, \nwe report the number of non-blank lines of code (LOC), the maximal number of return values and input \nparameters in any procedure in the program, the number of global variables, the total number of local \nvariables, the maximal number of local variables in any procedure, and the number of procedures in the \nprogram. For the GETAFIX tool, we report the .nal BDD size of the summary set, and the time taken to \ncompute the answer, in seconds, for both the entry-forward algorithm and the optimized entry-forward \nalgorithm. Note that the .nal BDD size is the same for both algorithms. We also report the time MOPED \nVERSION 1, MOPED VERSION 2and BEBOP took to answer the same queries on the same machine. As regards to \nBEBOP, on each suite we have tried different options which enable/disable counter-example generation \nand switch on/off optimizations; we report in the table the best time (minimumtime) takenby BEBOP foreach \nexperiment. The programs were all in compatible syntax so that they could be input to any of the tools. \nFor aggregated suites, the time and space reported are the average of the times and spaces for the suite. \nWe took care not to combine examples with very different complexities into a sub-suite. The .rst suite \nis the set of Regression examples; the positive ones are those where the target label is reachable, and \nthe negative ones are where it is unreachable. The Regression suite consists of 177 small programs meant \nto test SLAM on correctness of abstraction of language features. The next suite is a set of drivers from \nSLAM benchmarks, which we obtained from Stefan Schwoon. Each sub-suite contains several Boolean programs. \nFor all these suites, we report average statistics.  GETAFIX  Figure 1. Architecture of the GETAFIX \ntool #LOC #ret REGRESSION Positive 368 1.8 (99 programs) Negative 224 1.9 (79 programs) SLAM Driver iscsiprt \n10K 10 (positive) (15 programs) Driver .oppy 17K 15 (positive) (12 programs) Driver (negative) 10K 11 \n(4 programs) iscsi (positive) 12K 18 (16 programs) TERMINATOR Terminator-A (iterative) 284 18 (schoose) \n284 18 Terminator-B (iterative) 471 9 (schoose) 471 9 Terminator-C (iterative) 908 1 (schoose) 908 1 \n#param. 2.3 2.5 9 12 8.25 18 12 12 7 7 0 0 #globals (g) 0.81 2 3.5 5.3 10.7 17.1 9 9 14 14 23 23 #locals \n4.8 8.2 211 172.5 154.2 358.8 97 97 77 77 19 19 max locals per proc. (l) 3.2 3.6 11.8 16 12 18 68 68 \n42 42 19 19 #proc\u00adedures 6.9 6.5 148 103 116.2 158 4 4 4 4 4 4 Reach? Yes No Yes Yes No Yes Yes Yes \n No No No No GETAFIX #Nodes in BDD 240 625 8K 9K 17K 81K 141K 162K 997K 660K 48K 48K Time (s) EF 1 \n1 2 2 2 5 4 3 72 32 2 2 EF opt 1 1 2 2 2 5 3 3 12 9 3 3 MOPED 1 MOPED 2 BEBOP Time (s) Time (s) Time \n(s) 11 11 11 11 11 24 -14 14 1 3 24 490 1 1 711 1 1 709 Figure 2. Experimental results:  denotes time-out \nin 30 minutes Finally, the last suite contains three programs generated by the TERMINATOR tool [10] and \nprovided to us by Byron Cook. First, note that the entry-forward optimized algorithm outper\u00adforms the \nentry-forward algorithm, essentially, overall. In SLAM driver suites, notice that GETAFIX takes a little \nlonger thanMOPED,andexceptforthe ISCSIsuite,alsothan BEBOP.This is primarily due to an overhead in using \nMUCKE MUCKE .rst computes allocations of BDD-variables using an algorithm which actually takes a few \nseconds. These examples are extremely large in code-length (not particularly complex in the set of reachable \nstates). Pro.ling the tool, we found that the actual image computation time is less than a second on \nthese examples in GETAFIX. Let us turntothe TERMINATOR benchmarks, which are actually quite complex and \nwith large BDDs representing reachable states. The benchmarks we obtained had a dead statement that currently \nthe tools MOPED and GETAFIX do not support. A declaration of a set of variables as dead essentially means \nthat the variables will no longer be used in the computation of a module. We modeled the dead statement \nin two ways one way was to iteratively assign the variable to a nondeterministic value using conditional \nif-then-else statements (marked iterative in the table), and the other was to replace them using an assignment \ncalled schoose which can assign non-deterministic values (marked schoose in the table). Notice that Moped \ndoes not terminate on two of the three examples, in the iterative version. We cannot believe that it \nis actually experiencing dif.culty in solving the problem; we suspect this may just be an error in Moped. \nAlso, these examples are quite challenging for BEBOP.On TERMINATOR-B and TERMINATOR-C it takes several \nminutes and on the iterative version of TERMINATOR-B it did not terminate in 30 minutes. In all the TERMINATOR \nexamples GETAFIX terminates in less than 30 seconds. In summary, the experiments clearly show that GETAFIX \nis competitive against well-tuned mature tools. Note that this is de\u00adspite the fact that GETAFIX lacks \nseveral other low-level heuristic tricks built into other tools, such as static analysis to eliminate \ndead code, etc.  Two processes: one adder and one stopper (12 local variables and 8 global variables) \n1 No 0.6k 5.4 2 No 1.5k 5.5 3 No 5.5k 5.7 4 No 7.0k 5.8 5 No 13.3k 6.3 6 No 23.2k 7.3 Three processes: \none adder and two stoppers (18 local variables and 8 global variables) 1 No 0.7k 5.5 2 No 2.9k 5.5 3 \nYes 9.9k 5.7 4 Yes 34.6k 6.8 5 Yes 115.0k 9.2 6 Yes 370.5k 17.4 Three processes: two adders and one stopper \n(18 local variables and 8 global variables) 1 No 0.7k 5.4 2 No 2.6k 5.6 3 No 10.4k 6.0 4 Yes 41.1k 7.6 \n5 Yes 90.9k 9.1 6 Yes 250.1k 9.1 Four processes: two adders and two stoppers (24 local variables and \n8 global variables) 1 No 0.8k 5.5 2 No 3.6k 5.6 3 Yes 15.8k 5.9 4 Yes 67.8k 7.6 5 Yes 296.9k 13.0 6 Yes \n1227.4k 57.1 Figure 3. Experimental results on the Bluetooth driver example  6.2 GETAFIX on concurrent \nprograms The table in Figure 3 resumes the experiments we have run on our tool to test a Boolean model \nof Windows NT Bluetooth driver [17]. Brie.y, this driver has two types of threads, stoppers and adders.A \nstopper calls a stopping procedure to halt the driver, while an adder calls a procedure to perform I/O \nin the driver. We have considered four different con.gurations: an adder and a stopper, two adders and \na stopper, an adder and two stoppers, and two adders and two stoppers. For each of this con.gurations \nwe report the results allowing up to six context switches. Except for the con.guration with only two \nprograms, GETAFIX discovered a bug using at least three context switches when using two stoppers and \nat least four context switches when using only one stopper. The execution times shown in Figure 3 are \ncompetitive with those obtained by other tools on which this driver was tested [22, 12].  7. Conclusions \nWe have implemented in the tool GETAFIX two classes of algo\u00adrithms that solve respectively reachability \nin Boolean programs and bounded context-switch reachability in concurrent Boolean pro\u00adgrams, using formulae \nin a .xed-point calculus. The experimental results presented in this paper, and the ease of building \nalgorithms using the .xed-point calculus, encourage us also to extend our tool to solve static-analysis \nproblems in program analysis. GETAFIX uses MUCKE a symbolic .xed-point solver to evalu\u00adate formulae. \nWhile we have used only alternation-free .xed-point calculus formulae in this work (as we were interested \nin reachabil\u00adity), our formalism can easily be extended to arbitrary mu-calculus speci.cations. In fact, \nit is well-known that any mu-calculus spec\u00adi.cation on pushdown systems can be reduced to a mu-calculus \nformula on a .nite-state system (modeling a parity game solution on the pushdown graph) [23]. Moreover, \nMUCKE accepts speci.\u00adcations expressed as a formula of the mu-calculus. Currently, GETAFIX does not support \nreporting of counter\u00adexamples. Mucke does support counterexamples; we plan to adapt it to report readable \ncounter-examples for reachability to the user.  Acknowledgments We thank Armin Biere for his technical \nsupport on the tool MUCKE, Stefan Schwoon for his technical support on the MOPED tools and for providing \nus SLAM benchmarks, Byron Cook for pro\u00adviding us with TERMINATOR benchmarks, and Ella Bounimova and Tom \nBall for their technical support on the tool BEBOP.  References [1] R. Alur, M. Benedikt, K. Etessami, \nP. Godefroid, T. W. Reps, and M. Yannakakis. Analysis of recursive state machines. ACM Trans. Program. \nLang. Syst., 27(4):786 818, 2005. [2] R. Alur, M. McDougall, and Z. Yang. Exploiting behavioral hierarchy \nfor ef.cient model checking. In Proc., CAV, volume 2404 of LNCS, pages 338 342. Springer, 2002. [3] T. \nBall, B. Cook, V. Levin, and S. K. Rajamani. SLAM and Static Driver Veri.er: Technology transfer of formal \nmethods inside Microsoft. In Proc, IFM, volume 2999 of LNCS, pages 1 20. Springer, 2004. [4] T. Ball \nand S. K. Rajamani. Bebop: A symbolic model checker for Boolean programs. In Proc., SPIN, volume 1885 \nof LNCS, pages 113 130. Springer, 2000. [5] T. Ball and S. K. Rajamani. The SLAM project: debugging system \nsoftware via static analysis. In POPL, pages 1 3. ACM, 2002. [6] D. Beyer, T. A. Henzinger, R. Jhala, \nand R. Majumdar. The software model checker Blast. STTT, 9(5-6):505 525, 2007. [7] A. Biere. \u00b5cke -ef.cient \n\u00b5-calculus model checking. In CAV, volume 1254 of LNCS, pages 468 471. Springer, 1997. [8] J. R. B\u00a8uchi. \nRegular canonical systems. Arch. Math. Logik Grundlagenforschung, 6:91 111, 1964. [9] S. Chaudhuri. \nSubcubic algorithms for recursive state machines. In Proc., POPL, pages 159 169. ACM, 2008. [10] B. Cook, \nA. Podelski, and A. Rybalchenko. Terminator: Beyond safety. In Proc., CAV, volume 4144 of LNCS, pages \n415 418. Springer, 2006. [11] J. Esparza and S. Schwoon. A BDD-based model checker for recursive programs. \nIn Proc., CAV, volume 2102 of LNCS,pages 324 336. Springer, 2001. [12] A. Lal and T. W. Reps. Reducing \nconcurrent analysis under a context bound to sequential analysis. In A. Gupta and S. Malik, editors, \nCAV, volume 5123 of LNCS, pages 37 51. Springer, 2008. [13] M.S.Lam,J.Whaley, V.B. Livshits, M.C.Martin, \nD.Avots, M. Carbin, and C. Unkel. Context-sensitive program analysis as database queries. In Proc., PODS, \npages 1 12. ACM, 2005. [14] O. Lhot\u00b4ak and L. Hendren. Jedd: a bdd-based relational extension of java. \nIn Proc., ACM SIGPLAN PLDI, pages 158 169, USA, 2004. ACM. [15] M. Musuvathi and S. Qadeer. Iterative \ncontext bounding for systematic testing of multithreaded programs. In Proc., ACM SIGPLAN PLDI, pages \n446 455. ACM, 2007.  [16] S. Qadeer and J. Rehof. Context-bounded model checking of concurrent software. \nIn N. Halbwachs and L. D. Zuck, editors, TACAS, volume 3440 of LNCS, pages 93 107. Springer, 2005. [17] \nS. Qadeer and D. Wu. Kiss: keep it simple and sequential. In Proc. ACM SIGPLAN PLDI, USA, pages 14 24, \nACM, 2004. [18] T. W. Reps, S. Horwitz, and S. Sagiv. Precise interprocedural data.ow analysis via graph \nreachability. In POPL, pages 49 61, ACM, 1995. [19] T. W. Reps, S. Schwoon, and S. Jha. Weighted pushdown \nsystems and their application to interprocedural data.ow analysis. In Proc., SAS, volume 2694 of LNCS, \npages 189 213. Springer, 2003. [20] S. Schwoon. Model-Checking Pushdown Systems. PhD thesis, Technische \nUniversit\u00a8at M\u00a8unchen, 2002. [21] M. Sharir and A. Pnueli. Two approaches to inter-procedural data\u00ad.ow \nanalysis. In Program Flow Analysis: Theory and Applications, 1981. [22] D. Suwimonteerabuth, J. Esparza, \nand S. Schwoon. Symbolic context\u00adbounded analysis of multithreaded Java programs. In Proc. SPIN, volume \n5156 of LNCS, pages 270 287. Springer, 2008. [23] I. Walukiewicz. Pushdown processes: Games and model-checking. \nInf. Comput., 164(2):234 263, 2001. [24] J. Whaley and M. S. Lam. Cloning-based context-sensitive pointer \nalias analysis using binary decision diagrams. In Proc. ACM SIGPLAN PLDI, USA, pages 131 144, ACM, 2004. \n Appendix: Precise .xed-point formula for the entry-forward algorithm We now describe the implementation \nof the relation SummaryEF from Section 4.2, and is hence the precise algorithm implemented in that section. \nNotice the brevity of the code (~40 LOC without comments). In the following code, we use a structure \nConf de.ned as a tuple (mod, pc, CL, CG, ENTRY CL, ENTRY CG) where: mod is a module name, pc is a program \ncounter of module mod, CL and ENTRY CL are vectors of local variables, CG and ENTRY CG are vectors of \nglobal variables. Note that (mod, pc) uniquely determine a program counter in a program. We assume that \npc of an entry state is 0 in any module. The intended meaning of a given Conf s is as follows. Tuple \n((s.mod,s.pc),s.CL,s.CG) denotes the current state of the program (in the following, we refer to it as \ns-current), and ((s.mod, 0),s.CL,s.CG) is the state visited when the current module was entered for the \nlast time on a computation leading to the current state (in the following, we refer to it as s-entry). \nThe following formula Reachable de.nes the relation SummaryEF from Section 4.2. In fact, it is possible \nto show that Reachable(s) holds true if and only if SummaryEF(u, v) holds true where u is the state s-current \nand v is the state s-entry. mu bool Reachable (Conf s) ( /* early termination */ ( exists Conf t. ( target(t.mod,t.pc) \n&#38; Reachable(t) )) /* add initial configurations */ | Init(s) /* forward propagation on internal \ntransitions: s-current is reachable via a transition internal to s-module from t-current, for a reachable \nt */ | (exists Conf t. ( Reachable(t) &#38; t.mod=s.mod /* module does not change */ &#38; t.ENTRY_CG=s.ENTRY_CG \n&#38; t.ENTRY_CL=s.ENTRY_CL /* entry state does not change */ &#38; programInt(s.mod,t.pc,s.pc,t.CL,s.CL,t.CG,s.CG) \n /* internal transition from t-current to s-current */ )) /* forward propagation on calling a module: \n  there is a reachable t such that t-current is a call and s-current is a corresponding entry */ | \n(s.pc=0 &#38; s.ENTRY_CG=s.CG /*s-current is an entry*/ &#38; CopyLocals(s.mod,s.ENTRY_CL,s.CL) /* s.ENTRY_CL=s.CL \non local variables in s.mod */ &#38; (exists Conf t. (Reachable(t) &#38; t.CG=s.CG /* s-current and t-current \nmatch on global vars*/ &#38; programCall(t.mod,s.mod,t.pc,t.CL,s.CL,s.CG) /* t-current is a call to s.mod \nand parameters are passed from t-current to s-current */ ))) /* forward propagation from call to matching \nreturn: s-current is a return, (1) there is a reachable t such that (1.1) s-entry and t-entry match (1.2) \nt-current is a call matching s-current (1.3) s-current and t-current match on local variables not assigned \nwith return values (1.4) t-current is a call corresponding to u-entry (1.5) call parameters are computed \nfrom t-current and assigned to local variables of u-entry and (2) there is a reachable u=(u_mod,u_pc,u_CL,u_CG,u_ECL,u_ECG) \ns. t. (2.1) u-entry is an entry corresponding to t-current (u_ECG = t.CG) (2.2) u-current is an exit \n(2.3) u-current corresponds to return s-current (2.4) s-current and u-current match on global variables \nnot assigned with return values (2.5) remaining global variables and assigned local variables of s-current \nare assigned with return values computed from u-current */ | (exists PrCount t_pc, Global t_CG, Module \nu_mod, PrCount u_pc, Local u_ECL. /* clause (1) */ (exists Conf t. (Reachable(t) &#38; (t.pc=t_pc &#38; \nt.CG=t_CG) /* extract t components needed in clause 2 */ &#38; (t.mod=s.mod &#38; t.ENTRY_CL=s.ENTRY_CL \n&#38; t.ENTRY_CG=s.ENTRY_CG) /*clause 1.1*/ &#38; SkipCall(s.mod,t.pc,s.pc) /*clause 1.2*/ &#38; SetReturn1(s.mod,u_mod,t.pc,u_pc,t.CL,s.CL) \n/* clause 1.3 */ &#38; programCall(t.mod,u_mod,t.pc,t.CL,u_ECL,t.CG) /* clauses 1.4 and 1.5 */ )) &#38; \n/* clause 2 */ (exists Conf u.( (u.mod=u_mod &#38; u.pc=u_pc &#38; u.ENTRY_CL=u_ECL &#38; u.ENTRY_CG=t_CG) \n/* u conforms to extracted values &#38; clause 2.1*/ &#38; Reachable(u) /* u is reachable */ &#38; Exit(u_mod,u_pc) \n/* clause 2.2 */ &#38; SetReturn2(s_mod,u_mod,t_pc,u_pc, u_CL,s_CL,u_CG,s_CG) /* clauses 2.3, 2.4 and \n2.5 */ ))) ); /* Reachability query: is a target state reachable?*/ (exists Conf s. (target(s.mod,s.pc) \n&#38; Reachable(s)));  \n\t\t\t", "proc_id": "1542476", "abstract": "<p>We show that recursive programs where variables range over finite domains can be effectively and efficiently analyzed by describing the analysis algorithm using a formula in a fixed-point calculus. In contrast with programming in traditional languages, a fixed-point calculus serves as a high-level programming language to easily, correctly, and succinctly describe model-checking algorithms While there have been declarative high-level formalisms that have been proposed earlier for analysis problems (e.g., Datalog the fixed-point calculus we propose has the salient feature that it also allows <i>algorithmic</i> aspects to be specified.</p> <p>We exhibit two classes of algorithms of symbolic (BDD-based) algorithms written using this framework-- one for checking for errors in sequential recursive Boolean programs, and the other to check for errors reachable within a bounded number of context-switches in a concurrent recursive Boolean program. Our formalization of these otherwise complex algorithms is extremely simple, and spans just a page of fixed-point formulae. Moreover, we implement these algorithms in a tool called <sc>Getafix</sc> which expresses algorithms as fixed-point formulae and evaluates them efficiently using a symbolic fixed-point solver called <sc>Mucke</sc>. The resulting model-checking tools are surprisingly efficient and are competitive in performance with mature existing tools that have been fine-tuned for these problems.</p>", "authors": [{"name": "Salvatore La Torre", "author_profile_id": "81100393789", "affiliation": "Universit&#224; degli Studi di Salerno, Salerno, Italy", "person_id": "P1464278", "email_address": "", "orcid_id": ""}, {"name": "Madhusudan Parthasarathy", "author_profile_id": "81435592640", "affiliation": "University of Illinois at Urbana-Champaign, Urbana, IL, USA", "person_id": "P1464279", "email_address": "", "orcid_id": ""}, {"name": "Gennaro Parlato", "author_profile_id": "81332520215", "affiliation": "University of Illinois at Urbana-Champaign, Urbana, IL, USA", "person_id": "P1464280", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542500", "year": "2009", "article_id": "1542500", "conference": "PLDI", "title": "Analyzing recursive programs using a fixed-point calculus", "url": "http://dl.acm.org/citation.cfm?id=1542500"}