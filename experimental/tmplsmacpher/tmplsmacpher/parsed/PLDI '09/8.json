{"article_publication_date": "06-15-2009", "fulltext": "\n Lightweight Annotations for Controlling Sharing in Concurrent Data Structures Zachary Anderson David \nGay Mayur Naik University of California, Berkeley Intel Research, Berkeley zra@cs.berkeley.edu {david.e.gay,mayur.naik}@intel.com \nAbstract SharC is a recently developed system for checking data-sharing in multithreaded programs. Programmers \nspecify sharing rules (read\u00adonly, protected by a lock, etc.) for individual objects, and the SharC compiler \nenforces these rules using static and dynamic checks. Violations of these rules indicate unintended data \nsharing, which is the underlying cause of harmful data-races. Additionally, SharC allows programmers \nto change the sharing rules for a speci.c object using a sharing cast, to capture the fact that sharing \nrules for an object often change during the object s lifetime. SharC was successfully applied to a number \nof multi-threaded C programs. However, many programs are not readily checkable using SharC because their \nsharing rules, and changes to sharing rules, e.ectively apply to whole data structures rather than to \nindividual objects. We have developed a system called Shoal to address this shortcoming. In addition \nto the sharing rules and sharing cast of SharC, our system includes a new concept that we call groups. \nA group is a collection of objects all having the same sharing mode. Each group has a distinguished member \ncalled the group leader. When the sharing mode of the group leader changes by way of a sharing cast, \nthe sharing mode of all members of the group also changes. This operation is made sound by maintaining \nthe invariant that at the point of a sharing cast, the only external pointer into the group is the pointer \nto the group leader. The addition of groups allows checking safe concurrency at the level of data structures \nrather than at the level of individual objects. We demonstrate the necessity and practicality of groups \nby applying Shoal to a wide range of concurrent C programs (the largest approaching a million lines of \ncode). In all benchmarks groups entail low annotation burden and no signi.cant additional performance \noverhead. Categories and Subject Descriptors CR-number [subcategory]: third-level; D.3.3 [Programming \nLanguages]: Language Con\u00adstructs and Features; F.3.1 [Logics and Meanings of Programs]: Specifying and \nVerifying and Reasoning about Programs General Terms Languages, Veri.cation Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. \nCopyright &#38;#169;c2009 ACM 978-1-60558-392-1/09/06. . . $5.00 1. Introduction The increasing prevalence \nof multicore processors requires lan\u00adguages and tools that support safe concurrent programming. C itself \nprovides no such support most concurrency errors in C programs happen silently, and do not become observable \nuntil the program fails catastrophically. In these cases, it is common for the bug to be di.cult to deduce \nfrom the way the program fails. A number of tools [33, 12] have been developed for modern languages like \nC# and Java to detect one type of concurrency error: the data-race. A data-race occurs when two threads \naccess the same location in memory without synchronization, and at least one of the accesses is a write. \nIn these systems an exception is raised immediately whenever a data-race occurs. The fail-fast approach \nused by these runtimes is in agreement with good systems design. However, in the same way that a program \ncrash is a symptom of some deeper problem, a data-race is a symptom of unintended data sharing. SharC \n[1] is a recently-developed system that attempts to iden\u00ad tify instances of unintended data sharing. \nUsing SharC, program\u00admers make type annotations that describe how data is intended to be shared (or not) \namong threads. These annotations are called shar\u00ading modes. Additionally, SharC provides a checked cast \noperation called a sharing cast that a programmer can use to identify places in a program where the sharing \nmode for an object changes. Us\u00ading a combination of static and dynamic analysis, SharC checks that no \ndata is shared among threads in the program except in ways that have been explicitly declared by the \nprogrammer. This stronger condition also precludes the existence of unintended data-races. Unfortunately, \nSharC has a fairly serious limitation that prevents it from being easily applied to some widely-used \nmultithreaded C programs: sharing casts apply to individual objects to which only a single reference \nremains. Therefore, changing the sharing mode of data structures, such as linked lists and trees, is \neither unsafe, im\u00adpossible, or prohibitively expensive in SharC. Complex data struc\u00adtures occur frequently \nin all C programs including multithreaded C programs. Some of the structures used have di.erent sharing \nmodes at di.erent points in time. For example, data structures are initial\u00adized before being shared with \nother threads, or become private to a thread after being removed from shared queues, lists, and hash \ntables. Applying SharC to such programs is thus di.cult or impos\u00adsible. We have extended SharC to address \nthis shortcoming. In addi\u00adtion to the existing sharing modes and sharing cast of SharC, we have developed \na new concept that we call groups by borrowing ideas from region, ownership, and dependent type systems. \nFor the purposes of this paper, we use the name Shoal to refer to SharC extended with groups, and SharC \nto refer to the original system. A group is a collection of objects all having the same sharing mode. \nEach group has a distinguished member called the group leader.  When the sharing mode of the group leader \nchanges by way of a sharing cast, the sharing mode of all members of the group also changes. We distinguish \nthese casts from SharC s single-object casts by calling them group casts. We ensure soundness of group \ncasts by requiring that all external pointers into a group have a type that depends on a pointer to the \ngroup leader, and using reference counting to prevent casts when more than one pointer to the group leader \nremains. Objects can be added or removed from groups, and group casts can be used to combine groups. \nWe present the syntax along with examples of group use in Section 2, and formalize and prove the soundness \nof our group type system in Section 3. Our for\u00ad malism for groups is not strongly tied to the concept \nof a sharing mode, and could be used to track other properties, such as tainting, immutability, etc. \nWe hope that groups and group casts represent a promising approach to describing the runtime evolution \nof such properties. We have used Shoal, to check data sharing in several interest\u00ading benchmarks, including \nthe GIMP image manipulation program which is over 900k lines. Our benchmarks include scienti.c codes \nusing graphs and trees to organize calculations; a simple webserver using an in-memory cache shared among \nthreads that process re\u00adquests from clients; and two image manipulation programs that use threads to \nimprove performance and hide latency. To support these benchmarks, Shoal includes a sharing mode that \nchecks a com\u00admon idiom in parallel scienti.c applications; barrier synchroniza\u00adtion is used to separate \nupdates in one thread from reads by other threads. We have observed that Shoal s annotation burden is \nman\u00adageable. For small (a few thousand line) programs we made about one change for every 50 lines, but \nfor the GIMP we only needed one for every 10 000 lines. Additionally, making the right annotations requires \nminimal program understanding the GIMP required one person only three days to annotate. The scienti.c \nbenchmarks had overheads around 40% (mostly due to concurrent reference count\u00ading), the overheads on \nthe other benchmarks were less than 20%, and overheads were not a.ected by the number of threads. We \ndis\u00adcuss our experimental results in full in Section 4. To summarize, this paper makes the following \ncontributions: We present groups and group casts, lightweight mechanisms for describing data structure \nproperties, and evolution of these properties. Groups borrows ideas from region, ownership and dependent \ntype systems to describe sets of objects with a com\u00admon property, represented by a distinguished leader. \n We describe how groups can be used to specify the sharing strategy used in concurrent programs that \nuse complex data structures.  We demonstrate the practicality of Shoal by using it to check data sharing \nin several applications which require groups, with both low performance overheads, and low annotation \nburden. We also discuss how these applications would have been di.\u00adcult and impractical to check without \ngroups.  2. Overview SharC [1] is a system in which programmers add annotations, called sharing modes, \nto types. These modes include private, for objects accessible only by a single thread, readonly for objects \nthat cannot be modi.ed, and locked(L) (a dependent type) for objects that must only be accessed when \nlock L is held. SharC uses a combination of static and dynamic checking to ensure that these rules are \nfollowed. Additionally, SharC allows the programmer to specify where the sharing mode for an object changes \nusing a sharing cast. SharC checks these casts using reference counting: if only one reference to an \nobject exists, then the sharing mode of 1 typedef struct list { 2 int data; 3 struct list *next; 4 } \nlist t; 5 mutex t *Lck; 6 list t *lckL; 7 void init() { 8 list t *pL = NULL, *end = NULL; 9 for (int \ni = 0; i < 10; i++) { 10 list t *t; 11 t = malloc(sizeof(list t)); 12 t->data = i; 13 t->next = NULL; \n14 if (pL == NULL) { pL = t; end = pL;} 15 else { end->next = t; end = t; } 16 } 17 mutex lock(Lck); \n18 lckL = pL; 19 mutex unlock(Lck); 20 } Figure 1. Code that de.nes a linked structure, and shows how \nit is initialized by one thread before being shared through a lock with other threads. the object can \nbe changed by atomically copying the pointer to a pointer with the new sharing mode, and nulling out \nthe old pointer. 2.1 SharC s Limitation With these capabilities SharC is able to describe the sharing \nstrat\u00adegy in a variety of legacy multithreaded C programs. Unfortunately, the restriction that the sharing \ncast may apply only to single objects prevents SharC from being easily applied to a number of common \ncode patterns. In this section, we will refer to a simple example in which a singly-linked list is initialized \nby one thread before being shared through a lock with other threads. The code for this example is given \nin Figure 1. This code snippet de.nes a type for list nodes, and gives a function that initializes a \nlist before sharing it with other threads through a global variable protected by a lock. The sharing \nstrategy for this code dictates that the list is private when being constructed, and then becomes lock-protected \nwhen it is shared with other threads on line 18. We would like to simply declare that lckL is a pointer \nto a locked() list t, and that its next .eld also points to locked() list t s, and that similarly pL \nis a pointer to a private list t with a next .eld pointing to private list t s. However, if we do that \nSharC will not let us do a sharing cast from pL to lckL at line 18 because that would be unsound as as \nthere might still be a private pointer into the tail of the list now pointed to by lckL. Alternately, \nwe might try to de.ne two di.erent list structures, each with the appropriate annotation given explicitly \non the next .eld, say plist t and lcklist t. Then, we could traverse the list, doing a sharing cast on \neach node while casting from one list node type to the other1. We might write something like the code \nin Figure 2. In this snippet scast is SharC s single object sharing cast. This approach has a few problems. \nFirst, we would have to compel SharC to accept the dubious cast between two di.erent aggregate types, \nwhich it currently does not. Second, code with a similar goal may become quite cumbersome to write for \nanything beyond the simplest data structures. Finally, for data structures consisting of many individual \nobjects, the above code would adversely a.ect run-time performance. Furthermore, condoning such an approach \n1 This tactic might require writing to readonly objects, if that is the in\u00adtended target mode, and so \nwill trivially violate SharC s type system, but suppose for a moment that this is not a problem.  lcklist \nt locked(Lck) *convert(plist t private *L) { plist t *pt1 = L, *pt2; lcklist t locked(Lck) *lckhp = NULL, \nlcklist t locked(Lck) **lcktp = &#38;lckhp; while (pt1) { pt2 = pt1->next; pt1->next = NULL; *lcktp = \nscast (lcklist t locked(Lck) *,pt1); lcktp = &#38;(*lcktp)->next; pt1 = pt2; } return lckhp; } Figure \n2. Code that uses SharC s single object cast to convert a private list to a locked() list. scast is SharC \ns single object sharing cast. would violate SharC s design goal of requiring the programmer to write \nonly simple type annotations and casts to specify a program s sharing strategy.  2.2 Shoal s Goals The \ngoal of Shoal is to allow changing the sharing mode, not only of individual objects, but also of complex \ndata structures in one atomic action. In order to ensure the soundness of these operations, we require \nthe programmer to add annotations that describe a group of objects that have the same sharing mode. A \ngroup is identi.ed by a distinguished object called the group leader. Internal and external pointers \nto the group have distinct types such that external pointers must identify the group leader. We combine \nstatic and runtime checks to maintain the invariant that no object is referred to by pointers with di.erent \nsharing modes at the same time. In brief, we ensure that all external pointers identify the same object \nas the group leader, and that group casts are only performed when there is a single external pointer \nto the group. The rest of this section explains the syntax for groups, and how our type system enforces \nthe above semantics. Orthogonally, to better support scienti.c applications, Shoal also adds a new sharing \nmode, barrier for objects protected by barrier synchronization: between any two barriers a chunk2 of \nthe object is either only read, or only accessed by a single thread. 2.3 Group Annotations and Casts \nGroups are speci.ed using two annotations. First, we provide a dependent type annotation, group(p), which \nindicates that objects of that type belong to the group with leader pointed to by p. Second, we provide \nan annotation for structure .eld pointer types, same, which indicates that the structure .eld points \ninto the same group as the containing structure. The group(p) annotation identi.es external pointers, \nwhile the same annotations identi.es internal pointers. We also provide an additional checked cast operation, \ngcast, which indicates that the sharing mode or group leader for a group of objects is changing. gcast \nensures that there is only one external reference to a group leader, and atomically copies the value \nof the pointer into the new pointer with the new type, and nulls out the old pointer so that no pointers \nwith the old type refer to the same data structure after the cast. Consider the code snippet in Figure \n3. This is our linked list example from above, but now it is fully annotated with Shoal s sharing modes, \nand casts. Bolded annotations must be provided by the programmer, while the unbolded annotations are \ninferred. First note the same annotation in the type of the next .eld on line 3. 2 We break objects into \n16-byte chunks, to allow concurrent non-racy up\u00addates to composite objects such as arrays. 1 typedef \nstruct list { 2 int data; 3 struct list same *next; 4 } list t; 5 mutex t *Lck 6 list t group(lckL) locked(Lck) \n* locked(Lck) lckL; 7 void init() { 8 list t group(pL) private * private pL = NULL; 9 list t group(pL) \nprivate * private end = NULL; 10 for (int i = 0; i < 10; i++) { 11 list t group(pL) private * private \nt = NULL; 12 t = malloc(sizeof(list t)); 13 t->data = i; 14 t->next = NULL; 15 if (pL == NULL) {pL = \nt; end = pL} 16 else {end->next = t; end = t;} 17 } 18 mutex lock(Lck); 19 lckL = gcast (list t group(lckL) \nlocked(Lck) *, pL); 20 mutex unlock(Lck); 21 } Figure 3. Code that de.nes a linked structure, and shows \nhow it is initialized by one thread before being shared through a lock with other threads. Bolded annotations \nare provided by the programmer. Unbolded annotations are inferred. This indicates that next is an internal \npointer in the same group as the enclosing structure. Next, note that lckL is a locked() pointer into \na locked() list. The group(lckL) annotation indicates that lckL is an external pointer into the group \nidenti.ed by the target of lckL. That is, lckL is a pointer to the group leader. Inside of the init() \nfunction, pL and t are private pointers to private lists. They are both external pointers into the group \nidenti.ed by the target of pL. In the for loop, nodes are added to the list. After the list is built, \non line 19, the mode for the entire list is changed from private to locked(). This is safe because pL \nis the only external reference to the list, and because no other live, non\u00adnull variable refers to pL \nin its type. These checks are su.cient to ensure that there are no pointers with the wrong type. If our \nlist building code had, e.g., stored an external reference into the middle of the list, then its type \nwould have to refer to the group leader. If the type referred to a reference aside from pL, then the \nreference count on the group leader would be too high. If its type referred to pL, then the null check \non pointers that refer to pL would fail.  2.4 The Group Leader As mentioned, when a cast of a group \nis attempted, we must be able to verify that there is only one external pointer into the group. Further, \nfor soundness reasons when a pointer mentioned in a dependent type is assigned to, pointers of types \nthat depend on it must be null. To enforce the .rst requirement, we restrict what expressions may appear \nas parameters to a group() annotation. In the annota\u00adtion group(p), p is a pointer expression built from \nvariables and .eld names: the types of structure .elds may refer to other .elds of the same structure, \nand the types of locals may refer to other locals (including formal parameters) in the same function. \nGlobals may be mentioned in the group() parameter, but only when they are declared static readonly. Finally, \npointers mentioned in the group() parameter may not have their addresses taken. These re\u00adstrictions permit \nus to reason locally about what values types de\u00adpend on. That is, we require no alias analysis to discover \nwhat the dependencies of a type are. These are the same restrictions as those used in the Deputy [9] \ndependent type system for C. The second requirement exists to ensure that the group of an object cannot \nchange without a group cast. That is, changing the group of an object by simply changing the value of \nthe pointer in its group() annotation is forbidden. To enforce this, we simply insert dynamic checks \nfor null-ness ahead of assignments to group leader pointers on which other live pointers depend. Note \nthat in our linked list example in Figure 3, on line 15 t is dead after the assignment, so no null-check \nis required for t. However, pL is live after the assignment, and so we must check that it is null beforehand. \nIn short, pointers whose type depends on pL must be null before an assignment to pL or dead afterwards. \nThese restrictions may seem cumbersome, however they have not caused any substantial di.culties in porting \nour benchmarks.  In a fully typed program, every pointer type has either a group() annotation or a same \nannotation. However, the group() parameter may be null. When this is the case, the object cannot be the \nsubject of a group cast as it clearly cannot be the group leader, however it can be extracted from the \nnull group using the single\u00adobject sharing cast as described in Section 3. In our system we use the shorthand \nnogroup for group(NULL). In our linked list exam\u00adple, the nogroup annotations would go on types that \ndo not have a group() or same annotation, but these have been omitted for read\u00adability. In our implementation \nnogroup is the default annotation. This is so that the programmer is required to make annotations only \nfor instances of data structures where the group cast is needed.  2.5 Operations on Groups Objects can \nbe added to and removed from groups, while group casts can be used to change a group s sharing mode and/or \nmerge two groups. Consider the linked list structure above. Adding a node to the list is straightforward. \nWe simply declare a new list node pointer, and indicate that it points into the needed group as shown \nin the linked list example. In our .rst example with list t, we demonstrated the use of the group cast \nto change the sharing mode of an entire linked list. This idiom is fairly common in concurrent C programs. \nThat is, a data structure is initialized privately to one thread before being shared among all threads \neither protected by a lock, or read-only. We can also merge one group into another group. This operation \nrequires a checked cast because we do not currently support any notion of subgroups, and so no pointers \nidentifying the leader of the old group as their group leader may exist after the merge: list t group(Ltail) \nprivate * private Ltail; list t group(Lhead) private * private Lhead; // ... nodes are added to Ltail \n... Lhead->next = gcast (list t group(Lhead) private *, Ltail); Due to the few restrictions placed on \ninternal group pointers (i.e. the same pointers), our type system does not support group split\u00adting. \nHowever, we do support the removal of individual objects from a group using the single-object sharing \ncast; if the same .elds of an object are null, then it can be cast to any group. The inability to split \ngroups has not been problematic in our benchmarks. 2.6 Instrumentation In Figure 4 we show the instrumentation \nthat Shoal uses for its dynamic analysis. In fact, this snippet is simply meant to show log\u00adically what \nthe instrumentation does since the actual implementa\u00adtion involves some amount of optimization to reduce \nthe cost of ref\u00aderence counting, and some additional complexity because the ref\u00aderence counting must \nbe thread safe. Since this example involves only the private and locked() modes, all of the instrumenta\u00adtion \ncomes from checking that Lck is held when lckL is accessed (line 29), reference counting, and checking \nthe reference count at the group cast (line 31). Since we can verify statically that t is dead at the \nassignment at line 15 of Figure 3, and that t and end are dead at the group cast at line 19 of Figure \n3, the only dynamic checking 1 void init() { 2 list t *pL = NULL, *t = NULL, *end = NULL; 3 for (int \ni = 0; i < 10; i++) { 4 decrc(t); 5 t = malloc(sizeof(list t)); 6 incrc(t); 7 t->data = i; 8 t->next \n= NULL; 9 if (pL == NULL) { 10 assert (pL == NULL); 11 decrc(pL); 12 pL = t; 13 incrc(pL); 14 decrc(end); \n15 end = pL; 16 incrc(end); 17 } 18 else { 19 decrc(end->next); 20 end->next = t; 21 incrc(end->next); \n22 decrc(end); 23 end = t; 24 incrc(end); 25 } 26 } 27 mutex lock(Lck); 28 sharc lock acquire(Lck); 29 \nassert(sharc has lock(Lck)); 30 // The following six lines are performed atomically 31 assert(refcount(pL) \n== 1); 32 decrc(lckL); 33 lckL = pL; 34 incrc(lckL); 35 decrc(pL); 36 pL = NULL; 37 sharc lock release(Lck); \n38 mutex unlock(Lck); 39 } Figure 4. Our linked list example shown after instrumentation by Shoal. Since \nthe example is using only the private and locked() modes, the only instrumentation is for reference counting, \nchecking that locks are held, and checking the group cast. needed for the group() types is ensuring that \npL is null before it is assigned (line 10). If t and end were not determined statically to be dead at \nthe above mentioned locations, the instrumented code would contain assertions requiring them to be null. \n 2.7 A More Complex Example Figure 5 gives pseudo-code for an n-body simulation using the Barnes-Hut \nalgorithm [3]. At each simulation time-step, Barnes-Hut constructs an oct-tree based on the locations \nof the bodies, then computes the center of mass of each node in the oct-tree. The force on each particle \nis computed by walking the oct-tree; the e.ect of all particles within an oct-tree node can be approximated \nby the node s center of mass as long as this is far enough from the particle. Finally, the computed force \nis used to update a particle s velocity and position. Figure 5 omits the code that builds the tree and \ndoes the cal\u00adculations to highlight the data structures, sharing modes and group casts. This pseudo-code \nhas been adapted to pthreads from a Split-C [19] program (itself inspired by the Barnes-Hut Splash2 [32] \nbenchmark) written in an SPMD style; it uses barriers to synchro\u00adnize accesses to shared data structures, \nand each thread has a unique id given by MYPROC. The tree is built out of node t structures. Each node \nt records the total mass of the bodies below that node and the position of their center of mass. Further, \nleaf nodes in the tree can  1 typedef struct node { 2 double mass; 3 double pos[3]; 4 struct node same \n*parent; 5 int bodies[8]; 6 struct node same *children[8]; 7 } node t; 8 9 typedef struct body { 10 \ndouble mass; 11 double pos[3]; 12 double vel[3]; 13 double acc[3]; 14 } body t; 15 16 void BuildTree(node \nt group(root) private *root, 17 body t private *Bodies); 18 19 void run() { 20 node t group(root) private \n*root; 21 node t group(roRoot) readonly *roRoot; 22 body t private *bodies; 23 body t barrier *barBodies; \n24 25 if (MYPROC == 0) 26 initBodies(bodies); 27 while (not done) { 28 if (MYPROC == 0) { 29 root = malloc(sizeof(node \nt)); 30 BuildTree(root,bodies); 31 roRoot = 32 gcast(node t group(roRoot) readonly *,root); 33 barBodies \n= 34 scast(body t barrier *,bodies); 35 } 36 barrier(); 37 // Share roRoot and barBodies, then calculate \n38 // new body positions. 39 barrier(); 40 if (MYPROC == 0) { 41 root = 42 gcast(node t group(root) private \n*,roRoot); 43 bodies = 44 scast(body t private *,barBodies); 45 free tree(root); 46 } 47 } 48 } Figure \n5. An oct-tree is built privately to one thread, and then the entire tree is cast to readonly to be shared \nwith all other threads. point to up to eight bodies, while internal nodes have eight chil\u00ad dren. The \nbodies are represented in the node t s as an index into a body t array whose elements represent the particles. \nFinally, every node has a pointer to its parent node. The function run(), executed by each thread, shows \nan out\u00ad line of how the simulation runs. First, the initial positions and ve\u00ad locities of the bodies \nare written into the array of body t struc\u00ad tures(line 26) by one of the threads. This initialization \noccurs pri\u00ad vately to this thread. This is re.ected by the private sharing mode of the bodies array \non line 22. Next, the threads enter the main loop. First, an oct-tree is built by the same thread that \ninitialized the bodies(line 30). While the tree is being built, the parent pointers in the nodes are \n.lled in. In the last step of BuildTree(), the tree is walked up from each leaf node to calculate the \nmass and center of mass for each node3. During this process the parent nodes are nulled out, as they \nwill not be used again. After the tree is built, it will no longer need to be written. Further it will \nneed to be read by the other threads. This sharing mode change is implicit in the original program through \nthe use of the barrier() call, but with Shoal such changes must be explicit. Hence, we use a group cast \nto make the entire tree readonly (line 32). This cast succeeds because there is only one external reference \nto the whole oct-tree, and because no other pointers aside from root mention root in their types. Further, \nno other pointers aside from roRoot mention roRoot in their types, so it is also safe to write roRoot. \nIf BuildTree had saved an external reference into the tree, then this external reference would have been \ndependent on some pointer to the group leader. This unsafe condition would then be caught during the \nchecked cast because the reference count to the group leader would be greater than one. We also cast \nthe bodies array(line 34). We use the barrier sharing mode because di.erent threads own di.erent parts \nof the array. The thread that owns a body calculates its new position, velocity, and acceleration based \non the masses of nearby bodies (distant bodies are not accessed as their e.ects are summarised in the \noct-tree). Some parts of the body structure are readonly, and other parts are private. This fact cannot \nbe represented by our static type system, but we can check the desired access pattern using the barrier \nsharing mode. The cast of bodies can use the single-object sharing cast (scast) as the body t type contains \nno same pointers. Following these casts, the pointers to the body array and the tree root are shared \nthrough globals with the other threads, and the simulation is updated. Subsequently, these pointers are \nnulled out in all threads but one, and more casts are used to indicate that the body array and oct-tree \nare private again (lines 41 and 43). The oct-tree can then be destroyed (line 45). If this program compiles \nand runs without errors with Shoal, then we know that no pointers exist to the oct-tree or to the bodies \nwith the wrong type, that there are no data races on the bodies while they are protected by the barrier \nsynchronization (or on other objects in other sharing modes), and that only one thread accesses the oct-tree \nor the bodies while they are in the private mode. On this example, Shoal s dynamic checking incurs a \nruntime overhead of 38% when running a simulation of 100 time steps for approximately 16000 bodies. Most \nof this overhead is due to the cost of reference counting.  2.8 Static vs. Dynamic Checking Shoal does \nvery little dynamic checking beyond what is already done by SharC, i.e. reference counting, and checking \nfor the locked sharing modes. As mentioned above, our group() type is dependent, and as one might expect, \nsome of the type checking must be done at runtime. In our case, this entails inserting a small number \nof checks to make sure that certain pointers are null. In practice the number of checks is small, and \nour timing primitives are not precise enough to measure their a.ect on the performance of our benchmarks. \nShoal s barrier mode is checked at runtime. For objects in the barrier mode, in between barriers, dynamic \nchecks are inserted that require these objects to be either private or read-only between barriers. At \neach barrier, the analysis is reset to re.ect the fact that the ownership of barrier mode objects changes \nat barriers. All other components of our analysis are done statically. 3 We note here that it is sometimes \nnecessary when using groups to pass an unused pointer to the group leader to recursive functions. This \nhas not caused problems in our benchmarks.  Program P ::=. | P; P De.nition . ::= x : t | t = ( f1: \nf1,..., fn : fn) | f (){x1: t1,..., xn : tn; s}Dependent Type t ::= m<\u00a3> t Field Type f ::= t | t Sharing \nMode m ::= locked | private Statement s ::= s1; s2 | spawn f () | lock x | unlock x | \u00a3 := e [ when .1,...,.n \n] | wait | done L-expression \u00a3 ::= x | x. f Expression e ::= \u00a3 | new | gcast x Predicate . ::= oneref(x) \n| m(x) | \u00a31 = \u00a32 | \u00a3 = null Identi.ers f, x, t Figure 6. A simple imperative language. Elements in bold \nare only used in the operational semantics. Figure 7. A simple group 3. The Formal Model Shoal s formalism \nis derived from that SharC [1], with signi.cant changes to handle data structures, and our notion of \ngroups and group casts. Our language (Figure 6) consists of global variable (x : t), C-like structure \n(t = ...) and function ( f (){...}) de.nitions (we assume all identi.ers are distinct). Our global variables \nare unusual: for each global variable x : t a structure instance ox of type t is allocated at program \nstartup, and newly created threads have a local variable x : t that is initialized to ox. This allows \nsharing between our threads while simplifying our semantics by allowing all variables to be treated as \nlocal. Figure 7 shows typical type declarations for two variables x and y: a type t of the form m<x> \nt represents a pointer to the structure named t, that can be null. The sharing mode m is the sharing \nmode of the pointer s target; our formalization supports private (acces\u00adsible to only one thread) and \nlocked (each structure protected by an implicit lock, Java-style). As we described earlier, each group \nis identi.ed by a distinguished leader object. In our type system, all pointer types must include the \nname x of a variable or .eld that points to the leader (the syntax allows for arbitrary lvalues, but \nthese can only appear during type-checking and in the oper\u00adational semantics). For instance, in Figure \n7 y points to the leader for x s target. In the rest of this section, we simply call y x s leader. Note \nthat the leader of y is y itself (this is required for soundness), however it is legal to have multiple \npointers to the group leader. For instance, we could add declarations y1 : private<y1> u x1 : private<y1> \nt and legally assign y to y1 and x to x1. Thus, the declaration (y : m<x> t) is equivalent to the C \nlanguage declaration (tm group(x) * private y) since all variables in the formalism are locals. Our pointer \ntypes depend on variables and are thus a form of dependent types. To ensure soundness in the presence \nof mutation, we use similar type rules to the Deputy system [9] (see below). Structures consist of a \nset of typed .elds f : f, where f is either a dependent type t or an unquali.ed pointer to a structure \nt. In the .rst case, the type t can only depend on other .elds (as in Deputy) and cannot be private4, \nin the second case the pointer is a same group pointer, i.e. it s target is in the same group and has \nthe same sharing mode as the structure itself. For example list = (data: locked<data> stuff, next: list) \nx : private<x> list declares a linked-list type where the list node structures are in a single group. \nThus, these declarations are equivalent to the C language declarations: struct list { stuff locked(data) \ngroup(data) *data; struct list same *next; } struct list private group(x) * x; The variable x is thus \na private list with locked contents: x, x.next, x.next.next, . . . are all private objects in the same \ngroup, while the list contents x.data, x.next.data, . . . are in separate groups protected by locks. \nFunctions f consist of local variable de.nitions and a sequence of thread-spawning, locking and assignment \nstatements. Assign\u00adments are guarded by runtime checks (.) which check sharing modes are respected (m(x)), \ncompare lvalues (\u00a3 = \u00a3' and \u00a3 = null) and assert that x is the sole reference to a particular object \n(oneref(x)). These runtime checks are added automatically during type checking. The most important expression \nis gcast x which per\u00adforms a group cast on x s target. For instance: y : locked<y> list y := gcast x \n casts our list x whose node structures were private into a list y whose node structures are protected \nby locks. A group cast can also merge two groups: y : locked<z> list y = gcast x z.next = y Our formalism \ncan readily be extended with primitive types, further sharing modes and an scast x expression to extract \na sin\u00adgle object from a group (under the condition that all same-group .elds are null). However, our \nformalism does not currently support splitting a group into two arbitrary parts. 3.1 Static Semantics \nFigure 8 presents the type-checking rules for our language. These rules both check a program for validity \nand rewrite it to include necessary runtime checks. Also, we restrict assignments to the forms x := e \nand x. f := y. To simplify exposition, we assume in the rules that GG (x) gives the type of global variable \nx, T is the set of all structure types, and t( f ) gives the type of .eld f of structure t. The global, \nstructdef and thread rules enforce the restriction that variable types are only dependent on other variable \ntypes, while 4 This requirement can be relaxed to forbidding non-private pointers to such structures. \n .eld types are only dependent on other .elds of the same structure. Furthermore, globals cannot be \nprivate and structures cannot contain explicitly private .elds, as having a non-private pointer to a \nstructure with a private .eld would be unsound. The dependent rule requires that the leader of a group \nuses itself as leader. Reading or writing lvalue \u00a3 (read, write) requires three sets of runtime checks. \nFirst, if \u00a3 = x. f we must enforce x s sharing mode. Second, we must ensure that the lvalues denoting \nthe assignment s source and target group match after the assignment. Third, the function D adds runtime \nchecks to ensure that any variables or .elds dependent on the assignment s target \u00a3 ' are null before \nthe assignment, as the assignment would otherwise be unsound. The scoping rules enforced in global, structdef \nand thread make these checks tractable: if \u00a3 ' = x. f , .elds dependent on f must be in the same structure \ninstance, while variables dependent on \u00a3 ' = x must be variables of the same function. Finally, these \nchecks remain sound even in the presence of concurrent updates by other threads: variables cannot be \nmodi.ed by other threads, while the runtime check . that enforces \u00a3 = x. f s sharing mode also guarantees \nthat any other .elds of x can be accessed without races. A group cast of y can be performed if y is the \nonly reference to the target object. Because the group cast nulls-out y, the dependent\u00adtype restrictions \n(D) must hold for y, as in a regular assignment to y.  3.2 Operational Semantics The parallel operational \nsemantics of Figure 9 models the .ne\u00adgrained interleaving of threads in a shared memory setting. The \nshared memory M : I+ . . \u00d7 I \u00d7 I \u00d7 (name . I) maps a cell s address to its runtime type, owner, locker, \nand value. The runtime types . are of the form m<a> t, where a is the address of the cell s group leader. \nThe owner is the thread identi.er (an integer) that owns the cell if it s sharing mode is private. The \nlocker is the thread identi.er that currently holds a lock on the cell, or 0 if the cell is unlocked. \nFinally, the value is a map from .eld names to cell addresses. We use the notation M.(a), Mo(a), ML(a) \nand Mv(a) to denote respectively the type, owner, locker and value of cell a, . oL v while M[a ---- . \n.], M[a . n], M[a . n] and M[a . v] represent the corresponding updates to cell a. For convenience, we \nalso write Mv(a. f ) and M.(a. f ) to return respectively the value and type of .eld f of cell a, and \nM[a. f -v . b] to update .eld f of cell a. Note that M.(a. f ) returns the static type t of .eld f , \nnot the runtime type of cell Mv(a. f ).  Thread identi.ers are simply the address of a memory cell whose \nvalue is a map of the thread s variable names to their values. States of the operational semantics are \nof the form M, (id1, s1),..., (idn, sn) representing a computation whose memory is M and which has n \nthreads, each identi.ed by address idi and about to execute si. To handle thread creation, each thread \nde.nition f is represented by a prototype thread of the form (idf , wait; sf ) where sf is the body of \nthread f and M(id f ) is a memory cell with the initial state of f s variables: Mv(id f .x) is null for \nall local variables of f and a pointer to the preallocated structure instance ox for global variable \nx. Transitions between states are de.ned with a number of helper judgments and functions: M, id : s \n-s . M': execution of simple statement s by thread id updates the memory M to M' .  M, id |= . holds \nif runtime check . is valid.  lval(M, id,\u00a3) converts a static lvalue \u00a3 of thread id to a runtime lvalue \nof the form a. f (.eld f of cell a), and is unde.ned if \u00a3 requires dereferencing a null pointer.  P' \nis identical to P except for runtime checks that f P . P' ensure P s sound execution. (definitions) (global) \nf .1 . . ' 1 f .2 . . ' 2 GG f m<y> t m * private f .1; .2 . . ' 1; . ' 2 f x : m<y> t . x : m<y> t (structdef) \n [ f1: f1,..., fn : fn] f fi fi * private< f > u f t :( f1: f1,..., fn : fn) . t :( f1: f1,..., fn : \nfn) (thread) G=GG[x1: t1,..., xn : tn] G f ti G f s . s ' f f : {x1: t1,..., xn : tn; s}. f : {x1: t1,..., \nxn : tn; s '} G f f Type f is valid in environment G. (same)(dependent) t . T G(x) = m<x> ut . T G f \nt G f m<x> t In environment G, \u00a3 is a well-typed lvalue with G f \u00a3 : t, . type t assuming . holds. (name)(same \nfield) G(x) = m<y> t G(x) = m<y> tt( f ) = t ' G f x : m<y> t,E G f x. f : m<y> t ' , m(x) (dependent \nfield) G(x) = m<x> tt( f ) = m <g> t ' G f x. f : m <x.g> t ' , m(x) In environment G statement s compiles \nto s ', which G f s . s ' is identical to s except for added runtime checks. (new) G(x) = t G f x := \nnew . x := new when D(G, x) (group cast) x * y G(x) = t G(y) = m <y> t G f x := gcast y . x := gcast \ny when oneref(x), D(G, x), D(G, y) (read) G(x) = m<x ' > t G f \u00a3 : m<\u00a3 ' > t,. G f x := \u00a3 . x := \u00a3 when \n., x ' [\u00a3/x] = \u00a3 ' , D(G, x) (write) G f x. f : m<\u00a3> t,. G(y) = m<y ' > t G f x. f := y . x. f := y \nwhen ., \u00a3[y/x. f ] = y ' , D(G, x. f ) Runtime checks for dependent-type assignments D(G, x) = {y = null \n| x * y . G(y) = m<x> t} D(G, x. f ) = {x.g = null | G(x) = m<y> t . f * g . t(g) = m< f > t} Figure \n8. Typing judgments. We omit the straightforward rules for non-assignment statements.  sL M, id : lock \nx -M[Mv-(id.x)) =. (id.x) . id] if ML(Mv0 sL M, id : unlock x -M[Mv-(id.x)) = . (id.x) . 0] if ML(Mvid \nsv v M, id : x := new . extend(M[id.x --max(dom(M)) + 1 -. a], id, a, rtype(M[id.x . a], id, M. (id.x))) \nwhere a = s vv M, id : x := gcast y . gcast(M' , id, c, rtype(M' , id, M.(id.x))) where c = Mv(id.y), \nM' = M[id.x . c, id.y . 0] --- . s -v M, id : \u00a3 := \u00a3 '-M[lval(\u00a3) . Mv(lval(\u00a3 '))] Mv(lval(\u00a3)) = Mv(lval(\u00a3 \n' )) Mv(lval(\u00a3)) = 0 ML(Mv(id.x)) = id |{b. f |Mv(b. f ) = Mv(id.x)}| = 1 M, id |= \u00a3 = \u00a3 ' M, id |= \u00a3 \n= null M, id |= private(x) M, id |= locked(x) M, id |= oneref(x) (simple statement) (runtime check) \nM, id : s1 -sM, id |= .1 . M ' M, {(id, s1; s2)}. S . M' , {(id, s2)}. SM, {(id,\u00a3 := e when .1,.2 ...,.n; \ns)}. S . M, {(id,\u00a3 := e when .2 ...,.n; s)}. S (thread creation) (thread destruction) M '' id ' = max(dom(M)) \n+ 1 M ' = extend(M, id ' , id ' , M.(id f )) = M ' [id '-v (id f )] M ' = M\\id . Mv M, {(id, spawn f \n(); s), (id f , wait; sf )}. S . M '' , {(id ' , sf ; done), (id, s), (id f , wait; sf )}. SM, {(id, \ndone)}. S . M ' , S lval(M, id, x) = id.x lval(M, id, x. f ) = Mv(id.x). f if Mv(id.x) * 0 rtype(M, id, \nm<x> t) = m<Mv(id.x)> t extend(.M, id, a,.) = M[a . (., id, 0,. f.0)] . M. ' (a) = . if M.(a) = m <c> \nt . c * 0, M.(a) otherwise gcast(M, id, c,.) = M' where .Mo' (a) = id if M.(a) = m <c> t . c * 0, Mo(a) \notherwise . . Mv'(a) = Mv(a), ML' (a) = ML(a) Figure 9. Operational semantics. rtype(M, id,t) converts \na static type t of thread id to the corre\u00adsponding runtime type ..  extend(M, id,.) represents allocation \nof a cell of runtime type . by thread id.  gcast(M, id, c,.) performs a group cast to . in thread id \nof the group whose leader is M(c).  The rules are mostly straightforward, but a few points are worth \nnoting. We use . to denote disjoint union (A = B.C . BnC = \u00d8). Individual runtime checks are executed \natomically, but involve at most one lvalue of the form x. f . Other threads may execute be\u00adtween runtime \nchecks and between the checks and the assignment they protect. The oneref(x) check is computed by heap \ninspection, but we implement it in practice using reference-counting. We could exclude non-dependent \n.elds from oneref(x) check, this would cor\u00adrespond to not reference-counting same pointers. A group cast \nof a variable y whose value is null should have no e.ect. To ensure this, gcast never updates cells whose \ntype is m<0> t.E.ectively, group 0 corresponds to our nogroup C-level annotation: once in group 0, you \ncan no longer be subject to a group cast. Our formalism does allows casts to group 0, and allocations \nin group 0. Finally, and most importantly, the type and owner .elds of M are not required in an actual \nimplementation, thus gcast has no runtime cost.  3.3 Soundness We have proved [2] the following theorems, \nthat show that type safety is preserved and that the program respects the behavior speci.ed by the sharing \nmode declarations. Theorem 1. Soundness. Let P be a program with f P . P' and M0, S 0 be the initial \nmemory and threads for program P' . Let M, {(id1, s1),..., (idn, sn)} be a state reachable in i steps \nfrom M0, S 0. Then types and owners are consistent in M, and all state\u00adments si typecheck. Theorem 2. \nSafety of private accesses. During the execution of a program P' such that f P . P', if thread id writes \nto cell a with type M. (a) = private<b> t then Mo(a) = id. Theorem 3. Safety of locked accesses. During \nthe execution of a program P' such that f P . P', if thread id writes to cell a with type M. (a) = locked<b> \nt then ML(a) = id. 4. Evaluation We applied Shoal to 5 interesting applications, the largest of which \napproaches 1 million lines of code. All but one of these benchmarks use multithreading to improve performance; \nwe have included in our benchmarks a webserver that uses a thread pool to serve clients in parallel and \nhide I/O latency. None of the benchmarks required more than a few days to make su.cient annotations to \nsuppress a small number of false error reports and achieve good performance. The amount of human program \nunderstanding required to make these annotations is not especially burdensome. The goal of these experiments \nis to show that Shoal allows prac\u00adtical checking of data sharing in a substantially wider range of pro\u00adgrams \nthan it would be able to without groups, while maintaining low overhead. In the course of running our \nbenchmarks, we found no bugs, and the only sharing errors found were benign data races on .ags used for \ncondition variables. These races would at worst cause a thread to needlessly call a condition wait() \nfunction an extra time. For these .ags we used Shoal s racy annotation to sup\u00adpress the false error reports. \nIt is not surprising that we did not .nd more serious bugs because our testing of the benchmark applica\u00adTable \n1. Benchmarks for Shoal. For each test we show the maximum number of threads running concurrently(Conc.), \nthe size of the benchmark including comments (Lines), the number of annotations we added (Anns.), sharing \ncasts required (Casts), and the maximum size of a group in a run of the benchmark. We also report the \ntime overhead caused by Shoal  Name Conc. Benchmark Lines Anns. Casts Max Group Performance Orig. Shoal \nebarnes 2 3k 60 16 16384 6.26s 38% em3d-s 2 1k 42 2 100000 3.59s 42% knot 3 5k 60 17 75 0.69s 19% eog \n4 38k 67 38 20 1.42s 6% GIMP 4 936k 37 32 8 9.67s 13%  tions was intended only to measure the performance \noverhead seen in typical use-cases. 4.1 Implementation We extended the static type system of SharC to \ninclude our group() and same annotations. Further, we added our group cast operation, and extended the \ndynamic analysis with the null checks required by our dependent group types. We also implemented the \nbarrier mode by generalizing SharC s existing dynamic analysis. We reduced the additional annotation \nburden presented by the addition of groups by automatically applying common default an\u00adnotations to unannotated \nobjects. First, the default group annotation on pointer types that need one is nogroup. This way, the \nprogram\u00admer must only annotate objects needing a group annotation if they may eventually be involved \nin a group cast. Secondly, the default annotation on structure .elds in objects that may be subject to \na group cast is same. This prevents SharC from forbidding casts of these structures.  4.2 Benchmarks \nThe results of our experiments are reported in Table 1. The .gures we report are averages over 50 runs \nof each benchmark. These experiments were performed on a machine with a dual core 2GHz IntelR&#38;#169; \n5130 processor with 2GB of memory. Excepting the &#38;#169; XeonRscienti.c benchmarks, the runtime overhead \nimposed by Shoal is less than 20%. The higher overhead in the scienti.c benchmarks is due to reference \ncount updates in the inner loops. We also observed a reasonable annotation burden, ranging from one annotation \nor cast per 25 lines in the small benchmarks to less than one per 10 000 lines on the largest. Ebarnes \nwas presented in Section 2.7. Em3d-s is another adapted Split-C scienti.c program that models the propagation \nof electromagnetic waves through objects in three dimensions. In this simulation the system is modeled \nas a bipartite graph. One partition models the electric .eld, and the other partition models the magnetic \n.eld. At the beginning of the simulation the graph is constructed privately to one thread. Then, a sharing \ncast is used to indicate that the graph is shared with other threads with accesses synchronized by barriers. \nTo allow the sharing mode of the entire graph to change, the nodes and edges form a group whose leader \nis the structure containing pointers to the lists of nodes and edges. Knot [30] is a simple multithreaded \nwebserver. It maintains a thread pool for processing client requests. The threads share an in-memory \ncache of the .les on disk. The cache is implemented as a hash table and is protected by a lock. Each \ncall to the hash table API is made while the lock is held. Therefore, we cast the entire hash table to \nprivate before passing it to the hash table functions. The primary advantage of this approach is that \nit allows the hash table API to be used both in single-threaded and multi\u00adthreaded contexts. The benchmark \nfor knot involves two clients simultaneously making 10k requests for small .les that .t entirely in the \nin-memory cache. The webserver and clients both ran on the same host. The goal of this setup is to minimize \nthe extent to which the benchmark is I/O bound. The overhead for knot in Table 1 is reported as the percent \nincrease in CPU utilization. However, runtime for the benchmark did not increase signi.cantly, nor did \nthe throughput decrease signi.cantly. Because the sharing mode of the entire in-memory cache changes \nfrom locked to private and back, the hash table data structure used for the cache forms a single group \nalong with all cache entries. The hash table object containing pointers to the array used for the hash \ntable and other metadata is the group leader.  Eog is the Eye-of-Gnome image manipulation program dis\u00adtributed \nwith the Gnome desktop environment. It can open, dis\u00adplay, and rotate many di.erent image formats. Eog \nuses threads to hide the latency of the operations performed on images from the user interface. These \noperations include loading and saving images, transforming them, and creating image thumbnails. The GUI \nplaces Job data structures in a lock protected queue. When worker threads take jobs o. of the queue, \nthey must cast the entire Job data structure, which contains the image, and image metadata, to the private \nmode. Each Job structure and the objects to which it has pointers are placed in a group with the Job \nstructure itself being the group leader. For this benchmark we measured the CPU time needed to open an \nimage, rotate it, and then save it back to disk. The GIMP is also an image manipulation program, but \nwith many more features than Eye-of-Gnome. In particular, it is script\u00adable, and capable of many more \nsophisticated image transforma\u00adtions. On loading an image, the GIMP divides it up into distinct sections, \nwhich are stored in data structures called Tiles. To per\u00adform a transformation, the GIMP creates a thread \npool and an it\u00aderator over tiles that is protected by a lock. When a tile is in the iterator it is in \nthe locked mode, but when a thread removes it from the iterator it casts it to the private mode. The \nTile object con\u00adtains pointers that would be cumbersome to cast individually, so each Tile object and \nthe objects to which it has pointers are made a group with the Tile object itself being the group leader. \nFor this benchmark, we wrote a script that opened an image, performed 20 separate Blur operations, and \nthen saved the image back to disk.  4.3 Scaling In order to see how Shoal scales with the number of \nthreads, we ran the two scienti.c benchmarks on a server machine with 4GB of memory and two quad-core \nIntelR&#38;#169; E5462 processors run\u00ad &#38;#169; XeonRning at 2.8GHz. As shown in Figure 11, we observed \nthat the over\u00ad head incurred by our system did not increase signi.cantly as the number of threads ranged \nfrom two to eight while the workload was held constant. The di.erence in relative overhead on this ma\u00adchine \nvs the dual core machine used in the main experiments is due to di.erential speedup in the application \nand overhead: abso\u00adlute overhead for both ebarnes and em3d-s decreased by 30%, as expected from the clock \nspeed increase, while the application code sped up by 51% 59%, much more than the clock speed increase. \nWe suspect, though have not con.rmed, that the application code gets an extra advantage from the larger \nL2 cache (2x6MB vs 4MB) and memory bus speed (1600MHz vs 1333MHz). The main scaling bottleneck in Shoal \nis that only one thread may be computing a reference count at any time. This could impact programs performing \nmany group or sharing casts. However, this e.ect was not observed in our experiments. 4.4 Sources of \nOverhead Figure 10 shows the sources of performance overhead for our benchmarks. They are broken down \ninto concurrent reference counting, the Shoal runtime checks, and various infrastructure costs. Infrastructure \ncosts are incurred by the use of the CIL [22] compiler front end5, a custom malloc implementation needed \nfor concurrent reference counting, and the need to null out pointers on allocation for soundness reasons. \nWe observe substantial reference counting overhead in the ebarnes and em3d-s benchmarks due to the reference \ncount up\u00addates needed when building and traversing the oct-trees and graph respectively. In eog and the \nGIMP, the overall low overhead makes the cost of our custom runtime more apparent.  4.5 The Need for \nGroups In Table 1, we also report the maximum size of a group in each of our benchmarks. We interpret \ngroup size to be a rough measure of how costly it would be to port a program to SharC without groups, \nboth in terms of performance and programmer e.ort. This interpretation is justi.ed in the following ways. \nWithout groups, it would be necessary to cast each object in a group individually. In order to meet the \nsingle reference requirement for the sharing cast, it is necessary to completely remove an object from \na data structure before casting it. If a data structure has cycles, the code to perform this operation \ncan be complex, and goes far beyond the low level of e.ort needed to annotate a program. Further, the \nadditional data structure traversal, reconstruction, and reference counts would cause additional programmer \nand performance overhead. 5. Related Work The most closely related work is our paper describing the original \nSharC system [1]. This paper described our extensions to SharC s type system with support for handling \ncomplex data structures. Many other researchers have investigated both type systems for de\u00adscribing aggregates \nof objects, and methods for making concurrent programs safe. 5.1 Ownership and Region Type Systems Ownership \ntypes have been used to statically enforce properties such as object encapsulation, race-freedom, and \nmemory safety [4]. An ownership type system statically guarantees that every object has a unique owner \nand that the ownership relation is a forest of trees. The type system allows multiple pointers to an \nobject but statically checks that only the pointer from its owner has special privileges. For instance, \nan ownership type system for object en\u00adcapsulation prevents unrestricted accesses to an object by checking \nthat all accesses happen via the pointer from its owner [6]. Like\u00ad wise, an ownership type system for \nrace-freedom requires each ac\u00adcess to an object o to be protected by a lock held on its root owner, which \nis the object at the root of the tree in the ownership rela\u00adtion forest that contains o [5]. Finally, \nan ownership type system can be combined with a region type system and used for region\u00adbased memory management \n[7] in which each object is allocated in the same region as its owner. The resulting type system is more \nrestrictive and enforces memory safety by forbidding pointers from outside the region to objects inside \nthe region which enables it to safely free all objects in the region whenever the region handle is freed. \nFurther, dynamic analyses have been developed to help pro\u00adgrammers visualize ownership relationships \nin their programs [24]. In these systems, instead of requiring programmers to annotate in\u00adstances of \nencapsulation, which is the common case, the program\u00admer is shown the cases in which encapsulation is \nviolated, which is typically less common. The relationship of a group leader to objects in its group \nis analogous to that of an owner to objects it owns. Groups however 5 Using the CIL front end can cause \nchanges in performance. CIL performs some transformations (e.g. introducing additional temporary variables) \nthat can both enable and prevent certain C compiler optimizations.  are more general in that objects \ncan be added to or removed from them and group leaders can change dynamically, in contrast to the ownership \nrelation, which cannot be changed dynamically. We have found that this ability is crucial for applying \nan ownership-like system to large C programs. Region type systems have strong similarities to groups: \nthey use types to identify a collection of objects, and allow global op\u00aderations (typically deallocation) \nto be performed on that group. RC [16] is the closest to our groups: it uses reference counting to track \npointers into regions, and has a sameregion quali.er to identify pointers that stay within a region. \nHowever, as with other regions systems, region membership is .xed at allocation time and tracked explicitly \nat runtime, regions cannot be merged and sameregion is mostly a performance hint to avoid the need for \nreference-counting. Tofte and Talpin s statically checked region type system [29] places further restrictions \non region lifetimes and pointers between regions: essentially, region lifetimes are nested and pointers \nare only allowed from longer-lived regions to shorter\u00adlived regions, but not vice-versa. Crary and Walker \ns [10] use of capabilities relaxes these restrictions somewhat, but still does not allow unrestricted \npointers between regions. E.ectively, Shoal s use of reference-counting allows a runtime-check to recover \nthe linearity property of a group (region) reference that the static type systems must ensure at compile-time. \nThe authors of Cyclone [18] note the similarity in their type system between types for region membership \nand types for lock protection. Indeed, they go so far as providing a shorthand for when objects in the \nsame region are protected by the same lock. Shoal expands on this idea by allowing objects belonging \nto the same data structure (which may be unrelated with respect to memory allocation concerns) to be \nrelated not only by locking, but also a variety of mechanisms for safe concurrency. Further, we note \nthat Shoal would likely bene.t from some of the polymorphism in Cyclone s type system, but we leave this \nextension for future work.  5.2 Safe Concurrency Checking There has been much work on .nding concurrency \nrelated bugs in multi-threaded programs. Researchers have attempted to .nd and prevent data races, and \natomicity violations, using both static [21, 25, 15, 23, 31, 13, 18, 20] and dynamic [26, 33, 12, 14, \n8] analysis. SharC di.ers from these approaches because it attempts to .nd violations of a programmer \nspeci.ed sharing strategy rather than searching for violations using lock-set or happens-before based \nheuristics. The original SharC paper discusses in detail its relation to these traditional concurrency \nchecking methods. We also wish to mention a few other related projects. First, race freedom can be checked \nby translation to a linear program based on fractional capabilities [28]. Since linear programming instances \ncan be solved in parallel, this technique may be able to scale to large programs. However, the possibly \nsubstantial collection of warnings may be di.cult to investigate because analysis results do not indicate \nwhat locks may be held at each program point. Shoal scales to large programs, and gives detailed error \nreports. Some other tools are also guided by programmer annotations. LockLint [11] is a static system \nthat checks that locks are used consistently to protect program variables. It uses annotations to suppress \nfalse warnings, to describe hierarchical locking, and procedure side-e.ects, and as documentation. Further, \nthe Fluid Project [17] has investigated a system for Java that allows a pro\u00ad grammer to make annotations \ndescribing hierarchical regions, aliasing intent, and a locking strategy that can apply to regions, among \nother annotations. Shoal di.ers from these systems primar\u00adily because it allows the sharing mode for \ndata structures to change through sharing and group casts as the program executes. 6. Conclusion In this \npaper, we have presented groups, a lightweight mechanism for describing properties of data structures, \nand applied groups to checking data sharing strategies in several multithreaded C pro\u00adgrams. An important \nfeature of our system is the group cast, which allows the programmer to describe where in the program \nthe prop\u00aderties of a group change. For instance, in many of the C programs we examined, data structures \nswitch between stages where they are protected by locks and stages where they are private to a single \nthread. We have proved the soundness of groups, and implemented Shoal, our group-based sharing checker \nas an extension to the ear\u00adlier SharC system. We are able to check the correctness of sharing in our \nbenchmarks with reasonable overhead (6% 42%) and a rea\u00adsonable annotation burden. Our formalism for groups \nis not strongly tied to the concept of a sharing mode. In the future, we plan to investigate further \nuses of groups, including memory management and tracking user-speci.ed properties like tainting. We also \nwish to continue improving Shoal, to reduce concurrent reference counting overhead, to be able to de\u00adscribe \nand check more kinds of sharing, such as double-checked locking [27] and to be able to check more kinds \nof sharing stati\u00ad cally, rather than, like barrier, dynamically. References [1] Anderson, Z., Gay, D., \nEnnals, R., and Brewer, E. SharC: checking data sharing strategies for multithreaded C. In PLDI 08, pp. \n149 158. [2] Anderson, Z., Gay, D., and Naik, M. Lightweight annotations for controlling sharing in concurrent \ndata structures. Tech. Rep. UCB/EECS-2009-44, EECS Department, University of California, Berkeley, Mar \n2009. [3] Barnes, J., and Hut, P. A hierarchical O(N log N) force-calculation algorithm. Nature 324 (Dec. \n1986), 446 449. [4] Boyapati, C. SafeJava: A Uni.ed Type System for Safe Programming. PhD thesis, MIT. \n[5] Boyapati, C., Lee, R., and Rinard, M. Ownership types for safe programming: preventing data races \nand deadlocks. In OOPSLA 02, pp. 211 230. [6] Boyapati, C., Liskov, B., and Shrira, L. Ownership types \nfor object encapsulation. In OOPSLA 03, pp. 213 223. [7] Boyapati, C., Salcianu, A., Beebee,Jr., W., \nand Rinard, M. Ownership types for safe region-based memory management in Real-Time Java. In PLDI 03, \npp. 324 337. [8] Choi, J.-D., Lee, K., Loginov, A., O Callahan, R., Sarkar, V., and Sridharan,M. E.cient \nand precise datarace detection for multithreaded object-oriented programs. In PLDI 02, pp. 258 269. [9] \nCondit, J., Harren, M., Anderson, Z., Gay, D., and Necula, G. Dependent types for low-level programming. \nIn ESOP 07. [10] Crary, K., Walker, D., and Morrisett, G. Typed memory management in a calculus of capabilities. \nIn POPL 99, pp. 262 275. [11] developers.sun.com. LockLint -static data race and deadlock detec\u00adtion \ntool for C. http://developers.sun.com/solaris/articles/locklint.html. [12] Elmas, T., Qadeer, S., and \nTasiran, S. Goldilocks: a race and transaction-aware Java runtime. In PLDI 07, pp. 245 255. [13] Engler, \nD., and Ashcraft, K. RacerX: e.ective, static detection of race conditions and deadlocks. In SOSP 03, \npp. 237 252. [14] Flanagan, C., and Freund, S. N. Atomizer: a dynamic atomicity checker for multithreaded \nprograms. In POPL 04, pp. 256 267. [15] Flanagan, C., Freund, S. N., and Lifshin, M. Type inference for \natomicity. In TLDI 05, pp. 47 58. [16] Gay, D., and Aiken, A. Language support for regions. In PLDI 01, \npp. 70 80.  [17] Greenhouse, A., Halloran, T. J., and Scherlis, W. L. Observations on the assured evolution \nof concurrent Java programs. Sci. Comput. Program. 58, 3 (2005), 384 411. [18] Grossman, D. Type-safe \nmultithreading in Cyclone. In TLDI 03. [19] Krishnamurthy, A., Culler, D. E., Dusseau, A., Goldstein, \nS. C., Lumetta, S., von Eicken, T., and Yelick, K. Parallel Programming in Split-C. In SUPERCOM 93, pp. \n262 273. [20] McCloskey, B., Zhou, F., Gay, D., and Brewer, E. Autolocker: synchronization inference \nfor atomic sections. In POPL 06, pp. 346 358. [21] Naik, M., and Aiken, A. Conditional must not aliasing \nfor static race detection. In PLDI 07, pp. 327 338. [22] Necula, G. C., McPeak, S., and Weimer, W. CIL: \nIntermediate language and tools for the analysis of C programs. In CC 04, pp. 213 228. http://cil.sourceforge.net/. \n[23] Pratikakis, P., Foster, J. S., and Hicks, M. Locksmith: context\u00adsensitive correlation analysis for \nrace detection. In PLDI 06, pp. 320 331. [24] Rayside, D., Mendel, L., and Jackson, D. A dynamic analysis \nfor revealing object ownership and sharing. In WODA 06, pp. 57 64. [25] Sasturkar, A., Agarwal, R., Wang, \nL., and Stoller, S. D. Automated type-based analysis of data races and atomicity. In PPoPP 05, pp. 83 \n94. [26] Savage, S., Burrows, M., Nelson, G., Sobalvarro, P., and Anderson, T. Eraser: a dynamic data \nrace detector for multi-threaded programs. In SOSP 97, pp. 27 37. [27] Schmidt, D., and Harrison, T. \nDouble-Checked Locking. In Chapter 20 of Pattern Languages of Program Design 3, Addison-Wesley, ISBN \n0201310112. [28] Terauchi, T. Checking race freedom via linear programming. In PLDI 08, pp. 1 10. [29] \nTofte, M., and Talpin, J.-P. Region-based memory management. In Information and Computation (1977), vol. \n132, pp. 109 176. [30] von Behren, R., Condit, J., Zhou, F., Necula, G. C., and Brewer, E. Capriccio: \nscalable threads for internet services. In SOSP 03, pp. 268 281. [31] Voung, J. W., Jhala, R., and Lerner, \nS. RELAY: static race detection on millions of lines of code. In ESEC-FSE 07, pp. 205 214. [32] Woo, \nS. C., Ohara, M., Torrie, E., Shingh, J. P., and Gupta, A. The SPLASH-2 Programs: Characterization and \nMethodological Considerations. In ISCA 95, pp. 24 36. [33] Yu, Y., Rodeheffer, T., and Chen, W. Racetrack: \ne.cient detection of data race conditions via adaptive tracking. In SOSP 05, pp. 221 234.    \n\t\t\t", "proc_id": "1542476", "abstract": "<p>SharC is a recently developed system for checking data-sharing in multithreaded programs. Programmers specify sharing rules (read-only, protected by a lock, etc.) for individual objects, and the SharC compiler enforces these rules using static and dynamic checks. Violations of these rules indicate unintended data sharing, which is the underlying cause of harmful data-races. Additionally, SharC allows programmers to change the sharing rules for a specific object using a <i>sharing cast</i>, to capture the fact that sharing rules for an object often change during the object's lifetime. SharC was successfully applied to a number of multi-threaded C programs.</p> <p>However, many programs are not readily checkable using SharC because their sharing rules, and changes to sharing rules, effectively apply to whole data structures rather than to individual objects. We have developed a system called <i>Shoal</i> to address this shortcoming. In addition to the sharing rules and sharing cast of SharC, our system includes a new concept that we call <i>groups</i>. A group is a collection of objects all having the same sharing mode. Each group has a distinguished member called the <i>group leader</i>. When the sharing mode of the group leader changes by way of a sharing cast, the sharing mode of all members of the group also changes. This operation is made sound by maintaining the invariant that at the point of a sharing cast, the only external pointer into the group is the pointer to the group leader. The addition of groups allows checking safe concurrency at the level of data structures rather than at the level of individual objects.</p> <p>We demonstrate the necessity and practicality of groups by applying Shoal to a wide range of concurrent C programs (the largest approaching a million lines of code). In all benchmarks groups entail low annotation burden and no significant additional performance overhead.</p>", "authors": [{"name": "Zachary R. Anderson", "author_profile_id": "81332488087", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P1464246", "email_address": "", "orcid_id": ""}, {"name": "David Gay", "author_profile_id": "81100039538", "affiliation": "Intel Research, Berkeley, Berkeley, CA, USA", "person_id": "P1464247", "email_address": "", "orcid_id": ""}, {"name": "Mayur Naik", "author_profile_id": "81100223912", "affiliation": "Intel Research, Berkeley, Berkeley, CA, USA", "person_id": "P1464248", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542488", "year": "2009", "article_id": "1542488", "conference": "PLDI", "title": "Lightweight annotations for controlling sharing in concurrent data structures", "url": "http://dl.acm.org/citation.cfm?id=1542488"}