{"article_publication_date": "06-15-2009", "fulltext": "\n A Randomized Dynamic Program Analysis Technique for Detecting Real Deadlocks Pallavi Joshi Chang-Seo \nPark Koushik Sen EECS Department, UC Berkeley, USA {pallavi,parkcs,ksen}@cs.berkeley.edu Abstract We \npresent a novel dynamic analysis technique that .nds real dead\u00adlocks in multi-threaded programs. Our \ntechnique runs in two stages. In the .rst stage, we use an imprecise dynamic analysis technique to .nd \npotential deadlocks in a multi-threaded program by observ\u00ading an execution of the program. In the second \nstage, we control a random thread scheduler to create the potential deadlocks with high probability. \nUnlike other dynamic analysis techniques, our ap\u00adproach has the advantage that it does not give any false \nwarnings. We have implemented the technique in a prototype tool for Java, and have experimented on a \nnumber of large multi-threaded Java programs. We report a number of previously known and unknown real \ndeadlocks that were found in these benchmarks. Categories and Subject Descriptors D.2.5 [Software Engineer\u00ading]: \nTesting and Debugging; D.2.4 [Software Engineering]: Soft\u00adware/Program Veri.cation General Terms Languages, \nReliability, Veri.cation Keywords deadlock detection, dynamic program analysis, con\u00adcurrency 1. Introduction \nA common cause for unresponsiveness in software systems is a deadlock situation. In shared-memory multi-threaded \nsystems, a deadlock is a liveness failure that happens when a set of threads blocks forever because each \nthread in the set is waiting to ac\u00adquire a lock held by another thread in the set. Deadlock is a common \nform of bug in today s software Sun s bug database at http://bugs.sun.com/ shows that 6,500 bug reports \nout of 198,000 contain the keyword deadlock . There are a few reasons for the existence of deadlock bugs \nin multi-threaded programs. First, software systems are often written by many programmers; therefore, \nit becomes dif.cult to follow a lock order discipline that could avoid deadlock. Second, programmers \noften introduce dead\u00adlocks when they .x race conditions by adding new locks. Third, software systems \ncan allow incorporation of third-party software (e.g. plugins); third-party software may not follow the \nlocking dis- Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n09, June 15 20, 2009, Dublin, Ireland. Copyright c &#38;#169; 2009 ACM 978-1-60558-392-1/09/06. . . $5.00 \nMayur Naik Intel Research, Berkeley, USA mayur.naik@intel.com cipline followed by the parent software \nand this sometimes results in deadlock bugs [17]. Deadlocks are often dif.cult to .nd during the testing \nphase because they happen under very speci.c thread schedules. Coming up with these subtle thread schedules \nthrough stress testing or random testing is often dif.cult. Model checking [15, 11, 7, 14, 6] removes \nthese limitations of testing by systematically exploring all thread schedules. However, model checking \nfails to scale for large multi-threaded programs due to the exponential increase in the number of thread \nschedules with execution length. Several program analysis techniques, both static [19, 10, 2, 9, 27, \n29, 21] and dynamic [12, 13, 4, 1], have been developed to de\u00adtect and predict deadlocks in multi-threaded \nprograms. Static tech\u00adniques often give no false negatives, but they often report many false positives. \nFor example, the static deadlock detector developed by Williams et al. [29] reports 100,000 deadlocks \nin Sun s JDK 1.4 1, out of which only 7 are real deadlocks. Type and annotation based techniques [5, \n10] help to avoid deadlocks during coding, but they impose the burden of annotation on programmers. Predic\u00adtive \ndynamic techniques such as Goodlock [13] and its improve\u00adments [4, 1] give both false negatives and false \npositives. For exam\u00adple, in our experiments we have found that an improved Goodlock can report as many \nas 254 false positives for our Jigsaw web server. Being imprecise in nature, most of these tools require \nmanual in\u00adspection to see if a deadlock is real or not. Nevertheless, these tech\u00adniques are effective \nin .nding deadlocks because they can predict deadlocks that could potentially happen during a real execution \nfor such a prediction, static analyses do not need to see an actual ex\u00adecution and dynamic analyses need \nto see only one multi-threaded execution. Dynamic analysis based deadlock detection can be made precise \nby taking the happens-before relation [18] into account. However, it has several problems. First, it \nreduces the predictive power of dynamic techniques it fails to report deadlocks that could happen in \na signi.cantly different thread schedule. Second, it can perturb an execution signi.cantly and can fail \nto report a deadlock that can happen when no dynamic analysis is performed. We propose a new dynamic \ntechnique for detecting real dead\u00adlocks in multi-threaded programs, called DEADLOCKFUZZER, which combines \nan imprecise dynamic deadlock detection tech\u00adnique with a randomized thread scheduler to create real \ndead\u00adlocks with high probability. The technique works in two phases. In the .rst phase, we use an informative \nand a simple variant of the Goodlock algorithm, called informative Goodlock,or sim\u00adply iGoodlock, to \ndiscover potential deadlock cycles in a multi\u00adthreaded program. For example, iGoodlock could report a \ncycle 1 They reduce the number of reports to 70 after applying various unsound heuristics  '' of the \nform (t1,l1,l2, [c1,c2])(t2,l2,l1, [c1,c2]), which says that there could be a deadlock if thread t1 tries \nto acquire lock l2 at program location c2 after acquiring lock l1 at program location c1 ' and thread \nt2 tries to acquire lock l1 at program location c2 af\u00ad ' ter acquiring lock l2 at program location c1. \nIn the second phase, DEADLOCKFUZZER executes the program with a random sched\u00adule in order to create a \nreal deadlock corresponding to a cycle reported in the previous phase. For example, consider the cycle \n'' (t1,l1,l2, [c1,c2])(t2,l2,l1, [c1,c2]) again. At each program state, the random scheduler picks a \nthread and executes its next statement with the following exception. If t1 is about to acquire lock l2 \nat lo\u00adcation c2 after acquiring lock l1 at location c1, then the random scheduler pauses the execution \nof thread t1. Similarly, the random scheduler pauses the execution of thread t2 if it is about to acquire \n'' lock l1 at location c2 after acquiring lock l2 at location c1.Inthis biased random schedule, it is \nvery likely that both the threads will reach a state where t1 is trying to acquire l2 while holding l1 \nand t2 is trying to acquire l1 while holding l2. This results in a real dead\u00adlock. In summary, DEADLOCKFUZZER \nactively controls a random\u00adized thread scheduler based on a potential deadlock cycle reported by an imprecise \ndeadlock detection technique. The above technique poses the following key challenge.Phase II assumes \nthat Phase I can provide it with precise knowledge about the thread and lock objects involved in the \ndeadlock cycle. Unfor\u00adtunately, since thread and lock objects are created dynamically at runtime, their \naddresses cannot be used to identify them across ex\u00adecutions, i.e. in the above example, addresses of \nt1,t2,l1,l2 do not remain the same between Phase I and Phase II executions. There\u00adfore, we need some \nmechanism to identify the same objects across executions. Speci.cally, we need a form of object abstraction \nsuch that if two dynamic objects in different executions are the same, they must have the same abstraction. \nFor example, the label of a statement at which an object is created can be used as its abstrac\u00adtion. \nSuch an abstraction of an object does not change across execu\u00adtions. However, an abstraction could be \nthe same for several objects (e.g. if both l1 and l2 in the above example are created by the same statement). \nIn this paper, we propose two techniques for comput\u00ading the abstraction of an object that helps us to \ndistinguish between different objects more precisely the .rst technique is motivated by the notion of \nk-object-sensitivity in static analysis [20] and the second technique is motivated by the notion of execution \nindex\u00ading [30]. We show that both these abstractions are better than the trivial abstraction where all \nobjects have the same abstraction. We also empirically show that the abstraction based on execution in\u00addexing \nis better than the abstraction based on k-object-sensitivity in most benchmarks. We have implemented \nDEADLOCKFUZZER for multi-threaded Java programs in a prototype tool. We have applied the tool to a large \nnumber of benchmarks having a total of over 600K lines of code. The results of our experiments show that \nDEAD-LOCKFUZZER can create real deadlocks with high probability and DEADLOCKFUZZER can detect all previously \nknown real dead\u00adlocks. We make the following contributions in this paper. We propose a simple and informative \nvariant of the Goodlock algorithm, called iGoodlock. Unlike existing Goodlock algo\u00adrithms [13, 4, 1], \niGoodlock does not use lock graphs or depth\u00ad.rst search, but reports the same deadlocks as the existing \nalgo\u00adrithms. Due to this modi.cation, iGoodlock uses more memory, but reduces runtime complexity. We \nalso attach context infor\u00admation with each cycle that helps in debugging and in biasing the random scheduler. \niGoodlock is iterative in nature it .nds all cycles of length k before .nding any cycle of length k +1. \nOur experiments show that all real deadlocks in our benchmarks have length two. Therefore, if we have \na limited time budget, we can run iGoodlock for one iteration so that it only reports deadlock cycles \nof length 2. Our key contribution is an active random deadlock detecting scheduler that can create real \ndeadlocks with high probability (we show this claim empirically) based on information provided by iGoodlock. \nThis phase prevents us from reporting any false positives and creates real deadlocks which are useful \nfor de\u00adbugging. This relieves the manual inspection burden associated with other imprecise techniques \nsuch as Goodlock.  We propose two kinds of object abstraction techniques that help us correlate thread \nand lock objects between iGoodlock and the randomized scheduling algorithm.  We have implemented DEADLOCKFUZZER \nin a tool for Java and have discovered subtle previously known and unknown deadlocks in large applications. \nTo the best of our knowledge, DEADLOCKFUZZER is the .rst precise dynamic deadlock anal\u00adysis tool for \nJava that has been applied to large Java applica\u00adtions.   2. Algorithm The DEADLOCKFUZZER algorithm \nconsists of two phases. In the .rst phase, we execute a multi-threaded program and .nd poten\u00adtial deadlocks \nthat could happen in some execution of the program. This phase uses a modi.ed Goodlock algorithm, called \ninformative Goodlock, or simply iGoodlock, which identi.es potential dead\u00adlocks even if the observed \nexecution does not deadlock. We call the modi.ed algorithm informative because we provide suitable debugging \ninformation to identify the cause of the deadlock this debugging information is used by the second phase \nto create real deadlocks with high probability. A limitation of iGoodlock is that it can give false positives \nbecause it does not consider the happens\u00adbefore relation between the transitions in an execution. As \na result the user is required to manually inspect such potential deadlocks. The second phase removes \nthis burden from the user. In this phase, a random thread scheduler is biased to generate an execution \nthat creates a real deadlock reported in the previous phase with high probability. We next describe these \ntwo phases in more detail. 2.1 Background De.nitions We use a general and simple model of a concurrent \nsystem to describe our dynamic deadlock checking algorithm. We consider a concurrent system to be composed \nof a .nite set of threads. Each thread executes a sequence of labeled statements. A thread communicates \nwith other threads using shared objects. At any point during program execution, a concurrent system is \nin a state. Let s0 be the initial state. A concurrent system evolves from one state to another state \nwhen a thread executes a statement. In our algorithms, we will consider the following dynamic instances \nof labeled program statements: 1. c : Acquire(l), denoting the acquire of the dynamic lock object l. \nc is the label of the statement (same for below). 2. c : Release(l), denoting the release of the dynamic \nlock object l. 3. c : Call(m), denoting a call to the method m. 4. c : Return(m), denoting the return \nfrom the method m.  ' 5. c: o =new (o,T ), where the statement occurs in the body of a method m andwhenthe \nthis argument of m evaluates to object o',then o is the dynamic object of type T allocated by the statement. \nIn several languages including Java, locks are re-entrant, i.e., a thread may re-acquire a lock it already \nholds. In our algorithm, we ignore the execution of c : Acquire(l) or c : Release(l) statements by a \nthread t,if t re-acquires the lock l or does not release the lock l, respectively2. To simplify exposition, \nwe also assume that locks are acquired and released in a nested way, i.e., if a thread acquires l2 after \nacquiring l1, then it has to release l2 before releasing l1. Our algorithm can easily be extended to \nhandle languages where locks can be acquired and released in an arbitrary order.  Next we introduce \nsome de.nitions that we will use to describe our algorithms. Enabled(s) denotes the set of threads that \nare enabled in the state s. A thread is disabled if it is waiting to acquire a lock already held by some \nother thread (or waiting on a join or a wait in Java.)  Alive(s) denotes the set of threads whose executions \nhave not terminated in the state s.A state s is ina stall state if the set of enabled threads in s (i.e. \nEnabled(s))is empty and the set of threads that are alive (i.e. Alive(s)) is non-empty.  Execute(s, \nt) returns the state after executing the next state\u00adment of the thread t in the state s.   2.2 Phase \nI: iGoodlock In this section, we present a formal description of iGoodlock. The algorithm observes the \nexecution of a multi-threaded program and computes a lock dependency relation (de.ned below) and uses \na transitive closure of this relation to compute potential deadlock cycles. The algorithm improves over \ngeneralized Goodlock algo\u00adrithms [4, 1] in two ways. First, it adds context information to a computed \npotential deadlock cycle. This information helps to iden\u00adtify the program locations where the deadlock \ncould happen and also to statically identify the lock and thread objects involved in the deadlock cycle. \nSecond, we simplify the generalized Goodlock al\u00adgorithm by avoiding the construction of a lock graph, \nwhere locks form the vertices and a labeled edge is added from one lock to another lock if a thread acquires \nthe latter lock while holding the former lock in some program state. Unlike existing Goodlock algo\u00adrithms, \niGoodlock does not perform a depth-.rst search, but com\u00adputes transitive closure of the lock dependency \nrelation. As such it uses more memory, but has better runtime complexity. We next in\u00adtroduce some formal \nde.nitions before we describe the algorithm. Given a multi-threaded execution s,let Ls be the set of \nlock objects that were held by any thread in the execution and Ts be the set of threads executed in the \nexecution. Let C be the set of all statement labels in the multi-threaded program. We next de.ne the \nlock dependency relation of a multi-threaded execution as follows. DEFINITION 1. Given an execution s,a \nlock dependency relation Ds of s is a subset of Ts \u00d7 2Ls \u00d7 Ls \u00d7C * such that (t, L, l, C) . Ds iff in \nthe execution s, in some state, thread t acquires lock l while holding the locks in the set L, and C \nis the sequence of labels of Acquire statements that were executed by t to acquire the locks in L .{l}. \nDEFINITION 2. Given a lock dependency relation D, alock de\u00adpendency chain t = ((t1,L1,l1,C1),..., (tm,Lm,lm,Cm)) \nis a sequence in D * such that the following properties hold. 1. for all distinct i, j . [1,m], ti = \ntj , i.e. the threads t1,t2,...,tm are all distinct objects, 2 This is implemented by associating a usage \ncounter with a lock which is incremented whenever a thread acquires or re-acquires the lock and decre\u00admented \nwhenever a thread releases the lock. Execution of Acquire(l) by t is considered whenever the thread t \nacquires or re-acquires the lock l and the usage counter associated with l is incremented from 0 to 1. \n2. for all distinct i, j . [1,m], li lj , i.e. the lock objects = l1,l2,...,lm are distinct, 3. for all \ni . [1,m - 1], li . Li+1, i.e. each thread could potentially wait to acquire a lock that is held by the \nnext thread, 4. for all distinct i, j . [1,m], Li n Lj = \u00d8, i.e., each thread ti should be able to acquire \nthe locks in Li without waiting.  DEFINITION 3. A lock dependency chain t = ((t1,L1,l1,C1),..., (tm,Lm,lm,Cm)) \nis a potential deadlock cycle if lm . L1. Note that the de.nition of a potential deadlock cycle never \nuses any of the Ci s in Ds to compute a potential deadlock cycle. Each Ci of a potential deadlock cycle \nprovides us with information about program locations where the locks involved in the cycle were acquired. \nThis is useful for debugging and is also used by the active random deadlock checker to determine the \nprogram locations where it needs to pause a thread. Each lock and thread object involved in a potential \ndeadlock cy\u00adcle is identi.ed by its unique id, which is typically the address of the object. The unique \nid of an object, being based on dynamic in\u00adformation, can change from execution to execution. Therefore, \nthe unique id of an object cannot be used by the active random checker to identify a thread or a lock \nobject across executions. In order to overcome this limitation, we compute an abstraction of each object. \nAn abstraction of an object identi.es an object by static program in\u00adformation. For example, the label \nof a statement at which an object is created could be used as its abstraction. We describe two bet\u00adter \n(i.e. more precise) object abstraction computation techniques in Section 2.4. In this section, we assume \nthat abs(o) returns some abstraction of the object o. Given a potential deadlock cycle ((t1,L1,l1,C1), \n..., (tm,Lm,lm,Cm)), iGoodlock reports the abstract deadlock cycle ((abs(t1), abs(l1),C1), ..., (abs(tm), \nabs(lm),Cm)).The active random checker takes such an abstract deadlock cycle and biases a random scheduler \nso that a real deadlock corresponding to the cycle gets created with high probability. We next describe \niGoodlock. Speci.cally, we describe how we compute the lock dependency relation during a multi-threaded \nexecution and how we compute all potential deadlock cycles given a lock dependency relation. 2.2.1 Computing \nthe lock dependency relation of a multi-threaded execution In order to compute the lock dependency relation \nduring a multi\u00adthreaded execution, we instrument the program to maintain the following three data structures: \n LockSet that maps each thread to a stack of locks held by the thread  Context that maps each thread \nto a stack of the labels of statements where the thread acquired the currently held locks  D is the \nlock dependence relation  We update the above three data structures during a multi-threaded execution \nas follows: Initialization:  for all t, both LockSet[t] and Context[t] map toanempty stack  D is \nan empty set   If thread t executes the statement c: Acquire(l)  push c to Context[t]  add (t,LockSet[t],l, \nContext[t]) to D  push l to LockSet[t]   If thread t executes the statement c: Release(l)    pop \nfrom Context[t]  pop from LockSet[t]  At the end of the execution, we output D as the lock dependency \nrelation of the execution.  2.2.2 Computing potential deadlock cycles iteratively Let Dk denote the \nset of all lock dependency chains of D that has length k. Therefore, D1 = D. iGoodlock computes potential \ndead\u00adlock cycles by iteratively computing D2,D3,D4 ,... and .nding deadlock cycles in those sets. The \niterative algorithm for comput\u00ading potential deadlock cycles is described in Algorithm 1.  Algorithm \n1 iGoodlock(D) 1: INPUTS: lock dependency relation D 2: i . 1 3: Di . D 4: while Di = \u00d8 do 5: for each \n(t, L, l, C) . D and each t in Di do 6: if t, (t, L, l, C) is a dependency chain by De.nition 2 then \n7: if t, (t, L, l, C) is a potential deadlock cycle by De.nition 3 then 8: report abs(t, (t, L, l, C)) \nas a potential deadlock cycle 9: else 10: add t, (t, L, l, C) to Di+1 11: end if 12: end if 13: end for \n14: i . i +1 15: end while Note that in iGoodlock(D) we do not add a lock dependency chain to Di+1 if \nit is a deadlock cycle. This ensures that we do not report complex deadlock cycles, i.e. deadlock cycles \nthat can be decomposed into simpler cycles.  2.2.3 Avoiding duplicate deadlock cycles In Algorithm 1, \na deadlock cycle of length k gets reported k times. For example, if ((t1,L1,l1,C1), (t2,L2,l2,C2),..., \n(tm,Lm,lm,Cm)) is reported as a deadlock cycle, then ((t2,L2,l2,C2),..., (tm,Lm,lm,Cm), (t1,L1,l1,C1))is \nalso reported as a cycle. In order to avoid such duplicates, we put another constraint in De.nition 2: \nthe unique id of thread t1 must be less than the unique id of threads t2,...,tm.  2.3 Phase II: The \nActive Random Deadlock Checking Algorithm DEADLOCKFUZZER executes a multi-threaded program using a random \nscheduler. A simple randomized execution algorithm is shown in Algorithm 2. Starting from the initial \nstate s0,this al\u00adgorithm, at every state, randomly picks an enabled thread and exe\u00adcutes its next statement. \nThe algorithm terminates when the system reaches a state that has no enabled threads. At termination, \nif there is at least one thread that is alive, the algorithm reports a system stall. A stall could happen \ndue to a resource deadlock (i.e. dead\u00adlocks that happen due to locks) or a communication deadlock (i.e. \na deadlock that happens when each thread is waiting for a signal from some other thread in the set). \nWe only consider resource deadlocks in this paper. A key limitation of this simple random scheduling \nalgorithm is that it may not create real deadlocks very often. DEADLOCK-FUZZER biases the random scheduler \nso that potential deadlock cycles reported by iGoodlock get created with high probability. The active \nrandom deadlock checking algorithm is shown in Al\u00adgorithm 3. Speci.cally, the algorithm takes an initial \nstate s0 and Algorithm 2 simpleRandomChecker(s0 ) 1: INPUTS: the initial state s0 2: s . s0 3: while \nEnabled(s) = \u00d8 do 4: t . a random thread in Enabled(s) 5: s . Execute(s, t) 6: end while 7: if Alive(s) \n = \u00d8 then 8: print System Stall! 9: end if a potential deadlock cycle Cycle as inputs. It then executes \nthe multi-threaded program using the simple random scheduler, except that it performs some extra work \nwhen it encounters a lock acquire or lock release statement. If a thread t is about to acquire a lock \nl in the context C,thenif (abs(t), abs(l),C) is present in Cycle,the scheduler pauses thread t before \nt acquires lock l, giving a chance to another thread, which is involved in the potential deadlock cycle, \nto acquire lock l subsequently. This ensures that the system creates the potential deadlock cycle Cycle \nwith high probability. Algorithm 3 DEADLOCKFUZZER(s0 ,Cycle) 1: INPUTS: the initial state s0, a potential \ndeadlock cycle Cycle 2: s . s0 3: Paused .\u00d8 4: LockSet and Context map each thread to an empty stack \n5: while Enabled(s) \u00d8 do = 6: t . a random thread in Enabled(s)\\ Paused 7: Stmt . next statement to be \nexecuted by t 8: if Stmt = c: Acquire(l) then 9: push l to LockSet[t] 10: push c to Context[t] 11: checkRealDeadlock(LockSet) \n// see Algorithm 4 12: if (( abs(t), abs(l), Context[t]) ./Cycle) then 13: s . Execute(s,t) 14: else \n15: pop from LockSet[t] 16: pop from Context[t] 17: add t to Paused 18: end if 19: else if Stmt = c: \nRelease(l) then 20: pop from LockSet[t] 21: pop from Context[t] 22: s . Execute(s,t) 23: else 24: s . \nExecute(s,t) 25: end if 26: if |Paused| = |Enabled(s)| then 27: remove a random thread from Paused 28: \nend if 29: end while 30: if Active(s)  = \u00d8 then 31: print System Stall! 32: end if Algorithm 4 checkRealDeadlock(LockSet) \n1: INPUTS: LockSet mapping each thread to its current stack of locks 2: if there exist distinct t1,t2,...,tm \nand l1,l2,...,lm such that lm appears before l1 in LockSet[tm] and for each i . [1,m - 1], li appears \nbefore li+1 in LockSet[ti] then 3: print Real Deadlock Found! 4: end if Algorithm 3 maintains three data \nstructures: LockSet that maps each thread to a stack of locks that are currently held by the thread, \nContext that maps each thread to a stack of state\u00adment labels where the thread has acquired the currently \nheld locks, and Paused which is a set of threads that has been paused by DEADLOCKFUZZER. Paused is initialized \nto an empty set, and LockSet and Context are initialized to map each thread to an empty stack.  DEADLOCKFUZZER \nruns in a loop until there is no enabled thread. At termination, DEADLOCKFUZZER reports a system stall \nif there is at least one active thread in the execution. Note that DEADLOCKFUZZER onlycatchesresource \ndeadlocks. Ineach iter\u00adationoftheloop, DEADLOCKFUZZER picksarandomthread t that is enabled but not in \nthe Paused set. If the next statement to be ex\u00adecuted by t is not a lock acquire or release, t executes \nthe statement and updates the state as in the simple random scheduling algorithm (see Algorithm 2). If \nthe next statement to be executed by t is c : Acquire(l), c and l are pushed to Context[t] and LockSet[t], \nrespectively. DEADLOCKFUZZER then checks if the acquire of l by t could lead to a deadlock using checkRealDeadlock \nin Algorithm 4. checkRealDeadlock goes over the current lock set of each thread and sees if it can .nd \na cycle. If a cycle is discov\u00adered, then DEADLOCKFUZZER has created a real deadlock. If there is no cycle, \nthen DEADLOCKFUZZER determines if t needs to be paused in order to get into a deadlock state. Speci.cally, \nit checks if (abs(t), abs(l), Context[t]) is present in Cycle.If t is added to Paused, then we pop from \nboth LockSet[t] and Context[t] to re.ect the fact that t has not really acquired the lock l.Ifthe next \nstatement to be executed by t is c : Release(l), then we pop from both LockSet[t] and Context[t]. At \nthe end of each iteration, it may happen that the set Paused is equal to the set of all enabled threads. \nThis results in a state where DEADLOCKFUZZER has unfortunately paused all the en\u00adabled threads and the \nsystem cannot make any progress. We call this thrashing. DEADLOCKFUZZER handles this situation by re\u00admoving \na random thread from the set Paused. A thrash implies that DEADLOCKFUZZER has paused a thread inan unsuitable \nstate. DEADLOCKFUZZER should avoid thrashing as much as possible in order to guarantee better performance \nand improve the probability of detecting real deadlocks.  2.4 Computing object abstractions A key requirement \nof DEADLOCKFUZZER is that it should know where a thread needs to be paused, i.e. it needs to know if \na thread t that is trying to acquire a lock l in a context C could lead to a dead\u00adlock. DEADLOCKFUZZER \ngets this information from iGoodlock, but this requires us to identify the lock and thread objects that \nare the same in the iGoodlock and DEADLOCKFUZZER executions. This kind of correlation cannot be done \nusing the address (i.e. the unique id) of an object because object addresses change across ex\u00adecutions. \nTherefore, we propose to use object abstraction if two objects are same across executions, then they \nhave the same ab\u00adstraction. We assume abs(o) computes the abstraction of an ob\u00adject. There could be several \nways to compute the abstraction of an object. One could use the label of the statement that allocated \nthe object (i.e. the allocation site) as its abstraction. However, that would be too coarse-grained to \ndistinctly identify many objects. For example, if one uses the factory pattern to allocate all thread \nob\u00adjects, then all of the threads will have the same abstraction. There\u00adfore, we need more contextual \ninformation about an allocation site to identify objects at .ner granularity. Note that if we use a coarse-grained \nabstraction, then DEAD-LOCKFUZZER will pause unnecessary threads before they try to acquire some unnecessary \nlocks. This is because all these unnec\u00adessary threads and unnecessary locks might have the same abstrac\u00adtion \nas the relevant thread and lock, respectively. This will in turn reduce the effectiveness of our algorithm \nas DEADLOCKFUZZER will more often remove a thread from the Paused set due to the unavailability of any \nenabled thread. Note that we call this situa\u00adtion thrashing. Our experiments (see Section 5) show that \nif we use the trivial abstraction, where all objects have the same abstraction, then we get a lot of \nthrashing. This in turn reduces the probability of creating a real deadlock. On the other hand, if we \nconsider too .ne-grained abstraction for objects, then we will not be able to tol\u00aderate minor differences \nbetween two executions, causing threads to pause at fewer locations and miss deadlocks. We next describe \ntwo abstraction techniques for objects that we have found effective in our experiments. 2.4.1 Abstraction \nbased on k-object-sensitivity Given a multi-threaded execution and a k> 0,let o1,...ok be the sequence \nof objects such that for all i . [1,k-1], oi is allocated by some method of object oi+1.We de.ne absOk \n(o1) as the sequence (c1,...,ck) where ci is the label of the statement that allocated oi. absOk (o1) \ncan then be used as an abstraction of o1. We call this abstraction based on k-object-sensitivity because \nof the similarity to k-object-sensitive static analysis [20]. In order to compute absOk (o) for each \nobject o during a multi\u00adthreaded execution, we instrument the program to maintain a map CreationMap that \nmaps each object o to a pair (o ' ,c) if o is created by a method of object o ' at the statement labeled \nc. This gives the following straightforward runtime algorithm for computing CreationMap. If a thread \nt executes the statement c : o = new (o ' ,T ),then add o . (o ' ,c) to CreationMap. One can use CreationMap \nto compute absOk (o) using the fol\u00ad lowing recursive de.nition: absOk (o)= () if k =0 or CreationMap[o]= \n. absOk+1(o)= c :: abskO(o ' ) if CreationMap[o]=(o ' ,c) When an object is allocated inside a static \nmethod, it will not have a mapping in CreationMap. Consequently, absOk (o) may have fewer than k elements. \n 2.4.2 Abstraction based on light-weight execution indexing Given a multi-threaded execution, a k> 0, \nand an object o, let mn,mn-1,...,m1 be the call stack when o is created, i.e. o is created inside method \nm1 and for all i . [1,n - 1], mi is called from method mi+1. Let us also assume that ci+1 is the label \nof the statement at which mi+1 invokes mi and qi+1 is the number of times mi is invoked by mi+1 in the \ncontext mn,mn-1,...,mi+1.Then absIk(o) is de.ned as the sequence [c1,q1,c2,q2,...,ck,qk],where c1 is \nthe label of the statement at which o is created and q1 is the number of times the statement is executed \nin the context mn,mn-1,...,m1. 1 main() { 2 for ( int i=0; i<5; i++) 3 foo(); 4} 5 void foo() { 6 bar(); \n7 bar(); 8} 9 void bar() { 10 for ( int i=0; i<3; i++) 11 Object l= new Object(); 12 } For example \nin the above code, if o is the .rst object cre\u00adated by the execution of main,then absI 3(o) is the sequence \n[11, 1, 6, 1, 3, 1]. Similarly, if o is the last object created by the ex\u00adecution of main,then absI 3(o) \nis the sequence [11, 3, 7, 1, 3, 5]. The idea of computing this kind of abstraction is similar to the \nidea of execution indexing proposed in [30], except that we ignore branch statements and loops. This \nmakes our indexing light-weight, but less precise.  In order to compute absIk(o) for each object o during \na multi\u00adthreaded execution, we instrument the program to maintain a thread-local scalar d to track its \ndepths and two thread-local maps CallStack and Counters.We use CallStackt to denote the CallStack map \nof thread t. The above data structures are up\u00addated at runtime as follows. Initialization:  for all \nt, dt . 0  for all t and c, Counterst[dt][c] . 0   If a thread t executes the statement c: Call(m) \n Counterst[dt][c] . Counterst[dt][c]+1  push c to CallStackt  push Counterst[dt][c] to CallStackt \n  dt . dt +1  for all c, Counterst[dt][c] . 0   If a thread t executes the statement c: Return(m) \n  dt . dt - 1  pop twice from CallStackt   If a thread t executes the statement c: o =new(o ' ,T \n)  Counterst[dt][c] . Counterst[dt][c]+1  push c to CallStackt  push Counterst[dt][c] to CallStackt \n  absI (o) is the top 2k elements of CallStackt  k pop twice from CallStackt Note that absIk(o) has \n2k elements, but if the call stack has fewer elements, then absIk(o) returns the full call stack.  \n 3. Examples Illustrating DEADLOCKFUZZER Consider the multi-threaded Java program in Figure 1. The program \nde.nes a MyThread class that has two locks l1 and l2 and a boolean flag.The run method of MyThread invokes \na number of long running methods f1, f2, f3, f4 if flag is true and then it acquires locks l1 and l2 \nin order. The body of run shows a common pattern, where a thread runs several statements and then acquires \nseveral locks in a nested way. The main method creates two lock objects o1 and o2. It also creates two \nthreads (i.e. instances of MyThread). In the .rst instance l1 and l2 are set to o1 and o2, respectively, \nand flag is set to true. Therefore, a call to start on this instance will create a new thread which will \n.rst execute several long running methods and then acquire o1 and o2 in order. A call to start on the \nsecond instance of MyThread will create a new thread which will acquire o2 and o1 in order. We have commented \nout lines 24 and 27, because they are not relevant for the current example we will uncomment them in \nthe next example. The example has a deadlock because the locks o1 and o2 are acquired in different orders \nby the two threads. However, this dead\u00adlock will rarely occur during normal testing because the second \nthread will acquire o2 and o1 immediately after start, whereas the .rst thread will acquire o1 and o2 \nafter executing the four long running methods. iGoodlock will report this deadlock as a poten\u00adtial one \nby observing a single execution that does not deadlock. If we use the abstraction in Section 2.4.2 with, \nsay k =10, the report will be as follows: ([25, 1], [23, 1], [15, 16]), ([26, 1], [22, 1], [15, 16]) \n 1 class MyThread extends Thread { 2 Object l1, l2; 3 boolean flag; 4 MyThread( Object l1, Object l2, \nboolean b){ 5 this .l1 = l1; this .l2 = l2; this .flag = b; 6} 7 8 public void run() { 9 if (flag) { \n// some long running methods 10 f1(); 11 f2(); 12 f3(); 13 f4(); 14 } 15 synchronized (l1) { 16 synchronized \n(l2) { 17 } 18 } 19 } 20 21 public static void main (String[] args) { 22 Object o1 = new Object(); 23 \nObject o2 = new Object(); 24 // Object o3 = new Object(); 25 (new MyThread(o1,o2, true )).start(); 26 \n(new MyThread(o2,o1, false )).start(); 27 // (new MyThread(o2,o3,false)).start(); 28 } 29 } Figure 1. \nSimple Example of a Deadlock where [25, 1], [26, 1], [22, 1], [23, 1] are the abstractions of the .rst \nthread, the second thread, o1,and o2, respectively. [15, 16] denotes the context in which the second \nlock is acquired by each thread. The active random deadlock checker will take this report and create \nthe real deadlock with probability 1. Speci.cally, it will pause both the threads before they try to \nacquire a lock at line 16. The above example shows that DEADLOCKFUZZER can create a rare deadlock with \nhigh probability. In practice, the actual prob\u00adability may not be 1 DEADLOCKFUZZER can miss a deadlock \nbecause the execution could simply take a different path due to non\u00addeterminism and that path may not \nexhibit a deadlock. However, in our experiments we have found that the probability of creating a deadlock \nis high on our benchmarks. The above example does not show the utility of using thread and object abstractions. \nTo illustrate the utility of object and thread abstractions, we uncomment the lines at 24 and 27. Now \nwe create a third lock o3 and a third thread which acquires o2 and o3 in order. iGoodlock as before will \nreport the same deadlock cycle as in the previous example. In DEADLOCKFUZZER,if we do not use thread \nand object abstractions, then with probability 0.5 (approx), the third thread will pause before acquiring \nthe lock at line 16. This is because, without any knowledge about threads and objects involved in a potential \ndeadlock cycle, DEADLOCKFUZZER will pause any thread that reaches line 16. Therefore, if the third thread \npauses before line 16, then the second thread will not be able to acquire lock o2 at line15 and it will \nbe blocked. DEADLOCKFUZZER will eventually pause the .rst thread at line 16. At this point two threads \nare paused and one thread is blocked. This results in a thrashing (see Section 2.3). To get rid of this \nstall, DEADLOCKFUZZER will un-pause the .rst thread with probability 0.5 and we will miss the deadlock \nwith probability 0.25 (approx). On the other hand, if we use object and thread abstractions, then DEADLOCKFUZZER \nwill never pause the third thread at line 16 and it will create the real deadlock with probability 1. \nThis illustrates that if we do not use thread and object abstractions, then we get more thrashings and \nthe probability of creating a real deadlock gets reduced.  4. Optimization: avoiding another potential \ncause for thrashing We showed that using object and thread abstractions helps reduce thrashing; this \nin turn helps increase the probability of creating a deadlock. We show another key reason for a lot of \nthrashings using the following example and propose a solution to partly avoid such thrashings. 1: thread1{ \n8: thread2{ 2: synchronized(l1){ 9: synchronized(l1){ 3: synchronized(l2){ 10: 4: } 11: } 5: } 12: synchronized(l2){ \n6: } 13: synchronized(l1){ 14: } 15: } 16: } The above code avoids explicit thread creation for simplicity \nof exposition. iGoodlock will report a potential deadlock cycle in this code. In the active random deadlock \nchecking phase, if thread1 is paused .rst (at line 3) and if thread2 has just started, then thread2 will \nget blocked at line 9 because thread1 is holding the lock l1 and it has been paused and thread2 cannot \nacquire the lock. Since we have one paused and one blocked thread, we get a thrashing. DEADLOCKFUZZER \nwill un-pause thread1 and we will miss the real deadlock. This is a common form of thrashing that we \nhave observed in our benchmarks. In order to reduce the above pattern of thrashing, we make a thread \nto yield to other threads before it starts entering a deadlock cycle. Formally, if (abs(t), abs(l),C) \nis a component of a poten\u00adtialdeadlockcycle,then DEADLOCKFUZZER willmakeanythread t ' with abs(t)= abs(t \n' ) yield before a statement labeled c where c is the bottommost element in the stack C. For example, \nin the above code, DEADLOCKFUZZER will make thread1 yield be\u00adfore it tries to acquire lock l1 at line \n2. This will enable thread2 to make progress (i.e. acquire and release l1 at lines 9 and 11, re\u00adspectively). \nthread2 will then yield to any other thread before acquiring lock l2 at line 12. Therefore, the real \ndeadlock will get created with probability 1.  5. Implementation and Evaluation DEADLOCKFUZZER can be \nimplemented for any language that supports threads and shared memory programming, such as Java or C/C++ \nwith pthreads. We have implemented DEADLOCKFUZZER for Java by instrumenting Java bytecode to observe \nvarious events and to control the thread scheduler. The implementation is a part of the CALFUZZER framework[16]. \nDEADLOCKFUZZER cangointo livelocks. Livelocks happen when all threads of the program end up in the Paused \nset, except for one thread that does something in a loop without synchronizing with other threads. In \norder to avoid livelocks, DEADLOCKFUZZER creates a monitor thread that periodically removes those threads \nfrom the Paused set that are paused for a long time. 5.1 Experimental setup We evaluated DEADLOCKFUZZER \non a variety of Java programs and libraries. We ran our experiments on a dual socket Intel Xeon 2GHz \nquad core server with 8GB of RAM. The following programs were included in our benchmarks: cache4j, a \nfast thread-safe im\u00adplementation of a cache for Java objects; sor, a successive over\u00adrelaxation benchmark, \nand hedc, a web-crawler application, both from ETH [28]; jspider, a highly con.gurable and customizable \nWeb Spider engine; and Jigsaw, W3C s leading-edge Web server platform. We created a test harness for \nJigsaw that concurrently generates simultaneous requests to the web server, simulating mul\u00adtiple clients, \nand administrative commands (such as shutdown server ) to exercise the multi-threaded server in a highly \nconcur\u00adrent situation. The libraries we experimented on include synchronized lists and maps from the \nJava Collections Framework, Java logging fa\u00adcilities (java.util.logging), and the Swing GUI framework \n(javax.swing). Another widely used library included in our benchmarks is the Database Connection Pool \n(DBCP) component of the Apache Commons project. Each of these libraries contains potential deadlocks \nthat we were able to reproduce using DEAD-LOCKFUZZER. We created general test harnesses to use these \nli\u00adbraries with multiple threads. For example, to test the Java Collec\u00adtions in a concurrent setting, \nwe used the synchronized wrappers in java.util.Collections.  5.2 Results Table 1 shows the results of \nour analysis. The second column reports the number of lines of source code that was instrumented. If \nthe program uses libraries that are also instrumented, they are included in the count. The third column \nshows the average runtime of a normal execution of the program without any instrumentation or analysis. \nThe fourth column is the runtime of iGoodlock (Phase I). The .fth column is the average runtime of DEADLOCKFUZZER \n(Phase II). The table shows that the overhead of our active checker is within a factor of six, even for \nlarge programs. Note that runtime for the web server Jigsaw is not reported due to its interactive nature. \nThe sixth column is the number of potential deadlocks reported by iGoodlock. The seventh column is the \nnumber of cycles that correspond to real deadlocks after manual inspection. For Jigsaw, since DEADLOCKFUZZER \ncould reproduce 29 deadlocks, we can say for sure that Jigsaw has 29 or more real deadlocks. With the \nexception of Jigsaw, iGoodlock was precise enough to report only real deadlocks. The eighth column is \nthe number of deadlock cycles con.rmedby DEADLOCKFUZZER.Theninthcolumnistheempir\u00adical probability of \nDEADLOCKFUZZER reproducing the deadlock cycle. We ran DEADLOCKFUZZER 100 times for each cycle and calculated \nthe fraction of executions that deadlocked using DEAD-LOCKFUZZER. Our experiments show that DEADLOCKFUZZER \nreproduces the potential deadlock cycles reported by iGoodlock with very high probability. We observed \nthat for some Collections benchmarks, DEADLOCKFUZZER reportedalowprobabilityof0.5 for creating a deadlock. \nAfter looking into the report, we found thatinthe executions where DEADLOCKFUZZER reportednodead\u00adlock, \nDEADLOCKFUZZER created a deadlock which was different from the potential deadlock cycle provided as input \nto DEADLOCK-FUZZER. For comparison, we also ran each of the programs nor\u00admally without instrumentation \nfor 100 times to observe if these deadlocks could occur under normal testing. None of the runs re\u00adsulted \nin a deadlock, as opposed to a run with DEADLOCKFUZZER which almost always went into deadlock. Column \n10 shows the av\u00aderage number of thrashings per run. Columns 9 and 10 show that the probability of creating \na deadlock decreases as the number of thrashings increases. We conducted additional experiments to evaluate \nthe effective\u00adness ofvarious design decisions for DEADLOCKFUZZER.Wetried variants of DEADLOCKFUZZER: \n1) with abstraction based on k\u00adobject-sensitivity, 2) with abstraction based on light-weight exe\u00adcution \nindexing, 3) with the trivial abstraction, 4) without context information, and 5) with the optimization \nin Section 4 turned off. Figure 2 summarizes the results of our experiments. Note that the  Program \nname Lines of Avg. Runtime in msec. # Deadlock cycles Probability of Avg. # of code Normal iGoodlock \nDF iGoodlock Real Reproduced reproduction Thrashes cache4j 3,897 2,045 3,409 -0 0 --\u00adsor 17,718 163 396-0 \n0 --\u00adhedc 25,024 165 1,668 -0 0 --\u00adjspider 10,252 4,622 5,020 -0 0 ---Jigsaw 160,388 ---283 = 29 29 0.214 \n18.97 Java Logging 4,248 166 272 493 3 3 3 1.00 0.00 Java Swing 337,291 4,694 9,563 28,052 1 1 1 1.00 \n4.83 DBCP 27,194 603 1,393 1,393 2 2 2 1.00 0.00 Synchronized Lists (ArrayList, Stack, 17,633 2,862 3,244 \n7,070 9+9+9 9+9 + 9 9+9+9 0.99 0.0 LinkedList) Synchronized Maps (HashMap, TreeMap, WeakHashMap, 18,911 \n2,295 2,596 2898 4+4+4 4+4 + 4 4+4+4 0.52 0.04 LinkedHashMap, +4+4 +4+4 +4+4 IdentityHashMap) Table 1. \nExperimental results. (Context + 2nd Abstraction + Yield optimization) Runtime (Normalized to uninstrumented \nrun) Probability of reproducing deadlock 100 1 Context + 1st Abstraction Context + 2nd Abstraction Ignore \nAbstraction 50 Ignore Context 0.8 No Yields 0.6 15 0.4 10 0.2 5 0 0Collections Logging DBCP Swing \nCollections Logging DBCP Swing Avg. thrashing per runCorrelation between thrashing and probability. 600 \n1 Probability 500 10 8 6 4 Probability of reproducing deadlock 0.8 0.6 0.4 0.2 2 0 0 0 2 4 6 8 10 12 \n14 16 18 20 Collections Logging DBCP Swing # of thrashings Figure 2. Performance and effectiveness of \nvariations of DEADLOCKFUZZER results in Table 1 correspond to the variant 2, where we use the graph shows \nthe probability of creating a deadlock by the vari\u00adlight-weight execution indexing abstraction, context \ninformation, ants of DEADLOCKFUZZER. The third graph shows the average and the optimization in Section \n4. We found this variant to be the number of thrashings encountered by each variant of DEADLOCK\u00adbest \nperformer: it created deadlocks with higher probability than FUZZER.Thefourthgraphshowsthecorrelationbetweenthenum\u00adany \nother variant and it ran ef.ciently with minimal number of ber of thrashings and the probability of creating \na deadlock. thrashings. The .rst graph shows that variant 2, which uses execution index- The .rst graph \nshows the correlation between the various vari-ing, performs better than variant 1, which uses k-object-sensitivity. \nants of DEADLOCKFUZZER and average runtime. The second The second graph shows that the probability of \ncreating a dead\u00adlock is maximum for variant 2 on our benchmarks. The difference is signi.cant for the \nLogging and DBCP benchmarks. Ignoring ab\u00adstraction entirely (i.e. variant 3) led to a lot of thrashing \nin Col\u00adlections and decreased the probability of creating a deadlock. The third graph on the Swing benchmark \nshows that variant 2 has mini\u00admum thrashing. Ignoring context information increased the thrash\u00ading and \nthe runtime overhead for the Swing benchmark. In the Swing benchmark, the same locks are acquired and \nreleased many times at many different program locations during the execution. Hence, ignoring the context \nof lock acquires and releases leads to a huge amount of thrashing. The .rst graph which plots average \nruntime for each variant shows some anomaly. It shows that variant 3 runs faster than variant 2 for Collections \nthis should not be true given that variant 3 thrashes more than variant 2. We found the following reason \nfor this anomaly. Without the right debugging information provided by iGoodlock, it is possible for DEADLOCKFUZZER \nto pause at wrong locations but, by chance, introduce a real deadlock which is unrelated to the deadlock \ncycle it was trying to reproduce. This causes the anomaly in the .rst graph where the runtime overhead \nfor Collections is lower when abstraction is ignored, but the number of thrashings is more. The runtime \nis measured as the time it takes from the start of the execution to either normal termination or when \na deadlock is found. DEADLOCKFUZZER with our light\u00adweight execution indexing abstraction faithfully reproduces \nthe given cycle, which may happen late in the execution. For more imprecise variants such as the one \nignoring abstraction, a deadlock early in the execution may be reproduced wrongfully, thus reducing the \nruntime. The fourth graph shows that the probability of creating a dead\u00adlock goes down as the number \nof thrashings increases. This val\u00adidates our claim that thrashings are not good for creating dead\u00adlocks \nwith high probability and our variant 2 tries to reduce such thrashings signi.cantly by considering context \ninformation and ob\u00adject abstraction based on execution indexing, and by applying the optimization in \nSection 4.  5.3 Deadlocks found DEADLOCKFUZZER found a number of previously unknown and known deadlocks \nin our benchmarks. We next describe some of them. Two previously unknown deadlocks were found in Jigsaw. \nAs shown in Figure 3, when the http server shuts down, it calls cleanup code that shuts down the SocketClientFactory. \nThe shut\u00addown code holds a lock on the factory at line 867, and in turn at\u00adtempts to acquire the lock \non csList at line 872. On the other hand, when a SocketClient is closing, it also calls into the fac\u00adtory \nto update a global count. In this situation, the locks are held in the opposite order: the lock on csList \nis acquired .rst at line 623, and then on the factory at line 574. Another similar deadlock oc\u00adcurs when \na SocketClient kills an idle connection. These also involve the same locks, but are acquired at different \nprogram loca\u00adtions. iGoodlock provided precise debugging information to distin\u00adguish between the two \ncontexts of the lock acquires. The deadlock in the Java Swing benchmark occurs when a program synchronizes \non a JFrame object, and invokes the setCaretPosition() method on a JTextArea ob\u00adject that is a member \nof the JFrame object. The sequence of lock acquires that leads to the deadlock is as follows. The main \nthread obtains a lock on the JFrame object, and an EventQueue thread which is also running, obtains a \nlock on a BasicTextUI$BasicCaret object at line number 1304 in javax/swing/text/DefaultCaret.java.The \nmain thread then tries to obtain a lock on the BasicTextUI$BasicCaret object at line number 1244 in javax/swing/text/DefaultCaret.java, \norg.w3c.jigsaw.http.httpd { 384: SocketClientFactory factory; 1442: void cleanup(...) { 1455: factory.shutdown();} \n1711: void run() { 1734: cleanup(...);}} org.w3c.jigsaw.http.socket.SocketClient { 42: SocketClientFactory \npool; 111: void run() { 152: pool.clientConnectionFinished(...);}} org.w3c.jigsaw.http.socket.SocketClientFactory \n{ 130: SocketClientState csList; 574: synchronized boolean decrIdleCount() {...} 618: boolean clientConnectionFinished(...) \n{ 623: synchronized (csList) { 626: decrIdleCount();}} 867: synchronized void killClients(...) { 872: \nsynchronized (csList) {...}} 902: void shutdown() { 904: killClients(...);} } Figure 3. Deadlock in \nJigsaw but fails to do so since the lock has not been released by the EventQueue thread. The EventQueue \nthread tries to ac\u00adquire the lock on the JFrame object at line number 407 in javax/swing/RepaintManager.java \nbut cannot since it is still held by the main thread. The program goes into a dead\u00adlock. This deadlock \ncorresponds to a bug that has been reported at http://bugs.sun.com/view bug.do?bug id=4839713. One of \nthe deadlocks that we found in the DBCP benchmark occurs when a thread tries to create a PreparedStatement, \nand another thread simultaneously closes another PreparedStatement. The sequence of lock acquires that \nexhibits this deadlock is as follows. The .rst thread obtains a lock on a Connection object at line number \n185 in org/apache/commons/dbcp/DelegatingConnection.java.The second thread obtains a lock on a KeyedObjectPool \nobject at line number 78 in org/apache/commons/dbcp/PoolablePrepared\u00adStatement.java. The .rst thread \nthen tries to obtain a lock on the same KeyedObjectPool object at line number 87 in org/a\u00adpache/commons/dbcp/PoolingConnection.java, \nbut cannot obtain it since it is held by the second thread. The second thread tries to obtain a lock \non the Connection object at line number 106 in org/apache/commons/dbcp/PoolablePreparedStatement.java,but \ncannot acquire it since the lock has not yet been released by the .rst thread. The program, thus, goes \ninto a deadlock. The deadlocks in the Java Collections Framework happen when multiple threads are operating \non shared collection objects wrapped with the synchronizedX classes. For example, in the synchronizedList \nclasses, the deadlock can happen if one thread executes l1.addAll(l2) concurrently with another thread \nexecuting l2.retainAll(l1). There are three meth\u00adods, addAll(), removeAll(),and retainAll() that ob\u00adtain \nlocks on both l1 and l2 for a total of 9 combinations of deadlock cycles. The synchronizedMap classes \nhave 4 com\u00adbinations with the methods equals() and get(). The test cases for Java Collections are arti.cial \nin the sense that the deadlocks in those benchmarks arise due to inappropriate use of the API methods. \nWe used these benchmarks because they have been used by researchers in previous work (e.g. Williams et \nal. [29] and Jula et al. [17]), and we wanted to validate our tool against these benchmarks.   5.4 \nImprecision in Goodlock Since DEADLOCKFUZZER is not complete, if it does not classify a deadlock reported \nby iGoodlock as a real deadlock, we cannot de.nitely say that the deadlock is a false warning. For example, \nin the Jigsaw benchmark, the informative Goodlock algorithm re\u00adported 283 deadlocks. Of these 29 were \nreported as real deadlocks by DEADLOCKFUZZER. We manually looked into the rest of the deadlocks to see \nif they were false warnings by iGoodlock, or real deadlocks that were not caught by DEADLOCKFUZZER. For \n18 of the cycles reported, we can say with a high con.dence that they are false warnings reported by \nthe iGoodlock algorithm. These cycles involve locks that are acquired at the same program state\u00adments, \nbut by different threads. There is a single reason why all of these deadlocks are false positives. The \ndeadlocks can occur only if a CachedThread invokes its waitForRunner() method before that CachedThread \nhas been started by another thread. This is clearly not possible in an actual execution of Jigsaw. Since \niGoodlock does not take the happens-before relation between lock acquires and releases into account, \nit reports these spurious dead\u00adlocks. For the rest of the cycles reported by iGoodlock, we cannot say \nwith reasonable con.dence if they are false warnings, or if they are real deadlocks that were missed \nby DEADLOCKFUZZER.  6. Related Work We have already compared our proposed technique with several existing \ntechniques for detecting deadlocks in multi-threaded pro\u00adgrams. In this section, we discuss several other \nrelated approaches, and elaborate on some that we have previously mentioned. DEADLOCKFUZZER is part of \nthe active testing framework [16] that we have earlier developed for .nding real races [25] and real \natomicity violations [23]. We proposed RACEFUZZER [25] which uses an active randomized scheduler to con.rm \nrace conditions withhigh probability. RACEFUZZER only uses statement locations to identify races and \ndoes not use object abstraction or context information to increase the probability of race detection. \nAs shown in Section 5.2, simple location information is not good enough for creating real deadlocks with \nhigh probability. Recently, several random testing techniques have been pro\u00adposed [8, 26] that introduce \nnoise (using yield, sleep, wait (with timeout)) to a program execution to increase the possibility of \nthe exhibition of a synchronization bug. Although these techniques have successfully detected bugs in \nmany programs, they have a limitation. These techniques are not systematic as the primitives sleep(), \nyield(), priority() can only advise the sched\u00aduler to make a thread switch, but cannot force a thread \nswitch. As such they cannot pause a thread as long as required to create a real deadlock. More recently, \na few techniques have been proposed to con\u00ad.rm potential bugs in concurrent programs using random testing. \nHavelund et al. [3] uses a directed scheduler to con.rm that a po\u00adtential deadlock cycle could lead to \na real deadlock. However, they assume that the thread and object identi.ers do not change across executions. \nSimilarly, ConTest [22] uses the idea of introducing noise to increase the probability of the occurrence \nof a deadlock. It records potential deadlocks using a Goodlock algorithm. To check whether a potential \ndeadlock can actually occur, it introduces noise during program execution to increase the probability \nof exhibition of the deadlock. Our work differs from ConTest in the following ways. ConTest uses only \nlocations in the program to identify locks. We use context information and object abstractions to identify \nthe run-time threads and locks involved in the deadlocks; therefore, our abstractions give more precise \ninformation about run-time objects. Moreover, we explicitly control the thread scheduler to create the \npotential deadlocks, instead of adding timing noise to program ex\u00adecution. DEADLOCKFUZZER, being explicit \nin controlling sched\u00aduler and in identifying objects across executions, found real dead\u00adlocks in large \nbenchmarks with high probability. A couple of techniques have been proposed to prevent dead\u00adlocks from \nhappening during program execution, and to recover from deadlocks during execution. When a buggy program \nexecutes and deadlocks, Dimmunix [17] records the deadlock pattern. Dur\u00ading program execution, it tries \nto prevent the occurrence of any of the deadlock patterns that it has previously observed. Rx [24] pro\u00adposes \nto recover programs from software failures, including dead\u00adlocks, by rolling them back to a recent checkpoint, \nand re-executing the programs in a modi.ed environment. 7. Conclusion Existing techniques for deadlock \ndetection, based on static and dy\u00adnamic analysis, could predict potential deadlocks, but could not verify \nif they were real deadlocks. Going through all of these warn\u00adings and reasoning about them manually could \nbe time consuming. DEADLOCKFUZZER automates such veri.cation if a real dead\u00adlock is created by DEADLOCKFUZZER, \nthe developer no longer needs to verify the deadlock manually. However, DEADLOCK-FUZZER is incomplete \nif a deadlock is not con.rmed to be real by DEADLOCKFUZZER,thedeveloper cannot ignorethedeadlock. Nevertheless, \nDEADLOCKFUZZER has managed to .nd all pre\u00adviously known deadlocks in large benchmarks and it has discov\u00adered \npreviously unknown deadlocks. We believe that DEADLOCK-FUZZER is an indispensable and practical tool \nthat complements both static and predictive dynamic analysis.  Acknowledgments We would like to thank \nthe anonymous reviewers for their valuable comments. This research was supported in part by a generous \ngift from Intel, by Microsoft and Intel funding (award #20080469), by matching funding by U.C. Discovery \n(award #DIG07-10227), and by NSF Grant CNS-0720906.  References [1] R. Agarwal, L. Wang, and S. D. Stoller. \nDetecting potential deadlocks with static analysis and runtime monitoring. In Parallel and Distributed \nSystems: Testing and Debugging 2005, 2005. [2] C. Artho and A. Biere. Applying static analysis to large-scale, \nmulti-threaded Java programs. In Proceedings of the 13th Australian Software Engineering Conference (ASWEC \n01), pages 68 75, 2001. [3] S. Bensalem, J.-C. Fernandez, K. Havelund, and L. Mounier. Con.rmation of \ndeadlock potentials detected by runtime analysis. In PADTAD 06, pages 41 50, 2006. [4] S. Bensalem and \nK. Havelund. Scalable dynamic deadlock analysis of multi-threaded programs. In Parallel and Distributed \nSystems: Testing and Debugging 2005 (PADTAD 05), 2005. [5] C. Boyapati, R. Lee, and M. Rinard. Ownership \ntypes for safe programming: preventing data races and deadlocks. In 17th ACM SIGPLAN Conference on Object-Oriented \nProgramming, Systems, Languages, and Applications, pages 211 230, 2002. [6] S. Chaki, E. Clarke, J. Ouaknine, \nN. Sharygina, and N. Sinha. Concurrent software veri.cation with states, events, and deadlocks. Formal \nAspects of Computing, 17(4):461 483, 2005. [7] C. Demartini, R. Iosif, and R. Sisto. A deadlock detection \ntool for concurrent java programs. Software -Practice and Experience, 29(7):577 603, 1999. [8] O. Edelstein, \nE. Farchi, Y. Nir, G. Ratsaby, , and S. Ur. Multithreaded Java program test generation. IBM Systems Journal, \n41(1):111 125, 2002.  [9] D. R. Engler and K. Ashcraft. Racerx: effective, static detection of race \nconditions and deadlocks. In 19th ACM Symposium on Operating Systems Principles (SOSP), pages 237 252, \n2003. [10] C. Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson, J. B. Saxe, and R. Stata. Extended \nstatic checking for java. In PLDI 02: Proceedings of the ACM SIGPLAN 2002 Conference on Programming language \ndesign and implementation, pages 234 245. ACM, 2002. [11] P. Godefroid. Model checking for programming \nlanguages using verisoft. In 24th Symposium on Principles of Programming Languages, pages 174 186, 1997. \n[12] J. Harrow. Runtime checking of multithreaded applications with visual threads. In 7th International \nSPIN Workshop on Model Checking and Software Veri.cation, pages 331 342, 2000. [13] K. Havelund. Using \nruntime analysis to guide model checking of java programs. In 7th International SPIN Workshop on Model \nChecking and Software Veri.cation, pages 245 264, 2000. [14] K. Havelund and T. Pressburger. Model Checking \nJava Programs using Java PathFinder. Int. Journal on Software Tools for Technology Transfer, 2(4):366 \n381, 2000. [15] G. Holzmann. The Spin model checker. IEEE Transactions on Software Engineering, 23(5):279 \n295, 1997. [16] P. Joshi, M. Naik, C.-S. Park, and K. Sen. An extensible active testing framework for \nconcurrent programs. In 21st International Conference on Computer Aided Veri.cation (CAV 09), Lecture \nNotes in Computer Science. Springer, 2009. [17] H. Jula, D. Tralamazza, C. Zam.r, and G. Candea. Deadlock \nimmunity: Enabling systems to defend against deadlocks. In Proceedings of the 8th USENIX Symposium on \nOperating Systems Design and Implementation (OSDI 08), 2008. [18] L. Lamport. Time, clocks, and the ordering \nof events in a distributed system. Commun. ACM, 21(7):558 565, 1978. [19] S. Masticola. Static detection \nof deadlocks in polynomial time.PhD thesis, Rutgers University, 1993. [20] A. Milanova, A. Rountev, and \nB. Ryder. Parameterized object sensitivity for points-to analysis for Java. ACM Transactions on Software \nEngineering and Methodology, 14(1):1 41, Jan. 2005. [21] M. Naik, C.-S. Park, K. Sen, and D. Gay. Effective \nstatic deadlock detection. In 31st International Conference on Software Engineering (ICSE 09). IEEE, \n2009. [22] Y. Nir-Buchbinder, R. Tzoref, and S. Ur. Deadlocks: From exhibiting to healing. In 8th Workshop \non Runtime Veri.cation, 2008. [23] C.-S. Park and K. Sen. Randomized active atomicity violation detection \nin concurrent programs. In 16th International Symposium on Foundations of Software Engineering (FSE 08). \nACM, 2008. [24] F. Qin, J. Tucek, J. Sundaresan, and Y. Zhou. Rx: treating bugs as allergies a safe method \nto survive software failures. In SOSP 05: Proceedings of the twentieth ACM symposium on Operating systems \nprinciples, pages 235 248. ACM, 2005. [25] K. Sen. Race directed random testing of concurrent programs. \nIn ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 08), 2008. [26] S. \nD. Stoller. Testing concurrent Java programs using randomized scheduling. In Workshop on Runtime Veri.cation \n(RV 02), volume 70 of ENTCS, 2002. [27] C. von Praun. Detecting Synchronization Defects in Multi-Threaded \nObject-Oriented Programs. PhD thesis, Swiss Federal Institute of Technology, Zurich, 2004. [28] C. von \nPraun and T. R. Gross. Object race detection. In 16th ACM SIGPLAN conference on Object oriented programming, \nsystems, languages, and applications (OOPSLA), pages 70 82. ACM, 2001. [29] A. Williams, W. Thies, and \nM. Ernst. Static deadlock detection for Java libraries. In ECOOP 2005 19th European Conference on Object-Oriented \nProgramming (ECOOP 05), pages 602 629, 2005. [30] B. Xin, W. N. Sumner, and X. Zhang. Ef.cient program \nexecution indexing. In ACM SIGPLAN conference on Programming language design and implementation, pages \n238 248, 2008.  \n\t\t\t", "proc_id": "1542476", "abstract": "<p>We present a novel dynamic analysis technique that finds real deadlocks in multi-threaded programs. Our technique runs in two stages. In the first stage, we use an imprecise dynamic analysis technique to find potential deadlocks in a multi-threaded program by observing an execution of the program. In the second stage, we control a random thread scheduler to create the potential deadlocks with high probability. Unlike other dynamic analysis techniques, our approach has the advantage that it does not give any false warnings. We have implemented the technique in a prototype tool for Java, and have experimented on a number of large multi-threaded Java programs. We report a number of previously known and unknown real deadlocks that were found in these benchmarks.</p>", "authors": [{"name": "Pallavi Joshi", "author_profile_id": "81336490218", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P1464249", "email_address": "", "orcid_id": ""}, {"name": "Chang-Seo Park", "author_profile_id": "81435604146", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P1464250", "email_address": "", "orcid_id": ""}, {"name": "Koushik Sen", "author_profile_id": "81100399070", "affiliation": "University of California, Berkeley, Berkeley, CA, USA", "person_id": "P1464251", "email_address": "", "orcid_id": ""}, {"name": "Mayur Naik", "author_profile_id": "81100223912", "affiliation": "Intel Research, Berkeley, CA, USA", "person_id": "P1464252", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542489", "year": "2009", "article_id": "1542489", "conference": "PLDI", "title": "A randomized dynamic program analysis technique for detecting real deadlocks", "url": "http://dl.acm.org/citation.cfm?id=1542489"}