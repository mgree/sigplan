{"article_publication_date": "06-15-2009", "fulltext": "\n Stretching Transactional Memory Aleksandar Dragojevi\u00b4c Rachid Guerraoui Michal Kapalka Ecole Polytechnique \nF\u00b4ed\u00b4erale de Lausanne, School of Computer and Communication Sciences, I&#38;C, Switzerland {aleksandar.dragojevic, \nrachid.guerraoui, michal.kapalka}@ep..ch Abstract Transactional memory (TM) is an appealing abstraction \nfor pro\u00adgramming multi-core systems. Potential target applications for TM, such as business software \nand video games, are likely to involve complex data structures and large transactions, requiring speci.c \nsoftware solutions (STM). So far, however, STMs have been mainly evaluated and optimized for smaller \nscale benchmarks. We revisit the main STM design choices from the perspec\u00adtive of complex workloads and \npropose a new STM, which we call SwissTM. In short, SwissTM is lock-and word-based and uses (1) optimistic \n(commit-time) con.ict detection for read/write con.icts and pessimistic (encounter-time) con.ict detection \nfor write/write con.icts, as well as (2) a new two-phase contention manager that ensures the progress \nof long transactions while induc\u00ading no overhead on short ones. SwissTM outperforms state-of-the\u00adart \nSTM implementations, namely RSTM, TL2, and TinySTM, in our experiments on STMBench7, STAMP, Lee-TM and \nred-black tree benchmarks. Beyond SwissTM, we present the most complete evaluation to date of the individual \nimpact of various STM design choices on the ability to support the mixed workloads of large applications. \nCategories and Subject Descriptors D.1.3 [Programming Tech\u00adniques]: Concurrent Programming; D.2.8 [Software \nEngineering]: Metrics performance measures General Terms Measurement, Performance, Experimentation Keywords \nSoftware transactional memories, Benchmarks 1. Introduction Transactional memory (TM) is an appealing \nabstraction for making concurrent programming accessible to a wide community of non\u00adexpert programmers \nwhile avoiding the pitfalls of critical sections. With a TM, application threads communicate by executing \nopera\u00adtions on shared data inside lightweight in-memory transactions.A transaction performs a number \nof actions and then either commits, in which case all the actions are applied to shared data atomically, \nor aborts, in which case the effects of those actions are rolled back and never visible to other transactions. \nFrom a programmer s per\u00adspective, the TM paradigm is very promising as it promotes pro\u00adgram composition \n[20], in contrast to explicit locking, while still providing the illusion that all shared objects are \nprotected by some Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. Copyright c &#38;#169; 2009 ACM 978-1-60558-392-1/09/06. \n. . $5.00 global lock. Yet, it offers the possibility of performance comparable to hand-crafted, .ne-grained \nlocking. A possible target of TMs are large applications such as business software or video games: the \nsize of these applications make them ideal candidates to bene.t from emerging multi-core architectures. \nSuch applications typically involve dynamic and non-uniform data structures consisting of many objects \nof various complexity. For example, a video gameplay simulation can use up to 10,000 active interacting \ngame objects, each having mutable state, being updated 30 60 times per second, and causing changes to \n5 10 other objects on every update [40]. Unless a TM is used, making such code thread-safe and scalable \non multi-cores is a daunting task [40]. The big size and complexity of such applications can, in turn, \neasily lead to large transactions, for these can naturally be composed [20]. Some TM interfaces [1], \nin fact, promote the encapsulation of entire applications within very few transactions. The motivation \nof this work is to explore the ability of software mechanisms to effectively support mixed workloads \nconsisting of small and large transactions, as well as possibly complex data structures. We believe this \nto be of practical relevance because even if hardware TM support becomes widely available in the future, \nit is likely that only smaller-scale transactional workloads will be fully executed in hardware, while \nsoftware support will still be needed for transactions with large read and write sets. For example, the \nhybrid hardware/software scheme proposed in [26] switches from full hardware TM to full software TM when \nit encounters large transactions. The ability of STM systems to effectively deal with large transactions \nwill be crucial in these settings as well. Since the seminal paper on a software TM (STM) that supported \ndynamic data structures and unbounded transactions [22], all mod\u00adern STMs are supposed to handle complex \nworkloads [22, 27, 10, 31, 21, 2, 35, 29]. A wide variety of STM techniques, mainly in\u00adspired by database \nalgorithms, have been explored. The big chal\u00adlenge facing STM researchers is to determine the right combination \nof strategies that suit the requirements of concurrent applications requirements that are signi.cantly \ndifferent than those of database applications. So far, however, most STM experiments have been performed \nusing benchmarks characterized by small transactions, simple and uniform data structures, or regular \ndata access patterns. While such experiments reveal performance differences between STM implementations, \nthey are not fully representative of com\u00adplex workloads that STMs are likely to get exposed to once used \nin real applications. Worse, they can mislead STM implementors by promoting certain strategies that may \nperform well in small-scale applications but are counter-productive with complex workloads. Examples \nof such strategies, which we discuss in more details later in the paper, include the following. 1. The \ncommit-time locking scheme, used for instance in TL2 [10], is indeed effective for short transactions, \nbut might waste sig\u00adni.cant work of longer transactions that eventually abort due to write/write con.icts. \nThis is because write/write con.icts, which usually lead to transaction aborts1, are detected too late. \n2. The encounter-time locking scheme, used by most STMs, e.g., TinySTM [31], McRT-STM [35, 29], and Bartok-STM \n[21] im\u00admediately aborts a transaction that tries to read a memory loca\u00adtion locked by another transaction. \nHence, read/write con.icts, which can often be handled without aborts, are detected very early and resolved \nby aborting readers. Long transactions that write memory locations commonly read by other transactions \nmight thus end up blocking many other transactions, and for a long time, thus slowing down the system \noverall. 3. The timid contention management scheme, used by many STMs, especially word-based ones such \nas TL2 and TinySTM, and which aborts transactions immediately upon a con.ict, fa\u00advors short transactions. \nContention managers such as Greedy [16] or Serializer [34] are more appropriate for large transactions, \nbut are hardly ever used due to the overhead they impose on short transactions.  It is appealing but \nchallenging to come up with strategies that account both for long transactions and complex workloads, \nas well as for short transactions and simple data structures: these might indeed typically co-exist in \nreal applications. This paper is a .rst step towards taking that challenge up. We perform that step through \nSwissTM, a new lock-and word-based STM. The main distinctive features of SwissTM are: A con.ict detection \nscheme that detects (a) write/write con\u00ad.icts eagerly, in order to prevent transactions that are doomed \nto abort from running and wasting resources, and (b) read/write con.icts late, in order to optimistically \nallow more parallelism between transactions. In short, transactions eagerly acquire ob\u00adjects for writing, \nwhich helps detect write/write con.icts as soon as they appear. This also avoids wasting work of trans\u00adactions \nthat are already doomed to abort after a write/write con\u00ad.ict. By using invisible reads and allowing \ntransactions to read objects acquired for writing, SwissTM detects read/write con\u00ad.icts late, thus increasing \ninter-transaction parallelism. A time\u00adbased scheme [10, 33] is used to reduce the cost of transaction \nvalidation with invisible reads.  A two-phase contention manager that incurs no overhead on read-only \nand short read-write transactions while favoring the progress of transactions that have performed a signi.cant \nnum\u00adber of updates. Basically, transactions that are short or read-only use the simple but inexpensive \ntimid contention management scheme, aborting on .rst encountered con.ict. Transactions that are more \ncomplex switch dynamically to the Greedy mecha\u00adnism that involves more overhead but favors these transactions, \npreventing starvation. Additionally, transactions that abort due to write/write con.icts back-off for \na period proportional to the number of their successive aborts, hence reducing contention on memory hot \nspots.  We evaluate SwissTM with state-of-the-art STMs by using benchmarks that cover a large part of \nthe complexity space. We start with STMBench7 [18], which involves (1) non-uniform data structures of \nsigni.cant size, and (2) a mix of operations of various length and data access patterns. Then, we move \nto Lee-TM [4] a benchmark with large but regular transactions and STAMP [8] a collection of realistic \nmedium-scale workloads. Finally, we eval\u00aduate SwissTM with a red-black tree microbenchmark that involves \nvery short and simple transactions. SwissTM outperforms state-of\u00ad 1 Pure write/write con.icts do not \nnecessarily lead to transaction aborts, but are very rare most transactions read memory locations before \nupdating them. STM design choices Acquire Reads CM Effectiveness lazy invisible any + eager visible any \n+ eager invisible Polka + eager invisible timid or Greedy ++ mixed invisible timid or Greedy +++ mixed \ninvisible 2-phase ++++  Table 1. A summary comparison of the effectiveness of selected combinations \nof STM design choices in mixed workloads. the-art STMs RSTM [27], TL2 [10], and TinySTM [31] in all the \nconsidered benchmarks. For example, in the read-dominated workload of STMBench7 (90% of read-only operations), \nSwissTM outperforms the other STMs by up to 65%, and in the write\u00addominated workload (10% of read-only \noperations) by up to 10%. Also, SwissTM provides a better scalability than the other STMs, especially \nfor read-dominated and read-write (60% of read\u00adonly operations) workloads of STMBench7. We compare SwissTM \nto RSTM, TL2, and TinySTM for two reasons. They constitute the state-of-the-art performance-wise, among \nthe publicly available library-based STMs. Furthermore, just like SwissTM, they can be used to manually \ninstrument concur\u00adrent applications with transactional accesses. Indeed, our goal is to evaluate the \nperformance of the core STM algorithm, not the ef.ciency of the higher layers such as STM compilers. \nWe did not use for instance McRT-STM [35, 29], because it does not expose such a low-level API to a programmer. \nEvaluat\u00ading STM-aware compilers (which naturally introduce additional overheads above the low-level STM \ninterface [42, 6]) is largely an orthogonal issue;  They represent a wide spectrum of known TM design \nchoices: obstruction-free vs. lock-based implementation, eager vs. lazy updates, invisible vs. visible \nreads, and word-level vs. object\u00adlevel access granularity. They also allow for experiments with a variety \nof contention management strategies, from simply aborting a transaction on a con.ict, through exponential \nback\u00adoff, up to advanced contention managers like Greedy [16], Serializer [34], or Polka [41].  We report \non our SwissTM (trial-and-error) experience, which we believe is interesting in its own right. It is \nthe .rst to date that evaluates the ability of software solutions to provide good per\u00adformance to large \ntransactions and complex objects without intro\u00adducing signi.cant overheads on short transactions and \nsimple data structures. We evaluate the individual impact of various STM de\u00adsign choices on the ability \nto support mixed workloads. A summary of our observations, is presented in Table 1. From an implementation \nperspective, we also evaluate the im\u00adpact of the locking granularity. Word-based STM implementations \nused so far either word-level locking (e.g., TL2 and TinySTM) or cache-line level locking (e.g., McRT-STM \nC/C++). Our sensitivity analysis shows that a lock granularity of four words outperforms both word-level \nand cache line-level locking by 4% and 5% re\u00adspectively across all benchmarks we considered. To summarize, \nthe main contributions of this paper are (1) the design and implementation of an STM that performs particularly \nwell with large-scale complex transactional workloads while hav\u00ading good performance in small-scale ones, \nand (2) an extensive ex\u00adperimental evaluation of STM strategies and implementations from the perspective \nof complex applications with mixed workloads. The rest of the paper is organized as follows. In Section \n2, we give a short overview of STM design space and benchmarks. We then present SwissTM in Section 3. \nIn Sections 4 and 5, we present the results of our experimental evaluation: .rst, we com\u00adpare the performance \nof SwissTM to that of TL2, TinySTM, and RSTM, and, second, we evaluate the individual impact of the de\u00adsign \nchoices underlying SwissTM.  2. Background Transactional memory was .rst proposed in hardware (HTM) \n[23]. So far, most HTMs support only limited-size transactions and of\u00adten do not ensure transaction progress \nupon speci.c system events, e.g., interrupts, context switches, or function calls [9]. While there have \nbeen proposals for truly dynamic HTMs (e.g. [3, 32]), it is very likely that actual HTM implementations \nwill still have some of these limitations. Hybrid approaches either execute short transactions in hardware \nand fall back to software for longer ones (e.g., [26]), or accelerate certain operations of an STM in \nhard\u00adware. This work focuses on pure software solutions (STM) [37]. In this section, we survey some distinctive \nfeatures of STMs and discuss the three representative STMs we focus on in our evalua\u00adtion: RSTM [27], \nTL2 [10], and TinySTM [31] (see [24] for a full survey). We also give a short description of the benchmarks \nused in our experiments. 2.1 STM Design Space The maintaskof anSTM is to detect con.icts among concurrent \ntransactions and resolve them. Deciding what to do when con.icts arise is performed by a (conceptually) \nseparate component called a contention manager [22]. A concept closely related to con.ict detection is \nthat of validation. Validating a transaction consists of checking its read set (i.e., the set of locations2 \nthe transaction has already read) for consistency. Two classes of STMs can be distinguished, word-based \nand object-based, depending on the granularity at which they perform logging. RSTM is object-based while \nTL2 and TinySTM are word\u00adbased. There are also two general classes of STM implementa\u00adtions: lock-based \nand obstruction-free. Lock-based STMs, .rst pro\u00adposed in [19, 12], implement some variant of the two-phase \nlock\u00ading protocol [13]. Obstruction-free STMs [22] do not use any blocking mechanisms (such as locks), \nand guarantee progress even when some of the transactions are delayed. RSTM (version 3) is obstruction-free, \nwhile TL2 and TinySTM internally use locks. Con.ict detection. Most STMs employ the single-writer-multiple\u00adreaders \nstrategy; accesses to the same location by concurrent trans\u00adactions con.ict when at least one of the \naccesses is a write (update). In order to commit, a transaction T must eventually acquire every location \nx that is updated by T . Acquisition can be eager, i.e., at the time of the .rst update operation of \nT on x,or lazy, i.e., at the commit time of T . A transaction T that reads x can be either visible or \ninvisible [27] to other transactions accessing x.When T is invis\u00adible, T has the sole responsibility \nof detecting con.icts on x with transactions that write x concurrently, i.e., validating its read set. \nThe time complexity of a basic validation algorithm is proportional to the size of the read set, but \ncan be boosted with a global commit counter heuristic (RSTM), or a time-based scheme [10, 31] (TL2 and \nTinySTM). A mixed invalidation con.ict detection scheme (.rst proposed in [39]) eagerly detects write/write \ncon.icts while lazily detecting read/write con.icts (it is a mix between pure lazy and pure eager schemes). \nA similar con.ict detection scheme is provided by more 2 These are memory words in word-based STMs and \nobjects in object-based STMs. general (but also more expensive) multi-versioning schemes used in LSA-STM \n[33] and JVSTM [7]. Mixed invalidation, which under\u00adlies SwissTM, has never been used with lock-based \nor word-based STMs, nor has it been evaluated with any large-scale workload. RSTM supports lazy and eager \nacquisition, as well as visi\u00adble and invisible reads (i.e., four algorithm variants). TL2 and TinySTM \nuse, respectively, lazy and eager acquisition. Both TL2 and TinySTM employ invisible reads. Contention \nmanagement. The contention manager decides what a given transaction (attacker) should do in case of a \ncon.ict with another transaction (victim). Possible outcomes are: aborting the attacker, aborting the \nvictim, or forcing the attacker to retry after some period. The simplest scheme (which we call timid) \nis to always abort the attacker (possibly with a short back-off). This is the default scheme in TL2 and \nTinySTM. More involved contention managers were proposed in [41, 36, 16], and are provided with RSTM. \nThey can also be combined at run-time [15]. Polka [41] assigns every trans\u00adaction a priority that is \nequal to the number of objects the trans\u00adaction accessed so far. Whenever the attacker waits, its priority \nis temporarily increased by one. If the attacker has a lower priority than the victim, it will be forced \nto wait (using exponential back\u00adoff to calculate the wait interval), otherwise the victim gets aborted. \nGreedy assigns each transaction a unique, monotonically increas\u00ading timestamp on its start. The transaction \nwith the lower times\u00adtamp always wins. An important property of Greedy is that, un\u00adlike other contention \nmanagers we mention, it avoids starvation of transactions. Polka has been shown to provide best performance \nin smaller-scale benchmarks previously [41], while our experiments show that Greedy performs better in \nlarge-scale workloads (Sec\u00adtion 5). Serializer is very similar to Greedy except that it assigns a new \ntimestamp to a transaction on every restart, and thus does not prevent starvation or even livelocks of \ntransactions. 2.2 STM Benchmarks In this section, we give an overview of the benchmarks we use in our \nexperiments. These represent a large spectrum of workload types: from simple data structures with small \ntransactions (the red\u00adblack tree microbenchmark) to complex applications with possibly long transactions \n(STMBench7). All the benchmarks we used are implemented in C/C++. STMBench7. STMBench7 [18] is a synthetic \nbenchmark which workloads aim at representing realistic, complex, object-oriented applications that are \nan important target for STMs. STMBench7 exhibits a large variety of operations (from very short, read-only \noperations to very long ones that modify large parts of the data structure) and workloads (from workloads \nconsisting mostly of read-only transactions to write-dominated ones). The data structure used by STMBench7 \nis many orders of magnitude larger than in other typical STM benchmarks. Also, its transactions are longer \nand access larger numbers of objects. STMBench7 is inherently object-based and its implementations also \nuse standard language libraries. A thin wrapper, described in [11], is thus necessary to use STMBench7 \nwith word-based STMs (TL2, TinySTM, and SwissTM). STAMP. STAMP [8] is a TM benchmarking suite that consists \nof eight different transactional programs and ten workloads.3 STAMP applications are representative of \nvarious real-world workloads, in\u00adcluding bioinformatics, engineering, computer graphics, and ma\u00adchine \nlearning. While STAMP covers a broad range of possible STM uses, its does not involve very long transactions, \nsuch as those that might be produced by average, non-expert programmers or 3 We used STAMP version 0.9.9. \n generated automatically by a compiler along the lines of [1]. Fur\u00adthermore, some STAMP algorithms (e.g., \nbayes) split logical op\u00aderations into multiple transactions and use intricate programming techniques \nthat might not be representative of average program\u00admers skills. Lee-TM. Lee-TM [4] is a benchmark that \noffers large, realistic workloads and is based on Lee s circuit routing algorithm. The al\u00adgorithm takes \npairs of points (e.g., of an integrated circuit) as its input and produces non-intersecting routes between \nthem. While transactions of Lee-TM are signi.cant in size, they exhibit very regular access patterns \nevery transaction .rst reads a large num\u00adber of locations (searching for suitable paths) and then updates \na small number of them (setting up a path). Moreover, the bench\u00admark uses very simple objects (each can \nbe represented as a single integer variable). It is worth noting that STAMP contains an appli\u00adcation \n(called labyrinth) that uses the same algorithm as Lee-TM. However, Lee-TM uses real-world input sets \nthat make it more re\u00adalistic than labyrinth. Lee-TM distribution includes two input data sets: memory \nand main circuit boards. Red-black tree. The prevailing way of measuring the perfor\u00admance of STMs has \nbeen through microbenchmarks. The widely used (.rst in [22]) red-black tree microbenchmark consists of \nshort transactions that insert, lookup, and remove elements from a red-black tree data structure. Short \nand simple transactions of mi\u00adcrobenchmarks are good for testing mechanics of STM itself and comparing \nlow-level details of various implementations.  3. SwissTM SwissTM is a lock-based STM that uses invisible \nreads and counter based heuristics (the same as in TinySTM and TL2). It features eager write/write and \nlazy read/write con.ict detection, as well as a two-phase contention manager with random linear back-off. \nThe API of SwissTM is word-based, as it enables transactional access to arbitrary memory words. SwissTM \nuses a redo-logging scheme (partially to support its con.ict detection scheme). 3.1 Programming model \nSimilarly to most other STM libraries, SwissTM guarantees opac\u00adity [17]. Opacity is similar to serializability \nin database sys\u00adtems [30]. The main difference is that all transactions always ob\u00adserve consistent states \nof the system. This means that transactions cannot, e.g., use stale values, and that they do not require \nperiodic validation or sandboxing to prevent in.nite loops or crashes due to accesses to inconsistent \nmemory states. SwissTM is a weakly atomic STM, i.e., it does not provide any guarantees for the code \nthat accesses the same data from both inside and outside of transactions. SwissTM is not privatization \nsafe [38]. This could make programming with SwissTM slightly more dif.cult in certain cases, but did \nnot affect us, as none of the benchmarks we use requires privatization-safe STM. When programming with \nSwissTM, programmers have to re\u00adplace all memory references to shared data from inside transactions with \nSwissTM calls for reading and writing memory words. The programming model can be improved by using an \nSTM compiler (as in e.g. [21, 2, 14, 29]). While the compiler instrumentation can degrade performance \ndue to over-instrumentation [42] and possi\u00adbly even change the characteristics of the workload slightly \n(e.g. numbers and ratio of transactional read and write operations), the compiler instrumentation remains \na largely orthogonal issue to the performance of an STM library. Other three STMs we compare to in our \nexperiments provide the same semantical guarantees as SwissTM. Also, strengthening the guarantees (as \ndescribed in Section 6) would have a similar performance impact on all STMs we use.  3.2 Algorithm We \ngive the pseudo-code of SwissTM in Algorithm 1. The algo\u00adrithm invokes contention manager functions (cm-*), \nwhich are de\u00ad.ned in Algorithm 2 and described below. All transactions share a global commit counter \ncommit-ts incremented by every non-read\u00adonly transaction upon commit. Each memory word m is mapped to \na pair of locks in a global lock table: r-lock (read) and w-lock (write). Lock w-lock is acquired by \na writer T of m (eagerly) to pre\u00advent other transactions from writing to m.Lock r-lock is acquired by \nT at commit time to prevent other transactions from reading word m and, as a result, observing inconsistent \nstates of words writ\u00adten by T . In addition, when r-lock is unlocked, it contains the ver\u00adsion number \nof m. Every transaction T has a transaction descriptor tx that contains (among other data): (1) the value \nof commit-ts read at the start or subsequent validation of T , and (2) read and write logs of T . Transaction \nstart. Every transaction T , upon its start, reads the global counter commit-ts and stores its value \nin tx.valid-ts (line 2). Reading. When reading location addr, transaction T .rst reads the value of w-lock \nto detect possible read-after-write cases. If T is the owner of w-lock,then T can return the value from \nits write log immediately, which is the last value T has written to addr (line 6). Otherwise, i.e., when \nsome other transaction owns w-lock or when w-lock is unlocked, T reads the value of r-lock, then the \nvalue of addr, and then again the value of r-lock. Transaction T repeats these three reads until (1) \ntwo values of r-lock are the same, meaning that T has read consistent values of r-lock and addr,and (2) \nr-lock is unlocked (lines 8 15). When r-lock is unlocked, it contains the current version v of addr.If \nv is lower or equal to the validation timestamp tx.valid-ts of T (which means that addr has not changed \nsince T s last validation or start), T returns the value at addr read in line 18. Otherwise, T revalidates \nits read set. If the revalidation does not succeed, T rolls back (line 17). If it succeeds, the read \noperation returns and T extends its validation timestamp tx.valid-ts to the current value of commit-ts \n(line 56). Writing. Whenever some transaction T writes to a memory lo\u00adcation addr, T .rst checks if T \nis the owner of the lock w-lock corresponding to addr.If it is, T updates the value of addr in its write \nlog and returns (lines 21 23). Otherwise, T tries to acquire w-lock by atomically replacing, using a \ncompare-and-swap (CAS) operation, value unlocked with the pointer to the T s write log en\u00adtry that contains \nthe new value of addr (line 29). If CAS does not succeed, T asks the contention manager whether to rollback \nand retry or wait for the current owner of the lock to .nish (line 26). In order to guarantee opacity, \nT has to revalidate its read set if the cur\u00adrent version of addr (contained in r-lock) is higher than \nits validity timestamp tx.valid-ts (lines 31 32). Validation. To validate itself, T compares the versions \nof all memory locations read so far to their versions at the point they were initially read by T (lines \n51 52). These versions are stored in T s read log. If there is a mismatch between any version numbers, \nthe validation fails (line 52). Commit. A read-only transaction T can commit immediately, as its read \nlog is guaranteed to be consistent (line 35). A transaction T that is not read-only .rst locks all read \nlocks of memory locations T has written to (line 36). Then, T increments commit-ts (line 37) and re-validates \nits read log. If the validation does not succeed, T roll\u00adbacks and restarts (lines 38 41). Upon successful \nvalidation, T tra\u00adverses its write set, updates values of all written memory locations, and releases \nthe corresponding read and write locks (lines 42 45). When releasing read locks, T writes the new value \nof commit-ts to those locks. Algorithm 1: Pseudo-code representation of SwissTM. Algorithm 2: Pseudo-code \nof the two-phase contention man\u00ad 1 2 3 4 6 7 8 9 11 12 13 14 16 17 18 19 21 22 23 24 26 27 28 29 31 32 \n33 34 36 37 38 39 41 42 43 44 46 47 48 49 51 52 53 54 56 57 function start(tx) tx.valid-ts . commit-ts; \ncm-start(tx); function read-word(tx, addr) (r-lock,w-lock) . map-addr-to-locks(addr); if is-locked-by(w-lock, \ntx) then return get-value(w-lock, addr); version . read(r-lock); while true do if version = locked then \nversion . read(r-lock); continue; value . read(addr); version2 . read(r-lock); if version = version2 \nthen break; version2 . version; add-to-read-log(tx, r-lock, version); if version > tx.valid-ts and not \nextend(tx) then rollback(tx); return value;   function write-word(tx, addr, value) (r-lock,w-lock) \n. map-addr-to-locks(addr); if is-locked-by(w-lock, tx) then update-log-entry(w-lock, addr, value); return; \nwhile true do if is-locked(w-lock) then if cm-should-abort(tx, w-lock) then rollback(tx); else continue; \nlog-entry . add-to-write-log(tx, w-lock, addr, value); if compare&#38;swap(w-lock, unlocked,log-entry) \nthen break; if read(r-lock) > tx.valid-ts and not extend(tx) then rollback(tx); cm-on-write(tx);  \n function commit(tx) if is-read-only(tx) then return; for log-entry in tx.read-log do write(log-entry.r-lock, \nlocked); ts . increment&#38;get(commit-ts); if ts > tx.valid-ts + 1 and not validate(tx) then for log-entry \nin tx.read-log do write(log-entry.r-lock, log-entry.version); rollback(tx); for log-entry in tx.write-log \ndo write(log-entry.addr, log-entry.value); write(log-entry.r-lock, ts); write(log-entry.w-lock, unlocked); \n function rollback(tx) for log-entry in tx.write-log do write(log-entry.w-lock, unlocked); cm-on-rollback(tx); \n function validate(tx) for log-entry in tx.read-log do if log-entry.version = read(log-entry.r-lock) \nand not is-locked-by(log-entry.r-lock, tx) then return false; return true;   function extend(tx) ts \n. read(commit-ts); if validate(tx) then tx.valid-ts . ts; return true; return false;  ager (Wn is a \nconstant) 1 function cm-start(tx) 2 if not-restart(tx) then tx.cm-ts . 8 ; 3 function cm-on-write(tx) \n4 if tx.cm-ts = 8 and size(tx.write-log)= Wn then tx.cm-ts . increment&#38;get(greedy-ts) ;  5 function \ncm-should-abort(tx, w-lock) 6 if tx.cm-ts = 8 then return true; 7 lock-owner = owner(w-lock); 8 if lock-owner.cm-ts \n< tx.cm-ts then return true; 9 else abort(lock-owner); return false;  10 function cm-on-rollback(tx) \n11 wait-random(tx.succ-abort-count); Rollback. On rollback, transaction T releases all write locks \nit holds (lines 47 48), and then restarts itself. Contention management. We give the pseudo-code of our \ntwo\u00adphase contention manager in Algorithm 2. The contention manager gets invoked by Algorithm 1 (1) at \ntransaction start (cm-start in line 3), (2) on a write/write con.ict (cm-should-abort in line 26), (3) \nafter a successful write (cm-on-write in line 33), and (4) after restart (cm-on-rollback in line 49). \nEvery transaction, upon exe\u00adcuting its Wn th write (where we set Wn to 10), increments global counter \ngreedy-ts and stores its value in tx.cm-ts (line 4). Hence, short transactions (those that execute less \nthan Wn writes) do not access greedy-ts that would otherwise become a memory hot spot this reduces contention \nand the number of cache misses. Trans\u00adactions that have already incremented greedy-ts are in the second \nphase of the contention management scheme, and others are in the .rst phase. Upon a con.ict, a transaction \nthat is still in the .rst phase gets restarted immediately (line 6). If both con.icting trans\u00adactions \nare already in the second phase, the transaction with the higher value of cm-ts is restarted (lines 8 \n9). This prioritizes trans\u00adactions that have performed more work. Conceptually, transactions in the .rst \nphase have an in.nite value of cm-ts (set in line 2). This means that (longer) transactions, which are \nin the second phase, have higher priority than (short) transactions that are in the .rst phase. After \nrestarting, transactions are delayed using a random\u00adized back-off scheme (line 11). This reduces probability \nof hav\u00ading some transaction aborted many times repeatedly because of the same con.ict.  3.3 Implementation \nHighlights We implemented SwissTM in C++ (g++ 4.0.1 compiler). We used the (fairly portable) atomic ops \nlibrary [5] for atomic operations implementation. Currently, SwissTM works on 32-bit x86 Linux 2.6.x \nand OS X 10.5 platforms (64-bit port is in progress). Lock table. To map memory word m to a lock table \nentry, we take the address a of m, shift it to the right by 4 (it would be 5 with 64-bit words). This \nmakes each lock map to consecutive four memory words (we empirically selected this value, as explained \nin Section 5). Then, we set all high order bits to zero. As the lock table contains 222 entries in our \nimplementation, we just perform logical AND operation between shifted address and 222 - 1toget the index \ninto the table. Figure 1 depicts the mapping scheme. Having multiple consecutive memory words mapped \nto the same lock table entry can result in false con.ict, when unrelated memory words get locked together, \nbut this does not cause any problems in practice.   Lock table Memory Figure 1. Mapping of memory \nwords to lock table entries. Every lock is implemented as a single memory word w.The write lock is equal \nto 0 in its unlocked state and contains a pointer to the corresponding write log entry when locked. Acquiring \na write lock is done using a compare-and-swap (CAS) operation. When releasing write lock w, transactions \nsimply write 0 to w. The read lock has its least signi.cant bit set to 0 when unlocked, while other bits \nstore the version number of memory locations corresponding to w. When locked, the read lock is equal \nto 1. Both locking and unlocking of read locks is performed by simply writing a new value to w (CAS is \nnot used), as only the transaction that already acquired a write lock can acquire the corresponding read \nlock.   4. Evaluating SwissTM We compare the performance of SwissTM to that of TL2, TinySTM, and RSTM. \nWe performed all measurements on a 4-processor dual-core AMD Opteron 8216 2.4 GHz 1024 KB cache machine \nwith 8 GB of RAM, running Linux operating system. This provided us with 8 cores to experiment on. All \nresults were averaged over multi\u00adple runs, where the length and the number of runs were chosen to reduce \nvariations in collected data. We typically used 20 runs for STMBench7 and STAMP, 10 runs for LeeTM and \n80 runs for the red-black tree microbenchmark. We used the TL2 x86 implemen\u00adtation provided with the \nSTAMP benchmark suite (version 0.9.5). We were not able to use the TL2 implementation from original au\u00adthors \nas it does not support the x86 architecture. Also, the origi\u00adnal TL2 does not support transactional memory \nmanagement in a straightforward manner, and is, because of that, dif.cult to use with benchmarks we had \nat our disposal, without signi.cant changes to the benchmark code. While we did not use the original \nTL2 im\u00adplementation in a setting that it was primarily designed for, we be\u00adlieve that the TL2 x86 port \nwe used is the best representative of the TL2 algorithm and design available for the x86 architecture. \nThe experiments were performed with the RSTM (version 3) and TinySTM (version 0.9.5) implementations \navailable from respec\u00adtive sites. Unless stated otherwise, we con.gured RSTM to use eager con.ict detection, \ninvisible reads with the commit counter heuristic, and the Polka contention manager. We used default \ncon\u00ad.gurations of TL2 (i.e., lazy con.ict detection, GV4) and TinySTM (i.e., encounter-time locking, \ntimid contention manager). STMBench7. Figure 2 shows the performance of SwissTM, TL2, TinySTM, and RSTM \nwith STMBench7. We con.gured RSTM to use the Serializer contention manager, as this gave the best per\u00ad \n Threads Threads 1 2 3 4 5 6 7 8 Threads Figure 2. Throughput of SwissTM, RSTM, TL2, and TinySTM with \nSTMBench7; top to bottom: read-dominated, read-write, and write-dominated workload forming RSTM con.guration \nin STMBench7. SwissTM signi.\u00adcantly outperforms all other STMs for both read-dominated and read-write \nworkloads, while also achieving superior scalability. SwissTM also outperforms other STMs in high-contention \nwrite\u00addominated workload, but it is only marginally faster than TinySTM. The main reason for the good \nperformance of SwissTM is (a) its optimism in detecting read/write con.icts when compared to RSTM and \nTinySTM, and (b) its conservatism in detecting write/write con.icts when compared to TL2. The contention \nman\u00ad 0.9 1 1 2 120 0.7 0.8 4 8 100 0.6 80 Speedup - 1 Speedup - 1 Duration [s] Duration [s] 0.5 0.4 \n0.3 0.2 60 40 20 RSTM 0 TinySTM SwissTM 1 2 3 4 5 6 7 8 Threads 0.1 0 0.6 180 1 2 1600.5 4 8 1400.4 \n120 0.3 100 80 0.2 0.1 60 0 40 -0.1 0 20 RSTM TinySTM SwissTM 1 2 3 4 5 6 7 8 Threads Figure 3. SwissTM \nvs. TL2 (top) and TinySTM (bottom) in STAMP. The .gure conveys the speedup of SwissTM compared to TL2 \nand TinySTM (with 1 subtracted, i.e., positive numbers mean that SwissTM is faster and negative that \nit is slower) for 1, 2, 4, and 8 threads. agement scheme used in SwissTM also helps boost performance, \nas we illustrate in Section 5. TL2 performs poorly even in the read-dominated workload it does not scale \nafter 4 threads. Its performance gets even worse with higher contention. The main reason for this is \nthe lazy con.ict detection scheme of TL2, which wastes more work of transactions than the eager write/write \ncon.ict detection of other STMs. STAMP. Figure 3 compares the performance of SwissTM, TL2, and TinySTM \nin the STAMP benchmark suite workloads.4 SwissTM outperforms TL2 in all STAMP workloads, for all thread \ncounts, excluding the vacation benchmark under low contention where TL2 and SwissTM have the same performance. \nSwissTM out\u00adperforms TL2 by over 50% with eight threads for the bayes, intruder,and yada benchmarks (being \nalmost twice as fast as TL2 in yada), and by over 20% in kmeans (both variants) and labyrinth, while \nbeing about 10% faster than TL2 in genome, ssca2,and vacation under high contention. SwissTM outperforms \nTinySTM in ten STAMP workloads with eight threads, except for the kmeans benchmark under low contention \nwhere TinySTM has 4 There is no RSTM implementation of STAMP, due to API incompatibil\u00adity. RSTM provides \nan object-based API, while STAMP uses word-based API. This makes it dif.cult to simply plug-in RSTM into \ncurrent STAMP version. Figure 4. Execution time of SwissTM, TinySTM and RSTM in the Lee-TM benchmark; \ntop is memory, bottom is main circuit board input data set a slightly better performance (1% of difference). \nSwissTM out\u00adperforms TinySTM by over 45% with eight threads in intruder, kmeans under high contention, \nand yada, and by over 12% in bayes, genome, labyrinth,and ssca2, while being about 5% faster in vacation \n(both variants). SwissTM has good performance with lower thread counts, while scaling well as the number \nof concurrent threads increases. To summarize, SwissTM outperforms both TL2 and TinySTM in all STAMP \nbenchmark workloads. Lee-TM. Figure 4 compares the performance of SwissTM, RSTM, and TinySTM in the Lee-TM \nbenchmark.5 RSTM has the lowest performance mainly because of higher single object access over\u00adheads \n(objects in Lee-TM are very simple consisting of a single integer variable). SwissTM and TinySTM have \nvery similar perfor\u00admance, although SwissTM is faster by a small margin for all thread counts. Red-black \ntree. Finally, Figure 5 compares the performance of SwissTM, TL2, TinySTM, and RSTM in the commonly used \nred\u00adblack tree microbenchmark. RSTM delivers signi.cantly lower per\u00adformance than other three STMs due \nto its high overheads on single memory location accesses. These low-level overheads have most signi.cant \nimpact in microbenchmarks like this one. This is pre\u00adcisely the reason while SwissTM, that uses two locks \nfor each 5 We were not able to get Lee-TM to run with TL2 (we suspect there might be a bug in the x86 \nTL2 port). 1 2 3 4 5 6 7 8 Threads Figure 5. Throughput of SwissTM, TL2, TinySTM, and RSTM on red-black \ntree with range of 16384 and 20% of update operations Commit T1 t1 Commit t1 T1 t4t3 W RW VV RW Abort \nR Abort CommitT2 T2 t2 t4 t1t3 a) b) Figure 6. Disadvantages of lazy (left) and eager (right) con.ict \ndetection strategies memory location, has lower performance than TL2 and TinySTM, which use a single \nlock, in single thread executions. It is worth not\u00ading that a red-black tree is the only benchmark for \nwhich slightly higher overheads of using two locks have more than negligible per\u00adformance impact. SwissTM \noutperforms both TL2 and TinySTM when there are more than four threads and exhibits better scalabil\u00adity. \n 5. Dissecting the SwissTM Experience In this section, we evaluate individually the design choices under\u00adlying \nSwissTM: its con.ict detection strategy, the two-phase con\u00adtention manager, and the granularity of the \nlock table. Con.ict detection. Current state-of-the-art STMs typically detect both read/write and write/write \ncon.icts in the same way either as soon as con.icts occur (eagerly, e.g., TinySTM, McRT-STM and Bartok \nSTM), or at commit time (lazily, e.g., TL2). Detect\u00ading con.icts eagerly helps avoid wasting work of \ntransactions that are doomed to abort after a con.ict. Lazy con.ict detection, how\u00adever, is more optimistic \nand gives transactions more possibilities to commit. For example, Figure 6a depicts an execution of an \nSTM that uses lazy con.ict detection. There, transaction T2 spends time between t3 (commit time of T1)and \nt4 (commit time of T2) perform\u00ading work that is doomed to be roll-backed. The period between t3 and t4 \ncan be signi.cant with long transactions. It is worth noting that both T1 and T2 could commit with a \nlazy con.ict detection STM, if they both only write to V . However, pure write/write con\u00ad 1 2 3 4 5 6 \n7 8 Threads Figure 7. Throughput of eager and lazy con.ict detection schemes in read-dominated STMBench7 \n.icts are typically rare, as transactions usually .rst read some data and then subsequently update it. \nBecause of this, lazy con.ict de\u00adtection STMs react too slowly to write/write con.icts (which are good \nsigns that transactions cannot proceed in parallel) and results in transactions performing work that \nhas to be rolled back later. Figure 6b, gives an example execution of an STM that uses eager con.ict \ndetection. There, transaction T2 has to wait until time t4 be\u00adfore continuing, although it could commit \nalready at time t3 if lazy scheme was used. The waiting time of T2 might be signi.cant if T1 is very \nlong. SwissTM takes the best of both strategies it detects write/write con.icts eagerly and read/write \ncon.icts lazily. This combined strategy is bene.cial for complex workloads with long transactions because \nit (1) prevents transactions with write/write con.icts from running for a long time before detecting \nthe con.ict, and (2) allows short transactions having a read/write con.ict with longer ones to proceed, \nthus increasing parallelism. Figure 2 suggests that the mixed eager-lazy scheme gives better performance \nthan pure eager scheme which, in turn, outperforms lazy scheme (Figure 7). This does not say what kind \nof workloads bene.t most from the mixed scheme, and what part of the perfor\u00admance boost of SwissTM can \nbe attributed to its two-phase con\u00adtention manager (and not to the mixed con.ict detection). To answer \nthis question, we modi.ed slightly the Lee-TM benchmark. The performance of the original Lee-TM does \nnot seem to be in.uenced by the choice of a con.ict detection and contention management schemes, because \nthe transactions in Lee-TM are highly regular they .rst read and then write. We introduce a small irregularity \nin Lee-TM by adding a single object Oc that every transaction reads at its start. A small ratio R of \ntransactions (chosen randomly) also updates Oc, causing a read/write con.ict with all the other transactions. \nThe contention manager used by SwissTM does not provide a lot of bene.t in this case, as the num\u00adber \nof write/write con.icts introduced by this irregularity is not large (we keep R low in experiments). \nFigure 8 compares the performance of TinySTM and SwissTM for R of 0%, 5%, and 20%. Due to its con.ict \ndetection scheme, the SwissTM performance degrades only slightly even when R is relatively high (20%). \nAlso, SwissTM continues to scale well as the number of threads increases. On the other hand, the performance \nof TinySTM degrades signi.cantly even when R is only 5%, while with R of 20% it stops scaling already \nat three threads. We conclude here that applications exhibiting regular access patterns bene.t the most \nfrom lowering single-location access costs  1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 Threads Threads Figure 8. \nExecution time of SwissTM vs. TinySTM in irregular Figure 10. Throughput of the two-phase contention \nmanager vs. Lee-TM benchmark with memory circuit board input data setGreedy (in SwissTM) with the red-black \ntree Threads Figure 9. Throughput of Polka vs. Greedy (in RSTM) in the read\u00addominated workload of STMBench7 \nand are not signi.cantly in.uenced by the con.ict detection scheme itself. However, for applications \nwhere the access patterns intro\u00adduce even small irregularities, especially those creating longer\u00adlasting \nread/write con.icts, SwissTM s optimistic approach yields signi.cant bene.ts. Contention management. \nThe contention manager gets invoked in SwissTM only on write/write con.icts. The reasoning here is simple \nread/write con.icts are detected only at commit time of the writer, and it makes little sense for the \nreader to abort the writer that is already committing. This is why the reader waits until the writer \n(quickly) commits, before attempting to revalidate its read set. Figure 9 shows that Greedy performs \nbetter than Polka (which was shown previously to perform very well in a range of smaller scale benchmarks \n[41]) in STMBench7, our larger-scale bench\u00admark. However, Greedy performs poorly with short transactions, \nbecause all transactions increment a single shared counter at their start, which causes a lot of cache \nmisses and signi.cantly degrades performance and scalability (Figure 10). This problem is not no\u00adticeable \nwith longer transactions as the overhead caused by cache misses is relatively small compared to the work \nof the transactions themselves. As shown in Figure 10, our two-phase contention man- Threads ager overcomes \nthis issue completely, improving both performance and scalability over Greedy. This is because it allows \nall short and read-only transactions to commit without incrementing the shared counter used by the Greedy \nalgorithm, yet it provides the strong progress guarantees of Greedy for long ones. It might seem bene.cial \nto make transactions restart as soon as possible after con.icts that force them to rollback, as waiting \njust decreases the reaction time before the transaction re-executes. However, restarting immediately \ntends to increase contention on cache lines containing data that gets updated very frequently. Con\u00adsequently, \nshort back-offs after transaction rollbacks can improve performance. Figure 11 compares the performance \nof SwissTM in the STAMP intruder benchmark with and without the back-off scheme. (The intruder benchmark \nis a good example here, because it indeed contains a hot spot : a high number of transactions de\u00adqueue \nelements from a single queue.) The .gure shows that imme\u00addiately restarting transactions after rollback \ncauses scalability prob\u00adlem with eight threads. A simple randomized linear (in the number of successive \naborts) back-off scheme resolves the scalability issue. Finally, we evaluate the in.uence of our two-phase \ncontention manager on the overall performance of SwissTM. Figure 12 shows that the two-phase contention \nmanager improves performance by as 0.18 0.08 read 0.16 read/write write 0.06 0.14 0.04 Average speedup \n- 1 0.12 Speedup - 1 0.02 0 -0.02 -0.04 0.1 0.08 0.06 0.04 0.02 012345678 Threads Figure 12. Speedup \n(with 1 subtracted) of the two-phase con\u00adtention manager over the timid contention manager in SwissTM \nwith STMBench7 much as 16% in high-contention workloads. Its in.uence is lower in the read-dominated \nworkload, which is not surprising given that this workload is characterized by a small number of write/write \ncon.icts. Locking granularity. An important implementation choice in an STM is its lock table con.guration, \nin particular the size of the memory stripe that gets mapped to the same (lock table) entry. In\u00adcreasing \nthe size of memory stripes reduces locking and validation time, due to the data access locality, but \nincreases abort rates by introducing false con.icts when the memory stripe becomes too large. The optimal \nvalue for this parameter is application speci.c and we searched for the best value across all benchmarks \nwe used.6 Figure 13 depicts the average speedup (minus 1) of each logarith\u00admic lock granularity compared \nto all the others at eight threads (32 bit word). The .gure shows that the granularity of 24 bytes achieves \nthe best performance, with 23 and 25 being slightly slower. It is in\u00adteresting to note that the commonly \nused sizes of one word (22) and one cache line (26) have performance of 4% and 5% lower on average than \nthe one we select. We give a breakdown of these dif\u00adferences across benchmarks in Table 2. It is interesting \nto note here that, while using different lock granularities does impact performance, the impact of using \ncoarser lock granularities is not signi.cant enough to prevent SwissTM from scaling (e.g. due to increased \nnumber of false con.icts).  6. Concluding Remarks This paper presents SwissTM an effective compilation \nof STM design choices for mixed workloads characterized by non-uniform, dynamic data structures and various \ntransaction sizes. Those kinds of workloads are inherent to many applications that might be ex\u00adpected \nto signi.cantly bene.t from the STM paradigm and multi\u00adcore architectures. SwissTM signi.cantly outperforms \nstate-of-the\u00adart STMs in precisely such workloads, while also delivering good performance in smaller-scale \nscenarios. Not surprisingly, the design of SwissTM is a result of trial\u00adand-error. We reported in the \npaper on various choices that might have seemed natural, but revealed inappropriate. Besides those, we \nalso experimented with nested transactions (closed nesting) and multi-versioning, but we could not see \na clear advantage of those 6 Performance results presented in previous sections all use the same lock\u00ading \ngranularity of 24 bytes. -0.06 -0.08 2345678 Lock granularity (log2) Figure 13. Average speedup across \nall benchmarks used (with one subtracted) of locking granularities from 22 to 28 compared to all other \ngranularities, with 8 threads Difference in performance Benchmark 24 vs. 22 24 vs. 26 22 vs. 26 bayes \n0.16 0.81 0.57 genome 0.13 -0.03 -0.14 intruder 0 -0.04 -0.04 kmeans-high 0.19 0.4 0.18 kmeans-low 0.14 \n0.05 -0.08 labyrinth -0.12 -0.09 0.04 ssca2 0 0 0 vacation-high 0.14 -0.03 -0.15 vacation-low 0.12 -0.05 \n-0.15 yada 0 0.12 0.12 red-black tree -0.01 0 0.01 Lee-TM memory 0.01 -0.03 -0.04 Lee-TM main 0.02 -0.01 \n-0.02 STMBench7 read 0 -0.02 -0.02 STMBench7 read-write -0.01 -0.03 -0.02 STMBench7 write -0.04 -0.06 \n-0.02 Average 0.05 0.06 0.01 Table 2. Comparing three different lock granularities. Numbers represent \nrelative speedups (with one subtracted) with 8 threads techniques in the considered workloads. Further \nexperiments might be needed in this direction. Improving the programming model. Two main directions along \nwhich we plan to improve the semantical guarantees of SwissTM are: (1) adding compiler support, and (2) \nmaking SwissTM privatization\u00adsafe. There exists a number of STM C/C++ compilers that have open interfaces \nsupporting different STM libraries (e.g. [14, 29]) and we plan to integrate SwissTM with one of them. \nA conceptually simple algorithm for ensuring privatization-safety uses quiescence: every committing transaction \nT has to wait for all in-.ight transac\u00adtions to validate, commit, or abort. While this algorithm is simple, \nit would probably signi.cantly impact performance of SwissTM [42] and we plan to investigate other options, \npossibly using techniques similar to [28] or [25].  7. Availability SwissTM is open-source and available \nfrom: http://lpd.epfl. ch/site/research/tmeval. The source code of benchmarks used in the paper can be \ndownloaded from the same location.  Acknowledgments We would like to thank Hagit Attiya, Pascal Felber, \nEshcar Hillel, and Nir Shavit, as well as the anonymous reviewers, for their helpful comments and discussions \non the topic of this paper. This work is funded by the Velox FP7 European project and the Swiss National \nScience Foundation grant 200021-116745/1.  References [1] M. Abadi, A. Birrell, T. Harris, and M. Isard. \nSemantics of transactional memory and automatic mutual exclusion. In POPL, 2008. [2] A.-R. Adl-Tabatabai, \nB. T. Lewis, V. Menon, B. R. Murphy, B. Saha, and T. Shpeisman. Compiler and runtime support for ef.cient \nsoftware transactional memory. In PLDI, 2006. [3] C. S. Ananian, K. Asanovic, B. C. Kuszmaul, C. E. Leiserson, \nand S. Lie. Unbounded transactional memory. In HPCA, 2005. [4] M. Ansari, C. Kotselidis, K. Jarvis, M. \nLuj\u00b4an,C.Kirkham,and I. Watson. Lee-TM: A non-trivial benchmark for transactional memory. In ICA3PP, \n2008. [5] The atomic ops project. http://www.hpl.hp.com/research/ linux/atomic_ops. [6] C. Blundell, \nH. Cain, M. M. Michael, P. Wu, S. Chiras, and S. Chatterjee. Software transactional memory: Why is it \nonly a research toy? ACM Queue, Sept. 2008. [7] J. Cachopo and A. Rito-Silva. Versioned boxes as the \nbasis for memory transactions. Sci. Comput. Program., 63(2):172 185, 2006. [8] C. Cao Minh, J. Chung, \nC. Kozyrakis, and K. Olukotun. STAMP: Stanford transactional applications for multi-processing. In IISWC, \n2008. [9] D. Dice, M. Herlihy, D. Lea, Y. Lev, V. Luchangco, W. Mesard, M. Moir, K. Moore, and D. Nussbaum. \nApplications of the adaptive transactional memory test platform. In TRANSACT, 2008. [10] D. Dice, O. \nShalev, and N. Shavit. Transactional locking II. In DISC, 2006. [11] A. Dragojevi\u00b4c, R. Guerraoui, and \nM. Kapalka. Dividing transactional memories by zero. In TRANSACT, 2008. [12] R. Ennals. Ef.cient software \ntransactional memory. Technical report, Intel Research Cambridge, Jan 2005. [13] K. P. Eswaran, J. N. \nGray, R. A. Lorie, and I. L. Traiger. The notions of consistency and predicate locks in a database system. \nCommun. ACM, 19(11):624 633, 1976. [14] P. Felber, C. Fetzer, U. M\u00a8uller, T. Riegel, M. S\u00a8usskraut, and \nH. Sturzrehm. Transactifying applications using an open compiler framework. In TRANSACT, 2007. [15] R. \nGuerraoui, M. Herlihy, and B. Pochon. Polymorphic Contention Management. In DISC, 2005. [16] R. Guerraoui, \nM. Herlihy, and B. Pochon. Toward a theory of transactional contention managers. In PODC, 2005. [17] \nR. Guerraoui and M. Kapalka. On the correctness of transactional memory. In PPoPP, 2008. [18] R. Guerraoui, \nM. Kapalka, and J. Vitek. STMBench7: A benchmark for software transactional memory. In EuroSys, 2007. \n[19] T. Harris and K. Fraser. Revocable locks for non-blocking program\u00adming. In PPoPP, 2005. [20] T. \nHarris, S. Marlow, S. Peyton-Jones, and M. Herlihy. Composable memory transactions. In PPoPP, 2005. \n[21] T. Harris, M. Plesko, A. Shinnar, and D. Tarditi. Optimizing memory transactions. In PLDI, 2006. \n[22] M. Herlihy, V. Luchangco, M. Moir, and W. Scherer. Software transactional memory for dynamic-sized \ndata structures. In PODC, 2003. [23] M. Herlihy and J. E. B. Moss. Transactional memory: Architectural \nsupport for lock-free data structures. In ISCA, 1993. [24] J. R. Larus and R. Rajwar. Transactional Memory. \nMorgan&#38;Claypool, 2007. [25] Y. Lev, V. Luchangco, V. Marathe, M. Moir, D. Nussbaum, and M. Olszewski. \nAnatomy of a scalable software transactional memory. In TRANSACT, 2009. [26] Y. Lev, M. Moir, and D. \nNussbaum. PhTM: Phased transactional memory. In TRANSACT, 2007. [27] V. J. Marathe, M. F. Spear, C. Heriot, \nA. Acharya, D. Eisenstat, W. N. Scherer III, and M. L. Scott. Lowering the overhead of software transactional \nmemory. In TRANSACT, 2006. [28] V. J. Marathe, M. F. Spear, and M. L. Scott. Scalable techniques for \ntransparent privatization in software transactional memory. In ICPP, 2008. [29] Y. Ni, A. Welc, A.-R. \nAdl-Tabatabai, M. Bach, S. Berkowits, J. Cownie, R. Geva, S. Kozhukow, R. Narayanaswamy, J. Olivier, \nS. Preis, B. Saha, A. Tal, and X. Tian. Design and implementation of transactional constructs for c/c++. \nIn OOPSLA, 2008. [30] C. H. Papadimitriou. The serializability of concurrent database updates. J. ACM, \n26(4), 1979. [31] T. R. Pascal Felber and C. Fetzer. Dynamic performance tuning of word-based software \ntransactional memory. In PPoPP, 2008. [32] R. Rajwar, M. Herlihy, and K. Lai. Virtualizing transactional \nmemory. In ISCA, 2005. [33] T. Riegel, P. Felber, and C. Fetzer. A lazy snapshot algorithm with eager \nvalidation. In DISC, 2006. [34] RSTM home page. http://www.cs.rochester.edu/research/ synchronization/rstm. \n[35] B. Saha, A.-R. Adl-Tabatabai, R. L. Hudson, C. Cao Minh, and B. Hertzberg. McRT-STM: a high performance \nsoftware transactional memory system for a multi-core runtime. In PPoPP, 2006. [36] W. N. Scherer III \nand M. L. Scott. Contention management in dynamic software transactional memory. In CSJP, 2004. [37] \nN. Shavit and D. Touitou. Software transactional memory. In PODC, 1995. [38] M. F. Spear, V. J. Marathe, \nL. Dalessandro, and M. L. Scott. Privatization techniques for software transactional memory. In PODC), \n2007. [39] M. F. Spear, V. J. Marathe, W. N. Scherer III, and M. L. Scott. Con.ict detection and validation \nstrategies for software transactional memory. In DISC, 2006. [40] T. Sweeney. The next mainstream programming \nlanguage: a game developer s perspective. Invited talk at POPL, 2006. [41] I. William N. Scherer and \nM. L. Scott. Advanced contention management for dynamic software transactional memory. In PODC, 2005. \n[42] R. M. Yoo, Y. Ni, A. Welc, B. Saha, A.-R. Adl-Tabatabai, and H.- H. S. Lee. Kicking the tires of \nsoftware transactional memory: why the going gets tough. In SPAA, 2008.  \n\t\t\t", "proc_id": "1542476", "abstract": "<p>Transactional memory (TM) is an appealing abstraction for programming multi-core systems. Potential target applications for TM, such as business software and video games, are likely to involve complex data structures and large transactions, requiring specific software solutions (STM). So far, however, STMs have been mainly evaluated and optimized for smaller scale benchmarks.</p> <p>We revisit the main STM design choices from the perspective of complex workloads and propose a new STM, which we call SwissTM. In short, SwissTM is lock- and word-based and uses (1) optimistic (commit-time) conflict detection for read/write conflicts and pessimistic (encounter-time) conflict detection for write/write conflicts, as well as (2) a new two-phase contention manager that ensures the progress of long transactions while inducing no overhead on short ones. SwissTM outperforms state-of-the-art STM implementations, namely RSTM, TL2, and TinySTM, in our experiments on STMBench7, STAMP, Lee-TM and red-black tree benchmarks.</p> <p>Beyond SwissTM, we present the most complete evaluation to date of the individual impact of various STM design choices on the ability to support the mixed workloads of large applications.</p>", "authors": [{"name": "Aleksandar Dragojevi&#263;", "author_profile_id": "81435609511", "affiliation": "Ecole Polytechnique Federale de Lausanne, School of Computer and Communication Sciences, I&C, Lausanne, Switzerland", "person_id": "P1464262", "email_address": "", "orcid_id": ""}, {"name": "Rachid Guerraoui", "author_profile_id": "81100348136", "affiliation": "Ecole Polytechnique Federale de Lausanne, School of Computer and Communication Sciences, I&C, Lausanne, Switzerland", "person_id": "P1464263", "email_address": "", "orcid_id": ""}, {"name": "Michal Kapalka", "author_profile_id": "81100133264", "affiliation": "Ecole Polytechnique Federale de Lausanne, School of Computer and Communication Sciences, I&C, Lausanne, Switzerland", "person_id": "P1464264", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542494", "year": "2009", "article_id": "1542494", "conference": "PLDI", "title": "Stretching transactional memory", "url": "http://dl.acm.org/citation.cfm?id=1542494"}