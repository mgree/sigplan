{"article_publication_date": "06-15-2009", "fulltext": "\n Go with the Flow: Pro.ling Copies To Find Runtime Bloat Guoqing Xu Matthew Arnold Nick Mitchell Ohio \nState University IBM T.J. Watson Research Center IBM T.J. Watson Research Center xug@cse.ohio-state.edu \nmarnold@us.ibm.com nickm@us.ibm.com Atanas Rountev Gary Sevitsky Ohio State University IBM T.J. Watson \nResearch Center rountev@cse.ohio-state.edu sevitsky@us.ibm.com Abstract Many large-scale Java applications \nsuffer from runtime bloat. They execute large volumes of methods, and create many temporary objects, \nall to execute relatively simple operations. There are large opportunities for performance optimizations \nin these applications, but most are being missed by existing optimization and tooling technology. While \nJIT optimizations struggle for a few percent, performance experts analyze deployed applications and regularly \n.nd gains of 2\u00d7 or more. Finding such big gains is dif.cult, for both humans and compil\u00aders, because \nof the diffuse nature of runtime bloat. Time is spread thinly across calling contexts, making it dif.cult \nto judge how to improve performance. Bloat results from a pile-up of seemingly harmless decisions. Each \nadds temporary objects and method calls, and often copies values between those temporary objects. While \ndata copies are not the entirety of bloat, we have observed that they are excellent indicators of regions \nof excessive activity. By opti\u00admizing copies, one is likely to remove the objects that carry copied values, \nand the method calls that allocate and populate them. We introduce copy pro.ling, a technique that summarizes \nrun\u00adtime activity in terms of chains of data copies. A .at copy pro.le counts copies by method. We show \nhow .at pro.les alone can be helpful. In many cases, diagnosing a problem requires data .ow context. \nTracking and making sense of raw copy chains does not scale, so we introduce a summarizing abstraction \ncalled the copy graph. We implement three clients analyses that, using the copy graph, expose common \npatterns of bloat, such as .nding hot copy chains and discovering temporary data structures. We demonstrate, \nwith examples from a large-scale commercial application and sev\u00aderal benchmarks, that copy pro.ling can \nbe used by a programmer to quickly .nd opportunities for large performance gains. Categories and Subject \nDescriptors D.2.5 [Software Engineer\u00ading]: Testing and Debugging Debugging aids; D.3.4 [Program\u00adming \nLanguages]: Processors Memory management, optimiza\u00adtion, run-time environments General Terms Languages, \nMeasurement, Performance Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. Copyright c &#38;#169; 2009 ACM 978-1-60558-392-1/09/06. \n. . $5.00 Keywords Memory bloat, pro.ling, heap analysis, copy graph 1. Introduction As a community, \nwe have adopted guiding principles code quickly, favor reuse and dynamicity, integrate legacy functionality \nrather than rewrite it under the assumption that the compiler and garbage collector will take care of \nthe resulting runtime mess. This situation is especially common in large-scale Java applications de\u00adveloped \nusing many layers of custom and third party frameworks. After initial tuning has found the low-hanging \nfruit, these applica\u00adtions still consume excessive resources for what they accomplish. Java applications \nregularly suffer from systemic runtime bloat [18, 17]. Bloat consists of operations that, while not strictly \nnec\u00adessary for forward progress, are executed nonetheless. For exam\u00adple, we have worked with a commercial \ndocument management server, deeply diving into its inef.ciencies. We found that, to per\u00adform the seemingly \nsimple task of inserting a single small docu\u00adment in the database, this application invokes 25,000 methods \nand creates 3000 temporary objects. This is after the Just In Time (JIT) compiler s best efforts. With \nless than one person-week of manual tuning, work that only scratched the surface, a performance expert \nwas able to reduce the object creation rate by 66%. Vast improve\u00adments are possible, if only tuning were \neasier, or more automated. Consider a speci.c example where the server extracts name\u00advalue pairs from \na cookie that the client transmits in a serialized, string form. The methods that use these name-value \npairs expect Java objects, not strings. They invoke a library method to decode the cookie string into \na Java HashMap, yet another transient form of this very simple data. In the common case, the caller extracts \none or two elements from the 8-element map, and never uses that map again. Figure 1 illustrates the steps \nnecessary to decode a cookie in this application. Decoding a single cookie, an operation that occurs \nrepeatedly, costs 1000 method invocations and 35 temporary ob\u00adjects, after JIT optimizations. A hand-optimized \nspecialization for the common case that only requires one name-value pair invokes 4 invocations and constructs \n2 temporary objects. Today s JITs have sophisticated optimizers that offer important performance improvements, \nbut they are often unable to remove the penalty of systemic bloat. One problem is that the code in large \napplications is relatively free of hot spots. Table 1 shows a breakdown of the top ten methods from the \ndocument management server. This application executes over 60,000 methods, with no single method contributing \nmore than 3.19% to total application time, and only 14 methods contributing more than 1%. JITs are faced \nwith a plurality of important methods. The burden, with deserialize retrieve from client tokenize \nvalue  (a) Original version.   (b) Specialized version. Figure 1. The steps a commercial document \nmanagement server uses to decode a cookie; the original version tokenizes and returns the entire map, \neven if the caller needs only one name-value pair. method CPU time HashMap.get 3.19% Id.isId 2.84% String.regionMatches \n2.12% CharToByteUTF8.convert 2.04% String.hashCode 1.77% String.charAt 1.70% SimpleCharStream.<init> \n1.65% ThreadLocalMap.get 1.32% String.toUpperCase 1.30% Table 1. In a commercial document management \nserver, there is no hot method that can be optimized for an easy big gain. current JIT technology, is \non the method inliner to bundle together code into larger, hopefully optimizable, regions. Forming perfect \ncode regions, and then optimizing them, is an immensely challenging problem [24]. Optimizations that \ncan be easily performed by a programmer, such as a moving a call to a side-effect-free method out of \na loop, can require heroic JIT ef\u00adfort to achieve the same effect. That call may ultimately perform thousands \nof method invocations with call stacks hundreds deep, and allocate many objects. Automatically performing \nsuch a trans\u00adformation requires dozens of powerful analyses to work together .awlessly; a single missed \nopportunity can render the call immov\u00adable. Add in language features that restrict optimization, such \nas precise exceptions, and there is little hope for a fully automated solution. Our work advocates a \nnew approach that is not intended to re\u00adplace JIT optimization, but to complement it. Through a combina\u00adtion \nof metrics and analyses focused on bloat, we hope to quickly guide developers to the problematic areas \nof the application, al\u00adlowing them to refactor to avoid the problem. A small handful of performance experts \nare already capable of performing this task manually; our goal is to automate as much of it as possible, \nthus lowering the bar for tuning systemic bloat. The burden cannot re\u00admain solely on the shoulders of \nexperts: the problems of excessive bloat will become increasingly painful as cores become simpler, bandwidth \nper core goes down, and we can t rely on clock speed increases to ameliorate ever-increasing levels of \ninef.ciency. Bellwethers of Bloat The inef.ciencies at the heart of the cookie decoding example are common \nto many bloated implementations. In these implementations, there is often a chain of information .ow \nthat carries values from one storage location to another, often via temporary objects [18]; e.g. as visualized \nin Figure 1. Bloat of this form manifests itself in a number of ways: temporary structures to carry values, \nand a sea of method invocations that allocate and initialize these structures, and copy data between \nthem. In our experience, it is this data copying activity that is an excel\u00adlent bellwether of bloat. \nThis is not to say that one must only tune copying activity to lessen the burden of good software engineer\u00ading. \nRather, by tuning in a way that reduces the need for copying, one also reduces the attendant object creation \nand initialization, and method invocation activity. The specialized cookie decoding pro\u00adcess avoids not \nonly most of the copies, but also the construction and population of the temporary HashMap data structure, \nand its many unused key and value Strings. In Section 2, we introduce a way of pro.ling information .ows, \nrather than control .ows. These pro.les distinguish copies from other activities, such as arithmetic \noperations. We speci.cally use the volume of copies as a way to quantify bloat. We show how copies are \nnot targeted by current production Java JIT compilers, despite being highly concentrated. This is in \ncontrast to the lack of concentration in execution time: a small number of methods explain most of the \ncopies, but not most of the time. Copies are concentrated, even in the more complex applications. For \nexample, in the document management server, the top .fty consumers of time explain only 24% of total \nexecution time; the top .fty copying methods explain 82% of copies. Flat summaries that count copies \nare a good .rst step, but they are not suf.cient to help programmers alleviate bloat. Copies, by their \nnature, span methods and classes in cross-cutting ways. The specialized cookie decoding process shown \nin Figure 1(b) is neither the result of tuning the HashMap put or get methods, nor of tuning the HashMap \nstorage structure. To specialize this scenario requires understanding the chains of copies: which storage \nlocations carry values, and which methods enact the copies. During program execution, there will be billions \nof copy chains. To combat this blowup, in Section 3, we introduce an abstraction, the copy graph, that \nconcisely summarizes chains of copies. We have implemented a dynamic information .ow framework in the \nJIT compiler of the IBM J9 commercial JVM, which com\u00adputes copy pro.les and forms a copy graph as the \nprogram runs. Section 4 provides implementation details that were necessary to make it possible to track \ninformation .ow in a way that scales to production applications. The copy graph itself consumes a small \namount of memory, plus two words for every live object in the ap\u00adplication. To facilitate our initial \nimplementation, we store these two words in a side shadow heap, to avoid modifying the object header \nin the VM. The current implementation imposes a slow\u00addown of about 37 times, on average, across the test \nprograms. Al\u00adthough this overhead is signi.cant, it has not limited our ability to collect data from \nlarge production applications. The focus of this work is on the results of the analysis, not how cheaply \nthey can be collected. In Section 5, we introduce three client analyses that use the copy graph to generate \nuseful reports: hot copy chains, a clone detection analysis, and an approximation of escape analysis. \nIn Section 6, we provide examples of using these client analyses to .nd real problems of bloat. For example, \nwe very quickly found a performance defect in the DaCapo [4] bloat benchmark, and quickly implemented \na .x that reduced object creation rate by 65%, and execution time by 30%. We also quickly found an issue \nin the DaCapo Eclipse benchmark, and implemented a .x that resulted in a 9.3% performance improvement \nto that benchmark. The contributions of this paper are: A methodology, copy pro.ling, that identi.es \nhigh-overhead activity in terms of copies and chains of copies.  A runtime framework, implemented in \nthe JIT compiler of the J9 VM, that generates pro.les of information .ow, and also tracks the details \nof those .ows during program execution.   copies comparisons ALU operations total stores original w/ \nopt. handtuned handtuned w/ opt. total loads 0% 25% 50% 75% 100% 125% Counts Relative to the original \nrun with no JIT optimizations Figure 2. A breakdown of activity in a document processing server application. \nThe baseline, at 100%, is the original code run with JIT optimizations disabled; we compare this to the \noriginal code with JIT optimizations enabled, and to an implementation with a dozen hand-tunings. The \nJIT optimizer does not tune the number of copies or comparison instructions, and in some cases makes \nthings worse. The copy graph, an abstraction of chains of copies.  Three client analyses of the copy \ngraph: one that identi.es hot copy chains, a second that .nds pairs of allocation contexts whose allocated \ndata structures are deep clones of each other, and a third that .nds temporary data structures by identifying \nthe tops of structures that do not .ow through the heap.  2. Copy Pro.ling Bloat often stems from excessive \nwork done along data .ows. In this section, we introduce the notion of pro.ling operations along these \n.ows, with a focus on copies. A copy is a load-store pair that transfers a value, unmodi.ed, from one \nstorage location to another. A.at copy pro.le is the analog of execution time pro.le, except that it \ncounts copies rather than time. The copy pro.les, and the rest of the reports described in this paper, \nare in terms of heap locations and the methods that copy be\u00adtween them. In the pro.les, a copy operation \nis associated with the method that performed the write to the heap. Though it is necessary to track through \nstack locations (as described in Section 4), in order to determine whether a store is the second half \nof a copy, the reports do not include that level of detail. Since stack variables will likely be assigned \nto registers, chains of copies between stack locations will usually involve only register transfer operations. \nThey are also more likely to be optimized by conventional data.ow analysis. A simple count of the number \nof copies is a useful way to gauge the goodness of an implementation, and the effectiveness of the JIT \nat tackling certain classes of bloat. Figure 2 shows a comparison of four scenarios of the document management \nserver. The baseline, at 100%, represents the performance of the original code with JIT optimizations \ndisabled, in terms of the number of copy operations that were performed during a 10 minute load run. \nWe compare this baseline to the original code with JIT optimizations enabled, and to a version of the \ncode that had been hand-tuned to improve overall performance (both with and without optimizations). We \nalso show the number of comparison operations, the number of ALU oper\u00adations, and the total number of \nloads and stores. Observe that the JIT is good at what you d expect: reducing ALU operations, and the \ntotal number of loads and stores; common subexpression elimi\u00adnation probably explains much of these effects. \nOn the other hand, the JIT does not greatly affect the number of copies; it also has no great affect \non the number of comparison instructions. Compar\u00adisons are often a sign of over-protective or over-general \nimplemen\u00ad top method top 10 methods top 50 methods bloat chart luindex jython antlr pmd hsqldb lusearch \nfop eclipse xalan document server 0% 25% 50% 75% 100% Fraction of Pure Copies that Occurs within the \nTop-N Methods Figure 3. Copy concentration: a small number of methods explain most of the copies in \nthe DaCapo benchmarks, version 2006-10-MR2, and the document management server. top method top 10 methods \ntop 50 methods bloat luindex pmd chart fop lusearch antlr hsqldb ecilpse jython xalan document server \n0% 25% 50% 75% 100% Fraction of Execution Time that Occurs within the Top-N Methods Figure 4. Time concentration: \nin contrast to copies, which are con\u00adcentrated even for complex applications, the time spent in methods \nis only concentrated for the simpler benchmarks. tations. These coding practices also lead to bloat. \nThe hand-tuned implementation greatly lowers both the number of copies and the number of comparison operations. \nFlat copy pro.les show that copies serve as good indicators of problems. From them, we learn that copy \nactivity is concentrated in a small number of methods. From the copy pro.les for the DaCapo benchmark \nsuite1 [4] and the document management server, we observe the concentration of copies. Figure 3 shows \nthat, across the board, a small number of methods explain most of the copy activity in these programs. \nEven just the top method explains at least 12% of the copies, often much more. For comparison, Figure \n4 shows the concentration of execution time in methods. As expected, the more complex applications, such \nas the Eclipse DaCapo benchmark and the document management server, have very .at execution time method \npro.les; this is in contrast to the highly concentrated copy pro.les for those same programs. 3. Pro.ling \nCopy Chains Individual copies are usually part of longer copy chains. Optimiz\u00ading for bloat requires \nunderstanding the chains as a whole, as they 1 We used DaCapo version 2006-10-MR2. 2 Object[] elems; \nint count; 3 List(){ elems = new Object[1000]; } 4 List(List l){ this(); // call default constructor \n5 for(Iterator it = l.iterator(); it.hasNext();) 6 { add(it.next()); } } 7 void add(Object m){ 8 Object[] \nt = this.elems; 9 t[count++] = m; 10 } 11 Object get(int ind){ 12 Object[] t = this.elems; 13 Object \np = t[ind]; return p; 14 } 15 Iterator iterator(){ 16 return new ListIterator(this); 17 } 18 } 19 class \nListIterator{ 20 int pos = 0; List list; 21 ListIterator(List l){ 22 this.list = l; 23 } 24 boolean hasNext(){ \nreturn pos < list.count -1;} 25 Object next(){ return list.get(pos ++);} 26 } 27 class ListClient{ 28 \nList myList; 29 ListClient(List l){ myList = l; } 30 ListClient slowClone(){ 31 List j = new List(myList); \n32 return new ListClient(j); 33 } 34 ListClient fastClone(){ 35 return new ListClient(myList); 36 } 37 \n} 38 static void main(String[] args){ 39 List data1 = new List(); 40 for(int i = 0; i < 1000; i++)data1.add(new \nInteger(i)); 41 List data2 = new List(); 42 for(int i = 0; i<5; i++){data2.add(new String(args[i])); \n43 System.out.println(data2.get(i));} 44 ListClient c1 = new ListClient(data1); 45 ListClient c2 = new \nListClient(data2); 46 ListClient new_c1 = c1.slowClone(); 47 ListClient new_c2 = c2.fastClone(); 48 } \n Figure 5. Running example. may span large code regions that need to be examined and trans\u00adformed. We \nnow show how to form an abstraction, the copy graph, that can be used to identify chains of copies. DEFINITION \n1. A copy chain is a sequence of copies that carry a value through two or more heap storage locations. \nEach copy chain node is a heap location. Each edge represents a sequence of copies that transfers a value \nfrom one heap location to another, abstract\u00ading away the intermediate copies via stack locations, parameter \npassing, and value returns. The heap locations of interest are .elds of objects and elements of arrays. \nA copy chain ends if the value it carries is the operand of a computation, which produces a new value, \nor is an argument to a native method. It is important to note that, in a copy chain, each maximal-length \nsubsequence of stack copies is abstracted by a single edge directly connecting two heap locations. 3.1 \nA Motivating Example The code in Figure 5 is used for illustration throughout the paper. The example \nis based on a common usage scenario of Java col\u00adlections. A simple implementation of a data structure \nList is used by a client ListClient. ListClient declares two clone methods fastClone and slowClone, which \nreturn a new ListClient ob\u00ad  6 add(it.next()); Step 3  9 t[count++] = m;  Step 2 Write(O3.ELM) Read(O3.ELM) \n 13 p = t[ind]; return p; Step 1 25 return list.get(pos ++); Figure 6. A copy chain due to ListClient.slowClone.Line \nnumbers 6, 9, 13, and 25 correspond to the code in Figure 5. ject by reusing the old backing list and \nby copying list elements, respectively. The entry method main creates two lists data1 and data2 and initializes \nthem with 1000 Integer and 5 String ob\u00adjects (lines 40 and 42). The two lists are then passed into two \nListClient objects and eventually two new ListClient objects are created by calling slowClone and fastClone. \nFor simplicity, the approach is described at the level of Java source code, although our implementation \nworks with a lower-level virtual machine inter\u00admediate representation (IR). Figure 6 depicts the steps \nin the creation of a single-edge copy chain. This chain results from the invocation of slowClone (line \n46) which copies Integer object references from the array refer\u00adenced by .eld elems of one List to the \narray referenced by .eld elems of another List. The source array and the target array will be denoted \nby O3 since they are created at line 3 in the code. (For now, the reader can ignore the naming scheme; \nit will be discussed shortly.) The copy chain in Figure 6 is O3.ELM . O3.ELM , where ELM represents any \narray element. To represent the source and the sink of the data propagated along a copy chain, we can \naugment the chain with two nodes: a producer node added at the beginning, and a consumer node added at \nthe end. The producer node can be a constant value, a new X expression, or a computation operation representing \nthe creation of a new value. The consumer node has only one instance (denoted by C ) in the copy graph, \nshowing that the data goes to a computation operation or to a native method. These two types of nodes \nare not heap locations, and are added solely for the purpose of subsequent client analyses. Note that \nnot every chain has these two special nodes. For the producer node, we are interested only in reference-typed \nvalues because they are important for further analysis and program understanding. Thus, chains that propagate \nvalues of primitive types do not have producer nodes. Not every piece of data goes to a consumer and \ntherefore not every chain has a consumer node. The absence of a consumer is a strong symptom of bloat \nand can be used to identify performance problems. An example of a full augmented copy chain starting \nfrom producer O42 (i.e., new String)is O42 . O3.ELM . C. This chain ends in consumer node C because the \ndata goes into method println which eventually calls native method write. Pro.ling copy chains can be \nextremely space expensive, be\u00adcause it requires maintaining a distinct node for each heap loca\u00adtion on \neach copy chain, regardless of whether chains have shared heap locations. In addition, for each heap \nlocation, it is neces\u00adsary to maintain the history information regarding all chains that go through this \nlocation, which may incur signi.cant running time overhead. To make the analysis scale to large applications, \nwe ap\u00adply a series of abstractions on copy chains. These abstractions are also essential for producing \nsummarized reports that do not over\u00adwhelm the tool user with millions of chains. The .rst abstraction \nis to merge all copy chains in a copy graph, so that nodes shared among chains do not need to be maintained \nseparately. In addition, the copy graph construction algorithm can be designed to pro.le only graph edges \n(i.e., one-hop heap copy), which is much more ef.cient than pro.ling of entire chains. 1000,4 1000, \n4 5, 4 C 5, 4 1, 4O41 1, 4 O39 1, 4 1, 4  O44 O45 (a) Context-insenstive copy graph 1000, 4 1000, \n4O40 5, 4O42 5, 4  C 1, 4O41 1, 4 O39 1, 4 1, 4 O44 O45 (b) 1-object-senstive copy graph Allocation \nsite node (producer)  Heap location node C Consumer node Copy graph edge Figure 7. Partial copy graph \nwith context-insensitive and context\u00adsensitive object naming. DEFINITION 2. A copy graph G =(N , E) has \nnode set N. AL.IF .SF.{C}.Here AL is the domain of allocation sites Oi which serve as producer nodes \nand do not have any incoming edges. IF is the domain of instance .eld nodes Oi .f . SF is the domain \nof static .eld nodes. C is the consumer node; it has only incoming edges. The edge set is E.N\u00d7 Integer \n\u00d7 Integer \u00d7N . Each edge is annotated with two integer values: the frequency of the heap copy and the \nnumber of copied bytes (i.e., 1, 2, 4, or 8). There could be many different ways to map the run-time \nexe\u00adcution to these abstractions. The rest of this section describes the mapping used in our current \nwork; future work could explore other choices with varying cost, precision, and usefulness for tool users. \nObject naming scheme. Following an abstraction technique widely adopted in static analysis, an allocation \nsite is used to repre\u00adsent the set of run-time instances that it creates. Similarly, all heap locations \nthat an instance .eld dereference expression a.f repre\u00adsents are projected to a set of nodes {Oi.f} such \nthat the objects that a points to are projected to set {Oi}. Applying this abstraction reduces the number \nof allocation site nodes AL and instance .eld nodes IF. Each element of an array a is represented by \na special .eld node Oa .ELM ,where Oa denotes the allocation site of a and ELM represents the .eld name. \nIndividual array elements are not distinguished: considering each element separately may introduce infeasible \ntime and space overhead. For illustration, consider the partial copy graph in Figure 7(a). The .gure \nshows only paths starting from nodes in method main in the running example. An allocation site is named \nOi,where i is the number of the code line containing the site. Each copy graph edge is annotated with \ntwo numbers: its frequency and the number 1000,4 of bytes it copies. For example, edge O40 ----. O3.ELM \ncopies the Integer objects created at line 40 into the array referenced by data1 s elems .eld. This edge \nconsists of a sequence of copies via parameter passing (line 40 and line 9). This sequence of copies \noccurs 1000 times, and each time 4 bytes of data are transferred. 1000,4 1000,4 Both O40 ----. O3.ELM \nand O3.ELM ----. O3.ELM are hot edges: their frequencies and the total number of bytes copied are much \nlarger than those of other edges. When there exists a performance problem in the program, a better design \nmight be needed to eliminate these copies. It is important to note again that nodes that represent different \nobjects may be merged due to the employed abstraction. For exam\u00adple, although variable t at line 9 points \nto different objects at run time, the array element node t[count++] is represented by a sin\u00adgle node \nO3.ELM , regardless of the List object that owns the ar\u00ad 1000,4 ray. Consider the self-pointing edge \n----. at node O3.ELM .The edge captures the data .ow illustrated in Figure 6. This sequence of copies \nmoves object references from the array pointed-to by O39.elems to the array pointed-to by O31.elems. \nSince both arrays are represented by O3, their elements are merged into O3.ELM in the copy graph and \nthis self-pointing edge is generated. Merging of nodes could lead to spurious copy chains that are inferred \nfrom the copy graph. For example, from Figure 7(a), one could imprecisely conclude that both O40 and \nO42 will eventually 1000,45,4 be consumed, because both edges ----. and - . can lead to con\u00adsumer node \nC . The cause of the problem is the context-insensitive object naming scheme, which maps each run-time \nobject to its al\u00adlocation site, regardless of the larger data structure in which the object appears. \nIn order to model copy chains more precisely, we introduce a context-sensitive object naming scheme. \n 3.2 Context Sensitivity When naming a run-time object, a context-sensitive copy graph construction algorithm \ntakes into account both the allocation site and the calling context of the method in which the object \nis al\u00adlocated. Existing static analysis work proposes two major types of context sensitivity for object-oriented \nprograms: call-chain\u00adbased context sensitivity (i.e., k-CFA) [25], which considers a sequence of call \nsites invoking the analyzed method, and object\u00adsensitivity [16], in which the context is the sequence \nof static ab\u00adstractions of the objects (i.e., allocation sites) that are run-time re\u00adceivers of methods \npreceding the analyzed method on the call stack. Of particular interest for our work is the object-sensitive \nnaming scheme because, to a large degree, it re.ects object ownership and is suitable for improving the \nanalysis precision for real-world ap\u00adplications making use of a large number of object-oriented data \nstructures. Figure 7(b) shows the 1-object-sensitive version of the copy graph, in which an object is \nnamed using its allocation site together with the allocation site of the receiver object of the method \nin which the object is created. For objects created in a constructor, the context is usually their run-time \nowner. By adding context sensitivity, paths that start from O40 and O42 do not share any nodes. Note \nthat there are no contexts for nodes O39,...,O45 because they are created in static method main which \ndoes not have a receiver object. Although longer context strings may increase precision, our tool limits \nthe length of the context to 1 since it could be prohibitively expensive (both in time and space) to \nemploy longer contexts in a dynamic analysis. 4. Runtime Information Flow Tracking This section presents \nthe details of the copy pro.ling technique. We modi.ed J9, a production virtual machine developed by \nIBM, to support dynamic information .ow pro.ling: all memory locations in the program have a corresponding \nshadow location (c.f. [19]). This allows a dynamic analysis to tag all application data with data.ow \nmetadata information, which we refer to as tracking data. As the program executes and application data \nis read or written, the information .ow analysis updates the corresponding tracking data. Although we \nfocus on pro.ling of copies in this paper, various other client analyses can be implemented in this framework \nby rede.ning the shadow data initialization and .ow transfer functions. 4.1 Shadow Locations Our information \n.ow infrastructure supports shadowing of all memory in the application, including local variables, static \n.elds, arrays, and object .elds. Local variables are shadowed simply by introducing an extra location \non the stack. Tracking data is also passed interprocedurally through parameters and return values. A \ntracking stack is maintained for passing shadow variables for pa\u00adrameters, as well as return values. \nShadowing of object .elds is supported by use of a shadow heap [19]. The shadow heap is a contiguous \nregion of memory equal in size to the Java heap. Scratch space for every byte of data in the Java heap \ncan be referenced quickly by adding a constant offset to the address location. A non-moving garbage collector \nis used so the address of objects does not change during the execution. A moving collector could be used \nas long as it is modi.ed to move the corresponding shadow data when moving an object. Doubling size of \nthe heap is a signi.cant space overhead, but is not a limitation in practice, even for large applications. \nWith a 1-gigabyte Java heap and a 1-gigabyte shadow heap, we were able to successfully run all programs \nwe encountered, including large production web server applications. 4.2 Copy Graph Construction The \ncopy graph construction algorithm consists of two main com\u00adponents: (1) compile time instrumentation, \nwhich occurs at run time during JIT compilation, and (2) run-time pro.ling. To avoid having to modify \nboth the interpreter and the JIT, we run the VM in a JIT-only mode such that all methods in the program \nare com\u00adpiled by the JIT prior to their .rst invocation, allowing the tool to track data .ow throughout \nthe entire program. Copy graph construction requires the ability to tag an object with its allocation \nsite, so the allocation site information can be ef.ciently looked up at run time. To perform this lookup \nquickly we rely on the shadow heap. When an object is allocated, we store its allocation site ID and \nits context allocation ID in its shadow location, so it can be referenced through operation *(objAddr \n+ distance). This provides the ability to quickly store and retrieve the allocation site for every object. \n 4.3 Data Structure Design The data structure design for the copy graph is important for mini\u00admizing \noverhead. The goal of the design is to allow ef.cient map\u00adping from a run-time heap location to its name \n(which in our analy\u00adsis is a copy graph node address). Figure 8 shows an overview of the data structures \nfor the copy graph. Static .eld nodes are stored in a singly-linked-list that is constructed at instrumentation \ntime. The node address is hard-coded in the generated executable code, so that the retrieval of nodes \ndoes not contribute to running time (thus, the analysis does not need to use the shadow locations for \nstatic .elds). Each node has an edge pointer, which points to a linked list of copy graph edges that \nleave this node. Edge adding occurs at run time. If an existing edge is found for a pair of a source \nnode and a target node, a new edge is not added. Instead, the frequency .eld of the existing edge is \nincremented. The size .eld (i.e., number of bytes) can be determined at compile time by inspecting the \ntype of data that the copy transfers. Allocation site nodes and instance .eld nodes are implemented using \narrays to allow fast access. For each allocation site, a unique integer ID is generated at compile time \n(the IDs start from 0). The Edge Name Link pointer Static field node (a) Data structure for static field \nnodes Context Field Edge ID name ptr (b)Data structure for allocation nodes and instance fields nodes \nfor 1-object-sensitive copy graph Figure 8. Data structure overview. ID is used as the index into an \narray of allocation headers. Each allocation header corresponds to one ID, and points to an array of \nallocation nodes and toanarrayof .eld nodes, both speci.c to this ID. For a context-insensitive copy \ngraph, the allocation node array for the ID has only one element. For the context-sensitive copy graph \nthat requires a unique allocation node for each calling context (i.e., the allocation site ID of the \nreceiver object of the surrounding method), each element of the allocation node array corresponds to \na different calling context. In the current implementation the array does not grow dynamically, thus \nthe number of calling contexts for each allocation site is limited to a pre-de.ned value c.We have experimented \nwith different values of c and these results are reported in Section 7. An encoding function maps an \nallocation site ID representing a context to a value in [0,c 1]; currently, we use a simple mod operation \ncontextAllocId % c to encode contexts. As reported in Section 7, very few contexts for an object have \ncon.icts (i.e., they map to the same value) when using this function. A default c value of 4 was used \nfor the studies described in Section 6. The .eld node array is created similarly. The order of different \n.elds in the array is dependent on the offsets of these .elds in the class. We build a class metadata \ntable at the time the class is resolved by the JIT. The table sorts .elds based on their offsets, and \nmaps each .eld to a unique ID (starting from 0) indicating its order in the .eld node array. For each \ninstance .eld declared in the type (and all its supertypes) instantiated at the allocation site, there \nare 1 (i.e., for context-insensitive naming) or c (i.e., for 1-object\u00adsensitive naming) entries in the \n.eld node array. For example, consider an instance .eld dereference a.f for which the allocation site \nID of the object pointed-to by a is 1000, the corresponding context allocation ID is 245, the offset \nof f is 12, and this offset (at compile time) is mapped to .eld ID i = class metadata[12]. The corresponding \ncopy graph node address can be obtained from the element with index c * i + 245 % c in the array pointed-to \nby column Fields of alloc headers[1000]. [1. local=alloc] SH (i)=(AllocID (new O), SH (this)&#38;0xFFFFFFFF \n) CG' = CG . CreateAllocHeaderEntry(O, AllocID(new O)) E f SH (i): addr rhs shadow i = addrrhs CG .i=new \nO CG' [2. local=static] E f F : addrrhs CG' = CG shadow i = addrrhs CG .i=F CG' [3. local=instance .eld \ndereference] E f (SH (a), O.set(f)) : addr rhs CG' = CG shadow i = addrrhs CG .i=a.f CG' [4. local=local] \nCG' = CG shadow i = shadow j CG .i=j CG' [5. static=local] E f F : addrlhs CG' = CG . CreateEdge(shadow \ni, addr lhs ) CG .F =i CG' [6. instance .eld dereference=local] E f (SH (a), O.set(f)) : addr lhs CG' \n= CG . CreateEdge(addr lhs , shadow i) CG .a.f =i CG' [7. local=computation] edgec = CreateEdge(shadow \nc, C ) edged = CreateEdge(shadow d, C ) CG' = CG . edgec . edged CG .i=c+d CG' Figure 9. Run-time effects \nof instrumentation.  4.4 Instrumentation Relation CG .a CG' Our instrumenter takes the assembly-like \nJ9 intermediate represen\u00adtation (IR) as input, and feeds the instrumented IR to the code gen\u00aderator. \nThe goal of the instrumentation is to insert code to propagate the address of a copy graph node at run \ntime. The copy graph node represents the heap location from which a piece of data comes. The intraprocedural \ninstrumentation is illustrated at a high-level in Figure 9. Based on the techniques described earlier, \nthe name environment E maps each heap location to the address of its cor\u00adresponding copy graph node. \nFunction SH (i.e., shadow heap) re\u00adturns, for each object, its allocation site ID and its context allo\u00adcation \nsite ID. For example, E f SH (i) : addrrhs in rule 1 says that given the (allocation ID, context ID) \npair for the heap object pointed-to by local variable i, E maps this pair to the copy graph node at address \naddrrhs .Here addrrhs and addrlhs represent the addresses of the copy graph nodes for the heap locations \ncorre\u00adsponding to the right/left-hand-side expressions of an instruction. Each rule describes the update \nof the copy graph (i.e., CG) for a type of instruction, with unprimed and primed symbols represent\u00ading \nthe copy graph before and after the instruction is executed. In rule 1, the shadow of local variable \ni is assigned the address of the copy graph allocation node representing the newly-created heap object. \nIf the method containing the allocation site is an in\u00adstance method, the context object is the object \nreferenced by this. The bit operation (&#38; 0xFFFFFFFF) retrieves the lower 4 bytes from the shadow \nheap location, which stores the allocation site ID for this itself (while the higher 4 bytes contain \nthe allocation site ID of this s context). A static method does not have a context. Before each call \nsite in a caller, the shadow variables for the actual parameters are pushed on the tracking stack, and \nthey are popped at the entry of the callee method. Similarly, at the exit of the callee method, the shadow \nvariable for the returned value is pushed, and it is popped after the call site in the caller. Data carried \nby exception .ow is not tracked by the tool. Once a heap load operation is seen (rules 2 and 3), the \naddress of the node representing the heap location is stored in the shadow variable. Upon a heap store \n(rules 5 and 6), an edge with the source node address (contained in the shadow variable) and target node \naddress (obtained from the heap location) is created, and the graph is updated with this new edge. In \nrule 7, once data comes to a computation instruction, we create edges to connect the copy graph node \nfor each participating variable with the consumer node C . 5. Copy Graph Client Analyses This section \npresents three client analyses implemented in J9. These clients analyze the copy graph and generate reports \nthat are useful for understanding run-time behavior and pinpointing per\u00adformance bottlenecks. Due to \nspace limitations, the analyses are described informally, without low-level details. 5.1 Hot Copy Chains \nGiven a copy chain with frequency n and data size s, its copy volume is n \u00d7 s. The copy volume of a chain \nis the total amount of data transmitted along that chain. Chains with large copy volumes are more likely \nto be sources of performance problem. Another important metric is chain length the longer a copy chain \nis, the more wasteful memory operations it contains. Considering both factors, we compute a waste factor \n(WF) for each chain as the product of length and copy volume. The goal of the hot chain analysis is to \n.nd copy chains that have large WF values. The .rst issue is how to recover chains from copy graph edges. \nWe use a brute-force approach which traverses the copy graph and computes the set of all distinct paths \nwhose length is smaller than a pre-de.ned threshold value. If a path is a true copy chain, all its edges \nshould have the same frequency. Based on this observation, the WF for each path is computed by using \nits smallest edge frequency as the path frequency. The resulting copy graph paths are ranked based on \ntheir WF values, and the top paths are reported. An example of a chain reported for benchmark antlr from \nDaCapo is as follows: (355162, 2): array[antlr/PreservingFileWriter:61].ELM [java/io/BufferedWriter.write:198, \n177581, 2] . array[java/io/BufferedWriter:108].ELM  [sun/io/CharToByteUTF8.convert:262, 177759, 2] . \narray[sun/nio/cs/StreamEncoder$ConverterSE:237].ELM The chain contains three nodes connected by two edges. \nThe pair (355162,2) shows the WF and the chain length. Each node in this example is an array element \nnode. For instance .eld nodes and array element nodes, the allocation site of the base object is also \nshown. In this example, line 61 in class antlr.PreservingFileWriter creates the array whose elements \nare the sources of the copy chain. An edge shows the method where its last copy operation occurs  (e.g., \nline 198 in method java.io.BufferedWriter.write), the edge frequency (e.g., 177581), and the data size \n(e.g., 2 bytes). 5.2 Clone Detector Many applications make expensive clones of objects. A cloned ob\u00adject \ncan be obtained via .eld-to-.eld copies from another object (e.g., as usually done in clone methods), \nor by adding data held by another object during initialization (e.g., many container classes have constructors \nthat can initialize an object from another con\u00adtainer object). Although clones are sometimes necessary, \nthey in\u00addicate the existence of wasteful operations and redundant data. For instance, in our running \nexample, slowClone initializes a new list by copying data from an existing list. Invoking this method \nmany times may cause performance problems. The goal of this analysis is to .nd pairs of allocation sites, \neach of which represents the top (i.e., root) of a heap object subgraphs, such that a large amount of \ndata is copied from one subgraph to the other. a,b For each copy graph edge O1.f - . O2.g,where f and \ng are instance .elds, the value of a\u00d7b is counted as part of the direct .ow from O1 to O2. The total \ndirect .ow for pair (O1,O2) shows how many bytes are copied from .elds of O1 to .elds of O2. Next, the \nanalysis considers the indirect .ow between objects. Suppose that some .eld of O1 points to an object \nO3, and some .eld of O2 points to an object O4. Furthermore, suppose that there is direct .ow (i.e., \nsome copy volume) from O3 to O4. In addition to attributing this copy volume to the pair (O3,O4), we \nwant to also attribute it to the pair (O1,O2). This is done because O1 may potentially be the root of \nan object subgraph for a data structure containing O3. Similarly, O2 may be the root of a data structure \ncontaining O4. If copying is occurring for the entire data structures, the copy volume reported for pair \n(O1,O2) should re.ect this. The analysis considers all objects Oi reachable from O1 along reference chains \nof a pre-de.ned length (length 3 was used for the experiments). Similarly, all objects Oj reachable from \nO2 along reference chains of this length are considered. The copy volume reported for (O1,O2) is the \nsum of the direct copy volumes for all such pairs (Oi,Oj ), including the direct .ow from O1 to O2. To \ndetermine all relationships of the form O ' points to O , the analysis considers chains such that O is \nthe producer node that is, the value propagated along the chain is a reference to O.For any .eld node \nO ' .h in such a chain, object O ' points to object O. In the running example, slowClone illustrates \nthis approach. At line 31, a new List object is created. Its .eld elems points to an array which is initialized \nwith the contents of the array pointed to by the List created at line 39. In the .rst step of the analysis, \nvolume 4000 is associated with the two array objects (1000 copies of 4-byte references to Integer objects). \nThis volume is then also attributed to the two List objects, represented by pair (O39,O31),and to the \ntwo ListClient objects that own the lists, represented by pair (O44,O32). Ultimately, the reason for \nthis entire copy volume is the cloning of a ListClient object, even though it manifests in the copying \nof the array data owned by this ListClient. Reporting the pair (O44,O32) highlights this underlying cause. \n 5.3 Not Assigned To Heap (NATH) The third client analysis detects allocation sites that are instantiated \nmany times and whose object references do not .ow to the heap. For instance, O44 and O45 in the running \nexample represent objects whose references are never assigned to any heap object or static .eld. These \nallocation sites are likely to represent the tops of tem\u00adporary data structures that are constructed \nmany times to provide simple services. For example, we have observed an application that creates GregorianCalendar \nobjects inside a loop. These objects are used to construct the date .elds of other objects. This causes \nsignif\u00adicant performance degradation, as construction of GregorianCalen\u00addar objects is very expensive. \nIn addition, these objects are usually temporary and short-lived, which may lead to frequent garbage \ncol\u00adlection. A simple .x that moves the object construction out of the loop can solve the problem. The \nescape analysis performed by a JIT usually does not remove this type of bloat, because many such objects \nescape the method where they are created, and are even\u00adtually captured far away from the method. Using \ncopy graph, this analysis can be easily performed by .nding all allocation nodes that do not have outgoing \nedges. These nodes are ranked based on the numbers of times that they are instantiated. Using the informa\u00adtion \nprovided by this analysis, we have found in Eclipse 3.1 a few places where NATH objects are heavily used. \nRunning time reduc\u00adtion can be achieved after a simple manual optimization that avoids the creation of \nthese objects.  5.4 Other Potential Clients There are a variety of performance analyses that can take \nadvantage of the copy graph. For example, one can measure and identify use\u00adless data by .nding nodes \nthat cannot reach the consumer node, and by aggregating them based on the objects that they belong to. \nAs another example, developers of large applications usually maintain a performance regression test suite, \nwhich will be executed across versions of a program to guarantee that no performance degrada\u00adtion results \nfrom the changes. However, these performance regres\u00adsion tests can easily fail due to bug .xes or the \naddition of new features that involve extra memory copies and method invocations. It is labor-intensive \nto .nd the cause of these failures. Differenti\u00adating the copy graphs constructed from the runs of two \nversions of the program with the same input data can potentially help pin\u00adpoint performance problems \nthat are introduced by the changes. A possible direction for future work is to investigate these interesting \ncopy-graph-based analyses. 6. Using Copy Pro.les to Find Bloat This section presents three case studies \nof using copy pro.les, both .at and ones derived from the copy graph, to pinpoint sources of useless \nwork. 6.1 DaCapo Bloat Recall from Figure 4 that most of the simple benchmarks, including the DaCapo \nbloat benchmark, have highly concentrated method pro.les: a few methods explain most of the time. However, \nit is dif.cult to know whether these methods are important or merely excessive. Inspecting the total \ncopy count of the DaCapo bloat benchmark, we found a high volume of data copies. Averaged across all \nmethod invocations, 28% of all operations were copies from one memory location to another. This lead \nus to suspect that there were big opportunities for optimizing away excessive computations and temporary \nobject construction. When inspecting the cumulative copy pro.le (i.e. a copy pro\u00ad.le that counts copies \nin a method and any methods it invokes), we found that approximately 50% of all data copies came from \na variety of toString and append methods. Inspecting the source code, we found that most of these calls \ncentered around code of the form: Assert.isTrue(cond, \"bug: \" + node). This bench\u00admark was written prior \nto the existence of the Java assert key\u00adword. This coding pattern meant that debugging logic resulted \nin entire data structures being serialized to strings, even though most of the time the strings themselves \nwere unused; the isTrue method does not use the second parameter, if the .rst parameter is true. We made \na simple modi.cation to eliminate the temporary strings created during the most important copying methods2. \nThis resulted in a 65% reduction in objects created, and a 29 35% reduction in execution time (depending \non the JVM used; we tried Sun 1.6.0 10 and IBM 1.6.0 SR2). The DaCapo suite is geared towards JVM and \nhardware design\u00aders. Therefore, it is important to reevaluate the benchmarks so as to 2 We commented \nout the toString methods of Block, FlowGraph, RegisterAllocator, Liveness, Node, Tree, Label, MemberRef, \nInstruction, NameAndType, LocalVariable, Field,and Constant. distinguish inef.ciencies that a JIT could \npossibly eliminate from ones that require a programmer with good tooling. It may be better for such a \nbenchmark suite not to contain an excess of the latter.  6.2 Java 5 GregorianCalendar A recurring problem \nwith the Java 1.5 standard libraries is the slow performance of calendar-related classes [27]. Many users \nexperi\u00adenced a 50\u00d7 slowdown when upgrading from Java 1.4 to Java 1.5. The problems centered around methods \nin class Gregorian-Calendar, which is an important part of date formatting and pars\u00ading. We ran the test \ncase provided by a user and constructed a context-sensitive copy graph. The test case makes intensive \ncalls of the before, after,and equals methods. The report of hot copy chains includes a family of hot \nchains with the following structure: array[Calendar:907].ELM [Calendar.clone:2168,510000] . array[Calendar:2169].ELM \nThis chain (and others similar to it, for the .elds of a calendar) suggests that clone is invoked many \ntimes to copy values from one Calendar to another. To con.rm this, we ran the clone detector and the \ntop four pairs of allocation sites were as follows: 340000: (GregorianCalendar[GregorianCalendarTest:11],array[Calendar:2168]) \n340000: (array[Calendar:906],array[Calendar:2168]) 340000: (array[Calendar:907],array:[Calendar:2169]) \n340000: (array[Calendar:908],array[Calendar:2170]) The .rst pair shows that an array created at line \n2168 of Calendar gets a large amount of data from the GregorianCalendar object created in the test case. \nThe remaining three pairs of allocation sites also suggest the occurrence of clones, because the .rst \ngroup of ob\u00adjects (i.e., at lines 906, 907, 908) are arrays created in the construc\u00adtor of Calendar, \nwhile the second group (i.e., at lines 2168, 2169, and 2170) are arrays created in clone. By examining \nthe code, we found that clone creates a new object by deep copying all array .elds from the old Calendar \nobject. These copies also include the cloning of a time zone from the zone .eld of the existing ob\u00adject. \nUpon further inspection, we found the cause of the slowdown: methods before, after,and equals invoke \nmethod compareTo to compare two GregorianCalendar objects, which is imple\u00admented by comparing the current \ntimes (in milliseconds) obtained from these objects. However, getMillisof does not compute time directly \nfrom the existing calendar object, but instead makes a clone of the calendar and obtains the time from \nthe clone. The JDK 1.4 implementation of Calendar does not clone any objects. This is because the 1.4 \nimplementation of getMillisof mistakenly changes the internal state of the object when computing the \ncurrent time. In order to avoid touching the internal state, the implementers of JDK 1.5 made the decision \nto clone the calendar and get the time from the clone. Of course, it is not a perfect solution as it \n.xes the original bug at the cost of introducing a signi.cant performance problem. Our tool highlighted \nthe useless work being done in order to work around the getMillisof issue.  6.3 DaCapo Eclipse As a \nlarge framework-based application, Eclipse suffers from per\u00adformance problems that result from the pile-up \nof wasteful opera\u00adtions in its plugins. These problems impact usability, and even pro\u00adgrammers choice \nwhen comparing Java development tools [12]. We ran Eclipse 3.1 from the DaCapo benchmark set and used \nthe NATH analysis to identify allocation sites whose run-time objects are never assigned to the heap. \nThe top nine allocation sites are shown below: (1) 295004: org/eclipse/jdt/internal/compiler/ISourceElementRequestor$MethodInfo \n[SourceElementParser:968] (2) 161169: .../SimpleWordSet[SimpleWordSet:58] (3) 145987: .../ISourceElementRequestor$FieldInfo[SourceElementParser:1074] \n Class Modi.cation #Objs #GCs Time(s) Original  273991250 478 143.6 MethodInfo, Field- Directly pass \nthe data 272461138 460 139.6 Info, TypeInfo PackageFragment Get IResource 272429471 448 138.3 directly \nfrom String SimpleWordSet In-place rehash 272395776 430 136.8 HashtableOfObject In-place rehash 272320499 \n424 134.0  Table 2. Eclipse 3.1 performance problems, .xes, and perfor\u00admance improvements. (4) 46603: \n.../ContentTypeCatalog$7[ContentTypeCatalog:523] (5) 46186: .../ISourceElementRequestor$TypeInfo[SourceElementParser:1190] \n (6) 45813: .../Path[PackageFragment:309] (7) 44703, .../Path[CompilationUnit:786] (8) 37201, .../ContentTypeHandler[ContentTypeMatcher:50] \n (9) 30939, .../HashtableOfObject[HashtableOfObject:123] Each line shows an allocation site and the number \nof times it is instantiated. For example, the .rst line is for an allocation site at line 968 in class \nSourceElementParser, which creates 295004 objects of type ISourceElementRequestor$MethodInfo. Sites 4 \nand 8 are from plugin org.eclipse.core.resources. The remaining sites are located in org.eclipse.jdt.core. \nBecause the Eclipse 3.1 re\u00adlease does not contain the source code for org.eclipse.core.resources, we \ninspected only the seven sites in the JDT plugin.  The .rst site is located in class SourceElementParser,which \nis a key part of the JDT compiler. JDT provides many source code manipulation functionalities that can \nbe used for various purposes, such as automated formating and refactoring. The observer pat\u00adtern is used \nto provide source code element objects when a client needs them. Method notifySourceElementRequestor,which \ncontains this site, plays the observer role: once a requestor (i.e., a client) asks for a compilation \nunit node (i.e., a class), the method noti.es all child elements (i.e., methods) of the compilation unit \nby calling method enterMethod, which will subsequently notify source code statements in each method. \nMethod enterMethod takes a MethodInfo object as input; this object contains all nec\u00adessary information \nfor the method that needs to be noti.ed. The site creates MethodInfo objects which are then provided \nto enterMethod. Because enterMethod is de.ned in an inter\u00adface, we checked all implementations of the \nmethod. Surprisingly, none of these implementations invoke any methods on this param\u00adeter object. They \nextract all information about the method to be noti.ed from .elds of the object; these .elds are previously \nset by notifySourceElementRequestor. The third and the .fth al\u00adlocation sites from above tell the same \nstory: these hundreds of thousands of objects are created solely for the purpose of carrying data across \none-level method invocations. It is expensive to create and reclaim these objects, and to perform the \ncorresponding heap copies. We modi.ed the interface and all related implementations to pass data directly \nthrough parameters. This modi.cation reduces the number of allocated objects by millions and improves \nthe run\u00adning time by 2.8%. In large applications with no single hot spot, signi.cant performance improvements \nare possible by accumulat\u00ading several such small improvements, as illustrated below. Table 2 shows a \nlist of several problems we identi.ed with the help of the analyses. For each problem, the table shows \nthe prob\u00adlematic class (Class), our code modi.cation, the number of allo\u00adcated objects (#Objs), the total \nnumber of GC invocations (#GCs), and the running times. Row Original characterizes the original ex\u00adecution. \nEach subsequent row shows the cumulative improvements due to our changes in the JDT plugin. The second \nrow corresponds to allocation sites 1, 3, and 5 listed above, the third row is for sites 6 and 7, the \nfourth row is for site 2, and the last row is for site 9. By modifying the code to eliminate redundant \ncopies and the related creation of objects, we successfully reduced the number of GC runs, the number \nof allocated objects, and the total running time. With the help of the tool, it took us only a few hours \nto .nd these problems and to make modi.cations in a large application we had never studied before. It \nis important to note that this effort just scratches the surface: signi.cant performance improvement \nmay be possible if a devel\u00adoper or a performance expert carefully examines the tool reports (with different \ntests and workloads) and eliminates the identi.ed useless work. This is the kind of manual tuning that \nis already be\u00ading done today for large Java applications with performance prob\u00adlems that cannot be attributed \nto a single hot spot. This tedious and labor-intensive process can be made more ef.cient and effective \nby the dynamic analyses proposed in our work. Future studies should investigate such potential performance \nimprovements for a broad range of Java applications. 7. Copy Graph Characteristics This section presents \ncharacteristics of the copy graph and its con\u00adstruction. All experiments were performed on a machine \nwith a 1.99GHz Dual Core AMD Opteron processor, running Linux 2.6.9. The programs were run with JIT optimizations \nturned off to collect a copy graph of the unmodi.ed source program. The maximum heap size speci.ed for \neach run was 500Mb. Hence, the size of shadow for each run was 500Mb. IBM DMS is the IBM document management \nserver mentioned in the .rst section, which is run on top of a J2EE application server. Each DaCapo benchmark \nwas run with large workload for two iterations, and the running time for the second iteration is shown. \nSPECjbb and IBM DMS are server ap\u00adplications that report throughput, not total running time; both were \nrun for 30 minutes with a standard workload. Table 3 presents the time and space overhead of context\u00adinsensitive \ncopy graphs. The second column, labeled Torig ,presents the original running times in seconds. The remaining \ncolumns show the total numbers of nodes N0 and edges E0, the amount of memory M0 needed by the analysis \n(in megabytes), the running times T0 (in seconds), and the performance slowdowns (shown in parentheses). \nThe slowdown for each program is T0/Torig. Because the shadow heap is 500Mb, the space overhead of the \ncopy graph is M0 500. In Table 4, the same measurements are reported for 1-object\u00adsensitive copy graphs. \nTo understand the impact of the number of context slots (i.e., parameter c from Section 4.3), we experimented \nwith values 4, 8 and 16 when constructing the 1-object-sensitive copy graph. The slowdown for each program \nwas calculated as Ti/Torig (the original time from Table 3), where i .{4, 8, 16}. The copy graph itself \nconsumes a relatively small amount of memory. Other than for IBM DMS, the space overhead of the copy \ngraph does not exceed 27Mb even when using 16 context slots. As expected, a context-sensitive copy graph \nconsumes more memory than the context-insensitive one, and using more context slots leads to larger space \noverhead. The running time overheads for pro.ling the context-insensitive copy graph and the three versions \nof 1-object-sensitive copy graphs are, on average, 36\u00d7,37\u00d7,37\u00d7, and 37\u00d7 respectively. This over\u00adhead \nis not surprising because the analysis tracks the execution of every instruction in the program. The \noverhead also comes from synchronization performed by the instrumentation of allocation sites, which \nsequentially executes the allocation handler to cre\u00adate allocation header elements. The current implementation \npro\u00advides a general facility for mapping an object address to a context ID. This is done even for the \ncontext-insensitive analysis, where the ID is always 0. Since the cost of this mapping is negligible, \nwe have not created a specialized context-insensitive implementa\u00adtion. Hence, the difference between \nthe running times of pro.ling Program Original Context-insensitive Torig (s) #N0 #E0 M0(Mb) T0(s) (\u00d7) \nantlr 8.9 12516 56703 503.7 284.2 (31.9) bloat 157.5 14058 14471 502.2 9812.2 (62.4) chart 32.5 18113 \n12810 502.5 1053.2 (32.4) fop 3.6 12419 7675 501.8 38.2 (10.6) pmd 46.6 11289 8418 501.7 1542.4 (33.1) \njython 74.7 25653 21893 503.2 2826.1 (37.8) xalan 64.8 13505 28678 502.6 3030.5 (46.8) hsqldb 13.5 12294 \n9102 501.7 350.0 (25.9) luindex 12.1 10154 10227 501.6 583.4 (48.2) lusearch 19.2 8390 13849 501.5 662.8 \n(34.5) eclipse 124.7 34074 52957 506.5 4343.8 (34.8) SPECjbb 1800* 17146 12637 502.4 1800* IBM DMS 1800* \n147517 87531 519.6 1800*  Table 3. Copy graph size and time/space overhead, part 1. Shown are the original \nrunning time Torig , as well as the total numbers of graph nodes N0 and edges E0, the total amount of \nmemory consumed M0, the running time T0, and the slowdown (shown in parentheses) when using a context-insensitive \ncopy graph. context-insensitive and context-sensitive copy graphs is noise. The only signi.cant difference \nbetween context-insensitive and context\u00adsensitive analysis is the space overhead. Although signi.cant, \nthese overheads have not hindered us from running the tool on any programs, including real world large-scale \nproduction applications. It was an intentional design decision not to focus on the performance of the \nanalysis, but instead focus on the content collected and on demonstrating that the results are useful \nfor .nding performance problems in real programs. Now that the value of the tool has been established, \na possible future direction is to use sampling-based pro.ling to obtain the same or similar results. \nAnother possibility is to employ static pre-analyses that reduce the cost of the subsequent dynamic analysis. \nTable 5 shows measurements for the copy chains obtained from a context-insensitive copy graph, including \nthe total number of generated chains (#Chains) and the average length of these chains (Length). The table \nalso shows the number of NATH allocation sites and NATH run-time objects. The signi.cant numbers of NATH \nobjects indicate that eliminating such objects may be a worthwhile goal for future work on manual and \nautomatic optimizations. The .rst part of Table 6 lists the average node fan-out for the context-insensitive \ncopy graph (CIFO) and the three versions of context-sensitive copy graphs (CSFO-i,where i is the number \nof context slots for each object). A node s fan-out is the number of its outgoing edges. The average \nfan-out indicates the degree of node sharing among paths in the graph. Note that CIFO and CSFO-i are \nsmall, because there exist a large number of producer nodes (allocation site) that do not have outgoing \nedges. In addition, the more slots are used to represent contexts, the smaller the average fan-out, because \nmore nodes are created to avoid path sharing. In addition, for each context-sensitive copy graph, the \ntable reports the average context con.ict ratio (CCR-i). The CCR for an object o is de.ned as follows: \n( 0 max0=k=i (nc[k]) = 1 CCR-i(o)= P max (nc[k])/ nc[k] otherwise Here nc[k] represents the number of \ndistinct contexts that fall into context slot k. The CCR value captures the degree to which our encoding \nfunction (i.e., id % k) causes distinct contexts to be merged in the copy graph. For example, the CCR \nis 0 if each context slot represents at most one distinct context; the CCR is 1 if all contexts for the \nobject fall into the same slot. The table reports the average CCR for all allocation sites in the copy \ngraph. As expected, the average CCR decreases with an increase in the Program 1-object-sensitive (c \n=4) 1-object-sensitive (c =8) 1-object-sensitive (c =16) #N4 #E4 M4(Mb) T4(s) (\u00d7) #N8 #E8 M8(Mb) T8(s) \n(\u00d7) #N16 #E16 M16(Mb) T16(s) (\u00d7) antlr 48556 112907 506.9 294.8 (33.1) 96609 159042 510.2 300.7 (33.8) \n192713 210522 515.2 309.5 (34.8) bloat 54960 35678 504.3 10182.9 (64.7) 109494 48840 506.5 10147.4 (64.4) \n218558 60483 510.5 10068.2 (63.9) chart 69438 25951 504.6 1079.4 (33.2) 137945 39133 507.3 1054.4 (32.4) \n274903 45071 511.9 1056.5 (32.5) fop 47893 11985 503.1 37.4 (10.4) 95180 13509 504.6 37.2 (10.3) 189757 \n14388 507.7 36.8 (10.2) pmd 43740 15576 503.0 1586.7 (34.0) 86980 19568 504.5 1568.5 (33.7) 173484 21339 \n507.3 1555.5 (33.4) jython 95493 32256 505.8 2865.6 (38.4) 188583 37005 509.0 2879.9 (38.6) 374791 41027 \n515.0 2861.4 (38.3) xalan 52485 55367 504.9 2983.3 (46.0) 85751 88001 507.7 3067.6 (47.3) 208119 117760 \n512.2 3067.6 (47.3) hsqldb 47666 13432 503.0 358.0 (26.5) 94846 15201 504.6 346.7 (25.7) 189183 17190 \n507.7 345.9 (25.6) luindex 39319 17695 502.8 568.7 (47.0) 78232 22912 504.3 581.1 (48.0) 156033 28333 \n507.0 564.8(46.7) lusearch 32354 22163 502.6 643.5 (33.5) 64280 26629 503.8 651.6 (33.9) 128152 32544 \n506.1 658.4(34.3) eclipse 131065 124043 512.3 4521.5 (36.3) 259168 154004 517.4 4545.3 (36.4) 516030 \n174846 526.4 4746.4 (38.1) SPECjbb 66102 23909 503.3 1800* 131413 27660 507.2 1800* 261915 29017 511.0 \n1800* IBM DMS 193707 180187 533.7 1800* 381072 242049 571.2 1800* 755829 304759 652.3 1800* Table 4. \nCopy graph size and time/space overhead, part 2. The columns report the same measurements as Table 3, \nbut for 1-object sensitive copy graph with 4, 8 and 16 context slots. Program #Chains Length #NATH Sites \n#NATH Objects antlr 250680 2.60 811 411536 bloat 6955316 4.00 1160 31217025 chart 29490 1.16 1652 15080848 \nfop 275835 3.36 1282 167808 pmd 436397 2.96 1062 54103059 jython 6827057 4.00 493 35926287 xalan 93263 \n2.60 1218 6186112 hsqldb 8595 1.80 828 3059666 luindex 30183 2.24 749 5543579 lusearch 10640 3.8 302 \n4200325 eclipse 10070910 1.24 3030 3494187 SPECjbb 21468 2.00 575 722800 IBM DMS 1937646 3.75 4695 1413528 \n Table 5. Copy chains and NATH objects. All copy graph paths with length = 5 are traversed to compute \nhot chains. The columns show the total number of generated chains, the average length of these chains, \nand the number of NATH allocation sites and NATH run-time objects. number of context slots. Note that \nvery few context con.icts occur even when c = 4, because a large number of objects have only one distinct \ncontext during theirs lifetimes. 8. Related Work Dynamic Data Flow Dynamic taint analysis [20, 30, 21, \n7] tracks input data from untrusted channels to detect potential security at\u00adtacks. Debugging, testing, \nand program understanding tools track dynamic data.ow for other specialized purposes (e.g., [15]). The \nwork of [6] tracks the origin of unde.ned values. Dynamic slic\u00ading [34, 31, 32] generates a trace of \ncontrol and data .ow during an execution, in order to enable postmortem analyses for bug de\u00adtection. \nDynamic slicing is expensive in both time and space, as it records complete data and control .ow dependencies. \nOur analysis records only copy .ow. In addition, it applies static abstractions on dynamic information \n.ow, and thus makes it possible to scale to large and long-running applications such as IBM Websphere. \nPro.ling When pro.ling to .nd performance problems, all tech\u00adniques that we are aware of concentrate \non control .ow, rather than data .ow, from path pro.ling [3, 14, 5, 28] to feedback-directed pro.ling \n[2], all to identify heavily-executed paths for further opti\u00admization. The work of [1] develops a dynamic \nanalysis tool to ex\u00adplore calling context trees in order to .nd performance bottlenecks. The work of \n[26] uses a dynamic analysis technique that identi.es important program components, also by inspecting \ncalling context trees. Xu and Rountev propose container-centric pro.ling [29], and Rayside and Mendel \npropose object ownership pro.ling [23], both Program CIFO CSFO CSFO CSFO Context con.ict ratio Average \nfan-out CCR CCR CCR 4 8 16 4 8 16   antlr 4.66 2.33 1.64 1.09 0.237 0.131 0.081 bloat 1.03 0.64 0.44 \n0.27 0.199 0.090 0.068 chart 0.70 0.36 0.28 0.16 0.118 0.059 0.028 fop 0.62 0.25 0.15 0.08 0.134 0.060 \n0.043 pmd 0.75 0.35 0.22 0.12 0.131 0.059 0.051 jython 0.80 0.31 0.18 0.10 0.079 0.071 0.024 xalan 2.13 \n1.79 0.81 0.56 0.128 0.067 0.040 hsqldb 0.74 0.28 0.16 0.09 0.169 0.080 0.051 luindex 1.02 0.45 0.29 \n0.18 0.148 0.073 0.051 lusearch 1.68 0.68 0.41 0.25 0.127 0.082 0.052 eclipse 1.53 0.91 0.57 0.33 0.193 \n0.114 0.071 SPECjbb 0.75 0.36 0.21 0.11 0.144 0.065 0.026 IBM DMS 0.76 0.32 0.17 0.09 0.112 0.047 0.027 \n Table 6. Average node fan-out for context-insensitive (CIFO)and context-sensitive (CSFO-i) copy graphs, \nas well as average context con.ict ratios (CCR-i) for the context-sensitive copy graphs. to detect memory \nleaks in Java programs. Zhang and Gupta pro\u00adpose whole execution traces [33] that includes complete data \ninfor\u00admation of an execution to enable the mining of program pro.les that require understanding of relationships \namong various pro.les. Bloat Dufour et al. propose dynamic metrics for Java [8], which provide insights \nby quantifying run-time bloat. Many memory pro\u00ad.ling tools have been developed to take heap snapshots \nfor un\u00adderstanding memory usage [13], and identify objects of suspicious types [22, 11] that consume \na large amount of memory. However, none of these tools attempt to understand the underlying causes of \nmemory bloat, and thus cannot help programmers pinpoint the problematic areas. The research in [18] structures \nbehavior accord\u00ading to the .ow of information, though using a manual technique. Their aim is to allow \nprogrammers to place judgments on whether certain classes of computations are excessive. Our work is \nin this same spirit, and automates an important component of it. The work of [17] introduces a way to \n.nd data structures that consume ex\u00adcessive amounts of memory. Recent work .nds excessive use of temporary \ndata structures [9, 10] and summarizes the shape of the temporary structures. In contrast to the purely \ndynamic approxima\u00adtion introduced here, it employs a blended escape analysis, which applies static analysis \nto a region of dynamically collected calling structure with observed performance problem. By approximating \nobject effective lifetimes, the analysis has been shown to be useful in classifying the usage of newly \ncreated objects in the problem\u00adatic program region. Another recent work also identi.es regions that make \nheavy use of temporary objects, in order to guide ag\u00adgressive method inlining [24]. Our paper addresses \nthe challenge 9. Conclusion Programmers must have some level of trust in the optimizations that will \nbe performed on their behalf. This is especially true, because software is now assembled from so many \nabstractions. We trust compilers enough to avoid low-level tuning, in the hope that automated optimizations \nwill take care of those details. At every juncture, we make such assumptions, and add delegation to our \ndata models, and employ over-general libraries. What s one extra method call or object? At some point, \nhowever, these decisions pile up, and our assumptions are no longer true: the JIT can no longer clean \nup the mess. Most of the temporary strings in DaCapo bloat benchmark are never used beyond their construction, \nand yet state of the art JITs do not identify this fact. Compilers and tools are currently focused on \ncontrol .ow, and largely make optimization decisions based on time spent in con\u00adtrol dependence regions. \nIn large-scale systems, what makes code suspicious, and worthy of a focused optimization, is not time, \nbut other signs of excess such as data copying. In this paper, we in\u00adtroduced a way to help developers \n.nd larger performance improve\u00adments that are beyond the scope of local calling contexts. We are hopeful \nthat this analysis can also expose unexplored opportunities for the JITs to optimize more globally, such \nas specializing across multiple components, or hoisting complex, many-layered compu\u00adtations. This attention \nto the typical patterns of excess, i.e. that which should be optimizable at some level, can also help \nwith benchmark design and validation. Benchmark designers can use metrics such as the ones we have presented \nto ensure that the benchmarks mimic the kinds of bloat we see in real applications. If benchmark suites \ncame with copy pro.les for each benchmark, then researchers could use these same metrics to evaluate \nhow well their techniques target bloat. We would like to avoid a situation where, for example, hardware \ndesigners add features to help an application better digest its short-lived objects, all so that it runs \n5% faster. We know that there are larger opportunities, if we optimize at the right level. Acknowledgments \nWe would like to thank the PLDI reviewers for their valuable and thorough comments and suggestions. This \nresearch was supported in part by the National Science Foundation under CAREER grant CCF-0546040 and \nby an IBM Software Quality Innovation Faculty Award. Guoqing Xu was supported in part by a summer internship \nat the IBM T.J. Watson Research Center. References [1] G. Ammons, J.-D. Choi, M. Gupta, and N. Swamy. \nFinding and removing performance bottlenecks in large systems. In ECOOP, pages 172 196, 2004. [2] M. \nArnold, S. Fink, D. Grove, M. Hind, and P. F. Sweeney. A survey of adaptive optimization in virtual machines. \nProc. IEEE, 92(2):449 466, 2005. [3] T. Ball and J. Larus. Ef.cient path pro.ling. In MICRO, pages 46 \n57, 1996. [4] S. M. Blackburn and et al. The DaCapo benchmarks: Java benchmarking development and analysis. \nIn OOPSLA, 2006. [5] M. D. Bond and K. S. McKinley. Continuous path and edge pro.ling. In MICRO, pages \n130 140, 2005. [6] M. D. Bond, N. Nethercote, S. W. Kent, S. Z. Guyer, and K. S. McKinley. Tracking bad \napples: reporting the origin of null and unde.ned value errors. In OOPSLA, pages 405 422, 2007. [7] J. \nClause, W. Li, and A. Orso. Dytan: A generic dynamic taint analysis framework. In ISSTA, pages 196 206, \n2007. [8] B. Dufour, K. Driesen, L. Hendren, and C. Verbrugge. Dynamic metrics for Java. In OOPSLA, \npages 149 168, 2003. [9] B. Dufour, B. G. Ryder, and G. Sevitsky. Blended analysis for performance understanding \nof framework-based applications. In ISSTA, pages 118 128, 2007. [10] B. Dufour, B. G. Ryder, and G. \nSevitsky. A scalable technique for characterizing the usage of temporaries in framework-intensive Java \napplications. In FSE, pages 59 70, 2008. [11] ej-technologies. JPro.ler. www.ej-technologies.com. [12] \nJava Development Blog. dld.blog-city.com. [13] Java Heap Analyzer Tool (HAT). hat.dev.java.net. [14] \nJ. Larus. Whole program paths. In PLDI, pages 259 269, 1999. [15] W. Masri and A. Podgurski. An empirical \nstudy of the strength of information .ows in programs. In WODA, pages 73 80, 2006. [16] A. Milanova, \nA. Rountev, and B. G. Ryder. Parameterized object sensitivity for points-to analysis for Java. TOSEM, \n14(1):1 41, 2005. [17] N. Mitchell and G. Sevitsky. The causes of bloat, the limits of health. OOPSLA, \npages 245 260, 2007. [18] N. Mitchell, G. Sevitsky, and H. Srinivasan. Modeling runtime behavior in framework-based \napplications. In ECOOP, pages 429 451, 2006. [19] N. Nethercote and J. Seward. How to shadow every byte \nof memory used by a program. In VEE, pages 65 74, 2007. [20] J. Newsome and D. Song. Dynamic taint analysis \nfor automatic de\u00adtection, analysis, and signature generation of exploits on commodity software. In NDSS, \n2005. [21] F. Qin, C. Wang, Z. Li, H. Kim, Y. Zhou, and Y. Wu. Lift: A low\u00adoverhead practical information \n.ow tracking system for detecting security attacks. In MICRO, pages 135 148, 2006. [22] Quest Software. \nJProbe memory debugging. www.quest.com/jprobe. [23] D. Rayside and L. Mendel. Object ownership pro.ling: \na technique for .nding and .xing memory leaks. In ASE, pages 194 203, 2007. [24] A. Shankar, M. Arnold, \nand R. Bodik. JOLT: Lightweight dynamic analysis and removal of object churn. In OOPSLA, pages 127 142, \n2008. [25] O. Shivers. Control-.ow analysis in Scheme. In PLDI, pages 164 174, 1988. [26] K. Srinivas \nand H. Srinivasan. Summarizing application performance from a component perspective. In FSE, pages 136 \n145, 2005. [27] Sun Java Forum. forums.java.net/jive/thread.jspa? messageID=180784. [28] K. Vaswani, \nA. V. Nori, and T. M. Chilimbi. Preferential path pro.ling: Compactly numbering interesting paths. In \nPOPL, pages 351 362, 2007. [29] G. Xu and A. Rountev. Precise memory leak detection for Java software \nusing container pro.ling. In ICSE, pages 151 160, 2008. [30] W. Xu, S. Bhatkar, and R. Sekar. Taint-enhanced \npolicy enforcement: a practical approach to defeat a wide range of attacks. In USENIX Security, pages \n121 136, 2006. [31] X. Zhang, N. Gupta, and R. Gupta. Pruning dynamic slices with con.dence. In PLDI, \npages 169 180, 2006. [32] X. Zhang and R. Gupta. Cost effective dynamic program slicing. In PLDI, pages \n94 106, 2004. [33] X. Zhang and R. Gupta. Whole execution traces. In MICRO, pages 105 116, 2004. [34] \nX. Zhang, R. Gupta, and Y. Zhang. Precise dynamic slicing algorithms. In ICSE, pages 319 329, 2003. \n   \n\t\t\t", "proc_id": "1542476", "abstract": "<p>Many large-scale Java applications suffer from runtime bloat. They execute large volumes of methods, and create many temporary objects, all to execute relatively simple operations. There are large opportunities for performance optimizations in these applications, but most are being missed by existing optimization and tooling technology. While JIT optimizations struggle for a few percent, performance experts analyze deployed applications and regularly find gains of 2x or more.</p> <p>Finding such big gains is difficult, for both humans and compilers, because of the diffuse nature of runtime bloat. Time is spread thinly across calling contexts, making it difficult to judge how to improve performance. Bloat results from a pile-up of seemingly harmless decisions. Each adds temporary objects and method calls, and often copies values between those temporary objects. While data copies are not the entirety of bloat, we have observed that they are excellent indicators of regions of excessive activity. By optimizing copies, one is likely to remove the objects that carry copied values, and the method calls that allocate and populate them.</p> <p>We introduce <i>copy profiling</i>, a technique that summarizes runtime activity in terms of chains of data copies. A flat copy profile counts copies by method. We show how flat profiles alone can be helpful. In many cases, diagnosing a problem requires data flow context. Tracking and making sense of raw copy chains does not scale, so we introduce a summarizing abstraction called the <i>copy graph</i>. We implement three clients analyses that, using the copy graph, expose common patterns of bloat, such as finding hot copy chains and discovering temporary data structures. We demonstrate, with examples from a large-scale commercial application and several benchmarks, that copy profiling can be used by a programmer to quickly find opportunities for large performance gains.</p>", "authors": [{"name": "Guoqing Xu", "author_profile_id": "81350590981", "affiliation": "Ohio State University, Columbus, OH, USA", "person_id": "P1464335", "email_address": "", "orcid_id": ""}, {"name": "Matthew Arnold", "author_profile_id": "81100021720", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P1464336", "email_address": "", "orcid_id": ""}, {"name": "Nick Mitchell", "author_profile_id": "81100359733", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P1464337", "email_address": "", "orcid_id": ""}, {"name": "Atanas Rountev", "author_profile_id": "81100162864", "affiliation": "Ohio State University, Columbus, OH, USA", "person_id": "P1464338", "email_address": "", "orcid_id": ""}, {"name": "Gary Sevitsky", "author_profile_id": "81100222382", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P1464339", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542523", "year": "2009", "article_id": "1542523", "conference": "PLDI", "title": "Go with the flow: profiling copies to find runtime bloat", "url": "http://dl.acm.org/citation.cfm?id=1542523"}