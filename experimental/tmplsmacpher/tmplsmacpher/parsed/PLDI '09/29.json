{"article_publication_date": "06-15-2009", "fulltext": "\n An Integrated Proof Language for Imperative Programs Karen Zee Viktor Kuncak Martin C. Rinard Massachusetts \nInstitute of Technology CSAIL, Cambridge, MA, USA \u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne IC, Lausanne, \nVD, Switzerland Massachusetts Institute of Technology CSAIL, Cambridge, MA, USA * kkz@csail.mit.edu viktor.kuncak@ep..ch \nrinard@csail.mit.edu Abstract We present an integrated proof language for guiding the actions of multiple \nreasoning systems as they work together to prove com\u00adplex correctness properties of imperative programs. \nThe language operates in the context of a program veri.cation system that uses multiple reasoning systems \nto discharge generated proof obliga\u00adtions. It is designed to 1) enable developers to resolve key choice \npoints in complex program correctness proofs, thereby enabling au\u00adtomated reasoning systems to successfully \nprove the desired cor\u00adrectness properties; 2) allow developers to identify key lemmas for the reasoning \nsystems to prove, thereby guiding the reasoning sys\u00adtems to .nd an effective proof decomposition; 3) \nenable multiple reasoning systems to work together productively to prove a single correctness property \nby providing a mechanism that developers can use to divide the property into lemmas, each of which is \nsuitable for a different reasoning system; and 4) enable developers to identify speci.c lemmas that the \nreasoning systems should use when at\u00adtempting to prove other lemmas or correctness properties, thereby \nappropriately con.ning the search space so that the reasoning sys\u00adtems can .nd a proof in an acceptable \namount of time. The language includes a rich set of declarative proof constructs that enables developers \nto direct the reasoning systems as little or as much as they desire. Because the declarative proof statements \nare embedded into the program as specialized comments, they also serve as veri.ed documentation and are \na natural extension of the assertion mechanism found in most program veri.cation systems. We have implemented \nour integrated proof language in the con\u00adtext of a program veri.cation system for Java and used the resulting \nsystem to verify a collection of linked data structure implementa\u00adtions. Our experience indicates that \nour proof language makes it possible to successfully prove complex program correctness prop\u00aderties that \nare otherwise beyond the reach of automated reasoning systems. Categories and Subject Descriptors D.2.4 \n[Software Engineer\u00ading]: Software/Program Veri.cation; F.3.1 [Logics and Meaning of Programs]: Specifying \nand Verifying and Reasoning about Pro\u00adgrams * This research was supported in part by DARPA Cooperative \nAgree\u00adments SA 8750-06-2-0189 and FA 8750-04-2-0254; United States Na\u00adtional Science Foundation Grants \n0341620, 032583, 0509415, 0811397, and 0835652; and Swiss National Science Foundation Grant Precise and \nScalable Analyses for Reliable Software . Permission to make digital or hard copies of all or part of \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. Copyright c &#38;#169; 2009 \nACM 978-1-60558-392-1/09/06. . . $5.00 General Terms Algorithms, Languages, Reliability, Veri.cation \nKeywords veri.cation, theorem prover, proof system 1. Introduction We have developed a system, Jahob, \nfor specifying and verifying Java programs [46]. Because Jahob uses higher-order logic as its speci.cation \nlanguage, it can express very sophisticated correctness properties. Instead of relying on a single monolithic \nprover, Jahob uses integrated reasoning it contains interfaces to a variety of internal and external \nreasoning systems and uses these systems in a coordinated way to prove complex veri.cation conditions. \nThis approach allows Jahob to quickly exploit new reasoning systems as they become available and to incorporate \nspecialized decision procedures that can prove important properties within arbitrarily narrow domains. \nJahob currently interfaces to .rst-order provers (SPASS [43] and E [41]), SMT provers (CVC3 [22] and \nZ3 [15]), MONA [39], and the BAPA decision procedure [27, 29]. If all of these provers working together \nfail to prove a veri.cation condition, the devel\u00adoper can manually prove the desired property using Jahob \ns inter\u00adfaces to interactive theorem provers (Isabelle [35] and Coq [10]).1 In theory, this approach \nmakes it possible to solve program ver\u00adi.cation problems requiring arbitrarily complex reasoning. But \nin practice, to exploit this capability, developers must become pro\u00ad.cient in both the veri.cation system \nand an interactive theorem prover two separate systems with radically different basic con\u00adcepts, capabilities, \nand limitations. This approach also requires de\u00advelopers to maintain, in addition to the annotated program, \na set of associated proof scripts. And although the interactive prover en\u00adables developers to manually \nprove veri.cation conditions that fail to prove automatically, it also divorces the proof from its original \ncontext within the annotated program and denies the developer ac\u00adcess to the substantial automated reasoning \npower available via the Jahob prover interfaces. 1.1 Integrated Proof Language The Jahob proof language \naddresses these issues by making it pos\u00adsible for developers to control proofs of program correctness \nprop\u00aderties while remaining completely within a single uni.ed program\u00adming and veri.cation environment. \nThe proof commands are di\u00adrectly included in the annotated program and are veri.ed by the un\u00adderlying \nreasoning system as part of the standard program veri.ca\u00adtion work.ow. Because the proof language is \nseamlessly integrated into the veri.cation system, all of the automated reasoning capabil\u00adities of the \nJahob system are directly available to the developer. We have found that this availability enables developers \nto avoid the use of external interactive theorem provers altogether. Instead, devel\u00adopers simply use \nthe Jahob proof language to resolve key choice points in the proof search space. Once these choice points \nhave 1 The complete source code for Jahob, along with examples of its use, is available at javaveri.cation.org. \n been resolved, the automated provers can then perform all of the remaining steps required to discharge \nthe veri.cation conditions. This approach effectively leverages the complementary strengths of the developer \nand the automated reasoning system by allowing the developer to communicate key proof structuring insights \nto the reasoning system. These insights then enable the reasoning system to successfully traverse the \n(in practice large and complex) proof search space to obtain formal proofs of the desired veri.cation \ncon\u00additions. The following techniques are of particular interest: Lemma Identi.cation: The developer \ncan identify key lem\u00admas for the Jahob reasoning system to prove. These lemmas can then help the reasoning \nsystem .nd an appropriate proof decomposition. Such a proof decomposition can be especially important \nwhen multiple provers must cooperate to prove a sin\u00adgle correctness property. In this case separating \nthe property into lemmas, each of which contains facts suitable for a spe\u00adci.c prover, then combining \nthe lemmas, may be the only way to obtain a proof.  Witness Identi.cation: The developer can identify \nthe witness that enables the proof of an existentially quanti.ed veri.cation condition. Because there \nare, in general, an unbounded number of potential witnesses (very few of which may lead to a suc\u00adcessful \nproof), the dif.culty of .nding an appropriate witness is often a key obstacle that prevents a fully \nautomated system from obtaining a proof. But our results show that enabling the developer to remove this \nkey obstacle usually leaves the au\u00adtomated system easily able to successfully navigate the proof search \nspace to prove the desired correctness property.  Quanti.er Instantiation: The developer can identify \nhow to instantiate speci.c universally quanti.ed formulas. The poten\u00adtially unbounded number of possible \nquanti.er instantiations can make developer insight particularly useful in enabling suc\u00adcessful proofs. \n Case Split Identi.cation: The developer can identify the spe\u00adci.c cases to analyze for case analysis \nproofs.  Induction: The developer can identify an induction variable and induction property that lead \nto a successful proof by in\u00adduction.  Assumption Base Control: Modern theorem provers are usu\u00adally given \na set of facts (we call this set the assumption base), then asked to prove a consequent fact that follows \nfrom this set. An assumption base that contains irrelevant facts can produce an overly large proof search \nspace that impedes the ability of the provers to .nd a proof of the consequent. Our integrated proof \nlanguage enables developers to control the assumption base (and thereby productively focus the proof \nsearch space on the property of interest) by identifying a set of relevant facts for the provers to use \nwhen proving a speci.c veri.cation con\u00addition. We have found this functionality essential in enabling \nmodern provers to successfully prove the complex veri.cation conditions that arise in proofs of sophisticated \nprogram correct\u00adness properties.   1.2 Correctness of Linked Data Structures Because of the challenges \nthat aliasing, indirection, and an un\u00adbounded number of objects pose for automated reasoning systems, \nrecursive linked data structures comprise an especially challeng\u00ading veri.cation problem [46]. This paper \npresents our experience using our integrated proof language to verify the correctness of a collection \nof linked data structures. Because the correctness proofs establish complex correctness properties of \nthe data structure im\u00adplementations, the veri.cation conditions involve constructs (such as transitive \nclosure and quanti.ers) that are known to be intractable for automated reasoning systems [23, 28]. Despite \nthis intractabil\u00adity, we are able to use the integrated proof language to successfully identify key proof \nstructuring choices and thereby enable the auto\u00admated reasoning system to perform the required correctness \nproofs. This approach eliminates the need to use external interactive the\u00adorem provers, leaving the integrated \nprovers able to successfully carry almost all of the formal reasoning burden.  1.3 Contributions This \npaper makes the following contributions: Language: It presents our integrated proof language for prov\u00ading \ncorrectness properties of Java programs. The language in\u00adcludes a rich set of declarative proof constructs \nthat enable de\u00advelopers to direct the reasoning system as little or as much as desired. Because the declarative \nproof statements are embed\u00added into the program as specialized comments, they also serve as veri.ed documentation \nand are a natural extension of the as\u00adsertion mechanism found in most program veri.cation systems.  \nSoundness: It presents a proof that our integrated proof lan\u00adguage is sound.  Design: It presents the \nrationale behind the design of the inte\u00adgrated proof language. The basic idea is to provide constructs \nthat allow the developer to identify key choice points in the proof search space, then guide the proof \nby specifying how to resolve these choice points. This approach appropriately lever\u00adages the developer \ns insight to enable the automated reason\u00ading system to successfully prove complex program correctness \nproperties.  System: We have implemented our proof language as an ex\u00adtension to Java. To the best of \nour knowledge, this is the .rst system to integrate a sophisticated proof language into an exist\u00ading \nprogramming language with mutable state and object refer\u00adences and to use this proof language to show \nthe correctness of a substantial collection of linked data structures.  Results: We have used our language \nto prove the correctness of a collection of mutable linked data structure implementations. Our results \nshow that:  Elimination of Interactive Theorem Proving: Despite the complex and in some cases inherently \nintractable proper\u00adties that arise in verifying mutable linked data structure im\u00adplementations, our integrated \nproof language eliminates the need to use external interactive theorem provers to estab\u00adlish the correctness \nof our data structure implementations. Developers instead stay completely within a single uni.ed development \nand veri.cation environment, with no need to learn a second external system with very different basic \ncon\u00adcepts, capabilities, and limitations. Usage Patterns: In most cases, the identi.cation of several \nkey lemmas is all that is required to enable the automated reasoning system to prove the desired veri.cation \ncondi\u00adtions. But even though more sophisticated techniques are, in comparison, used less frequently, \nthey are required for proofs of the complex correctness properties that occasion\u00adally arise in our set \nof data structures. Experience: It discusses our experience using our approach to verify a set of mutable \nlinked data structure implementations. This discussion illuminates the interplay between the various \ndifferent components of our integrated reasoning system and il\u00adlustrates how the integrated proof language \nmakes it possible to build on existing automated reasoning systems to verify very sophisticated program \ncorrectness properties with tractable de\u00adveloper effort.  1.4 Implications To date, the vast majority \nof automated reasoning systems have fo\u00adcused on checking relatively simple consistency properties. As \nthe .eld matures, the focus will shift to more sophisticated properties involving inherently less tractable \nformalisms. We believe the basic concepts behind our integrated proof language (extensive use of au\u00adtomated \nreasoning combined with appropriate developer guidance at key points in the proof search space) will \nplay a prominent role in enabling the continued expansion in the sophistication and utility of the properties \nthat our community is able to verify. 2. Example We next present an example that illustrates the use \nof our integrated proof language. Figure 1 presents state declarations and two meth\u00adods from the ArrayList \nclass.2 The concrete state of an ArrayList object consists of an array elements, which stores the objects \nin the ArrayList, and size, which stores the number of objects in elements. The abstract state consists \nof content, which represents the abstract state of the ArrayList as a set of int, obj pairs; csize, which \ncontains the number of pairs in content; and init, which is false before the list has been initialized \nand true after. The two vardefs declarations comprise an abstraction function which de.ne the relationship \nbetween the abstract and concrete states.3 The remove(o) method removes the object o from the array list \nif it is present. The modi.es clause indicates that the method may change the content and csize components \nof the abstract state. The ensures clause contains the method postcondition. This postcon\u00addition identi.es \ntwo possible cases. In the .rst case the array list contains o. In this case, the method removes the \n.rst occurrence of a pair containing o from content, shifts the remaining pairs down to occupy the gap \nleft by the removal and maintain a dense relation, and returns true. In the second case the array list \ndoes not contain o. In this case the method does not change the abstract state and returns false. The \nbody of the remove method searches for the .rst occurrence of o in the array. The while loop has an invariant \nthat formalizes the properties that characterize the search. If the loop .nds o, it invokes the private \nhelper method shift to shift the elements above o down one position in the array (thereby overwriting \no), then returns true. Note that the speci.cation for shift expresses its postcondition in terms of the \nprivate concrete state, as opposed to the public abstract state (this is permissible because shift is \nprivate). At this point Jahob must use the postcondition of the shift method and the other facts that \nit knows after the call to shift to prove the postcondition of the remove method. Unfortunately, the \nprovers are unable to automatically prove the postcondition of remove. In part this is because irrelevant \nassumptions in veri.ca\u00adtion conditions create a large search space that the provers fail to successfully \nexplore in a reasonable amount of time. What makes the problem even more dif.cult is that the assumptions \ncontain uni\u00adversally quanti.ed formulas while the postcondition contains an existentially quanti.ed formula. \nIn the absence of developer guid\u00adance, the provers must therefore (in this case unsuccessfully) search \n2 The example uses mathematical notation for concepts such as set union (.) and universal quanti.cation \n(.). Developers can enter these symbols in Jahob input .les using X-Symbol ASCII notation, and view them \nin either ASCII or mathematical notation using the ProofGeneral editor mode for emacs [5]. 3 The ArrayList \nclass also contains additional class invariants and methods, which, for clarity, we omit in Figure 1. \nWe also omit certain conjuncts in loop invariants and postconditions. The complete source code for all \nof our benchmarks, including ArrayList, and the complete source code for Jahob itself are available at \njavaveri.cation.org. public class ArrayList { private Object[] elements; private int size ; /*: public \nspecvar init :: bool; public specvar content :: (int * obj) set ; vardefs content == {(i,n). 0=i.i<size.n=elements.[i]} \npublic specvar csize :: int ; vardefs csize == size */ public boolean remove(Object o) /*: requires \n init modi.es content, csize ensures ( result . (. i. (i,o).old content . (\u00ac. j. j<i . (j,o).old content) \n. (. je. 0=j.j<i.(j,e).content=(j,e).old content) . (i=j.j<csize.(j,e).content=(j+1,e).old content)) \n. (\u00acresult . (content=old content.\u00ac.i. (i,o).old content)) */ { int index = 0; while /*: inv (.j. 0=j.j<index.o \n =elements.[j]) . 0=index . size=old size */ (index < size) { if (elements[index] == o) { shift (index); \n /*: note ObjectRemoved: .j e. (0=j.j<index.(j,e).content=(j,e).old content) . (index=j.j<csize.(j,e).content=(j+1,e).old \ncontent) from shift Postcondition , LoopInv, LoopCondition content def , csize def ; witness index for \n.i. (i,o).old content . (\u00ac.j. j<i . (j,o).old content) . (.j e. (0=j.j<i.(j,e).content=(j,e).old content) \n. (i=j.j<csize.(j,e).content=(j+1,e).old content)) */ return true ; } index = index + 1; } return false \n; } private void shift ( int index) /*: requires init . 0=index . index<size modi.es elements, size \n, content, csize ensures (.j. 0=j.j<index . elements.[j]=old elements.[j])) . (.j. index=j.j<size . \nelements.[j]=old elements.[j+1])) . elements.[ size]=null . (size=old size-1) */ {...}} Figure 1. Array \nList Example a large space of possible witnesses for the existentially quanti.ed formula as they attempt \nto prove the postcondition. The developer .rst uses a note statement to instruct Jahob to prove an intermediate \nassertion (labeled ObjectRemoved in Fig\u00adure 1). The ObjectRemoved assertion is simpler than the remove \npostcondition it serves as a lemma that helps the provers struc\u00adture the subsequent successful proof \nof the postcondition. To elim\u00adinate irrelevant assumptions, the developer uses the from clause to indicate \nthat the proof of the lemma needs to use only 1) the post\u00adcondition of shift, 2) the loop invariant and \nexit condition from the closest enclosing loop, and 3) the de.nitions of content and csize. All of these \nfacts are automatically available in the Jahob sys\u00adtem and are accessible using standard names. With \nthis guidance, the theorem provers easily establish the ObjectRemoved lemma, which is then available \nfor subsequent reasoning. The developer next uses a witness statement to identify the wit\u00adness index \nfor the existentially quanti.ed formula in the postcondi\u00adtion. In this way, the developer resolves the \nwitness selection choice point in the proof, which eliminates the need for the provers to search for \nan appropriate witness. Given the resulting existentially quanti.ed formula and the ObjectRemoved lemma, \nthe provers easily prove the postcondition and all other proof obligations for remove. As this example \nshows, the automated provers are very effec\u00adtive at performing the vast majority of the required proof \nsteps. But insight from the developer at key choice points in the proof search space is occasionally \nrequired to enable the full proof to go through. In this example, this insight takes the form of a note \nstatement that identi.es a key lemma and the facts from which this lemma fol\u00adlows, and a witness statement \nthat identi.es a witness for an exis\u00adtentially quanti.ed formula. In general, the developer can express \nthis insight using other proof statements that draw on the devel\u00adoper s understanding of how the program \nworks. 3. Program Veri.cation in Jahob This section brie.y describes the Jahob veri.cation system (for \ndetails, see [46]). Speci.cation Constructs. Following standard practice [9, 16, 46], developers specify \nJahob programs using speci.cation variable declarations, method contracts, class invariants, and loop \ninvari\u00adants. Speci.cation constructs contain formulas whose syntax and semantics follow Isabelle/HOL \n[35]. When an annotation contain\u00ading a formula F occurs at program point q, v in F denotes the value \nof v at q; old v denotes the value of v at the entry of the currently veri.ed procedure. Veri.cation \nCondition Generation. Jahob produces veri.cation conditions by transforming the annotated Java code into \nextended guarded commands (Figures 2, 3) that contain both code and proof constructs. It then transforms \nextended guarded commands into simple guarded commands (Figures 4, 6, 8), and then .nally gener\u00adates \nveri.cation conditions using weakest liberal precondition se\u00admantics (Figure 5). From Java to Guarded \nCommands. Jahob simpli.es code into three-address form to make the evaluation order in expressions ex\u00adplicit \nand inserts assertions that check for null dereferences, array bounds violations, and type cast errors. \nIt converts .eld and array assignments into assignments of global variables whose right-hand side contains \nfunction update expressions. Having taken side ef\u00adfects into account, it transforms Java expressions \ninto mathematical expressions in higher-order logic. The Extended Guarded Command Language. Figures 2 \nand 3 present the syntax of the extended guarded command language. In addition to standard control-.ow \nand state change constructs, the language contains assert, assume, and havoc. These constructs fa\u00adcilitate \nthe staging of veri.cation condition generation into multi\u00adple translation steps. They also provide the \nfoundation for the inte\u00adgrated proof language described below in Section 4. Assert: An assert G annotation \nat program point q in the body of the method requires the formula G to be true at the program point q. \nJahob assertions produce proof obligations that Jahob statically veri.es to guarantee that G will be \ntrue in all program executions that satisfy the precondition of the method.  Assume: An assume G statement \nis dual to the assert state\u00adment. Whereas an assert requires Jahob to demonstrate that G holds, an assume \nstatement allows Jahob to assume that G is true at a given program point. In general, developer-supplied \nassume statements may violate soundness. The assume state\u00adment is therefore designed to support the automated \ntranslation  c ::= p | skip | x := F | c1 . c2 | c1 ; c2 | if(F ) c1 else c2 | loop inv(I) c1 while(F \n) c2 | assume l: F | havoc hx suchThat F Figure 2. Extended Guarded Commands p ::= p1 ; p2 | assert l: \nF from h | note l:F from h | localize in (p ; note l:F ) | mp l:(F . G) | assuming lF :F in (p ; note \nlG:G) | cases Fhfor l:G | showedCase i of l : F1 . ... . Fn | byContradiction l:F in p | contradiction \nl:F | instantiate l:.hx.F with ht | witness ht for l:.hx.F | pickWitness hx for lF :F in (p ; note lG:G) \n| pickAny hx in (p ; note l:F ) | induct l:F over n in p Figure 3. Integrated Proof Language Constructs \nc ::= assume l: F | assert l: F from h | havoc hx | skip | c1 . c2 | c1 ; c2 Figure 4. Simple Guarded \nCommands F [l] . G F [l;hh] . G wlp((assume l: F ),G)= wlp((assert l: F from h ),G)= wlp((havoc hx),G)= \n.x. G hwlp((skip),G)= G wlp((c1 . c2),G)= wlp(c1,G) . wlp(c2,G) wlp((c1 ; c2),G)= wlp(c1, wlp(c2,G)) \n Figure 5. Weakest Preconditions for Simple Guarded Commands for v fresh variable, [x := F ] = havoc \nv ; assume (v = F ) ; havoc x ; assume (x = v) [if(F ) c1 else c2] =(assume F ; [c1]) .(assume \u00acF ; [c2]) \n[loop inv(I) c1 while(F ) c2] = (where hr = mod(c1; c2) denotes variables modi.ed in c1, c2) assert I \n; havoc hr ; assume I ; [c1] ; (assume (\u00acF ) .(assume F ; [c2] ; assert I ; assume false)) [havoc hx \nsuchThat F ] = assert .hx.F ; havoc hx ; assume F Figure 6. Translating Code into Simple Guarded Commands \n of higher-level constructs into a lower-level intermediate lan\u00adguage, with soundness ensured by the \nform of the translation. Non-deterministic change: A statement havoc x suchThat G, where x is a variable \nand G is a formula, changes the value of x subject only to the constraint G (for example, the statement \nhavoc x suchThat 0 = x sets x to an arbitrary non-negative value). To ensure that the statement does \nnot have the effect of assume(false), Jahob emits an assertion that veri.es that at least one such value \nof x exists. From Code to Simple Commands. Figure 6 presents the transla\u00adtion of the code portion of \nthe extended guarded command lan\u00adguage into simple guarded commands. Jahob translates assign\u00adments into \na series of havoc statements and equality constraints, which reduces all state changes to havoc statements. \nConditional statements become non-deterministic choice with assume state\u00adments, as in control-.ow graph \nrepresentations. The Jahob encod\u00ading of loops with loop invariants is standard and analogous, for example, \nto the sound version of the encoding in ESC/Java [20]. Proving Veri.cation Conditions. Veri.cation conditions \ngener\u00adated using the rules in Figure 5 can typically be represented as a conjunction of a large number \nof formulas. Figure 7 describes Jahob s splitting process, which produces a list of implications whose \nconjunction is equivalent to the original formula. The in\u00addividual implications correspond to different \npaths in the method, as well as different conjuncts of assert statements, operation pre\u00adconditions, invariants, \npostconditions, and preconditions of invoked methods. The splitting rules in Jahob preserve formula annota\u00adtions, \nwhich are used for assumption selection. During splitting Ja\u00adhob also eliminates simple syntactically \nvalid implications, such as those whose goal occurs as one of the assumptions, or those whose assumptions \ncontain false. 4. The Integrated Proof Language Our integrated proof language is designed to allow developers \nto provide additional guidance to the system to enable the automated provers to succeed in proving the \ndesired veri.cation conditions. Figure 3 presents the constructs in this language. These constructs appear \nin comments embedded within the Java source code, and are preserved by the translation to the extended \nguarded command language. Figure 8 presents the semantics of the proof language constructs as a translation \ninto the simple guarded command lan\u00adguage. A primary goal of the design of the integrated proof language \nis to enable the developer to provide the system with as little or as much guidance as desired. At one \nextreme the provers should be able to prove veri.cation conditions with no developer guidance at all \nif they have this capability. At the other extreme the language should enable the developer to perform \nevery proof step explicitly if so desired. The language should also .exibly support intermedi\u00adate points \nat which the developer and provers cooperate, with the developer providing only the minimal guidance \nneeded to enable the provers to complete the proof. The Jahob proof language sup\u00adports this wide range \nof behaviors by providing not only high-level constructs that leverage the substantial automated reasoning \npower of the Jahob system, but also low-level constructs that allow the developer to precisely control \nproof steps to enable a successful proof. 4.1 The Assumption Base A veri.cation condition in Jahob has \nthe form of an implication F . G where the antecedent F is a conjunction of facts. This conjunction F \nis the assumption base that the provers use when they attempt to prove the consequent G. hhh A . G1 . \nG2 A . G1,A . G2 [q]) . G[pq] Ah. (Bh. G[p]) (Ah. Bh[q]hh A ..x.G A . G[x := xfresh] Figure 7. Splitting \nRules for Converting a Formula into an Impli\u00adcation List (F [c] denotes a formula F annotated with a \nstring c) The translations of the proof language constructs use assume commands to add facts to the assumption \nbase.4 The soundness of the assume commands in this context is guaranteed by the form of the translation. \nSome translations contain the following pattern: (skip (c ;[p] ; assert F ; assume false)) ; assume G \n The net effect of this pattern is to soundly add G to the orig\u00adinal assumption base. The pattern achieves \nthis effect as fol\u00adlows. The .rst branch of the non-deterministic choice operator (skip) propagates the \noriginal assumption base. The second branch (c ;[p] ; assert F ; assume false) generates the proof obligations \nrequired to ensure that G actually holds. The assume false at the end of the second branch conceptually \nterminates the computation at the end of the branch so that the veri.cation condition gen\u00aderator does \nnot take the computational path through the second branch into account when generating the veri.cation \ncondition at the program point after the choice. This mechanism ensures that the second branch generates \nno proof obligations other than those required to ensure that G holds. In effect, the second branch uses \nthe assume false statement to create a new local assumption base in which the developer can guide the \nproof of the properties required to ensure that G holds. Because this assumption base is local, none \nof the assumptions or intermediate lemmas in the proof propagate through to the program point after the \nchoice. This local assumption base mechanism there\u00adfore ensures that only G is added to the original \nassumption base at the program point after the translated proof language construct, and that local assumptions \nthat are only sound in the context of the proof are not propagated to the original assumption base. The \ncommand c contains statements introduced as part of the translation; p contains proof statements provided \nby the developer and originally nested inside the proof construct under translation. The command c can \ninclude constructs that may modify the pro\u00adgram state, such as assume and havoc constructs. The form \nof the translation ensures that these constructs are used in a sound way. 4.2 The note Construct The \nnote construct translates into an assert followed by an assume of the same formula. The net effect is \nto identify a formula for Jahob to prove, then add the veri.ed formula to the assumption base. Because \nJahob proves the formula before adding it to the assumption base, the use of note is sound. A note statement \nof the form note l:F from hh assigns a name l to the formula F and asks Jahob to prove F using the named \nformulas hh. Proof Decomposition. The note statement enables the developer to guide the decomposition \nof the proof by instructing the com\u00adbined proof system to prove certain lemmas. The availability of these \nlemmas is often suf.cient to guide the provers through the (usually unbounded) proof search space to \nsuccessfully .nd a proof for the veri.cation condition of interest. 4 Speci.cally, the veri.cation condition \ngeneration rule in Figure 5 for statements of the form assume l: F produces a veri.cation condition of \nthe form F [l] . G, which, in effect, adds F to the set of facts available to the provers when they attempt \nto prove the consequent G. [note l:F from hh] = assert l: F from hh ; assume l: F [localize in (p ; \nnote l:F )] =(skip ([p] ; assert F ; assume false)) ; assume l: F [mp l:(F . G)] = assert F ; assert \n(F . G) ; assume l: G [assuming lF :F in (p ; note lG:G)] =(skip (assume lF : F ; [p] ; assert G ; assume \nfalse)) ; assume lG:(F . G) [cases Fhfor l:G] = assert F1 . ... . Fn ; assert (F1 . G) ; ... ; assert \n(Fn . G) ; assume l: G [showedCase i of l : F1 . ... . Fn] = assert Fi ; assume l: F1 . ... . Fn [byContradiction \nl:F in p] =(skip (assume \u00acF ; [p] ; assert false ; assume false)) ; assume l: F [contradiction l:F ] \n= assert F ; assert \u00acF ; assume false [instantiate l:.hx.F with ht] = assert .hx.F ; assume l: F [hx \n:= ht] [witness ht for l:.hx.F ] = assert F [hx := ht] ; assume l: .hx.F [pickWitness hx for lF :F in \n(p ; note lG:G)] = (where hx is not free in G) (skip (assert .hx.F ; havoc hx ; assume lF : F ; [p] ; \nassert G ; assume false)) ; assume lG: G [pickAny hx in (p ; note l:G)] =(skip (havoc hx ; [p] ; assert \nG ; assume false)) ; assume l: .hx.G [induct l:F over n in p] =(skip (havoc n ; assume 0 = n ; [p] ; \nassert F [n := 0] ; assert (F . F [n := n+1]) assume false)) ; assume l: .n.(0 = n . F ) Figure 8. Translating \nProof Language Constructs into Simple Guarded Commands Multiple Provers. The note statement also enables \ndevelopers to decompose a proof obligation so that multiple provers (with arbitrarily narrow areas of \nspecialization) can work together to prove it. Consider, for example, a proof obligation that involves \nboth arithmetic reasoning and reasoning about the shape of a given data structure. By using one group \nof note statements to identify relevant arithmetic properties and another group of note statements to \nidentify relevant data structure shape properties, the developer can decompose the proof obligation to \nexpose speci.c parts of the proof obligation to different provers. A .nal note statement can then combine \nthe results to deliver the complete proof obligation. A potential advantage of this approach is that \nthe set of provers, when working together, may be able to provide sophisticated reasoning capabilities \nthat are beyond the reach of any single general system. Controlling the Assumption Base. Many provers \nperform a search over a (potentially unbounded) proof space. In practice, we have found that increasing \nthe size of the assumption base may degrade the ability of the prover to .nd proofs for facts that it \nis otherwise perfectly capable of proving. Note statements allow de\u00advelopers to give names to speci.c \nfacts (these facts can either be available directly in the assumption base or provable from the as\u00adsumption \nbase), then use the names to identify a speci.c set of facts that the prover should use when attempting \nto prove a new fact. The net effect is to eliminate irrelevant facts from the assumption base to productively \nfocus provers on the speci.c facts they need to use.  4.3 The localize Construct The localize construct \nallows the developer to create a new local as\u00adsumption base for the proof of an arbitrary formula, then \nadd only this proved formula back into the original assumption base. The construct therefore makes it \npossible to use intermediate lemmas to guide the proof of a formula without adding these intermediate \nlemmas back into the original assumption base. Excluding inter\u00admediate lemmas from the original assumption \nbase when the lem\u00admas are not relevant for subsequent veri.cation conditions can help keep the assumption \nbase (and resulting proof search space) small enough to enable the provers to .nd proofs of subsequent \nveri.ca\u00adtion conditions in an acceptable amount of time. Note that because the local assumption base \nis initially the same as the original as- FG F . GF . G false F . GF GF true Figure 9. Implicit First-Order \nLogic Rules sumption base, any formulas veri.ed in the local assumption base also hold in the original \nassumption base. This property ensures that the construct is sound. 4.4 First-Order Logic Constructs \nThe .rst-order logic proof constructs encode standard rules of nat\u00adural deduction systems [38, Section \n2.12], [21, Section 5.4]. When combined with the proof rules implicit in the splitting process, these \nconstructs give our system the completeness of .rst-order logic. (Note that for arbitrary higher-order \nlogic formulas we cannot hope to obtain a proof system complete with respect to the standard mod\u00adels \n[2].) During splitting, Jahob implicitly splits top-level conjunc\u00adtions of assumptions and goals, eliminating \nthe need for conjunc\u00adtion introduction and elimination commands. Jahob also implicitly incorporates the \nstandard rule for deriving any formula when false is one of the assumptions. Figure 9 shows the rules \nthat Jahob au\u00adtomatically applies as part of the splitting process. The assuming construct encodes the \nimplication introduction rule for .rst-order logic. It enables the developer to guide the proof of a \nfact of the form F . G. The fact F is .rst added to a new local assumption base, in which the developer \ncan guide the proof of G. F . G is then added back into the original assumption base. The assuming construct \nmakes it possible to decompose the components of an implication. Without such a construct, many intermediate \nlemmas in a proof of F . G would themselves be implications that could not be decomposed, increasing \nthe dif.culty of the proof task. In practice, we have found the assuming construct particularly useful \nwhen G becomes complex, because the provers often fail to .nd the proof in such cases without guidance. \nThe mp construct encodes the modus ponens rule of inference. It enables the developer to conclude a goal \nG from known facts of the form F and F . G. The pickAny construct encodes the universal introduction \nrule. It enables the developer to guide the proof of a fact of the form .hx.G by choosing arbitrary values \nfor hx in a new local assumption base, then allowing the developer to guide the proof of G. .hx.G is \nthen added to the original assumption base. The instantiate construct encodes the universal elimination \nrule. It enables the developer to establish a fact of the form G[hx := ht] by guiding the proof of a \nfact of the form .hx.G, then adding G[hx := ht] to the assumption base. The witness construct encodes \nthe existential introduction rule. It enables the developer to establish a fact of the form .hx.G by \nguiding the proof of a fact of the form G[hx := ht], then adding .hx.G to the assumption base. The pickWitness \nconstruct encodes the existential elimination rule. It enables the developer to instantiate a formula \nof the form .hx.F (i.e., eliminate the existential quanti.er and name the values that satisfy the constraint \nF ) in a new local assumption base, guide the proof of a formula G, then add the proved goal G back into \nthe original assumption base. To ensure soundness, hx the variable(s) with which the developer is instantiating \n.hx.F must not be free in G. By enabling the developer to name values of hx for which the constraint \nF is true, the pickWitness construct makes it possible to replace an existentially-quanti.ed formula \nwith an instantiated ver\u00adsion, then state additional facts about the named values. This func\u00adtionality \nbroadens the applicability of provers with limited abil\u00adity to reason about existentially quanti.ed formulas. \nWithout the pickWitness construct, every subgoal that depended on the con\u00adstrained values would have \nthe form .hx.(F . G). Such a subgoal is beyond the reach of any prover that cannot reason effectively \nabout existentially quanti.ed formulas. The pickWitness construct enables the developer to soundly eliminate \nthe existential quanti\u00ad.er, thereby transforming existentially quanti.ed proof goals into a form that \nsuch provers can more effectively handle. The cases construct enables the developer to decompose a goal \nusing case analysis. It ensures that the set of cases fully cover the space of the proof, proves each \ncase, then soundly concludes the goal. The showedCase construct encodes the disjunction introduction \nrule. It enables the developer to establish a fact of the form F1 . ... . Fn by guiding the proof of \na case Fi in the disjunction. The byContradiction construct enables the developer to prove an arbitrary \nformula F using proof by contradiction. It allows the developer to add \u00acF to a new local assumption base, \nthen use this assumption base to guide the proof of false. The veri.ed formula F can then be soundly \nadded to the original assumption base. The developer can also use this construct to perform negation \nintroduction by directing Jahob to prove a formula of the form \u00acF . The contradiction construct enables \nthe developer to derive false from a contradiction. It allows the developer to guide the proof of a formula \nF and its negation \u00acF to soundly conclude false.  4.5 The induct Construct The induct construct enables \nthe developer to prove facts of the form .n.(0 = n . F ) using mathematical induction. As the trans\u00adlation \nin Figure 8 illustrates, the induct statement encodes math\u00adematical induction by choosing an arbitrary \nvalue of n such that 0 = n holds, then allowing the developer to guide the proof of the base case F [n \n:= 0] and the inductive step F . F [n := n + 1]. The introduction of the constraint 0 = n makes it possible \nto sim\u00adulate mathematical induction over natural numbers using integers. The induct construct is particularly \nimportant because the fully automated provers that we use are generally unable to derive facts whose \nproofs require mathematical induction. Without this con\u00adstruct, the only recourse for the developer would \nbe to perform the proof using an external interactive theorem prover.  4.6 Executable Code Inside Proof \nConstructs Many proof language constructs can (recursively) contain other proof language constructs (see \nFigure 3). It is possible to gener\u00adalize this formulation and introduce sound constructs that contain \nnot only proof constructs, but also executable code that may mu\u00adtate the Java program state. In particular, \nit is possible to generalize pickWitness and pickAny to enclose the general extended guarded command \nc (which may contain executable Java code as well as proof constructs) instead of just the proof command \np. The gen\u00aderalization of pickWitness makes it possible to choose a witness for an existentially quanti.ed \nformula in the assumption base, then use that witness at multiple program points throughout a sequence \nof Java statements. The dual generalization of pickAny makes it possible to prove a universally quanti.ed \nformula at the end of a sequence of Java statements by 1) introducing a fresh variable that denotes an \narbitrary value at the start of the sequence, 2) using this new variable to refer to its value at multiple \nprogram points throughout the sequence of statements, then 3) concluding the uni\u00adversally quanti.ed formula \nat the end of the sequence. This ap\u00adproach is particularly useful in simplifying proofs of program prop\u00aderties \nthat would otherwise require the reasoning systems to work with universally quanti.ed loop invariants. \nTo enable the .exible combination of Java code and proof com\u00admands, we propose a proof language construct, \n.x, that subsumes both pickWitness and pickAny and can enclose executable code that may mutate the Java \nprogram state. Appendix B presents the .x construct, including its syntax, its semantics through a transla\u00adtion \ninto simple guarded commands, and a proof of its soundness. 5. Soundness The translation rules in Figure \n8 de.ne the semantics of our proof language constructs. We show the soundness of each of these rules \nusing properties of weakest liberal preconditions [6]. We de.ne the relation . such that c . c' if and \nonly if wlp(c, F ) . wlp(c',F ) ' for all formulas F . In this case we say that c is stronger than c. \nLet skip be the no-op command. We use induction on p to show p . skip for all p. This is suf.cient for \nsoundness because it ensures that any property provable for the annotated program containing proof language \nconstructs also holds in the unannotated program (which is equivalent to the annotated program with all \nproof constructs replaced with skip). The induction hypothesis is wlp([p],H) . H, where H is an arbitrary \nformula. For each proof language construct p, we apply the translation rules in Figure 8, the rules of \nweakest liberal pre\u00adconditions in Figure 5, the induction hypothesis, and the standard rules of logic \nto show that wlp([p],H) . H i.e., that p is stronger than skip. As a sample inductive step, consider \nthe assuming construct. By applying the translation rule for assuming, the rules of weakest liberal preconditions, \nand the standard rules of logic, we obtain: wlp([assuming F in (p ; note G)],H) = wlp(((skip (assume \nF ;[p] ; assert G ; assume false)) ; assume (F . G)),H) = ((F . G) . H) . (F . wlp([p],G)) According \nto the induction hypothesis, wlp([p],G) . G. There\u00adfore, ((F . G) . H) . (F . wlp([p],G)) implies the \nformula ((F . G) . H) . (F . G), which implies H. Consequently, assuming is stronger than skip and its \ntranslation is sound. The proofs for the other constructs, including induct, pickAny, and pickWitness, \nare similar and are given in Appendix A. Data Structure Hash Table 15 90 497.6 5 3 20 4 176 (93) 12 \nPriority Queue 12 60 130.2 5 0 9 2 105 (47) 0 Binary Tree 9 134 6519.9 2 4 7 6 98 (15) 2 Array List 23 \n121 194.5 4 0 10 10 27 (11) 0 Circular List 5 57 119.2 4 1 9 1 3 (0) 0 Cursor List 9 51 36.2 6 0 16 1 \n2 (0) 0 Association List 11 65 10.8 3 1 7 3 0 (0) 0 Linked List 6 38 5.3 3 0 8 2 0 (0) 0 assuming mp \npickAny instantiate witness pickWitness cases induct Data Structure Statements Statements Statements \nStatements Statements Statements Statements Statements Hash Table 26 3 17 8 0 0 3 0 Priority Queue 28 \n0 11 1 1 4 2 2 Binary Tree 0 0 0 0 0 0 0 0 Array List 3 0 1 0 1 0 0 0 Circular List 0 0 0 0 0 0 0 0 Cursor \nList 0 0 0 0 0 0 0 0 Association List 0 0 0 0 0 0 0 0 Linked List 0 0 0 0 0 0 0 0 Local Data Java Java \nVeri.cation Speci.cation Speci.cation Structure Loop note localize Methods Statements Time (s) Variables \nVariables Invariants Invariants Statements Statements Table 1. Method, Statement, Speci.cation, and Integrated \nProof Language Construct Counts for Veri.ed Data Structures 6. Experimental Results We next discuss our \nexperience using our integrated proof language in the speci.cation and veri.cation of a collection of \nlinked data structures. The complete source code for the data structures (in\u00adcluding implementations \nand speci.cations) as well as the Jahob veri.cation system (including source code) are all available \nat javaveri.cation.org. 6.1 Construct Counts and Veri.cation Times Table 1 presents the veri.cation times \nfor the data structures as well as counts of various Java and Jahob constructs. The .rst and second columns \npresent the number of Java methods and Java statements, respectively, in the data structure implementations. \nThe third column presents the time required for Jahob to verify each implementation. The remaining columns \npresent the counts of the different Jahob constructs. Each method s speci.cation typically contains requires, \nmodi.es, and ensures clauses, although some requires and modi.es clauses are empty and therefore omitted \nfrom the speci.cation. The remaining columns present counts of the various speci.cation and proof language \nconstructs, including the number of speci.cation variables, local speci.cation variables, data struc\u00adture \ninvariants, loop invariants, and proof statements. There is one column for each type of proof statement \nused in our data structures. The note Statements column contains entries of the form n(m). In these entries \nn counts the total number of note statements that appear in the data structure implementation. Of these \nn statements, m have a from clause that is used to identify a set of named facts for the provers to use \nwhen proving the new fact in the note statement. Because the typical motivation for including a from \nclause is to limit the size of the assumption base so that the provers can prove the new fact in a reasonable \namount of time, these numbers provide some indication of how sensitive the provers are to the size of \nthe assumption base in each data structure. In general, the data structures use note statements much \nmore extensively than any other proof language construct. This fact re\u00ad.ects the strength of the underlying \nprovers it is often possible to guide the provers to an effective proof by either providing a few lemmas \nthat effectively guide the proof decomposition or by appro\u00adpriately limiting the assumption base. Without \nProof With Proof Language Constructs Language Constructs Data Methods Sequents Methods Sequents Structures \nVeri.ed Veri.ed Veri.ed Veri.ed Hash Table 6 of 15 949 of 982 15 1226 Priority Queue 9 of 12 555 of 563 \n12 792 Binary Tree 1 of 9 776 of 866 9 1294 Array List 18 of 23 886 of 891 23 928 Circular List 2 of \n5 212 of 226 5 237 Cursor List 8 of 9 353 of 354 9 356 Association List 11 of 11 349 of 349 11 349 Linked \nList 6 of 6 168 of 168 6 168 Table 2. Effect of Proof Language Constructs on Veri.cation  6.2 Effect \nof Proof Language Constructs Table 2 presents numbers that summarize the effect that the proof language \nconstructs have on the veri.cation. The .rst two columns present the number of methods and sequents veri.ed \nwithout proof language constructs. We obtained these numbers by removing all proof statements from the \nprogram, then attempting to verify the data structure. Each prover runs with a timeout if the prover \nfails to prove the sequent within the timeout, Jahob terminates it and moves on to the next prover. In \ngeneral, the more complex the data structure, the more guidance the provers need to verify the data structure. \nThe .nal column in Table 2 presents the total number of se\u00adquents required to fully verify the corresponding \ndata structure implementations after adding the necessary proof language state\u00adments. Note that the number \nof sequents increases, in some cases signi.cantly. This is because the proof statements force the provers \nto prove additional lemmas, which in turn correspond to additional sequents. The increase in the number \nof sequents re.ects the dif\u00ad.culty of proving the complex sequents that failed to verify in the absence \nof developer guidance. We next discuss the use of the proof language constructs in the Hash Table, Priority \nQueue, Binary Tree, and Array List data structures in more detail.  6.3 Hash Table Hash Table implements \na relation between keys and values. It uses the standard array of linked lists implementation, with each \nelement in each list storing one of the key, value pairs in the relation. The data structure uses note \nstatements primarily for two pur\u00adposes: to control the assumption base, and to instruct the provers to \nprove key lemmas involving the relationship between the con\u00adcrete and abstract states. For example, the \nimplementation often performs an operation on the linked list to which a speci.c key hashes. In this \ncase a note statement often instructs the provers to prove a formula stating that if the abstract relation \ncontains a speci.c key, value pair, then the element storing that pair is in the list stored at the offset \nin the array given by the key s hash value. Other note statements involve data structure consistency \nproperties for example, that once a given key, value pair has been removed from the hash table, there \nis no list element in the table whose next pointer refers to an element with that same key, value pair. \nIn comparison with the other data structures in our benchmark set, the hash table is a fairly complex \ndata structure with many rep\u00adresentation invariants. Even though the provers are capable of prov\u00ading \nmany of the desired properties, the presence of all of the invari\u00adants produces an assumption base large \nenough to signi.cantly im\u00adpair the ability of the provers to .nd the proofs within a reasonable amount \nof time. Many of the note statements are therefore present primarily to restrict the assumption base \nto relevant facts, thereby enabling the provers to focus their efforts on a productive part of the search \nspace so that they can successfully prove the veri.cation conditions within a reasonable amount of time. \nIn addition to the note statement, the hash table also uses the localize, assuming, mp, pickAny, instantiate, \nand cases state\u00adments. The hash table uses localize statements to limit the scope of intermediate lemmas, \nsince adding extraneous facts to the assump\u00adtion base can degrade the effectiveness of the provers in \nproving subsequent veri.cation conditions. Note that localize statements also make certain aspects of \nthe proof structure (speci.cally, the correspondence between intermediate lemmas and veri.cation con\u00additions) \nexplicit. They therefore make the proofs easier to under\u00adstand. The hash table uses assuming and pickAny \nstatements primarily in the proof of data structure invariants, which typically have the general form \n.x.(x . C . P ) (for all objects x that belong to the class C, the property P holds). As a result, the \nproof of a data structure invariant often has the following general form: pickAny x in (assuming x . \nC in (p ; note P ) ; note P ) The hash table uses instantiate statements to appropriately in\u00adstantiate \nthe universal quanti.ers in data structure invariants to ob\u00adtain intermediate lemmas to prove other goals. \n 6.4 Priority Queue Priority Queue implements a priority queue with a set interface. The queue itself \nis implemented as a complete binary tree stored in a dense array. The children of a parent element stored \nat index i are stored at indices 2i +1 and 2i +2. An important ordering invariant is that each parent \ns key is greater than the keys of its two children. The greatest element is therefore the root of the \ntree. The majority of the note statements appear in methods that up\u00addate the tree, either to insert a \nnew element or to remove the greatest element. During these methods some of the invariants are temporar\u00adily \nviolated as the tree is updated. Many of the note statements appear in groups that identify these regions. \nConceptually, the pur\u00adpose of these statements is often to identify the updated region, instruct the \nprovers to prove lemmas stating that the invariants hold outside of the updated region, and identify \nthe properties that char\u00adacterize the updated region. Given this guidance, the provers are then able \nto prove that a completed update restores the invariants to implement the desired operation. The priority \nqueue uses the induct statement to prove that the element stored at index 0 of the array is the maximal \nelement in the tree. The provers are not able to prove this property without assistance, but by using \nthe induct statement as well as other proof statements to resolve key choice points in the intermediate \nsteps of the proof, it is possible to establish this property from the ordering invariant. Of the remaining \nconstructs, the priority queue uses the assuming and pickAny statements the most, to establish data structure \ninvariants and to establish equality between sets using proofs of the following form: pickAny x in (assuming \nx . A in (pf ; note x . B) ; note lf :x . B) ; pickAny x in (assuming x . B in (pb ; note x . A) ; note \nlb:x . A) ; note l:A = B from lf ,lb The pickAny and assuming statements establish that .x.x . A . x \n. B and .x.x . B . x . A. The .nal note statement establishes from these two facts that the sets A and \nB are equal. 6.5 Binary Tree Binary Tree stores a set of elements in a binary search tree. It ex\u00adports \na set interface to the elements in the tree. It is a challenging data structure to verify because the \nveri.cation conditions involve a wide range of different kinds of properties: data structure shape properties, \nordering properties involving the elements in the tree, and abstraction properties that relate the tree \nto the abstract set it implements. Moreover, the interactions between these properties make it dif.cult \nfor any single prover to prove the generated veri.\u00adcation conditions by itself. The binary tree uses \nprimarily note statements. The vast ma\u00adjority of the note statements in the data structure implementation \nare present to facilitate the interaction between the different provers that work together to verify \nthe implementation. Speci.cally, these note statements identify speci.c shape properties that the Mona \ndecision procedure is then able to prove. The .rst-order theorem provers use these shape properties as \nlemmas to establish the re\u00adlationships between the shape properties, ordering properties, and abstraction \nproperties required to prove the veri.cation conditions. In effect, the note statements serve a dual \npurpose: guiding the provers to an effective proof decomposition by instructing them to prove data structure \nshape lemmas and enabling the successful ap\u00adplication of multiple provers to a single veri.cation problem \nby identifying relevant facts for the specialized Mona decision proce\u00addure to prove. 6.6 Array List \nArray List implements a mapping from integers to objects. It stores the mapping in an array; the position \nof the element in the array corresponds to the element s index in the mapping. The note state\u00adments are \noften used to instruct the provers to prove lemmas that relate the contents of regions in the updated \narray to the contents of corresponding regions in the original array. For example, the method that adds \nan element at a speci.c index copies the block of items above the index up one position to make space \nfor the new element. The array list also contains a pickAny statement and several assuming statements. \nThese are used to guide the proofs of several universally quanti.ed lemmas that relate membership in \ndifferent versions of the array with restrictions on the corresponding index of the element. For example, \none of the lemmas states that if the element was in the array prior to the insertion of a new element, \nits index was less than the active size of the array. These formulas are used to prove a set equality \nrelationship involving the old content before an insertion and the new content after the insertion. As \ndiscussed above in Section 2, the array list also contains a witness statement that enables the developer \nto identify the witness for one of the clauses of the postcondition of the remove method. 7. Related \nWork Interactive theorem provers include Isabelle/HOL [35], PVS [37], Boyer-Moore provers [11], and Coq \n[10]. Most of these provers provide facilities for exporting executable de.nitions of mathe\u00admatical functions \ninto purely functional programs. It is natural to consider combinations of automated techniques to increase \nthe granularity of interactive proof steps in interactive provers. Such integration is used in PVS [37], \nBoyer-Moore provers [11], and Isabelle [33]. We adopt declarative-style proofs, which are also supported \nby the Isabelle s Isar notation [44] and are present in the Mizar [40] and Athena [4] systems. We adopted \nthe names (but not the exact semantics) of terms such as pickWitness and assumption base from the Athena \nsystem [3, 4]. The difference between the approach used in interactive theo\u00adrem provers and the approach \nused in our proof language is that the former aims to incorporate executable programs into the uni\u00adverse \nof proofs, while our proof language aims to bring proofs into the universe of executable programs. In \nparticular, our proof lan\u00adguage is able to naturally embed proofs into imperative programs. Most interactive \ntheorem provers operate over functional program\u00adming languages in an environment designed for proofs. \nOur proof language is integrated into the underlying imperative programming language and naturally extends \nits assertion mechanism. This ap\u00adproach provides the developer with an accessible way of reasoning not \nonly about the effect of executing a method but also about the intermediate states during the execution, \nwhich is often necessary when verifying complex program properties. Although Jahob supports the use of \ninteractive provers, its proof commands provide an alternative way of decomposing proof obligations without \never leaving the world of the original Java program. The fact that these proof constructs naturally translate \ninto guarded commands suggests that they are intuitive for the veri.cation of imperative programs. We \nnote that some theorem provers support primarily tactic\u00adstyle proofs. In comparison with our declarative \napproach, tactics must be executed to show the intermediate facts that support the proof, which can lead \nto problems with robustness and maintain\u00adability in the presence of changes to the names of intermediate \nvari\u00adables and theorem prover tactics. Programs as proofs. The Jahob proof system differs from sys\u00adtems \nbased on interpreting programs as proofs [13, 36, 45] and systems such as Ynot [34] based on monadic \ncomputations within Coq. The semantic basis of Jahob is the (.rst-order) guarded com\u00admand language (as \nopposed to lambda calculus). Instead of in\u00adtroducing a fundamental distinction between programs as proofs \nand types as propositions, Jahob views programs as guarded com\u00admands and (through the weakest precondition \nrules) as the corre\u00adsponding propositions. Jahob adopts the idea that certain propo\u00adsitions are simple \nenough to serve as their own proofs. The goal of Jahob s proof language then becomes soundly modifying \nthe guarded commands to decompose the generated formulas into simpler ones until they become self-evident. \nThe notion of self\u00adevidence is in principle given by the rules of .rst-order and higher\u00adorder logic, \nbut is in practice determined by the state of the art in automated reasoning. In comparison with the \nalternatives, we believe that this approach is easier for developers to use. Software veri.cation tools. \nSoftware veri.cation tools that can prove properties of linked data structures include Hob [25, 30, 31], \nSpec# [9], ESC/Modula-3 [16], ESC/Java [18], ESC/Java2 [12], and Jahob [46], [24]. Jahob has already \nbeen used to verify a col\u00adlection of linked data structures [46], but in certain cases relied on the \ndeveloper to use Isabelle to interactively prove veri.cation con\u00additions that the provers were unable \nto verify. Our results in Sec\u00adtion 6 show that our integrated proof language completely elim\u00adinates the \nneed to use external interactive theorem provers even when proving such complex properties. LOOP, KIV, \nKeY, Jive, and Krakatoa have been used to verify a variety of Java programs [1, 8, 14, 14, 17, 42]. Several \nof these veri.cation environments aim to avoid the disconnect between source code and the proof obli\u00adgation \nby incorporating the notion of imperative programs into the notion of proof and building interactive \ninterfaces that enable ma\u00adnipulations of annotated source code. Instead, Jahob shows how to introduce \nsmall extensions into a standard programming language to facilitate proof decomposition. To the best \nof our knowledge, no other system has been used to verify a collection of linked data structures of comparable \nsophistication to the ones in Section 6. The working draft of the Boogie 2 language reference man\u00adual \n[32] presents the call-forall statement as a means to introduce lemmas for helping the program veri.er \nin more advanced veri.\u00adcations. Lemma procedures, in conjunction with the call and call\u00adforall constructs, \nmake it possible to verify certain universally\u00adquanti.ed lemmas and implications. Using speci.cation \nvariables to prove quanti.ed properties. The idea of using speci.cation variables with arbitrary values \nto verify universally quanti.ed assertions appears in extensions of predicate abstraction [7, 19]. The \n.x construct makes this concept directly available to the developer, providing greater control over its \nuse. We have also identi.ed conditions under which this approach is sound. Summary. Over the past several \ndecades, researchers have pro\u00adposed a range of program veri.cation approaches and tools. Sound\u00adness is \nan essential property for any such approach and we have demonstrated the soundness of our approach. The \nnext most im\u00adportant question in practice is the feasibility of the proof system in verifying complex \nprogram properties. Our experience shows that our system effectively supports this task for a wide range \nof data structures. We attribute the effectiveness of our system to 1) its inte\u00adgration with the underlying \nimperative programming language and 2) its ability to incorporate the full range of automated reasoning \nprocedures based on fragments of well-understood classical logics. We believe our system is unique in \nthe extent to which it supports these two features. 8. Conclusion Automated reasoning systems are becoming \nincreasingly powerful and therefore increasingly useful in a range of domains. But despite these advances, \nproofs of many complex properties remain beyond the reach of fully automated techniques. Our results \nshow that our integrated proof language can enable developers to effectively resolve key proof choice \npoints to obtain, with reasonable effort, proofs of very sophisticated program correctness properties \nthat otherwise lie beyond the reach of automated techniques. These results suggest that the incorporation \nof a reasonable amount of developer guidance can dramatically increase the sophistication of the range \nof important program correctness properties that it is possible to formally prove. We anticipate that \nsimilar techniques would provide similar bene.ts in other domains. References [1] W. Ahrendt, T. Baar, \nB. Beckert, R. Bubel, M. Giese, R. H\u00a8ahnle, W. Menzel, W. Mostowski, A. Roth, S. Schlager, and P. H. \nSchmitt. The KeY tool. Software and System Modeling, 4:32 54, 2005. [2] P. B. Andrews. An Introduction \nto Mathematical Logic and Type Theory: To Truth Through Proof. Springer (Kluwer), 2nd edition, 2002. \n[3] K. Arkoudas. Denotational Proof Languages. PhD thesis, Massachusetts Institute of Technology, 2000. \n [4] K. Arkoudas, K. Zee, V. Kuncak, and M. Rinard. Verifying a .le system implementation. In ICFEM, \nvolume 3308 of LNCS, 2004. [5] D. Aspinall. Proof general: A generic tool for proof development. In TACAS, \n2000. [6] R.-J. Back and J. von Wright. Re.nement Calculus. Springer-Verlag, 1998. [7] I. Balaban, A. \nPnueli, and L. Zuck. Shape analysis by predicate abstraction. In VMCAI 05, 2005. [8] M. Balser, W. Reif, \nG. Schellhorn, K. Stenzel, and A. Thums. Formal system development with KIV. In FASE, number 1783 in \nLNCS, 2000. [9] M. Barnett, R. DeLine, M. F\u00a8ahndrich, K. R. M. Leino, and W. Schulte. Veri.cation of \nobject-oriented programs with invariants. Journal of Object Technology, 3(6):27 56, 2004. [10] Y. Bertot \nand P. Cast\u00b4eran. Interactive Theorem Proving and Program Development Coq Art: The Calculus of Inductive \nConstructions. Springer, 2004. [11] R. S. Boyer and J. S. Moore. Integrating decision procedures into \nheuristic theorem provers: A case study of linear arithmetic. In Machine Intelligence, volume 11, pages \n83 124. OUP, 1988. [12] P. Chalin, C. Hurlin, and J. Kiniry. Integrating static checking and interactive \nveri.cation: Supporting multiple theories and provers in veri.cation. In VSTTE, 2005. [13] T. Coquand \nand G. P. Huet. The calculus of constructions. Inf. Comput., 76(2/3):95 120, 1988. [14] A. Darvas and \nP. M\u00a8Formal encoding of JML Level 0 uller. speci.cations in JIVE. Technical Report 559, Chair of Software \nEngineering, ETH Zurich, 2007. [15] L. de Moura and N. Bj\u00f8rner. Ef.cient E-matching for SMT solvers. \nIn CADE, 2007. [16] D. L. Detlefs, K. R. M. Leino, G. Nelson, and J. B. Saxe. Extended static checking. \nTechnical Report 159, COMPAQ Systems Research Center, 1998. [17] J.-C. Filliatre. Veri.cation of non-functional \nprograms using interpretations in type theory. Journal of Functional Programming, 13(4):709 745, 2003. \n[18] C. Flanagan, K. R. M. Leino, M. Lilibridge, G. Nelson, J. B. Saxe, and R. Stata. Extended Static \nChecking for Java. In Proc. ACM PLDI, 2002. [19] C. Flanagan and S. Qadeer. Predicate abstraction for \nsoftware veri.cation. In Proc. 29th ACM POPL, 2002. [20] C. Flanagan and J. B. Saxe. Avoiding exponential \nexplosion: Generating compact veri.cation conditions. In Proc. 28th ACM POPL, 2001. [21] J. Gallier. \nLogic for Computer Science. http://www.cis.upenn. edu/~jean/gbooks/logic.html, revised on-line edition, \n2003. [22] Y. Ge, C. Barrett, and C. Tinelli. Solving quanti.ed veri.cation conditions using satis.ability \nmodulo theories. In CADE, 2007. [23] N. Immerman, A. M. Rabinovich, T. W. Reps, S. Sagiv, and G. Yorsh. \nThe boundary between decidability and undecidability for transitive\u00adclosure logics. In Computer Science \nLogic, pages 160 174, 2004. [24] V. Kuncak. Modular Data Structure Veri.cation. PhD thesis, EECS Department, \nMassachusetts Institute of Technology, February 2007. [25] V. Kuncak, P. Lam, K. Zee, and M. Rinard. \nModular pluggable analyses for data structure consistency. IEEE Transactions on Software Engineering, \n32(12), December 2006. [26] V. Kuncak and K. R. M. Leino. In-place re.nement for effect check\u00ading. In \nSecond International Workshop on Automated Veri.cation of In.nite-State Systems (AVIS 03), Warsaw, Poland, \nApril 2003. [27] V. Kuncak, H. H. Nguyen, and M. Rinard. Deciding Boolean Algebra with Presburger Arithmetic. \nJ. of Automated Reasoning, 2006. http://dx.doi.org/10.1007/s10817-006-9042-1. [28] V. Kuncak and M. Rinard. \nExistential heap abstraction entailment is undecidable. In Static Analysis Symposium, 2003. [29] V. Kuncak \nand M. Rinard. Towards ef.cient satis.ability checking for Boolean Algebra with Presburger Arithmetic. \nIn CADE-21, 2007. [30] P. Lam. The Hob System for Verifying Software Design Properties. PhD thesis, Massachusetts \nInstitute of Technology, February 2007. [31] P. Lam, V. Kuncak, and M. Rinard. Cross-cutting techniques \nin program speci.cation and analysis. In 4th International Conference on Aspect-Oriented Software Development \n(AOSD 05), 2005. [32] K. R. M. Leino. This is Boogie 2. http://research.microsoft.com/ leino/\u00adpapers/krml178.pdf, \nJune 2008. (working draft). [33] J. Meng and L. C. Paulson. Translating higher-order problems to .rst-order \nclauses. In ESCoR: Empir. Successful Comp. Reasoning, pages 70 80, 2006. [34] A. Nanevski, G. Morrisett, \nA. Shinnar, P. Govereau, and L. Birkedal. Ynot: dependent types for imperative programs. In ICFP, pages \n229 240, 2008. [35] T. Nipkow, L. C. Paulson, and M. Wenzel. Isabelle/HOL: A Proof Assistant for Higher-Order \nLogic, volume 2283 of LNCS. Springer-Verlag, 2002. [36] B. Nordstroem, K. Petersson, and J. Smith. Programming \nin Martin\u00adLoef s Type Theory: An Introduction. Oxford University Press, 1990. [37] S. Owre, J. M. Rushby, \nand N. Shankar. PVS: A prototype veri.cation system. In 11th CADE, 1992. [38] L. C. Paulson. Logic and \nComputation: Interactive Proof with Cambridge LCF. CUP, 1987. [39] S. Ranise and C. Tinelli. The SMT-LIB \nStandard: Version 1.2. Technical report, Department of Computer Science, The University of Iowa, 2006. \nAvailable at www.SMT-LIB.org. [40] P. Rudnicki and A. Trybulec. On equivalents of well-foundedness. J. \nAutom. Reasoning, 23(3-4):197 234, 1999. [41] S. Schulz. E A Brainiac Theorem Prover. Journal of AI \nCommunications, 15(2/3):111 126, 2002. [42] J. van der Berg and B. Jacobs. The LOOP compiler for Java \nand UML. Technical Report CSI-R0019, Computing Science Institute, Univ. of Nijmegen, Dec. 2000. [43] \nC. Weidenbach. Combining superposition, sorts and splitting. In A. Robinson and A. Voronkov, editors, \nHandbook of Automated Reasoning, volume II, chapter 27. Elsevier Science, 2001. [44] M. Wenzel. Isabelle/Isar \n a versatile environment for human\u00adreadable formal proof documents. PhD thesis, TU M\u00a8 unchen, 2002. [45] \nH. Xi. Dependent ML: An approach to practical programming with dependent types. J. Funct. Program., 17(2):215 \n286, 2007. [46] K. Zee, V. Kuncak, and M. Rinard. Full functional veri.cation of linked data structures. \nIn Proc. ACM PLDI, June 2008. A. Soundness Proofs Using the proof methodology described in Section 5, \nwe prove the soundness of the translations for each of the proof language con\u00adstructs given in Figure \n3. Figures 10 and 11 present these soundness proofs. The simplicity of these proofs illustrates the methodologi\u00adcal \nadvantages of de.ning proof constructs through a translation into guarded commands. p p1 ; p2 wlp([p], \nH) wlp([p1 ; p2], H) = wlp(([p1] ; [p2]), H) = wlp( p1 , wlp([p2], H)) . wlp([ p2] , H) . H assert F \nwlp([assert F ], H) = wlp((assert F ), H) = F . H . H note F wlp([note F ], H) = wlp((assert F ; assume \nF ), H) = F . (F . H) . H localize in (p ; note F ) wlp([localize in (p ; note F )], H) = wlp((skip ([p] \n; assert F ; assume false)) ; assume F ), H) = (F . H) . wlp([p], F ) . (F . H) . F . H mp (F . G) wlp([mp \n(F . G)], H) = wlp((assert F ; assert (F . G) ; assume G), H) = F . (F . G) . (G . H) . G . (G . H) . \nH assuming F in (p ; note G) wlp([assuming F in (p ; note G)], H) = wlp(((skip (assume F ; [p] ; assert \nG ; assume false)) ; assume (F . G)), H) = ((F . G) . H) . (F . wlp([p], G)) . ((F . G) . H) . (F . G) \n. H cases hF for G wlp([cases hF for G], H) = wlp((assert F1 . . . . . Fn ; assert (F1 . G) ; . . . ; \nassert (Fn . G) ; assume G), H) = (F1 . . . . . Fn) . (F1 . G) . . . . . (Fn . G) . (G . H) . G . (G \n. H) . H showedCase i of F1 . . . . . Fn wlp([showedCase i of F1 . . . . . Fn], H) = wlp((assert Fi ; \nassume F1 . . . . . Fn), H) = Fi . ((F1 . . . . . Fn) . H) . H byContradiction F in p wlp([byContradiction \nF in p], H) = wlp(((skip (assume \u00acF ; [p] ; assert false ; assume false)) ; assume F ), H) = (F . H) \n. ((\u00acF ) . wlp([p], false)) . (F . H) . ((\u00acF ) . false) . H contradiction F wlp([contradiction F ], H) \n= wlp((assert F ; assert \u00acF ; assume false), H) = F . \u00acF . H Figure 10. Soundness Proofs for Translations \nof Proof Language Constructs (continued in Figure 11) p instantiate .hx.F with ht wlp([p], H) wlp([instantiate \n.hx.F with ht], H) = wlp((assert .hx.F ; assume F [hx := ht]), H) = (.hx.F ) . (F [hx := ht] . H) . F \n[hx := ht] . (F [hx := ht] . H) . H witness ht for .hx.F wlp([witness ht for .hx.F ], H) = wlp((assert \nF [hx := ht] ; assume .hx.F ), H) = F [hx := ht] . ((.hx.F ) . H) . (.hx.F ) . ((.hx.F ) . H) . H pickWitness \nhx for F in (p ; note G) (where hx is not free in G) wlp([pickWitness hx for F in (p ; note G)], H) = \nwlp(((skip (assert .hx.F ; havoc hx ; assume F ; [p] ; assert G ; assume false)) ; assume G), H) = (G \n. H) . .hx.F . .hx.(F . wlp([p], G)) . (G . H) . .hx.F . .hx.(F . G) . (G . H) . G . H pickAny hx in \n(p ; note G) wlp([pickAny hx in (p ; note G)], H) = wlp(((skip (havoc hx ; [p] ; assert G ; assume false)) \n; assume .hx.G), H) = ((.hx.G) . H) . .hx.wlp([p], G) . ((.hx.G) . H) . .hx.G . H induct F over n in \np wlp([induct F over n in p], H) = wlp(((skip (havoc n ; assume 0 = n ; [p] ; assert F [n := 0] ; assert \n(F . F [n := n+1]) assume false)) ; assume .n.(0 = n . F )), H) = ((.n.(0 = n . F )) . H). .n.(0 = n \n. wlp([p], (F [n := 0] . (F . F [n := n+1]))) . ((.n.(0 = n . F )) . H) . .n.(0 = n .(F [n := 0] . (F \n. F [n := n+1]))) . ((.n.(0 = n . F )) . H) . .n.(0 = n . F ) . H Figure 11. Soundness Proofs for Translations \nof Proof Language Constructs (continued from Figure 10)  B. De.nition and Soundness of the Fix Construct \nFigure 12 gives the translation for the .x construct, which enables the developer to establish a formula \nof the form .x.(F ' . G). Unlike the other proof constructs we have presented, which can only enclose \nother proof statements, the .x construct may en\u00adclose statements that change the program state. In the \nstatement .x hx suchThat F in (c ; note G), F and G are formulas that may contain free occurrences of \nthe variables hx. The command c is an extended guarded command that may include commands that mod\u00adify \nthe program state, including, for example, Java code that has been translated into the extended guarded \ncommand language. Of course, c may also contain proof language constructs, including nested .x constructs. \nThe .x construct enables the developer to select arbitrary values of hx that satisfy F ' (provided that \nsuch values exist), where F ' is the formula F evaluated at the program point before c. The proof commands \nand loop invariants in c can refer to hx, but may not change hx (e.g., assigning a variable in hx to \na new value is prohibited). Thus, the formula F ' has the same meaning at all program points in c, even \nthough the commands in c may change the program state. [.x hx suchThat F in (c ; note G)] = hz0 := hz \n; assert .hx.F ' ; havoc hx ; assume F ' ; [c] ; assert G ; assume .hx.(F ' . G) where: hx does not \nappear outside F , G, and proof commands and loop invariants of c;  hz = mod(c) denotes variables modi.ed \nin c (disjoint from hx);  hz0 are fresh variables (used to save old values of hz);  F ' stands for \nF [hz := hz0].  Figure 12. The .x Construct and Its Translation At the program point after c, the translation \nasserts that G holds To show (1), we show  for the arbitrary values of hx selected to satisfy F '. If \nthe assertion 001 change ; c ; holds, the translation adds .hx.(F ' . G) to the assumption base. Note \nthat .x can be viewed as a generalization of the pickAny c ; assert G ; change ; CA CA assert G ; S1 \nS2 B@ assume .hx.(F ' . G) B@ assume .hx.(F ' . G) construct from Figure 8 in two ways. First, it permits \nstatements that change the program state in c. Second, it allows the quan\u00ad(3)ti.cation over hx to bind \nonly those values that satisfy F '. Thus, hx can be assumed to satisfy F ' in c. Note that, in contrast \nto the assuming construct (Figure 8), the translation of the .x construct We .rst show the step S1 by \nshowing, by induction on the syntax tree of c, that change ; cc ; change. We treat the loop command \nfrom Figure 2 as one abstract syntax tree node. (Figure 12) must ensure that the generated assume statement \nwill not restrict the values of any variables other than hx, such as, for ex\u00ad ample, Java variables within \nc. Indeed, if, for example, the body c of .x were the statement u.f = v, and F ' were the formula Case \nof non-structured commands. Let c be a havoc or assume command that occurs in the body of .x. We then \nshow change ; cc ; change (x null . u= null), then blindly assuming F ' would trivialize = the null dereference \ncheck on u. To enforce soundness, it is there-By de.nition, this condition reduces to showing that fore \nnecessary to ensure, before assuming F ', that, for the current values of the program variables, there \nexists at least one value for hx that satis.es F '. The command assert .hx.F ' ensures that this is the \ncase. The use of assert .hx.F ' has, simultaneously, another role: it ensures that .x serves as a generalization \nof pickWitness. The .x construct can be viewed as a generalization of the pickWitness construct from \nFigure 8 by taking as G the formula true. In this case .x picks hx as the witness for the existentially \nquanti.ed state\u00adment assert .hx.F '. Note that, if G is true, then the meaning of the translation of \n.x from Figure 12 is precisely havoc hx suchThat F ' . Therefore, .x can be used as a generalization \nof pickWitness that allows the use of Java code in its body c. Soundness. To show the soundness of the \nproof constructs together with .x, we build on and generalize the proof in Section A. We show that inserting \na set of proof commands and .x commands into a piece of Java code generates weakest preconditions that \nimply the weakest precondition of the concrete semantics given by the conjunction of the weakest precondition \nover all possible paths in the program. The soundness then essentially reduces to positive conjunctivity \nof commands [6, 26]. Consider an innermost occurrence of .x that contains no nested .x commands within \nits body c. Then we can 1) eliminate any proof commands p from c, to obtain a weaker command, then 2) \nreplace the loop desugarings of Figure 6 with the actual loop semantics, which (by soundness of the desugaring) \nproduces another weaker command. We .nally eliminate .x itself. To show soundness, it therefore suf.ces \nto show that wlp(.x hx suchThat F in (c ; note G),H0) . wlp(c, H0) (1) where c does not contain any proof \nlanguage constructs p or .x. Here the postcondition H0 of .x does not contain hx, which is justi.ed by \nthe assumption in Figure 12 that hx does not oc\u00ad cur outside F , c, and G. Furthermore, the loops within \nc are (.hx.F ' ) ..hx.(F ' . wlp(c, H)) implies wlp(c, (.hx.F ' ) ..hx.(F ' . H)), where H may contain \nhx. First consider the case of a command assume A. By the assumption that the body of .x cannot contain \nhx except in loop invariants, hx does not appear in A. The property thus reduces to showing that (.hx.F \n' ) ..hx.(F ' .(A . H)) implies A .((.hx.F ' ) ..hx.(F ' . H)), which easily follows for A not containing \nhx. Next consider an occurrence of havoc hy that occurs within the body of .x. In that case hy belongs \nto the modi.ed variables hz of Figure 12, which means that F ' does not contain any of the variables \nhy and that hx and hy are disjoint variables. This case then reduces to showing that (.hx.F ' ) . (.hx.(F \n' ..hy.H)) implies .hy.((.hx.F ' ) . (.hx.F ' . H)) under these assumptions on free variables, which \nis straightforward. Case of sequential composition. If by the inductive hypothesis change ; c1 c1 ; change \nand change ; c2 c2 ; change, then change ; c1 ; c2 c1 ; change ; c2 c1 ; c2 ; change Case of non-deterministic \nchoice. Similarly, by the induction hypothesis change ;(c1 c2) = = (change ; c1) (change ; c2) (c1 ; \nchange) (c2 ; change) (c1 c2) ; change V From the above steps, by induction we obtain change ; c c ; \nchange for all commands c without loops. Case of loop. Consider L of the form loop inv(I) c1 while(D) \nc2. For each n in the semantics of loops (2) the condition change ; cn cn ; change follows by the previous \ninductive proof for loop-free commands. From the de.nition of change we have that its weakest precondition \nis positively conjunctive, so wlp(change, .n=0Pn)= .n=0wlp(change,Pn). Using this fact we have the following. \n wlp(change ; cn,H) wlp(change, wlp( cn,H)) = n n = not desugared but remain in the syntax tree. The \nsemantics of V wlp(change, wlp(change, wlp(cn,H)) wlp(cn,H)) n=0 = loop inv(I) c1 while(D) c2 is given \nby the exact .xpoint semantics V n=0 that ignores loop invariants, that is, as countable non-deterministic \nchoice n cn over cn for n = 0, where cn is c1 ;(assume (D) ; c2 ; c1)n ; assume (\u00acD) (2) We represent \nthe remaining (non-loop) executable code constructs from Figure 2 by their desugaring (Figure 6) into \nthe simple guarded commands of Figure 4. We de.ne the command change as follows: change = assert .hx.F \n' ; havoc hx ; assume F ' . n=0 wlp(cn, wlp(change,H)) = wlp( n cn, wlp(change,H)) This shows (change \n; LL ; change) for a loop L. Change meets assert. It remains to show the step S2 of (3). De.ne f0 = change \n; assert G ; assume .hx.(F ' . G). We show wlp(f0,H0) . H0. Computing wlp(f0,H0) gives '' ' (.hx.F ) \n..hx.(F .(G . ((.hx.(F . G)) . H0)) which, after splitting the conjunct G . ((.hx.(F ' . G)) . H0) implies \n.rst .hx. F ' . H0. From this and .hx.F ', as well as the fact that hx does not appear in H0, we obtain \nH0.   \n\t\t\t", "proc_id": "1542476", "abstract": "<p>We present an integrated proof language for guiding the actions of multiple reasoning systems as they work together to prove complex correctness properties of imperative programs. The language operates in the context of a program verification system that uses multiple reasoning systems to discharge generated proof obligations. It is designed to 1) enable developers to resolve key choice points in complex program correctness proofs, thereby enabling automated reasoning systems to successfully prove the desired correctness properties; 2) allow developers to identify key lemmas for the reasoning systems to prove, thereby guiding the reasoning systems to find an effective proof decomposition; 3) enable multiple reasoning systems to work together productively to prove a single correctness property by providing a mechanism that developers can use to divide the property into lemmas, each of which is suitable for a different reasoning system; and 4) enable developers to identify specific lemmas that the reasoning systems should use when attempting to prove other lemmas or correctness properties, thereby appropriately confining the search space so that the reasoning systems can find a proof in an acceptable amount of time.</p> <p>The language includes a rich set of declarative proof constructs that enables developers to direct the reasoning systems as little or as much as they desire. Because the declarative proof statements are embedded into the program as specialized comments, they also serve as verified documentation and are a natural extension of the assertion mechanism found in most program verification systems.</p> <p>We have implemented our integrated proof language in the context of a program verification system for Java and used the resulting system to verify a collection of linked data structure implementations. Our experience indicates that our proof language makes it possible to successfully prove complex program correctness properties that are otherwise beyond the reach of automated reasoning systems.</p>", "authors": [{"name": "Karen Zee", "author_profile_id": "81100238724", "affiliation": "Massachusetts Institute of Technology, Cambridge, MA, USA", "person_id": "P1464311", "email_address": "", "orcid_id": ""}, {"name": "Viktor Kuncak", "author_profile_id": "81100277693", "affiliation": "&#201;cole Polytechnique F&#233;d&#233;rale de Lausanne, Lausanne, Switzerland", "person_id": "P1464312", "email_address": "", "orcid_id": ""}, {"name": "Martin C. Rinard", "author_profile_id": "81100087275", "affiliation": "Massachusetts Institute of Technology, Cambridge, MA, USA", "person_id": "P1464313", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542514", "year": "2009", "article_id": "1542514", "conference": "PLDI", "title": "An integrated proof language for imperative programs", "url": "http://dl.acm.org/citation.cfm?id=1542514"}