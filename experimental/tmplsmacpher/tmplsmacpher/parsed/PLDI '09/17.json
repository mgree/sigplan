{"article_publication_date": "06-15-2009", "fulltext": "\n Veri.able Composition of Deterministic Grammars August C. Schwerdfeger Eric R. Van Wyk Department of \nComputer Science and Engineering, University of Minnesota Minneapolis, Minnesota schwerdf@cs.umn.edu, \nevw@cs.umn.edu Abstract There is an increasing interest in extensible languages, (domain\u00adspeci.c) language \nextensions, and mechanisms for their speci.ca\u00adtion and implementation. One challenge is to develop tools \nthat al\u00adlow non-expert programmers to add an eclectic set of language ex\u00adtensions to a host language. \nWe describe mechanisms for compos\u00ading and analyzing concrete syntax speci.cations of a host language \nand extensions to it. These speci.cations consist of context-free grammars with each terminal symbol \nmapped to a regular expres\u00adsion, from which a slightly-modi.ed LR parser and context-aware scanner are \ngenerated. Traditionally, con.icts are detected when a parser is generated from the composed grammar, \nbut this comes too late since it is the non-expert programmer directing the composition of independently \ndeveloped extensions with the host language. The primary contribution of this paper is a modular analysis \nthat is performed independently by each extension designer on her ex\u00adtension (composed alone with the \nhost language). If each extension passes this modular analysis, then the language composed later by the \nprogrammer will compile with no con.icts or lexical ambigu\u00adities. Thus, extension writers can verify \nthat their extension will safely compose with others and, if not, .x the speci.cation so that it will. \nThis is possible due to the context-aware scanner s lexi\u00adcal disambiguation and a set of reasonable restrictions \nlimiting the constructs that can be introduced by an extension. The restrictions ensure that the parse \ntable states can be partitioned so that each state can be attributed to the host language or a single \nextension. Categories and Subject Descriptors D3.4 [Processors]: Pars\u00ading, Compiler generators; F4.2 \n[Grammars and Other Rewrit\u00ading Systems]: Parsing; F4.3 [Formal Languages]: Classes de.ned by grammars; \nD3.2 [Language Classi.cations]: Extensible Lan\u00adguages General Terms Languages, Algorithms, Veri.cation \nKeywords LR Parsing, context-aware scanning, language compo\u00adsition, grammar composition, extensible languages \n 1. Introduction. 1.1 Motivation. There is a rising amount of interest in the related areas of domain\u00adspeci.c \nlanguages, extensible languages, and in the tools and tech- Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 09, June 15 20, 2009, Dublin, Ireland. \nCopyright c &#38;#169; 2009 ACM 978-1-60558-392-1/09/06. . . $5.00 niques used to specify and implement \nthem. Of particular interest are systems that allow new syntax or semantic analysis to be added modularly \nto an extensible language framework. Ideally, it is done in a way that allows a non-expert programmer \nto extend his or her language with several eclectic extensions addressing the different aspects of the \nprogramming problem at hand. Consider the simple program in Figure 1. It is written in a ver\u00adsion of \nJava to which two extensions have been added (25). The .rst adds the using ... query ... and connection \n... con\u00adstructs to extend Java with the database query language SQL. Such an extension statically detects \nsyntax and type errors in the query and also adds a foreach construct, which iterates over results from \nthe query and extracts values from each query result. The import\u00adlike connection construct sets up the \nconnection to the database and retrieves database type schemas to type-check the query. The second extension \nadds a construct for representing boolean condi\u00adtions in a tabular form, inspired by similar constructs \nin modeling languages such as SCR (13). It consists of a keyword table fol\u00adlowed by a list of rows, each \nconsisting of a Java expression fol\u00adlowed by a colon and several truth-indicators (T, F, *) indicating \nif the expression is expected to be true, or false, or if it does not mat\u00adter. In this case, the table \nevaluates to true if a>18 is true and z == 10001 is false, or if a>18 is false (the value of z == 10001 \ndoes not matter). This extension checks that the expression in each row is of type boolean and that each \nrow has the same number of truth-indicators. To support these types of extensions, language extension \nframeworks and tools must allow new concrete syntax to be added to the language as well as new semantic \nanalysis to type\u00adcheck the extension constructs. Ideally, these extensions can be developed by separate \nparties, unaware of each other s extensions, and the non-expert programmer is provided with some mechanism \nto compose the host language (Java in this case) automatically with the language extensions. Al\u00adthough \nthe development of such language extensions may require some knowledge of programming language implementation \ntools and techniques, their use and composition should not. connection db_c with table person ; class \nDemo { booleanm(){ rs = using db_c query { SELECT age, zip FROM person WHERE state = \"NY\" } ; foreach \n(int a, int z) in rs { res=res&#38;&#38;table(a>18 :TF z == 10001:F*)} return res ; } } Figure 1. Code \nwritten in an extended version of Java.  A number of language processing tools and extensible language \nframeworks have been proposed. Polyglot (18) is a collection of Java classes that implement the core \nfront-end functions of a Java 1.4 compiler; one can add new classes and extend the existing ones to add \nnew language constructs and analyses. Others have investi\u00adgated the use of attribute grammars for building \nextensible speci.\u00adcations of languages. The JastAdd extensible Java compiler (9) is implemented in the \nJastAdd attribute grammar system (10). To ex\u00adtend this compiler, one writes new attribute grammar fragments \nthat the system combines to create a attribute grammar speci.cation for the extended language. From this \nspeci.cation a compiler for the extended language is automatically generated. We have developed ableJ \n(25) a similar system based on our Silver (24) attribute gram\u00admar system. Xoc (8) is an extensible language \nframework for C, also inspired by attribute grammars. These systems use standard LALR(1) parser and scanner \ngen\u00aderator technology such as Yacc and Lex (though they can be easily adapted to use other types of parser \nand scanner generators). These are notoriously brittle under composition and extension; merely adding \nor modifying a production can remove the grammar from the desired LALR(1) class. In the MetaBorg (5) \nsystem, where semantic processing is done by term rewriting in Stratego (29), the concrete syntax is \ninstead implemented using a scannerless GLR parser generator (28). Since GLR parsers can parse any context \nfree grammar the composition of the host language grammar and language extension grammars can always \nbe parsed. But the composed grammar may contain am\u00adbiguities; the programmer has no assurance that the \nparser created for their composed language will be deterministic and not, on oc\u00adcasion, return more than \none parse tree. We seek an approach that guarantees the determinism of the composed grammar. Parsing \nExpression Grammars (11) are closed under composi\u00adtion and thus satisfy this requirement and an extensible \nspeci.ca\u00adtion of C based on PEGs has been constructed (12). The determin\u00adism comes at a cost, however; \norder matters in the composition of PEGs. The concrete syntax tree returned by the parser may be different \nif the language extension grammars are composed in dif\u00adferent orders. Productions that have the same \nnonterminal on the left hand side are disambiguated by the order in which they ap\u00adpear in the speci.cation. \nDetermining the proper order of applying language extensions is the sort of implementation-level knowledge \nthat we do not want to require of the programmer. Furthermore, the problem of determining if altering \nproduction order alters the recognized language is undecidable (11).  1.2 Summary of results. In this \npaper, we consider the case of extending an existing host language H with some (unordered) set of language \nextensions {E1,E2, ..., En}. We have previously studied the issues of seman\u00adtics (25) and believe that \nthey are critical, but our concern here is only with their concrete syntax. Our goal is to generate a \nparser and scanner for the language H .{E1,E2, ..., En}. These speci\u00ad.cations consist of a context free \ngrammar that speci.es the parser and an association that maps each terminal in the grammar to a regular \nexpression, to specify the scanner. The speci.cation of a language L and an extension E are denoted, \nrespectively, as GL and GE . Grammars and the grammar composition operator (. * G) are de.ned formally \nin Section 2 but . * is just the component- G wise unions of the sets of terminals, nonterminals, productions, \nand terminal/regular-expression mappings de.ned in the grammars. We would like the resulting parser to \nbe deterministic; our parsing approach uses slightly modi.ed LALR(1) parsing and parse-table generation \ntechniques, ensuring no con.icts (shift\u00adreduce or reduce-reduce) in the generated LR parse table. We \nwrite con.ictFree(GL) to indicate that the parse table generated from grammar GL contains no con.icts \nand thus can be parsed with a deterministic LALR(1) parser. Also, we would like the scan\u00adner generated \nfrom GL to be ambiguity free, i.e., on any input the scanner will return exactly one token or, in the \ncase of a lexi\u00adcal error, zero tokens. We indicate this as lexAmbigFree(GL).A language speci.cation is \ndeterministic, indicated by det(GL),iff con.ictFree(GL) . lexAmbigFree(GL). Traditionally these analyses \nare performed on the complete lan\u00adguage speci.cation, i.e., after the extensions have been added to the \nhost language. In the approach to extensible languages outlined above, programmers can plug extensions \nfrom independent sources into their host language. Thus, an error message reporting a shift\u00adreduce con.ict \nin the generated parser or a lexical ambiguity in the generated scanner comes too late, as the programmer \nmay not be able to .x it; this is properly the job of the extension designer. Veri.able composition of \ngrammars. In this paper we introduce an analysis that can verify that the grammar for the composed language \nGC =GH . * , ..., GEn } will be deterministic G {GE1 , GE2 (det(GH )) if each extension grammar GEi individually \npasses a modular analysis. This modular analysis, denoted detm (GH , GEi ), can be described by the implication \nHH . * E1 En }). (.i . [1,n], detm (G, GEi )) =. det(GG {G, ..., G This states that if each extension \ngrammar GEi passes the modu\u00adlar determinism test (with respect to the host grammar GH )then the composition \nof GH and all of the extensions is deterministic. The implication of this is that extension writers can \ncertify their extensions as composable without needing to test against other lan\u00adguage extensions. (This \nis not that much unlike library writers cer\u00adtifying libraries by compiling them to ensure that they contain \nno type errors.) As will be seen, the modular test detm (GH , GE ) does put some restrictions on the \ntype of constructs that an extension E can add to H. For example, language extensions cannot specify \nsyntax such that new terminals, except for marking terminals (de.ned below), are added to the follow-sets \nof host language nonterminals. In our experience, these are reasonable for many language extensions. \nBut there are some that do not .t, such as the addition of new in.x binary operators to the host language \nH, though these can be added as part of an embedded language as is done in the SQL extension. We will \nlimit productions added by some extension E with a host language nonterminal on the left hand side to \na single production h . \u00b5E sE ,where \u00b5E is a marking terminal and sE is the extension s start nonterminal. \nThe effect of such a production is that it causes the parser, upon shifting \u00b5E , to enter a parse state \nthat is the domain of the language extension. Extensions typically add several productions whose left \nhand side is an extension-introduced nonterminal and the few restrictions placed on them are much less \nsevere. Critically, the right hand sides off these extension productions can contain terminals and nonterminals \nde.ned in the host language grammar GH . LALR(1) s brittleness and context-aware scanners. It may seem \nunlikely that this guarantee can be achieved, given that LALR(1) parsers can be rather brittle under \ncomposition and ex\u00adtension. Adding or modifying a production can easily remove the grammar from the desired \nLALR(1) class. A large part of this brittleness can be mitigated by the use of a context-aware scan\u00adner \n(21; 7; 27), which takes context into account when scanning. In this paper we have extended our notion \nof parse-state-based context-aware scanning as implemented in Copper, our LALR(1) parser and context-aware \nscanner generator (27). Each time the scanner is called by the parser it is passed the set of valid looka\u00adhead: \nterminals that can be accepted by the parser at that point in the parse. These terminals are those whose \naction in the LR parse table for the current state are shift, reduce,or accept, but not er\u00adror. The scanner \nwill then scan the input and only return a token that is in this set of valid lookahead. This allows \nterminals to have overlapping regular expressions as long as they appear in different parse-state contexts: \nit is the parse state context that disambiguates them. It does require the LR parsing algorithm to be \nslightly modi\u00ad.ed to pass parse-state information to the scanner when it is called to return the next \ntoken (27).  Consider scanning the type expression List<List<T>> in a language that includes Java-like \nparameterized types and a right bit shift operator >>.Ifthe >> operator is not valid in parse states \nwhere the closing bracket of a type expression is valid, then > will be in the valid lookahead set but \n>> will not. Thus the scanner will not return >> when parsing types and the grammar can be simpli.ed. \nThis is useful when extending languages, as one extension may introduce new terminals whose regular expressions \noverlap with those in other extensions but occur in different contexts. Note that the restrictions we \nplace on extension grammars would be unreasonable in a traditional scanning approach. With context-aware \nscanning, they are much more reasonable because extension writers can create their own terminal symbols \nthat may have overlapping regular expressions (with terminals introduced by other extensions) but this \noften does not cause con.icts in the composed language. For example, the table terminal introduced by \nthe SQL extension will not be in the same context as Java key\u00adwords or identi.ers and thus the lexeme \ntable can be used as an identi.er or a token for some other language extension, as it is in the table \nexpression extension. An appealing aspect of this approach is that we do not need to develop new parsing \nand scanning techniques from scratch to be able to certify language extensions as composable. The LR \nparsing technology used here is only slightly modi.ed from the established traditional approach. The \nscanner, by making it aware of its context, can be more discriminating in the tokens that it returns \nand thus language designers do not need to re-use the same token in many different contexts. Different \nterminals with the same regular expression can be used. This has a rather dramatic effect on the parser \n the additional tokens simplify the grammar and make it much less brittle and make practical the modular, \ncon.ict-free composability analysis that is proposed here. Paper Outline: Section 2 provides the formal \nspeci.cations of grammars used in this analysis and background material on LR parsing and context aware \nscanners. Section 3 describes the pri\u00admary contribution of this paper: a modular analysis of language \nex\u00adtension speci.cations that ensures that when a collection of exten\u00adsions are added to a host language, \nif each one individually passes the modular analysis, then the composed language has no parse\u00adtable shift-reduce \nor reduce-reduce con.icts. This analysis parti\u00adtions LR DFA of the extended language into sets of states \nthat are either the purview of the host language or of an individual language extension. This section \nalso provides a discussion of the algorithm s correctness. Section 4 describes the lexical ambiguity \nanalysis and how these techniques can be applied in the presence of practical speci.cations such as operator \nand lexical precedence. Section 5 discusses related work and brie.y explains how this partitioning of \nthe LR DFA can allow extension grammars to be separately com\u00adpiled down to parse tables that are composed \nby the programmer; thus allowing extensions to be distributed in a pre-compiled format. This section \nalso discusses limitations of this approach, and argues that the bene.ts of safe language composition \noutweigh the moder\u00adate loss of expressibility imposed by the restrictions of the modular analysis. Finally \nwe discuss Silver (24), an attribute grammar sys\u00adtem, and Copper (27), an LALR(1) parser and context-aware \nscan\u00adner generator we have developed to support the speci.cation and implementation of extensible languages \nand language extensions.  2. Grammar composition and parser and scanner generation. The problem we \naddress is how to ensure determinism while com\u00adbining a host grammar with several extension grammars, \nassuming no communication between the writers of the extensions. The host grammar is a context-free grammar \nin its own right, while exten\u00adsion grammars may reference host language terminals and nonter\u00adminals. \nExtensions, thus, are not de.ned to extend multiple host languages. While it may be appealing to see \nhow languages such as SQL can be embedded into multiple host languages (3), our in\u00adterests are in extensions \nthat are more closely tied to the host lan\u00adguage, both syntactically (in that extension constructs may \ninclude host language constructs, such as in the SQL foreach and table ex\u00adtensions) and also semantically. \nDetecting a type error in the table construct requires type-checking the Java expressions in it. 2.1 \nContext-free grammars and grammar composition. For the purposes of compiling a parser and scanner, a \ncontext-free grammar is embellished with a mapping (regex) that associates a regular expression (over \nsome alphabet) with each terminal sym\u00adbol. Thus, a language grammar is a 5-tuple (T, NT, P, s . NT, regex: \nT . Regex).Let CFGL denote the set of such context\u00adfree grammars. Below, we .x GH = (TH ,NTH ,PH ,sH \n, regexH ) to be the host language grammar. The grammars that de.ne lan\u00adguage extensions are similar \nto those for de.ning a complete (host) language, with one exception. Instead of having a start non\u00adterminal, \nthey have a bridge production that connects the extension\u00adde.ned language to the host language. We de.ne \nextension gram\u00admars to be of the following form: GE = (TE ,NTE,PE ,ntH . \u00b5EsE , regexE ) where sE . NTE \n,ntH . NTH ,dom(regexE)= TE .{\u00b5E }. The production ntH . \u00b5EsE is the bridge production. Its left hand \nside is a host language nonterminal; its right hand side is the extension s marking terminal (\u00b5E ), a \nterminal introduced by E but not in TE . It is followed by a nonterminal in NTE ,the start\u00adsymbol of \nthe embedded language. We can be less restrictive (but choose not to in order to simplify the presentation \nand discussion) and allow more than one bridge production each with a distinct marking terminal and \nany non-empty sequence of host and extension terminals and nonterminals following marking terminals. \nIf pE . PE, then symbols on the right hand side of pE are in TH . NTH . TE . NTE , but symbols on the \nleft-hand side must be in NTE . We say that GE extends GH if GE satis.es these conditions with respect \nto GH . Grammar composition is only de.ned when GE extends GH . Let CFGE denote the set of context-free \ngrammars de.ning language extensions. We will often use the unquali.ed term grammar but it will be clear \nfrom the context if the grammar is a language or extension grammar. Examples: Figure 2 shows a small \nportion of the grammars for Java 1.4 and its SQL and tables extensions. Each grammar declares the speci.ed \nnonterminals, terminals, and productions. The mark\u00ading terminal for the SQL query extension is the terminal \nUsing, which has the regular expression /using/; the extension s start symbol is Sql. The marking terminal \nof the tables extension is Tbl. Note that while the SQL productions do not use host language con\u00adstructs \n(except for a few terminals) the tables extension allows Java expressions to be in table rows (TRow). \nThus, it is syntactically correct (but not semantically so) to allow an SQL query or other phrase derived \nfrom Expr to appear at the beginning of a row. The SQL extension is split into two grammars here to conform \nto the grammar structure used in the proof of the modular analysis in Section 3, but in practice these \nare combined into one grammar.  Java 1.4: Nonterminals: Expr, PrimaryExpr, Dcl Terminals: Question \n/?/, Colon /:/, Comma /,/ Semi /;/, LParen /(/, RParen /)/, LBrk /{/, RBrk /}/, Id /[A-Za-z][A-Za-z0-9]*]/ \nExpr . Expr Question Expr Colon Expr Expr . PrimaryExpr PrimaryExpr . Id Dcl . ... SQL Connection: Nonterminals: \nConnDcl The names of nonterminal and terminal symbols in host and extension grammars can be assumed to \nbe distinct. One way to achieve this is to name grammars in the same way that Java pack\u00adages are uniquely \nnamed (based on Internet domain names) and append symbol names to their de.ning grammar name. 2.2 Background \non parser generation. This subsection provides some background on LR parsing, LALR(1) parsers, parse \ntables, and monolithic analysis of grammars. Readers familiar with these topics may wish to skim this \nsection. Traditionally, we would compose the host language and exten\u00adsion grammars to create the composed \nlanguage grammar GC = *H .G G {GE 1 , ...GE} and then create a parser for that grammar. If n LR parsing \nis used, we would create an LR DFA MC from the Terminals: Connection /connection/, SqlId /[A-Za-z]+/ \n, With /with/, Table /table/ Dcl . Connection ConnDcl ConnDcl . SqlId With Table SqlId Semi SQL Query: \nNonterminals: Sql, SqlQ, SqlIds, SqlExpr Terminals: Using /using/, Query /query/, Select /SELECT/, From \n/FROM/, Where /WHERE/, SqlId /[A-Za-z]+/ Expr . Using Sql Sql . SqlId Query LBrk SqlQ RBrk SqlQ . Select \nSqlIds From SqlId Where SqlExpr SqlIds . SqlId SqlIds . SqlId Comma SqlIds SqlExpr . ...  Tables: Nonterminals: \nBTable, TRows, TRow Terminals: Tbl /table/ PrimaryExpr . Tbl BTable BTable . LParen TRows RParen TRows \n. TRow TRows . TRow TRows TRow . Expr Colon TFStarList Figure 2. Sample grammar productions from host \nand extensions. Also, in practice we do not need to use a start nonterminal in the ex\u00adtensions; in the \ncase of the Tables extension we use the production PrimaryExpr . Tbl LParen TRows RParen instead. The \nproof generalizes to capture both of these modi.cations, but the simpler proof is presented below and \nthus the grammars in the .gure match that format. Composition of grammars. Let .G : CFGL \u00d7CFGE .. CFGL \nbe a non-commutative, non-associative operation on context\u00adfree grammars. If GE extends GH ,then GC =GH \n.G GE = (TC ,NTH . NTE ,PC ,sH , regexC ) where: TC = TH .TE .{\u00b5E }. \u00b5E is the extension s marking terminal. \n PC = PH . PE .{h . \u00b5E sE },where h . \u00b5EsE is the bridge production in GE .  j regexH (t) if t . TH \nregexC (t)= regexE (t) if t . TE or t = \u00b5E The operation for composing an unordered set of extensions, \n * * composed grammar (16; 17; 1). This LR DFA can be used to gen\u00aderate an LR parse table which is then \nchecked for shift-reduce and reduce-reduce con.icts. From a context free grammar G,anLR parser generator \ncreates an LR DFA from which an LR parse ta\u00adble is directly constructed. We do not review how LR DFAs \nare constructed from a context free grammar, but only the structure of these DFAs and how they are used. \nThe above references discuss the construction of LR DFAs. LALR(1) DFA. An LALR(1) DFA for a grammar GL \nis a 4-tuple ML = (GL , StatesL,sL . StatesL,dL),where StatesL is the set of states, sL is the DFA s \nstart state, and dL : States \u00d7 (TL . NTL) . States is the DFA s transition function. An LR DFA state \nis a pair S =(Items,la : Items .P(TL)),where Items is the set of items in that state and la maps each \nitem to its lookahead set. An item is a production in GL with a marker placed on its right hand side, \nto indicate the state of parsing. An item of the form x . a t\u00df, {t1,t2} in a state indicates that the \nparser has consumed input, a suf.x of which can be derived from a.Ifthe next terminal symbol consumed \nis t and it is shifted onto the parse stack the DFA moves to a state with the item x . at \u00df, {t1,t2}. \nIn the discussion of the modular analysis and argument for its correctness we will have need to compare \ndifferent LR DFA states; we introduce these comparisons here. Given two LR DFA states s and t: s is \nan I-subset of t, written s .I t,if Itemss . Itemst. They are LR(0)-equivalent, written s =0 t,if s \n.I t and t .I s i.e., they have the same item set. We use the term LR(0)-equivalent because in an LR(0) \nDFA, where there are no lookahead sets, two LR(0)-equivalent states would be equal. s is an IL-subset \nof t,written s .IL t,if s .I t and .i . Itemss. (las(i) . lat(i)). They are LR(1)-equivalent, written \ns =1 t,if s .IL t and t .IL s i.e., the states item sets and all lookahead sets are equal. Note that \nif s .IL t,and t produces a con.ict-free parse state, so does s. LR DFAs are converted to parse tables, \na more convenient representation, for use in parsing. See (1) for details on how this is done. Parse \ntables. Let States denote the set of all rows of all parse ta\u00ad bles. A parse table is de.ned as a 4-tuple \nPT =(GPT , StatesPT , S pPT ,.PT ,nPT . StatesPT ),where: GPT is a grammar that this parse table parses \ncorrectly.  pPT : StatesPT \u00d7 T .P(Actions),where Actions = {accept}.{reduce(p): p . P }.{shift(x): . \nStates}.  .PT : StatesPT \u00d7 NTPT .P(Goto),where Goto = : CFGL \u00d7P(CFGE ) . CFGL, which is written GH . \n.G G {goto(x):. States}. {GE 1 ,..., GE}, is the straightforward generalization of .G.There n is no \nnotion of ordering when composing multiple extensions If for some parse table pt, some n . States and \nt . T , with the host language; they can be seen as being applied all at ppt(n, t)= \u00d8, that cell contains \nan error action. A cell (n, t) in *Honce.Thus,thefollowingequivalenceshold: .G G {GE 1 , GE 2 }= a parse \ntable PT has a con.ict if |pPT (n, t)|= 2.Astate n is con.ict-free if for all t . TPT , cell (n, t) does \nnot have a con.ict: 1 ) .G GE 2 ) .G GE (GH .G GE 2 = (GH .G GE 1 .  .t . TPT . (|pPT (n, t)|= 1).Aparsetable \nPT is con.ict-free if all n . StatesPT are con.ict-free. The programmer can run this monolithic analysis \non the com\u00adposed grammar to ensure that there are no parse-table con.icts or lexical ambiguities. This \ncomes too late, however, as the program\u00admer will not necessarily have the skills to modify the grammars \nto .x the problems. What is needed is a modular analysis that the ex\u00adtension writer can use on his or \nher extension to ensure that when it is composed, by the programmer, with other extensions that also \npass the modular analysis, the resulting composed grammar will pass the monolithic test.  2.3 Context-aware \nscanners. The context-aware scanners used here are an extension of those described in (27). The scanner \ncan be constructed as described there or alternatively one can generate a scanner for each parse state \nthat only matches those in the valid lookahead set. How this scanner is constructed is not of concern; \nit is suf.cient that it return only tokens in the valid lookahead set for the current parse state. Given \na parse table PT (with terminals T ), valid looka\u00adhead sets are represented collectively by the function \nvalidLA : StatesPT .P(T ),where validLA(n)= {t : pPT (n, t) = \u00d8}(the terminals with non-error actions). \nFor this parse table and the function scan : P(T ) \u00d7 S* .P(T ) \u00d7 S*, it holds that ' scan(X, w)=(X',w) \nwhere X' is the set of terminals matched by the scanner and w' the lexeme they match. X is the valid \nlooka\u00adhead set and w is the input. Thus w' is a pre.x of w and X' . X. If scan(X, w)= \u00d8,itmeansthatno \nt . X matches a pre.x of w. A lexical ambiguity occurs when .n . StatesPT ,w . S*. (|scan(validLA(n),w)|= \n2).An ambiguity-free scanner is one for which this is untrue of every (n, w) . States \u00d7 S*.This can be \nveri.ed for all w by analyses on scanner DFAs (27). Lexical disambiguation. Context is the primary way \nin which terminals with overlapping regular expressions are disambiguated. Notions of lexical precedence \n(e.g., indicating that a keyword takes precedence over an identi.er terminal) can also be used. Using \nmarking terminals from different extensions may lead to lexical ambiguities because they may appear in \nthe same context (e.g.,at the beginning of an expression) and no lexical precedence settings can be speci.ed \nto disambiguate them, since they are in different extensions. A notion of transparent pre.xes (see Section \n4) al\u00adlows programmers to disambiguate them by pre.xing them with the grammar name, the same way that \na Java class name is pre.xed with its package name when two imported packages de.ne a class with the \nsame name. Other precedence setting techniques are also described in Section 4. These are used to ensure \nthat a composed language GC will have no lexical ambiguities that prevent the use of a deterministic \nscanner. Thus, in the following discussion of the modular analysis, we can focus our attention on the \nparser and as\u00adsume that there are no lexical ambiguities.  3. The modular determinism analysis. The \nmodular parser analysis isComposable(GH , GEi ) analyzes the context-free grammar of an extension with \nrespect to the host language being extended. If the extension passes this analysis it can be considered \ncerti.ed and safely composed with other certi.ed extensions by the programmer. Formally, this is expressed \nas , GE con.ictFree(GH .G GEi )) (.i . [1,n].isComposable(GHi ) . .\u00af GE =. con.ictFree(GH .*1 ,..., GE \n) Gn 3.1 The modular analysis isComposable. The restrictions we place on what kind of constructs can \nbe added in an extension to a host language are not restrictions on the extension grammar but on the \nLR DFA generated when compiling GH .G GEi as compared to the LR DFA generated when compiling GH alone, \ni.e., what states, items, and lookahead can be added to the LR DFA of GH to yield the LR DFA for GH .G \nGEi . The key factor is that items and lookahead added by one extension cause con.icts neither with the \nhost language nor with any other extensions that are added later (and have also passed this modular analysis). \nIn brief, the test isComposable(GH , GE ) must ensure that the grammar GH .G GE , and the LR DFA generated \nfor it, have the following properties: 1. For all ntH . NT H , no new terminals appear in its follow \nset follow(ntH ), except the marking terminal \u00b5Ei . 2. In states also appearing in the DFA for GH , \nno new terminals appear in the lookahead sets, except the marking terminal \u00b5Ei . 3. For states that \ndo not appear in the DFA for GH , but contain only host syntax items and thus could potentially be generated \nby several extensions, their item set and lookahead sets are subsets of those of some state also appearing \nin the DFA for GH that contains no con.icts, ensuring that these types of states (even when combined \nwith similar types of states generated by other extensions) will contain no con.icts.  In describing \nthe analysis and argument for its correctness we will need to consider various LR DFAs and different \nstates thereof: 1. The LR DFA for the original host language, denoted Morig ; GE extension Ei, denoted \nMEi ;and 2. The LR DFA generated for GH .Gi by the designer of G {GE grammer, denoted MC . 3. The LR \nDFA generated for GH 1 , ..., GE } by the pro\u00ad . * n The superscripts orig, Ei,and C indicate when the \nLR DFA is constructed: when the host language is de.ned, when an extension designer speci.es an extension \nand performs the modular analysis, and when a programmer combines multiple extensions. The extension \ndesigner will perform the modular analysis, which takes GH and GEi as inputs: isComposable(GHi ).The \n, GE analysis generates GH .G GEi and builds the two LR DFAs Morig and MEi (in the usual way) and then \nproceeds in two phases. First, it checks that no follow sets of host nonterminals have changed except \nto add the marking terminal. Formally, it checks if no E .nt . NTH . followGH .GGEi (nt) \\ followGH (nt) \n. \u00b5i . If additional (non-marking) terminals exist in the follow sets in GH .GGEi , then the analysis \nfails. Consider the production TRow . Expr Colon TFStarList from the tables extension and the conditional-expression \nproduction Expr . Expr Question Expr Colon Expr from the host language Java grammar, both shown in Figure \n2. The extension does not add to the follow set of Expr since terminal Colon is already there due the \nthe conditional\u00adexpression production. If new terminals are added to the follow sets of host language \nnonterminals two different extensions may compose individually with the host language to create con.ict-free \nparsers, but when combined together, the con.ict can arise. It is worth noting that this restriction \nis more easily satis.ed in syntactically rich fully-developed languages (such as Java), since their nonterminals \nhave larger follow sets, than in small toy lan\u00adguages with smaller follow sets. In the second phase, \nwhich is used only if the follow sets have not expanded, the analysis compares the two constructed LR \nDFAs Morig and MEi to determine if MEi can be constructed by adding new LR DFA states to Morig in a speci.c \nway (de.ned below), and adding new items and lookahead elements corresponding to this addition to the \nstates already existing in Morig . The constraints of the modular analysis only allow such additions \nto the states of the host LR DFA Morig as to allow a partitioning of the states in MEi . Such a partitioning \nassigns ownership of the states of MEi to either the host language, the extension, or neither. The LR \nDFA MEi consists of the states in the three DFA partitions: MEi (states  Ei Ei owned by the extension), \nMH (states owned by the host language), Ei and MNH (states owned by neither). The notion of ownership \nis indicated by the subscript. A diagram of this partitioned LR DFA is showninFigure3(a). It is possible \nthat these three partitions have no transitions be- Ei Ei tween them except for the single transition \nfrom MH into MEi labeled with \u00b5Ei , the marking terminal. If one of the extension s productions contains \na reference to a host language nonterminal in its right hand side there may also be other transitions, \nlabeled with host terminals, between the partitions. These possible transitions are indicated by the \ndotted lines in Figure 3. The analysis inspects each state n in M Ei . If each state can be assigned \nto one of these partitions, then the extension passes the modular analysis isComposable, and when several \nextensions are combined to form MC the parse table generated therefrom will be con.ict-free. Extension \nowned states MEi : A state n . MEi is assigned to Ei Ei the partition MEi if it has at least one item \n(i . Itemsn) whose left hand side symbol nt is an GEi nonterminal (i.e., nt . NT Ei ). States assigned \nto this partition are those used for parsing the embedded language of GEi . For the SQL extension, these \nstates parse the embedded SQL language. These states are said to be owned by GEi . There are few restrictions \non these states since they contain parts of the embedded language introduced by the extension, and hence, \nwhen extensions are merged, these states will not be merged with the states owned by other extensions. \nFormally, .n . MEi .(. (nt . \u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7 ) . Itemsn.(nt . Ei NT Ei ) . n . MEi ). Let n S be the state in \nMEi that contains the item h . \u00b5E s E . Ei ii SEi This is the extension start state n . M. Ei Ei In the \nLR DFA for the language composed by the programmer, these states may have new items added to them. These \nitems will only be bridge production items of the form h . \u00b5Ej sEj for some other extension Ej . Ei Host \nowned states MH : These states are said to be owned by the host language H. The analysis attempts to \nconstruct a bijection Ei . Morig m : MH that satis.es the criteria discussed below. The inverse function \nis denoted m -1. If such a bijection cannot be constructed, the analysis fails. If one can, then each \nstate in MEi H has a unique corresponding state in Morig . They are then further classi.ed by if and \nhow their item sets and lookahead are (safely) extended by the extension. If a state in Morig cannot \nbe so classi.ed the analysis fails. In constructing m, elements in its domain (i.e., MEi ) are further \nH Ei partitioned into 3 sets. The .rst is nochange(MH ).These are states that have not changed. A state \nn . MEi is a member of Ei Ei MH and assigned to the partition nochange(MH ) if .n0 . Morig .n0 =1 n. \nIn this case we specify that m(n)= n0.This checks if n0 and n have the same set of items and each item \nhas the same lookahead. If n0 hadnocon.icts,thenclearly n has no con.icts. This is one way in which we \nmaintain the determinism of Morig in MC . Ei The second is markingLA(MH ). These are states that do not \nhave new items, but may have the extension s marking terminal \u00b5Ei in the lookahead set of existing items. \nA state n . M Ei is assigned Ei . Morig to be in markingLA(M) if .n0 .n0 =0 n . (.i . H .\u00af \u00b5E n0 in the \noriginal host LR DFA has the same set of items as n (n0 =0 n) and for each item, either its lookahead \nsets are the same in both states or its lookahead in n has the single additional element \u00b5Ei . This does \nnot cause any con.icts; see lemma 3, below. This may result in shift and reduce actions based on this \nmark\u00ading terminal to appear in the parse table of MEi , but any con.icts will be detected by the extension \nwriter when checking that this ta\u00adble is con.ict free. This check is part of the analysis as speci.ed \nat the beginning of Section 3. Note the similarity of this test to the follow-set test. Both work along \nthe same basic principle; however, instead of entirely new symbols, this test aims to exclude from a \nstate symbols that were already in the follow set of some nontermi\u00adnal but did not show up as lookahead \nin this state. Itemsn0 .(lan(i) \\ lan0 (i) . i )). This checks that some state Ei The third is bridge(MH \n). These are states that have exactly E one new item, of the form h . \u00b5Ei si , [z], and also allow the \nmarking terminal \u00b5Ei in the lookahead of existing items. A state Ei Ei n . MEi is in MH andisassignedtobein \nbridge(MH ) if . Morig E .n0 .(Itemsn = Items\u00af n0 i si .{h . \u00b5E }. (.i . . Itemsn0 .(lan(i) \\ lan0 (i) \n. \u00b5Ei )). This checks that some state n0 in the original host LR DFA has the same set of items as n E \n(excluding the bridge item h . \u00b5Ei si ) and that the lookahead on the items that n and n0 have in common \nare identical except that the marking terminal \u00b5Ei may be in the lookahead of items in n. These items \ncause the parser to shift on the marking terminal of that extension to an extension language state in \nMEi , as indicated Ei by the two edges labeled \u00b5Ei in Figure 3(a). If n is a bridge state S then d(n, \n\u00b5E )= n\u00b5 ; it shifts to the start state of the extension. Ex- E tensions only add items of the form h \n. \u00b5Ei si to host language states. Thus, since the marking terminals for each extension are by de.nition \ndifferent we will not have any con.icts in the parse table of the programmer composed language. Ei New \nhost states MNH : Extensions do interact with the host language by including host language constructs \nin the extension\u00adintroduced constructs. Thus, productions in PEi may include host language nonterminals \nand terminals on the right hand side. These productions may cause states to be generated that contain \nitems consisting of only host language terminals and nonterminals, Ei but do not correspond to states \nin MH in one of the ways described above. We need to ensure that these new states do not have con.icts \nand are consistent with existing host language states, so that the determinism of the host language is \nmaintained in these states. This is needed to ensure that in creating the composed language LR DFA MC \nno con.icts are introduced based on how the extensions use host language terminals and nonterminals. \nEi A state n . MEi is assigned to the partition MNH if: Ei 1. It cannot be assigned to the partition \nMH in any of the three ways described above; 2. Each item i . Itemsn consists only of host language \nterminals  E and nonterminals, or is of the form h . \u00b5Ei si ; ' Ei ' 3. .n . MH .(n .IL n );and ' Ei \n' 4. .n . MH .(n .I n . n .IL n ' ). Conditions 3 and 4 ensure that productions that generate new- Ei \nEj host states from different extension DFAs (Mand M ), when NH NH combined, generate compositions of \nthese states in the new-host partition of the composed LR DFA MC , as in Figure 3(b). If a state n . \nMEi cannot be classi.ed as belonging to one of the Ei Ei Ei three partitions M, M,or M, then the modular \nanalysis Ei H NH  (a) (b) Figure 3. Abstract diagram of merging the host language with one extension \n(a) and with two extensions (b). fails. Since the partitions are, by these de.nitions, disjoint, the \norder in which the state n . MEi is checked against them does not matter. If each extension passes the \nmodular analysis and the host language extended with the extension has a con.ict free parser, then the \nhost language extended with all such extensions has a con.ict free parser as well. In Section 4 we de.ne \nthe modular lexical ambiguity checker isLexComp. In tandem, they ensure that certi.ed language extensions \ncan be safely composed by the programmer and recognized with a deterministic parser and scanner. Next \nwe provide some examples and then explain why this claim is true.  3.2 Examples of passing and failing \ngrammars. Composable extension. Consider the host, extension, and bridge productions below: PH = {E . \nT + E, E . T,T . x} PEi = {S . S1 E, S1 . #}, bridge production E . \u00b5E S This grammar passes the modular \ndeterminism analysis because the only reference to a host nonterminal inside the extension syntax occurs \nat the end of the .rst production in PEi . Therefore, the only symbols added to followGC (E) arethosein \nfollowGC (S).Since S itself appears only at the end of a production derived from E,this adds no new terminals \nto followGC (E). Extension adding to the follow set of a host nonterminal. Con\u00adsider an extension with \nthe following productions, which fails the analysis: PH = {E . T + E, E . T,T . x} PEi = {S . S1 E, S1 \n. T }, bridge production E . \u00b5E S In this extension, an expression derived from E can occur imme\u00addiately \nafter an expression derived from T . This means that all ter\u00adminals in followGH (E) are added to followGC \n(T ). This includes x/. followGH (T ); thus, the extension fails the analysis. Extension producing a \nnon-IL-subset condition. Consider another failing extension, with these following productions: PH = \n{E . T + E, E . T,E . x !,T . x}  PEi = {S . S1 zE,S1 . T }, bridge E . \u00b5E S  In the host grammar, \nboth E and T can derive expressions begin\u00adning with x. This results in there being a state inside Morig \ncontain\u00ading the items E . x !, {$} and T . x , {$, +}. The extension contains a reference to T ; the \nplacement adds z to followGC (T ), per se causing the extension to fail. However, unlike in the host \ngrammar there are no other references to x there; if x occurs in an extension expression it is derived \nfrom T .Thismeansthat there is inside the extension DFA a state containing only the item T . x , {z}. \nThis state is a new host state. This is an I-subset of the state named above, but is not an IL-subset \nof it, causing this extension to fail the analysis on a second count.  3.3 Correctness of the modular \nanalysis isComposable. Composability Theorem: The modular con.ict-free analysis isComposable performed \non the LR DFAs for GH and GE and traditional con.ict-free analysis performed on GH .G GE ensure that \nwhen the extension grammar E is composed with H and other extensions passing these analyses, the resulting \ngrammar will have a con.ict-free LR parse table. Formally, this is expressed as (.i . [1,n].isComposable(GH \n, GEi ) . con.ictFree(GH .G GE )) . i \u00af =. con.ictFree(GH . *G GEn 1 ,..., GE ) A sketch of the proof \nof this theorem follows. It is based on the fact that the partitioning of states in MEi , as seen in \nFigure 3(a), is extended to the partitioning of states in the composed language DFA MC , as seen in Figure \n3(b). A full version of the proof ap\u00adpears in an accompanying technical report (23). The following lem\u00admas \nare used in the proof; for brevity, their proofs are summarized. Lemma 1: No items from two extensions \nin any state. If a state n has (nti . a \u00df) . Itemsn,thenif nti . NTEi , {nt : (nt . . d) . Itemsn}. \nNTH . NTEi , i.e., no state has items with left-hand sides from more than one extension. Proof summary: \nThe only transition path from the start state of the composed LR DFA M to any state with such an item \nin it must, by construction, pass through a state seeded from item h . \u00b5E s E , that is, the extension \nstart state n S . This state ii Ei functions as a bottleneck that .lters out syntax from all other extensions. \nLemma 2: The follow sets of host nonterminals in the grammar GC add only marking terminals to the follow \nsets in GH . Proof summary: Any non-marking terminals introduced to the follow sets would have to have \nbeen put there by a single exten\u00adsion, which means that it would have been caught in the modular analysis. \nLemma 3: The class of con.ict-free states is closed under intro\u00adduction of bridge items and marking terminal \nlookahead. Proof summary: Since marking terminals are only de.ned with E one production h . \u00b5Ei si ,wherever \n\u00b5Ei can be shifted, so can the other terminals of .rst(h) (the set .rst(h) is the set of terminals that \nbegin any phrase derivable from h). Similarly, if \u00b5Ei is in a lookahead set, so is everything else in \n.rst(h). It follows that if there is a parse table con.ict on \u00b5Ei , an identical con.ict would occur \non all other terminals in .rst(h). Therefore, if a state is con.ict-free, con.icts cannot be introduced \nto it by adding bridge items or marking terminal lookahead. Proof sketch of the composability theorem: \nThe proof shows that the states in LR DFA MC built from the composed grammar GH 2 , ...GEH , MC .* {G1 \nE , GEn } can be partitioned into the sets MCE1 , G MC , ..., MC ,and MC NH . This partitioning is straightforward \nand E2 En depends one the structure of the state. The proof then shows that states in each of these sets \nare con.ict-free. Each of these partitions is described below and it is argued that the states in these \npartitions are necessarily con.ict-free.  Host state partition M C MC H : H will contain states n that \n1. are not in any M C (see below), and Ei 2. There exists a path through only non-extension states from \nthe start state of MC to this state, i.e., there exists a sequence {n0, (n1,s1) ,..., (nk,sk)} with n0 \n= sMC , dMC (ni-1,si) = ni, nk = n,and .i, j.nj . MC . Ei To reach this state from the start state of \nMC , we followed the path (s1,...,sk). None of these sis are extension symbols or marking terminals, \nsince each dMC (ni-1,si) points to a host state. Therefore, in each of the LR DFAs MEi , i . [1,n],inwhich \nthe host and a single extension are composed, we could follow the Ei path s1,...,sk and in each one end \nup in a state in MH that, if bridge items and marking terminal lookahead are not considered, is identical \nto n. This follows by construction, since host syntax is common to all MEi (for each i) and any states \nalong the same sequence of transitions on host-only symbols must have an identical set of host\u00adonly items \nand host-only lookahead. The state in MC is a union of the item set and lookahead sets of all of the \nstates in MEi .It only differs from any of these in that it contains additional bridge production items \nand marking terminal lookahead from multiple extensions. Since the marking terminals are distinct, the \nstate in MC will not have any con.icts even though it may have several bridge production items or lookahead \nsets with several marking terminals. If there were con.icts in this state, that con.ict would have to \nexist in one of the DFAs MEi , for some i. Extension state partitions MC : The LR DFA MC ,i . [1,n], \nEi Ei will consist of states containing items with an extension nontermi\u00adnal nt . NT Ei on the left hand \nside. Note that by lemma 1, these subsets are all disjoint. E Suppose that the bridge production for \nGEi is h . \u00b5Ei si .By construction, the only paths to any state n . MC from the start Ei S state of MC \nrun through the extension start state nEi . Furthermore, such a path must exist, since no state in the \nDFA is isolated. S If there is some state nI on a path between nEi and n for which nI . MC , then there \nis no syntax in its items from GE Ei i S in it, so by construction nEi must be on the path between nI \nand n. This constitutes a cycle. Since there is by de.nition an acyclic path between those two states, \nevery such acyclic path must consist entirely of states in MC . Ei The sequence of symbols labeling this \npath are all in TH . NTH . TEi . NTEi . If one were not, then it is in some TEj . NTEj . But this means \nthat the symbol in question must be in the state preceding the transition marked with that symbol, which \nis a contradiction. This means that MC forms an unbroken block of Ei S states connected by transition \nfrom nEi along paths marked solely with symbols in TH . NTH . TEi . NTEi . S Consider the properties \nof nEi . It is seeded from the single item iE = h . \u00b5iE siE , and is the only state containing this \nEi item. There is a corresponding state n0 . MEi seeded from iE . By construction lan0 (iE ) . lanS (iE \n). Since by construction Ei S there is a transition to nEi from any state in which there are items h \n. \u00b7\u00b7\u00b7 , the lookahead on iE is exactly the whole follow set of h: lanS (iE )= followGC (h). Analogously, \nlan0 (iE )= Ei followGH .GGEi (h). Therefore, the difference between the two lookahead sets is the same \nas the difference between the two follow sets: la S (iE )\\ lan0 (iE )= followGC (h)\\ followGH .GGEi (h). \nnEi By lemma 2, this difference consists entirely of marking terminals. Using the above process of following \ntransitions simultane- S ously, this time in MC and MEi and from nEi and n0,itfollows by construction \nthat for every state in n . MC there is a corre- Ei ' Ei sponding state in n . MEi , accessible via the \nsame path. Since S every acyclic path from nEi to n goes entirely through states in MC Ei , structural \ninduction shows that new bridge items are the only sort of new items that can appear, and n S and these \nbridge items Ei being the sole source for any new lookahead, marking terminals are the only new lookahead. \nTherefore, by lemma 3, no state in MC has a con.ict. Ei New host partition MC MC will contain all states \nnot in NH : NH the above subsets, which by elimination: 1. are not in any MC ,and Ei 2. all paths from \nMC s start state to n pass through some exten\u00adsion start state n S . Ei Firstly, note that it is altogether \npossible that there are paths S from several such nEi sto n, not counting paths through other extension \nstart states n S . Call the set of grammars with such a path Ej Contribn . |Contribn |= 1. No such path \ncontains any marking terminals (that would put it through some n S ) or terminals not Ej from the particular \nextension from whose start state it originates (in consequence of there being no marking terminals). \nNeither does it go through any state nH . M C H : as all transitions out of such states, except those \nlabeled with marking terminals, have another state in MC H as a destination, it follows that every state \nbetween nH and n is in MCH , which it is not. H . But this would put n in MC It is now established that \nfor each GEi . Contribn , there is a path with every transition in TH .NTH .TEi .NTEi leading from S \nnEi to n. This means that there is an identical path in MEi leading to a state ni that, ignoring bridge \nitems, is LR(0)-equivalent to n. Ei Ei Ei This state is in neither MH nor MEi , hence must be in MNH \n.For the same reasons as above, in addition to the new marking terminal lookahead, n contains exactly \nall the lookahead from all such ni. This is the set of lookahead that could potentially cause con.icts \nin this state. By conditions 3 and 4 of the analysis that assigns states to MEi NH , ' Ei ' there is \nsome ni . Mwith ni ni, and furthermore for NH .I all such ni' , ni .IL ni' . Furthermore, since the most \nthe item sets of the nis differ is one bridge item, and the addition of a bridge item to ni would imply \nthat it was also added to any I-superset of ni, it follows that the space of I-supersets of each ni maps \nto the same set of states in Morig , which are these states shorn of their bridge items and marking terminal \nlookahead. Furthermore, each hypothetical state consisting of ni shorn of its one possible bridge item \nand marking terminal lookahead is an IL-subset of each of these states in Morig . Now the subset relation \nis closed under union. This means that if a state consists of the union of the items and lookahead of \nseveral IL-subsets of the same state, the union state is itself an IL-subset of that state. It follows \nimmediately that the hypothetical state consisting of n shorn of all its bridge items and lookahead is \nan IL\u00adsubset of each of the Morig states. This state, therefore, is con.ict\u00adfree, and the addition of \nmarking terminal lookahead and bridge items will not add con.icts; therefore, n is also con.ict-free. \n  4. Lexical disambiguation and practical concerns. 4.1 Resolving lexical ambiguities. Above, we have \nassumed that there are no lexical ambiguities, em\u00adphasizing that if each language extension chosen by \nthe program\u00admer passes the modular analysis isComposable, then the com\u00adposed language parse table will \nbe deterministic. In practice, reg\u00adular expressions for terminal symbols do overlap and the language \ndesigner resolves them, typically by specifying some sort of lexical precedence so that, for example, \nkeyword terminals are preferred over identi.er terminals for lexemes that match both.  With context-aware \nscanners such as Copper (27), the parse\u00adstate-based context used to disambiguate the lexical syntax allows \nthe composed language to have terminal symbols that have overlap\u00adping regular expressions (those that \nshare at least one common lex\u00ademe) as long as those terminals are not in the same valid lookahead set \nfor any parse state. Based on the partitioning of MC described in Section 3 we know that non-marking \nterminals of different exten\u00adsions cannot cause lexical ambiguities in the composed language since they \nnever occur in the same valid lookahead set. (Lexical ambiguities between terminals in a single extension \nand/or the host language can be resolved by the extension designer.) For example, the Table keyword terminal \nintroduced by the SQL extension will never be in the same context as the table extension s Tbl termi\u00adnal \neven though both have the same regular expression /table/; therefore, that causes no lexical ambiguity. \nBut since bridge-production items can be (safely) added to parse states owned by the host language or \nother extensions we have the possibility for lexical ambiguities in two ways. The .rst is between marking \nterminals from different extensions. For example, the SQL marking terminal Using and the tables marking \nterminal Tbl can both appear at the beginning of an expression and there are thus in the same valid lookahead \nset for several parse states. The second occurs more rarely, in parse states owned by an ex\u00adtension E \nbetween its non-marking terminals and other extension marking terminals. (Note that this does not occur \nin the SQL exten\u00adsion since its Table terminal cannot appear in the same location as a Java expression, \nwhich can begin with the table extension s Tbl marking terminal.) Most scanner generators, including \ncontext-aware ones such as Copper, allow a global precedence relation to be speci.ed be\u00adtween terminals, \nso if s takes precedence over t, no string match\u00ading s will match t, even in contexts where s is invalid. \nThis type of static precedence does not respect boundaries of parse state: if some terminal te . TiE \nis made to take precedence over a host terminal th . TH , no lexeme matching te can match th even in \na state belonging to some other extension GEj . For this reason, extension writers should avoid de.ning \nstatic precedence relations between host terminals and extension terminals, though it is reason\u00adable \nfor static precedence to be speci.ed on host language keyword terminals. If an extension writer does \nthis, no additional con.icts or ambiguities will occur, but the presence of GEi will alter the lan\u00adguage \nof GEj . Also, extensions may not de.ne any new precedence relations between host terminals. Transparent \npre.xes (27) provide a solution for disambiguating marking tokens. The technique is similar to how class \nnames are disambiguated in Java programs when two packages that de.ne a class with the same name are \nimported into a Java program; the package name (based on the unique Internet domain name of the package \nauthor) is prepended to the class name to indicate the desired class. Grammar names, which can also be \nbased on Internet domain names, can be used to disambiguate marking tokens. This approach is taken by \nCopper and Silver. The grammar names are added to the valid lookahead tokens passed to the scanner. If \nthe input matches such a name, the scanner does not return it to the parser, but instead uses this extension \nname to remove terminals de.ned in other extensions from the valid lookahead set and scans again from \nthe point in the input after the grammar name. Now, only terminals from the extension and the host language \nare in the valid lookahead set so there will be no lexical ambiguities. (If there were, they would have \nbeen resolved by the extension writer.) Thus, if the scanner does report a lexical ambiguity to the programmer, \nit can be easily resolved by the programmer by adding the extension name before the marking token. This \nis the same burden that is placed on Java programmers and thus we do not feel that it is unreasonable. \nOur lexical ambiguity analysis reports these possible ambiguities, but these do not prevent the extension \nfrom passing the modular lexical ambiguity analysis. The analysis does, of course, check for lexical \nambiguities between extension and host language terminals, which are then resolved by the extension writer. \nIn addition to providing transparent pre.xes, the extension writer must specify a default behavior that \nuse of the pre.x can preempt. This is done by indicating that a marking terminal \u00b5E is of one of the \nfollowing sorts: Reserve against other terminals. This means that static prece\u00addence relations will \nbe formed with \u00b5E taking precedence over any terminals with which it con.icts lexically, and no string \nmatching \u00b5E s regular expression can match any of these ter\u00adminals in any context. The use of this option \nshould be avoided for the same reason as other static precedence relations between host and extension \nterminals should be avoided.  Prefer over host terminals. This means that wherever \u00b5E causes an ambiguity \nwith another terminal or terminals, the ambiguity is resolved in favor of \u00b5E .  Avoid in favor of host \nterminals. This means that wherever \u00b5E causes an ambiguity with another terminal, the ambiguity is resolved \nin favor of the other terminal. If one has a set of terminals X disambiguated via this mechanism, and \na new marking terminal \u00b5E is introduced, a new ambiguity X .  .\u00af i \u00b5Ei is resolved the same way X \nwas. N.B.: The use of this option mandates the use of \u00b5E s transparent pre.x to match it. Thus, there \nare a number of ways to design the host and ex\u00adtension languages to handle lexical disambiguation. The \nmodular lexical ambiguity checking analysis isLexComp veri.es that no lexical ambiguities are possible \nin the composed language except for those involving marking terminals that can be disambiguated by the \nprogrammer. Thus, a deterministic scanner can still be used and it can be designed to give helpful error \nmessages when a lex\u00adical ambiguity occurs. It can rescan the input with all terminals in the valid lookahead \nset, see which match, determine which exten\u00adsions de.ned those terminals and suggest to the programmer \nthat a transparent pre.x naming one of these extensions is needed. This disambiguation process requires \nno implementation-level knowl\u00adedge of the composed language parser or scanner and is essentially the \nsame as disambiguation done for ambiguous Java class names. Thus we do not consider it a signi.cant burden \non the programmer.  4.2 Operator precedence. We prove above that the introduction of a marking terminal \n\u00b5Ei , where h . \u00b5Ei s Ei , cannot cause parse-table con.icts because the con.ict in question would also \noccur on other members of .rst(h) and, therefore, be caught by the modular analysis. However, this does \nnot hold true if the con.icts on the non-marking terminal cells have been resolved by setting operator \nprecedence rules on these other members of .rst(h), which do not apply to \u00b5Ei .Given that marking terminals \nare pre.xes of a sort, this is unlikely to occur in practice. We have not seen any instance where it \noccurs, but for operator precedence to be used in this approach, one of the following two solutions could \nbe applied. Specify a blanket precedence rule. The extension writer could provide a blanket precedence \nrule specifying how to resolve such con.icts should they occur. This would simply be an ordinary operator \nprecedence speci.ed on a placeholder marking terminal, \u00b5 *, standing in for any \u00b5Ei that are introduced. \n Tighten the test. Extensions that reference a host nonterminal h could also be subjected to more stringent \ntests. While compiling the LR DFA for GH .G GEj , it is possible to keep track of what nonterminals contribute \nlookahead to items in which states. Let Interlopersj signify every host nonterminal contributing looka\u00adhead \nto any state owned by GEj . Then ensure that each of these nonterminals has a symbol in its .rst set \nwith no operator prece\u00addence de.ned on it. De.ne a bijection no mark : \u00b5 * 1,...,\u00b5 * |Interlopersj |. \nInterlopersj , mapping a fresh new marking terminal to every member of the set Interlopersj . Then compile \na grammar consisting of GH .G GEj combined with a set of productions mark(\u00b5 *i ) . \u00b5i*.Ifthis compiles \nwithout con.icts, the validity of the proof is restored.  5. Discussion. In this section we discuss \nsome opportunities for future work based on the partitioning of the LR DFA described in Section 3 as \nwell as some of the related work. We then describe our experience in build\u00ading various language extensions \nand the limitations imposed by the modular isComposable analysis. Finally we comment on the im\u00adportance \nof static analyses in the adoption of extensible languages and tools we have developed to support extensible \nlanguages. 5.1 Future work. Parse table composition. The strict separation of the parse states described \nabove suggests that it may be possible to compile an ex\u00adtension grammar into a parse table fragment that \ncould be com\u00adposed with the host language parse table (and other extension parse table fragments) at \nthe direction of the programmer when he or she selects the set of extensions with which to extend the \nhost language. Because of this strict separation, the items h . \u00b5Ei s Ei are the only additions to states \nin host language partition of the LR DFA MC H for the composed language. Thus, in those states, any new \nac\u00adtions introduced by adding an extension are only added in the \u00b5Ei columns of the parse table. States \nassociated with the extensions (in MC ) are entirely separate. It follows that, if GH .G GE has passed \nEi i the modular test, one can take parse tables for Morig and MEi , concatenate their rows, and add \na new column \u00b5Ei with appropriate actions, one will have a parse table for GH .G GEi , veri.ed cor\u00adrect \nand free of con.icts. Furthermore, one can concatenate a parse table for Morig with those of several \nextensions, adding a new col\u00adumn for each marking terminal; the resulting parse table would then parse \nMC and also be con.ict-free. Extension-speci.c lexical static precedence. Static lexical prece\u00addence, \nas used to specify that keywords take precedence over iden\u00adti.ers, is a convenient mechanism for disambiguating \nlexical syn\u00adtax. However, as discussed in Section 4, its use is not recommended for indicating that extension \nintroduced terminals have precedence over those de.ned in the host language, since such precedence speci.cations \nhave effect in all parse states. The strict separation of parse states may also be useful here in that \nit would allow an extension-speci.c static precedence that only has effect in the parse states owned \nby the extension in which the keyword is de.ned.  5.2 Related work. Context-aware scanning. In the TICS \nalgebraic compiler frame\u00adwork (20) the notion of context is used in the pattern-matching parser and in \nthe scanner. The scanner can take into account the results of the n previous scans in determining how \nto recognize the current input (21); the value of n is determined when the scanner is generated. This \nis a lexical notion of context and is more limited than parse-state-based context-aware scanning such \nas used in Cop\u00adper, which provides contextual information based on an unbounded number of tokens to the \nleft of the current point in the .le. How\u00adever, the context used in the TICS scanner is more general \nin two ways: the scanner also considers the context of what can follow the current token and it introduces \nthe notion of non-context in which terminals can specify contexts in which they are not valid. These \ncan be used, for example, to distinguish an integer constant termi\u00adnal from a label. They may have the \nsame regular expression, but the label has a following context of a colon and the integer has a colon \nin its following non-context speci.cation (21). The Tatoo parser and scanner generator (7) has two innovations \nof relevance here. First, it uses a lookahead activator implement\u00ading an independently developed notion \nof parse-state-based con\u00adtext aware scanning. However, the expressiveness of parse-state\u00adbased context-aware \nscanning appears not to have been .eshed out in Tatoo, as the lookahead activator is presented as a scanner \nopti\u00admization. Separate parse table-based approaches. The second innovation of Tatoo is that it also \nsupports rapid composition of extensions without the need for regenerating parse tables. The system can \nswitch between different pre-compiled parse tables and thus sup\u00adport some notion of parse table composition. \nBut Tatoo s concept of extensions is different from ours: while we conceive of a fully independent host \ngrammar supplemented by an unspeci.ed set of extensions, in Tatoo, certain holes are explicitly left \nin the host grammar, and users must .ll each of these with one of a possible selection of extensions \nwritten to .ll that particular hole. There\u00adfore, the extensions to a Tatoo grammar are not optional, \nare of a .xed number, and are of a more restricted character. Component LR-parsing (30) (CLR) is similar \nto Tatoo s ap\u00adproach in that multiple separate parse tables are used, but CLR in\u00adtroduces two new actions: \nswitch and return. When a component parser enters an error state it inspects the current state and will \nei\u00adther switch to another component parser, return to the parser that called it, or backtrack. This point \nat which the calling parser fails is where, in our approach, a shift on a marking terminal would oc\u00adcur. \nThe priorities of these new actions are .xed by the parsing algorithm and the order in which component \nparsers are called is determined by the textual-order in which they appear in the spec\u00adi.cation. Backtracking \nis used when a component parser fails and the system backtracks to try another component parser. It would \nbe interesting to add backtracking to our approach, but limit it to the states at which a marking terminal \nis shifted. This would allow extensions with overlapping marking terminals, at the expense of backtracking. \nArbitrary parse table composition. Bravenboer and Visser (6) outline a strategy for composing the parse \ntables of arbitrary ex\u00adtensions into a single GLR (speci.cally, GLR(0)) table. This ap\u00adproach is based \nupon a construct called an .-NFA a nondeter\u00administic LR(0) .nite automaton that allows .-transitions. \n.-NFAs being very easy to glom together in a composition, they are made use of as an intermediate step \nin the process of producing compos\u00adable parse tables. The .-NFA for the host or a particular extension \nis determinized into an .-DFA, whichisanordinaryDFAwith the .-transitions retained as metadata. This \nallows the addition of new items to an .-DFA state (i.e., the introduction of new exten\u00adsions) without \nthe need to recompute the entire closure of the state. Most of the information from the .-DFA is then \nincluded with the parse table. The generality of this method is at once a strength and a weakness: although \nit is able to do on-the-.y composition of a host grammar with any extension, there is no way to guarantee \nthat even one such extension, let alone several unrelated ones, will compose deterministically or without \nother issues. As most of this method concentrates on the potentially inef.cient process of recomputing \nclosures on-the-.y (entirely unneeded when using our approach of marking tokens) and ignores scanner \nissues (being designed for a scannerless GLR parser), its results, but not its methods, are similar to \nours.  Incremental generation of LR parse tables. Many have stud\u00adied the problem of incrementally generating \nLR parse tables. Hor\u00adspool (15), for example, presents a similar method to Bravenboer s for addition \nand deletion of productions in situ in deterministic parse tables. However, Horspool s method was designed \nfor inter\u00adactive development of grammars, where a whole grammar is being modi.ed and debugged all in \none place and a monolithic determin\u00adism analysis would be of much more use.  5.3 Experience with the \nmodular analysis restrictions. We have built parsers and scanners in Copper for Java 1.4 and ANSI C and \ndesigned several language extensions to these host lan\u00adguages that pass the modular analysis. For example, \nto the Java 1.4 host language we have added the signi.cant subset of SQL and the boolean-expressions \ntables mentioned in Section 1 (25). We have also implemented an extension that adds algebraic data types \nto Java in a manner similar to that of Pizza (19), specifying concrete syntax for de.ning different cases \nof a class and for pattern match\u00ading over them. Further examples include dimension-types used to check \nfor errors in computations over physical measurements (e.g., to check that a length measurement is not \nadded to a mass or accel\u00aderation measurement (26)). All of these extensions pass the mod\u00adular analysis \nisComposable; in fact, many of them were designed before the modular analysis was. Thus, our experience \nshows that the restrictions imposed by is-Composable are not too severe. That said, there are some limita\u00adtions. \nFor example, adding a new in.x binary operator (e.g.@)to the host language is not allowed since a production \nof the form Expr ::= Expr ' @ ' Expr does not have a marking terminal. (New in.x binary operators can, \nhowever, be speci.ed in the languages de.ned in extensions.) Many extensible language frameworks (10; \n24) do support type-based overloading of existing host language operators. Thus, adding a new numeric \ntype (e.g., complex or ratio\u00adnal numbers) may require new syntax to de.ne the type but no new syntax \nfor arithmetic operators over these values. If in the extension in Figure 1 we replaced the extension \nkey\u00adword foreach with the host language keyword for, we would not have a marking terminal in the bridge \nproduction of this ex\u00adtension and our analysis would thus reject this extension. This type of extension \nwould be possible with traditional LALR(1) parsers, PEGs and GLR parsers. In our approach, one could \nalso write the production using the host language for terminal, but now we must rely on the monolithic \nanalysis to detect any con.icts. Thus, one does not lose determinism completely, but the ability of the \nexten\u00adsion writer to ensure it is lost. In this case one could also design the host language to support \noverloading of the enhanced for loop (similar to operator overloading). Such an overloading would be \nappropriate since the intention of iterating over each element re\u00adturned from the query is consistent \nwith the intuitive understanding of the construct. Thus the extension would not need to add new concrete \nsyntax speci.cations. Therefore, one area of future work is to study how to best design host languages \nto support different types of overloading to mitigate this limitation to some degree. AspectJ. We have \nalso extended our Java 1.4 speci.cation to cre\u00adate a speci.cation for AspectJ, a language that provides \naspect constructs in Java. This language has historically proven dif.cult to parse using traditional \nmethods. The AspectJ Bench Compiler (abc) (14) uses a traditional LALR(1) parser, but uses a moded scanner \nthat switches modes based on whether or not an aspect con\u00adstruct is being parsed. This allows different \nkeywords to be reserved based on the scanner mode, but the hand-written mode-switching speci.cations \nare not declarative. More recently, Visser et al. (4) have devised a declarative parser for AspectJ in \ntheir nondetermin\u00adistic scannerless-GLR framework although they had to add a new feature, grammar mix-ins, \nto handle the problem of the differ\u00adent sets of keywords. We have adapted the LALR(1) grammar used in \nabc to ex\u00adtend the Java grammar in our ableJ framework. As it happens, with a context-aware scanner, \nthe abc version of AspectJ can be parsed deterministically and declaratively (22). Essentially, context-aware \nscanning provides a more .ne-grained version of the mode-switching that is done manually in the abc scanner. \nHowever, AspectJ does not pass our modular determinism anal\u00adysis, for two reasons. First, AspectJ introduces \nlarge numbers of new keywords, placed in such a way that they are allowed to follow host Java constructs \n(e.g., type constructs). This adds these termi\u00adnals to the follow sets of host nonterminals and causes \nthe test to fail. Second, AspectJ extends some Java host nonterminals that de\u00adrive phrases beginning \nwith an access modi.er such as public or protected. For example, Java speci.es the production Dcl . Modi.ers \nType Id ... for methods and AspectJ adds the production Dcl . Modi.ers Aspect Id ... to de.ne certain \naspect constructs. The new Aspect keyword is not a marking terminal at the beginning of the productions \nright-hand side. However, the host Java grammar could be refactored, and the extension productions modi.ed, \nso that they satisfy the require\u00adments of isComposable. Thus writers of a host grammar may be able to \nincrease the number of extensions that pass the analysis by designing the grammar in a particular way. \nOur Java 1.4 grammar was directly derived from the freely available JavaCup version (2) with no such \nmodi.cations, and our extensions (except AspectJ) passed the analysis with that host grammar. Thus it \nseems that the way one naturally writes grammars does lead to a high degree of extensibility. Alternate \nrestrictions. The set of restrictions imposed by the is-Composable analysis are not the only ones that \nwe have consid\u00adered. For example, we experimented with tighter but simpler re\u00adstrictions de.ned on the \ngrammar (25), instead of on the LR DFA. One required beginning and ending marking terminals. However, \nthese proved too restrictive to admit many of our previously imple\u00admented extensions. We also considered \nrelaxing, but complicating, the restrictions as follows: the analysis would, given a subset A of host \nnonterminals, only guarantee that the extension would com\u00adpose if all the other extensions with which \nit was composed had a bridge production with its left-hand side in A. This exploited the fact that few \nhost nonterminals would be used on left-hand sides of bridge productions (e.g., expression and statement \n). However, it is unclear if this is worth the added complexity.  5.4 Restrictions on expressiveness \nversus safe composition. It may still be asked, Are the restrictions imposed by this analy\u00adsis too severe? \nWe argue that the importance of a static analysis, performed by the extension writer, outweighs the moderate \nloss of expressibility imposed by the modular analysis restrictions. Other parsing techniques that support \nlanguage extension do allow some constructs not allowed by our analysis and it is appropriate to com\u00adpare \nthese approaches, as we have. It is also appropriate to compare all of these approaches to the accepted \nmechanism that program\u00admers currently use to extend their language with new abstrac\u00adtions: libraries. \nThey provide no new syntactic constructs (or new semantic analysis), but because the library writer can \ncompile and type-check the code before it is distributed, the programmer is as\u00adsured that he or she can \npick any combination of libraries needed to address the particular problem, and use them as needed in \na pro\u00adgram. It is this level of assurance that we seek, and our approach provides, allowing a wide range \nof new expressive syntactic con\u00adstructs to be safely added to the host language.  The requirements for \ntruly extensible languages are different from those for traditional language design in which a language \nexpert is expected to understand the language and the parsing and scanning technology. Here, one may \nreasonably choose to use a GLR parser to simplify the grammar rules and accept the responsibility of \nextensively testing and manually analyzing the grammar to ensure that no ambiguities exist at the top-level \nof the grammar. For PEGs, though it is unlikely that two extensions will introduce the exact same syntax, \nit is possible, and then the order in which the extensions are added will determine which construct is \nrecognized by the PEG parser and must be managed by someone familiar with PEGs. If extensible languages \nare to become widely used, we need static analyses that let extension writers certify their language \nex\u00adtensions to provide a guarantee that language extensions can be safely composed by the non-expert \nprogrammer.  5.5 Tool support. Copper is an integrated LALR(1) parser and context-aware scanner generator \nthat we developed to address the challenges in parsing and scanning extensible languages (27). Copper \nalso implements the modular analysis isComposable described in this paper. Copper serves as the parser \nand scanner generator for our attribute grammar system, Silver (24), which was used to implement ableJ \n(25). Copper, Silver, and the host language and language extension speci.cations mentioned in this paper \nare available on the web at http://melt.cs.umn.edu.  Acknowledgments We thank the anonymous reviewers \nfor their helpful and insight\u00adful comments. This work was partially funded by the McKnight Foundation \nand by the National Science Foundation under grants #0347860 and #0429640.  References [1] A. Aho, R. \nSethi, and J. Ullman. Compilers Principles, Techniques, and Tools. Addison-Wesley, Reading, MA, 1986. \n[2] S. Ananian. Java 1.4 LALR(1) grammar. Available at http://www2. cs.tum.edu/projects/cup/. [3] M. \nBravenboer, E. Dolstra, and E. Visser. Preventing injection attacks with syntax embeddings. In Proc. \nof the Intl. Conf. on Generative pro\u00adgramming and component engineering (GPCE), pages 3 12. ACM, 2007. \n\u00b4 extensible syntax de.nition for AspectJ. In Proc. of Conf. on Object\u00adoriented programming systems, \nlanguages, and applications (OOP-SLA), pages 209 228. ACM, 2006. [4] M. Bravenboer, Eric Tanter, and \nE. Visser. Declarative, formal, and [5] M. Bravenboer and E. Visser. Concrete syntax for objects: domain\u00adspeci.c \nlanguage embedding and assimilation without restrictions. In Proc. Conf. on Object-oriented programming, \nsystems, languages, and applications (OOPSLA), pages 365 383. ACM, 2004. [6] M. Bravenboer and E. Visser. \nParse table composition -separate compilation and binary extensibility of grammars. In Proc. of Intl. \nConf. on Software Language Engineering (SLE), 2008. [7] J. Cervelle, R. Forax, and G. Roussel. Tatoo: \nan innovative parser generator. In Proc. Principles and practice of programming in Java (PPPJ), pages \n13 20. ACM, 2006. [8] R. Cox, T. Bergany, A. T. Clements, F. Kaashoek, and E. Kohlery. Xoc, an extension-oriented \ncompiler for systems programming. In Proc. of Architectural Support for Programming Languages and Operating \nSystems (ASPLOS), 2008. [9] T. Ekman and G. Hedin. The JastAdd extensible Java compiler. In Proc. Conf. \non Object oriented programming systems and applications (OOPSLA), pages 1 18. ACM, 2007. [10] T. Ekman \nand G. Hedin. The JastAdd system -modular extensible compiler construction. Science of Computer Programming, \n69:14 26, December 2007. [11] B. Ford. Parsing expression grammars: a recognition-based syntactic foundation. \nIn Proc. of Symp. on Principles of Programming Lan\u00adguages (POPL), pages 111 122. ACM, 2004. [12] R. Grimm. \nBetter extensibility through modular syntax. In Proc. of Conf. on Programming Language Design and Implementation \n(PLDI), pages 38 51. ACM Press, 2006. [13] C. Heitmeyer, A. Bull, C. Gasarch, and B. Labaw. SCR*: A toolset \nfor specifying and analyzing requirements. In Proc. of Tenth Annual Conf. on Computer Assurance (COMPASS), \n1995. [14] L. Hendren, O. de Moor, A. S. Christensen, and the abc team. The abc scanner and parser, including \nan LALR(1) grammar for As\u00adpectJ. Available at http://abc.comlab.ox.ac.uk/documents/ scanparse.pdf, September \n2004. [15] R. N. Horspool. Incremental generation of LR parsers. Computer Languages, 15(4):205 223, 1990. \n[16] D. E. Knuth. On the translation of languages from left to right. Information and Control, 8(6):607 \n639, 1965. [17] W. R. LaLonde. An ef.cient LALR parser generator. Technical Report 2, Computer Systems \nResearch Group, University of Toronto, 1971. [18] N. Nystrom, M. R. Clarkson, and A. C. Myer. Polyglot: \nAn extensi\u00adble compiler framework for Java. In Proc. 12th International Conf. on Compiler Construction, \nvolume 2622 of LNCS, pages 138 152. Springer-Verlag, 2003. [19] M. Odersky and P. Wadler. Pizza into \nJava: translating theory into practice. In Proc. of Symp. on Principles of Programming Languages (POPL), \npages 146 159. ACM Press, 1997. [20] T. Rus. A uni.ed language processing methodology. Theoretical Computer \nScience, 281(1-2):499 536, 2002. [21] T. Rus and T. Halverson. A language independent scanner generator. \nPaper available at http://www.uiowa.cs.edu/~rus, 1998. [22] A. Schwerdfeger. A declarative speci.cation \nof a deterministic parser and scanner for AspectJ. Technical Report 09-007, University of Minnesota, \n2009. Available at http://www.cs.umn.edu. [23] A. Schwerdfeger and E. Van Wyk. Veri.able composition \nof determin\u00adistic grammars. Technical Report 09-008, University of Minnesota, 2009. Available at http://www.cs.umn.edu. \n[24] E. Van Wyk, D. Bodin, L. Krishnan, and J. Gao. Silver: an extensible attribute grammar system. Electronic \nNotes in Theoretical Computer Science (ENTCS), 203(2):103 116, 2008. Originally in LDTA 2007. [25] E. \nVan Wyk, L. Krishnan, A. Schwerdfeger, and D. Bodin. Attribute grammar-based language extensions for \nJava. In European Conf. on Object Oriented Programming (ECOOP), volume 4609 of LNCS, pages 575 599. Springer-Verlag, \nJuly 2007. [26] E. Van Wyk and Y. Mali. Adding dimension analysis to java as a com\u00adposable language extension. \nIn Post Proc. of Generative and Transfor\u00admational Techniques in Software Engineering (GTTSE), number \n5235 in LNCS, pages 442 456. Springer-Verlag, 2008. [27] E. Van Wyk and A. Schwerdfeger. Context-aware \nscanning for parsing extensible languages. In Intl. Conf. on Generative Programming and Component Engineering, \n(GPCE). ACM Press, October 2007. [28] E. Visser. Scannerless generalized-LR parsing. Technical Report \nP9707, Programming Research Group, University of Amsterdam, Aug. 1997. [29] E. Visser. Program transformation \nwith Stratego/XT: Rules, strategies, tools, and systems in StrategoXT-0.9. In C. Lengauer et al., editors, \nDomain-Speci.c Program Generation, volume 3016 of LNCS, pages 216 238. Spinger-Verlag, June 2004. [30] \nX. Wu, B. R. Bryant, J. Gray, and M. Mernik. Component-based LR parsing. Computer Languages, Systems \n&#38; Structures, 2009. In press.  \n\t\t\t", "proc_id": "1542476", "abstract": "<p>There is an increasing interest in extensible languages,</p> <p>(domain-specific) language extensions, and mechanisms for their specification and implementation. One challenge is to develop tools that allow non-expert programmers to add an eclectic set of language extensions to a host language. We describe mechanisms for composing and analyzing concrete syntax specifications of a host language and extensions to it. These specifications consist of context-free grammars with each terminal symbol mapped to a regular expression, from which a slightly-modified LR parser and context-aware scanner are generated. Traditionally, conflicts are detected when a parser is generated from the composed grammar, but this comes too late since it is the non-expert programmer directing the composition of independently developed extensions with the host language.</p> <p>The primary contribution of this paper is a modular analysis that is performed independently by each extension designer on her extension (composed alone with the host language). If each extension passes this modular analysis, then the language composed later by the programmer will compile with no conflicts or lexical ambiguities. Thus, extension writers can verify that their extension will safely compose with others and, if not, fix the specification so that it will. This is possible due to the context-aware scanner's lexical disambiguation and a set of reasonable restrictions limiting the constructs that can be introduced by an extension. The restrictions ensure that the parse table states can be partitioned so that each state can be attributed to the host language or a single extension.</p>", "authors": [{"name": "August C. Schwerdfeger", "author_profile_id": "81323495810", "affiliation": "University of Minnesota, Minneapolis, MN, USA", "person_id": "P1464276", "email_address": "", "orcid_id": ""}, {"name": "Eric R. Van Wyk", "author_profile_id": "81319502946", "affiliation": "University of Minnesota, Minneapolis, MN, USA", "person_id": "P1464277", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1542476.1542499", "year": "2009", "article_id": "1542499", "conference": "PLDI", "title": "Verifiable composition of deterministic grammars", "url": "http://dl.acm.org/citation.cfm?id=1542499"}