{"article_publication_date": "01-07-2008", "fulltext": "\n Engineering Formal Metatheory Brian Aydemir Arthur Chargu\u00b4eraud Benjamin C. Pierce University of Pennsylvania \nINRIA University of Pennsylvania baydemir@cis.upenn.edu arthur.chargueraud@inria.fr bcpierce@cis.upenn.edu \n Randy Pollack University of Edinburgh rpollack@inf.ed.ac.uk Abstract Machine-checked proofs of properties \nof programming languages have become a critical need, both for increased con.dence in large and complex \ndesigns and as a foundation for technologies such as proof-carrying code. However, constructing these \nproofs remains a black art, involving many choices in the formulation of de.nitions and theorems that \nmake a huge cumulative difference in the dif.\u00adculty of carrying out large formal developments. The representation \nand manipulation of terms with variable binding is a key issue. We propose a novel style for formalizing \nmetatheory, combin\u00ading locally nameless representation of terms and co.nite quanti.\u00adcation of free variable \nnames in inductive de.nitions of relations on terms (typing, reduction, . . . ). The key technical insight \nis that our use of co.nite quanti.cation obviates the need for reasoning about equivariance (the fact \nthat free names can be renamed in deriva\u00adtions); in particular, the structural induction principles of \nrelations de.ned using co.nite quanti.cation are strong enough for metathe\u00adoretic reasoning, and need \nnot be explicitly strengthened. Strong inversion principles follow (automatically, in Coq) from the induc\u00adtion \nprinciples. Although many of the underlying ingredients of our technique have been used before, their \ncombination here yields a signi.cant improvement over other methodologies using .rst-order representations, \nleading to developments that are faithful to infor\u00admal practice, yet require no external tool support \nand little infras\u00adtructure within the proof assistant. We have carried out several large developments \nin this style us\u00ading the Coq proof assistant and have made them publicly avail\u00adable. Our developments \ninclude type soundness for System F<: and core ML (with references, exceptions, datatypes, recursion, \nand patterns) and subject reduction for the Calculus of Constructions. Not only do these developments \ndemonstrate the comprehensive\u00adness of our approach; they have also been optimized for clarity and robustness, \nmaking them good templates for future extension. Categories and Subject Descriptors F.4.1 [Mathematical \nLogic and Formal Languages]: Mathematical Logic Mechanical theo- Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 08, January 7 12, 2008, San Francisco, \nCalifornia, USA. Copyright c &#38;#169; 2008 ACM 978-1-59593-689-9/08/0001. . . $5.00 Stephanie Weirich \nUniversity of Pennsylvania sweirich@cis.upenn.edu rem proving; D.3.1 [Programming Languages]: Formal \nDe.ni\u00adtions and Theory Syntax General Terms Design, Documentation, Languages, Theory, Ver\u00adi.cation Keywords \nbinding, Coq, locally nameless 1. Introduction Recent years have seen burgeoning interest in the use \nof proof as\u00adsistants for formalizing de.nitions of programming languages and checking proofs of their \nproperties. However, despite several suc\u00adcessful tours de force (Appel 2001; Crary 2003; Klein and Nipkow \n2006; Leroy 2006; Lee et al. 2007, etc.), the community remains fragmented, with little synergy between \ngroups and, for newcom\u00aders wanting to join the game, a perplexing array of choices between different \nlogics, proof assistants, and representation techniques. To stimulate progress on this problem, Aydemir \net al. (2005) proposed the POPLMARK challenge, a set of tasks designed to stress many of the critical \nissues in formalizing programming language metatheory. They laid out three criteria for evaluat\u00ading proposed \nformalization techniques: infrastructure overhead formalization overheads, such as additional operations \nand their associated proof obligations, should not be prohibitive for large developments; transparency \nformal de.nitions and theorems should not depart radically from the usual informal conventions familiar \nto a technical audience; and cost of entry the infrastruc\u00adture should be usable by someone who is not \nan expert in theorem prover technology. In this paper, we propose a new style for formalizing program\u00adming \nlanguage metatheory that performs well on all these criteria. The style builds upon two key ingredients: \nlocally nameless repre\u00adsentation of syntax involving binders and a co.nite style of quan\u00adti.cation for \nintroducing free names in rules dealing with binders. In locally nameless representation, bound variables \nare repre\u00adsented by de Bruijn indices while free variables are represented by names. This mixed representation \ncombines the bene.ts of both ap\u00adproaches, avoiding dif.culties associated with alpha-conversion by ensuring \nthat each alpha-equivalence class of terms has a unique representation, while supporting formal reasoning \nthat closely fol\u00adlows informal practice. The second ingredient is the use of a co.nite quanti.cation \nof free names introduced by rules dealing with binders, instead of the standard exists-fresh quanti.cation \nthese styles are illustrated by the following variants of the typing rule for abstraction in the simply-typed \nlambda calculus (..): EXISTS-FRESH COFINITE x/. FV(t) E, x:S f t x : T .x/. L. E,x:S f t x : T E f abs \nt : S . TE f abs t : S . T Here, tx is the body of abstraction (abs t) opened up with a free variable \nnamed x. In the second rule, L is some .nite set of names that is chosen when we apply the rule. Just \nas EXISTS-FRESH is applicable if there exists some x ./FV(t) such that E,x:S f tx : T , so COFINITE is \napplicable if there exists some L such that .x ./L. E,x:S f tx : T . The induction hypothesis for rule \nEXISTS-FRESH holds for one particular name x, which (notionally) comes from the derivation being eliminated \nby the induction; if that x is not fresh enough, the only way to proceed is to reason about equivariance \nof the typing judgement. The co.nite rule, on the other hand, asserts from the start that for E f abs \nt : S . T to hold there must be in.nitely many xs with E, x:S f tx : T ; surely one of them is fresh \nenough since only .nitely many names could have been used so far. In rare cases, renaming is necessary \nfor proofs, but it is straightforwardly supported by the co.nite presentation; the required lemmas may \nbe easily derived from standard properties such as substitution and weakening, which are themselves derivable \nusing only the co.nite de.nition. These renaming lemmas also provide the core arguments for the equivalence \nbetween the exists-fresh and co.nite presentations of the relations. Neither of these ingredients is \nentirely new. The locally name\u00adless representation dates back to the introduction of de Bruijn in\u00addices. \nSeveral strengthened induction principles that avoid manual renaming have been proposed (Gordon 1994; \nMcKinna and Pol\u00adlack 1993, 1999; Urban et al. 2007b). The idea of reasoning about the freshness of names \nby considering all but those in some .nite set is at the heart of nominal logic (Pitts 2003) and also \nappears in de.nitions of alpha-equivalence by Krivine (1990) and Ford and Mason (2001). Our contribution \nlies in the precise way that we combine and apply these ingredients. In particular, the co.nitely quanti.ed \ntyping rule for abstraction (presented earlier), which re\u00ad.ects both key aspects of our design, does \nnot appear in prior work. The observation that we can use this formulation to derive renaming lemmas \nwith little infrastructure is a key point, of both theoretical and practical interest. To demonstrate \nthe comprehensiveness of our approach we have developed several signi.cant examples in the Coq proof \nassis\u00adtant (Coq Development Team 2007): proofs of type soundness for .., System F<: (the core of the \nPOPLMARK challenge parts 1A and 2A), and ML extended with references, exceptions, datatypes, recursion \nand patterns, as well as a proof of subject reduction for the Calculus of Constructions (including a \nproof of the Church-Rosser property). These developments require no external tool sup\u00adport and could \nbe reproduced with another general purpose theo\u00adrem prover. Little infrastructure is required between \nthe statement of the system formalized and the core of the formal reasoning. Fur\u00adthermore, our formal \nreasoning faithfully follows informal practice, preserving the skeletons of proofs and the kinds of arguments \nin\u00advolved, unpolluted by details about alpha-conversion or freshness. We have carefully organized and \ncommented these proof scripts and made them freely available as starting points for comparison and extension.1 \nThe paper is organized as follows. Section 2 surveys possible approaches to representing binding structures, \nlocates the locally nameless approach in this space, and sketches its history. Section 3 presents a complete \nspeci.cation of .. using locally nameless representation and the standard exists-fresh presentation of \nthe se\u00ad 1 http://arthur.chargueraud.org/research/2007/binders/. mantics. Section 4, the technical meat \nof the paper, describes the problem faced by the exists-fresh speci.cation, shows how co.\u00adnite quanti.cation \nsolves this problem, and discusses why our so\u00adlution is signi.cantly better than other concrete approaches. \nFi\u00adnally, Section 5 gives a practical overview of our larger formaliza\u00adtions. This section also quantitatively \ncompares our developments to each other and to other publicly available Coq solutions to the POPLMARK \nchallenge. 2. A Survey of Binding Representations There are two main categories of approaches to representing \nand reasoning about syntax with binding, depending on whether vari\u00adables and binders are represented \nas concrete nodes in .rst-order algebraic structures or whether these aspects are lifted to the met\u00adalanguage \nby representing the bodies of binding constructs as met\u00adalanguage functions. In each category there are \nmany ingenious variations, and we do not attempt to be exhaustive in this survey. Outside the main categories, \nthere is a plethora of hybrid represen\u00adtations, multi-level representations, . . . , which we do not \nconsider. 2.1 Concrete Approaches With concrete (or .rst-order) approaches, variables are typically encoded \nusing names or natural numbers. Capture-avoiding substi\u00adtution must then be de.ned explicitly as a function \non terms, and in the case where bound variables are named, alpha-equivalence must also be de.ned explicitly. \nConcrete approaches can be subdi\u00advided roughly in three categories: those using names to represent variables, \nthose using de Bruijn indices, and those distinguishing bound and free variables (which may use either \nnames or indices for each kind of variable). The most standard representation on paper uses names to \nrep\u00adresent variables, generally quotienting raw expressions by some notion of alpha-equivalence. Although \nused since the .rst days of the lambda calculus, this representation has not proved convenient for formal \ndevelopments. For example, naive substitution is not structurally recursive in this setting but requires \nwell-founded re\u00adcursion. Nevertheless, the Church-Rosser property in pure lambda calculus has been proved \nusing named representations by Home\u00adier (2001) using HOL, Ford and Mason (2001) using PVS, and Vestergaard \nand Brotherston (2003) using Isabelle/HOL (unusu\u00adally, Vestergaard and Brotherston reason about unquotiented \nraw terms). Other attempts to tame this representation include work by Stoughton (1988), where simultaneous \nsubstitution is de.ned struc\u00adturally and puts terms into a canonical alpha-normal form, and by Hendriks \nand van Oostrom (2003). To overcome the clumsiness of explicit alpha-conversion or quotienting, the .rst \nlarge formalizations of languages with binders were based on de Bruijn indices (1972) rather than names. \nIn this approach, each alpha-equivalence class of lambda-terms has a unique syntactic representation \nin which variables are encoded us\u00ading natural numbers giving the depth of the variable relative to its \nbinder. Indices greater than the number of enclosing local binders may indicate a position in some enclosing \ncontext such as a typing context. There is abundant evidence of the effectiveness of this rep\u00adresentation, \nfrom proofs of the Church-Rosser property for lambda calculus for example, by Shankar (1988) using the \nBoyer-Moore prover, by Huet (1994) in Coq, by Rasmussen (1995) in Isabelle/ZF, and by Nipkow (2001) in \nIsabelle/HOL to harder results such as strong normalization for System F in LEGO (Altenkirch 1993) and \nformalizing Coq in Coq (Barras and Werner 1997). In de Bruijn representation, the treatment of bound \nvariables incurs minor tech\u00adnical annoyances (lifting over binders, etc.), while the treatment of free \nvariables (e.g., variables bound by a typing context) requires reasoning far from natural informal presentations. \nFor example, consider the statement of a lemma that says thinning the typing context (weakening and permuting) \npreserves a judgement: indices occurring in the judgement must be updated to match the permuta\u00adtion of \ntheir binding points in the context. Nominal logic (Pitts 2003) provides another way to address the problem \nof alpha-conversion inherent in the named representation. Urban (2007) and Urban et al. (2007a,b) have \nadapted these ideas to standard higher-order logic, and are developing a nominal pack\u00adage in Isabelle/HOL \nthat provides facilities for formal reasoning with binders over names. The package helps by automating \nlan\u00adguage de.nitions that equate alpha-equivalent terms, by provid\u00ading lemmas about renaming and freshness \nof names, by deriving strengthened induction principles that provide name freshness facts for relations \nover these languages, and by supporting recursion over these languages. Some syntactic restrictions must \nbe observed to use this package. See Section 4.6 for further discussion of the nom\u00adinal package. Besides \nthese homogeneous concrete approaches where there is a single notion of variable, either a name or a \nde Bruijn index there is a third category of concrete representations that uses two distinct syntactic \nclasses, called variables (for locally bound variables) and parameters (for free, or globally bound vari\u00adables). \nThe idea that variables and parameters should be distin\u00adguished goes back at least to Gentzen (1969) \nand Prawitz (1965). Several combinations can be considered, using names, indices, or levels to represent \nbound and free variables; of these, two have been used in the literature. The .rst is the locally named \nrepresentation, which uses dis\u00adtinct species of names to represent variables and parameters respec\u00adtively. \nMcKinna and Pollack introduced this technique to formal\u00adize Pure Type Systems (PTS) (1993; 1999), following \na suggestion by Coquand (1991). This representation avoids the dif.culties of reasoning about capture-avoiding \nsubstitutions: since variables and parameters are syntactically distinguished, no parameter can ever \nbe captured by a variable binder during substitution. McKinna and Pollack also introduced a technique \nfor handling the requirement of choosing fresh global variables that often occurs in reasoning about \nbinding (weakening lemmas are a prototypical example of the prob\u00adlem). By careful choice of de.nitions, \nthey avoid the need to reason about alpha-equivalence of bound variables throughout their large formal \nbody of PTS metatheory. With these techniques, reasoning about lambda calculus and type theory is straightforward, \nif heavy. Nonetheless, the use of names for bound variables is not a per\u00adfect .t to the intuitive notion \nof binding: eventually one needs to reason about alpha-conversion. For example, parallel reduction has \nthe diamond property concretely in locally named representation, but beta reduction has this property \nonly up to alpha-conversion (Pollack 1994b, Section 3.3.6). So Pollack (1994a) suggested that the McKinna \nPollack approach to reasoning with two species of variables also works well with a representation that \nuses names for parameters and de Bruijn indices for bound variables. This lo\u00adcally nameless representation, \nin which alpha-equivalence classes have canonical representation, was already mentioned in the con\u00adclusion \nof de Bruijn s famous paper (1972). It had been used for implementation in Huet s Constructive Engine \n(1989), and later in the implementations of the Coq, LEGO (Luo and Pollack 1992), HOL 4 (Norrish and \nSlind 2007), Isabelle, and EPIGRAM (McBride and McKinna 2004) proof assistants. In the context of formal \nproofs, Gordon (1994) appears to be the .rst to have used locally nameless representation. Rather than \nreason directly with locally nameless terms, he builds a represen\u00adtation of named lambda terms on top \nof locally nameless terms and demonstrates how the named terms may be used as a basis for representing \nsyntax. Using this technique, Gordon formalized Abramsky s lazy lambda calculus. Later work by Gordon \nand Mel\u00adham (1996) also uses locally nameless terms as a model for an ab\u00adstract axiomatic representation \nof named terms. Pollack (2006) has more recently emphasized the bene.ts of locally nameless rep\u00adresentation \nin the context of the POPLMARK challenge. Locally nameless representation with (variants of) McKinna \nPollack style reasoning has been used by several researchers (with several proof tools) for solutions \nto the POPLMARK challenge, .rst by Leroy (2007) and later by Chlipala (2006) and Ricciotti (2007). 2.2 \nHigher-Order Approaches Higher-order representations use the function space of the meta\u00adlogic to encode \nbinding in an object language, allowing issues like capture-avoidance and alpha-equivalence to be handled \nonce and for all by the meta-logic, rather than facing them anew for each object language. There is a \nbewildering variety of higher-order approaches, which we survey only super.cially. In higher-order abstract \nsyntax (HOAS) (Harper et al. 1993; Pfenning and Elliot 1988), the introduction form for lambda\u00adabstractions \nhas type (term->term)->term, i.e., the lambda con\u00adstructor packages a function of type (term->term), \nwhich should be thought of as the function substituting its argument into the body of the lambda. Not \nonly are alpha-equivalent terms equal, but substitution is handled by the meta-language. HOAS was introduced \nby Church and developed by de Bruijn, Martin-L\u00a8of, Plotkin, Pfenning, and their co-workers. The modern \nform, using dependent types and hypothetical and schematic judge\u00adments as well as HOAS term representation, \nappeared in the Edin\u00adburgh Logical Framework (LF) (Harper et al. 1993). By design, LF is a weak type \ntheory to be used as a metalanguage, not sup\u00adporting inductive de.nition or primitive recursion. It allows \nfaithful representation of object languages, where LF itself adds no math\u00adematical strength to the object \nlanguage representation. The use of LF methodology for metatheory (as opposed to just representa\u00adtion) \nhas been highly developed by Pfenning and his co-workers; the implementation of this approach is the \nTwelf system (Pfenning and Sch\u00a8 urmann 1999), which is widely used and very successful for formalizing \nthe metatheory of a wide variety of programming languages (Ashley-Rollman et al. 2005; Lee et al. 2007). \nThe ap\u00adproach continues to be developed foundationally as well as in prac\u00adtice (Harper and Licata 2007). \nA second main stream of work, weak higher-order encodings, gives a type such as (name->term)->term to \nthe lambda con\u00adstructor of terms.2 This constructor packages a function of type (name->term), which should \nbe thought of as a function that takes a name and returns the instance of the lambda s body instantiated \nwith that name. Here, alpha-equivalent terms are equated, but sub\u00adstitution must be de.ned as a relation \nbetween terms. Despeyroux et al. (1995) demonstrate an early use of this approach. The ap\u00adproach has \nbeen most developed by Honsell, Miculan, and their co-workers as the Theory of Contexts (Honsell et al. \n2002; Bucalo et al. 2006).  2.3 Why Locally Nameless? We have chosen to concentrate on concrete approaches \nto repre\u00adsent binding structure. Despite the attractiveness of higher-order approaches and their demonstrated \nsuccess in many large develop\u00adments, they are, at present, not completely general-purpose. Twelf is currently \nthe only industrial-strength proof assistant for devel\u00ad 2 The technical advantage of the weak variant \nis that the type of terms can be given as an inductive datatype. For strong HOAS, due to the negative \noc\u00adcurrence of term in (term->term)->term, there is no inductive datatype representing the set of terms. \nIn the weak version, on the other hand, the type name replaces the negative occurrence of term, so there \nis a datatype of weak higher-order terms in, e.g., Coq and HOL. Nonetheless technical problems arise \nunless name is a suf.ciently abstract type (Honsell et al. 2002). oping metatheory based on HOAS representations, \nand it is (in its current incarnation) strictly limited in its proof-theoretic strength. The Theory of \nContexts is also interesting, but hasn t yet been taken up beyond its originators. These are the subject \nof active research and may become more generally applicable in the future. Among the concrete approaches, \nlocally nameless representa\u00adtion offers the best combination of features. Because free variables are \nrepresented using names, lemmas are stated and proofs struc\u00adtured just as they are with the standard \nrepresentation using names, making locally nameless developments intuitive. In particular, the shifting \noperations that clutter both statements and proofs in a pure de Bruijn setting are avoided. Because bound \nvariables are repre\u00adsented using indices, each alpha-equivalence class of lambda terms has a unique representation, \nthus avoiding the dif.culties associated with alpha-equivalence. Finally, because bound and free variables \nare syntactically distinguished there is no issue of variable capture, and substitution can be de.ned \nby simple structural recursion. These observations motivate the choice of the locally nameless representation. \nThe next section presents this style in detail. 3. Locally Nameless Representation In this section, we \ndescribe locally nameless representation, using .. as a running example. All the material presented is \nformal, in the sense that we have implemented it in Coq.3 We write . for logical implication. 3.1 De.nitions \nThe fundamental idea of the locally nameless approach is to dis\u00adtinguish bound from free variables, using \nde Bruijn indices for the former and names for the latter. Figure 1 presents a locally name\u00adless speci.cation \nof ... An occurrence of a bound variable is rep\u00adresented as (bvar i) where i is a natural number index \ndenoting the number of enclosing lambda abstractions that must be traversed be\u00adfore reaching the abstraction \nbinding that variable. Abstractions do not bind names; for example, (abs (bvar 0)) is the identity func\u00adtion. \nIn its raw form, this representation is not isomorphic to ordinary named lambda terms because a bound \nvariable may not resolve to any binder. For example, (abs (bvar 2)) does not represent any lambda-term. \nWe therefore de.ne a predicate, (term t), on pre\u00adterms (the syntactic objects de.ned by the grammar in \nFigure 1) that selects the locally closed pre-terms or just terms in which all indices resolve to binders. \nThe key operation on pre-terms is opening an abstraction by in\u00adstantiating a bound variable with a term. \nIf (abs t) is an abstraction and u another term, then the result of opening the abstraction with u, written \ntu, is formed by replacing in the body t all bound vari\u00adables that point to the outermost lambda with \nu. Figure 1 gives the structurally recursive de.nition of the open function; the idea is to explore the \nterm, keeping track of the current number of binders passed through.4 One use of the open operation is \nin the conclusion of the beta reduction rule, RED-BETA, near the bottom of the .gure. The open operation \nis also frequently applied to a free variable; we call this specialized version variable opening, which \nwe write xfvar x with abuse of notation as (t) instead of (t). Variable opening is used when passing \nthrough a binder to turn the bound variable into a free variable. In a named representation, we may have \nour hands on an abstraction (abs xt) and wish to talk about its body t. With the locally nameless representation, \nthe abstraction would 3 The corresponding development is contained in .les STLC Core *.v. 4 Experts will \nnote that this de.nition of open works correctly only when zero is the only unbound index. The de.nition \ncan be generalized to allow multiple binders to be opened simultaneously as explained in Section 5 in \nthe paragraph about our ML development. Syntax: S, T = A | T1 . T2 t, u, w = bvar i | fvar x | app t1 \nt2 | abs t E, F, G = \u00d8 | E, x:T Open: tu ={0 . u} t, with {k . u} (bvar k)= u {k . u} (bvar i)= bvar \ni when i= k {k . u} (fvar x)= fvar x {k . u} (app t1 t2)= app ({k . u} t1)({k . u} t2) {k . u} (abs t)= \nabs ({(k + 1) . u} t) Free variables: FV(bvar i)= \u00d8 FV(fvar x)= {x} FV(app t1 t2)= FV(t1) . FV(t2) FV(abs \nt)= FV(t) Locally closed terms: term t1 term t2 TERM-VAR TERM-APP term (fvar x) term (app t1 t2) x/. \nFV(t) term (t x) TERM-ABS term (abs t) Well-formed environments (no duplicate names): ok Ex . dom(E) \nOK-NIL OK-CONS ok \u00d8 ok (E, x:T ) Typing: ok E (x:T ) . E TYPING-VAR E f fvar x : T E f t1 : S . TE f \nt2 : S TYPING-APP E f app t1 t2 : T x/. FV(t) E, x:T1 f t x : T2 TYPING-ABS E f abs t : T1 . T2 Call-by-value \nevaluation: term (abs t) VALUE-ABS value (abs t) term (abs t) value u RED-BETA app (abs t) u -. t u ' \nt1 -. t1 term t2 RED-APP-1 ' app t1 t2 -. app t1 t2 ' value t1 t2 -. t 2 RED-APP-2 app t1 t2 -. app t1 \nt2 ' Type soundness lemmas (preservation and progress): '' E f t : T . t -. t. E f t: T '' \u00d8 f t : T \n. (value t ..t, t -. t) Figure 1. Locally nameless presentation of .. be written (abs t); to talk about \nits body as a term (rather than a pre-term with an unbound index), we open t with some fresh name x. \nA typical example of variable opening appears in the typing rule for abstractions, TYPING-ABS. In variable \nopening, the chosen variable should not already appear free inside the term. Otherwise, the operation \nwould be a form of variable capture: the name being given to the index, a bound variable, would be the \nsame as a free variable. Therefore, the rule TYPING-ABS also includes the premise x/. FV(t),5 which uses \nthe free variable function to collect the set of free variables in a pre-term. Like open, this function \nis de.ned by simple structural recursion and need not worry about confusing free and bound variables \nall variable names in the term are free, since bound variables are represented by indices. To state the \ntyping judgement of .., we need to formalize typing environments. In Figure 1, environments are concretely \nrepresented as association lists, for which we assume some stan\u00addard operations. The concatenation of \ntwo environments is written (E, F ). The lookup of a variable in an environment is expressed by the predicate \n(x:T ) . E, which holds when (x, T ) is the rightmost pair of E whose .rst component is x. Finally, a \nvariable is fresh for an environment, written x/. dom(E), when that variable does not appear in the .rst \ncomponent of any pair in E. In principle, the association list representation allows multiple assumptions \nfor the same variable, but our typing rules ensure that environments partic\u00adipating in derivable judgements \nare well formed (ok) in the sense that a given variable is bound at most once in a given environment. \nThe .nal portion of Figure 1 completes the de.nition of .. by stating the properties we wish to prove: \nthe standard preservation and progress lemmas. The .gure, as a whole, forms our trusted base of de.nitions: \none must believe in the correctness of every\u00adthing stated in the .gure in order to believe that a formal \nproof of type soundness is really about one s informal notion of ... We discuss this issue in additional \ndetail in Section 3.4. 3.2 Substitution The de.nition of .. depends only on the open and FV operations. \nIn proofs, however, the operation of free variable substitution, replacing free names with terms, is \nalso needed. Written [x . u] t, it is de.ned by structural recursion in Figure 2. As in the de.nition \nof open, there is no arbitrary choice of name for the bound variable in the abstraction case, so we need \nnot worry that this choice will affect the result. Therefore, the behavior of substitution is natural \nand easy to reason about. The properties of the substitution function, shown in the bottom portion of \nFigure 2, are fundamental when working with a locally nameless representation. Lemma subst fresh states \nthat substitu\u00adtion for an unused variable has no effect, and lemma subst open states that substitution \ndistributes over the opening operation. The remaining two lemmas are immediate corollaries of the former \ntwo. Lemma subst open var permutes a substitution with variable opening, and lemma subst intro decomposes \nan open operation into a variable opening operation and a substitution. Examples of when these lemmas \nare used can be found in the proof of the substi\u00adtution lemma for .. (Section 4.1) and in the proof of \na renaming lemma (Section 4.2). We occasionally need a related operation intuitively, a recip\u00adrocal of \nvariable opening that abstracts the name x from the term t, replacing it with a bound variable. We call \nthis operation variable closing and de.ne it in Figure 3, again by structural recursion. 5The rule TYPING-ABS \ncould also explicitly include a premise to ensure that x does not appear in the domain of the environment \nE. However, that restriction is already implied by the second hypothesis. Substitution of a term for \na free name: [z . u](bvar i)= bvar i [z . u](fvar z)= u [z . u](fvar x)= fvar x when x = z [z . u](app \nt1 t2)= app ([z . u] t1) ([z . u] t2) [z . u](abs t)= abs ([z . u] t) Properties of substitution: subst \nfresh x/. FV(t) . [x . u] t = t w([x.u] w) subst open [x . u](t) = ([x . u] t) when term u subst open \nvar [x . u](ty) = ([x . u] t)y when x = y and term u subst intro [x . u](tx)= tu when x/. FV(t) Figure \n2. Substitution Close: \\xt ={0 . x} t, with {k . x} (bvar i)= bvar i {k . x} (fvar x)= bvar k {k . x} \n(fvar y)= fvar y when x = y {k . x} (app t1 t2)= app ({k . x} t1)({k . x} t2) {k . x} (abs t)= abs ({(k \n+ 1) . x} t) Figure 3. Variable Closing 3.3 Working With Local Closure We use an inductive de.nition \nof local closure, given in Figure 1. A bound variable on its own is never locally closed: there is no \ncase for (bvar i). An abstraction is locally closed if the body of that abstraction, once opened up with \na fresh name, is locally closed.6 There are alternative ways to de.ne local closure, but we favor this \nstyle which is similar to the VClosed relation of McKinna and Pollack (1993). As they point out, this \nde.nition provides a structural induction principle for locally closed terms: . x. P (x) . t1 t2.P (t1) \n. P (t2) . P (app t1 t2) . xt.x /. FV(t) . P (tx) . P (abs t) .t. term t . P (t) This de.nition can \nbe used in many different logics: intensional or extensional, dependent types or simply typed HOL.7 Although \nthe relations de.ning the semantics of .. in Figure 1 are formally de.ned over pre-terms, these relations \nactually include only locally closed terms and the basic operations preserve local 6 The freshness assumption \nis not actually required for this judgement; we include it to maintain the invariant that a term is never \nopened with a name that occurs free in that term. 7 In extensional higher order logic the (non-empty) \npredicate term can be made into a type of locally closed terms. In intensional dependent type systems \n(including Coq), this construction isn t available. However, in such systems we can de.ne the inductive \nfamily of pre-terms indexed by the set of bvars occurring free (e.g. McBride and McKinna (2004); for \ndiscussion of inductive families see Dybjer (1994)). Then the section of this family indexed by the empty \nset of bvars is exactly the locally closed terms. Improvements to our style may be possible along these \nlines, but for the moment we stick with the representation given above, for its simplicity of use and \nuniformity of presentation across different logics. closure. term (abs t) . term u . term (tu) term u \n. term t . term ([x . u] t) E f t : T . term t t -. t ' . term t . term t ' We formulate the de.nitions \nin this way for two reasons. First, it is required for the adequacy of our formalization: only locally \nclosed terms correspond to alpha-equivalence classes of ordinary named terms. Second, some useful properties \nof the de.nitions are true only for locally closed terms.8 The typing relation ensures local closure \nof its subject without any local closure premises, but not every relation of interest is this clean. \nFor example, to ensure this property of small-step evaluation, the de.nition includes several local closure \npremises. In general, such premises are only required at the leaves of the de.nition: e.g., we do not \nneed a premise (term t) if there is already a premise (value t), since the latter implies the former. \nSimilarly, because our de.nitions guarantee local closure, we usually do not need to add local closure \nhypotheses to the state\u00adments of lemmas and theorems. For example, the substitution pre\u00adserves typing \nlemma E, z:S, F f t : T . E f u : S . E, F f [z . u] t : T requires none because the typing relation \nensures that t, u, and [z . u] t are all locally closed. As a result, even though the use of the nameless \nrepresentation means that we must be careful about local closure, the management of this predicate does \nnot require a signi.cant departure from common informal practice.  3.4 Adequacy Why should you believe \nthis mechanized, formal representation of .. is correct, i.e., expresses your understanding of the rigorous, \ninformal system? This is the question of adequacy of the represen\u00adtation, set out by Harper et al. (1993) \nin their context of HOAS. (See also (Harper and Licata 2007) for a more recent take.) First, note that \nit is an informal question, because it involves the relation\u00adship between an informal thing and a formal \nthing. No matter how much faith you put in Coq, no Coq proof will completely settle this question. Nonetheless, \nformal proofs are useful for this question in three ways. First, you may prove that the formalization \nhas the proper\u00adties you expect from the informal system and does not have un\u00adexpected properties. E.g., \nour Coq representation of .. is shown to have Church Rosser, weakening, subject reduction, etc., some \nof which is discussed below. (You must also be convinced that our formal statements of these properties \nare correct.) If you think our rule TYPING-ABS requires a stronger side condition, prove your expected \nrule is admissible in our system. Second, you may prove some formal relationship with another formalization \nof the same in\u00adformal system that you, and other readers, believe to be adequate, e.g., that our formalization \nis related to a pure de Bruijn representa\u00adtion in some way (but we haven t done that). Finally, if intensional, \nimpredicative, constructive type theory is just too weird, you may carry out the same representation \nand its development in some other proof system. We have avoided using special properties of Coq or its \nlogic, and our style could be carried out in HOL, NuPrl, PVS, etc. Harper et al. (1993) ask that there \nbe a compositional bijection between the informal syntactic entities (terms, formulas, . . . ) and some \ncollection of entities of the formal representation. (They also note this may be taken to have different \nmeanings: e.g., adequacy 8 These include both low-level technical properties such as subst open and more \ninteresting properties such as re.exivity of subtyping in System F<: . for theorems versus adequacy for \nderivations.) In our setting, you can carry this out (on paper, not in Coq) with a fairly simple bijection. \n4. Co.nite Quanti.cation Although the de.nitions in the previous section adequately repre\u00adsent .., they \nyield insuf.ciently strong induction principles: in many situations we must rename the variable used \nto open an ab\u00adstraction to complete a proof. The need to reason about renaming motivates our use of co.nite \nquanti.cation for inductively de\u00ad.ned relations. In this section, we present a complete style of proof \ndevel\u00adopment based on co.nite quanti.cation. We .rst explain co.nite quanti.cation and give a new de.nition \nof .. using it. De.ni\u00adtions in this style are suf.cient, by themselves, to develop signif\u00adicant amounts \nof metatheory e.g., to prove weakening and sub\u00adstitution results since they naturally balance strong \ninduction and inversion principles with useful introduction forms. In a few situa\u00adtions, however, renaming \nlemmas are required to build derivations using the co.nitely quanti.ed rules. We show how these lemmas \ncan be derived directly from weakening and substitution. Finally, to be con.dent that relations de.ned \nwith co.nite quanti.cation are adequate encodings of .., we use renaming to show that they are equivalent \nto their counterparts shown in Figure 1. Having described our complete style of development, we then \nobserve that some signi.cant streamlining is possible, notably in cases where one believes in the adequacy \nof the co.nite presenta\u00adtion of a relation without requiring a formal proof of equivalence with the exists-fresh \nvariant. We conclude the section with com\u00adparisons to previous work, arguing that the added value of \nour ap\u00adproach is signi.cant in each case. 4.1 Stronger Induction Principles The de.nitions of the local \nclosure and typing relations in Figure 1 use an exists-fresh style of quanti.cation. When an abstraction \nis opened in the premise of a rule (TERM-ABS and TYPING-ABS), the name used in the premise is required \nto be fresh for the body of the abstraction. Thus, to build a derivation using one of these rules, it \nsuf.ces to show that there exists a single suf.ciently fresh name for which the premise holds. The premises \nof rules written in this way are easy to satisfy, making them ideal introduction forms. However, such \nrules give rise to weak elimination forms (in\u00adversion and induction principles). The fact that the premises \nof a rule de.ned using exists-fresh quanti.cation need only hold for one particular name means that the \ncorresponding induction hypothesis also holds for one particular name. That name will only be as fresh \nas the premise of the rule requires, which may not be enough. For example, consider the proof of the \nweakening lemma for the typing relation, which allows one to insert additional typing assumptions anywhere \ninto a typing environment: typing weaken : E, G f t : T . ok (E, F, G) . E, F, G f t : T When proving \nthis by induction on the given typing derivation, in the case for TYPING-ABS we are given a derivation \nending with x/. FV(t1) E, G,x:T1 f t1 x : T2 E, G f abs t1 : T1 . T2 and an induction hypothesis ok (E, \nF, G,x:T1) . (E, F, G,x:T1 f t1 x : T2) and we must derive E, F, G f abs t1 : T1 . T2 C-TERM-VAR termc \n(fvar x) termc t1 termc t2 C-TERM-APP termc (app t1 t2) . x/. L. termc (t x) C-TERM-ABS termc (abs t) \nok E (x:T ) . E C-TYPING-VAR E fc fvar x : T E fc t1 : S . TE fc t2 : S C-TYPING-APP E fc app t1 t2 : \nT . x/. L. (E, x:T1 fc t x : T2) C-TYPING-ABS E fc abs t : T1 . T2 Figure 4. Local closure and typing \nusing co.nite quanti.cation for an arbitrary F . By TYPING-ABS, it suf.ces to derive E, F, G,y:T1 f t1 \ny : T2 , for some name y ./FV(t1). Intuitively, we want to use y = x, since the induction hypothesis \napplies to x. However, the given typing derivation shows that t1 x is well typed in the environment (E, \nG,x:T1), so we can only derive that x is fresh for (E, G). We need to type t1 x in the extended environment \n(E, F, G,x:T1), but x is not guaranteed to be suf.ciently fresh for that environment as it could appear \nin F . The particular name x appearing in the induction hypothesis is (notionally) the name that occurs \nin that position of the particular derivation of E, G f t : T being eliminated in the proof. In an informal \nproof, we avoid the problem by assuming this derivation uses suf.ciently fresh names. (Depending on our \ninformal view, this is usually justi.ed by appeal to the Barendregt Variable Con\u00advention (1984), which \nallows us to assume that the name of the bound variable in the abstraction case is suf.ciently fresh.) \nOur solution is to strengthen the induction principle for the typing relation by changing its de.nition \nto the one at the bottom of Figure 4. This de.nition differs only in the rule for abstractions, C-TYPING-ABS. \nThis new rule intuitively states: to show that (abs t) is well typed it suf.ces to choose some .nite \nset of names, L, and show that tx is well-typed for every x not in L. We say that this de.nition of the \ntyping relation uses co.nite quanti.cation since we must show that the premise of C-TYPING-ABS ( C for \nco.nite ) holds for all but .nitely many names. The set of names L may be different for each use of the \nrule. To similarly strengthen the structural induction principle for terms, we rede.ne term in the co.nite \nstyle at the top of Figure 4, and replace all references to term in the reduction relation with this \none. Although this new de.nition of .. differs from the one given in Figure 1, it is equivalent, as we \nshow in Section 4.3. Using co.nite quanti.cation in the rules provides a stronger induction principle \nbecause, in the cases that open abstractions, the induction hypotheses will hold for all names except \nthose in some .nite set L, rather than just for a single name. On the other hand, a rule de.ned using \nco.nite quanti.cation is nearly as easy to use for introduction as the exists-fresh version because L \ncan include the .nitely many names that could potentially lead to clashes. Consider again the proof of \nthe weakening lemma this time, for the co.nite typing relation fc. In the case for C-TYPING-ABS, we are \ngiven the assumption . x/. L ' . (E, G,x:T1 fc t1 x : T2) for some .nite set of names L ', and an induction \nhypothesis . x/. L ' . ok (E, F, G,x:T1) . E, F, G,x:T1 fc t1 x : T2 , and we must derive E, F, G fc \nabs t1 : T1 . T2 . By C-TYPING-ABS, it suf.ces to .nd an L for which we can show . x/. L. (E, F, G,x:T1 \nfc t1 x : T2) . Choosing L = L ' . dom(F ) does the trick: any x/. L is also not in L ', so the induction \nhypothesis directly gives us the result. As an additional example of the usefulness of the stronger induction \nhypothesis, we prove the standard substitution preserves typing lemma for the co.nite typing relation: \ntyping subst : E, z:S, F fc t : T . E fc u : S . E, F fc [z . u] t : T. The proof of this lemma also \ndemonstrates the ease of working with substitution in a locally nameless setting. It proceeds by induction \non the given typing derivation for t. In the case for C-TYPING-ABS, we have a derivation that ends in \n. x/. L ' . (E, z:S, F,x:T1 fc t1 x : T2) E, z:S, F fc abs t1 : T1 . T2 for some .nite set of names L \n', and an induction hypothesis . x/. L ' . (E, F,x:T1 fc [z . u](t1 x): T2) , and we must derive E, F \nfc [z . u](abs t1): T1 . T2 . By the de.nition of substitution, we simplify the substitution to abs ([z \n. u] t1). Then to apply C-TYPING-ABS, we must .nd an L for which we can show . x/. L. (E, F,x:T1 fc ([z \n. u] t1)x : T2) . We use subst open var to write ([z . u] t1)x as [z . u](t1 x) (to match the induction \nhypothesis). To do this rewriting, we need x and z to be distinct. Since the induction hypothesis holds \nonly for x/. L ', we choose L = L ' .{z}. In this proof and in the proof of weakening, we carefully chose \nL when applying C-TYPING-ABS to create a new typing derivation. In practice, we use a tactic to instantiate \nL with the set of all names appearing in the current proof context: intuitively, showing that a judgement \nholds for fewer names is easier than showing that it holds for more. 4.2 Renaming There are a few situations \nin which we need to apply a derivation rule with a co.nitely quanti.ed premise but only know that this \npremise holds for one particular fresh name. Alternatively, know\u00ading that an abstraction type checks, \nwe may wish to use inversion to show that the body of an abstraction type checks with a particu\u00adlar name, \nbut we do not know that that particular name is excluded from the set L used with that invocation of \nC-TYPING-ABS. In such situations, we need to explicitly invoke the fact that our judgments are equivariant \nthrough a renaming lemma. We present now an ex\u00adample of such a situation and explain how to prove the \nrenaming lemma by reusing the corresponding substitution lemma. Suppose that we are trying to show that \ntype checking is decid\u00adable.9 10 typing decidable : term t . ok E . (E fc t : T ) .\u00ac(E fc t : T ) We \nprove this result by induction on term t. Consider the case for abstractions (where t = abs t1) with \nan arbitrary environment E and an arrow type (where T = T1 . T2). Here we are given an induction hypothesis \nthat states that type checking the body is decidable (for some .nite set L '). . x/. L ' . . E ' T ' \n, x ' x ' ok E ' . (E ' fc t1 : T ) .\u00ac(E ' fc t1 : T ) At this point we must determine whether the body \ntype checks to know whether the abstraction should type check. So we pick an arbitrary fresh variable, \nx/. L ' . FV(t1) . dom(E), and consider the two cases that arise from instantiating E ' with (E, x:T1) \nand ' T with T2.11 If the body does type check, we have a derivation of E, x:T1 fc t1 x : T2 . However, \nto show that the abstraction type checks, using rule C-TYPING-ABS, we must show that there is some L \nsuch that . y/. L. E,y:T1 fc t1 y : T2 . Although x was arbitrary, we do not know whether the particular \nvariable that we chose in.uenced whether the body type checked. Therefore, we complete the proof with \nthe help of a renaming lemma that asserts that typing judgments are stable under certain renamings:12 \ntyping rename : x/. (dom(E) . FV(t1)) . E, x:T1 fc t1 x : T2 . . y/. (dom(E) . FV(t1)). E,y:T1 fc t1y \n: T2 This renaming lemma allows us to go from a typing derivation for a single variable x, to a typing \nderivation for a co.nite set of variables. Using this lemma and choosing L ' = dom(E) . FV(t1) lets us \ncomplete the decidability proof. The renaming lemma is simply a consequence of properties (substitution \nand weakening) that we have already proven about the co.nite typing judgement. Importantly, showing these \nproper\u00adties does not require renaming. We can derive typing rename as follows. If x = y, then there is \nnothing to do. Otherwise, we rewrite the conclusion using subst intro as E, y:T1 fc [x . fvar y](t1 x): \nT2 . By the substitution lemma, typing subst, it suf.ces to show that 1. E, y:T1 fc fvar y : T1 and \n2. E, y:T1,x:T1 fc t1 x : T2 .  9 Coq is a constructive logic, so a proof of this lemma is an algorithm \nthat produces either a typing derivation, or a proof that one isn t possible. 10 The simplicity of the \nexample requires a slight change to the formaliza\u00adtion of .., to annotate applications (app) with the \nargument type. This change permits the proof to go through in the application case, but is other\u00adwise \nindependent of binding. 11 The variable x must be fresh for L ' for the induction hypothesis to apply \nand must be fresh for dom(E) so that ok (E, x:T1). We also include FV(t1) to maintain the invariant that \nterms are only opened with fresh variables. 12 While the freshness condition on y . dom(E) ensures that \n(E, y:T1) is well-formed, the freshness condition x . dom(E) could be derived with some work from the \nsecond hypothesis; nevertheless we we choose to stick to a simpler and symmetric presentation. To show \n(1), we use C-TYPING-VAR. To show (2), we use the weak\u00adening lemma, by which it suf.ces to show that \nE, x:T1 fc tx : T2. This result follows from the assumptions of typing rename. In our experience, renaming \nlemmas are rarely needed. Aside from typing decidable, the only situations in our developments where \nthey are required are in the proofs of con.uence for beta reduction in the lambda calculus and the Calculus \nof Constructions. In these proofs, the conclusion of the theorem is an existential statement: there exists \na common reduct. . . . The cases which require renaming involve rules with binding, where we have an \ninduction hypothesis of the form for all x not in L ', there exists t such that . . . which we need \nto use to prove a statement of the form there exists t such that for all y not in L, . . . . The induction \nhypothesis is strictly weaker than the statement we are trying to prove. For each name x, it gives us \nan object t for which some relation holds. We must use the renaming lemma for that relation to show that \nthe relation holds for all suf.ciently fresh names y. 4.3 Equivalence of Exists-Fresh and Co.nite De.nitions \nAt this point we have de.ned two sets of rules for ..: one con\u00adsisting of the original exists-fresh de.nitions, \nwhich corresponds directly to the paper presentation, and one that uses co.nite quan\u00adti.cation, which \nyields stronger induction principles. To be con.\u00addent that the co.nite de.nitions are adequate, we verify \n(formally) that they de.ne the same relations as the exists-fresh variants.13 Note that these proofs \nof equivalence are straightforward conse\u00adquences of renaming lemmas. Let us take the typing relation \nas an example. The theorem to prove is the following: E fc t : T . E f t : T. Both directions are straightforward \ninductions. The TYPING-ABS case of the . direction is the only interesting case, where we must show (E \nfc abs t1 : T1 . T2) from the induction hypothesis (E, x:T1 fc t1 x : T2) and an assumption (x ./FV(t1)). \nThis case follows by applying C-TYPING-ABS, instantiating L to be (FV(t1) . dom(E) .{x}). We are left \nwith the subgoal .y/. L. (E, y:T1 fc t1 y : T2) and conclude using typing rename. 4.4 Streamlining Developments \nIn general, then, developing metatheory in the locally nameless style involves the following steps. 1. \nState de.nitions using exists-fresh quanti.cation. 2. Restate the de.nitions using co.nite quanti.cation. \n 3. Prove basic lemmas, such as subst intro. 4. Prove substitution and weakening lemmas. 5. Prove renaming \nlemmas. 6. Prove the equivalence of the co.nite and exists-fresh presenta\u00adtions.  However, we can sometimes \nget by with even less. To begin with, observe that the exists-fresh de.nitions are needed only in the \n.rst and last steps above. The main reason for stating the exists-fresh de.nitions is to check (informally) \nthat the co.nite de.nitions ad\u00adequately encode the relations of interest. Thus, it is only necessary \nto state the exists-fresh de.nitions for relations whose adequacy is crucial those relations that appear \nhereditarily in the statements of theorems of interest. The style can be streamlined by omitting 13 The \nformal proofs can be found in .le STLC Core Adequacy.v. steps 1 and 6 for de.nitions of technical relations \nthat are intro\u00adduced only to help with proofs, as long as the equivalence of the existential and universal \nforms of de.nition is not actually needed in proofs (see Section 4.2). In fact, the style can be streamlined \nfurther, according to need and personal taste. One may (after gaining some familiarity) feel convinced \nthat the co.nite de.nitions are adequate encodings of one s informal ideas, without the need of a formal \nproof of equiva\u00adlence with their more obviously adequate exists-fresh versions.14 In this case, steps \n1 and 6 can be omitted. By doing this, one may be risking adequacy of representation, but one is not \nrisking con\u00adsistency: the soundness of co.nite-quanti.ed relations checked by Coq is no more in question \nthan the soundness of Coq itself. Finally, if we omit step 6, we can then prove renaming lemmas step \n5 only as needed, rather than going to the trouble of stating and proving them for all relations. Indeed, \nas we described in Sec\u00adtion 4.2, our experience has been that they are rarely needed. In short, the core \nof our style is to de.ne relations using co.nite quanti.cation and to reason about those particular de.nitions, \ni.e., steps 2 through 4. The remaining steps need not be carried out for every relation. 4.5 Comparison \nAs we mentioned in Section 2, we are not the .rst to propose a locally nameless representation for languages \nwith binders. Nev\u00adertheless, our style of formal reasoning using this representation differs from previous \nwork in important ways, requiring much less infrastructure as a result. In this subsection, we give a \ncomparison to the styles used by Gordon (1994), McKinna and Pollack (1993; 1999), and Leroy (2007). To \nobtain a meaningful comparison, we sometimes apply their styles to our de.nitions. Gordon was the .rst \nto use a locally nameless representation for formal reasoning about binders: he used them as a concrete \ndatatype upon which to erect a type of named terms up to alpha equivalence. In contrast to our judgements \n(both the exists-fresh and co.nite versions), his are stated using the close operation in\u00adstead of open. \nFor example, Gordon s local closure rule for abstrac\u00adtion (in our notation) is: term t term (abs (\\x \nt)) Gordon observed that the rule induction principle arising from this form is too weak (Gordon 1994, \nSection 4) in that renaming a variable with a fresh name is sometimes required. He derives a strengthened \ninduction principle by well-founded induction on the length of a term (as is standard). Then, to avoid \nfurther reasoning about length, he uses this strengthened induction principle to derive another strengthened \ninduction principle that picks a name fresh for some .nite set. However, Gordon s strengthened induction \nprinci\u00adple is not the same as that arising from our form of co.nite quan\u00adti.cation, since the induction \nhypothesis only applies to a single variable in the abstraction case. In this respect, Gordon s strength\u00adened \nprinciple is more similar to that of Urban et al. (2007b) than to ours. We get a stronger induction principle \nand stronger inversion principles automatically from the co.nite quanti.ed forms. McKinna and Pollack \n(1993, 1999) proposed a style of develop\u00adment for working with locally named terms. The most signi.cant \ndifference from our style is that it obtains strengthened induction principles by stating universal de.nitions \nof inductive relations, 14 It is worth emphasizing that the exists-fresh versions are more obvi\u00adously \nadequate, in a technical sense: they can be formalized in a very weak theory Primitive Recursive Arithmetic \nwhile co.nite presentations in\u00advolve rules with in.nitely many hypotheses that cannot be formalized in \nany conservative extension of PRA. which quantify bound variables over as many names as possible. For \nexample, they would state the typing rule for abstractions as follows: . x/. dom(E). (E, x:S fa tx : \nT ) A-TYPING-ABS E fa abs t : S . T This form of quanti.cation is natural, as there is no arbitrary choice \nof fresh name in rule A-TYPING-ABS, hence there is at most one derivation of a judgement E fa t : T , \nand the associated in\u00adduction principle is as strong as possible. The problem with rela\u00adtion fa is that \nrule A-TYPING-ABS is too weak as an introduction rule, since it requires its premise to hold for every \nsuf.ciently fresh name, where co.nite quanti.cation (rule C-TYPING-ABS) allows a .nite number of problematic \nnames to be excluded. In McKinna-Pollack style one must prove the equivalence between f and fa (at signi.cant \ncost in infrastructure) before metatheoretic results step 4 in our style can be developed, since f is \ntoo weak in elim\u00adination and fa is too weak in introduction for either to prove both weakening and substitution \nlemmas for themselves. Thus our strat\u00adegy for proving equivalence between de.nitions, which piggybacks \non standard metatheoretic results, fails in the McKinna-Pollack style. Leroy s locally nameless solution \nto the POPLMARK Challenge uses McKinna and Pollack s ideas. He takes universal de.nitions as the of.cial \nones, obtaining strong induction principles for free , and does not explicitly de.ne the exist-fresh \nde.nitions at all. However, to make his proofs go through he needs to show that exists-fresh forms are \nadmissible for the universal forms. E.g., Leroy proves the following lemma for his universally quanti.ed \ntyping relation: t abs : x/. FV(t) . E, x:T1 fa tx : T2 . E fa abs t : T1 . T2. Such lemmas, which are \nessentially equivalent to showing that f and fa de.ne the same relation, must be stated and proved for \nevery rule with binding in the development. The proof of such lemmas requires a signi.cant amount of \ninfrastructure related to renaming, so Leroy s style is a minor streamlining of the McKinna-Pollack style. \n 4.6 Nominal Isabelle and Local Representation The nominal Isabelle package (Urban 2007; Urban et al. \n2007a,b) supports representation in Isabelle/HOL of languages with bind\u00ading (as an extended notion of \ndatatype) using a single species of name for both bound and free variables. Using the HOL type de.\u00adnition \nfacility, the package arranges that HOL equality of terms in these represented languages is up-to alpha \nequivalence, while users need not de.ne alpha equivalence or see any quotient structure. The package \nsupports multiple classes of names (e.g., type variables and term variables) in mutually inductive datatypes \n(e.g., terms and dependent types) and multiple relations on them (e.g., typing and reduction). Using \nthe Isabelle typeclass facility, the package au\u00adtomatically provides de.nitions of name freshness and \nname per\u00admutation (renaming) polymorphic over these multiple aspects of a formalization. Importantly, \ngiven some syntactic restrictions on the represented languages, the package automatically derives equivari\u00adance \nlemmas and strengthened induction principles for formalized languages. The nominal package involves no \naxiomatic extension to Isabelle/HOL, hence is as safe as Isabelle/HOL itself. This nom\u00adinal representation \nis a serious alternative to our style for users who want to do formal metatheory. However it is based \non a great deal of bespoke infrastructure only available in Isabelle/HOL, there are some syntactic restrictions, \nand certain aspects of formalization (such as rule inversion and recursive de.nition over terms) are \nnot well supported (at time of writing) because of the need to respect alpha equivalence. A locally nameless \nformalization (as we propose) or a locally named formalization (` a la McKinna-Pollack) can be formalized \nin many logics and proof tools, depending only on basic notions like datatypes and inductively de.ned \nrelations.15 In particular, the local representation can be seen as a nominal representation that doesn \nt happen to use any nominal binding; in this case the nominal relation of freshness of names for language \nstructures (terms, types, contexts, . . . ) is the same as the local representation s notion of non-occurrence. \nThis leads to an interesting possibility: local representations can be de.ned and reasoned about using \nthe nominal Isabelle package, getting the de.nitions of freshness and renaming and the proofs of equivariance \nfor free from the package. Interestingly, the nominal package can also automatically infer a strengthened \ninduction principle for inductive relations over local representations (with some syntactic restrictions); \nsee (Urban and Pollack 2007) for more details. A detailed comparison between nominal representation and \nlo\u00adcally nameless representation is beyond the scope of this paper, but, as we are focusing on strengthened \ninduction principles, we can remark that the locally nameless strengthened induction principle (e.g., \nfrom rule C-TYPING-ABS or rule A-TYPING-ABS) is stronger than the strengthened induction principle automatically \nderived by the nominal Isabelle package. For a full explanation of the nom\u00adinal strengthened induction, \nsee Urban et al. (2007b); here it is enough to observe that, when using such an induction principle, \none speci.es not only the derivation being eliminated ( induction on . . . ), but also an arbitrary .nitely \nsupported structure to be used as a freshness context. Whenever a chosen name appears in an in\u00adduction \nhypothesis (e.g., the name that is bound in an abstraction typing rule), that name is known to be fresh \nfor the speci.ed fresh\u00adness context. This solves many problems, as in the example above of weakening \nfor the typing judgement. However, you must spec\u00adify the freshness context when invoking induction. In \ncontrast, the locally nameless strengthened induction principles, with their uni\u00adversally quanti.ed fresh \nnames, allow fresh instantiation of these names later, at the point where you have seen the particular \ncases that must be proved. Since particular cases may involve existential quanti.ers, you may not know \nwhat the necessary freshness context is until after seeing a case and eliminating an existential quanti.er. \nIn such rare examples, the automatically derived nominal strength\u00adened induction principle is not adequate \n(a detailed hand proof is necessary) while the locally nameless strengthened induction prin\u00adciple works \nperfectly. 5. Practical Formal Metatheory We close with a concrete discussion of our Coq realization \nof work\u00ading with co.nite quanti.cation. We present the major developments we have carried out System \nF<: , the Calculus of Constructions, and extensions of ML to demonstrate that our techniques scale to \nlarger languages and are expressive enough for wide use. We dis\u00adcuss issues speci.c to each development \n(e.g., dealing with multi\u00adbinders) as well as properties common to all of them (e.g., the con\u00adciseness \nand robustness on change of our scripts). Finally, we give an overview of the structure of our developments \nfor readers who may wish to use them as a basis for their own formalizations. 15 Some specialized tactics, \nas in the accompanying Coq code http:// arthur.chargueraud.org/research/2007/binders/, are useful, but \nnot essential. In any case these tactics are very much simpler than the nominal Isabelle package. 5.1 \nSystem F<: The heart of the POPLMARK Challenge is a proof of type sound\u00adness of System F<: . This task \nwas designed as a stress test for formalized metatheory. Our solution closely follows the structure proposed \nin the appendix of the challenge s description. To get a sense of how our solution compares to other \nsolutions, we measured the number of lemmas and steps of reasoning in\u00advolved in several developments;16 \nthe results are summarized in Figure 5. Our study is restricted to Coq developments since there are no \nmeaningful metrics across different proof assistants. In this comparison, a step of reasoning is de.ned \nas the invocation of one tactic, excluding trivial ones: intros (introduces hypotheses into the context), \nauto (performs automated proof search), and simple variations of these two. We also exclude from the \ncounts material from libraries that are reusable across metatheory developments. We isolate part 1A of \nthe challenge (technical properties of the subtyping relation) from parts 1A+2A (preservation and progress) \nbecause some submissions cover only part 1A. Even when attention is restricted to Coq developments, the \ncom\u00adparison is necessarily rough, since the developments were carried out by different people with different \npreferences in the amount of automation they used, etc. Nevertheless, a few interesting points emerge. \nThe .rst line of the table shows that our style compares well against Vouillon s development, which uses \npure de Bruijn indices a representation commonly thought to be quite effective. The solutions that do \nnot use a standard de Bruijn or locally name\u00adless representation (Stump and Hirschowitz &#38; Maggesi) \nrequire signi.cantly more steps. The last line shows that our style re\u00adquires signi.cantly less infrastructure \nthan Leroy s solution, a lo\u00adcally nameless solution faithful to McKinna and Pollack s way of dealing \nwith the quanti.cation of names. Chlipala s is a variation on an earlier version of Leroy s development \nand is the only one that is shorter than ours, mainly because Chlipala s proof script re\u00adlies heavily \non development-speci.c tactics. Although clever automation and development-speci.c tactics can make scripts \nextremely small (Nipkow [2001] gives an impres\u00adsively automated proof of con.uence, for example), they \ncan also make them slow (hard to work with) and brittle (hard to reuse). Brittleness emerges when automation \nfails after some changes to earlier de.nitions or lemmas: it can be hard to know exactly what has been \nbroken and how to .x it. Of course, the other extreme of no automation at all is also unmanageable, especially \nfor metathe\u00adory proofs, which involve many related arguments. Moreover, too little automation can also \nmake scripts brittle: even a tiny change in de.nitions or statements of lemmas will require update. Aiming \nfor maximal robustness, our convention is to rely as much as pos\u00adsible on automation for low-level details \n(e.g., proving that a term is locally closed) while giving all the important arguments (the ones that \nwould appear in a rigorous paper proof) manually.  5.2 Calculus of Constructions (CoC) This formalization \ncontains three main components. The .rst is a proof of con.uence for parallel beta-reduction. Its use \nof the vari\u00adable closing operation requires slightly more advanced reasoning about binders. We have also \nused this development to evaluate our scripts for robustness: we .rst completed a proof of con.uence \nfor the pure lambda calculus and then migrated it to CoC, preserving the same .ow of arguments and just \nadding the extra cases and up\u00addating the names of some hypotheses. The second part consists of a set \nof inversion results for the typing and the conversion judgments, which are quite technical in themselves \nbut do not involve much dif.culty with respect to 16 All are publicly available from http://alliance.seas.upenn.edu/ \n~plclub/cgi-bin/poplmark/. Author (chronological order) Representation used Lemmas 1A Proof steps 1A \nLemmas 1A+2A Proof steps 1A+2A Vouillon de Bruijn 30 402 72 1175 Leroy locally nameless 49 495 128 1364 \nStump levels/names 56 938 - - Hirschowitz &#38; Maggesi de Bruijn (nested datatype) 49 1574 - - Chlipala \nlocally nameless 23 75 - - Our development locally nameless 22 101 65 576 Figure 5. Comparison of Coq \nsubmissions to the POPLMARK Challenge Number of Infrastructure Core Infrastructure Core Language Results \nformalized trusted de.nitions lemmas lemmas proof steps proof steps .. Preservation and progress 13 \n13 4 49 45 System F<: Preservation and progress 20 48 17 335 241 ML core only Preservation and progress \n23 37 8 181 98 ML with features Preservation and progress 42 55 18 367 396 Lambda calculus Church-Rosser \n11 21 25 112 160 CoC Church-Rosser, preservation 17 36 55 214 475 Figure 6. Complexity of our developments \nbinders. This part is representative of the effort required for the CoC formalization: we felt that the \nlargest share of the work was to understand and be able to state clearly the arguments involved. The \nfact that the proofs were machine-checked appeared to be only a way to force oneself to understand all \nthe details of the proofs formalized, not as an extra burden to be dealt with. The third and last part \nis the core of the preservation proof, which shares a signi.cant amount of structure with the correspond\u00ading \nproof for System F<: (only the steps of reasoning are more complex to follow). Compared to the System \nF<: development, the fact that terms and types are represented in a uniform way in CoC and that proofs \nare more complex reduces the binding infrastructure from about 60% of the total development down to 35% \npercent. Compared to Barras s formalization of CoC in Coq (1997) using a pure de Bruijn representation, \nour style saves us from numerous issues associated with shifting indices particularly bothersome when \nworking with CoC s dependent types and so, unlike Barras, we did not need clever engineering of the statements \nof lemmas to make them .t the representation used.  5.3 Extensions of ML We also investigated how to \nextend the basic .. development with features such as datatypes, .xpoints, references, exceptions, pattern \nmatching, and ML-style polymorphic types. Then, building on the individual successes of each of these \nextensions, we set up the for\u00admalization of a language containing all of these features together. This \nexperiment demonstrates that our style can be applied to full\u00adfeatured programming languages, not just \ntiny lambda-calculi. Pleasingly, most of the arguments that would be omitted as trivial on paper and \nwhich do not involve binders are solved by the auto tactic. In particular, the infrastructure lemmas \ndo not need any change when we add features like pairs or references. The key proofs preservation and \nprogress contain respectively in 60 and 80 lines, which seems reasonable for a system with 24 typing \nrules. A key idea involved in this development is a treatment of multi\u00adbinders, used to encode ML type \nschemes, patterns, and recur\u00adsion. The basic operation on a multi-binder is to open it with a list of \nterms. A bound variable pointing to the jth variable bound by the ith binder above the current position \nis represented as (trm bvar ij). Free variables are still represented as one single name and substitution \nlemmas are still stated in terms of an atomic substitution from one name to one term. Then, to prove \nsubject re\u00adduction, for example, the substitution lemma is applied iteratively in the cases involving \nmulti-binders. 5.4 Organization of Our Developments Each of our developments is divided into three main \nparts: trusted de.nitions, infrastructure, and core lemmas. The trusted de.nitions part contains the \ndescription of the lan\u00adguage formalized the syntax of the language, its semantics, and its type system, \nif any and the statements of the main theorems which are to be proven about the language. This part is \nthe only material that needs to be trusted, in the following sense: if one is convinced about the adequacy \nof these de.nitions and trusts that Coq correctly type-checks all proofs in the development, then one \ncan have con.dence that the system has been formally certi.ed. The infrastructure part sets up the machinery \nrequired for the core lemmas and consists of several components: 1. Language-speci.c specializations \nof tactics for working with co.nite quanti.cation, e.g., to automatically choose a set L when applying \na rule that uses co.nite quanti.cation. 2. Proofs about properties of substitution (Figure 2). 3. Proofs \nthat local closure is preserved by various operations, e.g., substitution (Section 3.3). 4. Regularity \nlemmas which state that relations contain only lo\u00adcally closed terms (Section 3.3). 5. Hints to enable \nCoq s automation to use regularity lemmas.  Note that the lemmas about substitution are similar from \none lan\u00adguage to the next. When setting up a new development, those who wish to get to interesting proofs \nquickly may state as axioms properties of substitution and regularity lemmas, proving them only after \nthey believe that their main proofs will go through. In this manner, one can test-drive a language de.nition \nwithout having to revise infrastructure proofs as the de.nition is modi.ed. Finally, the core lemmas \npart contains the lemmas that would normally be stated in an informal presentation. The statements closely \nmatch their informal counterparts, and the proofs contain few uninteresting details facts about local \nclosure and freshness side conditions are almost always handled automatically. We conclude this section \nwith a breakdown of our developments by the number of de.nitions and lemmas in each part, as well as \nthe number of proof steps required to prove the lemmas; the results are summarized in Figure 6. The number \nof trusted de.nitions gives an idea of the size of the language formalized. The number of core lemmas \ngives an idea of the theoretical complexity of the develop\u00adment; recall that these lemmas correspond \nclosely with results that would be proven informally. The amount of infrastructure, in terms of both \nlemmas and steps, is proportional to the number of binding constructs and relations in the language. \nA comparison between .gures from the last two columns suggests that the amount of in\u00adfrastructure work \nis reasonable compared to the core proof work especially since infrastructure proofs follow a standard \npattern and are easily set up. More precisely, the ratio infrastructure over core proofs increases with \nthe number of binding constructs involved but decreases with the inherent complexity of the development. \n6. Conclusion We have argued for a novel style for formalizing programming\u00adlanguage metatheory, based \non a combination of locally nameless representation with a co.nite idiom for quantifying free names in \ninductive de.nitions. This design satis.es the evaluation criteria of POPLMARK. First, our presentation \nis transparent: the proofs closely follow their informal equivalents. Second the overheads of the approach \nare low: we do not need manual proofs of freshness side-conditions nor reasoning about alpha-equivalence, \nand only on rare occasions do we need to justify well-formedness of objects (e.g. local closure) or explicitly \nrename variables. When we do, the required proofs of renaming lemmas follow with virtually no infrastructure. \nAt the same time, there is no need for external tools, and the style works in any general purpose theorem \nprover (although we found Coq to be well-suited to the task). In our scripts, de.nitions and results \nabout variables, freshness, and environments are factored into a reusable library. Finally, experience \nwith a number of large developments suggests that the approach is complete in the informal sense that \nany language de.nition and accompanying reasoning techniques that would be accepted as informally correct \ncan be carried out in this style. Our formalizations provide a good starting point for new work reports \nfrom early adopters con.rm that modifying them is much easier than starting a new development from scratch. \nIn the future, we would like to integrate our approach with the Ott tool (Sewell et al. 2007), which \nautomatically generates Coq (and LATEX) de.nitions from compact, high-level language descrip\u00adtions. A \nmore ambitious next step is to study the possibility of auto\u00admatically generating the required infrastructure \nproofs, which fol\u00adlow a fairly simple pattern. Finally, we would like to explore cer\u00adti.ed programming \nof tools such as type checkers and compilers that must deal with binders. In the long term, we hope that \nour techniques will help with the veri.cation of both speci.cations and implementations of programming \nlanguages. Acknowledgments Many thanks to the members of the Penn PLClub for extensive feedback and discussion, \nand to Michael Norrish and Christian Urban for important technical insights and to the POPL reviewers, \nBob Harper, Peter Sewell, and Karl Crary for helping improve the .nal version. This work was supported \nby NSF grant 545886, CRI: Machine Assistance for Program\u00adming Language Research. Pollack thanks the International \nCentre for Mathematical Sciences (Edinburgh) Workshop on Abstraction, Substitution and Naming and the \nEU Framework 6 Coordination Action 510996, TYPES. References Thorsten Altenkirch. A formalization of \nthe strong normalization proof for System F in LEGO. In Bezem and Groote (1993), pages 13 28. Andrew \nW. Appel. Foundational proof-carrying code. In IEEE Symposium on Logic in Computer Science (LICS), Boston, \nMassachusetts, pages 247 258, June 2001. Michael Ashley-Rollman, Karl Crary, and Robert Harper. Submission \nto the POPLMARK challenge. Available from http://www.cis.upenn. edu/~plclub/mmm/, 2005. Brian E. Aydemir, \nAaron Bohannon, Matthew Fairbairn, J. Nathan Foster, Benjamin C. Pierce, Peter Sewell, Dimitrios Vytiniotis, \nGeoffrey Wash\u00adburn, Stephanie Weirich, and Steve Zdancewic. Mechanized metathe\u00adory for the masses: The \nPOPLMARK challenge. In Joe Hurd and Tom Melham, editors, Theorem Proving in Higher Order Logics: 18th \nInter\u00adnational Conference, TPHOLs 2005, volume 3603 of Lecture Notes in Computer Science, pages 50 65. \nSpringer, 2005. Henk P. Barendregt. The Lambda Calculus. North Holland, revised edition, 1984. Bruno \nBarras and Benjamin Werner. Coq in coq. Available from http: //pauillac.inria.fr/~barras/coq_work-eng.html, \n1997. M. Bezem and J. F. Groote, editors. Typed Lambda Calculi and Applica\u00adtions: International Conference \non Typed Lambda Calculi and Appli\u00adcations, TLCA 93, volume 664 of Lecture Notes in Computer Science, \n1993. Springer. Anna Bucalo, Furio Honsell, Marino Miculan, Ivan Scagnetto, and Martin Hoffman. Consistency \nof the theory of contexts. J. Funct. Program, 16 (3), 2006. Adam Chlipala. Submission to the POPLMARK \nchallenge, part 1a. Available from http://www.cs.berkeley.edu/~adamc/ poplmark/, 2006. The Coq Development \nTeam. The Coq proof assistant reference manual, version 8.1. Available from http://coq.inria.fr/, 2007. \nThierry Coquand. An algorithm for testing conversion in type theory. In G\u00b4erard Huet and Gordon Plotkin, \neditors, Logical Frameworks, pages 255 279. Cambridge University Press, 1991. Karl Crary. Toward a foundational \ntyped assembly language. In POPL 03: Proceedings of the 30th ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Languages, pages 198 212. ACM Press, 2003. N. G. de Bruijn. Lambda calculus notation with \nnameless dummies, a tool for automatic formula manipulation, with application to the Church-Rosser theorem. \nIndagationes Mathematicae, 34(5):381 392, 1972. Jo\u00a8e Hirschowitz. Higher-order ab\u00adelle Despeyroux, Amy \nFelty, and Andr\u00b4stract syntax in Coq. In Typed Lambda Calculi and Applications, Second International \nConference on Typed Lambda Calculi and Applications, TLCA 95, volume 902 of Lecture Notes in Computer \nScience, pages 124 138. Springer, 1995. Also available as INRIA Research Report 2556. Peter Dybjer. Inductive \nfamilies. Formal Aspects of Computing, 6:1 26, 1994. Jonathan M. Ford and Ian A. Mason. Operational techniques \nin PVS A preliminary evaluation. Electronic Notes in Theoretical Computer Science, 42, 2001. Gerhard \nGentzen. The Collected Papers of Gerhard Gentzen. North-Holland, 1969. Edited by Mandred Szabo. Andrew \nD. Gordon. A mechanisation of name-carrying syntax up to alpha\u00adconversion. In J. J. Joyce and C.-J. H. \nSeger, editors, Higher-order Logic Theorem Proving And Its Applications, Proceedings, 1993, volume 780 \nof Lecture Notes in Computer Science, pages 414 426. Springer, 1994. Andrew D. Gordon and Tom Melham. \nFive axioms of alpha-conversion. In J. von Wright, J. Grundy, and J. Harrison, editors, Theorem Proving \nin Higher Order Logics: 9th International Conference, TPHOLs 96, volume 1125 of Lecture Notes in Computer \nScience, pages 173 190. Springer, 1996. Robert Harper and Daniel R. Licata. Mechanizing metatheory in \na logical framework. Journal of Functional Programming, 17(4 5):613 673, 2007. Robert Harper, Furio Honsell, \nand Gordon Plotkin. A framework for de.ning logics. Journal of the ACM, 40(1):143 184, 1993. Dimitri \nHendriks and Vincent van Oostrom. Adbmal. In F. Baader, editor, Automated Deduction CADE-19, volume \n2741 of Lecture Notes in Arti.cial Intelligence, pages 136 150. Springer Verlag, 2003. Peter Homeier. \nA proof of the Church-Rosser theorem for the lambda calculus in higher order logic. In Richard J. Boulton \nand Paul B. Jackson, editors, TPHOLs 2001: Supplemental Proceedings, pages 207 222. Division of Informatics, \nUniversity of Edinburgh, September 2001. Available as Informatics Research Report EDI-INF-RR-0046. Furio \nHonsell, Marino Miculan, and Ivan Scagnetto. The theory of contexts for .rst order and higher order abstract \nsyntax. Electronic Notes in Theoretical Computer Science, 62, 2002. G\u00b4erard Huet. The constructive engine. \nIn Raghavan Narasimhan, editor, A Perspective in Theoretical Computer Science: Commerative Volume for \nGift Siromoney. World Scienti.c Publishing, 1989. Also available as INRIA Technical Report 110. G\u00b4erard \nHuet. Residual theory in .-calculus: A formal development. Journal of Functional Programming, 4(3):371 \n394, July 1994. Also available as INRIA Research Report 2009 (August 1993). Gerwin Klein and Tobias Nipkow. \nA machine-checked model for a Java\u00adlike language, virtual machine, and compiler. ACM Transactions on \nProgramming Languages and Systems, 28(4):619 695, 2006. J. L. Krivine. Lambda-Calculus, Types and Models. \nEllis Horwood, 1990. Daniel K. Lee, Karl Crary, and Robert Harper. Towards a mechanized metatheory of \nStandard ML. In POPL 07: Proceedings of the 34th Annual ACM SIGPLAN-SIGACT Symposium on Principles of \nProgram\u00adming Languages, pages 173 184. ACM Press, 2007. Xavier Leroy. Formal certi.cation of a compiler \nback-end, or: programming a compiler with a proof assistant. In Proc. of the 33rd Symposium on Principles \nof Programming Languages, pages 42 54. ACM Press, 2006. Xavier Leroy. A locally nameless solution to \nthe POPLmark challenge. Research report 6098, INRIA, January 2007. Zhaohui Luo and Robert Pollack. The \nLEGO proof development system: A user s manual. Technical Report ECS-LFCS-92-211, University of Edinburgh, \nMay 1992. Conor McBride and James McKinna. Functional pearl: I am not a number I am a free variable. \nIn Haskell 04: Proceedings of the 2004 ACM SIGPLAN Workshop on Haskell, pages 1 9. ACM Press, 2004. James \nMcKinna and Robert Pollack. Pure Type Systems formalized. In Bezem and Groote (1993), pages 289 305. \nJames McKinna and Robert Pollack. Some lambda calculus and type theory formalized. Journal of Automated \nReasoning, 23(3 4):373 409, 1999. Tobias Nipkow. More Church-Rosser proofs (in Isabelle/HOL). Journal \nof Automated Reasoning, 26(1):51 66, January 2001. Michael Norrish and Konrad Slind. HOL 4. Available \nfrom http://hol. sourceforge.net/, 2007. Frank Pfenning and Conal Elliot. Higher-order abstract syntax. \nIn PLDI 88: Proceedings of the ACM SIGPLAN 1988 Conference on Pro\u00ad gramming Language Design and Implementation, \npages 199 208. ACM Press, 1988. Frank Pfenning and Carsten Sch\u00a8urmann. System description: Twelf A meta-logical \nframework for deductive systems. In Harald Ganzinger, editor, Automated Deduction, CADE 16: 16th International \nConference on Automated Deduction, volume 1632 of Lecture Notes in Arti.cial Intelligence, pages 202 \n206. Springer, 1999. Andrew M. Pitts. Nominal logic, a .rst order theory of names and binding. Information \nand Computation, 186:165 193, 2003. Randy Pollack. Reasoning about languages with binding: Can we do \nit yet?, February 2006. Presentation, slides available from http:// homepages.inf.ed.ac.uk/rpollack/. \nRobert Pollack. Closure under alpha-conversion. In H. Barendregt and T. Nipkow, editors, TYPES 93: Workshop \non Types for Proofs and Pro\u00adgrams, Nijmegen, May 1993, Selected Papers, volume 806 of Lecture Notes in \nComputer Science, pages 313 332. Springer, 1994a. Robert Pollack. The Theory of LEGO: A Proof Checker \nfor the Extended Calculus of Constructions. PhD thesis, Univ. of Edinburgh, 1994b. Dag Prawitz. Natural \nDeduction: Proof Theoretical Study. Almquist and Wiksell, Stockholm, 1965. Ole Rasmussen. The Church-Rosser \ntheorem in Isabelle: A proof porting experiment. Technical Report 364, University of Cambridge, Computer \nLaboratory, March 1995. Wilmer Ricciotti. Submission to the POPLMARK challenge, part 1a. Avail\u00adable from \nhttp://ricciott.web.cs.unibo.it/, 2007. Peter Sewell, Francesco Zappa Nardelli, Scott Owens, Gilles Peskine, \nThomas Ridge, Susmit Sarkar, and Rok Strni.sa. Ott: Effective tool sup\u00adport for the working semanticist. \nIn ICFP 07: Proceedings of the 2007 ACM SIGPLAN International Conference on Functional Programming, pages \n1 12. ACM, 2007. Natarajan Shankar. A mechanical proof of the Church-Rosser theorem. Journal of the Association \nfor Computing Machinery, 35(3):475 522, 1988. Allen Stoughton. Substitution revisited. Theoretical Computer \nScience, 59 (3):317 325, 1988. Christian Urban. Nominal techniques in Isabelle/HOL. Journal of Auto\u00admatic \nReasoning, 2007. To appear; available from http://www4.in. tum.de/~urbanc/publications.html. Christian \nUrban and Randy Pollack. Locally nameless representation in Nominal Isabelle. Talk at Workshop on Mechanizing \nMetatheory. Available from www4.in.tum.de/~urbanc/Publications/ln.pdf, 2007. Christian Urban, Stefan \nBerghofer, and Julien Narboux. Nominal datatype package for Isabelle/HOL. Available from http://isabelle.in. \ntum.de/nominal/, 2007a. Christian Urban, Stefan Berghofer, and Michael Norrish. Barendregt s variable \nconvention in rule inductions. In Proceedings of the 21th Conference on Automated Deduction (CADE 2007), \nvolume 4603 of Lecture Notes in Computer Science, pages 35 50. Springer, 2007b. Ren\u00b4e Vestergaard and \nJames Brotherston. A formalised .rst-order con.u\u00adence proof for the .-calculus using one-sorted variable \nnames. Informa\u00adtion and Computation, 183(2):212 244, 2003.   \n\t\t\t", "proc_id": "1328438", "abstract": "<p>Machine-checked proofs of properties of programming languages have become acritical need, both for increased confidence in large and complex designsand as a foundation for technologies such as proof-carrying code. However, constructing these proofs remains a black art, involving many choices in the formulation of definitions and theorems that make a huge cumulative difference in the difficulty of carrying out large formal developments. There presentation and manipulation of terms with variable binding is a key issue.</p> <p>We propose a novel style for formalizing metatheory, combining <i>locally nameless</i> representation of terms and cofinite quantification of free variable names in inductivedefinitions of relations on terms (typing, reduction, ...). The key technical insight is that our use of cofinite quantification obviates the need for reasoning about equivariance (the fact that free names can be renamed in derivations); in particular, the structural induction principles of relations defined using cofinite quantification are strong enough for metatheoretic reasoning, and need not be explicitly strengthened. Strong inversion principles follow (automatically, in Coq) from the induction principles. Although many of the underlying ingredients of our technique have been used before, their combination here yields a significant improvement over other methodologies using first-order representations, leading to developments that are faithful to informal practice, yet require noexternal tool support and little infrastructure within the proof assistant.</p> <p>We have carried out several large developments in this style using the Coq proof assistant and have made them publicly available. Our developments include type soundness for System <i>F</i> sub; and core ML (with references, exceptions, datatypes, recursion, and patterns) and subject reduction for the Calculus of Constructions. Not only do these developments demonstrate the comprehensiveness of our approach; they have also been optimized for clarity and robustness, making them good templates for future extension.</p>", "authors": [{"name": "Brian Aydemir", "author_profile_id": "81330487931", "affiliation": "University of Pennsylvania, Philadelphia, PA", "person_id": "P869023", "email_address": "", "orcid_id": ""}, {"name": "Arthur Chargu&#233;raud", "author_profile_id": "81372592434", "affiliation": "INRIA, Rocquencourt, France", "person_id": "P925375", "email_address": "", "orcid_id": ""}, {"name": "Benjamin C. Pierce", "author_profile_id": "81100303310", "affiliation": "University of Pennsylvania, Philadelphia, PA", "person_id": "PP14111350", "email_address": "", "orcid_id": ""}, {"name": "Randy Pollack", "author_profile_id": "81100439862", "affiliation": "University of Edinburgh, Edinburgh, United Kingdom", "person_id": "PP43136315", "email_address": "", "orcid_id": ""}, {"name": "Stephanie Weirich", "author_profile_id": "81100093135", "affiliation": "University of Pennsylvania, Philadelphia, PA", "person_id": "P267927", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1328438.1328443", "year": "2008", "article_id": "1328443", "conference": "POPL", "title": "Engineering formal metatheory", "url": "http://dl.acm.org/citation.cfm?id=1328443"}