{"article_publication_date": "01-07-2008", "fulltext": "\n On the Computational Soundness of Cryptographically Masked Flows Peeter Laud Tartu University, Institute \nof Computer Science, and Cybernetica AS peeter.laud@ut.ee Abstract To speak about the security of information \n.ow in programs em\u00adploying cryptographic operations, de.nitions based on computa\u00adtional indistinguishability \nof distributions over program states have to be used. These de.nitions, as well as the accompanying analysis \ntools, are complex and error-prone to argue about. Cryptographi\u00adcally masked .ows, proposed by Askarov, \nHedin and Sabelfeld, are an abstract execution model and security de.nition that attempt to abstract \naway the details of computational security. This abstract model is useful because analysis of programs \ncan be conducted us\u00ading the usual techniques for enforcing non-interference. In this paper we investigate \nunder which conditions this abstract model is computationally sound, i.e. when does the security of a \nprogram in their model imply the computational security of this program. This paper spells out a reasonable \nset of conditions and then proposes a simpler abstract model that is nevertheless no more restrictive \nthan the cryptographically masked .ows together with these conditions for soundness. Categories and Subject \nDescriptors F.3.2 [Semantics of Pro\u00adgramming Languages]: Operational Semantics, Program Analysis General \nTerms Languages, Security, Veri.cation Keywords Secure Information Flow, Encryption, Computational Soundness, \nCryptographically Masked Flows 1. Introduction Non-interference (Goguen and Meseguer 1982) is the usual \nway of de.ning the secure information .ow in programs (Sabelfeld and Myers 2003). It states that varying \nonly the secret inputs of the program must not change the public outputs public outputs are determined \nby the non-secret inputs only. For programs containing encryption or other cryptographic operations, \nsuch a de.nition may be too strong, because a ciphertext still depends on the plaintext used to produce \nit, albeit in a manner that cannot be exploited by an adversary that uses only a reasonable amount of \nresources. Instead, the notion of computational non-interference (Laud 2003) has to be used. The de.nition \nof computational non-interference is quite complex in its structure and in the used domains. The usage \nof such a de.nition requires the semantics of the program Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for pro.t or commercial advantage and that copies bear this notice and the full \ncitation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to \nlists, requires prior speci.c permission and/or a fee. POPL 08, January 7 12, 2008, San Francisco, California, \nUSA. Copyright c &#38;#169; 2008 ACM 978-1-59593-689-9/08/0001. . . $5.00 to be probabilistic, making \nit more dif.cult to argue about. Also, the precise program analyses based directly on computational non\u00ad \ninterference (Laud 2001, 2003; Laud and Vene 2005) tend to have a complex structure and their correctness \nis not always so obvious. It would be nice to have a more abstract de.nition for the semantics of the \nprogramming language, as well as for the security of the information .ow, such that (i) the used domains \nand the structure of de.nitions are more conventional; (ii) the security of the program in the abstract \nmodel would imply its security in the computational model;  (iii) the abstraction would hide the cryptographic \ndetails of the en\u00adcryption (including the necessary use of probabilistic domains), but not much else \nof the computational model. Cryptographically masked .ows by Askarov et al. (2006) aims to be such a \nmore abstract model. This model considers an imperative programming language (in the original paper this \nlanguage is quite feature-rich; we consider a stripped-down version of it) with key generation, encryption \nand decryption as distinguished operations. In the concrete semantics, corresponding to the real-world \nimple\u00ad mentations of the language, the encryption operation is probabilis\u00ad tic (otherwise it cannot be \nsuf.ciently secure). The semantics of a program maps the initial state Si to a probability distribution \nDf over .nal states. In the model of cryptographically masked .ows, henceforth called the abstract semantics, \nthe encryption operation is non-deterministic the encryption algorithm works in the same way as in the \nconcrete semantics, but each time it .ips a coin it gets both 0 and 1 as the result. The abstract semantics \nof a pro\u00ad gram maps the initial state Si to a set Sf of possible .nal states. The set Sf can be obtained \nfrom the distribution Df by just for\u00ad getting the probabilities (at least if there are no other probabilistic \noperations except key generation and encryption; such requirement is put forth by Askarov et al. (2006)). \nThe de.nition of secure in\u00ad formation .ow in the setting of cryptographically masked .ows is the conventional \npossibilistic non-interference (Smith and Volpano 1998) stating that the set of the low-slices of possible \n.nal states may not depend on the initial secrets. However, when considering whether the low-slices of \ntwo states are equal, we sometimes al\u00ad low the values of the variables containing ciphertexts to differ. \nThe equivalence of low-slices is de.ned so that generally all ciphertexts are considered equal, but we \ncan distinguish a pair of two differ\u00ad ent ciphertexts from a pair of equal ciphertexts. Cryptographically \nmasked .ows can hence be said to satisfy the objectives (i) and (iii). The aim of the current paper is \nto investigate, to what extent and under which conditions the objective (ii) is satis.ed. Askarov et \nal. (2006) also give a type system for checking whether a program satis.es the non-interference property \ngiven by the cryptographically masked .ows. In the current paper, we do not treat this type system in \nany way; we are interested strictly only in the cryptographically masked .ows. Still, the results of \nthis paper and Askarov et al. (2006) together establish that if a program is typable according to this \ntype system, and also satis.es certain conditions that we put on it in this paper, then this program \nhas computationally secure information .ow. In the following we will give a precise de.nition of the \nprogram\u00adming language and its concrete and abstract semantices in Sec. 2. We continue by formally stating \nthe de.nitions of secure informa\u00adtion .ow in both the concrete and abstract settings in Sec. 3. In Sec. \n4 we state and discuss the security de.nitions that the encryp\u00adtion systems employed in this paper must \nsatisfy. In Sec. 5 we give several examples of programs that seem to violate the computa\u00adtional soundness \nof cryptographically masked .ows and outline the conditions that would exclude such programs, these conditions \nare formally stated in Sec. 6 and their suf.ciency is proved in Sec. 7. Re.ecting on the constraints \nput on the programs we devise a new model for abstract execution and non-interference that is simpler \nand less restrictive; we describe it in Sec. 8. We .nish with a review of some related work in Sec. 9 \nand discussion on desired properties of such abstractions in general in Sec. 10. 2. Programming language \nIn this paper we consider programs P in the usual WHILE\u00adlanguage de.ned by P ::= x := o(x1,...,xk) | \nskip | P1 ; P2 | if b then P1 else P2 | while b do P ' where b, x, x1,...,xk are variables from a given \nset Var and o ranges over a .xed set of arithmetic, relational, boolean, etc. op\u00aderations. Among the \noperations of the language we will handle the following ones in a special way: new key generation newkey, \n(sym\u00admetric) encryption enc, decryption dec, pairing (, ) and projections p1 and p2. The language in \n(Askarov et al. 2006) is much richer, but the subset we are considering here represents the underlying \nprob\u00adlem well. As usually done in this area (research on secure informa\u00adtion .ow), we consider only terminating \nprograms the issue of leaking information by non-termination (or by execution time) is orthogonal to \nthe issues considered here and can be mitigated by known methods (Agat 2000). Askarov et al. (2006) give \na big-step operational semantics for the programming language. The semantics is quite typeful values \nfrom different sources have different types (key, ciphertext, pair, integer) and if the arguments of \nthe operations are not of the right type, the operation gets stuck (in some sense, by disallowing type \nerrors, the semantics already contains some aspects of the enforcement of non-interference). In this \npaper, we have tried to simplify the operational semantics as much as possible, leaving out such constraints. \nRushing ahead, those constraints actually turn out to be necessary for the soundness result, thus they \nll appear again in Sec. 6. The abstract semantics of expressions is given in Fig. 1. The semantics of \nan n-ary normal operation o is a polynomial-time computable function [ o] : Valn . Val where Val = {0, \n1} * is the set of values (no operations are probabilistic, except key gen\u00aderation and encryption). We \nassume that there is a distinguished value .. Val denoting failure, and that all operations are strict \nwith respect to .. For giving semantics to pairing and projections, we assume that an easily computable \nand reversible injective func\u00adtion . : Val2 . Val is .xed; this function is the semantics of the pairing \noperation. For giving semantics to the key generation, encryption and decryption operations, we .x an \nencryption system (K, E, D). Here K is the key generation algorithm, E is the encryp\u00adtion and D the decryption \nalgorithm. The algorithms K and E are M(x)= v (M, x).a v (M, ei).a vi [ o]](v1,...,vk)= v (M, o(e1,...,ek)).a \nv (M, e).a u.(v1,v2)= u (M, pi(e)).a vi (M, e).a uu . Dom . (M, pi(e)).a . v . Supp K() (M, newkey).a \nv (M, ek).a vk (M, ex).a vx vy . Supp E(vk,vx) (M, enc(ek,ex)).a vy Figure 1. Abstract semantics of \nexpressions probabilistic, D is deterministic. The algorithm K takes no argu\u00adments, the algorithms E \nand D take two the key and the plain\u00ad/ciphertext. For all keys k that can be output by K, for all plaintexts \nx . Val and all ciphertexts y that can be output by E(k, x), the equality D(k, y)= x must hold. The decryption \nis allowed to fail, it has to produce . then. The semantics of the operation dec is D. For a probability \ndistribution D we denote by Supp D the set of all such x where D(x) > 0. The ability of operations, particularly \ndecryption, to fail is dif\u00adferent from (Askarov et al. 2006). In their treatment, the failures are invisible \n the executions where an operation is about to fail just get stuck and do not contribute anything to \nthe .nal set of states. In our opinion this is unrealistic, as the failures are de.nitely visible in \nthe real world. In Fig. 1, M is a memory a mapping from variables to values. We see that .a is non-deterministic \n the key generations and encryptions may have several possible values. Compared to the treatment of Askarov \net al. (2006), we have made a simpli.cation they let the program state also to contain the stream of \nyet-to\u00adbe-generated keys and the operation newkey takes and returns the .rst element of that stream (this \ndetail turns out to be important in the security de.nition, we will discuss it in Sec. 5). Having de.ned \nthe abstract semantics of expressions .a we now de.ne the transition relation of the abstract small-step \nstructural op\u00ad a erational semantics -. of the programming language. The relation a -. relates program \ncon.gurations (M, P ) to program con.gura\u00ad a tions or memories. The de.nition of -. is completely standard \n(Nielson and Nielson 1992, Chap. 2.2) and is omitted. But note that the non-determinism of .a also causes \nthe non-determinism of aa a -.. We also de.ne (M, P ) =.M if M = {M' |(M, P ) -. * M'}. On the concrete \n/ computational side, the non-deterministic constructs are replaced by probabilistic ones. We de.ne .c, \nrelating an expression e to the probability distribution of its values; c the transition relation -. \nof the concrete small-step structural operational semantics, relating a program con.guration (M, P ) \nto a probability distribution D over memories or to a pair (D, P '). c (these straightforward de.nitions \nare omitted) Given -. we can de.ne the probability of a sequence (M0,P0).(M1,P1). \u00b7\u00b7\u00b7. (Mn-1,Pn-1). Mn \nas the product of the probabilities p1,...,pn where pi is the probability of Mi in the distribution Di \nc and Di is given by (Mi-1,Pi-1) -. (Di,Pi) (for 1 = i = n-1) cc or (Mn-1,Pn-1) -. Dn. Finally we de.ne \n(M, P ) =. D relating the initial program memory M and the program P to the probability distribution \nD over .nal program memories. Here the probability assigned by D to some memory M ' is the sum of probabilities \nof all sequences (M, P ) . \u00b7 \u00b7\u00b7 . M '. The mapping D is indeed a probability distribution (i.e. all probabilities \nassigned by it sum up to 1) because we have disallowed the non-termination of P . 3. Security de.nition \nLet VarS, VarP . Var be the sets of initial secret and .nal public variables we want the adversary that \nlearns the .nal values of the variables in VarP to be unable to deduce anything it did not know before \nabout the initial values of the variables in VarS. We demand VarS n VarP = \u00d8, but not VarS . VarP = Var \n there may be auxiliary variables that do belong to neither VarS nor VarP. We demand that the program \ndoes not use the initial values of such auxiliary variables. To give the de.nition of non-interference \nin the abstract setting, Askarov et al. (2006) .rst de.ned when two cryptotexts look the same . For bit-strings \ny1,y2 they de.ned y1 = E y2 if there exist such r, k1,k2,x1,x2, such that y1 = E(r; k1,x1) and y2 = E(r; \nk2,x2). Here the argument r denotes the choice of the random coins for the algorithm E. I.e. y1 = E y2 \nif they could be ciphertexts generated with the same random coins (initial vectors). This relaxed equality \nis applied only to ciphertexts. To use it for the values of program variables we have to .x which of \nthose variables contain ciphertexts. Hence let VarE . VarP be the public variables that are assumed to \ncontain ciphertexts. For program memories M1 and M2 we de.ne the low-equivalence of M1 and M2, denoted \nM1 ~P M2, if M1(x)= M2(x) for all x . VarP\\VarE and M1(x)=E M2(x) for all x . VarE. Askarov et al. (2006) \nde.ne a program P to be non-interfering if for all program memories M1,M2, such that M1 ~P M2 and a for \nall memories M1' , such that (M1,P ) -. * M1 ' there exists a a ' ''' memory M2, such that (M2,P ) -. \n* M2 and M1 ~P M2. This de.nition gives us the standard nondeterministic non-interference, only the de.nition \nof equality for values has been changed. In the computational setting, the non-interference is de.ned \nas the computational independence of secret inputs and public outputs. To de.ne the asymptotic computational \nnotions we need a security parameter n relative to which the asymptotics are taken. Hence let the semantics \nof the operations be parametrized by this security parameter and let their running time be polynomial \nwith respect to this parameter. In particular, the algorithms K, E and D take the security parameter \nas an extra argument. The semantic cc relations .c , -. and =. are thus parametrized with n, too. Let \nD be the probability distribution of initial memories for the program P ; the adversary knows this distribution. \nActually, because of the security parameter, D = {Dn}n.N is a family of probability distributions over \nprogram memories. The program P is computationally non-interferent with respect to D (Laud 2003) if the \nfamilies of probability distributions (parametrized by n) c {|(M|VarS ,T |VarP ) | M . Dn, (M, P ) =.n \nD, T . D |} and '' c {|(M |VarS ,T |VarP ) | M, M . Dn, (M, P ) =.n D, T . D |} are computationally \nindistinguishable. Here {|E | C|} denotes the distribution of the random expression E under the conditions \nC. The notation M . Dn means that the random variable is dis\u00adtributed according to Dn. Hence the .rst \nof the above distributions is that of the initial values of the secret variables and .nal values of the \npublic variables, where the initial memory M is sampled ac\u00adcording to Dn and the .nal memory T is obtained \nby executing the program P (which is probabilistic) on M. The second of the above distributions is that \nof the same values of the same variables, but here the initial memory M ' and the .nal memory T correspond \nto different runs (the initial memories M and M ' are sampled inde\u00adpendently of each other). Two families \nof probability distributions D = {Dn}n.N and D ' = {D ' }n.N are computationally indis\u00ad n tinguishable \n(this is the cryptographic equivalent for being the same ) if for all probabilistic polynomial-time (PPT) \nadversaries A the difference ' Pr[A(n, x)=1 | x . Dn] - Pr[A(n, x)=1 | x . Dn] is negligible in n. Here \nA(n, x) denotes the probability distribution of the outputs of the algorithm A on the input (n, x). A \nfunction f is negligible if f is o(1/p) for any polynomial p. Our desired result We want to have a soundness \ntheorem with more or less the following wording: Let P be a program. If P satis.es certain conditions \nand the initial probability distribution D satis.es certain conditions and P is non-interferent in the \nabstract setting then P is computationally non-interferent with respect to the initial distribution D. \nHere the conditions on D should be something natural, for exam\u00adple the independence of the secret values \nfrom the public ones. The conditions on P should be veri.able in the abstract setting, other\u00adwise we \nlose the modularity of the approach. In the Sec. 5 we take a look at what these conditions could be. \nLet us call a program P well-structured if it obeys those conditions. In the following we often have \nto speak about the public part of the result of some computation. For a memory M we thus de.ne MP as \nthe restriction of M to VarP. For a set of memories M we de.ne MP = {MP | M . M}. For a probability distribution \nD over memories we have to collapse all memories with the same public part we de.ne DP(M\u00af)= P \u00afD(M). \nM:MP=M 4. Security of encryption systems So far we have only de.ned the functionality of an encryption \nsys\u00adtem, but not its security. This de.nition is necessary when arguing about the security of information \n.ow. Obviously, we require that our encryption system hides the contents of plaintexts. To simplify our \narguments in the rest of the paper we also want the length of the plaintext to be hidden. We still need \nmore the encryption must also hide the identities of plaintexts. This means that it must be im\u00adpossible \nto determine whether two ciphertexts were generated using the same key or different keys. The programs \nin our programming language are able to decrypt, too, hence we also need to protect the integrity of \nencrypted messages. We do not want to put many con\u00adstraints on the programs, hence the security properties \nmust hold even if the keys are treated quite arbitrarily (short of leaking them). In particular, it must \nbe possible to treat the keys as parts of plain\u00adtexts, too. The details are given below. There we also \ndiscuss the existence of such encryption systems. Against passive attacks, the most common security de.nition \nis the indistinguishability under chosen plaintext attacks (IND-CPA security) (Bellare et al. 1997). \nIt states that there exists no PPT adversary A (that has access to an oracle), such that the difference \nof probabilities Pr[AEn(k,\u00b7)(n)=1 | k .Kn()]- Pr[AEn(k,0|\u00b7|) (n)=1 | k .Kn()] is non-negligible. This \nde.nition is a typical instance of security de.nitions of cryptographic primitives and systems where \nthe in\u00addistinguishability of the real functionality from the ideal func\u00adtionality is required. Here the \nreal functionality is the encryption functionality given a plaintext it returns a corresponding cipher\u00adtext. \nThe ideal functionality also returns a ciphertext, but this ci\u00adphertext is generated without actually \nusing the plaintext (except its length). In the de.nition of =E, ciphertexts created with different keys \nmay also be considered equal. Hence we need the encryption sys\u00adtem to hide the identities of keys (Abadi \nand Rogaway 2000) as well: for no PPT adversary A, the following difference may be non\u00adnegligible: ,\u00b7)' \nPr[AEn(k,\u00b7),En(k'(n)=1 | k, k .Kn()]- Pr[AEn(k,\u00b7),En(k,\u00b7)(n)=1 | k .Kn()] . Our security proofs in this \npaper will be simpler if we do not state that in the ideal functionality all keys are the same, but state \nthat in the ideal functionality all keys are different. We also give the adversary the possibility to \nchoose among several encryption oracles, not just two (in the de.nition of IND-CPA, the adversary could \nalso be allowed to access several encrypting oracles simulta\u00adneously). Let O be an oracle that works \nas follows: At the initialization (or before it answers its very .rst query) it independently generates \nthe keys ki using the algorithm Kn for all i . N. Actually, the keys ki are not all generated in the \nbeginning of the run, but only right before they are .rst used.  When queried with (i, x) the machine \nO returns En(ki,x).  Let O ' be an oracle that on query (i, x) generates a new key k, encrypts x with \nit and returns the result. An encryption system hides the identities of the keys if and only if no PPT \nadversary is able to distinguish the oracles O and O ' with non-negligible advantage. The non-interference \nde.nition in the abstract model does not attempt to rule out key cycles (Abadi and Rogaway 2000) in any \nway. A key cycle of length 1 occurs when a key k (or a message where k may be obtained from) is used \nas a plaintext in encryption with k. In a longer key cycle, the key k1 is encrypted with k2, the key \nk2 is encrypted with k3, etc., until the key kn is encrypted again with k1. In such scenarios we can \n.nd no real functionality, as given in the de.nition of IND-CPA, that can be replaced with the ideal \none. Therefore the de.nition of IND-CPA does not say anything about the security of such usage of keys. \nSuch usage of keys is certainly possible in programs. Also, = E will have no problem relating ciphertexts \nwhose plain\u00adtexts are of obviously different lengths. It may make sense to re.ne = E so that the lengths \nof plaintexts were discriminated, but the issue of concealing the lengths is orthogonal to other issues \nin se\u00adcure information .ow. Hence the current choice should be consid\u00adered reasonable. A strengthening \nof the de.nition of IND-CPA to key-dependent messages (Black et al. 2002) that also conceals the lengths \nof the plaintexts and the identities of the keys can be given as follows. Let O be an oracle that works \nas follows At the initialization it independently generates the keys ki using the algorithm Kn for all \ni . N. Actually, the keys ki are not all generated in the beginning of the run, but only right before \nthey are .rst used. . .  O accepts queries of the form (i, e) where i . N and e is an expression in \nsome Turing-complete language whose running time is polynomial in n (we may also state that the query \ncon\u00ad  tains the maximum running time of e as well). The expression e may contain free variables kj . \nWhen queried with (i, e), the machine O evaluates e, substitut\u00ading the values of the keys kj to the free \nvariables kj of e. It then encrypts the result with the key ki and returns it. Let O ' be an oracle that \non each query generates a new key and re\u00adturns the encryption of a .xed constant with this key. The encryp\u00adtion \nsystem (K, E, D) is IND-CPA-secure, which-key concealing and length-concealing in presence of key-dependent \nmessages if no PPT adversary A can distinguish O from O ', i.e. the difference of probabilities Pr[AO(\u00b7)(n)] \n- Pr[AO'(\u00b7)(n)] must be negligible for all PPT A. The properties considered above only deal with con.dentiality \nof messages, and only with encryption. They do not state anything about what happens if the decryption \nalgorithm is invoked (the de.nition of encryption systems states that the decryption of a correctly constructed \nciphertext must give back the corresponding plaintext, but does not state anything about decrypting other \nbit\u00adstrings). The property that we are going to need is plaintext integrity (INT-PTXT) (Bellare and Namprempre \n2000) stating that no PPT adversary A that is given access to the encryption oracle E(k, \u00b7) (where k \nis generated using the key generation algorithm) is able (with non-negligible probability) to output \na ciphertext c, such that D(k, c)= p = . and A had not queried the encryption oracle with p before. Askarov \net al. (2006) argue that if the encryption system has plaintext integrity then D(k, E(k ' ,x)) results \nin error almost always (i.e. the opposite has only negligible probability). Here x is any plaintext and \nk, k ' are two keys that are independent of each other. The above de.nition of INT-PTXT does not allow \nencryption cycles, either. We will turn the given de.nition into one that allows key-dependent messages \nin the same way as was done for the de.\u00adnition of IND-CPA. First, we give the adversary access to multiple \nencryption oracles E(k1, \u00b7), E(k2, \u00b7),... where the keys ki are in\u00addependently generated. Such access \nis equivalent to the access to an oracle O that on query (i, x) returns E(ki,x). After interacting with \nthe oracle O, the adversary outputs a pair (i, c) and wins if D(ki,c)= p = . and the adversary did not \nquery O with (i, p) before. The modi.cation of INT-PTXT we have done so far (re\u00adplacing a single key \nk with multiple keys k1,k2,...) has not been substantial the modi.ed de.nition can be proved equivalent \nto the original de.nition by a standard hybrid argument (Goldreich 2001, Chap. 3.2.3). We will now modify \nthe de.nition by allow\u00ading key-dependent messages as well in the query (i, x) to O the component x is \nnot just a bit-string but an expression for computing the bit-string to be encrypted. As before, x may \ncontain free vari\u00adables k1,k2,..., these are substituted with the values of the keys k1,k2,... that have \nbeen generated by O. Existence. It is not known how to construct encryption systems that are secure in \nthe presence of key-dependent messages, as long as the construction is in the plain model i.e. assumes \nonly the existence of one-way functions. Black et al. (2002) give a con\u00adstruction for IND-CPA-secure \n(with key-dependent messages) en\u00adcryption system in the random oracle model (Bellare and Rogaway 1993). \nThis model assumes the existence of a globally .xed ran\u00addom function H : {0, 1} * .{0, 1}. that all parties \n(including the adversary, and the expressions it sends to its oracle(s)) can access (in practice, H is \nreplaced by some (function based on some) cryp\u00adtographic hash function). The distribution of H is such \nthat all bits in its image are distributed fairly and independently of each other. In the encryption \nsystem by Black et al. (2002), the key generation algorithm just returns an n-bit random string (where \nn is the se\u00adcurity parameter). The encryption algorithm En(k, x) generates an n-bit random string r and \nreturns (r, H|x|(klr) . x) where l de\u00adnotes the concatenation of bit-strings and He returns the .rst \ne bits of H. Black et al. (2002) show this system to be IND-CPA-secure. A slight modi.cation of their \nproof is suf.cient to show that this encryption system also conceals the identities of the keys. This \nen\u00adcryption system obviously does not hide the length of the plaintext, padding has to be used for that. \nBellare and Namprempre (2000) show how to use message au\u00adthentication codes (MACs) to provide plaintext \n(and ciphertext) in\u00adtegrity for encryption systems. A MAC consists of three algorithms key generation \nalgorithm, tagging algorithm (taking the key and the message as inputs) and veri.cation algorithm (taking \nthe key, the message and the alleged tag as inputs). The tagging algorithm may be deterministic in which \ncase the veri.cation algorithm sim\u00adply has to recompute it. A MAC is weakly unforgeable (WUF), if no \nPPT adversary with the access to tagging and veri.cation algo\u00adrithms (as oracles) can produce a message \nand a valid tag, such that the message had not been submitted to the tagging oracle before that. Bellare \nand Namprempre (2000) prove that a compound en\u00adcryption system where a message is .rst tagged with a \nweakly un\u00adforgeable MAC and then encrypted with an IND-CPA-secure cryp\u00adtosystem (using different keys) \nprovides plaintext integrity. As the encryption operation is the last step in the construction, the con\u00adstruction \nalso preserves the concealing of key identities. We can modify the de.nition of weak unforgeability to \nalso al\u00adlow key-dependent messages (the adversary can then submit ex\u00adpressions, not just messages to \nthe tagging and veri.cation oracles). The proof by Bellare and Namprempre (2000) can then be modi\u00ad.ed, \nshowing that if the construction is made using primitives that are secure in the presence of key-dependent \nmessages then the re\u00adsulting encryption system is INT-PTXT-secure also even with key\u00addependent messages. \nA WUF-secure (with key-dependent messages) MAC is easy to construct in the random oracle model. Let the \nkey generation algo\u00adrithm return a random n-bit string and let the tag of the message x with the key \nk be the .rst n bits of H(klx). In this way the tags of the messages are really just random bit-strings \nthat do not reveal anything about k. 5. Non-well-structured programs In this section we give some examples \nof programs that are secure in the abstract setting, but possibly insecure in the computational setting. \nWe then explain what patterns in programs have to be excluded to make sure that the soundness theorem \nwould not apply to this or analogous programs. 5.1 Bad keys The program k := s; p := enc(k, s) where \nVarS = {s} and VarP = VarE = {p}, is secure in the abstract setting. In the computational setting we \ndo not know whether k is a good key. Hence we do not know whether E(s, s) suf.ciently hides s or not. \nWe cannot use the security de.nitions of encryption systems to argue about the computational security \nof this program. The conditions we put on programs must make sure that only keys generated with the operation \nnewkey can be used as keys in encryption operations. 5.2 Constructing ciphertexts Similarly to using \nonly good keys when encrypting we must use only good ciphertexts when applying the relaxed equivalence \n=E on them. 5.3 Publishing keys Consider the following program k := newkey; p := enc(k, s) where VarS \n= {s}, VarP = {k, p} and VarE = {p}. Accord\u00ading to the possibilistic non-interference de.nition, this \nprogram is secure. Indeed, an initial memory {s . vs} is transformed to the .nal memories where the value \nof k is just a key and the part of the value of p that matters for the relation =E is just a random initial \nvector. Hence the public part of the set of .nal memories does not depend on the initial secret. On the \nother hand we would certainly want to consider the preceding program secure if the set of public variables \nVarP would have consisted of just the variable p. To avoid considering such programs secure we must make \nsure that the keys cannot become public. This includes using these keys in computations (other than encryption \nand possibly decryption), such that the results of those computations become public. Askarov et al. (2006) \nactually consider the previous program to be insecure because the program state also contains the values \nof all yet-to-be-generated keys; these values are treated as high-security inputs. Hence one cannot publish \nkeys or anything that depends on them (except when used in encryption). 5.4 Possibilistic vs. probabilistic \nsecurity The following well-known example (McLean 1990) shows that the possibilistic non-interference \ndoes not always imply probabilistic (and similarly computational) non-interference. x := rnd(0, 1); if \nx then l := h else l := rnd(1, 100) where rnd(a, b) returns a uniformly chosen random integer be\u00adtween \na and b, l . VarP, h . VarS and it is known that the value of h is between 1 and 100. In the possibilistic \nsetting the se\u00admantics of rnd(a, b) is nondeterministic, we have rnd(a, b) .a c for all c where a = c \n= b. In the possibilistic setting, the above program is secure because the set of possible .nal values \nof l does not depend on the value of h. In the probabilistic setting it is insecure because the most \nprob\u00adable .nal value of l is equal to the value of h. In our programming language, we can implement rnd \n(or something close to it) by using the probabilistic operation enc. For certain constructions of secure \nencryption systems, the output of E is indistinguishable from a uni\u00adformly distributed bit-string. To \navoid considering the previous program, we must disallow computations with ciphertexts. The ciphertexts \nmay be published, included in pairs, encrypted or decrypted, but their actual value may not be used in \ncomputations. 5.5 Non-failure of bad decryptions Consider the following program: k := newkey; k ' := \nnewkey; x := enc(k, C); y := dec(k ' ,x); if y = . then l := h else l := 1 - h where C is some constant, \nVarP = {l}, VarS = {h} and the possible values of h are 0 and 1. In the concrete (probabilistic) setting, \nthe program is insecure because the then-branch is taken with overwhelming probability. The model of \ncryptographically masked .ows (Askarov et al. 2006) makes the assumption that the decryption with the \nwrong key always fails. I.e. if k = k ' then dec(k ' , enc(k, x)) returns . with probability equal to \n1, and not to 1 - a for some negligible a. Under that assumption the above program is insecure, too, \nbecause the else-branch is never taken. However, it is not clear whether there exist (even in the random \noracle model) encryption systems with such a property, that also satisfy other properties we stated in \nSec. 4, in particular hiding the identity of keys. If we drop the requirement that the decryption with \nthe wrong key always fails (i.e. dec(k ' , enc(k, x)) returns . with probability of only 1 - a) then, \nin the possibilistic setting, it is actually possible to take the else-branch in the above program, which \nis then de.ned as secure. Note that this particular program is actually insecure by the de.nitions given \nby Askarov et al. (2006) even if we drop the requirement that the decryption with a wrong key always \nfails, because at the failure of the decryption the execution becomes stuck and hence the then-branch \nis unreachable. But then we could just replace the predicate y = . with some other predicate P that is \nsatis.ed by some of the possible values of y and not satis.ed by others. Both branches would then still \nbe reachable in the abstract semantics, but in the concrete semantics the branch corresponding to the \nvalue of P (.) would be chosen most of the time. There is also a negligible chance that the two key generations \nin the considered program return the same key. If this happens then the value of h can also be deduced \nfrom the value of l because the else-branch is always taken. We do not have a good remedy against cases \nlike this where the abstract semantics considers the events that happen only neg\u00adligibly often in the \nconcrete semantics as equals to the events that happen almost always in the concrete semantics. We thus \nresort to modifying the abstract semantics, such that two key genera\u00adtions cannot produce equal keys, \nand the decryption of a cipher\u00adtext is possible only with the key that was used in creating it. We change \nthe de.nition of .a, it is now a relation of the form (M, K.,C.,e).a (v, K ,C ) where M is the memory, \ne the evaluated expression and v its value. Additionally, K. and K are the sets of generated keys before \nand after the evaluation of e, and C./C is the set of triples (c, k, p) of ciphertexts, keys and plain\u00adtexts, \nsuch that c has been generated by encrypting p with k during the course of the program. The de.nition \nof .a for particular ex\u00adpressions is changed as follows: For key generations, we have the side condition \nthat the newly generated key v is not a member of K.. The set K is then de.ned as K. .{v} (for all other \noperations, K = K.).  For encryptions, the generated ciphertext may not yet be a ciphertext in the set \nC.. The triple of the newly generated ciphertext, key and plaintext is added to C along with the rest \nof C. (for all other operations, C = C.).  The decryption operation dec(k, c) .rst computes the plaintext \nvp = D(M(k),M(c)). It then checks whether (vc,M(k),vp) belongs to C. for some value vc. If this is the \ncase then dec(k, c) returns vp, otherwise it returns ..  The sets K and C are also added to program \ncon.gurations. 6. Well-structured programs To satisfy the necessary constraints demonstrated by the programs \nin the previous section, it is suf.cient to require that all operations that the program (in the abstract \nsemantics) performs are well\u00adtyped. Here the types t . T are de.ned by the following grammar: t ::= int \n| key | enc(t ) | (t, t), and the operations of the program expect and produce the values of the following \ntypes: arithmetic operations (of arity k): intk . int;  key generation: key;  encryption: key \u00d7 t \n. enc(t);  decryption: key \u00d7 enc(t) . t ;  M(x)= v G(x)= t (M, G, K, C, x).a (v, t, K, C) (M, G,Ki-1,Ci-1,ei).a \n(vi, int,Ki,Ci) [ o]](v1,...,vk)= v (M, G,K0,C0,o(e1,...,ek)).a (v, int,Kk,Ck) (M, G,Ki-1,Ci-1,ei).a \n(vi,ti,Ki,Ci) .(v1,v2)= v (M, G,K0,C0, (e1,e2)).a (v, (t1,t2),K2,C2) (M, G,K.,C.,e).a (u, (t1,t2),K ,C \n) .(v1,v2)= u (M, G,K.,C.,pi(e)).a (vi,ti,K ,C ) (M, G,K.,C.,e).a (u, (t1,t2),K ,C ) u . Dom . (M, G,K.,C.,pi(e)).a \n(.,ti,K ,C ) `\u00b4 v . Supp K() \\K (M, G, K, C, newkey).a (v, key,K .{v},C) (M, G,K0,C0,ek).a (vk, key,K1,C1)(M, \nG,K1,C1,ex).a (vx,t,K2,C2) `\u00b4 vy . Supp E(vk,vx) \\p1(C2) C3 = C2 .{(vy,vk,vx)} (M, G,K0,C0, enc(ek,ex)).a \n(vy, enc(t ),K2,C3) (M, G,K0,C0,ek).a (vk, key,K1,C1) (M, G,K1,C1,ey).a (vy, enc(t ),K2,C2) vp = D(vk,vy) \nv = if (vk,vp) . p2,3(C2) then vp else . (M, G,K0,C0, dec(ek,ey)).a (v, t, K2,C2) where pi1,...,ik (C) \ndenotes {(ui1 ,...,uik ) | (u1,u2,u3) . C} Figure 2. Extended .a pairing: t1 \u00d7 t2 . (t1,t2);  projections: \n(t1,t2) . ti.  Also, the guards of the branching statements must have the type int, the secret inputs \n(i.e. the initial values of the variables in VarS) must also have the type int, .nal values of the variables \nin VarE must have types of the form enc(t ), and .nal values of the variables in VarP may not have a \ntype that has a component key (de.ne that the only component of the types int, key and enc(t) is that \ntype itself, and the components of the type (t1,t2) are the components of t1 and t2). The previous paragraph \nspoke about the types of values, not variables. Indeed, we can allow the typing to be dynamic, extend\u00ading \nthe memories with the information about the current types of variables. This dynamic typing disallows \nthe usage of non-keys as keys and the usage of actual values of keys (excluding encryption and decryption) \nand ciphertexts. To formalize this typing we again extend the de.nition of .a: it is now a set of judgements \nof the form (M, G,K.,C.,e).a (v, t, K ,C ), where G is a mapping from variables to types and t is the \ntype of v. The modi.ed .a, also covering the modi.cations of Sec. 5.5, is given in Fig. 2. The typing \nG is also added to program con.gurations; the type G(x) is updated whenever x is assigned to. The extended \nabstract semantics is given in Fig. 3. We call a program well-structured if its execution according to \nthe abstract semantics never gets stuck, i.e. no such con.guration is reachable where there is still \na program P , but no outgoing transitions. Also, a well-structured program must satisfy the constraints \non the .nal types of variables, as stated above (for variables in VarP, the type may not be key, and \nfor variables in VarE, the type must be enc(t ) for some t ). The type system still allows us to perform \ncryptographic opera\u00adtions quite freely, as long as they are not combined with operations (M, G,K.,C.,e).a \n(v, t, K ,C ) a (M, G,K.,C.,x := e) -. (M[x . v], G[x . t ],K ,C ) a (M, G, K, C, skip) -. (M, G, K, \nC) a (M, G, K, C, P1) -. (M ' , G ' ,K ' ,C ' ) a ' '' (M, G, K, C, P1; P2) -. (M, G ' ,K ,C ,P2) a (M, \nG, K, C, P1) -. (M ' , G ' ,K ' ,C ' ,P 1' ) a ' ''' (M, G, K, C, P1; P2) -. (M, G ' ,K ,C ,P 1; P2) \n(M, G,K.,C.,e).a (b, int,K ,C ) b .{0, 1} a (M, G,K.,C., if e then P1 else P0) -. (M, G,K ,C ,Pi) a (M, \nG, K, C, while e do P ) -. (M, G, K, C, if e then (P ; while e do P ) else skip) a Figure 3. Instrumented \nsemantics -. that make use of the actual value of a key or a ciphertext. We are allowed to copy keys \nand ciphertexts from one variable to an\u00adother, as well as to encrypt keys and ciphertexts (or pairs containing \na key or a ciphertext as a component). Among the restrictions the inability to use the actual value of \na ciphertext is the most signi.\u00adcant one, but likely unavoidable, because of Sec. 5.4 (otherwise our \nabstract semantics has to be probabilistic as well). Also, Sec. 5.3 prohibits us making public the values \nof the keys, hence our type system must ensure that the keys do not end up as values of type int. LEMMA \n1. Let P be a well-structured program and M a memory. a Let (M, G, K, C, P ) -. (M ' , G ' ,K ' ,C ' \n,P ' ). Then P ' is well\u00adstructured, too. PROOF. Well-structuredness of a program implies the well-struct\u00aduredness \nof all of its subprograms. Consider the de.nition of a -.. According to it, P ' is either a subprogram \nof P , or P ' = P '' ; while b do P '', such that P = while b do P ''. In the last case P '' and while \nb do P '' are well-structured with respect to the same typing, and their sequential composition admits \nthe same typing as well. D We can now state the main result of this paper: THEOREM 2. If a well-structured \nprogram P that does not as\u00adsign to variables in VarS and does not use the initial values of the variables \nwith types different from int has possibilistic non\u00adinterference then it has probabilistic non-interference \nfor all fami\u00adlies of probability distributions D over initial memories where the variables in VarS are \nindependent of the rest of the variables. We see that the conditions on P , besides the well-structuredness, \nare not signi.cant. They can be worked around by adding more variables to P . 7. Security proof Here \nwe will sketch the proof of Theorem 2. We are going to perform the standard steps in reasoning about \nprograms that con\u00adtain cryptographic operations we replace the parts of the pro\u00adgram that correspond \nto the real functionality of the cryptographic primitives with the code that corresponds to the ideal \nfunctionality (Sec. 7.1). The modi.cation will transform the program P to some program P , thereby also \nchanging both the abstract and the con\u00adcrete semantics of the program. The concrete semantics will change \nonly indistinguishably. We will compare the abstract execution of P with the concrete execution of P \nand conclude that they run in lock-step, producing similar structures of .nal states (Sec. 7.2). In particular, \nwe will show that for each M, the set of abstract .nal states M, where (M, P ) =.Ma , determines the \ndistribution D, c where (M, P ) =. D. If the program P has secure information .ow in the abstract setting \nthen the program P is probabilistically non-interferent1. The concrete semantics of P is indistinguishable \nfrom the semantics of P for an adversary that does not see the keys generated by the programs, hence \nP is computationally non\u00adinterferent. 7.1 Program modi.cations We would like to apply the de.nition of \nIND-CPA (including the concealing of key identities and plaintext lengths, and security in presence of \nkey-dependent messages), thereby changing the ex\u00adpressions enc(k, y) to expressions enc(newkey, 0). But \nwe cannot apply this transformation right away in the de.nition of IND-CPA the encryption keys may only \nbe used in encryption opera\u00adtions (and they may also be used in arbitrary manner to create the plaintexts \nthat are encrypted), but in our program they may also be used in decryption operations. We have to apply \nthe de.nition of INT-PTXT .rst. The well-structuredness of programs ensures that we only at\u00adtempt to \ndecrypt valid ciphertexts. We are not ensured that the key used for decryption is the right one. The \nplaintext integrity of the used encryption system guarantees that if the used key is not the correct \none then the decryption almost always fails in the con\u00adcrete semantics. The modi.cations made to the \nabstract semantics in Sec. 5.5 also ensure this for the abstract semantics. We can mod\u00adify the program \nso that we record the plaintext of each ciphertext, as well as (the identity of) the key used to create \nit, and replace the decryption with the return of the plaintext if the comparison of key identities succeeds. \nThis modi.cation does not change the abstract semantics of a program and changes its concrete semantics \nonly indistinguishably. Let P0 be the original program. We perform the following pro\u00adgram modi.cations. \nTo simplify the presentation we assume that there are no nested expressions, i.e. in each statement x \n:= e in the program the expression e contains just a single operation. We also assume that all guard \nexpressions in if -and while-statements are just variables. First, we introduce a new variable idk of \ntype int for producing key names and prepend the program with the initial\u00adization idk := 0. Then we rewrite \nall assignments and branches according to Table 1. We see that in the modi.ed program all variables contain \npairs whose .rst component is the original value of the variable. The second component records the auxiliary \ninformation for eliminat\u00ading decryptions: for keys, we record their identity;  for ciphertexts, we \nrecord the identity of the key and the plain\u00adtext with associated auxiliary information;  for pairs, \nwe record the auxiliary information of both compo\u00adnents;  we do not record anything for integers, but \nstill keep the second component to avoid special cases in Table 1.  To .nish the execution of the program \nwith the same values of vari\u00adables in VarP as before we append to the program the statements 1 The security \nof P is even information-theoretic (Sabelfeld and Sands 1999, Sec. 5), not just computational before \nafter x := y x := y x := o(x1, . . . , xk) x := (o(p1(x1), . . . , p1(xk)), 0) x := newkey idk := idk \n+ 1; x := (newkey, idk) x := enc(k, y) x := (enc(p1(k), p1(y)), (p2(k), y)) y := dec(k, x) if p1(p2(x)) \n= p2(k) then p2(p2(x)) else . x := (y, z) x := ((p1(y), p1(z)), (p2(y), p2(z))) y := pi(x) y := (pi(p1(x)), \npi(p2(x))) if b . . . / while b . . . if p1(b) . . . / while p1(b) . . . Table 1. Removing decryption \noperations x := p1(x) for all x . VarP. We also must introduce the sec\u00adond component to all initial values \nof the variables. For all vari\u00adables x whose initial values are used by the program we prepend x := (x, \n0) to the program (By Thm. 2, all those variables have the initial type int). Let P be the resulting \nprogram. Let P ' be the program P without the .nal statements x := p1(x) for x . VarP. LEMMA 3. If P0 \nis a well-structured program then so is P . More\u00adover, for each initial state the .nal typings G and \nG ' of P0 and P ' are such, that G ' (x) = (G(x),...) for all x . Var. We have introduced the relation \n= E on values two typed values are related by = E if they are equal or if they are both ciphertexts \nand have the same initial vector. We now de.ne a more relaxed version of it: we say that v = EK v ' if \nv = E v ' or both v and v ' are keys. LEMMA 4. Let M0 be an initial state. If (M0, .x.int, \u00d8, \u00d8,P0) =.a \nM and (M0, .x.int, \u00d8, \u00d8,P ' ) =a.M ' then for all M .M there exists some M ' .M ', and for all M ' .M \n' there exists some M .M, such that M(x)=EK M ' (p1(x)). The preceding two lemmas can be proved by constructing \na (weak) bisimulation between the program con.gurations of P0 and a P '. The transition relation is -. \nin both cases. A con.guration of P0 is related to a con.guration of P ', if the programs correspond \nto each other;  the values and types of variables in the con.guration of P0 are related by =EK to the \n.rst components of the values and types of variables in the con.guration of P ' ;  the key identities \nand recorded plaintexts in the con.guration of P ' correspond to the recorded ciphertext-key-plaintext \ntriples in the con.guration of P0.  For the concrete semantics we can show the following result. LEMMA \n5. Let O1 [resp. O2] be the following oracle. On input of an initial memory M and the security parameter \nn, it executes the program P0 [resp. P ] on it (using n as the parameter for the algorithms K, E and \nD) and returns the public part of the .nal memory. Then no PPT algorithm A can distinguish with non\u00adnegligible \nadvantage (in n) whether it interacts with O1 or O2. Indeed, plaintext integrity of the encryption system \nensures that the decryption of a ciphertext with a wrong key returns .. The proof is again formalized \nby constructing a weak bisimulation be\u00adtween the program con.gurations of P0 and P '. The transition \nre\u00ad c lation is -. in both cases. The bisimulation relation is similar to the proof of Lemma 4. But this \ntime, the bisimulation is probabilis\u00ad c tic, because the transition relation -. is. Also, the bisimulation \nis with error sets (Backes et al. 2003) two traces have to be similar only until one of them has reached \na state from a certain error set. In our case the error sets correspond to situations where a cipher\u00adtext \ncan be decrypted by a key different from the one used to create it. Such situation arises with only a \nnegligible probability. From a well-structured program P0 we have now constructed a program P that is \nalso well-structured and that is secure in the abstract or concrete setting iff the program P0 is secure. \nAlso, the program P contains no decryption operations. Hence it suf.ces to prove Theorem 2 only for programs \nthat contain no decryptions; this, together with the given construction of the program P from the program \nP0 immediately implies Theorem 2 in its full generality. If a program P contains no decryptions then \nwe can apply the de.nition of IND-CPA-security (the strongest of them in Sec. 4) of the encryption system \nand replace all expressions enc(k, y) in P with the expression enc(newkey, 0). Let P be the resulting \nprogram. The concrete semantices of P and P are indistinguishable a result similar to Lemma 5 can be \nproved for P and P . 7.2 Similarity of executions In this subsection we will show that the abstract \nexecution of P and the concrete execution of P proceed in some sense in lock-step. Whenever we talk about \nthe concrete semantics of the program P in this subsection, the security parameter is implicit. We are \ngoing to establish the probabilistic non-interference of P without any quali.ers about the power of the \nadversaries (i.e. the advantage of any adversary is the constant function 0), hence an explicit security \nparameter would just clutter the notation. We start by noting the following: LEMMA 6. Let M be an initial \nmemory and consider an execution C0aaa -. C1 -. \u00b7 \u00b7\u00b7 -. Cf where C0 is the initial con.guration (M, .x.int, \n\u00d8, \u00d8,P ) and Cf is a .nal con.guration. Then the path of that execution through the program P (or: the \nvalues of the guard expressions at if -and while-statements) depend only on M, not on the values of keys \nand ciphertexts generated during the execution. Indeed, the guard expressions have to have the type int, \nbut the keys and the ciphertexts have the types key and enc(t), respec\u00adtively, and there are no operations \nthat can be applied to these val\u00adues that could produce a value of type int (remember that P does not \ncontain decryptions). Similar claims about the keys and cipher\u00adtexts not affecting the control .ow of \nthe program can be made for the concrete semantics of P . Hence for an initial memory M there exists \na sequence (M0, G0,P0) . (M1, G1,P1) . \u00b7 \u00b7\u00b7 . (Mr, Gr) (1) where M0 = {M}, G0 = .x.int, P0 = P , the \nset of memories Mi contains all those memories that can be reached by executing P with the initial memory \nM for i steps, Gi is the typing of variables after these i steps and Pi is the program that is still \nleft to execute after i steps. As the path of the execution depends only on M, the typing and the remaining \nprogram are the same for all possible memories after i steps. Similarly, for the concrete semantics of \nP there exists a sequence (D0,P0).(D1,P1) . \u00b7 \u00b7\u00b7 . Dr (2) where D0 is the probability distribution that \nputs all its weight on M, P 0 = P , Di is the distribution over memories reached after i steps and P \ni is the program that is still left to execute at this point. We are going to show that P i is the program \nPi where all encryption expressions enc(k, x) are replaced with enc(newkey, 0); (Mi, Gi) uniquely determine \nDi (without referring to the ini\u00adtial memory M) the mapping from (M, G) to D will be such that if the \n, M '' public parts of the two sets M ' are equal then the , D '' public parts of the corresponding distributions \nD ' are also equal. these claims imply the probabilistic non-interference of P . But .rst we have to \nexplore the structure of the sets Mi some more. Given a typing G we consider the set of extended variables \nEVarG that contains all atomic components of the variables in Var, where atomic currently means having \ntype int, key or enc(t ) . I.e. we want to refer directly to the components of the values of variables \nwhose types are pairs. Formally, EVarG is de.ned by the following process: 1. Let EVarG := Var. 2. If \nEVarG contains some z, such that G(z)=(t1,t2) then  Let EVarG := EVarG\\{z}.{p1(z),p2(z)}; Let G := \nG[p1(z) . t1,p2(z) . t2]  Go to step 2.  3. Otherwise return EVarG. For some z . EVarG and a memory \nM whose variables are typed according to G we can also de.ne the value of z in M. LEMMA 7. Let (Mi, Gi,Pi) \nbe an element in the sequence (1). Then the following claims hold. For all extended variables z . EVarGi \nwith Gi(z)= int, the value of z is the same in all M .Mi.  There exists a partitioning .K of the set \nof all extended vari\u00ad  ables in EVarGi with type key, such that for all V . .K, z1,z2 . V and M .Mi, \nM(z1)= M(z2); for all V . .K and M1,M2 .Mi there exists M3 .Mi, such that - M3(z)= M1(z) for all z . \nV , - M3(z)=E M2(z) for all z . EVarGi \\V unless some key in M2 is equal to the keys M1(z) where z . \nV . There exists a partitioning .E of the set of all extended vari\u00ad ables in EVarGi with type enc(t), \nsuch that for all V . .E, z1,z2 . V and M .Mi, M(z1)= M(z2); for all V . .E and M1,M2 .Mi there exists \nM3 .Mi, such that - M3(z)=E M1(z) for all z . V , - M3(z)=E M2(z) for all z . EVarGi \\V unless some ciphertext \nin M2 is equal to the ciphertexts M1(z) where z . V . The preceding lemma states that at each step of \nthe computation, the values that are present in the variables of the program are the following: Integers \nwhose values are .xed.  A number of keys that may each occur several times. The pattern of copying the \nkeys is .xed. Each key takes all possible values independently of everything else. For example, it cannot \nhappen that the possible values of a key at a certain program point are only half of all possible values \nfor keys, the other half being cut away by some branch statement.  A number of ciphertexts that may \neach occur several times. The pattern of copying the ciphertexts is .xed. The initial vector of each \nciphertext takes all possible values independently of everything else. Hence the set Mi is completely \ndetermined by Gi, the values of extended variables of type int and the partitions .K and .E. The lemma \nis proved by induction over i, considering all pos\u00adsible steps that a program may make (of which there \nare just two assignment and branching). The induction base is i =0, the set M0 contains just a single \nmemory where all variables have the type int. To simplify the induction step, assume again without lessening \nof generality that the program contains no nested expressions and that all guard expressions are just \nvariables (the program P con\u00adstructed in Sec. 7.1 does not satisfy this, so we have to introduce temporary \nvariables to store intermediate results). Assume that the lemma holds for Mi. A branching step is controlled \nby a guard variable of type int which has the same value in all memories in Mi, hence Mi+1 = Mi in this \ncase. An assignment step x := e can be decomposed into two parts killing the current value of x and \nassigning a new value to x. Killing x simply removes the val\u00adues of all extended variables derived from \nit from the memory M, thereby possible reducing some sets in the partitions .K and .E. The effects of \nassigning a new value to x depend on e: if some values are just copied around (e is a variable, a pair \nor a projection) then new extended variables of type int will contain a value that is same in all memories, \nand the equivalence classes of .K and .E may be extended with new extended variables;  if e is o(x1,...,xk) \nthen the types of the variables x1,...,xk is int, their values are constant across Mi, the operation \no is deterministic, and its result is also constant;  if e is a key generation [resp. encryption] then \n{x} will be a new equivalence class in .K [resp. .E]; the possible values of x are all possible keys \n[resp. have all possible initial vectors].  Recall that P does not contain decryption operations. We \ncan now de.ne the probability distribution D[M, G] corre\u00adsponding to a set of memories and a typing satisfying \nthe conditions of Lemma 7 (hence the partitions .K and .E are de.ned). We be\u00adlieve that it is best described \ninformally, by stating how a memory M is constructed when the distribution D[M, G] is sampled. The values \nof the variables in M have the structure given by G there is the same set of extended variables as in \nthe memories in M. The extended variables of type int have the same values in M as they have in M these \nvariables were constants in M and they are constants in D[M, G]. For each equivalence class V . .K we \ngenerate a key kV using the algorithm K and assign the result to all extended variables in V . For each \nequivalence class V . .E we generate a new key k using the algorithm K and then encrypt the constant \n0 with the key k using the algorithm E; the resulting value is assigned to all extended variables in \nV . Hence the distribution D[M, G] is the Cartesian product of a one-point distribution (as\u00adsigning the \nvalues to extended variables of type int), a number of distributions K() and a number of distributions \nE(K(), 0). LEMMA 8. Let Mi, Gi and Di be de.ned as in (1) and (2). Then Di = D[Mi, Gi]. This lemma is \nagain proved by induction over i, considering the possible computation steps. We omit the proof here. \nWe have shown that if the .nal sets of memories are the same for the abstract executions from initial \nmemories M1 and M2 then the .nal distributions over memories for the concrete executions from M1 and \nM2 are the same as well. It remains to note that if just the public parts of the .nal sets of the memories \nare the same then the public parts of the .nal distributions are the same as well. The public part of \na set of memories M (together with a typing G, such that the conditions of Lemma 7 are satis.ed) consists \nof the values of all those extended variables of type int that are parts of the variables in VarP; \n the initial vectors of the ciphertexts that are the values of all those extended variables of type enc(t \n) that are parts of the variables in VarP.  The public part of a distribution D over memories is sampled \nsimply by sampling D and only taking the values of variables in VarP in the resulting distribution. The \nabstract security de.nition states precisely that modifying only the secret inputs of an initial memory \ndoes not change the public part of the resulting .nal set of memories. Computational non-interference \n(our security de.nition in the concrete setting) is a relaxation of probabilistic non-interference stating \nthat the public part of the .nal distribution may not change if only the secret inputs of the initial \nmemory change. Hence the abstract security of P implies the concrete security of P that is equivalent \nto the concrete security of P . 8. A new model In this section we give a model that is simpler but equivalent \n(and sometimes even more permissive) than the semantics and the security de.nition in the framework for \ncryptographically masked .ows, together with the constraints we gave in Sec. 6. In contrast to the presented \nabstract model, we can also publish the .nal values of keys in the new model there are no constraints \nof VarP, except that it must be disjoint with VarS. Also, the program semantics in the new model is deterministic, \nin this aspect it is simpler than the model of cryptographically masked .ows. The main components of \nthe new model, particularly the equivalence of abstract memories, are similar to the way the equivalence \nis de.ned for formal messages by Abadi and Rogaway (2000). It is even more similar to the subsequent \ndevelopment of these results by Abadi and J\u00a8urjens (2001) who were also one of the .rst to use formal \nrandomness to distinguish between different encryptions of the same message with the same key in the \nabstractions of cryptography (another early paper was (Bodei et al. 2001), but both were in.uenced by \nthe idea of confounders by Abadi (1999)). We have to rede.ne the set of values. A value v . Val is either \n. or de.ned by the following grammar: v ::= b | k(i)|{v}rk((ji) | (v1,v2) where b .{0, 1} * and i, j \n. N. The value k(i) denotes the (formal) key that is produced by the i-th invocation of newkey. Similarly, \nr(j) is the formal randomness (or: initial vector) of the j-th ciphertext. The semantices of operations \nare functions from tuples of values to values. In particular, the semantics of a normal operation o of \narity k is still given by a function from ({0, 1} * )k to {0, 1} *. If one of the arguments is not a \nbit-string, the result is .. The pairing takes two values v1 and v2 and returns (v1,v2), unless some \nof v1,v2 is ., in which case it returns ., too. The projections take the .rst or second component of \na pair; if the argument of a projection is not a pair then the result is .. The evaluation context for \nexpressions has to contain the num\u00adber nk of already generated keys and the number ne of already generated \nciphertexts; the values of nk and ne are also part of program con.gurations. The key generation operation \nnewkey returns k(nk +1) and increments nk. The encryption operation enc(k, y) expects the value of k \nbe k(i) for some i . N. It returns {vy}r(ne+1) , where vy is the value of y, and increments ne. If the \nk(i) value of k is not a formal key or if the value of y is ., it returns .. The decryption operation \nexpects two arguments of the form k(i)and {v}r(j) and returns v. k(i) Again we require that in the initial \nmemory all values are bit\u00adstrings. We de.ne the program P to have secure information .ow in our new model \nif for all memories M1,M2,M1' ,M2 ' where Mi ' is the .nal memory corresponding to the initial memory \nMi, ' ~' M1 ~P M2 implies M1 = M2. The formal equivalence ~of = memories is de.ned in the same way as \nby Abadi and Rogaway (2000). Formally, let visibles(M ) . Val be the least set such that if x . VarP \nthen M(x) . visibles(M);  if (v1,v2) . visibles(M) then vi . visibles(M);  j) if k(i). visibles(M) \nand {v}rk( i) . visibles(M) then v . visibles(M). Let keys(M)= visibles(M) n{k(i)| i . N}. Extend the \nset of values by v ::= ... | Dr(j), the value Dr(j) denotes a ciphertext generated using the formal coins \nr(j), that the adversary is unable to decrypt. Let the pattern pat(v, K) of a value v with respect to \na set of keys K be de.ned as follows: pat(., K)= . pat(b, K)= b pat(k(i), K)= k(i) pat((v1,v2), K)=(pat(v1, \nK), pat(v2, K)) pat(Dr(j), K)= Dr(j) ( {pat(v, K)}r(j) if k(i). K k(i), pat({v}rk((ji)), K)= Dr(j), if \nk(i) . K Finally de.ne pattern(M): VarP . Val by pattern(M)(x) := pat(M(x), keys(M)) . We de.ne two memories \nM1 and M2 as equivalent if pattern(M1) and pattern(M2) are a-conversions of each other. I.e. there must \nexist permutations ., . : N . N, such that if we replace each k(i)in pattern(M1) with k(.(i)) and each \nr(j) with r(.(j)), we get pattern(M2). The proof of computational soundness of the secure information \n.ow in the new model is similar to the proof of soundness of cryptographically masked .ows. Again we \nstart with the removal of decryption operations by recording the name (identity) of the key alongside \neach key we generate, and the plaintext and the identity of the key alongside each ciphertext (the change \nis given in Table 1). There will be no change in the visible abstract semantics. We can now de.ne the \ncomputational interpretation of an abstract memory a mapping from abstract memories to distri\u00adbutions \nover memories. The computational interpretation is actu\u00adally identical to the one proposed by Abadi and \nRogaway (2000); Ad ao et al. (2005). We show that the computational interpreta\u00adtion commutes with the \ncomputation steps in the abstract and con\u00adcrete semantices that the runs in the abstract and in the \ncon\u00adcrete model proceed in lock-step. Finally we use the result by Ad ao et al. (2005), stating that \nformal equivalence of memories implies the indistinguishability of the public parts of their computational \ninterpretations. Let us see some examples of secure and insecure programs ac\u00adcording to the presented \nde.nition. Consider the following program k := newkey; if h then l1 := enc(k, a); l2 := enc(k, b) else \nl2 := enc(k, a); l1 := enc(k, b) where VarS = {h} and VarP = {l1,l2}. The quantities a and b are constants. \nDepending on the initial value of h (either 0 or 1), the .nal memories of this program will be {h . 1,k \n. k(1),l1 .{a}rk((11)),l2 .{b}rk((21))} and {h . 0,k . k(1),l1 .{b}rk((21)),l2 .{a}rk((11))} . The patterns \nof the public parts are {l1 . Dr(1),l2 . Dr(2)} and {l1 . Dr(2),l2 . Dr(1)} . We see that the patterns \ndo not depend on the constants a and b. Furthermore, the .rst of them can be a-converted to the second \none by letting the permutation . of formal randomness indices map 1 to 2 and 2 to 1. Hence the considered \nprogram is secure. Consider now the following program: k := newkey; l1 := enc(k, a); if h then l2 := \nenc(k, b) else l2 := l1 with the same VarS, VarP, a and b as before. Depending on the value of h, the \n.nal memories of this program will be {h . 1,k . k(1),l1 .{a}rk((11)),l2 .{b}rk((21))} and {h . 0,k . \nk(1),l1 .{a}rk((11)),l2 .{a}rk((11))} . The patterns of the public parts are {l1 . Dr(1),l2 . Dr(2)} \nand {l1 . Dr(1),l2 . Dr(1)} . As there exists no a-conversion between these possible patterns, the program \nis not secure. Indeed, the value of h can be determined by considering the equality of l1 and l2. This \nexample (called the occlusion example) was presented by Askarov et al. (2006) as one of the motivating \nexamples for the equivalence relation =E among ciphertexts. 9. Related work Cryptographically masked \n.ows were proposed by Askarov et al. (2006) along with a type system for checking the security of infor\u00admation \n.ow. Askarov and Sabelfeld (2007) considered the release of keys in this framework, using it to provide \na mechanism for de\u00adclassi.cation. In quite general terms, the topic of this paper is secure informa\u00adtion \n.ow. A semi-recent overview of this topic is given by Sabelfeld and Myers (2003). The handling of encryption \nand publishing the ciphertexts is also closely connected to the topic of declassi.cation, a good overview \nof which is given by Sabelfeld and Sands (2005). In this paper we have searched for abstractions of cryptogra\u00adphy; \nwe have been particularly concerned with the soundness of such abstractions. The most well-known and \ncelebrated abstraction of cryptography is without doubt the Dolev-Yao model (Dolev and Yao 1983) that \nabstracts the cryptographic messages by terms in a free algebra and lists all possible means to derive \nnew messages from the known ones. The Dolev-Yao model even appears in this paper, in Sec. 8. The question \non the soundness has been unan\u00adswered for a long time, the .rst well-known results connecting it to the \ncomputational model were given by Abadi and Rogaway (2000). Abadi and Rogaway (2000) considered only \npassive adver\u00adsaries, but the soundness (for integrity properties) in the presence of active adversaries \nwas shown by Cortier and Warinschi (2005). Another, earlier soundness proof was given by Herzog (2002), \nbut this proof required plaintext aware encryption systems for which no constructions without random \noracles are known. Also, a compre\u00adhensive soundness result was established by the presentation of the \nuniversally composable cryptographic library (Backes et al. 2003) showing that minor adjustments to the \nDolev-Yao model indeed cause it to re.ect all observable properties of the computational model. Still, \nthose results about the Dolev-Yao model do not carry that easily over to cryptographically masked .ows. \nRecently, some other abstractions of the encryption function\u00adality have appeared, although the focus \nof these works has been different an information-hiding and integrity-preserving con\u00adstruction has been \nproposed and then it is shown how to implement it using cryptographic primitives. Vaughan and Zdancewic \n(2007) have proposed an information-packing primitive that declassi.es its argument from its original \nsecurity level to the lowest level, but at the same time preserves its con.dentiality and integrity as \nif it had not been declassi.ed. The packing primitive is integrated into the decentralized label model \n(Myers 1999) and implemented us\u00ading public-key encryption and signatures. Fournet and Rezk (2008) give \na sound implementation of the shared memory security model (stating which principal is allowed to read \nor write which variables) using cryptography (again, public-key encryption and signatures). The soundness \nof the implementation is shown using language\u00adbased techniques, by giving type systems for secure information \n.ow for both the source and target languages (which may be of in\u00addependent interest) and showing that \nthe translation preserves typ\u00ading. 10. Discussion This paper has demonstrated the limits of cryptographically \nmasked .ows. Some of them are quite natural (e.g. the handling of keys), but one of them in particular \nmay seem excessive, partly because the program analyses working directly on the computational se\u00admantics \n(Laud 2001, 2003; Laud and Vene 2005) do not have that limit. We are concerned about the inability to \nuse the actual val\u00adues of ciphertexts in arbitrary computations. Still, as Sec. 5.4 demonstrated, we \nlikely cannot allow the arbi\u00adtrary handling of random values (in the concrete semantics), unless these \nvalues are somehow randomly generated in the abstract se\u00admantics as well. Models where the encryption \nis replaced with ran\u00addom number generation have been considered (Smith and Alp\u00b4izar 2006) and they would \nbe quite similar to the programs that we get after performing the replacement of the real functionality \nof the en\u00adcryption primitive with the ideal functionality. If we also want to have decryption operations \nin such a model then we have to keep a table of plaintext-key-ciphertext pairs that have occurred in \nthe course of the computation, similarly to the modi.cations of the ab\u00adstract semantics in Sec. 5.5. \nThe practical value of such abstract model is strongly dependent on the available tool support. Fortu\u00adnately, \ntools for arguing about stochastic programs will suf.ce; the tools do not have to deal with the cryptographic \neffects because these have been abstracted away. 11. Acknowledgements This research has been supported \nby Estonian Science Founda\u00adtion, grant No. 6944 and by EU Integrated Project MOBIUS (contract no. IST-15905). \nWe thank the anonymous referees and Steve Zdancewic for their valuable comments, as well as Pierpaolo \nDegano for pointing out the origins of formal randomness. References Mart\u00b4in Abadi. Secrecy by Typing \nin Security Protocols. Journal of the ACM, 46(5):749 786, September 1999. Mart\u00b4in Abadi and Jan J\u00a8urjens. \nFormal Eavesdropping and Its Computa\u00adtional Interpretation. In Naoki Kobayashi and Benjamin C. Pierce, \nedi\u00adtors, Theoretical Aspects of Computer Software, 4th International Sym\u00adposium, TACS 2001, volume 2215 \nof LNCS, pages 82 94, Sendai, Japan, October 2001. Springer-Verlag. Mart\u00b4in Abadi and Phillip Rogaway. \nReconciling Two Views of Cryptog\u00adraphy (The Computational Soundness of Formal Encryption). In Jan van \nLeeuwen, Osamu Watanabe, Masami Hagiya, Peter D. Mosses, and Takayasu Ito, editors, International Conference \nIFIP TCS 2000, vol\u00adume 1872 of LNCS, pages 3 22, Sendai, Japan, August 2000. Springer-Verlag. Pedro Ad \nao, Gergei Bana, Jonathan Herzog, and Andre Scedrov. Sound\u00adness of formal encryption in the presence \nof key-cycles. In Sabrina De Capitani di Vimercati, Paul F. Syverson, and Dieter Gollmann, ed\u00aditors, \nESORICS, volume 3679 of Lecture Notes in Computer Science, pages 374 396. Springer, 2005. Johan Agat. \nTransforming out timing leaks. In POPL 2000, Proceedings of the 27th ACM SIGPLAN-SIGACT Symposium on \nPrinciples of Program\u00adming Languages, pages 40 53, Boston, Massachusetts, January 2000. ACM Press. Aslan \nAskarov and Andrei Sabelfeld. Gradual release: Unifying declassi.\u00adcation, encryption and key release \npolicies. In P.tzmann and McDaniel (2007), pages 207 221. Aslan Askarov, Daniel Hedin, and Andrei Sabelfeld. \nCryptographically-Masked .ows. In Kwangkeun Yi, editor, SAS, volume 4134 of Lecture Notes in Computer \nScience, pages 353 369. Springer, 2006. Michael Backes, Birgit P.tzmann, and Michael Waidner. A Universally \nComposable Cryptographic Library. In Proceedings of the 10th ACM Conference on Computer and Communications \nSecurity, Washington, DC, October 2003. ACM Press. Extended version available as Report 2003/015 of Cryptology \nePrint Archive. Mihir Bellare and Chanathip Namprempre. Authenticated Encryption: Relations among Notions \nand Analysis of the Generic Composition Paradigm. In Tatsuaki Okamoto, editor, Advances in Cryptology \n-ASIACRYPT 2000, 6th International Conference on the Theory and Application of Cryptology and Information \nSecurity, volume 1976 of LNCS, pages 531 545, Kyoto, Japan, December 2000. Springer-Verlag. Mihir Bellare \nand Phillip Rogaway. Random Oracles are Practical: A Paradigm for Designing Ef.cient Protocols. In CCS \n93, Proceedings of the 1st ACM Conference on Computer and Communications Security, pages 62 73, Fairfax, \nVirginia, November 1993. ACM Press. Mihir Bellare, Anand Desai, Eron Jokipii, and Phillip Rogaway. A \nCon\u00adcrete Security Treatment of Symmetric Encryption. In 38th Annual Sym\u00adposium on Foundations of Computer \nScience, pages 394 403, Miami Beach, Florida, October 1997. IEEE Computer Society Press. John Black, \nPhillip Rogaway, and Thomas Shrimpton. Encryption-scheme security in the presence of key-dependent messages. \nIn Kaisa Nyberg and Howard M. Heys, editors, Selected Areas in Cryptography, volume 2595 of Lecture Notes \nin Computer Science, pages 62 75. Springer, 2002. Chiara Bodei, Pierpaolo Degano, Flemming Nielson, and \nHanne Riis Niel\u00adson. Static analysis for secrecy and non-interference in networks of pro\u00adcesses. In Victor \nE. Malyshkin, editor, PaCT, volume 2127 of Lecture Notes in Computer Science, pages 27 41. Springer, \n2001. Veronique Cortier and Bogdan Warinschi. Computationally Sound, Auto\u00admated Proofs for Security Protocols. \nIn Shmuel Sagiv, editor, Program\u00adming Languages and Systems, 14th European Symposium on Program\u00adming, \nESOP 2005, volume 3444 of LNCS, pages 157 171, Edinburgh, UK, April 2005. Springer-Verlag. Danny Dolev \nand Andrew C. Yao. On the security of public key protocols. IEEE Transactions on Information Theory, \nIT-29(12):198 208, March 1983. C\u00b4edric Fournet and Tamara Rezk. Cryptographically Sound Implementa\u00adtions \nfor Typed Information-Flow Security. In POPL 2008, Proceedings of the 35th ACM SIGPLAN-SIGACT Symposium \non Principles of Pro\u00adgramming Languages, San Francisco, California, January 2008. ACM Press. Joseph A. \nGoguen and Jos\u00b4e Meseguer. Security Policies and Security Models. In Proceedings of the 1982 IEEE Symposium \non Security and Privacy, pages 11 20, Oakland, California, April 1982. IEEE Computer Society Press. Oded \nGoldreich. Foundations of Cryptography. Volume 1 -Basic Tools. Cambridge University Press, 2001. Jonathan \nHerzog. Computational Soundness of Formal Adversaries. Mas\u00adter s thesis, Massachusetts Institute of Technology, \nSeptember 2002. Peeter Laud. Semantics and Program Analysis of Computationally Secure Information Flow. \nIn David Sands, editor, Programming Languages and Systems, 10th European Symposium on Programming, ESOP \n2001, vol\u00adume 2028 of LNCS, pages 77 91, Genova, Italy, April 2001. Springer-Verlag. Peeter Laud. Handling \nEncryption in Analyses for Secure Information Flow. In Pierpaolo Degano, editor, Programming Languages \nand Sys\u00adtems, 12th European Symposium on Programming, ESOP 2003, volume 2618 of LNCS, pages 159 173, \nWarsaw, Poland, April 2003. Springer-Verlag. Peeter Laud and Varmo Vene. A Type System for Computationally \nSecure Information Flow. In Maciej Li\u00b4skiewicz and R\u00a8udiger Reischuk, editors, 15th International Symposium \non Fundamentals of Computation Theory (FCT) 2005, volume 3623 of LNCS, pages 365 377, L\u00a8 ubeck, Germany, \nAugust 2005. Springer-Verlag. John McLean. Security models and information .ow. In IEEE Symposium on \nSecurity and Privacy, pages 180 189, 1990. Andrew C. Myers. JFlow: Practical Mostly-Static Information \nFlow Con\u00adtrol. In POPL 99, Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages, pages 228 241, San Antonio, Texas, January 1999. ACM Press. Hanne Riis Nielson and Flemming \nNielson. Semantics with Applications: A Formal Introduction. Wiley, 1992. Birgit P.tzmann and Patrick \nMcDaniel, editors. 2007 IEEE Symposium on Security and Privacy (S&#38;P 2007), 20-23 May 2007, Oakland, \nCalifor\u00adnia, USA, 2007. IEEE Computer Society. Andrei Sabelfeld and Andrew C. Myers. Language-Based Information-Flow \nSecurity. IEEE Journal on Selected Areas in Communications, 21(1):5 19, January 2003. Andrei Sabelfeld \nand David Sands. A Per Model of Secure Information Flow in Sequential Programs. In S. Doaitse Swierstra, \neditor, Program\u00adming Languages and Systems, 8th European Symposium on Program\u00adming, ESOP 99, volume 1576 \nof LNCS, pages 40 58, Amsterdam, The Netherlands, March 1999. Springer-Verlag. Andrei Sabelfeld and David \nSands. Dimensions and principles of declassi\u00ad.cation. In CSFW, pages 255 269. IEEE Computer Society, \n2005. Geoffrey Smith and Rafael Alp\u00b4izar. Secure Information Flow with Random Assignment and Encryption. \nIn 4th ACM Workshop on Formal Methods in Security Engineering, pages 33 43, 2006. Geoffrey Smith and \nDennis M. Volpano. Secure Information Flow in a Multi-threaded Imperative Language. In POPL 98, Proceedings \nof the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Program\u00adming Languages, pages 355 364, San \nDiego, California, January 1998. ACM Press. Jeffrey A. Vaughan and Steve Zdancewic. A cryptographic decentralized \nlabel model. In P.tzmann and McDaniel (2007), pages 192 206.  \n\t\t\t", "proc_id": "1328438", "abstract": "<p>To speak about the security of information flow in programs employing cryptographic operations, definitions based on computational indistinguish ability of distributions over program states have to be used. These definitions, as well as the accompanying analysis tools, are complex and error-prone to argue about. Cryptographically masked flows, proposed by Askarov, Hedin and Sabelfeld, are an abstract execution model and security definition that attempt to abstract away the details of computational security. This abstract model is useful because analysis of programs can be conducted using the usual techniques for enforcing non-interference.</p> <p>In this paper we investigate under which conditions this abstract model is computationally sound, i.e. when does the security of a program in their model imply the computational security of this program. This paper spells out a reasonable set of conditions and then proposes a simpler abstract model that is nevertheless no more restrictive than the cryptographically masked flows together with these conditions for soundness.</p>", "authors": [{"name": "Peeter Laud", "author_profile_id": "81100361595", "affiliation": "Tartu University and Cybernetica AS, Tartu, Estonia", "person_id": "PP14249896", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1328438.1328479", "year": "2008", "article_id": "1328479", "conference": "POPL", "title": "On the computational soundness of cryptographically masked flows", "url": "http://dl.acm.org/citation.cfm?id=1328479"}