{"article_publication_date": "01-07-2008", "fulltext": "\n Generating Precise and Concise Procedure Summaries Greta Yorsh * Eran Yahav Satish Chandra Tel Aviv \nUniversity, Israel IBM T.J. Watson Research Center, USA IBM T.J. Watson Research Center, USA gretay@post.tau.ac.il \neyahav@us.ibm.com satishchandra@us.ibm.com Abstract We present a framework for generating procedure \nsummaries that are precise applying the summary in a given context yields the same result as re-analyzing \nthe procedure in that context, and concise the summary exploits the commonalities in the ways the procedure \nmanipulates abstract values, and does not contain super.uous context information. The use of a precise \nand concise procedure summary in mod\u00adular analyses provides a way to capture in.nitely many possible \ncontexts in a .nite way; in interprocedural analyses, it provides a compact representation of an explicit \ninput-output summary table without loss of precision. We de.ne a class of abstract domains and transformers \nfor which precise and concise summaries can be ef.ciently generated using our framework. Our framework \nis rich enough to encode a wide range of problems, including all IFDS and IDE problems. In addition, \nwe show how the framework is instantiated to pro\u00advide novel solutions to two hard problems: modular linear \nconstant propagation and modular typestate veri.cation, both in the pres\u00adence of aliasing. We implemented \na prototype of our framework that computes summaries for the typestate domain, and report on preliminary \nexperimental results. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program \nVeri.cation; F.3.1 [Theory of Computa\u00adtion]: Specifying and Verifying and Reasoning about Programs General \nTerms Veri.cation, Reliability, Languages, Algorithms Keywords summarization, composition, relational \nanalysis, sym\u00adbolic summary, typestate veri.cation, aliasing, data.ow analysis, micro-transformers 1. \nIntroduction The problem of automatically computing procedure summaries is a fundamental problem in program \nanalysis. Most of the existing general-purpose approaches to interprocedural analysis (Sharir and Pnueli \n1981; Cousot and Cousot 1978; Reps et al. 1995; Sagiv et al. 1996b) compute tabulation-based procedure \nsummaries: sum\u00admaries that are represented as an explicit tabulation of the relation * This research \nwas supported in part by an Eshkol Fellowship. Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 08, January 7 12, 2008, San Francisco, California, USA. Copyright \nc . 2008 ACM 978-1-59593-689-9/08/0001. . . $5.00 between abstract values at the entry of a procedure, \nand the corre\u00adsponding values at its exit. In particular, the commonly used (e.g,. in Dor et al. (2004); \nDas et al. (2002); Qadeer and Wu (2004); Jhala and Majumdar (2007); Fink et al. (2006); Rinetzky et al. \n(2005)) framework for solving IFDS problems (Reps et al. 1995) performs explicit tabulation for distributive \ndomains. However, an explicit input-output table is just one possible rep\u00adresentation of the procedure \ns abstract effect. Indeed, in their sem\u00adinal works, Cousot and Cousot (1978) with the relational ap\u00adproach \nand Sharir and Pnueli (1981) with the functional ap\u00adproach represent a procedure summary as a function \nfrom input abstract values to output abstract values. The functional represen\u00adtation of a summary does \nnot necessarily enumerate input abstract values; it can also describe how classes of input abstract values \nare transformed by the procedure, by referring symbolically to ab\u00adstract values. The dif.culty already \nacknowledged in (Sharir and Pnueli 1981) is in generating such a symbolic summary. Cousot and Cousot \n(2002) introduced symbolic relational sep\u00adarate analysis, a conceptual framework for modular analysis. \nOur contribution is in identifying a rich class of problems for which it is feasible to generate procedure \nsummaries that are symbolic, and thus, solve these problems using modular analysis. There has been relatively \nlittle previous work on symbolic summarization tech\u00adniques in this setting. Chatterjee et al. (1999) \nintroduced a modular points-to analysis. Our work draws inspiration from their work in identifying relevant \nbehaviors of procedures. Other efforts in this direction include (Cheng and Hwu 2000; Whaley and Rinard \n1999; Gulwani and Tiwari 2007; Xie and Aiken 2005; Ball et al. 2005), but we are not aware of a more \ngeneral framework that computes symbolic procedure summaries for a wider class of problems. In this paper, \nwe present a new framework for generating sym\u00adbolic procedure summaries for a rich class of abstract \ndomains and transformers over those domains. Given a procedure and a program-independent description \nof an abstract domain and its transformers, our framework automatically computes a symbolic summary of \nthat procedure. The summary is applicable in any call\u00ading context. Our framework derives procedure-level \ntransformers by sym\u00adbolic composition of statement-level transformers, and represents the result of composition \nin the same form as a statement-level transformer. The procedure-level transformers or the procedure \nsummaries computed by our framework have the following prop\u00aderties: Precise: applying the summary in \na given context yields the same result as re-analyzing the procedure in that context; no information \nis lost during creation of the summary.  Concise: the summary exploits the commonalities in the ways \nthe procedure manipulates different abstract values, and does not contain super.uous context information. \n Ef.cient: applying the summary in a given context is more ef.cient than re-analyzing the procedure \nin that context.  The procedure itself is a trivial summary of its effect, but of course it is not ef.cient \n. We are interested in a summary that captures the composite effect of a procedure, such that applying \nthe summary does not use statement-level abstract transformers. The motivation for generating concise \nsummaries is two-fold. First, a concise procedure summary provides a way to capture in.nitely many possible \ncontexts in a .nite way, and hence, can be used in modular analyses. For example, a concise summary of \na library can be used when analyzing any client of that library. Moreover, a summary of a library can \nbe generated before a client code is written, because a summary can refer to possibly unknown calling \ncontext symbolically. Second, for interprocedural analyses, a concise summary provides a compact representation \nof an explicit input-output summary table, without loss of precision. A concise summary, that ignores \nirrelevant context information, is potentially more compact than, e.g., a shared representation of an \nexplicit input/output table using BDDs. We have identi.ed suf.cient conditions on the structure of ab\u00adstract \ndomains and their transformers that guarantee that our frame\u00adwork can automatically compute concise and \nprecise summaries. The key idea is that the transformers we support make only .nitely many distinctions \nover input values, and each distinct class of val\u00adues behaves uniformly. Rather sophisticated abstract \ndomains and transformers can be encoded in this restricted form. Not only can our framework handle the \nwell-known IFDS (Reps et al. 1995) and IDE (Sagiv et al. 1996a) problems, it can also handle problems \nsuch as modular linear constant propagation in the presence of aliasing, and modular typestate veri.cation \nin the presence of aliasing (Fink et al. 2006). We have created a prototype implementation of modu\u00adlar \ntypestate veri.cation based on this framework and have run the analysis on a number of realistic, albeit \nsmall programs. 1.1 Overview Our Approach to Generating Summaries We derive procedure summaries by symbolic \ncomposition of statement-level transform\u00aders, as follows. For basic statements, the transformers are \ngiven as input to our framework. For call statements, the transformers are the summaries of the callees \n(after replacing formal parame\u00adters with actual arguments). For loop statements, the transformer is computed \nby iterated composition of the transformer for the loop body, until the composite transformer reaches \na .xpoint. Recursion and callbacks can be handled similarly to loops. The procedure summary is simply \nthe composite transformer for the procedure body. A suf.cient condition for this approach is that the \nlanguage of statement-level transformers (summaries) is (a) closed under composition, i.e., the result \nof composition is again represented in the same form as a statement-level transformer, and (b) .nite, \nto guarantee that iterated composition terminates. Challenge of Composition When summaries are represented \nas explicit relational tables, composition of summaries is easy albeit possibly inef.cient to compute, \nas it corresponds intuitively to the relational join of the tables. By contrast, for symbolic summaries, \ncomposition of two (symbolic) transformers might not be express\u00adible in the same form as transformers, \nor .nding the representation of transformers might be infeasible to compute. Given a pair of transformers \ntr12 and tr23, the goal of composi\u00adtion is to return a transformer tr13 that precisely captures the com\u00adposed \neffect of tr12 and tr23. Intuitively, one can think of these transformers as relating values in three \ndomains: (A1), (A2), and (A3), where tr12 transforms values between (A1) and (A2), and tr23 transforms \nvalues between (A2) and (A3). The challenge of creat\u00ading a precise summary is to relate the values of \n(A1) and (A3) with\u00adout explicit mention of the values in (A2). This is shown schemati\u00adcally in Fig. 1 \n(a). The key to composition is therefore to represent Figure 1. Schematic view of composition with (a) \ngeneric trans\u00adformers (b) .nite domain with distributive transformers (c) condi\u00adtional micro-transformers. \n the restriction imposed on values in (A2) due to the composition of tr12 and tr23 by expressing them \nas restrictions in (A1) and in (A3). In general, avoiding restrictions on values in (A2) is a hard prob\u00adlem \nclosely related to that of existential quanti.er elimination. (The transformers can be viewed as a symbolic \nrepresentation of rela\u00adtions, and their composition corresponds to conjunction and exis\u00adtential quanti.cation.) \nHowever, when the domain and the trans\u00adformers are of a certain restricted structure, composition becomes \nfeasible. For example, when the domain is .nite and the transform\u00aders are distributive, e.g., Fig. 1 \n(b), the composed effect can be com\u00adputed via graph reachability (Reps et al. 1995). Exploiting Structure \nfor Composition The key insight used in this paper is that by exposing the underlying structure of an \nabstract domain and transformers we can express the domain as an aggre\u00adgate of simpler domains, for which \nit is feasible to compute the composition of transformers. That is, the composition of transform\u00aders \nfor the aggregate domain can be broken into smaller composi\u00adtion problems of micro-transformers that \napply to the sub-domains, and so on. We do allow limited interaction between sub-domains. Micro-transformers \nin our framework can be expressed as oper\u00adating on classes of values in a sub-domain rather than working \non individual elements. We call micro-transformers written in this way conditional micro-transformers. \nA conditional micro-transformer consists of several cases, each of which has a precondition that de.nes \na distinct class of input values, and a postcondition that de.nes how these values are transformed. The \nidea is to expose enough structure of the aggregate domain such that all values in the same class are \ntransformed uniformly, and thus can be described by simple postconditions. Just as statement-level transformers \nthat we support make only .nitely many distinctions over input values, the procedure-level transformer \nor the summary distinguishes between only a .nite number of classes of these values. This reduces the \ninformation that needs to be encoded in a summary from a potentially in.nite context into a .nite one. \nComposition of Conditional Micro-Transformers Our composi\u00adtion algorithm leverages the particular structure \nof transformers we enforce by considering each class of values separately. Fig. 1 (c) shows how our algorithm \ncomposes a single case of tr12 with a single case of tr23. The composition is performed in two stages: \n(I) expressing the precondition of tr23 (shown as pre 23 in A2) in the domain (A1). This is done by computing \nthe weakest precondition of pre 23 under tr12 as shown by the dotted ar\u00adrow marked (I). The set wp(pre \n23) expresses the restriction on values imposed by pre 23 in terms of the domain (A1). (II) expressing \nthe postcondition of tr12 under the effect of tr23 in the domain (A3). Technically, this step is performed \nby substitution and is shown by the dotted arrow marked (II). The set g(f(pre 12)) expresses the restriction \non values im\u00adposed by f(pre 12) in terms of the domain (A3). The intersection of wp(pre 23) and pre 12 \nexpresses the precon\u00addition of the composite transformer tr13 in terms of the domain (A1). The intersection \nof g(pre 23) and g(f(pre 12) expresses the postcondition of tr13 in terms of the domain (A3). Therefore, \nthe result of composition of conditional micro-transformers can also be expressed as a conditional micro-transformer. \nWe give an elaborate description of both steps in Section 4.  1.2 Contributions The main contributions \nof this paper are: We introduce a formal framework for generating symbolic sum\u00admaries for a class of \nabstract domains and transformers, and show that for those domains and transformers, the framework produces \nsummaries that are concise, precise and ef.cient.  We show how the framework is instantiated to provide \nnovel solutions to two hard problems: (i) modular typestate veri.ca\u00adtion in the presence of aliasing, \nand (ii) modular linear constant propagation in the presence of aliasing. We also brie.y describe how \nthe framework can be used to solve a few other problems.  We present a prototype implementation that \ncomputes proce\u00addure summaries for the typestate domain. Our experiments show that our implementation \nsuccessfully generates sum\u00admaries for procedures of real (albeit small) programs.  Outline In Sec. 2, \nwe illustrate our method by a simple example of composition, and introduce our running example. In Sec. \n3, we de.ne the class of abstract domains and transformers handled by our framework. In Sec. 4, we present \nthe composition algorithm and outline its properties. In Sec. 5, we describe how the composi\u00adtion algorithm \nis put to use in a general framework for generating procedure summaries and show how to instantiate the \nframework for several applications. In Sec. 6, we report on preliminary exper\u00adimental results obtained \nusing our prototype for generating sum\u00admaries for typestate domain. Finally, in Sec. 7, we survey related \nwork.  2. Illustrative Examples In this section, we present our main ideas at a semi-technical level \nusing examples. We present two examples: the .rst one illustrates our entire approach on a simple analysis \nproblem, and the other one introduces the important but complex analysis problem of typestate veri.cation, \nand is developed gradually throughout the paper. 2.1 Nullness of References The analysis problem modeled \nin this example tracks whether the value of a given reference must be null at runtime. Although meant \nfor expository purposes, it may also serve as part of an analysis targeted to statically identify potential \nnull-dereferences. Domain We use an abstract domain in which the abstract value is a set of access paths, \nsuch that all elements in the set must have the value null. For a given program, an example value in \nthis abstract domain could be {p.f, q..}, meaning that p.f and q are both null. Here, p.f is an access \npath of length 1, and q.. is an access path of length 0. We write q instead of q.. when no confusion \nis likely. To guarantee termination of the nullness analysis, the length of the access paths represented \nin the nullness domain is bounded. To simplify the presentation, we bound the length to be at most 1. \nclass DataReader {private FileComp f; void readData(FileComp p) { init(p); process(); } void setComponent(FileComp \np) { this.f = p; } FileComp getComponent() { return this.f; } void init(FileComp p) { this.f = p; f.open(); \n } void process() { FileComp q = this.f; while (?) q.read(); q.close(); }} Figure 2. A program using \nthe type FileComp. Let AP denote the set of all access paths of length at most 1; the abstract domain \nfor this example is therefore P(AP ). The do\u00admain AP is de.ned as VarId \u00d7(FieldId .{.}), where VarId \nand FieldId are parameters of the domain, that denote variable names and .eld names, respectively: unless \nthey are instantiated for a spe\u00adci.c program, we do not know which speci.c program variables and .elds \nthey contain. Since AP relies on these parametric do\u00admains, it too is a parametric domain. Transformers \nConsider the setComponent procedure in the ex\u00adample program of Fig. 2. Denoting the set of access paths \nof the ab\u00adstract value by M .P(AP ), the concise summary (transformer) for this procedure is: trP(AP \n)(M)= trAP (d) d.M where trAP (d) is a micro-transformer that describes how an el\u00adement of the set is \nindividually manipulated by the transformer, and maps d to a set of resulting elements. This illustrates \nthe gen\u00aderal pattern of expressing transformers on abstract values in some domain A in terms of micro-transformers \non abstract values in sub\u00addomains that comprise A. As we shall see later, other examples use additional \ndomain constructors. The micro-transformer trAP (d) for setComponent is: . this.f, p d = p trAP (d)= \ndd .= this.f . d .= p The format of this transformer is a series of preconditions (shown on right) and \nthe corresponding output (shown on left). For clarity, we have written the contents of the returned sets \n(the left-hand\u00adside) without the enclosing set brackets, and we have omitted cases in which the resulting \nset is empty. The intuitive meaning of the procedure summary (described by the micro-transformer) is \nthat if the access path p is known to have a null value before the procedure, then it has null value \nafter the procedure, and in addition, the access path this.f must also have a null value; for all other \naccess paths d such that (d . = this.f . d .p) before the transformer, their membership in M = remains \nunchanged. Composition Now consider an additional procedure nop added to the class DataReader as follows: \nvoid nop() { FileComp t = getComponent(); setComponent(t); } Figure 4. Composition of t=getComponent();setComponent(t). \nThe micro-transformer for the call t=getComponent() is: 12 . t, this.f d = this.f trAP (d)= dd .= t . \nd .= this.f The micro-transformer for call setComponent(t) is: 23 . this.f, t d = t trAP (d)= dd .= this.f \n. d .= t The summary of the entire code sequence inside nopis: 13 . t, this.f d = this.f trAP (d)= dd \n.= t . d .= this.f The summary of the whole procedure (after the effect on the local variable tis removed) \namounts to the identity function. Each of the conditional micro-transformers in the composition example \nis shown in Fig. 3 in the form of a one-level tree: the root of the tree represents an input value d, \nthe leaves of the tree correspond to different output values, whose preconditions appear on the edges \nleading to the leaves. In the micro-transformer for t=getComponent(), the input value is a single access \npath d. The edges leading to the leaves t and this.f are labeled with the precondition d = this.f, representing \nthe .rst case of the transformer. The edge leading to the leaf d is labeled with the precondition d .t \n. d = this.f, representing the second case of the transformer. Note that every leaf corresponds to a \nterm of the postcondition, and the edge leading to it is labeled with the precondition that is guarding \nthat term. We illustrate how our composition algorithm generates a com\u00adposite micro-transformer for t=getComponent();setComponent(t) \nusing the conditional micro-transformers for t=getComponent() and setComponent(t), denoted by tr12 AP \nand tr23 AP , respectively. For each term t(d) in a postcondition of tr12 AP (d), we make a copy of tr23 \nAP (d), in which we replace d with t(d). Fig. 4 depicts this operation. The top dotted rectangle in the \n.gure depicts the trans\u00adformer for t=getComponent(). The three dotted rectangles at the bottom depict \nthe copies of the transformer for setComponent(t) in which d was replaced with t(d) as described above. \nWe label the root of each tree on the second level with the corresponding assign\u00adment of t(d) to d. For \nexample, the rightmost tree corresponds to a case in which t(d) is this.f. The two-level tree in Fig. \n4 can be used to obtain the result of composition. A conjunction of preconditions on the path from the \nroot to a leaf de.nes a new precondition. We label the leaves for which the new preconditions are consistent \nwith a checkmark. For example, the new precondition for the rightmost branch of the tree is incosistent \nbecause the access paths t and this.f are distinct. 1 We simplify the result by removing inconsistent \nleaves, and re\u00adplacing paths from the root to the remaining leaves with edges. The result of composition \nis shown as the rightmost transformer in Fig. 3. Other analysis problems present much more challenging \ntasks of simpli.cation and subsequent normalization sometimes re\u00adquiring domain-speci.c axioms but conceptually \nthe idea is the same. Properties The summaries that we compute for getComponent() and setComponent() \nindividually, as well as for their composi\u00adtion, have all the desired properties: they are concise, precise, \nand ef.cient. The properties depend crucially on the strength of the composition algorithm: for example, \na sound but imprecise algo\u00adrithm could have lost the fact that the effect of nop()is the identity function, \nand in particular, it might fail to establish the fact that this.f must have a null value after the execution \nof the code sequence if it initially had a null value. To represent a complete summary of setComponent \nby ex\u00adplicit tabulation, one would need to describe input-output pairs for the possibly large number \nof elements of P(AP ), that would de\u00adpend on the actual program variables and .eld names outside of this \nprocedure. In addition, even a partial summary table for this procedure might contain redundant information. \n 2.2 Typestate Veri.cation in the Presence of Aliasing We introduce typestate veri.cation as an example \nof a more com\u00adplicated domain. A typestate speci.cation (Strom and Yemini 1986) for a type constrains \nthe sequences of procedure calls that can be invoked on an object of that type. In the example pro\u00adgram \nof Fig. 2, the typestate speci.cation for the type FileComp open() contains the following non-error transitions: \ninit -. open, read()close() open -. open, and open -. closed; all other transitions lead to a designated \nerror state. Formally, a typestate speci.cation is a deterministic .nite-state automaton with alphabet \nS, states Q, initial state init .Q, .nal state err .Q, also called error state , and transition function \nds : Q.Q for each s . S. Given a program and a typestate speci.cation, the purpose of typestate veri.cation \nis to ensure that in all possible executions of the program, no object can enter an error state. Typestate \nver\u00adi.cation is a well studied problem (e.g., (Foster et al. 2002; Das et al. 2002; Dor et al. 2004; \nFink et al. 2006; DeLine and F\u00a8ahndrich 2004; DeLine and F\u00a8ahndrich 2002; Field et al. 2003)), but most \nexisting solution provide a limited treatment of aliasing, or lim\u00adited scalability. A modular implementation \nof typestate analysis is therefore of signi.cant practical interest. We focus on one abstraction that \nforms the core of the type\u00adstate veri.cation system of (Fink et al. 2006), which carried out typestate \nveri.cation as a non-modular, whole-program interpro\u00adcedural analysis using this abstraction. In this \nabstract domain, an abstract value is a set of data.ow facts. Each data.ow fact refers to a single allocation \nsite and combines information about the type\u00adstate of an object allocated at that site, and pointer information \nrelated to the same object. In particular, a data.ow fact is of the form .a, s, M. where a is an allocation \nsite, s is a typestate from 1 Here, the equality of access paths is a syntactic, as opposed to checking \naliasing between access paths. {init, open, closed}, and M is a set of access paths (similar to those \nused in the null-dereference example) that must point to the tracked allocation site a. Abstract transformers \nfor this domain are distributive and, therefore, can be represented pointwise for the set of data.ow \nfacts. See (Fink et al. 2006) for the rationale behind this abstraction; suf.ce it to say that tracking \nmust alias access paths is crucial for getting a low false positive rate for this veri.cation prob\u00adlem. \nSubsequent sections of the paper show how we model this composite domain (Sec. 3.1), what are the transformers \n(Sec. 3.2), and the details of the composition algorithm (Sec. 4). In particular, we will see how the \ncomposition algorithm obtains the typestate summary of readData from those of init and process: our composition \nalgorithm is powerful enough to establish that each FileComp always goes through correct typestate transitions. \n 3. Parametric Domains and Transformers In this section, we describe the abstract domains and transformers \nsupported by our framework. First, we restrict attention to paramet\u00adric abstract domains that are built \nusing simple domain construc\u00adtors. Then, we restrict the abstract transformers to those de.ned via micro-transformers \noperating on the components of an abstract value. In particular, in Sec. 3.2, we de.ne the notion of \nconditional micro-transformers which is the key to concise representation. Expressing transformers using \nmicro-transformers allows us to leverage their structure, and implement a composition algorithm for generating \nprecise and concise summaries, as described in Sec. 4. 3.1 Domain Constructors Abstract interpretation \n(Cousot and Cousot 1977) computes, for each program point, an abstract value that overapproximates the \nsets of concrete program states that actually arise at that program point. Abstract values are drawn \nfrom an abstract domain that usu\u00adally depends on the program under analysis. For example, for a pro\u00adgram \nwith variables x, y, and z, an abstract value for the abstract domain of constant propagation is a mapping \nenv : {x, y, z}. (Z.{.}). Abstract values may also refer to elements of an explic\u00aditly de.ned, program-independent, \npotentially in.nite set of atomic values, such as the states Q of a typestate automaton, or the set of \nall naturals N. A parametric abstract domain provides a program-independent description of abstract values \nin the domain, using domain parame\u00adters. A domain parameter is a symbolic place-holder for program\u00adspeci.c \nvalues that are to be bound at a later time. For example, a parametric abstract domain for constant propagation \nwill introduce a domain parameter VarId as a place holder for the set of program variable identi.ers. \nA parametric abstract domain can be instantiated for a speci.c program by binding the domain parameters \nto program-speci.c values (e.g., set of program variables). We refer to an instantiated parametric domain \nas a speci.c abstract domain. In this paper, we consider abstract domains de.ned using the domain constructors \nof the following de.nition. DEFINITION 3.1 (Domain Constructors). An abstract domain A can be constructed \nusing the following (non-recursive) domain constructors: A(.) ::=|P(A1(.1)) powerset binary relation \n |P(A1(.1) \u00d7 A2(.2)) with Prop (with properties) | A1(.1) \u00d7 ... \u00d7 Ak(.k) with IR (reduced) product | \nA1(.1) . A2(.2) union | Valj set of atomic values | Xi parameter where . = {X1,...,Xn} is a set of parameters; \nXi is one of the parameters, for 1 = i = n; .1,...,.k are subsets of .; Val1,..., Valm are sets of atomic \nvalues; 1 = j = m. For a binary relation, we support the following standard re\u00adlational properties Prop: \ndeterministic, re.exive, symmetric, and transitive. For a product domain, we use integrity rules IR to \nspec\u00adify restrictions on how domains are combined. Note that these domain constructors can construct \nboth parametric and speci.c abstract domains (when . = \u00d8). Also, the construc\u00adtors can use both parameters \nand atomic values as basic domain building blocks. A binary relation P(A1(.1)\u00d7A2(.2)) with deterministic \nprop\u00aderty denotes a (partial) function A1(.1) . A2(.2). Binary rela\u00adtion without properties can be de.ned \nusing powerset and product constructors. Integrity rules allow us to better approximate the reduced prod\u00aduct \n(Cousot and Cousot 1979) when combining domains using the product constructor. That is, if the component \ndomains are not inde\u00adpendent (e.g., use the same VarId parameter), then some of the tu\u00adples in the product \ndomain might represent inconsistent concrete in\u00adformation. The integrity rules de.ne consistent tuples. \nFor brevity, we omit the syntax of integrity rules, and the (standard) de.nition of the satisfaction \nrelation x |= IR, for a concrete value x. In Section 4 we explain how properties and integrity rules \nare used by the composition algorithm. The composition algorithm requires decidability of checking certain \nqueries about the set of abstract values that satisfy Prop and IR. The following example shows how several \nstandard domains are expressed using our domain constructors. EXAMPLE 3.2 (Nullness of References). A \nset of access paths of def length at most 1 is AP (VarId, FieldId)= VarId \u00d7 (FieldId .{.}), where VarId \nand FieldId are domain parameters. The parametric abstract domain for tracking nullness of refer\u00ad def \nences is NR(VarId, FieldId)= P(AP (VarId, FieldId)); an abstract value M . NR(VarId, FieldId) is a set \nof access paths that must have null value. . EXAMPLE 3.3 (Typestate). The typestate abstract domain, \npara\u00admetric in VarId, FieldId, and AS, is a powerset of D, de.ned as follows (omitting the domain parameters). \nD = AS \u00d7Q\u00d7 MustSet \u00d7 P ts \u00d7 Alias with IRD MustSet = P(AP ) P ts = P(AP \u00d7 AS) Alias = P(AP \u00d7 AP ) with \nre.exive, symmetric, transitive Here, a . AS is an allocation site, s .Q is a state of the typestate \nautomaton, M . MustSet is a set of access paths that must point to a, pts . P ts is a .ow-insensitive \npoints\u00adto information, and alias . Alias is a .ow-insensitive alias information with re.exive, symmetric, \nand transitive properties. A tuple .a, s, M, pts, alias. satis.es integrity rules IRD iff if p . M then \n.p, a.. pts, and,  if .p1,a.. pts and .p2,a.. pts then .p1,p2.. alias. .  def Notations For a domain \nA = A1 \u00d7 ... \u00d7 Ak, we use pi(A) to denote Ai, the i-th component in the product, and pi(a) to denote \nai the i-th component of the tuple a = .a1,...,ak. in A. For access paths, we use p1.p2 as a shorthand \nfor the tuple .p1,p2. in AP . We write p instead of p.. when no confusion is likely. We omit the domain \nparameters from domain identi.ers when they are clear from the context. Given a parametric abstract domain \nconstructed as above, we can instantiate it into a speci.c domain by binding its domain parameters to \nvalues. DEFINITION 3.4 (Domain Binding). Given a parametric abstract domain A, and a code fragment s, \nwe use [ A] s to denote the abstract values of the speci.c abstract domain obtained from A for s. The \nset [ A] s is de.ned inductively: def [ A1 \u00d7...\u00d7Ak] s = {.c1,...,ck.|.c1,...,ck.|= IR, .i.ci . [ Ai] \ns} def [ P(A1)]]s = {X | X is .nite,X |= Prop,X . [ A1] s} def [ A1 . A2] s =[ A1] s . [ A2] s If A is \na set of atomic values, then [ A] s = A. Finally, [ .] s is the set of program-speci.c values for ., \nextracted from the code. For instance, [ VarId] s is the set of names of program variables, [ FieldId] \ns is the set of names of pointer .elds, and [ AS] s is the set of names of allocation sites that appear \nin s. def EXAMPLE 3.5. For the parametric domain AP (VarId, FieldId)= VarId \u00d7 (FieldId .{.}), we get \nthe set of values [ AP ] x:=y.f is {x.f, x.., y.f, y..}, because [ FieldId] x:=y.f is {f }, and [ VarId] \nx:=y.f is {x, y}. 3.2 Micro-Transformers Our method is restricted to abstract transformers described \nin terms of micro-transformers. Micro-transformers, de.ned in this sec\u00adtion, operate on the components \nof an abstract value. If abstract transformers for all basic statements are expressed via the micro\u00adtransformers \nas de.ned in this section, then the algorithm presented in Section 4 generates composite transformers, \nwhich are also ex\u00adpressed via micro-transformers. Let A = P(Q) be the (top-level) abstract domain. We \nre\u00adquire that for every basic statement stmt the abstract transformer trstmt : A.A be expressed using \na micro-transformer that oper\u00adates pointwise on the values from the domain Q: trstmt trstmt = .X. Q (x) \nx.X where trstmt is a micro-transformer for the domain Q. The micro- Q transformer trstmt takes a value \nin Q and returns a set of values in Q Q. A micro-transformer trstmt can be de.ned using other micro- \nQ transformers that operate on the components of a value from Q, and so on. Before we proceed to formally \nde.ne micro-transformers we .rst de.ne the notion of query parameters that can be used in a micro-transformer. \nOne of the important concepts in this paper is the ability to make micro-transformers conditional on \nsome information about the con\u00adtext. That is, a micro-transformer that operates on a component a of the \nvalue q . Q can also query another component c of q to de\u00adtermine the effect of a statement on a. We \nsay that q is the context in which a is transformed, and c is a query parameter. Formally, given q . \nQ, cl(q) is a tuple of components of q that can be queried, and cl(Q) is a tuple of the corresponding \ndomains. The operations .j (q) and .j (Q) return the j-th element of cl(q) and cl(Q), respectively. We \nsay that .j (q) is a query parameter. In the following examples, we assume that queried components and \nthe corresponding domains are named, and refer to them by their names (rather than using .j ). For example, \nfor typestate, we assume that the domain D has the following named components: cl(.a, s, M, pts, alias.)= \n.a, M, pts, alias. cl(D)= .AS, MustSet, P ts, Alias. Given a domain Q, and query parameters for it, we \nformalize the notion of micro-transformers. A mapping trs A : Q . A .P(A) that takes context q . Q, and \nvalue a . A, and returns a set of values from A, is a micro-transformer for a code fragment s and a domain \nA if it can be expressed in the syntax de.ned below. P(A D for a= set = Ai = = 1 E = . d1,d2 d = d1 trD(d)= \nd3 d = d3 For a speci.c IFDS problem, we can easily compose micro\u00adtransformers and get a composite micro-transformer \nin our syn\u00adtax. In general, however, some restrictions are required on condi\u00adtional micro-transformers \nto guarantee that the language of micro\u00adtransformers is closed under composition. . .a, dopen(s). p . \nM trAS\u00d7Q(r)= .a, dopen(s).,r p/. M ..p, a.. pts r .p, a. .. pts . dp2(d)= f ..p1(d), this. .. alias trAP \n(d)= d .. p2(d)= f . d = p p, this.f d = p Table 1. Summary for the procedure init. In the typestate \nmicro\u00adtransformer, we use a instead of p1(r), and s instead of p2(r), to denote the components of r = \n.a, s.. EXAMPLE 3.8. An abstract value for typestate is a set X of tu\u00adples from D, de.ned in Example \n3.3. An abstract transformer tr: P(D) .P(D) is de.ned by tr(X)= x.X trD(x), where the micro-transformer \nfor D is separable. Let x be .a, s, M, pts, alias.: trD(x)= trAS\u00d7Q(.a, s.) \u00d7 trMustSet(M) \u00d7{pts}\u00d7{alias} \nAll micro-transformers for pts and alias are identity, because these sets are carrying .ow-insensitive \ninformation. Table 1 shows the micro-transformers for the procedure initof Fig. 2: a micro-transformer \nfor typestate pairs, denoted by trAS\u00d7Q, and a micro-transformer for the access paths in the must-set, \nde\u00adnoted by trAP . The typestate micro-transformer trAS\u00d7Q describes the effect of the statement p.open(), \nthe only statement in this procedure which alters the typestate. The .rst case of this transformer de\u00adscribes \na strong update of the typestate: if the must-set M of the incoming value contains the access path p, \nthen the resulting value in the typestate domain is .a, dopen(s)., where d is the transition re\u00adlation \nof the typestate automaton for FileComp. The second case describes a weak update of typestate: if p may \npoint to the alloca\u00adtion site a, according to a global points-to analysis pts, and there is no must information \nabout p in the incoming value, then the result contains two values, one in which the typestate has changed, \nand one in which it is preserved. The third case describes that the orig\u00adinal value is preserved, when \np is known to must not point to the allocation site a. The must-set micro-transformer trMustSet(M) is \nde.ned point\u00adwise on the access paths in the set M , using the micro-transformer for individual access \npaths, trAP (d). It describes the effect of the statement this.f=p. Note that the kill effect of the \ntransformer is described implicitly: if this may alias to some other variable v, according to the global \nmay-alias analysis alias, then the f-.eld of the object pointed-to by v may change as a result of the \ndestructive update this.f=p. In this case, we cannot guarantee that v.f still points to the tracked object \nafter the update, and, thus, an access path of the form v.f where v may be aliased with this, will not \nbe propagated by this transformer. . 3.2.1 Restrictions on Conditional Micro-Transformers In this section, \nwe describe syntactic restrictions on preconditions and postconditions that ensure that conditional micro-transformers \nare closed under composition. We start by giving the syntax of terms that we use in precondi\u00adtions and \npostconditions. A term can refer to speci.c values that ap\u00adpear in the transformed code fragment s, e.g., \nit can explicitly refer to program variables that appear in s, members of the set [ VarId] s. Values \nthat appear in the rest of the code are referred to symboli\u00adcally using the parameters a and q. The fact \nthat we do not explic\u00aditly refer to these values in the transformer allows us to concisely describe the \nbehavior of the code fragment s when the number of different contexts is large (interprocedural analysis) \nor even in.nite (modular analysis). Moreover, a term can refer to function symbols such as f : B . B, \nfor some domain B, whose semantics is inde\u00adpendent of the analyzed program. A term in TAs .B(a) denotes \na value in domain B as a function of the value of the parameter a from domain A. DEFINITION 3.9. A term \nin TAs .B(a) has the following syntax: T s (a)::= a if B = A A.B | v if v . [ B] s | f(t) if t . T s \n(a),f : B . B is symbolic A.BA | pi(t) if pi(C)= B, t . p(a) C |.t1,. . . ,tk. if B =B1 \u00d7...\u00d7Bk, and \n.i.1 = i = k : ti . TAs .Bi (a) For example, in Table 1, dopen(p2(r)) is a term in T init AS\u00d7Q.Q(r), \nwhich refers to the function dopen symbolically. There are no special restrictions on the syntax of terms \nthat can be used in a postcondition of a conditional micro-transformer: for a domain A and a code fragment \ns, any term in TAs .A(a) can be used in the postcondition. We restrict the precondition queries to guarantee \nthat micro-transformers are closed under composition, and that their composition can be done automatically. \nDEFINITION 3.10. Given a code fragment s, and a domain A,a precondition query is de.ned by the following \nsyntax: Cs (a, q) ::= t = v if v . [ B] s A | t = .j (q) if .j (Q)= B, B is invertible,.j (q) . = a | \nt . .j (q) if .j (Q)= P(B),B is invertible where t is a termin TAs .B (a). A precondition is a conjunction \nof literals, where a literal is a precondition query from CAs (a, q) or its negation. We use P res A(a, \nq) to denote the set of all preconditions. In the .rst case, a precondition query is an equality test \nof a term and a speci.c value, independent of q. In the second case, it is an equality test of a term \nand a query parameter. In the third case, it is a set membership test of a term in a set described by \na query parameter. The restricted structure of the query will allow us to compute the weakest precondition \nof a query and guarantee that the (simpli.ed) result is in the language of our preconditions. The most \nimportant restriction is that domain B associated with the query parameter be invertible,2 as de.ned \nin Section 3.2.2. For example, in Table 1, we use the query p . M where p is an access path and the corresponding \ndomain AP is required to be invertible. It is worth noting here that the language of preconditions is \nclosed under conjunction. Also, the language of postcondition terms is closed under substitution. Thus, \nthe language of precondi\u00adtions is also closed under substitution of these terms. We rely on these facts, \namong others, to show that the result of our composition algorithm is in the language of our micro-transformers. \nMoreover, given a code fragment, the language of (normalized) terms and queries are .nite, assuming no \nsymbolic functions are used. We rely on this to show that the algorithm for summary generation terminates \nand the summaries are .nite. Notations Let s1 and s2 be two code fragments. For terms t1 . s1 s1 T (a) \nand t2 . T (a), we use t1[a . t2] to denote the A.BA.A s1.s2 term in TB.A (a) obtained by substitution \nof t2 instead of a in t1. For a term t . TAs1 .B(a) and a speci.c value w . [ A] s2 , we use t(w) to \ndenote the (unique) value of the term obtained by re\u00adplacing a with w in t. Note that t(w) . [ B] s1.s2 \n. Similarly, for a precondition query c . CA s1 (a, q), and a value u . [ cl(Q)]]s2 of the query parameters \nreferred to by the query, c(w, u) denotes 2 For the second test, the requirement on B can be weakened. \nthe value true or false. We lift this interpretation to boolean com\u00adbinations of queries in the usual \nway. For a micro-transformer trs1 A , values w and u as above, if s1 contains s2, we use trs1 (w) to \nde- A note the set of speci.c values in [ A] s2 returned by the transformer when its input value is w \nand the the query parameters has value u. Now that we have de.ned the restrictions on terms and queries, \nwe are .nally ready to de.ne the restrictions on conditional micro\u00adtransformers. Given a code fragment \ns, the effect of a conditional micro\u00adtransformer on A can be decomposed into equivalence classes of values \nin [ A] s with a uniform behavior, and each equivalence class is described by one of the cases in the \nmicro-transformer. The following conditions require that every input value satis.es the precondition \nof exactly one case in a micro-transformer. DEFINITION 3.11 (Conditional Micro-Transformer Syntax). Given \na code fragment s and a domain A, a conditional micro-transformer trs is de.ned by A . post1 pre1 s tr= \n.a. ... ... A postn pren where for all i =1,...,n, posti . TAs .A(a),  for all i =1,...,n, prei . P \nres  A(a, q), for every code fragment s1 that contains s, for every value u . [ cl(Q)]]s1 , w . [ A] \ns1 , there exists a unique i, 1 = i = n, such that prei(w, u) is true. We rely on these conditions to \nprovide an ef.cient composition algorithm for conditional transformers, as explained in Sec. 4. Remark. \nA conditional transformer can represent the kill effect of a statement using cases whose postcondition \nis an empty set (in the examples, these cases are omitted). A transformer can repre\u00adsent the gen effect \nof a statement using a designated value ., propagated by every pointwise transformer (similar to the \nuse of . in (Reps et al. 1995; Sagiv et al. 1996b)). In typestate abstraction, for example, we use . \ncases to model allocation. The transformer trAS\u00d7Q(r) for an allocation statement x = new FileComp() at \nallocation site aL contains the case with precondition r =., whose postcondition is the singleton .aL, \ninit.. For brevity, we omit the discussion about . from this paper. 3.2.2 Invertible Micro-Transformers \nAs we will see in Section 4, the composition algorithm for con\u00additional micro-transformers uses the invert \noperation to compute the reverse-image of some micro-transformers. The success of the composition algorithm \nrelies on the ability of invert to compute simple precondition on the input values of a micro-transformer \nfor which the micro-transformer yields a certain value. This motivates the following de.nition. DEFINITION \n3.12 (Invertible). Let trs1 be a micro-transformer B for domain B and code fragment s1. The micro-transformer \ntrs1 is B invertible iff there exists a computable operation invert such that for every domain A that \nqueries B, for every code fragment s2 and s2 term t in T (a), the result of invert(trs1 ,t) is .k .i \nwhere A.BBi=1 for all i =1,...,k, .i is of the form (b = t.) . pre, where . s1.s2 s1.s2 t. T (a), pre \n. P re(a, q), and (b = t.) is A.BA optional; for every code fragment s that contains both s1 and s2, \nfor every u . [ cl(Q)]]s, w . [ A] s, and v . [ B] s, t(w) . trs1 (v) iff there exists i such that .i(w, \nv, u) is true. B Domain B is invertible when for all basic statements, the micro\u00adtransformers for B are \ninvertible. A , tr23 compose(tr12 )= A . tr12 tr23 is identity AA tr23 tr12 is identity AA A , tr23 .X.{ \nx.X tr13 (x)} tr12 are pointwise, A1 A A = P(A1), . . tr13 = compose(tr12 , tr23 ) A1 A1 A1 A , tr23 \n..a1,...,ak.. tr12 are separable, A tr13 (a1) \u00d7 ... \u00d7 tr13 (ak) A=A1 \u00d7...\u00d7 Ak, .i.1=i= k : A1 Ak tr13 \n= compose(tr12 , tr23 ) Ai Ai Ai . A , tr23 A , tr23 . composeCond(tr12 ) tr12 are conditional AA Table \n2. Composition algorithm for micro-transformers. The input is a pair of micro-transformers tr12 A : A \n.P(A). The output A , tr23 is a micro-transformer for A. The subroutine composeCond is given in Fig. \n5. The following lemma de.nes syntactic restrictions on a condi\u00adtional micro-transformer that guarantee \nthat they are invertible. LEMMA 3.13. A conditional micro-transformer trs is invertible if B every case \ni in trs B , and every term t in posti satisfy one of the following: t is b, prei is of the form b \n= w . pre . where w . [ B] s and b does not appear in pre . (and we place no restrictions of t),  t \nis of the form .t1,...,tk., and there is a set of indexes J = {j1,...,jm}.{1,...,k}, such that prei is \nof the form  (pj1 (b)= w1) . ... . (pjm (b)= wm) . pre . where for all j =1,...,m, wj . [ B] s, b does \nnot appear in pre ., and for all j =1,...,k, either j . J or tj is pj (b), t is f(t.), f-1 is a function, \nand t. and prei satisfy one of the conditions above (with t. in place of t). A degenerate case of invertible \ndomain is immutable domain. DEFINITION 3.14 (Immutable Domain). Domain B is immutable when for all basic \nstatements, the micro-transformers for B are identity. The invert of operation for immutable domain B \nis essentially identity: invert(trB,t) is (b = t). In our typestate example, the domains P ts and Alias \nare im\u00admutable, and the domain AP is invertible. To guarantee that the weakest precondition is computable, \nour method restricts domains of certain query parameters to be invert\u00adible, depending on the way the \nquery parameter is used in precon\u00additions. Not all domains need to be invertible.  4. Composition Algorithm \nIn this section, we describe a composition algorithm for micro\u00adtransformers and employ it for computing \nfunctional composition of abstract transformers, the basis of our framework for generating procedure \nsummaries. Given a pair of micro-transformers tr12 A : A .P(A), the A , tr23 algorithm, shown in Table \n2, returns a micro-transformer for A that precisely captures the composed effect of tr12 A and tr23 A \n. The main part of the algorithm is the subroutine composeCond shown in Fig. 5, which composes conditional \nmicro-transformers, as described Sec. 4.1. This procedure computes a generalized weakest precondition \nof queries that appear in the preconditions of a micro-transformer, as described in Sec. 4.2. It relies \non a de\u00adcision procedure for checking consistency of preconditions, and for simpli.cation of summaries, \nto guarantee that the summary is precise and that its size is bounded, as explained in Sec. 4.3. A , \ntr23 composeCond(tr12 ) { A 12 1212 // tr= {.pre , post.| 1 = i = n} A ii 23 2323 // tr= {.pre , post.| \n1 = j = m} A jj tr:= \u00d8 A 1212 for each .pre , post12. in tr A 12| k := |post for each set of indexes \nI := {i1,...,ik} s.t. 1 = il = m for all l =1,...,k {// cover I with maximally-consistent // (possibly-overlapping) \nsets cover := \u00d8 // map: P(I) to pairs of pre/post conds for each J . I { if not exists K . domain(cover) \ns.t. J . K {// J not subsumed by other index set in cover 13 12 . .|J| 23 pre := simplify-pre(pre j=1 \nwp(pre ,tj )) ij 13 23 post:= |J| } j=1{simplify-term(t[a . tj ]) | t . post ij 13 if pre is consistent \n{// remove all index sets K subsumed by J cover := cover \\{K .. ....| K . J}// add J to cover 13 cover \n:= cover . [ J .. DDNF(.pre , post13.)] }}} 13 13 tr:= tr. image(cover) AA } } 13 return tr A } Figure \n5. Composition algorithm for conditional transformers. 4.1 Composition of Conditional Transformers The \ncomposed transformers can be viewed as relating values in three domains: (A1), (A2), and (A3), where \ntr12 transforms values between (A1) and (A2), and tr23 transforms values between (A2) and (A3). The key \nto composition is to express the restriction imposed by the composition of tr12 and tr23 on the values \nof (A2) AA as restrictions on (A1) and (A3). Intuitively, our composition algorithm operates in two stages, \ndepicted in Fig. 1(c): (I) computing the reverse image of preconditions of tr23 under A the transformer \ntr12 A . The result is that all preconditions in tr23 A , previously expressed in (A2), are now expressed \nin (A1). (II) computing the forward image of the postconditions of tr12 A under the transformer tr23 \nA . The result is that all postcondi\u00adtions in tr12 A , previously in (A2), are now expressed in (A3). \nTo make the composition process feasible, our approach lever\u00adages the structure of transformers. Fig. \n5 shows the pseudo-code of the composition algorithm of conditional micro-transformers. Note that the \ncomputation of pre 13 corresponds to the intuitive step (1) above (realized as computation of the weakest \nprecondition). Note that the computation of post13 corresponds to the intuitive step (2) above (realized \nas substitution). Both steps are making calls to simpli.cation procedures. Also note that the iteration \nin the algorithm is required to handle postcondi\u00adtions with multiple terms, and it guarantees that all \ncases are cov\u00adered. The following example illustrates how the composition algo\u00adrithm obtains a summary \nusing the typestate abstraction of Exam\u00adple 3.8. EXAMPLE 4.1. We illustrate how the composition algorithm \nob\u00adtains a summary of the procedure readData shown in Fig. 2 from those of init and process. The summary \ntrinit AS\u00d7Q(.a, s.) for init is shown in Table 1. Consider the composition of the .rst case of the summary \nfor init .p1(r),dopen(p2(r)). if p . M with the following case of the summary trprocess(r) for process: \nAS\u00d7Q .p1(r),dclose(p2(r)). if this.f . M We use t(r) to denote the term .p1(r),dopen(p2(r)).. First, \nthe composition algorithm .nds a new precondition on the values of input parameter r and the query parameter \nq under which the output value t(r) of init satis.es the precondition this.f . M of process. Towards \nthis end, we compute the (generalized) weakest precondition of this.f . M, as described in Section 4.2. \nwp(this.f . M, t(r)) = p . M The result is conjoined with the precondition p . M , which hap\u00adpens to \nbe the same syntactically, in this simple example, there\u00adfore, the new precondition is consistent. Under \nthe new precondi\u00adtion, we replace r by .p1(r),dopen(p2(r)). in the postcondition .p1(r),dclose(p2(r)). \nof process. After simpli.cation, we get the postcondition .p1(r),dclose(dopen(p2(r))). Now consider the \ncomposition of the third case of the summary of init with the same case of the summary of process. The \nweakest precondition for this.f . M is the same as before, because the query does not depend on r. We \nconjoin the weakest precondition p . M with the precondition .p, p1(r). .. pts from init. The consistency \nchecker .nds out that the new precondition is inconsistent with the integrity rule if p . M then .p, \np1(r).. pts . Hence, the algorithm does not generate a new postcondition for this combination of cases. \n. 4.2 Weakest Preconditions To obtain a composed transformer, we use the operation wp to express each \nprecondition pre 23 that appears in tr23 and refers to jA the intermediate state in (A2), in terms of \nthe initial state, in (A1). The weakest-precondition operation wp for code fragment s takes as input \na precondition pre and a term t, and returns a boolean combination of preconditions. Formally, given \na code fragment s2, a precondition pre . s2 P reA (a, q), and t . TAs .A(a), we de.ne wp inductively \non the syntax of pre: def wp(pre, t)= wp(pre1,t) . wp(pre2,t) if pre is pre1 . pre2 . \u00acwp(pre1,t) if \npre is \u00acpre1 . ... . lift(.j (q), invert(trs )) if pre is t. . .j (q) or t B,t= .j (q), .. def and t. \n.TAs .B (a),t= t.[a . t] . . pre[a . t] otherwise The weakest precondition is closed under conjunction, \nas usual. It is also closed under negation, because all transformers that we use are deterministic. For \nthe base case of a precondition, a query in CAs (a, q), we use substitution, as usual, when the query \nis inde\u00adpendent of q. Recall from De.nition 3.10 that if .j (q) is used in a precon\u00addition query then \nthen micro-transformer trB must be invertible. When the query is of the form t . .j (q), or t = .j (q), \nwe com\u00adpute weakest precondition using invert for transformer trB and lift. The idea for handling weakest \nprecondition computation of a set membership query of the form t . .j (q) is to break it down into equality \nqueries on the underlying domain, compute the weak\u00adest precondition in the underlying domain, and lift \nthe result back to a membership query in the powerset domain. Intuitively, this cor\u00adresponds to observing \nthe effect of an update on a set membership query by observing its effect on individual members of the \nset. Technically, we compute weakest precondition pointwise, where invert(trB,t) operation, de.ned in \nSection 3.2.2, computes the re\u00adverse image of trB , and the lift replaces every equality queries over \nB by membership queries over P(B). The invert operation is implemented as: nki def invert(trB ,t)= .. \nsimplify-pre(t = tl . prei) i=1 l=1 For each term tl in a postcondition of trB , we unify t with tl and \nconjoin it with the corresponding precondition to get a condition on b that guarantees that the result \nof applying transformer trB to b is t. Since trB is invertible, the result of simpli.cation is a disjunction \nof preconditions each of which is of the form b = t. . pre1, where t. . TA.B (a) and b does not occur \nin pre1. This syntactic form allows us, for instance, to lift each pointwise query b = t. that appears \nin invert(trB ,t) to the membership query t. . .j (q). Formally, lift(.j (q),.) is de.ned inductively \non the syntax of .: def lift(.j (q),.)= . lift(.j (q),.1) . lift(.j (q),.2) if . is .1 . .2 lift(.j \n(q),.1) . lift(.j (q),.2) if . is .1 . .2. \u00aclift(.j (q),.1) if . is \u00ac.1 . t. . .j (q) if . is b = t. \nand .j (Q)= P(B) = .j (q) if . is b = t. and .j (Q)is not P(B). t. . . otherwise EXAMPLE 4.2. The weakest \nprecondition used in Example 4.1 is generated by breaking the weakest precondition computation to work \npointwise on the underlying domain. init wp(this.f . M, t)= lift(M, invert(trAP , this.f )) To compute \ninvert(trinit AP , this.f), we use the micro-transformer trinit AP shown in Table 1. After unifying this.f \nwith each term in the postcondition of trinit AP , and conjoining it with the corresponding precondition, \nwe get the following cases: this.f = d . p2(d)= f ..p1(d), this../alias this.f = d . p2(d) .= f . d .= \np this.f = this.f . d = p this.f = p . d = p We simplify and check consistency of each of these cases. \nThe .rst case implies that .p1(this.f), this../alias and after sim\u00adpli.cation of car and tuple-constructor, \nwe get .this, this../alias. The consistency checker detects inconsistency with the re\u00ad.exivity property \nof alias. The last case is inconsistent because this.f . = p (recall that this is a syntactic equality \nof access paths). Only the third case survives the consistency check and we get that invert(trinit = \nLifting this equality con- AP , this.f) is dp. straint back to the powerset domain yields the membership \nquery p.. . M, as a result of wp. . Remark. In general, the result of wp(pre1,t) is a boolean com\u00adbination \nof conditions, whereas the syntax of conditional micro\u00adtransformers does not allow disjunctions in preconditions. \nThere\u00adfore, in the algorithm shown in Fig. 5, we use the operation DDNF, de.ned as follows: DDNF(.pre, \npost.)= {.pre . , post.| pre . . DDNF(pre)} where DDNF(pre) converts a boolean combination of conditions \npre into an equivalent disjunction of disjoint consistent precondi\u00adtions. In the worst-case, this operation \ncan cause exponential blow\u00adup. In practice, the size of the composite transformers and their pre\u00adconditions \nis expected to remain small, because many of the gen\u00aderated preconditions are inconsistent. Our experiments \nin Section 6 support this hypothesis. 4.3 Consistency Checking and Simpli.cation The composition algorithm \nrelies on the computable operations simplify-term and simplify-pre on terms and preconditions, respec\u00adtively, \nto limit the size of its result without losing precision. These operations are essential for showing \nthat the language of summaries is .nite and that the algorithm for generating summaries (Sec\u00adtion 5.1) \nterminates. In addition, the weakest precondition computation (described in Section 4.2) depends on the \nability of simplify-pre to produce a new precondition whose pointwise representation can be lifted and \nexpressed in terms of the query parameters. Intuitively, the purpose of simplify-term and simplify-pre \nis to replace nested terms and complex preconditions by equivalent sim\u00adpler ones. The challenge in simplify-term \nis to handle postconditions with nested functions, whose semantics depends on the domain A. For example, \nthe result of composition shown in Example 4.1 contains the term dclose(dopen(p2(r))) with nested d functions, \nalthough the input micro-transformers did not have nesting. Subsequent compo\u00adsitions might create deeper \nnesting of d functions. In Section 5.2.3, we show how to simplify nested ds and guarantee that their \nsize is bounded. The main challenge in simplify-pre is checking consistency, tak\u00ading into account integrity \nrules IR, properties Prop, and structural rules for tuple-constructors and selectors, e.g., pi(....,ai,....)= \nai. 3 In particular, the consistency check guarantees that all precon\u00additions in the composite micro-transformer \nare consistent. 4.4 Properties of the Composition Algorithm def Consider a (top-level) abstract domain \nA = P(Q). Given abstract transformers tr12 , tr23 : A.A, expressed by micro-transformers tr12 Q , respectively, \nwe generate an abstract transformer that Q , tr23 captures the composed effect of tr12 and tr23. The \nresult is an ab\u00adstract transformer expressed by the micro-transformer that captures the composed effect \nof tr12 Q and tr23 Q : , tr23Q , tr23 compose(tr12 )= .X. compose(tr12 Q )(x) x.X The composition algorithm \nfor micro-transformers is in Table 2. DEFINITION 4.3 ( Compatible Transformers). Abstract transform\u00aders \ntr12 and tr23 are compatible iff they are expressed using com\u00adpatible micro-transformers. Micro-transformers \ntr12 and tr23 are AA compatible iff one of them is identity, or both are pointwise, or both are separable, \nor both are conditional, and the micro-transformers for all components of A are compatible. In particular, \nif trAA 12 is a pointwise micro-transformer and tr23 is a conditional micro-transformer, then they are \nnot compatible. The following theorem states that given two abstract transform\u00aders tr12 , tr23 : A . \nA that are compatible and de.ned by micro\u00adtransformers, as in Section 3.2, the compose algorithm computes \ntheir functional composition. Moreover, the result is a transformer also expressed by micro-transformers. \nTHEOREM 4.4 (Composition Algorithm). If tr12 , tr23 : A.A are compatible abstract transformers, the result \nof compose(tr12 , tr23) is a transformer that is also expressed via micro-transformers and computes the \nfunction .a.tr23(tr12(a)). Let T denote the set of abstract transformers of basic statements that satisfy \nthe following properties: (a) every abstract transformer is expressed by micro-transformers, (b) all \nmicro-transformers for 3 Extension of the Theory of Lists (Nelson and Oppen 1980) to k-tuples. the same \ndomain A are compatible. The language of summaries, denoted by L, is the closure of T under composition. \nThe following theorem de.nes suf.cient conditions of simplify-term and simplify-pre that guarantee that \nthe language of summaries is .nite. If the language L is .nite, then the algorithm for computing procedure \nsummaries terminates and produces .nite summaries. 5.2.1 IFDS In a (speci.c) IFDS problem (Reps et al. \n1995), the data.ow facts are known D = {d1,...,dk}. The speci.c abstract domain is P(D). The abstract \ntransformers for basic statements are of the form: tr(X)= d.X trD(d) where trD is a conditional micro\u00adtransformer \nof the form .. . S1 d = d1 ... ... Sk d = dk THEOREM 4.5 (Finite Language of Summaries). The language \nof summaries L is .nite if the following properties hold: trD(d)= 1. Bound on the size of terms: for \nevery code fragment stmt, there exists a bound K such that for every pair of terms t1(a) and and Si . \nD for all i 1,...,k. In particular, all preconditions t2(a) over stmt, |simplify-term(t2(t1(a)))|= K. \n2. Bound on the size of preconditions: for every code fragment = in the conditional transformers for \na speci.c IFDS domain are stmt, there exist a bound N such that for every pair of pre\u00adconditions pre1 \nand pre2 over stmt, |simplify-pre(pre2 . pre1)|= N. When the micro-transformers contain function symbols \nor in\u00adtegrity rules, the user of our framework need to supply appropriate simplify-term and simplify-pre. \n  5. Generating Procedure Summaries In this section we describe how the composition algorithm is put \nto use in a general framework for generating procedure summaries and show how to instantiate the framework \nfor several applications. always of the limited form d = di for some 1 = i = k, i.e., the preconditions \ndo not refer to query parameters; all postconditions are subsets of data.ow facts. An example transformer \nis shown in Example 3.7. 5.2.2 IDE A (speci.c) abstract domain for IDE problems (Sagiv et al. 1996b) \ndef with environment D . L is de.ned by Env = P(D \u00d7 L) with deterministic property, and the symbols are \nknown D = {d1,...,dk}. Note that the abstract domain has no parameters, as we are encoding a speci.c \nIFe problem, in contrast to a modular version of an IDE problem, considered in Section 5.2.4. The abstract \ntransformers are tr(env)= .d,l..env trD\u00d7L(.d, l.) where trD\u00d7L is a conditional micro-transformer of the \nform  5.1 Framework .. . post1 d = d1 ... ... postk d = dk Our framework computes procedure summaries \nby performing ab-trD\u00d7L(.d, l.)= stract interpretation over a domain in which the abstract values are \n sets of micro-transformers. Intuitively, an abstract value at a pro\u00adgram point L represents the abstract \ntransformer for the code frag-and posti {.dj ,fdi,dj (l).| j =1,...,k}, for all i : LL captures the effect \nthat = = ment between procedure entry and the program point L. 1,...,k. The function fdi,dj To compute \nthe summary of a procedure, our framework starts the value of di . in the input environment has on the \nvalue of dj with an initial identity transformer that maintains the original value of procedure parameters. \nIt then proceeds to compute the .xed\u00adpoint of propagating this initial transformer through the procedure. \nIn order to apply the effect of a statement to an incoming abstract value, each incoming micro-transformer \nis composed with the basic transformer of the statement. In order to apply the effect of a procedure \ninvocation to an incoming abstract value, each incoming micro-transformer is composed with the summary \nof the invoked procedure (after replacing formals with actuals). When the analysis of a procedure reaches \na .xed-point, the summary of the procedure is the set of micro-transformers at the point of procedure \nexit. Join Operation Our framework supports an optional join opera\u00ad 1 tion for micro-transformers. Given \ntwo micro-transformers trA and 2 12 trA, we de.ne a join operation trA . trA such that it emulates the \n12 join of the underlying domain A transformed by trA and trA. That 12 12 is, for every a in A, (trA \n. trA)(a)= trA(a) . trA(a). Remark. Our framework is designed for abstract domains with .nite-height. \nFor in.nite-height domains, precise procedure sum\u00admaries are not well-de.ned because termination of abstract \ninter\u00adpreter is achieved using widening, which does not guarantee pre\u00adcision, e.g., result may depend \non order of chaotic iteration. It is possible to encode widening in our framework, similarly to join, \nbut we lose the ability to guarantee precision.  5.2 Applications First, we show that speci.c IFDS and \nIDE problems can be en\u00adcoded in our framework. Second, we show that parametric version of interesting \nIFDS and IDE problems can be encoded in our frame\u00adwork: typestate veri.cation with aliasing and constant \npropagation with aliasing (the latter requires join). in the output environment. The ef.cient representation \nof functions fdi,dj , which is one of the requirements in the IDE framework, guarantees that (i) the \njoin operation on micro-transformers can be implemented using the join for L, and (ii) simplify-term \ncan be implemented using the composition for L such that there is a bound on the size of terms. 5.2.3 \nTypestate We have described the domains used for our typestate abstraction in Example 3.3, and the structure \nof typestate transformers in Ex\u00adample 3.8. Fig. 6 shows the conditional micro-transformers for up\u00addating \na pair r . AS \u00d7Q under a typestate operation x.op(), and allocation. It uses the query parameters pts \nand M where the transformer trAP is invertible. Fig. 7 shows the conditional micro\u00adtransformer for updating \nmust information under the basic state\u00adments. The query parameter alias is used to perform strong update \nfor x.f = null. We do not show statements for which the trans\u00adformers are identity. Note that the typestate \nabstraction of (Fink et al. 2006), which we follow in this example, treats branch state\u00adments as identity. \nWe show that for a given procedure P , the summaries for AS \u00d7Q domain are of bounded size. The dif.culty \nis that after substitution, the postcondition of a case can contain terms t with arbitrarily nested d \ns. We simplify these terms using the fact that they represent states of the .nite-state automaton F, \nas follows. We say that terms t, t. . S * are equivalent when for all states q . Q, t(q) and t.(q) is \nthe same state. The idea is to keep only the shortest term from each equivalence class of this relation. \nThe length of shortest terms t is bounded by the diameter of F. (This is not a problem in practice, because \nthe automata we consider, which represent typestate properties, are usually small.) Statement trAS\u00d7Q(M)(r) \nx.op() .a, dop(s). .x, a. . pts . x . M .a, dop(s)., r .x, a. . pts . x /. M r .x, a. /. pts x = new \naL .aL, sinit. r r = . r .= . Figure 6. Typestate abstraction: transformers for a pair r of def def \ntracked allocation site a = p1(r), and its typestate s = p2(r). Statement trAP (a)(d) x = null d p1(d) \n.= x x = y d, .x, p2(d). p1(d) = y d p1(d) .= y x = y.f d, x.. d = y.f d d .= y.f x.f = null d p2(d) \n= f . \u00ac.p1(d), x. . alias d p2(d) .= f x.f = y d, x.f d = y.. d d .= y.. x = new aL x.. d = . . a = aL \nd d .= . . p1(d) .= x Figure 7. Typestate abstraction: transformers for an access path d. However, it \nis worth noting that the size of a summary can be exponential in the size of VarIdP , if the procedure \ndistinguishes between different aliasing contexts. 5.2.4 Constant Propagation with Aliasing Linear constant \npropagation is a variant of constant propagation that was given an ef.cient solution by the IDE framework \nof (Sa\u00adgiv et al. 1996a). We deal with a generalization of this problem to pointers and aliasing. We \nsolve the parametric version of this problem, which allows us to generate summaries in a modular way, \nwithout knowing the rest of the program. The abstract domain, parametric in VarId and FieldId, is de.ned \nby Env \u00d7 Alias, where Env = P(CPA) with deterministic CPA = VarId \u00d7 (Z . {.}) Alias = P(AP \u00d7 AP ) with \nre.exive, symmetric, transitive An abstract value is .env, alias. where env is a set of pairs .d, l., \nd is an access path, l is an integer if the value of the access path is known to be constant l, or ., \notherwise; alias is the set of access paths that may be aliased, according to a .ow-insensitive information, \ni.e., the domain Alias is immutable. Consider the following example procedure: void cpex(T p, T q, int \ny) {if (?) { p.f = y + 5; } else { q.f = 42; }} The procedure cpex takes two parameters of type T, and \nan integer parameter. We assume that the type Thas an integer .eld f. The procedure assigns the .eld \nffor the object pointed to by either qor p. An abstract transformer for CPA is de.ned by trEnv\u00d7Alias(.env, \nalias.)= trEnv(env) \u00d7{alias} trEnv(env)= { .d,l..env trCPA(.d, l.)} and trCPA(.d, l.) is a conditional \nmicro-transformer that depends on the statement. The micro-transformers for q.f = 42 and p.f = y + 5 \nare: trq.f = 42 (.d, l.)= .CPA .d, 42. d = q.f ..d, 42.. d = q.f . p2(d)= f ..q, p1(d).. alias . l = \n42 . .d, .. d .= q.f . p2(d)= f ..q, p1(d).. alias . l .= 42 ..d, l. otherwise . trp.f = y + 5 (.d, \nl.)= CPA . \u00d8 d = p.f .d, l., .p.f, l +5. d = y.. .d, l. d .= p.f . d .= y.. . p2(d)= f. . . .p, p1(d).. \nalias . l . = ...y, l - 5.. env .d, .. d .= p.f . d .= y.. . p2(d)= f. .p, p1(d).. alias . l .. env = \n...y, l - 5. / . .d, l. otherwise . Note that the micro-transformers use the query parameters alias. \nAlso, the micro-transformer trp.f = y + 5 , which de.nes the CPA effect on the elements of env, uses \nenv as a query parameter. This kind of dependency is supported by our composition algorithm, because \nCPA is invertible. If the input access path d may be aliased with p.f, then the assignment p.f = 42may \nmodify the value of d in env, denoted by l. If l is the same as the value of y - 5 in env, the new value \nof d is l. Otherwise, the result is .. Note that we do not need to know what the value of y is, only \nwhether it is the same as l - 5 or not.  6. Prototype Implementation We have implemented a prototype \nas a proof-of-concept for our approach. This prototype is capable of analyzing Java programs and computing \nprocedure summaries. We used our prototype to compute summaries of several small benchmarks. The goals \nof our experiments are: (i) to validate the correctness of the derived summaries; (ii) to evaluate the \nsizes of summaries in practice, and in particular check whether summaries grow expo\u00adnentially. We have \nintegrated our algorithm into the analysis framework of (Fink et al. 2006). We use this to drive our \nsummary compu\u00adtation. For some examples, we used this to validate the results of summarization against \nresults of a whole-program analysis. The heart of our implementation is the symbolic composition algorithm \nof Section 4. For conditional micro-transformers, we im\u00adplemented an incremental version of Fig. 5. This \nalgorithm requires non-trivial consistency checking and simpli.cation of formulas. Ef\u00adfectively, the \nprocedure simplify-term and simplify-pre are imple\u00admenting consistency checkers specialized for the typestate \ndomain with must information for access paths of length up to 1. The experiments described in Table 3 \nwere used as a prelimi\u00adnary evaluation of our composition algorithm and for studying the behavior of \nsummaries. We only report a narrow view of the re\u00adsults that is indicative of the maximal sizes of summaries \nfor our benchmarks. The .rst three benchmarks in the table are small examples: the running example, a \nrecursive example, and an example of simple composition. Next is the library of Ganymed SSH-2 for Java, \nfol\u00adlowed by benchmarks from the The Ashes suite. Every row in the table corresponds to the analysis \nof a benchmark with a typestate property. The typestate property describes the correct behavior of the \ntype shown in the table. For every experiment, we report the number of procedure nodes (i.e., nodes in \nthe call graph) summarized (sum), the number of pro\u00adcedure summarized into skip (skipsum). We refer to \nthe number of compositions used to create a summary as the rank of the summary, and also report the maximal \nnumber of compositions used to create a summary (MR). We only report data for procedure summaries, and \nnot for intermediate summaries created during the analysis of bench property sum skip sum MR Typestate \nMust cases @MR avg. pre max #case cases @MR avg. pre max #case Running .lecomp 15 8 9 13 2.92 13 32 5.16 \n32 Recursive .lecomp 15 7 6 6 1.67 6 5 1.6 5 Simple .lecomp 16 8 6 6 1.67 6 5 0.4 5 Ganymed socket 2353 \n2092 11 704 8.55 704 6 1.83 6 transmgr 2356 2102 37 145 7.23 145 11 2 11 session 2356 2133 4 4 1 4 1 \n1 1 jlex stack 737 643 5 3 0.66 3 1 0 1 printstr 697 593 7 40 5.25 64 1 0 1 enum 733 632 19 268 5.11 \n272 1 1 1 rhino printstr 1266 1056 9 512 9 512 1 0 1 Table 3. Sample experimental results. a procedure. \nWe also report the maximal number of cases in sum\u00admaries of the maximal rank (cases @MR), and the average \nnumber of terms in their preconditions (avg. pre). These are the dominant factors in the size of our \nsummaries, and should give an impression of the maximal summaries used in a program. In addition to these, \nwe also report the maximal number of cases observed in a summary of any rank (max#case). Our experiments \nshow that our composition algorithm can be used to successfully summarize procedures of real (albeit \nsmall) programs. A more subtle point is that they also show that sum\u00admaries can sometime decrease in \nsize (in this table, only for JLex). For some of our benchmarks, the required must alias informa\u00adtion \nis rather limited. For example, for the Stack type in JLex, only a single instance is created, and it \nis used without aliases, and never passed as a parameter. Similar simple usage patterns are ob\u00adserved \nfor Sessionin Ganymed. There are interesting trade-offs between the cost of simpli.ca\u00adtion and the sizes \nof summaries, as well as many other implemen\u00adtation details. These are beyond the scope, and space limitations, \nof this paper. The prototype is not yet engineered to compete with the opti\u00admized implementation of (Fink \net al. 2006). We plan to develop a robust implementation of our composition algorithm that will enable \nus to compare modular analysis to (Fink et al. 2006). In practice, a combination of symbolic summaries \nand explicit input\u00adoutput tables may be used for optimizing performance. 7. Related Work Interprocedural \nand modular analyses General approaches to interprocedural analysis are described in (Sharir and Pnueli \n1981; Cousot and Cousot 1978). Already in (Cousot and Halbwachs 1978), it is shown that a procedure s \neffect can be computed using linear-relation analysis. In (Cousot and Cousot 2002), the general concept \nof symbolic relational separate analysis is described, but does not provide languages for expressing \nprocedure summaries. Our approach could be thought of as a realization of this concept providing specialized \nlanguages for expressing procedure sum\u00admaries. Precise and ef.cient interprocedural data.ow analysis \nalgo\u00adrithms are presented in (Reps et al. 1995; Sagiv et al. 1996b) for special classes of problems. \nIFDS problems (Reps et al. 1995) can be encoded in our approach, by representing each .ow fact as a propositional \nparameter. IDE problems (Sagiv et al. 1996b) can be encoded by representing each symbol of an environment \nas a basic parameter. In contrast to (Sagiv et al. 1996b), we consider in Section 5.2.4 the problem of \nlinear constant propagation in presence of aliasing and in a modular setting, where the variables in \nthe rest of program are unknown. It is not clear whether this problem can be encoded in the IDE framework \n(in a na\u00a8ive encoding, the set of symbols would not be .nite). Precise and ef.cient interprocedural analysis \nof (M\u00a8uller-Olm and Seidl 2004), specialized for .nding all af.ne relationships between program variables, \nsubsumes the problem of linear constant propagation considered in (Sagiv et al. 1996b), but does not \ndeal with aliasing. It is challenging to compute precise procedure summaries for an arbitrary calling \ncontext. To enable modular analysis, many analyses compute approximate summaries. A common approach is \nto analyze the procedure in a symbolic context. For example, (Ball et al. 2005) introduces auxiliary \nvariables to record the input values of the procedure, and uses predicates de.ned by both the program \nvariables and the auxiliary variables. Then, the result of the analysis can be interpreted as a relation \nbetween the auxiliary variables, which denote input values, and the output values. However, the predicates \nmight not be expressive enough to capture the precise summary. In interprocedural analysis based on pushdown \nsystems, e.g., (Reps et al. 2005), summaries are created as a byproduct of an analysis. Another approach \nis to specialize the summary generation for a particular problem, to discover which contexts are relevant. \nFor example, Xie and Aiken (2005) create summaries for checking correct use of locks. They use a SAT \nprocedures to enumerate all the relevant calling contexts. Recently, Gulwani and Tiwari (2007) introduced \na method for generating precise procedure summaries in the form of constraints on the input variables \nof the procedure that must be satis.ed for some appropriate generic assertion involving output variables \nof the procedure to hold at the end of the procedure. Their method is based on computing weakest preconditions \nof a generic asser\u00adtion. To guarantee termination of the analysis, they preform second\u00adorder uni.cation \nto strengthen and simplify the weakest precondi\u00adtions. Our composition algorithm computes weakest preconditions \nof certain queries, as described in Section 4.2, and relies on simpli\u00ad.cation, but does not use strengthening. \nModular Pointer Analyses Our work has been motivated by modular points-to analysis of (Chatterjee et \nal. 1999). Their work infers distinct relevant contexts and computes precise information for each such \ncontext, parametric in aliasing between abstract loca\u00adtions at the entry of a procedure. This information \ncan be expressed using symbolic summaries with query parameters on alias and non\u00adalias. We add to these \nideas in several ways: (i) we formulate the notion of concise summaries for a more general class of summaries, \ngoing beyond the points-to setting; (ii) we add the property that our summaries are as precise as re-analyzing \nthe procedure, and this is a fundamental requirement that drives our treatment of summaries; (iii) we \nintroduce a framework that allows us to generate concise summaries for a class of abstract domains and \ntransformers. The modular pointer analysis of (Cheng and Hwu 2000) is an adaptation of (Chatterjee et \nal. 1999) to work with the entire C lan\u00adguage. From our perspective, the most notable difference is the \nfact that (Cheng and Hwu 2000) uses access paths to express context conditions where (Chatterjee et al. \n1999) only uses conditions on aliasing between abstract locations at the entry of a procedure. Modular \npointer analyses in (Whaley and Rinard 1999; Salcianu 2006) make best-case aliasing assumptions at the \nentry of a proce\u00addure, but in order to be sound, compute an approximation of the default semantics by \nnot performing strong updates (except in spe\u00adcial cases, see (Salcianu 2006)). The summary is later specialized \nfor a given aliasing situation at a call site. Because the summary computation is based on approximation \nof default semantics, the summary could be less precise than an (ideal) non-modular analy\u00adsis. Typestate \nVeri.cation DeLine and F\u00a8 ahndrich (2004,2002) present a type system for typestate properties for objects. \nThey can assume must-alias properties for a limited program scope, and thus ap\u00adply strong updates allowing \ntypestate transitions. Their approach is limited to programs for which an expression can be assigned \na unique type at a given program point. As opposed to that, our mod\u00adular typestate analysis is context-sensitive, \nmatching the precision of (Fink et al. 2006). In general, our approach for designing mod\u00adular analysis \nis an alternative for using type systems for the same domain. 8. Conclusions and Future Work For proving \nnon-trivial properties of programs, program analyses use expressive abstract domains. We aim at improving \nscalability of these analyses, without compromising the precision, by using precise, concise and ef.cient \nprocedure summaries. In this paper, we have described a class of complex abstract domains, for which \nwe can generate summaries with the desirable properties, thereby advancing the state-of-the-art in this \narea. The focus of this work has been the automatic composition of summaries (with precision guarantees). \nThis is a key step, but not the only one, in making modular analysis practical. In future work, we plan \nto explore techniques that can trade-off precision for scalability (e.g., as done in (Chatterjee et al. \n1999) by limiting sizes of conditions). Finally, the expressivity of micro-transformers is inherently \nlim\u00adited. Nevertheless, we believe that many interesting problems can be encoded using micro-transformers. \nWe plan to further investi\u00adgate the expressivity of our framework by applying it to additional problems, \nsuch as modular pointer analysis.  Acknowledgments We thank Mooly Sagiv, Noam Rinetzky, Tal Lev-Ami, \nand the anonymous reviewers for their comments on earlier drafts of this paper. References T. Ball, \nT. D. Millstein, and S. K. Rajamani. Polymorphic predicate abstrac\u00adtion. ACM Trans. Program. Lang. Syst., \n27(2):314 343, 2005. R. Chatterjee, B. G. Ryder, and W. A. Landi. Relevant context inference. In POPL, \npages 133 146, 1999. B.-C. Cheng and W.-M. W. Hwu. Modular interprocedural pointer analysis using access \npaths: design, implementation, and evaluation. In PLDI, pages 57 69, 2000. P. Cousot and R. Cousot. Modular \nstatic program analysis. In CC, pages 159 178, 2002. ISBN 3-540-43369-4. P. Cousot and R. Cousot. Abstract \ninterpretation: A uni.ed lattice model for static analysis of programs by construction of approximation \nof .xed points. In POPL, 1977. P. Cousot and R. Cousot. Static determination of dynamic properties of \nrecursive procedures. In E.J. Neuhold, editor, Formal Descriptions of Programming Concepts, (IFIP WG \n2.2, St. Andrews, Canada, August 1977), pages 237 277. North-Holland, 1978. P. Cousot and R. Cousot. \nSystematic design of program analysis frame\u00adworks. In POPL, pages 269 282, 1979. P. Cousot and N. Halbwachs. \nAutomatic discovery of linear restraints among variables of a program. In POPL, pages 84 96, 1978. M. \nDas, S. Lerner, and M. Seigle. ESP: Path-sensitive program veri.cation in polynomial time. In PLDI, pages \n57 68, 2002. R. DeLine and M. F\u00a8ahndrich. Adoption and focus: Practical linear types for imperative programming. \nIn PDLI, pages 13 24, June 2002. R. DeLine and M. F\u00a8ahndrich. Typestates for objects. In ECOOP, pages \n465 490, 2004. N. Dor, S. Adams, M. Das, and Z. Yang. Software validation via scalable path-sensitive \nvalue .ow analysis. In ISSTA, 2004. URL http://doi.acm.org/10.1145/1007515. J. Field, D. Goyal, G. Ramalingam, \nand E. Yahav. Typestate veri.cation: Abstraction techniques and complexity results. In SAS, pages 439 \n462, 2003. S. Fink, E. Yahav, N. Dor, G. Ramalingam, and E. Geay. Effective typestate veri.cation in \nthe presence of aliasing. In ISSTA, pages 133 144, 2006. J. S. Foster, T. Terauchi, and A. Aiken. Flow-sensitive \ntype quali.ers. In PLDI, pages 1 12, 2002. Ganymed SSH-2 for Java. Ganymed SSH-2 for java. http://www.ganymed.ethz.ch/ssh2/. \nS. Gulwani and A. Tiwari. Computing procedure summaries for interpro\u00adcedural analysis. In ESOP, pages \n253 267, 2007. R. Jhala and R. Majumdar. Interprocedural analysis of asynchronous pro\u00adgrams. In POPL, \npages 339 350, 2007. M. M\u00a8uller-Olm and H. Seidl. Precise interprocedural analysis through linear algebra. \nIn POPL, pages 330 341, 2004. G. Nelson and D. C. Oppen. Fast decision procedures based on congruence \nclosure. J. ACM, 27(2):356 364, 1980. S. Qadeer and D. Wu. Kiss: keep it simple and sequential. In PLDI, \npages 14 24, 2004. T. Reps, S. Horwitz, and M. Sagiv. Precise interprocedural data.ow analysis via graph \nreachability. In POPL, pages 49 61, 1995. T. Reps, S. Schwoon, S. Jha, and D. Melski. Weighted pushdown \nsystems and their application to interprocedural data.ow analysis. Sci. Comput. Program., 58(1-2):206 \n263, 2005. N. Rinetzky, M. Sagiv, and E. Yahav. Interprocedural shape analysis for cutpoint-free programs. \nIn Proc. Static Analysis Symp., 2005. M. Sagiv, T. Reps, and S. Horwitz. Precise interprocedural data.ow \nanalysis with applications to constant propagation. Theor. Comput. Sci., 167(1-2): 131 170, 1996a. ISSN \n0304-3975. doi: http://dx.doi.org/10.1016/0304\u00ad3975(96)00072-2. M. Sagiv, T. W. Reps, and S. Horwitz. \nPrecise interprocedural data.ow analysis with applications to constant propagation. Theor. Comput. Sci., \n167(1&#38;2):131 170, 1996b. A. Salcianu. Pointer Analysis for Java Programs: Novel Techniques and Applications. \nPhD thesis, Massachusetts Institute of Technology, Cam\u00adbridge, Massachusetts, USA, 2006. M. Sharir and \nA. Pnueli. Two approaches to interprocedural data ow analysis. In S.S. Muchnick and N.D. Jones, editors, \nProgram Flow Analysis: Theory and Applications, chapter 7, pages 189 234. Prentice-Hall, Englewood Cliffs, \nNJ, 1981. R. E. Strom and S. Yemini. Typestate: A programming language concept for enhancing software \nreliability. IEEE Trans. Software Eng., 12(1): 157 171, 1986. The Ashes suite. The ashes suite. http://www.sable.mcgill.ca/ashes/. \nJ. Whaley and M. Rinard. Compositional pointer and escape analysis for java programs. In OOPSLA, pages \n187 206, 1999. Y. Xie and A. Aiken. Scalable error detection using boolean satis.ability. In POPL, pages \n351 363, 2005.  \n\t\t\t", "proc_id": "1328438", "abstract": "<p>We present a framework for generating procedure summaries that are (a) precise - applying the summary in a given context yields the same result as re-analyzing the procedure in that context, and(b) concise - the summary exploits the commonalitiesin the ways the procedure manipulates abstract values, and does not contain superfluous context information.</p> <p>The use of a precise and concise procedure summary inmodular analyses provides a way to capture infinitely many possible contexts in a finite way; in interprocedural analyses, it provides a compact representation of an explicit input-output summary table without loss of precision.</p> <p>We define a class of abstract domains and transformers for which precise and concise summaries can be efficiently generated using our framework. Our framework is rich enough to encode a wide range of problems, including all IFDS and IDE problems. In addition, we show how the framework is instantiated to provide novel solutions to two hard problems: modular linear constant propagation and modular typestate verification, both in the presence of aliasing. We implemented a prototype of our framework that computes summaries for the typestate domain, and report on preliminary experimental results.</p>", "authors": [{"name": "Greta Yorsh", "author_profile_id": "81315492721", "affiliation": "Tel Aviv University, Tel Aviv, Israel", "person_id": "PP43135351", "email_address": "", "orcid_id": ""}, {"name": "Eran Yahav", "author_profile_id": "81100285431", "affiliation": "IBM T.J. Watson Research Center: NY: USA, Hawthorne, NY", "person_id": "PP14234036", "email_address": "", "orcid_id": ""}, {"name": "Satish Chandra", "author_profile_id": "81100394237", "affiliation": "IBM T.J. Watson Research Center: NY: USA, Hawthorne, NY", "person_id": "PP43119595", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1328438.1328467", "year": "2008", "article_id": "1328467", "conference": "POPL", "title": "Generating precise and concise procedure summaries", "url": "http://dl.acm.org/citation.cfm?id=1328467"}