{"article_publication_date": "01-07-2008", "fulltext": "\n Relational Inductive Shape Analysis Bor-Yuh Evan Chang University of California, Berkeley bec@cs.berkeley.edu \nAbstract Shape analyses are concerned with precise abstractions of the heap to capture detailed structural \nproperties.Todoso,theyneedtobuild and decompose summaries of disjoint memory regions. Unfortu\u00adnately, \nmanydata structure invariants require relations be tracked across disjoint regions, such as intricate \nnumerical data invariants or structural invariants concerning back and cross pointers. In this paper, \nwe identify issues inherent to analyzing relational structures and design an abstract domain that is \nparameterized both by an ab\u00adstract domain for pure data properties andby user-supplied speci.\u00adcationsofthedata \nstructureinvariantsto check.Particularly,itsup\u00adportshybridinvariants about shape and data and features \na generic mechanism for materializing summaries at the beginning, middle, or end of inductive structures. \nAround this domain, we build a shape analysis whose interesting components includeapre-analysis on the \nuser-supplied speci.cations that guides the abstract interpre\u00adtation and a widening operator over the \ncombined shape and data domain.Wethendemonstrateour techniquesontheproofofpreser\u00advation of the red-black \ntree invariants during insertion. Categories and Subject Descriptors D.2.4[Software Engineer\u00ading]: Software/ProgramVeri.cation; \nF.3.1[Logics and Meanings of Programs]: Specifying andVerifying and Reasoning about Pro\u00adgrams GeneralTerms \nLanguages,Veri.cation Keywords shape analysis, inductive de.nitions, heap analysis, separation logic, \nsymbolic abstract domain, materialization 1. Introduction Shape analyses de.ne precise heap abstractions \nto provide the de\u00adtailed aliasing and structural information often necessary for veri\u00ad.cation or program \ntransformation tasks when typically no other static program analysis can. Most shape analyses are extremely \neffective when the analysis can be done non-relationally, that is, the property of interest can be decomposed \nso that the checking of one part is (mostly) independent of the checking of others.Asig\u00adni.cant challenge \nfor almost all shape analyses is to step beyond non-relational abstractions, which become clearly necessary \nwhen combining structural shape analysis with numerical analyses. \u00b4prieure,Paris * Abstraction Project-team, \nshared with CNRS and Ecole Normale Su- Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage.To copyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. POPL 08, January 7 12, 2008, San Francisco, California, USA. Copyright c . 2008ACM \n978-1-59593-689-9/08/0001...$5.00 Xavier Rival INRIA * and University of California, Berkeley rival@di.ens.fr \n To obtain the necessary precision, shape analyses rely on spe\u00adcialized descriptions for abstracting \nmemory. In prior work (Chang et al. 2007), we proposed a shape analysis parameterized by inductively-de.ned \npredicates provided by the user. The novel as\u00adpect of our proposal is that these inductive de.nitions \ncan come from checking code, that is, code that could be used to verify data structure instances dynamically.Anice \npropertyof using invariant checkers isthatthey arenotonlyafamiliarwayforthedeveloper to describethe data \nstructureinvariantsbut alsoexpressdeveloper intent on how the data structure should be used. In some \nrespects, inductively-de.ned predicates are a natural .t for shape analysis (seemingly evidenced by the \nmany shape analyses beingbuilt around them (Lee et al. 2005; Distefano et al. 2006; Berdine et al. 2007; \nMagill et al. 2007; Guo et al. 2007)).A keycomponent of shape analysis is amaterialization (i.e., a partial \nconcretization) operation that then enables strong updates, which are critical for precision. With an \ninductively-de.ned predicate, a natural materialization operation is to unfold its de.nition. For example, \nconsider the following de.nition for an acyclic doubly\u00adlinked list: l. dll(lprev ) := if (l = null ) \nthen [] else l@next -> n * l@prev -> lprev * n. dll(l) Here, we write inductive checkers in a pseudo-code \nnotation that de.nes a class of memory regions by a traversal from a distin\u00adguished root pointer (the \ntraversal parameter).The [] indicates an end to the traversal (i.e., an empty region), while -> indicates \nthe addressandvalueofa.eld (i.e.,adereferenceofa .eld).The * in\u00addicates the components corresponding \nto disjoint memory regions (i.e., the traversal is allowed to dereference each object .eld once). New \nvariables (e.g., n )are considered as local variables bound to the value of the speci.ed .eld. In the \nabove, dll says a doubly\u00adlinked list is either empty or has next and prev .elds where prev must contain \nlprev and next must be a doubly-linked list whose prev is the current root pointer l .Asingly-linked \nlist checker is similar and can be obtained by simply dropping the constraint on prev and the lprev parameter. \nCircular lists can be described by adding a parameter for a distinguished head node and stopping the \ntraversal when the head is reached (instead of null ). The kinds of invariant checkers considered in \nour earlier paper were non-relational. At a high-level, a non-relational checker de\u00adscribes each segment \nof the data structure independently. This in\u00adcludes checkersfor singly-linked lists, singly-linked circular \nlists, trees, and skip lists,but not the dll checker. Syntactically,ina non\u00adrelational checker, the additional \nparameters of the checker (i.e., the state of the checker) are constant across all recursive calls. This \ncondition clearly holds for a stateless checker like the one for a singly-linked list. In contrast, the \ndll checker uses an additional parameter lprev to specify that the prev .eld of the next element points \nto the current element. The main dif.culty with relational checkers is that simply un\u00adfolding instances \ninto their de.nitions does not reveal these rela\u00adtions. Thus, code that utilizes such relations are not \nanalyzable without other techniques. With the dll checker, an unfolding re\u00adveals that next points to \nanother dll ,but not that prev must also point to a segment of dll, nor that next and prev are inverses \n(i.e., following next and then prev gets back to the same node). As such, analyzing code that traverses \na doubly-linked list using the next .eld with the dll checker is easier than analyzing code that traverses \nusing the prev .eld.Part of the problem is that there are a number of ways to traverse a doubly-linked \nlist (i.e., a number of inductive schemes).Forexample, an alternative checker could start at the tail \nof the list following prev .elds,but then the above dif.culty is simply reversed for the .elds. The relational \nissue becomes even more salient when we con\u00adsider inductive invariants with more involved data constraints \nthan pointer equality.Forexample, consider the following checkers: t. bst (tlo, tup ) := if (t = null \n) then [] &#38;&#38; tlo < tup else t@l -> l * t@d -> d * t@r -> r  * l. bst (tlo, d)* r. bst(d, tup \n) &#38;&#38; tlo < d < tup l. listn(llen ) := if (l = null ) then [] &#38;&#38; llen =0 else l@next \n-> n * n. listn(llen - 1)  The bst checker describes a binary search tree, while listn spec\u00adi.es a list \nof a particular length. Each of these relational check\u00aders uses parameters to capture very different \nkinds of relations and thus pose different challenges. The bst checker enforces a global ordering property \non the data .elds( d)with the range narrowing in recursive calls(the shape constrains the data), while \nlistn uses llen to specify the recursion depth(the data constrains the shape). Finally, the dll checker \ndescribes a kind of invertible structuralin\u00advariant with a data structure that points to previous roots. \nIn this paper, we identify a dividing line in the complexity be\u00adtween non-relational and relational inductive \nshape analysis. We extend our earlier work to the relational case and make the follow\u00ading contributions: \n We propose a parametric abstract domain for relational induc\u00adtive shape analysis. Our domain is not \nonly parameterized by programmer-suppliedinvariant checkers,but alsobya numeri\u00adcal domain for data constraints \n(Section 3). In order to support relational shape analysis, we strengthen prior notions of partial checker \nruns, which are used to abstractmemory regions where user-supplied invariants hold only partially.  \nWeobservethat shape analysis with invertible checkers, such as dll , can be strengthenedwith a notion \nof backwardunfolding. The novel aspect of our proposal is that the backward unfolding operation can be \nderived automatically from the standard for\u00adward unfolding (Section 5.1). Another interesting aspect \nis that we use a pre-analysis on checkers, in particular, a type infer\u00adence, to guide the abstract interpretation \n(Section 4).  Wedescribehowour shape domain interacts withexample base data domains in the abstract \ninterpretation phase to compute precise .xed-point invariants. In particular, we show that the widening \nrequires careful coordination between shape and data (Section 5.2).  In the next section, we highlight \nthe challenges that we aim to address in this paper with an example analysis of red-black tree insertion. \nAfter describing our analysis, we return to this example in Section7to indicatehowour algorithmcanbeusedtoverifythe \ncorrectness of operations on such complex data structures. 2. Background and Overview To set the stage \nfor this paper, we .rst present the basic ideas of inductive checker-based shape analysis by tracing \nthrough the ex\u00adample in Figure 1. Our shape analysis is a standard forward ab\u00adstract interpretation (Cousot \nand Cousot 1977) that computes an typedef struct RBNode {struct RBNode *l, *r, *p; // left child, right \nchild, parent int d; color clr; // data, color } RBNode; void insert(RBNode **t, RBNode *n) { RBNode \n*pa, **sonp, *son;  1 .  pa = null ; sonp = t; 2 while (*sonp != null ) {3 pa = *sonp; 4 if (n->d < \npa->d) sonp = &#38;(pa->l); 5 else if (n->d > pa->d) sonp = &#38;(pa->r); 6 else return; 7 alo <ad <.d \n<aup alo = \u00dflo <\u00dfd <.d <\u00dfup = aup } 8 n->p = pa; n->clr = RED;  9 . *sonp =n;son= n; 10 while (pa \n!= null ) { 11 if (pa does not locally satisfy the red-blackinvariants) { 12 ... perform rotations to \nreestablish invariants ... 19 } 20 son = pa; pa = pa->p; 21  } 22 son->clr = BLACK; *t = son; } First \nIteration At Fixed Point Figure 1. Red-black tree insertion in C. abstract memory state at each program \npoint. In the .gure, we show the abstract memory state of the analysis at a number of program points \nusing a graphical notation. For the program points inside loops, we give two memory states: one for the \n.rst iteration (left) and one for the .xed point (right). Our memory abstractionisbuilt around using \nuser-supplied inductive checkers to summarize mem\u00adory regions. Intuitively, a programmer-de.ned checker \ndescribes the class of memory regions arranged according to particular con\u00adstraints on which an execution \nof the checker would succeed. In a graph, each node denotes a value (e.g., a memory address) and, when \nnecessary, is labeled by a symbolic value. Symbolic values areexistentially quanti.edvariables usedto \nnameheap objects.To distinguish them from program variables, we use lowercase Greek letters( a, \u00df, ., \n...). A program variable (e.g., pa )below a node indicates that thevalueof thatvariableis that node. \nEdges describe disjoint memory regions.Athin edgegivesa points-to relationship, that is, a memory cell \nwhose address is the source node and whose value is the destination node. To keep the diagram compact, \nwe draw points-to edges only for the pointer .elds, and, when neces\u00adsary,we notatethevaluesofdata .eldsabovethenode(e.g.,atpro\u00adgrampoint7).Athickedge(a \nchecker edge) summarizesamemory region, that is, some number of points-to edges with certain proper\u00adties. \nThere are twokinds of checker edges: complete checker edges, which have only a source node, and partial \nchecker edges, which have botha source anda target node. Complete checker edges indi\u00adcate memory regions \nthat satisfy particular checkers (e.g., on line1, the complete checker edge labeled rbtree says the memory \nregion from a satis.es the red-black tree checker).To describe memory states at intermediate program \npoints, partial checker edges cap\u00adture the notion of a checker that holds on just a segment of a data \nstructure.Forexample,at programpoint7inthe.xed-point graph, the partial checker edge from a to \u00df summarizes \na memory re\u00adgion that is a rbtree along that segment.For data constraints, our memory abstraction is \nparameterized by a base abstract domain whose coordinates (i.e., variables) are the symbolic values. \nIn the examples, we note the data constraints that are necessary to get the desired results and assume \nthe base domain can capture them. Amemoryupdateis capturedinthegraphby modifyingtheap\u00adpropriate points-to \nedges (performing strong updates).Forexam\u00adple, considerthe transitionfrom programpoint7to9wherewesee \nthe updating of n s parent and color .elds (line 8). In the .gure, we show only the disjunct where sonp \nwent right( r )on the .\u00adnal iteration; the case for the l .eld is similar. Sometimes, checker edges are \nunfolded to materialize the points-to edges for an update. For example, the rbtree checker edge (as on \nline 1) is unfolded to materialize the l and r .elds on lines4 and5.To reacha .xed point, we fold subgraphs \ninto checker edges.We determine where to fold in the graph (as to retain enough precision) by consulting \nthe iteration history (as described in Chang et al. (2007)). The analysisofthe red-black tree insertion \nroutine posesanum\u00adber of challenges that we aim to address in this paper. These chal\u00adlenges appear in \nboth the unfolding to materialize neededpoints-to edges and the folding to retain suf.cient precision \nin the data con\u00adstraints. In particular, while the non-relational shape analysis de\u00adscribedinourpriorworkcouldobtainthe \nstructuralinvariants(i.e., graphs)at program points1,7,and9,itwouldfailto inferthekey data constraints \nand even the .xed-point graph at point 21. To better understand these challenges, we .rst describe infor\u00admallytheinvariantsof \nthe red-black tree we consider here. The in\u00adverse invariant (cf., doubly-linked lists) speci.es that \nthe p .eld is the inverse of the l and r .elds (i.e., for each node n , if n->l .= n and analogously \nfor the r .eld). = null , then n->l->p Next, the order invariant (cf., binary search trees) says that \nfor each node n , the values in the left subtree (i.e., the value of the d .elds in the nodes reachable \nfrom n->l )are less thann->d ,and theval\u00adues of the right subtree are greater than n->d . Finally, the \nbalance invariant (cf., lists of a given length) is as follows: (a) a node is ei\u00adtherredor black(givenbythe \nclr .eld); null is considered black; (b) the root is black; (c) both children of a red node are black; \n(d) every simple path (i.e., following l and r .elds) from a node to a leaf contains the same number \nof black nodes. Observethat each of these invariants describes a relation between nodes, and in the case \nof the order and balance invariants, theydescribe a global relation on all the nodes of the tree. It \nis clear that to write code that checks this invariant, a checker needs to carry some state (in order \nto turn the global relations speci.ed above into local checks). In terms of checkers, we de.ne the following \nred-black checker for a node t : t. rbtree(tp, tlo, tup, tredok , tbh ) := if (t = null ) then [] &#38;&#38; \ntlo < tup &#38;&#38; tbh =0 else t@l -> l * t@r -> r * t@p -> tp * t@d -> d * t@clr -> c * l. rbtree \n(t, tlo, d, c .= red, ite( c = red,tbh ,tbh - 1 )) * r. rbtree (t, d, tup, c .= red, ite( c = red,tbh \n,tbh - 1 )) &#38;&#38; tlo < d < tup &#38;&#38; (c .  = red || tredok ) where ite isan if-then-elseexpression.Thekeypointisthatthe \nadditional parameters are used to impose the following constraints: tp is where the p .eld should point; \ntlo is a lower bound on the d .eld; tup is an upper bound on the d .eld; tredok gives whether the clr \nis allowed to be red; tblkht is the number of black nodes on all paths toa leaf (i.e., the black height).We \ncan see that the kindsofrelations usedbythe rbtree checker have parallels to each of the relational checkers \npresented in Section 1. As such, the red\u00adblack tree insertion routineisafairly representativeexampleof \nthe kindsof challengesin relationalshape analysis.Intheexample.g\u00adure, we have elided the additional parameters \non the instances of rbtree. Instead, we adopt the convention of referring to the ad\u00additional parameters \nby subscripting the node name on which the checker applies.Forexample, the checker edge on line1 conveys \nthe following: a.rbtree(ap,alo,aup,aredok ,abh) where any con\u00adstraints on the additional parameters are \ngiven in the data domain. Returning to the example analysis in Figure 1, we comment on the points where \nthe relational aspect of the rbtree checker poses obstacles to overcome in the analysis. First, consider \nthe memory state at program point 21 in the .rst iteration. Note that the value of pa is . , which has \nno outgoing edges from it (neither points-to nor checker). However, on the next iteration, we will analyze \nstatements that access the .elds of pa and thus need to materialize them. From our intuitive understanding \nof the rbtree checker, we know that . lies on the segment between a and \u00df (when it is non-empty), so \nif we were to unfold the segment backward from \u00df , we could materialize the .elds of . .To justify the \nunfolding of partial checker edges, we must strengthen the logical representation of such segments (Section \n3.1). The novel aspect of our proposal is that we determine when to apply this backward unfolding automatically \nusingapre-analysis on checkers (Section4).Wealso reducethe soundness justi.cationofbackward unfolding \nto that of forward unfolding (Section 5.1.1). In other words, while the user supplies the forward unfolding \naxiom (as an inductive checker de.nition), the backward unfolding is derived automatically and not axiomatized \n(cf., Berdine et al. (2007)). Second, consider the memory states at program point 7, which is a location \nwhere the combination of shape and relational data constraintsposes challenges.Wegetthedata constraintsinthe.rst \niteration simply by unfolding rbtree and from the guard on the conditional. The challenge is on widening \nto generate the .xed\u00adpoint invariant. In this example, we need the underlined constraint to know that \nthe insertion preserves the orderinginvariant,butitis not necessarilyeasy to obtain. At a high-level, \nthe core of the dif.\u00adcultyisthatwhilethetopofthetreecanbefairlyeasily summarized into the segment from \na to \u00df , the data invariant we desire requires synthesizing relations between the pre.x segment( a to \n\u00df )and the suf.x (from \u00df ).To address this dif.culty, we make some observa\u00adtions that allow us to apply \nof some standard analysis techniques in this context. One, we observe that because the coordinates of \nthe data domain are given by heap nodes, the data domain is rather sensitiveto the large changes that \nresult from widening in the shape domain. Thus, we delay widening elements of the data domain until the \nshape portion has converged (keeping symbolic joins instead). Two, we notice that we can separate this \nsynthesis task into .nding appropriate arguments for the checker parameters and inferring the appropriate \nrelation on those arguments. Speci.cally, we can make the .nding of checker arguments shape-guided by \nusing additional data .elds that correspond to the checker parameters. 3. Memory Abstraction with Inductive \nSegments The core component of our analysis state is an abstract memory state M (as shown in Figure 2). \nThe memory state is based largely on separation logic (Reynolds 2002), so we use notation that is bor\u00adrowed \nfrom there. The .rst three items are as in separation logic: emp is the empty memory, a@f .. \u00df is a points-to \nrelation de\u00adscribing a single memory cell, and M0 * M1 is the separating memories M ::= emp empty | a@f \n.. \u00df memory cell | M0 * M1 disjoint regions | a.c(d) checker region | a.c(d) *= a..c.(d.) checker segment \ndata constraints P . P. environment E ::= \u00b7| E, x ..a analysis state A ::= .|.E, M, P .| A1 . A2 symbolic \nvalues a . Val. .eld names f program variables x . Var checker names c Figure 2. Analysis state. conjunction \nspecifying a memory that can be divided into two dis\u00adjoint regions (i.e., with disjoint domains), which \ntogether can sym\u00adbolically describea .nite memory.A.eldoffsetexpression a@f corresponds to the base address \na plus the offset of .eld f (i.e., &#38;(a.f) in C).For simplicity, we assume that all pointers occur \nas .elds in a struct . Also for simplicity in presentation, we con\u00adsideronly symbolicvaluesontherightsideof \npoints-to( \u00df )(i.e., for the contents of memory cells) and assume anyadditional con\u00adstraints on those \nvalues are captured elsewhere (e.g., is null). The next twoitems are used to summarize memory regions. \nAn applica\u00adtion of a user-supplied checker a.c(d) describes a memory region where c succeeds when applied \nto a and d .For presentation, we write checkers with one traversal parameter and one additional pa\u00adrameter, \nthough everything applies to checkers with zero-or-more additional parameters. The last item provides \na generic mechanism for specifying segments of user-supplied checkers, which we will describe further \nbelow. In Figure 2, we show the correspondence between formulas and graphs. The thick edges (for checker \nregions and checker segments) can be intuitively thought of as representing possible subgraphs of thin \npoints-to edges arranged in particular shapes and with certain constraints. Inductive Checker De.nitions. \nFormally, the de.nition of a checker c , with traversal parameter p and a sequence of zero\u00ad . or-more \nadditional parameters -. , is a .nite disjunction of rules. A rule R consists of a conjunction of a memory \nportion M and a pure portion F (given as a .rst-order formula). Further, M is separated into two parts: \nan unfolded region Mu given by a series of points-to edges and a folded region Mf given by a series of \nchecker applications. Schematically, we write checker de.nitions as follows: -.ff p.c(. ) := .M0u * M0,F0..\u00b7 \n\u00b7\u00b7..Mn u * Mn,Fn. Free variables in the rules are considered as existential variables bound at the de.nition. \nNote that because we view checkers as code, the kinds of inductive predicates are further restricted. \nIn particular, Mu correspond to .nite access paths from p and thus existentials are only for the values \nof .elds along those access paths from p . Each checker call in Mf is applied to arguments among the \nparameters (the traversal or the additional ones) or the existentials introduced in M u . These kinds \nof inductivede.nitions are apt for analysis, as we know that unfolding such a de.nition corresponds to \nmaterializing points-to edges from p . Inductive Segments. Inductive predicates from checkers, such as \ndll and rbtree, give us rather precise summaries of memory re\u00adgions,but unfortunately, they are typically \nnot general enough to capturetheinvariantsof interestatall program points.Forexam\u00adple,in Figure1at program \npoints7and9,we needto summarize the region between a and \u00df (i.e., between the root pointer *t and the \ncursor pointer pa ).As observedin our priorwork (Changet al. 2007), such segment regions are captured \nby a partial checker run. In terms of inductively-de.ned predicates, we want to describe a segment as \na partial derivation (i.e., a derivation with a hole in a subtree). In the past work, we have used the \nstandard separating implication *- from separation logic for this purpose. While suf.\u00adcient and useful \nfor summarizing segments, this de.nition does not allow for unfolding. As noted in Section 2, unfolding \nof segments, particularly backward unfolding, is often necessary with relational checkers (e.g., the \nrebalancing of the red-black tree in Figure 1). In this paper, we strengthen this connector by imposing \nan in\u00adductive structure. This additional structure then enables the de.\u00adnition of forward and backward \nunfolding schemes on segments. Informally, a.c(d) *= a. .c .(d.) is a memory region where it sat\u00adis.es \na.c(d) up to some number of unfoldings and conjoining any disjoint memory that satis.es a. .c .(d.) makes \nthe combined region satisfy a.c(d). In Section 3.1, we discuss this de.nition in further detail, and \nin Section 5.1.1, we describe and justify the unfolding operations on segments. Analysis State. To track \ndata constraints (i.e., non-points-to con\u00adstraints), we maintain a pure state P , which we assume is \nan ele\u00adment of an abstract domain P. . Note that the base data domain P. isa parameterofthe analysis.To \nconnectthe abstract memorywith the program, we alsokeep an environment E that maps program variablestosymbolicvaluesthatdenotetheir \naddresses.Finally,the overall analysis state A isa.nite disjunctionof .E, M, P . tuples. 3.1 Semantics \nof the Memory Abstraction In this subsection, we give the semantics of our memory abstrac\u00adtion.We focus \nmostly on segments, as other aspects of the graph follow mostly from separation logic.We write u . Val \nfor con\u00adcretevalues and make no distinction between addresses andvalues. Further, we write u + f for \nthe base address u plus the offset of .eld f .A concrete store s : Val ..n Val maps addresses into values.We \nwrite [\u00b7] for the empty concrete store and [u0 .. u1] for the store of one cell mapping u0 to u1 . A \ncompound store s0 * s1 isastore with disjoint substores s0 and s1 where s0 and s1 musthavedisjoint domains(i.e.,overloadingthe \noperatorsfrom the abstract memory).To capture relations among memory cells, we consider a valuation that \nessentially assigns an interpretation to symbolic values. More precisely, a valuation . : Val. . Val \nis a mapping from symbolic values into concrete values. Checker Regions. We write .s, ..|= M to mean \na concrete store s and a valuation . satisfy an abstract memory M . The semantics of a checker application \nis de.ned by induction over the height of the underlying calling tree .We write a.ci(d) for a checker \napplication of height at most i .We also write [a/p]M for substituting a for p in M . Now, we de.ne |= \nas follows: .[\u00b7],..|= emp (always, for all .) .[.(a)+ f .. .(\u00df)],..|= a@f .. \u00df (always, for all .) .s0 \n* s1,..|= M0 * M1 iff .s0,..|= M0 and .s1,..|= M1 .s, ..|= a.c(d) iff there exists an i such that .s, \n..|= a.ci(d) .s, ..|= a.ci+1(d) iff there exists a rule .Mu * Mf ,F . in the de.nition of p.c(.) where \nMf = \u00df0.c0(.0) * \u00b7\u00b7\u00b7 * \u00dfm.cm(.m) and such that . satis.es [a, d, .e/p, ., ..]F and ii .s, ..|=[a, d, \n.e/p, ., ..]Mu * \u00df0.c(.0) * \u00b7\u00b7\u00b7 * \u00dfm.c(.m) 0m where .. are the free variables of the rule and .e are \nfresh. Intuitively,achecker applicationof height 1 should makeno recur\u00adsive calls (i.e., it should correspond \nto a case where Mf is emp ). Observe that the valuation . is what connects regions and thus al\u00adlows checkers \nto be relational. Segment Regions. In a similar way, the semantics of a segment a.c(d) *= a. .c .(d.) \nis de.ned by induction over the number of checker rule applications needed to build a derivation of a.c(d) \nfrom a derivation of a. .c .(d.).For this purpose, we add an index i on segments to indicate its length \n(when it is known). Thus, the standard segment is one of zero-or-more steps: .s, ..|= a.c(d) *= a..c.(d.) \niff there exists an i such that .s, ..|= a.c(d) *=.c.(d.) i a. The de.nition of *= i then proceedsby \ninduction on i. Intuitively, we want a 0-step segment to be an empty partial derivation of a.c(d), which \nmeans it should be case that the checkers and arguments match and correspond to an empty store.Formally, \n0 a. .[\u00b7],..|= a.c(d) *=.c(d.) iff .(a)= .(a.) and .(d)= .(d.) The main purpose of these restrictions \nis to guarantee that *= has many of the same properties as the separating implication *-. Moreover, in \nSection 5.1.1, we will see that these restrictions are critical for the backward unfolding (as used in \nthe red-black tree example of Figure 1). The de.nition of the inductive case is very similar to the corresponding \ncase for checker applications. For an (i+1)-step segment, we unfold the head checker c once materializing \npoints-toedgesandaseriesof recursivecheckercalls whereoneofthesecheckercalls shouldbe replacedwithasegment \nof rank i. More precisely, i+1 a. .s, ..|= a.c(d) *=.c.(d.) iff there exists a rule .Mu * (Mf * \u00df.c..(.)),F \n. in the de.ni\u00adtion of p.c(.) such that . satis.es [a, d, .e/p, ., ..]F and .s, ..|=[a, d, .e/p, ., \n..]Mu * Mf * (\u00df.c..(.) *=i a..c.(d.)) where .. are the free variables of the rule and .e are fresh. Concretization. \nFinally, we tie these de.nitions together by giv\u00ading the concretization of our abstract domain, which \nis a reduced product of the shape domain (of graphs) and the base data do\u00admain. As the concrete counterpart \nof the environment E , we write . : Var . Val for a concrete environment that maps variables to concrete \nvalues. Here, we overload the concretization operator . to apply to each of the component parts. De.nition1 \n(Concretization). .( M )= { (s, .) |.s, ..|= M }.( .M, P . )= { (s, .) | (s, .) . .(M) . . . .P. (P ) \n}.( .E, M, P . )= { (., s) |.., . = . . E . (s, .) . .(.M, P .) } We write .P. for the concretization \nfunction in the base domain, which yields a set of satisfying valuations (independent of a store).  \n3.2 Properties of Inductive Segments While inductive segments *= are specialized to inductive check\u00aders, \nit still has manyof the properties of the separating implication *- (whenappliedtocheckers).Wewanttobeableto \nunfoldseg\u00adments, but we also need to maintain the properties necessary for analysis. In particular, we \ncan prove that *= isa restrictionof *- (by inductionoverthe lengthofthesegment).The semanticsof *- is \nthe standard one in separation logic. Theorem1 (Stronger than Separating Implication). If (s, .) . .( \na.c(d) *= a..c.(d.)), then (s, .) . .( a.c(d) *- a..c.(d.)). Asa consequence, weget the elimination rule. \nIf (s, .) . .((a.c(d) *= a..c.(d.)) * a..c.(d.)) , then (s, .) . .( a.c(d)). We also prove the following \nbasicbut important properties. a.. If (s, .) . .( a.c(d) *= a..c.(d.) * a..c.(d.) *= .c..(d..)), then \n(s, .) . .( a.c(d) *= a...c..(d..)) . For all . , ([\u00b7],.) . .( a.c(d) *= a.c(d)) .  Intermsoftheshapegraph,thesefactsallowtheanalysisto \ndiscard intermediate nodes when theyare no longer needed, such as a. and a.. in the following graph: \n Furthermore,itallowsustodiscoverwhenaregionagain satis.esa complete runofa checker (i.e.,the entire \nstructureagain adheresto the data structure invariant). In the above, dropping the intermediate nodes \nallows us to derive that the region from a (pointed to by root )satis.es the invariants of checkerc . \nThe lastfact allows us to introduce segments anywhere when needed. We remark that our notion of segments \nis designed to capture precisely a partial run (i.e., a partial derivation) and not only struc\u00adture segments \nwhere an empty structural segment need not neces\u00adsarily have equal additional parameters (i.e., d s). \nThis distinction shows up in the above properties, which are crucial to our analysis. 4. Typing CheckerParameters \nAs alluded to in Section 2, we perform a pre-analysis on checker de.nitionstogather informationthatwethenusetoguidetheshape \nanalysis. In particular, we saw that at program point 21 in Figure 1, in order to materialize the .elds \nof . (i.e., the node pointed to by pa ), we need to unfold the segment between a and \u00df backward from \n\u00df . However, note that this reasoning was based only on our intuitive understanding of the rbtree checker. \nNevertheless, we notice that with some additional type information on the checker parameters, the analysis \ncan then make this unfolding decision automatically. Inthissection,weprescribeatypesystemtochecker parameters \nthat classi.es them intovarious kindsof pointersand non-pointers. This type information will then instruct \nthe shape analysis where to perform unfolding (see Section 5.1). Intuitively, we consider a checker parameter \nto have pointer type if it appears on the left side of points-to in some disjunct of a checker unfolding. \nThat is, in terms of checker runs, a parameter has pointer type if one of its .elds is ever dereferenced \nalong some path in a checker run (ona satisfying store). Thusfarin the paper, wehavein essence implicitly \nassigneda pointer type to the traversal parameter (i.e., p in a de.nition p.c(.) ). To direct unfolding \ndecisions, we introduce further re.nements of the pointer type to indicate, for example, which .elds \nf are dereferenced. We thus write a pointer type as a record of .elds that are dereferenced {f0..0.,...,fn..n.} \n(in some disjunct).We consider the non-pointer type to be simply the empty record of .elds {}. The level \n. provides a relative measure of where in the sequence of checker calls a .eld is dereferenced (i.e., \nwhere the points-toedgeis materialized).To describe this notion, considera derivationofachecker application \na.c n(),shown belowdiagram\u00admatically:  where the ci s are the sequence of checker calls (of various \ncheck\u00aders) through a path in the derivation (i.e., a path in the computation tree of a.c n()).Fora pointer \nargument \u00df of a call, such as at c0 , we want to track an approximation of where along the run are the \n.elds of \u00df dereferenced (i.e., materialized).A level . is thus an integer indicating in how many checker \ncalls is the .eld derefer\u00adenced or unk if unknown (e.g., at different levels depending on a conditional); \nnegative integers indicate backward from the current call, while positive integers indicate forward. \nExample1 (Typing the Doubly-Linked List Checker). The follow\u00ading assigns parameters types to the dll \nchecker from Section 1. types t ::= {f0..0.,...,fn..n.}levels . ::= n | unk G .S M ok {f.0.} <: G(a)G \n. M ok t-emp t-.eld G . emp ok G . M * a@f .. \u00df ok G(ai) - 1 = S(c)(pi)G . M ok (for p0.c(p1) := ...) \nt-checker G . M * a0.c(a1) ok .S chkdef ok S(c) . Mi ok t-chkdef . p.c(.) := .M0,F0..\u00b7 \u00b7\u00b7..Mn,Fn. ok \nt0 <: t1 .0 <:: .1 .i <:: .. (0 = i = n = m) .<:: unk i {f0..0., ..., fn..n.} <: {f0... ., ..., fm... \n.} .<:: . 0m Figure 3. Type-checking checker parameters. (p : {next.0., prev.0.}).dll(. : {next.-1., \nprev.-1.}) := .( . : {next.1., prev.1.}). .emp,p = null. ..p@next .. . * p@prev .. . * ..dll(p),p . = \nnull. Example 2 (An Alternative Doubly-Linked List Checker). The following pair of checkers de.ne a doubly-linked \nlist where the unfolding materializes the next .eld of the current node and then the prev .eld of the \nnext node (if it is non-null) instead of the next and prev .elds of the current node as in dll . (p : \n{next.0., prev.-1.}).npdll() := .( . : {next.2., prev.1.}). .p@next .. . * ..npdll.(p),p . = null. (p \n: {next.1., prev.0.}).npdll.(. : {next.-1., prev.-2.}) := .emp,p = null...p@prev .. . * p.npdll(),p . \n= null. In Figure 3, we present a type-checking algorithm for the pointer types described above, which \nwill then lead to an inference algorithm.We write G for a type environment mapping symbolic values a \nto types t and S for a checker environment mapping checker names c to a type environment G for the types \nof all the parameters of c. Also, we assume that S(c) includes types for all thefree symbolicvaluesinthe \nde.nitionof c (i.e., theexistentially quanti.edvariables).Boththetypesandlevelsform (semi-)lattices where \nthe ordering is given by the <: and <:: relations, respec\u00adtively. For types, records are ordered by subset \ncontainment of .elds modulo ordering in the levels, while the level lattice is the .at lattice on integers \nwith unk as the top element. Intuitively, the absence of a .eld indicates it is not dereferenced anywhere. \nThe core judgment is G .S M ok, which checks that an abstract memory is well-formed with respect to the \nparameter types G and checker environment S, which are .xed throughout.Fora points\u00adto edge, we check \nthat the .eld is in the set of dereferenced .elds (rule t-.eld).Fora checker application, we check that \nthe setof dereferenced .elds for the actuals and formals are the same,but we need to shift the frame \nof reference of the levels (rule t-checker). We write t - 1 for the function on types that decrements \neach of the .eld levels (and where unk maps to unk ). Finally, at the top\u00adlevel, we typecheck each checker \nseparately andfor each checker, we check the memory speci.cation of each rule. The type-checking algorithmisfairly \nstraightforward,butit also yields a natural extension to inferring parameter types by a least .xed-point \ncomputation. The inference proceeds by initializing the global environment S to map all symbolic values \nto {} (the bottom element). At each place where we check conformance in Figure 3, we instead compute \nthe join in the type lattice and update the appropriate environments. Then, we iterate until we reach \na .xed point. Since the type lattice has .nite height (as the number of .elds is .xed for any set of \nchecker de.nitions), the process terminates. This procedure provides fairly generic support for unfolding \n(forward and backward). The graph unfolding described in Sec\u00adtion 5.1 combined with this pre-analysis \nallows support for back\u00adward pointers that go back a .nite number of steps (e.g., a list with a pointerthatgoesbacktwo \nnodes),but more importantly,itmakes the unfolding process less sensitiveto howthe checkers are written. \nFor example, the alternative doubly-linked list checker of Example 2works equally well. The types are \nslightly different, which in turn guides the graph unfolding algorithm appropriately. Also, observe that \nin t-checker, we make no distinction between the traversal parameters and the additional parameters. \nThus, with this type in\u00adformation, one could consider checkers with, forexample, multiple forward parameters \n(at least in terms of unfolding). 5. Analysis Algorithm Our analysisworks asatypical abstract interpretation \non programs. In particular, the analyzer computes an abstract state A for each controlpoint.Todothat,weneed \ntransfer functionsfor commands, such as assignment and condition testing. As alluded to in Sec\u00adtion2, \nthekeydomain operationis the unfoldingof checker edges (forward and backward) in order to materialize \npoints-to edges. A novel aspect of our proposal is that we reduce the problem of unfolding segments backward \nto unfolding them forward (Sec\u00adtion 5.1).To infer loopinvariants and obtaina terminating analy\u00adsis, we \nde.ne comparison and join operations on abstract states that summarize graphsbyfolding them into checker \nedges. The primary source of complexity in folding is the interaction between the shape graph and the \nbase data domain.Anice property of our algorithm is that at a high-level, we separate the computation \nof the compari\u00adson and join operations into phases: .rst, a traversal over the shape graphgathering constraints,and \nthen,a propagationofthese con\u00adstraints to the base data domain before applying the corresponding base \ndomain operation (Section 5.2). 5.1 AbstractTransition with Segment Unfolding Recall that the complete \nchecker edges and partial checker edges summarize memory regions. In order to re.ect memory updates in \na precise manner, we often need to partially concretize these sum\u00admaries, which wedoby unfolding.To describe \nunfoldingin detail, we consider a schematic example of doubly-linked list traversals that illustrate \nthe various forms of unfolding (shown in Figure 4). Initially, we have that l points to the head of a \ndoubly-linked list (satisfying the dll checker from Section 1). From program point3 to 4, we perform \na forward unfolding of a complete checker edge to materialize the edge corresponding to c0 ->next (the \none from a in the .rst iteration and the one from . in the .xed-point it\u00aderation). Observe that the analysis \ndetermines that it should, for example, unfold forward at a in the .rst iteration because while there \nis no outgoing points-to edge for the next .eld (correspond\u00ading to c0 ->next ), node a does have an outgoing \nchecker edge (i.e., a is the traversal argument to a checker). Because checkers are inductive de.nitions \nwhere points-to edges emanate from the traversal parameter, unfolding the inductive predicate at its \ntraver\u00adsal argument (e.g., a in a.dll(null) )is likely to materialize the desired points-to edge. From \nprogrampoint7to8,to materializetheedge c1 ->next , we must unfold forward at the head of a dll segment \n(the one from a to . in the .rst iteration and the one from . to . in the .xed\u00adpoint iteration). Like \nin the previous case, the analysis determines it should unfold forward because it arrives at an outgoing \nchecker edge, but in this case, it is a partial checker edge and thus how 1 c0 = l; 2 while (c0 != null \n&#38;&#38; c0 should be advanced forward) {  3 c0 =c0 ->next; 4 } 5 c1 = l; 6 while (c1 != c0 &#38;&#38; \nc1 should be advanced forward) {  !l,c1c0dll(null)dll( )dll( )  !lc1c0dll(null)dll(\")dll(\")dll( )dll( \n) 7 c1 =c1 ->next; 8 } 9 c2 =c1 != null ?c1 ->prev : null ; 10 while (c2 != null &#38;&#38; c2 should \nbe advanced backward) {  \"lc2dll(null)dll(\")nextprevdll( ) 11 c2 =c2 ->prev; 12 } First Iteration \nAt FixedPoint Figure 4. Unfolding of doubly-linked lists (checker dll). to unfold it does not come directly \nfrom a user-supplied inductive de.nition. Finally, from program point 11 to 12, we can only make progress \nby unfolding backward at the tail of a segment (the one from a to . )to materializethe edge forc2 ->prev \n. There are two distinct aspects to both forward and backward unfolding (though they are more evident \nin the backward case): (1) implementing the unfolding operations on the abstract domain, while justifying \ntheir soundness (described in Section 5.1.1) and (2) determining when to apply which unfolding operation \n(discussed in Section 5.1.2). Unlike forward unfolding, determining when and where to apply backward \nunfolding is not so obvious. 5.1.1 Unfolding Operations Weapplyan unfoldinginordertoexposeaheapcell(i.e.,apoints\u00adto \nedge) before performing an operation on it. Relational checker de.nitions include not only shape information \n(i.e., how are the points-to edges arranged)but also data information in the form of pure constraints \non the exposed heap cells. Thus, unfolding not only modi.es the shape graph M but must also add additional \nconstraints to the pure state P . In general, unfolding takes an element of the product domain .M, P \n. and yields a disjunction of abstractions .M0. ,P 0... ... ..M. ,P . .. Though, it is often the nn case \nthat allbut one are ruled outbythe data domain (i.e., we derive a contradiction in the pure constraints). \nTo mark the phases of unfolding, we distinguish an unfolding operation that works only on shape graphs \nfrom the overall un\u00adfolding operation. This distinction is also useful in describing other domain operations \nthat rely on unfolding.We write ua for the for\u00adward unfolding at node a that takes a shape graph M and \nreturns asetofgraphand formulapairs wherethe .rst-order formulasgive the pure constraints on the unfolded \ngraphs. The overall unfolding operation unfolda then takes an element of the product domain .M, P . and \nreturns a disjunction of such elements. Unfolding Inductive Checkers. Let us consider the unfolding \nof a complete checker edge a.c(d), in the abstract element .M * a.c(d),P ..We describe unfolding of complete \nchecker edges for\u00admally, as it serves as a basis for the unfolding of segments. The unfolding of a checker \nproceeds by unfolding each rule separately: def _ unfolda(M * a.c(d),P )= unfolda(M * a.R(d),P ) R.c \ndef ua(M * a.c(d)) = { ua(M * a.R(d)) | R . c } where we write R . c for a rule R of checker de.nition \nc and overload checker application to also apply to rules. To unfold a rule, we .rst materialize the \n.elds of the rule and then add the data constraint.Weassume the base domain providesa guardP. (P, F ) \nfunction that is a sound approximation of constraining P with F . def unfolda(M * a.R(d),P )= .M. , \nguardP. (P, F .). where (M.,F .)= ua(M * a.R(d)) ua(M * a.R(d)) def =(M * [a, d, .e/p, ., ..](Mu * Mf \n), [a, d, .e/p, ., ..]F ) In the shape graph, we simply unfold the rule and perform substitu\u00adtions (where \n.e are fresh; and rule R has formals p and ., has free variables .., and has the form .Mu * Mf ,F .). \nThis scheme can be performedin an automaticway and generatesa .nite numberof disjuncts, which are well-formed \nelements of the domain. Further\u00admore, this algorithm is sound in that unfolding the checker edge results \nin a weaker disjunction. Theorem 2 (Soundness of Unfolding). If unfolding transforms .M, P . into .i \n.Mi .,P i .., then .(.M, P .) ..i .(.Mi .,P i ..). The proof is by an (easy) induction on the height \nof the checker call tree . Example3 (Unfoldinga Binary SearchTree). We show the un\u00adfolding of a region \nsatisfying the bst checker from Section 1.  Forward Unfolding of Inductive Segments. Because the seman\u00ad \na.. tics of a partial checker edge a.c(d) *= .c (d.) is de.ned by induction over the sequence of derivations \n(from a to a. ), we can de.ne an unfolding scheme analogous to the one for complete checker edges. We \ncall this operation forward unfolding since it proceeds by unfolding checker de.nitions at the top of \nthe deriva\u00adtion tree in the standard way (i.e., corresponding to the material\u00adization of edges at the \nhead a). This unfolding operation is exactly what is needed to materialize the edge for c1 ->next at \nprogram point7in Figure4. Weextend the de.nitionof forward unfolding(unfolda )for segments. Like for \ncomplete checker edges, unfolda on partial checker edges generatesa.nite disjunctionof .M, P . pairs. \nHow\u00adever, for partial checker edges, we must consider an additional case for the empty segment (i.e., \nthe 0-step segment);only if the segment is non-empty (i.e., is of 1-or-more steps) do we get materializations \ncorresponding to the rules of c. unfolda(M * (a.c(d) *= a..c.(d.)),P ) def a(M * (a.c(d) * = unfold0 \n= a..c.(d.)),P ) `W \u00b4 . unfolda(M * (a.R(d) *= a..c.(d.)),P ) R.c unfold0 = a..c.(d.)),P ) a(M * (a.c(d) \n* ( def (M, guardP. (P, a = a. . d = d.)) if c = c = . if c =.c. Observe that for the empty segment(unfold0 \na ), we assert the additional equalities( a = a. and d = d. )in the base domain. Only with these equalities \ncan we determine in the analysis that the segmentat programpoint7oftheexampleis non-empty. We omit the \nde.nition for unfolda on rules and the corre\u00adsponding de.nitions of ua for the sake of brevity, as like \nfor complete checker edges, they follow directly from the semantics given in Section 3.1. This extended \nunfolding function unfolda is sound in the same sense as the complete checker unfolding (i.e., it satis.es \nTheorem 2). The proof proceeds by induction over the length i of *= i derivations. Example4 (Unfoldinga \nBinary SearchTreeSegment). We show the unfolding of a segment region satisfying the bst checker.  Note \nthat using separating implication( *-)for partial checker edgeswouldmakethemverydif.cultto unfold,asitwould \nrequire involved restrictions to be made on checkers. Instead, our notion of segments as we de.ne in \nthis paper( *= )seems to be closer to our intuitive understanding of partial derivations of checkers \nand thus leads to a natural forward unfolding operation. Backward Unfolding of Inductive Segments. The \nunfolding function de.ned above allows the analysis to materialize mem\u00adory regions from the traversal \nargument of a checker edge. How\u00adever,these unfolding operationsdo not applyto algorithmswalking backward \nthrough invertible data structures, such as doubly-linked lists, as the sequence of edge dereferences \ndoes not follow the re\u00adcursivechecker calls that the forward unfoldingwould uncover.For example, this \nsituation arises at program point 11 in Figure 4. From our intuitive understanding of dll, we know that \nif the segment be\u00adtween a and . is non-empty,then e thevalue of c2 lies along that segment just before \n. (i.e., e s next .eld points to . ).Thus, if we are able to unfold backward along the segment from \n. , we could materialize the edge for c2 ->prev . Thekeyobservation we make to de.ne the backward unfolding \noperationis that we can split segments into subsegments.Forex\u00adample, we can split a *= i+1 segments into \na pair of subsegments: *= i and *= 1 . This segment splitting property is captured by the following lemma: \nLemma1 (Splitting Inductive Segments). Let i+1 ... (s, .) . .(a.c(d) *= a.c (d)) Then, there exists a \nchecker c .. and nodes a..,d.. suchthat i a.. ..(d..) * a.. ..(d..1 a..(d. (s, .) . .(a.c(d) *= .c .c \n) *= .c )). The proof proceeds by induction on i. We remark that only checkers that may be called transitively \nfrom c need be considered for c .. and that the nodes a..,d.. are fresh (modulo renaming). Observethat \nLemma1makesit possibleto decomposeaseg\u00adment into a .nite set of disjuncts with shorter segments. We can \nthen de.ne a backward unfolding operation by .rst splitting an (i+1)-step segment into an i-step segment \nand a 1 -step segment Figure 5. Backward unfolding of a doubly-linked list segment. unfold.1 (a.c(d) \na..c.(d.)),P ) returns a disjunction a. (M **= composed of the following: 1. the term unfold0 * (a.c(d) \n*= a..c.(d.)),P ) , which a(M corresponds to the empty segment; 2. the disjuncts that result from = a....(d..)) \nunfolda.. (M * (a.c(d) *.c * (a....(d..) *1 a. .c=.c.(d.)),P ) for each possible cand with a..,d.. fresh \n(as in Lemma 1), which corresponds to splitting the non-empty segment and apply\u00ading the forward unfolding \non the *=1 edge. This backward unfolding function is sound in the same sense as in Theorem 2. Note that \nLemma1 can be generalized to splitting segments of length i + k , which allows us to unfold backward \nk steps in one operation (for any constant k ).We write unfold.k a. for the k -step backward unfolding \nfunction at a. . In Figure 5, we show the individual steps in the backward unfolding of a doubly-linked \nlist segment that is needed in the example shown in Figure 4. At the top, we show the subgraph of interest \nfrom program point 11. The empty segment case is ruled out because we have that e .null from the loop \ncondition; = since the parameter at a is null , an empty segment would imply that e = null (as e is the \nparameter at . ). Figure 5 shows the steps for the non-empty segment case. It is in the last step that \nwe discover that . = .. and e = e. , which allows us to .nd out that e@next .. . (i.e., is the points-to \nedge for c2 ->next ). 5.1.2 Expression Evaluation and Controlling Unfolding The basic transfer functions \nfor atomic operations (e.g., muta\u00adtion, allocation, deallocation, and condition testing) are all fairly \nstraightforward, as updates affect graphs locally.As described in Section 2, once points-to edges have \nbeen materialized, pointer up\u00addates amount to the swinging of an edge. Determining which edge to swing \nand to where is a simple walk of the graph from variables following the sequence of .eld dereferences \nof the command. This strong update is sound because each edge is a disjoint region of memory (i.e., the \nseparation constraint). For data operations (e.g., arithmetic expressions) on heap val\u00adues, we symbolically \nevaluate the expressions by obtaining sym\u00adbolicvalues for each memory access.We then createa new sym\u00adbolic \nvalue to stand for this expression in the graph and assert this equality relation in the data domain \nP. .For example, consider the and then apply forward unfolding to the 1 -step segment (while sep\u00ad following \nassignment showing an example transition: .x = x->data + x->data; arately considering the 0-step segment \ncase). statement More precisely, we de.ne a backward unfolding function . ax ,ax@data .. \u00df, P . unfold.1 \n, which should be applied at a node a. in an abstract a. x->data state of the form .M * (a.c(d) *= a. \n.c .(d.)),P . and conceptu\u00ad .x .,ax@data .. ., guardP. (P, . = \u00df + \u00df). . ax ally unfolds the checker \napplication just before a. in the sequence of calls from a to a. . where . is a fresh symbolic value. \nAs described above, evaluating expressions requires following points-to edges in the shape graph. In \ncase the relevant points\u00adto edges are folded into complete or partial checker edges (i.e., summarized), \nwe need to unfold the appropriate checker edge to materialize the desired points-to edge (using the operations \nde.ned in Section 5.1.1). To choose the appropriate edge and unfolding operation, we take advantage of \nthe type inference on checker parameters de.ned in Section 4. We arefaced with deciding where to perform \nunfolding when the evaluation of an expression requires dereferencing a .eld f of a node a,but there \nis no such points-to edge from a. If there is a complete checker edge a.c(d) orapartial checker edge \na.c(d) *= a. .c .(d.) starting from a (i.e., a is the traversal argument for some checker edge), then \nwe may unfold this summary edge using the forward unfolding function unfolda . If the points-to edge \nfor a@f is materialized, then the evaluation of the expression can be resumed in the new unfolded graph(s). \nThis materialization step is the basic one based on the knowledge that points-to edges emanate from the \ntraversal parameterin inductive checker de.nitions andis whatappliesat programpoints3and7inFigure4.Notethatasan \noptimization, we need only consider outgoing checker edges where the type of the traversal parameter \nof the checker includes f... (for a level . that is non-negative or unk ). Otherwise, if there is no \noutgoing checker edge from a, we look fora potential backward unfolding.We look elsewhere fora \u00df.. partial \nchecker edge \u00df.c(d) *= .c (a) where a is a parameter at the tail. If additionally, the corresponding \nparameter of checker c . has a type that includes f.n. where n< 0, then we apply the backward unfold \nfunction at \u00df. (unfold.\u00df.|n| ). The magnitude of the integer level tells us how many steps backward (i.e., \nhow to split the segment from \u00df to \u00df. ). In the doubly-linked list example at program point 11, we are \ntrying materialize e@prev when e has no outgoing edges. However, we have the edge a.dll(null) *= ..dll(e) \nin the graph. Since the type of the additional parameter to dll contains prev.-1. (see the type of . \nin Example 1), we know to unfold backward 1-step from . . Observe that the checker parameter typing does \nnot affect soundness; it is utilized only as guide to decide where to unfold.  5.2 Folding with Relational \nData Constraints To obtain loop invariants in the shape domain, we need a way to identify subgraphs that \nshould be folded into complete or par\u00adtial checker edges. Because checker edges incorporate both shape \nand data properties, this summarization requires careful coordi\u00adnation between the shape domain and the \ndata domain (in order to avoid losing precision unnecessarily). As observed in our prior work (Chang \net al. 2007), the folding of the shape graph can be guidedby consultingthe iteration history througha \nwideningoper\u00adator de.nedon shape graphs. In this paper, we describe a widening algorithm that applies \nin the presence of relational checkers (i.e., with the introduction of inductivesegments and rich data \ndomains). In this subsection, we de.ne the comparison and widening op\u00aderations, which both .rst perform \na simultaneous traversal over the input shape graphsgathering constraints before then applying the corresponding \noperationin the base domain.We describe the com\u00adparison algorithm .rst,asithas similarbut slightly simpler \nstruc\u00adture as compared to the widening and is also the key subroutine used by the widening. 5.2.1 Comparison \nof Abstract States The comparison operator checks inclusion between two abstract elements in a conservative \nway. More precisely, it takes as input two abstract elements A. = .E.,M.,P.., Ar = .Er,Mr,Pr. and returns \ntrue if it can establish that .(A.) . .(Ar) and false otherwise (which does not necessarily mean that \nthe inclusion does not hold at the concrete level). Recall that the nodes in the shape graph correspondtoexistentially-quanti.ed \nsymbolicvalues,soat the basis of the comparison is a notion of node equivalence, which states that valuations \nshould map nodes in A. and Ar to the same value for the inclusion to hold. For instance, if x is a variable, \nthen the address of x should be the same on both sides, or the inclusion cannot hold. In fact, these \nequality relations constrain the valuations. Thus, when it succeeds, the comparison algorithm should \nreturna valuation transformer . thatisafunction mapping nodes of Ar into nodes of A. . The condition \nthat . is a function ensuresthatanyaliasingexpressedin Ar is also re.ected in A. ,so if at anypoint, \nthis condition on . is violated, then the comparison returns false . At a high-level, the algorithm \nproceeds in three stages: First, the initialization of the algorithm creates an initial valu\u00adation transformer \n.init de.ned by the environments E. and Er . Each variable should be mapped to the same address, so it \nis de.ned as follows: .x . Var, .init(Er(x)) = E.(x).  Second,a comparison in the shape domain is performed, \nwhich proceeds by checking inclusion locally. When new node rela\u00adtions are established as required for \nthe inclusion to hold, the valuation transformer should be extended in order to include these constraints. \nFinally, it returns the following: (1) the .nal valuation transformer .; (2) a .rst-order formula F , \nwhich collects pure constraints, which may arise during the compu\u00adtation that must ultimately be proven \n(i.e., are temporarily as\u00adsumed).  Last, a comparison in the data domain is performed that shows the \ninclusion of P. in Pr .We must also ask the data domain to proveand discharge the .rst-order side-conditions \nF computed in the previous step hold under the assumption of P. . All this is done modulo application \nof the valuation transformer ..  Comparison in the Shape Domain. The basic idea of the graph comparison \nalgorithm is to determine semantic inclusion by itera\u00adtively reducing to stronger statements until the \ninclusion is obvious. It does so using a set of rules that apply to the graph locally. While applying \nthis set of rules, the algorithm carries along and enriches the pair (.,F ) introduced above. The rules \nare presented in Figure 6.For conciseness, we omit the explicit bookkeeping of the node relations in \nthe valuation transformer ., that is, the rules assume the .nal . is given and state the soundness of \nthe whole computation. In practice, the state of . also determines when a rule applies. We show this \naspect indirectly by underlining the constraints on . that are added once the rule applies, while the \nmappings that are not underlined must be in . for the rule to apply.For instance, rule c-pt applies when \na. and ar match (i.e., when .(ar)= a. ) and when there is a .eld edge with label f from each node in \nboth graphs. Then, the edges can be removed from both abstract elements (since a.@f .. \u00df. is obviously \nweaker than ar@f .. \u00dfr ).Acorrespondence between \u00df. and \u00dfr can be added into . , for these two nodes \nshould correspond to the same value. When adding such a correspondence is not possible, because it would \nmake . not a function, the algorithm should return false (i.e., the inclusion cannot be established because \nthis situation would mean that onevaluein Mr should be equal to two possibly distinct values in M. ). \nIn the following, we brie.y summarize the behavior of the other rules, whereas we show how the rules \napply concretely in Example 5. Rule c-emp allows returning true when the proof is .nished. Similar to \nc-pt, rule c-chk matches two checker edges from related nodes. When there is a partial checker edge in \nM. and a checker edge in Mr , we split out the pre.x segment in the right to match the left (rule c-segchk \nfor a complete checker edge .(ar)= a. M. .F .(\u00dfr)= \u00df. .(ar)= a. M. .F .(dr)= d. . Mr . Mr c-emp c-pt \nc-chk emp .true emp M. * a.@f .. \u00df. .F Mr * ar@f .. \u00dfr M. * a..c(d.) .F Mr * ar.c(dr) .. . .(ar)= a. \nM. .F Mr * a. .c.(d. ) .(dr)= d. .(a. )= a. .(d. )= d. (a. ,d. fresh) . rrr. r.rr c-segchk M. * a..c(d.) \n*= a. .c.(d. ) .F Mr * ar.c(dr) ... = a.. ..(d.. .(ar)= a. M. .F Mr * a. .c.(d. ) *.c) .(dr)= d. .(a. \n)= a. .(d. )= d. (a. ,d. fresh) . rrrr r. r.rr c-segseg = a..(d. ) .F = a.. ..(d.. M. * a..c(d.) *.cMr \n* ar.c(dr) *.c) ... rr M. .F M. where (M. ,F .) . uar (Mr * ar.c(dr)) M. .F M. where (M. ,F .) . uar \n(Mr * ar.c(dr) *= a. .c.(d. )) . rr. rrrr c-uchk c-useg M. .F .F . Mr * ar.c(dr) M. .F .F . Mr * ar.c(dr) \n*= a. .c.(d. ) .. rr Figure 6. The comparison operation in the shape domain. in Mr and rule c-segseg \nfor a partial checker edge). Rules c-uchk and c-useg unfold complete or partial checker edges in Mr when \nno other rule applies. Intuitively, when the comparison succeeds, . gives us a relationship between the \nvaluation of nodes on the left and on the right. In other words, a valuation .. for A. can be composed \nwith . , to give a valuation for Ar . We write this composition as .. . ., which we use to state soundness. \nTheorem3 (Soundness of Comparison in the Shape Domain). The above comparison function is sound: if M. \n. Mr , (s, .) . .F .(M.) and . . . satis.es F , then (s, . . .) . Mr . The proof proceeds by induction \non the derivation of .F . . Soundness of rules c-pt and c-chk is straightforward. Proving rules c-segchk \nand c-segseg requires an induction over the length of the segments. Finally, the soundness of c-uchk \nand c-useg follows from the soundness of unfolding. We remark that the rules differ signi.cantly from \nthe rules pro\u00adposed in our prior work because of the introduction of inductive segments that we need \nfor segment unfolding. In particular, the rules c-segseg (matching of partial checker edges) and c-useg \n(un\u00adfolding of partial checker edges) are new and replace the assume rule, which does not hold for inductive \nsegments. Furthermore, the proofs for rules c-segchk and c-uchk are also quite different. The comparison \nalgorithm in the shape domain is incomplete (i.e., the comparisonmayfailtoprovethe inclusionwhenitdoesholdatthe \nconcrete level). These rules have been primarily designed to be ef\u00adfective in the way the comparison \nis used in the join and widening algorithms where we need to see if M. is an unfolded version of Mr (see \nSection 5.2.2). Comparison in the Combined Domain. If the comparison in the shape domain succeeds,thenthe \ncomparisonholdsinthe combined domain if we can discharge the side-conditions F and show the inclusion \nin the data domain. The key is that the comparison in the shape domain has computed . , the correspondence \nbetween values in the left and values in the right, which captures the rela\u00adtionship between the shape \nand data domains.To de.ne theover\u00adall comparison, we assume that the data domain has a function proveP. \nthat takes as input an abstract element P . P. and a .rst-order formula F and tries to prove that any \nvaluation . in .P. (P ) satis.es F , as well as a conservative comparison function .P. . Furthermore, \nwe assume the data domain can apply . at the abstract level, that is, P . . applies the valuation transformer \n. to rename symbolicvalues and capture anyrelations. Conceptually, this operation can be implemented \nby asserting equalities for each mapping in . then projecting out the symbolic values in the range of \n. .With that, the comparison function for the product domain is de.ned as follows: .M.,P.... .Mr,Pr. \niff there exists an F such that M. .F . Mr and proveP. (P. . .,F ) and P. . . .P. Pr. Moreover, .E.,M.,P....Er,Mr,Pr. \nif and only if the above comparison evaluates successfully when started with .=.init . The .. operator \nis sound, that is, if .M.,P.... .Mr,Pr., then .(.M.,P..) . .(.Mr,Pr.). Similarly, if .E.,M.,P... .Er,Mr,Pr., \nthen .(.E.,M.,P..) . .(.Er,Mr,Pr.). Example5 (VerifyingaLoopInvariantof SearchTreeTraversal). We highlight \nsome aspectsof the comparison algorithmby follow\u00ading an example derivation. This example checks, for \na region, the inclusionofan iterationinaloopinvariantfor .ndingthevalue d in a binary search tree (essentially, \nthe .rst stage prior to the inser\u00adtioninthe red-blacktreeexample,asshowninFigure1,lines2 8). The .rst \nline shows the initial goal: on the left-side of the compar\u00adison, we have the state where the cursor \nc has advanced to the left subtree of the root t .We want to show that this subgraph is con\u00adtained in \nthe segment from t to c . At the top, we show the pure constraints for each side: on the left, we have \nthat d<\u00df 0 d , which is why c advanced to the left subtree.Wewant to show that d is in the range of the \nsubtree from .1 . In the right column, we show the valuation transformer . as it is extended through \nthe course of the computation.Weshowtherulesusedto transitionbetweeneach step boxed and .ush right. The \nhighlighting of nodes and edges in\u00addicates where the rules apply. To keep the diagram compact, we write \nthe values of the data .elds as a tuple (e.g., \u00df0 d ,\u00df0 lo,\u00df0 up). The .rst step applies c-useg that \nunfolds the segment on the right producinga proof obligation F (shown boxed). The next step matches points-to \nand complete checker edges, which extends . . Finally, the last step unfolds the segment at .1 . asa \n0-step segment, which produces key additional constraints on . that come from the semantics of the 0-step \nsegment. To complete the proof, we need to discharge the above proof obligation and show inclusion at \nthe data level. Applying the valu\u00adation transformer to the element of the data domain on the left side \n(i.e., P. . . ), we get the following: = .lo = .up .0 .<d<. d = null . .lo <.up 01 010 which clearly \nimplies the proof obligation and theinequality con\u00adstraints on the right side (i.e., the loop invariant). \n 5.2.2 Join andWideningof Abstract States The join and widening operators combine shape and data con\u00adstraints \nto build an over-approximation of two abstract elements A. = .E.,M.,P.. and Ar = .Er,Mr,Pr.. Furthermore, \nthe widening operation should ensure the termination of sequences of abstract iterates. In particular, \ntermination should be achieved at both the shape and data levels. We .rst consider the join of ab\u00adstract \nelements, that is, the computation of a sound approximation of both A. and Ar . Like for the comparison \noperator, we need to trackthe correspondence between symbolicvaluesintheinputsand those in the output. \nIntuitively, a node a in the result should over\u00adapproximate the values corresponding to a pair of nodes \n(a.,ar), where a. is in A. and ar in Ar , so we maintain a pair of valua\u00adtion transformers (.., .r) that \ndescribe these relations.For con\u00advenience, we also write .(a) for (..(a), .r(a)). At a high-level, we \ncan partition the join into stages in a similar manner as the comparison operation (by utilizing the \nvaluation transformers .., .r ): First, during initialization, for each variable x in the environ\u00adment, \na node ax is created so as to represent the address of x . The valuation transformers .., .r are initialized \nso that .x . Var, .(ax)=(E.(x),Er(x)), and the resulting envi\u00adronment E is de.ned by .x . Var,E(x)= ax \n. Second, a join in the shape domain builds a new shape ab\u00adstraction M and returnsit together withvaluation \ntransformers .., .r and residual .rst-order constraints F.,Fr that should be proven at the data level. \nLike in the comparison, it also en\u00adriches .. and .r whenever a new node is created in order to preserve \nthe consistencyof the node pairing.  Last, a join in the data domain is applied to P. . .. and Pr . \n.r .We must also ask the data domain to discharge the .rst-order constraints F.,Fr (so as to check that \nthe abstrac\u00adtions performed in the shape join are valid with respect to data constraints).  Join in \nthe Shape Domain. The join in the shape domain iter\u00adatively attempts to replace fragments in each of \nthe input shape graphs( m. and mr )witha new fragment(m)through a set of rewriting rules.Arule consumes \nfragments m. of M. and mr of Mr and produces a fragment m for the result, which should be a sound approximation \nof m. and mr modulo the application of .. and .r , respectively. In Figure7, we present the fragment \nrewriting rules.We write .m.,mr. .F m for such a rewriting rule where . is the valu\u00ad . ation transformer \nand F is the residual .rst-order constraint from the rewriting. Like for the comparison, we do not explicitly \nshow the extending of . but rather assume the .nal . isgiven. Also, the rules for the join are intended \nto be symmetric; for conciseness, we elide the left-sided version of the non-symmetric right-sided rules. \nFurther discussion on how we decide in what order to ap\u00adply the rules is found elsewhere (Chang et al. \n2007). A key rule is j-waliases , which introduces a segment as a weakening for both sides. Note that \nthe weakening on the left (from emp )is justi.ed by one of basic properties of inductive segments (see \nSection 3.2). Theorem4 (Soundness of Join in the Shape Domain). If the join algorithm returns M = M. \n. Mr together with the valuation transformers .., .r and the .rst-order constraints F.,Fr , then for \neachside i .{., r} and for all (s, .) . .(Mi) , if . . .i satis.es Fi , then (s, . . .i) . .(M). The \nproof proceeds by induction on the sequence of rewriting steps and case analysis on the rules used. Join \nin the Combined Domain. The join operator for the com\u00adbined domain .E, M, P . = .E.,M.,P...Er,Mr,Pr. \nis de\u00ad.ned as follows: (1) E is the environment computed from E. and Er during initialization; (2) the \nshape join returns M together with .. , .r , F. , and Fr when applied to M. and Mr ;(3) the resid\u00adual \nside-conditions are discharged, that is, proveP. (P. . ..,F.) and proveP. (Pr . .r,Fr) succeed; and (4) \nP is the join in the data domain (i.e., P =(P. . ..) P. (Pr . .r)). This join operator is sound, that \nis, .(.E.,M.,P..) . .(.Er,Mr,Pr.) . .(.E, M, P .) . Widening. Awidening operator . isa join operator \nwitha stabi\u00adlizing property so as to ensure termination of the analysis (Cousot and Cousot 1977). This \noperator should ensure that both shapes and data invariants are stable after .nitely many iterations. \nThe shape join already has the stabilizing property, so a widening oper\u00adationforthe combined domaincanbe \nobtainedbysimplyusingthe widening operator .P. instead of the join P. in the data domain. Theorem5 (WideningTermination). \nGiven any sequence (A. )n.N, nthe sequence (An)n.N (where An =(En,Mn,Pn))de.ned by A0 = A0 . and An+1 \n= An.An. +1 is ultimately stationary. The proof is based arguments similar to those required to prove \nthe termination of widening in co.bered domains (Venet 1996): the shape graphs stabilize .rst, and then \nthe data abstract values eventually converge since a widening operator is used. Example6 (Traversal of \na List of Given Length). In this example, we consider the join of the .rst two iterates that arise during \nthe traversal of a list of length n:  alen \u00dflen = n = n - 1 01 The above join algorithm produces the \nfollowing shape invariant M after applying rules j-chk and j-waliases:  Rule j-chk extends the valuation \ntransformer so that .(.1 len)= (alen,\u00dflen 01 ). From rule j-waliases ,we get on the left side that .0 \nlen = .len ..(.len (i.e., ..(.len)= )). On the right side, one unfolding step is required in the comparison \n(to fold from \u00df0 to \u00df1 into a listn segment), so by the de.nition of the additional parameter of the \nrecursive call in the de.nition of checker listn, we have the 1 01 = .len relation that .0 len 1 +1 \n. This relation cannotbe trackedby .r aswehave de.neditinthispaper,butwecan consideran extended valuation \ntransformer that not only maps nodes of the result into nodesofoneoftheinputs,butalsoallowsexpressingsuch \nrelations among the nodes of the output graph. Such relations typically arise in the unfoldings performed \nduring the comparisons required for applying rules j-waliases , j-wchk, and j-wseg. After the join of \nthe shape abstractions, the above relations are propagated to P. and Pr (i.e., by applying .).This results \nin the following for the join in the data domain P. : .len = n . .len = .len .len = n - 1 . .len = .len \n1 01 P. 1 01 +1 If we let P. be the domain of linear equalities (Karr 1976), the - .len n - .len result \nof the join is [.0 len 1 = 1 ] , which says that the sum of the lengths corresponding to the partial \nand the complete checker segments is n (i.e., the length of the list does not change .(a)=(a.,ar) .(\u00df)=(\u00df.,\u00dfr) \n.(a)=(a.,ar) .(d)=(d.,dr) .(a)=(a.,ar) mr .F a.c(d)..(d)= d. .r j-pt j-chk j-wchk .a.@f ..\u00df.,ar@f ..\u00dfr. \n.a@f ..\u00df .a..c(d.),ar.c(dr). .a.c(d) .a..c(d.),mr. .F a.c(d) .. . .(a)=(a.,ar) .(a.)=(a. ,a. ) mr .F \na.c(d) *= a..c.(d.)..(d)= d. ..(d.)= d. .r.r . j-wseg .a..c(d.) *= a. .c.(d. ),mr. . a.c(d) *= a..c.(d.) \n.(a)=(a.,ar) .(a.)=(a.,a. ) mr .F a.c(d) *= a..c(d.)..(d)= d. ..(d.)= d. r.r j-waliases .emp,mr. .F \na.c(d) *= a..c(d.) . Figure 7. Fragment rewriting rules for the join operation in the shape domain. \nduring the traversal). This invariant is the most precise one can hope for on this example. Example7 \n(Inferringa LoopInvariant for SearchTreeTraversal). Consideragainthecodefor .ndingavalue d inabinary \nsearch tree (i.e., lines2 8in Figure1).For thisexample,we assume P. is an abstract domain that supports \ninequalities among pairs of variables (e.g., octagons (Min\u00b4 e 2006)). Suppose in the .rst iteration, \nthe cursor c is advanced to the left subtree (i.e., d is smaller than the data at the root), then the \nthe .rst widening is applied to the (*) The join in the shape domain yields the following shape graph: \n( ) The valuation transformer . is initialized to .(.0)=(a0,\u00df0), .(.1)=(a0,\u00df1) from the environment. \nThen, rule j-chk applies to addthe complete checker edge from .1 , which also extends . (alo upup so \nthat .(.1 lo)= 0 ,\u00df0 lo) and .(.1 )=(a0 ,\u00df 0 d ). Finally, rule j-waliases applies to create the segment, \nwhich enriches . so ..(.lo up that the following relations hold: ..(.0 lo)= 1 ), ..(.0 )= ..(.up (.lo \n(.lo \u00dflo 1 ) for the initial state and .r0 )=.r1 )= 0 , upup up .r(.)= \u00df, .r(.)= \u00df0 d for the .rst iterate. \nNote that the 00 1 inclusion check that we need to weaken the subgraph from \u00df0 to \u00df1 to a partial checker \nedge is the comparison in the shape domain shownin Example5.Theextensionsto .r can be read from there. \nThen, applying thevaluation transformers .., .r to the respec\u00adtive input elements, the data invariants \nto join are as follows: .lo = .lo upup up . .= .. -8 = .lo <d<.= 8 0101 11 -8 = .lo = .lo = .lo = .up \nP. <d<.up <.up = 8 011 110 However, the join of these two data invariants is problematic because the \n.rst invariant is, in a sense, too general, for any (.lo up (.lo up 0 ,.0 )= 1 ,.1 ) approximates a 0-step \nsegment. Speci.\u00adcally, the equality constraint (.0 lo,.0 up)=(.0 lo,.0 up) is not required in the initial \nstate (i.e., the left data element)but is required in the .rst iterate (i.e., the right data element). \nMoreover, the segment between .0 and .1 is only an approximation of the corresponding subgraph on the \nright when (.0 lo,.0 up)=(-8, 8). This example illustrates one of the dif.culties that we sketched in \nSection 2. As the symbolic values form the coordinates of the base data domain, it is quite sensitive \nto large changes in the shape graph. Here, we see that between the graph at the initial state and the \njoin, a0 has been split into .0 and .1 and (.0 lo,.0 up) has up up been split into (.0 lo,.0 ) and (.1 \nlo,.1 ). However, we observe that this becomes a non-issue once the graph stabilizes. Therefore, we propose \nto delay the join of the data invariants until the next iteration, which is a common static analysis \ntechnique. Now, for the case where the cursoris advancedto the right sub\u00adtree in the .rst iteration, \nthe result of the widening yields the same shape graph shown above and marked as( ). The data constraints \nare, however, as follows: = .lo = .up = .up -8 = .lo <.lo <d<.up = 8 011 110 The join of the numerical \ninvariants corresponding to the left and right branches after one iteration is as follows: lo lolo = \n.up = .up -8 = .= .= .<d<.up = 8 ( ) 011 110 After the next iteration, we get the following two shape \ngraphs: The computation of the join of each of these invariants with the result of the .rst widening \noutput( )reveals that the latter is stable at the shape level. Furthermore, from this point, the data \ninvariant marked as( )above is also stable, so we have obtained a .xed point. The loop invariant says \nthat at anystep of the .nd, the cursor c points to a subtree of t where the range of the data values \nin the subtree contains d. Example 7 also shows the other dif.culty alluded to in Sec\u00adtion2, whichwas \nsolvedbya different technique.In the above, the rangeof the subtreeis not onlyexpressedin the checker \nparame\u00adtersofa folded regionbut also as .eldsof unfolded nodes.With\u00adout these .elds, the resulting situation \nof the .rst widening (shown in display(*)) is similar to what is described above without the delayed \njoin of data invariants. Speci.cally, we would get a too general instantiation of the partial checker \nedge where the lower bound at the head( .0 lo)couldbeanyvalue smaller thanthekeyat the root. The valuation \ntransformer .r is never constrained so that .r(.lo .r(.lo \u00dflo 0 )= 1 )= 0 . This folding would be sound, \nbut it would not allow folding at the next step, due to being too general. Instead, with these .elds, \nwe break the dependence on synthesizing the appropriate less general parameters. Example6does not re\u00adquire \nsuch .elds because of the tight constraints on the parameters. We note that this kind of technique is \nalso rather common in veri\u00ad.cation (e.g., McPeak and Necula (2005)), which we apply here to separate \nthe analysis concerns from the modeling ones. 6. Experimental Evaluation We have applied a prototype \nimplementation of our shape analysis forCcodetoa setof data structure manipulation benchmarks.Ta\u00adble1presents \nanalysis statisticsexecuted ona 2.0GHz Intel Xeon with 2GB of RAM. In each case, we veri.ed that the \npointer ma\u00adnipulation preserved the structural invariants of the data structures (e.g., back-pointer \nproperty, acyclicity, non-sharing, treeness).We did not verify anynumerical properties on the node data, \nas we do not yet have an effective interface to implementations of numerical base domains. In the table, \nwhen the operation exists for the non\u00adback pointer analogue (i.e., singly-linked list vs. doubly-linked \nlist and tree vs. tree with parent pointers), we show the analysis time Table 1. Benchmark results forverifying \nshape preservation.We show the analysis time, the maximum number of disjuncts at any program point (Disj.), \nand the maximum number of iterations at anypoint (Iter.). Where applicable, we also show the analysis \ntime for the analogous operation in the structure without back pointers. With Back Pointers Without Benchmark \nTime (sec) Disj. (num) Iter. (num) Time (sec) list reverse 0.0014 1 3 0.0006 list copy 0.0053 2 3 0.0037 \nlist insert 0.0038 2 4 0.0049 list insert* 0.0042 2 4 - list remove* 0.0065 5 4 - list remove and back \n0.0068 5 4 - search tree insert 0.0083 5 5 0.0148 search tree insert and back 0.0470 5 5 - of the non-back \npointer variant as a point of comparison. The in\u00adsert and remove cases marked with * are variants where \nthe search for the location to do the operation is done with only one cursor, so back pointers are required \nto perform the operation. The list remove and back example .nds an element if it exists, removes it, \nand walks back modifying the previous nodes (e.g., updating a length .eld); the tree insert and back \nis similar. In all the test cases, the analysis times are negligible,but more importantly, the maximum \nnumber of disjuncts (i.e., the number of shape graphs), weneedtokeepatanyprogrampoint seemstobe small. \n7. Example: Red-BlackTrees We now return to the red-black tree insertion example from Fig\u00adure 1, Section \n2 to discuss how the invariants in the rebalancing loop after an insertion can be obtained. In Figure \n8, we present one of the rebalancing cases in detail with the .xed-point invariants shownatkeypoints.At \nprogrampoint21,weshowaloopinvari\u00adant for the rebalancing loop that is suf.cient to show that after the \nloop, a (pointed toby *t )is a red-black tree according to checker rbtree. The shape portion of the loop \ninvariant indicates that d and e are red-black trees (with certain parameters)but perhaps not lo\u00adcally \naround \u00df . In the data portion, we have the ordering property on the data (shown at the bottom), which \nis obtained in the search loop (lines 2 to 8) prior to the insertion. Note that this ordering invariant \nis obtained by the analysis algorithm as described in the example wideningona binary search treetraversal(Example7of \nSection 5.2.2) and then preserved in this loop. The other data con\u00adstraints describe the invariant on \nthe black height parameters of the checkers (e.g., \u00dfbh). The top constraintgives the relation between \nthe black height at \u00df with those at d and e,which .rst comes from the unfolding of the rbtree in the \nsearch loop and then notably pre\u00adserved on insertion (line 9). The middle constraint is the relation \nbetween the black height at a with the subtree at \u00df (where bh is the initial black height of the entire \ntree and \u00df. bh is the black height checker parameter at the end of segment to \u00df as opposed to \u00dfbh that \nis the black height parameter from \u00df ). This invariant is also obtained in the search loop and in the \nsame manner as the example widening on lists of given length (Example 6). However, the base domain should \nbe richer to handle the additional boolean structure (on whether a node is red or black) by using, for \nexample, binary decision diagrams (BDDs) with linear equalities at the leaves. Observe that we have no \nconstraints on the red-ok parameters (e.g., eredok)meaning that any of d , e, and \u00df may be red and thus \nlocally violating the color aspect of the red-black tree invariant for the entire structure. The shown \nrebalancing case addresses 10 while (pa != null ) {11 if (pa->r &#38;&#38; pa->r->r &#38;&#38; pa->r->clr \n== RED &#38;&#38; pa->r->r->clr == RED) {12 son = pa->r; 13  son->r->clr = BLACK; 14 son->p = pa->p; \nset pa->p s l /r .eld to replace pa with son ; 15 pa->r = son->l; if (son->l) { son->l->p = pa; }16 son->l \n= pa; pa->p = son; 17 pa = son; 18 } 19 ... other rebalancing cases ... 20 son = pa; pa = pa->p;  \n21 } Figure 8. Rebalancing in the red-black tree insertion example. this violation by performing a left \nrotation and coloring. From program point 21 to 13, the analysis does a backward unfolding to materialize \nthe .elds of pa . This unfolding (along with abh-\u00df. = bh bh - \u00dfbh) yields the additional black height \nconstraint on .bh and \u00dfbh . Then the condition that \u00dfclr = red (and an unfolding constraint on eredok)tells \nus that.clr = black.For compactness, we do not show the unfolding of e, which is needed only to access \nits color .eld. Aside from the coloring of e, the rotation only affects the graph (as shown at point \n18). Now, compare this after-rotation state with the loop invariant at 21. We see that the after-rotation \nstate is contained in the loop invariant (after advancing the cursor pa )by folding the region from. \nintoa rbtree , which is computed by the join as described in Section 5.2.2. In the data constraints, \nthe keyobservation is that the coloring gives us that .bh = dbh = ebh . Also, while the new black height \nat \u00df and e increase by one, this is summarizedby the difference equality constraint. 8. RelatedWork In \nthe past few years, we note a growing interest in shape analyses based on inductive de.nitions in separation \nlogic. Distefano et al. (2006)build into the analysisa singly-linked list segment predicate with specialized \nfolding rules (in a unary canonicalization opera\u00adtion). Berdine et al. (2007) have extended this framework \nto apply to doubly-linked lists polymorphically. In contrast, our analysis al\u00adgorithmis parameterizedby \ninductive checker de.nitions that sup\u00adport data constraints and folds using a generic widening operator \n(i.e., uses iteration history). Magill et al. (2007) propose an analy\u00adsis for length-speci.ed lists (like \nlistn )that is staged as opposed to a reduced product: the shape analysis is performed prior to apply\u00ading \nthe numerical analysis. This design has clear engineering ad\u00advantagesbut may make it harder to achieve \nthe desired precision. Also, like the works mentioned previously, the length-speci.ed list predicate \nisbuilt into the analysis, which enables the domain op\u00aderations to be tuned for the relational aspects. \nGuo et al. (2007) describe a global shape analysis that synthesizes inductive struc\u00adtural invariants \n(i.e., shape only) from construction patterns present in the code. In contrast, our approach is to focus \nthe shape analysis based on developer intent, which often includes intertwined data constraints. Theyalso \ndescribe a notion similar to segments ( trun\u00adcation points ), though it is unclear how unfolding is applied. \nTVLA (Sagiv et al. 2002) is a well-known, very powerful and generic framework based on three-valued logic \nfor setting up shape analyses. It has been widely used to verify complex structures and has proven able \nto tackle deep properties, such as sortedness (Lev\u00adAmietal.2000).Alarge amountofongoingworkonthistopicad\u00addresses \nscalability (e.g., Arnold (2006)). Our parametric framework seems to offer an interesting balance between \nexpressivity and ef\u00ad.ciency(Chang et al. 2007); the present contribution signi.cantly extends it to accommodate \ndata invariants and relational shapes. The abstract interpretation-based analysis proposedby Gulwani \nandTiwari (2007)is based on an encodingof shapeinvariants into quiteexpressive .. quanti.ed formulas \nthat essentially correspond to our checker edges. The existential de.nes a segment endpoint (i.e., a \nbound on the recursion depth), while the universal gives the induction.Also,itdoesnotmakeexplicituseof \nseparationandthus requires may/must alias information to be recomputed on the .y. Shape analysis-based \non reference counting and region infer\u00adence techniques has proven quite successful in addressing cer\u00adtain \nrelational properties, such as the balance invariant in AVL trees (Rugina 2004) and doubly-linked lists \n(Cherem and Rugina 2007) at a very reasonable cost. However, it is not clear how to extend the analysis \nto more global properties, such as the search tree ordering invariant, amenable to the shape analyses \nmentioned previously. There is also a large body of work on using veri.ca\u00adtion procedures for shape properties \n(e.g., Nguyen et al. (2007); Chatterjee et al. (2007); McPeak and Necula (2005); M\u00f8ller and Schwartzbach \n(2001)). These techniques typically address expres\u00adsive setsof predicatesbut requirethe userto supplyloopinvariants. \nAnother relevant line of work addresses array properties. Whereas no folding/unfolding of specialized \nstructures need to be consid\u00adered, partitioning and summarization of array cells are required. In particular, \nGopan et al. (2005) utilize canonical abstraction and nu\u00admerical abstract domains to achieve this, while \nCousot (2003) uses parametric predicate abstraction. 9. Conclusion We have described a generic framework \nfor relational inductive shape analysiswith user-suppliedinvariantcheckers.Wehavehigh\u00adlighted the dif.culties \nwith relational checkers, which include in\u00advertible structural invariants, such as in doubly-linked lists, \nas well as intertwined data and shape invariants, such as in binary search trees. Thekeymechanisms wehave \nintroducedto enable relational shape analysis are the notion of (generic) inductive segments and a two-phased \nwidening operator over the combination of shape and data domains. Moreover, we have introduced a typing \nof checker parameters with an inference algorithm that is then utilized to con\u00adtrol the .ring of unfoldings \nin the abstract interpretation. Finally, we have shown the applicability of our analysis algorithm to \nthe correctness veri.cation of insertion for red-black trees (including both the ordering and balance \ninvariants). Acknowledgments We thank George Necula for valuable discussions and his support of this \nproject, as well as the anonymous referees for providing helpful comments on drafts of this paper. This \nresearch was sup\u00adported in part by NSF under grants CCR-0326577, CCF-0524784, and CNS-0509544; and an \nNSF Graduate Research Fellowship. References Gilad Arnold. Specialized 3-valued logic shape analysis \nusing structure\u00adbased re.nement and loose embedding. In Static Analysis (SAS), 2006. Josh Berdine, Cristiano \nCalcagno, Byron Cook, Dino Distefano, PeterW. O Hearn, ThomasWies, and HongseokYang. Shape analysis for \ncom\u00adposite data structures. In Computer-AidedVeri.cation (CAV), 2007. Bor-Yuh Evan Chang, Xavier Rival, \nand George C. Necula. Shape analysis with structural invariant checkers. In Static Analysis (SAS), 2007. \nShaunak Chatterjee, Shuvendu K. Lahiri, Shaz Qadeer,and Zvonimir Raka\u00admaric. A reachability predicate \nfor analyzing low-level software. In Tools and Algorithms for the Construction and Analysis of Systems \n(TACAS), 2007. Sigmund Cherem and Radu Rugina. Maintaining doubly-linked list in\u00advariants in shape analysis \nwith local reasoning. In Veri.cation, Model Checking, and Abstract Interpretation (VMCAI), 2007. Patrick \nCousot. Veri.cation by abstract interpretation. In Veri.cation: Theory and Practice, 2003. Patrick Cousot \nand Radhia Cousot. Abstract interpretation:Auni.ed lattice model for static analysis of programs by construction \nor approximation of .xpoints. In Principles of Programming Languages (POPL), 1977. Dino Distefano, Peter \nW. O Hearn, and Hongseok Yang. A local shape analysis based on separation logic. In Tools and Algorithms \nfor the Construction and Analysisof Systems(TACAS), 2006. Denis Gopan, Thomas W. Reps, and Shmuel Sagiv. \nA framework for numeric analysis of array operations. In Principles of Programming Languages (POPL), \n2005. Sumit Gulwani and AshishTiwari. An abstract domain for analyzing heap\u00admanipulating low-level software. \nIn Computer-AidedVeri.cation (CAV), 2007. Bolei Guo, NeilVachharajani, and David I. August. Shape analysis \nwith inductive recursion synthesis. In Programming Language Design and Implementation (PLDI), 2007. Michael \nKarr.Af.ne relationships amongvariablesofa program. Acta Inf., 6, 1976. OuksehLee, HongseokYang,andKwangkeunYi. \nAutomaticveri.cation of pointer programs using grammar-based shape analysis. In European Symposium on \nProgramming (ESOP), 2005. Tal Lev-Ami, Thomas W. Reps, Shmuel Sagiv, and Reinhard Wilhelm. Putting static \nanalysis towork forveri.cation:Acase study. In Software Testing and Analysis (ISSTA), 2000. Stephen Magill, \nJosh Berdine, Edmund Clarke, and Byron Cook. Arith\u00admetic strengthening for separation logic based shape \nanalyses. In Static Analysis (SAS), 2007. Scott McPeak and George C. Necula. Data structure speci.cations \nvia local equality axioms. In Computer-AidedVeri.cation (CAV), 2005. Antoine Min \u00b4 e. The octagon abstract \ndomain. Higher-Order and Symbolic Computation, 19(1), 2006. Anders M\u00f8ller and Michael I. Schwartzbach. \nThe pointer assertion logic engine. In Programming Language Design and Implementation (PLDI), 2001. Huu \nHai Nguyen, Cristina David, Shengchao Qin, and Wei-Ngan Chin. Automatedveri.cationofshapeandsize propertiesvia \nseparationlogic. In Veri.cation, Model Checking, and Abstract Interpretation (VMCAI), 2007. John C. Reynolds. \nSeparation logic: A logic for shared mutable data structures. In Logic in Computer Science (LICS), 2002. \nRadu Rugina. Quantitative shape analysis. In Static Analysis (SAS), 2004. Shmuel Sagiv, ThomasW. Reps, \nand ReinhardWilhelm.Parametric shape analysis via 3-valued logic. ACMTrans. Program. Lang. Syst., 24(3), \n2002. ArnaudVenet. Abstract co.bered domains: Applicationtothe alias analysis of untyped programs. In \nStatic Analysis (SAS), 1996.  \n\t\t\t", "proc_id": "1328438", "abstract": "<p>Shape analyses are concerned with precise abstractions of the heap to capture detailed structural properties. To do so, they need to build and decompose summaries of disjoint memory regions. Unfortunately, many data structure invariants require relations be tracked across disjoint regions, such as intricate numerical data invariants or structural invariants concerning back and cross pointers. In this paper, we identify issues inherent to analyzing relational structures and design an abstract domain that is parameterized both by an abstract domain for pure data properties and by user-supplied specifications of the data structure invariants to check. Particularly, it supports hybrid invariants about shape and data and features a generic mechanism for materializing summaries at the beginning, middle, or end of inductive structures. Around this domain, we build a shape analysis whose interesting components include a pre-analysis on the user-supplied specifications that guides the abstract interpretation and a widening operator over the combined shape and data domain. We then demonstrate our techniques on the proof of preservation of the red-black tree invariants during insertion.</p>", "authors": [{"name": "Bor-Yuh Evan Chang", "author_profile_id": "81464662824", "affiliation": "University of California: Berkeley, Berkeley, CA", "person_id": "PP43124952", "email_address": "", "orcid_id": ""}, {"name": "Xavier Rival", "author_profile_id": "81100659525", "affiliation": "INRIA - ENS, Paris, France", "person_id": "P502800", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1328438.1328469", "year": "2008", "article_id": "1328469", "conference": "POPL", "title": "Relational inductive shape analysis", "url": "http://dl.acm.org/citation.cfm?id=1328469"}