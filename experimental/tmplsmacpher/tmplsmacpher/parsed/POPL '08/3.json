{"article_publication_date": "01-07-2008", "fulltext": "\n Contextual EffectsforVersion-Consistent Dynamic Software Updating and Safe Concurrent Programming Iulian \nNeamtiu Michael Hicks JeffreyS.Foster Polyvios Pratikakis Department of Computer Science University of \nMaryland CollegePark,MD 20742, USA {neamtiu,mwh,jfoster,polyvios}@cs.umd.edu Abstract This paper presents \na generalization of standard effect systems that we call contextual effects. A traditional effect system \ncomputes the effect of an expression e. Our system additionally computes the effects of the computational \ncontext in which e occurs. More speci.cally, we compute the effect of the computation that has already \noccurred (the prior effect)and the effect of the computation yet to take place (the future effect). Contextual \neffects are useful when the past or future compu\u00adtation of the program is relevant at various program \npoints. We present two substantial examples. First, we show how prior and future effects can be used \nto enforce transactional version consis\u00adtency (TVC),anovel correctness property for dynamic software \nup\u00addates. TVC ensures that programmer-designated transactional code blocks appeartoexecute entirelyatthe \nsamecodeversion,evenifa dynamic update occurs in the middle of the block. Second, we show how future \neffects can be used in the analysis of multi-threaded programs to .nd thread-shared locations. This is \nan essential step in applications such as data race detection. Categories and Subject Descriptors F.3.2 \n[Semantics of Pro\u00adgramming Languages]: Program analysis; C.4[Performance of Systems]: Reliability,availability, \nand serviceability; D.1.3[Pro\u00adgrammingTechniques]: Concurrent Programming General Terms Languages, Reliability, \nTheory,Veri.cation Keywords Contextual effects, computation effects, type and ef\u00adfect systems, version \nconsistency, dynamic software updating, data race detection 1. Introduction Type and effect systems provide \na framework for reasoning about the possible side effects of a program s executions. Effects tra\u00additionally \nconsider assignments or allocations, but can also track otherevents, such as functions called or operations \nperformed.A standard type and effect system (Lucassen 1987; Nielson et al. 1999) proves judgments e;G \nf e : t , where e is the effect of the expression e.For manyapplications, knowing the effect of the Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page.To copyotherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 08, January 7 12, 2007, \nSan Francisco, California, USA. Copyright c &#38;#169; 2008ACM 978-1-59593-689-9/08/0001...$5.00 context \nin which e appearsis also useful.Forexample,if e includes a security-sensitive operation, then knowing \ntheeffectofexecution prior to evaluating e could be used to support history-based access control (Abadi \nandFournet 2003; Skalka et al. 2007). Conversely, knowingtheeffectofexecution following e could be used \nfor some forms of staticgarbage collection, e.g., to free initialization func\u00adtions once initialization \nis complete (Foster et al. 2006). The core idea of this paper is a generalization of standard effect \nsystems to compute what we call contextual effects. Our contextual effect system proves judgments of \nthe form F; G f e : t, where F is a tuple [a; e; .] containing e, the standard effect of e, and a and \n., the prior effect and future effect, respectively, of e s context.For example, in an application e1 \ne2, the prior effect of e2 includes the effect of e1, and likewise the future effect of e1 includes the \neffect of e2. The .rst contribution of this paper is a system for computing contextual effects and a \nproof that the system is sound (Section 2). The inspiration for contextual effects arose from experience \nwith two research projects. The .rst considers dynamic software updating (DSU), a technique by which \nrunning software can be updated on-the-.y with new code and data. In prior work we for\u00admalized and implemented \nGinseng, a compiler and tool suite that supports DSU forC programs (Neamtiu et al. 2006; Stoyle et al. \n2007). Updates are at the granularity of function calls, meaning that following an update, active code \ncontinues with the old ver\u00adsion, while subsequent calls aretothenewversion.Akeyconsid\u00aderation for update \ncorrectness is timing, since, applied at the wrong time, the changes due to an update could con.ict with \nprocessing in .ight.Forexample, suppose the original codede.ned function h() { f (); g (); },but then \nis changed to move the call to g from h to f, i.e., h() { f (); } and f () { ...; g (); }. Suppose the \nupdate occurs just prior to the original pair of calls. The call to f will be to the new version that \ncalls g,but then returns to its caller, the old h, which then calls g again, potentially leading to an \nerror. We address this problem with a novel correctness property called transactional version consistency \n(TVC), the second con\u00adtribution of this paper. In this approach, programmers designate blocks of code \nas transactions whose execution must always be attributable to a single program version. Thus an update \nis only allowed within a transaction if the transaction s execution still ap\u00adpears due to either the \nold or new program version. The problem\u00adatic update above would be ruled out by placing the body of h \nin a transaction.We formalize this ideaina small language Proteus-tx, whichextends our prior dynamic \nupdating calculus Proteus (Stoyle et al. 2007) with transactions. Proteus-tx s type system uses con\u00ad \ntextual effects at candidate update points within a transaction to determine what updates are safe to \napply. We have proven that Proteus-tx enforces transactional version consistency, and we have developed \na preliminary implementation for C. In our prior work, we manually speci.ed that updates could occur \nat one ortwo qui\u00adescent program points, typically at the conclusion of event pro\u00adcessing loops (Neamtiu \net al. 2006). Using these quiescent points to identify transaction boundaries, we discovered manyadditional \nversion-consistent update points within transactions, which can be used to reduce the time from when \nan update becomes available to when it is applied (Section 3). The second research effort from which \ncontextual effects arose is Locksmith (Hicks et al. 2006; Pratikakis et al. 2006), a tool that can automatically \ndetect data races inCprograms.We found that we could use contextual effects to compute what memory locations \nare shared among threads in a multi-threaded program. The basic idea is that thread-shared locations \nare exactly those in the intersection of the standard effect of a child thread and the future effect \nof the parent thread at the point the child is created. Locations accessed prior to creating the childbut \nnot afterward are not shared. The .nal contribution of this paper is a presentation of our algorithm \nfor computing shared locations as an extension to contextual effects. We used this analysis to compute \nshared locationsina rangeofCprograms. Our algorithm .nds that many locations are thread-local, and hence \ncannot have races (Section 4). We believe that contextual effects have many other uses, in particular \nanyapplication in which the past or future computation ofthe programisrelevantatvarious programpoints.The \nremainder of the paper presents our core contextual type and effect system, followedbyits applicationto \ntransactionalversion consistencyand thread sharing analysis. 2. Contextual effects To begin, we present \na core contextual effect system for a sim\u00adple imperative calculus and prove it sound. Figure1 presents \nour source language, which contains expressions e that consist of val\u00adues v (integers or functions); \nvariables; let binding; function appli\u00adcation; and the conditional if0, which tests its integer-valued \nguard against 0. Our language also includes updatable references ref L e along with dereference and assignment. \nHere we annotate each syn\u00adtactic occurrence of ref with a label L, which serves as the abstract name \nfor the locations allocated at that program point.We use la\u00adbels to de.ne contextual effects.For simplicity \nwe do not model recursive functions directly in our language, but they can be en\u00adcoded using references. \nOur system uses two kinds of effect information. An effect, written a, e, or ., is a possibly-empty set \nof labels, and may be 1, the set of all labels.A contextual effect, written F, is a tuple [a; e; .]. \nIn our system, if e' is a subexpression of e, and e' has contextual effect [a; e; .], then The current \neffect e is the effect of evaluating e' itself.  The prior effect a is theeffectofevaluating e up until \nwe begin evaluating e'.  The future effect . is the effect of the remainder of the evalua\u00adtion of e \nafter e' is fully evaluated.  Thus e is the effect of e' itself, and a .. is the effect of the context \nin which e' appears and therefore a . e . . contains all locations accessed during the entire reduction \nof e. To make contextual effects easier to work with, we introduce some shorthand.We write Fa , Fe, and \nF. for the prior, current, and future effect components, respectively, of F.We also write F\u00d8 for the \nempty effect [1; \u00d8; 1] by subsumption, discussed below, an expression with this effect may appear in \nany context. In what follows, we refer to contextual effects simply as effects, for brevity. Expressions \ne ::= v | x | let x = e in e | ee | if0 e then e else e | refL e | ! e | e := e Values v ::= n | .x.e \nEffects a, e, . ::= \u00d8| 1 |{L}| e . e Contextual Effs. F ::= [a; e; .] Types t ::= int | ref e t | t -.F \nt Labels L Figure 1. Contextual effects source language Typing G(x)= t (TINT) (TVAR) F\u00d8;G f n : int F\u00d8;G \nf x : t F1;G f e1 : t1 F2;G,x : t1 f e2 : t2 F1 1 F2 '. F (TLET) F; G f let x = e1 in e2 : t2 F1;G f \ne1 : int F2;G f e2 : t F2;G f e3 : t F1 1 F2 '. F (TIF) F; G f if0 e1 then e2 else e3 : t F; G f e : \nt (TREF) F; G f refL e : ref {L} t F1;G f e : ref e t Fe = e F1 1 F2 '. F (TDEREF) 2 F; G f ! e : t F1;G \nf e1 : ref e t F2;G f e2 : t Fe = e F1 1 F2 1 F3 '. F (TASSIGN) 3 F; G f e1 := e2 : t F; G,x : t' f e \n: t (TLAM) F\u00d8;G f .x.e : t' -.F t F1;G f e1 : t1 -.Ff t2 F2;G f e2 : t1 F1 1 F2 1 Ff '. F (TAPP) F; G \nf e1 e2 : t2 F';G f e : t' t' = t F' = F (TSUB) F; G f e : t Effect combinator F1 =[a1; e1;(e2 . .2)] \nF2 = [(e1 . a1); e2; .2] F=[a1;(e1 . e2); .2] (XFLOW-CTXT) F1 1 F2 '. F Subtyping (SINT) int = int (SREF) \nt = t' t' = t ref e t = ref e' e . e' t' (SFUN) t'1 = t1 t2 = t'2 F = F' t1 -.F t2 = t'1 -.F' t'2 (SCTXT) \na2 . a1 e1 . e2 .2 . .1 [a1; e1; .1] = [a2; e2; .2] Figure 2. Contextual effects type system 2.1 Typing \nWe now present a type and effect system to determine the contex\u00adtualeffectofevery subexpressionina program.Types \nt , listed at the end of Figure 1, include the integer type int;reference types ref e t , which denote \na reference to memory of type t where the reference itself is annotated with a label L . e;and function \ntypes t -.F t ',wheret and t ' are the domain and range types, respec\u00adtively, and the function has contextual \neffect F. Figure 2 presents our contextual type and effect system. The rules prove judgments of the form \nF; G f e : t, meaning in type environment G, expression e has type t and contextual effect F. The .rsttwo \nrules,(TINT)and(TVAR), assigntheexpectedtypes and the empty effect, since values have no effect. (TLET)types \nsubexpressionse1 and e2, which have effects F1 and F2, respectively, and requires that these effects \ncombine to form F, theeffectof the entireexpression.We usea call-by-value semantics, and hence the effect \nof the let should be the effect of e1 followed by the effect of e2.We specify the sequencing of effects \nwith the combinator F1 C F2 '. F, de.ned by (XFLOW-CTXT) in the middle part of Figure 2. Since e1 happens \nbefore e2, this rule requires that the future effect of e1 be e2 . .2, i.e., everything that happens \nduring the evaluation of e2, captured by e2, plus everything that happens after, captured by .2. Similarly, \nthe past effect of e2 must be e1 . a1, since e2 happens just after e1. Lastly, the effect F of the entire \nexpression has a1 as its prior effect, since e1 happens .rst; .2 as its future effect, since e2 happens \nlast; and e1 . e2 as its current effect, since both e1 and e2 are evaluated. We write F1 C F2 C F3 '. \nF as shorthand for (F1 C F2 '. F ' ) . (F ' C F3 '. F). (TIF)requires that its branches have the same \ntypet and ef\u00adfect F2, which can be achieved with subsumption (below), and uses C to specify that F1, \nthe effect of the guard, occurs before either branch. (TREF)types memory allocation, which has no ef\u00adfectbut \nplaces the annotation L into a singleton effect {L} on the output type. This singleton effect can be \nincreased as necessary by using subsumption. (TDEREF)types the dereference of a memory location of type \nref e t . In a standard effect system, the effect of ! e is the effect of e plus the effect e of accessing \nthe pointed-to memory. Here, the effect of e is captured by F1, and because the dereference occurs after \ne is evaluated, (TDEREF)putsF1 in sequence just before some F2 such that F2 s current effect is e. Thereforeby(XFLOW\u00adCTXT),Fe \nis Fe 1 . e, and e s future effect F. 1 must include e and the future effect of F2. On the other hand, \nF. 2 is unconstrained by this rule, but it will be constrained by the context, assuming the dereference \nis followed by another expression. (TASSIGN)is similar to (TDEREF), combining the effects F1 and F2 of \nits subexpressions with a F3 whose current effect is e. (TLAM)types the function bodye and sets the effect \non the function arrow to be the effect of e. The expression as a whole has no effect, since the function \nproduces no run-time effects until it is actually called.(TAPP)types function application, which combines \nF1, the effect of e1, with F2, the effect of e2, and Ff , the effect of the function. The last rule in \nour system, (TSUB), introduces subsumption on types and effects. The judgments t ' = t and F ' = F are \nde.nedatthe bottomof Figure2.(SI NT),(SREF),and(SFUN)are standard, with the usual co-and contravariance \nwhere appropriate. (SCTXT) de.nes subsumption on effects, which is covariant in the current effect, as \nexpected, and contravariant in both the prior and future effects.To understand the contravariance, .rst \nconsider an expression e with future effect .1. Since future effects should soundly approximate (i.e., \nbe a superset of) the locations that may be accessed in the future, we can use e in anycontext that accesses \nat most locations in .1. Similarly, since past effects approximate Values v ::= ... | rL Heaps H ::= \n\u00d8| H, r . v Environments G ::= \u00d8| G,x : t | G,r : t [ID] (a, ., H, v) -.\u00d8 (a, ., H, v) (a, ., H, e1) \n-.e1 (a1,.1,H1, .x.e) (a1,.1,H1,e2) -.e2 (a2,.2,H2,v2) ' (a2,.2,H2,e[x . v2]) -.e3 (a ' ,. ' ,H ,v) [CALL] \n' (a, ., H, e1 e2) -.e1.e2.e3 (a ' ,. ' ,H ,v) ' (a, ., H, e) -.e (a ' ,. ' ,H ,v) r/. dom(H ' ) [REF] \n' (a, ., H, refL e) -.e (a ' ,. ' , (H ,r . v),rL) ' (a, ., H, e) -.e (a ' ,. ' .{L},H ,rL) r . dom(H \n' ) [DEREF] (a, ., H, ! e) -.e.{L} (a ' .{L},. ' ,H ' ,H ' (r)) (a, ., H, e1) -.e1 (a1,.1,H1,rL) (a1,.1,H1,e2) \n-.e2 (a2,.2 .{L}, (H2,r . v ' ),v) [ASSIGN] (a, ., H, e1 := e2) -.e1.e2.{L}(a2 .{L},.2, (H2,r . v),v) \n(a, ., H, e1) -.e1 (a1,.1,H1,v1) v1 =0 (a1,.1,H1,e2) -.e2 (a2,.2,H2,v) [IF-T] (a, ., H, if0 e1 then e2 \nelse e3) -.e1.e2 (a2,.2,H2,v) (a, ., H, e1) -.e1 (a1,.1,H1,v1) v1 = n =0 (a1,.1,H1,e3) -.e3 (a3,.3,H3,v) \n[IF-F] (a, ., H, if0 e1 then e2 else e3) -.e1.e3 (a3,.3,H3,v) (a, ., H, e1) -.e1 (a1,.1,H1,v1) (a1,.1,H1,e2[x \n. v1]) -.e2 (a2,.2,H2,v2) [LET] (a, ., H, let x = e1 in e2) -.e1.e2 (a2,.2,H2,v2) Figure 3. Contextual \neffects operational semantics (partial) locations that were accessed in the past, we can use e in anycontext \nthat accessed at most locations in a1. 2.2 Semantics and Soundness We now prove that our contextual \neffect system is sound. The top of Figure3gives some basic de.nitions needed for our operational semantics.We \nextend values v to include the form rL, which is a run-time heap location r annotated with label L.We \nneed to track labels through our operational semantics to formulate and prove soundness,but these labels \nneed notexist at run-time.We de.ne heaps H to be maps from locations to values. Finally, we extend typing \nenvironments G to assign types to heap locations. The bottom partof Figure3de.nesa big-step operational \nse\u00ad mantics for our language. Reductions operate on con.gurations (a, ., H, e), where a and . are the \nsets of locations accessed be\u00adfore and after evaluation of e, respectively; H is the heap; and e is the \nexpression to be evaluated. Evaluations have the form '' ' (a, ., H, e) -.e (a ,. ,H ,R) where e is theeffectofevaluating \ne and R is the result of reduction, either a value v or err, indicatingevaluationfailed. Intuitively, \na records what has happened in the past, and . is a capability de\u00adscribing what locations may be accessed \nin the future. As evalua\u00adtion proceeds, labels move from the future . to the past a. The reduction rules \nare straightforward.[ID]reducesavalueto itself without changing the state or the effects. [CALL]evaluates \nthe .rst expression to a function, the second expression to a value, and then the function body with \nthe formal argument replaced by the actual argument. [REF]generates a fresh locationr, which is bound \nin the heap to v and evaluates to rL. [DEREF]reads the location r in the heap and adds L to the standard \nevaluation effect. This rule requires that the future effect after evaluating e have the form . ' .{L}, \ni.e., L must be in the capability after evaluating e. Then L is added to a ' in the the output con.guration \nof the rule. Notice that . ' .{L} isastandard union, and so L may also be in . ' , which is needed so \nthe same location can be accessed multiple times.[ASSIGN]behaves similarly to[DEREF]. Lastly,[IF-T]and[IF-F]give \nthe two cases for conditionals, and [LET] binds x to the result of evaluating e1 inside of e2. Our semantics \nalso includes rules (not shown) that produce err when the program tries to access a location that is \nnot in the input capability, or when values are used at the wrong type. Given this operational semantics, \nwe can now prove that the contextualeffect systemin Figure2is sound. Dueto limited space, we only state \nour lemmas and theorems. The proofs can be found in full in our companion technical report (Neamtiu et \nal. 2007). We begin with a standard de.nition of heap typing. De.nition 2.1 (HeapTyping). We say heap \nH is well-typed un\u00adder G, written G f H, if dom(G) = dom(H) and if for every r . dom(H), we have F\u00d8;G \nf H(r) : G(r). Given this de.nition, we show the standard effect soundness theorem, which states that \nthe program does not go wrong and that the standard effect Fe captures the effect of evaluation. Theorem \n2.2 (Standard Effect Soundness). If F; G f e : t and G f H and (1, 1, H, e) -.e (1, 1,H ' ,R), then there \nis a G ' . G suchthatRisavalue v for which F0;G ' f v : t where G ' f H ' and e . Fe . Next, we show \nthe operational semantics is adequate, in that it moves effects from the future to the past during evaluation. \nLemma 2.3 (Adequacy of Semantics). If (a, ., H, e) -.e (a ' ,. ' ,H ' ,v) then a ' = a . e and . = . \n' . e. Next we must de.ne what it means for the statically-ascribed contextual effects of some expression \ne to be sound with respect to the effects of e s evaluation. Suppose that ep is a program that is well-typed \naccording to typing derivation T and evaluates to some value v as witnessed by an evaluation derivation \nD. Observe that each term e1 that is reduced in a subderivation of D is either a subterm of ep, or is \nderived from a subterm e2 of ep via reduction; inthe latter caseitis soundtogive e1 the same type and \neffect that e2 has in T .Toreason about the soundness of the effects, therefore, we must track the static \neffect of expression e2 as it is evaluated. Our approach has two parts. First, we de.ne a set of inference \nrules that relate evaluation terms to terms, types, and effects in the original typing derivation.We \nde.ne F; G; ep fT e1 . e2 : t to mean that F; G ' f e2 : t is a subderivation of T , the typing of the \noriginal program ep,wheree2 isasubtermof ep,andF and t come from T . Second, we de.ne an algorithm FT \n(D) that constructs a derivation O :: F;G; ep fT e1 . e2 : t given an evaluation derivation D such that \ne1 is derived from e2 in D. Given such an O, we say e1 originates from e2 in ep with effect F and type \nt . Tomodel the heap, we de.ne another judgmentG fT H . ep, meaning each r in the domain of heap H originates \nfrom a ref L e in ep, with a matching type. Note that G, used to type the evaluated term e1 and the heap, \nand G ', used to type the original term e2 differ. This is because e1 does not necessarily have the same \nfree variables as e2, possibly because of substitutions that eliminate some free variables and might \nintroduce others. Also, G includes heap typing information not in G '. We also construct judgments G \nfT H . ep in our algorithm F. To show soundness, .rst we prove that for any con.guration (a, ., H, e) \nencountered while reducing ep,bothH and e originate from some sub-term of ep (lemma omitted). Then, contextual \neffect soundness means that the F of the term a redex originates from soundly approximates the prior \nand future effects of the actual evaluation: Theorem 2.4 (Prior and Future Effect Soundness). Assume \na pro\u00adgram e with no free variables. If T :: [\u00d8; 1; \u00d8]; \u00d8f ep : t and D is a derivation of (\u00d8, ., \u00d8,ep) \n-.e (a, \u00d8, H, v), then for all sub-derivations Di of D of the form Di :: (ai,.i,Hi,ei) -.ei (a ' i,. \ni' ,H i' ,vi) where FT (Di)=Fi;Gi; ep fT ei . e ' : ti, it i is the case that ai . Fa and .i ' . F. ii \n. The proof of the above theorem is by induction on the deriva\u00adtion, startingatthe rootandworkingtowardstheleavesand \nrelying on Theorem 2.2 and Lemma 2.3.  2.3 Contextual Effect Inference The typing rulesin Figure2forma \nchecking system,but wewould prefer toinfer effect annotations rather than require the program\u00admer to \nprovide them. Here we sketch the inference process, which is straightforward and uses standard constraint-based \ntechniques. We change the rulesin Figure2into inference rulesby making three modi.cations. First, we \nmake the rules syntax-driven by in\u00adtegrating (TSUB)into the other rules (Mitchell 1991); second, we add \nvariables . to represent as-yet-unknown effects; and third, we replace implicit equalities with explicit \nequality constraints. The resulting rules are mostly as expected, with one interesting difference for(TAPP).We \nmightexpect inlining subsumption into (TAPP)to yield the following rule: ' F1;G f e1 : t1 -.Ff t2 F2;G \nf e2 : t 1 ' t1 = t1 F1 1 F2 1 Ff '. F (*) F; G f e1 e2 : t2 However, this would cause the inferred Ff \neffect to be larger than necessary if there are multiple calls to the same function. For example, consider \nthe following code, where f is some one\u00adargument function, x, y, and z are references, and A and B identify \ntwo program points: ( if0 ... then /*A*/ (f 1; !x) else /*B*/ (f 2; !y)); !z If we used rule(*),then \nfrom branch A,wewould require{x, z}. F. , and from branch B, wewould require {y, z}. F., where Ff is \nthe effect of function f. Putting these together, we would thus have F.f = {x, y, z}. This result is \nappropriate, since anyof those locations may be accessed after some call to f. However, consider the \nfuture effect F.A ff A at program point A. By(XFLOW-CTXT),F. would contain F.f , and yet y will not be \naccessed once we reach A, since that access is on another branch. The analogous problem happens at program \npoint B, whose future effect is polluted by x. The problem is that our effect system con.ates all calls \nto f. One solution would be to add Hindley-Milner style parametric poly\u00admorphism, which would address \nthis particular example. However, even with Hindley-Milner polymorphism wewould suffer the same problem \nat indirect function calls, e.g., in C, calls through function pointers would be monomorphic. The solutionisto \nnotice that inlining subsumption into(TAPP) should not yield(*),but instead resultsin the following rule: \nF1;G f e1 : t1 -.Ff t2 F2;G f e2 : t1 ' Ff = Ff ' t1 ' = t1 Ff ' fresh F1 C F2 C F ' f '. F (TAPP ') \nF; G f e1 e2 : t2 1 int main() { ... 19 2 conn = accept loop(); 20 3 init log (); 21 4 handle sess (conn); \n22 5 ... } 23 6 24 7 void handle sess (conn) { 25 8 ... 26 9 while (1) { 27 10 tx { 28 11 cmd = get(conn.fd); \n29 12 if (cmd == LIST ) { 30 13 handle list (cmd); 31 14 } else ... 32 15 /* new: log log () */ 33 16 \n} /* end tx */ 34 17 } 35 18 } 36 conn accept loop() {... while (1) {tx { addr = accept(); if (! fork \n()) /* child */ return conn; }} /* end tx */ }} void handle list (cmd) { start log entry (); ... log \nlog (); /* old */ } Figure 4. High-level structure of the vsftpd server Applied to the above example, \n(TAPP ')results in two constraints on the future effect of Ff : .. .. Ff . FfA = {x, z} Ff . FfB = {y, \nz} Here FfA and FfB are the fresh function effects at the call to f in A and B, respectively. Notice \nthat we have F. = {x, y, z}, as before, f since f is called in both contexts. But now F. fA need not \ncontain y, and FfB need not contain x. Thus with (TAPP '), a function s effectsummarizes allof its contexts,but \ndoes not cause the prior and future effects from different contexts to pollute each other. To perform \ntype inference, we apply our inference rules, view\u00ading them as generating the constraints C in theirhypotheses,given \nby the following grammar: C ::= t = t ' | F = F ' | F1 C F2 '. F We can then solve the constraintsby \nperforming graph reachability to .nd, for each variable ., the set of base effects {L} or 1 that reachit.In \npractice, these constraints canbe solvedveryef.ciently usinga toolkit such as Banshee(Kodumal and Aiken \n2005), which also canbe usedtobuilda context-sensitiveversionof inference using context-free language \nreachability (Pratikakis et al. 2006). 3. TransactionalVersion Consistencyfor DSU In prior work we developed \nGinseng, a dynamic software updating (DSU) system forCprograms (Neamtiu et al. 2006; Stoyle et al. 2007). \nTo use Ginseng, programmers construct dynamic patches that contain new or updated functions and data. \nGinseng applies these patches to the running program, and then subsequent function calls and data accesses \napply to the newversions.Akey novelty of Ginseng is that it ensures dynamic updates do not violate type \nsafety while still allowing patches to change function and data types (Neamtiu et al. 2006; Stoyle et \nal. 2007), which is often necessary (Baumann et al. 2007; Neamtiu et al. 2005). However, while type safety \nis important, it is only one aspect of program correctness. In this section we introduce transactional \nversion consistency (TVC),a new property thatlets programmers reason more easily about the safety of \nupdates, and show how contextual effects can enforce TVC. To illustrate the problem with an example, \nconsider Figure 4, which sketches the structure of vsftpd, an FTP server which we have dynamically updated \nusing Ginseng (Neamtiu et al. 2006). For the moment, ignore the tx{} annotations in the code. In this \nprogram, main (lines 1 5) .rst calls accept loop, whose body (lines 19 30) contains an in.nite loop. \nEach iteration of the loop accepts a connection request (line 23) and forks a child process to handle \nthe requested session (line 24). If forking succeeds, the child returns (line 26) to main, which initializes \nthe session s log (line 3, function not shown) and processes the session (line 4) by calling handle sess \n(lines 7 18). In turn, handle sess processes client commandsuntilthe sessionis closed.Weshowone command \nprocessor, handle list (lines 32 36), which is called on line 13. This function creates a log entry (line \n33) that is .ushed when processing is .nished (line 35). Consider the following update, inspired by actual \nchanges to vsftpd. Rather than .ush the log entry at the end of each command processing function (like \nhandle list), the update changes the code todo soin handle sess instead, e.g., the call to log log on \nline 35 is moved to line 15. Once this update is applied, the next iteration of the loop will execute \nthe new version of the code.1 Thisupdateistypesafe,but noticethatitsbehaviormaybein\u00adcorrect depending \non where it occurs. Suppose Ginseng applies the update after line 15, meaning that future calls to handle \nlist and the handle sess loopbodygotothenewversion. Theneverythinghap\u00adpens correctly: we have just called \nthe old version of handle list, so logging occurred, and we .nish executing the old version of the handle \nsess loop, and thus do not call log log. The next iteration uses all new code, and so logging continues \nas usual. In contrast, suppose the update was applied at line 11. At this point we areexecuting the old \nhandle sess,but we will call thenew handle list, which no longer calls log log. Moreover, handle list \nreturns to its caller, i.e., the old handle sess, which also does not call log log. Thus no log entry \nis produced for the command. Thisexamplerevealsa violationofwhatwecall version consis\u00adtency:duetothetimingofthe \nupdate,weexecutepartoldcodeand part new code, and the overall result is inconsistent. It is easy to construct \nother problematic updates that violate program semantics in various ways depending where the update is \napplied. Prior to the current work, we maintained version consistencyin Ginseng by only allowing updates \nat programmer-speci.ed posi\u00adtions. In vsftpd, we chose update points on lines 16 and 28, at the end of \nthe connection acceptance and request processing code, just prior to the next iteration of the loop. \nHowever, this approach of having one or two well-placed update points may result in less up\u00addate availability, \nmeaning it may take longer for updates to occur once submitted to the program. While this may be reasonable \nfor single-threaded programs with low-latency event processing code, in a multi-threaded program like \nan operating system or embed\u00added system the problem could be quite serious. In particular, we would have \nto require that all threads reach their update points si\u00admultaneously for an update to take place. Since \nthis is unlikely to happen naturally, we could treat update points as synchroniza\u00adtion barriers,waiting \nuntilall threadshaveblocked before applying the update (Stoyle et al. 2007). However, this will degrade \nservice while waiting for threads to block, and at worst could introduce deadlock. 3.1 Version Consistency \nvia Contextual Effects To increase update availability while ensuring version consistency, we draw inspiration \nfrom recent work on making multi-threaded programming simpler by using atomic blocks (Harris and Fraser \n2003).Thekeybene.tof atomic blocksisthatthe programmercan consider them in isolation, because the language \nguarantees they will be serializable with respect to the rest of the computation. 1Updates to functions \nin Ginseng take effect the next time the function is called. To update the body of a long-running loop, \nprogrammers specify the loop should be treated as a tail-recursive function, which can then be updated \nusing the normal function update mechanism. Thus the update takes effect at the next iteration of the \nloop (Neamtiu et al. 2006). 1 f () // {f} = a {v, g} = . 2 v := 2; (*) // {f, v} {g} 3 g (); // {f, \nv, g} {} Figure 5. Asample transaction Analogously, we allow programmers to specify transactions within \ntheir code, and we enforce transactional version consistency (TVC), meaning that transactions execute \nas if they were entirely the old version or entirely the new version, no matter where an update actually \noccurs.Forexample,in Figure4,wehave marked the bodies of the two event-processing loops as transactions \nby placing them within tx{} blocks (lines 10 and 22), and thus the programmer can consider updates as \noccurring at lines 10 or 16 in handle sess or lines 22 or 28 in accept loop, which are equivalent to \nthe manually speci.ed locations we used earlier. We can use contextual effects to enforce TVC while still \nal\u00adlowing updates to occur within transactions.To see how, consider the code snippet in Figure 5. Comments \nshow the prior and future effects after each statement, where we include both locations ac\u00adcessed and \nfunctions called in effects. Suppose we are running this code within a transaction and have just executed \nline 2, marked with a star, when an update becomes available. At this point the transaction has called \nf and written to v (a = {f, v}), and will call g in the future(. = {g}). Consider the possible outcomes \ndepend\u00ading on the effect e of the update, where an update s effect consists of the set of functions and \nglobal variables that it adds or changes. 1. If a n e = \u00d8, e.g., the update only modi.es g (e = {g}), \nthen theupdateissafe.Inourexample,thiswould resultinusingthe newversions of f and v, which are the same \nas the oldversions, with the new version of g. It is as if we applied the update at the beginning of \nthe transaction, and the entire transaction runs under the new version. 2. If . ne = \u00d8,e.g., the update \nonly modi.esf (e = {f}),then the update is also safe. In our example, this would result in using the \nold versions of f, v, and g. Notice that although we have called f (a n e \u00d8), we never call it again \nafter the update. It  = is as if we applied the update at the end of the transaction, and the whole \ntransaction runs under the old version. 3. If a n e \u00d8 and . n e= \u00d8, e.g., the update modi.es f and g, \n= then we cannot apply the update, because that would result in using some old code(f)and some new code(g). \nPutting these together, we can apply an update with effect e any\u00adwhere in a transaction such that a n \ne = \u00d8 or . n e = \u00d8, where a and . are the prior and future effects at the update point. Our transactions \nare enforced using statically-determined con\u00adtextualeffectsas de.nedin Section2. Alternatively,we couldloga \ntransaction s actual effects at run-time and use these to check ver\u00adsion consistency. Similar to common \nimplementations of transac\u00adtional memory (Harris and Fraser 2003; Herlihyand Moss 1993), we could optimistically \napply an update when it becomes avail\u00adable, and then commit it or roll it back at the end of a transaction \ndependinghow the transaction seffectintersects with theeffectof the update. This might improve update \navailability, since contex\u00adtual effects are conservative approximations of the actual run-time effects. \nNevertheless, we believe the bene.ts of a static approach outweigh the drawbacks. First, the static approach \ndoes not pay the overhead of logging, which is unnecessary most of the time since updates are infrequent. \nSecond, there are no restrictions on the use of I/O within transactions; notice that network I/O occurs \nin both transactions in Figure 4. The optimistic approach generally must De.nitions d ::= main e | var \ng = v in d | fun f(x)= e in d Expressions e ::= v | x | let x = e in e | ee | if0 e then e else e | ref \ne | ! e | e := e | tx e | updatea,. Values v ::= n | z Effects a, ., e ::= \u00d8| 1 |{z}| e . e Global symbols \nf, g, z . GSym Dynamic updates upd ::= {chg, add} Additions add . GSym . (t \u00d7 b) Changes chg . GSym \n. (t \u00d7 b) Bindings b ::= v | .x.e Figure 6. Proteus-tx syntax, effects, and updates avoid I/O in transactions \nto properly roll back if version consis\u00adtencyis violated.  3.2 Syntax Figure6presents Proteus-tx, whichextends \nthe language from Sec\u00adtion2to model transactionallyversion-consistent dynamic updates, adapting the ideas \nof Proteus, our prior dynamic updating calcu\u00adlus (Stoyle et al. 2007). A Proteus-tx program is a de.nition \nd, which consists of an expression main e, possibly preceded by def\u00adinitions of global symbols, written \nf, g, or z and drawn from a set GSym. The de.nition var g = v in d binds mutable variable g to v within \nthe scope of d, and the de.nition fun f(x)= e in d binds f to a (possibly-recursive) function with formal \nparameter x and body e. Expressions e in Proteus-tx have several small differences from the languageof \nFigure1.Weadd global symbols z tothe setofval\u00adues v.We also remove anonymous lambda bindings tokeep things \nsimpler,for reasons discussedin Section3.4.Tomark transactions, we add a form tx e for a transaction \nwhose body is e. We specify program points where dynamic updates may occur with the term updatea,., where \nthe annotations a and . specify the prior and future effects at the update point, respectively. When \nevaluation reaches updatea,., an available update is applied if its contents do not con.ict with the \nfuture and prior effect annotations; otherwise evaluation proceeds without updating. Adynamic update \nupd consistsofapairof partial functions chg and add that describe the changes and additions, respectively, \nof global symbol bindings. The range of these functions is pairs (t,b), where b is the new or replacement \nvalue (which may be a function .x.e)andt is its type. Note that Proteus-tx disallows type-altering updates,though \nSection3.6explainshowtheycanbe supportedby employing ideas from our earlier work (Stoyle et al. 2007). \nAlso, although our implementation allows state initialization functions, for simplicity we do not model \nthem in Proteus-tx. Finally, effects in Proteus-tx consist of sets of global symbol names z, which represent \neither a dereference of or assignment to z (if it is a variable) or a call to z (if it is a function \nname). Because updates in Proteus-tx can only change global symbols (and do not read or write through \ntheir contents), we can ignore the effects of the latter (we use syntax ref e instead of ref L e). 3.3 \nTyping Figure7extendsthe core contextualeffecttypingrulesfromFig\u00adure2to Proteus-tx. The .rst three rules \nde.ne the judgment G f d, meaning de.nition d is well-typed in environment G. (TMAIN) types e in G, where \ne mayhave anyeffect and anytype.(TDVAR) types the value v, which has the empty effect (since it is a \nvalue), F; G f e : t (TMAIN) G f main e F\u00d8;G f v : t G, g : ref {g} t f d (TDVAR) G f var g = v in d \nG '' ' =G, f : t -.F t F; G ' ,x : t f e : t G ' f d {f}. F (TDFUN) G f fun f(x)= e in d G(f)= t (TGVAR) \nF\u00d8;G f f : t Fa . a ' F. . . ' (TUPDATE) F; G f updatea ' ,. ' : int Fa . Fa F. . F. F1;G f e : t 11 \n(TTRANSACT) F; G f tx e : t Figure 7. Proteus-tx typing(extends Figure2) and then types d with g boundtoareferenceto \nv labeled with effect {g}. The last de.nition rule, (TDFUN), constructs a new environ\u00adment G ' that extends \nG with a binding of f to the function s type. The function body e is type checked in G ', to allow for \nrecursive calls. This rule also requires that f appear in all components of the function s effect F, \nwritten {f}. F.We add f to the prior effect because f musthavebeen calledforitsentrytobe reached.Weadd \nf tothe currenteffectsothatitis includedintheeffectatacall site. Lastly,we add f to the future effect \nbecause f is on the call stack and we consider its continued execution to be an effect. Note that this \nprohibits updates to main(), which is always on the stack. How\u00adever, we can solve this problem by extracting \nportions of main() into separate functions, which can then be updated; Ginseng pro\u00advides support to automate \nthis process (Neamtiu et al. 2006). The next rule,(TGVAR), types globalvariables, which are boundinG. \nThe last two rules type the dynamic updating-related elements of Proteus-tx.(TU PDATE)typesupdate bychecking \nthat its prior and future effect annotations are supersets of (and thus conservatively approximate) the \nprior and future effects of the context. Finally,(TTRANSACT)types transactions.Akeydesign choice hereisdecidinghowto \nhandle nested transactions.In(TTRANS-ACT), we include the prior and future effects ofF, from the outer \ncontext, into those of F1, from the transaction body. This ensures that an update within a child transaction \ndoes not violate version consistencyof its parent. However, we do not require the reverse the components \nof F1 need not be included in F. This has two consequences. First, sequenced transactions are free to \ncommit in\u00addependently.Forexample, consider the following code tx { tx { /*A*/ }; /*B*/ tx { /*C*/ }} \nAccordingto(TT RANSACT),theeffectatB is included in the prior and future effects of C and A, respectively,but \nnot the otherway around. Thus neither transaction s effect propagates into the other, and therefore does \nnot in.uence anyupdate operations in the other. The second consequenceisthatversion consistencyfora parent \ntransaction ignores the effects of its child transactions. This resem\u00adbles open nesting in concurrencytransactions \n(Ni et al. 2007).For example, suppose in the code above that A and C contain calls to a hash table T \n.Without the inner transaction markers, an update to T available at B would be rejected, because due \nto A it would overlap with the prior effect, and due to C it would overlap with the futureeffect.With \nthe inner transactionsin place,however, the update would be allowed. As a result, the parent transaction \ncould usetheoldversionofthehash tablein A and the newversionin C . This treatment of nested transactions \nmakes sense when inner transactions contain code whose semantics is largely independent of the surrounding \ncontext, e.g., the abstraction represented by a hash table is independent of where, or how often, it \nis used. Bau\u00ad mann et al. (2007) have applied this semantics to successfully par\u00ad tition dynamic updates \nto the K42 operating system into indepen\u00addent, object-sized chunks. While we believe open nesting makes \nsense, we can see circumstances in which closed nesting might be more natural, so we expect to re.ne \nour approach with experience.  3.4 Operational Semantics Figure 8 de.nes a small-step operational semantics \nthat reduces con.gurations (n; S; H; e), where n de.nes the current program version (a successful dynamic \nupdate increments n), S is the transaction stack (explained shortly), H is the heap, and e is the active \nprogram expression. Reduction rules have the form (n; S; H; e) -.. (n ' ;S ' ; H ' ; e ' ), where the \nevent . on the arrow is either \u00b5, a dynamic update that occurred (discussed be\u00adlow), or e, the effect \nof the evaluation step. In our semantics, heaps map references r and global variables z to triples (t, \nb, .) consisting of a type t , a binding b (de.ned in Figure 6), and a version set .. The .rst and last \ncomponents are relevant only for global symbols; the type t is used to ensure that dynamic updates do \nnot change the types of global bindings, and the version set . contains all the program versions up to, \nand including, the current version since the corresponding variable was last updated. When an update \noccurs, new or changed bindings are given only the current version, while all other bindings have the \ncurrentversionaddedtotheirversionset(i.e.,we preservethefact that the same binding was used in multiple \nprogram versions). As evaluation proceeds, we maintain a transaction stack S, which is a list of pairs \n(n, s) that track the currently active transac\u00adtions. Here n is the version the program had when the \ntransaction began, and s is a trace. A trace is a set of pairs (z,.), each of which represents a global \nsymbol access paired with its version set atthetimeof use.The tracesactasalogof dynamicevents,andwe track \nthem in our semantics so we can provethat all global symbols accessed in a transaction come from the \nsame version. To evaluate a program d, we .rst compute C(\u00d8,d) using the function C shown at the top of \nFigure 8, which yields a pair H; e. This function implicitly uses the types derived by typing d using \nthe rules in Figure 7. Then we begin regular evaluation in the con.guration (0; (0, \u00d8); H; e), i.e., \nweevaluate e at version 0, with initial transaction stack (0, \u00d8), and withthe declared bindings H. This \ncauses the top-level expression e in main e to be treated as if it were enclosed in a transaction block. \nThe .rst several reduction rulesin Figure8are straightforward. [LET],[REF],[DEREF],[ASSIGN],[IF-T], and[IF-F]are \nsmall-step versions of the rules in Figure 3, though normal references no longer have effects. None of \nthese rules affects the current version or transaction stack.[CONG]is standard. [GVAR-DEREF], [GVAR-ASSIGN], \nand [CALL]each have effect {z} and add (z,.) to the current transaction s trace, where . is z s current \nversion set. Notice that [CALL]performs dereference and application in one step, .nding z in the heap \nand performing substitution. Since dynamic updates modify heap bindings, this ensuresthatevery functioncallistothemost \nrecentversion. Notice that althoughboth functionsandvariablesare storedintheheap,we assign regular function \ntypes to functions ((TDFUN)in Figure 7) so that they cannot be assigned to within a program. Including \n.\u00adterms in the expression language would either complicate function typing or makeit harder to de.ne \nfunction updates so we omit them tokeep things simpler. The next several rules handle transactions. [TX-START]pushes \nthe pair (n, \u00d8) onto the right of the transaction stack, where n is De.nitions Compilation Heaps H ::= \n\u00d8| r . (\u00b7, b, .),H C(H; main e)= H; e | z . (t, b, .),H ' C(H; fun f(x)= e in d)= C(H, f . (t -.F t \n, .x.e, {0}); d) Version sets . ::= \u00d8|{n}. . C(H; var g = v in d)= C(H, g . (t, v, {0}); d) Traces s \n::= \u00d8| (z,.) . s Transaction stacks S ::= \u00d8| (n, s), S Evaluation Contexts Expressions e ::= ... | r \n| intx e E ::= [] | E e | v E | let x = E in e Events . ::= e | \u00b5 | ref E | ! E | E := e | r := E | \ng := E Update Direction dir ::= bck | fwd | if0 Ethen e else e Update Bundles \u00b5 ::= (upd, dir) Computation \n' [LET] (n;(n ,s); H; let x = v in e) -.\u00d8 (n;(n ' ,s); H; e[x . v]) ' [REF] (n;(n ,s); H; ref v) -.\u00d8 \n(n;(n ' ,s); H[r . (\u00b7, v, \u00d8)]; r) r . dom(H) ' [DEREF] (n;(n ,s); H;! r) -.\u00d8 (n;(n ' ,s); H; v) H(r)=(\u00b7, \nv, \u00d8) ' [ASSIGN] (n;(n ,s); H; r := v) -.\u00d8 (n;(n ' ,s); H[r . (\u00b7, v, \u00d8)]; v) r . dom(H) ' [IF-T] (n;(n \n,s); H; if0 0 then e1 else e2) -.\u00d8 (n;(n ' ,s); H; e1) ' '' '' [IF-F] (n;(n ,s); H; if0 n then e1 else \ne2) -.\u00d8 (n;(n ' ,s); H; e2) n =0 ' '' [CONG] (n; S; H; E[e]) -.. (n ' ;S ' ; H ; E[e ' ])(n; S; H; e) \n-.. (n ;S ' ; H ' ; e ) '' [GVAR-DEREF] (n;(n ,s); H;! z) -.{z} (n;(n ,s . (z,.)); H; v) H(z)=(t, v, \n.) '' [GVAR-ASSIGN] (n;(n ,s); H; z := v) -.{z} (n;(n ,s . (z,.)); H[z . (t, v, .)]; v) H(z)=(t, v ' \n,.) '' [CALL] (n;(n ,s); H; z v) -.{z} (n;(n ,s . (z,.)); H; e[x . v]) H(z)=(t, .x.e, .) ' [TX-START] \n(n;(n ,s); H; tx e) -.\u00d8 (n;(n ' ,s), (n, \u00d8); H; intx e) ' [TX-CONG-1] (n;(n '' ,s), S; H; intx e) -.\u00b5 \n(n ' ; U[(n '' ,s)]\u00b5 ' , S ' ; H ' ; intx e ' )(n; S; H; e) -.\u00b5 (n ' ;S ' ; H ; e ' ) n '' [TX-CONG-2] \n(n; S; H; intx e) -.\u00d8 (n ' ;S ' ; H ; intx e ' )(n; S; H; e) -.e (n ' ;S ' ; H ; e ' )[TX-END] (n; ((n \n' ,s ' ), (n '' ,s '' )); H; intx v) -.\u00d8 (n;(n ' ,s ' ); H; v) traceOK (n '' ,s '' ) ' upd,dir upd [UPDATE] \n(n;(n ,s); H; updatea,.) -.(upd,dir) (n + 1; U[(n ' ,s)]; U[H];1) updateOK (upd, H, (a, .), dir) n+1 \nn+1 ' [NO-UPDATE] (n;(n ,s); H; updatea,.) -.\u00d8 (n;(n ' ,s); H;0) Update Safety Trace Safety updateOK \n(upd, H, (a, .), dir)= traceOK (n, s)=(.(z,.) . s. n . .) dir = bck . a n dom(updchg )= \u00d8 . dir = fwd \n. . n dom(updchg )= \u00d8 Heap Updates . G= types(H) 8 >>< >>: z . (t, b ' , {n}), U[H]upd n if updchg (z) \n. (t, b ' ) z . (t, b, . .{n}), U[H]upd n otherwise Gupd =G, types(updadd ) . U[(z . (t, b, .),H)]upd \n= n \u00b7) . updchg . .z . (t, b, F\u00d8;Gupd ` . \u00b4 f b : t . heapType(t, z) = G(z) \u00b7) . updadd . .z . (t, b, \nF\u00d8;Gupd f b : t . z ./dom(H) ` U[(r . (\u00b7, b, \u00d8),H)]upd =(r . (\u00b7, b, \u00d8)), U[H]upd nn . \u00b4 U[\u00d8]upd = {z \n. (t, b, {n}) | z . (t, b) . updadd } n Trace Stack Updates HeapTyping Environments types(\u00d8) types(z \n. (t, b, .),H ' ) heapType(t1 -.F t2, z) heapType(t, z)  = \u00d8 = z : heapType(t, z), types(H ' ) = t1 \n-.F t2 z . F = ref {z} tt =(t1 -.F t2) U[(n ' , s)]upd,fwd n = (n ' , s) U[(n ' , s)]upd,bck n = (n, \nUt[s]upd n ) Ut[s]upd n = . {(z, . . {n} | z . dom(updchg )}{(z, .) | z . dom(updchg )}  Figure 8. Proteus-tx \noperational semantics the current version and \u00d8 is the empty trace. The expression tx e is reduced to \nintx e, which is a new form that represents an actively\u00adevaluating transaction. The form intx e does \nnot appear in source programs, and its type rule matches that of tx e (see Figure 9). Next, [TX-CONG-1] \nand [TX-CONG-2] perform evaluation within an active transaction intx e by reducing e to e '. The latter \nrule applies if e s reduction does not include an update, in which case the effect e of reducing e is \ntreated as \u00d8 in the outer transac\u00adtion. This corresponds to our model of transaction nesting, which does \nnot consider the effects of inner transactions when updating outer transactions. Otherwise,ifanupdate \noccurs,then[TX-CONG\u00ad1]applies, and we use the functionU to updateversion numbers on the outermost entry \nof the transaction stack. U is discussed shortly. Thekeyproperty guaranteedbyProteus-tx, that transactions \nare version consistent, is enforced by [TX-END], which gets stuck un\u00adless traceOK (n '' ,s '' ) holds. \nThis predicate, de.ned just belowthe reduction rules, states that every element (z,.) in the transaction \ns trace s '' satis.es n '' . ., meaning that when z was used, it could be attributed to version n '', \nthe version of the transaction. If this predicate is satis.ed, [TX-END]strips offintx and pops the top \n(rightmost) entry on the transaction stack. The last two rules handle dynamic updates. When updatea,. \nis in redex position, these rules try to apply an available update F1;G f e : t Fa . Fa F. . F. TIntrans \n11 F; G f intx e : t dom(G) = dom(H) .z . (t -.F t ' , .x.e, .) . H. '' F; G,x : t f e : t . G(z)= t \n-.F t . z . F .z . (t, v, .) . H. F\u00d8;G f v : t . G(z)= ref e t . z . e .r . (\u00b7, v, .) . H. F\u00d8;G f v : \nt . G(r)= ref e t .z . (t, b, .) . H. n . . n; G f H f . s . f . a f . e . n . ver(H, f) [a; e; .], \u00b7; \nH f (n, s) F ' , R; H f S f . s . f . a f . e . n . ver(H, f) [a; e; .], F ' , R; H f (n, s), S where \nver(H, f)= . i. H(f)=(t, b, .) Figure 9. Proteus-tx typing extensions for proving soundness bundle\u00b5, \nwhich is a pair (upd, dir) consisting of an update (from Figure6) anda direction dir that indicates whether \nwe should con\u00adsider the update as occurring at the beginning or end of the trans\u00adaction, respectively. \nIf updateOK (upd, H, (a, .), dir) is satis.ed for some dir, then[UPDATE]applies and the update occurs. \nOther\u00adwise[NO-UPDATE]applies, and the update mustbe delayed. If[UPDATE]applies, we increment the program \nsversion num\u00adber and update the heap using U[H]upd ,de.ned in the middle-right n+1 of Figure 8. This \nfunction replaces global variables and adds new bindings according to the update. New and replaced bindings \nver\u00adsion sets contain only the current version, while unchanged bind\u00adings add the current version to \ntheir existing version sets. The updateOK () predicate is de.ned just below the reduction rules in Figure \n8. The .rst two conjuncts enforce the update safety requirement discussed in Section 3.1. There are two \ncases. If dir = bck, then we require that the update not intersectthe prior effects, so that the update \nwill appear to have happened at the beginning of the transaction. In this case, we need to update the \nversion number of the transaction to be the new version, and anyelements in the trace not modi.ed by \nthe update can have the new version added to their version sets, i.e., the past effect can be attributed \nto the new version. To do this, [UPDATE] applies the function ' upd,dir U[(n ,s)]n+1 , de.ned on the \nbottom right of Figure 8, with dir = bck. The update applies to outer transactions as well, and thus[TX-CONG-1]applies \nthis sameversion number replacement process across the transaction stack. In the other case, if dir = \nfwd, we require that the remainder of the transaction not be affected by the update, so the update will \nappear to have happened at the end of the transaction. In this case we need not modify the transaction \nstack, and hence upd,dir U[(n ' ,s)]n with dir = fwd simply returns (n ' ,s). The remaining premises \nof updateOK () determine whether the update itself is well-formed: each replacement binding must have \nthe same type as the original, and new and added bindings must type check in the context of the updated \nheap.  3.5 Soundness We have proven that well-typed Proteus-tx programs are version\u00adconsistent. The \nmain result is that a well-typed, well-formed pro\u00adgram either reduces to a value or evaluates inde.nitely \nwhile pre\u00adservingtypingandversion consistency.Toprovethisweneedtwo additional judgments, shown in Figure \n9. Heap typing n;G f H extends De.nition 2.1 from the core system, where the additional conditions ensure \nthat global symbols are well-typed, have well\u00adformed effects, and include version n (presumed to be the \ncurrent version) in their version sets. Stack well-formedness R; H f S checks that a transaction stack \nS is correctly approximatedbya transaction effect R, which consists of a list of contextual effects F, \none for each nestedtrans\u00adaction. R is computed fromatyping derivationinastraightforward way according \nto the function [F; G f e : t ] = R, extracting F1 fromeach occurrenceof(TINTRANS)recursively;therulesarenot \nshown due to space constraints. Stack well-formedness ensures two properties. First, it ensures that \neach element in the trace s is in\u00adcluded in the corresponding prior effect a (i.e., f . s . f . a). As \na result, we know that bck updates that rewrite the stack will add the new version to all elements of \nthe trace, since none have changed. Second, it ensures that elements in each transaction s cur\u00adrent effect \n(i.e., the part yet to be executed) have the version of that transaction: f . e . n . ver(H, f). With \nthis we can prove the core result: Theorem 3.1 (Single-step Soundness). If F; G f e : t where [F; G f \ne : t ] = R; and n;G f H; and F, R; H f S; and traceOK (S), then either e is a value, or there exist \nn ' , H ' , S ' , ' '' F ' , e ', and . suchthat (n; S; H; e) -. . (n ;S ' ; H ; e ) and F ' ;G ' f e \n' : t where [F ' ;G ' f e ' : t] = R ';andn ' ;G ' f H ' ; and F ' , R ' ; H ' f S ';andtraceOK (S ' \n) for some F ' , G ' , R ' . The proofis based on progress and preservation lemmas, as is standard. Details \nare in our technical report (Neamtiu et al. 2007). From this lemma we can prove soundness: Corollary \n3.2 (Soundness). If F; G f e : t and 0; G f H then ''' ' (0; (0, \u00d8); H; e) . A (n ;(n ,s); H ; v) for \nsome value v or else evaluates inde.nitely,where. A isthere.exive,transitive closure of the -. . relation \nsuchthat A is a set of events .. 3.6 TransactionalVersion ConsistencyforCPrograms We extended Ginseng \nto implement transactional version consis\u00adtencyforCusing contextualeffects.In our implementation, trans\u00adactional \nblocks areindicated witha special label, and are written DSU TX : {...}. Candidate update points can \nbe inserted either manually or, in our experiment, automatically, as discussed below. To perform effect \ninference, we .rst compute a context-sensitive points-to analysis using CIL (Necula et al. 2002). Then \nwe gener\u00ad ate (context-insensitive) effect constraints (following Section 2.3) using labels derived from \nthe points-to analysis, and we solve the constraints with Banshee (Kodumal and Aiken 2005). After computing \nthe contextual effects, Ginseng transforms the program to make it updatable, and transforms each update \npoint into a call to a function update(., a, .). Here a and . are the prior and future effects at the \nupdate point, pre-computed by our contextual effect inference, and . is a set of type names whose de.nitions \ncannot be modi.ed and variables whose types cannot be modi.ed. More speci.cally, . contains all of those \nentities that could be accessed functions f that might be called, variables g that might be dereferenced, \nand types t whose values might be destructed by code possibly on the stack at the time of the update, \nsince that code will expect the old version s type (Neamtiu et al. 2006; Stoyle et al. 2007). When update \nis called at run time, it checks to see whether an update is available and, if so, applies the update \nif it is both type safe (i.e., no variable or type in . has been changed by the update to have a different \ntype) and version consistent (given a and .). If an update is not safe, it is delayed and execution continues \nat the old version. Type-altering Updates Sinceafunction f stype is annotated with its contextual effect \nF, a modi.cation to the program that causes f s effect F to change must be considered a change to f s \ntype. This can occur even when f s code has not changed, e.g., if f calls g and an update changes g s \neffect. Our implementation handles such changes following the approach of our earlier work (Stoyle et \nal. 2007). In particular, if a variable f s type changes from t to ' '' t due to an update, then if either \nt = t or t = t and f . ., the update is safe and can be applied. In the latter case, although f s type \nchanges in an incompatible way, no active code depends on its type. On the other hand, if t ' = t and \nf . . then the update may be unsafe, since active code may rely on its type, and thus the update must \nbe delayed. State Transformation Ourversion consistencyconditionis slight\u00adly more complicated in practice \ndue to state transformers.Astate transformer is an optional function, supplied by the programmer, that \nis called at update time to transform old program state into new program state. The programmer writes \nthe state transformer as if it will be run at the beginning or end of a transaction, and our system must \nensure that this appearance is true. That is, to allow anupdateto occur withina transaction,wemust ensurethat(1)the \nwrites performedbythe state transformerdonot violatetheversion consistencyof the current program transactions, \nand (2) the effects of the current transactions do not violate the version consistency of the state transformer \nitself.We achieve both endsby consider\u00ading the update changes (dom(updchg )) and the state transformer \ns current effect exf as the effect of the update when performing the usual checks for version consistency. \nFor example, if an update point update(., a, .) is reached within a transaction, then if . n (exf . dom(updchg \n)) = \u00d8 then the remaining actions of the transaction will not affect the state transformer, and vice \nversa, and so it is as if the update occurred at the end of the transaction. Likewise, if an(exf .dom(updchg \n)) = \u00d8 then the effect of the transaction to this point has no bearing on the execution of the state \ntransformer, and vice versa, so it is as if the update occurred at the beginning of the transaction. \nNote that because state transformers can also access the heap from global variables we need to include \naccesses to standard heap references (i.e., names L as in Section 2) in our effects. Non-updatable transactions \nWhen writing a state transformer, the programmer needs to anticipate where it might be applied in the \nprogram, i.e., the transformer might need to do different things depending on which transactions have \ncompleted (as evidenced by the current state). Thus we have found it is convenient to rule out updates \nin some transactions, to limit the amount of location\u00addependent code in a state transformer. For example, \nin Figure 4, we would like to forbid updates from the program start up to the .rst transaction on line \n22, and from the end of the transaction on line 28 to the beginning of the transaction on line 10. Since \nthis code is not run very often, prohibiting transactions in it should not signi.cantly reduce update \navailability. Formally, we could support this notion by adding a new form tx * e that has the same type \nrule and operational semantics as a transaction tx e,but in which no updates are allowed at run time. \nIn the example, however, the regions to which we would like to apply tx * are non-lexically scoped.We \ncould refactor the code to form lexical blocks,but ultimately we plan to support non-lexical transactions \nin our implementation. For our experiments below, we simulate tx * e transactions by simply not .owing \nthe prior and future effect of the outer context into the tx e blocks (i.e., eliminating the constraints \nin the hypothesis of (TT RANSACT)). This producesthe resultwewantandissafe becausethe tx e blocks in \nvsftpd are only nested inside the transaction for the top-level expression, and everything else in that \nexpression is effectively in a tx * block. Version LoC Time (s) Upds Type-safe VC-safe 1.1.0 1.1.1 1.1.2 \n1.1.3 1.2.0 1.2.1 1.2.2 2.0.0 2.0.1 2.0.2pre2 2.0.2pre3 2.0.2 10,157 10,245 10,540 10,723 12,027 12,662 \n12,691 13,465 13,478 13,531 14,712 17,386 193 196 234 238 326 264 278 440 420 632 686 649 344 346 350 \n354 413 438 439 471 471 471 484 471 300 19 25 19 31 368 32 392 459 471 484 468 33 9 8 8 9 146 9 9 9 9 \n8 9 Figure 10. Version consistencyanalysis results  3.7 Experiments We measured the potential bene.ts \nof transactionalversion consis\u00adtency by analyzing 12 dynamic updates to vsftpd. The updates correspondtoversions \n1.1.0 through 2.0.2.For ourexperiment,we modi.ed Ginseng to seed the transactions in each vsftpd version \nwith candidate update points. While we could conceivably insert update points at every statement, we \nfound through manual exami\u00adnation that inserting update points just before the return statement of anyfunction \nreachable from within a transaction provides good coverage. Then we used Ginseng to infer the contextual \neffects and type modi.cation restrictions at each update point, and computed at how manyof them we could \nsafely apply the update. We conducted our experiments on an Athlon 64 X2 dual core 4600 machinewith4GBofRAM,runningDebian,kernelversion \n2.6.18. Figure10 summarizes our results.For eachversion, we list its size, the time Ginseng takes to \npre-compute contextual effects and type modi.cation restrictions, and the number of candidate update \npoints that were automatically inserted. The analysis takes around 10 minutes for the largest example, \nand we expect that time could be reduced with more engineering effort. The last two columns indicate \nhow manyupdate points are type safe, and how many are both type safe and version consistent, with respect \nto the update from the version in that row to the next version. Note that determining whether an update \nis type safe and version consistent isveryfast, and so wedo not report the time for that computation. \nRecall that in our prior work with vsftpd we manually added twoupdate points. From the table, we can \nsee that several additional update points are type safe andversion consistent.Wemanuallyex\u00adaminedallof \nthese update points.Forall programversionsexcept 1.1.0, 1.2.1, and 2.0.2pre2, we found that roughly one-third \nof the VC-safe update points occur somewhere in the middle of a trans\u00adaction, providing better potential \nupdate availability. Another third occur close to or just before the end of a transaction, and the last \nthird occurindeadcode,providingnoadvantage.Forthe remaining versions, 1.1.0, 1.2.1,and 2.0.2pre2,we found \nthat roughly10%of the update points are in the middle of transactions, and almost all the remaining ones \nare close to the end of a transaction, with a few more in dead code. One reason so manyupdate points \ntend to occur toward the end of the transaction is due to the .eld-insensitivity of the alias anal\u00adysis \nwe used. In vsftpd, the type vsf session contains a multitude of .elds and is used pervasively throughout \nthe code. The .eld\u00adinsensitive analysis causes spurious con.icts when one .eld is ac\u00adcessed early in \nthe transactionbut others are accessed later on, as is typical. This pushes the update points to the \nend of the transac\u00adtion, following vsf session s last use.Weplanto integratea .eld\u00adsensitive alias analysis \ninto Ginseng to remedy this problem. Interestingly, there are generallyfar more updates that areex\u00adclusively \ntype safe than those that are both type safe and version consistent.We investigated some of these, and \nwe found that the 1 let x=ref 0, y =ref 1, 2 z=ref 2, w=ref3in 3 y := 4; 4 fork (!x; !y; !z); 5 x := \n5; 6 fork (z := 2); 7 while (...) fork (w := (!w) + 1) Fei;G f e : t Fe . Fe (TFORK) ei i Fi;G f forki \ne : t Figure 11. Thread sharing analysis: example and type rule reasons for thisvaried with the update.Forexample, \nthe updates that do not change vsf session (e.g., 1.1.0) have a high number of type-safe update points, \nwhile those that do (e.g., 1.1.1) havefar fewer. This makes sense, given vsf session s frequent use. \nIn summary,these results showthat manyupdate points are both type safe and version consistent, providing \ngreater availability of updates than via manual placement.We expect still more update availability with \na more accurate alias analysis. 4. Thread Sharing Analysis Data race detectors (Savage et al. 1997; Flanagan \nand Freund 2000; Pratikakis et al. 2006; Naik et al. 2006) and other static analysis tools often perform \nthread sharing analysis to identify memory lo\u00adcations that may be accessed by multiple threads (and conversely \nthose locations that are purely thread-local) in a concurrent pro\u00adgram. This is useful because only shared \nlocations need to be pro\u00adtected from concurrent access. In this section we showhow contex\u00adtual effects \ncan be used to implement a thread sharing analysis. We illustrate our analysis with an example. Suppose \nwe have a language construct fork e, which creates a new thread that evalu\u00adates e, and consider the code \nin the top of Figure 11, written in an ML-like language with a while loop. This program creates four \nup\u00addatable references and then manipulates them in the parent thread and various child threads. One simplebut \nincorrect method for computing sharingwould be to compute the (standard) effects of each thread and then \ninter\u00adsect them; anylocation in the intersection of two threads would be considered thread-shared. In \nthis case the effect of the main thread is {x, y} (the writes on lines3and5), and theeffectsof the threads \non lines4,6, and7 are {x, y, z}, {z}, and {w}, respectively. Thus we would compute that x, y, and z are \nshared, and that w is not. The most obvious problem here is that w is determined thread\u00adlocal, even though \nit is shared among the several threads created on line7.We could solve this problemby performing some \nkindof analysis to determine which calls to fork might be invoked multiple times,but that adds complexity \nand does not solveanother problem involving precision. Observe that although x and y are accessed both \nby the main thread and the thread created on line 4, their sharing is different. The main threadwrites \nto x on line5after the child thread on line4 may have started, hence the read and write may be simultaneous. \nOn the other hand, the write to y on line3happens before(Lamport 1978; Mansonetal.2005)thechild threadis \ncreatedonline4,and since there is no other write in the parent thread, we can consider y to be thread-local \nthere are no possible concurrent accesses from different threads. We can solve bothof these problemsbyusing \ncontextualeffects rather than regular effects to determine sharing. The idea is simple: a location is \nthread-shared if it may be accessed by a child thread andbythe parent thread,but only after the child \nthread is created and we can use the future effect to compute what happens after thread creation. This \ntakes care of the problems with loops, since the future effect of a fork in a loop will include the back-edge \nin the loop; and it allows the parent to modify data before a child thread is created without forcing \nthat data to be considered shared. This technique is even more useful when we distinguish read and write \neffects, which we do in practice, in which case data need only be considered shared if at least one of \nthe potential simultaneous accesses is a write. Name LoC Time (s) Shared Total % aget 1,914 0.40 60 338 \n18% ctrace 2,212 0.25 21 307 7% engine 2,608 0.49 10 390 3% knot 1,985 0.35 29 319 9% pfscan 1,948 0.25 \n26 238 11% smtprc 8,630 2.46 128 1077 12% eql 16,568 1.68 22 240 9% 3c501 17,441 0.64 23 353 7% plip \n19,141 0.88 64 402 16% sundance 19,951 1.05 25 633 4% wavelan 20,085 1.14 123 660 19% hp100 20,368 1.16 \n24 450 5% synclink 24,691 2.65 219 1158 19% Figure 12. Sharing analysis results  4.1 Typing The bottom \nof Figure 11 gives the new type rule (TFORK)needed for sharing analysis. This rule types thread creation, \nwhere each syntactic occurrence forki e has been named with an index i. In this rule, we compute the \neffect Fei of the child thread separately from the effect Fi of the parent thread. Once we haveall such \neffects, we can compute the set of shared locations as shared = S i(Feei nFi.). Inotherwords,alocationis \nsharedifitis accessedbothinthechild thread and in the parent thread after a call to fork. There is one \ncatch, however. Consider z from the example program in Figure 11. This particular location is not accessed \nby the parent thread after it is created, and hence is not (yet) in F.i , and thus will notbe considered \nshared.To handle this case, sharing among two child threads, we simply add the child s effects to the \nparent s effects with the constraint Fe . i . Considering the Fe ei example again, this causes the write \nto z on line6 to be added to the parent thread s effect on the same line, and therefore it will be in \nthe parent s future effect on line 4. 4.2 Implementation and Experiments We have incorporated our thread \nsharing analysis into Lock\u00adsmith (Pratikakisetal.2006),a static analysistoolwedevelopedto .nd data racesinCprograms. \nLocksmithworksby enforcing the guarded-by pattern: Every shared location in the program must be consistently \nguarded by some lock. Locksmith requires essentially no annotations, and uses several other analyses \nin addition to the thread sharing analysis described above. Previous presentations of Locksmith s sharing \nanalysis were informal (Pratikakis et al. 2006) or used a different formulation (Hicks et al. 2006) (see \nSection 5), and did not report the effectiveness of the analysis. Figure 12 shows the results.We measure \nthe running time, the number of shared locations, and the total number of locations. Here locations include \nall global variables, syntactic occurrences of malloc, local variables whose address is taken, or .elds \nof lo\u00adcations (our analysis is .eld sensitive). The results show that con\u00adtextual effect inference runs \nvery quickly, and is able to determine that many locations in the program are thread-local. On average, \nonly 11% of the total locations are determined to be shared. Thus Locksmith can safely assume that accesses \nto the remaining 89% of locations need not be guarded by locks, greatly improving the precision of race \ndetection. 5. RelatedWork 5.1 Effect Systems Several researchers have proposed extending standard effect \nsys\u00adtems (Lucassen 1987; Nielson et al. 1999) to model more com\u00adplex properties. One common approach \nis to use traces of actions for effects rather than sets of actions. These traces can be used to check \nthat resources are accessed in the correct order (Igarashi and Kobayashi 2002), to statically enforce \nhistory-based access con\u00adtrol (Skalka et al. 2007), and to check communication sequenc\u00ad ing (Nielson \net al. 1999). While these systems can model the or\u00ad dering of events, theydo not compute the prior or \nfuture effect at a programpoint.Webelievewecould combinetraceeffectswithour approach to create a contextual \ntrace effect system, which we leave for future work. In prior work (Hicks et al. 2006) we introduced \ncontinuation effects .,which resemble the unione.. of our standard and future effects. Judgments in this \nsystem have the form .;G f e : t; . ' , where . ' describes the effect of e s continuation in the remainder \nof the program, and . is equivalent to e .. ' where e is the standard effect of e. The drawback of this \nformulation is that the standard effect e of e cannot be recovered from ., since (e . . ' ) - . ' = e \nwhen e n . ' = \u00d8. This system also does not include prior effects. Capabilities in AliasTypes (Smith \net al. 2000) and region sys\u00ad tems like CL (Walker et al. 2000) are likewise related to our stan\u00ad dard \nand future effects.Acapability consists of static approxima\u00adtion of the memory locations that are live \nin the program, and thus may be dereferenced in the current expression or in later evalua\u00adtion. Because \nthese systems assume their inputs are in continuation passingstyle(CPS),theeffectofa continuationisequivalenttoour \nfuture effects. The main differences are that we compute future ef\u00adfects at every program point (rather \nthan only for continuations), that we compute prior effects, and that we do not require the input program \nto be CPS-converted. 5.2 Correctness of Dynamic Software Updating Several systems for on-line updates \nhave been proposed. Here we focus on how prior work controls an update s timing to assure its effects \nare correct. Most work disallows updates to code that is active, i.e., actu\u00adally running or referencedby \nthe call stack. The simplest approach to updating active code, taken by several recent systems (Gilmore \net al. 1997; Makris and Ryu 2007; Chen et al. 2006), is to pas\u00ad sively wait for it to become inactive. \nThis can be problematic for multi-threaded programs, since thereisagreater possibility that ac\u00adtive threads \nreferencea to-be-updated object.To address this prob\u00adlem, Soules et al. (2003) developed a quiescence \nprotocol to sup\u00ad port dynamic updating in the object-oriented K42 operating sys\u00adtem (Baumann et al. 2005, \n2007). Once an update for an object is proposed, an adaptor object is interposed to block subsequent \ncallers of the object. Once the active threads have exited, the ob\u00adject is upgraded and the blocked callers \nare resumed. The danger is that dependencies between updated objects could result in a dead\u00adlock. Whilecode \ninactivityisuseful,itisnotsuf.cientfor ensuring higher-level properties like version consistency. In \nparticular, ver\u00adsion consistencymay require delaying an update if to-be-updated objects are not currently \nactivebut were during the transaction. Lee (1983) proposed a generalization of the quiescence con\u00addition \nby allowing programmers to specify timing constraints on when elements of an update should occur; recent \nwork by Chen et al. (2007) is similar. As an example, the condition update P, Q when P, M, S idle speci.es \nthat procedures P and Q should be updated only when procedures P, M, and S are not active. Lee provides \nsome guidance for using these conditions.Forexample,if procedure P s type has changed, then an update \ntoitand its callers should occur when all are inactive. Ourwork usesaprogram analy\u00adsis to discover conditions \nsuch as these to establish the higher-level transactional version consistencyproperty. Prior work with \nGinseng focused on ensuring that a dynamic update does not introduce type errors when it is applied (Neamtiu \net al. 2006; Stoyle et al. 2007). For example, the program point just before a call to a function f is \nrestricted from changing the type of f to allow the update would result in the old code calling the new \nf atan incompatible type.Wedevelopedastatic updata\u00adbility analysis thatgathers type constraints imposedby \nthe active (old) code at each program point and only allows an update to take place if it satis.es the \nconstraints. This is more .ne-grained than Lee s constraints if the type of a function changes, we can \nup\u00addate it even when its callers are active so long as theywill not call the updated function directly. \nOur current work is complementary to this work, as a type-safe update will not necessarily be version\u00adconsistent(as \nillustratedby theexamplein Section3), and depend\u00ad ing on how transactions are speci.ed the reverse may \nalso be true. Our use of transactions to ensure version consistency resem\u00adbles work by Boyapati et al. \n(2003) on lazily upgrading objects in a persistent object store (POS). Using a type system that guar\u00adantees \nobject encapsulation, their system ensures that an object s transformation function, used to initialize \nthe state of a new ver\u00adsion based on old state, sees only objectsofthe oldversion, which issimilarto \nourversion consistencyproperty.Howupdates interact with application-level transactions is less clear \nto us. The assump\u00adtion seems to be that updates to objects are largely semantically\u00adindependent, so there \nis less concern about version-related depen\u00addencies between objects within a transaction. 5.3 Thread \nSharing Analysis Thread sharing analysisisakeypartof several tools for analyzing multi-threaded programs. \nEraser (Savage et al. 1997), a dynamic data race detector, assumes locations are shared after they have \nbeen accessedbyat leasttwothreads.Our thread-sharing analysis canbeseenasastaticversionofthis approach.RCCJava(Flanagan \nand Freund 2000) allows programmers to manually add annotations to mark classes as thread local, so that \ntheir .elds need not be guarded by locks when accessed. Chord (Naik et al. 2006) uses a thread escape \nanalysis to .nd shared locations; a location is considered shared if it is reachable from a thread object. \nThis is more conservative than our approach, which allows data to be thread-local as long as it is not \nused in the parent after a child thread is forked. Chord avoids this problem by discounting constructors \nwhen determining thread sharing or data races.A newerversionof Chord includesa .ow-sensitive sharing \nanalysis (Naik and Aiken 2007),butitis not describedin detail. von Praun and Gross (2003) propose a thread \nsharing analysis for Java. Their system determines that an object is shared if it is accessed by multiple \nthreads, and includes additional reasoning to reduce sharingby taking thread creation and joining into \naccount. RacerX (Engler and Ashcraft 2003) performs deadlock and data race detectionforC. RacerX usesa \nheuristic, statistical approach to decide whether data is likely to be shared, based on how often it \nis accessed when a lock is held. This is in contrast to our approach, which tries to compute thread sharing \nin a sound manner. 6. Conclusion We have introduced contextual effects, which extend standard ef\u00adfect \nsystems to capture the effect of the context in which each subexpression appears,i.e.,theeffectofevaluationboth \nbeforeand aftertheevaluationofthesubexpression.Weformalizedacore con\u00adtextual type and effect system and \nproved it sound.We then used extensions of our core system in two applications. First, we pro\u00adposed transactional \nversion consistency, a new correctness condi\u00adtionfor dynamic software updates.Weshowedhowto use contex\u00adtual \neffects to enforce this property while allowing updates to occur more frequently within programs. Second, \nwe used contextual ef\u00adfects to compute locations shared between threads in concurrent programs.We determined \nshared locationsby intersecting the fu\u00adture effect of the parent at thread creation time with the effect \nof the child. Our experimental results show that our static contextual ef\u00adfectsystemisusefulinboth applications.Theseexamplesshowthe \nutility of contextual effects, and we anticipate theywill also prove useful in a variety of other applications. \nAcknowledgments The authors thank Peter Sewell, Nikhil Swamy, and the anonymous referees for their insightful \ncomments on drafts of this paper. This research was supported in part by National Science Foundation \ngrants CCF-0541036 and CCF-0346989, and the University of MarylandPartnership with theLaboratory forTelecommunications \nSciences. References Martin Abadi and Cedric Fournet. Access control based on execution history. In NDSS, \n2003. Andrew Baumann, Gernot Heiser, Jonathan Appavoo, et al. Providing dynamic update in an operating \nsystem. In USENIX, 2005. Andrew Baumann, Jonathan Appavoo, RobertW.Wisniewski, et al. Re\u00adboots are for \nhardware: Challenges and solutions to updating an operat\u00ading system on the .y. In USENIX, 2007. Chandrasekhar \nBoyapati, Barbara Liskov, Liuba Shrira, Chuang-Hue Moh, and Steven Richman. Lazy modular upgrades in \npersistent object stores. In OOPSLA, 2003. Haibo Chen, Rong Chen, Fengzhe Zhang, Binyu Zang, and Pen-Chung \nYew. Live updating operating systems using virtualization. In VEE, 2006. Haibo Chen, JieYu, Rong Chen, \nBinyu Zang, and Pen-ChungYew. PO-LUS: A POwerful Live Updating System. In ICSE, pages 271 281, 2007. \nDawson Engler and Ken Ashcraft. RacerX: effective, static detection of race conditions and deadlocks. \nIn SOSP, 2003. Cormac Flanagan and Stephen N. Freund. Type-based race detection for Java. In PLDI, 2000. \nJeffreyS.Foster, Robert Johnson, JohnKodumal, and Alex Aiken. Flow-Insensitive Type Quali.ers. TOPLAS, \n28(6):1035 1087, November 2006. Stephen Gilmore, Dilsun Kirli, and ChrisWalton. Dynamic ML without dynamic \ntypes.Technical Report ECS-LFCS-97-378, LFCS, University of Edinburgh, 1997. Tim Harris andKeir Fraser. \nLanguage support for lightweight transactions. In OOPSLA, 2003. M. HerlihyandJ.E.B. Moss.Transactional \nmemory: Architectural support for lock-free data structures. In ISCA, 1993. Michael Hicks, JeffreyS.Foster, \nand Polyvios Pratikakis. Lock Inference for Atomic Sections. In TRANSACT, 2006. AtsushiIgarashiandNaokiKobayashi. \nResourceUsage Analysis.In POPL, Portland, Oregon, 2002. JohnKodumal and Alexander Aiken. Banshee:Ascalable \nconstraint-based analysis toolkit. In SAS, 2005. Leslie Lamport. Time, clocks, and the ordering of events \nin a distributed system. CACM, 21(7):558 565, 1978. Insup Lee. DYMOS:ADynamic Modi.cation System. PhD \nthesis, Dept. of Computer Science, UniversityofWisconsin, Madison, April 1983. John M. Lucassen. Types \nand Effects: Towards the Integration of Func\u00adtional and Imperative Programming. PhD thesis, MIT Laboratory \nfor Computer Science, August 1987. MIT/LCS/TR-408. Kristis Makris andKyung Dong Ryu. Dynamic and adaptive \nupdates of non-quiescent subsystems in commodity operating systemkernels. In Proc. EuroSys, March 2007. \nJeremy Manson, William Pugh, and Sarita V. Adve. The Java Memory Model. In POPL, 2005. JohnC. Mitchell.Type \ninference with simple subtypes. JFP,1(3):245 285, July 1991. Mayur Naik and Alex Aiken. Conditional must \nnot aliasing for static race detection. In POPL, 2007. Mayur Naik, Alex Aiken, and John Whaley. Effective \nstatic race detection for Java. In PLDI, 2006. Iulian Neamtiu,JeffreyS.Foster,and Michael Hicks. Understanding \nSource Code Evolution Using Abstract Syntax Tree Matching. In MSR 05, 2005. URL http://www.cs.umd.edu/~mwh/papers/evolution. \npdf. Iulian Neamtiu, Michael Hicks, Gareth Stoyle, and Manuel Oriol. Practical dynamic software updating \nfor C. In PLDI, 2006. Iulian Neamtiu, Michael Hicks, JeffreyS.Foster, and Polyvios Pratikakis. Contextual \nEffects forVersion-Consistent Dynamic Software Updating and Safe Concurrent Programming. Technical Report \nCS-TR-4920, Dept. of Computer Science, University of Maryland, November 2007. George C. Necula, Scott \nMcPeak, Shree P. Rahul, and Westley Weimer. CIL: Intermediate language and tools for analysis and transformation \nof Cprograms. LNCS, 2304:213 228, 2002. Yang Ni,Vijay S. Menon, Ali-Reza Adl-Tabatabai, et al. Open nesting \nin software transactional memory. In PPoPP, 2007. Flemming Nielson, Hanne R. Nielson, and Chris Hankin. \nPrinciples of Program Analysis. Springer-Verlag, 1999. ISBN 3540654100. Polyvios Pratikakis,JeffreyS.Foster,and \nMichael Hicks. Context-sensitive correlation analysis for detecting races. In PLDI, 2006. Stefan Savage, \nMichael Burrows, Greg Nelson, Patrick Sobalvarro, and Thomas Anderson. Eraser:ADynamic Data Race Detector \nfor Multi-Threaded Programs. In SOSP, 1997. Christian Skalka, Scott Smith,andDavidVan Horn.Typesand traceeffects \nof higher order programs. JFP, July 2007. Forthcoming; available on\u00adline at http://www.journals.cambridge.org. \nFred Smith,DavidWalker,andGregMorrisett. Alias types.In ESOP,2000. Craig A. N. Soules, Jonathan Appavoo,Kevin \nHui, et al. System support for online recon.guration. In USENIX, 2003. Gareth Stoyle, Michael Hicks, \nGavin Bierman, Peter Sewell, and Iulian Neamtiu. Mutatis Mutandis: Safe and .exible dynamic software \nup\u00addating (full version). TOPLAS, 29(4):22, August 2007. Christoph von Praun and Thomas R. Gross. Static \ncon.ict analysis for multi-threaded object-oriented programs. In PLDI 03, 2003. DavidWalker,Karl Crary,and \nGregMorrisett.Typed memory management in a calculus of capabilities. TOPLAS, 24(4):701 771, July 2000. \n   \n\t\t\t", "proc_id": "1328438", "abstract": "<p>This paper presents a generalization of standard effect systems that we call <i>contextual effects</i>. A traditional effect system computes the effect of an expression <i>e</i>. Our system additionally computes the effects of the computational context in which <i>e</i> occurs. More specifically, we computethe effect of the computation that has already occurred(the <i>prior effect</i>) and the effect of the computation yet to take place (the <i>future effect</i>).</p> <p>Contextual effects are useful when the past or future computation of the program is relevant at various program points. We present two substantial examples. First, we show how prior and future effects can be used to enforce <i>transactional version consistency</i>(TVC), a novel correctness property for dynamic software updates. TV Censures that programmer-designated transactional code blocks appear to execute entirely at the same code version, even if a dynamic update occurs in the middle of the block. Second, we show how future effects can be used in the analysis of multi-threaded programs to find thread-shared locations. This is an essential step in applications such as data race detection.</p>", "authors": [{"name": "Iulian Neamtiu", "author_profile_id": "81100589658", "affiliation": "University of Maryland, College Park, MD", "person_id": "P707740", "email_address": "", "orcid_id": ""}, {"name": "Michael Hicks", "author_profile_id": "81100060959", "affiliation": "University of Maryland, College Park, MD", "person_id": "PP43115685", "email_address": "", "orcid_id": ""}, {"name": "Jeffrey S. Foster", "author_profile_id": "81338488852", "affiliation": "University of Maryland, College Park, MD", "person_id": "PP43125382", "email_address": "", "orcid_id": ""}, {"name": "Polyvios Pratikakis", "author_profile_id": "81100266082", "affiliation": "University of Maryland, College Park, MD", "person_id": "P698422", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1328438.1328447", "year": "2008", "article_id": "1328447", "conference": "POPL", "title": "Contextual effects for version-consistent dynamic software updating and safe concurrent programming", "url": "http://dl.acm.org/citation.cfm?id=1328447"}