{"article_publication_date": "01-07-2008", "fulltext": "\n SemanticsofTransactional Memory andAutomatic Mutual Exclusion Mart\u00b4inAbadi . AndrewBirrell TimHarris \nMichaelIsard MicrosoftResearch,SiliconValley University ofCalifornia,SantaCruz . MicrosoftResearch,Cambridge \n abadi@microsoft.com birrell@microsoft.com tharris@microsoft.com misard@microsoft.com Abstract SoftwareTransactionalMemory(STM) \nisanattractivebasisfor thedevelopment oflanguagefeaturesforconcurrentprogramming. However, thesemanticsof \nthesefeaturescanbedelicateandprob\u00adlematic. In this paper we explore the tradeoffs between semantic simplicity, \nthe viability of ef.cient implementation strategies, and the .exibility of language constructs. Speci.cally, \nwe develop se\u00admantics and type systems for the constructs of the Automatic Mu-tualExclusion(AME)programming \nmodel;ourresults applyalso to other constructs, such as atomic blocks. With this semantics as a point \nof reference, we study several implementation strategies. We model STM systems that use in-place update, \noptimistic con\u00adcurrency, lazy con.ictdetection,and roll-back.Thesestrategiesare correct only under non-trivial \nassumptions that we identify and an\u00adalyze. One important source of errors is that some ef.cient imple\u00admentationscreatedangerous \nzombie computationswhereatrans\u00adactionkeepsrunning afterexperiencing acon.ict; theassumptions con.ne the \neffects of these computations. Categories and Subject Descriptors D.1.3[Programming Tech\u00adniques]:ConcurrentProgramming \nParallelprogramming General Terms Languages,Theory 1. Introduction The notorious dif.culty of concurrent \nprogramming stems in part from thechallengesof expressing theintendedprogramsemantics with the available \nconstructs for synchronization and mutual ex\u00adclusion.Forexample,programswith threadsandlocksoftensuffer \nfromdeadlocks andrace conditions.Some recent type systems and otherprogramanalysesaim toprevent theseerrors(e.g.,(Sterling \n1993; Abadi et al. 2006; Naik et al. 2006)). More radically, many researchershavebeenexploring theuseofSoftwareTransactional \nMemory(STM)(ShavitandTouitou1995) asabasisfor language features that may make it easier to develop and \nanalyze concur\u00adrent programs. In one approach, locks are replaced with block\u00adstructured atomicsections,soaprogrammermay \nreasonas ifeach atomicsectionisexecuted asasinglestep,serializedwithrespectto allotheratomicsections(Harris \nandFraser2003;Harris et al.2005; Carlstrom etal.2006).Several other related modelshavebeenpro\u00adposed; \nthese includeSafeFutures(Welcetal.2005),Transactions Permission to make digital or hard copies of all \nor part of this work for personal or classroomuseisgrantedwithout feeprovidedthat copies arenotmadeordistributed \nforpro.t orcommercialadvantageandthatcopiesbearthisnotice andthefullcitation onthe.rstpage.To copy otherwise,to \nrepublish,topostonserversorto redistribute tolists, requirespriorspeci.cpermission and/ora fee. POPL \n08, January7 12,2007,SanFrancisco,California,USA. Copyright c . 2008ACM978-1-59593-689-9/08/0001. . .$5.00 \nEverywhere(Kuszmaul andLeiserson2003), andAutomaticMu\u00adtualExclusion(AME)(Isard andBirrell2007),described \ninSec\u00adtion2,onwhich thispaper isbased. Intuitively, the semantics of STM is appealingly simple. How\u00adever, \nas researchers are coming to discover, this simplicity is illu\u00adsory and the actual semantics offered \nby implementations are of\u00adten counterintuitive programs that look obviously correct may behave in unexpected \nways. The crux of the problem is that im\u00adplementations do not detect con.icts between a transaction run\u00adning \nin one thread and non-transactional steps of another thread. Thisproperty,sometimes termed weak atomicity \n(Blundellet al. 2005), is attractive from an implementation standpoint: it means that non-transacted \ncode does not incur a performance overhead, and that existing libraries and operating system interfaces \ncan be used without recompilation in non-transacted code. In contrast, strong atomicity requirestheavoidanceordetectionofthosecon\u00ad.icts. \nStrong atomicity appears to be the semantics expected by programmers but, unfortunately, it does not \nappear to be practical to implement using STM without restrictions and without recom\u00adpilingnon-transacted \ncode. This paper examines this problem and explores the tradeoffs between semantic simplicity, the use \nof ef.cient implementation strategies, and the .exibility of language constructs. We present our results \nfocusing on the AME programming model for two reasons. First, while developing this new programming model, \nwe hope to avoid the pitfalls we have encountered with earlier work on atomic blocks; we want to understand \nAME s constructs and whichtechniqueswecanuse to implement them.Second, there isa straightforward mechanicaltranslationfromaprogramwithatomic \nblocks into AME s constructs, so the results that we establish will apply more broadly; the translation \nin the other direction is less obvious. We present the AME calculus as a formalization of the AME programming \nmodel(Section3) andde.neastrong semanticsfor this calculus that abstracts the underlying STM (Section \n4). We show that, without language restrictions, the techniques used by practical STMs can lead to behavior \nthat is incorrect under the strong semantics(Section5).Earlier workhasprovided some ex\u00adamples(Blundellet \nal.2005;Shpeismanet al.2007).Weargue that most of theseare incorrectlysynchronizedprograms;however,we \nshowanumberoffurtherexampleswhich, informally,donot con\u00adtain race conditions. We focus, in particular, \non the problems that occurwhenusing theBartok-STM implementation(Harrisetal. 2006)inwhich updatesaremade \nin-place totheheap( eagerver\u00adsioning (Mooreetal.2006))so tentativework isvisiblebeforea transaction commits, \nand con.icts may not be detected until com\u00admit time( lazy con.ictdetection ),allowing atransactiontocon\u00adtinuerunning \nasa zombie (Diceet al.2006) afterbecoming con\u00ad.icted. Similar implementation choices have been made in \nother STM systemssuch asMcRT(Sahaetal.2006),becauseof their ef.ciency on manypractical workloads. We \nthen examine language restrictions that enable weaker semantics which model some of the techniques used \nby Bartok\u00adSTM to implement theseexamplescorrectly(Section6). First, we consider a violation-freedom condition, \nwhich formalizes the sense in which our examples of Section 5 are race-free. For pro\u00adgrams that satisfy \nthis condition, we show that a lower-level se\u00admantics with weak atomicity, in-place update, and roll-backimple\u00adments \nthestrong semantics(Section7).In thissemantics,atmost one transaction executes at a time. While this \nsemantics is still some way from an actual implementation, it resembles a practical uni-processorSTM(Manson \net al.2005a). A further language restriction is a type system that statically separates data according \nto whether or not it is accessed transac\u00adtionally. We show that, for well-typed programs, a weaker seman\u00adtics \nthat models the concurrent execution of transactions and lazy con.ict detection between them implements \nthe strong semantics (Section8).Violation-freedomdoesnotsuf.cefor thisproperty. WediscussrelatedworkinSection9.We \nconclude inSection10 by considering further work, and the implications of our results to theimplementationchoicesmadewithinanSTM \nand tothedesign of language features based on it. Proofs and additional results are available at http://research.microsoft.com/research/ \nsv/ame/. 2. AutomaticMutualExclusion The AME programming model has been outlined in a workshop paper(Isard \nandBirrell2007).Wesummarize itsconstructshere, and refer tothatpaperforsupportingdetailsand examples. \n2.1 AMEBasics The motivation for AME is to encourage programmers to place as much of the program text \ninside transactions as possible we refer to this as protected code leaving non-transacted unpro\u00adtected \ncode primarily for interactions with legacy code. We be\u00adlieve that this protected by default style will \nhelp programmers write concurrent code whose semantics are clearer than is typical with today slanguages;inparticular,programsinthisstyleshould \nbe easier to understand and to maintain than those with lock-based idioms, or with a straightforward \ntranslation of lock-based code to use atomicblocks. Running an AME program consists of executing a set \nof asyn\u00adchronous method calls. The AME system guarantees that the pro\u00adgram execution is equivalent to \nexecuting each of these calls(or their fragments, de.ned below) in some serialized order. AME achieves \nconcurrency by overlapping the execution of the calls in caseswheretheyarenon-con.icting.Theprogram terminateswhen \nall itsasynchronousmethod callshavecompleted.Initially,theset consists of a call of main() initiatedby \ntheAME system.Aswell as ordinary method calls, code can create another asynchronous method callby executing: \nasync MethodName(<method arguments>); The calling code continues immediately after this call. In the \ncon\u00adceptual serialization of the program, the asynchronous callee will beexecuted after thecallerhascompleted. \nInorder toachievetheserializationguarantee,weenvisionthat each asynchronous method call will be executed \nby the AME sys\u00adtemasa transaction,inathreadprovidedbythesystem.If a trans\u00adaction initiates other asynchronous \nmethod calls, their execution is deferred until the initiating transaction commits. If the initiating \ntransaction aborts, they are discarded. When it commits, they are madeavailableforexecution(inan indeterminateorder).Theset \nof available asynchronous method calls will be executed concur\u00adrently, within the available resources \nand subject to strategies that preventexcessive transaction aborts. 2.2 Blocking anAsynchronousMethod \nAn asynchronous method may contain any number of calls to the system-supplied method: blockUntil(<predicate>); \nFrom the programmer s perspective, the code of an asynchronous method executes to completion only if \nall the executed calls of blockUntil within the method have predicates that evaluate to true. blockUntil \ns implementation does nothing if the predi\u00adcate holds, but otherwise it aborts the current transaction \nand re\u00adexecutesitlater(at a timewhenitis likelytosucceed).Thisbehav\u00adior is like that of retry in some \nsystems(Harris et al.2005). 2.3 Fragmenting anAsynchronousMethod Apurely event-basedmodelproducesprogram \nstructure that canbe unpleasant and unstable.Forexample, ifapreviouslynon-blocking method callismodi.ed \ntorequireablocking action(e.g.,ahash table is modi.ed to use disk storage instead of main memory), the \nevent-based style would require that the method, and all of its callers, gets split into two separate \nmethods (a request and a response handler). This splitting is sometimes referred to as stack ripping \n(Adyaetal.2002).AME ssolutionis toallowan asynchronous method call to contain one or more invocations \nof the system method yield().A yield call breaks a method into multiple atomic fragments. Importantly, \nthese atomic fragments are delimited dynamically by the calls of yield, not statically scoped like explicit \natomic blocks. With this enhancement, the overall execution of a program is guaranteed to be a serialization \nof its atomic fragments. We implement yield by committing the current transaction and starting a new \none. A blockUntil call blocksexecutionofonly thecurrent atomicfragment(thecode that follows the most \nrecent yield), or equivalently, it retries only the transactionbegunafter themost recent yield. 2.4 \nExternalSideEffects Actions with external side effects, such as I/O, are performed by asynchronouscallstoanI/O \nlibraryinterface.Theactuallow-level I/O operations take place outside of transactions, either inside \nthe AMEruntimeorinexplicitlyunprotected code.Inorder tosupport this and other access to legacy non-transacted \ncode, we allow the followingform: unprotected { ... } The unprotected code must use existing mechanisms \nfor synchro\u00adnization.Thecurrent atomicfragment endsbefore theunprotected statement, and a new one starts \nafter it.  3. TheAMECalculus In our formal study, we focus on a small but expressive language. The language \nincludes constructs for AME, as discussed above; it also includes higher-order functions and imperative \nfeatures. We call it the AME calculus, though undoubtedly other calculi with AMEarepossible. Thesyntax \noftheAMEcalculus isde.nedinFigure1.This syn\u00adtax isuntyped; we introducea typesystem inSection6.2.Wealso \ngiveseveralformalsemanticsbelow.Thesyntax introducessyntac\u00adtic categories of values, constants, variables, \nand expressions. The values are constants, variables, and lambda abstractions (.x. e). In addition to \nvalues and to expressions of the forms async e, blockUntil e, and unprotected e, the expressions include \nno\u00adtationsforfunction application(ef), allocation(ref e, which allo\u00adcates a new reference location and \nreturns it after initializing it to V . Value = c |x |.x. e c . Const = unit |false |true x,y . Var e,f \n. Exp = V | ef | ref e |!e |e := f | async e | blockUntil e | unprotected e Figure1. Syntaxof theAME \ncalculus. the value of e),dereferencing(!e, which returns the contents in the reference location that \nis the value of e), andassignment(e := f, which sets the reference location that is the value of e to \nthe value of f). The syntax allows arbitrary nestings of async, unprotected, and blockUntil, and also \nallows async anywhere, not necessarily attached toafunctioncall.Inunprotected contexts, blockUntil e \nwillbehaveroughly like waituntil e theprecisemeaning ofthis isde.nedby thesemanticsofSection4.Practical \nembodimentsof AME need notbeas liberalintheserespects. As usual there is no dif.culty in including other \nconstructs. Several arede.nable: Weabbreviate(.x. e ' ) e to let x = e in e ' .We alsoabbreviate '' ' \nlet x = e in e to e; e when x doesnotoccurfree in e . We treat yield as syntactic sugarfor unprotected \nunit.  We can express abort and retry as blockUntil false.  Traditional atomic blocks typically occur \nin the context of un\u00adprotected expressions, and differ from asynchronous calls in thatthey aresupposed \ntobeexecutedimmediately,notinsome inde.nitefuture.We can express atomic e as:  let x = ref false in \nasync (e; unprotected (x := true)); blockUntil !x where x is a fresh variable that serves for signaling \ne s termi\u00adnation.The use of unprotected (x := true) rather than sim\u00adply (x := true) ensures that, when \nthis encoding is used in unprotected contexts(as intended), all accesses to x are done in unprotected \ncontexts, thus conforming to the type system of Section6.2.  4. Strong Semantics This section de.nes \na semantics for the AME calculus, intended to be a simple model of the constructs s expected behavior \nrather thanofpossibleunderlyingimplementation techniques.Tothisend, the semantics provides strong atomicity \nbetween the execution of transacted and non-transacted code, and it does not model roll\u00adback,optimisticconcurrency,and \nother low-levelfeatures.InSec\u00adtions 7 and 8 we consider richer and weaker semantics that add thesefeatures. \n4.1 States Asdescribed inFigure2,astate (s,T,e)consistsof thefollowing components: a reference store \ns,  a collection of expressions T,which wecall thepool,  adistinguished active expression e.  S . \nState = RefStore \u00d7 ExpSeq\u00d7 Exp s . RefStore = RefLoc . Value r . RefLoc . Var T . ExpSeq = Exp * Figure2. \nState space. A reference store s is a .nite mapping of reference locations to values. Reference locations \nare simply special kinds of variables that can be bound only by a reference store. We write RefLoc for \nthe set of reference locations. We assume that RefLoc is in.nite, so RefLoc -dom(s) is never empty. For \nevery state (s,T,e), we require that if r . RefLoc occurs free in s(r ' ), in T, or in e, then r . dom(s). \nThis condition will be assumed for initial states and willbepreservedby computation steps. Informally, \nwe may imagine that a computer includes a single specialprocessorforperforming protected work,occupiedbythe \nactive expression, and an unbounded set of additional processors capableofdoing unprotected work,dedicated \ntothepool.(This informal modelissomewhat independent ofthedetailsoftheAME calculus; indeed, we .nd it \nvaluable in our work in the context of richer languages.) If no unprotected work is available, then expressions \nin thepool aresimplywaitingfor thespecialprocessor. We identifyexpressions with threads of computation;the \nsemantics doesnotdescribestacksorother thread-speci.cdata.  4.2 Steps The evaluation of a program starts \nin an initial state (s,e,unit) with a single expression in the pool and with unit as the distin\u00adguishedactive \nexpression. Evaluationthen takesplaceaccordingtorules(givenbelow)that specifythebehaviorof thevariousconstructs \nin the language.The execution of threads is interleaved in a non-deterministic manner, subject to atomicity \nconstraints. Each evaluation step produces a new state. Given a state, the next state is determined by \nthe next possible operation in the active expression or in one of the expres\u00adsions in the pool. We model \nstrong atomicity by allowing expres\u00adsions in the pool to take steps only when the active expression is \nunit, thus preventing the interleaving of steps of unprotected and protectedwork. Inall cases, the nextpossible \noperation in an expression isfound by decomposing the expression into an evaluation context and a subexpression \nthat describes this operation. As usual, a context is an expression with ahole [], and an evaluation \ncontext is a context of a particular kind. Given a context C and an expression e, we write C[ e ] for \nthe result of placing e in the hole in C. We use severalkindsof evaluationcontexts,de.ned inFigure3: \n P evaluation contexts are for the execution of protected frag\u00adments: thepositionforevaluation isnot \nunder unprotected.  U evaluationcontextsarefor theexecutionof unprotectedfrag\u00adments: thepositionforevaluation \nisunder unprotected.  E evaluation contexts allow us to manipulate unprotected values in theexecutionof \nunprotectedfragments.  We also let some evaluation contexts be sequences of expressions with ahole: \nF evaluation contexts are of the form T.U.T ' ,unit or of the form T,P. Thus, F[ e ] is either of the \nform T.U[ e ].T ' ,unit or of the form T,P[ e ]. We write e0 .F[ e1 ] as an abbreviation for e0 .T.U[ \ne1 ].T ' ,unit or e0 .T, P[ e1 ], respectively. P = [ ] |P e |V P | ref P | !P | P := e |r := P | blockUntil \nP U = unprotected E | U e |V U | ref U | !U | U := e |r := U | blockUntil U E = [ ] |E e |V E | ref E \n| !E | E := e |r := E | blockUntil E | unprotected E F = T.U.T ' ,unit |T,P Figure3. Evaluation contexts. \n(s,F[ (.x. e) V ]) -.s (s,F[ e[V/x] ]) (Trans Appl)s (s,F[ ref V ]) -.s (s[r . V],F[ r ]) (Trans Ref)s \nif r . RefLoc -dom(s) (s,F[ !r ]) -.s (s,F[ V ]) (Trans Deref)s if s(r) = V (s,F[ r := V ]) -.s (s[r \n. V],F[ unit ]) (Trans Set)s (s,F[ async e ]) -.s (s,e.F[ unit ]) (Trans Async)s (s,F[ blockUntil true \n]) -.s (s,F[ unit ]) (Trans Block)s (s,T,P[ unprotected e ]) -.s (s,T.P[ unprotected e ],unit) (Trans \nUnprotect)s (s,T.E[ unprotected V ].T ' ,unit) -.s (s,T.E[ V ].T ' ,unit) (Trans Close)s (s,T.e.T ' ,unit) \n-.s (s,T.T ' ,e) (Trans Activate)s Figure4. Transitionrulesof theabstract machine(strong). Figure4givesrules \nthatspecifythe transitionrelation that takes execution from one state to the next. The string Trans in \nthe names of the rules refers to transition rules, not to transaction . In these rules, we write e[V/x] \nfor the result of the capture-free substitution of V for x in e, and write s[r . V] for the store that \nagrees with s except at r, which is mapped to V. The subscript s in -.s indicates that this is a strong \nsemantics. Were yield not syntactic sugar we could have the two extra rules: (s,T,P[ yield ]) -.s (s,T.P[ \nyield ],unit) (s,T.E[ yield ].T ' ,e ' ) -.s (s,T.E[ unit ].T ' ,e ' ) These rules are easily derived \nfrom those of Figure 4 and the de.nition of yield as unprotected unit.  5. ProblemswithWeakAtomicity \nThestrong semanticsofSection4isintended tore.ect aprogram\u00admer s intuitionabout thebehaviorof theAME constructs,but \nit is unlikely tobepractical toimplementinsoftwarewithoutlanguage restrictions.Inparticular, themainpurposeof \nusing unprotected re\u00adgions is to interactwith the operating system and other legacy code that cannot \neasily be changed; implementations that offer strong atomicityby recompiling unprotected codedonot support \nthispur\u00adpose. In this section we discuss the ways in which different imple\u00admentations of STM can give \nbehavior that differs from the strong semantics. For the purposes of this discussion, we write examples \ninformally(ratherthaninacalculus likethat ofSection3)forcon\u00advenience, and in order to emphasize the relevance \nof these exam\u00adples to practical code. However, we use the strong semantics as a pointof reference. 5.1 \nReviewofExamplesfromShpeismanet al. The .rst set of examples, in Figure 5, comes from work on implementing \nstrong atomicity (Shpeisman et al. 2007). In all casescodeisprotected(i.e.,runs transactionally) unlessitiscon\u00adtained \nin an unprotected block. Shpeisman et al. discuss how these examples can cause unexpected behavior with \nexisting STM implementations in particular, almost all of these problems oc\u00adcur with Bartok-STM because \nof its use of in-place update and lazy con.ict detection. Bartok-STM does not exhibit the GIR and GLUproblems;theseoccur \ninotherSTMs(e.g.,(HarrisandFraser 2003)) which can buffer data at a coarser granularity than indi\u00advidual \n.elds: a transaction committing or being rolled back can involve writes that spill over onto adjacent \nlocations. 5.2 AreTheseProblemsDataRaces? One may reasonably ask Do these problems matter? because most \nof the examples in Figure 5 intuitively have data races. For instance, in the Non-Repeatable Reads (NR) \nproblem, there is no synchronization between the non-transacted store to x and the transacted read from \nx. In fact, almost all the examples in the .gure involve two threads accessing x without any synchronization \nbetween them. (The sole exception is GLU and this problem is readilysolvedby making theSTMbufferdataonaper-.eldbasis. \nBartok-STMalreadydoes this.) Unfortunately,althoughtheseexamplescouldbeconsidered to have data races, \nother examples are free from data races at the sourcelevel(bothintuitivelyand withrespect toformalde.nitions \nbelow) but do not obey the strong semantics with many STM systems.Forconcreteness,againwefocusonhow theseproblems \ncan occur with Bartok-STM; however, we believe that variants of theproblems ofSections5.4 5.5 affect \nall extantSTM systems that allowdata tobesharedbetweenprotected and unprotected code. r2 =x; x=1; } (ILU)Intermediatelostupdates: \nx==1 r1 = x; unprotected { x=r1 +1; x=10; } (IDR)Intermediatedirtyreads: r1==1 x ++; unprotected { x++; \nr1 =x; } (SLU)Speculativelostupdates: x==0 if (y==0) { unprotected { x=1; x=2; // Abort y=1; }} (SDR)Speculativedirtyreads: \nx==0, y==1 if (y == 0) { unprotected { x=1; if (x == 1) { // Abort y=1; } }} (OW)Overlappedwrites: r1==0 \no1.val = 1; unprotected { x=o1; r1 =-1; if (x != null) { r1 = x.val; }} (BW)Bufferedwrites: r2!=r3 or \nr1.val!=0 // Initially x!=null, x.val==1 r1 =x; if (x != null) { x = null; x.val++; unprotected { } r2 \n= r1.val; r3 = r1.val; r1.val = 0; } (GIR)Granularinconsistent reads:r==0 r = -1; unprotected { atomic \n{ y.g = 1; y.f =...; x=1; if (x==1) { } r = y.g; }} (GLU)Granularlost update:x.g==0 x.f = 1; unprotected \n{ x.g = 1; } Figure5. ExampleproblemsfromShpeisman etal.(2007).Unless otherwisenoted,all.elds initiallyhold0.Registers \nr, r1, r2, and r3 are thread-local. 5.3 ZombieTransactions The .rst example concerns zombie transactions \nthat access more data than would be touched in any serialization. Consider the fol\u00adlowingtwo atomic actions \nA1 and A2 that run concurrently with the unprotectedblock U1: // A1 // A2 // U1 r1 = u; u++; unprotected \n{ r2 =v; v++; r1 =x; if (r1 != r2) { } x = 42; } Informally, one may reason that both serialization \norders for A1 and A2 will maintain the invariant u==v, so the condition r1!=r2 should never be satis.ed, \nA1 will never write to x, and therefore there isnodataracewith U1 s readfrom x. However, with Bartok-STM, \nA2 may run in its entirety in be\u00adtween A1 s readsfrom u and v, causing A1 to write to x before the con.ict \nisdetected.Despite thecon.ictdetectionand any resulting roll-back, U1 may see this write. This kind of \nexample is particu\u00adlarlyproblematic innativecode.For instance,suppose that instead of writing to x, A1 \nindexes an array x[r1-r2]: in a language with\u00adout bounds checking, it may actually write to any location \ndepen\u00addent on thenumberofincrementsperformed in A2. 5.4 Privatization A second example is the privatization \nproblem in which a piece ofdata issometimesaccessedfromprotected codeand sometimes accessed directly. \nConsider these code fragments, with one thread running A1 and then U1, and a secondthread running A2: \n// Initially: x_shared=true, x=0 // A1 // A2 x_shared = false; if (x_shared) { // U1 x=42; unprotected \n{ } x ++; } Informally, one may reason that this code has no data races: x shared is always accessed \ntransactionally and, by the time U1 accesses x non-transactionally, A1 has already been executed and \neither A2 is serialized before A1 (so the accesses tox cannot race) or A2 is serialized after A1 (so \nit will see thatx shared is false). WithBartok-STM, it ispossibleforA1 to execute in its entirety between \nA2 s read from x shared and its write to x and then for U1 s accesses to x to race with A2. In Bartok-STM \nthe problem is thereforesimilar tothat ofSection5.3inthat itoccursbecause A2 continues toexecuteasazombie.However, \nthesameproblemcan occur without zombies on STMs that buffer transactional updates and write them back \non commit (Harris and Fraser 2003): A2 s write-back to x may race with U1 s accesses. 5.5 Publication \nA.nalexample is the publicationproblemin which apiece ofdata is initially thread-privateand thenbecomesshared: \n// Initially: x_shared=false, x=0 // U1 // A2 unprotected { r1 = -1; x = 42; if (x_shared) { } r1 =x; \n// A1 } x_shared = true; Once again, one may reason informally that this code has no data races: x shared \nis always accessed transactionally and, when it is set by A1, the update to x has already been performed. \nIf A1 is serializedbefore A2 then A2 will seeboth updates. The problem here is more subtle and relates \nto more of the language thanjust theSTM implementation: there isno indication in thesourcecode that theorderingbetween \nA2 s readsfrom x and x shared is important. If they are re-ordered during compilation then the implementation \nof A2 may readfrom x beforeU1, andthen read from x shared after A1, leaving A2 serialized after A1, but \nwith r1==0. A similar lock-based program, placing A1 and A2 in regionsprotectedbythesame lock, iscorrectlysynchronized \nunder theJava memory model(Manson et al.2005b).As with our strong semantics, itwouldgiveeither r1==-1 \nor r1==42.  6. Violation-freedom and Separation In Section 5, we show example programs that are not \nexecuted correctlybySTM systems.Insomecases, theseareprogramswith dataraces,while inothers theproblemsarisebecause(despite \nthe absence of apparent data races) a variable x is accessed from both protectedand unprotected code \nin the implementations. In this section we present two criteria that formalize the sep\u00adaration of protected \nand unprotected code, in the AME calculus. The .rst criterion, violation-freedom, says that, dynamically, \ndata cannot be accessed with and without protection at the same time. This criterion allows us to say, \nformally, that the examples of Sec\u00adtions 5.3 5.5 are correctly synchronized, while most of the exam\u00adplesofSection5.1arenot.Thesecond \ncriterion,separation, isem\u00adbodied in a static discipline that guarantees that protected and un\u00adprotected \ncomputations do not use the same reference locations. As we prove, separation implies violation-freedom. \nIn Sections 7 and8,weshowthat,by restricting ourselves toprogramsthat meet these criteria, we can enable \nthe use of ef.cient and correct lower\u00adlevel semantics. 6.1 Violation-freeExecutions Wede.neaconditionaccording \ntowhichdatacannotbeaccessed withand withoutprotectionatthesame timeindifferentthreads. Given a state \n(s,e1 . \u00b7\u00b7\u00b7 .en,e), there is a violation on a loca\u00adtion r if ei = U[ f ] for some i =1..n and e = P[ \nf ' ] where f and f ' are reads or writes on r (that is, expressions!r or r := ...), and at least one \nof them is a write(r := ...). A computation is violation-freeifnoneofitsstateshaveviolationsforanylocations. \n(Analogously,wecouldde.neraces, inwhichwewouldalsocon\u00adsider con.icts within e1 . \u00b7\u00b7\u00b7 .en; every violation \nis a race but not every race is a violation.) A possible programming discipline is to require that programs \nnevergenerateviolations in thestrong semantics.Under thisdisci\u00adpline, a state (s,T,e)is good if all strong \ncomputations that start from this state are violation-free. The use of the strong semantics is signi.cant: \nprogrammers should not have to understand lower\u00adlevelimplementations.However,analogouscriteriaapply to \nlower\u00adlevel implementations, and might be of bene.t in compiler opti\u00admizations. Some of our lemmas say \nthat the absence of violations in the strong semantics implies the absence of violations in certain lower-level \nimplementations. 6.2 Separation The type system described in this section embodies a discipline in whichprotected \nand unprotected computationsdonot use thesame portions of the reference store. They may however communicate \nvia variables. The type system is de.ned in Figure 6, using judgments and rules for reasoning about the \njudgments. The core of the type system is the set of rules for the judgment E; p . e : t (read e is a \nwell-typed expression of type t in typing environment E with effect p ). The intent is that, if this \njudgment holds, then e yields values of type t with effect p,and thefreevariablesof e are given bindings \nconsistent with the typing environment E. When p is P, this means that the evaluation of e accesses only \nthe part of the reference store for protected computations; when p is U, this means that the evaluation \nof e accesses only the rest of the store. The typing environment E is organized as a sequence ofbindings, \nand we use \u00d8todenote theemptyenvironment.Similarly, s .p tis thetypeoffunctionthat takeargumentsoftype \ns andyield results of type t with effect p. The type system introduces a sharp distinction between P \ncode and U code . The type system is thus deliberately simple; various elaborations are possible, mostly \nalong standard lines, but wedonot need themforourpresentpurposes. Judgments E . . E; p . e : t E is a \nwell-formedtyping environment e is a well-typedexpression of type t in E with effect p Rules \u00d8.. (Env\u00d8) \nE .. x .. dom(E) (Envx) E,x : t .. E .. (ExpUnit) E; p . unit : Unit E .. (ExpBoolfalse) E; p . false \n: Bool E .. (ExpBooltrue) E; p . true : Bool E,x : t,E ' .. (Expx) E,x : t,E ' ; p . x : t E,x : s ; \np . e : t (ExpFun) E; q . .x. e : s .p t E; p . e1 : s .p tE; p . e2 : s (ExpAppl) E; p . e1 e2 : t E; \np . e : t (ExpRef) E; p . ref e : Refp t E; p . e : Refp t (ExpDeref) E; p . !e : t E; p . e1 : Refp \ntE; p . e2 : t (ExpSet) E; p . e1 := e2 : Unit E; P . e : Unit (ExpAsync) E; q . async e : Unit E; p \n. e : Bool (ExpBlock) E; p . blockUntil e : Unit E; U . e : t (ExpUnprotect) E; p . unprotected e : t \nFigure6. The .rst-order typesystemforseparation. Thefollowing smallexample illustratestherestrictionsthatthe \ntype system imposes: let x = ref V in let y = ref true in async (y := false; unprotected z := !x); async \n(blockUntil !y; x := V ' ) where V and V ' are distinct values. Intuitively, the contents of the reference \nlocation y indicates whether x is shared; setting that location to false amounts to a privatization. \nThis program is not permitted by the type system, because the reference location that is the value of \nx is used in both protected and unprotected computations. let x = ref V in let y = ref true in async \n(y := false; let x ' =!x in (unprotected z := x ' )); async (blockUntil !y; x := V ' ) Here, the reference \nlocation in question is used only in protected computations; itsvalueisputintoalocal variable x ' for \nuse in an unprotected computation in the same thread. Inorder toprovethesoundnessofthetypesystem,weextendit \nto states (s,T,e).We write E .(s,e1 . \u00b7\u00b7\u00b7 .en,e) if dom(s)= dom(E) nRefLoc,  for allr . dom(s), there \nexist t and psuchthat E(r)= Refp t and E; p . s(r): t,  E; P . ei : Unit for alli =1..n,  E; P . e \n: Unit.  We say that (s,e1 . \u00b7\u00b7\u00b7 .en ,e)is well-typed if there exist E such that E .(s,e1 . \u00b7\u00b7\u00b7 .en,e). \nWe write -.* s for the re.exive\u00adtransitive closure of -.s . We obtain that typability is preserved bycomputation(that \nis,by -.* s ): THEOREM 6.1 (Preservation ofTypability). If (s,T,e) is well\u00adtyped and (s,T,e) -.* s (s \n' ,T ' ,e ' ), then (s ' ,T ' ,e ' )is well-typed. This theorem helps in relating the type system to \nthe absence of violations,anditservesas thebasisforanalogousresultsfor lower\u00adlevel semantics,below. We \nalso obtain a progress result, which characterizes when a computation may stop and implies that computations \ndo not get stuck inunexpected ways(for instance,by applying abooleanas though it were a function). This \nprogress result is partly a sanity check; stronger ones are viable. THEOREM 6.2 (Progress). If (s,T,e)is \nwell-typed, the only free variables in (s,T,e)are reference locations, and (s,T,e) -.s * (s '' ,T ,e \n' ), then: 1. e ' is unit and T ' is empty; or 2. e ' is of the form P[ blockUntil false ];or  ' (s \n'' '' '' '' ). 3. (s ' ,T ,e ' ) -.s ,T ,e '' )for some (s '' ,T ,e 6.3 ComparingSeparationwithViolation-freedom \nViolation-freedom is a clear but undecidable dynamic criterion. The type system for separation provides \na suf.cient condition for violation-freedom.Asacorollary toTheorem6.1,weobtain: COROLLARY 6.3. If(s,T,e)is \nwell-typed, then all strong compu\u00adtations that start from (s,T,e)are violation-free. As suggested above, \nseparation appears to be more robust than violation-freedom(forinstance, lessfragile in thepresenceof \ncom\u00adpiler optimizations).  7. WeakSemanticswithRoll-back Having introduced the violation-freedom and \nseparation criteria in Section 6, we can examine their impact on the use of weaker semantics that model \nsome of the implementation techniques used byactualSTMs:if aprogram meets one or other ofthe criteria, \nthen S . State = RefStore \u00d7 ExpSeq\u00d7 Exp \u00d7 Exp \u00d7 Log\u00d7 ExpSeq s . RefStore = RefLoc . Value l . Log =(RefLoc\u00d7 \nValue)* r . RefLoc . Var T,P . ExpSeq = Exp * Figure7. State space, with roll-back. whichimplementation \ntechniquescanbeused whilerespectingthe strong semantics? In thissectionwede.neasemantics that modelsweak \natomic\u00adity,allowing stepsof unprotected code tobeinterleaved withsteps ofprotected code, and alsomodelseagerversioning,inwhichtrans\u00adactionsmakein-placeupdates \ntotheheap and arerolledbackifthey abort for some reason. This semantics still serializes transactions: \nonly one piece of protected code can run at a time. We show that this weak semantics is correct for violation-free \nprograms. Even without concurrency between transactions, this weak semantics is still interesting from \na practical point of view as well as a theo\u00adretical one for instance to provide roll-back on a uni-processor \nreal-time system(Manson et al.2005a).We consider concurrency between transactions inSection8. 7.1 States \nFigure 7 de.nes states for the semantics with roll-back. A state (s,T,e,f,l,P)consistsofthefollowing \ncomponents: s, T, and e, which are as usual,  f,anexpressionthat, through computation,hasyielded e \n(and which we call the origin of e),  l, a list of memory locations and their values, to be used as \na login undos,  P,a list of pending threadstobeforked uponcommit.  Muchas inSection4.1,forevery state \n(s,T,e,f,l,P), we require that if r . RefLococcursfree in s(r ' ), in T, in e, in f, in l, or in P, then \nr . dom(s).Thisconditionwillbeassumedfor initial states and willbepreservedby computation steps. Wewriteeachpair \nin l in the form [r . V], we let dom(l) be the set of locations r for which l is de.ned, and when r . \ndom(l) we write l(r) for the value V to which r is mapped.  7.2 Steps Figure 8 gives the rules of this \nsemantics. The intent is that, upon a roll-back caused by e, the origin expression f is added back to \nT and theundosdescribedin l areperformed.The semanticshas a few subtleties. As insomepracticalSTM implementations(Sahaetal.2006; \nHarris et al. 2006), the undos described in l are performed individually rather than as one atomic step.Wepick \nan arbitrary order.  Allocations are not undone. If they were, we could cause dan\u00adgling pointers in \nprograms with race conditions and we be\u00adlieve thatdanglingpointersshouldbeavoided even inprograms with \nsynchronization errors. Again, this detail is inspired by practicalSTMs(Harris etal.2005).  No undofacilities \nareprovidedfor unprotectedcomputations.  Since this is a weak semantics, unprotected computations may \nbe interleaved with protected computations, and even with the roll-backs ofprotected computations.  \n (s,T,P[ (.x. e) V ],f,l,P) -.rw (s,T,P[ e[V/x] ],f,l,P) (Trans Appl P)rw (s,T.U[ (.x. e) V ].T ' ,e \n' ,f,l,P) -.rw (s,T.U[ e[V/x] ].T ' ,e ' ,f,l,P) (Trans Appl U)rw (s,T,P[ ref V ],f,l,P) -.rw (s[r . \nV],T,P[ r ],f,l,P) (Trans Ref P)rw ifr . RefLoc -dom(s) (s,T.U[ ref V ].T ' ,e,f,l,P) -.rw (s[r . V],T.U[ \nr ].T ' ,e,f,l,P) (Trans Ref U)rw ifr . RefLoc -dom(s) (s,T,P[ !r ],f,l,P) -.rw (s,T,P[ V ],f,l,P) (Trans \nDeref P)rw ifs(r) = V (s,T.U[ !r ].T ' ,e,f,l,P) -.rw (s,T.U[ V ].T ' ,e,f,l,P) (Trans Deref U)rw ifs(r) \n= V (s,T,P[ r := V ],f,l,P) -.rw (s[r . V],T,P[ unit ],f,l ' ,P) (Trans Set P)rw where l ' = ifr . dom(l) \nthen l else l.[r . s(r)] (s,T.U[ r := V ].T ' ,e,f,l,P) -.rw (s[r . V],T.U[ unit ].T ' ,e,f,l,P) (Trans \nSet U)rw (s,T,P[ async e ],f,l,P) -.rw (s,T,P[ unit ],f,l,e.P) (Trans Async P)rw (s,T.U[ async e ].T \n' ,e ' ,f,l,P) -.rw (s,e.T.U[ unit ].T ' ,e ' ,f,l,P) (Trans Async U)rw (s,T,P[ blockUntil true ],f,l,P) \n-.rw (s,T,P[ unit ],f,l,P) (Trans Blocktrue P)rw (s,T.U[ blockUntil true ].T ' ,e,f,l,P) -.rw (s,T.U[ \nunit ].T ' ,e,f,l,P) (Trans Blocktrue U)rw (s,T,P[ blockUntil false ],f,\u00d8,P) -.rw (s,f.T,unit,unit,\u00d8,\u00d8) \n(Trans Blockfalse Restore)rw (s,T,P[ blockUntil false ],f,l.[r . V],P) -.rw (s[r . V],T,P[ blockUntil \nfalse ],f,l,P) (Trans Blockfalse Undo)rw (s,T,P[ unprotected e ],f,l,P) -.rw (s,T.P.P[ unprotected e \n],unit,unit,\u00d8,\u00d8) (Trans Unprotect)rw (s,T,unit,f,l,P) -.rw (s,T.P,unit,unit,\u00d8,\u00d8) (Trans Done)rw (s,T.E[ \nunprotected V ].T ' ,e,f,l,P) -.rw (s,T.E[ V ].T ' ,e,f,l,P) (Trans Close)rw (s,T.e.T ' ,unit,unit,\u00d8,\u00d8) \n-.rw (s,T.T ' ,e,e,\u00d8,\u00d8) (Trans Activate)rw Figure8. Transitionrulesoftheabstractmachine,withroll-back(weak). \nIn thestrongsemanticsofSection4,thereisnoanalogueforthe list ofpendingthreads P.Instead, the correspondingthreads \nare put intoT,but they cannot make immediateprogress.  7.3 Correctness The goal of this section is to \nestablish the correctness of the weak semanticswithroll-backas an implementationofthesimpler strong semantics \nwithout roll-back, assuming the absence of violations. As the examples of Section 5 suggest, the violation-freedom \nhy\u00adpothesis isneeded.Morespeci.cally,weprovethatan intermediate strong semantics with roll-back implements \nthe strong semantics without roll-back; this result does not require violation-freedom. On the other \nhand, the weak semantics with roll-back is a correct implementation of the strong semantics with roll-back \nonly under someassumptions.Weobtain thefollowingtheorem: THEOREM 7.1 (Correctness). Assume that all strong \ncomputa\u00adtions that start from the state (s,T,unit)are violation-free. Con\u00adsider a weak computation with \nroll-back (s,T,unit,unit,\u00d8,\u00d8) -. * (s ' ,T ' ,unit,unit,\u00d8,\u00d8) rw Then there is a strong computation '' \n'' (s,T,unit) -. * s (s,T ,unit) '' '' for some s '' and T suchthat s ' is an extension of s '' and T \n= T up to reordering. This theorem is restricted to computations that lead to states of a particular \nform, in particular with an active expression unit. In general, when the active expression is not unit, \nthe intermediate store s ' may be one that cannot be obtained by strong computa\u00adtions.Moreover, this \ntheoremdoesnotyieldastrong computation with exactly the same .nal store: intuitively, the computation \nwith roll-backs may allocate additional locations, and those are not de\u00adallocated. However, the two .nal \nstores coincide at all accessible locations: our invariant on states implies that both stores are de\u00ad.ned(and \nequal)at allreferenced locations. Wededuceacorrectness theoremforwell-typedprograms: COROLLARY 7.2. Assume \nthat (s,T,unit) is well-typed. Con\u00adsider a weak computation with roll-back (s,T,unit,unit,\u00d8,\u00d8) -. * (s \n'' ,unit,unit,\u00d8,\u00d8) rw ,T Then there is a strong computation (s '' '' (s,T,unit) -. * s ,T ,unit) '' '' \nfor some s '' and T suchthat s ' is an extension of s '' and T = T up to reordering. S . State = RefStore \n\u00d7 ExpSeq\u00d7 TrySeq \u00d7 Log s . RefStore = RefLoc . Value l . Log =(RefLoc\u00d7 Value)* r . RefLoc . Var T,P \n. ExpSeq = Exp * O . TrySeq = Try * d . Try = Exp \u00d7 Exp \u00d7 Accesses \u00d7 ExpSeq a . Accesses = RefLoc * Figure9. \nState space, with optimistic concurrency.  8. WeakSemanticswithOptimisticConcurrency Building onthestudy \nof roll-back,we treat adif.cultextensionof the operational semantics in which multiple active expressions \nare evaluated simultaneously, with roll-backs in case of con.ict. We ground our work on important aspects \nof Bartok-STM, as above, by making in-place updates to the reference store and using lazy con.ict detection \nalthough alternative strategies might be easier to analyze. Like roll-back, optimistic concurrencyraises \ncorrectness issues. Interestingly, and unlike for our semantics of Section 7, violation\u00adfreedom isnot \nasuf.cient conditionforcorrectness in thiscase.As in our examples of Section 5.3 5.4, a program can be \nviolation\u00adfree under the strong semantics but have lower-level violations because of zombie transactions. \nNevertheless, we show that if a program is well-typed in the type system of Section 6.2 then its weak \nsemantics is correct with respect to the strong semantics. 8.1 States As described in Figure 9, states \nbecome more complex for this semantics.Inaddition tothecomponents s, T, and lthat appear in the semantics \nwith roll-back, here we have a list of tuples instead of a single active expressions e andits origin \nexpression f.Each of the tuplesiscalled a try,and consistsofthefollowing components: an active expression \ne,  its origin expression f, as in the semantics with roll-back,  a description of the accesses that \ne has performed, which are used for con.ict detection and which here is simply a list of reference locations, \n a list P ofthreads tobeforked uponcommit.  Clearly these components could be re.ned further in more \nelabo\u00adrate, realistic schemes. For instance, con.ict detection could dis\u00adtinguish readsand writes,possiblywith \ntimestamps; moreover,the log usedforundoscouldcontainadditionalinformationinorder to support moreselectiveundos.(ActualSTM \nimplementations typi\u00adcally resolve con.icts by aborting some transactions and commit\u00adting others.) We \nprefer to avoid this tedious book-keeping since it might obscure the presentation. Even in the present \nform, the se\u00admantics exhibits challengingfeatures. 8.2 Steps Figure10gives therulesofthissemantics.Theyrelyon \nthefollow\u00adingde.nitions: (ei,fi ,ai,Pi) and (ej ,fj ,aj ,Pj ) con.ict if ai and aj have at least one \nelement in common.  (e,f,a,P ) con.icts with O if (e,f,a,P ) con.icts with some tryin O.  O con.ictsifitcontains \ntwodistinct triesthat con.ict.  Given a logl and a list of reference locations a, l-a is the log obtainedfrom \nlby restricting to reference locations not in a.  If O is (e1 ,f1 ,a1 ,P1 ). \u00b7\u00b7\u00b7 .(en,fn,an,Pn) then \norigin(O) is the list f1 . \u00b7\u00b7\u00b7 .fn.  sl is the result of applying all elements of l to s.  The rules \nallow for con.icts to be detected as soon as they occur, but they do not require it. For simplicity, \nthe rules do not include somesecondaryfeaturessuf.cientlyexploredinthesemanticswith roll-back of Section \n7. In particular, undos are atomic. Moreover, there is no special treatment for blockUntil false; the \nrules simply allow undo to happen at any point (possibly because of con.icts,but alsopossiblybecause \nof blockUntil false). Inthissemantics,each transitionhastheform '' '' (s,T,O,l) -.ow (s ,T ,O ,l ) Inmany \ncases,a transitionisde.nedin termsof acontextthathas a hole either in T and in T ' , or in O and in O \n' . We say that the transition isprotectedif thehole is in O andin O ' , and saythat the transition isunprotectedif \nthehole is in T andin T ' .Byde.nition, wehave: transitionsthatareinstancesof(Trans ...P)ow are alwayspro\u00adtected; \n transitions that are instances of(Trans ...U)ow or of (Trans Close)ow are always unprotected;  transitions \nthat are instances of (Trans Undo)ow , (Trans Un\u00adprotect)ow ,(Trans Done)ow , or(TransActivate)ow are \nneither protectednor unprotected.   8.3 Correctness As explained above, the absence of high-level violations \ndoes not in general suf.ce for correctness. It is plausible that the absence of lower-level violations \nwould suf.ce for correctness. This result couldbe adequate as abasisfor compiler optimizations,but would \nnotbefullysatisfactory programmersshouldnotbeawareof the details of this lower-level semantics. Instead, \nwe rely on the type systemfor separation. Wedonotmodifythesourcetyping rulesofSection6.2,but we doextendthem \ntothestatesde.nedinthissection.Wewrite: E .(s,T,O,l) if dom(s)= dom(E) nRefLoc,  for allr . dom(s), \nthere exist t and psuchthat E(r)= Refp t and E; p . s(r): t,  for each e ' in T, E; P . e ' : Unit, \n for each (e,f,a,P ) in O, E; P . e : Unit and E; P . f : Unit, andfor each e ' in P, E; P . e ' : Unit, \n for each r . dom(l), there exists t such that E(r)= RefP t and E; P . l(r): t.  In the specialcase \nwhere Oand lare empty, we may omit them and simply say that (s,T)is well-typed. This condition is equivalent \nto (s,T,unit) being well-typed according to the de.nition of Section6.2.Thus, whether (s,T)is well-typed \ncanbe understood andproved entirely in termsofthehigher-levelde.nitions,without any regardfor optimistic \nconcurrency. Weobtain thattypability ispreservedbycomputation( -.* ): ow THEOREM 8.1 (Preservation ofTypability). \nIf(s,T,O,l)is well\u00adtyped and (s,T,O,l) -.* (s ' ,T ' ,O ' ,l ' )then (s ' ,T ' ,O ' ,l ' )is ow well-typed. \n (s,T,O.(P[ (.x. e) V ],f,a,P).O ' ,l) -.ow (s,T,O.(P[ e[V/x] ],f,a,P).O ' ,l) (Trans ApplP)ow (s,T.U[ \n(.x. e) V ].T ' ,O,l) -.ow (s,T.U[ e[V/x] ].T ' ,O,l) (Trans ApplU)ow (s,T,O.(P[ ref V ],f,a,P).O ' ,l) \n-.ow (s[r . V],T,O.(P[ r ],f,a,P).O ' ,l) (Trans RefP)ow if r . RefLoc -dom(s) (s,T.U[ ref V ].T ' ,O,l) \n-.ow (s[r . V],T.U[ r ].T ' ,O,l) (Trans RefU)ow if r . RefLoc -dom(s) (s,T,O.(P[ !r ],f,a,P).O ' ,l) \n-.ow (s,T,O.(P[ V ],f,r.a,P).O ' ,l) (Trans Deref P)ow if s(r) = V (s,T.U[ !r ].T ' ,O,l) -.ow (s,T.U[ \nV ].T ' ,O,l) (Trans Deref U)ow if s(r) = V (s,T,O.(P[ r := V ],f,a,P).O ' ,l) -.ow (s[r . V],T,O.(P[ \nunit ],f,r.a,P).O ' ,l ' ) (Trans Set P)ow where l ' = if r . dom(l) then lelse l.[r . s(r)] (s,T.U[ \nr := V ].T ' ,O,l) -.ow (s[r . V],T.U[ unit ].T ' ,O,l) (Trans Set U)ow (s,T,O.(P[ async e ],f,a,P).O \n' ,l) -.ow (s,T,O.(P[ unit ],f,a,e.P).O ' ,l) (Trans Async P)ow (s,T.U[ async e ].T ' ,O,l) -.ow (s,e.T.U[ \nunit ].T ' ,O,l) (Trans Async U)ow (s,T,O.(P[ blockUntil true ],f,a,P).O ' ,l) -.ow (s,T,O.(P[ unit ],f,a,P).O \n' ,l) (Trans BlockP)ow (s,T.U[ blockUntil true ].T ' ,O,l) -.ow (s,T.U[ unit ].T ' ,O,l) (Trans BlockU)ow \n(s,T,O,l) -.ow (sl,origin(O).T, \u00d8,\u00d8) (Trans Undo)ow (s,T,O.(P[ unprotected e ],f,a,P).O ' ,l) -.ow (s,T.P[ \nunprotected e ].P,O.O ' ,l -a) (Trans Unprotect)ow if (P[ unprotected e ],f,a,P) does notcon.ict with \nO.O ' (s,T,O.(unit,f,a,P).O ' ,l) -.ow (s,T.P,O.O ' ,l -a) (Trans Done)ow if (unit,f,a,P) does not con.ict \nwith O.O ' (s,T.E[ unprotected V ].T ' ,O,l) -.ow (s,T.E[ V ].T ' ,O,l) (Trans Close)ow (s,T.e.T ' ,O,l) \n-.ow (s,T.T ' ,(e,e, \u00d8,\u00d8).O,l) (Trans Activate)ow Figure10. Transitionrulesof theabstract machine,withoptimisticconcurrency(weak). \nInfact,weprove that if(s,T,O,l)is well-typed with respect to an environment E, then (s ' ,T ' ,O ' ,l \n' )is well-typed with respect to an extension of E.In thecasesof(TransRef ...)ow ,(TransDeref . . .)ow \n,and(TransSet ...)ow ,whichdeal withareference location of type Refp0 t0 , if the transition is protected, \nthen p0 must be P, and if the transition is unprotected, then p0 must be U. It follows that, if (s,T,O,l) \n-.* (s ' ,T ' ,O ' ,l ' )and (s,T,O,l)is well\u00adtyped, then there exist subsets P and U of dom(s ' ) such \nthat the ow protectedtransitions in (s,T,O,l) -.* (s ' ,T ' ,O ' ,l ' )allocate, read, or write only \nreference locations in P, and the unprotected ow transitions in (s,T,O,l) -.* (s ' ,T ' ,O ' ,l ' )allocate, \nread, or write only reference locations in U. Moreover, reference locations resetby(TransUndo)ow are \nin P.Thesubsets inquestionconsist of the reference locations declared with effects P and U, respectively, \nin the environment. Using Theorem 8.1, we establish the correctness for the weak semantics with optimistic \nconcurrency with respect to the high\u00adlevel, strong semantics. ow THEOREM 8.2 (Correctness). Assume that \n(s,T) is well-typed. Consider a computation (s,T,\u00d8,\u00d8) -. * (s ' ,T ' ,\u00d8,\u00d8) ow Then there is a strong \ncomputation '' '' (s,T,unit) -. * s (s,T ,unit) '' '' for some s '' and T suchthat s ' is an extension \nof s '' and T = T up to reordering. More generally, in the proof of this result we establish that if \n(s,T,\u00d8,\u00d8) -.* (s ' ,T ' ,O ' ,l ' )then there is a strong computation ow (s '' '' l ' (s,T,unit) -.* \ns ,T ,unit)where s ' is an extension of s '' , and T '' = T ' .origin(O ' ) up to reordering. We also \nadd some furtherconditionsinorder topermitaninductiveproof.  9. RelatedWork This paper is related to \nwork in several areas. There have been informal de.nitions about how STM or atomic blocks should be used \nby programmers (Section 9.1); Section 6 is our formaliza\u00adtion ofthese criteria.Therehave alsobeen severalformal \nsemantics foratomicblocks(Section9.2); ourstrong semantics issimilar to existing de.nitions, but our \nweaker semantics go further towards the details of actual implementations. We believe that they are the \n.rst to expose problems like those of Section 5. Finally, work on de.ning weak memory models inspired \nthe approach of consider\u00ading violation-freeprograms(Section9.3). 9.1 InformalDe.nitions Several papers \npropose adding atomic blocks to Java, C#, and similar languages, relyingonSTMimplementations that offer \nweak atomicity.The criteriafor using atomicblocks correctly are usually treated informally (Harris and \nFraser 2003; Adl-Tabatabai et al. 2006;Allen etal.2007).Forexample,HarrisandFraser(2003) provideaformof \nseparationrule,sayingthat each shared location should either be protected by a given mutex, or be accessed \nin atomic blocks, or be marked volatile. Our zombie example of Section 5.3 shows the problem with this \nstyle of de.nition: the locations accessed by a zombie transaction depend on the STM implementation, \nnot just on the source language. Our violation-freedom criterion tries to formalize this de.ni\u00adtion.Thisapproach \nmay alsobeapplicable totheFortresslanguage, whereAllenetal.(2007) require that updates toshared locations \nshouldalwaysbeperformed using anatomicexpression ,or tothe extensions toJavainAdl-Tabatabai etal.(2006) \nthatrequirethat allpotentiallyconcurrent accesses toshared memory areproperly guardedbyatomicregions \n.Of course,both languages includefea\u00adturesnotpresent in theAME calculus,so theremaybefurthersub\u00adtleties. \nThe Atomos language notably provides atomic blocks with strong atomicity (Carlstrom et al. 2006). It \nemploys a hardware implementation of transactions. 9.2 FormalDe.nitions Jagannathanetal.(2005)de.neTFJ,anextension \ntoFeatherweight Java(Igarashi etal.2001).They model asource languagewhere transactions include internalfork-joinparallelism,andthey \nexplore two implementations based on optimistic concurrency control and on two-phaselocking.Although \nstepsoftheexecutionsof transac\u00adtions can be interleaved, all TFJ memory accesses are made trans\u00adactionallyso \ntheproblemswearestudyingdonot occur. Liblit (2006) de.nes a detailed operational semantics for the LogTMhardware.Thissemanticsmodels \nthecreationandtermina\u00adtion ofthreads, the execution oftransactional and non-transactional memory accesses, \nthe interleaving of memory accesses within transactions, and the use of open-nested and closed-nested \ntrans\u00adactions. The semantics implements strong atomicity. A memory access isnotpermittedtoexecute if \nitwouldcon.ict withaconcur\u00adrent transaction; non-transacted operations are stalled until they may run \nwithout con.ict. Commit and roll-back are both modeled as single transitions. Like Jagannathan et al. \ns semantics, Liblit s semanticsdoesnot expose theproblems that wearestudying. Harris etal.(2005)provide \nan operational semanticsfor atomic blocks in Haskell. The semantics is split into three layers: a core \nlayer thatcontains transitionsfor theevaluationofpurefunctional code, a transactional layer thatcontainsSTM \noperationsandpure functional code, and an I/O layer that contains input/output oper\u00adations, pure functional \ncode, and atomic blocks of transactional code. In this semantics, complete transactions execute as single \nstepsintheI/Olayer,withoutinterleavingbetween transactionsor between transactedand non-transacted code. \nScott(2006) tackles another aspect of the subject: what is the sequential speci.cation of transactional \nmemory as a shared object inHerlihy andWing sformalism: e.g.,what valuesmay a transac\u00adtional read return, \nand under what circumstances must aparticular transaction commit successfully? Extending Scott s model \nto con\u00adsider non-transacted accesses to the same memory would provide anotherway of approachingtheproblemsofSection5. \nIncurrentwork,MooreandGrossman(2008) arestudying the operational semantics of transactions. Our studies \nwere started in\u00addependently, but we have had the opportunity to compare notes. While it appears that \nour high-level goals and our techniques are similar, there are a number of differences in our results. \nIn par\u00adticular, Moore and Grossman focus on traditional atomic blocks, with internal concurrencybut withnoyielding \nand noprovisionfor unprotectedfragmentsexcept atthe toplevel;theyhaveyet toana\u00adlyzeschemeswithoptimisticconcurrency.Despite \ntheseand other differences, theworksareconsistent in theirdemonstratingthevia\u00adbilityand valueofpreciseoperational \nsemanticsfor theconstructs considered. 9.3 MemoryModels AdveandHill(1990) introduced the ideaofproviding \nstrong se\u00admantics to programs that obey a set of formally speci.ed con\u00adstraints; our de.nition and use \nof violation-freedom is partly in\u00adspiredby theirapproach.Spearetal.(2007) independently identi\u00ad.edthe \nlinkbetweenthiswork and transactional memory,propos\u00ading a hierarchy of models for sharing data between \ntransactional and non-transactional code. In many languages the memory model must also consider pro\u00adgrams \nthat are not correctly synchronized so that, for example, a programmer cannot use data races to violate \nsafety and security properties ofa virtual machine.Grossman et al.(2006)have started to examine some \nof the questions that arise when extending this aspect of amemory modeltoprogramswrittenwithatomicblocks. \nBlundell et al. (2005) illustrate how a program may run to completion under a particular implementation \nof transactions, but will always deadlock under strong atomicity. Their example is not violation-free \nand not well-typed under a type system like that of Section 6.2. Furthermore, with some implementations \nof weak atomicity(HarrisandFraser2003), theexamplewillnever run to completion. This point is yet another \nillustration of how semantics with weak atomicity are tied to the details of particular implementations. \n  10. Conclusionand FurtherWork Thepresentexplorationoflanguageconstructsrepresents thefoun\u00addationforongoing \nwork onprogramming with transactional mem\u00adory. Understanding the semantics of the constructs and the \nrelated tradeoffs has proven both challenging and worthwhile. In partic\u00adular, the realization that weak \nsemantics like that of Section 8 do not correctlyexecuteallviolation-freeprograms indicates that im\u00adplementation \ntechniquesemployedinBartok-STM cannot be used withoutfurther languagerestrictionsorotherprecautions. \nWehavedemonstratedthatimposing astrong languagerestric\u00adtion,staticseparationof mutablestate, letsusgive \ntheprogrammer the attractive behavior of the strong semantics even with a very permissive implementation. \nIn hindsight, this fact may not appear surprising, but it is worth noting that several de.nitions of \nsepara\u00adtion arepossible(e.g.,(Harris and Fraser2003;Harris et al. 2005; Moore and Grossman 2008)), and \nthat they have substantially dif\u00adferent consequences; for instance, some de.nitions do not suf.ce in \nthe presence of zombies (see Section 9). Although separation is appealing in a functional setting, it \nis probably less palatable in an imperative languagewheremostdata isconsidered mutable,and would thereforerequiremarshaling \nacross theseparationboundary. These results suggest a number of directions for future work by developingthetypesystem(toallowmoreprograms \ntobecorrectly typed),thelanguageconstructs(perhaps todescribedata transfer betweenprotectedand unprotected \nmodes),or theSTMimplemen\u00adtation(perhaps tosupportmoreprogramswiththestrong seman\u00adtics).Thisexplorationhighlightsthebene.tsof \nco-designof these three aspects ofthe language and its implementation. We have also explored several \nalternative semantics. Clearly therearemany others.Someofthose that captureappealingimple\u00admentation strategies \nmay be worth studying further. Moreover, in\u00adcorporating some of the subtleties of relaxed memory models \nmay lead tofurtherproblemsand assumptions. Inaddition to thetypesysteminthispaper,wehavedeveloped and \nanalyzed atypesystemthat characterizes yielding behavior. With this type system, the caller of a function \nobtains static infor\u00admation on whether the function may yield and therefore commit. Combiningthe twotypesystems \nisstraightforward,andmaybeat\u00adtractive ifyielding and separationaregeneralized(so,forexample, yieldingmay \ncommitonlyapart of theheap). Our initial exploration of AME includes writing example pro\u00adgrams. At this \npoint, we have con.dence that the constructs are interesting and useful, and in any case we expect that \nsome of the ideas and results of our work will be of value whether or not par\u00adticular constructs are \nwidely adopted.Designing constructs andde\u00adsigninglanguagesaredistinct activities;furtherresearch should \nin\u00adforma languagedesignbased onAME. Acknowledgements We would like to thank Dan Grossman for interesting \ndiscussions onourwork,VirendraMarathefor identifyingtheoriginalformof the privatization problemduring \naninternshipatMicrosoft,Dave Detlefsforencouragingus tostudyit,andSimonPeyton-Jonesand Jean-PhilippeMartinforcommentsonearlierdraftsof \nthispaper. References Martin Abadi, Cormac Flanagan, and Stephen N. Freund. Types for safe locking: \nStatic race detection for Java. ACM Trans. Program. Lang. Syst.,28(2):207 255,2006. Ali-Reza Adl-Tabatabai, \nBrian T. Lewis, Vijay Menon, Brian R. Murphy, Bratin Saha, and Tatiana Shpeisman. Compiler and runtime \nsupport for ef.cient software transactional memory. In PLDI 06: Proc. 2006 ACM SIGPLAN Conference on \nProgramming Language Design and Implementation,pages26 37,2006. Sarita V. Adve and Mark D. Hill. Weak \nordering a new de.nition. SIGARCHComput.Archit.News,18(3a):2 14,1990. Atul Adya, Jon Howell, Marvin \nTheimer,William J. Bolosky, and John R. Douceur. Cooperative task management without manual stack manage\u00adment. \nIn Proc. 2002 USENIX Annual Technical Conference(USENIX\u00ad02),pages289 302,2002. Eric Allen, David Chase, \nJoe Hallett, Victor Luchangco, Jan-Willem Maessen, Sukyoung Ryu, Guy L. Steele Jr., and Sam Tobin-Hochstadt. \nTheFortresslanguage speci.cation, v1.0\u00df. Technical report,2007. ColinBlundell,E.ChristopherLewis, andMiloM.K.Martin.Deconstruct\u00ading \ntransactional semantics: The subtleties of atomicity. In Proc. 2005 Workshop onDuplicating,Deconstructing \nandDebunking,2005. Brian D. Carlstrom, Austen McDonald, Hassan Cha., JaeWoong Chung, Chi Cao Minh, Christos \nKozyrakis, and Kunle Olukotun. The Atomos transactional programming language. In PLDI 06: Proc. 2006 \nACM SIGPLAN Conference on Programming Language Design and Imple\u00admentation,pages1 13,2006. DavidDice,OriShalev,andNirShavit. \nTransactionallockingII. In Proc. ofthe20thInternationalSymposium onDistributedComputing(DISC 2006),pages194 \n208,2006. Dan Grossman, Jeremy Manson, and William Pugh. What do high-level memory models mean for transactions? \nIn MSPC 06: Proc. 2006 Workshop on Memory System Performance and Correctness,pages 62 69,2006. TimHarris \nandKeirFraser. Language supportforlightweight transactions. In OOPSLA 03: Proc. 18th Annual ACM SIGPLAN \nConference on Object-Oriented Programming, Systems, Languages, and Applications, pages388 402,2003. Tim \nHarris, Simon Marlow, Simon Peyton-Jones, and Maurice Herlihy. Composable memorytransactions.InPPoPP \n05:Proc.10thACMSIG-PLANSymposium onPrinciples andPractice ofParallelProgramming, pages48 60,2005. TimHarris,MarkPlesko,AvrahamShinnar, \nandDavidTarditi. Optimizing memory transactions. In PLDI 06: Proc. 2006 ACM SIGPLAN Con\u00adference on Programming \nLanguage Design and Implementation, pages 14 25,2006. Atsushi Igarashi, Benjamin C. Pierce, and Philip \nWadler. Featherweight Java: a minimal core calculus for Java and GJ. ACM Trans. Program. Lang.Syst.,23(3):396 \n450,2001. Michael Isard and Andrew Birrell. Automatic mutual exclusion. In Proc. 11thWorkshop onHotTopicsinOperatingSystems,2007. \nSuresh Jagannathan, Jan Vitek, Adam Welc, and Antony Hosking. A transactional object calculus. Science \nof Computer Programming, 57 (2):164 186,2005. Bradley C.Kuszmaul andCharlesE.Leiserson. Transactions \neverywhere. Technical report,2003. http://hdl.handle.net/1721.1/3692. BenLiblit. An operational semanticsforLogTM. \nTechnicalReport1571, U.Wisconsin Madison,2006. Version1.0. Jeremy Manson, Jason Baker, Antonio Cunei, \nSuresh Jagannathan, Marek Prochazka, Bin Xin, and Jan Vitek. Preemptible atomic regions for real-time \nJava. In Proceedings of the 26th IEEE Real-Time Systems Symposium(RTSS),2005a. Jeremy Manson, William \nPugh, and Sarita V. Adve. The Java memory model. In POPL 05: Proc. 32nd ACM SIGPLAN-SIGACT Symposium \nonPrinciples ofProgrammingLanguages,pages378 391,2005b. Katherine F. Moore and Dan Grossman. High-level \nsmall-step opera\u00adtional semantics for transactions. To appear, POPL 08: Proc. 35th ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages,2008. Kevin E. Moore, Jayaram Bobba, Michelle J. Moravan, \nMark D. Hill, and David A. Wood. LogTM: Log-based transactional memory. In Proc. 12th International Symposium \non High-Performance Computer Architecture,pages254 265.2006. MayurNaik,AlexAiken,andJohn Whaley. Effectivestaticracedetection \nfor Java. In PLDI 06: Proc. 2006 ACM SIGPLAN Conference on Programming Language Design and Implementation, \npages 308 319, 2006. Bratin Saha, Ali-Reza Adl-Tabatabai, Richard L. Hudson, Chi Cao Minh, and Benjamin \nHertzberg. McRT-STM: a high performance software transactional memory system for a multi-core runtime. \nIn PPoPP 06: Proc. Eleventh ACM SIGPLAN Symposium on Principles and Practice ofParallelProgramming,pages187 \n197,2006. MichaelL.Scott.Sequential speci.cationof transactional memory seman\u00adtics. In Proc. 1st ACM \nSIGPLAN Workshop on Languages, Compilers, andHardwareSupportforTransactionalComputing.2006. NirShavit \nandDanTouitou.Softwaretransactional memory.In Proc.14th AnnualACMSymposium onPrinciples ofDistributedComputing,pages \n204 213,1995. Tatiana Shpeisman, Vijay Menon, Ali-Reza Adl-Tabatabai, Steven Balen\u00adsiefer, Dan Grossman, \nRichard L. Hudson, Katherine F. Moore, and Bratin Saha. Enforcing isolation and ordering in STM. In PLDI \n07: Proc.2007ACMSIGPLANConference onProgrammingLanguageDe\u00adsign andImplementation,pages78 88,2007. Michael \nF. Spear, Virendra J. Marathe, Luke Dalessandro, and Michael L. Scott. Privatization techniques for software \ntransactional memory. Technical Report #915, Computer Science Department, University of Rochester,2007. \nNicholas Sterling. Warlock: A static data race analysis tool. In Proc. USENIXWinterTechnicalConference,1993. \nAdam Welc, Suresh Jagannathan, and Antony Hosking. Safe futures for Java.InOOPSLA 05:Proc.20thAnnualACMSIGPLANConferenceon \nObject-Oriented Programming, Systems, Languages, and Applications, pages439 453,2005.  \n\t\t\t", "proc_id": "1328438", "abstract": "<p>Software Transactional Memory (STM) is an attractive basis for the development of language features for concurrent programming. However, the semantics of these features can be delicate and problematic. In this paper we explore the tradeoffs between semantic simplicity, the viability of efficient implementation strategies, and the flexibilityof language constructs. Specifically, we develop semantics and type systems for the constructs of the Automatic Mutual Exclusion (AME) programming model; our results apply also to other constructs, such as atomic blocks. With this semantics as a point of reference, we study several implementation strategies. We model STM systems that use in-place update, optimistic concurrency, lazy conflict detection, and roll-back. These strategies are correct only under non-trivial assumptions that we identify and analyze. One important source of errors is that some efficient implementations create dangerous 'zombie' computations where a transaction keeps running after experiencing a conflict; the assumptions confine the effects of these computations.</p>", "authors": [{"name": "Mart&#237;n Abadi", "author_profile_id": "81100547147", "affiliation": "Microsoft Research, Silicon Valley", "person_id": "P429232", "email_address": "", "orcid_id": ""}, {"name": "Andrew Birrell", "author_profile_id": "81100124997", "affiliation": "Microsoft Research, Silicon Valley", "person_id": "P17731", "email_address": "", "orcid_id": ""}, {"name": "Tim Harris", "author_profile_id": "81406593835", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "PP43116348", "email_address": "", "orcid_id": ""}, {"name": "Michael Isard", "author_profile_id": "81100309298", "affiliation": "Microsoft Research, Silicon Valley", "person_id": "PP43123925", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1328438.1328449", "year": "2008", "article_id": "1328449", "conference": "POPL", "title": "Semantics of transactional memory and automatic mutual exclusion", "url": "http://dl.acm.org/citation.cfm?id=1328449"}