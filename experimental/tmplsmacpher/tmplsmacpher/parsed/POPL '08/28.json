{"article_publication_date": "01-07-2008", "fulltext": "\n Extensible Encoding of Type Hierarchies HamedSeiiedAlavi Seth Gilbert Rachid Guerraoui IC, EPFL, Lausanne, \nSwitzerland IC, EPFL, Lausanne, Switzerland IC, EPFL, Lausanne, Switzerland hamed.alavi@ep..ch seth.gilbert@ep..ch \nrachid.guerraoui@ep..ch Abstract The subtyping test consists of checking whether a type t is a descendant \nof a type r (Agrawal et al. 1989). We study how to perform such a test ef.ciently, assuming a dynamic \nhierarchy when new types are inserted at run-time. The goal is to achieve time and space ef.ciency, even \nas new types are inserted. We propose an extensible scheme, named ESE, that ensures (1) ef.cient insertion \nof new types, (2) ef.cient subtyping tests, and (3) small space usage. On the one hand ESE provides comparable \ntest times to the most ef.cient existing static schemes (e.g., Zibin et al. (2001)). On the other hand, \nESE has comparable insertion times to the most ef.cient existing dynamic scheme (Baehni et al. 2007), \nwhile ESE outperforms it by a factor of 2-3 times in terms of space usage. Categories and Subject Descriptors \nD.3.3 [PROGRAMMING LANGUAGES]: Language Constructs and Features General Terms Languages, Algorithms Keywords \nSubtyping Test, Dynamic Loading 1. Introduction One of the most frequent operations in object-oriented \nprograms is the subtyping test: Givenanobject O of a type t,is O also an instance of a type r i.e is \nt a subtype of r? Such tests, also known as type inclusion tests, are usually in\u00advoked by explicit requests \nof programmers when they use linguis\u00adtic constructs like instanceof (Java) (Gosling et al. 2005), is \n(C#) (Hejlsberg et al. 2001) or iskindof (SmallTalk) (Goldberg et al. 1983). They are also sometimes \ninserted by the compiler in the contexts of type casting, array casts and exception handling (Gosling \net al. 2005; Hejlsberg et al. 2001). Since the cost of sub\u00adtyping tests has a signi.cant effect on the \noverall performance of systems, considerable attention has been paid to optimizing the test. Typically, \nthe main challenge has been to preprocess the type hier\u00adarchy and producing a data structure that encodes \nthe subtyping relationships in an ef.cient manner. The ef.ciency here is typically de.ned in terms of \ntest time and required memory space. The most obvious encoding scheme is a binary matrix (BM) in which \nM[i, j]=1 iff i is a subtype of j; this results in a constant Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 08, January 7 12, 2008, San Francisco, \nCalifornia, USA. Copyright c . 2008 ACM 978-1-59593-689-9/08/0001. . . $5.00 O(1) test time, but requires \nO(n 2) space, which is considerably big in large type hierarchies (e.g. JDK 1.3 with around 5500 types \ntakes 3.8MB (Zibin et al. 2001)). If the type hierarchy is simply encoded as a tree, requiring O(n) space, \nthe worst-case time for a test may be O(n). More elegant schemes have improved this trade-off be\u00adtween \ntime and space complexity. Relative numbering (Schubert et al. 1983) guarantees both constant test time \nand minimal encoding size of log(n) bits per type for single-inheritance type hierarchies. In the case \nof multiple-inheritance type hierarchies, PQE (Zibin et al. 2001) provides constant test time and, in \ncomparison to other algorithms, provides the smallest encoding size (to the best of our knowledge). Maybe \nsurprisingly, relatively little attention has been paid to the handling of dynamic type loading, i.e. \nthe ability to add new types at run-time in the hierarchy. (See Baehni et al. (2007) for the only exception \nwe know of, and which we discuss of length in Section 6.) Dynamic type loading is a key requirement of \nmodern systems (Ajmani et al. 2006) and is promoted in Java (Gosling et al. 2005) and .Net (Microsoft \n2005). In fact, even more traditional languages like C++ and SmallTalk support dynamic (or incremen\u00adtal) \nlinking (Stroustrup 2004; Goldberg et al. 1983). One way to perform subtyping tests is to use traditional \nstatic solutions and re\u00adencode the hierarchy for each new type insertion. Clearly, this leads to slow \ninsertion time. In this paper we consider the cost of type in\u00adsertions as an important metric in devising \nthe subtyping test. In short, this paper proposes a new encoding algorithm that performs insertions ef.ciently \nwhile preserving the performance of the best known static schemes in terms of test time and encoding \nsize. We focus on designing an encoding algorithm that works well for real-world type hierarchies (e.g. \nJDK), as validated by experimental evidences. (See Section 6.) One reason why inserting new types is \nexpensive is that most algorithms need to update the encoding of old types whenever a new type is inserted \n(Zibin et al. 2001, 2002; Cohen 1991; Vitek et al. 1997). This modi.cation takes considerable time and \nthus slows down the overall speed of the system signi.cantly. For example PQE (Zibin et al. 2001) which \noutperforms all the other subtyping algorithms in terms of encoding size and query time, requires the \nreconstruction of almost the entire encoding for each newly added type. PQE partitions the type hierarchy \ninto a set of types called slices using a sophisticated algorithm. Since this algorithm requires the \nwhole type hierarchy as input, it recomputes the slicing for each newly inserted type, which is quite \ntime consuming for large type hierarchies (e.g. JDK 1.3: 113 msec). This is so in a centralized setting. \nIn distributed settings the problem becomes even more drastic since any modi.cation to the encoding has \nto be broadcast over the network to maintain the consistency, i.e. to ensure a unique encoding throughout \nthe distributed system. Such mechanism is extremely costly as it involves reaching agreement in a distributed \nsetting (Lynch 1996). The reason why traditional encoding schemes require recon.g\u00aduration upon the addition \nof new types is actually easy to see. In these schemes, the encoding of a type depends on its sub\u00adtypes \n(Zibin et al. 2001, 2002; Cohen 1991; Vitek et al. 1997) and this requires modifying the old encoding \nupon insertion of new types. The solution proposed by Baehni et al. (2007), called DST, avoids this recon.guration \nby encoding each type based on its su\u00adpertypes rather than its subtypes. Like PQE, DST partitions the \nhi\u00aderarchy into a set of slices. The number of slices is the major factor in.uencing the required memory \nspace, i.e. the number of slices used directly impacts the size of the memory required. The prob\u00adlem \nwith DST is in (1) its partitioning algorithm, which does not provide the optimal slicing and (2) its \ninsertion algorithm which generates too many new slices upon insertion of new types. Our ESE solution \nimproves DST in terms of space usage. More pre\u00adcisely, ESE partitions a hierarchy into fewer slices than \nDST, re\u00adquiring less space. On the other hand, upon addition of new types, ESE s insertion algorithm \ncreates new slices less often than DST. This fact further underlines the difference between ESE and DST \nin terms of space usage. Time and space ef.ciency. Our ESE solution provides compara\u00adble performance \nwith the most ef.cient static subtyping methods we know of, with respect to the test time and encoding \nsize. This is so even after the insertion of new types (in contrast to DST (Baehni et al. 2007)). Extensibility. \nESE does not require any modi.cation in the exist\u00ading encoding when new types are inserted. Our performance \nanalysis on standard Java type hierarchies (e.g. JDK 1.5, java.lang) shows that: ESE performs subtyping \ntests in constant time, which is com\u00adparable to the most ef.cient approach we know of (Zibin et al. 2001). \n ESE has a smaller encoding size than DST (2-3 times), which is the most ef.cient extensible encoding \nalgorithm we know about. Moreover, after a sequence of insertions, the difference in size between ESE \ns and DST s encoding becomes even more pronounced. More precisely, the encoding size in DST grows 3 times \nfaster than ESE with the number of insertions at run-time.  ESE is an extensible algorithm that ensures \nvery fast insertion in centralized settings and minimum bandwidth utilization in distributed settings, \ncompared to non-extensible algorithms like PQE.  Outline. The reminder of this paper is organized as \nfollows. Sec\u00adtion 2 presents some basic de.nitions related to type hierarchies and Section 3 introduces \nand formally de.nes the problem of exten\u00adsible encoding. Section 4 describes our encoding algorithm. \nSec\u00adtion 5 shows how we implement our algorithm ef.ciently. Section 6 evaluates the performance of our \nscheme. Section 7 summarizes the related works and .nally Section 8 draws some conclusions. 2. Model \nThis section (1) reviews the basic subtyping model that has been traditionally used in the literature \n(Sections 2.1, 2.2) as well as (2) introduces some new concepts which we will use in describing our extensible \nencoding scheme (Section 2.3). 2.1 Type hierarchy A type hierarchy H =(T,R)consists of two components: \na set T of types, and a relation R on pairs of types. The relation R is referred to as the subtyping \nrelation and is re.exive, transitive and anti-symmetric. We often use the notion .as follows: ti .tj \niff R(ti,tj); thisimpliesthat ti is subtype of tj. 2.2 Relations In a type hierarchy H =(T,R): Descendant. \nA type tj is a descendant of a type ti if R(tj,ti) (i.e. tj is a subtype of ti). D(ti) denotes the set \nof all the descendants of ti in H. It is formally de.ned as: D(ti)={tj .T|tj .ti} Ancestor. A type tj \nis an ancestor of a type ti if R(ti,tj)(i.e. tj is a super-type of ti). A(ti)denotes all the ancestors \nof ti in H. It is formally de.ned as: A(ti)={tj .T|ti .tj } Note that each type tis parent and ancestor \nof itself. Child. A type tj is a child of a type ti if (1) R(tj,ti)(2) i= j (3) for any k /tj)or tk .D(. \n=i,j, either tk .A(/ti) Parent. A type tj is a parent of a type ti if tj has ti as a child.  Root. \nA type ti is a root of H if A(ti)=ti.  Leaf. A type ti is a leaf of H if D(ti)=tj.  2.3 Slicing In \nthis section we recall the notion of straight slicing (Baehni et al. 2007). Slice. A slice sof a type \nhierarchy (T,R)is an ordered subset of types in T like [ti;tj;...;tk]such that {ti,tj,...,tk}.T. For \nexample, [B;A;C] is a slice of the type hierarchy of Figure 1. Notice that, we could change the ordering \n(e.g. [A;B;C]) and have another slice.  Slicing. A slicing S of a type hierarchy (T,R) is a parti\u00adtion \nof types in T in which each set in the partition is or\u00addered. For example, considering the type hierarchy \nof Figure 1, {[B;A;C],[E;F;J;G;k],[H;I;D]}is a slicing. Notice that {[A;B;D],[E]}and {[A;B;C;E;F;G;H;I],[J;K;I;A]} \n are not slicing because the .rst one does not cover all the types and in the second one A occurs two \ntimes.  Straight Slice. A straight slice s of a type hierarchy H = (T,R)is a slice of H such that for \nany type ti . T, all the supertypes of twithin sare consecutive in s. Formally, a slice s=[t1;t2;...;tn]is \nstraight if:  .t.T,1=a<b<c=n :ta,tc .A(t).tb .A(t) Figure 1. A straight slicing of a type hierarchy \nWhich is equivalent to: .1= a<b<c = n :D(ta)n D(tc). D(tb) Accordingly, a slicing is straight if all \nits slices are straight. A type hierarchy might have more than one straight slicing. Figure 1 depicts \na type hierarchy and one of its straight slicings. Arrows are directed from a child to its parent. In \nthis .gure, slice [B;A;C] for example is straight. Indeed, for every type . T, all of its ancestors in \nthis slice are consecutive. For instance the ancestors of C (C, A) and the ancestors of J within this \nslice (A, B, C) are consecutive. Considering the type hierarchy of Figure 1 a slice like [D;B;A;C] is \nnot straight because the ancestors of I in this slice (A, C, D) are not consecutive.  3. Subtype Encoding \nIn this section we de.ne the problem we address in this paper: providing an extensible subtype encoding. \nEncoding algorithm. Given a type hierarchy H =(T,R),an encoding algorithm E =(V,f,R * ) consists of three \ncompo\u00adnents: (1) a value domain V (often referred to as the encod\u00ading ), (2) a function f :T . V that \nmaps types to values, and (3) a relation R * between pairs of values, such that for vi =f(ti)and vj =f(tj), \nR * (vi,vj)iff R(ti,tj). Considering the above de.ned model, encoding size is log|V | i.e. the size of \nV ,and the subtyping test time corresponds to the time needed to evaluate R * (vi,vj). A trivial encoding \nalgorithm maps each type t . T to an identi.er and the list of its super-types. Calculating R * (vi,vj \n)consists in searching in the list of super\u00adtypes of ti, which costs O(n)where n =|T|. We are basically \ninterested in encoding algorithms where (1) the relation R * can be evaluated ef.ciently, as in constant-time, \nand (2) provides a minimal encoding size. Extension. Roughly speaking, a type hierarchy H+ =(T+,R+)is \nan extension of H =(T,R) if H+ is the outcome of insert\u00ading some new types into H. Formally, H+ is an \nextension of H if: T . T+ .ti,tj . T :R(ti,tj). R+(ti,tj) .ti . T,tj . T+ :R+(ti,tj). tj . T The third \ncondition captures the fact that newly inserted types cannot be super-types of existing ones. Notice \nthat the notions of encoding algorithm and extension have been informally used in the literature. Using \nthese notions, we introduce and formally de.ne the concept of extensible encoding algorithm in the following. \nExtensible encoding algorithm. We say that an encoding al\u00adgorithm is extensible if the value mapped to \nany type t re\u00admains unchanged after the insertion of new types. More pre\u00adcisely, given a type hierarchy \nH =(T,R), its encoding al\u00adgorithm E =(V,f,R * ) is extensible if for any extension of H like H+ =(T+,R+), \nthere exists an encoding algorithm E+ =(V +,f+,R *+) such that: .t . T :f(t)=f+(t) We focus on providing \nan extensible encoding algorithm which provides a test time and encoding size comparable to the most \nef.cient non-extensible algorithms, even after the insertion of new types at run-time. Describing an \nencoding algorithm consists of describing how to implement the following data structure: 1. Query(ti,tj) \n Input: ti,tj . T.  Function: check whether ti is subtype of tj i.e. evaluate R(ti,tj )=R * (f(ti),f(tj)). \n 2. Insert(ti,T1) Input: ti . T, T1 . T.  Function: insert ti in H as child of all types like tj such \nthat tj . T1 i.e. calculate E+ when new type t and its corresponding relations are inserted.  The .rst \noperation is well-known as the subtyping test, whereas the second captures the ability to include new \ntypes at run-time.  4. Extensible Subtyping Encoding: ESE In the following, .rst we introduce our ESE \nencoding scheme (which de.nes the value domain V ) in Section 4.1. Section 4.2 shows how to perform the \nsubtyping test (i.e. how to calculate R *) using this scheme. Then in Section 4.3 we explain how to construct \nthe initial encoding (which completes the de.nition of function f). The insertion algorithm is given \nin Section 4.4. The basic idea is the following. We .rst provide a straight slicing of the type hierarchy. \nThen we assign an identi.er to each type cor\u00adresponding to its position in a slice, and to its position \nwith respect to its ancestors in each slice. Testing if t is subtype of r consists of comparing the identi.er \nof r with identi.ers of ancestors of t (which de.ne an interval). We insert new types in such a way that \nwe maintain the straightness of the slicing whenever possible. It is worth mentioning that, in cases \nwhere the ancestors of the new type t are not consecutive in a slice si, by de.nition, si is not straight \nwith respect to t. Since our insertion algorithm does not change the encoding of the old types, we might \nend up in these cases with slices that are not straight. We evaluate the effect of such cases on the \naverage test time in the Section 6. 4.1 Encoding We explain here how we use the notion of straight slicing \nto encode a type hierarchy. Speci.cally, we de.ne the value domain V (the encoding ) and how to encode \nH, given a slicing S. Considering a type hierarchy H =(T,R), and a slicing S of H, we encode each type \nt . T with the following parameters: 1. SID(t). The identi.er of the slice to which t belongs. 2. ID(t). \nAn integer indicating the position of t within its slice. 3. Ii(t). For each slice si . S, Ii(t)represents \nthe set of intervals of ancestors of t in si. To be more accurate, we specify an interval I with two \nintegers I.beginning and I.end for the beginning and the end of I respectively.  For example in Figure \n1, according to the given straight slic\u00ading ([B;A;C][E;F;J;G;K][H;I;D]), the type J is encoded by SID(J)=1, \nID(J)=2, I0(J)=[0,2], I1(J)=[1,3] and I2(J)=[-], and the type C is encoded by SID(C)=0, ID(C)=2, I0(C)=[1,2],I1(C)=[-]and \nI2(C)=[-]. Since the given slicing is straight, the ancestors of each type (like J) are consecutive in \neach slice (like s0) and so they are repre\u00adsented by only one interval like ([0,2]). In general, as long \nas the slicing is straight, Ii(t)(i.e. set of intervals of ancestors of t in slice si) includes only \none interval. In the case of single inheritance type hierarchies, we insert new types such that the slicing \nalways re\u00admains straight. This is not the case for multiple inheritance, as the insertion algorithm in \nsome special cases violates the straightness of slices, resulting in certain types having more than one \ninterval as part of their encoding. 4.2 Subtyping test In order to test whether a given type t is a \nsubtype of another type r, we simply check the ancestors of t in r s slice, which are de.ned by one or \nmore intervals. That is, if SID(r)= i, the subtyping test consists in checking whether or not ID(r)is \nwithin one of the intervals Ii(t). Figure 2 shows how we implement the subtyping test more precisely. \n1: function QUERY(t,r) {Check if t is subtype of r} 2: i . SID(r) 3: for all I . Ii(t) do 4: if I.beginning \n= ID(r) = I.end then 5: return true 6: end if 7: end for 8: return false 9: end Figure 2. Subtyping test. \nFor example in the type hierarchy given by Figure 1, it is observable that J is subtype of C because \nSID(C)=0 and I0(J).beginning =0= ID(C)=2= I0(J).end =2. 4.3 Preprocessing (encoding initialization) \nWe now describe how to preprocess the type hierarchy in order to construct a straight slicing that results \nin an ef.cient encoding. Consider the trivial straight slicing in which each slice contains exactly one \ntype. Notice that this slicing effectively corresponds to the trivial encoding algorithm, and results \nin n = |T | slices. Our goal is to devise a straight slicing with a minimal number of slices. 4.3.1 Constructing \nthe straight slicing Our encoding initialization algorithm goes as follows (Figure 3): 1. Sort all the \ntypes by their number of descendants, such that the type with the maximum number of descendants is the \nhead of the list. 2. Put the head of the list in the .rst slice. 3. Iterate over the list, and insert \neach type within the .rst position such that it maintains a straight slice. If such a slice does not \nexist, simply create a new one and put that type within the new slice. (An ef.cient method to check whether \nor not inserting a type in a slice violates the straightness of that slice is given in Section 5.)  \nIf we consider the type hierarchy of Figure 1, for instance, after ordering types by their number of \ndescendants we end up with the ordered list L = {A, C, B, G, D, F, E, H, I, J, K}. Initially, we put \nA in a slice leading to the slicing S = {[A]}. Putting C right before A does not violate the straightness \nof its slice and thus S ={[C;A]}. B and A are ancestors of B and C is not ancestor of B, therefore [B;C;A]is \nnot straight; for the same reason [C;B;A] is not straight; so we put B right after A yielding S ={[C;A;B]}. \nG is subtype of C and A, and can be inserted right before C.The next type in the list is D and putting \nD anywhere in this slice violates its straightness. So according to the algorithm we create a new slice \nand put D within that (S = {[G;C;A;B][D]}). Continuing this process we will end up with a straight slicing \nS = {[K;G;C;A;B;F ][J;H;E;D;I]} whichhas onlytwo slices. 1: procedure STRAIGHTSLICING(H) {Generates a \nstraight slicing of H} 2: L . sort(H) {Sort types by number of descendants} 3: Put(L[0],Slices[0], 0) \n{Put the 1st type within the 1st slice} 4: numberOfSlices . 1 5: for i . 1 to sizeOf(L) do 6: for j . \n0 to numberOfSlices - 1 do 7: for k . 0 to sizeOf(Slices[j]) do 8: if STRAIGHT (Slices[j],L[i],k) then \n9: Put(L[i],Slices[j],k) 10: Goto 5 {Goto the next type in the list} 11: end if 12: end for 13: end for \n14: Put(L[i],Slices[numberOfSlices], 0) {Put in new slice} 15: numberOfSlices . numberOfSlices +1 16: \nend for 17: end Figure 3. Initialization (creating a straight slicing). Precisely because the algorithm \nensures the straightness of all the slices before adding a new type, one can immediately conclude that \nthe generated slicing is always straight. On the other hand, the order in which types are inserted into \nthe slicing is the key point that limits the number of generated slices in this algorithm. Roughly speaking, \nthe only constraint that might force our algorithm to create a new slice is a subtyping relation between \ntwo types. For instance, considering the example given in Figure 1, the reason why the algorithm has \nto create a new slice for D is that B, C,and D are all subtypes of A. Thus, after serving the types which \nhave lots of descendants, it would be less likely for the algorithm to need new slices. 4.3.2 Identi.er \nreservation ESE reserves some places (identi.ers) in each slice for run-time insertions. This list of \nreserved identi.ers (called reservedIDs)is initialized after the straight slicing construction and will \nbe used by our insertion algorithm. Section 5 illustrates how we provide such a list. Roughly speaking, \nthe idea is to reserve some places in each slice, for which the insertion of new types does not violate \nthe straightness of slicing. According to our reservation algorithm (given in Section 5), each reserved \nplace is surrounded by two existing types (i.e. reserved places are not consecutive), the number of reserved \nplaces cannot be more than the number of existing types. 4.3.3 Identi.er assignment Using the straight \nslicing constructed with one of the algorithms proposed in Sections 4.3.1 and 4.3.2, we assign to each \ntype t two identi.ers (ID(t), SID(t)), as well as its interval of ancestors for each slice s (Is(t)). \nEach slice s is assigned a unique integer i as the identi.er. If type t is placed within si, SID(t)= \ni. ID(t) speci.es the position of t within si. The identi.er of the types of a slice might not be consecutive \nas ESE reserves some identi.ers in each slice for run-time insertions. The identi.ers of ancestors of \nt in each slice si specify the Ii(t).  4.4 Insertion In this section we illustrate how to insert a new \ntype in the hierarchy at run-time. Considering the fact that a new type t added at run-time cannot be \nancestor of any existing types, inserting a new type in a slice be\u00adtween two ancestors of an existing \ntype would violate the straight\u00adness of the slicing. Thus we either (1) use the reserved list for new \ntypes (reservedIDs) (2) append it at the head or tail of a slice, or (3) create a new slice. On the other \nhand, in order to place ancestors of t within a minimal number of intervals, it would be preferable to \nput t adjacent to one of its parents. Our insertion algorithm goes as following: 1. If there exists a \nreserved place adjacent to one of the parents of t,insert t there, and remove that place from the list \nof re\u00adserved places. (Notice that each slice has its own list of reserved places.) 2. Otherwise, if \na parent of t is at the head (tail) of a slice si, put t within si right before (after) its parent. \n3. Otherwise, create a new slice and put t within it. 4. Set the parameters of t accordingly (e.g. ID(t), \nSID(t),etc.).  Figure 4 illustrates the insertion of a new type N as subtype of H and I into the type \nhierarchy of Figure 1. Since H (one of the parents of N) is the head of its slice according to the insertion \nalgorithm we put N right before H. It is easily observable that not only the encoding of all the old \ntypes remains unchanged but also, in this case, the slicing is still straight with respect to the newly \nadded type (i.e. all the ancestors of the new type are consecutive in all the slices). Figure 4. Inserting \na new type N in a type hierarchy Figure 5 depicts the protocol for inserting a new type in a given type \nhierarchy. Notice that, in speci.c cases, after the insertion of a new type, the resulting slicing might \nbe non-straight. This is especially true when the newly added type is subtype of two types of a slice \nsi whose ancestors are not consecutive in si. For example, in Figure 6, inserting N as subtype of E, \nK violates the straightness of the slice [N;E;F;J;G;K], because ancestors of N in this slice (N, E, G, \nK) are not consecutive.  5. Detecting a Straight Slicing This section illustrates (1) how we test if \nthe straightness of a slice is maintained after the insertion of a type and (2) how we provide the list \nof reserved identi.ers for run-time insertions. The .rst one is needed to ensure the straightness of \nslicing during the initialization process at compile-time (Figure 3) and the second one ensures the same \nproperty upon insertion of new types at run-time (Figure 5). 5.1 Straightness maintenance As shown in \nSection 4.3.1, our initialization algorithm iteratively picks a type t and puts it in an existing or \na new slice as we 1: procedure INSERT(t,Tl) {Insert t in a given type hierarchy as child of all the types \nin T I} 2: for all si . S do 3: for all r . Tl do 4: Ii(t) . Ii(t) . Ii(r) 5: end for 6: end for 7: createNewSlice \n. true 8: for all r . Tl do {S is the slicing of the type hierarchy} 9: if isHead(r) or reservedIDs(SID(r),ID(r) \n- 1) then 10: createNewSlice . false 11: SID(t) . SID(r) 12: ID(t) . ID(r) - 1 13: i . SID(t) 14: Ii(t) \n. Ii(t) . [ID(t),ID(r)] 15: break 16: end if 17: if isTail(r) or reservedIDs(SID(r),ID(r)+1) then 18: \ncreateNewSlice . false 19: SID(t) . SID(r) 20: ID(t) . ID(r)+1 21: i . SID(t) 22: Ii(t) . Ii(t) . [ID(r),ID(t)] \n23: break 24: end if 25: end for 26: if createNewSlice then 27: SID(t) . newSliceID 28: ID(t) . 0 29: \ni . SID(t) 30: Ii(t) . [0, 1] 31: end if 32: if ID(t) . reservedID(SID(t)) then 33: reservedID(SID(t)) \n. reservedID(SID(t)) - ID(t) 34: end if 35: end Figure 5. Inserting a new type in a type hierarchy. \nFigure 6. Inserting a new type N in a type hierarchy discuss below. It puts t in an existing straight \nslice s if this insertion maintains the straightness of s. This section presents an ef.cient algorithm \nto check this constraint. More precisely, for a type t and a straight slice s, our algorithm .nds the \n.rst place in s such that insertion of t at that place maintains the straightness of s.This algorithm \nperforms the following operation: Search(r, s) Input: a type r .T , a straight slice s =[t1;t2;...;tn]. \n Output: the .rst position i such that sI=[t1;t2;...;ti;r;ti+1;...;tn]is straight, if any. Assuming that \ns =[t1;t2;...;tn]is a straight slice by de.nition we have: .a, b, c .{1..n},a<c<b :D(ta)nD(tb).D(tc) \nIn order to check if sI=[t1;t2;...;ti;r;ti+1;...;tn]is straight we have to ensure three conditions: (1) \n.a, b .{1..n},i<a<b :D(r)nD(tb).D(ta) (2) .a, b .{1..n},b<a =i :D(r)nD(tb).D(ta) (3) .a, b .{1..n},a \n=i<b :D(ta)nD(tb).D(r)  A trivial algorithm which checks all the above conditions takes O(n 2)subset \ntests (i.e. considering two sets A, B to test if A .B), for each position i, leading to an overall O(n \n3)number of tests to search the entire slice s. In the following we present a method to perform the search \nin O(n 2). In fact, the idea is to remove the redundant tests. Observe .rst that, independently of the \nposition i, the following set of conditions includes those in (1) and (2). (4) .a, b .{1..n}:D(r)nD(tb).D(ta) \nClearly, (1) and (2) can be checked in O(n 2)number of tests for all the positions i (i.e .i .{1..n}). \nOn the other hand it is easy to see that condition (3) is reducible to: (5) D(ti)nD(ti+1).D(r) This is \ninduced by the straightness of s since: .a, b .{1..n},a =i<b :D(ta)nD(tb).D(ti),and .a, b .{1..n},a<i \n+1=b :D(ta)nD(tb).D(ti+1) which yields: .a, b .{1..n},a =i<b :D(ta)nD(tb).D(ti)nD(ti+1) And thus knowing \n(5) we have: .a, b .{1..n},a =i<b :D(ta)nD(tb).D(r)(i.e. (3)) Checking condition (5) rather than (3) \ntakes O(1)tests. Using the above mentioned facts, our algorithm performs search(r, s =[t1;...;tn]) as \nfollows: 1. Perform all the tests in (4), and generate a two dimensional array A[n][n]such that A[a, \nb]=1iff D(r)nD(tb).D(ta).  2. List all the positions like i satisfying (1) and (2). Notice that the \nanswer to all the tests in (1) and (2) are available in A.  3. Return the .rst i in the list that satis.es \n(5).   5.2 Reserved identi.ers After constructing the straight slicing we put a place P of a slice \ns =[t1;t2;...;tn]in the reserved list if: D(tP -1)nD(tP )=\u00d8 If P is a reserved place, then ID(tP )= ID(tP \n-1 +2).As illustrated in Section 4.4, we insert a new type r in P if r has tP -1 or tP as a parent. Considering \nthe facts that r is an ancestor of itself and we insert r beside one of its parents in s, if the ancestors \nof r are consecutive in s before inserting r, these ancestors remain consecutive after this insertion \n(i.e. s remains straight with respect to r). In the following we show that this is also the case for \nexisting types. More precisely, we show that if the ancestors of an existing type u are consecutive in \ns, the insertion of r in P does not separate them (i.e. s remains straight with respect to the existing \ntypes). Suppose by contradiction that the insertion of r in P separates some consecutive ancestors of \nu.Since r is placed between tp-1 and tp, u has both tp-1 and tp as its ancestors which contradicts with \nour assumption that D(tP -1)nD(tP )=\u00d8.  6. Performance Analysis In this section we analyze the performance \nof our algorithm in static and dynamic settings. In static settings, we consider the tradi\u00adtional metrics \nof subtyping test time and encoding size. In dynamic settings, we also consider the cost of insertions. \nWe examine the performance of our algorithm in the context of 13 commonly used type-hierarchies, and \nprovide experimental data to support our ef.\u00adciency claims. We compare our algorithm with two commonly \nused schemes: PQE, the fastest (to our knowledge) in static hierarchies and DST, one of the only schemes \ndesigned for dynamic type hierarchies. The conclusions we draw are as follows: All three protocols, \nPQE, DST, and ESE have roughly the same subtyping test time(see Table 2).  Among extensible schemes, \nESE has the smallest encoding size (see Table 3). Moreover, after a sequence of insertions, the difference \nis size between ESE s and DST s encoding be\u00adcome even more pronounced (see Figure 9). (By contrast, non\u00adextensible \nPQE has a smaller encoding size than ESE.)  The running time for an insertion for ESE is only slightly \nslower than for DST, and much faster than for (non-extensible) PQE.  We thus conclude that ESE provides \na better trade-off between the encoding size and insertion time, while maintaining a near-optimal subtype \ntest time. All experiments we refer to were obtained from Java implemen\u00adtations of ESE, PQE and DST1 \nusing an Intel Pentium 4 2.4GHz with 1GB RAM on a Fedora 2.6 machine. We consider the type hierarchies \nof standard Java packages including java.io, java.lang, Java EE 5, JDK 1.1.8, JDK 1.2.2, JDK 1.3.1, JDK \n1.4.2, and JDK 1.5.0. All the presented values are averaged over 10000 measure\u00adments. We generate subtyping \ntests randomly (in a uniform manner over the set of types). The types to be inserted are generated ran\u00addomly \nbut with respect to the statistical analysis made by Zibin et al. (2001), as recalled in Table 1. This \ntable shows some topologi\u00adcal properties of 13 type hierarchies, including the number of types, the average \nnumber of parents and the average number of ancestors for each hierarchy. 6.1 Subtyping test time Worst \ncase. In a static setting, each test takes O(1)steps. Since all the slices are straight, all the ancestors \nof a type t are consec\u00adutive. Then a subtyping test consists in checking one interval. In a dynamic setting, \nchecking whether a type t is subtype of a type r 1 For this algorithm we use its open source code at: \nhttp://lpd.epfl.ch/baehni/dst.tgz Hierarchy n |P |/n |A|/n IDL 66 0.98 3.83 JDK 1.1 225 1.04 3.17 Laure \n295 1.07 8.13 ED 434 1.66 7.99 LOV 436 1.71 8.50 Unidraw 613 0.78 3.02 Cecil 932 1.21 6.47 Geode 1,318 \n1.89 13.99 JDK 1.18 1,704 1.10 4.35 Self 1,801 1.02 29.89 Eiffel4 1,999 1.28 8.78 JDK 1.22 4,339 1.19 \n4.37 JDK 1.30 5,438 1.17 4.37  Table 1. Topological properties of some hierarchies. n: number of types, \n|P |/n: average number of parents, |A|/n: average number of ancestors (Zibin et al. 2001). takes O(|parents(t)|)steps, \nsince our insertion algorithm is such that, in some cases, the ancestors of a newly inserted type t are \nseparated into |parents(t)| intervals. Experiments. The results given in Table 2 compare the test time \nof ESE with PQE and DST (1) in a static setting and (2) after the insertion of some randomly chosen new \ntypes (we add to each hier\u00adarchy 10%of its size). In static settings, ESE performs a subtyping test slower \nthan PQE but faster than DST. For the dynamic case, as Table 2 conveys, ESE like PQE and DST maintains \nits ef.ciency after the addition of new types. Type Static Dynamic hierarchy ESE PQE DST ESE PQE DST \njava.lang 12 10 13 12 10 13 java.io 12 10 13 12 10 13 java EE 5 12 10 13 13 10 13 JDK 1.1.8 13 11 13 \n13 11 14 JDK 1.2.2 13 11 14 14 11 14 JDK 1.3.1 13 11 13 13 11 14 JDK 1.4.2 13 11 14 14 11 14 JDK 1.5.2 \n13 11 14 14 12 14 Table 2. Subtyping test time in micro second. According to Table 1, and the analysis \nof Zibin et al. (2001), the average number of parents is no more than 1.89; also the number of types \ninserted at run-time is usually small compared to the entire hierarchy, and so the situation in which \nthe resulting slicing is not straight happens rarely. For example, after the insertion of 500 new types \ninto the type hierarchy of JDK 1.5, our experiments show that, on the average, the number of intervals \nthat have to be checked is less than 1.052. More precisely, in order to perform the test Query(t, r) \n(i.e if t is subtype of r) we check only one interval if t has existed from compile-time. If t is added \nat run-time, the number of intervals that have to be checked depends on the number of parents it has \nand their position in the type hierarchy. Figure 7 shows how the query time is in.uenced by the average \nnumber of parents. In this experiment we consider queries like Query(t, r)in which t is inserted at run-time, \nand we measure the average test time in JDK 1.5, after the addition of new types with different average \nnumbers of parents: 2, 3, and 14 (the maximum number of ancestors according to Table 1). Figure 7. Test \ntime after insertions  6.2 Encoding size Worst case. If a slicing has k slices, then the encoding size \nof ESE is O(k). We assign to each type two identi.ers (ID, SID) and the interval of its ancestors for \neach slice (see Section 2.1) which leads to the encoding length of 2k +2for each type. (The encoding \nsize of DST and PQE is in the order of 2k +2and k +2respectively.) Experiments. Table 3 compares ESE \nwith DST and PQE in terms of encoding size which is in.uenced mainly by the number of slices. Here, we \nconsider the algorithms excluding their optimiza\u00adtions related to the compression of integer indices \n(ids) into a mini\u00admal bit representation. (Such optimizations are common to all three schemes.) According \nto this table, the amount of space that ESE uses is between 2 to 3 times less than DST, but it is larger \nthan PQE. Type Encoding Size of Slices hierarchy ESE DST PQE ESE DST PQE java.lang 8 26 - 3 12 - java.io \n8 22 - 3 10 - Java EE 5 10 32 - 4 15 - JDK 1.1.8 16 36 8 8 17 6 JDK 1.2.2 18 38 10 8 18 8 JDK 1.3.1 18 \n36 10 8 17 8 JDK 1.4.2 18 38 - 8 18 - JDK 1.5.0 18 38 - 8 18 - Table 3. Encoding size per type (number \nof integers). For the case of single-inheritance type hierarchies, our experi\u00admental results show that \nESE gives a near-optimal number of slices. Figure 8 gives an example showing that the approximation-rate2 \nof DST is not less than n/6 in terms of encoding size in com\u00adparison to ESE. In this example the optimal \nslicing has 2 slices ([A;D;G;J][B;C;E;F;H;I]), while DST gives 4 ([B;A;C][E;D;F] [H;G;I][J]). If we continue \nthe pattern of Figure 8 (a) (like Fig\u00adure 8 (b)), for each additional 3 types, DST creates a new slice. \nSince, in such hierarchies the optimal slicing has always 2 slices, the approximation-rate of DST is \n(n/3)/2=n/6. Figure 9 evaluates ESE against DST in terms of average encod\u00ading length, in a dynamic setting, \nafter the addition of new types at 2 The approximation-rate is de.ned as result of the algorithm / optimal \nresult  run-time. In this experiment, we only measure the encoding size of the new types, because the \nencoding size of the old types remains unchanged. We consider java.lang and JDK 1.5 as samples of rela\u00adtively \nsmall and large type hierarchies. We generate the new types randomly with the average number of parents \nof 2 which is more than the average number of parents of all the hierarchies shown in Table 2. As can \nbe observed from Figure 9, compared to DST, our algorithm is much more ef.cient under insertion of new \ntypes. Inserting 20 types, the average encoding size in ESE grows 3-30 times less than PQE. This fact \ncould be explained by the method we use to reserve identi.ers for newly inserted types, given in Sec\u00adtion \n4.3.3. Apparently, this method is effective until the reserved identi.ers are exhausted. Figure 10 illustrates \nthe effectiveness of our method after the addition of several types (up to 300) in JDK 1.5 type hierarchy. \nLet us observe that the growth of the encoding length with the number of insertions becomes slower when \nwe in\u00adcrease the average number of parents. This may be explained by our insertion algorithm which tries \nto insert new types beside one of their parents. (Otherwise, it creates a new slice.) The worst cases \nhappen when all the parents of the new type are among newly added types. According to our insertion algorithm, \nno reserved identi.er can be used for such cases. Figure 11 depicts the fast growth of en\u00adcoding length \nwith the number of insertions in one of these cases. Figure 9. Growth of encoding size with insertions. \n  6.3 Insertion time As noticed before, the insertion method proposed in Section 4.4 does not impact \nthe encoding of the old types. In central\u00adized settings, this fact normally speeds up the subtyping process, \nwhereas in distributed systems it avoids the propagation of encod\u00ading changes throughout the network. \nWith respect to this property, we compare our algorithm with PQE and DST which are the most ef.cient \n(non-extensible and extensible respectively) approaches we know of. Worst case. While ESE and DST takes \nO(|parents(t)|) to add a new type t, PQE insertsnew typesin O(|A|) in which |A| is the number of ancestors \nin the type hierarchy. From Table 2, the average number of parents is always less than 2. On the other \nhand, the number of ancestors in a type hierarchy can be 29.89 times larger than the number of types. \nThese facts illustrate the signi.cant difference between the insertion time in ESE and PQE. To better \nappreciate the advantage of extensible algorithms in dy\u00adnamic distributed settings, consider a system \nwith two components C1, C2, and a type t a priori known by both components. Upon receiving an object \nO, C2 which was expecting an object of type t, has to check whether or not the object it has received \nis of that type. To do that, it is necessary for C1 to send the identi.er of type t along with O (Microsoft \n2005; Sun Microsystems 2005; OMG 2001; Dedecker et al. 2006). On the other hand, upon the addition of \na new type r at C1, PQE changes the encoding of the old types including t, and hence the new identi.er \nof t at C1 is not valid for C2 anymore. Apparently, any algorithm aimed to .x this problem has to perform \na global agreement on the encoding between all the components of the system for each newly added type, \nwhich is ex\u00adtremely costly in terms of time and bandwidth utilization. We recall that, in extensible \nschemes (ESE and DST), after the addition of r at C1, the encoding of the types at C2 are still valid \nand thus, there is no need for further information exchanges. Experiments. Table 4 compares the insertion \ntime of ESE with DST and PQE. While ESE and PQE usually provides comparable speed, PQE as the most ef.cient \nnon-extensible solution takes much more time. Hierarchy ESE DST PQE java.lang @ JDK 1.5.0 16 12 37 java.io \n@ JDK 1.5.0 16 12 36 Java EE 5 16 11 385 JDK 1.1.8 17 13 757 JDK 1.2.2 17 15 4263 JDK 1.3.1 19 15 5381 \nJDK 1.4.2 21 15 6995 JDK 1.5.0 21 17 8905 Table 4. Insertion time in micro second.  7. Related Work \nGiven that the subtyping test has a signi.cant impact on the overall performance of systems, several \ntype encoding schemes have been proposed in the literature (Zibin et al. 2001, 2002; Cohen 1991; Vitek \net al. 1997; Sprugnoli 1977; Krall et al. 1997; Dietz 1982, 1987; Denielou et al. 2006; Palacz et al. \n2003). However, almost all previous works were basically designed for static type systems and do not \nef.ciently provide support for newly inserted types. We overview in the following these algorithms as \nwell as the dynamic algorithms we know of (Baehni et al. 2007; Vitek et al. 1997). (C)PQE: (Coalesced) \nPQ-encoding (Zibin et al. 2001). Based on PQ-trees (Gosling et al. 2005), a technique for searching an \norder\u00ading satisfying prescribed constraints, PQ-encoding (PQE) splits the type hierarchy into a minimum \nnumber of groups of types called slices, such that each slice satis.es local consecutiveness. A slice \ni is locally consecutive if there is an ordering of i in which for each type t, all the descendants of \nt are consecutive in i. PQE encodes a type t with (1) an integer st which is the number of slice to which \nt belongs (2) a pseudoarray idt, such that idt@i is the id of type t with respect to slice i (3) for \neach slice i, the interval of descen\u00addants of t in i. In order to check if a type t is a subtype of another \ntype r, PQE checks if the identi.er of t is part of the interval of the subtypes of r in the slice containing \nt. While PQE improves the en\u00adcoding length of all previous results, it can not handle newly added types \nat runtime without reconstructing the entire encoding. CPQE is an optimization of PQE which reduces the \nspace consumption of PQE even further. CPQE does not simply support the addition of new types at run-time. \nTS: Type Slicing (Zibin et al. 2002). TS uses the idea of PQE\u00adencoding without requiring global recon.guration \nfor each newly added type. It maintains an ordered list for all types in a slice and substitutes integers \nand arithmetical comparisons by list positions and list order maintenance. Upon addition of a new type, \nTS inserts this type into the .rst ordered list in which this insertion does not violate the local consecutiveness. \nIf such a slice does not exist, it creates a new slice. It is worth mentioning that, when a new type \nis added, the encoding of the parents of the new type must be modi.ed. On the other hand, TS is around \n10 times less ef.cient than CPQE in terms of encoding size. DST: Distributed Subtyping Test (Baehni et \nal. 2007). Basically, DST is designed for distributed environments while retaining the ef.ciency of a \ncentralized scheme in terms of encoding size and test time. The idea of DST and ESE are similar in the \nsense that they use the same slicing technique, which can be viewed as a modi.cation of PQE s slicing \nscheme with a fundamental difference: ancestors are ordered instead of descendants. A major difference \nbetween DST and ESE is in the construction of the initial slicing and the algorithm they use for inserting \nnew types at run-time. Range compression encoding (Agrawal et al. 1989). Like PQE, range compression \nencoding splits the type hierarchy into subsets of types which are in the form of trees. The algorithm \nensures that all the subtypes of a type t are in one interval in a tree (the types are ordered using \na post-order traversal algorithm). A type t is identi.ed by its identi.er which is its position in the \ntree it belongs to, as well as the set of its subtypes intervals. Upon addition of a new type, the old \nencoding is useless and the algorithm has to reconstruct the trees. Bit vector encoding (Krall et al. \n1997). This algorithm encodes a type t with a vector of k bits called vect such that, if a type t is \na subtype of a type r,then vect .vecr =vecr. Obviously, whenever a new type is added at run-time, the \nentire type hierarchy encoding has to be re-computed. (B)PE: (Bit) Packed Encoding (Vitek et al. 1997). \nWith packet encoding, the type hierarchy is divided into subset of types called bucket, such that two \nsuper-types of a type can not be in the same bucket. The encoding of a type t consists of the identi.er \nof the bucket in which t is contained, the position of t in its bucket, and a set of pairs (bucket, super \n- type) indicating the super\u00adtype of t in each bucket. Bit packet encoding is an optimization which permits \ntwo or more buckets to be encoded in a single byte. According to both algorithms, the number of buckets \nand hence the average encoding length grows with the number of ancestors in the type hierarchy. Both \nalgorithms avoid global recon.guration upon addition of new types at runtime. Perfect Hashing (Fredman \net al. 1984; Sprugnoli 1977). This algorithm simply hashes each ancestor of a type with a unique hash \nkey (Ducournau 2006). The subtyping test then is just a search in a hash table. While perfect hashing \ndoes not need global recon.gura\u00adtion for each newly added type at runtime, the size of the hash table \nand hence the encoding length grows with the number of ancestors in the type hierarchy. Two-Hop Cover \n(Schenkel et al. 2005). For each pair of nodes t, r, if there is a path from t to r, it chooses a node \nw on a path from t to r and adds w to the set of ancestors of r (Lin(r))and set of descendants of t (Lout(t)). \nIt tests if r is reachable from t by checking whether Lin(r)n Lout(t)=\u00d8. The connection from t to r is \ngiven by (1) the hop from t to w and (2) the hop from w to r, hence the name of the method. Upon insertion \nof a new type u,this method adds u to Lout(a)for all ancestors a of u (i.e. It changes the encoding of \nthe old types, leading to a non-extensible encoding algorithm). Dietz s Algorithm (Dietz 1982, 1987). \nThemainideaofDeitz s algorithm is to maintain the pre-and post-order of the tree in an or\u00addered list. \nType ti is subtype of tj iff ti occurs before tj in the post order and tj occurs before ti in the pre-order. \nIt provides constant time for insertion and query operations and linear encoding size. The problem of \nhaving a dynamic Deitz s algorithm turns into the problem of order maintenance (Gosling et al. 2005). \nThis restricts the scope of the algorithm to single inheritance only. Cohen s Algorithm (Cohen 1991). \nThis algorithm is also re\u00adstricted to single inheritance hierarchies. It de.nes for each type t a level \ndenoted by lt which is its number of ancestors (i.e. its distance to the root of the tree). Then it associates \nwith t a unique identi.er and an array A of length lt which stores the identi.er of ancestors of t like \ntI in L[ltu]. While the algorithm is fully incre\u00admental, in the worst case the encoding length is O(n \n2) when the type hierarchy is a chain. 8. Conclusion and Future Research This paper introduces ESE, \nan extensible subtyping test algo\u00adrithm that ensures (1) ef.cient insertion of new types, (2) ef.cient \nsubtyping tests, and (3) small space usage. More precisely, ESE provides subtyping test time and encoding \nsize that are comparable to the most ef.cient static subtyping algorithms we know of (PQE). ESE, on the \nother hand, uses less memory space (2-3 times) than the most ef.cient dynamic subtyping algorithms published \nbefore (DST). In addition, unlike DST, ESE remains ef.cient even after new types are inserted at run-time. \n  References R. Agrawal, A. Borgida, and H. V. Jagadish. Ef.cient Management of Tran\u00adsitive Relationships \nin Large Data and Knowledge Bases. In Proceedings of the ACM International Conference on Management of \nData, pages 253 262, 1989. S. Ajmani, B. Liskov, and L. Shrira. Modular Software Upgrades for Distributed \nSystems. In Proceedings of the 20th European Conference on Object-Oriented Programming, pages 452 476, \n2006. S. Baehni, J. Bareto, P. Eugster, and R. Guerraoui. Ef.cient Distributed Subtyping Tests. In Proceedings \nof the ACM International Conference on Distributed Event-based Systems, pages 214 225, 2007. N. H. Cohen. \nType-Extension Tests can be Performed in Constant Time. ACM Transactions on Programming Languages and \nSystems, 13:626 629, 1991. J. Dedecker, T. V. Cutsem, S. Mostinckx, T. D Hondt, and W. D. Meuter. Ambient-Oriented \nProgramming in AmbientTalk. In Proceedings of the 20th European Conference on Object-Oriented Programming, \npages 230 254, 2006. P. F. Dietz. Maintaining order in a linked list. In Proceedings of the 14th Ann. \nACM Symposium on Theory of Computing, pages 122 127, 1982. P. F. Dietz and D. D. Sleator. Two algorithms \nfor maintaining order in a list. In Proceedings of the 19th Ann. ACM Symposium on Theory of Computing, \npages 365 372, 1987. P.-M. Denielou and J. Leifer. Abstraction Preservation and Subtyping in Distributed \nLanguages. In Proceedings of the 11th ACM International Conference on Functional Programming (ICFP 06), \npages 286 297, 2006. R. Ducournau. Le hachage parfait fait-il un parfait test de sous-typage? In Proceedings \nof the Conf\u00b4erence des Languages et Mod`eles aObjets, ` pages 71 86, 2006. M. L. Fredman, J. Koml\u00b4os, \nand E. Szemer\u00b4edi. Storing a Sparse Table with O(1) Worst Case Access Time. Journal of the ACM, 31(3):58 \n544, 1984. A. Goldberg and A. Robson. Smalltalk-80: The Language and its Imple\u00admentation. Addison-Wesley, \n1983. J. Gosling, B. Joy, G. Steele, and G. Bracha. Java 1.5 Language Speci.ca\u00adtion, third edition. http://java.sun.com/j2se/1.5.0/docs/index.html, \n2005. A. Hejlsberg and S. Wiltamuth. C# Language Speci.cation. Microsoft Press, 2001. A. Krall, J. Vitek, \nand R. N. Horspool. Near Optimal Hierarchical Encoding of Types. In Proceedings of the 11th European \nConference on Object-Oriented Programming, pages 128 145, 1997. N. Lynch. Distributed Algorithms. Morgan \nKaufmann Publishers Inc. San Francisco, CA, USA, 1996. Microsoft. Microsoft Message Queuing, 2005. Microsoft. \n.NET Framework Reference Documentation. http://www.microsoft.com/net/, 2005. Sun Microsystems Inc. Java \nMessage Service -Speci.cation, version 1.1. http://java.sun.com/products/jms/docs.html, 2005. OMG. The \nCommon Object Request Broker: Architecture and Speci.cation, 2001. K. Palacz and J. Vitek. Java Subtype \nTests in Real-Time. In Proceedings of the 17th European Conference on Object-Oriented Programming, pages \n378 404, 2003. L. K. Schubert, M. A. Papalaskaris, and J. Taugher. Determining Type, Part, Colour, and \nTime Relationships. IEEE Computer, 16:53 60, 1983. R. Sprugnoli. Perfect Hashing Functions: A Single \nProbe Retrieving Method for Static Sets. Communications of the ACM, 20(11):841 850, 1977. B. Stroustrup. \nThe C++ Programming Language. Addison-Wesley, 2004. J. Vitek, R. N. Horspool, and A. Krall. Ef.cient \nType Inclusion Tests. In Proceedings of the 12th ACM Conference on Object-Oriented Program\u00adming Systems, \nLanguages and Applications, pages 142 157, 1997. Y. Zibin and J. Gil. Ef.cient Subtyping Tests with PQ-Encoding. \nIn Pro\u00adceedings of the 16th ACM Conference on Object-Oriented Programming Systems, Languages and Applications, \npages 819 856, 2001. Y. Zibin and J. Gil. Fast Algorithm for Creating Space Ef.cient Dispatch\u00ading Tables \nwith Application to Multi-Dispatching. In Proceedings of the 17th ACM Conference on Object-Oriented Programming \nSystems, Lan\u00adguages and Applications, pages 142 160, 2002. R. Schenkel, A. Theobald, and G. Weikum. Ef.cient \nCreation and Incre\u00admental Maintenance of the HOPI Index for Complex XML Document Collections. In Proceedings \nof the 21st International Conference on Data Engineering, pages 360 371, 2005. \n\t\t\t", "proc_id": "1328438", "abstract": "<p>The <i>subtyping test</i> consists of checking whether a type <i>t</i> is a descendant of a type <i>r</i> (Agrawal et al. 1989). We study how to perform such a test efficiently, assuming a <i>dynamic</i> hierarchy when new types are inserted at run-time. The goal is to achieve time and space efficiency, even as new types are inserted. We propose an <i>extensible</i> scheme, named <i>ESE</i>, that ensures (1) efficient insertion of new types, (2) efficient subtyping tests, and (3) small space usage. On the one hand ESE provides comparable test times to the most efficient existing static schemes (e.g.,Zibin et al. (2001)). On the other hand, ESE has comparable insertion times to the most efficient existing dynamic scheme (Baehni et al. 2007), while ESE outperforms it by a factor of 2-3 times in terms of space usage.</p>", "authors": [{"name": "Hamed Seiied Alavi", "author_profile_id": "81543831556", "affiliation": "EPFL, Lausanne, Switzerland", "person_id": "P925377", "email_address": "", "orcid_id": ""}, {"name": "Seth Gilbert", "author_profile_id": "81100549132", "affiliation": "EPFL, Lausanne, Switzerland", "person_id": "PP43124959", "email_address": "", "orcid_id": ""}, {"name": "Rachid Guerraoui", "author_profile_id": "81100348136", "affiliation": "EPFL, Lausanne, Switzerland", "person_id": "PP15049948", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1328438.1328480", "year": "2008", "article_id": "1328480", "conference": "POPL", "title": "Extensible encoding of type hierarchies", "url": "http://dl.acm.org/citation.cfm?id=1328480"}