{"article_publication_date": "01-07-2008", "fulltext": "\n A Logical Account of PSPACE Marco Gaboardi Jean-Yves Marion Simona Ronchi Della Rocca Nancy-University, \nENSMN-INPL, Loria B.P. 239, 54506 Vandoeuvre-l`es-Nancy, France Dipartimento di Informatica, Universit`a \ndegli Studi di Torino -Corso Svizzera 185, 10149 Torino, Italy Jean-Yves.Marion@loria.fr gaboardi,ronchi@di.unito.it \nAbstract We propose a characterization of PSPACE by means of a type as\u00adsignment for an extension of lambda \ncalculus with a conditional construction. The type assignment STAB is an extension of STA, a type assignment \nfor lambda-calculus inspired by Lafont s Soft Linear Logic. We extend STA by means of a ground type and \nterms for booleans. The key point is that the elimination rule for booleans is managed in an additive \nway. Thus, we are able to program polynomial time Alternating Turing Machines. Conversely, we introduce \na call-by\u00adname evaluation machine in order to compute programs in polyno\u00admial space. As far as we know, \nthis is the .rst characterization of PSPACE which is based on lambda calculus and light logics. Categories \nand Subject Descriptors F.3.3 [Logics and mean\u00adings of programs]: Studies of program constructs type \nstructure; F.4.1 [Mathematical logic and formal languages]: Mathematical logic lambda calculus and related \nsystems, proof theory General Terms Languages, Theory, Design Keywords Implicit Computational Complexity, \nPolynomial Space, Linear Logic, Type Assignment 1. Introduction The argument of this paper .ts in the \nso called Implicit Compu\u00adtational Complexity topic, in particular on the design of program\u00adming languages \nwith bounded computational complexity. We want to use a ML-like approach, so having a .-calculus like \nlanguage, and a type assignment system for it, where the types guarantee, besides the functional correctness, \nalso complexity properties. So types can be used in a static way in order to check the correct be\u00adhaviour \nof the programs, also with respect to the resource usage. If the considered resource is the time, the \nnatural choice is to use as types formulae of the light logics, which characterize some classes of time \ncomplexity. Light Linear Logic (LLL) of Girard (Girard 1998), and Soft Linear Logic (SLL) of Lafont (Lafont \n2004) char\u00adacterize polynomial time, while Elementary Linear Logic (EAL) characterizes elementary time. \nThe characterization is based on the fact that cut-elimination in these logics is performed in a number \nof steps which depends in a polynomial or elementary way from Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 08, January 7 12, 2008, San Francisco, \nCalifornia, USA. Copyright c &#38;#169; 2008 ACM 978-1-59593-689-9/08/0001. . . $5.00 the initial size \nof the proof (while the degree of the proof, i.e. the nesting of exponential rules, is .xed). Moreover \nall these logics are also complete with respect to the related complexity class. The good properties \nof such logics have been fruitfully used in or\u00adder to design type assignment systems for .-calculus which \nare correct and complete with respect to the polynomial or elementary complexity bound. Namely every \nwell typed term \u00df-reduces to nor\u00admal form in a number of steps which depends in a polynomial or elementary \nway from its size, and moreover all functions with the corresponding complexity are representable by \na well typed term. Examples of polynomial type assignment systems are in (Baillot and Terui 2004) and \n(Gaboardi and Ronchi Della Rocca 2007), based respectively on LAL ( an af.ne variant of LLL designed \nby Asperti and Roversi (Asperti and Roversi 2002)) and on SLL, and an example of an elementary type assignment \nsystem is in (Cop\u00adpola et al. 2005). Here we use the same approach for studying space complexity, in \nparticular we build a type system for a .-calculus like language, in such a way that well typed terms \nare correct and complete for PSPACE. More precisely, every well typed program reduces in polynomial space \nand all decision functions computable in poly\u00adnomial space are computed by well typed programs. There \nis no previous logical characterization of PSPACE from which we can start. But we will use the fact that \npolynomial space computations coincide with polynomial time alternating Turing machine compu\u00adtations \n(APTIME) (Savitch 1970; Chandra et al. 1981). In particu\u00adlar PSPACE = NPSPACE = APTIME So we will start \nfrom the type assignment STA for .-calculus pre\u00adsented in (Gaboardi and Ronchi Della Rocca 2007), which \nis based on SLL, in the sense that in STA both types are a proper sub\u00adset of SLL formulae, and type assignment \nderivations correspond, through the Curry-Howard isomorphism, to a proper subset of SLL derivations. \nSTA is correct and complete (in the sense said before) with respect to polynomial time computations. \nThen we design a type assignment system (STAB), where the types are STA types plus a type B for booleans, \nand the language .B is an extension of .-calculus with two boolean constants and a conditional construc\u00adtor. \nThe elimination rule for conditional is the following: G f M : B G f N0 : A G f N1 : A (BE) G f ifMthen \nN0 else N1 : A In the if-rule above, contexts are managed in an additive way, that is with free contractions. \nFrom a computational point of view, this intuitively means that a computation can repeatedly fork into \nsubcomputations and the result is obtain by a backward computation from all subcomputation results. While \nthe time complexity result for STA is not related to a particular evaluation strategy, here, for characterizing \nspace complexity, the evaluation should be done carefully. Indeed, a call-by-value evaluation can use \nexponential size. So we de.ne a call-by-name evaluation machine, inspired by Krivine s machine (Krivine \n2007) for .-calculus, where substitutions are made only on head variables. This machine is equipped with \na memory device thanks to which the space used is easily determined, as the dimension of the maximal \nmachine con.guration. Then we prove that, if the machine takes a program (i.e. a closed term well typed \nwith a ground type) as input, then each con.guration is bounded in a polynomial way in the size of the \ninput. So every program is evaluated by the machine in polynomial space. Conversely, we encode every \npolynomial time alternating Turing machine by a term of STAB. The simulation relies on a higher order \nrepresentation of a parameter substitution recurrence schema which was used in (Leivant and Marion 1994). \nSTAB is the .rst characterization of PSPACE through a type assignment system. A proposal for a similar \ncharacterization has been made by Terui (Terui 2000), but the work has never been completed. There are \nprevious implicit characterizations of polynomial space computations. The characterizations in (Leivant \nand Marion 1994, 1997) and (Oitavem 2001) are based on rami.ed recursions over binary words. In .nite \nmodel theory, PSPACE is captured by .rst order queries with a partial .xed point operator (Vardi 1982; \nAbiteboul and Vianu 1989). The reader may consult the recent book (Gr\u00a8adel et al. 2007). Finally there \nare some algebraic characterizations like the one (Goerdt 1992) or (Jones 2001) but which are, in essence, \nover .nite domains. An example of a characterization of a complexity space class through a light logic \nis in (Sch\u00a8opp 2007) where a logical system characterizing logarithmic space computations is de.ned, \nthe Strat\u00adi.ed Bounded Af.ne Logic (SBAL). Logarithmic space soundness is proved by considering only \nproofs of certain sequents to repre\u00adsent the functions computable in logarithmic space. Our characterization \nis strongly based on the additive rule (BE). A similar tool has been used by Maurel s Non Deterministic \nLight Logic (nLLL) (Maurel 2003) in order to characterize non determin\u00adistic polynomial time. More precisely \nnLLL introduces an explicit sum rule to deal with non deterministic computation. A different approach \nbut also based on linear logic is to characterize circuit complexity classes by means of Booleans proof \nnets (Terui 2004; Mogbil and Rahli 2007) but this does not relate to the task of designing programming \nlanguage with an intrinsically polynomial computational bound. Outline of the paper In Section 2 the \nsystem STAB is introduced and the proofs of subject reduction and strong normalization prop\u00aderties are \ngiven. In Section 3 the operational semantics of STAB program is de.ned, through an abstract evaluation \nmachine. In Sec\u00adtion 4 we show that STAB programs can be executed in polyno\u00admial space. In Section 5 \nthe completeness for PSPACE is proved. In Section 6 some complementary argument are considered. The Appendix \ncontains the most technical proofs. 2. Soft Type Assignment system with Booleans In this section the \ntype assignment STAB is presented, and its prop\u00aderties are proved. STAB is an extension of the type system \nSTA for .-calculus introduced in (Gaboardi and Ronchi Della Rocca 2007), which assigns to terms of the \n.-calculus a proper subset of for\u00admulae of Lafont s Soft Linear Logic (Lafont 2004). STA has been proved \nto be correct and complete for polynomial time computa\u00adtions. STAB is obtained from STA by extending \nboth the calculus and the set of types. The calculus is the .-calculus extended by boolean constants \n0, 1 and an if constructor, types are the types of STA plus a constant type B for booleans. De.nition \n1. 1. The set .B of terms is de.ned by the following grammar: M ::= x |0 |1 |.x.M |MM | ifMthenMelse \nM where x ranges over a countable set of variables and B = {0, 1}is the set of booleans. 2. The set T \nof B types is de.ned as follows: A ::= B |a |s -A |.a.A (Linear Types) s ::= A |!s where a ranges over \na countable set of type variables and B is the only ground type. 3. A context is a set of assumptions \nof the shape x : s,where all variables are different. We use G, . to denote contexts. dom(G) = {x |.x \n: s . G}and G#. means dom(G) n dom(.) = \u00d8. 4. STAB proves judgments of the shape G fM : s where G is \na context, M is a term, and s is a B type. The rules are given in Table 1. 5. Derivations are denoted \nby ., ., D. (.)G f M : s denotes a derivation .with conclusion G f M : s.We let f M : s abbreviate \u00d8fM \n: s.  Note that while all rules in STA have a multiplicative treatment of contexts, the rule (BE) of \nSTAB is additive and so contraction is free. Notation 1. Terms are ranged over by M, N, V, P. As usual \nterms are considered up to a-equivalence, namely a bound variable can be renamed provided no free variable \nis captured. Moreover M[N/x] denotes the capture-free substitution of all free occurrences of x in M \nby N. FV(M) denotes the set of free variables of M, no(x, M) the number of free occurrences of the variable \nx in M. Type variables are ranged over by a, \u00df, linear types by A, B, C, and types by s, t, \u00b5. =denotes \nthe syntactical equality both for types and terms (modulo renaming of bound variables). As usual -associates \nto the right and has precedence on ., while ! has precedence on everything else. s[A/a] denotes the capture \nfree substitution in s of all occurrences of the type variable a by the linear type A. FTV(G) denotes \nthe set of free type variables occurring in the assumptions of the context G. We stress that each type \nis of the shape !n.&#38;a.A is a.A where .&#38;an abbreviation for .a1.....am.A, and !ns is an abbreviation \nfor !...!sn-times, where n, m =0. In particular !0s =s. We have the following standard properties for \na natural deduc\u00adtion system. Lemma 1 (Free variable lemma). 1. G fM : s implies FV(M) .dom(G). 2. G \nfM : s, . .G and FV(M) .dom(.) imply . fM : s. 3. G fM : s, G .. implies . fM : s.  The functional \nbehaviour of .B is described in the next de.ni\u00adtion. De.nition 2. The reduction relation .\u00dfd. .B \u00d7.B \nis the contextual closure of the following rules: (.x.M)N .\u00df M[N/x] if0then MelseN .d M if1then MelseN \n.d N (Ax)(B0 I)(B1 I) x : A fx : A f0 : B f1 : B G fM : s G, x : s fM : A (w) (-I) G, x : A fM : s G \nf.x.M : s -A G fM : s -A . fN : s G#. (-E) G, . fMN : A G, x1 : s,... , xn : s fM : \u00b5 G fM : s (m)(sp) \nG, x :!s fM[x/x1, \u00b7\u00b7\u00b7 , x/xn]: \u00b5 !G fM :!s G fM : Aa/.FTV(G) G fM : .a.B (.I) (.E) G fM : .a.A G fM : \nB[A/a] G fM : B G fN0 : A G fN1 : A (BE) G f if M then N0 else N1 : A Table 1. The Soft Type Assignment \nsystem with Booleans . * denotes the re.exive and transitive closure of .\u00dfd. \u00dfd In what follows, we will \nneed to talk about proofs modulo commutations of rules. De.nition 3. Let . and .' be two derivations \nin STAB,proving the same conclusion: . . .' denotes the fact that .' is obtained from . by commuting \nor deleting some rules. The Generation Lemma connects the shape of a term with its possible typings, \nand will be useful in the sequel. Lemma 2 (Generation lemma). 1. (.)G f .x.M : .a.A implies there is \n.' such that . . .' where the last rule of .' is (.I). 2. (.)G f.x.M : s -A implies there is .' such \nthat .. .', whose last rule is (-I). 3. (.)G fM :!s implies there is .' such that .. .' where .' consists \nof a subderivation, ending with the rule (sp)proving !G' fM :!s, followed by a (maybe empty) sequence \nof rules (w) and/or (m). 4. (.)!G f M :!s implies there is .' such that . . .', whose last rule is (sp). \n The substitution lemma will be the key lemma to show that STAB enjoys the subject reduction property. \nLemma 3 (Substitution lemma). Let (.)G, x : \u00b5 f M : s and (.). f N : \u00b5 such that G#.. Then there exists \n(D)G, . f M[N/x]: s. Proof. Since the proof is quite involved, we postpone it to Ap\u00adpendix A.1. We can \n.nally prove the main property of this section. Lemma 4 (Subject Reduction). Let G f M : s and M .\u00dfd \nN. Then G fN : s. Proof. The case of a .d reduction is easy, the one of .\u00df reduction follows by Lemma \n3. By strong normalization of STA we have the following. Lemma 5 (Strong Normalization). Let G f M : \ns then M is strongly normalizing with respect to the reduction relation .\u00dfd. Nevertheless due to the \nadditive rule (BE), STAB is no more correct for polynomial time. In fact, terms with an exponential number \nof reductions can be typed by derivations with a priori .xed degree, i.e. the nesting of exponential \nrules. Example 1. Consider for n .N terms Mn of the shape: (.f..z.fn(z))(.x. ifxthen xelsex)0 It is easy \nto verify that for each Mn there exist reduction sequences of length exponential in n.  3. Structural \nOperational Semantics In this section the operational semantics of terms of .B will be given, through \nan evaluation machine, de.ned in SOS style, per\u00adforming the evaluation according to the leftmost outermost \nstrategy. The machine, if restricted to .-calculus, is quite similar to the Kriv\u00adine machine (Krivine \n2007), since \u00df-reduction is not an elementary step, but the substitution of a term to a variable is performed \none occurrence at a time. The evaluation machine is related to the type assignment system STAB in the \nsense that, when it starts on an empty memory, all the programs (closed terms of ground type) can be \nevaluated. De.nition 4. The set P of STAB programs is the set of closed terms typable by the ground type. \ni.e. P = {M |fM : B}. It is easy to check that a STAB term is of the following shape: M =.x1...xn..V1 \n\u00b7\u00b7\u00b7Vm where . is either a boolean b,a variable x,a redex (.x.N)P,or a subterm of the shape if P then \nN0 else N1 . In particular, if a term is a program, then its shape is as before, but with the condition \nthat the number n of initial abstractions is equal to 0. Moreover if . is a boolean b then the number \nm of arguments is equal to 0. We will use this characterization of programs to design the evaluation \nmachine KC B. KC B uses two memory devices, the m-context and the B-context, that memorize respectively \nthe assignments to variables and the control. De.nition 5. 1. An m-context A is a sequence of variable \nassignments of the shape xi := Mi where all variables xi are distinct. The set of m-contexts is denoted \nby Ctxm. 2. The cardinality of an m-context A, denoted by #(A),is the number of variable assignments \nin A. 3. The size of an m-context A, denoted by |A|,is the sumof the size of each variable assignment \nin A, where a variable assignment x := M has size |M| +1, and |M| is the number of symbols of M. 4. \nLet .be a distinguished symbol. The set CtxB of B-contexts is de.ned by the following grammar:  C[.] \n::= .|( if C[.] then M else N )V1 \u00b7\u00b7\u00b7Vn 5. The size of a B-context C[.] denoted |C[.]| is the size of \nthe term obtained by replacing the symbol . by a variable. The cardinality of a B-context C[.], denoted \nby #(C[.]),is the number of nested B-contexts in it. Notation 2. e denotes the empty m-context and A1@A2 \ndenotes the concatenation of the m-contexts A1 and A2. [x := M] .A denotes the fact that x := M is in \nthe m-context A. FV(A)= FV(M). [x:=M].A As usual C[M] denotes the term obtained by .lling the hole [.] \nin C[.] by M. In general we omit the hole [.] and we range over B\u00adcontexts by C. FV(C)=FV(C[M]) for every \nclosed term M. (Ax) C,A|= b .b C,A@{x ' := N}|= M[x ' /x]V1 \u00b7\u00b7\u00b7Vm .b * (\u00df) C,A|=(.x.M)NV1 \u00b7\u00b7\u00b7Vm .b \n{x := N}.A C,A|= NV1 \u00b7\u00b7\u00b7Vm .b (h) C,A|= xV1 \u00b7\u00b7\u00b7Vm .b C[( if [.] then N0 else N1 )V1 \u00b7\u00b7\u00b7Vm],A|= M .0 \nC,A|= N0 V1 \u00b7\u00b7\u00b7Vm .b ( if 0) C,A|=( if M then N0 else N1 )V1 \u00b7\u00b7\u00b7Vm .b C[( if [.] then N0 else N1 )V1 \n\u00b7\u00b7\u00b7Vm],A|= M .1 C,A|= N1 V1 \u00b7\u00b7\u00b7Vm .b ( if 1) C,A|=( if M then N0 else N1 )V1 \u00b7\u00b7\u00b7Vm .b (*) x ' is a fresh \nvariable. Table 2. The Abstract Machine KC B Note that variable assignments in m-contexts are ordered; \nthis fact allows us to de.ne the following closure operation. De.nition 6. Let A=[x1 := N1,...,xn : Nn] \nbe an m-context. Then ()A :.B ..B is the map associating to each term M the term M[Nn/xn][Nn-1/xn-1] \n\u00b7\u00b7\u00b7[N1/x1]. KC B is de.ned in Table 2. Some comments are in order. The rules will be commented bottom-up, \nwhich is the natural direction of the evaluation .ow. Rule (Ax) is obvious. Rule (\u00df) applies when the \nhead of the subject is a \u00df-redex: then the association between the bound vari\u00adable and the argument is \nremembered in the m-context and the body of the term in functional position is evaluated. Note that an \na-rule is always performed. Rule (h) replaces the head occurrence of the head variable by the term associated \nto it in the m-context. Rules ( if 0) and ( if 1) perform the d reductions. Here the evaluation naturally \nerases part of the subject, but the erased information is stored in the B-context. In order to state \nformally the behaviour of the machine KC B we need a further de.nition. De.nition 7. 1. The evaluation \nrelation .. CtxB \u00d7Ctxm \u00d7.B \u00d7Bis the effective relation inductively de.ned by the rules of KC B.If M \nis a program, and if there is a boolean bsuch that [.],e |= M .b then we say that M evaluates, and we \nwrite M .. |= M .b is a short for [.],e |= M .b. 2. Derivation trees are called computations in the \nabstract ma\u00adchine and are denoted by .,S. .:: C,A|= M .b denotes a computation with conclusion C,A|= \nM .b. 3. Given a computation . each node of ., which is of the shape C,A|= M .b is a con.guration. C,A|= \nM .b .. denotes that C,A|= M . b is a con.guration in the computation .. Con.gurations are ranged over \nby f,.and f. C,A|= M .b means that fis the con.guration C,A|= M .b. The conclusion of the derivation \ntree is called the initial con.guration. 4. Given a computation .,the path to reach a con.guration f \ndenoted path. (f) is the sequence of con.gurations between the conclusion of . and f. In general we will \nwrite path(f) when . is clear from the context.  We are interested in the behaviour of the machine when \napplied to programs. By an analysis of the rules of Table 2, and from the previous comments, it is easy \nto verify the following. Lemma 6. 1. Let M .P, .::|= M . b and C,A|= N . b ' . ..Then (C[N])A ,(N)A .P. \n 2. Let M .Pand .::|= M .b.For each C,A|= N .b ' ..  * A* M .\u00dfd (C[N]).\u00dfd b Note that, in the previous \nlemma, the m-context and the B\u00adcontext are essential in proving the desired properties. In fact the B-context \nrecovers the part of the term necessary to complete d\u00adreductions, while the m-context completes \u00df-reductions \nthat have been performed only partially by the machine. Example 2. In Table 5 we present an example of \nKC B computation on the same term of Example 1. Note that by De.nition 7.1 a term M evaluates only if \nit is a program and there exists b such that |= M .b. We stress here, that the machine KC B is complete \nwith respect to programs, in the sense that all the programs can be evaluated. Theorem 1. M .P implies \nM . Proof. By induction on the reduction to normal form using Lemma 5. 3.1 A small step version of KC \nB In Table 3 we depict a small step version of the machine KC B.The rules are similar to the rules in \nTable 2 but the use of a garbage collector procedure described in Table 4 which is needed in order to \nmaintain the desired complexity property. In fact the small step machine can be easily shown equivalent \nto the big step one. The small step machine explicits the evaluation order clarifying that every con.guration \ndepends uniquely on the previous one (thanks to the B-context). So the space necessary to evaluate a \nprogram turns out to be the maximum space used by one of its con.gurations. Nevertheless, the big step \nmachine has the advantage of being more abstract and this make it easy to prove the complexity properties. \nIn fact, the garbage collector procedure make more dif.cult the proofs of such properties for the small \nstep machine. For this reason in what follows we will work on the big step machine. (C,A>(.x.M)NV1 \u00b7\u00b7\u00b7Vm) \n' := N] >M[x ' /x]V1 \u00b7\u00b7\u00b7Vm) (\u00df) .(C,A@[x (h0) (C,A1@[x := N]@A2 >xV1 \u00b7\u00b7\u00b7Vm) .(C,A1@[x := N]@A2 >NV1 \n\u00b7\u00b7\u00b7Vm) ( if ) (C,A>( ifMthen N0 else N1 )V1 \u00b7\u00b7\u00b7Vm).(C [( if [.] then N0 else N1 )V1 \u00b7\u00b7\u00b7Vn],A>M) A ' = \nclear(C,A,N0 V1 \u00b7\u00b7\u00b7Vn) (r0 ) (C[( if [.] then N0 else N1 )V1 \u00b7\u00b7\u00b7Vn],A>0) ' >N0 V1 \u00b7\u00b7\u00b7Vn .(C,A) A ' \n= clear(C,A,N1 V1 \u00b7\u00b7\u00b7Vn) (r1 ) (C[( if [.] then N0 else N1 )V1 \u00b7\u00b7\u00b7Vn],A>1) ' >N1 V1 \u00b7\u00b7\u00b7Vn) .(C,A Table \n3. The small step machine kC B clear(C,e,M)= e clear(C,A,M)= A ' x .FV(C) .FV(M) .FV(A) clear(C,[x := \nN]@A,M)=[x := N]@A ' clear(C,A,M)= A ' x ./FV(C) .FV(M) .FV(A) clear(C,[x := N]@A,M)= A ' Table 4. The \ngarbage collector procedure. 3.2 Space Measures We can now de.ne the space effectively used to evaluate \na term. The remarks in the previous section allows us to consider the following de.nition. De.nition \n8. Let fc C,A|= M . b be a con.guration then its size denoted |f|is the sum |C|+ |A|+ |M|.Let .:: C,A|= \nM .b be a computation, then its space occupation denoted space(.) is the maximal size of a con.guration \nin .. In particular since there is a one-to-one correspondence between a program M and its computation \n.::[.],e |= M . b, we will usually write space(M) in place of space(.).In order to have polynomial space \nsoundness we will show that for each M .P there exists a polynomial P(X) such that space(M) = P(|M|). \nThe result will be proved in next section. Example 3. By returning to the computation of Example 2 it \nis worth noting that to pass from the con.guration f to the con.g\u00aduration . all necessary informations \nare already present in the con.guration f itself. We can view such a step as a .d step ( if 0 then x1 \nelse x1 )A3 .d (x1)A3 noting that (x1)A3 = (x1)A2 . In fact this can be generalized, so in this sense \nwe don t need neither mechanism for backtracking nor the memorization of parts of the computation tree. \nIn what follows we will introduce some relations between the size of the contexts and the behaviour of \nthe machine, which will be useful later. De.nition 9. Let . be a computation and f .. a con.guration. \n #\u00df(f) denotes the number of applications of the (\u00df) rule in path(f).  #h(f) denotes the number of applications \nof the (h) rule in path(f).  #if (f) denotes the number of applications of (if 0) and (if 1) rules in \npath(f).  The cardinality of the contexts is a measure of the number of some rules performed by the \nmachine. Lemma 7. Let .::|= M . b. Then for each con.guration f c Ci,Ai |= Pi .b ' ..: 1. #(Ai)=#\u00df(f) \n 2. #(Ci)=#if (f)  The following is an important property of the machine KC B. Property 1. Let M .P \nand .::|= M .b then for each fcC,A|= P .b ' . . if [xj := Nj ] .Ai then Nj is an instance of a subterm \nof M. Proof. The property is proven by contradiction. Take the con.gu\u00adration fwith minimal path from \nit to the root of ., such that in its m-context Af there is xj := Nj ,where Nj is not an instance of \na subterm of M.Let p be the length of this path. Since the only rule that makes the m-context grow is \na (\u00df) rule we are in a situation like the following: C,A ' @[xj := Nj ] |= P[xj /x]V1 \u00b7\u00b7\u00b7Vn .b C,A ' \n|=(.x.P)Nj V1 \u00b7\u00b7\u00b7Vn .b If Nj is not an instance of a subterm of M it has been obtained by a substitution. \nSubstitutions can be made only through applications of rule (h) replacing the head variable. Hence by \nthe shape of (.x.P)Nj V1 \u00b7\u00b7\u00b7Vn, the only possible situation is that there exists an application of rule \n(h)as: [y :=M ' ].A ' C,A ' |=M ' V1 \u00b7\u00b7\u00b7Vn .b C,A ' |=yV1 \u00b7\u00b7\u00b7Vn .b with Nj an instance of a subterm of \nM ' . But this implies M ' is not an instance of a subterm of M and it has been introduced by a rule \nof a path of length less than p, contradicting the hypothesis. The next lemma gives upper bounds to the \nsize of the m\u00adcontext, of the B-context and of the subject of a con.guration. Lemma 8. Let M .Pand .::|=M \n.b then for each con.guration fc C,A|=P .b ' ..: 1. |A|=#\u00df (f)(|M|+1) 2. |P|=(#h(f)+1)|M| '' N .b '' \n  3. |C|=#if (f)(max{|N||.c C ,A|=..}) Proof. 1. By inspection of the rules of Table 2 it is easy to \nverify that m-contexts can grow only by applications of the (\u00df)rule. So the conclusion follows by Lemma \n7 and Property 1. 2. By inspection of the rules of Table 2 it is easy to verify that the subject can \ngrow only by substitutions through applications of the (h)rule. So the conclusion follows by Property \n1. 3. By inspection of the rules of Table 2 it is easy to verify that B-contexts can grow only by applications \nof (if 0)and (if 1) rules. So the conclusion follows directly by Lemma 7.  4. PSPACE Soundness In this \nsection we will show that STAB is correct for polynomial space computation, namely each program typable \nthrough a deriva\u00adtion with degree d can be executed on the machine KBC in space polynomial in its size, \nwhere the maximum exponent of the poly\u00adnomial is d. The degree of a derivation counts the maximum nesting \nof applications of the rule (sp)in it. So considering .xed degrees we get PSPACE soundness. Considering \na .xed d is not a limita\u00adtion. Indeed until now, in STAB programs we do not distinguish between the program \ncode and input data. But it will be shown in Section 5 that data types are typable through derivations \nwith de\u00adgree 0. Hence the degree can be considered as a real characteristic of the program code. Moreover \nevery STAB program can be typed through derivations with different degrees, nevertheless for each program \nthere is a sort of minimal derivation for it, with respect to the degree. So we can stratify programs \nwith respect to the degree of their derivations, according to the following de.nition. De.nition 10. \n1. The degree d(.)of .is the maximum nesting of applications of rule (sp)in .. 2. For each d.N the set \nPd is the set of STAB programs typable through derivation with degree d.  Pd ={M | (.) fM :B . d(.)=d} \nClearly P corresponds to the union for n . N of the different Pn. Moreover if M .Pd then M .Pe for every \ne=d. This section is divided into two subsections. In the .rst, we will prove an intermediate result, \nnamely we will give the notion of space weight of a derivation, and we will prove that the subject reduction \ndoes not increment it. Moreover this result is extended to the machine KBC . In the second part the soundness \nwith respect to PSPACE will be proved. 4.1 Space and STAB We need to de.ne measures of both terms and \nproofs, which are an adaptation of those given by Lafont in (Lafont 2004). De.nition 11. 1. The rank \nof a rule (m): G,x1 :s,...,xn :s fM :\u00b5 (m) G,x :!s fM[x/x1,\u00b7\u00b7\u00b7 ,x/xn]:\u00b5 is the number k =nof variables \nxi such that xi belongs to the free variables of M.Let rbe the the maximum rank of a rule (m) in .. The \nrank rk(.)of .is the maximum between 1and r. 2. Let rbe a natural number. The space weight d(.,r)of .with \nrespect to ris de.ned inductively as follows. (a) If the last applied rule is (Ax),(B0 I),(B1 I) then \nd(.,r)=1. (b) If the last applied rule is (-I)with premise a derivation .,then d(.,r)=d(.,r)+1. (c) \nIf the last applied rule is (sp)with premise a derivation ., then d(.,r)=rd(.,r). (d) If the last applied \nrule is (-E)with premises . and D then d(.,r)=d(.,r)+d(D,r)+1. (e) If the last applied rule is:  (.)GfM \n:B (D0 )GfN0 :A (D1 )GfN1 :A Gf if M then N0 else N1 :A then d(.,r)=max{d(.,r),d(D0 ,r),d(D1 ,r)}+1 (f) \nIn every other case d(.,r)=d(.,r)where . is the unique premise derivation. In order to prove that the \nsubject reduction does not increase the space weight of a derivation, we need to rephrase the Substitution \nLemma taking into account this measure. Lemma 9 (Weighted Substitution Lemma). Let (.)G,x : \u00b5 f M : s \nand (.). f N : \u00b5 such that G#. then there exists (D)G,.fM[N/x]:s such that if r =rk(.): d(D,r)=d(.,r)+d(.,r) \nProof. We postpone the proof to Appendix A.2. We are now ready to show that the space weight dgives a \nbound on the number of both \u00df and if rules in a computation path of the machine KBC . Lemma 10. Let M \n.P and .::|=M .b. 1. Consider an occurrence in .of the rule: C,A@{x ' :=N}|=M[x ' /x]V1 \u00b7\u00b7\u00b7Vm .b C,A|=(.x.M)NV1 \n\u00b7\u00b7\u00b7Vm .b (\u00df) Then, for every derivations (.) f ((.x.M)NV1 \u00b7\u00b7\u00b7Vm)A : B 'A@{x :=N} there exists a derivation \n(D) f (M[x /x]V1 \u00b7\u00b7\u00b7Vm).: B such that for every r =rk(.): d(.,r)>d(D,r) 2. Consider an occurrence in \n.of an if rule as: C ' ,A|=M .0 C,A|=N0 V1 \u00b7\u00b7\u00b7Vm .b C,A|=(if Mthen N0 else N1 )V1 \u00b7\u00b7\u00b7Vm .b where C ' \n=C[(if [.]then N0 else N1 )V1 \u00b7\u00b7\u00b7Vm]. Then, for each derivation (.) f((if M then N0 else N1 )V1 \u00b7\u00b7\u00b7Vm)A \n: B there are derivations (D) f (M)A : B and (.) f (N0 V1 \u00b7\u00b7\u00b7Vm)A :B such that for every r =rk(.): d(.,r)>d(D,r) \nand d(.,r)>d(.,r)  C1,A3 |=0 .0 C1,A3 |=z1 .0 C1,A3 |=x2 .0 fc C0,A3 |=0 .0 C0,A3 |=z1 .0 C0,A3 |=x2 \n.0 C0,A3 |= if x2 then x2 else x2 .0 C0,A2 |=(.x.if x then x else x)z1 .0 C0,A2 |=f1z1 .0 C0,A2 |=x1 \n.0 C2,A4 |=0 .0 C2,A4 |=z1 .0 C2,A4 |=x3 .0 A4 |=0 .0 A4 |=z1 .0 A4 |=x3 .0 A4 |= if x3 then x3 else \nx3 .0 A2 |=(.x.if x then x else x)z1 .0 A2 |=f1z1 .0 .c A2 |=x1 .0 A2 |= if x1 then x1 else x1 .0 A1 \n|=(.x.if x then x else x)(f1z1).0 A1 |=f1(f1z1).0 A0 |=(.z.f1(f1z))0 .0 |=(.f..z.f2(z))(.x.if x then \nx else x)0 .0 A0 =[f1 :=.x.if x then x else x] A1 =A0@[z1 :=0] A2 =A1@[x1 :=f1z1] A3 =A2@[x2 :=z1] A4 \n=A2@[x3 :=z1] C0 = if . then x1 else x1 C1 =C0[if . then x2 else x2 ] C2 = if . then x3 else x3 Table \n5. An example of computation in KBC . Proof. 1. It suf.ces to consider the case where m=0, and to prove \nthat, if (.)Gf(.x.M)N :s, then there exists (. ' )GfM[N/x]:s with rk(.)=rk(. ' )such that for r =rk(.): \nd(.,r)>d(. ' ,r) Since (.R),(.L),(m)and (w)rules don t change the d mea\u00adsure we can without loss of generality \nassume that .ends as: (.)G1,x :s fM :A (-I) G1 f.x.M :s -A (D)G2 fN :s (-E)G!,G2 f(.x.M)N :A (sp)n !nG1,!nG2 \nf(.x.M)N :!nA where G1#G2, G=!nG1,!nG2, s =!nA and n = 0. Clearly we have d(.,r)=r n(d(.,r)+1+d(D,r)). \nBy Lemma 9 wehaveaderivation (.' )G1,G2 fM[N/x]: A such that d(.' ,r)=d(.,r)+d(D,r). Hence, we can construct \n. ' ending as: (.' )G1,G2 fM[N/x]:A (sp)n !nG1,!nG2 fM[N/x]:!nA Clearly d(. ' ,r) = r n(d(.,r)+d(D,r)), \nso the conclusion follows. 2. Easy, by de.nition of d. Since it is easy to verify that hrules leave the \nspace weight un\u00adchanged, a direct consequence of the above lemma is the following. Lemma 11. Let (.) \nfM : B and .::|= M .b. Then for each fc C,A|=N .b ' ..if r =rk(.): #\u00df(f)+#if (f)=d(.,r) Now we are ready \nto prove that subject reduction does not increase the space weight. Property 2. Let (.)G f M : s and \nM .\u00dfd * N. Then there exists (. ' )G f N : s with rk(.) = rk(. ' )such that for each r =rk(.): d(.,r)=d(. \n' ,r) Proof. By Lemma 9 and de.nition of d, noting that a reduction inside an if can leave d unchanged. \nThe previous result can be extended to the machine KBC in the following way. Property 3. Let (.) f M \n: B and .::|= M . b.For each con.guration fc Ci,Ai |= Ni .bi ..such that C =.there exist derivations \n(.) f(C[Ni])A :B and (D) f(Ni)A :B such that D is a proper subderivation of . and for each r =rk(.): \nd(.,r)=d(.,r)>d(D,r) 4.2 Proof of PSPACE Soundness As we said in the previous section, the space used \nby the machine KBC is the maximum space used by its con.gurations. In order to give an account of this \nspace, we need to measure how the size of a term can increase during the evaluation. The key notion for \ndoing it is that of number of the sliced occurrence of a variable, which takes into account that in performing \nan if reduction a subterm of the subject is erased. In particular by giving a bound on the number of \nsliced occurrence we obtain a bound on the number of applications of the hrule in a path. De.nition 12. \nThe number of sliced occurrences nso(x,M)of the variable x occurring free in M is de.ned as: nso(x,x)=1,nso(x,y)= \nnso(x,0)= nso(x,1)=0, nso(x,MN)= nso(x,M)+ nso(x,N),nso(x,.y.M)= nso(x,M), nso(x, if M then N0 else N1 \n)= max{nso(x,M),nso(x,N0 ),nso(x,N1 )} A type derivation gives us some informations about the number \nof sliced occurrences of a free variable x in its subject M. Lemma 12. Let (.)G,x :!nAfM : sthen nso(x,M) \n=rk(.)n . Proof. By induction on n. Case n =0. The conclusion follows easily by induction on (.). Base \ncases are trivial. In the case (.) ends by (BE) conclusion follows by nso(x,M) de.nition and induction \nhypothesis. The other cases follow directly from the induction hypothesis remembering the side condition \nG#. in (-E) case. Case n> 0. By induction on (.). Base cases are trivial. Let the last rule of (.) be: \n (.)G fM ' : B (D0 )G fN0 : B (D1 )G fN1 : B (BE) G f if M ' then N0 else N1 : B where x :!nA .G. By \ninduction hypothesis nso(x,M ' ) =rk(.)n and nso(x,Ni) =rk(Di)n for i .{0,1}. By de.nition rk(.)= max{rk(.),rk(D0 \n),rk(D1 )}and since by de.nition nso(x, if M then N0 else N1 ) is equal to max{nso(x,M),nso(x,N0 ),nso(x,N1 \n)}, then the conclusion fol\u00adlows. Let the last rule of (.) be: (.)G,x1 :!n-1A,...,xm :!n-1AfN : \u00b5 (m) \nG,x :!nAfN[x/x1,\u00b7\u00b7\u00b7,x/xm]: \u00b5 where N[x/x1,\u00b7\u00b7\u00b7,x/xm] = M. By induction hypothesis nso(xi,N) = rk(.)n-1 \nfor 1 = i = m. Hence in particular, nso(x,N) =m\u00d7rk(.)n-1.Now, since m=rk(.) and rk(.) = rk(.) it follows \nnso(x,N) =rk(.) \u00d7rk(.)n-1 =rk(.)n and so the conclusion. In every other case the conclusion follows di\u00adrectly \nby induction hypothesis. It is worth noting that the above lemma and the subject reduction property gives \ndynamical informations about the number of sliced occurrences of a variable. Lemma 13. Let (.)G,x :!nA \nf M : s and M .\u00dfd N.Then nso(x,N) =rk(.)n . The lemma above is essential to prove the following remarkable \nproperty. Lemma 14. Let M .Pd and .::|= M . b then for each fc C,A|= P .b ' ..: #h(f) =#(A)|M|d Proof. \nFor each [y := N] .Athe variable y is a fresh copy of a variable x originally bound in M hence M contains \na subterm (.x.P)Q and there exists a derivation (.) x :!nAfP : B. Hence by Lemma 13 for every P ' such \nthat P .\u00dfd * P ' we have nso(x,P ' ) =rk(.)n . In particular the number of applications of h rules on \nthe variable y is bounded by rk(.)n.Since |M|= rk(.) and d = n the conclusion follows. The following \nlemma relates the space weight with both the size of the term and the degree of the derivation. Lemma \n15. Let (.)G fM : s. 1. d(.,1) =|M| 2. d(.,r) =d(.,1) \u00d7r d(.) d(.)+1 3. d(.,rk(.)) =|M| Proof. 1. By \ninduction on (.). Base cases are trivial. Cases (sp),(m),(w),(.I) and (.E) follow directly by induction \nhy\u00ad pothesis. The other cases follow by de.nition of d. 2. By induction on (.). Base cases are trivial. \nCases (sp),(m),(w),(.I) and (.E) follow directly by induction hy\u00adpothesis. The other cases follow by \nde.nition of dand d. 3. By de.nition of rank it is easy to verify that rk(.) =|M|, hence by the previous \ntwo points the conclusion follows.  The next lemma gives a bound on the dimensions of all the components \nof a machine con.guration, namely the term, the m\u00adcontext and the B-context. Lemma 16. Let M .Pd and \n.:: |= M . b. Then for each fc C,A|= N .b ' ..: 1. |A|=2|M|d+2 2. |N|=2|M|2d+2 3. |C|=2|M|3d+3  Proof. \n1. By Lemma 8.1, Lemma 11 and Lemma 15.3. 2. By Lemma 8.2, Lemma 14, Lemma 7.1, Lemma 11 and Lemma \n 15.3: d+1 2d+2 |N|=(#h(f)+1)|M|=#(A)|M|+ |M|=2|M| 3. By Lemma 8.3, the previous point of this lemma, \nLemma 7.2, Lemma 11 and Lemma 15.3: 2d+2 d+12d+2 3d+3 |C|=#(C)2|M|=|M|2|M|=2|M| The PSPACE soundness \nfollows immediately from the de.ni\u00adtion of space(.), for a machine evaluation ., and from the previ\u00adous \nlemma. Theorem 2 (Polynomial Space Soundness). Let M .Pd. Then: space(M) =6|M|3d+3 5. PSPACE completeness \nIt is well known that the class of problems decidable by a Deter\u00administic Turing Machine (DTM) in space \npolynomial in the length of the input coincides with the class of problems decidable by an Alternating \nTuring Machine (ATM) (Chandra et al. 1981) in time polynomial in the length of the input. In (Gaboardi \nand Ronchi Della Rocca 2007) it has been shown that polytime DTM are de.nable by .-terms typable in STA.Analo\u00adgously \nhere we will show that polytime ATM are de.nable by pro\u00adgrams of STAB. We achieve such a result considering \na notion of function programmable in STAB. We will consider the same rep\u00adresentation of data types as \nin STA, in particular data types typable through derivations with degree 0. (We will recall it brie.y \nbut we refer to (Gaboardi and Ronchi Della Rocca 2007) for more details.) Finally we show that for each \npolytime ATM Mwe can de.ne a recursive evaluation procedure which behaves as M. Some syntactic sugar \nLet . denote composition. In particu\u00adlar M . N stands for .z.M(Nz) and M1 . M2 . \u00b7\u00b7\u00b7 . Mn stands for \n.z.M1(M2(\u00b7\u00b7\u00b7(Mnz))). . Tensor product is de.nable as s .t = .a.(s -t -a) -a. In particular (M, N) stands \nfor .x.xMN and let z be x, y in N stands for z(.x..y.N). Note that, since STAB is an af.ne system, tensor \nproduct enjoys some properties of the additive conjunction, as to al\u00adlow the projectors: as usual p1(M) \nstands for M(.x..y.x) and p2(M) stands for M(.x..y.y). n-ary tensor product can be easily de.ned through \nthe binary one and we use sn to denote s.\u00b7\u00b7\u00b7.sn-times. Natural numbers and strings of booleans Natural \nnumbers are . represented by Church numerals, i.e. n = .s..z.s n(z).Terms de.ning successor, addition \nand multiplication are typable by in\u00ad . dexed types Ni = .a.!i(a -a) -a -a. We write N to mean N1. In \nparticular the following still holds for STAB: Lemma 17. Let P be a polynomial and deg(P ) its degree. \nThen there is a term P de.ning P typable as: deg(P )fP :!N -N2deg(P )+1 Strings of booleans are represented \nby terms of the shape .cz.cb0(\u00b7\u00b7\u00b7(cbnz) \u00b7\u00b7\u00b7) where bi .{0, 1}. Such terms are ty\u00ad . pable by the indexed \ntype Si = .a.!i(B -a -a) -a -a. Again, we write S to mean S1. Moreover there is a term len ty\u00adpable as \nf len : Si -Ni that given a string of boolean returns its length. Note that the data types de.ned above \ncan be typed in STAB by derivations with degree 0. Programmable functions The polynomial time completeness \nin (Gaboardi and Ronchi Della Rocca 2007) relies on the notion of .-de.nability, given in (Barendregt \n1984), generalized to different kinds of data. The same can be done here for STAB, by using a generalization \nof .-de.nability to the set of terms .B. Nevertheless this is not suf.cient, since we want to show that \npolynomial time ATM can be de.ned by programs of STAB. In fact we have the following de.nition. n-times \n De.nition 13. Let f : S \u00d7... \u00d7S .B and let every string s .S be representable by a term s. Then, f is \nprogrammable if, there exists a term f ..B, such that fs1 ... sn .P and: f(s1,...sn)= b .. |= fs1 ... \nsn .b Boolean connectives It is worth noting that due to the presence of the (BE) rule it is possible \nto de.ne the usual boolean connectives. . In fact let M and N = if M then ( if N then 0 else 1 ) else \n1 . and Mor N = if M then 0 else ( if Nthen 0 else 1 ) .Then the following rules with an additive management \nof contexts are derived: G fM : B G fN : B G fM : B G fN : B G fM and N : B G fMorN : B Moreover we have \na term not de.ning the expected boolean func\u00adtion. ATMs Con.gurations The encoding of Deterministic Turing \nMachine con.guration given in (Gaboardi and Ronchi Della Rocca 2007) can be adapted in order to encode \nAlternating Turing Ma\u00adchine con.gurations. In fact an ATM con.guration can be viewed as a DTM con.guration \nwith an extra information about the state. There are four kinds of state: accepting (A), rejecting (R), \nuniver\u00adsal (.), existential (.) . We can encode such information by tensor pairs of booleans. In particular: \n We say that a con.guration is accepting, rejecting, universal or existential depending on the kind of \nits state. We can encode ATM con.gurations by terms of the shape: l lrr .c.(cb0 .\u00b7\u00b7\u00b7.cbn, cb0 .\u00b7\u00b7\u00b7.cbm, \n(Q, k)) where cbl 0 .... .cbl and cbr 0 .... .cbr are respectively the left and right hand-side words \non the ATM tape, Q is a tuple of length q encoding the state and k is the tensor pair encoding the kind \nof state. Such terms can be typed as: nn . i2 .Bq+2 ATMi = .a.!(B -a -a) -((a -a)) It is easy to adapt \nthe term described in (Gaboardi and Ronchi Della Rocca 2007) dealing with TM to the case of ATM. In par\u00ad \nticular we have: fInit : Si -ATMi Initial con.guration fTr1 , Tr2 : ATMi -ATMi Transition functions Moreover \nwehaveaterm: . = .x.let x(.b..y.y) be l, r, s in (let s be q, k in k) Kind typable as f Kind : ATMi \n-B2 which takes a con.guration and return its kind. We also have a term . Ext = .x.let (Kind x) be l, \nr in r typable as f Ext : ATMi -B. Assuming that a given con.g\u00aduration is either accepting or rejecting \nExt returns 0 or 1 respec\u00adtively. Evaluation function Given an ATM M working in polynomial time we de.ne \na recursive evaluation procedure evalM which takes a string s and returns 0 or 1 if the initial con.guration \n(with the tape .lled with s) leads to an accepting or rejecting con.gura\u00adtion respectively. Without loss \nof generality we consider ATMs with transition rela\u00adtion of degree two (at each step we consider two \ntransitions). We need to de.ne some auxiliary functions. . a(M0 , M1 , M2 )= let M0 be a1 , a2 in if \na1 then ( if a2 then (a1 , p2 (M1 ) or p2 (M2 ))else (a1 ,p2 (M1 ) and p2 (M2 ))) else (a1 , a2 ) which \nacts as: a(A, M1, M2)= A a(., M1, M2)= M1 .M2 a(R, M1, M2)= R a(., M1, M2)= M1 .M2 Note that for a de.ned \nas above we have the following typing rule: G fM0 : B2 G fM1 : B2 G fM2 : B2 G fa(M0, M1, M2): B2 where \nthe management of contexts is additive. We would now de.ne evalM as an iteration of an higher order StepM \nfunction over a Base case. Let Tr1 M be two closed terms de.ning M and Tr2 the two components of the \ntransition relation. . Base = .c.(Kind c): . StepM = .h..c.a((Kind c), (h(Tr1 M c))) M c)), (h(Tr2 It \nis easy to verify that such terms are typable as: fBase : ATMi -B2 fStepM :(ATMi -B2) -ATMi -B2 Now we \ncan .nally de.ne the evaluation function. Let P be a :!deg(P )N polynomial de.nable by a term P typable \nas f P . N2deg(P )+1. Then the evaluation function of an ATM Mworking in polynomial time P is de.nable \nby the term: . evalM = .s.Ext((P (len s) StepM Base)(Init s)) which is typable in STAB as f evalM :!tS \n-B where t = max(deg(P ), 1) + 1. Here, the evaluation is performed by a higher order iteration, which \nrepresents a recurrence with parameter substitutions. Note that by considering an ATM M which decides \na language L the .nal con.guration is either accepting or rejecting hence the term Ext can be applied \nwith the intended meaning. Lemma 18. A decision problem D :{0, 1} * .{0, 1}decidable by an ATM Min polynomial \ntime is programmable in STAB. Proof. D(s)=b .. evalMs .b From the well known result of (Chandra et al. \n1981) we can conclude. Theorem 3 (Polynomial Space Completeness). Every decision problem D.PSPACE is \nprogrammable in STAB. 6. Related Topic In this section we will discuss some topic which are related to \nthe work we have presented. FPSPACE characterization. FPSPACE is the class of functions computable in \npolynomial space. The completeness for FPSPACE can be obtained by replacing booleans by words over booleans. \nIn particular we can add to STA the type W and the following rules: GfM :W GfM :W GfM :W fE :W Gf0(M):W \nGf1(M):W Gfp(M):W and the conditional GfM :W GfNE :W GfN0 :W GfN1 :W GfD(M, NE, N0, N1):W The obtained \nsystem STAW equipped with the obvious reduction relation can be shown to be FPSPACE sound following what \nwe have done for STAB. Moreover, analogously to (Leivant and Mar\u00adion 1993), completeness for FPSPACE \ncan be proved by consid\u00adering two distinct data types S (Church representations of Strings) and W (Flat \nwords over Booleans) as input and output data type re\u00adspectively. The above is one of the reasons that \nleads us to consider STAB instead of the above system. STAB and Soft Linear Logic. STA has been introduced \nas a type assignment counterpart of Soft Linear Logic (Lafont 2004). STAB is an extension of STAby booleans \nconstants. We now pose our attention to the question of which is the logical counterpart of such extension. \nWe can add to SLL (or de.ne by means of second order quanti.er) the additive disjunction . and the rules \nto deal with it, which in a natural deduction style (Ronchi Della Rocca and Roversi 1997) are: GfA .B \n.,A fC .,B fC GfA .B GfA .B G, .fC GfA GfB We can so de.ne B = 1 .1,where 1 is the multiplicative unit, \nand specialize the above rules to booleans: Gf1 Gf1 (0) (1) Gf1 .1 Gf1 .1 Gf1 .1 ., 1 fC ., 1 fC (E)G, \n.fC It is worth noting that such rules do not change the complexity of SLL. In fact it is essential in \norder to obtain a logical system behaving as STAB to modify the above elimination rule allowing free \ncontraction between contexts Gand .. Hence we can modify it as: Gf1 .1 G, 1 fC G, 1 fC (E)GfC We conjecture \nthat the logical system obtained by adding the above modi.ed rule to SLL behaves like STAB. In order \nto prove the polynomial space soundness for such a system we need to mimic in the cut elimination process \nthe abstract machine mechanism of Section 3. For this reason it could be more interesting introduce proof-nets \nfor such a system and study cut elimination in this framework. A. Technical Proofs A.1 Proof of Substitution \nLemma The technical notion of height of a variable in a derivation will be useful in the proof of the \nSubstitution Lemma. De.nition 14. Let (.)G, x : t f M : s.The height of x in .is inductively de.ned as \nfollows: 1. if the last applied rule of .is: GfN :s x :A fx :A or G, x :A fN :s then the height of x \nin .is 0. 2. if the last applied rule of .is: (.)G, x1 :t,..., xk :t fN :s (m) G, x :!t fN[x/x1, ..., \nx/xk]:s then the height of x in .is the max between the heights of xi in .for 1=i =k plus one. 3. Let \nG ' =G, x :t and let the last applied rule p of .be: '' ' (.)G fM :B (D0 )G fN0 :A (D1 )G fN1 :A G, x \n:t f if M then N0 else N1 :A Then the height of x in .is the max between the heights of x in ., D0 and \nD1 respectively plus one. 4. In every other case there is an assumption with subject x both in the conclusion \nof the rule and in one of its premises ..Then the height of x in .is equal to the height of x in . plus \none. Proof of Substitution Lemma. By induction on the height of x in .. Base cases (Ax)and (w)are trivial. \nThe cases where .ends by (-I), (.I), (.E)and (-E)follow directly from the induction hypothesis. '' :\u00b5 \n' f M :s ' Let .end by (sp)rule with premise (.)G, x then .'' by Lemma 2.3 . which is composed by a subderivation \nending with an (sp)rule with premise (.' ). ' f N : \u00b5 ' followed by a sequence of rules (w)and/or (m). \nBy the induction hypothesis we have a derivation (D' )G ' , . ' f M[N/x]: s ' . By applying the rule \n(sp)and the sequence of (w)and/or (m)rules we obtain (D)G, .fM[N/x]:s. Let .end by (.0)GfM0 :B (.1)GfM1 \n:A (.1 )GfM2 :A (BE) Gf if M0 then M1 else M2 :A with G=G ' , x : \u00b5. Then by the induction hypothesis \nthere are derivations (D0)G ' , .f M0[N/x]:B, (D1)G ' , .f M1[N/x]:A and (D2)G ' , .fM2[N/x]:A. By applying \na (BE)rule we obtain a derivation (D)with conclusion: G ' , .f if M0[N/x]then M1[N/x]else M2[N/x]:A Let \n.end by (. ' )G, x1 :\u00b5 ' ,..., xm :\u00b5 ' fN :s (m) G, x :!\u00b5 ' fN[x/x1, \u00b7\u00b7\u00b7 , x/xm]:s .'' By Lemma 2.3 . \nending by an (sp) rule with premise (.' ). ' f N :\u00b5 ' followed by a sequence of rules (w)and/or (m). \nConsider fresh copies of the derivation .' i.e. (.' j ).j ' f Nj :\u00b5 ' where Nj and .j ' are fresh copies \nof N and . ' (1=j =m). Let xi be such that its height is maximal between the heights of all xj (1 = j \n= m). By induction hypothesis there is a ' '' derivation (Di)G,x1 : \u00b5 ,...,xi-1 : \u00b5,xi+1 : \u00b5 ,...,xm \n: '' ' \u00b5,.i f M[Ni/xi]: s Then we can repeatedly apply induc\u00adtion hypothesis to obtain a derivation (D' \n)G,. ' 1,...,. ' m f M[N1/x1,\u00b7\u00b7\u00b7 ,Nm/xm]: s. Finally by applying repeatedly the rules (m)and (w)the conclusion \nfollows. A.2 Proof of Weighted Substitution Lemma It suf.ces to verify how the weights are modi.ed by \nthe proof of Substitution Lemma. We will use exactly the same notation as in the lemma. Proof of Weighted \nSubstitution Lemma. Base cases are trivial and in the cases where .ends by (-I),(.I),(.E)and (-E) the \nconclusion follows directly by induction hypothesis. If .ends by (sp): d(.,r)=rd(. ' ,r)and d(.,r)=rd(.' \n,r). By the induction hypothesis d(D' ,r) = d(. ' ,r)+d(.' ,r)and applying (sp): d(D,r)=r(d(. ' ,r)+d(.' \n,r))=d(.,r)+d(.,r) If . ends by (BE): d(.,r)=max0=i=2(d(.i,r))+1.By induction hypothesis we have derivations \nd(Di,r) = d(.i,r)+ d(.,r)for 0=i =2. and applying a (BE)rule: d(D,r)= max(d(.i,r)+d(.,r))= max(d(.i,r))+d(.,r) \n0=i=20=i=2 If . ends by (m): d(.,r)= d(. ' ,r)and d(.,r)= rd(.' ,r). Clearly d(.' ,r)=d(.' j,r)so d(D' \n,r)= d(. ' ,r)+md(.' ,r) and since r =rk(.)then: d(D' ,r)=d(. ' ,r)+rd(.' ,r)=d(.,r)+d(.,r) Now the rules \n(m)and (w)leave the space weight d unchanged hence the conclusion follows. Acknowledgments We are grateful \nto the anonymous referees for the numerous de\u00adtailed and fruitful comments and suggestions on the preliminary \nversion of the paper. References Serge Abiteboul and Victor Vianu. Fixpoint extensions of .rst-order \nlogic and datalog-like languages. In Proceedings of the 4th Annual Sympo\u00adsium on Logic in Computer Science \n-LICS 89, pages 71 79, Asilomar, California, 1989. IEEE Computer Society Press. Andrea Asperti and Luca \nRoversi. Intuitionistic light af.ne logic. ACM Transactions on Computational Logic, 3(1):137 175, 2002. \nPatrick Baillot and Kazushige Terui. Light types for polynomial time computation in lambda-calculus. \nIn Proceedings of the 19th Annual Symposium on Logic in Computer Science -LICS 04, pages 266 275, Turku, \nFinland, 2004. IEEE Computer Society Press. Henk Barendregt. The Lambda Calculus: Its Syntax and Semantics. \nElsevier/North-Holland, Amsterdam, London, New York, revised edi\u00adtion, 1984. Ashok K. Chandra, Dexter \nC. Kozen, and Larry J. Stockmeyer. Alternation. Journal of the ACM, 28(1):114 133, 1981. Paolo Coppola, \nUgo Dal Lago, and Simona Ronchi Della Rocca. Elemen\u00adtary af.ne logic and the call by value lambda calculus. \nIn Proceedings of the Typed Lambda Calculi and Applications, 7th International Con\u00adference -TLCA 05, \nNara, Japan, April 21-23, 2005, volume 3461 of Lecture Notes in Computer Science, pages 131 145. Springer, \n2005. Marco Gaboardi and Simona Ronchi Della Rocca. A soft type assignment system for .-calculus. In \nProceedings of the Computer Science Logic, 21st International Workshop -CSL 07, Lausanne, Switzerland, \nSeptem\u00adber 11-15, 2007, volume 4646 of Lecture Notes in Computer Science, pages 253 267. Springer, 2007. \nJean-Yves Girard. Light linear logic. Information and Computation, 143(2): 175 204, 1998. Andreas Goerdt. \nCharacterizing complexity classes by higher type primi\u00adtive recursive de.nitions. Theoretical Computer \nScience, 100(1):45 66, 1992. Erich Gr\u00a8adel, Phokion G. Kolaitis, Leonid Libkin, Maarten Marx, Joel Spencer, \nMoshe Y. Vardi, Yde Venema, and Scott Weinstein. Finite Model Theory and its applications. Springer, \n2007. Neil D. Jones. The expressive power of higher-order types or, life without cons. Journal of Functional \nProgramming, 11(1):55 94, 2001. Jean-Louis Krivine. A call-by-name lambda calculus machine. Higher Order \nand Symbolic Computation, 2007. To appear. Yves Lafont. Soft linear logic and polynomial time. Theoretical \nComputer Science, 318(1-2):163 180, 2004. Daniel Leivant and Jean-Yves Marion. Lambda calculus characterizations \nof poly-time. In Proceedings of the Typed Lambda Calculi and Appli\u00adcations, 1tst International Conference \n-TLCA 93, Utrecht, The Nether\u00adlands, March 16-18, 1993, volume 664 of Lecture Notes in Computer Science, \npages 274 288. Springer, 1993. Daniel Leivant and Jean-Yves Marion. Rami.ed recurrence and computa\u00adtional \ncomplexity II: Substitution and poly-space. In Proceedings of the Computer Science Logic, 8th International \nWorkshop -CSL 94, Kaz\u00adimierz, Poland September 25 -30, 1994, volume 933 of Lecture Notes in Computer \nScience, pages 486 500. Springer, 1994. Daniel Leivant and Jean-Yves Marion. Predicative functional recurrence \nand poly-space. In Proceedings of the Theory and Practice of Soft\u00adware Development, 7th International \nJoint Conference -TAPSOFT 97, volume 1214 of Lecture Notes in Computer Science, pages 369 380. Springer-Verlag, \n1997. Franc\u00b8ois Maurel. Nondeterministic light logics and NP-time. In Martin Hofmann, editor, Proceedings \nof the Typed Lambda Calculi and Ap\u00adplications, 6th International Conference -TLCA 2003, Valencia, Spain, \nJune 10-12, 2003, volume 2701 of Lecture Notes in Computer Science, pages 241 255. Springer, 2003. Virgile \nMogbil and Vincent Rahli. Uniform circuits, &#38; boolean proof nets. In Sergei N. Artemov and Anil Nerode, \neditors, Proceedings of the Symposium on Logical Foundations of Computer Science -LFCS 07, volume 4514 \nof Lecture Notes in Computer Science, pages 401 421. Springer, June 2007. Isabel Oitavem. Implicit characterizations \nof pspace. In Proceedings of the Proof Theory in Computer Science, International Seminar -PTCS 2001, \nDagstuhl Castle, Germany, October 7-12, 2001, volume 2183 of Lecture Notes in Computer Science, pages \n170 190. Springer, 2001. Simona Ronchi Della Rocca and Luca Roversi. Lambda calculus and intuitionistic \nlinear logic. Studia Logica, 59(3), 1997. Walter J. Savitch. Relationship between nondeterministic and \ndeterministic tape classes. Journal of Computer and System Sciences, 4:177 192, 1970. Ulrich Sch\u00a8opp. \nStrati.ed bounded af.ne logic for logarithmic space. In Proceedings of the 22nd Annual IEEE Symposium \non Logic in Com\u00adputer Science -LICS 07, pages 411 420, Wroclaw, Poland, 2007. IEEE Computer Society. \nKazushige Terui. Linear logical characterization of polyspace functions (extended abstract), 2000. URL \nhttp://citeseer.ist.psu.edu/294754.html. Unpublished. Kazushige Terui. Proof nets and boolean circuits. \nIn Proceedings of the 19th Annual Symposium on Logic in Computer Science -LICS 04, pages 266 275, Turku, \nFinland, 2004. IEEE Computer Society Press. Moshe Y. Vardi. Complexity and relational query languages. \nIn Fourteenth Symposium on Theory of Computing, pages 137 146. ACM, New York, 1982.   \n\t\t\t", "proc_id": "1328438", "abstract": "<p>We propose a characterization of PSPACE by means of atype assignment for an extension of lambda calculus with a conditional construction. The type assignment STA<sub>B</sub> is an extension of STA, a type assignment for lambda-calculus inspired by Lafont's Soft Linear Logic.</p> <p>We extend STA by means of a ground type and terms for booleans. The key point is that the elimination rule for booleans is managed in an additive way. Thus, we are able to program polynomial time Alternating Turing Machines. Conversely, we introduce a call-by-name evaluation machine in order tocompute programs in polynomial space. As far as we know, this is the first characterization of PSPACE which is based on lambda calculusand light logics.</p>", "authors": [{"name": "Marco Gaboardi", "author_profile_id": "81367593990", "affiliation": "Universit&#224; di Torino, Torino, Italy", "person_id": "P925379", "email_address": "", "orcid_id": ""}, {"name": "Jean-Yves Marion", "author_profile_id": "81100434172", "affiliation": "Nancy-University: ENSMN-INPL: Loria, Nancy, France", "person_id": "P137000", "email_address": "", "orcid_id": ""}, {"name": "Simona Ronchi Della Rocca", "author_profile_id": "81342492829", "affiliation": "Universit&#224; di Torino, Torino, Italy", "person_id": "PP43138277", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1328438.1328456", "year": "2008", "article_id": "1328456", "conference": "POPL", "title": "A logical account of pspace", "url": "http://dl.acm.org/citation.cfm?id=1328456"}