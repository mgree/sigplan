{"article_publication_date": "01-01-1975", "fulltext": "\n A FAST AND USUALLY LINEAR ALGORITHM FOR GLOBAL FLOW ANALYSIS+ Permission to make digital or hard copies \nof part or all of this work or personal or classroom use is granted without fee provided that copies \nare not made or distributed for profit or commercial advantage and that copies bear this notice and the \nfull citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute \nto lists, requires prior specific permission and/or a fee.&#38;#169; 1975 ACM 0-12345-678-9 $5.00 (Extended \nAbstract) by Susan L. Graham and Mark Wegman Computer Science Division University of California Berkeley, \nCalifornia 94720 S!mN.LY A new algorithm for global flow analysis on reducible graphs is presented. The \nalgorithm is shown to treat a very general class of function spaces. For a graph of e edges, the algorithm \nhas a worst case time bound of O(e log,e) func\u00adtion operations. In programming terms, the number of operations \nis shown to be proportional to e + the number of exit nodes from program loops. Consequently a restriction \nto one-entry one-exit control structures guarantees linearity. It is shown that by relaxing these time \nbounds, a yet wider class of function spaces can be handled. 1. Introduction In analyzing a computer \nprogram for purposes of code improvement, program verification, or error diagnosis, it is necessary to \nbe able to trace (at compile-time) the flow of information through a program. In connection with code \nimprovement tech\u00adniques (such as, for example, common subexpression elimination or moving invariant computation \nout of loops), this analysis is called Global Flow Analysis . Until recently the principal systematic \ntechnique for global flow analysis has been the interval analysis of Cocke and Allen [2,4]. The time \nneeded to analyze the graphical representation of a program using this method is at worst propor\u00adtional \nto the number of edges in the graph times the number of nodes. Kennedy [12] extended inter\u00adval analysis \nto deal with a wider class of global flow problems than had previously been handled by this method. Hecht \nand Unman [8] have presented an itera\u00adtive approach to global flow analysis in which the analysis can \nbe carried out in time proportional to the number of edges in the graph times the maximum depth of the \ngraph. (In the worst case the depth is proportional to the number of nodes in the graph.) Kildall [14] \nhas proposed and implemented several eXteIISiOnS to the Iterative method. The method is investigated \nfurther by Kam and Unman in [11]. Comparisons of the iterative approach with interval analysis appear \nboth in Hecht and Unman [8] and in Kennedy [13]. In [20], Unman presents a somewhat compli\u00adcated algorithm \nfor common sub-expression elimina\u00ad-tion which requires, at worst, time proportional to e log~e for a \ngraph with e edges. Hecht Research sponsored by National Science Foundation Grant GJ-43318. and Unman \n[7,9] also provide several useful cha\u00adracterizations of the class of graphs, termed reducible flow graphs \n, on which interval analysis can be used. Global flow analysis is also discussed in Aho and Unman [1] \nand Schaefer [17]. In this paper, we present a new algorithm for global flow analysis which combines \na modification of interval analysis with a modification of the transformations introduced by Hecht and \nUnman in [7] to characterize reducible flow graphs. For a very general class of information flow problems \nthe algorithm requires time at worst proportional to e log e for a flow graph with e edges. A dif\u00adferent \nanalysis of the algorithm reveals that the time is proportional to the number of edges plus the sum of \nthe number of exits from program loops. Consequently the algorithm is linear for GOTO-free programs and \nvery nearly linear for most well\u00adstructured programs. The paper is organized as follows. In the next \nsection, the basic definitions and results about program flow graphs are presented. In sec\u00adtion 3 we \nintroduce the notions of information pro\u00adpagation problems, fast functions and acceptable assignments. \nIn section 4 we introduce transfor\u00admations T;, T , and T~. We investigate the use of these trans ?ormations \nin solving information propagation problems. Section 5 contains an anal\u00adysis of the number of T;, T , \ncarried out by the af and on a transfo\u00ad rmations gorlthm $ flow graph. In section 6 we outline an efficient \nimple\u00admentation of the algorithm which requires time pro\u00adportional to the number of transformations. \nSec\u00adtion 7 contains further discussion of the method and possible extensions. The present paper is in \nthe form of an extend\u00aded abstract in which the proofs are omitted or briefly sketched. A full presentation \nof these results will be submitted for publication in a journal and the results will be contained in \nthe Ph.D. dissertation of the second author. 2. Basic Notions A directed * G = (N,E) has a set of nodes \nN and a set of * E, where E~NxN. ~is, for all e members of E, e = (u,v) for some u, v members of N. In \nthis paper we will assume that all graphs are directed. Am P= PCIYP1,. ..>P ~ , \\zO isasequence of nodes \nsuch that for a 1 1 between O and k-l,  22 (Pj, Pi+l) is an edge. A path P = PO,Pl,. ..,Pk is a path \nfrom p. to pk of length k. For any iyj such that O<~<j <k, pi is a predecessor Of pj and pj is a suc;essor \nof pi, relative to p. If j=i+l th~n p. is an immediate successor Of Pi. A path ? = PO,P1,. . .5P \u00ad[ \n-anode u if for some 1, o~i: , pi=U. A path p= Po,pl,. . . ,Pk Passes through an edge e = (u,v) if for \nsome i, O<i<k, . pi+l V. An edge (u,v) leaves u and ent~;; ;. A-is a path c = po,pl,. ..,pk where A trivial \n-or a @is a cycle whose k IS Thus, if c is a trivial cycle, PO=P lengt 1. C=po, PI and po=-pl. An edge \n(po;~l) where Po = P1 IS termed a looping edge. A graph with no cycles is acyclic. A flow graph G = (N,E,no) \nis a graph with a distinguished node no in N such that for all v members of N there exists a path from \nno to v. Let G = (N,E,n ) be a flow graph. Node x dominates node y i! and only if every path from no \nto y passes through x. Lemma. Dominance induces a partial ordering on the nodes of a flow graph. An interval \n(I, h) of a flow graph G : (N,E-a maximal set of nodes I con. talned In N with a header node h in I \nsuch that for all edges e-v) in E, ifu~I and v s I then v = h and furthermore all cycles with nodes only \nfrom I pass through h. Theorem (Cocke and Allen). Every flow graph can b-tioned into a unique set of \nintervals in time proportional to the number of edges. Let G = (N,E,no) be a flow graph. Let N be a set \nof nodes, each representing an interval of G and let E be a set of edges between nodes of N such that \n(x,y) is in E ifl) x and y represent different intervals of G and 2) there exists an edge in E from a \nnode in the interval represented by x to the header of the node repre\u00adsented by y. Let n~ be the node \nrepresenting the interval containing no. Then G = (N , E , n~) is the derived @ of G. A flow graph G \nis reducible if there exists an integer k~O and a sequence of graphs is he derived graph of Gi. A flow \n@aph whi~h is not reducible is irreducible. Figure 1 is an example of an irre\u00adducible flow graph. The \nflow graphs in the other figures in this paper are reducible. ~~~!l~~;~~!kan~u~~rth~~ i!=kGO~ .+~k s \nthe ri\u00ad o 6A Figure 1. The paradigm irreducible flow graph Let G = (N,E,no) be a reducible flow graph. \nAn edge (x,y) is a frond if y dominates x. A looping edge is a trivial frond. The present work is based \non the following two theorems of Hecht and Unman on reducible flow graphs. Theorem [Hecht&#38; Unman, \n9]. A flow graph G = (~ is reducible if and only if its edges can be par t ltioned into two sets S1, \nS2 such that O = (N,S1,no) is a directed acyclic flow graph, for any e in S , D = (N,SIUe},no) is nOt \na directed acyclic flow graph, and for every edge (x,Y) of S2, y dominates x. Definition. Let G = (N,E,no) \nbe a flow qrauh. ., If there exists a node v in N and e = (v,v) is a looping edge in E then transfor\u00admation \nTl(G,e) ~ (N,E-{e},no). Thus, T1 elim\u00adinates loops. If there exists a node v in N and the only edge which \nenters v is e = (u, v) then transfor\u00admation T2(G,e) ~ (N-{v},{(x,y)l x,yeN-v and m (x,y)cE or X=U and \n(v,y)c E},no). Thus, transformation T2 eliminates v and replaces all edges leaving v by path-equivalent \nedges leaving u. Figures 2 and 3 are examples of T1 and T2. Theorem [Hecht &#38; Unman, 7]. Let G=(N,E,no) \nbe a flow graph. G is reducible if and only if there exists a sequence of flow graphs GO,Gl, . . ..Gk. \nk>O such that G=GO, G is the trivial graph, an~ for l<i<k, Gi+l = f j(G., e), for some js{l,2} and ~e~ \nsuch that Tj/G,e) is defined. It can be shown that the sequence of flow graphs in the theorem is at least \nas long as the sequence of derived graphs for reduction by intervals. Figure 2. A T1 transformation \n.oiil)on( de Figure 3. A T2 transformation Lemma. Let G = (N,E,no) be a reducible The composition h \n= fog of two functions is flow graph. G contains a nontrivial cycle if and defined for all subsets Xl \nof X by only if E contains a nontrivial frond. h(Xl) = f(g(Xl )). A set of functions F is an information \npro\u00ad 3. Information Propagation Problems -space if 1) F is closed under composi\u00adtion and Intersection, \n2) F is monotonic. In order that our global flow analysis tech-A set of functions F is fast if 1) F is \nanniques be most useful, we wish to demonstrate that information propagation space, ~or all f in Fthey \ncan be carried out efficiently for various and all Xl subsets of X, f(xl)nxl gf(f(xl )). program flow \nproblems. Rather than presenting a separate algorithm for each type of code improve-Lemma. The transitive \nclosure of a set of ment, we characterize the class of problems han\u00admonotonic functions under composition \nand intersec\u00addled by our algorithm, following, in spirit, the tion is an information propagation space. \nunifying approach of Kildall [14]. Evidence for the generality of this class is provided by Fong, Kam, \nand Unman [6]. 1< i ~: :::::!!p~~~~,!: }~li~f~i;~?l~}~or We cannot expect to obtain complete informa-!g~Xi)=Xl \n-{ai}. ret F be the ransltive closure tion for every kind of code improvement technique ot the identity \nfunction and the fi s and gi s un\u00adthat might seem useful. For example, it is impor-der composition and \nintersection. Since the fi s tant to determine what arithmetic operations are and gi s are monotonic, \nF is an information propa\u00adunaffected by program flow and can therefore be gation space. All functions \nin F are of the form determined at compile-time. Suppose there is a f(X1) = X UX2-X , where X1, X2, and \nX3 are statement A:=B+C; in a program. If the value of subsetso$ X. T?us, forany X~CX B is 3 and the \nvalue of C is 5, every time this f(f(Xl))=f(Xl) and F is fast. The functions in statement is executed \nthen we would like to replace F include those using Kills and Gens from many the statement with A:=8; \n. However, since even global flow problems. determining whether a variable equals 1 or O is For many \nglobal flow problems of practical in\u00adundecidable, we cannot detect all such instances. terest, each \nsubset of X can be represented by Consequently, for each program analyzed, we a bit vector of length \n1X1. Function operations restrict our attention to a finite set X of can then be implemented as Boolean \nword operations facts (for example, A=5, C a power of 2), and are consequently very rapid. whose truth \nvalu~s at any point in the program may Next we complete our specification of the or may not be determinable. \nWith each edge (u,v) class of problems we are considering. Given a flowin the program graph is associated \na function graph G = (N,E,n ) and an information propagationwhich maps the subset of facts true at node \nu to space F, we wil ? associate functions of F withthe subset of facts true at node v if the con\u00adedges \nin E by a function M from E to F. Wetrol flow of the program leaves node U along use the notational convention \nthat for any e E E,edge (u,v). The task of our global flow analysis fe = M(e). Let P = PO, Pi,. ... Pk \nbe a path. Weis then to associate with each node in the graph a extend our notational convention to paths \nso thatsubset of X which will always be true just before for k>O fp=f( the node is executed at run-time. \nThe association pk-l,pk)Of(pk-2>pk-3)0 0f(0,1 ) of sets of facts with nodes is termed an If p is the \ntrivial path, then for any Xl ~X, assignment. fp(xl) = xl. Finding a maximal such assignment is at least \nAn information ro a ation roblem is a tuple as difficult as polynomial complete problems [3]. IP= (G,F,x, \n~ where E* how graph, However we can find substantially faster algorithms F is an information propagation \nspace, Xisa if we restrict ourselves to assignments with the set (the domain of the functions in F), \nand M property that if Xl is the set of facts for node is a mapping E+ F. u, X2 is the set of facts for \nnode V, and f Having stated the problem, we are now ready tois the function associated with edge (u,v), \nthen define a class of solutions. ~~~~~~~~ Wenowmake these notions more A fixed oint for an information \npropagation} problem -Y- -1P = G,F,X,M) 1s a function FP: N+2 We first define the sets of functions we \nsuch that for all n in N, e = (m,n) in E,consider. FP(n) qfe(FP(m)) and FP(no) = o.* Defi?l{tion. Let \nX be a set. A function f A ~assi nment to an information propaga\u00admapping subsets of X into subsets of \nX is said tion roblem 1P = G F~,~ is a function S,N:2, + to b-monotonic if for all xl, X2 subsets of \nX such that for all paths p = Po,pl, . . ..pk such that X1 is contained in X2, then f(Xl) where PO= no \nthen S(pk) ~fp($). is contained in f(xz). An acce table assi nment man informationThe intersection h \n= fng of two functions ro a ation ~roblem~-F,X,~ is a functionf and g is defined for all subsets Xl of \nX &#38;such that AS isasafe assiQnmenttoby h(xl) = fag. 1P and for all fixed points FP for IF and for \nt all n in N, FP(n) ~AS(n). The reader familiar with the program verification techniques of Hoare [10] \nand Floyd [5] will find The nota~~;; ;; s N + 2Xdenotes the set of all subsetsrelationships with that \nwork. We do not explore of x. and neN thenthose issues here. S(n) is som~ subse~ of X. Let K be a set \nof functions, such that if f is in K then f is a mapping f: N+2X. We say f is maximal in K if for all \nf in K either f =f or there exists n in N such that f(n) ~f (n). Intuitively, given a set of facts true \njust before a node is executed, a fixed point for that node yields a set of facts true upon entry to \nany successor of that node. A safe assignment asso\u00adciates with each node a set of facts that are prov\u00adably \ntrue at that point in the program. An accept\u00adable assignment is safe, and in addition, is at least as \ngood as a maximal fixed point. Example. Consider the information propagation problem of Figure 4, letting \nal stand for 1=0 , a2 for Y=5 , and a3 for Z=5 . Let F be the transitive closure of the functions in \nthe range of M under composition and intersection. Let FP be the maximal fixed point for this example. \nThen FP(no) = ~, FP(nl) = 0, FP(n2) = {al}, FP(n3) = O, FP(n4) = 0, Fp(n5)=@ and Fp(n6) = $. Let S be \na maximal safe assignment. Then S(no) =$, S(nl) =0, S(n2) = {a }, S(n ) $, S(n4) = $, S(n5) = {a2,a3}, \nS(n6] =@. 3 - Both FP and S are acceptable assignments. The function mapping each node to $ is a fixed \npoint and a safe assignment, but it is not an acceptable assignment. Notice that the safe assignment \ngiven above is not a fixed point, since (n5)~f(n4,n5)(S(n4)). It is easily shown that every fixed point \nis a safe assignment. /read(I)\\ read(Z) no read(Y) v Yes n2 Z:=5 No rint( No ) stop 5 X = {al,a2,a3} \nFor any Xl ~X, define M as = X1-{al}-{a2}-{a31 (no,n~) (Xl) (Xl)=Xlu{al} (n] ,n2) f(n, ,na)(xl) = 1 \n(n~,n4) (x, ) =Xlu{a3} (Xl) =Xlu{a2} (n3,n4) (Xl u{a2} if a3e X1 = Xlu{a3} if a2EX1 (n4,n5)(x, ) i \notherwise xl )(x, ) =x] (n49n6 F gure 4. Flow graph and functional mapping of information propagation \nproblem In dealing with fast information propagation spaces, the fact that X is finite is never used \nand is therefore inessential in theory although it can lead to a more efficient implementation. sup\u00adpose \nwe have an information propagation space all functions of which map finite sets to finite sets. Then \neven if the set X of facts is infinite, only a finite subset are necessary for any flow graph. Such a \nfinite subset is easily found by the following technique. Construct an assignment B to the nodes by the \nfollowing method: Set B(no) = 1$1 While B(v) is undefined for some v, if (u,v) is in E and B(u) is defined, \nset B(v) = f(u, v)(B(u)). The set X = UNB(U) is finite and if S is any safe assignment for IP = (G,F,x,M) \nthen for every USN, S(U) gx . Thus for any u, S is a safe assignment for IP = (G,F,X ,M) if and only \nif S is a safe assignment for 1P. 4. The Transformations In section 3 we introduced the notions of an \ninformation propagation problem and an acceptable assignment for such a problem. In this section and \nthe next, we develop an algorithm for finding an acceptable assignment for an information propaga\u00adtion \nproblem on any reducible flow graph. In this section we describe three transforma\u00adtions, T;, T~, and \nT:, on flow graphs. We show that given an information propagation problem on a flow graph, a graph transformed \nby T;, T~, or T~ has a corresponding information propagation pro\u00adblem. From an acceptable assignment \nfor the trans\u00adformed graph we can find an acceptable assignment for the original graph. If the information \npropa\u00adgation space is fast then this process requires at most three functional operations (application \nof a function to an argument, composition of two func\u00adtions, or intersection of two functions). If the \nspace is not fast, up to loglX/t compositions of functions can be required for a T; transforma\u00adtion, \nwhere X is the set of facts of the infor\u00admation propagation problem. It follows from these results that \nif we can reduce a flow graph to one node using these trans\u00adformations, then from an acceptable assignment \nfor the one-node graph we can find an acceptable assignment for the original graph in time propor\u00adtional \nto the number of T;, Ti, and Ti trans\u00adformations needed. We show in section 5 that the number of such \ntransformations is 0(1 Ellog IEl) where IEI is the number of edges in the original graph, and that the \nnumber of T; transformations is at most IEI. Consequently we can find an acceptable assignment for an \ninformation propaga\u00adtion space with fast functions in O(lElloglEl) functional operations and in 0(1 Ello91El \n+ \\ElloglXl) otherwise. We now introduce the flow graph transforma ~ tions. Definition. Let G = (N,E,no) \nbe a flow graph. If for some v in N there exists an edge e = (v, v) in E and there exists a unique u \nin N-{v} such that (u,v) is in E then transformation Tj(G,e) = (N,E-{e},no). For any set X, 1X1 denotes \nthe number of ele\u00adments in X. Thus T;, when defined, has the same effect as transformation T1 of Hecht \nand Unman. .mfinition. .Let G = (N,E,no) be a flow graph. If for some v in N there exists a unique u \nin N-{v} such that (u,v) is in E and there exists any e = (v,w) in E, where v # w, then transformation \nT~(G,e) = (N ,E ,no) where, if v has no immediate successors other than w, then N = N-{v}, E = Eu{(u,w)} \n-{(u,v), (v,w)} and otherwise N = N, E = EU{(U,W)}-{(V,W)}. Thus, (v,w) is removed and replaced by (U,w). \nIf there are then no nontrivial paths from v is removed from N and (u,v) is removed ~~om E. Given a node \nv entered by a unique edge (u,v), transformation T2 of Hecht and Unman connects u to all immediate successors \nof v and discards v and the edge entering v. In con\u00adtrast, each application of transformation T~ con\u00adnects \nu to one of the immediate successors of v, discarding v and the edge entering v only when the last immediate \nsuccessor is eliminated. Be fini*ion. Let G = (N,E,no) be a flow graph. G is a fan graph if every non-looping \nedge 1eaves no Figure 5. A fan graph Definition. Let G = (N,E,no) be a fan graph. If for some v in N, \ne = (no,!) is the only edge entering v, then transformation l~(G,e) = (N-{v},E-{e},no). Since the node \nv has no immediate successors, transformation T~, when defined, has the same effect as transformation \nT2 of Hecht and Unman. We next relate these transformations to ac\u00adceptable assignments to information \npropagation problems. Lemma 4.1. Let. IP= (G, F,X, M) be an informa\u00adtion propagation problem, where \nG = (N,E,no) and F is fast. Let G = Ti(G,e) be defined for some e in E. An information propagation problem \n1P .= (G , F,x, M ) can be found using only one com\u00ad position of functions and one intersection of func\u00adtions \nsuch that any acceptable assignment to 1P is an acceptable assignment to 1P.  e= ?~ht o?;?:Z;V, Le l;: \nonly other edge entering v. Define M such that : _(;~)e~lM(e )nM(e)OM(e ) and for all a in ,, M:(a) = \nM(a). Show that this satisfies the lemma. Notice that, unlike the previous lemma, the next two lemmas \ndo not assume a fast information propagation space. Lemma 4.2. Let IP=(G,F,X,M) be an informa\u00ad tion propagation \nproblem, where G=(N,E,no). Let G = T~(G,e) be defined for some e in E. An information propagation problem \n1P = (G ,F,X,M ) can be found using at most one intersection of functions and one composition of functions \nsuch that by at most one functional application we can obtain an acceptable assignment to 1P from an \nacceptable assignment to 1P . be the unique edge In ~hich enters v and let e = (v,w), v # w be an edge \nin E which leaves v. Let e = (u,w) and let G = (N ,E ). Define M such that =&#38;%%W&#38; OrsOmevin \n N :et M(e )nM(e)0M(e ) if e EE M (e ) = { M(e)OM(e ) otherwise and for all a in E -{e }, M (a) = M(a). \nIf e $E , then for any acceptable assignment AS to 1P let AS(v) = f(u,v)(AS (u)). Show that this satisfies \nthe lemma. D needed to find 1P only if IE I < IEI. Afunc\u00ad tional application is needed to obtain an accept\u00ad \nable assignment to 1P from an acceptable assign\u00adment to 1P only if IN I < INI. Follows from construction \nin proof of Lemma%? ! Lema 4.4. Let lP= (G,F,X,M) be an informa\u00adtion propagation problem, where G=(N,E,no) \nis a fan graph. Let G =T.j(G, e) be defined for some e in E. An information propagation problem 1P = \n(G , F, X, M ) can be found using no function operations. By one functional application we can obtain \nan acceptable assignment to 1P from an acceptable assignment to 1P . Sketch of Proof. For some v in N-{no}, \n1et be the unique edge in E which enters Ino v) v. For all e in E-{e}, let M (e ) = M(e ). For anv acce!Jtable \nassignment AS to 1P let AS(v) L f(n (Asf(no)j. Show that this satisfies o >~) the lemma. By combining \nthese three lemmas and the corollary, we get Theorem 4.1. Let IP=(G,F,X,M) be an informa\u00adtion propagation \nproblem, where G = (N,E,no) and F is fast. Let T be the number of T; and Tj transformations needed to \nreduce G to a graph with the single node no. Then we can find an acceptable assignment to 1P in INI applications \nof functions, at most IEl intersections of func\u00adtions, and T compositions of functions. Thus for any \ninformation propagation problem 1P = (G,F,X,M) where F is fast it remains only to analyze the number \nof T;, T?, and Tj trans\u00adformations necessary to reduce G in order to know how many function operations \nare needed to find an acceptable assignment. We do this analysis in the next section. In order to find \nthe number of function opera\u00adtions needed to find an acceptable assicmment if F is not fast, it suffices, \nby Lemma 4.2, to examine the number of operations required for each Ti transformation and the number \nof T transforma\u00adtions needed to reduce G. The lat~er issue is resolved in section 5. We answer the former \nby the following lemma. Lemma 4.5. Let IP=(G,F,X,M) be an informa\u00adtion propagation problem, where G \n= (N,E,n ) and X is a finite set. Let G = Ti(G,e) be ~efined for some e in E. An information propagation \nproblem 1P = (G ,F,X,M ) can be found using only log21Xl+l compositions of functions and two intersections \nof functions such that any acceptable assignment to 1P is an acceptable assignment to 1P. ,, fl:+;r:;:re \n, :::e ;;::e ), f~(Xl) = fe(X1)fi Xl and f~og]xl denotes the lX1-term composition f:of;o... of; . D \n5. Reduction of Flow Graphs In this section we analyze the number of T;, T~ , and T transformations \nnecessary to reduce a flow grap i to a graph with one node, if such reduction is possible. This result \ncombined with the results from the previous section give us the number of function operations needed \nfor global flow analysis. The study of the number of transformations proceeds in several stages. We first \nexhibit an algorithm for reducing a reducible flow graph using these transformations. We then prove the \ncorrectness of the algorithm, at the same time proving certain characteristics of its behavior. We then \ngive two analyses of the number of trans\u00adformations carried out by the algorithm. The first analysis \nshows that the number of transfor\u00admations is at worst 0(lEllog21 El) where E is the set of edges of the \noriginal graph. The second analysis, while being cruder than the first SinCe it yields an O(INIIEI) worst \ncase, reveals that the algorithm is linear or nearly linear on the graphs for most programs. The algorithm, \nwhich we refer to as Algorithm A, is written in a higher-level Algol-like lan\u00adguage. In section 6, we \nshow that the algorithm can be refined in such a way that the time taken to find an appropriate sequence \nof transformations is proportional to the number of transformations. The heart of the algorithm is a \nsuccession of calls on a procedure Reduceset. At every call from label B of the program, Reduceset is \npassed a set S of nodes similar to an interval and a header h. The set S differs from an interval in \nthat 1) a node in the set may have a looping edge and 2) there is a path from every node to the header \n(hence the graph is strongly connected). Reduceset eliminates all nontrivial cycles pass\u00ading through \nnodes other than the header. At the final call of Reduceset at label C the entire graph, now acyclic \nexcept possibly for a looping edge through no is passed to Reduceset and reduced to a fan graph. The \nfinal while loop re\u00adduces the graph to one node. Within Reduceset, applicable transformations on the \nedges connecting the nodes of S can be made in arbitrary order. In fact, one need not even follow a Ti \ntransformation by a T~ trans\u00ad formation as the algorithm indicates. (We have written the algorithm this \nway only to aid the exposition. ) We next state the algorithm. Notice that Reduceset changes only edges \nbetween nodes in S. However procedure T$ must inspect other edges of the graph in order to determine \nwhether to delete a node. Algorithm A Procedure T; (E: set of edges; v: node of looping edge); begin \nE:=E-{(v,v)} end; Procedure T (N: set of nodes; E: set of edges; h,v,w: no5es of edges (h,v) and (v,w) \nin E); begin E:=EU{(h,w)}-{(v,w)]; if v has no immediate successor in G=(N,E) then begin N:=N-{v}; E:=E-{(h,v)} \nend; end; Procedure Reduceset (S: set of nodes; h: node in S) begin while there exists an edge (v,w) \nin E with V,WCS, vfw such that if (u,v)sE then u=h oru=v do begin choose anv such (v.w); if (v,v)~E then \nTi(E~v); T~(N,E,h,v,w) end; end; Procedure T~ (N: set of nodes; E: set of edges; no,v: nodes of edge \n(no,v)); begin E:=E-{(no,v)}; N:=N-{v} end; begin comment: Main Program; while G contains a nontrivial \nfrond do begin T:={ul(v,u) is a nontrivial frond}; h:=a node in T not dominated by any other node in \nT; S:={vcNlh dominates v and there is a path p from v to h such that all nodes on p are dominated by \nh}; B: Reduceset(S,h) end; c: Reduceset(N,nQ); while N-{no} 1s nonempty do begin choose any v in N-{no}; \nif (v,v)EE then Tj(E,v); T~(N,E,no,v) end; end. In the following Reduceset. example each step is a call \nto Examp h . a n Step 1 T = {a,b,c,d} Reduceset is called with S={d,e}, h=d T~(N,E,d,e,d) replaces edge \n(e,d) by edge (djd) Step 2 T = {a,b,c} Reduceset is called with S = {c,d,e}, h=c T;(E,d) deletes edge \n(d,d) Tj(N,E,c,d,e) replaces edge (d,e) by edge (c,e) Tj_(N,E,c, e,c) replaces edge (e,c) by edge (c,c) \nStep 3 T = {a,b] Reduceset is called with S = {b,c,d,e}, h=b Ti(E,c) deletes edge (c,c) T~(N,E,b,c,e) \nreplaces edge (c,e) by edge (b, e) Tj(N,E,b,e,b) replaces edge (e,b) by edge (b$b) The graph T = {a} \nReduceset is called.,. with S = {a,b,c,d,e,f,g,h}, h=a Tj(E,b) deletes edge (b,b) T~(N,E,a,b,e) replaces \nedge (b,e) by edge (a, e) T~(N,E,a,e,a) replaces edge (eja) by edge (a,a), deleting edge (b,e) and node \ne T~(N,E,a,b,c) replaces edge (b,c) by edge (a,c), deleting edge (a,b) and node b T~(N,E,a,c,d) replaces \nedge (c,d) by edge (a,d), deleting edge (a,c) and node c T~(N,E,a,d,f) replaces edge (d,f) by edge (a,f) \nT~(N,E,a,d,g) replaces edge (d,g) by edge (a,g) T~(N,E,a,d,h) replaces edge (d,h) by edge (a,h), deleting \nedge (a,d) and node d T~(N,E,a,f,a) replaces edge (f,a) by edge (a,a), deleting edge (a,f) and node f \nT~(N,E,a,g,a) deletes edges (g,a) and (a,g) and node g T~(N,E,a,h,a) deletes edges (h,a) and (a,h) and \nnode h The final graph is The next few lemmas are used in proving Theorem 5.1 and will serve as an outline \nof that proof. It follows from the second theorem of Hecht and Unman quoted in section 2 that Ti and \nT: transform a reducible flow graph to a reducible flow graph. In Lemma 5.1 we establish the same result \nfor T~. Lemma 5.1. Let G = (N,E,no) be a reducible flow graph such that, for some U, V, w in N, U+v, \nV+w, E contains edges e = (v,w) and e = (u,v), where (u,v) is the only edge which enters v. Then G = \nTj(G,e) is a reducible flow graph. =. Omitted. D The next lemma is used in proving termination of the \nalgorithm. Lemma 5.2. Let G = (N, E) be a directed graph. If every node of G is entered by some edge \nwhich is not a looping edge, then G contains a non-trivial cycle. -. Induction on INI. Corollary 5.3. \nLet G = (N,E,n ) be a flow graph with no non-trivial cycles. T~en either N = {n } or there exists x~N, \n~fno, such that ~nn,x) and possibly (x,x) are the onlv . edges entering x. Next we establish the properties \nof the argu\u00adments of Reduceset. Lemma 5.4. Let G = (N,E,n ) be a reducible flow graph with a nonempty \nset ? = {uEN\\ for some VSN, (v,u) is a nontrivial frond of G}. Let h be any node in T not dominated by \nanother node in T. Define S = {vsNI h dominates v and there exists a path p from v to h such that all \nnodes of p are dominated by h}. Let Es = {(x,y)c El x,y&#38;S}. Then 1) There are no nontrivial fronds \nin E which enter nodes in S other than h. 2) There is a path in E from h to every node in S. 3) G.j = \n(S,ES,h) is a reducible flow graph.+ Omitted. D E2z.f. The following lemma shows that procedures T; \ncorrespond to transformations ?~d~$that Reduceset hasthedesire~~f;?$on a flow graph. Lemma 5.5 (Correctness \nof Reduceset). Let G = (~ and Gs = (S,ES,h) be reducible flow graphs suc~that SCN, Es={(x,y)c El x,ys \nS} and no nontrivial frtinds in E enter nodes in S other than h. After Reduceset(S,h) is carried out, \nlet N be the resulting set of nodes and E be the resulting set of edges. Let E~ be the set of edges (x,y) \nin E such that x and y are in S. Then 1) Every execution of procedures Ti and T; satisfies the conditions \nfor transformations Ti and T . 2f Ti and T} are called exactly as many times as the number of edges (x,y) \nin Es, such that x+h. (Consequently Reduceset always ter\u00adminates. ) 3) After completion of Reduceset(S,h), \nG = (N ,E ,no) is a reducible flow graph, all edges in E$ leave h, E contains no new non\u00ad trivial fronds, \nand lE 1~ IEI. =. Omitted. D As a consequen~of Lemma 5.5, Algorithm A could be rewritten so that set \nT is computed only once, at the beginning of execution, and after each call of Reduceset, h is removed \nfrom T. Having established that Reduceset is cor\u00adrect, the correctness of Algorithm A easily follows. \nTheorem 5.1. Algorithm A terminates and reduces any reducible flow graph G = (N,E,no) to a graph with \nthe single node no. m. Omitted. D Now we are ready to analyze the number of Ti, T~ , and T transformations \nnecessary to reduce a reducible f f ow graph to a single node. We will ob\u00adtain our bound by choosing \na particular ordering on the edges in executing Reduceset and then showing that that ordering is unessential. \nTo carry out GS is a region in the sense of [9]. this analysis, we must introduce a few more con\u00adcepts. \nDefinitions. A flow graph G = (N,E,~o) is a tree rooted at no if for every node x In N-{no] there is \nexactly one node in E which enters x. If G = (N,E,nQ) is a tree rooted at no and G1 = (Nl, El, nl) 1s \na tree rooted at nl such that N1 ~N and El SE, then G1 is a subtree of G. Let G = (N,E,nQ) be a flow \ngraph. A~\u00adning tree (m @ IS a flow graph G =(N,E ,no), E CE such that G is a tree rooted at n.. A cro~s-l \nink of G is an edge (xjy) of E s~ch that x does not dominate y and y does not dominate x. The definition \nof a frond outside the domain of reducible graphs is dependent on a parti\u00adcular spanning tree of a graph. \nA frond is an edge (x,y) such that y dominates x in the given spanning tree. A reverse frond is an edge \n(x,y) such that x dominates y. If a graph is reduci\u00ad ble then the fronds are the same no matter which \nspanning tree is used. Let x, y be nodes of a tree such that dominates y. Let Uo, Ul, U2,. ... Uk be \nthe path from x to y in the tree where x= UO, (There can be only one such path.) The tra;~f~$~ mation \ncfind(x, ) replaces edges (u2,u),*uk) byedges (x,L11~?1!13),..., (x,uk?, there~y transforming thetree \ntoanother tree. The cost of cfind(x,y) is k-1, which is the number of edges changed. Paterson [15] states \na less general theorem but his proof supports the following: Theorem (Paterson s Theorem). If a tree \nhas less than or equal to e edges and less than or equal to e c-finds are performed then the sum of the \ncosts of the c-finds is no more than O(e loge). We will show that Algorithm A is equivalent to performing \nno more than e c-finds on a spanning tree of a flow graph G = (N,E,no). We will obtain a bol~nd on the \nnumber of Ti and T; transformations, by appealing to Paterson s theorem. In order to invoke Paterson \ns theorem, which is about trees, we will show how Algorithm A transforms a spanning tree of a flow graph \nas it transforms the graph. For that purpose we need the following two lemmas. Lemma 5.6. Let G = (N,E,no) \nand Gs = -be reducible flow graphs such that SCN, Es = {(x,Y)s EI x,ysS}, no nontrivial frtind of E enters \na node of S other than h, and there is a path in Gs from every node to h. Then any spanning tree for \nG contains a subtree rooted at h which is a spanning tree for Gs. E+?Q,f. Omitted. D Lema 5.7. Let G \n= (N,E,no) and Gs = l-be reducible flow graphs such that SCN, Es = {(x,Y)c EI x,YsS}, no nontrivial fr~nd \nof E enters a node of S other than h, Gs contains a path from every node in S to h, contains at least \none nontrivial cycle. ~~~ :$= (N, E ,no) be a spanning tree for G. Then there is some node x in S-{h} \nsuch that 1) E contains a cross-link or a non-trivial Theorem 5.3. Let 1P = (G,F,x,M) be an frond which \nleaves x and enters a node in S. information propagation problem, where G= (N,E,no). 2) There is a path \nU0,ul,112,. ..,Uk in G If F is fast. then we can find an acceptable where h = Uo, X = Uk, assignment \nto 1P in INI applications of func\u00ad3) For O<i~k, n~n~r~~~-l ~fii~k;on~~r;-s tions, at most El intersections \nof functions., vial frond in E enters uj. and O(lEllogZIE ) compositions of functions. If F is not fast, \nthen we can find an acceptable Omitted. El assignment to 1P in INI applications, at most IE +INI intersections \nof functions, and We next define a sequence of Tj and T~ 0( Ellog21E\\ +INllog21Xl) compositions. transformations \ncalled a collapse. It will turn out that a collapse on a flow graph is equivalent =. Follows from Theorem \n4.1, Lemma 4.5 to a cfind on a spanning tree of the graph. We and Theorem 5.2. D then show that we can \nreduce any reducible flow graph to a fan graph by a sequence of collapses. We can expect that a typical \ncollection of program flow graphs will tend to exhibit a more Definition. Let G = (N,E,no) be a flow \nspecial set of characteristics than the total set graph and let G = (N,E ,no) be any spanning tree of \nreducible flow graphs we have just studied, par\u00adfor G. Let x. v be nodes in N. X+V. such ticularly in \nview of the current ideas about well\u00adthat either there-exists a path in G %~om structured programs. \nConsequently we again analyze x to y or, for some z in N, there exists a the number of transformations \nof Algorithm A, this path in G from x to z and an edge (z,y) in time with respect to programming language \nissues. zzz!f - E. In either case let uo,LIl, L12,. ..,uk be the We define two characterizations of \niterationspecified path from x to y, where X=UO and loops in programs. We then show that the number ofy=uk. \nThe transformation collapse(x,y) 1s a T;, T~, and T$ transformations needed to reduce sequence of applications \nof T~ and, if necessary a reducible flow graph is no more than O(IEI + theTj , to the edges (ul,u2),(u2,u3),. \n..,(ul,y)y) number of exits from program loops). Finally, wewhich replaces them respectively by (x,u2),(x,u \n), discuss the implications of this result. . . . . (X,y). It is defined only if the sequence o+ applications \nof Tj and T~ is defined. Definition. Let G = (N,E,no) be a reducible flow raph. For each n in N, p-loop(n) \n= Lemma 5.8. Let G, Gs, and G be defined {VEN 7 n dominates v and there is a nontrivial pathas in Lemma \n5.7. Then there exists a sequence of p from v to n containing only nodes dominated bychoices of nodes \nand edges in the while loop of n}. c-loop(n) = {vcNI n dominates v and there isReduceset which corresponds \nto a sequence of a nontrivial path p from v to n containing onlycollapses such that each collapse eliminates \na nodes dominated by n and passing through only onenontrivial frond or a cross-link of G. frond}. c-number(n) \nis the number of nodes in c-loop(n) which are left by edges which enterE?zQf. Omitted. D nodes not in \np-loop(n) and e-number(n) is the number of nodes n such that n s c-loop(n ) and Lemma 5.9. Let G = (N,E,no) \nbe a reducible n is left by an edge which enters a node not inflow graph. G can be reduced to a graph \nwith no p-loop (n ). nontrivial fronds in IEI collapses. Intuitively if non-empty, p-loop(n) corres\u00adEx!Q.f. \nFollows from Lemmas 5.5 and 5.8. D ponds to a program loop starting from the statement represented by \nn. Clearly for any node n,Since collapses on flow graphs correspond to c-loop(n) ~ p-loop(n). If non-empty, \nc-loop(n)cfinds on their spanning trees we get corresponds to a program loop without its inner loops \nthat do not pass through n. For any node Theorem 5.2. Let G = (N,E,no) be a reduci\u00adn, c-number(n) is \nthe number of exit nodes fromble flow graph. The number of Tj, T~, and T~ the program loop dominated \nby n and e-number(n)transformations carried out by Algorithm A to is the number of program loops exited \nfrom node n. reduce G to a flow graph with the single node no is no more than INI, 0(1 Ellog,l El), \nand INI Figure 6 contains an example illustrating respectively. these concepts. We obtain the following \nconsequences fromSketch oj?%oof. It follows from Lemma 5.9, these definitions. Paterson s theorem, and \nshowing the equivalence of numbers of collapses and numbers of cfinds Lema 5.10. Let G = (N, E,no) be \na reduciblethat all nontrivial cycles can be eliminated in flow graph. Then ~ c-number(n) = n~Ne-number(n). \n0(1 Ellog, lEl) T transformations. It follows ncN from Lemma 5.5 t 2at this bound holds independent of \nthe order in which edges are chosen within Follows easily from definitions. D E.Q!2.C Reduceset. It \ncan be shown that a graph with no nontrivial cycles can be reduced in O(IEI) T~ Lemna 5.11. Let G = (N,E,no) \nbe a reducible transformations and at most IN I T$ transforma-flow graph. The number of T+ transformations \ntions. A total of at most lN\\ Tj transforma-carried out by Algorithm A to reduce G is at most tions is \nneeded. D IEI +n~Nc-number(n). Combining this with the results of section 4 Sketch of Proof. Induction \non ~ c-number(n),we get ncN u  o -=-0 nl e T 6 k+2> + e . . 1 0 2k> J 2k+l 1 . . . o a b c d e f \n9 h p-loop -\u00adabcdefgh bcdefg cdef def -\u00ad. . .\u00ad-\u00ad c-loop -\u00adabcdefgh bcdefg cde def -\u00ad-\u00ad-\u00ad-\u00ad c-number \no 1 3 1 2 0 0 0 0 e-number o 0 0 0 0 3 2 1 1 3k (5 ,/ 1 3k+l . . . I j .\u00ad -\u00ad 0 0 Figure 6. Ixampl e \nFigure 7. Example for Lemma 5 .11 Since we have shown in Theorem 5.3 that it is only the number of T~ \ntransformations that can be non-linear in the size of the flow-graph, Lemma 5.11 provides a convenient \nmeasure of the time needed for global flow analysis for particular classes of programs, even though, \nas Figure 7 illustrates, the measure is somewhat coarse. Consider the flow graph shown in Figure 7. If \nIN I is the number of nodes and IEI is the number of edges, then IEI < 21NI. However since there are \napproximately lN1/4 exit nodes, each from approximately /N1/4 program 100PS, it follows from Lemma 5.11 \nthat the number of T~ transforma\u00adtions needed by Algorithm A is no more than 0( IN12). However, it is \neasily seen that Algorithm A performs only O(IEI) transformations on this graph. Using notions of graph \ngrammars similar to those found in [7], we can analyze the forms of program graphs obtained from various \ncombinations of programming language control structures. For example suppose we consider a programming \nlanguage containing assignment statements, possi\u00adbly-nested conditional statements, while state\u00adments, \nrepeat-until statements, case statements and for statements~his is essent~y what is found in PASCAL [22], \nomitting gc&#38; statements and proce\u00addures.) It can be rather easily shown that for such a language \n1) the number of edges in a program flow graph is proportional to the number of nodes, 2) every program \nflow graph is reducible, and 3) there is (at most) one exit node from every pro\u00adgram loop. Consequently \nthe time required for glo\u00adbal flow analysis is proportional to the number of nodes (i.e. roughly to the \nsize of the program). If we add a halt statement, or any statement which, effectively causes an exit \nfrom the entire program, such a statement appears in a program flow graph as a node with no successors. \nConse\u00adquently, it turns out that such nodes cannot affect the non-linearity of Algorithm A. It is only \nwhen a programming language includes an unrestricted ~, a labelled exit as is found in Bliss [23], or \nsome equivalent facility to make multiple jumps out of nested loops that the possibility of non\u00adlinearity \noccurs. Even for such a language, we can probably expect, in practice, that the number of such jumps \nbe reasonably small relative to the size of the program. Furthermore, their effect on the complexity \nof the algorithm is additive rather than multiplicative. 6. Implementation We have shown that the number \nof transforma\u00adtions to reduce a reducible flow graph is 0(1 E1-log21 E\\) where IEI is the number of edges \nin the graph and that consequently the number of function operations for many global flow problems also \nhas this bound. We have also argued infor\u00admally that for actual programs the number of opera\u00adtions is \napproximately linear in the size of the program (i.e. the number of nodes). In order to argue that the \nmethod is indeed of practical interest, we now indicate how one might implement the algorithm so that \nthe time required on a ran\u00addom access machine for finding the transformations and doing other bookkeeping \nis on the order of the number of transformations. Figure 8 summarizes the data structures used in the \nimplementation. We will represent the flow graph G = (N, E,no) by an adjacency structure; namely, with \neach node x we will associate an unordered adjacency list of the nodes y such that (x,Y) is an edge of \nthe graph. The nodes are numbered from 1 to INI and can be addressed directly. The key to an efficient \nimplementation is the following notion. Definition. An s-numbering of the nodes of a graph is an assignment \nof integers to the nodes such that for any non-looping edge (x,Y), if (x,y) is a frond, then s-number(y) \n< s-number(x) and, if not, then s-number(x) < s-number(y). Tarjan [18] gives an algorithm which produces \nan s-numbering of the nodes in a graph in time proportional to the number of edges. He also shows the \nusefulness of adjacency structures and s-num\u00adbering for a variety of graph algorithms. An s-numbering \nhas the property that for any nodes x> Y3 if x+y and x dominates y, then s-number(x) < s-number(y). The \nfirst step in the implementation is to produce an s-numbering of the nodes. We list the nodes in their \ns-number ordering. The ordered list can be constructed in linear time by a radix sort, creating an array \nof pointers to the nodes and adjacency lists, indexed by s-numbers. Next we create a reverse adjacency \nstructure in which each node x points to two lists. The first is a list of nodes y such that (y,x) is \nan edge which is a frond; the second is a list of nodes y such that (y,x) is an edge which is not a frond. \nThus for each node x, the lists to which x points indicate the edges entering x. Since a frond can be \ndetermined by the fact that it goes from a node with a higher s-number to one with a lower s-number, \nthe reverse adjacency structure can be created in linear time. The next step is to find the set S and \nnode h which are arguments to Reduceset. We scan the list of nodes in decreasing s-number order. We let \nh be the first node encountered which is entered by a nontrivial frond. This h cannot dominate any node \nwith an entering frond, since such a node would have to have a higher s-number. Having found h, we find \nthe subgraph C&#38;c\\S,ES,h) by what is essentially a depth-first Recall that for any frond (x,h), x \nmust be in S since by definition of frond, h domi\u00ad nates x, and the edge (x,h) provides a path from x \nto h. Also, for any node x in S-{h}, any node entering x leaves a node in S. We mark each node as its \nmembership in S is discovered. Beginning with h and using the reverse adjacency structure, after adding \na node x to S, we fol\u00ad low one of the edges entering x. If that edge leaves a node not already in S we \nadd the node to S and follow one of its edges, otherwise we back\u00ad track and follow another edge from \na previously encountered node. The number of steps in this pro\u00ad cess is the number of edges in the resulting \nEs> since each edge is traversed once. Additionally, an edge-from-h bit is associated with each node, \nwhich is set if an edge from h to that node is traversed. Also, as edges are traversed, construct an \nadjacency structure for the subgraph Gs. Next, in time proportional to the number of edges in Es, we \ndo an s-numbering on the nodes of s. As before, we list the nodes of S in order of the new s-numbering. \nThis new list has the same order as the old list but has no gaps caused by nodes not in S. (The purpose \nof the new s-numbering is only to obtain this list. The new s-numbering can then be discarded. This method \nof obtaining the list is in general theoretically faster than obtaining the sublist of nodes by scan\u00adning \nthe original list starting at h.) Now we are ready to carry out the computation of Reduceset, by again \nexploiting the properties of s-numbering. Since the graph has no fronds entering nodes of S-{h}, all \nentering edges of nodes in S-{h} must leave nodes with smaller s-numbers. The node h has the smallest \ns-number of any node in S. Consequently the node following h in the new list has entering edges only \nfrom h and possibly itself. If the node has a looping edge, apply Ti. Then, using the adjacency struc\u00adture \nfor the subgraph, apply T to all edges leaving that node. At the comp?etion of the T~ transformations, \nthe third node of S in the s-number ordering will have entering edges only from h and possibly itself. \nRepeat until all nodes in S have been processed. Application of Tj and T; requires changing edges in \nthe original adjacency structure and the reverse adjacency structure. By keeping a pointer from each \nentry in the adjacency structure for Gs to the corresponding entry in the original adja\u00adcency structure, \nedges are easily deleted. By checking the edge-from-h bit before adding an edge, duplicate entries for \nedges leaving h can be avoided. If the edge is added, the appropriate edge-from-h bit is set. Since the \nreverse adja\u00adcency structure is not needed during the Reduceset computation, when a node in S-{h} is \nprocessed, its non-frond reverse adjacency list can be re\u00adplaced immediately by the single entry for \nh. The frond reverse adjacency list for h can be re\u00adplaced by the single entry for the looping edge to \nh. The adjacency structure for Gs need not be updated. Application of Tj or T~ does not change the s-numbering \nof the nodes. Since finding each is done in time proportional to the ;;%%p~f~~gesin Es, itcanbe shown \nthatthe time for finding all such subgraphs is proportional to the number of transformations necessary \nto re\u00admove all non-trivial cycles. Once the nontrivial cycles have been eliminated, the rest of the compu\u00adtation \ncan be done in a straightforward way by pro\u00adcessing the remaining nodes in increasing s-number order. \nTile time for the total computation is pro\u00adportional to the total number of transformations. The implementation \njust described illustrates that our global flow analysis algorithm can be realized on a random access \nmachine within the theoretical time bound. However, we make no claims that what we have described is \nin any sense the best implementation. In particular one is likely, in practice, to put an upper bound \non the size of a graph to be analyzed. In light of such a bound, and the empirical characteristics of \nflow graphs for actual programs, other realizations might well be more efficient. In addition, we have \nmade no attempt to save space, instead creating new doubly\u00adlinked lists atwill. Data structures include: \n An array containing a record for each node with fields for 1) pointer to doubly-linked adjacency list \n2) pointer to each linked reverse adjacency list 3) s-number 4) membership-in-S bit 5) edge-from-h bit \n6) pointer to linked adjacency list for sub\u00ad graph Gs An array containing nodes of G ordered by s-number. \nAn array containing nodes of Gs ordered by s-number. Auxiliary stacks and temporaries, adjacency lists, \net al. Figure 8. Data representation for implementation 7. Discussion We have presented a global flow \nanalysis algorithm for reducible flow graphs and have ana\u00adlyzed its time complexity in number of function \noperations both in general and for special classes of program flow graphs. The algorithm presented here \nis a major modi\u00adfication and generalization of interval analysis. Like interval analysis, the algorithm \nworks only on reducible graphs and requires composition and intersection of functions. The iteration \napproach to global flow analysis works on all graphs and requires only functional application. However, \nalmost all programs written yield reducible graphs, and reducibility has been proposed as a necessary \ncondition for a well-formed or structured pro\u00adgram [16]. In practice, all functions tradition\u00adally used \nin code optimization have been as easy to compose and intersect as they were to apply. It should be noted \nthat Algorithm A is easily modified to incorporate a test for reducibility of any flow graph. We are \npresently extending the algorithm to include irreducible graphs by relaxing the unique-entering-edge \ncondition for T). The complexity appears to be favorable compared with the node-splitting techniques \nfor achieving reducibility. For a flow graph G = (N,E,no), both of the previously known methods have \na worst case time of O(IEI. INI) function operations. Their worst cases occur in loops which are nested \ndeeply. The me\u00adthods are often linear in practice because nesting level is almost independent of the \nlength of the program. However, the nesting level, typically about 3, appears as a multiplicative factor \n(this is an oversimplification in the case of interval analysis). This increases the running time by \na factor of 3. This does not occur in our algorithm. We expect that the running time of our algorithm \nwill usually be significantly less than the running time of the previously known algorithms. We have \nexpressed our class of global flow problems as information propagation problems for sets of facts . We \ncould instead have used the more general bounded lattice-theoretic framework. The distributive law frequently \nrequired would be replaced by the weaker monotonicity requirement. We used the set formulation for ease \nof understand\u00ading by the reader. After analyzing the algorithm for fast functions, we indicated how to \nextend the algorithm to non-fast functions and then to infi\u00adnite sets together with an information propagation \nspace of functions which map finite sets to finite sets. Our algorithm is easily generalized to handle \nglobal flow problems such as live-dead analysis for which one analyzes the reverse of the flow graph. \nWe are also studying methods for increased computa\u00adtional efficiency. For many programming languages, \nsuch as the PASCAL subset mentioned in section 5, program loops can be analyzed before the entire program \nhas been scanned. Consequently we can in\u00adcorporate composition and intersection operations of global \nflow analysis in the parsing semantics , leaving only a stack of function applications to be carried \nout after parsing is completed. For large programs, this technique can reduce the use of secondary storage \nfor intermediate results during compilation. All of the above-mentioned extensions will be included in \n[21]. References [1] Aho, A.V. and Unman, J.D., The Theory of Parsing, Translation and Compiling, Vol. \nII Compiling, Prentice-Hall, Englewood Cliffs, N. J., 1973. [2] Allen, F. E., Control Flow Analysis, \nSIGPLAN Notices, Vol. 5, No. 7, July 1970, pp. 1-19. [3] Angluin, D., Private communication, July 1974. \n[4] Cocke, J., Global Common Subexpression Elimination, SIGPLAN Notices, Vol. 5, No. 7, July 1970, pp. \n20-24. [5] Floyd, R.W., Assigning Meanings to Programs; Proceedings American Mathematical Society Symposia \nin Applied Mathematics, Vol. 19, 1967, pp. 19-32. [6] Fong, A., Kam, J. and Unman, J.O., Appli\u00adcations \nof Lattice Algebra to Loop Optimi\u00adzation, in these Proceedings. [7] Hecht, M.S. and Unman, J. D., FlowGraph \nReducibil ity, SIAM Journal of Computing, Vol. 1, No. 2, June 1972, pp. 188-202. [8] Hecht, M.S. and \nUnman, J.D., Analysis of a Simple Algorithm for Global Flow Problems, Proceedings ACM Symposium on Principles \nof Programming Languages, October 1973, pp. 207-217. [9] Hecht, M.S. and Unman, J.D., Characteriza\u00adtions \nof Reducible Flow Graphs, Journal of the ACM, Vol. 21, No. 3, July 1974, pp. 367-375. [10] Hoare, C.A.R., \nAn Axiomatic Basis for Compu\u00adter Programming, Communications of the ACM, Vol. 12, No. 10, October 1969, \npp. 576-583. [11] Kam, J. and Unman, J.D., Global Optimization Problems and Iterative Algorithms, TR-146, \nDepartment of Electrical Engineering, Princeton University, January 1974. [12] Kennedy, K., A Global \nFlow Analysis Algorithm, International Journal of Compu\u00adter Mathematics, Vol. 3, December 1971, pp. 5-15. \n[13] Kennedy, K., A Comparison of Algorithms for Global Data Flow Analysis, Rice Technical Report 476-093-1, \nRice University, February 1974. [14] Kildall, G. A., A Unified Approach to Global Program Optimization, \nProceedings ACM Symposium on Principles of Programming Lan\u00adguages, October 1973, pp. 194-206. [15] Paterson, \nM., unpublished memorandum, University of Warwick, Coventry, England, April 1972. See also [19]. [16] \nPeterson, W., Kasami, T. and Tokura, N., On the Ca~abilities of While. Re~eat. and Exit Statements, Communications \nof the ACM, Vol. 16, No. 8, August 1973, pp. 503-512. [17] Schaefer, M., A Mathematical Theory of Global \nProgram Optimization, Prentice-Hall, Engle\u00adwood Cliffs, N.J., 1973. [18] Tarjan, R. E., Depth-first \nSearch and Linear Graph Algorithms, SIAM Journal of Computin~ Vol. 1, No. 2, September 1972, pp. 146-160. \n[19] Tarjan, R.E., Efficiency of a Good But Not Linear Set Union Algorithm, to appear in Journal of the \nACM. [20] Unman, J. D., Fast Algorithms for the Elim\u00adination of Common Subexpressions, Acts Informatica, \nVol. 2, No. 3, December 1973, pp. 191-213. [21] Wegman, M., Ph.D. Dissertation, in progress. [22] Wirth, \nN., The Programming Language PASCAL, Acts Informatica, Vol. 1, No. 1, 1971, pp. 35-63. [23] Wulf, W.A., \nA Case Against the GOTO, SIGPLAN Notices, Vol. 7, No. 11, November 1972, pp. 63-69. \n\t\t\t", "proc_id": "512976", "abstract": "A new algorithm for global flow analysis on reducible graphs is presented. The algorithm is shown to treat a very general class of function spaces. For a graph of e edges, the algorithm has a worst case time bound of 0(e log<inf>2</inf>e) function operations. In programming terms, the number of operations is shown to be proportional to e + the number of exit nodes from program loops. Consequently a restriction to one-entry one-exit control structures guarantees linearity. It is shown that by relaxing these time bounds, a yet wider class of function spaces can be handled.", "authors": [{"name": "Susan L. Graham", "author_profile_id": "81452606376", "affiliation": "University of California, Berkeley, California", "person_id": "PP14173434", "email_address": "", "orcid_id": ""}, {"name": "Mark Wegman", "author_profile_id": "81100339949", "affiliation": "University of California, Berkeley, California", "person_id": "P191288", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512976.512979", "year": "1975", "article_id": "512979", "conference": "POPL", "title": "A fast and usually linear algorithm for global flow analysis", "url": "http://dl.acm.org/citation.cfm?id=512979"}