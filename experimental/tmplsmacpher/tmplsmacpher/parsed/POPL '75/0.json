{"article_publication_date": "01-01-1975", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1975 ACM 0-12345-678-9 $5.00 APPLICATION OF LATTICE ALGEBRA TO LOOP OPTIMIZATION* Amelia Fong, John Kam \nand Jeffrey Unman Department of Electrical Engineering Princeton University ----- Princeton, N.J. U834U \nmation at the entry of a region to the 1. Introduction information at the nodes of the region. This idea \ncan be generalized to lattices Kildall [1] has recently developed as developed . by Kildall. lattice \ntheoretic techniques for solving many data flow analysis problems. It is We shall use the following formulation \nthe purpose of this paper to demonstrate of Kildall s ideas. that many of the loop optimization such \nas code motion and induction variables Definition: A data flow analysis frame\u00ad detection can be done \nefficiently and in work is a pair D = (L,F) where great lattice generality theoretic by essentially techniques. \nthe same (i) L is zero a semilattice element Q, with satisfying meet A the and bounded\u00ad ness condition \nWe shall use the usual model for a program ment, being the flow subjected graph G to code = (N,E, improve\u00adno) \n, where (Vx8L)(Hk) (xl <x2<... <x n =x implies n<k) N is and a no set c N of is nodes, the initial E \nis a ~. set of edqes There where and y<z y<z is means shorthand y~z and for y#z. yA z = y is a path from \nn ~ to each node in N. The (ii) F is a set of functions from L to L nodes represent straight line blocks \nof (morphisms) on L) closed under compo\u00ad code. There is an edge from nl to n2 if sition and meet, having \nan identity 2 can immediately follow n 1 in a possible (denoted distributivity by e) and satisfying condition \nthe execution of the program. (Vf CF)(Vx,ye L)(f(x Ay) = f(X) A f(y)). The notion of a loop in a flow \ngraph may be modeled by a reqion R = (N1,E1,nl) (iii) For each xc L, there exists f E F which is a set \nof nodes N ,1 and edges E 1 such that x = f(~) . with a header node nl having the property Intuitively, \nthe lattice elements .,. that every path from the initial node to a represent about data information \nat entrance which to might be some block known of a node in R passes through nl. Various loop flow graph, \nand F represents the set of optimization techniques such as code transformations on this information \nthat motion or induction variables (see [2,3,7] could be effected by portions of a program e.g.) make \nuse of functions relating ififor\u00ad (basic blocks in particular) as control passes through it. In the case \nof loop + work supported by NSF grant GJ-1052. optimization, functions we relating shall be information \ninterested at the in entry of a region to that at each node of the region. These functions may be defined \nas follows. For each region R and each node n in for R, all define x in the L function f R,n such that \n f Rn(X) = Afp(x) > P where the meet is taken over all paths P in R from the header of R to the exit \nof n. The function f associated with a path p P is the composition of the functions which reflect the \nactions of the nodes on the path. In certain cases an efficient algori\u00adthm can be obtained to compute \nthe functions associated with various regions as a flow\u00adgraph is parsed [4] or interval analyzed [5]. \nThe issues which we must consider to demon\u00adstrate the practicality of our approach are: 1) How can morphisms \nbe represented so that their important operations \u00adcomposition and meet (f A g is defined by [f Ag](x) \n= f(x) Ag(x)) can be performed efficiently? 2) Under what conditions are the functions associated with \nregions efficiently computable? 3) Are there frameworks that meet the re\u00adquirements of (1) and (2) and \nhave practical applications? we shall turn to each of these issues in the following sections. In Section \nII, we shall discuss ex\u00adamples of representations of functions. In Section III, we shall. give the outline \nof an efficient algorithm to compute these functions and discuss the conditions under which the techniques \nin the algorithm may be applied. Section IV concludes the paper by giving some practical applications \nof this approach. 11. Representing Functions For the kinds of lattices L and sets of m~rphisms F on L \nconsidered most fre\u00adquently, representation of the functions In fact the repre\u00adsentation of the morphisms \nin each case bears a resemblance to the representation of a pair of elements of L, but we cannot prove \na general result of this nature. aPPears to be feasible. The most common case considered in the literature \non global flow analysis [2,3,4,6] is the use of bit vectors. Here L is the set of bit vectors of some \nfixed length, A is bitwise and, and the elements of F are functions which deal with the components of \nbit vectors uniformly and in\u00addependently. In this case each f in F can be represented as a pair of bit \nvectors a and b, where f(x) = (a\\x) V(bA 7x). Examples where this approach has been used are the GEN \nand KILL representation of r3,4], or the dual assumptions approach of [2]. For a second example, in [11 \n, the structured partition lattice is described for common subexpression detection. A relatively efficient \nrepresentation of structured partitions in terms of value numbers [7] was given in [1]. The repre\u00adsentation \nis equivalent to the dag intro\u00adduced in [8]. we shall show that the dag provides a natural generalization \nto repre\u00adsentation of morphisms on structured partitions. Definition: Let A be a finite set of variables \nA= (Xl, . . ..Xk]. Let ~ = {~il X. @a). 1 Let C be an infinite set of constants. Let O be a finite set \nof binary operators. A structured partition DAG G = (V,E,LABELG,OPG) with respect to (A,c,o) is a finite \ndirected acyclic graph with a set of nodes V, a set of edges E, together with two functions LABEL : v \n~ set of finite subsets of G (AU~UC) oPG :V B +O where Bis the set of base nodes satisfying the following \nconditions 1.) No symbol or constant is in the two sets labelling two nodes of the dag. 2) Each ;i c \n~ appears in the label of exactly one base node. 3) If v is a base node, LABELG(v) contains either one \n~. e E or one constant 1 C ~ C but not both. (It may contain any number of symbols in A) Intuitively, \nif the dag represents a together with the required node mergers barred symbols represent are shown in \nFig. 2(a) , while Fig. 2(b) Inltlal va to shows the resulting DAG G3. Unc: on Yn &#38;es on entry region \nR and unbarred symbols represent final values on +A {B) +A11z) (D) 51 exiting node n. For example the \nfunction associated with the block: (A) 2 * A+B+C B+-,A*D A+c+l {~) A (~,D would be represented by the \nDAG of Fig. 1. {5,CI {A,B) 1 + E) (51 A (E,c (a) (A) Fig. 1 It is clear from the above example that \nstructured partition dags (SPDAG) representing functions associated with straight line blocks can be \nobtained in a routine fashion. Composition of functions can also be performed on these dags in the following \nmanner. Let fl and f ~ be the functions associ\u00ad ated with the paths PI and p2 respectively. Let G1 and \nG2 be the corresponding SPDAG S. f20f is the function associated with the path consisting of p followed \nby p2. Hence final values of Gl s A ould become inxtial values of G in the composite SPDAG G 23 representing \nf20 fl. To create G from G1 3 and G2, nodes of G are linked with base 1 nodes of G2 by identifying each \nunbarred symbol X of G, with the corresponding barred symbol ? of G2. The two nodes are collapsed into \none node and the symbols X and ~ are deleted from the label of the resulting node, since the X of G is \nnow 2 the final value and the ~ of G1 is now the initial value for f2 o f An example will 1 illustrate \nthe operation. and G , 1 2 [i] (B]  3#LAA (;) (1) {E) @] (b) Fig. 2 A binary operation on the SPDAG \ns must be defined to reflect the meet operation on functions. Definition: Let G = (V,E LABELG,OPG) be \nan SPDAG with respect to A,C,O). G = (V ,E , LABEL GI,OPG,) is a sub-SPDAG of G if v gVandV includes \nall base nodes of G, E = Efl V XV and for all v CV LABEL, ~ LABELG( v ) OPG, (V ) =OPG (V ) For example, \nin Fig. 3, G is a sub-SpDAG of G. {B) {C) The rank of an SPDAG G denoted RANK(G), .. M is the maximum \nrank of its nodes. +* G Alqorithm G Fig. 3 Definition Let G1,G2 be two SPDAG S with respect to (A,C,O). \nis isomorphic to G if 1. 2 there is a 1-1. correspondence 2 between the nodes V of G1 and the nodes W \nof G2 such that for all vc v, if g(v) = w~wthen 1.) v is a base node iff w is a base node and LABEL (v) \n= LABEL (w), and G 1. 2 2) if v, w are not base nodes, then OPG (v) = OP (w) and the left and 1 2 right \nsons of v are in correspondence with the left and right sons of w. Let Gl and G2 be two SPDAG S repre\u00ad \nsenting f] and f2, then fl A f2 is repre\u00ad sented by the maximal SPDAG G3 which is isomorphic to a sub-SPDAG \nof G1 and a sub- SPDAG Of G2. The definition of isomorphism can easily be executed to take into accout \nthe commutativity of certain operators, but we do not do so here. It should be clear that the meet of \nSPDAG S is effectively computable. The following algorithm constructs the meet of two SPDAG S Gl and \nG2 w.r.t. (A,C,O) 3 in an efficient manner. First, we need the definition of the rank of a SPDAG. Definition: \nThe rank of a base node is O. The rank of an interior node is the maximum rank among its sons plus 1. \n Let V and w be the set of nodes of SPDAG S Gl and G2 whose meet we want to compute. Initialization -consider \nbase nodes. Assign integers to operators in O such that for each operator o c O, there is a unique integer \nassociated with it. Let A = {X~,x2, .. ..xk} There are k base nodes on Gl and on G2 each has label containing \none ~. while the 1 remaining base nodes have labels containing constants. Let C c c be the finite set \nof constants which appear in the labels of ad G 1 2 Define a linear order <. on ~U C such that %i < ~. \nfor all i<j, l~i, j<k 1 2 <-c for all i, l<i<k, i for all ceC + if C is less than C2, c1 C2 1 for all \nCl, C2cC Represent each base node in G1 by the barred variable or constant contained in its label. Sort \nthe base nodes on this representation according to the linear order <. . Sort the base nodes of G2 in \nthe same manner. Merge the two sorted lists, obtaining the pairs of base nodes (Vi,Wi) , v. Cv> Wi c \nW which have the same representa\u00ad 1 tion. Let the total number of these pairs be m. o Construct m o \nbase nodes (ul,u2,. ..,um ) o for G3 such that if (Vl,Wl) , (V2,W2) . . . , (Vmo,wmo) are the pairs obtained \nfrom the merge, then for all l<i~mo LABEL (Ui) = LABELGl(Vi) ~LABEL (wi) . 3 2 + we assume C has an ordering \ndefined on it. This will surely be the case for any constants that are computer representable. nodes \nare the same. If V. = (V1,V2S. ..,V ) {w1,w2,. ..,wm ) o o and (U ,U ] are the sorted lists For all 1. \n< i < m 1 2  mo r of nodes described above, define NUM ~ (vi) = OP (Ui) = OP (vi) = OP (Wi) , 3 1. \n2 i, NUMG (wi) =i and NUM (ui) =i. 1 2 3 LABELG (Ui) = LABEL (Vi) nLABEL (Wi) 3 G1. 2 Induction ~ Let \nV = (vl,,v2, . . ..vm ), r We now present the algorithm which con\u00ad siders nodes in order of increasing \nrank, w = {wl,w2, . .,wm ] and Urr= (ul,u2, . . ..um). r constructing the SPDAG G3 as it goes. r r Number \nthe nodes in v Of G such that r1 1) Initialize NUMG (Vi) + total + i, l~i~m Similarly r 1 number W and \nU such that NUMG (Wi~ + tn*~l + i, NUMG (ui) + total +i, 2) Increment rank 2 3 1. < i<m. total. + total. \n+ m r 3) Consider nodes of rank r. go to step (2) . Let Vr be the set of nodes of Gl of By using a bucket \nsort [12], the meet rank r. Define Wr similarly. of two SPDAG S may be obtained in time pro\u00ad portional \nto the total number of nodes in if either V =@orW = @ then stop --r ---\u00ad r the two SPDAG S. The algorithm \ncan be easily modified to accommodate a definition 4) Assume Vr # @ and Wr # o. For each of isomorphism \ntaking into account the node v in Vr, form the 3 component key commutative laws of certain operators. \n(k,nl,n2) where k, n],, n z are all inte-III. Computinq Functions Efficiently gers. k is the integer \nassociated with OP (v), nl = NUMG (VI), n2 = NUMG (V2) In this section we shall outline an efficient \nalgorithm adapted from [4] , to where v ,vare the left and right sons of compute functions for progressively \nlarger 12 11 1 regions in terms of the functions for the v respectively. constituent regions, and discuss \nthe con\u00ad ditions under which the techniques in the Similarly, for each node w in Wr, form algorithm is \napplicable. the three component key in the same fashion. Sort Vr and Wr separately on the three com-The \nidea is to construct a rooted, un\u00adordered tree representing each region, each ponent key. Merge the two \nsorted lists, leaf representing a node in the region and obtaining the pairs of nodes (Vi,Wi) vi e V \nr with the following properties: Wicw r which have exactly the same key. (i) Each interior node has two \nor three Let the number of these pairs be mr. sons, except that a two node tree is permissible. if m \n= Othen stop -4 r (ii) All. paths from a node to its descend\u00ad5) Assume m > 0. Let (Vi,Wi) l~i~mr r ant \nleaves have the same length. be the pairs obtained from the merge. The edges of the tree will be labelled \nCreate nodes Ur = (u1,u2, . . ..Un ) On G3 r by a function. It will. be arranged so that if the tree \nrepresents region R, then fsuch that the left and right sons of each R,n to u i are the nodes on 3 corresponding \nthe can be computed by following the path from the leaf n to the root and composing the left and right \nsons of v i (also wi) i.e. functions labelling the edges of that path, the number assigned to the corresponding \n bottommost function first. 5 A basic manipulation of edge labels Algorithm is given in the next lemma \nand exhibited in Fig. 4. We refer to it as strippin% of1) Initialization an edge (tO,t~). For the initial \nregions consisting of and t tk be nodes of a a single node n, construct the tree as et O ti tree w~th \nedqes and +;;ii;asinl?ig. 4(a). shown in Fig. 5. If the l.abel.~ of these edges are changed to those \nin Fig. 4(b) then the same fR n , as before is computed for all. the leaves of the tree. fn Fig. 5 t \n2) ApP lication of ~1 o .C f fofl fo.k Suppose region Rl = (N,El,nl) is 1 created by an application of \nT ~ from region = (N,E2,n1). That is, El consists of 1 k 2 2% and those edges of the original flow (a) \nb) 2 graph represented by the edge eliminated. Fig. 4 Note that an edge with label e, the Letf= A f identity \nfunction, has no effect on the (L,nll C E1-E2 2,L calculation of f when the path from the R,n loop representing \nnode n to the root is followed. ,/ (i times). Create the tree for region RI The algorithm consists of \nthree parts, by the following steps: one for initialization, i.e. the construc\u00adtion of trees for regions \nconsisting of a 1) Create a new node r whose lone son single basic block, the second for regions is the \nroot r of the tree for R 2 constructed by applications of T and T Label edge (r,r ) by f. 12 where T \n, T are transformations on flow 2) Strip the edge (r,r ).graphs ?lefi;ed in [13]. Tl is the dele\u00ad tion \nof an edge from a node to itself. 3) Delete r and the edge (r,r ); r is 2 the root for RI. is the merging \nof n and n into a single 12 node, where n is the unique predecessor 1 3) APP lication ~ !C2 of n and \nn is not the initial node. 22 Let R = (N,E,n ) be the region formed We say n2 is consumed by n 1 by T2 \nfrom regions $ = (Nl, El, nl) and .We assume that the flow graph is re-= (N2,E2,n2), with RI consuming \nR2. 2 ducible (i.e. it can become a single node Letf= A f under the T transformations [13]) and 2 (f,,n2) \nCE E1-E2 1,1, that a sequ~;ce of reductions by Tl and are available. It should be emphasized 2 Create \nthe tree for region R by the that this algorithm will not work for an following steps: arbitrary framework, \nbut only on a re\u00adstricted class to be defined subsequently. 1) Create a new node r whose lone son is \nthe root r of the tree for R 2 Label the edge (r,r ) byf. 2) Strip the edge (r, r ) 3) Delete r and the \nedge (r,r ) 4) Merge the resulting tree with root r and the tree for region R 1 The re\u00ad sulting tree \nis the tree for region R. The merger algorithm is rather compli\u00adcated, but is identical in spirit to \nthat of [4]. We omit the details. The necessary and sufficient condi\u00adtion for the above algorithm to \nwork is for the meet of the functions associated with all paths in R from its header to a node n in R \nto be equal to the meet of the functions associated with a particular re\u00adstricted set of paths. This \nrestricted set consists of those paths which include at most one back latch. This condition is equivalent \nto: 1) (Vf,g,he F) (hfg~hf AhgAh) In turn, we can easily show the equiv\u00adalence of (1) to the simpler \ncondition 2) (iffc F)(ff~fAe) Condition (2), in its turn is implied by: 3) (Vf,g~F) (Vxe L)(fg(0) >f(x) \n~g(~) Ax) which is the condition shown in [9] to be necessary and sufficient for the depth first search \ntechnique of [10] to be appli\u00adcable to a data flow analysis framework. (2) does not imply (3), however \n[9], The reader may easily check that the structured partition dag of Section II does satisfy condition \n(2). We can also show that the generaliza\u00adtion of (3): k-l (3k)(t7fc F)(fk ~ A fi) i=o 4) is sufficient \nfor a straightforward general\u00adization of the algorithm described above to work. This algorithm requires \nO(nlogn) composition and meet operations on an n node flow graph, as does the algorithm above. It should \nbe noted that Kildall s con\u00additions are not sufficient by themselves to guarantee that any algorithm \nfor comput\u00ading morphisms will converge. The problem is that boundedness must be replaced by a else there \nwould be no limit on the number of passes around a loop needed for a function to attain its final value \nfor every value of its argument. uniform boundedness condition, Iv. Some App lications A. ~ invariant \ncomputations. An assign\u00adment A + B 8 C is ~ invariant if neither B nor c change inside the loop. In terms \nof regions, each path inside the region from the header to the assignment must leave B and C unchanged. \nIf the region happens to have some back latches, then it is efficient to move the computation A + B 9 \nC to just before the header. One easy way to detect many loop in\u00advariant computations is to use a lattice \nof bit vectors with one position for each variable. The bit for a variable is to be 1 at a point if and \nonly if no path in the region from the header to the point sets the variable. Meet is logical and, and \nthe fun~tion associated with A @ B e C sets the bit for A to O and leaves others unchanged. A more sophisticated \napproach is to use the structured partition representation described in Section II. This approach enables \nus to compute fR-n(Q) for each region R and node n in R~--is a dag including a structure such as the \none in Fig. 6 we could detect that B is B 51 Fig. 6 invariant at the entry to n, although the bit vector \napproach would not do so. B. Induction variables. Intuitively, an induction variable . X at a node n \nin region . _ R is one for which every path in R from the header to the exit of n adds the same loop \ninvariant quantity (increment) to X. Alter\u00adnatively, successive values of X at n form an arithmetic progression \nas long as we stay within the region R. If for all nodes n in R which are predecessors of the header \n(tails of back latches) x is an induction variable at n with the same increment, then t x is an induction \nvariable of R. It is . X=1 these variables we wish to identify, but the more general search for induction \nvari-I ables at individual nodes n seems to be the most efficient route to our goal. we can again use \nthe structured par\u00adtition lattice to compute a dag represent\u00ading fR,q(~) for each R and n. We may then \nidentifY induction variables at n by a variety of rules, depending on how much algebraic manipulation \nwe are willing to Fig. 8 perform. The basic strategy is to look for variables X such that f ~ n(Q) indicates \nThe approach taken in [11] is to limit that X is incremented by a c;nstant each the depth of nesting \nof set of or tuple time through n. An example is Fig. 7(a), of to three. Anything more complex is where \nX =~+2. For a more subtle example, don t know, We can i.e. , the lattice ~. consider Fig. 7(b). Suppose \nY is an in-avoid any a priori bound on the depth of duction variable of the region R. (We can nesting \nof type descriptors if we detect only tell this by considering Y at all the those variables whose type \ndepends non\u00adlatching nodes ofR.) Then, since X has a trivially on itself around a loop (by non\u00advalue \nwhich is a linear function of an trivially, we mean that a set ortuple form induction variable, namely \n2Y-1, it can be ing operation is involved in the formula shown to assume an arithmetic progression that \nrelates the type after traversing at n. the loop to the type before the loop). If we detect only these \nvariables -and we can do so using a variety of techniques -then we can give each of these variables the \ntype ~ around the loop before applying global propagation techniques as [11] does. +f In this way, the \nlattice of types will i still not obey Kildall s boundedness condi\u00adtion, but there willbe a bound for \nevery flow (a) graph. Thus Kildall s technique canbe made to work even though his condition is, strictly \n(b) speaking, not satisfied. we can represent functions on types by Fig. 7 a notation similar to the \ndag representation discussed in Section II. The symbols ~ and C TYP e Discover y-Self Dependency. X represent \nthe set of possible types for X Another interesting application of these at entrance to the region and \ncurrently. techniques is to detect the self dependency The constants are a-priori defined types of a \nvariable. We shall discuss one situa such as integer or character string. The tion where this idea is \nuseful. Tennenbaum operators, if it is SETL we are talking [11] has used lattice techniques to discover \nabout, are ( ] (set former) , < > (tuple identifier types in SETL (Ill . Here the former), and I (alternation \nor union of lattice elements are sets of types which types) . For example the dag in Fig. 9 says variables \ncould assume. Meet is union of that the type of X currently is either sets of types, and the functions \nassociated with blocks reflect certain inferences re-x garding types which may be made from the syntactic \nrules of SETL. Unfortunately, the lattice of all sets of types is not bounded. For example, the piece \nof flow\u00adchart in Fig. 8 gi;es x the infinite set of types integer or set of integers or set of set of \nset of integers, or . . . Fig. 9 1) a set of whatever types of elements ~ [6] J. Cocke, Global common \nSubexpres\u00ad could represent at entrance to the sion Elimination, ibid. pp 20-24, region, or [ 7] J. Cocke \nand J. Schwartz, Proqramminq 2) a set of elements which are each Languages and Their Compilers, Courant \neither of whatever type Y could be Inst., N.Y.U., New York, 1970. initially or 2-tuples consisting of \nan integer and an object of whatever [8] A.V. Aho and J.D. Unman, Optimization type Z was initially. \nof Straight Line Programs, SIAM J. Computinq, 1:1, pp 1-19, March 1972. The meet operation in this \nlattice is alternation: the reader can easily con\u00ad [ 9] J. Kam and J.D. Ul~man, Global Opti\u00ad struct \nan algorithm to perform the meet mization Problems and Iterative Al\u00ad operation on dags by splicing them \ntogether gorithms, TR 146, Computer Science with new nodes labeled I . The effect of Lab., Dept. of \nElectrical Eng g, basic blocks on types of variables is as Princeton University, N.J. , January described \nin [11]. It may be easily checked 1974. that condition (4) of Section III is satis\u00ad fied if k is the \nnumber of variables. [10] M.S. Hecht and J.D. Unman, Ana~ysis of a Simple Algorithm for Global Flow \nProblems, Proc. ACM Symp osium on In order to determine all and only Principles of Programming Languages, \nthose variables which could assume an in\u00ad pp 207-217, ~ctober 1973. finite set of types when the program \nwas run, we would have to concern ourselves [11] A. Tennenbaum, Type Determination in with actual values \nassumed by variables, Very High Level Languages, NSO-3, rather than their types alone. However, Courant \nInst., N.Y.U., New York, 1974. we can, using the dag representation defined above, find a superset of \nall such varaiblee. [12] A.V. Aho, J.E. Hopcroft and J.D. Ul.l- Namely, if R is a region with header \nn , 0 man, The Design and Analysis of  Com\u00ad then say x is self dependent if in the dag a Alqorithms~ddison \nWesley, representing f R,no there is a path from Reading, Mass. , 1974. ~ to X which contains a node \nlabeled by [13] M.S. Hecht and J.D. Unman, F1ow the ( ) or < > operator. Graph Reducibility, SIAM \nJ. Computinq 1:2, pp 188-202, June 1972. References [14] J.T. Schwartz, On Programming Vo~s I and II, \nCourant~nstitute, New york, [1] G.A. Kildall, A Unified Approach to 1973. Global Program Optimization, \n Proc. ACM Symposium on Principles of Pro\u00ad gramming Langu~es, pp 194-206, October 1973. [2] M. Schaefer, \nfi Mathematical Theory of. Global Proqram Optimization, Prentice Hall, 1973. [3] A.V. Aho and J.D. Unman, \nThe Theory of Parsin g, Translation an~ompiling G1 . II, Prentice Hall, =3. [4] J.D. Ul~man, Fast Algorithms \nfor the Elimination of common ,subexpres\u00ad sions, Acts ~., 2, Pp 191-213, January 1974. [5] F.E. Allen, \n Control Flow Analysis, SIGPLAN Notices, 5:7, pp 1-19, July 1970.  \n\t\t\t", "proc_id": "512976", "abstract": "", "authors": [{"name": "Amelia Fong", "author_profile_id": "81546347956", "affiliation": "Princeton University, Princeton N. J.", "person_id": "PP14043775", "email_address": "", "orcid_id": ""}, {"name": "John Kam", "author_profile_id": "81536838956", "affiliation": "Princeton University, Princeton N. J.", "person_id": "P348468", "email_address": "", "orcid_id": ""}, {"name": "Jeffrey Ullman", "author_profile_id": "81100314798", "affiliation": "Princeton University, Princeton N. J.", "person_id": "PP39037328", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512976.512977", "year": "1975", "article_id": "512977", "conference": "POPL", "title": "Application of lattice algebra to loop optimization", "url": "http://dl.acm.org/citation.cfm?id=512977"}