{"article_publication_date": "01-01-1975", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1975 ACM 0-12345-678-9 $5.00 NEW CONTROL STRUCTURIIS TO AID GOTOLESSNESS D.&#38;l. Symes Queen s University \nKingstonr Ontario, Canada Introduction This paper contains a suggestion for a calculus for constructing \nflowchartable algorithms . The calculus is a generalization of an Algol-like calculus, and hence main\u00adtains \nsome discipline over the algorithms constructible with it. The essence of the great go to debate seems \nto be that the use of the go to device allows the construction of spaghetti-like algorithms which are \ndifficult to control intellectually, and hence that only more restrictive, special-purpose control structures \n(which are presumably well thought out) should be used. Another way of saying this, per\u00adhaps, is that \nthe go to device is the most primitive (and hence most general) possible control structure, and though \nimplementations of any control structure will ultimately have to be done using it, a programmer should \nno more be content using a go to than if he were forced to use bit strings for data types. He should \nbe demanding higher-level control structures. To some extent, of course, he has them; but, in discussing \nthe go to debate, the conclusion arrived at by Knuth (l), for instance, is that more powerful con\u00adtrol \nstructures than are freely available at present are needed to enable programmers to express their algorithms. \nHe mentions a suggestion by Zahn (2) for strengthening the set of available control structures, but shows \nthat he still needs to resort to the dreaded go to device. (He confesses a sinful urge to jump into the \nmiddle of Zahn s loops.) The implication is that even with Zahn s suggestions there is a need for more \ncontrol structures . We concur with this view, and present here a suggestion for making more such structures \navailable. We invite discussion as to whether the results are profitable for programming language design. \nThe lack of well-developed control structures is manifested, incidentally, not only in the dearth of \npublic control structures (i.e. made freely available to all users) , but also in the lack of facilities \nfor creating private ones (analogously to the notion of subroutines or user defined data types) . These \ndeficiencies are not all that sur\u00adprising since control structures are, in a sense, devices at a third \nlevel of sophisti\u00adcation: data (being the first level) is acted upon by programs (being the second level) \nto produce other data; and programs are acted upon by control str<-.ures to produce other programs. But \nthe time has perhaps come to pay some more attention to control structures. An Algol-like Language as \na Calculus for Flowcharts Let us take a reasonably modern version of Algol (e.g. Algol W) and strip from \nit: go to s (because they are too primitive), case and for (because they are special cases of o$her control \nstructures) , and procedures (because we wish to consider only flowchartable algorithms) . We can view \nthe control structure which remains as a calculus for constructing a restricted set of flowchart schemas, \nwhose def nition can be g, ven in terms of three basic devices: (a) computation block (b) branch (c) \nmerge Then a l-directional flowchart can be defined recursively to be either: (i) a basic computation \nblock; or a schema of one of the following forms, where -++ and + are l directional flowcharts: (ii) \nsequencing (iii) conditional (iv) while (v) until Two immediate comments which can be made about this \ncalculus are: 1. The set of non-looping schemas is quite restricted. The following simple construction, \nfor instance, is not available: <~ > <+>+ This sort of deficiency seems to be a consequence of a design \nphilosophy which en\u00adcourages the production of schemas which have only one entry point and one exit point, \nand tries to persuade us to deviate as briefly as possible from this discipline: namely in a conditional, \nwhich uses a branch (one entry point and two exit points) and a merge (two entry points and one exit \npoint) , and in the looping devices while and until which also use a branch and a merge. It is not clear \nthat this is a deliberate philosophy: it may be dictated as much by syntactic considerations as anything \nelse. However, since it is doubtful if there is any serious difficulty in securing intel\u00adlectual control \nover a non looping algorithm, this seems to be unnecessary caution. In the case of looping schemasr though, \nthe discipline may be a wise one. However: 2. Forms (iv)and (v) are the only looping devices customarily \navailable in Algol; and when presented in the context of the above definition they appear unnecessarily \nrestrictive . Why not permit, for instance: c>++<- This is what has been called executing a loop n 1/2 \ntimes . As a construction it appears quite frequently in algorithms and its lack is keenly felt by gotoless \nprogrammers . Both of these deficiencies have been pointed out elsewhere (for instance (1)) , and suggestions \nfor syntactic devices for including them have been made. A Bi-di.rectional Calculus Even with these amendments, \nhowever, there is still a large class of commonly occurring schemas which is not available. For instance, \nthe schema which is used in a simple search algorithm search a sequence al, . . . ,an for an occurrence \nof x , which would normally be (with suitable initialization and entry point) : yes no I I This is a \nsimple example of an alg orithm which inevitably has more than one exit point: that is precisely the \npoint of it; and if we recall the common dilemma: where do I enter the loop? , we may suppose it is \nalso natural to regard it as having more than one possible entry point, one if the initial value of i \nneeds to be tested against n and one if it does not: yes no II This is one of several examples (some \nmore are given later) which are offered as initial justification for suggesting the following generalization \nof the l-directional calculus discussed above. The calculus is aimed at producing schemas having more \nthan one entry point and exit point but not in a completely free-for-all manner. First, it is suggested \nthat the points be grouped in pairs, an entry and an exit point constituting a pair and each pair has \nan orientation, left or right; and secondly, only certain control structures (i.e. ways of putting schemas \ntogether) are permitted. The permissible structures are modeled on the previously defined l-directional \ncalculus except that we have adopted our own suggestion of removing the restrictions mentioned in the \ndiscussion of that calculus. Thus :. is the generalization of which we intend to explore; and because \nof its appearance the calculus will be called, for want of a better name, a hi-directional calculus. \nWe will develop the calculus first, without pausing to justify it on the grounds of applicability . Some \nexamples of its use will be given subsequently. The definition is given, as before, in terms of a number \nof basic devices: (i) called a decision ~; of which there is one degenerate form: in which one of the \nentry points is ignored. (ii) . called a computation node (in which only ---LJ-+ one exit point is possible); \nof which there are also two degenerate forms: in which one of the entry points is ignored. and ---m \n--cl=-\u00ad (iii) ,----_--., 1 I called a link-unit. t 1..-_J--J 196 (iv) called a branch-merge (in which \nthere are three entry/exit point pairs) . This is intended as the analogy of the branch and merge devices \nin the l-directional * calculus . Then a hi-directional flowchart is defined recursively to be either: \n(i) one of the above four basic devices; ~:~md~~~ or, a schema of one of the following forms, where \nare hi-directional flowcharts with i left pairs and j right pairs: (ii) re-pairing: the entry and exit \npoints have been paired together in the only other possible way to that of Alrl (i.e. Al ~ has r been \nturned on its side ) (iii) reversing: the pairs are reversed, so that left pairs become right pairs and \nvice\u00ad versa. (iv) serial connection: any m (where m s j and m s k) of the right pairs of Ai,j are con \nnetted to any m of the left pairs of Bk,l to produce a flowchart Cp,q where p=i+k-m and q= j+1-m. [The \nexamples which follow use relatively simple special cases of this construction; e.g.: (iv) sequencing \n(analogous to the sequencing  =mi==m= construction in the l-direct. onal calculus) (iv) hi conditional \n(analogous to a conditional) 1 (v) cascade connection: the exit point from a pair (left or right) of \nAi,j is connected to an entry pOint in a pair of Bk,l: the P={ fl~~-1},:.s bereaved entry point of A \nand exit point of B together become a new pair. This is done for any number of pairs. (In the diagram \nthe result is a flowchart Cp,q, ma where: p= i +k-m and ~ q=j+l n ) [Again, the examples of this construction \nwhich occur tend to be relatively simple; e.g. : or H It is also possible to dream up analogies to the \nlooping constructions of the l-directional calculus: (vi) looping: a flowchart with two left and two \n~ right pairs is reduced to a 1 1 flowchart 2,2 by connecting up a left and right pair. [For instance, \na generalization of the until construction: The crucial construction in this calculus is sequencing : \n=u==n= This sort of hi directional connection is very common in computing (for instance co\u00adroutinesr \ntwo-way data links) . Here, it takes on the same primitive significance as ordinary sequencing does in \nthe l-directional calculus. The simplest constructions in the calculus are thus relatively complex schemas, \nas the examples below will demonstrate. In fact, they are as complex as nested loops in an ordinary schema \ncalculus. We also note here that the l-directional constructions appear in this calculus as degenerate \nspecial cases. Some Examples of the Calculus The reasonableness or otherwise of the calculus is presumably \na matter of experiment to some extent, and with this in mind we present a number of examples. The first \nbatch of examples are of schemas which use only the operations of re pairing , reversing and sequencing \n. 1. Search a column array a for x: x== This is a sequence of three basic devices. It demonstrates in \na rather simple way what is involved in gaining intellectual control over hi-directional algorithms: \nthere are, in general, four points of entry or exit at which specifications for a unit should be given \n(or in program-proving parlance: four points at which assertions must be made and established), and when \ntwo such units are connected in sequence the job of establishing the specifications involves determining \nthe effect of an iteration. For the example given, the specifications may be described by: . 2. Search \na rectangular array b for x: QYes [where Sj is the column search algorithm just given for the jth column \nof b] . Notice that there is a choice of two orientations of S+ (one of which is obtainable from the \nother by re-pairing) depending on which of the ~ntry requirements Pyes or 1?no is selected. ~qsi::or~;i~;~ \n% no ;+;+1 W * 0 Also, there is a choice of entry points for the resulting algorithm, though in this \nparticular case it is not clear under what circumstances the right hand one would be used. 3. Determine \nwhether x occurs in every column of a rectangular array b: x~q=~ Qyes Again, there are two possible \norientations for S.t one of which results in: ~=s 4. One pass in a quicksort routine can be expressed \nby: which is constructed as a sequence of five elements, two of which are sequences to which the re-pairing \noperation has been applied. The examples which follow are related to the implementation of procedures, \nin par\u00adticular recursive procedures, and involve some of the other constructions in the calculus . We \ncan think of a procedure (an ordinary one that is: with one entry point and one exit point) which calls \nother procedures, Q1 and Q2 say, in terms of a hi-directional construction in the following way: -:;u:~ \n i 5. For example,: P := if t(x) then while a(x) ~ Ql(x) else while b(x) d= Q2(x); can be expressed \nas: which is immediately recognizable as an application of the branch-merge con struction. If Q1 and \nQ2 happen to be the same procedure Q, this ~ould normally be implemented by: Q -~~> 1I where t determines \nwhich return point to use. This is, of courser another use of the branch-merge device. Suppose now that \nP calls only one procedure Q (for simplicity s sake), and that Q happens to be P (i.e. P is recursive) \n. This is normally implemented (missing out most of the details) by: where t is a test for whether the \nrecursion unwinding is complete (e.g. is the stack empty?) . This is an example of a looping hi-directional \nconstruction. Hencer we appear to have arrived at the position that a l-directional algorithm with non-recursive \nprocedure calls can be implemented as a non-looping hi-directional algorithm, and a l-directional algorithm \nwith recursive procedure calls can be implemented as a looping hi-directional algorithm. 6. We give an \nexample of the implementation of a recursive procedure in order to demonstrate the above standard construction: \nconsider the recursive schema \u00ad(*) f(x,y) := if p(x,y) then a(x,y) else f(x,f(b(x),c(y)) . Let us look \nfirst at the corresponding non-recursive schema: f(x,y) := if p(x,y) then a(x,y) else f (x, f (b(x),c(y)) \n. A straightforward implementation of this (with f left unspecified) is: * V&#38; yes X *X y +f t.o \nk-e1 ml % This is a non-looping construction in the hi-directional calculus (using cascade connection \namong other things) . Using this as a guide, the original schema (*) could be implemented by: \\ ---Eg-- \nTzt\u00ad.% ys k= O no The game of recursion removal! can now be played, as for instance in (3) , to massage \nthis algorithm into a more efficient one, but that is another story. (In this particular case, a considerable \nsimplification can be made.) Syntax A fact of life which at present we have to live with is that diagrams, \nhowever stylized, are not a suitable language for communicating algorithms to a machine. We there\u00ad fore \nconclude this account with some suggestions for a linear language for expressing bi\u00addirectional algorithms. \nThe suggestions are frankly quite tentative, and are intended mainly as a starting point for attacking \nthis problem. We have not attempted to define syntactic constructions for the full calculus as described \nhere, but only some of the more useful constructions, and wherever possible we have stolen the syntax \nof the analogous Algol-like construction. First for the basic devices: is written: +p$ or +p+ [where \nthe right hand arrow indicates which direction control flows in should the.test p succeed] (ii) is written: \ns+ or s+ [again, depending on the direction control is to flow] -m= ,-----\u00ad (iii) is written: S1++S2 \nI I Then, for a few of the operations: (iv) a sequence ==m= is written: endl s~; 2; . . . Sn end2 (v) \nre-pairing: endl(flipped) s~; . . . . Sn end2(flipped) (vi) a hi-conditional is written: if p then: \ns~ else S2 :if q then [There is a strong urge to write the last line here as :neht . q fi , but this \nhas been resisted]. 201 (vii) The following simple example of a cascade connection: from: s, S1 S2 is \nwritten: to: = S2 (viii) As an example of a 100 in construction we offer: do :until p s becomes: &#38;..&#38;z&#38;$ \nuntil q :do What does a hi-directional program then look like? Example (4) (quicksort) appears as follows: \nendl ii <j+ endl(flipped) +ai >V+ ; k := i +1+; end2(flipped) ; a. :=ai ++ai :=a. ; 17 endl(flipped) \n\u00ad j := j-1+; v+ +aj < : end2(flipped) : +j >i+ end2 Example (6) becomes: do until stack empty . end 1 \n endl (~) +p(x,y) + : f := a(x,y)+ ; continue+ end2(flipped) from: begin save x,y,O ; x := b(x) ; Y \n:= C(Y) end ++ to else begin save x,y,l ; := Yf end ++ if t #Othen ; ++ restore xty,t end 2 This last \nexample, it must be confessed, is not too easy to read. This is partly because it >akes practice to become \nat ease with any new language, but to a large extent it is because a good deal of strain is being placed \nhere on the constructions, by trying Summary to squeeze them into a linear expression. However, some \nof the simpler (i.e. more linear) constructions are quite readable with a little practice. A possible \nline of attack to ease the situation in general is to work with a 2-dimensional syntax. We have suggested \na possible direction for generalizing the well-established control structures which appear in most structured \nlanguages. The particular approach has been to develop a calculus which produces schemas in which entry \npoints and exit points are grouped in pairs, and in which the most commonly occurring unit is a schema \nwith two entry points and two exit points. The result is a calculus in which the simplest schemas (analogous \nto straight-line schemas in an ordinary calculus) are, roughly speaking, as complex as nested iteration, \nand the other analogous constructions such as conditionals and looping devices produce correspondingly \nmore involved schemas. A series of examples involving procedure calls, both recursive and non-recursive, \nhave been given to demonstrate this. In a sense, therefore, we are suggesting that programmers (or at \nleast some programmers who need more elaborate control structures) should become accustomed to working \nas a matter of course with structures which are complex by present standards. We have also made a stab \nat establishing some syntactic devices for expressing hi-directional schemas. References (1) Knuth, D.E., \nStructured programming with go to statements; unpublished manuscript. (2) Zahn, C.T., A control statement \nfor natural top-down structured programming; presented at Symposium on Programming Languages, Paris, \n1974. (3) Strong, H.R., Jr., Translating recursion equations into flowcharts; Journal of Computing &#38; \nSystem Sciences 5-3 (1971) pp. 254-285.   \n\t\t\t", "proc_id": "512976", "abstract": "This paper contains a suggestion for a calculus for constructing 'flowchartable' algorithms. The calculus is a generalization of an Algol-like calculus, and hence maintains some discipline over the algorithms constructible with it.The essence of the great 'go to' debate seems to be that the use of the 'go to' device allows the construction of 'spaghetti-like' algorithms which are difficult to control intellectually, and hence that only more restrictive, special-purpose control structures (which are presumably well thought out) should be used. Another way of saying this, perhaps, is that the 'go to' device is the most primitive (and hence most general) possible control structure, and though implementations of any control structure will ultimately have to be done using it, a programmer should no more be content using a 'go to' than if he were forced to use bit strings for data types. He should be demanding higher-level control structures. To some extent, of course, he has them; but, in discussing the 'go to' debate, the conclusion arrived at by Knuth (1), for instance, is that more powerful control structures than are freely available at present are needed to enable programmers to express their algorithms. He mentions a suggestion by Zahn (2) for strengthening the set of available control structures, but shows that he still needs to resort to the dreaded 'go to' device. (He confesses a sinful urge to jump into the middle of Zahn's loops.) The implication is that even with Zahn's suggestions there is a need for more control structures. We concur with this view, and present here a suggestion for making more such structures available. We invite discussion as to whether the results are profitable for programming language design.The lack of well-developed control structures is manifested, incidentally, not only in the dearth of 'public' control structures (i.e. made freely available to all users), but also in the lack of facilities for creating 'private' ones (analogously to the notion of 'subroutines' or user-defined data types). These deficiencies are not all that surprising since control structures are, in a sense, devices at a third level of sophistication: data (being the first level) is acted upon by programs (being the second level) to produce other data; and programs are acted upon by control structures to produce other programs. But the time has perhaps come to pay some more attention to control structures.", "authors": [{"name": "D. M. Symes", "author_profile_id": "81537655456", "affiliation": "Queen's University, Kingston, Ontario, Canada", "person_id": "PP14219152", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512976.512996", "year": "1975", "article_id": "512996", "conference": "POPL", "title": "New control structures to aid gotolessness", "url": "http://dl.acm.org/citation.cfm?id=512996"}