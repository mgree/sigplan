{"article_publication_date": "01-01-1975", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1975 ACM 0-12345-678-9 $5.00 ON THE COMPLEXITY OF LR(k) TESTING Harry B. Hunt III + University of Wisconsin, \nMadison Thomas G. Szymanski~ and Jeffrey D. Ullman~ Princeton University Abstract are implicit in [4], \nwhereas a class of In this paper we derive upper bounds O (n 2k+2) algorithms are presented in [1]. on \nthe complexity of LR(k) test&#38; bothwlen In Section 2 of this paper we shall sharpen k is considered \nto be a fixed integer and this bound by presenting a class of also meter when of k the is considered \nproblem. In to the be a latter para\u00adcase, O (n k+2 ) algorithms. we show that the lower bounds on the \ntime of such algorithms depend very ly on the representation chosen for LR(k) testing is NP-complete \nwhen k expressed in unary and complete for terministic exponential time when k expressed in binary. running \nstrong\u00adk. Thu is nonde\u00adis S In Section 3, we shall consider lower bounds on the complexity of any uniform \nalgorithm for LR(k) testing, that is, any algorithm which accepts both k and the grammar in question \nas parameters. More specifically, we shall show that the prob\u00adlem of testing whether a grammar is LR(k) \nis These parameterized the LL(k), strong Lc(k) results carry classes of strong LL(k), , BRC(_L,k) , over \nto grammars, SLR(k), BC(L,k) many other such as LC(k), and extend\u00ad 1) polynomial unary as complete time \nan input if for k to non-deterministic is expressed the algorithm. in ed precedence (L,k) grammars. 2) \ncomplete for non-deterministic I. Introduction exponential sentation of time~ k if as a the natural binary \ninteger repre\u00adis It has long been known that LR(k) chosen. parsers can is exponential which they have \nin parse. a number of the size of Nevertheless, states which the grammar$ for any Moreover, these other \nparameterized results carry classes of over to many grammars. . fixed value of k there is a polynomial \ntime algorithm for testing whether an bitrary grammar possesses the LR(k) 4k+4 property. A class of O(n \n) algorithms ar- Throughout this the notation ~(k) to any of the following LL(k), strong LL(k), paper, \nwe shall use generically refer to classes of grammars: LC(k), strong LC(k) , LR(k), SLR(k). Similarly, \nC3(l,,k) will t Work supported by NSF grant GJ35570. refer to the BC(k,L) , BRC(k,L) and ex\u00ad tt work \nsupported by U.S. Army grant #D-4-31-124-ARO-D-462 .andNSF 9rantGJ35570. i By exponential time we mean \n2P(n) for $ we consider the size of a grammar to be some polynomial p. the sum of the lengths of the \nproductions of the grammar and denote this size by n. tended precedence (L,k) classes of grammars. The \nrest of this section reviews the basic notions related to LR(k) parsing. Definitionl.1 Let G = (V,E,P,S) \nbe a CFG. Then for any a e v*, we define FIRSTk(a) =(xI a ~ x~ and 1x1 = k ora~xandlx! <k] Similarly, \nwe define EFFk(U) =(X @FIRSTk(a)l U r= ~ &#38; xy but B# Axy for any nonterminal A) Definition 1.2 Let \nG = (V,X,P,S) be a CFG . Let $ and S be symbols not in V, we define the k-au gmented grammar de\u00adrived \nfrom G (or simply the augmen~d grammar when k is understood) to be G =(w{S ,$), ZIU($), PU(S -+$k),S \n) With these preliminaries, we may de\u00adfine an LR(k) grammar as follows. Definition 1.3 Let G be a context \nfree grammar and G = (V,X,P,S ) be its k\u00adaugmented grammar. G is said to be LR(k) if the three conditions \n(1) S aAw~m a8w jm (2) S ~myBX=&#38;aRy (3) FIRSTk(W) = FIRSTk(Y) imply that aAy = yBx . Some additional \nterminology is neces\u00adsary before we state a lemma which will lead into the results of Section 2. Definition \n1.4 Suppose that S ~ aAw * rm rm asw is a rightmost derivation in grammar G. Then any prefix y of UB \nis s aid to be a viable prefix of G. Moreover, if and u c FIRSTk(W) then we say p = @l~2 that [A -B1 \n82, u] is a valid LR(k) item for a~l. The following lemma provides an equivalent definition of LR(k) \ngrammar. Lemma 1.5 [4] Let G be an augmented con\u00adtext free grammar. Then G is not LR(k) iff there exist \n1) a string u eZk 2) a viable prefix y 3) two distinct LR(k) items = [A+ a ,u] and 11 = [B * ~1.B2,v] \n12 such that A) and I are both valid for y 11 2 B) u c EFFk(S2V). Section 2 Upper Bounds In this section \nwe shall consider the problems of testing whether a grammar is LR(k) both when k is fixed in advance \nand when k is a parameter of the decision pro\u00ad cedure. The bounds which we obtain repre\u00adsent a marked \nimprovement over those re\u00adported in [1]. We need one preliminary definition by which we shall be able \nto associate viable prefixes with those strings of k symbols which may legitimately follow them in a \nright sentential form. Definition 2.1 Let Y be a viable prefix of G. k Letuc2. u is said to be a lookahead \nstrin~ for y if there exists a derivation with ucEFF (Bz) and y=a8 . k2 1 (note: the use of FIRSTk rather \nthan EFFk yields an equivalent definition. ) The key construction used by our algo\u00ad rithm is described \nin the next lemma, in which we show that the set of viable pre\u00ad fixes having a given lookahead string \nhas a very simple structure. Lemma 2.2 Let G = (V,Z,P,S) be an CFG and k UEE . Then there exists a non-deterministic \nfinite state automaton M(u) such that 1) M(u) accepts precisely those viable prefixes of G which have \nu as a lookahead string. -. 2) IM(u)l = O(k2n) Define M(u) = (Q,V,5,qo,F) as fo~~ows= 1) Let Q1 = {[X,V] \nlXe Vandve SUFFIX(u)] and Q= ([A a F31 B2,v] IA-B1B2cP 2 and ve SUFFIX(u)) Let Q = Q1UQ2. 2) Define a) \n5([A, zI, A)= ([A+. B, ZIIA+6CP) c) 8([A+R1*XL32, Z], /1) = {[ X, Z Z]I Z Z e SUFFIX(U) u d) {[x, AItz \n=A] Call these type (a), (b), (c) and (d) transitions, respectively. 3) Let qO= [S,A] 4) Let F = {[A-i31, \nB2,Z] I UC EFFk(82Z)) It is straightforward to verify that i) [X,2] e ij(qO,y) iff 3W such that S ~ Vxw \nwith z c PREFIX(w) il SUFFIX. ii) [A+ B1 82, zlc b(qo,y) iff 3a such that y = afjl S r~m aAw Z e PREFIX(w) \nfi SUFFIX(U) This fact, in conjunction with the definition of the set of final states F, establishes \npart 1 of the lemma. Next we must bound the size of M. clearly IQII ~lP\\ (k+l) and IQ21 < \\G\\. (k+l). \nHence-\\Ql <2n-(k+l) = O(nk). Consider next the transitions of 6. For=each production of G there are exactly \nk+l transitions of type (a), hence the total. number of type (a) transitions is \\P1. (k+l) = O(nk). The \nnumber of type (b) transitions is exactly n(k+l), and for each of the n(k+l) states in Q2 there can be \nat most k+l transitions of type (c). Finally, the number of type (d) transitions is at most n . Hence \nthe total number of transi\u00adtions of 6 is 0(k2n). Thus IM(u)I= 0(k2n). 0 The construction ofan efficient \nLR(k) test hinges on the ability to efficiently detect the presence of LR(k) conflicts. We formalize \nthis notion in the following definition. Definition 2.3 Let G be a CFG and Ue Ek. Let M(u) be constructed \nfor the aug\u00admented grammar corresponding to G according to Lemma 2.2. Define CONF(U) ={y I ~(qo,y) contains \n2 or more final states). Proposition 2.4 G is LR(k) iff CONF(U) =@ for a~~ ue~k. proof Directly from \nLemma 1.5, ?3efinition 2.1 and Lemma 2.2. tl The next corollary demonstrates that if LR(k) conflicts \noccur at all, then they also occur on relatively short strings. Corollary 2.5 If G is not LR(k), then \nthere exists a viable prefix of G of length < 2. (k+l).n2 which exhibits an LR(k) conflict. PT22@ By \nProposition 2.4, CONF(U) # @ for some u. Let y be the shortest string in CONF(U) and let us bound the \nlength of y. Consider any two computations of M on Y + which accept y by different final states. The \nstandard repeated pairs of corresponding states argument suf\u00ad fices to show that ly\\~lQ\\2=O(k2n2). The \nsharper bound mentioned in the statement of this corollary may be achieved by noting that the lookahead \ncomponent of the states in any computa\u00adtion must be monotonically non-decreas\u00ading. Hence y can be partitioned \ninto at most 2(k+l) segments in which the lookahead component of the states of both computations remains \nconstant. In any computation, at least 1 state of Q2 must appear between any two grammar f A computation \nof M on string U is a such that equence Oxlslx2 ... m-lxmsm 1) each Si eQ 2) each Xi CVU{A) and a = X1X2. \n..Xm 3) =CIo o 4) s i+la Ci(si,xi) symbols. Thus no segment (as defined above) of y can be as long as \nlQ212=n2 or else there would exist a member of CONF(U) which is shorter than y. Hence Ivl <2(k+l) n2. \n[1 Lemma 2.6 Let G = (V,X,P,S) be a CFG and k Uex. Then CONF(U) may be tested for emptiness in a) deterministic \ntime 0(k3n2) b) nondeterministic time O(k n2). First we construct M(u) for the m a) augmented grammar \nG . The only parts of this construction which cannot ob\u00adviously be done in O(kn) steps are determining \nthe transitions of type (c) and computing the set of final states F. To do these, we construct a grammar \n~ = (~,Z,~,~) in which ~=VU([A-~l B2] {A+ BlB2Ep) and ~=PIJ([A-Bl XEJ2] + X(A*BIX-B2] lA-BlXB2 e P] u \n([ A-JR.] -AIA+fJaP). Notice that 1~1 = O(IG!) and that [A+@l B21 ~w iff 82 ~w. G ~ can be converted \nto Two-Normal Form (i.e. the right side of any production is of length O, 1 or 2) without alter\u00ading \nits size or deleting any non-termin\u00adals. If we now apply Younger s recog\u00adnition algorithm [7] to ~ and \nu=a . . .a ? lk we can compute a table T such that T(i,j) ={[A+B ~ ~21 I ~2 ~ ai. ..ajl . Construction \nof this table takes atmost 3 ~(lul 1~1) =O(k3n) steps. This table then makes it trivial to compute which \ntype (c) transitions are to be included in M. A similar construction allows us to compute F. Thus the \ntotal time necessary to construct M(u) is 0(k3n) steps. We shall test CONF(U) for emptinessby constructing \na set S={(s,t) c QXQI 3a such that SYte b(qo,a)). S represents the set of pairs of states which are \nmutually reachable on some input string. CONF(U) is empty iff no pair of distinct final states is a member \nof S. The set S will be stored as a IQIxIQI bit matrix. We will also maintain a stack STACK of backlogged \nmembers of S. The algorithm for computing S appears below. procedure INSERT(p,q): ..,-------. }: (p,q) \n# S then begin ., ..-S -SU((P,CI)): add (p,q) to STACK end end INSERT: begin -..,.-z S+@; INSERT (qo,qo) \n; 1) while ----- STACK w empty do -,. begin,----\u00ad 2) pop (p)q) from STACK; 3) Vq e 5(~,A) , INSERT (P,q \n4) Vp s 6(q,A), INSERT (P ,q : 5) if -\u00ad p = [A*al.Xa2,v] and q [B* B1 YB2, w] and X = Y then INSERT \n(6 (p,X),6(q,X)): ~--\u00adend end It should be clear that the algorithm computes S. Let us consider the amount \nof work performed by each of the numbered statements. Since no pair of states is ever stacked twice, \nstatements 1, 2 and 5 require a maximum of 0(IQ12) = 0(k2n2) work. In the worst case statements 3 and \n4 will be ex\u00adecuted for every pair (p,q) of QxQ. The amount of work done in statement 3 will then be \n(Z I 6(p,A)l) .IQI representing ~ peQ traversal of the 6(p,A) list for each P and q. However, z \\6(p,A)l= \nZ 15(P,A)I+ Z IJ(P,A)I PeQ PeQ1 P~Q2 = O(kn) + 0(k2n) = 0(k2n) as explained in the proof of Lemma 2.2. \n Hence the work charged to statement 3 (and similarly to statement 4) is O(k3n2). b) In order to test \nCONF(U) + @ non-de\u00ad terministically, we simply guess a string y and test whether y e CONF(U) . By Corollary \n2.5, we may assume that \\yl~2(k+l)n2. we must next verify that Y supports two accepting amputations \nwith distinct final states. In order to check this condition, we need. only construct those portionsofM \nwhich are actually used in either accepting computation. Observe that any computation of M on U contains \nat most k transitions of type (c) , Ia\\ transi\u00adtions of type (b) and as many as n.lal transitions of \ntypes (a) and (d). Recall that it is possible to non\u00ad deterministically test whether X Z z in time O(\\zl.n). \nSince the sum of the lengths of the lookahead component pro\u00advided by each type (c) transition in an accepting \ncomputation is exactly k, we may guess which type (c) transitions we shall need, using a total time of \nO(kn) . Finally, we may non-deterministically bypass any portion of the computation which consists only \nof type (a) and (d) transi\u00adtions. Each such bypass requires unit time if we have precomputed the set \n((x,y) I X : y] (which may be constructed in time 0(n2)). Thus a representation of an accept\u00ading computation \nof a can be constructed in time O(lal) = 0(kn2). [] The above lemma leads directly to the first major \nresult of this section. Theorem 2.7 An arbitrary CFG can be tested for the ,LR(k) property in a) non-deterministic \ntime 0(kn2) . 3 k+2 b) deterministic time O(k n ). . proof a) We can determine that G is not LR(k) by \nguessing some string u and testing whether CONF(U) is empty. By Lemma 2.6(b) , this requires at most \n0(kn2) time. b) To perform this test deterministically, we merely te.St CONF(U) for eII@hc2SS emptiness \nfor each of the strings u @Zk. Since each test takes 0(k3n2) determin\u00adistic time and there are at most \nO(nk) such strings, we have the desired uPPer bound. [1 Similar techniques yield similar bounds for \ntesting whether a grammar is SLR(k), BC(L,k) , BRC(L,k) or extended precedence (%,k) . Moreover, since \nthe methods of Brosgol [6] may be adapted to reduce LL(k) or LC(k) testing to LR(k) testing and strong \nLL(k) and strong LC(k) testing to SLR(k) testing, we conclude Theorem 2.8 FOr every k (for all L and \nk) there exists a deterministic polynomial time algorithm for testing whether a grammar is C(k) (O(L,k)). \nIt is important to note that this theorem fixes k before selecting the deci\u00adsion procedure. That is, \nit establishes the existence of separate (and distinct) polynomial time algorithms for C(O) testing, \n0(1) testing, etc. We can also apply Theorem 2.7 to the case in which we have a single decision pzm\u00adcedure \nwhich takes both k and a grammar as inputs. Theorem 2.9 An arbitrary grammar can be tested for membership \nin C(k) (or in Ct(L,k)) in non-deterministic time which is polynomial in both k and n (poly\u00adnomial in \nL, k and n). Section 3 Lower Bounds In this section we develop an idea of Hartmanis [2] to yield lower \nbounds on the complexity of LR(k) testing. Suppose that M is a non-deterministic Turing Machine which \nalways halts before taking more than T(n) steps on any input of length n. Given an input string x, we \ncan construct two context free languages LI (M,x) and L2(M,x) such that = {x#lx is the initial id of \nMon x) 1 o o(yRev#y#ly isa configuration ofM)* {z#\\ z is an accepting configuration of M) o {#l*o {$1 \n = {y#zRev # I Y and z are configurations 2 of Mand y~ z)* o {#)*o ($1  It is easy to verifythatM accepts \niff L, (7Ln # ~. Moreover, L, and L. are J-L -LL generated by s-grammars [5] , that is gram\u00admars in \nwhich every right side of a produc\u00ad tion begins with a terminal and no two productions for the same nonterminal \nbeqin with the same terminal. Lemma 3.1 Let M, T and x be as above. Letk=T2(\\xl) +4T xl) +3. Then in \ntime O(lxl we can find gram\u00adand G3, each of size c + lx!, ars 1 G2 where c depends only on M, such that \nthe following are equivalent. 1) M accepts x 2) L(G1) llL(G2) # @ 3) Some pair of words in L(Gl) and \nL(G2) have a common prefix of size ~ k 4) 3 is ambiguous 5) 3 is not C3(k) 6) 3 is not ~(l,,k) for \nany &#38; 7) 3 is not LALR(k) . G1 and G2 are the s-grammars gen- J2ZQSZ erating L1(M,X) and L2(M,x) \nrespectively. is the grammar whose productions are 3 all of the productions of G and G 12 along with \ns -I ASl\\BS2, A + # and B + #. The equivalence of the first four conditions should be obvious from the \nre\u00ad marks preceding the statement of the lemma. condition 4 clearly implies conditions 5, 6 and 7. Moreover, \nfor each grammar class represented by a, it is possible to verify that G3 can fail to be in G only if \nL(Gl) flL(G2) #@. Thus the last 3 condi\u00ad tions of the lemma are equivalent to the first four. Finally, \nwe point out that in the case of (3 representing the class of ex\u00adtended precedence grammars, it is necessary \nto perform minor alterations on G to make it uniquely invertible before cla?ming the above lemma. rl \n Let us turn next to the main topic of this section, namely uniform algorithms for ~(k) testing. Theorem \n3.2 Let Q be any algorithm which takes a context free grammar G and an integer k (pair of integers L \nand k) as inputs and determines whether G is L3(k) (~(l,,k )). Then there exists as constant c such that \n0 requires more lGlc@ units of timeon infinitely many input pairs (G,k). proof Directly from Lemma 3.1. \nn The next theorem recasts this result in terms of the amount of space needed to represent both input \nparameters. Theorem 3.3 The problem of determining whether G is C?(k) or &#38;(L,k) with both G and k \n(or t and k) considered to be parameters is a) complete for non-deterministic poly\u00adnomial time if k \n(or L and k) are expressed in unary, b) complete for non-deterministic expon\u00adential time if k (or L and \nk) are expressed in binary. The fact that the problems can be done within the required time bounds follows \ndirectly from Theorem 2.9. = To see that the problems are in fact complete we need only consider the \namount of space needed to represent both the grammar G3 and the value of k mentioned in Lemma 3.1. Let \nS(lxl) be the space needed when k appears in unary and S (1x1) be the space used when a binary representation \nis employed. Then S(!xl) =O(lX\\+T2(\\Xl)) ands (lxl) =O(lx\\ +log T(lxl )). If T is a polynomial function \nthen S is also a polynomial function. If T is an exponential function then S is Still a polynomial function. \nn Note that we have shown LALR(k) testing to be at least as hard as the above, but have not provided \nthe upper bound as we did for the classes represented by &#38;(k) and C(//,k) . Conclusions The undecidability \nof problems involv\u00ading context free grammars is an accepted fact. We have shown that even if one drastically \nrestricts the questions which one is allowed to ask (for example, by asking whether a grammar is LR(k) \nfor some particular k rather than whether, there exists a k for which the grammar is LR(k)) then the \nresulting problems are still intractable. MOre specifically, we have shown that no good, uniform algorithm \nexists for testing LR(k)-ness (or any of a number of similar properties) if k is allowed to be a Parameter \nof the algorithm. We leave as an open question whether there exist algo\u00adrithms for specific values of \nk which are k+2 faster than the O(n ) class of algorithms presented herein. References [1] Hunt, H.B. \nIII, T.G. Szymanski and J.D. Unman Operations on Sparse Re\u00adlations and Efficient Algrithms for Grammar \nProblems, IEEE Conference Record of 15th Annual Symposium on _ Switchinq and Automata Theory (1=4) . \n [2] Hartmanis, J. Context-Free Languages and Turing Machine Computations. Pro\u00ad ceedings ~ Symposia &#38; \nApplied Math\u00adematics, Volume 19, pp 42-51, 1967. [3] Aho , A.V. and J.D. Unman, The Theory of Parsinq \nTranslation and ~pilinq, ~entice-Ha~l, 1972 and 1973. f4] Knuth, D.E. On the Translation of Languages \nfrom Left to Right, Infor\u00admation and Control, 8:6,pp 607-639, 1965. [5] Korenjak, A.J. and J.E. Hopcroft \nsimple Deterministic Languages, IEEE Confer\u00ad ence Record of 7th Annual Symposium on Switching and Automata \nTheory, pp %-46, 1966. [6] Brosgol, B.M. Deterministic Trans\u00adlation Grammars, TR-3-74, Center for Research \nin Computing Technology, Harvard University, 1974. [7] Younger, D.H. Recognition and Parsing of Context-free \nLanguages in Time n3, Information and Control, 10:2, pp 189-208. \n\t\t\t", "proc_id": "512976", "abstract": "In this paper we derive upper bounds on the complexity of LR(k) testing both when k is considered to be a fixed integer and also when k is considered to be a parameter of the problem. In the latter case, we show that the lower bounds on the running time of such algorithms depend very strongly on the representation chosen for k. Thus LR(k) testing is NP-complete when k is expressed in unary and complete for nondeterministic exponential time when k is expressed in binary.These results carry over to many other parameterized classes of grammars, such as the LL(k), strong LL(k), SLR(k), LC(k), strong LC(k), BRC(<i>l</i>,k), BC(<i>l</i>,k) and extended precedence (<i>l</i>,k) grammars.", "authors": [{"name": "Harry B. Hunt", "author_profile_id": "81337489860", "affiliation": "University of Wisconsin, Madison", "person_id": "PP42050709", "email_address": "", "orcid_id": ""}, {"name": "Thomas G. Szymanski", "author_profile_id": "81100648246", "affiliation": "Princeton University", "person_id": "PP39052384", "email_address": "", "orcid_id": ""}, {"name": "Jeffrey D. Ullman", "author_profile_id": "81100314798", "affiliation": "Princeton University", "person_id": "PP39037330", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512976.512990", "year": "1975", "article_id": "512990", "conference": "POPL", "title": "On the complexity of LR(k) testing", "url": "http://dl.acm.org/citation.cfm?id=512990"}