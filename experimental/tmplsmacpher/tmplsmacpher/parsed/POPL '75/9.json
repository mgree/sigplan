{"article_publication_date": "01-01-1975", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1975 ACM 0-12345-678-9 $5.00 A SEMANTIC MODEL FOR PARALLEL SYSTRMS WITH SCHEDULING Ellis S. Cohen Department \nof Computer Science Carnegie-Mellon University Pittsburgh, Pa. 15213 Abstract This paper presents a \nsemantic model for par\u00adallel systems with a scheduling mechanism that is useful for expressing and proving \na wider range of properties than semantic models that do not consid\u00ad er scheduling. We formally describe \na number of properties related to scheduling and deadlock, including !!Fairne~~lT and !lFullneas!f, and \nshow that schedulers with these properties behave in desirable ways. Laatly, we prove and conjecture \nsome proof rules for scheduled systems and outline briefly the relation of this work to modelling protection \nin parallel systems. Introduction Using Scott s Mathematical Theory of Computa\u00adtion [Scott 72], Cadiou \n&#38;Levy [Cadiou &#38;Levy 73] have introduced a model of parallel procesaea based on processes that \ncommunicate by sharing memory, and have ahown how to state and prove properties such as mutual exclusion \nformally within the mech\u00adanizable LCF system. They treat nondeterminism by introducing an oracle from \nthe domain TT$< (string of truth values, see [Kahn 73]). The determination of which pro\u00ad cess to execute \nnext depends on an initial sequence of the oracle, with the remainder becoming the new oracle. In spite \nof the elegance of their system, they are unable to prove certain properties of par\u00adallel systems that \none would expect to be true. Primarily this trouble sterna from the difficulty of characterizing the \nwell-behavedneaa of their oracle. By using a model derived from Lipton s work [Lipton 73], we replace \nthe oracle with a scheduler and state a property of schedulers, fair\u00adness, which is shown to be adequate \nto prove a property of a particular parallel system that is difficult to express in Cadiou &#38; Levy \ns system. This work was supported by the Advanced Research Projects Agency of the Department of Defense \nunder contract no. F44620-73-c-O074 and monitored by the Air Force Office of Scientific Research. Factors \nin Choosing a Model There are three major concerns that have prompted the particular model that will \nbe de\u00adscribed in this paper. 1) It is difficult (at best) to characterize anomalous oracles, since anomaly \ndepends so heavily on the changing nature of the state. For example, in a 2 process P/V system, Cadiou \n&#38; Levy are only able to prove that one or the other will run for\u00ad ever, while under a reasonable \nfair scheduler, we would expect both to run forever. By providing a model with a Scheduler, we can characterize \nthe Scheduler in such a way that anomalous schedules can be avoided. Thus, we will replace the Oracle \nby a Scheduler which has acceas to the state of the system. When pulsed, \\t selects a particular pro\u00adcess \nto be run as well as producing a new scheduler to schedule the next process (presumably by modify\u00ading \ninternal variables or queues). 2) We want to model situations where one pro\u00ad cess may arbitrarily start, \nstop or otherwise con\u00ad trol another process. Thu S , the model contains a multiplexer M, which may be \nviewed as a vector of processes. The Scheduler sp ecifies a process to be run by supplying an integer \nindex into M. 3) There is no way to easily characterize those processes which are blocked if synchroniza\u00adtion \nis modeled aa busy waiting. In actual sys\u00adtems, we expect schedulers to have two functions. First, to \nschedule processes which can run, and second, to not schedule those which cannot. Thus , following Lipton \n[Lipton 73], we describe the code of an individual process as a labelled flowchart, where each box of \nthe flowchart is called an EP (Elementary process) and representa an entity which is indivisibly executed. \nAn EP consists of three parts, the first of which (SYNCHFORM) represents a synchronize tion 4con\u00addition. \nIf the Scheduler schedules a process, and the synchronization condition of its current EP is not met, \nno action is taken, and the Scheduler is simply invoked to schedule again. If the synchro\u00adnization condition \nis met, the other two parts of the EP are (indivisibly) executed. One part (STATSFOFM) .hanSes the data \nstate <S) f the sys\u00ad tem, and one part (CONTROLFORM) changes the control state (M) of the system (specifying \nthe label of the next EP of the current process or starting, stopping or otherwise controlling another \nprocess. Action(n)(m) <== Prcs(m(n) .LABEL)(m(n).ARGS) . One special label is STOP and denotes the end \nof a (Note: Given an index n (produced by the sched\u00ad process. ) uler) and a multiplexer m, Action produces \nthe EP selected to run. ) So, evaluation proceeds in the following way: First the Scheduler produces \nan index into the Exec: N+[SXM+SXM] multiplexer (as well as a new Scheduler to schedule the next iteration). \nIf the label indexed is Exec(n)(s,m) <== USTOpiJ, then no further action is taken for this Let <ayfrm,stfrm,cfr@ \nbe Action(n)(m) in iteration. Otherwise, the labelled EP is executed. Synchfn(syfrm. NAME) (syfrm.ARGS) \n(s) -( First its synchronization condition is tested. If Let <s ,resul= be Stat.efn(stfrm.NAME) false, \nno further action takes place with the EP. (stfrm.ARGS) (s) in If true though, the rest of the EP is \nevaluated to <s ,Controlfn(cfrm.NAME) (cfrm.ARGS) update both the data state (S) and the multiplexer \n(result),(m)>) , (M) . <s,@. (Note: Given the current sta~te of the system The Formal Model (s and m), \nExec produces the new state when the scheduler has selected process n to run.) Primitive Domains The \nreader is encouraged tc, look ahead to the TT -truth values Applications section for an example of how \na par- N\u00adnatural numbers ticular system would be modelled. LABEL -labels, including the element STOP \nARG -function argument In this model (as in actual. systems), it is NAME -names of functions not so clear \nwhen computation stops (for example, S -states an idle process may run in an Operating system when nothing \ncan otherwise be scheduled). However, for Constructed Domains simplicity, we will aasume a continuous \npredicate, SYNCHFORM = NAME X ARGS Mstop. STATEFORM = NAME X ARGS CONTROLFORM = NAME X ARGS Mstop: SXMXSCRRD+TI \nEP = SYNCHFORM X STATEFORM X CONTROLFORM M = N + LABEL x ARGS For example, if the scheduler returns a \nzero ARGS = ARG* (We will indicate the least defined index when there is nothing to schedule, then we \nelement of this domain as < > rather than UU. could define Mstop as: If we know that an element of ARG* \ncontains a particular fixed number of ARGs, we will use Mstop(s,m,sched)<==(sched (s,m).1~ = O). tuple \nnotation, e.g. <a,b,c> rather than a #b # c, where #t is the string concatena- In any case, we can define \nthe result (final tion operator.) state) of running mO with state sO and scheduler SM=SXM schedO as Mmem(sO,mO,schedO) \nwhere Mmem is defined as The Scheduler Mmem(s,m,sched) <== SCHRD=SXM+NXSCHED Mstop(s,m,sched) + S, Mmem(Next(s,m,sched)). \nPrimitive Functions Properties of Scheclulers Synchf n: NAME + [ARGS + [s + TT]I Statefn: lUiME + [ARGS+ \n[S+ S xARGS]] Treatment of schedulers in this paper will be Controlfn: NAMR -[ARGS + [ARGs + [M +M]]] \nindependent of any particular synchronization prim- Prcs: LABEL + [ARGS +EP] itives (e.g. P/V, P/Vchunk, \nup/down) and any par\u00ad (Note: Synchfn , Statefn and Controlfn titular implementation or internal structure \nof the map formal names into the functions they represent. Ilprcall maps a label into a class scheduler \n(e.g. FIFO queues, priority order), rath\u00ader we simply express a number ojE scheduler proper\u00ad of EP s; \na particular one is selected by ARGS. ) ties using the model. The properties described are either ones \nthat will be used later in the paper, The Interpreter or ones that have appeared already in the litera\u00ad \nture. A comparison of these properties by example Next: SXMXSCHED +SXMXSCHED can be found in the Applications \nsection of this paper. Next(s,m,ached) <== Let <n,sched > be sched(s,m) in The properties as described \nare dependent m(n).LABEL = STOP + <s,m,sched >, heavily on S and M as well as the scheduler, where- Let \n<s , m > be Exec(n)(s, m) in <s , m , sched >. as commonly, we are simply interested in a property of \na scheduler independent of what it schedules. (Note that ifAB = A x B, and ab: AB (ab is The last section \nof this paper notes how this can of type AB), then we use ab. A and ab. B to indicate be dealt with. \nthe projections of ab onto its A and B components respect ively. ) Notes: We will be using process j \nto indicate Action: N+[M-EP] the continuing behavior of the (contents of M(j). We use the notation [= \nto mean less defined than -also . -Strong equivalence (a z b iff a[=bAb[=a)  ![ -Strictly less defined \nthan (a J[ b iff a[=bAm(a=b)) Note that string domains (e.g. ARG$< and T lW) areorderedby<>[= a[=(a#b)anda=a \n#<>. 1. Defined (sched) (sjm) Def(s,m,sched) <== tt # Def(Next(s,m, sched)). Defined(sched) (s,m) iff \nDef(s,m,sched) ~ t@ 2. Full(sched) (s, m) -A scheduler is full if if does not schedule an unrunnable \nprocess when a runnable process can be run. Canrun(k)(s, m) <== m(k) .LABEL = STOP + ff, (Let syn be \nAction(k) (m).SYNCHFORM in Synchfn(syn. NAMR) (syn. ARGS) (s) ) . Runnable (j, k)(s, m,sched) <== (j \n-I= sched(s,m). NV Canrun(j)(s,m) V -Canrun(k) (s ,m)) #Runnable(j,k) (Next(s,m,sched) ). Full (sched)(s,m) \niff (Vj, k)(Runnable(j,k) (s,m, ached) [= tt;~) 3. Release(sched) (s,m) -A scheduler is a release scheduler \n[Lipton 73] if, when some action unblocks a set of processes, then some process from that set will be \nthe next to run. Unblock(k) (s,m,sched) <== Let <s , m , sched > be Next(s, m,sched) in (Canrun(k)(s,m) \n+ tt, Canrun(k)(s ,m ) + ( Let n be sched (s , m ). N in n =k+tt, mCanrun(n ) (s, m) A Canrun(n ) (s \n,m )), tt) # U,,block(k) (s ,m ,sched ). Release(sched) (s,m) iff(Vk) (Unblock(k) (s,m, sched) [= tt~r) \n4. Ready~un(sched) (s,m) -A scheduler has the Ready Run property when no process has to wait forever \nto run from the time it becomes continuously capable of running. We actually state this in the logic \nas \u00adany process which is unable to run at most a finite number of times must run infin\u00aditely often. Some \nthought should convince the reader that these are the same. Run(j) (s,m,sched) <== T(j = sched(s,m).N \nA Canrun(j)(s,m)) #Run(j) (Next(s,m,sched)) . t(p) <== p + tt, Uu. Cantrun(j) (s, m,sched) <== ?(-Canrun(j)(s,m)) \n# Cantrun(j) (Next (s,m,sched)). Ready \\ Run(sched)(s,m) iff (Vj)(Cantrun(j) (s,m, sched) ![ tt~ < 2 \nRun(j) (s,m, sched) ~ tt$ ) 5. Pointer / Bounded (sched)(a,m) -A scheduler is pointer bounded [Lipton \n73] when a pro\u00ad cess able to run infinitely often is scheduled infinitely often. (We will see in the \nApplication section that both Ready\\Run and Pointer\\Bounded are too weak and that Fairness is a more \nappropri\u00ad ate property.) Tried (k)(s, m,sched) <== ?(k = sched(s,m).N) # Tried(k) (Next (s,m,sched)). \nInfcan(k) (s,m,sched) <== t(Canrun(k)(s,m)) # Infcan(k) (Next (s,m, sched)) . Pointer \\ Bounded (sched)(s, \nm) iff (Vk)(Infcan(k) (s,m, sched) = tt~~ o Tried (k)(s,m, sched) z tt~<) 6. Fair(sched)(s, m) -A scheduler \nis fair if any process able to run infinitely often, runs infinitely often at times that it canrun (is \nnot blocked or stop). Fair(sched)(s,m) iff (b k) (Infcan(k) (s,m, sched) z tt ~ Run(k) (s,m,sched) ~ \ntt~ ) 7. We say a scheduler sched is an idling extension of sched if a. (sched(s,m) = uu A (Vk)(-canrun(k) \n(s,m))) + sched (s,m).N = O, sched (s,m).N ~ sched(s,m).N b. sched (s, m). SCHRD is an idling extension \nof sched(s,m).SCHED This corresponds nicely with the example definition of Mstop in the previous section. \nIt is easily provable that every scheduler has an idling extension, that Defined(sched )(s,m) and Run(j) \n(s,m, sched) ~ Run(j) (s,m, sched ). Also Full(sched) (s,m) ~ Pull (sched )(s, m) and similarly for Fair. \nFairness is in general the weakest propert~ (along with definedness) that we would ever demand of a legitimate \nactual scheduler. Luckily, fair\u00adness (with definedness) will be adequate for prov\u00ading properties that \nwe are interested in. However, proving certain properties (in particular, the ex\u00ad ample proven in the \nnext section) given fairness alone turns out to be somewhat difficult. The key problem is knowing exactly \nwhen a particular ac\u00adtion will occur, even when it ia known that it must occur eventually. This problem \noften disappears if the scheduler is full as well. So we will show that to prove: A. De fined (sched)(s,m), \nFair(sched)(s, m), Q(j,s,m) ~ Run(j) (s,m,sched) ~ tt$r it is sufficient to show that B. Defined(sched) \n(s,m), Fair(sched)(s,m), Full(sched)(s, m), Q(j, s,m) ~ Infcan(j) (s,m, ached) ~ tt* Proof: Suppose \nthere were a function Fullsched: SCHED + SCHED s.t. for any scheduler sched, 1. Full(Fullsched (sched)) \n(s,m) 2. Run(j) (s,m,Fullsched(sched)) s Run(j) (s,m, sched) 3. Infcan(j) (s, m, Fullsched(sched)) \n[=  Infcan(j) (s,m,sched) Now, suppose Defined(sched) (s,m), Fair(sched) (s,m), Q(j,s,m), but Run(j) \n(s,m,sched) ![ tt*. Since Fair(sched)(a, m), Infcan(j )(s,m, sched) ![ tt*. rhus by (l), (2), and (3), \nFull (Fullsched(sched)) (s,m), Run(j) (s,m,Fullsched(sched) ) J[ tt~. and Infcan(j) (s,m,Fullsched(sched) \n) ![ tt*  Then trivially, Fair(Fullsched(sched)) (s,m) , by defn of Fair. Now, let fsched be an idling \nextension of Fullsched(sched) . Then Defined(fsched) (s,m), Fair(fsched)(s,m), Full(fsched)(s,m) and \nRun(j) (s,m, fsched) ![ tt*. If we can prove (B), then Infcan(j)(s,m, fsched) = tt$<, and by defn of \nFair, Run(j) (s,m, fsched) = tt*. TINIS, we have a contradiction to Run(j) (s,m, fsched) 1[ t~<, and \ntherefore the original hypoth\u00adesis that Run(j) (s,m,sched) ![ tt* must be false. Since it is easily shown \nthat Run(j) (s,m,sched) [= tt~c, it must be case that Run(j) (s,m,sched) = tt~~ and (A) follows. Definition \nof Fullsched and proofs of (l), (2) and (3) can be found in [Cohen 74]. Applications . Some above can \n(adapted executing notion be from the g of ained [Lipton loop: the by 72]) properties consideration of \nthree in p the seof the rocesses, ction example each ---~----> P(sem) ------> V(sem) ----I I I, -------------<------------------. \nwhere the initial value of sem is 1. (We will describe execution sequence as a sequence of pi and vi, \ni=l,2,3 to denote the exe\u00adcute of a P or V by the i th process.) Under a scheduler that is merely defined \nand full, the execution could simply be pl V1pl VI pl V1pl VI ... That is, processes 2 and 3 might never \nexecute. If the scheduler is additionally a Release scheduler, the execution could be pl V1p2V2pl VTp2v2pl \nV1p2V2... that is, VI releases P of process 2 and V2 releaaes pl, but again process 3 might never be \nexecuted. If the scheduler additionally has the Ready\\ Run property, it helps matters not at all, since \nprocess 3 is never continuously capable of running. It is blocked each time process 1 or 2 executes a \nP. Likewise the Pointer\\Bounded property does not help, since process 3 might only be tried when it is \nblocked. If the scheduler though is merely defined and fair, each of pl, p2, p3, vI, V2 and V3 must exe\u00adcute \ninfinitely often. We will prove that last statement for the more general case where there are n processes. \nAs al\u00adready noted, this is a problem that Cadiou &#38; Levy would have difficulty proving. To simplify, \nwe will assume that the state s is identically sem, and we will define the follow\u00ading functions: true(args) \n(s) <== tt. tst(args) (s) <== (s = 1). clr(args) (s) <== <O,< > >. set(args) (s) <== <1,< > >. go(<n,lbl, \nargs>)(res) (m) <== lk. (k=n + <lbl, args>, m(k)). Introducing some notation, we use label(args): When \nsyf(sya) do stf(sta) ==> cf (ca) to represent the EP <<syf,sya,<stf,sto,<cf,ca>> where the EP is the \nresult of Prcs(label)(args). Where sya, sta or ca are < > (no arguments) , we eliminate parentheses as \nwell. We further use the notation : n=> lbl(args) for ==> GO(n,lbl,args) (Note: Function definitions, \nlike go , have their names in lower case. The formal name, (e.g. GO , from the domain NAME) is the same \nname written in upper case.) So, the parallel system described pictorially above has two Labels, P and \nV, and its formal de\u00adscription for n concurrent processes is: P(+): When TST do CLR :k=> V(<&#38;-) V(-): \nWhen TRUE do SET :k=> P(<!+) pmo(nprcs) <== lk. (Range (k, nprcs) -<P,->, <STOP, u@) . so <== 1.  where \nRange(k,n) <== k 2 1 A k < n. Now, the problem can be stated in the ogic as, Prove: Defined(schedO) (sO,pmO(n) \n), Fair(schedO)(sO pmO(n)), Range(k,n) ~ Run(k) (sO,pmO(n),schedO) ~ tt* By the results of the previous \nsection, we can also assume that Full(schedO) (aO,pmO(n)) and simply prove Infcan(k) (sO, pmO(n), schedO) \na tt*. Proof: Defined(schedO) (sO,pmO(n)), Fair(schedO) (sO,pmO(n)), Full(schedO) (sO, pmO(n)), Range \n(k, n) 4 Infcan(k) (sO,pmO(n),schedO) s tt$ Infcan2k(j) (s,m, sched) (k) <== ?(Canrun(j) (Desc(s,m,sched) \n(2*k).SM)) # t(fJanrun(j) (Desc(s,m, sched)(2*k+l). SM)) # Infcan2k(j) (s,m, sched)(k+l). Lemma 1 Defined \n(sched)(s,m) A Full(sched)(s,m) 3 (Vk)(Let <s ,m ,sched > be Desc(s,m,sched) (k) in Defined (sched )(s \n,m ) A Full(sched )(s ,m )) Proof: Math Ind on k Lemma 2 Infcan2k(j) (s,m,sched) (k) s Infcan(j) (Desc(s,m, \nsched) (2*k)) Proof: Parallel Comp Ind on Infcan2k and Infcan Lemma 3 De fined (schedO) (sO, pmO(n)), \nFull(schedO) (sO, pmO( n)) -i Let <s ,m ,sched > be Desc(sO,pmO(n),schedO) (2*k) , <s ,m ,sched > be \nDesc(sO,pmO(n),schedO) (2*k+l ) , j be sched (s ,m ) in Range (i, n) 3 Canrun(i)s , m ) A Canrun(j)(s \n,m ) A i+ j D+anrun(i)(s , m ) Proof: Math Ind on k using the system definitions in the Applications \nsection and Lemma 1. Lemma 3 Defined(schedO) (sO,pmO(n)) , Full(schedO) (sO,pmO(n)) , Range(j,n) ~ Canrun(j) \n(Deac(sO,pmO(n), achedO)(2*k).SM) ~ tt The proof of the theorem follows directly from ! Lemmas 2 and \n3a. We can also state (though we will not prove) the mutual exclusion problem as Range(j,n), Range(k,n), \nj#k ~ Mutex(sO,pmO(n), schedO) = < > Mutex(j,k) (s,m,sched) <== ?(m(j).LABEL= m(k) .LABEL = V) #Mutex(j,k) \n(Next(s,m,sched)). Deadlock Briefly, we can state some deadlock properties in the logic based on the \nmodel. 1. Starved(k) (sched)(s,m) -A process is starved [Dijkstra 72] if it is not STOPr! and is continuously \nincapable of running. Insafe(k) (s,m, sched) <== t(m(k).LABEL = STOP or Canrun(k)(s,m)) # Infsafe (k)(Next(s,m, \nsched)). Starved (k)(sched)(s, m) iff Infsafe(k) (s,m, sched) ![ tt~t 2. Deadlock(ached) (s,m) -The system \nis dead\u00adlocked if some process becomes starved, Deadlock(sched) (s,m) iff (3k)(Blocked(k) (sched) (s,m) \n) 3. Safe (s,m) -We are often interested, re\u00adgardless of the scheduler whether or not a particular set \nof processes can ever lead to deadlock. If not, the system is safe. Yet, we cannot ignore the scheduler \ncompletely, as degenerate schedulers can lead to anomalous behavior as we noted in an earlier section. \nWe take as a minimal requirement that the scheduler be fair and defined.  Safe (s,m) iff (Vsched) (Defined \n(ached) (a, m) A Fair(sched) (S,m) > (Vk)(Inaafe (k)(sched)(s,m) s tt*)) Clearly, the P/V system of \nthe previous section is safe. Of course, it is in general undecidable wheth\u00ader or not <s,ti is safe \neven in simple systems such as P/V (with conditionals), and even knowing that under a particular fair, \nfull, defined scheduler, deadlock cannot occur. Consider s composed of a semaphore, sem, init\u00adially O, \nintegers k and n, initially O, and f, a description of a total function of type N + IT. And lat m be \nrunning the two processes informally described by: -. Process 1 Process 2 k:=O; k:=1; n := o; loop V(aem) \n; if k = O then V(sem); loop P(sem) ; if Eval(f) (n) then V(sem); endloop n := n+ 1; endloop  Now, \nunder a scheduler that runs process 2 first, the eventual value of k will be O and there will never be \ndeadlock, but if process 1 runs first, k will be 1, and determining Safe(s,m) becomes equivalent to deciding \nwhether f is true infinitely often, which is reducible to the halting problem. Modelling Protection Systems \n In the model presented, each process operates on a common memory state S. Yet in programming systems, \ndifferent processes do have different ac\u00adcessing rules for accessing the memory (e.g. Frames, Contours, \nVirtual or Local Name Spaces and Execution Domains). By passing the EP its multi\u00adplexer slot as an argument, \ndifferential accessing of S can easily be achieved. For example, if S = N + DOMAIN, then if p is executing \nin Multi\u00adplexer slot k, s(k) could represent its execution domain. It would also be useful though for \neach pro\u00ad cess to execute its own program (set of LABELs) rather than having a monolithic primitive \nfunction Prcs . Such a change is rather simple, redefine M S0: M= N* PROGXLABEL x ARGS PROG = LABEL + \n[ARGS + EP] and redefine action to be Action(n) (m)<==( (m(n) .PROG) (m(n) .LABEL)) (m(n) .ARGS) . All \nprevious results hold, although we would have to change the definition of go in the ap\u00adplication section \nto be: go(<n,lbl, args>)(res) (m) <== Xk. (k=n +<m(n). PROG,lbl, args>,m(k))  Now , consiser the modelling \nof a segmented operating system with this modification. Process j s data segments would be part of S, \nwhereas its code segment would be modeled directly by the PROG component of M(j). We could then model \nthe start\u00ading of a new program by the EP: Start(<n,se@): When TR~ do CONTENTS(<se@) ==> LOADGI)(<n>) \nwhere contents(<se@) (s) returns as its result the contents of segment set (in state a) , and loadgo \n(<o) loada up those contents inM(n) and begins executing the process. Loadgo(<ti) (segcontents) (m) \n<== lk.(k=n +<link(segcontents),BEGIN,<@>,m(k)) whe~e link(x) assembles x into PROG form with start \naddreas, BEGIN. An interesting byproduct is that one can model a process changing a data segment of \nanother pro\u00adcess (possible in systems with shared data) by us\u00ading a STATEFORM, whereas a change in an \nexecuting process s code segment (most likely a bug) can only be modeled by using a CONTROLFORM (like \nLOADGO). In fact, in pursuing this modified model, just such a bug was discovered in CMU S HYDRA sys\u00ad \ntem. (The bug in HYDRA can be circumvented by the use of frozen pages (see [Rotenberg 74]). A frozen \ncode page is permanently protected against modification.) Other small changes in the model make it more \nuseful for describing and proving properties about protection systems. [Cohen 75] will report further \nresults. A Conjectured Induction Rule We will often want to prove A. Defined(schedO) (sO,mO), Fair(schedO) \n(sO,mO) -1 Run(j) (s O,mO, schedO) = tt* undar more difficult conditions than in the toy ex\u00ad ample of \nthe applications section. The following induction principle (which is a generalization of the principle \napplied in proving that example) would be useful to prove. Suppose that (W, <) is a well-founded set \n with a set of least elements WO, and that P: W X N + [S x M + TT] and Closer: WxN*Nare total. Then to \nprove (A), it is sufficient to prove a. Q(j, s,d q (3w)(P(w, j)(s,d) b. WO 6 WO, P(wO, j)(s, m) + Canrun(j)(s, \nm) C. WO<WI, P(wo,j)(s,m) -[(vk)(3w)(p(w, j) (Exec(k)(s,m))) d. w T< WO, P(w, j)(s, m) -1  (Vk)(3w \n~)(P(w , j)(Exec(k)(s,m))) A (3w <w) (p(w ,j) (Exec(Closer(w, j)) (s,m))) which says that whatever state \nthe system is in, either j can run, or if j cannot run, nO matter which prOcess is scheduled, j is nO \nfarther awaY from being able to run and in fact there is always some runnable process that brings j closer \nto being able to run. For the proof in the applications section, let w = {~r]+ {1 ,...,n] and WO= {$ \n], under the order\u00ad ing, ,~< i, i = 1,... ,n. Let P($~,j)(s, m) ~ S= 1 A m(k). LABEL = (Range (k, n) \n+ P, STOP) and P(i, j)(s, m) ~ S= OA m(k).LABEL = (k=i + V, Range(k,n) + P, STOP) and Closer (i, j) = \ni. Then, it is relatively trivial to prove that: a. Range(j,n) ~ P(*,j)(sO,pmO(n)) b. P(*, j)(a,m) i \nCanrun(j)(a,m) c. P(*, j)(s,m) ~  (Vk)(Rahge(k,n) + p(k,j)(Exec(k)(s,m)), P(*, j)(Exec(k)(s,m)) ) \nd. P(i, j)(s, m) A (Vk)(k=i + P( , j)(Exec(k)(s,m)), P(i, j)(Exec(k)(s, m)) which is easily seen to \nsatisfy the induction pred\u00adicates. To simplify proofs, it may be useful to parti\u00adtion the system. We \nwould have to define the no\u00adtion of an independent partition , and then prove that if <ml, . . . ,mj> \nwas an independent partition of m under s, then Safe(s,ml), . . . . Safe(s,mj) -1 Safe(s,m) A Note on \nScheduler Properties AS noted in an earlier section, scheduler properties depend heavily on S and M \nas well as SCHEDi Since future behavior of the system is completely determined by the initial system, \nall we need do is allow the scheduler to be tailor made to the initial configuration. Suppose that we \ndemand that in the initial atate of the system, n < j ~mO(j).LABEL = STY3P, and call this property Init(mO,n). \nThe use of n, fixing an upper bound to the initial number of runnable processes allows us to define a \nrecursive scheduler prototype: PROTOSCHED = N X S X M + SCHED and a scheduler maker Makesched: PROTOSCHED \n+ [N x S x M + SCHED] We say that PROTOSCHED is fair if Init(mO,n) DFair(Makesched(protosched) (n,sO,mO))(aO,mO) \n and similarly for other properties. Conclusion We have introduced a semantic model for par\u00adallel systems \nand have presented a number of prop\u00aderties of parallel systems based on the model as. well as some proofs \nand proof rules. The development with the most potential ap\u00adpears to be the conjectured induction rule \nbased on well founded sets. As Cadiou &#38; Levy note, LCF proofs force the program prover to (sometimes \ntediously) explicate all the possible states of the system. To make proofs of complex parallel programs \nmore tractable, and especially to make the proofs more amenable to automatic verifica\u00adtion, it seems \nclear that some (elegant) embedded or externally imposed (see[Milner &#38;Weyrauch 72]) structure is \ncritical. Well founded sets may be a useful structure for proofs of deadlock; for other properties of \nparallel programs, further exploration is necessary. A somewhat serious deficiency of the scheduler model \n(and other models as well) is its inability to model time dependent behavior; for example, timer interrupts \nin programming systems and timing considerations in machine architecture. While the nature of problems \nto be studied with respect to time dependencies would likely call for a different model in any caae, \nproving the correctness of something like a multiplexer/scheduler for a multi\u00adplexer would likely require \na scheduler model modi\u00adfied in some way to handle time dependencies. Perhaps the most serious problem \nwith the model described here is in the nature of the assump\u00adtions made about how processes interact \n(or should interact). A formal semantics for a sequential programming language with structured control \npro\u00advides a better base for various proofs than a se\u00admantica for a language with GOTO s. Similarly, suitably \nrestricted interactions between processes should provide a better semantic system than the one described \nhere in which arbitrary interactions are allowed. A solution is to provide additional axioms which restrict \nthe possible schedules. disciplines are too unstructured. Work along the lines of Path expressions [Campbell \n&#38;Habermann 74] appear to be more promising in providing a semantic basis in which proofs will be \nless tedious. Acknowledgments I want to express my thanks to Bill Wulf and Nico Habermann for their \ncareful readings of this paper and for their excellent comments and sugges\u00adtions. Bibliography [Cadiou \n&#38;Levy 73] Cadiou, J., J. Levy, Mechaniz\u00adable proofs about Parallel Processes, w Symp osium on Switching \nTheory and Automata, October, 1973. [Campbell &#38;Habermann 74] Campbell, R. H., A. N. Habermann, The \nSpecification of Process Synch\u00adronization by Path Express ions, Proc. Int. Symp . on Operating System \nTheory and Practice, April, 1974. [Cohen 74] Cohen, E., Semantic Models for Parallel Systems, @lU Tech. \nReport, December, 1974. [Cohen 75] Cohen, E., Modelling Protection Systems, @lU Ph.D Thesis, forthcoming. \n[Dijkstra 72] Dijkstra, E., A Class of Allocation Strategies Inducing Bounded Delay Only, SJCC 72. [Kahn \n73] Kahn, G., A Preliminary Theory for Paral\u00adlel Programs, I.R.I.A. Report, January, 1973. [Lipton 73] \nLipton, R., On Synchronization Primi\u00adtive Systems, CMU Ph. D Thesis, June, 1973 or see Proc. 6th Annual \nSym p. on the Theory of Computing, May, 1974. [Manna &#38; Viullemin 72] Manna, Z., J. Viullemin, Fixpoint \nApproach to the Theory of Computation, -. CACM, Vol. 15, No. 7, JuIY, 1972. l!An Algebraic Definition[Milner \n71] Milner, R.j of Simulation between Programs, I.J.C.A.I. 2, 1971. !!Implementation and Applica\u00ad [Milner \n72] Milner, R., tion of Scott s Logic for Computable Functions, Proc. of a Conf. on Proving Assertions \nabout Programs, January, 1972. [Milner &#38;Weyrauch 72] Milner, R. and R. Weyrauch, Proving Compiler \nCorrectness in a Mechanized Logic, Machine Intelligence 7. [Newey 73] Newey, M., Axioms and Theorems \nfor Integers, Lists and Finite Sets in LCF, Stanford AIM-184, January, 1973. [Rotenberg 74] Rotenberg, \nL., Making Computers Keep Secrets, MIT Ph.D Thesis, MAC TR 115, February, 1974. [Scott 72] Scott, D., \nThe Lattice of Flow Dia\u00adgrams, Symp. on Semantics of Algorithmic Languages, Springer Verlag Lecture Notes \nin Mathematics 188, 1971. [Scott 72] Scott, D., Mathematical Concepts in Programming Language Semantic, \nSJCC 72. [Scott &#38;Strachey 72] Scott, D., C. Strachey, Toward a Mathematical Semantica for Computer \nLanguages, Oxford University Computing Lab PRG-6, 1972. \n\t\t\t", "proc_id": "512976", "abstract": "This paper presents a semantic model for parallel systems with a scheduling mechanism that is useful for expressing and proving a wider range of properties than semantic models that do not consider scheduling.We formally describe a number of properties related to scheduling and deadlock, including \"Fairness\" and \"Fullness\", and show that schedulers with these properties behave in desirable ways.Lastly, we prove and conjecture some proof rules for scheduled systems and outline briefly the relation of this work to modelling protection in parallel systems.", "authors": [{"name": "Ellis S. Cohen", "author_profile_id": "81100146153", "affiliation": "Carnegie-Mellon University, Pittsburgh, Pa.", "person_id": "PP31029345", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512976.512986", "year": "1975", "article_id": "512986", "conference": "POPL", "title": "A semantic model for parallel systems with scheduling", "url": "http://dl.acm.org/citation.cfm?id=512986"}