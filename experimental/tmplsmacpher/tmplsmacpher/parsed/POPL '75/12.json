{"article_publication_date": "01-01-1975", "fulltext": "\n On the Complexity of the Circularity Test for Attribute Grammars Permission to make digital or hard \ncopies of part or all of this work or personal or classroom use is granted without fee provided that \ncopies are not made or distributed for profit or commercial advantage and that copies bear this notice \nand the full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute \nto lists, requires prior specific permission and/or a fee.&#38;#169; 1975 ACM 0-12345-678-9 $5.00 M. \nJazayeri,* University of North Carolina W. F. Ogden, Case Western Reserve University W. C. Rounds, University \nof Michigan ABSTRACT It is shown that both the upper and the low\u00ader bounds on the time complexity of \nthe circular\u00adity test for Knuth s attribute grammars are ex\u00adponential functions of the size of the grammar \ndescription. This result implies the intract\u00adability of the circularity test in the sense that the implementation \nof a general algorithm is not feasible. Another significance of this result is that this is one of the \nfirst problems actually arising in practice which has been proven to be of exponential time complexity. \nI -Summary In section II we will review attribute gram\u00admars as defined by Knuth [1] and discuss the cir\u00adcularity \nproblem associated with them. In section III we will concentrate on the complexity of any algorithm to \ntest an arbitrary attribute grammar for circularity. By embedding into the circular\u00adity problem the membership \nproblem for writing pushdown acceptors, which is known to be exponen\u00adtial, we derive a lower bound of \n*c*n/log(n) for the time complexity of the circularity test. In section IV we propose an algorithm for \nthe circu\u00ad larity test which implicitly provides us with an upper time bound of ~c*n for the circularity \ntest. Finally, in section V, we will briefly discuss the implications of these results. II -Attribute \nGrammars 11.1 -History Attribute grammars were defined by Knuth [1] in 1968 as a tool for formally defining \nthe syn\u00adtax and semantics of programming as well as natu\u00adral languages. They were subsequently used by \ndifferent investigators to define the languages SIMULA [2], and PL360 [3]. These applications seem to \nsupport Knuth s original contention that the attribute grammars are a very natural, hu\u00admanly-understandable \nmethod of language definition. Related to the idea of attribute grammars are: Syntax-directed translations \n[4,5], and attributed translations [6]. 11.2 -Definition and Example An attribute grammar is a context-free \ngram\u00admar G with the following additions: T-Each nonterminal has a fixed set of attributes associated \nwith it. A fixed subset of these attri\u00adbutes are of type synthesized and the rest are in\u00adheri ted. 2-Associated \nwith each production X+ B are a number of semantic rules specifying how to evalu\u00adate the values of the \nsynthesized attributes of the left-hand side nonterminal X, and the inherited attributes of the nonterminals \nin the right-hand side string B, The semantic rule for evaluating each attribute can be any computable \nfunction of the attributes of any nonterminal appearing in the same production. The attributes serve \nto specify the context-sensitive features as well as the se\u00admantics of the language. An example attribute \ngrammar G is shown in Table I. TABLE I Start Symbol: A Nonterminals: {A, B, C} Terminals: {x, y, z} Attributes: \nsynthesized: {al, bl, Cl} inherited: {a2, b2, C2, C3} Productions &#38; semantic rules: 1) A+ BCZ a, \n= b1+5 b2 = f(cl ) ~2 . 26 C, 56 C3 = * The work supported of this by the author, while a graduate student \nat Case Advanced Research Projects Agency of the Western Reserve University, Department of Defense under \nwas partially Contract Number DAAB03-70-C-O024. 2) BO+BIX 2) B. (bl )0 = (bl)l bl b2 (b2)1 = (b2)0/12 \n3) B+x = b2 h 4) c+y C1=4 Notes: 1. f is a known function. 2. In production 2 the subscripts are used \nin order to distinguish between the attri\u00adbutes of the left hand side B and the right hand side B.  \nIn practical applications, these attributes could denote a variety of things: they could signify the \ndata type of the nonterminal, its lo\u00adcation in memory, etc. Most interesting context free grammars can \ngenerate an infinite number of derivation trees. An attribute grammar is said to be well-formed if and \nonly if the attributes at any node of any de\u00adrivation tree of the grammar can be evaluated. 11.3 -Dependency \nGraphs Looking at the definition of G in Table I, we see that al, for example, cannot be evaluated in \nany derivation tree unless bl is already eval\u00ad uated and bl in production 2 depends on the right hand \nside b, and in production 3 it depends on b and so on. We can follow this path for a whil!. Inorder toseethis \ninformation more easily, dependency graphs are introduced. A de\u00adpendency graph for a production consists \nof a node for each attribute of the nonterminals of the pro\u00adduction and an arc from attribute ai to attribute \nif ai is used in the evaluation of a.. Figure aj 1 shows the productions (in tree form),Jthe seman\u00adtic \nrules, and the dependency graphs of grammar G. Fig. 1 bl bz al =b1+5 b2=f(c1) C2=26C1 C3=56 /  0 /1x \nH 1 0 bl b2 (b,)o= (b,), (b2)l = (b2)0/12 3) ~ x b, =bz 4) ~ Y \\ c, =4 Notice that the semantic rules \nprovide for in\u00adformation flow throughout the tree and dependency graphs help represent this flow of information. \nAlso note that synthesized attributes carry infor\u00admation upward while inherited attributes provide for \na downward information flow. We can now associate a dependency network with any derivation tree. Fig. \n2 shows a derivation tree and its assocaited dependency network, Fig. 2 A A al a2 //1 A\\ @#Q: Cz / \n,1v ~e~ / bl@2 c1 C2 C3 \\jJ1// .. Y B XYL bl b2 x we try evaluating a , bl, b2 or C2. Now su pose there \nwas an arc fram b2 to b at level 2 in Fig. b 11.4 -Circularity By looking at the dependency network in \nFig. 2 we can tell that we had better evaluate c before 2. This situation is show?I in Fig. 3. Obvious\u00adly, \nneither of the attributes bl or b2 COUltj ~yep be evaluated because to evaluate bl we would need to evaluate \nb2 first and u al % 7\u00b0 vice versa. This would cause al not to be evalua\u00adtable either. Dependency trees \nexhibiting this property are called circular for obvious reasons. An attribute grammar is malformed or \ncircular if it can generate a circular dependency network. Circular attribute grammars are clearly undesir\u00adable \nand one would like to be able to test an at\u00adtribute grammar for circularity. In his second attempt [1.5] \nKnuth gives an algorithm which shows that the circularity problem is decidable. His algorithm has time \ncomplexity 2cn2/log(n), and it appears that a number of other investigators have felt that the problem \nis quite difficult. What we will show in the next two sections is that the circularity test for attribute \ngrammars is in fact of exponential complexity and thus not generally practical. III. Complexity of the \nCircularity Test: Lower Bound In this section we will begin bydemonstrat\u00ading how to simulate a linear \nbounded automaton (lba) using attribute grammars and, consequently, reducing the membership problem for \nlba to the circularity test for attribute grammars. This construction shows the circularity test to be \nquite hard, since the best known algorithms for solving the lba membership problem are exponential. The \ncircularity test will then be proved to actually be of exponential complexity by extending the re\u00adduction \ntechnique to include the membership pro\u00adblem for writing pushdown acceptors. 111.1 -Simulation of Linear \nBounded Automaton A linear bounded automaton (lba) is a Turing machine whose working tape is bounded \nby the length of the input tape, that is, the tape head is constrained to scan only a finite amount of \ntape delineated by left and right end-markers (for a full description, see [7]). The membership pro\u00adblem \nfor linear bounded automata is the following: Given the description of a lba and an input tape for that \nlba, determine whether the lba will ac\u00adcept the input, that is, when started on that in\u00adput, will it \neventually halt in an accepting state. We will assume, for simplicity s sake, that the tape head is always \nscanning the leftmost square of the tape after the lba has accepted the input. We will present a scheme \nfor translating the description of an lba and an input tape to a line\u00adar attribute grammar. The attribute \ngrammar will be circular if and only if the lba accepts the in\u00adput tape. A simple example will be used \nto illu\u00adstrate the procedure. For our purposes, an lba is characterized by a set of states, Q, one final \nstate qf, an alpha\u00adbet E containing s symbols, an input of length n, cl=x, X2X3 . . . Xn, and a number \nof move rules. A move is shown by &#38;(q, x) = [q ,D,y] which expresses the fact that, when the machine \nis in state q, if the lba reads the symbol x on the cur\u00adrently scanned square, the x will be replaced \nby y, the state will be changed to q , and the point\u00ader will be moved one square in the direction D. \nD can be R meaning right, L meaning left, or S mean\u00ading stationary, indicating no movement. The nonterminals \nof the associated attribute grammar are ordered pairs <q,x> where q is a state and x is a tape symbol \nof the lba. Each nonterminal has two sets of attributes, each con\u00adtaining 2n-1 subsets. Set 1 contains \ninherited attributes and each subset contains s attributes, where s is the number of symbols in the tape \nalpha\u00adbet of the lba. Set 2 contains synthesized attri\u00adbutes and each of the 2n-1 subsets contains only \na single attribute. The inherited attributes are used to keep track of the current tape contents, and \nthe synthesized attributes are used as return paths in the circuit that we are trying to create. We refer \nto the inherited attributes by I(j,x) where j signifies that the attribute belongs to the jth of the \n2n-1 subsets of inherited attri\u00adbutes and x signifies the letter of the tape al\u00adphabet with which the \nattribute is associated. To refer to the synthesized attributes we simply re\u00adquire an integer between \n1 and 2n-1. Thus, Sj re\u00adfers to the jth synthesized attribute. For exam\u00adple, assuming a binary tape alphabet \nconsisting of symbols a and b, and a tape length of 3, the at\u00adtributes of nonterminal <q,x> are shown \nbelow: ------ \u00ad ,tJZlmnmnrunm n . . . . ..-.-. \u00ad -,-Cwmlm m ed m m -.. .... .. u-)*mmJ--\u00ad . -)-.. 1--1 \n------V) w u-l u-lo 0eo,ooloolool  kml.K!A If the starting state is q , the first square to be scanned \nis square 1, an~ the input string is aab , then the first production and accompanying semantic rules \nin the attribute granmnar are: PRODUCTION: --> s <q, ,a> IMPORTANTSEMANTICRULES: I(3,a)= S5 I(4,a)= S3 \nI(5,b)= S4 INCIDENTAL SEMANTICRULES: I(l,a)=17 I(2,a)=17 I(3,b)=17 1(5, a)=17 1(1, b)=17 1(2, b)=17 1(4, \nb)=17 = 17 S5 S4= 17 The dependency graph induced by these rules: J. @ \\oo/oolooloo190 k In the rest \nof this discussion, we will ignore the Incidental Semantic Rules and assume that-all in\u00adherited attributes \nof the right hand side nonter\u00adminals and the synthesized attributes of the left hand side nonterminal \nare filled in as arbitrary constants. Each move of the lba gives rise to one pro\u00adduction in the grammar. \nThe intent is to keep track of the symbol in each tape square via the inherited attributes and carry \nthe dependencies initiated in the first production down to form a closed loop if and only if the associated \nlba suc\u00adcessfully reaches a final state. We will have a circularity in the attribute grammar if, in the \nprocess of getting to the point of loop-closing, we have not broken the circuits, which implies that \nwe have followed the movements of the lba properly. The form of the resulting circuit is shown in Figure \n4. From the figure, notice that the reason for numbering the synthesized subsets from right to left is \nthat now we want to asso\u00adciate set j of the inherited attributes (n . j . Zn-1) with set j of the synthesized \nat\u00adtrihute~. Fig. 4. General form of the desired circuit  &#38; ~ ,. i ., !, .! I ..- . .1 Note two \npoints here. We only use n of the syn\u00adthesized subsets. The other n-1 will be used in the next section. \nIn the inherited attributes, the nth set, here the 3rd, is always associated with the tape square currently \nbeing scanned. Thus, if the tape head moves to the left, each set k of the left hand side variable is \nconnected to the set k+l of the right hand side variable so that the set n-1 of the left hand variable \nwhich will now be scanned is associated with the set n of the right hand side variable. The same situa\u00adtion \nholds for a move to the right, set k of left hand stale nonterminal is connected to set k-1 of right \nhand side nonterminal. Nowwe are in a position to write down the productions of the grammar. A move ~(ql,a) \n= [q8,R,b] of the lba, gives riSe to the following productions in our grammar: <ql ,a> --> <q8, a> 01 \n<ql ,a> --> <q8, b> 01 both with semantic rules I(2,b)l= I(3,a)o I(j,a)l= I(j+l,a)o j=l,3,4 I(j,b)l= \nI(j+l,b)o j=l ,3,4 (Sj)o= (Sj)l j=3,4,5 F-1 L2 P :SOISO{OO!COIOD] rolololcjo] lo olo910tl@c!o@ afi IL \nl-l G ~ Informally, the inherited attributes in each set except the middle one are connected directly \nto the attributes of the corresponding set at the lower level. In the middle set, the old symbol at\u00ad \ntribute is connected to the new symbol attribute at the lower level to reflect the symbol change. The \nreason we need two productions is that we do not know what symbol will be scanned after the move and \nwe have to allow for all s (here 2) pos\u00ad sibilities. Notice that now the middle set of <q ,a> is associated \nwith the second square which i 8 current\u00adly under scan and the second set correctly shows a content of \nb ?or square 1, AIw notice that many connections are irrelevant becduse of the ori inal configuration. \nFor example, the arcs from su~set 2 to subset 1 can be ignored because subset 1 does not correspond with \na tape square at the present time. Consider another move: (q8Ya)=[q~3S L a] Y <q8, @ -->0 %3 b>l 1(4,a)l \n= I(3,a)o I(j,a)l = I(j-l,a)o j=2,3,5 I(j, b), = Iti-l,b)o j=2,3,5 = (Sj), j=3,4,5 (Sj )0 Now assuming \nq13 is a final state, we gene\u00adrate a terminal, t, and close the loops. <q13,b> -..> t S3 I(3,b) Sj = \nI(j,a)+I(j,b) j=4,5 ~po!ooloo loo loo IOIQ 10101 w k IJ Figure 5 shows the moves of the lba leading \nto the acceptance of the input, the corresponding deriva\u00adtion in the grammar generating a terminal and \nthe circle in the dependency network. E9J J (ql ,~ab => => => ACC EP (q8,b$b)(q13,bab) The L8A moves \nS ==> <ql, a> ==> <q8, a> ==> <q13, b> .= >t Derivation of t In AG I 11 Circular dependency network \nof AG (only the arcs contributing to the circuit are shown) We note that if the lba had not accepted \nthe input tape --that is, it had not entered a final state --the dependency network would not have been \ncircular because the state transitions would not have agreed with the tape contents and the cy\u00adcle would \nhave been broken somewhere. Therefore, in order to find out whether the lba accepts the tape, we could \ntest the attribute grammar for circularity. In other words, we have reduced the membership problem for \nlinear bounded automata to the circularity question for attri\u00adbute grammars. In order for this reduction \nto be useful, we must show that all the difficulty is not hidden in the translation process, That is, \nwe must show that the translation procedure takes only a poly\u00adnomial number of steps as a function of \nthe size of the lba description, The number of steps re\u00adquired to construct the attribute gramnar is \npro\u00adportional to its size. Consequently, it is suffi\u00adcient to show that the size of the ag is a poly\u00adnomial \nfunction of the size of the lba and its in\u00adput tape: We are interested in determining the behavior of \nthese description lengths as the tape length n becomes large. We have shown [8] that 1) the description \nlength of the lba and its input tape is bounded below by cl*n for some cOnStant cl; and 2) the size of \nthe description of the associated attribute grammar is bounded above by c2*n*log(n) for some sufficiently \nlarge constant c2. We can then see that the length of the description of the attribute grammar is certainly \nno more than, for example, a constant times the square of the length of the lba description. Once the \nsize of the various constituents of the translation process are established, it is not hard to see that \nthe translation process itself only takes a polynomial number of steps in terms of the length of the \ndescription of the lba. Since the membership problem for lba s is polynomially hard [9, page 101], we \ncan already see that the circularity test must be quite complex. In the next section, we will tackle \nthe question of just how complex it is. 111.2 -The Writing Pushdown Acceptor (wpda) A writing pushdown \nacceptor (or, equivalently, an auxiliary pushdown automaton) is an lba with an added feature: it also \nhas a stack. It is thus a mixture of a linear bounded automaton and a push\u00addown automaton. For more information \non wpda, see [10, 11]. Cook [11, page 12] has proven that the mem\u00adbership problem for wpda is of exponential \ncom\u00ad plexity (2c*n). Therefore, by reducing the wpda membership problem to the circularity test, we can \nfind an exponential lower bound for the complexity of the circularity test. The reduction technique is \nquite similar to the one in the previous sec\u00adtion with some added complications. These compli\u00adcations \nresult directly from the added capabili\u00ad ties of the wpda attributable to its stack. Spe\u00adcifically, the \ngrammar now has to: 1) remember the symbol on top of the stack, and 2) be able to simulate the push and \npop moves. The stack symbol can be remembered in the nonterminal with no cLif\u00adficulty at all. Push and \npop, however, are more cumbersome. We will subsequently explain how they can be handled. The grammar \nis now nonlinear. When the auto\u00admaton makes a push move, the derivation tree solits into two branches. \nthe left one simulating -, ., the wpda s behavior with the new symbol on top of the stack and the right \none simulating its behav\u00adior after the new symbol has been popped off of the stack, When a pop is made, \nthe current branch generates a terminal symbol and closes all the loops so that the right branch can \ncontinue. In order to ensure that the right branch picks up where the left one.leaves off, we have to \ntake some precautions. Before splitting, a guess is made as to the configuration of the wpda after the \ncor\u00adresponding pop. This guess is carried to the left branch as the current guess and to the right branch \nas the actual configuration of the wpda. At the time of the pop, the guess is verified and the cir\u00adcuits \nclosed if and only if the guess agrees with the actual contents of the tape at the time of the pop instruction. \nWe let the guess for the contents of each po\u00adsition be carried in synthesized attributes which provide \nreturn paths for the circuit, Thus, in contrast to the lba case where each of the 2n-1 synthesized subsets \ncontained only one return path (that is, a single synthesized attribute) we must now provide s synthesized \nattributes in each of the 2n-1 subsets. So now the use of the inherited and synthesized attributes becomes \nmore symmetric and we can refer to them, respectively, as I(j,x) and S(j,x), where 1 ~j ~2n-1 and x is \na tape sym\u00adbol (see Figure 6). We again repeat that the in\u00adherited attributes contain the current tape \ncon\u00adtents while the synthesized attributes contain the guessed (or desired) contents after the pop. m.n(u.nmcltmnmn \nn run ma an ma m .......... . ..- . . . . . . -,--04 N come e m m mlneq-cov-)cu~ r-\u00ad %. . * l..+. . . \n--mu)lnmlnmlnmm V) 010000 00100/ b }0 010010 010 01 Each nonterminal is a quintuple, indicating the mode \n(to be discussed shortly), the current state, the desired state, the current tape symbol, and the current \nstack symbol. The desired state is initially set to qf, the final state. Before each push move simulation, \nthe derivation tree en\u00adters a guess mode in order to guess what the con\u00adtents of each square of the work \ntape will be when the symbol which is being pushed onto the stack finally gets popped back off of the \nstack. The nonterminals in the guess mode have n!cre attributes. Each nonterminal in the guess mode has \nexactly twice as many attributes as the other nonterminals, so that the current tape contents and the \npreviously guessed tape contents will not be overwritten during the guessing process. We call-these two \nextra sets of attributes the guess sets, as opposed to the old ones which we call the current sets (see \nFigure 7). HQz Inherited Synthesized Inherited Synthesized Current Guess Guess Current The guess sets \nare used to (nondeterministi\u00adcally) guess a configuration of the lba --the tape contents and the pointer \nposition --without disturbing the current contents of the other two sets. At the split, the synthesized \nattributes of the guess sets are carried to the left branch as the guess for this branch; the inherited \nattributes of the guess sets are carried to the right branch as the set of the current contents, because \nif the left branch does end in the configuration that has been guessed, then the right branch should \ngo on with that configuration. The old guess, i.e. the original synthesized attributes are carried to \nthe right branch as the guess for that branch (see Figure 8).  H.9Q The Attribute split involved in \nsimulating a push move Inherited Synthesized Inherited Synthesized Current Guess Guess Current Inherited \nSynthesized Inherited Synthesized Current Current Current Current We will now show, specifically, what \nproduc\u00adtions are needed for the push move 6(q,x,Z) = [q ,y,R,ZZ ], which indicates that the state will \nbe changed from q to q , the current tape symbol x will be replaced byy, the symbol Z will be put on \ntop of the current symbol Z on the stack and, finally, the tape head will be moved one square to the \nright. (Anon push, non pop move is handled almost exactly as in the lba case and we will not elaborate \non it.) To enter the guess mode, the following pro\u00adductions are needed <Normal,q, q , x,Z> --> <u, q,q \n, x,Z> for all states o and taoe symbol U The left hand side nonterminal says that the gram\u00admar is in \nNormal Mode, the current state is q, the desired state is:q , the current tape symbol is x and the current \nstack symbol is Z. The right hand side nonterminal is similar except for its first entry. The u (which \nis a tape symbol) as the first entry of the nonterminal, indicates that the grammar is in Guess Mode \nand a guess of u is being made. This is portrayed in the attributes by se\u00admantic rules which produce \nthe following dependen\u00adcy graph: Now the current sets will remain intact while through a series of productions, \na guess will be made in the guess sets. These productions are: <U,q,q , x,z> --> <v,q,q ,x,Z> for all \nu and v in the alphabet By means of these productions, a guess is made in the (2n-l)th subset of the \ninherited and synthe\u00adsized sets and the previous guesses all pushed over one square. Remembering that \nthe middle set is associated with the square under scan, we re\u00adquire some more productions to position \nthe guess correctly, that is, push it over an arbitrary num\u00adber of squares without adding new guesses. \n<U,q,q ,x,z> --> <*,q,q ,x,Z> for all u in the tape alphabet and <*,q,q ,x, z> --> <*,q,q ,x,z> After \na series of these productions, the guess sets, the middle two sets, will contain a configuration that \nwe think the automaton will have after the pop. It is now time to split into two branches. The * in the \nnonterminal indicates that the nonterminal is ready for the split. <*Yqsq sxYz> --> < Normal, q , q \n, y,> > < Normal,q ~q , w,Z> for all states q and tape alphabet symbol w Notice that the x is changed \nto y as the push in\u00adstruction required and that the first nonterminal on the right hand side of the production \nrecords the fact that the new stack symbol is Z . For a pop move 8(q,x,Z)=[q ,y,R,B] the gram\u00admar does \nthe following: <Normal,q,q ,x,Z> --> POP Notice that the next state in the pop move must match the desired \nstate q in the nonterminal. Changing the scanned tape symbol from x to y and shifting the tape one square \nto the right will be reflected in the dependencies among the attributes of the quintuple nonterminal \nand the attributes of the POP nonterminal. The grammar contains one pro\u00adduction for eliminating the POPnonterminal \nand connecting the current tape attributes to the guessed tape contents attributes. POP --> t (t is a \nterminal symbol in the grammar) These semantic rules will cause the circuits to be closed at this point \nand if the guess at split time was correct, the paths will go all the way up to the start of the right \nbranch. TO end a derivation, for the final state qf, <Normal,qf, qf, x,Zo> -> t for all x in the alpha\u00adbet \n(Z is the initial stack Qymbol) In order for these semantic rules to close all the circuits, we make \nthe assumption that the wpda will only accept an input with its read head to the left of the tape. This \nassumption does not result in any loss of generality but allows us to write down the start production \neasily. Suppose, for example, that the input tape is xl X2 X3, then the starting production would be: \ns --> <Normal, ql, qf, xl,.ZO> (ql is the~:~;~l The associated attribute dependencies would be: - 4 \\ \n/\\ +\\/ tt , ]0 10 1o 10 SIbol 9010 bl . 1 2 3 This will ensure that a cycle will result if the wpda accepts \nthe input (and vice versa). Notice that the double connections of the synthesized attributes to the inherited \nattributes in thts production imply that we do not care what the tape contents are at the time of acceptance \nof the tape, An example transformation from wpda to ag is shown in Figure 9. A counting argument similar \nto the one used in the lba case shows that, for any class of wpda with a fixed alphabet, if the length \nof the input tape is n, the length of the attri\u00adbute grammar description is proportional to n*log (n). \nThe time required to construct the at\u00adtribute grammar is a polynomial in the length of the input tape, \nas it is easily seen from the con\u00adstruction. This, in conjunction with Cook s re\u00adsult [11, page 12], \ngives us a lower bound of 2c*n/lo9(n) for the complexity of the circularity test for attribute grammars. \nIV -Complexity of the Circularity Test:Upper Bound In order to find an upper bound for the com\u00adplexity \nof a problem, one merely has to find an algorithm to solve the problem. We consider an algorithm here \nwhich appears to be less complex than that given by Knuth. The solution we propose Figure 9 44 1 + $4 \n ql ~aab :> q8~aab :> q15 Z. bcb :> q3 Z. bba :> uu (a) The Moves of wpda Causing it rI +&#38;+ ?It polooloolo~lool \npolool$o] here is as follows: Given an attribute grammar, G, write down a context free grammar, G , \nsuch that G will be nonempty if and only if G is cir\u00adcular. Then by testing G for emptiness, we are in \neffect testing G for circularity. We know that the complexity of the emptiness problem for con\u00adtext free \nlanguages is polynomial-bounded. There\u00ad c*n fore, if the translation procedure does not cause more than \nan exponential explosion, we can con\u00ad clude that the complexity of the circularity test is hounded above \nby 2 . IV,l -Construction of a Context Free Grammar from an Attribute Grammar Given an attribute grammar \nG, we intend to build a context free grammar G such that G will be nonempty if and only if G is circular. \nClearly, we must not lose any information during the trans\u00adformation from AG to CFG. We move the information \ncontained in the attributes of G into the nonter\u00adminals of G . Thus, each nonterminal in G gives rise \nto a number of nonterminals in G which re\u00adflect certain dependencies. The more attributes which are associated \nwith each nonterminal, the 4J q6~bba :> qg ~bba > ACCEPT to Accept the String aab u oeloq <Normal ,ql \n,q9, a,ZO> ,, II I poloeloojeol,q a,qglqgYzoYzl> $ b,qg>qg,zo,zl> v b,qg>qgszo,zl> 4 *,q@;,z@l> * Z,z> \n*+jYqg, () 1 J z> *,q8YqgYzoY 1 qg,qgsb,zo> 4 t rk more nonterminals there will be in G , because there \nare more possible dependencies among the at\u00ad tributes. For any nonterminal X in G, we can write the \ncorresponding nonterminal in G as <X,D> where D indicates a number of dependencies among the at\u00adtributes \nof X. In the following paragraphs, we will sketch the procedure for constructing G from G. In order to \nunderstand how G works, observe that in a derivation tree of G with circularly de\u00adfined attributes, any \nparticular circuit has a single top node, some (one or more) bottom nodes, and some up and down arcs \nthat connect certain at\u00adtributes of these nodes to form a circuit. It is important to realize that there \nis only one top node for a given circuit. The first thing that grammar G does is to find the node at \nthe top of the circuit. To this end, every time the derivation tree splits, we guess which branch will \neventually lead to the de\u00adsired top node. This guess can be indicated by associating a star with the \nnonterminal of the guessed branch, that is, by writing the nonter\u00adminal X as <X,*>. We can now write \nthe first series of productions of G : they are identical to those of G except that the left side nontermi\u00adnal \nand one of the right side nonterminals are starred. The nonterminals in these productions do not record \nany dependencies among their attri\u00adbutes. As an example of these productions, P: x--b iz in G, gives \nrise to <X,*> --> <Y,*> Z and <X,*> --~ Y <Z,*> in G . Notice that an unstarred nonterminal can now \ndo exactly as its counterpart does in G: its be\u00ad havior has no effect on the circuit because we have \ndecided that the circuit is along another branch. If we take <S,*> as the starting nonterminal of G , \nwhere S is the starting nonterminal of G, these productions will eventually cause the top of the circuit \nto be located in the derivation tree. Now we need productions to cause the star to go away when the top \nnode has been located. For each production P:X+YZ inG, we write in G , a number of productions of the \nform P : <X,*> +<Y,E> <Z,F> where 1) E and F reflect a number of dependen\u00ad cies among the attributes \nof Y and Z, respective\u00ad ly, and 2) the dependencies reflected in the dependency sets E and F together \nwith the depend\u00ad encies implied by the semantic rules of produc\u00ad tion P form a circuit. The dependencies \nimplied by the semantic rules of P supply some up and down dependencies and it is assumed that the de\u00ad \npendency sets E and F (which do not exist at this production, and which will be supplied by the bot\u00adtom \nnodes) will be created by the nodes further down the derivation tree. Now a search must be undertaken \nto ascertain that E and F will in fact be generated. The following productions will do just that. For \neach production P: X-->YZ in G, we write a series of productions in G P : <X,D> --> <Y,E> <Z,F> such \nthat, if those dependencies among attributes of Y and Z which the dependency sets E and F pre\u00addiet will \narise from dependencies lower in the de\u00adrivation tree were actually to arise, then those dependencies \ntogether with the dependencies in\u00adherent in the semantic rules of P would give rise to the dependencies \npostulated in dependency set D. With the productions obtained so far, we can detect the top of the circuit \nand work our way down the tree looking for desired dependencies that will cause a circuit. The next series \nof productions detect these desired dependencies when they are encountered. For each production P: X-->YZ \nin G, we write in G P : <X,D> -.-> Y Z if the dependency set D is implied by the semantic rules of production \np. Now by also including in G all the produc\u00adtions of G, we allow for the possibility of the derivation \nof terminal strings in G . We claim that the above productions of G produce a terminal string if and \nonly if a deriva\u00adtion tree in G produces the same terminal string and the attributes of this tree are \ncircularly de\u00adfined. This can be seen by observing that in a de\u00adrivation tree of G , the start symbol \ngenerates a number of branches one of which is starred. The non-starred ones act exactly as they would \nin G and derive terminals only if they derive termi\u00adnals in G. However, the starred branch can only derive \nstarred nonterminals and eventually a num\u00adber of nonterminals with desired dependency sets which would \ncause a circuit. These nonterminals will go away only if the desired dependency sets are found to exist, \nthat is, if a circuit is found. Thus, given a circular derivation tree in G, we can find a terminal-deriving \nderivation tree in G , and vice versa. In other words, we have translated the pro\u00adblem of the circularity \nof G to the emptiness of G . We know that the emptiness problem is poly\u00adnomial-bounded. Therefore, if \nwe show that the size of G is an exponential function of the size of G and that the translation procedure \nis also exponential bounded, we can deduce that the cir\u00adcularity test is exponential (remember that apply\u00ad \ning a polynomial function to an exponential pre\u00ad serves the exponentiality). Theorem: The important point \nin the counting argument are the following: -If there are k attributes associated with pro\u00ad~uction P \ninG, we would require at least k*log(k) space to specify the semantic rules. That is, k*log(k) is a lower \nbound on the size np of the description of the production P and its semantic rules. 2 -This production \ngives rise to a series of pro\u00adductions in G : P : <x$D> --> <Y,E> <Z,F> Let us investigate the total \nsize of these produc\u00adtions. To begin with, note that a circuit needs to go through an attribute at most \nonce. The de\u00adpendencies D, E and F are therefore only required to contain pairs of attributes with the \nrestric\u00adtion that the left members of these pairs be unique (the pair indicates that the left element \ndepends on the right one). Therefore, with k attributes, there can be at most kk possible pairs of dependencies \namong k them (i.e. D, E, and F can each be any one of k possible sets of pairs). The description of each \nnonterminal <X,D> is, therefore, of approximate length log (kk) = k*log(k). (We can write kk al\u00ad ternatively \nas 2k*log (k).) The length of the description of one such production is bounded above by c *k*log(k) \nfor some constant cl, which is propo ) tlonal to the number of nonterminals in production P. The num\u00adber \nof possible productions, in the worst case, is c2 time C *K*log(k)k*log(k)*2k*log(k)*. . . *2k*log(k))=2 \n2(2 C2 is the number of nonterminals in production P. Therefore, an upper bound on the total length \nnplof the descriptions of productions P in G , whicn come from a given production P in G, can be written \nas c2*k*log(k) c3*k*log(k) c,*k*log(k)*2 <2  for some constant C3. Since the size np of the description \nof the pro\u00ad duction P satisfies k*log(k) ~np, we see that c3*np npl~2 . This argument can be extended \nto prove that the size of the description of G is at most an exponential function of the size n of the \ndescript\u00adion of G, which in turn provides us with 2c*n as the upper bound for the complexity of the \ncir\u00adcularity test.  Resolving the circularity question for attri\u00adbute grammars is an exponential problem, \nThe up\u00adper and lower bounds on the time complexity of the c*n 1 c2*n/log(n) problem are, respectively, \n2 and 2 where c1 and C2 are constants and n is the length of the description of the attribute grammar, \nV-Summary and Implications In this paper, we have established that the circularity test for attribute \ngrammars is of ex\u00adponential time complexity. Such problems are generally regarded as intractable. That \nis to say, there can be no algorithm which is general enough to work in every instance within practical \ntime and space limits. This implies that if we want to be able to answer the circularity question for \na particular attribute grammar, which we would be interested in doing if we are trying to write a compiler \nfor the language, we should be willing to impose some restrictions on the way attributes are defined \nin the grammar. Such restrictions have been suggested previously [4,6,12], Amore general (less restrictive \nset of restrictions is given in [13] and will be discussed in a future paper. Acknowledgements We would \nlike to thank Professor K. G. Walter for stimulating our interest in Attribute Gram\u00admars, and Professor \nH. B. Hunt for sharing many insights concerning computational complexity. REFERENCES [1] D. E. Knuth, \nSemantics of context free lan\u00adguages, Math. Syst. Th., 2, 127 (1968); [1.5]T~. E. Knuth, Correction to \n[1], Math. Syst. ., 5, 95 (1971); [2] W. T. Wilner, Declarative semantic definition, Report STAN-CS-233-71, \nComputer Science Department, Stanford University, 1971; [3] T. A. Dreisbach, A declarative semantic \ndefinition of PL360, UCLA-ENG-7289, Computer Languages Group, Computer Science Department, UCLA, 1972; \n[4] A. V. Aho and J. D. Unman, Translations on a context free grammar, Information and Control, 19,5 \n(December, 1971); [5] P. M. Lewis, R. E. Stearns, Syntax-directed transductions, JACM 15, 3 (July 1968); \n [61 P. M. Lewis, D. J. Rosenkrantz, and R. E. Stearns, Attributed translations, Proc. Fifth Annual ACM \nSymp. on Theory of Comp., (1973); [7] J. Hopcroft and J. D. Unman, Formal langu\u00adages and their relation \nto automata, Addison-Wesely, 1969;  [8] M. Jazayeri, W. F. Ogden, andW. C. Rounds, On the Complexity \nof the Circularity Test for Attribute Grammars, Jennings Computing Center Report No. 1148, Case Western \nReserve University, Cleveland, Ohio, 1974; [9] R. M. Karp, Reducibility Among Combinatorial Problems, \nin Complexity of Computer Compu\u00adtations, R. E. Miller and J. W. Thatche~ -plenum press, New York 1972; \n [10] G. Mager, Writing pushdown acceptors, J. Comp. Syst. Sci. 3, 3(1969); [11] S. A. Cook, Characterization \nof pushdown machines in terms of time-bounded computers, JACM 18, l(Jan. 1971); [12] G. V. Bochmann, \nSemantics evaluated from left to right, publication No. 135, Department d informatique, Universit6 de \nMontr6al, June 1973; [13] M. Jazayeri, On Attribute Grammars and the semantic Specification of Programming \nLanguages, Ph.D. Thesis, Department of Com\u00adputing and Information Sciences, Case Western Reserve University, \n1974 (Jennings Computing Center Report 1159) \n\t\t\t", "proc_id": "512976", "abstract": "It is shown that both the upper and the lower bounds on the time complexity of the circularity test for Knuth's attribute grammars are exponential functions of the size of the grammar description. This result implies the \"intractability\" of the circularity test in the sense that the implementation of a general algorithm is not feasible. Another significance of this result is that this is one of the first problems actually arising in practice which has been proven to be of exponential time complexity.", "authors": [{"name": "M. Jazayeri", "author_profile_id": "81100022171", "affiliation": "University of North Carolina", "person_id": "PP48022716", "email_address": "", "orcid_id": ""}, {"name": "W. F. Ogden", "author_profile_id": "81547266156", "affiliation": "Case Western Reserve University", "person_id": "PP39045948", "email_address": "", "orcid_id": ""}, {"name": "W. C. Rounds", "author_profile_id": "81100645808", "affiliation": "University of Michigan", "person_id": "PP39052265", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512976.512989", "year": "1975", "article_id": "512989", "conference": "POPL", "title": "On the complexity of the circularity test for attribute grammars", "url": "http://dl.acm.org/citation.cfm?id=512989"}