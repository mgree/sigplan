{"article_publication_date": "01-08-2014", "fulltext": "\n Toward General Diagnosis of Static Errors Danfeng Zhang Andrew C. Myers Department of Computer Science \nCornell University Ithaca, NY, 14853 zhangdf@cs.cornell.edu andru@cs.cornell.edu Abstract We introduce \na general way to locate programmer mistakes that are detected by static analyses such as type checking. \nThe program anal\u00adysis is expressed in a constraint language in which mistakes result in unsatis.able \nconstraints. Given an unsatis.able system of con\u00adstraints, both satis.able and unsatis.able constraints \nare analyzed, to identify the program expressions most likely to be the cause of un\u00adsatis.ability. The \nlikelihood of different error explanations is eval\u00aduated under the assumption that the programmer s code \nis mostly correct, so the simplest explanations are chosen, following Bayesian principles. For analyses \nthat rely on programmer-stated assump\u00adtions, the diagnosis also identi.es assumptions likely to have \nbeen omitted. The new error diagnosis approach has been implemented for two very different program analyses: \ntype inference in OCaml and information .ow checking in Jif. The effectiveness of the ap\u00adproach is evaluated \nusing previously collected programs containing errors. The results show that when compared to existing \ncompilers and other tools, the general technique identi.es the location of pro\u00adgrammer errors signi.cantly \nmore accurately. Categories and Subject Descriptors D.2.5 [Testing and Debug\u00adging]: Diagnostics; D.4.6 \n[Security and Protection]: Information .ow controls; F.3.2 [Semantics of Programming Languages]: Pro\u00adgram \nanalysis. Keywords Error diagnosis; static program analysis; type inference; information .ow 1. Introduction \nSophisticated type systems and other program analyses enable ver\u00adi.cation of complex, important properties \nof software. Advances in type inference, data.ow analysis, and constraint solving have made these veri.cation \nmethods more practical by reducing both analy\u00adsis time and annotation burden. However, the impact on \nindustrial practice is disappointing. We posit that a key barrier to adoption of sophisticated analy\u00adses \nis that debugging is dif.cult when the analysis reports an error. When deep, non-local software properties \nare being checked, the analysis may detect an inconsistency in a part of the program far Permission to \nmake digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. Copyrights for components of this work owned \nby others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. Request \npermissions from permissions@acm.org. POPL 14, January 22 24, 2014, San Diego, CA, USA. Copyright c &#38;#169; \n2014 ACM 978-1-4503-2544-8/14/01. . . $15.00. http://dx.doi.org/10.1145/2535838.2535870 from the actual \nerror, resulting in a misleading error message. De\u00adtermining from this message where the true error lies \ncan require an unreasonably complete understanding of how the analysis works. We are motivated to study \nthis problem based on experience with two programming languages: ML, whose uni.cation-based type in\u00adference \nalgorithm sometimes generates complex, even misleading error messages [35], and Jif [30], a version of \nJava that statically an\u00ad alyzes the security of information .ow within programs but whose error messages \nalso confuse programmers [19]. Prior work has ex\u00ad plored a variety of methods for improving error reporting \nin each of these languages. Although these methods are usually specialized to a single language and analysis, \nthey still frequently fail to identify the location of programmer mistakes. In this work, we take a more \ngeneral approach. Most program analyses, including type systems and type inference algorithms, can be \nexpressed as systems of constraints over variables. In the case of ML type inference, variables stand \nfor types, constraints are equali\u00adties between different type expressions, and type inference succeeds \nwhen the corresponding system of constraints is satis.able. When constraints are unsatis.able, the question \nis how to report the failure indicating an error by the programmer. The standard prac\u00adtice is to report \nthe failed constraint along with the program point that generated it. Unfortunately, this simple approach \noften results in misleading error messages the actual error may be far from that program point. Another \napproach is to report all expressions that might contribute to the error (e.g., [7, 14, 34, 35]). But \nsuch reports are often verbose and hard to understand [16]. Our insight is that when the constraint system \nis unsatis.able, a more holistic approach should be taken. Rather than looking at a failed constraint \nin isolation, the structure of the constraint system as a whole should be considered. The constraint \nsystem de.nes paths along which information propagates; both satis.able and unsatis.\u00adable paths can help \nlocate the error. An expression involved in many unsatis.able paths is more likely to be erroneous; an \nexpression that lies on many satis.able paths is more likely correct. This approach can be justi.ed on \nBayesian grounds, under the assumption, cap\u00adtured as a prior distribution, that code is mostly correct. \nIn some languages, the satis.ability of constraint systems de\u00adpends on environmental assumptions, which \nwe call hypotheses. The same general approach can also be used to identify hypothe\u00adses likely to be missing: \na small, weak set of hypotheses that makes constraints satis.able is more likely than a large, strong \nset. Contributions This paper presents the following contributions: 1. A general constraint language \nthat can express a broad range of program analyses. We show that it can encode both ML type inference \nand Jif information .ow analysis, as well as other analyses, including many data.ow analyses (Section \n3). 2. A general algorithm for identifying likely program errors, based on the analysis of a constraint \nsystem extracted from the pro\u00ad  1 l e t f ( l s t : m o v e l i s t ) : ( f l o a t * f l o a t ) l \ni s t = 2 . . . 3 l e t r e c l o o p l s t x y d i r acc = 4 i f l s t = [ ] t h e n 5 acc 6 e l s e \n7 print string \"foo\" 8 i n 9 L i s t . r e v ( l o o p l s t 0 . 0 0 . 0 0 . 0 [(0.0,0.0)] ) Figure \n1. OCaml example. Line 9 is blamed for a mistake at line 7. gram. Using a Bayesian posterior distribution \n[13], the algorithm suggests program expressions that are likely errors and offers hypotheses that the \nprogrammer is likely to have omitted (Sec\u00adtions 4 and 5). 3. An evaluation of this new error diagnosis \nalgorithm on two dif\u00adferent sets of programs written in OCaml and Jif. As part of this evaluation we \nuse a large set of programs collected from students using OCaml to do programming assignments [22] (Section \n6). Appealingly, high-quality results do not rely on language-speci.c tuning. 2. Approach Our general \napproach to diagnosing errors can be illustrated through examples from two languages: ML and Jif. 2.1 \nML type inference The power of type inference is that programmers may omit types. But when type inference \nfails, the resulting error messages can be confusing. Consider Figure 1, containing (simpli.ed) OCaml \ncode written by a student working on a programming assignment [22]. The OCaml compiler reports that the \nexpression [(0.0, 0.0)] at line 9 is a list, but is used with type unit. However, the programmer s actual \n.x shows that the error is the print string expression at line 7. The misleading report arises because \ncurrently prevalent error re\u00adporting methods (e.g., in OCaml [31], SML [28], and Haskell [17]) unify \ntypes according to type constraints or typing rules, and report the last expression considered, the one \non which uni.cation fails. However, the .rst failed expression can be far from the actual error, since \nearly uni.cation using an erroneous expression may lead type inference down a garden path of incorrect \ninferences. In our example, the inference algorithm uni.es (i.e., equates) the types of the four highlighted \nexpressions, in a particular order built into the compiler. One of those expressions, [(0.0, 0.0)], is \nblamed because the inconsistency is detected when unifying its type. Prior work has attempted to address \nthis problem by reporting either the complete slice of the program relating to a type inference failure, \nor a smaller subset of unsatis.able constraints [7, 14, 34, 35]. Unfortunately, both variants of this \napproach can still require considerable manual effort to identify the actual error within the program \nslice, especially when the slice is large.  2.2 Jif label checking Confusing error messages are not \nunique to traditional type infer\u00adence. The analysis of information .ow security, which checks a dif\u00adferent \nkind of nonlocal code property, can also generate confusing messages when security cannot be veri.ed. \nJif [30] is a Java-like language whose static analysis of informa\u00ad tion .ow often generates confusing \nerror messages [19]. Figure 2 shows a simpli.ed version of code written by a Jif programmer. Jif programs \nare similar to Java programs except that they specify se\u00adcurity labels, shadowed in the example. Omitted \nlabels (such as the 1 2 p u b l i c . . . f i n a l e n c T e x t ; 3 4 p u b l i c v o i d e n c F \no s ) m ( F i l e O u t p u t S t r e a m [ {this} ] {this}t h r o w s ( I O E x c e p t i o n ) { 5 \nt r y { 6 f o r ( i n t i = 0 ; i < e n c T e x t . l e n g t h ; i + + ) 7 e n c F o s . w r i t e ( \ne n c T e x t [ i ] ) ; 8 } c a t c h ( I O E x c e p t i o n e ) { } 9 }  Figure 2. Jif example. Line \n3 is blamed for a mistake at line 1. label of i at line 6) are inferred automatically. However, Jif \nlabel inference works differently from ML type inference algorithms: the type checker generates constraints \non labels, creating a system of inequalities that are then solved iteratively. For instance, the com\u00adpiler \ngenerates a constraint {} = {this} for line 7, bounding the label of the argument encText[i] by that \non the formal parameter to write(), which is {this} because of encFos s type. Jif error messages are \na product of the iterative process used to solve these constraints. The solver uses a two-pass process \nthat involves both raising lower bounds and lowering upper bounds on labels to be solved for. Errors \nare reported when the lower bound on a label cannot be bounded by its upper bound. As with ML, early \nprocessing of an incorrect constraint may cause the solver to detect an inconsistency later at the wrong \nloca\u00adtion. In this example, Jif reports that a constraint at line 3 is wrong, but the actual programmer \nmistake is the label {} at line 1. Jif permits programmers to specify assumptions, capturing trust relationships \nthat are expected to hold in the environment in which the program is run. A common reason why label checking \nfails in Jif is that the programmer has gotten these assumptions wrong (sharing constraints on ML functor \nparameters are also assumptions, but are simpler and less central to ML programming). For instance, an \nassignment from a memory location labeled with a patient s security label to another location with a \ndoctor s label might fail to label-check because the crucial assumption is missing that the doctor acts \nfor the patient. That assumption would imply that an information .ow from patient to doctor is secure. \nIn this paper, we propose a uni.ed way to infer both program expressions likely to be wrong and assumptions \nlikely to be missing. 2.3 Overview of the approach As a basis for a general way to diagnose errors, \nwe de.ne an expressive constraint language that can encode a large class of program analyses, including \nnot only ML type inference and Jif label checking, but also data.ow analyses. Constraints in this language \nassert partial orderings on constraint elements. These constraints are then converted into a representation \nas a directed graph. In that graph, a node represents a constraint element, and a directed edge represents \nan ordering between the two elements it connects. For example, Figure 3 is part of the constraint graph \ngenerated from the OCaml code of Figure 1. Each node represents either the type of a program expression \nor a declared type; in the .gure, nodes are annotated with the line numbers of that expression or declaration. \nEach solid edge represents one constraint generated by an OCaml typing rule. For example, the leftmost \nnode represents the type of the result of print string, which is unit. Since function loop can return \nthis result, the leftmost node is connected by edges to the node representing the result type of loop \n(at line 9). Type inference fails if there is at least one unsatis.able path within the constraint graph, \nindicating a sequence of uni.cations that generate a contradiction. Consider, for example, the three \npaths P1, P2, and P3 in the .gure. The end nodes of each path must  Figure 3. Part of the constraint \ngraph for the OCaml example represent the same types. Other such inferred paths exist, such as between \nthe node for unit and the node for variable acc(3), but these paths are not shown since a path with at \nleast one variable on an end node is trivially satis.able. We call paths that are not trivially satis.able, \nsuch as P1, P2, and P3, the informative paths. In this example, the paths P1 and P2 are unsatis.able \nbecause the types at their endpoints are different. Note that path P2 corresponds to the expressions \nhighlighted in the OCaml code. By contrast, path P3 is satis.able. The constraints along unsatis.able \npaths form a complete expla\u00adnation of the error, but one that is often too verbose. Our goal is to be \nmore useful by pinpointing where along the path the error occurs. The key insight is to analyze both \nsatis.able and unsatis.able paths. In Figure 3, the strongest candidate for the real source of the error \nis the leftmost node of type unit, rather than the lower\u00adright expression of type (float*float) list \nthat features in the misleading error report produced by OCaml. Two general heuristics help us identify \nunit as the culprit: 1. All else equal, an explanation for unsatis.ability in which pro\u00adgrammers have \nmade fewer mistakes is more likely. This is an application of Occam s Razor. In this case, the minimum \nexpla\u00adnation is a single expression (the unit node) which appears on both unsatis.able paths. 2. The \nunit node appears only on unsatis.able informative paths, but not on the informative, satis.able path \nP3. Since erroneous nodes are less likely to appear in satis.able paths, the unit node is a better error \nexplanation than any node lying on path P3.  Appealingly, these two heuristics rely only on graph structure, \nand are oblivious to the language and program being diagnosed. The same generic approach can therefore \nbe applied to very different program analyses: our tool correctly and precisely points out the actual \nerror in both the OCaml and Jif examples above. In addition to helping identify incorrect expressions, \nthe con\u00adstraint graph also provides enough information to identify assump\u00adtions that are likely to be \nmissing. 3. Constraint language Central to our approach is a general core constraint language that can \nbe used to capture a large class of program analyses. In this constraint language, constraints are inequalities \nusing an ordering = that corresponds to a .ow of information through a program. The constraint language \nalso has constructors and destructors cor\u00adresponding to computation on that information. 3.1 Syntax \nThe syntax of the constraint language is formalized in Figure 4. G ::= G1 . G2 | A A ::= C1 f C2 (n=0) \n C ::= I1 . ... . In I ::= E1 = E2 E ::= a | c(E1, . . . , Ea(c)) | c i(E) | E1UE2 | E1nE2 | . | T Figure \n4. Syntax of constraints The top-level goal G to be solved is a conjunction of assertions A, each with \nthe form C1 f C2, where constraint C1 is the hypoth\u00adesis (that is, assumption) and constraint C2 is a \nconclusion to be satis.ed. A constraint C, serving either as the hypothesis or as the conclu\u00adsion of \nan assertion, is a possibly empty conjunction of inequalities I over elements from E, based on the ordering \n=. We denote an empty conjunction as \u00d8, and abbreviate \u00d8 f C2 as f C2. An element E may be a variable \na . Var whose value is to be solved for, an application of constructor c . Con or the i-th argument to \na constructor application, represented by c i(E). The arity of constructor c is represented as a(c). \nConstants c are nullary constructors, with arity 0. The ordering = is treated abstractly, but it must \nde.ne a lattice with the usual join (U) and meet (n) operators, which can be used as syntax. The bottom \nand top of the element ordering are . and T. Example To model ML type inference, we can represent the \ntype int->bool as a constructor application fn(int, bool), where int and bool are constants. Its .rst \nprojection fn 1 (fn(int, bool)) is int. Consider the expressions acc (line 5) and print string (line \n7) in Figure 1. These are branches of an if statement, so one as\u00adsertion is generated to enforce that \nthey have the same type: f acc(5) = unit . unit = acc(5). Section 3.4.1 describes in more detail how \nassertions are generated for ML. 3.2 Interpretation of constraints The partial ordering on two applications \nof the same constructor is determined by the variances of that constructor s arguments. For each argument, \nthe ordering of the applications is either covariant with respect to that argument (denoted by +), contravariant \nwith respect to that argument (-), or invariant with respect to it. More general partial ordering rules \non constructors (e.g., a rule c1(x, y) = c2(y, x) can also be handled by our inference algorithm in 4.3 \nin a manner similar to the handling of n and U, though with increased complexity. With these abstract \nde.nitions, the validity of variable-free con\u00adstraints can be de.ned in a natural way. A variable-free \ngoal G is valid if all assertions it contains are valid. An assertion C1 f C2 is valid if the partial \norderings in C2 are entailed from C1, using just the lattice properties of the relation = and the variances \nof the various constructor arguments. Example Let A, B, C be three distinct constants. Then A = B . B \n= C f A = C is valid by the transitivity of =. Assertion f A = A U B is valid by the de.nition of join. \nAssertion f A = B is invalid: the empty assumption does not entail the conclusion. 3.3 Satis.ability \nValidity as de.ned so far works for constraints without variables. When constraints mention variables, \nthey are satis.able if there exists a valuation of all variables such that the goal after value substitution \nis valid. Satis.ability depends on the ground terms T that a variable can map into. Let T be the greatest \n.xed point of the following rules: All constants are in T .  c(t1, . . . , ta(c)) . T if .i.{1,...,a(c)} \nti . T and c . Con.   Notice that ground terms may be in.nite. This feature is essential for modeling \nrecursive types. A valuation F : Var . T is a function from variables to ground terms. A goal is satis.able \nwhen there exists a valuation F such that the goal is valid after substitution using F. Example Let a \n. Var, A, B, C . T . Then f a = A is trivially satis.able by the valuation F(a) = A or F(a) = .. However, \nf a = A . B = a is unsatis.able since otherwise, B = A by the transitivity of =, yet this ordering on \nA and B is not entailed.  3.4 Expressiveness The constraint language is the interface between various \nprogram analyses and our diagnostic tool. To use this tool, the program analysis implementer must instrument \nthe compiler or analysis to express a given program analysis as a set of constraints in the constraint \nlanguage. As we now show, the constraint language is expressive enough to capture a variety of different \nprogram analyses. Of course, the constraint language is not intended to express all program analyses, \nsuch as analyses that involve arithmetic. We leave incorporating a larger class of analyses into our \nframework as future work. 3.4.1 ML type inference ML type inference maps naturally into constraint solving, \nsince typing rules are usually equality constraints on types. Numerous efforts have been made in this \ndirection (e.g., [2, 14, 16, 26, 36]). Most of these formalizations are similar, so we discuss how Damas \ns Algorithm T [8] can be recast into our constraint language, extending the approach of Haack and Wells \n[14]. We follow that ap\u00ad proach since it supports let-polymorphism. Further, our evaluation builds on \nan implementation of that approach. For simplicity, we only discuss the subset of ML whose syntax is \nshown in Figure 5. However, our implementation does support a much larger set of language features, including \nmatch expressions and user-de.ned data types. In this language subset, expressions can be variables (x), \ninte\u00adgers (n), binary operations (+), functions abstractions fn x . e, function applications (e1 e2), \nor let bindings (let x = e1 in e2). Notice that let-polymorphism is allowed, such as an expression (let \nid = fn x . x in id 2) The typing rules that generate constraints are shown in Figure 5. Types t can \nbe type variables to be inferred (a), the prede.ned integer type int, and function types constructed \nby .. The typing rules have the form e : (G, t, C ). G is a typing environment that maps a variable x \nto a set of types. Intuitively, G tracks a set of types with which x must be consistent. Let [ ] be an \nenvironment that maps all variables to \u00d8, and G{x . T } be a map identical to G except for variable x. \nG1 . G2 is a pointwise union for all type variables: .x.(G1 . G2)(x) = G1(x) . G2(x). As before, C is \na constraint in our language. It captures the type equalities that must be true in order to give e the \ntype t. Note that a type equality t = t' is just a shorthand for the assertion f t = t' . t' = t. Most \nof the typing rules are straightforward. To type-check fn x . e, we ensure that the type of x is consistent \nwith all appear\u00adances in e, which is done by requiring ax = t' for all t' . G(T ). The mapping G(x) is \ncleared since x is bound only in the function de.nition. The rule for let-bindings is more complicated. \nBecause of let-polymorphism, the inferred type of e1 (t1) may contain free type variables. To support \nlet-polymorphism, we generate a fresh variant of (G1, t1, C1), where free type variables are replaced \nby fresh ones, for each use of x in e2. These fresh variants are then required to be equal to the corresponding \nuses of x. Creating one variant for each use in the rule for let-bindings may increase the size of generated \nconstraints, and hence make our error diagnosis algorithm more expensive. However, we .nd e ::= x | \nn | e1 + e2 | fn x . e | e1 e2 | let x = e1 in e2 t ::= a | int | t . t x : ([ ]{x . {ax}}, a, ax = a) \nn : ([ ], a, int = a) e1 : (G1, t1, C1) e2 : (G2, t2, C2) e1 + e2 : (G1 . G2, a, int = t1 . int = t2 \n. int = a . C1 . C2) e : (G, t, C ) G(x) = T _ fn x.e : (G{x . \u00d8}, a, {ax = t' | t'.T } . a = ax.t . \nC) e1 : (G1, t1, C1) e2 : (G2, t2, C2) e1 e2 : (G1 . G2, a, t1 = t2 . a . C1 . C2) e1 : (G1, t1, C1) \ne2 : (G2, t2, C2) G2(x) = {t1', . . . , t'} n let x = e1 in e2 : (G1'. G2{x . \u00d8}, a, a = t2 . C . C1'. \nC2) where (G1,1, t1,1, C1,1) . . . (G1,k, t1,k, C1,k), k = max(1, n), are fresh _ '' variants of (G1, \nt1, C1), G1 = G1,i, C1 = C1,i and 1=i=k 1=i=k '' C = {t1,1 = t1, . . . , t1,n = tn} Figure 5. Constraint \ngeneration for a subset of ML. a and ax are fresh variables in typing rules. performance is still reasonable \nwith this approach. One way to avoid this limitation is to add polymorphically constrained types, as \nin [12]. We leave that as future work. 3.4.2 Information-.ow control In information-.ow control systems, \ninformation is tagged with security labels, such as unclassi.ed or top secret . Such security labels \nnaturally form a lattice [9], and the goal of such systems is to ensure that all information .ows upward \nin the lattice. To demonstrate the expressiveness of our core constraint lan\u00adguage, we show that it can \nexpress the information .ow checking in the Jif language [30]. To the best of our knowledge, ours is \nthe .rst general constraint language expressive enough to model the chal\u00adlenging features of Jif. Label \ninference and checking Jif [30] statically analyzes the se\u00ad curity of information .ow within programs. \nAll types are anno\u00adtated with security labels drawn from the decentralized label model (DLM) [29]. Information \n.ow is checked by the Jif compiler using constraint solving. For instance, given an assignment x := y, \nthe compiler generates a constraint L(y) = L(x), meaning that the label of x must be at least as restrictive \nas that of y. The programmer can omit some security labels and let the com\u00adpiler generate them. For instance, \nwhen the label of x is not speci\u00ad.ed, assignment x := y generates a constraint L(y) = ax, where ax is \na label variable to be inferred. Hence, Jif constraints are broadly similar in structure to our gen\u00aderal \nconstraint language. However, some features of Jif are challeng\u00ading to model. Label model The basic building \nblock of the DLM is a set of principals representing users and other authority entities. Principals are \nstructured as a lattice with respect to a relation actsfor. The proposition A actsfor B means A is at \nleast as privileged as B. Security policies on information are expressed as labels that mention these \nprincipals. For example, the con.dentiality label {patient . doctor} means that the principal patient \npermits the principal doctor to learn the labeled information. Principals can be used to construct integrity \nlabels as well. For example, consider the following Jif code: 1 i n t { p a t i e n t . T} x ; 2 i n \nt y = x ; 3 i n t { d o c t o r . T} z ; 4 i f ( d o c t o r a c t s f o r p a t i e n t ) z = y ; The \ntwo assignments generate two satis.able assertions: f conf(patient, T) = ay . patient = doctor f ay = \nconf(doctor, T) The principals patient and doctor are constants, and the covariant constructor conf(p1, \np2) represents con.dentiality labels. A DLM con.dentiality policy can be treated as a covariant con\u00adstructor \non principals. Integrity policies are dual to con.dentiality policies, so they can be treated as contravariant \nconstructors on principals. The proof can be found in the associated technical re\u00adport [38]. Label polymorphism \nLabel polymorphism makes it possible to write reusable code that is not tied to any speci.c security \npol\u00adicy. For instance, consider a function foo with the signature int foo(bool{A.A} b). Instead of requiring \nthe parameter b to have exactly the label {A.A}, the label serves as an upper bound on the label of the \nactual parameter. Modeling label polymorphism is straightforward, using hypothe\u00adses. The constraint C \nb = {A . A} is added to the hypotheses of all constraints generated by the method body, where the constant \nC b represents the label of variable b. Method constraints Methods in Jif may contain where clauses , \nexplicitly stating constraints assumed to hold true during the execu\u00adtion of the method body. The compiler \ntype-checks the method body under these assumptions and ensures that the assumptions are true at all \nmethod call sites. In the constraint language, method constraints are modeled as hypotheses.  3.4.3 \nData.ow analysis Data.ow analysis is used not only to optimize code but also to check for common errors \nsuch as uninitialized variables and unreachable code. Classic instances of data.ow analysis include reaching \nde.ni\u00adtions, live variable analysis and constant propagation. Aiken [1] showed how to formalize data.ow \nanalysis algorithms as the solution of a set of constraints with equalities over the follow\u00ading elements \n(a subclass of the more general set constraints in [1]): E ::= A1 | . . . | An | a | E1 . E2 | E1 n E2 \n|\u00acE where A1, . . . , An are constants, a is a constraint variable, elements represents sets of constants, \nand ., n, \u00ac are the usual set operators. Consider live variable analysis. Let Sdef and Suse be the set \nof program variables that are de.ned and used in a statement S, and let succ(S) be the statement executed \nimmediately after S. Two constraints are generated for statement S: Sin = Suse . (Sout n \u00acSdef )  Sout \n= Xin X.succ(S) where Sin, Sout, Xin are constraint variables. Our constraint language is expressive \nenough to formalize com\u00admon data.ow analyses since the constraint language above is nearly a subset of \nours: set inclusion is a partial order, and negation can be eliminated by preprocessing in the common \ncase where the number of constants is .nite (e.g., \u00acSdef is .nite).  3.5 Errors and explanations Recall \nthat the goal of this work is to diagnose the cause of errors. Therefore we are interested not just in \nthe satis.ability of a set of assertions, but also in .nding the best explanation for why they are not \nsatis.able. Failures can be caused by both incorrect constraints and missing hypotheses. Incorrect constraints \nOne cause of unsatis.ability is the existence of incorrect constraints appearing in the conclusions of \nassertions. Constraints are generated from program expressions, so the pres\u00adence of an incorrect constraint \nmeans the programmer wrote the wrong expression. Missing hypotheses A second cause of unsatis.ability \nis the ab\u00adsence of constraints in the hypothesis. The absence of necessary hy\u00adpotheses means the programmer \nomitted needed assumptions. In our approach, an explanation for unsatis.ability may consist of both incorrect \nconstraints and missing hypotheses. To .nd good explanations, we proceed in two steps. The system of \nconstraints is .rst converted into a representation as a constraint graph (Section 4). This graph is \nthen analyzed using Bayesian principles to identify the explanations most likely to be correct (Section \n5). 4. Constraint graph The core constraint language has a natural graph representation that enables \nanalyses of the system of constraints. In particular, the satis.ability of the constraints can be tested \nvia context-free\u00adlanguage reachability in the graph. 4.1 Running example We use the following example \nthroughout this section to illustrate the key ideas behind the constraint graph representation. Example \nConsider the following set of constraints. f a = fn(ty1, bool) . ty1 = ty2 f \u00df = a . f fn(ty2, int) = \n\u00df We interpret = here as the subtyping relation. The constructor fn(E1, E2) represents the function type \nE1 . E2. Note that the constructor fn is contravariant in its .rst argument and covariant in its second. \nThe identi.ers ty1, ty2, bool, int are distinct constants and a, \u00df are type variables to be inferred. \nThe .rst assertion claims that a is a subtype of fn(ty1, bool), with no hypotheses. The third assertion \nis similar. The second asser\u00adtion says that \u00df is a subtype of a under the assumption that ty1 is a subtype \nof ty2. To determine whether this goal is satis.able, we construct a constraint graph to infer partial \norderings that must hold based on these constraints and the built-in, language-independent inference \nrules associated with the relation =, the constructors used, and the operators U and n. 4.2 Constraint \ngraph construction The graph contains a node for each distinct element in the constraint system. For \neach partial ordering E1 = E2 appearing in assertion conclusions, a directed edge exists from E1 to E2, \nrepresenting the legal .ow of information. We call this edge an LEQ edge. Hypotheses of assertions are \nrecorded on the LEQ edges gener\u00adated by the corresponding conclusions. We denote an edge annotated by \nhypothesis H as LEQ{H}. For instance, the second constraint in our running example, ty1 = ty2 f \u00df = a, \ngenerates an edge LEQ{ty1 = ty2} from node \u00df to node a. Additional constructor edges in the constraint \ngraph represent the action of constructors. Constructor edges connect the construc\u00adtor s arguments to \nthe element representing its result. For example,  (a) Constructor edges (b) Full constraint graph (c) \nHypothesis graph Figure 6. Constraint graph generated from unsatis.able constraints there would be a \nconstructor edge to the node representing the el\u00adement fn(ty1, bool) from each of the nodes for ty1 and \nbool, as illustrated in Figure 6(a). Constructor edges include the following annotations: the con\u00adstructor \nname, the argument position, and the variance of the pa\u00adrameter (covariant, contravariant or invariant). \nFor instance, the edge labeled (-fn1) connects the .rst argument to the constructor appli\u00adcation. For \neach constructor edge there is also a dual decomposition edge that connects the constructor application \nback to its arguments. It is distinguished by an overline above the constructor name in the graph, and \nhas the same variance: for example, (-fn 1 ). To simplify reasoning about the graph, LEQ edges are also \nduplicated in the reverse direction, with negative variance. Thus, the .rst assertion in the example, \nf a = fn(ty1, bool), generates a (+LEQ) edge from a to fn(ty1, bool), and a (-LEQ) edge in the other \ndirection, as illustrated in Figure 6(a). The constraint graph generated using all three assertions from \nthe example is shown in Figure 6(b), excluding the dotted arrow. Formal construction of the constraint \ngraph Figure 7 formally presents a function A that translates a set of assertions A1 . . . . . An into \na constraint graph with annotated edges. The graph is represented in the translation as a set of edges \nde.ned by the set Edge. The nodes of the constructed graph are implicitly de.ned by their connecting \nedges. Nodes are drawn from the set Node, which consists of the legal elements E modulo the least equivalence \nrelation ~ that satis.es the commutativity of the operations U and n and that is preserved by the productions \nin Figure 4. As shown, there are three kinds of edges. The LEQ edges, an\u00adnotated with hypotheses, are \ngenerated by the translation rule for A[ C f E1 = E2] and by the rules for meets and joins. Construc\u00adtor \nedges are generated by the rules E[ cons(E1, . . . , En)]]C and E[ cons i(E)]]C, which connect a constructor \napplication to its argu\u00adments. Invariant arguments generate edges as though they were both covariant \nand contravariant, so twice as many edges are generated.  4.3 Inferring node orderings The constraint \ngraph facilitates inferring all = relationships that can be proved using the corresponding constraints. \nThe idea is to construct a context-free grammar, shown in Figure 8, whose productions correspond to inference \nrules for = relationships. To perform inference, each production is interpreted as a re\u00adduction rule \nthat replaces the right-hand side with the single LEQ edge appearing on the left-hand side. For instance, \nthe transitivity of = is expressed by the .rst grammar production, which derives (pLEQ{H1 .H2}) from \nconsecutive LEQ edges (pLEQ{H1}) and (pLEQ{H2}), where p is some variance. The inferred LEQ edge has \nhypotheses H1 and H2 since the inferred partial ordering is valid only when both H1 and H2 hold. n : \nNode (Node = Element/~) e : Edge ::= (pLEQ){C}(n1 . n2) | (pi consi)(n1 . n2) | (pi consi)(n1 . n2) \nGraph = P(Edge) A[ G] : Graph E[ E] C : Graph  A[ A1 . . . . . An] = A[ Ai]  i.1..n  A[ C f I1 . . \n. . . In] = A[ C f Ii] i.1..n A[ C f E1 = E2] = E[ E1] C . E[ E2] C . {(+LEQ){C}(E1 . E2), (-LEQ){C}(E2 \n. E1)} E[ a] C = E[ c] C = E[ .] C = E[ T] C = \u00d8  E[ cons(E1, . . . , En)]]C = {(pi cons i)(Ei .cons(E1, \n. . . , En)))} i.1..n . {(pi consi)(cons(E1, . . . , En) . Ei)} . E[ Ei] C E[ cons i(E)]]C = {(pi cons \ni)(cons i(E) . E)}. {(pi cons i)(E . cons i(E))} . E[ E] C (where pi is the variance of argument i to \nconstructor cons)  E[ E1 U E2] C = {(+LEQ){C}(Ei . E1 U E2)} i.1..2 . {(-LEQ){C}(E1 U E2 . Ei)} . E[ \nEi] C  E[ E1 n E2] C = {(+LEQ){C}(E1 n E2 . Ei)} i.1..2 . {(-LEQ){C}(Ei . E1 n E2)} . E[ Ei] C Figure \n7. Construction of the constraint graph (pLEQ{H1 . H2}) ::= (pLEQ{H1}) (pLEQ{H2}) (+LEQ{H}) ::= (pc i) \n(pLEQ{H}) (pc i) - i i (LEQ{H}) ::= (pc ) (pLEQ{H}) (pc ) where c . Con, 1 = i = a(c), p . {+, -}, + \n= - and - = + Figure 8. Context-free grammar for (+LEQ) inference The power of context-free grammars \nis needed in order to han\u00addle reasoning about constructors. In the running example, applying transitivity \nto the constraints yields ty1 = ty2 f fn(ty2, int) = fn(ty1, bool). Then, because fn is contravariant \nin its .rst argu\u00adment, we derive ty1 = ty2. Similarly, we can derive int = bool, the dotted arrow in \nFigure 6(b). To capture this kind of reasoning, we use the .rst two produc\u00adtions in Figure 8. In our \nexample of Figure 6(b), the path from ty1 to ty2 has the following edges: (-fn1) (-LEQ) (-LEQ{ty1 = ty2}) \n(-LEQ) (-fn 1 ). These edges reduce via the .rst and then the second production to an edge (+LEQ{ty1 \n= ty2}) from ty1 to ty2. Note that the variance is .ipped because the .rst con\u00adstructor argument is contravariant. \nSimilarly, we can infer another (+LEQ{ty1 = ty2}) edge from int to bool. The third grammar production \nin Figure 8 is the dual of the second production, ensuring the invariant that each (+LEQ) edge has an \ninverse (-LEQ) edge. In our example of Figure 6(b), there is also an edge (-LEQ{ty1 = ty2}) from ty2 \nto ty1, derived from the following edges: (-fn1) (+LEQ) (+LEQ{ty1 = ty2}) (+LEQ) (-fn 1 ). These edges \nreduce via the .rst and then the third production to an edge (-LEQ{ty1 = ty2}) from ty2 to ty1. Computing \nall inferable (+LEQ) edges according to the context\u00adfree grammar in Figure 8 is an instance of context-free-language \nreachability, which is well-studied in the literature [5, 27] and has been used for a number of program-analysis \napplications [33]. We adapt the dynamic programming algorithm of Barrett et al. [5] to .nd shortest (+LEQ) \npaths. We call such paths supporting paths since the hypotheses along these paths justify the inferred \n(+LEQ) edges. We extend this algorithm to also handle join and meet nodes. Take join nodes, for instance \n(meet is handled dually). The rule E1 U E2 = E .. E1 = E . E2 = E can be used in two directions. The \ndirection from left to right is already handled when we construct edges for join elements (Figure 7). \nTo use the rule in the other direction, we use the following procedure when a new edge (+LEQ){C}(n1 . \nn2) is processed: for each join element E where n1 is an argument of the U operator, we add an edge from \nE to n2 if all arguments of the U operator have a (+LEQ) edge to n2.  4.4 Checking the satis.ability \nof (+LEQ) edges A (+LEQ) edge, whether inferred or speci.ed directly in an asser\u00adtion, is added to the \ngraph only when the corresponding = ordering is entailed by the constraints along the supporting path. \nHence, the constraints along the path must be unsatis.able if the partial order\u00ading on the end nodes \nis unsatis.able. When either end node of a (+LEQ) edge is a variable or a U(n) node where at least one \nargument of U(n) is a variable, the edge is trivially satis.able and hence not informative for error \ndiagnosis. For simplicity, we ignore such edges and refer subsequently only to informative (+LEQ) edges. \nTwo informative (+LEQ) edges can be inferred in Figure 6(b). These edges are int . bool and ty1 . ty2, \nthough only the .rst is shown. A (+LEQ) edge holds only if all hypotheses on the edge hold too. Therefore, \nthe satis.ability of an edge (+LEQ){C}(n1 . n2) is equivalent to the satis.ability of the assertion C \nf n1 = n2. In our running example, the combined hypotheses along both informative edges are ty1 = ty2. \nTherefore, satis.ability of the constraint system reduces to satis.ability of these assertions: ty1 = \nty2 f int = bool ty1 = ty2 f ty1 = ty2 To check the satis.ability of these assertions, we test if the \nconclusion can be proved from all constraints in the hypothesis. Recall that a constraint graph facilitates \nthe inference of all provable partial ordering given a set of constraints. Therefore, a hypothesis graph \nis constructed in exactly the same way as the constraint graph to .nd all provable = relations. Speci.cally, \nto test if an edge (+LEQ){C}(n1 . n2) is sat\u00adis.able, we construct a hypothesis graph using C as described \nin Section 4.2 and .nd all inferable (+LEQ) edges as described in Sec\u00adtion 4.3. Edge (+LEQ){C}(n1 . n2) \nis unsatis.able if the rela\u00adtionship (+LEQ)(n1 . n2) cannot be inferred from the hypothesis graph using \nC. For our running example, the hypothesis graphs for both infor\u00admative edges are the same. From this \ngraph, shown in Figure 6(c), int = bool is not provable. The constraints along the supporting path from \nint to bool form a proof of unsatis.ability. Satis.able and unsatis.able paths When the partial ordering \non the end nodes of a path is invalid, we say that the path is end-to-end unsatis.able. End-to-end unsatis.able \npaths are helpful because the constraints along the path explain why the inconsistency occurs. Also useful \nfor error diagnosis is the set of satis.able paths: paths where there is a valid partial ordering on \nany two nodes on the path for which a (+LEQ) relationship can be inferred. Any remaining paths are ignored \nin our error diagnosis algo\u00adrithm, since by de.nition they must contain at least one end-to-end unsatis.able \nsubpath. For brevity, we subsequently use the term un\u00adsatis.able path to mean a path that is end-to-end \nunsatis.able. 5. Ranking explanations The algorithm in Section 4 identi.es unsatis.able paths in the \ncon\u00ad straint graph, which correspond to sets of unsatis.able constraints expressed by our constraint \nlanguage. Although the information along unsatis.able paths already cap\u00adtures why the goal is unsatis.able, \nreporting all constraints along a path may give more information than the programmer can digest. Our \napproach is to use Bayesian reasoning to identify programmer errors more precisely. 5.1 A Bayesian interpretation \nThe cause of errors can be wrong constraints, missing hypotheses, or both. To keep our diagnostic method \nas general as possible, we avoid building in domain-speci.c knowledge about mistakes programmers tend \nto make. However, the framework does permit adding such knowledge in a straightforward way. The language-level \nentity about which errors are reported can be speci.c to the language. OCaml reports typing errors in \nexpressions, whereas Jif reports errors in information-.ow constraints. To make our diagnosis approach \ngeneral, we treat entities as an abstract set O and assume a mapping F from entities to constraints. \nWe assume a prior distribution on entities PO, de.ning the probability that an entity is wrong. Similarly, \nwe assume a prior distribution P. on hypotheses ., de.ning the probability that a hypothesis is missing. \nGiven entities E . O and hypotheses H . ., we are inter\u00adested in the probability that E and H are the \ncause of the error observed. In this case, the observation o is the satis.ability of in\u00adformative paths \nwithin the program. We denote the observation as o = (o1, o2, . . . , on), where oi . {unsat, sat} represents \nunsatis\u00ad.ability or satis.ability of the corresponding path. The observation follows some unknown distribution \nPO. We are interested in .nding a subset E of entities O and a subset H of hypotheses . for which the \nposterior probability P (E, H |o) is large, meaning that E and H are likely causes of the given observation \no. In particular, a maximum a priori estimate is a pair (E, H ) at which the posterior probability takes \nits maximum value; that is, at arg maxE.O,H.. P (E, H |o). By Bayes theorem, P (E, H |o) is equal to \nPO\u00d7.(E, H )P (o|E , H )/PO(o) The factor PO(o) does not vary in the variables E and H, so it can be \nignored. Assuming the prior distributions on O and . are independent, a simpli.ed term can be used: PO(E)P.(H)P \n(o|E, H )  PO(E) is the prior knowledge of the probability that a set of entities E is wrong. In principle, \nthis term might be estimated by learning from a large corpus of buggy programs or using language\u00adspeci.c \nheuristics. For simplicity and generality, we assume that each entity is equally likely to be wrong; \nwe leave the incorporation of language-speci.c knowledge to future work. We also assume the probability \nof each entity being the cause is |E| independent.1 Hence, PO(E) is estimated by P1 , where P1 is a constant \nrepresenting the likelihood that a single entity is wrong. P.(H) is the prior knowledge of the probability \nthat hypotheses H are missing. Of course, not all hypotheses are equally likely to be wrong. For example, \nthe hypothesis T = . is too strong to be useful: it makes all constraints succeed. The likely missing \nhypothe\u00adsis is both weak and small. Our general heuristics for obtaining this term are discussed in Section \n5.3. P (o|E , H ) is the probability of observing the constraint graph, given that entities E are wrong \nand hypotheses H are missing. To estimate this factor, we assume that the satis.ability of the remain\u00ading \npaths is independent. This allows us to write P (o|E, H ) = i P (oi|E, H ). The term P (oi|E, H ) is \ncalculated using two i heuristics: 1. For an unsatis.able path, either something along the path is wrong, \nor adding H to the hypotheses on the path makes the partial ordering on end nodes valid. So P (oi = unsat|E \n, H ) is equal to 1 in this case, and is otherwise 0. 2. A satis.able path is unlikely (with some constant \nprobability P2 < 0.5) to contain a wrong entity. Since adding or removing H does not affect a path that \nis already satis.able, P (oi = sat|E , H ) is not affected by H. Hence, we have P (oi = sat|E , H ) = \nP2 if path pi contains a constraint generated by some entity in E. Otherwise, P (oi = sat|E, H ) = 1 \n- P2.  The .rst heuristic suggests we only need to consider the enti\u00adties and hypotheses that explain \nall unsatis.able paths (otherwise P (oi|E, H ) = 0 for some oi = unsat by heuristic 1). We denote this \nset by G. Suppose nsat (a constant) paths are satis.able, and entities E appear on kE of them. Then, \nbased on the simplifying assumptions made, we have arg max PO(E)P.(H)P (o|E, H ) E.O,H.. |E| (1 - P2)nsat-kE \n.i:oi = arg max P1 P.(H)P2 kE =unsat P (oi|E) E.O,H.. |E| = arg max P1 (P2/(1 - P2))kE P.(H) (E,H ).G \nAn intuitive understanding of this estimation is that the cause must explain all unsatis.able paths; \nthe wrong entities are likely to be small (|E| is small) and not used often on satis.able paths (since \nP2 < 1 - P2 by heuristic 2); the missing hypothesis is likely to be weak and small, as de.ned in Section \n5.3, which maximizes the term P.(H). Although this estimation is affected by the values of P1 and P2, \nempirical study suggests that the diagnosis result is insensitive to their values across a broad range \n(see Section 6.2.1).  5.2 Inferring likely wrong entities |E| The term P1 (P2/(1 - P2))kE can be used \nto calculate the likeli\u00adhood that a subset of entities is the cause. However, its computation for all \npossible sets of entities can be impractical. Therefore, we propose an instance of A* search [15], based \non novel heuristics, to calculate optimal solutions in a practical way. 1 It seems likely that the precision \nof our approach could be improved by re.ning this assumption, since the (rare) missed locations in our \nevaluation usually occur when the programmer makes a similar error multiple times. A* search is a heuristic \nsearch algorithm for .nding minimum\u00adcost solution nodes in a graph of search nodes. In our instance of \nthe algorithm, each search node n represents a set of entities deemed wrong, denoted En. A solution node \nis one that explains all unsat\u00adis.able paths the corresponding entities appear in all unsatis.able paths. \nAn edge corresponds to adding a new entity to the current set. The key to making A* search effective \nis a good cost function f (n). The cost function is the sum of two terms: g(n), the cost to reach node \nn, and h(n), a heuristic function estimating the cost from n to a solution. Before de.ning the cost function \nf(n), we note that maximizing |E| the likelihood P1 (P2/(1 - P2))kE is equivalent to minimizing C1|E| \n+ C2kE , where C1 = - log P1 and C2 = - log(P2/(1 - P2)) are both positive constants because 0 < P1 < \n1 and 0 < P2 < 0.5. Hence, the cost of reaching n is g(n) = C1|En| + C2kEn To obtain a good estimate \nof the remaining cost that is, the heuristic function h(n) our insight is to use the number of entities \nrequired to cover the remaining unsatis.able paths, denoted as Prm , since C1 is usually larger than \nC2. More speci.cally, h(n) = 0 if Prm = \u00d8. Otherwise, h(n) = C1 if Prm is covered by one single entity; \nh(n) = 2C1 otherwise. An important property of the heuristic function is its optimality: all and only \nthe most likely wrong subsets of entities are returned. The proof is included in the associated technical \nreport [38]. The heuristic search algorithm is also ef.cient in practice: on current hardware, it takes \nabout 10 seconds when the search space is over 21000. More performance details are given in Section 6. \nSince the remaining part of our instance of A* search is largely standard, we leave the details in the \naccompanied technical re\u00adport [38]. The only nonstandard feature is that the search stops when a suboptimal \nsuggestion is found, rather than when the .rst sugges\u00adtion is found, since we are interested in all top-ranked \nsuggestions. 5.3 Inferring missing hypotheses Another factor in the Bayesian interpretation is the likelihood \nthat hypotheses (assumptions) are missing. Recall that a path from ele\u00adment E1 to E2 in a constraint \ngraph is unsatis.able if the conjunc\u00adtion of hypotheses along the path is insuf.cient to prove the partial \nordering E1 = E2. So we are interested in inferring a set of miss\u00ading hypotheses that are suf.cient to \nrepair unsatis.able paths in a constraint graph. 5.3.1 Motivating example Consider the following assertions: \n(Bob = Carol f Alice = Bob) .(Bob = Carol f Alice = Carol) .(Bob = Carol f Alice = Carol U .) Since \nthe only hypothesis we have is Bob = Carol (meaning Carol is more privileged than Bob), none of the three \nconstraints in the conclusion holds. One trivial solution is to add all invalid conclusions to the hypothesis. \nThis approach would add Alice = Bob . Alice = Carol . Alice = Carol U . to the hypotheses. However, this \nnaive approach is undesirable for two reasons: 1. An invalid hypothesis may invalidate the program analysis. \nFor instance, adding an insecure information .ow to the hypotheses can violate security. The programmer \nhas the time-consuming, error-prone task of checking the correctness of every hypothesis. 2. A program \nanalysis may combine static and dynamic ap\u00adproaches. For instance, although most Jif label checking is \nstatic, some hypotheses are checked dynamically. So a large hypothesis may also hurt run-time performance. \n  It may also be tempting to select the minimal missing hypothesis, but this approach does not work \nwell either: a single assumption T = . is always a minimal missing hypothesis for all unsatis.able paths. \nGiven T = ., any partial order E1 = E2 can be proved since E1 = T = . = E2. However, this assumption \nis obviously too strong to be useful. Intuitively, we are interested in a solution that is both weakest \nand minimal. In the example above, our tool returns a hypothesis with only one constraint Alice = Bob: \nboth weakest and minimal. We now formalize the minimal weakest missing hypothesis, and give an algorithm \nfor .nding this missing hypothesis.  5.3.2 Missing hypothesis Consider an unsatis.able path P that supports \nan (+LEQ) edge e = (+LEQ){C}(n1 . n2). For simplicity, we denote the hypothesis of P as H(P ) = C, and \nthe conclusion C(P ) = n1 = n2. We de.ne a missing hypothesis as follows: DE FI NI TI O N 1. Given unsatis.able \npaths P = {P1, P2, . . . , Pn}, a set of inequalities S is a missing hypothesis for P iff .Pi . m P . \nH(Pi) . I.S I f C(Pi). Intuitively, adding all inequalities in the missing hypothesis to the assertions \nhypotheses removes all unsatis.able paths in the constraint graph.2 Example Returning to the example \nin Section 5.3.1, it is easy to verify that Alice = Bob is a missing hypothesis that makes all of the \nassertions valid.  5.3.3 Finding a minimal weakest hypothesis We are not interested in all missing hypotheses; \ninstead, we want to .nd one that is both minimal and as weak as possible. To simplify the notation, we \nfurther de.ne the conclusion set of unsatis.able paths P as the union of all conclusions: C(P) = {C(Pi) \n| Pi . P }. The .rst insight is that the inferred missing hypothesis should not be too strong. DE FI \nNI TI O N 2. For a set of unsatis.able paths P, a missing hy\u00adpothesis S is no weaker than S ' iff _ '' \n' .I . S . .P . P . H(P ) . I f I I.S That is, S is no weaker than S ' if all inequalities in S ' can \nbe proved from S, using at most one existing hypothesis. Given this de.nition, the .rst property we show \nis that every subset of C(P) that forms a missing hypothesis is maximally weak: LEMM A 1. .S . C(P). \nS is a missing hypothesis =. no missing hypothesis is strictly weaker than S. Proof. Suppose there exists \na strictly weaker missing hypothesis S ' . m Since S ' is a missing hypothesis, H(Pi) . F.SF I ' f C(Pi) \nfor m I all i. Since S . C(P), .I . S . H(Pi) . IF.SF I ' f I. So S ' is no weaker than S. Contradiction. \nD The lemma above suggests that subsets of C(P) may be good candidates for a weak missing hypothesis. \nHowever, they are not necessarily minimal. For instance, the entire set C(P) is a maxi\u00admally weak missing \nhypothesis. To remove the redundancy in this weakest hypothesis, we ob\u00adserve that some of the conclusions \nare subsumed by others. To be 2 A more general form of missing hypothesis might infer individual hypothe\u00adses \nfor each path. But it is less feasible to do so. more speci.c, we say a conclusion ci subsumes another \nconclusion cj = C(Pj ) if ci . H(Pj ) f cj . Intuitively, if ci subsumes cj , then adding ci to the hypothesis \nof Pj makes Pj satis.able. Example Return to the example in Section 5.3.1. The missing hypothesis Alice \n= Bob is both the weakest and minimal. Based on Lemma 1 and the de.nition above, .nding a minimal weakest \nmissing hypothesis in C(P) is equivalent to .nding the minimum subset of C(P) which subsumes all c . \nC(P). This gives us the following algorithm: Algorithm Given a set of unsatis.able paths P = {P1, P2, \n. . . , Pn}: 1. Construct the set C(P) from the unsatis.able paths. 2. For all ci, cj in C(P), add cj \nto set Si, the set of conclusions subsumed by ci, if ci subsumes cj .  3. Find the minimum cover M of \nC(P), where S = {S1, . . . , Sn} and M . S .  4. Return {ci | Si . M}.  A brute force algorithm for \n.nding the minimal weakest missing hypothesis may check all possible hypotheses. That is on the order \nof 2N2 (the number of all subsets of = orderings on elements) where N is the total number of elements \nused in the constraints. While the complexity of our algorithm is exponential in the number of unsatis.able \npaths in the constraint graph, this number is usually small in practice. So the computation is still \nfeasible. 6. Evaluation 6.1 Implementation We implemented our general error diagnostic tool in Java. \nThe im\u00adplementation includes about 5,500 lines of source code, excluding comments and blank lines. As \ninput, the diagnostic tool reads in constraints following the syntax of Figure 4. The program analyses \nto be diagnosed must be modi.ed to emit those constraints. To evaluate our error diagnostic tool on real-world \nprogram analyses, we modi.ed the Jif compiler and an extension to the OCaml compiler, EasyOCaml [11], \nto generate constraints in our constraint language format. EasyOCaml is an extension of OCaml 3.10.2 \nthat generates the labeled constraints de.ned in [14]. Generating constraints in our language format \ninvolved only modest effort. Changes to the Jif compiler include about 300 LoC (lines of code) above \nmore than 45,000 LoC in the Jif compiler. Changes to EasyOCaml include about 500 LoC above the 9,000 \nLoC of the EasyOCaml extension. Slightly more effort is required for EasyOCaml because that compiler \ndid not track the locations of type variables; this functionality had to be added to trace constraints \nback to the corresponding source code. 6.2 Case study: OCaml error reporting To evaluate the quality \nof our ranking algorithm, we used a corpus of previously collected OCaml programs containing errors, \ncollected by Lerner et al. [22]. The data were collected from a graduate-level programming-language course \nfor part-time students with at least two years professional software development experience. The data \ncame from 5 homework assignments and 10 students participating in the class. Each assignment requires \nstudents to write 100 200 lines of code. From the data, we analyzed only type mismatch errors, which \ncorrespond to unsatis.able constraints. Errors such as unbound val\u00adues or too many arguments to a constructor \nare more easily localized and are not our focus. We also exclude programs using features not supported \nby Easy-OCaml and .les where the user s .x is unclear. After excluding these .les, 336 samples remain. \nAnalysis Analyzing a .le and the quality of error report message manually can be inherently subjective. \nWe made the following ef\u00adforts to make our analysis less subjective: 1. Instead of judging which error \nmessage is more useful, we judged whether the error locations the tools reported were cor\u00adrect. 2. To \nlocate the actual error in the program, we use the user s changes with larger timestamps as a reference. \nFiles where the error location is unclear are excluded in our evaluation.  To ensure the tools return \nprecisely the actual error, a returned location is judged as correct only when it is a subset of the \nactual error locations. One subtlety of judging correctness is that multiple locations can be good suggestions, \nbecause of let-bindings. For instance, consider a simple OCaml program: 1 l e t x = t r u e i n x + 1 \nEven if the programmer later changed true to be some integer, the error suggestion of the let-binding \nof x and the use of x are still considered to be correct since they bind to the same expression as the \n.x. However, the operation + and the integer 1 are not since the .x is not related. Since the OCaml error \nmessage reports an expression that ap\u00adpears to have the wrong type, to make the reports comparable, we \nuse expressions as the program entities on which we run our infer\u00adence algorithm our tool reports likely \nwrong expressions in eval\u00aduation. Recall that our tool can also generate reports of why an ex\u00adpression \nhas a wrong type, corresponding to unsatis.able paths in the constraint graph. Using such extra information \nmight improve the error message, but we do not use that capability in the evalua\u00adtion. Another mismatch \nis that our tool inherently reports a small set of program entities (expressions in this case) with the \nsame estimated quality, whereas OCaml reports one error at one time. To make the comparison fair, we \nmake the following efforts: 1. For cases where we report a better result (our tools .nds the error location \nthat OCaml misses), we ensure that all locations returned are correct. 2. For other cases, we ensure \nthat the majority of the suggestions are correct.  Moreover, the average top rank suggestion size is \nsmaller than 2. Therefore, our evaluation results should not be affected much by the fact that our tool \ncan offer multiple suggestions. 6.2.1 Sensitivity Recall that maximizing the likelihood of entities \nE being an error is equivalent to minimizing the term C1|E| + C2kE, where C1 = - log P1 and C2 = - log(P2/(1 \n- P2)) (see, Section 5.2). Hence, the ranking is only affected by the ratio between C1 and C2. To test \nhow sensitive our tool is to the choice of P1 and P2, we collect two important statistics for a wide \nrange of P1 and P2 values: 1) the number of programs where the actual error is missing in top rank suggestions \n(among 336 programs), 2) the average number of suggestions in the top rank. The result is summarized \nin Table 1. We arrange the columns in Table 1 such that for any 0 < P2 < 0.5, P1 decreases exponentially \nfrom left to right. The last column corresponds to the special case when P2 = 0.5. Empirically, the overall \nsuggestion quality is best when P1 = P2 '3, where P2 ' = P2/1 - P2. However, the quality of the sugges- \n '2 '6 tions is close for any P1 and P2 s.t. P2 = P1 = P2 ; the results are not very sensitive to the \nchoice of these parameters. If satis.able paths are ignored (P2 = 0.5, that is, C2 = 0), the top-rank \nsuggestion size is much larger, and more errors are missing. Hence, using satis.able paths is important \nto suggestion quality. The quality of the error report is also considerably worse when P1 is very large \nrelative to P2 (P1 = P2 '). This result shows that unsuccessful paths are more important than successful \npaths, but that ascribing too importance to the unsuccessful paths (e.g., at P1 = P2 '10) also hurts \nthe quality of the error report. 6.2.2 Comparison with OCaml and Seminal For each .le we analyze, we \nconsider both the error location re\u00adported by OCaml and the top-ranked suggestion of our tool (based \non the setting P1 = (P2/1 - P2)3). We reused the data offered by the authors of the Seminal tool [22], \nwho labeled the correctness of Seminal s error location report. We classify the .les into one of the \nfollowing .ve categories and summarize the results in Figure 9: 1. Our approach suggests an error location \nthat matches the pro\u00adgrammer s .x, but the other tool s location misses the error. 2. Our approach reports \nmultiple correct error locations that match the programmer s .x, but the other tool only reports one \nof them. 3. Both approaches .nd error locations corresponding to the pro\u00adgrammer s .x. 4. Both approaches \nmiss the error locations corresponding to the programmer s .x. 5. Our tool misses the error location \nbut the other tool captures it.  The result shows that OCaml s reports .nd about 75% of the error locations \nbut miss the rest. Seminal s reports on error locations are slightly better, .nding about 80% of the \nerror locations. Compared with both OCaml and Seminal, our tool consistently identi.es a higher percentage \nof error locations across all home\u00adworks, with an average of 96%. In about 10% of cases, our tool identi.es \nmultiple errors in programs. According to the data, the programmers usually .xed these errors one by \none since the OCaml compiler only reports one at a time. Reporting multiple errors at once may be more \nhelpful. Limitations Of course, our tool sometimes misses errors. We stud\u00adied programs where our tool \nmissed the error location, .nding that in each case it involved multiple interacting errors. In some \ncases P1 = P ' 2 P1 = P '2 2 P1 = P '3 2 P1 = P '4 2 P1 = P '5 2 P1 = P '6 2 P1 = P '10 2 P2 = 0.5 Missed \nError 21 15 14 17 17 16 22 23 Avg. Sugg. Size 1.86 1.80 1.72 1.69 1.70 1.69 1.67 5.58 Table 1. The quality \nof top-ranked suggestions with various values of P1 and P2, where P2 ' = P2/1 - P2. (a) Comparison with \nthe OCaml compiler (b) Comparison with Seminal Figure 9. Results organized by homework assignment. From \ntop to bottom, columns represent programs where (1) our tool .nds a correct error location that the other \ntool misses. (2) both approaches report the correct error location, but our tool reports multiple (correct) \nerror locations; (3) both approaches report the correct error location; (4) both approaches miss the \nerror location; (5) our tool misses the error location while the other tool identi.es one of them. For \nevery assignment, our tool does the best job of locating the error. the programmer made a similar error \nmultiple times. Our tool fails to identify such errors because they violate the assumption of error independence. \nAs our result suggests, this situation is rare. The comparison between the tools is not completely apples\u00adto-apples. \nWe only collect type mismatch errors in the evaluation. OCaml is very effective at .nding other kinds \nof errors such as unbound variables or wrong numbers of arguments, and Seminal not only .nds errors but \nalso proposes .xes.  6.2.3 Performance We measured the performance of our tool on a Ubuntu 11.04 system \nusing a dual core at 2.93GHz with 4G memory. Results are shown in Figure 10. We separate the time spent \ngenerating and inferring LEQ edges in the graph from that spent computing rankings. The results show \nhow the running time of both graph building time and ranking time scale with increasing constraint graph \nsize. Interestingly, graph building, including the inference of (+LEQ) relationships, dominates and is \nin practice quadratic in the graph size. The graph size has less impact on the running time of our ranking \nalgorithm. We suspect the reason is that the running time of our ranking algorithm is dominated by the \nnumber of unsatis.able paths, which is not strongly related to total graph size. Considering graph construction \ntime, all programs .nish in 79 seconds, and over 95% are done within 20 seconds. Ranking is more ef.cient: \nall programs .nish in 10 seconds. Considering the human cost to identify error locations, the performance \nseems acceptable.  6.3 Case study: Jif hypothesis inference We also evaluated how helpful our hypothesis \ninference algorithm is for Jif. In our experience with using Jif, we have found missing hypotheses to \nbe a common source of errors. A corpus of buggy programs was harder to .nd for Jif than for OCaml. We \nobtained application code developed for other, earlier projects using either Jif or Fabric (a Jif extension). \nThese applica- Secure Tie Better Worse Total Number 12 17 11 0 40 Percentage 30% 42.5% 27.5% 0% 100% \n Table 2. Hypothesis inference result tions are interesting since they deal with real-world security \ncon\u00adcerns. To mimic potential errors programmer would meet while writ\u00ading the application, we randomly \nremoved hypotheses from these programs, generating, in total, 40 .les missing 1 5 hypotheses. The frequency \nof occurrence of each application in these 40 .les corre\u00adsponds roughly to the size of the application. \nFor all .les generated in this way, we classi.ed each .le into one of four categories, with the results \nsummarized in Table 2: 1. The program passed Jif/Fabric label checking after removing the hypotheses: \nthe programmer made unneeded assumptions. 2. The generated missing hypotheses matched the one we removed. \n 3. The generated missing hypotheses provides an assumption that removes the error, but that is weaker \nthan the one we removed (in other words, an improvement). 4. Our tool fails to .nd a suggestion better \nthan the one removed.  The number of redundant assumptions in these applications is considerable (30%). \nWe suspect the reason is that the security mod\u00adels in these applications are nontrivial, so programmers \nhave dif.\u00adculty formulating their security assumptions. This observation sug\u00adgests that the ability to \nautomatically infer missing hypotheses could be very useful to programmers. All the automatically inferred \nhypotheses had at least the same quality as manually written ones. This preliminary result suggests that \nour hypothesis inference algorithm is very effective and should be useful to programmers. Errors Separate \nCombined Interactive Missing hypothesis 11 10 7 11 Wrong expression 5 4 4 4 Total 16 14 11 15 Percentage \n100% 87.5% 68.75% 93.75% Table 3. Jif case study result. (1) Separate: top rank of both sep\u00adarately \ncomputed hypothesis and expression suggestions (2) Com\u00adbined: top rank combined result only (3) Interactive \napproach  6.4 Case study: combined errors To see how useful our diagnostic tool is for Jif errors that \noccur in practice, we used a corpus of buggy Fabric programs that a devel\u00adoper collected earlier during \nthe development of the FriendMap application [3]. As errors were reported by the compiler, the pro\u00ad grammer \nalso clearly marked the nature and true location of the er\u00adror. This application is interesting for our \nevaluation purposes since it is complex it was developed over the course of six weeks by two developers \nand it contains both types of errors: missing hypothe\u00adses and wrong expressions. The corpus contains \n24 buggy Fabric programs. One dif.culty in working on these programs directly was that 9 .les contained \nmany errors. This happened because the buggy code was commented out earlier by the programmer to better \nlocalize the errors reported by the Fabric compiler. We posit that this can be avoided if a better error \ndiagnostic tool, like ours, is used. For these .les, we reproduced the errors the programmer pointed \nout in the notes when possible and ignored the rest. Redundancy programs producing the same errors was \nalso removed. Result for the remaining 16 programs are shown in Table 3. Most .les contain multiple errors. \nWe used the errors recorded in the note as actual errors, and an error is counted as being identi.ed \nonly when the actual error is suggested among top rank suggestions. The .rst approach (Separate) measures \nerrors identi.ed if the er\u00adror type is known ahead, or both hypothesis and expression sugges\u00adtions separately \ncomputed are used. The result is comparable to the result in Sections 6.2 and 6.3, where error types \nare known ahead. Providing a concise and correct error report when multiple errors interact can be more \nchallenging. We evaluated the performance of two approaches providing combined suggestions. The combined \napproach simply ranks the combined suggestions by size. Despite its simplicity, the result is still useful \nsince this approach is automatic. The interactive approach calculates missing hypotheses and re\u00adquires \na programmer to mark the correctness of these hypotheses. Then, correct hypotheses are used and wrong \nentities are suggested to explain the remaining errors. We think this is the most promis\u00ading approach, \nsince it involves limited manual effort: hypotheses are usually facts of properties to be checked, such \nas is a .ow from Alice to Bob secure? . We leave a more comprehensive study of this approach to future \nwork. 7. Related work Program analyses, constraints and graph representations Mod\u00adeling program analyses \nvia constraint solving is not a new idea. The most related work is on set constraint-based program analysis \n[1, 2] and type quali.ers [12]. However, these constraint languages do not model hypotheses, which are \nimportant for some program analyses, such as information .ow. Program slicing, shape analysis, and .ow-insensitive \npoints\u00adto analysis are expressible using graph-reachability [33]. Melski and Reps [27] show the interchangeability \nbetween context-free\u00ad language reachability (CFL-reachability) and a subset of set con\u00adstraints [1]. \nBut only a small set of constraints in fact, a single variable may appear on the right hand side of a \npartial order. Moreover, no error diagnostic approach is proposed for the graphs. Error diagnoses for \ntype inference and information-.ow control Dissatisfaction with error reports has led to earlier work \non improv\u00ading the error messages of both ML-like languages and Jif. Efforts on improving type-error messages \nin ML-like languages can be traced to the early work of Wand [35] and of Johnson and Walz [18]. These \ntwo pieces of work represent two directions in improving error messages: the former traces everything \nthat con\u00adtributes to the error, whereas the latter attempts to infer the most likely cause. We only discuss \nthe most related among them, but Heeren s summary [16] provides more details. In the .rst direction, \nseveral efforts [7, 12, 14, 32, 34] improve the basic idea of Wand [35] in various ways. Despite the \nattractive\u00ad ness of feeding a full explanation to the programmer, the reports are usually verbose and \nhard to follow [16]. In the second direction, one approach is to alter the order of type uni.cation [21, \n25]. But since the error location may be used any\u00ad where during the uni.cation procedure, any speci.c \norder fails in some circumstance. Some prior work [16, 18] builds a type graph from a more limited constraint \nlanguage and infers error locations based on heuristics mostly tailored for type inference. Though the \nweighted options heuristic in [18] uses successful type uni.ca\u00ad tions to distinguish abnormal types from \nnormal ones, information about satis.able paths is leveraged with .ner-granularity in our ap\u00adproach, \nto distinguish the constraints that caused errors. This is shown to be effective in Section 6.2.1. A \nthird approach is to generate .xes for errors by searching for similar programs [22, 26] or type substitutions \n[6] that do type\u00ad check. Unfortunately, we cannot obtain a common corpus to per\u00adform direct comparison \nwith some of this prior work [6, 26]. It is worth noting that the ranking heuristics used in [6] are \nlanguage\u00ad speci.c: there is no obvious way to extend them to information .ow, for instance. We are able \nto compare directly with the work of Lerner et al. [22]; the results of Section 6.2 suggest that our \nap\u00ad proach .nds error locations more accurately. In fact, by pinpointing where searches for .xes are \nlikely to be productive, our approach ought to be complementary. For information-.ow control, King et \nal. [19] propose to gener\u00ad ate a trace explaining the information-.ow violation. Although this approach \nalso constructs a diagnosis from a dependency graph, only a subset of the DLM model is handled. As in \ntype-error slicing, reporting whole paths can yield very verbose error reports. Recent work by Weijers \net al. [37] diagnoses information-.ow violations in a higher-order, polymorphic language. But the mechanism \nis based on tailored heuristics and a more limited constraint language. More\u00adover, the algorithm in [37] \ndiagnoses a single unsatis.able path, while our algorithm diagnoses multiple errors. Probabilistic inference \nApplying probabilistic inference to pro\u00adgram analysis has appeared in earlier work, particularly on spec\u00adi.cation \ninference [20, 24]. Our contribution is to apply proba\u00ad bilistic inference to a general class of static \nanalyses, allowing errors to be localized without language-speci.c tuning. Also re\u00adlated is work on statistical \nmethods for diagnosing dynamic errors (e.g., [23, 39]). These algorithms rely on a different principle \nstatistical interpretation and do not handle important features for static analysis, such as constructors \nand hypotheses. The work of Ball et al. on diagnosing errors detected by model checking has exploited \na similar insight by using information about traces for both correct execution and for errors to localize \nerror causes [4]. Beyond differences in context, that work differs in not actually using probabilistic \ninference; each error trace is considered in isolation, and transitions are not .agged as causes if they \nlie on any correct trace. Missing hypothesis inference The most related work on inferring likely missing \nhypotheses is the recent work by Dillig et al. on er\u00adror diagnosis using abductive inference [10]. This \nwork computes small, relevant queries presented to a user that capture exactly the information a program \nanalysis is missing to either discharge or val\u00adidate the error. It does not attempt to identify incorrect \nconstraints. With regard to hypothesis inference, the algorithm in [10] infers missing hypotheses for \na single assertion, while our tool .nds miss\u00ading hypotheses that satisfy a set of assertions. Further, \nthe algorithm of [10] infers additional invariants on variables (e.g., x = 3 for a constraint variable \nx), while our algorithm also infers missing par\u00adtial orderings on constructors (e.g., Alice = Bob in \nSection 5.3.1). 8. Conclusion Better tools for helping programmers locate the errors detected by program \nanalysis should make them more willing to use the many powerful program analyses that have been developed. \nThe science of diagnosing programmer errors is still rather primitive, but this paper takes a step towards \nimproving the situation. Our analysis of program constraint graphs offers a general, principled way to \nidentify both incorrect expressions and missing assumptions. Results on two very different languages, \nOCaml and Jif, with little language-speci.c customization, suggest this approach is promising and broadly \napplicable. There are many interesting directions to take this work. Though we have shown that the technique \nworks well on two very different type systems, it would likely be fruitful to apply these ideas to other \ntype systems and program analyses, and to explore more sophisti\u00adcated ways to estimate the likelihood \nof different error explanations. Acknowledgments Nate Foster, Mike George, Chinawat Isradisaikul, Jean-Baptiste \nJeannin, Vincent Rahli, Robert Soul\u00b4e and Ross Tate gave many useful comments on this presentation. We \nalso thank Ben Lerner and Dan Grossman for making available the excellent data set they used for their \nwork on Seminal, Dexter Kozen for pointing out the similarity between our constraints and set constraints, \nand Mike George for a well-organized and labeled set of Jif test cases. This work was supported by two \ngrants from the Of.ce of Naval Research, N00014-09-1-0652 and N00014-13-1-0089, by MURI grant FA9550-12-1-0400, \nby a grant from the National Science Foundation (CCF-09644909), and by a grant administered by the Air \nForce Research Laboratory. References [1] A. Aiken. Introduction to set constraint-based program analysis. \nScience of Computer Programming, 35:79 111, 1999. [2] A. Aiken and E. L. Wimmers. Type inclusion constraints \nand type inference. In Conf. Functional Programming Languages and Computer Architecture, pp. 31 41, 1993. \n[3] O. Arden, M. D. George, J. Liu, K. Vikram, A. Askarov, and A. C. Myers. Sharing mobile code securely \nwith information .ow control. In Proc. IEEE Symp. on Security and Privacy, pp. 191 205, May 2012. [4] \nT. Ball, M. Naik, and S. Rajamani. From symptom to cause: Localizing errors in counterexample traces. \nIn POPL 30, pp. 97 105, Jan. 2003. [5] C. Barrett, R. Jacob, and M. Marathe. Formal-language-constrained \npath problems. SIAM Journal on Computing, 30:809 837, 2000. [6] S. Chen and M. Erwig. Counter-factual \ntyping for debugging type errors. In POPL 41, Jan. 2014. [7] V. Choppella and C. T. Haynes. Diagnosis \nof ill-typed programs. Tech\u00adnical report, Indiana University, December 1995. [8] L. M. M. Damas. Type \nassignment in programming languages. PhD thesis, Department of Computer Science, University of Edinburgh, \n1985. [9] D. E. Denning. A lattice model of secure information .ow. Comm. of the ACM, 19(5):236 243, \n1976. [10] I. Dillig, T. Dillig, and A. Aiken. Automated error diagnosis using abductive inference. In \nPLDI 12, pp. 181 192, 2012. [11] EasyOCaml. http://easyocaml.forge.ocamlcore.org. [12] J. S. Foster, \nR. Johnson, J. Kodumal, and A. Aiken. Flow-insensitive type quali.ers. ACM Trans. Prog. Lang. Syst., \n28(6):1035 1087, Nov. 2006. [13] A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin. Bayesian Data \nAnalysis. Chapman &#38; Hall/CRC, 2nd edition, 2004. [14] C. Haack and J. B. Wells. Type error slicing \nin implicitly typed higher\u00adorder languages. Science of Computer Programming, 50(1 3):189 224, 2004. [15] \nP. Hart, N. Nilsson, and B. Raphael. A formal basis for the heuristic determination of minimum cost paths. \nSystems Science and Cybernetics, IEEE Transactions on, 4(2):100 107, 1968. [16] B. J. Heeren. Top Quality \nType Error Messages. PhD thesis, Universiteit Utrecht, The Netherlands, Sept. 2005. [17] P. Hudak, S. \nP. Jones, and P. Wadler. Report on the programming language Haskell. SIGPLAN Notices, 27(5), May 1992. \n[18] G. F. Johnson and J. A. Walz. A maximum .ow approach to anomaly isolation in uni.cation-based incremental \ntype inference. In POPL 13, pp. 44 57, 1986. [19] D. King, T. Jaeger, S. Jha, and S. A. Seshia. Effective \nblame for information-.ow violations. In Int l Symp. on Foundations of Software Engineering, pp. 250 \n260, 2008. [20] T. Kremenek, P. Twohey, G. Back, A. Ng, and D. Engler. From un\u00adcertainty to belief: inferring \nthe speci.cation within. In OSDI 06, pp. 161 176, 2006. [21] O. Lee and K. Yi. Proofs about a folklore \nlet-polymorphic type inference algorithm. ACM Trans. Prog. Lang. Syst., 20(4):707 723, 1998. [22] B. \nS. Lerner, M. Flower, D. Grossman, and C. Chambers. Searching for type-error messages. In PLDI 07, pp. \n425 434, 2007. [23] B. Liblit, M. Naik, A. X. Zheng, A. Aiken, and M. I. Jordan. Scalable statistical \nbug isolation. In PLDI 05, pp. 15 26, 2005. [24] B. Livshits, A. V. Nori, S. K. Rajamani, and A. Banerjee. \nMerlin: spec\u00adi.cation inference for explicit information .ow problems. In PLDI 09, pp. 75 86, 2009. [25] \nB. J. McAdam. On the uni.cation of substitutions in type inference. In Implementation of Functional Languages, \npp. 139 154, 1998. [26] B. J. McAdam. Repairing Type Errors in Functional Programs. PhD thesis, Laboratory \nfor Foundations of Computer Science, The University of Edinburgh, 2001. [27] D. Melski and T. Reps. Interconvertibility \nof a class of set constraints and context-free language reachability. Theoretical Computer Science, 248(1 \n2):29 98, 2000. [28] R. Milner, M. Tofte, and R. Harper. The De.nition of Standard ML. MIT Press, Cambridge, \nMA, 1990. [29] A. C. Myers and B. Liskov. A decentralized model for information .ow control. In SOSP \n97, pp. 129 142, 1997. [30] A. C. Myers, L. Zheng, S. Zdancewic, S. Chong, and N. Nystrom. Jif 3.0: Java \ninformation .ow. Software release, www.cs.cornell.edu/jif, July 2006. [31] OCaml programming language. \nhttp://ocaml.org. [32] V. Rahli, J. B. Wells, and F. Kamareddine. A constraint system for a SML type \nerror slicer. Technical Report HW-MACS-TR-0079, Heriot-Watt university, 2010. [33] T. Reps. Program analysis \nvia graph reachability. Information and Software Technology, 40(11 12):701 726, 1998. [34] F. Tip and \nT. B. Dinesh. A slicing-based approach for locating type errors. ACM Trans. on Software Engineering and \nMethodology, 10(1):5 55, 2001. [35] M. Wand. Finding the source of type errors. In POPL 13, 1986. [36] \nM. Wand. A simple algorithm and proof for type inference. Fundamenta Informaticae, 10:115 122, 1987. \n[37] J. Weijers, J. Hage, and S. Holdermans. Security type error diagnosis for higher-order, polymorphic \nlanguages. In ACM SIGPLAN workshop on Partial evaluation and program manipulation, pp. 3 12, 2013. [38] \nD. Zhang and A. C. Myers. Toward general diagnosis of static errors: Technical report. Technical Report \nhttp://hdl.handle.net/1813/33742, Cornell University, Aug. 2014. [39] A. X. Zheng, B. Liblit, and M. \nNaik. Statistical debugging: simultaneous identi.cation of multiple bugs. In ICML 06, pp. 1105 1112, \n2006.    \n\t\t\t", "proc_id": "2535838", "abstract": "<p>We introduce a general way to locate programmer mistakes that are detected by static analyses such as type checking. The program analysis is expressed in a constraint language in which mistakes result in unsatisfiable constraints. Given an unsatisfiable system of constraints, both satisfiable and unsatisfiable constraints are analyzed, to identify the program expressions most likely to be the cause of unsatisfiability. The likelihood of different error explanations is evaluated under the assumption that the programmer's code is mostly correct, so the simplest explanations are chosen, following Bayesian principles. For analyses that rely on programmer-stated assumptions, the diagnosis also identifies assumptions likely to have been omitted. The new error diagnosis approach has been implemented for two very different program analyses: type inference in OCaml and information flow checking in Jif. The effectiveness of the approach is evaluated using previously collected programs containing errors. The results show that when compared to existing compilers and other tools, the general technique identifies the location of programmer errors significantly more accurately.</p>", "authors": [{"name": "Danfeng Zhang", "author_profile_id": "81470651200", "affiliation": "Cornell University, Ithaca, NY, USA", "person_id": "P4383905", "email_address": "zhangdf@cs.cornell.edu", "orcid_id": ""}, {"name": "Andrew C. Myers", "author_profile_id": "81100011022", "affiliation": "Cornell University, Ithaca, NY, USA", "person_id": "P4383906", "email_address": "andru@cs.cornell.edu", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535870", "year": "2014", "article_id": "2535870", "conference": "POPL", "title": "Toward general diagnosis of static errors", "url": "http://dl.acm.org/citation.cfm?id=2535870"}