{"article_publication_date": "01-08-2014", "fulltext": "\n Profiling for Laziness Stephen Chang stchang@ccs.neu.edu PLT at Northeastern University Boston, MA 02115 \nMatthias Felleisen matthias@ccs.neu.edu Abstract While many programmers appreciate the bene.ts of lazy \nprogram\u00adming at an abstract level, determining which parts of a concrete program to evaluate lazily poses \na signi.cant challenge for most of them. Over the past thirty years, experts have published numer\u00adous \npapers on the problem, but developing this level of expertise requires a signi.cant amount of experience. \nWe present a pro.ling-based technique that captures and auto\u00admates this expertise for the insertion of \nlaziness annotations into strict programs. To make this idea precise, we show how to equip a formal semantics \nwith a metric that measures waste in an evalu\u00adation. Then we explain how to implement this metric as \na dynamic pro.ling tool that suggests where to insert laziness into a program. Finally, we present evidence \nthat our pro.ler s suggestions either match or improve on an expert s use of laziness in a range of real\u00adworld \napplications. Categories and Subject Descriptors D.3.1 [Programming Lan\u00adguages]: Formal De.nitions and \nTheory General Terms laziness; pro.ling; code refactoring 1. Where To Be Lazy Experts have extolled the \nbene.ts of laziness for decades now. As Hughes explained [12], lazy programming languages enable pro\u00adgrammers \nto design code in a modular way; even earlier, Abelson and Sussman [1] argued that programs in strict \nlanguages can pro.t from laziness. Programmers have learned, however, that the key to deploying laziness \nis moderation, because laziness severely com\u00adplicates reasoning about a program s resource consumption \n[11]. Approaches to taming laziness come from two different direc\u00adtions. From one direction, lazy language \nresearchers have devised strategies for determining when to safely remove laziness [4, 6, 16]. Because \nthese methods still tend to leave too much laziness behind, lazy programmers frequently annotate their \nprograms with strict\u00adness annotations such as Haskell s seq [18]. From the other direc\u00adtion, strict programmers \nadd laziness via constructs such as delay and force, for example to manage large data structures [17], \nde\u00adlay possibly unneeded tasks [8], or leverage other lazy design pat\u00adterns [21]. Though the strict approach \nis appealing since most pro\u00adgrams need only a small amount of laziness [5, 14, 15, 20], .nding exactly \nwhere to add the laziness can be problematic. Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. Copyrights for components of this work owned by others than the author(s) must be honored. \nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. Request permissions from permissions@acm.org. \nPOPL 14, January 22 24, 2014, San Diego, CA, USA. Copyright is held by the owner/author(s). Publication \nrights licensed to ACM. ACM 978-1-4503-2544-8/14/01. . . $15.00. http://dx.doi.org/10.1145/2535838.2535887 \n Consider a programmer who wishes to insert laziness annota\u00adtions into a .nite strict program in order \nto improve its perfor\u00admance. The problem is that laziness is a .ow-oriented, global prop\u00aderty of programs. \nInserting an annotation in one place tends to re\u00adquire additional annotations at other, distant points \nin the program. Omitting even one of these annotations can result in the complete loss of the desired \nbene.ts. In short, the dif.culty in placing lazi\u00adness in strict programs is a devastating handicap. 1 \nRecently, Chang [3] tackled the problem with a static analysis\u00adbased tool. This static analysis assumes \nthat a programmer has partially annotated a program. Based on these annotations and a control-.ow analysis, \nit suggests additional delay annotations. Be\u00adcause the tool considers only static information, it merely \napprox\u00adimates where laziness is needed and often produces spurious sug\u00adgestions. The requirement for \nsome initial seed annotations con\u00adtributes additional imprecision. Finally, Chang reports that he oc\u00adcasionally \nhas to run his tool more than once to .nd expert-level placement but offers no guidance on this issue. \nIn this paper, we present a dynamic solution that interprets in\u00adformation from an execution to determine \nwhich parts of the pro\u00adgram to evaluate lazily. Our solution consists of three concrete con\u00adtributions. \nFirst, we show how to equip a call-by-value .-calculus semantics with a metric for assessing each expression \ns laziness potential. Roughly, laziness potential represents the amount of un\u00adneeded computation performed \nby the evaluation of an expression. It thus predicts the degree to which a program s performance ben\u00ade.ts \nfrom delaying that expression. Second, we explain how to im\u00adplement this metric as a dynamic pro.ler \nfor an untyped scripting language.2 After pro.ling a program on a typical input, the tool suggests where \nto add laziness annotations. Third, we present evi\u00addence that our pro.ler generates advice comparable \nto that of ex\u00adperts in the literature. For most of the programs we examined, our pro.ler requests the \ninsertion of delays at the same places as hu\u00adman experts; in a few instances, the pro.ler s suggestions \nachieve the same performance bene.ts with fewer laziness annotations. The next section presents some \nmotivating examples, and sec\u00adtion 3 formally describes the notion of laziness potential. Section 4 presents \nour prototype pro.ler implementation, while section 5 demonstrates its effectiveness. Finally, the remaining \nsections con\u00adclude with related and future work. 2. Laziness Potential, the Intuition In some instances, \nit is easy for a programmer to identify where laziness is bene.cial. Other times, trying to .nd these \nspots in a program is challenging. In this section, we explain our method for .nding such spots with \na series of examples. 1 http://pchiusano.blogspot.com/2009/05/optional-laziness-doesnt-quite-cut-it.html \n2 These languages tend to support laziness annotations natively or with libraries and should bene.t most \nfrom our work. Our work applies to typed languages as well; see section 5. 2.1 Criteria for Laziness \n If an expression s result is not used, we should delay its evaluation. Informally, a value is used if \nit reaches a position that requires a speci.c (kind of) value to continue the evaluation process. Exam\u00adples \nof such positions are the operands to primitive functions, the test in a conditional, and the function \nposition in an application. In contrast, positions such as arguments to a programmer s functions and \ndata constructors do not use their values. Thus the underlined argument in the following expression should \nbe delayed: (.x.1) (2 + 3) Our initial laziness criterion does not cover the case where a program evaluates \nan expression more than once, e.g., via recur\u00adsion, producing multiple values. We could extend our criterion \nto delay expressions where none of its values are used, but obviously this binary classi.cation is useless \nfor practical cases. Consider the following pseudocode, which represents a function de.nition and its \nuse in a typical strict functional language: def rng n m = (1) if n = m then nil (2) else n ::rng (n+1) \nm (3) (4) let lst = rng 1 1000 (5) in (second lst) + (third lst) (6) A call to rng n m produces the list \nof integers in [n, m). In this example, the (underlined) recursive call to rng is evaluated multiple \ntimes and produces multiple values. Although second and third use two of these values, the program is \nlikely to bene.t from delaying the underlined expression because most of the list is unused. The example \nsuggests a quantitative criterion for the injection of laziness into strict programs. Speci.cally, it \nhints that the ratio of the number of used results to the total number of results per expression might \npinpoint delayable expressions. In the example, the recursive call to rng is evaluated m - n = 999 times \nand two of the values are used, giving it a ratio of 2/999. Pro.ling this example with our tool reports \nthe following: rng (n+1) m [ln 3]: 2/999 values used An expression with such a low ratio seems like \na promising candi\u00addate for laziness, but as the following (boxed) changes to the exam\u00adple show, this \n.rst quantitative criterion is still insuf.cient: def rng f n m = (1) if n = m then nil (2) else f n \n::rng f (n+1) m (3) (4) let lst = rng add1 1 1000 (5) in (second lst) + (third lst) (6) Here is some \ndata returned by our pro.ler: f n [ln 3]: 2/999 values used rng f (n+1) m [ln 3]: 2/999 values used \n The expressions f n and rng f (n+1) m have equal ratios, seem\u00adingly indicating that the program bene.ts \nequally from delaying each. A programmer immediately understands, however, that this recommendation is \nmisleading because delaying the call to rng would prevent most calls to f. To combine these factors, \nwe focus only on the unused values, and additionally weight them by the number of child-values created \nduring the creation of an unused value. Essentially, this weight is correlated to the size of the dynamic \nvalue-dependency tree whose root is the unused value. The weight of an expression then, which we dub \nits laziness potential, is roughly the average of the weights of all its unused values. Our pro.ler reports \nthis information, too: rng f (n+1) m [ln 3]: 2/999 values used -delaying 997 unused avoids 2989 subvalues, \nwgt=2990 f n [ln 3]: 2/999 values used -delaying 997 unused avoids 0 subvalues, wgt=1 A higher weight \nindicates a greater bene.t from laziness. The exact calculation of laziness potential is discussed in \nsection 3 but the important takeaway here is that the pro.ler now considers delaying the call to rng \nmore bene.cial than delaying the call to f, which aligns with a programmer s intuition. Laziness potential \nseems promising as a criterion but the follow\u00ading generate and .lter example demonstrates another problem: \ndef rng f n m = (1) if n = m then nil (2) else f n :: rng f (n+1) m (3) def .lter p? lst = (4) if nil? \nlst then nil (5) else let x = first lst (6) in if p? x then x ::.lter p? (rest lst) (7) else .lter p? \n(rest lst) (8) (9) let lst = .lter even? (rng add1 1 1000) (10) in (second lst) + (third lst) (11) Pro.ling \nthis example reports the following initial data: filter p? (rest lst) [ln 7]: 2/500 used -delaying 498 \nunused avoids 2486 subvalues, wgt=2487 meaning the pro.ler proposes delaying only a call to .lter. Intu\u00aditively, \nthe recursive call to rng should be delayed as well, but it does not appear in the results because .lter \nuses the entire list. In response, our pro.ler iteratively: 1. simulates delaying the expression with \nthe highest laziness po\u00adtential, and then 2. recalculates usages to possibly uncover more unused values. \n With this re.nement, the pro.ler reports: ~~~~~~~~~~~~~~ Profiling Summary: Round 0 ~~~~~~~~~~~~~~ \nfilter p? (rest lst) [ln 7]: 2/500 values used -delaying 498 unused avoids 2486 subvalues, wgt=2487 ~~~~~~~~~~~~~~ \nProfiling Summary: Round 1 ~~~~~~~~~~~~~~ rng f (n+1) m [ln 3]: 4/999 values used -delaying 995 unused \navoids 983 subvalues, wgt=2984 f n [ln 3]: 5/999 values used -delaying 994 unused avoids 0 subvalues, \nwgt=1 After round 0, the analysis simulates a delay of the call to .lter and then recomputes all usages, \nrevealing unused values from the call to rng in round 1. This process repeats until there are no more \nunused expressions. The pro.ler then reports that delaying both the calls to .lter and rng would bene.t \nprogram performance. 2.2 A Complete Example This subsection shows how a programmer can use our laziness\u00adpotential \npro.ler to solve the n-queens problem. We compare our result to Chang s [3], who describes the problem \nlike this: The n-queens problem makes an illustrative playground for advertising lazy programming. An \nidiomatic lazy solution to such a puzzle may consist of just two parts: a part that places n queens at \narbitrary positions on an n by n chess board, and a part for deciding whether a particular place\u00adment \nis a solution to the puzzle.  Thus, Chang separates the program into two independent com\u00adponents and \nde.nes one function to compute a solution: def nqueens n = first (.lter isValid all placements) where \nlet all placements = foldl process row [nil] (rng n) def process row r qss so far = foldr (.(qs new qss). \n(map (.c.(r, c):: qs) (rng n)) @ new qss) nil qss so far While all placements generates a stream of all \npossible queen placements, isValid checks whether a placement is valid according to the rules of chess. \nThe solution then composes these functions via .lter and first. As Chang explains, the approach cleanly \nseparates two distinct concerns: all placements ignore[s] the rules of the puzzle, while isValid enforce[s] \nthem. If the components were large, two differ\u00adent programmers could tackle them in parallel. All they \nwould have to agree on is the representation of queen placements, for which we choose a list of board \ncoordinates (r, c). Accordingly, running all placements n yields a list of lists of positions: [[(n,1);(n-1,1); \n... ;(1,1)]; ...; [(n,n);(n-1,n); ... ;(1,n)]] Each line represents one possible placement. In a strict \nlanguage, computing all placements generates all possible placements. Adding laziness preserves the elegant \nsolution and makes it ef.cient because it prevents unnecessary evaluation. The question is which parts \nshould be delayed. As Chang [3] reports, na\u00a8ively switching all lists to lazy lists does not improve \nprogram performance. Chang then presents a static tool to aid programmers with the task of inserting \nadditional laziness. For n\u00adqueens, with lazy lists as the initial source of laziness, the static analysis \nmakes the key suggestion of adding laziness to foldr, which results in a signi.cant speedup. Without \nany such initial hints, our pro.ler suggests laziness at the same place in foldr and also suggests laziness \nin .lter: filter p? (rest lst) [ln 23]: 0/2 values used -delaying 2 unused avoids 5242 subvalues, wgt=5243 \nfoldr f base (rest lst) [ln 40]: 36/85 vals used -delaying 49 unused avoids 1939 subvalues, wgt=1507 \nFigure 1 summarizes the running times for the 8-queens program implemented in Racket [9] and varying \ndegrees of laziness. The .gure reports that the strict version is slow and that adding the suggestions \nfrom Chang s static tool produces roughly a four-fold speedup. However, adding laziness annotations as \nsuggested by our pro.ler produces a program that is roughly twenty times faster than the strict version. \nChang s oversight is due to the seed laziness required by the static analysis. In order for the static \ntool to compute its suggestions, Chang recommends .rst converting lists to lazy lists, as strict programmers \nlooking to add laziness commonly do. It turns out, however, that this inserts too much laziness. As evident \nfrom our pro.ler s recommendations, only .lter needs additional laziness; the other lists should be evaluated \neagerly. Implementation Description Time (ms) no laziness 20245 static tool-based suggestions from [3] \n4874 pro.ler-based suggestions 1057 Figure 1. Running times for an 8-queens program. 3. Laziness Potential, \nthe De.nition As our informal presentation suggests, we consider laziness poten\u00adtial the key to determining \nwhere to insert effective laziness anno\u00adtations in strict programs. This section formally de.nes the \nnotion in two stages, using a small model. 3.1 Partially-labeled .-calculus Our model starts from a \nlabeled version of the untyped .-calculus: tt tt \u00b7t e . Exp = x | v | e e | e | e l v . LabVal = wt w \n. Val = .x.e x . Var, \u00a3 . eLab, \u00a3 . vLab The syntax employs two kinds of labels. Static labels \u00a3 (in \nbold) name a syntactic expression in the source program. Dynamic labels \u00a3 (plain) name a value during \nevaluation, i.e., the result of one runtime execution of an expression with a particular set of bindings \nfor its free variables. De.ne a program to be a closed expression e with only static labels. As the grammar \nindicates, static labels are optional decorations. During evaluation, a statically labeled expression \nmay be paired with a dynamic label at the upper left. Evaluation may also tag values with any number \nof dynamic labels, all positioned at the upper right and denoted with l\u00a3. We use w when we wish to refer \nto a value without labels. A program may evaluate an expression multiple times, e.g. via recursion, so \na statically \u00a3 -labeled expression may be associated with a set of dynamic labels representing the values \nthat this ex\u00adpression produces. Further, we wish to compute usage of these val\u00adues, which requires tracking \nvalue .ow, so values themselves may accumulate multiple \u00a3 labels to enable identi.cation of the value \ns source expression(s). In the example (.x.x) ((.z.z) .y.y), .y.y is the result of evaluating both underlined \nexpressions and thus must have two dynamic labels. Evaluation contexts [7] specify the order of evaluation \nin our labeled .-calculus. They are the standard by-value evaluation con\u00adtexts, plus an additional labeled \ncontext: t E . ECtx = [ ] | E e | v E | t \u00b7tE These contexts dictate that reductions take place within \na labeled expression only if it comes with a static and a dynamic label. The -. reduction relation speci.es \none step of evaluation. It is generated from three basic notions of reduction: \u00dfv and two additional \nreductions that introduce and manipulate value labels: l E[(.x.e)t v] -. E[e{x ::= v}] (\u00dfv) t t t \u00b7t \nt tt E[e] -. E[e], \u00a3 /. E[e] (vstart) tt \u00b7t tlt,lt E[w] -. E[w] (vend) The semantics satis.es a conventional \nwell-de.nedness theorem. Theorem 1 (Well-De.nedness). A program e either reduces to a value v or starts \nan in.nitely long chain of reductions. Proof Sketch. The -. relation satis.es unique decomposition, so \ne is a value or can be partitioned uniquely into an evaluation context and a redex. Using a progress-and-preservation \napproach [7], we can then show that this property is preserved for all reductions. From an extensional \nperspective, the labeled .-calculus reduces programs just like the by-value .-calculus [19]. Theorem \n2 says that the labeled calculus produces the same result, modulo labels, as the unlabeled by-value semantics \ngenerated by \u00dfv. The -.v relation is the by-value standard reduction and -. v is its re.exive, transitive \nclosure. The function . strips labels from programs.  Theorem 2 (Label Non-interference). For any labeled \nprogram e1, if e1 -. e2, then .(e1) -. v .(e2). Proof Sketch. Show, by cases on -., that if e1 -. e2, \nthen either .(e1) -.v .(e2) or .(e1) = .(e2). From an intensional perspective, labels play a critical \nrole. Ex\u00adpressions may be labeled in three different ways and the two label\u00adrelated reductions specify \ntransitions between labelings. Suppose a redex is statically labeled with \u00a3 . Before it is evaluated, \na unique, dynamic label \u00a3 is generated and placed on the upper-left, as indi\u00adcated by the vstart reduction. \nWhen such a labeled subexpression is reduced to a value, a vend reduction shifts the value label from \nthe left-hand side to the right-hand side and discards the static label.  3.2 Labeling a Program The \nlabeled .-calculus does not specify which expressions in a program to label statically. Hence, the calculus \nis applicable in a variety of scenarios, depending on the speci.c labeling strategy. For the purposes \nof .nding candidates for lazy evaluation, we employ a function L that maps unlabeled expressions to expres\u00adsions \nwith labels on arguments that are not already values: L[ x] = x L : Exp . Exp L[ .x.e] = .x.L[ e] L[ \ne1 e2] = L[ e1] Larg[ e2] Larg[ x] = x Larg[ .x.e] = .x.L[ e] Larg[ e1 e2] = t (L[ e1] Larg[ e2]]) \nThe L function labels only applications because delaying values or variables is pointless. Furthermore, \nonly applications in an ar\u00adgument position receive a label. Again, it is not bene.cial to delay applications \nin a usage context because the created suspension is immediately forced. We also do not label function \nbodies. We pre\u00adfer to delay its application to avoid spoiling the proper implemen\u00adtation of tail calls \nfor the execution of annotated programs. 3.3 Usage Contexts To determine whether a particular value \nis used during evaluation, we de.ne usage contexts U: u . uCtx = [ ] e U . UCtx = [ ] | E[u] Intuitively, \na context is a usage context if creating a redex requires a speci.c (kind of) value placed in the hole. \nIn our core calculus, the function position of an application is the only usage context because it requires \na . value. In addition, the top-level context is a usage context and thus a program result is considered \nused.  3.4 Extending the Model By design, our model smoothly generalizes to constructs found in practical \nlanguages. Almost any evaluation-context-based reduc\u00adtion semantics can easily be extended to an appropriate \nlabeled reduction system. The only requirements are to extend the usage contexts and labeling strategy. \nWe extend our model with typical features. Speci.cally, we add constants, let, conditionals, primitive \narithmetic and boolean operations, lists and list operations, and delay and force laziness constructs; \nsee .gures 2 and 3. The reductions are conventional [7]: e = . . . | n | b | let x = e in e | if e then \ne else e | o e e | and e e | or e e | not e | cons e e | first e | rest e | nil | nil? e | delay e | \nforce e o = + | - | * | /, n . N, b = #t | #f w = . . . | n | b | cons v v | nil | delay e E = . . . \n| let x = E in e | if E then e else e | o E e | o v E | and E e | and v E, v = #f | or E e | or #f E \n| not E | cons E e | cons v E | first E | rest E | nil? E | force E Figure 2. Syntax for an extended \nby-value language. E[let x = v in e] -. E[e{x ::= v}] (let) E[if #f then e1 else e2] -. E[e2] (iff ) \nE[if v then e1 else e2] -. E[e1], v (ift) = #f E[o v1 v2] -. E[d v1 v2] (prim) E[or v e] -. E[v], v \n(ort) = #f E[or #f v] -. E[v] (orf ) E[and #f e] -. E[#f] (andf ) E[and v1 v2] -. E[v2], v1 (andt) = \n#f E[not #f] -. E[#t] (notf ) E[not v] -. E[#f], v (nott) = #f E[first (cons v1 v2)] -. E[v1] (fst) E[rest \n(cons v1 v2)] -. E[v2] (rst) E[nil? nil] -. E[#t] (nil) E[nil? v] -. E[#f], v (nil) = nil E[force (delay \ne)] -. E[force e] (frcd) E[force v] -. E[v], v (frcv) = delay e Figure 3. Semantics for an extended by-value \nlanguage. The true and false boolean literals are #t and #f. The seman\u00adtics treats all non-#f values \nas true, as is standard in untyped (and some typed) languages.  The and and or primitives are short-circuiting, \nmeaning that the second argument is only evaluated if necessary. This behavior is re.ected in the evaluation \ncontexts for and and or.  The force form is recursive, speci.ed by the frcd rule, mean\u00ading that applying \na single force to a suspension returns the underlying value no matter how many delays it is wrapped in. \n Untyped force is idempotent, as seen in the frcv rule. Applying force to a non-delayed value returns \nthat value.  Here is the extended set of usage contexts: u = . . . | if [ ] e e | o [ ] e | o v [ ] \n| and [ ] e | and v [ ], v = #f | or [ ] e | or #f [ ] | not [ ] | first [ ] | rest [ ] | nil? [ ] | \nforce [ ]  Finally, we extend our labeling function to mark expressions of in\u00adterest, maintaining the \ngoal of .nding expressions to delay. In ad\u00addition to arguments in a function application, we label the \nbound expression in a let and the arguments to cons. The ellipses tra\u00adverse all other expressions in \na homomorphic manner: L[ e1 e2] = L[ e1] Larg[ e2] L[ let x = e1 in e2] = let x = Larg[ e1] in L[ e2] \n L[ cons e1 e2] = cons Larg[ e1] Larg[ e2] . . . Larg[ x] = x Larg[ v] = L[ v] Larg[ e] = t (L[ e]]), \nif e = x or v  3.5 Calculating Laziness Potential We calculate laziness potential via functions that \nextract informa\u00adtion from the propagation of labels in reduction sequences. Let Red be the set of .nite \nreduction sequences. In the following de.nitions, a comma-separated series of expressions represents \nan element of Red, i.e., a trace. We also use (T e) to denote e s complete trace. The V function takes \na reduction sequence and a static label \u00a3 and returns a set of dynamic labels representing the values \ngener\u00adated by the \u00a3 -labeled expression over the course of reduction: V : Red \u00d7 eLab . P(vLab) V (e) \n\u00a3 = \u00d8 V (E[t e], E[t \u00b7t e], e', . . .) \u00a3 = {\u00a3} . V (e', . . .) \u00a3 ' ' V (e, e, . . .) \u00a3 = V (e, . . .) \n\u00a3 \u00a3, if e = E[t e0] Intuitively, V inspects all vstart steps. In the last example from section 2.1, call \nit program P , if the recursive call to .lter has static label \u00a3 1, then a new dynamic label is created \nevery time t 1 (.lter p? (rest lst)) is a redex and V (T P ) \u00a3 1 = {\u00a31, . . . , \u00a3500}. The Ufunction \ncounts how many times a speci.ed value is used in a given reduction sequence, as dictated by usage contexts: \nU : Red \u00d7 vLab . N t U (w l) \u00a3 = 1, if \u00a3 . l\u00a3 U (e) \u00a3 = 0, if e = v, or e = w tlbut \u00a3 /. \u00a3l t ' ' U (U[w \nl], e , . . .) \u00a3 = 1 + (U (e , . . .) \u00a3), if \u00a3 . \u00a3l ' ' U (e, e, . . .) \u00a3 = U (e, . . .) \u00a3, t if e = \nU[v], or e = U[w l] but \u00a3 /. l\u00a3 An \u00a3-labeled value is unused in (T e) if U (T e) \u00a3 = 0. The unused function \nrelies on U and V to compute (the labels of) all the unused values produced by a particular expression \nin e: unused : Exp \u00d7 eLab . P(vLab) unused (e, \u00a3 ) = {\u00a3 | \u00a3 . V (T e) \u00a3 \u00a3, U (T e) \u00a3 = 0} For sample \nprogram P , if second and third are desugared to firsts and rests, then two created values reach a first \n[ ] or rest [ ] usage context, so for \u00a3i . {\u00a31, . . . , \u00a3500}, U (T P ) \u00a3i = 1 for two values of i and \nis otherwise 0. Thus, unused (P, \u00a3 1) = 2. The Cfunction returns the labels of all the child-values that \nare generated during the creation of a given \u00a3-labeled value: C : Red \u00d7 vLab . P(vLab) C (e) \u00a3 = \u00d8 ' \n' C (E[t \u00b7t e], e, . . .) \u00a3 = C' (e, . . .) \u00a3 ' ' C (e, e, . . .) \u00a3 = C (e, . . .) \u00a3, if e = E[t \u00b7t e0] \nC' : Red \u00d7 vLab . P(vLab) C' (e) \u00a3 = \u00d8 C' t,lt ' (E[w],e,...) \u00a3 = \u00d8 C' u (E[t e], E[t \u00b7te], e', . . .) \n\u00a3 = {\u00a3'} . C' (e', . . .) \u00a3 ' ' C' (e, e, . . .) \u00a3 = C' (e, . . .) \u00a3, if e = E[t e0] When the creation \nof the speci.ed value begins, the Cfunction dis\u00adpatches to C'. When this helper function encounters a \nreduction that creates another value label, it adds it to its results. When eval\u00aduation of the speci.ed \nvalue completes or the reduction sequence ends, the helper function stops collecting labels. The created \nfunction uses C to compute (the labels of) all child-values generated during the creation of all the \nunused values of a given \u00a3 -labeled expression in e: created : Exp \u00d7 eLab . P(vLab)  created (e, \u00a3 ) \n= C (T e) \u00a3 t.unused (e,t ) In our running example, created (P, \u00a3 1) tallies the additional values created \nwhile evaluating each of \u00a31, . . . , \u00a3500, about 2,500. Finally, the LP function computes the laziness \npotential of an \u00a3 -labeled expression in program e. Roughly, the function computes the average number \nof child-values generated during the creation of an unused value of expression \u00a3 , if unused (e, \u00a3 ) \n= \u00d8: LP : Exp \u00d7 eLab . R |(unused (e, \u00a3 )) . (created (e, \u00a3 ))| LP (e, \u00a3 ) = |(unused (e, \u00a3 )) \\ (created \n(e, \u00a3 ))| The function uses unused to compute the (labels of the) unused values created by the speci.ed \n\u00a3 -labeled expression and created to compute the (labels of the) child-values. Together, these two sets \nrepresent the total number of wasted values for which expression \u00a3 is responsible. The numerator of the \ncalculation uses the union of the two sets to avoid double-counting values, for example when expression \n\u00a3 is a recursive call. To compute the desired ratio, LP divides the total value count by the number of \nunused values pro\u00adduced by expression \u00a3 . The denominator of the calculation addi\u00adtionally subtracts \nthose unused values that are child-values of other unused values. This appropriately gives higher weight \nto recursive calls, which matches a programmer s intuition. In the running example, all but one of the \n498 unused values are induced by the .rst recursive call to .lter. Thus the denominator in the laziness \npotential for \u00a3 1 is one and LP (P, \u00a3 1) 2500. The LP function computes the laziness potential of one \npar\u00adticular expression in a program. Delaying the expression with the highest laziness potential should \ngenerate the largest possible ben\u00ade.t but doing so may reveal additional opportunities for laziness. \nHence, we iteratively de.ne the following series of LP functions:  LP0 (e, \u00a3 ) = LP (e, \u00a3 ) LPi+1 (e, \n\u00a3 ) = LPi (Cforce t max [delay emax], \u00a3 ), where e = C[t max emax] and \u00a3 max ' = arg max LPi (e, \u00a3 ) \nt u.e,unused (e,t u) =\u00d8 An LPi+1 function .rst delays the subexpression with (according to LPi) maximal \nlaziness potential and adds appropriate forcing for the used values of that subexpression. It then uses \nLPi on this transformed program to determine the next opportunity for laziness injection. In the de.nition, \n\u00a3 max labels emax, the expression with the most laziness potential, and C is its context. Since some \nvalues produced by emax may still be used, Cforce is C augmented with forces around those usage contexts \nthat require emax s values. Though it is suf.cient to simply force every usage context in C, a .ow analysis \nlike Chang s [3] may compute a more a precise placement of forces. In our running example, assume LP0 \ndetermines that the \u00a3 1 \u00adlabeled .lter expression has the highest laziness potential. Then LP1 .rst delays \n\u00a3 1 and inserts forces at its use points. LP1 then re-runs the augmented program and recomputes laziness \npotential for other expressions. Assume that both arguments to cons in rng also have static labels. As \nmentioned in section 2.1, the LP1 computations would .nd that the call to both rng and f create unused \nvalues but that only the unused values of rng subsequently induce many more values and thus has higher \nlaziness potential. A Non-theorem An astute reader may wonder whether we can re\u00adlate the laziness potential \nof an expression to a formal step-counting cost model. It would show that the suggestions are guaranteed \nto improve a program s performance. Unfortunately, the predictive ca\u00adpability of a step-counting model \ndepends on how laziness is imple\u00admented meaning the desired theorem may hold only for semantic cost models \ntruly close to one speci.c implementation. 4. A Laziness Pro.ler An implementation of a laziness pro.ler \ncannot use the de.nition of LPi as a blueprint because it is highly impractical to re-run a modi.ed program \nfor every i. Instead our pro.ler creates a value dependence graph in an online fashion during a single \nexecution and uses this graph to perform laziness potential calculations. 4.1 Usage Information Gathering \nTable 1 describes the collected information. It also lists the anal\u00adogous mathematical function from \nsection 3.5. The I function in\u00adstruments a labeled .-calculus program to collect this information: I[ \nx] = x I : Exp . Exp I[ .x.e] = .x.I[ e] I[ e1 e2] = U[ I[ e1]]]] A[ I[ e2]]]] I relies on two additional \nfunctions, A and U, to instrument argu\u00adment and usage positions, respectively. We de.ned I only for core \n.-calculus expressions so far but in general the application of A exactly follows the labeling strategy \nfrom the previous section. In other words, a subexpression in a program is only instrumented as an argument \nif it has a static label \u00a3 . In addition, a subexpression is instrumented with U if it resides in a usage \ncontext. Here are A and U, which inject imperative code fragments that perform the required accounting \nduring program execution: Information collected during evaluation Math function ALL-VNUMS : P(vLab) set \nof labels representing all values created during evaluation EXPR-VALS : eLab . P(vLab) V maps an expression \nlabel to a set of value labels representing the values created by that expression during evaluation CHILD-VNUMS \n: vLab . vLab C maps a value label \u00a3 to a value label \u00a3hi such that the set of values created while evaluating \n\u00a3 is the exclusive interval (\u00a3, \u00a3hi); i.e., the \u00a3-rooted subtree in the value-dependency tree USES : \nvLab . N U the number of times a value is used during evaluation USES-BY-VNUM : vLab . vLab . N maps \na value label \u00a3 to another map of value labels to counts, representing the value usage while evaluating \n\u00a3 only; to avoid double-counting uses, a value with label \u00a3used is considered used while evaluating value \n\u00a3 only if \u00a3 is the immediate an\u00adcestor in the program s value-dependency tree; for example, if value \n\u00a3 is created while evaluating another value with label \u00a3parent, then \u00a3used is considered used while evaluating \n\u00a3 but not while evaluating \u00a3parent Table 1. Information collected by the pro.ler. A[ t e] = let \u00a3new \n= next-vnum () in all-vnums .= {\u00a3new} expr-vals[\u00a3 ] .= {\u00a3new} push-ctxt-vnum \u00a3new l let w t = t e in \npop-ctxt-vnum () child-vnums[\u00a3new] = current-vnum () l tnew,t return w U[ e] = let \u00a3ctxt = top-ctxt-vnum \n() in let w tl= e in for \u00a3 . l\u00a3 : uses[\u00a3] += 1 uses-by-vnum[\u00a3ctxt][\u00a3]+= 1 l t return w In these de.nitions, \nlet w tl= e is a pattern-matching notation that means evaluate e, bind the resulting value to w, and \nbind any resulting value labels to the vector l\u00a3. The A and U-instrumented code generates unique dynamic \nlabels from a counter, and it tracks which value is being evaluated via a value stack. The interfaces \nfor the counter and the stack are described in table 2. counter current-vnum next-vnum returns the current \ncount returns then increments current count stack push-ctxt-vnum pop-ctxt-vnum top-ctxt-vnum adds a value \nlabel to the top of the stack removes top label from the context stack returns top label but does not \npop it Table 2. Auxiliary functions for instrumenting functions.  4.2 Post-Execution Analysis Before \nwe show the loop that computes LPi, we introduce func\u00adtions that use the collected information from table \n1:  unused \u00a3 = {\u00a3 | \u00a3 . EXPR-VALS[\u00a3 ], \u00a3 . ALL-VNUMS, USES[\u00a3] = 0} createdv \u00a3 = {\u00a3sub | \u00a3 < \u00a3sub < \nCHILD-VNUMS[\u00a3], \u00a3sub . ALL-VNUMS}  created \u00a3 = createdv \u00a3 t.unused t |(unused \u00a3 ) . (created \u00a3 )| LP \n\u00a3 = |(unused \u00a3 ) \\ (created \u00a3 )| For program e, the main processing loop then looks like this:  while \n( unused \u00a3 ) = \u00d8 : t .e \u00a3 = arg max (LP \u00a3 ' ) t u.e,unused t u=\u00d8 for \u00a3 . (unused \u00a3 ) : erase \u00a3 record-result \n\u00a3 The loop performs another iteration as long as some expression in the program has an unused value. \nIf all values are used, i.e., the program cannot bene.t from laziness, then the pro.ler does not report \nany suggestions. At the start of each iteration, the analysis selects an expression with the currently \ngreatest laziness potential, identi.ed with label \u00a3 above. The analysis then simulates delaying this \nexpression by erasing its unused values via erase: erase \u00a3 = sub-uses-by-vnum \u00a3 ALL-VNUMS \\= {\u00a3} for \n\u00a3sub . (createdv \u00a3) : erase \u00a3sub sub-uses-by-vnum \u00a3 = for (\u00a3used, n) . USES-BY-VNUM[\u00a3] : USES[\u00a3used] \n-= n The erase function erases a value by (1) subtracting its usage of values from the total usage counts; \n(2) marking the value as erased by removing it from ALL-VNUMS, so it is not considered in subsequent \ncalculations; and (3) recursively erasing all child-values that were created while evaluating the parameter \nvalue. Finally, at the end of each iteration, the analysis records the de\u00adlayed expression via record-result, \nso it can present a summary to the programmer after the calculations terminate. The main loop always \nterminates since each iteration of the loop erases at least one unused value. Theorem 3. The pro.ler \nimplements the labeled .-calculus model. Proof Sketch. The interesting part is showing that our post-execu\u00adtion \nanalysis implements the functions from section 3.5. Speci.\u00adcally, the ith iteration of the main loop \nin this section corresponds to the LPi function. In an iteration, both the model and implemen\u00adtation \n.rst compute the expression with highest laziness potential. The implementation then erases information \npertaining to this expression and loops, while the math model inserts delays and forces and re-runs the \nprogram. Thus the correctness of the imple\u00admentation hinges on a correspondence between the erase function \nand the delay and force transformation in LPi. Delaying an expression and then forcing the needed thunks \neliminates: (1) the unused values produced by that expression, (2) the usages incurred while producing \nthose unused values, and (3) all child-values of those unneeded values and their usages. Similarly, \nan iteration of the main loop in the implementation calls erase to eliminate: (1) all unused values of \nthe highest potential expression by removing them from ALL-VNUMS, the set of all  values produced during \nexecution, (2) subtracts the usages incurred by those unused values, as recorded in USES-BY-VNUM, from \nthe total usage counts in USES, and (3) recursively calls erase for each (remaining) child-value, as \nrecorded in CHILD-VNUMS. Note that the theorem does not hold once side-effects as simple as exception \nhandling are added to the language, although our empirical evidence suggests that this is not an issue \nin practice.  4.3 Implementation We have implemented a prototype of the pro.ler described in this section \nfor most of the Racket language [9]. The pro.ler supports all the language constructs from section 3.4, \nas well as several other frequently used Racket forms such as pattern matching (match), named records \n(struct), sequence iterations and comprehensions (for), additional binding forms (define, let*, etc.), \nmuch of the object system, and a large part of the syntax system. We use Racket s syntax system to modify \nthe compiler so that it imple\u00adments I[ \u00b7] , U[ \u00b7] , and A[ \u00b7] . Using this compiler API greatly sim\u00adpli.es \nthe implementation of our pro.ler. A Note on Performance Preliminary measurements indicate roughly a \ntwo to three order-of-magnitude slowdown when pro\u00ad.ling certain degenerate programs. This kind of slowdown \nis not unreasonable for high-level pro.lers because programmers are ex\u00adpected to test their code with \nsmall representative inputs. Programs requiring laziness are especially suited for this style of testing \nbe\u00adcause they generate lots of excess unused data, but so long as the ratio of unused to used data remains \nthe same, it does not matter to the pro.ler whether the absolute amount of data is large or small. 5. \nEvaluation To demonstrate the usefulness of the laziness potential metric, we present the results of \npro.ling a range of real-world examples known to bene.t from laziness: some of Okasaki s purely func\u00adtional \ndata structures, monadic parser combinators, and AI game players. We show that in most cases, the pro.ler \nreproduces the knowledge of experts. Secondarily, when our results differ from the experts, we turn to \nwall-clock measurements to further evaluate our pro.ler s output. General Pro.ling Issues In general, \npro.lers produce meaning\u00adful results only when given representative programs. For exam\u00adple, it is impossible \nto demonstrate the effectiveness of a mem\u00adory pro.ler using programs without memory leaks. Similarly, \nwe wish to demonstrate our pro.ler s effectiveness at inserting lazi\u00adness into strict programs for performance \nreasons; thus we choose well-known uses of laziness rather than arbitrary programs and use inputs designed \nto force our test applications to rely on laziness. Our experiments proceeded as follows: 1. we implemented \none of the expert examples as a strict program; 2. we then pro.led this strict version in a representative \ncontext; 3. and .nally, we re-inserted delays according to the pro.ler s suggestions. We inserted appropriate \nforces by hand, but one could in principle derive the positions automatically [3].  We conducted all \nexperiments in Racket, an untyped language. We ported all implementations verbatim as we found them, \nexcept for a few type-related discrepancies. Okasaki points out [17, page 35] that laziness in a typed \nlanguage occasionally requires extra annotations to make the types work out . For example, typed languages \nmust delay an empty stream tail, while in an untyped language, this annotation is unneeded since the \nempty stream is a value. In general, laziness in typed languages requires a pairing of delays and forces, \nwhile untyped languages are more .exible due to the recursive and idempotent nature of untyped force. \n Data Structure Description Result Basic Data Structures banker s queue canonical two-list functional \nqueue with streams P@ banker s deque like the banker s queue, but allows inserting and deleting from \nboth ends P@ binomial heap stores ordered elements in a series of increasingly sized trees, analogous \nto the representation of binary numbers; supports constant amortized time insert and log worse-case merge, \ndelete min, and min operations =@ pairing heap stores ordered elements as a tree where each node consists \nof a heap element and a list of subheaps; supports constant worst-case time insert, merge, and min operations, \nand log amortized time delete min operation =@ Insightful Data Structures physicist s queue canonical \ntwo-list functional queue with a stream front list, an eager front list cache, and a delayed rear list \n*@ real-time queue converted banker s queue with an incrementally reversed rear list, with the goal of \nachieving worst case, rather than amortized, bounds =@ real-time deque double-ended version of real-time \nqueue =@ bootstrapped queue improves on banker s queue by eliminating redundancy in append operation. \n=@ catenable list lists that support constant amortized time append =@ implicit queue achieves constant \namortized operations via implicit recursive slowdown P@ implicit deque double-ended version of implicit \nqueue P@ Other Functional Data Structures .nger tree Hinze and Paterson s general purpose data structure \n(related to implicit queues) P@ @ = pro.ler-assisted implementation outperforms Okasaki s implementation \n= P @ = pro.ler suggests the same lazy annotations as Okasaki s implementation * @ = mixed results \nTable 3. Comparison of Okasaki s lazy data structures with analogous pro.ler-generated data structures. \n5.1 Purely Functional Data Structures Okasaki s purely functional data structures make up a well-known \nlibrary of algorithms that bene.t from some degree of laziness in the data representation. At the same \ntime, these data structures do not assume that the underlying language is lazy. Hence they are a nearly \nideal test bed for checking the usefulness of our pro.ler. The appropriateness of our comparisons depends \non the design of a particular data structure. We therefore classify Okasaki s lazy data structures into \ntwo categories: 1. The .rst kind of lazy data structure is derived from an existing strict data structure. \nOkasaki added laziness to improve perfor\u00admance without making any other changes. 2. The second kind \nof data structure is either designed with lazi\u00adness in mind or is converted from an existing strict data \nstruc\u00adture with changes more signi.cant than simply adding laziness.  The .rst kind of data structure, \ndubbed basic, is ideal for evaluating our pro.ler because a straightforward comparison of the laziness \nannotations is appropriate. For the second kind of data structure, which we refer to as insightful, the \nlaziness is possibly integral to its design and removing the laziness may not yield a realistic strict \ndata structure. Hence, any results concerning insightful structures may be less general than basic ones, \nbut enlightening nonetheless. Table 3 describes several data structures of each kind and presents the \nresults of our comparisons. For most examples, our pro.ler suggests laziness identical to Okasaki s version. \nIn some cases, however, our pro.ler suggests what appears to be a better use of laziness, and we present \nthese latter cases in detail. Banker s Queue Our pro.ler-assisted banker s queue and deque implementations \nimprove on Okasaki s versions. To help readers understand the differences and how they come about, we \npresent the queue experiment in more detail. def enq x (Q f lenf r lenr ) = chk f lenf (x:: r) (lenr \n+1) def chk f lenf r lenr = if lenr = lenf then Q f lenf r lenr else Q (f ++ rev r) (lenf + lenr ) nil \n0 rotation def hd (Q nil ) = error | hd (Q (x:: f) lenf r lenr ) = x def tl (Q nil ) = error | tl (Q \n(x::f ) lenf r lenr ) = chk f (lenf -1) r lenr def (++) nil lst = lst | (++) (x :: xs) lst = x:: (xs \n++ lst) def rev lst = rev/acc lst nil def rev/acc nil acc = acc | rev/acc (x::xs) acc = rev/acc xs (x::acc) \nFigure 4. Functional queue implementation without laziness. The canonical functional queue is implemented \nwith two eager lists, a rear list onto which elements are added to the queue, and a front list from which \nelements are removed. A record data de.nition, (Q front lenf rear lenr ), represents these queues where \nQ is the constructor and front , lenf , rear , and lenr are .eld names. The front and rear lists are \nfront and rear , respectively, and lenf and lenr are the number of elements in each list. Figure 4 presents \nthis strict queue implementation in pseu\u00addocode. Function de.nitions in the .gure use a pattern-matching \nsyntax to decompose lists and queues, where is the wildcard pat\u00adtern. The enq function adds an element \nto a queue, hd returns the  def enq x (Q f lenf r lenr ) = chk f lenf $(x :: r) (lenr +1) def chk f \nlenf r lenr = if lenr = lenf then Q f lenf r lenr else Q (f ++ rev r) (lenf + lenr ) nil 0 def hd (Q \n$nil ) = error | hd (Q $(x :: f) lenf r lenr ) = x def tl (Q $nil ) = error | tl (Q $(x::f) lenf r lenr \n) = chk f (lenf -1) r lenr def (++) $nil lst = lst | (++) $(x ::xs) lst = $(x :: (xs ++ lst)) def rev \nlst = $(rev/acc lst nil) def rev/acc $nil acc = acc | rev/acc $(x::xs) acc = rev/acc xs $(x:: acc) Figure \n5. Okasaki s lazy banker s queue. frontmost element without removing it, and tl removes the front element \nand returns the remaining elements as a new queue. The .gure also includes in.x list append, ++, and \nlist reverse, rev . When elements are added to rear or removed from front , a queue maintains the invariant \nthat the size of front must be equal to or greater than the size of rear . When rear is larger than front \n, a rotation is performed (.gure 4 box), i.e., rear is reversed and appended to the end of front , and \nrear is reset to empty. The chk function checks the queue invariant and performs rotations as needed. \nThough reversing a list takes time proportional to the size of the list, for any given set of inserted \nelements, the list containing those elements is only reversed once. Thus a functional queue supports \nconstant amortized time enq, hd, and tl operations. Rotations are expensive but since the rotated elements \nare added to the end of front and are not needed immediately, laziness might improve the strict queue \nimplementation. Also the constant amor\u00adtized time bounds of the strict queue do not hold when the queue \nis used persistently. To illustrate this problem, consider a queue with enough elements such that calling \ntl triggers a rotation. Calling tl repeatedly on this pre-rotated queue triggers a rotation each time. \nWhile the cost of the .rst rotation is amortized over all the ele\u00adments, the subsequent rotations require \nmore than constant amor\u00adtized time because the savings are already spent by the .rst one. To address \nthese issues, Okasaki adds laziness to the strict queue implementation. The new queue, dubbed the banker \ns queue,3 re\u00adplaces the eager lists with lazy streams and is shown in .gure 5. We adopt Okasaki s syntax \nfor laziness, where $ pre.xing an ex\u00adpression delays that expression, while $ in a pattern means to force \nthe argument before trying to match the pattern. Since the banker s queue merely adds laziness to the \nstrict queue, it falls into the basic kind of lazy data structure described earlier. To see what laziness \nannotations our pro.ler suggests, we need a representative benchmark that uses the strict queue: def \nbuild&#38;sum size tosum = sum (build size) tosum def build n = buildq 0 n def buildq n n = Q nil 0 nil \n0 | buildq m n = enq m (buildq (m+1) n) def sum q n = sumq q 0 n def sumq q n n = 0 | sumq q m n = (hd \nq) + (sumq (tl q) (m+1) n) 3 Okasaki uses the banker s method to determine the queue s complexity. def \nenq x (Q f lenf r lenr ) = chk f lenf (x::r) (lenr +1) 1 def chk f lenf rlenr = if lenr = lenf then Q \nf lenf r lenr else Q (f ++ $(rev r) ) (lenf + lenr ) nil 0 2 def hd (Q $nil ) = error | hd (Q $(x:: f) \nlenf r lenr ) = x def tl (Q $nil ) = error | tl (Q $(x::f ) lenf r lenr ) = chk f (lenf -1) r lenr def \n(++) $nil lst = lst | (++) $(x :: xs) lst = x:: $(xs ++ lst) 3 def rev lst = rev/acc lst nil 1 def rev/acc \nnil acc = acc | rev/acc (x ::xs) acc = rev/acc xs (x::acc) 1 Figure 6. Pro.ler-assisted version of lazy \nbanker s queue. The build function builds a queue of the speci.ed size while sum adds up the speci.ed \nnumber of elements from the front of the given queue. The build&#38;sum function combines build and sum. \nOur representative benchmark should bene.t from laziness if we sum only the .rst few elements of the \nqueue, leaving most of the queue unused. Hence, pro.ling this benchmark should re\u00adveal the places where \nit is pro.table to insert laziness annotations. Speci.cally, pro.ling build&#38;sum 1024 50 produces \nthe following laziness suggestions: rev r [ln 5]: 8/10 values used -delaying 2 unused avoids 3848 subvalues, \nwgt=2564 xs ++ lst [ln 13]: 645/1013 values used -delaying 368 unused avoids 2204 subvalues, wgt=1870 \nFigure 6 shows a lazy queue that implements these suggestions. Our pro.ler-assisted lazy queue has fewer \nand different laziness annotations than Okasaki s. Speci.cally, the pro.ler does not rec\u00adommend inserting \nlaziness in enq and rev (boxes 1), leaving rear as an eager list.4 This is justi.ed because rev is monolithic, \ni.e., it always traverses its entire argument regardless of whether it is an eager list or a lazy stream. \nInstead, our pro.ler suggests a single delay around the call to rev in chk (box 2). The pro.ler also \ndiffers in its suggestion to delay the tail of the list returned by append (box 3) while Okasaki delays \nthe entire list. Since the .rst list element is already a value, this difference is trivial. Since our \npro.ler recommends uses of laziness different from Okasaki, we further compare the queue implementations \nwith em\u00adpirical experiments. We timed several calls to build&#38;sum, varying the number of elements \nsummed. For each run, we used a .xed queue of size 220: 20 20 for i . [0, 2] : time (build&#38;sum 2i) \n(BU I L D &#38;S UM) The graph in .gure 7 shows that using an eager rear list in the pro.ler-assisted \nlazy queue improves performance over Okasaki s queue, which has to build a suspension for each element. \nA problem is that the BU ILD&#38;S U M benchmark does not test per\u00adsistence, because the queue is used \nin a single-threaded manner. To expose persistence-related issues, a representative benchmark must 4 \nOkasaki observes in a footnote that the rear list could be left as an eager list but, because of his \npreference of theoretical simplicity over practical optimizations, he presents the version in .gure 5. \n  Figure 7. Summing elements of a banker s queue (lower is better). implementation test name subtest \ntime (ms) strict strict time1 250 strict strict time2 250 Okasaki PE R S I S T:L A Z Y time1 828 Okasaki \nPE R S I S T:L A Z Y time2 0 pro.ler-assisted PE R S I S T:L A Z Y time1 94 pro.ler-assisted PE R S I \nS T:L A Z Y time2 0 Table 4. Testing persistence with rotations in the banker s queue. construct a queue \nsuch that a tl operation on the queue triggers the rotations suggested by the spikes in the graph of \n.gure 7. For the lazy queues, the rotation operation is delayed, so we must re\u00admove a suf.cient number \nof elements before the rotation is forced. Speci.cally, we build a queue of size 2n - 1, right after \na delayed rotation is appended to the end of front , and then remove 2n-1 -1 elements from the queue. \nRemoving the next element of the queue forces the rotation. This benchmark uses a drop function, which \nre\u00admoves some number of elements from a list. We again use n = 20 in the persistence benchmark: 20 19 \nlet q = drop (build (2-1)) (2-1) (P E R S I S T:L AZ Y) in time1 = time (tl q); time2 = time (tl q) Table \n4 presents timings for the persistence benchmarks. For ref\u00aderence, we additionally include times for \na strict queue, which re\u00adquires the same time on each access because it repeats the rotation each time. \nIn contrast, the lazy queue times verify that both im\u00adplementations offer truly constant amortized operations, \nwith the pro.ler-assisted queue outperforming Okasaki s queue. Though our laziness potential model does \nnot explicitly account for the memoization that enables constant amortized operations for persistently \nused queues, our pro.ler is still able to suggest lazi\u00adness annotations that satisfy the desired behavior, \nwhich is a pleas\u00adant surprise. This suggests that reasoning with laziness potential possibly suf.ces \nto account for both the delaying and the memo\u00adization bene.ts of laziness, which makes intuitive sense \nbecause programmers typically do not use laziness for memoization only. This observation warrants further \ninvestigation in future work. Physicist s Queue Okasaki s physicist s queue differs from the banker s \nqueue in three ways. First, it employs a plain list for the rear list instead of a stream. Second, the \nfront list is a delayed plain list instead of a stream. Third, the content of the front list is cached \ninto a separate plain list before a rotation, speeding up hd accesses. Thus the physicist s queue requires \nan extra .eld in def enq x (Qp f ' f lenf r lenr ) = chk f ' f lenf (x :: r) (lenr+1) def chk f ' f lenf \nr lenr = if lenr = lenf then chkw f ' f lenf r lenr else let f '' = force f '' '' in chkw f $(f ++ rev \nr) (lenf + lenr ) nil 0 def chkw nil f lenf r lenr = (Qp (force f) f lenf r lenr ) | chkw f ' f lenf \nr lenr = (Qp f ' f lenf r lenr ) def hd (Qp nil ) = error | hd (Qp (x :: f ' ) f lenf r lenr ) = x def \ntl (Qp nil ) = error | tl (Qp (x:: f ' ) f lenf r lenr ) = chkw f ' $(rest (force f)) (lenf -1) r lenr \ndef (++) nil lst = lst | (++) (x:: xs) lst = x:: (xs ++ lst) def rev lst = rev/acc lst nil def rev/acc \nnil acc = acc | rev/acc (x ::xs) acc = rev/acc xs (x ::acc) Figure 8. Okasaki s lazy physicists s queue. \ndef enq x (Qp f ' f lenf r lenr ) = chk f ' f lenf (x :: r) (lenr+1) def chk f ' f lenf r lenr = if lenr \n= lenf then chkw f ' f lenf r lenr else chkw f (f ++ $(rev r)) (lenf + lenr ) nil 0 def chkw nil f lenf \nr lenr = (Qp f f lenf r lenr ) | chkw f ' f lenf r lenr = (Qp f ' f lenf r lenr ) def hd (Qp $nil ) = \nerror | hd (Qp $(x ::f ' ) f lenf r lenr ) = x def tl (Qp $nil ) = error | tl (Qp $(x :: f ' ) $(y ::f) \nlenf r lenr ) = chkw f ' f (lenf -1) r lenr def (++) $nil lst = lst | (++) $(x :: xs) lst = x:: $(xs \n++ lst) def rev lst = rev/acc lst nil def rev/acc nil acc = acc | rev/acc (x ::xs) acc = rev/acc xs (x \n::acc) Figure 9. Pro.ler-assisted lazy physicists s queue. its data de.nition: (Qp front cache front \nlenf rear lenr ). Figure 8 shows the implementation for Okasaki s physicist s queue. Deriving the physicist \ns queue from the strict queue (in .gure 4) involves more than just adding lazy annotations, so it belongs \nin the insightful category of data structure. Nevertheless, we follow the previously described steps \nto develop the alternative implementa\u00adtion in .gure 9. It turns out that laziness potential cannot replicate \nOkasaki s caching strategy, and the pro.ler suggests turning front and front cache into duplicate lazy \nstreams. The other pro.ler sug\u00adgestions are identical to the pro.led banker s queue: the rear list remains \nan eager list and is delayed with a single delay in chk.  Figure 10 shows physicist s queue timings \nfor the BUI L D &#38;S U M benchmark. With its caching, Okasaki s physicist s queue is faster than the \npro.ler-assisted implementation, until half the queue is used. After that point, the bene.ts of caching \nin the Okasaki s queue are nulli.ed because the entire front list must be forced anyways. Also, forcing \nthis last part of front takes much longer due to all the extra suspensions created by tl, which manifests \nas a large spike in the graph. Essentially, our pro.ler-assisted queue forces a little of front with \neach tl call, while Okasaki s version delays all the forcings until the second half of the queue is consumed. \nDeciding which queue implementation is better depends on the expected use cases. Implicit Queues Implicit \nqueue and deque data structures pose challenging obstacles for both designers and pro.lers. Hinze and \nPaterson s .nger trees [10] are a related data structure and pose the same problems. This section presents \ndetails concerning queues; the cases for deques and .nger trees are similar; see table 3. Implicit queues \nrely on implicit recursive slowdown [17, Ch. 11], a technique inspired by functional representations \nof Peano numerals. Thus implicit queues are also an insightful kind of data structure. Like explicit \nqueues, implicit queues offer constant amor\u00adtized time hd, tl, and enq operations. Essentially, the queue \nmain\u00adtains some front elements and some rear elements in two digit structures, with the remaining elements \nresiding in a delayed mid\u00addle queue. Here are the record de.nitions for implicit queues. A digit is a \n(Zero ) or (One x) or (Two x y) A queue is a (Shallow digit ) or (Deep digit f midQ digit r) A digit \nis either a Zero , One, or Two structure and an implicit queue itself is represented with either a Shallow \nor a Deep struc\u00adture. A Shallow queue is comprised of a single digit while a Deep queue has two digits \nplus a delayed middle queue of element pairs. Figure 11 presents enq, tl, and hd for implicit queues. \nThe enq function shows the progression of a queue s internal state as more elements are added, with the \ndigits transitioning from Zero to Two, and the queue itself from Shallow to Deep . These transitions \nare reversed in tl. Finally, the hd function returns the front element by destructuring a queue in a \nstraightforward manner. While the design of this data structure leverages laziness to support constant \namortized operations, it also magni.es the over\u00adhead of laziness because every operation must destructure \nnot only the queue, but many .elds of the queue as well. These numerous destructuring operations result \nin a high rate of suspension cre\u00adation and forcing. In fact, pro.ling the BU I L D &#38;S UM benchmark \nonly .nds expressions with low laziness potential, even for queues where most or all of the elements \nare unused, suggesting that the def enq (Shallow (Zero )) x = Shallow (One x) | enq (Shallow (One x)) \ny = Deep (Two x y) nil (Zero) | enq (Deep f m (Zero )) x = Deep f m (One x) | enq (Deep f m (One x)) \ny = Deep f $(enq (force m) (x, y)) (Zero) def hd (Shallow (Zero)) = error | hd (Shallow (One x)) = x \n| hd (Deep (One x) m r) = x | hd (Deep (Two x y) m r) = x def tl (Shallow (Zero )) = error | tl (Shallow \n(One x)) = Shallow (Zero ) | tl (Deep (One x) $(Shallow (Zero)) r) = Shallow r | tl (Deep (One x) $m \nr) = let (y, z) = hd m in Deep (Two y z) $(tl m) r | tl (Deep (Two x y) m r) = Deep (One y) m r Figure \n12. Summing elements of a implicit queue (lower is better). data structure should not use any laziness. \nThis makes intuitive sense since each operation effectively uses the entire queue. To investigate this \ndiscrepancy, .gure 12 presents BU I L D &#38;SUM timing information for a strict queue compared to Okasaki \ns queue. The chart shows that the high rate of suspension creation and forcing negates any bene.ts that \nlaziness might provide, no matter how much of the queue is used. Obviously, the laziness overhead is \nimplementation dependent. We implemented suspensions with a lambda and a mutable box. Although direct \ncompiler support for suspensions would likely improve performance of the lazy queue and decrease the \ngap, the discrepancy is large enough that an implementer should consider omitting laziness. While BU \nILD&#38;S U M does not use the queue persistently, the worst-case expensive operation for implicit queues \nis only log\u00adarithmic in the size of the queue (as opposed to the linear rotations of the banker s queue). \nThus, even when we tested the queues with persistent-usage benchmarks, the strict version still outperformed \nthe lazy one. In conclusion, this experiment further supports omit\u00adting laziness from an implicit queue \nimplementation even if it may spoil its theoretical properties.  5.2 Monadic Parser Combinators Our \nsecond suite of benchmarks concerns Parsec [13], a monadic parser combinator library. Leijen and Meijer \npoint to one spot in the monadic bind operator where laziness is key, calling it essential for ef.cient \nbehavior. Since the library is a higher-order program, we instantiated it for .ve different scenarios \nto apply our pro.ler: a CSV parser, a URL query parser, a JSON parser, and an HTTP request parser.5 In \nevery case, the pro.ler suggested adding laziness at the exact spot identi.ed by the Parsec paper.  \n 5.3 Manipulating Game Trees Our .nal benchmark is an AI game algorithm from Land of Lisp [2], which \nintroduces programmers to functional Lisp via a series of games. One of these games, Dice of Doom, is \na turn-based strategy game similar to Risk. After several chapters, a diligent stu\u00addent is rewarded with \na full-.edged game, complete with graphical interface and AI players. An AI player generates a game tree \nof all possible moves to help it determine the next move and utilizes lazi\u00adness to manage the tree. Without \nlaziness, the AI player analyzes only a small version of the game. Utilizing laziness, however, the AI \nplayer scales to a realistic-size game. The game implementation (some 1,500 lines of code) consti\u00adtutes \na broad-spectrum benchmark for our pro.ler, not only be\u00adcause it requires laziness, but also because \nit uses many additional language features such as mutable state, list comprehensions, and GUI libraries. \nOur pro.ler is able to instrument the game and col\u00adlects data as the game is played, returning suggestions \nwhen the game concludes. It suggests enough laziness so that playing the full game is possible but with \nfewer annotations than the Land of Lisp version. 6. Related Work Strictness Analysis A concept related \nto use is the denotational notion of strictness [4, 16], which is de.ned via .: a function f is strict \nif f . = .. In a lazy language, a strict function s argument does not need to be delayed. In the strict \nworld, however, there is no analogous .-like value that extensionally indicates when to delay an expression. \nWe must instead consider intensional value .ows, which is precisely what use captures. Low-Utility Data \nStructures Xu et al. [22] present a tool that uses an object cost-bene.t analysis to help programmers \n.nd inef.\u00adcient parts of Java programs. While they analyze imperative, object\u00adoriented programs instead \nof functional ones, they have goals sim\u00adilar to ours. However, a key difference lies in their somewhat \nindi\u00adrect approach. Their goal is to .nd problematic spots in the program source, but they compute costs \nat the level of memory accesses and bytecode instructions, thus requiring an extra .nal step to inter\u00adpret \nthe results in terms of the source. It is not clear how the paper achieves this last step, which becomes \neven more complicated for a higher-order language. Our approach computes laziness potential directly \nin terms of a high-level semantics, from which the problem spots in a program become apparent. 7. Conclusion \nand Future Work We introduce the notion of laziness potential, a metric that pre\u00addicts which program \nexpressions bene.t from lazy evaluation. Our Racket pro.ler implements these calculations and guides \nprogram\u00admers with the insertion of laziness annotations. An evaluation of our pro.ler automatically replicates, \nand in some cases improves on, the laziness in a range of real-world applications, demonstrat\u00ading the \npotential usefulness of our approach. Though we presented laziness potential for a by-value .\u00adcalculus \nand implemented our pro.ler for a matching language, the idea should be applicable to any language that \nsupports both strict and lazy evaluation. Speci.cally, our insights may transfer 5 We followed Real World \nHaskell [18] for guidance. to a lazy language with strictness annotations, such as Haskell. While the \nmaturity of Haskell s strictness analysis already assists programmers with the task of eliminating unnecessary \nlaziness, the approach is intrinsically limited by its static, approximate nature. Hence, books for real-world \nprogrammers [18] suggest the inser\u00adtion of strictness annotations to help the compiler. We conjecture \nthat a dynamic pro.ler, based on the notion of laziness potential, would assist these programmers with \nthe dif.cult task of locating appropriate positions for these annotations. Acknowledgments We thank Greg \nMorrisett for initial inspiration, Asumu Takikawa and J. Ian Johnson for reading drafts, and the reviewers \nfor their suggestions. This work has been partly supported by NSF Infras\u00adtructure grant CI-ADDO-EN 0855140. \nReferences [1] H. Abelson, G. J. Sussman, and J. Sussman. Structure and Interpreta\u00adtion of Computer Programs. \nMIT Press, 1984. [2] C. Barski. Land of Lisp. No Starch Press, 2011. [3] S. Chang. Laziness by need. \nIn Proc. 22nd ESOP, pages 81 100, 2013. [4] C. Clack and S. L. Peyton Jones. Strictness analysis a practical \napproach. In Proc. 2nd FPCA, pages 35 49, 1985. [5] R. Ennals and S. Peyton Jones. Optimistic evaluation: \nan adaptive evaluation strategy for non-strict programs. In Proc. 8th ICFP, pages 287 298, 2003. [6] \nK.-F. Fax\u00b4en. Cheap eagerness: speculative evaluation in a lazy func\u00adtional language. In Proc. 5th ICFP, \npages 150 161, 2000. [7] M. Felleisen, R. B. Findler, and M. Flatt. Semantics Engineering with PLT Redex. \nMIT Press, 2009. [8] R. B. Findler, S. Guo, and A. Rogers. Lazy contract checking for immutable data \nstructures. In Proc. 19th IFL, pages 111 128, 2007. [9] M. Flatt and PLT. Reference: Racket. Technical \nReport PLT-TR-2013\u00ad1, PLT Inc., 2013. http://racket-lang.org/tr1/. [10] R. Hinze and R. Paterson. Finger \ntrees: a simple general-purpose data structure. In J. Funct. Program., pages 197 217, 2006. [11] P. Hudak, \nJ. Hughes, S. P. Jones, and P. Wadler. A history of Haskell: being lazy with class. In Proc. 3rd HOPL, \npages 12 1 12 55, 2007. [12] J. Hughes. Why functional programming matters. Comp. J., 32:98 107, 1989. \n[13] D. Leijen and E. Meijer. Parsec: direct style monadic parser combina\u00adtors for the real world. TR \nUU-CS-2001-35, Utrecht University, 2001. [14] J.-W. Maessen. Eager Haskell: resource-bounded execution \nyields ef.cient iteration. In Proc. Haskell Workshop, pages 38 50, 2002. [15] F. Morandat, B. Hill, L. \nOsvald, and J. Vitek. Evaluating the design of the R language. In Proc. 26th ECOOP, pages 104 131, 2012. \n[16] A. Mycroft. Abstract interpretation and optimising transformations for applicative programs. PhD \nthesis, University of Edinburgh, 1981. [17] C. Okasaki. Purely Functional Data Structures. Cambridge \nUniversity Press, 1998. [18] B. O Sullivan, D. Stewart, and J. Goerzen. Real World Haskell. O Reilly \nMedia, 2008. [19] G. D. Plotkin. Call-by-name, call-by-value and the .-calculus. Theor. Comput. Sci., \n1:125 159, 1975. [20] K. E. Schauser and S. C. Goldstein. How much non-strictness do lenient programs \nrequire? In Proc. 7th FPCA, pages 216 225, 1995. [21] P. Wadler. How to replace failure by a list of \nsuccesses. In Proc. 2nd FPCA, pages 113 128, 1985. [22] G. Xu, N. Mitchell, M. Arnold, A. Rountev, E. \nSchonberg, and G. Se\u00advitsky. Finding low-utility data structures. In Proc. 31st PLDI, pages 174 186, \n2010.   \n\t\t\t", "proc_id": "2535838", "abstract": "<p>While many programmers appreciate the benefits of lazy programming at an abstract level, determining which parts of a concrete program to evaluate lazily poses a significant challenge for most of them. Over the past thirty years, experts have published numerous papers on the problem, but developing this level of expertise requires a significant amount of experience.</p> <p>We present a profiling-based technique that captures and automates this expertise for the insertion of laziness annotations into strict programs. To make this idea precise, we show how to equip a formal semantics with a metric that measures waste in an evaluation. Then we explain how to implement this metric as a dynamic profiling tool that suggests where to insert laziness into a program. Finally, we present evidence that our profiler's suggestions either match or improve on an expert's use of laziness in a range of real-world applications.</p>", "authors": [{"name": "Stephen Chang", "author_profile_id": "81488650526", "affiliation": "Northeastern University, Boston, MA, USA", "person_id": "P4383843", "email_address": "stchang@ccs.neu.edu", "orcid_id": ""}, {"name": "Matthias Felleisen", "author_profile_id": "81100323458", "affiliation": "Northeastern University, Boston, MA, USA", "person_id": "P4383844", "email_address": "matthias@ccs.neu.edu", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535887", "year": "2014", "article_id": "2535887", "conference": "POPL", "title": "Profiling for laziness", "url": "http://dl.acm.org/citation.cfm?id=2535887"}