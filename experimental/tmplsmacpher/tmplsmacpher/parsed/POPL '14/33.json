{"article_publication_date": "01-08-2014", "fulltext": "\n A Sound and Complete Abstraction for Reasoning about Parallel Pre.x Sums * Nathan Chong Alastair F. \nDonaldson Jeroen Ketema Imperial College London {nyc04,afd,jketema}@imperial.ac.uk Abstract Pre.x sums \nare key building blocks in the implementation of many concurrent software applications, and recently \nmuch work has gone into ef.ciently implementing pre.x sums to run on massively par\u00adallel graphics processing \nunits (GPUs). Because they lie at the heart of many GPU-accelerated applications, the correctness of \npre.x sum implementations is of prime importance. We introduce a novel abstraction, the interval of summations, \nthat allows scalable reasoning about implementations of pre.x sums. We present this abstraction as a \nmonoid, and prove a sound\u00adness and completeness result showing that a generic sequential pre\u00ad.x sum implementation \nis correct for an array of length n if and only if it computes the correct result for a speci.c test \ncase when instantiated with the interval of summations monoid. This allows correctness to be established \nby running a single test where the in\u00adput and result require O(n lg(n)) space. This improves upon an \nex\u00adisting result by Sheeran where the input requires O(n lg(n)) space and the result O(n 2 lg(n)) space, \nand is more feasible for large n than a method by Voigtl\u00a8ander that uses O(n) space for the input and \nresult but requires running O(n 2) tests. We then extend our abstrac\u00adtion and results to the context \nof data-parallel programs, developing an automated veri.cation method for GPU implementations of pre\u00ad.x \nsums. Our method uses static veri.cation to prove that a generic pre.x sum implementation is data race-free, \nafter which functional correctness of the implementation can be determined by running a single test case \nunder the interval of summations abstraction. We present an experimental evaluation using four different \npre.x sum algorithms, showing that our method is highly auto\u00admatic, scales to large thread counts, and \nsigni.cantly outperforms Voigtl\u00a8ander s method when applied to large arrays. Categories and Subject Descriptors \nF.3.1 [Logics and Meanings of Programs]: Specifying, Verifying &#38; Reasoning about Programs Keywords \nParallel pre.x sum computation; GPUs; abstraction; formal veri.cation. * This work was supported by the \nEU FP7 STREP project CARP (project number 287767), the EPSRC PSL project (EP/I006761/1), and an EPSRC \nFirst Grant (EP/K011499/1). Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nCopyrights for components of this work owned by others than ACM must be honored. Abstracting with credit \nis permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. Request permissions from permissions@acm.org. POPL 14, January \n22 24, 2014, San Diego, CA, USA. Copyright &#38;#169; 2014 ACM 978-1-4503-2544-8/14/01. . . $15.00. http://dx.doi.org/10.1145/2535838.2535882 \n1. Introduction The pre.x sum operation, which given an array A computes an array B consisting of all \nsums of pre.xes of A, is an important building block in many high performance computing applications. \nA key example is stream compaction: suppose a group of n threads has calculated a number of data items \nin parallel, each thread t (1 = t = n) having computed dt items; now the threads must write the resulting \nitems to a shared array out in a compact manner, i.e. thread t should write its items to a series of \ndt indices of out starting from position d1 + \u00b7 \u00b7 \u00b7 + dt-1. Compacting the data stream by serialising \nthe threads, so that thread 1 writes its results, followed by thread 2, etc., would be slow. Instead, \ncompaction can be performed in parallel via a pre.x sum. Each thread t writes its count dt to an array \ncount at position t, then the threads perform an exclusive parallel pre.x sum (de.ned formally in Section \n2) on count to yield an array index. The pre.x sum sets the elements of index to [0, d1, d1 +d2, . . \n. , d1 +\u00b7 \u00b7 \u00b7+dn-1], so that a thread t can write its results to out compactly starting from position \nindex[t]. Stream compaction is just one example; the pre.x sum opera\u00adtion is de.ned for any binary associative \noperator, and pre.x sums using various operators have found wide application in computa\u00adtionally intensive \ntasks. A selection of examples are summarised in Table 1. For several decades the design of ef.cient \nparallel pre\u00ad.x sums has been an active research area. Parallel pre.x sums were .rst implemented in hardware \ncircuits as logic for propagat\u00ading carry bits in adders [34]. The design space for these circuits has \nbeen explored and important circuits known in the literature are due to Kogge and Stone [21], Ladner \nand Fischer [22], and Brent and Kung [5]. More recent work by Sheeran [33] has further explored the design \nspace. In software, pre.x sum algorithms have been used in the context of evaluating polynomials in parallel \n[36] and Blel\u00adloch [3] has proposed the use of pre.x sums as a primitive parallel operation, giving numerous \nexamples of their application [4]. Pre\u00ad.x sums are now primitives in parallel programming models such \nas MPI [29] and OpenMP [35]. Recently there has been a great deal of interest in implementing ef.cient \npre.x sums for acceleration on massively parallel graphics processing units (GPUs) [2, 7, 12, 16, 26, \n31], implemented using GPU programming models such as OpenCL [19] and CUDA [27]. The major benchmark \nsuites for general-purpose GPU program\u00adming, SHOC [12], Rodinia [7] and Parboil [37] all include a variety \nof pre.x sum implementations. The thrust1 and CUDA Data Par\u00adallel Primitives (cudpp)2 libraries implement \nef.cient pre.x sum primitives for NVIDIA GPUs. We present a method for formally verifying that a generic \npar\u00adallel pre.x sum implementation designed to work for any data 1 http://code.google.com/p/thrust/ 2 \nhttp://code.google.com/p/cudpp/  Pre.x sum application Data-type Operator Stream compaction [2, 16] \nInt + Sorting algorithms [16, 30] Int + Polynomial interpolation [13] Float *a Line-of-sight calculation \n[4] Int max Binary addition [22] pairs-of-bits carry operator Finite state machine simulation [22] transition \nfunctions function composition a Floating point multiplication is not actually associative, but is often \ntreated as such in applications where some error can be tolerated. Table 1. Some applications of parallel \npre.x sums. Stream com\u00adpaction requires an exclusive pre.x sum; the other applications em\u00adploy regular \npre.x sums. The carry operator and functional compo\u00adsition are examples of non-commutative operators. \ntype with an associative operator is functionally correct. Because pre.x sum implementations are at the \nheart of many parallel ap\u00adplications, the correctness of these implementations is vital. The challenges \nof concurrent programming make it especially hard to correctly implement pre.x sums for modern architectures \nsuch as GPUs. This motivates a dedicated veri.cation method. By observing that a generic pre.x sum algorithm \nmay only exploit the property of associativity, we have devised a novel ab\u00adstraction which we call the \ninterval of summations abstraction. For i = j, the interval of summations abstraction represents a contigu\u00adous \nsummation interval of input elements in[i] . \u00b7 \u00b7 \u00b7 . in[j] (with respect to any data type and associative \noperator .) abstractly as a pair (i, j). Abstract summation intervals can be added together if they kiss \n: the abstract sum of (i, j ) and (k, l) is (i, l) if j + 1 = k; otherwise, the addition results in a \nspecial value T which represents all sums of input elements that are not necessarily contiguous. Sum\u00adming \nany monoid element to T yields T, modelling the fact that, using only the property of associativity, \na non-contiguous summa\u00adtion of inputs cannot be made contiguous by adding more inputs. We present the \ninterval of summations abstraction as a monoid, with an identity element representing an empty summation. \nThis makes it possible to run a generic pre.x sum implementation with respect to the data type and operator \nde.ned by the interval of sum\u00admations monoid. Our .rst main contribution is a theorem showing that a \nse\u00adquential generic pre.x sum on n elements is correct for all data types and operators if and only if, \nwhen instantiated using the in\u00adterval of summations monoid and applied to the input sequence [(0, 0), \n(1, 1), . . . , (n - 1, n - 1)], it computes the correct result sequence: [(0, 0), (0, 1), . . . , (0, \nn - 1)]. This theorem shows that the interval of summations abstraction is sound and complete: by running \na single test we can establish either that the generic pre\u00ad.x sum is correct (if the test passes), or \nthat it is incorrect for one speci.c data-type/operator pair, namely that of the interval of sum\u00admations \nmonoid itself (if the test fails). Our result provides a highly scalable method for verifying sequential \npre.x sums: elements of the interval of summations monoid capable of representing inter\u00advals of up to \nlength n can be encoded using O(lg(n)) bits, allow\u00ading a generic pre.x sum to be veri.ed by running a \nsingle test case requiring O(n lg(n)) space for both the input and result. This is an improvement on \na previous result by Sheeran [33, 38] which allows a sequential program implementing a pre.x sum to be \nveri.ed by running one test case requiring O(n lg(n)) space for the input and O(n 2 lg(n)) space for \nthe result. For large values of n, this space requirement becomes infeasible. Our method is also more \npracti\u00adcally feasible than an alternative approach of Voigtl\u00a8ander [38] that uses only O(n) space for \nthe input and result but requires running O(n 2) tests. void prefixSum(const T *in, T *out) {out[0] = \nin[0]; for(unsigned i = 1; i < n; i++) out[i] = out[i-1] . in[i]; } Figure 1. A sequential pre.x sum \nfor inputs of length n Our second main contribution is an extension of our method and theoretical results \nto the case of barrier-synchronising data-parallel programs, the programming model of GPU kernels. This \nis a con\u00adtribution over previous work on the correctness of parallel pre.x sums [33, 38] which applies \nto synchronous parallel hardware de\u00adscribed as sequential HA S K E L L programs, but not to asynchronous \nconcurrent programs. We show that if a data-parallel program im\u00adplementing a generic pre.x sum can be \nproved free from data races then correctness of the pre.x sum can be established by running a single \ntest case using the interval of summations monoid, as in the sequential case. We use this result to design \nand implement a highly automatic method for verifying parallel pre.x sum imple\u00admentations at the level \nof GPU kernel source code, using the GPU-Verify tool [1] to prove data race-freedom. We present a large \nexperimental evaluation using four different pre.x sum algorithms implemented as OpenCL kernels. We show \nthat race-freedom of these kernels can be proven ef.ciently for all power-of-two element sizes up to \n231, and that verifying the kernels by running a single test is very fast: using two NVIDIA GPUs, two \nIntel CPUs (for which OpenCL is also supported), and an ARM GPU, pre.x sums on vectors of up to length \n106 can be checked in a matter of seconds. We argue that, once race-freedom has been established, the \nmethod of Voigtl\u00a8 ander [38] can also be used to prove correctness of pre.x sum implementations using \ntesting, but show that our method dramatically outperforms Voigtl \u00a8 ander s approach, which requires \nrunning O(n 2) tests. Because we can ef.ciently prove data race-freedom of GPU kernels implementing pre.x \nsums for all conceivably useful sizes, and because veri.cation using our method involves running a single \ntest case, taking no longer than using the pre.x sum in practice, we claim that we have made a major \nstep towards solving the problem of verifying GPU implementations of generic pre.x sums. 2. Background \non Pre.x Sums We brie.y review the de.nitions of a pre.x sum and an exclusive pre.x sum, and give examples \nof sequential and parallel pre.x sum implementations. Given a set S with an associative binary operation \n. (i.e., a semigroup), the pre.x sum of a list [s1, s2, . . . , sn] of elements of Sis the list: [s1, \ns1 . s2, . . . , s1 . s2 . \u00b7 \u00b7 \u00b7 . sn] consisting of all sums of pre.xes, in increasing order of length. \nFor example, if we consider the set of integers under addition, the pre.x sum of [1, 3, 5, 7] is [1, \n4, 9, 16]. If (S, .) has an identity element 1, so that (S, .) is a monoid, then the exclusive pre.x \nsum of [s1, s2, . . . , sn] is de.ned as: [1, s1, s1 . s2, . . . , s1 . s2 . \u00b7 \u00b7 \u00b7 . sn-1] . For example, \nif S is the set of all four-bit binary numbers and . is the bitwise-or operator with identity 0000 then \nthe exclusive pre.x sum of [0001, 0010, 0100, 1000] is [0000, 0001, 0011, 0111]. It is trivial to implement \na sequential pre.x sum: the C-like program of Figure 1 computes the pre.x sum of in into out,  kernel \nvoid koggeStone(const local T *in, local T *out) {out[tid] = in[tid]; barrier(); for (unsigned offset \n= 1; offset < n; offset *= 2) { T temp; if (tid = offset) temp = out[tid-offset]; barrier(); if (tid \n= offset) out[tid] = temp . out[tid]; barrier(); }} Figure 2. Kogge-Stone pre.x sum implemented in OpenCL \n Figure 3. Evolution of the output array for the Kogge-Stone kernel of Figure 2 with n = 8 for an example \ninput where T is some data type with associative binary operator .. An exclusive pre.x sum can be implemented \nsimilarly.3 Figure 2 shows the Kogge-Stone parallel pre.x sum imple\u00admented in OpenCL and designed to \nbe executed by a single work\u00adgroup of n threads.4 The koggeStone function is marked kernel to indicate \nthat it is the entry point for a GPU kernel, and arrays in and out have the local quali.er to indicate \nthat they are allocated in GPU memory local to the work-group. Threads execute asyn\u00adchronously, and a \nthread can use tid to access its unique thread identi.er, in the range {0, . . . , n -1}. Threads synchronise \nby call\u00ading barrier(), which causes all threads to wait until every thread reaches the barrier statement. \nOn each iteration of the loop, ev\u00adery thread whose tid is greater than or equal to offset sums the value \nit has already computed with the value previously computed by the thread offset places to the left. Figure \n3 illustrates how the output array evolves when the kernel is instantiated using integer addition and \napplied to the input [1, 1, 1, 1, 1, 1, 1, 1], with n = 8. 3. Sequential Computational Model We present \na sequential imperative programming language, and de.ne what it means to implement a correct pre.x sum \nin this language. This provides a simple foundation on which to clearly introduce our interval of summations \nabstraction, which we do in Section 4. We extend our language, abstraction and theoretical results to \napply to data-parallel programs (and in particular GPU kernels) in Section 5. Syntax and typing The syntax \nfor our language is shown in Fig\u00adure 4, where c ranges over literal values, v and A over scalar and ar\u00adray \nvariable names, respectively, and op over an unspeci.ed set of binary operators. Our presentation can \nbe easily extended to cater for operators of other arities. 3 For ease of presentation, we assume throughout \nthat the input length n is hard-coded into the program under consideration. In practice, n would be supplied \nas a parameter. 4 For readability, we deviate a little from the precise syntax of OpenCL. expr e ::= \nc literal | v variable | A[e] array element | e1 op e2 operator stmt s ::= v := e variable assignment \n| A[e1] := e2 array element assignment | if (e) {ss1} else {ss2} conditional | while (e) {ss} loop stmts \nss ::= e empty sequence | s; ss sequence Figure 4. Syntax All variables, arrays and literals are typed \n(assuming some stan\u00addard syntax for variable and type declarations, which we omit). Types for scalar \nvariables and literals are drawn from a set of base types T , ranged over by T , which includes at least \nintegers and Booleans (denoted Int and Bool respectively) equipped with the usual literals and operators \nand the single-element type Unit. Ar\u00adray variables have type Array(T ) which denotes all maps of type \nInt . T . For ease of presentation we assume no out-of-bounds errors occur and we do not allow arrays \nof arrays. The language also omits features such as pointers, procedures and unstructured control .ow. \nIn Section 6 we argue that our technique extends to languages with these features. The typing rules of \nthe language are straightforward and are depicted in Figure 5. As usual there is a context G which speci.es \nthe types of variables. Operational semantics Let Var be a set of variables and Arr a set of arrays all \nof which are assumed to be typed. A variable store sv is a mapping .. Var . T T .T such that if v . Var \nis of type T , then sv(v) is of type T . An array store sA is a mapping .. Arr . Array(T ) T .T such \nthat if A is of type Array(T ), then sA(A) is of type Array(T ). Expressions are evaluated under a variable \nstore and an array store. Denoting the evaluation of an expression e by [e]sv , we sA de.ne: [c]sv = \nc [A[e]]sv = sA(A)([e]sv ) sA sA sA [v]sv = sv(v) [e1 op e2]sv = [e1]sv op [e2]sv sA sA sA sA Figure \n6 gives the operational semantics for our language. The semantics is de.ned over program states S = (sv, \nsA, ss) with sv a variable store, sA an array store and ss a sequence of statements. In the .gure, ss1 \n\u00b7 ss2 denotes the concatenation of sequences of statements ss1 and ss2. The rules are standard for an \nimperative language like ours, except that we have both a variable and an array store instead of just \na single store. Although this split is not strictly needed here, it eases the extension to data-parallel \nprograms in Section 5 where we shall regard variables as thread-local and arrays as shared among all \nthreads. Let a program P be a sequence of statements. An initial state of P is any program state with \nP as the sequence of statements. Given an initial state S0 of P , an execution of a program P is a .nite \nor in.nite sequence: S0 .s S1 \u00b7 \u00b7 \u00b7 .s Si .s Si+1 .s \u00b7 \u00b7 \u00b7 with each Si (i = 0) a program state. An execution \nis maximal if it (a) cannot be extended by applying one of the rules from the  c of type T G f c : T \n( T-L I T E R A L ) v : T . G G f v : T ( T-VA R I A B L E ) A : Array(T ) . G G f e : Int G f A[e] : \nT (T-AR R AY ) op of type T1 \u00d7 T2 . T3 G f e1 : T1 G f e1 op e2 : T3 G f e2 : T2 (T-OP) (a) Typing rules \nfor expressions v : T . G G f e : T A : Array(T ) . G G f e1 : Int G f e2 : T (T-A S S I G N ) (T-A \nR R AY-AS S I G N ) G f v := e : Unit A[e1] := e2 : Unit G f e : Bool G f ss1 : Unit G f ss2 : Unit G \nf e : Bool G f ss : Unit ( T-IT E ) (T-LO O P ) G f if (e) {ss1} else {ss2} : Unit G f while (e) {ss} \n: Unit G f s : Unit G f ss : Unit ( T-E M P T Y ) (T-S E Q ) G f e : Unit G f s; ss : Unit (b) Typing \nrules for statements Figure 5. Typing rules of our sequential programming language s = sv[v . [e]sv ] \nsv = n A = sA(A)[n . [e2]sv ] s = sA[A . A ] v sA [e1]sA sA A ( S-A S S I G N ) ( S-A R R AY )  (sv, \nsA, v := e; ss ) .s (s, sA, ss ) ) .s (sv, s ) (sv, sA, A[e1] := e2; ssA, ss[e]sv \u00ac[e]sv v sA sA (S-IT \nE -T) ( S -I T E -F ) (sv, sA, if (e) {ss1} else {ss2}; ss) .s (sv, sA, ss1 \u00b7 ss ) (sv, sA, if (e) {ss1} \nelse {ss2}; ss) .s (sv, sA, ss2 \u00b7 ss ) sv [e]sv \u00ac[e] sA sA (S -LO O P -T) (S -LO O P -F) ) (sv, sA, \nwhile (e) {ss}; ss ) .s (sv, sA, ss \u00b7 while (e) {ss}; ss) (sv, sA, while (e) {ss}; ss ) .s (sv, sA, ss \nFigure 6. Operational semantics of our sequential programming language operational semantics or (b) is \nin.nite. We say P terminates for an initial state S, if all maximal executions starting from S are .nite. \nNote that the maximal execution is unique in the current case as execution is deterministic; this will \nno longer be so in the data-parallel case of Section 5. The proof that our type system and operational \nsemantics satisfy the usual safety property that types are preserved under execution and progress can \nalways be made unless termination has occurred [28, Section 8.3] is standard. Pre.x sum algorithms We \nnow de.ne what it means for a pro\u00adgram in our language to implement a pre.x sum algorithm. Recall from \nSection 2 that a pre.x sum can be de.ned with respect to a semigroup, and an exclusive pre.x sum with \nrespect to a monoid. Because most pre.x sums of interest in practice are over monoids we shall henceforth \nconsider pre.x sums over monoids. All the results we present restrict easily to the case of semigroups. \nWe shall write M to refer to a monoid with elements SM . T , binary operator .M (which we assume is a \nprogramming language operator) and identity 1M . SM . Moreover, we say that a variable v, respectively \nan array A, is read-only in P if no assignment of the form v := . . . , respectively A[e] := . . . , \noccurs in P . De.nition 3.1. Let M be a monoid, P be a program, n a natural number, and in, out arrays \nof type Array(SM ) such that in is read-only in P . The program P computes an M-pre.x sum of length n \nfrom in to out for an initial state S if P terminates for S and for each .nal array store sA it holds \nthat sA(out)(k) = S sA(in)(i) (0 = k < n). M, 0=i=k The program P implements an M-pre.x sum of length \nn from in to out if P computes an M-pre.x sum of length n from in to out for every initial state. Whether \na program computes a pre.x sum for a given input can be established by running the program; determining \nwhether a pro\u00adgram implements a pre.x sum amounts to functional veri.cation. Implementation of an exclusive \npre.x sum is de.ned analogously. Designating the array in as read-only is for ease of presentation, making \nit suf.cient to consider only the .nal array store in the above de.nition and avoiding the need to relate \n.nal and initial array stores. We observe that De.nition 3.1 quanti.es over all possible .nal array stores \nto be able to cover the data-parallel case of Section 5. In the current sequential case the .nal array \nstore is unique as execution is deterministic. Henceforth we shall assume that a pre.x sum is always \nfrom in to out, and shall simply talk about a program implementing an M\u00adpre.x sum of length n, or computing \nan M-pre.x sum of length n from an initial state. 4. The Interval of Summations Abstraction We now turn \nour attention to proving the correctness of generic pre.x sums: pre.x sums that are designed to be polymorphic, \nso that they work for any type and operator that together have the properties of a monoid. We present \nour main theoretical result, that correctness of a generic pre.x sum of length n can be established by \nshowing that the pre.x sum is correct for one particular monoid, the interval of summations monoid, for \none particular input. Generic pre.x sums Let us extend our programming language with a fresh generic \ntype SX , a new operator .X : SX \u00d7SX . SX , and a distinguished literal value 1X of type SX . We intend \nthis generic type to represent an arbitrary monoid X = (SX , .X ) with identity 1X .  We call a program \nthat makes use of SX a generic program. Akin to a generic method in JAVA, a template method in C++, or \na function with a type class context in HASKELL, a generic program cannot be directly executed: it must \n.rst be instantiated with respect to a speci.c type. De.nition 4.1. Let P be a generic program and M \na monoid. We write P [M] to denote the program that is identical to P except that every occurrence of \nSX , .X , 1X is replaced by SM , .M , 1M , respectively. We refer to the process of obtaining P [M] from \nP as a monoid substitution. If M already occurs in P then we cannot tell, from P [M] alone, which uses \nof M were already present in P or originated from uses of X. We handle this issue as follows, to simplify \nour formal treatment: if M occurs in P then we choose a monoid M isomorphic to M such that M does not \noccur in P , and we de.ne P [M] to be P [M ]. For ease of presentation we still refer to the monoid M \nas M . It is easy to see that monoid substitution is well-de.ned, and that if the abstract program P \nis well-typed according to the rules of Figure 5 then applying a monoid substitution to P leads to a \nwell-typed program. De.nition 4.2 (Generic pre.x sums). Let P be a generic program. Then P implements \na generic pre.x sum of length n if in and out are of type Array(SX ) and, for every monoid M, P [M] imple\u00adments \nan M-pre.x sum of length n. The interval of summations monoid The key insight behind our result is the \nobservation that a generic pre.x sum can only rely on the properties of a monoid: associativity and the \nexistence of an identity element. Relying on any additional properties speci.c to a particular operator, \nsuch as commutativity, idempotence or distributivity with respect to some other operator, would render \nthe pre.x sum inapplicable in general. Suppose we wish to compute a pre.x sum of length n from array \nin into array out, with respect to an arbitrary monoid M. Thus in and out have type Array(SM ), and the \npre.x sum operator is .M . If the pre.x sum is correctly implemented then at the end of the computation \neach element of out must be the sum of a contiguous sequence of elements of in. For example, out[0] should \nbe equal to in[0] and out[3] to in[0] .M in[1] .M in[2] .M in[3]. As computation progresses, these contiguous \nsummations are built up using the .M operator, initially starting with individual elements of in. Consider, \nfor any 0 = k < n, how out[k] could be computed (to give the main intuition in a simple manner we ignore \npossible uses of the identity element): either (a) the existing value of a variable or array element \ncould be copied into out[k] or (b) out[k] could be derived by summing two values of SM , c and d, say, \nusing .M . In the latter case c and d are summations of contiguous elements of in: c = S S in[j] and \nd = in[j], for some i1 M, 0=j=i1 M, i2=j=k and i2 (where an empty summation is de.ned to be 1M ), and \nthe summations c and d must kiss : we must have i1 + 1 = i2. If c and d did not have these forms then, \nusing only the laws of associativity and identity, it would not be possible to rewrite c .M d S into \nthe form in[j], the required value for out[k]. By M,0=j=k a similar argument, if c (similarly d) is in \nturn constructed by summing two values e and f then e and f must both be contiguous summations of elements \nof in that kiss, otherwise it would not be possible, using just the monoid laws, to rearrange e .M f \ninto the form of c. Continuing this argument we can see that a correct generic pre.x sum must compute \nits result by successively summing partial sums of contiguous input elements that kiss; if a non-contiguous \nsum is ever constructed then this sum cannot contribute to the .nal pre.x sum result. We introduce a \nmonoid, the interval of summations monoid, which captures abstractly the notion of contiguous summation \nin\u00adtervals, and the operation of summing pairs of kissing intervals. De.nition 4.3. The interval of summations \nmonoid I (henceforth referred to as the interval monoid) has the elements SI = {(i1, i2) . Int \u00d7 Int \n| i1 = i2} . {1I , T} and a binary operator .I de.ned by: 1I .I x = x .I 1I = x for all x . SI T .I x \n= x .I T = for all x . SI T (i1, i4) if i2 + 1 = i3 (i1, i2) .I (i3, i4) = T otherwise It is easily \nchecked that I de.nes a monoid with identity 1I . The interval monoid abstractly describes summations \nof ele\u00adments of in with respect to an arbitrary monoid, say, M. A pair S (i1, i2) abstractly describes \nthe summation in[i]. M, i1=i=i2 The identity 1I represents an empty interval of summations, thus is an \nabstraction of 1M . Finally, the element T represents all non\u00adempty summations of elements in with respect \nto .M that are not known to correspond to contiguous summations. The .I operator precisely captures the \neffect of summing two contiguous summations. For i1 = i2 < i3, S S in[i] .M in[i] M, i1=i=i2 M, i2+1=i=i3 \nS = in[i] M, i1=i=i3 and, correspondingly, (i1, i2) .I (i2 + 1, i3) = (i1, i3). The way .I treats 1I \nexpresses the fact that adding an empty summation to either side of a summation interval has no effect. \nFinally, the treat\u00adment of T by the operator captures the argument above: using only the properties of \na monoid, it is not possible to transform a non\u00adcontiguous summation into a contiguous one by applying \nthe .M operator. Notice that T is an absorbing element, or annihilating el\u00adement, of I: once a summation \nhas become non-contiguous there can be no return. Super.cially, it may appear that the interval monoid \nis similar to the abstract domain of intervals that is commonly used in abstract interpretation [11]. \nThe domains are in fact very different: an ele\u00adment (i, j) of our interval of summations domain represents \na sin\u00adgle concrete value that can be expressed as a summation, whereas an element [i, j] of the traditional \ndomain of intervals represents the set of values {i, i + 1, . . . , j}. We now de.ne a condition on initial \nprogram stores which, for a given natural number n, ensures that the .rst n elements of in are abstracted \nin the interval monoid by appropriate singleton sum\u00admation intervals, and that all other array elements \nand variables of type SI have values that are not known to be summation intervals. De.nition 4.4 (Singleton \ncondition for sequential programs). Let P be a generic program with in of type Array(SX ). An initial \nstate of P [I] with variable store sv and array store sA satis.es the singleton condition for n if 1. \nfor all v of type SX in P , sv(v) = T; 2. for all A of type Array(SX ) in P and k . Int,  T (k, k) \nif A = in and k . {0, . . . , n - 1} sA(A)(k) = T otherwise We can now state our main theorem which shows \nthat, with respect to generic pre.x sums, the interval monoid is a sound and complete abstraction: a \nprogram implements a generic pre.x sum if and only if it implements a pre.x sum when instantiated with \nthe interval monoid. In fact, our result is stronger than this: it shows that correctness of a generic \npre.x sum can be established by considering the interval monoid instantiation only for those initial \nstores that satisfy the singleton condition.  Theorem 4.5 (Soundness and completeness). Let P be a generic \nprogram and n a natural number. Then: P [I] computes an I-pre.x sum of length n for every initial state \nsatisfying the singleton condition for n .. P implements a generic pre.x sum of length n. Given a generic \nprogram P , the main proof idea is to simulate the execution of P [M] for any monoid M by P [I], and \nvice versa, whilst relating the states encountered in the executions. To this end, we .rst de.ne a rei.cation \nfunction. Rei.cation Let M be a monoid and let ArrayStore denote the type of array stores. De.ne ReifyM \n: SI \u00d7ArrayStore . P (SM ): S ReifyM ((i1, i2), sA) = { sA(in)(i)} M, i1=i=i2 ReifyM (1I , sA) = {1M \n} ReifyM (T, sA) = SM Thus ReifyM maps a contiguous summation represented ab\u00adstractly in the interval \nmonoid to the set containing the correspond\u00ading concrete summation in the monoid M, and maps an unknown \nsummation, represented by T in the interval monoid, to the full set of elements of M. Let P be a generic \nprogram and for a monoid M let StateP [M] denote the set of all program states of P [M]. We lift ReifyM \nto map states of P [I] to sets of states of P [M]. Formally, ReifyM : StateP [I] . P (StateP [M]) is \nde.ned by (sv, sA, ss ) . ReifyM (sv, sA, ss) if and only if for all v of type T in P sv(v) = sv(v) if \nT= SX sv(v) . ReifyM (sv(v), sA) if T = SX for all A of type Array(T ) in P and k . Int sA(A)(k) = sA(A)(k) \nif T= SX sA(A)(k) . ReifyM (sA(A)(k), sA) if T = SX there exists a generic program Q such that ss = Q[I] \nand ss = Q[M]. Observe that the generic program Q in the .nal condition is unique even if I or M is used \nin P , due to the discussion following De.nition 4.1. Simulation We can now prove our simulation result. \nLemma 4.6. Let P be a generic program and M a monoid. If SI is a program state of P [I] and SM . ReifyM \n(SI ) is a program state of P [M], then if SI .s SI , there exists a program state SM . ReifyM (SI ) \nof P [M] such that SM .s SM , and  if SM .s SM , there exists a program state SI of P [I] such that \nSI .s SI and SM . ReifyM (SI ).  Proof. Let SI be a program state of P [I] and SM . ReifyM (SI ) be \na program state of P [M ]. Moreover, let Q be the generic pro\u00adgram such that Q[I] and Q[M] are the program \ncomponents of SI and SM , respectively. Observe that monoid substitution (De.nition 4.1) satis.es the \nfollowing algebraic laws for any monoid M: (v := e)[M] = v := (e[M ]) (A[e1] := e2)[M] = A[e1] := (e2[M]) \n(if (e) {ss1} else {ss2})[M] = if (e) {ss1[M]} else {ss2[M]} (while (e) {ss})[M] = while (e) {ss[M]} \ne[M] = e (s; ss)[M] = s[M]; ss[M] where it is immediate by the typing rules and the de.nition of generic \nprograms that neither .X nor 1X can occur in either the expression e1 of A[e1] := e2 or the expression \ne of a conditional or loop. For the same reason, it follows that if the .rst statement in Q is a loop \nor conditional with guard e, then e will evaluate identically in both SI and SM . Thus, whatever the \nform of Q, the same rule from the operational semantics applies in both SI and SM . Let the resulting \nprogram states after application of the rule be SI and SM . By the algebraic laws it is now immediate \nthat there exists a unique generic program Q such that Q [I] is the sequence of statements of SI and \nQ [M] is the sequence of statements of SM . It remains to show that the conditions on the stores of SI \nand SM are satis.ed. If the applied rule was one of S-ITE-T, S-ITE -F, S-LOOP -T, S-LO OP-F, this is \nimmediate, as the stores are identical before and after the steps. For S-ASS I G N there are two cases \nto consider. If v is not of type SX in Q, it is immediate by the typing rules and the genericity of Q \nthat e evaluates identically in both SI and SM . If v is of type SX in Q, it follows by the typing rules \nand associativity of .X that e is an expression of the form x0 .X \u00b7 \u00b7 \u00b7 .X xk where for all xi with 0 \n= i = k either (a) the identity element 1X , (b) a variable or (c) an array element. For each xi = A[e \n], the expression e evaluates identically in both SI and SM by the typing rules and genericity of Q. \nThe result is now immediate by the de.nition of .I and the fact that (a) for each xi = 1X we have 1M \n. ReifyM (1I , sA), (b) for each variable v among xi we have by assumption that sv(v) . ReifyM (sv(v), \nsA(in)), and (c) for each A[e ] among s xi we have sA(A)([e ] v ) . ReifyM (sA(A)([e ]sv ), sA(in)), \ns sA A where (sv, sA) are the stores of SI and (sv, sA) those of SM . For S-AR R AY observe that e1 evaluates \nidentically in both SI and SM by the typing rules and genericity of Q. Hence, the same array element \nis updated in each application of the rule. There are now two cases to consider, i.e., A is or is not \nof type Array(SX ) in Q. These cases are identical to those of S-ASSI G N. Lemma 4.7. Let P be a generic \nprogram, M a monoid, and n a natural number. If SM is an initial state of P [M], then there exists an \ninitial state SI of P [I] satisfying the singleton condition for n such that SM . ReifyM (SI ) and if \nSI .s * SI , there exists a program state SM . ReifyM (SI ) of P [M] such that SM .s * SM , and  if \nSM . * s SM , there exists a program state SI of P [I] such that SI . * s SI and SM . ReifyM (SI ). \n Proof. Let SM be an initial state of P [M]. The lemma is immediate by induction on the number of steps \napplying Lemma 4.6 once we show that an initial state SI of P [I] exists that satis.es the singleton \ncondition for n such that SM . ReifyM (SI ). To this end, write SM as (sv, sA, P [M]) and de.ne SI as \n(sv, sA, P [I]) with for all v of type T in P T sv(v) if T= SX sv(v) = T if T = SX  for all A of type \nArray(T ) in P and k . Int possibly multiple) load and store instructions between which other threads \ncould interleave. Even if we re.ned the semantics to re.ect sA(A)(k) = (k, k) if A = in and k . {0, \n..., n - 1} this, we would still need to account for the weak memory models T if A = in and k /. {0, \n..., n - 1} of modern architectures. However, if a program is free from data = SX . .. . . .. races, \nwhich we de.ne formally below, the effects of this assump\u00ad if A = in and T T tion are not visible. The \nveri.cation technique for GPU implemen\u00ad sA(A)(k) otherwise tations of parallel pre.x sums, which we present \nin Section 6, de- That SI satis.es the singleton condition for n and that we have SM . ReifyM (SI ) is \nnow immediate. Proof (Theorem 4.5). The .-direction is trivial, as I is a monoid. For the .-direction, \nlet M be a monoid and SM an initial state of P [M]. By Lemma 4.7 there exists an initial state SI of \nP [I] such that SI satis.es the singleton condition and SM . Reify(SI ). All executions starting from \nSI are terminating because P [I] im\u00adplements an I-pre.x sum. By Lemma 4.7, for every terminat\u00ading execution \n(and thus every execution) SI . * s SI there ex\u00adists a corresponding terminating execution SM . * s SM \nsuch that SM . ReifyM (SI ). Moreover, these are the only executions of SM : if there would exist a non-terminating \nor another termi\u00adnating execution starting from SM , then the induction argument from Lemma 4.7 would \nyield an additional execution starting from pends on proving that a GPU kernel is free from data races. \nOur rules for barrier synchronisation follow the MPI program\u00adming model [14] in which it is valid for \nparallel processes to syn\u00adchronise at syntactically distinct barriers. In GPU programming models, such \nas OpenCL and CUDA the rules for barrier synchro\u00adnisation are stricter, requiring that all threads synchronise \nat the same barrier, and that if a barrier is inside a loop all threads must have executed the same number \nof loop iterations on reaching the barrier [19, 27]; precise semantics for barrier synchronisation in \nGPU kernels have been formally speci.ed [1, 10]. Our results for the looser barrier synchronisation model \nof MPI makes our tech\u00adnique more widely applicable. Adding stricter conditions for bar\u00adrier synchronisation \ndoes not affect our theoretical results, and the GPUVerify tool used as part of our veri.cation method \nchecks the stricter conditions required in the GPU setting. Given a kernel program P , an initial state \nof P is any kernel state (sA, K) where, for every thread t, the sequence of statements SI . Because P \n[I] computes an I-pre.x sum, we have for the ar\u00adray store sA of SI that sA(out)(k) = sA(in)(i) = I, 0=i=k \n S of K(t) is P . An execution of a program P starts from an initial state. Maximal executions and termination \nfor an initial state are (0, k) for all k . {0, . . . , n - 1}. Hence, by de.nition of rei.\u00adcation for \nthe array store sA of SM we have that sA(out)(k) = S de.ned as for sequential programs. Note that the \ninterleaving na\u00ad ture of the semantics means that there may be multiple maximal executions, contrary \nto the sequential case. sA(in)(i) for all k . {0, . . . , n - 1}. M, 0=i=k 5. Extension to Data-Parallel \nPrograms We next consider data-parallel programs, or kernels, in which threads synchronise by means \nof barriers. Syntax, typing and semantics We extend the language of Fig\u00adure 4 with a barrier synchronisation \nstatement as follows: stmt s ::= \u00b7\u00b7\u00b7 | barrier The typing rule for barrier is straightforward: (T-BARRIER) \nG f barrier : Unit The typing rules for expressions and all other statements are as before (see Figure \n5). Given a .nite set of thread identi.ers D . Int, a kernel (pro\u00adgram) state is a tuple (sA, K) with \nsA an array store and K a map from D to (variable store, sequence of statements)-pairs such that for \neach t . D and variable store sv of K(t) we have sv(tid) = t. The array store sA represents arrays that \nare shared among all threads, and K represents the local variables and instruction se\u00adquence for each \nthread. The variable tid represents the identity of a thread, and must occur read-only in every program \nP . Our theo\u00adretical presentation does not depend on the existence of tid, but the pre.x sum implementations \nwe evaluate in Section 7 rely on each thread having a unique identi.er. Figure 7 gives the operational \nsemantics of our kernel program\u00adming language, where .s is as de.ned in Figure 6. The semantics is a \nstandard interleaving semantics (see rule K-STEP) with an ad\u00additional rule for barrier synchronisation \n(rule K-BARRIER). Rule K-BARRIER checks whether all threads are either at a barrier or have terminated; \nthe additional condition that at least one thread must be at a barrier ensures that rule K-BARRIER and \ntermination are mutually exclusive. The semantics assumes that statements are executed atomically, so \nthat for example a thread can execute a shared state update such as A[i] := A[j] + 1 in a single step. \nThis assumption is not valid in practice: such a statement would involve issuing separate (and Pre.x \nsums and generic pre.x sums Computation and imple\u00admentation of a pre.x sum is de.ned as in the sequential \ncase (see De.nition 3.1) with P interpreted as a kernel program. A generic kernel program and generic \npre.x sum are also de.ned as in the sequential case (De.nition 4.1). Interval monoid Employing the interval \nmonoid as is (De.ni\u00adtion 4.3), we extend the de.nition of the singleton condition to kernel programs, \ntaking into account that there is now a variable store per thread. De.nition 5.1 (Singleton condition \nfor kernel programs). Let P be a generic program with in of type Array(X). An initial state (sA, K) of \nP [I] satis.es the singleton condition for n if 1. for all t . D and v of type SX in P , sv(v) = T with \nsv the variable store of K(t); 2. condition 2 of De.nition 4.4 is satis.ed  Soundness and completeness \nOur soundness and completeness theorem for sequential programs, Theorem 4.5, can now be stated identically \nfor kernel programs. The proof strategy is the same, using rei.cation of abstract states to concrete \nstates to set up a simulation, using lemmas analogous to Lemma 4.6 and Lemma 4.7. We explain the notable \ndifferences in how the proof is set up. The ReifyM function is adapted to map states of kernel pro\u00adgrams \nP [I] to sets of states of kernel programs P [M]. The function treats the array store as before, but \nmust take into account the fact that each thread now has its own variable store and program. Thus, while \nrei.cation of array stores still operates at the level of the whole program state, rei.cation of the \nvariable store and program component now operates at the level of each individual thread. The de.nition \nis left unchanged otherwise. The proof of Lemma 4.6 translates to the case of kernel pro\u00adgrams by observing \nthat barrier[M] = barrier  K(t) = (sv, ss) (sv, sA, ss) .s (s, sA, ss ) K = K[t . (s, ss )] v v (K -ST \nE P ) (sA, K ) .k (sA, K )  (.ss : K(t) = (sv, barrier; ss) . K (t) = (sv, ss)) .t : .sv :.t, sv, \nss : K(t) = (sv, barrier; ss) (K(t) = (sv, e) . K (t) = (sv, e)) (K -BA R R I E R ) (sA, K ) .k (sA, \nK ) Figure 7. Operational semantics of our kernel programming language, extending the sequential rules \nof Figure 6 and that by this algebraic law and the algebraic laws from the proof of Lemma 4.6 we have \nthat the same rule will be applied in both the case of SI and SM , where the proof of Lemma 4.6 is embedded \nin the treatment of the K-STEP case. In proving Lemma 4.7 for kernel programs, we must relate an initial \nstate SM = (sA, K ) of P [M] to an initial state SI of P [I] that satis.es the singleton condition. Otherwise, \nthe proof is identical to that of Lemma 4.7. The de.nition of the initial state SI is easily adapted \nfrom the de.nition in the proof of Lemma 4.7 by applying the de.nition for the variable store to the \nvariable store of each individual thread; the de.nition is left unchanged otherwise. Data race freedom \nWe now de.ne what it means for a kernel program to exhibit a data race. We show that if a kernel program \nis data race-free then, due to the properties of barrier synchronisa\u00adtion, the program computes a deterministic \nresult. The veri.cation technique we present in Section 6 depends on this guarantee of de\u00adterminism and, \nas discussed above, establishing race-freedom of a kernel avoids the need to reason about weak memory \nsemantics or the granularity of memory accesses. Say that we read from an array element A[i] in an execution \nstep if sA(A)(i) is referenced during the evaluation of any of the expressions occurring in the step. \nLikewise, say that we write to an array element A[i] in an execution step if sA(A)(i) is updated in the \nstep. An array element A[i] is accessed if it is either read from or written to in the execution step. \nObserve that an array element can be accessed multiple times in a single execution step, e.g., when evaluating \nA[tid] := A[tid] .M 1M . De.nition 5.2. Let S0 . * k Sn be an execution of a kernel program P . The execution \nis said to have a data race if there are steps Si .k Si+1 and Sj .k Sj+1 along the execution such that: \n distinct threads are responsible for these steps,  a common array element is accessed in both execution \nsteps,  at least one of the accesses writes to the array element,  no application of K-BAR RI E R occurs \nin between the accesses.  A program P is data race-free if for every initial state S0 of P and execution \nstarting from S0 it holds that the execution does not have a data race. Theorem 5.3. Let P be a generic \nkernel program and let M be a monoid. Then: P [M] is data race-free .. P [M ] is data race\u00adfree for all \nmonoids M . Proof. The .-direction is trivial, as M is a monoid. For the .\u00addirection, observe that neither \nthe control-.ow nor the array ac\u00adcesses can be in.uenced by the choice of M by the typing rules and genericity \nof P . We now argue that data race-free kernel programs behave de\u00adterministically. Say that a barrier \nsynchronisation occurs during execution of a program whenever the K-BA R RI E R rule of Figure 7 applies. \nSuppose that a kernel program is race-free, and consider executing the program from an initial state \nS. Race-freedom means that the execution of one thread cannot depend upon the actions of another until \nall threads participate in a barrier synchronisation. Thus while the threads may interleave nondeterminstically, \ntheir individual execution is deterministic and when the .rst barrier syn\u00adchronisation occurs (assuming \nall threads reach a barrier without diverging), the program state S1 is deterministic. By a similar ar\u00adgument, \nindividual thread execution until the next barrier synchro\u00adnisation is deterministic, leading to a deterministic \nprogram state S2 when the second barrier synchronisation occurs. Applying this argument and using induction \non program executions, we can prove the following: Lemma 5.4. Let P be a data race-free kernel program \nand let S be an initial state of P . If there exists a .nite, maximal execution starting from S with \n.nal array store sA, then all executions starting from S are .nite and for all maximal executions the \n.nal array store is sA. 6. An Automated Veri.cation Technique Our theoretical results show that to verify \nfunctional correctness of a generic parallel pre.x sum of length n, implemented as a barrier\u00adsynchronising \nprogram, it suf.ces to prove that the program is free from data races and then test that the program \nbehaves correctly with respect to the interval monoid for every initial state with in = [(0, 0), (1, \n1), . . . , (n - 1, n - 1)]. In practice, a library routine for computing a pre.x sum takes no input \nexcept for in so that there is just a single input to test. GPU kernels are barrier synchronising programs \nthat are re\u00adquired to be data race-free: the semantics of an OpenCL or CUDA kernel is unde.ned if the \nkernel exhibits data races [19, 27]. Thus our results suggest the following method for verifying functional \ncorrectness of GPU kernels that claim to implement generic pre.x sums with respect to a single input \narray: 1. Prove that the GPU kernel is data race-free. 2. Run the interval monoid test to check functional \ncorrectness.  Steps 1 and 2 can be conducted independently, but the func\u00adtional correctness guarantee \nprovided by step 2 is conditional on the result of step 1. We now discuss how we have implemented a practical \nveri.cation method for generic pre.x sums written in OpenCL, based on this approach. Representing a generic \npre.x sum The OpenCL programming model does not support generic functions directly. However, it is easy \nto describe a generic pre.x sum by writing a kernel that uses a symbol TYPE and a macro OPERATOR as placeholders \nfor the concrete type and operator with respect to which the pre.x sum should be executed. A concrete \nchoice of type and operator can be chosen by including a header .le that speci.es TYPE and OPERATOR. \nRace analysis Step 1 above can be discharged to any sound ver\u00adi.er for GPU kernels capable of proving \nrace-freedom. For GPU kernels this includes the PUG [24] and GPUVerify [1] tools, which rely on SMT solvers, \nand the tool described in [23] which performs veri.cation using a combination of dynamic and static analysis. \nIn our experiments (Section 7) we use the GPUVerify tool because it is actively maintained and publicly \navailable, and is the only tool supporting the multi-platform OpenCL programming model, which allows \nus to evaluate step 2 above on a number of platforms.  By Theorem 5.3, we can prove race-freedom of \na generic pre.x sum using any choice of TYPE and OPERATOR. In our experiments we use the interval monoid. \nRunning the interval monoid test case Step 2 above requires an encoding of the interval monoid. Observe \nthat to check a pre.x sum of length n we need only encode elements (i, j) of the interval monoid for \n0 = i = j < n, as well as the 1I and T elements. An element can thus be encoded using O(lg(n)) bits, \nmeaning that O(n lg(n)) space is required for the test input and result. With this encoding, the interval \nmonoid test case can be executed as a regular OpenCL kernel. Soundness, completeness and automation Our \nveri.cation strat\u00adegy is sound due to the guarantees provided by the version of Theorem 4.5 for kernel \nprograms, together with Theorem 5.3 and Lemma 5.4, and the requirement that a sound method for verifying \nrace-freedom is used. As with any dynamic technique, soundness of the testing phase of our approach depends \non the probity of the compiler, driver and hardware implementation of the architecture on which the test \nis executed. In our experiments we guard against this source of unsoundness by testing with respect to \nmultiple, di\u00adverse platforms. Our veri.cation strategy is only complete if the technique used to prove \nrace freedom is complete. The GPUVerify method which we employ is not complete: the technique uses both \nthread abstrac\u00adtion and loop invariant abstraction, which can lead to false positive data race reports. \nA small amount of manual effort is required in order to prove race-freedom of pre.x sum kernels: GPUVerify \ntries to perform automatic inference of invariants required to prove race-freedom, but often this inference \nis not strong enough and manual invariants must be supplied by the programmer. However, these invariants \nare checked by GPUVerify they are not taken on trust by the tool. In the examples we consider in Section \n7 we disabled automatic invariant inference and supplied a small number of relatively sim\u00adple, non-quanti.ed \nloop invariants by hand. The dynamic analysis phase of our veri.cation method is fully automatic. Handling \nextended programming language features Our se\u00adquential language and its data-parallel extension omit \nreal-world language features such as procedures, unstructured control .ow, and pointers (with associated \naliasing issues). We are con.dent that our results apply directly in this extended setting under the \ncondi\u00adtion that data of generic type SX are never accessed via pointers with different element types. \nThis is important for the testing part of our approach; without this restriction it would be possible \nto pass our test case by casting the out array to a char pointer and writing the desired .nal result \nfor the interval monoid byte-by-byte. Prov\u00ading race-freedom in the presence of intricate pointer manipulation \ncan be challenging, but is possible with the right invariants and is supported by GPUVerify. Because \nGPUVerify operates at the level of control .ow graphs using the techniques of [10], unstructured control \n.ow is also supported. Nevertheless, the pre.x sum implementations we have seen in practice do not manipulate \npointers in complex ways, call auxiliary procedures or exhibit unstructured control .ow. As discussed \nin Section 3, the requirement that the input array in be read-only is for ease of presentation only and \ncan be dropped in practice, allowing our technique to be used in verifying pre.x sums that operate in \nplace. Algorithm Depth Size Fanout Sequential Kogge-Stone Sklansky Brent-Kung Blelloch n lg n lg n (2 \nlg n) - 1 2 lg n n n lg n - (n - 1) (n/2) lg n 2n - lg n - 2 2(n - 1) 2 2 n 2 2 Table 2. Characteristics \nof the pre.x sum algorithms considered in this paper where n is the number of elements 7. Experimental \nEvaluation We demonstrate the effectiveness of our method for pre.x sum veri.cation in practice by applying \nit to four different algorithms implemented as OpenCL kernels. All materials required to reproduce our \nexperimental results, including implementations all kernels, are available online.5 Details of pre.x \nsum kernels We evaluate our technique us\u00ading four different, well-known pre.x sum algorithms: Kogge-Stone \n[21], Sklansky [34], Brent-Kung [5] and Blelloch [4]. The Blelloch algorithm is an exclusive pre.x sum. \nFigure 8 provides a circuit diagram description for each algo\u00adrithm. There is a wire for each input and \ndata .ows top-down through the circuit. Each node performs the binary associative operator on its two \ninputs and produces an output that passes down\u00adward and also optionally across the circuit (through a \ndiagonal wire). Table 2 gives a comparison of these algorithms, as well as the straightforward sequential \nimplementation, in terms of circuit char\u00adacteristics: depth, the number of levels; size, the number of \nnodes; and fanout, the maximum number of outbound wires per node, as the size of the input (or width) \nn of the circuit varies. The depth of a circuit indicates how long it takes for the result to propagate \nthrough the circuit, and thus dictates the time taken for pre.x sum computation. Size indicates how many \ngates would be required to build the circuit in hardware, while fanout indicates the required driving \ncapacitance of the output gate. A software implementation of a pre.x sum is work ef.cient if the number \nof operations required is within the same order of magnitude as the sequential version. The size column \nof Figure 2 indicates that Blelloch and Brent-Kung are work-ef.cient, while Kogge-Stone and Sklansky \nare not. A more detailed discussion of these characteristics can be found in [16]. Through a survey of \nseveral GPU code repositories (the AMD APP SDK,6 the NVIDIA CUDA SDK,7 and the SHOC [12], Ro\u00addinia [7] \nand Parboil [37] benchmarks) we found Kogge-Stone to be the most widely used GPU implementation of a \npre.x sum in practice, Blelloch to be used where an exclusive pre.x sum is re\u00adquired, and Brent-Kung \nemployed several times in one large CUDA kernel that computes eigenvalues of a matrix. Sklansky is the \noldest pre.x sum algorithm we consider; we did not see it used in practi\u00adcal GPU kernels. Experimental \nsetup As discussed in Section 6, we use the GPU-Verify tool [1] to prove that each kernel is free from \ndata races. These experiments were performed on a Linux machine with a 1.15 GHz AMD Phenom 9600B 4 core \nprocessor, using a version of GPUVerify downloaded from the tool web page8 on 26 June 2013. We then verify \nfunctional correctness for each kernel by running the interval of summations test case. We give results \nfor .ve differ\u00adent platforms: two NVIDIA GPUs a 1.16 GHz GeForce GTX 570 5 http://multicore.doc.ic.ac.uk/tools/GPUVerify/POPL14 \n6 http://developer.amd.com/tools/heterogeneous-computing/ amd-accelerated-parallel-processing-app-sdk/ \n7 https://developer.nvidia.com/gpu-computing-sdk 8 http://multicore.doc.ic.ac.uk/tools/GPUVerify/  \n(a) Kogge-Stone (b) Sklansky (c) Brent-Kung (d) Blelloch Figure 8. Circuit representations of the pre.x \nsum algorithms for n = 8 elements and a 1.15 GHz Tesla M2050; two Intel CPUs a 2.13 GHz 4 core Xeon \nE5606 and a 2.67 GHz 6 core Xeon X5650; and one ARM GPU a 533 MHz 4 core Mali T604. These devices exhibit \na range of power and performance characteristics. The NVIDIA GPUs of\u00adfer a large number of parallel processing \nelements running at a rel\u00adatively low clock-rate; the Intel CPUs run at a higher clock-rate but exhibit \nless parallelism; and the ARM GPU is designed for high power-ef.ciency. We chose to run on multiple platforms \nto guard against possible unsound results as a result of a particular compiler, driver or hardware con.guration. \nEach experiment was run with a timeout of 1 hour. All the timing results we present are averages over \nthree runs. In [38], Voigtl\u00a8ander shows for sequential programs that a generic pre.x sum is correct for \nall input lengths if it can be shown to behave correctly for all input lengths with respect to two binary \noperators over a set of three elements. He shows further that it is suf.cient to consider O(n 2) test \ninputs: n(n + 1)/2 tests using the .rst operator and n - 1 tests using the second operator. The result \nof [38] considers all possible n, but also restricts so that a pre.x sum of a speci.c length n can be \nshown correct by testing the corresponding set of inputs. Our Lemma 5.4 allows us to lift this method \nto race-free barrier-synchronising programs. Thus, by way of comparison, we also tried dynamically verifying \nthe pre.x sum kernels by running, for each element size, the set of Voigtl\u00a8 ander tests. We discuss Voigtl\u00a8 \nander s paper further in the related work (Section 8). Veri.cation using the interval of summations test \ncase and the Voigtl\u00a8 ander tests both require race-freedom to be established, thus the overhead of race \nchecking applies to both approaches. Results for proving race-freedom Table 3 presents veri.cation times, \nin seconds, for proving race-freedom of each of our pre.x sum kernels using GPUVerify, for a selection \nof power-of-two element counts up to 231. Times for the power-of-two thread counts not shown are in the \nsame order of magnitude. The results show that veri.cation time is more-or-less indepen\u00addent of the number \nof threads executing the kernel. This is because GPUVerify checks race-freedom for a kernel with respect \nto an ar\u00adbitrary pair of threads, and reasons about loops using invariants rather than by unrolling. \nThis excellent scalability demonstrates that the data race analysis aspect of our veri.cation method \nis prac\u00adtical for very large arrays. As noted in Section 6, we disabled automatic invariant inference \nin GPUVerify as it did not allow fully automatic veri.cation of our examples. Instead we provided relatively \nsimple, non-quanti.ed loop invariants for each of our kernels in order for veri.cation to succeed. For \nexample, for the loop of the Kogge-Stone kernel shown in Figure 2 we provided the following invariant \n(no further invariants were necessary): no read(out) . no write(out) which speci.es that no access to \nthe out array is in-.ight at the head of the loop. The most intricate invariant we had to specify, for \nthe Blelloch kernel, was: (d &#38; (d - 1)) = 0 . ((o.set = 0 . d = N) . d * o.set = N) . Here, d and \no.set are loop counters, with d increasing in powers\u00adof-two from 1 to N, and o.set decreasing in powers-of-two \nfrom N to 1, and .nally reaching zero. The conjunct (d &#38; (d - 1)) = 0 uses the bitwise-and operator, \n&#38;, to compactly express that d must be a power-of-two or zero. Counting each top-level conjunct of \na loop invariant as a sep\u00adarate invariant, the number of invariants required for veri.cation of each \nkernel was as follows: (Kogge-Stone, 2); (Sklansky, 1); (Brent-Kung, 4); (Blelloch, 6). The invariants \ndid not have to be tailored for individual thread counts. Results for dynamic analysis The I rows of \nTable 4 present, for each pre.x sum and platform, the time in seconds taken to run the single interval \nof summations test for power-of-two array sizes from 29 to 214 and 218 to 220 (results in between follow \na similar trend). For each array size we also show in the #Voigtl \u00a8 ander tests row the total number \nof tests that would need to be run to verify the kernel using Voigtl\u00a8ander s method and the V rows show \nhow long these tests took to run. The times are end-to\u00adend, taking into account device initialisation, \ncreation of memory buffers, compilation of the OpenCL kernel,9 copying data into memory buffers, running \nthe test and validating the result. For the Voigtl\u00a8ander tests we used a wrapper so that device initialisation, \ncreation of memory buffers and kernel compilation is performed only once for each array size. We note \nthat while in theory an array of length n can be processed by n/2 concurrent threads (or n threads in \nthe case of Kogge-Stone), it is up to the OpenCL runtime to decide how to schedule threads across hardware \nresources, and that in practice a large number of threads will be launched in a series of waves. From \nthe I rows it can be seen that running the interval of summations test case is very fast on all platforms, \neven for arrays of length 220. It may seem surprising that the runtime does not increase signi.cantly \nas the array size increases. This is because (a) computing with the interval monoid is very cheap, requiring \nonly integer equality testing and addition by a constant and (b) the expense of online compilation of \nthe OpenCL kernel, which dominates the runtime of these simple tests. The V rows show that, unsurprisingly, \nrunning a quadratic num\u00adber of tests per array size does not scale well. On all platforms, we = 214 found \nthat sizes of n exhausted our time limit of 1 hour, showing that the Voigtl\u00a8ander method will not scale \nto large arrays. 8. Related Work Relationship to results by Voigtl \u00a8ander and Sheeran The closest work \nto this paper is work by Voigtl\u00a8ander [38] which proves two interesting results for sequential generic \npre.x sums. 9 In the OpenCL model, a kernel is compiled at runtime using an online compiler, so that \nit need not be pre-compiled for any given device [19].  210 211 212 213 214 229 230 231 21 22 23 28 \n29 n ... ... Kogge-Stone 5.7 5.8 5.9 5.8 5.8 6.0 5.6 5.8 5.7 5.6 6.4 6.4 6.6 Sklansky 5.6 6.1 6.5 6.8 \n6.6 6.7 6.8 6.7 6.5 6.4 7.3 8.1 7.9 Brent-Kung 5.9 6.7 7.4 12.3 11.4 12.9 10.2 10.3 10.7 12.6 14.9 11.1 \n16.4 Blelloch 6.0 7.4 9.0 12.4 12.6 13.8 12.0 14.1 11.6 12.3 15.5 13.0 14.8 Table 3. Time (in seconds) \ntaken to prove race freedom for pre.x sum kernels, for increasing array lengths. An array of length n \nis processed by n/2 threads, except in the case of Kogge-Stone where n threads are used. 210 211 212 \n213 214 218 219 220 n 29 . . . #Voigtl ander tests \u00a8131,839 525,823 2.1 \u00d7 106 8.4 \u00d7 106 3.4 \u00d7 107 1.3 \n\u00d7 108 3.4 \u00d7 1010 1.4 \u00d7 1011 5.5 \u00d7 1011 NVIDIA GeForce GTX 570 Kogge-Stone V 19.2 76.2 337.6 1463.9 -----I \n0.4 0.5 0.3 0.4 0.3 0.4 0.4 0.4 0.4 Sklansky V 18.5 71.8 320.2 1438.3 -----I 0.4 0.4 0.4 0.4 0.4 0.4 \n0.4 0.4 0.4 Brent-Kung V 19.0 69.3 317.3 1454.3 -----I 0.5 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 Blelloch V \n19.2 75.4 324.2 1595.3 -----I 0.5 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 NVIDIA Tesla M2050 Kogge-Stone V 14.6 \n36.1 160.9 653.0 2796.8 ----I 0.3 0.3 0.6 0.5 0.5 0.5 0.6 0.5 0.6 Sklansky V 12.2 32.5 149.6 609.3 2601.5 \n----I 0.3 0.3 0.5 0.5 0.5 0.5 0.6 0.6 0.6 Brent-Kung V 10.9 35.9 165.7 678.1 2889.2 ----I 0.3 0.3 0.6 \n0.5 0.6 0.5 0.6 0.6 0.6 Blelloch V 10.9 36.7 166.0 679.9 2931.8 ----I 0.3 0.3 0.5 0.6 0.6 0.6 0.6 0.6 \n0.6 Intel Xeon X5650 Kogge-Stone V 21.1 109.8 660.8 3467.1 -----I 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 \nSklansky V 12.2 78.4 404.8 2003.9 -----I 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 Brent-Kung V 12.6 80.4 469.9 \n2272.5 -----I 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 Blelloch V 12.9 80.7 472.1 2332.5 -----I 1.3 1.3 1.3 \n1.3 1.3 1.3 1.3 1.4 1.3 Intel Xeon E5606 Kogge-Stone V 107.0 909.2 -------I 1.9 1.9 2.1 2.1 2.0 2.1 2.4 \n2.7 3.2 Sklansky V 38.7 266.0 1221.5 ------I 1.9 1.9 2.0 2.1 2.0 2.0 2.2 2.3 2.4 Brent-Kung V 51.5 409.1 \n1793.8 ------I 2.0 2.0 2.1 2.1 2.1 2.1 2.3 2.3 2.5 Blelloch V 54.3 429.9 1900.3 ------I 1.9 2.0 2.1 2.1 \n2.1 2.1 2.4 2.4 2.6 ARM Mali T604 Kogge-Stone V 287.0 1166.1 -------I 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 \n0.5 Sklansky V 287.2 1147.6 -------I 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.5 Brent-Kung V 287.4 1108.1 -------I \n0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.5 0.6 Blelloch V 277.0 1105.3 -------I 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.5 \n0.6 Table 4. Time (in seconds) taken to establish correctness of pre.x sum implementations, for increasing \narray lengths, on NVIDIA GPU, Intel CPU and ARM GPU architectures. The number of test cases associated \nwith Voigtl \u00a8 ander s method for each array length is also shown. First Voigtl\u00a8ander shows, using relational \nparametricity, that a this result was inspired by earlier unpublished work by Sheeran; generic pre.x \nsum is correct if and only if it behaves correctly for Sheeran con.rms this claim when exploiting the \nresult in later work each length n with respect to integer lists and list concatenation on the design \nof pre.x sum algorithms [33]. We refer to this as when applied to the input [[0], [1], . . . , [n - 1]], \nthat is, it yields the Sheeran result. The result also holds for .xed lengths n, which the output [[0], \n[0, 1], . . . , [0, . . . , n - 1]]. Voigtl\u00a8ander states that means the result is similar to our result \nfor sequential pre.x sums with respect to the interval monoid. However, the Sheeran result cannot be \nused for practical veri.cation of pre.x sums for large n, because O(n 2 lg(n)) space is required to represent \nthe result.10 Our interval of summations monoid avoids this problem by exploiting the fact that, as argued \nin Section 4, a correct generic pre.x sum should never compute a non-contiguous summation. The interval \nof summations abstraction thus allows a contiguous summation to be represented precisely and compactly \nas an interval (i, j) (or as 1I in the case of an empty summation), and collapses all other summations \ninto the absorbing element T. Letting L denote the monoid of integer lists under list concate\u00adnation \nemployed by the Sheeran method, there is an obvious homo\u00admethod described in [23] uses a combination \nof dynamic and static analysis for race-freedom veri.cation. We employed GPUVerify to prove race-freedom \nof pre.x sum kernels in our experimental eval\u00aduation (Section 7). The GKLEE [25] and KLEE-CL [9] methods \nemploy dynamic symbolic execution, based on the KLEE tool [6], to .nd data races and array bounds errors \nin CUDA and OpenCL kernels, respectively. A recent technique for functional veri.cation of OpenCL ker\u00adnels \nusing permission-based separation logic [18] could, in princi\u00adple, be applied to generic pre.x sum kernels. \nHowever, tool support for automation of this method is not yet available. In prior work we introduced \nbarrier invariants [8] to enable reasoning about data-dependent GPU kernels, and used barrier in\u00ad morphism \n. : L . I de.ned by: variants to statically prove functional properties of Blelloch, Brent\u00ad 1I if m = \n0 Kung and Kogge-Stone pre.x sum kernels. The challenges in mak\u00ad(x1, xm) if m > 0 and ing this approach \nscale provided insights which ultimately led to . . .. . .. .([x1, . . . , xm]) = xi+1 = xi + 1 (1 = \ni < m) the interval of summations abstraction, and we used an early for\u00admulation of the abstraction to \nverify the Kogge-Stone kernel in [8]. T otherwise The method for pre.x sum veri.cation presented here \nsigni.cantly This homomorphism discards exactly those summations that outperforms the technique of [8], \nbut the concept of barrier invari\u00ad ants has wider applicability. 9. Conclusions cannot contribute to \na correct generic pre.x sum. Secondly, Voigtl\u00a8ander presents an elegant proof of the 0-1-2-Principle \nfor parallel pre.x computation. In the spirit of the 0-1-Principle of Knuth [20],11 the 0-1-2-Principle \nstates that a pre.x We have introduced the interval of summations abstraction, investi\u00adsum algorithm \nis correct on all ternary sequences with every as\u00adgated theoretical guarantees provided by this abstraction \nfor verify\u00adsociative operator (de.ned over the ternary set) if and only if it is ing pre.x sum algorithms, \nand shown that it can be used to designcorrect on any input sequence with an associative operator. In \nfact, a practical and scalable veri.cation method for GPU kernel imple\u00adcarefully tracing his proof, Voigtl\u00a8ander \nobserves that it suf.ces to mentations of pre.x sums. Our experimental results demonstrateconsider just \ntwo operators and for every length n a particular input that we can prove race-freedom of pre.x sum implementations \nfor all conceivably useful array sizes, after which checking functional correctness of a pre.x sum boils \ndown to running a single test case, taking no longer than the time required to run the pre.x sum in practice. \nWe believe this substantiates our claim that we have made a major step towards solving the problem of \nfunctional veri.cation for GPU implementations of generic pre.x sums. set of ternary sequences of size \nO(n 2) and O(n) for his .rst and second operator, respectively. As with the Sheeran result, this re\u00ad \nsult also holds for .xed lengths n. Voigtl\u00a8 ander does not present an experimental evaluation of his \nmethod in [38]; we believe that our work is the .rst to do so. As we demonstrated in the experiments \nof Section 7, verifying a pre.x sum by running Voigtl\u00a8 ander s set of tests does not scale to large array \nsizes. Our approach depends on the ability to prove that a data-parallel program behaves deterministically. \nFor models of computation where barriers provide the only means of synchronisation this boils down to \nproving race-freedom (Lemma 5.4). Our approach thus extends to pre.x sums written in programming models \nsuch as OpenMP, MPI and pthreads as long as these implementations use barriers exclusively for synchronisation, \nin favour of locks or atomic operations. Correspondingly, our method cannot be applied to GPU kernel \nimplementations where threads communicate using atomics; in practice we have not seen the use of atomics \nin pre.x sum kernels. The focus of [33, 38] is on sequential HASKELL programs de\u00ad scribing parallel synchronous \nhardware. In contrast, we have pre\u00ad sented a method for verifying pre.x sums implemented as asyn\u00ad chronous \nbarrier-synchronising programs, leading to a practical method for verifying GPU kernel implementations. \nDue to our im\u00ad perative, data-parallel setting, we present proofs using a direct sim\u00ad ulation argument; \nwe are not aware of any work on using relational parametricity to reason about data-parallel programs \nand believe this would be challenging. Correct-by-derivation pre.x sums An alternative approach by Hinze \n[17] is to construct pre.x sums that are correct by derivation. In Hinze s work, rather than verifying \ncandidate implementations for functional correctness, new pre.x sum circuits are built from a set of \nbasic primitives and combinators. The correctness of these circuits is ensured by a set of algebraic \nlaws derived for these combinators. Similar to the work of Sheeran, pre.x sums are given as HASKELL programs \ndescribing circuit layouts. We are not aware of any work that translates this approach to a data-parallel \nsetting. Formal veri.cation of GPU kernels Recently a number of tech\u00adniques for formal or semi-formal \nanalysis of GPU kernels have been proposed [1, 9, 18, 23 25], and formal semantics for GPU ker\u00adnels have \nbeen studied in-depth [10, 15]. The PUG [24] and GPU-Verify [1] methods aim to statically prove race-freedom, \nwhile the 10 The space complexity is O(n2 lg(n)) for correct algorithms; an incorrect algorithm could \napply the concatenation operator arbitrarily many times, requiring unbounded space. 11 If an oblivious \nsorting algorithm is correct on all Boolean valued input sequences then it is correct on input sequences \nover any totally ordered set. We have considered veri.cation of pre.x sums with respect to .xed array \nsizes. To prove that a pre.x sum is correct for all array sizes it would be necessary to prove race-freedom \nfor arbitrary array sizes, and also to prove that the pre.x sum would compute the correct result for \nour interval of summations test case for every array size. While the former is beyond the scope of current \ntools such as GPUVerify, and the latter obviously cannot be achieved through testing, one could attempt \nto establish both through (manual or partially automated) mathematical proof. We deliberately designed \nthe interval of summations abstraction to capture the speci.c case of pre.x sums, due to the importance \nof this class of algorithms. The abstraction can be used to analyse any algorithm that operates over \nan abstract monoid as long as the results computed by the algorithm are required to be contiguous summations. \nWe are aware of one further class of such algorithms: reduction operations. The reduction of an array \n[s1, s2, . . . , sn] is the sum s1 . s2 . \u00b7 \u00b7 \u00b7 . sn. Indeed, a reduction is performed during the .rst \nphase of the Blelloch and Brent-Kung pre.x sum algorithms.  A natural question is to ask if there are \npre.x sum algorithms that gain ef.ciency by exploiting other properties of operators, such as commutativity \nor idempotence. We are aware of recent work by Sergeev [32] which investigates pre.x sum circuits for \nthe XOR operator, exploiting the fact that this operator satis.es the iden\u00adtity x . y . y = x. Beyond \npre.x sums, there is scope for de\u00advising abstractions to allow representation-independent reasoning via \na canonical test case in less restricted settings. For example, potentially discontiguous summations \nof monoid elements can be represented using lists [33, 38], and commutativity can be accom\u00admodated by \nswitching to a bag representation. However, these rep\u00adresentations lose the space-ef.ciency afforded \nby the interval of summations abstraction which allows our approach to scale. Acknowledgments We are \ngrateful to Josh Berdine, Pantazis Deligiannis, Samin Ish\u00adtiaq, Alan Mycroft, Jakob Grue Simonsen, John \nWickerson and our POPL reviewers for their insightful comments on various drafts of this work, and to \nAkash Lal for helpful discussion. We thank Daniel Liew (Imperial College), Anton Lokhmotov (ARM) and \nDong Ping Zhang (AMD) for their assistance with our experimental evaluation. Finally, we thank Mary Sheeran \nand Janis Voigtl\u00a8ander for their work, which inspired our efforts. References [1] A. Betts, N. Chong, \nA. F. Donaldson, S. Qadeer, and P. Thomson. GPUVerify: a veri.er for GPU kernels. In OOPSLA, pages 113 \n132, 2012. [2] M. Billeter, O. Olsson, and U. Assarsson. Ef.cient stream compaction on wide SIMD many-core \narchitectures. In HPG, pages 159 166, 2009. [3] G. E. Blelloch. Scans as primitive parallel operations. \nIEEE Trans. Comput., 38(11):1526 1538, 1989. [4] G. E. Blelloch. Pre.x sums and their applications. In \nJ. H. Reif, editor, Synthesis of Parallel Algorithms. Morgan Kaufmann, 1990. [5] R. P. Brent and H.-T. \nKung. A regular layout for parallel adders. IEEE Trans. Computers, 31(3):260 264, 1982. [6] C. Cadar, \nD. Dunbar, and D. R. Engler. KLEE: Unassisted and au\u00adtomatic generation of high-coverage tests for complex \nsystems pro\u00adgrams. In OSDI, pages 209 224, 2008. [7] S. Che et al. Rodinia: A benchmark suite for heterogeneous \ncomput\u00ading. In Workload Characterization, pages 44 54, 2009. [8] N. Chong, A. F. Donaldson, P. H. Kelly, \nJ. Ketema, and S. Qadeer. Barrier invariants: A shared state abstraction for the analysis of data\u00addependent \nGPU kernels. In OOPSLA, pages 605 622, 2013. [9] P. Collingbourne, , C. Cadar, and P. H. J. Kelly. Symbolic \ntesting of OpenCL code. In HVC 11, pages 203 218, 2012. [10] P. Collingbourne, A. F. Donaldson, J. Ketema, \nand S. Qadeer. Inter\u00adleaving and lock-step semantics for analysis and veri.cation of GPU kernels. In \nESOP, pages 270 289, 2013. [11] P. Cousot and R. Cousot. Abstract interpretation: A uni.ed lattice model \nfor static analysis of programs by construction or approxima\u00adtion of .xpoints. In POPL, pages 238 252, \n1977. [12] A. Danalis et al. The scalable heterogeneous computing (SHOC) benchmark suite. In GPGPU 2010, \npages 63 74, 2010. [13] O. E .gecio .glu, E. Gallopoulos, and C. Koc\u00b8. A parallel method for fast and \npractical high-order Newton interpolation. BIT Numerical Mathematics, 30:268 288, 1990. [14] W. Gropp, \nE. Lusk, and A. Skjellum. Using MPI: Portable Parallel Programming with the Message Passing Interface. \nMIT Press, 2nd edition, 1999. [15] A. Habermaier and A. Knapp. On the correctness of the SIMT execution \nmodel of GPUs. In ESOP, pages 316 335, 2012. [16] M. Harris, S. Sengupta, and J. Owens. Parallel pre.x \nsum (scan) with CUDA. In H. Nguyen, editor, GPU Gems 3. Addison-Wesley, 2007. [17] R. Hinze. An algebra \nof scans. In MPC, pages 186 210, 2004. [18] M. Huisman and M. Mihelci.c.\u00b4Speci.cation and veri.cation \nof GPGPU programs using permission-based separation logic. In BYTE-CODE, 2013. [19] Khronos OpenCL Working \nGroup. The OpenCL speci.cation, ver\u00adsion 1.2, 2012. [20] D. E. Knuth. The Art of Computer Programming, \nvolume 3. Addison-Wesley, 2nd edition, 1998. [21] P. M. Kogge and H. S. Stone. A parallel algorithm for \nthe ef.cient solution of a general class of recurrence equations. IEEE Trans. Computers, C-22(8):786 \n793, 1973. [22] R. E. Ladner and M. J. Fischer. Parallel pre.x computation. J. ACM, 27(4):831 838, 1980. \n[23] A. Leung, M. Gupta, Y. Agarwal, et al. Verifying GPU kernels by test ampli.cation. In PLDI, pages \n383 394, 2012. [24] G. Li and G. Gopalakrishnan. Scalable SMT-based veri.cation of GPU kernel functions. \nIn FSE, pages 187 196, 2010. [25] G. Li, P. Li, G. Sawaya, G. Gopalakrishnan, I. Ghosh, and S. P. Rajan. \nGKLEE: concolic veri.cation and test generation for GPUs. In PPoPP, pages 215 224, 2012. [26] D. Merrill \nand A. Grimshaw. Parallel scan for stream architectures. Technical Report CX2009-14, Department of Computer \nScience, Uni\u00adversity of Virginia, 2009. [27] NVIDIA. CUDA C programming guide, version 5.0, 2012. [28] \nB. C. Pierce. Types and Programming Languages. MIT Press, 2002. [29] P. Sanders and J. L. Tr \u00a8aff. Parallel \npre.x (scan) algorithms for MPI. In PVM/MPI, pages 22 29, 2006. [30] N. Satish, M. Harris, and M. Garland. \nDesigning ef.cient sorting algorithms for manycore GPUs. In IPDPS, pages 1 10, 2009. [31] S. Sengupta, \nM. Harris, Y. Zhang, and J. D. Owens. Scan primitives for GPU computing. In GH, pages 97 106, 2007. [32] \nI. Sergeev. On the complexity of parallel pre.x circuits. Technical Re\u00adport TR13-041, Electronic Colloquium \non Computational Complexity, 2013. [33] M. Sheeran. Functional and dynamic programming in the design \nof parallel pre.x networks. J. of Funct. Program., 21(1):59 114, 2011. [34] J. Sklansky. Conditional-sum \naddition logic. IRE Trans. Electronic Computers, EC-9:226 231, 1960. [35] B. So, A. M. Ghuloum, and Y. \nWu. Optimizing data parallel operations on many-core platforms. In In First Workshop on Software Tools \nfor Multi-Core Systems (STMCS), 2006. [36] H. S. Stone. Parallel processing with the perfect shuf.e. \nIEEE Trans. Comput., 20(2):153 161, 1971. [37] J. Stratton et al. Parboil: A revised benchmark suite \nfor scienti.c and commercial throughput computing. Technical Report IMPACT-12-01, University of Illinois \nat Urbana-Champaign, 2012. [38] J. Voigtl \u00a8ander. Much ado about two (pearl): a pearl on parallel pre.x \ncomputation. In POPL, pages 29 35, 2008.  \n\t\t\t", "proc_id": "2535838", "abstract": "<p>Prefix sums are key building blocks in the implementation of many concurrent software applications, and recently much work has gone into efficiently implementing prefix sums to run on massively parallel graphics processing units (GPUs). Because they lie at the heart of many GPU-accelerated applications, the correctness of prefix sum implementations is of prime importance.</p> <p>We introduce a novel abstraction, the interval of summations, that allows scalable reasoning about implementations of prefix sums. We present this abstraction as a monoid, and prove a soundness and completeness result showing that a generic sequential prefix sum implementation is correct for an array of length $n$ if and only if it computes the correct result for a specific test case when instantiated with the interval of summations monoid. This allows correctness to be established by running a single test where the input and result require O(n lg(n)) space. This improves upon an existing result by Sheeran where the input requires O(n lg(n)) space and the result O(n<sup>2</sup> \\lg(n)) space, and is more feasible for large <i>n</i> than a method by Voigtlaender that uses O(n) space for the input and result but requires running O(n<sup>2</sup>) tests. We then extend our abstraction and results to the context of data-parallel programs, developing an automated verification method for GPU implementations of prefix sums. Our method uses static verification to prove that a generic prefix sum implementation is data race-free, after which functional correctness of the implementation can be determined by running a single test case under the interval of summations abstraction.</p> <p>We present an experimental evaluation using four different prefix sum algorithms, showing that our method is highly automatic, scales to large thread counts, and significantly outperforms Voigtlaender's method when applied to large arrays.</p>", "authors": [{"name": "Nathan Chong", "author_profile_id": "81548601456", "affiliation": "Imperial College London, London, United Kingdom", "person_id": "P4383860", "email_address": "nyc04@imperial.ac.uk", "orcid_id": ""}, {"name": "Alastair F. Donaldson", "author_profile_id": "81318493370", "affiliation": "Imperial College London, London, United Kingdom", "person_id": "P4383861", "email_address": "afd@imperial.ac.uk", "orcid_id": ""}, {"name": "Jeroen Ketema", "author_profile_id": "81384591133", "affiliation": "Imperial College London, London, United Kingdom", "person_id": "P4383862", "email_address": "jketema@imperial.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535882", "year": "2014", "article_id": "2535882", "conference": "POPL", "title": "A sound and complete abstraction for reasoning about parallel prefix sums", "url": "http://dl.acm.org/citation.cfm?id=2535882"}